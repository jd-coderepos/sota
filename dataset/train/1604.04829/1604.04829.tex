\begin{filecontents*}{example.eps}
gsave
newpath
  20 20 moveto
  20 220 lineto
  220 220 lineto
  220 20 lineto
closepath
2 setlinewidth
gsave
  .4 setgray fill
grestore
stroke
grestore
\end{filecontents*}
\RequirePackage{fix-cm}
\documentclass{article}       

\usepackage{graphicx}
\usepackage{amssymb}
\usepackage{supertabular}
\usepackage{amsmath}
\usepackage{algpseudocode}
\usepackage{algorithm}
\usepackage{tabularx}
\usepackage{multicol}
\usepackage{lineno}
\usepackage{booktabs}
\usepackage{lscape}
\usepackage{natbib}
\usepackage{subfigure}
\usepackage{color}

\begin{document}

\title{A heuristic approach for dividing graphs into bi-connected components with a size constraint}




\author{Raka Jovanovic      \\
Qatar Environment and Energy Research Institute,\\
 Hamad bin Khalifa University, Doha, Qatar\\
 rjovanovic@qf.org.qa\\
 \\
        Tatsushi Nishi \\
          Graduate School of Engineering Science,\\
           Osaka University,  Osaka,Japan\\
            \\
        Stefan Vo{\ss}\\
        Institute of Information Systems, \\
        University of Hamburg, Germany\\
        and\\
 Escuela de Ingenieria Industrial, \\
Pontificia Universidad Cat\'olica de Valpara\'iso, Chile
        }








\maketitle

\begin{abstract}
In this paper we propose a new problem of finding the maximal bi-connected partitioning of a graph with a size constraint (MBCPG-SC).  With the goal of finding approximate solutions for the MBCPG-SC, a heuristic method is developed based on the open ear decomposition of graphs. Its essential part is an adaptation of the breadth first search which makes it possible to grow bi-connected subgraphs. The proposed randomized algorithm consists of  growing several subgraphs in parallel. The quality of solutions generated in this way is further improved using a local search which exploits neighboring relations between the subgraphs. In order to evaluate the performance of the method, an algorithm for generating pseudo-random unit disc graphs with known optimal solutions is created. The conducted computational experiments show that the proposed  method  frequently manages to find optimal solutions and has an average error of  only a few percent to known optimal solutions.   Further, it manages to find high quality approximate solutions for graphs having up to 10.000 nodes in reasonable time.
\end{abstract}


\section{Introduction}

The bi-connectivity of graphs is essential for many real world applications ranging from power distribution systems, communication networks and many others. The reason for this is that such typologies provide a certain level of resistance to failures, and as a result more robust and reliable systems \citep{Zhang2009812,Moraes20133188,Goldschmidt199697,hu2010generalized}. These benefits are a direct consequence of the fact that such graphs have two disjoint paths connecting any two nodes in the graphs. This property is often called 2-connectivity of graphs. In literature there is differentiation between vertex  and edge 2-connected graphs, where the two paths are vertex  or edge disjoint, respectively. In practice this means that the vertex/edge 2-connected graph stays connected if any single vertex/edge is removed from it. Vertex 2-connectivity is a stronger property in the sense that every such graph is also 2-edge connected but the reverse is not necessarily true. The term bi-connected graph is used for 2-vertex connected graphs. 

Testing if a graph is bi-connected can be done efficiently using the standard algorithm for finding articulation points of a graph based on depth first search  in linear time \citep{hopcroft1973algorithm}. A similar approach has also been used for finding a 3-connected partitioning of  a graph \citep{TriConnected}. Other examples of algorithms for testing bi-connectivity of a graph  exploit the fact that bi-connected graphs have an ear  \citep{EarDecomposition} or  chain  \citep{schmidt2013simple} decomposition.  
There are several types of mixed integer programs based on multi-commodity flow constraints that are used for exploring bi-connectivity, but such models generally have a large number of variables \citep{MorganG08}. There are alternative formulations containing a lower number of variables but having an exponential number of constraints \citep{doForte2013415,buchanan2015integer}.  


For many graph optimization problems, like the weighted vertex cover and the independent set, it is sufficient to solve the problem separately on each of the bi-connected components \citep{HOCHBAUM1993203}.  The most commonly used method for partitioning graphs into bi-connected components is Tarjan's algorithm, which accomplishes this task  in linear time \citep{tarjan1972depth}. There are several interesting variations of the original algorithm with similar computational times \citep{Pearce201647}. The problem with these types of algorithms is that it is hard to modify them to a setting where the subgraphs need to satisfy some additional constraints.
  The proposed work is focused on developing a method that can partition a graph into bi-connected subgraphs with a maximal allowed size, but the general concept can be adapted to other interesting constraints.   In current literature there are many practical problems which are modeled using the problem of partitioning graphs into connected subgraphs. 
Some examples are applications in surveillance systems \citep{Borra2015227}, data clustering \citep{shafique2004partitioning} and education \citep{matic2012maximally}. An interesting group of applications comes from the satisfactory graph partitioning problem, like finding communities within social or biological networks,  defense alliances, artificial intelligence development, etc. \citep{Bazgan2010271}. Partitioning problems defined on supply/demand graphs have proven to be essential in modeling systems of interconnected microgrids   \citep{SelAdeq,SelHea,BalancedGSD,SupDem,MIPGSD,Parametric,Tree4}. Clustering in 
   For many of them it would be reasonable to substitute the constraint of connectivity with bi-connectivity, producing the benefit of higher reliability of the system.  This type of extension has frequently been applied  to modeling real-world systems based on general  graph problems  including connectivity. Some examples are power optimization in ad hoc wireless  networks \citep{Moraes20133188} and facility layout problems \citep{Goldschmidt199697}.  A common approach for solving such problems is to start from an approximate solution that is only connected  and extend it with additional  nodes to achieve bi-connectivity, like in the case of the problem of constructing a 2-connected virtual backbone in wireless networks     \citep{BackBone}. 

In case of graph problems containing connectivity constraints,  a standard approach is to grow a partial solution by adding neighboring nodes. One example is the method used for finding the minimal connected dominating set of a graph \citep{Raka2}. The concept  of growth has also been extended to problems where a graph is divided into connected components. In case of such problems the general approach is to grow several subgraphs in parallel  with the constraint that no vertex can be added to more than one of them. The effectiveness of this type of method  is  well presented on the problem of partitioning  supply/demand graphs into connected subgraphs \citep{BalancedGSD,MultiHeuristicGSD,Jovanovic2016317}. It is important to note that the concept of growing a solution gives a high level of flexibility of the method, in the sense of potential applications. Another advantage of growth based algorithms is that they can easily be improved by their extension to metaheuristics like  the ant colony optimization      \citep{dorigo2005ant}, the GRASP algorithm \citep{GRASP} and the variable neighborhood search \citep{hansen2010variable}. 


In this paper we introduce a new problem of finding the maximal bi-connected partitioning of a graph with a size constraint (MBCPG-SC). For the newly defined problem we show  NP-hardness. Because of this a growth based algorithm is developed for  MBCPG-SC for finding approximate solutions. More precisely, it is solved using a heuristic procedure that exploits the fact that each bi-connected graph has an ear decomposition. The algorithm is based on a breadth first search (BFS) that also tracks additional properties of the nodes in the BFS tree. The additional information makes it possible to have an efficient way to "grow" a bi-connected subgraph by expanding it with suitable ears. The concept of growing a bi-connected graph using an ear decomposition is also used in case of constructing a fault-tolerant connected set cover problem \citep{Zhang2009812}. In this algorithm the best open ears for extending the current solution are found using the idea of shortest cycles in the original graph. A similar approach is used for the  minimum 2-connected r-hop dominating set problem  \citep{li2010two}.  The proposed  method consists in  growing several subgraphs in parallel, with some auxiliary corrections applied to  the corresponding BFS trees. To improve the performance of the basic algorithm several methods of randomization are developed. The quality of found solutions is further enhanced using  a local search procedure. 

The practical objective of the proposed graph problem and the corresponding solution method is its application to real word problems in the field of smartgrids, more precisely on the underlying wireless networks. Such systems are well presented using unit disc graphs. The proposed graph problem is closely related to the clustering scheme for hierarchical control of wireless networks \citep{banerjee2001clustering,chang2006cluster}. Because of this,  the focus of the numerical experiments is on unit disc graphs. To be able to evaluate the method, an extensive effort has been dedicated to developing an algorithm for generating problem instances with known optimal solutions. Our computational results  show that the proposed method is able to find optimal solutions for small graphs. In case of large graphs (10.000 nodes) the method manages to find solutions within a few percent of error, in reasonable time. 

The paper is organized as follows. In the second section we give the definition for MBCPG-SC and a proof of NP- hardness. In the following section we present the method for growing a bi-connected subgraph. The third section gives  details of the algorithm for parallel growth of several subgraphs and randomization. The next section describes the proposed local search mechanism. In Section 5, we provide details of the data generation mechanism for problem instances with known optimal solutions. Moreover, we discuss results of our computational experiments and provide some conclusions and ideas for future research.




\section{Maximal bi-connected partitioning of a graph with a size constraint}
The problem is defined on a graph , where  is the set of nodes and  is the set of edges. We also define a set , whose elements  will be called root nodes. The aim of the problem is to divide the graph  into a set of subgraphs , where  , satisfying the  constraints given in the following text. The notation  will be used for the set of nodes that induces subgraph .  Each of the  must contain only one distinct root node . A node  can be an element of at most one . The number of nodes in each of the subgraphs  is less or equal to some constant . The last constraint is that each of the subgraphs  is bi-connected. The goal of the problem is to find  containing the maximal number of nodes in all the subgraphs.  More formally, we wish to maximize the  sum:
\\
where each of the subgraphs  satisfies 

In the definition we use notation  to indicate the number of nodes in a graph. An illustration of a problem instance and solution for the MBCPG-SC is given in Figure \ref{fig:ProblemColor}. It is important to note that the MBCPG-SC does not produce a partitioning in the strict sense, since some nodes may not be included in any .

\begin{figure}[tcb]
\centering
\includegraphics[width=1\textwidth]{Problem}
\caption{Example of a problem instance (left) and solution (right) for the MBCPG-SC with maximal allowed size . The circle nodes represent root nodes.  Different shades of gray  are used for different subgraphs.}
\label{fig:ProblemColor}
\end{figure} 

The MBCPG-SC is a hard optimization problem in the sense that it is NP hard. We give a proof by reduction to a restriction of the problem of maximal partition of supply/demand graphs (MPGSD) \citep{Ito2008627}.  It has been shown that the MPGSD is NP-hard  in the case of a graph containing  only one supply node and having a star structure \citep{Ito2008627}.
For a more comprehensive presentation  we first give the definition of the MPGSD for star graphs, which is a simplified version of the original problem. It is defined for an undirected  star graph   with a set of nodes  and a set of edges . The center node of the graph  is called a supply node and it has a corresponding supply value . All the other nodes   are  called demand nodes, and they have a corresponding  demand value  which is a positive integer  .   The aim is to find a set of nodes   which satisfies the constraint that  the supply  must be greater or equal  to the total demand of nodes in . The goal is to maximize the fulfillment of demands.



In the following text we prove that MBCPG-SC is NP hard by reducing the MPGSD for star graphs to it. Let MPGSD be defined  for a star graph  having a central supply node  with a supply value  connected to  demand nodes  having demand values . Let us convert this problem to MBCPG-SC in the following way. The parameter   of MBCPG-SC will be set to  and there will be only one root node . Let us convert the star graph  to   used in MBCPG-SC. First, we include the root node  in . The node  is connected to two nodes  (corresponding to the supply node in ) and node  which will be used for some extra edges.  Let us remember that the edge set  of  consists of edges . For each demand node  we will add a path . Next, we add an additional edge   for each demand node . An illustration of this conversion is given in Figure \ref{fig:ConvertNP}.
\begin{figure}[tcb]
\centering
\includegraphics[width=1\textwidth]{ConvertNP}
\caption{Illustration of a conversion of a MPGSD for star graph (left) to MBCPG-SC (right). In the graphic representation for the MPGSD the circle node indicates the supply node and the corresponding supply value. The square nodes indicate the demand nodes and corresponding demand values. Different shades of gray are used to show the changes from nodes (MPGSD) to paths in the MBCPG-SC. In case of the illustration for MBCPG-SC  represents the root node,  the supply node from MPGSD and  the auxiliary node. Dashed lines are used for the auxiliary edges. The size limit MBCPG-SC is .}
\label{fig:ConvertNP}
\end{figure} 

Let us make a few observations on the solution of a MBCPG-SC on the convert graph . First, any solution must contain nodes ,  since there must be at least two disjoint paths from  to any other node. Second if any node  is included in the solution  all the nodes  must be included in it. Let us assume the opposite that node  is not included in the solution and that  the nodes  for  are. In such a case the removal of node  from   results in all the nodes  where   becoming disconnected from  the graph induced by . In the same way, the removal of node  from   results in all the nodes , where , becoming disconnected from the graph induced by .  As a consequence any  is connected to  by two disjoint paths (containing only elements in )  ,  , ,  and by path ,, , . Note that nodes , , ,...,  ,  form a cycle and as a consequence two disjoint paths exist among any 2 of them.


We will prove that MPGSD on  can be reduced to MBCPG-SC on  by showing that any solution  of MPGSD has a corresponding solution  of the MBCPG-SC such that  and and vice versa. Let us first prove  the direction MPGSD to MBCPG-SC, by constructing the solution  from .   will consist of nodes , ,   and all nodes  were  and . First, by construction we have  .  The only additional case that needs to be considered to prove bi-connectivity of   is for two nodes   such that . To be more precise we need to prove that there are two disjoint paths connecting them.   From the previous observation we have that each of these two nodes is connected to nodes ,   by two disjoint paths. So, nodes   are connected with disjoint paths  and . 

The construction of the solution  of MPGSD from a solution of  of the MBCPG-SC is trivial and is based on the construction of graph  and the fact, shown in the previously made observation,  that any solution   consists of , ,   and all nodes   where  for some nodes .





The main motivation for defining the MBCPG-SC is its application to systems of interconnected microgrids  \citep{MicroGrid}. It has been shown that optimization of self-adequacy of individual microgrids in such systems can be well modeled using the  MPGSD. The proposed problem can also be understood as a partitioning of a power supply network in which all supply nodes (elements of ) have a value  and demand nodes (elements of ) have value 1. The problem with using the MPGSD for this type of systems is that it does not address the problem of failure resistance. In MBCPG-SC we exploit the fact that by strengthening the constraint of connectivity to bi-connectivity, compared to MPGSD, we are able to have a model that produces more robust subsystems. 

Another potential application of the proposed problem is on the hierarchical clustering for wireless networks. In the work of   \citep{banerjee2001clustering}, a network is divided into clusters that can be hierarchically controlled. The basic properties of a cluster are that it has a single control node, the  number of nodes it can contain is limited, and the corresponding  subgraph needs to be connected. It is natural to extend this formulation with an additional constraint of bi-connectivity of  subgraphs to enhance reliability.
 


\section{Growing bi-connected subgraphs}
\subsection{Definition of open ear decomposition}
Since the proposed algorithm is based on the property that a bi-connected graph has an open ear decomposition we start with its definition. An open ear decomposition of a graph  is defined as a series of paths  called ears. The term path is used for an ordered sequence (, , \dots , ) such that all edges . In the following text we will use the notation  for the set of nodes in . The notation  is used for a sequence of nodes in ear . All the ears ,  in the decomposition satisfy   if . The exception is the first ear  which is a cycle . For , we have that for each of the two terminating nodes  exists   such that ,  where it is not necessarily . We wish to point out that , so each  is an open ear. Except for such terminating nodes, there is no  if . Finally, for each  there exists  at least one  such that . If such a decomposition exists for graph  then  is bi-connected. An illustration of an open ear decomposition of a graph is given in Figure \ref{fig:OpenEarDecomposition}. 

\begin{figure}[tcb]
\centering
\includegraphics[width=0.55\textwidth]{OpenEarDecomposition}
\caption{Examples of an open ear decomposition for a bi-connected graph. Different shades of gray are used for separate open ears.}
\label{fig:OpenEarDecomposition}
\end{figure} 
\subsection{Algorithm outline}
In the proposed algorithm the idea is to grow a bi-connected subgraph , starting from an initial cycle and extending it with adequate ears.  More formally, we will be iteratively generating a sequence of subgraphs , where  and  is an open ear for .  It is evident that if a subgraph is generated in this way it will always have an open ear decomposition. Although  it  is possible to develop such an algorithm using a depth first search (DFS) the use of BFS is more suitable since it gives us more control of the size  of the ear that will be added.  

In the subsequent text we will be using the following notation. 
\begin{itemize}
\item{ the set  of adjacent/neighboring nodes to node  in graph . }
\item{/ are  the  set of nodes/edges in the BFS tree.  }
\item{ is the set of children of node  in the BFS tree.}
\item{ is the parent node of  in the BFS tree.}
\item{ is the set of all descendants of node  in the BFS tree. }
\item{ is defined for nodes . It represents the path , ,  , , ,  connecting ,   such that  all . Brackets ""/""  are used to indicate if ,  are included/excluded in the path. The notation  is  used for the corresponding set of nodes. }
\item{}, is node  which is the first ancestor of , in the BFS tree, such that . In case  , then . 
\item{}, is node  which is the first ancestor of , in the BFS tree, such that . In case  , then . 
\item{} is the length of the path (number of nodes), . Note, that it does not include node . In case , we have . 
\end{itemize}
It is well known that BFS can be used to find cycles which we exploit in the proposed method. Let us assume that we start the BFS from some initial node .  As we expand the BFS tree, or in other words, new nodes are visited,  the first time we encounter a back-edge  an initial cycle  is found. More precisely,   is acquired by connecting three segments:  path from  to , the back edge  and the path from  to . In the proposed notation  and it has all its nodes in the BFS tree.  

In a similar way we can find new open ears. Let us assume the BFS tree is further expanded and a new back-edge  has been found, and that at least one of the nodes  is not in . It is obvious  that if the following is satisfied, 

then the sequence 

 will produce a new open ear connected to . As a consequence  will also be a bi-connected subgraph. We will use the notation  for the set of nodes corresponding to . The same procedure can be used to further expand  with new open ears.
 
 The second constraint that exists in the MBCPG-SC is that . While growing , it can easily be maintained if we only allow adding  ear  if the following equation is satisfied 

If we adapt the BFS search in a way to always explore node  having the lowest value of  the length  of the newly found open ear will be among the shorter ones (except in rare cases).  This is due to the method of construction in which newly  found ears will always have one terminating node equivalent to the currently visited node in the BFS. If  has the largest value of all nodes in the BFS tree which are not in  then the maximal   difference between  and the shortest ear will be .  In case of adapting the BFS in this way some additional work will be necessary to update the values of  and  as new ears are added to . It is important to note that after such updates it is possible that several back edges  that have been previously tested may now satisfy the constraints given in Eqs. \eqref{ConDifRoot},\eqref{ConLength}.  

\subsection{Algorithm}

The algorithm for growing a bi-connected subgraph  based of the idea presented in the previous section will start the BFS from some root node . As the first ear in the decomposition  differs from the rest as it is a cycle, some special initialization needs to be done for  and its neighbors . For all these nodes  we will initially set . In the adaptation of BFS for growing a bi-connected graph the distance in the BFS tree will have a different meaning. Instead of following the distance of a node  from the root node  we will track the distance from  to the already generated bi-connected subgraph . At the initial step we will consider . Let us assume that we have found two nodes ,  that satisfy the constraints given in Eqs. \eqref{ConDifRoot}, \eqref{ConLength}, then the first ear   can be constructed as 
 

As previously stated in case a new ear  is added to    the values of ,  will need to be updated for some elements of the BFS tree.  It will be necessary to update these values for all  in the following way.





It is important to note that the proposed correction for functions  will produce approximations to the exact 
distance . For the function  we have that   since it is possible to have an alternative path to  using some back edges which is shorter. A consequence of this is that the constraint defined in  Eq.\eqref{ConLength} will never give false positives if function  is used instead of . By using this approximate approach it is possible to have a simpler and less computationally expensive implementation. 

In the standard BFS there is no change in the distance for visited nodes and no node is re-visited. In the proposed adaptation of BFS such changes can occur and some revisits are necessary. It is possible to use a heap or similar structure instead of a queue to always test the node  with the lowest value . In practice this is not necessary especially since we are only using an approximation to . On the other hand the need for retesting some nodes further increases the complexity of implementation. Both of these issues are addressed simultaneously using the following approach. First, nodes will be re-added to the queue as a new ear is added to  and their re-evaluation is needed. Since it is possible for the same node to be added multiple times to the queue due to the addition of multiple ears, an additional value will be used to track if an evaluation is needed. The algorithm for growing a bi-connected subgraph is better understood by observing Algorithm \ref{Alg:Grow}.
\begin{algorithm}
\begin{algorithmic}
\Procedure{BFSGrowBiConnected} {G, r}
\State{For all   initialize  }
\State{Initialize all  }
\State{Add all  to  }
\While{ is not empty}

 \State{} \Comment{Using Queue (FIFO) structure}
 \If{}
 \ForAll{}
 \If{ is BackEdge)}
 	\If { produce an open ear satisfying Eq. \eqref{ConDifRoot}, \eqref{ConLength}}
	 	\State{Set  based on Eq. \eqref{PNormal} or  Eq.\eqref{PRoot}}
 		\State{} 
	 	\State{} 
	 	\State{Exit procedure if }
 	\EndIf
 \Else
 	\State{} 
 	\State{Update parent, child relations for ,  } 
	\State{ } 
 \EndIf
 \EndFor
  \State{}
  \EndIf
\EndWhile
\EndProcedure
\end{algorithmic}
\caption{\label{Alg:Grow} Pseudo code for growing a bi-connected subgraph}
\end{algorithm}


The proposed algorithm starts with a standard BFS initialization of the distance, parents and descendants for all the nodes with the additional property of the need for evaluation. Initially all the values of  will be set to . An auxiliary structure is used to store all the properties of individual nodes, which can be accessed and updated using  the node id. Next, we initialize the root  and all its neighbors  as previously described and all nodes in  are added to the queue . The main loop is executed for each node  in  until .  For each such node we first check if an evaluation is needed and if so all its neighbors  are evaluated. For each  we check if  is a back-edge. In case it is not we add  to the  as in the BFS, and we set . In case  is a back-edge we check if   is an open ear connected to . If this is true the subgraph  is extended with  and necessary updates are performed using procedure  . After all the elements of  are visited the evaluation of node  is complete and we set .  

The update procedure for a newly found open ear, ,  is used to change the state of  and nodes based on the .  The details of the procedure are given in Algorithm \ref{Alg:UpdateAddEar}.
\begin{algorithm}
\begin{algorithmic}
\Procedure {Update }{P,Q} 
\ForAll{()}
			\State{}
 		    \State{}
 		    \State{}
\EndFor
\EndProcedure

\Procedure {UpdateBFSBranch}{ u, root, dist} 
\ForAll{()}
		\If{ } 
			\State{}
 		    \State{}
  		    \State{}
  		 \EndIf   
\EndFor
\EndProcedure
\end{algorithmic}
\caption{\label{Alg:UpdateAddEar} Update procedure for adding an ear to subgraph .}
\end{algorithm}
In it, for all  the distance is set to . Each node  now becomes a root of a new potential ear, so we set . For each node  we wish to update the branch of the BFS tree whose root is . 

 This is done using a recursive procedure .  In it we go through all the BFS descendants  of  that are not already in  and set the  and . By doing so the node properties are set to the values that correspond to the new state of . For each such node re-eavaluation is needed to check if new open ears have been created so we set . The addition  to the queue  is done after the recursive call   for updating the descendants. This order is important since nodes will be added to the queue in reverse order of their distance and as a consequence shorter potential ears are checked first. By doing so  is more gradually grown. 
 

\section{Algorithm for MBCPG-SC}

When solving the MBCPG-SC multiple subgraphs  should be grown together. The idea of the algorithm is to randomize this process. The randomization is done on two levels. First,  the growth of individual subgraphs  should be randomized. This can simply be done by adding an additional parameter   and a corresponding random variable  which will be used to decide if a valid open ear is added to  or not. It is important to note that by not adding an open ear  at iteration   does not necessarily exclude the nodes inside  from the corresponding subgraph . This is due to the fact that they can be a part of some ear  that will be added to  at a later iteration. 

It is evident that the growth of subgraphs  is interdependent since a  node  can only be an element of a unique . On the other hand, the growth of some  will also effect the direction of expansion of the BFS tree of neighboring subgraphs. Because of this the second type of randomization should effect the speed and order in which all the  will be grown. The proposed method can be better understood through the pseudocode given in Algorithm \ref{Alg:GenerateSolution}.
\begin{algorithm}
\begin{algorithmic}
\Procedure {GenerateMBCPG-SC}{roots} 
\State{For all  Set  for all  where }
\State{Initialize all  for }
\While{Can Expend Some }
\State{Select Random Expansion Length }
\State{Select Random  from Expandable}
\State{}
\Repeat
\State{}
\State{Apply  for all  } 
\State{}
\Until{  ) }
\EndWhile
\EndProcedure
\end{algorithmic}
\caption{\label{Alg:GenerateSolution} Randomized method for generating a solution for MBCPG-SC .}
\end{algorithm}


In the proposed algorithm  separate BFS trees and corresponding auxiliary structures exist for each of the . The auxiliary structure for tracking node properties is extended with a property  for nodes, which is used to indicate if a node has been added to some of the other subgraphs. Initially this value is set to  for all nodes in all subgraphs. The first step, is setting  for all the  where . Here we use the notation  for node  in the auxiliary structure of subgraph . Next, the  is initialized for each subgraph  using the corresponding  as described in the previous section. The main loop is repeated until no subgraph can be further expanded. At each iteration a random subgraph  is selected for expansion of a maximal allowed size .  is a random variable from some range . The goal of the inner loop is to extend  with at least  nodes, or until it is not possible to extend it. In this loop an adaptation of the procedure presented in the previous section  is used in the form of function  which only adds a single ear  to . This function does not consider nodes having . After an ear  is added to , the  BFS tree and corresponding structures need to be updated for all  where  using procedure . 

The update procedure needs to perform several tasks. First, all the nodes  need to be made unavailable for the growth of , where , which can be done by setting  in the corresponding auxiliary structures. Secondly, all the nodes in  which have been cutoff from the BFS tree (for some , ), by the removal of , need to be re-initialized so they can potentially be re-added to the BFS tree. This is done by setting  and . Although there is a potential that a node   may be reached by continuing the growth of the BFS tree, there is no guarantee for this.  The question is which nodes need to be re-evaluated to make this possible. It is obvious that if a back-edge   existed for the BFS tree that node  can be reconnected to . On the other hand if such a back edge existed and  then the corresponding open ear would have been already added to . The only potentially disregarded back edges  are of the type .  Because of this  the nodes in   should be re-evaluated if  , since they can  establish a connection with . The details of the update procedure for deleting a node are given in Algorithm \ref{Alg:DeleteNode}.

\begin{algorithm}
\begin{algorithmic}
\Procedure {UpdateBFSTree}{, } 
\ForAll{  }
\State{ }
\State{Update ,  relation for }
\ForAll{}
   \If{}
	\State{}	
	\State{}
\EndIf
\EndFor

\ForAll{}

\State{ }
\State{Clear parent, child relations}
\EndFor
\EndFor
\EndProcedure


\end{algorithmic}

\caption{\label{Alg:DeleteNode} Randomized method for generating a solution for MBCPG-SC.}
\end{algorithm}


\section{Local Search for MBCPG-SC}

The algorithm in the previous section gives us a method for generating a single solution for MBCPG-SC.  A simple way of finding higher quality solutions is to perform multiple runs with different random seeds and selecting the best one. The problem with this approach is that no experience is gained from previously generated solutions and as a consequence a very high number of them needs to be generated to get good quality ones. An alternative approach is to develop a local search procedure which improves sections of already generated solutions. The basic idea of the proposed local search is to regrow only a subsection  of the previously best found solution. Ideally, we wish to do this only  for  subsections for which an improvement is possible. The growth procedure presented in the previous section can easily be adapted to such a setting. 

Let us define the set on non-located nodes as
 
It is obvious that  should contain at least one  such that . The other requirement is that  has a potential to expand to some . For simplicity let us assume that there is only one non-located node , and there is only one  such that . Since  must be bi-connected there must be a  having only nodes in . We can define the set of neighboring nodes of a subgraph in the following way
 
It is evident that for an appropriate  to exist,  must satisfy  for some . Using this logic, we can specify  containing  subgraphs based on this necessary condition. Select one  having  and  such that it  . Select  random subgraphs from . We will call this method for selecting the elements of  growth random ().

This method for specifying  satisfies the necessary condition but further constraints can be added to make the local search more efficient. Let us observe a graph  induced by  in the following way.  Each node in   corresponds to a subgraph . An edge  is in   if there exist nodes ,  such that . If we are re-growing only two subgraphs  there is a potential that nodes may be exchanged between  them  if , and more generally  will influence each other's growth. Transitively, the influence will extend to all subgraphs in a connected subgraph .

\begin{figure}[tcb]
\centering
\includegraphics[width=0.85\textwidth]{NonLocPath}
\caption{An illustration of an exchange between subgraphs through non-located nodes. Different shades of gray are used to indicate different subgraphs. Dashed lines represent non-located paths (left side). The edge sets used for defining   and   are  and , respectively. }
\label{fig:NonLocPath}
\end{figure} 

An exchange can occur between subgraphs  in the same setting even if   through nodes in .     Let us assume that for some ,  there is a connecting  which only contains nodes in . In such a case there is a chance that node  can be added to  using this path. We give an illustration   in Figure \ref{fig:NonLocPath}. Let us define  as a set of edges, where   only if a connecting path exists containing only  non-located nodes.  Let us now define a new graph  using the following edge set 
 
Now, we can say that for the same  an exchange between subgraphs ,   can only occur if and only if  and more generally  will influence each other's growth. Transitively the same applies to any connected subgraph . A consequence of this is that  regrowing should only be considered for a connected (in ) subsections  , since each isolated section can be treated separately. 

Using graph  we can define a method for generating a set  suitable for regrowth in the following way. First select an initial  random node  such that . Note as a reminder that  represents a subgraph in . Iteratively, we add a random node  such that it is connected (in ) to at least one node  . When , we check if at least one node   satisfies  . If this is true   is accepted as the set that will be regrown. In case this is not true a new set  is generated in the same way. If after  attempts no such  is generated  is increased by one. This process is repeated until  satisfying the necessary constraints is generated.  We will call this method for selecting the elements of  growth neighbor ().

The method based on the local search  for the MBCPG-LS is given in Algorithm \ref{Alg:LocalSearch}.
\begin{algorithm}
\begin{algorithmic}
\State{ Generate solution  using }
\State{ }
\State{Calculate  for }
\While{Not Termination Condition}
	\State{Randomly select  from  }	
	\State{Randomly select  such that }
	\State{Generate  based on ,  and }
	\State{}
	\If{ }
	\State{ }
	\State{Calculate  for }
	\EndIf
\EndWhile
\end{algorithmic}
\caption{\label{Alg:LocalSearch} Local search based algorithm for finding a high quality solutions for MBCPG-SC.}
\end{algorithm}
The methods starts with generating an initial solution using procedure  which is set as the . For this solution we generate the graph  as described in the previous text. In the main loop we first select a random subgraph  such that  and a random number  which indicates how many subgraphs  will be regrown. Next, we generate a random  subgraph   based on the node  containing  nodes  using one of the two methods  or . A new solution  is acquired by regrowing  using procedure . This procedure is the same as  with the following changes. First, for all nodes   we set . Next, only subgraphs in  are grown and considered in the update procedure. The rest of the subgraphs are left unchanged. 
The next step in the main loop consists in  testing if . In case this is true the best found solution is updated and the graph  is recalculated. Note that we have allowed the update of the best solution even if it has the same quality as  to diversify the search. The main loop is repeated until a maximal number of iterations or no further improvement can be achieved. 


\section{Computational Experiments}

In this section we present the results of the computational experiments used to evaluate the  performance of the proposed  method. We have compared the basic randomized growth algorithm with its extension using the local search procedure with and without exploiting the subgraph neighborhoods. All the algorithms  have been implemented in C\# using Microsoft Visual Studio 2015. The source code and the execution files have been made available at \citep{Data}. The calculations have been done on a machine with Intel(R) Core(TM) i7-2630 QM CPU \@ 2.00 Ghz, 4GB of DDR3-1333 RAM, running on Microsoft Windows 7 Home Premium 64-bit. 

\subsection{Test instance generation}
In the evaluation of the proposed algorithm our focus is on unit disc graphs due to there close relation with wireless networks. As  stated above the proposed problem can be used to find   clustering schemes for hierarchical control of such systems with enhanced fault tolerance.  
Due to the fact that this is a newly defined problem there are no standard benchmark instances available for comparison it was necessary to also generate  problem instances with known optimal solutions. In the generation procedure our goal is to generate graphs that are "as random as possible". To be more precise we attempt to have the node positions close to the uniform probability distribution and to have the number of edges that are adjacent to each node relatively balanced. To achieve this we use the following procedure. 

Let us say that we are generating a problem instance having  root nodes and  is the maximal allowed number of nodes in a subgraph, having a solution in which  contains all the nodes. 
For problem instances of this form  we generate unit disc graphs inside of a box   with dimensions , . 
The value for the length for establishing edges is .  is an additional parameter used to vary the density of the graph used in specifying different data sets. The first step is generating   random bi-connected unit disc graphs having  nodes.  As our aim is to have the nodes of graph  spread over the entire area of the box  having an area equal to . We want to have each of the subgraphs  covering an area of close to . To achieve this  for each such graph we first define a box with dimensions ,   where  is randomly selected  from the interval  used to vary the shape of .  For this box a random bi-connected graph  is generated. This is done by repeatedly generating  random points and checking if the resulting unit dist graph contains a bi-connected subgraph  containing  nodes. To increase the probability of having nodes of the graph covering an area close to , four nodes have been forced to random positions at each edge of the  box.  To achieve this a high number of graphs needs to be generated, especially in the case of a high value of . This is the reason for the additional points, specified using parameter , in the box, since it greatly reduces the number of graphs that are generated.  Out of all the nodes in  one would be randomly selected as the .

The next step in generating a problem instance with a known solution is combining graphs . Let us remember that by the method of construction for each subgraph  contains  nodes having some values of coordinates , as a consequence we can easily translate  by a vector  by changing all node positions to . The basic idea of combining the graphs  is to randomly position (translate) them in a way that all the nodes fit in a box having dimensions , . As previously stated our goal is to have a relatively balanced number of edges for all the nodes. Secondly, we want to distribute the nodes over the entire box .  This is achieved through the following iterative procedure. Initially, the graph  is set to  . At each iteration a new graph  is set at a random position and added to , but some constraints must be satisfied. First, all the points in  must fit into a box having dimensions ,. The number of new edges  connecting  and , has to satisfy .  To achieve this multiple random positions  have to be tested for each subgraph . The parameter   is used to bound the allowed number of new edges which is related to the number of edges  in the graph as . Empirical tests have shown that values  produce satisfactory results. For each  graph  a  positions are tested and the one satisfying the constraints and having the lowest number of  would be chosen for adding to . The last step is randomly enumerating all the nodes in . 

\subsection{Experiments}




To have an extensive evaluation of the proposed algorithm, we have generated a wide range of problem instances for different numbers of root nodes  (5-100) and maximal allowed number of nodes in a subgraph  (5-100). For each pair ,  40 problem instances have been generated using the algorithm presented in the previous subsection with different values for the seed of the random number generator. We have generated two problem sets varying in the level of connectivity by setting .  For each of the problem instances a single run of the growth based algorithms is performed. This is done for the two local search methods based on  and  for generating the set of subgraphs  which will be regrown. 

The same set of parameters for specifying the algorithm is used for all the problem sizes. The value of the parameter for accepting an ear is  in the growth algorithm.  The parameter specifying the maximal expansion of a subgraph  at one step is .  The value  was used for the the upper bound on the value  which is used for generating the size  of the set of subgraphs that will be regrown. These values have been chosen empirically after a wide range of values have been tested in computational experiments. In all of the computational experiments the algorithm would execute until  10.000 iterations (generated solutions) have been reached  or  more than 2000 iterations have been completed without an improvement to the best found solution. 

The results of the computational experiments focus on the quality of found solutions and the computational cost which can be seen in Tables \ref{table:Alpha2}, \ref{table:Alpha15}. The evaluation of solution quality is done using the  average normalized error of the found solutions compared to the known optimal ones, for each of the used methods. More precisely, for each of the 40 test instances, for each pair ,  the normalized error is calculated by , and we show the average values.  To have a better comprehension of the performance we have also included the standard deviation, maximal errors and the number of found optimal solutions (hits).  The computational cost is analyzed through  the average execution time  needed to find the best solution. To have a better understanding of these execution times,  we have also included the average number of iterations (number of generated solutions) to find the best solution and the corresponding standard deviation in Tables \ref{table:Alpha2}, \ref{table:Alpha15}.


\begin{table*}[htb]
\footnotesize
\center
\caption{\label{table:Alpha2}
Comparison of the performance of the  and  methods for  unit disc graphs with .}
\begin{tabularx}{430pt}{X*{10}{c}}

\toprule
Roots X M&  \multicolumn{2}{c}{}  & \multicolumn{2}{c}{} & \multicolumn{2}{c}{}& \multicolumn{2}{c}{}& \multicolumn{2}{c}{}\\

&  &   &   &  &   & &  & &   & \\

\midrule
5 X 5 & 0.30(1.38) & 0.30(1.38) & 8.00 & 8.00 & 38 & 38 & 122(47) & 63(41) & 12 & 8 \\
5 X 10 & 0.15(0.69) & 0.00(0.00) & 4.00 & 0.00 & 38 & 40 & 357(224) & 269(228) & 40 & 31 \\
5 X 25 & 0.78(1.32) & 0.96(1.61) & 5.60 & 7.20 & 24 & 23 & 884(435) & 644(170) & 236 & 185 \\
5 X 50 & 1.12(1.46) & 0.90(1.41) & 8.00 & 8.00 & 11 & 14 & 1428(1160) & 1455(364) & 851 & 940 \\
5 X 100 & 1.40(1.39) & 1.38(1.64) & 5.00 & 6.00 & 5 & 7 & 1707(851) & 1738(215) & 2472 & 2547 \\
\midrule
10 X 5 & 0.50(1.40) & 0.25(0.80) & 6.00 & 4.00 & 35 & 36 & 393(903) & 359(507) & 34 & 33 \\
10 X 10 & 0.43(0.80) & 0.28(0.63) & 4.00 & 3.00 & 28 & 32 & 1034(928) & 848(775) & 162 & 162 \\
10 X 25 & 2.78(2.03) & 2.30(2.26) & 9.60 & 9.60 & 1 & 5 & 1810(1031) & 1569(594) & 748 & 680 \\
10 X 50 & 2.04(1.34) & 1.51(1.19) & 6.80 & 5.00 & 0 & 1 & 2775(441) & 2946(1389) & 2497 & 2730 \\
10 X 100 & 1.92(1.30) & 1.70(1.35) & 6.30 & 6.30 & 0 & 0 & 3470(555) & 3479(1997) & 7883 & 7870 \\
\midrule
25 X 5 & 3.36(3.13) & 1.98(2.71) & 9.60 & 8.80 & 12 & 21 & 2113(3057) & 1635(686) & 246 & 207 \\
25 X 10 & 2.19(1.42) & 1.41(1.18) & 5.20 & 4.00 & 2 & 7 & 2268(2228) & 1731(890) & 431 & 399 \\
25 X 25 & 3.35(1.31) & 2.04(0.87) & 6.88 & 4.16 & 0 & 0 & 4475(3739) & 4494(1885) & 2221 & 2248 \\
25 X 50 & 2.91(0.98) & 2.41(0.95) & 4.88 & 4.56 & 0 & 0 & 6225(2062) & 4480(1170) & 6842 & 4985 \\
25 X 100 & 2.59(0.93) & 2.32(1.04) & 6.00 & 5.16 & 0 & 0 & 7220(2221) & 6105(1092) & 22812 & 18533 \\
\midrule
50 X 5 & 6.47(2.08) & 3.08(1.97) & 10.40 & 8.00 & 0 & 2 & 3669(3037) & 4020(1764) & 746 & 728 \\
50 X 10 & 2.93(1.16) & 1.37(0.82) & 6.00 & 3.20 & 0 & 1 & 5385(2962) & 3548(248) & 1681 & 1118 \\
50 X 25 & 3.88(0.86) & 2.50(0.74) & 5.68 & 4.16 & 0 & 0 & 7779(1800) & 7322(1683) & 5911 & 4801 \\
50 X 50 & 3.91(0.76) & 2.79(0.70) & 5.68 & 4.40 & 0 & 0 & 8822(813) & 7966(1921) & 15347 & 12788 \\
50 X 100 & 3.51(0.79) & 2.47(0.59) & 5.26 & 4.40 & 0 & 0 & 9295(228) & 8995(916) & 42597 & 38596 \\
\midrule
100 X 5 & 8.87(1.53) & 4.87(1.19) & 13.00 & 7.40 & 0 & 0 & 5333(2432) & 5829(832) & 2681 & 2256 \\
100 X 10 & 4.16(0.75) & 1.92(0.74) & 6.00 & 3.40 & 0 & 0 & 8100(1171) & 6944(2128) & 6452 & 3875 \\
100 X 25 & 5.51(0.88) & 2.99(0.47) & 8.00 & 4.04 & 0 & 0 & 9449(306) & 9127(475) & 17044 & 11720 \\
100 X 50 & 5.44(0.70) & 3.26(0.44) & 6.94 & 4.82 & 0 & 0 & 9710(240) & 9640(212) & 39697 & 29134 \\
100 X 100 & 5.00(0.82) & 3.15(0.49) & 6.84 & 4.31 & 0 & 0 & 9844(168) & 9731(255) & 100213 & 78981 \\
\bottomrule
\end{tabularx}
\end{table*}



\begin{table*}[htb]
\footnotesize
\center
\caption{\label{table:Alpha15}
Comparison of the performance of the  and  methods for  unit disc graphs with .}
\begin{tabularx}{430pt}{X*{10}{c}}

\toprule
Roots X M&  \multicolumn{2}{c}{}  & \multicolumn{2}{c}{} & \multicolumn{2}{c}{}& \multicolumn{2}{c}{}& \multicolumn{2}{c}{}\\
&  &   &   &  &   & &  & &   & \\

\midrule
5 X 5 & 0.10(0.62) & 0.10(0.62) & 4.00 & 4.00 & 39 & 39 & 158(150) & 153(124) & 10 & 10 \\
5 X 10 & 0.00(0.00) & 0.10(0.44) & 0.00 & 2.00 & 40 & 38 & 254(147) & 211(180) & 27 & 28 \\
5 X 25 & 0.38(0.69) & 0.18(0.42) & 2.40 & 1.60 & 29 & 33 & 511(273) & 526(480) & 137 & 153 \\
5 X 50 & 0.05(0.13) & 0.06(0.17) & 0.40 & 0.80 & 35 & 35 & 911(252) & 542(456) & 536 & 341 \\
5 X 100 & 0.17(0.31) & 0.16(0.43) & 1.60 & 2.60 & 23 & 26 & 1305(1029) & 875(502) & 1772 & 1243 \\
\midrule
10 X 5 & 0.75(1.53) & 1.00(2.10) & 6.00 & 8.00 & 31 & 31 & 624(434) & 349(185) & 49 & 35 \\
10 X 10 & 0.65(1.15) & 0.33(0.75) & 5.00 & 4.00 & 26 & 31 & 807(457) & 578(464) & 126 & 121 \\
10 X 25 & 0.70(1.01) & 0.49(0.82) & 4.40 & 3.60 & 18 & 24 & 1548(820) & 1269(324) & 659 & 595 \\
10 X 50 & 0.39(0.55) & 0.38(0.40) & 2.80 & 1.60 & 15 & 13 & 2429(1540) & 1914(1255) & 2421 & 2043 \\
10 X 100 & 0.50(0.75) & 0.38(0.60) & 3.00 & 2.80 & 6 & 13 & 2859(1494) & 2431(1869) & 7150 & 6134 \\
\midrule
25 X 5 & 3.48(1.47) & 2.18(1.51) & 6.40 & 6.40 & 0 & 6 & 1581(450) & 1336(838) & 208 & 182 \\
25 X 10 & 1.17(1.01) & 0.76(0.79) & 4.40 & 2.80 & 3 & 13 & 2256(1616) & 1664(714) & 516 & 496 \\
25 X 25 & 1.18(0.74) & 0.80(0.69) & 3.52 & 2.88 & 0 & 4 & 4392(2236) & 3231(730) & 2556 & 1970 \\
25 X 50 & 0.98(0.64) & 0.76(0.79) & 3.12 & 4.00 & 0 & 1 & 5522(1851) & 4478(1968) & 7367 & 5983 \\
25 X 100 & 1.22(0.76) & 1.02(0.80) & 3.52 & 3.44 & 0 & 0 & 6704(2977) & 4824(3691) & 22793 & 15582 \\
\midrule
50 X 5 & 4.54(1.21) & 2.74(0.82) & 8.40 & 4.80 & 0 & 0 & 2805(825) & 3111(2346) & 652 & 644 \\
50 X 10 & 1.63(0.78) & 0.85(0.49) & 3.80 & 2.00 & 0 & 1 & 4818(1732) & 3410(1566) & 1746 & 1518 \\
50 X 25 & 1.72(0.66) & 0.90(0.37) & 3.36 & 1.60 & 0 & 0 & 7604(1662) & 5735(1714) & 7030 & 4764 \\
50 X 50 & 1.61(0.45) & 0.97(0.36) & 2.76 & 1.92 & 0 & 0 & 8573(1729) & 7110(2077) & 18569 & 13504 \\
50 X 100 & 1.50(0.60) & 1.01(0.44) & 2.96 & 2.72 & 0 & 0 & 9178(705) & 8132(1189) & 52250 & 39889 \\
\midrule
100 X 5 & 5.14(1.03) & 3.32(0.74) & 7.60 & 5.60 & 0 & 0 & 5442(1610) & 4417(976) & 2876 & 1843 \\
100 X 10 & 2.36(0.57) & 1.03(0.45) & 3.50 & 1.80 & 0 & 0 & 8590(1161) & 6651(1594) & 6909 & 4301 \\
100 X 25 & 2.52(0.58) & 1.19(0.42) & 4.24 & 2.16 & 0 & 0 & 9675(146) & 8769(3070) & 20390 & 12047 \\
100 X 50 & 2.51(0.59) & 1.23(0.34) & 4.18 & 2.28 & 0 & 0 & 9641(78) & 9319(387) & 46193 & 30645 \\
100 X 100 & 2.36(0.47) & 1.26(0.33) & 3.61 & 1.95 & 0 & 0 & 9708(245) & 9702(808) & 129312 & 87792 \\
\bottomrule
\end{tabularx}
\end{table*}

As it can be seen in Tables \ref{table:Alpha2}, \ref{table:Alpha15} the local search based on the use of subgraphs  manages to significantly outperform . As expected,  produces a higher level of improvement for problem instances having a higher number of roots, or in other words when the  graph is divided into a greater number of subgraphs. In case of problems having 100 subgraphs the  average error is nearly halved. For problem instances with lower values of  this improvement is smaller but consistent. In the 50 problem sets, in only 5  produces slightly better results. This only occurred for problems having five subgraphs, in which the use of neighborhoods is not essential. Overall both methods had a good performance, with an average error going up to / and / for problem instance generated using  for  and , respectively. In practice the problem instances having the maximal number of allowed nodes  proved to be the hardest. The methods managed to find better solutions for  graphs with higher edge densities (). We believe that the main reason for this is that such problem instances are in practice easier to solve since there is a greater number of potential bi-connected subgraphs.  The hardest instances to solve are the ones in which the maximal allowed size of a graph is the smallest and the number of subgraphs is the highest. For a notable number of test instances  manages to find optimal solutions, in case of  it is close to . It is important to note that optimal solutions are only found for graphs having up to 500 nodes.  has a robust behavior in the sense that the maximal error for a problem set  is  but in the majority of the cases it is less than  for .

When we observe the computational speed of the proposed methods the additional cost for calculating the neighborhoods in  is overall neglectable  when compared to . In case of large problem instances the use of neighborhoods even decreases the calculation time. Overall both methods prove to be computationally  very efficient having taken  100/120 and 80/87 seconds to generate close to 10 000 solutions in case of graphs having 10 000 nodes and  for  and , respectively. It is important to note that for the largest instances in case of both methods the execution of the algorithm was terminated before the stagnation occurred (no improvements of the best found solution). The scaling of the methods is good in the sense that the increase of average execution time from instances having 100 nodes to 10000 was around 10 000 times. The number of iterations performed for different problem instances for the same pair  would highly vary which can be seen from the standard variation. We wish to point out that   manages to find high quality solutions with a  low number of generated solutions when compared to the solution space. 

\section{Conclusion}

In this paper we have introduced a new problem of finding the maximal number of nodes contained in a set of disjoint bi-connected subgraphs of a graph with the additional constraint on the maximal  size of a subgraph. This type of problem can be potentially applied for many practical problems. One example is the partitioning of electrical grids into a system of interconnected microgrids with a high level of resistance to failure. For solving the MBCPG-SC, a novel computationally efficient method for growing bi-connected subgraphs has been introduced. This method has been adapted to the setting of growing multiple graphs in parallel to generate solutions for MBCPG-SC. The quality of solutions generated in this way  was further improved using a local search method exploiting neighboring relations between subgraphs. The proposed method managed to  acquire  approximate solutions having an average error of up to  when compared to known optimal solutions.  Further, the method is highly computationally efficient in the sense that it manages to find such solutions within two minutes for graphs having 10.000 nodes.

In the future we plan to extend the current research in several directions. First, we aim to  explore the weighted version of the problem which would be more suitable for problems occurring in electrical distribution systems. Once the weighted version is solved we may also relate the problem towards  multi-depot vehicle rooting problems and the assignment of costumers to routes of different depots. Secondly, we shall extend the method to metaheuristic approaches like ant colony optimization, GRASP or variable neighborhood search which appear  as good options. Finally, we shall explore the potential of applying the proposed growth procedure for problems like the  bi-connected dominating set and bi-connected  vertex cover problem. 




\bibliographystyle{spbasic}      

\begin{thebibliography}{38}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{{#1}}
\providecommand{\urlprefix}{URL }
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{DOI~\discretionary{}{}{}#1}\else
  \providecommand{\doi}{DOI~\discretionary{}{}{}\begingroup
  \urlstyle{rm}\Url}\fi
\providecommand{\eprint}[2][]{\url{#2}}

\bibitem[{Arefifar et~al(2012)Arefifar, Mohamed, and EL-Fouly}]{SelAdeq}
Arefifar SA, Mohamed YARI, EL-Fouly TH (2012) Supply-adequacy-based optimal
  construction of microgrids in smart distribution systems. IEEE Trans Smart
  Grid 3(3):1491--1502

\bibitem[{Arefifar et~al(2013)Arefifar, Mohamed, and EL-Fouly}]{SelHea}
Arefifar SA, Mohamed Y, EL-Fouly TH (2013) Comprehensive operational planning
  framework for self-healing control actions in smart distribution grids. IEEE
  Trans Power Syst 28(4):4192--4200

\bibitem[{Banerjee and Khuller(2001)}]{banerjee2001clustering}
Banerjee S, Khuller S (2001) A clustering scheme for hierarchical control in
  multi-hop wireless networks. In: INFOCOM 2001. Twentieth Annual Joint
  Conference of the IEEE Computer and Communications Societies. Proceedings.
  IEEE, IEEE, vol~2, pp 1028--1037

\bibitem[{Bazgan et~al(2010)Bazgan, Tuza, and Vanderpooten}]{Bazgan2010271}
Bazgan C, Tuza Z, Vanderpooten D (2010) Satisfactory graph partition, variants,
  and generalizations. Eur J Oper Res 206(2):271 -- 280

\bibitem[{Borra et~al(2015)Borra, Pasqualetti, and Bullo}]{Borra2015227}
Borra D, Pasqualetti F, Bullo F (2015) Continuous graph partitioning for camera
  network surveillance. Automatica 52:227 -- 231

\bibitem[{Buchanan et~al(2015)Buchanan, Sung, Butenko, and
  Pasiliao}]{buchanan2015integer}
Buchanan A, Sung JS, Butenko S, Pasiliao EL (2015) An integer programming
  approach for fault-tolerant connected dominating sets. INFORMS J Comput
  27(1):178--188

\bibitem[{Chang et~al(2006)Chang, Lin, and Chen}]{chang2006cluster}
Chang YC, Lin ZS, Chen JL (2006) Cluster based self-organization management
  protocols for wireless sensor networks. IEEE Trans Consum Electron
  52(1):75--80

\bibitem[{Dorigo and Blum(2005)}]{dorigo2005ant}
Dorigo M, Blum C (2005) Ant colony optimization theory: A survey. Theor Comput
  Sci 344(2):243--278

\bibitem[{Feo and Resende(1995)}]{GRASP}
Feo T, Resende M (1995) Greedy randomized adaptive search procedures. J Global
  Optim 6(2):109--133

\bibitem[{do~Forte et~al(2013)do~Forte, Lucena, and Maculan}]{doForte2013415}
do~Forte VL, Lucena A, Maculan N (2013) Formulations for the minimum
  2-connected dominating set problem. Electronic Notes in Discrete Mathematics
  41:415 -- 422

\bibitem[{Goldschmidt et~al(1996)Goldschmidt, Takvorian, and
  Yu}]{Goldschmidt199697}
Goldschmidt O, Takvorian A, Yu G (1996) On finding a biconnected spanning
  planar subgraph with applications to the facilities layout problem. Eur J
  Oper Res 94(1):97 -- 105

\bibitem[{Hansen et~al(2010)Hansen, Mladenovi{\'c}, and
  P{\'e}rez}]{hansen2010variable}
Hansen P, Mladenovi{\'c} N, P{\'e}rez JAM (2010) Variable neighbourhood search:
  methods and applications. Ann Oper Res 175(1):367--407

\bibitem[{Hatziargyriou et~al(2007)Hatziargyriou, Asano, Iravani, and
  Marnay}]{MicroGrid}
Hatziargyriou N, Asano H, Iravani R, Marnay C (2007) Microgrids. IEEE Power
  Energy Mag 5(4):78--94

\bibitem[{Hochbaum(1993)}]{HOCHBAUM1993203}
Hochbaum DS (1993) Why should biconnected components be identified first.
  Discrete Appl Math 42(2):203 -- 210

\bibitem[{Hopcroft and Tarjan(1973{\natexlab{a}})}]{hopcroft1973algorithm}
Hopcroft J, Tarjan R (1973{\natexlab{a}}) Algorithm 447: efficient algorithms
  for graph manipulation. Commun ACM 16(6):372--378

\bibitem[{Hopcroft and Tarjan(1973{\natexlab{b}})}]{TriConnected}
Hopcroft JE, Tarjan RE (1973{\natexlab{b}}) Dividing a graph into triconnected
  components. SIAM J Compu 2(3):135--158

\bibitem[{Hu et~al(2010)Hu, Leitner, and Raidl}]{hu2010generalized}
Hu B, Leitner M, Raidl GR (2010) The generalized minimum edge-biconnected
  network problem: Efficient neighborhood structures for variable neighborhood
  search. Networks 55(3):256--275

\bibitem[{Ito et~al(2008)Ito, Demaine, Zhou, and Nishizeki}]{Ito2008627}
Ito T, Demaine ED, Zhou X, Nishizeki T (2008) Approximability of partitioning
  graphs with supply and demand. J Discrete Algorithms 6(4):627 -- 650

\bibitem[{Ito et~al(2012)Ito, Hara, Zhou, and Nishizeki}]{Tree4}
Ito T, Hara T, Zhou X, Nishizeki T (2012) Minimum cost partitions of trees with
  supply and demand. Algorithmica 64(3):400--415

\bibitem[{Jovanovic(2013)}]{Data}
Jovanovic R (2013) Benchmark data sets for the problem of the maximal
  bi-connected partitioning of a graph with a size constraint.
  \urlprefix\url{http://mail.ipb.ac.rs/\~{}rakaj/home/mbcgpsc.htm}

\bibitem[{Jovanovic and Tuba(2013)}]{Raka2}
Jovanovic R, Tuba M (2013) Ant colony optimization algorithm with pheromone
  correction strategy for the minimum connected dominating set problem. Comp
  Sci Inform Syst pp 133--149

\bibitem[{Jovanovic and Voss(2015)}]{MIPGSD}
Jovanovic R, Voss S (2015) A mixed integer program for partitioning graphs with
  supply and demand emphasizing sparse graphs. Optim Lett ,
  doi:10.1007/s11590-015-0972-6

\bibitem[{Jovanovic et~al(2015{\natexlab{a}})Jovanovic, Bousselham, and
  Voss}]{MultiHeuristicGSD}
Jovanovic R, Bousselham A, Voss S (2015{\natexlab{a}}) A heuristic method for
  solving the problem of partitioning graphs with supply and demand. Ann Oper
  Res 235(1):371--393

\bibitem[{Jovanovic et~al(2015{\natexlab{b}})Jovanovic, Bousselham, and
  Voss}]{BalancedGSD}
Jovanovic R, Bousselham A, Voss S (2015{\natexlab{b}}) Partitioning of
  supply/demand graphs with capacity limitations: an ant colony approach. J
  Comb Optim , doi:10.1007/s10878-015-9945-z

\bibitem[{Jovanovic et~al(2016)Jovanovic, Tuba, and Voss}]{Jovanovic2016317}
Jovanovic R, Tuba M, Voss S (2016) An ant colony optimization algorithm for
  partitioning graphs with supply and demand. Appl Soft Comput 41:317 -- 330

\bibitem[{Li and Zhang(2010)}]{li2010two}
Li X, Zhang Z (2010) Two algorithms for minimum 2-connected r-hop dominating
  set. Inform Process Lett 110(22):986--991

\bibitem[{Matic and Bozic(2012)}]{matic2012maximally}
Matic D, Bozic M (2012) Maximally balanced connected partition problem in
  graphs: Application in education. Teach Math 15(2):121--132

\bibitem[{Moraes and Ribeiro(2013)}]{Moraes20133188}
Moraes RE, Ribeiro CC (2013) Power optimization in ad hoc wireless network
  topology control with biconnectivity requirements. Comput Oper Res
  40(12):3188 -- 3196

\bibitem[{Morgan and Grout(2008)}]{MorganG08}
Morgan M, Grout V (2008) Finding optimal solutions to backbone minimisation
  problems using mixed integer programming. In: Seventh International Network
  Conference {(INC} 2008), Plymouth, UK, July 8-10, 2008. Proceedings, pp
  53--63

\bibitem[{Morishita and Nishizeki(2013)}]{Parametric}
Morishita S, Nishizeki T (2013) Parametric power supply networks. In: Du DZ,
  Zhang G (eds) Computing and Combinatorics, Lecture Notes in Computer Science,
  vol 7936, Springer, Berlin, pp 245--256

\bibitem[{Pearce(2016)}]{Pearce201647}
Pearce DJ (2016) A space-efficient algorithm for finding strongly connected
  components. Inform Process Lett 116(1):47 -- 52

\bibitem[{Popa(2013)}]{SupDem}
Popa A (2013) Modelling the power supply network - hardness and approximation.
  In: Chan TH, Lau L, Trevisan L (eds) Theory and Applications of Models of
  Computation, Lecture Notes in Computer Science, vol 7876, Springer, Berlin,
  pp 62--71

\bibitem[{Robbins(1939)}]{EarDecomposition}
Robbins HE (1939) A theorem on graphs, with an application to a problem of
  traffic control. Am Math Mon 46(5):281--283

\bibitem[{Schmidt(2013)}]{schmidt2013simple}
Schmidt JM (2013) A simple test on 2-vertex-and 2-edge-connectivity. Inform
  Process Lett 113(7):241--244

\bibitem[{Shafique(2004)}]{shafique2004partitioning}
Shafique KH (2004) Partitioning a graph in alliances and its application to
  data clustering. PhD thesis, University of Central Florida Orlando, Florida

\bibitem[{Tarjan(1972)}]{tarjan1972depth}
Tarjan R (1972) Depth-first search and linear graph algorithms. SIAM J Compu
  1(2):146--160

\bibitem[{Wang et~al(2009)Wang, Thai, and Du}]{BackBone}
Wang F, Thai MT, Du DZ (2009) On the construction of 2-connected virtual
  backbone in wireless networks. IEEE Trans Wireless Commun 8(3):1230--1237

\bibitem[{Zhang et~al(2009)Zhang, Gao, and Wu}]{Zhang2009812}
Zhang Z, Gao X, Wu W (2009) Algorithms for connected set cover problem and
  fault-tolerant connected set cover problem. Theor Comput Sci 410(8–10):812
  -- 817

\end{thebibliography}




\end{document}
