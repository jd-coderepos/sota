\documentclass{acmtrans2m}
\usepackage{latexsym}
\usepackage{proof}




\newenvironment{definition}{\begin{define} \rm}{\end{define}}
\newenvironment{example}{\begin{exa} \rm}{\end{exa}}
\newtheorem{theorem}{Theorem}
\newtheorem{corollary}[theorem]{Corollary}
\newtheorem{define}[theorem]{Definition}
\newtheorem{exa}[theorem]{Example}
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{proposition}[theorem]{Proposition}

\newcommand{\ie}{{\em i.e.}}
\newcommand{\eg}{{\em e.g.}}

\def \mTrue {\hbox{true}}
\def \mFalse {\hbox{false}}
\def \mAnd {\&}
\def \mOr {\hat \lor}
\def \mEq {\dot =}
\newcommand \mBox[1] {[#1]}
\newcommand \mDia[1] {\langle #1 \rangle}
\newcommand \stf[2] {#1 \models #2}
\newcommand \matchBox[3] {[#1 \dot = #2] #3}
\newcommand \matchDia[3] {\langle #1 \dot = #2\rangle #3}
\newcommand \actBox[2] {[#1] #2}
\newcommand \actDia[2] {\langle #1 \rangle #2}
\newcommand \outBox[2] {[\outact\! #1] #2}
\newcommand \outDia[2] {\langle \outact\! #1 \rangle #2}
\newcommand \inBox[2] {[\inact\! #1] #2}
\newcommand \inDia[2] {\langle \inact\! #1 \rangle #2}
\newcommand \inBoxL[2] {[\inact\! #1]^l #2}
\newcommand \inDiaL[2] {\langle \inact\! #1 \rangle^l #2}
\newcommand \inBoxO[2] {[\inact\! #1]^o #2}
\newcommand \inDiaO[2] {\langle \inact\! #1 \rangle^o #2}
\newcommand \inBoxOL[2] {[\inact\! #1]^o_l #2}
\newcommand \inDiaOL[2] {\langle \inact\! #1 \rangle^o_l #2}

\newcommand \inBoxOE[2] {[\inact\! #1]^o_e #2}
\newcommand \inDiaOE[2] {\langle \inact\! #1 \rangle^o_e #2}

\newcommand \inBoxE[2] {[\inact\! #1]^e #2}
\newcommand \inDiaE[2] {\langle \inact\! #1\rangle^e #2}

\def\Ascr{{\mathcal A}}
\def\Bscr{{\mathcal B}}
\def\Cscr{{\mathcal C}}
\def\Dscr{{\mathcal D}}
\def\Escr{{\mathcal E}}
\def\Fscr{{\mathcal F}}
\def\Gscr{{\mathcal G}}
\def\Hscr{{\mathcal H}}
\def\Iscr{{\mathcal I}}
\def\Jscr{{\mathcal J}}
\def\Kscr{{\mathcal K}}
\def\Lscr{{\mathcal L}}
\def\Mscr{{\mathcal M}}
\def\Nscr{{\mathcal N}}
\def\Oscr{{\mathcal O}}
\def\Pscr{{\mathcal P}}
\def\Qscr{{\mathcal Q}}
\def\Rscr{{\mathcal R}}
\def\Sscr{{\mathcal S}}
\def\Tscr{{\mathcal T}}
\def\Uscr{{\mathcal U}}
\def\Vscr{{\mathcal V}}
\def\Wscr{{\mathcal W}}
\def\Xscr{{\mathcal X}}
\def\Yscr{{\mathcal Y}}
\def\Zscr{{\mathcal Z}}

\def\ssty{\scriptstyle}

\def\pizero{{\mathtt 0}}
\def\Api{{\mathtt A}}
\def\Bpi{{\mathtt B}}
\def\Cpi{{\mathtt C}}
\def\Dpi{{\mathtt D}}
\def\Ipi{{\mathtt I}}
\def\Mpi{{\mathtt M}}
\def\Npi{{\mathtt N}}
\def\Ppi{{\mathtt P}}
\def\Qpi{{\mathtt Q}}
\def\Rpi{{\mathtt R}}
\def\Spi{{\mathtt S}}
\def\Tpi{{\mathtt T}}

\def\relbar{\mathrel{\smash-}}
\def\joinrelm{\mathrel{\mkern-3.2mu}}
\def\tailpiece{\kern 1pt\vrule height 1ex width 0.3ex depth -.25ex}
\def\seqsym{\mathrel{\tailpiece\joinrelm\relbar}}

\newcommand\tylist[1]{\hat{\tau}(#1)}
\newcommand\g[2]{#1\! :\! #2}
\newcommand\rs[2]{#1^{\uparrow#2}}

\newcommand\ndef[1]{{\rm def}(#1)}
\newcommand\ncontr[1]{{\rm contr}(#1)}
\newcommand\nnew[1]{{\rm new}(#1)}
\newcommand\ncoin[1]{{\omega}(#1)}
\newcommand\rank[1]{\mid #1 \mid}
\newcommand{\sep}{\;\mid\;}
\newcommand{\FOL   }{FO\lambda}
\newcommand{\FOLD  }{\FOL^{\Delta}}
\newcommand{\FOLDN }{\FOL^{\Delta\N}}
\newcommand{\FOLDNb}{\FOL^{\Delta\nabla}}
\newcommand{\FOLNb }{\FOL^{\nabla}}
\newcommand{\FOLDCo}{\FOL^{\Delta\omega}}
\newcommand{\FOLDIn}{\FOL^{\Delta{\cal I}}}
\newcommand{\FOLDCoIn}{\FOL^{\Delta{\cal CI}}}
\newcommand{\Linc}{{\rm Linc}}
\newcommand{\Judg}[2]{#1\triangleright#2}
\newcommand{\Ll}{L_\lambda}
\newcommand{\NSeq}[3]{#1\,;\,#2 \seqsym #3}
\newcommand{\N}{{\rm I} \! {\rm N}}
\newcommand{\Seq}[2]{#1\seqsym #2}
\newcommand{\ISeq}[3]{#1\stackrel{#2}{\longrightarrow} #3}
\newcommand{\TSeq}[3]{#1 \vdash #2 : #3}
\newcommand{\aand}[2]{#1\mathbin{\hbox{\sl and}}#2}
\newcommand{\abs}{\hbox{\sl abs}}
\newcommand{\action}{\hbox{\sl a}}
\newcommand{\amatch}[3]{\langle#1=#2\rangle#3}
\newcommand{\anot}[1]{\mathop{\hbox{\sl not}}#1}
\newcommand{\app}{\hbox{\sl app}}
\newcommand{\arrow}{\hbox{\sl arr}}
\newcommand{\assertl}[1]{\hbox{\sl assert}_l(#1)}
\newcommand{\assert}{\hbox{\sl assert}}
\newcommand{\atomic}[1]{\hbox{\sl atom}~#1}
\newcommand{\atrue}{\hbox{\sl true}}
\newcommand{\llbra}{[\![}
\newcommand{\rrbra}{]\!]}
\newcommand{\bc}[2]{\hbox{\sl bc}(#1, #2)}
\newcommand{\bcl}[2]{\hbox{\sl bc}_{l}(#1, #2)} 
\newcommand{\bisimi}[3]{\hbox{\sl bisim}_{#1}~#2~#3}
\newcommand{\bisim}[2]{\hbox{\sl bisim}~#1~#2}
\newcommand{\gbisim}[2]{\hbox{\sl gbisim}~#1~#2}
\newcommand{\ebisim}[2]{\hbox{\sl ebisim}~#1~#2}
\newcommand{\lbisim}[2]{\hbox{\sl lbisim}~#1~#2}
\newcommand{\obisim}[2]{\hbox{\sl obisim}~#1~#2}
\newcommand{\boimp}{\subset}
\newcommand{\botL}{\bot{\cal L}}
\newcommand{\bulletL}{\bullet{\cal L}}
\newcommand{\bulletR}{\bullet{\cal R}}
\newcommand{\cL}{\hbox{\sl c}{\cal L}}
\newcommand{\circL}{\circ{\cal L}}
\newcommand{\circR}{\circ{\cal R}}
\newcommand{\cut}{\hbox{\sl cut}}
\newcommand{\defL}{\hbox{\sl def}{\cal L}}
\newcommand{\defR}{\hbox{\sl def\/{}}{\cal R}}
\newcommand{\defc}[4]{{\rm dfn}(#1,#2,#3,#4)}
\newcommand{\defcp}[4]{{\rm dfn}(#1,#2,#3,#4)}
\newcommand{\defeq}{\mathrel{\stackrel{{\scriptscriptstyle\triangle}}{=}}}
\newcommand{\defmu}{\mathrel{\stackrel{\mu}{=}}}
\newcommand{\defnu}{\mathrel{\stackrel{\nu}{=}}}
\newcommand{\depth}[2]{\hbox{\sl depth}_l(#1,#2)}
\newcommand{\diamb}[2]{\langle#1\rangle#2}
\newcommand{\diame}[2]{\langle\inact #1\rangle^E#2}
\newcommand{\diami}[2]{\langle\inact #1\rangle#2}
\newcommand{\diaml}[2]{\langle\inact #1\rangle^L#2}
\newcommand{\diamo}[2]{\langle\outact #1\rangle#2}
\newcommand{\dom}[1]{{\rm dom}(#1)}
\newcommand{\eqL}{{\rm eq}{\cal L}}
\newcommand{\eqR}{{\rm eq}{\cal R}}
\newcommand{\eval}[2]{#1\mathop{\Downarrow}#2}
\newcommand{\evs}{\hbox{\sl evs}}
\newcommand{\existsL}{\exists{\cal L}}
\newcommand{\existsR}{\exists{\cal R}}
\newcommand{\false}{\hbox{\sl false}}
\newcommand{\forallL}{\forall{\cal L}}
\newcommand{\forallR}{\forall{\cal R}}
\newcommand{\formula}{\hbox{\sl formula}}
\newcommand{\fst}{\rho}
\newcommand{\fv}[1]{{\rm fv}(#1)}
\newcommand{\generic}[2]{\langle #1\triangleleft#2\rangle}
\newcommand{\hc }{\hbox{\sf hc}}
\newcommand{\hcu}{\hc^\forall}
\newcommand{\hcn}{\hc^\nabla }
\newcommand{\hcun}{\hc^{\forall\nabla} }
\newcommand{\iand}{\wedge}
\newcommand{\iexists}{\exists}
\newcommand{\ifalse}{\bot}
\newcommand{\ifcond}[3]{\hbox{\sl if}~#1~#2~#3}
\newcommand{\iforall}{\forall}
\newcommand{\iimp}{\supset}
\newcommand{\iimpR}{\supset{\cal R}}
\newcommand{\ii}{\hbox{\sl i}}
\newcommand{\inact}{\mathop{\downarrow}}
\newcommand{\indR}{\mu {\cal R}}
\newcommand{\indL}{\mu {\cal L}}
\newcommand{\indm}[1]{{\rm ind}(#1)}
\newcommand{\coindR}{\nu {\cal R}}
\newcommand{\coindL}{\nu {\cal L}}

\newcommand{\init}{\hbox{\sl init}}
\newcommand{\inpi}[2]{\hbox{\sl in}~#1~#2}
\newcommand{\interp}[1]{\hbox{\sl pv}~#1}
\newcommand{\interpl}[1]{\mathop{\triangleright}_{l}#1}
\newcommand{\itrue}{\top}
\newcommand{\lam}{{\rm lam}}
\newcommand{\landL}{\land{\cal L}}
\newcommand{\landR}{\land{\cal R}}
\newcommand{\level}[1]{{\rm lvl}(#1)}
\newcommand{\lname}[2]{{lname}~#1~#2}
\newcommand{\loc}{\hbox{\sl loc}}
\newcommand{\lorL}{\lor{\cal L}}
\newcommand{\lorR}{\lor{\cal R}}
\newcommand{\lra}{\longrightarrow}
\newcommand{\lub}[1]{{\rm lub}(#1)}
\newcommand{\matchpi}[3]{{match}~#1~#2~#3}
\newcommand{\mc}{\hbox{\sl mc}}
\newcommand{\measure}[1]{{\rm ht}(#1)}
\newcommand{\nablaL}{\nabla{\cal L}}
\newcommand{\nablaR}{\nabla{\cal R}}
\newcommand{\name}{\hbox{\sl n}}
\newcommand{\natL}{\hbox{\sl nat}{\cal L}}
\newcommand{\natR}{\hbox{\sl nat}{\cal R}}
\newcommand{\nat}[1]{\hbox{\sl nat} \; #1}
\newcommand{\nlist}{\hbox{\sl nlist}}
\newcommand{\nt}{\hbox{\sl nt}}
\newcommand{\nupi}[2]{\nu #1.#2}
\newcommand{\oand}{\mathbin{\&}}
\newcommand{\obj}{\hbox{\sl obj}}
\newcommand{\oexists}{\mathop{\hat\exists}}
\newcommand{\oforall}{\mathop{\hat\forall}}
\newcommand{\oimpL}{\oimp{\cal L}}
\newcommand{\oimpR}{\oimp{\cal R}}
\newcommand{\oimp}{\supset}
\newcommand{\one  }[3]{#1\stackrel{#2}{-\!\!-\!\!\!\rightarrow    } #3}
\newcommand{\onel }[4]{#1\stackrel{#2}{-\!\!-\!\!\!\rightarrow_{#3}} #4}
\newcommand{\onep }[3]{#1\stackrel{#2}{-\!\!-\!\!\!\rightharpoonup} #3}
\newcommand{\onepl}[4]{#1\stackrel{#2}{-\!\!-\!\!\!\rightharpoonup_{#3}} #4}
\newcommand{\oo}{\hbox{\sl o}}
\newcommand{\otrue}{\hat\top}
\newcommand{\outact}{\mathop{\uparrow}}
\newcommand{\outpi}[3]{\hbox{\sl out}~#1~#2~#3}
\newcommand{\parpi}[2]{#1\mathbin{|}#2}
\newcommand{\barpi}{\mathbin{|}}
\newcommand{\pisim}{\stackrel{.}{\sim}}
\newcommand{\pluspi}[2]{#1 + #2}
\newcommand{\prg}[1]{\hbox{\sl prog}~#1}
\newcommand{\proc}{\hbox{\sl p}}
\newcommand{\prog}{\hbox{\sl prog}}
\newcommand{\ran}[1]{{\rm ran}(#1)}
\newcommand{\ra}{\rightarrow}
\newcommand{\rst}{\hat\rho}
\newcommand{\sat}[2]{#1\models_{l}#2}
\newcommand{\siml}{\hbox{\sl sim}_l}
\newcommand{\simm}[2]{\hbox{\sl sim}~#1~#2}
\newcommand{\simu}[2]{#1\sqsubseteq #2}
\newcommand{\ssat}[3]{#2\models_{l}^{#1}#3}
\newcommand{\suc}[1]{\hbox{\sl s} \; #1}
\newcommand{\taupi}[1]{\tau~#1}
\newcommand{\term}{\hbox{\sl term}}
\newcommand{\tm}{\hbox{\sl tm}}
\newcommand{\topL}{\top{\cal L}}
\newcommand{\topR}{\top{\cal R}}
\newcommand{\trans}[1]{[\![ #1 ]\!]}
\newcommand{\true}{\hbox{\sl true}}
\newcommand{\tup}[1]{\langle #1 \rangle}
\newcommand{\typeof}{\hbox{\sl typeof}}
\newcommand{\ty}{\hbox{\sl ty}}
\newcommand{\variable}{\hbox{\sl variable}}
\newcommand{\wL}{\hbox{\sl w}{\cal L}}
\newcommand{\zero}{\hbox{\sl z}}
\newcommand{\z}{\hbox{\sl z}}

\newcommand\rsubst[2]{{#1}_{\restriction {#2}}}



\newcommand{\fn}[1]{{\rm fn}(#1)}
\newcommand{\bn}[1]{{\rm bn}(#1)}
\newcommand{\n}[1]{{\rm n}(#1)}
\newcommand{\nm}{{\rm nm}}
\newcommand{\TauAct}{{\rm TAU}}
\newcommand{\OutAct}{{\rm OUT}}
\newcommand{\InActL}{{\rm INP\!-\!L}}
\newcommand{\InActE}{{\rm INP\!-\!E}}
\newcommand{\PiSum}{{\rm SUM}}
\newcommand{\PiMatch}{{\rm MAT}}
\newcommand{\PiIde}{{\rm IDE}}
\newcommand{\PiPar}{{\rm PAR}}
\newcommand{\PiComL}{{\rm COMM\!-\!L}}
\newcommand{\PiComE}{{\rm COMM\!-\!E}}
\newcommand{\PiClose}{{\rm CLOSE}}
\newcommand{\PiCloseL}{{\rm CLOSE\!-\!L}}
\newcommand{\PiCloseE}{{\rm CLOSE\!-\!E}}
\newcommand{\PiRes}{{\rm RES}}
\newcommand{\PiOpen}{{\rm OPEN}}

\newcommand\pitoproc[1]{\langle #1 \rangle}
\newcommand\proctopi[1]{\| #1 \|}




\bibliographystyle{acmtrans}

\markboth{A. Tiu and D. Miller}
         {Proof Search Specifications of the -calculus}
\title{Proof Search Specifications of Bisimulation and\\
       Modal Logics for the -calculus}
\author{Alwen Tiu \\ Logic and Computation Group\\ 
College of Engineering and Computer Science\\
The Australian National University
\and 
Dale Miller\\ INRIA-Saclay \& LIX, \'Ecole polytechnique}

\begin{abstract}

We specify the operational semantics and bisimulation relations for
the finite -calculus within a logic that contains the
 quantifier for encoding {\em generic judgments} and
definitions for encoding fixed points.
Since we restrict to the finite case, the ability of the logic to unfold fixed
points allows this logic to be complete for both the inductive nature
of operational semantics and the coinductive nature of bisimulation.
The  quantifier helps with
the delicate issues surrounding the scope of variables within
-calculus expressions and their executions (proofs).  We 
illustrate several merits of the logical specifications permitted by
this logic: they
are natural and declarative; they contain no side-conditions
concerning names of variables while maintaining a completely formal
treatment of such variables; differences between late and open
bisimulation relations arise from familar logic distinctions; 
the interplay between the three quantifiers (, , and
) and their scopes can explain the differences between early
and late bisimulation and between various modal operators based on
bound input and output actions;
and proof search involving the application of inference rules, unification, and
backtracking can provide complete proof systems for one-step
transitions, bisimulation, and satisfaction in modal logic.
We also illustrate how one can encode the -calculus with replications,
in an extended logic with induction and co-induction.
\end{abstract}

\category{F.3.1}{Logics and Meanings of Programs}
         {Specifying and Verifying and Reasoning about Programs}
         [Specification Techniques]
\category{F.4.1}{Mathematical Logic and Formal Languages}
         {Mathematical Logic}[Proof Theory] 

\terms{Theory, Verification}
\keywords{proof search, -tree syntax,  quantifier, 
generic judgments, higher-order abstract syntax, -calculus, 
bisimulation, modal logics}


\begin{document}
\begin{bottomstuff}
Authors' addresses: A. Tiu, Logic and Computation Group, College of Engineering
and Computer Science, Building 115, The Australian National University,
Canberra, ACT 0200, Australia; D. Miller, Laboratoire d'Informatique
(LIX), \'Ecole Polytechnique, Rue de Saclay, 91128 Palaiseau Cedex,
France. 
\end{bottomstuff}
\maketitle

\section{Introduction}
\label{sec:intro}

We present formal specifications of various aspects of the
-calculus, including its syntax, operational semantics,
bisimulation relations, and modal logics.  We shall do this by using
the  logic \cite{miller05tocl}.  We provide a high-level
introduction to this logic here before presenting more technical
aspects of it in the next section.

Just as it is common to use meta-level application to represent
object-level application (for example, the encoding of  is via
the meta-level application of the encoding for plus to the encoding of
its two arguments), we shall use meta-level -abstractions to
encode object-level abstractions.  The term {\em higher-order abstract
  syntax} (HOAS) \cite{pfenning88pldi} is commonly used to describe
this approach to mapping object-level abstractions into some
meta-level abstractions.  Of course, the nature of the resulting
encodings varies as one varies the meta-level.  For example, if the
meta-level is a higher-order functional programming language or a
higher-order type theory, the usual abstraction available constructs
function spaces.  In this case, HOAS maps object-level abstractions to
semantically rich function spaces: determining whether or not two
syntactic objects are equal is then mapped to the question of
determining if two functions are equal (typically, an undecidable
judgment).  In such a setting, HOAS is less about syntax and more
about a particular mathematical denotation of the syntax.  In this
paper, we start with an intuitionistic subset of the Simple Theory of
Types \cite{church40} that does not contain the {\em mathematical}
axioms of extensionality, description, choice, and infinity.  In this
setting, -abstraction is not strong enough to denote general
computable functions and equality of -terms is decidable.  As
a result, this weaker logic provides term-level bindings that can be
used to encode syntax with bindings.  This style of describing syntax
via a meta-logic containing a weak form of -abstraction has
been called the {\em -tree syntax} \cite{miller00cl} approach
to HOAS in order to distinguish it from the approaches that use
function spaces.  The -tree syntax approach to encoding
expressions is an old one ({\em cf.}
\cite{huet78,miller86acl,miller87slp,paulson86jlp}) and is used in
specifications written in the logic programming languages
Prolog \cite{nadathur88iclp} and Twelf \cite{pfenning99cade}.


Following Church, we shall use -abstractions to encode
both {\em term-level abstractions} and {\em formula-level
abstractions} ({\em e.g.}, quantifiers).  The computational aspects of the
-calculus are usually specified via structured operational
semantics \cite{plotkin81}: here, such specifications are encoded
directly as inference rules and proofs over primitive relational
judgments ({\em e.g.}, one-step transitions).  As a result, a formal account
of the interaction of binding in syntax and binding in computation
leads to notions of {\em proof-level abstractions}.  One such binding
is the familiar {\em eigenvariable} abstraction of
\cite{gentzen35} used to encode a universally quantified variable that has
scope over an entire sequent.  A second proof-level binding was
introduced in \cite{miller05tocl} to capture a notion of {\em generic
judgment}: this proof-level binding has a scope over individual
entries within a sequent and is closely associated with the
formula-level binding introduced by the -quantifier.  A major
goal of this paper is to illustrate how the -quantifier
and this second proof-level abstraction can be used to specify and
reason about computation: the -calculus has been chosen, in part,
because it is a small calculus in which bindings play an important role
in computation.

A reading of the truth condition for  is something
like the following: this formula is true if  is true for the new
element  of type .  In particular, the formula  is a theorem regardless of the
intended interpretation of the domain  since the bindings for
 and  are distinct.  In contrast, the truth value of the
formula  is dependent on the
domain : this quantified inequality is true if and only if 
the interpretation of  is empty.


The  logic is based on
intuitionistic logic, a weaker logic than classical logic.  One of the
principles missing from intuitionistic logic is that of the excluded
middle: that is,  is not generally provable in
intuitionistic logic.  Consider, for example, the following formula
concerning the variable :

In classical logic, this formula is a trivial theorem.  From a
constructive point-of-view, it might not be desirable to admit this
formula as a theorem in some cases. 
If the type of quantification  is
a conventional (closed) first-order datatype, then we might expect to have a
decision procedure for equality.  For example, if  is the type
for lists, then it is a simple matter to construct a procedure that
decides whether or not two members of  are equal by
considering the top constructor of the list and, in the event of
comparing two non-empty lists, making a recursive call (assuming a
decision procedure is available for the elements of the list).  In fact, it
is possible to prove in an intuitionistic logic augmented with
induction (see, for example, \cite{tiu04phd}) the formula  for
closed, first-order datatypes.  

If the type  is not given inductively, as is the usual case
for names in intuitionistic formalizations of the -calculus (see
\cite{despeyroux00ifiptcs} and below), then
the corresponding instance of  is not provable.
Thus, whether or not
we allow instances of  to be assumed can change the nature
of a specification.  In fact, we show in Section~\ref{sec:bisim},
that if we add to our specification of {\em open bisimulation}
\cite{sangiorgi96acta} assumptions corresponding to , then we get
a specification of {\em late bisimulation}.  If we were working with a
classical logic, such a declarative presentation of these two
bisimulations would not be so easy to describe.  

The authors first presented the logic used in this paper in
\cite{miller03lics} and illustrated its usefulness with the
-calculus: in particular, the specifications of one-step
transitions in Figure~\ref{late pi def} and of late bisimulation in
Figure~\ref{bisim} also appear in \cite{miller03lics} but without
proof.  In this paper, we state the formal properties of our specifications,
provide a specification of late bisimulation, and provide a novel
comparison between open and late bisimulation.
In particular, we show that the difference between open and late
bisimulation (apart from the difference that arises from the use of
types defined inductively or not) can be captured by the different
quantification of free names using  and .
We show in Section~\ref{sec:bisim} that a natural class of name {\em
distinctions} can be captured by the alternation of  and
 quantifiers and, in the case where we are interested only in
checking open bisimilarity modulo the empty distinction, the notion of
distinction that arises in the process of checking bisimilarity is
completely subsumed by quantifier alternation.
In Section~\ref{sec:modal} we show that ``modal logics
for mobility'' can easily be handled as well and present, for the
first time, a modal characterization of open bisimulation.  Since our
focus in this paper is on names, scoping of names, dependency of
names, and distinction of names, we have chosen to focus on the finite
-calculus.  The treatment of the -calculus with replication is
presented in Section~\ref{sec:pi rep} through an example.  In
Section~\ref{sec:auto} we outline the automation of proof search based
on these specifications: when such automation is applied to our
specification of open bisimulation, a symbolic bisimulation
procedures arises.  In Section~\ref{sec:related} we present some related and
future work and Section~\ref{sec:conc} concludes the paper. 
In order to improve the readability of the main part of the paper, 
numerous technical proofs have been moved to the appendices.

Parts of this paper, in their preliminary forms and without proofs,
have been presented in \cite{tiu04fguc,tiu05concur}: in particular,
the material on encoding bisimulations (Section~\ref{sec:bisim})
corresponds to \cite{tiu04fguc} and the material on encoding modal
logics for the -calculus (Section~\ref{sec:modal}) corresponds to
\cite{tiu05concur}.



\section{Overview of the logic}
\label{sec:foldn}

This paper is about the use of a certain logic to specify and reason
about computation.  We shall assume that the reader is not interested
in an in-depth analysis of the logic but with its application.  We
state the most relevant results we shall need about this logic in
order to reason about our -calculus specifications.  The reader
who is interested in more details about this logic is referred to
\cite{tiu04phd} and \cite{miller05tocl}.


At the core of the logic  (pronounced ``fold-nabla'') is a
first-order logic for -terms (hence, the prefix ) that
is the result of extending Gentzen's LJ sequent calculus for
first-order intuitionistic logic \cite{gentzen35} with simply typed
-terms and with quantifiers that range over non-predicate
types.
The full logic is the result of making two extensions to this core.
First, ``fixed points'' are added via the technical
device of ``definitions,'' presented below and marked with the symbol
.  Fixed points can capture important forms of ``must
behavior'' in the treatment of operational semantics
\cite{mcdowell00tcs,mcdowell03tcs}.  Fixed points also strengthen
negation to encompass ``negation-as-finite-failure.''  In the presence
of this stronger negation, the usual treatment of -tree
syntax via ``generic judgments'' encoded as universal quantifiers is inadequate:
a more intensional
treatment of such judgments is provided by the addition of the
-quantifier \cite{miller05tocl}.

A {\em sequent} is an expression of the form

where  are formulas and the elongated turnstile
 is the sequent arrow.
To the left of the turnstile is a multiset: thus
repeated occurrences of a formula are allowed.  If the formulas  contain free variables, they are considered universally
quantified outside the sequent, in the sense that if the above sequent
is provable then every instance of it is also provable.  In proof
theoretical terms, such free variables are called {\em eigenvariables}.

A first attempt at using sequent calculus to capture judgments about
the -calculus could be to use eigenvariables to encode names in
the -calculus, but this is certainly problematic.  For example, if we
have a proof of the sequent , where  and  are
different eigenvariables, then logic dictates that the sequent
 is also provable (given the universal quantifier
reading of 
eigenvariables).  If the judgment  is about, say,
bisimulation, then it is not likely that a statement about
bisimulation involving two different names  and  remains true if
they are identified to the same name .

To address this problem, the logic  extends sequents with a
new notion of ``local scope'' for proof-level bound variables
(originally motivated in \cite{miller03lics} to encode ``generic
judgments'').  In particular, sequents in  are of the form

where  is a {\em global signature}, \ie, the set of eigenvariables 
whose scope is over the entire sequent, and  is a {\em local signature}, \ie, 
a list of variables scoped over . 
We shall consider sequents to be binding structures in the sense 
that the signatures, both the global and local
ones, are abstractions over their respective scopes.
The variables in 
 and  will admit -conversion by systematically
changing the names of variables in signatures as well as those in
their scope, following the usual convention of the -calculus.
The meaning of eigenvariables is as before except that 
now instantiation of eigenvariables has to be capture-avoiding with respect
to the local signatures.
The variables in local signatures act as locally scoped {\em generic constants}:
that is, they do not vary in proofs since they will not be instantiated.
The expression  is called a {\em generic judgment}
or simply a {\em judgment}. 
We use script letters , , {\em etc} to denote judgments.
We write simply  instead of  if the
signature  is empty. We shall often write 
the list  as a string of variables: \eg,
a judgment  will be written as .
If the list  is known from context we shall also abbreviate the
judgment as .

Following Church \citeyear{church40}, the type  is used to denote the
type of formulas.  The propositional constants of  are
 (conjunction),  (disjunction),  (implication),
 (true) and  (false). We shall abbreviate 
as  (intuitionistic negation).
Syntactically, logical constants can be seen as typed constants: for example, the binary connectives have
type .  For each simple type  that does not
contain , there are three quantifiers in : namely,
 (universal quantifier),  (existential
quantifier),  (nabla), each one of type .  The subscript type  is often dropped when it can be
inferred from context or its value is not important.  Since we do not
allow quantification over predicates, this logic is
proof-theoretically similar to first-order logic.
The inference rules for  that do not deal with
definitions are given in Figure~\ref{fig:core foldnb}.  

\begin{figure}









\caption{The inference rules of  not dealing with definitions.}
\label{fig:core foldnb}
\end{figure}

During the search for proofs (reading rules bottom up), inference rules 
for  and  quantifier place new variables
(eigenvariables) into 
the global signature while the inference rules for  place new
variables into a local signature. 
In the  and  rules, {\em raising} \cite{miller92jsc} is
used when replacing the bound variable  (which can be substituted for by
terms containing variables in both the global signature and the local signature
) with the variable  (which can only be instantiated with
terms containing variables in
the global signature). In order not to miss substitution terms, the
variable  is replaced by the term : the latter
expression is written simply as  where  is the list
.
As is usual, the eigenvariable  must not be free in the lower
sequent of these rules. In  and , the term  can have free
variables from both  and , a fact that is given
by the typing judgment .  
The  and  rules have the proviso that  is 
not free in . The introduction rules for propositional connectives are 
the standard ones for intuitionistic logic. Reading the rules top down, 
the structural rule  (contraction) allows removal of duplicate judgments from the sequent 
and the rule  (weakening) allows introduction of a (possibly new) 
judgment into the sequent. Note that since the initial rule  has 
implicit weakening, the weakening rule  can actually be shown admissible, hence
it is strictly speaking not necessary. It is, however, convenient for interactive proof
search, since it allows one to remove irrelevant formulae (reading the rule bottom up)
in a sequent.

While sequent calculus introduction rules generally only introduce
logical connectives, the full logic  additionally allows introduction
of atomic judgments; that is, judgments which do not contain any
occurrences of logical constants.  To each atomic judgment, , we
associate a defining judgment, , the {\em definition} of
.  The introduction rule for the judgment  is in effect
done by replacing  with  during proof search.  This
notion of definitions is an extension of work by Schroeder-Heister
\citeyear{schroeder-heister93lics}, Eriksson \citeyear{eriksson91elp}, Girard
\citeyear{girard92mail}, St\"ark \citeyear{staerk92jfcs}, and McDowell and
Miller \citeyear{mcdowell00tcs}.  These inference rules for definitions
allow for modest reasoning about the fixed points of (recursive) definitions.

\begin{definition}
\label{def:def}
A {\em definition clause} is written 
, 
where  is a predicate constant, every free variable of
the formula  is also free in at least one term in the list
 of terms, and all variables free in  are
contained in the list  of variables.  The atomic formula  is called the {\em head} of the clause, and the formula
 is called the {\em body}.  The symbol  is used simply to
indicate a definitional clause: it is not a logical connective.  

Let  be a
definition clause. Let  be a list of variables of types
, respectively. 
The {\em raised definition clause} of  with respect to the signature
 is defined as

where  is the substitution
 and 
 is of type
, for every
. 
A {\em definition} is a set of definition clauses
together with their raised clauses.
\end{definition}

Recall that we use script letters, such as , , etc., 
to refer to generic judgments. In particular, in referring to a raised definition clause, e.g., 

we shall sometimes simply write  when the 
local signatures can be inferred from context or are unimportant to the discussion.

To guarantee the consistency (and cut-elimination) of the logic
, we need some kind of stratification of definition so as to 
avoid a situation where a definition of a predicate depends
negatively on itself. 
For this purpose, we associate to each predicate  a 
natural number , the {\em level} of .  The notion of
level is generalized to formulas as follows.
\begin{definition}
\label{def:level}
Given a formula , its {\em level}  is defined as follows:
\begin{enumerate}
\item 
\item 
\item 
\item 
\item . 
\end{enumerate}
We shall require that for every definition clause , .  
\end{definition}
Note that the stratification condition above implies that in
a stratified definition, say ,
the predicate  can only occur strictly positively in  (if it occurs at all).
All definitions considered in this paper can be easily stratified according
to the above definition and cut-elimination holds for the logic using them.
For the latter, we refer the reader to \cite{miller05tocl} for the full details.


The introduction rules for a defined judgment are as follows.
When applying the introduction rules, we shall omit the 
outer quantifiers in a definition clause 
and assume implicitly that the free variables in the definition
clause are distinct from other variables in the sequent.


In the above rules, we apply substitution to judgments.
The result of applying a substitution  to a generic judgment
, written as
, is
, if  is equal (modulo -conversion) to .  If  is a multiset of generic
judgments, then  is the multiset .  
In the  rule, we use the notion of {\em complete set of
unifiers} (CSU) \cite{huet75tcs}. We denote by  the
complete set of unifiers for the pair : that is, for
any substitution  such that , there
is a substitution  such that  for some substitution .  In all the
applications of  in this paper, the set  is
either empty (the two judgments are not unifiable) or contains a
single substitution denoting the most general unifier.  The signature
 in  denotes a signature obtained from 
by removing the variables in the domain of  and adding the
variables in the range of .  In the  rule, reading the
rule bottom-up, eigenvariables can be instantiated in the premise,
while in the  rule, eigenvariables are not instantiated.  The
set that is the premise of the  rule means that that rule
instance has a premise for every member of that set: if that set is
empty, then the premise is proved.

Equality for terms can be defined in  using the single
definition clause .
Specializing the  and  rules to equality yields the
inference rules

Disequality , the negation of equality, is an abbreviation
for .

One might find the following analogy with logic programming helpful:
if a definition is viewed as a logic program, then the  rule
captures backchaining and the  rule corresponds to {\em case
analysis} on all possible ways an atomic judgment could be proved.  In
the case where the program has only finitely many computation paths,
we can effectively encode {\em negation-as-failure} using 
\cite{hallnas91jlc}.


\section{Some meta-theory of the logic}
\label{sec:meta}

Once we have written a computational specification as logical
formulas, it is important that the underlying logic has 
formal properties that allow us to reason about that
specification.  In this section, we list a few formal properties of
 that will be used later in this paper.

Cut-elimination for  \cite{miller05tocl,tiu04phd} is probably
the single most important meta-theoretic property needed.  Beside
guaranteeing the consistency of the logic, it also provides
completeness for {\em cut-free} proofs: these proofs are 
used to help prove the {\em adequacy} of a logical specification.  For
example, the proof that a certain specification actually encodes the
one-step transition relation or the bisimulation relation starts by
examining the highly restricted structure of cut-free proofs.  Also,
cut-elimination allows use of modus ponens and substitutions into
cut-free proofs and to be assured that another cut-free proof arises
from that operation.

Another important structural property of provability is the {\em
invertibility} of inference rules.  An inference rule of logic is {\em
invertible} if the provability of the conclusion implies the
provability of the premise(s) of the rule.  The following rules in
 are invertible:  (see \cite{tiu04phd} for a proof).  Knowing the
invertibility of a rule can be useful in determining some structure of
a proof.  For example, if we know that a sequent  is provable, then by the invertibility of , we know
that it must be the case that  and
 are provable.

We now present several meta-theoretic properties of provability that
are specifically targeted at the -quantifier.  These
properties are useful when proving the adequacy of our
specifications of bisimulation and modal logic in the following
sections.  These properties also provide some insights into
the differences between the universal and the  quantifiers.  The
proofs of the propositions listed in this section can be found in 
\cite{tiu04phd}.

Throughout the paper, we shall use the following notation for provability:
We shall write  
to denote the fact the sequent  is provable, and 
 to denote provability of the sequent 

The following proposition states that the global scope of an
eigenvariable can be weakened to be a locally scoped variable when
there are no assumptions.

\begin{proposition}
\label{prop:forall nabla}
If   then .
\end{proposition}

Notice that the implication  does not necessarily hold.   For example, if the type  is
empty, then  may be true vacuously, independently of the
structure of , whereas attempting to prove  reduces to
attempting to prove  given the fresh element  of type . 

As we suggested in Section~\ref{sec:intro} with the formula , the converse of
Proposition~\ref{prop:forall nabla} is not true in general.  That
converse does hold, however, if we use definitions and formulas that
do not contain implications and, consequently, do not contain
negations (since these are formally defined as implications).
Horn clauses provide an 
interesting fragment of logic that does not contain negations: in
that setting, the distinction between  and  cannot be
observed using the proof system.  More precisely, let {\em
-formulas} (for Horn clauses formulas with  and
) be a formulas that do not contain occurrences of the logical
constant  (implication).  A -definition is a definition
whose bodies are -formulas.  For example, the definition of the
one-step transition in Figure~\ref{late pi def} is an
-definition but the definition of bisimulation in
Figure~\ref{bisim} is not a -definition.

\begin{proposition}\label{prop:nabla forall}
Let  be a -definition and  be a -formula.
Then, assuming  is the only definition used,  is provable  
if and only if  is provable.
\end{proposition}

The above proposition highlights the fact that positive occurrences of
 are interchangeable with  The specification of the
operational semantics of the -calculus in the next section uses
only positive occurences of , hence its specification can be
done also in a logic without .  However, our specifications of
bisimulation and modal logics in the subsequent sections make use of
implications in definitions and, as a result,  cannot be
replaced with .  We shall come back to this discussion on the
distinction between  and  when we present the
specification of bisimulation in Section~\ref{sec:bisim}.

Finally, we state a technical result about proofs in  that
states that provability of a sequent is not affected by the
application of substitutions.

\begin{proposition}
\label{prop:subst}
Let  be a proof of . 
Then for any substitution , there exists a proof  of 
 such that
the height of proof of  is less than or equal to the height of .
\end{proposition}


\section{Logical specification of one-step transition}

The finite -calculus is the fragment of the -calculus
without recursion (or replication). 
In particular, process expressions are defined as

We use the symbols , , , ,  to
denote processes and  lower case letters, {\em e.g.}, 
to denote names.
The occurrence of  in the processes  and  is a binding 
occurrence with  as its scope. 
The set of free names in  is denoted by , the set of bound
names is denoted by . We write  for the set
. We consider processes to be equivalent 
if they are identical up to a renaming of bound variables.


The relation of one-step (late) transition \cite{milner92icII} for the
-calculus is denoted by , 
where  and  are processes and  is an action. 
The kinds of actions are {\em the silent action} , 
{\em the free  input action} , 
{\em the free output action} , 
{\em the bound input action} , and
{\em the bound output action} . The name  in  and
 is a binding occurrence. Just as we did with processes, we use
,  and  to denote free names,
bound names, and names in . An action without binding
occurrences of names is a {\em free action} (this includes the silent action); 
otherwise it is a {\em bound action}. 

Three primitive syntactic categories are used to encode the
-calculus into -tree syntax: \name\ for names, \proc\
for processes, and  for actions.  We do not assume any
inhabitants of type : as a consequence, a free name is
translated to a variable of type  that is either universally or
-quantified, depending on whether we want to allow names to
be instantiated or not. For instance, when encoding late bisimulation,
free names correspond to -quantified variables, while when
encoding open bisimulation, free names correspond to universally
quantified variables (Section~\ref{sec:bisim}).  Since the rest of
this paper is about the -calculus, the  quantifier will
from now on only be used at type .

There are three constructors for actions:  (for the
silent action) and the two constants  and , both of
type  (for building input and output
actions, respectively).  The free output action , is encoded
as  while the bound output action  is encoded
as  (or the -equivalent term ).  The free input action , is encoded as  while
the bound input action  is encoded as 
(or simply ).  Notice that bound input and bound output actions
have type  instead of .

The following are process constructors, where  and  are written
as infix: 

Notice  is overloaded by being used as a constructor
of actions and of processes.
The one-step transition relation is represented using two predicates:
The predicate  of type
, where the first argument (indicated with )
is of type , the second argument is of type , and
the third argument is of type , 
encodes transitions involving the free actions while the 
predicate  of type
 encodes transitions
involving bound values.  The precise translation of the -calculus
syntax into simply typed -terms is given in the following
definition. We assume that names in -calculus processes are
translated to variables (of the same names) in the meta logic. 


\begin{definition}
The following function  translates process expressions
to -long normal terms of type . 

We abbreviate  as simply .  
The one-step transition judgments are translated to atomic
formulas as follows (we overload the symbol ).

\end{definition}

Notice that we mention encodings of free input actions and free input transition
judgments. Since we shall be concerned only with late transition systems, these 
will not be needed in subsequent specifications.  Giving these actions
and judgments explicit encodings, however, simplifies the argument for the adequacy of
representations of these syntactic judgments: that is, every
-normal term
of type  corresponds to an action in the -calculus, and similarly, every
atomic formula encoding of a one-step transition judgment (in -normal form) 
corresponds to a one-step transition judgment in the -calculus.


\begin{figure}

\caption{Definition clauses for the late transition system.}
\label{late pi def}
\end{figure}

Figure~\ref{late pi def} contains a definition, called ,
that encodes the operational semantics of the late transition system
for the finite -calculus.
In this specification, free variables are schema
variables that are assumed to be universally scoped over the 
definition clause in which they appear.  These schema
variables have primitive types such as , , and 
as well as functional types such as  and
.  

Notice that, as a consequence of using -tree syntax for this
specification, the usual side conditions in the original specifications of
the -calculus \cite{milner92icII} are no longer present. 
For example, the side condition that  in
the open rule is implicit, since  is outside the scope of  and, therefore,
cannot be instantiated with  (substitutions into logical
expressions cannot capture bound variable names).
The adequacy of our encoding is stated in the following lemma and 
proposition (their proofs can be found in \cite{tiu04phd}).

\begin{lemma}
\label{lemma: adequacy}
The function  is a bijection between -equivalence
classes of process expressions and -equivalence classes of
terms of type  whose free variables (if any) are of type .
\end{lemma}

\begin{proposition}
\label{prop:one step}
Let  and  be processes and  an action. Let  be
a list of free names containing the free names in , , and .
The transition  is derivable in the -calculus if and only
if  is provable 
in  with the definition .
\end{proposition}

If our goal was only to correctly encode one-step transitions for the
-calculus then we would need neither  nor definitions.
In particular, let  be the result of replacing
all  quantifiers in  with  quantifiers.
A slight generalization of Proposition~\ref{prop:nabla forall} (see
\cite{miller05tocl,tiu04phd}) allows us to conclude that
 is provable 
in  with the definition  if and only if
 is provable 
in  with the definition .  Furthermore, we
can also do with the simpler notions of {\em theory} or {\em
assumptions} and not {\em definition}.  In particular, let  be the set of implications that result from changing all
definition clauses in  into reverse implications
(i.e., the head is implied by the body).  We can then conclude that
 is provable 
in  with the definition  if and only if 
 
is provable in intuitionistic (and classical) logic.  In fact, such a specification 
of the one-step transitions in the -calculus as a theory without  dates
back to at least Miller and Palamidessi \citeyear{miller99surveys}.


Definitions and  are needed, however, for proving non-Horn
properties (that is, properties requiring a strong notion of
negation).  The following proposition is a dual of
Proposition~\ref{prop:one step}. Its proof can be found in the appendix.

\begin{proposition}
\label{prop:neg one step}
Let  and  be processes and  an action.   Let  be
a list of free names containing the free names in , , and .
The transition  is not derivable in the -calculus if and only
if  is provable 
in  with the definition .
\end{proposition}


The following example illustrates how a negation can be proved in
.  When writing encoded process expressions, we shall use,
instead, the syntax of the -calculus along with the usual
abbreviations: for example, when a name  is used as a prefix, it
denotes the prefix  where  is vacuous in its scope; when a
name  is used as a prefix it denotes the output prefix
 for some fixed name .  We also abbreviate
 as  and the process term  is omitted
if it appears as the continuation of a prefix. We assume that the
operators  and  associate to the right, {\em e.g.}, we write 
to denote .

\begin{example}
\label{ex:one step negative}
Consider the process , which could be the
continuation of some other process which inputs  on some channel,
{\em e.g.}, .  
Since the bound variable  is different from
any name substituted for , that process cannot make
a transition and the following formula should be provable.
 
Since  is bound inside the
scope of ,  no instantiation for  can be equal to .
The formal derivation of the above formula is (ignoring the initial 
uses of  and ):

The success of the topmost instance of  depends on the failure of 
the unification problem

Notice that the scoping of term-level variables is maintained at the proof-level
by the separation of (global) eigenvariables and (locally bound) generic variables.
The ``newness'' of  is internalized as a -abstraction and, hence,
it is not subject to instantiation. 
\end{example}

The ability to prove a negation is implied by any proof system that
can also prove bisimulation for the -calculus (at least for
the finite fragment): for
example, the negation above holds because the process
 is bisimilar to  (see the next
section). 


\section{Logical specifications of strong bisimilarity}
\label{sec:bisim}

We consider specifying three notions of bisimilarity tied to the late
transition system: the strong early bisimilarity, the strong late bisimilarity 
and the strong open bisimilarity.  As it turns out, the definition clauses
corresponding to strong late and strong open bisimilarity coincide.
Their essential differences are in the quantification of free names
and in the presence (or the absence) of the axiom of excluded middle
on the equality of names.
The difference between early and late bisimulation is tied to the scope
of the quantification of names in the case involving bound input (see the
definitions below).
The original definitions of early, late, and open bisimilarity are given in 
\cite{milner92icII,sangiorgi01}.  Here we choose to make the
side conditions explicit, instead of adopting the bound variable
convention in \cite{sangiorgi01}.

Given a relation on processes , we write 
to denote 

\begin{definition} 
\label{def:lbisim}
A process relation  is a {\em strong late bisimulation}
if  is symmetric and whenever ,
\begin{enumerate}
\item if  and  is a free action,
  then there is  such that
   and ;
\item if  and  
  then there is  such that
   and, for every name , 
  ; and 
\item if  and  
  then there is 
  such that  and .
\end{enumerate}
The processes  and  are {\em strong late bisimilar},
written , if there is a strong late bisimulation
 such that 
\end{definition}

\begin{definition} 
\label{def:ebisim}
A process relation  is a {\em strong early bisimulation}
if  is symmetric and whenever ,
\begin{enumerate}
\item if  and  is a free action,
  then there is  such that
   and ,
\item if  and  
  then for every name , there is  such that
   and ,
\item if  and  
  then there is 
  such that  and .
\end{enumerate}
The processes  and  are {\em strong early bisimilar}, written 
, if there is a strong early bisimulation  such that

\end{definition}

\begin{definition} 
A {\em distinction}  is a finite symmetric and irreflexive relation
on names.  A substitution  {\em respects} a distinction  if
 implies . We refer to the
substitution  as a {\em -substitution}.  Given a distinction
 and a -substitution , the result of applying 
to all variables in , written , is another distinction.
We denote by  the set of names occurring in .
\end{definition}

Since distinctions are symmetric by definition, when we enumerate a
distinction, we often omit the symmetric part of the distinction.  For
instance, we shall write  to mean the distinction  and we shall also write , for some
distinction  and finite sets of names  and , to mean the
distinction .
 
Following Sangiorgi~\cite{sangiorgi96acta}, we use a set of relations,
each indexed by a distinction, to define open bisimulation.

\begin{definition} 
\label{def:obisim}
The indexed set  of process relations is an
{\em indexed
open bisimulation} if for every distinction , the relation
 is symmetric and for every 
 that respects , if  then:
\begin{enumerate}
\item if  and  is a free action,
  then there is  such that
   and ,
\item if  and  
  then there is  such that
   and ,
\item \label{def:obisim3} if  and  
  then there is 
  such that  and 
   where .
\end{enumerate}
The processes  and  are {\em strong open -bisimilar},
written , if there is an indexed open bisimulation
 such that . The processes  and  are
{\em strong open bisimilar} if 
\end{definition}

Note that we strengthen a bit the condition 3 in
Definition~\ref{def:obisim} to include the distinction .  Strengthening the distinction this way does not change the
open bisimilarity, as noted in \cite{sangiorgi01}, but in our encoding
of open bisimulation, the distinction  is part of the specification
and the modified definition above helps us account for names better.

\begin{figure}
{\small


}
\caption{Specification of strong early, {\sl ebisim}, and late, {\sl
    lbisim}, bisimulations.}
\label{bisim}
\end{figure}

Early and late bisimulation can be specified in  using the
definition clauses in Figure~\ref{bisim}.  The definition clause for
open bisimulation is the same as the one for late bisimulation.  The
exact relationship between these definitions and the bisimulation
relations repeated above will be stated later in this section.

In reasoning about the specifications of early/late bisimulation, we encode
free names as -quantified variables whereas in the
specification of open bisimulation we encode free names as
-quantified variables.  For example, the processes  and  are late
bisimilar. The corresponding encoding in  would be .  The free names  and  should
not be -quantified for the following, simple reason: in logic
we have the implication .  That is, either
 is not provable, or it is
provable and we have a proof of . In
either case we lose the adequacy of the encoding.

The definition clauses shown in Figure~\ref{bisim} 
do not fully capture early and late bisimulations, since there is an
implicit assumption in the definition of these bisimulations that
name equality is decidable. This basic assumption on the ability to 
decide the equality among names is one of the differences between 
open and late bisimulation.  Consider,
for example,  the processes (taken from \cite{sangiorgi96acta})

As shown in \cite{sangiorgi96acta}  and  are late bisimilar but
not open bisimilar: establishing late bisimulation makes use 
of a case analysis that depends on
whether the input name  is equal to  or not.  
Decidability of name equality, in the case of early and late bisimulation,
is encoded as an additional axiom of excluded middle on names, i.e., 
the formula .
Note that since we allow dynamic creation of scoped names (via
), we must also state this axiom for arbitrary extensions of
local signatures.  The following set collects together such 
generalized excluded middle formulas:

We shall write  to indicate that  is a
finite subset of .


The following theorem states the soundness and completeness of the
 and  specifications with respect to the notions of early and 
late bisimilarity in the -calculus. By soundness we mean that, given a
pair of processes  and , if the encoding of the late (early)
bisimilarity is provable in  then the processes  and  are late (early) bisimilar.
Completeness is the converse.  The soundness and completeness of the
open bisimilarity encoding is presented at the end of this section, where we
consider the encoding of the notion of distinction in the -calculus.

\begin{theorem}
\label{thm:lbisim}
Let  and  be two processes and let  be
the free names in  and . 
Then  if and only if the sequent

is provable for some .
\end{theorem}


\begin{theorem}
\label{thm:ebisim}
Let  and  be two processes and let  be
the free names in  and . 
Then  if and only if the sequent

is provable for some .
\end{theorem}


It is well-known that the late bisimulation relation is
not a congruence since it is not preserved by the input prefix.
Part of the reason why the congruence property fails 
is that in the late bisimilarity there is no syntactic distinction
made between names which can be instantiated and names which cannot be
instantiated. 
Addressing this difference between names
is one of the motivations behind the introduction 
of distinctions and open bisimulation. 
There is another important
difference between open and late bisimulation; in open bisimulation
names are instantiated {\em lazily}, i.e., only when needed. 
The lazy instantiation of
names is intrinsic in ; eigenvariables are instantiated
only when applying the -rule. 
The syntactic distinction between names that can be instantiated and 
those that cannot be instantiated are reflected in  by the difference between 
the quantifier  and . 
The alternation of quantifiers in  gives rise to
a particular kind of distinction, the precise definition of which
is given below.

\begin{definition}
A {\em quantifier prefix} 
is a list  for some ,
where  is either  or .
If  is the above quantifier prefix, then the
{\em -distinction} is the distinction

\end{definition}
Notice that if  consists only of universal quantifiers
then the -distinction is empty.  Obviously, the
alternation of quantifiers does not capture all possible distinction,
{\em e.g.}, the distinction 

does not correspond to any quantifier prefix.  However, we can encode
the full notion of distinction by an explicit encoding of the unequal
pairs, as shown later.

It is interesting to see the effect of  substitutions on 
when  corresponds to a prefix . 
Suppose  is the prefix 

Since any two -quantified
variables are not made distinct in the definition of  prefix,
there is a  which respects  and which can identify  and .
Applying  to  changes 
 to some  which corresponds to the prefix 
. 
Interestingly, these two prefixes are related by logical implication:

for any formula . This observation suggests the following lemma.

\begin{lemma}
\label{lm:prefix}
Let  be a -distinction and let 
be a -substitution. Then the distinction 
corresponds to some prefix  such that
 for any 
formula  such that .
\end{lemma}

\begin{definition}
Let  be a distinction.  The
distinction  is translated as the formula .  If  then  is the logical constant  (the empty conjunction).
\end{definition}


\begin{theorem}
\label{thm:open bisim sound}
Let  and  be two processes, let  be a distinction and
let  be a quantifier prefix, where  contains
the free names in  and .
If the formula 

is provable then , where  is the union of
 and the -distinction.
\end{theorem}

\begin{theorem}
\label{thm:open bisim complete}
If  then the formula
 is provable, where 
are the free names in  and .
\end{theorem}

If a distinction  corresponds to a quantifier prefix , 
then it is easy to show that  is derivable in 
Therefore, we can state more concisely the adequacy result for the class of 
-open bisimulations in which  corresponds to a quantifier
prefix.  The following
corollary follows from Theorem~\ref{thm:open bisim sound}, 
Theorem~\ref{thm:open bisim complete} and Proposition~\ref{prop:forall nabla}. 

\begin{corollary}
\label{cor:open bisim prefix}
Let  be a distinction, let  and  be two processes and let 
be a quantifier prefix such that  contains the free names of ,  and ,
and  corresponds to the -distinction. Then
 if and only if 
\end{corollary}

Note that, by Lemma~\ref{lm:prefix}, the property of being a quantifier-prefix distinction
is closed under -substitution. Note also that in Definition~\ref{def:obisim}(\ref{def:obisim3}),
if  is a quantifier-prefix distinction then so is 

That is, if  corresponds to a quantifier prefix ,
then  corresponds to the quantifier prefix 
Taken together, these facts imply that one can define 
an open bisimulation relation which is indexed only by 
quantifier-prefix distinctions. That is, the family of relations ,
where each  is a quantifier-prefixed distinction and each  is defined as

is an indexed open bisimulation. 


Notice the absence of the excluded middle assumption on names in the
specification of open bisimulation. Since  is
intuitionistic, this difference between late and open bisimulation is
easily observed.  This would not be the case if the specification logic were
classical.  Since the axiom of excluded middle is present as well in
the specification of early bisimulation (Theorem~\ref{thm:ebisim}),
one might naturally wonder if there is a meaningful notion of
bisimulation obtained from removing the excluded middle in the
specification of early bisimulation and -quantify the free names.
In other words, we would like to see if there is a
notion of ``open-early'' bisimulation. In fact, 
the resulting bisimulation relation is exactly the same as open ``late''
bisimulation.


\begin{theorem}
\label{thm:open-early-bisim}
Let  and  be two processes and let  be the 
free names in  and . Then 
 is provable if and only if
 is provable.
\end{theorem}

We note that while it is possible to prove the impossibility
of transitions (Proposition~\ref{prop:neg one step}) within , 
it is in general not the case with non-bisimilarity (which is 
not even recursively enumerable in the infinite setting). 
If we have evidence that two processes are not
bisimilar, say, because one has a trace that the other does not have,
then this trace information can be used in the proof a
non-bisimulation.  Probably a good approach to this is to rely on
the modal logics developed later in the paper: if processes are not
bisimilar, there is an assertion formula that separates them.  We
have not planned to develop this particular theme since it seems to
us to not be the main thrust of this paper: describing proofs of
non-bisimilarity in the finite pi-calculus case is an interesting thing 
that could be developed on top of the foundation we provide.


To conclude this section, we should explicitly compare 
the two specifications of early bisimulation in Definition~\ref{def:ebisim}
and in Theorem~\ref{thm:ebisim},
the two specifications of late bisimulation in Definition~\ref{def:lbisim} and
in Theorem~\ref{thm:lbisim} and
the two specifications of open bisimulation in Definition~\ref{def:obisim}
and in Corollary~\ref{cor:open bisim prefix}.
Notice that those specifications that rely on logic are
written without the need for any explicit conditions on variable names
or any need to mention distinctions explicitly.  These various
conditions are, of course, present in the detailed description of the
proof theory of our logic, but it seems desirable to push
the details of variable names, substitutions, free and
bound-occurrence, and equalities into logic, where they have elegant
and standard solutions.


\section{Specification of modal logics}
\label{sec:modal}


\begin{figure}[t]
(a) Propositional connectives and {\em basic} modality:

(b) {\em Late} modality:


\vskip11pt
(c) {\em Early} modality:

\caption{Modal logics for the -calculus in -tree syntax}
\label{fig:modal}
\end{figure}

We now present the modal logics for the -calculus that were introduced
in \cite{milner93tcs}.  
In order not to confuse meta-level () formulas (or connectives) with
the formulas (connectives) of the modal logics under consideration, we shall
refer to the latter as object formulas (respectively, object connectives). 
We shall work only with positive object formulas, i.e., we do not permit
negations in those formulas. Note that since there are no atomic formulas
in these modal logics (in particular,  or  are not atomic),
de Morgan identities can be used to remove all occurrences of
negations from such formulas.
The syntax of the object formulas is as follows. 

The symbol  denotes a free action, i.e., a free input, a free
output, or the silent action.
In each of the formulas 
, ,  and
 (and their dual `boxed'-formulas), the occurrence of  in parentheses is
a binding occurrence whose scope is .
We use , , ,  to range over object formulas.
Note that we consider only finite conjunctions since the transition system
we are considering is finitely branching, and, therefore, an infinite
conjunction is not needed (as noted in \cite{milner93tcs}).
We consider object formulas equivalent up to renaming of bound variables. 

To encode object formulas we introduce the 
type  to denote such formulas and introduce the
following constants for encoding the object connectives:
 and  of type ; 
 and  of type ; 
 and 
of type ; 
 and  of type ; and
,
,
, 
, 
, 
, 
, and
 of type .
The translation of object formulas to -tree syntax is
given in the following definition.

\begin{definition}
The following function  translates object formulas 
to -long normal terms of type . 

\end{definition}

In specifying the satisfaction relation  between processes and
formulas, we restrict to the class of formulas which do not contain
occurrences of the free input modality. This is because we consider only the late transition system
and the semantics of the free input modality is defined with respect to the early
transition system.
But we note that adding this input modality and the early transition system 
does not pose any difficulty. Following Milner et. al., we shall identify
an object logic with the set of formulas it allows. We shall refer
to the object logic without the free input modalities as . 

The satisfaction relation  is encoded using the same symbol, 
which is given the type . This satisfaction
relation is defined by the clauses in Figure~\ref{fig:modal}.
This definition, called , 
corresponds to the modal logic  defined in \cite{milner93tcs}, minus
the clauses for the free input modality.  
Notice that  interprets object-level disjunction and conjunction
with, respectively, meta-level disjunction and conjunction. Since the modal logic 
is classical and the meta-logic  is intuitionistic, 
one may wonder whether such an encoding is complete. But since 
we consider only negation-free object formulas and since 
there are no atomic formulas, classical and intuitionistic provability
coincide for the non-modal fragment of .
The definition  is, however, incomplete for the full logic , 
in the sense that there are true assertions of modal logics that are not provable 
using this definition alone. Using the `box' modality, one can still encode 
some limited forms of negation, e.g., inequality of names. For instance, the modal judgment 

which essentially asserts that any two names are equal or unequal, is valid in , 
but its encoding in  is not provable without additional assumptions. 
It turns out that, as in the case with the specification of late bisimulation,
the only assumption we need to assure completeness is the 
axiom of excluded middle on the equality of names: 

Again, as in the specification of late bisimulation, we must also
state this axiom for arbitrary extensions of local signatures. 
The adequacy of the specification of modal logics is 
stated in the following theorem.

\begin{theorem}
\label{thm:modal adequacy}
Let  be a process, let  be an object formula of the modal logic . 
Then  if and only if for some
list  such that 
and some  ,  
the sequent 

is provable in  with definition .
\end{theorem}

The adequacy result stated in Theorem~\ref{thm:modal adequacy}
subsumes the adequacy for the specifications of the sublogics of .
Note that we quantify free names in the process-formula pair
in the above theorem since we do not assume any constants
of type . Of course, such constants can be introduced
without affecting the provability of the satisfaction 
judgments, but for simplicity, we repeat our treatment of names in the
late bisimulation setting here as well.


Notice that the list of names  in Theorem~\ref{thm:modal adequacy}
can contain more than just the free names of  and 
This is important for the adequacy of the specification, since in the modal
logics for the -calculus, we can specify a modal formula  and a process 
 such that the assertion  is true only if 
there exists a new name which is not among the free names of both 
and . Consider, for example, the assertion

and its encoding in  as the formula

If we do not allow extra new names in the quantifier prefix
in Theorem~\ref{thm:modal adequacy}, then we would have to
prove the formula

It is easy to see that provability of this formula reduces to
provability of

Since we do not assume any constants of type \name, the only way to prove
this would be to instantiate  with , hence, 

must be provable.  This is, in turn, equivalent to  which should not be 
provable for the adequacy result to hold. 
The key step here is the instantiation of . For the original formula
to be provable,  has to be instantiated with a name that is
distinct from .  This can be done only if we allow extra names
in the quantifier prefix: for example, the following formula is provable.


Note that in the statement of Theorem~\ref{thm:modal adequacy}, the list of names 
is existentially quantified. If one is to implement model checking for  using
the specification in Figure~\ref{fig:modal}, the issue of how these names are chosen needs to
be addressed. Obviously, the free names of  needs to be among .
It remains to calculate how many new names need to be added.
An inspection on the definition in Figure~\ref{fig:modal} shows that such 
new names may be needed only when bound input modalities are present in the modal formula.
More specifically, when instantiating the name quantification ( or ) in 
a definition clause for a bound input modality, such as in the definition clause

we need to consider only cases where  is instantiated to a free name in ,
and where  is instantiated to a new name. For the latter, the particular choice of the new name 
is unimportant, since the satisfiability relation for  is closed under substitution 
with new names (cf. Lemma 3.4. in \cite{milner93tcs}). 
One can thus calculate the number of new names needed based on the number of bound 
input modalities in 

In \cite{milner93tcs}, late bisimulation was characterized by the
sublogic  of  that arises from restricting the
formulas to contain only the propositional connectives and the
following modalities: , , , , , and their duals.  We shall now show a similar 
characterization for open bisimulation.

The following theorem states that by dropping the excluded middle and
changing the quantification of free names from  to ,
we get exactly a characterization of open bisimulation by the encoding
of the sublogic .

\begin{theorem}
\label{thm:ch-open}
Let  and  be two processes.
Then  if and only if
for every -formula ,
it holds that 
if and only if 
,
where  is the list of free names in ,  and .
\end{theorem}


\section{Allowing replication in process expressions}
\label{sec:pi rep}


We now consider an extension to the finite -calculus which will allow
us to represent non-terminating processes. 
There are at least two ways to encode non-terminating processes in the
-calculus; {\em e.g.}, via recursive definitions or
replications \cite{sangiorgi01}. We consider here the latter approach since it leads to
a simpler presentation of the operational semantics. 
To the syntax of the finite -calculus we add the process expression
. The process  can be understood as the infinite
parallel composition of , i.e., .
Thus it is possible to have a process 
that retains a copy of itself after making a transition;
{\em e.g.}, . The operational semantics for one-step
transitions of the -calculus with replication 
is given as the definition clauses Figure~\ref{fig:rep-pi def}, 
adapted to the -tree syntax from the original presentation in \cite{sangiorgi01}. 
We use the same symbol to encode replication in -tree syntax,
{\em i.e.}, .

\begin{figure}

\caption{Definition clauses for the -calculus with replication}
\label{fig:rep-pi def}
\end{figure}

In order to reason about bisimulation of processes involving , we need to move
to a stronger logic which incorporates both induction and co-induction
proof rules. We consider the logic  \cite{tiu04phd}, which is an extension of
 with induction and co-induction proof rules. 
We first need to extend the notion of definitions to include inductive
and co-inductive definitions. 

\begin{definition}
An inductive definition clause is written

where  is a closed term. The symbol  is used to indicate
that the definition is inductive. 
Similarly, a co-inductive definition clause is written

The notion of definition given in Definition~\ref{def:def}
shall be referred to as {\em basic definition}.
An {\em extended definition} is a collection of 
basic, inductive, or co-inductive definition clauses.
\end{definition}
A definition clause can be seen as a fixed point 
equation: in fact, Baldle \& Miller \citeyear{baelde07lpar} provide an
alternative approach to inductive and co-inductive definitions similar
to what is available in the -calculus.
When definitions are seen as fixed points, provability of
, depending on whether  is basic, inductive or co-inductive, 
means that  is, respectively, in a fixed point, the least fixed point, and 
the greatest fixed point of the underlying fixed point equation defining .


Notice that the head of the (co-)inductive definition clauses contains
a predicate with arguments that are only variables and not more
general terms: this restriction simplifies the presentation
of the induction and co-induction inference rules.  Arguments that are more
general terms can
be encoded as explicit equalities in the body of the clause.
We also adopt a higher-order notation in describing the body
of clauses, {\em i.e.}, we use  to mean that  is a
top-level abstraction that has
no free occurrences of the predicate symbol  and the variables .
This notation simplifies the presentation of the (co-)induction
rules: in particular, it simplifies the presentation of predicate
substitutions.

There must be some stratification on the extended definition
so as not to introduce inconsistency into the logic.
For the details of such stratification we refer the interested 
readers to \cite{tiu04phd}. For our current purpose, it should be
sufficient to understand that mutual recursive (co-)inductive definitions are
not allowed, and dependencies through negation are forbidden
as it already is in basic definitions.

Let  be an inductive definition. Its left and
right introduction rules are

where  is the {\em induction invariant}, and it is a closed term 
of the same type as . 
The introduction rules for co-inductively defined predicates are dual
to the inductive ones. In this case, we suppose that  is 
defined by the co-inductive clause .

Here  is a closed term denoting the co-induction invariant
or {\em simulation}. 
Induction rules cannot be applied to co-inductive predicates and
vice versa. The  and  rules, strictly speaking,
are applicable only to basic definitions. But as it is shown
in \cite{tiu04phd}, these rules are derivable for (co-)inductive
definitions: that is, for these definitions,  can be shown to be 
a special case of  and  a special case of .

The definitions in  we have seen so far can be carried over to
 with some minor bureaucratic changes: {\em e.g.}, in the case of bisimulations, 
we now need to indicate explicitly that it is a co-inductive definition.
For instance, the definition of  should now be indicated as 
a co-inductive definition by changing the symbol  with .
We shall now present an example of proving bisimulation using explicit
induction and co-induction rules. We shall not go into details of the technical 
theorems of the adequacy results: these can be found in \cite{tiu04phd}.

\begin{example}
Let  and .
The only action  can make is the silent action  since
the channel  is restricted internally within the process.
It is easy to see that .
That is, the continuation of  is capable of outputting a free name 
or making a silent transition.
Obviously  can make the same  action and results in 
a bisimilar continuation.
Let us try to prove .
The simple proof strategy of unfolding the
 clause via  will not work here since
after the first  on  
(but before the second  on ) 
we arrive at the sequent 

Since  and  still occur in the continuation pair,
it is obvious that this strategy is non terminating. 
We need to use the co-induction proof rules instead.

An informal proof starts by 
finding a bisimulation (a set of pairs of processes)  such that
. 
Let 

Define  to be the symmetric closure of . 
It can be verified that  is a bisimulation set by showing the set is
closed with respect to one-step transitions. To prove this formally
in  we need to represent the set .
We code the set  as the following inductive definition
(we allow ourselves to put general terms in the head of this
definition and to have more than one clause: it is straightforward to
translate this definition to the restricted one give above).
\newcommand\invar[2]{{\hbox{\sl inv}~#1~#2}}

Note that for simplicity of presentation, we assume that we have two
constants of type , namely,  and , in the logic (but we note that
this assumption is not necessary). 
The set of pairs encoded by {\sl inv} can be shown to be symmetric,
i.e., the formula  is provable
inductively (using the same formula as the induction invariant).

To now prove the sequent , we can use 
the  rule with the predicate {\sl inv} as the invariant.  The
premises of the  rule are the two sequents  and 
, where  is the following
large conjunction

The sequent reads, intuitively, that the set defined by {\sl inv} 
is closed under one-step transitions. This is proved by induction on
{\sl inv}. Formally, this is done by applying  to 
, using the invariant 
 
The sequents corresponding to the base cases of the induction are

and the inductive cases are given by 

and their symmetric variants.
The full proof involves a number of cases of which we show one here:
the other cases can be proved similarly.

We consider a case for free output, where we have the sequent (after applying
some right-introduction rules)

to prove. 
Its symmetric case can be proved analogously. 
The sequent (\ref{eq:pi rep}) can be simplified by applying
 to the {\sl inv} predicate, 
followed by an instance of . The resulting sequent is


\begin{figure}

\caption{A derivation in Linc}
\label{fig:pi rep ex1}

where  is

\caption{A derivation in  given in two parts}
\label{fig:pi rep ex2}
\end{figure}

There are three ways in which the one-step transition
in the left-hand side of the sequent (\ref{eq:pi rep}) can be inferred 
(via ), 
{\em i.e.}, either  is  and  is , or
 and  is , or  is  and 
,  is 
for some  and . These three cases correspond to the following sequents.

The proof of the first sequent is given in Figure~\ref{fig:pi rep ex1} and of the
second sequent is given in Figure~\ref{fig:pi rep ex2}. 
The proof for the third sequent is not given but it is easy to see that
it has a similar structure to the proof of the second one.
\end{example}


\section{Automation of proof search}
\label{sec:auto}

The above specifications for one-step transitions, for late, early,
and open bisimulation, and for modal logics are not only declarative
and natural, they can also, in many cases, be turned into effective and
{\em symbolic} implementations by using techniques from the proof
search literature.  In this section we outline high-level aspects of
the proof theory of  that can be directly exploited to
provide implementations of significant parts of this logic: we also
describe how such general aspects can be applied to some of our
-calculus examples.

\subsection{Focused proof search}

Since the cut-elimination theorem holds for , the search for
a proof can be restricted to {\em cut-free proofs}.  It is possible to
significantly constrain cut-free proofs to {\em focused proofs} while
still preserving completeness.  The search for focused proofs has a
simple structure that is organized into two phases.  The {\em
  asynchronous} phase applies only invertible inference rules in any
order and until no additional invertible rules can be applied.  The
{\em synchronous} phase involves the selection of (possibly)
non-invertible inference rule and the hereditary (focused) application
of such inference rules until invertible rules are possible again.
Andreoli \cite{andreoli92jlc} provided such a focused proof system for
linear logic and proved its completeness.  Subsequently, many 
focusing systems for intuitionistic and classical logic have been
developed, {\em cf.} \cite{liang07csl} for a description of several of
them. 
Baelde and Miller \citeyear{baelde07lpar} present a 
focusing proof system for the multiplicative and additive linear
logic (MALL) extended with fixed points and show that that proof
system provides a focusing proof system for a large
subset of .
Focused proof systems are
generally the basis for the automation of logic programming languages
and they generalize the notion of {\em uniform proofs}
\cite{miller91apal}.  

\subsection{Unification}
Unification can be used in the implementation of  proof
search in two different ways.  
One way involves the implementation of the  inference rule
and the other way involves the determination of appropriate terms for
instantiating the 
 quantifier in the  inference rule and the
 quantifier in the  inference rule.  In the
specifications presented here, unification only requires the decidable
and determinate subset of higher-order unification called {\em
higher-order pattern} (or ) unification \cite{miller91jlc}.
This style of unification, which can be described as first-order
unification extended to allow for bound variables and their mobility
within terms, formulas, and proofs, is known to have efficient and practical
unification algorithms that compute most general unifiers whenever
unifiers exist \cite{nipkow93lics,nadathur05iclp}.  The Teyjus implementation
\cite{nadathur99cade,nadathur05tplp} of Prolog provides an
effective implementation of such unification, as does Isabelle
\cite{paulson90abs} and Twelf \cite{pfenning99cade}.

\subsection{Proof search for one-step transitions.}
Computing one-step transitions can be done entirely using a
conventional, higher-order logic programming language, such as
Prolog: since the definition  for one-step
transitions is Horn, we can use Proposition~\ref{prop:nabla forall} to show
that for the purposes of computing one-step transitions, all
occurrences of  in  can be changed to
.  The resulting definition is then a Prolog logic
program for which Teyjus provides an effective implementation.  In particular,
after loading that definition, we would simply ask the query
, where  is the encoding of a particular
-calculus expression and  and  are free
variables.  Standard logic programming interpreters would then
systematically bind 
these two variables to the actions and continuations that  can
make.  Similarly, if the query was , logic
programming search would systematically return all bound actions
(here,  has type ) and corresponding bound
continuations (here,  has type ).

\subsection{Proof search for open bisimulation.}

Theorem proving establishing a bisimulation goal is not done via a
conventional logic programming system like Prolog since such
systems do not implement the -quantifier and the case analysis
and unification of eigenvariables that is required for the 
inference rule.  None-the-less, the implementation of proof search for
open bisimulation is easy to specify using the following key steps.
(Sequents missing from this outline are trivial to address.)  In the
following, we use the quantifier prefix  to denote either
 or  or the empty quantifier prefix.
\begin{enumerate}

\item When searching for a proof of
 apply
right-introduction rules: {\em i.e.}, simply introduce the quantifier
 (if it is non-empty) and then open the definition of
{\sl lbisim}.

\item If the sequent has a formula on its left-hand side, then that
formula is , where  denotes a
particular term where all its non-ground subterms are of type , 
and  and  are terms, possibly containing eigenvariables.  In this
case, select the  inference rule: the premises of this
inference rule will then be either  the empty-set of premises
(which represents the only way that proof search terminates), or
 a set of premises that are all again of the form of one-step
judgments, or 
the premise contains  instead of an atom on the left, in which
case, we must consider the remaining case that follows (after using
the weakening  inference rule).

\item If the sequent has the form
, where  involves a recursive call to {\sl
lbisim} and where  is a closed term, then we must instantiate the
existential quantifier with an appropriate substitution.  Standard
logic programming techniques can be
used to find a substitution for  such that  is
provable (during this search, eigenvariables and locally scoped
variables are treated as constants and  and  denote particular
closed terms).  There might be several ways to prove such a formula
and, as a result, there might be several different substitutions for
.  If one chooses the term  to instantiate , then one proceeds
to prove the sequent
.  
If the sequent has instead the form , then one proceeds in an analogous manner.
\end{enumerate}
Proof search for the first two cases is invertible (no backtracking is
needed for those cases).  On the other hand, the third
case is not invertible and backtracking on possibly all choices of
substitution term  might be necessary to ensure completeness.

\subsection{The Bedwyr model checker}

The various implementation techniques mentioned above---unification of
-terms, backtracking focused proof search, unfolding
definitions---have all been implemented within the Bedwyr model
checking system ~\cite{baelde07cade}, which implements proof search for a
simple fragment \cite{tiu05eshol} of .  The definitions of
one-step transitions and of bisimulation are in this fragment and the
Bedwyr system is a complete implementation of open bisimulation for
the finite -calculus: in particular, it provides a decision
procedure for open-bisimulation.  Bedwyr also implements limited forms
of the modal logic described in Section~\ref{sec:modal}.  It is also
possible to use Bedwyr to explore why two -calculus
processes might not be bisimilar: for example, it easy to define
traces for such processes and then to search for a trace that holds of
one process but not of the other. 


Since Bedwyr is limited to intuitionistic reasoning, it does not
fully implement late bisimulation.  We now speculate briefly on how
one might extend a system like Bedwyr to treat late bisimulation.

\subsection{Proof search for late bisimulation.}
The main difference between doing proof search for open bisimulation
and late bisimulation is that in the latter we need to select and
instantiate formulas from the set  and explore the cases
generated by the resulting  rule. 
For example, consider a sequent of the form , where  is a set of
formulas 
which may have  free.  One way to proceed with the search for a proof
would be to instantiate  twice with the
constants  and .  We would then need to consider proofs of the
sequent  
.
Using the  rule twice, we are left with four sequents to prove:
\begin{enumerate}
\item  which is 
  proved trivially since the equalities are contradictory; 
\item , which is
  equivalent to ;
\item , which is
  equivalent to ; and 
\item .
\end{enumerate}
In this way, the excluded middle can be used with a set of  items
to produce  sequents: one for each member of the set and
one extra sequent to handle all other cases (if there are any).

The main issue for implementing proof search with this specification
of late bisimulation is to determine what instances of the excluded
middle are needed: answering this question would then reduce proof
search to one similar to open bisimulation.  There seems to be two
extreme approaches to take. At one extreme, we can take instances for
all possible names that are present in our process expressions:
determining such instances is simple but might lead to many more cases
to consider than is necessary.  The other extreme would be more lazy:
an instance of the excluded middle is suggested only when there seems
to be a need to consider that instance.  The failure of a  rule
because of a mismatch between an eigenvariable and
a constant would, for example, suggest that excluded middle should be
invoked for that eigenvariable and that constant.  The exact details
of such schemes and their completeness are left for future work.


\section{Related and future work}
\label{sec:related}

There are many papers on topics related to the encoding of the
operational semantics of the -calculus into formal systems.  An
encoding of one-step transitions for the -calculus using Coq was
presented in \cite{despeyroux00ifiptcs} but the problem of computing
bisimulation was not considered.  Honsell, Miculan, and Scagnetto
\cite{honsell01tcs} give a more involved encoding of the
-calculus in Coq and assume that there are an infinite number of
global names.  They then build formal mechanisms to support notions
such as ``freshness'' within a scope, substitution of names,
occurrences of names in expressions, etc.  Gabbay
\cite{gabbay03automath} does something similar but uses the
set theory developed in \cite{gabbay01fac} to help develop his formal
mechanisms.  This formalism is later given a first-order axiomatization by
Pitts~\cite{pitts03ic}, resulting in an extension of first-order logic called 
{\em nominal logic}.  Aspects of nominal reasoning have been incorporated
into the proof assistant Isabelle~\cite{urban05cade} and there has been
some recent work in formalizing the meta theory of the -calculus
in this framework \cite{bengtson07fossacs}.
Hirschkoff \cite{hirschkoff97tphol} also used Coq but
employed deBruijn numbers \cite{debruijn72} instead of explicit names.
In the papers that address bisimulation, formalizing names and their
scopes, occurrences, freshness, and substitution is considerable work.
In our approach, much of this same work is required, of course, but it
is available in rather old technology, particularly, via Church's
Simple Theory of Types (where bindings in terms and formulas were put
on a firm foundation via -terms), Gentzen's sequent calculus,
Huet's unification procedure for -terms \cite{huet75tcs},
etc.  More modern work on proof search in higher-order logics is also
available to make our task easier and more declarative.

The encoding of transitions for the -calculus into logics and type
systems have been studied in a number of previous
works~\cite{honsell98,despeyroux00ifiptcs,honsell01tcs,roeckl01fossacs,bengtson07fossacs}.
Our encoding, presented as a definition in Figure~\ref{late pi def},
has appeared in \cite{miller99surveys,miller03lics}.  The material on
proof automation in Section~\ref{sec:auto} clearly seems related to
{\em symbolic bisimulation} (for example, see
\cite{hennessy95tcs,boreale96ic}) and on using unification and logic
programming techniques to compute symbolic bisimulations (for example,
see \cite{basu01iclp,boreale01icalp}).  Since the technologies used to
describe these other approaches are rather different than what is
described here, a detailed comparison is left for future work.

It is, of course, interesting to consider the general -calculus
where infinite behaviors are allowed (by including  or recursive
definitions).  In such cases, one might be able to still do many
proofs involving bisimulation if the proof system included induction
and co-induction inference rules. We have illustrated with a simple
example in Section~\ref{sec:pi rep} how such a proof might be done.
Inference rules for induction and co-induction appropriate for the 
sequent calculus have been presented 
in \cite{momigliano03types} and a version of these rules that also
involves the  quantifier has been presented in the first
author's PhD thesis \cite{tiu04phd}.  Open bisimulation, however, has not
been studied in this setting. We plan to investigate further how these
stronger proof systems can be used to establish properties about
-calculus expressions with infinite behaviors.

Specifications of operational semantics using a logic should make
it possible to formally prove properties concerning that operational
semantics.  This was the case, for example, with specifications of the
evaluation and typing of simple functional and imperative programming
languages: a number of common theorems (determinacy of evaluation,
subject-reduction, etc) can be naturally inferred using logical
specifications \cite{mcdowell02tocl}.  We plan to investigate using
our logic (also incorporating rules for induction and
co-induction) for formally proving parts of the theory of the
-calculus.  It seems, for example, rather transparent to prove
that open bisimilarity is a congruence in our setting (see
\cite{ziegler05sos} for a more general class of congruence relations).

\section{Conclusion}
\label{sec:conc}

In this paper we presented a meta-logic that allows for declarative specifications of
judgments related to the -calculus.
These specifications are done entirely within the logic and without any
additional side conditions.  The management of name bindings in the
specification of one-step transition, bisimulation, and modal logic is
handled completely by the logic's three levels of binding,
namely, -bindings within terms, the formula-level
binders (quantifiers) , , and , and the
proof-level bindings for eigenvariables and local (generic) contexts.

This paper can be seen as part of a tradition of treating
syntax more abstractly.   The early, formal treatments of syntax by, for
example, Church and G\"odel, formalized terms and formulas as strings.
Eventually, that treatment of syntax was replaced by more abstract
objects such as parse trees: it is on parse trees that most
syntactic descriptions of the -calculus and -calculus
are now given.  Unfortunately, parse trees do not come equipped with
primitive notions of bindings.  To fix that problem, for example,
Prawitz introduced ``discharge functions'' \cite{prawitz65} and de
Bruijn introduced ``nameless dummies'' \cite{debruijn72}.  The move
from parse trees to -trees, along with the use of a logic
able to deal intimately with syntactic abstractions, is another way to
fix this problem.

A significant part of this paper deals with establishing adequacy
results that show a formal connection between the ``standard''
definitions of judgments concerning the -calculus and the
definitions given in logic (see the appendices for the details).
These adequacy results are all 
rather tedious and shallow but seem necessary to ensure that we have
not invented our own problems for which we provide good solutions.  It
would seem, however, that the tediousness nature of the adequacy
results can be
attributed to the large gap between our proof-theory approach and
the ``standard'' approach used to encode the
-calculus: now that some of these basic adequacy results have
been written down, the adequacy results for any additional logical
specifications using -tree syntax should follow more
immediately.

We note that our effort in developing a proof theoretic setting for
the -calculus has led us to find new description for, in
particular, the underlying assumptions on names in open and late
bisimulatons.  This examination has led us to characterize the
differences between open and late bisimulations in a simple and
logical fashion: in particular, as the difference in name
quantification and in the assumption about decidability of name
equality.

\smallskip
\noindent
{\em Acknowledgments.}  We are grateful to the reviewers of earlier
drafts of this paper for their detailed and useful comments.  We also
benefited from support from INRIA through the ``Equipes
Associ{\'e}es'' Slimmer, and from the Australian Research Council
through the Discovery Project ``Proof Theoretical Methods for 
Reasoning about Process Equivalence.''
\par 

\begin{thebibliography}{}

\bibitem[\protect\citeauthoryear{Andreoli}{Andreoli}{1992}]{andreoli92jlc}
{\sc Andreoli, J.-M.} 1992.
\newblock Logic programming with focusing proofs in linear logic.
\newblock {\em J. of Logic and Computation\/}~{\em 2,\/}~3, 297--347.

\bibitem[\protect\citeauthoryear{Baelde, Gacek, Miller, Nadathur, and
  Tiu}{Baelde et~al\mbox{.}}{2007}]{baelde07cade}
{\sc Baelde, D.}, {\sc Gacek, A.}, {\sc Miller, D.}, {\sc Nadathur, G.}, {\sc
  and} {\sc Tiu, A.} 2007.
\newblock The {Bedwyr} system for model checking over syntactic expressions.
\newblock In {\em 21th Conference on Automated Deduction (CADE)},
  {F.~Pfenning}, Ed. Number 4603 in LNAI. Springer, 391--397.

\bibitem[\protect\citeauthoryear{Baelde and Miller}{Baelde and
  Miller}{2007}]{baelde07lpar}
{\sc Baelde, D.} {\sc and} {\sc Miller, D.} 2007.
\newblock Least and greatest fixed points in linear logic.
\newblock In {\em International Conference on Logic for Programming and
  Automated Reasoning (LPAR)}, {N.~Dershowitz} {and} {A.~Voronkov}, Eds. LNCS,
  vol. 4790. 92--106.

\bibitem[\protect\citeauthoryear{Basu, Mukund, Ramakrishnan, Ramakrishnan, and
  Verma}{Basu et~al\mbox{.}}{2001}]{basu01iclp}
{\sc Basu, S.}, {\sc Mukund, M.}, {\sc Ramakrishnan, C.~R.}, {\sc Ramakrishnan,
  I.~V.}, {\sc and} {\sc Verma, R.~M.} 2001.
\newblock Local and symbolic bisimulation using tabled constraint logic
  programming.
\newblock In {\em International Conference on Logic Programming ({ICLP})}.
  LNCS, vol. 2237. Springer, Paphos, Cyprus, 166--180.

\bibitem[\protect\citeauthoryear{Bengtson and Parrow}{Bengtson and
  Parrow}{2007}]{bengtson07fossacs}
{\sc Bengtson, J.} {\sc and} {\sc Parrow, J.} 2007.
\newblock Formalising the -calculus using nominal logic.
\newblock In {\em Proceedings of FOSSACS 2007}. LNCS, vol. 4423. Springer,
  63--77.

\bibitem[\protect\citeauthoryear{Boreale}{Boreale}{2001}]{boreale01icalp}
{\sc Boreale, M.} 2001.
\newblock Symbolic trace analysis of cryptographic protocols.
\newblock In {\em Proceedings of ICALP 2001}. LNCS, vol. 2076. Springer-Verlag,
  667--681.

\bibitem[\protect\citeauthoryear{Boreale and Nicola}{Boreale and
  Nicola}{1996}]{boreale96ic}
{\sc Boreale, M.} {\sc and} {\sc Nicola, R.~D.} 1996.
\newblock A symbolic semantics for the -calculus.
\newblock {\em Information and Computation\/}~{\em 126,\/}~1 (Apr.), 34--52.

\bibitem[\protect\citeauthoryear{Church}{Church}{1940}]{church40}
{\sc Church, A.} 1940.
\newblock A formulation of the simple theory of types.
\newblock {\em J. of Symbolic Logic\/}~{\em 5}, 56--68.

\bibitem[\protect\citeauthoryear{de~Bruijn}{de~Bruijn}{1972}]{debruijn72}
{\sc de~Bruijn, N.~G.} 1972.
\newblock Lambda calculus notation with nameless dummies, a tool for automatic
  formula manipulation, with application to the {Church-Rosser Theorem}.
\newblock {\em Indag. Math.\/}~{\em 34,\/}~5, 381--392.

\bibitem[\protect\citeauthoryear{Despeyroux}{Despeyroux}{2000}]{despeyroux00ifiptcs}
{\sc Despeyroux, J.} 2000.
\newblock A higher-order specification of the -calculus.
\newblock In {\em Proc. of the IFIP International Conference on Theoretical
  Computer Science, IFIP TCS'2000, Sendai, Japan, August 17-19, 2000.}
  425--439.

\bibitem[\protect\citeauthoryear{Eriksson}{Eriksson}{1991}]{eriksson91elp}
{\sc Eriksson, L.-H.} 1991.
\newblock A finitary version of the calculus of partial inductive definitions.
\newblock In {\em Proceedings of the Second International Workshop on
  Extensions to Logic Programming}, {L.-H. Eriksson}, {L.~Halln{\"{a}}s}, {and}
  {P.~Schroeder-Heister}, Eds. LNAI, vol. 596. Springer-Verlag, 89--134.

\bibitem[\protect\citeauthoryear{Gabbay}{Gabbay}{2003}]{gabbay03automath}
{\sc Gabbay, M.~J.} 2003.
\newblock The -calculus in {FM}.
\newblock In {\em Thirty-five years of {A}utomath}, {F.~Kamareddine}, Ed.
  Kluwer, 80--149.

\bibitem[\protect\citeauthoryear{Gabbay and Pitts}{Gabbay and
  Pitts}{2001}]{gabbay01fac}
{\sc Gabbay, M.~J.} {\sc and} {\sc Pitts, A.~M.} 2001.
\newblock A new approach to abstract syntax with variable binding.
\newblock {\em Formal Aspects of Computing\/}~{\em 13}, 341--363.

\bibitem[\protect\citeauthoryear{Gentzen}{Gentzen}{1969}]{gentzen35}
{\sc Gentzen, G.} 1969.
\newblock Investigations into logical deductions.
\newblock In {\em {The Collected Papers of Gerhard Gentzen}}, {M.~E. Szabo},
  Ed. North-Holland, Amsterdam, 68--131.

\bibitem[\protect\citeauthoryear{Girard}{Girard}{1992}]{girard92mail}
{\sc Girard, J.-Y.} 1992.
\newblock A fixpoint theorem in linear logic.
\newblock An email posting to the mailing list linear@cs.stanford.edu.

\bibitem[\protect\citeauthoryear{Halln{\"{a}}s and
  Schroeder-Heister}{Halln{\"{a}}s and Schroeder-Heister}{1991}]{hallnas91jlc}
{\sc Halln{\"{a}}s, L.} {\sc and} {\sc Schroeder-Heister, P.} 1991.
\newblock A proof-theoretic approach to logic programming. {II}. {Programs} as
  definitions.
\newblock {\em J. of Logic and Computation\/}~{\em 1,\/}~5 (Oct.), 635--660.

\bibitem[\protect\citeauthoryear{Hennessy and Lin}{Hennessy and
  Lin}{1995}]{hennessy95tcs}
{\sc Hennessy, M.} {\sc and} {\sc Lin, H.} 1995.
\newblock Symbolic bisimulations.
\newblock {\em Theoretical Computer Science\/}~{\em 138,\/}~2 (Feb.), 353--389.

\bibitem[\protect\citeauthoryear{Hirschkoff}{Hirschkoff}{1997}]{hirschkoff97tphol}
{\sc Hirschkoff, D.} 1997.
\newblock A full formalization of pi-calculus theory in the {Calculus of
  Constructions}.
\newblock In {\em International Conference on Theorem Proving in Higher Order
  Logics (TPHOLs'97)}, {E.~Gunter} {and} {A.~Felty}, Eds. Number 1275 in LNCS.
  Murray Hill, New Jersey, 153--169.

\bibitem[\protect\citeauthoryear{Honsell, Lenisa, Montanari, and
  Pistore}{Honsell et~al\mbox{.}}{1998}]{honsell98}
{\sc Honsell, F.}, {\sc Lenisa, M.}, {\sc Montanari, U.}, {\sc and} {\sc
  Pistore, M.} 1998.
\newblock Final semantics for the -calculus.
\newblock In {\em Proc.~of PROCOMET'98}.

\bibitem[\protect\citeauthoryear{Honsell, Miculan, and Scagnetto}{Honsell
  et~al\mbox{.}}{2001}]{honsell01tcs}
{\sc Honsell, F.}, {\sc Miculan, M.}, {\sc and} {\sc Scagnetto, I.} 2001.
\newblock -calculus in (co)inductive type theories.
\newblock {\em Theoretical Computer Science\/}~{\em 2,\/}~253, 239--285.

\bibitem[\protect\citeauthoryear{Huet}{Huet}{1975}]{huet75tcs}
{\sc Huet, G.} 1975.
\newblock A unification algorithm for typed -calculus.
\newblock {\em Theoretical Computer Science\/}~{\em 1}, 27--57.

\bibitem[\protect\citeauthoryear{Huet and Lang}{Huet and Lang}{1978}]{huet78}
{\sc Huet, G.} {\sc and} {\sc Lang, B.} 1978.
\newblock Proving and applying program transformations expressed with
  second-order patterns.
\newblock {\em Acta Informatica\/}~{\em 11}, 31--55.

\bibitem[\protect\citeauthoryear{Liang and Miller}{Liang and
  Miller}{2007}]{liang07csl}
{\sc Liang, C.} {\sc and} {\sc Miller, D.} 2007.
\newblock Focusing and polarization in intuitionistic logic.
\newblock In {\em CSL 2007: Computer Science Logic}, {J.~Duparc} {and} {T.~A.
  Henzinger}, Eds. LNCS, vol. 4646. Springer, 451--465.
\newblock Extended version to appear in TCS.

\bibitem[\protect\citeauthoryear{McDowell and Miller}{McDowell and
  Miller}{2000}]{mcdowell00tcs}
{\sc McDowell, R.} {\sc and} {\sc Miller, D.} 2000.
\newblock Cut-elimination for a logic with definitions and induction.
\newblock {\em Theoretical Computer Science\/}~{\em 232}, 91--119.

\bibitem[\protect\citeauthoryear{McDowell and Miller}{McDowell and
  Miller}{2002}]{mcdowell02tocl}
{\sc McDowell, R.} {\sc and} {\sc Miller, D.} 2002.
\newblock Reasoning with higher-order abstract syntax in a logical framework.
\newblock {\em ACM Trans.\ on Computational Logic\/}~{\em 3,\/}~1, 80--136.

\bibitem[\protect\citeauthoryear{McDowell, Miller, and Palamidessi}{McDowell
  et~al\mbox{.}}{2003}]{mcdowell03tcs}
{\sc McDowell, R.}, {\sc Miller, D.}, {\sc and} {\sc Palamidessi, C.} 2003.
\newblock Encoding transition systems in sequent calculus.
\newblock {\em Theoretical Computer Science\/}~{\em 294,\/}~3, 411--437.

\bibitem[\protect\citeauthoryear{Miller}{Miller}{1991}]{miller91jlc}
{\sc Miller, D.} 1991.
\newblock A logic programming language with lambda-abstraction, function
  variables, and simple unification.
\newblock {\em J. of Logic and Computation\/}~{\em 1,\/}~4, 497--536.

\bibitem[\protect\citeauthoryear{Miller}{Miller}{1992}]{miller92jsc}
{\sc Miller, D.} 1992.
\newblock Unification under a mixed prefix.
\newblock {\em Journal of Symbolic Computation\/}~{\em 14,\/}~4, 321--358.

\bibitem[\protect\citeauthoryear{Miller}{Miller}{2000}]{miller00cl}
{\sc Miller, D.} 2000.
\newblock Abstract syntax for variable binders: An overview.
\newblock In {\em Computational Logic - {CL} 2000}, {J.~Lloyd} {and} {{et.
  al.}}, Eds. Number 1861 in LNAI. Springer, 239--253.

\bibitem[\protect\citeauthoryear{Miller and Nadathur}{Miller and
  Nadathur}{1986}]{miller86acl}
{\sc Miller, D.} {\sc and} {\sc Nadathur, G.} 1986.
\newblock Some uses of higher-order logic in computational linguistics.
\newblock In {\em Proceedings of the 24th Annual Meeting of the Association for
  Computational Linguistics}. Association for Computational Linguistics,
  Morristown, New Jersey, 247--255.

\bibitem[\protect\citeauthoryear{Miller and Nadathur}{Miller and
  Nadathur}{1987}]{miller87slp}
{\sc Miller, D.} {\sc and} {\sc Nadathur, G.} 1987.
\newblock A logic programming approach to manipulating formulas and programs.
\newblock In {\em IEEE Symposium on Logic Programming}, {S.~Haridi}, Ed. San
  Francisco, 379--388.

\bibitem[\protect\citeauthoryear{Miller, Nadathur, Pfenning, and
  Scedrov}{Miller et~al\mbox{.}}{1991}]{miller91apal}
{\sc Miller, D.}, {\sc Nadathur, G.}, {\sc Pfenning, F.}, {\sc and} {\sc
  Scedrov, A.} 1991.
\newblock Uniform proofs as a foundation for logic programming.
\newblock {\em Annals of Pure and Applied Logic\/}~{\em 51}, 125--157.

\bibitem[\protect\citeauthoryear{Miller and Palamidessi}{Miller and
  Palamidessi}{1999}]{miller99surveys}
{\sc Miller, D.} {\sc and} {\sc Palamidessi, C.} 1999.
\newblock Foundational aspects of syntax.
\newblock {\em ACM Computing Surveys\/}~{\em 31}.

\bibitem[\protect\citeauthoryear{Miller and Tiu}{Miller and
  Tiu}{2003}]{miller03lics}
{\sc Miller, D.} {\sc and} {\sc Tiu, A.} 2003.
\newblock A proof theory for generic judgments: An extended abstract.
\newblock In {\em 18th Symp.\ on Logic in Computer Science}, {P.~Kolaitis}, Ed.
  IEEE, 118--127.

\bibitem[\protect\citeauthoryear{Miller and Tiu}{Miller and
  Tiu}{2005}]{miller05tocl}
{\sc Miller, D.} {\sc and} {\sc Tiu, A.} 2005.
\newblock A proof theory for generic judgments.
\newblock {\em ACM Trans.\ on Computational Logic\/}~{\em 6,\/}~4 (Oct.),
  749--783.

\bibitem[\protect\citeauthoryear{Milner, Parrow, and Walker}{Milner
  et~al\mbox{.}}{1992}]{milner92icII}
{\sc Milner, R.}, {\sc Parrow, J.}, {\sc and} {\sc Walker, D.} 1992.
\newblock A calculus of mobile processes, {Part II}.
\newblock {\em Information and Computation\/}~{\em 100,\/}~1, 41--77.

\bibitem[\protect\citeauthoryear{Milner, Parrow, and Walker}{Milner
  et~al\mbox{.}}{1993}]{milner93tcs}
{\sc Milner, R.}, {\sc Parrow, J.}, {\sc and} {\sc Walker, D.} 1993.
\newblock Modal logics for mobile processes.
\newblock {\em Theoretical Computer Science\/}~{\em 114,\/}~1, 149--171.

\bibitem[\protect\citeauthoryear{Momigliano and Tiu}{Momigliano and
  Tiu}{2003}]{momigliano03types}
{\sc Momigliano, A.} {\sc and} {\sc Tiu, A.} 2003.
\newblock Induction and co-induction in sequent calculus.
\newblock In {\em Post-proceedings of TYPES 2003}, {M.~Coppo}, {S.~Berardi},
  {and} {F.~Damiani}, Eds. Number 3085 in LNCS. 293--308.

\bibitem[\protect\citeauthoryear{Nadathur}{Nadathur}{2005}]{nadathur05tplp}
{\sc Nadathur, G.} 2005.
\newblock A treatment of higher-order features in logic programming.
\newblock {\em Theory and Practice of Logic Programming\/}~{\em 5,\/}~3,
  305--354.

\bibitem[\protect\citeauthoryear{Nadathur and Linnell}{Nadathur and
  Linnell}{2005}]{nadathur05iclp}
{\sc Nadathur, G.} {\sc and} {\sc Linnell, N.} 2005.
\newblock Practical higher-order pattern unification with on-the-fly raising.
\newblock In {\em {ICLP 2005: 21st International Logic Programming
  Conference}}. LNCS, vol. 3668. Springer, Sitges, Spain, 371--386.

\bibitem[\protect\citeauthoryear{Nadathur and Miller}{Nadathur and
  Miller}{1988}]{nadathur88iclp}
{\sc Nadathur, G.} {\sc and} {\sc Miller, D.} 1988.
\newblock An {Overview} of {Prolog}.
\newblock In {\em {Fifth International Logic Programming Conference}}. MIT
  Press, Seattle, 810--827.

\bibitem[\protect\citeauthoryear{Nadathur and Mitchell}{Nadathur and
  Mitchell}{1999}]{nadathur99cade}
{\sc Nadathur, G.} {\sc and} {\sc Mitchell, D.~J.} 1999.
\newblock System description: {Teyjus} --- {A} compiler and abstract machine
  based implementation of {Prolog}.
\newblock In {\em 16th Conference on Automated Deduction (CADE)},
  {H.~Ganzinger}, Ed. Number 1632 in LNAI. Springer, Trento, 287--291.

\bibitem[\protect\citeauthoryear{Nipkow}{Nipkow}{1993}]{nipkow93lics}
{\sc Nipkow, T.} 1993.
\newblock Functional unification of higher-order patterns.
\newblock In {\em Proc.\ 8th {IEEE} Symposium on Logic in Computer Science
  ({LICS} 1993)}, {M.~Vardi}, Ed. IEEE, 64--74.

\bibitem[\protect\citeauthoryear{Paulson}{Paulson}{1986}]{paulson86jlp}
{\sc Paulson, L.~C.} 1986.
\newblock Natural deduction as higher-order resolution.
\newblock {\em Journal of Logic Programming\/}~{\em 3}, 237--258.

\bibitem[\protect\citeauthoryear{Paulson}{Paulson}{1990}]{paulson90abs}
{\sc Paulson, L.~C.} 1990.
\newblock Isabelle: The next 700 theorem provers.
\newblock In {\em Logic and Computer Science}, {P.~Odifreddi}, Ed. Academic
  Press, 361--386.

\bibitem[\protect\citeauthoryear{Pfenning and Elliott}{Pfenning and
  Elliott}{1988}]{pfenning88pldi}
{\sc Pfenning, F.} {\sc and} {\sc Elliott, C.} 1988.
\newblock Higher-order abstract syntax.
\newblock In {\em Proceedings of the {ACM}-{SIGPLAN} Conference on Programming
  Language Design and Implementation}. ACM Press, 199--208.

\bibitem[\protect\citeauthoryear{Pfenning and Sch{\"u}rmann}{Pfenning and
  Sch{\"u}rmann}{1999}]{pfenning99cade}
{\sc Pfenning, F.} {\sc and} {\sc Sch{\"u}rmann, C.} 1999.
\newblock System description: Twelf --- {A} meta-logical framework for
  deductive systems.
\newblock In {\em 16th Conference on Automated Deduction (CADE)},
  {H.~Ganzinger}, Ed. Number 1632 in LNAI. Springer, Trento, 202--206.

\bibitem[\protect\citeauthoryear{Pitts}{Pitts}{2003}]{pitts03ic}
{\sc Pitts, A.~M.} 2003.
\newblock Nominal logic, {A} first order theory of names and binding.
\newblock {\em Information and Computation\/}~{\em 186,\/}~2, 165--193.

\bibitem[\protect\citeauthoryear{Plotkin}{Plotkin}{1981}]{plotkin81}
{\sc Plotkin, G.} 1981.
\newblock A structural approach to operational semantics.
\newblock {DAIMI} {FN}-19, Aarhus University, Aarhus, Denmark. Sept.

\bibitem[\protect\citeauthoryear{Prawitz}{Prawitz}{1965}]{prawitz65}
{\sc Prawitz, D.} 1965.
\newblock {\em Natural Deduction}.
\newblock Almqvist  Wiksell, Uppsala.

\bibitem[\protect\citeauthoryear{R{\"o}ckl, Hirschkoff, and
  Berghofer}{R{\"o}ckl et~al\mbox{.}}{2001}]{roeckl01fossacs}
{\sc R{\"o}ckl, C.}, {\sc Hirschkoff, D.}, {\sc and} {\sc Berghofer, S.} 2001.
\newblock Higher-order abstract syntax with induction in {Isabelle/HOL}:
  Formalizing the pi-calculus and mechanizing the theory of contexts.
\newblock In {\em Proc. FOSSACS'01}, {F.~Honsell} {and} {M.~Miculan}, Eds.
  LNCS, vol. 2030. Springer, 364--378.

\bibitem[\protect\citeauthoryear{Sangiorgi}{Sangiorgi}{1996}]{sangiorgi96acta}
{\sc Sangiorgi, D.} 1996.
\newblock A theory of bisimulation for the -calculus.
\newblock {\em Acta Informatica\/}~{\em 33,\/}~1, 69--97.

\bibitem[\protect\citeauthoryear{Sangiorgi and Walker}{Sangiorgi and
  Walker}{2001}]{sangiorgi01}
{\sc Sangiorgi, D.} {\sc and} {\sc Walker, D.} 2001.
\newblock {\em -Calculus: {A} Theory of Mobile Processes}.
\newblock Cambridge University Press.

\bibitem[\protect\citeauthoryear{Schroeder-Heister}{Schroeder-Heister}{1993}]{schroeder-heister93lics}
{\sc Schroeder-Heister, P.} 1993.
\newblock Rules of definitional reflection.
\newblock In {\em Eighth {Annual Symposium on Logic in Computer Science}},
  {M.~Vardi}, Ed. IEEE Computer Society Press, IEEE, 222--232.

\bibitem[\protect\citeauthoryear{St{\"a}rk}{St{\"a}rk}{1994}]{staerk92jfcs}
{\sc St{\"a}rk, R.~F.} 1994.
\newblock Cut-property and negation as failure.
\newblock {\em International Journal of Foundations of Computer Science\/}~{\em
  5,\/}~2, 129--164.

\bibitem[\protect\citeauthoryear{Tiu}{Tiu}{2004}]{tiu04phd}
{\sc Tiu, A.} 2004.
\newblock A logical framework for reasoning about logical specifications.
\newblock Ph.D. thesis, Pennsylvania State University.

\bibitem[\protect\citeauthoryear{Tiu}{Tiu}{2005}]{tiu05concur}
{\sc Tiu, A.} 2005.
\newblock Model checking for -calculus using proof search.
\newblock In {\em CONCUR}, {M.~Abadi} {and} {L.~de~Alfaro}, Eds. LNCS, vol.
  3653. Springer, 36--50.

\bibitem[\protect\citeauthoryear{Tiu and Miller}{Tiu and
  Miller}{2004}]{tiu04fguc}
{\sc Tiu, A.} {\sc and} {\sc Miller, D.} 2004.
\newblock A proof search specification of the -calculus.
\newblock In {\em 3rd Workshop on the Foundations of Global Ubiquitous
  Computing}. ENTCS, vol. 138. 79--101.

\bibitem[\protect\citeauthoryear{Tiu, Nadathur, and Miller}{Tiu
  et~al\mbox{.}}{2005}]{tiu05eshol}
{\sc Tiu, A.}, {\sc Nadathur, G.}, {\sc and} {\sc Miller, D.} 2005.
\newblock Mixing finite success and finite failure in an automated prover.
\newblock In {\em Empirically Successful Automated Reasoning in Higher-Order
  Logics (ESHOL'05)}. 79--98.

\bibitem[\protect\citeauthoryear{Urban and Tasson}{Urban and
  Tasson}{2005}]{urban05cade}
{\sc Urban, C.} {\sc and} {\sc Tasson, C.} 2005.
\newblock Nominal techniques in {I}sabelle/{HOL}.
\newblock In {\em 20th Conference on Automated Deduction (CADE)},
  {R.~Nieuwenhuis}, Ed. LNCS, vol. 3632. Springer, 38--53.

\bibitem[\protect\citeauthoryear{Ziegler, Miller, and Palamidessi}{Ziegler
  et~al\mbox{.}}{2005}]{ziegler05sos}
{\sc Ziegler, A.}, {\sc Miller, D.}, {\sc and} {\sc Palamidessi, C.} 2005.
\newblock A congruence format for name-passing calculi.
\newblock In {\em Structural Operational Semantics (SOS'05)}. Electronic Notes
  in Theoretical Computer Science. Elsevier Science B.V., Lisbon, Portugal,
  169--189.

\end{thebibliography}

\newpage
\appendix
 
\def\onef{\hbox{\sl one}_f}
\def\oneb{\hbox{\sl one}_b}
\def\pidef{{\bf D}_\pi}
\def\defrule{\mbox{\it def}}


\section{Properties of one-step transitions}

To prove the adequacy results for the encodings of bisimulation and 
modal logics, we shall consider 
some derived rules which allow us to enumerate all possible next states
from a given process. 
In the following, we use the notation  to denote the type
, and we write 
to denote  for some  Due to space limits, some results
in this section are stated without proofs, but they can be found
in the electronic appendix of the paper.


\begin{definition}
The judgments  and
 are 
{\em higher-order patterned judgments}, or patterned judgments for short, if
\begin{enumerate}
\item every occurrence of the free variables in the judgment is applied
to distinct names, which are either in  or bound by -abstractions, \ie,
, where  or it is bound by some
-abstraction, and  are pairwise distinct,
\item the only occurrences of free variables in  are those of type
 where , and the only occurrences of 
free variables in  are those of type 
 or ,
\item and  is of the form  for some variable  
\end{enumerate}
The process term  in the transition predicate  and 
 is called a {\em primary} process term. 
The notion of patterned judgments extends to non-atomic judgments,
which are defined inductively as follows: 
\begin{itemize}
\item  is a patterned judgment,
\item if  and  are patterned judgments
such that both judgments have no free variables in common which are
of type   then  is a patterned judgment, 
\item if  is a patterned judgment, then 
 is a patterned judgment, 
\item and if  is a patterned judgment
then  is a patterned judgment, provided that 
 is of type  or , and
 is not free in . 
\end{itemize}
Two patterned judgments  and  are {\em -compatible}
if they do not have variables in common which are of type 
\end{definition}
The restrictions on the occurences of free variables in 
patterned judgments are similar to the restrictions used in higher-order
pattern unification. This is to ensure that proof search for patterned judgments 
involves only higher-order pattern unification. 


Let  be a substitution and let  be a signature.
We write  if for every  of type ,
we have  
Two signatures  and  are said to be compatible
if whenever  and , 
 implies 
Given two signature-and-substitution pairs 
 and  such that  and 
are compatible, and  and , 
we write  to denote the pair
 
This definition of composition extends straightforwardly
to composition between a pair and a set or a list of pairs. 

Let us call a  signature-substitution pair  a {\em solution}
for a patterned judgment  if  and 
 is provable. 
In proving the adequacy of the encoding of bisimulation and
modal logics for the  calculus, we often want to find
all possible solutions to a given transition relation, which
corresponds to enumerating all possible continuations of
a given process. 
For this purpose, we define a construction of ``open'' derivation 
trees for a given list of patterned judgments . Open derivation trees 
are trees made of nodes which are instances of certain inference rules. 
This construction gives us a set of derivation trees for the 
sequent , following a certain order of rule applications. 
As we shall see, the construction of the trees basically amounts to 
application of left-introduction rules to . We are interested 
in collecting all the substitutions generated by the  rule
in these trees, which we will show to correspond 
to the solutions for the patterned judgments in 

\begin{definition}
\label{def:patterned-judgment}
Let  be a list of patterned judgments such that its elements are
pairwise -compatible, and let  be a pair 
such that , and that the free variables of  are in 
An {\em open inference rule} is an inference on triples of the form
 where  is a signature,  is a list of patterned
judgments and  is a substitution such that 
We will use the notation  to denote such a triple.
{\em Open derivation trees} are derivations constructed using 
the following open inference rules:



In the -rule, the eigenvariable  is new, \ie, it is not in 
In the -rule, we require that for every ,
the judgments  are patterned judgments. 
That is, we restrict the CSU's to those that preserves the pattern
restrictions on judgments.
The instances of the -rule in an open derivation are 
called {\em open leaves} of the derivation. 
Given an open derivation , we denote with  the set of 
signature-substitution pairs in the open leaves of  
\end{definition}

\begin{definition}
The measure of a patterned judgment ,
written , is the
number of process constructors occuring in the primary terms in 
The measure of a list of judgments  is the multiset of
measures of the judgments in 
\end{definition}


\begin{lemma}
\label{lm:open-drv-exists}
Let  be a list of patterned judgments such that its elements are
pairwise -compatible, and whose variables
are in a given signature . Let  be a substitution such that
. Then there exists an open derivation  of  
\end{lemma}


\begin{lemma}
\label{lm:solution-comp}
Let , ,  and  be signatures and substitutions
such that  and . Let  be a list of
pairwise -compatible patterned jugdments such that all its free variables are in 
If there exists an open derivation  of 
, then there exists an open 
derivation  of  of the same height such that 

and vice versa.
\end{lemma}

The following lemma states that the open leaves in an open derivation are solutions
of the patterned judgments on the root of the derivation tree. This can be proved
by induction on the height of derivation and case analysis on the definition clauses
of one-step transitions.

\begin{lemma}
\label{lm:open-drv-sound}
Let  be a list of patterned judgments such that its elements are pairwise
-compatible and whose variables are in a given signature . 
Let  be an open derivation of  
Then for every element  and every pair
, the sequent
 is provable.
\end{lemma}

We are now ready to define the following derived rules.
The rule  enumerates all possible free-actions that a process can 
perform. Given a patterned judgment  
and an open derivation  of ,
the  rule, applied to this judgment, is as follows:

The corresponding rule for bound input or bound output transition is defined 
analogously, \ie,

where  is an open derivation of 
Since open inference rules are essentially invertible left-rules of ,
these derived rules are sound and invertible.
\begin{lemma}
The rules  and  are invertible and derivable in .
\end{lemma}

We can now prove Proposition~\ref{prop:neg one step}.


\begin{proof}
Suppose that  does not hold in the -calculus.
We show that the sequent  is 
derivable in  
This is equivalent to proving the sequent

We apply either  or  to the sequent (bottom-up), 
depending on whether  is a free or a bound action. 
In both cases, if the premise of the  or  is 
empty, then we are done. Otherwise, there exists a substitution
 such that 
is derivable in . Since the transition judgment is ground, this would
mean that  is derivable, and
by Proposition~\ref{prop:one step}, the transition  holds
in the -calculus, contradicting our assumption.

Conversely, suppose that 
is derivable in  Then  cannot be a transition
in the -calculus, for otherwise, we would have 
by Proposition~\ref{prop:one step}, and by cut, we would have a proof of , which
is impossible. 
\end{proof}



\section{Adequacy of the specifications of bisimulations}

We need some auxiliary lemmas that concern the structures of cut free proofs.
The next three lemmas can be proved by simple permutations of inference rules. 

\begin{lemma}
\label{lm:right-first}
Let  be a cut-free derivation of ,  where  
contains a non-equality atomic formula and 
every judgment in  is in one of the following forms:


for some  and distinct names  in .
Then there exists a derivation of the sequent which ends with a right-introduction rule on 
\end{lemma}

\begin{lemma}
\label{lm:lbisim-inv}
The  rule, applied to , for any  and , is
invertible. 
\end{lemma}

\begin{lemma}
\label{lm:ebisim-inv}
The  rule, applied to , for any  and , is
invertible. 
\end{lemma}

\subsection{Adequacy of the specification of late bisimulation}

In the following, we use the notation
 to abbreviate the conjunction

With a slight abuse of notation, we shall write ,
where  is a finite set of formula  , to mean 
, and we shall write  to mean the formula


\begin{lemma}
\label{lm:lbisim-complete}
Let  and  be two late-bisimilar finite -processes and let
 be the free names in  and 
Then for some finite set , we have

\end{lemma}
\begin{proof}
We construct a proof of formula (\ref{eq:lbisim-completeness}) by induction on the size of
 and  \ie, the number of action prefixes in  and  
It can be easily shown that the number of prefixes in a process is reduced
by transitions, for finite processes. 
By applying the introduction rules
for ,  and unfolding the definition of  (bottom up) 
to the formula (\ref{eq:lbisim-completeness}), we get the following three sequents:
\begin{enumerate}
\item 
\item 
\item 
\end{enumerate}
and their symmetric counterparts (obtained by exchanging the role of  and ).
The set  is left unspecified above, since it will be constructed by induction
hypothesis (in the base case, where both  and  are deadlocked processes, 
define  to be the empty set). 
We show here how to construct proofs for these three sequents; their symmetric counterparts can be
proved similarly. In all these three cases, we apply either the  rule (for sequent 1) 
or the  rule (for sequent 2 and 3). If this application of  (or )
results in two distinct name-variables, say  and , to be identified, then
the sequent is proved by using the assumption  Therefore the only 
interesting cases are when the name-variables  are instantiated to 
distinct name-variables, say, . In the following we assume
that the substitution in the premises of  or  are non-trivial,
meaning that they do not violate the assumption on name-distinction above.
\begin{description}
\item[Sequent 1] In this case, after applying the  rule bottom up
and discharging the trivial premises, we need to prove, 
for each  associated with the rule, the sequent

for some signature  We give a top-down construction of a derivation of this sequent as follows. 
By Lemma~\ref{lm:open-drv-sound}, we know that 

Since  are the only free names in , we can show by
induction on proofs that  in the sequent is redundant and can be removed,
thus 

By the adequacy of one-step transition (Proposition~\ref{prop:one step}),
we have
 Notice that  is a renaming of , since
 are pairwise distinct. We recall that both one-step
transitions and (late) bisimulation are closed under injective renaming 
(see, \eg, \cite{milner92icII}). Therefore, there exist  and  such that
, where  and  are obtained from  and , respectively,
under the same injective renaming. Since  and  are bisimilar, there exists
 such that , hence, by injective renaming and the adequacy
result for one-step transitions, the sequent 
 is provable. It remains to show
that 

By induction hypothesis (note that the size of  is smaller
than ), we have 

where  is a subset of 
We can weaken the formula with extra variables and assumptions to get

Now since the  and  rules are invertible, this means 

Now define  to be  and apply a renaming
substitution which maps each  to , we get a derivation of

Since provability is closed under weakening of signature, we have

and together with provability of 
, we get 

Finally, applying an  to this sequent, we get


\item[Sequent 2.]
In this case, we need to prove the sequent

for each non-trivial  in the premises of  rule. 
By the same reasoning as in the previous case, we obtain, for every transition

where  another transition

such that for all name 

It is enough to consider +1 cases for , \ie, those in which
 is one of  and another where  is a new name,
say 
By induction hypothesis, we have, for each , a provable formula


and a provable formula :

Let  be the set

Then the sequent  is proved, in a bottom-up fashion, by instantiating  to ,
followed by an -rule, resulting in the sequents:


The first sequent is provable following the adequacy of one-step transition.
For the second sequent, we apply the -rule to get the sequent

We then do a case analysis on the name , using the assumption
 in  
Let  and let 
We consider  instantiations, each instantiation compares 
with , for  We thus get the following sequents:

Here  denotes the set  and
 denotes the set 
Provability of these sequents follow from provability of 

\item[Sequent 3] In this case, we need to prove the sequent

for each non-trivial  in the premises of  rule. As in the previous case, we obtain
 and  such that

and

where  We assume, without loss of generality, that  is fresh.
By the induction hypothesis,  and 

Now apply Proposition~\ref{prop:forall nabla} to replace  with ,

And since  distributes over all propositional connectives, we also have

Let .
Now, since the right-introduction rules for ,  and  are all invertible,
we have that the sequent

is provable. It can be easily checked that the following sequents are provable:

By applying the cut rules to these sequents and sequent  above, we
obtain

Provability of sequent  then follows from provability of sequent  above
and the adequacy of the one-step transition (\ie, by instantiating 
with ).\qed
\end{description}
\end{proof}

The following lemma shows that {\em lbisim} is symmetric. Its proof is
straightforward by induction on derivations. 

\begin{lemma}
\label{lm:lbisim-sym}
Let  and  be two -processes and let  be the
list of all free names in  and .
If , for
some , then 

\end{lemma}


\subsection{Proof for Theorem~\ref{thm:lbisim} (adequacy of late bisimulation specification)}

{\em Soundness.} 
We define a set  as

and show that  is a bisimulation, \ie, it is symmetric and 
closed with respect to the conditions 1, 2 and 3 in Definition~\ref{def:lbisim}.
The symmetry of  follows from Lemma~\ref{lm:lbisim-sym}.


Suppose that , that is, 
 for some . 
Since  on  is invertible (Lemma~\ref{lm:lbisim-inv}), and since
, ,  and  are also invertible, there is a proof of the formula that ends 
with applications of these invertible rules. From this and the definition of , 
we can infer that provability of 
implies provability of six other sequents, three of which are given 
in the following (the other three are symmetric counterparts of these):

By examing the structure of proofs of these three sequents, we show 
that  is closed under all possible transitions from  and 
We examine the three cases in Definition~\ref{def:lbisim}:

\noindent (1) Suppose  for some free action  
Since , by the adequacy result for one-step transitions,
we have that  is derivable.
Let . Applying  to the derivation
of sequent , we get 

By a cut between  and this sequent,
we obtain a derivation of 

By Lemma~\ref{lm:right-first}, we know that there exists a derivation of this sequent
which ends with a right-rule, hence, there exists a process  such that

and

It is easy to show that  plays no part in the proof of the first sequent,
so it can be removed from the sequent. Hence by the adequacy of one-step transitions,
we have . Provability of the second sequent implies
that  is in the set .  Thus
 is indeed closed under the -transition.

\noindent(2) Suppose that 
Applying a similar argument as in the previous case to sequent  with
substitution ,
we obtain a provable sequent 

Again, as in the previous case, using Lemma~\ref{lm:right-first}, we can show that
 for some process  such that

This implies that 

are all provable.
The formula  is obtained from  by instantiating  with one of 
The formula  is obtained from  as follows:
Since 

where  is not free in , are theorems of , 
we can enlarge the scope of  in  to the outermost level:
hence, we have that 
is provable. Now apply Proposition~\ref{prop:forall nabla} to turn  into , then distribute
the  over the implication  and conjunction , and we have 

It remains to show that for every name , the pair
 is in  There are two cases to consider:
The case where  is among  follows straightforwardly from ,
the other case, where  is a new name, follows from 

\noindent(3) Suppose  Using the same argument as in the previous case,
we can show that there exists a process  such that 
and such that

The latter entails that , as required. \qed



\subsection{Completeness} We are given  and
we need to show that  where 
 and  includes all the free names in
 and  From Lemma~\ref{lm:lbisim-complete} we have that 

for some . By Proposition~\ref{prop:forall nabla},
we can turn all the  into , hence

Since  distributes over all propositional connectives, we have

Now,  is a theorem of  (since any
two distinct -quantified names are not equal), therefore by modus ponens
we have

Let , then we have 
as required.
\qed


\subsection{Adequacy of the specification of early bisimulation}

The proof for the adequacy of the specification of early bisimulation follows a 
similar outline as that of late bisimulation. The proof is rather tedious and is not
enlightening. We therefore omit the proof and refer interested readers to
the electronic appendix of the paper for more details.

\subsection{Adequacy of the specification of open bisimulation}

{\em Proof of Lemma~\ref{lm:prefix}: }
The proof proceeds by induction on the length of the quantifier prefix 
At each stage of the induction, we construct a quantifier prefix 
such that  and  corresponds to
the -distinction.
In the base case, where the quantifier prefix  is empty, the quantifier
 is also the empty prefix. In this case we have
, therefore  holds trivially.
There are the following two inductive cases.

\noindent (1) Suppose 
Let  be the distinction that corresponds to 
Note that by definition, we have
.
Let  be the substitution  with domain restricted to 
Since  respects , obviously  respects  and 
 for all  By induction hypothesis, we have
a proof of the formula
 
for some quantifier prefix  such that
 is the -distinction.
Note that since  is not in the domain of , 
we have 
Let  Since  is distinct from all other free names in
, we can rename  with , thus, 

But  is exactly . Let  be the
prefix  It then follows that 

Moreover,  can be easily shown to be the -distinction.

\noindent(2) Suppose 
Note that in this case, the -distinction and
-distinction co-incide, \ie, both are the same
distinction  Moreover, 
Let  be the substitution  restricted to the domain

By induction hypothesis, we have that 
,
for some quantifier prefix  
such that  corresponds to 
Note that , because 
There are two cases to consider when constructing 
The first case is when  is identified, by , with
some name in  In this case, by the property of 
universal quantification, we have that 
.
In this case, we let 
Note that  is the same as  in this case.
Therefore  is the -distinction. 
For the second case, we have that  is instantiated by 
to a new name, say . 
Then following the same argument as the case with , we have that
.
In this case, we let 
Note that in this case the -distinction also coincides
with -distinction, \ie, both are the same set
 \qed


In the proof of soundness of open bisimulation to follow, we make use of
a property of the structure of proofs of certain sequents. 
The following three lemmas state some meta-level properties of .
Their proofs are easy and are omited.

\begin{lemma}
\label{lm:distinction}
Suppose the sequent  is provable, where  is an existential
judgment and  is a set of inequality between distinct terms, \ie, every element of
 is of the form , for some ,  and 
Then there exists a proof of the sequent ending with  applied to 
\end{lemma}

\begin{lemma}
\label{lm:context}
For any positive formula context ,  
\end{lemma}

\begin{lemma}
\label{lm:modus ponens}
Let  be a quantifier prefix. 
If  and 
 are provable 
then  is provable.
\end{lemma}


\begin{lemma}
\label{lm:nabla distinction}
Let  be a conjunction of inequalities between terms.
If , where  is not free in , 
then  .
\end{lemma}


The following lemma is a simple corollary of Proposition~\ref{prop:one step}
and Proposition~\ref{prop:nabla forall}.
\begin{lemma}
\label{lm:mixed prefix one step}
 if and only if 
is provable, where  is a quantifier prefix and  are the free names of 
\end{lemma}

To prove soundness of open bisimulation specification, we define 
a family of sets  in the following, and show that it is indeed an open
bisimulation.

Suppose  That is, 

Let  be the distinction that corresponds to the prefix 
We have to show that for every name substitution  which respects ,
the set  is closed under conditions 1, 2, and 3 in Definition~\ref{def:obisim}.
Since  respects , it also respects  (since  is a subset of ).
Therefore, it follows from Lemma~\ref{lm:prefix} that there exists a prefix 
such that  is the -distinction, and 
.
By the invertibility of  on  and the right-introduction rules 
for , ,  and , we can infer that provability of the
above formula implies provability of six other formulas, three of which
are given in the following (the other three are symmetric variants of these formulas):

Using provability of these formulas, we show that  is closed under
free actions, bound input actions and bound output actions.

\begin{itemize}
\item Suppose  where  is a free action. 
By Lemma~\ref{lm:mixed prefix one step}, we have that 

From formula  and Lemma~\ref{lm:context}, we have that

Applying Lemma~\ref{lm:modus ponens} to formula (\ref{eq:obisim1}) and (\ref{eq:obisim2}) above,
we have that 

The latter implies, by the invertibility of the right rules for  and ,
provability of the sequent

where  are the eigenvariables corresponding to the universally quantified variables in 
(with appropriate raising) and  corresponds to the -quantified variables
in the same prefix. The terms , ,  and  are obtained from, respectively,  
, ,  and  by replacing their free names with their raised counterparts.
Note that since  respects , the inequality in  are those that relate
distinct terms, hence, by Lemma~\ref{lm:distinction}, provability of the above sequent implies
the existence of a term  such that 

and

It can be shown by induction on the height of derivations that  in the first sequent can
be removed, hence we have that

Applying the appropriate introduction rules to this sequent (top down), we 
``unraise'' the variables in  and obtain 

where  corresponds to  By Lemma~\ref{lm:mixed prefix one step}, this means that 

It remains to show that  This is obtained from the sequent
(\ref{eq:obisim4}) above as follows. 
We apply the introduction rules for quantifiers and implication (top down) to sequent (\ref{eq:obisim4}), 
hence unraising the variables in  and obtain the provable formula

from which it follows that 

\item Suppose 
As in the previous case, using Lemma~\ref{lm:mixed prefix one step}, Lemma~\ref{lm:context}, 
Lemma~\ref{lm:modus ponens} and formula 
we can show that 

From this formula, we can show that there exists  such that ,
therefore , and that 

We need to show that for a fresh name ,  
From provability of formula (\ref{eq:obisim5}), and the fact that
 we obtain

Since the -distinction is the same as -distinction,
the overal distinction encoded in the above formula is , therefore, by definition
of , we have 
 

\item Suppose  This case is similar to the bound input
case. Applying the same arguments shows that there exists a process 
such that  and 

We have to show that, for a fresh , 
 where 
Note that the free names of ,  and  are all in  by definition.
From formula (\ref{eq:obisim6}) and Lemma~\ref{lm:nabla distinction}, we have that

Notice that the -distinction is 
, and since  is the free names of , 
and , the overall distinction encoded by the above formula is exactly
 hence  as required. \qed
\end{itemize}


The proof of Theorem~\ref{thm:open bisim complete}
is analogous to the completeness proof for Theorem~\ref{thm:lbisim}.
Suppose  and  are open -bisimilar. We construct a derivation of
the formula 

by induction on the number of action prefixes in  and  
By applying the introduction rules
for ,  and unfolding the definition of  (bottom up) 
to the formula (\ref{eq:obisim-completeness}), we get the following sequents:
\begin{enumerate}
\item 
\item 
\item 
\end{enumerate}
and their symmetric counterparts. 
We show here how to construct proofs for these three sequents; the rest can be
proved similarly. In all these three cases, we apply either the  rule (for sequent 1) 
or the  rule (for sequent 2 and 3). If this application of  (or )
results in two distinct name-variables, say  and , in  to be identified, then
the sequent is proved by using the assumption  in . Therefore the only 
interesting cases are when the instantiations of name-variables  respect the
distinction . 
In the following we assume the names  are instantiated to 
 and the distinction  is respected. 
Note that  may be smaller than , depending on , \ie, it may allow
some names to be identified. 

\begin{description}
\item[Sequent 1] In this case, after applying the  rule bottom up
and discharging the trivial premises (\ie, those that violates the distinction ), 
we need to prove, for each  associated with the rule, the sequent

for some signature   
By Lemma~\ref{lm:open-drv-sound}, we know that 
 is provable.
Since  are the only free names in , we can show by
induction on proofs that  in the sequent is redundant and can be removed,
thus the sequent
 is also provable.
By the adequacy of one-step transition (Proposition~\ref{prop:one step})
and Proposition~\ref{prop:nabla forall}, we have
 for some free action  and 
where  and 
Let  be  with domain restricted to 
Obviously,  respects  and 
Since  and  are open -bisimilar, we have that
there exists  such that 
and  hence by induction hypothesis, we have that

Provability of sequent (\ref{eq: open-comp1}) follows from these facts,
by instantiating  with 

\item[Sequent 2.]
In this case, we need to prove the sequent

for each non-trivial  in the premises of  rule. 
By the same reasoning as in the previous case, we obtain, for every transition

where  another transition

such that (we assume w.l.o.g. that  is fresh)

The former implies that  is derivable, and the latter
implies, by induction hypothesis, that 

is derivable. 
As in the previous case, from these two facts, we can prove the sequent (\ref{eq: open-comp3})
by instantiating  with .


\item[Sequent 3] In this case, we need to prove the sequent

for each non-trivial  in the premises of  rule. As in the previous case, we obtain
 and  such that
 and 
where  We assume, without loss of generality, that  is fresh, therefore
since , by definition we have that 
where 
Note that the free names of ,  and  are exactly
, so 
Thus by induction hypothesis, the formula

Now apply Proposition~\ref{prop:forall nabla} to replace  with ,

And since  distributes over all propositional connectives, we also have

It can be shown that  is provable, 
since the inequalities between  and  trivially true. 
Therefore we have that

Now in order to prove sequent (\ref{eq: open-comp4}), we instantiate
 with , and the rest of the proof proceeds as in the previous case,
\ie, with the help of formula (\ref{eq: open-comp5}).\qed
\end{description}


\subsection{ ``Early'' open bisimulation}

The proof of Theorem~\ref{thm:open-early-bisim} is by induction on the
number of input prefixes in  and  
We prove a more general result: 
if and only if , for any 
quantifier prefix 
By Lemma~\ref{lm:lbisim-inv} and Lemma~\ref{lm:ebisim-inv}, and the invertibility of  and 
rules, we know that if 
and , then their unfolded instances
are also provable. We show that one can construct a derivation for one instance
from the other. The non-trivial case is when the bound input transition is 
involved. That is, given a derivation of

we can construct a derivation of

and vice versa. Note that we cannot do any analysis on the universally quantified
name  in both formulas, since we do not have any assumptions on names
(\eg, the excluded middle on names as in the adequacy theorem for late bisimulation).
It is then easy to check that the choice of  in both cases is independent of
the name , and their correspondence follows straightforwardly from the induction
hypothesis.
\qed

\section{Adequacy of the specifications of modal logics}


The completeness proof of the modal logics specification shares similar structures
with the completeness proofs for specifications of bisimulation. 
In particular, we use an analog of Lemma~\ref{lm:lbisim-complete}, given in the following. 
\begin{lemma}
\label{lm:modal-complete}
Let  be a process and  an assertion such that 
Then 

for some  and some names 
such that 
\end{lemma}
The proof of lemma proceeds by induction on the size of . The crucial
step is when its interpretation in  contains universal quantification
over names, \eg, when . In this case, we again
use the same technique as in the proof of Lemma~\ref{lm:lbisim-complete}, \ie,
using the excluded middle assumptions on names to enumerate all possible
instances of the judgments. A more detailed proof can be found in the electronic
appendix of this paper.


\subsection{Proof of Theorem~\ref{thm:modal adequacy} (Adequacy of the
modal logic encoding)}

First consider proving the soundness part of this theorem.
Suppose we have a derivation  of 
We want to show that . 
This is proved by induction on the size of . The proof also uses the property
of invertible rules and the fact that applications of the excluded middles in 
in deriving the sequent can be permuted up over all the right introduction rules.
The latter is a consequence of Lemma~\ref{lm:right-first}.
We look at a couple of interesting cases involving bound input and bound output.

\begin{description}

\item[out:] Suppose  is . We need to show that for every
 such that , we have  
(By -conversion we can assume without loss of generality that 
 is not free in  and .) Note that here the occurrence of  in  is bound 
in the transition judgment .
By Lemma~\ref{lm:right-first} and the invertibility of certain inference rules, we can
show that provability of 
implies the existence of a derivation  of 

for some eigenvariable . 
By the adequacy of one-step transitions, we have that 
.
Let  be the substitution 
Applying  to  we get the derivation  of

By cutting this derivation with the one-step transition judgment above, we obtain
a derivation of 

Hence by induction hypothesis, we have that .

\item[in:] Suppose  is . We show that there exists
a process  such that  and
for all name , . It is enough to consider
the case where  is a name in  and the case where 
is a new name not in . By Lemma~\ref{lm:right-first} and the invertibility
of some inference rules, we can show that provability of 

implies the existence of two derivations  and , of the sequents

and 
,
respectively, for some closed term .

By the adequacy result in Proposition~\ref{prop:one step},
there exists a process  such that  and 
By Proposition~\ref{prop:subst}, we can instantiate  with any of the free names occurring
in  or  (since they are all in the list ), and hence for any name 
by induction hypothesis we get . The case where  is a new name
is dealt with as follows. Without loss of generality we assume that  (since we can always
choose  to be sufficiently fresh).  
From  it follows that 
Using the  theorems

where  is not free in , we can move the  quantification in 
 to the outermost level and get
the provable formula 
.
We then apply Proposition~\ref{prop:forall nabla}, to turn  into , thus obtaining
a derivation of 

and by distributing  over , we get

We can now apply the induction hypothesis to get 
\end{description}

Next we consider proving the completeness part of Theorem~\ref{thm:modal adequacy}.
Given , we would like to show that 
 is provable.
By Lemma~\ref{lm:modal-complete}, there are  and  such that
 
Let  and let 
By Proposition~\ref{prop:forall nabla}, we have a derivation of 

By distributing the 's over implication and conjunction we obtain

But since  is provable, by cut we obtain
a derivation of 



\section{Characterisation of open bisimulation}

\begin{lemma}
\label{lm:ch-open-sound}
Let  and  be two processes. 
If for all , 
 if and only if , where , 
then  where  is the -distinction.
\end{lemma}
\begin{proof}
Let  be the following family of relations 

We then show that  is an open bisimulation.  is obviously symmetric, so it remains
to show that it is closed under one-step transitions. 
We show here a case involving bound output; 
the rest are treated analogously.

Suppose . Then we have that for all , 
 iff ,
for some prefix 
Let  be a substitution that respects . Suppose 
 We need to show that there exists a 
such that  and 
where  (Here we
assume w.l.o.g.\ that 
 is chosen to be sufficiently fresh.)
Suppose  identifies the following pairs of names in  and :
, and suppose that 
Then by the definition of :

if and only if for all ,



Note that the statement cannot hold vacuously, since for at least
one instance of , \ie, , both judgments must be true.
By analysis on the (supposed) cut-free proofs of both judgments, for any , 
the above statement reduces to

for some prefix  such that -distinction
is the result of applying  to the -distinction.

Now let  be the set of all  such that
 and suppose that for all ,
 That means that there exists an 
, for each , that separates  and 
\ie,  but

Note that we can assume w.l.o.g. that  include all the free names
of  (recall that  is really a schematic list of names,
dependent on the choice of  in the first place). 
Let  be 
Then, by analysis of cut-free proofs, we can show that 

but

which contradicts our initial assumption.
Therefore, there must be one  such that
 and 
\qed
\end{proof}


\begin{lemma}
\label{lm:ch-open-complete}
Let  and  be two processes such that  for some distinction .
Then for all  and for all prefix  such that
 corresponds to the -distinction and ,
 if and only if 

\end{lemma}
\begin{proof}
Suppose that  and  
We show, by induction on the size of 
that   The other direction
is proved symmetrically, since open bisimulation is symmetric. 
We look at the interesting cases.
\begin{itemize}

\item Suppose  for some 
By analysis on the cut free derivations of , 
it can be shown that

This entails that there exists a process  such that

And by the invertibility of the right-introduction rules for ,  and , this in turn entails that

and
 The former implies, by the adequacy of one-step transition, that
 Since , this means
that there exists  such that  and
, where  At this point we are almost ready to
apply the induction hypothesis to , except that  may not corresponds to the
-distinction, since the latter may contain more
inequal pairs than .  However, since open bisimulation is closed
under extensions of distinctions (see Lemma
6.3. in \cite{sangiorgi96acta}), we can assume without loss of
generality that  is indeed the -distinction. Therefore by the adequacy of one-step transition and
induction hypothesis, we conclude that 
and

and from these, it follows that  is also provable.

\item Suppose  This case is analogous to the previous case. The only
difference is that the bound input is universally quantified, instead of -quantified.
So we apply the induction hypothesis to , which can be done
without resorting to extensions of the distinction , since in this case the -distinction
is exactly 

\item For the cases where  is prefixed by either  or , the proof follows
a similar argument as in the completeness proof of open bisimulation (Theorem~\ref{thm:open bisim complete}).
For instance, for the case where , from the fact that 
, it follows that 

As in the proof of Theorem~\ref{thm:open bisim complete}, we can further show that there is 
a derivation of this formula that ends with -rule, such that every  in this
premise is a -respecting substitution. 
Since , we can show that every bound input 
action of , for any -respecting , can be imitated by  and vice versa. 
From this and induction hypothesis, we can therefore obtain a derivation of 

hence   \qed
\end{itemize}
\end{proof}

Finally, the proof of Theorem~\ref{thm:ch-open} now follows 
immediately from Lemma~\ref{lm:ch-open-sound} and
Lemma~\ref{lm:ch-open-complete}. 
\qed 



 \begin{received}
 Received May 2008;
 revised December 2008;
 accepted February 2009
 \end{received}

 \end{document}
