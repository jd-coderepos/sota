\newpage

\appendix

\begin{center}
\begin{huge}
\textbf{Appendix}
\end{huge}
\end{center}

\section{Proof for Proposition 1}\label{sec:appendix-proof}
We restate the proposition \ref{prop} and its proof here.
\begin{proposition}
Given the probabilistic logical operators $\gI$ and $\gN$ defined in Sec. \ref{sec:setoperators}, \methodname has the following properties:
\begin{enumerate}
    \item Given Beta embedding $\Em{S}$, $\Em{S}$ is a fixed point of $\gN\circ\gN$: $\gN(\gN(\Em{S})) = \Em{S}$.
    \item Given Beta embedding $\Em{S}$, we have $\gI(\{\Em{S},\Em{S},\dots,\Em{S}\})=\Em{S}$.
\end{enumerate}
\end{proposition}
\begin{proof}
For the first property, the probabilistic negation operator $\gN$ takes the reciprocal of the parameters of the input Beta embeddings. If we apply $\gN$ twice, it naturally equals the input Beta embeddings. For the second property, the probabilistic intersection operator $\gI$ takes the weighted product of the PDFs of the input Beta embeddings, and according to Eq. \ref{eq:betainter}, the parameters of the output Beta embeddings are linear interpolation of the parameters of the input Beta embeddings. Then we naturally have $\Em{S}=\gI(\{\Em{S}, \dots, \Em{S}\})$.
\end{proof}

\section{Computation Complexity of DM and DNF}\label{appendix:complexity}
Here we discuss the computation complexity of representing any given FOL query using the De Morgan's laws (DM) and the disjunctive normal form (DNF). Given a FOL query $q$, representing $q$ with DNF may in the worst case creates exponential number of atomic formulas. For example, transforming a valid FOL query $(q_{11}\vee q_{12})\wedge(q_{21}\vee q_{22})\dots\wedge(q_{n1}\vee q_{n2})$ leads to exponential explosion, resulting in a query with $2^n$ number of formulas in the DNF. For DM, since we could always represent a disjunction operation with three negation operation and one conjunction operation: $q_1\vee q_2 = \neg (\neg q_1 \wedge \neg q_2)$, which is a constant. Hence, the DM modeling only scales linearly.

\section{Query Generation and Statistics}\label{sec:query_generation}
\textbf{Generation of EPFO (with $\exists$, $\vee$ and $\wedge$) Queries:} Following \cite{ren2020query2box}, we generate the 9 EPFO query structures in a similar manner. Given the three KGs, and its training/validation/test edge splits, which is shown in Table \ref{tab:meta_kg}, we first create $\G_\texttt{train}$, $\G_\texttt{valid}$, $\G_\texttt{test}$ as discussed in Sec. \ref{sec:exp-setup}. Then for each query structure, we use pre-order traversal starting from the target node/answer to assign an entity/relation to each node/edge iteratively until we instantiate every anchor nodes (the root of the query structure). After the instantiation of a query, we could perform post-order traversal to achieve the answers of this query. And for validation/test queries, we explicitly filter out ones that do not exist non-trivial answers, \textit{i.e.}, they can be fully answered in $\G_\texttt{train} / \G_\texttt{valid}$. Different from the dataset in \cite{ren2020query2box}, where the maximum number of test queries may exceed 5,000, we set a bar for the number of answers one query has, and additionally filter out unrealistic queries with more than 100 answers. We list the average number of answers the new test queries have in Table \ref{tab:meta_new_query} and the number of training/validation/test queries in Table \ref{tab:meta_query}.

\begin{table*}[!h]
\centering
\small
\resizebox{\columnwidth}{!}{\begin{tabular}{|l|c|c|c|c|c|c|}
\hline
\textbf{Dataset} & \textbf{Entities} & \textbf{Relations} & \textbf{Training Edges} & \textbf{Validation Edges} & \textbf{Test Edges} & \textbf{Total Edges}\\
\hline
FB15k & 14,951 & 1,345 & 483,142 & 50,000 & 59,071 & 592,213\\
\hline
FB15k-237 & 14,505 & 237 & 272,115 & 17,526 & 20,438 & 310,079\\
\hline
NELL995 & 63,361 & 200 & 114,213 & 14,324 & 14,267 & 142,804\\
\hline
\end{tabular}
}
\caption{Knowledge graph dataset statistics as well as training, validation and test edge splits.}
\label{tab:meta_kg}
\end{table*}

\begin{table}[!h]
\resizebox{\columnwidth}{!}{\begin{tabular}{|l|c|c|c|c|c|c|c|c|c|c|c|c|c|c|}
\hline
\textbf{Dataset} & \textbf{1p} & \textbf{2p} & \textbf{3p} & \textbf{2i} & \textbf{3i} & \textbf{ip} & \textbf{pi} & \textbf{2u} & \textbf{up} & \textbf{2in} & \textbf{3in} & \textbf{inp} & \textbf{pin} & \textbf{pni} \\\hline
FB15k            & 1.7         & 19.6        & 24.4        & 8.0         & 5.2         & 18.3        & 12.5        & 18.9        & 23.8        & 15.9         & 14.6         & 19.8         & 21.6         & 16.9         \\\hline
FB15k-237        & 1.7         & 17.3        & 24.3        & 6.9         & 4.5         & 17.7        & 10.4        & 19.6        & 24.3        & 16.3         & 13.4         & 19.5         & 21.7         & 18.2         \\\hline
NELL995          & 1.6         & 14.9        & 17.5        & 5.7         & 6.0         & 17.4        & 11.9        & 14.9        & 19.0        & 12.9         & 11.1         & 12.9         & 16.0         & 13.0    \\ \hline   
\end{tabular}
}\caption{Average number of answers of test queries in our new dataset.}
\label{tab:meta_new_query}
\end{table}

\begin{table*}[!h]
\centering
\small
\begin{tabular}{|l|c|c|c|c|c|c|}
\hline
         \textbf{Queries} & \multicolumn{2}{c|}{\textbf{Training}} & \multicolumn{2}{c|}{\textbf{Validation}} & \multicolumn{2}{c|}{\textbf{Test}} \\ \hline
\textbf{Dataset}     & 1p/2p/3p/2i/3i               & 2in/3in/inp/pin/pni           & 1p              & others          & 1p               & others          \\ \hline
FB15k     & 273,710          & 27,371          & 59,097          & 8,000           & 67,016           & 8,000           \\ \hline
FB15k-237 & 149,689          & 14,968          & 20,101          & 5,000           & 22,812           & 5,000           \\ \hline
NELL995     & 107,982          & 10,798          & 16,927          & 4,000           & 17,034           & 4,000           \\ \hline
\end{tabular}
\caption{Number of training, validation, and test queries generated for different query structures.}
\label{tab:meta_query}
\end{table*}

\textbf{Generation of Queries with Negation:} 
For the additional queries with negation, we derive 5 new query structures from the 9 EPFO structures. Specifically, as shown in Fig. \ref{fig:all-query}, we only consider query structures with intersection for the derivation of queries with negation. The reason is that queries with negation are only realistic if we take negation with an intersection together. Consider the following example, where negation is not taken with intersection, \qu{List all the entities on KG that is not European countries.}, then both \qu{apple} and \qu{computer} will be the answers. However, realistic queries will be like \qu{List all the countries on KG that is not European countries.}, which requires an intersection operation. In this regard, We modify one edge of the intersection to further incorporate negation, thus we derive $2in$ from $2i$, $3in$ from $3i$, $inp$ from $ip$, $pin$ and $pni$ from $pi$. Note that following the 9 EPFO structures, we also enforce that all queries with negation have at most 100 answers.



\section{Experimental Details}\label{sec:experiment-detail}

We implement our code using Pytorch. We use the implementation of the two baselines \gqe \cite{hamilton2018embedding} and \qb \cite{ren2020query2box} in \url{https://github.com/hyren/query2box}. We finetune the hyperparameters for the three methods including number of embedding dimensions from $\{200, 400, 800\}$ and the learning rate from $\{1e^{-4}, 5e^{-3}, 1e^{-3}\}$, batch size from $\{128, 256, 512\}$, and the negative sample size from $\{32,64,128\}$, the margin $\gamma$ from $\{20, 30, 40, 50, 60, 70\}$. We list the hyperparameters of each model in the Table \ref{tab:hyperparam}. Additionally, for our \methodname, we finetune the structure of the probabilistic projection operator $\texttt{MLP}_r$ and the attention module $\texttt{MLP}_\texttt{Att}$. For both modules, we implement a three-layer MLP with 512 latent dimension and ReLU activation.

\begin{table}[!h]
\begin{tabular}{|l|c|c|c|c|c|}
\hline
                           & embedding dim & learning rate & batch size & negative sample size & margin \\ \hline
\gqe        & 800           & 0.0005        & 512        & 128                  & 30     \\ \hline
\qb         & 400           & 0.0005        & 512        & 128                  & 30     \\ \hline
\methodname & 400           & 0.0005        & 512        & 128                  & 60     \\ \hline
\end{tabular}
\caption{Hyperparameters used for each method.}\label{tab:hyperparam}
\end{table}


Each single experiment is run on a single NVIDIA GeForce RTX 2080 TI GPU, and we run each method for 300k iterations.

\section{Additional Experimental Results}\label{appendix:results}
Here we list some additional experimental results. 

We show in Table \ref{tab:conjmrr} the MRR results of the three methods on answering EPFO queries.
Our methods show a significant improvement over the two baselines in all three datasets.

We show in Table \ref{tab:conjold} the MRR results of the three methods on answering EPFO queries in the dataset proposed in \cite{ren2020query2box}, where the queries may have more than 5,000 answers. Our method is still better than the two baselines. 

We show in Table \ref{tab:pearson} the Pearson correlation coefficient between the learned embedding and the number of answers of queries. Our method is better than the baseline \qb in measuring the uncertainty of the queries. 



\begin{table}[t]
\resizebox{\columnwidth}{!}{\begin{tabular}{|l|l|ccc|cc|cc|cc|cc|c|}
\hline
\multirow{2}{*}{\textbf{Dataset}} & \multirow{2}{*}{\textbf{Model}} & \multirow{2}{*}{\textbf{1p}} & \multirow{2}{*}{\textbf{2p}} & \multirow{2}{*}{\textbf{3p}} & \multirow{2}{*}{\textbf{2i}} & \multirow{2}{*}{\textbf{3i}} & \multirow{2}{*}{\textbf{pi}} & \multirow{2}{*}{\textbf{ip}} & \multicolumn{2}{c|}{\textbf{2u}} & \multicolumn{2}{c|}{\textbf{up}} & \multirow{2}{*}{\textbf{avg}} \\ \cline{10-13}
                                  &                                 &                              &                              &                              &                              &                              &                              &                              & \textbf{DNF}     & \textbf{DM}   & \textbf{DNF}     & \textbf{DM}   &                               \\ \hline
\multirow{3}{*}{FB15k}            & \methodname      & \textbf{52.0}                & \textbf{17.0}                & \textbf{16.9}                & \textbf{43.5}                & \textbf{55.3}                & \textbf{32.3}                & \textbf{19.3}                & \textbf{28.1}    & 17.0          & \textbf{16.9}    & 17.4          & \textbf{31.3}                 \\
                                  & \qb              & \textbf{52.0}                & 12.7                         & 7.8                          & 40.5                         & 53.4                         & 26.7                         & 16.7                         & 22.0             & -             & 9.4              & -             & 26.8                          \\
                                  & \gqe             & 34.2                         & 8.3                          & 5.0                          & 23.8                         & 34.9                         & 15.5                         & 11.2                         & 11.5             & -             & 5.6              & -             & 16.6                          \\ \hline
\multirow{3}{*}{FB15k-237}        & \methodname      & \textbf{28.9}                & \textbf{5.5}                 & \textbf{4.9}                 & \textbf{18.3}                & \textbf{31.7}                & \textbf{14.0}                & 6.7                          & \textbf{6.3}     & 6.1           & \textbf{4.6}     & 4.8           & \textbf{13.4}                 \\
                                  & \qb              & 28.3                         & 4.1                          & 3.0                          & 17.5                         & 29.5                         & 12.3                         & \textbf{7.1}                 & 5.2              & -             & 3.3              & -             & 12.3                          \\
                                  & \gqe             & 22.4                         & 2.8                          & 2.1                          & 11.7                         & 20.9                         & 8.4                          & 5.7                          & 3.3              & -             & 2.1              & -             & 8.8                           \\ \hline
\multirow{3}{*}{NELL995}          & \methodname      & \textbf{43.5}                & 8.1                          & \textbf{7.0}                 & \textbf{27.2}                & \textbf{36.5}                & \textbf{17.4}                & 9.3                          & \textbf{6.9}     & 6.0           & 4.7              & 4.7           & \textbf{17.8}                 \\
                                  & \qb              & 23.8                         & \textbf{8.7}                 & 6.9                          & 20.3                         & 31.5                         & 14.3                         & \textbf{10.7}                & 5.0              & -             & \textbf{6.0}     & -             & 14.1                          \\
                                  & \gqe             & 15.4                         & 6.7                          & 5.0                          & 14.3                         & 20.4                         & 10.6                         & 9.0                          & 2.9              & -             & 5.0              & -             & 9.9                           \\ \hline
\end{tabular}
}
\caption{H@1 results (\%) of \methodname, \qb and \gqe on answering EPFO ($\exists$, $\wedge$, $\vee$) queries.}
\vspace{-7mm}
\label{tab:conjhone}
\end{table}

\begin{table}[!h]
\resizebox{\columnwidth}{!}{\begin{tabular}{|l|l|ccc|cc|cc|cc|c|}
\hline
\textbf{Dataset}           & \textbf{Model}             & \textbf{1p}   & \textbf{2p}   & \textbf{3p}   & \textbf{2i}   & \textbf{3i}   & \textbf{pi}   & \textbf{ip}   & \textbf{2u}   & \textbf{up}   & \textbf{avg}  \\ \hline
\multirow{3}{*}{FB15k}     & \methodname & 65.0          & \textbf{42.1} & \textbf{37.8} & \textbf{52.9} & \textbf{64.0} & \textbf{41.5} & \textbf{22.9} & 48.8          & 26.9          & \textbf{44.6} \\
                           & \qb         & \textbf{67.1} & 38.0          & 27.5          & 49.2          & 62.8          & 36.2          & 19.2          & \textbf{49.0} & \textbf{28.9} & 42.0          \\
                           & \gqe        & 54.6          & 30.5          & 22.2          & 37.7          & 48.4          & 24.8          & 14.7          & 33.8          & 24.7          & 32.4          \\ \hline
\multirow{3}{*}{FB15k-237} & \methodname & 39.1          & \textbf{24.2} & \textbf{20.4} & \textbf{28.1} & \textbf{39.2} & \textbf{19.4} & \textbf{10.6} & \textbf{22.0} & 17.0          & \textbf{24.4} \\
                           & \qb         & \textbf{40.3} & 22.8          & 17.5          & 27.5          & 37.9          & 18.5          & 10.5          & 20.5          & \textbf{17.4} & 23.6          \\
                           & \gqe        & 35.0          & 19.0          & 14.4          & 22.0          & 31.2          & 14.6          & 8.8           & 15.0          & 14.6          & 19.4          \\ \hline
\multirow{3}{*}{NELL995}   & \methodname & \textbf{53.0} & \textbf{27.5} & \textbf{28.1} & \textbf{32.9} & \textbf{45.1} & \textbf{21.8} & 10.4          & \textbf{38.6} & \textbf{19.6} & \textbf{30.7} \\
                           & \qb         & 41.8          & 22.9          & 20.8          & 28.6          & 41.2          & 19.9          & \textbf{12.3} & 26.9          & 15.5          & 25.5          \\
                           & \gqe        & 32.8          & 19.3          & 17.9          & 23.1          & 31.9          & 16.2          & 10.3          & 17.3          & 13.1          & 20.2          \\ \hline
\end{tabular}
}
\caption{MRR results (\%) on queries from \cite{ren2020query2box}, where we show that we are also able to achieve higher performance than baselines \qb and \gqe on all three KGs.
}
\label{tab:conjold}
\end{table}

\begin{table}[t]
\resizebox{\columnwidth}{!}{\begin{tabular}{|l|l|ccc|cc|cc|ccccc|}
\hline
                  \textbf{Dataset}         &     \textbf{Model}       & \textbf{1p}    & \textbf{2p}    & \textbf{3p}    & \textbf{2i}    & \textbf{3i}    & \textbf{pi}    & \textbf{ip}    & \textbf{2in} & \textbf{3in} & \textbf{inp} & \textbf{pin} & \textbf{pni} \\\hline
\multirow{2}{*}{FB15k}     & \qb         & 0.075          & 0.217          & 0.258          & 0.285          & 0.226          & 0.245          & 0.133          & -            & -            & -            & -            & -            \\
                           & \methodname & \textbf{0.216} & \textbf{0.357} & \textbf{0.383} & \textbf{0.386} & \textbf{0.299} & \textbf{0.311} & \textbf{0.312} & 0.438        & 0.413        & 0.343        & 0.360        & 0.442        \\\hline
\multirow{2}{*}{FB15k-237} & \qb         & 0.017          & 0.194          & 0.261          & \textbf{0.366} & \textbf{0.488} & \textbf{0.335} & 0.197          & -            & -            & -            & -            & -            \\
                           & \methodname & \textbf{0.225} & \textbf{0.365} & \textbf{0.450} & 0.362 & 0.307 & 0.319 & \textbf{0.332} & 0.464        & 0.409        & 0.390        & 0.361        & 0.484        \\\hline
\multirow{2}{*}{ NELL995}      & \qb         & 0.068          & 0.211          & 0.306          & 0.362          & 0.287          & 0.240          & 0.338          & -            & -            & -            & -            & -            \\
                           & \methodname & \textbf{0.236} & \textbf{0.403} & \textbf{0.433} & \textbf{0.404} & \textbf{0.385} & \textbf{0.403} & \textbf{0.403} & 0.515        & 0.514        & 0.255        & 0.354        & 0.455   \\ \hline    
\end{tabular}
}\caption{Pearson correlation coefficient between learned embedding (differential entropy for \methodname, box size for \qb) and the number of answers of queries (grouped by different query type). Ours achieve higher correlation coefficient.}\label{tab:pearson}
\end{table}

