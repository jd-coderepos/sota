

\documentclass[runningheads]{llncs}
\usepackage{graphicx}
\usepackage{multirow}
\usepackage{soul}
\usepackage{subfigure}


\usepackage{tikz}
\usepackage{comment}
\usepackage{amsmath,amssymb} \usepackage{color}

\usepackage[accsupp]{axessibility}  \usepackage[misc]{ifsym}




\newcommand{\Figref}[1]{Figure~\ref{fig:#1}}
\newcommand{\figref}[1]{Fig.~\ref{fig:#1}}
\newcommand{\Eqnref}[1]{Equation~\ref{eq:#1}}
\newcommand{\eqnref}[1]{Eq.~\ref{eq:#1}}
\newcommand{\Tabref}[1]{Table~\ref{tab:#1}}
\newcommand{\tabref}[1]{Tab.~\ref{tab:#1}}

\graphicspath{{./figures}{./}}

\begin{document}
\pagestyle{headings}
\mainmatter
\def\ECCVSubNumber{609}  

\title{Human Trajectory Prediction via Neural Social Physics} 

\begin{comment}
\titlerunning{ECCV-22 submission ID \ECCVSubNumber} 
\authorrunning{ECCV-22 submission ID \ECCVSubNumber} 
\author{Anonymous ECCV submission}
\institute{Paper ID \ECCVSubNumber}
\end{comment}


\titlerunning{Human Trajectory Prediction via Neural Social Physics}
\author{Jiangbei Yue\inst{1} \and
Dinesh Manocha\inst{2} \and
He Wang\inst{1}}
\authorrunning{J. Yue et al.}
\institute{University of Leeds, Leeds, UK \\ \email{H.E.Wang@leeds.ac.uk} \and
University of Maryland at College Park, College Park, USA}



\maketitle

\begin{abstract}
Trajectory prediction has been widely pursued in many fields, and many \textit{model-based} and \textit{model-free} methods have been explored. The former include rule-based, geometric or optimization-based models, and the latter are mainly comprised of deep learning approaches. In this paper, we propose a new method combining both methodologies based on a new Neural Differential Equation model. Our new model (Neural Social Physics or NSP) is a deep neural network within which we use an explicit physics model with learnable parameters. The explicit physics model serves as a strong inductive bias in modeling pedestrian behaviors, while the rest of the network provides a strong data-fitting capability in terms of system parameter estimation and dynamics stochasticity modeling. We compare NSP with 15 recent deep learning methods on 6 datasets and improve the state-of-the-art performance by 5.56\%-70\%. Besides, we show that NSP has better generalizability in predicting plausible trajectories in drastically different scenarios where the density is 2-5 times as high as the testing data. Finally, we show that the physics model in NSP can provide plausible explanations for pedestrian behaviors, as opposed to black-box deep learning. Code is available: https://github.com/realcrane/Human-Trajectory-Prediction-via-Neural-Social-Physics.
\keywords{Human Trajectory Prediction; Neural Differential Equations}
\end{abstract}


\section{Introduction}
Understanding human trajectories is key to many research areas such as physics, computer science and social sciences. Being able to learn behaviors with non-invasive sensors is important to analyzing the natural behaviors of humans. This problem has been widely studied in computer graphics, computer vision and machine learning~\cite{BENDALIBRAHAM_recent_2021}. Existing approaches generally fall into \textit{model-based} and \textit{model-free} methods. Early model-based methods tended to be empirical or rule-based methods derived via the first-principles approach: summarizing observations into rules and deterministic systems based on fundamental assumptions on human motion. In such a perspective, social interactions can be modelled as forces in a particle system~\cite{helbing1995social} or an optimization problem~\cite{vanDenBerg_reciprocal_2008}, and individuals can be influenced by affective states~\cite{Luo_Agentbased_2008}. Later, data-driven model-based methods were introduced, in which the model behavior is still dominated by the assumptions on the dynamics, e.g. a linear dynamical system~\cite{He_Informative_2020}, but retains sufficient flexibility so that the model can be adjusted to fit observations. 
More recently, model-free methods based on deep learning have also been explored, and these demonstrate surprising trajectory prediction capability~\cite{alahi2016social,gupta2018social,sadeghian2019sophie,bhattacharyya2019conditional,li2019conditional,liang2019peeking,deo2020trajectory,liang2020simaug,mangalam2020not,salzmann2020trajectron++,liang2020garden,mangalam2021goals,su2021pedestrian,zhou2021sliding,gao2022social,xia2022cscnet}.

Empirical or rule-based methods possess good explainability because they are formed as explicit geometric optimization or ordinary/partial differentiable equations where specific terms correspond to certain behaviors.
Therefore, they have been used for not only prediction but also analysis and simulation~\cite{vantoll_algorithms_2021}. However, they are less effective in data fitting with respect to noise and are therefore unable to predict accurately, even when the model is calibrated on data~\cite{Wolinski_paramter_2014}. Data-driven model-based methods (e.g., statistical machine learning) improve the ability of data fitting but are restricted by the specific statistical models employed which have limited capacities to learn from large amounts of data~\cite{He_Informative_2020}. Finally, deep learning approaches excel at data fitting. They can learn from large datasets, but lack explainability and therefore have been mainly used for prediction rather than analysis and simulation~\cite{alahi2016social,mangalam2020not,zhou2021sliding}.

We explore a model that can explain pedestrian behaviors and retain good data-fitting capabilities by combining model-based and model-free approaches. Inspired by recent research in neural differential equations~\cite{chen2018neural,rackauckas2020universal,zhong2019symplectic,zubov2021NeuralPDE,kidger_neural_2022}, we propose a new crowd neural differentiable equation model consisting of two parts. The first is a deterministic model formulated using a differentiable equation. Although this equation can be arbitrary, we use a dynamical system inspired by the social force model~\cite{helbing1995social}. In contrast to the social force model and its variants, the key parameters of our deterministic model are learnable through data instead of being hand-picked and fixed. The second part of our model captures complex uncertainty in the motion dynamics and observations via a Variational Autoencoder. Overall, the whole model is a deep neural network with an embedded explicit model; we call this model \textit{Neural Social Physics} (NSP).

We demonstrate that our NSP model outperforms the state-of-the-art methods~\cite{gupta2018social,sadeghian2019sophie,bhattacharyya2019conditional,li2019conditional,liang2019peeking,deo2020trajectory,liang2020simaug,mangalam2020not,salzmann2020trajectron++,liang2020garden,mangalam2021goals,su2021pedestrian,zhou2021sliding,gao2022social,xia2022cscnet} in standard trajectory prediction tasks across various benchmark datasets~\cite{robicquet2016learning,pellegrini2010improving,lerner2007crowds} and metrics. In addition, we show that NSP can generalize to unseen scenarios with higher densities and still predict plausible motions with less collision between people, as opposed to pure black-box deep learning approaches. Finally, from the explicit model in NSP, we demonstrate that our method can provide plausible explanations for motions. 
Formally, (1) we propose a new neural differentiable equation model for trajectory prediction and analysis. (2) we propose a new mechanism to combine explicit and deterministic models with deep neural networks for crowd modeling. (3) We demonstrate the advantages of the NSP model in several aspects: prediction accuracy, generalization and explaining behaviors.

\section{Related Work}
\subsection{Trajectory Analysis and Prediction}
Statistical machine learning has been used for trajectory analysis in computer vision~\cite{oliver2000bayesian,ellis2009modelling,wang2011trajectory,kim2015interactive,wang2016globally,chaker2017social}. They aim to learn individual motion dynamics~\cite{zhou2011random}, structured latent patterns in data~\cite{wang2016globally,wang_trending_2016}, anomalies~\cite{charalambous2014data,chaker2017social}, etc. These methods provide a certain level of explainability, but are limited in model capacity for learning from large amounts of data. Compared
with these methods, our model leverages the ability of deep neural networks to handle high-dimensional and large data. More recently, deep learning has been exploited for trajectory prediction~\cite{sighencea2021review}. Recurrent neural networks (RNNs)~\cite{alahi2016social,bartoli2018context,vemula2018social} have been explored first due to their ability to learn from temporal data. Subsequently, other  deep learning techniques and neural network architectures are introduced into trajectory prediction, such as Generative Adversarial Network (GAN)~\cite{gupta2018social}, conditional variational autoencoder (CVAE)~\cite{ivanovic2019trajectron,mangalam2020not,zhou2021sliding} and Convolutional Neural Network (CNN)~\cite{mohamed2020social}. In order to capture the spatial features of trajectories and the interactions between pedestrians accurately, graph neural networks (GNNs) have also been used to reason and predict future trajectories~\cite{mohamed2020social,shi2021sgcn}. 
Compared with existing deep learning methods, our method achieves better prediction accuracy. Further, our method has an explicit model which can explain pedestrian motions and lead to better generalizability. Very recently, attempts have been made in combining physics with deep learning for trajectory prediction~{\cite{antonucci2020generating,kreiss2021deep,hossain2022sfmgnet}}. But their methods are tied to specific physics models and are deterministic, while NSP is a general framework that aims to accommodate arbitrary physics models and is designed to be intrinsically stochastic to capture motion randomness.

\subsection{Pedestrian and Crowd Simulation}
Crowd simulation aims to generate trajectories given the initial position and destination of each agent~\cite{vantoll_algorithms_2021}, which essentially aims to predict individual motions. Empirical modelling and data-driven methods have been the two foundations in simulation~\cite{narain2009aggregate,lopez2019character}. Early research is dominated by empirical modelling or rule-based methods, where crowd motions are abstracted into mathematical equations and deterministic systems, such as flows~\cite{narain2009aggregate}, particle systems~\cite{helbing1995social}, and velocity and geometric optimization~\cite{vanDenBerg_reciprocal_2008,shen2018data}. Meanwhile, data-driven methods using statistical machine learning have also been employed, e.g., using first-person vision to guide steering behaviors~\cite{lopez2019character} or using trajectories to extract features to describe motions~\cite{karamouzas2018crowd,wei2020simulating}. While the key parameters in these approaches are either fixed or learned from small datasets, our NSP model is more general. It can take existing deterministic systems as a component and provides better data-fitting capacity via deep neural networks. Compared with afore-mentioned model-based methods, our NSP can be regarded as using deep learning for model calibration. our model possesses the ability to learn from large amount of data, which is difficult for traditional parameter estimation methods based on optimization or sampling~{\cite{wan2017learning}}. Meanwhile, the formulation of our NSP is more general, flexible and data-driven than traditional model-based methods.

\subsection{Deep Learning and Differential Equations}
Solving differentiable equations (DE) with the assistance of deep learning has recently spiked strong interests~\cite{chen2018neural,zhong2019symplectic,zubov2021NeuralPDE,Karniadakis_datadriven_2021}. Based on the involvement depth of deep learning, the research can be categorized into deep learning assisted DE, differentiable physics, neural differential equations and physics-informed neural networks (PINNs). Deep learning assisted DE involves accelerating various steps during the DE solve, such as Finite Element mesh generation~\cite{Zhang_MeshingNet_2020,zhang_meshingnet3d_2021}. The deeper involvement of neural networks is shown in differentiable physics and neural differential equations, where the former aims to make the whole simulation process differentiable~\cite{Gong_finegrained_2022,liang2019differentiable,Werling2021fast}, and the latter focuses on the part of the equations being parameterized by neural networks~\cite{Shen_high_2021}. PINNs aim to bypass the DE solve and use NN for prediction~\cite{raissi2019physics,cai2022physics}. Highly inspired by the research above, we propose a new neural differential equations model in a new application domain for human trajectory prediction.

\section{Methodology}


\subsection{Neural Social Physics (NSP)}

At any time , the position  of the th pedestrian can be observed in a crowd. Then a trajectory can be represented as a function of time , where we have discrete observations in time up to , . An observation or \textit{state} of a person at time  is represented by  where ,  are the position and velocity. For most datasets,  is given and  can be estimated via finite difference. Given an observation  of the th person, we consider her neighborhood set  containing other nearby pedestrians . The neighborhood is also a function of time . Then, in NSP the dynamics of a person (agent) in a crowd can be formulated as:

where  and  are learnable parameters,  represents the environment.  contains interpretable parameters explained later and  contains uninterpretable parameters (e.g. neural network weights). The agent dynamics are governed by  which depends on time , its current state , its time-varying neighborhood  and the environment . Similar to existing work, we assume there is dynamics stochasticity in NSP. But unlike them which assume simple forms (e.g. white noise)~\cite{He_Informative_2020}, we model time-varying stochasticity in a more general form: as a function of time, the current state and the brief history of the agent, . Then we have the following equation in NSP:

given the initial and final condition .

Physics models have been widely used to model crowd dynamics~\cite{narain2009aggregate,helbing1995social}. To leverage their interpretability, we model the dynamics as a physical system in NSP. Assuming the second-order differentiability of , NSP expands  via Taylor's series for a first-order approximation:

where  is the time step. The stochasticity  is assumed to only influence . \Eqnref{timeDiscretization} is general and any dynamical system with second-order differentiability can be employed here. Below, we realize NSP by combining a type of physics models-social force models (SFM)~\cite{helbing1995social} and neural networks. We refer to our model NSP-SFM.


\subsection{NSP-SFM}
\begin{figure}[b]
\centering
\includegraphics[width=0.7\textwidth]{model.png}
\caption{Overview of NSP-SFM. ,  and  are estimated in every time step by Goal-Network, Collision-Network and \eqnref{env} before solving \eqnref{forces}. The output is used to update the position and velocity which are then combined with the estimated noise from  for the final prediction}
\label{fig:model}
\end{figure}

We design the NSP-SFM by assuming each person acts as a particle in a particle system and each particle is governed by Newton's second law of motion.  is designed to be dependent on three forces: goal attraction , inter-agent repulsion  and environment repulsion .

where  is the environment and explained later. However, unlike \cite{helbing1995social}, the three forces are partially realized by neural networks, turning \Eqnref{nde} into a neural differential equation.
The overall model is shown in~\Figref{model}. Note that, in \Eqnref{nde}, we assume  is given, although it is not available during prediction. Therefore, we employ a Goal Sampling Network (GSN) to sample . During testing, we either first sample a  for prediction or require the user to input . The GSN is similar to a part of Y-net~\cite{mangalam2021goals} and pre-trained, and detailed in the supplementary materials.

Given the current state and the goal, we compute  using the Goal-Network  in \eqnref{goal} (\figref{subnets} Left),  using the Collision-Network  in \eqnref{collision} (\figref{subnets} Right) and  using \eqnref{env} directly. The Goal-Network encodes  then feeds it into a Long Short Term Memory (LSTM) network to capture dynamics. After a linear transformation, the LSTM output is concatenated with the embedded . Finally,  is computed by an MLP (multi-layer perceptron). In Collision-Network, the architecture is similar. Every agent  in the neighborhood  is encoded and concatenated with the encoded agent . Then  is computed.  and  are interpretable key parameters of  and . The corresponding parameter in  is . Finally, we show our network for  for stochasticity modeling in \Figref{CVAE}.

\begin{figure}[tb]
\centering
\includegraphics[width=0.8\textwidth]{two_networks.png}
\caption{Left: Goal-Network and Right: Collision-Network. The numbers in square brackets show both the number and dimension of the layers in each component.}
\label{fig:subnets}
\end{figure}

\begin{figure}[tb]
\centering
\includegraphics[width=0.8\textwidth]{cvae.png}
\caption{The architecture of the CVAE, where  is the intermediate prediction out of our force model and . Encoder , ,  and decoder  are all MLP networks with dimensions indicated in the square brackets. More Details of the network can be found in the supplementary material}
\label{fig:CVAE}
\end{figure}

\textbf{Goal attraction}. Pedestrians are always drawn to destinations, which can be abstracted into a goal attraction force. At time , a pedestrian has a desired walking direction  determined by the goal  and the current position : . If there are no other forces, she will change her current velocity to the desired velocity  where  and  are the magnitude and direction respectively. Instead of using a fixed  as in \cite{helbing1995social}, we update  at every  to mimic the change of the desired speed as the pedestrian approaches the destination: . Therefore, the desired velocity is defined as .
The goal attraction force  represents the tendency of a pedestrian changing her current velocity  to the desired velocity  within time :

where  is learned through a neural network (NN) parameterized by .

\begin{figure}[tb]
\centering
\includegraphics[width=\textwidth]{vision_fields.png}
\caption{(a) The neighborhood  of a person is a sector within a circle (centered at this person with radius ) spanned by an angle  from the current velocity vector (green arrow). (b) Each person has a view field (orange box) within which the environment repels a pedestrian. The view field is a square with dimension  based on the current velocity vector (green arrow). The current velocity is along the diagonal of the orange box. (c) The environment is segmented into walkable (red) and unwalkable (blue) areas. Within the view field of the pedestrian in (b), the yellow pixels are the environment pixels that repel the pedestrian. ,  and  are hyperparameters.}
\label{fig:forceFields}
\end{figure}

\textbf{Inter-agent Repulsion}. Pedestrians often steer to avoid potential collisions and maintain personal space when other people are in the immediate neighborhood (\figref{forceFields} a). Given an agent  in  of agent  and her state , agent  repels agent  based on :

where we employ a repulsive potential field  modeled by a monotonic decreasing function of . Then the repulsive force caused by agent  to agent  is the gradient of . Previously, simple functions such as symmetric elliptic fields were employed for ~\cite{helbing1995social}. Here, we model  as a time-varying field parameterized by 
which is learned via a neural network. Instead of directly learning , we set .  and  are hyperparameters to ensure that the learned  value is valid. If we have  agents at time t in , the net repulsive force on agent  is: .

\textbf{Environment Repulsion}. Besides collisions with others, people also avoid nearby obstacles. We model the repulsion from the environment as:

where  is the position of the obstacle and  is a learnable parameter. NSP-SFM learns  directly via back-propagation and stochastic gradient descent. Since the environment is big, we assume the agent mainly focuses on her view field (\figref{forceFields} b) within which the environment (\figref{forceFields} c) repels the pedestrian. We calculate  as the center of the pixels that are classified as obstacles in the view field of an agent.  is shared among all obstacles. So far, we have introduced all the interpretable parameters  in \Eqnref{nde}.

\textbf{Dynamics Stochasticity }. Trajectory prediction needs to explicitly model the motion randomness caused by intrinsic motion stochasticity and observational noises~\cite{wang_path_2016,wang_trending_2016}. We employ a more general setting by assuming the noise distribution can have arbitrary shapes and is also time varying, unlike previous formulations such as white noise~{\cite{He_Informative_2020}} which is too restrictive. Generally, learning such functions requires large amounts of data, as it is unconstrained. To constrain the learning, we further assume the noise is \textit{Normally} distributed in a latent space, rather than in the data space.

Given a prediction  without dynamics stochasticity and its corresponding observation , there is an error . To model the arbitrary and time-varying shape of the distribution of , we assume it depends on the brief history  which implicitly considers the environment and other people. Then the conditional likelihood of  is: , where  is a latent variable. Assuming a mapping  and  being \textit{Normally} distributed, minimizing the KL divergence between , i.e., the variational posterior, and  leads to a conditional Variational Autoencoder (CVAE)~\cite{sohn_learning_2015}.





Our overall loss function is defined as  where:


 is the total number of samples,  is the length of the history, and  is the total length of the trajectory.  minimizes the difference between the predicted position and the ground-truth, while  learns the distribution of randomness . During training, in each iteration, we assume the first  frames of the trajectory are given and run the forward pass iteratively to predict the rest of the trajectory, then back-propagate to compute the gradient to update all parameters. During the forward pass, we use a semi-implicit scheme for stability:  and .
We employ a progressive training scheme for the sub-nets. We first train Goal-Network with  only, then fix Goal-Network and add Collision-Network and  for training using . Finally, we fix Goal-Network, Collision-Network and , add  for training under . We find this progressive training significantly improves the convergence speed. This is because we first train the deterministic part with the main forces added gradually, which converges quickly. Then the stochasticity part is trained separately to capture complex randomness. Please see the supplementary material for implementation details.

\subsection{NSP vs. Deep Neural Networks}
One big difference between NSP and existing deep learning is the deterministic system embedded in NSP. Instead of learning any function mapping the input to the output (as black box deep learning does), the deterministic system acts as a strong inductive bias and constrains the functional space within which the target mapping should lie. This is because a PDE family can be seen as a flow connecting the input and the output space~\cite{alvarez1999pde}, and the learning is essentially a process of finding the most fitting PDE within this flow. In addition to better data-fitting capability, this strong inductive bias also comes with two other advantages. First, the learned model can help explain motions because the PDE we employ is a physics system where the learnable parameters have physical meanings. Second, after learning, the PDE can be used to predict motions in drastically different scenes (e.g., with higher densities) and generate more plausible trajectories (e.g., fewer collisions). This is difficult for existing deep learning as it requires to extrapolate significantly to unseen interactions between pedestrians. 

\section{Experiments}
 
\subsection{Datasets}

We employ six widely used datasets in human trajectory prediction tasks: the Stanford Drone Dataset~\cite{robicquet2016learning}, ETH Hotel, ETH University~\cite{pellegrini2010improving}, UCY University, Zara1, and Zara2 datasets~\cite{lerner2007crowds}. \textbf{Stanford Drone Dataset (SDD):} SDD contains videos of a university campus with six classes of agents with rich interactions. SDD includes about 185,000 interactions between different agents and approximately 40,000 interactions between the agent and the environment. \textbf{ETH/UCY Datasets:} The datasets consist of human trajectories across five scenes recording the world coordinates of pedestrians. Following previous research~\cite{mangalam2021goals,mangalam2020not}, we adopt the standard leave-one-out evaluation protocol, where the model is trained on four sub-datasets and evaluated one. Since our goal sampling network and  need to work in the pixel space, we project the world coordinates in ETH/UCY into the pixel space using the homography matrices provided in Y-net~\cite{mangalam2021goals}. When computing the prediction error, we project the predictions in the pixel space back into the world space. Finally, for SDD and ETH/UCY, we follow previous work~\cite{mangalam2021goals,sadeghian2018trajnet} to segment trajectories into 20-frame samples and split the dataset for training/testing. Given the first 8 () frames, we train NSP to predict the remaining 12 frames for each trajectory.

\subsection{Trajectory Prediction}
Average Displacement Error (ADE) and Final Displacement Error (FDE) are employed as previous research~\cite{alahi2016social,gupta2018social,mangalam2020not,mangalam2021goals}. ADE is calculated as the  error between a predicted trajectory and the
ground truth, averaged over the entire trajectory. FDE is calculated as the  error between the predicted final point and the ground truth. Following prior works, in the presence of multiple possible future predictions, the minimal error is reported. We compare our NSP-SFM with an extensive list of baselines, including published papers and unpublished technical reports: Social GAN (S-GAN)~\cite{gupta2018social}, Sophie~\cite{sadeghian2019sophie}, Conditional Flow VAE (CF-VAE)~\cite{bhattacharyya2019conditional}, Conditional Generative Neural System (CGNS)~\cite{li2019conditional}, NEXT~\cite{liang2019peeking}, P2TIRL~\cite{deo2020trajectory}, SimAug~\cite{liang2020simaug},  PECNet~\cite{mangalam2020not}, Traj++~\cite{salzmann2020trajectron++}, Multiverse~\cite{liang2020garden}, Y-Net~\cite{mangalam2021goals}, SIT~\cite{su2021pedestrian}, S-CSR~\cite{zhou2021sliding}, Social-DualCVAE~\cite{gao2022social} and CSCNet~\cite{xia2022cscnet}. We divide the baselines into two groups due to their setting differences. All baseline methods except S-CSR report the minimal error out of 20 sampled trajectories. S-CSR achieved better results by predicting 20 possible states in each step, and it is the only method adopting such sampling to our best knowledge. We refer to the former as standard-sampling and the latter as ultra-sampling. We compare NSP-SFM with S-CSR and other baseline methods under their respective settings.

Standard-sampling results are shown in \Tabref{sampling}. On SDD, NSP-SFM outperforms the best baseline Y-Net by 16.94\% and 10.46\% in ADE and FDE, respectively. In ETH/UCY, the improvement on average is 5.56\% and 11.11\% in ADE and FDE, with the maximal ADE improvement 12.5\% in UNIV and the maximal FDE improvement 27.27\% in ETH. We also compare NSP-SFM with S-CSR in \Tabref{ultraSampling}. NSP-SFM outperforms S-CSR on ETH/UCY by 70\% and 62.5\% on average in ADE and FDE. In SDD, the improvement is 35.74\% and 0.3\% (\Tabref{ultraSampling}). S-CSR is stochastic and learns per-step distributions, which enables it to draw 20 samples for every step during prediction. Therefore, the min error of S-CSR is much smaller than the other baselines. Similarly, NSP-SFM also learns a per-step distribution (the  function) despite its main behavior being dictated by a deterministic system. Under the same ultra-sampling setting, NSP-SFM outperforms S-CSR.

\begin{table}[tb]
\scriptsize
\begin{center}
\caption{Results on ETH/UCY and SDD based standard-sampling. NSP-SFM outperforms all baseline methods in both ADE and FDE. 20 samples are used in prediction and the minimal error is reported.  in all experiments. The unit is meters on ETH/UCY and pixels on SDD.}
\begin{tabular}{ |p{2cm}|p{1cm}||p{0.9cm}|p{0.9cm}|p{0.9cm}|p{0.9cm}|p{0.9cm}|p{0.9cm}||p{0.9cm}| }
\hline
Methods& Metrics& ETH & Hotel &UNIV & ZARA1 & ZARA2 & AVG &SDD \\
\hline
\multirow{2}*{S-GAN~\cite{gupta2018social}} & ADE & 0.81 & 0.72 & 0.60 & 0.34 & 0.42 & 0.58 & 27.23 \\
& FDE & 1.52 & 1.61 & 1.26 & 0.69 & 0.84 & 1.18 & 41.44 \\
\hline
\multirow{2}*{Sophie~\cite{sadeghian2019sophie}} & ADE & 0.70 & 0.76 & 0.54 & 0.30 & 0.38 & 0.54 & 16.27 \\
& FDE & 1.43 & 1.67 & 1.24 & 0.63 & 0.78 & 1.15 & 29.38 \\
\hline
\multirow{2}*{CF-VAE~\cite{bhattacharyya2019conditional}} & ADE & N/A & N/A &  N/A & N/A &  N/A & N/A & 12.60 \\
& FDE & N/A & N/A &  N/A & N/A &  N/A & N/A & 22.30 \\
\hline
\multirow{2}*{CGNS~\cite{li2019conditional}} & ADE & 0.62 & 0.70 & 0.48 & 0.32 & 0.35 & 0.49 &15.6 \\
& FDE & 1.40 & 0.93 & 1.22 & 0.59 & 0.71 & 0.97 & 28.2 \\
\hline
\multirow{2}*{NEXT~\cite{liang2019peeking}} & ADE & 0.73 & 0.30 & 0.60 & 0.38 & 0.31 & 0.46 & N/A \\
& FDE & 1.65 & 0.59 & 1.27 & 0.81 & 0.68 & 1.00 & N/A \\
\hline
\multirow{2}*{P2TIRL~\cite{deo2020trajectory}} & ADE & N/A & N/A &  N/A & N/A &  N/A & N/A & 12.58 \\
& FDE & N/A & N/A &  N/A & N/A &  N/A & N/A & 22.07 \\
\hline
\multirow{2}*{SimAug~\cite{liang2020simaug}} & ADE & N/A & N/A &  N/A & N/A &  N/A & N/A & 10.27 \\
& FDE & N/A & N/A &  N/A & N/A &  N/A & N/A & 19.71 \\
\hline
\multirow{2}*{PECNet~\cite{mangalam2020not}} & ADE & 0.54 & 0.18 & 0.35 & 0.22 & 0.17 & 0.29 & 9.96 \\
& FDE & 0.87 & 0.24 & 0.60 & 0.39 & 0.30 & 0.48 & 15.88 \\
\hline
\multirow{2}*{Traj++~\cite{salzmann2020trajectron++}} & ADE & 0.39 & 0.12 & \textbf{0.20} & \textbf{0.15} & \textbf{0.11} & 0.19 & N/A \\
& FDE & 0.83 & 0.21 & 0.44 & 0.33 & 0.25 & 0.41 & N/A \\
\hline
\multirow{2}*{Multiverse~\cite{liang2020garden}} & ADE & N/A & N/A &  N/A & N/A &  N/A & N/A & 14.78 \\
 & FDE & N/A & N/A &  N/A & N/A &  N/A & N/A & 27.09 \\
\hline
\multirow{2}*{Y-net~\cite{mangalam2021goals}} & ADE & 0.28 & 0.10 & 0.24 & 0.17 & 0.13 & 0.18 &7.85 \\
& FDE & 0.33 & 0.14 & 0.41 & \textbf{0.27} & 0.22 & 0.27 & 11.85 \\
\hline
\multirow{2}*{SIT~\cite{su2021pedestrian}} & ADE & 0.38 & 0.11 & \textbf{0.20} & 0.16 & 0.12 & 0.19 & N/A \\
& FDE & 0.88 & 0.21 & 0.46 & 0.37 & 0.27 & 0.44 & N/A \\
\hline
Social & ADE & 0.66 & 0.34 & 0.39 & 0.27 & 0.24 & 0.38 & N/A \\
DualCVAE~\cite{gao2022social}& FDE & 1.18 & 0.61 & 0.74 & 0.48 & 0.42 & 0.69 & N/A \\
\hline
\multirow{2}*{CSCNet~\cite{xia2022cscnet}} & ADE & 0.51 & 0.22 & 0.36 & 0.31 & 0.47 & 0.37 & 14.63 \\
& FDE & 1.05 & 0.42 & 0.81 & 0.68 & 1.02 & 0.79 & 26.91 \\
\hline
NSP-SFM & ADE & \textbf{0.25} & \textbf{0.09} & 0.21 & 0.16 & 0.12 & \textbf{0.17} & \textbf{6.52} \\
(Ours)& FDE & \textbf{0.24} & \textbf{0.13} & \textbf{0.38} & \textbf{0.27} & \textbf{0.20} & \textbf{0.24} & \textbf{10.61} \\
\hline
\end{tabular}
\label{tab:sampling}
\end{center}
\end{table}


\begin{table}[tb]
\scriptsize
\begin{center}
\caption{Results on ETH/UCY (left) and SDD (right) based on ultra-sampling. 20 samples per step are used for prediction and the overall minimal error is reported. NSP-SFM outperforms S-CSR on both datasets in ADE and FDE.}
\begin{tabular}{ |p{1.6cm}|p{1cm}||p{0.9cm}|p{0.9cm}|p{0.9cm}|p{0.9cm}|p{0.9cm}|p{0.9cm}||p{0.9cm}| }
\hline
Methods & Metrics & ETH & Hotel & UNIV & ZARA1 & ZARA2 & Avg & SDD \\
\hline
\multirow{2}*{S-CSR~\cite{zhou2021sliding}} & ADE & 0.19 & 0.06 & 0.13 & 0.06 & 0.06 & 0.10 & 2.77 \\
& FDE & 0.35 & \textbf{0.07} & 0.21 & 0.07 & 0.08 & 0.16 & 3.45 \\
\hline
\multirow{2}*{NSP-SFM} & ADE & \textbf{0.07} & \textbf{0.03} & \textbf{0.03} & \textbf{0.02} & \textbf{0.02} & \textbf{0.03} & \textbf{1.78} \\
& FDE & \textbf{0.09} & \textbf{0.07} & \textbf{0.04} & \textbf{0.04} & \textbf{0.04} & \textbf{0.06} & \textbf{3.44} \\
\hline
\end{tabular}
\label{tab:ultraSampling}
\end{center}
\end{table}




\subsection{Generalization to Unseen Scenarios}
We evaluate NSP-SFM on significantly different scenarios after training. We increase the scene density as it is a major factor in pedestrian dynamics~\cite{narang2015generating}. This is through randomly sampling initial and goal positions and let NSP-SFM predict the trajectories. Since there is no ground truth, to evaluate the prediction plausibility, we employ collision rate because it is widely adopted~\cite{liu2021social} and parsimonious: regardless of the specific behaviors of agents, they do not penetrate each other in the real world. The collision rate is computed based on the percentage of trajectories colliding with one another. We treat each agent as a disc with radius  in ECY/UCY and  pixels in SDD. Once the distance between two agents falls below , we count the two trajectories as in collision. Due to the tracking error and the distorted images, the ground truth  is hard to obtain. We need to estimate . If it is too large, the collision rate will be high in all cases; otherwise the collision rate will be too low, e.g.,  will give  collision rate all the time. Therefore, we did a search and found that the above values are reasonable as they keep the collision rate of the ground-truth data approximately zero. We show two experiments. The first is the collision rate on the testing data, and the second is scenarios with higher densities. While the first is mainly to compare the plausibility of the prediction, the second is to test the model generalizability. For comparison, we choose two state-of-the-art baseline methods: Y-net and S-CSR. Y-net is published which achieves the best performance, while S-CSR is unpublished but claims to achieve better performance.

\begin{table}[b]
\begin{center}
\caption{Collision rate on testing data in ETH/UCY and SDD. NSP-SFM universally outperforms all baseline methods.}
\begin{tabular}{ |p{1.5cm}||p{1.1cm}|p{1.1cm}|p{1.5cm}|p{1.5cm}|p{1.5cm}|p{1.3cm}| |p{1.3cm}|}
 \hline
  Methods& ETH & Hotel & UNIV & ZARA1 & ZARA2 & Avg & SDD \\
 \hline
 Y-net & 0 & 0 & 1.51\% & 0.82\% & 1.31\% & 0.73\% & 0.47\% \\
 \hline
 S-CSR & 0 & 0  & 1.82\% & 0.41\% & 1.31\% & 0.71\% & \textbf{0.42\%} \\
 \hline
 NSP-SFM & \textbf{0} & \textbf{0} & \textbf{1.48\%} & \textbf{0} & \textbf{0.66\%} & \textbf{0.43\%} & \textbf{0.42\%}\\
 \hline
\end{tabular}
\label{tab:collisionETH}
\end{center}
\end{table}

\begin{table}[tb]
\scriptsize 
\begin{center}
\caption{Collision rates of the generalization experiments on ZARA2 (Z) and coupa0 (C). NSP-SFM shows strong generalizability in unseen high density scenarios.}
\begin{tabular}{ |p{1.3cm}||p{1cm}|p{1cm}|p{1cm}|p{1.2cm}||p{1cm}|p{1cm}|p{1cm}| p{1.2cm}| }
 \hline
 Methods& Z(1) & Z(2) & Z(3) & Z(avg)& C(1) & C(2) & C(3)& C(avg)\\
 \hline
 Y-net  & 1.8\% & 2.2\% & 2.0\% &  2.0\% & 2.8\% & 2.9\% & 3.8\%& 3.2\% \\
 S-CSR  & 3.2\% & 2.4\% & 1.8\% & 2.5\%  & 2.5\% & 1.7\% & 1.9\% & 2.0\% \\
 NSP-SFM  & \textbf{0.2\%} & \textbf{0.2\%} & \textbf{0} & \textbf{0.1\%}  & \textbf{0.6\%} & \textbf{0.6\%} & \textbf{0.6\%} & \textbf{0.6\%} \\
 \hline
\end{tabular}
\label{tab:collisionSim}
\end{center}
\end{table}

\Tabref{collisionETH} shows the comparison of the collision rate. NSP-SFM outperforms the baseline methods in generating trajectories with fewer collisions. Y-net and S-CSR also perform well on the testing data because their predictions are close to the ground-truth. Nevertheless, they are still worse than NSP-SFM. Next, we test drastically different scenarios. We use ZARA2 and coupa0 (a sub-dataset from SDD) as the environment and randomly sample the initial positions and goals for 32 and 50 agents respectively. Because the highest number of people that simultaneously appear in the scene is 14 in ZARA2 and 11 in coupa0, we effectively increase the density by 2-5 times. For NSP-SFM, the initial and goal positions are sufficient. For Y-net and S-CSR which require 8 frames (3.2 Seconds) as input, we use NSP-SFM to simulate the first 8 frames of each agent, then feed them into both baselines. \Tabref{collisionSim} shows the results of three experiments. Since the density is significantly higher than the data, both Y-net and S-CSR cause much higher collision rate. While NSP-SFM's collision rate also occasionally increases (i.e. SDD) compared with \Tabref{collisionETH}, it is far more plausible.

\subsection{Interpretability of Prediction}
\begin{figure}[tb]
\centering
\includegraphics[width=0.8\textwidth]{inter_all.png}
\caption{Red dots are observed, green dots are our prediction and black dots are the ground-truth. Blue dots are pedestrians. ,  and  are shown as yellow, light blue and black arrows for a person. The orange areas are the view field for avoiding collisions with other people (left) and the environment (middle). They provide plausible explanations of individual behaviors such as steering. Left and middle show the major influence of different forces. Right shows motion randomness captured by our model.}
\label{fig:interpretability}
\end{figure}

Unlike black-box deep learning methods, NSP-SFM has an embedded explainable model. While predicting a trajectory, NSP can also provide plausible explanations of the motion, by estimating the `forces' exerted on a specific person. This potentially enables NSP-SFM to be used in applications beyond prediction, e.g. behavior analysis~\cite{zeng2014application}. \Figref{interpretability} Left shows that a person, instead of directly walking towards the goal, steered upwards (the green trajectory in the orange area). This could be explained by the strong repulsive force (the light blue arrow) which is generated by the potential collisions with the agents in front of this person, in line with existing studies~\cite{narang2015generating}. Similar explanations can be made in \Figref{interpretability} Middle, where all three forces are present.  (the black arrow) is the most prominent, as expected, as the person is very close to the car. The repulsive force (light blue arrow) also plays a role due to the person in front of the agent (the blue dot in the orange area). 

\Figref{interpretability} Right shows an example where motion randomness is captured by NSP. In this example, there was no other pedestrian and the person was not close to any obstacle. However, the trajectory still significantly deviates from a straight line, which cannot be fully explained by e.g. the principle of minimal energy expenditure~\cite{virtanen2013energy}. The deviation could be caused by unobserved factors, e.g. the agent changing her goal or being distracted by something on the side. These factors do not only affect the trajectory but also the dynamics, e.g. sudden changes of velocity. These unobserved random factors are implicitly captured by the CVAE in NSP-SFM. More results are in the supplementary material.

We emphasize that NSP-SFM merely provides plausible explanations and by no means the only possible explanations. Although explaining behaviors based on physics models has been widely used, there can be alternative explanations~\cite{wang2016understanding}. Visualizing the forces is merely one possible way. Theoretically, it is also possible to visualize deep neural networks, e.g. layer activation. However, it is unclear how or which layer to visualize to explain the motion.  Overall, NSP-SFM is more explainable than black-box deep learning. 

\subsection{Ablation Study}

\begin{table}[tb]
\begin{center}
\caption{Ablation study on SDD. (w/o) means without CVAE and (w) means with CVAE.  is goal attraction only and NSP-SFM is all three forces.}
\begin{tabular}{ |p{1.2cm}||p{2cm}|p{2.5cm}|p{2cm}| }
 \hline
 SDD & (w/o) & NSP-SFM(w/o) & NSP-SFM(w)\\
 \hline
 ADE & 6.57 & 6.52 & 1.78\\
 FDE & 10.68 & 10.61 & 3.44\\
 \hline
\end{tabular}
\label{tab:ablation}
\end{center}
\end{table}

\begin{figure}[tb]
\centering
\includegraphics[width=\textwidth]{ablation.png}
\caption{Red, green and cyan dots are observations, prediction and ground-truth respectively. From left to right: ground truth, (w/o), NSP-SFM(w/o) and NSP-SFM(w).}
\label{fig:ablation}
\end{figure}



To further investigate the roles of different components, we conduct an ablation study on SDD with three settings: (w/o) with goal attraction only, i.e. omitting other components such as ,  and dynamics stochasticity; NSP-SFM (w/o) without dynamics stochasticity; and NSP-SFM (w) the full model. The results are shown in \Tabref{ablation}. Interestingly, (w/o) can already achieve good results. This is understandable as it is trained first in our progressive training scheme and catches most of the dynamics. NSP-SFM (w/o) further improves the performance. The improvement seems to be small but we find the other repulsive forces are crucial for trajectories with irregular geometries such as avoiding obstacles. Further NSP-SFM (w) significantly improves the results because it enables NSP to learn the dynamics stochasticity via a per-step distribution. We show one example in \Figref{ablation} in all settings. More ablation experiments can be found in the supplementary material.



\section{Conclusions, Limitations, and Future Work}


In this paper, we have proposed a new Neural Differential Equation model for trajectory prediction. Through exhaustive evaluation and comparison, our model, Neural Social Physics, has proven to be more accurate in trajectory prediction, generalize well in significantly different scenarios and can provide possible explanations for motions. The major limitation of NSP lies in the physics model, which overly simplifies people into 2D particles. In real-world scenarios, people are much more complex, and their motions can be influenced by other factors such as their affective states or interact with dense scenarios~\cite{bera2014realtime,bera2017aggressive}. It would be useful to extend our NSP framework by incorporating these ideas and handle complex  systems such as fluids/fields/agent-based modeling can be adopted to replace the components in \Eqnref{timeDiscretization}. In the future, we would like to extend the current framework to model high-density crowds, where continuum models or reciprocal  velocity obstacles need to be used. We would also like to incorporate learning-based collision detection techniques into this framework~\cite{tan2021lcollision,tan2022n}.

\paragraph{Acknowledgements} This project has received funding from the European Unionâ€™s Horizon 2020 research and innovation programme under grant agreement No 899739 CrowdDNA.

 
\bibliographystyle{splncs04}
\bibliography{egbib}

\newpage
\begin{table}[!b]
\centering
\caption{Collision rates of the generalization experiments on Coupa0. Results of Y-net, S-SCR and NSP on 50, 74, 100, 150 and 200 agents are shown in corresponding tables, where (1), (2) and (3) denote three intervals for calculating the collision rate.}

\subtable[50 Agents]{
\begin{tabular}{ |p{1.5cm}||p{0.8cm}|p{0.8cm}|p{0.8cm}|p{0.8cm}| }
 \hline

 Methods & (1) & (2) & (3) & avg \\
 \hline
 Y-net & 2.8\%  & 2.9\% & 3.8\% & 3.2\%\\ 
 \hline
 S-CSR & 2.5\%  & 1.7\% & 1.9\% & 2.0\%\\ 
 \hline 
 NSP(ours) & 0.6\%  & 0.6\% & 0.6\% & 0.6\% \\
 \hline 
\end{tabular}
}
\subtable[74 Agents]{
\begin{tabular}{ |p{1.5cm}||p{0.8cm}|p{0.8cm}|p{0.8cm}|p{0.8cm}| }
 \hline

 Methods & (1) & (2) & (3) & avg \\
 \hline
 Y-net & 3.8\%  & 4.8\% & 3.0\% & 3.9\%\\ 
 \hline
 S-CSR & 0.9\%  & 0.9\% & 1.5\% & 1.1\%\\ 
 \hline 
 NSP(ours) & 0.2\%  & 0.3\% & 0.5\% & 0.3\% \\
 \hline 
\end{tabular}
}
\subtable[100 Agents]{
\begin{tabular}{ |p{1.5cm}||p{0.8cm}|p{0.8cm}|p{0.8cm}|p{0.8cm}| }
 \hline
 Methods & (1) & (2) & (3) & avg \\
 \hline
 Y-net  & 4.2\% & 5.2\%  & 7.6\% & 5.7\%\\ 
 \hline
 S-CSR & 0.9\% & 1.1\%  & 0.8\% & 0.9\%\\ 
 \hline 
 NSP(ours) & 0.3\% & 0.7\%  & 0.4\% & 0.5\%\\
 \hline 
\end{tabular}
}
\subtable[150 Agents]{
\begin{tabular}{ |p{1.5cm}||p{0.8cm}|p{0.8cm}|p{0.8cm}|p{0.8cm}| }
 \hline
 Methods & (1) & (2) & (3) & avg \\
 \hline
 Y-net & 4.9\%  & 4.0\% & 3.4\% & 4.1\% \\ 
 \hline
 S-CSR & 0.6\%  & 1.0\% & 1.7\% & 1.1\%\\ 
 \hline 
 NSP(ours) & 0.2\%  & 0.5\% & 1.0\% & 0.6\%\\
 \hline
\end{tabular}
}
\subtable[200 Agents]{
\begin{tabular}{ |p{1.5cm}||p{0.8cm}|p{0.8cm}|p{0.8cm}|p{0.8cm}| }
 \hline
 Methods & (1) & (2) & (3) & avg \\
 \hline
  Y-net &  5.9\% & 4.0\%  & 3.5\% & 4.5\%\\ 
 \hline
 S-CSR & 0.6\% & 0.9\%  & 2.0\% & 1.2\%\\ 
 \hline 
 NSP(ours) & 0.2\% & 0.5\%  & 0.8\% & 0.5\%\\
 \hline
\end{tabular}
}
\label{tab:collision_supp}
\end{table}

\noindent
\textbf{\Large A Additional Experiments}
\vspace{15pt}

\noindent
\textbf{\large A.1 Generalization to Unseen Scenarios}
\vspace{10pt}

\noindent
We use the collision rate to evaluate prediction plausibility. We first elaborate on the definition of the collision rate and then show more experimental results. Provided there are N agents in a scene, we consider their collision rates during a period of time such as 4.8 seconds which is widely used to evaluate trajectory predictions~\cite{mangalam2020not,mangalam2021goals,zhou2021sliding}. We count one collision if the minimum distance between two agents is smaller than 2r at any time, where r is the radius of a disc representing an agent. The maximum possible number of collisions is . The final collision rate is defined as:

where  is the number of collisions. 

We show more results on the scene, coupa0, with different numbers of agents. We chose coupa0 because it is a large space and can accommodate many people. The highest number of people simultaneously in the environment in the original data is merely 11. Therefore, this is a good scene to show how different methods can generalize to higher densities when learning from low density data. In each experiment, the agents are randomly initialized with different initial positions, initial velocities and goals near the boundary of the scene, which is sufficient for our method to simulate. Therefore, we use NSP to predict trajectories of 30 seconds (t = 0 to 29) at FPS = 10 for all agents. We sample three intervals out of every trajectory, from t = 0 to 8, t = 4 to 12 and t = 8 to 16, where the density in the central area reaches the highest during t=8 to 16. For each interval (8 seconds long), we subsample at FPS = 2.5 to get 20 frames, where the first 8 frames are used as input for Y-net~\cite{mangalam2021goals} and S-CSR~\cite{zhou2021sliding}. The remaining 12 frames and the predictions (12 frames) of Y-net and S-CSR are used to calculate the collision rate. Before prediction, all methods are trained on the training dataset of SDD under the same setting explained in the main paper.

The results are shown in \Tabref{collision_supp}. We tested 50, 74, 100, 150 and 200 agents on the aforementioned three methods including ours. We can see that our method is always the best in the collision rate under different settings. Although its collision rate increases with the growth of the number of agents, our method is still the best compared with the baselines and our predictions are more plausible. In addition, we also plot the relation between the collision rate (and the number of collisions) and the agent number ranging from 50 to 200 in \Figref{col_all_supp}. Y-net is worse than S-CSR and NSP. In addition, although the trend of NSP and S-CSR are similar, the number of collisions of S-CSR increases faster than NSP. Finally, some visualization results can be found in~\Figref{col_vis_supp}. Here, every green disc has a radius of 7.5 pixels. When two green discs intersect, they collide with each other.~\Figref{col_vis_supp} demonstrates that our method (NSP) has better performance in avoiding collisions than Y-net and S-CSR.         


\begin{figure}[tb]
\centering
\subfigure[Collision Rate]{\includegraphics[width=0.47\textwidth]{collision_rate.png}} 
\subfigure[Number of Collisions]{\includegraphics[width=0.47\textwidth]{nocollision.png}}
\caption{The collision rate and the number of collisions against the number of agents are shown in (a) and (b) respectively. Both of horizontal axes represent the number of agents from 50 to 200. The vertical axes in (a) and (b) represent the collision rate and the number of collisions respectively.  }
\label{fig:col_all_supp}
\end{figure}


\begin{figure}[tb]
\centering
\subfigure[74 Agents]{\includegraphics[width=0.47\textwidth]{collision_74.png}} 
\subfigure[100 Agents]{\includegraphics[width=0.47\textwidth]{collision_100.png}}
\\ \centering
\subfigure[150 Agents]{\includegraphics[width=0.47\textwidth]{collision_150.png}} 
\subfigure[200 Agents]{\includegraphics[width=0.47\textwidth]{collision_200.png}}
\caption{The visualization results of generalization to 74, 100, 150 and 200 agents on coupa0 are shown in (a), (b), (c) and (d) respectively. For each experimental setting, visualization results of NSP, Y-net and S-CSR are at the same frame. We amplify the area of red ellipse to boxes with yellow borders for better visualization performance.}
\label{fig:col_vis_supp}
\end{figure}

\vspace{15pt}
\noindent
\textbf{\large A.2 Interpretability of Prediction}
\vspace{10pt}

\noindent
More examples of interpretability are shown in~\Figref{interpret_supp}. In \Figref{interpret_supp} (1)-(2), we show the influence of different three forces, ,  and , on the whole trajectory of an agent. In \Figref{interpret_supp} (3)-(4), we choose two consecutive moments of one agent for analysis. In \Figref{interpret_supp} (1), instead of directly aiming for the goal, the agent suddenly turns (at the intersection between red and green dots) due to the incoming agents (the three blue dots under the green dots). The result is a result of major influence from  and . Similarly, the agent in \Figref{interpret_supp} (2) did not need to avoid other agents but still did not directly walk towards the goal, because of  from the grass. In \Figref{interpret_supp} (3)-(4), we show the detailed analysis of forces at two consecutive time steps of the same agent, where  is from the lawn which is a 'weakly repulsive area'.  
More examples where randomness is captured by our model are shown in \Figref{randomness_supp}. 

\begin{figure}[tb]
\centering
\includegraphics[width=\textwidth]{explanation.png}
\caption{Examples of interpretability. Red dots are observed, green dots are our prediction. Bule dots in (1), (3) and (4) are other pedestrians at time step 7, 16 and 17 respectively. We show the influence of all forces, ,  and , on the whole trajecroty in (1) and (2). We display detailed analysis of three forces at two consecutive time steps of the same agent, where ,  and  are shown as yellow, light blue and black arrows respectively. }
\label{fig:interpret_supp}
\end{figure}

\begin{figure}[tb]
\centering
\includegraphics[width=0.8\textwidth]{uncertainty_cvae.png}
\caption{Motion randomness is captured by our model. Red dots are observed, green dots are our prediction and black dots are the
ground-truth.}
\label{fig:randomness_supp}
\end{figure}

\vspace{15pt}
\noindent
\textbf{\large A.3 Ablation Experiments}
\vspace{10pt}

\noindent
We conduct more ablation experiments to further validate our design decisions and explore the effect of components of our model. The ablation studies on the network architectures focuses on the Goal-Network and the Collision-Network. The main variants are with/without LSTM to show the importance of the temporal modeling for learning  and , and replacing the MLPs with simple two-layer MLPs. \Tabref{ae1_supp} shows the results on SDD. We can see that the temporal modeling and the original MLPs make our model achieve the best performance.
To understand the role of each component in our model, we take social force model (SFM) as the baseline and incrementally add components from our model. The results are shown in \Tabref{ae2_supp}. We tried our best to manually find good parameter values: , =25/50 and =65. We adopted the same way with our model to sample destinations for SFM. Then we only learn  and . At last, the result of the full model without CVAE is given. The performance is better when more components are added.

\begin{table}[t]
\begin{small}
\begin{center}
\caption{Ablation experiments on network architecture. Goal-Network and the Collision-Network possess the same architecture under each experimental setup.}
\label{tab:ae1_supp}
\begin{tabular}{ |p{1.8cm}||p{2.4cm}|p{1.8cm}|}
\hline
ADE & Two layers MLP & Full MLP \\
\hline
w/o LSTM & 6.83 & 6.61 \\ 
\hline
with LSTM & 6.66 & \textbf{6.52}\\
\hline
\end{tabular}
\end{center}
\end{small}
\end{table}

\begin{table}
\begin{small}
\begin{center}
\caption{Ablation experiments on SDD. Different components from our model are added incrementally}
\label{tab:ae2_supp}
\begin{tabular}{ |p{1.2cm}||p{2.0cm}|p{2.7cm}|p{1.1cm}|}
\hline
=25 & hand-tuned & learned  and  & NSP\\
\hline
ADE & 8.32 & 6.53 & 6.52 \\ 
\hline
FDE & 10.97 & 10.61 & 10.61\\
\hline
\hline
=50 & hand-tuned & learned  and  & NSP\\
\hline
ADE & 7.54 & 6.53 & 6.52 \\ 
\hline
FDE & 10.81 & 10.61 & 10.61\\
\hline
\end{tabular}
\end{center}
\end{small}
\end{table}


\vspace{15pt}
\noindent
\textbf{\Large B Details of the Neural Social Physics Model}
\vspace{15pt}

\noindent
In this section, we elaborate the details of the Goal Sampling Network (GSN) and the conditional Variational Autoencoder (CVAE) in our model.

\vspace{15pt}
\noindent
\textbf{\large B.1 Goal Sampling Network}
\vspace{10pt}

\noindent
The main components of the GSN are two U-nets~\cite{ronneberger2015u} as illustrated in~\Figref{gsn_supp}. We first feed the scene image  to a U-net, , to get its corresponding environment pixel-wise segmentation with dimension of .  and  are the height and width of , and  is the number of classes for segmentation. The segmantation maps are byproducts of the GSN from~\cite{mangalam2021goals}. NSP can use manually annotated or automatically segmented environment maps to calculate , but using segmentation maps from the GSN is more efficient. Then the past trajectories  are converted into M+1 trajectory heatmaps by:

where  is the pixel coordinate on the heatmap and  is the pixel coordinate on the scene image . Then, we concatenate these trajectory heatmaps and the segmentation map to get the input with dimension of  for the network .  will output a non-parametric probability distribution map, , with dimensions . Every pixel in  has a corresponding probability value between 0 and 1, and their sum is equal to 1. Details of these two U-nets can be found in~\cite{mangalam2021goals}. We train the GSN by minimizing the Kullbackâ€“Leibler divergence between predicted  and its ground truth . We assume that  is a discrete gaussian distribution with a mean at the position of the ground-truth goal and a hyper-parameter variance . During testing, instead of picking the position with highest probability, we adopt the test-time sampling trick introduced by~\cite{mangalam2021goals} to sample goals for better performance.

\begin{figure}[tb]
\centering
\includegraphics[width=0.8\textwidth]{goal_sampling_network.png}
\caption{Model Architecture of Goal Sampling Network. The detailed network architecture of two U-nets,  and , can be found in~\cite{mangalam2021goals}.}
\label{fig:gsn_supp}
\end{figure}

\vspace{15pt}
\noindent
\textbf{\large B.2 Conditional Variational Autoencoder}
\vspace{10pt}

\noindent
We model the dynamics stochasticity for each agent individually by using a CVAE as illustrated in~\Figref{cvae_supp}. Red connections are only used in the training phase. Given an agent  and his/her destination, a deterministic prediction  without dynamics stochasticity is first calculated from ,  and  and a semi-implicit scheme. During training time, we use the corresponding ground truth  to calculate the error , and feed  into an encoder  to get the feature . The brief history  is encoded as  by using an encoder . We concatenate  with  and encode it using a latent encoder to yield the parameters  of the gaussian distribution of the latent variable Z. We sample Z, concatenate it with  for history information, and decode using the decoder  to acquire our guess for stochasticity . Finally, the estimated stochasticity will be added to the deterministic prediction  to get our final prediction . During testing time, the ground truth  is unavailable. Therefore, we sample the latent variable Z from a gaussian distribution  where  is a hyper-parameter. We concatenate the sampled Z and  to decode directly using the learned decoder  to get the estimate of stochasticity . We can produce final prediction  using the same way as the training phase. Encoders , ,  and the decoder  are all multi-layer perceptrons (MLP) with dimensions indicated in the square brackets in~\Figref{cvae_supp}.

\begin{figure}[tb]
\centering
\includegraphics[width=\textwidth]{cvae_supp.png}
\caption{The architecture of the CVAE, where  is the intermediate prediction out of our force model and . Encoder , ,  and decoder  are all MLP networks with dimensions indicated in the square brackets. Red connections are only used in the training phase.}
\label{fig:cvae_supp}
\end{figure}

\begin{table}[t]
\begin{center}
\caption{Hyper-parameters for all six datasets.}
\begin{tabular}{ |p{1.8cm}||p{1.3cm}|p{1.3cm}|p{1.3cm}|p{1.3cm}|p{1.3cm}|p{1.3cm}|}
 \hline
 Hyper-Para & ETH & Hotel & UNIV & ZARA1 & ZARA2 & SDD \\
 \hline
 a() & 1 & 1 & 1 & 1 & 1 & 1 \\
 \hline
 b() & 0.1 & 0.1 & 2.2 & 1.6 & 1.4 & 0.4 \\
 \hline
 a() & 50 & 50 & 50 & 50 & 50 & 100 \\
 \hline
 b() & 0 & 0 & 0 & 0 & 0 & 0 \\
 \hline
 &  &  &  &  &  & \\
 \hline
  & 75 & 75 & 75 & 75 & 75 & 100 \\
 \hline
  & 50 & 50 & 50 & 75 & 75 & 50 \\
 \hline
  & 4 & 4 & 4 & 4 & 4 & 4 \\
 \hline
  & 1.3 & 1.3 & 1.3 & 1.3 & 1.3 & 1.3 \\
 \hline 
  & N/A & N/A & N/A & N/A & N/A & 0.2 \\
 \hline
 
\end{tabular}

\label{tab:hyperp_supp}
\end{center}
\end{table}

\vspace{15pt}
\noindent
\textbf{\large C Implementation Details}
\vspace{15pt}

\noindent
We use ADAM as the optimizer to train the Goal-Network, Collision-Network and  with a learning rate between  and , and to train the CVAE with a learning rate between  and . When we train the CVAE of our model, the training data is scaled by 0.005 to balance reconstruction error and KL-divergence in . The hyper-parameter  in  is set to 1. Concrete structures of all sub-network are shown in \Figref{cvae_supp}. In all experiments, we follow existing work in using 20-frame samples. For trajectories with less than 20 frames, we treat them as observed dynamic obstacles and do not predict their trajectories. 

For the Goal-Network, instead of learning parameter  directly, we set  where  and  are hyper-parameters. We list all hyper-parameters of our model in \Tabref{hyperp_supp}. We segment scene images into two classes and three classes on ETH/UCY and SDD, respectively. The two classes on ETH/UCY are `walkable area' and `unwalkable area'. Three classes on SDD include `walkable area', `unwalkable area' and `weakly repulsive area' that some people tend to avoid such as lawns. The calculation of  on ETH/UCY has been introduced in our main paper. On SDD, we calculate the position of the obstacle  and the position of the weak obstacle  (i.e. in the weakly repulsive area) by averaging pixels that are classified as `unwalkable area' and `weak repulsive area' respectively. Then, the  consists of two repulsive forces from   and  as shown in \Eqnref{env_supp}, where the parameter  is shared and an additional hyper-parameter  is introduced for :




\end{document}
