 \documentclass{article}

\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{amsthm}

\usepackage{xcolor}
\usepackage{stmaryrd}
\usepackage{fullpage}
\usepackage{wasysym}
\usepackage{pifont}
\usepackage{hyperref}
\hypersetup{colorlinks=true,linkcolor=black,citecolor=black}
\usepackage{cite}
\usepackage{comment}
\usepackage{setspace}












\usepackage[noend]{algorithmic} 
\usepackage{algorithm,caption}

\newcounter{thmcount}
\newcounter{ass}
\newcounter{notec}
\newcounter{obscount}
\newcounter{propcount}
\newtheorem{thm}[thmcount]{Theorem}
\newtheorem{lem}[thmcount]{Lemma}
\newtheorem{defn}[thmcount]{Definition}
\newtheorem{assume}[ass]{Assumption}
\newtheorem{observation}[obscount]{Observation}









\definecolor{nts}{rgb}{.8,.1,.8}

\definecolor{hilite}{rgb}{.1,0,.9}
\definecolor{clear}{rgb}{.8,.8,.8}

\definecolor{ozc}{rgb}{.8,.4,.2}
\definecolor{lhc}{rgb}{.4,.2,.6}
\definecolor{lsc}{rgb}{.2,.6,.4}






{\makeatletter
 \gdef\xxxmark{\expandafter\ifx\csname @mpargs\endcsname\relax \expandafter\ifx\csname @captype\endcsname\relax \marginpar{xxx}\else
       xxx \fi
   \else
     xxx \fi}
 \gdef\xxx{\@ifnextchar[\xxx@lab\xxx@nolab}
 \long\gdef\xxx@lab[#1]#2{{\bf [\xxxmark #2 ---{\sc #1}]}}
 \long\gdef\xxx@nolab#1{{\bf [\xxxmark #1]}}
\long\gdef\xxx@lab[#1]#2{}\long\gdef\xxx@nolab#1{}\gdef\turnoffxxx{\long\gdef\xxx@lab[##1]##2{}\long\gdef\xxx@nolab##1{}}}


\newcounter{oztix}
\setcounter{oztix}{1}
\newcommand{\ozverone}{A} 
\newcommand{\shl}[1]{\textcolor{hilite}{\textbf{#1}}}\newcommand{\ehl}{}
\newcommand{\oz}[1]{\textcolor{ozc}{\xxx[Oz~\ozverone.\arabic{oztix}\addtocounter{oztix}{1}]{#1}}}
\newcommand{\ozclear}[1]{\textcolor{clear}{\xxx[Oz~\ozverone.\arabic{oztix}\addtocounter{oztix}{1}]{#1}}}

\newcounter{lhtix}
\setcounter{lhtix}{1}
\newcommand{\lhverone}{A} 
\newcommand{\lisa}[1]{\textcolor{lhc}{\xxx[LH~\lhverone.\arabic{lhtix}\addtocounter{lhtix}{1}]{#1}}}
\newcommand{\lisaclear}[1]{\textcolor{clear}{\xxx[LH~\lhverone.\arabic{lhtix}\addtocounter{lhtix}{1}]{#1}}}

\newcounter{lstix}
\setcounter{lstix}{1}
\newcommand{\lsverone}{A} 
\newcommand{\linda}[1]{\textcolor{lsc}{\xxx[ls~\lsverone.\arabic{lstix}\addtocounter{lstix}{1}]{#1}}}
\newcommand{\lindaclear}[1]{\textcolor{clear}{\xxx[ls~\lsverone.\arabic{lstix}\addtocounter{lstix}{1}]{#1}}}






\newcommand{\ozc}[1]{\ens{\mbox{\textcolor{ozc}{\textbf{#1} -Oz}}}}
\newcommand{\lhc}[1]{\ens{\mbox{\textcolor{lhc}{\textbf{#1} -LH}}}}
\newcommand{\lsc}[1]{\ens{\mbox{\textcolor{lsc}{\textbf{#1} -Linda}}}}


\newcommand{\imp}[1]{\textcolor{Red}{#1}}					\newcommand{\fade}[1]{\textcolor{LightGrey}{#1}}
\newcommand{\nts}[1]{\textcolor{nts}{\ens{\rightarrow} #1 \ens{\leftarrow}}}		

\newcommand{\ntsm}[1]{\ens{\nts{#1}}}						\newcommand{\plchold}[1]{\textcolor{clear}{\uppercase{\texttt{#1}}}}					




\newcommand{\ens}[1]{\ensuremath{#1}}					\newcommand{\card}[1]{\ens{|#1|}}							\newcommand{\dotlist}[2]{\ens{#1,\ldots,#2}}
\newcommand{\bigoh}[1]{\ens{\mathcal{O}(#1)}}				\newcommand{\bigom}[1]{\ens{\Omega(#1)}}
\newcommand{\thet}[1]{\ens{\Theta(#1)}}
\newcommand{\varbigoh}[1]{\ens{\mathcal{O}\left(#1\right)}}	\newcommand{\varbigom}[1]{\ens{\Omega\left(#1\right)}}
\newcommand{\varthet}[1]{\ens{\Theta\left(#1\right)}}
\newcommand{\ith}{\ens{i^{\mbox{\hspace{.2mm}\scriptsize th}}}} 
\newcommand{\jth}{\ens{j^{\mbox{\hspace{.2mm}\scriptsize th}}}} 
\newcommand{\kth}{\ens{k^{ \mbox{\hspace{.2mm}\scriptsize th}}}}
\newcommand{\zth}{\ens{z^{ \mbox{\hspace{.2mm}\scriptsize th}}}} 
\newcommand{\setbuild}[2]{\ens{\{#1\ |\ #2\}}}				\newcommand{\usedin}[3]{\textbf{(\small\textcolor{Brown}{Used in \andin{#1}{#2}{}}~#3)}} \newcommand{\andin}[3]{\textbf{\small\textcolor{Brown}{#1~\ref{#2}}~#3}}





\newcommand{\hsp}{\hspace{5mm}}
\newcommand{\nhsp}{\hspace{-5mm}}
\newcommand{\vsp}{\vspace{5mm}}
\newcommand{\nvsp}{\vspace{-5mm}}

\newcommand{\mb}[1]{\mbox{#1}}
\newcommand{\mathc}[1]{\mb{}}
\newcommand{\bylem}[1]{\mathc{\mb{by Lemma~\ref{#1}}}}
\newcommand{\bythm}[1]{\mathc{\mb{by Theorem~\ref{#1}}}}
\newcommand{\byeq}[1]{\mathc{\mb{by Equation~\ref{#1}}}}


\newcommand{\consa}{\ens{\kappa_{a}}}
\newcommand{\consb}{\ens{\kappa_{b}}}
\newcommand{\consc}{\ens{\kappa_{c}}}
\newcommand{\consd}{\ens{\kappa_{d}}}
\newcommand{\anitem}{\ens{x}}

\newcommand{\valn}{\ens{n}}
\newcommand{\valk}{\ens{k}}
\newcommand{\valnmk}{\ens{\valn - \valk + 1}}

\newcommand{\maxthru}{\textsc{MaxThroughput}}
\newcommand{\mincost}{\textsc{MinCost}}
\newcommand{\kofn}{\valk-of-\valn}
\newcommand{\oneofn}{-of-\valn}
\newcommand{\kofnpr}{\kofn{} testing}
\newcommand{\primal}{(P)}
\newcommand{\dual}{(D)}
\newcommand{\strategy}{\ens{T}}
\newcommand{\flowtype}{\ens{\tau}}
\newcommand{\thruput}{\ens{F}}
\newcommand{\kfunc}{\ens{f}}                                                      \newcommand{\stratspace}{\ens{\mathcal{\strategy}}}		\newcommand{\stratspacec}{\ens{\mathcal{\strategy}_c}}	\newcommand{\perm}{\ens{\pi}}										\newcommand{\loadratio}{\ens{M}}									\newcommand{\flowamt}{\ens{m}}									\newcommand{\routing}{\ens{R}}										\newcommand{\commonr}{\ens{r}}                                                                                                      \newcommand{\unsat}{\ens{L}}											\newcommand{\satsuff}{\ens{Q}}										\newcommand{\vecy}{\ens{y}}
\newcommand{\processor}{processor}
\newcommand{\Processor}{Processor}
\newcommand{\megaprocessor}{mega\processor}	
\newcommand{\Megaprocessor}{Mega\processor}											

\newcommand{\smt}{\textsf{SMT} problem}				\newcommand{\cmt}{\textsf{CMT} problem} 		


\newcommand{\retval}[1]{\ens{\anitem_{#1}}}					\newcommand{\pr}[1]{\ens{p_{#1}}}									\newcommand{\qr}[1]{\ens{q_{#1}}}									\newcommand{\op}[1]{\ens{O_{#1}}}									\newcommand{\megaop}[1]{\ens{E_{#1}}}
\newcommand{\test}[1]{\ens{#1}}										\newcommand{\cost}[1]{\ens{c_{#1}}}								\newcommand{\rate}[1]{\ens{r_{#1}}}								\newcommand{\resrate}[1]{\ens{r'_{#1}}}							\newcommand{\landprob}[2]{\ens{g(#1,#2)}}					\newcommand{\cstrat}[2]{\ens{\strategy^c_{#1}(#2)}}				\newcommand{\sstrat}[2]{\ens{\strategy^s_{#1}(#2)}}				\newcommand{\varz}[1]{\ens{z_{#1}}}								\newcommand{\vary}[1]{\ens{y_{#1}}}									

\newcommand{\probgen}[1]{\ens{\mathbf{Pr}\left[#1\right]}}
\newcommand{\varprobgen}[1]{\ens{\mathbf{Pr}\left[#1\right]}}

\newcommand{\hitsum}[2]{\ens{X_{#1,#2}}}					\newcommand{\probeq}[3]{\probgen{\hitsum{#1}{#2}~=~#3}}
\newcommand{\varprobeq}[3]{\varprobgen{\hitsum{#1}{#2}~=~#3}}
\newcommand{\probge}[3]{\probgen{\hitsum{#1}{#2}~\geq~#3}}
\newcommand{\varprobge}[3]{\varprobgen{\hitsum{#1}{#2}~\geq~#3}}

\newcommand{\flowin}[2]{\ens{f_{#1}(#2)}}
\newcommand{\xicost}[1]{\ens{c(#1)}}
\newcommand{\xitot}{\ens{\mathcal C}}
\newcommand{\pitot}{\ens{\mathcal C'}}
\newcommand{\opmerge}[1]{\ens{M_{#1}}}
\newcommand{\mergeop}[2]{\ens{E_{#2}^{(#1)}}}
\newcommand{\mopfirst}[2]{\ens{b{(#1,#2)}}}
\newcommand{\moplast}[2]{\ens{c{(#1,#2)}}}
\newcommand{\picost}[2]{\ens{\xitot_{#1,#2}}}
\newcommand{\minmega}[1]{\ens{E_{\min}^{(#1)}}}
\newcommand{\mindex}[1]{\ens{h(#1)}}
\newcommand{\themergeop}[1]{\ens{\mergeop{#1}{\mindex{#1}}}}
\newcommand{\themergeoplus}[1]{\ens{\mergeop{#1}{\mindex{#1}+1}}}

\newcommand{\opchargeind}[3]{\ens{\kappa_{#1}(#2,#3)}}
\newcommand{\opchargev}[2]{\ens{\kappa_{#1}(#2)}}
\newcommand{\opcharge}[1]{\ens{\kappa_{#1}}}
\newcommand{\indexsym}{\ens{i'}}
\newcommand{\chargenumv}[2]{\ens{\indexsym(j,#1,#2)}}
\newcommand{\chargenumvgen}[3]{\ens{\indexsym(#1,#2,#3)}}
\newcommand{\chargenumvshort}[1]{\ens{\indexsym(#1)}}










\title{Max-Throughput for (Conservative) -of- Testing}
\author{Lisa Hellerstein\thanks{Polytechnic Institute of NYU. This research is supported by the NSF Grant CCF-0917153. {\tt hstein@poly.edu}}
 \and 
\"Ozg\"ur \"Ozkan\thanks{Polytechnic Institute of NYU. This research supported by US Department of Education Grant P200A090157. {\tt ozgurozkan@gmail.com}}
\and
Linda Sellie\thanks{Polytechnic Institute of NYU. This research is supported by a CIFellows Project postdoc, sponsored by NSF and the CRA. {\tt sellie@mac.com}}}

\begin{document}
\maketitle


\begin{abstract}
We define a variant of \kofn{} testing
that we call {\em conservative} \kofn{} testing.
We present a polynomial-time, combinatorial algorithm for the
problem of maximizing throughput of
conservative \kofn{} testing, in
a parallel setting.  
This extends previous work of Kodialam and Condon et al., 
who presented combinatorial
algorithms for parallel pipelined filter ordering,
which is the special case where  (or )~\cite{conf/ipco/Kodialam01,conf/pods/CondonDHW06,journals/talg/CondonDHW09}.
We also consider the problem of maximizing throughput for 
{\em standard} \kofn{} testing, and show how to obtain a polynomial-time algorithm based on the ellipsoid method using previous techniques.
\end{abstract}






\section{Introduction}


In {\em standard} \kofn{} testing, there are \valn\ binary
tests, that can be applied to an ``item'' \anitem.  
We use \retval i to denote the value of the \ith\ test on \anitem, 
and treat \anitem{} as an
element of .
With probability ,
,  and with probability ,
.
The tests are independent, and we are given
.
We need to determine whether at least  of the \valn\ tests on \anitem{}
have a value of 0, by applying the tests
sequentially to \anitem.
Once we have enough
information to determine whether this is the case, that is, {\em once
we have observed  tests with value 0, or \valnmk\ tests with
value 1}, we do not need to perform further tests.\footnote{In an alternative definition of \kofn{} testing, the task is to determine whether at least  of the \valn\ tests have a value of 1.  Symmetric results hold for this definition.}

We define {\em conservative} \kofn{} testing the same way,
except that we continue performing tests
until we have either observed  tests with value 0,
or have performed all \valn\ tests.  In particular, we do not stop
testing when we have observed \valnmk\ tests with value 1.

There are many applications where \kofn{} testing problems
arise, including 
quality testing, medical diagnosis, and database query optimization.
In quality testing, an item \anitem{} manufactured by a factory is tested for defects.  If it has at least  defects, it is discarded.  
In medical diagnosis, the item \anitem{} is a patient;
patients are diagnosed with a particular disease if they fail at least
 out of  special medical tests. 
A database query may ask 
for all tuples \anitem{} satisfying at least  of \valn\ given predicates (typically  or ).

For , standard and conservative \kofn{} testing
are the same.
For , the conservative variant is relevant
in a setting where, for items failing fewer than  tests,
we need to know {\em which} tests they failed. 
For example, in quality testing, we may want to know which tests
were failed by items failing fewer than 
 tests (i.e. those not discarded)
in order to repair the associated defects.

Our focus is on the \maxthru\ problem 
for \kofn{} testing. 
Here the objective is to maximize the 
throughput of a system for \kofn{} testing in a parallel setting where each
test is performed by a separate ``{\processor}''.
In this problem, in addition to the probabilities , there
is a {\em rate limit}  associated with the {\processor} that performs
test , indicating that the
{\processor} can only perform tests on  items per unit time.

\maxthru\ problems are closely related to 
\mincost\ problems~\cite{conf/pods/LiuPRY08,DBLP:journals/talg/DeshpandeH12}.
In the \mincost\ problem for \kofn{} testing, 
in addition to the probabilities ,
there is a cost  associated with performing the \ith\ test.
The goal is to find a testing strategy (i.e.
decision tree) that minimizes the expected cost of testing an individual
item.    There are polynomial-time algorithms for solving the
\mincost\ problem for standard \kofn{} testing~\cite{salloumphd,salloumbreuer,bendov81,journals/tc/ChangSF90}.

Kodialam was the first to study the \maxthru\ \kofn{} 
testing problem, for the special case where ~\cite{conf/ipco/Kodialam01}.
He gave a \bigoh{n^3\log n} algorithm for the problem.  The algorithm is
combinatorial, but its correctness proof relies on
polymatroid theory.  
Later, Condon et~al.~studied the problem, calling it 
``parallel pipelined filter ordering''. 
They gave two \bigoh{n^2} combinatorial algorithms, 
with
direct correctness proofs~\cite{journals/talg/CondonDHW09}.

\paragraph{Our Results.} In this paper, we extend the previous work by giving a polynomial-time
combinatorial algorithm for the \maxthru\ problem for
conservative \kofn{} testing.
Our algorithm can be implemented to run in time 
\bigoh{n^2}, matching the running time of the algorithms of
Condon et al.~for 1-of-n testing.
More specifically, the running time
is \bigoh{\valn(\log \valn + \valk) + o}, where  varies depending on the
output representation used;
the algorithm can be modified to produce different output representations. We discuss output representations below. 

The \maxthru\ problem for
standard \kofn{} testing appears to be fundamentally different
from its conservative variant.
We leave as an open problem the task of developing
a polynomial time {\em combinatorial} algorithm for this problem.
We show that previous techniques can
be used to obtain a polynomial-time
algorithm based on the ellipsoid method. This approach
could also be used to yield an algorithm, based on the
ellipsoid method, for the conservative variant.

\subparagraph{Output Representation}
For the type of representation used by Condon et al.~in achieving their
\bigoh{n^2} bound, .  A more explicit representation
has size .
We also describe a new, more compact output representation for which
. 

In giving running times, we follow Condon et al.~and 
consider only the time taken by the algorithm 
to produce the output representation.
We note, however, that different output representations may
incur different post-processing costs when we want to use them
them to implement the routings.
For example, the compressed representation has , 
but it requires spending \bigoh{n} time in the worst case 
to extract any permutation of \megaprocessor s stored by the 
\megaprocessor\ representation. We can reduce this complexity to 
\bigoh{\log n} using persistent 
search trees~\cite{DBLP:journals/cacm/SarnakT86}.  
In contrast, the explicit  representation gives direct access
to the permutations.
In practice, the choice of the best output representation can vary
depending on the application and the setting.

For ease of presentation, in our pseudocode we use the \megaprocessor\ representation, which is also used by Condon et al.~\cite{journals/talg/CondonDHW09} in their Equalizing Algorithm.

\section{Related Work}

Deshpande and Hellerstein studied the 
\maxthru\ problem for , when there are precedence constraints
between tests~\cite{DBLP:journals/talg/DeshpandeH12}.
They also showed a close relationship between
the exact \mincost\ and \maxthru\ problems for \kofn{} testing, when .
Their results can be generalized to apply to testing of other functions.

Liu et al.~\cite{conf/pods/LiuPRY08} presented a generic, 
LP based method for converting an 
approximation algorithm for a \mincost\ problem, into an approximation
algorithm for a \maxthru\ problem. Their results are not applicable to
this paper, where we consider only exact algorithms.

Polynomial-time algorithms for the
\mincost\ problem for standard \kofn{} testing were given
by Salloum, Breuer, 
Ben-Dov, and Chang et al.~\cite{salloumphd,salloumbreuer,bendov81,journals/tc/ChangSF90,salloumfaster}.

The problem of how to best order a sequence of tests, in
a sequential setting, has been studied in many
different contexts, and in many different models.   
See for example~\cite{conf/pods/LiuPRY08} and~\cite{journals/talg/CondonDHW09}
for a discussion of related work on                                                                                        
the filter-ordering problem (i.e. the \mincost\ problem for )
and its variants, and~\cite{unluyurt2004189} for a general survey 
of sequential testing of functions.







\section{Problem Definitions}


A {\em \kofn{} testing strategy} for tests  is a binary decision tree 
\strategy\ that computes the \kofn{} function, 
, where  if and only if
\anitem{} contains fewer than  0's.
Each node of \strategy\ is labeled by a variable .
The left child of a node labeled with \retval{i} is associated
with  (i.e., failing test ), and the right child 
with  (i.e., passing test ). 
Each  corresponds to a root-to-leaf path
in the usual way, and the label at the leaf is  
.

A \kofn{} testing strategy \strategy\ is {\em conservative} if, 
for each root-to-leaf path leading
to a leaf labeled 1, the path contains exactly \valn\ non-leaf nodes,
each labeled with a distinct variable .

Given a permutation  of the  tests, we define 
\cstrat{\valk}{\perm} to be the conservative strategy described by the following procedure:
{\it Perform the tests
in order of permutation  until at least  0's have been observed,
or all tests have been performed, whichever
comes first.  Output  in the first case, and  in the second.}


Similarly, we define \sstrat{\valk}{\perm} to be the following
standard \kofn{} testing strategy:
{\it Perform the tests
in order of permutation  until at least  0's have been observed,
or until  1's have been observed, whichever
comes first.  Output  in the first case, and  in the second.}

Each test  has an associated probability , where .
Let  denote the product distribution on  
defined by the 's; that is, if  is drawn from , then
 and the \retval{i} are independent.
We use  to denote a random  drawn from .
In what follows, when we use an expression of 
the form   involving 
an item , we mean the probability with respect to .


\subsection{The \mincost\ problem}
\label{sec:mincostdef}
In the \mincost\ problem for standard \kofn{} testing,
we are given  probabilities  and costs , for , associated with the tests.
The goal is to find a \kofn{} testing strategy \strategy\ that minimizes
the expected cost of applying \strategy\ to a random item .
The cost of applying a
testing strategy \strategy\ to an item
\anitem{} is the sum of the costs of the tests along the root-to-leaf 
path for \anitem{} in \strategy. 

In the \mincost\ problem for conservative \kofn{} testing, the goal is the same,
except that we are restricted to finding a {\em conservative} testing strategy.

For example, consider the \mincost\ -of- problem with probabilities ,  and costs , .
A standard testing strategy for this problem can be
described procedurally as follows: {\em Given item , begin by performing test .  
If , 
follow strategy , where .
Else if , 
follow strategy , where .}

Under the above strategy, which can be shown to be optimal,
evaluating  costs
, and
evaluating 
 costs .
The expected cost of applying this strategy to a random item  is . 



Because the \mincost\ testing strategy may be a 
tree of  size exponential in the
number of tests,  algorithms for the
\mincost\ problem may output a compact representation of the output strategy.
\paragraph{The Algorithm for the \mincost\ Problem.}

In the literature, versions of the \mincost\ problem 
for \oneofn\ testing are studied under a variety of different
names, including pipelined filter ordering, selection ordering, 
and satisficing search (cf.~\cite{journals/talg/CondonDHW09}).

The following is a well-known, simple
algorithm for solving the \mincost\ problem for standard \oneofn\ testing
(see e.g.~\cite{GAREY73}):
First, sort the
tests in increasing order of the ratio .
Next, renumber the tests, so that
.
Finally, output the sorted list  of tests, which
is a compact representation of the strategy \sstrat{1}{\perm} (which is the same as \cstrat{1}{\perm}).

The above algorithm can be applied to the \mincost\ problem
for conservative \kofn{} testing, simply by treating  as
a compact representation of the conservative strategy \cstrat{\valk}{\perm}.
In fact, that strategy is optimal for conservative \kofn{} testing: it has
minimum expected cost among
all conservative strategies.   This follows immediately from a lemma of Boros et al.~\cite{journals/amai/BorosU99}\footnote{The lemma of Boros et al.~actually 
proves that the corresponding decision tree is {\em 0-optimal}.
A decision tree computing a function  
is 0-optimal if it minimizes the expected cost of
testing an random , {\em given that }.
In conservative \kofn{} testing, where  is the
\kofn{} function, the cost of testing  is the same for all  such that .
Thus the problem of finding a min-cost conservative strategy for \kofn{} testing
is essentially equivalent to the problem of finding a 0-optimal decision tree
computing the \kofn{} function.  The lemma of Boros et al.~also applies to a more
general class of functions  that include the \kofn{} functions.
}. 



\subsection{The \maxthru\ problem}

The \maxthru\ problem for \kofn{} testing
is a natural generalization of the 
\maxthru\ problem for
\oneofn\ testing,
first studied by Kodialam~\cite{conf/ipco/Kodialam01}. 
We give basic definitions and motivation here.
For further information about this problem, including
information relevant to its application in practical settings, 
see~\cite{conf/ipco/Kodialam01,conf/pods/CondonDHW06,journals/talg/CondonDHW09}.

In the \maxthru\ problem for \kofn{} testing, as in the \mincost\ problem, 
we are given the probabilities
 associated with the tests.
Instead of costs  for the tests, we are given
{\em rate limits} .
The \maxthru\ problem arises in the following context.
There is an (effectively infinite) stream of items \anitem{} that need to be tested.
Every item \anitem{} must be assigned a strategy \strategy\ that will
determine which tests are performed on it.
Different items may be assigned to different strategies.
Each test is performed by a separate ``{\processor}'', and the {\processor}s operate in parallel.
(Imagine a factory testing setting.)
Item \anitem{} is sent from {\processor} to {\processor} for testing, 
according to its strategy \strategy.
Each {\processor} can only test one item at a time.
We view the problem of assigning items to strategies as
a flow-routing problem.

{\Processor}  performs test .  It has rate limit (capacity) , indicating
that it can only
process  items \anitem{} per unit time. 


The goal is to determine how many items should be assigned to each strategy \strategy,
per unit time, in order to maximize 
the number of items that can be processed per unit time, the throughput of the system.
The solution must respect the rate limits of the {\processor}s, in that the
expected number of items that need to be tested by {\processor}  per unit time must
not exceed .  
We assume that tests behave according to expectation: if \flowamt\ items
are tested by {\processor}  per unit time, then  of them will have the value 1,
and  will have the value 0.

Let \stratspace\ denote the set of all \kofn{} testing strategies and
 denote the set of all conservative \kofn{} testing strategies. 
Formally, the \maxthru\ problem for standard \kofn{}
testing is defined by the linear program below.
The linear program defining the \maxthru\ problem for conservative \kofn{} testing is obtained 
by simply replacing the set of \kofn{} testing strategies \stratspace\ by the
set of conservative \kofn{} testing strategies .

We refer to a feasible assignment to the variables  in the LP below as a {\em routing}.
We call constraints of type (1) {\em rate constraints}.
The value of  is the {\em throughput} of the routing.
 We define  as the probability that test  will be performed on an item \anitem{} that is tested using strategy \strategy, when .
For , if 
, 
we say that the routing {\em saturates} {\processor} .

We will refer to the \maxthru\ problems for standard and conservative \kofn{} testing as the ``\smt" and the ``\cmt", respectively. 




As a simple example, consider 
the following \cmt{} (equivalently, \smt) instance, 
where  and : , , , .
There are only two possible strategies, , where ,
and , where .  
Since all flow assigned to  is tested by , ; 
this flow continues on to  only if it passes test 1, which happens with probability ,
so .  
Similarly,  while  since .
Consider the routing that assigns
 units of flow to strategy , and  units 
to strategy .  Then the amount of flow reaching  is
, 
and the amount of flow reaching  is
.  Since  and ,
 this routing saturates both {\processor}s.   By the results of Condon et al.~\cite{journals/talg/CondonDHW09}, it is optimal.
 
 
\vspace{16pt}
\hrule
\vspace{6pt}

{\bf \noindent \maxthru\ LP:}

Given  and ,
find an assignment to the variables , for all ,
that maximizes
 
subject to the constraints:\3pt]
\mbox{\ \ \ \ }(2) \
\frac{(R_{i} - \xi(i)\hat t) - (R_{i-1} - \xi(i-1)\hat t)}{\xi(i) - \xi(i-1)} &= 
\frac{R_{i} - R_{i-1}}{\xi(i) - \xi(i-1)} - \hat t. 

\xi(\mindex i) =  \sum_{j=0}^{k-1} \flowin{j}{\moplast i{\mindex i + 1}}\cdot\left(	\sum_{v= 1}^{k-j} \probge{	\mopfirst i{\mindex i}}{\moplast i{\mindex i + 1}}{v}		\right) / 
\sum_{t=\mopfirst i{\mindex i}}^{\moplast i{\mindex i+1}} (1-\pr t)

D_{j} = \sum_{v= 1}^{k-j}\probge{\mopfirst i{\mindex i}}{\moplast i{\mindex i + 1}}v	.

D_{j} = D_{j+1} + \probge{\mopfirst i{\mindex i}}{\moplast i{\mindex i + 1}}{k-j}.

\probge{\mopfirst i{\mindex i}}{\moplast i{\mindex i + 1}}v = \probge{\mopfirst i{\mindex i}}{\moplast i{\mindex i + 1}}{v+1} + \probeq{\mopfirst i{\mindex i}}{\moplast i{\mindex i + 1}}v.

\label{eq:picost}
\probeq{\mopfirst i{\mindex i}}{\moplast i{\mindex i + 1}\hspace{-2mm}}{\hspace{-1mm}v} = 
\hspace{-7mm}
\sum_{j=\max(0,v-\card{\themergeoplus i})}^{\min(v,\card{\themergeop i})} 
\hspace{-10mm}
\probeq{\mopfirst i{\mindex i}}{\moplast i{\mindex i}}j \cdot \probeq{\mopfirst i{\mindex i + 1}}{\moplast i{\mindex i + 1}\hspace{-2mm}}{\hspace{-1mm}v-j}

\label{eq:costbound}
\picost iv < 2\cdot\min(v+1,\card{\minmega i}+1).

\label{eq:jiv}
\opchargeind jiv = 
\left\{
\begin{array}{cl}
\picost iv/\card{\minmega i} & \mbox{if } \op j\in\minmega i,  \\
0  &    \mbox{otherwise.}
\end{array}
\right.

\opchargev jv = \sum_{i=1}^{n-1} \opchargeind jiv

\opcharge j = \sum_{v=0}^{k} \opchargev jv = \sum_{i=1}^{n-1}\sum_{v=0}^{k} \opchargeind jiv

\chargenumvshort z = \chargenumv vz =
\left\{
\begin{array}{cl}
\ell  & \mbox{if } \exists \ell\in[1,n-1] \mbox{ s.t.~} \opchargeind j\ell{v}>0 \wedge \card{\{t\ |\ t<\ell, \opchargeind jtv>0\}} = z-1    \\
0  & \mbox{otherwise}     
\end{array}
\right.

\label{eq:twiceisv}
\card{\minmega{\chargenumvshort 2}} \geq \card{\mergeop{\chargenumvshort 1}{\mindex{\chargenumvshort 1}}} + \card{\mergeop{\chargenumvshort 1}{\mindex{\chargenumvshort 1} + 1}} \geq v.

\label{eq:doubling}
\card{\minmega{\chargenumvshort z}} \geq 2\cdot \card{\minmega{\chargenumvshort {z-1}}}.

\opchargev jv 
&= \sum_{i=1}^{n-1} \opchargeind jiv && \mb{by definition}\\
&\leq 4+ \sum_{i=2}^{n-1} \opchargeind jiv && \opchargeind jiv < 4\\
&= 4 + \sum_{z=2}^{Z} \opchargeind j{\chargenumvshort z}v && \mb{by definition}\\
&= 4+ \sum_{z=2}^{Z} \frac{\picost {\chargenumvshort z}v}{\card{\minmega{\chargenumvshort z}}} && \mb{by Equation~\ref{eq:jiv}}\\
&< 4+ \sum_{z=2}^{Z} \frac{2v+2}{\card{\minmega{\chargenumvshort z}}} && \mb{by Equation~\ref{eq:costbound}}\\
&\leq 4+ \sum_{z=2}^{Z} \frac{2v+2}{2^{z-2}\cdot\card{\minmega{\chargenumvshort 2}}} && \mbox{by Equation~\ref{eq:doubling}}\\
&< 6+ \sum_{z=2}^{Z} \frac{2v}{2^{z-2}\cdot\card{\minmega{\chargenumvshort 2}}} && \card{\minmega{\chargenumvshort 2}}\geq 2\\
&\leq 6+ \sum_{z=2}^{Z} \frac{2}{2^{z-2}} && \mb{by Equation~\ref{eq:twiceisv}}\\
&< 6+ 4 \\
&= 10.

\sum_{i=1}^{n-1}\sum_{v=0}^{k}\picost iv = \sum_{j=1}^{n} \opcharge j \leq n\cdot\bigoh{k} = \bigoh{nk}
\thruput = \sum_{i=1}^{n} \rate i \vary{i}3pt]
\mbox{\ \ \ \ }(1) ,\3pt]
\mbox{\ \ \ \ }(2) .\\
\vspace{6pt}
\hrule
\vspace{10pt}

\begin{thm}
\label{thm:smt}
There is a polynomial-time algorithm, based on the ellipsoid method, for
solving the \smt.
\end{thm}

\begin{proof} 
The  approach of Deshpande and Hellerstein works as follows.  The input consists of
the  and the , and the goal is to solve the
\maxthru\ LP in time polynomial in \valn.
The number of variables of the \maxthru\ LP is not
polynomial, so the LP cannot be 
solved directly.
Instead, the idea is to solve it by first using 
the ellipsoid method to solve the dual LP.
The ellipsoid method is
run using an algorithm that simulates a separation oracle
for the dual in time polynomial in \valn.
During the running of the ellipsoid method, the violated
constraints returned by the separation oracle are saved
in a set \loadratio.  Each constraint of the dual corresponds
to an ordering \strategy.  When the ellipsoid method terminates,
a modified version of the \maxthru\ LP is generated,
which includes only the variables  corresponding to
orderings \strategy\ in \loadratio\ (i.e. the other variables  are
set to 0).  This modified version can then be solved 
directly using a polynomial-time LP algorithm.
The resulting solution is an optimal
solution for the original \maxthru\ LP.

The above approach requires 
a polynomial-time algorithm for simulating the separation oracle
for the dual.  
Deshpande and Hellerstein's method for simulating the
separation oracle relies on the following observations.
In the dual LP for the
\maxthru\, \oneofn\ testing problem,
there are  constraints corresponding to the
 permutations of the {\processor}s.
The constraint for permutation 
is
.
If one views  as a vector of costs, where the cost of 
is , then 
  is the expected cost of testing
an item \anitem{} using ordering \strategy.
Thus one can determine the ordering \strategy\ that minimizes

by solving the \mincost\ problem with probabilities
 and cost vector .
(Liu et al.'s approximation algorithm for generic
\maxthru\ also relies on this observation~\cite{conf/pods/LiuPRY08}.)

If the \mincost\ ordering \strategy\ has expected cost
less than 1, then the constraint it corresponds to is
violated.  Otherwise, since the right hand side of
each constraint is 1,  obeys all constraints.
Thus simulating the separation oracle for
the dual on input  can be done by
first running the \mincost\ algorithm (with probabilities  and costs
) to find a \mincost\ ordering \strategy.  Once \strategy\ is found,
the values of the coefficients  are calculated.
These are used to calculate
, the expected cost of \strategy.  If this value
is less than 1, then the constraint
 is returned.

To apply the above approach to \maxthru\ for standard \kofn{} testing,
we observe that in the dual LP for this problem,
there is a constraint, 
,
for every possible strategy ,
We can simulate a separation
oracle for the dual on input  by
running a \mincost\ algorithm for standard \kofn{} testing.
We also need to be able to compute the  values for the
strategy output by that algorithm.
The algorithm of 
Chang et al.~for the \mincost\ standard \kofn{} testing problem is suitable for this purpose,
as it can easily be modified to output
the  values associated with its output strategy \strategy~\cite{journals/tc/ChangSF90}. 
\end{proof}

\bibliographystyle{plain}
\bibliography{kofnonly}


\end{document}
