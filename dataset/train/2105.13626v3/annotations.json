[{'LEADERBOARD': {'Task': 'Question Answering', 'Dataset': 'TweetQA', 'Metric': 'BLEU-1', 'Score': '72.0'}}, {'LEADERBOARD': {'Task': 'Question Answering', 'Dataset': 'TweetQA', 'Metric': 'BLEU-1', 'Score': '70.8'}}, {'LEADERBOARD': {'Task': 'Question Answering', 'Dataset': 'TweetQA', 'Metric': 'ROUGE-L', 'Score': '74.3'}}, {'LEADERBOARD': {'Task': 'Question Answering', 'Dataset': 'TweetQA', 'Metric': 'ROUGE-L', 'Score': '75.7'}}, {'LEADERBOARD': {'Task': 'Cross-Lingual Question Answering', 'Dataset': 'MLQA', 'Metric': 'EM', 'Score': '54.9'}}, {'LEADERBOARD': {'Task': 'Cross-Lingual Question Answering', 'Dataset': 'MLQA', 'Metric': 'F1', 'Score': '71.6'}}, {'LEADERBOARD': {'Task': 'Cross-Lingual Question Answering', 'Dataset': 'TyDiQA-GoldP', 'Metric': 'EM', 'Score': '81.9'}}, {'LEADERBOARD': {'Task': 'Cross-Lingual Question Answering', 'Dataset': 'TyDiQA-GoldP', 'Metric': 'EM', 'Score': '60.0'}}, {'LEADERBOARD': {'Task': 'Cross-Lingual Question Answering', 'Dataset': 'TyDiQA-GoldP', 'Metric': 'F1', 'Score': '75.3'}}, {'LEADERBOARD': {'Task': 'Cross-Lingual Question Answering', 'Dataset': 'XQuAD', 'Metric': 'EM', 'Score': '63.6'}}, {'LEADERBOARD': {'Task': 'Cross-Lingual Question Answering', 'Dataset': 'XQuAD', 'Metric': 'F1', 'Score': '79.7'}}, {'LEADERBOARD': {'Task': 'Cross-Lingual Natural Language Inference', 'Dataset': 'XNLI', 'Metric': 'Accuracy', 'Score': '83.7'}}, {'LEADERBOARD': {'Task': 'Cross-Lingual Natural Language Inference', 'Dataset': 'XNLI', 'Metric': 'Accuracy', 'Score': '69.1'}}, {'LEADERBOARD': {'Task': 'Cross-Lingual NER', 'Dataset': 'WikiAnn NER', 'Metric': 'F1', 'Score': '67.7'}}, {'LEADERBOARD': {'Task': 'Extreme Summarization', 'Dataset': 'GEM-XSum', 'Metric': 'BLEU score', 'Score': '15.3'}}, {'LEADERBOARD': {'Task': 'Extreme Summarization', 'Dataset': 'GEM-XSum', 'Metric': 'BLEU score', 'Score': '14.3'}}]
