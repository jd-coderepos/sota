

\section{Experiments and Results}
\stlabel{experiments}

The theory of neighbourhood abstraction ensures that the number of shapes for
any graph grammar is finite, and therefore that the abstract state space is also
finite~\cite{BBKR08}. However, the theoretical upper bound of the abstract
state space size is still quite large, meaning that in practice we have to
optimise the state space traversal in order to implement an efficient tool.
In~\cite{RZ10} we described the major aspects of the implementation of
neighbourhood abstraction in \GROOVE (though without shape subsumption), and
reported a few experiments. In this section we present more of
such experiments, that illustrate: (i) the upper bounds on abstract state space
sizes that are reachable in practice, (ii) the performance gains that are
obtained with the shape subsumption technique presented in \stref{subsumption},
and (iii) how different exploration strategies perform in the abstract setting.

For our experiments we collected 8 graph grammars, from various problem
domains. Some of these problems can also be solved with other abstractions, but
they are usually tuned with certain characteristics from the domain at
hand\footnote{Shape analysis, for example, is designed to work on heap pointer
structures, which are deterministic graphs. In our setting, this correspond to
having shapes with all outgoing edge multiplicities limited to $\multone$.}. Our
abstraction extension for \GROOVE, on the other hand, is generic, in the sense
that the concept of neighbourhood equivalence is always applicable, but perhaps
with varying performance. Here is a list with a short description of the
grammars used.
\begin{itemize}
\item {\bf linked-list}: a grammar modelling operations on a single-linked
list structure. Elements can always be appended at the end of the list, which
can thus grow unbounded.
\item {\bf circ-buf-0}: a grammar modelling a circular buffer structure with
an unbounded number of cells. Cell usage is marked with special labels, without
reference to stored objects.
\item {\bf circ-buf-1}: a variant of the circular buffer where the stored
objects are explicitly represented.
\item {\bf euler-0}: a grammar that can construct Euler's walks of arbitrary
size. Adapted from the classical K\"onigsberg bridges problem from graph theory.
\item {\bf euler-1}: a variant of the Euler grammar without explicitly
representing connecting bridges.
\item {\bf firewall-[2-6]}: the grammar of our firewall example. Network
structure is fixed, while packages are collapsed by the abstraction. Instances
vary on the number of locations: from 2 to 6.
\item {\bf firewall-6-F}: variant of the firewall grammar with a network of six
fully connected locations.
\item {\bf car-platoon}: grammar simulating a wireless communication protocol
between cars, for establishing platoons in highways. Cars can enter and leave a
platoon at any time, which leads to an exponential growth on the number of
possible configurations.
\end{itemize}

\tref{size} gives all the figures on state space sizes for the grammars listed
above. Numbers for the BFS and DFS exploration strategies are grouped per
grammar, to ease the comparison between the two. State space sizes are divided
in two groups of values: the number of explored states, \ie, the number of
shapes produced, and the number of transitions between states, \ie, the count of
rule applications. State and transition counts in \tref{size} are broken down in
five and three types, respectively.

\begin{table}[t]
\centering
\caption{State space sizes for the explorations performed with different graph
grammars.}
\tlabel{size}
\scriptsize
\begin{tabular}{c|c|rrrrr|rrr}
\hline
\bf \multirow{2}{*}{Grammar} & \bf \multirow{2}{*}{Strat.} &
\multicolumn{5}{|c|}{\bf States} & \multicolumn{3}{|c}{\bf Transitions} \\
& & \bf Maximum & \bf Generated & \bf Subsumed & \bf Relevant & \bf Discarded
& \bf Maximum & \bf Generated & \bf Relevant \\
\hline
\multirow{2}{*}{linked-list} &
BFS & \multirow{2}{*}{9} & 9 & 3 & 6 & 0 & \multirow{2}{*}{17} & 17 & 11 \\
& DFS & & 8 & 2 & 6 & 1 & & 14 & 11 \\
\hline
\multirow{2}{*}{circ-buf-0} &
BFS & \multirow{2}{*}{54} & 31 &  5 & 26 & 3 & \multirow{2}{*}{130} & 65 & 59 \\
& DFS & & 39 & 13 & 26 & 2 & & 88 & 59 \\
\hline
\multirow{2}{*}{circ-buf-1} &
BFS & \multirow{2}{*}{57} & 33 & 16 & 17 & 0 & \multirow{2}{*}{182} & 100 & 40
\\
& DFS & & 30 & 13 & 17 & 2 & & 89 & 40 \\
\hline
\multirow{2}{*}{euler-0} &
BFS & \multirow{2}{*}{878} & 248 & 96 & 152 & 54 & \multirow{2}{*}{10,448} &
1,356 & 584 \\
& DFS & & 213 & 61 & 152 & 28 & & 1,286 & 618 \\
\hline
\multirow{2}{*}{euler-1} &
BFS & \multirow{2}{*}{14} & 14 & 4 & 10 & 0 & \multirow{2}{*}{23} & 23 & 15 \\
& DFS & & 13 & 3 & 10 & 2 & & 19 & 15 \\
\hline
\multirow{2}{*}{firewall-2} &
BFS & \multirow{2}{*}{125} & 98 & 90 & 8 & 36 & \multirow{2}{*}{875} & 409 & 37
\\
& DFS & & 50 & 42 & 8 & 15 & & 207 & 37 \\
\hline
\multirow{2}{*}{firewall-3} &
BFS & \multirow{2}{*}{1,625} & 991 & 971 & 20 & 549 & \multirow{2}{*}{19,825} &
5,021 & 121 \\
& DFS & & 232 & 212 & 20 & 102 & & 1,314 & 121 \\
\hline
\multirow{2}{*}{firewall-4} &
BFS & \multirow{2}{*}{4,875} & 2,356 & 2,326 & 30 & 1,487 &
\multirow{2}{*}{83,850} & 13,577 & 203 \\
& DFS & & 427 & 397 & 30 & 212 & & 2,959 & 203 \\
\hline
\multirow{2}{*}{firewall-5} &
BFS & \multirow{2}{*}{} & 14,878 & 14,818 & 60 & 10,549 & \multirow{2}{*}{} &
93,549 & 459 \\
& DFS & & 1,201 & 1,141 & 60 & 654 & & 10,421 & 459 \\
\hline
\multirow{2}{*}{firewall-6} &
BFS & \multirow{2}{*}{} & 25,251 & 25,171 & 80 & 18,373 & \multirow{2}{*}{} &
187,126 & 643 \\
& DFS & & 1,783 & 1,703 & 80 & 1,007 & & 18,485 & 643 \\
\hline
\multirow{2}{*}{firewall-6-F} &
BFS & \multirow{2}{*}{} & 183,478 & 182,966 & 512 & 147,028 & \multirow{2}{*}{}
& 1,409,451 & 8,711 \\
& DFS & & 5,930 & 5,418 & 512 & 3,003 & & 93,087 & 8,711 \\
\hline
car-platoon & DFS & \multicolumn{8}{|c}{Out of memory after exploring 445,439
states and 8,484,600 transitions} \\
\hline
\end{tabular}
\end{table}

The following five types of state count are given in columns 3-7 of
\tref{size}.
\begin{itemize}
\item {\bf Maximum} is the upper bound on the number of abstract states of the
grammar. This number is obtained by exploring the state space without shape
subsumption, \ie, by running the exploration algorithm of \lstref{main-alg}
with the original $\isfresh$ procedure of \lstref{isfresh}. Thus, these are the
figures that would have been reported by the prior implementation
of~\cite{RZ10}. Empty entries in
this column for the larger cases of the firewall grammar indicate that the
upper bound could not be computed: these runs timed out after several hours of
execution, due to state space explosion. Note that we give only one maximum
state count for both BFS and DFS strategies. The reason is that all states are
explored when subsumption is off, and therefore the maximum state count is
the same, regardless of the strategy used. The upper bound provided by this
column gives an interesting basis of comparison when analysing the reduction
obtained with subsumption.
\item {\bf Generated} is the number of states produced during exploration using
shape subsumption, \ie, the exploration algorithm of \lstref{main-alg} was run 
with the new $\isfresh$ procedure of \lstref{newisfresh}. Numbers in this
column correspond to the size of set $Q$, \ie, the number of states that were
added to the set of all explored states (line 8 in \lstref{main-alg}). When
comparing the number of generated states against the maximum upper bound we can
see the reduction given by subsumption. Take, for example, the
\emph{firewall-4} line, where the number of generated states using DFS with
subsumption is an order of magnitude smaller than the maximum upper bound
obtained without subsumption. The gain provided by subsumption can also be seen
for the larger cases of the firewall grammar: runs that timed-out without
subsumption can now be finished when we turn it on.
\item {\bf Subsumed} is the number of states generated that were later marked
as subsumed by another state. They correspond to states that are added to set
$B$ at line 6 of \lstref{newisfresh}.
\item {\bf Relevant} is the number of states that were never marked as subsumed
during the exploration. This column corresponds to the {\bf Generated} column
minus the {\bf Subsumed} one. The closer the number of generated states gets to
the relevant state count the better. A perfect exploration method would generate
only the relevant abstract states, since they are sufficient to cover all
concrete behaviour.
\item {\bf Discarded} is the number of states that were marked as subsumed and
were removed from the set of states to be explored. This number corresponds to
the sum of all states removed from $F$ at line 10 of \lstref{newisfresh}.
\end{itemize}
The remainder columns of \tref{size} give the number of transitions outgoing
from the states in the associated state count columns.

When comparing the figures in \tref{size} for BFS and DFS exploration, it is
clear that DFS gives a much better performance. The DFS generated state count is
smaller than the BFS count in all but one test (\emph{circ-buf-0}), and as we
move to grammars with larger state spaces the advantage increases greatly, until
reaching two orders of magnitude for the \emph{firewall-6-F} case. The reason
for this performance difference between BFS and DFS is simple. Usually, the more
a shape is transformed by subsequent rule applications the more abstract it
becomes, until it reaches a fix-point, \ie, further rule applications yield the
same shape again. These more abstract shapes capture more concrete behaviour
and thus can subsume other shapes in the state space. As a rule-of-thumb, more
abstract shapes are more likely to be part of the set of relevant states, and
since they are only discovered after a succession of rule applications, these
relevant states are deeper in the state space. Therefore, DFS is more likely to
reach these states first. This fact can be seen from the numbers in the {\bf
Discarded} column: BFS generates a lot of states that are later discarded. This
is wasted effort: in BFS a state is produced and added to sets $Q$ and $F$ but
it is very likely that later it is going to be removed from $F$ (while remaining
in $Q$). On the other hand, since DFS already found more abstract shapes, it is
more probable that the search will immediately throw a new state away, without
storing it on $Q$, since the new state will be subsumed by some other state
already in $Q$.

From the discussion above, one may wonder why shapes that were marked as
subsumed are kept in set $Q$. The reason is that removing states from $Q$ could
leave ``dangling'' transitions in the set of generated transitions $P$. A
possible solution could be the following. For $S \in Q$ and $T$ fresh, if $S
\subsump T$ then we should take all transitions in $P$ with $S$ as a source or
target and replace $S$ by $T$. This on-the-fly state space collapsing under
subsumption is not provided by the current implementation, but the tool offers
a simpler option: \emph{reachability mode}. In this mode we are only interested
in the shapes that are reachable in the abstract state space, and thus there is
no need to store the transitions, \ie, set $P$ is kept empty. In this case there
is no danger of having ``dangling'' transitions and we can remove subsumed
shapes from $Q$, thus decreasing memory usage. Reachability mode was a late
addition to the implementation and as such its experimental analysis is left as
future work.

\begin{figure}[t]
\centering
\inputtikz{state-chart.tikz}
\vspace{-2ex}
\caption{Accumulated percentages of the number of states relative to the
maximum state space size, for the firewall grammar instances with a known
maximum state count.}
\flabel{state-chart}
\end{figure}

\fref{state-chart} gives a visual aid for the comparison between BFS and
DFS, for the firewall grammar instances with a known maximum state count. The
figure shows a stacked bar chart with the accumulated percentages of the number
of states relative to the maximum state space size. From this chart we see that
the percentage of states generated with DFS decreases as the start graph size
increases. On the other hand, the percentage of states generated with BFS
remains roughly the same, at around 40\% the maximum (this can be seen from the
interval sizes of the generated BFS bars in \fref{state-chart}).

Other metrics that must be analysed in a performance evaluation are running time
and memory consumption. Results for these measurements are given in \tref{time},
for runs with and without state subsumption checks. The experiments were
performed in a machine with a Intel Xeon X5365 CPU running at 3 GHz and a total
32 GB of RAM. Blank entries indicate timed-out executions. From the numbers in
\tref{time} we see the performance improvement given by subsumption: running
times for the firewall grammar are two orders of magnitude smaller when
subsumption is used, and memory consumption is also reduced. When comparing the
running times for BFS and DFS, we see that both strategies have a similar
performance when subsumption is not used but when it is turned on, DFS is far
more efficient than BFS, both in execution time and memory consumption. This
performance figures are directly related to the number of states generated by
each strategy: DFS produces far fewer states than BFS, which translates to a
large performance gain. This can be confirmed visually with the chart in
\fref{time-chart}, where the running times for the firewall grammar are plotted
against start graph sizes. Clearly, DFS has a much more tamed growth (note that
the time axis is in a logarithmic scale).

\begin{table}[t]
\centering
\caption{Running time and memory consumption, with and without state subsumption
checks.}
\tlabel{time}
\scriptsize
\begin{tabular}{c|rr|rr|rr|rr}
\hline
\bf \multirow{3}{*}{Grammar} & \multicolumn{4}{|c|}{\bf Time (s)} &
\multicolumn{4}{|c}{\bf Memory (MB)} \\
& \multicolumn{2}{|c|}{\bf Subsump. OFF} &
\multicolumn{2}{|c|}{\bf Subsump. ON} &
\multicolumn{2}{|c|}{\bf Subsump. OFF} &
\multicolumn{2}{|c}{\bf Subsump. ON} \\
& \bf BFS & \bf DFS
& \bf BFS & \bf DFS
& \bf BFS & \bf DFS
& \bf BFS & \bf DFS \\
\hline
linked-list & $<$ 1 & $<$ 1 & $<$ 1 & $<$ 1 & $<$ 1 & $<$ 1 & $<$ 1 & $<$ 1 \\
circ-buf-0 & $<$ 1 & $<$ 1 & $<$ 1 & $<$ 1 & 2 & 2 & 2 & 2 \\
circ-buf-1 & $<$ 1 & $<$ 1 & $<$ 1 & $<$ 1 & 2 & 2 & 2 & 2 \\
euler-0 & 61 & 47 & 2 & 2 & 57 & 57 & 12 & 11 \\
euler-1 & $<$ 1 & $<$ 1 & $<$ 1 & $<$ 1 & $<$ 1 & $<$ 1 & $<$ 1 & $<$ 1 \\
firewall-2 & 2 & 2 & $<$ 1 & $<$ 1 & 6 & 6 & 4 & 2 \\
firewall-3 & 177 & 157 & 5 & 2 & 110 & 110 & 49 & 12 \\
firewall-4 & 4,448 & 3,824 & 16 & 3 & 432 & 432 & 136 & 25 \\
firewall-5 & & & 347 & 10 & & & 1,054 & 85 \\
firewall-6 & & & 1,679 & 16 & & & 2,001 & 143 \\
firewall-6-F & & & 3,732 & 55 & & & 14,277 & 556 \\
\hline
\end{tabular}
\end{table}

\begin{figure}[t]
\centering
\inputtikz{time-chart.tikz}
\vspace{-2ex}
\caption{Running time (with subsumption on) versus start graph size for the
firewall grammar.}
\flabel{time-chart}
\end{figure}
