\pdfoutput=1


\documentclass[11pt]{article}

\usepackage{EMNLP2022}

\usepackage{times}
\usepackage{latexsym}

\usepackage[T1]{fontenc}


\usepackage{xspace}
\usepackage{siunitx}
\usepackage{xcolor}
\usepackage{makecell}
\usepackage{booktabs}
\usepackage{hyperref}
\usepackage{mathtools}
\usepackage{amsfonts}
\usepackage{amsmath,amssymb}
\usepackage{nicefrac}       \usepackage{empheq}
\usepackage[utf8]{inputenc}
\usepackage{amsmath}
\usepackage{graphicx}
\usepackage{bm}
\usepackage[shortlabels]{enumitem}
\usepackage{cleveref}
\Crefformat{section}{\S#2#1#3}
\Crefformat{subsection}{\S#2#1#3}
\Crefformat{subsubsection}{\S#2#1#3}
\Crefrangeformat{section}{\S\S#3#1#4 to~#5#2#6}
\Crefmultiformat{section}{\S\S#2#1#3}{ and~#2#1#3}{, #2#1#3}{ and~#2#1#3}
\usepackage{refstyle}
\Crefformat{figure}{#2Fig.~#1#3}
\Crefmultiformat{figure}{Figs.~#2#1#3}{ and~#2#1#3}{, #2#1#3}{ and~#2#1#3}
\Crefformat{table}{#2Tab.~#1#3}
\Crefmultiformat{table}{Tabs.~#2#1#3}{ and~#2#1#3}{, #2#1#3}{ and~#2#1#3}
\Crefformat{appendix}{#2Appx.~\S#1#3}
\Crefformat{algorithm}{Alg.~#2#1#3}
\Crefformat{equation}{#2Eq.~#1#3}
\usepackage{colortbl}
\newcommand{\CC}[1]{\cellcolor{blue!#1}}
\newcommand{\RED}[1]{\cellcolor{red!#1}}
\newcommand{\muhao}[1]{\textcolor{blue}{MC:{#1}}}
\newcommand{\temprel}{\textsc{TempRel}\xspace}
\newcommand{\todo}[1]{\textcolor{red}{#1}}
\newcommand{\zb}{\mathbf{z}}
\newcommand{\yb}{\mathbf{y}}
\newcommand{\stitle}[1]{\vspace{1ex}\noindent{\bf #1}}
\DeclareMathOperator*{\argmax}{argmax}
\DeclareMathOperator{\acc}{acc}
\DeclareMathOperator{\conf}{conf}
\newcommand{\scrL}{\mathcal{L}}
\newcommand{\xb}{\bar{X}}

\usepackage{microtype}

\looseness=-1

\title{\emph{Extracting or Guessing?} Improving Faithfulness of Event Temporal Relation Extraction}



\author{\makecell{Haoyu Wang, Hongming Zhang, Yuqian Deng, \\Jacob R. Gardner,   Dan Roth \& Muhao Chen}\\
Department of Computer and Information Science, UPenn\\
Tencent AI Lab, Seattle\\
Department of Computer Science, USC\\
\texttt{\{why16gzl, yuqiand, jacobrg, danroth\}@seas.upenn.edu};\\ \texttt{hongmzhang@tencent.com};
\texttt{muhaoche@usc.edu}\\
}

\begin{document}
\maketitle
\begin{abstract}
In this paper, we seek to improve the faithfulness of \temprel extraction models from two perspectives.
The \textit{first} perspective is to extract genuinely based on contextual description. 
To achieve this, we propose to conduct counterfactual analysis to attenuate the effects of two significant types of training biases: the \textit{event trigger bias} and the \textit{frequent label bias}.
We also add tense information into event  representations to explicitly place an emphasis on the contextual description.
The \textit{second} perspective is to provide proper uncertainty estimation and abstain from extraction when no relation is described in the text.
By parameterization of Dirichlet Prior over the model-predicted categorical distribution, we improve the model estimates of the correctness likelihood and make \temprel predictions more selective.
We also employ temperature scaling to recalibrate the model confidence measure after bias mitigation.
Through experimental analysis on MATRES, MATRES-DS, and TDDiscourse, we demonstrate that our model extracts \temprel and timelines more faithfully compared to SOTA methods, especially under distribution shifts.
\end{abstract}

\section{Introduction}
\label{sec:intro}
Event temporal relation (\temprel) extraction is an essential step towards understanding narrative text, such as stories, novels, news, and guideline articles. 
With a robust temporal relation extractor, one can easily construct a storyline from text and capture the trend of temporally connected event mentions. 
\temprel extraction is also broadly beneficial to various downstream tasks including clinical narrative processing \cite{jindal-roth-2013-using, bethard-etal-2016-semeval}, question answering \cite{llorens-etal-2015-semeval, meng-etal-2017-temporal, stricker-2021-question-answering}, and schema induction \cite{chambers-jurafsky-2009-unsupervised, wen-etal-2021-resin, li-etal-2021-future}.

Most existing \temprel extraction models are developed with data-driven machine learning approaches, for which recent studies also incorporate advanced learning and inference techniques such as structured prediction \cite{ning-etal-2017-structured,ning-etal-2018-improving,han-etal-2019-joint,wang-etal-2020-joint,tan-etal-2021-extracting}, graph representation \cite{mathur-etal-2021-timers, qiang-naacl-2022}, data augmentation \cite{ballesteros-etal-2020-severing,trong2022selecting}, and indirect supervision \cite{zhao-etal-2021-effective, zhou-etal-2021-temporal}.
These models are prevalently built upon pretrained language models (PLMs) and fine-tuned on a small set of annotated documents, e.g., TimeBank-Dense \cite{cassidy-etal-2014-annotation}, MATRES \cite{ning-etal-2018-multi}, and TDDiscourse \cite{naik-etal-2019-tddiscourse}.



\begin{figure}[t]
\begin{minipage}{\linewidth}
\noindent
\fbox{\parbox{0.95\linewidth}{
    \fontsize{11pt}{13pt}\selectfont
    A) I went to \textcolor{blue}{\textsc{:see}} the doctor. However, I was more seriously \textcolor{blue}{\textsc{:sick}}.  \textcolor{blue}{\textsc{}} \textsc{After} \textcolor{blue}{\textsc{}} \\ 

    B) Microsoft said it has \textcolor{blue}{\textsc{:identified}} three companies for \textit{the China program} to run through June. The company also \textcolor{blue}{\textsc{:gives}} each participating startup in \textit{the Seattle program} \\Longrightarrowe_3e_4DD = [w_1, \cdots, e_1, \cdots, e_2, \cdots, w_m]\mathcal{E}_D = \{e_1, e_2, \cdots, e_n\}(e_i, e_j)r\mathcal{R} \cup \{\textsc{Vague}\}\mathcal{R}\mathcal{R}\yb^{(i, j)}\mathcal{R}\yb\mathcal{R}\yb(e_i, e_j)(e_i, e_j)e_ii < j(e_i, e_j)e_ie_je_ie_j@*\wedge(e_i, e_j)|\mathcal{R}||\mathcal{R}|\zb^{(i, j)}\yb^{(i, j)}r \in \mathcal{R}\sigma(\cdot)\mathcal{R}\yb\mathcal{R}\mathcal{R}\Gamma(\cdot)\bm{\alpha}\alpha_0\alpha_0\yb\yb\yb{\tt p_{ID}}(\bm{x})\bm{\alpha}_{s}{\tt p_{OOD}}(\bm{x})\bm{\alpha}_{f}\lambda\check{\yb}\bar{\yb}\check{\yb}\bar{\yb}\yb'\beta\beta_1\beta_2\hat{\beta_1}, \hat{\beta_2} = \mathop{\arg \max}\limits_{\beta_1, \beta_2}\psi(\beta_1, \beta_2), \ \ \beta_1, \beta_2 \in [a, b]\psiF_1a, b\yb'\yb'\epsilonr \in \mathcal{R}\zb'\zb'\hat{\yb}T>0T\hat{\yb}\mathcal{H}[\hat{\yb}]F_1F_1F_1F_1F_1F_1\mathcal{R}_{T}\mathcal{R}_{T}\mathcal{R}_{M}\mathcal{R}_{M} \cup \{\textsc{Vague}\}F_1F_1GGGF_1F_1F_1F_1F_1F_1F_1F_1F_1F_1e_1e_2e_3(e_1, e_2)(e_2, e_3)(e_1, e_3)(e_1, e_2, e_3)(e_1, e_2, e_3)(e_1, e_3, e_2)(e_1, e_3, e_2)(e_1, e_2, e_3)(e_1, e_2, e_3)\wedge\wedgeMB_mm \in
\{1, 2, ..., M\}ip_i\frac{m-1}{M}, \frac{m}{M}B_mB_mB_mn\hat{\pi}(Y|X)n\hat{\pi}(Y|X)\pi(Y|X)T\num{5e-6}\bm{\alpha}_{s}\lambda_1 = \lambda_2 = 1\beta\beta_1 = -0.4, \beta_2 = 0.6ab$ equal to -1 and 1.





 
\end{document}
