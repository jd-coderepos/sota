
\documentclass{article} \usepackage{iclr2024_conference,times}



\usepackage{amsmath,amsfonts,bm}

\newcommand{\figleft}{{\em (Left)}}
\newcommand{\figcenter}{{\em (Center)}}
\newcommand{\figright}{{\em (Right)}}
\newcommand{\figtop}{{\em (Top)}}
\newcommand{\figbottom}{{\em (Bottom)}}
\newcommand{\captiona}{{\em (a)}}
\newcommand{\captionb}{{\em (b)}}
\newcommand{\captionc}{{\em (c)}}
\newcommand{\captiond}{{\em (d)}}

\newcommand{\newterm}[1]{{\bf #1}}


\def\figref#1{figure~\ref{#1}}
\def\Figref#1{Figure~\ref{#1}}
\def\twofigref#1#2{figures \ref{#1} and \ref{#2}}
\def\quadfigref#1#2#3#4{figures \ref{#1}, \ref{#2}, \ref{#3} and \ref{#4}}
\def\secref#1{section~\ref{#1}}
\def\Secref#1{Section~\ref{#1}}
\def\twosecrefs#1#2{sections \ref{#1} and \ref{#2}}
\def\secrefs#1#2#3{sections \ref{#1}, \ref{#2} and \ref{#3}}
\def\eqref#1{equation~\ref{#1}}
\def\Eqref#1{Equation~\ref{#1}}
\def\plaineqref#1{\ref{#1}}
\def\chapref#1{chapter~\ref{#1}}
\def\Chapref#1{Chapter~\ref{#1}}
\def\rangechapref#1#2{chapters\ref{#1}--\ref{#2}}
\def\algref#1{algorithm~\ref{#1}}
\def\Algref#1{Algorithm~\ref{#1}}
\def\twoalgref#1#2{algorithms \ref{#1} and \ref{#2}}
\def\Twoalgref#1#2{Algorithms \ref{#1} and \ref{#2}}
\def\partref#1{part~\ref{#1}}
\def\Partref#1{Part~\ref{#1}}
\def\twopartref#1#2{parts \ref{#1} and \ref{#2}}

\def\ceil#1{\lceil #1 \rceil}
\def\floor#1{\lfloor #1 \rfloor}
\def\1{\bm{1}}
\newcommand{\train}{\mathcal{D}}
\newcommand{\valid}{\mathcal{D_{\mathrm{valid}}}}
\newcommand{\test}{\mathcal{D_{\mathrm{test}}}}

\def\eps{{\epsilon}}


\def\reta{{\textnormal{$\eta$}}}
\def\ra{{\textnormal{a}}}
\def\rb{{\textnormal{b}}}
\def\rc{{\textnormal{c}}}
\def\rd{{\textnormal{d}}}
\def\re{{\textnormal{e}}}
\def\rf{{\textnormal{f}}}
\def\rg{{\textnormal{g}}}
\def\rh{{\textnormal{h}}}
\def\ri{{\textnormal{i}}}
\def\rj{{\textnormal{j}}}
\def\rk{{\textnormal{k}}}
\def\rl{{\textnormal{l}}}
\def\rn{{\textnormal{n}}}
\def\ro{{\textnormal{o}}}
\def\rp{{\textnormal{p}}}
\def\rq{{\textnormal{q}}}
\def\rr{{\textnormal{r}}}
\def\rs{{\textnormal{s}}}
\def\rt{{\textnormal{t}}}
\def\ru{{\textnormal{u}}}
\def\rv{{\textnormal{v}}}
\def\rw{{\textnormal{w}}}
\def\rx{{\textnormal{x}}}
\def\ry{{\textnormal{y}}}
\def\rz{{\textnormal{z}}}

\def\rvepsilon{{\mathbf{\epsilon}}}
\def\rvtheta{{\mathbf{\theta}}}
\def\rva{{\mathbf{a}}}
\def\rvb{{\mathbf{b}}}
\def\rvc{{\mathbf{c}}}
\def\rvd{{\mathbf{d}}}
\def\rve{{\mathbf{e}}}
\def\rvf{{\mathbf{f}}}
\def\rvg{{\mathbf{g}}}
\def\rvh{{\mathbf{h}}}
\def\rvu{{\mathbf{i}}}
\def\rvj{{\mathbf{j}}}
\def\rvk{{\mathbf{k}}}
\def\rvl{{\mathbf{l}}}
\def\rvm{{\mathbf{m}}}
\def\rvn{{\mathbf{n}}}
\def\rvo{{\mathbf{o}}}
\def\rvp{{\mathbf{p}}}
\def\rvq{{\mathbf{q}}}
\def\rvr{{\mathbf{r}}}
\def\rvs{{\mathbf{s}}}
\def\rvt{{\mathbf{t}}}
\def\rvu{{\mathbf{u}}}
\def\rvv{{\mathbf{v}}}
\def\rvw{{\mathbf{w}}}
\def\rvx{{\mathbf{x}}}
\def\rvy{{\mathbf{y}}}
\def\rvz{{\mathbf{z}}}

\def\erva{{\textnormal{a}}}
\def\ervb{{\textnormal{b}}}
\def\ervc{{\textnormal{c}}}
\def\ervd{{\textnormal{d}}}
\def\erve{{\textnormal{e}}}
\def\ervf{{\textnormal{f}}}
\def\ervg{{\textnormal{g}}}
\def\ervh{{\textnormal{h}}}
\def\ervi{{\textnormal{i}}}
\def\ervj{{\textnormal{j}}}
\def\ervk{{\textnormal{k}}}
\def\ervl{{\textnormal{l}}}
\def\ervm{{\textnormal{m}}}
\def\ervn{{\textnormal{n}}}
\def\ervo{{\textnormal{o}}}
\def\ervp{{\textnormal{p}}}
\def\ervq{{\textnormal{q}}}
\def\ervr{{\textnormal{r}}}
\def\ervs{{\textnormal{s}}}
\def\ervt{{\textnormal{t}}}
\def\ervu{{\textnormal{u}}}
\def\ervv{{\textnormal{v}}}
\def\ervw{{\textnormal{w}}}
\def\ervx{{\textnormal{x}}}
\def\ervy{{\textnormal{y}}}
\def\ervz{{\textnormal{z}}}

\def\rmA{{\mathbf{A}}}
\def\rmB{{\mathbf{B}}}
\def\rmC{{\mathbf{C}}}
\def\rmD{{\mathbf{D}}}
\def\rmE{{\mathbf{E}}}
\def\rmF{{\mathbf{F}}}
\def\rmG{{\mathbf{G}}}
\def\rmH{{\mathbf{H}}}
\def\rmI{{\mathbf{I}}}
\def\rmJ{{\mathbf{J}}}
\def\rmK{{\mathbf{K}}}
\def\rmL{{\mathbf{L}}}
\def\rmM{{\mathbf{M}}}
\def\rmN{{\mathbf{N}}}
\def\rmO{{\mathbf{O}}}
\def\rmP{{\mathbf{P}}}
\def\rmQ{{\mathbf{Q}}}
\def\rmR{{\mathbf{R}}}
\def\rmS{{\mathbf{S}}}
\def\rmT{{\mathbf{T}}}
\def\rmU{{\mathbf{U}}}
\def\rmV{{\mathbf{V}}}
\def\rmW{{\mathbf{W}}}
\def\rmX{{\mathbf{X}}}
\def\rmY{{\mathbf{Y}}}
\def\rmZ{{\mathbf{Z}}}

\def\ermA{{\textnormal{A}}}
\def\ermB{{\textnormal{B}}}
\def\ermC{{\textnormal{C}}}
\def\ermD{{\textnormal{D}}}
\def\ermE{{\textnormal{E}}}
\def\ermF{{\textnormal{F}}}
\def\ermG{{\textnormal{G}}}
\def\ermH{{\textnormal{H}}}
\def\ermI{{\textnormal{I}}}
\def\ermJ{{\textnormal{J}}}
\def\ermK{{\textnormal{K}}}
\def\ermL{{\textnormal{L}}}
\def\ermM{{\textnormal{M}}}
\def\ermN{{\textnormal{N}}}
\def\ermO{{\textnormal{O}}}
\def\ermP{{\textnormal{P}}}
\def\ermQ{{\textnormal{Q}}}
\def\ermR{{\textnormal{R}}}
\def\ermS{{\textnormal{S}}}
\def\ermT{{\textnormal{T}}}
\def\ermU{{\textnormal{U}}}
\def\ermV{{\textnormal{V}}}
\def\ermW{{\textnormal{W}}}
\def\ermX{{\textnormal{X}}}
\def\ermY{{\textnormal{Y}}}
\def\ermZ{{\textnormal{Z}}}

\def\vzero{{\bm{0}}}
\def\vone{{\bm{1}}}
\def\vmu{{\bm{\mu}}}
\def\vtheta{{\bm{\theta}}}
\def\va{{\bm{a}}}
\def\vb{{\bm{b}}}
\def\vc{{\bm{c}}}
\def\vd{{\bm{d}}}
\def\ve{{\bm{e}}}
\def\vf{{\bm{f}}}
\def\vg{{\bm{g}}}
\def\vh{{\bm{h}}}
\def\vi{{\bm{i}}}
\def\vj{{\bm{j}}}
\def\vk{{\bm{k}}}
\def\vl{{\bm{l}}}
\def\vm{{\bm{m}}}
\def\vn{{\bm{n}}}
\def\vo{{\bm{o}}}
\def\vp{{\bm{p}}}
\def\vq{{\bm{q}}}
\def\vr{{\bm{r}}}
\def\vs{{\bm{s}}}
\def\vt{{\bm{t}}}
\def\vu{{\bm{u}}}
\def\vv{{\bm{v}}}
\def\vw{{\bm{w}}}
\def\vx{{\bm{x}}}
\def\vy{{\bm{y}}}
\def\vz{{\bm{z}}}

\def\evalpha{{\alpha}}
\def\evbeta{{\beta}}
\def\evepsilon{{\epsilon}}
\def\evlambda{{\lambda}}
\def\evomega{{\omega}}
\def\evmu{{\mu}}
\def\evpsi{{\psi}}
\def\evsigma{{\sigma}}
\def\evtheta{{\theta}}
\def\eva{{a}}
\def\evb{{b}}
\def\evc{{c}}
\def\evd{{d}}
\def\eve{{e}}
\def\evf{{f}}
\def\evg{{g}}
\def\evh{{h}}
\def\evi{{i}}
\def\evj{{j}}
\def\evk{{k}}
\def\evl{{l}}
\def\evm{{m}}
\def\evn{{n}}
\def\evo{{o}}
\def\evp{{p}}
\def\evq{{q}}
\def\evr{{r}}
\def\evs{{s}}
\def\evt{{t}}
\def\evu{{u}}
\def\evv{{v}}
\def\evw{{w}}
\def\evx{{x}}
\def\evy{{y}}
\def\evz{{z}}

\def\mA{{\bm{A}}}
\def\mB{{\bm{B}}}
\def\mC{{\bm{C}}}
\def\mD{{\bm{D}}}
\def\mE{{\bm{E}}}
\def\mF{{\bm{F}}}
\def\mG{{\bm{G}}}
\def\mH{{\bm{H}}}
\def\mI{{\bm{I}}}
\def\mJ{{\bm{J}}}
\def\mK{{\bm{K}}}
\def\mL{{\bm{L}}}
\def\mM{{\bm{M}}}
\def\mN{{\bm{N}}}
\def\mO{{\bm{O}}}
\def\mP{{\bm{P}}}
\def\mQ{{\bm{Q}}}
\def\mR{{\bm{R}}}
\def\mS{{\bm{S}}}
\def\mT{{\bm{T}}}
\def\mU{{\bm{U}}}
\def\mV{{\bm{V}}}
\def\mW{{\bm{W}}}
\def\mX{{\bm{X}}}
\def\mY{{\bm{Y}}}
\def\mZ{{\bm{Z}}}
\def\mBeta{{\bm{\beta}}}
\def\mPhi{{\bm{\Phi}}}
\def\mLambda{{\bm{\Lambda}}}
\def\mSigma{{\bm{\Sigma}}}

\DeclareMathAlphabet{\mathsfit}{\encodingdefault}{\sfdefault}{m}{sl}
\SetMathAlphabet{\mathsfit}{bold}{\encodingdefault}{\sfdefault}{bx}{n}
\newcommand{\tens}[1]{\bm{\mathsfit{#1}}}
\def\tA{{\tens{A}}}
\def\tB{{\tens{B}}}
\def\tC{{\tens{C}}}
\def\tD{{\tens{D}}}
\def\tE{{\tens{E}}}
\def\tF{{\tens{F}}}
\def\tG{{\tens{G}}}
\def\tH{{\tens{H}}}
\def\tI{{\tens{I}}}
\def\tJ{{\tens{J}}}
\def\tK{{\tens{K}}}
\def\tL{{\tens{L}}}
\def\tM{{\tens{M}}}
\def\tN{{\tens{N}}}
\def\tO{{\tens{O}}}
\def\tP{{\tens{P}}}
\def\tQ{{\tens{Q}}}
\def\tR{{\tens{R}}}
\def\tS{{\tens{S}}}
\def\tT{{\tens{T}}}
\def\tU{{\tens{U}}}
\def\tV{{\tens{V}}}
\def\tW{{\tens{W}}}
\def\tX{{\tens{X}}}
\def\tY{{\tens{Y}}}
\def\tZ{{\tens{Z}}}


\def\gA{{\mathcal{A}}}
\def\gB{{\mathcal{B}}}
\def\gC{{\mathcal{C}}}
\def\gD{{\mathcal{D}}}
\def\gE{{\mathcal{E}}}
\def\gF{{\mathcal{F}}}
\def\gG{{\mathcal{G}}}
\def\gH{{\mathcal{H}}}
\def\gI{{\mathcal{I}}}
\def\gJ{{\mathcal{J}}}
\def\gK{{\mathcal{K}}}
\def\gL{{\mathcal{L}}}
\def\gM{{\mathcal{M}}}
\def\gN{{\mathcal{N}}}
\def\gO{{\mathcal{O}}}
\def\gP{{\mathcal{P}}}
\def\gQ{{\mathcal{Q}}}
\def\gR{{\mathcal{R}}}
\def\gS{{\mathcal{S}}}
\def\gT{{\mathcal{T}}}
\def\gU{{\mathcal{U}}}
\def\gV{{\mathcal{V}}}
\def\gW{{\mathcal{W}}}
\def\gX{{\mathcal{X}}}
\def\gY{{\mathcal{Y}}}
\def\gZ{{\mathcal{Z}}}

\def\sA{{\mathbb{A}}}
\def\sB{{\mathbb{B}}}
\def\sC{{\mathbb{C}}}
\def\sD{{\mathbb{D}}}
\def\sF{{\mathbb{F}}}
\def\sG{{\mathbb{G}}}
\def\sH{{\mathbb{H}}}
\def\sI{{\mathbb{I}}}
\def\sJ{{\mathbb{J}}}
\def\sK{{\mathbb{K}}}
\def\sL{{\mathbb{L}}}
\def\sM{{\mathbb{M}}}
\def\sN{{\mathbb{N}}}
\def\sO{{\mathbb{O}}}
\def\sP{{\mathbb{P}}}
\def\sQ{{\mathbb{Q}}}
\def\sR{{\mathbb{R}}}
\def\sS{{\mathbb{S}}}
\def\sT{{\mathbb{T}}}
\def\sU{{\mathbb{U}}}
\def\sV{{\mathbb{V}}}
\def\sW{{\mathbb{W}}}
\def\sX{{\mathbb{X}}}
\def\sY{{\mathbb{Y}}}
\def\sZ{{\mathbb{Z}}}

\def\emLambda{{\Lambda}}
\def\emA{{A}}
\def\emB{{B}}
\def\emC{{C}}
\def\emD{{D}}
\def\emE{{E}}
\def\emF{{F}}
\def\emG{{G}}
\def\emH{{H}}
\def\emI{{I}}
\def\emJ{{J}}
\def\emK{{K}}
\def\emL{{L}}
\def\emM{{M}}
\def\emN{{N}}
\def\emO{{O}}
\def\emP{{P}}
\def\emQ{{Q}}
\def\emR{{R}}
\def\emS{{S}}
\def\emT{{T}}
\def\emU{{U}}
\def\emV{{V}}
\def\emW{{W}}
\def\emX{{X}}
\def\emY{{Y}}
\def\emZ{{Z}}
\def\emSigma{{\Sigma}}

\newcommand{\etens}[1]{\mathsfit{#1}}
\def\etLambda{{\etens{\Lambda}}}
\def\etA{{\etens{A}}}
\def\etB{{\etens{B}}}
\def\etC{{\etens{C}}}
\def\etD{{\etens{D}}}
\def\etE{{\etens{E}}}
\def\etF{{\etens{F}}}
\def\etG{{\etens{G}}}
\def\etH{{\etens{H}}}
\def\etI{{\etens{I}}}
\def\etJ{{\etens{J}}}
\def\etK{{\etens{K}}}
\def\etL{{\etens{L}}}
\def\etM{{\etens{M}}}
\def\etN{{\etens{N}}}
\def\etO{{\etens{O}}}
\def\etP{{\etens{P}}}
\def\etQ{{\etens{Q}}}
\def\etR{{\etens{R}}}
\def\etS{{\etens{S}}}
\def\etT{{\etens{T}}}
\def\etU{{\etens{U}}}
\def\etV{{\etens{V}}}
\def\etW{{\etens{W}}}
\def\etX{{\etens{X}}}
\def\etY{{\etens{Y}}}
\def\etZ{{\etens{Z}}}

\newcommand{\pdata}{p_{\rm{data}}}
\newcommand{\ptrain}{\hat{p}_{\rm{data}}}
\newcommand{\Ptrain}{\hat{P}_{\rm{data}}}
\newcommand{\pmodel}{p_{\rm{model}}}
\newcommand{\Pmodel}{P_{\rm{model}}}
\newcommand{\ptildemodel}{\tilde{p}_{\rm{model}}}
\newcommand{\pencode}{p_{\rm{encoder}}}
\newcommand{\pdecode}{p_{\rm{decoder}}}
\newcommand{\precons}{p_{\rm{reconstruct}}}

\newcommand{\laplace}{\mathrm{Laplace}} 

\newcommand{\E}{\mathbb{E}}
\newcommand{\Ls}{\mathcal{L}}
\newcommand{\R}{\mathbb{R}}
\newcommand{\emp}{\tilde{p}}
\newcommand{\lr}{\alpha}
\newcommand{\reg}{\lambda}
\newcommand{\rect}{\mathrm{rectifier}}
\newcommand{\softmax}{\mathrm{softmax}}
\newcommand{\sigmoid}{\sigma}
\newcommand{\softplus}{\zeta}
\newcommand{\KL}{D_{\mathrm{KL}}}
\newcommand{\Var}{\mathrm{Var}}
\newcommand{\standarderror}{\mathrm{SE}}
\newcommand{\Cov}{\mathrm{Cov}}
\newcommand{\normlzero}{L^0}
\newcommand{\normlone}{L^1}
\newcommand{\normltwo}{L^2}
\newcommand{\normlp}{L^p}
\newcommand{\normmax}{L^\infty}

\newcommand{\parents}{Pa} 

\DeclareMathOperator*{\argmax}{arg\,max}
\DeclareMathOperator*{\argmin}{arg\,min}

\DeclareMathOperator{\sign}{sign}
\DeclareMathOperator{\Tr}{Tr}
\let\ab\allowbreak
 
\usepackage{hyperref}
\usepackage{url}
\usepackage{graphicx}
\usepackage[ruled,vlined]{algorithm2e}
\usepackage{graphicx}
\usepackage{setspace}
\usepackage{wrapfig}
\usepackage{multirow}
\usepackage{booktabs}
\usepackage{subfigure}
\usepackage{pdfpages}
\usepackage{wrapfig}


\title{Text2NKG: Fine-Grained N-ary Relation Extraction for N-ary relational Knowledge Graph Construction}



\author{{\bf Haoran Luo\textsuperscript{\rm 1}, Haihong E\textsuperscript{\rm 1}\thanks{\ \ Corresponding author.}  , Yuhao Yang\textsuperscript{\rm 2}, Tianyu Yao\textsuperscript{\rm 1}, Yikai Guo\textsuperscript{\rm 3},} \\{\bf Zichen Tang\textsuperscript{\rm 1}, Wentai Zhang\textsuperscript{\rm 1}, Kaiyang Wan\textsuperscript{\rm 1}, Shiyao Peng\textsuperscript{\rm 1}, Meina Song\textsuperscript{\rm 1}, Wei Lin\textsuperscript{\rm 4}} \\
         \textsuperscript{1}School of Computer Science, Beijing University of Posts and Telecommunications, China \\ 
         \textsuperscript{2}School of Automation Science and Electrical Engineering, Beihang University, China \\ 
         \textsuperscript{3}Beijing Institute of Computer Technology and Application 
         \ \textsuperscript{4}Inspur Group Co., Ltd., China \\ 
         \texttt{\{luohaoran, ehaihong\}@bupt.edu.cn}}



\newcommand{\fix}{\marginpar{FIX}}
\newcommand{\new}{\marginpar{NEW}}

\begin{document}


\maketitle

\begin{abstract}
Beyond traditional binary relational facts, n-ary relational knowledge graphs (NKGs) are comprised of n-ary relational facts containing more than two entities, which are closer to real-world facts with broader applications. However, the construction of NKGs still significantly relies on manual labor, and n-ary relation extraction still remains at a course-grained level, which is always in a single schema and fixed arity of entities. To address these restrictions, we propose Text2NKG, a novel fine-grained n-ary relation extraction framework for n-ary relational knowledge graph construction. We introduce a span-tuple classification approach with hetero-ordered merging to accomplish fine-grained n-ary relation extraction in different arity. Furthermore, Text2NKG supports four typical NKG schemas: hyper-relational schema, event-based schema, role-based schema, and hypergraph-based schema, with high flexibility and practicality. Experimental results demonstrate that Text2NKG outperforms the previous state-of-the-art model by nearly 20\% points in the $F_1$ scores on the fine-grained n-ary relation extraction benchmark in the hyper-relational schema. Our code and datasets are publicly available at \url{https://github.com/LHRLAB/Text2NKG}.
\end{abstract}

\section{Introduction}
\label{introduction}


\begin{wrapfigure}{r}{0.5\textwidth}
\vspace{-5mm}
\centering
\includegraphics[width=7cm]{F0.drawio.pdf}
\caption{An example of NKG construction.}
\label{f0}
\vspace{-2mm}
\end{wrapfigure}

Modern knowledge graphs, such as Freebase~\citep{Freebase}, Google Knowledge Vault~\citep{GoogleKG}, and Wikidata~\citep{Wikidata}, convert unstructured knowledge to structured multi-relational graphs with various applications in question-and-answer~\citep{KGQA}, query-answering~\citep{KGquery}, logical reasoning~\citep{FuzzQE}, and recommendation systems~\citep{KGRS}. Traditional knowledge graphs consist of triple-based facts ($subject$, $relation$, $object$) with two entities and one relation between them~\citep{TransE, TuckER}. However, real-world facts tend to contain more than two entities, which are called n-ary relational facts ($n\geq 2$), which cannot be represented by merging binary relations. For example, considering the statement: ``\texttt{Einstein received his Bachelor degree in Mathematics and his Doctorate degree in Physics.}", if broken down into binary relations, we can't merge them again effectively because we can't determine whether \texttt{Einstein}'s \texttt{Doctorate} major was in \texttt{Physics} or \texttt{Mathematics}, which necessitates the use of N-ary relational Knowledge Graphs (NKG) to represent such information, like (\texttt{Einstein, degree, Doctorate, major, Physics}). As shown in Figure~\ref{f0}, an NKG consists of numerous n-ary relational facts with richer knowledge representation and a wider application capability.

\begin{figure*}[t]
\centering
\includegraphics[width=14cm]{F1.drawio.pdf}
\caption{An example of fine-grained n-ary relation extraction in four NKG schemas. }
\label{f1}
\end{figure*}

Each NKG has a schema to represent the structure of every n-ary relational fact in the NKG. For example, Wikidata utilizes n-ary relational facts with hyper-relational schema~\citep{Hinge, StarE, GRAN}, i.e., ($ s, r, o, \{(k_i, v_i)\}_{i=1}^{n-2}$) adds $(n-2)$ key-value pairs to the main triple to represent auxiliary information, forming an n-ary relational fact with n entities. In addition to the hyper-relational schema, the n-ary relational facts of NKGs also have event-based schema ($r,\{(k_i, v_i)\}_{i=1}^{n}$)~\citep{EventSurvey,Text2Event}, role-based schema ($\{(k_i, v_i)\}_{i =1}^{n}$)~\citep{NaLP,RAM} and hypergraph-based schema ($r,\{v_i\}_{i=1}^{n}$)~\citep{m-TransH,HypE} for different scenarios. Extracting these n-ary relational facts from textual knowledge is called n-ary relation extraction, which is the key step in NKG construction. Taking a real-world textual fact ``\texttt{Einstein received his Doctorate degree in Physics from the University of Zurich.}" as an example, through n-ary relation extraction, we can extract a four-arity structured span-tuple for entities (\texttt{Einstein, University of Zurich, Doctorate, Physics}) with an answer label-list for relations accordingly as a 4-ary relational fact from the sentence as shown in Figure~\ref{f1}.

However, most existing NKGs, such as JF17K~\citep{m-TransH}, Wikipeople~\citep{NaLP}, WD50K~\citep{StarE}, EventKG~\citep{EventSurvey}, etc., are constructed manually but not automatically. The key step of knowledge graph construction is relation extraction, but most relation extraction methods target traditional binary relational facts~\citep{table-filling,PURE,PL-Marker}. The n-ary relation extraction methods are currently always focused on the course-grained extraction with solid keys~\citep{documentlevelNRE,ReSel}, but are not competent for fine-grained NKG construction with various n-ary relations. Recently, CubeRE~\citep{HyperRED} proposes the cube-filling method, the only fine-grained n-ary relation extraction method. Nevertheless, it can only perform hyper-relational extraction with limited accuracy and cannot cover other useful NKG schemas.

To address these challenges, we propose a novel n-ary relation extraction framework, Text2NKG, which automates the generation of n-ary relational facts from natural language text for NKG construction. Text2NKG proposes a span-tuple multi-label classification method with hetero merging, which converts n-ary relation extraction into a multi-label classification problem for span-tuples consisting of all arrangements of three entities in a sentence. The number of labels is determined by the number of relations in the selected NKG schema. Text2NKG can be applied to all NKG schemas, with hyper-relational schema, event-based schema, role-based schema, and hypergraph-based schema provided as examples, which have a wide range of applications.

In addition, we extend the current n-ary relation extraction benchmark HyperRED~\citep{HyperRED}, which is only in the hyper-relational schema, to four NKG schemas. We've done sufficient n-ary relation extraction experiments on HyperRED, and the experimental results show that Text2NKG achieves nearly 20 percentage points ahead of the existing state-of-the-art model CubeRE in $F_1$ scores of hyper-relational extraction. We also compared the results of Text2NKG in four schemas to verify applications. 







\section{Related Work}

\textbf{N-ary relational Knowledge Graph. }
An n-ary relational knowledge graph (NKG) consists of n-ary relational facts, which contain $n$ entities ($n\geq 2$) and several relations. The n-ary relational facts are necessary and cannot be replaced by combinations of some binary relational facts because we cannot distinguish which binary relations are combined to represent the n-ary relational fact in the whole KG. Therefore, NKG utilizes a schema in every n-ary relational fact locally and a hypergraph representation globally. 
Firstly, the simplest NKG schema is hypergraph-based. \cite{m-TransH} found that over 30\% of Freebase~\citep{Freebase} entities participate facts with more than two entities, first defined n-ary relations mathematically and used star-to-clique conversion to convert triple-based facts representing n-ary relational facts into the first NKG dataset JF17K in hypergraph-based schema ($r,\{v_i\}_{i=1}^{n}$). \cite{HypE} proposed FB-AUTO and M-FB15K with the same hypergraph-based schema. Secondly, \cite{NaLP} introduced role information for n-ary relational facts and extracted Wikipeople, the first NKG dataset in role-based schema ($\{(k_i, v_i)\}_{i =1}^{n}$), composed of role-value pairs. Thirdly, Wikidata~\citep{Wikidata}, the largest knowledge base, utilizes an NKG schema based on hyper-relation ($ s, r, o, \{(k_i, v_i)\}_{i=1}^{n-2}$), which adds auxiliary key-value pairs to the main triple. \cite{StarE} first proposed an NKG dataset in hyper-relational schema WD50K. Fourthly, as \cite{EventSurvey} pointed out, events are also n-ary relational facts. One basic event representation has an event type, a trigger, and several key-value pairs~\citep{Text2Event}. Regarding the event type as the main relation, the (trigger: value) as one of the key-value pairs, and the arguments as the rest key-value pairs, we can obtain an event-based NKG schema ($r,\{(k_i, v_i)\}_{i=1}^{n}$).

Based on four common NKG schemas, we propose Text2NKG, the first method for extraction of structured n-ary relational facts from natural language text, which improves NKG representation and application.

\textbf{N-ary Relation Extraction. }
Relation extraction is an important part of knowledge graph construction, directly affecting the quality, scale, and application of KGs. While most of the current n-ary relation extraction for NKG construction depends on manual construction~\citep{m-TransH,NaLP,StarE} but not automated methods. Most automated relation extraction methods target the extraction of traditional binary relational facts. For example, \cite{table-filling} proposes a table-filling method for binary relation extraction, and \cite{PURE,PL-Marker} propose span-based relation extraction methods with levitated marker and packed levitated marker, respectively. 
For n-ary relation automated extraction, some approaches~\citep{documentlevelNRE,Document2,Document3} treat n-ary relation extraction as a binary classification problem and predict whether the composition of n-ary information in a document is valid or not. However, these methods extract n-ary information in fixed arity, which are not flexible. Moreover, most of these methods are based on the course-grained level with solid keys, which is not competent for fine-grained NKG construction with various n-ary relations. Recently, \cite{HyperRED} proposes the only automated n-ary relation extraction method, CubeRE, which extends the table-filling extraction method to n-ary relation extraction with cube-filling. However, it can only model hyper-relational schema with limited extraction accuracy.

In this paper, we propose the first fine-grained n-ary relation extraction framework Text2NKG for NKG construction in four example schemas, proposing a span-tuple multi-label classification method with hetero-ordered merging to improve the accuracy of hyper-relational extraction substantially.



\section{Preliminaries}
\textbf{Formulation of NKG. } 
An NKG $\mathcal{G}=\{\mathcal{E},\mathcal{R},\mathcal{F}\}$ consists of an entity set $\mathcal{E}$, a relation set $\mathcal{R}$, and an n-ary fact (n$\geq$2) set $\mathcal{F}$. Each n-ary fact $f^n \in \mathcal{F}$ consists of entities $\in \mathcal{E}$ and relations $\in \mathcal{R}$.
For hyper-relational schema~\citep{Hinge}: $f^n_{hr}=(e_1,r_1,e_2,\{r_{i-1},e_i\}_{i=3}^{n}) $ where $\{e_i\}_{i=1}^{n}\in \mathcal{E}$, $\{r_i\}_{i=1}^{n-1}\in \mathcal{R}$.
For event-based schema~\citep{Text2Event}: $f^n_{ev}=(r_1,\{r_{i+1},e_i\}_{i=1}^{n})$, where $\{e_i\}_{i=1}^{n}\in \mathcal{E}$, $\{r_i\}_{i=1}^{n+1}\in \mathcal{R}$. 
For role-based schema~\citep{NaLP}: $f^n_{ro}=(\{r_i,e_i\}_{i=1}^{n})$, where $\{e_i\}_{i=1}^{n}\in \mathcal{E}$, $\{r_i\}_{i=1}^{n}\in \mathcal{R}$.
For hypergraph-based schema~\citep{m-TransH}: $f^n_{hg}=(r_1,\{e_i\}_{i=1}^{n})$, where $\{e_i\}_{i=1}^{n}\in \mathcal{E}$, $r_1\in \mathcal{R}$.






\textbf{Problem Definition. }
Given an input sentence with $l$ words $s=\{w_1,w_2,...,w_l\}$, an entity $e$ is a consecutive span of words: $e=\{w_p,w_{p+1},...,w_q\}\in \mathcal{E}_s$, where $p,q\in\{1,...,l\}$, and $\mathcal{E}_s=\{e_j\}_{j=1}^m$ is the entity set of all $m$ entities in the sentence. The output of n-ary relation extraction, $R()$, is a set of n-ary relational facts $\mathcal{F}_s$ in given NKG schema in $\{f^n_{hr},f^n_{ev},f^n_{ro},f^n_{hg}\}$. Specifically, each n-ary relational fact $f^n \in \mathcal{F}_s$ is extracted by multi-label classification of one of the ordered span-tuple for $n$ entities $[e_i]_{i=1}^n\in\mathcal{E}_s$, forming an answer label-list for $n_r$ relations $[r_i]_{i=1}^{n_r}\in\mathcal{R}$, where $n$ is the arity of the extracted n-ary relational fact, and $n_r$ is the number of answer relations in the fact, which is determined by the given NKG schema: $R([e_i]_{i=1}^n)=[r_i]_{i=1}^{n-1}$, when $f^n=f^n_{hr}$, $R([e_i]_{i=1}^n)=[r_i]_{i=1}^{n+1}$ when $f^n=f^n_{ev}$, $R([e_i]_{i=1}^n)=[r_i]_{i=1}^{n}$ when $f^n=f^n_{ro}$, and $R([e_i]_{i=1}^n)=[r_1]$ when $f^n=f^n_{hg}$.


\begin{figure*}[t]
\centering
\includegraphics[width=13.8cm]{F2.drawio.pdf}
\caption{An overview of Text2NKG extracting n-ary relation facts from a natural language sentence in hyper-relational NKG schema for an example. }
\label{f2}
\end{figure*}


\section{Methodology}
In this section, we first introduce the overview of the Text2NKG framework, followed by the span-tuple multi-label classification, training strategy, hetero-ordered merging, and output merging.

\subsection{Overview of Text2NKG}
Text2NKG is a fine-grained n-ary relation extraction framework built for n-ary relational knowledge graph (NKG) construction. The input to Text2NKG is natural language text tokens labeled with entity span in sentence units. We \textbf{extract 3-ary facts as an atomic unit} and then \textbf{merge them into n-ary facts} later to realize n-ary extraction of arbitrary arity. Because if using binary facts, merging them into n-ary facts based on shared elements within these facts will lead to misunderstandings as analyzed in Section~\ref{introduction}. On the other hand, using facts with four entities or more makes it challenging to judge which of the included 3-ary facts can be extracted as independent facts.

Specifically, inspired by \cite{PL-Marker}, Text2NKG first encodes the entities using BERT-based Encoder~\citep{Bert} with a packaged levitated marker for embedding. Then, each arrangement of ordered span-tuple with three entity embeddings will be classified with multiple labels, and the framework will be learned by the weighted cross-entropy with a null-label bias. In the decoding stage, in order to filter the n-ary relational facts whose entity compositions have isomorphic hetero-ordered characteristics, Text2NKG proposes a hetero-ordered merging strategy to merge the label probabilities of $3!=6$ arrangement cases of span-tuples composed of the same entities and filter out the output 3-ary relational facts existing non-conforming relations. Finally, Text2NKG combines the output 3-ary relational facts to form the final n-ary relational facts with output merging.

\subsection{Span-tuple Multi-label Classification}

 

For the given sentence token $s=\{w_1,w_2,...,w_l\}$ and the set of entities $\mathcal{E}_s$, in order to perform fine-grained n-ary relation extraction, we need first to encode a span-tuple ($e_1,e_2,e_3$) consisting of every arrangement of three ordered entities, where $e_1,e_2,e_3\in \mathcal{E}_s$. Due to the high time complexity of training every span-tuple as one training item, inspired by \cite{PL-Marker}, we achieve the reduction of training items by using packed levitated markers that pack one training item with each entity in $\mathcal{E}_s$ separately. Specifically, in each packed training item, a pair of solid tokens, [S] and [/S], are added before and after the packed entity $e_S=\{w_{p_S},...,w_{q_S}\}$, and ($|\mathcal{E}_s|-1$) pairs of levitated markers, [L] and [/L], according to other entities in $\mathcal{E}_s$, are added with the same position embeddings as the beginning and end of their corresponding entities span $e_{L_i}=\{w_{p_{L_i}},...,w_{q_{L_i}}\}$ to form the input token $\mathbf{X}$:
\begin{equation}
\begin{aligned}
\mathbf{X}=&\{w_1,...,[S],w_{p_S},...,w_{q_S},[/S],...,\\&w_{p_{L_i}}\cup[L],...,w_{q_{L_i}}\cup[/L],...,w_l\}.
\end{aligned}
\end{equation}
We encode such token by the BERT-based pre-trained model encoder~\citep{Bert}:
\begin{equation}
\{h_1,h_2,...,h_t\}=\text{BERT}(\mathbf{X}),
\end{equation}
where $t=|\mathbf{X}|$ is the imput token length, $\{h_i\}_{i=1}^t \in \mathbb{R}^d$, and $d$ is embedding size.

There are several span-tuples ($A,B,C$) in a training item. The embedding of first entity $h_{A}\in\mathbb{R}^{2d}$ in the span-tuple is obtained by concat embedding of the solid markers, [S] and [/S], and the embeddings of second and third entities $h_{B}, h_{C}\in\mathbb{R}^{2d}$ are obtained by concat embeddings of levitated markers, [L] and [/L] with all $A_{m-1}^2$ arrangement of any other two entities in $\mathcal{E}_s$. Thus, we obtain the embedding representation of the three entities to form $A_{m-1}^2$ span-tuples in one training item. Therefore, every input sentence contains $m$ training items with $mA_{m-1}^2=A_{m}^3$ span-tuples for any ordered arrangement of three entities.

We then define $3 \times n_r$ linear classifiers $\{\text{FNN}^k_i\}_{i=1}^{n_r}, k=1,2,3$ to classify the span-tuples for multiple-label classification. Each classifier targets the prediction of one relation $r_i$, thus obtaining a probability lists $(\mathbf{P}_i)_{i=1}^{n_r}$ with all relations in given relation set $\mathcal{R}$ plus a null-label:
\begin{equation}
\mathbf{P}_i=\text{FNN}^1_i(h_{A})+\text{FNN}^2_i(h_{B})+\text{FNN}^3_i(h_{C}),
\end{equation}
where $\text{FNN}^k_i\in\mathbb{R}^{2d\times (|\mathcal{R}|+1)}$, and $\mathbf{P}_i\in \mathbb{R}^{(|\mathcal{R}|+1)}$. 




\subsection{Training Strategy}
In order to train the $n_r$ classifiers for each relation prediction more accurately, we performed data augmentation strategy in terms of span-tuples. Taking the hyper-relational schema as an example, given a hyper-relational fact ($A,r_1,B,r_2,C$), we consider swapping the head and tail entities and changing the main relation to the corresponding inverse relation ($B,r_1^{-1},A,r_2,C$), as well as swapping the tail entities and auxiliary values, and swapping the main relation and the auxiliary key ($A,r_2,C,r _1,B$) also as labeled training span-tuple cases. Thus $R_{hr}(A,B,C)=(r_1,r_2)$ can be augmented with $3!=6$ orders of span-tuples:
\begin{equation}
\left\{
\begin{aligned}
&R_{hr}(A,B,C)=(r_1,r_2),\\
&R_{hr}(B,A,C)=(r_1^{-1},r_2),\\
&R_{hr}(A,C,B)=(r_2,r_1),\\
&R_{hr}(B,C,A)=(r_2,r_1^{-1}),\\
&R_{hr}(C,A,B)=(r_2^{-1},r_1),\\
&R_{hr}(C,B,A)=(r_1,r_2^{-1}).\\
\end{aligned}
\right.
\label{e9}
\end{equation}
For other schemas, we can also obtain 6 fully-arranged cases of labeled span-tuples in a similar way, as described in Appendix~\ref{AppA}. If no n-ary relational fact exists between the three entities of span-tuples, then relation labels are set as null-label.

Since most cases of span-tuple are null-label, we set a weight hyperparameter $\alpha \in (0,1]$ between the null-labels and other labels to balance the learning of the null-label. We jointly trained the $n_r$ classifiers for each relations by cross-entropy loss $\mathcal{L}$ with a null-label weight bias $\mathbf{W}_{\alpha}$: 
\begin{equation}
\mathcal{L}=-\sum_{i=1}^{n_r}\mathbf{W}_{\alpha} \log\left( \frac{\exp \left(\mathbf{P}_i[r_i]\right)}{\sum_{j=1}^{|\mathcal{R}|+1} \exp \left(\mathbf{P}_{ij}\right)}\right) ,
\end{equation}
where $\mathbf{W}_{\alpha}=[\alpha,1.0,1.0,...1.0]\in \mathbb{R}^{(|\mathcal{R}|+1)}$.




\subsection{Hetero-ordered Merging}
In the decoding stage, since Text2NKG labels all 6 different arrangement of the same entity composition, we design a hetero-ordered merging strategy to merge the corresponding labels of these 6 hetero-ordered span-tuples into one to generate non-repetitive n-ary relational facts unsupervisedly. For hyper-relational schema ($n_r=2$), we combine the predicted probabilities of two labels $\mathbf{P}_{1},\mathbf{P}_{2}$ in 6 orders to ($A,B,C$) order as follows:
\begin{equation}
\left\{
\begin{aligned}
\mathbf{P}_{1}=&\ \mathbf{P}_1^{(ABC)}+I(\mathbf{P}_1^{(BAC)})+\mathbf{P}_2^{(ACB)}\\
&+I(\mathbf{P}_2^{(BCA)})+\mathbf{P}_2^{(CAB)}+\mathbf{P}_1^{(CBA)},\\
\mathbf{P}_{2}=&\ \mathbf{P}_2^{(ABC)}+\mathbf{P}_2^{(BAC)}+\mathbf{P}_1^{(ACB)}\\
&+\mathbf{P}_1^{(BCA)}+I(\mathbf{P}_1^{(CAB)})+I(\mathbf{P}_2^{(CBA)}),\\
\end{aligned}
\right.
\end{equation}
where $I()$ is a function for swapping the predicted probability of relations and the corresponding inverse relations. Then, we take the maximum probability to obtain labels $r_1,r_2$, forming a 3-ary relational fact ($A,r_1,B,r_2,C$) and filter it out if there are null-labels in ($r_1,r_2$). If there are inverse relation labels in ($r_1,r_2$), we can also transform the order of entities and relations as equation~\ref{e9}. For event-based schema, role-based schema, and hypergraph-based schema, all can be generated by hetero-ordered merging according to this idea, shown in Appendix~\ref{AppB}.

\subsection{Output Merging}
After hetero-ordered merging, we merge the output 3-ary relational facts to form higher-arity facts, with hyper-relational schema based on the same main triple, event-based schema based on the same main relation (event type), role-based schema based on the same key-value pairs, and hypergraph-based schema based on the same hyperedge relation. This way, we can \textbf{unsupervisedly} obtain n-ary relational facts \textbf{with dynamic number of arity numbers} for NKG construction. 





\begin{table*}[t]
\centering
\scriptsize
\setlength{\tabcolsep}{1.0mm}{
\begin{tabular}{lccccccccccccc}
\toprule
\multirow{2.5}{*}{\textbf{Dataset}} & \multirow{2.5}{*}{\textbf{\#Ent}} & \multirow{2.5}{*}{\textbf{\#R\_hr}} & \multirow{2.5}{*}{\textbf{\#R\_ev}} & \multirow{2.5}{*}{\textbf{\#R\_ro}} & \multirow{2.5}{*}{\textbf{\#R\_hg}} & \multicolumn{2}{c}{\textbf{All}}      & \multicolumn{2}{c}{\textbf{Train}}    & \multicolumn{2}{c}{\textbf{Dev}}      & \multicolumn{2}{c}{\textbf{Test}}     \\
\cmidrule(lr){7-8}\cmidrule(lr){9-10}\cmidrule(lr){11-12}\cmidrule(lr){13-14}
                                  &                                 &                                   &                                   &                                   &                                   & \textbf{\#Sentence} & \textbf{\#Fact} & \textbf{\#Sentence} & \textbf{\#Fact} & \textbf{\#Sentence} & \textbf{\#Fact} & \textbf{\#Sentence} & \textbf{\#Fact} \\
\midrule
HyperRED                          & 40,293                          & 106                               & 232                               & 168                               & 62                                & 44,840              & 45,994          & 39,840              & 39,978          & 1,000               & 1,220           & 4,000               & 4,796           \\
\bottomrule
\end{tabular}}
\caption{\label{t2}
Dataset statistics, where the columns indicate the number of entities, relations with four schema, sentences and n-ary relational facts in all sets, train set, dev set, and test set,respectively.
}
\end{table*}


\section{Experiments}

This section presents the experimental setup, results, and analysis. We answer the following research questions (RQs):
\textbf{RQ1}: Does Text2NKG outperform other fine-grained n-ary relation extraction methods?
\textbf{RQ2}: Whether Text2NKG can cover NKG construction for various schemas?
\textbf{RQ3}: Does the main components of Text2NKG work?
\textbf{RQ4}: How does the null-label bias hyperparameter in Text2NKG affect performance?
\textbf{RQ5}: Can Text2NKG get complete n-ary relational facts in different arity?
\textbf{RQ6}: How does Text2NKG perform in specific case study?
\textbf{RQ7}: What is the future development of Text2NKG in the era of large language models?

\subsection{Experimental Setup}

\textbf{Datasets. }
The HyperRED~\citep{HyperRED} dataset is the only existing dataset for extracting n-ary relations with annotated extracted entities. Therefore, we expand the HyperRED dataset to four schemas as standard fine-grained n-ary relation extraction benchmarks and conduct experiments on them. The statistics of the HyperRED with four schemas are shown in Table~\ref{t2}, and the construction detail is in Appendix~\ref{datasetc}.

\textbf{Baselines. } We compare Text2NKG against \textbf{Generative Baseline}~\citep{BART}, \textbf{Pipeline Baseline}~\citep{UniRE}, and \textbf{CubeRE}~\citep{HyperRED} in fine-grained n-ary relation extraction task of hyper-relational schema. For n-ary relation extraction in the other three schemas, we compared Text2NKG with event extraction models such as \textbf{Text2Event}~\citep{Text2Event}, \textbf{UIE}~\citep{UIE}, and \textbf{LasUIE}~\citep{LasUIE}. Furthermore, we utilized different prompts to test the currently most advanced large-scale pre-trained language models \textbf{ChatGPT}~\citep{ChatGPT} and \textbf{GPT-4}~\citep{GPT-4} in an unsupervised manner, specifically for the extraction performance across the four schemas. The detailed baseline settings can be found in Appendix~\ref{baseline}.

\textbf{Ablations. } To evaluate the significance of Text2NKG's three main components, data augmentation (DA), null-label weight hyperparameter ($\alpha$), and hetero-ordered merging (HM), we obtain three simplified model variants by removing any one component from the model (\textbf{Text2NKG w/o DA}, \textbf{Text2NKG w/o $\alpha$}, and \textbf{Text2NKG w/o HM}) for comparison.


\textbf{Evaluation Metrics. }
We use the $F_1$ score with precision and recall to evaluate the dev set and the test set. For a predicted n-ary relational fact to be considered correct, the entire fact must match the ground facts completely.

\textbf{Hyperparameters and Enviroment. }
We train 10 epochs on HyperRED using the Adam optimizer. All experiments were done on a single NVIDIA A100 GPU, and all experimental results were derived by averaging five random seed experiments. Appendix~\ref{hyper} shows Text2NKG's optimal hyperparameter settings. Appendix~\ref{train} shows training details.


\begin{table*}[t]
\centering
\scriptsize
\setlength{\tabcolsep}{1.35mm}{
\begin{tabular}{lcccc|ccc}
\toprule
\multicolumn{1}{c}{\multirow{2}{*}{\textbf{Model}}} & \multicolumn{1}{c}{\multirow{2}{*}{\textbf{PLM}}} & \multicolumn{3}{c}{\textbf{HyperRED : Hyper-relational / Dev}}                      & \multicolumn{3}{c}{\textbf{HyperRED : Hyper-relational / Test}} \\ \cline{3-8} 
\multicolumn{1}{c}{}                                & \multicolumn{1}{c}{}                              & Precision             & Recall                & \multicolumn{1}{c|}{$F_1$}                 & Precision              & Recall                & $F_1$                 \\ \hline
\multicolumn{8}{c}{\textbf{Unsupervised Method}}                                                                                                                                                                                                                              \\ \hline
ChatGPT                                             & gpt-3.5-turbo ($\approx$175B)                             & 12.0583               & 11.2764               & \multicolumn{1}{c|}{11.6542}               & 11.4021                & 10.9134               & 11.1524               \\
GPT-4                                               & gpt-4 ($\approx$1760B)                                    & 15.7324               & 15.2377               & \multicolumn{1}{c|}{15.4811}               & 15.8187                & 15.4824               & 15.6487               \\ \hline
\multicolumn{8}{c}{\textbf{Supervised Method}}                                                                                                                                                                                                                                \\ \hline
Generative Baseline                                 & \multirow{7}{*}{BERT-base (110M)}                 & 63.79 ± 0.27          & 59.94 ± 0.68          & \multicolumn{1}{c|}{61.80 ± 0.37}          & 64.60 ± 0.47           & 59.67 ± 0.35          & 62.03 ± 0.21          \\
Pipelinge Baseline                                  &                                                   & 69.23 ± 0.30          & 58.21 ± 0.57          & \multicolumn{1}{c|}{63.24 ± 0.44}          & 69.00 ± 0.48           & 57.55 ± 0.19          & 62.75 ± 0.29          \\
CubeRE                                              &                                                   & 66.14 ± 0.88          & 64.39 ± 1.23          & \multicolumn{1}{c|}{65.23 ± 0.82}          & 65.82 ± 0.84           & 64.28 ± 0.25          & 65.04 ± 0.29          \\
Text2NKG w/o DA                                     &                                                   & 76.02 ± 0.50          & 72.28 ± 0.68          & \multicolumn{1}{c|}{74.10 ± 0.55}          & 73.55 ± 0.81           & 70.63 ± 1.40          & 72.06 ± 0.34          \\
Text2NKG w/o $\alpha$                               &                                                   & 88.77 ± 0.85          & 78.39 ± 0.47          & \multicolumn{1}{c|}{83.26 ± 0.70}          & 88.09 ± 0.69           & 76.64 ± 0.45          & 81.97 ± 0.58          \\
Text2NKG w/o HM                                     &                                                   & 61.74 ± 0.34          & 76.97 ± 0.44          & \multicolumn{1}{c|}{68.52 ± 0.69}          & 61.07 ± 0.73           & 76.16 ± 0.59          & 67.72 ± 0.48          \\
Text2NKG (ours)                                     &                                                   & \textbf{91.26 ± 0.69} & \textbf{79.36 ± 0.51} & \multicolumn{1}{c|}{\textbf{84.89 ± 0.44}} & \textbf{90.77 ± 0.60}  & \textbf{77.53 ± 0.32} & \textbf{83.63 ± 0.63} \\ \hline
Generative Baseline                                 & \multirow{4}{*}{BERT-large (340M)}                & 67.08 ± 0.49          & 65.73 ± 0.78          & \multicolumn{1}{c|}{66.40 ± 0.47}          & 67.17 ± 0.40           & 64.56 ± 0.58          & 65.84 ± 0.25          \\
Pipelinge Baseline                                  &                                                   & 70.58 ± 0.78          & 66.58 ± 0.66          & \multicolumn{1}{c|}{68.52 ± 0.32}          & 69.21 ± 0.55           & 64.27 ± 0.24          & 66.65 ± 0.28          \\
CubeRE                                              &                                                   & 68.75 ± 0.82          & 68.88  ± 1.03         & \multicolumn{1}{c|}{68.81 ± 0.46}          & 66.39 ± 0.96           & 67.12 ± 0.69          & 66.75 ± 0.28          \\
Text2NKG (ours)                                     &                                                   & \textbf{91.90 ± 0.79} & \textbf{79.43 ± 0.42} & \multicolumn{1}{c|}{\textbf{85.21 ± 0.69}} & \textbf{91.06 ± 0.81}  & \textbf{77.64 ± 0.46} & \textbf{83.81 ± 0.54} \\
\bottomrule
\end{tabular}
}
\caption{\label{t4}
Comparison of Text2NKG with other baselines in the hyper-relational extraction on HyperRED. Results of the supervised baseline models are mainly taken from the original paper~\citep{HyperRED}. The best results in each metric are in \textbf{bold}. 
}
\end{table*}

\begin{table*}[t]
\centering
\scriptsize
\setlength{\tabcolsep}{0.8mm}{
\begin{tabular}{lcccccccccc}
\toprule
\multicolumn{1}{c}{\multirow{2}{*}{\textbf{Model}}} & \multirow{2}{*}{\textbf{PLM}}    & \multicolumn{3}{c}{\textbf{HyperRED : Event-based}}                                 & \multicolumn{3}{c}{\textbf{HyperRED : Role-based}}                                  & \multicolumn{3}{c}{\textbf{HyperRED : Hypergraph-based}}       \\ \cline{3-11} 
\multicolumn{1}{c}{}                                &                                  & Precision             & Recall                & \multicolumn{1}{c|}{$F_1$}                 & Precision             & Recall                & \multicolumn{1}{c|}{$F_1$}                 & Precision             & Recall                & $F_1$                 \\ \hline
\multicolumn{11}{c}{\textbf{Unsupervised Method}}                                                                                                                                                                                                                                                                                                        \\ \hline
ChatGPT                                             & gpt-3.5-turbo ($\approx$175B)            & 10.4678               & 11.1628               & \multicolumn{1}{c|}{10.8041}               & 11.4387               & 10.4203               & \multicolumn{1}{c|}{10.9058}               & 11.2998               & 11.7852               & 11.5373                \\
GPT-4                                               & gpt-4 ($\approx$1760B)                   & 13.3681               & 14.6701               & \multicolumn{1}{c|}{13.9888}               & 13.6397               & 12.5355               & \multicolumn{1}{c|}{13.0643}               & 13.0907               & 13.6701               & 13.3741               \\ \hline
\multicolumn{11}{c}{\textbf{Supervised Method}}                                                                                                                                                                                                                                                                                                          \\ \hline
Text2Event                                          & \multirow{3}{*}{T5-base (220M)}  & 73.94          & 70.56          & \multicolumn{1}{c|}{72.21}          & 72.73          & 68.45          & \multicolumn{1}{c|}{70.52}          & 73.68          & 70.37          & 71.98         \\
UIE                                                 &                                  & 76.51          & 73.02          & \multicolumn{1}{c|}{74.72}          & 72.17          & 69.84          & \multicolumn{1}{c|}{70.98}          & 72.03          & 68.74          & 70.34          \\
LasUIE                                              &                                  & 79.62          & 78.04          & \multicolumn{1}{c|}{78.82}          & 77.01          & 74.26          & \multicolumn{1}{c|}{75.61}          & 76.21          & 73.75          & 74.96          \\
Text2NKG (ours)                                     & BERT-base (110M)                 & \textbf{86.20} & \textbf{79.25} & \multicolumn{1}{c|}{\textbf{82.58}} & \textbf{86.72} & \textbf{78.94} & \multicolumn{1}{c|}{\textbf{82.64}} & \textbf{83.53} & \textbf{86.59} & \textbf{85.03} \\ \hline
Text2Event                                          & \multirow{3}{*}{T5-large (770M)} & 75.58          & 72.39          & \multicolumn{1}{c|}{73.97}          & 73.21          & 70.85          & \multicolumn{1}{c|}{72.01}          & 75.28          & 72.73          & 73.98           \\
UIE                                                 &                                  & 79.38          & 74.69          & \multicolumn{1}{c|}{76.96}          & 74.47          & 71.84          & \multicolumn{1}{c|}{73.14}          & 74.57          & 71.93          & 73.22          \\
LasUIE                                              &                                  & 81.29          & 79.54          & \multicolumn{1}{c|}{80.40}          & 79.37          & 76.63          & \multicolumn{1}{c|}{77.97}          & 77.49          & 74.96          & 76.20          \\
Text2NKG (ours)                                     & BERT-large (340M)                & \textbf{88.47} & \textbf{80.30} & \multicolumn{1}{c|}{\textbf{84.19}} & \textbf{86.87} & \textbf{80.86} & \multicolumn{1}{c|}{\textbf{83.76}} & \textbf{85.06} & \textbf{86.72} & \textbf{85.89} \\ \bottomrule
\end{tabular}
}
\caption{\label{t3}
Comparison of Text2NKG with other baselines for n-ary relation extraction in event-based, role-based, and hypergraph-based schemas on HyperRED. The best results in each metric are in \textbf{bold}. 
}
\end{table*}


\begin{figure*}[h!t]
    \centering
    \subfigure[\label{a}]{
        \includegraphics[width=0.23\textwidth, height=0.2\textwidth]{a.pdf}
    }
    \subfigure[\label{b}]{
        \includegraphics[width=0.23\textwidth, height=0.2\textwidth]{b.pdf}
    }
\subfigure[\label{c}]{
        \includegraphics[width=0.23\textwidth, height=0.2\textwidth]{c.pdf}
    }
    \subfigure[\label{d}]{
        \includegraphics[width=0.23\textwidth, height=0.2\textwidth]{d.pdf}
    }
	\caption{(a) Precision, Recall, and $F_1$ changes in the dev set during the training of Text2NKG. (b) The changes of the number of true facts, the number of predicted facts, and the number of predicted accurate facts during the training of Text2NKG. (c) Precision, Recall, and $F_1$ results on different null-label hyperparameter ($\alpha$) settings. (d) The changes of the number of extracted n-ary
  relation extraction in different arity.}
	\label{f3}
\end{figure*}



\subsection{Main Results (RQ1)}

The experimental results of proposed Text2NKG and other baselines with both BERT-base and BERT-large encoders can be found in Table~\ref{t4} for the fine-grained n-ary relation extraction in hyper-relational schema. We can observe that Text2NKG shows a huge improvement over the existing optimal model CubeRE on both the dev and test datasets of HyperRED. The $F_1$ score is improved by 19.66 percentage points in the dev set and 18.60 percentage points in the test set with the same BERT-base encoder, and 16.40 percentage points in the dev set and 17.06 percentage points in the test set with the same BERT-large encoder, reflecting Text2NKG's excellent performance. Figure~\ref{a} and \ref{b} intuitively show the changes of evaluation metrics and answers of facts in the dev set during the training of Text2NKG. It is worth noting that Text2NKG exceeds 90\% in precision accuracy, which proves that the model can obtain very accurate n-ary relational facts and provides a good guarantee for the quality of fine-grained NKG construction.

\subsection{Results on Various NKG Schemas (RQ2)}

As shown in Table~\ref{t3}, besides hyper-relational schema, Text2NKG also accomplishes the tasks of fine-grained n-ary relation extraction in three other different NKG schemas on HyperRED, which demonstrates good utility. In the added tasks of n-ary relation extraction for event-based, role-based, and hypergraph-based schemas, since no model has done similar experiments at present, we used event extraction or unified extraction methods such as Text2Event~\citep{Text2Event}, UIE~\citep{UIE}, and LasUIE~\citep{LasUIE} for comparison. We found that Text2NKG still works best in these schemas, which demonstrates good versatility.


\subsection{Ablation Study (RQ3)}

Data augmentation (DA), null-label weight hyperparameter ($\alpha$), and hetero-ordered merging (HM) are the three main components of Text2NKG. For the different Text2NKG variants as shown in Table~\ref{t4}, it can be observed that DA, $\alpha$, and HM all contribute to the accurate results of our complete model. By comparing the differences, we find that HM is most effective by combining the probabilities of labels of different orders, followed by DA and $\alpha$.



\subsection{Analysis of Null-label Weight Hyperparameters (RQ4)}

We compared the effect for different null-label weight hyperparameters ($\alpha$). As shown in Figure~\ref{c}, the larger the $\alpha$, the greater the learning weight of null-label compared with other lables, the more relations are predicted as null-label. After filtering out the facts having null-label, fewer facts are extracted, so the precision is generally higher, and the recall is generally lower. The smaller the $\alpha$, the more relations are predicted as non-null labels, thus extracting more n-ary relation facts, so the recall is generally higher, and the precision is generally lower. Comparing the results of $F_1$ values for different $\alpha$, it is found that $\alpha=0.01$ works best. When applied in practice, the hyperparameter $\alpha$ can be adjusted according to specific needs to obtain the best results. 



\subsection{Analysis of N-ary Relation Extraction in Different Arity (RQ5)}

We use output merging to address the dynamic changes in the number of elements in n-ary relational facts. For instance, in the hyper-relational fact (\texttt{Einstein, educated\_at, University of Zurich, degree: Doctorate degree, major: Physics}), the Text2NKG algorithm allows us to extract two 3-ary atomic facts: (\texttt{Einstein, educated\_at, University of Zurich, degree: Doctorate degree}) and (\texttt{Einstein, educated\_at, University of Zurich, major: Physics}). These are then merged based on the same primary triple (\texttt{Einstein, educated\_at, University of Zurich}) to form a 4-ary fact. The same principle applies to facts of higher arities.

Figure~\ref{d} shows the number of n-ary relational facts extracted after output merging and the number of the answer facts in different arity during training of Text2NKG on the dev set. We find that, as the training proceeds, the final output of Text2NKG converges to the correct answer in terms of the number of complete n-ary relational facts in each arity, achieving implementation of n-ary relation extraction in indefinite arity unsupervised, with good scalability.


\subsection{Case Study (RQ6)}
\begin{figure}[t]
\centering
\includegraphics[width=8cm]{Case_study.drawio.pdf}
\caption{Case study of Text2NKG's n-ary relation extraction with four schemas on HyperRED.}
\label{case}
\end{figure}



Figure~\ref{case} shows a case study of n-ary relation extraction by a trained Text2NKG. For a natural language sentence, "\texttt{He was born in Skirpenbeck, near York and attended Pocklin.}", four structured n-ary relation extraction can be obtained by Text2NKG according to the requirements. Taking the hyper-relational schema for an example, Text2NKG can successfully extract one n-ary relational fact consisting of a main triple [\texttt{He, educated at, Pocklington}], and two auxiliary key-value pairs \{\texttt{start time:1936}\}, \{\texttt{end time:1943}\}. This intuitively validates the practical performance of Text2NKG on the fine-grained n-ary relation extraction to better contribute to the NKG construction. 

\subsection{Comparison with ChatGPT and GPT-4 (RQ7)}

As shown in Table~\ref{t4} and Table~\ref{t3}, we compared the extraction effects under four NKG schemas of the supervised Text2NKG with the unsupervised ChatGPT and GPT-4. We found that, these large language models cannot accurately distinguish the closely related relations in the fine-grained NKG relation repository, resulting in their F1 scores ranging around 10\%-15\%, which is much lower than the performance of Text2NKG. 
On the other hand, the limitation of Text2NKG is that its performance is confined within the realm of supervised training. Therefore, in future improvements and practical applications, we suggest combining small supervised models with large unsupervised models to better balance solving the cold-start and fine-grained accuracy problems in NKG construction. Appendix~\ref{chatgpt}.


\section{Conclusion}
In this paper, we propose Text2NKG, a novel fine-grained n-ary relation extraction framework for n-ary relational knowledge graph (NKG) construction. Experimental results show that Text2NKG outperforms other baselines on fine-grained n-ary relation extraction tasks, with nearly 20 percentage points improvement in $F_1$ scores. Moreover, Text2NKG supports n-ary relation extraction in four schemas: hyper-relational, event-based, role-based, and hypergraph-based. Meanwhile, we extend HyperRED dataset to a fine-grained n-ary relation extraction benchmark in four schemas.

\subsubsection*{Acknowledgments}
This work is supported by the National Science Foundation of China (Grant No. 62176026) and the Beijing Natural Science Foundation (M22009). This work is also supported by the BUPT Excellent Ph.D. Students Foundation and the BUPT Postgraduate Innovation \& Entrepreneurship Project led by Haoran Luo.












\bibliography{iclr2024_conference}
\bibliographystyle{iclr2024_conference}
\newpage
\appendix
\section*{Appendix} 

\section{Supplement to Data Augmentation}
\label{AppA}

In addition to the hyper-relational schema, the data augmentation strategies for other schemas are as follows:

For event-based schema, given an event-based fact ($r_1,r_2,A,r_3,B,r_4,C$), we consider keeping the main relation $r_1$ unchanged, and swapping other key-value pairs, \{$r_2,A$\}, \{$r_3,B$\}, and \{$r_4,C$\}, positionally, also as labeled training span-tuple cases. Thus $R_{ev}(A,B,C)=(r_1,r_2,r_3,r_4)$ can be augmented with 6 orders of span-tuples:
\begin{equation}
\left\{
\begin{aligned}
&R_{ev}(A,B,C)=(r_1,r_2,r_3,r_4),\\
&R_{ev}(B,A,C)=(r_1,r_3,r_2,r_4),\\
&R_{ev}(A,C,B)=(r_1,r_2,r_4,r_3),\\
&R_{ev}(B,C,A)=(r_1,r_3,r_4,r_2),\\
&R_{ev}(C,A,B)=(r_1,r_4,r_2,r_3),\\
&R_{ev}(C,B,A)=(r_1,r_4,r_3,r_2).\\
\end{aligned}
\right.
\end{equation}

For role-based schema, given a role-based fact ($r_1,A,r_2,B,r_3,C$), we consider swapping key-value pairs, \{$r_1,A$\}, \{$r_2,B$\}, and \{$r_3,C$\}, positionally, also as labeled training span-tuple cases. Thus $R_{ro}(A,B,C)=(r_1,r_2,r_3)$ can be augmented with 6 orders of span-tuples:
\begin{equation}
\left\{
\begin{aligned}
&R_{ro}(A,B,C)=(r_1,r_2,r_3),\\
&R_{ro}(B,A,C)=(r_2,r_1,r_3),\\
&R_{ro}(A,C,B)=(r_1,r_3,r_2),\\
&R_{ro}(B,C,A)=(r_2,r_3,r_1),\\
&R_{ro}(C,A,B)=(r_3,r_1,r_2),\\
&R_{ro}(C,B,A)=(r_3,r_2,r_1).\\
\end{aligned}
\right.
\end{equation}

For hypergraph-based schema, given a hypergraph-based fact ($r_1,A,B,C$), we consider keeping the main relation $r_1$ unchanged, and swapping entities, $A$, $B$, and $C$, positionally, also as labeled training span-tuple cases. Thus $R_{hg}(A,B,C)=(r_1)$ can be augmented with 6 orders of span-tuples:
\begin{equation}
\left\{
\begin{aligned}
&R_{hg}(A,B,C)=(r_1),\\
&R_{hg}(B,A,C)=(r_1),\\
&R_{hg}(A,C,B)=(r_1),\\
&R_{hg}(B,C,A)=(r_1),\\
&R_{hg}(C,A,B)=(r_1),\\
&R_{hg}(C,B,A)=(r_1).\\
\end{aligned}
\right.
\end{equation}


\section{Supplement to Hetero-ordered Merging}
\label{AppB}

In addition to the hyper-relational schema, the hetero-ordered merging strategies for other schemas are as follows:

For event-based schema ($n_r=4$), we combine the predicted probabilities of four labels $\mathbf{P}_{1},\mathbf{P}_{2},\mathbf{P}_{3},\mathbf{P}_{4}$ in 6 orders to ($A,B,C$) order as follows:
\begin{equation}
\left\{
\begin{aligned}
\mathbf{P}_{1}=&\ \mathbf{P}_1^{(ABC)}+\mathbf{P}_1^{(BAC)}+\mathbf{P}_1^{(ACB)}\\
&+\mathbf{P}_1^{(BCA)}+\mathbf{P}_1^{(CAB)}+\mathbf{P}_1^{(CBA)},\\
\mathbf{P}_{2}=&\ \mathbf{P}_2^{(ABC)}+\mathbf{P}_3^{(BAC)}+\mathbf{P}_2^{(ACB)}\\
&+\mathbf{P}_4^{(BCA)}+\mathbf{P}_3^{(CAB)}+\mathbf{P}_4^{(CBA)},\\
\mathbf{P}_{3}=&\ \mathbf{P}_3^{(ABC)}+\mathbf{P}_2^{(BAC)}+\mathbf{P}_4^{(ACB)}\\
&+\mathbf{P}_2^{(BCA)}+\mathbf{P}_4^{(CAB)}+\mathbf{P}_3^{(CBA)},\\
\mathbf{P}_{4}=&\ \mathbf{P}_4^{(ABC)}+\mathbf{P}_4^{(BAC)}+\mathbf{P}_3^{(ACB)}\\
&+\mathbf{P}_3^{(BCA)}+\mathbf{P}_2^{(CAB)}+\mathbf{P}_2^{(CBA)}.\\
\end{aligned}
\right.
\end{equation}
Then, we take the maximum probability to obtain labels $r_1,r_2,r_3,r_4$, forming a 3-ary relational fact ($r_1,r_2,A,r_3,B,r_4,C$) and filter it out if there are null-labels in ($r_1,r_2,r_3,r_4$).

For role-based schema ($n_r=3$), we combine the predicted probabilities of three labels $\mathbf{P}_{1},\mathbf{P}_{2},\mathbf{P}_{3}$ in 6 orders to ($A,B,C$) order as follows:
\begin{equation}
\left\{
\begin{aligned}
\mathbf{P}_{1}=&\ \mathbf{P}_1^{(ABC)}+\mathbf{P}_2^{(BAC)}+\mathbf{P}_1^{(ACB)}\\
&+\mathbf{P}_3^{(BCA)}+\mathbf{P}_2^{(CAB)}+\mathbf{P}_3^{(CBA)},\\
\mathbf{P}_{2}=&\ \mathbf{P}_2^{(ABC)}+\mathbf{P}_1^{(BAC)}+\mathbf{P}_3^{(ACB)}\\
&+\mathbf{P}_1^{(BCA)}+\mathbf{P}_3^{(CAB)}+\mathbf{P}_2^{(CBA)},\\
\mathbf{P}_{3}=&\ \mathbf{P}_3^{(ABC)}+\mathbf{P}_3^{(BAC)}+\mathbf{P}_2^{(ACB)}\\
&+\mathbf{P}_2^{(BCA)}+\mathbf{P}_1^{(CAB)}+\mathbf{P}_1^{(CBA)}.\\
\end{aligned}
\right.
\end{equation}
Then, we take the maximum probability to obtain labels $r_1,r_2,r_3$, forming a 3-ary relational fact ($r_1,A,r_2,B,r_3,C$) and filter it out if there are null-labels in ($r_1,r_2,r_3$).

For hypergraph-based schema ($n_r=1$), we combine the predicted probabilities of one label $\mathbf{P}_{1}$ in 6 orders to ($A,B,C$) order as follows:
\begin{equation}
\left\{
\begin{aligned}
\mathbf{P}_{1}=&\ \mathbf{P}_1^{(ABC)}+\mathbf{P}_1^{(BAC)}+\mathbf{P}_1^{(ACB)}\\
&+\mathbf{P}_1^{(BCA)}+\mathbf{P}_1^{(CAB)}+\mathbf{P}_1^{(CBA)}.\\
\end{aligned}
\right.
\end{equation}
Then, we take the maximum probability to obtain labels $r_1$, forming a 3-ary relational fact ($r_1,A,B,C$) and filter it out if $r_1$ is null-label.


\section{Construction of Dataset}
\label{datasetc}
Based on the original hyper-relational schema on HyperRED dataset~\citep{HyperRED}, we construct other three schemas (event-based, role-based, and hypergraph-based) for fine-grained n-ary relation extraction. Firstly, we view the main relation in the hyper-relational schema as the event type in the event-based schema, combine the head entity and tail entity with two extra head key and tail key to convert them into two key-value pairs, and remain the auxiliary key-value pairs in the hyper-relational schema. Taking ‘\texttt{Einstein received his Doctorate degree in Physics from the University of Zurich.}' as an example, it can be represented as (\texttt{Einstein, educated, University of Zurich,} \{\texttt{academic\_major, Physics}\}, \{\texttt{academic\_ degree, Doctorate}\}) in the hyper-relational schema and (\texttt{education}, \{\texttt{trigger, received}\}, \{\texttt{person, Einstein}\}, \{\texttt{college, University\ of\ Zurich}\}, \{\texttt{academic\_major, Physics}\},\{\texttt{academic\_degree, Doctorate}\}) in the event-based schema. Secondly, we remove the event type in the event-based schema to obtain the role-based schema. Thirdly, we remove all the keys in key-value pairs and remain the relation to build the hypergraph-based schema.

\section{Baseline Settings}
\label{baseline}

Firstly, for the original hyper-relational schema of HyperRED, we adopted the same baselines as in the CubeRE paper~\citep{HyperRED} to compare with Text2NKG:

\textbf{Generative Baseline: }
Generative Baseline uses BART~\citep{BART}, a sequence-to-sequence model, to transform input sentences into a structured text sequence.


\textbf{Pipeline Baseline: }
Pipeline Baseline uses UniRE~\citep{UniRE} to extract relation triplets in the first stage and a span extraction model based on BERT-Tagger~\citep{Bert} to extract value entities and corresponding qualifier labels in the second stage.

\textbf{CubeRE: }
CubeRE~\citep{HyperRED} is the only hyper-relational extraction model that uses a cube-filling model inspired by table-filling approaches and explicitly considers the interaction between relation triplets and qualifiers.

Secondly, for the event-based schema, role-based schema, and hypergraph-based schema, we added the following baselines to further validate the effect of Text2NKG on the fine-grained N-ary relation fact extraction task in the HyperRED dataset:

\textbf{Text2Event: }
Text2Event~\citep{HyperRED} is a classic model in the Event extraction domain. However, it is not applicable to extractions of the hyper-relational schema. For the role-based schema extraction, we retained the key without referring to the main relation, while for the hypergraph-based schema extraction, we retained the main relation without referring to the key to get the final result for comparison.

\textbf{UIE / LasUIE: }
UIE~\citep{UIE} and LasUIE~\citep{LasUIE} are unified information extraction models that can handle most tasks like NER, RE, EE, etc. However, they are still only suitable for event extraction in the multi-relational extraction domain and are not applicable to extractions of the hyper-relational schema. Therefore, we adopted the same approach as with Text2Event to compare with Text2NKG.

Thirdly, under the impact of the wave of large-scale language models brought about by ChatGPT on traditional natural language processing tasks, we added unsupervised large models as baselines to compare with Text2NKG in the n-ary relation extraction tasks of the four schemas.

\textbf{ChatGPT / GPT4: }
Using different prompts, we tested the latest state-of-the-art large-scale pre-trained language models ChatGPT~\citep{ChatGPT} and GPT-4~\citep{GPT-4} in an unsupervised manner, evaluating their performance on the extraction of the four schemas.


\section{Hyperparameter Settings}
\label{hyper}

We use the grid search method to select the optimal hyperparameter settings for both Text2NKG with Bert-base and Bert-large. We use the same hyperparameter settings in Text2NKG with different encoders. The hyperparameters that we can adjust and the possible values of the hyperparameters are first determined according to the structure of our model in Table~\ref{t6}. Afterward, the optimal hyperparameters are shown in \textbf{bold}.

\begin{table}[h]
\centering
\setlength{\tabcolsep}{5.8mm}{
\begin{tabular}{rr}
\toprule
\multicolumn{1}{c}{\textbf{Hyperparameter}} & \multicolumn{1}{c}{\textbf{HyperRED}}\\
\midrule
\multicolumn{1}{c}{$\alpha$} & \multicolumn{1}{c}{$\left\{1.0, 0.1, \textbf{0.01}, 0.001\right\}$}\\
\multicolumn{1}{c}{Train\underline{\space}batch\underline{\space}size} & \multicolumn{1}{c}{$\left\{2, 4, \textbf{8}, 16\right\}$}\\
\multicolumn{1}{c}{Eval\underline{\space}batch\underline{\space}size} & \multicolumn{1}{c}{$\left\{\textbf{1}\right\}$}\\
\multicolumn{1}{c}{Learning rate} & \multicolumn{1}{c}{$\left\{1e-5, \textbf{2e-5}, 5e-5\right\}$}\\
\multicolumn{1}{c}{Max\underline{\space}sequence\underline{\space}length} & \multicolumn{1}{c}{$\left\{128, \textbf{256}, 512, 1024\right\}$}\\
\multicolumn{1}{c}{Weight decay} & \multicolumn{1}{c}{$\left\{\textbf{0.0}, 0.1, 0.2, 0.3\right\}$}\\
\bottomrule   
\end{tabular}}

\caption{\label{t6}
Hyperparameter Selection.
}

\end{table}



\section{Model Training Details}
\label{train}
We train 10 epochs on HyperRED with the optimal combination of hyperparameters. Text2NKG and all its variants have been trained on a single NVIDIA A100 GPU. Using our optimal hyperparameter settings, the time required to complete the training on HyperRED is 4h with BERT-base encoder and 10h with BERT-large encoder.


\section{Discussion of Advanced LLMs such as ChatGPT in Fine-Grained N-ary Relation Extraction Tasks}
\label{chatgpt}




We have tried to use LLM APIs such as ChatGPT and GPT to do similar n-ary relation extraction tasks, i.e., prompting model input and output formats for extraction. The advantage of ChatGPT is that it can perform similar tasks in a few-shot situation, however, for building high-quality knowledge graphs, the performance and the fineness of the n-ary relation extraction are much lower than Text2NKG. This is because ChatGPT is not good at multi-label classification tasks that contain less semantic interpretation. When the number of labels of relations in our relation collection is very large, we need to write a very long prompt to tell the LLM about our label candidate collection, which again leads to the problem of forgetting. Therefore, we have tried numerous prompt templates to enhance the extraction effect of ChatGPT, however, on fine-grained n-ary relation extraction task, the best result of ChatGPT can only reach about 10\% of $F_1$ value on HyperRED, which is much lower than the result of 80\%+ $F_1$ value of Text2NKG. 

However, advanced LLMs such as ChatGPT are a good idea for training dataset generation for Text2NKG in such tasks to save some manual labor to only verify and correct the training items generated. For future work, we will continue our research in this direction and try to combine large language models with Text2NKG-like supervised models for automated fine-grained n-ary relation extraction for n-ary relational knowledge graph construction.

\end{document}
