The framework of the proposed GGHL is shown in Fig. 3, which is mainly composed of three parts: the proposed label assignment strategy OLA, the CNN model with developed ORC, and the designed objective function JOL. First, each label is assigned one-to-many to the Gaussian candidate locations in the feature maps through the proposed OLA strategy. Second, a CNN model is constructed to extract features from the input images. Then, the proposed ORC encodes these features to predict the OBB and category at each positive location. Furthermore, the Gaussian prior weight of each positive candidate location is adjusted by the designed CNN-learnable OWAM to fit the object’s shape adaptively. Third, the joint-optimization loss between the ground truth of the constructed training sample space and the prediction of the CNN model is calculated. Finally, the CNN model is trained until the loss converges to obtain the optimal parameters.
\begin{figure}[tbp]
	\vspace{-0.5em}
	\centering
	\epsfig{width=0.45\textwidth,file=3.pdf}
	\vspace{-1em}
	\caption{The GGHL framework comprises (a) the proposed OAL strategy, (b) the CNN model with developed ORC and OWAM, (c) the designed objective function JOL.}\label{fig:3}
	\vspace{-0.5em}
\end{figure} 

\vspace{-0.5em}
\subsection{OLA Strategy}

In the previous works, although anchor-based methods, e.g., CenterMap \cite{wang2020learning}, introduced "Gaussian-like" or "Centerness-like" \cite{tian2019fcos} weighting mechanisms for positive candidates, they are still essentially based on maximum IoU matching to define P\&N samples. As mentioned before, such matching strategies suffer from mismatch risks especially in dense object scenarios and they rely on a large number of hyperparameters. Methods like GWD \cite{yang2021rethinking} mainly employ 2-D Gaussians for loss calculation, and its label assignment is still based on anchor boxes. CenterNet \cite{zhou2019objects}, BBAvectors \cite{yi2020oriented}, DRN \cite{pan2020dynamic}, etc., also use the 2-D Gaussian distribution to define positive candidate locations, as shown in Fig.~\ref{fig:4} (b). However, their Gaussian heatmap of each object is a circle (the standard Gaussian distribution), which may not well reflect the shape and direction of an object. Besides, they only take Gaussian peak points as positive locations, which need to detect objects on higher resolution feature maps (stride=4) with higher computational complexity and more unbalanced P\&N locations. In contrast, the proposed OLA uses an oriented elliptical Gaussian region to represent an object's positive candidate set intuitively. Furthermore, the objects are assigned to lower-resolution feature maps with different scales (stride=8, 16, 32) according to their sizes, as shown in Fig.~\ref{fig:4} (d) (e) (f), which has lower computational complexity and is compatible with the mainstream Backbone-FPN \cite{linFeaturePyramidNetworks2017a,redmonYOLOv3IncrementalImprovement2018} pipeline in OD tasks. 

Different from the existing methods, the proposed OLA strategy directly uses the 2-D Gaussian for label assignment to make the assigned candidates more in line with objects’ shapes and directions, and alleviates the mismatch problem of anchor-based methods in dense instance scenarios. More specifically, the proposed OLA more fully discusses the relationship between 2-D Gaussian and geometric transformations in oriented object label assignment from a theoretical perspective. Based on this, the technical details to be considered for 2-D Gaussian label assignment are explained, including multi-scale assignment, overlap problem in the assignment, discussion of Gaussian radius, etc.

\textbf{1) First, a general 2D Gaussian distribution is used to represent the positive candidate area with rotation and scaling}, and the locations of the entire Gaussian region are regarded as positive locations and given different weights according to the Gaussian density function, compared to just taking the point at Gaussian peak as the positive locations.

\begin{figure}[tbp]
	\vspace{-1em}
	\centering
	\epsfig{width=0.48\textwidth,file=4.pdf}
	\vspace{-1em}
	\caption{The principle of the proposed object-adaptation label assignment (OLA) strategy. (a) The original image. (b) The higher-resolution heatmaps (down-sampling stride=4) generated by the Gaussian key-points strategy of CenterNet \cite{zhou2019objects}, BBAVectors \cite{yi2020oriented}, DRN \cite{pan2020dynamic}, etc. (c) The principle of generating 2-D Gaussian heatmaps. (d) (e) (f) represent the multiscale (down-sampling stride=8, 16, 32) Gaussian positive candidates generated by the proposed OLA strategy. The color bars represent Gaussian probability.}
	\label{fig:4}
	\vspace{-1em}
\end{figure}
Specifically, the Gaussian probability density function (PDF) is represented as

where   contains two random variables in the two dimensions.  represents the mean vector, and the non-negative semi-definite real matrix  represents the covariance matrix of the two variables. The real symmetric matrix  is orthogonally diagonalized and decomposed into

Thus,

where  is a real orthogonal matrix, and  is a diagonal matrix composed of the eigenvalues of descending order. The Gaussian probability density function is transformed into


From the perspective of geometric transformation, the mean vector  controls the spatial translation. The real orthogonal matrix  is a rotation in this case:

where  denotes the angle of rotation. Because  and  are the same in this case, . The diagonal matrix  composed of eigenvalues represents the scaling, that is

where the eigenvalues  and  represent the square of the semi-major axis  and the square of the semi-minor axis  of the ellipse, respectively. Finally, the distribution becomes the standard Gaussian distribution of  mean vector and  covariance matrix, where  is the 2×2 identity matrix. 

\begin{algorithm}[!t]
	\label{alg:1}
	\small \caption{Generate the Gaussian Candidate Region}\LinesNumbered \KwIn{Labels, each of which contains four vertices (, , , ) of the OBB:  represent an OBB); number of labels }\KwOut{General Gaussian heatmap }\For{1 to }{
		Pre-process the label to get , ,  \;
		Calculate the threshold  at the end 
		point  of the semi-axis according to  and Eq.~\ref{eq:4}, which is explained in Section III-A-2) \;
		\For{ to }{
			\For{ to }{
				Calculate  according to Eq.~\ref{eq:4} \;
				\If{}{
					\;
				}
				\If{}{
					
					Assign other parameters of the label (see Section III-B)\;
				}
			}	
		}
		Normalize  in each Gaussian region.
	}
\end{algorithm}

In summary, as shown in Fig.~\ref{fig:4} (c), probability density of any 2-D Gaussian distribution  is obtained by a linear transformation from a standard 2-D Gaussian distribution (two random variables are independent Gaussian random variables with normal distribution). According to Eq.~\ref{eq:4}, a P\&N location distribution map  is generated through Algorithm~\ref{alg:1}. Define the element at  of  as ; and define  as the Gaussian value at  calculated by Eq.~\ref{eq:4}, which is normalized in each generated Gaussian region respectively. If , this location is defined as negative (background), . If , this location is defined as positive (foreground), , and the value of  represents the weight of this location in the Gaussian region it belongs to. 

\textbf{2) Second, the problem of possible overlap of Gaussian regions needs to be considered in the assignment process.} Unlike FCOS \cite{tian2019fcos} or CenterMap \cite{wang2020learning}, which assign overlapping region labels to instances with smaller areas, the proposed OLA allows more flexibility to assign labels for each candidate location. Specifically, if a location is contained in different Gaussian regions, it is assigned to the region that has the largest . This location is selected as the candidate to predict the object belongs to this Gaussian region. Moreover, the calculation of weights using Gaussian PDFs does not suffer from interpolation approximation problems encountered during the rotation of "Centerness" maps \cite{wang2020learning}. After determining the positive candidate locations, other parameters in the labels also need to be assigned to them, see Section III-B for details. 

\textbf{3) Third, the spatial and scale extents of the candidate regions using the above strategy need to be carefully studied.} First, a bounding box centered at the Gaussian peak location (called C-BBox) is computed based on the assigned labels. Then, it is assumed that many bounding boxes of different sizes centered at the other Gaussian candidate locations are generated. At a location, if there exists a bounding box whose Intersection over Union (IoU) with the C-BBox is greater than the threshold , this location is selected as a positive location. As shown in Fig.~\ref{fig:5}, these positive locations form a subset of the original Gaussian candidate locations (appearing as a smaller ellipse that is co-centered with the original Gaussian ellipse), and its semi-axis length is

where , represents the semi-axis lengths of the original Gaussian ellipse. Then, the Gaussian boundary threshold in Algorithm~\ref{alg:1} is calculated from . The purpose of the above reasoning is to explain the relationship between the Gaussian range and the IoU metric, and in practice it is not necessary to calculate the IoU during label assignment. Considering the versatility of multiple criteria,  is set to 0.3, which is the same as many classic methods, like Faster R-CNN \cite{renFasterRCNNRealTime2017a} and YOLO \cite{redmonYOLOv3IncrementalImprovement2018}. 

\begin{figure}[tbp]
	\vspace{-1.2em}
	\centering
	\epsfig{width=0.45\textwidth,file=5.pdf}
	\vspace{-1em}
	\caption{The radiuses of the candidate region. (a) The case that the predicted box is as large as the ground truth. (b) The case that the predicted box is larger than the ground truth. (c) The case that the predicted box is smaller than the ground truth. (d) The radiuses of the candidate region.}
	\label{fig:5}
	\vspace{-1em}
\end{figure} 

In order to detect objects of different sizes on feature maps of different scales, objects’ OBBs with different sizes are assigned to feature maps with different down-sampling rates , as ground truth. The generated  from Algorithm~\ref{alg:1} of different scales are visualized in Fig.~\ref{fig:4} (d) (e) (f). To ensure that more than one positive candidate is generated on a certain scale after assignment, we set , that is,  for each . Define the lengths of the four sides of an OBB as , then  because when calculating the diagonal matrix  in Eq.~\ref{eq:6} to generate the Gaussian ellipse, half the values of the length and width of the OBB are used as  and . Thus, introduce a hand-crafted hyperparameter  to get two boundary values of the three assignment ranges, they are

When , , and , the object is assigned to feature maps with down sampling rates , , and , respectively.  represents the length or width of the image input to CNN. The hyperparameter  is the only hand-crafted hyperparameter in the proposed GGHL. In Section IV, the setting of  will be discussed later.

\vspace{-0.5em}
\subsection{ORC, OWAM, and CNN Model}
\textbf{1) Oriented-bounding-box representation component (ORC).} The proposed ORC is used to encode the ground truth labels and CNN’s predictions to represent objects in feature maps by their positive locations, OBBs, and categories. The existing OBB representation methods are divided into two main categories: angle-based and vertex-based. The angle-based methods, e.g., CenterMap \cite{wang2020learning}, only represent rotated rectangular bounding boxes, and the problem of periodicity and mutation in angle regression has been analyzed in GWD \cite{yang2021rethinking}. The vertex-based methods, such as Gliding Vertex \cite{xu2020gliding}, represent more other shapes of quadrilaterals, but do not account for the case where the vertices do not fall on the circumscribed HBB. Moreover, these OBB representations are based on anchor boxes, which are inflexible and depend on many anchor hyperparameters. The proposed ORC follows the simple principle of anchor-free 2-D Gaussian assignment, which directly represents the OBB using the horizontal and vertical components of the distances from each Gaussian candidate position to the four vertices of the OBB, as shown in Fig.~\ref{fig:6}. The proposed ORC is free from the dependence on the anchors in decoding the OBB and fits naturally with the proposed OLA. Moreover, the proposed ORC addresses the undiscussed case in Gliding Vertex \cite{xu2020gliding}, in which some vertices do not fall on the HBB.

The representation method of ORC is shown in Fig.~\ref{fig:6} and all the defined variables of ORC at the location  are summarized in Table~\ref{table:1}. To represent an object in the feature map, first, the positive locations to detect the object are assigned. In the proposed OLA, the locations in the general Gaussian region are defined as the positive locations, while the other locations are defined as the negative locations. Thus, matrices  are generated to represent the ground truth positive and negative locations, which are binary versions of the matrices . Let the component at location  of  be . (For convenience, the subscripts  are used in the following to indicate the variables at the location .) If , , and  is a positive location. If , , and  is a negative location. In CNN, , are generated to represent the estimation of , whose component  at  is in the range of .
\begin{table}[tbp]
	\vspace{-1.5em}
	\centering
\renewcommand\arraystretch{1.5}
	\caption{{Summary of the definition of ORC variables at }}
	\vspace{-0.5em}
	\label{table:1}
	\setlength{\tabcolsep}{1.5mm}{	
		\resizebox{0.48\textwidth}{!}{
		\begin{tabular}{c|m{4cm}<{\centering}|m{1.5cm}<{\centering}|m{1.5cm}<{\centering}}
				\hline\hline
				Variable &  Definition & Dimension & Value of Each Component \\ \hline
				 & Ground truth representing that the location  is positive or negative & \multirow{2}{1.5cm}{\centering Scalar} & 1 or 0 \\
				\cline{1,2,4}
				 & Prediction score that 
				the location  is positive
				 & ~ &  \\
				\hline
				 & \multirow{2}{3cm}{\centering Vector of the distances from  to the HBB boundaries} & \multirow{2}{1.5cm}{\centering } & \multirow{2}{1.5cm}{\centering } \\
				\cline{1}
				 & ~ & ~ & ~ \\
				\hline
				  & \multirow{2}{4cm}{\centering Vector of the distances from the HBB vertices to the corresponding OBB vertices at } & \multirow{2}{1.5cm}{\centering } & \multirow{2}{1.5cm}{\centering } \\
				\cline{1}
				 & ~ & ~ & ~ \\
				\hline
				 & \multirow{2}{3cm}{\centering Area ratio of the HBB and OBB at } & \multirow{2}{1.5cm}{\centering Scalar} & \multirow{2}{1.5cm}{\centering } \\
				\cline{1}
				 & ~ & ~ & ~ \\
				\hline
				 & \multirow{2}{3cm}{\centering Vector representing the OBB at } & \multirow{2}{1.5cm}{\centering } & \multirow{2}{1.5cm}{\centering } \\
				\cline{1}
				 & ~ & ~ & ~ \\
				\hline
				 & Ground truth vector of classification at  & \multirow{2}{1.5cm}{\centering } & 1 or 0 \\
				\cline{1,2,4}
				 & Prediction vector 
				of classification at  & ~ &  \\
				\hline\hline
		\end{tabular}}}	
\end{table}
\begin{figure}[tp]
	\vspace{-1em}
	\centering
	\epsfig{width=0.35\textwidth,file=6.pdf}
	\vspace{-1em}
	\caption{The OBB representation of the proposed ORC.}
	\label{fig:6}
	\vspace{-1em}
\end{figure}

\begin{figure}[tp]
	\vspace{-1.5em}
	\centering
	\epsfig{width=0.48\textwidth,file=6_A.pdf}
	\vspace{-1em}
	\caption{Discussion of different cases of arbitrary convex quadrilateral represented by ORC. The colored letters , , , and  indicate the ordered convex quadrilateral vertices after ORC preprocessing.}
	\label{fig:6_A}
	\vspace{-1em}
\end{figure}

Second, when the positive locations are assigned, OBBs of different locations are represented for locating the objects more accurately. As shown in Fig.6, we use , and  to represent the OBB of an object at .  are the distances from the location  to the top, right, bottom, and left edges of the circumscribing horizontal bounding box (HBB) calculated from the ground truth coordinates. , are the distances from the vertices of the HBB to the corresponding vertices of the OBB. Note that  is normalized to the range of  by dividing by the corresponding side length of the HBB. Besides, as with Gliding Vertex \cite{xu2020gliding},  are generated to represent the area ratio of the HBB and OBB. Thus, the OBB of the object at  is represented by a -dimensional vector . Correspondingly, the CNN’s prediction of the OBB, , at  is represented as . 

Third, the object’s category is represented at each location. The ground truth classification at  is represented as a -dimensional one-hot vector , where  denotes the number of categories. Let the th component of  be , . If the object at location  belongs to the cth category, ; otherwise, . Correspondingly, the CNN’s prediction of  is represented as , the component  of which represents the probability that the object belongs to the th category. 

\textbf{2) Refined approximation of OBBs.} Furthermore, not all convex quadrilaterals are directly represented by the ideal ORC drawn as shown in Fig.~\ref{fig:6_A}. The cases that the vertices do not fall on the HBB and the implicit ordering of vertices in the ORC need to be discussed. These are not fully considered in vertex-based methods, such as Gliding Vertex \cite{xu2020gliding}. They cope with these cases by converting the quadrilateral to its minimal outer rectangle. But such large-scale one-size-fits-all approximate conversions introduce large errors. And vertex-based methods only represent rotated rectangles and not arbitrary convex quadrilaterals. In response, we generalize and discuss the problem more comprehensively by generalizing the ORC representation and vertex ordering of arbitrary convex quadrilaterals to 16 cases. For their interpretations, schematic diagrams are more intuitive and easier to understand than words, so a summary of these cases is illustrated in Fig.~\ref{fig:6_A}. According to this refined approximation (RA), it is only necessary to make different types of approximations with as small error as possible for few convex quadrilaterals to represent arbitrary convex quadrilaterals and to obtain implicitly ordered vertices. Based on the statistics of more than two million OBBs in the DOTA dataset \cite{xiaDOTALargeScaleDataset2018}, only 4.79\% of the OBBs need to be approximated. The error introduced by using the minimum outer rectangle approximation for all the “difficult” convex quadrilaterals (counted by pixel areas) is more than twice as large as the one in the proposed method. Due to the space limitation, a more detailed algorithm is available in our open-source codes (https://github.com/Shank2358/GGHL). 

After the above variables are obtained and represented, the CNN training process is to make the CNN’s predictions approach the ground truth values, i.e., minimizing the loss in Eq.~\ref{eq:19}, which will be described later.

\textbf{3) Object-adaptive weight adjustment mechanism (OWAM).} Generally, after generating an elliptical Gaussian candidate region and assigning labels to all the locations in this region, as shown in Fig.~\ref{fig:6}, the value of  is used to weight a location of the candidate region when calculating the location loss. However, some objects like harbors in the remote sensing datasets as shown in Fig.~\ref{fig:7} do not conform to the Gaussian center prior. Therefore, it is not appropriate to use Gaussian weight directly. This has not been considered by the existing Gaussian-center-prior methods, such as CenterNet \cite{zhou2019objects}, BBAVectors \cite{yi2020oriented}, DRN \cite{pan2020dynamic}, O-DNet \cite{wei2020oriented}, and loss functions like GWD \cite{yang2021rethinking}. In the field of horizontal object detection, AutoAssign \cite{zhu2020autoassign} and IQDet \cite{ma2021iqdet} employed the adaptive weight adjustment with success. OWAM borrows this idea and extends it to oriented object detection. Compared to the existing methods, benefitting from using general Gaussian PDFs defined in OLA as prior weights, the proposed OWAM represents translation, rotation, and scaling for the arbitrary-oriented object. This Gaussian prior is for each individual while not for each category designed in AutoAssign \cite{zhu2020autoassign}. Besides, as mentioned before, using general Gaussian instead of “Rotated-Centerness-like” mechanisms to learn "Objectness" avoids the possible interpolation approximation problem. Based on this prior, the weights are dynamically adjusted by the orientation correlation variables  and  designed in ORC during the CNN training. That is, OWAM combines the static prior in OLA with the dynamically learnable OBB representation in ORC to re-weight the assigned candidates.
\begin{figure}[bp]
	\vspace{-2em}
	\centering
	\epsfig{width=0.42\textwidth,file=7.pdf}
	\vspace{-1em}
	\caption{The object-adaptive weight adjustment mechanism (OWAM) based on Gaussian center prior (GCP) weight and OBB shape regression score.}
	\label{fig:7}
	\vspace{-0.5em}
\end{figure} 

In OWAM, the higher weights are assigned to the key positive locations of an object learned by CNN, while not always the center point of an object that is used by . As shown in Fig.~\ref{fig:7}, weight adjustment matrices  are introduced to adaptively adjust the weight of each Gaussian region of , according to object’s shape. Note that matrices  are calculated based on the proposed ORCs of CNN using the OBB regression loss described below, which reflects the OBB shape prediction scores at positive locations. The value of each component in  is in the range of . More specifically, based on the above OBB encoding process, the OBB regression loss at each positive location , is

The loss function in Eq.~\ref{eq:9} is obtained from maximizing the likelihood function of the parameters to estimate. It is explained in Appendix A-1).  function \cite{rezatofighiGeneralizedIntersectionUnion2019} is an improved IoU for training, the calculation of which is given in Appendix B.  is the th component of -dimensional vector , and  is the th component of -dimensional vector . Therefore, the output of  is a scalar greater than or equal to 0 at location . The smaller its value is, the more accurate the prediction of OBB is.

Thus,  is in the range of . Let the value of  at location  be

The larger its value is, the more accurate the prediction of OBB is. Then,  is adaptively adjusted according to the shape of the objects to be predicted by the CNN training. So, the weight of  is changed from  to 

where scalar  represents the object-adaptive weight at .  denotes the weighting factor.  means that the weights are completely dependent on the Gaussian prior, and . If  is a negative location, then ; otherwise, . Finally, -dimensional CNN-learnable weight matrices  composed of  are generated, where  and  represent the width and height of the feature map of scale   respectively.  weight different locations dynamically to fit different object shapes in different scales. Besides, in the above process, there is no need to change the label assignments designed in Section III-A. Compared with the scheme of using CNN to predict the weights directly, this scheme makes the adjustment converge faster and more stable based on , during the CNN training.  

\textbf{4) CNN model.} Many methods use large and complicated CNN models to pursue high accuracy, which may be too complex in practical applications. For computational simplicity, the CNN model of the proposed GGHL chooses a straightforward and practical structure for its versatility and ease of use, which can more precisely reflect the effectiveness of the proposed GGHL. The designed CNN model is mainly composed of three parts: backbone network, feature pyramid network (FPN) \cite{linFeaturePyramidNetworks2017a}, and detection head composed of ORCs, which are represented by red, blue and yellow in Fig. 4 (b), respectively. Considering that the object scale varies greatly in remote sensing scenes, spatial pyramid pooling (SPP) \cite{huang2020dc} is introduced in FPN to fuse multiscale features and expand the receptive field. In addition, the DropBlock \cite{ghiasi2018dropblock} is used to improve the generalization ability of CNN, which does not bring additional computational complexity. The detection head uses a very light two-layer convolution structure, unlike the heavy convolution layers of RetinaNet \cite{linFocalLossDense2017}.

\vspace{-0.5em}
\subsection{Joint-optimization Loss (JOL)}
First, the joint PDF of the P\&N location detection, OBB regression, and object classification at each location of feature maps is provided. Second, an area normalization and loss re-weighting mechanism is designed for adaptively adjusting the weight of loss at different locations. Finally, the maximum likelihood estimation (MLE) is used to obtain the total joint-optimization function. Besides, the CNN predictions in the inference stage are explained.

\textbf{1) The joint PDF of the positive or negative location detection, OBB regression, and object classification.} Use  to represent the ground truth of object detection at location . For the CNN model, let  be the CNN parameters used for object detection at the location . , , and  are the parameters used for the positive or negative location detection, OBB regression, and object classification, respectively. Similarly, let  be the input features of the prediction layers of CNN at , which are extracted by the hidden layers of CNN. 

Then, define the predictions of CNN as , which is generated by  and . Specifically, for the positive or negative location detection, define  as a deterministic function with Sigmoid activation related to CNN, then,

The estimation  is in the range of , which represents the classification score that the location  is positive. The larger the  is, the more likely  is to be a positive location.

For the OBB regression, define  as a deterministic regression function related to the CNN, which uses the linear activation function [1]. Note that in the CNN training stage, the ground truth of positive and negative location detection, i.e., , is given. The estimation of OBB is only carried out at the positive locations \cite{renFasterRCNNRealTime2017a}:

which is used in the joint PDF and loss function. While in the CNN inference stage,  is unknown, but  has been obtained after the training, which will be explained in detail in Sub-section 4).

For the object classification, the parameters , and the input features . Define  as a deterministic function with Sigmoid activation related to the CNN. Note that in the CNN training stage,  and  are given, and  is calculated after  is predicted by the CNN. In this stage, the estimation of classification is only carried out at the positive locations, i.e.  \cite{redmonYouOnlyLook2016a}. In the existing methods like \cite{redmonYOLOv3IncrementalImprovement2018,linFocalLossDense2017,tian2019fcos,yangSCRDetMoreRobust2019,xu2020gliding}, the classification score is usually learned independently by CNN. While in the proposed GGHL,  is multiplied to the classification score, which makes the classification score also affected by the OBB regression score. Thus, the estimation that object belongs to the th category is

where  is given in Eq.~\ref{eq:10}. The estimation  activated by Sigmoid function is in the range of . The larger the  is, the more likely the object at  is to belong to the th category. Therefore, the classification sub-task is affected by the OBB regression error. In the training process, in order to obtain a higher classification accuracy, the model parameters will be jointly adjusted to approach the optimal results of not only the classification sub-task but also the OBB regression task. Thus, when  and  are given, the joint PDF of the positive or negative location detection, OBB regression, and object classification is

which is derived in Appendix A. The PDF of the error of the OBB regression, which is assumed to obey an i.i.d. Gaussian distribution with a mean of 0 and variance . 

\textbf{2) Area normalization and loss adaptive re-weighting.} Because CNN prefers to learn the object with a larger Gaussian region generated by the proposed OLA, i.e., with more positive locations, an area normalization factor  at  that decreases with increasing Gaussian candidate areas is considered. The statistics of OLA assignment for many AOOD datasets, such as DOTA \cite{xiaDOTALargeScaleDataset2018}, show that the number of objects and the area of the assigned candidate region (number of pixels) exhibit a decreasing trend from fast to slow. Therefore, the reciprocal form of the logarithm is chosen to design variables  so that the variation trend approximates the distribution described above with a lower bound. According to Eq.~\ref{eq:8}, the theoretical maximum value of candidate area is , and the variation of this value is still large, so its square root is taken. To ensure that the denominator is not 0, 1 is added to the log of the denominator. To make the maximum value be 1, the numerator is log2. The designed area normalization variable is

where  denotes the area of positive region and is always no less than 1. The normalization weight is in the range of .

In JOL, to make the detection of positive and negative affected by the object’s shape,  designed in Eq.~\ref{eq:11} is used to adaptively weight the location loss according to the error of OBB regression, i.e., the error of object’s shape prediction. Besides, to impose classification effects on regression, the weight  is designed to weight the OBB regression loss after  is obtained in the total loss,

where the ground truth category is the th category. Similar to Eq.~\ref{eq:11},  is also in the range .  is used to make the non-object part of the weights equal to 1. Here,  and  do not perform the gradient backpropagation during training. In GGHL, taking  obtains equal contributions from the prior weights and adjusted values, which may not be optimal but is simplest.

\textbf{3) Total joint-optimization function.} After caonsidering  and , and introducing the Focal Loss \cite{linFocalLossDense2017}, from the LF of Eq.~\ref{eq:15} and using the MLE, the total loss of all the locations in feature maps is obatined, which is 

In the total loss, the loss of P\&N location detection is

where  represents the feature maps in scales .  is the hyperparameter of Focal Loss \cite{linFocalLossDense2017}, which is set to 2 as \cite{linFocalLossDense2017}. In JOL, the loss of P\&N location detection is separated from the classification loss so that the imbalance of P\&N samples will not affect the classification task. The OBB regression loss is

and the classification loss is

where the classification estimation  defined by Eq.~\ref{eq:14} is associated with the OBB regression result . This is different from the ordinary loss scheme in which independent regression loss and classification loss are added together.

\textbf{4) The CNN predictions in the inference stage.} Note that  and  in the CNN training stage and inference stage are different. In the CNN inference stage,  is unknown, after  is obtained. If  is larger than the threshold, which is given by the benchmarks of different datasets, the location is predicted as a positive location,


where   and  represent the optimal parameters obtained from the CNN training for OBB regression and object classification, respectively. If  is less than the threshold, the location is predicted as a negative location, and the OBB regression and object classification are not performed.
