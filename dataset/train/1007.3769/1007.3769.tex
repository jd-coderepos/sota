\documentclass{LMCS}

\mathcode`:="003A  \mathcode`;="003B  \mathcode`?="003F  \mathcode`|="026A  \mathcode`<="4268  \mathcode`>="5269  

\mathchardef\ls="213C    \mathchardef\gr="213E    \mathchardef\uparrow="0222  \mathchardef\downarrow="0223  \newcommand{\blue}[1]{\textcolor{blue}{#1}}


\newcommand{\lbb}{\mathopen{[\![}}
\newcommand{\rbb}{\mathclose{]\!]}}
\newcommand{\bb}[1]{\lbb #1 \rbb}
\newcommand\D{\mathcal{D}}
\newcommand\N{\mathcal{N}}
\newcommand\M{\mathcal{M}}
\newcommand\Pa{\mathcal{Q}}
\def\pow{{\mathcal P_{\!\!\!\omega}}}
\newcommand\pto\rightharpoonup
\newcommand\E\varepsilon
\newcommand\Exp{\mathsf{Exp}}
\newcommand\Plus{\mathsf{Plus}}
\newcommand\Empty{\mathsf{Empty}}
\newcommand\ndf{\mathit{NDF}}
\newcommand\id{\mathsf{Id}}
\newcommand\B{\mathsf{B}}
\newcommand\G{\mathcal{G}}
\newcommand\F{\mathcal{F}}
\newcommand\Pol{\mathbf{P}}
\newcommand\Fin{\mathbf{F}}
\newcommand\emp{\underline\emptyset}



\newcommand{\rules}[2]{\mbox{#1#2}}


\DeclareSymbolFont{lasy}{U}{lasy}{m}{n}
\DeclareMathSymbol\myDiamond{\mathord}{lasy}{"33}
\newcommand{\myplus}{\mathbin{\rlap{}\hspace*{.01cm}\raisebox{.14ex}{}}}
\newcommand{\mybigplus}{\scalebox{1.5}{}}

\def\expr#1{<\!< \, #1 \, >\!>}
\def\ceil#1{\lceil\, #1 \,\rceil}
\newcommand{\pp}[1]{\|#1\|}

\def\mean#1{[\![ \, #1 \, ]\!]}



\hyphenation{spe-ci-fi-ca-tion}
\hyphenation{pre-con-di-tion}
\hyphenation{in-ter-fe-rence}
\hyphenation{in-ter-fe-ring}
\hyphenation{non-in-ter-fe-rence}
\hyphenation{non-in-ter-fe-ring}
\hyphenation{non-de-ter-mi-nis-tic}

\hyphenation{ho-mo-mor-phism}
\hyphenation{de-ter-mi-nis-tic}

\def\hyph{-\penalty0\hskip0pt\relax} 
\usepackage{verbatim}
\usepackage{longtable}
\usepackage{amsmath}
\usepackage{enumerate,hyperref}

\theoremstyle{definition}
\newtheorem{mydefinition}{\textsc{Definition}}[section]
\theoremstyle{plain}
\newtheorem{mylemma}[mydefinition]{\textsc{Lemma}}
\theoremstyle{plain}
\newtheorem{mytheorem}[mydefinition]{\textsc{Theorem}}
\theoremstyle{plain}
\newtheorem{myproposition}[mydefinition]{\textsc{Proposition}}
\theoremstyle{plain}
\newtheorem{mycorollary}[mydefinition]{\textsc{Corollary}}
\theoremstyle{definition}
\newtheorem{myremark}[mydefinition]{\textsc{Remark}}
\theoremstyle{definition}
\newtheorem{myexample}[mydefinition]{\textsc{Example}}



\newenvironment{definition}{
\begin{mydefinition}}
    {\hfill\end{mydefinition}}

\newenvironment{example}{
\begin{myexample}}
    {\hfill\end{myexample}}

\newenvironment{lemma}{
\begin{mylemma}}
    {\end{mylemma}}

\newenvironment{theorem}{
\begin{mytheorem}}
    {\end{mytheorem}}
\newenvironment{proposition}{
\begin{myproposition}}
    {\vspace{1ex}\end{myproposition}}


\usepackage{backref}
\usepackage{memhfixc}

\usepackage{color}
\usepackage{graphics}
\usepackage{graphicx}
\marginparwidth=2.7cm
\newcommand{\todo}[1]{\marginpar{#1}}
\usepackage[all,2cell,cmtip,dvips,ps]{xy}

\usepackage{etex}
\usepackage{tikz}
\newcommand*\mycirc[1]{\begin{tikzpicture}[baseline=(C.base)]
    \node[draw,circle,inner sep=1pt](C) {#1};
  \end{tikzpicture}}



\def\doi{6 (3:23) 2010}
\lmcsheading {\doi}
{1--39}
{}
{}
{Jan.~\phantom03, 2010}
{Sep.~\phantom09, 2010}
{}

\begin{document}


\title{Non-deterministic Kleene coalgebras}
\author[A.~Silva]{Alexandra Silva\rsuper a}  
\address{{\lsuper a}CWI, Amsterdam, The Netherlands}  
\email{ams@cwi.nl} 
\thanks{{\lsuper a}The first author was partially supported by the
Funda\c{c}\~ao para a Ci\^encia e a Tecnologia, Portugal, under grant
number SFRH/BD/27482/2006.} 

\author[M.~Bonsangue]{Marcello Bonsangue\rsuper b}
\address{{\lsuper b}LIACS, University of Leiden,The Netherlands}
\email{marcello@liacs.nl}  

\author[J.~Rutten]{Jan Rutten\rsuper c}	
\address{{\lsuper c}CWI (Amsterdam), VUA (Amsterdam) and RUN (Nijmegen) , The Netherlands}	
\email{janr@cwi.nl}  

\keywords{Coalgebra, Kleene's theorem, axiomatization}
\subjclass{F3.1, F3.2, F4.1}

\begin{abstract}
In this paper, we present a systematic way of deriving (1) languages of (generalised) regular expressions, and
(2) sound and complete axiomatizations thereof,
for a wide variety of systems. 
This generalizes both the
results of Kleene (on regular languages and deterministic finite
automata)
and Milner (on regular behaviours and finite labelled transition
systems),
and includes many other systems such as Mealy and Moore machines.
\end{abstract}

\maketitle

\section{Introduction}
In a previous paper~\cite{BRS08}, we presented a language to describe the 
behaviour of Mealy machines and a sound and complete axiomatization
thereof. The defined language and axiomatization can be seen as the analogue of classical regular
expressions~\cite{kleene} and Kleene algebra~\cite{kozen}, for
deterministic finite automata (DFA), or the
process algebra and axiomatization for labelled transition
systems (LTS)~\cite{milner}.

We now extend the previous approach and devise a framework wherein
languages and axiomatizations can be uniformly derived for a large
class of systems, including DFA, LTS and Mealy machines, which we
will model as coalgebras.
 
Coalgebras provide a general framework for the study of dynamical
systems such as DFA, Mealy machines and LTS. For a functor
, a -coalgebra or -system is a pair ,
consisting of a set  of states and a function 
defining the ``transitions'' of the states. We call the functor 
the \emph{type} of the system. For instance, DFA can be modelled as
coalgebras of the functor , Mealy machines are obtained by taking  and 
image-finite LTS are coalgebras for the functor , where  is finite powerset.


Under mild conditions, functors  have a \emph{final coalgebra}
(unique up to isomorphism) into which every -coalgebra can be
mapped via a unique so-called \hyph\emph{homomorphism}. The final
coalgebra can be viewed as the universe of all possible
-\emph{behaviours}: the unique homomorphism into the final
coalgebra maps every state of a coalgebra to a canonical
representative of its behaviour. This provides a general notion of
behavioural equivalence: two states are equivalent if and only if they are
mapped to the same element of the final coalgebra. Instantiating the
notion of final coalgebra for the aforementioned examples, the result
is as expected: for DFA the final coalgebra is the set  of all languages over ; for Mealy
machines it is the set of causal functions ;
and for LTS it is the set of
finitely branching trees with arcs labelled by  modulo bisimilarity. The notion of
equivalence also specializes to the familiar notions: for DFA, two states are
equivalent when they accept the same language;
for Mealy machines, if they realize (or compute) the same causal function; and 
for LTS if they are bisimilar.

It is the main aim of this paper to show how the type of a system,
given by the functor , is not only enough to determine a notion of
behaviour and behavioural equivalence, but also allows for a uniform
derivation of both 
a set of expressions describing behaviour and a corresponding
axiomatization. The theory of universal coalgebra~\cite{Rutten00}
provides a standard equivalence and a universal domain of behaviours,
uniquely based on the functor . The main contributions of this
paper are (1) the definition of a set of expressions 
describing -behaviours, (2) the proof of the correspondence between
behaviours described by  and locally finite -coalgebras (this is the analogue of Kleene's theorem),  and (3) a corresponding sound and complete
axiomatization, with respect to bisimulation, of  (this is the analogue of
Kleene algebra). All these results are solely based on the type of
the system, given by the functor . 

In a nutshell, we combine the work of Kleene
with coalgebra, considering the class of non-deterministic functors.
Hence, the title of the paper: non-deterministic Kleene coalgebras.   

\paragraph{\textbf{Organization of the paper.}} In Section~\ref{sec:ndc} we
introduce the class of non\hyph deterministic functors and coalgebras. In
Section~\ref{sec:expressions} we associate with each non\hyph
deterministic functor  a generalized language  of regular
expressions and we present an analogue of Kleene's theorem, which
makes precise the connection between   and -coalgebras. A
sound and complete axiomatization  of  is presented in
Section~\ref{sec:axiom}. Section~\ref{sec:appl} contains two more
examples of application of the framework and Section~\ref{sec:pol_fin} shows a language
and axiomatization for the class of polynomial and finitary
coalgebras. Section~\ref{sec:conclusions5} presents
concluding remarks, directions for future work and discusses related work. 
This paper is an extended version of~\cite{regexp,BRS09b}: it includes
all the proofs, more examples and explanations, new material about polynomial and finitary functors and an extended discussion section.

\section{Preliminaries} \label{sec:ndc}
We give the basic definitions on non-deterministic functors and coalgebras
and introduce the notion of bisimulation.

\medskip\noindent
First we fix notation on sets and operations on them. Let
 be the category of sets and functions. Sets are
denoted by capital letters  and functions by lower case
. We write  for the empty set and the collection of
all {\em finite} subsets of a set  is defined as
Y. The collection of functions from a set  to a set
 is denoted by . We write  for the identity
function on set . Given functions  and
 we write their composition as . The product
of two sets  is written as , with projection
functions
The set  is a singleton set typically written as  and
it can be regarded as the empty product. We define  as the set
, where  is the disjoint
union of sets, with injections
. Note that the set  is different from the classical
coproduct of X and Y (which we shall denote by ), because of the two extra elements  and
.
These extra elements will later be used to represent, respectively,
underspecification and inconsistency in the specification of some
systems. The intuition behind the
need of these extra elements will become clear when we present our language
of expressions and concrete examples, in
Section~\ref{sec:examples_synt}, of systems whose type
involves . Note that . 

For each of the operations defined above on sets, there are analogous
ones on functions. Let ,  and . We
define the following operations:
.6ex]
(f_1\times f_2)(<x,z>) = <f_1(x),f_2(z)> &
(f_1\myplus f_2)(c) = c,\ c\in\{\bot,\top\}\\ &
(f_1\myplus f_2)(\kappa_i(x)) = \kappa_i(f_i(x)),\ i\in\{1,2\}\.6ex]

f^A (g) = f\circ g & \pow(f)(S) = \{f(x) \mid x\in S\}
\end{array}

b_1 \leq_\B b_2 \Leftrightarrow b_1\vee_\B b_2 = b_2

\ndf \ni \G ::= \id \mid \B \mid \G\myplus \G \mid \G\times
\G \mid \G^A \mid \pow \G

\begin{array}{lll}
\id(X) = X & \B(X) = \B & (\G_1\myplus \G_2) (X) = \G_1(X)\myplus \G_2(X) \\
\id(f) = f &  \B(f) = \mathit{id}_\B & (\G_1\myplus \G_2) (f) = \G_1(f)
\myplus \G_2 (f) \
Typical examples of non\hyph deterministic functors include ,
 ,  and , where  is a two-element join
semilattice with  as bottom element () and  is a
one element join-semilattice. These
functors represent, respectively, the type  of Mealy,
deterministic, partial deterministic and non\hyph deterministic
automata. 
In this paper, we will use the last three as running examples.
In~\cite{BRS08}, we have studied in detail regular
expressions for Mealy automata. Similarly to what happened there, we
impose a join\hyph semilattice structure on the constant functor. The
product, exponentiation and powerset functors preserve the
join\hyph semilattice structure and thus do not need to be changed.
 This is not the case for the classical coproduct and
thus we use  instead, which also guarantees that the join
semilattice structure is preserved. 

Next, we give the definition of  the ingredient relation, which
relates a non\hyph deterministic functor  with its {\em
ingredients}, {\em
i.e.} the functors used in its inductive construction. We shall use
this relation later for typing our expressions.

\begin{definition}

Let  be the least reflexive and
transitive relation on
non\hyph deterministic functors
such that

\end{definition}
Here and throughout this document we use  as a shorthand
for . If , then  is said to  be an
\emph{ingredient} of . For example, , ,  and 
itself are all the ingredients of the deterministic automata functor
.


\paragraph{\textbf{Non-deterministic coalgebras.}} A {non\hyph
deterministic} coalgebra is a pair , where
 is a set of states and  is a non\hyph deterministic functor. 
 The functor , together with the
function , determines the {\em transition structure} (or
dynamics) of the -coalgebra~\cite{Rutten00}. Mealy,
deterministic, partial deterministic and non\hyph deterministic
automata are, respectively, coalgebras for the functors
,
 ,  and .

A {\em -homomorphism\/} from a -coalgebra  to a
-coalgebra  is a function  preserving the
transition structure, {\em i.e.} such that . 

\begin{definition}
A -coalgebra  is said to be {\em final} if
for any -coalgebra  there exists a unique -homomorphism
 . 
\end{definition}
For every non-deterministic functor 
there exists a final -coalgebra ~\cite{Rutten00}. For instance, as we already mentioned in
the introduction, the final coalgebra for the functor  is the set
of languages  over , together with a transition function
 defined as . Here 
denotes the empty sequence and  denotes the word resulting from
prefixing  with the letter . The notion of finality will play
a key role later in providing a semantics to expressions.

Given a -coalgebra  and a subset  of~ with inclusion
map  we say that  is a subcoalgebra of  if there
exists  such that  is a homomorphism.
Given , , denotes the smallest subcoalgebra generated by
, with  given by

If the functor
 preserves arbitrary intersections, then the subcoalgebra 
exists. This will be the case for every functor considered in this
paper. Moreover, all the functors we will consider preserve
monos and thus the transition structure  is
unique~\cite[Proposition 6.1]{Rutten00}. 
 
We will write  for the category of -coalgebras together
with coalgebra homomorphisms. We also write
 for the category of
-coalgebras that are {\em locally finite}. Objects are
-coalgebras
 such that
for each state  the generated subcoalgebra  is finite.
Maps are the usual homomorphisms of coalgebras.

Let  and  be two -coalgebras. We call a relation
 a {\em bisimulation\/}~\cite{HermidaJ98}
iff 

where  is defined as
 . We write  whenever there exists a bisimulation relation
containing  and we call  the bisimilarity relation.
We shall drop the subscript  whenever the functor  is clear
from the context. For all non-deterministic -coalgebras  and  and , it holds that  (the left to right implication always holds, whereas
the right to left implication only holds for certain classes of
functors, which include the ones we consider in this
paper~\cite{Rutten00,staton}). 

\section{A language of expressions for non\hyph deterministic
coalgebras}\label{sec:expressions}

In this section, we generalize the classical notion of regular
expressions to non\hyph deterministic coalgebras. We start by introducing an
untyped language of expressions and then we single out the
well-typed ones via an appropriate typing system, thereby associating
expressions to non\hyph deterministic functors. 

\begin{definition}[Expressions]
Let  be a finite set,  a finite join\hyph semilattice and  a set
of fixed point variables. The set  of all {\em expressions\/} is given
by the following grammar, where ,  and :

where  is a {\em guarded expression} given by:

The only difference between the BNF of  and  is the
occurrence of .
\end{definition}
 In the expression ,  is a binder for
all the free occurrences of  in . Variables that are not bound are
free. A {\em closed expression} is an expression
without free occurrences of fixed point variables . We denote the set of closed
expressions by . 

Intuitively, expressions denote elements of the final coalgebra. The
expressions ,  and   will
play a similar role to, respectively, the empty language, the union
of languages and the Kleene star in classical regular expressions
for deterministic automata. The expressions  and  refer to the left and right hand-side
of products. Similarly,  and  refer to the left and right hand-side
of sums. The expressions  and  denote function application and a singleton set, respectively. We shall soon
illustrate, by means of examples, the role of these expressions. Here,
it is already visible that our approach (to define a language) for the
powerset functor differs from classical modal logic where  and
 are used. 
 This is a choice, justified by the fact that our goal is to have a ``process algebra'' like 
language instead of a modal logic one. It also explains why we only consider finite powerset: 
every finite set can be written as the finite union of its singletons.


Our language does not have any operator denoting intersection or
complement (it only includes the sum operator ). This is a
natural restriction, very much in the spirit of Kleene's regular
expressions for deterministic finite automata. We
will prove that this simple language is expressive enough to denote
exactly all locally finite coalgebras.

Next, we present a typing assignment system for associating
expressions to non\hyph deterministic functors. This will allow us to associate with each functor
 the expressions  that are valid specifications of
-coalgebras. The typing proceeds following
the structure of the expressions and the ingredients of the
functors.

\begin{definition}[Type system]\label{def:ts}
We define a typing relation  that will associate an expression  with two non\hyph
deterministic functors  and , which are related by the
ingredient relation ( is an ingredient of ). We shall write
 for .  The rules that define  are the following:

\end{definition}
Intuitively,  (for a closed expression ) means that  denotes an element 
 of , where  is the final
coalgebra of . As expected, there is a rule for each expression
construct. The extra rule involving  reflects
the isomorphism between the final coalgebra  and
 (Lambek's lemma, cf.~\cite{Rutten00}). Only fixed points at the outermost level of the
functor are allowed. This does not mean however that we disallow nested
fixed points. For instance,  would be
a well-typed expression for the functor  of deterministic automata,
as it will become clear below, when we will present more examples of well-typed and non-well-typed
expressions. The presented type system is decidable
(expressions are of
finite length and the system is inductive on the structure of ). Note that the rules above are meant to be read as an inductive
definition rather than as an algorithm. In an eventual implementation,
extra care is needed in the case , to avoid looping in the rule for
.  

We can formally define the set of -expressions: (closed and
guarded) well-typed
expressions associated with a non\hyph deterministic functor .

\begin{definition}[-expressions]
Let  be a non\hyph deterministic functor and  an ingredient of
.
We define  by:

We define the set  of well-typed {\em
-expressions\/} by .
\end{definition}
Let us instantiate the definition of -expressions to the functors of
deterministic automata .
\begin{example}[Deterministic expressions]
Let  be a finite set of input actions and let  be a set of
(recursion or) fixed point variables. The set  of {\em deterministic
expressions\/} is given by the set of closed and guarded (each
variable occurs in the scope of ) expressions generated by the following BNF grammar. For  and :

\end{example}
Examples of well-typed expressions for the functor 
(with  a two-element join-semilattice with  as bottom
element; recall that the ingredients of  are ,  and 
itself) include
,  and .
The expressions ,  and  are examples of
non well-typed
expressions for , because the functor  does not involve , the
subexpressions in the sum have different type, and
recursion is not at the outermost level ( has type ),
respectively.

It is easy to see that the closed (and guarded) expressions generated
by the grammar presented above are exactly the elements of
. The most interesting case to check is the expression
. Note that  has type
 as long as  has type . And the crucial
remark here is that, by definition of , .  
Therefore,  has type  if it is of type
, or more precisely, if , which explains why the
grammar above is correct. 

At this point, we should remark that the syntax of our expressions
differs from the classical regular expressions in the use of 
and action prefixing  instead of star and full concatenation.
We shall prove later that these two syntactically different
formalisms are equally expressive (Theorems~\ref{kleene1} and
~\ref{kleene2}), but, to increase the intuition behind our expressions,
 let us present the syntactic translation from classical
regular expressions to  (this translation is inspired
by~\cite{milner}) and back. 

\begin{definition}\label{def:regexp_to_exp} The set of regular expressions is given by the following syntax

where  and  denotes sequential composition. We define the following translations between regular expressions and deterministic expressions:

The function  translates  into a system of
equations in the following way. Let   be all the fixed point subexpressions of , with
 and . We define  equations , where  is obtained from
 by replacing each subexpression  by , for
all . The solution of the system,
, is then computed in the usual way (the solution of an equation of shape  is ).

In~\cite{Rut98c}, regular expressions were given a coalgebraic
structure, using Brzozowski derivatives~\cite{Brz64}. Later in
this paper, we will provide a coalgebra structure to , after
which the soundness of the above translations can be stated and proved:  and , where  will coincide with language equivalence.
\end{definition}
Thus, the regular expression   is translated to , 
whereas the expression  is transformed into .

We present next the syntax for the
expressions in  and in  (recall that
 and ).

\begin{example}[Partial expressions]
Let  be a finite set of input actions and  be a set of (recursion or)
fixed point variables. The set  of {\em partial expressions\/} is given by the set of closed and guarded expressions generated by the following BNF grammar. For  and :

Intuitively, the expressions  and  specify,
respectively, a state which has no
defined transition for input  and a state with an outgoing
transition to another one specified by .  
\end{example}
\begin{example}[Non-deterministic expressions]
Let  be a finite set of input actions and  be a set of (recursion or)
fixed point variables. The set  of {\em non\hyph deterministic expressions\/} is given by the set of closed and guarded expressions generated by the following BNF grammar. For  and :

Intuitively, the expression  specifies a
state which has two outgoing transitions labelled with the input letter , one to a
state specified by  and another to a state specified by .
\end{example}

We have defined a language of expressions which gives us an
algebraic description of systems.  We should also remark at this point 
that in the examples we strictly follow the type system to derive the 
syntax of the expressions. However, it is obvious that many 
simplifications can be made in
order to obtain a more polished language. In particular, after the
axiomatization we will be able to decrease the number of levels in the
above grammars, since will we have axioms of the shape . In Section~\ref{sec:appl}, we will
sketch two examples where we apply some simplification to the syntax. 

The goal is now to present a generalization 
of Kleene's theorem for non\hyph deterministic coalgebras (Theorems~\ref{kleene1} and \ref{kleene2}). Recall that, for regular languages, the theorem states that a language is regular
if and only if it is recognized by a finite automaton. In order to
achieve our goal we will first show that the set  of
-expressions carries a -coalgebra structure. 

\subsection{Expressions are coalgebras}\label{sec:expressions_coalg}

In this section, we show that the set of -expressions for a given
non\hyph deterministic functor  has a coalgebraic structure
. More precisely, we
are going to define a function

for every ingredient  of , and then set . Our definition of the
function  will make use of the following.
\begin{definition}For every  and for every  with
:
\begin{itemize} 
\item[(i)] we define a constant  by induction on the syntactic structure of :

\item[(ii)] we define  a function  by induction on the syntactic structure of :

\end{itemize}
Intuitively, one can think of the constant 
and the function  as liftings of 
and  to the level of ).
\end{definition}
We need two more things to define . First, we define an order  on the types of expressions. 
For ,  and  non-deterministic functors such that
 and , we define 
The order  is a partial order (structure inherited from
). Note also that  . Second, we define a measure  based on the maximum number of nested unguarded occurrences of -expressions in  and unguarded occurrences of .  We say that a subexpression  of   occurs unguarded if it is not in the scope of one of the operators , , , ,  or . 
\begin{definition}\label{def:N} For every guarded expression , we define  as follows:

\end{definition}
\noindent The measure  induces a partial order on the set of expressions: , where  is just the ordinary inequality of natural numbers. 

Now we have all we need to define .
\begin{definition}
For every ingredient  of a non\hyph deterministic functor
 and an expression , we define  as follows:

Here,  denotes syntactic substitution,
replacing every free occurrence of   in  by .
\end{definition}
In order to see that the definition of  is
well-formed, we have to observe that  can be seen
as a function having two arguments: the type  and the
expression . Then, we use induction on the Cartesian product of
types and expressions with orders  and , respectively.
More precisely, given two pairs  and   we have an order 

Observe that in the definition above it is always true that
, for all occurrences of
 occurring in the right hand side of the
equation defining . In all cases, but the ones
that  is a fixed point or a sum expression, the inequality comes
from point (i) above. For the case of the sum, note that  and   by point (ii), since  and . Similarly, in the case of  we
have that , which can easily be proved by (standard) induction on the
syntactic structure of , since  is guarded (in ), and this
guarantees that . Hence, . Also note that clause
4 of the above definition overlaps with clauses 1 and 2 (by taking
). However, they give the same result and
thus the function  is well-defined.

\begin{definition}
We define, for each non\hyph deterministic functor , a -coalgebra

by putting .
\end{definition}
The function  can be thought of as the generalization of
the well-known notion of Brzozowski derivative~\cite{Brz64} for regular
expressions and, moreover, it provides an operational semantics for
expressions, as we shall see in Section~\ref{sec:expressive}.

The observation that the set of expressions has a coalgebra structure
will be crucial for the proof of the generalized Kleene theorem,
as will be shown in the next two sections.

\subsection{Expressions are expressive}\label{sec:expressive}

Having a -coalgebra structure on  has two advantages. First,
it provides us, by finality, directly with a natural semantics
because of the existence of a (unique) homomorphism , that
 assigns to every expression  an element  of the
final coalgebra .

The second advantage of the coalgebra structure on  is that
it lets us use the notion of -bisimulation to relate
-coalgebras  and expressions . If one can
construct a bisimulation relation between an expression  and a
state  of a given coalgebra, then the behaviour represented by
 is equal to the behaviour of the state . This is the
analogue of computing the language  represented by a given
regular expression  and the language  accepted by a state
 of a finite state automaton and checking whether .


The following theorem states that every state in a locally finite
-coalgebra can be represented by an expression in our language.
This generalizes {\em half} of Kleene's theorem for deterministic automata: if a language is
accepted by a finite automaton then it is regular ({\em i.e.} it can
be denoted by a regular expression). The
generalization of the other {\em half} of the theorem (if a language
is regular then it is accepted by a finite automaton) will be
presented in Section~\ref{sec:synthesis}. It is worth to remark that
in the usual definition of deterministic automaton the initial state
of the automaton is included and, thus, in the original Kleene's
theorem, it was enough to consider finite automata. In the
coalgebraic approach, the initial state is not explicitly modelled and
thus we need to consider locally-finite coalgebras: coalgebras where each state will generate a finite subcoalgebra.
\begin{theorem}\label{kleene1}
Let  be a non\hyph deterministic functor and let  be a
locally-finite -coalgebra. Then, for any , there exists an
expression  such that . 
\end{theorem}

\proof 
Let  and let  with .
We construct, for every state , an expression  such that  .

If , we set, for every , .  It is easy to see that  is a bisimulation and, thus, we have that .

For , we proceed in the following way. Let, for every ,
 where, for  and , the expression  is defined by
induction on the structure of~:
2ex]
\gamma^{\F_1\myplus \F_2}_{\kappa_1(c)} = l[\gamma^{\F_1}_{c}] & 
\gamma^{\F_1\myplus \F_2}_{\kappa_2(c)} = r[\gamma^{\F_2}_{c}] &
\gamma^{\F_1\myplus \F_2}_{\bot} = \emp & \gamma^{\F_1\myplus \F_2}_{\top} = l[\emp]\oplus r[\emp] \
Note that here the choice of  to 
represent inconsistency is arbitrary but {\em canonical}, in the
sense that any other expression involving sum of  and
 will be bisimilar. Formally, the definition of 
above is parametrized by a function from  to a
fixed set of
variables . It should also be noted that 
 stands for  (this is a choice, since later we will axiomatize 
to be commutative and associative).

Let , define  and then set  . Here,
 denotes syntactic replacement (that is, substitution
without renaming of bound variables in  which are also free
variables in ). The definition of  does not depend in
the chosen order of : the expressions obtained are
just different modulo renaming of variables. 

Observe that  the term 

is a closed term because, for every , the term  contains at most  free variables in the set .

It remains to prove that . We show that 
 \mbox{ }
is a bisimulation. For that, we define, for  and ,  and the relation

Then, we  prove that \mycirc{}  and \mycirc{} .

\begin{itemize}
\item[\mycirc{}] By induction on the structure of .

 \fboxsep=2pt
\fbox{} Note that   which is equal to  provided that . The latter is indeed the case:
1ex]
&=& x_i  \{A^0_{1}/x_{1}\} \ldots \{A^{n-1}_{n}/x_{n}\} & \text{(def. )}\1ex]
&=& A^0_i \{A^0_{1}/x_{1}\} \ldots \{A^{n-1}_{n}/x_{n}\}& \text{(def. )}\

\fbox{} Note that, for , . Thus, we have
that .  

\fbox{} 
1.5ex]
&\iff&  <u,e>  \in R_{\F_1 \lhd \G} \text{ and } <v,f>  \in  R_{\F_2 \lhd \G}& \text{(ind. hyp.)}\1.5ex]
&\iff& <u,v> = <c,c'> \text{ and }  <e,f> = \delta_{\F_1\times
\F_2\lhd \G}(l(\xi^{\F_1}_{c}) \oplus r(\xi^{\F_2}_{c'}))&\text{(def. )}\1.5ex]
&\iff&  <<u,v>, <e,f>> \in R_{\F_1\times \F_2\lhd \G} 
\end{array}
1.5ex]
&\1.5ex]
&&[A^n_i/x_i] =
\{A^n_i/x_i\}\1.5ex]
&
\end{longtable}
\end{center}
}Here, note that , because  has no free variables.
The last two steps follow, respectively, because  is not free in  and: 
1.5ex]
 \label{eq:subst1} &=& \{A^{i-1}_i/x_i\} \{A^i_{i+1}/x_{i+1}\} \ldots\{A^{n-1}_{n}/x_{n}\}
  \label{eq:subst2}A\{B\{C/y\}/x\}\{C/y\} =
A\{B/x\}\{C/y\},\ \ \ y \text{ not free in }
\xymatrix{*++[o][F]{s_1} \ar[r]^{a}\ar@(l,u)[]^{b}&*++[o][F=]{s_2}
\ar@(r,u)[]_{a, b}}

 \gamma^\D_{g(s_1)} = l<0> \oplus r<b(x_1) \oplus a(x_2)> \;\;\;\;\;
\gamma^\D_{g(s_2)} =
l<1> \oplus r<a(x_2) \oplus b(x_2)>

 \mu x_1 . \, l<0> \oplus r<b(x_1) \oplus a(\mu x_2 . \, l<1> \oplus r<a(x_2) \oplus
b(x_2)>
)>
\xymatrix{*++[o][F]{q_1} \ar[r]^{a}& *++[o][F]{q_2}
\ar@(r,u)[]_{b}}

\begin{array}{l}
A_1 = A^0_1 = A^1_1 =  \mu x_1  . b(l[*]) \oplus a(r[x_2]) \
Thus:

Again we have  and . 

As a last example, let us consider the following non\hyph deterministic automaton, over a one letter alphabet :

We start with the equations:

Then we have the following iterations:
1ex]
A_1^2 = A_1 \{A_2^1/x_2\} = \mu x_1. l<0> \oplus r<a(\{x_1\} \oplus \{A_2\} \oplus \{x_3\})>\1ex]
A_2^2 = A_2 \{A_1/x_1\} = A_2\1ex]
A_3^2 = A_3  \{A_1/x_1\}\{A_2^1/x_2\} = \mu x_3. l<1> \oplus r<a(\{(A_1\{A_2^1/x_2\}) \} \oplus \{x_3\})>\
This yields the following expressions:
{\small

}
\subsection{Finite systems for expressions}\label{sec:synthesis}
Next, we prove the converse of
Theorem~\ref{kleene1}, that is, we
show how to construct a \emph{finite}
-coalgebra  from an arbitrary expression , such
that there exists a state  with .

The immediate way of
obtaining a coalgebra from an expression  is to compute
the subcoalgebra , since we have provided the set  with a
coalgebra structure . 
 However, the subcoalgebra
generated by an expression  by repeatedly
applying
 is, in general, infinite. Take for instance the
deterministic expression  (for simplicity, we consider  and below we will
write, in the second component of , an expression 
instead of the function mapping  to ) and
observe that:
\begin{center}
\scalebox{.975}{
}
\end{center}
As one would expect, all the new states are equivalent  and will be
identified by  (the morphism into the final coalgebra). However, the 
function  does not make any state 
identification and thus yields an infinite coalgebra.

This phenomenon occurs also in classical regular expressions. It was
shown in~\cite{Brz64} that normalizing
the expressions using the axioms for associativity, commutativity and
idempotency was enough to guarantee finiteness\footnote{Actually, to
guarantee finiteness, similar to classical regular expressions, it
is enough to eliminate double occurrences of expressions  at the
outermost level of an expression  (and to do this one needs the ACI axioms). Note that
this is weaker than taking expressions modulo the ACI
axioms: for instance, the expressions  and , for , would not be identified in the process
above. }. We will show in this
section that this also holds in our setting. 

Consider the following axioms (only the first three are essential, but we include
the fourth to obtain smaller coalgebras):

We define the relation , written infix, as the least equivalence
relation containing the four identities above. The relation
 gives rise to the (surjective) equivalence
map . The following diagram shows the maps defined so far:

In order to complete the diagram, we next prove that  is contained in the kernel
of \footnote{This is
equivalent to prove that , together with
, is the coequalizer of the projection morphisms from  to
.}. 

This will
guarantee the existence of a function  which, when , provides
 with a coalgebraic structure  (as before we write
 for ) and which
makes  a homomorphism of coalgebras. 
\begin{lemma}\label{lemma:equivACIE}
Let  and  be non\hyph deterministic functors, with . For all ,

\end{lemma}
\proof 
In order to improve readability, in this proof we will use 
to denote .  

It is enough to prove that for all : 
\begin{itemize}
\item[\mycirc{1}] 
\item[\mycirc{2}] 
\item[\mycirc{3}] 
\item[\mycirc{4}] 
\end{itemize}
By induction on the structure of . We illustrate a few cases, the
omitted ones are proved in a similar way.

\noindent\fbox{}  
 
1.5ex]
\mycirc{4}&& [\Plus_{\id\lhd \G}( \Empty_{\id\lhd
\G},x_1) ] \\
&=&[\emp \oplus x_1] &\text{(def.
 and )}\\
 &=& [x_1] &\text{()}
\end{array}\begin{array}{@{}llll}
\mycirc{2}&&(\F_1\times \F_2) ([-])(\Plus_{\F_1\times \F_2\lhd
\G}(<u_1,v_1>,<u_2,v_2>))\\
&= & <\F_1 ([-])(\Plus_{\F_1\lhd \G}(u_1,u_2)),\F_2 ([-])(\Plus_{\F_2\lhd
\G}(v_1,v_2))>&\text{(def. )}\\
&=&<\F_1 ([-])(\Plus_{\F_1\lhd \G}(u_2,u_1)),\F_2 ([-])(\Plus_{\F_2\lhd
\G}(v_2,v_1))>&\text{(ind. hyp.)}\\
&=& (\F_1\times \F_2)([-])(\Plus_{\F_1\times \F_2\lhd
\G}(<u_2,v_2>,<u_1,v_1>)) &\text{(def. )}\


\noindent\fbox{}  

In the last but one step, we use the fact
that, for any set ,  is a join\hyph semilattice
(hence, ). Due to this
fact, in the case , in this particular proof, the
induction hypothesis will not be
used.
\qed
Thus, we have a well-defined function  such that . 

We are ready to state and prove the second half of Kleene's theorem. 

\begin{theorem}\label{kleene2}
Let  be a non\hyph deterministic functor. For every ,
there exists  such that  is finite and there exists  with .
\end{theorem}
\proof 
For every , we set  (recall that  denotes the smallest subcoalgebra
generated by ). First note that, by
Lemma~\ref{lemma:equivACIE}, the map  is a
homomorphism and thus . We prove, for every
, that the subcoalgebra   has a finite state space  (here, 
actually stands for the restriction of  to ).
Again, in order to improve readability, below we will use  to denote .  

More precisely, we prove, for all , the
following inclusion 

Here,  if  we take the sum above to be  and  denotes the smallest set containing all subformulas of  and the unfoldings of  (sub)formulas, that is, the smallest subset satisfying:

Note that the set  is finite (the number of different unfoldings is finite) and has the property .

We prove the inclusion in equation~(\ref{eq:incl_kleene2}) in the following way. First,
we observe that , because . Then,
we prove that  (again, 
actually stands for the restriction of  to ) is a subcoalgebra of
. Thus, , since , the
state space of  is equal to the intersection of all
subcoalgebras of  containing .
 
To prove that  is a subcoalgebra we prove
that, for ,

The intended
result then follows by taking .

We first prove two auxiliary results, by induction on the structure of
:
1.2ex]
\mycirc{2}& (\F [-])(\Plus_{\F\lhd \G}(u,v)) \in \F(\overline V)
\Leftrightarrow (\F [-])(u) \in \F(\overline V)\text{ and } (\F [-])(v) \in
\F(\overline V)
\end{array}

\begin{array}{clr}
\mycirc{1}& (\F [-])(\Empty_{\F\lhd \G}) = [\emp] \in \overline V\
The right to left implication follows because, using
 the ,  and
 axioms, we can rewrite  as
, with all  distinct. 

\noindent\fbox{} 
1.2ex]
\mycirc{2}& (\B [-])(\Plus_{\B\lhd \G}(u,v)) = u \vee v \in \B(\overline
V)
\Leftrightarrow u \in \B(\overline V)\text{ and } v \in
\B(\overline V)& u,v\in \B(\Exp_\G)= \B
\end{array}

\begin{array}{@{}clr}
\mycirc{1}& (\F_1\times \F_2 [-])(\Empty_{\F_1\times \F_2\lhd \G}) \\&=
<(\F_1 [-])(\Empty_{\F_1\lhd \G}),(\F_2 [-])(\Empty_{\F_2\lhd \G})> \in \F_1\times \F_2(\overline
V)\
\fbox{} and 
\fbox{}: similar to .

\ \\
\fbox{} 
1.2ex]
\mycirc{2}& (\pow \F [-])(\Plus_{\pow \F\lhd
\G}(u,v))= 
((\pow \F [-]) (u) \cup (\pow \F [-])(v))\in \pow \F(\overline V) \\ &
\Leftrightarrow (\pow \F [-] (u))\in \pow \F(\overline V)
\text{ and } (\pow \F [-] (v))\in \pow \F(\overline V) \end{array}

\overline\delta_{\F\lhd
\G}([\E_1\oplus\ldots \oplus \E_k]) \in \F(\overline V)
\Leftrightarrow (\F[-])(\delta_{\F\lhd
\G}(\E_i)) \in \F(\overline V), \ \E_i\in \mathit{cl}(\E),\ i=1,\ldots,k
1.1ex]

&\mathit{IH}\1.1ex]
 &\1.1ex]
 \\

&\mathit{IH}\1.1ex]

&\mathit{IH}\1.1ex]
&\mathit{IH}\
\xymatrix{*++[o][F]{\emp} \ar@(r,u)[]_{a,b}} \ \ \
\xymatrix{*++[o][F]{l<0>} \ar[r]^{a,b}&  *++[o][F]{\emp } \ar@(r,u)[]_{a,b}}
\ \ \ \xymatrix{*++[o][F=] {l<1>} \ar[r]^{a,b}&  *++[o][F]{\emp}
\ar@(r,u)[]_{a,b}}

\xymatrix{ *+[F-:<3pt>]{r<a(l<1>)>} \ar[r]^-{a}\ar[dr]_{b}& *++[o][F=]{l<1>}
\ar[d]^{a,b}  \\
& *++[o][F]{\emp}  \ar@(r,d)[]^{a,b}}

\xymatrix{*+[F-:<3pt>]{\mu x.\, r<a(l<0>\oplus l<1>\oplus x)>}
\ar[r]^-{a}\ar@/{}_{2 pc}/[rr]_{b}&
*+[F=:<3pt>]{{l<0>\oplus l<1>\oplus \E}} \ar@(r,u)[]_{a}\ar[r]^-{b} &
*++[o][F]{\emp}  \ar@(r,d)[]^{a,b}}

\xymatrix{*+[F-:<3pt>]{\mu
x.\, r<a(x \oplus \mu y.\, r<a(y)>)>}
\ar[r]^-{a}\ar@/{}_{2 pc}/[rr]_{b}&
*+[F-:<3pt>]{\E_1 \oplus \mu y.\, r<a(y)>}
&*++[o][F]{\emp } }

\begin{array}{lcl}
\delta_\D(\E_1 \oplus \mu y.\, r<a(y)>)& =& <0,t>\\
&\text{where}& t(a) = \E_1 \oplus \mu y.\,
r<a(y)>\oplus \mu y.\, r<a(y)>>\\
&& t(b) = \emp
\end{array}

\xymatrix{*+[F-:<3pt>]{\mu
x.\,r< a(x \oplus \mu y.\, r<a(y)>)>}
\ar[r]^-{a}\ar@/{}_{2 pc}/[rr]_{b}& *+[F-:<3pt>]{
\E_1 \oplus \mu y.\, r<a(y)>}\ar@(r,u)[]_-{a}\ar[r]^-{b}
&*++[o][F]{\emp} \ar@(r,d)[]^{a,b} }

\xymatrix{*+[F-:<3pt>]{\mu
x.\, r<a(x \oplus \mu y.\, r<a(y)>)>} \ar[r]^-{a}\ar[dr]_{b}&
*+[F-:<3pt>]{\E_1 \oplus \E_2}\ar[r]^-{a}\ar[d]^{b}&
*+[F-:<3pt>]{\E_1 \oplus \E_2 \oplus \E_2}\ar[r]^-{a}\ar[dl]^{b}&\ldots\\
&*++[o][F]{\emp} \ar@(r,d)[]^{a,b} &}

\xymatrix{*++[o][F]{\emp} \ar@{~>}[r]^-{a,b}& *++[F]{\bot}} \ \ \
\xymatrix{*++[o][F]{a(l[*])} \ar@{~>}[r]^-{b}&  *++[F]{\bot }}
\ \ \ \xymatrix{*++[o][F] {a(\emp)}
\ar[r]^-{a}\ar@{~>}@/^0.7cm/[rr]^-{b}&  *++[o][F]{\emp} \ar@{~>}[r]^-{a,b}&
*++[F]{\bot}}\ \ \ \xymatrix{*+[F-:<3pt>]{a(l[*]) \oplus
b(l[*])} }

\xymatrix{*+[F-:<3pt>]{a(l[*]) \oplus b(l[*]) \oplus a(r[a(l[*])
\oplus b(l[*])])
} \ar@{~>}[r]^-{a}& *++[F]{\top}}

   &\E \oplus \E  \equiv \E && \mathit{(Idempotency)}\\
 &\E_1 \oplus \E_2  \equiv \E_2 \oplus \E_1 &&\mathit{(Commutativity)} \\
  &\E_1 \oplus (\E_2 \oplus \E_3)   \equiv (\E_1 \oplus
\E_2) \oplus \E_3 && \mathit{(Associativity)} \\
 &\emp \oplus \E \equiv \E &&\mathit{(Empty)}     

&\gamma[\mu x.\gamma/x] \equiv \mu x . \gamma && \mathit{(FP)}  \\
&{\gamma[\E/x]  \equiv  \E \Rightarrow \mu
x.\gamma \equiv \E} &&\mathit{(Unique)}

\begin{array}{lcll@{\hspace{.5cm}}lcll}
\emp &\equiv& \bot_\B & (\B - \emp) &  b_1 \oplus b_2 &\equiv& b_1 \vee_\B b_2
&(\B - \oplus)  \\
  l<\emp> &\equiv& \emp & (\times - \emp - L) &   l<\E_1 \oplus \E_2>
&\equiv& l<\E_1> \oplus l<\E_2> &(\times - \oplus - L)\\
 r<\emp> &\equiv& \emp &(\times - \emp - R)  &
r<\E_1 \oplus \E_2> &\equiv& r<\E_1> \oplus r<\E_2> &(\times - \oplus - R) 
\\
  a(\emp) &\equiv& \emp &(-^A - \emp)  &
  a(\E_1 \oplus \E_2) &\equiv& a(\E_1) \oplus a(\E_2)&(-^A - \oplus)\\
&& &&  l[\E_1 \oplus \E_2] &\equiv& l[\E_1] \oplus l[\E_2] &(+ - \oplus - L) 
\\ &&&&     r[\E_1 \oplus \E_2] &\equiv& r[\E_1] \oplus
r[\E_2]&(+ - \oplus - R) \\
& &&&  l[\E_1] \oplus r[\E_2] &\equiv& l[\emp] \oplus r[\emp]
&{(+ - \oplus - \top)} 
\end{array}

\E_1\equiv \E_2 \Rightarrow \E[\E_1/x]\equiv \E[\E_2/x]& \text{\ \ \ \
for  free in }&(\mathit{Cong})

\mu x.\gamma \equiv \mu y. \gamma[y/x] &\ \ \   \text{ for 
  not free in }&& \mathit {(\alpha-\mathit{equiv})} 

\xymatrix{*++[o][F]{s_1}
\ar@(l,u)^-{a}}\hspace{2cm}\xymatrix{*++[o][F]{s_2} \ar@/^/[r]^-{a}&
*++[o][F]{s_3} \ar@/^/[l]^-{a}}

\begin{array}{l}
\E_1 = \expr{s_1} = \mu x_1. l<0> \oplus r<a(\{x_1\})>\\ 
\E_2 = \expr{s_2} = \mu y_1. l<0> \oplus r< a(\{\mu y_2. l<0> \oplus r<a(\{\mu y_1. l<0> \oplus r<a(\{y_2\})> \})>\})>
\end{array}

\begin{array}{@{}lcll}
&& \E_2\equiv \E_1 \\
&\Leftrightarrow & r<a(\{\mu y_2. r<a(\{r<a(\{y_2\})>\})>\})>
\equiv \E & \text{(, ,  and )}\\
&\Leftrightarrow& \mu y_2. r<a(\{r<a(\{y_2\})>\})> \equiv \E &\text{( on  and  twice)}\\
&\Leftarrow &  r<a(\{r<a(\{\E\})>\})>  \equiv \E & \text{(uniqueness of fixed points)}
\\
&\Leftrightarrow &  r<a(\{\E\})> \equiv \E &\text{(fixed point axiom)}
\\
&\Leftrightarrow & \E \equiv \E
&\text{(fixed point axiom)}\end{array}

\xymatrix{*++[o][F]{s_1} \ar[r]^-{a,b}& *++[o][F]{s_2} &
*++[o][F]{s_3}\ar[l]^-{a,b} \ar[r]^-{b}& *++[o][F]{s_4} }

\begin{array}{l}
\E_1 =  \expr{s_1} =\mu x_1. l<0> \oplus r<a(\{\E_2\})\oplus
b(\{\E_2\})> \\
\E_2 =\expr{s_2} = \mu x_2. l<0> \oplus \emp\\
\E_3 = \expr{s_3} =\mu x_3. l<0> \oplus r< a(\{\E_2\}) \oplus
b(\{\E_2\}\oplus\{\E_4\})>\\
\E_4 = \expr{s_4} =\mu x_4. l<0> \oplus \emp\\
\end{array}

\begin{array}{lcll}
\E_2 &\equiv& l<0>\oplus \emp& \text{()}\\
&\equiv& l<\emp> &  \text{() and ()}\\
&\equiv& \emp &  \text{()}
\end{array}

\hspace{-.3cm}\begin{array}{@{}lcll}
&& \E_1\equiv \E_3 \\
&\Leftrightarrow &l<0> \oplus r<a(\{\E_2\})\oplus b(\{\E_2\})>\equiv  l<0> \oplus r< a(\{\E_2\}) \oplus
b(\{\E_2\}\oplus\{\E_4\})> & \text{()}\\
&\Leftrightarrow& l<0> \oplus r<a(\{\emp\})\oplus
b(\{\emp\})>\equiv  l<0> \oplus r< a(\{\emp\}) \oplus
b(\{\emp\}\oplus\{\emp\})> &\text{()}\\
&\Leftrightarrow& l<0> \oplus r<a(\{\emp\})\oplus
b(\{\emp\})>\equiv  l<0> \oplus r< a(\{\emp\}) \oplus
b(\{\emp\})> &\text{()}\\
\end{array}

\xymatrix{
\Exp_{\F\lhd \G}\ar[d]_{\delta_{\F\lhd \G}} \ar[r]^{[-]} &
\Exp_{\F\lhd \G}/_{\equiv}\\
\F(\Exp_{\F\lhd \G})\ar[r]_{\F([-])} & \F (\Exp_\G/_{\equiv}) 
}
\partial_{\F\lhd
\G}\colon
\Exp_{\F\lhd \G}/_{\equiv} \to \F(\Exp_\G/_{\equiv})\F([-])\circ
\delta_{\F\lhd \G}(\E_1) = \F([-])\circ
\delta_{\F\lhd \G}(\E_2)
\begin{array}{@{}l@{\ }ll}
&\G([-])\circ \delta_\G(\mu x.\gamma) \\
=& \G([-])\circ \delta_\G(\gamma[\mu
x.\gamma/x]) & \text{(def. of )}\\
=&  \G([-])\circ \delta_\G(\gamma[\mu
y.\gamma[y/x]/x])&\text{(by )}\\
=& \G([-])\circ \delta_\G(\gamma[y/x][\mu
y.\gamma[y/x]/y])& \text{\small(,  not
free in )}\\
=& \G([-])\circ \delta_\G(\mu y. \gamma[y/x])) & \text{(def. of )}
\end{array}2.2ex]

&

\\\\\\
\fbox{}\2ex]
\multicolumn{2}{l}{
}
\\\\
{\fbox{}} & \fbox{ }
\
\begin{array}{l}
\delta_{\F_1\myplus \F_2\lhd \G}(l[\emp])
=\kappa_1([\bot])
\neq 
\bot 
=
\delta_{\F_1\myplus \F_2\lhd \G}(\emp)\\
\delta_{\F_1\myplus \F_2\lhd \G}(r[\emp])
=\kappa_2([\bot])
\neq 
\bot 
=
\delta_{\F_1\myplus \F_2\lhd \G}(\emp)

\end{array}

\begin{array}{@{}lcll}
\G([-])\circ \delta_\G(\mu x.\gamma) 
&=& \G([-])\circ \delta_\G(\gamma [\mu x.\gamma/x]) &\text{(def. )}\\
&=& \G([-])\circ \delta_\G(\gamma [\E /x]) &\text{(by )}\\
&{=}& \G([-])\circ \delta_\G(\E)&\text{(induction hypothesis)}
\end{array}
\label{eq:ind}
(\F [-])(\delta_{\F\lhd \G}(\E_1))=(\F [-])(\delta_{\F\lhd \G}(\E_2))

\begin{array}{lcll}
(\G [-])(\delta_{\G}(x[\E_1/x] ) &=& (\G[-])(\delta_{\G}(\E_1))\\
&=& (\G [-])(\delta_{\G}(\E_2)) &\text{(\ref{eq:ind})} \\
&=& (\G [-])(\delta_{\G}(x[\E_2/x]))
\end{array}

\begin{array}{@{}lcl}
\delta_{\G\lhd \G}  ((\mu y. \E)[\E_1/x]) &=& \delta_{\G\lhd \G}
(\E[\E_1/x][\mu y.
\E/y]))\\
& \stackrel{\mathit{(IH)}}=& \delta_{\G\lhd \G}
(\E[\E_2/x][\mu y.
\E/y]))= \delta_{\G\lhd \G}  ((\mu y. \E)[\E_2/x])\1.1ex]
\delta_{\F_1\myplus \F_2 \lhd \G} (l[\E][\E_1/x])& =&
\kappa_1(\delta_{\F_1
\lhd \G}(\E[\E_1/x]))\\&\stackrel{(\mathit{IH})}= &\kappa_1(\delta_{\F_1
\lhd \G}(\E[\E_2/x]))=\delta_{\F_1\myplus \F_2 \lhd \G} (l[\E][\E_2/x])
\end{array}

\E_1 \equiv \E_2 \Rightarrow \E_1 \sim \E_2
\mathbf{beh}_{\Exp_\G/_{\equiv}}([\E_1])=
\mathbf{beh}_{\Exp_\G/_{\equiv}}([\E_2])
\mathbf{beh}_{\Exp_{\G}}(\E_1)
=  \mathbf{beh}_{\Exp_{\G}}(\E_2)\label{eq:comp}
\E_1\sim \E_2 \Leftrightarrow \mathbf{beh}_{\Exp_{\G}}(\E_1)
=  \mathbf{beh}_{\Exp_{\G}}(\E_2)\Leftrightarrow \mathbf{beh}_{\Exp_\G/_{\equiv}}([\E_1])=
\mathbf{beh}_{\Exp_\G/_{\equiv}}([\E_2])

\xymatrix{
\Exp_\G/_{\equiv}\ar@{-->}@/{}^{1.4pc}/[rr]^-{\mathbf{beh}_{\Exp_\G/_{\equiv}}}
\ar@{>>}[r]^-{e}
\ar[d]_{\partial_{\G}} &
I\ar@{^{(}->}[r]^-{m} \ar[d]_{\overline\omega_\G} &
\Omega_\G\ar[d]^{\omega_\G}\\
\G(\Exp_\G/_{\equiv})\ar[r]& \G(I)\ar[r]
& \G(\Omega_\G)\\
}
\label{eq:h_inv}
\partial^{-1}_{\F\lhd \G} (c) = [\overline\gamma^\F_{c}] 

\begin{array}{@{}l}
\overline\gamma^\id_{\partial_{\id\lhd \G}([\E])} = \E\1.5ex]
\overline\gamma^\G_{\partial_{\G}([\mu x.\E])} =
\overline\gamma^\G_{\partial_{\G}([\E[\mu x.\E/x]])}
\stackrel{(\mathit{IH})}\equiv
\E[\mu x.\E/x]\equiv \mu x.\E
\end{array}

\mycirc{}\ \ 
 \overline\gamma^\F_{\F[-](\Empty_{\F\lhd \G})} \equiv \emp
\text{ and } \mycirc{}\ \  \overline\gamma^\F_{\F[-](\Plus_{\F\lhd \G}(x_1,x_2))} \equiv \overline\gamma^\F_{\F[-](x_1)}\oplus
\overline\gamma^\F_{\F[-](x_2)}1.2ex]
&\2ex]
b & \1.4ex]
&
& \\&&
\1.2ex]
&& \
\begin{array}{lcl}
\partial_{\F_1\myplus \F_2 \lhd \G}([\overline\gamma^{\F_1\myplus \F_2}_{c}])&=&
\begin{cases} \partial_{\F_1\myplus \F_2\lhd
\G}([l[\overline\gamma^{\F_1}_{c'}]])= \kappa_1(\partial_{\F_1\lhd
\G}([\overline\gamma^{\F_1}_{c'}]))&c= \kappa_1(c')\\
\partial_{\F_1\myplus \F_2\lhd
\G}([r[\overline\gamma^{\F_2}_{c'}]]) = \kappa_2(\partial_{\F_2\lhd
\G}([\overline\gamma^{\F_2}_{c'}]))
&c=\kappa_2(c') \\ \partial_{\F_1\myplus \F_2\lhd \G}([\emp])=\bot &c=\bot \\
\partial_{\F_1\myplus \F_2 \lhd
\G}([l[\emp]\oplus r[\emp]])=\top & c=\top \end{cases}\\
&\stackrel {(\mathit{IH})}=& c
\end{array}

\begin{array}{lcl}
\partial_{\pow \F \lhd \G}([\overline\gamma^{\pow \F}_{C}])&=&
\begin{cases} \partial_{\pow \F \lhd
\G}([\emp])= \emptyset & C=\emptyset\\
\partial_{\pow \F \lhd
\G}([\bigoplus_{c\in C}\overline\gamma^{\F_1}_{c}])=\{\partial_{\F \lhd
\G}([\overline\gamma^{\F_1}_{c}])\mid c\in C\} &
\text{otherwise}\end{cases} \\
&\stackrel {(\mathit{IH})}=& C
\end{array}
\label{eq:regexp_decomp}
r_s = o(s) + \sum_{a\in A} a\cdot r_{t(s)(a)}
\label{gamma_eq} 
\expr{s_i} &\equiv& \gamma_{g(s_i)}^\G \{\expr {s_1}/x_1\} \ldots \{\expr
{s_n}/x_n\}

\begin{array}{@{}l@{\ }l@{\ \ }l@{}}
& \expr{ s_i }\\ = & A^n_i \\
=& (\mu x_i. \gamma^\G_{g(s_i)}) \{A^0_1/x_1\} \ldots
\{A_n^{n-1}/x_n\}\1ex] 
\equiv& \gamma^\G_{g(s_i)} \{A^0_1/x_1\} \ldots
\{A_{i-1}^{i-2}/x_{i-2}\}\{A^i_{i+1}/x_{i+1}\} \ldots \{A_n^{n-1}/x_n\}
\{A^n_i/x_i\} &\text{(fixed point axiom\footnotemark )}\1ex] 
=&  \gamma^\G_{g(s_i)} \{A^0_1\{A^1_2/x_2\}\ldots \{A_n^{n-1}/x_n\}/x_1\} \ldots \{A_n^{n-1}/x_n\} &  \text{(by
\ref{eq:subst2})}\2ex] 
\vdots& \text{(repeat last 2 steps for )}\
\footnotetext{Note that the fixed point axiom can be formulated using syntactic replacement rather than substitution --  -- since  is a closed term.}
\qed

Instantiating~(\ref{gamma_eq}) for , one can easily spot the similarity with
equation~(\ref{eq:regexp_decomp}) above:


Next, we prove that there exists a coalgebra homomorphism between any
locally finite - coalgebra  and .

\begin{lemma}\label{lemma:ceil-exists}
Let  be a locally finite -coalgebra. There exists a coalgebra
homomorphism .
\end{lemma}

\proof 
We define , where  is as
 in the proof of Theorem~\ref{kleene1}, associating to a state  of
a locally finite coalgebra an expression  with . To prove that  is a
homomorphism we need to verify that .

If , then  . For  we calculate, using Lemma~\ref{lemma:gamma}:

and we then prove the more general equality, for  and
:

The intended equality then follows by taking  and . 
Let us prove the equation (\ref{eq:interm}) by induction on .

\medskip 
\fbox{} 


\fbox{} 


\fbox{} 



\fbox{}, 
\fbox{} and 
\fbox{}: similar to .
\qedhere\medskip

\noindent We can now prove that the coalgebras  and  are both final in the
category of locally finite -coalgebras.
\begin{lemma}\label{lemma:final1}
The coalgebra  is final in the category
.
\end{lemma}
\vfill\eject
\proof 
We want to show that for any locally finite -coalgebra , there exists a {\em unique} 
homomorphism~. The existence is
guaranteed by Lemma~\ref{lemma:ceil-exists}, where the homomorphism {} is defined. Post-composing this homomorphism with
 (defined above) we get a coalgebra homomorphism .
If there is another homomorphism , then by post-composition with the inclusion 
 we get two homomorphisms (
and ) into the
final -coalgebra. Thus,  and  must be equal.
\qed


\begin{lemma}\label{lemma:final2}
The coalgebra  is final in the category
.
\end{lemma}
\proof 
We want to show that for any locally finite -coalgebra , there exists a {\em unique} 
homomorphism~. We only
need to prove uniqueness, since the existence is guaranteed by
Lemma~\ref{lemma:ceil-exists}, where {} is defined. 

Suppose we have
another homomorphism . Then, we
shall prove that . Let, for any ,  denote any 
representative of  (that is, ). First, observe that 
because  is a homomorphism the following holds for every :

where , with  (recall that
 was defined in~(\ref{eq:h_inv}) and note that
).

Next, we prove that  (which is equivalent to ), for all
. For simplicity we will here prove the case . The general case is identical but notationally heavier.
First, we prove that .
.8ex]
\Leftrightarrow& f_{s_1} \equiv \gamma_{g(s_1)}^\G [f_{s_2}/x_2]  [f_{s_3}/x_3] [f_{s_1}/x_1]  &\text{(all  are closed)}\.8ex]
\Leftrightarrow& f_{s_1} \equiv A_1[f_{s_2}/x_2]  [f_{s_3}/x_3]  &\text{(def. of )}
\end{array}

\begin{array}{@{}lll} 
&f_{s_2} \equiv \gamma_{g(s_2)}^\G [f_{s_1}/x_1]  [f_{s_2}/x_2]  [f_{s_3}/x_3] &\text{(by~(\ref{eq:m})})\.8ex]
\Leftrightarrow& f_{s_2} \equiv \gamma_{g(s_2)}^\G [A_1/x_1]  [f_{s_3}/x_3] [f_{s_2}/x_2] &\text{(all  are closed)}\.8ex]
\Leftrightarrow& f_{s_2} \equiv A_2^1[f_{s_3}/x_3]  &\text{(def. of )}
\end{array}

f_{s_1} \equiv  A_1[A^1_2 [f_{s_3}/x_3]  /x_2]  [f_{s_3}/x_3]  \equiv A_1[A^1_2/x_2]  [f_{s_3}/x_3] 

\begin{array}{@{}lll} 
&f_{s_3} \equiv \gamma_{g(s_3)}^\G [f_{s_1}/x_1]  [f_{s_2}/x_2]  [f_{s_3}/x_3] &\text{(by~(\ref{eq:m})})\.8ex]
\Rightarrow& f_{s_3} \equiv \mu x_3. \gamma_{g(s_3)}^\G [A_1/x_1]  [A_2^1/x_2]  &\text{(by uniqueness of fixed points)}\
Thus, we have ,  and . Note that
 since  is not
free in . Similarly, since  is not free in  and
, we have that . Thus , for all .
\qed


As a consequence of
Lemma~\ref{lemma:final2}, we have that if  and  are
isomorphic
functors then  and  are
also isomorphic (for instance, this would be true for  and
). 

We remark that Lemma~\ref{lemma:final1} could have been proved as a
consequence of Lemma~\ref{lemma:final2}, by observing that
 is, by construction, a quotient of
.  

At this point, because final objects are unique up-to isomorphism, we
know that  is an isomorphism and hence we
can conclude that the map  is injective, since it factorizes into
an isomorphism followed by a mono. This fact is the last
thing we need to prove completeness.

\begin{theorem}[Completeness]
Let  be a non\hyph deterministic functor. For all
,

\end{theorem}

\proof 
Let  be a non\hyph deterministic functor, let  and suppose that
 .
Because only bisimilar elements are identified in the final coalgebra
we know that it must be the case that  and thus, since the equivalence class
map  is a homomorphism, . Because
 is injective we have that . Hence, .
\qed

\section{Two more examples}\label{sec:appl}

In this section we apply our framework to two other examples: 
labelled transition systems (with explicit termination) and automata on guarded strings.
These two automata models are directly connected to, respectively, basic process algebra and 
Kleene algebra with tests. To improve readability we will present the corresponding languages 
using a more user-friendly syntax than the canonically derived one.

\paragraph{\textbf{Labelled transition systems.}} Labelled transition systems (with explicit termination) are coalgebras
for the functor .  As we will show below, instantiating our framework for this functor produces a language that
is equivalent to the closed and guarded expressions generated by the
following grammar, where  and  ( is a set of
fixed point variables):

together with the equations (omitting the congruence and -equivalence rules)


Note that, as expected, there is no law that allows us to prove . Moreover, 
 observe that this syntax and axiomatization is very similar to the one presented 
in~\cite{AcetoH92}. In the syntax above, 
represents deadlock,  successful termination and 
the totally undefined process.

We will next show how the beautified syntax above was derived from the
canonically derived syntax for the expressions , which is given by the set of closed and guarded expressions
defined by the following BNF:

We define two maps between this grammar and the grammar presented above.
Let us start to show how to translate 's into 's, by defining 
a map  by induction on the structure of :

And now the converse translation:

One can prove that if  (using the equations above) 
then   (using the automatically derived equations 
for the functor) and also that   implies . 

\paragraph{\textbf{Automata on guarded strings.}} It has recently been shown~\cite{kozen08} that automata on guarded
strings (acceptors of the join irreducible elements of the free Kleene algebra
with tests on generators ) are coalgebras for the functor
, where  is the set of 
atoms, {\em i.e.} minimal nonzero elements of the free Boolean algebra 
generated by  and  is a set of actions.  Applying our framework to this functor yields a
language that is equivalent to the closed and guarded expressions
generated by the following grammar, where  and :

accompanied by the equations (omitting the congruence and -equivalence rules)

We will not present a full comparison of this syntax to the one of Kleene algebra 
with tests~\cite{kozen08} (and propositional Hoare triples). The
differences between our syntax and that of KAT are similar to the ones
between regular expressions and the language  for the functor
representing deterministic automata (see
Definition~\ref{def:regexp_to_exp}). 
Similarly to the LTS example one can define maps between the beautified syntax and the automatically generated one and prove its correctness. 


\section{Polynomial and finitary coalgebras}\label{sec:pol_fin}

The functors we considered above allowed us to modularly derive
languages and axiomatizations for a large class of coalgebras. If we
consider the subset of  without the  functor, the class of
coalgebras for these functors almost coincides with polynomial
coalgebras (that is, coalgebras for a polynomial functor). The only
difference comes from the use of join-semilattices for constant
functors and  instead of the ordinary
coproduct, which played an important role in order for
us to be able to have underspecification and overspecification.  
We will next show how to derive expressions and axiomatizations
directly for polynomial coalgebras, where no underspecification or
overspecification is allowed. 

Before we show the formal definition, let us provide some intuition. 
The main changes\footnote{This syntax was suggested to us by B. Klin,
during CONCUR'09.}, compared to the previous sections, would be not to 
have  and  and consider an expression  for the
product instead of the two expressions  and  which we
considered and an expression  for
the exponential (with ). As an example, take the
functor  of deterministic automata. The expressions corresponding
to this functor would then be the set of closed and guarded
expressions given by the following BNF:

This syntax can be perceived as an explicit and complete description
of the automaton. This means that underspecification is nonexistent and
the compactness of regular expressions is lost. As an example of the
verbosity present in this new language, take  and
consider the language that accepts words with only 's and has at
last one  (described by  in Kleene's regular expressions). In
the language  it would be written as .
Using the approach described above it would be encoded as the
expression

where  is the expression
denoting the empty language. The approach we presented before, by
allowing underspecification, provides
a more user-friendly syntax and stays close to the know syntaxes for
deterministic automata and LTSs. 

In what follows we will formally present a language for polynomial
coalgebras. We start by introducing the definition of polynomial functor, which we
take from~\cite{adamek06}. 

\begin{definition}[Polynomial Functor]
Sums of the Cartesian power functors are called polynomial functors:

Here,  stands for ordinary coproduct and 
 the indexing set  is a signature, that is a possibly infinite
collection of symbols , each of 
which is equipped with a finite cardinal , called
the arity of . 
\end{definition}


\begin{definition}[Expressions and axioms for polynomial functors]
Let  be a polynomial functor. The set  of expressions for  is given by the closed and guarded expressions generated by the following BNF, where  and , for  a set of fixed point variables:

accompanied by the equations:



\end{definition}
Providing the set  with a coalgebraic structure is
 achieved using induction on the number of unguarded occurrences of nested fixed points:

We are now ready to state and prove Kleene's theorem.
\begin{theorem}[Kleene's theorem for polynomial functors]
Let  be a polynomial functor.

\begin{enumerate}[\em(1)]
\item  For every locally finite coalgebra  and for every  there exists an expression   such that .
\item For every expression  there is a finite  coalgebra  with  such that .
\end{enumerate}
\end{theorem}
\begin{proof}
Point  amounts to solve a system of equations. Let . We associate with each  an expression , where  is defined inductively as in the proof of~\ref{kleene1}, with  and  given by

It remains to prove that , for all . We observe that

is a bisimulation, since, for , we have
1.5ex]
=\delta(\mu x_i.  \sigma(x_{s_1'}, \ldots, x_{s_{\mathit{ar}(\sigma)}'})  \{A^0_{1}/x_{1}\} \ldots  \{A^{i-2}_{i-1}/x_{i-1}\}  \{A^i_{i+1}/x_{i+1}\} \ldots\{A^{n-1}_{n}/x_{n}\})\1.5ex]
=\delta( \sigma(x_{s_1'}, \ldots, x_{s_{\mathit{ar}(\sigma)}'})  \{A^0_{1}/x_{1}\} \ldots  \{A^{i-2}_{i-1}/x_{i-1}\}  \{A^i_{i+1}/x_{i+1}\} \ldots\{A^{n-1}_{n}/x_{n}\}\{A^n_i/x_i\})&\1.5ex]
=\kappa_\sigma(\expr{s_1'},\ldots, \expr{s_{\mathit{ar}(\sigma)}'})
\end{array}
\overline{\Pol}_\Sigma(X) = \mybigplus_{\sigma\in \Sigma} \
X^{\mathit{ar}(\sigma)}
\rules{\vdash \E\colon \F_j\lhd \G\ \ \ \ \ \ j\in I}
      {\vdash j[\E] \colon  \mybigplus_{i\in I} \F_i\lhd \G}

\begin{array}{l}
 l[\E_1 \oplus \E_2] \equiv l[\E_1] \oplus l[\E_2] \ \ \ \ \ 
   r[\E_1 \oplus \E_2] \equiv r[\E_1] \oplus
r[\E_2]\ \ \ \ \ \ 
 l[\E_1] \oplus r[\E_2] \equiv l[\emp] \oplus r[\emp]
 \end{array}

\begin{array}{l}
i[\E_1]\oplus i[\E_2] \equiv i[\E_1\oplus \E_2]\ \ \ \ \ \ 
i[\E_1]\oplus j[\E_2] \equiv k[\emp]\oplus l[\emp], \ \ \ \
i\neq j, k\neq l
\end{array}

\xymatrix{T \ar[d]_{f^\sharp}\ar[r]^{\mathit{id}}& T\ar[d]^f\ar[r] & S\ar[d]^f\\
\Pol_\Sigma(T)\ar@{->>}[r]_{\eta_S} & \Fin(T)\ar[r]& \Fin(S)}

\E ::= x \mid \mu x.\E \mid i(\E_1,\ldots,\E_i), \ \ \ i\in \mathbb{N}\\

\begin{array}{l}
i(\E_1,\ldots,\E_i) \equiv i(\E_1',\ldots,\E_i') \text { if }
\{\E_1,\ldots \E_i\} =  \{\E_1',\ldots \E_i'\}\\
i(\E_1,\E_2,\ldots,\E_i) \equiv (i-1)(\E_1,\E_3,\ldots,\E_i) \text { if }
\E_1\equiv \E_2\\

\end{array}

In this case, one can see that this set of axioms is sound and
complete, by simply proving, for , 
(since we already had a language and sound and complete axiomatization
for the  functor). The restricted syntax and axioms needs to 
be derived for each concrete finitary functor. 
Finding a uniform way of defining such restricted syntax/axioms and
also uniformly proving soundness and completeness is a challenging problem and it is left as future work. 

\section{Discussion}\label{sec:conclusions5}

We presented a systematic way of deriving, from the type of a system,
a language of (generalized) regular expressions and a sound and
complete axiomatization thereof. We showed the analogue of Kleene's
theorem, proving the correspondence of the behaviours captured by
the expressions and the systems under consideration. The whole
approach was illustrated with five examples: deterministic finite
automata, partial deterministic automata, non\hyph deterministic automata,
labelled transition systems and automata on guarded strings. Moreover,
all the results presented in~\cite{BRS08} for Mealy machines can be recovered as
a particular instance of the present framework. 
 
Iterative theories have been introduced by Elgot~\cite{elgot} as a model of
computation and they formalize potentially infinite computations as
solutions of recursive equations. The main example of an iterative theory is the theory of
regular trees, that is trees which have on finitely many distinct
subtrees. Ad\'amek, Milius and Velebil have presented Elgot's work
from a coalgebraic perspective~\cite{AMV03,adamekmscs2006}, simplified
some of his original proofs, and generalized the notion of free
iterative theory to any finitary endofunctor of every locally
presentable category. The language modulo the axioms we will associate
with each functor is closely related to the work above: it is an 
initial iterative algebra. This also shows the connection of our work with the
work by Bloom and \'Esik on iterative algebras/theories~\cite{BE93}.
 It would be
interesting to investigate the connections with iterative
algebras further. 

In~\cite{jacobs06}, a bialgebraic review of deterministic automata and
regular expressions was presented. One of the main results of~\cite{jacobs06}
was a description of the free algebra and Brzozowski coalgebra
structure on regular expressions as a bialgebra with respect to a GSOS
law. We expect that this extends to our framework, but fully working this out is left as future
work. 

In this paper we studied coalgebras for  functors. It is
an important and challenging question to extend our results to other
categories. Following our work, S. Milius~\cite{milius:lics10} has 
showed how to derive a language and sound and complete
axiomatization for the functor  in the category
of vector spaces and linear maps. It would also be interesting to study functors
over metric spaces~\cite{TuriR98,BreugelW06}.

In his seminal paper~\cite{kleene}, S.~Kleene introduced an
algebraic description of regular languages: regular expressions. This
was the precursor of many papers, including this one. Salomaa \cite{salomaa} presented a sound and complete axiomatization
for proving the equivalence of regular expressions. This was later
refined by Kozen in \cite{kozen}: he showed that Salomaa's
axiomatization is non-algebraic, in the sense that it is unsound under
substitution of alphabet symbols by arbitrary regular expressions, and
presented an algebraic axiomatization. In~\cite{milner}, Milner
introduced a set of expressions for finite LTS's and proved an
analogue of Kleene's theorem: each expression denotes the behaviour
of a finite LTS and, conversely, the behaviour of a finite LTS can
be specified by an expression. He also provided an axiomatization for his expressions, with the property that two expressions are provably equivalent if and only if they are bisimilar.

Our approach is inspired by the work of Kleene, Kozen and Milner. For that
reason, we have  and  in the syntax of our
expressions, which allow to have underspecification and
overspecification. These features had to be reflected in the type of
the coalgebras we are able to deal with: the class of functors
considered include join-semilattices as constant functors and
 instead of the ordinary coproduct, which has allowed us to
remain in the category . The fact that underspecification and
overspecification can be captured by a semilattice structure, plus the
fact that the axiomatization provides the set of expressions with a
join semilattice structure, hint (as one of the reviewers pointed out)
that the whole framework could have been studied directly in the
category of join-semilattices. This is indeed true, but, for
simplicity, we decided to remain in the category . It is
not clear how much could be gained by directly working on join
semi-lattices. 

The connection between regular expressions and coalgebras was first
explored in~\cite{Rut98c}. There deterministic  automata, the set of formal languages
and regular expressions are all presented as coalgebras of the
functor  (where  is the alphabet, and  is the
two element set). It is then shown that the standard semantics of
language acceptance of automata and the assignment of languages to
regular expressions both arise as the unique homomorphism into the
final coalgebra of formal languages. The coalgebra structure on the
set of regular expressions is determined by their so-called {\em
Brzozowski} derivatives~\cite{Brz64}. In the present paper, the set
of expressions for the functor  differs from
the classical definition in that we do not have Kleene star and full
concatenation (sequential composition) but, instead, the least fixed
point operator and action prefixing. Modulo that difference, the
definition of a coalgebra structure on the set of expressions in
both~\cite{Rut98c} and the present paper is essentially the same.
All in all, one can therefore say that standard regular expressions
and their treatment in \cite{Rut98c} can be viewed as a special
instance of the present approach. This is also the case for the
generalization of the results in~\cite{Rut98c} to automata on guarded
strings~\cite{kozen08}. Finally, the present paper extends the results
in our FoSSaCS'08 paper~\cite{BRS08},
where a sound and complete specification language and a synthesis
algorithm for Mealy machines is given. Mealy machines are coalgebras
of the functor , where  is a finite input
alphabet and  is a finite semilattice for the output alphabet. Part of the material of the present paper is based on two conference papers: our FoSSaCS'09 paper~\cite{regexp} and our LICS'09 paper~\cite{BRS09b}.

In the last few years, several proposals of specification languages
for coalgebras
appeared \cite{Moss99,Rossiger00,Jacobs01,Gol02,CirsteaP04,Bonsangue-Kurz05,Bonsangue-Kurz06,SP07,KV07}.
Our approach is similar in
spirit to that of~\cite{Gol02,Rossiger00,Jacobs01,SP07} in that we use the
ingredients of a functor for typing expressions, and differs
from~\cite{Rossiger00,Jacobs01} because we do not need an explicit "next-state"
operator, as we can deduce it from the type information. The modal operators associated to a functor
in~\cite{Rossiger00,Jacobs01,SP07} can easily be related with the
expressions considered in our language. As an example, consider the
expression , written in the syntax
of~\cite{Rossiger00}, which belongs to the language associated with the
functor  (the modal operator  is next
operator associated with the identity functor). In our language, this
would be represented by .

Apart from~\cite{KV07}, the languages mentioned above do not include fixed point
operators. Our language of regular expressions can be seen as an
extension of the coalgebraic logic
of~\cite{Bonsangue-Kurz05} with fixed point operators, as well as the multi-sorted logics of~\cite{SP07}, and it is similar to a fragment of the
logic presented in~\cite{KV07}. However, our goal is rather
different: we want (1) a finitary language that characterizes
exactly all \emph{locally finite} coalgebras; (2) a Kleene like
theorem for the language or, in other words, a map (and not a
relation) from expressions to coalgebras and vice-versa. Similar to
many of the works above, we also derive a modular
axiomatization, sound and complete with respect to observational
equivalence. From the perspective of modal logic, the second half of
Kleene's theorem, where we show how to construct a coalgebra from an
expression, is the same as constructing a canonical model.
In~\cite{SP07}, the models presented for the multi-sorted logics are
multi-sorted coalgebras, whereas here we remain in the world of
coalgebras in the category  \textbf{Set}, constructing, from an
expression in , for a given functor , a -coalgebra.
 Further exploring the connections with the approach presented
in~\cite{SP07} is a promising research path, opening the door to extending our framework for more general classes of functors.   

In conclusion, we mention a recent generalization of the present
approach: all the results presented in this paper can be extended in order to accommodate systems with \emph{quantities}, such as probability or costs~\cite{BBRS09}. The main
technical challenge
is that quantitative systems have an inherently non-idempotent
behaviour and thus the proof of Kleene's theorem and the
axiomatization require extra care. This extension allows for the derivation of specification languages and axiomatizations for a wide variety of systems, which include weighted automata, simple probabilistic systems (also known as Markov chains) and systems with mixed probability and non-determinism (such as Segala systems). For instance, we have derived a language and an axiomatization for the so-called stratified systems. The language is equivalent to the one presented in~\cite{GSS95}, but no axiomatization was known. 

The derivation of the syntax and axioms associated with each non-deterministic functor has been implemented in the coinductive prover CIRC~\cite{circ}. This allows for automatic reasoning about the equivalence of expressions specifying  systems. 

\paragraph{\textbf{Acknowledgements.}} The authors are grateful for useful
comments from several people: Filippo Bonchi, Helle Hansen, Bartek
Klin, Dexter Kozen, Clemens Kupke, Stefan Milius, Prakash Panagaden,
Ana Sokolova, Yde Venema and Erik de Vink.  The title of this paper
was inspired by the title of a section of a paper of Dexter
Kozen~\cite{kozen08}. The proof of soundness and completeness was
simplified (when compared with the one presented in our LICS
paper~\cite{BRS09b}) inspired by recent work of Stefan Milius on
expressions for linear systems (personal communication). Finally, we
would like to thank the three anonymous reviewers for their very detailed
reports, which greatly improved the presentation of the paper.\vspace{-24 pt}

\bibliographystyle{plain}
\bibliography{refs}
\vspace{-20 pt}
\end{document}
