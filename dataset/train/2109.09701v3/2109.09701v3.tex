\documentclass[a4paper]{article}
\pdfoutput=1
\usepackage{INTERSPEECH2022}
\usepackage{latexsym}
\usepackage{amsmath}
\usepackage{url}
\usepackage{amssymb}
\usepackage{amsfonts}
\usepackage{graphicx}
\usepackage{tabularx}
\usepackage{multirow}
\usepackage{arydshln}
\usepackage{mathtools,nccmath}
\usepackage[T5]{fontenc}
\usepackage{enumitem}
\usepackage{todonotes}
\usepackage[most]{tcolorbox}
\usepackage[hidelinks]{hyperref}

\usepackage{helvet}  \usepackage{courier}  \usepackage{graphicx} \usepackage{algorithm}
\usepackage{algorithmic}
\usepackage{multirow}
\usepackage[T5]{fontenc}



\usepackage{amsmath}
\usepackage{url}
\usepackage{amssymb}
\usepackage{amsfonts}
\usepackage{graphicx}
\usepackage{tabularx}
\usepackage{multirow}
\usepackage{arydshln}
\usepackage{mathtools,nccmath}
\usepackage{listings}

\usepackage[T5]{fontenc}
\usepackage{enumitem}
\usepackage{todonotes}
\usepackage{cancel}
\usepackage[draft]{minted}




\makeatletter
\def\PYG@reset{\let\PYG@it=\relax \let\PYG@bf=\relax \let\PYG@ul=\relax \let\PYG@tc=\relax \let\PYG@bc=\relax \let\PYG@ff=\relax}
\def\PYG@tok#1{\csname PYG@tok@#1\endcsname}
\def\PYG@toks#1+{\ifx\relax#1\empty\else \PYG@tok{#1}\expandafter\PYG@toks\fi}
\def\PYG@do#1{\PYG@bc{\PYG@tc{\PYG@ul{\PYG@it{\PYG@bf{\PYG@ff{#1}}}}}}}
\def\PYG#1#2{\PYG@reset\PYG@toks#1+\relax+\PYG@do{#2}}

\expandafter\def\csname PYG@tok@w\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.73,0.73,0.73}{##1}}}
\expandafter\def\csname PYG@tok@c\endcsname{\let\PYG@it=\textit\def\PYG@tc##1{\textcolor[rgb]{0.25,0.50,0.50}{##1}}}
\expandafter\def\csname PYG@tok@cp\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.74,0.48,0.00}{##1}}}
\expandafter\def\csname PYG@tok@k\endcsname{\let\PYG@bf=\textbf\def\PYG@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PYG@tok@kp\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PYG@tok@kt\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.69,0.00,0.25}{##1}}}
\expandafter\def\csname PYG@tok@o\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PYG@tok@ow\endcsname{\let\PYG@bf=\textbf\def\PYG@tc##1{\textcolor[rgb]{0.67,0.13,1.00}{##1}}}
\expandafter\def\csname PYG@tok@nb\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PYG@tok@nf\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.00,0.00,1.00}{##1}}}
\expandafter\def\csname PYG@tok@nc\endcsname{\let\PYG@bf=\textbf\def\PYG@tc##1{\textcolor[rgb]{0.00,0.00,1.00}{##1}}}
\expandafter\def\csname PYG@tok@nn\endcsname{\let\PYG@bf=\textbf\def\PYG@tc##1{\textcolor[rgb]{0.00,0.00,1.00}{##1}}}
\expandafter\def\csname PYG@tok@ne\endcsname{\let\PYG@bf=\textbf\def\PYG@tc##1{\textcolor[rgb]{0.82,0.25,0.23}{##1}}}
\expandafter\def\csname PYG@tok@nv\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\expandafter\def\csname PYG@tok@no\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.53,0.00,0.00}{##1}}}
\expandafter\def\csname PYG@tok@nl\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.63,0.63,0.00}{##1}}}
\expandafter\def\csname PYG@tok@ni\endcsname{\let\PYG@bf=\textbf\def\PYG@tc##1{\textcolor[rgb]{0.60,0.60,0.60}{##1}}}
\expandafter\def\csname PYG@tok@na\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.49,0.56,0.16}{##1}}}
\expandafter\def\csname PYG@tok@nt\endcsname{\let\PYG@bf=\textbf\def\PYG@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PYG@tok@nd\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.67,0.13,1.00}{##1}}}
\expandafter\def\csname PYG@tok@s\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PYG@tok@sd\endcsname{\let\PYG@it=\textit\def\PYG@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PYG@tok@si\endcsname{\let\PYG@bf=\textbf\def\PYG@tc##1{\textcolor[rgb]{0.73,0.40,0.53}{##1}}}
\expandafter\def\csname PYG@tok@se\endcsname{\let\PYG@bf=\textbf\def\PYG@tc##1{\textcolor[rgb]{0.73,0.40,0.13}{##1}}}
\expandafter\def\csname PYG@tok@sr\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.73,0.40,0.53}{##1}}}
\expandafter\def\csname PYG@tok@ss\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\expandafter\def\csname PYG@tok@sx\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PYG@tok@m\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PYG@tok@gh\endcsname{\let\PYG@bf=\textbf\def\PYG@tc##1{\textcolor[rgb]{0.00,0.00,0.50}{##1}}}
\expandafter\def\csname PYG@tok@gu\endcsname{\let\PYG@bf=\textbf\def\PYG@tc##1{\textcolor[rgb]{0.50,0.00,0.50}{##1}}}
\expandafter\def\csname PYG@tok@gd\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.63,0.00,0.00}{##1}}}
\expandafter\def\csname PYG@tok@gi\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.00,0.63,0.00}{##1}}}
\expandafter\def\csname PYG@tok@gr\endcsname{\def\PYG@tc##1{\textcolor[rgb]{1.00,0.00,0.00}{##1}}}
\expandafter\def\csname PYG@tok@ge\endcsname{\let\PYG@it=\textit}
\expandafter\def\csname PYG@tok@gs\endcsname{\let\PYG@bf=\textbf}
\expandafter\def\csname PYG@tok@gp\endcsname{\let\PYG@bf=\textbf\def\PYG@tc##1{\textcolor[rgb]{0.00,0.00,0.50}{##1}}}
\expandafter\def\csname PYG@tok@ga\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.50,0.00,0.50}{##1}}}
\expandafter\def\csname PYG@tok@go\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.53,0.53,0.53}{##1}}}
\expandafter\def\csname PYG@tok@gt\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.00,0.27,0.87}{##1}}}
\expandafter\def\csname PYG@tok@err\endcsname{\def\PYG@bc##1{\setlength{\fboxsep}{0pt}\fcolorbox[rgb]{1.00,0.00,0.00}{1,1,1}{\strut ##1}}}
\expandafter\def\csname PYG@tok@kc\endcsname{\let\PYG@bf=\textbf\def\PYG@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PYG@tok@kd\endcsname{\let\PYG@bf=\textbf\def\PYG@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PYG@tok@kn\endcsname{\let\PYG@bf=\textbf\def\PYG@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PYG@tok@kr\endcsname{\let\PYG@bf=\textbf\def\PYG@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PYG@tok@bp\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PYG@tok@fm\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.00,0.00,1.00}{##1}}}
\expandafter\def\csname PYG@tok@vc\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\expandafter\def\csname PYG@tok@vg\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\expandafter\def\csname PYG@tok@vi\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\expandafter\def\csname PYG@tok@vm\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\expandafter\def\csname PYG@tok@sa\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PYG@tok@sb\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PYG@tok@sc\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PYG@tok@dl\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PYG@tok@s2\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PYG@tok@sh\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PYG@tok@s1\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PYG@tok@mb\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PYG@tok@mf\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PYG@tok@mh\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PYG@tok@mi\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PYG@tok@il\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PYG@tok@mo\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PYG@tok@ch\endcsname{\let\PYG@it=\textit\def\PYG@tc##1{\textcolor[rgb]{0.25,0.50,0.50}{##1}}}
\expandafter\def\csname PYG@tok@cm\endcsname{\let\PYG@it=\textit\def\PYG@tc##1{\textcolor[rgb]{0.25,0.50,0.50}{##1}}}
\expandafter\def\csname PYG@tok@cpf\endcsname{\let\PYG@it=\textit\def\PYG@tc##1{\textcolor[rgb]{0.25,0.50,0.50}{##1}}}
\expandafter\def\csname PYG@tok@c1\endcsname{\let\PYG@it=\textit\def\PYG@tc##1{\textcolor[rgb]{0.25,0.50,0.50}{##1}}}
\expandafter\def\csname PYG@tok@cs\endcsname{\let\PYG@it=\textit\def\PYG@tc##1{\textcolor[rgb]{0.25,0.50,0.50}{##1}}}

\def\PYGZbs{\char`\\}
\def\PYGZus{\char`\_}
\def\PYGZob{\char`\{}
\def\PYGZcb{\char`\}}
\def\PYGZca{\char`\^}
\def\PYGZam{\char`\&}
\def\PYGZlt{\char`\<}
\def\PYGZgt{\char`\>}
\def\PYGZsh{\char`\#}
\def\PYGZpc{\char`\%}
\def\PYGZdl{\char`\\ast\mathcal{N}\lambda<><\star\ast\star\ast\ast\ast\approx$ 7 times bigger Vietnamese pre-training data than BARTpho. In addition, the multilingual seq2seq mT5 \cite{xue-etal-2021-mt5} is pre-trained on the multilingual dataset mC4 that includes 79M Common Crawl Vietnamese pages consisting of 116B syllable tokens, i.e.  mT5 uses 116 / 4 = 29 times bigger Vietnamese pre-training data than BARTpho. However, BARTpho surpasses both mBART and mT5, reconfirming that the dedicated language-specific model still performs better than the multilingual one \cite{nguyen-tuan-nguyen-2020-phobert}. Tables \ref{tab:results} and \ref{tab:originaltest} also show that BARTpho\textsubscript{word} outperforms BARTpho\textsubscript{syllable}, thus demonstrating the positive influence of word segmentation for seq2seq pre-training and fine-tuning in Vietnamese. 





\subsection{Capitalization and punctuation restoration}

Most Automatic Speech Recognition (ASR) systems generate text transcripts without information about capitalization and punctuation, which limits the readability of the transcripts. 
In addition, using these lowercasing and non-punctuation types of ASR transcripts as input to downstream task models, e.g. named entity recognition, machine translation and the like, might also cause performance degradation \cite{tundik18_interspeech} because the downstream task models are usually trained on well-formatted text datasets. Thus, capitalization and punctuation restoration are important steps in ASR transcript post-processing. An example enriching ASR transcripts with capitalization and punctuation restoration is 
as follows: 

\medskip

\begin{tcolorbox}[title=A transcript]
chuỗi nhà hàng này gần đây đã phải đóng cửa một loạt các chi nhánh theo sở kế hoạch và đầu tư hà nội và thành phố hồ chí minh golden gate đã đóng cửa bảy chi nhánh vào cuối năm 2015
\end{tcolorbox}

\begin{tcolorbox}[title=The transcript enriched with capitalization and punctuation restoration \& its English translation]
Chuỗi nhà hàng này gần đây đã phải đóng cửa một loạt các chi nhánh. Theo Sở Kế hoạch và Đầu tư Hà Nội và Thành phố Hồ Chí Minh, Golden Gate đã đóng cửa bảy chi nhánh vào cuối năm 2015. \\
The chain has recently had to shut down a series of branches. According to the Hanoi and Ho Chi Minh City Planning and Investment Departments, the Golden Gate closed seven branches by the end of 2015.
\end{tcolorbox}

Capitalization and punctuation restoration models generally fall into two main categories of approaches: sequence tagging \cite{NguyenNTDM20,huang21g_interspeech, shi21_interspeech} and sequence-to-sequence \cite{NGUYEN20212020BDP0005,capu_binhnguyen}. In this investigation, we follow the sequence-to-sequence approach to evaluate and compare our BARTpho and mBART on the Vietnamese capitalization and punctuation restoration tasks. The models take lowercase, unpunctuated texts as input and produce true case, punctuated texts as output.



\subsubsection{Experimental setup}

Due to the lack of benchmark datasets for Vietnamese capitalization and punctuation restoration, we generate a dataset automatically by leveraging the PhoST dataset  \cite{phost} that contains 327370, 1933, and 1976  Vietnamese examples for training, validation and test, respectively. 
We convert those examples into a lowercase form and remove all punctuations to simulate the ASR transcript output. Here, the standard formats for numbers and currencies are retained. 
Following previous work \cite{NguyenNTDM20,NGUYEN20212020BDP0005}, we only consider three types of punctuation marks, which are Comma (includes commas, colons, and dashes), Period (includes full stops, exclamation marks, and semicolons), and Question (only question mark). 

We use the same fine-tuning procedure that we use for the  summarization task as presented in Section \ref{ssec:setup}. Here, for fine-tuning BARTpho\textsubscript{word}, we perform an automatic Vietnamese word segmentation on the data using RDRSegmenter \cite{rdrsegmenter} from the VnCoreNLP toolkit \cite{vu-etal-2018-vncorenlp}. We detokenize the
fine-tuned BARTpho\textsubscript{word}’s output before computing scores. Note that we select the model checkpoint that produces the lowest loss on the validation set and we apply the selected one to the test set.


\subsubsection{Main results}
Table \ref{tab:punct_results} presents the results obtained by our BARTpho and mBART  on the capitalization task. We find that our BARTpho performs better than mBART. In particular, BARTpho\textsubscript{word}  and BARTpho\textsubscript{syllable}  obtain  1.1\% and 0.7\% absolute higher F\textsubscript{1} scores than mBART, respectively.


Table \ref{tab:punct_results} also shows the obtained results of our BARTpho and mBART on the punctuation restoration task. Both BARTpho versions outperform mBART on the Comma and Question types, and the performance gap is substantial w.r.t. the latter mark. Furthermore, mBART does better than BARTpho on the Period mark, however, the performance gaps are small, i.e.  mBART produces 0.14\% and 0.4\% higher scores than BARTpho\textsubscript{word} and BARTpho\textsubscript{syllable}, respectively. Overall, our BARTpho still  outperforms mBART, where BARTpho\textsubscript{word} obtains the highest Overall F\textsubscript{1} score. 


\section{Conclusion}

In this paper, we have presented BARTpho\textsubscript{syllable} and BARTpho\textsubscript{word}---the first pre-trained and large-scale monolingual seq2seq models for Vietnamese. We demonstrate the usefulness of our BARTpho by showing that BARTpho performs better than its competitor mBART and helps produce the SOTA performance for the downstream generative task of Vietnamese text summarization. We also show that BARTpho is more effective than mBART on the Vietnamese capitalization and punctuation restoration tasks. We hope that our public BARTpho models can foster future research and applications of generative Vietnamese NLP tasks.

\bibliography{refs}
\bibliographystyle{IEEEtran}


\end{document}
