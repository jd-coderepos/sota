\documentclass[sigconf]{acmart}

\usepackage{amsthm}
\usepackage{multirow}
\usepackage{stfloats}
\usepackage{graphicx}
\usepackage{url}

\usepackage{subcaption}


\setlength{\abovecaptionskip}{2pt}
\setlength{\textfloatsep}{3pt}
\setlength{\intextsep}{3pt}

\newtheorem{definition}{Definition}

\AtBeginDocument{\providecommand\BibTeX{{Bib\TeX}}}





\copyrightyear{2023}
\acmYear{2023}
\setcopyright{acmlicensed}\acmConference[CIKM '23]{Proceedings of the 32nd ACM International Conference on Information and Knowledge Management}{October 21--25, 2023}{Birmingham, United Kingdom}
\acmBooktitle{Proceedings of the 32nd ACM International Conference on Information and Knowledge Management (CIKM '23), October 21--25, 2023, Birmingham, United Kingdom}
\acmPrice{15.00}
\acmDOI{10.1145/3583780.3615160}
\acmISBN{979-8-4007-0124-5/23/10}

\begin{document}

\setlength{\abovedisplayskip}{3pt} \setlength{\belowdisplayskip}{3pt} 

\title{STAEformer: Spatio-Temporal Adaptive Embedding Makes Vanilla Transformer SOTA for Traffic Forecasting}


\author{Hangchen Liu*\textsuperscript{1}, Zheng Dong*\textsuperscript{1}, Renhe Jiang\textsuperscript{\textdagger2}, Jiewen Deng\textsuperscript{1}, \\Jinliang Deng\textsuperscript{3}, Quanjun Chen\textsuperscript{2}, Xuan Song\textsuperscript{\textdagger1,2}}

\thanks{* Equal contribution.}
\thanks{\textdagger~Corresponding author.}

\affiliation{
\textit{\textsuperscript{1}Southern University of Science and Technology}, \textit{\textsuperscript{2}The University of Tokyo}, 
\textit{\textsuperscript{3}University of Technology Sydney}
\country{}
}




\email{{liuhc3, zhengdong00}@outlook.com, jiangrh@csis.u-tokyo.ac.jp}

\renewcommand{\shortauthors}{H. Liu, Z. Dong, and R. Jiang et al.}
















\begin{abstract}
With the rapid development of the Intelligent Transportation System (ITS), accurate traffic forecasting has emerged as a critical challenge. The key bottleneck lies in capturing the intricate spatio-temporal traffic patterns. In recent years, numerous neural networks with complicated architectures have been proposed to address this issue. However, the advancements in network architectures have encountered diminishing performance gains. In this study, we present a novel component called \textbf{\textit{spatio-temporal adaptive embedding}} that can yield outstanding results with vanilla transformers. Our proposed \underline{S}patio-\underline{T}emporal \underline{A}daptive \underline{E}mbedding trans\underline{former} (\textbf{STAEformer}) achieves state-of-the-art performance on six real-world traffic forecasting datasets. Further experiments demonstrate that spatio-temporal adaptive embedding plays a crucial role in traffic forecasting by effectively capturing intrinsic spatio-temporal relations and chronological information in traffic time series.

\end{abstract}

\begin{CCSXML}
<ccs2012>
<concept>
    <concept_id>10002951.10003227.10003236</concept_id>
    <concept_desc>Information systems~Spatial-temporal systems</concept_desc>
    <concept_significance>500</concept_significance>
    </concept>
    <concept>
	<concept_id>10010147.10010178</concept_id>
	<concept_desc>Computing methodologies~Artificial intelligence</concept_desc>
	<concept_significance>500</concept_significance>
    </concept>
    <concept>
       <concept_id>10010147.10010178.10010187</concept_id>
       <concept_desc>Computing methodologies~Knowledge representation and reasoning</concept_desc>
       <concept_significance>500</concept_significance>
    </concept>
</ccs2012>
\end{CCSXML}

\ccsdesc[500]{Information systems~Spatial-temporal systems}
\ccsdesc[500]{Computing methodologies~Artificial intelligence}


\keywords{traffic forecasting, spatio-temporal embedding, transformer}

\maketitle

\begin{figure}[!t]
    \centering
    \begin{subfigure}[t]{0.192\linewidth}
        \centering
    \includegraphics[width=\linewidth]{figure/Embedding_STGNNs.pdf}
        \caption{STGNNs}
        \label{fig: embedding_STGNNs}
    \end{subfigure}
        \begin{subfigure}[t]{0.30\linewidth}
        \centering
        \includegraphics[width=\linewidth]{figure/Embedding_PDFormer.pdf}
        \caption{Transformer-\\based Models}
        \label{fig: embedding_PDFormer}
    \end{subfigure}
    \begin{subfigure}[t]{0.23\linewidth}
        \centering
        \includegraphics[width=\linewidth]{figure/Embedding_STID.pdf}
        \caption{Spatial Temporal Identity}
        \label{fig: embedding_STID}
    \end{subfigure}
    \label{fig: embeddings}
    \begin{subfigure}[t]{0.23\linewidth}
        \centering
        \includegraphics[width=\linewidth]{figure/Embedding_ours.pdf}
        \caption{Ours}
        \label{fig: embedding_ours}
    \end{subfigure}
    \caption{Input Embeddings in Different Traffic Models.}
    \label{fig: model_embeddings}
\end{figure}

\section{Introduction}
Traffic forecasting~\cite{jiang2021dl} aims to predict the future traffic time series in road networks based on historical observations. In recent years, the success of deep learning models has been notable, primarily attributable to their ability to capture the inherent spatio-temporal dependencies in the traffic system. Among them, Spatio-Temporal Graph Neural Networks (STGNNs)~\cite{STGCN, DCRNN} and Transformer-based models~\cite{ASTGCN, GMAN, STTN, PDFormer} become very popular for their outstanding performance. Researchers have devoted considerable effort to developing fancy and complicated models for traffic forecasting, such as novel graph convolutions~\cite{StemGNN, STSGCN, STFGNN, STMGCN, CCRNN, DMSTGCN, STGNN, TGCN, Z-GCNETs, HGCN, AutoSTGCN, STGODE, STAGGCN}, learning graph structures~\cite{GWNet, MegaCRN, GTS, MTGNN, SLCNN}, efficient attention mechanisms~\cite{STWA, Informer, Autoformer, Pyraformer, FEDformer}, and other methods~\cite{STMetaNet, D2STGNN, PMMemNet, EnhanceNet, AutoSTG, STEP}. Nonetheless, the advancements in network architectures have encountered diminishing performance gains, prompting a shift in focus from complicated model designs towards effective representation techniques for the data itself. 



In light of this, in this study, we focus on \textbf{\textit{input embedding}}, a widely-used, simple, yet powerful representation technique, that is often overlooked by many researchers in terms of its effectiveness. Specifically, it adds an embedding layer on the input, providing multiple types of embeddings for the model backbone. Figure~\ref{fig: model_embeddings} presents a comparative analysis of the utilized embeddings by previous models. STGNNs mainly use feature embedding , i.e. a transformation to project the raw input into hidden space. Transformer-based models require additional knowledge such as temporal positional encoding  and periodicity (daily, weekly, monthly) embedding  due to the attention mechanism's inability to preserve the positional information of the time series. Recent models, including PDFormer~\cite{PDFormer}, GMAN~\cite{GMAN} and STID~\cite{STID}, apply spatial embedding . Notably, STID~\cite{STID} is among the few studies that explore these embeddings. It employs spatial embedding and temporal periodicity embedding with a simple Multi-layer Perceptron (MLP) and achieves remarkable performance.


To further enhance the representation effectiveness, 
we propose a novel \textbf{\textit{spatio-temporal adaptive embedding}}  and apply it on the vanilla Transformer~\cite{attention} along with  and , which is shown in Figure~\ref{fig: embedding_ours}. In detail, the raw input goes through an embedding layer to obtain the input embedding, which is fed into temporal and spatial transformer layers followed by a regression layer to make predictions. Our proposed model, named \underline{S}patio-\underline{T}emporal \underline{A}daptive \underline{E}mbedding trans\underline{former} (\textbf{STAEformer}), has a far more concise architecture but achieves the state-of-the-art (SOTA) performance. In our model,  plays a crucial role by effectively capturing intrinsic spatio-temporal relations and chronological information in traffic time series. Experiments and analyses on six real-world traffic datasets prove that our proposed  can make vanilla transformer SOTA for traffic forecasting.

\section{Problem Definition}
Given the traffic series  in the previous  time frames, traffic forecasting aims to infer the traffic data in the future  frames by training a model  with parameters , which can be formulated as:

\noindent where each frame ,  is the number of spatial nodes.  is the dimension of the input feature which equals 1 in our case, standing for traffic volume. 




\begin{figure*}[t]   \centering \includegraphics[width=175mm]{figure/Architecture2.pdf} \caption{The Architecture of \underline{S}patio-\underline{T}emporal \underline{A}daptive \underline{E}mbedding trans\underline{former} (\textbf{STAEformer}).}
\label{fig:STAdp}   \end{figure*}

\section{Methodology}
As shown in Figure~\ref{fig:STAdp}, our model consists of an embedding layer, vanilla transformers applied along temporal axis as the temporal transformer layer and along spatial axis as the spatial transformer layer, then a regression layer. The embedding layer obtains the hidden representation fused by the feature embedding, the periodicity embedding, and the spatio-temporal adaptive embedding. The spatio-temporal transformer layers capture traffic relations, followed by a regression layer making the prediction.

\subsection{Embedding Layer}
To keep the native information in the raw data, we utilize a fully connected layer to obtain the feature embedding :

\noindent where  is the dimension of the feature embedding, and  indicates a fully connected layer.







We denote the learnable day-of-week embedding dict as , and the timestamps-of-day embedding dict as , where  = 7 denotes the number of days in a week. In our case,  = 288 is the number of timestamps in each day. Denoting ,  as the day-of-week data and the timestamp-of-day data for the traffic time series in -+1:, we use them as indices to extract the corresponding day-of-week embedding  and timestamp-of-day embedding  from the embedding dicts. By concatenating and broadcasting them, we get the periodicity embedding  for the traffic time series.

On one hand, it's intuitive that the temporal relation is not only decided by periodicity but also affected by the chronological order in the traffic time series. For example, a time frame in traffic time series should be more similar to the time frames nearby. On the other hand, the time series from different sensors tend to have different temporal patterns. Thus, instead of adopting a pre-defined or dynamic adjacency matrix for spatial relation modeling, we designed a spatio-temporal adaptive embedding  to capture intricate spatio-temporal relation in a uniform way. In particular,  is shared across different traffic time series.

By concatenating the embeddings above, we obtain the hidden spatio-temporal representation  as follows:

where the hidden dimension  equals .

\subsection{Transformer and Regression Layer}
We apply vanilla transformers along temporal and spatial axes to capture intricate traffic relations. 
\begin{table*}[]
\centering
\caption{Performance on METR-LA and PEMS-BAY.}
\small
\resizebox{\linewidth}{!}{
\begin{tabular}
{p{0.2cm}p{1.6cm}c|cccccccccccc}
\hline\hline
\multicolumn{2}{c}{Datasets}   & Metric & HI      & GWNet             & DCRNN   & AGCRN   & STGCN   & GTS     & MTGNN  & STNorm & GMAN  & PDFormer & STID & \textbf{STAEformer}  \\ \hline\hline
\multirow{9}{*}{\rotatebox{90}{METR-LA}}  & \multirow{3}{*}{\parbox{2cm}{\centering Horizon 3\30 min)} }    & MAE    & 6.80    & 3.08            & 3.12    & 3.20    & 3.15      & 3.14    & 3.05   & 3.18 & 3.12    & 3.20    & 3.19     & \textbf{2.97}   \\
                          &                                                                                  & RMSE   & 14.21   & 6.20            & 6.27    & 6.52    & 6.35       & 6.33    & 6.13   & 6.59 & 6.49    & 6.46    & 6.57     & \textbf{6.00}   \\
                          &                                                                                  & MAPE   & 16.72\% & 8.47\%          & 8.42\%  & 9.00\%  & 8.62\%   & 8.62\%  & 8.16\% & 8.47\% & 8.73\%  & 9.19\%  & 9.39\%   & \textbf{8.13\%} \\
                          & \multirow{3}{*}{\parbox{2cm}{\centering Horizon 12\15 min)} } & MAE    & 3.06    & \textbf{1.30}   & 1.31    & 1.35    & 1.36       & 1.37    & 1.33   & 1.33 & 1.35    & 1.32    & 1.31     & 1.31            \\
                          &                                                                                  & RMSE       & 7.05    & \textbf{2.73}   & 2.76    & 2.88    & 2.88        & 2.92    & 2.80   & 2.82 & 2.90   & 2.83    & 2.79     & 2.78            \\
                          &                                                                                  &  MAPE      & 6.85\%  & \textbf{2.71\%} & 2.73\%  & 2.91\%  & 2.86\%   & 2.85\%  & 2.81\% & 2.76\% & 2.87\%  & 2.78\%  & 2.78\%   & 2.76\%          \\
                          & \multirow{3}{*}{\parbox{2cm}{\centering Horizon 6\60 min)} }   & MAE    & 3.05    & 1.99            & 1.97    & 1.94    & 2.02        & 2.06    & 1.95   & 1.92 & 1.92    & 1.91    & 1.91     & \textbf{1.88}   \\
                          &                                                                                  & RMSE   & 7.03    & 4.60            & 4.60    & 4.50    & 4.63       & 4.60    & 4.50   & 4.45 & 4.49    & 4.43    & 4.42     & \textbf{4.34}   \\
                          &                                                                                  & MAPE   & 6.83\%  & 4.71\%          & 4.68\%  & 4.55\%  & 4.72\%    & 4.88\%  & 4.62\% & 4.46\% & 4.52\% & 4.51\%  & 4.55\%   & \textbf{4.41\%} \\ \hline\hline
\end{tabular}}
\label{table:metrla&pemsbay}
\end{table*}
Given hidden spatio-temporal representation  with  frames and  spatial nodes, we obtain the query, key and value matrices through temporal transformer layers as: 

\noindent where  are learable parameters. Then we calculate the self-attention score as:

\noindent where  captures the temporal relations in different spatial nodes.
Finally, we obtain the output of temporal transformer  as:

Similarly, the spatial transformer layer performs as:

where  follows Equation~\ref{qkv}, \ref{att_score}, \ref{value}, and  is the output of the spatial transformer. Notably, we also apply layer normalization, residual connection and multi-head mechanism.


Finally, we leverage the output of the spatio-temporal transformer layers  to generate predictions. The regression layer can be formulated as:

\noindent where  is the prediction,  is the horizon of prediction.  is the dimension of the output features which equals 1 in our case. Thus, the fully-connected layer regresses the dimension from  in  to  in .

\begin{table}[b]
\small
\caption{Summary of Datasets.}
\begin{tabular}{cccc}
\hline\hline
\textbf{Dataset} & \textbf{\#Sensors (N)} & \textbf{\#Timesteps} & \textbf{Time Range} \\ \hline
METR-LA          & 207                    & 34,272               & 03/2012 - 06/2012   \\
PEMS-BAY         & 325                    & 52,116               & 01/2017 - 05/2017   \\
PEMS03          &  358 & 26,209 & 05/2012 - 07/2012 \\
PEMS04           & 307                    & 16,992               & 01/2018 - 02/2018   \\
PEMS07           & 883                    & 28,224               & 05/2017 - 08/2017   \\
PEMS08           & 170                    & 17,856               & 07/2016 - 08/2016   \\ \hline\hline
\end{tabular}
\label{table:datasets}
\end{table}

\begin{table}[t]
\small
\caption{Performance on PEMS03, 04, 07, and 08.}
\renewcommand\arraystretch{1.1}
\tabcolsep=0.7mm
\resizebox{8.5cm}{!}{
\begin{tabular}{c|ccc|ccc|ccc|ccc}
\hline\hline
Dataset                       & \multicolumn{3}{c|}{PEMS03} & \multicolumn{3}{c|}{PEMS04}                        & \multicolumn{3}{c|}{PEMS07}                       & \multicolumn{3}{c}{PEMS08}                        \\ \hline\hline
Metric      & MAE            & RMSE           & MAPE                  & MAE            & RMSE           & MAPE             & MAE            & RMSE           & MAPE            & MAE            & RMSE           & MAPE            \\ \hline\hline
HI               & 32.62 & 49.89 & 30.60\%            & 42.35          & 61.66          & 29.92\%          & 49.03          & 71.18          & 22.75\%         & 36.66          & 50.45          & 21.63\%         \\
GWNet                         & \textbf{14.59} & 25.24 & 15.52\% & 18.53          & \textbf{29.92}          & 12.89\%          & 20.47          & 33.47          & 8.61\%          & 14.40          & 23.39          & 9.21\%          \\
DCRNN    &  15.54 & 27.18 & 15.62\%                   & 19.63          & 31.26          & 13.59\%          & 21.16          & 34.14          & 9.02\%          & 15.22          & 24.17          & 10.21\%         \\
AGCRN      & 15.24 & 26.65 & 15.89\%                & 19.38          & 31.25          & 13.40\%          & 20.57          & 34.40          & 8.74\%          & 15.32          & 24.41          & 10.03\%         \\
STGCN    &  15.83 & 27.51 & 16.13\%                   & 19.57          & 31.38          & 13.44\%          & 21.74          & 35.27          & 9.24\%          & 16.08          & 25.39          & 10.60\%         \\
GTS   &  15.41 & 26.15 &  15.39\%                    & 20.96          & 32.95          & 14.66\%          & 22.15          & 35.10          & 9.38\%          & 16.49          & 26.08          & 10.54\%         \\
MTGNN   & 14.85 & \textbf{25.23} & 14.55\%                    & 19.17          & 31.70          & 13.37\%          & 20.89          & 34.06          & 9.00\%          & 15.18          & 24.24          & 10.20\%         \\
STNorm    & 15.32 &25.93 & \textbf{14.37\%}                   & 18.96          & 30.98          & 12.69\%          & 20.50          & 34.66          & 8.75\%          & 15.41          & 24.77          & 9.76\%          \\
GMAN  & 16.87 & 27.92 & 18.23\%                       & 19.14          & 31.60          & 13.19\%          & 20.97          & 34.10          & 9.05\%          & 15.31          & 24.92          & 10.13\%         \\
PDFormer & 14.94 & 25.39 & 15.82\% & 18.36          & 30.03          & 12.00\% & 19.97          & 32.95          & 8.55\%          & 13.58          & 23.41          & 9.05\%          \\
STID    &  15.33 & 27.40 & 16.40\%                  & 18.38          & 29.95 & 12.04\%          & 19.61          & 32.79          & 8.30\%          & 14.21          & 23.28          & 9.27\%          \\
\textbf{STAEformer}   & 15.35 & 27.55 & 15.18\%            & \textbf{18.22} & 30.18          & \textbf{11.98}\%          & \textbf{19.14} & \textbf{32.60} & \textbf{8.01\%} & \textbf{13.46} & \textbf{23.25} & \textbf{8.88\%} \\ \hline\hline
\end{tabular}
}
\label{table:040708}
\end{table}

\section{Experiments}
\subsection{Experimental Setup}

\quad\,\textit{\textbf{Datasets.}} Our method is verified on six traffic forecasting benchmarks, i.e., METR-LA, PEMS-BAY, PEMS03, PEMS04, PEMS07, and PEMS08. The first two datasets were proposed by DCRNN~\cite{DCRNN}. The last four datasets were proposed by STSGCN ~\cite{STSGCN}. The time interval in the six datasets is 5 minutes, so there are 12 frames in each hour. More details are shown in Table~\ref{table:datasets}.


\textit{\textbf{Implementation.}} We implement the model with the PyTorch toolkit on a Linux server with a GeForce RTX 3090 GPU. METR-LA and PEMS-BAY are divided into the training, validation, and test sets in a fraction of 7:1:2. PEMS03, PEMS04, PEMS07 and PEMS08 are divided in a fraction of 6:2:2. In fact, the performance of our model is not sensitive to the hyper-parameters. For more details, the embedding dimension  is 24 and the  is 80. The number of layers  is 3 for both spatial and temporal transformers. The number of heads is 4. We set the input and prediction length to be 1 hour, namely, ==12. Adam is chosen as the optimizer with the learning rate decaying from 0.001, and the batch size is 16. We apply an early-stop mechanism if the validation error converges within 30 continuous steps. The code is available at \textbf{\url{https://github.com/XDZhelheim/STAEformer}}.

\begin{table}[t]
\caption{Ablation Study on PEMS04, PEMS07 and PEMS08.}
\renewcommand\arraystretch{1.3}
\tabcolsep=0.7mm
\resizebox{8.5cm}{!}{
\begin{tabular}{c|ccc|ccc|ccc}
\hline\hline
Dataset        & \multicolumn{3}{c|}{PEMS04}                        & \multicolumn{3}{c|}{PEMS07}                       & \multicolumn{3}{c}{PEMS08}                        \\ \hline\hline
Metric         & MAE            & RMSE           & MAPE             & MAE            & RMSE           & MAPE            & MAE            & RMSE           & MAPE            \\ \hline\hline
w/o       & 21.63          & 34.88          & 14.26\%          & 22.37          & 37.21          & 9.25\%          & 15.00          & 25.85        & 9.74\%          \\
w/o       & 18.92          & 30.74          & 12.27\%          & 20.21          & 33.59          & 8.40\%          & 15.00          & 24.05          & 9.56\%          \\
w/o -    & 18.50          & 30.34          & 12.24\%          & 19.87          & 33.67          & 8.29\%          & 13.83          & 23.79        & 9.09\%            \\
w/o -   & 25.17          & 39.89          & 18.00\%          & 27.71          & 42.99          & 17.61\%         & 19.96          & 31.47          & 18.53\%         \\
\textbf{STAEformer} & \textbf{18.22} & \textbf{30.29} & \textbf{12.01\%} & \textbf{19.14} & \textbf{32.60} & \textbf{8.01\%} & \textbf{13.46} & \textbf{23.25} & \textbf{8.88\%} \\ \hline\hline
\end{tabular}
}
\label{table:ablation study}
\end{table}

\textit{\textbf{Metrics.}} We use three widely used metrics for traffic forecasting task, i.e, MAE, RMSE and MAPE. Following previous work, we select the average performance of all predicted 12 horizons on the PEMS03, PEMS04, PEMS07 and PEMS08 datasets. To evaluate the METR-LA and PEMS-BAY datasets, we compare the performance on horizon 3, 6 and 12 (15, 30, and 60 min).

\textit{\textbf{Baselines.}} 
In this study, we compare our proposed method against several widely used baselines in the field. HI~\cite{HI} is a typical traditional model. We also consider STGNNs such as GWNet~\cite{GWNet}, DCRNN~\cite{DCRNN}, AGCRN~\cite{AGCRN}, STGCN~\cite{STGCN}, GTS~\cite{GTS}, and MTGNN~\cite{MTGNN}, which employ the embeddings shown in Figure~\ref{fig: model_embeddings}(a). Additionally, we examine STNorm~\cite{STNorm}, which focuses on factorizing traffic time series. While there exist Transformer-based methods for time series forecasting, such as Informer~\cite{Informer}, Pyraformer~\cite{Pyraformer}, FEDformer~\cite{FEDformer}, and Autoformer~\cite{Autoformer}, they are not specially tailored for short-term traffic forecasting. Hence, we select GMAN~\cite{GMAN} and PDFormer~\cite{PDFormer}, which are transformer models targeting the same task as ours. The input embeddings in ~\cite{GMAN} and ~\cite{PDFormer} follow the configuration in Figure~\ref{fig: model_embeddings}(b). Furthermore, we consider STID~\cite{STID}, which enhances the spaito-temporal distinction in traffic time series by utilizing the input embedding depicted in Figure~\ref{fig: model_embeddings}(c).

\begin{figure}[!t]
    \centering
    \includegraphics[width=\linewidth]{figure/performance_drop.pdf}
    \caption{By shuffling the input along the temporal axis, our spatio-temporal adaptive embedding shows a more dramatic performance decrease than spatial embedding, indicating its capability in capturing chronological information.}
    \label{fig: performance_drop}
\end{figure}

\subsection{Performance Evaluation}

As shown in Table~\ref{table:metrla&pemsbay} and~\ref{table:040708}, our method achieves better performance on most metrics on all six datasets. STAEformer outperforms STGNNs by a large degree without any graph modeling. STNorm and STID also achieve competitive results, while Transformer-based models can better capture the intricate spatio-temporal relations. Compared with PDFormer, the encouraging results indicate STAEformer is a simpler but more effective solution.

\subsection{Ablation Study}\label{ablation study}

To evaluate the effectiveness of each part in STAEformer, we conduct ablation studies with 4 variants of our model as follows:
\begin{itemize}


    \item 
    \textbf{w/o .}
    It removes spatio-temporal adaptive embedding . 
    
    \item 
    \textbf{w/o .}
    It removes periodicity embedding , including day-of-week and timestamps-of-day embedding.
    
    \item 
    \textbf{w/o -.}
    It removes temporal transformer layers.

    \item 
    \textbf{w/o -.}
    It removes both temporal transformer layers and spatial transformer layers.
    
\end{itemize}
Table~\ref{table:ablation study} reveals the significance of various embeddings on the performance of our model.  can capture daily and weekly patterns, while the proposed  is vital for traffic modeling. Furthermore, the substantial performance degradation observed upon the removal of spatial or temporal transformer layers shows that our proposed embeddings effectively model the inherent spatio-temporal patterns in the traffic data. Therefore, both spatial and temporal layers are necessary for extracting those features.

\begin{figure}[!t]
    \centering
    \begin{subfigure}[t]{0.55\linewidth}
        \centering
        \includegraphics[width=\linewidth]{figure/s_emb_tsne.png}
        \caption{Spatial Axis}
        \label{fig: vis-s-emb}
    \end{subfigure}
    \begin{subfigure}[t]{0.44\linewidth}
        \centering
        \includegraphics[width=\linewidth]{figure/t_emb_heatmap.png}
        \caption{Temporal Axis}
        \label{fig: vis-t-emb}
    \end{subfigure}
    \caption{Visualization of Spatio-Temporal Adaptive Embedding  on PEMS08.}
    \label{fig: vis}
\end{figure}

\subsection{Case Study}
\quad\,\textit{\textbf{Comparison with Spatial Embedding.}} To validate the effectiveness of spatio-temporal adaptive embedding in capturing chronological order information implied in the  input frames, we conduct more experiments on PEMS04 and PEMS08 datasets. Following~\cite{AreTrans}, we randomly shuffle the raw input along temporal axis . For comparison, we replace our spatio-temporal adaptive embedding  with spatial embedding  that was used in~\cite{STID,PDFormer}. As shown by Figure~\ref{fig: performance_drop}, our model has more severe performance degradation when shuffling the raw input along temporal axis . It means that spatio-temporal adaptive embedding  makes our model more sensitive to the chronological order, while the model with  is relatively insensitive. In summary,  can better model the chronological information in the raw input and other intricate traffic patterns, which is crucial to the task.




\textit{\textbf{Visualization of Spatio-Temporal Adaptive Embedding.}} Figure~\ref{fig: vis} further provides visualizations of our proposed spatio-temporal embedding  on the spatial and temporal axes by taking PEMS08 dataset as an example. For the spatial axis, we use t-SNE~\cite{TSNE} to get Figure~\ref{fig: vis-s-emb}. It shows that the embeddings of different nodes naturally form into clusters, which matches the spatial characteristics of the traffic data. For the temporal axis, we calculate the correlation coefficient across the 12 input frames and draw a heat map as Figure~\ref{fig: vis-t-emb}. It shows that each frame is highly correlated to the nearby frames, and the correlation gradually decreases for further frames. This shows that our proposed  models the chronological information in the time series correctly.





\section{Conclusion}


In this study, we focus on a basic representation learning technique for traffic time series forecasting, i.e., input embedding. We propose a novel spatio-temporal adaptive embedding that can work on vanilla transformers to achieve the SOTA performance on six traffic benchmarks. Further studies demonstrate that our model can effectively capture intrinsic spatio-temporal dependencies. Instead of designing complicated models, our study shows a promising direction for addressing the challenges in traffic forecasting.



\begin{acks}
This work was partially supported by the grants of National Key Research and Development Program of China (2021YFB1714400) .
\end{acks}

\bibliographystyle{ACM-Reference-Format}
\bibliography{reference}

\end{document}
