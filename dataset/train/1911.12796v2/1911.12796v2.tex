





\begin{figure*}[!htp]
\centering
\includegraphics[scale=0.25]{architecture_cropped.pdf}
\caption{\textbf{Network architectures used for digits experiments}~. We show the source classifier $F_s$, proposed calibrator $G_c$, pixel level domain discriminator $D_{pixel}$ and feature level domain discriminator $D_{feat}$.
}
\label{fig:architecture}
\end{figure*}


\begin{figure*}[!htp]
\centering
\includegraphics[scale=0.25]{epsilon_cropped.pdf}
\caption{\textbf{Performance vs. $L_{\infty}$ ball of calibration produced by the calibrator}.~ We show that with calibration that is imperceivable to human, we can achieve state-of-the-art domain adaptation performance. Calibration with large  $L_{\infty}$ ball has worse performance, probably due to overfitting or models' poor rosbutness to pixel modification in general
}
\label{fig:epsilon}
\end{figure*}



\begin{table*}[!htp]
\centering
\begin{tabular}{lll}
\hline
GTA5 to CityScapes & N. of Param.(M) & Flops(G) \\ \hline
DRN-26 & 20.6 & 200 \\
Data Calibrator & 0.05 & 2.67 \\ \hline
Digits & N. of Param.(M) & Flops(G) \\ \hline
LeNet & 3.13 & 0.03 \\
Data Calibrator & 0.18 & 0.02 \\ \hline
\end{tabular}
\caption{\textbf{Overhead of data calibrator}.~We show that our calibrator is light-weight both in terms of number of parameters and flops. Even for network as tiny as LeNet, the calibrator is small compared to it}
\label{table:overhead}
\end{table*}









%
