\documentclass[10pt,twocolumn,letterpaper]{article}
\usepackage[rebuttal]{cvpr}

\usepackage{graphicx}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{booktabs}
\usepackage{enumitem}
\usepackage{xcolor, colortbl}

\usepackage[pagebackref,breaklinks,colorlinks,bookmarks=false]{hyperref}

\usepackage[capitalize]{cleveref}
\crefname{section}{Sec.}{Secs.}
\Crefname{section}{Section}{Sections}
\Crefname{table}{Table}{Tables}
\crefname{table}{Tab.}{Tabs.}


\definecolor{darkblue}{rgb}{0, 0.2, 0.6}
\definecolor{orange}{rgb}{1.0, 0.5, 0.0}
\newcommand{\suha}[1]{{\color{darkblue}{#1}}}
\newcommand{\suhac}[1]{{\color{orange}{(#1)}}}





\def\cvprPaperID{4410} \def\confName{CVPR}
\def\confYear{2022}

\begin{document}

\title{Semi-supervised Semantic Segmentation with Error Localization Network}  

\maketitle
\thispagestyle{empty}

We thank all the reviewers for their constructive comments. 

\noindent{\textbf{[R1] Averaged results on randomized selection:}}
As shown in Table \hyperref[sec:avg-res-pascal]{1} and \hyperref[sec:avg-res-city]{2}, we conduct the experiments with three randomly chosen data selections to the same ratio. The tables show mIoU score with different labeled-unlabeled ratios, presented as mean Â± std-dev computed from three subsets except full ratio.

\noindent{\textbf{[R1] Values of benchmark method and related work:}} We appreciate this comment. In the rebuttal, due to lack of time and resources, it is unable to reproduce the previous studies. In the revised version of our paper, we will list benchmark scores by reproducing as much previous work as possible. We will also describe in a separate paragraph how our paper differs from other related work in more detail.

\noindent{\textbf{[R1] Further ablation study:}} We conduct additional experiments on the ratio of 1/20 to PASCAL VOC 2012 with ResNet50 as a backbone network to investigate how each loss term impacts our work.  
It results in 69.1 when only  is applied, 69.3 when only  is applied, and 70.52 points when both are applied. Thresholding strategy without any additional network achieves 67.77, as mentioned in Table 3 in our paper (Threshold). 

\noindent{\textbf{[R1] Inconsistent figures:}}
Fig.1 and Fig.2 of our paper represent our semi-supervised learning framework and supervised learning framework (training auxiliary decoders and ELN). Proposed auxiliary decoders are only used in supervised learning; they produce plausible erroneous predictions for efficient training of ELN. In the semi-supervised learning step, no auxiliary decoders are used. We will modify our figures and captions to convey their meaning more clearly.

\noindent{\textbf{[R1] Unreferenced paper:}} We observe that ``semi-supervised semantic segmentation with cross-consistency training" [2] has a similar model architecture to our method. We already cited the paper in our work (as [40]), but we will add a more detailed discussion about the difference from our method in a revised version.

\noindent{\textbf{[R2,R3] Model parameters and training time:}} \textbf{Model parameters.}
The number of parameters for the baseline and the proposed method is about 40.6M and 115.4M with ResNet50 as a backbone, respectively. 
\textbf{Training time.} On the ratio of 1/4 to PASCAL VOC 2012 with ResNet50 as a backbone network, we measured the training time for baseline and each case with 0, 1, and 2 auxiliary decoders. The whole training times for 250 epochs are 6.0hr, 12.3hr, 13.6hr, and 14.4hr, respectively. Note that there is no difference in model size and inference time complexity compared to baseline when testing the our final model.

\noindent{\textbf{[R2] Entropy Map:}}  is the pixel-wise entropy map of (Line 366). We consider that this entropy information could be helpful for ELN learning; the higher the entropy of prediction (low-confident prediction), the more erroneous it will be. On the ratio of 1/4 to PASCAL VOC 2012 with ResNet50 as a backbone network, our method with entropy map achieves 74.6, while 73.6 for without entropy map.

\noindent{\textbf{[R2] Teacher and student framework with ELN:}}
Mean teacher [3] has been widely used in recent work [1,5] to produce a more stable pseudo label. ELN is firstly trained with auxiliary decoders, and then it filters \textit{erroneous predictions of the teacher network} in the later semi-supervised learning stage.

\noindent{\textbf{[R2] Normalization in Eq (3):}}
We appreciate this comment based on a keen insight. We intended to make the auxiliary decoders learn slowly, simulating various error patterns in the early stage. However, normalization with a constant could be more appropriate, as you might suspect. We will do additional empirical analysis of this.

\noindent{\textbf{[R2] Learning in the first stage:}} We only use  in the pre-training stage, but in the subsequent learning process, it is correct that several losses are jointly minimized. We will explain this clearly when explaining Eq (7) in a revised version of our paper.

\noindent{\textbf{[R3]  constraint:}} We assign different 20 and 50 to each decoder (line 548). The expression was misleading and will be corrected. Thanks for pointing it out.

\noindent{\textbf{[R3] Small batch sizes:}} Due to the proposed model's size and traits of its task - segmentation, we cannot help but choose relatively small batch sizes. 

\noindent{\textbf{[R3] Hyper-parameter selections:}} \textbf{color jittering.} There are four components for color jittering - bright, contrast, saturation, and hue. The first four are chosen uniformly from [0.6, 1.4] and [-0.1, 0.1] for the hue. \textbf{loss constraint parameter.} A too-large value makes it difficult for the auxiliary decoder to learn, and a too-small value makes it impossible to generate erroneous predictions. We observed the loss value of the main decoder after pre-training and intuitively selected a proper value. \textbf{temperature parameter.} The temperature parameter is one of the critical parameters in our method. We selected its value of 0.5 according to [4]. Note that we did not tune the parameter manually by observing the performance of models.  


\begin{table}
\centering
\resizebox{\linewidth}{!}{ \begin{tabular}{@{}lccccc@{}}
\toprule
\vspace{-1mm}
SegNet & Backbone & 1/20 & 1/8 & 1/4 & Full\\
\midrule
\vspace{-1mm}
 DL3+ & ResNet50 & 70.5\small{0.2} & 73.4\small{0.3} & 74.8\small{0.5} & 76.6\\ 
\midrule
\vspace{-1mm}
 DL3+ & ResNet101 & 72.6\small{0.2} & 74.7\small{0.3}& 76.6\small{0.3} & 78.2 \\ 
\bottomrule
\vspace{-3mm}
\end{tabular}
} \vspace{-5mm}
\caption{
Average mIoU on the PASCAL VOC 2012 \emph{val} set. 
} \label{sec:avg-res-pascal} 
\vspace{1mm}
\resizebox{\linewidth}{!}{ \begin{tabular}{@{}lcccccc@{}}
\toprule
\vspace{-1mm}
SegNet & Backbone & 1/8 & 1/4 & 1/2 & Full\\
\midrule
\vspace{-1mm}
DL3+ & ResNet50 & 71.1\small{0.1} & 73.3\small{0.2}& 75.2\small{0.3} & 77.7 \\ 
\bottomrule
\end{tabular}
} \vspace{-4mm}
\caption{
Average mIoU on the Cityscapes \emph{val} set.
} \vspace{-2mm}
\label{sec:avg-res-city} 
\end{table}
\begin{table}
\centering
\vspace{-1mm}
\resizebox{0.8\linewidth}{!}{ \begin{tabular}{@{}cccc@{}}
\toprule
\vspace{-1mm}
Threshold &  &  &   \\
\midrule
\vspace{-1mm}
67.77 & 69.14 & 69.30 & \textbf{70.52}\\ 
\bottomrule
\end{tabular}
} \vspace{-3mm}
\caption{
Performance of different loss combinations in mIoU. 
} \label{sec:loss-ablation} 
\vspace{-6mm}
\end{table}
 


\scriptsize{
    \begin{enumerate}[label={[\arabic*]},itemsep=-1.5mm,leftmargin=5mm]
      \item Semi-supervised semantic segmentation with pixel-level contrastive learning from a class-wise memory bank, ICCV 2021.
      \item Semi-supervised semantic segmentation with cross-consistency training, CVPR 2020.
      \item Weight-averaged consistency targets improve semi-supervised deep learning results, NeurIPS 2017.
      \item Pixel contrastive-consistent semi-supervised semantic segmentation, ICCV 2021.
      \item -semiseg: Contrastive semi-supervised segmentation via cross-set learning and dynamic class-balancing, ICCV 2021.
    \end{enumerate}
}




\end{document}
