\documentclass{IOS-Book-Article}     \usepackage{amsmath}
\usepackage{amssymb}
\usepackage{amsfonts}
\usepackage{amsthm}
\usepackage{graphicx}
\usepackage{color}
\usepackage{url}
\usepackage{listings}
\usepackage{setspace}
\usepackage{subfigure}
\usepackage{wrapfig}
\usepackage{rotating}
\usepackage{algorithm}
\usepackage{subfigure}
\usepackage{url}
\usepackage{pgf}
\usepackage{tikz}
\usepackage{listings}

\theoremstyle{plain}            

\newtheorem{theorem}{Theorem}[section]
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{proposition}[theorem]{Proposition}
\newtheorem{corollary}[theorem]{Corollary}
\newtheorem{alg}[theorem]{Algorithm}

\theoremstyle{definition}       

\newtheorem{definition}[theorem]{Definition}
\newtheorem{observation}[theorem]{Observation}
\newtheorem{example}[theorem]{Example}
\newtheorem{conjecture}[theorem]{Conjecture}
\newtheorem{remark}[theorem]{Remark}

\newcommand{\vectband}{\owedge}

\newcommand{\vectbnot}{\bnot}

\newcommand{\vectbor}{\ovee}

\newcommand{\vectgt}{{
 \tikz[baseline=(X.base)]{
  \useasboundingbox (-.22,-.11) rectangle (.22,.11);
  \draw[style=very thin] (0,0) circle (3.2pt);
  \draw               (0,-.09) node (X) {};
  \draw               (0.01,-0.01) node {\footnotesize\ttfamily>};
}
}}

\newcommand{\vectlt}{{
 \tikz[baseline=(X.base)]{
  \useasboundingbox (-.22,-.11) rectangle (.22,.11);
  \draw[style=very thin] (0,0) circle (3.2pt);
  \draw               (0,-.09) node (X) {};
  \draw               (-0.01,-0.01) node {\footnotesize\ttfamily<};
}
}}

\newcommand{\vecteq}{{
 \tikz[baseline=(X.base)]{
  \useasboundingbox (-.22,-.11) rectangle (.22,.11);
  \draw[style=very thin] (0,0) circle (3.2pt);
  \draw               (0,-.09) node (X) {};
  \draw               (0,-0.02) node {\footnotesize\ttfamily=};
}
}}

\newcommand{\vectleq}{{
 \tikz[baseline=(X.base)]{
  \useasboundingbox (-.22,-.11) rectangle (.22,.11);
  \draw[style=very thin] (0,0) circle (3.2pt);
  \draw               (0,-.09) node (X) {};
  \draw               (-0.01,0.01) node {\footnotesize\ttfamily<};
  \draw           (-.06,-.08) -- (.06,-.08);
}
}}

\newcommand{\vectgeq}{{
 \tikz[baseline=(X.base)]{
  \useasboundingbox (-.22,-.11) rectangle (.22,.11);
  \draw[style=very thin] (0,0) circle (3.2pt);
  \draw               (0,-.09) node (X) {};
  \draw               (0.01,0.01) node {\footnotesize\ttfamily>};
  \draw           (-.06,-.08) -- (.06,-.08);
}
}}


\newcommand{\band}{{
 \tikz[baseline=(X.base)]{
  \useasboundingbox (-.18,-.11) rectangle (.18,.11);
  \draw               (0,-.09) node (X) {};
  \draw               (0,0) node {\bfseries\ttfamily\&};
}
}}

\newcommand{\bplus}{{
 \tikz[baseline=(X.base)]{
  \useasboundingbox (-.22,-.11) rectangle (.22,.11);
  \draw[style=very thin] (0,0) circle (3.2pt);
  \draw               (0,-.09) node (X) {};
  \draw               (0,0) node {\bfseries\ttfamily+};
}
}}


\newcommand{\bnot}{{
 \tikz[baseline=(X.base)]{
  \useasboundingbox (-.09,-.11) rectangle (.09,.11);
  \draw               (0,-.09) node (X) {};
  \draw               (0,-0.12) node {\Large\bfseries\ttfamily\~{\ }};
}
}}

\newcommand{\bor}{{
 \tikz[baseline=(X.base)]{
  \useasboundingbox (-.09,-.18) rectangle (.09,.12);
  \draw               (0,-.12) node (X) {};
  \draw[style=thick]  (0,-0.18) -- (0,.12);
}
}}

\newcommand{\bshl}{{
\ensuremath{\ll}
}}

\newcommand{\bshr}{{
\ensuremath{\gg}
}}

\lstdefinelanguage  {algorithm}
{keywords=[18]{begin,end,if,else,elsif,then,while,for,repeat,do,input,output,proc,return,let,with,where,set},
morecomment=[s]{\{}{\}} }
\lstnewenvironment {pseudocode}{\lstset{tabsize=4, language=algorithm,
texcl=true, mathescape=true, keywordstyle=\color{black}\bf,
basicstyle=\footnotesize\color{darkgray}, commentstyle=\itshape,columns=flexible }
\lstset{moredelim=[is][\underline]{_}{_}}
}{}

\begin{document}
\begin{frontmatter}          \title{Computing alignment plots efficiently}
\runningtitle{Computing alignment plots efficiently}


\author{Peter Krusche and Alexander Tiskin*},
\runningauthor{P. Krusche and A. Tiskin}
\address{Dept. of Computer Science, University of Warwick, Coventry,
CV4~7AL, UK}
\begin{abstract}
Dot plots are a standard method for local comparison of biological
sequences. In a dot plot, a substring to substring distance is computed for all
pairs of fixed-size windows in the input strings. Commonly, the Hamming distance
is used since it can be computed in linear time. However, the Hamming distance
is a rather crude measure of string similarity, and using an alignment-based edit
distance can greatly improve the sensitivity of the dot plot method.
In this paper, we show how to compute alignment plots of the latter type
efficiently. Given two strings of length  and  and a window size , this
problem consists in computing the edit distance between all pairs of
substrings of length , one from each input string. The problem can be
solved by repeated application of the standard dynamic programming
algorithm in time . This paper gives an improved
data-parallel algorithm, running in time  using vector
operations that work on  values in parallel and  processors.
\end{abstract}



\end{frontmatter}



\section{Introduction}

\let\thefootnote\relax\footnotetext{* Research supported by the
 Centre for Discrete Mathematics and Its Applications
 (DIMAP), University of Warwick, EPSRC award EP/D063191/1.
 Computational resources were provided by the Centre for Scientific
 Computing at the University of Warwick.
 }
Dot plots are a standard method for local comparison of two biological
sequences introduced by Gibbs/McIntyre~\cite{Gibbs:70} and
Maizel/Lenk~\cite{Maizel_Lenk:81}.
When creating a dot plot, a substring to substring distance is computed
for all pairs of fixed-size windows in the input strings. The result
can be visualized by a plot showing a dot for each pair of windows that
achieves a distance below a fixed threshold.
Commonly, the Hamming distance is used~\cite{Maizel_Lenk:81,Krumsiek:07}, since it can be
computed very efficiently. 
However, the Hamming distance is a rather crude measure of string similarity.
Using a string edit distance or alignment score (see e.g.\ \cite{Gusfield:97})
for dot plot filtering can greatly improve the sensitivity of the method.
In the context of biological sequence comparison, this idea has been implemented
by Ott et al.~\cite{Ott:09}, where a sequential algorithm is given which
creates an alignment plot for two strings of lengths  and  using a 
fixed window length~ in time . 


In this paper, we give an improved data-parallel algorithm, running in time
 using vector operations that work on  values in
parallel, and show experimental speedups from an implementation using
MMX~\cite{Intel:09}. Furthermore, we demonstrate that the algorithm can be
parallelized to run on multiple processors using MPI~\cite{Snir+:95}.

\section{Computing longest common subsequences and string
alignments}\label{sec:lcs} 
Let  and  be two strings over an alphabet  of size . We distinguish between contiguous
\textit{substrings} of a string , which can be obtained by removing zero or
more characters from the beginning and/or the end of , and \textit{subsequences},
which can be obtained by deleting zero or more characters in any position.
The \textit{longest common subsequence} (LCS) of two strings is the longest
string that is a subsequence of both input strings; its length (the LLCS) is a
measure for the similarity of the two strings.
Substrings of length  are called \textit{-windows}.
For a given , the length of the LCS of two -windows 
and  will be denoted as . 
An \textit{alignment plot} for  and  consists of all values
 with , .


Although the LCS is more accurate than the Hamming score, 
more general similarity measures are of interest in practice. A standard
interpretation of LCS is \textit{string alignment}~\cite[p. 209 ff.]{Gusfield:97}. 
An alignment of strings  and  is obtained by putting a subsequence of 
into one-to-one correspondence with a (not necessarily identical) subsequence
of , character by character and respecting the index order. The
corresponding pairs of characters, one from  and the other from , are
said to be \textit{aligned}. A character not aligned with a character of
another string is said to be aligned with a \textit{gap} in that string.
Finding the LCS corresponds to computing a maximum alignment when assigning the scores
  to aligning a matching pair of characters,  to
inserting a gap, and  to aligning two mismatching characters.
More general alignments than the LCS can be obtained using the standard dynamic
programming algorithm~\cite{Wagner+:74,Needleman1}, which allows for gap
penalties as well as different scores for each individual pair of matching/mismatching characters,
forming a \textit{pairwise score matrix}. Any algorithm for LCS computation can
be generalized to pairwise score matrices with small rational scores at the
price of a constant factor blow-up of the input
strings~\cite{TiskinL:07:Applications}. In this paper, we will consider
alignments with match score , mismatch score  and gap penalty
.
To compute these alignments, we modify the input strings by adding a new character
\texttt{\a\a\xymnS(x,y)x'y'S(x,y) = LLCS(x',y') - 0.5 \cdot (m + n)\{i, i+1, \ldots, j\}[i : j]\{i+\frac{1}{2}, i+\frac{3}{2}, \ldots, j - \frac{1}{2}\}\langle i : j
\rangle\hat{\ }M\hat{\imath}\hat{\jmath}M(\hat{\imath}, \hat{\jmath}) = M(i, j)i = \hat{\imath}-1/2j = \hat{\jmath} - 1/2[1:m]\times [1:n]\langle 1:m+1\rangle\times \langle 1:n+1\rangleD^\Sigmam\times nD D^\Sigma(i,j) = \sum
D(\hat{\imath},\hat{\jmath})(\hat{\imath},\hat{\jmath})\in
\langle i:m+1 \rangle \times \langle 1:j \rangle
\text{.}G_{x,y}xyv_{i,j}i \in [0:m]j \in [0:n]v_{i, j-1} \rightarrow v_{i, j}v_{i-1, j} \rightarrow v_{i, j}v_{i-1, j-1} \rightarrow v_{i, j}x_i = y_jx_i x_{i+1} \ldots x_{j}yv_{i-1,0}v_{j,m}x_iy_j(i-\frac{1}{2}, j-\frac{1}{2})A_{x,y}A_{x,y}(i,j)G_{x,y}v_{i-1,0}v_{j,m}A_{x,y}(i,j)0 < i < j < nxy_i \ldots y_jA_{x,y}(i,j)ijA_{x,y}(i,j)A(\hat{\imath}, \hat{\jmath})A(\hat{\imath}+\frac{1}{2},\hat{\jmath}-\frac{1}{2}) + 1 =
 A(\hat{\imath}-\frac{1}{2},\hat{\jmath}-\frac{1}{2}) =
 A(\hat{\imath}+\frac{1}{2},\hat{\jmath}+\frac{1}{2}) =
 A(\hat{\imath}-\frac{1}{2},\hat{\jmath}+\frac{1}{2})
 AD_AD_A(\hat{\imath},
\hat{\jmath}) = 1(\hat{\imath},\hat{\jmath})AD_A(\hat{\imath},\hat{\jmath}) = 0mnm+nAO(m+n)D_AA(i,j) = j - i -
D^\Sigma_A(i,j)D_A^\SigmaD_Av_{0, \hat{\imath} - \frac{1}{2}}v_{0,\hat{\imath} + \frac{1}{2}}v_{m, \hat{\jmath} - \frac{1}{2}}v_{m,\hat{\jmath} + \frac{1}{2}}x_{k} = y_{l}G_{x,y}v_{i-1,0}v_{j,m}\langle i:j\ranglewO(wn)wnwxwy_i \ldots y_{i+w-1}\langle i:i+w \ranglewwxymnwxyO(mnw)(w,1)yxwwnx_i \ldots x_{i+w-1}yO(w)j\langle j-w:j\rangle{B}B\lceil\log n\rceilBwyO(\log w)d\langle j-w:j\rangleBy_{j-w+1}\ldots y_jx_i\ldots x_{i+w-1}w-dnO(w)m-wO(m n w)hwhO(\log (m+n))wO(\log w)(\hat{\imath}, \hat{\jmath})\hat{\jmath} - \hat{\imath}w(i,j)i\ \mathrm{mod}\ r = j\ \mathrm{mod}\ r = 0rr=2w0\ \mathrm{mod}\ rA(w,r)A^{w,r}A^{w,r}(i,j)= A(i,j) \ \mathrm{if}\ j - i \leq wi\ \mathrm{mod}\ r = j\
            	\mathrm{mod}\ r = 0A^{w,r}(i,j) = \textit{undefined}(w,r)(\hat{\imath}, \hat{\jmath})\hat{\jmath}-\hat{\imath} < w(w,r)xyO(\log(w/r))Sm+n\lceil \log_2(w/r + 1) \rceil(\hat{\imath}, \hat{\jmath})S(\hat{\imath}+1/2) = \min(2^{w/r+1}-1,(\hat{\jmath}-\hat{\imath})/r)\hat{\imath}O(\log w)(w,r)wwO(\log w/r)i\ \mathrm{mod}\ r = j\
 \mathrm{mod}\ r = 0r[k:k+r-1]k \bmod r = 0rrV(j)Vv+\infty\mathit{INF} \equiv 2^v - 1v = \lceil \log_2 2w+1 \rceil{V}(k){V}(k) + 1V(k) < 2w\mathit{INF}{V}{W}\mathit{INF}k{V}(k) = {W}(k){V}{W}{V}(k){W}(k){V}(k) > {W}(k)M{V}{W}){V}(k){M}(k)
= \mathit{INF}{W}(k)VWvW\times\times\times\times\div\div\div\div\div\div\div\div\div\div\div\div\div\div\div\div\div\div\div\div\div\div\div\div\times\div\div\div\div\div\div\div\div\div\div\div\div\div\div(200,2)wO(mn)$. We are currently investigating a 
practical variation of this theoretical method which further reduces the
dependency on the window size, and may improve the algorithm shown here.
Moreover, we believe that it is possible to use a similar heuristic to the one
applied in~\cite{Ott:09} to further improve performance.

\bibliographystyle{plain}
\begin{thebibliography}{10}

\bibitem{website_csc_facilities}
{Centre for Scientific Computing, University of Warwick,
  \url{http://www.csc.warwick.ac.uk}}.

\bibitem{Abrash:09}
M.~Abrash.
\newblock {A First Look at the Larrabee New Instructions (LRBni)}.
\newblock {\em Dr. Dobb's Journal}, 2009.

\bibitem{Alves+:08}
C.E.R. Alves, E.N. Caceres, and S.W. Song.
\newblock An all-substrings common subsequence algorithm.
\newblock {\em Discrete Applied Mathematics}, 156(7):1025--1035, April 2008.

\bibitem{Cormen+01}
T.H. Cormen, C.E. Leiserson, R.L. Rivest, and C.~Stein.
\newblock {\em Introduction to Algorithms, Second Edition}.
\newblock MIT Press/McGraw-Hill Book Company, 2001.

\bibitem{Crochemore+:01}
M.~Crochemore, C.S. Iliopoulos, Y.J. Pinzon, and J.F.~Reid.
\newblock A fast and practical bit-vector algorithm for the longest common
  subsequence problem.
\newblock {\em Inf. Proc. Lett.}, 80(6):279--285, 2001.

\bibitem{Gibbs:70}
A.J. Gibbs and G.A. McIntyre.
\newblock The diagram: {A} method for comparing sequences. its uses with amino
  acids and nucleotide sequences.
\newblock {\em Eur. J. Biochem.}, 16:1--11, 1970.

\bibitem{Gusfield:97}
D.~Gusfield.
\newblock {\em Algorithms on Strings, Trees, and Sequences}.
\newblock Cambridge Univ. Press, 1997.

\bibitem{Intel:09}
\newblock {Intel Software Developer's
Manuals}, 
\newblock \url{http://www.intel.com/products/processor/manuals}, 2009.

\bibitem{Krumsiek:07}
J.~Krumsiek, R.~Arnold, and T.~Rattei.
\newblock Gepard: a rapid and sensitive tool for creating dotplots on genome
  scale.
\newblock {\em Bioinformatics}, 23(8):1026--1028, 2007.

\bibitem{Maizel_Lenk:81}
J.~V. Maizel and R.~P. Lenk.
\newblock Enhanced graphic matrix analysis of nucleic acid and protein
  sequences.
\newblock {\em Proc. Nat. Academy of Sciences of the USA}, 78(12):7665--7669,
  1981.

\bibitem{Needleman1}
S.~B. Needleman and C.~D. Wunsch.
\newblock A general method applicable to the search of similarities in the
  amino acid sequence of two proteins.
\newblock {\em J. Mol. Biology}, 48:443--453, 1970.

\bibitem{Ott:09}
S.~Ott, S.~Gunawardana, M.~Downey, and G.~Koentges.
\newblock Loss-free identifcation of alignment-conserved {CRMs}.
\newblock {\em In preparation}, 2009.

\bibitem{Schmidt:98}
J.~P. Schmidt.
\newblock All highest scoring paths in weighted grid graphs and their
  application to finding all approximate repeats in strings.
\newblock {\em SIAM J. Computing}, 27(4):972--992, 1998.

\bibitem{Snir+:95}
M.~Snir, S.~W. Otto, D.~W. Walker, J.~Dongarra, and S.~Huss-Lederman.
\newblock {\em MPI: The Complete Reference}.
\newblock MIT Press, Cambridge, MA, USA, 1995.

\bibitem{Tiskin:05}
A.~Tiskin.
\newblock Semi-local longest common subsequences in subquadratic time.
\newblock {\em J. Discrete Algorithms}, 6(4):570--581, 2008.

\bibitem{TiskinL:07:Applications}
A.~Tiskin.
\newblock Semi-local string comparison: Algorithmic techniques and
  applications.
\newblock {\em Mathematics in Computer Science}, 1(4):571--603, 2008.
\newblock See also arXiv: 0707.3619.

\bibitem{Wagner+:74}
R.~A. Wagner and M.~J. Fischer.
\newblock The string-to-string correction problem.
\newblock {\em J. ACM}, 21(1):168--173, 1974.

\end{thebibliography}

\end{document}
