\def\year{2020}\relax
\documentclass[letterpaper]{article} \usepackage{aaai20}  \usepackage{times}  \usepackage{helvet} \usepackage{courier}  \usepackage[hyphens]{url}  \usepackage{graphicx} \usepackage{subfigure}
\usepackage{multirow}
\usepackage{amsmath}
\usepackage{adjustbox}
\usepackage{threeparttable}
\urlstyle{rm} \def\UrlFont{\rm}  \usepackage{graphicx}  \setlength{\pdfpagewidth}{8.5in}  \setlength{\pdfpageheight}{11in}  

\usepackage{color}

\pdfinfo{
/Title (Multi-Label Classification with Label Graph Superimposing)
/Author (Ya Wang, Dongliang He, Fu Li, Xiang Long, Zhichao Zhou, Jinwen Ma, Shilei Wen)
} 




\setcounter{secnumdepth}{0} 

\setlength\titlebox{2.5in} \title{Multi-Label Classification with Label Graph Superimposing}
\author{
Ya Wang}\thanks{equal contribution. This work was done when Ya Wang was a full-time research intern at Baidu.}^{\ddag*}^{\ddag}^{\ddag}^{\ddag}^{\,
Shilei Wen
\\
}^{\ddag}Xy=F_1\circ F_0(X)F_0:X\mapsto fF_1: f\mapsto yF_0A_S\in R^{N\times N}A_K\in R^{N\times N}0.2G = (\mathcal{V}, \mathcal{E}, A)\mathcal{V}\mathcal{E}AAN \times N(i,j)V_iV_jN=|\mathcal{V}|E\in R^{N \times F}NG_S = (\mathcal{V}, \mathcal{E}_S, A_S)G_K = (\mathcal{V}, \mathcal{E}_K, A_K)A_SA_KA_SA_KS_{ij}\mathcal{V}_i\mathcal{V}_jw_rr|S_{ij}|S_{ij}A_S'A_K'A_SA_KA_SA_S' = D_S^{-1/2} A_S D_S^{-1/2}D_S[D_S]_{ii} = \sum_j [A_S]_{ij}A_SA_S'A_K'\lambda \in [0, 1]A_S'A_K'AA_SA_KAG_SG_K\tau \in RAA_{KS}\mathit{I}_NN \times N\eta \in RA_{KS}(V_i, V_j)V_iV_jG_{KS} = (\mathcal{V}, \mathcal{E}_{KS}, A_{KS})A_{KS}'E^{(l)}\in R^{N \times C^{(l)}}lNE^{(0)}W^{(l)} \in R^{C^{(l)} \times C^{(l+1)}}\sigma(\cdot)x \in R^{C\times T\times H \times W}CTHWNE \in R^{N \times C}g1\times 1\times 1g: R^{N \times T\times H\times W} \mapsto R^{C \times T\times H\times W}\otimes(\cdot)^T\sigma(\cdot)R_{N\times T\times H\times W}(\cdot)R_{THW \times C}(\cdot)(\cdot)^T\times+x^{(l)}E^{(l)}l^{\text{th}}1\times1\times1256512102420480.2300G_S\lambda\tau\eta10^{-4}224\times 224256\times 256\lambda\eta\tau10^{-4}10^{-4}E^{(0)}CE^{(0)}\lambda\lambda\tau$ varies from 0.01 to 0.04 by step of 0.01, the mAP is 44.6, 44.62, 44.93 and 44.77. 


\section{Conclusion}

Capturing label relationship takes a crucial position on multi-label recognition. In order to better model this information, we propose to construct the KS graph for label correlation modeling by superimposing knowledge graph into statistical graph. Then the LC operation is presented for injecting GCN embeddings into CNN features, resulting in a novel neural network KSSNet. LC operation acts as label-feature correlation modeling and helps the model learn label-anchored feature representations. The KSSNet is proven to be capable of learning better feature representations for a specific multi-label recognition task anchored on its label relationship. Experiments on MS-COCO and Charades have demonstrated the effectiveness of our proposed KS graph and KSSNet for both multi-label image and video recognition tasks.

\paragraph{Acknowledgement} This work was supported by the Joint Laboratory of Intelligent Sports of China Institute of Sport Science (CISS).
	
{	
	\small
	\bibliographystyle{aaai}
	\bibliography{AAAI-WangY.951}
}

\end{document}
