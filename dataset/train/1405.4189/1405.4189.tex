\section{Introduction}
 
Termination analysis is an active research topic, and a wide range of methods and tools exist~\cite{pldi/CookPR06,conf/tacas/CookSZ13,sas/HarrisLNR10,cav/KroeningSTW10,cav/LeeWY12,tacas/PopeeaR12,conf/esop/UrbanM14}. Each method provides its own twist to address the same issue: in the presence of loops with branching or nesting, the termination argument has to account for all possible interleavings between the different paths through the loop. 

If the program is \emph{lasso-shaped} (a stem followed by a single loop without branching), the control flow is trivial; there is only one path.
Consequently, the termination argument can be very simple.  Many procedures are specialized to lasso-shaped programs and derive a simple termination argument rather efficiently~\cite{cav/Ben-Amram09,popl/Ben-AmramG13,cav/BradleyMS05,tacas/CookKRW10,conf/atva/HeizmannHLP13,conf/tacas/LeikeH14,vmcai/PodelskiR04}. The relevance of lasso-shaped programs stems from their use as the representation of an infinite trace through the control flow graph of a program with arbitrary nesting.



We present a new method that analyzes termination of a general program  but has to find termination arguments only for lasso-shaped programs.
In our method we see the program  as a blackbox from which we can obtain sample traces. 
We transform a sample trace  into a lasso-shaped program and use existing methods to compute a termination argument for this lasso-shaped program.  
Afterwards we construct a ``larger'' program  (which may have branching and nested loops) for which the same termination argument is applicable.
We call this construction \emph{learning}, because we learned the terminating program  from a sample trace .
Our algorithm continues iteratively until we learned a set of programs  that forms a decomposition of the original program .
This decomposition can be seen as a program of the form , i.e., a nondeterministic choice of programs , that is semantically equivalent to the original program .


Our technical contribution is this method, which does not only extend the existing portfolio of termination analyses but also provides a new functionality: the decomposition of a program  into modules .  
This decomposition is not guided by the syntax of the program, this decomposition exploits a novel notion of modularity where a module is defined by a certain termination argument. This novel notion of modularity is the conceptual contribution of our paper.




\begin{center}
\begin{minipage}{40mm}
\pseudo{program sort(int i)}
\begin{tabular}{@{}l@{\;}l@{}}
: & \pseudo{while (i>0)}\0.8mm]
: & \pseudo{while(j<i)}\0.8mm]
 & \pseudo{//} \pseudo{swap(a[j],a[i])}\0.8mm]
: & \pseudo{i--}\
(\textsc{\color{innerT}Inner}+\textsc{\color{outerT}Outer})^*. \textsc{\color{innerT}Inner}^\omega 

(\Inner^*.\Outer)^\omega
(\Outer + \Inner)^\omega,\prg=\langle \Loc,\delta,\ellinit,\ellfin\rangle(\ell,\st,\ell')\in \delta \quad\text{\ \ implies \ \ }\quad \ell\in \Loc_U \text{ \  or \  } \ell'\in \Loc_V\ell_0\stackrel{\st_{1}}{\rightarrow}\dots\stackrel{\st_{k}}{\rightarrow}\ell_k\stackrel{\st_{k+1}}{\rightarrow}\cdots\stackrel{\st_n}{\rightarrow}\ell_n\nu_0\stackrel{\st_{1}}{\rightarrow}\dots\stackrel{\st_{k}}{\rightarrow}\nu_k\stackrel{\st_{k+1}}{\rightarrow}\cdots\stackrel{\st_n}{\rightarrow}\nu_nf(\nu_n)\prec f(\nu_k). \mI(\ellinit) \;\Leftrightarrow\; \oldrk = \infty. \mI(\ellfin) \;\Rightarrow\;  \big(f(\vec\var)\prec\oldrk\big).\{ \; \mI(\ell) \; \} \; \st \;  \{ \; \mI(\ell') \; \} \text { is valid } 
\mbox{for }(\ell,\st,\ell')\in\delta, \ell\neq\ellfin
\{ \; \mI(\ell) \; \} \; \stsm{:=};\st \;  \{ \; \mI(\ell') \; \} \text { is valid } 
\mbox{ for }(\ellfin,\st,\ell')\in\delta
1mm]
\mI(\ell_{k}) \Rightarrow  f(\vec\var)<\oldrk\1mm]
\hoare{\mI(\ell_i)}{\st_{i+1}}{\mI(\ell_{i+1})} \quad \text{ for } k < i < n\\begin{array}{cl}
& \oldrk := \infty\\
\ell_1: & \st_1\\
\vdots & \;\vdots\\
\ell_{k-1}: & \st_{k-1}\\
\ell_{k}: & \pseudo{while (true)} \\
& \quad\quad \pseudo{assert}(f(\vec\var)<\oldrk)\\
& \quad\quad \oldrk := f(\vec\var)\\
& \quad\quad \st_{k}\\
\ell_{k+1}: & \quad\qquad \st_{k+1}\\
\vdots & \quad\quad \;\vdots\\
\ell_{n}: & \quad\quad \st_{n}
\end{array}I\;\;\land\;\; f(\vec\var)<\oldrk\;\;\land\;\; \oldrk\geq 0\mL(\prg) \subseteq \mL(\prg_1)\cup\dots\cup \mL(\prg_n)(\prg_1,f_1,\mI_1),\dots,(\prg_n,f_n,\mI_n)\mL(\prg) = \mL(\prg_1)\cup\dots\cup \mL(\prg_n)\prg_\mathsf{rem} := \prg \backslash (\prg_1\cup\dots\cup \prg_{n-1})\mL(\prg) \subseteq \mL(\prg_1)\cup\dots\cup \mL(\prg_n)\mL(\prg) \cap \mL(\overline{\prg_1})\cup\dots\cup \mL(\overline{\prg_n})
(a+b)^*=(b^*ab^*)^+ + b^*
(a+b)^\omega = (a+b)^* b^\omega + (b^*a)^\omega.(a+b)^+ = b^+ + (b^*ab^*)^+(a+b)^\omega = (a+b)^* \; b^\omega + (a+b)^* \; (b^*ab^*)^\omega(a+b)^*(b^*ab^*)^\omega(ab)^\omega = a(baba)^\omega.


The idea of size-change
termination~\cite{cav/Ben-Amram09,journals/corr/abs-1110-6183,popl/LeeJB01}
is to track the value of (auxiliary) variables and show the absence of infinite executions by showing that one value would be decreased infinitely often in a well-ordered domain.
The (auxiliary) variables can be seen as a predefined set of mutually
independent termination arguments. 


In contrast with the above approaches,  a termination argument in our setting is a \emph{stand alone} module (its validity is checked
for the corresponding fair -traces, independently from all other program traces).  In contrast, a component of a
lexicographic ranking function, a disjunct of a transition invariant,
or a size-change variable
makes sense only as part of a global termination argument (whose
validity has to be checked for the global program).

Finally, we use ``learning'' as a metaphor rather than as a technical term, in contrast with the work in~\cite{lee2012termination} which uses machine learning for termination analysis.  
















\section{Conclusion and Future Work}
We have presented a algorithm for termination analysis that transforms a program into a nondeterministic choice of programs. 
Our transformation is not guided by the syntactic structure of the program, but by its semantics. 
Instead of decomposing the program into modules and analyzing termination of the modules, we construct modules that we learned from sample traces and that are terminating by construction.

The general idea of such a transformation is the same as for \emph{trace refinement}~\cite{conf/esop/MauborgneR05}: move disjunction over abstract values to the disjunction over sets of traces.  
The formalization of the shared idea and the exploration of its theoretical and practical consequences for program analyses is a topic of future work.
