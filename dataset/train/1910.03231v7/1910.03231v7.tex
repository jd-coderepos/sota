\newpage
\setcounter{section}{0}
\setcounter{figure}{0}
\setcounter{table}{0}
\setcounter{lemma}{0}
\setcounter{theorem}{0}

\makeatletter 
\renewcommand{\thefigure}{A\arabic{figure}}
\setcounter{table}{0}
\renewcommand{\thetable}{A\arabic{table}}
\setcounter{algorithm}{0}
\renewcommand{\thealgorithm}{A\arabic{algorithm}}
\setcounter{definition}{0}
\renewcommand{\thedefinition}{A\arabic{definition}}

\newpage
\appendix
\setcounter{page}{1}
\resetlinenumber

\begin{center}
\vskip 0.15in
\LARGE{\bf Appendix}  
\end{center}



\section*{Related work with more details}

\paragraph{Learning from Noisy Labels}


Our work fits within a stream of research on learning with noisy labels.
A large portion of research on this topic works with the \emph{random classification noise} (RCN) model, where observed labels are flipped independently with probability  
\citep{bylander1994learning,cesa1999sample,cesa2011online,ben2009agnostic}. Recently, learning with asymmetric noisy data (or also referred as \emph{class-conditional} random classification noise (CCN)) for binary classification problems has been rigorously studied in \citep{stempfel2009learning,scott2013classification,natarajan2013learning,scott2015rate,van2015learning,menon2015learning}.

\rev{
\paragraph{Symmetric loss} For RCN, where the noise parameters are symmetric, there exist works that show symmetric loss functions \citep{manwani2013noise,ghosh2015making,ghosh2017robust,van2015learning} are robust to the underlying noise, without specifying the noise rates. It was also shown that under certain conditions, the proposed loss functions are able to handle asymmetric noise. Our focus departs from this line of works and we exclusively focus on asymmetric noise setting, and study the possibility of an approach that can ignore the knowledge of noise rates.

Follow-up works \citep{du2013clustering,van2015average,menon2015learning,charoenphakdee2019symmetric} have looked into leveraging symmetric conditions and 0-1 loss with asymmetric noise, and with more evaluation metrics, such as balanced error rate and AUROC. In particular, experimental evidence is reported in \citep{charoenphakdee2019symmetric} on the importance of symmetricity when learning with noisy labels.

\paragraph{More recent works}
 More recent developments include an importance re-weighting algorithm \citep{liu2016classification}, a noisy deep neural network learning setting \citep{sukhbaatar2014learning,han2018co,song2019selfie}, and learning from massive noisy data for image classification \citep{xiao2015learning,goldberger2016training,zhang2017mixup,jiang2017mentornet,jenni2018deep,yi2019probabilistic}, robust cross entropy loss for neural network \citep{zhang2018generalized}, loss correction \citep{patrini2017making}, among many others. Loss or sample correction has also been studied in the context of learning with unlabeled data with weak supervisions \citep{lu2018minimal}. Most of the above works either lacks theoretical guarantee of the proposed method against asymmetric noise rates \citep{sukhbaatar2014learning,zhang2018generalized}, or require estimating the noise rate or transition matrix between noisy and true labels \citep{liu2016classification,xiao2015learning,patrini2017making,lu2018minimal}. A good number of the recent works can be viewed as derivatives or extension of the unbiased surrogate loss function idea introduced in \citep{natarajan2013learning}, therefore they would naturally require the knowledge of the noise rates or transition matrix. We do provide thorough comparisons between peer loss and the unbiased surrogate loss methods.
 
 A recent work \citep{xu2019l_dmi} proposes an information theoretical loss (an idea adapted from an earlier theoretical contribution \citep{kong2018water}) that is also robust to asymmetric noise rate. We aimed for a simple-to-optimize loss function that can easily adapt to existing ERM solutions. \citep{xu2019l_dmi} involves estimating a joint distribution matrix between classifiers and noisy labels, and then invokes computing a certain information theoretical measure based on this matrix. Therefore, its sample complexity requirement and the sensitivity to noise in this estimation are not entirely clear to us (not provided in the paper either). We do provide calibration guarantees, generalization bounds, and conditions under which the loss functions are convex. In general, we do think computationally peer loss functions are easy to optimize with, in comparison to information theoretical measures. Experiments comparing with \citep{xu2019l_dmi} are also given in Section \ref{sec:exp}. 
}

\vspace{-0.1in}
\paragraph{Peer Prediction}

Our work builds on the literature for peer prediction \citep{prelec2004bayesian,MRZ:2005,witkowski2012robust,radanovic2013,Witkowski_hcomp13,dasgupta2013crowdsourced,shnayder2016informed,sub:ec17}. \citep{MRZ:2005} established that strictly proper scoring rule \citep{Gneiting:07} could be adopted to elicit truthful reports from self-interested agents.  Follow-up works that have been done to relax the assumptions imposed \citep{witkowski2012robust,radanovic2013,Witkowski_hcomp13,radanovic2016incentives,sub:ec17}.
Most relevant to us is \citep{dasgupta2013crowdsourced,shnayder2016informed} where a correlated agreement (CA) type of mechanism was proposed. CA evaluates a report's correlations with another reference agent - its specific form inspired our peer loss.

\section*{Illustration of our implementation of peer loss}

\begin{figure*}[!h]
\begin{center}
\includegraphics[width=0.9\textwidth]{figures/illustration2.pdf}
\caption{Illustration of our peer loss implementation.}
\end{center}
\label{mechanism:ill_plf} 
\end{figure*}
We illustrate our peer loss method in Figure 5. 


\section*{Other peer prediction functions}

 Other notable examples include quadratic and logarithmic scoring function, defined as follows:
\begin{example}
Quadratic scoring function:

\end{example}

\begin{example}
Logarithmic scoring function: 

\end{example}
We know the following is true:
\begin{lemma}[\cite{MRZ:2005}]
 defined in Example 1 \& 2 induce strict truthfulness when  and  are \emph{stochastically relevant}.
\end{lemma}
with defining stochastic relevance as follows:
\begin{definition}
 and  are stochastically relevant if
 ~ s.t. 

\end{definition}


Similarly we conclude that when  and  are stochastic relevant, the correlated agreement scoring rule, quadratic scoring rule and logarithmic scoring rule are strictly truthful. 






\section*{Proof for Theorem \ref{THM:MAIN}}

\begin{proof}
Note that proving  is equivalent with proving  

First note that the expected score of a classifier over the data distribution further writes as follows:

 is able to elicit the Bayes optimal classifier  using  implies that 



Denote by  a sub-optimal classifier that disagrees with  on set . Denote . Construct the following reporting strategy for : 
  
 We can similarly construct the above reporting strategy for   with parameter :
   
 By definition of sub-optimality of  in reporting we know that
, as a zero measure mis-reporting strategy does not affect its optimality. Not hard to check that 
 
  Each of the two conditional expectation terms further derives:
 
In the second equality above, the dropping of conditions  in  is due to the fact that  is conditionally independent of  given . The above argument repeats for . Therefore we conclude
 
 
 Yet we have the following fact that

  Subtracting and adding  and  in above partial sums in , and combining the first  terms, we have 
  
Note that  corresponds to a reporting strategy that always reports , and  is the one to always report . 




 Similarly for : Suppose  disagrees with  on set . Note  
 because of the assumption 
, in above we have the same  as in the . Construct the following reporting strategy for 
  
 We can similarly construct the above reporting strategy for   with parameter :
   
 Similarly we claim that (details not repeated)
  
Again we note that
  
 And by further rearranging terms as done above we have (with only difference being replacing  with ; we omit the details)

 Therefore 
 
  Due to the truthfulness of  (unless  is predicting all  or all  labels), 
  
Using the fact that :

Therefore we proved the optimality of .



\end{proof}




 According to Theorem \ref{THM:MAIN} and Theorem 4.4,  \cite{shnayder2016informed}, minimizing  defined in CA is going to find the Bayes optimal classifier, if  and  are categorical, which is easily satisfied:
\begin{lemma}\label{LEMMA:CATE}
When ,  and  are categorical. 
\end{lemma}

\begin{proof}
Being categorical means

which further implies

and

Consider the following fact

Since  is a function of  and , due to conditional independence between  and  (conditional on ) we have

Therefore

We also have

Then we have

 means that the Bayes' optimal classifier is at least informative (\citep{sub:ec17}) - if otherwise, we can flip the classifier's output to obtain one, which contradicts the optimality of Bayes optimal classifier.

\end{proof}


\section*{Details for Example \ref{exa:delta}}


First of all, we compute the marginals of  and :

And easily

For noisy labels:

and

For the joint distribution,


Further, 

With above, the entries in Delta can be computed easily, for instance



\section*{Proof for Lemma \ref{LEMMA:SGN} }

\begin{proof}
Again recall that 


Then we have

when . Interestingly this coincides with the condition imposed in \citep{natarajan2013learning}. Similarly we can prove that 

The other entries for  and  are symmetric.
Therefore the sign matrix of above score matrix is exactly the diagonal matrix.
\end{proof}

\section*{Proof for Lemma \ref{LEM:AFFINE}}
\begin{proof}
We denote by  the random variable corresponding to the peer samples . 

First we have

Consider the two terms on the RHS separately.

 The above is done mostly via law of total probability and using the assumption that  is conditionally (on ) independent of . Subtracting and adding  and  to the two expectation terms separately we have
 
And consider the second term:

Subtracting the first and second term on RHS of Eqn. (\ref{eqn:pl0}):
\end{proof}


\paragraph{Multi-class extension for 0-1 loss}
\begin{proof}







\rev{


 We denote by  a transition matrix that characterizes the relationships between noisy label  and the true label . The  entry of  is defined as . We write . 
 
 
 Consider the following case: suppose the noisy labels have the same probability of flipping to a specific wrong class, that is, we pose the following conditions: 
, for all . 
This condition allows us to define  new quantities:

Note that this condition is easily satisfied for the binary case since there is only one other class to be flipped to wrongly.

We show that  is a diagonal matrix when , a similar condition as . 

Notice the following facts:

and using Eqn. \ref{eqn:qii} we have

Then

 Now consider the following 
 
Therefore 

For clean distribution we have

For the second term above we have

Therefore 

and the above concludes 

where the RHS above is the peer loss computed on the clean distribution. 

Again when we have balanced label distribution that , 

Therefore minimizing peer loss on the clean distribution returns the same minimizer as for the true and clean 0-1 risk.}
\end{proof}


\section*{Proof for Theorem \ref{THM:EQUAL}}
\begin{proof}
From Lemma \ref{LEM:AFFINE} we know

  When  is the 0-1 loss we have , and therefore
 
With above we proved .
\end{proof}
\section*{Proof for Theorem \ref{THM:pneq}}

\begin{proof}




Apply Lemma \ref{LEM:AFFINE} we know

Denote by . From the optimality of  we have

i.e., 

Note :

Then we have

Therefore

\end{proof}

\section*{Proof for Lemma \ref{LEM:alpha1}}

\begin{proof}


Again since  is an affine transform of  we conclude the proof.
\end{proof}

\section*{Proof for Theorem \ref{THM:weightedPeer}}

\begin{proof}


Again the last equality is due to the independence between  and . Replace  and  as functions of :

we further have

where  is a constant:


Let 
 
that

we obtain that


concluding our proof. The last equation Eqn.(\ref{eqn:alphapeer}) also implies the following proposition: 
\begin{proposition}\label{prop:alpha}
For any , we have

\end{proposition}

\noindent : ~~When , we have

That is 

Therefore .
\end{proof}

\section*{Proof for Theorem \ref{THM:converge1}}
\begin{proof}

, using Hoeffding's inequality with probability at least  

where  denote the upper and lower bound on . 

Note we also have the following:

Now we show

We conclude the proof.
\end{proof}

\section*{Proof for Theorem \ref{THM:calibration}}

\begin{proof}
We start with condition (1). From Lemma \ref{LEM:AFFINE},

The above further derives as


Denote by  we have 

Then

Further by our conditions we know

Therefore we have proved

Since  is calibrated, and according to Proposition \ref{prop:alpha} and Theorem \ref{THM:EQUAL}:

Therefore , where  is the calibration transformation function for . It's straight-forward to verify that  satisfies the conditions in Definition \ref{def:cc}, when  satisfied it,  and . We conclude the proof.

Now we check condition (2). 
Denote  (marginal distribution of the noisy label), where , then we have :

 encodes the expectation of the peer term: due to the random sampling of , each  the same chance  being paired with other samples. Regardless of the realization of , the two terms are exactly one  and one  - this is due to the independence between  and .

Let , we have

When

we also know that

This is because

and

From  we obtain

But when  and  are constants that are independent of , we can further denote

That is . Therefore proving calibration for  is equivalent with proving the calibration property for .

We now introduce a theorem:
\begin{theorem}[Theorem 6, \citep{bartlett2006convexity}]
    Let  be convex. Then  is classification-calibrated if and only if it is differentiable at  and .
\end{theorem}
We now show that  is convex:

when . The last inequality is due to the fact that  is convex.

Secondly we show the first derivative of  is negative at : :

Recall that
. Plug into to Eqn. (\ref{eqn:varder}) we have

Since  and  (due to calibration property of , Theorem 6 of \cite{bartlett2006convexity}), we proved that . Then based on Theorem 6 of \cite{bartlett2006convexity}, we know  is classification calibrated.
\end{proof}



\section*{Proof for Theorem \ref{THM:GEN}}


\begin{proof}

We first prove the following Rademacher complexity bound:
 \begin{lemma}\label{LEM:RAD}
 Let  denote the Rademacher complexity of .  denote the Lipschitz constant of . Then with probability at least ,  \end{lemma}
Note we also have the following :

Then apply the calibration condition we have

with probability at least .
\end{proof}
\section*{Proof for Lemma \ref{LEM:RAD}}

\begin{proof}
 Define  (marginal distribution of the noisy label), where ; and
define the following loss function:

Due to the random sampling of  for the peer term, we have

In above,   encodes the expectation of the peer term (similar to the arguments in Theorem 6) each  has  chance being paired with each of the training samples - so the expected number of count is 1. Regardless of , the two terms are exactly one  and one  - this is due to the independence between  and .

Then via Hoeffding inequality, with probability at least  (over randomness of ), 

 denote the upper and lower bound of  respectively. Further we know that 




Via Rademacher bound on the maximal deviation we have with probability at least 

Since  is -Lipschitz, due to the fact that   is linear in 
,  is -Lipschitz. Based on the Lipschitz composition of Rademacher averages, we have

Therefore, via union bound (events in Eqn. (\ref{eqn:samplemean2}) and Eqn. (\ref{eqn:maxf})), we know with probability at least :

In above  because  and  share the same expected risk over  by construction.
 Plug in the fact that
   is linear in :
 
 and an easy consequence that

Let , we conclude the proof.

\end{proof}

\section*{Proof for Lemma \ref{LEM:CONVEX}}

\begin{proof}
This was proved in the proof for Theorem \ref{THM:calibration}, when proving the classification calibration property of  under condition (2).
\end{proof}

\section*{Experiment}

\subsection*{Implementation Details}
On each benchmark, we use the same hyper-parameters for all  neural network based methods.
For C-SVM, we fix one of the weights to 1, and tune the other. For PAM, we tune the margin.

\subsection*{Results}


\begin{table}[ht]
\small
\centering
\begin{tabular}{|c|c|c|c|c|c|c|c|c|c|c|c|c|c|}


\hline
\multicolumn{2}{|c|}{Task}  & \multicolumn{6}{c|}{With Prior Equalization }          & \multicolumn{6}{c|}{Without Prior Equalization }       \\ \hline
 &  & Peer  & Surr & \rev{Symm} & \rev{DMI}   & NN    & C-SVM & Peer  & Surr & \rev{Symm} & \rev{DMI}   & NN    & C-SVM \\ \hline\hline
               & 0.1, 0.3   & \textbf{0.977} & \textbf{0.968}     & \textbf{0.969}     & \textbf{0.974} & \textbf{0.964} & \textbf{0.966}
               & \textbf{0.977} & \textbf{0.968}     & \textbf{0.969}     & \textbf{0.974} & \textbf{0.964} & \textbf{0.966} \\
               & 0.2, 0.2   & \textbf{0.977} & \textbf{0.969}     & \textbf{0.974}     & \textbf{0.976} & \textbf{0.972} & \textbf{0.969}
               & \textbf{0.977} & \textbf{0.969}     & \textbf{0.974}     & \textbf{0.976} & \textbf{0.972} & \textbf{0.969} \\
Twonorm        & 0.1, 0.4   & \textbf{0.976} & \textbf{0.964}     & \textbf{0.956}     & \textbf{0.974} & 0.911 & 0.95
               & \textbf{0.976} & \textbf{0.964}     & 0.956     & \textbf{0.974} & 0.911 & 0.95  \\
(20,3700,3700) & 0.2, 0.4   & \textbf{0.976} & 0.919     & \textbf{0.959}     & \textbf{0.966} & 0.911 & 0.935
               & \textbf{0.976} & 0.919     & \textbf{0.959}     & \textbf{0.966} & 0.911 & 0.935 \\
               & 0.4, 0.4   & \textbf{0.973} & 0.934     & \textbf{0.958}     & 0.936 & 0.883 & 0.875
               & \textbf{0.973} & 0.934     & \textbf{0.958}     & 0.936 & 0.883 & 0.875 \\ \hline
               & 0.1, 0.3   & \textbf{0.919} & 0.878     & 0.851     & 0.875 & 0.811 & \textbf{0.928}
               & \textbf{0.925} & 0.885     & 0.868     & 0.889 & 0.809 & \textbf{0.933} \\
               & 0.2, 0.2   & \textbf{0.918} & 0.874     & 0.879     & 0.888 & 0.819 & \textbf{0.931}
               & \textbf{0.927} & 0.876     & 0.906     & 0.885 & 0.812 & \textbf{0.941} \\
Splice         & 0.1, 0.4   & \textbf{0.914} & 0.86      & 0.757     & 0.842 & 0.743 & 0.891 
               & \textbf{0.925} & 0.862     & 0.777     & 0.852 & 0.754 & 0.898 \\
(60,1527,1648) & 0.2, 0.4   & \textbf{0.901} & 0.832     & 0.757     & 0.801 & 0.714 & 0.807 
               & \textbf{0.912} & 0.84      & 0.782     & 0.81  & 0.725 & 0.824 \\
               & 0.4, 0.4   & \textbf{0.819} & 0.754     & 0.657     & 0.66  & 0.626 & 0.767 
               & \textbf{0.822} & 0.755     & 0.674     & 0.647 & 0.601 & 0.76  \\ \hline
               & 0.1, 0.3   & \textbf{0.833} & 0.78      & 0.777     & 0.797 & 0.756 & 0.753 
               & \textbf{0.856} & 0.802     & 0.803     & 0.83  & 0.75  & 0.788 \\ 
               & 0.2, 0.2   & \textbf{0.821} & 0.762     & 0.795     & \textbf{0.801} & 0.75  & 0.717 
               & \textbf{0.856} & 0.813     & 0.793     & 0.826 & 0.769 & 0.796 \\
Heart          & 0.1, 0.4   & \textbf{0.827} & 0.777     & 0.714     & 0.779 & 0.717 & 0.744 
               & \textbf{0.859} & 0.815     & 0.725     & 0.814 & 0.723 & 0.677 \\
(13,165,138)   & 0.2, 0.4   & 0.812 & 0.768     & 0.717     & 0.788 & 0.679 & 0.714 
               & \textbf{0.856} & 0.758     & 0.725     & 0.797 & 0.693 & 0.704 \\
               & 0.4, 0.4   & \textbf{0.75}  & 0.729     & 0.654     & 0.69  & 0.595 & 0.688 
               & \textbf{0.785} & 0.728     & 0.686     & 0.711 & 0.554 & 0.698 \\ \hline
               & 0.1, 0.3   & \textbf{0.745} & 0.707     & 0.674     & 0.72  & 0.667 & 0.67  
               & \textbf{0.778} & 0.75      & 0.738     & 0.729 & 0.727 & 0.726 \\ 
               & 0.2, 0.2   & \textbf{0.755} & 0.708     & 0.72      & 0.729 & 0.671 & \textbf{0.745}
               & \textbf{0.759} & 0.736     & 0.753     & \textbf{0.743} & 0.706 & \textbf{0.759} \\
Diabetes       & 0.1, 0.4   & \textbf{0.745} & 0.682     & 0.612     & 0.701 & 0.627 & 0.568 
               & \textbf{0.777} & 0.724     & 0.694     & 0.713 & 0.71  & 0.688 \\
(8,268,500)    & 0.2, 0.4   & \textbf{0.755} & 0.681     & 0.634     & 0.682 & 0.596 & 0.59  
               & \textbf{0.739} & 0.705     & 0.695     & 0.707 & 0.672 & 0.7   \\
               & 0.4, 0.4   & \textbf{0.719} & 0.645     & 0.619     & 0.637 & 0.551 & 0.654 
               & 0.651 & \textbf{0.685}     & 0.68      & 0.633 & 0.583 & \textbf{0.702} \\ \hline
               & 0.1, 0.3   & \textbf{0.639} & 0.563     & 0.507     & 0.529 & 0.519 & 0.529 
               & \textbf{0.727} & 0.645     & \textbf{0.709}     & 0.666 & 0.648 & 0.698 \\ 
               & 0.2, 0.2   & \textbf{0.659} & 0.606     & 0.537     & 0.548 & 0.534 & 0.615 
               & \textbf{0.698} & 0.661     & 0.655     & 0.627 & 0.623 & \textbf{0.695} \\
Breast         & 0.1, 0.4   & \textbf{0.587} & \textbf{0.577}     & 0.504     & 0.504 & 0.519 & 0.553 
               & \textbf{0.735} & 0.654     & 0.685     & 0.621 & 0.66  & 0.698 \\
(9,85,201)     & 0.2, 0.4   & \textbf{0.63}  & 0.534     & 0.482     & 0.496 & 0.538 & 0.538 
               & \textbf{0.73}  & 0.674     & 0.666     & 0.58  & 0.672 & 0.698 \\
               & 0.4, 0.4   & \textbf{0.596} & 0.519     & 0.504     & 0.526 & 0.471 & 0.51  
               & 0.677 & 0.628     & 0.545     & 0.537 & 0.529 & \textbf{0.698} \\ \hline
               & 0.1, 0.3   & \textbf{0.928} & \textbf{0.922}     & \textbf{0.924}     & \textbf{0.934} & 0.873 & \textbf{0.924} 
               & \textbf{0.956} & \textbf{0.949}     & \textbf{0.943}     & \textbf{0.954} & 0.92  & \textbf{0.943} \\ 
               & 0.1, 0.4   & \textbf{0.932} & \textbf{0.938}     & \textbf{0.937}     & \textbf{0.944} & 0.83  & 0.85  
               & \textbf{0.951} & 0.929     & \textbf{0.946}     & \textbf{0.941} & 0.898 & 0.929 \\
Breast         & 0.2, 0.2   & 0.928 & 0.904     & 0.835     & 0.897 & 0.887 & \textbf{0.961} 
               & \textbf{0.952} & \textbf{0.952}     & 0.897     & \textbf{0.942} & \textbf{0.955} & \textbf{0.946} \\
(30,212,357)   & 0.2, 0.4   & \textbf{0.93}  & 0.885     & 0.844     & 0.89  & 0.844 & 0.865 
               & \textbf{0.933} & 0.898     & 0.898     & \textbf{0.918} & 0.831 & 0.862 \\
               & 0.4, 0.4   & \textbf{0.928} & 0.867     & 0.819     & 0.746 & 0.824 & 0.855 
               & \textbf{0.908} & 0.839     & 0.817     & 0.795 & 0.673 & 0.866 \\ \hline
               & 0.1, 0.3   & \textbf{0.701} & 0.624     & 0.614     & 0.637 & 0.581 & 0.611 
               & \textbf{0.68}  & \textbf{0.693}     & 0.603     & 0.605 & 0.6   & 0.671 \\ 
               & 0.2, 0.2   & \textbf{0.689} & 0.65      & 0.647     & 0.623 & 0.611 & 0.664 
               & 0.702 & 0.693     & 0.704     & 0.62  & 0.6   & \textbf{0.738} \\
German         & 0.1, 0.4   & \textbf{0.696} & 0.642     & 0.587     & 0.63  & 0.562 & 0.55  
               & \textbf{0.667} & \textbf{0.693}     & 0.54      & 0.594 & 0.54  & 0.553 \\
(23,300,700)   & 0.2, 0.4   & \textbf{0.664} & 0.59      & 0.6       & 0.618 & 0.572 & 0.469 
               & \textbf{0.676} & \textbf{0.681}     & 0.537     & 0.573 & 0.535 & 0.581 \\
               & 0.4, 0.4   & \textbf{0.606} & 0.55      & 0.573     & 0.573 & 0.556 & 0.572 
               & 0.654 & 0.632     & 0.549     & 0.611 & 0.553 & \textbf{0.696} \\ \hline
               & 0.1, 0.3   & \textbf{0.89}  & \textbf{0.895}     & \textbf{0.892}     & 0.856 & 0.868 & 0.862 
               & \textbf{0.893} & \textbf{0.898}     & \textbf{0.883}     & 0.785 & 0.863 & \textbf{0.878} \\ 
               & 0.2, 0.2   & \textbf{0.883} & \textbf{0.899}     & \textbf{0.9}       & 0.861 & \textbf{0.894} & \textbf{0.886} 
               & \textbf{0.901} & \textbf{0.899}     & \textbf{0.894}     & 0.792 & \textbf{0.898} & \textbf{0.897} \\
Waveform       & 0.1, 0.4   & \textbf{0.884} & \textbf{0.893}     & 0.762     & 0.856 & 0.771 & 0.804 
               & \textbf{0.888} & \textbf{0.894}     & 0.703     & 0.778 & 0.821 & 0.821 \\
(21,1647,3353) & 0.2, 0.4   & \textbf{0.881} & \textbf{0.89}      & 0.828     & 0.835 & 0.81  & 0.795 
               & \textbf{0.884} & \textbf{0.884}     & 0.745     & 0.761 & 0.837 & 0.837 \\
               & 0.4, 0.4   & \textbf{0.87}  & \textbf{0.866}     & \textbf{0.867}     & 0.773 & 0.835 & 0.776 
               & \textbf{0.853} & \textbf{0.852}     & \textbf{0.852}     & 0.672 & 0.828 & \textbf{0.848} \\ \hline
               & 0.1, 0.3   & \textbf{0.906} & \textbf{0.9}       & 0.89      & 0.87  & \textbf{0.909} & 0.881 
               & \textbf{0.943} & 0.909     & 0.897     & 0.811 & \textbf{0.93}  & \textbf{0.924} \\ 
               & 0.2, 0.2   & \textbf{0.913} & \textbf{0.894}     & \textbf{0.907}     & \textbf{0.897} & \textbf{0.899} & \textbf{0.918 }
               & 0.905 & 0.905     & 0.905     & 0.91  & \textbf{0.936} & \textbf{0.936} \\
Thyroid        & 0.1, 0.4   & \textbf{0.875} & \textbf{0.862}     & 0.834     & 0.784 & \textbf{0.88}  & \textbf{0.869 }
               & 0.902 & \textbf{0.924}     & 0.856     & 0.75  & \textbf{0.919} & \textbf{0.917} \\
(5,65,150)     & 0.2, 0.4   & \textbf{0.863} & \textbf{0.862}     & \textbf{0.85}      & 0.784 & 0.822 & 0.781 
               & \textbf{0.905} & 0.898     & 0.865     & 0.759 & 0.881 & \textbf{0.92}  \\
               & 0.4, 0.4   & 0.762 & 0.738     & \textbf{0.859}     & 0.788 & 0.764 & 0.781 
               & 0.769 & 0.818     & \textbf{0.876}     & 0.738 & 0.738 & 0.837 \\ \hline
               & 0.1, 0.3   & 0.856 & 0.875     & 0.843     & \textbf{0.896} & 0.866 & \textbf{0.892} 
               & 0.796 & 0.835     & \textbf{0.903}     & 0.896 & 0.878 & \textbf{0.892} \\ 
               & 0.2, 0.2   & \textbf{0.9}   & 0.835     & \textbf{0.911}     & 0.894 & \textbf{0.908} & \textbf{0.912} 
               & \textbf{0.931} & 0.896     & 0.917     & 0.883 & \textbf{0.934} & 0.908 \\
Image          & 0.1, 0.4   & 0.723 & 0.841     & 0.705     & \textbf{0.881} & 0.799 & 0.785 
               & 0.717 & 0.806     & 0.679     & \textbf{0.888} & 0.825 & 0.808 \\
(18,1320,990)  & 0.2, 0.4   & 0.836 & \textbf{0.862}     & 0.719     & \textbf{0.845} & 0.832 & 0.802 
               & 0.672 & 0.755     & 0.722     & \textbf{0.86}  & 0.599 & 0.825 \\
               & 0.4, 0.4   & 0.741 & 0.72      & 0.788     & 0.763 & 0.732 & \textbf{0.834} 
               & 0.806 & 0.803     & 0.823     & 0.762 & 0.8   & \textbf{0.86}  \\ \hline
\end{tabular}
\caption{Experiment Results on 10 UCI Benchmarks. Entries within 2\% from the best in each row are in bold. \rev{Surr: surrogate loss method \citep{natarajan2013learning}; DMI: \citep{xu2019l_dmi}; Symm: symmetric loss method \citep{ghosh2015making}.} All method-specific parameters are estimated through cross-validation. The proposed method (Peer) are competitive across all the datasets. Neural-network-based methods (Peer, Surrogate, NN, \rev{Symmetric, DMI}) use the same hyper-parameters. All the results are averaged across 8 random seeds.}
\label{tab:uci}
\end{table}

The full experiment results are shown in Table.\ref{tab:uci}. \textit{Equalized Prior} indicates that in the corresponding experiments, we resample to make sure  and we fix  in these experiments. Our method is competitive in all the datasets and even able to outperform the surrogate loss method with access to the true noise rates in most of them. C-SVM is also robust when noise rates are symmetric, and is competitive in 8 datasets.

From Figure \ref{fig:test}, we can see our peer loss can prevent over-fitting, which is also part of the reason of its achieved high robustness across different datasets and noise rates.

\begin{figure}
    \centering
    \subfigure[Twonorm (, )]{\includegraphics[width=0.4\textwidth]{figures/twonorm.pdf}}
    \subfigure[Splice (, )]{\includegraphics[width=0.4\textwidth]{figures/splice.pdf}}
    \subfigure[Heart (, )]{\includegraphics[width=0.4\textwidth]{figures/heart.pdf}}
    \subfigure[Breast (, )]{\includegraphics[width=0.4\textwidth]{figures/breast.pdf}}
    \caption{Accuracy on test set during training}
    \label{fig:test}
\end{figure}


\subsection*{2D visualization of decision boundary}



\begin{figure}[!ht]
\centering
\includegraphics[width=0.25\textwidth]{figures/bcewithlogits_clean.png}\hspace{-0.1in}
\includegraphics[width=0.25\textwidth]{figures/bcewithlogits_random-0_2.png}\hspace{-0.1in}
\includegraphics[width=0.25\textwidth]{figures/bcewithlogits_random-0_4.png}\hspace{-0.1in}
\includegraphics[width=0.25\linewidth]{figures/bcewithlogits_random-2-3.png}
\caption{Decision boundary for cross entropy trained on clean and noisy data (Left:  trained on noisy labels, . Middle: trained on noisy labels, . Right: asymmetric noise  ).}\label{CE:db:clean}
\end{figure}

\begin{figure}[!ht]
\centering
\includegraphics[width=0.3\textwidth]{figures/bcewithlogits_peer_random-0_2.png}\hspace{-0.15in}
\includegraphics[width=0.3\textwidth]{figures/bcewithlogits_peer_random-0_4.png}\hspace{-0.15in}
\includegraphics[width=0.3\linewidth]{figures/bcewithlogits_peer_random-2-3.png}
\caption{Decision boundary for peer loss. Left: . Middle: . Right: asymmetric noise } \end{figure}


%
