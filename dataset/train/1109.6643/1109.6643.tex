\documentclass[11pt,a4paper]{article}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{amsfonts}
\usepackage[vlined,ruled,linesnumbered]{algorithm2e}
\usepackage[pdftex]{graphicx}
\usepackage{amsthm}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{url}
\usepackage{cite}
\usepackage{booktabs}
\usepackage{hyperref}
\usepackage{mathrsfs}
\usepackage[vmargin=3cm, hmargin=3cm]{geometry}
\usepackage{paralist}

\usepackage{microtype}
\setlength{\emergencystretch}{2em}

\DeclareMathOperator{\rand}{rand}
\DeclareMathOperator{\hit}{hit}
\DeclareMathOperator{\bel}{BEL}
\DeclareMathOperator{\rel}{REL}
\DeclareMathOperator{\poly}{poly}
\DeclareMathOperator{\E}{\mathbb{E}}
\DeclareMathOperator{\Pb}{Pr}
\DeclareMathOperator{\der}{d\!}
\DeclareMathOperator{\ic}{IN}
\DeclareMathOperator{\is}{IS}
\DeclareMathOperator{\oc}{oc}
\DeclareMathOperator{\ms}{ms}
\DeclareMathOperator{\amis}{AMIS}
\DeclareMathOperator{\miss}{MISS}
\DeclareMathOperator{\ax}{ACCESSES}
\DeclareMathOperator{\out}{OUT}
\DeclareMathOperator{\ev}{EV}
\DeclareMathOperator{\rp}{RP}
\DeclareMathOperator{\lru}{LRU}
\DeclareMathOperator{\mru}{MRU}
\DeclareMathOperator{\opt}{OPT}
\DeclareMathOperator{\T}{T}
\DeclareMathOperator{\pol}{POL}
\DeclareMathOperator{\lpr}{LPR}
\DeclareMathOperator{\kl}{K-L}
\DeclareMathOperator{\har}{H}
\DeclareMathOperator{\mf}{\enspace .}
\DeclareMathOperator{\mc}{\enspace ,}
\DeclareMathOperator{\nat}{_{\mathbb{Z}}}
\DeclareMathOperator{\rot}{rot}
\DeclareMathOperator{\rotz}{ROT-ZERO}
\newcommand{\de}{\textrm{d}}
\newcommand{\deq}{\mathrel{\mathop:}=}
\newcommand{\eye}{\mathbb{I}}
\newcommand{\Z}{\mathbb{Z}}
\newcommand{\Pav}{{\sc Aver}}
\newcommand{\Pscal}{{\sc Scal}}
\newcommand{\tone}{}
\newcommand{\ttwo}{'}
\newcommand{\pin}{p^{in}}
\newcommand{\tpin}{\tilde p^{in}}
\newcommand{\apin}{\bar p^{in}}
\newcommand{\pev}{p^{ev}}
\newcommand{\phit}{\Pb^{hit}}
\newcommand{\aphit}{\bar \Pb^{hit}}
\newcommand{\apev}{\bar p^{ev}}
\newcommand{\reals}{\mathbb{R}}
\newcommand{\comment}[1]{}

\newtheorem{theorem}{Theorem}
\newtheorem{conjecture}{Conjecture}
\newtheorem{corollary}{Corollary}
\newtheorem{proposition}{Proposition}
\newtheorem{lemma}{Lemma}
\newtheorem{claim}{Claim}

\theoremstyle{definition}
\newtheorem{definition}{Definition}
\newtheorem{remark}{Remark}
\newtheorem{exercise}{Exercise}

\theoremstyle{remark}
\newtheorem*{solution}{Solution}
\def\vec#1{\mathchoice{\mbox{\boldmath}}
  {\mbox{\boldmath}}
  {\mbox{\boldmath}}
  {\mbox{\boldmath}}}

\newcounter{romen} \newenvironment{romenum}{\setcounter{romen}{1}\def\item{
    (\roman{romen})\ \stepcounter{romen}}}{\newline}




\title{Optimal Eviction Policies for Stochastic Address
  Traces\footnote{Published in Theoretical Computer Science, 2013:
    \url{http://dx.doi.org/10.1016/j.tcs.2013.01.016}}}




\author{Gianfranco Bilardi\thanks{\texttt{bilardi@dei.unipd.it}} \and Francesco
  Versaci\thanks{\texttt{versaci@par.tuwien.ac.at}. {Currently at Vienna
      University of Technology. Supported by PAT-INFN Project
      \emph{AuroraScience}, by MIUR-PRIN Project \emph{AlgoDEEP}, and by the
      University of Padova Projects \emph{STPD08JA32} and \emph{CPDA099949}.}}}
\date{University of Padova}

\begin{document}
\maketitle

\begin{abstract}
  The eviction problem for memory hierarchies is studied for the
  Hidden Markov Reference Model (HMRM) of the memory trace,
  showing how miss minimization can be naturally formulated in
  the optimal control setting.
    In addition to the traditional version assuming a buffer of fixed
  capacity, a relaxed version is also considered, in which buffer
  occupancy can vary and its average is constrained.
    Resorting to multiobjective optimization, viewing occupancy as a
  cost rather than as a constraint, the optimal eviction policy is
  obtained by composing solutions for the individual addressable
  items.

  This approach is then specialized to the Least Recently Used Stack Model
  (LRUSM), a type of HMRM often considered for traces, which includes 
  parameters, where  is the size of the virtual space. A gain optimal policy
  for any target average occupancy is obtained which (i) is computable in time
   from the model parameters, (ii) is optimal also for the fixed capacity
  case, and (iii) is characterized in terms of priorities, with the name of
  Least Profit Rate (LPR) policy. An  upper bound (being  the
  buffer capacity) is derived for the ratio between the expected miss rate of
  LPR and that of OPT, the optimal off-line policy; the upper bound is tightened
  to , under reasonable constraints on the LRUSM parameters. Using the
  stack-distance framework, an algorithm is developed to compute the number of
  misses incurred by LPR on a given input trace, simultaneously for all buffer
  capacities, in time  per access.

  Finally, some results are provided for miss minimization over a
  finite horizon and over an infinite horizon under bias optimality,
  a criterion more stringent than gain optimality.

\end{abstract}

\vspace{5mm}
\noindent{\bf Keywords}: Eviction policies, Paging, Online problems,
Algorithms and data structures, Markov chains, Optimal control,
Multiobjective optimization.
 





\section{Introduction to Eviction Policies for the Memory Hierarchy}
\label{chap:an-optimal-control}


The storage of most computer systems is organized as a hierarchy of
levels (currently, half a dozen), for technological and economical
reasons \cite{HennessyP06} as well as due to fundamental physical
constraints \cite{BilardiP95}. Memory hierarchies have been
investigated extensively, in terms of hardware organization
\cite{Fotheringham61,Przybylski90,HennessyP06}, operating systems
\cite{SilberschatzGG05}, compiler optimization
\cite{AllenK02,Wolfe95,GuoGP03}, models of computation
\cite{Savage97}, and algorithm design \cite{AggarwalACS87}.  A central
issue is the decision of which data to keep in which level.  It is
customary to focus on two levels (see Fig.~\ref{two-lev-hier}),
respectively called here the \emph{buffer} and the \emph{backing
  storage}, the extension to multiple levels being generally
straightforward. (We adopt the neutral names used in the seminal paper
of Mattson et al.\ \cite{MattsonGST70}, since the concepts introduced
have application at each level of the memory hierarchy: register
allocation, CPU caching, memory paging, web caching, etc.) We assume
that an engine generates a sequence of access requests  for \emph{items} (equally sized blocks of data)
stored in the hierarchy.  A request is called a \emph{hit} if the
requested item is in the buffer and a \emph{miss} otherwise. Upon a
miss, the item must be brought into the buffer, a costly operation.
If the buffer is full, the requested item will replace another
item. We are interested in an \emph{eviction policy} that selects the
items to be replaced so as to minimize subsequent misses.

The \emph{MIN policy} of Belady \cite{Belady66} and the \emph{OPT
  policy}\footnotemark\ of Mattson, Gecsei, Sluts, and Traiger
\cite{MattsonGST70}, minimize the number of misses in an off-line
setting. \footnotetext{OPT: Upon a miss, if the buffer contains items that will
  not be accessed in the future then evict (any) one of them, else evict the
  (unique) item whose next access is furthest in the future.} Since, in
practical situations, the address trace unfolds with the computation, eviction
decisions must be made \emph{on-line}.  Dozens of on-line policies have been
proposed and implemented in hardware or within operating systems.
Somewhat schematically, we can say that implemented policies have evolved mostly
experimentally, by benchmarking plausible proposals against relevant workloads
\cite{Przybylski90}.  Most of these policies are variants of the \emph{Least
  Recently Used} (LRU) policy. Departure from pure LRU is motivated to a large
extent by its high implementation cost.  However, several authors have also
explored variants of LRU that incur fewer misses, at least on some
workloads~\cite{MegiddoM04}.
\begin{figure}
  \centering  \includegraphics[width=2.3cm]{images/two-level-hierarchy.pdf}
  \caption{Two-level memory hierarchy.}
  \label{two-lev-hier}
\end{figure}

Theoretical investigations have focused mostly on two objectives: (a) to
``explain'' the practical success of LRU-like policies and (b) to explore the
existence of better policies.  One major question is how to model the input
traces (i.e., the lists of requested memory references). An interesting
perspective, proposed by Koutsoupias and Papadimitriou \cite{KoutsoupiasP00}, is
to model traces by a class of stochastic processes, all to be dealt with by the
same policy.  For a given stochastic model, two metrics help assess the quality
of a policy: (i) the expected number of misses and (ii) its ratio with the
expected number of misses incurred by OPT, called the \emph{competitive ratio}.
The competitive ratio of a policy with respect to a class of stochastic
processes is defined in a worst-case sense, maximizing over the class.

Competitive analysis was proposed by Sleator and Tarjan \cite{SleatorT85} for
the class of all possible traces (all stochastic processes), for which they
showed that the competitive ratio of any on-line policy is at least the buffer
capacity , a value actually achieved by, e.g., LRU and FIFO. While
theoretically interesting, this results shed little light on what is
experimentally known. For example, if we restrict the possible traces to the
ones which actually emerge in practical applications, the miss ratio between LRU
and OPT is much smaller than , being typically around 2 and seldom exceeding
4.
Borodin et al.\ \cite{BorodinIRS95} restrict the class of possible
traces to be consistent with an underlying ``access graph'' that
models the program locality (nodes correspond to items and legal
traces correspond to walks); a heuristic policy based on this model has
been developed by Fiat and Rosen \cite{FiatR97} and has been shown to
perform better than LRU, relative to some benchmarks.

Albers et al.\ \cite{AlbersFG05} propose a trace restriction based on
Denning's working set concept \cite{Denning68}: for a given function
, the (average or maximum) number of distinct items referenced
in  consecutive steps is at most . LRU is proved to be
optimal in both the average and maximum cases.

Koutsoupias and Papadimitriou \cite{KoutsoupiasP00} have considered
the class  () of stochastic
processes such that, given any prefix of the trace, the probability to
be accessed next is at most  for any item.  A
combinatorially rich development establishes that LRU achieves minimum
competitive ratio, for each value of .  A careful analysis
of how the competitive ratio depends upon both  and  has
been provided by Young \cite{Young98}: in particular, the competitive
ratio increases with . Qualitatively speaking, buffering is
more efficient exactly when the items in the buffer are more likely to
be referenced than those outside the buffer. Hence, for traces where
LRU (or any policy) exhibits good performance (that is, few misses),
 must be correspondingly high. Then, the 
competitive ratio is also high, unlike what observed in practice.  For
a more quantitative appraisal of the issue, consider that, at any level
of the memory hierarchy of real systems, the average miss ratio is
typically below 1/4 (even well below 1\% in main memory). Let then
 be the buffer capacity at which the miss rate would be
1/2. It is easy to see that it must be .
The actual buffer capacity  is typically considerably larger than
, say , by the rule of thumb that
quadrupling the cache capacity halves the miss ratio
\cite{Przybylski90}.  Then, . By the bounds of
Young \cite{Young98}, the  competitive ratio of LRU
is at least , which is not much more informative than the value
 of \cite{SleatorT85}.

To ``explain'' both the low miss rate and the low competitive ratio of
LRU in practical cases, the approach of \cite{KoutsoupiasP00} requires
some restriction to the class of stochastic processes, in order to
capture temporal locality of the reference trace, while essentially
assigning low the probability to those traces for which OPT vastly
outperforms LRU.  The model and results of Becchetti
\cite{Becchetti04} can be viewed as an exploration of this direction.

Following what could be viewed as an extreme case of the approach
outlined above, a number of studies have focused on specific
stochastic processes (the class is a singleton), with the objective of
developing (individually) optimal policies for such processes.  In
\cite{FranaszekW74}, the address trace 
is taken to be a sequence of mutually independent random variables, a
scenario known as the Independent Reference Model (IRM).  While
attractive for its simplicity, the IRM does not capture the
cornerstone property that memory hierarchies relay upon: the temporal
locality of references.  To avoid this drawback, the LRU-Stack Model
(LRUSM) of the trace \cite{OdenS72,SpirnD72} has been widely
considered in the literature
\cite{TurnerS77,EffelsbergH84,KobayashiM89} and is the focus of much
attention in this paper.  Here, the trace is statistically
characterized by the probability  of accessing the -th most
recently referenced item.  The values of  for different accesses
are assumed to be statistically independent. Throughout, we assume
that the items being referenced belong to a finite virtual space of
size .  If  is monotonically decreasing, LRU is optimal
\cite{SpirnD72} (for an infinite trace); in general, the optimal
policy varies with  and can differ from LRU, as shown by Woof,
Fernandez and Lang\cite{WoodFL77,WoodFL83}. Smaragdakis, Kaplan, and
Wilson\cite{SmaragdakisKW99,SmaragdakisKW03} introduced the EELRU
policy as a heuristic inspired by the LRUSM. The model of Becchetti
\cite{Becchetti04} mentioned above is similar to LRUSM,  essentially
dropping the assumption of independence, while restricting the form of
the conditional distribution of accessing the -th most recent item,
given the value of the past trace. LRU is compared to OPT under this
model.

A different generalization of the IRM model is the Markov Reference
Model (MRM), already suggested by \cite{MattsonGST70}, where the
address trace is a finite Markov chain.  A wealth of results are
obtained by Karlin, Phillips, and Raghavan \cite{KarlinPR00} for MRM,
including the Commute Algorithm, a remarkable policy computable from
the transition probabilities of the chain in polynomial time, whose
expected miss rate is within a constant factor of optimum. We
underscore that MRM and LRUSM are substantially different models; in
general, while the MRM trace is itself a Markov process with 
states, the LRUSM trace is a function of a Markov process with 
states.

\paragraph{Paper outline} In this work, we further the study of the
LRUSM, deriving new results and strengthening its understanding. Some
methodological aspects of our investigation, however, can be of
interest for a wider class of models of the reference trace, hence
they will be presented in a more general context.

A first methodological aspect we explore is the possibility as well as
the fruitfulness of casting miss minimization as a problem of optimal
control theory (or, equivalently, as a Markov Decision Problem
\cite{LewisP02}).  In Section \ref{sec:ocfr}, we show as this is
possible whenever the trace is a hidden Markov process, a scenario
which we call the Hidden Markov Reference Model (HMRM). The IRM, the
MRM, and the LRUSM are all special cases of the HMRM.  We refer to the
classical optimal control theory framework as presented, for instance,
in the textbook of Bertsekas \cite{Bertsekas00}.  In the dynamical
system to be controlled, the state encodes the content of the buffer
and some information on the past trace.  The disturbance input models
the uncertainty in the address trace, while the control input encodes
the eviction decisions available to the memory manager. The cost per
step is one if a miss is incurred and zero otherwise.  We modify the
standard assumption that the control is a function only of the state
and allow it to depend on the disturbance as well:
.  This modification is necessary since eviction
decisions are actually taken with full knowledge of the current
access.  The Bellman equation characterizing the optimal policies has
to be modified accordingly. The technicalities of this adaptation are
dealt with in the Appendix.

A second methodological aspect we explore is a generalization of the
buffer management problem where rather than imposing the capacity as a
fixed constraint, we let the number of buffer positions vary
dynamically, under the control of the management policy. The average
buffer occupancy becomes a second cost, in addition to the miss rate,
and the tradeoff between the two costs is of interest. This problem
could have practical applications. For example, in a time-shared
environment, processes could be charged for their average use of main
memory and hence be interested in utilizing more memory in phases
where this can result in significant page-fault reduction and less
memory in other phases. In addition, the study of the average
occupancy problem sheds significant light even on the solution of the
fixed capacity problem. In particular, for the LRUSM, an optimal
policy for the case of a fixed buffer can be simply obtained from
optimal policies for the average occupancy case. In Section
\ref{sec:relax-buff-manag}, the average buffer occupancy problem is
studied for the HMRM, exploiting techniques of multi-objective
optimization and optimal control. A key advantage lies in the possibility of composing a
global policy from policies tailored to the individual items in the
virtual space. Furthermore, the approach naturally lends itself to the
efficient management of a buffer shared among different processes.
Throughout this section, the notion of optimality of the policies
under consideration is that of \emph{gain} optimality over an infinite
horizon.

In Section \ref{lrusm}, the framework and the results developed in the
two previous sections are applied to the LRUSM. After reviewing the
LRU stack model, a class of optimal policies is derived, for an
arbitrary distribution , for the average occupancy problem. It is
then shown that this class of policies includes some that use a buffer
of fixed capacity .  More specifically, it is shown that the
minimum miss rate under a constraint on the average occupancy can be
attained with fixed capacity. A buffer of capacity  is optimally
managed by a  policy \cite{WoodFL77,WoodFL83}, which can be
specified by two parameters, denoted as  and .  
policies include, as special cases, LRU (, ) and Most
Recently Used (MRU) (, ). Our derivation of the optimal
policy has a number of advantages. (i) The optimality is established
for the more general setting of average occupancy. (ii) The policy is
naturally described in terms of a system of priorities for the
eviction of items. As a corollary of a result of \cite{MattsonGST70},
it follows that the policy does satisfy the inclusion property: if an
item is in a given buffer, then it is also in all buffers of larger
capacity.  The inclusion property rules out the so-called Belady
anomaly
\cite{BeladyNS69} and enables more efficient algorithms for its
performance evaluation.  (iii) By linking the eviction priorities to
the (planar) convex hull of the Pareto optimal points of the average
occupancy problem and by adapting Graham's scan, an algorithm is
derived for a \emph{linear} time computation of the values  and
 for all relevant values of . (Previously known properties of
the  policy lead to a straightforward cubic algorithm.) (iv)
Finally, the priorities can be shown to correspond to a suitable
notion of profit rate of an item, informally capturing the best
achievable ratio between expected hits and the expected occupancy for
that item, leading to the concept of Least Profit Rate (LPR)
policy. The LPR policy can be defined for models different from the
LRUSM for which, while not necessarily optimal, it may yield a good
heuristic.

In Section~\ref{sec:olol}, we show that the ratio 
between the expected miss rate of the optimal on-line policy, LPR, and
that of OPT is . Moreover, for the class of stack access
distributions  for which the miss rate of LPR is lower bounded by
some constant , we have .

The ability to efficiently compute the number of misses for buffers of
various capacities when adopting a given policy for benchmark traces
is of key interest in the design of hardware as well as software
solutions for memory management
\cite{BilardiEP11,SugumarA93,ThompsonS89}.
In Section~\ref{sec:fast-simul-optim}, we develop an algorithm to compute the
LPR misses for all buffer capacities in time  per access, providing a
rather non trivial generalization of an analogous result for LRU
\cite{BennettK75,AlmasiCP02}.

In the remainder of the paper, we explore alternate notions of
optimality. In Section~\ref{sec:fh}, we consider optimization over a
finite interval, or horizon.  Technically, the optimal control problem
is considerably harder. As an indication, even if the system dynamics,
its cost function, and the statistics of the disturbance are all time
invariant, the optimal control policy is in general time-dependent.
We show that, for any monotonically non increasing stack distribution
, LRU is an optimal policy for any finite horizon, whereas MRU is
optimal if the stack distribution is non decreasing.  While these
results appear symmetrical and highly intuitive, their proofs are
substantially different and all but straightforward.  The standard
approach based on the Bellman equation, which requires ``guessing''
the optimal cost as a function of the initial state, does not seem
applicable, lacking a closed form for such function. We have
circumvented this obstacle by establishing an inductive invariant on
the relative values of the cost for select pairs of states. This
approach may have applicability to other optimal-control problems.
Some of the results are derived for a considerably more general
version of the LRUSM, which does not assume the statistical
independence of stack distances at different steps.

Finally, in Section~\ref{sec:ih}, we take a preliminary look at 
\emph{bias} optimality, a property stronger than \emph{gain} optimality,
but also considerably more difficult to deal with. As an indication of
the obstacles to be faced, we prove that, in some simple cases of
LRUSM, no bias-optimal policy satisfies the useful inclusion property.
We also develop a closed-form solution for the simplest non-trivial
case of buffer capacity, that is, .  The derivation as well as
the results are not completely straightforward, suggesting that the
solution for arbitrary buffer capacity may require considerable
ingenuity.

We conclude the paper with a brief discussion of directions for
further research.

The main notation introduced and used throughout this work is summarized in
Table~\ref{tab:notation}.

\newcommand{\otoprule}{\specialrule{\heavyrulewidth}{.5em}{.5em}}
\begin{table}
  \centering
  \begin{tabular}{lp{.8\textwidth}}
    \toprule
    \textbf{Symbol} & \textbf{Description}\\
    \otoprule
     & The (off-line) optimal replacement policy\\
     & The Least Recently Used replacement policy\\
     & The Least Profit Rate replacement policy\\
     & Size of the high-latency memory\\
     & Size of the low-latency buffer\\
     & Address of the item accessed at time \\
     & The  stack at time  and  stack depth of
    item accessed at time  ()\\
     & Probability of accessing the -th most recently referenced item\\
     & Cumulative probability distribution of : \\
     & Stochastic competitive ratio\\
     & State at time  (dynamical systems)\\
     & Disturbance at time  (dynamical systems)\\
     & Control at time  (dynamical systems)\\
     & State transition (dynamical systems)\\
     & Cost (dynamical systems)\\
     & Optimal cost starting from state  with a time horizon of
     steps (dynamical systems)\\
    \bottomrule
  \end{tabular}
  \caption{Main notation used throughout the paper}
  \label{tab:notation}
\end{table}

\section{Optimal Control Formulation of Eviction for the
Hidden Markov Reference Model}
\label{sec:ocfr}

In the typical problem of optimal control \cite{Bertsekas00}, one is given a
dynamical system described by a state-transition equation of the form
 
where  is the \emph{state} at time , while both  and  are
inputs, with crucially different roles. Input , called the \emph{control},
can be chosen by whoever operates the system.  In contrast input ,
historically called the \emph{disturbance}, is determined by the environment and
modeled as a stochastic process. At each step , a cost is incurred, given by
some function . The objective of optimal control is to find a
\emph{control policy}  so as to minimize the total cost
 
where  is a time interval of interest.  A key premise of most optimal control
theory is the assumption of \emph{past-independent disturbances} (PID): given the
current state , the current disturbance  is statistically independent
of past disturbances .

In this section, we define a dynamical system whose optimal control
corresponds to the minimization of the number of misses when the
reference trace can be expressed as a function  of a
Markov chain  with a finite state space .  We call this
scenario the Hidden Markov Reference Model (HMRM).
In the following we assume the system to be \emph{unichain}, i.e., under any
stationary policy the Markov chain associated with the system evolution has only
a single recurrent class. This hypothesis guarantees that the average cost in
infinite horizon does not depend on the initial state and that there is always a
solution to the Bellman equation (e.g., a Markov chain with two non
communicating classes is not unichain).

To cast eviction as a problem in optimal control, the state of our
dynamical system will model both the Markov chain underlying the trace
and the content of the buffer:

where  is a Boolean vector such that, for ,


Toward formulating the transition function governing the evolution of
, let us first observe that any Markov chain can be written
as

where  is a sequence of equally distributed random variables,
independent of each other and of the initial state  \cite{LevinPW09}.
Furthermore,  is a finite set with .  We take  to
be the ``disturbance'' in (\ref{eqn:xtransition}).  We let the control input
 encode the eviction decisions with  denoting no
eviction (the only admissible control in case of a hit) and  denoting the
eviction of the item  (an admissible control only when a miss occurs and the
item  is in the buffer, i.e., ). We can then write:

where the transition function  is specified as

Finally, we have:

The instantaneous cost function  is simply

Finally, we assume that a policy can set the control  with
knowledge of both the state and the disturbance: .
This requires adaptation of some results derived in the control theory
literature typically assuming .

Consider a policy 
applied to our system during the time interval ,
so that, for  in this interval, we have

We define the cost of , starting from state , with time
horizon  as

where the 's are subject to (\ref{mi-dynamics}) and the expected value
averages over disturbances . For our system, this is the expected number of
misses in  steps. The optimal cost is

The optimal cost satisfies the following dynamic-programming
recurrence (analogous to Eq.~1.6 in Vol.~1 of \cite{Bertsekas00})

where  denotes the set of controls admissible when the state is 
and the disturbance is .  Introducing a vector  whose components
are the values , in some chosen order of the states,
(\ref{beqsys1}) can be concisely rewritten as

where  is the (non-linear) \emph{optimal-cost update operator}.

In applications where the temporal horizon of interest is long and perhaps not
known a priori, one is interested in policies that are optimal over an infinite
horizon; an added benefit is that such policies are provably \emph{stationary},
under very mild conditions.  Usually, the cost defined in (\ref{Jdef}) diverges
as , thus alternate definitions of optimality are
considered \cite{Bertsekas00,LewisP02,ArapostathisBFGM93,blackwell1962discrete},
like gain and bias optimality.
\begin{description}
\item[Gain Optimality] refers to a policy  that achieves the lowest \emph{
    average cost} (that can be shown to be independent of ):  .
\item[Bias Optimality] refers to a policy  that is as good as any other
  stationary policy for  long enough, i.e.,\ . (Note that a bias optimal policy is also gain optimal.)
\end{description}

In this work we mostly concentrate on the standard gain optimality concept
(which corresponds to the miss rate minimization), but we also give some
particular results for the stronger concept of bias optimality in
Section~\ref{sec:ih}.  In Sections~\ref{sec:relax-buff-manag} and \ref{sec:ih}
we will use the classical \emph{Bellman equation}, which characterizes optimal
control policies in infinite horizon as solutions of a fixed point equation
\cite{Bertsekas00}. We show in \ref{sec:bellman-equation} that the result holds
in our model as well:
\begin{proposition}\label{bel}
  Let  be a dynamical system, with state space , whose control 
  can be chosen with knowledge of the disturbance . If
     ,     then  is the \emph{optimal average cost} of  and
   is the vector of the \emph{differential costs} of the
  states, i.e.
  
\end{proposition}
In the rest of the paper devoted to infinite horizon, since the costs will be
independent of the initial state , we will simplify (and abuse a little)
the notation by setting .

\section{The Average Occupancy Eviction Problem}
\label{sec:relax-buff-manag}

The classical form of the eviction problem, as reviewed in the
Introduction, is based on the assumption of a \emph{fixed capacity}
buffer: when the buffer is full, an eviction is required every time a
miss occurs, otherwise no eviction is performed. In this section, we
consider a relaxed version of the eviction problem where the buffer
is of potentially unlimited capacity ( is actually sufficient)
and a variable portion of it can be occupied at different times. The
requirement that the item being referred must be kept in the buffer or
brought in if not already there is retained. However, after an access
(whether a hit or a miss), any item in the buffer, except for the one
just accessed, can be evicted. In this \emph{relaxed buffer
management} scenario, in addition to the miss rate, an interesting
cost metric is the \emph{average occupancy} of the buffer.  We call
average occupancy eviction problem the minimization of the miss
rate, given a target value for the average occupancy. This problem has
direct applications, as mentioned in the Introduction. However, the
study of average occupancy also sheds light on the fixed capacity
version, as we will see in particular in the next section for the
LRUSM.  A key advantage of the average capacity problem is that its
solution can be obtained by combining policies for the individual
items considered in isolation.


\subsection{The Single Item Problem}
\label{sec:one-item-eviction}

In this section we study eviction policies for single items from a
multiobjective perspective \cite{Ehrgott05,Miettinen99}, i.e., we are not
interested in optimizing a single objective, but in obtaining all the ``good''
policies.

When focusing on a single item, say , a first simplification
arises from the fact that the state of the buffer, denoted
, is just a binary variable, set to  when the item is
kept in the buffer and to  otherwise.  One also can restrict
attention to the -\emph{trace} , defined as 
when the item is referenced () and to  otherwise.
Clearly, if the full trace  is a hidden Markov process, so is
also the -trace. However, in some cases, the -trace
can be described with fewer states, forming a set . For
example, the reduction is dramatic for the LRUSM, where  while
, for every item . In general, we can write

Process  is called the \emph{Characteristic Generator}
(CG) of item .  The control input 
determines whether  is evicted from the buffer (),
which is admissible only when the item is in the buffer at time 
() and it is not currently accessed
(). This amounts to specifying the function
 such that

The overall state of the control system is then , evolving as

We are interested into two types of cost: buffer occupancy and misses.
Correspondingly, we introduce two instantaneous cost functions:

Obviously, there is a tradeoff between the two costs, occupancy being
minimized by evicting the item as soon as possible and misses being minimized by
never evicting it. The set of ``good'' solutions to multiobjective optimization
problems is the Pareto set, i.e., the set of all policies whose costs are not
dominated by the costs of other policies (Pareto points are also known as
Efficient Points, EPs).

A peculiarity of multiobjective optimization problems is that, since we are
studying tradeoffs among the costs, sometimes we can usefully introduce
Randomized Mixtures of Policies (RMoPs) to obtain more points in the costs
space. E.g., consider the problem of choosing a route every day from home to
work between two possible routes  and , with costs 
defined by the driving time and gas used. If )\vec J(\mu_2)=(30 \text{ minutes}, 5 \ by choosing
every day with the same probability  or  we have long-run average
costs equal to )x^*=(z^*,1)r_\omega(z^*)=1t_1, t_2, \ldots[t_i+1, t_{i+1}]\mu'\mu''J_{\oc}(\mu')=\eta'J_{\oc}(\mu'')=\eta''C = \gamma \eta' + (1-\gamma) \eta''\gamma \in [0,1]\mu = \rand_\gamma\left(\mu', \mu''\right)\mu\mu'\gamma\mu''1-\gammax^*J_{\ms}(\mu)=\gamma J_{\ms}(\mu') + (1-\gamma) J_{\ms}(\mu'')C\mu_2\mu_3\cal{S}|Z_\omega|\hat{\cal{S}}\cal{S}(J_1,J_2)\cal{S}({\hat J}_1', {\hat J}_2')({\hat J}_1'', {\hat J}_2'')\hat{\cal{S}}0 \leq \gamma \leq 1q=1,2J_q (1+\epsilon) \geq \gamma {\hat J}_q' + (1 - \gamma) {\hat J}_q''\hat{\cal{S}}\hat{\cal{S}}|Z_\omega|(1/\epsilon)\theta \in \left[0, \pi/2\right]\lambda_{\omega,\theta} \in \realsh_{\omega,\theta} : X_\omega
\rightarrow \realsX_\omega = Z_\omega \times \{0,1\}|Z_\omega|\mu_{\omega,\theta}(x_{\omega}, w_{\omega}) =
\arg\min_{u_\omega} \left\{h_{\omega,\theta} \left(f_\omega(x_{\omega},
u_{\omega}, w_{\omega})\right) \right\}\mu_{\omega,\theta}G_{\omega, \theta}J_{\omega,\theta}
=\lambda_{\omega,\theta}J_{\oc,\omega}J_{\ms,\omega}g_{\oc, \omega}g_{\ms, \omega}\omega\mu\muJ_{\oc,\omega}(\mu)J_{\ms,\omega}(\mu)\omega\mu_\omegaJ_{\ms,\omega}(\mu_\omega)J_{\oc,\omega}(\mu_\omega)=J_{\oc,\omega}(\mu)J_{\ms,\omega}(\mu_\omega)=J_{\ms,\omega}(\mu)\mu\mu_\omega\rho_\omega\mu_\omega'\mu_\omega\sum_\omega|Z_\omega|MC\vec J(\mu^1_\omega)=(\eta^1_\omega,\zeta^1_\omega), \, \vec
  J(\mu^2_\omega)=(\eta^2_\omega,\zeta^2_\omega), \, \ldots\eta^i_\omega < \eta^{i+1}_\omega\omega\mu_\omega\forall \omega \; c[\omega] \leftarrow 1 B \leftarrow 1 B<C\displaystyle \phi \leftarrow \arg\max_\omega \left\{
      -\frac{\zeta_\omega^{c[\omega]+1}-{\zeta_\omega^{c[\omega]}}}{\eta_\omega^{c[\omega]+1}
        - {\eta_\omega^{c[\omega]}}}\right\}B \leftarrow B + \eta_\phi^{c[\phi]+1} - {\eta_\phi^{c[\phi]}}c[\phi] \leftarrow c[\phi]+1\forall \omega\not = \phi \quad \mu_\omega \leftarrow
    \mu_\omega^{c[\omega]}  \gamma \leftarrow \text{such that } B-\sum_{\omega \not = \phi} \eta_\omega^{c[\omega]} = \gamma
    \eta_\phi^{c[\phi]-1}+(1-\gamma) \eta_\phi^{c[\phi]}\mu_\phi \leftarrow \rand_\gamma\left(\mu_\phi^{c[\omega]-1},\mu_\phi^{c[\omega]} \right)CC-1 < C' \leq CCniV_ii\pi_i\sum_{i=1}^n \pi_i=1C_ii\sum_{i=1}^n
C_i=CJ_{\ms}i\pi_iV\muB_t^\mu(C)Cta_1,\ldots,a_{t}tC>1B_t^\mu(C-1) \subseteq B_t^\mu(C)\left|B_t^\mu(C)\right| < C\muB_0^\mu(C)1 \leq C \leq V\Lambda^\mu_tCCd_ta_{t+1}tdC<d\Lambda\Lambda=\Lambda^{\lru}\Lambda_{t+1}(1)=a_{t+1}d_td_td_1,d_2, \ldotss(V)\not = 0s(V)=0s(j)ja_1,a_2,
\ldotsd_1,d_2, \ldots\Lambda_0z_t=\Lambda_tw_t=d_ta_{t+1}=r(\Lambda_{t+1})=\Lambda_{t+1}(1)\phi\Lambda_{t+1} = \phi(\Lambda_t,d_t)d_t\Lambda_tu_tb_tb_{t+1}=\phi(b_t,u_t) \kl\klKL1\leq K < C \leq
L \leq Va_{t+1}B_t(C)B_t(C)\LambdaB(C)\kla_{t+1}K=C\forall LK=1L=VCK(C)L(C)\klKV-LC-KL-KK+1L\kl\klsCK(C)L(C)\Theta(V^3)(K,L)C(K,L)sK(C)L(C)\klKLC \in \{1, V\}\omegaz_{\omega,t}Z_\omega=\{1, \ldots, V \}r_\omega(1)=1\forall i \neq 1, \quad r_\omega(i)=0Vx^* \deq (z^* = 1,\beta=1)x^*x^*\ev_ki\leq ki > k\mu\ev_kk+1\muk+1\ev_k\ev_kz_\omegat^j_{j+h}j+hh\geq
  0jhh=0jj+1hjjjj+1j+1t_j^1=1V\ev_kkj>ks(j)\mu_\omegaJ_{\oc}J_{\ms}Vq_1=1 < q_2 < \ldots < q_l=Vk\ev_kq_i<C' \leq
q_{i+1}C'=\gamma' q_i + (1-\gamma')q_{i+1}\gamma' \in (0,1]\ev_{q_i}\ev_{q_{i+1}}\gamma'(1-\gamma')C'sl=Vq_i=isl=2q_1=1q_2=VK'(C)L'(C)\klK=K'(C)L=L'(C)\kl\ev_K\ev_LCMC=C'K=K'L=L'\gamma'=\gammaM=M'\klK=K'(C)L=L'(C)CCK=K'(C)L=L'(C)C \leq VK(C)L(C)sq_1,q_2,
  \ldots, q_l1
  \leq C \leq Vq_i\{(1,0)\} \cup \{(j, S(j))\}_j
  \cup \{(V,0)\}ji\nu[1] \leftarrow 1\quad\pi[1] \leftarrow s(1)\quad\Delta[1] \leftarrow 1\pi[V+1] \leftarrow 0\quad\Delta[V+1] \leftarrow 1j \leftarrow V2\nu[j] \leftarrow j\quad\pi[j] \leftarrow s[j]\Delta[j] \leftarrow 1\quadn \leftarrow \nu[j]+1\pi[j]/\Delta[j] \leq \pi[n]/\Delta[n]\nu[j] \leftarrow \nu[n]\pi[j] \leftarrow \pi[j]+\pi[n]\Delta[j] \leftarrow \Delta[j]+\Delta[n]n \leftarrow \nu[j]+1j \leftarrow 1\quadi \leftarrow 1j \leq Vq_i = \;\nu[j]j \leftarrow \nu[j]+1\quadi \leftarrow i+1j \leftarrow 2j \leq V\xi(j) = \;\pi[j]/\Delta[j]j \leftarrow j+1K(C)=q_i < C \leq q_{i+1}=L(C)i\lprCK(C)L(C)\bar s(i)s\omegai\Lambda(i)=\omega\xi\Lambda(1)\lpri^*CC(q_1,q_2, \ldots, q_l)s\bar
    s(1+q_i,q_{i+1}) > \bar s(1+q_{i+1},q_{i+2})\forall k \in [1+q_i,q_{i+1}]\bar s(1+q_i,k) \leq
    \bar s(1+q_i,q_{i+1}) \leq \bar s(k,q_{i+1})Ci^* = \arg \min_i \max_j
  \bar s(i,j)K+1l\max_j
  \bar s(l,j)< \max_j \bar s(i^*,j)L+1L\omegat\muz\omega\mu\omega\pi^{\mu}\omega\omegat+\Delta\Delta>0t\omegat+\Delta\E^{\mu}[\Delta]\omega\pi^{\mu}/ \E^{\mu}[\Delta]\mu\omega\omega\muzijij\bar s(i,j)jsM^{\lpr}[s]M^{\opt}[s]sC\chi[s]
  =O (\ln C)M^{\lpr}[s] \geq \frac{1}{C}\chi[s] \in O\left(\ln\frac{1}{M^{\lpr}[s]}\right)
  O(\ln C)Cs : s(C+1)=1 L^{\opt}[s]M^{\opt}[s]\chi[s]ss' M^{\opt}[s]
  \geq L^{\opt}[s]G\in\{1,\ldots,V-C\}Ga_1, a_2, \ldotsC+G\tau_ii\tau_1, \tau_2, \ldots\tau\phi_jj\phi_jp_j=1-S(j)\Pb[\phi_j=k]=(1-p_j)^{k-1}p_j1/p_j\tau_1,\tau_2, \ldots GC\bar \tau_q\deq\sum_{i=1}^q \frac{\tau_i}{q}\bar \tau_q\E[\tau]1/x\bar \tau_q\{x\in\Z : x\geq C+G\}i\tau_i \geq
  C+Gs'G=\frac{V-C}{2}\forall j \; S_1(j) \geq S_2(j)L^{\opt}[s_1] \leq L^{\opt}[s_2]L^{\opt}\sum_{g=0}^{C+G-1} \frac{1}{1-S(g)}S(j)sC\lprs'\eta \deq \bar s(K+1,L)\sigma \deq S(K) - (K-1)\etaD \deq
  \left\lceil \frac{1-S(L)}{\eta} \right\rceil - 1\eta' \deq 1-S(L)-D\eta0<\eta'\leq \etas'L^{\opt}[s'] \leq L^{\opt}[s]M^{\lpr}[s'] = M^{\lpr}[s]\bar s(2, K)>\bar s(K+1, L)>\bar s(L+1, V)ss'\eta=\bar s(K+1, L)[K+1, L]s(j)=\eta[2,K]\bar s(2, K)>\bar
    s(K+1, L)[2, K]s(1)1-S(L)L+1\eta\eta'\bar s(K+1, L)>\bar s(L+1, V)s'\forall j \; S'(j) \geq S(j)L^{\opt}[s'] \leq L^{\opt}[s]ss'W \deq L+D+1\leq V\chi[s]C \gg 1W-C>2M^{\lpr}[s] \leq (W-C)\eta\eta \leq \frac{1}{W-2}s(1)+\eta'+\eta(W-2)=1M^{\lpr}[s] \leq \frac{W-C}{W-2}M^{\lpr}[s]>\frac{1}{C}O(V)O(\log V)sNO(V+N \log V)s(q_1, q_2, \ldots,
  q_l)s\Lambda\PisiQ_i\deq[q_i+1, q_{i+1}]j \in
  \{1,2, \ldots, V\}\rho_t(j)\Pi_tj\Lambda_t\Pi_t(\rho_t(j))\Lambda_t(j)tQ_ij \in Q_i\rho_t(j) \in Q_ia_td_td_t=1\rhod_t>1\rhotQ_ii=1,\ldots, l-1h \in \{0, q_{i+1}-q_i-1\}(q_i+1+h) \in Q_i\rho\rho\{q_1, q_2, \ldots, q_l \}B_t^{LPR}(q_i) =B_t^{LRU}(q_i)\klLC=q_iL(C)=q_iq_iq_iQ_iB(q_{i+1})B(q_i)d_t=1\rho_{t+1}=\rho_td_t \in Q_aQ_aC>q_{a+1}\rhoq_{a+1}i>a1+q_i+h
  >q_{a+1}C \in Q_aC<d_td_td_tC_aa_{t+1}C<C_a\Lambda_{t}(q_a)C_aC_aQ_ah=(d_t+1)-(q_a+1), \ldots, q_{a+1}-(q_a+1)\rho_{t+1}(q_a+1+h)=\rho_{t}(q_a+1+h)\rho_{t+1}(q_a+1)=\rho_t(d_t)h=1, \ldots,
  d_t-(q_a+1)\rho_{t+1}(q_a+1+h)=\rho_{t}(q_a+1+h-1)Q_ii<ab_ta_ty_t(C)C\Lambda_0a_1, \dots, a_td_0,\ldots,d_{t-1}O(V+ t \log V)\rhoO(\log V)a_{t+1}\rho(d_t)\rho(\rho(q_i+1), \ldots, \rho(q_{i+1}))\rho(q_i+1+h)h
\in [0,q_{i+1}-(q_i+1)]O(1+\log(q_{i+1}-q_i)) = O(\log V)R_iQ_i\rho\theta(V)Q_aVTQ_al-1Q_1,
\ldots Q_{l-1}i\rhoQ_ia_{t+1}d_tT\cal PQ_ad_t\cal P\nu\nu{\cal P}Q_a\cal PR_aQ_a\rho_t(d_t)(d_t-q_a)R_aa_{t+1}(d_t-q_a)R_aO(\log V)NO(V+N \log V)V\nu\nu\piJ^{\pi}_{\tau}(\cdot)\piss(j)\geq s(j+1) j\in\{1,
  V-1\}\tau \geq 1ss(j)\leq s(j+1) j\in\{1,
  V-1\}\tau \geq 1\zeta\zetas_\zetaC/VO(1)xVx_t(j)=1jtx_t(j)=0w_t=d_tu_tfR_d(x)dxx(d)=0R_d(x)x(d)=0yzy <_c z\nu,\iota\sigma \in 0^*y \leq_c zy = zy <_c zyzf^{\lru}(x,d)=f(x,d,\lru(x,d))yzy' <_c z'yz\iota \in 0^*y'
    <_c z'yzzy'=z'yzyy'=z'\iota \in 0^*y' <_c z's\tau\tau\tau=1st < \tau\bar g(y)\leq \bar g(z)J^*_\tau(y) \leq J^*_\tau(z)\mathcal{V}\deq\{1, 2, \ldots, V\}\mathcal{V}^0\deq\{\epsilon\}\epsilon\mathcal{V}_L =\cup_{i=0}^L \mathcal{V}^iLXL\zetat-1=|\zeta|\zeta\forall x \in Xd\zeta\forall \zetas_\zetaL\zeta \tau_\zeta \deq L -
  |\zeta|\tau_\zeta\forall \theta :
  \tau_\theta < \tau\forall x \in X\theta \deq \zeta d\forall y \leq_c z \quad
  J^*_L(\theta,y) \leq J^*_L(\theta,z)J^*_L(\zeta, y) \leq J^*_L(\zeta, z)st\leq \tau\tau+1\mu\Psid_tt\psil_t^\mu\left(\psi,x_0,d_{t'<t}\right)t\psitd_t=l_t^\mu\left(\psi,x_0,d_{t'<t}\right)\tau\psi\in\Psi\psi_jj\psi_jx_0l_t^{\mru}(\psi_j,x_0,d_{t'<t}) =
l_t^{\mru}(\psi_j,d_{t'<t})=l_t(\psi_j)x'x''\psi_i\psi_j\Gamma'\Gamma''\gamma_\tau(i)\deq\sum_{t=0}^{\tau-1}\Pb[d_t=l_t(\psi_i)]\gamma_\tau(i)i\tau+1t\leq \taus\forall j\in\{1, V-1\} \;\; s(j)\leq s(j+1)t=1\forall k \;\; \gamma_t(k)=s(k)C=2sC'C''C' < C''B_0(C') \subseteq B_0(C'')\tauj'j''C=C'j'C=C'j''sV=8\beta=\frac{1}{16}s(j)\beta3\beta3\beta04\beta005\betaj\in[1,V]\Lambda_0B_0(2)B_0(3)B_0(2)
  \subset B_0(3)x_0=\Lambda_0(8)T=5C=2\Lambda_0(1)C=3\Lambda_0(4)\Lambda(8)\Lambda(5)\Lambda(8)g\Lambda(6)C=2\Lambda(6)C=2C=2j\in\{2, \ldots, V\}1jh(j)h(2)=0h(j)=h(j)-h(2)=\lim_{\tau\rightarrow +\infty} J_\tau^*(j)-J_\tau^*(2)\Phi(j)\beta\phi(j)\lambdah(j)\psi(j) \deq\frac{1}{1-S(j-1)}\min\left\{0, h(j)\right\}=-\psi(j)\rho(j)\phi(j)\lambdah(j)\DeltaXWQ\mathcal{P}utut\Delta\tone=\left(X\tone,W\tone,Q\tone,g\tone,f\tone,U\tone(\cdot,\cdot)\right)\Delta\ttwo=\left(X\ttwo,W\ttwo,Q\ttwo,g\ttwo,f\ttwo,U\ttwo(\cdot)\right)X\tone=X\ttwoW\tone=W\ttwog\tone=g\ttwox_0w_t\Delta\tone\Delta\ttwou\tone_t\Delta\toneu\ttwo_tx_t\Delta\tone\Delta\ttwo\Delta\tone\Delta\ttwo\Delta\ttwo\Delta\toneu' \in \mathcal{P}\forall x \in X, \quad \forall w \in W,\forall u\tone \in U\tone(x,w)y=f\tone\left(x,u\tone,w\right)u\ttwou\ttwo(x,w)=u\tone\forall u\ttwo\in U\ttwo(x)y=f\ttwo\left(x,u\ttwo,w\right)u\tone=u'(x,w)w_tWt\Delta\tone\Delta\ttwo\Delta\tone\Delta\ttwo\Delta\ttwo\exists \lambda\exists \vec h\lambda\Delta\tone\vec h\Delta\tone\Delta\ttwo\Delta\tone\Delta\ttwo\Delta\tone\lambda\vec h\T\ttwo \vec h=\T\tone \vec h\lambda\vec h$
\end{proof}

\end{document}
