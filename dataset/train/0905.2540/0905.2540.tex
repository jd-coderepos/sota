\documentclass[11pt]{article}



\usepackage{geometry}
\usepackage{theorem}
\usepackage{graphicx}
\usepackage{amsmath}
\usepackage{float}
\usepackage{amssymb}



\date{}
\geometry{letterpaper,tmargin=1in,bmargin=1in,lmargin=1in,rmargin=1in}



\newtheorem{theorem}{Theorem}
\newtheorem{definition}{Definition}
\newtheorem{lemma}{Lemma}
\newtheorem{corollary}{Corollary}
\newtheorem{specification}{Specification}
\newtheorem{proposition}{Proposition}
\newtheorem{notation}{Notation}

\newenvironment{proof}{{\noindent\bf Proof. } }{{\hfill }}
\newenvironment{sketchproof}{{\noindent\bf Sketch of proof. } }{{\hfill }}

\floatstyle{ruled}
\newfloat{algorithm}{tbp}{loa}
\floatname{algorithm}{Algorithm}

\begin{document}



\newcommand{\AN}{~}
\newcommand{\AD}{~}



\title{Two snap-stabilizing point-to-point communication\\ protocols in message-switched networks}

\author{
Alain Cournier\thanks{MIS Laboratory, Universit\'e de Picardie Jules Verne, alain.cournier@u-picardie.fr}
\and 
Swan Dubois\thanks{LIP6 - UMR 7606 Universit\'e Pierre et Marie Curie - Paris 6 \& INRIA Rocquencourt, swan.dubois@lip6.fr}
\and
Vincent Villain\thanks{MIS Laboratory, Universit\'e de Picardie Jules Verne, vincent.villain@u-picardie.fr}
}

\maketitle



\begin{abstract}
A \emph{snap-stabilizing} protocol, starting from any configuration, always behaves according to its specification. In this paper, we present a snap-stabilizing protocol to solve the message forwarding problem in a message-switched network. In this problem, we must manage resources of the system to deliver messages to any processor of the network. In this purpose, we use information given by a routing algorithm. By the context of stabilization (in particular, the system starts in an arbitrary configuration), this information can be corrupted. So, the existence of a snap-stabilizing protocol for the message forwarding problem implies that we can ask the system to begin forwarding messages even if routing information are initially corrupted.

In this paper, we propose two snap-stabilizing algorithms (in the \emph{state model}) for the following specification of the problem:
\begin{itemize}
	\item Any message can be generated in a finite time.
	\item Any emitted message is delivered to its destination once and only once in a finite time.
\end{itemize}
This implies that our protocol can deliver any emitted message regardless of the state of routing tables in the initial configuration.

These two algorithms are based on the previous work of \cite{MS78}. Each algorithm needs a particular method to be transform into a snap-stabilizing one but both of them do not introduce a significant overcost in memory or in time with respect to algorithms of \cite{MS78}.
\end{abstract}

\newpage

\section{Introduction}

The quality of a distributed system depends on its \emph{fault-tolerance}. Many fault-tolerant schemes have been proposed. For instance, \emph{self-stabilization} (\cite{D74}) allows to design a system tolerating arbitrary transient faults. A self-stabilizing system, regardless of the initial state of the system, is guaranteed to converge into the intended behavior in a finite time. An other paradigm called \emph{snap-stabilization} has been introduced in \cite{BDPV07,BDPV99}. A snap-stabilizing protocol guarantees that, starting from any configuration, it always behaves according to its specification. In other words, a snap-stabilizing protocol is a self-stabilizing protocol which stabilizes in 0 time unit.

In a distributed system, it is commonly assumed that each processor can exchange messages only with its \emph{neighbors} (\emph{i.e.} processors with which it shares a communication link) but processors may need to exchange messages with \emph{any} processor of the network. To perform this goal, processors have to solve two problems: the determination of the path which messages have to follow in the network to reach their destinations (it is the \emph{routing} problem) and the management of network resources in order to forward messages (it is the \emph{message forwarding} problem).

These two problems received a great attention in literature. The routing problem is studied for example in \cite{BLT93,CM82,FG97,FG98,G00,LT87,LT94,MS79,T77,T80b} and self-stabilizing approach can be found (directly or not) in \cite{HC92,KK05,D97,JT03}. The forwarding problem has also been well studied, see \cite{D96,MS78,SJ95,T80,TS81,TU81} for example. As far we know, the message forwarding problem was never directly studied with a snap-stabilizing approach (note that the protocol proposed by \cite{JT03} can be used to perform a self-stabilizing forwarding protocol for dynamic networks since it is guaranteed that routing tables remain loop-free even if topological changes are allowed).

Informally, a message forwarding protocol allows any processor of the network to send messages to any destination of the network knowing that a routing algorithm computes the path that messages have to follow to reach their destinations. Problems come of the following fact: messages traveling through a \emph{message-switched network} (\cite{T01}) must be stored in each processor of their path before being forwarded to the next processor on this path. This temporary storage of messages is performed with reserved memory spaces called buffers. Obviously, each processor of the network reserves only a \emph{finite} number of buffers for the message forwarding. So, it is a problem of bounded resources management which exposes the network to deadlocks and livelocks if no control is performed. 

In this paper, we focus on message forwarding protocols which deal the problem with a snap-stabilizing approach. The goal is to allow the system to forward messages (without looses) regardless of the state of the routing tables. Obviously, we need that theses routing tables repair themselves in a finite time. So, we assume the existence of a self-stabilizing protocol to compute routing tables (see \cite{HC92,KK05,D97}).

In the following, a \emph{valid} message is a message which has been generated by a processor. As a consequence, an \emph{invalid} message is a message which is present in the initial configuration. We can now specify the problem. We propose a specification of the problem where message duplications (\emph{i.e.} the same message reaches its destination many time while it has been generated only once) are forbidden:

\begin{specification}[]\label{specif:spe2}
Specification of message forwarding problem forbidding duplication.
\begin{itemize}
	\item Any message can be generated in a finite time.
	\item Any valid message is deliver to its destination once and only once in a finite time.
\end{itemize}
\end{specification}

In this paper, we investigate the possibility to transform two known message forwarding protocols (\cite{MS78}) into snap-stabilizing ones. We use a different scheme for both of them but we prove that these two schemes do not significantly modify time and space complexities of these protocols. Consequently, the main contribution of this paper is to show that it is possible to provide stronger safety properties without significant overcost.

The sequel of this paper is organized as follows: we present first our model (section \ref{sec:Model}). We quickly survey the seminal work of \cite{MS78} in section \ref{sec:survey}. Then we give, prove, and analyze our two solutions (sections \ref{sec:protocolN} and \ref{sec:protocolD}). Finally, we conclude by some remarks and open problems (section \ref{sec:Conclusion}).

\section{Model and definitions}\label{sec:Model}

We consider a network as an undirected connected graph  where  is a set of processors and  is the set of bidirectional asynchronous communication links. In the network, a communication link  exists if and only if  and  are \emph{neighbors}. Every processor  can distinguish all its links. To simplify the presentation, we refer to a link  of a processor  by the label . We assume that the labels of  are stored in the set . 

We also use the following notations: respectively,  is the number of processors,  the maximal degree, and  the diameter of the network. If  and  are two processors of the network, we denote by  the length of the shortest path between  and  (\emph{i.e.} the \emph{distance} between  and ). In the following, we assume that the network is \emph{identified}, \emph{i.e.} each processor have an identity which is unique on the network. Moreover, we assume that all processors know the set  of all identities of the network.

\subsection{State model}\label{sub:State-model}

We consider the classical \emph{local shared memory model} of computation (see \cite{T01}) in which communications between neighbors are modeled by direct reading of variables instead of exchange of messages. 

In this model, the program of every processor consists in a set of \emph{shared variables} (henceforth, referred to as \emph{variables}) and a finite set of \emph{actions}. A processor can write to its own variables only, and read its own variables and those of its neighbors. Each action is constituted as follows: . The \emph{label} is a name to refer to the rule in the discussion. The \emph{guard} of an action in the program of  is a Boolean expression involving variables of  and its neighbors. The \emph{statement} of an action of  updates one or more variables of . An action can be executed only if its guard is satisfied.

The \emph{state} of a processor is defined by the value of its variables. The state of a system is the product of the states of all processors. We refer to the state of a processor and the system as a (local) \emph{state} and (global) \emph{configuration}, respectively. We note  the set of all configurations of the system. 

Let  and  an action of  ().  is \emph{enabled} for  in  if and only if the guard of  is satisfied by  in . Processor  is \emph{enabled} in  if and only if at least one action is enabled at  in . Let a distributed protocol  be a collection of actions denoted by , on . An \emph{execution} of a protocol  is a maximal sequence of configurations  such that,  (called a \emph{step}) if  exists, else  is a terminal configuration. \emph{Maximality} means that the sequence is either finite (and no action of  is enabled in the terminal configuration) or infinite. All executions considered here are assumed to be maximal.  is the set of all executions of .

As we already said, each execution is decomposed into steps. Each atomic step is composed of three sequential phases: (i) every processor evaluates its guards, (ii) a \emph{daemon} chooses some enabled processors, (iii) each chosen processor executes one of its enabled actions. When the three phases are done, the next step begins. A daemon can be defined in terms of \emph{fairness} and \emph{distribution}. There exists several kinds of fairness assumption. Here, we present the \emph{strong fairness}, \emph{weak fairness}, and \emph{unfairness} assumptions. Under a \emph{strongly fair} daemon, every processor that is enabled infinitely often is chosen by the daemon infinitely often to execute an action. When a daemon is \emph{weakly fair}, every continuously enabled processor is eventually chosen by the daemon. Finally, the \emph{unfair} daemon is the weakest scheduling assumption: it can forever prevent a processor to execute an action except if it is the only enabled processor. Concerning the distribution, we assume that the daemon is \emph{distributed} meaning that, at each step, if one or several processors are enabled, then the daemon chooses at least one of these processors to execute an action. 

We consider that any processor  is \emph{neutralized} in the step  if  was enabled in  and not enabled in , but did not execute any action in . To compute the time complexity, we use the definition of \emph{round} (introduced in \cite{DIM97} and modified by \cite{BDPV07}). This definition captures the execution rate of the slowest processor in any execution. The first round of , noted , is the minimal prefix of  containing the execution of one action or the neutralization of every enabled processor from the initial configuration. Let  be the suffix of  such that . The second round of  is the first round of , and so on.

\subsection{Message-switched networks}\label{sub:Message-switched-network}

Today, most of computer networks use a variant of the \emph{message-switching} method (also called \emph{store-and-forward} method). It is why we have choose to work with this switching model. In this section, we are going to present this method (see \cite{T01} for a detailed presentation).

Each processor has  buffers for temporarily storing messages. The model assumes that each buffer can store a whole message and that each message needs only one buffer to be stored. The switching method is modeled by four types of moves:

\begin{enumerate}
\item \textbf{Generation}: when a processor sends a new message, it ``creates'' a new message in one of its empty buffers. We assume that the network may allow this move as soon as at least one buffer of the processor is empty. 
\item \textbf{Forwarding}: a message  is forwarded (copied) from a processor  to an empty buffer in the next processor  on its route (determined by the routing algorithm). We assume that the network may allow this move as soon as at least one buffer buffer of the processor is empty. 
\item \textbf{Consumption}: A message  occupying a buffer in its destination is and delivered to this processor. We assume that the network may always allow this move. 
\item \textbf{Erasing}: a message  is erased from a buffer. We assume that the network may allow this move as soon as the message is forwarded at least one time or delivered to its destination.
\end{enumerate}

\subsection{Stabilization}\label{sub:Stabilization}

In this section, we give formal definitions of self- and snap-stabilization using notations introduced in \ref{sub:State-model}.

\begin{definition} [Self-Stabilization \cite{D74}] \label{def:self}
Let  be a task, and  a specification of . A protocol  is self-stabilizing for  if and only if , there exists a finite prefix  of  such that any executions starting from  satisfies .
\end{definition}

\begin{definition} [Snap-Stabilization \cite{BDPV99,BDPV07}] \label{def:snap}
Let  be a task, and  a specification of . A protocol  is snap-stabilizing for  if and only if ,  satisfies .
\end{definition}

This definition has the two following consequences. We can see that a snap-stabilizing protocol for  is a self-stabilizing protocol for  with a stabilization time of 0 time unit. A common method used to prove that a protocol is snap-stabilizing is to distinguish an action as a ``starting action'' (\emph{i.e.} an action which initiates a computation) and to prove the following property for every execution of the protocol: if a processor requests it, the computation is initiated by a starting action in a finite time and every computation initiated by a starting action satisfies the specification of the task. We use these two remarks to prove snap-stabilization of our protocol in the following of this paper.

\section{Fault-free protocols}\label{sec:survey}

In this section, we survey the seminal work of \cite{MS78}\footnote{The reader is referred to \cite{T01} to find a much detailed description of this work.}. Remind that this work assume that routing tables are correct in the initial configuration.  To simplify the presentation, we assume that the routing algorithm induces only minimal paths in number of edges.

We have seen in section \ref{sub:Message-switched-network} that, by default, the network always allows message moves between buffers. But, if we do no control on these moves, the network can reach unacceptable situations such as \emph{deadlocks}, \emph{livelocks} or \emph{message losses}. If such situations appear, specifications of message forwarding are not respected.

In order to avoid deadlocks, we must define an algorithm which permits or forbids various moves in the network (functions of the current occupation of buffers). A such algorithm is a \emph{controller}. If a controller  ensure the following property: in any execution,  prevents the network to reach a deadlock, then  is a \emph{deadlock-free} controller.

Livelocks can be avoided by fairness assumptions on the controller for the generation and the forwarding of messages. Message losses are avoided by the using of identifier on messages. For example, one can use the concatenation of the identity of the source and a two-value flag in order to distinguish two consecutive identical messages generated by the same processor for a Destination  (since all messages follow the same path).

Then, a deadlock-free controller which prevents also livelocks and message losses satisfies the specification of the message forwarding problem.

In the case where routing table are initially correct, \cite{MS78} introduced a generic method to design deadlock-free controllers. It consists to restrict moves of messages along edges of an oriented graph  (called \emph{buffer graph}) defined on the network buffers. Then, it is easy to see that cycles on  can lead to deadlocks. So, authors show that, if  is acyclic, they can define a deadlock-free controller on this buffer graph. In the sequel of this section, we present the two buffer graph which we use in our snap-stabilizing protocols.

\paragraph{"Destination-based" buffer graph.} In this scheme, we assume that the routing algorithm forwards all packets of Destination  via a directed tree  rooted in . Each processor  of the network has a buffer  for each possible Destination  (called the target of ). The buffer graph has  connected components, each of them containing all the buffers which shared their target. The connected component associated to the target  is isomorphic to . The reader can find an example of a such graph in Figure \ref{fig:ExempleBG1}.

Since each connected component of this graph is a tree, this oriented graph is acyclic. Consequently, \cite{MS78} allows us to define a deadlock-free controller on this graph. Note that this scheme use  buffers per processor. So, we need  buffers on the whole network.
\begin{figure}
\noindent \begin{centering}
\clearpage{}\ifx\JPicScale\undefined\def\JPicScale{0.35}\fi
\unitlength \JPicScale mm
\begin{picture}(216.97,165)(0,0)
\linethickness{0.3mm}
\put(20,97.12){\circle{10}}

\linethickness{0.3mm}
\put(50,87.12){\circle{10}}

\linethickness{0.3mm}
\put(30,77.12){\circle{10}}

\linethickness{0.3mm}
\put(70,87.12){\circle{10}}

\linethickness{0.3mm}
\put(90,87.12){\circle{10}}

\linethickness{0.3mm}
\multiput(25,97.12)(0.24,-0.12){83}{\line(1,0){0.24}}
\linethickness{0.3mm}
\multiput(30,82.12)(0.36,0.12){42}{\line(1,0){0.36}}
\linethickness{0.3mm}
\put(55,87.12){\line(1,0){10}}
\linethickness{0.3mm}
\put(75,87.12){\line(1,0){10}}
\linethickness{0.3mm}
\put(125,162.12){\line(1,0){10}}
\put(125,152.12){\line(0,1){10}}
\put(135,152.12){\line(0,1){10}}
\put(125,152.12){\line(1,0){10}}
\linethickness{0.3mm}
\put(165,152.12){\line(1,0){10}}
\put(165,142.12){\line(0,1){10}}
\put(175,142.12){\line(0,1){10}}
\put(165,142.12){\line(1,0){10}}
\linethickness{0.3mm}
\put(185,152.12){\line(1,0){10}}
\put(185,142.12){\line(0,1){10}}
\put(195,142.12){\line(0,1){10}}
\put(185,142.12){\line(1,0){10}}
\linethickness{0.3mm}
\put(205,152.12){\line(1,0){10}}
\put(205,142.12){\line(0,1){10}}
\put(215,142.12){\line(0,1){10}}
\put(205,142.12){\line(1,0){10}}
\linethickness{0.3mm}
\put(145,142.12){\line(1,0){10}}
\put(145,132.12){\line(0,1){10}}
\put(155,132.12){\line(0,1){10}}
\put(145,132.12){\line(1,0){10}}
\linethickness{0.3mm}
\multiput(135,157.12)(0.36,-0.12){83}{\line(1,0){0.36}}
\put(135,157.12){\vector(-3,1){0.12}}
\linethickness{0.3mm}
\multiput(150,142.12)(0.36,0.12){42}{\line(1,0){0.36}}
\put(165,147.12){\vector(3,1){0.12}}
\linethickness{0.3mm}
\put(175,147.12){\line(1,0){10}}
\put(175,147.12){\vector(-1,0){0.12}}
\linethickness{0.3mm}
\put(195,147.12){\line(1,0){10}}
\put(195,147.12){\vector(-1,0){0.12}}
\linethickness{0.3mm}
\put(125,132.12){\line(1,0){10}}
\put(125,122.12){\line(0,1){10}}
\put(135,122.12){\line(0,1){10}}
\put(125,122.12){\line(1,0){10}}
\linethickness{0.3mm}
\put(165,122.12){\line(1,0){10}}
\put(165,112.12){\line(0,1){10}}
\put(175,112.12){\line(0,1){10}}
\put(165,112.12){\line(1,0){10}}
\linethickness{0.3mm}
\put(185,122.12){\line(1,0){10}}
\put(185,112.12){\line(0,1){10}}
\put(195,112.12){\line(0,1){10}}
\put(185,112.12){\line(1,0){10}}
\linethickness{0.3mm}
\put(205,122.12){\line(1,0){10}}
\put(205,112.12){\line(0,1){10}}
\put(215,112.12){\line(0,1){10}}
\put(205,112.12){\line(1,0){10}}
\linethickness{0.3mm}
\put(145,112.12){\line(1,0){10}}
\put(145,102.12){\line(0,1){10}}
\put(155,102.12){\line(0,1){10}}
\put(145,102.12){\line(1,0){10}}
\linethickness{0.3mm}
\multiput(135,127.12)(0.36,-0.12){83}{\line(1,0){0.36}}
\put(165,117.12){\vector(3,-1){0.12}}
\linethickness{0.3mm}
\multiput(150,112.12)(0.36,0.12){42}{\line(1,0){0.36}}
\put(150,112.12){\vector(-3,-1){0.12}}
\linethickness{0.3mm}
\put(175,117.12){\line(1,0){10}}
\put(175,117.12){\vector(-1,0){0.12}}
\linethickness{0.3mm}
\put(195,117.12){\line(1,0){10}}
\put(195,117.12){\vector(-1,0){0.12}}
\linethickness{0.3mm}
\put(125,102.12){\line(1,0){10}}
\put(125,92.12){\line(0,1){10}}
\put(135,92.12){\line(0,1){10}}
\put(125,92.12){\line(1,0){10}}
\linethickness{0.3mm}
\put(165,92.12){\line(1,0){10}}
\put(165,82.12){\line(0,1){10}}
\put(175,82.12){\line(0,1){10}}
\put(165,82.12){\line(1,0){10}}
\linethickness{0.3mm}
\put(185,92.12){\line(1,0){10}}
\put(185,82.12){\line(0,1){10}}
\put(195,82.12){\line(0,1){10}}
\put(185,82.12){\line(1,0){10}}
\linethickness{0.3mm}
\put(205,92.12){\line(1,0){10}}
\put(205,82.12){\line(0,1){10}}
\put(215,82.12){\line(0,1){10}}
\put(205,82.12){\line(1,0){10}}
\linethickness{0.3mm}
\put(145,82.12){\line(1,0){10}}
\put(145,72.12){\line(0,1){10}}
\put(155,72.12){\line(0,1){10}}
\put(145,72.12){\line(1,0){10}}
\linethickness{0.3mm}
\multiput(135,97.12)(0.36,-0.12){83}{\line(1,0){0.36}}
\put(165,87.12){\vector(3,-1){0.12}}
\linethickness{0.3mm}
\multiput(150,82.12)(0.36,0.12){42}{\line(1,0){0.36}}
\put(165,87.12){\vector(3,1){0.12}}
\linethickness{0.3mm}
\put(175,87.12){\line(1,0){10}}
\put(175,87.12){\vector(-1,0){0.12}}
\linethickness{0.3mm}
\put(195,87.12){\line(1,0){10}}
\put(195,87.12){\vector(-1,0){0.12}}
\linethickness{0.3mm}
\put(125,72.12){\line(1,0){10}}
\put(125,62.12){\line(0,1){10}}
\put(135,62.12){\line(0,1){10}}
\put(125,62.12){\line(1,0){10}}
\linethickness{0.3mm}
\put(165,62.12){\line(1,0){10}}
\put(165,52.12){\line(0,1){10}}
\put(175,52.12){\line(0,1){10}}
\put(165,52.12){\line(1,0){10}}
\linethickness{0.3mm}
\put(185,62.12){\line(1,0){10}}
\put(185,52.12){\line(0,1){10}}
\put(195,52.12){\line(0,1){10}}
\put(185,52.12){\line(1,0){10}}
\linethickness{0.3mm}
\put(205,62.12){\line(1,0){10}}
\put(205,52.12){\line(0,1){10}}
\put(215,52.12){\line(0,1){10}}
\put(205,52.12){\line(1,0){10}}
\linethickness{0.3mm}
\put(145,52.12){\line(1,0){10}}
\put(145,42.12){\line(0,1){10}}
\put(155,42.12){\line(0,1){10}}
\put(145,42.12){\line(1,0){10}}
\linethickness{0.3mm}
\multiput(135,67.12)(0.36,-0.12){83}{\line(1,0){0.36}}
\put(165,57.12){\vector(3,-1){0.12}}
\linethickness{0.3mm}
\multiput(150,52.12)(0.36,0.12){42}{\line(1,0){0.36}}
\put(165,57.12){\vector(3,1){0.12}}
\linethickness{0.3mm}
\put(175,57.12){\line(1,0){10}}
\put(185,57.12){\vector(1,0){0.12}}
\linethickness{0.3mm}
\put(195,57.12){\line(1,0){10}}
\put(195,57.12){\vector(-1,0){0.12}}
\linethickness{0.3mm}
\put(125,42.12){\line(1,0){10}}
\put(125,32.12){\line(0,1){10}}
\put(135,32.12){\line(0,1){10}}
\put(125,32.12){\line(1,0){10}}
\linethickness{0.3mm}
\put(165,32.12){\line(1,0){10}}
\put(165,22.12){\line(0,1){10}}
\put(175,22.12){\line(0,1){10}}
\put(165,22.12){\line(1,0){10}}
\linethickness{0.3mm}
\put(185,32.12){\line(1,0){10}}
\put(185,22.12){\line(0,1){10}}
\put(195,22.12){\line(0,1){10}}
\put(185,22.12){\line(1,0){10}}
\linethickness{0.3mm}
\put(205,32.12){\line(1,0){10}}
\put(205,22.12){\line(0,1){10}}
\put(215,22.12){\line(0,1){10}}
\put(205,22.12){\line(1,0){10}}
\linethickness{0.3mm}
\put(145,22.12){\line(1,0){10}}
\put(145,12.12){\line(0,1){10}}
\put(155,12.12){\line(0,1){10}}
\put(145,12.12){\line(1,0){10}}
\linethickness{0.3mm}
\multiput(135,37.12)(0.36,-0.12){83}{\line(1,0){0.36}}
\put(165,27.12){\vector(3,-1){0.12}}
\linethickness{0.3mm}
\multiput(150,22.12)(0.36,0.12){42}{\line(1,0){0.36}}
\put(165,27.12){\vector(3,1){0.12}}
\linethickness{0.3mm}
\put(175,27.12){\line(1,0){10}}
\put(185,27.12){\vector(1,0){0.12}}
\linethickness{0.3mm}
\put(195,27.12){\line(1,0){10}}
\put(205,27.12){\vector(1,0){0.12}}
\put(20,107.12){\makebox(0,0)[cc]{a}}

\put(30,67.12){\makebox(0,0)[cc]{b}}

\put(50,77.12){\makebox(0,0)[cc]{c}}

\put(70,77.12){\makebox(0,0)[cc]{d}}

\put(90,77.12){\makebox(0,0)[cc]{e}}

\linethickness{0.3mm}
\put(122.88,165){\line(1,0){14.55}}
\put(122.88,28.03){\line(0,1){136.97}}
\put(137.42,28.03){\line(0,1){136.97}}
\put(122.88,28.03){\line(1,0){14.55}}
\linethickness{0.3mm}
\put(202.42,154.85){\line(1,0){14.55}}
\put(202.42,17.88){\line(0,1){136.97}}
\put(216.97,17.88){\line(0,1){136.97}}
\put(202.42,17.88){\line(1,0){14.55}}
\linethickness{0.3mm}
\put(182.88,155){\line(1,0){14.55}}
\put(182.88,18.03){\line(0,1){136.97}}
\put(197.42,18.03){\line(0,1){136.97}}
\put(182.88,18.03){\line(1,0){14.55}}
\linethickness{0.3mm}
\put(162.73,154.85){\line(1,0){14.55}}
\put(162.73,17.88){\line(0,1){136.97}}
\put(177.27,17.88){\line(0,1){136.97}}
\put(162.73,17.88){\line(1,0){14.55}}
\linethickness{0.3mm}
\put(142.88,145){\line(1,0){14.55}}
\put(142.88,8.03){\line(0,1){136.97}}
\put(157.42,8.03){\line(0,1){136.97}}
\put(142.88,8.03){\line(1,0){14.55}}
\put(130,22.12){\makebox(0,0)[cc]{a}}

\put(150,2.12){\makebox(0,0)[cc]{b}}

\put(170,12.12){\makebox(0,0)[cc]{c}}

\put(190,12.12){\makebox(0,0)[cc]{d}}

\put(210,12.12){\makebox(0,0)[cc]{e}}

\end{picture}
\clearpage{}
\end{centering}
\caption{\label{fig:ExempleBG1}Example of a "destination-based" buffer graph (on the right) on the network of the left.}
\end{figure}

\paragraph{"Distance-based" buffer graph.} In this scheme, each processor have  buffers ranked from  to  (remind that  is the diameter of the network). New messages are always generated in the buffer of rank  of the sending processor. When a message occupying a buffer of rank  is forwarded to a neighbor , it is always copied in the buffer of rank  of . We need  buffers per processor since, in the worst case, there are  forwarding of a message between its generation and its consumption. The reader can find an example of such a graph in Figure \ref{fig:ExempleBG2}.

Since messages always "come upstairs" the buffer rank, this oriented graph is acyclic. Consequently, \cite{MS78} allows us to define a deadlock-free controller on this graph. Note that this scheme use  buffers per processor. So, we need  buffers on the whole network.

\begin{figure}
\noindent \begin{centering}
\clearpage{}\ifx\JPicScale\undefined\def\JPicScale{0.35}\fi
\unitlength \JPicScale mm
\begin{picture}(215.61,90.45)(0,0)
\linethickness{0.3mm}
\put(15,55){\circle{10}}

\linethickness{0.3mm}
\put(45,45){\circle{10}}

\linethickness{0.3mm}
\put(25,35){\circle{10}}

\linethickness{0.3mm}
\put(65,45){\circle{10}}

\linethickness{0.3mm}
\put(85,45){\circle{10}}

\linethickness{0.3mm}
\multiput(20,55)(0.24,-0.12){83}{\line(1,0){0.24}}
\linethickness{0.3mm}
\multiput(25,40)(0.36,0.12){42}{\line(1,0){0.36}}
\linethickness{0.3mm}
\put(50,45){\line(1,0){10}}
\linethickness{0.3mm}
\put(70,45){\line(1,0){10}}
\put(15,65){\makebox(0,0)[cc]{a}}

\put(25,25){\makebox(0,0)[cc]{b}}

\put(45,35){\makebox(0,0)[cc]{c}}

\put(65,35){\makebox(0,0)[cc]{d}}

\put(85,35){\makebox(0,0)[cc]{e}}

\linethickness{0.3mm}
\put(115,20){\line(1,0){10}}
\put(115,10){\line(0,1){10}}
\put(125,10){\line(0,1){10}}
\put(115,10){\line(1,0){10}}
\linethickness{0.3mm}
\put(135,20){\line(1,0){10}}
\put(135,10){\line(0,1){10}}
\put(145,10){\line(0,1){10}}
\put(135,10){\line(1,0){10}}
\linethickness{0.3mm}
\put(155,20){\line(1,0){10}}
\put(155,10){\line(0,1){10}}
\put(165,10){\line(0,1){10}}
\put(155,10){\line(1,0){10}}
\linethickness{0.3mm}
\put(175,20){\line(1,0){10}}
\put(175,10){\line(0,1){10}}
\put(185,10){\line(0,1){10}}
\put(175,10){\line(1,0){10}}
\linethickness{0.3mm}
\put(195,20){\line(1,0){10}}
\put(195,10){\line(0,1){10}}
\put(205,10){\line(0,1){10}}
\put(195,10){\line(1,0){10}}
\put(120,0){\makebox(0,0)[cc]{a}}

\put(140,0){\makebox(0,0)[cc]{b}}

\put(160,0){\makebox(0,0)[cc]{c}}

\put(180,0){\makebox(0,0)[cc]{d}}

\put(200,0){\makebox(0,0)[cc]{e}}

\linethickness{0.3mm}
\multiput(120,20)(0.48,0.12){83}{\line(1,0){0.48}}
\put(160,30){\vector(4,1){0.12}}
\linethickness{0.3mm}
\multiput(140,20)(0.24,0.12){83}{\line(1,0){0.24}}
\put(160,30){\vector(2,1){0.12}}
\linethickness{0.3mm}
\multiput(160,20)(0.24,0.12){83}{\line(1,0){0.24}}
\put(180,30){\vector(2,1){0.12}}
\linethickness{0.3mm}
\multiput(140,30)(0.24,-0.12){83}{\line(1,0){0.24}}
\put(140,30){\vector(-2,1){0.12}}
\linethickness{0.3mm}
\multiput(120,30)(0.48,-0.12){83}{\line(1,0){0.48}}
\put(120,30){\vector(-4,1){0.12}}
\linethickness{0.3mm}
\multiput(180,20)(0.24,0.12){83}{\line(1,0){0.24}}
\put(200,30){\vector(2,1){0.12}}
\linethickness{0.3mm}
\multiput(160,30)(0.24,-0.12){83}{\line(1,0){0.24}}
\put(160,30){\vector(-2,1){0.12}}
\linethickness{0.3mm}
\multiput(180,30)(0.24,-0.12){83}{\line(1,0){0.24}}
\put(180,30){\vector(-2,1){0.12}}
\linethickness{0.3mm}
\put(115,40){\line(1,0){10}}
\put(115,30){\line(0,1){10}}
\put(125,30){\line(0,1){10}}
\put(115,30){\line(1,0){10}}
\linethickness{0.3mm}
\put(135,40){\line(1,0){10}}
\put(135,30){\line(0,1){10}}
\put(145,30){\line(0,1){10}}
\put(135,30){\line(1,0){10}}
\linethickness{0.3mm}
\put(155,40){\line(1,0){10}}
\put(155,30){\line(0,1){10}}
\put(165,30){\line(0,1){10}}
\put(155,30){\line(1,0){10}}
\linethickness{0.3mm}
\put(175,40){\line(1,0){10}}
\put(175,30){\line(0,1){10}}
\put(185,30){\line(0,1){10}}
\put(175,30){\line(1,0){10}}
\linethickness{0.3mm}
\put(195,40){\line(1,0){10}}
\put(195,30){\line(0,1){10}}
\put(205,30){\line(0,1){10}}
\put(195,30){\line(1,0){10}}
\linethickness{0.3mm}
\multiput(120,40)(0.48,0.12){83}{\line(1,0){0.48}}
\put(160,50){\vector(4,1){0.12}}
\linethickness{0.3mm}
\multiput(140,40)(0.24,0.12){83}{\line(1,0){0.24}}
\put(160,50){\vector(2,1){0.12}}
\linethickness{0.3mm}
\multiput(160,40)(0.24,0.12){83}{\line(1,0){0.24}}
\put(180,50){\vector(2,1){0.12}}
\linethickness{0.3mm}
\multiput(140,50)(0.24,-0.12){83}{\line(1,0){0.24}}
\put(140,50){\vector(-2,1){0.12}}
\linethickness{0.3mm}
\multiput(120,50)(0.48,-0.12){83}{\line(1,0){0.48}}
\put(120,50){\vector(-4,1){0.12}}
\linethickness{0.3mm}
\multiput(180,40)(0.24,0.12){83}{\line(1,0){0.24}}
\put(200,50){\vector(2,1){0.12}}
\linethickness{0.3mm}
\multiput(160,50)(0.24,-0.12){83}{\line(1,0){0.24}}
\put(160,50){\vector(-2,1){0.12}}
\linethickness{0.3mm}
\multiput(180,50)(0.24,-0.12){83}{\line(1,0){0.24}}
\put(180,50){\vector(-2,1){0.12}}
\linethickness{0.3mm}
\put(115,60){\line(1,0){10}}
\put(115,50){\line(0,1){10}}
\put(125,50){\line(0,1){10}}
\put(115,50){\line(1,0){10}}
\linethickness{0.3mm}
\put(135,60){\line(1,0){10}}
\put(135,50){\line(0,1){10}}
\put(145,50){\line(0,1){10}}
\put(135,50){\line(1,0){10}}
\linethickness{0.3mm}
\put(155,60){\line(1,0){10}}
\put(155,50){\line(0,1){10}}
\put(165,50){\line(0,1){10}}
\put(155,50){\line(1,0){10}}
\linethickness{0.3mm}
\put(175,60){\line(1,0){10}}
\put(175,50){\line(0,1){10}}
\put(185,50){\line(0,1){10}}
\put(175,50){\line(1,0){10}}
\linethickness{0.3mm}
\put(195,60){\line(1,0){10}}
\put(195,50){\line(0,1){10}}
\put(205,50){\line(0,1){10}}
\put(195,50){\line(1,0){10}}
\linethickness{0.3mm}
\multiput(120,60)(0.48,0.12){83}{\line(1,0){0.48}}
\put(160,70){\vector(4,1){0.12}}
\linethickness{0.3mm}
\multiput(140,60)(0.24,0.12){83}{\line(1,0){0.24}}
\put(160,70){\vector(2,1){0.12}}
\linethickness{0.3mm}
\multiput(160,60)(0.24,0.12){83}{\line(1,0){0.24}}
\put(180,70){\vector(2,1){0.12}}
\linethickness{0.3mm}
\multiput(140,70)(0.24,-0.12){83}{\line(1,0){0.24}}
\put(140,70){\vector(-2,1){0.12}}
\linethickness{0.3mm}
\multiput(120,70)(0.48,-0.12){83}{\line(1,0){0.48}}
\put(120,70){\vector(-4,1){0.12}}
\linethickness{0.3mm}
\multiput(180,60)(0.24,0.12){83}{\line(1,0){0.24}}
\put(200,70){\vector(2,1){0.12}}
\linethickness{0.3mm}
\multiput(160,70)(0.24,-0.12){83}{\line(1,0){0.24}}
\put(160,70){\vector(-2,1){0.12}}
\linethickness{0.3mm}
\multiput(180,70)(0.24,-0.12){83}{\line(1,0){0.24}}
\put(180,70){\vector(-2,1){0.12}}
\linethickness{0.3mm}
\put(115,80){\line(1,0){10}}
\put(115,70){\line(0,1){10}}
\put(125,70){\line(0,1){10}}
\put(115,70){\line(1,0){10}}
\linethickness{0.3mm}
\put(135,80){\line(1,0){10}}
\put(135,70){\line(0,1){10}}
\put(145,70){\line(0,1){10}}
\put(135,70){\line(1,0){10}}
\linethickness{0.3mm}
\put(155,80){\line(1,0){10}}
\put(155,70){\line(0,1){10}}
\put(165,70){\line(0,1){10}}
\put(155,70){\line(1,0){10}}
\linethickness{0.3mm}
\put(175,80){\line(1,0){10}}
\put(175,70){\line(0,1){10}}
\put(185,70){\line(0,1){10}}
\put(175,70){\line(1,0){10}}
\linethickness{0.3mm}
\put(195,80){\line(1,0){10}}
\put(195,70){\line(0,1){10}}
\put(205,70){\line(0,1){10}}
\put(195,70){\line(1,0){10}}
\put(215.61,90.45){\makebox(0,0)[cc]{Rank}}

\put(215,15){\makebox(0,0)[cc]{1}}

\put(215,35){\makebox(0,0)[cc]{2}}

\put(215,55){\makebox(0,0)[cc]{3}}

\put(215,75){\makebox(0,0)[cc]{4}}

\linethickness{0.3mm}
\put(112.73,83.94){\line(1,0){14.55}}
\put(112.73,6.52){\line(0,1){77.42}}
\put(127.27,6.52){\line(0,1){77.42}}
\put(112.73,6.52){\line(1,0){14.55}}
\linethickness{0.3mm}
\put(132.88,83.79){\line(1,0){14.55}}
\put(132.88,6.36){\line(0,1){77.42}}
\put(147.42,6.36){\line(0,1){77.42}}
\put(132.88,6.36){\line(1,0){14.55}}
\linethickness{0.3mm}
\put(152.42,83.33){\line(1,0){14.55}}
\put(152.42,5.91){\line(0,1){77.42}}
\put(166.97,5.91){\line(0,1){77.42}}
\put(152.42,5.91){\line(1,0){14.55}}
\linethickness{0.3mm}
\put(172.58,82.88){\line(1,0){14.55}}
\put(172.58,5.45){\line(0,1){77.42}}
\put(187.12,5.45){\line(0,1){77.42}}
\put(172.58,5.45){\line(1,0){14.55}}
\linethickness{0.3mm}
\put(192.73,83.03){\line(1,0){14.55}}
\put(192.73,5.61){\line(0,1){77.42}}
\put(207.27,5.61){\line(0,1){77.42}}
\put(192.73,5.61){\line(1,0){14.55}}
\end{picture}
\clearpage{}
\end{centering}
\caption{\label{fig:ExempleBG2}Example of a "distance-based" buffer graph (on the right) on the network of the left.}
\end{figure}

\section{First protocol}\label{sec:protocolN}

\subsection{Informal description}

The main idea of this section is to adapt the "destination-based" scheme (see Section \ref{sec:survey}) in order to tolerate the corruption of routing tables in the initial configuration. To perform this goal, we assume the existence of a self-stabilizing silent (\emph{i.e.} no actions are enabled after convergence) algorithm  to compute routing tables which runs simultaneously to our message forwarding protocol. Moreover, we assume that  has priority over our protocol (\emph{i.e.} a processor which has enabled actions for both algorithms always chooses the action of ). This guarantees us that routing tables are correct and constant in a finite time. To simplify the presentation, we assume that  induces only minimal paths in number of edges. We assume that our protocol can have access to the routing table via a function, called . This function returns the identity of the neighbor of  to which  must forward messages of Destination . 

We now describe our buffer graph adapted from the "destination-based" one. Our buffer graph is composed of  connected components, each associated to a destination  and based on the oriented tree  (remind that  is the tree induced by routing table for Destination ). Consequently, we can present only one connected component, associated to a destination noted  (others are similar). We use two buffers per processor for Destination . The first one, noted  (for processor ), is reserved to the reception of messages whereas the second one, noted , is used to emit messages (see Figure \ref{fig:ExempleBG3}). This scheme allows us to control the advance of messages. Indeed, we allow a message to be forwarded from  to  if and only if the message is only present in  and we erase it simultaneously. In this way, we can control the consequences of routing tables moves on messages (duplication or merge which can involve message losses).

\begin{figure}
\noindent \begin{centering}
\clearpage{}\ifx\JPicScale\undefined\def\JPicScale{0.35}\fi
\unitlength \JPicScale mm
\begin{picture}(217.27,85)(0,0)
\linethickness{0.3mm}
\put(20,52.12){\circle{10}}

\linethickness{0.3mm}
\put(50,42.12){\circle{10}}

\linethickness{0.3mm}
\put(30,32.12){\circle{10}}

\linethickness{0.3mm}
\put(70,42.12){\circle{10}}

\linethickness{0.3mm}
\put(90,42.12){\circle{10}}

\linethickness{0.3mm}
\multiput(25,52.12)(0.24,-0.12){83}{\line(1,0){0.24}}
\linethickness{0.3mm}
\multiput(30,37.12)(0.36,0.12){42}{\line(1,0){0.36}}
\linethickness{0.3mm}
\put(55,42.12){\line(1,0){10}}
\linethickness{0.3mm}
\put(75,42.12){\line(1,0){10}}
\put(20,62.12){\makebox(0,0)[cc]{a}}

\put(30,22.12){\makebox(0,0)[cc]{b}}

\put(50,32.12){\makebox(0,0)[cc]{c}}

\put(70,32.12){\makebox(0,0)[cc]{d}}

\put(90,32.12){\makebox(0,0)[cc]{e}}

\linethickness{0.3mm}
\put(125,60){\line(1,0){10}}
\put(125,50){\line(0,1){10}}
\put(135,50){\line(0,1){10}}
\put(125,50){\line(1,0){10}}
\linethickness{0.3mm}
\put(165,60){\line(1,0){10}}
\put(165,50){\line(0,1){10}}
\put(175,50){\line(0,1){10}}
\put(165,50){\line(1,0){10}}
\linethickness{0.3mm}
\put(185,60){\line(1,0){10}}
\put(185,50){\line(0,1){10}}
\put(195,50){\line(0,1){10}}
\put(185,50){\line(1,0){10}}
\linethickness{0.3mm}
\put(205,60){\line(1,0){10}}
\put(205,50){\line(0,1){10}}
\put(215,50){\line(0,1){10}}
\put(205,50){\line(1,0){10}}
\linethickness{0.3mm}
\put(145,40){\line(1,0){10}}
\put(145,30){\line(0,1){10}}
\put(155,30){\line(0,1){10}}
\put(145,30){\line(1,0){10}}
\linethickness{0.3mm}
\put(122.73,85){\line(1,0){14.54}}
\put(122.73,45){\line(0,1){40}}
\put(137.27,45){\line(0,1){40}}
\put(122.73,45){\line(1,0){14.54}}
\linethickness{0.3mm}
\put(202.72,65){\line(1,0){14.55}}
\put(202.72,25){\line(0,1){40}}
\put(217.27,25){\line(0,1){40}}
\put(202.72,25){\line(1,0){14.55}}
\linethickness{0.3mm}
\put(182.73,65){\line(1,0){14.54}}
\put(182.73,25){\line(0,1){40}}
\put(197.27,25){\line(0,1){40}}
\put(182.73,25){\line(1,0){14.54}}
\linethickness{0.3mm}
\put(162.73,65){\line(1,0){14.54}}
\put(162.73,25){\line(0,1){40}}
\put(177.27,25){\line(0,1){40}}
\put(162.73,25){\line(1,0){14.54}}
\linethickness{0.3mm}
\put(142.73,45){\line(1,0){14.54}}
\put(142.73,5){\line(0,1){40}}
\put(157.27,5){\line(0,1){40}}
\put(142.73,5){\line(1,0){14.54}}
\linethickness{0.3mm}
\put(125,80){\line(1,0){10}}
\put(125,70){\line(0,1){10}}
\put(135,70){\line(0,1){10}}
\put(125,70){\line(1,0){10}}
\linethickness{0.3mm}
\put(145,20){\line(1,0){10}}
\put(145,10){\line(0,1){10}}
\put(155,10){\line(0,1){10}}
\put(145,10){\line(1,0){10}}
\linethickness{0.3mm}
\put(165,40){\line(1,0){10}}
\put(165,30){\line(0,1){10}}
\put(175,30){\line(0,1){10}}
\put(165,30){\line(1,0){10}}
\linethickness{0.3mm}
\put(185,40){\line(1,0){10}}
\put(185,30){\line(0,1){10}}
\put(195,30){\line(0,1){10}}
\put(185,30){\line(1,0){10}}
\linethickness{0.3mm}
\put(205,40){\line(1,0){10}}
\put(205,30){\line(0,1){10}}
\put(215,30){\line(0,1){10}}
\put(205,30){\line(1,0){10}}
\put(130,35){\makebox(0,0)[cc]{a}}

\put(150,0){\makebox(0,0)[cc]{b}}

\put(170,20){\makebox(0,0)[cc]{c}}

\put(190,20){\makebox(0,0)[cc]{d}}

\put(210,20){\makebox(0,0)[cc]{e}}

\linethickness{0.3mm}
\put(130,60){\line(0,1){10}}
\put(130,60){\vector(0,-1){0.12}}
\linethickness{0.3mm}
\put(170,40){\line(0,1){10}}
\put(170,40){\vector(0,-1){0.12}}
\linethickness{0.3mm}
\put(190,40){\line(0,1){10}}
\put(190,40){\vector(0,-1){0.12}}
\linethickness{0.3mm}
\put(210,40){\line(0,1){10}}
\put(210,40){\vector(0,-1){0.12}}
\linethickness{0.3mm}
\put(150,20){\line(0,1){10}}
\put(150,20){\vector(0,-1){0.12}}
\linethickness{0.3mm}
\put(135,55){\line(1,0){30}}
\put(165,55){\vector(1,0){0.12}}
\linethickness{0.3mm}
\multiput(175,55)(0.12,-0.24){83}{\line(0,-1){0.24}}
\put(175,55){\vector(-1,2){0.12}}
\linethickness{0.3mm}
\multiput(195,55)(0.12,-0.24){83}{\line(0,-1){0.24}}
\put(195,55){\vector(-1,2){0.12}}
\linethickness{0.3mm}
\put(155,35){\line(1,0){10}}
\put(155,35){\vector(-1,0){0.12}}
\end{picture}
\clearpage{}
\end{centering}
\caption{\label{fig:ExempleBG3}Example of our buffer graph (on the right) for Destination  on the network (on the left).}
\end{figure}

To avoid livelocks, we use a fair scheme of selection of processors allowed to forward or to emit a message for each reception buffer. We can manage this fairness by a queue of requesting processors. Finally, we use a specific flag to prevent message losses. It is composed of the identity of the last processor cross over by the message and a  which is dynamically given to the message when it reaches an emission buffer. In order to distinguish a such incoming message of these contained in reception buffers of neighbors of the considered processor, we give to this incoming message a  which is not carried by a such message. It is why a message is considered as a triplet  in our algorithm where  is the useful information of the message,  is the identity of the last processor crossed over by the message, and  is a color (a natural integer between  and ).

We must manage a communication between our algorithm and processors in order to know when a processor have a message to send. We have chosen to create a Boolean shared variable  (for any processor ). Processor  can set it at  when it is at  and when  has a message to send. Otherwise,  must wait that our algorithm sets the shared variable to  (that is done when a message is generated).

The reader can find a complete example of the execution of our algorithm in Figure \ref{fig:ExempleExecution}. Diagram  shows the network and diagram  shows the initial configuration for the connected component associated to  of the buffer graph. We observe that , so we need 4 different values for the variable , we have chosen to represent them by a natural integer in .  Remark that routing tables are incorrect (in particular there exists a cycle involving buffers of  and ) and that there exists an invalid message  in the reception buffer of  (its  is ). Then, Processor  emits a message  (its  is ) in the reception buffer of  to obtain configuration . When the message  is forwarded to the emission buffer of , we associate it the   (since  is forbidden, see configuration ). During the next step, message  is forwarded to the reception buffer of  (remark that it keeps its ) and  emits (in its reception buffer) a new message  which has the same useful information as the invalid message present on . So, we obtain configuration . Message  can now be erased from the emission buffer of  and  can be forwarded into this buffer (we associate it the  ). These two steps lead to configuration . Assume that routing tables are repaired during the next step. Simultaneously, processor  is allowed to forward  into its emission buffer. We obtain configuration . Remark that the use of  forbids the merge between the two messages which have  for useful information. Then, the system is able to deliver these three messages by the repetition of moves that we have described: 
\begin{itemize}
\item forwarding from reception buffer to emission buffer of the same processor.
\item forwarding from emission buffer to reception buffer of two processors.
\item erasing from emission buffer or delivering.
\end{itemize}
The sequence of configuration  to  shows an example of the end of our execution.

\begin{figure}
\noindent \begin{centering}
\includegraphics[scale=0.29]{ExempleExecution.eps}
\par\end{centering}
\caption{\label{fig:ExempleExecution}An example of execution of our first algorithm.}
\end{figure}

\subsection{Algorithm}

We now present formally our protocol in Algorithm \ref{algo:AN}. We call it \AN for nap-tabilizing essage orwarding rotocol 1. In order to simplify the presentation, we write the algorithm for Destination  only. Obviously, each destination of the network needs a similar algorithm. Moreover, we assume that all these algorithms run simultaneously (as they are mutually independent, this assumption has no effect on the provided proof).

\begin{algorithm}
\caption{\label{algo:AN}(\AN): Message forwarding protocol for Processor  with Destination .}
\small{
\begin{description}
\item [Data:] ~\\
- : natural integer equals to the number of processors of the network.\\
- : set of processor identities of the network.\\
- : set of neighbors of .\\
- : natural integer equals to the maximal degree of the network.
\item [Message:] ~\\
-  with  useful information of the message,  identity of the last processor crossed over by the message, and  a color. The message destination is the buffer index.
\item [Variables:] ~\\
- , : buffers which can contain a message or be empty (denoted by ).
\item [Input/Output:] ~\\
- : Boolean. The higher layer can set it to  when its value is  and when there is a waiting message. We consider that this waiting is blocking.
\item [Macros:] ~\\
- : gives the message waiting in the higher layer.\\
- : gives the destination of  if it exists,  otherwise.
\item [Procedures:] ~\\
- : neighbor of  given by the routing algorithm for Destination .\\
- : fairly chooses one of the processors which can forward or generate a message in , \emph{i.e.}  satisfies predicate  . We can manage this fairness with a queue of length  of processors which satisfies the predicate.\\
- : delivers the message  to the higher layer of .\\
- : gives a natural integer  between  and  such as ,  does not contain a message with  as color.
\item [Rules:] ~\\
\textbf{/{*}} Rule for the generation of a message \textbf{{*}/}\\
\\
\textbf{/{*}} Rule for the internal forwarding of a message \textbf{{*}/}\\
\\
\textbf{/{*}} Rule for the forwarding of a message \textbf{{*}/}\\
\\
\textbf{/{*}} Rule for the erasing of a message after its forwarding
\textbf{{*}/}\\
\\
\textbf{/{*}} Rule for the erasing of a message after its duplication
\textbf{{*}/}\\
\\
\textbf{/{*}} Rule for the consumption of a message \textbf{{*}/}\\

\end{description}

 The fact that  may be different of  implies that the message was in the system at the initial configuration. We could locally delete this message but this does not improve the performance of \AN.}
\end{algorithm}

\subsection{Proof of correctness}

In order to simplify the proof, we introduce a second specification of the problem. This specification allows message duplications.

\begin{specification} [\textbf{}] \label{specif:spe1}
Specification of message forwarding problem allowing duplication.
\begin{itemize}
\item Any message can be generated in a finite time.
\item Any valid message is deliver to its destination in a finite time.
\end{itemize}
\end{specification}

In this section, we prove that \AN is a snap-stabilizing message forwarding protocol for specification .  For that, we are going to prove successively that:
\begin{enumerate}
\item \AN is a snap-stabilizing message forwarding protocol for specification  if routing tables are correct in the initial configuration (Lemmas \ref{lem:avanceN}, \ref{lem:depotN}, \ref{lem:transportN} and Proposition \ref{prop:snapTRN}). 
\item \AN is a self-stabilizing message forwarding protocol for specification  even if routing tables are corrupted in the initial configuration (Proposition \ref{prop:selfN}). 
\item \AN is a snap-stabilizing message forwarding protocol for specification  even if routing tables are corrupted in the initial configuration (Lemmas \ref{lem:perteN}, \ref{lem:duplicationN} and Theorem \ref{th:snapN}).
\end{enumerate}

In this proof, we consider that the notion of message is different from the notion of useful information. This implies that two messages with the same useful information generated by the same processor are considered as two different messages. We must prove that the algorithm does not lose one of them thanks to the use of the flag. Let  be a configuration of the network. We say that a message  is existing in  if at least one buffer contains  in . We say that  is existing on  in  if at least one buffer of  contains  in .

\begin{definition} [Caterpillar of a message ] \label{def:caterpillarN}
Let  be a message of Destination  existing on a processor  in a configuration . We define a caterpillar associated to  as the longest sequence of buffers that satisfies one of the three definitions below:
\begin{enumerate}
\item Caterpillar of type 1: . 
\item Caterpillar of type 2: . 
\item Caterpillar of type 3: . 
\end{enumerate}
\end{definition}

The reader can find in Figure \ref{fig:CaterpillarN} an example for each type of caterpillar. Remark that an emission buffer can belong to several caterpillars of type 3.

\begin{figure}
\begin{centering}
\includegraphics[scale=0.35]{ExempleChenille1.eps}
\par\end{centering}
\caption{\label{fig:CaterpillarN}Examples of caterpillar associated to  on  (from left to right: two of type 1, one of type 2 and one of type 3).}
\end{figure}

\begin{lemma} \label{lem:avanceN}
Let  be a configuration in which routing tables are correct. Let  be a message existing on  in . Under a weakly fair daemon, the execution of \AN products in a finite time one of the following effects for any caterpillar of type 1 associated to :
\begin{itemize}
\item  is delivered to its destination.
\item the caterpillar disappeared on  and there exists a caterpillar of type 1 associated to the same message on . 
\end{itemize}
\end{lemma}

\begin{proof}
Let  be a configuration in which routing tables are correct. Let  (of Destination ) be a message existing in . Let  be a caterpillar of type 1 associated to . Denote by  the distance between  and  (). We are going to prove the result by induction on . We define the following predicate:

: if  is a caterpillar of type 1 associated to  such that , then, under a weakly fair daemon, the execution of \AN products one of the following effect in a finite time:

\begin{itemize}
\item  is delivered to . 
\item  disappeared on  and there exists a caterpillar of type 1 associated to the same message on . 
\end{itemize}

\begin{description}
\item [Initialization:] We are going to prove that  is true.\\
Let  be a caterpillar of type 1 associated to  such that . This implies that . Let be . We must distinguish two cases :

\begin{description}
\item [Case 1:] .\\
The rule  is enabled for the processor . We can observe that this rule can not be neutralized. Since we assumed a weakly fair daemon, we obtain that  executes  in a finite time. We can then consider the case 2 since this rule erases the content of .
\item [Case 2:] .\\
By the definition of a caterpillar of type 1,  is enabled for . This rule can be neutralized if and only if  is occupied by . This is impossible by the construction of . Since we assume a weakly fair daemon, we obtain that  executes  in a finite time.  disappears and a new caterpillar of type 2 appears in . By the same reasoning of the case 1, we can say that  executes  in a finite time. This implies that  is delivered to .
\end{description}

We proved that  is true.

\item [Induction:] Let . We assume that  is true. We are going to prove that then  is true.\\
Let  be a caterpillar of type 1 associated to  such that . Let be . We must distinguish two cases:

\begin{description}
\item [Case 1:] .\\
Let be .

\begin{description}
\item [Case 1.1:]  is occupied by a caterpillar  of type 2.\\
By the definition of a caterpillar of type 2, either  or  is enabled on  if and only if .

\begin{description}
\item [Case 1.1.a:] If , then  executes  or  (since we assumed a weakly fair daemon and these rules cannot be neutralized). The result of this execution depends on the value of :

\begin{itemize}
\item If , then  becomes a caterpillar of type 3. We are now in the case 1.2. 
\item If , then a message   is forwarded in . So,  remains a caterpillar of type 2 and we are in the case 1.1.b. It is important to remark that the fairness of  guarantees us that this case cannot appear infinitely. 
\end{itemize}

\item [Case 1.1.b:] If , then we can distinguish two cases:

\begin{itemize}
\item If  belongs to at least one caterpillar of type 3, we can apply the reasoning of the case 1.2 to  and conclude that  belongs to a caterpillar of type 1 in a finite time. 
\item If  belongs to a caterpillar of type 1, we can say that  becomes empty in a finite time by application of  ( since routing tables are correct). Then, we are on the case 1.1.a. 
\end{itemize}

\end{description}

We can conclude that  belongs to a caterpillar of type 3 associated to  in a finite time. So, we are on the case 1.2.

\item [Case 1.2:]  belongs to at least one caterpillar of type 3.

\begin{description}
\item [Case 1.2.a:]  belongs to at least two caterpillars of type 3.\\
This implies that there exists , . The processor  is enabled by  infinitely (since routing tables are correct and  cannot erase  by the construction of ). Since we assumed a weakly fair daemon, ) is erased from  in a finite time. We can repeat this reasoning until  belongs to only one caterpillar of type 3 since the construction of  guarantees us that it is impossible to create a new caterpillar of type  involving . So, we are on the case 1.2.b.
\item [Case 1.2.b:]  belongs to only one caterpillar of type 3.\\
By the definition of a caterpillar of type 3, we can say that  is enabled for . The construction of  guarantees us that it is impossible to create a new caterpillar of type  involving , also  is not neutralized. As we assumed a weakly fair daemon,   executes  in a finite time. Then,  is empty in a finite time, we are in the case 2.
\end{description}

\end{description}

We can conclude the case 1 by the following affirmation : we are in the case 2 in a finite time.

\item [Case 2:] .\\
By the definition of a caterpillar of type 1,  is enabled by . By the construction of  and of  (for ),  cannot neutralized for . Since we assumed a weakly fair daemon, we can say that  executes  in a finite time. This implies that  disappears and a new caterpillar  of type 2 associated to  appears. We can now apply the reasoning of the case 1 to deduce that  becomes a caterpillar of type 1 on  in a finite time.
\end{description}

\end{description}

We have proved that  is true, that ended this proof.
\end{proof}

\begin{lemma} \label{lem:depotN}
If routing tables are correct, every processor can generate a first message (\emph{i.e.} it can execute ) in a finite time under a weakly fair daemon.
\end{lemma}

\begin{proof}
Let  be a processor which has a message  (of Destination ) to send. As  has a waiting message, we have  whatever its value in the initial configuration. We must now study two cases:

\begin{description}
\item [Case 1:] .\\
The processor  executes either  or  in a finite time (since we assumed a weakly fair daemon and these rules cannot be neutralized).
The result of this execution depends on the value of :

\begin{itemize}
\item If , then  executes  in a finite time, we obtain the result.
\item If , then  executes  in a finite time. Consequently,  is occupied by a caterpillar of type 3. So, we are in the case 2.1. Note that the fairness of  guarantees us that this case cannot appear infinitely. 
\end{itemize}

\item [Case 2:] .\\

\begin{description}
\item [Case 2.1:]  belongs to a caterpillar  of type 3.\\
We can apply the reasoning of the case 1.2 of the proof of Lemma \ref{lem:avanceN} to  and conclude that  becomes a caterpillar of type  in a finite time. We are now in the case 2.2.
\item [Case 2.2:]  belongs to a caterpillar  of type 1.\\
We can apply Lemma \ref{lem:avanceN} to  and say that  becomes empty in a finite time. We are now in the case 1.
\end{description}

\end{description}

By the remark of the case 1, this reasoning is finite, that proves the result.
\end{proof}

\begin{lemma} \label{lem:transportN}
If a message  is generated by \AN in a configuration in which routing tables are correct, \AN delivers  to its destination in a finite time under a weakly fair daemon.
\end{lemma}

\begin{proof}
Assume that routing tables are correct when \AN accepts a message  (of Destination ) on Processor . This implies that  generated  executing rule . This rule leads to the creation of a caterpillar of type 1 associated to  in . Since routing tables are assumed correct and constant, the result follows from  applications of Lemma \ref{lem:avanceN}.
\end{proof}

\begin{proposition} \label{prop:snapTRN}
\AN is a snap-stabilizing message forwarding protocol for  if routing tables are correct in the initial configuration.
\end{proposition}

\begin{proof}
Assume that routing tables are correct in the initial configuration. To prove that \AN is a snap-stabilizing message forwarding protocol for specification , we must prove that :

\begin{enumerate}
\item If a processor  requests to send a message, then the protocol is initiated by at least one starting action on  in a finite time. In our case, the starting action is the execution of . Lemma \ref{lem:depotN} proves this property. 
\item After a starting action, the protocol is executed according to . If we consider that  have been executed at least one time, we can prove that:

\begin{itemize}
\item The first property of  is always satisfied (following Lemma \ref{lem:depotN} and the fact that the waiting for the sending of new messages is blocking). 
\item The second property of  is always satisfied (following Lemma \ref{lem:transportN}). 
\end{itemize}

\end{enumerate}

Consequently, we deduce the proposition.
\end{proof}

\begin{proposition} \label{prop:selfN}
\AN is a self-stabilizing message forwarding protocol for  (even if routing tables are corrupted in the initial configuration) when  runs simultaneously.
\end{proposition}

\begin{proof}
Remind that  is a self-stabilizing silent algorithm for computing routing tables running simultaneously to \AN. Moreover, we assumed that  has priority over \AN (\emph{i.e.} a processor which have enabled actions for both algorithms always chooses the action of ). This guarantees us that routing tables are correct and constant in a finite time regardless of the initial state. 

By Proposition \ref{prop:snapTRN}, \AN is a snap-stabilizing message forwarding protocol for specification  when it starts from a such configuration. Consequently, we obtain the proposition.
\end{proof}

\begin{lemma} \label{lem:perteN}
Under a weakly fair daemon, \AN does not delete a valid message without deliver it to its destination even if  runs simultaneously.
\end{lemma}

\begin{proof}
By contradiction, let  be a valid message which is deleted without being delivered to its destination.

By the construction of the rule , this cannot be the result of an internal forwarding since the message is sequentially copied in  and erased from .

By the construction of rules  and , this cannot be the result of the execution of  (since we are guaranteed that  is in  and cannot be erased from this buffer simultaneously).

By the construction of rules  and ,  cannot be erased from  in the step in which it is erased from .

Since we have seen that a simultaneous erasing is impossible, the hypothesis implies that  is erased from a buffer  without being copied in another buffer.

The only rule which erases a message from  and does not deliver  is . If a processor  executes this rule, then we have  and . Assume that the message contained by  is not the result of the application of rule  on . If this message was in  before  came in , we obtain a contradiction with
the definition of . This implies that this message came in  after  came in . Then, the construction of  allows us to say that  contains a message  with  (since we have supposed that the message does not come from ). We obtain a contradiction. We can conclude that, when we have  and , the message   has been copied at least one time. This result contradicts the existence of .
\end{proof}

\begin{lemma} \label{lem:duplicationN}
Under a weakly fair daemon, \AN never duplicates a valid message even if  runs simultaneously.
\end{lemma}

\begin{proof}
Since the emission of a message creates one caterpillar of type 1 by the construction of the rule , it remains to prove the following property : if a caterpillar of type 1 associated to a message  is present on a processor  and this message is erased from all buffers of , then only one neighbor of  contains a caterpillar of type 1 associated to  or  have been delivered to its destination.

Let  be a caterpillar of type 1 associated to a message  (of Destination ) on a processor . Since  is not enabled for  (by definition of a caterpillar of type 1),  is erased from  by . So,  is still present on  (since it has been copied in ). Then, we have two cases to observe:

\begin{description}
\item [Case 1:] .\\
The only rule for erasing  which can be enabled is . This rule delivers  to its destination.
\item [Case 2:] .\\
The only rule for erasing  which can be enabled is . The construction of this rule implies the announced property.
\end{description}

We can conclude that  is delivered at most once to its destination, that proves the result.
\end{proof}

\begin{theorem} \label{th:snapN}
\AN is a snap-stabilizing message forwarding protocol for  (even if routing tables are corrupted in the initial configuration) when  run simultaneously.
\end{theorem}

\begin{proof}
Proposition \ref{prop:selfN} and Lemma \ref{lem:perteN} allows us to conclude that \AN is a snap-stabilizing message forwarding protocol for specification  even if routing tables are corrupted in the initial configuration on condition that  runs simultaneously.

Then, using this remark and Lemma \ref{lem:duplicationN}, we obtain the result.
\end{proof}

\subsection{Time complexities}\label{sub:analyseN}

Since our algorithm needs a weakly fair daemon, there is no points to do an analysis in terms of steps. It is why all the following complexities analysis are given in rounds. Let  be the stabilization time of  in terms of rounds.

In order to lighten this paper, we present only key ideas of this section proofs.

\begin{proposition} \label{prop:analysemesN}
For any Processor , \AN delivers  invalid messages to  in the worst case.
\end{proposition}

\begin{sketchproof}
In the initial configuration, the system has at most  distinct invalid messages of Destination  (since the connected component of the buffer graph associated to  has  buffers). In the worst case, all these invalid messages are delivered to their destination, that allows us to reach the announced bound.
\end{sketchproof}

\begin{proposition} \label{prop:complexiteN}
In the worst case, a message  (of Destination ) needs  rounds to be delivered to  once it has been generated by its source.
\end{proposition}

\begin{sketchproof}
In a first time, we show by induction the following result: if  is a configuration in which routing tables are correct and  is a caterpillar of type 1 associated to a message  (of Destination ) on a processor  such as , then  is delivered to  or there exists a caterpillar of type 1 associated to  on  in at most  rounds. This result is due to the fairness of  which can allow at most  messages to ``pass''  (see the proof of Lemma \ref{lem:avanceN}). 

Then, consider that  is the source of a message  of Destination . We have  by definition. We can conclude that  is delivered in at most  rounds if routing tables are correct when  is emitted. 

Finally, we can deduce the result when  is emitted in a configuration in which routing tables are not correct since the message is delivered in at most  rounds after routing tables computation (which takes at most  rounds if  is not delivered during the routing tables computation since we have assumed the priority of  over \AN).
\end{sketchproof}

\begin{proposition} \label{prop:delaiN}
The delay (waiting time before the first emission) and the waiting time (between two consecutive emissions) of \AN is  rounds in the worst case.
\end{proposition}

\begin{sketchproof}
Let  be a processor which has a message of Destination  to emit. By the fairness of , we can say that  is generated after at most  releases of  (see proof of Lemma \ref{lem:avanceN}). The result of Proposition \ref{prop:complexiteN} allows us to say that  is released in  rounds at worst. Indeed, we can deduce the result.
\end{sketchproof}

The complexity obtained in Proposition \ref{prop:complexiteN} is due to the fact that the system delivers a huge quantity of messages during the forwarding of the considered message. It's why we interest now in the amortized complexity (in rounds) of our algorithm. For an execution , this measure is equal to the number of rounds of  divided by the number of delivered messages during  (see \cite{CLRS02} for a formal definition).

\begin{proposition} \label{prop:amortieN}
The amortized complexity (to forward a message) of \AN is   rounds.
\end{proposition}

\begin{sketchproof}
In a first time, we must prove the following property: if  is a configuration in which at least one message of Destination  is present and in which routing tables are correct, then \AN delivers at least one message to  in the  rounds following . 

The proof of this property is done as follows. Let  be the smallest number such that there exists a message of Destination  on a processor  which satisfy . Then, we prove that, after at most three rounds, there exists a message (not necessarily ) on a processor  which satisfies . Since  in , we obtain the announced property.
 
Assume now an initial configuration in which routing tables are correct. Let  be one execution leads to the worst amortized complexity. Let  be the number of rounds of . By the previous property, we can say that \AN delivers at least  messages during . So, we have an amortized complexity of . Then, the announced result is obvious.
\end{sketchproof}

\subsection{Conclusion}

In this section, we prove that we can adapt the ``destination-based'' deadlock-free controller defined in \cite{MS78} to obtain a snap-stabilizing message forwarding algorithm. Our algorithm is mainly based on the control of effects of routing tables moves on message. This control is performed in two ways. Firstly, we ``slow down'' messages by using two buffers per processor in order to control the number of copy of a same message in the network at a given time. Secondly, we use a specific flag to avoid message merge or duplication.

The initial fault-free protocol uses  buffers for the whole network and our protocol uses  buffers. Consequently, our protocol ensures a stronger safety and fault-tolerance with respect the initial one without a significant overcost in space. Our time analysis (see Section \ref{sub:analyseN}) shows that this stronger safety does not leads to an overcost in time.
 
\section{Second protocol}\label{sec:protocolD}

\subsection{Informal description}

In this section, we give a second snap-stabilizing message forwarding protocol adapted to the ``distance-based'' deadlock-free controller (see Section \ref{sec:survey}). Our idea is to adapt this scheme in order to tolerate transient faults. To perform this goal, we assume the existence of a self-stabilizing silent (\emph{i.e.} no actions are enabled after convergence) algorithm  to compute routing tables which runs simultaneously to our message forwarding protocol. Moreover, we assume that  has priority over our protocol (\emph{i.e.} a processor which has enabled actions for both algorithms always chooses the action of ). This guarantees us that routing tables are correct and constant in a finite time. To simplify the presentation, we assume that  induces only minimal paths in number of edges. We assume that our protocol can have access to the routing table via a function, called . This function returns the identity of the neighbor of  to which  must forward messages of Destination . 

Our idea is as follows. We choose exactly the same graph buffer as \cite{MS78} and we allow the erasing of a message only if we are assured that the message has been delivered to its destination. In this goal, we use an acknowledgment scheme which guarantees the reception of the message.

More precisely, we associate to each copy of the message a type which has 3 values:  (Sending),  (Acknowledgment) and  (Fail). Forwarding of a valid message follows the above scheme:

\begin{enumerate}
\item Generation with type  in a buffer of rank .
\item Forwarding (with copy in buffers of increasing rank) with type  without any erasing.
\item If the message reaches its destination :
\begin{enumerate}
\item It is delivered and the copy of the message takes type .
\item Type  is propagated to the sink of the message following the income path.
\item Buffers are allowed to free themselves once the type  is propagated to the previous buffer on the path.
\item The sink erases its copy, that performs the erasing of the message.
\end{enumerate}
\item Otherwise, (the message reaches a buffer of rank  without cross its destination) :
\begin{enumerate}
\item The copy of the message takes type .
\item Type  is propagated to the sink of the message following the income path.
\item Buffers are allowed to free themselves once the type  is propagated to the previous buffer on the path.
\item Then, the sink of the message gives the type  to its copy, that begin a new cycle (the message is sending once again).
\end{enumerate}
\end{enumerate}

Obviously, it is necessary to take in account invalid messages: we have chosen to let them follow the forwarding scheme and to erase them if they reach step 4.d.

The key idea of the snap-stabilization of our algorithm is the following: since a valid message is never erased, it is sent again after the stabilization of routing tables (if it never reached its destination before) and it is then normally forwarded. 

To avoid livelocks, we use a fair scheme of selection of processors allowed to forward a message for each buffer. We can manage this fairness by a queue of requesting processors. Finally, we use a specific flag to prevent message losses. It is composed of the identity of the next processor on the path of the message, the identity of the last processor cross over by the message, the identity of the destination of the message and the type of the message (,  or ).

We must manage a communication between our algorithm and processors in order to know when a processor has a message to send. We have chosen to create a Boolean shared variable  (for any processor ). Processor  can set it at  when it is at  and when  has a message to send. Otherwise,  must wait that our algorithm sets the shared variable to  (when a message is sent out).

\subsection{Algorithm}

We now present formally our protocol in Algorithm \ref{algo:AD}. We call it \AD for nap-tabilizing essage orwarding rotocol 2.

\begin{algorithm}
	\caption{\label{algo:AD}\AD : Message forwarding protocol for processor .}
\small{
		\textbf{Data:}\\
			-  : natural numbers equal resp. to the number of processors and to the diameter of the network.\\
			-  : set of processor identities of the network.\\
			-  : set of neighbors of .\\
		\textbf{Message:}\\
			-  with  useful information of the message, 
			identity of the next processor to cross for the message (when it reaches the node), 
			 identity of the last processor cross over by the message,  
			identity of the destination of the message,  type of the message.\\
		\textbf{Variables:}\\
			- ,  : buffer which can contain a message or be empty (denoted by )\\
		\textbf{Input/Output:}\\
			-  : Boolean. The higher layer can set it to "true" when its value is "false"
			and when there is a waiting message. We consider that this waiting is blocking.\\
			- : gives the message waiting in the higher layer.\\
			- : gives the destination of  if it exists,  otherwise.\\
		\textbf{Procedures:}\\
			- : neighbor of  given by the routing for Destination  (if , we choose arbitrarily ).\\
			- : fairly chooses one of the processors which can send a message
			in , \emph{i.e.}  satisfies predicate 
			. 
			We can manage this fairness with a queue of length  of processors which satisfies the
			predicate.\\
			- : delivers the message  to the higher layer
			of .\\
		\textbf{Rules:}
			\begin{description}
				\item \textbf{/*} Rules for the buffer of rank  \textbf{*/}\\
					\textbf{/*} Generation of messages \textbf{*/}\\
					 ::  with \\
					\textbf{/*} Processing of acknowledgment \textbf{*/}\\
					 ::  \\
					 ::  \\
					\textbf{/*} Management of messages which reach their destinations \textbf{*/}\\
					 ::  \\
					 ::  \\
					 :: 
				\item \textbf{/*} Rule for buffers of rank  to  : propagation of acknowledgment \textbf{*/}\\
					 :: 
					 
				\item \textbf{/*} Rules for buffers of rank  to  \textbf{*/}\\
					\textbf{/*} Forwarding of messages \textbf{*/}\\
					 :: 
					\\
			\textbf{/*} Erasing of messages of which the acknowledgment has been forwarded \textbf{*/}\\
				 :: 
		\item \textbf{/*} Rules for buffers of rank  to  \textbf{*/}\\
			\textbf{/*} Consumption of a message and generation of the acknowledgment  \textbf{*/}\\
			 ::  \\
	\textbf{/*} Erasing of messages of destination  of which the acknowledgment has been forwarded \textbf{*/}\\
			 :: 
			\end{description}
}
\end{algorithm}

\begin{algorithm}
	\begin{description}
		\item \textbf{End of Algorithm \ref{algo:AD}:}
\small{
			\item \textbf{/*} Rules for the buffer of rank  \textbf{*/}\\
			\textbf{/*} Forwarding of messages \textbf{*/}\\
			 ::  
			\textbf{/*} Generation of the acknowledgment  \textbf{*/}\\
			 ::  \\
			\textbf{/*} Erasing of messages of which the acknowledgment has been forwarded \textbf{*/}\\
			 ::  
		\item \textbf{/*} Correction rules: erasing of tail of abnormal caterpillars of type  (\emph{cf.} definitions below) \textbf{*/}\\
			 ::  \\
			 ::  \\
			 ::  \\
			 :: 
}
	\end{description}
\end{algorithm}

\subsection{Proof of correctness}

In order to simplify the proof, we introduce a second specification of the problem. This specification allows message duplications.
      
\begin{specification} []
Specification of message forwarding problem allowing duplication.
\begin{itemize}
\item Any message can be send out in a finite time.
\item Any valid message is delivered to its destination in a finite time.
\end{itemize}
\end{specification}

In this section, we prove that \AD is a snap-stabilizing message forwarding protocol for specification . For that, we are going to prove successively that:

\begin{enumerate}
\item Copies of a same message have a particular structure. Then, we prove some properties on the behavior of these structures under \AD(Lemmas \ref{lem:prelem1}, \ref{lem:prelem2}, \ref{lem:prelem3}, and \ref{lem:prelem4}).
\item \AD is a snap-stabilizing message forwarding protocol for specification  if routing tables are correct in the initial configuration (Lemmas \ref{lem:chenilleSA}, \ref{lem:depotD}, \ref{lem:transportD} and Proposition \ref{prop:snapTRD}). 
\item \AD is a self-stabilizing message forwarding protocol for specification  even if routing tables are corrupted in the initial configuration (Proposition \ref{prop:selfD}).
\item \AD is a snap-stabilizing message forwarding protocol for specification  even if routing tables are corrupted in the initial configuration (Lemmas \ref{lem:perteD}, \ref{lem:duplicationD} and Theorem \ref{th:snapD}).
\end{enumerate}

In this proof, we consider that the notion of message is different from the notion of useful information. This implies that two messages with the same useful information sent by the same processor are considered as two different messages. We must prove that the algorithm does not loose one of them thanks to the use of the flag.

\paragraph{Preliminaries.}In a first time, we define a particular structure of messages and we study the behavior of these structure under \AD. Let  be a configuration of the network. We say that a message  is existing in  if at least one buffer contains  in .

\begin{definition} [Caterpillar of a message ] 
Let  be a message of Destination  existing in a configuration . We define a caterpillar associated to  (noted ) as the longest sequence of buffers  (with ) which satisfies:
\begin{itemize}
\item ,  and .
\item , .
\item , .
\item , .
\item , 
\end{itemize}
We call respectively , , and  the tail, the head, and the length of .
\end{definition}

We give now some characterization for caterpillars.

\begin{definition} [Characterization of caterpillar of a message ]
Let  be a message of Destination  in a configuration  and  () a caterpillar associated to . Then,
\begin{itemize}
\item  is a normal caterpillar if . It is abnormal otherwise ().
\item  is a caterpillar of type  if ,  (\emph{i.e.} ).
\item  is a caterpillar of type  if ,  (\emph{i.e.} ).
\item  is a caterpillar of type  if ,  (\emph{i.e.} ).
\end{itemize}
\end{definition}

It is obvious that, for each caterpillar , either  is normal or abnormal. In the same way,  is only of type ,  or . The reader can find in Figure \ref{fig:CaterpillarD} an example for some type of caterpillar. 

\begin{figure}
\begin{centering}
\includegraphics[scale=0.4]{ExempleChenille2.eps}
\par\end{centering}
\caption{\label{fig:CaterpillarD}Examples of caterpillar (at left: abnormal of type , at right: normal of type ).}
\end{figure}

\begin{lemma} \label{lem:prelem1}
Let  be a configuration and  be a message of Destination  existing in . Under a weakly fair daemon, every abnormal caterpillar of type  (resp. ) associated to  disappears in a finite time or become a normal caterpillar of type  (resp. ).
\end{lemma}

\begin{proof}
Let  be a configuration of the network. Let  be an existing message (of Destination ) in . Let  ( and ) be a normal caterpillar of type  or   associated to . Let  be the type of .

\begin{enumerate}
\item By definition of caterpillar of type , we have . We can deduce that  and then  is enabled for . This rule can not be neutralized since Processor  is not enabled by a rule affecting its buffer of rank . As the daemon is weakly fair,  executes these rule in a finite time. We can repeat this reasoning  times on Processors . Then, we obtain a caterpillar which all buffers are on type  in a finite time.
\item If , we can directly go to case 4. Otherwise (), we must distinguish the following cases:

\begin{description}
\item [Case 1:] .\\
Processor  is the enabled for rule  by definition of a caterpillar and the fact that all buffers of  are of type . Note that Processor  is not enabled. Consequently, this rule remains infinitely enabled for . Since the daemon is weakly fair,  executes this rule in a finite time. Then,  is empty in a finite time.
\item [Case 2:] .\\

\begin{description}
\item [Case 2.1:] .\\
Then, Processor  is enabled for rule  by definition of a caterpillar and the fact that all buffers of  are of type . Note that Processor  is not enabled. Consequently, this rule remains infinitely enabled for . Since the daemon is weakly fair,  executes this rule in a finite time. Then,  is empty in a finite time.
\item [Case 2.2:] .\\
Assume that . Then, Processor  is enabled for rule  by definition of a caterpillar and the fact that all buffers of  are of type . Note that Processor  is not enabled and that Processor  cannot forward a message  in its buffer of rank  (since  is of type ). Consequently, this rule remains infinitely enabled for . Since the daemon is weakly fair,  executes this rule in a finite time. Then,  is empty in a finite time.
\end{description}

\end{description}

\item By following a reasoning similar to the one of case 2.2, we can prove that  executes  sequentially in a finite time
\item Then, we obtain a caterpillar of type  of length  satisfying . Assume that . We can distinguish the following cases:

\begin{description}
\item [Case 1:] .

\begin{description}
\item [Case 1.1:]  .\\
By the definition of a caterpillar of type  of length  and the hypothesis,  is enabled for rule  (if ) or  (if ). By a reasoning similar to the one of case 2.2 above, these rule remains infinitely enabled. Since the daemon is weakly fair,  executes this rule in a finite time. Consequently,  becomes empty in a finite time. Then,  disappears.
\item [Case 1.2:] .\\
Assume that . Then,  belongs to . This contradicts the fact that  is of type . Consequently, . 

If , then the execution of rule  by  leads to the merge of two caterpillars of type . Then, consider the new caterpillar   (with ). If , then we have a normal caterpillar of type . Otherwise, we can restart the reasoning (we are ensured that this reasoning is finite since we have  at each step).

Consider now the case . By definition of a caterpillar of type  of length  and the hypothesis,  is enabled by rule  (if ) or  (if ). By a reasoning similar to the one of case 2.2 above, these rule remains infinitely enabled. Since the daemon is weakly fair,  executes this rule in a finite time. Consequently,  becomes empty in a finite time. Then,  disappears.
\end{description}

\item [Case 2:] .\\
By definition of a caterpillar of type  of length  and the hypothesis,  is enabled by rule  (if ) or  (if ). By a reasoning similar to the one of case 2.2 above, these rule remains infinitely enabled. Since the daemon is weakly fair,  executes this rule in a finite time. Consequently,  becomes empty in a finite time. Then,  disappears.
\end{description}

\end{enumerate}

In all cases,  disappears or becomes a normal caterpillar of type  in a finite time, that leads us to the lemma.
\end{proof}

\begin{lemma} \label{lem:prelem2}
Let  be a configuration and  be a message of Destination  existing in . Under a weakly fair daemon, every normal caterpillar of type  associated to  disappears in a finite time.
\end{lemma}

\begin{proof}
Let  be a configuration and  be a message of Destination  existing in . Let  () be a normal caterpillar of type  associated to . We must distinguish the following cases:

\begin{description}
\item [Case 1:] .

\begin{description}
\item [Case 1.1:] .\\
Then, rule  is enabled for . Since the guard of this rule involves only local variables, it remains infinitely enabled. Since the daemon is weakly fair,  executes this rule in a finite time. Consequently,  disappears.
\item [Case 1.2:] .\\
By the definition of a caterpillar and the hypothesis,  is enabled by rule . By a reasoning similar to the one of the case 2.2.2 of the proof of Lemma \ref{lem:prelem1}, we can prove that this rule remains infinitely enabled. Since the daemon is weakly fair,  executes this rule in a finite time. Consequently,  disappears.
\end{description}

\item [Case 2:] .\\
We can apply the reasoning of points 1,2, and 3 of the proof of Lemma \ref{lem:prelem1}. That leads us to case 1.2. 
\end{description}

In all the cases,  disappears in a finite time, that leads us to the lemma.
\end{proof}

\begin{lemma} \label{lem:prelem3}
Let  be a configuration and  be a message of Destination  existing in . Under a weakly fair daemon, every normal caterpillar of type  associated to  becomes a normal caterpillar of type  of length  in a finite time.
\end{lemma}

\begin{proof}
Let  be a configuration and  be a message of Destination  existing in . Let  () be a normal caterpillar of type  associated to . We must distinguish the following cases:

\begin{description}
\item [Case 1:] .

\begin{description}
\item [Case 1.1:] .\\
Then, rule  is enabled for . Since the guard of this rule involves only local variables, it remains infinitely enabled. Since the daemon is weakly fair,  executes this rule in a finite time. Consequently,  becomes a caterpillar of type  of length .
\item [Case 1.2:] .\\
By the definition of a caterpillar and the hypothesis,  is enabled by rule . By a reasoning similar to the one of the case 2.2.2 of the proof of Lemma \ref{lem:prelem1}, we can prove that this rule remains infinitely enabled. Since the daemon is weakly fair,  executes this rule in a finite time. Consequently,  becomes a caterpillar of type  of length .
\end{description}

\item [Case 2:] .\\
We can apply the reasoning of points 1,2, and 3 of the proof of Lemma \ref{lem:prelem1}. That leads us to case 1.2. 
\end{description}

In all cases, we proved that  becomes a caterpillar of type  of length  in a finite time, that leads us to the lemma.
\end{proof}

\begin{lemma} \label{lem:prelem4}
Let  be a configuration and  be a message of Destination  existing in . Under a weakly fair daemon, every caterpillar of type  associated to  becomes a caterpillar of type  or  in a finite time.
\end{lemma}

\begin{proof}
Let  be a configuration of the network and  be a message (of Destination ) existing in . Let  () be a caterpillar of type  associated to .

We prove this result by a decreasing induction on the rank of the buffer occupied by the head of  in . Let us define the following property:

 : If  satisfies , then it becomes a caterpillar of type  or  in a finite time.

\begin{description}
\item [Initialization:] We want to prove that  is true.\\
Let  () be a caterpillar of type  associated to  such that . We must distinguish the following cases:

\begin{description}
\item [Case 1:] .\\
By hypothesis, Processor  is enabled for rule . Since the guard of this rule involves only local variables, it remains infinitely enabled. Since the daemon is weakly fair,  executes this rule in a finite time. Consequently,  becomes a buffer of type  and  becomes a caterpillar of type  in a finite time. Then, Property  is satisfied.
\item [Case 2:] .\\
By hypothesis, Processor  is enabled for rule . Since the guard of this rule involves only local variables, it remains infinitely enabled. Since the daemon is weakly fair,  executes this rule in a finite time. Consequently,  becomes a buffer of type  and  becomes a caterpillar of type  in a finite time. Then, Property  is satisfied.
\end{description}

\item [Induction:] Let be . Assume that  are satisfied. We want to prove that  is then satisfied.\\
Let  () be a caterpillar of type  associated to  such that . We must distinguish the following cases:

\begin{description}
\item [Case 1:] .

\begin{description}
\item [Case 1.1:] .\\
By hypothesis, Processor  is enabled for rule . Since the guard of this rule involves only local variables, it remains infinitely enabled. Since the daemon is weakly fair,  executes this rule in a finite time. Consequently,  becomes a buffer of type  and  becomes a caterpillar of type  in a finite time. Then, Property  is satisfied.
\item [Case 1.2:] .\\
These case is similar to the case 1 of initialization. Consequently,  becomes a caterpillar of type  in a finite time. Then, Property  is satisfied.
\end{description}

\item [Case 2:] .\\


Assume w.l.g. that . We want to prove that the head of  goes up of one buffer in a finite time. We must study the following cases:

\begin{description}
\item [Case 2.1:] .\\

\begin{enumerate}
\item If , then Processor  is enabled by rule . Since Processor  is not enabled, this rule remains infinitely enabled for . Processor  executes this rule in a finite time because the daemon is weakly fair. The result of this execution depends on the value of :

\begin{enumerate}
\item If , then the head of  goes up of one buffer when  executes rule .
\item If , then  takes the value  when  executes rule . This leads us to case 2.b. Note that the fairness of   ensures us that these case can appear only a finite number of times.
\end{enumerate}

\item Consider now that .\\
Assume that  and , then   belongs to  (the type of  is then identical to the one of  ). Consequently, we have a contradiction with the definition of . This implies that  or . Let  be the caterpillar whose  belongs. Consider the three possible cases:

\begin{enumerate}
\item  is of type : we can apply the induction hypothesis to  since its head stays in a buffer of rank greater or equals to . Consequently,  becomes a caterpillar of type  or  in a finite time. That leads us to one of the following cases.
\item  is of type : following Lemmas \ref{lem:prelem1} and \ref{lem:prelem2},  disappears in a finite time. Then,  becomes empty. That leads us to point 1.
\item  is of type :  following Lemmas \ref{lem:prelem1} and \ref{lem:prelem3},  disappears or becomes a caterpillar of type  and length  in a finite time. In all cases,  becomes empty (since ). That leads us to point 1.
\end{enumerate}
\end{enumerate}

\item [Case 2.2:] .\\
Consider the following cases:

\begin{enumerate}
\item .\\
Assume w.l.g. that  and .
By the construction of rule  and the definition of a caterpillar,  is enabled if and only if  is not the tail of an abnormal caterpillar  associated to . Let us study the following cases:

\begin{enumerate}
\item  is of type :  we can apply the induction hypothesis to  since its head stays in a buffer of rank greater or equals to . Consequently,  becomes a caterpillar of type  or  in a finite time. That leads us to one of the following cases.
\item  is of type : following Lemma \ref{lem:prelem1},  disappears in a finite time. Then,  becomes empty.
\item  is of type :  following Lemma \ref{lem:prelem1},  disappears in a finite time (it cannot become a caterpillar of type  and length  since ). Consequently,  becomes empty in a finite time.
\end{enumerate}

Then, Rule  is enabled for  in a finite time. This rule remains infinitely enabled since no message of type  can be copied in  (indeed, the contrary implies that  executes rule  whereas ). Since the daemon is weakly fair,   executes rule  in a finite time. The result of this execution is one of the following:

\begin{enumerate}
\item If , then the head of  goes up of one buffer when  executes rule .
\item If , then  takes the value  when  executes rule . This situation is similar to the one of point 2 below. Note that the fairness of   ensures us that these case can appear only a finite number of times.
\end{enumerate}

\item If , the reasoning is similar to the one of point 2 of case 2.1. Consequently, that leads us to point 1 in a finite time.
\end{enumerate}

In conclusion of case 2 (), the head of  goes up of one buffer in a finite time. Then, the induction hypothesis allows us to state that  becomes a caterpillar of type  or  in a finite time. Consequently,  is satisfied. 
\end{description}
\end{description}
\end{description}
\end{proof}

\paragraph{Snap-stabilization when routing tables are correct in the initial configuration.} Now, we assume that routing tables are correct in the initial configurations and we prove that \AD is a snap-stabilizing algorithm for specification .

\begin{lemma} \label{lem:chenilleSA}
Let  be a configuration in which routing tables are correct  and  be a message of Destination  existing in . Under a weakly fair daemon, every normal caterpillar of type  associated to  becomes a caterpillar of type  in a finite time.
\end{lemma}

\begin{proof}
Let  be a configuration of the network in which routing tables are correct and  be a message (of Destination ) existing in . Let  () be a normal caterpillar of type  associated to .

By Lemma \ref{lem:prelem4},  becomes a caterpillar of type  or  in a finite time. In the first case, the proof ends here. In the second case (which is possible if  in ), it follows by Lemma \ref{lem:prelem3} that  becomes a caterpillar of type  of length  in a finite time. Then, we have: . 

Following Lemma \ref{lem:prelem4},  becomes a caterpillar of type  or  in a finite time. Assume that  becomes a caterpillar of type . This implies that  have been forwarded  times without reach its destination. This result is absurd since we have by definition that  and we assumed that routing tables are correct and constant. Consequently,  becomes a caterpillar of type  in a finite time.
\end{proof}

\begin{lemma} \label{lem:depotD}
If routing tables are correct, every processor can generate a first message (\emph{i.e.} it can execute ) in a finite time under a weakly fair daemon .
\end{lemma}

\begin{proof}
Let  be a processor of the network which have a message  (of Destination ) to forward. As  have a waiting message, the higher layer put  whatever its value in the initial configuration.

Assume that  already contains a message. Let  be the caterpillar which contains this buffer. We must distinguish the following cases:

\begin{description}
\item [Case 1:]  is of type . Following Lemma \ref{lem:prelem3},  becomes a caterpillar of type  in a finite time. That leads us to case 2.
\item [Case 2:]  is of type . Following Lemma \ref{lem:chenilleSA},  becomes a caterpillar of type  in a finite time. That leads us to case 3.
\item [Case 3:]  is of type . Following Lemma \ref{lem:prelem2},  disappears in a finite time.
\end{description}

In all cases, we obtain that  becomes empty in a finite time. It remains empty while  does not execute rule  (since it is the only rule which can put a message in this buffer). In these case,  is enabled for  if and only if . 

Assume that this condition is not satisfied. This implies (by definition of a caterpillar) that  is the tail of an abnormal caterpillar . Following sequentially Lemmas \ref{lem:prelem4} and \ref{lem:prelem1},  disappear in a finite time (note that the merge with  is impossible since this buffer is empty). Moreover,  can not be fill by a message of type  (since  is empty). Consequently, rule  is infinitely enabled for Processor . As the daemon is weakly fair,  executes this rule in a finite time, that leads to the lemma.
\end{proof}

\begin{lemma} \label{lem:transportD}
If a message  is generated by \AD in a configuration in which routing tables are correct, \AD delivers  to its destination in a finite time under a weakly fair daemon.
\end{lemma}

\begin{proof}
The generation of a message  (of Destination ) by \AD results from the execution of rule  by the processor which sends . This rule creates a normal caterpillar of type  associated to . Following Lemma \ref{lem:chenilleSA}, this caterpillar becomes a caterpillar of type  in a finite time. It is due to the execution of rule  or  by . These rules delivers the message to the higher layer of , that ends the proof.
\end{proof}

\begin{proposition} \label{prop:snapTRD}
\AD is a snap-stabilizing message forwarding protocol for  if routing tables are correct in the initial configuration.
\end{proposition}

\begin{proof}
Assume that routing tables are correct in the initial configuration. To prove that \AD is a snap-stabilizing message forwarding protocol for specification , we must prove that :

\begin{enumerate}
\item If a processor  requests to send a message, then the protocol is initiated by at least one starting action on  in a finite time. In our case, the starting action is the execution of . Lemma \ref{lem:depotD} proves this property. 
\item After a starting action, the protocol is executed according to . If we consider that  have been executed at least one time, we can prove that:

\begin{itemize}
\item The first property of  is always satisfied (following Lemma \ref{lem:depotD} and the fact that the waiting for the sending of new messages is blocking). 
\item The second property of  is always satisfied (following Lemma \ref{lem:transportD}). 
\end{itemize}

\end{enumerate}

Consequently, we deduce the proposition.
\end{proof}

\paragraph{Self-stabilization.} Now, we assume that routing tables are corrupted in the initial configurations and we prove that \AD is a self-stabilizing algorithm for specification .

\begin{proposition} \label{prop:selfD}
\AD is a self-stabilizing message forwarding protocol for  even if routing tables are corrupted in the initial configuration when  runs simultaneously.
\end{proposition}

\begin{proof}
Remind that  is a self-stabilizing silent algorithm for computing routing tables running simultaneously to \AD. Moreover, we assumed that  has priority over \AD (\emph{i.e.} a processor which have enabled actions for both algorithms always chooses the action of ). This guarantees us that routing tables are correct and constant in a finite time regardless of their initial states. 

By Proposition \ref{prop:snapTRD}, \AD is a snap-stabilizing message forwarding protocol for specification  when it starts from a such configuration. Consequently, we can conclude on the proposition.
\end{proof}

\paragraph{Snap-stabilization.} We still assume that routing tables are corrupted in the initial configuration and we prove that \AD is a snap-stabilizing algorithm for specification .

\begin{lemma} \label{lem:perteD}
Under a weakly fair daemon, \AD does not delete a valid message without delivering it to its destination even if  runs simultaneously.
\end{lemma}

\begin{proof}
When \AD accepts a new valid message , the processor which sends  executes rule . By construction of the rule, this execution creates a normal caterpillar  of type  associated to .

While  is not delivered to its destination, we know, by Lemmas \ref{lem:prelem4} and \ref{lem:prelem3}, that  follows infinitely often the above cycle:

\begin{itemize}
\item  is of type  and becomes of type  (type  is impossible since  is not delivered).
\item  is of type  and becomes of type .
\end{itemize}

This implies that there always exists at least one copy of  in  (if  is the sending processor of ). Then, this message is not deleted without being delivered to its destination.
\end{proof}

\begin{lemma} \label{lem:duplicationD}
Under a weakly fair daemon, \AD never duplicates a valid message even if  works simultaneously.
\end{lemma}

\begin{proof}
It is obvious that the emission of a message  by rule  only creates one caterpillar of type  associated to . 

Then, observe that all rules are designed to obtain the following property: if a caterpillar has one head in a configuration, it also has one head in the following configuration whatever rules have been applied. Indeed, this property is ensured by the fact that the next processor on the path of a message  is computed (and put in the second field on the message) when  is copied into a buffer  (not when it is forwarded to a neighbor). Consequently, if there is a routing table move after the copy of  in , the caterpillar does not fork. The head of the caterpillar remains unique.

We can conclude that, for any valid message , there always exists a unique caterpillar  associated to . Assume that  is delivered. By construction of rules  and ,  becomes of type . Following Lemma \ref{lem:prelem2},  disappears in a finite time. Consequently,  cannot be delivered several times.
\end{proof}

\begin{theorem} \label{th:snapD}
\AD is a snap-stabilizing message forwarding protocol for  even if routing tables are corrupted in the initial configuration when  runs simultaneously.
\end{theorem}

\begin{proof}
Proposition \ref{prop:selfD} and Lemma \ref{lem:perteD} allows us to conclude that \AD is a snap-stabilizing message forwarding protocol for specification  even if routing tables are corrupted in the initial configuration on condition that  runs simultaneously.

Then, using this remark and Lemma \ref{lem:duplicationD}, we obtain the result.
\end{proof}

\subsection{Time complexities} \label{sub:analyseD}

Since our algorithm needs a weakly fair daemon, there is no points to do an analysis in terms of steps. It is why all the following complexities analysis are given in rounds. Let  be the stabilization time of  in terms of rounds.

In order to lighten this paper, we present only key ideas of this section proofs.

\begin{proposition} \label{prop:analysemesD}
In the worst case,  invalid messages are delivered to Processor .
\end{proposition}

\begin{sketchproof}
In the initial configuration, the system has at most  distinct invalid messages of Destination . Then, the number of invalid messages deliver to  is in . 

We can obtain the lower boundwith a chain of  processors labeled . Assume that all buffers of rank least or equals to  initially contain a message of destination  and other buffers are empty. Moreover, assume that routing tables are initially correct. Then, \AD delivers all invalid messages of this initial configuration to . This initial configuration contains  invalid messages. The result follows.
\end{sketchproof}

\begin{proposition} \label{prop:complexiteD}
In the worst case, a message  (of Destination ) needs  rounds to be delivered to  once it has been sent out by its source.
\end{proposition}

\begin{sketchproof}
In a first time, one must prove by induction the following fact: if  is a configuration in which routing tables are correct and in which a message of Destination  exists and  is a caterpillar of type  associated to  which head is a buffer of rank  on , then the head of  goes up of one buffer in at most  round if there exists no abnormal caterpillar whose tail is a buffer of rank greater than .

In a second time, it is possible to show that , the set of abnormal caterpillars in  looses at least one element during the  rounds which follow . Then, we can say that, when routing tables are correct, an accepted message is forwarded in at most  rounds.

Finally, we can deduce the result when  is emitted in a configuration in which routing tables are not correct since the message is delivered in at most  rounds after routing tables computation (which takes at most  rounds if  is not delivered during the routing tables computation since we have assumed the priority of ).
\end{sketchproof}

\begin{proposition} \label{prop:delaiD}
The delay (waiting time before the first emission) and the waiting time (between two consecutive emissions) of \AD is  rounds in the worst case.
\end{proposition}

\begin{sketchproof}
Let  be a processor which has a message of Destination  to emit. By the fairness of , we can say that  is sent after at most  releases of . The result of Proposition \ref{prop:complexiteD} allows us to say that  is released in  rounds at worst. Indeed, we can deduce the result.
\end{sketchproof}

The complexity obtained in Proposition \ref{prop:complexiteD} is due to the fact that the system delivers a huge quantity of messages during the forwarding of the considered message. It's why we interest now in the amortized complexity (in rounds) of our algorithm. For an execution , this measure is equal to the number of rounds of  divided by the number of delivered messages during  (see \cite{CLRS02} for a formal definition).

\begin{proposition} \label{prop:amortieD}
The amortized complexity (to forward a message) of \AD is in   rounds when there exists no invalid messages.
\end{proposition}

\begin{sketchproof}
In a first time, we must prove the following property: if  is a configuration in which at least one caterpillar of type   is present, routing tables are correct, and there exists no invalid messages, then \AD delivers at least one message to a processor in the  rounds following .

Assume now an initial configuration in which routing tables are correct and in which there exists no invalid messages. Let  be one execution which leads to the worst amortized complexity. Let  be the number of rounds of . By the last remark, we can say that \AD delivers at
least  messages during . So, we have an amortized complexity of . Then, the announced result is obvious.
\end{sketchproof}

\subsection{Conclusion}

In this section, we prove that we can adapt the ``distance-based'' deadlock-free controller defined in \cite{MS78} to obtain a snap-stabilizing message forwarding algorithm. Our algorithm is mainly based on an acknowledgement scheme. Each message is re-emitted until it reaches its destination. As routing tables stabilize in a finite time, we are ensured that, in the worst case, the message is re-emitted after the end of computation of routing tables. Hence, it can reach its destination normally.

The initial fault-free protocol uses  buffers for the whole network and our protocol uses exactly the same number of buffers. Consequently, our protocol ensures a stronger safety and fault-tolerance with respect the initial one without overcost in space. Our time analysis (see Section \ref{sub:analyseD}) shows that this stronger safety does not leads to an overcost in time.

\section{Conclusion}\label{sec:Conclusion}

In this paper, we provide the first algorithms (at our knowledge) to solve the message forwarding problem in a snap-stabilizing way (when a self-stabilizing algorithm for computing routing tables runs simultaneously) for a specification which forbids message losses and duplication. This property implies the following fact: our protocol can forward any emitted message to its destination regardless of the state of routing tables in the initial configuration. Such an algorithm allows the processors of the network to send messages to other without waiting for the routing table computation. We use a tool called ``buffer graph'' which has been introduced in \cite{MS78}. This paper proposed an adaptation of two "buffer graphs" in order to control the effect of routing table moves on messages. Our analysis shows that we ensure snap-stabilization without significant overcost in space or in time with respect to the fault-free algorithm.

\cite{MS78} also proposed other buffer graphs. So, it is natural to wonder if they could be adapted to tolerate transient faults. In particular, one of them (based on the acyclic covering of the network, see also \cite{T01}) is very interesting since it needs less buffers per processor in general (3 for a ring, 2 for a tree...). But, authors of \cite{KR07} show that it is NP-hard to compute the size of the acyclic covering of any graph. So, this buffer graph cannot be easily applied to any network. A very important open problem is the following: what is the minimal number of buffers per processor to allow snap-stabilization on the message forwarding problem ?

Another way to improve our protocol is to speed up the message forwarding in the worst case (without increasing amortized complexity). In this goal, we believe that we can keep our protocol and modify the fair scheme of selection of messages . In fact, the complexity of our algorithm depends on the number of messages which can ``pass'' a specific message at each hop.

Our protocol has the following drawback: when a message  is delivered to a processor ,  cannot determine if  is valid or not. This can bring some problems for applications which use these messages. So, an interesting way of future researches could be to design a protocol which solves this problem. In \cite{CDV06} the authors propose an efficient solution for the PIF problem that deals with a similar problem, unfortunately their approach does not seem suitable for our problem.

Finally, it would be interesting to carry our protocol in the message passing model (a more realistic model of distributed system) in order to enable snap-stabilizing message forwarding in a real network. To our knowledge, in this model, only two snap-stabilizing protocols exist in the literature (\cite{DDNT08,DT06}). The problem to carry automatically a protocol from the state model to the message passing model is still open. 



\newpage

\bibliographystyle{plain}
\bibliography{Biblio}

\end{document}
