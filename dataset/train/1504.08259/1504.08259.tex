\documentclass{CSML}

\pdfoutput=1

\usepackage{lastpage}


\def\dOi{13(3:23)2017}
\lmcsheading {\dOi}
{1--\pageref{LastPage}}
{}
{}
{Mar.~24, 2016}
{Sep.~13, 2017}
{}

\usepackage[hidelinks]{hyperref}
\usepackage{multirow,array}
\usepackage{amssymb,verbatim,color,amsthm}
\usepackage{slashbox}
\usepackage{subfigure}\usepackage{amsmath}
\newcommand{\ZZ}{\mathbb{Z}}

\usepackage{fixmath}


\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}

\usepackage[color=light gray]{todonotes}
\presetkeys{todonotes}{inline}{}



\makeatletter{}\newcommand{\Paragraph}[1]{\noindent\textbf{#1}}
\newcommand{\aut}{\mathcal{A}}
\newcommand{\editInclude}[1]{\subseteq^E_{#1}}

\newcommand{\PTIME}{\textsf{PTime}}
\newcommand{\PSPACE}{\textsf{PSpace}}
\newcommand{\EXPTIME}{\textsf{ExpTime}}
\newcommand{\NEXPTIME}{\textsf{NExpTime}}
\newcommand{\coNP}{\textsf{coNP}}
\newcommand{\NP}{\textsf{NP}}
\newcommand{\undecidable}{undecidable}

\newcommand{\class}{\mathcal{C}}

\newcommand{\DFA}{\mathsf{DFA}}
\newcommand{\NFA}{\mathsf{NFA}}
\newcommand{\PDA}{\mathsf{PDA}}
\newcommand{\DPDA}{\mathsf{DPDA}}

\newcommand{\TED}{\mathsf{TED}}
\newcommand{\FED}{\mathsf{FED}}
\newcommand{\INC}{\mathsf{INC}}

\newcommand{\N}{\mathbb{N}}

\newcommand{\T}{\widehat{T}}
\newcommand{\lang}{\mathcal{L}}
\newcommand{\G}{\mathcal{G}}
\newcommand{\R}{\textsf{R}}
\newcommand{\prefix}[1]{\textsf{prefix}(#1)}
\newcommand{\algoFEDPDADFA}{\textsf{InfEdsSeq}}

\definecolor{darkgreen}{RGB}{00,180,00}
\newcommand{\ed}{ed}
\newcommand{\wed}{wed}

\newcommand{\jotop}[1]{\textcolor{blue}{#1}}
\newcommand{\rasmus}[1]{\textcolor{darkgreen}{#1}}

 

\newtheorem{theorem}{Theorem}
\newtheorem{corollary}[theorem]{Corollary}
\newtheorem{proposition}[theorem]{Proposition}
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{definition}[theorem]{Definition}
\newtheorem{remark}[theorem]{Remark}
\newtheorem{claim}[theorem]{Claim}
\newtheorem{example}[theorem]{Example}
\newcommand{\NN}{\mathbb{N}}
\usepackage{tikz}

\usetikzlibrary{arrows,automata,shapes,decorations,calc,matrix,decorations.pathmorphing}


\newcommand{\conJ}[1]{\textcolor{red}{#1}}

\title[Edit Distance for Pushdown Automata]{Edit Distance for Pushdown Automata}
\author[K.~Chatterjee]{Krishnendu Chatterjee\rsuper a}
\address{{\lsuper{a,b,c}}IST Austria}
\email{\{krishnendu.chatterjee, tah, rasmus.ibsen-jensen\}@ist.ac.at}

\author[T.~A.~Henzinger]{Thomas A. Henzinger\rsuper b}
\address{\vspace{-18 pt}}


\author[R.~Ibsen{-}Jensen]{Rasmus Ibsen{-}Jensen\rsuper c}
\address{\vspace{-18 pt}}


\author[J.~Otop]{Jan Otop\rsuper d}
\address{{\lsuper d}University of Wroc≈Çaw}
\email{jotop@cs.uni.wroc.pl}

\thanks{This research was funded in part by the European Research Council (ERC) under grant 
agreement 267989 (QUAREM), by the Austrian Science Fund (FWF) projects S11402-N23 (RiSE) and Z211-N23 (Wittgenstein Award),
FWF Grant No P23499- N23, FWF NFN Grant No S11407-N23 (RiSE), 
ERC Start grant (279307: Graph Games), MSR faculty fellows award, and 
by the National Science Centre (NCN), Poland under grant 2014/15/D/ST6/04543.}


\begin{document}
\maketitle

\makeatletter{}\begin{abstract}
The edit distance between two words  is the minimal number of word 
operations (letter insertions, deletions, and substitutions) 
necessary to transform  to .
The edit distance generalizes to languages , where 
the edit distance from  to  is the minimal number  such that for every word 
from  there exists a word in  with edit distance at most .
We study the edit distance computation problem between pushdown automata 
and their subclasses.
The problem of computing edit distance to a pushdown automaton is undecidable,
and in practice, the interesting question is to compute the edit distance 
from a pushdown automaton (the implementation, a standard model for programs with 
recursion) to a regular language (the specification).
In this work, we present a complete picture of decidability and complexity
for the following problems: (1)~deciding whether, for a given threshold , the edit distance from a pushdown automaton to a finite
automaton is at most , and
(2)~deciding whether the edit distance from a pushdown automaton to a finite automaton is finite.
\end{abstract}
 

\section{Introduction}
\makeatletter{}\noindent{\em Edit distance.}
The edit distance~\cite{levenshtein1966binary} between two words is a well-studied 
metric, which is the minimum number of edit operations (insertion, deletion, 
or substitution of one letter by another) that transforms one word to 
another. 
The edit distance between a word  to a language  is the minimal 
edit distance between  and words in . 
The edit distance between two languages  and  is the supremum over 
all words  in  of the edit distance between  and .

\smallskip\noindent{\em Significance of edit distance.}
The notion of {\em edit distance} provides a quantitative measure of 
``how far apart'' are (a)~two words, (b)~words from a language, and (c)~two 
languages.
It forms the basis for quantitatively comparing sequences, a problem that 
arises in many different areas, such as error-correcting codes, 
natural language processing, and computational biology.
The notion of edit distance between languages forms the foundations of a 
quantitative approach to verification.
The traditional qualitative verification (model checking) question is the 
\emph{language inclusion} problem: given an implementation (source language) 
defined by an automaton  and a specification (target language) 
defined by an automaton , decide whether the language 
 is included in the language  
(i.e., ). 
The \emph{threshold edit distance} () problem is a generalization of the 
language inclusion problem, which for a given integer threshold 
asks whether every word in the source language  has edit 
distance at most  to the target language  
(with  we have the traditional language inclusion problem).
For example, in simulation-based verification of an implementation against a 
specification, the measured trace may differ slightly from the 
specification due to inaccuracies in the implementation. 
Thus, a trace of the implementation may not be in the specification. 
However, instead of rejecting the implementation, one can quantify the 
distance between a measured trace and the specification.
Among all implementations that violate a specification, the closer the 
implementation traces are to the specification, the 
better~\cite{Chatterjee08quantitativelanguages,chatterjee2012nested,ModelMeasuring}.
The edit distance problem is also the basis for {\em repairing} 
specifications~\cite{riveros,boundedRiveros}. 

The  problem answers a fine-grained question with a fixed bound on the number of edit operations. 
A related problem, the \emph{finite edit distance} () problem, asks
whether there exists  such that the answer to the  problem with threshold
 is YES. Hence, in verification applications we ask the  question first, 
and in case of the positive answer, we can ask the  question.




\smallskip\noindent{\em Our models.}
In this work we consider the edit distance computation problem between two 
automata  and , where  and  can be (non-)deterministic finite 
automata or pushdown automata.
Pushdown automata are the standard models for programs with recursion, 
and regular languages are canonical to express the basic properties of systems 
that arise in verification.
We denote by DPDA (resp., PDA) deterministic (resp., non-deterministic) 
pushdown automata, and DFA (resp., NFA) deterministic 
(resp., non-deterministic) finite automata.
We consider source and target languages defined by DFA, NFA, DPDA, and PDA. 
We first present the known results and then our contributions.

\smallskip\noindent{\em Previous results.}
The main results for the classical language inclusion problem are as follows~\cite{HU79}: 
(i)~if the target language is a DFA, then it can be solved in polynomial time;
(ii)~if either the target language is a PDA or both source and target languages are DPDA, 
then it is undecidable; 
(iii)~if the target language is an NFA, then (a) if the source language
is a DFA or NFA, then it is -complete, and (b) if the source language 
is a DPDA or PDA, then it is -hard and can be solved in  
(to the best of our knowledge, there is a complexity gap where the upper 
bound is  and the lower bound is ). 
The  and  problems were studied for DFA and NFA. 
The  problem is -complete, when the source and target languages are 
given by DFA or NFA~\cite{riveros,boundedRiveros}. 
When the source language is given by a DFA or NFA, the  problem is: 
(i)~-complete, when the target language is given by a DFA~\cite{boundedRiveros},
(ii)~-complete, when the target language is given by an NFA~\cite{boundedRiveros}.


\begin{table}[t]
\begin{subtable}
\centering\centering
\begin{tabular}{|c|c|c|c|c|}
\hline
&  &   &  &  \\ 
\hline
 & \multirow{2}{*}{} & \PSPACE-c   & 
  &  \\
\cline{1-1}
\cline{3-4}
{} &  & \textbf{\EXPTIME-c~(Th.~\ref{th:mainTED})} & 
\multicolumn{2}{c|}{ {\undecidable}} \\
\hline
\end{tabular}
\caption{Complexity of the language inclusion problem from  to . Our results are boldfaced.
}
\label{tab:complexityOfINC}
\end{subtable}

\begin{subtable}
\centering\centering
\begin{tabular}{|c|c|c|c|c|}
\hline
&  &   &  &  \\ 
\hline
 & \coNP-c~\cite{boundedRiveros} & \PSPACE-c~\cite{boundedRiveros}   & 
 open~(Conj.~\ref{conj:FEDisUndec}) &  \\
\cline{1-4}
\multirow{2}{*}{} &   \textbf{-complete}& \textbf{\EXPTIME-c} & 
\multicolumn{2}{c|}{\multirow{2}{*}{ \textbf{\undecidable~(Prop.~\ref{p:undecidable})}}} \\
&  \textbf{(Th.~\ref{th:FEDonDFAcoNP})}    & \textbf{(Th.~\ref{th:FEDmain})}  &   \multicolumn{2}{c|}{}\\
\hline
\end{tabular}
\caption{Complexity of . Our results are boldfaced.
}
\label{tab:complexityOfFED}
\end{subtable}

\begin{subtable}
\centering\centering
\begin{tabular}{|c|c|c|c|c|}
\hline
&  &   &  &  \\ 
\hline
 & \multicolumn{2}{c|}{ \PSPACE-c~\cite{riveros}}   & 
\textbf{\undecidable~(Prop.~\ref{th:fromDPDAUndecidable})} & \\
\cline{1-4}
{} &   \multicolumn{2}{c|}{\textbf{\EXPTIME-c (Th.~\ref{th:mainTED} (1))}} & \multicolumn{2}{c|}{\undecidable}   \\
\hline
\end{tabular}
\caption{Complexity of . Our results are boldfaced.\hspace{3cm}}
\label{tab:complexityOfTED}
\end{subtable}
\end{table}




\smallskip\noindent{\em Our contributions.}
Our main contributions are as follows.
\begin{enumerate}
\item We show that the  problem is -complete, when the source 
language is given by a DPDA or a PDA, and the target language is given by 
a DFA or NFA. 
We present a hardness result which shows that the  problem is -hard 
for source languages given as DPDA and target languages given as DFA. 
We present a matching upper bound by showing that for source languages given 
as PDA and target languages given as NFA the problem can be solved in . 
As a consequence of our lower bound we obtain that the language inclusion 
problem for source languages given by DPDA (or PDA) and target languages given by NFA is -complete.
In contrast, if the target language is given by a DPDA, then the  
problem is undecidable even for source languages given as DFA.
Thus we present a complete picture of the complexity of the  problem, and 
in addition we close a complexity gap in the classical language inclusion problem.
Note that the interesting verification question is when the implementation 
(source language) is a DPDA (or PDA) and the specification (target language)
is given as a DFA (or NFA), for which we present decidability results
with optimal complexity.

\item We also study the  problem.
For finite automata, it was shown in~\cite{riveros,boundedRiveros} that if the answer 
to the  problem is YES, then a polynomial bound on  exists.
In contrast, the edit distance can be exponential between DPDA and DFA.
We present a matching exponential upper bound on  for the  problem 
from PDA to NFA.
We show that when source languages are given as DPDA or PDA, 
the  problem is:
(i)~-complete, if the target languages are given as DFA, and
(ii)~-complete, if the target languages are given as NFA.
\end{enumerate}
The lower bound in (i) holds even for source languages given as DFA~\cite{boundedRiveros}.
Our results are summarized in Tables~\ref{tab:complexityOfINC}, \ref{tab:complexityOfFED}~and~\ref{tab:complexityOfTED}.

This paper extends~\cite{editDistanceConference} in the following two ways:
\begin{itemize}
\item We provide full proofs of all results from~\cite{editDistanceConference}.
\item We show that the  problem is -complete if the source language is given by 
DPDA or PDA and the target language is an DFA. This result is technically involved, but it completes 
the complexity picture for the  problem in case of 
the source language given by a pushdown automaton and the target language given by a finite automaton. 
\end{itemize}

\smallskip\noindent{\em Related work.}
Algorithms for edit distance have been studied extensively for words~\cite{levenshtein1966binary,AhoPeterson,Okuda,Pighizzini,Karp,Mohri}.
The edit distance between regular languages was studied in~\cite{riveros,boundedRiveros},
between timed automata in~\cite{timedEdit}, and between straight line programs 
in~\cite{lifshits2007processing,DBLP:conf/spire/Gawrychowski12}. 
A near-linear time algorithm to approximate the edit distance for a word to a 
{\sc Dyck} language has been presented in~\cite{Saha14}.

 


\section{Preliminaries}
\makeatletter{}\subsection{Words, languages and automata}
\newcommand{\dTree}{\mathcal{D}}

\Paragraph{Words.} 
Given a finite alphabet  of letters, a \emph{word}  is a finite sequence 
of letters.
For a word , we define  as the -th letter of  and  
as its length.
For instance, if , then  and .
We denote the set of all words over  by .
We use  to denote the empty word.

\Paragraph{Pushdown automata.} 
A \emph{(non-deterministic) pushdown automaton} (PDA) is a tuple 
, where 
 is the input alphabet, 
 is a finite stack alphabet,  is a finite set of states, 
 is a set of initial states, 

is a finite transition relation and  is a set of final 
(accepting) states. 
A PDA  is a \emph{deterministic pushdown automaton} (DPDA)
if  and  is a function from  to .
We denote the class of all PDA (resp., DPDA) by  (resp., ).
We define the size of a PDA , denoted by ,
 as .

\Paragraph{Runs of pushdown automata.} Given a PDA  and a word  over ,
a \emph{run}  of  on  is a sequence of elements from 
 of length  such that
 and for every
 either (1)~,
 and , or 
(2)~,
 and .
A run  of length  is \emph{accepting} if , i.e.,
the automaton is in an accepting state and the stack is empty. The \emph{language recognized (or accepted) by }, denoted , is the set of words that have an accepting run.

\Paragraph{Context free grammar (CFG).}  
A context free grammar (CFG) is a tuple , where  is the alphabet,  is a set of {\em non-terminals},  is a {\em start symbol} and  is a set of {\em production rules}.
A production rule  has the following form , where  and .

A CFG in Chomsky normal form (CNF) is the special case in which each production rule  has one of the following forms (recall that  is the start symbol): (1)~, where  and ; or (2)~, where  and ; or (3)~. It is well-known that any CFG can be brought onto CNF in polynomial time~\cite{C59}.

\Paragraph{Languages generated by CFGs.} Fix a CFG . We define \emph{derivation}  as a relation on  as follows:
 iff , with , and  for some  such that  is a production from .
We define  as the transitive closure of . The \emph{language generated by }, denoted by  is the set of words that can be derived from .  
We omit  and write  for  if  is clear from the context and for any non-terminal  and word , we call  an {\em implied production rule}.
For instance, the CFG , where ,  , and the rules  are  and , generates the language .

 It is well-known~\cite{HU79} that CFGs and PDAs are language-wise polynomial equivalent (i.e., there is a polynomial time procedure that, given a PDA,  outputs a CFG of the same language and vice versa).

\Paragraph{Derivation trees of CFGs.} 
Fix a CFG . The CFG defines a (typically infinite) set of {\em derivation trees}. 
A derivation tree is an ordered tree\footnote{In an ordered tree, children 
of every node are ordered.} where (1)~each leaf is associated with an element of ; and (2)~each internal node  is associated with a non-terminal  and production rule , such that  has  children and the -th child, for each , is associated with  if it is a leaf or
a production rule  if it is an internal node.
A derivation tree  defines a string  over  formed by reading labels of the leaves of  in an ascending lexicographic path order (``from left to right'') while skipping  symbols. Existence of a derivation tree  with the root  certifies that 
. 
For instance given  (as in the previous paragraph), the  derivation tree for  is as given in Figure~\ref{fig:ex}.

\begin{figure}
\center
\begin{tikzpicture}[node distance=2cm,-{stealth},shorten >=2pt]
\tikzstyle{every state}=[fill=white,draw=black,text=black,font=\small , inner sep=0.05cm]



\node[state,label=right:] (q1) {};



\node[state,label=right:,below of=q1] (q3) {};
\node[state,label=right:{}] (q2) at () {};
\node[state,label=right:{}] (q4)  at () {};



\node[state,label=right:{},below of=q2] (q5)  {};
\node[state,label=right:{},below of=q4] (q7) {};



\draw (q2) -> (q1);
\draw (q3) -> (q1);
\draw (q4) -> (q1);
\draw (q5) -> (q3);
\draw (q7) -> (q3);
\end{tikzpicture}
\caption{\label{fig:ex}Example of a derivation tree of  for the CFG  given in paragraph "Languages generated by CFGs."}
\end{figure}




\Paragraph{Finite automata.} A \emph{non-deterministic finite automaton} (NFA) is 
a pushdown automaton with empty stack alphabet. We will omit  while referring to 
NFA, i.e., we will consider them as tuples .
We denote the class of all NFA by .
Analogously to DPDA we define \emph{deterministic finite automata} (DFA).

\Paragraph{Language inclusion.} Let  be subclasses of . 
The \emph{inclusion problem from  in } asks, 
given , , whether .


\Paragraph{Single letter operations on words.}
A single letter operation on a word can be either an {\em insertion}, a {\em deletion}, or a {\em substitution}.
Given a  letter  and a number  we define relations  as follows

\begin{itemize}
\item 
the insert relation : for all  we have  iff . For example, . 
\item the delete relation : for all  we have  
iff . For example, . (Note that we ignore the letter parameter for deletions. We use  over a notation like  to ensure that all three types of single letter operations have 2 parameters)
\item the substitution relation : for all  we have  
iff . For example, .
\end{itemize}


\Paragraph{Edit distance between words.} Given two words , the edit 
distance between , denoted by , is the minimal number of single letter operations:
insertions, deletions, and substitutions, necessary to transform  into .
More formally,  is the length of the shortest sequence , 
 where each  is an operation  for each , such that there exist words , , for which (1)~, (2)~ and (3)~ for all .



\Paragraph{Edit distance between languages.} 
Let  be languages. We define the edit distance 
\emph{from}  \emph{to} , denoted , as
.
The edit distance between languages is not a distance function. In particular,
it is not symmetric. 
For example: , while
 because for every , we have 
.

\subsection{Problem statement}

In this section we define the problems of interest. Then, we recall the previous results 
and succinctly state our results. 

\begin{defi}
For   we define the following questions:
\begin{enumerate}
\item \emph{The threshold edit distance problem from  to  (denoted ):} 
Given automata ,  and an integer threshold , 
decide whether .

\item
 \emph{The finite edit distance problem from  to  (denoted ):}
Given automata  , ,
decide whether .


\item \emph{Computation of edit distance from  to :}
Given automata  , ,
compute .
\end{enumerate}
\end{defi}


\noindent We establish the complete complexity picture for the  problem for all combinations of 
source and target languages given by  and :
\begin{enumerate}
\item  for regular languages has been studied in~\cite{riveros}, where 
 -completeness of  for  
has been established.
\item In Section~\ref{s:TEDPDAToRegular}, we study  the  problem 
for source languages given by pushdown automata and target languages given 
by finite automata. 
We establish -completeness of  for
  and .
\item In Section~\ref{s:fromPDA}, we study the  problem for target languages
given by pushdown automata. We show that  is undecidable for 
 and .
\end{enumerate}

\begin{comment}
Table~\ref{tab:complexityOfTED} summarizes the complexity of the  problem.

\begin{table}
\centering
\begin{tabular}{|c|c|c|}
\hline
&   &  \\
\hline
 & \PSPACE-c~\cite{riveros}  &  \multirow{2}{*}{\textbf{\undecidable{} (Prop.~\ref{p:undecidable} and Th.~\ref{th:fromDPDAUndecidable})}}\\
\cline{1-2}
 & \textbf{{\EXPTIME-c (Th.~\ref{th:mainTED})}}  & \\
\hline
\end{tabular}
\caption{Complexity of  with references to the results.}
\label{tab:complexityOfTED}
\end{table}
\end{comment}

\noindent We study the  problem for all combinations of 
source and target languages given by  and  and obtain the following results:
\begin{enumerate}
\item  for regular languages has been studied in~\cite{boundedRiveros}.
It has been shown that for , the problem 
 is -complete, while the problem
 is -complete.
\item We show in Section~\ref{s:FEDPDAtoRegular} that for , 
the problem  is -complete and
the problem  is -complete.
\item We show in Section~\ref{s:fromPDA} that
(1)~for , the problem  is undecidable, and
(2)~the problem  is undecidable.
\end{enumerate}

\begin{rem}
{\bf Weighted edit-distance.} 
One could also consider a notion of weighted edit-distance, where a weight function  is given that to each edit operation and letter assigns a weight.
I.e. inserting a letter  might have a different weight from inserting a letter .
The weighted edit-distance  would then be the minimum sum of weights  over any  and sequence of edit operation ,  
 where  for each , such that there exists words , , for which (1)~, (2)~ and (3)~  for all .
 
 Our results extend to the case where  assigns {\bf positive} weights. There are naturally no differences for the FED case (since if the minimum length is infinite, then so too is the sum of weights). There are no  differences either for the TED case, since the only time it comes up (in the following Claim~\ref{cla:letter-by-letter}) there are no differences.
 
 Allowing  to assign zero or infinite weights leads to distances very different from the classical edit distance, such as the Humming distance,
 or the length difference. Such distances are out of scope of this paper.
\end{rem}


 

\section{Threshold edit distance from pushdown to regular languages}
\makeatletter{}\label{s:TEDPDAToRegular}

In this section we establish the complexity of the  problem
from pushdown to finite automata. 

\begin{thm}
(1)~For  and , the  problem  is -complete.
(2)~For , the language inclusion problem from  in  is -complete.
\label{th:mainTED}
\end{thm}

We establish the above theorem as follows:
In Section~\ref{sec:upperBoundTED}, we present an exponential-time algorithm 
for  (for the upper bound of~(1)). 
Then, in Section~\ref{sec:lowerBoundTED} we show~(2), in a slightly stronger form, 
and reduce it (that stronger problem), to , which shows the -hardness 
part of (1).
We conclude this section with a brief discussion on parametrized complexity 
of  in Section~\ref{sec:parametricTED}.

\subsection{Upper bound}
\label{sec:upperBoundTED}

We present an \EXPTIME\ algorithm that, given (1)~a PDA ; 
(2)~an NFA ; and (3)~a threshold  given in  binary, decides whether 
the edit distance from  to  is above .
The algorithm extends a construction for  by Benedikt et al.~\cite{riveros}.

\paragraph{Intuition.}
The construction uses the idea that for a given word  and an NFA  
the following are equivalent: 
(i)~, and 
(ii)~for each accepting state  of  and for every word , if 
   can reach  from some initial state upon reading , then .
We construct a PDA  which simulates the PDA  and stores in its states all
states of the NFA  reachable with at most  edits. 
More precisely, the PDA  remembers in its states, for every state  of the NFA ,
the minimal number of edit operations necessary to transform the currently read prefix  of the input word 
into a word , upon which  can reach  from some initial state. 
If for some state the number of edit operations exceeds , 
then we associate with this state a special symbol  to denote this.
Then, we show that a word  accepted by the 
PDA  has  iff the automaton  has a run on 
that ends (1)~in an accepting state of simulated , 
(2)~with the simulated stack of  empty, and 
(3)~the symbol  is associated with every accepting state of .


\begin{lem}
Given (1)~a PDA ; (2)~an NFA ; and (3)~a threshold  given in binary, 
the decision problem of whether  can be reduced to the emptiness problem 
for a PDA of size .
\label{l:EDtoPDAreduction}
\end{lem}
\newcommand{\Impact}{\mathsf{Impact}}
\begin{proof}
\newcommand{\QN}{Q_{N}}
\newcommand{\FN}{F_{N}}
\newcommand{\QP}{Q_{P}}
\newcommand{\FP}{F_{P}}
\newcommand{\SP}{S_{P}}
\newcommand{\SN}{S_{N}}
\newcommand{\autImpact}{{\aut_{I}}}
\newcommand{\lpair}[1]{\langle #1 \rangle}
\newcommand{\deltaI}{\delta_I}
Let  (resp., ) be the set of states (resp., accepting states) of .
For  and a word , we define 
 there exists  with  such that  has a run on the word  ending in .
For a pair of states  and , we define   as the minimum number of edits needed to apply to  
so that  has a run on the resulting word from  to .
For all  and , we
can compute  in polynomial time in .
For a state  and a word  let , i.e.,  is the minimal number of edits necessary 
to apply to  such that  reaches   upon reading the resulting word.
We will  first prove the following claim.

\begin{clm}\label{cla:letter-by-letter}We have that \end{clm}
\begin{proof}
Consider a run witnessing .
 As shown by~\cite{WF74} we can split the run into two parts, one sub-run on  ending in , for some , and one sub-run on  starting in . Clearly, the sub-run on  has used  edits and the one on  has used  edits.
\end{proof}


Let  (resp., ) be the set of states (resp., accepting states) of the PDA .
For every word  and every state  such that there is a run on  ending in , we define 
 as a pair 
 in , where  is defined as follows:
for every  we have  if , and 
 otherwise. 
Clearly, the edit distance from  to  exceeds  if there is a 
word  and an accepting state  of  such that  is a pair 
and for every  we have 
(i.e., the word  is in  but any run of  ending in  has distance exceeding ).
 
We can now construct an {\em impact automaton}, a PDA ,
with state space  and the
following transition relation:
A tuple  is a transition of  iff the following conditions hold:
\begin{enumerate}
\item the tuple projected to the first component of its state (i.e., the tuple ) is a transition of , and 
\item the second component  is computed from  using Claim~\ref{cla:letter-by-letter}, i.e.,
for every  we have .
\end{enumerate}
The initial states of  are , where 
 are initial states of  and  is defined as follows.
For every  we have , where  are initial states of 
(i.e.,  a start state of  is a pair of a start state of  together with the vector where the entry describing  is the minimum number of edits needed to get to the state  on the empty word). 
Also, the accepting states are  and for every  we have . 
Observe that for a run of  on  ending in , the vector  is precisely .
Thus, the PDA  accepts a word  iff the edit distance between 
 and  is above . 
Since the size of  is  we obtain 
the desired  result.
\end{proof}


Lemma~\ref{l:EDtoPDAreduction} implies the following:

\begin{lem}\label{l:TEDinexp}
 is in .
\end{lem}
\begin{proof}
Let  and  be an instance of , where
 is a PDA,  is an NFA, and  is a threshold given in binary.
By Lemma~\ref{l:EDtoPDAreduction}, we can reduce  to the emptiness question of 
a PDA of the size .
Since  is exponential in  and
the emptiness problem for PDA can be decided in time polynomial in their size~\cite{HU79},
the result follows.
\end{proof}


\subsection{Lower bound}
\label{sec:lowerBoundTED}

Our -hardness proof of  extends the idea from~\cite{riveros} that shows -hardness of the edit distance for
DFA. The standard proof of -hardness of the universality problem
for ~\cite{HU79} is by reduction to the halting problem of a fixed Turing machine  working on a bounded tape. The Turing machine  is the one that simulates other Turing machines (such a machine is called universal). 
The input to that problem is the initial configuration  and the tape is bounded by its size .  
In the reduction, the NFA recognizes the language of all words that do not encode a valid computation of  starting from the initial configuration , i.e., 
it accepts if one of the following conditions is violated: 
(1)~the given word is a sequence of configurations,
(2)~the state of the Turing machine and the adjacent letters follow from transitions of , 
(3)~the first configuration is 
and (4)~the tape's cells are changed only by , i.e., they do not change values spontaneously.
While violation of conditions (1), (2) and (3) can be checked by a DFA of polynomial size, condition~(4)
can be encoded by a polynomial-size NFA but not a polynomial-size DFA. However, to check~(4)
the automaton has to make only a single non-deterministic choice to pick a position in the encoding of the computation, 
which violates~(4), i.e., the value at that position is different from the value  letters further, which
corresponds to the same memory cell in the successive configuration, and the head
of  does not change it. We can transform a non-deterministic automaton  checking (4) into 
a deterministic automaton  by encoding such a non-deterministic pick using an external letter.
Since we need only one external symbol, we show that  iff
. This suggests the following definition:

\begin{defi}
An NFA  is \emph{nearly-deterministic} if 
 and , where  is a function and in
every accepting run the automaton takes a transition from  exactly once.
\end{defi}

\begin{lem}
There exists a DPDA  such that the problem, given a nearly-deterministic NFA , decide
whether , is -hard.
\label{l:ExpTimeHardness}
\end{lem}


\begin{proof}
\newcommand{\Ap}{\mathcal{A}_P}
\newcommand{\Ar}{\mathcal{A}_N}
\newcommand{\UATM}{{M}_U}
Consider the \emph{linear-space halting} problem for a (fixed) alternating Turing machine (ATM) :
given an input word  over an alphabet , decide whether  halts on  with the tape bounded by .
There exists an ATM , such that
the linear-space halting problem for  is -complete~\cite{Chandra:1981:ALT:322234.322243}.
We show the -hardness of the problem from the lemma statement by reduction from the 
linear-space halting problem for .

Without loss of generality, we assume that existential and universal transitions of  alternate. Fix an input of length .
The main idea is to construct the language  of words that encode valid terminating computation trees of  on the given input. 
Observe that the language  depends on the given input. 
We encode a single configuration of  as a word of length  of the form , where  is a state of . 
Recall that a computation of an ATM is a tree, where every node of the tree is a configuration of ,  
and it is accepting if every leaf node is an accepting configuration.
We encode computation trees   of  by traversing  in pre-order and executing the following:
if the current node has only one successor, then write down the current configuration , terminate it with  
and move down to the successor node in .
Otherwise, if the current node has two successors  in the tree, then write 
down in order (1)~the reversed current configuration ; and (2)~the results of traversals on  and , each surrounded  by parentheses  and , i.e.,
, where  (resp., ) is the result of the traversal of the sub-tree of  rooted at  (resp., ).
Finally, if the current node is a leaf, write down the corresponding configuration and terminate with C_1C_2C_3C_4\,\right)\, \left(\, C_{4} \ldots \\Ar\Ap\Sigma \cup \{\#,\. 
The automaton  is a nearly deterministic NFA that recognizes only (but not all) words 
not encoding valid computation trees of .
More precisely,  accepts in four cases:
(1)~The word does not encode a tree (except that the parentheses may not match as the automaton cannot check that) 
of computation as presented above.
(2)~The initial configuration is different from the one given as the input. 
(3)~The successive configurations, i.e., those that
result from existential transitions or left-branch universal transitions (like  to ), are not valid. 
The right-branch universal transitions, which are preceded by the word ``'', are not checked by . 
For example, the consistency of the transition  to   is not checked by .
Finally, (4)~ accepts words in which at least one final configuration, which is a configuration followed by \UATMC_2C_3\UATM\delta_2\Ar\ApC_2C_{4}\ApC_2^RC_{4}\left(\, C_{3} \ldots \, it can use its stack to check consistency of universal transitions in that sub-word.
We assumed that  does not have consecutive universal transitions. This means that, for example,  does not need to check 
the consistency of  with its successive configuration.
By construction, we have  (recall that  is the language of encodings of computations of  on the given input) and 
 halts on the given input if and only if  fails.
Observe that  is fixed for all inputs, since it only depends on the fixed Turing machine .\end{proof}


Now, the following lemma, which is (2) of Theorem~\ref{th:mainTED}, 
follows from Lemma~\ref{l:ExpTimeHardness}.

\begin{lem}
The language inclusion problem from  to  is -complete.
\label{th:inlusionExpTimeHard}
\end{lem}
\begin{proof}
\newcommand{\Ap}{\mathcal{A}_p}
\newcommand{\Ar}{\mathcal{A}_r}
\newcommand{\Ad}{\mathcal{A}_d}
The  upper bound is immediate (basically, an exponential 
determinization of the NFA, followed by complementation, 
product construction with the PDA, and the emptiness check of the product 
PDA in polynomial time in the size of the product).
-hardness of the problem follows from Lemma~\ref{l:ExpTimeHardness}.
\end{proof}

Now, we show that the inclusion problem of DPDA in nearly-deterministic NFA,
which is -complete by Lemma~\ref{l:ExpTimeHardness},
reduces to . In the reduction, we transform a nearly-deterministic NFA  over the alphabet 
into a DFA  by encoding a single non-deterministic choice by auxiliary letters. 

\begin{lem}
 is -hard.
\label{th:TEDexpHard}
\end{lem}
\begin{proof}
To show -hardness of , 
we reduce the inclusion problem of  in nearly-deterministic NFA to .
Consider a DPDA  and a nearly-deterministic NFA  over an alphabet .
Without loss of generality we assume that letters on even positions are  and 
do not appear on the odd positions.
Let  be the transition relation of , where  is a function
and along each accepting run,  takes exactly one transition from .
We transform the NFA  to a DFA  by extending the alphabet  with external letters .
On letters from , the automaton  takes transitions from . 
On a letter , the automaton  takes the -th transition from .


We claim that  iff 
.
Every word  contains a letter , which does not belong to . 
Therefore, .
But, if we substitute letter  by the letter in the -th transition of , we get a word from . 
If we simply delete the letter , we get a word which does not belong to  as it has letter  on an odd position.
Therefore,  implies 
. 
Finally, consider a word . The automaton  has an accepting run on , which takes exactly once a transition from .
Say the taken transition is the -th transition and the position in  is .
Then, the word , obtained from  by substituting the letter at position  by letter , is accepted by .
Therefore,  implies .
Thus we have  iff .
\end{proof}



\subsection{Parameterized complexity}
\label{sec:parametricTED}

Problems of high complexity can be practically viable if the complexity
is caused by a parameter, which tends to be small in the applications. In this section 
we discuss the dependence of the complexity of  based on its input values.

\begin{proposition}
(1)~There exist a threshold  and a   such that 
the variant of , in which the threshold is fixed to  and DPDA 
is fixed to , is still -complete.
(2)~The variant of , in which the threshold is given in unary and 
 is fixed, is in .
\end{proposition}

\begin{proof}
\noindent\emph{(1):} The inclusion problem of DPDA in nearly-deterministic NFA is
-complete even if a DPDA is fixed (Lemma~\ref{l:ExpTimeHardness}).
Therefore, the reduction in Lemma~\ref{th:TEDexpHard} works for threshold  and fixed DPDA.

\noindent\emph{(2):} In the reduction from Lemma~\ref{l:EDtoPDAreduction}, the resulting PDA has size , where  is a PDA,  is an NFA
and  is a threshold. If  is fixed and  is given in unary, then 
is polynomial in the size of the input and we can decide its non-emptiness in polynomial time.
\end{proof}

Conjecture~\ref{conj1} completes the study of the parametrized complexity of .

\begin{conj}\label{conj1}
The variant of , in which the threshold is given in binary and 
 is fixed, is in .
\end{conj}

 

\section{Finite edit distance from pushdown to regular languages}
\makeatletter{}\label{s:FEDPDAtoRegular}
\newcommand{\nonTerm}{T}
\newcommand{\extNon}{B}
\newcommand{\reach}{\textsf{Reach}}


In this section we study the complexity of the  problem 
from pushdown automata to finite automata. 


\begin{thm}
(1)~For  and  we have the following dichotomy:
for all  either   is 
exponentially bounded in  or  is infinite.
Conversely, for every  there exist a DPDA  and a DFA , both of the size , such that 
 is finite and exponential in  (i.e.,
the dichotomy is asymptotically tight).
(2)~For  the  problem is -complete.
(3)~For  the  problem is -complete.
(4)~Given a PDA  and an NFA , we can compute the edit distance 
 in time exponential in .
\label{th:FEDmain}
\end{thm}

First, we show in Section~\ref{sec:FEDUpperBoundNFA} the dichotomy of (1), 
which together with Theorem~\ref{th:mainTED}, implies the  upper bound for (2).
Next, in Section~\ref{sec:FEDUpperBoundDFA}, we show that  problem is in , which together with the results from~\cite{boundedRiveros}
shows (3). 
Finally, in Section~\ref{sec:FEDLowerBound}, we show that  is 
-hard.
We also present the exponential lower bound for (1).
Conditions (1), (2), and Theorem~\ref{th:mainTED} imply (3)
(by iteratively testing with increasing thresholds upto exponential bounds 
along with the decision procedure from Theorem~\ref{th:mainTED}).

\subsection{Upper bound for NFA}
\label{sec:FEDUpperBoundNFA}

In this section we consider the problem of deciding whether the edit distance from a PDA to an NFA is finite. 

We first give an overview of the section. Let  be an NFA and  a PDA that has  non-terminals. We show (in Lemma~\ref{lem:comp_deco}) that for any word  one can break the word into chunks , such that  and for any  word  defined as  belongs to  (this is in some sense the opposite of the pumping lemma, since the part that {\em cannot} be pumped is small). We then show (this follows from Lemma~\ref{l:FED-equivalences}) that if there is a word  such that , then for every word  defined as above we have
  for all , showing that the edit-distance  is unbounded. On the other hand, clearly, if  for all , then the edit-distance  by definition.


We start with a reduction of the problem. 
Given a language , we define 
 is a prefix of some word from .
We call an automaton  a \emph{safety automaton} if every state of  is accepting. 
Note that automata are not necessarily total, i.e. some states might not have an outgoing transition for some input symbols, and thus a safety automaton does not necessarily accept all words.
Note that for every NFA , the language  is the language of a safety NFA.
We show that  reduces to  from  to safety NFA. 

\begin{lem}\label{lem:prefix_closure}
Let  be a PDA and  an NFA. The following inequalities 
hold: 

\end{lem}
\begin{proof}
Since , we have 
 as the latter is the minimum over a larger set by definition. 

Hence, we only need to show the other inequality.
First observe that for every , upon reading , the automaton  can reach a state from which an accepting state is reachable and thus, an accepting state can be 
reached in at most  steps. 
Therefore, for every  there exists  of length bounded by  such that 
. It follows that .
\end{proof}

\begin{rem}
Consider an NFA  recognizing a language such that .
For every PDA , the edit distance  is bounded by .
\end{rem}



In the remainder of this section we work with context-free grammars (CFGs) instead of PDAs. There are polynomial-time transformations between CFGs and PDAs that preserve the generated language;
switching from PDAs to CFGs is made only to simplify the proofs. 
The following definition and lemma can be seen as a reverse version of the pumping lemma for context free grammars (in that we ensure that the part which can not be pumped is small). 

As an abuse of notation we will think of a sequence of words as both the concatenation of the words and the sequence.
We define .

 \smallskip\noindent{\bf Left and right language. }
For a CFG  and a non-terminal , we define the languages 

Also, the set of directions  is .
We next argue that we can construct a CFG for .

\begin{lem}\label{lem:L(G,A,D)}
Given a CFG , a non-terminal  and a direction , we can construct in polynomial time 
a CFG  for which .
\end{lem}
\begin{proof}
We describe the construction of a CFG for  and the construction for  is similar.

To simplify, we consider  to be on CNF. We construct  as follows: The CFG  consists of two versions of each non-terminal in , one with a star and one without. I.e. for each non-terminal , we have the non-terminals  and  in . The idea is that  derives prefixes of words derivable from  in , which ends just before a . 
The productions are then as follows: 
\begin{itemize}
\item {\bf Non-starred.} Each production of  is also in , which defines the productions for the non-starred non-terminals.
\item {\bf Starred.} For each production  in , there are productions  and  in .
\item {\bf Additional for .} The non-terminal  has the production  in  (no other starred non-terminal can produce any terminal). 
\end{itemize}
The start symbol of  is . 
We next argue that .

\smallskip\noindent{\bf .}
It is easy to see from the productions of  that the only way to remove a starred non-terminal is to eventually replace a  by . By construction this is the last non-terminal in some prefix  of a word in  with start state  and thus . 


\smallskip\noindent{\bf .}
Given a word  in  by definition there is an implied production rule  (in ) for some . 
Given a derivation tree  for the implied production rule , 
it is easy to construct a derivation tree  for  in , indicating that  is in . 
The two trees  and  are identical except as follows:
For a node  in  let  be the corresponding node in . 
 Let  be the leaf in  such that  is the leaf with label  in . 
 The production rule of  is . Then, consider the path  from  to the root of . 
 For each internal node  in  where  has production rule , we have the following:
\begin{itemize}
\item  {\bf  comes from the left child.}  If  goes through the left child, the production rule of  is  and the sub-tree under the right child of  is cut out of  (including that  has no right child in this case).
\item {\bf  comes from the right child.} If  goes through the right child the production rule of  is .
\end{itemize} 
Then, tree  spells the word  and is a derivation tree in . Thus  and the lemma follows.
\end{proof}



\smallskip\noindent{\bf Realizable. }
Given a CFG  in Chomsky normal form, we define the {\em realizable CFG }  (for clarity we do not define it in CNF) that 
\begin{itemize}
\item for each production of the form  in  have the production ,
\item for each production of the form  in  have the production 
\end{itemize}
 and no other productions (the language is then especially over the terminals ). 
A sequence is {\em realizable} if it is a sub-sequence of a word in , i.e., it results from deletion of letters from some word of .

 
\begin{lem}\label{lem:de_word}
Let  be a realizable sequence in .
Then for every sequence of words 
there exist words  such that
 belongs to .
\label{l:meaning-of-realizability}
\end{lem} 
\begin{proof}
\newcommand{\reSeq}{\alpha}
Let .
We consider two cases: Either  or not.

 \smallskip\noindent{\bf The case where . }
Consider a derivation tree  for . We translate it into a derivation tree in  for 
, by replacing each production (which are in ) of the nodes in  with (generalized) productions in .
 
Each leaf node  corresponds to a production . By definition there exists a production  in  and we then simply replace  in  with  in .

Each non-leaf node , with children  and  respectively, corresponds to the use of a production , where the  is the -th letter and  the -th of  for some .
By definition of  we have that there is a production  in  for some . In this case we replace  in  with  in .
(The word  are concatenation of words  and letters derived  by productions  corresponding to . )

 \smallskip\noindent{\bf The case where . }
Find a word  such that  is a sub-sequence of  (letting  be the sequence of positions defining  from ) and do as above with  and the sequence of words  which is an extension of the sequence  of length  by inserting  at the remaining positions (i.e., the extension is such that  is the sub-sequence of  defined by ).
\end{proof}


\smallskip\noindent{\bf Compact -decomposition. }
Given a CFG  with a set of non-terminals of size  and a word , we define 
a \emph{compact -decomposition} of  as  

 such that
\begin{enumerate}
\item for each , there is an associated terminal , such that the sequence  is realizable and .
\item for all , the word  is in . 
\item  and .
\end{enumerate}


\begin{lem}\label{lem:comp_deco}
For every CFG  in CNF, every word  admits a compact -decomposition.
\end{lem}
\smallskip\noindent{\em Intuition.} The proof follows by repeated applications of the principle behind the pumping lemma, until the part which is not pumped is small.
\begin{proof}
Fix some  and consider some word  in  and some derivation tree  for .
 We will greedily construct a compact -representation, using that we do not give bounds on . 

 \smallskip\noindent{\bf Greedy traversal and the first two properties. }
 The idea is to consider nodes of  in a depth first pre-order traversal (ensuring that when we consider some node we have already considered its ancestors). 
 When we consider some node , we continue with the traversal, 
 unless there exists a descendant  of , such that . 
 If there exists such a descendant, let  be the bottom-most descendant (pick an arbitrary one if there are more than one such bottom-most descendants) such that . 
 We say that  forms a {\em pump pair} of .
Consider subword  of  derived by subtrees of  with roots at  and  respectively.
 We can then write  as 
 (and hence ), for some  and  in the obvious way and  and  will correspond to  and  respectively for some  ( and  are defined by the traversal that we have already assigned  's then we first visit  and then assign  as the  and then we return to the parent of , we have assigned  's and assign  to be ). 

 Furthermore,  is associated with  and  is associated with . 
Observe that  implies that  and  and we therefore have ensured the first property of compact -representation. 
 This also shows that we can replace  with  and  with  (because, clearly ) and the new word is in . 
 Hence,  is in , showing the second property of compact -representation.
 This furthermore defines a derivation tree  for  (which has  occurrences of words ), 
 which is the same as , except that for each pump pair , the node  is replaced with the sub-tree of  with root .
So as to  not split  or  up, we continue the traversal on , which, when it is finished, continues the traversal in the parent of , having finished with .  Notice that this ensures that each node is in at most one pump pair. 


  \smallskip\noindent{\bf The third property. }
  Consider the word  which has  occurrences of words . Observe that in derivation tree  for , there is at most one occurrence of each non-terminal in each path to the root, since we visited all nodes of  in our defining traversal and were greedy. 
  Hence, the height is at most  and thus, since the tree is binary, it has at most  many leaves, which is then a bound on .
Notice that each node of , being a subset of , is in at most  pump pair of . On the other  hand for each pump pair  of , we have that  is a node of  by construction. Hence,  has at most  many pump pairs. Since each pump pair gives rise to at most  word , we have .
\end{proof}

\smallskip\noindent{\bf Sets closed under reachability.}
Fix an NFA.
We say that a set  of states of the NFA is \emph{closed under reachability} if for all  and  we have . Clearly, the set of all states is closed under reachability.

\smallskip\noindent{\bf Reachability sets.}
Fix an NFA.
Given a state  in the NFA and a word , let  be the set of states reachable upon reading , starting in . The set of states  is then the set of states reachable from  upon reading any word. For a set  and word , the set  is . 


Note the following: For all  and  the set  is closed under reachability.
If a set  is closed under reachability then  for all . 

We have the following {\bf property of reachability sets}:  Fix a word , a number , an NFA and a set of states  of the NFA, where  is closed under reachability. Let  be a word with  occurrences of  (e.g. ).
Consider any word  with edit distance strictly less than  from . Any run on , starting in some state of , reaches a state of . This is because  must be a sub-word of . 




\begin{lem}
Let  be a CFG in CNF with a set of non-terminals of size  and let  be a safety NFA with a set of states .
The following conditions are equivalent:
\begin{enumerate}[label=(\roman*)]
\item the edit distance  is infinite,
\item the edit distance  exceeds , and
\item there exists a word , with compact -decomposition
, such that
.
\item there exist words  such that 
 and
for every  
there exist words  such that 
the word  belongs to .
\end{enumerate}
\label{l:FED-equivalences}
\end{lem}

\noindent We use condition~(iv) from Lemma~\ref{l:FED-equivalences} later in Section~\ref{sec:FEDUpperBoundDFA}.
Before we proceed with we argue by example that the nested applications of the  function in Lemma~\ref{l:FED-equivalences}  is necessary.

\smallskip\noindent{\em The necessity of the recursive applications of the  operator.}
Consider for instance the alternate requirement that at least one of  is empty, for some . 
This alternate requirement would not capture that 
the pushdown language  has infinite edit distance to 
the regular language  --- for any word in the pushdown language , for some fixed , a compact -representation of  is ,  and  (and the remaining words are empty). 
But clearly  and  are not empty since both strings are in the regular language. On the other hand  is empty.


\begin{proof}
The implication \textbf{(i)  (ii)} is trivial.

We show the implication \textbf{(ii)  (iii)} as follows: Consider a word  with 
 and its 
compact  representation  (which exists due to Lemma~\ref{lem:comp_deco}).
We claim that .
The argument is by contradiction. Assume that  and we will construct a run of  spelling a word  in , which has edit distance at most  to .
The description of the run is iteratively in ; we start with .
First, spell out a word , so that  reaches some state  such that there exists a run on . The length of  is at most . Afterwards follow the run on  and go to the next iteration. This run spells the word . All the choices of 's can be made since .
Also, since  is a safety automata, this run is accepting.
To edit  into  change each  into  and insert  at the end. In the worst case, each  is empty except for  and in that case it requires   edits for deleting each  and inserting  at the end (in any other case, we would be able to substitute some letters when we change some  into  which would make the edit distance smaller). This is a contradiction. 

The implication \textbf{(iii)  (iv)} is trivial.

For the implication \textbf{(iv)  (i)} we will argue that for all , the word  requires at least  edits.
Consider  for some .
Any run on  (a prefix of ) has entered  or made at least  edits by the property of reachability sets. Similarly, for any , any run on  has either entered  or there has been at least  edits. Since  , no run can enter that set and thus there has been at least  edits on . The implication and thus the lemma follows.
\end{proof}

As a direct consequence of Lemma~\ref{l:FED-equivalences} we have the following.

\begin{thm}
(1)~For a PDA  and an NFA  we have  is either exponentially bounded in 
 or it is infinite.
(2)~For  we have  is in 
\end{thm}
\begin{proof}
(1)~The equivalence of (i) and (ii) gives a bound on the maximum finite edit distance. 

(2)~The argument follows from Lemma~\ref{l:TEDinexp} and (1), i.e., we can check with
Lemma~\ref{l:TEDinexp}  for  exceeding the bound from (1). 
\end{proof}

\subsection{Upper bound for DFA}
\label{sec:FEDUpperBoundDFA}

We show that the problem  is -complete for .


\smallskip\noindent{\bf -hardness and attempting to apply known techniques for the upper bound.}
The lower bound follows directly from the fact that  is -hard~\cite{boundedRiveros}. We thus focus on the upper bound. Note that the upper bound was simple for , since the edit distance for such is either polynomial or infinite and there is a polynomial length witness in case it is infinite. Hence, one just guess the polynomial sized witness~ and runs a polynomial time algorithm for  and the result follows. Doing the similar thing for  would give a  upper-bound, since the word we need to guess might be of exponential length (thus the above  upper bound for  is better). To give our algorithm, we will first define extended reachability sets and give a key proposition.

\smallskip\noindent{\bf Closed under concatenation and extended reachability sets.}
A language  is said to be {\em closed under concatenation} if for all  we have . Note that , for any non-terminal  and direction , is always closed under concatenation.

We extend reachability sets as follows:
Let  be a context-free language closed under concatenation, let  be a DFA and let  be a subset of the states of .
We define  as the intersection . 
Observe that for every  there exists a finite subset  such that .

\begin{rem}\label{rem:R_set}
 If  is closed under reachability, then for any set
  of words such that~, we have that  and  . The latter comes from the fact that for any word  and set  closed under reachability, we have that  for all  and . 
 
Also, observe that we have the following facts about , from the definition of :
\begin{enumerate}
\item For any  and word  we have that .
\item For any language , any  and word , we have that .
\end{enumerate}
  \label{rem:exists_word_equal_to_L}
\end{rem}

The following proposition is a key to our -algorithm.

\begin{proposition}\label{pro:language_to_words}
For any , any sequence of languages  and any word  for each , we have 

Also, if each  is closed under concatenation, then there exist words  for each , such that

\end{proposition}
\begin{proof}

The proposition 
follows from Remark~\ref{rem:exists_word_equal_to_L} and simple induction.
\end{proof}


\smallskip\noindent{\bf -upper bound algorithm.} 
Our -algorithm \algoFEDPDADFA\ deciding whether the edit distance is finite works as follows:
\begin{enumerate}
\item Guess a sequence , for some .
\item return ``no'' if  is such that (1)~ is realizable; and (2) 
\item otherwise return yes.
\end{enumerate}


\smallskip\noindent{\bf Requirements for \algoFEDPDADFA\ to be in .}
For \algoFEDPDADFA\ to be in , we need to give the following:
\begin{enumerate}
\item A polynomial bound on  (so that  is a polynomial sized witness). The bound will be given in Lemma~\ref{l:bound_k}.
\item A polynomial time algorithm to decide whether a sequence  is realizable. The algorithm will be given in Lemma~\ref{l:realizability-polynomial}.
\item A polynomial time algorithm for computing   for any CFG , any non-terminal , any direction  and any set   closed under reachability.
This will allow us to decide, given a realizable sequence , whether 
 
by evaluating the expression on the left-hand side inside-out. The algorithm for computing   will be given in Corollary~\ref{cor:compute-reachable-states}.
\end{enumerate}

We will first argue that the algorithm is correct.

\begin{lem}
The algorithm \algoFEDPDADFA\ is correct\label{l:correct}.
\end{lem}

\begin{proof}
To argue that the algorithm is correct, we just need to argue that a sequence with properties (1) and (2) exists if and only if the edit distance is infinite.

\smallskip\noindent{\bf Such a sequence implies infinite edit distance.}
According to Proposition~\ref{pro:language_to_words}, such a sequence indicates that there are words  for each , such that 

For all , since  is closed under concatenation, we also have  for all .
Thus, by Lemma~\ref{l:meaning-of-realizability}, there exist words  such that
 belongs to .
Hence, item (iv) of Lemma~\ref{l:FED-equivalences} is satisfied and we get that the edit distance is infinite. 

\smallskip\noindent{\bf Infinite edit distance implies the existence of such a sequence.}
When the edit distance is infinite, according to Lemma~\ref{l:FED-equivalences}(iii) there exists a word , with compact -decomposition
, such that
. 
By definition of compact -decomposition, every  from the decomposition is associated with a terminal , such that the sequence  is realizable (satisfying property (1)) and  for each . By Proposition~\ref{pro:language_to_words} we then have that  (satisfying property (1)). Thus such a sequence always exists and the lemma follows.
\end{proof}

Next, we will give the bounds and algorithms to show that \algoFEDPDADFA\ is in . First the bound on . 
\begin{lem}\label{l:bound_k}
Let  be a CFG and let  be a safety DFA with a set of states .
The following conditions are equivalent:
\begin{enumerate}[label=(\roman*)]
\item the edit distance  is infinite.
\item there exists a realizable sequence  with 
such that 
\end{enumerate}
\end{lem}
\begin{proof}
\noindent{\textbf{(i) implies (ii).}}
Assume that  is infinite. By Lemma~\ref{l:FED-equivalences},
there exists a word , with compact -decomposition
, such that
. Observe that  can be exponential. We claim that we can 
pick from  a sub-sequence 
of polynomial length in  for which the reachable set of states is empty as well.
Indeed, the sequence 
is weakly decreasing with respect to the set inclusion (i.e. if a state is not in , then, it cannot be in  for , because  is closed under reachability). 
We select from  indices  on which the sequence   
strictly decreases and denote the resulting sub-sequence by . 
Then, 
There are at most  such indices, therefore .
Using Proposition~\ref{pro:language_to_words}, since  by compact -decomposition,  we get that

and hence is empty.

\noindent{\textbf{(ii) implies (i).}} 
Assume that condition~(ii) holds. Then, the algorithm \algoFEDPDADFA\ returns YES, and its correctness (Lemma~\ref{l:correct}) implies (i).
\end{proof}



Next we will describe the algorithm deciding whether a sequence is realizable.


\begin{lem}
Let  be a CFG.  
We can decide in polynomial time whether
a given sequence  is realizable.
\label{l:realizability-polynomial}
\end{lem}
\begin{proof}
Consider grammar  associated with . 
We convert  to CNF and add productions  for every non-terminal. 
Let the resulting CFG be .
Observe that  derives a word of terminals and non-terminals  if and only if 
 derives a word  such that  is a subsequence of . 
Thus,  is realizable if and only if 
 is derivable by . 
Since  has polynomial size in , we can check whether a word is derivable in  in polynomial time.
\end{proof}

Finally, we present the algorithm that computes . 
The result will follow as a corollary of the following lemma.


\begin{lem}
Given a CFG , such that  is closed under concatenation, a DFA  with a set of states  and a set of states  closed under reachability, 
the set  is computable in polynomial time.
\label{l:compute-reachable-states}
\end{lem}
\begin{proof}
Given a set of states , we define  as the set of states reachable from  in .
We can divide  into strongly connected components (SCCs). 
We say that an SCC  is \emph{recurrent} if  can stay in  upon reading any word from .


We claim that  is the set of states  reachable from all recurrent SCCs in . Clearly,  is closed under reachability.
\begin{itemize}
\item We will first argue that .
First, for every recurrent SCC  and every word , there is a state  such that 
. Therefore, . By Remark~\ref{rem:exists_word_equal_to_L}, it follows that  and . 

\item We will next argue that 
Observe that for every state  in a non-recurrent SCC  there exists a word  that forces  to leave , i.e.,
. Thus, . It follows that we can remove states from 
one by one by concatenating words  to obtain a word  such that .
Since  is closed under concatenation, the word  belongs to .

Let  be the SCCs in  not in  (and thus non-recurrent) ordered topologically. Let the word  be the word .  Observe that . 
We have  by Remark~\ref{rem:exists_word_equal_to_L} and we argue that . 

Any run starting in  will end in , since  is closed under reachability. 
Observe that  does not contain  as 
 and due to topological order  is not reachable from .
Thus, by induction reasoning we have  does not 
contain . Observe that 
, 
and hence . 



 
\end{itemize}


\noindent Given a SCC  and a state , let the automaton  be  restricted to  and with start state .
Observe that a SCC  is recurrent if and only if there is a state  such that . We can then easily test if a SCC is recurrent by trying each possibility for  and testing if . This can be done in polynomial time since language inclusion of a CFG in a DFA can be tested in polynomial time.

Thus our algorithm is as follows: Compute the set  of SCCs in . For each  test if  is recurrent and let  be the recurrent SCCs in . Return .
\end{proof}

We next get the wanted corollary.
\begin{cor}\label{cor:compute-reachable-states}
Given a CFG , a non-terminal , a direction , a DFA  and a set of states  of  closed under reachability, 
the set  is computable in polynomial time.
\end{cor}
\begin{proof}
The proof follows from Lemma~\ref{lem:L(G,A,D)} and Lemma~\ref{l:compute-reachable-states}, using that  is closed under concatenation.
\end{proof}



\begin{lem}
Given a context-free grammar  and a safety DFA  the algorithm \algoFEDPDADFA\ can be implemented in  and correctly decides whether  is finite.
Moreover, if  is of constant size then \algoFEDPDADFA\ does not need non-determinism (and thus uses polynomial time only).
\label{l:FEDforSafeDFAiscoNP}
\end{lem}
\begin{proof}
The correctness comes from Lemma~\ref{l:correct}. The complexity comes from Lemma~\ref{l:bound_k}, Lemma~\ref{l:realizability-polynomial} and Corollary~\ref{cor:compute-reachable-states}. Note that, in case the DFA is of constant size, then  is bounded by a constant, according to Lemma~\ref{l:bound_k}, and thus there are only a polynomial number of candidates for  and hence all can be checked using polynomial time in total.
\end{proof}


\begin{thm}
For  we have  is -complete.
\label{th:FEDonDFAcoNP}
\end{thm}
\begin{proof}
First, we discuss containment of  in .
Consider a PDA  and a DFA . We can transform 
to a context-free grammar  with  in polynomial time. 
Also, we can transform  to a safety DFA  recognizing
the language .  
Due to Lemma~\ref{lem:prefix_closure}, we have 
 is finite if and only if  is finite. 
By Lemma~\ref{l:FEDforSafeDFAiscoNP} we can decide whether  is finite
in . Hence,  and  are in .

Is has been shown in~\cite{boundedRiveros} that  is -hard, therefore
 and  are -hard
\end{proof}








\subsection{Lower bound}
\label{sec:FEDLowerBound}

We have shown the exponential upper bound on the edit distance if it is finite.
As mentioned in the introduction, it is easy to define a family of context free grammars only accepting an exponential length word, using repeated doubling and thus the edit distance can be exponential between DPDAs and DFAs.
We can also show that the inclusion problem reduces to the finite edit distance problem  and get the following lemma. 


\begin{lem}
 is -hard.
\label{th:FEDexpHard}
\end{lem}
\begin{proof}
We show that the inclusion problem of  in , which is -hard by Lemma~\ref{l:ExpTimeHardness} reduces to 
. 
Consider  a DPDA  and an NFA .
We define .
Observe that either   or .
Therefore,  if and only if 
. 
In particular,  if and only if
.
Observe that in polynomial time we can transform  (resp., ) to 
a DPDA  (resp., an NFA ) recognizing
 (resp., ). 
It suffices to add transitions 
from all final states to all initial states with the letter , i.e.,
 for NFA (resp.,  for DPDA).
For DPDA the additional transitions are possible only with empty stack.
\end{proof}



 

\section{Edit distance to PDA}
\makeatletter{}\label{s:fromPDA}

Observe that the threshold distance problem from  to  with the fixed threshold 
and a fixed DFA recognizing  coincides with the universality problem for . 
Hence, the universality problem for , which is undecidable, reduces to .
The universality problem for  reduces to  as well by 
the same argument as in Lemma~\ref{th:FEDexpHard}. 
Finally, we can reduce the inclusion problem from  in , which is undecidable, to
 (resp., ). Again, we can use 
the same construction as in Lemma~\ref{th:FEDexpHard}. 
In conclusion, we have the following proposition.

\begin{proposition}
(1)~For every class , the problems
 and  are undecidable.
(2)~For every class , the problem
 is undecidable.
\label{p:undecidable}
\end{proposition}

The results in (1) of Proposition~\ref{p:undecidable} are obtained by reduction from
the universality problem for . However, the universality problem for  is 
decidable. Still we show that  is undecidable.
The overall argument is similar to the one in Section~\ref{sec:lowerBoundTED}.
First, we define nearly-deterministic PDA, a pushdown counterpart of nearly-deterministic NFA.

\begin{defi}
A PDA  is \emph{nearly-deterministic} if 
 and , where  is a function and for
every accepting run, the automaton takes a transition from  exactly once.
\end{defi}

By carefully reviewing the standard reduction of the halting problem for Turing machines to 
the universality problem for pushdown automata~\cite{HU79}, we observe that
the PDA that appear as the product of the reduction are 
nearly-deterministic.

\begin{lem}
The problem, given a nearly-deterministic PDA , decide
whether , is undecidable.
\label{l:PDAuniversality}
\end{lem}


Using the same construction as in Lemma~\ref{th:TEDexpHard} we show
a reduction of the universality problem for nearly-deterministic PDA to
.

\begin{proposition}
For every class ,
the problem  is undecidable.
\label{th:fromDPDAUndecidable}
\end{proposition}
\begin{proof} 
We show that  (resp., ) is undecidable as it implies undecidability of the rest of the problems.
The same construction 
as in the proof of Lemma~\ref{th:TEDexpHard} shows a reduction of 
the universality problem for nearly-deterministic PDA, which is undecidable by Lemma~\ref{l:PDAuniversality}, to .
\end{proof}


We presented the complete decidability picture for the problems , for
  and . 
To complete the characterization of the problems ,
with respect to their decidability, we still need to settle the decidability (and complexity)
status of . We leave it as an open problem, but conjecture that it is -complete. 

\begin{conj}
 is -complete.
\label{conj:FEDisUndec}
\end{conj}

 

\section{Conclusions}
In this work we consider the edit distance problem for PDA and its subclasses
and present a complete decidability and complexity picture for the  problem.
We leave some open conjectures about the parametrized complexity of the 
problem, and the complexity of  problem when the target is a DPDA.
Moreover, one can study the edit distance for other classes of languages between 
regular languages and context-free languages such as visibly pushdown automata.

While in this work we count the number of edit operations, a different notion is
to measure the average number of edit operations. 
The average-based measure is undecidable in many cases even for finite automata,
and in cases when it is decidable reduces to mean-payoff games on graphs~\cite{limavgRiveros}.
Since mean-payoff games on pushdown graphs are undecidable~\cite{CV12}, most of the problems 
related to the edit distance question for average measure for DPDA and PDA are likely
to be undecidable.


\noindent\textbf{Acknowledgements}. We wanted to thank the anonymous reviewers for their thorough and helpful
reviews, which help us to improve this paper.

\bibliographystyle{plain}
\bibliography{papers}



\end{document} 
