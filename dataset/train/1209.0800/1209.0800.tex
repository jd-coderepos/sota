\documentclass[fleqn,envcountsame]{LMCS}

\def\doi{8(3:24)2012}
\lmcsheading {\doi}
{1--15}
{}
{}
{May~\phantom{.0}2, 2011}
{Sep.~27, 2012}
{}

\usepackage{verbatim} \usepackage[latin1]{inputenc}\usepackage[usenames]{color}

\usepackage{amsmath}\usepackage{amssymb}

\usepackage{enumerate,hyperref}

\usepackage{eepic}
\usepackage{xspace}

\definecolor{darkred}{rgb}{0.65,0,0}
\definecolor{darkblue}{rgb}{0,0,0.4}
\definecolor{owngreen}{rgb}{0,0.6,0}
\definecolor{linkdarkgreen}{rgb}{0,0.45,0}

\newcommand\dju[2]{\cup\hspace{-#1mm^\cdot}\hspace{#2mm}}
\newcommand\cdju[2]{\bigcup_{#1}^{#2}\hspace{-4.2mm\cdot}\hspace{2.2mm}}
\newcommand\ldju[2]{\bigcup_{#1}^{#2}\hspace{-9mm\cdot}\hspace{7mm}}
\newcommand{\dotcup}{\mathrel{\mathaccent\cdot\cup}}

\newcommand{\aut}[1]{\ensuremath{\mathcal{#1}}}
\newcommand{\qz}{\ensuremath{q_0}\xspace}
\newcommand{\qs}{\ensuremath{q_{sink}}\xspace}
\newcommand{\G}{\ensuremath{\Gamma}\xspace}
\newcommand{\ga}[2]{\ensuremath{\mathcal{#1}_{#2}}}
\newcommand{\qga}[2]{\ensuremath{\mathcal{#1}/_{#2}}}
\newcommand{\pz}{Player~0\xspace}
\newcommand{\po}{Player~1\xspace}
\newcommand{\pt}{Player~2\xspace}
\newcommand{\pli}{Player~\xspace}

\newcommand{\pI}{Player~I\xspace}
\newcommand{\pO}{Player~O\xspace}
\newcommand{\pls}{Player~\xspace}
\newcommand{\Leq}{\ensuremath{L_{\mathrm{eq}}}\xspace}
\newcommand{\GSG}{\ensuremath{\Gamma^{SG}}\xspace}
\newcommand{\Gd}[1]{\ensuremath{\Gamma_{#1}}\xspace}
\newcommand{\GdL}[1]{\ensuremath{\Gamma_{#1}(L)}\xspace}
\newcommand{\GdLA}[1]{\ensuremath{\Gamma_{#1}(\LA)}\xspace}
\newcommand{\Gp}[1]{\ensuremath{\Gamma'_{#1}}\xspace}
\newcommand{\GpLA}[1]{\ensuremath{\Gamma'_{#1}(\LA)}\xspace}
\newcommand{\Gpempty}{\ensuremath{\Gamma'}\xspace}
\newcommand{\GA}{\ensuremath{\Gamma(\aut{A})}\xspace}
\newcommand{\GL}{\ensuremath{\Gamma(L)}\xspace}
\newcommand{\LA}{\ensuremath{L(\aut{A})}\xspace}
\newcommand{\LsA}{\ensuremath{L_*(\aut{A})}\xspace}
\newcommand{\LoA}{\ensuremath{L_{\omega}(\aut{A})}\xspace}
\newcommand{\GLoA}{\ensuremath{\Gamma(\LoA)}\xspace}
\newcommand{\const}[1]{\ensuremath{\langle#1\rangle}\xspace}
\newcommand{\Nat}{\ensuremath{\mathbb{N}}\xspace}
\newcommand{\Natp}{\ensuremath{\mathbb{N}_+}\xspace}
\newcommand{\B}{\ensuremath{\mathbb{B}}\xspace}
\newcommand{\Bst}{\ensuremath{\mathbb{B}^*}\xspace}
\newcommand{\Bsq}{\ensuremath{\mathbb{B}^2}\xspace}
\newcommand{\Bom}{\ensuremath{\mathbb{B}^{\omega}}\xspace}
\newcommand{\Bsqst}{\ensuremath{(\mathbb{B}^2)^*}\xspace}
\newcommand{\Bsqom}{\ensuremath{(\mathbb{B}^2)^{\omega}}\xspace}
\renewcommand{\S}{\ensuremath{\Sigma}\xspace}
\newcommand{\Sst}{\ensuremath{\Sigma^*}\xspace}
\newcommand{\Som}{\ensuremath{\Sigma^{\omega}}\xspace}
\newcommand{\SI}{\ensuremath{\Sigma_I}\xspace}
\newcommand{\SO}{\ensuremath{\Sigma_O}\xspace}
\newcommand{\SIom}{\ensuremath{\Sigma^{\omega}_I}\xspace}
\newcommand{\SOom}{\ensuremath{\Sigma^{\omega}_O}\xspace}
\newcommand{\al}{\ensuremath{\alpha}\xspace}
\newcommand{\be}{\ensuremath{\beta}\xspace}


\newcommand{\ie}{i.e.\xspace}
\newcommand{\cf}{cf.\xspace}
\newcommand{\eg}{e.g.\xspace}
\newcommand{\wrt}{w.r.t.\xspace}
\newcommand{\wlofg}{w.l.o.g.\xspace}

\newcommand{\Inf}{\mathrm{Inf}}
\newcommand{\Index}{\mathrm{index}}
\newcommand{\CFLom}{\ensuremath{\mathrm{CFL}_{\omega}}}

\let\obinom\binom
\renewcommand\binom[2]{
  \Big( { {{#1}} \atop {{#2}} } \Big)
}



\begin{document}
\title[Degrees of Lookahead in Regular~Infinite~Games]{Degrees of Lookahead in Regular~Infinite~Games}

\author[M.~Holtmann]{Michael Holtmann\rsuper a}
\address{{\lsuper a}Lehrstuhl f{\"u}r Informatik 7, RWTH Aachen University}
\email{holtmann@automata.rwth-aachen.de}

\author[{\L}.~Kaiser]{{\L}ukasz Kaiser\rsuper b}
\address{{\lsuper b}LIAFA, CNRS \& Universit{\'e} Paris Diderot -- Paris 7}
\email{kaiser@liafa.univ-paris-diderot.fr}

\author[W.~Thomas]{Wolfgang Thomas\rsuper c}
\address{{\lsuper c}Lehrstuhl f{\"u}r Informatik 7, RWTH Aachen University}
\email{thomas@automata.rwth-aachen.de}

\keywords{automata, model checking, regular infinite games}
\subjclass{D.2.4}

\begin{abstract}
We study variants of regular infinite games where the strict alternation
of moves between the two players is subject to modifications.
The second player may postpone a move for a finite number of steps,
or, in other words, exploit in his strategy some lookahead on the moves
of the opponent. This captures situations in distributed systems, \eg
when buffers are present in communication or when signal transmission
between components is deferred. We distinguish strategies with
different degrees of lookahead, among them being the continuous and
the bounded lookahead strategies. In the first case the lookahead is of finite
possibly unbounded size, whereas in the second case it is of bounded size.
We show that for regular infinite games the solvability by continuous strategies
is decidable, and that a continuous strategy can always be reduced to one
of bounded lookahead. Moreover, this lookahead is at most doubly exponential
in the size of a given parity automaton recognizing the winning condition.
We also show that the result fails for non-regular games
where the winning condition is given by a context-free -language.
\end{abstract}

\maketitle

\section{Introduction}\label{sec:introduction}
The algorithmic theory of infinite games is a powerful and flexible framework
for the design of reactive systems (see e.g. \cite{GTW02AutLogInfGam}).
It is well known that, for instance, the
construction of a controller acting indefinitely within its
environment amounts to the computation of a winning strategy in an
infinite game. For the case of regular games, algorithmic solutions
of this synthesis problem have been developed, providing methods for
automatic construction of controllers. The basis of this approach is
the B\"uchi-Landweber Theorem, which says that in a regular infinite
game, \ie a game over a finite arena with a winning condition given by
an -regular language, a finite-state winning strategy for the
winner can be constructed \cite{BL69SolSeqCondFinStateStr}.
Much work in the past two decades has been devoted to generalizations of
this fundamental result. The game-theoretic setting is built on
two components, a \emph{game arena} or game graph, representing the
transition structure of a system, and a \emph{winning condition},
usually given by a logic formula or an automata theoretic condition.
Most generalizations address an extension of either of the two, or both.
A rapidly growing literature is thus concerned with the case of infinite game
graphs and non-regular winning conditions \cite{Wal96PushProc,Cach03HighOrdPushAutCaucalHier,BSW03PushGamUnboundRegCond}.

In the present paper we investigate a different kind of generalization of
the basic setting, regarding the possibility to get a lookahead on the moves
of the opponent. To explain this aspect it is convenient to refer to
the simplest format of infinite games, also called Gale-Stewart
games \cite{Mosch80DST}.
In such a game we abstract from arenas but just let the two players choose
letters from a finite alphabet in turn. (For notational convenience let us
only consider the typical case of the Boolean alphabet .)
A play is built up as a sequence  where
 is chosen by one player and  by the other.
A natural view is to consider the sequence
 as \emph{input stream} and  as
\emph{output stream}. Accordingly, the players are called
Player Input and Player Output, or short \pI and \pO.
The play is won by \pO if the -word

satisfies the winning condition, \ie if it belongs to a given -regular
language . In the classical setting, a strategy for \pO is
a function  that maps a finite input prefix  to
the bit  that is to be chosen by \pO. Such a strategy induces an operator
 from input streams to output streams.~In this
work we study more generalized operators that correspond to strategies
where the choice of  depends on , for .
We show results on the existence of such strategies
for different conditions on the relation between  and .

There are two motivations for the study of such a generalization,
a practical and a theoretical one. In many scenarios, the occurrence of
delays (say between input and output) is realistic, either as a
modeling assumption or as a feature of strategies. For example,
the design of a controller may involve a buffer that allows to store
a sequence of input bits of some fixed length  such that the bit
 of the output sequence is to be delivered with lookahead ,
\ie on the basis of the input sequence . Conversely,
in the context of networked control (\ie systems with components in
different locations), there may be a delay  in the transmission of
data, which means that the delivery of  is due at a point where
only the input bits  are available. It is clear
that the occurrence of lookaheads and delays influences the existence
of solutions. In the first case, we obtain for increasing  an increasing
advantage for the output player, whereas in the second case we obtain
an increasing disadvantage. Observe that the cases are symmetric
in the two players, and thus are mutually reducible.

A more theoretical motivation is to explore more comprehensively
and systematically the solution concepts for infinite games.
The classical concept of a strategy gives a very special kind of operator,
but there are natural options of higher generality, well-known
already from background fields like descriptive set theory and topology \cite{Mosch80DST}.
Let us mention four fundamental levels of operators, corresponding to
different levels of obligation for \pO to move. The most general ones are
the continuous operators (see \eg \cite{TB73FinAutBehSynth,TL93LogSpecInfComp}).
An operator  is continuous (in the Cantor space of infinite
sequences over \B) if in the output sequence 
the bit  is determined by a finite prefix of .
Referring only to the length of prefixes, we call an operator
uniformly continuous if for some strictly monotone function  we have that 
is determined by . For fixed  we then speak of -delay operators.
On a further level of specialization, we are dealing with operators of
bounded delay. These are -delay operators with , for some .
Analogously, if , then we speak of operators with constant delay , and
finally, the function  supplies the operators induced by standard strategies.
All these levels of delay naturally correspond to different types of games;
for example, a continuous strategy involves the moves ``wait'' or
``output~'' after each move of the opponent.

Our main result connects the different kinds of operators
in the context of infinite games. We show that
in a two-person game with regular winning condition, one can decide whether
there is a continuous winning strategy for \pO, and in this case 
a strategy of constant delay can be constructed.
Moreover, one can compute a suitable bound  for the delay.
Thus, in the first mentioned application scenario, if a standard
controller for satisfying a regular specification does not exist then
one can decide whether some finite buffer will help, and determine
the needed size of that buffer. We also show that the result fails when
passing to non-regular specifications. However, which functions may be
appropriate for uniformly continuous strategies in the non-regular
case is left open. It seems that for infinite-state (or non-regular)
games our result can serve as an entry into a much wider field of study
(see \eg the recent work \cite{FLZ11}).

As indicated above, the idea of generalized concepts of strategies is
far from new. An early contribution is found in the (not well-known)
paper of Hosch and Landweber \cite{HL72FinDelSol}. It deals with constant
delay strategies in regular games and exploits a result of Even and Meyer
from Boolean circuit theory
to establish a bound for delays \cite{EM69SeqBoolEq}.
We obtain this result here as a corollary of the main theorem.
The extension of our result over \cite{HL72FinDelSol} covers
three aspects: the connection with strategies of unbounded delay,
a considerably simplified and transparent proof of the Hosch-Landweber-Theorem
(the construction in \cite{HL72FinDelSol} is highly complex),
and finally better complexity bounds for suitable delays.

This paper is organized as follows.
In the next section we introduce notation.
In Section~\ref{sec:operators_games_delay} we present several kinds
of functions and the operators they induce.
We also bridge from continuous operators to delay operators
and introduce games with delay.
In Sections~\ref{sec:block_game}--\ref{sec:connection_block_semigroup_game}
we prove our main result via a two-stage reduction:
In Section~\ref{sec:block_game} we do the first step,
switching over to block games.
In Section~\ref{sec:semigroup_game} we deal with notions
related to semigroups
and define a semigroup game.
This framework is finally used in Section~\ref{sec:connection_block_semigroup_game}
to establish the second step of the reduction, \ie the connection between
block games and the semigroup game.
Sections~\ref{sec:pusdown_games_delay} and \ref{sec:conclusion}
provide evidence that our results cannot be generalized
to -context-free specifications and give an outlook
on future investigations.



\section{Preliminaries}\label{sec:preliminaries}
Let \S be a finite \emph{alphabet}.
By \Sst and \Som we denote the sets of finite and infinite \emph{words} over \S.
Usually, finite words are denoted  whereas  are infinite words.
By  we denote the \emph{length} of  and
 is the set of words of length .
 is the set of natural numbers and .
Given  with 
we write  for .

A \emph{(deterministic) finite automaton}, DFA for short, over \S is a tuple
 where  is a (non-empty) finite set of
\emph{states},  is the \emph{initial state}, 
is a \emph{transition function}, and  is a set of
\emph{final states}. The \emph{run}  of \aut{A} on 
is the finite sequence  with  and
 for . We define
\aut{A} to \emph{accept}  if and only if . The
set of all words accepted by \aut{A} is called the
\emph{-language} of \aut{A} and denoted . Later in
our work we need the following basic property of deterministic
finite automata.

\begin{lem}\label{lem:length}
Let \aut{A} be a DFA with  states and . Then, for all
, \aut{A} accepts a word  of length .
\end{lem}

\begin{proof}
Let \aut{A} be a DFA with  states and . Since \LsA
is infinite it must be possible, for each , to read a word
 of length  such that from  a final state is
reachable. Otherwise, the length of words accepted by \aut{A} is
bounded by , which is a contradiction to the infiniteness of
\LsA. Then, from  we can reach a final state by a
word  of length at most . The word  is accepted by \aut{A}
and is of length between  and .
\end{proof}

A \emph{(deterministic) parity automaton}, DPA for short,
over \S is similar to a DFA, but instead of the set  of final
states it has a \emph{coloring}, \ie a function .
A run of a DPA is the natural extension of a run of a DFA to infinite words.
For , the set  is
the set of states visited infinitely often in run .
We define the parity automaton \aut{A} to accept  if and only if
 is even, \ie the maximal color seen
infinitely often in the run on  is even. Accordingly, the
acceptance condition of \aut{A} is called a \emph{max-parity}
acceptance condition. The set of all words accepted by \aut{A} is
called the -language of \aut{A} and denoted \LoA.

In the next sections, we write \LA instead of \LsA or \LoA if it is
clear from the context whether \aut{A} is a DFA or DPA. It is
well-known that languages accepted by DPAs are exactly the
\emph{-regular} languages (see \eg \cite{GTW02AutLogInfGam}).

A \emph{parity game}  is played by two players,
\pI and \pO, on a directed graph :
\begin{iteMize}{}
\item  is a partition of  into positions of \pI and \pO,
\item  is the set of allowed \emph{moves}, and
\item  is a coloring of 
  (w.l.o.g.\ ).
\end{iteMize}
We assume that for each  there is a valid move from ,
\ie .
A \emph{play} is an infinite path through . A (standard) \emph{strategy} for \pO is
a function  defining, for each position of \pO and each history
 of the play, her next move. Thus, for each 
(with  for all ) and , the
function  is defined such that .
A play  is \emph{consistent} with the strategy  if for each
 the next position is given by , \ie .

The \emph{parity winning condition} is again defined so that a play
 is winning for \pO if and only if the maximal color occurring
infinitely often in  is even.
In the other case the play is winning for \pI.
The function  is called a \emph{winning strategy for \pO from }
if each play starting in  that is consistent with  is winning for \pO,
and analogously for \pI. Parity games, even on infinite graphs, are
\emph{determined}, \ie for each  either \pI or \pO has a winning strategy
from  (see \eg \cite{GTW02AutLogInfGam}).

For the rest of this paper, let us fix  as input and
output alphabet, \ie let . All the definitions
and results are analogous for other finite alphabets of size
at least two.



\section{Operators and Games with Delay}\label{sec:operators_games_delay}

In this section we introduce different kinds of functions and operators,
and show how they induce games with different degrees of lookahead.
Below, we mostly use the term ``delay'' in place of ``lookahead'',
following \eg \cite{HL72FinDelSol}.



\subsection{Delay Operators}\label{subsec:delay_operators}

Let  denote a function from \Bom to \Bom, also called
an \emph{operator}. We shall distinguish the following classes of operators,
starting form the most general ones.
\begin{enumerate}[(1)]
\item \emph{continuous operators}
\item \emph{uniformly continuous operators}
\item \emph{-delay operators} for a fixed 
\item \emph{bounded delay operators}
\item \emph{-delay operators} for a fixed 
\end{enumerate}

An operator  is continuous if in the output sequence
 each bit is determined by a finite prefix of . 
This condition is equivalent to the standard topological definition,
where  is continuous if the preimage  of every open set
 is open in \Bom. Here, open sets in \Bom are given by
the standard Cantor topology, \ie  is open if there exists
 such that .
Consult \eg \cite{TL93LogSpecInfComp} for more details.
This topology is induced by the standard metric  on \Bom:

and the standard metric definitions of continuity and uniform continuity
are equivalent to the ones we use. Let us recall here three of these classical
definitions. An operator  is: 
\begin{iteMize}{}
\item \emph{Continuous} if for all  and each 
  there exists a  such that if  then 
  .
\item \emph{Uniformly continuous} if for each 
  there exists a  such that for all 
  if  then 
  .
\item \emph{Lipschitz continuous} with constant  if
  for all  the following holds:
  .
\end{iteMize}

\noindent Since we do not use metric properties of the Cantor space,
to formally capture the constraint that each output bit is
determined by a finite prefix of the input, we define
the continuity of  in the following equivalent way.
We use a map  that transforms each input bit into either  or 
or , the latter meaning that the production of the next output bit
is still deferred. The value  is then obtained from the sequence
of -values by deleting all entries .

\begin{defi}\label{def:continuous_to_delay}
An operator  is \emph{continuous}
if there exists 
such that for all  the word

satisfies the following:
\begin{enumerate}[(1)]
\item  does not end with , and
\item  where  is
the word  with all  removed.
\end{enumerate}
\end{defi}

Let us now define \emph{-delay} and \emph{uniformly continuous}
operators. Let  be a strictly monotone function.
We say that  is an \emph{-delay} operator if,
for each , the bit  depends only
on . An operator  is uniformly continuous
if there exists an  such that  is an -delay operator.
Observe that each uniformly continuous operator is indeed continuous --
the function  supplies the information 
how long the output  should be produced. 


For the space \Bom it is known that
the converse also holds. This is a consequence of K\"onig's Lemma, or
equivalently of the fact that continuous functions
on a closed bounded space are uniformly continuous.

\begin{lem}\label{lem:continuous_to_delay_operator}
For every continuous operator  there exists
a strictly monotone function  such that  is
an -delay operator.
\end{lem}

By the above lemma, the classes of continuous operators  and
uniformly continuous operators  are exactly the same.
A space where this does not hold is \eg .
Consider  with

Intuitively, the operator  checks if there is  or 
after the first  in the input. One can verify that  is
a continuous function from  to \Bom, but
it is not uniformly continuous and can not be extended to any continuous
function from \Bom to \Bom. Our results do not hold for such operators:
Already  is a counterexample, since it is continuous
but not of bounded delay. Thus, in this paper we adhere to the space \Bom.

Among the uniformly continuous operators, we distinguish an even more
restricted class of bounded delay operators. A function 
is said to be of \emph{bounded delay} if there exist 
such that  for all , and it is said to be
a \emph{-delay} function (or a function of \emph{constant} delay )
if  for all . The induced operators are named accordingly.

In topological terms, bounded delay operators are Lipschitz continuous
functions from \Bom to \Bom, as defined above. The -delay operator is
clearly Lipschitz continuous with constant .
Conversely, if an operator  is not of bounded delay
then for each  there exists  and an index 
such that the -th bit of  is not a function of the first
 bits of \al. This means that there exists  with the same
first  bits as \al, \ie satisfying ,
such that  differs from  on the -th bit,
therefore . This contradicts 
Lipschitz continuity as the constant  would have to satisfy ,
for all .

In all definitions above, we assume that the delay function
 is strictly monotone. For our purpose it is more convenient
to consider the function ,
denoting the number of additional input bits until the next output bit:

In the next sections, we work only with the functions .
Moreover, we use the special notation \const{d} for
the function  with  of constant delay :
 and  for .
From now on, we omit the subscript  in our notation.



\subsection{Regular Games with Delay}\label{subsec:regular_games_delay}

In this section we introduce the regular infinite game \GdL{f}.
It is induced by an -language  (usually given by a DPA \aut{A}) over \Bsq, and a function .
(Since we focus on the impact of the function ,
we omit  if it is clear from the context and write \Gd{f}.)
The function  imposes a delay (or lookahead) on the moves of \pO.
This means that in round  \pI has to choose 
many bits, and \pO chooses one bit, afterwards.
This way the players build up two infinite sequences; \pI builds up
 and \pO builds up ,
respectively. The corresponding play is winning for \pO if and only if
the word 
is accepted by \aut{A}.
For a DPA \aut{A}, we say that
\LA is \emph{solvable with finite delay}
if and only if there exists  such that \pO wins \GdLA{f}
(analogously for restricted classes of functions).

Observe that the possible strategies for \pO in \Gd{f} correspond precisely
to -delay operators, since \pO must output her th bit after receiving
the next  bits of input. Thus, the question whether there exists
an -delay operator  such that 

is equivalent to the question whether there exists a winning strategy for
\pO in \Gd{f}.

A basic observation is that winning with delay is a monotone property.
For two functions  we write
 if and only if .
\begin{rem}\label{rem:winning_monotone}
If \pO wins \Gd{f_0} then she also wins \Gd{f} for each .
Analogously, if \pI wins \Gd{g_0} then he also wins \Gd{g},
for each .
\end{rem}

\begin{exa}\label{ex:game_with_delay}
Let  be given by the -regular expression

where  and  denotes any bit.
If \pI chooses 0 as his first bit then \pO needs to know ,
so she needs delay one in this situation.
Contrary, if \pI chooses  as his first bit then \pO needs delay three
to obtain . Thus, she wins the game with delay three,
but neither with delay two nor one.
\end{exa}

In the next sections we prove our main result (see Theorem~\ref{thm:main}):
\emph{Let \aut{A} be a DPA
with  states,  colors, and let .
Then, there is a continuous operator 
with  (for all )
if and only if there is a -delay operator with the same property.}
To obtain this result we show that
\LA is solvable with finite delay
if and only if \LA is solvable with delay .



\section{The Block Game}\label{sec:block_game}
In this section we make the first step in the proof of our main result,
which is to relax the number of bits \pI can choose in each move.
For this reason we introduce a new game \Gp{f}, called the \emph{block game}.

The game \Gp{f} differs from \Gd{f} in two ways.
Firstly, the lengths of the words to be chosen by the players
are decided by \pI, within certain intervals determined by .
Secondly, \pI is one move ahead compared to \Gd{f}.

A play in \Gp{f} is built up as follows: \pI chooses
 and ,
then \pO chooses .
In each round thereafter, \ie for , \pI chooses
 and \pO responds
by a word .
The winning condition is defined as before.

We show that \pI wins the game \Gd{f} for all functions  if and only
if he wins the block game \Gp{f} for all functions . To this end, for
, let  be defined by
, and  for .

\begin{prop}\label{prop:G_f_prime_G_prime_f}
Let . If \pI wins \Gd{f'} then he also wins \Gp{f}.
\end{prop}
\begin{proof}
Assume \pI has a winning strategy in \Gd{f'}. For , let
 be the words chosen by \pI in \Gd{f'} and  the words
chosen by \pI in \Gp{f}, and analogously  for \pO.
The winning strategy yields  as \pI's first move.
Since  we can choose  as \pI's first move
in \Gp{f}. \pO answers by . We can use  to
simulate the moves  of \pO in \Gd{f'},
each of which consists of one bit. \pI answers by
 of lengths .
Since , the sum  is non-empty and
at least . Accordingly, the word  is
long enough to give  with .
We choose  as the prefix of  of length .
\pO answers in \Gp{f} by  of length , and we can use it to
simulate another  rounds in \Gd{f'}. Thereby, we obtain enough
bits to give , and so on. This way, we build up the same plays
in \Gd{f'} and \Gp{f}. Since \pI wins \Gd{f'}, he also wins \Gp{f}.
\end{proof}

For , let  be inductively defined by 
and 
\begin{prop}\label{prop:G_prime_f_prime_prime_G_f}
Let . If \pI wins \Gp{f''} then he also wins \Gd{f}.
\end{prop}
\begin{proof}
Assume \pI has a winning strategy in \Gp{f''}. For , let
 be the words chosen by \pI in \Gp{f''} and  the words
chosen by \pI in \Gd{f}, and analogously   for \pO.
\pI's winning strategy yields  and
 as his first move in \Gp{f''}.
For , let  be the length of .
Since

we can give the moves  of \pI in \Gd{f}. This
yields \pO's answers , \ie  bits. We
can use them to simulate , \ie \pO's first move in
\Gp{f''}. \pI's winning strategy yields  of length . We need to give another  moves of \pI in
\Gd{f} to obtain \pO's answers . For
that we need  bits. With  in our
hands we can give these moves, because
\begin{center}
\begin{tabular}{rcccl}
 &  &  &  & \\
	& & &  & \\
	& & &  & .
\end{tabular}
\end{center}
Iterating this we obtain the same plays built up in \Gp{f''} and
\Gd{f}. Since \pI wins \Gp{f''}, he also wins \Gd{f}.
\end{proof}

The following corollary of Propositions \ref{prop:G_f_prime_G_prime_f} and
\ref{prop:G_prime_f_prime_prime_G_f}, which follows by taking functions of
the form  in the one direction and of the form  in the other,
is the first step in our proof.

\begin{cor}\label{cor:equivalence_all_Gf_all_G_prime_f}
Let \aut{A} be a DPA. Then the following are equivalent:
\begin{enumerate}[\em(1)]
\item For all  \pI wins \GdLA{f}.
\item For all  \pI wins \GpLA{f}.
\end{enumerate}
\end{cor}



\section{The Semigroup Game}\label{sec:semigroup_game}

In this section we introduce a game which is independent of particular delays.
To define it, we extract from a DPA \aut{A} two equivalence relations,
one for each player, such that the moves of the players are equivalence classes of
these relations. The first one (for \pO) is denoted  and induces
a finite semigroup on~\Bsqst. The second one (for \pI)
is denoted  and ranges over \Bst.
Roughly speaking, two (pairs of) words are equivalent
if they effect the same behavior on~\aut{A}.

Our approach to transform parity automata into finite semigroups
is similar to the constructions presented in \cite{PP95SemInfinite,Pin95FiniteSem}.
Let  be a DPA over \Bsq.
We use the semiring  in
which addition is defined as maximum, \ie  with 
being the least element, and multiplication is defined as follows:

Note that the set , \ie the set of pairs of words of equal length, is a regular language.
With each pair  we associate a matrix 
of size  with entries in , \ie ,
defined as follows:

Observe that  induces a finite semigroup and
.
Let  be the equivalence relation on \Leq defined by:
 if and only if .
For each , the equivalence class  is identified by
a matrix . Since  and 
are finite,  is finite as well, and so the
relation  has finite index, \ie it has finitely many equivalence classes.
We denote the index of  by . Note that 
induces a finite semigroup, and  is a semigroup morphism from
 to .

\begin{lem}\label{lem:sim_regular_class}
Let . Then, the set 
is a regular -language over \Bsq.
\end{lem}

\begin{proof}
We construct an automaton recognizing  as follows:
First, we construct for all  the automaton
 recognizing the set of all words that induce a path
from  to  in \aut{A} where  is the highest color seen on that
path. The idea for this construction is to simulate the behavior of
\aut{A} while memorizing the highest color seen. To this end, define

where

for all . The automaton starts in the state
 and simulates the behavior of \aut{A} on its input. If it
stops in state  then it accepts. The automaton 
is then obtained as the intersection of all  for 
such that  . 
\end{proof}

Since  has finite index, we can find automata for all equivalence
classes of  in the following way: For , let
 be the automata already constructed.
Then  has index  if and only if
.
This equality can be effectively checked, and if this test fails,
then we repeat the construction with a word contained in
.

Let  be
the equivalence relation on \Bst defined by

For , the -equivalence class of , denoted ,
can be identified with a subset of the set of all -classes.
Since  has finite index, we get that  has finite index as well;
more precisely it holds .

\begin{lem}\label{lem:approx_regular_class}
Let . Then, the set  is a regular -language over \B.
\end{lem}

\proof
We construct an automaton recognizing the language  as follows:
First, we have to check for which -classes 
there exists  such that
. Let \aut{B} be a DFA
recognizing . We take the projection on the
first component (deleting the second component from the transitions of \aut{B})
and test whether the resulting automaton, say , accepts .
If we do the same for all -classes,
then we obtain  automata  accepting
, and  automata  not accepting ,
where . From these automata we can effectively construct
an automaton for , because \label{pageref:definition_L_A_u}

We now define the game \GSG (induced by a DPA \aut{A} over \Bsq) where the moves of
the players are classes from  and , respectively.
Accordingly, we call \GSG the \emph{semigroup game} of \aut{A}.

The game \GSG is defined similar to the block game \Gpempty.
The difference is that the players do not choose concrete words but the
respective classes from the relations  and . A play is
built up as follows: \pI chooses infinite classes
, then \pO chooses a class
. In each round thereafter,
\ie for , \pI chooses an infinite class
 and \pO chooses a class
.
A play is winning for \pO if and only if
 is accepted
by \aut{A}.

Note that  contains at least one infinite class and that
for each class  there exists at least one class in 
associated with  (by the definition of~).
Hence, both players can always move.
Furthermore, the winning condition of \GSG is well-defined
because acceptance of \aut{A} is independent of representatives:
If  for all , then
.

\GSG\label{pageref:size_of_GSG} can be modeled by a parity game on a graph of size .
(Thus, its winner is computable~\cite{GTW02AutLogInfGam}.)
In the vertices we keep track of the -classes recently chosen by \pI,
a color depending on the course of the play and
the current state  of \aut{A}. The vertex reached by
a move  of \pO is colored by ,
where  is the state reached in \aut{A} from  when reading .



\section{Connecting the Block Game and the Semigroup Game}\label{sec:connection_block_semigroup_game}
In this section we show that \pI wins the block game \Gp{f} for all
functions  if and only if he wins the semigroup game \GSG.
This completes the reduction and also yields the proof of our main result.

The basic idea of the proof of Theorem~\ref{thm:equivalence_all_f_greater_than_f_0_GSG} (see below)
is, for arbitrary , to simulate the moves of the players in \Gp{f} by the corresponding
equivalence classes of the relations  and , respectively, and vice versa.
For the last-mentioned direction,
one has the problem whether a class  contains an
appropriate representative, \ie one of length between  and .
We use Lemma~\ref{lem:length} to show that there exists a particular 
such that each function  with  indeed has this property.
Then, the following lemma completes the proof.

\begin{lem}\label{lem:equivalence_all_f_all_f_greater_than_f_0}
\pI wins \Gp{f} for all functions  if and only if there exists
a function  such that \pI wins \Gp{g} for
all .
\end{lem}
\begin{proof}
The direction from left to right is immediate. For the converse,
recall first that the block game \Gp{f} is determined for each .
Assume there exists  such that \pI does not win \Gp{f_0}.
Determinacy yields that \pO wins \Gp{f_0}.
By Proposition~\ref{prop:G_f_prime_G_prime_f} \pO wins \Gd{f'_0}, and
from Remark~\ref{rem:winning_monotone} it follows that she also wins \Gd{f} for
all . Proposition~\ref{prop:G_prime_f_prime_prime_G_f}
yields that \pO wins \Gp{f''}, for all . Towards
a contradiction, let  be a function such that \pI wins \Gp{g} for
all , and let  be the maximum of  and
, \ie for all 
  
Since  it holds that \pO wins
\Gp{f''_*}. However, since  \pI
must win \Gp{f''_*}, by assumption. This yields a contradiction which
means that  cannot exist.
\end{proof}

Lemma~\ref{lem:equivalence_all_f_all_f_greater_than_f_0} and the next
theorem establish the second step of our reduction.

\begin{thm}\label{thm:equivalence_all_f_greater_than_f_0_GSG}
\pI wins \GSG if and only if there is a function  such that
\pI wins \Gp{g} for all .
\end{thm}

\begin{proof}
We start with the direction from right to left. Let 
be a function such that \pI wins \Gp{g} for all . We
define a function  such that  and each word of
length  is contained in an infinite -class, for all .
To this end, let  be the length of a longest word in all finite
-classes\footnote{If  has no finite
equivalence class, then we define .} and define, for all ,
.

Since , \pI wins \Gp{g_0} by assumption, and a winning strategy yields his first
two moves . Both  and  are infinite, and so he can
choose them in \GSG. We simulate \pO's answer 
by choosing  in \Gp{g_0}, and \pI's winning strategy yields  with  being
infinite. Choosing  in \GSG we obtain \pO's next move
, and so on.

We argue that the plays built up have the same maximal color occurring
infinitely often. It suffices to show that in both plays a move of \pO
leads \aut{A} to the same state, via paths with equal maximal
color. Then, the rest follows by induction. Let  be the current
state of \aut{A} and  be the words chosen by \pI. If \pO
chooses  in \GSG, then we reach the state

via the maximal color
. The state  is well-defined
because from  every 
leads \aut{A} to the same state, though via different paths, but with the
same maximal color. In \Gp{g_0} \pO chooses . As in \GSG, we reach
the state  via the maximal color
.

Conversely, assume that \pI wins \GSG. Let
 be automata recognizing all the
-classes, and  the maximal number of states among these
automata, \ie , where  is the number of states of  ().
Let  be the constant function with  for all .
We first show that \pI wins \Gp{f}:
\pI's winning strategy in \GSG yields .
Since  are infinite, we can apply Lemma~\ref{lem:length}.
Accordingly, each  accepts a word of length between  and
 and thus between  and , because .\footnote{To simplify matters we write  instead of .}
Hence, we can assume \wlofg that .
\pI chooses  in \Gp{f} and \pO answers by a word  with
. We simulate this move by  in \GSG
and obtain \pI's answer , so the next move of \pI in \Gp{f} is
 (for appropriate ). \pO chooses  with ,
and so on.

The plays built up this way have the same maximal color occurring
infinitely often, using the same inductive argument as above. Starting
at , \pO's move  in \Gp{f} has the same effect as the
corresponding move  in \GSG, \ie we reach
the state  via
the maximal color .

We complete the proof by showing that \pI wins \Gp{g} for all .
Let  be the size of the interval
. If , then (since ) it holds
, for all . Hence, to win \Gp{g} \pI
simply chooses longer representatives of the -classes than in
\Gp{f}.
\end{proof}

A thorough analysis of the constructions of the -classes and
-classes, respectively, yields an upper bound for . Let
 be the number of states of \aut{A} and  the number of
colors. Let  with . Since \aut{A} is deterministic,
there is exactly one entry distinct from  in each of the 
rows of , and  has at most 
states. Hence, each  has at most 
states, \ie as many as the product of  (deterministic) automata
of size . To obtain an automaton for a class  we have to intersect
 languages (\cf page~\pageref{pageref:definition_L_A_u}).
By the same argument as above, there are at most  possible
matrices identifying all the -classes. Since our construction
includes determinization, we obtain each  having
at most  states, where

Next, we obtain our main result showing that in regular games constant delay
is sufficient for \pO to win, if she can win with delay at all.
Recall that we write  for the constant delay function,
 and  for .

\begin{lem}\label{lem:bound}
Let  be as in the proof of Theorem~\ref{thm:equivalence_all_f_greater_than_f_0_GSG}.
Then, \pO wins \GSG if and only if \pO wins \Gd{\const{2n'-1}}.
\end{lem}

\begin{proof}
Define  for all  and let  of length  be a longest word in all
finite -classes. Moreover, let , where  has  states.
Then we have . Otherwise, the run of  on  had a loop,
which is a contradiction to the finiteness of .
Since  we get  and so .
Thus, each -class containing a word of length at least  is infinite.

Assume that \pO wins \GSG. We first show that \pO wins \Gp{f}.
Let  with  be the first move of \pI in
\Gp{f}. By the above remarks  are infinite, and we can
simulate  in \GSG. \pO's winning strategy in \GSG yields
 for some suitable . Let him choose
 in \Gp{f}. Then \pI chooses  and we simulate  in
\GSG, and so on.

As in the proof of Theorem~\ref{thm:equivalence_all_f_greater_than_f_0_GSG},
we obtain plays with the same maximal color occurring infinitely often, and so
\pO wins \Gp{f}. Simulating a winning strategy for \Gp{f} she also wins
\Gd{\const{2n'-1}}. The factor  comes from the fact that we need at least
 bits when simulating \pI's first move in \Gp{f}.

Conversely, let \pO win \Gd{\const{2n'-1}} and , for all
. Since , \pO wins \Gd{g}.
Then, by Proposition~\ref{prop:G_prime_f_prime_prime_G_f},
she also wins \Gp{g''}. Given a winning strategy for \pO in \Gp{g''}
we can specify one for her in \GSG as follows: A move  of \pI is
simulated by  in \Gp{g''}, for .
(By Lemma~\ref{lem:length}, an appropriate representative  must exist
because , and so  for all
.) We use \pO's answer  to choose
 in \GSG.
This yields a play winning for \pO in \GSG.
\end{proof}

With Corollary~\ref{cor:equivalence_all_Gf_all_G_prime_f}, Lemma~\ref{lem:equivalence_all_f_all_f_greater_than_f_0}
and Theorem~\ref{thm:equivalence_all_f_greater_than_f_0_GSG} we have shown that the problem whether
\LA is solvable with finite delay is reducible to the question whether
\pO wins \GSG. Finally, Lemma~\ref{lem:bound} shows that
\LA is solvable with finite delay if and only if it is solvable with constant delay.

\begin{thm}\label{thm:main}
Let \aut{A} be a DPA over \Bsq. Then, \LA is solvable with finite delay
if and only if \LA is solvable with delay .
There is a continuous operator  such that

if and only if there is a -delay operator with the same property.
\end{thm}

Assuming that \aut{A} has  states and  colors
we can bound the number of vertices of \GSG by .
Since it requires only  colors,
its winner can be computed in time  \cite{Sch07ParGameBigSteps}.

\begin{cor}\label{cor:decide_bounded_delay}
Let \aut{A} be a DPA over \Bsq. The problem
whether \LA is solvable with finite delay
and the problem whether there is a continuous operator  with

are in \textsc{ExpTime}.
\end{cor}



\section{Lookahead in Non-Regular Games}\label{sec:pusdown_games_delay}

In this section we show that the above results do not hold for context-free
-languages (\CFLom, for an introduction see \eg \cite{CG78OmegaComputDetPushMach}).
Let us first recall that it is undecidable whether a context-free
-language  is universal, \ie whether  holds.

\begin{thm}[see also \cite{Fin01TopProp}]\label{thm:finkel_context_free_gale_stewart_undecidable}
Let  be a context-free -language.
Then, it is undecidable whether there exists  such that \pO wins \GdL{f}.
\end{thm}
\begin{proof}
We make a reduction from the universality problem for context-free -languages.
Let  and .
If  is universal then  is universal as well, and \pO wins
with any .
Conversely, if  is not universal, then \pI wins by playing a word .
There is no response \be such that , therefore
\pO looses with each .
Altogether,  is universal if and only if
there exists  such that \pO wins~\GdL{f}.
\end{proof}
It has recently been shown \cite{FLZ11} that the same holds for
\emph{deterministic} -context-free specifications, but in that
case at least establishing the winner of the standard game \Gd{\const{0}}
is decidable \cite{Wal96PushProc}.

In addition to undecidability for the general case, we show that there exist
context-free specifications which are solvable with finite delay,
but not with constant delay.

\begin{exa}\label{ex:non_regular_not_constant_delay}
Let  be defined such that if \pI chooses an -word
of the form , for , then
\pO wins if and only if he answers by .
This means \pO's th block of s must have exactly half the length of
\pI's th block of s, and both blocks must start at the same position.
If \al is not of the above form, then \pO wins as well.

The language  is recognized by a deterministic -pushdown automaton.
As long as the input is , we push a symbol on the stack.
If we read the first  after ,
we start to pop symbols from the stack. If we reach the initial stack
symbol at the same time as we read the first 
after  then we are satisfied and visit a final state.

Observe that \pO wins \GdL{f}, if  for all .
When she has to give her th bit  she already knows \pI's th bit ,
and that is enough to decide whether to play  or .

Let us show that  is not solvable with constant delay.
Towards a contradiction, assume \pO wins \Gd{\const{d}} for some .
We construct a winning strategy for \pI in \Gd{\const{d}} as follows:
\pI chooses  as initial move and 1 as each of his  subsequent moves.
\pO must answer each of these  moves by choosing . Otherwise, she loses immediately.
Afterwards, \pI chooses another  to complete his block of s to even length.
(After this move, \pI has chosen exactly twice as many s as \pO.)
Whatever \pO answers, say , \pI wins by choosing  next.
This is due to the fact that the block of s chosen by \pO gets either
too short or too long. 
\end{exa}



\section{Conclusion}\label{sec:conclusion}

In this paper we introduced and compared strategies
with different kinds of lookahead in regular infinite games.
We showed that continuous strategies can be reduced to
uniformly continuous strategies of a special form,
namely strategies with constant lookahead.
This result is a first step into a wider -- and it
seems rather unexplored -- topic. Let us mention some
aspects. First, it is straightforward to present
the results in a set-up that is symmetric in the two players.
We also skipped here a lower bound proof for the
double exponential size in Theorem \ref{thm:main}.
It is also possible to think of ``infinite lookahead'' where,
for instance, the second player may use information about
the first player's sequence up to a partition of the
space of sequences into regular sets. Moreover, while
basic questions about lookahead in context-free games have
recently been answered, some problems for visibly pushdown
winning conditions remain open, cf. \cite{FLZ11}.


\begin{thebibliography}{10}

\bibitem{BSW03PushGamUnboundRegCond}
Alexis-Julien Bouquet, Olivier Serre, and Igor Walukiewicz.
\newblock Pushdown games with unboundedness and regular conditions.
\newblock volume 2914 of {\em LNCS}, pages 88--99. Springer, 2003.

\bibitem{BL69SolSeqCondFinStateStr}
J.~Richard B{\"u}chi and Lawrence~H. Landweber.
\newblock Solving sequential conditions by finite-state strategies.
\newblock {\em Transactions of the AMS}, 138:295--311, 1969.

\bibitem{Cach03HighOrdPushAutCaucalHier}
Thierry Cachat.
\newblock Higher order pushdown automata, the caucal hierarchy of graphs and
  parity games.
\newblock In Jos C.~M. Baeten, Jan~Karel Lenstra, Joachim Parrow, and
  Gerhard~J. Woeginger, editors, {\em ICALP}, volume 2719 of {\em LNCS}, pages
  556--569. Springer, 2003.

\bibitem{CG78OmegaComputDetPushMach}
Rina~S. Cohen and Arie~Y. Gold.
\newblock Omega-computations on deterministic pushdown machines.
\newblock {\em Journal of Computer and System Sciences}, 16(3):275--300, 1978.

\bibitem{EM69SeqBoolEq}
Shimon Even and Albert~R. Meyer.
\newblock Sequential boolean equations.
\newblock {\em IEEE Transactions on Computers}, C-18(3):230--240, 1969.

\bibitem{Fin01TopProp}
Olivier Finkel.
\newblock Topological properties of omega context-free languages.
\newblock {\em Theoretical~Computer~Science}, 262(1-2):669--697, 2001.

\bibitem{FLZ11}
Wladimir Fridman, Christof L{\"o}ding, and Martin Zimmermann.
\newblock Degrees of lookahead in context-free infinite games.
\newblock In {\em Proceedings of CSL~'11}, volume~12 of {\em LIPIcs}, pages
  264--276. Schloss Dagstuhl -- Leibniz-Zentrum f{\"u}r Informatik, 2011.

\bibitem{GTW02AutLogInfGam}
Erich Gr{\"a}del, Wolfgang Thomas, and Thomas Wilke, editors.
\newblock {\em Automata, Logics and Infinite Games}, volume 2500 of {\em LNCS}.
\newblock Springer, 2002.

\bibitem{HL72FinDelSol}
Frederick~A. Hosch and Lawrence~H. Landweber.
\newblock Finite delay solutions for sequential conditions.
\newblock In M.~Nivat, editor, {\em Automata, Languages and Programming}, pages
  45--60, Paris, France, 1972. North-Holland, Amsterdam.

\bibitem{Mosch80DST}
Yiannis~N. Moschovakis.
\newblock {\em Descriptive Set Theory}, volume 100 of {\em Studies in Logic and
  the Foundations of Mathematics}.
\newblock North-Holland Publishing Company, 1980.

\bibitem{PP95SemInfinite}
Dominique Perrin and Jean{-}{\'E}ric Pin.
\newblock Semigroups and automata on infinite words.
\newblock In J.~Fountain, editor, {\em NATO Advanced Study Institute {\it
  Semigroups, Formal Language and Groups}}, pages 49--72. Kluwer academic
  publishers, 1995.

\bibitem{Pin95FiniteSem}
Jean{-}\'{E}ric Pin.
\newblock Finite semigroups and recognizable languages: An introduction, 1995.

\bibitem{Sch07ParGameBigSteps}
Sven Schewe.
\newblock Solving parity games in big steps.
\newblock In Vikraman Arvind and Sanjiva Prasad, editors, {\em FSTTCS}, volume
  4855 of {\em LNCS}, pages 449--460. Springer, 2007.

\bibitem{TL93LogSpecInfComp}
Wolfgang Thomas and Helmut Lescow.
\newblock Logical specifications of infinite computations.
\newblock In J.~W. de~Bakker, W.~P. de~Roever, and G.~Rozenberg, editors, {\em
  REX School/Symposium}, volume 803 of {\em LNCS}, pages 583--621. Springer,
  1993.

\bibitem{TB73FinAutBehSynth}
Boris~A. Trakhtenbrot and Janis~M. Barzdin.
\newblock {\em Finite Automata, Behavior and Synthesis}.
\newblock North Holland, Amsterdam, 1973.

\bibitem{Wal96PushProc}
Igor Walukiewicz.
\newblock Pushdown processes: Games and model checking.
\newblock volume 1102 of {\em LNCS}, pages 62--74. Springer, 1996.

\end{thebibliography}


\end{document}
