\section{Experiments}
\subsection{Datasets and Evaluation Metric}
We choose Pascal- and COCO-, two widely used datasets for few-shot semantic segmentation, to analyze our model performance.
Pascal-~\cite{oslsm} includes images from the PASCAL VOC 2012 \cite{pascal} and extra annotations from SBD \cite{sbd}.
The total 20 categories are evenly partitioned into four splits, and the model training is conducted in a cross-validation manner.
Specifically, three splits are selected in the training process and the remaining one is used for testing.
During inference, 1000 support-query pairs are randomly sampled for evaluation~\cite{oslsm}.
Different from Pascal-, MSCOCO \cite{mscoco} is a large-scale dataset with 82,081 images 
in the training set.
Following FWB \cite{fwb}, the overall 80 classes from MSCOCO~\cite{mscoco} are evenly divided into four splits with the same cross-validation strategy.
For more stable results, we randomly sample 20,000 pairs during evaluation~\cite{pfenet}.

We use mean intersection-over-union (mIoU) 
as a primary evaluation metric for the ablation study, as it is commonly recognized in image segmentation.
In addition, for more consistent comparisons, results of foreground-background IoU (FB-IoU) are also reported.


\subsection{Implementation Details}
We adopt ResNet \cite{resnet} as the backbone network~\cite{canet},
and we concatenate block2 and block3 to generate feature maps.
We train the model 
with a SGD optimizer on Pascal- for 200 epochs and COCO- for 50 epochs.
We set the initial learning rate to 0.0025 with batch size 4 on Pascal-, and 0.005 with batch size 8 on COCO-.
The number of iterations in the SGC module is set to 10 during training and 5 during inference. We use data augmentation during training - input images are transformed with random scale, horizontal flip and rotation from [-10, 10], and then all images are cropped to  (Pascal) or  (COCO) as training samples.
We implement our model using Pytorch and run our experiments on a workstation with Nvidia Tesla V100 GPU.
To increase the variance of the cosine measurement, we remove the ReLU layer before both support and query features, so the similarity metric is bounded in [-1, 1] rather than [0, 1].

\subsection{Ablation Study}
To verify the effectiveness of the proposed modules, we implement extensive ablation studies with a 
ResNet-50 backbone on Pascal-.
We use floating point operations (FLOPs) to represent the amount of computation, and take both addition and multiplication into account.

\label{max_proto}
\vspace{1mm}
\noindent{\textbf{Number of Superpixel Centroids.}}
To explore the effect of the number of superpixel centroids, we conduct experiments with different  in 1-shot segmentation.
As stated in Section \ref{sec:adaptability},  is a hyper-parameter set to regulate the maximum number of prototypes.
Particularly, when , the prototype generation process degrades to the masked average pooling.
As shown in Table \ref{proto_number}, when  equals 5, ASGNet achieves the best results in split 0 and 2, as well as the best mean performance, which 
demonstrates the validity of superpixel-guided clustering.
The results get improved gradually when  increases from 1 to 5, and then decrease slightly after that, denoting that excessive prototypes bring negative effect and are prone to over-fitting.
Finally, we choose  as 5 for both 1-shot and 5-shot segmentation.
In addition, we analyzed
the impact of the proposed adaptive scheme on the number of superpixel centroids  and show the results in Table~\ref{adaptive_proto}.
Compared with using the fixed number (5) of superpixels, the results show that the adaptive setting (Eqn.~\ref{eqn:adaptability}) can reduce redundant computation while obtaining 
better performance.





\begin{table}[htbp]
\begin{center}
\begin{tabular}{|c|cccc|c|}
\hline
 & s-0 & s-1 & s-2 & s-3 & mean\\ \hline \hline
1        &  57.40       & 67.52       &  55.69     & \textbf{54.36}    & 58.74 \\
3        &  57.92       & 67.86       &  55.86     & 53.74    & 58.85 \\
5        &  \textbf{58.84}       & 67.86       &  \textbf{56.79}     & 53.66    & \textbf{59.29} \\ 
7        &  \textbf{58.84}       & \textbf{68.11}       &  55.85     & 54.00    & 59.20 \\ 
9        &  57.61       & 67.97       &  56.68     & 53.27    & 58.88 \\ \hline
\end{tabular}
\end{center}
\caption{Ablation study on the maximum number of superpixel centroids . s- denotes different cross-validation splits.}
\label{proto_number}
\end{table}

\begin{table}[htbp]
\begin{center}
\begin{tabular}{|c|cccc|c|}
\hline
Centroids & s-0 & s-1 & s-2 & s-3 & mean\\ \hline \hline
Fixed       &  57.87       & 67.62       &  \textbf{57.10}     & 53.61    & 59.05 \\
Adaptive & \textbf{58.84}       & \textbf{67.86}       &  56.79     & \textbf{53.66}    & \textbf{59.29} \\ \hline
\end{tabular}
\end{center}
\caption{Performance comparison between fixed and adaptive superpixel centroids.}
\label{adaptive_proto}
\end{table}

\vspace{1mm}
\noindent{\textbf{SGC and GPA.}}
To demonstrate the effectiveness of proposed SGC and GPA modules, we conduct diagnostic experiments on prototype generation and matching.
We first implement a baseline model with the single prototype learning proposed in PFENet \cite{pfenet}.
Then, we introduce SGC to generate multiple prototypes, and fuse them in a dense 
manner with reference to PMMs \cite{pmms}.
Finally, we replace the prototype expansion with the proposed allocation scheme.
For ablations on the SGC module, as shown in Table \ref{methods_ablation}, in the 1-shot setting we observe that replacing mean average pooling (MAP) with SGC can worsen the representations and lead to degraded performance, but the model benefits in the 5-shot scenario.
We deem the main reason is that excessive prototypes become highly similar on a single support sample, and cosine distance can not distinguish them apart.
Finally, when GPA module is adopted for prototype matching, the performance improves by 2.70\% compared to the prototype expansion, and also the computational overhead is
much lower.






\begin{table}[htbp]
\begin{center}
\resizebox{84.3mm}{10.9mm}{
\begin{tabular}{|cc|cc|cc|c|}
\hline
\multicolumn{2}{|c|}{Generation}              & \multicolumn{2}{c|}{Matching}              & \multicolumn{2}{c|}{mIoU} & \multicolumn{1}{c|}{\multirow{2}{*}{FLOPs}} \\ \cline{1-6}
\footnotesize{MAP}   & \footnotesize{SGC}  & \footnotesize{Expand}   & \footnotesize{GPA}  & 1-shot & 5-shot & \multicolumn{1}{c|}{}                       \\ \hline \hline
        \checkmark  &           &   \checkmark      &               &  58.96    &  60.19       & 0.9G              \\
         &  \checkmark          &   \checkmark      &               &  58.31     & 61.24       & K*8.5G+0.5G             \\
  &       \checkmark    &         &  \checkmark       & \textbf{59.29}  & \textbf{63.94}    & K*5.5M+0.9G          \\ \hline
\end{tabular}}
\end{center}
\caption{Ablation study on prototype generation (Masked average pooling (MAP) vs. SGC) and matching (Expand vs. GPA). FLOPs denotes the computational cost from prototype matching process, and K is the adaptive number of prototype (K).}
\label{methods_ablation}
\end{table}

\vspace{1mm}
\noindent{\textbf{K-shot Fusion Setting.}}
As mentioned in Section \ref{sec:k-shot}, ASGNet is able to tackle the -shot learning problem without collapsing the support features.
To explore the effect of different fusion methods, we compare our -shot setting with two other commonly used solutions: 1) feature average fusion \cite{co-fcn} and 2) attention weighted summation \cite{canet}. 
For simplicity, experiments of this ablation study are only conducted in Pascal-.
As reported in Table \ref{k-shot}, our simple strategy achieves the best performance and the largest increment over the 1-shot baseline (4.82\%) without additional computation.
On the contrary, attention-based fusion requires a large amount of computation, and has limited performance improvement.
This demonstrates that the GPA module is highly effective when given a large number of selections.


\begin{table}[htbp]
\begin{center}
\begin{tabular}{|l|ccc|}
\hline
5-shot setting & mIoU & IoU & FLOPs \\ \hline \hline
1-shot basline &     58.84     &  -   & -      \\ \hline
Attention    & 60.69         & 1.85 & 42.6G      \\ \hline
Feature-avg     &  62.10        &  3.26   & 3.7M      \\ \hline
Ours      & \textbf{63.66}       & \textbf{4.82}    &  None     \\ \hline
\end{tabular}
\end{center}
\caption{Ablation study of different -shot fusion strategy.}
\label{k-shot}
\end{table}










\subsection{Comparison to State-of-the-art}

\begin{table*}[htbp] \small
\begin{center}
\begin{tabular}{|l|l|ccccc|ccccc|c|}
\hline
\multicolumn{1}{|l|}{\multirow{2}{*}{\textbf{Backbone}}} & \multirow{2}{*}{\textbf{Methods}} & \multicolumn{5}{c|}{\textbf{1-shot}}                                                                              & \multicolumn{5}{c|}{\textbf{5-shot}}                                                                             & \multirow{2}{*}{} \multirow{2}{*}{}         \\ \cline{3-12}
\multicolumn{1}{|l|}{}                          &                          & s-0            & s-1            & s-2            & s-3            & mean                                & s-0            & s-1            & s-2            & s-3            & mean                                &                           \\ \hline\hline
\multirow{6}{*}{VGG-16}                         & OSLSM \cite{oslsm}                    & 33.60          & 55.30          & 40.90          & 33.50          & 40.80                               & 35.90          & 58.10          & 42.70          & 39.10          & 43.95                               & 3.15                      \\
                                                & co-FCN \cite{co-fcn}                   & 36.70          & 50.60          & 44.90          & 32.40          & 41.10                               & 37.50          & 50.00          & 44.10          & 33.90          & 41.40                               & 0.30                      \\
                                                & AMP \cite{amp}                      & 41.90          & 50.20          & 46.70          & 34.40          & 43.40                               & 40.30          & 55.30          & 49.90          & 40.10          & 46.40                               & 3.00                      \\
                                                & SG-One \cite{sgone}                   & 40.20          & 58.40          & 48.40          & 38.40          & 46.30                               & 41.90          & 58.60          & 48.60          & 39.40          & 47.10                               & 0.80                      \\
                                                & PANet \cite{panet}                    & 42.30          & 58.00          & 51.10          & 41.20          & 48.10                               & 51.80          & 64.60          & 59.80          & 46.50          & 55.70                               & \textbf{7.60}                      \\
                                                & FWB \cite{fwb}                      & 47.04          & 59.64          & 52.61          & 48.27          & 51.90                               & 50.87          & 62.86          & 56.48          & 50.09          & 55.08                               & 3.18                      \\ \hline
\multirow{7}{*}{ResNet50}                       & CANet \cite{canet}                    & 52.50          & 65.90          & 51.30          & 51.90          & 55.40                               & 55.50          & 67.80          & 51.90          & 53.20          & 57.10                               & 1.70                      \\
                                                & PGNet \cite{pgnet}                    & 56.00          & 66.90          & 50.60          & 50.40          & 56.00                               & 57.70          & 68.70          & 52.90          & 54.60          & 58.50                               & 2.50                      \\
                                                & RPMMs \cite{pmms}                     & 55.15          & 66.91          & 52.61          & 50.68          & 56.34                               & 56.28          & 67.34          & 54.52          & 51.00          & 57.30                               & 0.96                      \\
& SimPropNet \cite{simprop}               & 54.82          & 67.33          & 54.52          & 52.02          & 57.19                               & 57.20          & 68.50          & 58.40          & 56.05          & 60.04                               & 2.85                      \\
& PPNet \cite{ppnet}       & 47.83          & 58.75 & 53.80 & 45.63          & 51.50                               & 58.39          & 67.83          & \textbf{64.88}          & 56.73          & 61.96                               & \textbf{10.46} \\
 & PFENet \cite{pfenet}       & \textbf{61.70}          & \textbf{69.50} & 55.40 & \textbf{56.30}          & \textbf{60.80}                               & 63.10          & \textbf{70.70}          & 55.80          & \textbf{57.90}          & 61.90                               & 1.10 \\
 & ASGNet (ours) & 58.84 & 67.86          & \textbf{56.79}         & 53.66  & 59.29 & \textbf{63.66} & 70.55 & 64.17 & 57.38 & \textbf{63.94} & 4.65                      \\ \hline
\multirow{4}{*}{ResNet101}      & FWB \cite{fwb}                    & 51.30          & 64.49 & 56.71 & 52.24          & 56.19                               & 54.84          & 67.38          & 62.16          & 55.30          & 59.92                               & 3.73 \\
& DAN \cite{danet}                    & 54.70          & 68.60 & \textbf{57.80} & 51.60          & 58.20                               & 57.90          & 69.00          & 60.10          & 54.90          & 60.50                               & 2.30 \\
& PFENet \cite{pfenet}       & \textbf{60.50}          & \textbf{69.40} & 54.40 & \textbf{55.90}          & \textbf{60.10}                    & 62.80          & 70.40          & 54.90          & \textbf{57.60}          & 61.40                               &  1.30 \\
& ASGNet (ours)  & 59.84 & 67.43          & 55.59          & 54.39 & 59.31 & \textbf{64.55} & \textbf{71.32} & \textbf{64.24} & 57.33 & \textbf{64.36} & \textbf{5.05}                      \\ \hline

\end{tabular}
\end{center}
\caption{Comparison with state-of-the-art on Pascal-.  indicates multi-scale inference is adopted.  means increment over 1-shot segmentation result.}
\vspace{-3mm}
\label{pascal}
\end{table*}

\begin{table}[htbp] \small
\begin{center}
\begin{tabular}{|l|cc|c|c|}
\hline
\multirow{2}{*}{\textbf{Methods}} & \multicolumn{2}{c|}{\textbf{FB-IoU}} & \multirow{2}{*}{} & \multirow{2}{*}{\textbf{\#Params}} \\ \cline{2-3}
                                  & 1-shot             & 5-shot         &                   &                                    \\ \hline\hline
OSLSM \cite{oslsm}                            & 61.3               & 61.5           & 0.2               & 272.6M                             \\
co-FCN \cite{co-fcn}                           & 60.1               & 60.2           & 0.1               & 34.2M                              \\
AMP \cite{amp}                              & 62.2               & 63.8           & 1.6               & 14.9M                              \\
SG-One \cite{sgone}                            & 63.1               & 65.9           & 2.8               & 19.0M                              \\
CANet \cite{canet}                            & 66.2               & 69.6           & 3.4               & 10.5M                              \\
PGNet \cite{pgnet}                           & 69.9               & 70.5           & 0.6               & -                             \\
PANet \cite{panet}                            & 66.5               & 70.7           & 4.2               & 14.7M                              \\ 
DAN \cite{danet}                            & 71.9               & 72.3           & 0.4               & -      \\
SimPropNet \cite{simprop}                            & 73.0               & 72.9           & -0.1               & -                              \\
PFENet \cite{pfenet}                            & \textbf{73.3}               & 73.9           & 0.6               & 10.8M                              \\ \hline
ASGNet (RN-50)                            & 69.2          & 74.2               &  \textbf{5.0}                 & \textbf{10.4M}    \\
ASGNet (RN-101)                            & 71.7          & \textbf{75.2}               & 3.5                 & \textbf{10.4M}     \\ \hline
\end{tabular}
\end{center}
\caption{Comparison of FB-IoU and the number of trainable parameters on Pascal-.  indicates multi-scale inference is adopted.  means increment over 1-shot segmentation result.}
\vspace{-3mm}
\label{pascal_fb}
\end{table}

\begin{table}[htbp]\footnotesize
\begin{center}
\begin{tabular}{|l|l|cc|cc|}
\hline
\multirow{2}{*}{\textbf{Backbone}} & \multirow{2}{*}{\textbf{Methods}} & \multicolumn{2}{c|}{\textbf{mIoU}} & \multicolumn{2}{c|}{\textbf{FB-IoU}} \\ \cline{3-6} 
                                   &                                   & 1-shot               & 5-shot      & 1-shot                & 5-shot       \\ \hline\hline
\multirow{3}{*}{ResNet101}         & FWB \cite{fwb}                              & 21.19                & 23.65       & -                     & -            \\ 
                                   & DAN \cite{danet}                             & 24.20                & 29.60       & \textbf{62.30}        & 63.90        \\ 
                                   & PFENet \cite{pfenet}                             & 32.40                & 37.40       & 58.60        & 61.90        \\ \hline
\multirow{2}{*}{ResNet50}          & RPMMs \cite{pmms}                             & 30.58                & 35.52       & -                     & -            \\ 
                                   & ASGNet                            & \textbf{34.56}       &  \textbf{42.48}           & 60.39                 &  \textbf{66.96}            \\ \hline
\end{tabular}
\end{center}
\caption{Comparison with state-of-the-arts on COCO-.}
\vspace{-5mm}
\label{coco}
\end{table}

\vspace{1mm}
\noindent{\textbf{Pascal-\bm{}.}}
Comparisons to state-of-the-art methods are shown in Table \ref{pascal} and \ref{pascal_fb}, where two different metrics are adopted.
In Table \ref{pascal}, with ResNet-101 as the backbone, ASGNet outperforms recent methods with a considerable margin of 2.40\% in 5-shot segmentation, while being on par with state-of-the-arts under the 1-shot setting.
In Table \ref{pascal_fb}, we further make comparisons on FB-IoU and the number of trainable parameters.
Once again, the proposed ASGNet achieves significant improvement over state-of-the-arts in 5-shot setting (75.2\% vs.73.9\%), and it also has the largest performance increment of 5.0\% over 1-shot result.
In addition, we have far fewer trainable parameters than other methods.
In Figure \ref{qualitative}, we show some representative segmentation examples.
We observe that the proposed ASGNet can generate accurate segmentation results even when there are large variations in appearance and pose between support and query images.


\begin{figure}[t]
\centering
\includegraphics[width=8.4cm]{qualitative_examples.eps}
\caption{Qualitative examples of 1-shot segmentation on the Pascal-. Best viewed in color and zoom in.}
\vspace{-3mm}
\label{qualitative}
\end{figure}


\vspace{1mm}
\noindent{\textbf{COCO-\bm{}.}} In Table \ref{coco}, we present the performance comparison of mean IoU and FB-IoU on COCO-.
As can be seen, ASGNet achieves state-of-the-art results in both 1-shot and 5-shot setting in terms of the mean IoU, and it substantially outperforms previous methods.
Particularly, ASGNet achieves a margin of 3.98\% and 6.96\% higher mean IoU over RPMMs~\cite{pmms} in 1-shot and 5-shot segmentation respectively.
Also, our ASGNet obtains competitive 1-shot results and top-performing 5-shot results with respect to FB-IoU.
These results demonstrate that the proposed method is capable of handling more complex cases, as MSCOCO is a much more challenging dataset with diverse samples and categories.




%
