[{'LEADERBOARD': {'Task': 'Reading Comprehension', 'Dataset': 'MuSeRC', 'Metric': 'Average F1', 'Score': '0.806'}}, {'LEADERBOARD': {'Task': 'Reading Comprehension', 'Dataset': 'MuSeRC', 'Metric': 'EM', 'Score': '0.42'}}, {'LEADERBOARD': {'Task': 'Reading Comprehension', 'Dataset': 'MuSeRC', 'Metric': 'Average F1', 'Score': '0.587'}}, {'LEADERBOARD': {'Task': 'Reading Comprehension', 'Dataset': 'MuSeRC', 'Metric': 'EM', 'Score': '0.242'}}, {'LEADERBOARD': {'Task': 'Question Answering', 'Dataset': 'DaNetQA', 'Metric': 'Accuracy', 'Score': '0.915'}}, {'LEADERBOARD': {'Task': 'Question Answering', 'Dataset': 'DaNetQA', 'Metric': 'Accuracy', 'Score': '0.621'}}, {'LEADERBOARD': {'Task': 'Common Sense Reasoning', 'Dataset': 'PARus', 'Metric': 'Accuracy', 'Score': '0.982'}}, {'LEADERBOARD': {'Task': 'Common Sense Reasoning', 'Dataset': 'PARus', 'Metric': 'Accuracy', 'Score': '0.486'}}, {'LEADERBOARD': {'Task': 'Common Sense Reasoning', 'Dataset': 'RuCoS', 'Metric': 'Average F1', 'Score': '0.93'}}, {'LEADERBOARD': {'Task': 'Common Sense Reasoning', 'Dataset': 'RuCoS', 'Metric': 'EM', 'Score': '0.89'}}, {'LEADERBOARD': {'Task': 'Common Sense Reasoning', 'Dataset': 'RuCoS', 'Metric': 'Average F1', 'Score': '0.26'}}, {'LEADERBOARD': {'Task': 'Common Sense Reasoning', 'Dataset': 'RuCoS', 'Metric': 'EM', 'Score': '0.252'}}, {'LEADERBOARD': {'Task': 'Common Sense Reasoning', 'Dataset': 'RWSD', 'Metric': 'Accuracy', 'Score': '0.662'}}, {'LEADERBOARD': {'Task': 'Common Sense Reasoning', 'Dataset': 'RWSD', 'Metric': 'Accuracy', 'Score': '0.84'}}, {'LEADERBOARD': {'Task': 'Word Sense Disambiguation', 'Dataset': 'RUSSE', 'Metric': 'Accuracy', 'Score': '0.805'}}, {'LEADERBOARD': {'Task': 'Word Sense Disambiguation', 'Dataset': 'RUSSE', 'Metric': 'Accuracy', 'Score': '0.57'}}, {'LEADERBOARD': {'Task': 'Natural Language Inference', 'Dataset': 'TERRa', 'Metric': 'Accuracy', 'Score': '0.92'}}, {'LEADERBOARD': {'Task': 'Natural Language Inference', 'Dataset': 'TERRa', 'Metric': 'Accuracy', 'Score': '0.471'}}, {'LEADERBOARD': {'Task': 'Natural Language Inference', 'Dataset': 'RCB', 'Metric': 'Average F1', 'Score': '0.68'}}, {'LEADERBOARD': {'Task': 'Natural Language Inference', 'Dataset': 'RCB', 'Metric': 'Accuracy', 'Score': '0.702'}}, {'LEADERBOARD': {'Task': 'Natural Language Inference', 'Dataset': 'RCB', 'Metric': 'Average F1', 'Score': '0.301'}}, {'LEADERBOARD': {'Task': 'Natural Language Inference', 'Dataset': 'RCB', 'Metric': 'Accuracy', 'Score': '0.441'}}, {'LEADERBOARD': {'Task': 'Natural Language Inference', 'Dataset': 'LiDiRus', 'Metric': 'MCC', 'Score': '0.626'}}, {'LEADERBOARD': {'Task': 'Natural Language Inference', 'Dataset': 'LiDiRus', 'Metric': 'MCC', 'Score': '0.06'}}]
