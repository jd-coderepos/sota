\documentclass[letterpaper]{article} \usepackage{aaai23}  \usepackage{times}  \usepackage{helvet}  \usepackage{courier}  \usepackage[hyphens]{url}  \usepackage{graphicx} \urlstyle{rm} \def\UrlFont{\rm}  \usepackage{natbib}  \usepackage{caption} \frenchspacing  \setlength{\pdfpagewidth}{8.5in}  \setlength{\pdfpageheight}{11in}  \usepackage{algorithm}
\usepackage{algorithmic}
\usepackage[table]{xcolor}
\usepackage{color, xcolor}
\usepackage{amsmath}
\usepackage{multirow}
\usepackage{pifont}
\usepackage{graphicx}


\usepackage{float}



\usepackage{newfloat}
\usepackage{listings}
\DeclareCaptionStyle{ruled}{labelfont=normalfont,labelsep=colon,strut=off} \lstset{basicstyle={\footnotesize\ttfamily},numbers=left,numberstyle=\footnotesize,xleftmargin=2em,aboveskip=0pt,belowskip=0pt,showstringspaces=false,tabsize=2,breaklines=true}
\floatstyle{ruled}
\newfloat{listing}{tb}{lst}{}
\floatname{listing}{Listing}
\pdfinfo{
/TemplateVersion (2023.1)
}



\setcounter{secnumdepth}{0} 





\title{Hybrid-SORT: Weak Cues Matter for Online Multi-Object Tracking}



\author {
Mingzhan Yang \textsuperscript{\rm 1,\rm 2}\equalcontrib,
    Guangxin Han \textsuperscript{\rm 1}\equalcontrib, 
    Bin Yan \textsuperscript{\rm 1},
    Wenhua Zhang \textsuperscript{\rm 1},
    Jinqing Qi \textsuperscript{\rm 1},
    Huchuan Lu \textsuperscript{\rm 1},
    Dong Wang \textsuperscript{\rm 1}
}
\affiliations {
\textsuperscript{\rm 1} Dalian University of Technology\\
    \textsuperscript{\rm 2} Shenzhen Tvt Digital Technology Co., Ltd\\
}


\iffalse
\author{
Written by AAAI Press Staff\textsuperscript{\rm 1}\thanks{With help from the AAAI Publications Committee.}\\
    AAAI Style Contributions by Pater Patel Schneider,
    Sunil Issar,\\
    J. Scott Penberthy,
    George Ferguson,
    Hans Guesgen,
    Francisco Cruz\equalcontrib,
    Marc Pujol-Gonzalez\equalcontrib
}
\affiliations{
\textsuperscript{\rm 1}Association for the Advancement of Artificial Intelligence\\




    1900 Embarcadero Road, Suite 101\\
    Palo Alto, California 94303-3310 USA\\
publications23@aaai.org
}
\fi

\iffalse
\title{My Publication Title --- Single Author}
\author {
    Author Name
}
\affiliations{
    Affiliation\\
    Affiliation Line 2\\
    name@example.com
}
\fi

\iffalse
\title{My Publication Title --- Multiple Authors}
\author {
First Author Name,\textsuperscript{\rm 1,\rm 2}
    Second Author Name, \textsuperscript{\rm 2}
    Third Author Name \textsuperscript{\rm 1}
}
\affiliations {
\textsuperscript{\rm 1} Affiliation 1\\
    \textsuperscript{\rm 2} Affiliation 2\\
    firstAuthor@affiliation1.com, secondAuthor@affilation2.com, thirdAuthor@affiliation1.com
}
\fi


\usepackage{bibentry}


\begin{document}

\maketitle

\begin{abstract}
Multi-Object Tracking (MOT) aims to detect and associate all desired objects across frames. Most methods accomplish the task by explicitly or implicitly leveraging strong cues (i.e., spatial and appearance information), which exhibit powerful instance-level discrimination. However, when object occlusion and clustering occur, both spatial and appearance information will become ambiguous simultaneously due to the high overlap between objects. In this paper, we demonstrate that this long-standing challenge in MOT can be efficiently and effectively resolved by incorporating weak cues to compensate for strong cues. Along with velocity direction, we introduce the confidence state and height state as potential weak cues. With superior performance, our method still maintains Simple, Online and Real-Time (SORT) characteristics. Furthermore, our method shows strong generalization for diverse trackers and scenarios in a plug-and-play and training-free manner. Significant and consistent improvements are observed when applying our method to 5 different representative trackers. Further, by leveraging both strong and weak cues, our method Hybrid-SORT achieves superior performance on diverse benchmarks, including MOT17, MOT20, and especially DanceTrack where interaction and occlusion are frequent and severe. The code and models are available at \textcolor{red}{https://github.com/ymzis69/HybirdSORT}. 

\end{abstract}












\section{Introduction}
Recently, tracking-by-detection \textcolor{blue}{\cite{bewley2016simple, wojke2017simple, chen2018real, zhang2021fairmot, zhang2022bytetrack, du2023strongsort, ren2023focus, qin2023motiontrack, cao2023observation}} has become the most popular paradigm in Multi-Object-Tracking (MOT), which divides the problem into two sub-tasks. The first task is to detect objects in each frame. The second task is to associate them in different frames. The association task is primarily solved by explicitly or implicitly utilizing strong cues, including spatial and appearance information. This design is reasonable because these strong cues provide powerful instance-level discrimination for each object (i.e., global discrimination). However, the commonly used strong cues suffer from degradation under challenging situations such as occlusion and clustering (ID 1 and 2 in Figure \ref{Motivation}). Specifically, when two objects are highly overlapped in the current frame, the Intersection over Union (IoU) between detections and estimated tracklet locations becomes ambiguous, and the appearance features of both objects are dominated by the foreground ones (red dash arrow in the top-right part of Figure \ref{Motivation}). 

In the bottom-right part of Figure \ref{Motivation}, we demonstrate that weak cues, such as confidence state, height state, and velocity direction, can effectively alleviate the ambiguous associations where strong cues become unreliable. However, to the best of our knowledge, weak cues have been ignored in most methods except for very few (e.g., OC-SORT \textcolor{blue}{\cite{cao2023observation}}, MT-IOT \textcolor{blue}{\cite{yan2022multiple}}, as they only possess reliable discrimination among certain objects. As shown in Figure \ref{Motivation}, the confidence state is only discriminative between ID 2 and other IDs). 

In this paper, we select the confidence state and height state as potential types of weak cues, in addition to the velocity direction used in OC-SORT \textcolor{blue}{\cite{cao2023observation}}. The confidence state can explicitly indicate the occluding/occluded (foreground/background) relations among clustered objects, providing a critical clue that strong cues (i.e., spatial and appearance information) lack. Height state is a stable property of objects which is usually robust to diverse object poses and contains some degree of depth information (i.e., reflects the distance from the camera to the objects).

To maintain the simplicity, online and real-time (SORT) capacity, we propose simple yet effective strategies to exploit the aforementioned weak cues and leverage them in the association step, namely Tracklet Confidence Modeling (TCM) and Height Modulated IoU (HMIoU). Both of the modeling consists of two parts: state estimation and cost computation. In state estimation, we use Kalman Filter and Linear Prediction to estimate the confidence state of tracklets based on historical confidence states of tracklets, which is then used as a metric to associate with high-confidence and low-confidence detections. For the height state, we also use Kalman Filter for estimation. In cost computation for the association, the confidence cost matrix is the absolute difference between the estimated tracklet confidence and detection confidence. The height cost matrix is first defined as the IoU along the height axis for the estimated tracklet box and detection box, then fused with the IoU matrix generated from spatial information.

To evaluate the generalization ability of our design, we apply the proposed modeling to 5 different representative trackers, including SORT \textcolor{blue}{\cite{bewley2016simple}}, DeepSORT \textcolor{blue}{\cite{wojke2017simple}}, MOTDT \textcolor{blue}{\cite{chen2018real}}, ByteTrack \textcolor{blue}{\cite{zhang2022bytetrack}}, and OC-SORT \textcolor{blue}{\cite{cao2023observation}}. Both of our designs for confidence state and height state consistently achieve significant improvements, demonstrating the importance of weak cues in the association task. For example, by applying Tracklet Confidence Modeling (TCM) to DeepSORT, the HOTA increases by 4.9 on the DanceTrack validation
set and 0.9 on the MOT17 validation set. By applying Height Modulated IoU (HMIoU) to SORT, the HOTA increases by 1.6 on the DanceTrack validation set and 1.0 on
the MOT17 validation set. 

Further, to advance the state-of-the-art performance of Simple, Online, and Real-Time (SORT) MOT methods, we modify the current state-of-the-art SORT-like algorithm OC-SORT \textcolor{blue}{\cite{cao2023observation}} as our strong baseline. Firstly, we modify the velocity direction modeling in OC-SORT, namely Observation-Centric Momentum (OCM), by extending the box center to four box corners and the fixed temporal interval to multiple intervals. Secondly, we include an additional association stage for low-confidence detection following ByteTrack \textcolor{blue}{\cite{zhang2022bytetrack}}. Along with the proposed TCM and HMIoU, our method Hybrid-SORT achieves superior performance on all DanceTrack, MOT17, and MOT20 benchmarks by leveraging both strong and weak cues, while still maintaining Simple, Online and Real-Time (SORT). We hope that the generalization ability, plug-and-play and training-free characteristics of Hybrid-SORT make it attractive for diverse real-world scenarios and edge devices. Our contributions can be summarized as follows:

\begin{itemize}
\item We demonstrate the long-standing challenges of occlusion and clustering can be substantially alleviated by incorporating weak cues (i.e., confidence state, height state and velocity direction) as compensation for commonly used strong cues.
\item We introduce simple Tracklet Confidence Modeling (TCM) and Height Modulated IoU (HMIoU) to model and leverage the confidence state and height state. With delicate modeling, the weak cues effectively and efficiently relieve the ambiguous matches generated by strong cues with negligible additional computation.
\item The plug-and-play and training-free design generalizes well over diverse scenarios and trackers. We implement our design on 5 representative trackers, achieving consistent and significant improvements. Finally, Our method Hybrid-SORT achieves superior performance on DanceTrack, MOT17, and MOT20 benchmarks. \end{itemize}

\begin{figure*}[t]
\centering
\includegraphics[width=0.9\textwidth]{CameraReady/LaTeX/motivation.pdf} \caption{The discrimination of strong and weak cues. Based on historical tracklets and current detections, we can \textbf{reliably} discriminate between pairwise objects using \textcolor[RGB]{50, 205, 50}{green solid arrows}, while \textcolor{red}{red dashed arrows} indicate \textbf{unreliable} discrimination. The higher the value of the arrow, the more reliable the discrimination is. Existing works commonly rely on strong cues, such as spatial and appearance information, to distinguish all objects \textbf{theoretically}. However, these cues suffer from simultaneous degradation under challenging situations like occlusion and clustering. In contrast, weak cues, such as confidence state, height state, and velocity direction, can provide reliable discrimination and resolve ambiguous or incorrect matches generated by strong cues. Unfortunately, existing works tend to overlook weak cues because they can only maintain discrimination between certain objects.} \label{Motivation}
\end{figure*}

\section{Related Work}
\subsection{Heuristic Matcher}
\subsubsection{Spatial-based Heuristic Matcher}
Spatial information is the most widely used strong cue in high-FPS benchmarks. When time intervals between frames are short, the movement of an object is also small and can be treated as linear. This makes spatial information an accurate metric in the short-term association. The pioneer work SORT \textcolor{blue}{\cite{bewley2016simple}} uses Kalman Filter \textcolor{blue}{\cite{kalman1960contributions}} to predict the spatial locations of tracklets and associates them with detection boxes based on the IoU metric. Subsequent works, such as CenterTrack \textcolor{blue}{\cite{zhou2020tracking}}, ByteTrack \textcolor{blue}{\cite{zhang2022bytetrack}}, and OC-SORT \textcolor{blue}{\cite{cao2023observation}}, are all heuristic matching methods that utilize spatial information to match tracklets with detection boxes. However, even the most advanced method, OC-SORT \textcolor{blue}{\cite{cao2023observation}}, still suffers from heavy occlusion and clustering. 

\subsubsection{Appearance-based Heuristic Matcher}
Unlike spatial information, appearance information possesses relatively stable consistency throughout the whole video, thus benefiting long-term association. Following SORT, DeepSORT \textcolor{blue}{\cite{wojke2017simple}} incorporated an independent ReID model to extract appearance features for the association. Then the following work JDE \textcolor{blue}{\cite{wang2020towards}}, FairMOT \textcolor{blue}{\cite{zhang2021fairmot}}, CSTrack \textcolor{blue}{\cite{liang2022rethinking}} and QDTrack \textcolor{blue}{\cite{pang2021quasi}} integrated the detection and ReID models for joint training and devised improved network architectures to enhance performance. However, we observe that among clustered objects, both spatial and appearance cues suffer from severe discrimination degradation, even if delicate network architectures and association strategies are designed for joint utilization of both spatial and appearance information. 





\subsection{Learnable Matcher}
\subsubsection{Graph-based Learnable Matcher}
Graph-based learnable matchers formulate the association task as an edge classification task, where the edge label is 1 for tracklet nodes and detection nodes with the same ID and vice versa. MOTSolv \textcolor{blue}{\cite{braso2020learning}} and GMTracker \textcolor{blue}{\cite{he2021learnable}} are based on Graph Neural Network (GNN) and make the data association step differentiable.  Most recently, SUSHI \textcolor{blue}{\cite{cetintas2023unifying}} leverages graph models to hierarchically connect short tracklets into longer tracklets in an offline fashion. However, the major limitation of graph-based matchers is that the training and inference pipeline is often complicated or even offline, which restricts their practical use in online tracking scenarios that impose strict real-time demands, such as autonomous driving. 

\subsubsection{Transformer-based Learnable Matcher}
Since the Transformer became popular in vision tasks, many works are proposed to utilize its powerful attention mechanism to model the association task. TrackFormer \textcolor{blue}{\cite{meinhardt2022trackformer}} and MOTR \textcolor{blue}{\cite{zeng2022motr}} utilize both track queries and standard detection queries to jointly perform trajectory propagation and initialization. Most recently, MOTRv2 \textcolor{blue}{\cite{zhang2023motrv2}} introduces a separate detector to MOTR, trying to resolve the conflict between detection and association. However, the Transformer-based matchers involve a significant number of self/cross-attention operations, preventing the algorithm from achieving real-time capability. 



\section{Method}
In this section, we first present our strategies to exploit the newly introduced weak cues (i.e., confidence state and height state), namely Tracklet Confidence Modeling (TCM) and Height Modulated IoU (HMIoU) in Section 3.1. The two proposed modeling can be applied to various trackers in a plug-and-play and training-free manner. Further, to put forward the state-of-the-art performance of SORT-like algorithms, we propose Hybrid-SORT by incorporating the modeling of weak cues into the enhanced OC-SORT in Section 3.2. The enhancement includes Robust OCM for more detailed and robust modeling of velocity direction, and BYTE in ByteTrack \textcolor{blue}{\cite{zhang2022bytetrack}} for association with low-confidence detection. Additionally, we incorporate an independent ReID model from BoT-SORT \textcolor{blue}{\cite{aharon2022bot}} for joint utilization of multiple types of strong and weak cues, leading to Hybrid-SORT-ReID. Finally, we provide an overview of the association framework and the pseudo-code for Hybrid-SORT and Hybrid-SORT-ReID.


\begin{figure*}[t]
\centering
\includegraphics[width=0.9\textwidth]{CameraReady/LaTeX/pipeline.pdf} \caption{Pipeline of Hybrid-SORT and Hybrid-SORT-ReID. For strong cues, we utilize IoU as the metric for spatial information, and utilize cosine distance for appearance features if the ReID model is incorporated. For weak cues, we incorporate the confidence state, height state, and velocity direction. All weak cues are modeled using a shared Kalman Filter or simple handcrafted Tracklet Memory, both with negligible additional computation. Velocity direction is illustrated by centers instead of corners for better clarity.}
\label{pipeline}
\end{figure*}




\subsection{Weak Cues Modeling}
In this section, we introduce two novel techniques for modeling confidence state and height state, namely Tracklet Confidence Modeling (TCM) and Height Modulated IoU (HMIoU), which are both plug-and-play and training-free.

\subsubsection{Tracklet Confidence Modeling}

\begin{figure}[ht]
\centering
\includegraphics[width=0.9\columnwidth]{CameraReady/LaTeX/TCM_small.pdf} \caption{The confidence curve of an object. When the confidence of a \textcolor[RGB]{50, 205, 50}{detected} object decreases suddenly due to occlusion, the tracklet confidence estimated by the \textcolor{red}{Kalman Filter} lags behind the actual confidence. In contrast, the \textcolor{orange}{Linear Prediction} method provides a more accurate estimation.}
\label{TCM}
\end{figure}

We demonstrate that the previously overlooked confidence state is effective information to compensate for the ambiguity of strong cues when heavy occlusion and clustering happen. From the high-level perspective, it is common sense and the key guideline that the states of tracklets in each time step should change continuously. As one of the states provided by the detector, the confidence state belonging to the same trajectory should also exhibit temporal continuity. However, the confidence state is ignored by existing methods as it lacks global discrimination to distinguish all objects (i.e., the confidence is distinct only for certain objects). 

The reason why the confidence state helps association is straightforward. Specifically, when both commonly used strong cues (i.e., spatial and appearance information) fails as multiple objects are highly overlapped, the confidence of objects provides explicit foreground/background (i.e., occluding/occluded) relationships, which is exactly what strong cues lack. This is because detecting unobstructed objects tends to result in higher confidence scores, while occluded objects pose greater challenges for detection, leading to lower confidence scores.

Based on this insight, we introduce two modeling approaches for tracklet confidence to association with high-confidence and low-confidence detections. When objects are unobstructed or only slightly occluded, Kalman Filter is an ideal model for modeling and estimating the continuous state that varies within a small range. Therefore, we extend the widely used standard Kalman Filter in SORT \textcolor{blue}{\cite{bewley2016simple}} with two additional states: the tracklet confidence  and its velocity component . For better clarity, we first revisit the standard Kalman Filter states in SORT, depicted in Eq. \ref{eq:sort_kf}. Here,  and  denote the object's center, while  and  represent the object box's scale (area) and aspect ratio, respectively. The velocity components are denoted by , , and . 



With the two newly introduced states  and , the complete states of Kalman Filter in TCM are shown in Eq. \ref{eq:tcm_kf}. 



For low-confidence detections in the second association step, we utilize Linear Prediction to estimate the tracklet confidence. ByteTrack has demonstrated that low detection confidence typically corresponds to heavy occlusion and clustering. The confidence of objects will rapidly increase or decrease during the occlusion starts or ends. Unfortunately, Kalman Filter exhibits significant lag when attempting to estimate sudden changes in the confidence state, as shown in Figure \ref{TCM}. However, we observe that the trend of changes in the confidence state during this short period exhibits clear directionality (i.e., consistently increasing or decreasing). Therefore, we use a simple Linear Prediction based on trajectory history to address this issue. The formula for linear modeling is given by Eq. \ref{eq:tcm_lp}, where  represents the confidence of tracklets saved in Tracklet Memory.




When utilizing either Kalman Filter or Linear Prediction, the confidence cost is calculated as the absolute difference between the estimated tracklet confidence  and detection confidence  following Eq. \ref{eq:confidence_cost}. 




\subsubsection{Height Modulated IoU}

\begin{figure}[ht]
\centering
\includegraphics[width=0.9\columnwidth]{CameraReady/LaTeX/HMIoU.pdf} \caption{Illustration of IoU, HIoU and HMIoU.} \label{fig:HMIoU}
\end{figure}

Identifying the temporally stable properties of objects is one of the most critical aspects of multiple object tracking (MOT). In addition to confidence states, height state also provides informative weak clues that help to compensate for the discrimination of strong cues. Specifically, height state enhances association in two aspects. Firstly, the height of objects reflects depth information to some extent. For datasets such as DanceTrack, the height of detection boxes mainly depends on the distance between objects and the camera. This makes the height state an effective cue for distinguishing highly overlapped objects. Secondly, the height state is relatively robust to diverse poses, making it an accurately estimated state and a high-quality representation of objects. 

\begin{figure}[b]
\centering
\includegraphics[width=0.9\columnwidth]{CameraReady/LaTeX/height_over_width.pdf} \caption{The variation of the object height and width over time.} \label{fig:height_over_width}
\end{figure}

A natural question arises as to why object width is not a preferred state. The reason is that the width of the object box in the image tends to change irregularly due to pose changes or limb movements, which is especially severe in the DanceTrack dataset, as shown in Figure \ref{fig:height_over_width}. The highly irregular and sudden changes in states are difficult for Kalman Filter to estimate precisely. In contrast, the height state typically changes only when objects squat or stand up, which is a relatively short and continuous process that can be effectively modeled using Kalman Filter.

The utilization of the height state is visually represented in Figure \ref{fig:HMIoU}. Specifically, we define the two boxes as  and  in which  and  represents the top-left corner while  an  represents the bottom-right corner. Also, we define the areas of two boxes as  and . The computation of conventional IoU is shown in Eq. \ref{eq:IoU} and Figure \ref{fig:HMIoU} (a), which is based on the area metric. Further, the Height IoU (HIoU) can be generated by computing the IoU based on the height metric, as in Eq. \ref{eq:HIoU} and Figure \ref{fig:HMIoU} (b). 









To better utilize the height state, we introduce Height Modulated IoU (HMIoU) by combining Height IoU (HIoU) with the conventional IoU, as shown in Eq. \ref{eq:HMIoU} and Figure \ref{fig:HMIoU} (c). The  means element-wise multiplication. Considering the HIoU represents the height state which is a weak cue, and IoU represents the spatial information which is a strong cue, we use HIoU to modulate the IoU by element-wise multiplication, achieving enhanced discrimination for occluded or clustered objects. 




\subsection{Hybrid-SORT}
In this section, we introduce Hybrid-SORT and Hybrid-SORT-ReID. For Hybrid-SORT, we combine the proposed techniques of Tracklet Confidence Modeling (TCM) and Height Modulated IoU (HMIoU) with an enhanced version of OC-SORT, which is modified in two ways. Firstly, we replace Observation-Centric Momentum (OCM) with Robust OCM for more robust modeling of velocity direction. Secondly, we include low-confidence detections in the association following ByteTrack. For Hybrid-SORT-ReID, we incorporate an independent ReID model to enhance tracking performance. 

\subsubsection{Robust OCM}
In OC-SORT, the Observation-Centric Momentum (OCM) considers the velocity direction of object centers in the association. The cost metric used in OCM is the absolute difference between the tracklet velocity direction  and the tracklet-to-detection velocity direction  in radians format, which is expressed as . The tracklet velocity direction is obtained from two box centers in the tracklet at a temporal interval , and the tracklet-to-detection velocity direction is obtained from the centers of a tracklet historical box and a new detection box. Given two points  and , the velocity direction is computed as Eq. \ref{eq:velocity_direction}. However, the modeling of the original OCM is vulnerable to noise caused by fixed temporal intervals and sparse states (i.e., only object centers).




In this section, we enhance the OCM by introducing more detailed and robust modeling to provide a more comprehensive and accurate representation of the velocity direction of objects. Our modifications include two aspects. Firstly, we extend the fixed time interval of 3 frames to the stack of multiple intervals ranging from 1 to 3. Secondly, we use the four corners of the object instead of its center point to calculate the velocity direction. As illustrated in Figure \ref{Better_OCM}, given a tracklet and its correctly matched detection, the tracklet and tracklet-to-detection velocity direction of centers can be completely opposite due to sudden pose changes, leading to the incorrect match. By extending the centers to corners, the tracklet and tracklet-to-detection velocity directions of the 2 left corners remain high similarity, thus generating a correct match. This further demonstrates the higher robustness of calculating OCM using the four corners. With multiple temporal intervals, the calculation formula for the Robust OCM is as Eq. \ref{eq:ROCM}:




\begin{figure}[t]
\centering
\includegraphics[width=0.9\columnwidth]{CameraReady/LaTeX/Better_OCM_green.pdf} \caption{Velocity direction of the center and corners. Resulted of limb movements and pose changing, the velocity direction of the center obtained in the current frame will be completely opposite to the velocity direction maintained in the tracklet. Using four corner points to calculate the velocity direction will be more robust.}
\label{Better_OCM}
\end{figure}


\begin{algorithm}[H]
\caption{Pseudo-code of Hybrid-SORT and Hybrid-SORT-ReID. \protect\\Our contributions in \textcolor[RGB]{50, 205, 50}{green} and ReID components in \textcolor{cyan}{blue}.}
\label{alg:algorithm}
\textbf{Input}: Detections ; \textcolor{cyan}{Appearance Features }; Kalman Filter KF; detection score threshold ; threshold to remove untracked tracks \\
\textbf{Output}: Tracks {\huge } of the video

\begin{algorithmic}[1] \STATE  Initialization:  {\huge }  and KF;
\FOR{timestep }

\STATE {\color{gray}{Step 1: association with high confidence box}} 



\STATE   
\STATE  from {\huge }  {\color{gray}{KF.predect}} 
\STATE   \STATE  \STATE  Linear assignment by Hungarians with cost 
\STATE  {\huge } tracks matched to a detection
\STATE  {\huge } tracks not matched to any detections
\STATE   detections not matched to any tracklet
\STATE  \textcolor{cyan}{update appearance features by EMA in {\huge }} 

\STATE
\STATE  {\color{gray}{Step 2: association with low confidence box in ByteTrack}} 
\STATE   
\STATE   from {\huge }
\STATE      \STATE  

\STATE  Linear assignment by Hungarians with cost 
\STATE  update {\huge } and {\huge }

\STATE
\STATE  {\color{gray}{Step 3: perform OCR to find lost tracks back in OC-SORT}} 
\STATE   last matched detection of tracks in {\huge }
\STATE   \STATE  Linear assignment by Hungarians with cost 
\STATE   detection unmatched to tracks
\STATE  update {\huge } and \ \ {\huge }

\STATE
\STATE  {\color{gray}{Step 4: update states of matched tracks in OC-SORT}} 
\FOR{{\huge } in {\huge }}
\STATE update KF.parameters through ORU in OC-SORT
\ENDFOR

\STATE
\STATE  {\color{gray}{Step 5: initialize and remove tracks}} 
\STATE  {\huge }   new tracks generated from 
\FOR{{\huge } in {\huge } }
\STATE remove  {\huge }  {\huge }
\ENDFOR
\STATE  {\huge }  {\huge } {\huge }

\ENDFOR
\STATE  {\huge }  Postprocess({\huge })  {\color{gray}{[Optional] offline processing}}
\STATE \textbf{return} {\huge }
\end{algorithmic}
\end{algorithm}




\subsubsection{Appearance Modeling}
We incorporate appearance information using an independent ReID model, as illustrated in Figure \ref{Motivation}. Following BoT-SORT, our pipeline first detects objects and then feeds the resulting cropped patches into the ReID model. We model tracklet appearance information using Exponential Moving Average (EMA), and utilize cosine distance as the metric for computing similarity between tracklet appearance features and detection appearance features. Note that the ReID components are not the focus of our paper. 

\subsubsection{Algorithm Framework}
The association stage primarily consists of three stages: the first association stage for high-confidence objects, the second association stage for low-confidence objects (BYTE in ByteTrack), and the third association stage to recover lost tracklets with their last detection (OCR in OC-SORT). 

Taking into account all the aforementioned strong and weak cues, the final cost matrix basically comprises the following terms: 


The pseudo-code of Hybrid-SORT and Hybrid-SORT-ReID are shown in Algorithm \ref{alg:algorithm}. 





























\section{Experiments}
\subsection{Experimental Setting}
\subsubsection{Datasets}
We evaluated our design on various MOT benchmarks, including DanceTrack \textcolor{blue}{\cite{sun2022dancetrack}}, MOT20 \textcolor{blue}{\cite{dendorfer2020mot20}} and MOT17 \textcolor{blue}{\cite{milan2016mot16}}. DanceTrack is currently one of the most challenging benchmarks in the MOT field, characterized by diverse non-linear motion patterns as well as frequent interactions and occlusions. It is noteworthy that the detection task in DanceTrack is relatively easy, making it an ideal benchmark to evaluate association performance. MOT20 was developed to evaluate algorithms under dense objects and severe occlusions. MOT17 is a widely used standard benchmark in MOT, in which the motion is mostly linear. Given the characteristics of these benchmarks, we primarily focus on comparing our approach to DanceTrack as we aim to improve association performance with weak cues in challenging situations, especially where strong cues fail. We use MOT17 and MOT20 to evaluate the generalization ability of our approach under diverse scenarios. The MOT17 validation set follows a widely adopted convention \textcolor{blue}{\cite{zhou2020tracking}}, where the train set is split into halves for training and validation.  



\subsubsection{Metrics}
We selected HOTA\textcolor{blue}{\cite{luiten2021hota}} as our primary metric due to its higher-order nature. HOTA 
combines several sub-metrics that evaluate algorithms from different perspectives, providing a comprehensive assessment of algorithm performance. In addition to HOTA, we also include other well-established metrics, such as MOTA \textcolor{blue}{\cite{bernardin2008evaluating}} and IDF1 \textcolor{blue}{\cite{ristani2016performance}}. IDF1 reflects the association aspect of the tracker, while MOTA is primarily influenced by detection performance. We believe that these metrics provide a comprehensive evaluation of algorithm performance. 



\subsubsection{Implementation Details}
To ensure a fair comparison and demonstrate the superiority of our Hybrid-SORT, we directly adapt publicly available detection and ReID models from existing works. Specifically, for the detection part, we use the same detection model (i.e., YOLOX \textcolor{blue}{\cite{ge2021yolox}}) as our baseline OC-SORT on DanceTrack, MOT17, and MOT20. Likewise, for the ReID part, we use the model (i.e., BoT \textcolor{blue}{\cite{luo2019strong}}) in BoT-SORT \textcolor{blue}{\cite{aharon2022bot}} on DanceTrack, MOT17, and MOT20. The dimension of the appearance feature is 2048. The weight hyper-parameter of the confidence cost matrix in the first association stage (for high-confidence detections) and the second stage (for low-confidence detections) are set to 1.5 and 1.0 on DanceTrack, 1.0 and 1.0 on other benchmarks. The weight of Robust OCM cost is 0.2, following OC-SORT. The IoU threshold to reject a match is set to 0.15 on DanceTrack, and 0.25 on other benchmarks. Following ByteTrack \textcolor{blue}{\cite{zhang2022bytetrack}}, FPS is measured with FP16-precision \textcolor{blue}{\cite{micikevicius2017mixed}} with batchsize of 1. The hardware is a single V100 GPU with Intel Xeon(R) Silver 4214R CPU @ 2.40GHz.  



\subsection{Benchmark Results}
In this section, we present benchmark results on DanceTrack, MOT20 and MOT17. We employ the same detection results as ByteTrack and OC-SORT for fair and unbiased comparison. Methods with identical detection results are grouped together at the bottom of each Table. 

Two important points must be emphasized. Firstly, Hybrid-SORT significantly outperforms the baseline OC-SORT in all three datasets with negligible additional computation and maintains Simple, Online and Real-Time (SORT) characteristics, even though its performance lags slightly behind by a few works with much heavier models (i.e., MOTRv2), offline pipelines (i.e., SUSHI) or complex pipelines (i.e., MotionTrack and FineTrack) on certain datasets. Secondly, the performance of Hybrid-SORT is highly stable across all datasets, in contrast to MOTRv2 performs well on DanceTrack but poorly on MOT17 and MOT20, SUSHI and FineTrack perform well on MOT17 and MOT20 but poorly on DanceTrack, and MotionTrack performs well on simple MOT17 but poorly on challenging MOT20.





\subsubsection{DanceTrack}
Compared to the previous state-of-the-art heuristic tracker OC-SORT, Hybrid-SORT exhibits significantly superior performance in all metrics (i.e., 7.6 HOTA, 8.4 IDF1, and 2.0 MOTA) and sets a new state-of-the-art HOTA of 62.2 for the heuristic tracker, with identical association inputs and nearly identical computational complexity (refer to Table \ref{table:DanceTrack}). The results provide convincing evidence that the introduction and modeling of multiple types of weak cues, such as confidence state and height state, can effectively and efficiently resolve ambiguous and incorrect matches where strong cues fail. Further, with an independent ReID model, Hybrid-SORT-ReID achieves an even higher state-of-the-art HOTA of 65.7 on DanceTrack for the heuristic tracker. For trackers with learnable matcher which show higher performance, MOTRv2 is also based on YOLOX detector but utilized a modified Deformable DETR \textcolor{blue}{\cite{zhu2020deformable}} with 6 layers of Transformer encoder and 6 layers of Transformer decoder as the matcher, while SUSHI employs GNNs as the matcher with totally offline pipeline. 



\begin{table}[!ht]
\begin{center}
\caption{Results on DanceTrack test set. Methods in the blue blocks share the same detections. The top three results with heuristic matcher were highlighted in the order of \textcolor{red}{red}, \textcolor{blue}{blue}, and \textcolor{green}{green}, respectively.}
\label{table:DanceTrack}
\scalebox{0.66}{
\begin{tabular}{l|ccc}
\hline\noalign{\smallskip}
Tracker & HOTA  & IDF1  & MOTA \\
\noalign{\smallskip}
\hline
\noalign{\smallskip}
\color{gray}{Learnable Matcher:} \\
MOTR \textcolor{blue}{\cite{zeng2022motr}}  & 54.2 & 51.5 & 79.7\\
MOTRv2 \textcolor{blue}{\cite{zhang2023motrv2}}  & 69.9 & 71.7 & 91.9 \\
SUSHI \textcolor{blue}{\cite{cetintas2023unifying}}  & 63.3 & 63.4 & 88.7\\
\hline
\color{gray}{Heuristic Matcher:} \\
CenterTrack \textcolor{blue}{\cite{zhou2020tracking}}  & 41.8 & 35.7 & 86.8\\
TransTrack \textcolor{blue}{\cite{sun2020transtrack}} & 45.5 & 45.2 & 88.4 \\
FairMOT \textcolor{blue}{\cite{zhang2021fairmot}}  & 39.7 & 40.8 & 82.2\\
QDTrack \textcolor{blue}{\cite{pang2021quasi}} & 45.7 & 44.8  & 83.0\\
GTR \textcolor{blue}{\cite{zhou2022global}} & 48.0 & 50.3 & 84.7 \\
FineTrack \textcolor{blue}{\cite{ren2023focus}} & 52.7 & \textcolor{green}{59.8}  & 89.9\\
\rowcolor{blue!10} SORT \textcolor{blue}{\cite{bewley2016simple}}  & 47.9 & 50.8  & \textcolor{red}{91.8}\\
\rowcolor{blue!10} DeepSORT \textcolor{blue}{\cite{wojke2017simple}}  & 45.6 & 47.9  & 87.8\\
\rowcolor{blue!10} ByteTrack \textcolor{blue}{\cite{zhang2022bytetrack}}  & 47.3 & 52.5  & 89.5 \\
\rowcolor{blue!10} StrongSORT++ \textcolor{blue}{\cite{du2023strongsort}}  & 55.6 & 55.2  & 91.1 \\
\rowcolor{blue!10} GHOST \textcolor{blue}{\cite{seidenschwarz2023simple}}  & \textcolor{green}{56.7} & 57.7  & \textcolor{green}{91.3} \\
\rowcolor{blue!10} OC-SORT \textcolor{blue}{\cite{cao2023observation}}  & 54.6 & 54.6  & 89.6\\
\rowcolor{blue!10} \textbf{Hybrid-SORT(Ours)}  & \textcolor{blue}{62.2} & \textcolor{blue}{63.0}  & \textcolor{blue}{91.6}\\
\rowcolor{blue!10} \textbf{Hybrid-SORT-ReID(Ours)}  & \textcolor{red}{65.7} & \textcolor{red}{67.4}  & \textcolor{red}{91.8}\\
\hline
\end{tabular}
}
\end{center}
\end{table}

\subsubsection{MOT20}
Remarkably, Hybrid-SORT achieves superior performance in the MOT20 test set (as shown in Table \ref{table:MOT20}) with high inference speed. Specifically, Hybrid-SORT surpasses OC-SORT in all metrics (i.e., 0.4 HOTA, 0.3 IDF1, and 0.9 MOTA), with practically indistinguishable additional computation. By utilizing an independent ReID model, Hybrid-SORT achieves a state-of-the-art performance of HOTA 63.9 on MOT20 for the heuristic tracker. The results demonstrate the effectiveness, robustness, and generalization of the proposed method in modeling weak cues for clustered and heavily occluded scenarios with dense objects. 

\begin{table*}
\begin{center}
\caption{Results on MOT20-test with the private detections. Methods in the blue blocks share the same detections. The top three results with heuristic matcher were highlighted in the order of \textcolor{red}{red}, \textcolor{blue}{blue}, and \textcolor{green}{green}, respectively.}
\label{table:MOT20}
\scalebox{0.65}{
\begin{tabular}{l|cccccccc}
\hline\noalign{\smallskip}
Tracker & HOTA  & IDF1  & MOTA  & FP & FN &IDs  & AssA  & AssR \\
\noalign{\smallskip}
\hline
\noalign{\smallskip}
\color{gray}{Learnable Matcher:} \\
TrackFormer \textcolor{blue}{\cite{meinhardt2022trackformer}}  & 54.7 & 65.7 & 68.6 & / & / & 1,532 & / & / \\
TransMOT \textcolor{blue}{\cite{chu2023transmot}}  & 61.9 & 75.2 & 77.5 & 3.42 & 8.08 & 1,615 & 60.1 & 66.3 \\
MOTRv2 \textcolor{blue}{\cite{zhang2023motrv2}}  & 61.0 & 73.1 & 76.2 & / & / & / & 59.3 & / \\
UTM \textcolor{blue}{\cite{you2023utm}}  & 62.5 & 76.9 & 78.2 & 3.00 & 8.15 & 1,228 & / & / \\
SUSHI \textcolor{blue}{\cite{cetintas2023unifying}}  & 64.3 & 79.8 & 74.3 & / & / & 706 & / & / \\
\hline
\color{gray}{Heuristic Matcher:} \\
FairMOT \textcolor{blue}{\cite{zhang2021fairmot}}  & 54.6 & 67.3 & 61.8 & 10.3 & 8.89 & 5,243 & 54.7 & 60.7 \\
CSTrack \textcolor{blue}{\cite{liang2022rethinking}}  & 54.0 & 68.6 & 66.6 & 2.54 & 14.4 & 3,196 & 54.0 & 57.6 \\
FineTrack \textcolor{blue}{\cite{ren2023focus}} & \textcolor{blue}{63.6} & \textcolor{red}{79.0} & \textcolor{blue}{77.9} & \textcolor{green}{2.44} & 8.90 & \textcolor{green}{980} & / & / \\
MotionTrack \textcolor{blue}{\cite{qin2023motiontrack}} & 62.8 & 76.5 & \textcolor{red}{78.0} & 2.86 & \textcolor{red}{8.42} & 1,165 & / & / \\
\rowcolor{blue!10} ByteTrack \textcolor{blue}{\cite{zhang2022bytetrack}}  & 61.3 & 75.2 & \textcolor{green}{77.8} & 2.62 & 8.76 & 1,223 & 59.6 & 66.2 \\
\rowcolor{blue!10} BoT-SORT-ReID \textcolor{blue}{\cite{aharon2022bot}}  & \textcolor{green}{63.3} &   \textcolor{green}{77.5} & \textcolor{green}{77.8} & 2.46 & 8.89 & 1257 & / & / \\
\rowcolor{blue!10} StrongSORT \textcolor{blue}{\cite{du2023strongsort}}  & 61.5 & 75.9 & 72.2 & / & / & 1,066 & \textcolor{green}{63.2} & / \\
\rowcolor{blue!10} StrongSORT++ \textcolor{blue}{\cite{du2023strongsort}}  & 62.6 &77.0 & 73.8 & \textcolor{red}{1.66} & 11.8 & \textcolor{red}{770} & \textcolor{blue}{64.0} & \textcolor{blue}{69.6} \\
\rowcolor{blue!10} GHOST \textcolor{blue}{\cite{seidenschwarz2023simple}}  & 61.2 & 75.2 & 73.7 & / & / & 1,264 & / & / \\
\rowcolor{blue!10} OC-SORT \textcolor{blue}{\cite{cao2023observation}}  & 62.1 & 75.9 & 75.5 & \textcolor{blue}{1.80} & 10.8 & \textcolor{blue}{913} & 62.0 & 67.5 \\
\rowcolor{blue!10} \textbf{Hybrid-SORT(Ours)}  & 62.5 & 76.2 & 76.4 & 3.59 & \textcolor{blue}{8.50} & 1,300 & 62.0 & \textcolor{green}{68.4} \\
\rowcolor{blue!10} \textbf{Hybrid-SORT-ReID(Ours)}  & \textcolor{red}{63.9} & \textcolor{blue}{78.4} & 76.7 & 3.39 & \textcolor{green}{8.54} & 1,136 & \textcolor{red}{64.5} & \textcolor{red}{69.9} \\
\hline
\end{tabular}
}
\end{center}
\end{table*}



\subsubsection{MOT17}
We present the performance of Hybrid-SORT on MOT17 in Table \ref{table:MOT17}. Specifically, Hybrid-SORT surpasses the previous state-of-the-art tracker OC-SORT in all metrics (i.e., 0.4 HOTA, 0.9 IDF1, and 1.3 MOTA) with negligible additional computation. By incorporating an independent ReID model, Hybrid-SORT further accomplishes performance improvements, setting a superior HOTA of 64.0 on MOT17. These results indicate the generalization of our modeling of weak cues, even in easy scenarios with predominantly linear motion patterns which are relatively well resolved by existing methods. It is important to note that our method is primarily designed to address the challenges of object clustering and complex motion patterns. Nevertheless, even when applied to the MOT17 dataset, which represents a more general scenario of linear motion patterns, our method consistently exhibits enhanced tracking performance. 

\begin{table*}[!ht]
\begin{center}
\caption{Results on MOT17-test with the private detections. Methods in the blue blocks share the same detections. The top three results with heuristic matcher were highlighted in the order of \textcolor{red}{red}, \textcolor{blue}{blue}, and \textcolor{green}{green}, respectively.}
\label{table:MOT17}
\scalebox{0.65}{
\begin{tabular}{l|cccccccc}
\hline\noalign{\smallskip}
Tracker & HOTA  & IDF1  & MOTA  & FP & FN &IDs  & AssA  & AssR \\
\noalign{\smallskip}
\hline
\noalign{\smallskip}
\color{gray}{Learnable Matcher:} \\
TrackFormer \textcolor{blue}{\cite{meinhardt2022trackformer}}  & 57.3 & 68.0 & 74.1 & / & / & 2,829 & / & / \\
MOTR \textcolor{blue}{\cite{zeng2022motr}}  & 57.8 & 68.6 & 73.4 & / & / & 2,439 & 55.7 & / \\
TransMOT \textcolor{blue}{\cite{chu2023transmot}}  & 61.7 & 75.1 & 76.7 & 3.62 & 9.32 & 2,346 & 59.9 & 66.5 \\
MOTRv2 \textcolor{blue}{\cite{zhang2023motrv2}}  & 62.0 & 75.0 & 78.6 & / & / & / & 60.6 & / \\
UTM \textcolor{blue}{\cite{you2023utm}} & 64.0 & 78.7 & 81.8 & 2.51 & 7.63 & 1,431 & / & / \\
SUSHI \textcolor{blue}{\cite{cetintas2023unifying}}  & 66.5 & 83.1 & 81.1 & / & / & 1,149 & / & / \\
\hline
\color{gray}{Heuristic Matcher:} \\
CenterTrack \textcolor{blue}{\cite{zhou2020tracking}}  & 52.2  & 64.7 & 67.8 & \textcolor{blue}{1.85} & 16.0 & 3,039 & 51.0 & / \\
TransTrack \textcolor{blue}{\cite{sun2020transtrack}}  & 54.1 & 63.5 & 75.2 & 5.02 & 8.64 & 3,603 & 47.9 & 57.1 \\
QDTrack \textcolor{blue}{\cite{pang2021quasi}}  & 53.9  & 66.3 & 68.7 & 2.66 & 14.7 & 3,378 & 52.7 & 57.2 \\
FairMOT \textcolor{blue}{\cite{zhang2021fairmot}}  & 59.3 & 72.3 & 73.7 & 2.75 & 11.7 & 3,303 & 58.0 & 63.6 \\
CSTrack \textcolor{blue}{\cite{liang2022rethinking}}  & 59.3 & 72.6 & 74.9 & 2.38 & 11.4 & 3,567 & / & / \\
GTR \textcolor{blue}{\cite{zhou2022global}}  & 59.1 & 71.5 & 75.3 & 2.68 & 11.0 & 2,859 & 61.6 & / \\
FineTrack \textcolor{blue}{\cite{ren2023focus}} & 64.3 & \textcolor{green}{79.5} & 80.0 & \textcolor{green}{2.18} & 9.01 & 1,272 & / & / \\
MotionTrack \textcolor{blue}{\cite{qin2023motiontrack}} & \textcolor{red}{65.1}  & \textcolor{blue}{80.1} & \textcolor{red}{81.1} & 2.38 & \textcolor{blue}{8.17} & \textcolor{red}{1,140} & / & / \\
\rowcolor{blue!10} ByteTrack \textcolor{blue}{\cite{zhang2022bytetrack}}  & 63.1 & 77.3 & \textcolor{green}{80.3} & 2.55 & 8.37 & 2,196 & 62.0 & 68.2 \\
\rowcolor{blue!10} BoT-SORT-ReID \textcolor{blue}{\cite{aharon2022bot}}  & \textcolor{blue}{65.0} & \textcolor{red}{80.2} & \textcolor{blue}{80.5} & 2.25 & 8.60 & 1212 & / & / \\
\rowcolor{blue!10} StrongSORT \textcolor{blue}{\cite{du2023strongsort}}  & 63.5 & 78.5 & 78.3 &  / &  / & 1,446 & \textcolor{blue}{63.7} &  / \\
\rowcolor{blue!10} StrongSORT++ \textcolor{blue}{\cite{du2023strongsort}}  & \textcolor{green}{64.4} & \textcolor{green}{79.5} & 79.6  & 2.79 & 8.62 & \textcolor{green}{1,194} & \textcolor{red}{64.4} & \textcolor{red}{71.0} \\
\rowcolor{blue!10} GHOST \textcolor{blue}{\cite{seidenschwarz2023simple}}  & 62.8 & 77.1 & 78.7 & / & / & 2,325 & / & / \\
\rowcolor{blue!10} OC-SORT \textcolor{blue}{\cite{cao2023observation}}  & 63.2 & 77.5 & 78.0 & \textcolor{red}{1.51} & 10.8 & 1,950 & 63.2 & 67.5 \\
\rowcolor{blue!10} \textbf{Hybrid-SORT(Ours)}  & 63.6 & 78.4 & 79.3 & 3.54 & \textcolor{red}{7.91} & 2109 & 63.2 & \textcolor{green}{69.1} \\
\rowcolor{blue!10} \textbf{Hybrid-SORT-ReID(Ours)}  & 64.0 & 78.7 & 79.9 & 3.02 & \textcolor{green}{8.22} & \textcolor{blue}{1,191} & \textcolor{green}{63.5} & \textcolor{blue}{69.9}\\
\hline

\end{tabular}

}
\end{center}
\end{table*}



\subsection{Ablation Study}
\subsubsection{Component Contribution}
We conduct an ablation study to assess the contribution of the proposed components on the validation sets of DanceTrack and MOT17, as shown in Table \ref{table:component_ablation}. The results demonstrate the effectiveness of the proposed modules in Hybrid-SORT. The confidence state modeled by TCM significantly enhances the performance on both datasets, with improvements of 4.0 HOTA, 5.3 IDF1, and 0.5 MOTA in DanceTrack, and 0.4 HOTA, 0.8 IDF1, and 0.7 MOTA in MOT17. Similarly, the utilization of height state by HMIoU leads to improvements in HOTA by 1.6 in DanceTrack, and 0.3 in MOT17, respectively. We argue that the motion patterns are linear in most of the videos in MOT17. In contrast, DanceTrack involves more complicated motions and much heavier clustering, in which the superiority of Hybrid-SORT is clearly demonstrated. These results suggest that weak cues, such as confidence state and height state, can effectively compensate for commonly used strong cues under diverse scenarios, even if they can only distinguish certain objects (i.e., local discrimination).





\begin{table*}
\begin{center}
\caption{Components ablation on MOT17-val and DanceTrack-val.}
\label{table:component_ablation}
\scalebox{0.94}{
\begin{tabular}{ccccc|cccc|ccc}
\hline\noalign{\smallskip}
\multicolumn{5}{c|}{ } & \multicolumn{4}{c|}{DanceTrack-val} & \multicolumn{3}{c}{MOT17-val} \\
\noalign{\smallskip}
\hline\noalign{\smallskip}
BYTE & Robust OCM & TCM & HMIoU & ReID & HOTA  & IDF1  & MOTA  & FPS  & HOTA  & IDF1  & MOTA  \\
\noalign{\smallskip}
\hline
\noalign{\smallskip}
   &   &   &  &  & 52.3 & 51.9 & 87.3 & \textbf{30.3} & 66.1 & 77.7 & 74.5 \\
\ding{51}&   &   &  &  & 53.1 & 52.5 & 88.7 & 30.1 & 66.1 & 76.8 & 74.9 \\
\ding{51}&\ding{51}&   &  &  & 53.7 & 53.2 & 88.9 & 28.6 & 66.4 & 77.2 & 75.0 \\
\ding{51}&\ding{51}&\ding{51}&  &  & 57.7 & 58.5 & 89.4 & 27.9 & 66.8 & 78.0 & 75.7 \\
\ding{51}&\ding{51}&\ding{51}&\ding{51}& & 59.3 & 60.6 & 89.5 & 27.8 & 67.1 & 78.0 & 75.8  \\
\ding{51}&\ding{51}&\ding{51}&\ding{51}&\ding{51}& \textbf{63.0} & \textbf{64.8} & \textbf{89.8} & 15.5 & \textbf{68.2} & \textbf{80.6} & \textbf{76.9}  \\
\hline
\end{tabular}
}
\end{center}
\end{table*}

\subsubsection{Component Efficiency}
As shown in Table \ref{table:component_ablation}, Hybrid-SORT still maintains real-time capacity with all proposed components. To establish a strong baseline, we incorporate low-confidence detections (BYTE in ByteTrack) and improve OCM in OC-SORT with Robust OCM. The introduction of BYTE has a negligible effect on inference speed (-0.2 FPS), while Robust OCM leads to a reduction of 1.5 FPS. The observed phenomenon can be attributed to the transition of the velocity direction from 1 single point (i.e., the center) over a fixed temporal interval of 3 frames, to 4 points (i.e., corners) with varying temporal intervals ranging from 1-3 frames. As for the two primary contributions of this paper, TCM only has a minor impact on inference speed (-0.7 FPS), and HMIoU barely affects inference speed (-0.1 FPS). All the results presented above demonstrate the high efficiency of Hybrid-SORT. 

With a commonly used ReID model in BoT-SORT for a fair comparison, the inference speed of Hybrid-SORT-ReID becomes near real-time. The primary reasons are the separated feature extraction and the high feature dimension of the ReID model. However, the efficient incorporation of the ReID model into the MOT framework is beyond the scope of this paper. 


\subsubsection{Modeling Strategies in TCM}
As previously mentioned, Kalman Filter is used to estimate the tracklet confidence for high-confidence detections in the first association stage, while Linear Prediction is employed for low-confidence detections in the second association stage. In Table \ref{table:confidence_modeling}, we investigate the performance of these two confidence state modeling methods in the two association stages on the DanceTrack validation set. In the first association stage with high-confidence detections, Kalman Filter significantly boosts the association performance by 2.9 HOTA, while Linear Prediction decreases HOTA by 1.1. We attribute the results to the fact that high-confidence detections usually do not suffer from heavy occlusion. Therefore the tracklet confidence varies within a small range, which can be effectively modeled by Kalman Filter. On the other hand, Linear Prediction fails because the confidence changes do not exhibit a clear directional trend. In the second association stage with low-confidence detections, both Kalman Filter and Linear Prediction perform well (0.7 and 1.1 HOTA, respectively), with the latter performing slightly better. As discussed in ByteTrack, the second stage of association occurs when objects cluster heavily. Therefore, the confidence can decrease or increase rapidly depending on whether the clustering starts or ends. Kalman Filter is incapable of modeling such sudden changes, and thus its estimations usually lag behind the actual confidence. However, Linear Prediction can model the directional changes well. In summary, Kalman Filter achieves satisfactory estimation for objects with no or slight occlusions, while Linear Prediction is more suitable for heavily occluded objects.


\begin{table}
\begin{center}
\caption{Results of different confidence modeling in DanceTrack-val.}
\label{table:confidence_modeling}
\scalebox{0.92}{
\begin{tabular}{cc|ccc}
\hline\noalign{\smallskip}
First association & BYTE & HOTA  & IDF1  & MOTA \\
\noalign{\smallskip}
\hline
\noalign{\smallskip}
   &   & 53.7 & 53.2 & 88.9 \\
Kalman  &   & 56.6 & 56.6 & 89.2 \\
Kalman  &Kalman  & 57.3 & 57.9 & 89.2 \\
Linear  &   & 52.6 & 52.1  & 89.0 \\
Linear  &Linear  & 53.9 & 53.1 & 89.2\\
Kalman  &Linear  & \textbf{57.7} & \textbf{58.5} & \textbf{89.4} \\
\hline
\end{tabular}
}
\end{center}
\end{table}

\subsubsection{Height State over Width State}
As stated above, height state, rather than width state, can benefit association. Similar to the Height Modulated IoU (HMIoU) shown in Figure \ref{fig:HMIoU} and Eq. \ref{eq:HMIoU}, Width Modulated IoU (WMIoU) can also be obtained by fusing the standard IoU based on area metric with the Width IoU (WIoU) based on width metric. As shown in Table \ref{table:different_iou}, the width state significantly hurt association performance, whereas the height state is beneficial. In summary, regularly changing states can be modeled well thus benefiting association, while irregular states are difficult to estimate precisely thus harming association.



\begin{table}
\begin{center}
\caption{Results of different IoU in DanceTrack-val.}
\label{table:different_iou}
\scalebox{1.1}{
\begin{tabular}{c|ccc}
\hline\noalign{\smallskip}
 & HOTA  & IDF1  & MOTA  \\
\noalign{\smallskip}
\hline
\noalign{\smallskip}
IoU  & 57.7 & 58.5 & 89.4 \\
WMIoU   & 52.6 & 52.0 & 89.0  \\
HMIoU  & \textbf{59.3}  & \textbf{60.6} & \textbf{89.5} \\
\hline
\end{tabular}
}
\end{center}
\end{table}



\subsubsection{Form of Robust OCM}
Table \ref{table:rocm} demonstrates that regardless of whether BYTE association is used or not, both stacking velocity directions obtained from the 1-3 frame interval and utilizing the four corners instead of the center point yield improvements in the HOTA on DanceTrack val set. These findings suggest that incorporating more detailed and robust modeling leads to enhanced association performance.

\begin{table}
\begin{center}
\caption{Ablation on the form of OCM in DanceTrack-val.}
\label{table:rocm}
\scalebox{0.8}{
\begin{tabular}{ccc|ccc}
\hline\noalign{\smallskip}
 BYTE & stack vectors & 4 corners & HOTA  & IDF1  & MOTA \\
\noalign{\smallskip}
\hline
\noalign{\smallskip}
  &   &   & 52.3  & 51.9 & 87.3\\
   & \ding{51}  &   & 52.7 & 52.2 & 87.2\\
   & \ding{51}   & \ding{51}   & 53.1 & 52.7  & 87.4\\
\ding{51}  &   &   & 53.1 & 52.5 & 88.7 \\
 \ding{51}  & \ding{51}  &  \ding{51}  & \textbf{53.7}  & \textbf{53.2} & \textbf{88.9}\\
\hline
\end{tabular}
}
\end{center}
\end{table}

\subsubsection{Generality on Other Trackers}
We applied our design to other 4 representative heuristic trackers, namely SORT \textcolor{blue}{\cite{bewley2016simple}}, DeepSORT \textcolor{blue}{\cite{wojke2017simple}}, MOTDT \textcolor{blue}{\cite{chen2018real}}, and ByteTrack \textcolor{blue}{\cite{zhang2022bytetrack}}. Among these trackers, SORT, and ByteTrack rely solely on spatial information, while MOTDT and DeepSORT jointly utilize both spatial and appearance information. The results are presented in Table \ref{table:tcm_generalization} and Table \ref{table:vhiou_generalization}, where a significant improvement can be observed in both DanceTrack and MOT17 datasets for all aforementioned trackers. For instance, our design TCM improves DeepSORT by 4.9 HOTA in DanceTrack and 0.9 HOTA in MOT17, while our HMIoU boosts SORT by 1.6 HOTA in DanceTrack and 1.0 HOTA in MOT17. These results provide convincing evidence that our insight of introducing weak cues like confidence state and height state as compensation for strong cues is effective and generalizes well across different trackers and scenarios. Moreover, our approach can be readily applied to existing trackers in a plug-and-play and training-free manner for enhanced performance.

\begin{table}
\begin{center}
\caption{TCM in other trackers.}
\label{table:tcm_generalization}
\scalebox{0.75}{
\begin{tabular}{cc|cc}
\hline\noalign{\smallskip}
Tracker & TCM & DanceTrack & MOT17 \\
\noalign{\smallskip}
\hline
\noalign{\smallskip}
ByteTrack  &   & 47.06 & 67.85 \\
\textcolor{blue}{\cite{zhang2022bytetrack}}&\ding{51}  & 49.32(\textcolor{red}{+2.3}) & 68.03(\textcolor{red}{+0.2}) \\
\hline
SORT  &   & 48.34 & 66.32 \\
\textcolor{blue}{\cite{bewley2016simple}} & \ding{51}  & 51.80(\textcolor{red}{+3.5}) & 66.52(\textcolor{red}{+0.2})\\
\hline
MOTDT  &   & 36.47 & 65.32\\
\textcolor{blue}{\cite{chen2018real}} & \ding{51}  & 37.66(\textcolor{red}{+1.2}) & 65.62(\textcolor{red}{+0.3})\\
\hline
DeepSORT  &   & 40.38 & 63.45\\
\textcolor{blue}{\cite{wojke2017simple}}& \ding{51}  & 45.29(\textcolor{red}{+4.9}) & 64.36(\textcolor{red}{+0.9})\\
\hline
\end{tabular}
}
\end{center}
\end{table}



\begin{table}[!ht]
\begin{center}
\caption{HMIoU in other trackers.}
\label{table:vhiou_generalization}
\scalebox{0.75}{
\begin{tabular}{cc|cc}
\hline\noalign{\smallskip}
Tracker & HMIoU & DanceTrack & MOT17 \\
\noalign{\smallskip}
\hline
\noalign{\smallskip}
ByteTrack &   & 47.06 & 67.85 \\
\textcolor{blue}{\cite{zhang2022bytetrack}} &\ding{51}  & 49.68(\textcolor{red}{+2.6}) & 67.70(\textcolor[RGB]{50, 205, 50}{-0.2}) \\
\hline
SORT  &   & 48.34 & 66.32 \\
\textcolor{blue}{\cite{bewley2016simple}} & \ding{51}  & 49.96(\textcolor{red}{+1.6}) & 67.30(\textcolor{red}{+1.0})\\
\hline
MOTDT  &   & 36.47 & 65.32\\
\textcolor{blue}{\cite{chen2018real}} & \ding{51}  & 36.83(\textcolor{red}{+0.4}) & 65.21(\textcolor[RGB]{50, 205, 50}{-0.1})\\
\hline
DeepSORT &   & 40.38 & 63.45\\
\textcolor{blue}{\cite{wojke2017simple}} & \ding{51}  & 41.23(\textcolor{red}{+0.9}) & 63.64(\textcolor{red}{+0.2})\\
\hline
\end{tabular}
}
\end{center}
\end{table}

\section{Conclusion}
In this paper, we analyze common and long-standing failure cases caused by heavy occlusion and clustering, when strong cues such as spatial and appearance information become unreliable simultaneously. We demonstrate an important finding that previously overlooked weak cues, such as confidence state, height state, and velocity direction, can compensate for the limitations of strong cues. Then, we propose Hybrid-SORT by introducing simple modeling for the newly incorporated weak cues and leveraging both strong and weak cues. The design effectively and efficiently resolves ambiguous matches generated by strong cues, and significantly improves association performance. Furthermore, Hybrid-SORT still maintains Simplicity, Online, and Real-Time (SORT) capacity, and can be readily applied to
existing trackers in a plug-and-play and training-free way. Our extensive experiments demonstrate the strong generalization ability of Hybrid-SORT across diverse trackers and scenarios. When including widely used appearance information, Hybrid-SORT achieves superior performance over state-of-the-art methods, with a much simpler pipeline and faster association speed. We hope the generalization ability, plug-and-play and training-free characteristics of Hybrid-SORT make it attractive for diverse real-world scenarios and devices with limited computational resources.


\bibliography{aaai23}

\end{document}
