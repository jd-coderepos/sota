\def\year{2022}\relax
\documentclass[letterpaper]{article} \usepackage{aaai22}  \usepackage{times}  \usepackage{helvet}  \usepackage{courier}  \usepackage[hyphens]{url}  \usepackage{graphicx} \usepackage{bm}
\usepackage{booktabs}
\usepackage{amsmath}
\usepackage{bbm}
\usepackage{url}
\usepackage{newfloat}
\usepackage{algorithm}
\usepackage{algorithmic}
\usepackage{amssymb}
\usepackage{listings}
\usepackage{bm}
\urlstyle{rm} \def\UrlFont{\rm}  \usepackage{natbib}  \usepackage{caption} \DeclareCaptionStyle{ruled}{labelfont=normalfont,labelsep=colon,strut=off} \frenchspacing  \setlength{\pdfpagewidth}{8.5in}  \setlength{\pdfpageheight}{11in}  \usepackage{algorithm}
\usepackage{algorithmic}

\usepackage{newfloat}
\usepackage{listings}
\lstset{basicstyle={\footnotesize\ttfamily},numbers=left,numberstyle=\footnotesize,xleftmargin=2em,aboveskip=0pt,belowskip=0pt,showstringspaces=false,tabsize=2,breaklines=true}
\floatstyle{ruled}
\newfloat{listing}{tb}{lst}{}
\floatname{listing}{Listing}
\pdfinfo{
	/Title (AAAI Press Formatting Instructions for Authors Using LaTeX -- A Guide)
	/Author (AAAI Press Staff, Pater Patel Schneider, Sunil Issar, J. Scott Penberthy, George Ferguson, Hans Guesgen, Francisco Cruz, Marc Pujol-Gonzalez)
	/TemplateVersion (2022.1)
}




\setcounter{secnumdepth}{0} 





\title{Imagine by Reasoning: A Reasoning-Based Implicit Semantic Data Augmentation for Long-Tailed Classification}
\author{
Xiaohua Chen\textsuperscript{\rm 1,2}, 
	Yucan Zhou\textsuperscript{\rm 1}\thanks{Yucan Zhou is the corresponding author}, 
	Dayan Wu\textsuperscript{\rm 1}, \\
	Wanqian Zhang\textsuperscript{\rm 1}, 
	Yu Zhou\textsuperscript{\rm 1}, 
	Bo Li\textsuperscript{\rm 1,2}, 
	Weiping Wang\textsuperscript{\rm 1,2}
}
\affiliations{
	\textsuperscript{\rm 1} Institute of Information Engineering, Chinese Academy of Sciences, Beijing, China\\
	\textsuperscript{\rm 2} School of Cyber Security, University of Chinese Academy of Sciences, Beijing, China\\
	\{chenxiaohua, zhouyucan, wudayan, zhangwanqian, zhouyu, libo, wangweiping\}@iie.ac.cn




}





\usepackage{bibentry}


\begin{document}
	\maketitle
	\begin{abstract}
		Real-world data often follows a long-tailed distribution, which makes the performance of existing classification algorithms degrade heavily. A key issue is that samples in tail categories fail to depict their intra-class diversity. Humans can imagine a sample in new poses, scenes, and view angles with their prior knowledge even if it is the first time to see this category. Inspired by this, we propose a novel reasoning-based implicit semantic data augmentation method to borrow transformation directions from other classes. Since the covariance matrix of each category represents the feature transformation directions, we can sample new directions from similar categories to generate definitely different instances. Specifically, the long-tailed distributed data is first adopted to train a backbone and a classifier. Then, a covariance matrix for each category is estimated, and a knowledge graph is constructed to store the relations of any two categories. Finally, tail samples are adaptively enhanced via propagating information from all the similar categories in the knowledge graph. Experimental results on CIFAR-100-LT, ImageNet-LT, and iNaturalist 2018 have demonstrated the effectiveness of our proposed method\footnote{Code is available at \url{https://github.com/xiaohua-chen/RISDA}} compared with the state-of-the-art methods. 
	\end{abstract}
	
	\section{Introduction}
	Deep neural networks have achieved dramatic performance when high-quality annotated and balanced distributed training data is provided \cite{KrizhevskySH12, he2016deep, HuangLMW17}. However, in real-world scenarios, data is usually long-tail distributed, where many tail categories occupy only a small number of samples and most samples belong to a few head categories. It is a great challenge to train deep models on long-tail distributed data. On the one hand, the separating hyperplane will be heavily skewed to the tail classes because of their weak statistical ability. More importantly, tail classes are easily overfitted as their samples fail to describe their intra-class diversity.
	
	




	To strengthen the effect of tail classes in training, a typical and intuitive strategy is re-balancing, including data re-sampling and loss re-weighting. Data re-sampling
	achieves training fairness by balancing the data distribution through sampling, while loss re-weighting pays more attention to tail categories by assigning higher penalties to the loss of tail classes. Although these methods can alleviate hyperplane skewness, over-fitting on tail categories is still a big issue because of the limited intra-class diversity. 
	
	\begin{figure}
		\setlength{\abovecaptionskip}{0pt}
\includegraphics[width=\linewidth,scale=1.00]{./motivation_cxh.pdf}
		\caption{An illustration of imagining new samples by reasoning.
			People can imagine a kingfisher in various view angles, poses, and backgrounds with their prior knowledge.  }
		\label{fig:EP}
	\end{figure}
	
	Data augmentation is an efficient way to enrich tail categories, where cropping, rotation, mixup, and generative adversarial network are adopted to generate new samples \cite{simonyan2014very,he2016deep,ratner2017learning,bowles2018gan}. Nevertheless, with the increasing number of augmented examples, the training speed is sharply slowed down. 
	Fortunately, ISDA \cite{wang2019implicit} propose an instance-based implicit data augmentation method to reduce the computation cost, where new instances can be generated by changing the original instance to semantic transformation directions sampled from the feature covariance matrix. However, for tail classes, it is incapable to estimate a diversified covariance matrix
	\cite{li2021metasaug}. 
	
	We argue that humans can imagine a rare animal in different poses, colors, and backgrounds with prior knowledge, though we have only seen one picture of this animal. For instance (shown in Figure \ref{fig:EP}), as ``Kingfisher" is similar to ``Sparrow" in humans' prior knowledge, we can easily imagine a ``Kingfisher" with an open mouth when we have seen a ``Sparrow" with an open mouth. Inspired by this, tail classes can borrow semantic transformations from other classes.
	
	
	In this paper, in order to mimic the human reasoning process, we propose an effective Reasoning-Based Implicit Semantic Data Augmentation (\textbf{RISDA}) method for long-tailed classification. It enriches a tail instance by transferring semantic transformation directions from similar categories to expand the intra-class diversity. Specifically, we first train a network with the long-tail distributed data. Then, a covariance matrix for each category is estimated, which represents all the possible transformation directions of a category. After that, for each tail category whose covariance matrix is limited, we enhance it with similar categories. To recognize similar categories, a knowledge graph is constructed, where each non-diagonal element indicates the similarity of two categories. Finally, sufficient instances can be generated by augmenting a tail instance via propagating transformation directions from similar categories. Nevertheless, to ensure the tail instance contains all the features to transfer, we also complement it with features from similar categories. Therefore, our method can generate instances that are definitely different from the training data. 
The contributions of this paper are summarized as follows.
	\begin{itemize}
		\item We propose a reasoning-based implicit data augmentation method, which transfers semantic transformation directions from other classes to enhance tail classes. It can largely enrich the intra-class diversity for tail categories. To the best of our knowledge, this is the first time to transfer feature transformations from similar categories for augmentation. 
		\item We construct a learnable knowledge graph so that our method can adaptively select similar categories for different samples to make the reasonable transformation.
		\item The proposed RISDA outperforms current state-of-the-art methods on long-tailed datasets, such as CIFAR-100-LT, ImageNet-LT, and iNaturalist 2018.
	\end{itemize}


	
	\section{Related Work}
	\subsection{Re-Balance}
A common re-balance strategy is re-sampling, which aims to achieve a balanced data distribution, including over-sampling \cite{buda2018systematic,byrd2019effect} and under-sampling \cite{he2009learning,buda2018systematic}. However, over-sampling may cause over-fitting by duplicating tail data, while under-sampling will damage feature representation when abandoning head data. 
	Recently, some decoupling methods are developed, which adopt different sampling strategies in representation learning and classifier training\cite{kang2019decoupling,zhou2020bbn,wang2021contrastive}.


Another strategy is re-weighting the loss to give more attention to tail classes. An intuitive way is to re-weight the loss of each class inversely proportional to the number of samples \cite{huang2016learning}. Then, class-balance loss \cite{cui2019class} is proposed to emphasize the effective number of samples. Thereafter, meta-class-weight \cite{jamal2020rethinking} estimates class weights by meta-learning, while LDAM \cite{cao2019learning} uses class-level re-weighting optimization schedule to train a label-distribution-aware loss.
In addition, some fine-grained instance-level re-weighting methods are studied. Such as Focal Loss \cite{lin2017focal} reduces the weights of easy samples to make the model focus on hard samples in training. L2RW \cite{ren2018learning} and meta-weight-net \cite{shu2019meta} assign instance-wise weights on the gradient direction. 
	
	Although re-balance methods have achieved great improvements, the intra-class diversity for tail categories is still limited, making them easily over-fitted.
	
	\subsection{Data Augmentation}
	To enhance the intra-class diversity for tail categories, data augmentation methods are explored. A direct way is to generate samples by combining other samples in a tail class linearly \cite{he2008adaptive,zhang2017mixup}. However, the combination may be meaningless. To address this issue, GAN \cite{bowles2018gan} is introduced. The above methods are explicit data augmentation methods. With the increasing number of samples, the convergence speed is sharply slowed down. ISDA \cite{wang2019implicit} is a great way to handle this problem, which uses the class-wise covariance matrix and instance-wise feature to formulate a Gaussian distribution, thus infinite samples can be generated. But ISDA fails for tail classes where the insufficient samples are incapable of estimating a diversified covariance matrix. MetaAug \cite{li2021metasaug} tries to find an optimal covariance matrix that generalizes well on unseen samples. However, it still suffers from limited diversity for tail classes as the covariance matrix is calculated with samples at hand.
	
	Fortunately, tail classes can borrow information from other categories \cite{chu2020feature,liu2020deep,xiao2021does}. As head categories are sufficiently diversified, some methods propose to transfer knowledge from head to tail. For example, Liu et al. model each category into a ``feature cloud” and expand tail categories by transferring the intra-class angular distribution from head categories \cite{liu2020deep}. Chu et al. generate new high-level features for tail categories by merging class-specific features of the head categories and class-generic features of the tail categories \cite{chu2020feature}. However, the ``head to tail" is defined by the number of samples, transferring variations based on this relation may be meaningless. For example, if ``Apple"  is a head class, and ``Kingfisher'' is a tail class, then transferring color variations from ``Apple" to ``Kingfisher'' is unreasonable.
	
	Our method follows the idea of implicit data augmentation and tries to borrow variations from other categories to enrich tail categories. However, different from other methods, we transfer variations from all the related classes in a knowledge graph other than the head categories. 
	


	\section{The Proposed Method}
	\begin{figure*}[!tp]
\centering
		\includegraphics[width=\linewidth,scale=1.00]{./cxh_framework.pdf}
\caption{The framework of RISDA. In Stage-I, all training data is used to train a feature subnet and a classifier. Subsequently, we calculate the covariance matrix and the prototype for each category with the feature extracted with the subnet. Then, the classifier is used to construct a knowledge graph. In Stage-II, we augment each tail instance with a semantic transformation direction sampled from the covariance matrix. For tail classes, the covariance matrix is limited, so we refine it with similar classes defined in the knowledge graph. What's more, to ensure the tail instance contains all the features to transfer, we complement it with the prototypes from similar categories. Finally, unlimited instances can be sampled to calculate the  
		}
		\label{Architecture}
	\end{figure*}
	A classifier usually performs worse for tail classes. To enhance their diversity, we propose to borrow variations from other categories as shown in Figure \ref{Architecture}.
	
	In stage-I, we use all the samples to train a feature subnetwork and a classifier. Subsequently, we use the extracted features to calculate the covariance matrix and the prototype for each category, where the covariance matrix represents all the feature semantic transformation directions of each category, and the prototype contains its specific features. Then, the classifier is adopted to construct a knowledge graph, which stores the similarity of any two categories. In stage-II, a tail sample is first propagated to the feature subnetwork to get semantic features. Then, we aim to augment it with the semantic transformations sampled from the covariance matrix of its category. However, the covariance matrix of tail categories is limited, so we refine it with similar classes defined in the knowledge graph. What's more, the tail instance may miss some features to transfer. Thus, to ensure it contains all the features, we complement it with the features from similar categories. Consequently, unlimited instances can be generated by changing an instance with infinite semantic transformation directions from the refined distribution. Finally, an upper bound of the CE loss on unlimited data is derived to fine-tune the network.
	
	In the following, we will describe how a tail sample is implicitly augmented by reasoning, and the loss function to fine-tune the network with unlimited generated data.
	
	\subsection{Implicit Data Augmentation}
	Given a long-tail distributed dataset  , where ,  is the number of categories. Inspired by the observation that instance-balanced sampling learns better generalizable representations \cite{kang2019decoupling}, we use the original distribution to train a feature extractor  and a classifier  in Stage-I. 
	
	For a sample  in a tail class , we extract its feature with . Inspired by ISDA, we can randomly sample along  to generate features with different semantic transformations,  i.e., .


	As the semantic transformation directions of different categories are different, we need to compute a covariance matrix for each category. To get the covariance matrix, we first need to calculate each class prototype by averaging features of all the samples in a class, as shown in Equation (\ref{eq1}): 
	
	
	where ,  is the number of samples in class , and  represents feature of the -th sample in . Secondly, we calculate each element in a covariance matrix with: 
	
	
	After that, the covariance matrixes of all classes  can be obtained. 
However, covariance matrixes for tail classes contain limited variations.
	To alleviate this issue, we propose a novel reasoning module to transfer plentiful variations from other classes. 
	


	
	




	


	
	
	\subsection{Reasoning-Based Implicit Data Augmentation}
	In this section, we elaborate on the process of transferring knowledge to augment a tail sample. With the constructed knowledge graph, we can enrich the covariance matrixes of tail classes by reasoning.
	\subsubsection{Knowledge Graph Construction}
	Current methods usually transfer variations from head classes to the tail ones. Instead, our approach tries to transfer knowledge from similar categories. To achieve this, we use the classifier  to construct a knowledge graph, which is built with the confusion matrix on the training data. Actually, it is a category-to-category directed graph , where  are category nodes and . Each element  represents the similarity of  and , which can be calculated as follows:
	
	
	where  is the indicator function.  represents the ratio of the number of samples in  predicted into .
	
	\subsubsection{Reasoning-Based Semantic Transformation}
	We propose to refine the covariance matrix of each tail class with those of its similar classes. Intuitively, different categories are similar because they have similar appearances or living environments. 
For example, because ``Kingfisher" and ``Parrot" are very similar, when we see a flying ``Parrot", we can imagine a flying ``Kingfisher" even if we haven't seen a flying ``Kingfisher".
	Therefore, we can infer a better intra-class covariance for tail classes by transferring semantic transformations from similar classes:  
	
	Ideally, we need to compute the reasoning-based class-conditional covariance matrix with entire training samples in each epoch. It is cost-expensive. So we use an online process to update and transfer covariance matrix batch by batch.
	
	With the reasoning-based covariance matrix, we can change an instance with a more diversified semantic direction. However, an instance may miss some features that are necessary for a reasoning-based transformation direction. For example, only when the mouth is detected in a ``Kingfisher", we can change the pose of its mouth. Therefore, to ensure a tail instance contains all the features to transfer, we complement it with features from similar categories: 
	 
	
	After the feature distribution of each tail sample is refined by a reasoning prototype and a reasoning covariance matrix.
Then,  can perform various semantic transformations along the random direrctions sampled from  and generate the augmented feature  during trainning with Equation (\ref{eq7}): 
	
	where  and  are positive coefficients to control the strength of reasoning-based semantic data augmentation. In the experiment, both  and  are decayed by , where  and  represent the current number of epochs and the number of total epochs, respectively.
\subsection{Optimization}
	With our data augmentation method, a straightforward way to train a classifier is to generate samples for tail classes with Equation (\ref{eq7}) untill they have comparable samples with head classes. Assume each sample in tail class  is augmented  times, then we can obtain a new data set , where  sampled from  is the -th augmented feature of .
	
	Thereafter, we can use the traditional cross-entrory loss to train a classifier: 
	
	
	where  represents the set of tail classes,  is the set of head classes,
	 and  are the weight matrixes and
	biases corresponding to the last fully connected layer, respectively.
	\begin{table*}[!pt]
		\centering
		\begin{tabular}{lccccc}
			\toprule
			Imbalance factor ()      & 200   & 100   & 50    & 20    & 10 \\
			\midrule
			Cross-Entropy      & 65.30 & 61.54 & 55.98 & 48.94 & 44.27 \\ 
			Mixup \cite{zhang2017mixup}     &-       &60.46       &55.01       &-       &41.98       \\ 
			L2RW \cite{ren2018learning}        &67.00       &61.10       &56.83       &49.25       &47.88       \\ 
			Class-balanced CE \cite{cui2019class}         &64.44       &61.23       &55.21       &48.06       &42.43       \\ 
			Class-balanced  fine-tuning \cite{DBLP:conf/cvpr/CuiSSHB18}         &61.34       &58.50       &53.78       &47.70       &42.43       \\ 
			Meta-weight net \cite{shu2019meta}                           &63.38      &58.39       &54.34      &46.96       &41.09       \\ 
			Meta-class-weight with cross-entropy loss \cite{jamal2020rethinking} &60.69       &56.65       &51.47       &44.38       &40.42       \\ 
			BBN \cite{zhou2020bbn}                                       &-       &57.44       &52.98       &-       &40.88       \\ 
			Hybrid-PSC \cite{wang2021contrastive}                                &-       &55.03       & 51.07      &-      &37.63       \\ 
			Bag of Tricks \cite{zhang2021bag}                           &-       &52.17       &48.31       &-       &-       \\ 
			MetaSAug with cross-entropy loss \cite{li2021metasaug}          &60.06       &53.13       &48.10       &42.15       &38.27       \\ 
			\textbf{RISDA}                                 &\textbf{55.24}       &\textbf{49.84}       &\textbf{46.16}       &\textbf{41.33}         &\textbf{37.62}       \\ 
			\bottomrule
		\end{tabular}
		\caption{Error rate () of ResNet-32 on CIFAR-100-LT under different imbalance factors.}
		\label{tab1}
	\end{table*}
	


	However, for the tail category, when sampling  times, the sampling variance is unstable and limited. An ideal way is to generate as much data as possible (i.e., set  as large as possible). But the increasing  can lead to additional calculations. To simplify computation while generating more data, we plan to implicitly generate unlimited features. When  is close to infinity, we can derive an easy upper-bound loss following the Law of Large Numbers.
	In detail, when , we take into account all possible enhanced samples, and then the loss for tail categories can be defined as:
	
	
	Nevertheless, the above equation is difficult to calculate accurately. With the help of Jensen’s inequality , we can derive its upper bound as follows: 
	
	Because of 
	, we can obtain that  is also a Gaussian random variable, i.e.
	, where .
	
	After that, we use the moment-generating function: 
	
	 
	Finally, we can get Equation (\ref{eq12}): 
	
	 
	where 
	, and  is the -th logits of the output for . Essentially, Equation (\ref{eq12}) provides a surrogate
	loss for our reasoning implicit data augmentation method, through optimizing upper bound 
	instead of minimizing the exact loss function . This new loss can effectively adjust the classification decision boundary with the reasoning-based augmented features. 
	
	But when we generate unlimited samples for tail categories, the data distribution is still unbalanced where the head categories become ``tail categories". Therefore, similar to the tail class, we also make infinite enhancements for head classes. In this way, we find that head categories are still dominant because the augmentation results rely on the training samples and the head class has most of the samples. To solve this problem, we introduce the re-weighting strategy by setting different weights to different classes, which are defined as , where  is a hype-parameter. With the re-weighting strategy, we can modify the loss function as follows: 
	 


	Our reasoning module can generate more diversified samples by reasoning features and transformations from other classes, which is shown in the experiment. In addition, the proposed novel robust loss can be easily adopted as a plug-in module for other methods.
	
	\section{Experiment}
	
	\subsection{Datasets}
	We conduct experiments on three long-tailed datasets: CIFAR-100-LT, ImageNet-LT, and iNaturalist 2018\footnote{\url{https://github.com/visipedia/inat_comp}}.
	
	CIFAR-100 is a balanced dataset containing 60,000 images from 100 categories. In our experiment, an imbalance factor , which is the ratio of sample numbers of the most frequent and least frequent classes, is used to generate different training sets for CIFAR-100-LT \cite{cui2019class,cao2019learning}. By varying , we can obtain five training sets. 
	
	ImageNet-LT is constructed from ImageNet by discarding some training samples \cite{liu2019large}. It has 115,846 training images, 20,000 validation images, and 50,000 testing images. The most frequent class contains 1,280 images, while the least frequent one only has 5 samples. 
	
	The iNaturalist 2018 is a large-scale species dataset with an extremely imbalanced distribution, where the imbalance factor is 500. It contains 437,513 training images and 24,426 validation images from 8,142 classes. 
	
	
	\subsection{Results on CIFAR-100-LT}
	
	For CIFAR-100-LT, we use ResNet-32 as our backbone, which is trained by standard stochastic gradient descent (SGD) with a momentum of 0.9 and a weight decay . We train the model for 200 epochs with a batch size of 100. The initial learning rate is set to 0.10, and the linear warm-up learning rate schedule is adopted.  Besides, we decay the learning rate by 0.01 at the  and  epochs. For the hyperparameters  and , we select them from . Different  have different optimal  and , which are shown in Table \ref{tab0}. We compare our RISDA with some state-of-the-art methods. The results are shown in Table \ref{tab1}, where ``" indicates the results reported in the original paper, and ``" indicates the results reported in \cite{li2021metasaug}. 
	
	\begin{table}[!hbp]
		\centering
		\begin{tabular}{lccccc}
			\toprule
			    & 200 & 100 & 50 & 20 & 10 \\
			\midrule
			& 0.50    &  0.50   & 0.75   &  0.75  & 0.50   \\ 
			&   1.00 &   0.75   & 1.00   & 0.75   & 0.50   \\ 
			\bottomrule
		\end{tabular}
		\caption{Optimal  and  under different }
		\label{tab0}
	\end{table}
	
	


	


	We can draw the following conclusions: Firstly, our method can achieve the best performance compared with existing state-of-the-art methods. Secondly, the more unbalanced the data set is, the more our method improves. For example, when the  is 200 and 100, the error rate is reduced by 4.82 and 3.29  compared with MetaSAug. While, when the  is 20, the error rate is reduced by 0.82. However, when the  is 10, the error rate is only reduced by 0.65. 
	We believe that this situation occurs because the fewer samples, the worse the covariance matrix learned by the tail category. Then, the variations transferred from similar categories can better improve the feature diversity of a tail category. Therefore, we can conclude that our method is more suitable for dealing with extremely imbalanced data.
	
	\begin{table}[t]
\centering
		\begin{tabular}{l c}
			\toprule
			Method      & Error rate (     \\ 
			\midrule
			Cross-Entropy & 61.12                \\ 
			Class-balanced CE \cite{cui2019class}&59.15                      \\ 
			OLTR \cite{liu2019large}& 59.64                     \\ 
			LDAM \cite{cao2019learning}&58.14                      \\ 
			LDAM-DRW \cite{cao2019learning}&54.26                      \\ 
			Meta-class-weight \cite{jamal2020rethinking}&55.08                      \\ 
			MetaSAug \cite{li2021metasaug} &52.61                      \\ 
			Bag of Tricks \cite{zhang2021bag} &56.87                      \\ 
			\textbf{RISDA}&\textbf{49.31}                    \\ 
			\bottomrule
		\end{tabular}
		\caption{Results on ImageNet-LT of different methods. }
\label{tab2}
	\end{table}


	
\subsection{Results on ImageNet-LT }
	
For fairness, we use ResNet-50 as the backbone. Concretely, the ResNet-50 is trained for 100 epochs by SGD with a momentum of 0.9 and a weight decay . We set the initial learning rate to 0.1 and use the linear warm-up learning rate schedule for the first five epochs. Then, we decay the learning rate by 0.1 at the  and  epochs.
	Due to GPU memory limitation, we only transfer the covariance, so we augment a sample  during training with . We set  = 7.5. To recognize tail classes for augmentation, we define classes with more than 100 images as head classes, otherwise are the tail classes. 


	
	We compare our RISDA with the following methods: 1)Cross-Entropy(CE), class-balanced loss, meta-class-weight, LDAM-DRW, OLTR, and Bag of Tricks. 2)Mixup and MetaSAug. The experimental results are shown in Table \ref{tab2}. We can see that the error rate of RISDA is reduced to 49.31. More importantly, the error rate is reduced by 3.3 compared with MetaSAug, which shows that the diversity depicted by tail classes is limited, and can be greatly enriched by borrowing transformations from other classes.
	
	


	\subsection{Results on iNaturalist 2018}
For iNaturalist 2018, we also implement ResNet-50 to achieve better classification results. We train the network with a batch size 128 for 120 epochs by SGD with a momentum of 0.9
	and a weight decay . The learning rate is initialized to 0.05. We adopt the linear warm-up learning rate schedule \cite{goyal2017accurate} and decay the learning rate by 0.1 at  and  epochs. Referring to the setting in paper \cite{liu2019large}, we split the classes into head classes (with more than 100 images) and tail classes (with less than or equal to 100 images). Due to GPU memory limitation, we also only transfer the covariance, so a sample  is augmented during training with .  
\begin{table}
\centering
		\begin{tabular}{l c}
			\toprule
			Method             & Error rate ()             \\ 
			\midrule
			Cross-Entropy      &34.24            \\ 
			Class-balanced CE \cite{cui2019class}                    &33.57                      \\ 
			Class-balanced focal \cite{cui2019class}                      &38.88                      \\ 
			cRT \cite{kang2019decoupling}                      &32.40                      \\ 
			LDAM \cite{cao2019learning}             & 35.42       \\ 
			LDAM-DRW \cite{cao2019learning}   &32.00      \\ 
			BBN \cite{zhou2020bbn}     & 33.71                      \\ 
			Meta-class-weight \cite{jamal2020rethinking}                     &32.45                      \\ 
			MetaSAug \cite{li2021metasaug}        &31.25      \\     
			Hybrid-PSC \cite{wang2021contrastive}                     &31.90                      \\                
			Bag of Tricks \cite{zhang2021bag}                    &\textbf{29.13}                     \\ 
			\textbf{RISDA}   & \multicolumn{1}{c}{    } \\ 
			\bottomrule
		\end{tabular}
		\caption{Results on iNaturalist 2018 of different methods.}
\label{tab3}
	\end{table}


	We compare our RISDA with the following methods: 1) CE, class-balanced with CE and focal loss, meta-class-weight, and LDAM-DRW. 2) BBN, decoupling, and Hybrid-PSC. 3)Bag of Tricks and MetaSAug. The experimental results are shown in Table  \ref{tab3}. The average error rate of our method is reduced to 30.85.
	
	
	\subsection{Analysis}
	In this section, we conduct experiments to study the effect of different components of the proposed RISDA and discuss the parameter sensitivity on CIFAR-100-LT.
	
	\subsubsection{Ablation Study}
	
	To verify the effect of each part of our method, we do experiments by removing the re-weighting (w/o )  or the reasoning (w/o ) component from our RISDA. Results shown in Table \ref{tab4} demonstrate that: (1) Re-weighting is important in our RISDA. Although we aim to generate unlimited samples through the Gaussian distribution, augmentation is implemented in each sample. Therefore, re-weighting plays a significant role to achieve fairness in training. (2) The reasoning module can effectively refine the feature and the covariance matrix to improve the accuracy of classification. (3) In addition, when  is 200, the reasoning module decreased by 1.73, and when the  is 10, the reasoning module decreased by 0.81, which proves again that our reasoning module is more suitable for dealing with extremely unbalanced data.
	


	\begin{table}[!ht]
\centering
		\begin{tabular}{cccccc}
			\toprule
			 & 200   & 100   & 50    & 20    & 10    \\ 
			\midrule
			w/o  & 36.82      &42.76       &46.98       &54.40       &58.60       \\ 
			w/o     & 56.97 & 51.09 & 47.60  & 42.60  & 38.43 \\ 
			\textbf{RISDA}                                 &\textbf{55.24}       &\textbf{49.84}       &\textbf{46.16}       &\textbf{41.33}         &\textbf{37.62}       \\ 
			\bottomrule
		\end{tabular}
		\caption{Results of RISDA on CIFAR-100-LT under different imbalance factors.}
		\label{tab4}
	\end{table}
	


	\begin{figure*}[!tp]
\centering
\includegraphics[width=\linewidth]{./visualization.pdf}
		\caption{ Visualization of the semantically augmented images for the four tail classes on ImageNet-LT: Wagon, Dunlin, White Stork, and Miniature Schnauzer. ``Original" represents the original training sample. ``Restored" is the image reconstructed by a generator with features of the corresponding training sample. And ``Augmented Images" are generated with features sampled from our refined feature distribution. Our method can generate samples with semantic transformations that are not found in the original training set in terms of color, angle, pose, background, etc. These samples are highlighted in green boxes.}
		\label{visualization}
	\end{figure*}
	
	\subsubsection{Sensitivity of  and }
	For the Gaussian distribution  constructed by the reasoning module, the multivariate of sampling includes two significant componets: reasoning-based complementary feature  and the reasoning-based covariance matrix . We analyze the influence of the transformation strength , . 
\begin{figure}[!ht]
\centering
		\includegraphics[width=0.95\linewidth]{./cxh_plot.pdf}
		\caption{The influence of different  and  on CIFAR-100-LT with  100 and  200.}
		\label{cxh_plot}
	\end{figure}

	
	As shown in Figure \ref{cxh_plot}, we can see that: (1)  = 0.50 can achieve the best performance with  = 100, and 200. Then, when  increases, the performance drops. It indicates that features of other classes can help to complement the feature of a tail instance. (2)  = 1.00 achieves best results on  = 200, and  = 0.75 performs best on  = 100. We can conclude that the more unbalanced, the larger  is better.
\subsubsection{Effect of Head Categories}
\begin{figure}
\centering
		\includegraphics[width=0.95\linewidth]{./cxh_bar.pdf}
		\caption{Results with different number of head categories.}
		\label{cxh_bar}
	\end{figure}
Head categories are expected to have rich diversity. Transferring transformations from other classes may damage their representation, reducing the overall performance. Therefore, we explore the influence of head categories by varying the number in .
	
	As shown in Figure \ref{cxh_bar}, the green bar on the left and the orange bar on the right shows the results with the different number of head categories on  and , respectively. We can see that when the top  categories are regarded as head categories, the best performance is achieved. When it increases,  categories with limited diversity are underrepresented. However, when it decreases, the representation of some rich categories is damaged.
	


	
	
\subsection{Qualitative Analysis}
	

	
	To intuitively show that our RISDA can generate more various samples, we implement the visualization method proposed in ISDA to show some implicitly generated samples. As shown in Figure \ref{visualization}, we can see that our RISDA can generate samples with different backgrounds, view angles, and poses. More importantly, images in green boxes are quite different from those in training sets. For example, the ``Wagon" changes the background, view angle, and color while the ``Dunlin" changed the posture, background, view angle.
	These changes are not available in the training data, and we believe they are delivered from similar categories. Therefore, it can be concluded that our RISDA can transfer more meaningful transformations than ISDA.


	\section{Conclusion and Future Work}
	In this paper, we have proposed a novel reasoning-based implicit semantic data augmentation method to effectively enrich the intra-class diversity for tail categories. By transferring transformation directions from other classes, an instance from tail categories can be augmented with definitely different semantics. Experimental results have shown that our proposed method can improve the performance of long-tail classification. Besides, the visualization experiment has demonstrated that our augmentation method can generate samples that are quite different from those in the training data. In the future, we will work on some fine-grained transformations to achieve more reasonable augmentation.
	

        \bibliography{aaai22}
\begin{table*}[!pt]
		\centering
		\begin{tabular}{{lccccc}}
			\toprule
			Imbalance factor ()      & 200   & 100   & 50    & 20    & 10 \\
			\midrule
			Cross-Entropy    & 34.13& 29.86 & 25.06  & 17.56  & 13.82  \\
			Mixup \cite{zhang2017mixup}     &-       &26.94       &22.18       &-      &12.90       \\ 
			L2RW \cite{ren2018learning}        &33.75       &27.77      &23.55       &18.65       &17.88       \\ 
			Class-balanced CE \cite{cui2019class}         &31.23       &27.32       &21.87       &15.44      &13.10        \\ 
			Class-balanced  fine-tuning \cite{DBLP:conf/cvpr/CuiSSHB18}         &33.76      &28.66       &22.56       &16.78       &16.83       \\ 
			Meta-weight net \cite{shu2019meta}    &32.80     &26.43      &20.90      &15.55       &12.45       \\ 
			Meta-class-weight with cross-entropy loss \cite{jamal2020rethinking} &29.34       &23.59     &19.49       &13.54       &11.15       \\ 
			BBN \cite{zhou2020bbn}    &-       &20.18       &17.82       & -       &11.68       \\ 
			Hybrid-PSC \cite{wang2021contrastive}                                &-       &21.18       & \textbf{14.64}      &-      &\textbf{9.94}       \\
			Bag of Tricks \cite{zhang2021bag}                           &-       &19.97       &16.41       &-       &-       \\ 
			MetaSAug with cross-entropy loss \cite{li2021metasaug}          &\textbf{23.11}    & \textbf{19.46}       &15.97       &\textbf{ 12.36}       &10.56       \\ 
			\textbf{RISDA}                                 &\multicolumn{1}{c}{    }       &\multicolumn{1}{c}{    }        &\multicolumn{1}{c}{    }         &\multicolumn{1}{c}{    }          &\multicolumn{1}{c}{    }      \\
			\bottomrule
		\end{tabular}
		\caption{Error rate () of ResNet-32 on CIFAR-10-LT under different imbalance factors.}
		\label{cifar10}
	\end{table*}
\newpage



\section*{Appendix}

\subsection{Details about Baselines on CIFAR}

In the CIFAR-100-LT and CIFAR-10-LT experiment, we compare with the following methods: (1) Cross-Entropy (CE): we train the model with vanilla cross-entropy loss.
(2)Re-weighting (RW): we train the model with two re-weighting strategies: class-level and instance-level re-weighting. Class-level re-weighting assign different weights to different classes according to the number of samples in loss function, including class-balanced loss \cite{cui2019class} , meta-class-weight \cite{jamal2020rethinking}, and LDAM-DRW \cite{cao2019learning}. Instance-level re-weighting allocate weights to samples, including Focal loss \cite{lin2017focal},  L2RW \cite{ren2018learning} and meta-weight-net \cite{shu2019meta}. (3)Data augmentation method improves classification performance by enhancing data diversity, including mixup \cite{zhang2017mixup} and MetaSAug \cite{li2021metasaug}. 
(4)Two-stage learning splits the learning procedure into feature representation learning and classifier training, such as BBN \cite{zhou2020bbn}, decoupling \cite{kang2019decoupling} and Hybrid-PSC \cite{wang2021contrastive}. In addition, we also compare with Bag of Tricks\cite{zhang2021bag}, which integrates the commonly used training tricks in long-tail classification.

\subsection{Results on CIFAR-10-LT}

CIFAR-10 is a balanced dataset containing 60,000 images from 10 categories, and the training set has 5000  images per class. In our experiment, an imbalance factor , which is the ratio of sample numbers of the most frequent and least frequent classes, is used to generate different training sets for CIFAR-10-LT \cite{cui2019class,cao2019learning}. By varying , we can obtain five training sets. A long-tail distribution usually contains many classes. As CIFAR-10-LT only contains 10 classes, we leave out its experiments in the main body. 

Experimental results on CIFAR-10-LT are shown in Table \ref{cifar10}. 
We can see that our RISDA is better than most baseline methods, but achieves comparable performance with MetaSAug. We believe that this situation occurs because our method is good at dealing with large-scale long-tailed classification problem. With more categories, there are rich similarity relations to make reasonable transformatnion. In addition, the CIFAR-10-LT dataset contains a large number of samples in each category. Even in the most unbalanced case, there are 25 samples for the least tail categories. Consequently, the diversity of samples learned in each category is rich enough. Therefore, although RISDA performs better, we argue that it is more suitable to deal with many classes.
\subsection{Comparison with ISDA}
Our RISDA is developed from ISDA to achieve implicitly data augmentation. However, ISDA fails on long-tail distributed data. Firstly, the diversity of augmented data for tail classes is quite limited because ISDA enhances a sample with the covariance of its class. As tail classes only own a few samples, their covariance is limited. Secondly, ISDA lacks strategies to achieve balance training. For the sake of fairness, we show the results of ISDA and ISDA with reweighting in Table \ref{cifar100}. We can see that even if equipped with reweighting, ISDA is still worse than RISDA because of the limited diversity.
\begin{table}[!ht]
\centering
	\begin{tabular}{lclclclclclc}
		\toprule
		      & 200   & 100   & 50    & 20    & 10 \\
		\midrule
		CE      & 65.30 & 61.54 & 55.98 & 48.94 & 44.27 \\ 
		ISDA  & 64.48      &58.65       &54.35      &47.25       &42.84      \\
		ISDA+     & 56.97 & 51.09 & 47.6  & 42.6  & 38.43  \\
		\textbf{RISDA}                                 &\textbf{55.24}       &\textbf{49.84}       &\textbf{46.16}       &\textbf{41.33}         &\textbf{37.62}       \\
		\bottomrule
	\end{tabular}
	\caption{Error rates () on CIFAR-100-LT.}
	\label{cifar100}
\end{table}

Our RISDA diversify tail classes from two aspects: (1) We transfer covariance from similar classes to tail classes to expand the variations. Therefore, RSIDA can imagine a flying bird when there are only birds on the roost in the training set(the flying is transferred from similar classes). (2) A tail sample may miss some features since tail classes are under-fitted. If a bird's wing features can't be extracted, the corresponding semantic changes will not work. In RSIDA, we can infer some missing features through the knowledge graph, so as to achieve more variations for a specific sample.

\end{document}
