\documentclass[11pt]{article}


\addtolength{\jot}{1ex}                



\newtheorem{theorem}{Theorem}[section]
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{corollary}[theorem]{\indent Corollary}
\newtheorem{proposition}[theorem]{Proposition}
\newtheorem{conjecture}[theorem]{Conjecture}
\newtheorem{example}{\indent Example}
\newtheorem{definition}{Definition}
\newenvironment{claim}{\par \noindent{\bf Claim:}}{\par}
 
\newcommand{\qed}{\nopagebreak \hfill }
\newenvironment{proof}{\par \noindent {\em Proof:}}{\qed \par}
\newenvironment{defproof}[1]{\par \noindent {\em Proof~#1:}}{\qed \par}
 
\newcommand{\case}[1]{\par{\small \sc Case #1:}}
\newcommand{\subcase}[1]{\par{\em Case #1:}\/}
\newcommand{\basis}{\par{\small \sc Basis }}
\newcommand{\induction}{\par{\small \sc Induction }}
\newcommand{\construction}{\par{\small \sc Construction: }}
\newcommand{\correctness}{\par{\small \sc Correctness: }}
\newcommand{\analysis}{\par{\small \sc Analysis: }}
 
\newenvironment{algorithm}{\begin{center}\begin{minipage}[b]{0.8\textwidth}\begin{list}{}{\setlength{\listparindent}{-2.5mm}\setlength{\itemindent}{\listparindent}}\setlength{\labelsep}{0in}\setlength{\parskip}{0ex}\setlength{\parsep}{\parskip}\setlength{\topsep}{0in}\setlength{\partopsep}{0in}\item[]}{\end{list}\end{minipage}\end{center}}
 
\newenvironment{block}{\begin{list}{}{\setlength{\leftmargin}{5mm}\setlength{\listparindent}{-0.5\leftmargin}\setlength{\itemindent}{\listparindent}}\setlength{\labelsep}{0in}\setlength{\parskip}{0ex}\setlength{\parsep}{\parskip}\setlength{\topsep}{0in}\setlength{\partopsep}{0in}\item[]}{\end{list}}
 
\newcommand{\Algorithm}{{\bf algorithm\ }}
\newcommand{\Comment}{{\bf comment:\ }}
\newcommand{\Begin}{{\bf begin\ }}
\newcommand{\End}{{\bf end\ }}
\newcommand{\If}{{\bf if\ }}
\newcommand{\Or}{{\bf or\ }}
\newcommand{\And}{{\bf and\ }}
\newcommand{\Then}{{\bf then\ }}
\newcommand{\Else}{{\bf else\ }}
\newcommand{\Repeat}{{\bf repeat\ }}
\newcommand{\Times}{{\bf times\ }}
\newcommand{\Forever}{{\bf forever\ }}
\newcommand{\For}{{\bf for\ }}
\newcommand{\From}{{\bf from\ }}
\newcommand{\To}{{\bf to\ }}
\newcommand{\By}{{\bf by\ }}
\newcommand{\All}{{\bf all\ }}
\newcommand{\Do}{{\bf do\ }}
\newcommand{\Choose}{{\bf choose\ }}
\newcommand{\Accept}{{\bf accept}}
\newcommand{\Reject}{{\bf reject}}
\newcommand{\Halt}{{\bf halt}}
\newcommand{\Return}{{\bf return\ }}
\newcommand{\Send}{{\bf send\ }}
\newcommand{\Receive}{{\bf receive}}
 
\setlength{\marginparwidth}{1in}
\setlength{\marginparpush}{-5ex}
\newenvironment{change}{\marginpar{}}{\marginpar{}}
\newcommand{\deletion}{\marginpar{}}
\newcommand{\mnote}[1]{\marginpar{\scriptsize\it
            \begin{minipage}[t]{1in}
              \raggedright #1
            \end{minipage}}}
 
\newcommand{\etal}{{\em et al.}}
\newcommand{\half}{\frac{1}{2}}                      \newcommand{\floor}[1]{\left\lfloor #1 \right\rfloor }
\newcommand{\ceiling}[1]{\left\lceil #1 \right\rceil }
\newcommand{\binomial}[2]{\left(
  \begin{array}{@{}c@{}} #1\
\nonumber
\mbox{min  }&\sum_{i \in \mathcal{F}, j \in \mathcal{C}}{c_{ij}x_{ij}} +
\sum_{i \in \mathcal{F}}{f_i y_i} & ~\mbox{s.t.} \\ \nonumber
&\sum_{i \in \mathcal{F}} x_{ij} = 1 & \mbox{for all }j \in \mathcal{C}, \\ \nonumber
&x_{ij} - y_i \leq 0 & \mbox{for all } i \in \mathcal{F}, j \in \mathcal{C},\\ \label{eq_int}
&x_{ij},y_i \in \{ 0,1 \}       & \mbox{for all } i \in \mathcal{F}, j \in \mathcal{C}\,.

d_j = d(j, \F) = \frac{\sum_{i \in \F} c_{ij} \cdot x^*_{ij} }{\sum_{i \in \F} x^*_{ij}}  = \sum_{i \in \F} c_{ij} \cdot x^*_{ij}.

d^{(c)}_j = d(j,C_j) = \frac{\sum_{i \in \F} c_{ij} \cdot \overline{x}_{ij} }{\sum_{i \in \F} \overline{x}_{ij}}
= \frac{\sum_{i \in C_j} c_{ij} \cdot \overline{y}_{i} }{\sum_{i \in C_j} \overline{y}_{i}}  = \sum_{i \in C_j} c_{ij} \cdot \overline{y}_{i},

d^{(d)}_j = d(j,D_j) = \frac{\sum_{i \in D_j} c_{ij} \cdot x^*_{ij} }{\sum_{i \in D_j} x^*_{ij}}
= \frac{\sum_{i \in D_j} c_{ij} \cdot \overline{y}_{i} }{\sum_{i \in D_j} \overline{y}_{i}}
 = \frac{\sum_{i \in D_j} c_{ij} \cdot \overline{y}_{i} }{\gamma - 1}.

 d(j,C_{j'} \setminus (C_j \cup D_j )) \leq
 d_{j}^{(d)} + d_{j'}^{(max)} + d_{j'}^{(c)}.

 E\left[\min_{i\in A, y_i=1}c_{ij} \ | \ \sum_{i\in A} y_i \geq 1\right] \leq d(j,A)
 \label{eq:gamma0}
\left( \frac{e^{-1} + e^{-\gamma}}{1 - \frac{1}{\gamma}} \right) -  \left(1 + 2e^{-\gamma} \right) = 0 

E[cost(OPEN_i)] & = &\gamma \cdot F^*_i, \\
E[cost(CONN_j)] & \leq & \max\left\{1 + 2e^{-\gamma}, \frac{e^{-1}+e^{-\gamma}}{1 - \frac{1}{\gamma}}\right\} \cdot C^*_j\\  

  E[cost(CONN_j)] & \leq &p_c \cdot d_j^{(c)} + p_d \cdot d_j^{(d)} + p_s \cdot (d_{j}^{(d)} + d_{j'}^{(max)} + d_{j'}^{(c)})\\
  & \leq & \left( (p_c + p_s) \cdot d_j^{(c)} + (p_d + 2p_s) \cdot d_j^{(d)} \right)\\
  & = & \left( (p_c + p_s) \cdot (1- \rho_j) d_j + (p_d + 2p_s) \cdot (d_j (1+ \frac{\rho_j}{\gamma -1})) \right)\\
  & = &((p_c + p_d + p_s) + 2p_s) \cdot d_j + d_j \cdot \left( -\rho_j(p_c + p_s) + (p_d + 2p_s) \cdot \frac{\rho_j}{\gamma -1} \right) \\
  & = &(1 + 2p_s) \cdot d_j +  d_j \cdot \rho_j \left( \frac{1-\gamma p_c + (2 - \gamma)p_s}{\gamma-1} \right)\\
  & \leq &(1 + 2e^{-\gamma}) \cdot d_j +  d_j \cdot \rho_j \left( \frac{1-\gamma (1-e^{-1}) + (2 - \gamma)e^{-\gamma}}{\gamma-1} \right)\\
  & = &(1 + 2e^{-\gamma}) \cdot d_j +  d_j \cdot \rho_j \left( \left( \frac{e^{-1}+e^{-\gamma}}{1 - \frac{1}{\gamma}}\right) - \left(1 + 2e^{-\gamma} \right) \right)\\
  & = &d_j \cdot \left[ (1 - \rho_j)\left(1 + 2e^{-\gamma} \right) + \rho_j \left( \frac{e^{-1}+e^{-\gamma}}{1 - \frac{1}{\gamma}} \right) \right] \\
  & \leq &d_j \cdot \max\left\{1 + 2e^{-\gamma}, \frac{e^{-1}+e^{-\gamma}}{1 - \frac{1}{\gamma}}\right\} \\
  & = &C^*_j \cdot \max\left\{1 + 2e^{-\gamma}, \frac{e^{-1}+e^{-\gamma}}{1 - \frac{1}{\gamma}}\right\}
 \mbox{minimize} ~
\sum_{i \in \mathcal{F}} f_i^I y_i +
\sum_A p_A (\sum_i f_i^A y_{A,i} + \sum_{j \in A} \sum_i c_{ij} x_{A,ij})~
\mbox{subject to} 
\sum_i x_{A,ij} & \geq & 1 ~~\forall A ~\forall j \in A; 
\label{eqn:facloc-assign} \\
x_{A,ij} & \leq & y_i + y_{A,i} ~~\forall i ~\forall A ~\forall j \in A; 
\label{eqn:facloc-xleqy} \\
x_{A,ij}, y_i, y_{A,i} & \geq & 0 ~~\forall i ~\forall A ~\forall j \in A.
\nonumber

 \mbox{maximize} && \sum_{A} p_A (\sum_{j \in A} v_{j,A})
~\mbox{subject to:}\\
 && w_{ij,A} \geq v_{j,A} - c_{ij}\\
 && f_i^I \leq \sum_{A} p_A (\sum_{j \in A} w_{ij,A})\\
 && f_i^A \leq \sum_{j \in A} w_{ij,A}\\
 &&  w_{ij,A},v_{j,A} \geq 0.
 
 E[COST(A)] & \leq & e^{-2} \cdot 3 \cdot \sum_{j \in A} v_{j,A} + 
 (1-e^{-2})  (\sum_{j\in A}\sum_{i\in \F} c_{ij}x^*_{A,ij}) + 
 2 \cdot (\sum_{i \in \F} (f_i^I y^*_{i} + f_i^A y^*_{A,i})) \\
 & \leq & e^{-2} \cdot 3 \cdot V_A + (1-e^{-2}) \cdot C_A + 2 \cdot F_A.

 E[COST(\hat{x},\hat{y})]& = & \sum_A p_A E[COST(A)]\\
 & \leq & \sum_A p_A\left( e^{-2} \cdot 3 \cdot V_A + (1-e^{-2}) \cdot C_A + 2 \cdot F_A \right)\\
 & = & (1-e^{-2}) \cdot C^* + 2 \cdot F^* + 3e^{-2} (\sum_A p_A V_A)\\
 & = & (1-e^{-2}) \cdot C^* + 2 \cdot F^* + 3e^{-2} (F^*+C^*)\\
 & = & (2 + e^{-2} \cdot 3) F^* + (1 + e^{-2} \cdot 2) C^* \\
 & \leq & 2.4061 \cdot F^* + 1.2707 \cdot C^*.
 \label{eqn:rf0}
 \mbox{minimize} ~
\sum_{i \in \mathcal{F}} f_i y_i +
\max_A \sum_{j} \sum_i c_{ij} x_{A,ij}~
\mbox{subject to} 

\sum_i x_{A,ij} & \geq & 1 ~~\forall A ~\forall j; 
\label{eqn:rf1} \\
x_{A,ij} & \leq & y_i  ~~\forall i ~\forall A ~\forall j ; 
\label{eqn:rf2} \\
x_{A,ij} & = & 0  ~~\forall A ~\forall i \in A ~\forall j ; 
\label{eqn:rf3} \\
x_{A,ij}, y_i, y_{A,i} & \geq & 0 ~~\forall i ~\forall A ~\forall j.
\nonumber

F_{(j,A)}^I = \left\{ 
\begin{array}{l l}
    argmin_{F' \subseteq \F : \sum_{i \in F'} \overline{x}^{(I)}_{A,ij} \geq 1 } max_{i \in F'} c_{ij} &  
    \mbox{if }\\
  \emptyset &  \mbox{if }\\
\end{array} \right.

F_{(j,A)}^{II} = \left\{ 
\begin{array}{l l}
    argmin_{F' \subseteq \F : \sum_{i \in F'} \overline{x}^{(II)}_{A,ij} \geq 1 } max_{i \in F'} c_{ij} &  
    \mbox{if }\\
  \emptyset &  \mbox{if }\\
\end{array} \right.


Note that  these sets can easily be computed by considering facilities in an order of non-decreasing distances 
to the considered client .
Since we can split facilities, w.l.o.g., for all  we assume that if  is nonempty then
, and if  is not empty then
.
Define  and .
Let .

For a client-scenario pair , if we have , then we call such a pair \emph{first-stage clustered},
and put its \emph{cluster candidate} . Otherwise, if , 
we say that  is \emph{second-stage clustered} and put its \emph{cluster candidate} 

Recall that we use  to denote the fractional connection cost of client  in scenario .
Let us now argue that distances to facilities in \emph{cluster candidates} are not too large. 

\begin{lemma} \label{lemma:d_j_A}
  for all pairs . 
\end{lemma}

\begin{proof}
Fix a client-scenario pair . Assume  (the other case is symmetric).
Recall that in this case we have .
Consider the following two subcases.\\
\textbf{Case 1.} .\\
Observe that we have  for all .
Note also that  and
. 
Hence, .\\
\textbf{Case 2.} , which implies that 
. Observe that now we have ,
and therefore .
Recall that  for all , hence
. 
\end{proof}
 
Like in Section~\ref{section:general_exp}, the algorithm opens facilities randomly in each of the stages
with the probability of opening facility  equal to 
in Stage I, and  in Stage II of scenario .
Some facilities are grouped in disjoint \emph{clusters} in order to correlate 
the opening of facilities from a single cluster.
The clusters are formed in each stage by the following procedure.
Let all facilities be initially unclustered.
In Stage I, consider all first-stage clustered client-scenario pairs, 
i.e., pairs  such that .
(in Stage II of scenario , consider all second-stage clustered client-scenario pairs)
in the order of non-decreasing values .
If the set of facilities  contains no facility
from the previously formed clusters, 
then form a new cluster containing facilities from ,
otherwise do nothing.
In each stage, open exactly one facility in each cluster.
Recall that the total fractional opening of facilities in each cluster
equals 1. Within each cluster choose the facility randomly with the probability
of opening facility  equal to the fractional opening  
in Stage I, or  in Stage II of scenario .
For each unclustered facility  open it independently with 
probability  in Stage I, and with probability  in Stage II of scenario .

Finally, at the end of Stage II of scenario , connect each client  to the 
closest open facility.

\paragraph{Analysis.}
The expected facility-opening cost is obviously  times the fractional opening cost.
More precisely, the expected facility-opening cost in scenario  equals 
it remains to bound the expected connection cost in scenario  in terms of 
. 

\begin{lemma}
The expected connection cost in scenario A is at most .
\end{lemma}

\begin{proof}
Consider a single client-scenario pair .
Observe that the facilities fractionally connected to  in scenario 
have the total fractional opening of  in the scaled facility-opening vector .
Since there is no positive correlation (only negative correlation in the disjoint clusters formed 
by the algorithm), with probability at least  at least one such facility will be opened,
moreover, by Lemma~\ref{exp_distance_lemma} the expected distance to the closest of the open facilities from this set
will be at most the fractional connection cost .

Just like in the proof of Lemma~\ref{primal_dual_lemma}, from the greedy construction of the clusters
in each phase of the algorithm, with probability 1, there exists facility  opened 
by the algorithm such that .
We connect client  to facility  if no facility from facilities fractionally serving  was opened.
We obtain that the expected connection cost of client  is at most .
By Lemma~\ref{lemma:d_j_A}, this can by bounded by  

\end{proof}

To equalize the opening and connection cost approximation ratios we solve  and obtain the following.

\begin{theorem}
The described algorithm with  delivers solutions such that the expected cost in each scenario 
is at most 2.4957 times the fractional cost in scenario . 
\end{theorem}

\section{Robust fault-tolerant UFL}
\label{app:rft}

\subsection{The -approximation rounding routine}
\label{sec:rftfl-general}
Like in the algorithms in the previous sections we first scale up the fractional facility-opening costs,
we then cluster certain facilities to correlate their opening,
and then use a randomized rounding routine to decide the subset of facilities to open.
Once we open facilities and the adversary chooses which  of them to close,
clients get connected to the closest of the remaining open facilities.

Let  be an optimal solution to the above LP relaxation 
of the problem.
We first scale up the opening of facilities by ,
i.e., we set .
We also set 
 
Consider a single client-scenario pair .
Consider facilities  fractionally serving this pair in solution 
in an order  of non-decreasing distance to .
Let  be the first facility in this order such that 
.
Recall that 
denotes the fractional connection cost of client  in scenario .
By an argument analogous to the one in Lemma~\ref{exp_distance_lemma}, we obtain that 
.
We now distinguish two cases.\\
\textbf{Case 1.} There exists  among  such that .
Then facility  will be deterministically opened by the algorithm.
Note that since , we have  (i.e., facility  
is not closed by the adversary
in scenario ); hence, we can connect  to  in scenario  in our constructed integral solution. 
It remains to observe that  
is a distance that we can accept.

\smallskip \noindent
\textbf{Case 2.} There is no  among  such that .
Then we have ,
which is the fractional connection to at least  facilities, each of them
within the distance of . 
With a randomized rounding technique described below, they will be turned into
 facilities opened within the distance of . Since at most  of these facilities will be closed by the adversary,
there remains an open facility for client  in scenario  at distance at most .

It remains to argue that we can turn  fractional connections to facilities at distance at most 
into  integral connections to facilities at distance at most . This can be seen
as a situation typical for LP-rounding algorithms for the standard fault-tolerant facility location problem.
Indeed, exactly this property is associated with the rounding scheme in~\cite{ipco10} (Sections 3 and 4). 
It is obtained by carefully constructing
a laminar family of subsets of facilities and performing a dependent rounding procedure guided
by the subsets. It can also be thought of as an application of the pipage-rounding technique~\cite{AS}. 

\subsection{Better bound in the oblivious setting}
\label{sec:rftfl-oblivious}
Let us now consider the \emph{oblivious} setting where the  facilities to 
close/fail are chosen
without the knowledge of our opening of facilities. 
In this setting we give a bound on the expected connection cost, where the expectation is 
over the random choices of the algorithm. More precisely, we will argue that the expected
connection cost of client  in scenario  is bounded with respect to the fractional connection
cost of  in scenario . 

The difference with the previous setting is that now we can use the argument that after scaling the facility-opening variables
by a constant , for a client  in scenario , with probability at least ,
at least one facility from those fractionally serving  will be opened. Moreover, we can bound
the expected distance to such facility by the fractional connection cost of .
This allows us to use those facilities that get opened with certainty 
(as described in Section~\ref{sec:rftfl-general}) 
only with a certain small probability. 
In such a situation, it is beneficial to scale the 
facility-opening variables by a little less.

The algorithm is like in Section~\ref{sec:rftfl-general}),
only the scaling parameter  is smaller (say ),
and the analysis is different. We argue that 
for every client  in each single 
scenario (choice of the  facilities to close)  the expected
connection cost is bounded. As before we distinguish two cases.\\
{\bf Case 1.} (There exists  such that )
If there is such facility at distance at most  we just connect to it,
otherwise, the average connection cost in  is only smaller then the average connection cost in ,
and we may use a version of the Lemma~\ref{exp_distance_lemma} to argue
that the expected connection cost to the closest of the facilities 
randomly opened by the algorithm is at most .

\smallskip \noindent
{\bf Case 2.} (There is no such facility, 
and therefore there is no  among  such that )
Then we have ,
which is the fractional connection to at least  facilities, each of them
within the distance of . Just like in Section~\ref{sec:rftfl-general}),
we argue that as a result of dependent rounding we obtain  facilities 
deterministically opened within the distance .
And now we propose a suboptimal assignment procedure to bound the cost of the optimal one.
In the suboptimal assignment, client first looks at facilities fractionally serving
him. If one of them is opened then connect to the closest one, which would 
incur an expected cost of , and if non is open, then take a facility
deterministically opened within distance .
Like for the other results in this paper, we then argue that the expected connection cost is 
at most ,
which is less then  for .

\subsection{Integrality gap example}
Let us now show that the program (\ref{eqn:rf0})-(\ref{eqn:rf3})
has integrality gap at least .
Consider the following instance. There is a single client
and  identical facilities. All the facility-opening costs are 1,
and all the connection costs are 0.
The optimal fractional solution opens each facility 
to the extent of , 
incurring cost .
Any integral solution, however, needs to open at least  facilities
and therefore has cost at least .
Therefore, for any  there exists an instance of the -robust fault tolerant problem, for which the integrality gap of the 
program (\ref{eqn:rf0})-(\ref{eqn:rf3}) at least .


\end{document}
