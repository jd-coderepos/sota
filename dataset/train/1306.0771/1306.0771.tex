\documentclass[11pt]{article}



\usepackage{latexsym}
\usepackage{amsmath, amssymb} \usepackage{xspace}
\usepackage{multirow}

\newtheorem{xdefinition}{Definition}
\newtheorem{xobservation}{Observation}
\newtheorem{xtheorem}{Theorem}
\newtheorem{xlemma}{Lemma}
\newtheorem{xproposition}{Proposition}
\newtheorem{xcorollary}{Corollary}
\newenvironment{definition}{\begin{xdefinition}\rm}{\hspace*{\fill}\raisebox{-1pt}{\boldmath}\end{xdefinition}}
\newenvironment{observation}{\begin{xobservation}\rm}{\hspace*{\fill}\raisebox{-1pt}{\boldmath}\end{xobservation}}
\newenvironment{theorem}{\begin{xtheorem}\rm}{\end{xtheorem}}
\newenvironment{lemma}{\begin{xlemma}\rm}{\end{xlemma}}
\newenvironment{proposition}{\begin{xproposition}\rm}{\end{xproposition}}
\newenvironment{corollary}{\begin{xcorollary}\rm}{\end{xcorollary}}
\newenvironment{proof}{\begin{trivlist}\item[]{\bf Proof }}{\hspace*{\fill}\raisebox{-1pt}{\boldmath}\end{trivlist}}

\newcommand{\opt}{{\ensuremath{\textsc{Opt}}}\xspace}
\newcommand{\maj}{{\ensuremath{\textsc{Maj}}}\xspace}
\newcommand{\nav}{{\ensuremath{\textsc{Nai}}}\xspace}
\newcommand{\eag}{{\ensuremath{\textsc{Eag}}}\xspace}
\newcommand{\majnospace}{{\ensuremath{\textsc{Maj}}}}
\newcommand{\navnospace}{{\ensuremath{\textsc{Nai}}}}
\newcommand{\eagnospace}{{\ensuremath{\textsc{Eag}}}}
\newcommand{\alg}{{\ensuremath{\textsc{Alg}}}\xspace}
\newcommand{\algA}{{\ensuremath{\mathcal{A}}}\xspace}
\newcommand{\algB}{{\ensuremath{\mathcal{B}}}\xspace}
\newcommand{\adv}{{\ensuremath{\textsc{Adv}}}\xspace}
\DeclareMathOperator{\WR}{\textrm{WR}}
\DeclareMathOperator{\Max}{\textrm{Max}}
\DeclareMathOperator{\Min}{\textrm{Min}}

\newcommand{\WEHAVE}{\!:\;}
\newcommand{\TO}{\sqsubseteq}
\newcommand{\TRIP}[3]{\ensuremath{(#1,#2,#3)}\xspace}



\begin{document}

\title{The Frequent Items Problem in \\ Online Streaming
under \\ Various Performance Measures\,\thanks{Supported
in part by the Danish Council for Independent Research.  Part 
of this work was done while the
authors were visitng the University of Waterloo.}}

\author{Joan Boyar \hspace{2em} Kim S. Larsen \hspace{2em} Abyayananda Maiti \1ex]
        {\tt \{joan,kslarsen,abyaym\}@imada.sdu.dk}}

\date{}

\maketitle

\begin{abstract}
In this paper, we strengthen the competitive analysis results obtained
for a fundamental online streaming problem, the Frequent Items Problem.
Additionally, we contribute with a more detailed analysis of this
problem, using alternative performance measures,
supplementing the insight gained from competitive analysis.
The results also contribute to the general study of
performance measures for online algorithms. It has long been known
that competitive analysis suffers from drawbacks in certain situations,
and many alternative measures have been proposed. However, more
systematic comparative studies of performance measures have
been initiated recently, and we continue this work, using competitive
analysis, relative interval analysis, and relative worst order
analysis on the Frequent Items Problem.
\end{abstract}

\section{Introduction}
The analysis of problems and algorithms for streaming applications, treating
them as online problems, was started in~\cite{Becchetti09}. 
In online streaming, the
items must be processed one at a time by the algorithm, making some irrevocable
decision with each item. A fixed amount of resources is assumed.
In the frequent items problem~\cite{CH08},
an algorithm must store an item,
or more generally a number of items, in a buffer,
and the objective is to store the items appearing most frequently in
the entire stream.
This problem has been studied in~\cite{Giannakopoulos12}.
In addition to probabilistic considerations,
they analyzed deterministic algorithms using competitive analysis.
We analyze the frequent items problem using relative interval
analysis~\cite{Dorrigiv09} and relative worst order analysis~\cite{Boyar07}.
In addition, we tighten the competitive analysis~\cite{ST85,KMRS88}
results from~\cite{Giannakopoulos12}.

It has been known since the start of the area that competitive analysis does not
always give good results~\cite{ST85} and many alternatives have been proposed.
However, as a general rule, these alternatives have been fairly problem specific
and most have only been compared to competitive analysis.
A more comprehensive study of a larger number of performance measures
on the same problem scenarios was initiated in~\cite{BIL09p}
and this line of work has been continued in~\cite{BLM12p,BGL12p,BGLtap}.
With this in mind, we would like to produce complete and tight results,
and for that reason, we focus on a fairly simple combinatorial problem
and on simple algorithms for its solution, incorporating greediness
and adaptability trade-offs to a varying extent.

Finally, we formalize a notion of competitive function, as opposed to
competitive ratio, in a manner which allows us to focus on the constant
in front of the high order term.
These ideas are also used to generalize
relative worst order analysis.

\section{Preliminaries}\label{sec:prob}
This is a streaming problem, but as usual in online algorithms
we use the term sequence or input sequence to refer to
a stream.
We denote an \emph{input sequence} by ,
where the items  are from some universe ,
assumed to be much larger than .
We may refer to the index also as the \emph{time step}.
We consider online algorithms, which means that items are given
one by one. 


We consider the simplest possible frequent items
problem: An algorithm has a \emph{buffer} with space for one item.
When processing an item, the algorithm can either discard the item
or replace the item in the buffer by the item being processed.
The objective is to keep the most frequently occurring items in the buffer,
where frequency is measured over the entire input, i.e.,
when an algorithm must make a decision, the quality of the decision
also depends on items not yet revealed to the algorithm.
We define this objective function formally:

Given an online algorithm  for this problem,
we let  denote \emph{the item in the buffer at time step~}.
We may omit the superscript when it is clear from the context which
algorithm we discuss.

Given an input sequence  and an item , the {\em frequency}
of the item is defined as ,
where  is the number of occurrences of  in .
The objective is to maximize the
\emph{aggregate frequency}~\cite{Giannakopoulos12}, defined by
,
i.e., the sum of the frequencies of the items stored in the
buffer over the time.



We compare the quality of the achieved aggregate frequencies
of three different deterministic online algorithms
from~\cite{Giannakopoulos12}:
the naive algorithm (\nav), the eager algorithm (\eag),
and the majority algorithm (\maj).
All three are practical streaming 
algorithms, being simple and using very little extra space.

\begin{definition}\label{def:nav}
\mbox{\rm [\navnospace]} \nav buffers every item as it arrives,
i.e.,  for all .
\end{definition}

The algorithm \eag switches mode upon detecting a {\em repeated item}, an
item which occurs in two consecutive time steps.
\begin{definition}\label{def:eag}
\mbox{\rm [\eagnospace]} Initially, \eag buffers every item as it arrives.
If it finds a repeated item, then it keeps
that item until the end, i.e., let

if such a  exists, and otherwise .
Then \eag is the algorithm with  for all  and
 for all .
\end{definition}


The algorithm \maj keeps a counter along with the buffer.
Initially, the counter is set to zero.
\begin{definition}\label{def:maj}
\mbox{\rm [\majnospace]}
If the counter is zero, then \maj buffers the arriving item and sets the counter to one.
Otherwise, if the arriving item is the same as the one currently buffered,
\maj increments the counter by one, and otherwise decrements it by one.
\end{definition}

Finally, as usual in online algorithms, we let \opt denote an optimal
offline algorithm. \opt is, among other things, used in competitive
analysis as a reference point, since no online algorithm can do better.
If  is an algorithm, we let  denote the result (profit)
of the algorithm, i.e., .

In comparing these three algorithms, we repeatedly
use the same two families of sequences;
one where \eag performs particularly poorly and one where \maj
performs particularly poorly.

\begin{definition}\label{sequences}
We define the sequences
 where there are  copies of , and

\end{definition}

The four algorithms, including \opt,
obtain the aggregate frequencies below on these two families of sequences.
The arguments are simple, but fundamental, and also serve as an
introduction to the algorithmic behavior of these algorithms.
\begin{proposition}\label{prop_sequences}
The algorithms' results on  and  are as in
Fig.~\ref{fig-profit}.
\begin{figure}[ht]
\begin{center}
nnnn
\end{center}
\caption{The algorithms' aggregate frequencies on  and .}
\label{fig-profit}
\end{figure}
\end{proposition}
\begin{proof}
In , the frequency of  is  and the frequency of  is .
Thus .
In , the frequency of  is , and the frequencies of all the other , , are . Thus, . Considering both even and odd  gives the required result.

When processing , \eag keeps  in its buffer. Hence, .
Since  has no repeated item, .

For , \maj will have  in its buffer for the first four time steps, so  is . For , \maj brings each , , into its buffer and never brings  into its buffer. Thus, .

With , \opt is forced to perform the same as \nav.
In , \opt must buffer  in the first time step, but it buffers  for the remainder of the sequence. Thus, . Considering both even and odd  gives the required result.
\end{proof}




\begin{definition}\label{def:worstpermut}
Let  be any online algorithm.
We denote the worst aggregate frequency of  
over all the
permutations  of  by
.
\end{definition}
It is convenient to be able to consider items in order of their
frequencies.
Let  be a sorted list of the item
in  in nondecreasing order of frequencies.
For example, if , then .
We will use the notation  throughout the paper.
\begin{lemma}\label{lem:wmaj}
For odd ,
 ,
and for even ,
,
where the  are the items of .
\end{lemma}
\begin{proof}
Every time step where the counter is decremented can be paired with an
earlier one
where it is incremented and the same item is in the buffer.
So, at least  requests contribute to the aggregate frequency of the algorithm.
One can order the items so that exactly the 
requests to that many least frequent items are buffered as follows:
Assuming  is even, then the worst permutation is .
All  (but the last request when  is odd) of the requests which lead
to an item entering the buffer contribute twice, since they are also in
the buffer for the next step.
\end{proof}





\section{Competitive Analysis}\label{sec:comp}
An online streaming problem was first studied from an online algorithms
perspective using competitive analysis by Becchetti and 
Koutsoupias~\cite{Becchetti09}.
Competitive analysis\cite{ST85,KMRS88} evaluates an online algorithm in comparison to an optimal offline algorithm.
For a maximization problem, an algorithm, \algA is called -competitive,
for some constant , if there exists a constant  such that for all finite input sequences , .
The competitive ratio of \algA is the infimum over all  such that \algA is -competitive.
Since, for the online frequent items problem, the relative performance of algorithms depends on the length of , we define
a modified and more general version of competitive analysis,
providing a formal basis for our own claims as well as claims made in
earlier related work.
Functions have also been considered in~\cite{DorrigivL05}.
Here, we focus on the constant in front of the most significant term.
Our definition can be adapted easily to minimization problems in the same
way that the adaptations are handled for standard competitive analysis.
In all these definitions, when  is not otherwise defined,
we use it to denote , the length of the
sequence . As usual, when using asymptotic notation in inequalities,
notation such as  means that there exists a
function  such that .
Thus, we focus on the multiplicative factors that relate the online
algorithm's result to the input length.

\begin{definition} \label{def:com}
An algorithm \algA is -{\em competitive} if

\algA has {\em competitive function}  if \algA is
-{\em competitive} and for any  such that \algA
is -{\em competitive},
.

If algorithm \algA has {\em competitive function}  and algorithm \algB has {\em competitive function} , then \algA is better than \algB according to competitive analysis if
.
\end{definition}


Thus, the concept of competitive function is an exact characterization
up to the level of detail we focus on. It can be viewed as an
equivalence relation, and if  for two
functions  and , then they belong to (and are representatives of)
the same equivalence class. For example,
 and  are
considered equivalent,
whereas  and  are not.

All three algorithms discussed here are non-competitive according to
the original definition.
However, information regarding the relative quality of these algorithms
can be obtained by considering the most significant constants
from the corresponding functions.
Giannakopoulos et~al.\ has proved that no randomized algorithm for the
online frequent items problem, where the buffer has room for one item,
can have a competitive function better than
~\cite{Giannakopoulos12}.
That result can be strengthened for the deterministic case:
\begin{theorem}\label{thm:comp_all}
No deterministic algorithm for the online frequent items problem can have a competitive function better than .
\end{theorem}
\begin{proof}
Consider any deterministic algorithm , and input of the form
 where the
first  items are distinct and the last 
items are identical.
Since \algA is deterministic, an adversary will know whether 
or  is in the buffer upon completion of time step~2.
The value of  is based on this.
If it is , then the adversary sets , and if it is , then
it sets .
As  does not occur among the next  items,
 has no chance of bringing  into its buffer until
the last  items arrive, so it
stores  in its buffer at most  times.
 stores  at least  times.
That gives the ratio of

\end{proof}

In \cite{Giannakopoulos12}, Giannakopoulos et~al.\ proved that
for all sequences  of length , .
Here we give a tighter result for \nav.
\begin{theorem}\label{thm:comp_nav}
\nav has competitive function . It is an 
optimal deterministic online algorithm for the frequent items problem.
\end{theorem}
\begin{proof}
Let  be the frequency of the most frequent item in the input sequence .
Since the lowest possible frequency of an item is ,

Thus,

The right hand side of Ineq.~\ref{eq:comp_nav} reaches its maximum when .
Substituting this value into Ineq.~\ref{eq:comp_nav}, we get the result:

Thus, \nav is a -competitive algorithm and,
by Theorem~\ref{thm:comp_all}, it is optimal.

\end{proof}



For \maj Giannakopoulos et~al.~\cite{Giannakopoulos12} proved a competitive ratio of .
We give the asymptotically tight bounds, including the multiplicative factor.
\begin{theorem}\label{thm:comp_maj}
\maj has competitive function .
\end{theorem}
\begin{proof}
For the lower bound, consider the family of sequences, , from
Definition~\ref{sequences}.
By Proposition~\ref{prop_sequences}, ,
and
1ex]
\frac{n}{2} -1 + \frac{3}{2n}  & \mbox{for odd }
\end{array} \right.\frac{\opt(I)}{\eag(I)} \leq \frac{n-\frac{p}{2}}{2-\frac{p}{n}}=\frac{n}{2}.\Min_{\mathcal{A}, \mathcal{B}}(n) = \min_{|I| = n} \left \lbrace \mathcal{A}(I) - \mathcal{B}(I)\right\rbrace
\mbox{~and~}
\Max_{\mathcal{A}, \mathcal{B}}(n) = \max_{|I| = n} \left \lbrace \mathcal{A}(I) - \mathcal{B}(I)\right\rbrace,\Min(\mathcal{A}, \mathcal{B}) = \liminf _{n\to \infty} \frac{\Min_{\mathcal{A}, \mathcal{B}}(n)}{n} \mbox{ and } \Max(\mathcal{A}, \mathcal{B}) = \limsup _{n\to \infty} \frac{\Max_{\mathcal{A}, \mathcal{B}}(n)}{n}.l(\mathcal{A}, \mathcal{B}) = \left[ \Min(\mathcal{A}, \mathcal{B}), \Max(\mathcal{A}, \mathcal{B}) \right].
\limsup _{n\to \infty} \frac{\nav (E_n) - \eag (E_n)}{n}
= \limsup _{n\to \infty} \frac{n-6+\frac{8}{n}}{n} = 1.

\Min(\nav, \eag)\leq \liminf _{n\to \infty} \frac{\frac{1}{2} - \frac{n}{4}}{n} = -\frac{1}{4}. \nonumber
\nav(I) - \maj_W(I)  &=& \sum_{i=1}^n f_I(a'_i) - 2\sum_{i=1}^{\lfloor \frac{n}{2} \rfloor}f_I(a'_i) - \left (\left\lceil \frac{n}{2} \right\rceil - \left\lfloor \frac{n}{2} \right\rfloor \right) f_I(a'_{\lceil \frac{n}{2} \rceil}) \nonumber\\
 &=& \sum_{i=\lceil \frac{n+2}{2}\rceil}^n f_I(a'_i) - \sum_{i=1}^{\lfloor\frac{n}{2}\rfloor}f_I(a'_i). \label{eq:dif_navmaj}

\nav(I) - \maj_W(I) &=&
\sum_{i=\lceil \frac{n+2}{2}\rceil}^n f_I(a'_i) - \sum_{i=1}^{\lfloor\frac{n}{2}\rfloor}f_I(a'_i) \nonumber
\\
&\leq& \left\lfloor\frac{n}{2}\right\rfloor\frac{p}{n} - \left(p - \left\lceil\frac{n}{2}\right\rceil\right)\frac{p}{n} \nonumber
\\
&=& p - \frac{p^2}{n}. \nonumber
&& \maj(I_B) - \nav(I_B) \nonumber\\
&=& 2  \sum_{i=\lceil \frac{n+2}{2} \rceil}^{n}   f_I(a'_i) + \left(\left\lceil \frac{n}{2} \right\rceil - \left\lfloor \frac{n}{2} \right\rfloor \right) f_I(a'_{\lceil \frac{n}{2} \rceil}) - \sum_{i=1}^n f_I(a'_i)  \nonumber\\
 &=& \sum_{i=\lceil \frac{n+2}{2}\rceil}^n f_I(a'_i) - \sum_{i=1}^{\lfloor\frac{n}{2}\rfloor}f_I(a'_i). \nonumber I_n = a_0,a_0,\ldots,a_0,a_1,a_2,\ldots,a_{\lfloor\frac{n}{2}\rfloor},
\nav(I_n) = \left\lfloor\frac{n}{2}\right\rfloor\frac{1}{n} + \left\lceil \frac{n}{2} \right\rceil \frac{\lceil\frac{n}{2}\rceil}{n}
= \left\{ \begin{array}{ll}
\frac{n}{4} + \frac{1}{2} & \mbox{for even }\\
\frac{n}{4} + 1 + \frac{1}{4n} & \mbox{for odd }
\end{array} \right.

\maj(I_n) = n\frac{\lceil\frac{n}{2}\rceil}{n}=\left\lceil\frac{n}{2}\right\rceil.
\eag(I) - \maj(I) &\leq& nf_k -  1 
\leq  n\frac{\lceil \frac{n}{2} \rceil}{n} - 1
\leq \frac{n}{2} - \frac{1}{2}
\label{eq:majcond}

\eag(I) - \maj(I) &\leq& \left\lceil \frac{n}{2} \right\rceil + q -  2\left( \frac{1}{n}\left(\left\lfloor \frac{n}{2} \right\rfloor -q \right) + q \frac{\lceil \frac{n}{2} \rceil + q}{n}  \right)  \nonumber
\\
&=& \left\{ \begin{array}{ll}
\frac{n}{2} - 1 - \frac{2}{n}(q^2 - q) & \mbox{for even }\vspace{1 mm} \\
\frac{n}{2} - \frac{1}{2} - \frac{1}{n}(2q^2 - q-1) & \mbox{for odd }
\end{array} \right. \nonumber
\\
&\leq&
\frac{n}{2} - \frac{1}{2}
\label{eq:majcond2}

\eag(I) - \maj(I) &=& n\frac{1}{2} - \left( 4\frac{1}{2} + (n-4)\frac{1}{n}\right) \nonumber
\\
&=& \frac{n}{2} -3 + \frac{4}{n}.   \nonumber

\Min(\maj, \eag) = -\Max(\eag, \maj) = -\limsup _{n\to \infty} \frac{\eag (I) - \maj (I)}{n} = -\frac{1}{2}.\nonumber
\forall I\WEHAVE \algA_W(I) \TO (f(n)+o(f(n)))\cdot\algB_W(I),
\frac{\nav_W(I)}{\maj_W(I)} &=& \frac{\sum_{i=1}^k n_if_i}{2(\sum_{i=1}^{j-1}n_if_i + pf_j) + \left (\lceil \frac{n}{2} \rceil - \lfloor \frac{n}{2} \rfloor \right) f_j} \nonumber
\\
&=& \frac{\sum_{i=1}^k n_i^2}{2(\sum_{i=1}^{j-1}n_i^2 + pn_j) + \left (\lceil \frac{n}{2} \rceil - \lfloor \frac{n}{2} \rfloor \right) n_j} \label{eq:majw_profit}

\frac{\nav_W(I')}{\maj_W(I')} \leq \frac{\lfloor \frac{n}{2} \rfloor^2 + \sum_{i=1}^j \hat{n}_i^2}{2\sum_{i=1}^{j}\hat{n}_i^2  - \left (\lceil \frac{n}{2} \rceil - \lfloor \frac{n}{2} \rfloor  \right) \hat{n}_j }\label{eq:majw_profit2}

\frac{\nav_W(I')}{\maj_W(I')} = \left\{ \begin{array}{ll}
\frac{n}{4} + \frac{1}{2} & \mbox{for even }\vspace{1 mm}\\
\frac{n}{4} + \frac{3}{4n} & \mbox{for odd }
\end{array} \right. \label{eq:majw_up}

\frac{\nav_W(I)}{\maj_W(I)} &=& \frac{\sum_{i=1}^k n_if_i}{2(\sum_{i=1}^{k-1}n_if_i + qf_k) + \left (\lceil \frac{n}{2} \rceil - \lfloor \frac{n}{2} \rfloor \right) f_k} \nonumber
\\
&=& \frac{n_k^2 + \sum_{i=1}^{k-1} n_i^2}{2qn_k + 2\sum_{i=1}^{k-1}n_i^2 + \left (\lceil \frac{n}{2} \rceil - \lfloor \frac{n}{2} \rfloor \right) n_k} \label{eq:majw_profit3}
2qn_k - 2(q-1)(n_k-1)-2 +  \left\lceil \frac{n}{2} \right\rceil - \left\lfloor \frac{n}{2} \right\rfloor = 2(n_k + q -2) + \left\lceil \frac{n}{2} \right\rceil - \left\lfloor \frac{n}{2} \right\rfloor
\frac{\nav_W(I)}{\maj_W(I)} &\leq& \frac{\lceil \frac{n}{2} \rceil^2 + \lfloor \frac{n}{2}\rfloor}{2\lfloor \frac{n}{2}\rfloor  + \lceil \frac{n}{2} \rceil - \lfloor \frac{n}{2} \rfloor} \nonumber \\
& = & \left\{ \begin{array}{ll}
\frac{n}{4} + \frac{1}{2} & \mbox{for even }\\
\frac{n}{4} + 1 - \frac{1}{4n} & \mbox{for odd }
\end{array} \right. \label{eq:majw_up2}
\maj_W(E_n) = n-6+\frac{16}{n} \geq \left(\frac{n}{2}-3+\frac{8}{n}\right)\eag_W(E_n).W'_n = a_1,a_2,\ldots,a_{\lceil\frac{n}{2}\rceil},a_0,a_0,\ldots,a_0,\eag_W(W_n) \geq \frac{n}{4}\maj_W(W_n).

These two families of sequences show that \maj~ and \eag~ are incomparable under relative worst order analysis.

\end{proof}










\section{Conclusion and Future Work}
The frequent items problem for streaming was considered as an online
problem. Three deterministic algorithms, \nav, \maj, and \eag were
compared using three different quality measures: competitive analysis,
relative worst order analysis, and relative worst order ratio. According
to competitive analysis, \nav is the better algorithm and \maj and
\eag are equivalent. According to relative interval analysis, \nav
and \maj are equally good and both are better than \eag. According
to relative worst order analysis, \nav and \opt are equally good
and better than \maj and \eag, which are incomparable.

All three analysis techniques studied here are worst case measures.
According to both competitive analysis and relative worst order analysis,
\nav is the best possible online algorithm, and according the
relative worst order analysis, it is as good as \maj and better than
\eag. This is a consequence of \nav being very adaptive and, as a result,
good at avoiding the extreme poor performance cases.
Both \maj and \eag attempt to
keep the most frequent items in the buffer for longer
than their frequency would warrant. The heuristic approaches hurt
these algorithms in the worst case.

Relative interval analysis compares the algorithms on the same sequence
in a manner which, in addition to the worst case scenarios, also
takes the algorithms' best performance into account
to some extent. This makes \maj's sometimes superior performance visible,
whereas \eag, not being adaptive at all, does not benefit in the same way from
its best performance.
In some sense, \maj's behavior can be seen as swinging around the
behavior of \nav, with worse behavior on some sequences counter-acted
by correspondingly better behavior on other sequences.

Our conclusion is that purely worst behavior measures do not give
indicative results for this problem. Relative interval analysis does
better, and should possibly be supplemented by some expected case
analysis variant.
To that end, natural performance measures to consider would be
bijective and average analysis~\cite{Angelopoulos07}.
However, as the problem is stated in~\cite{Giannakopoulos12} and studied here,
the frequent items problem has an infinite universe from which the
items are drawn. Thus, these analysis techniques
cannot be applied directly to the problem in any meaningful way.
Depending on applications, it could be realistic to assume a finite universe.
This might give different results than those obtained here, and might allow
the problem to be studied using other measures, giving results dependent on the size of the universe.
Another natural extension of this work is to consider multiple buffers, which
also allows for a richer collection of algorithms~\cite{Berinde09},
or more complicated, not necessarily discrete, objective
functions~\cite{Cohen06}.



\bibliography{ref_stream}
\bibliographystyle{plain}

\end{document}
