\documentclass [11pt] {article} 

\usepackage{fullpage}
\usepackage[pdftex]{graphicx}

\usepackage{color}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{amsfonts}
\usepackage{enumitem}



\usepackage[english]{babel}

\usepackage{multirow}
\usepackage{rotating}



\usepackage{epstopdf}

\begin{document}


\newtheorem{theorem}{Theorem}[section]
\newtheorem{lemma}{Lemma}[section]
\newtheorem{corollary}{Corollary}[section]
\newtheorem{claim}{Claim}[section]
\newtheorem{proposition}{Proposition}[section]
\newtheorem{definition}{Definition}[section]
\newtheorem{fact}{Fact}[section]
\newtheorem{example}{Example}[section]





\newcommand{\cA}{{\cal A}}
\newcommand{\cP}{{\cal P}}
\newcommand{\cC}{{\cal C}}
\newcommand{\cG}{{\cal G}}
\newcommand{\cN}{{\cal N}}
\newcommand{\cU}{{\cal U}}
\newcommand{\cT}{{\cal T}}
\newcommand{\cS}{{\cal S}}
\newcommand{\cL}{{\cal L}}
\newcommand{\cV}{{\cal V}}
\newcommand{\loc}{{\cal LOCAL}}
\newcommand{\cM}{{\cal M}}


\newcommand{\f}[4][0pt]{\begin{list}{#2}{\setlength{\leftmargin}{#3 em}\addtolength{\leftmargin}{#3 em}\addtolength{\leftmargin}{1 em}\setlength{\labelsep}{#3 em}\addtolength{\labelsep}{#3 em}
 \setlength{\labelwidth}{20pt}
 \if!#1!\else\addtolength{\leftmargin}{#1}\fi \setlength{\topsep}{2pt}\setlength{\partopsep}{0pt}\if!#1!\else\setlength{\itemindent}{-#1}\fi }\item  #4\end{list}}

\newcommand{\qed}{\hfill  \smallbreak}
\newenvironment{proof}[1][Proof]
{\par\noindent{\bf #1:} }{\hspace*{\fill}\nolinebreak{}\bigskip\par}

\newcommand{\view}{\mathcal{V}}
\newcommand{\agent}{\lambda}
\newcommand{\lab}{\alpha}
\newcommand{\labels}{\mathcal{L}}
\newcommand{\lista}{\mathcal{Q}}
\newcommand{\code}{\xi}
\newcommand{\home}{h}
\newcommand{\routebegin}{b}
\newcommand{\routeend}{d}
\newcommand{\cR}{\mathcal{R}}
\newcommand{\hist}{\mathcal{H}}
\newcommand{\cQ}{\mathcal{Q}}

\newcommand{\ints}{\mathbb{N}}
\newcommand{\algorithmCL}{{\tt Choose\textup{-}Leader}}
\newcommand{\algorithmUL}{{\tt Update\textup{-}Label}}
\newcommand{\algorithmLE}{{\tt Leader\textup{-}Election}}
\newcommand{\algorithmInit}{{\tt Initialization}}

\newcommand{\last}{\textup{last}}
\newcommand{\depth}{3(n-1)}
\newcommand{\len}{\ell}
\newcommand{\conditionEC}{\textup{EC}}





\title{{\bf  How to Meet Asynchronously at Polynomial Cost}\thanks{A preliminary version of this paper appeared in
Proc. 32nd Annual ACM Symposium on Principles of Distributed Computing (PODC 2013).} }

\author{
Yoann Dieudonn\'{e}\thanks{
MIS, Universit\'{e} de Picardie  Jules  Verne Amiens,  France. E-mail:  {\tt yoann.dieudonne@u-picardie.fr}}
 \and Andrzej Pelc\thanks{
 D\'epartement d'informatique, Universit\'e du Qu\'ebec en Outaouais, Gatineau,
Qu\'ebec J8X 3X7, Canada. {\tt pelc@uqo.ca}. Partially supported by NSERC discovery grant 
and by the Research Chair in Distributed Computing at the
Universit\'e du Qu\'ebec en Outaouais.}
\and  Vincent Villain\thanks{
MIS, Universit\'{e} de Picardie  Jules  Verne Amiens,  France. E-mail: {\tt vincent.villain@u-picardie.fr}}
}




\maketitle

\thispagestyle{empty}


\begin{abstract}

Two mobile agents starting at different nodes of an unknown network have to meet.
This task is known in the literature as {\em rendezvous}.
Each agent has a different label which is a positive integer known to it, but unknown to the other agent.
Agents move in an asynchronous way: the speed
of agents may vary and is controlled by an adversary.  
The cost of a rendezvous algorithm is the total number of edge traversals by both agents until their meeting.
The only previous deterministic algorithm solving this problem has cost exponential in the size of the graph and in the larger label.
In this paper we present a deterministic rendezvous algorithm with cost {\em polynomial} in the size of the graph and in the {\em length}
of the {\em smaller} label. Hence we decrease the cost exponentially in the size of the graph and doubly exponentially in the labels of agents.

As an application of our rendezvous algorithm we solve several fundamental problems involving teams of unknown size larger than 1 of labeled agents
moving asynchronously in unknown networks. Among them are the following problems: {\tt team size}, in which every agent has to find the total
number of agents, {\tt leader election}, in which all agents have to output the label of a single agent, {\tt perfect renaming} in which all agents
have to adopt new different labels from the set , where  is the number of agents, and {\tt gossiping}, in which each agent has initially a piece of information (value) and all agents have to output all the values. Using our rendezvous algorithm we solve all these problems at cost polynomial in the size of the graph and in the smallest length of all labels of participating agents. 

\vspace*{1cm}

{\bf keywords:} asynchronous mobile agents, network, rendezvous, deterministic algorithm, leader election, renaming, gossiping

\vspace*{3cm}
\end{abstract}

\pagebreak
\section{Introduction} \label{sec:intro}


\noindent
{\bf The background.}
Two mobile agents, starting at different nodes of a network, possibly at different times, have to meet.
This basic task,  known  as {\em rendezvous}, has been thoroughly studied in the literature.
It even has applications in human and animal interaction, e.g., when agents are people that have to meet in a city whose streets form a network,
or migratory birds have to gather at one destination flying in from different places.
In computer science applications,
mobile agents usually represent software agents in computer networks, or mobile robots, if the network is a labyrinth or is composed of corridors in a building.
The reason to meet may be to exchange data previously collected by the agents,
or to coordinate some future task, such as network maintenance or finding a map of the network.

In this paper we consider the rendezvous problem under a very weak scenario which assumes little knowledge and control power of the agents.
This makes our solutions more widely applicable, but significantly increases the difficulty of meeting. More specifically, agents do not have any a priori information about the network, they do not know its topology or any bounds on parameters such as the diameter or the size. 
We seek rendezvous algorithms that do not
rely on the knowledge of node labels, and can work in anonymous networks as well  (cf. \cite{alpern02b}). 
The importance of designing such algorithms
is motivated by the fact that, even when nodes are equipped with distinct labels, agents may be unable to perceive them
because of limited sensory capabilities, 
or nodes may refuse to reveal their labels, e.g., due to security or privacy reasons.
Note that if nodes had distinct labels that can be perceived by the agents, then agents might explore the network and meet in the smallest node, hence rendezvous would reduce to exploration.
Agents have distinct labels, which are positive integers and each agent knows its own label, but not the label of the other agent. 
The label of the agent is the only a priori initial input to its algorithm. During navigation agents gain knowledge of the visited part of the network:
when an agent enters a node, it learns the port number by which it enters and the degree of the node.
The main difficulty of the scenario is the asynchronous way in which agents move: the speed of the agents may vary, may be different for each of them, and is totally controlled by an adversary.  This feature of the model is also what makes it more realistic than the synchronous scenario: in practical applications the speed of agents depends on various factors
that are beyond their control, such as congestion in different parts of the network or mechanical characteristics in the case of mobile robots.
Notice that in the asynchronous scenario we cannot require that agents meet in a node: the adversary can prevent this even in the two-node graph.
Thus, similarly as in previous papers on asynchronous rendezvous \cite{BCGIL,CCGL,CLP,DGKKPV,GP}, we allow the meeting either in
a node or inside an edge. 
The cost of a rendezvous algorithm is the total number of edge traversals by both agents until their
meeting.

\noindent
{\bf Our results.} The main result of this paper is a deterministic rendezvous algorithm, working in arbitrary unknown networks and whose cost is polynomial in the size of the network and in the {\em length} of the {\em smaller} label (i.e. in the logarithm of this label).
The only previous algorithm solving the asynchronous rendezvous problem \cite{CLP} is exponential in the size of the network and in the larger label.
Hence we decrease the cost exponentially in the size of the network and doubly exponentially in the labels of agents.

As an application of our rendezvous algorithm we solve several fundamental problems involving teams of unknown size larger than 1 of labeled agents
moving asynchronously in unknown networks. Among them are the following problems: {\tt team size}, in which every agent has to find the total
number of agents, {\tt leader election}, in which all agents have to output the label of a single agent, {\tt perfect renaming} in which all agents
have to adopt new different labels from the set , where  is the number of agents, and {\tt gossiping}, in which each agent has initially a piece of information (value) and all agents have to output all the values. Using our rendezvous algorithm we solve all these problems at cost
(total number of edge traversals by all agents) polynomial in the size of the graph and in the smallest length of all labels of participating agents.
To the best of our knowledge this is the first solution of these problems for asynchronous mobile agents, even regardless of the cost.

 




\noindent
{\bf The model.}
The network is modeled as a finite simple undirected connected graph (without self-loops or multiple edges), referred to hereafter as a graph. 
Nodes are unlabeled, but
edges incident to a node  have distinct labels in 
, where  is the degree of . Thus every undirected
edge  has two labels, which are called its {\em port numbers} at 
and at . Port numbering is {\em local}, i.e., there is no relation between
port numbers at  and at . Note that in the absence of port numbers, edges incident to a node
would be undistinguishable for agents and thus gathering would be often impossible, 
as the adversary could prevent an agent from taking some edge incident to the current node. 
{By  we denote the neighbor of  linked to it by the edge with port number  at .}

In order to avoid crossings of non-incident edges, we consider an embedding of the underlying graph in the
three-dimensional Euclidean space, with nodes of the graph being points of the
space and edges being
pairwise disjoint line segments joining them.
 Agents are modeled
as points moving inside this embedding. (This embedding is only for the clarity of presentation; in fact crossings of non-incident edges
would make rendezvous simpler, as agents traversing distinct edges could sometimes meet accidentally at the crossing point.)


There are two agents that start from different nodes of the graph  and  traverse its edges.
They cannot mark visited nodes or traversed edges in any way.
Agents have distinct labels which are strictly positive integers. Each agent knows only its own label which is an initial input
to its deterministic algorithm.
Agents do not  know the topology of the graph or any bound on its size. They can, however, acquire knowledge about the network:
When an agent enters a node, it learns its degree and the port of entry. We assume that the memory of the agents is unbounded: from the computational point of view they are modeled as 
Turing machines. 

Agents navigate in the graph in an asynchronous way which is formalized by an adversarial model used in 
\cite{BCGIL,CCGL,CLP,DGKKPV,GP} and described below.
Two important notions used to specify movements of agents are the {\em route} of the agent and its {\em walk}.
Intuitively, the agent chooses the route {\em where} it moves and the adversary describes the walk on this 
route, deciding {\em how} the agent  moves. More precisely,  these notions are defined as follows.
The adversary initially places an agent at some node of the graph.
The route is chosen by the agent and is defined as follows. 
The agent chooses one of the available ports at the current node. 
After getting to the other end of the corresponding edge, the agent chooses one of the available ports at this node
or decides to stay at this node. It does so on the basis of all information currently available to it.
The resulting route of the agent is the corresponding sequence of edges ,
which is a (not necessarily simple) path in the graph. 

We now describe the walk  of an agent on its route. Let  be the route of an agent. Let .
Let , where , be an increasing sequence of reals, chosen by the adversary, 
that represent points in time. Let  be any continuous function, chosen by the adversary, such that  and . For any , we define . 
The interpretation of the walk  is as follows: at time  the agent
is at the point  of its route.  This general definition of the walk and the fact that (as opposed to the route) it is designed by the adversary,
are a way to formalize the asynchronous characteristics of the process.  The movement of the agent can be
at arbitrary speed, the adversary may sometimes stop the agent or move it back and forth, as long as the walk 
in each edge of the route is continuous and covers all of it.
This definition makes the adversary very powerful,
and consequently agents have little control on how they move. This makes a meeting between agents hard to achieve.
Agents with routes  and  and with walks  and  meet at time ,
if points  and  are identical. 
A meeting is guaranteed for routes  and ,
if the agents using these routes meet at some time , regardless of the walks chosen by the adversary.







\noindent{\bf Related work.}
In most papers on rendezvous a synchronous scenario was assumed, in which agents navigate in the graph in synchronous rounds.
An extensive survey of  randomized rendezvous in various scenarios can be found in
\cite{alpern02b}, cf. also  \cite{alpern95a,alpern02a,alpern99,anderson90}. 
Deterministic rendezvous in networks has been surveyed in \cite{Pe}.
Several authors
considered the geometric scenario (rendezvous in an interval of the real line, see, e.g.,  \cite{baston01},
or in the plane, see, e.g., \cite{anderson98a,anderson98b}).
Rendezvous of  more than two agents, often called gathering, has been studied, e.g., 
in \cite{DiPe,DPP,lim96,YY}. In \cite{DiPe} agents were anonymous, while in~\cite{YY} the authors considered 
gathering many agents with unique labels. Gathering many labeled agents in the presence of Byzantine agents was studied in \cite{DPP}. 
The problem was also studied in the context of multiple robot systems, cf.
\cite{CP05,fpsw}, and fault tolerant gathering of robots in the plane was studied, e.g., in \cite{AP06,CP08}. 

For the deterministic setting a lot of effort has been dedicated to the study of the feasibility of rendezvous, and to the time required to achieve this task, when feasible. For instance, deterministic rendezvous with agents equipped with tokens used to mark nodes was considered, e.g., in~\cite{KKSS}. Deterministic rendezvous of two agents that cannot mark nodes but have unique labels was discussed in {\cite{DFKP,KM,TSZ14}}.
These papers are concerned with the time of synchronous rendezvous in arbitrary
graphs. In \cite{DFKP} the authors show a rendezvous algorithm polynomial in the size of the graph, in the length of the shorter
label and in the delay between the starting time of the agents. In {\cite{KM,TSZ14}} rendezvous time is polynomial in the first two of these parameters and independent of the delay.

Memory required by two anonymous agents to achieve deterministic rendezvous has been studied in \cite{FP2} for trees and in  \cite{CKP} for general graphs.
Memory needed for randomized rendezvous in the ring is discussed, e.g., {in~\cite{KKPM11}}.

Asynchronous rendezvous of two agents in a network has been studied in \cite{BCGIL,CCGL,CLP,DGKKPV,GP}. The model used in the present paper has been
introduced in \cite{DGKKPV}. In this paper  the authors investigated the cost of rendezvous in the infinite line and in the ring. They also proposed a rendezvous
algorithm for an arbitrary graph with a known upper bound on the size of the graph. This assumption was subsequently removed in \cite{CLP}, but both in
 \cite{DGKKPV} and in  \cite{CLP} the cost of rendezvous was exponential in the size of the graph and in the larger label. In \cite{GP} asynchronous rendezvous was studied for anonymous agents and the cost was again exponential. The only asynchronous rendezvous algorithms at polynomial cost were
 presented in \cite{BCGIL,CCGL}, but in these papers authors restricted attention to infinite multidimensional grids and they used 
 the powerful assumption that each agent knows its starting coordinates. (The cost in this case is polynomial in the initial distance).
 
 A different asynchronous scenario was studied in \cite{CFPS,fpsw} for the plane. In these papers the authors assumed that agents are memoryless, but they can observe the environment and make navigation decisions based on these observations.
 
 The four problems that we solve in the context of asynchronous mobile agents as an application of our rendezvous algorithm, are
 widely researched tasks in distributed computing, under many scenarios. Counting the number of agents is a basic task, cf. \cite{FP3},
 as many mobile agents algorithms depend on this knowledge.  Leader election, cf. \cite{Ly},  is a fundamental problem in distributed
 computing. Renaming  was introduced in \cite{ABDKPR} and further studied by many authors. Gossiping, also called all-to-all communication,
 is one of the basic primitives in network algorithms, cf. \cite{FL}. 





\section{Preliminaries}\label{prelim}

Throughout the paper, 
the number of nodes of a graph is called its size.
In this section we {present two procedures}, that will be used as building blocks in our algorithms. 
The aim of both of them is graph exploration, i.e., visiting all nodes and traversing all edges of the graph by a single agent. 
The first procedure, based on universal exploration sequences (UXS), is a corollary of the  result of Reingold \cite{Re}. Given any positive integer , it allows the agent to traverse all edges of any graph of size at most ,
starting from any node of this graph, using  edge traversals, where  is some polynomial. (The original procedure of Reingold only visits all nodes, but it can be transformed to traverse all edges by visiting all neighbors of each visited node before going to the next node.) After entering a node of degree  by some port ,
the agent can compute the port  by which it has to exit; more precisely , where  is the corresponding term of the UXS.

A {\em trajectory} is a sequence of nodes of a graph, in which each node is adjacent to the preceding one. (Hence it is a sequence of nodes visited following a route.)
Given any starting node ,  we denote by  the trajectory obtained by Reingold's procedure. The procedure can be applied in any graph starting at any node, giving
some trajectory. We say that  the agent {\em follows} a trajectory if it executes the above procedure used to construct it.
This trajectory will be called {\em integral}, if the corresponding route covers all edges of the graph. By definition, the trajectory  is integral if it is
obtained by Reingold's procedure applied in any graph of size at most  starting at any node~. 

{The second procedure, derived from \cite{DP} and adapted here to our needs, allows an agent to traverse all edges {and visit all nodes} of any graph of size at most  provided that there is a {unique token located on an {\em extended edge}  (for some adjacent nodes  and ) and authorized to move arbitrarily on it.
An extended edge is defined as the edge  augmented by nodes  and }. (It is well known that a terminating exploration even of all anonymous rings of unknown size by a single agent without a token is impossible.) 
In our applications the roles of the token and of the exploring agent will be played by agents. We call this procedure , for {\em exploration with a semi-stationary token}, {as the token always remains on the same extended edge (even if it can move arbitrarily inside it)}. We first describe the procedure before showing its validity as well as its polynomial complexity with respect to the size of the graph.}


{
The following notion will be crucial for our considerations. Let  be a positive integer.  An application of  to a graph  at some node  is called {\em clean}, if all nodes in this application are of degree at most .}

\vspace*{0.2cm}
\noindent
{{\bf Procedure ESST}}

{The algorithm proceeds in {phases .} In any phase , the agent first applies 

at the node  in which it started this phase.
Let  be the trajectory  ( and ). Call this trajectory the trunc of this phase.
If it is not clean, or if no token is seen, the agent aborts phase  and starts phase {}. Otherwise, the agent backtracks to , and applies 

at each node  of the trunc, interrupting a given execution of  when it sees a token, every time recording the {\em code} of the path from  to this token. 
This code is defined as the sequence of ports
encountered while walking along the path.
(If, for some , the token is at , then this code is an empty sequence.) After seeing a token, the agent backtracks to , goes
to  and starts executing . For each node  of the trunc, if at the end of  either no token is seen during the execution of , or the agent has recorded at least {} different codes in phase , then
the agent aborts phase  and starts phase {} (in the special case where the agent decides to abort phase  while traversing an edge, phase {} starts at the end of this edge traversal). Otherwise, upon completion of phase , it stops as soon as it is at a node.}

\vspace*{0.2cm}

{The remaining part of this section is devoted to the proof that Procedure ESST is correct and works at polynomial cost. Again, this result uses  ideas from \cite{DP}: we include it for the sake of completeness.}

\begin{lemma}\label{lemma}
{Let  be positive integers, and let  be a graph of size . Let  be the trajectory in  resulting from the execution of , for some node  of . If trajectory  is clean, then  contains at least  different nodes.}
\end{lemma}

\begin{proof}
{Let  with  and .
Suppose for contradiction that there are fewer than  different nodes in , and let  be the set of these nodes. Consider any node .
A port  at node  is called {\em occupied}, if for some index , we have  and either  or   .
Otherwise it is called {\em free}.
Let  be the maximum number of free ports at any node of .
Construct the following graph . The set of nodes of  is , where all  are distinct and do not belong to . 
The set of edges of the graph  consists of all edges  from  augmented by the following set of edges. Consider all nodes 
in the order of their first appearance in the sequence . Let  be the free ports at , listed in increasing order. We add edges  
with the following ports: the port at  corresponding to the edge   is , and the port at  corresponding to the edge   is the smallest port not yet used
at this node. This completes the construction of graph~.}

{Since trajectory  is clean, we have . Since the size of  is smaller than , the graph  has fewer than  nodes.
Since the size of  is smaller than  (in view of ), at least one port at some node of  is free, and consequently .
It follows that some nodes  were added to  in order to construct .
Nodes  are not terms of the trajectory  in . This is a contradiction with the fact that  allows to visit all nodes of any graph  of size at most  from any node  of .}
\end{proof}

{We are now ready to prove the following theorem.}

\begin{theorem}
\label{theo:est}
{Procedure  terminates in every graph  after a number of steps polynomial in the size of . Upon its termination, all {edges of  are traversed 
by the agent}.}
\end{theorem}

\begin{proof}
{Let  be the size of the graph .
First observe that the procedure terminates at the latest after completion of phase {}. Indeed in this phase, every trajectory , for any node  of , must be clean.
{Moreover, by the end of each trajectory , for any node  of the trunc, the token must be met. Finally,} the number of possible codes recorded by the agent cannot exceed { (there are at most  different codes in a graph of size , as there are at most  different codes for each node, {depending on whether the token is at one of the nodes or inside the edge corresponding to the extended edge on which it is located)} and thus at most  codes in phase .}}

{Let us estimate the number of edge traversals executed by the agent in some phase  from some node . The agent walks at most three times along the trunc corresponding to the trajectory , and at most twice along each trajectory  from each node  of the trunc of phase . This gives a total of at most  edge traversals, which is polynomial in .}
{Hence the total number of edge traversals made by the agent by the end of phase  is upper bounded by {, which is polynomial in .}}

{It remains to show that if the agent stops upon completion of some phase , then all {edges are traversed}. Consider this phase .  By the description of the procedure, the main trajectory, corresponding to the trunc of phase , must be clean, the token must be seen
in each trajectory , for each node  of the trunc, made in this phase, and the number of codes recorded by the agent cannot exceed {}.
Suppose by contradiction that .
By Lemma \ref{lemma}, the set of distinct nodes visited during the main trajectory  in phase  is at least .
On the other hand, by the description of the procedure, the agent has recorded at most {} different codes.}
{Hence, there are  distinct nodes ,  and  visited during the main trajectory  and at least one code  such that  was recorded from each of these nodes (among  other possible codes from these nodes).}

{However, a given code cannot be recorded from more than two distinct nodes as otherwise that would imply that there is more than one token in  or there is a node  in the graph, for which edges to two of its neighbors correspond to the same port number at , which is impossible. Hence, ,  and  cannot be all distinct, which is a contradiction.}

{This implies that , and consequently all {edges of  are traversed} during the main trajectory . It follows that upon completion of phase  all {edges of  are traversed}.}
\end{proof}

{Note that the fact that all the edges of a graph  are traversed during an execution of procedure  implies that all nodes of  are visited.}
We denote by  the maximum number of edge traversals in an execution of the procedure 
in a graph of size at most .

{To complete this section, let us introduce some more notation.} For a positive integer , by  we denote the length of its binary representation, called the length of . Hence . All logarithms are with base 2.
For two agents, we say that the agent with larger (smaller) label is larger (resp. smaller). For any trajectory , we denote by   the reverse trajectory . For two trajectories  and  we denote by  the trajectory 
. For any trajectory , for which  and for any positive integer , we define  to be , 
with  copies of .
For any trajectory  we define  to be the number of {edge traversals} in .

\section{The rendezvous algorithm}

In this section we describe and analyze our rendezvous algorithm working at polynomial cost. Its high-level idea is based on the following observation.
If one agent follows an integral trajectory during some time interval, then it must either meet the other agent or this other agent must perform at least one complete edge traversal during this time
interval, i.e., it must make {\em progress}.  
A naive use of this observation leads to the following simple algorithm: an agent with label  starting at node  of a graph of size  follows the trajectory 
and stops.
Indeed, in this case the number of integral trajectories  performed by the larger agent is larger than the number of edges traversed by the smaller agent and consequently, if they have not met before,  the larger agent must meet the smaller one after the smaller agent stops, because the larger agent will still perform at least one entire trajectory afterwards.
However,  this simple algorithm has two major drawbacks.
First, it requires knowledge of  (or of an upper bound on it) and second, it is exponential in , while we want an algorithm {\em polylogarithmic} in . Hence the above observation has to be used in a much more subtle way. Our algorithm constructs a trajectory for each agent, polynomial in the size of the graph and polylogarithmic in the shorter label, i.e., polynomial in its length, which has the following {\em synchronization} property that holds in a graph of arbitrary unknown size. 
When one of the agents has already followed some part of its trajectory, it has either met the other agent, or this other agent must have completed
some other related part of its trajectory. (In a way, if the meeting has not yet occurred, the other agent has been ``pushed'' to execute some part of its route.) The trajectories are designed in such a way
that, unless a meeting has already occurred, the agents are forced to follow in the same time interval such parts of their trajectories that meeting is inevitable. A design satisfying this
synchronization property is difficult due to the arbitrary behavior of the adversary and is the main technical challenge of the paper.

\subsection{Formulation of the algorithm}

We first define several trajectories based on trajectories . Each trajectory
is defined using a starting node  and a parameter . Notice that, similarly as the basic trajectory , each of these trajectories (of increasing complexity)
can be defined in any graph, starting from any node~: {in particular, for a fixed parameter , a given trajectory always traverses the same number of edges, regardless of the graph and of the starting node}.

\begin{definition}
The trajectory  is the sequence of nodes  .
\end{definition}

{In other terms, trajectory  consists in following trajectory  and then backtracking to node  by following the reverse path }.

\begin{definition}
\label{def:Q}
The trajectory  is the sequence of nodes  {(refer to Figure~\ref{fig:Q})}.
\end{definition}

\begin{figure*}[httb!]
	\begin{center}
	\includegraphics[width=0.3\textwidth]{def321.pdf}
	\caption{{A schematic representation of trajectory  which is made up of a sequence of consecutive trajectories  from  to .}}
	\label{fig:Q}
	\end{center}
\end{figure*}

\begin{definition}
\label{def:Y}
Let . Let  We define
the trajectory  as . 
\end{definition}

{In other terms, trajectory  consists in following trajectory  and then backtracking to node  by following the reverse path . A schematic representation of  is depicted in Figure~\ref{fig:Y'}.}

\begin{figure*}[httb!]
	\begin{center}
	\includegraphics[width=0.5\textwidth]{def331.pdf}
	\caption{{A schematic representation of trajectory  which consists in following trajectory  with the following insertions: for all , before going from node  to  the agent follows trajectory .}}
	\label{fig:Y'}
	\end{center}
\end{figure*}

\begin{definition}
\label{def:Z}
The trajectory  is the sequence of nodes  {(refer to Figure~\ref{fig:Z})}.
\end{definition}

\begin{figure*}[httb!]
	\begin{center}
	\includegraphics[width=0.3\textwidth]{def322.pdf}
	\caption{{A schematic representation of trajectory  which is made up of a sequence of consecutive trajectories  from  to .}}
	\label{fig:Z}
	\end{center}
\end{figure*}


\begin{definition}
\label{def:A}
Let . Let  We define
the trajectory  as . 
\end{definition}
\newpage
{In other terms, trajectory  consists in following trajectory  and then backtracking to node  by following the reverse path . A schematic representation of  is depicted in Figure~\ref{fig:A'}.}

\begin{figure*}[httb!]
	\begin{center}
	\includegraphics[width=0.5\textwidth]{def332.pdf}
	\caption{{A schematic representation of trajectory  which consists in following trajectory  with the following insertions: for all , before going from node  to  the agent follows trajectory .}}
	\label{fig:A'}
	\end{center}
\end{figure*}


{If the node  is clear from the context, we will sometimes omit it, thus writing  instead of , etc.}

{In the following definition,  corresponds to the number of edges that are traversed by following trajectory  for any node .} 
\begin{definition}
\label{def:B}
The trajectory  is the sequence of nodes . 
\end{definition}

{Below is the pseudocode describing how to follow trajectory .}

\begin{center}
\fbox{
\begin{minipage}{0.4\columnwidth}\small
{\bf for}  {\bf from} 1 {\bf to} \\
\hspace*{0.8cm}Follow trajectory \\
{\bf end for}
\end{minipage}
}
\end{center} 

{In the following definition, the value  (resp. ) corresponds to the number of edges that are traversed by following trajectory  (resp. ) for any node .}

\begin{definition}
\label{def:K}
The trajectory  is the sequence of nodes . 
\end{definition}

{Below is the pseudocode describing how to follow trajectory .}

\begin{center}
\fbox{
\begin{minipage}{0.4\columnwidth}\small
{\bf for}  {\bf from} 1 {\bf to} \\
\hspace*{0.8cm}Follow trajectory \\
{\bf end for}
\end{minipage}
}
\end{center} 

{In the following definition, the value  corresponds to the number of edges that are traversed by following trajectory  for any node .}

\begin{definition}
\label{def:ome}
The trajectory  is the sequence of nodes .
\end{definition}

{Below is the pseudocode describing how to follow trajectory .}

\begin{center}
\fbox{
\begin{minipage}{0.4\columnwidth}\small
{\bf for}  {\bf from} 1 {\bf to} \\
\hspace*{0.8cm}Follow trajectory \\
{\bf end for}
\end{minipage}
}
\end{center} 


{Using the above defined trajectories we are now ready to describe Algorithm RV-asynch-poly executed by an agent with label  in an arbitrary graph. Below we give the pseudocode of this algorithm and then the main intuition that is behind it.}



The agent first modifies its label. If  is the binary representation of , define the {\em modified label} of the agent to be the sequence .  
Note that, for any  and , the sequence  is never a prefix of .
Also,  for . 

\vspace*{0.5cm}

\begin{center}
\fbox{
\begin{minipage}{11cm}



\noindent
{\bf Algorithm RV-asynch-poly}.

\vspace*{0.5cm}

Let  be the binary representation of the label  of the agent and let . Let  be the starting node of the agent.

\vspace*{0.5cm}

\noindent
Execute until rendezvous. 



\noindent
;\\
;\\
{\bf repeat}\\
\hspace*{0.5cm}{\bf  while}   {\bf do} \\
\hspace*{1cm}{\bf if}  {\bf then} follow the trajectory \\
\hspace*{1cm}{\bf else} follow the trajectory \\
\hspace*{1cm}{\bf if}  {\bf then} follow the trajectory \\
\hspace*{1cm}{\bf else} follow the trajectory \\
\hspace*{1cm}\\
\hspace*{0.5cm}\\
\hspace*{0.5cm}

\end{minipage}
}
\end{center}

{The main idea of the above formulated algorithm is the following. In order to guarantee rendezvous, symmetry in the actions of the agents must be broken.
 Since agents have different transformed labels, this can be done by designing the algorithm so that each agent processes consecutive bits of its transformed label, acting differently when the current bit is 0 and when it is 1.  (The way of processing each bit is described in the ``while'' loop.) The aim is to force rendezvous when each agent processes the bit corresponding to the position where their transformed labels {first} differ. This approach requires overcoming two major difficulties. The first is that, due to the behavior of the asynchronous adversary,
 agents may execute corresponding bits of their transformed labels at different times. This problem is solved in our algorithm by using trajectories of type  and  (refer to Definitions~\ref{def:K} and~\ref{def:ome}), in order to synchronize the agents. These trajectories have the following role in this synchronization effort: for , trajectories  and  executed by one agent push the other agent to proceed in its execution or otherwise rendezvous is accomplished. The joint application of these two specific trajectories {ends up forcing} the agents to push each other in such a way that at some point they process almost simultaneously the bit on which they differ.}

{ The second difficulty is to orchestrate rendezvous after the first difficulty has been overcome, i.e., when each agent 
 processes this bit. This is done by making use of trajectories of type  and  (refer to Definitions~\ref{def:A} and~\ref{def:B}). Our algorithm is designed in such a way that processing bit  consists in following twice a trajectory of type  (for some parameters), while processing bit  consists in following twice a trajectory of type  (for some parameters). This choice in the design stems from the desire to exploit the following feature: if two agents  and  simultaneously start to follow respectively trajectory  and  (for any  and for any nodes  and ) the rendezvous must occur by the time an agent terminates its trajectory first. Indeed, this is the case if  is finished before , as  consists in repeating , while  allows agent  to follow  at least once from every node  of the graph: roughly speaking, agent  ends up ''catching'' agent .
Otherwise (when  is finished by the time  is finished), this is also the case, as  consists in repeating the trajectory , which is integral, more times than there are edges to traverse when following : roughly speaking, agent  ends up ''catching'' agent .}


{Of course, the occurrence of the kind of situation described above is ideal. However, we actually ensure only the occurence of a more general situation in which trajectories  and  may be followed from starting times that are "slightly" different and for a parameter  that may also be different for each of them. Hence, to handle this, the algorithm is enriched by additionnal technical ingredients that are necessary to guarantee correctness. (It is particularly for these technical reasons that trajectory  (resp. B) is repeated twice instead of only once when the processed bit corresponds to  (resp. 1) and that agents follow trajectory  or  instead of simply  or ).}


{We will show that the synchronization, and hence also rendezvous, always occurs soon enough to guarantee that every execution of the algorithm has necessarily a polynomial cost.}


\subsection{Proof of correctness and cost analysis}

We will use the following terminology refering to parts of the trajectory constructed by Algorithm RV-asynch-poly. The part before the start of  is called the {\em first piece}
and is denoted ,
the part between the end of  and the beginning of  is called the {\em second piece} and is denoted , etc. In general, the part  
 between the end of  and the beginning of  is called the th {\em  piece} and is denoted .
 The trajectory  between pieces  and , is called the th {\em fence}.
 
 Inside each piece, the trajectory  and the trajectory   are called {\em segments}. Each of the two trajectories  in the segment  and each of the two trajectories   in the segment   are called {\em atoms}. We denote by  the segment in the th piece corresponding to the bit  in .  Each trajectory
  is called a {\em border}. We denote by  the border between the segment  and the segment .
 
 We start with the following fact that will be often used in the sequel.
 
 \begin{lemma}\label{tunel}
 Suppose that agents  and  operate in a graph . Let  be a node of  and let  be a positive integer. If in some time interval  agent  keeps repeating the trajectory  and agent  follows at least one entire trajectory , then the agents must meet during time interval .
 The lemma remains true when  is replaced by .
 \end{lemma}
 
 \begin{proof}
 Let . By definition, . During the time interval  agent  follows the entire trajectory  at least once.
 If at the time when  starts following , agent  is following , then they have to meet before  finishes  because 
is on a reverse path with respect to . If at the time when  starts following , agent  is also following , then they are two cases to consider.

Case 1.  completes trajectory  before  or simultaneously.\\ In this case they must meet because  ``catches'' .

Case 2.   completes trajectory  before .\\ In this case agent  starts following trajectory  before  the time when  completes .
Hence agents must meet by the time  completes trajectory  because  is on a reverse path with respect to . 

For  instead of  the argument is similar.
 \end{proof}


The following five lemmas establish various synchronization properties concerning the execution of the algorithm by the agents. 
They show that, unless agents have already met before, if one agent executes some part of  
Algorithm RV-asynch-poly, then the other agent must execute some other related part of it. These lemmas show the interplay of pieces, fences, segments,
atoms and borders that are followed by each of the agents:
these trajectories are the milestones of synchronization. In all lemmas we
suppose that agents  and  execute Algorithm RV-asynch-poly in a graph of size , and we let  to be the length of the smaller of their modified labels.  

\begin{lemma}
\label{lem:1}
If the agents have not met before, then by the time one of the agents completes its  th fence, then the other agent must have completed its th piece.
\end{lemma}

\begin{proof}
Without loss of generality assume that agent  is the first to complete its th fence 
. When  completed its th fence , agent  must have completed its first piece , otherwise  and  must have met because the trajectory  contains more integral trajectories  than there are {edge traversals} in the trajectory . Indeed, according to Algorithm RV-asynch-poly, the number of {edge traversals} in  is bounded by , while according to Definitions~\ref{def:ome} and~\ref{def:K}, the number of integral trajectories  within  is equal to {}, which is larger than  since . 


When  completes its th piece , agent  must have completed its first fence . Suppose not. This implies
that  while agent  follows , agent  must follow
only its first fence  or a part of it. This fence consists of repeating the trajectory
. Agent  follows at some point the trajectory 
or the trajectory  in its th piece .
By Definitions \ref{def:A} and \ref{def:B}, agent  must have completed , for any node  of the graph,
and hence must have met , in view of Lemma \ref{tunel} which is a contradiction.

Similarly we prove that when  completes its th fence , agent  must have completed its second piece ,
and when  completes its th piece , agent  must have completed its second fence . 
In general, it follows by induction on  that when  completes its th fence , agent  must have completed its th piece .
\end{proof}



\begin{lemma}
\label{claim1}
Let  be the first agent to complete its th fence. If the agents have not met before, then during the time segment in which agent  follows its
th fence, agent  follows a trajectory included in {}, for some fixed  satisfying , where {} is the last atom of its th piece ,  is its th fence,
and {} is the first atom of its th piece .
This  will be called the index of agent .
\end{lemma}


\begin{proof}
Consider the time interval  during which agent  follows its th fence . If during this time interval agent  has not started any fence,
it would have to follow a trajectory included in a piece  for some , because  was the first agent to complete its th fence.
By Definition~\ref{def:ome}, the trajectory  contains more copies of the integral trajectory {} than there are edge traversals done by agent . 
Indeed, according to Algorithm RV-asynch-poly, the number of {edge traversals} in  is bounded by {}, which is at most  for , while the number of integral trajectories  in  is equal to .
Hence the agents would have met, which is a contradiction.

Hence agent  must have started some fence during the time interval . By Lemma~\ref{lem:1}, during the time interval  agent  must have started its
th fence  , for some . Moreover, during the time interval  agent  could not have followed the entire last atom {} 
of its th piece . Indeed, this would mean that during the time interval  agent  has 
entirely followed either the trajectory  or the trajectory .
In the first case, since ,
this would imply that during the time interval , agent  followed an entire trajectory ,
where  is the starting node of , for
, while  followed only all or a part of the trajectory   consisting of repetitions of .
{In view of Lemma~\ref{tunel},} this would force a meeting because, by Definition~\ref{def:B},
the trajectory , for  contains at least one trajectory  for every node  of the graph. In the second case, in view of , a meeting would be forced in a similar way, because the trajectory , also contains at least one trajectory  for every node  of the graph.

This shows that  agent  has started the last atom {} of its th piece  during the time interval . Using a similar argument we prove that agent  could not 
complete the first atom {} of  its th piece during the time interval . This completes the proof. 
\end{proof}




\begin{lemma}
\label{claim2}
Let  be the first agent to complete its th fence. If the agents have not met before, then by the time agent  completes its th fence,
agent  must have completed the last {atom } of its th piece, where  is the index of agent .
\end{lemma}

\begin{proof}
Suppose not. Then, in view of Lemma \ref{claim1}, during the time interval when agent  follows its th fence, the trajectory of  is included in {}. However, according to {Definitions~\ref{def:K} and~\ref{def:ome}}, the number of integral trajectories  in  is {at least} . Moreover, according to Algorithm RV-asynch-poly, the number of {edge traversals} in {} is less than . So, since  in view of Lemma~\ref{claim1}, the number of integral trajectories in  is larger than the number of {edge traversals} in {}. This would force a meeting. 
\end{proof}

{
\begin{lemma}
\label{claim3}
Let  be the first agent to complete its th fence. If the agents have not met before, then by the time agent  completes the first atom of its segment , agent  must have completed its th fence , where  is the index of agent .
\end{lemma}}
{
\begin{proof}
Suppose not. Then, in view of Lemma \ref{claim2}, during the time interval when agent  follows the first atom of its segment , the trajectory of  is included in . Since the trajectory  consists of repetitions of the trajectory  starting at the same node , and while following the first atom of  agent  followed at least one trajectory  for any node  of the graph (because  by Lemma \ref{claim1}), this would force a meeting in view of Lemma \ref{tunel}.
\end{proof}}

\begin{lemma}
\label{lem:four}
Let  be the first agent to complete its th fence. {Let  be the first time at which an agent finishes its th piece. If the agents do not meet by time , then
the following properties hold, for  denoting the index of agent }.
\begin{itemize}
\item {\bf Property 1.} Let  be the time when agent  completes 
a segment , if this segment exists. Let  be the time when agent  completes 
the border , if this border exists. Then .
\item {\bf Property 2.} Let  be the time when agent  completes a segment , if this segment exists.
Let  be the time when agent  completes 
the border , if this border exists. Then .
\item {\bf Property 3.}
 Let  be the time when agent  completes 
a border , if this border exists. Let  be the time when agent  completes 
the first atom of the segment , if this segment exists. Then .
 \item {\bf Property 4.}
Let  be the time when agent  completes a border , if this border exists.
Let  be the time when agent  completes 
the first atom of the segment , if this segment exists. Then . 
\end{itemize}
\end{lemma}

\begin{proof}
{Assume that the agents do not meet by time .}
Suppose, for contradiction, that at least one of the above 4 properties is not satisfied and let  be the smallest value of the index  for which one of these properties is not satisfied. We consider 4 cases.

{\bf Case~1.} Property~1 is false for . This implies that  completed its border  before  completed . Hence agent  has completed  while agent  was following 
. Indeed, if agent  completed  before agent  started , this would imply:
\begin{itemize}

\item if  then agent  started  before agent  has completed . Hence  had completed  before  completed . This would imply that Property~3 is not satisfied for , which contradicts the definition of . 

\item if  then agent  started  before  has completed its th fence . {This is a contradiction with Lemma \ref{claim3}}



\end{itemize}

Hence agent  has completed  while agent  was following 
. Similarly as before, agent  has also started following  while agent  was following . 

Hence agent  has followed the entire trajectory  while  was following . 
However, by Definition~\ref{def:K}, the trajectory  contains  integral trajectories . Moreover, according to Algorithm RV-asynch-poly, the number of {edge traversals} in trajectory  is equal to  which is at most  (recall that  by Lemma \ref{claim1}). Thus, this would force a meeting because the number of integral trajectories  in  is larger than the number of {edge traversals} in , which is a contradiction.  



{\bf Case~2.} Property 2 is false for . This implies that agent  completed  before agent  completed . Hence agent  completed  while agent  was following 
. Indeed, if agent  completed  before  started , this would imply:
\begin{itemize}
\item if  then agent  started  before agent  completed . Hence  had completed  before  completed . This would imply that Property~4 is not satisfied for , which contradicts the definition of . 

\item if  then agent  started  before  completed its th fence   which contradicts Lemma \ref{claim2}.
\end{itemize}
Hence agent  completed  while  was following . Similarly as before, agent  started  while  was
following .

Hence agent  has followed the entire trajectory  while  was following . 
However, by Definition~\ref{def:K}, the number of integral trajectories  (note that  is integral because  in view of Lemma \ref{claim1}) in  is  which is at least  because  in view of Lemma \ref{claim1}. Moreover, according to Algorithm RV-asynch-poly, the number of {edge traversals} in  is less than . Thus, this would force a meeting because the number of integral trajectories  in  is larger than the number of {edge traversals} in , which is a contradiction.  



{\bf Case~3.} Property~3 is false for . This implies that agent  completed the first atom of   before agent  completed . This implies that agent  completed the first atom of   while  was following . Indeed, otherwise agent  would have completed  before  completed  which would imply that Property 1 is false for . This
is impossible by Case 1.

Hence agent  completed the first atom of  while  was following .  For the same reasons agent  also started the first atom of  while  was following .  Then while  was following ,  agent  either followed entirely the trajectory  or followed entirely the trajectory .  Consequently, in view of Definitions ~\ref{def:A} and~\ref{def:B}, agent  must have followed trajectory  for every node  of the graph at least once  (because  by Lemma \ref{claim1}). Since  consists of repeating  for the same node ,  agents would meet in view of Lemma \ref{tunel}, which is a contradiction.

{\bf Case~4.} Property~4 is false for . This implies that agent  completed the first atom of   before agent  completed 
. This implies that agent  completed the first atom of   while  was following . Indeed, otherwise agent  would have completed before agent  completed  which would imply that Property 2 is false for . This
is impossible by Case 2.

Hence agent  completed the first atom of  while  was following  . For the same reasons agent  also started the first atom of   while  was following .  Then while  was following
, agent  either followed entirely the trajectory  or followed entirely the trajectory .  Consequently,  in view of Definitions ~\ref{def:A} and~\ref{def:B},  agent  must have followed trajectory  for every node  of the graph at least once (because   by Lemma \ref{claim1}). Since  consists of repeating  for the same node ,  agents would meet in view of Lemma \ref{tunel}, which is a contradiction.
\end{proof}
















\begin{theorem}\label{main}
There exists a polynomial , non decreasing in each variable, such that
if two agents with labels  and  execute Algorithm RV-asynch-poly in a graph of size , then their meeting is guaranteed by the time one of them performs  edge traversals. 
\end{theorem}

\begin{proof}
Let . Let  be the agent with label  and let  be the agent with label .
Let  be the modified label of agent  and let  be the modified label of agent . Let  be the length of the shorter of labels ,  .
Hence .
As observed before, the modified label of one agent cannot be a prefix of the modified label of the other. Hence there exists an integer {}, such that 
the th bit of  is different from the th bit of .
{Let  be the first time at which an agent finishes its th piece.
By Lemma \ref{lem:four},  if the agents have not met by time ,} then one of them cannot have completed the first atom of   as long as the other agent has not completed  {(i.e. started )}, {for some . (Since  and , these objects must exist.)}


First suppose that the th bit of  is 1. There are two possible cases.

\begin{itemize}
\item agent  follows the entire trajectory  while agent  is following . 


Since , by Definition~\ref{def:B} the trajectory  contains  
integral trajectories . Moreover, according to Algorithm RV-asynch-poly, the number of {edge traversals} in  is . So, the trajectory  contains more integral trajectories  than there are {edge traversals} in , hence there is a meeting.

\item agent  follows the entire trajectory  while agent  is following  . 

The trajectory  consists of repetitions of  for some node . 
Since by Lemma \ref{claim1}, , the trajectory , contains  for every node  of the graph, which implies a meeting by Lemma \ref{tunel}.
\end{itemize}

Next suppose that the th bit of  is 0. There are two possible cases.

\begin{itemize}

\item agent  follows the entire trajectory  while agent  is following . 

The trajectory  consists of repetitions of {} for some node .  Since by Lemma \ref{claim1}, , the trajectory
, contains   for every node  of the graph, which implies a meeting by Lemma \ref{tunel}.

\item agent  follows the entire trajectory  while agent  is following . 

By Definition~\ref{def:B} the trajectory  contains  integral trajectories . Moreover, since , the number of {edge traversals} in  is  i.e., at most . So, the number of integral trajectories  in  is larger than the number of {edge traversals} in , hence there is a meeting.
\end{itemize}

{Hence in all cases agents meet by the time when the first of the agents completes its th piece}. Now the proof can be completed by the following estimates which are a consequence of the formulation of the algorithm and of the definitions of respective trajectories.
 (Recall that  is the
polynomial describing the number of edge traversals in the trajectory obtained by Reingold's procedure.)


For any , .

For any , .

For any , .

For any , .

For any , .

{For any , .}

{For any , .}

For any , .

For every integer , let  denote the number of nodes in a piece in iteration  of the repeat loop in Algorithm RV-asynch-poly. Let . Recall that . 
 We have .
 {For any agent, the length of the trajectory it follows by the time it
 completes the th piece is at most .} Let .
It follows from the above discussion that agents must meet by the time one of them performs  edge traversals.
 Since  and  are polynomials in , while  and  are polynomials in  and , the function  is a polynomial.
Since the polynomial  is non-decreasing,  is non-decreasing in each variable. This completes the proof.
\end{proof}

\section{Applications: solving problems for multiple asynchronous agents}

In this section we apply our polynomial-cost rendezvous algorithm for asynchronous agents to solve four basic distributed problems
involving multiple asynchronous agents in unknown networks. Agents solve these problems by exchanging information during their meetings.
The scenario for all the problems is the following. There is a team of  agents having distinct integer labels, located at different nodes of an unknown network. 
The adversary wakes up some of the agents at possibly different times. A dormant agent is also woken up by an agent that visits its starting node, if such an agent exists.
As before, each agent knows a priori only its own label. Agents do not know the size of the team and, as before, have no
a priori knowledge concerning the network.
The assumptions concerning the movements of agents remain unchanged. We only need to add a provision in the model specifying what happens when agents meet. (For rendezvous, this was the end of the process.) This addition is very simple. 
When (two or more)  agents meet, they notice this fact and can exchange all previously acquired information. 
However, if the meeting is inside an edge,
they continue the walk prescribed by the adversary until reaching the other end of the current edge. New knowledge acquired at the meeting
can then influence the choice of the subsequent part of the routes constructed by each of the agents. It should be noted that the possibility
of exchanging all current information at a meeting is formulated only for simplicity. In fact, during a meeting, our algorithm prescribes the exchange of only at most
 labels of other agents that the meeting agents have already heard of, their initial values in the case of the gossiping problem, and a constant number of control bits.

We now specify the four problems that we want to solve:
\begin{itemize}
\item
{\tt team size}: every agent has to output the total
number  of agents; 
\item{\tt leader election}: all agents have to output the label of a single agent, called the leader;
\item
{\tt perfect renaming}: all agents
have to adopt new different labels from the set , where  is the number of agents;  
\item
{\tt gossiping}:  each agent has initially a piece of information (value) and all agents have to output all the values; thus agents have to exchange
all their initial information.
\end{itemize} 
The cost of a solution of each of the above problems is the total number of edge traversals by all agents until they output the solution.
Using our rendezvous algorithm we solve all these problems at cost polynomial in the size of the graph and in the smallest length of all labels of participating agents. 

Let us first note that accomplishing all the above tasks is a consequence of solving the following problem: 
at some point each agent acquires the labels of all the agents {\em and is aware} of this fact. We call this more general problem Strong Global Learning (SGL), where the word ``strong''  emphasizes awareness of the agents that learning is accomplished.\footnote{Notice that the assumption that the number  of agents is larger than 1 is necessary. For a single agent neither SGL nor any of the above mentioned problems can be solved. Indeed,
for example in an oriented ring of unknown size (ports 0,1 at all nodes in the clockwise direction), a single agent cannot realize that it is alone.}
Indeed, if each agent gets the labels of all the agents {\em and is aware} of it, then each agent can count all agents, thus solving
{\tt team size}, each agent can output the smallest label as that of the leader, thus solving {\tt leader election},  each agent can adopt the new label
 if its original label was th in increasing order among all labels, 
thus solving {\tt perfect renaming}, and each agent can output all initial values,
thus solving {\tt gossiping},  if we append in the algorithm for SGL the initial value to the label of each agent.

Hence it is enough to give an algorithm for the SGL problem, working at cost polynomial in the size of the graph 
and in the smallest length of all labels of participating agents. This is the aim of the present section. Notice that this automatically solves all
distributed problems that depend only on acquiring by all agents the knowledge of all labels and {\em being aware of this fact}.
(The above four problems are in this class.) We stress this latter requirement, because it is of crucial importance. Note, for example, that none of the above four problems can be solved even if agents
eventually learn all
labels but are never aware of the fact that no other agents are in the network. 
This detection requirement is non-trivial to achieve: recall that agents have 
no a priori bound on the size of the graph or on the size of the team. 


We now describe Algorithm SGL solving the SGL problem at cost polynomial in the size of the graph 
and in the smallest length of all labels of participating agents.  In this description we will use procedure RV-ASYNCH-POLY to denote Algorithm RV-asynch-poly
as executed by an agent with label . 

\vspace*{0.3cm}

\noindent
{\bf Algorithm SGL}


{We will define three states in which an agent can be. These states are {\em traveller}, {\em explorer}
and {\em ghost}. Transitions between states depend on the history of the agent, and more specifically on comparing the labels exchanged during meetings.} 

{The high-level idea of the algorithm is the following. An agent  with label  wakes up in state {\em traveller} and executes procedure RV-ASYNCH-POLY until the first meeting when it meets either agents that are not in state {\em explorer}, or agents having heard of some label smaller than  (below we explain what ''having heard of'' exactly means via the notion of {\em bag}).}
{Then, depending on the comparison of labels of the agents it meets or the labels that have been heard of by the agents it meets, it transits either to state {\em ghost} or to state {\em explorer}. In the first case it terminates its current move and stays idle.
In the second case it simulates procedure  by using an agent in state {\em ghost} as token and learns a polynomial upper bound  on the size  of the graph. Then it resumes procedure RV-ASYNCH-POLY, from where it interrupted it when leaving state {\em traveller}, until it performes the  edge traversals of RV-ASYNCH-POLY or it hears of another agent having a smaller label than .}

{If the agent is informed about the existence of a label smaller than  before executing the  edge traversals of RV-ASYNCH-POLY, it switches to state {\em ghost}: in fact we will prove that this kind of situation occurs for all explorers having a label different from  (where  is the smallest label among the participating agents) and after at most a number of edge traversals polynomial in  and .} 

{Otherwise, the agent ends up executing the  edge traversals of RV-ASYNCH-POLY (we will show that this occurs only when ).
At this point, there are no longer agents in state {\em traveller} and an execution of Reingold's procedure
followed by a complete backtrack of the trajectory resulting from this procedure permits the agent to learn all labels of participating agents as well as to convey this knowledge to all agents in state {\em ghost}.
All other agents will in turn get this knowledge from these agents.}


Below we specify what an agent  with label 
does in each state and how it transits from state to state. Each agent has a set variable , called its {\em bag}, initialized to , where  is its label. At each point of the execution of the algorithm  the value of the bag is the set of labels of agents that  has been informed about {(the bag of an agent is the set of labels it has heard of)}. More precisely, during any meeting of  with agents whose current values of their bags are ,
respectively, agent  sets the value of its bag  to .  Notice that since each bag can be only incremented, the number of updates of each bag
is at most , where  is the number of agents.

\vspace*{0.3cm}

\noindent
State {\em traveller}.

{The agent  wakes up in this state and starts executing procedure RV-ASYNCH-POLY  until the first meeting. Suppose the first meeting is with a set  of agents (). If there is an agent in  having a bag which includes a value smaller than  then agent  transits to state {\em ghost}.} 

{Otherwise, if  contains an agent in state
{\em ghost} or {\em traveller}, then agent  transits to state {\em explorer} and the smallest agent in set  which is not an explorer, say agent , will play the role of the token of agent  in order to simulate procedure  (refer to state {\em explorer}). Note that if agent  is not in state {\em ghost} when it meets agent  then its transits to this state while  transits to state {\em explorer}}.

{In all the other cases, agent  remains in state {\em traveller} and continues executing procedure RV-ASYNCH-POLY until the next meeting.}

\vspace*{0.3cm}

\noindent
State {\em ghost}.

{Agent  completes the traversal of the current edge and remains idle at its extremity forever.
As soon as it gets the information (from some agent in state {\em explorer}) that its current bag contains all labels of participating agents, agent  outputs the value of its bag.}

\vspace*{0.3cm}

\noindent
State {\em explorer}.

{When agent  transits to this state, it has just met an agent  in state {\em ghost} (or which has just transited to state {\em ghost}), that  considers as its token.
The actions of agent  are divided into three phases. If agent  transited to state {\em explorer} while traversing an edge, Phase~1 starts as soon as this edge traversal is done. Otherwise, Phase~1 starts immediately.}

\noindent \underline{Phase 1}.

{If agent  transited to state {\em explorer} from a node , agent  performs procedure  with its token which stays idle at  on the extended edge  (where  is some node adjacent to ). Otherwise, agent  transited to state {\em explorer} while traversing an edge  from  to . In this latter case, agent  also performs procedure  with its token located on the extended edge  (according to state {\em ghost}, the token remains on this extended edge forever)}.

{After completing Phase~1, agent  has visited all the nodes of the graph and it knows a polynomial upper bound on the size  of the network: this upper bound, denoted , is the cost of the entire execution of  previously made by agent  (refer to Theorem~\ref{theo:est}).} 

\noindent  \underline{Phase 2}.



{Let  be the trajectory made by the agents during Phase~1. Agent  backtracks to node  using the trajectory . Then, knowing the polynomial upperbound  on the size of the graph, agent  resumes the execution of procedure RV-ASYNCH-POLY (from where it interrupted it when transiting from state {\em traveller} to state {\em explorer}) and executes it until it made  edge traversals of RV-ASYNCH-POLY. More precisely, procedure RV-ASYNCH-POLY was interrupted either at node  just after  completed the first  edge traversals of the procedure or on edge  while  was walking from  to , executing the -th edge traversal of the procedure. In the first case, agent  resumes the execution of procedure RV-ASYNCH-POLY from node  by making the -th edge traversal, the -th edge traversal, etc., until the -th edge traversal. In the second case, the agent does the same but by resuming the procedure from  by executing the -th edge traversal of RV-ASYNCH-POLY (instead of starting from node  with the -th edge traversal): to do so, the agent first moves from node , where it is currently located, to node .}

{Whenever , agent  aborts Phase~2 as soon as it is at a node and switches to Phase~3.}

\noindent  \underline{Phase 3}.


{Let  be the node where agent  is located at the beginning of Phase~3.
If  then agent  seeks to meet its token (i.e. agent ) by applying . Once the meeting occurs, if agent  has already output its bag then agent  does the same. Otherwise, agent  transits to state {\em ghost}.}

{If , we know that agent  has carried out the execution of Phase~2 until its term without aborting it prematurely. We will show that
at this point  there does not remain any agent that is either dormant or in state {\em traveller}. The labels of all remaining agents are in the union of bags of all agents currently in state {\em ghost}. In this case, agent   performs  followed by a complete backtrack .
After the first trajectory  the agent has in its bag the labels of all participating agents.
During the second trajectory , all these labels are transmitted to all agents in state {\em ghost}, together with the information that this is the set of all labels. After completing the second trajectory
agent  outputs the value of its bag.}

\begin{theorem}\label{sgl} 
Upon completion of Algorithm SGL, each agent outputs the set of labels of all participating agents. The total cost of the algorithm is polynomial 
in the size of the graph 
and in the smallest length of all labels of participating agents.
\end{theorem}









\begin{proof}
{Let  be the agent having the smallest label, denoted , among all the participating agents. The argument is split in proofs of two claims.}

\vspace*{0.3cm}
\noindent
{{\bf Claim~1.} By applying Algorithm SGL in a graph of size , every agent makes a number of edge traversals polynomial in  and .}

{To prove this claim, consider an agent  with label  {(label  can be any label among those that are carried by the agents circulating in the graph: In particular, if , agent  corresponds to agent )}. If agent  never wakes up, it makes no edge traversals. So, let us focus on the case where it eventually wakes up. Upon waking up the agent is in state {\em traveller} and starts executing  procedure RV-ASYNCH-POLY. In view of Theorem \ref{main},  
by the time the agent performs  edge traversals, it must meet some agent that is in state {\em traveller} or in state {\em ghost}, or some agent with a bag containing a label smaller than  (if ).} ({Indeed, in the case  note that during this time interval if agent  (which corresponds to agent  in this case) does not meet any agent in state {\em traveller}, it must meet an agent in state {\em ghost} because there is an agent in state ghost located in each edge at which an agent transited from state {\em traveller} to state {\em explorer}. In the case  (i.e., when agent  and agent  are different), note that} during this time interval, agent  is idle or is executing procedure RV-ASYNCH-POLY as a traveller, or an agent in state {\em ghost} playing the role of the token of  is located in the edge at which  stopped the execution of RV-ASYNCH-POLY to transit to state {\em explorer}. So if agent  has not met another agent in state {\em traveller} or in state {\em ghost} or some agent with a bag containing a label smaller than  before it makes the th edge traversal of RV-ASYNCH-POLY, it must meet agent  or the token of agent  while making the th edge traversal of RV-ASYNCH-POLY.) At this meeting, agent  transits either to state
{\em ghost} or to state {\em explorer}. In the first case agent  does not perform any further edge traversals and the claim follows in that case. So consider the second case, when agent  transited to state {\em explorer}.
In this case  agent   uses at most 
{ edge traversals in Phase 1 in order to perform procedure }.
After completing Phase 1 agent  knows a polynomial upper bound  on the size of the graph. 

{In state {\em explorer} agent  starts Phase 2 by executing a complete backtrack of the trajectory made by the agent in Phase~1 which also costs at most 
{} edge traversals. Then after at most one extra edge traversal, agent  resumes the execution of procedure RV-ASYNCH-POLY from where it interrupted it (when leaving state {\em traveller}) until it made the th edge traversal of RV-ASYNCH-POLY or as soon as , where  is the bag of agent . However, notice that if  then agent  cannot go beyond the execution of the th edge traversal of RV-ASYNCH-POLY (and thus every explorer different from  aborts Phase~2 having a bag with a value smaller than its own label). Indeed, if at the time when procedure RV-ASYNCH-POLY is resumed we  have , then the token of  has not met agent  executing RV-ASYNCH-POLY as a traveller. Hence according to Algorithm  and Theorem \ref{main}, if agent  does not meet an agent with a bag containing a value smaller than  before the execution of the th edge traversal of RV-ASYNCH-POLY then it meets either agent  or the token of  while executing the th edge traversal of 
RV-ASYNCH-POLY which immediately makes  smaller than .}

{Thus Phase~2 costs at most {} edge traversals if agent  is different from , and at most {} for agent , which leads to an upper bound of { for any agent}.}

{Since in Phase~3, an explorer executes at most  edge traversals, the total number of edge traversals performed by any agent can be upper-bounded by  {} which is polynomial in  and . Hence the claim is proven.}

\vspace*{0.3cm}

\noindent
{{\bf Claim~2.} By applying Algorithm SGL in a graph of size , every agent eventually outputs its bag. Moreover, when a bag is output, it contains the labels of all the participating agents.}

{To prove the claim, first note that only agent  ends up executing  for some node  in Phase~3 of state {\em explorer}. Indeed, a necessary condition, for agent with label  to execute this, is that its bag does not contain a label smaller than . However, as mentioned in the proof of Claim~1, at the end of Phase~2 every explorer different from  has its bag containing a value smaller than its own label. Moreover, from Algorithm  we know that an agent, say , transits to state {\em explorer} by the time when the first woken up agent leaves state {\em traveller}, and thus in view of Theorem~\ref{theo:est}, agent  is woken up by the time agent  finishes executing Phase~1 of state {\em explorer}. Finally, agent  never transits to state {\em ghost} and eventually executes  in Phase~3 of state {\em explorer} because its bag cannot include a label smaller than .}

{Suppose that at the end of the execution of Phase~2 by agent  at time , there remains an agent  that is either still dormant or in state {\em traveller}. In particular this means that agent  does not meet agent  during the execution of the  edge traversals of RV-ASYNCH-POLY, first as a {\em traveller} and then as an {\em explorer}. From Theorem~\ref{main} and Algorithm  it follows that the token of  necessarily meets agent  by time . However, by meeting the token of , which has in its bag label , agent  must transit to state {\em ghost} by time  according to Algorithm , which is a contradiction. Hence at time  all the agents different from  are in state {\em ghost} or {\em explorer} and all the labels of participating agents are in the union of the bags of agents in state {\em ghost}.}

{After round , according to Phase~3 of state {\em explorer}, agent  performs . By the end of , agent  must meet all agents that
were in state {\em ghost} at time , as these agents never enter a different edge from the one where they transited to state {\em ghost}. Consequently, by the end of , the bag of agent 
contains the labels of all agents, and  is aware of this fact. 
During the execution of , agent  transmits its bag to all agents currently in state {\em ghost} together with the information
that this bag contains all labels. 
This permits all agents currently in state {\em ghost} to output the value of their bag which now contains all labels. 
Upon completion of Phase~3, agent
 outputs the value of its bag which contains all labels.}

{To conclude the proof of this claim, we have to argue that each agent (different from ) that is in state {\em explorer} at time , also eventually outputs its bag with the labels of all participating agents. This is the case because, as mentioned before, these agents end up transiting to state {\em ghost} by executing Phase~3 of state {\em explorer}. Indeed, if such an agent transits to state {\em ghost} by the end of the execution of Phase~3 by agent , it will get the information that its bag contains all the labels and can be output, either from agent  or from its token, when transiting to state {\em ghost}. Otherwise, it transits to state {\em ghost} after the end of the execution of Phase~3 by agent , and thus it gets this final information from its token when transiting from state {\em explorer} to state {\em ghost}, which proves the claim.}

{The theorem follows from Claims~1 and~2.}
\end{proof}





\section{Conclusion}

We presented an algorithm for asynchronous rendezvous of agents in arbitrary finite connected graphs, working at cost polynomial in the size  of the graph and in the length
of the smaller label. In \cite{CLP}, where the exponential-cost solution was first proposed, the authors stated the following question:
\begin{quotation}
Does there exist a deterministic asynchronous rendezvous algorithm,
working for all connected finite unknown graphs,
with complexity polynomial in the labels of the agents and in the
size of the graph?
\end{quotation}
Our result gives a strong positive answer to this problem: our algorithm is polynomial in the {\em logarithm} of the smaller label and in the size of the graph.

In this paper we did not make any attempt at optimizing the cost of our rendezvous algorithm, the only concern was to keep it polynomial. Cost optimization seems to be a very challenging problem. Even finding the optimal cost of exploration of unknown graphs of known size is still open, and this is a much simpler problem, as it is equivalent to rendezvous of two agents one of which is inert. 

We also applied our rendezvous algorithm to solve four fundamental distributed problems in the context of multiple asynchronous mobile agents.
The cost of all solutions is polynomial in the size of the graph and in the length of the smallest of all labels. 






\bibliographystyle{plain}
\begin{thebibliography}{99}

\bibitem{ABDKPR}
H. Attiya, A. Bar-Noy, D. Dolev, D. Koller, D. Peleg and R. Reischuk,
Renaming in an asynchronous environment, Journal of the ACM 37 (1990), 524-548.

\bibitem{AP06}
N. Agmon and D. Peleg, 
Fault-tolerant gathering algorithms for autonomous mobile robots,  
SIAM J. Comput. 36 (2006), 56-82. 

\bibitem{alpern95a}
S. Alpern,
The rendezvous search problem,
SIAM J. on Control and Optimization 33 (1995), 673-683.


\bibitem{alpern02a}
S. Alpern,
Rendezvous search on labelled networks,
Naval Research Logistics 49 (2002), 256-274.

\bibitem{alpern02b}
S. Alpern and S. Gal,
The theory of search games and rendezvous.
Int. Series in Operations research and Management Science,
Kluwer Academic Publisher, 2002.

\bibitem{alpern99}
J. Alpern, V. Baston, and S. Essegaier,
Rendezvous search on a graph,
Journal of Applied Probability 36 (1999), 223-231.



\bibitem{anderson90}
E. Anderson and R. Weber,
The rendezvous problem on discrete locations,
Journal of Applied Probability 28 (1990), 839-851.

\bibitem{anderson98a}
E. Anderson and S. Fekete,
Asymmetric rendezvous on the plane,
Proc. 14th Annual ACM Symp. on Computational Geometry (1998), 365-373.

\bibitem{anderson98b}
E. Anderson and S. Fekete,
Two-dimensional rendezvous search,
Operations Research 49 (2001), 107-118.




\bibitem{BCGIL}
E. Bampas, J. Czyzowicz, L. Gasieniec, D. Ilcinkas, A. Labourel, Almost optimal asynchronous rendezvous in infinite multidimensional grids,
Proc. 24th International Symposium on Distributed Computing (DISC 2010),  297-311.

\bibitem{baston01}
V. Baston and S. Gal,
Rendezvous search when marks are left at the starting
points,
Naval Research Logistics 48 (2001), 722-731.

{\bibitem{CFPS}
M. Cieliebak, P. Flocchini, G. Prencipe, N. Santoro, 
Distributed Computing by Mobile Robots: Gathering,
SIAM J. Comput. 41 (2012),  829-879.}

\bibitem{CP05}
R. Cohen and D. Peleg, 
Convergence properties of the gravitational algorithm in asynchronous robot 
systems, SIAM J. Comput. 34 (2005), 1516-1528. 

\bibitem{CP08}
R. Cohen and D. Peleg, 
Convergence of autonomous mobile robots with inaccurate sensors and movements, 
SIAM J. Comput. 38 (2008), 276-302. 



\bibitem{CCGL}
A. Collins, J. Czyzowicz, L. Gasieniec, A. Labourel,
Tell me where I am so I can meet you sooner.
Proc. 37th International Colloquium on Automata, Languages and Programming (ICALP 2010), 502-514.

\bibitem{CKP}
J. Czyzowicz, A. Kosowski and A. Pelc,
How to meet when you forget:  Log-space rendezvous in arbitrary graphs,
Distributed Computing 25 (2012), 165-178.

 \bibitem{CLP}
 J. Czyzowicz, A. Labourel, A. Pelc, How to meet asynchronously (almost) everywhere,
ACM Transactions on Algorithms 8 (2012), article 37. 
 
 \bibitem{DGKKPV}
G. De Marco, L. Gargano, E. Kranakis, D. Krizanc, A. Pelc, U. Vaccaro,
 Asynchronous deterministic rendezvous in graphs, 
Theoretical Computer Science 355 (2006), 315-326.
 
 \bibitem{DFKP}
A. Dessmark, P. Fraigniaud, D. Kowalski, A. Pelc.
Deterministic rendezvous in graphs.
Algorithmica 46 (2006), 69-96.




\bibitem{DiPe}
Y. Dieudonn\'{e}, A. Pelc, Anonymous Meeting in Networks, Proc. 24rd Annual ACM-SIAM Symposium on Discrete Algorithms (SODA 2013),  737-747.

{\bibitem{DPP}
Y. Dieudonn\'{e}, A. Pelc, D. Peleg, Gathering despite mischief, ACM Transactions on Algorithms 11 (2014), article 1.}

\bibitem{DP}
Y. Dieudonn\'{e}, A. Pelc,
Deterministic network exploration by a single agent with Byzantine tokens,
Information Processing Letters 112 (2012), 467-470

{\bibitem{fpsw}
P. Flocchini, G. Prencipe, N. Santoro, P. Widmayer,
Gathering of asynchronous oblivious robots with limited visibility,
Theor. Comput. Sci. 337 (2005), 147-168.}

\bibitem{FL}
P. Fraigniaud, E. Lazard, Methods and problems of communication in usual networks. Discrete Applied Mathematics 53 (1994), 79-133.



\bibitem{FP2}
P. Fraigniaud, A. Pelc, Delays induce an exponential memory gap for rendezvous in trees, ACM Transactions on Algorithms 9 (2013), article 17. 
\bibitem{FP3}
P. Fraigniaud, A. Pelc, Decidability classes for mobile agents computing, Proc. 10th Latin American Theoretical Informatics Symposium (LATIN 2012), LNCS 7256, 362-374. 





\bibitem{GP}
S. Guilbault, A. Pelc, Asynchronous rendezvous of anonymous agents in arbitrary graphs,
Proc. 15th International Conference on Principles of Distributed Systems (OPODIS 2011), 162-173.

{\bibitem{KM}
D. Kowalski, A. Malinowski,
How to meet in anonymous network,
Theor. Comput. Sci. 399 (2008), 141-156.}

{\bibitem{KKPM11}
E. Kranakis, D. Krizanc, and P. Morin, 
Randomized rendez-vous with limited memory,
ACM Transactions on Algorithms 7 (2011), article 34}.


\bibitem{KKSS}
E. Kranakis, D. Krizanc, N. Santoro and C. Sawchuk, 
Mobile agent rendezvous in a ring, 
Proc. 23rd Int. Conference on Distributed Computing Systems
(ICDCS 2003), IEEE, 592-599.

\bibitem{lim96}
W. Lim and S. Alpern,
Minimax rendezvous on the line,
SIAM J. on Control and Optimization 34 (1996), 1650-1665.

\bibitem{Pe}
A. Pelc, Deterministic rendezvous in networks: A comprehensive survey, Networks 59 (2012), 331-347. 





\bibitem{Ly}
N.L. Lynch, Distributed algorithms, Morgan Kaufmann Publ. Inc.,
San Francisco, USA, 1996.

\bibitem{Re}
O. Reingold, Undirected connectivity in log-space, Journal of the ACM 55 (2008).



{\bibitem{TSZ14}
A. Ta-Shma and U. Zwick.
Deterministic rendezvous, treasure hunts and strongly universal exploration sequences, 
ACM Transactions on Algorithms 10 (2014), article 12.}

\bibitem{YY}
X. Yu and M. Yung, 
Agent rendezvous: a dynamic symmetry-breaking problem, 
Proc.  International Colloquium on Automata,
Languages, and Programming (ICALP 1996), 610-621.





\end{thebibliography}





\end{document}
