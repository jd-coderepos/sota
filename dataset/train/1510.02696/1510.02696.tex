\noindent This section describes the design of \name, in particular bandwidth
reservations and their enforcement. After a brief overview, we describe \name's
reservation types in detail.


\subsection{SIBRA overview}
\label{sec:overview}

\noindent A key insight of \name is its hierarchical decomposition of the
bandwidth allocation problem to make management and configuration scale to the
size of the Internet. More specifically, \name makes use of 
(1)~\textbf{core} contracts:
\emph{long-term} contracts amongst the core ASes of large-scale isolation domains (ISDs),
(2)~\textbf{steady} contracts:
\emph{intermediate-term} contracts amongst \ADs within an ISD, and
(3)~\textbf{ephemeral} contracts:
\emph{short-term} contracts for end-to-end communication that leverage the long-term
and inter\-mediate-term contracts.

Thanks to this three-layer decomposition, on the order of 100 large-scale ISDs (e.g.,
composed by sets of countries or groups of companies) can scalably establish
long-term \textbf{core~paths} with guaranteed bandwidth between each other (the
double continuous lines in \autoref{fig:topology}). Within each ISD, providers
sell bandwidth to their customers, and customers can establish
inter\-mediate-term reservations for specific \emph{intra}-ISD paths, which we
call \textbf{steady paths} (the dashed lines in \autoref{fig:topology}). Steady
paths are mostly used for connection setup traffic, but can also be used for
low-bandwidth data traffic.
Finally, core and steady paths in conjunction enable the creation of short-term
end-to-end reservations \emph{across} ISDs, which we call
\textbf{ephemeral paths} (the solid green lines in
\autoref{fig:topology}). Ephemeral paths, in contrast to steady paths,
are used for the transmission of high-throughput data traffic.

\begin{figure}[t]
  \begin{center}
    \includegraphics[width=0.9\linewidth]{SIBRA-paths.pdf}
  \end{center}
  \vspace{-5mm}
  \caption{Exemplary \name topology with 4 isolation domains and their ASes
  (the core ASes are filled). The ephemeral path (green) from end host  to
  end host  is created along a steady up-path, a core path, and a steady
  down-path. The attack traffic (red) does not diminish the reserved bandwidth
  on ephemeral paths.}
  \label{fig:topology}
  \vspace{-7mm}
\end{figure}

\name paths are established over \name links whose anatomy
is depicted in \autoref{fig:anatomy}: \bweph\% of
the bandwidth of each \name link is allocated for ephemeral traffic, \bwstd\% for
steady traffic, and the remaining \bwbst\% for best-effort traffic.
These proportions are flexible system parameters; we discuss the current choice
in \autoref{sec:parameters}. Note that the proportion for steady and ephemeral
traffic constitutes an upper bound: in case the ephemeral bandwidth is not
fully utilized, it is allocated to best-effort traffic
(Section~\ref{sec:ephemeral}).

An important feature of \name is that steady paths, besides carrying the
\bwstd\% control traffic of links inside an ISD, also limit the bandwidth for ephemeral
paths: An ephemeral path is created by launching a request through existing
steady paths whose amounts of bandwidth determine -- up to a fixed scaling factor
-- the bandwidth of the requested ephemeral path. More precisely, an ephemeral
path is created through the combination of (i) a steady up-path in the source
ISD, (ii) the steady part of a core path, and (iii) a steady down-path in the
destination ISD.\footnote{For instance, \autoref{fig:topology} shows an
ephemeral path from host  in  to host  in . If the source and
destination are in the same ISD, then the core path may not be necessary, e.g.,
the ephemeral path inside the US ISD.} The ephemeral path \emph{request} uses
only the steady portion of a link (the blue part in \autoref{fig:anatomy}); the
actual ephemeral path \emph{traffic} uses only the ephemeral portion of a link
(the orange part in \autoref{fig:anatomy}). In other words, the more steady
bandwidth a customer purchases locally within her ISD, the larger the fraction
of ephemeral bandwidth she obtains to any other ISD in the Internet.


\begin{figure}[t]
  \begin{center}
    \includegraphics[width=0.7\linewidth]{SIBRA-paths-anatomy.pdf}
  \end{center}
  \vspace{-3mm}
  \caption{The anatomy of \name links: \bweph\% of the link bandwidth is used
  for ephemeral traffic, \bwstd\% for steady traffic, and \bwbst\% for
  best-effort traffic. The core path from  to  comprises
  steady and ephemeral traffic, but excludes best-effort traffic.}
  \vspace{-7mm}
  \label{fig:anatomy}
\end{figure}


Based on these ideas, it becomes intuitively clear how botnet-size independence
is achieved and how the \tragedy is resolved: Each pair of domains can obtain a
minimum bandwidth allocation, based on their respective steady paths and based
on the core contract. Thus, a botnet cannot influence the minimum allocation,
no matter its size and distribution. A bot can only use up the bandwidth
allocated to the AS it resides in, but not lower the minimum allocation of any
other AS. It is thus in the responsibility of an AS to manage its allocations,
and thereby to prevent bots from obtaining resources of others within that AS.

In case an \AD is dissatisfied with its minimum allocation, it can purchase
more bandwidth for its steady paths, as well as request its core \AD to
purchase a larger allocation for the core contract, which the \AD would likely
need to pay for. An important point of these contracts is that, in order to
scale, core contracts are purely neighbor-based: only neighboring \ADs perform
negotiations.

\name's scalability is additionally based on a relatively low number of
ephemeral paths, compared to \emph{all possible} end-to-end paths in today's
Internet, considered for instance by IntServ~\cite{intserv}. As mentioned
above, an ephemeral path in \name is fully determined by choosing two steady
paths and a core path. The number of steady up-/down-paths an \AD can
simultaneously have is upper-bounded by a small \name system parameter (e.g.,
 to ), and the number of core paths is naturally upper-bounded by the
number of ISDs.

To make \name viable for practical applications, we need to ensure that all
aspects of the system are scalable and efficient, which holds in particular for
the frequent operations such as flow admission, reservation renewal, and
monitoring and policing.
For instance, all fastpath operations are per-flow stateless to avoid
state-exhaustion attacks and to simplify the router architecture.


\subsection{Core paths}
\label{sec:corepaths}

\noindent
Directly-connected core \ADs (i.e., Tier-1 ISPs) are expected to agree on a
guaranteed amount of bandwidth for traffic traversing their connecting links.
We envision that \ADs ratify such \emph{core contracts} on mutual business
advantages for their customers, on top of currently negotiated
customer-to-provider or peering relations. Similar to SLAs, core contracts are
long term (e.g., on the order of months) and can have an up-time associated
(e.g., the bandwidth is guaranteed 99.99\% of the time). Core contracts
comprise steady and ephemeral traffic, as illustrated in the shaded part of
\autoref{fig:anatomy}.
If one of the \ADs sends more traffic than agreed on, the \AD is held
accountable, according to the established contract.

Core contracts are initiated by \textit{receiver core \ADs}: each core \AD
observes the historical traffic values \textit{received} on its neighboring
links, and proposes in the core contracts similar values for the traffic the
\AD is willing to absorb. For instance, in \autoref{fig:corecontracts},
 proposes to absorb 5~Tbps of steady and ephemeral traffic from
 (Step~\ding{172}), and  accepts. The contract is followed as long as 
sends at most 5~Tbps to , regardless of whether  is the
actual origin of the traffic, or  only forwards someone else's traffic
to . For instance,  could forward traffic from  and
 to . In the example,  offers to forward 1~Tbps
from  (Step~\ding{173}), and 3~Tbps from 
(Step~\ding{174}).  extends the latter contract by proposing to
 to absorb 2~Tbps towards  (Step~\ding{175}). After
completion of the negotiation,  obtains guaranteed bandwidth to
 along two \textbf{core paths}.


\label{sec:contracts}
\begin{figure}[t]
  \begin{center}
    \includegraphics[width=0.95\linewidth, trim=0 30 0 0]{SIBRA-core_contracts.pdf}
  \end{center}
  \caption{Core contracts between core \ADs (, , ,
    ).}
  \vspace{-3mm}
  \label{fig:corecontracts}
\end{figure}

\autoref{tab:core} illustrates a local \emph{guaranteed-bandwidth} table that
stores such core paths for . The table resembles a forwarding table
and may contain multiple entries for each destination core \AD, one entry for
each core path. It results from the contract proposals and the received
acknowledgments for a specific destination,  in this case. For
brevity's sake, \autoref{tab:core} shows only the entries for destination
.

\begin{figure}[tp]
\small
\renewcommand{\arraystretch}{1.0}
\centering
 \begin{tabular}{lll}
 \hline
 Destination & \centering Path & Bandwidth \\ [0.5ex]
 \hline\hline
 &  & 1 Tbps\\
 &  & 2 Tbps \\ [-1ex]
 ~  & ~  & ~  \\
 \hline
 \end{tabular}
\caption{Core contracts table at . Two core paths lead to .}
\vspace{-5mm}
\label{tab:core}
\end{figure}

The bandwidth of a core path reflects the overall traffic volume exchanged
between the source and the destination ASes. To bootstrap the process, each
participating AS observes aggregate traffic volumes on its neighboring links,
and initiates contracts with a bandwidth of 85\% of the observed aggregate
volume (5\% steady + 80\% ephemeral). The initially estimated contracts are
refined as dictated by the customer requirements and payments (explained below).



\paragraph{Scalability} The core contract proposals traverse only one link
before being accepted or denied. For instance, in \autoref{fig:corecontracts},
 first accepts 's proposal (Step~\ding{172}), and only
afterwards, it submits its offers (Steps~\ding{173} and \ding{174}). Achieving
global consensus through immediate agreements is possible due to the
\textit{destination-initiated} process of establishing core contracts, in which
the supported amount of traffic is already specified and can thus be decided
based on \textit{local knowledge}. In contrast, source-initiated requests would
require a distributed consensus algorithm that would traverse all ASes whose
agreement is required. \name's design decision sacrifices such costly
interactions for better scalability, achieving a core contract design that is
scalable with the number of core \ADs.


\paragraph{Payment} Core paths not only guarantee bandwidth between
ISDs, they also regulate the traffic-related money flow between core
\ADs according to existing provider-to-customer (p2c) or peering (p2p)
relationships (e.g., c2p between  and , and p2p
between  and ).

Similar to today's state of affairs, we believe that market forces create a
convergence of allocations and prices when ASes balance the bandwidth between
their peers and adjust the contracts such that the direct core \AD neighbors
are satisfied. The neighbors, in turn, recursively adapt their contracts to
satisfy the bandwidth requirements of their customers. Paying customers thus
indirectly dictate to core \ADs the destination ISDs of core paths and the
specified bandwidth in the contracts.


\subsection{Steady paths}

\noindent Steady paths are intermediate-term, low-bandwidth
reservations that are established by ASes for guaranteed
communication availability within an ISD. We envision that the
default validity of steady paths is on the order of minutes, but it
can periodically be extended. An endpoint \AD can voluntarily tear
down its steady path before expiration and set up a new steady path.
For example, in \autoref{fig:topology},  sets up a steady path
to , and  requests bandwidth guarantees from
. As mentioned earlier, \name uses steady paths for two
purposes: (1)~as communication guarantees for low-bandwidth
traffic, and (2)~as building block for ephemeral paths: to
guarantee availability during connection setup and to perform
weighted bandwidth reservations (Section~\ref{sec:ephemeral}).

\begin{figure}[t]
  \begin{center}
  \includegraphics[width=0.95\linewidth, trim=0 25 0 0]{res-request-processing.pdf}
  \end{center}
  \caption{Transit  processing reservation requests for sources , ,  and
  destination .\footref{fnt:destination}}
  \vspace{-5mm}
  \label{fig:reservation}
\end{figure}

\footnoteblind{fnt:destination}{We use the term \emph{destination} in the following (and also in
\autoref{fig:reservation}) to stay as general as possible. For steady-path
reservation requests, the destination is the ISD core; for ephemeral-path
reservation requests, the destination will be another end host
(\autoref{sec:ephemeral}).}


\paragraph{Reservation request}
\name leverages so-called SCION \emph{routing beacons}~\cite{scion2015} that
disseminate top-down from the ISD core to the \ADs. On their journey down, they
collect AS-level path information as well as information about the current
amount of available bandwidth (both steady and ephemeral) for each link.
\ifFullVersion
Given this information, each half-path can become a steady
path, and each end-to-end path can become an ephemeral path,
through the mechanism we describe next.

\fi
When a leaf \AD receives such a routing beacon with information about
a path segment, the \AD can decide to submit a reservation request
that promotes the path segment to a steady path. In this case, the
leaf \AD (e.g.,  in \autoref{fig:topology}, or  in
\autoref{fig:reservation}) computes a new flow ID, chooses the amount
of bandwidth and the expiration time, and sends a \emph{steady path
reservation message} up the path to the core. 
The requested amount of bandwidth can be chosen from a number of predefined
bandwidth classes, introduced for monitoring optimization purposes
(Section~\ref{sec:mon}).

Each intermediate AS on the path to the core performs \textit{admission
control} by verifying the availability of steady bandwidth to its
neighbors on the path (Step~I in \autoref{fig:reservation}). Given
the fact that inbound traffic from multiple ingress routers may
converge at a single egress router, admission control is performed at
both ingress and egress routers. Specifically, the ingress router of
 checks the availability of steady bandwidth on the link
, and the egress router of  on the
link .
If enough bandwidth is available at both the ingress and the egress
router (Case~\ding{202} in \autoref{fig:reservation}), both routers
\textit{temporarily} reserve the requested bandwidth (Step~II).
Subsequently, the egress router of  issues a cryptographically
authenticated \textit{reservation token} (RT) encoding the positive
admission decision (Step III).

An RT generated by  is authenticated using a cryptographic key
 known only to , by which  can later verify if an RT
embedded in the data packet is authentic.
More specifically, the RT contains the authenticated ingress and the
egress interfaces of , and the reservation request information.
RTs are onion-authenticated to prevent an attacker from crafting a
steady path from RT chunks:

\vspace{-12pt}

where  is defined as
.
We emphasize that steady path reservation flow identifiers are independent of
TCP flow identifiers: A steady path can carry packets from \emph{multiple} TCP
flows, as long as these packets contain the RTs corresponding to the steady
path in their header.


If at least one of the routers of  cannot meet the request
(Case \ding{203}), it suggests an amount of bandwidth that could be
offered instead, and adds this suggestion to the packet header.
Although already failed, the request is still forwarded to the
destination (i.e., to the ISD core in case of steady paths) to collect
suggested amounts of bandwidth from subsequent
\ADs. This information helps the source make an informed and direct
decision in a potential bandwidth re-negotiation.

As steady paths are only infrequently updated, scalability and
efficiency of steady path updates are of secondary importance.
However,  can still perform an efficient admission decision by
simply considering the current utilization of its directly adjacent
\AD neighbors.
Such an efficient mechanism is necessary for reservation requests (and
renewals) to be fastpath operations, avoiding to access per-path state.
In case of a positive admission decision,  needs to account for
the steady path individually per leaf \AD where the reservation
originates from. Only slowpath operations, such as policing of
misbehaving steady paths, need to access this per-path information
about individual steady paths.

\paragraph{Confirmation and usage} When the reservation request reaches the
destination~, the destination replies to the requesting source (e.g., )
either by a \textit{confirmation message} (Case \ding{204} in
\autoref{fig:reservation}) containing the RTs accumulated in the request packet
header, or by a \textit{rejection message} (Case \ding{205}) containing the
suggested bandwidth information collected before.\footref{fnt:destination} As
the confirmation message travels back to the source, every ingress and egress
router accepts the reservation request and switches the reservation status from
temporary to active (Step IV).

In order to use the reserved bandwidth for actual data traffic, the
source includes the RTs in the packet header.


\subsection{Ephemeral paths}
\label{sec:ephemeral}

\noindent Ephemeral paths are used for communication with guaranteed high
bandwidth. Ephemeral paths are short-lived, only valid on the order of tens of
seconds, and thus require continuous renewals through the life of the connection.
The source, the destination, and any on-path \AD can rapidly renegotiate the
allocations. \autoref{fig:topology} shows two ephemeral paths, one inside an
ISD, one across three ISDs.

We emphasize that the amount of ephemeral bandwidth that is proportional to
steady bandwidth may constitute a lower bound: If more ephemeral bandwidth is
available (for instance since not everybody might be using his fair share of
ephemeral bandwidth), requesters can choose a bandwidth class \emph{above} the
proportional ratio. In the spirit of fair allocation of joint resources, the
lifetime of ephemeral paths is limited to 16 seconds in order to curtail the
time of resource over-allocation. The details of the over-allocation, however,
are out of scope and left for future work.

\paragraph{Ephemeral paths from steady paths} Ephemeral path requests bear many
similarities with steady path requests, yet bootstrapping is different: An
ephemeral path reservation is launched by an end host, as opposed to a steady
path reservation that is launched by a leaf \AD. The end host (e.g., host  in
\autoref{fig:topology}) first obtains a steady up-path starting at its \AD
(e.g., ) to the ISD core, and a steady down-path starting at the
destination ISD core (e.g., ) to the destination leaf \AD (e.g.,
).  Joining these steady paths with an inter-ISD core path (e.g., from
 to ) results in an end-to-end path , which is used to
send the ephemeral path request from the source end host  to the destination
end host  using allocated steady bandwidth.

More specifically,  first generates a new flow ID, chooses an amount of
bandwidth to request from \name's predefined ephemeral bandwidth classes, and
sends the ephemeral path request along path .\footnote{Similarly to the
steady path case, although an ephemeral path is identified by a flow ID, this
flow ID is orthogonal to TCP flow IDs. A single ephemeral path can transport any
data packets regardless of their layer-4 protocol.} Recall that the path is
composed of a steady up-path of , a core path, and a steady down-path of
.  The leaf \AD where the source end host resides (e.g., ) may decide
to block the request in some cases, for instance if the bandwidth purchased by
the leaf \AD is insufficient. Each intermediate \AD on path  performs admission
control through a weighted fair sharing mechanism that ensures the ephemeral
bandwidth is directly proportional with its steady path bandwidth, as described
next. The bandwidth reservation continues similarly to the steady path case.


If bots infest source and destination leaf \ADs, these bots may try to exceed
their fair share by requesting, respectively approving, excessively large
amounts of bandwidth. To thwart this attack, each leaf \AD is responsible for
splitting its purchased bandwidth among its end hosts according to its local
policy, and for subsequently monitoring the usage.


\paragraph{Efficient weighted bandwidth fair sharing} The intuition behind
\name's weighted fair sharing for ephemeral bandwidth is that purchasing steady
bandwidth (or generally spoken: bandwidth for control traffic) on a link 
guarantees a proportional amount of ephemeral bandwidth on . In
\autoref{fig:topology}, the ephemeral bandwidth on the ephemeral path from end
host  to  is proportional to the steady bandwidth on the steady up-path
from  to core , and also proportional to the steady bandwidth on
the steady down-path from core  down to .
We explain the details of the three cases of intra-source-ISD links, core
links, and intra-destination-ISD links in the following.

\emph{(1) Ephemeral bandwidth in the source ISD.}
For instance, a steady up-path of  kbps traversing intra-ISD
link  guarantees  kbps of ephemeral
bandwidth on . Note that  is the
ratio between ephemeral and steady bandwidth
(\autoref{sec:overview}). Generally speaking, a steady up-path
 with steady bandwidth  traversing  can request
ephemeral bandwidth of

Consequently, an \AD that purchases a steady up-path  can
guarantee its customers a fixed amount of ephemeral bandwidth for
customers' ephemeral path requests launched via , regardless of
the ephemeral path requests from other \ADs on .

To provide bandwidth guarantees on \emph{every} link to a destination,
\name extends the influence of the purchased steady up-path
bandwidth along the path to the destination AS. In fact, \name's
weighted fair sharing for ephemeral bandwidth on core paths includes
the purchased steady up-path bandwidth, as explained in the following.

\emph{(2) Ephemeral bandwidth on core links.} Let  be the
total amount of steady bandwidth sold by a core  for \emph{all}
steady paths in 's ISD. Let  be the reserved bandwidth
sold for a \emph{particular} steady up-path  in this ISD. Let
further  be the control traffic bandwidth of a core path 
between the core ASes of the steady paths for  and . Then,
ephemeral reservations on  launched via  can be up to

In other words, the ephemeral bandwidth reservable on  launched via steady
path  depends not only on the amount of total ephemeral
bandwidth on , but also on 's steady up-path bandwidth in
relation to the total amount of steady up-path bandwidth purchased in
's ISD.


\emph{(3) Ephemeral bandwidth in the destination ISD.} In the
destination ISD, the weighted fair sharing is slightly more complex,
but follows the ideas of the previous cases: the weighting includes
the steady bandwidth of all steady up-paths and all steady
down-paths, as well as the ratios of the bandwidth of the core
contracts. Before explaining the details, we note that the reason for
including also the steady down-paths is to give the destination \AD
control over the minimum amount of traffic it receives along
ephemeral paths.

More precisely, an ephemeral path launched over steady up-path 
and steady down-path  with core path  in between obtains
ephemeral bandwidth

where  is the bandwidth negotiated in the core contract
for  between the core ASes of  and , and  is the total
amount of bandwidth negotiated in all core contracts between any core
AS and 's core AS.

\autoref{eq:eph:destination} looks similar to
\autoref{eq:eph:core}, with an additional factor in the weighting
that reflects the ratio of incoming traffic from other core ASes.
Intuitively, this factor assures that traffic from every other core
AS obtains its fair share based on the bandwidth negotiated in the
individual bilateral contracts.

Finally, the overall bandwidth for an ephemeral path
between end hosts  and  launched over
steady up-path  reads



These equations compute the guaranteed bandwidth using the envisioned long-term
ratio of 5\% steady traffic, 80\% ephemeral traffic, and 15\% best-effort
traffic. Ideally, the ratio should be adjustable by each AS, initially with an
imbalance in favor of best-effort during incremental deployment of \name, until the
number of \name subscribers increases. The overall bandwidth  that
can be obtained during early deployment is the minimum of the individual ratios
for each AS and their link bandwidth. We discuss the choice of the ratio in
Section~\ref{sec:parameters} and its adaption in terms of an incremental
deployment strategy in Section~\ref{sec:deployment}.

\paragraph{Fair sharing of steady paths} A challenging question is whether a
fair sharing mechanism is necessary for steady bandwidth. A steady up-path is
used solely by the \AD that requested it, and its use is monitored by the \AD,
which splits the steady up-path bandwidth between its end hosts. In contrast,
steady down-paths need to be revealed to several potential source \ADs, either
as \emph{private} steady down-paths (e.g., for a company's internal services),
or as \emph{public} steady down-paths (e.g., for public services). To
prevent a botnet residing in malicious source \ADs from flooding steady
down-paths, \name uses a weighted fair sharing scheme similar to ephemeral
paths: each \AD using a steady down-path obtains a fair share proportional to
its steady up-path, and its ISD's core path. We give the details of the scheme
in Appendix~\ref{appendix:sharing-down-paths}.

\paragraph{Efficient bandwidth usage via statistical multiplexing}
Internet traffic often exhibits a cyclical pattern, with alternating levels of
utilized bandwidth.
In situations of low utilization, fixed
allocations of bandwidth for steady and ephemeral paths that are
unused would result in a waste of bandwidth. \name reduces such
bandwidth waste through statistical multiplexing,
i.e., unused steady and ephemeral bandwidth is temporarily given to
best-effort flows. A small slack of unallocated steady and ephemeral
bandwidth still remains to accommodate new steady and ephemeral
bandwidth requests. As more and more entities demand steady paths and
their fair share of ephemeral paths, \name gradually squeezes
best-effort flows and releases the borrowed steady and ephemeral
bandwidth up to the default allocations.

\paragraph{Renewal} End hosts can launch ephemeral path renewals to increase
the reserved bandwidth and extend the expiration time of the ephemeral path.
Since ephemeral reservations have a short lifetime, they are frequently
renewed. Renewals are launched using the old reservation which contains the
bandwidth class of the reservation; therefore routers can rapidly decide on the
fastpath how much bandwidth they should allocate for the renewal, for instance
if the bandwidth increased, decreased, or remained the same. Reservations are
given a , incremented for each renewal of a specific
ephemeral path. Reservations can be renewed anytime before they expire, and the
end host is allowed to switch to the newer reservation at any time. However,
the end host is not allowed to use both the old and the renewed reservation at
the same time; \autoref{sec:mon_renew} shows a mechanism to detect such
misbehavior.


\subsection{Priority traffic monitoring and policing}
\label{sec:mon}

\noindent Flows that violate their reservations may undermine the
guarantees of other legitimate flows. An ideal monitoring algorithm
should immediately catch \emph{every} such malicious flow. This,
however, would be too expensive for line-rate traffic in the Internet
core.

Instead, as the first line of defense, \name relies on edge \ADs to perform fine-grained traffic
monitoring.  Edge \ADs rely on flow IDs to check each flow's bandwidth usage
and compare it against the reserved bandwidth for that flow ID, which is stored
by each \AD locally during the reservation request.  Previous research has
shown that per-flow slowpath operations are feasible at the edge of the
network~\cite{Stoica2003}.

Monitoring on transit \ADs, however, needs to be processed on the fastpath.  To
detect misbehaving \ADs that purposely fail to regulate their own traffic,
\name deploys a lightweight monitoring mechanism in transit \ADs. First, each
\AD monitors the bandwidth usage of incoming traffic from each neighbor \AD and
compares it against the \emph{total} bandwidth reserved for that neighbor. Such
coarse-grained monitoring timely detects a misbehaving neighbor that
failed to correctly police its traffic.

\begin{figure}[t]
  \begin{center}
    \includegraphics[width=0.9\linewidth]{monitoring.pdf}
  \end{center}
  \vspace{-3mm}
  \caption{Per-neighbor monitoring may label benign  malicious.}
  \vspace{-7mm}
  \label{fig:monitoring}
\end{figure}

\paragraph{Why per-neighbor monitoring is insufficient} There are cases,
though, when per-neighbor monitoring in transit \ADs is insufficient.
\autoref{fig:monitoring} depicts two flows originating in , each having
reserved  Mbps. Flow 1 is malicious and sends traffic with  Mbps, while
flow 2 underuses its reservation.  hence does not properly monitor its
flows.  When  performs per-neighbor monitoring, it can only notice that,
in the aggregate, it receives  Mbps from  and sends  Mbps to .
However, when the two flows diverge,  detects flow 1 as malicious and
holds  responsible, although  properly performed per-neighbor
monitoring. 

For this reason, \name additionally utilizes \textit{fine-grained} probabilistic
monitoring of individual flows at the transit \ADs, using a a recently proposed
technique~\cite{hao}. Each transit \AD monitors, per given time interval, all
the flows in a number of randomly chosen bandwidth classes.  Recall that the
bandwidth class of a flow is authenticated by the RTs in the packet header.  In
case the average bandwidth utilization of a flow during that time interval
exceeds the flow's bandwidth class, the flow is classified as malicious and
added to a blacklist, preventing its renewal.
  

We emphasize that transit \ADs perform monitoring on the fastpath.  Only in
case of suspicion of misbehavior, these \ADs perform out-of-band slowpath
monitoring to police misbehaving neighbors and flows.

To localize the origin \AD of the malicious flow, an \AD informs the previous
\AD of the misbehaving flow. In response, the previous \AD can simply monitor
that specific flow explicitly.  If the violation persists, the suspicious
previous-hop neighbor is likely to be malicious. Then, the \AD can punish it,
for instance, by terminating their contract.


\subsection{Flow renewal monitoring and policing}\label{sec:monitoring-policing}
\label{sec:mon_renew}

\noindent
A successful ephemeral path renewal replaces the old
reservation, therefore the renewal receives the same flow ID as the old
reservation.  However, \name paths allow for RTs with
overlapping validity periods. Therefore, if multiple renewals occur before the
ephemeral path expires, the source would be in possession of multiple sets of
valid RTs: Some corresponding to the ephemeral path with the previous bandwidth class
and old expiration time, and the others corresponding to the new values for
bandwidth class and expiration time, along the same path.  Since all sets of
RTs are associated with the same flow ID, routers would overwrite their
per-flow entries with the new bandwidth class.

A malicious end host could thus exploit renewals by using both sets of RTs, old
and new, during the overlap time of the RTs, thus using more bandwidth than the
amount reserved. To prevent such misuse, end hosts are not allowed to use old
RTs after having used the renewed RTs. When renewals use the same bandwidth
class as the old reservation, simultaneous use of old and new RTs is detected
by the per-class monitoring mechanism (as described above) since the usage is
jointly accounted under the same flow ID.

We now consider the case when the renewed bandwidth class is different from the
old one. The edge AS performs per-flow stateful inspection and is supposed to
filter out traffic that violates the sending rule. Therefore, the edge \AD can
be held accountable by other \ADs for improperly filtering traffic. In transit
\ADs, however, we propose a probabilistic approach for catching this type of
misbehavior. \ADs maintain one Bloom filter~\cite{bloom} per currently active
expiration time and per bandwidth class. Since an RT is maximally valid for 16
seconds and the time granularity is 4 seconds, 4 Bloom filters are needed per
bandwidth class, to record flow IDs that use the bandwidth class within that
time period. We will discuss the details about time discretization in \name in
\autoref{subsec:request}. For an incoming packet with a reservation in a
monitored class , \ADs simply store the tuple  in the Bloom filter of class . By
probabilistically inspecting some of these Bloom filters, each \AD notices
whether a flow ID uses two different bandwidth classes during a time period.

We further optimize the monitoring algorithm as follows. \name selects a small
number of classes to monitor at a given moment in time, therefore \ADs store
Bloom filters only for the few monitored traffic classes. In addition, \name
does not investigate all Bloom filters: We observe that, when the renewed
bandwidth is much higher or much lower than the previous bandwidth, using both
the old and new reservations would incur an insignificant bandwidth overuse.
Therefore, if a certain reservation index is used in class , \name
investigates only the Bloom filters of the classes whose bandwidth values are
comparable to 's bandwidth (the comparability of classes is discussed in
\autoref{subsec:request}).  \name investigates whether in these Bloom filters
an index  is present, where  chosen randomly ( detects whether the end host maliciously reuses
the same reservation index).  If found, \ADs increment a violation counter for
the source of that flow ID.  The violation counter allows for Bloom filter
false positives. When the violation counter exceeds a threshold, an alarm is
raised for that sender.  Therefore, the more packets an attacker sends, the
higher the probability of detection.  The policing push back technique can then
localize the source \AD of the misbehaving flow. 

\subsection{Dealing with failures}

\noindent
While bandwidth guarantees along fixed network paths allow for a
scalable design, link failures can still disrupt these paths and thus render
the reservations futile. In fact, leaf \ADs and end hosts are rather
interested in obtaining a bandwidth guarantee than
obtaining a specific network path for their traffic.

\name deals with link failures using two mechanisms: (1)
a failure \emph{detection} technique to remove reservations along
faulty paths, and (2) a failure \emph{tolerance} technique to provide
guarantees in the presence of failures. For (1), \name uses short
expiration times for reservations and keep-alive mechanisms. Steady
paths expire within 3 minutes of creation, but leaf \ADs can extend
the steady paths' lifetime using keep-alive messages. Ephemeral paths
have a default lifetime of 16 seconds, which can be extended by
source end hosts through renewals. Unless keep-alive messages or
renewals are used, reservations are removed from the system within
their default expiration time. By construction, a new reservation
cannot be created on top of faulty paths. For (2), \name allows
leaf \ADs to register multiple disjoint steady paths. We also
envision source end hosts being able to choose a bandwidth
reservation service with high reliability, which would use a
small number of disjoint ephemeral paths to the same destination.

\subsection{Dynamic Interdomain Leased Lines}

\noindent Businesses use \emph{leased lines} to achieve highly reliable
communication links. ISPs implement leased lines virtually through reserved
resources on existing networks, or physically through dedicated network links.
Leased lines are very costly, can require weeks to be set up, and are
challenging to establish across several ISPs.

A natural desire is to achieve properties similar to traditional leased lines,
but more efficiently. GEANT offers a service called ``Bandwidth-On-Demand''
(BoD), which is implemented through the InterDomain Controller
Protocol~\cite{idcp} to perform resource allocations across the participating
providers~\cite{geant:bod}.  Although BoD is a promising step, the allocations
are still heavy-weight and require per-flow state.

With \name's properties, ISPs can offer light\-weight Dynamic Interdomain
Leased Lines (DILLs). A DILL can be composed by two longer-lived steady paths,
connected through a core path, or dynamically set up with an ephemeral path
that is constantly renewed. Thanks to the light\-weight operation of \name,
DILLs can be set up with an RTT setup message and are immediately usable. Our
discussions with operators of availability-critical services have shown that
the DILL model has sparked high interest among operators.

To enable long-term DILLs, valid on the order of weeks, the concept of
ephemeral paths in \name could be reframed: long-term DILLs could use the same
techniques for monitoring and policing as ephemeral paths, however, they would
also introduce new challenges.  To enable long-term DILLs, ISPs need to ensure
bandwidth availability even when DILLs are not actively used, as opposed to
ephemeral bandwidth, which can be temporarily used by best-effort flows.  For
this purpose, ISPs could allocate a percentage of their link bandwidth for
DILLs, besides steady, ephemeral, and best-effort paths. Additionally, for
availability in the face of link failures, ISPs would need to consider active
failover mechanisms. For instance, in architectures that provide path choice,
ISPs could leverage disjoint multipath reservations concentrated in a highly
available DILL.  A detailed design though is out of scope for this paper. 


