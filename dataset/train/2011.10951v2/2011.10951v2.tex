

\documentclass{article}

\usepackage{microtype}
\usepackage{graphicx}
\usepackage{subfigure}
\usepackage{booktabs} 

\usepackage{multirow}
\usepackage{mathrsfs}
\usepackage{amsmath}

\usepackage{amssymb}
\newcommand{\liu}{\color{red}}
\newcommand{\hvc}{\color{blue}}
\newcommand{\fin}{\color{black}}



\usepackage{subfigure} 

\usepackage{amsthm}
\theoremstyle{definition}
\newtheorem{definition}{Definition}
\newtheorem{theorem}{Theorem}
\newtheorem{lemma}{Lemma}
\newtheorem{corollary}{Corollary}

\usepackage{hyperref}

\newcommand{\theHalgorithm}{\arabic{algorithm}}



\usepackage[accepted]{icml2021}

\begin{document}

\twocolumn[
\icmltitle{Learning Class Unique Features in Fine-Grained Visual Classification}





\icmlsetsymbol{equal}{*}

\begin{icmlauthorlist}
\icmlauthor{Runkai Zheng}{e,j}
\icmlauthor{Zhijia Yu}{t}
\icmlauthor{Yinqi Zhang}{j}
\icmlauthor{Chris Ding}{d}
\icmlauthor{Hei Victor Cheng}{u}
\icmlauthor{Li Liu}{c}
\end{icmlauthorlist}

\icmlaffiliation{e}{Elecholic, Guangzhou, China}
\icmlaffiliation{j}{Jinan University, Guangzhou, China}
\icmlaffiliation{t}{Tsinghua University, Beijing, China}
\icmlaffiliation{d}{The Chinese University of Hong Kong Shenzhen, Shenzhen, China}
\icmlaffiliation{c}{Shenzhen research institute of big data, the Chinese University of Hong Kong Shenzhen, Shenzhen, China}
\icmlaffiliation{u}{Department of Electrical and Computer Engineering, University of Toronto, Toronto, Canada}

\icmlcorrespondingauthor{Li Liu}{liuli@cuhk.edu.cn}


\icmlkeywords{Machine Learning, ICML}


\vskip 0.3in
]

\printAffiliations{}
\begin{abstract}

A major challenge in Fine-Grained Visual Classification (FGVC) is distinguishing various categories with high inter-class similarity by learning the feature that differentiate the details. Conventional cross entropy trained Convolutional Neural Network (CNN) fails this challenge as it may suffer from producing inter-class invariant features in FGVC. In this work, we innovatively propose to regularize the training of CNN by enforcing the uniqueness of the features to each category from an information theoretic perspective. To achieve this goal, we formulate a minimax loss based on a game theoretic framework, where a Nash equilibria is proved to be consistent with this regularization objective. Besides, to prevent from a feasible solution of minimax loss that may produce redundant features, we present a Feature Redundancy Loss (FRL) based on normalized inner product between each selected feature map pair to complement the proposed minimax loss. Superior experimental results on several influential benchmarks along with visualization show that our method gives full play to the performance of the baseline model without additional computation and achieves comparable results with state-of-the-art models.

\end{abstract}

\begin{figure}[tb]
    \centering
    \includegraphics[width=0.9\linewidth]{Figure/ce_intro.pdf}
    \caption{Three images of similar bird species from CUB-200-2011 dataset are selected to present the major challenge in FGVC. The first row presents the original images and the second row presents the activation maps. The activation maps are obtained from forward propagating the image of Red Winged Blackbird to the CE trained CNN and extracting the penultimate layer feature maps. Then the channel that has the largest mean activation value is selected. An observation is that the same channel also has high activation value when we input the other two categories of images (Brewer Blackbird and Rusty Blackbird).}
    \label{fig:intro}
\end{figure}

Convolutional Neural Networks (CNN) achieves a great success in the computer vision domain. The large diversity in standard visual recognition tasks make it possible for CNN to well learn discriminative features by minimizing the cross entropy (CE) loss. When it comes to Fine-Grained Visual Classification (FGVC), different categories with highly similar appearance leads to inter-class invariants and intra-class variants, which limit the performance of standard CE trained CNN. 

Over the past few years, FGVC has attracted lots of attention in research community. Early works \cite{zhang2014part,bransonbird,wei2016mask} utilize multi-stage architecture that consists of a localization network and a classification network. The localization network is responsible for detecting discriminative regions, which requires bounding box or part annotations for training. Then the classification network works on the cropped regions given by the localization network. However, these approaches depend on annotations and cannot be trained end-to-end, thus lead to extra training cost. To solve the above mentioned challenges, recent approaches manage to develop end-to-end networks that only require weak supervision. Commonly these approaches outperform baseline models by mimicking human actions like attention mechanism and part localization \cite{zheng2017learning,fu2017look,sun2018multi,wang2018learning,chen2019destruction,ding2019selective,wang2020graph}. However, these works focus on discriminative parts on spatial domain. Even if the regions of interest are correctly cropped or detected, CNN will inevitably encode unnecessary information that may mix up with other categories. As shown in Fig. \ref{fig:intro}, the problem is, although the model can well localize the discriminative parts, the channel that responsible for detecting the feature will also be activated when encounter a similar texture. That means localization is not sufficient for learning a good feature if the filters can not precisely encode the unique feature. It is a challenge to extract the features that contain unique information about the categories.

In this work, we propose an explicit regularization objective for encoding unique features with a theoretical guarantee. Our motivation is based on an \textbf{assumption} that a unique feature should contain only the information of a specific category and not any other categories. In other words, for a given image, we expect the extracted features to be highly correlated with the target class without extra information about the non-target classes. We call this kind of features Class Unique Features (CUFs). To achieve this goal, we formulate CUF using the Mutual Information (MI), from which we deduce an explicit regularization objective, i.e., \textit{Maximum Non-Target distribution Entropy (MaxNTE)}. To efficiently optimize the objective, we propose a game theoretic framework to simplify the problem formulation. Under this game theoretic framework, the existence of Nash equilibria and the consistency between the outcome and our objective are proved rigorously. 

In summary, our contribution includes:
\begin{enumerate}
\item We innovatively formulate our assumption to an ideal CUF learner from an information theoretic perspective and deduce an explicit regularization objective.

\item We construct a game-theoretic framework between the model and the adversary. On this basis, we arrive at a simple yet efficient minimax (MM) loss to achieve the regularization goal. To reduce the feature redundancy brought by the minimax loss, we further propose a Feature Redundancy Loss (FRL), encouraging the model to focus on multiple discriminative parts, as a complement to the minimax loss.

\item Experimental results on influential benchmarks of both FGVC and standard visual classification show that our method outperforms the baseline models by a large margin and achieves state-of-the-art (SOTA) results on FGVC-Aircraft and Standard Cars dataset.
\end{enumerate}

\section{Related Work}

\subsection{Fine-Grained Visual Classification}
Recently, FGVC is a research hotspot in the field of computer vision. We mainly discuss related works according to the following three research branches.

\textbf{Attention mechanism and part localization} were explored to settle this problem, as the model is able to learn to pay attention to the region or features that contain inter-class variations. Benefited from the interaction of part learning and feature learning, Multi-Attention CNN (MA-CNN) was proposed in \cite{zheng2017learning} to extract part-based fine-grained features. 
\cite{fu2017look} utilized recurrent architecture to repeatedly crop and scale the regions of interest by attention mechanism.
\cite{sun2018multi} proposed One-Squeeze Multi-Excitation that generate multiple attention map based on Multi-Attention Multi Class Constraint to efficiently obtain the highly discriminative part.
\cite{wang2018learning} used  convolution kernel as a discriminative patch detector and designed an asymmetric, multi-channel structure to enhance the learning of discriminative mid-level patches.
\cite{chen2019destruction} shuffled the local regions to enforce the network to focus on the most discriminative patches.
\cite{ding2019selective} used sparse attention for feature sampling to capture detailed visual evidence without losing the context information.


\textbf{High-order statistics} were explored for aggregating features to improve the first-order statistics such as max pooling and average pooling because they were difficult to capture the diversity of features among different categories.
\cite{lin2015bilinear} produced an image descriptor via pooling the outer product from two CNN feature extractor sub-branches, which was able to model local pairwise feature interactions in a translational invariant manner.
\cite{gao2016compact} approximated bilinear pooling operation by applying low-dimensional approximation of the polynomial kernel to speed up the computation.
\cite{wang2019deep} inserted Matrix Power Normalized COVariance (MPN-COV) block into the final layer of convolutions to obtain a global representation by second order statics. 

\textbf{Regularization based methods} usually do not need extra computation and thus are much light weight compared with the above mentioned methods. They developed efficient training manner that can boost the performance of simple baseline models. \cite{dubey2018maximum} formulated the relation between model selection and feature diversity, and utilizing the idea of maximum entropy to minimize the lower bound of Frobenius norm of the weights and thus improved the performance of models in fine-grained visual tasks. \cite{dubey2018pairwise} minimized the L2 distance between the prediction probability distribution of the random sample pairs of the training set to confuse the network and prevent from overfitting. Our method is also based on regularization of output distribution, and thus can be a simple and lightweight tool to be used among similar tasks.

\subsection{Label smoothing}
Label smoothing \cite{szegedy2016rethinking} was first proposed to prevent deep learning model from overconfident in classification problem. The characteristic of softmax function makes it impossible for a model to convergent to the hard 0 and 1 targets \cite{Goodfellow-et-al-2016}. Thus the model may keep seeking for extreme prediction and become overfitting. Label smoothing introduces uniform noise distribution  to the ground truth labels by replacing 0 and 1 targets with  and , where  is a hyperparameter determines the amount of smoothing. Our method produces uniformly distributed probabilities on non-target class, which is similar to the ground truth of label smoothing. However, our method is different from label smoothing in terms of motivation, training manner and resulting outputs. 
More precisely, 1) our motivation is to achieve an assumption on MI between extracted features and output distribution, while LS is proposed to inject noise to the labels to prevent from extreme logits and overfitting.
2) We use a minimax loss to achieve our objective while LS directly takes the designed target to supervise the model.
3) In terms of the regularization results, our method leads to uniform distribution on non-target classes, but LS can not.

\subsection{Mutual Information}
Mutual Information (MI) is a measure of information in information theory, which indicates the mutual dependencies between two random variables. More specifically, it quantifies the amount of information about another random variable when one of the variables is observed. 
MI has been used in the field of deep learning. 
\cite{tishby2015deep} firstly showed that Deep Neural Networks (DNN) can be quantified by the mutual information between the layers and the input and output variables. They provide a novel perspective that the goal of DNN is to optimize Information Bottleneck (IB) trade off between compression and prediction. 
\cite{hjelm2018learning} wielded the rich knowledge about mutual information into the construction of encoder, called Deep InforMax (DIM), which maximized the mutual information between the inputs and the high-level representation. Belghazi et al. \cite{belghazi2018mutual} proposed Mutual Information Neural Estimator (MINE) and applied it to Generative Adversarial Networks (GANs) 
\cite{goodfellow2014generative} to improve the reconstruction quality and alleviate mode-drop in GANs. 
\subsection{Game Theory}
Game Theory provides mathematical models of strategic interaction among intelligent decision makers \cite{myerson1991game}. It is a mathematical theory and method to study the phenomenon of competition, and was studied in \cite{osborne2004introduction} the interaction between the formulaic incentive structures. With the increasing popularity of Artificial Intelligent, game theory has been applied to different fields including Multi-Agent Reinforcement Learning \cite{bowling2000analysis} and GANs \cite{goodfellow2014generative, goodfellow2016nips}. In this work, we apply the game theory to the object recognition task.

\section{Method}
Our goal is to extract features that do not contain information from non-target classes, i.e., CUF. This can be formulated by minimizing the MI between extracted feature and the non-target output distribution. By the formulation, we further deduce a regularization objective, where a key finding is derived (i.e., all output probabilities over non-target classes should be uniformly distributed). To efficiently optimize this objective function, we propose a minimax loss to simplify the reformulated regularization objective. 

\subsection{Mutual Information based Problem Formulation}

 We denote the input space by , the label space by , where  is the number of classes. 
 The training data are all i.i.d sample pairs , where  is in the form of a -dimensional one-hot vector.

Let  be a parametric function mapping from the input space to the feature space. 
Overall parameter set of the model is . Consider one of the \textbf{fix target categories }, and the corresponding input  (i.e., images that belong to the class ).  is the predicted output of non-target classes with distribution , where . Note that all the random variables  are dependent on input , here we omit the dependence for brevity.

The problem formulation can be written as minimizing the MI between predicted output of non-target classes  and extracted features , i.e. . However, this MI cannot be computed in practice as the distribution of  is intractable. To resolve the intractability issue, we apply the data processing inequality \cite{information_theory} and use the obtained upper bound, the MI between input  of class  and predicted output of non-target classes , as our objective:

where  represents the mutual information under model parameter .

According to the property of MI, i.e., , where  is the entropy, and  are two random variables, Eq. \ref{equ:objective1} can be decomposed into the difference between entropy and conditional entropy:

where  denotes the entropy under model parameter . Computing  involves the marginalization over  which is computationally intractable in practice. Thus, instead of directly optimizing Eq. \ref{equ:objective1}, we consider optimizing its upper bound. From the fact that entropy reaches its upper bound when all the probabilities are equal, we have:



The following lemma gives a theoretic justification for using the upper bound to replace Eq. \ref{equ:objective1}.
\begin{lemma}\label{lemma1}
    When the conditional probability distribution over non-target classes is uniform, the MI in Eq. \ref{equ:objective1} is 0, and hence .
\end{lemma}

Lemma \ref{lemma1} shows that making the conditional distribution of the non-target classes uniform is desired. Thus we formulate the problem using the upper bound as maximizing , which promotes the distribution to be uniform. When the mutual information is , this suggests that the extracted features contains no information about the non-target classes.

In practice, we maximize the empirical conditional entropy for each class :

where  is the number of training samples in class .

We use the empirical conditional entropy as a regularization term with a weight parameter  into the CE objective function to form the overall objective function (i.e., \textbf{MaxNTE}):


Here,  has a reachable upper bound. However, directly taking this as the objective function may not be the best choice for our goal, since the gradients become extremely small when closing to the upper bound. From Lemma \ref{lemma1}, we know a sufficient condition for  is to enforce the conditional distribution of non-target classes to be uniform. In the following, we propose an efficient minimax loss based on game theory to achieve this target, which is lightweight and also insensitive to the choice of hyper-parameter. The comparison of MaxNTE and the new proposed loss will be provided in the experiments.
\begin{figure*}[t]
    \centering\centerline{\includegraphics[width=0.75\linewidth]{Figure/framework.pdf}}
    \caption{(a) During the training phase (before convergence), the model keep promoting the smallest probability in the non-target model output by assign  to the index of the minimum value in , i.e..,  in (a). (b) After iterations of training, the model output distribution will finally be uniformly distributed over non-target classes. When reaching a convergence, a Nash equilibrium exists between the optimal solution of the model and the adversary.}
    \label{fig:overview}
\end{figure*}
\subsection{Game Theoretic Framework}
In this section, we introduce the game theoretic framework in detail. The resulting loss function will be shown in Eq. \ref{eq:MPP}, which is used as the major part of our main method in the experiments.
\subsubsection{Preliminaries}
Here we introduce some basic game-theoretic definitions \cite{myerson1991game} that we will use later.

\begin{definition} \label{game}
A strategic game is a tuple , where  is a nonempty set of players,  is the set of actions available to each player ,  is the profiles of actions and  defines the payoff function for each player .  
 A two player strictly competitive game or zero-sum game is the strategic game  with  and for all :

\end{definition} 

\begin{definition}
   A mixed strategy set  is the set of all probability distributions over .  defines a mixed strategy for each player , and  is the probability that player  plays . In a two player game, the expected payoff of player  playing a mixed strategy against pure strategy  can be calculated as:
   
   Likewise, the expected payoff of playing a pure strategy  against mixed strategy can be calculated as:
   
   where  denotes the player other than .
\end{definition}

\begin{definition} \label{response}
Let  be the strategic game,  be a player, and  be a strategy profile of players other than . Then a strategy  is a \textit{best response} of player  to  if:

\end{definition}

\begin{definition} \label{nash}
A \textit{Nash equilibrium} of the strategic game  is a action profile  such that for every player ,  is the best response to .
\end{definition}

\subsubsection{ zero-sum strategic game}
We define a zero-sum strategic game played between the \emph{model} and a designed \emph{adversary} with loss of the model defined as . 
 We let  be the ground truth label vector, normally one-hot encoding, while in our work we specifically design it for the objective.
Here,  is the strategy of the adversary and  is the strategy of the model. We assume that the model is a classifier with confidence  on the target class. The model aims to assign the rest of the probability  to non-target classes to minimize the loss. The adversary is the controller of the ground truth with fixed  for the target class, and it aims to maximize the loss via adjusting the distribution on non-target class of . This is a dynamic game that the two players play in order, in which the model goes first, and the adversary can adjust the strategy according to the previous action of the model. Fig. \ref{fig:overview} gives an overview of the proposed game theoretic framework.

\begin{definition}
For , the defined strategic game is a tuple  with:

\end{definition}

By Definition \ref{game},  is a two-player zero-sum game. In the following, we will prove the existence of Nash equilibrium.
\begin{theorem} \label{adversary}
For , we have:

where : 

for any .

\end{theorem}

Note that in the rest of the paper, if there exists more than one minimum value in ,  refers to randomly taking one of them.

\begin{theorem} \label{model}
For , we have:

where

\end{theorem}

Theorem \ref{adversary} gives the worst case payoff for the model . However, since  depends on the index of the minimum value in , they are not the best responses to each other. For example, when , the adversary chooses one of the indexes of the minimum values in  to determine . Once  is fixed,  is no longer the best responses to , since there exist a better  to get a higher payoff (e.g., change the position of the minimum value). Thus, we need randomize  to avoid this situation. Specifically, when , the model uniformly distributes the probabilities over non-target classes. The adversary can randomly choose one of them since they are all the smallest value and the adversary's strategy becomes a mixed strategy. In this case, the two strategies form a Nash equilibrium. To show this mathematically, we give the following theorem.
\begin{theorem}
    Define an action subset for the adversary:
    
    where \}. 
    
    For the model:
    
    Then we have the following strategies: 
    
    
    such that  forms a Nash equilibrium.
    \label{the:theorem 3}
\end{theorem}
The detailed proofs of the three theorems are in Appendix.

\subsubsection{Minimax Loss}
The Nash equilibrium in a two player zero-sum game is equivalent to a minimax solution \cite{ferreira2012minimax}. Thus, by training with the worst-case payoff , we expect that the model output ultimately converges to the best response .
Finally our proposed \textbf{minimax loss (MM)} is defined as: 


where .
Here, we leave  as a hyper-parameter to weight the regularizer of the objective corresponding to the class . When  is set to 1 for all classes, the loss function is equivalent to the standard CE loss. It is worth noting that, in regularization methods such as label smoothing and confidence penalty, the number of log operations increases with the number of categories. MM has only one more log operation than the cross entropy loss, while gains more performance in many tasks.

\begin{figure}[tb]
    \centering
    \includegraphics[width=\linewidth]{Figure/redundancy.pdf}
    \caption{The feature redundancy problem in MM trained model. As shown in the first row, the three channels with the largest activation values detect the same region of the bird. That means the model's prediction is over dependent on the single feature. Once the region is cropped, as shown in the image below, the model cannot correctly predict the object category. The introduced FRL is shown to be able to eliminate this problem.}
    \label{fig:redundancy}
\end{figure}

\subsection{Feature Redundancy Loss}
MM promotes the feature uniqueness of each category. There may exist more than one solutions that having this property. In some cases, the obtained features can be redundant, different feature maps of a specific category are almost the same, as shown in the first row of Fig. \ref{fig:redundancy}. We want the extracted features to be more diverse, because single feature can be unreliable especially when the training set is small. Combining multiple features for decision can avoid wrong prediction under unexpected cases such as occlusion and make the model more robust. The second row of Fig. \ref{fig:redundancy} shows the case that one of the important regions is blocked, in which MM trained model that rely on single feature fails to make a correct prediction. Therefore we add an additional regularization term to choose more diverse features while maintaining the class uniqueness.

To enforce the difference of feature maps, we use normalized inner product to measure the similarity among feature maps of top activation as a loss function, named Feature Redundancy Loss. Specifically, in each forward sample, we select the feature maps that has top  activation values before global average pooling. Let the shape of the selected feature maps  from a sample  be , we calculate the normalized inner product between each pairs.

The loss can be calculated parallelly using tensor operation, thus a simple yet efficient trick. Our final loss is the weighted sum of MM and FRL:


\section{Experiments}
\subsection{Experimental Setup}
For evaluating our method, we use the following three benchmarks: CUB-200-2011 \cite{wah2011caltech}, FGVC-Aircraft \cite{maji2013fine}, Stanford Cars \cite{KrauseStarkDengFei-Fei_3DRR2013}. Further more, we assesses the effect of our method on standard visual classification benchmarks: CIFAR-10 \cite{krizhevsky2009learning}, CIFAR-100 \cite{krizhevsky2009learning}, STL-10 \cite{coates2011analysis}. Different methods are compared using ResNet18 \cite{he2016deep}, VGGNet11 \cite{simonyan2014very}, DenseNet161 \cite{huang2017densely} as the backbone models. The statistics of six datasets and the implementation details are introduced in Appendix.

\begin{figure}[t]
    \centering
    \subfigure[]{
        \centering
        \includegraphics[width=1.5in]{Figure/hyper_standard.pdf}
    }
    \hspace{1mm}
    \subfigure[]{
        \centering
        \includegraphics[width=1.5in]{Figure/hyper_mpp.pdf}
    }
    \caption{Comparison between MM trained and MaxNTE loss trained models. Non-target classes entropy (scale using left vertical axis) and test accuracy (scale using right vertical axis) are shown. The entropy upper bound 2.197 is shown as the blue dotted line. We see that MM trained model reaches this upper bound, while MaxNTE trained model does not.}
    \label{fig:comparison with MaxNTE}
\end{figure}

We first compare our proposed MM with MaxNTE. Then we quantitatively compare our proposed method with different methods on FGVC tasks  as well as the standard visual classification tasks. Finally we conduct visualization to further show the effect of our method.

\subsection{Comparison between MaxNTE and MM}
We compare MM with the MaxNTE that directly minimize Eq. \ref{equ:objective3} on CIFAR-10 dataset. Note that when  set to 1 for all classes (i.e.  set to 0) and  set to 0, both of the losses are equal to the cross entropy loss. In MaxNTE, as shown in Fig. \ref{fig:comparison with MaxNTE}, the left figure, the test accuracy is decreasing when  is increasing, the maximum entropy reaches its bottleneck at about 2.12. The right figure shows that as  (hyperparameter) increases, the entropy gradually approaches its upper bound () with stable test accuracy. The results show that MM can achieve our goal in a more efficient way, thus we apply it to the following experiments.

\subsection{Quantitative results}

\paragraph{Fine-Grained Visual Classification} From Table \ref{comparison with baseline model}, our proposed method improves the performance of three baseline models (i.e., ResNet-18, VGGNet-11 and DenseNet-161) across all three datasets (i.e., CUB-200-2011, FGVC-Aircraft and Stanford Cars). For example, training VGGNet-11 with MM obtained significant improvements of 2.50\% on average across three datasets compared with CE. LS performs better than CE since it also encourages the model to produce an output close to our objective. Besides, DenseNet-161 with MM achieves best results compared with other baselines.
\begin{table}[b]
\centering
\scriptsize
\caption{Comparison with three baseline models.}
\label{comparison with baseline model}
\begin{tabular}{c|c|c|c|c}
    \hline
    \hline
    Backbone & Method & CUB & Aircraft & Cars \cr
    \hline
    \hline
    \multirow{3}{40pt}{\centering {ResNet-18}} 
    & CE & 81.32  0.31 & 89.89  0.14 & 88.50  0.21 \cr
    & LS & 81.83  0.22 & 89.77  0.27 & 91.06  0.18 \cr
    & MM & \bf{83.14  0.18} & \bf{90.37}  0.14 & \bf{91.74  0.11} \cr
    \hline
    \multirow{3}{40pt}{\centering {VGGNet-11}} 
    & CE & 77.76  0.28 & 85.38 s 0.66 & 87.32  0.47 \cr
    & LS & 77.94  0.23 & 87.57  0.19 & 89.46  0.32 \cr
    & MM & \bf{80.41  0.15} & \bf{87.72}   0.22 & \bf{89.83  0.28} \cr
    \hline
    \multirow{3}{40pt}{\centering {DenseNet-161}} 
    & CE & 86.69  0.32 & 90.94  0.15 & 94.21   0.12 \cr
    & LS & 87.63  0.15 & 92.65  0.21 & 94.27  0.16 \cr
    & MM & \bf{87.98  0.14} & \bf{93.34  0.19} & \bf{94.72  0.11} \cr
    \hline
    \hline
\end{tabular}
\end{table}

The overall experimental results compared with recent works including SOTA are shown in Table \ref{comparison with sota}. Our methods outperforms regularization-based methods (e.g. MaxEnt and PC) across all three datasets. While SOTA models achieve excellent results, they rely on extra structure or computational cost. Our proposed methods can fully bring out the potential of the baseline models and achieve SOTA in FGVC-Aircraft and Stanford Cars by only regularization. 

\begin{table}[t]
\centering
\scriptsize
\caption{Comparison with SOTA methods. * means the best performance among regularization-based methods.}
\label{comparison with sota}
\begin{tabular}{c|c|c|c}
    \hline
    \hline
    Method & CUB & Aircraft & Cars \cr
    \hline
    \hline
    B-CNN (\cite{lin2015bilinear})      & 84.1 & 84.1 & 91.3 \cr
    CBP (\cite{gao2016compact})         & 84.3 & 84.1 & 91.2 \cr
    KP (\cite{cui2017kernel})           & 86.2 & 86.9 & 92.4 \cr
    iSQRT-COV (\cite{li2018towards})    & 88.7 & 91.4 & 93.3 \cr
    MA-CNN (\cite{zheng2017learning})   & 86.5 & 91.8 & 92.8 \cr
    RA-CNN (\cite{fu2017look})          & 85.3 & 92.5 & 93.0 \cr
    MAMC (\cite{sun2018multi})          & 86.5 & ---  & 93.0 \cr
    DFL-CNN (\cite{wang2018learning})   & 87.4 & ---  & 93.8 \cr
    NTS-Net (\cite{yang2018learning})   & 87.5 & 91.4 & 93.9 \cr
    MaxEnt (\cite{dubey2018maximum})    & 86.5 & 89.2 & 92.9 \cr
    PC     (\cite{dubey2018pairwise})   & 86.9 & 89.8 & 93.0 \cr
    DCL (\cite{chen2019destruction})    & 87.8 & 93.0 & 94.5 \cr
    S3N (\cite{ding2019selective}       & 88.5 & 92.8 & 94.7 \cr
    DF-GMM (\cite{wang2019weakly}       & 88.8 & 93.8 & 94.8 \cr
    MGE-CNN (\cite{zhang2019learning}   & 89.4 & ---  & 93.9 \cr
    GCL (\cite{wang2020graph}           & 88.3 & 93.2 & 94.0 \cr
    API-Net (\cite{zhuang2020learning}) & \bf{90.0} & 93.9 & \bf{95.3} \cr
    ELoPE (\cite{hanselmann2020elope}   & 88.5 & 93.5 & 95.0 \cr
    DFL (\cite{liu2020filtration}       & 89.1 & 93.4 & 94.3 \cr
    CIN (\cite{gao2020channel})         & 88.1 & 92.8 & 94.5 \cr
    ACNet (\cite{ji2020attention}       & 88.1 & 92.4 & 94.6 \cr
    \hline
DenseNet161+MM(Ours)                & 88.0 & 93.3 & 94.7 \cr
    DenseNet161+MM+FRL(Ours)            & \bf{88.5}* & \bf{94.0} & \bf{95.2}* \cr
  \hline
\hline
\end{tabular}
\end{table}

\begin{table}[b]
\centering
\scriptsize
\caption{Comparison with three baseline models on standard visual classification tasks.}
\label{comparison with standard vc}
\begin{tabular}{c|c|c|c|c}
    \hline
    \hline
    Backbone & Method & CIFAR-10 & CIFAR-100 & STL-10 \cr
    \hline
    \hline
    \multirow{4}{40pt}{\centering {VGGNet-11}} 
    & CE  & 92.260.08 & 70.370.33 & 79.800.31 \cr
    & CP  & \bf{92.620.05} & 70.300.19 & 80.170.14 \cr
    & LS  & 92.280.06 & 71.340.07 & 80.410.08 \cr
    & MM & 92.430.06 & \bf{71.620.18} & \bf{82.260.09} \cr
    \hline
    \multirow{4}{40pt}{\centering {ResNet-18}} 
    & CE  & 94.940.12 & 75.790.03 & 83.440.23 \cr
    & CP  & 95.110.01 & 76.010.31 & 83.750.02 \cr
    & LS  & 95.080.11 & 76.240.21 & 84.030.01 \cr
    & MM & \bf{95.330.12} & \bf{76.640.07} & \bf{85.420.04} \cr
    \hline
    \hline
\end{tabular}
\end{table}

\paragraph{Standard Visual Classification} We compare our method with two output regularization based methods: Confidence Penalty (CP)\cite{pereyra2017regularizing} and Label Smoothing (LS)\cite{szegedy2016rethinking}. As shown in Table \ref{comparison with standard vc}. our method outperforms several output regularization based methods across almost all the datasets and architectures. In CIFAR-10 and CIFAR-100, the improvements are not significant, and the test accuracy of VGGNet-11 with confidence penalty is slightly higher than that of our method in CIFAR-10. In STL-10, our method outperforms three baselines by a large margin.

\paragraph{Ablation Study}
We perform ablation experiments to show how different parts of our method work. As shown in Table \ref{ablation}, both MM and FRL greatly improves the performance of the baseline model. MM brings greater improvement overall, because CE can not precisely encode the unique feature even with FRL. Moreover, as FRL works by reducing the similarity of different feature maps, the effect of FRL on baseline model shows that feature redundancy also exists in regular training using CE. It is worth noting that hyper-parameters ,  and  have little affect on the proposed MM and FRL.

\begin{table}[b]
\centering
\scriptsize
\caption{Ablation study using DenseNet-161 as the baseline model.}
\label{ablation}
\begin{tabular}{c|c|c|c|c}
    \hline
    \hline
    Minimax & FRL & CUB & Aircraft & Cars \cr
    \hline
    \hline
    &  & 86.69  0.32 & 91.26  0.15 & 94.21  0.12 \cr
     &  & 87.98  0.14 & 93.34  0.19 & 94.74  0.11\cr
    &  & 87.14  0.16 & 92.71  0.48 & 94.71  0.04 \cr
     &  & \bf{88.48  0.24} & \bf{93.96  0.11} & \bf{95.18  0.14}\cr
    \hline
    \hline
\end{tabular}
\end{table}


\subsection{Qualitative Result}

\begin{figure}[t]
    \centering
    \includegraphics[width=\linewidth]{Figure/comp_bl_mm.pdf}
    \caption{The comparison of the learned filters of models trained with CE and our MM. We select the three images of similar bird species to demonstrate the effect of our method. The two channels with the largest activation values according to the forward pass of Red Winged Blackbird (the images in the first row) are presented. Although CE trained filters are able to capture the important features, they are confused with other categories. MM trained filters can extract precisely the unique features which will not be activated when encounter similar objects.}
    \label{fig:cam_1}
\end{figure}

\begin{figure}[ht]
    \centering
    \includegraphics[width=\linewidth]{Figure/comp_bl_mm_frl.pdf}
    \caption{The comparison of the filters with largest activation values of different models. The left side present the original image. On the right side, the first row is the model trained with CE as the baseline. The second row is the model trained with MM and the third row is the model trained with MM and FRL. Compared with baseline, MM minimizes the activation of irrelevant regions, so as to produce a clear and focused activation map. On the basis of the effect of MM, FRL encourages the model to focus on different discriminative regions.}
    \label{fig:cam_2}
\end{figure}

To show in detail how our approach works, we visualize the penultimate layer feature maps with top activation values. We up-sample the feature maps to match the original image by bi-linear interpolation. As shown in Fig. \ref{fig:cam_1}, CE trained model (in the first row, column 2, 3) correctly localize the important parts of the bird, but it will cover irrelevant areas, which may lead to false triggering of other features (see the second and the third row). The filters trained by MM that responsible for detecting the unique features of Red Winged Blackbird do not response to other species as CE trained filters do. 

Fig. \ref{fig:cam_2} shows the second row demonstrate the different effects of our proposed MM and FRL. With our regularization, the model become more concentration so as to avoid introducing information about irrelevant categories. However, the regularization objective will lead to redundancy features, i.e. all the feature maps point on the same area, which means that the model become overdependent on single feature, and may be harmful for generalization. FRL well eliminates this problem by forcing the model to distract its attention. The final results are shown in the last row of Fig. \ref{fig:cam_2}, the model attention become both focused and diversified. With a clearer activation maps, we can better see how the model works.

\section{Conclusion}
In this work, we provide an information theoretic point of view, to address the major challenge in FGVC, i.e., learning the features unique to categories. We formulate the aim to minimizing the MI between the learned features and non-target classes, based on which we deduce an explicit regularization objective. To efficiently achieve our objective, we construct a game-theory based framework to derive a stable minimax loss, which is proved to converge to a Nash equilibrium. Furthermore, FRL is proposed to avoid over depending on single feature as a complement of MM. As a result, the model is able to extract the most distinctive parts of the object and reduce the influence of background noise. By only regularization, our proposed methods bring the potential of the baseline models into full play and achieves competitive results with SOTA models without extra computational cost.
\bibliography{arxiv}
\bibliographystyle{icml2021}

\end{document}