







\documentclass[final,3p,times]{elsarticle}




\usepackage{amsmath,amssymb,amsfonts}
\usepackage{color}
 \usepackage{amsthm}




\newcommand{\owa}{\mbox{OWA}}
\newcommand{\pii}{{\pi(i)}}
\newcommand{\RM}{\mathbb{R}^m}
\newcommand{\RP}{\mathbb{R}^p}
\newcommand{\R}{\mathbb{R}}
\newcommand{\opt}{\mbox{opt}}
\newcommand{\vij}{v_{i}^{j}}
\newcommand{\ej}{e^{j}}
\newcommand{\Sol}{\mathcal{T}}
\newcommand{\blue}{\mbox{\tt blue}}
\newcommand{\red}{\mbox{\tt red}}
\newtheorem{defn}{\bf Definition}
\newtheorem{prop}{\bf Proposition}
\newenvironment{pf}[1][]{{\noindent \bf Proof. #1 }}{\hfill \\ }

\newtheorem{thrm}{Theorem}
\newtheorem{defi}{Definition}
\newtheorem{axio}{Axiom}
\newtheorem{example}{Example}
\newtheorem{lemme}{Lemma}
\newtheorem{propr}{Property}

\def\keyw#1{{\bf#1}}
\def\tab{\hspace*{5mm}}

\newsavebox{\fminibox}
\newlength{\fminilength}

\newenvironment{fminipage}[1][\linewidth]{\vspace{\parsep}
    \setlength{\fminilength}{#1}\setlength{\fboxrule}{0.5pt}
    \setlength{\fboxsep}{1.5mm}
    \addtolength{\fminilength}{-2\fboxsep}\addtolength{\fminilength}{-2\fboxrule}\begin{lrbox}{\fminibox}\begin{minipage}{\fminilength}}
  {\end{minipage}\end{lrbox}\noindent\fbox{\usebox{\fminibox}}\vspace{\parsep}}

\def\algo#1#2#3{\begin{fminipage}{{\bf Algorithm~}{\sc#1}\\{\bf Input~:~}#2\\{\bf Output~:~}#3\\}}
\def\endalgo{\end{fminipage}}


\journal{Computers \& Operations Research}

\begin{document}

\begin{frontmatter}







\title{Exact algorithms for -optimization in multiobjective\\ spanning tree problems}
\author[LIP6]{Lucie Galand}
\ead{lucie.galand@lip6.fr}
\author[LIP6]{Olivier Spanjaard\corref{cor1}}
\ead{olivier.spanjaard@lip6.fr}
\address[LIP6]{LIP6-CNRS, Universit\'e Pierre et Marie Curie (UPMC), 104 Avenue du Pr\'esident Kennedy, F-75016 Paris, France}
\cortext[cor1]{Corresponding author.}


\begin{abstract}
This paper deals with the multiobjective version of the optimal
spanning tree problem. More precisely, we are interested in determining the optimal
spanning tree according to an \emph{Ordered Weighted Average} (OWA) of its objective values. We first show that the problem is
weakly NP-hard. In the case where the weights of the OWA are strictly decreasing, we then propose a mixed integer programming formulation, and provide dedicated optimality conditions yielding an important reduction of the size of the program. Next, we present two bounds that can be used to prune
subspaces of solutions either in a shaving phase or in a branch and bound procedure. The validity of these bounds does not depend on specific properties of the weights (apart from non-negativity). All these exact resolution algorithms are compared on the basis of numerical experiments, according to their respective validity scopes. 
\end{abstract}

\begin{keyword}
Multiobjective spanning tree problem \sep ordered weighted
  average \sep MIP formulation \sep optimality conditions \sep branch and bound 


\end{keyword}

\end{frontmatter}



\section{Introduction}
\label{intro}
Multiobjective combinatorial optimization deals with problems
involving multiple viewpoints \cite{Ehrgo05}. More formally, the
valuation structure of such problems is made of vectors (each
component representing a specific viewpoint) instead of scalars. All
popular single objective optimization problems (e.g., valued graph
problems, integer linear programming...) can be recasted in this
setting, and solution algorithms must be proposed. Two types of
approaches can be studied: either one looks for a best compromise
solution according to a given aggregation function (e.g., max
operator, Chebyshev's norm to a reference vector \cite{Wierz80},
ordered weighted average \cite{Yager88}, Choquet integral
\cite{Grabi96}), or one aims at generating the whole set of
Pareto-optimal solutions (i.e., solutions that cannot be improved on
one objective without being depreciated on another one). Computing this set (also called
the Pareto set) is natural when no preferential information is available 
or when the available information is unsufficient to elicit the parameters of the aggregation function: the solutions in the Pareto
set are indeed the only ones likely to be selected by any rational
decision maker. The interest in this approach has spawned a
substantial literature (for a survey on the topic, the reader can
refer to several quite recent papers \cite{EhrgG00,EhrgG04}). However,
the number of Pareto-optimal solutions can grow exponentially
with the size of the instance \cite[e.g.][]{HamaR94,Hanse80} and the number
of objectives \cite{Rosin91}. The
examination of the whole set of Pareto-optimal solutions can therefore become
quickly awkward. Furthermore, focusing on one particular compromise solution
makes it possible to considerably speed up the resolution
procedure. Consequently, for practicality and
efficiency reasons, the search for a best compromise solution seems to be a
better approach when an aggregation function is available. This is the approach we study in this paper. 

More precisely, we investigate here the multiobjective version of the
optimal spanning tree problem. This problem arises naturally in
various contexts. For example, consider a broadcasting network where
the values of the edges represent bandwidths. Assuming that the
bandwidth of a chain equals the minimum bandwidth over its edges, it
is well-known that, in a maximal spanning tree, the bandwidth between
two nodes is the maximum possible. When there are several scenarios of
traffic (impacting the values of the bandwidths) or several opinions
of experts on the values of the bandwidths, the problem becomes
multiobjective. Previous works on the subject mainly deal with generating the whole Pareto set in the biobjective case \cite{AndJL96,HamaR94,SourS08,SteiR08}, or computing a min-max (regret) optimal solution when there are more than two objectives \cite{AisBV09,HamaR94,KouvY97,Warbu85,Yu98}. To our knowledge, there is therefore no operational algorithmic tool for this problem when there are more than two objectives and when the min-max (regret) criterion is not really suitable. The present paper precisely aims at tackling this gap, by providing algorithms able to optimize a less conservative decision criterion for any number of objectives. Provided the required preferential information is available, and provided the objectives are commensurate (which is the case in the above example for instance), we propose to resort to an averaging operator to compare
the vectorial values of the feasible solutions (spanning trees). According to the decision context, one may however want to put the emphasis on the best, the worst or the median evaluations of a solution. In other words, one needs to assign
importance weights not to specific objectives (scenarios, experts), but rather to
best and worst evaluations. The \emph{Ordered Weighted Average} (OWA)
precisely enables to model such concern. For this reason, we focus
here on the \emph{OWA-optimal spanning tree problem}, i.e. finding the
optimal spanning tree according to OWA in a multiobjective spanning
tree problem. 
In the case of strictly decreasing weights (favouring well-balanced
solutions), the use of an  objective function has been studied
by Ogryczak and Sliwinski \cite{Ogryc09,OgryS03} in continuous
optimization under linear constraints, and by Galand and Spanjaard \cite{GalaS07b} in multiobjective heuristic search. In this paper, we propose new algorithms specifically dedicated to the optimization of OWA in multiobjective spanning tree problems, some of which are able to handle not only strictly decreasing weights but also every other types of weights.

The paper is organized as follows. After recalling some preliminary
definitions and stating the problem, we give some insights into computational complexity (Section 2). Then, we provide a mixed integer programming formulation of the problem, as well as a preprocessing procedure based on optimality conditions for the -optimal spanning tree problem (Section 3). We then propose two -- efficiently computable -- alternative bounds for discarding subspaces
of solutions in either a branch and bound or a shaving procedure (Section 4). Finally, we provide numerical experiments to assess the operationality of the proposed methods (Section 5). 


\section{Preliminaries}
\label{sec:OWA}


\subsection{Multiobjective compromise search problem}
\label{sec:comp}

A \emph{multiobjective compromise search problem} is a
problem endowed with vectorial costs where one searches for a best
compromise solution according to a given aggregation function. A generic multiobjective compromise search problem can be formulated as a mathematical program.
We now introduce some notations for this purpose. 
We denote by  the set of feasible
solutions,  a vector valued function on , and  a multiobjective aggregation function. Within this setting, a multiobjective compromise search problem is written as follows: 

    

Denoting by  the \emph{image set} of  in the \emph{objective space} , problem  can be simply reformulated as . The -optimal spanning tree problem obviously belongs to this class of
problems. The resolution methods we propose hereafter for this problem are actually quite generic. 
The mathematical formulations of  will therefore be convenient to describe these methods in the sequel.
We now more specifically introduce the  operator and then the -optimal spanning tree problem.

\subsection{The  operator}
\label{sec:def}

Given a set  of objectives (to minimize), one can associate a vector in  to every feasible solution of a multiobjective problem. The comparison of solutions amounts then to comparing the corresponding vectors. Following several works in multiobjective optimization \cite[e.g.][]{Ogryc00,PernS03,PerSS06}, we propose to compare the vectors on the basis of their OWA value \cite{Yager88} (to minimize), defined as follows:

\begin{defi}
Given a vector  in , its ordered weighted average is =, where  and   ..   are the components of  sorted in non-increasing order.
\end{defi}

According to the decisional context, one can distinguish within the class of OWA operators two interesting subclasses depending on the definition of the weights:
\begin{itemize}
\item \emph{strictly decreasing weights}, i.e. : the set of weights naturally belongs to this class when
  performing robust discrete optimization. In \emph{robust
    optimization} \cite{KouvY97}, the cost of a solution depend on
  different possible scenarios (states of the world). The aim is to
  find a \emph{robust solution} according to this multiobjective
  representation, i.e. a solution that remains suitable whatever
  scenario finally occurs. The use of the  criterion in this setting is justified since it can be characterized by a set of axioms that are natural for modelling robustness \cite{PernS03}. More precisely, these axioms characterize an OWA criterion with strictly positive and strictly decreasing weights. Compared to
  the  criterion frequently used in robustness, the OWA
  criterion is less conservative since it enables trade-offs between
  several scenarios. Note however that the  criterion includes
  the  criterion as a special case, when one sets
  , , ,
   with 
  and  tends towards . Another interesting special
  case is obtained for ``big-stepped weights'', i.e. when the gaps
  between successive weights are huge (). The
   criterion reduces then to the leximax operator, which
  consists in comparing two vectors on the basis of their greatest
  component, their second greatest one in case of equality on the
  first one, and so on... This criterion refines thus the 
  criterion by discriminating between vectors with the same value on
  the greatest component.
\item \emph{non-monotonic weights}: one of the most famous decision criterion in decision under complete uncertainty (i.e., when several states of the world can occur, and no information is available about their plausibilities) is Hurwicz's criterion, that enables to model intermediate attitudes towards uncertainty (i.e., neither desperately pessimistic nor outrageously optimistic) by performing a linear combination of the maximum possible value of a solution under the different scenarios, and the minimum possible one. More formally, if  is the image of a solution in the objective space, then its value according to Hurwicz's criterion is: . Hurwicz's criterion clearly is a special case of the OWA criterion, obtained by setting ,  and  . As soon as there are more than two scenarios and , these sets of weights are neither non-increasing nor non-decreasing. Another natural decision context where the sequence of weights is non-monotonic happens when every component represents the opinion of a particular expert, and one wants to dismiss the extreme opinions. For instance, one can set ,  and  .
\end{itemize}

\subsection{Problem and complexity}

The problem we study in this paper is the OWA-optimal spanning tree problem, that can be formulated as follows:\\ [1ex]
\textsc{-optimal spanning tree problem (-ST)}\\
\emph{Input: } a finite connected graph ,  integer valuations  for every edge  , and a set of weights  () for the  criterion;\\
\emph{Goal: } we want to determine a spanning tree , where  is the set of spanning trees in  and . \(P_{\mbox{\sc mst}})\left\{\begin{array}{ll}
 \min & \displaystyle \sum_{e\in E} v^e x^e\\
  \mbox{s.t.} & \displaystyle \sum_{(i,j) \in A} \varphi_{ij} - \displaystyle \sum_{(j,i) \in A} \varphi_{ji} = \left\{\begin{array}{ll}
	n - 1 & \mbox{if } i=1,\\
	-1 & \forall i \in V \setminus \{1\},
	\end{array}\right.\\ [5ex]	
&\varphi_{ij} \leq (n-1) x^e \quad \forall e =[i,j],	 \\
&\varphi_{ji} \leq (n-1) x^e \quad \forall e =[i,j],\\ [2ex]	
&\displaystyle \sum_{e \in E} x^e = 1,\\
&\varphi \geq 0, ~x^e \in \{0,1\} \quad \forall e \in E.	 
\end{array}\right.
(P_i^y)\begin{array}{ccc}
\left\{\begin{array}{ll}
\max & \sum_{j=1}^p \alpha_j^i y_j\\
\mbox{s.t.} & \sum_{j=1}^p \alpha_j^i = i,\\
& 0 \le \alpha_j^i \le 1 \quad \forall j \in \{1,\ldots,p\}.
\end{array}\right.
& ~~~~ & 
(D_i^y)\left\{\begin{array}{ll}
\min & i r_i + \sum_{j=1}^p d_j^i\\
\mbox{s.t.} & r_i + d_j^i \ge y_j \quad \forall j \in \{1,\ldots,p\},\\
& d_j^i \ge 0 \quad \forall j \in \{1,\ldots,p\}.
\end{array}\right.
\end{array}
(P_{\mbox{\sc owa}})\left\{\begin{array}{ll}
\min & \displaystyle\sum_{i=1}^p (w_i  - w_{i+1}) \displaystyle(i r_i + \sum_{j=1}^p d_j^i\displaystyle)\\
\mbox{s.t.} & r_i + d_j^i \ge y_j \quad \forall i,j \in \{1,\ldots,p\},\\
& y_i = \sum_{e \in E} v_i^e x^e\forall i \in \{1,\ldots,p\},\\
 & \displaystyle \sum_{(i,j) \in A} \varphi_{ij} - \displaystyle \sum_{(j,i) \in A} \varphi_{ji} = \left\{\begin{array}{ll}
	n - 1 & \mbox{if } i=1,\\
	-1 & \forall i \in V \setminus \{1\},
	\end{array}\right.\\ [5ex]	
& \varphi_{ij} \leq (n-1) x^e \quad \forall e =[i,j],	 \\
& \varphi_{ji} \leq (n-1) x^e \quad \forall e =[i,j],\\ [2ex]	
& \displaystyle \sum_{e \in E} x^e = 1,\\
& d_i^j \ge 0 \quad \forall i,j \in \{1,\ldots,p\} \mbox{ and } r_i \mbox{ unrestricted},\\
&\varphi \geq 0, ~x^e \in \{0,1\} \quad \forall e \in E.	 
\end{array}\right.(P_{Y'}) ~~~\left\{
    \begin{array}{ll}
      \min ~~ \varphi(y)\\\mbox{s.t. } y  \in Y'
    \end{array}\right. (P_{\varphi'})~~~ \left\{
    \begin{array}{ll}
      \min ~~ \varphi'(y)\\\mbox{s.t. } y  =  f(x)\\
      ~~~~~x  \in  X
    \end{array}\right. 
Y'=\{y \in \RP:y_i \geq b_i \quad \forall i=0,\ldots,p\}
 (P_{Y',\pi}) \ \left \{ \begin{array}{ll}
\min\sum_{i=1}^p w_i y_{\pi(i)}  \\
\begin{array}{rrclllr}
\mbox{s.t.} & y_{\pi(i)} & \geq & y_{\pi(i+1)} & \forall i\in\{1,\ldots,p-1\}, &(1.1)\\
& y_i & \geq & b_i & \forall i\in\{1,\ldots,p\}, &(1.2)\\
& \sum_{i=1}^p y_i & \geq & b_0, & &(1.3)\\
& y & \in & \mathbb{R}^p.
\end{array}
\end{array} \right.

\left\{
\begin{array}{ll}
\min & \mbox{ OWA}(y) = w_1 y_{(1)} + w_2 y_{(2)} + w_3 y_{(3)} \\
\mbox{s.t.} & y_1 \geq 4 \quad y_2 \geq 7 \quad y_3 \geq 3, \\
& y_1 + y_2 + y_3 \geq 19, \\
& y_1 \in {\mathbb R},\,y_2 \in {\mathbb R},\,y_3 \in {\mathbb R}.
\end{array}
\right.

\left\{
\begin{array}{ll}
\min & w_1 y_2 + w_2 y_1 + w_3 y_3 \\
\mbox{s.t.} & y_{2} \geq y_{1} \geq y_{3}, \\
& y_1 \geq 4 \quad y_2 \geq 7 \quad y_3 \geq 3, \\
& y_1 + y_2 + y_3 \geq 19, \\
& y_1 \in {\mathbb R},\,y_2 \in {\mathbb R},\,y_3 \in {\mathbb R}.
\end{array}
\right.
 \label{EQ1}
\sum_{i \in I} \lambda_i \leq \sum_{i=1}^{\vert I \vert} w_i \quad \mbox{ for all subset } I \subseteq \{1,\ldots,p\}  \mbox{ of objectives}

 \max_{\lambda \in \mathbb{R}^p} & z(\lambda) &  = \min_{y \in Y} \sum_{i=1}^p \lambda_i y_i, \\
 & \mbox{s.t. } & \sum_{i \in I} \lambda_i \leq \sum_{i=1}^{\vert I \vert} w_i \quad \forall I \subseteq \{1,\ldots,p\},\\
& & \lambda_i \geq 0 \quad \forall i = 1, \ldots, p. \label{const2}


Given that  is a concave piecewise linear function of  for a fixed  (since it is the
lower envelope of a set of linear functions ), we solve this program by using the SolvOpt
library \cite{KappK00}, which is an implementation of Shor's
-algorithm \cite{Shor85}. This algorithm is indeed especially convenient for
non-differentiable optimization, and the implemented SolvOpt library
enables to perform constrained optimization. This approach is closed
to the lower bounding procedure proposed by Punnen and Aneja \cite{PunnA95} for min-max combinatorial optimization. In broad outline, it can be viewed as a sequence of minimum spanning tree computations according to a varying weight vector , until convergence towards a weight vector maximizing .

\begin{example}
Let us come back to the instance of Example \ref{EXP1}. Running Shor's -algorithm yields  and  (the image of spanning tree , which is actually OWA-optimal). The bound is therefore  (which is the value of an OWA-optimal tree). This is better than the bound obtained by the previous relaxation (value 6.5). The computational burden is however more important, since it requires to solve much more single objective problems.
\end{example}

\subsection{Branch and bound procedure}

The two bounds presented above can of course be inserted into a branch and bound procedure in order to determine an OWA-optimal spanning tree for arbitrary weights. We summarize below the main features of the branch and bound procedure we propose.\\ [1ex]
\emph{Branching scheme.} The branching scheme is very simple: at each node, an edge  of  is selected and two subproblems are created. In the first one, edge  is mandatory while in the second one, edge  is forbidden. The heuristic to select the next edge consists in searching for an edge  such that  is minimal among the remaining ones.\\ [1ex]
\emph{Computing the lower bound.} The lower bound at each node of the branching tree is computed by relaxation of the image set (by generating and solving problem ) or by relaxation of the objective function (by solving a sequence of problems ).\\ [1ex] \emph{Updating the incumbent.} When defining and solving problem
 or , the algorithm checks whether a newly
computed spanning tree is better than the current best known spanning
tree according to . We take indeed advantage of the property that feasible spanning trees are generated when computing the lower bound: either  spanning trees are generated to obtain the values of  () in 
or a sequence of spanning trees is generated during the running of
Shor's -algorithm to find the best possible bound according to
.\\ [1ex] 
\emph{Initialization.} A branch and bound algorithm is notoriously more efficient when a good solution is known even before starting the search. The initial solution in our method is the best known solution (according to ) after the run of the shaving procedure described below.

\subsection{Shaving procedure}
The definition of lower bounds makes it possible to resort to a \emph{shaving} procedure in order to reduce the size of the instance before running the main algorithm. The term ``shaving'' was introduced by Martin and Shmoys \cite{MartinShmoys96} for the job-shop scheduling problem. Assuming at least a feasible solution is known, this procedure works as follows: for each edge , we build a subproblem in which  is made mandatory. If the computation of the lower bound proves that the subproblem cannot improve the current best known solution, then it means that  can be made definitively forbidden (colored red). Conversely when  has not been colored red by the previous procedure, we test similarly whether  can be made definitively mandatory (colored blue). Note that, here again, when computing the lower bounds, one checks whether a newly detected spanning tree improves the current best known solution (according to ). Of course, the shaving procedure is all the more efficient as a good feasible solution is initially known. For this purpose, we generate  feasible solutions by running a -best ranking algorithm (i.e., returning the  best solutions) for the minimum spanning tree problem on the instance valued by the arithmetic mean of the vectors. The choice of  depends on the size of the instance.

\begin{example}
Let us come back again to the clique of Example~\ref{EXP1}. Assuming that
the -best ranking algorithm is run for , the current best known solution is then spanning tree . Let us now
simulate the progress of the shaving procedure. Making edge 
forbidden, the minimum spanning tree for weight vector  is  with image . The induced lower bound is 7.4, which is strictly greater
than the OWA-value of  (). Therefore edge 
is colored blue. Then making edge  mandatory, the minimum spanning
tree for weight vector  is
 with image . The induced lower
bound is 7.3, which is strictly greater than the OWA-value of
. Therefore edge  is colored red. 
Next, making edge  forbidden, the minimum spanning tree for
weight vector  is 
with image . The induced lower bound is 8.3, and edge
 is therefore colored blue. Finally, making edge 
forbidden, the minimum spanning tree for weight vector  is  with image . The induced lower bound is 7.3, and consequently edge
 is colored blue. All edges of  are colored blue: one concludes
that  is an -optimal spanning tree without even starting the
main algorithm. 
\end{example}

\section{Experimental results} \label{STests}

Before we study more carefully the behavior of our algorithms, we give some insights into previous results on related topics. The most widely studied related topic is the generation of the Pareto set in the bi-objective spanning tree problem \cite{AndJL96,HamaR94,RaASG98,SourS08,SteiR08}. To our knowledge, the most efficient algorithm for this problem enables to solve randomly drawn clique instances containing up to 400 vertices \cite{SourS08} (note that these results significantly improved the size of the instances that could be handled, since it grew from 40 to 400 vertices). However these results do not extend to more than two objectives. More generally, even when looking for a single compromise solution within the Pareto set, it seems that there is very few available numerical experiments in the literature for more than two objectives. Although several works deal with the min-max spanning tree problem (i.e. determining a spanning tree minimizing the max criterion) \cite{AisBV07,AisBV09,HamaR94,Warbu85,Yu98}, the content of these works is indeed mainly theoretical. Actually, the only numerical results we know for more than two objectives are devoted to the determination of a Choquet-optimal spanning tree \cite{GalPS09}. The size of the tackled instances goes from 30 to 70 vertices according to the number of objectives and the parameterization of the Choquet integral.



\subsection{Experimental details} \label{SSImpl}

All the algorithms have been implemented in C++ and were run on a 2.6
GHz personal computer with a memory of 3.4GB. The test instances are defined as follows. All considered graphs are cliques. The components of cost vectors are randomly drawn between 1 and 100 on each edge. The number of objectives varies from 3
to 10, and the number of vertices from 10 to 100 for strictly decreasing weights, and from 10 to 25 for non-monotonic weights. For each kind of
instances (depending on the number of nodes and on the number of
objectives), 30 instances were randomly drawn to obtain average results. 

\subsection{Tests with strictly decreasing weights}

The global procedure to solve problem  when the
weights are strictly decreasing consists of two phases: 
\begin{enumerate}
\item \emph{Coloration phase}: making the most possible edges blue (mandatory) or
  red (forbidden) by running first the preprocessing procedure, and then a shaving procedure taking into account the coloration obtained by preprocessing. 
\item \emph{Resolution phase}: determining the -optimal spanning
  tree by running the main resolution algorithm (solution by MIP or
  branch and bound) on the reduced instance.
\end{enumerate}

In this section, one summarizes the results one has obtained by
running this global procedure. For initializing the shaving procedure in the coloration phase, the -best ranking algorithm proposed by Katoh et al. \cite{KatIM81} is launched for  varying from 500 to 5000 depending on the size of the instance. In all cases, the order of magnitude of its running time is about a few milliseconds. Concerning the shaving itself, preliminary
results have shown that it is much more efficient
when the bound is defined by relaxation of the objective function than by the
relaxation of the image set, especially when the
size of the instances grows. For this reason, one only summarizes here
the execution times obtained when the shaving procedure is performed
by relaxation of the objective function. This shaving procedure is
denoted by \emph{sh} in the sequel. Finally, one compares the various
resolution algorithms proposed in this paper: the solution by MIP and the one by
branch and bound (two versions according to the bound adopted). The mixed integer program is solved by using solver ILOG CPLEX 11. Regarding the branch and bound procedure, the bounds proposed in Section 4 are compared: the one obtained by relaxation of the objective function, and the one obtained by relaxation of the image set. 

Tables \ref{tabPL1}, \ref{tabPL2} and \ref{tabPL3} summarize the results
obtained by running the algorithms on cliques with respectively 3, 5
or 10 objectives (the weights of the  operator are indicated in the caption of the tables), for various numbers of vertices for which the average resolution time is lower than 30 minutes. The upper part of the tables summarizes the informations
about the coloration phase (line \emph{pp} for the preprocessing
procedure and line \emph{sh} for the shaving procedure). For each procedure and each size of instance, the average execution time is indicated. Furthermore, below line \emph{pp} (resp. \emph{sh}), the average number of edges made blue () or red () after preprocessing (resp. after preprocessing \emph{and} shaving) is indicated (couple ). In the lower part of the tables are indicated the average total resolution times for various combinations of procedures for the coloration phase and the resolution phase. To evaluate the variability of the resolution time, the minimal running time () as well as the maximal one () are also indicated (couple  under the average execution time). To encode the combinations, the following abbreviations are used: MIP stands of course for Mixed Integer Programming,   for the branch and bound obtained by relaxation of the image set, and  for the branch and bound obtained by relaxation of the objective function. Note that, in order to show the impact of the coloration phase, the first line of the lower part indicates the resolution times when solving the MIP formulation without resorting to any preprocessing or shaving. 

\begin{table}[!h]
  \begin{center}
{\small \begin{tabular}{|c|ccccc|}    \hline
      \rule[1pt]{0pt}{13pt} 
    & 20&30&40&50&60\\
    \hline
    pp  &0&0.02&0.05&0.11&0.21\\
    	 &(2.8 - 128.3)&(4.4 - 332)&(5.8 - 628.3)&(6.3 - 1025.4)&(7.1 - 1524.9)\\
    sh&0.51&2.89&10.76&31.43&79.19\\
         &(12 - 160.7)&(20.1 - 390)&(26.1 - 720.5)&(33.5 - 1154.7)&(37.9 - 1680.4)\\
   \hline
 MIP&0.51&2.8&8.11&56.11&1018.5\\
      &0.02 - 4.65&0.2 - 20.3&0.45 - 49.7&0.88 - 639.9&1.58
      - 16842\\  
pp+sh+MIP&0.55&3.04&11.73&32.26&89.38\\
   &0.31 - 0.99&2.26 - 4.93&7.88 - 32.55&25.7 - 43.4&68.8
   - 177.3\\ 
pp+sh+BB&0.58&3.11&25.89&34.51&241.52\\
     &0.31 - 1.49&2.26 - 5.79&7.87 - 345.4&25.7 - 67.7&68.8 - 1945.5\\
pp+sh+BB&1.35&10.27&72.1&206&1049.7\\
    &0.32 - 3.79&2.71 - 37.2&8 - 571.2&28.5 - 1183.3&75.8 - 4457.9\\
  \hline
    \end{tabular}\\ [2ex]
\begin{tabular}{|c|cccc|}   \hline
 \rule[1pt]{0pt}{13pt} 
   & 70&80&90&100\\
  \hline
  pp & 0.34&0.54&0.79&1.14\\
    &(8.5 - 2125.2)&(9.3 - 2827.8)&(12 - 3624.1)&(13.2 - 4520.8)\\
  sh&165.6&314.7&563.7&987.7\\
  &(50.1 - 2318)&(52.8 - 3044.7)&(63.1 - 3879.1)&(71.6 - 4811.4)\\
  \hline
 pp+sh+MIP&266.94&342.79&590.98&1167.83\\
 &138.3 - 3206.5&267.1 - 720.6&475.2 - 1025.3&810.6 - 4453\\
\hline
\end{tabular}
}
\end{center}
\caption{\label{tabPL1} Synthesis of the numerical results for 3 objectives (,  and ). Execution times are indicated in seconds.
}
\end{table}

Table 1 shows that the best results are obtained by using the MIP formulation with a coloration phase. This is the only algorithm able to handle instances with more than 60 vertices with an average computation time below 30 minutes. It is essential to note that the coloration phase has a very significative impact on the computation time. For , one sees indeed that the resolution time for MIP is above 1000 seconds, while it is below 100 seconds when the coloration phase is used. This can be easily understood by observing that the number of colored edges at the end of the coloration phase is a low fraction of the initial number of edges. For instance, in average, it remains only 67 uncolored edges over 4950 for . The main interest of preprocessing is that it enables to color a lot of edges in a very low computation time. Hence, the number of edges that are tested during the shaving procedure is reduced, which is computationally interesting since the shaving is more powerful but takes also much more time. Performing shaving after preprocessing makes it possible to color blue a large part of the optimal spanning tree in a reasonable computation time.  For illustration, in average,  preprocessing colors red 4520.8 edges for , and shaving colors blue 71.6 edges (including those colored blue by preprocessing) over a maximum number of 99. A large amount of the total resolution time is spent in the coloration phase: for , 988.84 seconds are spent in average in the coloration phase (pp+sh) over a total resolution time of 1167.83 seconds. Finally, note that there is an important variability in the resolution time according to the instance (for , the MIP algorithm takes between 1.58 seconds and more than 4 hours and half). The coloration phase tends however to reduce this variability.

\begin{table}[!h]
  \begin{center}
 {\small \begin{tabular}{|c|cccccc|}
   \hline
      \rule[1pt]{0pt}{13pt} 
    & 10&20&30&40&50&60 \\
    \hline
 pp  &0&0.01&0.02&0.065&0.14&0.27\\
    	  &(0.16 - 8.36)&(0.18 - 63.42)&(0.27 - 187.2)&(0.16 - 384.9)&(0.27 - 668)&(0.3 - 1034.9)\\
 sh& 0.13&1.71&10.5&43.57&132.21&337.13\\
    	  &(3.54 - 26.84)&(5.42 - 142.5)&(8.13 - 359.3)&(9.92 - 667.1)&(12.77 - 1079.7)&(15.52 - 1596.3)\\
    \hline
 MIP&0.07&1.74&52.39&133.8&1426.7&-\\
    &0.03 - 0.14&0.12 - 12.06&0.59 - 1166.2&0.94 - 3591&12.26 - 16610& - \\
  pp+sh+MIP &0.16&2.63&27.27&87.66&433.8&1202.7\\
      & 0.09 - 0.24&1.47 - 12.83&8.66 - 284.2&38.88 - 693&110.5 - 2589.6&301.8 - 10153.4\\
  pp+sh+BB& 0.17&14.23&764&-&-&-\\
 & 0.09 - 0.62&1.5 - 218.8&8.75 - 13767.5& - & - & - \\
pp+sh+BB& 0.37&19.63&541.3&-&-&-\\
    &0.09 - 2.02&2.58 - 91.58&13.52 - 5018.5& - & - & - \\
  \hline
       \end{tabular}
}
\end{center}
\caption{\label{tabPL2} Synthesis of the numerical results for 5 objectives (, ,
  ,  and ). Execution times are indicated in seconds. Symbol ``-'' means that the average execution time exceeds 30 minutes.}
\end{table}

\begin{table}[!h]
  \begin{center}
 {\small  \begin{tabular}{|c|ccccc|}
    \hline
      \rule[1pt]{0pt}{13pt} 
    & 10&15&20&30&35\\
    \hline
 pp  & 0&0&0.01&0.03&0.05\\
    	 &(0 - 2.22)&(0 - 8.73)&(0.03 - 20.2)&(0.03 - 69.5)&(0.03 - 108.5)\\
 sh& 2.69&5.21&11.41&44&86.57\\
    	 &(3.78 - 25.58)&(2.43 - 58.33)&(1.83 - 107.07)&(1.1 - 256.7)&(1.3 - 365.27)\\
    \hline
 MIP&0.15&1.87&11.47&519.2&-\\
    & 0.05 - 0.55&0.13 - 7.65&0.6 - 33.65&4.76 - 6623& - \\
  pp+sh+MIP& 2.77&6.54&19.29&311&1284.8\\
  &  2.32 - 3.58&4.42 - 12.52&10.2 - 40.6&41.26 - 2937.3&188.1 - 8504.6\\
  pp+sh+BB & 3.15&91.74&-&-&-\\
  & 2.32 - 8.47&4.41 - 532.71& - & - & - \\
pp+sh+BB& 7.93&58.27&477.4&-&-\\
    & 2.32 - 25.75&5.21 - 317&13.32 - 2109.5& - & - \\
  \hline
    \end{tabular}
}
\end{center}
\caption{\label{tabPL3} Synthesis of the numerical results for 10 objectives (, ,
  , , , , ,
  ,  and ). Execution times are indicated in seconds. Symbol ``-'' means that the average execution time exceeds 30 minutes.}
\end{table}

Tables \ref{tabPL2} and \ref{tabPL3} show that the number of objectives has a great impact on the performances of the algorithms. For instance, for , the resolution time of algorithm pp+sh+MIP is 1202.7 seconds in average for 5 objectives, compared to 89.38 seconds for 3 objectives. Besides, for 10 objectives, one can only handle instances with up to 35 vertices within the time limit of 30 minutes.
The resolution time is also sensitive to the weights of the  operator. In order to evaluate this sensitivity, we also performed a test with weights inducing an 
operator closer to the arithmetic mean. Namely, we set ,  and .

\begin{table}[!h]
  \begin{center}
  {\small \begin{tabular}{|c|ccccc|}    \hline
      \rule[1pt]{0pt}{13pt} 
    & 40&50&60&70&80\\
    \hline
    pp  &0.06&0.12&0.22&0.38&0.59\\
    	 &(23.57 - 717.6)&(30.47 - 1148.5)&(35.9 - 1675.2)&(41.85 - 2305.7)&(48 - 3033.6)\\
    sh&2.75&7.22&18.65&37.51&74.3\\
         &(32.5 - 733.9)&(41.9 - 1167.3)&(49.3 - 1700.2)&(57.1 - 2334.9)&(64.85 - 3064.8)\\
   \hline
 MIP&7&65.24&243.8&-&-\\
      &0.25 - 94.75&0.57 - 830.3 &7.12 - 3227& - & - \\
pp+sh+MIP&2.81&7.35&18.9&37.96&75.21\\
  &2.04 - 3.96&4.22 - 11.37&14.23 - 22.75&26.26 - 48.95&55 - 95.15\\
pp+sh+BB&2.82&7.38&18.97&38.376&77.85\\
     &2.04 - 4.01&4.22 - 11.86&14.23 - 23.04&26.26 - 55.59&54.99 - 104.1\\
pp+sh+BB&5.37&13.28&51.5&114.9&391.1\\
    &2.1 - 17.03&4.33 - 48.46&15.57 - 184.5&26.57 - 484.1&64.08 - 1853.1\\
  \hline
    \end{tabular}\\ [2ex]
}
\end{center}
\caption{\label{tabPL26} Synthesis of the numerical results for 3 objectives (,  and ). Execution times are indicated in seconds. 
}
\end{table}

For this set of weights, all the tested algorithms perform better, as it can be seen in
Table~\ref{tabPL26}. In particular, the preprocessing procedure makes it possible to color
blue more edges than for the previous set of weights. For example, for , 49.3 edges are colored blue
in average (over a maximal number of blue edges of 59)
while only 37.9 are colored blue in average when the
previous set of weights is used. Moreover, one can also observed that,
once the coloration phase is performed, branch and bound procedure
BB is as efficient as the
resolution by MIP.




\subsection{Tests with non-monotonic weights}

We present here the results obtained when the weights are
non-monotonic. In this subsection, we used Hurwicz's criterion as
 operator. We recall that, for a vector , it is defined as
. The instances are defined
similarly to the previous subsection, with 3, 4 or 5 objectives, and
parameter  varying from 0.4 to 0.6 in Hurwicz's criterion. As
mentioned in Section 3, the MIP formulation is no more valid in this
case, as well as the preprocessing procedure (the optimality
conditions do not hold anymore). Furthermore, the bound obtained by
relaxation of the objective function becomes weak since there does not
necessarily exist a normalized set of weights satisfying
Constraint~\ref{EQ1} (see Section~\ref{PPHI'}). Consequently, in the
global procedure described in Subsection 5.2, the coloration phase consists of a
single run of the shaving procedure with the bound obtained by
relaxation of the image set, and the resolution phase consists of
applying branch and bound BB. Tables~\ref{tabPL4}, \ref{tabPL5}
and \ref{tabPL6} summarize the results obtained. The conventions are the same than in the previous subsection.

\begin{table}[!h]
  \begin{center}
 {\small 
 \begin{tabular}{|c|c|ccccc|}
    \hline
      \rule[1pt]{0pt}{13pt} 
       & & 5&10&15&20&25\\
       \hline
  \hline
       & sh&0&0&0.02&0.04&-\\
          & &(1.5 - 3.23)&(0.13 - 12.53)&(0 - 4)&(0 - 2.73)& - \\
       \cline{2-7} 
       &sh+BB&0&0.05&1.01&37.93&-\\
       &  & 0 - 0.02&0 - 0.77&0.05 - 6.18&0.85 - 129.7& - \\
  \hline
\hline
   & sh&0&0&0.02&0.04&0.07\\
  & &(1.72 - 3.22)&(0.07 - 10.83)&(0.03 - 18.5)&(0 - 15.27)&(0 - 12.57)\\

    \cline{2-7} 
 &sh+BB&0&0.03&0.87&7.53&195.6\\
  &  &0 - 0.03&0 - 0.14&0.06 - 9.93&0.23 - 40.46&2.14 - 2203.1\\
  \hline
  \hline
  & sh&0&0.01&0.01&0.03&0.06\\
    & &(1.73 - 3.3)&(1.9 - 23.2)&(0.8 - 48.07)&(0.23 - 82.1)&(0 - 100.5)\\
  \cline{2-7} 
  &sh+BB&0&0.01&0.11&0.66&5.09\\
  &  &0 - 0.01&0 - 0.04&0.01 - 0.66&0.07 - 3.02&0.19 - 23.68\\
  \hline
    \end{tabular}
}
\end{center}
\caption{\label{tabPL4} Synthesis of the numerical results for 3 objectives. Execution times are indicated in seconds. Symbol ``-'' means that the average execution time exceeds 30 minutes.}
\end{table}



\begin{table}[!h]
  \begin{center}
  {\small \begin{tabular}{|c|c|ccccc|}
    \hline
       \rule[1pt]{0pt}{13pt} 
       & & 5&10&15&20&25\\
       \hline
     \hline
    & sh&0&0.01&0.02&-&-\\
          & &(0.9 - 2.6)&(0 - 2.67)&(0 - 4.33)& - & - \\

       \cline{2-7} 
       &sh+BB&0&0.21&10.31&-&-\\
       &  &0 - 0.02&0.02 - 0.57&0.21 - 82.37& - & - \\
  \hline
  \hline
   & sh&0&0.01&0.02&0.05&-\\
  & &(0.63 - 2.03)&(0 - 4.53)&(0 - 4.9)&(0 - 0.47)& - \\

    \cline{2-7} 
 &sh+BB&0&0.12&6.03&669.09&-\\
  &  &0 - 0.02&0.01 - 0.72&0.22 - 63.63&10.84 - 8779.1& - \\
  \hline
  \hline
  & sh&0&0.01&0.02&0.05&0.09\\
    & &(1.17 - 2.33)&(0.07 - 7.8)&(0 - 8.07)&(0 - 3.1)&(0 - 2.7)\\
  \cline{2-7} 
  &sh+BB&0&0.11&1.66&84.87&886.8\\
  &  &0 - 0.03&0.01 - 0.32&0.16 - 4.65&6.15 - 760.5&12.46 - 5198.1\\
  \hline
    \end{tabular}
}
\end{center}
\caption{\label{tabPL5} Synthesis of the numerical results for 4 objectives. Execution times are
  indicated in seconds. Symbol ``-'' means that the average execution time exceeds 30 minutes.}
\end{table}


\begin{table}[!h]
  \begin{center}
  {\small \begin{tabular}{|c|c|cccc|}
    \hline
      \rule[1pt]{0pt}{13pt} 
       & & 5&10&15&20\\
       \hline
     \hline
    & sh&0&0.01&0.02&-\\
          & &(0.83 - 2.4)&(0.03 - 2.27)&(0 - 1.17)& -\\
       \cline{2-6} 
       &sh+BB&0&0.45&40.74&-\\
       &  &0 - 0.02&0.01 - 2.98&1.4 - 184.8& -\\
  \hline
  \hline
   & sh&0&0.01&0.02&0.06\\
  & &(0.87 - 1.93)&(0 - 1.6)&(0 - 0.1)&(0 - 0)\\

    \cline{2-6} 
 &sh+BB&0.01&0.72&47.93&1674.9\\
  &  &0 - 0.02&0.05 - 4.45&1.27 - 528.6&139 - 8378.1\\
  \hline
  \hline
  & sh&0&0.01&0.04&0.05\\
    & &(0.47 - 1.2)&(0 - 1.47)&(0 - 1.4)&(0 - 0)\\
  \cline{2-6} 
  &sh+BB&0.01&0.87&40.12&760.9\\
  &  &0 - 0.03&0.1 - 3.96&0.2 - 267& 29.61 - 3611.1\\
  \hline
    \end{tabular}
}

\end{center}
\caption{\label{tabPL6} Synthesis of the numerical results for 5 objectives. Execution times are
  indicated in seconds. Symbol ``-'' means that the average execution time exceeds 30 minutes.}
\end{table}

In these tables, one can observe that parameter  has a significant impact on the resolution times: it is easier for values of  that are above 0.5. For
example, with 3 objectives and , the
average execution time is 5.09 seconds for , while it
is 195.6 seconds for , and it is more than 30 minutes
for . The sizes of the tackled instances are more modest than for strictly decreasing weights. The only available alternative method should be however to resort to an exhaustive enumeration procedure \cite{KapoR95}, that would become
intractable for 12 vertices. The results presented here are therefore
a first step towards optimizing non-convex aggregation functions in
multiobjective spanning tree problems. They make it possible to handle
instances the size of which grows up to 25 vertices. 


\section{Conclusion}

In this paper we have proposed several methods to solve the
-optimal spanning tree problem. One is based on a MIP
formulation and is valid only when the weights of the  operator
are strictly decreasing. We have shown that the use of a preprocessing
phase, as well as a shaving procedure, makes it possible to
considerably reduce the size of the problem, and therefore speed up
the resolution. The numerical results prove the efficiency of the global resolution procedure (one is able to solve multiobjective instances with up to 100 vertices in reasonable times). Two branch and bound algorithms have also been
presented, that work whatever weights are used. Despite a greater resolution time in the strictly decreasing case, they make it possible to tackle the non-monotonic case. This is a very challenging task, and the numerical results presented here are a first step in this direction. For future works, it would be worth further investigating optimization of OWA in this case, as well as some interesting variations of OWA, namely the non-monotonic OWA operator \cite{Yager99} (where negative
weights are allowed) and the weighted OWA operator \cite{Torra97}
(where importance weights specific to each objective are allowed in
addition to the weights of the OWA operator). Other promising research
direction would be to propose a MIP formulation for a broader subclass
of Choquet integrals (enabling to take into account positive and
negative interactions between objectives), as for instance the class of
-additive Choquet integrals \cite{Grabi97}. These research tracks
are especially important because the search for a single best
compromise solution is nearly the only operational approach when there
are more than three objectives and the problem does not fit into
the dynamic programming framework. 








\bibliographystyle{plain}      \bibliography{lgos4or09}   



\end{document}
