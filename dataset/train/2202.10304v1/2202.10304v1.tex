\section{Experiments}\label{sec:experiments}

\subsection{Datasets}
The scene text datasets used in the experiments are described as follows.

\textit{SynthText}~\cite{SynthText} is a synthetic dataset which consists of  images. These images are synthesized from  background images. This dataset is only used to pre-train our model.

\textit{MLT-2017 dataset}~\footnote{https://rrc.cvc.uab.es/?ch=8} is a multi-language dataset. It includes  languages representing 6 different scripts. There are  training images,  validation images, and  testing images in this dataset. We use both the training set and the validation set in the finetune period.

\textit{MLT-2019 dataset}~\footnote{https://rrc.cvc.uab.es/?ch=15} is a multi-language dataset. It is an extension of MLT-2017. It includes  languages representing  different scripts. The languages include Chinese, Japanese, Korean, English, French, Arabic, Italian, German, Bangla, and Hindi (Devanagari). There are  training images,  validation images, and  testing images in this dataset. We use the training set in the finetune period. 

\textit{ICDAR 2015 dataset}~\cite{icdar15} consists of  training images and  testing images, which are captured by Google glasses with a resolution of . The text instances are labeled at the word level. 

\textit{MSRA-TD500 dataset}~\cite{MSRA} is a multi-language dataset that includes English and Chinese. There are  training images and  testing images. The text instances are labeled at the text-line level. Following the previous methods~\cite{east,lyu2018multi,long2018textsnake}, we include extra  training images from HUST-TR400~\cite{yao2014unified}.

\textit{CTW1500 dataset}~\cite{ctw1500} mainly focuses on curved text. It consists of  training images and  testing images. The text instances are annotated at the text-line level.

\textit{Total-Text dataset}~\cite{totaltext} includes the text of various shapes, including horizontal, multi-oriented, and curved. They are  training images and  testing images. The text instances are labeled at the word level.



\begin{table*}[ht]
\setlength{\tabcolsep}{13.0pt}
\centering
\caption{Detection results with different settings of deformable convolution, differentiable binarization and adaptive scale fusion module. ``DConv" indicates deformable convolution. ``ASF" indicates adaptive scale fusion module. ``P'', ``R'', and ``F'' indicate precision, recall, and f-measure respectively.}
\begin{tabularx}{1.0\linewidth}{lc*{10}c}
\toprule
\multirow{2}{*}{Backbone} & \multirow{2}{*}{DConv} & \multirow{2}{*}{DB} &  \multirow{2}{*}{ASF}& \multicolumn{4}{c}{MSRA-TD500} & \multicolumn{4}{c}{CTW1500} \\ \cline{5-12} 
                          &                                         &                             &                 & P      & R      & F      & FPS & P      & R      & F      & FPS \\ 
\midrule   
ResNet-18                 &                                       &                                            &                                            & 85.5   & 70.8   & 77.4   & \textbf{66} & 76.3 & 72.8 & 74.5 & \textbf{59} \\ 
ResNet-18                 & \checkmark                                     &                                            &                                            & 86.8   & 72.3   & 78.9   & 62  & 80.9 & 75.4 & 78.1 & 55 \\ 
ResNet-18                 &        & \checkmark                &              &  87.3   & 75.8   & 81.1   & 66  & 82.4 & 76.6 & 79.4 & 59 \\ 
ResNet-18                 &        &                   &  \checkmark          &  84.9  & 78.5    & 81.6   & 53  & 83.5 & 75.9 & 79.5 & 45 \\ 
ResNet-18                 & \checkmark     & \checkmark                &              & \textbf{90.4}   & 76.3   & 82.8   & 62 & 84.8 & 77.5 & 81.0 & 55  \\
ResNet-18                 & \checkmark     &                   & \checkmark           & 87.1   & 79.9   & 83.3   & 55  & 86.4 & 80.8 & 83.5 & 40 \\
ResNet-18                 & \checkmark     &  \checkmark               & \checkmark           & 87.9   & \textbf{82.5}   & \textbf{85.1}  & 55  & \textbf{86.7} & \textbf{81.3} & \textbf{83.9} & 40 \\
\midrule  

ResNet-50                 &                                       &                                            &                                       & 84.6   & 73.5   & 78.7   & \textbf{40}  & 81.6 & 72.9 & 77.0 & \textbf{27} \\ 
ResNet-50                 & \checkmark                                     &                                            &                                       & 90.5   & 77.9   & 83.7   & 32 & 86.2 & 78.0 & 81.9 & 22 \\ 
ResNet-50                 &                                       & \checkmark                                          &                                       & 86.6   & 77.7   & 81.9   & 40 & 84.3 & 79.1 & 81.6 & 27 \\ 
ResNet-50                 &        &                   &  \checkmark          &  84.5  & 83.2    & 83.8   & 32  & 83.3 & 79.1 & 81.2 & 24 \\ 

ResNet-50                 & \checkmark                                     & \checkmark                                          &                                       & 91.5   & 79.2   & 84.9   & 32 & 86.9 & 80.2 & 83.4 & 22 \\ 

ResNet-50                 &  \checkmark         &                  & \checkmark         & 90.7   & \textbf{83.5}  & 86.9   & 29 & 89.2 & 81.4 & 85.1 & 21   \\
ResNet-50                 & \checkmark          & \checkmark               & \checkmark         & \textbf{91.5}   & 83.3  & \textbf{87.2}   & 29 & \textbf{87.9} & \textbf{82.8} & \textbf{85.3} & 21 \\
\bottomrule
\end{tabularx}
\label{tab:ablation}
\end{table*}

\begin{table*}[ht]
\setlength{\tabcolsep}{13.0pt}
\centering
\caption{Detection results with different settings of ASF. ``Spatial'' means spatial attention in the adaptive scale fusion module; ``Scale'' means adaptive scale fusion.}
\begin{tabularx}{1.0\linewidth}{lc*{9}c}
\toprule
\multirow{2}{*}{Base Method} & \multirow{2}{*}{Scale} & \multirow{2}{*}{Spatial} & \multicolumn{4}{c}{MSRA-TD500} & \multicolumn{4}{c}{CTW1500} \\ \cline{4-11} 
                          &                                         &                                              & P      & R      & F      & FPS & P      & R      & F      & FPS \\ 
\midrule   
DBNet (ResNet-50)                 &                                       &                                            & 91.5  &  79.2   &  84.9  & 32  & 86.9 &  80.2 &  83.4  & 22 \\  
DBNet (ResNet-50)                & \checkmark                                     &                                            & 92.2   & 81.8 & 86.7  & 30 & 85.4 & 83.2 & 84.3 & 21 \\ 
DBNet (ResNet-50)               & \checkmark                                     & \checkmark                                          & 91.5   & 83.3   & 87.2   & 29 & 87.9 & 82.8 & 85.3 & 21 \\
\bottomrule
\end{tabularx}
\label{tab:ablation_asf}
\end{table*}





\subsection{Implementation Details}
For all the models, we first pre-train them with the SynthText dataset for  iterations. Then, we finetune the models on the corresponding real-world datasets for  epochs. The training batch size is set to 16. We follow a “poly” learning rate
policy where the learning rate at the current iteration equals the initial learning rate
multiplying , where the initial learning rate is set to 0.007 and  is . We use a weight decay of 0.0001 and a momentum
of 0.9. The  means the maximum number of iterations, which depends on the maximum epochs.

The data augmentation for the training data includes: (1) Random rotation with an angle range of ; (2) Random cropping; (3) Random Flipping. All the processed images are re-sized to  for better training efficiency.

In the inference period, we keep the aspect ratio of the test images and re-size the input images by setting a suitable height for each dataset. The inference speed is tested with a batch size of , with a single GTX 1080Ti GPU. The inference time cost consists of the model forward time cost and the post-processing time cost. The post-processing time cost is about  of the inference time.

\subsection{Ablation Study}
We conduct an ablation study on the MSRA-TD500 dataset and the CTW1500 dataset to show the effectiveness of the modules including differentiable binarization, deformable convolution, and adaptive scale fusion. The detailed experimental results are shown in Tab.~\ref{tab:ablation}, Tab.~\ref{tab:ablation_asf},  and Tab.~\ref{tab:ablation_thresh}.

\minisection{Differentiable Binarization}
In Tab.~\ref{tab:ablation}, we can see that our proposed DB improves the performance significantly for both ResNet-18 and ResNet-50 on the two datasets.
For the ResNet-18 backbone, DB achieves  and  performance gain in terms of F-measure on the MSRA-TD500 dataset and the CTW1500 dataset. For the ResNet-50 backbone, DB brings  (on the MSRA-TD500 dataset) and  (on the CTW1500 dataset) improvements. Moreover, since DB can be removed in the inference period, the speed is the same as the one without DB. 

\minisection{Deformable Convolution}
As shown in Tab.~\ref{tab:ablation}, the deformable convolution can also brings  performance gain since it provides a flexible receptive field for the backbone, with small extra time costs. For the MSRA-TD500 dataset, the deformable convolution increase the F-measure by  (with ResNet-18) and  (with ResNet-50). For the CTW1500 dataset,  (with ResNet-18) and  (with ResNet-50) improvements are achieved by the deformable convolution.

\begin{table}[!ht]
\setlength{\tabcolsep}{10.0pt}
\centering
\caption{Effect of supervising the threshold map on the MLT-2017 dataset. ``Thr-Sup'' denotes applying supervision on the threshold map.}
\begin{tabularx}{1.0\linewidth}{lc*{5}c}
\toprule

Backbone & Thr-Sup & P      & R      & F      & FPS  \\               
\midrule                     
ResNet-18                                     &                                           & 81.3   & 63.1   & 71.0   & 41 \\ 

ResNet-18                                     & \checkmark                                          & \textbf{81.9}   & \textbf{63.8}   & \textbf{71.7}   & 41 \\ \midrule  
ResNet-50                                                    &                                            & 81.5   & 64.6   & 72.1   & 19   \\ 
ResNet-50                                      & \checkmark                                          & \textbf{83.1}   & \textbf{67.9}   & \textbf{74.7}   & 19 \\ \bottomrule
\end{tabularx}
\label{tab:ablation_thresh}
\end{table}

\minisection{Backbone}
The proposed detector with the ResNet-50 backbone achieves better performance than the ResNet-18 but runs slower. Specifically, The best ResNet-50 model outperforms the best ResNet-18 model by  (on the MSRA-TD500 dataset) and  (on the CTW1500 dataset), with approximate double time cost.

\minisection{Supervision of Threshold Map}
Although the threshold maps with/without supervision are similar in appearance, the supervision can bring performance gain. As shown in Tab.~\ref{tab:ablation_thresh}, the supervision improves  (ResNet-18) and  (ResNet-50) on the MLT-2017 dataset.

\begin{table*}[ht]
\setlength{\tabcolsep}{15.0pt}
\centering
\caption{Comparisons with multi-scale feature fusion and context enhancement modules in semantic segmentation methods. ``PPM": Pyramid
Pooling Module; ``CCA": Criss-Cross Attention.}
\begin{tabularx}{1.0\linewidth}{lc*{9}c}
\toprule
\multirow{2}{*}{Base Method} & \multirow{2}{*}{Module} & \multicolumn{4}{c}{MSRA-TD500} & \multicolumn{4}{c}{CTW1500} \\ \cline{3-10} 
                    &                & P      & R      & F      & FPS & P  & R    & F    & FPS \\ 
\midrule   
DBNet (ResNet-50) & PPM~\cite{zhao2017pyramid}     & 91.2   & 79.7   & 85.1   & 23 & 87.0 & 79.9 & 83.3 & 16 \\ 
DBNet (ResNet-50) & CCA~\cite{Huang_2019_ICCV}   & 92.9   & 80.9   & 86.5   & 22  & 88.4 & 81.5 & 84.8 & 15 \\  
DBNet (ResNet-50) & ASF(ours)                           & 91.5   & 83.3   & \textbf{87.2}  & \textbf{29}  & 87.9 & 82.8 & \textbf{85.3} & \textbf{21} \\
\bottomrule
\end{tabularx}
\label{tab:compare_with_multi_scale}
\end{table*}

\begin{figure*}[htbp]
\centering
\includegraphics[width=0.95\linewidth]{figures/example_dbVsdbv2.pdf}
\caption{Some visualization results of DBNet and DBNet++ on text instances of various shapes, including curved text, vertical text and multi-oriented text. For each unit, the top is the result of DBNet; the bottom is the result of DBNet++. \revise{More results are shown in the appendix.}}
\label{fig:vis_compare}
\end{figure*}

\minisection{Adaptive Scale Fusion}
As shown in Tab.~\ref{tab:ablation}, the adaptive scale fusion module improves the F-measure by  and  on the MSRA-TD500 dataset and the CTW1500 dataset, respectively. The inference speed decreases slightly. As shown in Tab.~\ref{tab:ablation_asf}, the spatial attention in the ASF module brings  and  on the MSRA-TD500 dataset and the CTW1500 dataset by providing more flexible and adaptive attention weights across the spatial dimension.

\minisection{Comparisons with PPM and CCA}
We compare our proposed ASF with a multi-scale feature fusion module (Pyramid Pooling Module, PPM~\cite{zhao2017pyramid}) and a context enhancement module (Criss-Cross Attention, CCA~\cite{Huang_2019_ICCV}). We integrate them into the encoder of the DBNet for a fair comparison.
As shown in Tab.~\ref{tab:compare_with_multi_scale}, the proposed ASF outperforms the PPM and CCA in terms of both the detection accuracy and the inference speed. The experimental results demonstrate that the proposed ASF is more effective than PPM and CCA.

Our proposed ASF performs better than PPM and CCA on the text detection task because that ASF is not designed to simply enlarge the receptive field or introduce more context for the segmentation model. It fuses the multi-scale feature maps with stage-wise and spatial-wise attention weights, which can be guided by the scales of the corresponding text regions.

\subsection{Comparisons with Previous Methods}
We compare our proposed method with previous methods on five standard benchmarks, including two benchmarks for curved text, one benchmark for multi-oriented text, and two multi-language benchmarks for long text lines. Some qualitative results are visualized in Fig.~\ref{fig:visu}.


\begin{table}[!ht]
\setlength{\tabcolsep}{10.0pt}
\centering
\caption{Detection results on the Total-Text dataset. The values in the bracket mean the height of the input images. ``*" indicates testing with multiple scales.}
\begin{tabularx}{1.0\linewidth}{lc*{3}c}
\toprule
Method           & P    & R    & F    & FPS \\ \midrule
TextSnake~\cite{long2018textsnake}      & 82.7 & 74.5 & 78.4 & -   \\ 
ATRR~\cite{atrr}            & 80.9 & 76.2 & 78.5 & -   \\ 
Mask TextSpotter~\cite{lyu2018mask} & 82.5 & 75.6 & 78.6 & -   \\ 
TextField~\cite{xu2019textfield}        & 81.2 & 79.9 & 80.6 & -   \\ 
LOMO~\cite{lomo}*        & 87.6 & 79.3 & 83.3 & -   \\ 
CRAFT~\cite{craft}           & 87.6 & 79.9 & 83.6 & -   \\ 
CSE~\cite{cse}              & 81.4 & 79.1 & 80.2 & -   \\ 
PSENet-1s~\cite{wang2019shape}        & 84.0   & 78.0   & 80.9 & 3.9 \\ 
PAN~\cite{wang2019efficient}        & \textbf{89.3}   & 81.0   & 85.0 & 39.6 \\ 
\midrule  
DBNet (ResNet-18) (800)~\cite{LiaoWYCB20}   & 88.3 & 77.9 & 82.8 & \textbf{50}  \\ 
DBNet (ResNet-50) (800)~\cite{LiaoWYCB20}  & 87.1 & 82.5 & 84.7 & 32  \\ 
\midrule
DBNet++ (ResNet-18) (800)   & 87.4 & 79.6 & 83.3 & 48  \\ 
DBNet++ (ResNet-50) (800)  & 88.9 & \textbf{83.2} & \textbf{86.0} & 28 \\ 
\bottomrule
\end{tabularx}
\label{tab:totaltext}
\end{table}


\begin{table}[!ht]
\setlength{\tabcolsep}{9.5pt}
\centering
\caption{Detection results on the CTW1500 dataset. The methods with ``*" are collected from~\cite{ctw1500}. The values in the bracket mean the height of the input images.}
\begin{tabularx}{1.0\linewidth}{lc*{3}c}
\toprule
Method        & P             & R             & F             & FPS         \\ \midrule
CTPN*          & 60.4          & 53.8          & 56.9          & 7.14        \\ 
EAST*          & 78.7          & 49.1          & 60.4          & 21.2        \\ 
SegLink*       & 42.3            & 40.0            & 40.8            & 10.7         \\ 
TextSnake~\cite{long2018textsnake}     & 67.9          & \textbf{85.3}          & 75.6          & 1.1         \\ 
TLOC~\cite{ctw1500}     & 77.4            & 69.8          & 73.4          & 13.3           \\ 
PSENet-1s~\cite{wang2019shape}    & 84.8         & 79.7          & 82.2          & 3.9         \\ 
SAE~\cite{tian2019learning}       & 82.7          & 77.8          & 80.1    & 3  \\ 
PAN~\cite{wang2019efficient}  & 86.4          & 81.2          & 83.7    & 39.8  \\ 
\midrule  
DBNet (ResNet-18) (1024)~\cite{LiaoWYCB20} & 84.8          & 77.5          & 81.0          & \textbf{55} \\ 
DBNet (ResNet-50) (1024)~\cite{LiaoWYCB20} & 86.9 & 80.2 & 83.4 & 22          \\ 
\midrule
DBNet++ (ResNet-18) (1024)   & 86.7 & 81.3 & 83.9 & 40 \\ 
DBNet++ (ResNet-18) (800)   & 84.3 & 81.0 & 82.6 & 49  \\ 
DBNet++ (ResNet-50) (1024)   & \textbf{88.5} & 82.0 & 85.1 & 21  \\ 
DBNet++ (ResNet-50) (800)  & 87.9 & 82.8 & \textbf{85.3} & 26  \\ \bottomrule
\end{tabularx}
\label{tab:CTW}
\end{table}

\minisection{Curved Text Detection}
We prove the shape robustness of our method on two curved text benchmarks (Total-Text and CTW1500). As shown in Tab.~\ref{tab:totaltext} and Tab.~\ref{tab:CTW}, our method achieves state-of-the-art performance both on accuracy and speed.
Specifically, ``DBNet++ (ResNet-50)" outperforms the previous state-of-the-art method by  and  on the Total-Text and the CTW1500 dataset.
``DBNet (ResNet-50)" runs faster than all previous methods and the speed can be further improved by using a ResNet-18 backbone, with a small performance drop. Compared to the recent fast text detector~\cite{wang2019efficient}, DBNet++ achieves better accuracy with a comparable inference speed.

\minisection{Multi-Oriented Text Detection}
The ICDAR 2015 dataset is a multi-oriented text dataset that contains lots of small and low-resolution text instances.
In Tab.~\ref{tab:ic15}, we can see that ``DBNet++ (ResNet-50) (1152)" and ``DBNet (ResNet-50) (1152)" achieve the state-of-the-art performance on accuracy. 
Compared to EAST~\cite{east}, ``DBNet++ (ResNet-50) (736)" outperforms it by  on accuracy and runs twice faster. Compared to PAN~\cite{wang2019efficient}, ``DBNet++ (ResNet-18) (736)" performs better in terms of accuracy and inference speed. 

\begin{table}[ht]
\setlength{\tabcolsep}{9.5pt}
\centering
\caption{Detection results on the ICDAR 2015 dataset. The values in the bracket mean the height of the input images.}
\begin{tabularx}{1.0\linewidth}{lc*{3}c}
\toprule
Method        & P    & R    & F    & FPS  \\ \midrule
CTPN~\cite{eccv/TianHHH016}          & 74.2 & 51.6 & 60.9 & 7.1  \\ 
EAST~\cite{east}          & 83.6 & 73.5 & 78.2 & 13.2 \\ 
SSTD~\cite{sstd}          & 80.2 & 73.9 & 76.9 & 7.7  \\ 
WordSup~\cite{hu2017wordsup}       & 79.3 & 77   & 78.2 & -  \\ 
Lyu \textit{et al.}~\cite{lyu2018multi}    & \textbf{94.1} & 70.7 & 80.7 & 3.6  \\ 
TextBoxes++~\cite{TextBoxes++}   & 87.2 & 76.7 & 81.7 & 11.6 \\ 
RRD~\cite{liao2018rotation}           & 85.6 & 79   & 82.2 & 6.5  \\ 
MCN~\cite{mcn}           & 72   & 80   & 76   & -  \\ 
TextSnake~\cite{long2018textsnake}     & 84.9 & 80.4 & 82.6 & 1.1  \\ 
PSENet-1s~\cite{wang2019shape}    & 86.9 & 84.5 & 85.7 & 1.6  \\ 
SPCNet~\cite{spc}       & 88.7 & \textbf{85.8} & 87.2 & -  \\ 
LOMO~\cite{lomo}      & 91.3 & 83.5 & 87.2 & -  \\ 
CDAFT~\cite{craft}      & 89.8 & 84.3 & 86.9 & -  \\ 
SAE(720)~\cite{tian2019learning}  & 85.1  & 84.5  & 84.8  & 3       \\ 
SAE(990)~\cite{tian2019learning}  & 88.3   & 85.0  & 86.6  & -       \\ 
PAN~\cite{wang2019efficient}  & 84.0   & 81.9  & 82.9  & 26.1       \\ 
\midrule  
DBNet (ResNet-18) (736)~\cite{LiaoWYCB20} & 86.8 & 78.4 & 82.3 & \textbf{48}   \\ 
DBNet (ResNet-50) (1152)~\cite{LiaoWYCB20} & 91.8   & 83.2 & \textbf{87.3} & 12   \\ 
\midrule  
DBNet++ (ResNet-18) (736) & 90.1 & 77.2 & 83.1 & 44  \\ 
DBNet++ (ResNet-50) (1152) & 90.9 & 83.9 & \textbf{87.3} & 10   \\ 
\bottomrule
\end{tabularx}
\label{tab:ic15}
\end{table}


\minisection{Multi-Language Text Detection}
Our method is robust on multi-language text detection. As shown in Tab.~\ref{tab:td500} and Tab.~\ref{tab:mlt19}, ``DBNet++ (ResNet-50)" is superior to previous methods on accuracy and speed. For the accuracy, ``DBNet++ (ResNet-50)" surpasses the previous state-of-the-art method by  and  on the MSRA-TD500 dataset and the MLT-2019 dataset respectively. For the speed, ``DBNet++ (ResNet-18) (736)" is faster than the previous fastest method~\cite{wang2019efficient} while achieving better accuracy on the MSRA-TD500 dataset. The speed can be further accelerated to 80 FPS (``DBNet++ (ResNet-18) (512)") by decreasing the input size.

\begin{table}[ht]
\setlength{\tabcolsep}{10.0pt}
\centering
\caption{Detection results on the MSRA-TD500 dataset. The values in the bracket mean the height of the input images.}
\begin{tabularx}{1.0\linewidth}{lc*{3}c}
\toprule
Method        & P             & R             & F             & FPS         \\ \midrule
He \textit{et al.}~\cite{he2016text}          & 71            & 61            & 69            & -         \\ 
DeepReg~\cite{deepdirect}       & 77            & 70            & 74            & 1.1         \\ 
RRPN~\cite{rrpn}          & 82            & 68            & 74            & -         \\ 
RRD~\cite{liao2018rotation}           & 87            & 73            & 79            & 10          \\ 
MCN~\cite{mcn}          & 88            & 79            & 83            & -         \\ 
PixelLink~\cite{deng2018pixellink}     & 83            & 73.2          & 77.8          & 3           \\ 
Lyu \textit{et al.}~\cite{lyu2018multi}    & 87.6          & 76.2          & 81.5          & 5.7         \\ 
TextSnake~\cite{long2018textsnake}     & 83.2          & 73.9          & 78.3          & 1.1         \\ 
Xue \textit{et al.}~\cite{xue2018accurate}         & 83.0          & 77.4          & 80.1          & -       \\ 
MSR~\cite{MSR}     & 87.4          & 76.7          & 81.7          & -       \\   
CRAFT~\cite{craft}         & 88.2          & 78.2          & 82.9          & 8.6       \\ 
SAE~\cite{tian2019learning}        & 84.2          & 81.7          & 82.9          & -       \\ 
PAN~\cite{wang2019efficient}        & 84.4          & \textbf{83.8}          & 84.1          & 30.2       \\ 
\midrule  
DBNet (ResNet-18) (512)~\cite{LiaoWYCB20} & 85.7          & 73.2          & 79.0          & \textbf{82} \\ 
DBNet (ResNet-18) (736)~\cite{LiaoWYCB20} & 90.4          & 76.3          & 82.8          & 62 \\ 
DBNet (ResNet-50) (736)~\cite{LiaoWYCB20} & \textbf{91.5} & 79.2 & 84.9 & 32          \\  
\midrule  
DBNet++ (ResNet-18) (512) & 89.7   & 76.5   & 82.6  & 80 \\ 
DBNet++ (ResNet-18) (736) & 87.9   & 82.5   & 85.1  & 55 \\ 
DBNet++ (ResNet-50) (736) & \textbf{91.5}   & 83.3   & \textbf{87.2}   & 29  \\  
\bottomrule
\end{tabularx}
\label{tab:td500}
\end{table}

\begin{table}[!ht]
\setlength{\tabcolsep}{12.0pt}
\centering
\caption{Detection results on the MLT-2019 dataset. *CRAFTS used character-level annotations and integrated a recognition model.}
\begin{tabularx}{1.0\linewidth}{ll*{3}c}
\toprule
Method        & P             & R             & F             & FPS         \\ \midrule
PSENet~\cite{wang2019shape}          & 73.5            & 59.6            & 65.8            & -         \\ 
CRAFTS*~\cite{baek2020character}          & 79.5          & 59.6          & 68.1          & -        \\ 
\midrule  
DBNet (ResNet-18)~\cite{LiaoWYCB20} & 75.3          & 60.2          & 66.9          & \textbf{19} \\ 
DBNet (ResNet-50)~\cite{LiaoWYCB20} & 78.3 & 64.0 & 70.4 & 10 \\ 
\midrule  
DBNet++ (ResNet-18) & 77.5    & 61.0    & 68.2     & 18 \\ 
DBNet++ (ResNet-50) & \textbf{78.6} & \textbf{65.4}  & \textbf{71.4} & 10 \\ 
\bottomrule
\end{tabularx}
\label{tab:mlt19}
\end{table}




\begin{figure*}[htbp]
\centering
    \begin{subfigure}{0.21\linewidth}
    \centering
        \includegraphics[width=\linewidth]{figures/td500-ic15.png}
        \caption{ICDAR 2015 dataset and MSRA-TD500 dataset}
    \end{subfigure} \qquad
    \begin{subfigure}{0.21\linewidth}
    \centering
        \includegraphics[width=\linewidth]{figures/ctw-total.png}
        \caption{Total-Text dataset and CTW1500 dataset}
   \end{subfigure} \qquad
    \begin{subfigure}{0.21\linewidth}
    \centering
        \includegraphics[width=\linewidth]{figures/height_width_sigma_bar.png}
        \caption{The standard deviation of height and width}
   \end{subfigure} \qquad
   \begin{subfigure}{0.21\linewidth}
    \centering
        \includegraphics[width=\linewidth]{figures/improvement_bar.png}
        \caption{The improvements obtained by ASF}
   \end{subfigure}
\caption{The scale distributions of the test sets of different datasets. \revise{The points in (a) and (b) represent the text instances of various scales.} The scales of the bounding boxes are measured by the width and height of their minimum bounding rectangles.}
\label{fig:dataset_scale}
\end{figure*}

\subsection{Comparisons with the Conference Version}
The major extension of this paper over the conference version is the proposed ASF module. Some qualitative results are shown in Fig.~\ref{fig:vis_compare} \revise{and more results are shown in the appendix}. \revise{As shown, DBNet++ performs better in detecting the text instances of diverse scales, especially for the large-scale text instances. In contrast, DBNet may generate inaccurate bounding boxes or discrete bounding boxes for large-scale text instances. This indicates that the proposed ASF module strengthens the scale robustness of the text detection model.}


The quantitative results in the standard scene text benchmarks show that the proposed DBNet++ outperforms the conference version in terms of accuracy with little speed drop. Specifically, The accuracy increases 0.5\% (1.3\%), 2.9\% (1.9\%), 0.8\% (0.0\%), 3.6\% (2.3\%), and 1.3\% (1.0\%) in terms of F-measure on the Total-Text dataset, the CTW1500 dataset, the ICDAR 2015 dataset, the MSRA-TD500 dataset, and the MLT-2019 dataset, respectively, with the backbone of ResNet-18 (ResNet-50).

The performance improvements on the CTW1500 dataset and the MSRA-TD500 dataset are more significant than those on the Total-Text dataset and the ICDAR 2015 dataset. \revise{Thus, we visualize the scale distributions of these datasets in Fig.~\ref{fig:dataset_scale} for further analysis. As shown in Fig.~\ref{fig:dataset_scale}, the scale distributions of the ICDAR 2015 dataset and the Total-Text dataset are less diverse than those of the MSRA-TD500 dataset and the CTW1500 dataset. As shown in Fig.~\ref{fig:dataset_scale} (c) and Fig.~\ref{fig:dataset_scale} (d), the performance improvements approximately have a positive correlation with the diversity of the scales, which quantitatively reflects that DBNet++ is superior to DBNet on scale robustness.}

\subsection{Limitation}
One limitation of our method is that it is difficult to deal with cases ``text inside text", which means that a text instance is inside another text instance.
Although the shrunk text regions are helpful to the cases that the text instance is not in the center region of another text instance, it fails when the text instance is exactly located in the center region of another text instance. This is a common limitation for segmentation-based scene text detectors.