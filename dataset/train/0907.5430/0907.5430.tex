\documentclass[10pt,twocolumn,conference,final]{IEEEtran}
\usepackage{color}
\makeatletter
\def\ps@headings{\def\@oddhead{\mbox{}\scriptsize\rightmark \hfil \thepage}\def\@evenhead{\scriptsize\thepage \hfil \leftmark\mbox{}}\def\@oddfoot{}\def\@evenfoot{}}
\makeatother
\pagestyle{headings}
\usepackage{cite}
\usepackage{epsfig} \usepackage{amsmath} \usepackage{amstext}
\usepackage{amsfonts} \usepackage{amssymb}
\usepackage{eucal} \usepackage{graphicx}
\usepackage{colordvi,rotating}
\usepackage{subfigure}
\usepackage{url}
\def\endpf{\hfill}
\newcommand{\ls}[1] {\dimen0=\fontdimen6\the\font \lineskip=#1\dimen0
\advance\lineskip.5\fontdimen5\the\font \advance\lineskip-\dimen0
\lineskiplimit=.9\lineskip \baselineskip=\lineskip
\advance\baselineskip\dimen0 \normallineskip\lineskip
\normallineskiplimit\lineskiplimit \normalbaselineskip\baselineskip
\ignorespaces } \ls{1}
\newcommand {\R} {\rm I\!R} \newcommand{\dfn}{\stackrel{\triangle}{=}}
\newcommand {\argmax} {\mbox{argmax}}
\newcommand{\Prob}[1]{{\mathbb P \left [  {#1} \right ] }}
\newtheorem{definition}{Definition}[section]
\newtheorem{lma}{Lemma}[section]
\newtheorem{proposition}{Proposition}[section]
\newtheorem{thm}{Theorem}[section]
\newtheorem{example}{Example}[section]
\newtheorem{cexample}{Counter-example}[section]
\newtheorem{remark}{Remark}[section]
\newtheorem{corol}{Corollary}[section]
\newcommand{\Lt}{\tilde L}
\newcommand{\Zt}{\tilde Z}
\newcommand{\Z}{\mathbf Z}
\newcommand{\eF}{\mathcal F_{\mathbf X}}
\newcommand{\Xu}{\overline X}
\newcommand{\eat}[1]{}
\newcommand{\ubf}{\mathbf u}
\begin{document} 
\baselineskip 4.044mm
\title{\LARGE Dynamic control of Coding in Delay Tolerant
Networks} \author{\IEEEauthorblockN{Eitan Altman}
\IEEEauthorblockA{INRIA,  \\ 2004
Route des Lucioles, \\
06902 Sophia-Antipolis Cedex, France\\
eitan.altman@sophia.inria.fr}
\and
\IEEEauthorblockN{Francesco De Pellegrini}
\IEEEauthorblockA{CREATE-NET, \\ via Alla Cascata 56 c,\\
38100 Trento, Italy\\
francesco.depellegrini@create-net.org}
\and
\IEEEauthorblockN{Lucile Sassatelli}
\IEEEauthorblockA{Laboratory for Information and \\ Decision Systems, MIT
\\ Cambridge MA, USA \\
lucisass@mit.edu}
}
\date{} \maketitle
\begin{abstract}
Delay tolerant Networks (DTNs) leverage the mobility of relay nodes to
compensate for lack of permanent connectivity and thus enable
communication between nodes that are out of range of each other. To
decrease message delivery delay, the information to be transmitted
is replicated in the network. We study replication mechanisms that include
Reed-Solomon type codes as well as network coding in order to improve the
probability of successful delivery within a given time limit.
We propose an analytical approach that allows us to compute the probability
of successful delivery.  We study the effect of
coding on the performance of the network while optimizing parameters that
govern routing.
\end{abstract}
\begin{keywords}
Delay Tolerant Networks, Optimal Scheduling, Coding, Network Codes
\end{keywords}
\thispagestyle{empty}
\thispagestyle{empty}
\section{Introduction}\label{sec:intro}
DTNs exploit random contacts between mobile nodes
to allow end-to-end communication between points that do not have
end-to-end connectivity at any given instant. The contacts between any
two nodes may be quite rare, but still, when there are sufficiently
many nodes in the system, the timely delivery of information to the destination
may occur with high probability. This is obtained at the cost of
many replicas of the original information, a process which requires
energy and memory resources.
Since many relay nodes (and thus network resources) may be involved in ensuring
successful delivery, it becomes crucial to design efficient resource allocation
and data storage protocols. In this paper we address this combined
problem. The basic data unit that is transferred or stored is called a frame,
and to transfer successfully a file, all frames of which it is composed are
needed at the destination.
We consider both energy costs as well as memory constraints: The memory
of a DTN node is assumed to be limited to the size  of a single frame.
We study adding coding in order to improve
the storage efficiency of the DTN. We consider
Reed-Solomon type codes as well as network coding.
The basic questions are then: (i) {\bf transmission policy:}
When the source is in contact with a relay node, should it transmit a frame to the relay?
(ii) {\bf scheduling:} If yes, which frame should a source transfer?
Each time the source meats a relay node, it chooses a frame  for transmission with probability .
In a simple scenario, the source has initially all the frame and  are fixed  in time.
It was shown in \cite{infocom09} that the transmission policy has a threshold structure: use all opportunities
to spread frame till some time  and then stop  (this is similar to the ``spray and wait'' policy \cite{SPR}).
Due to convexity arguments it turns out that the optimal  does not depend on  \cite{infocom09}.
In this paper we assume a general arrival process of frames: they need
not become available for transmission simultaneously at time zero as in 
\cite{infocom09}. We further consider {\it dynamic} scheduling: the probabilities
 may change in time. We define various performance measures and
solve various related optimization problems.
Surprisingly, the transmission does not follow anymore a
threshold policy (in contrast with \cite{infocom09}). We extend these results to include also coding, and show that
all performance measures improve when increasing the amount of redundancy. We then study
the optimal transmission under network coding.
\noindent{\bf Related Work} The works \cite{JDPF} and \cite{WJMK} describe the 
technique to erasure code a file and distribute the generated code-blocks over a 
large number of relays in DTNs. The use of erasure codes is meant to increase 
the efficiency of DTNs under uncertain mobility patterns. In \cite{WJMK} the 
performance gain of the coding scheme is compared to simple replication, i.e., 
when additional copies of the same file are released. The benefit of erasure 
coding is quantified by means of extensive simulations and for different routing 
protocols, including two-hops routing. 
In \cite{JDPF}, the authors address the case of non-uniform encounter patterns, 
and they demonstrate strong dependence of the optimal successful delivery probability
on the way replicas are distributed over different paths. The authors evaluate several
allocation techniques; also, the problem is proved to be NP--hard.
The paper \cite{FBW} proposes general network coding techniques for DTNs. In \cite{LLL}
ODE based models are employed under epidemic routing; in that work, 
semi-analytical numerical results are reported describing the effect 
of finite buffers and contact times; the authors also propose a prioritization algorithm.
The paper \cite{WB} addresses the design of stateless routing protocols based on 
network coding, under intermittent end-to-end connectivity. A forwarding 
algorithm based on network coding is specified, and the advantage 
over plain probabilistic routing is proved when delivering multiple frames.
Finally, \cite{FSCB} describes an architecture supporting random linear coding in challenged
wireless networks.
The structure of the paper is the following. In Sec.~\ref{sec:model} we introduce 
the network model and the optimization problems tackled in the paper. Sec.~\ref{sec:wc} and Sec.~\ref{sec:nwc} describe 
optimal solutions in the case of work conserving and not-work conserving forwarding policies, 
respectively. Sec.~\ref{sec:constr} addresses the case of energy constraints. Sec.~\ref{sec:redundancy}
 deals with erasure codes. Rateless coding techniques are presented in Sec.~\ref{sec:rataft}. The use of 
network coding is addressed in Section~\ref{sec:ratbef}. Sec.~\ref{sec:concl} concludes the paper.
\section{The model}\label{sec:model}
\begin{table}[t]\caption{Main notation used throughout the paper}
\centering
\begin{tabular}{|p{0.10\columnwidth}|p{0.8\columnwidth}|}
\hline
{\it Symbol} & {\it Meaning}\\
\hline
 & number of nodes (excluding the destination)\\
 & number of frames composing the file\\
 & number of redundant frames\\
 & inter-meeting intensity\\
 & timeout value\\
 & number of nodes having frame  at time  (excluding the destination) \\
 & summation \\
 & corresponding sample paths\\
 & := will be taken 0 unless otherwise stated.\\
 & forwarding policy for frame ;  \\
 & sum of the s \\
,&, , , , \\
& probability of successful delivery of frame  by time \\
& probability of successful delivery of the file by time ;  is
used to stress the dependence on  and \\
 & nonnegative real numbers \\
\hline
\end{tabular}\
\frac{ d X_i (t) } { dt} = u_i (t) \lambda (1 - X(t))
\label{dyn1}

\frac{ d X (t) } { dt} = \lambda u (1 - X(t))
\label{dyn2}

\label{all}
X(t) = 1 + (z-1) e^{ - \lambda \int_0^t u(r) dr }, \quad X(0)= z
\label{dyn4}
\frac{d X_i (t) }{dt} = - u_i(t) \lambda
(z-1) e^{ - \lambda \int_0^t u(r)d r }
\label{eq:expectation}
E[ D_K (\tau |\eF) ]= E \left[ \prod_{i=1}^K ( 1 - \exp (- \lambda  \widehat Z_i )) \right]

P_s ( \tau )=\lim_{N \to \infty} E[D_K(\tau|\eF,N) ]
= \prod_{i=1}^K ( 1 - \exp (- \lambda   E[ \widehat Z_i ] ))

E[D] = \int_0^\infty ( 1 - P_s ( \tau )) d \tau

\zeta(h) = 1-\exp(-\lambda\,  h  ) .

Z_i = \int_0^\tau X_i(v)dv .

\log P_s(\tau ,\ubf)= \sum_{i=1}^K \log(\zeta ( Z_i )) .
\label{log}
\log P_s(\tau , \ubf )
\leq K \log\left(\zeta \left( {Z}/{K} \right)\right)

\sum_{i=1}^k  d_{[i]} (1) &\leq& \sum_{i=1}^k  d_{[i]} (2) , \quad k=1,...,n-1, \label{eq:major1}\\
\mbox{ and     }
\sum_{i=1}^n  d_{[i]} (1) &=& \sum_{i=1}^n  d_{[i]} (2),\label{eq:major2}

X_1(t) =
\left\{
\begin{array} {lr}
\Xu(t) & 0 \leq t \leq t_2 \\
\Xu(t_2) & t_2 < t \leq \tau
\end{array}
\right.

X_2(t) =
\left\{
\begin{array} {lr}
0  & 0 \leq t \leq t_2 \\
\Xu(t) - X(t_2) =
e^{-\lambda t_2 } - e^{ - \lambda t }  & t_2 \leq t \leq \tau
\end{array}
\right.
-3mm]
-3mm]

\int_0^\tau X_2(t) dt =
\frac{e^{-\lambda t_2 }}{\lambda}
( \lambda ( \tau - t_2 ) - 1 + e^{ - \lambda ( \tau - t_2 )} )

t_{eq} = \frac{1}{\lambda}  \left[
LambertW \left( - \frac{ \exp( \xi ) }{ 1 - 2 \exp( - \lambda t_2 ) } \right)
+ \xi \right]

\mbox{and where  }
\xi:= \frac{ - 1 + 2 e^{-\lambda t_2} + 2 \lambda t_2 e^{-\lambda t_2 }}{ 1 - 2 e^{-\lambda t_2 } }
-5mm]
\label{algo1}
\end{table}
Algorithm A seeks to equalize the less populated frames at each point in time:  
it first increases the CCI of the latest arrived frame, trying to increase
it to the minimum CCI which was attained over all the frames existing before the 
last one arrived (step A3.2). If the minimum is reached (at some threshold ), then it next increases the fraction 
of all frames currently having minimum CCI, seeking now to equalize towards the second smallest CCI, sharing 
equally the forwarding probability among all such frames. The process is repeated until the next frame arrives: 
hence, the same procedure is applied over the novel interval. Notice that, by construction, the algorithm will 
naturally achieve equalization of the CCIs for  large enough. Moreover, it holds the following:
\begin{thm}
\label{thm:maximize}
[See Appendix]
Fix some .
Let  be the policy obtained by Algorithm A when substituting there
. Then
\\
(i)
 is uniformly optimal for P2.
\\
(ii) If in addition  are the same for all 's,
then  is optimal for P1.
\label{thm3p1}
\end{thm}
\section{Beyond work conserving policies}\label{sec:nwc}
We have obtained the structure of the best
work conserving policies, and identified their structure,
and identified cases in which these are globally optimal.
We next show the limitation of work-conserving policies.
\subsection{The case K=2}
\label{ex2}
We consider the example of Section \ref{ex1} but with .
Consider the policy  where 
which transmits type-1 frames during , does not
transmit anything during  and then transmits type 2
frames  after . It then holds

where . Also,
-3mm]
-3mm]
-3mm]

\int_0^\tau X_2(t) dt =
\frac{e^{-\lambda s }}{\lambda}
( \lambda ( \tau - t_2 ) - 1 + e^{ - \lambda ( \tau - t_2 )} )

\int_0^\tau X_2 (t) dt \leq \tau( 1 - X (t_2 ) )

s=\frac 1\lambda \log \Big ( 1- e^{-\lambda (\tau - t_2)}\Big ) .

\frac {d {\overline X}(s) }{ds}= v(s) \lambda ( 1 - \overline X(s))

\frac{ d \overline X (s) }{ dt } =
p \frac{ d {\overline X}(s ) }{d (s) }
= p v( s) \lambda ( 1 - \overline X(s) ) =
u(t) \lambda ( 1 - \overline X(s ) ))

\frac{ d {\overline X}_i (s) } { dt } =
p \frac{ d {\overline X}_i (s)}{ds}  = p v_i ( s) \lambda
( 1 - \overline X(s ) ) =
u_i (t) \lambda ( 1 - \overline X(s ) )
-5mm]
\label{algo2}
\end{table}
\section{The constrained problem}\label{sec:constr}
Let  be any policy that achieves the constraint  as 
defined in Section~\ref{subsec:perf}. We make the following observation. The constraint involves only . It
thus depends on the individual 's only through their sum; the sum , in turn,
 depends on the policies 's only through their sum .
{\bf Work conserving policies.}
Any policy which is not a threshold one can be strictly
improved as described in Lemma \ref{improve}.
Consider the case of work conserving policies.
Then the optimal policy is of a threshold type \cite{ABD}:
 till some time  and is then zero.
 is the solution of , i.e.\
s = - \frac{1}{\lambda}\log\left(\frac{1-x-z}{1-z}\right),

P(S_{n,p}=m) = B(p,n,m) := { n \choose m } p^m (1-p)^{n-m}

P_s (\tau,K,H) = \sum_{j=K}^{K+H} B( D_i(\tau) , K+H , j  ),

P_s ( \tau,K,H ) = \sum_{ h \in A(H,K) } \prod_{i\in h} \zeta (Z_i)

P_s(\tau,K,H) = \zeta ( Z_i ) \zeta ( Z_j ) g_1
+ ( \zeta (Z_1 ) + \zeta (Z_2 ) ) g_2 + g_3

g_1 =  \sum_{ h \in A_{\{i,j\}} (H,K) } \prod_{
\stackrel{ m\in h }{ m\not=i },\;{ m\not=j}} \zeta (Z_m)
-5mm]
\label{algo3}
\end{table}
{\bf Proof:}
\textcolor{black}{Let  be any set made of pairwise different elements from .
 We have

where  denotes the probability that the received coded frames, added to the received information frames, form a rank  matrix. Let  denote the number of elements in , and  be the probability that exactly  coded frames are received at the destination by time . Let consider the probability that, given that  coded frames have been received, these frames form a rank  matrix with the received  information frames. We lower-bound this probability by the probability that only  coded frames form a rank  matrix with the  frames, and this probability corresponds to the product term in the following equation. Then we can lower-bound  by}

Let us now express . Let  denote 
the proportion corresponding to
the number of coded frames released at time  and  be defined by . We have .
Let  denote the 
proportion corresponding to the
total number of frames in the network at time : 

Since coded frames are released only after ,  for . We can consider that  for any  as coded frames are sent as soon as all the information frames have been received by the source. 
Thus, for 

with  for . 
Thus, for , equations (\ref{dyn1}) to (\ref{dyn4}) remain unchanged. For ,  and  for .
Hence, for , we have

with .
Thus we get


Finally



Thus, to maximize  for  in terms of the , , it is sufficient to maximize its lower bound in terms of the .
From eq. (\ref{eqLB}), for maximizing the lower bound, we can see that the proof of Theorem \ref{thmFA} carries almost unchanged, as the second product term in eq. (\ref{eqLB}) results in weighting constants in front of each product in the summations of ,  and . Hence, the success probability is maximized when all the  are the same for all .
\endpf
\section{Rateless codes for coding before }\label{sec:ratbef}
We now consider the case where after receiving frame  and before receiving frame  at the source, we allow to code over the available information frames and to send resulting encoding frames between  and . LT codes and Raptor codes require that all the information frames are available at the source before generating encoding frames.  
Due to their fully random structure, network codes do not have this constraint, and allow to generate encoding frames online, along the reception of frames at the source. We present how to use network codes in such a setting.
The objective is the successful delivery of the entire file (the  information frames) by time \footnote{We do not have constraints on making available at the destination a part of the  frames in case the entire file cannot be delivered.}. 
Information frames are not sent anymore, only encoding frames are sent instead. \textcolor{black}{At each transmission opportunity, an encoding frame is generated and sent with probability . Note that  is not relevant anymore because, at each transmission, network coding allows to propagate an equivalent amount of information of each of the frames in the source buffer, by sending a frame which is a random linear combination of all buffer frames. This is detailed later on.}
\begin{thm}\label{THbeforeTK}
(i) Given any forwarding policy , it is optimal, for maximizing , to send coded frames resulting from random linear combinations of all the information frames available at the time of the transmission opportunity.\\
(ii) \textcolor{black}{For a constant policy }, the probability of successful delivery of the entire file is lower-bounded by

with

and ,
, and

\end{thm}
{\bf Proof:} For all , let  be . For sake of shorter notations, we say that a coded frame is ``a frame over '' if the coefficients of the first  information frames are chosen uniformly at random in , while the others are zero. 
We analyze first the probability of successful delivery of the file by time , i.e., the probability of decoding of the  information frames. Let us first briefly discuss the general case, following the formalization in \cite{Lun}. As previously mentioned, the decoding is successful if the matrix of received coded frames has rank . When no coding is used, the matrix of received uncoded frames can be only the identity for the decoding to be possible. \textcolor{black}{Hence, if a frame is lost, only the same frame can recover the loss}. However, when coding is used, we can send coded frames which are random linear combinations of all  information frames. Then, if any frame is lost, the rank of the received matrix results into : \textcolor{black}{in order to get a rank- matrix it is sufficient to receive an extra coded frame which is independent of all previously received ones, i.e., dependent on the lost frame. This is known to happen with high probability as soon as  is large enough \cite{Lun}.} 
Let us now formalize the successful decoding conditions for our problem.
\begin{figure}
\begin{picture}(0,0)\includegraphics{fig1.pstex}\end{picture}\setlength{\unitlength}{1973sp}\begingroup\makeatletter\ifx\SetFigFont\undefined \gdef\SetFigFont#1#2#3#4#5{\reset@font\fontsize{#1}{#2pt}\fontfamily{#3}\fontseries{#4}\fontshape{#5}\selectfont}\fi\endgroup \begin{picture}(7299,4681)(3439,-3959)
\put(6826,-3361){\makebox(0,0)[lb]{\smash{{\SetFigFont{7}{8.4}{\rmdefault}{\mddefault}{\updefault}{\color[rgb]{0,0,0}}}}}}
\put(6751,-1036){\makebox(0,0)[lb]{\smash{{\SetFigFont{7}{8.4}{\rmdefault}{\mddefault}{\updefault}{\color[rgb]{0,0,0}}}}}}
\put(6751,-1561){\makebox(0,0)[lb]{\smash{{\SetFigFont{7}{8.4}{\rmdefault}{\mddefault}{\updefault}{\color[rgb]{0,0,0}}}}}}
\put(6751,-2086){\makebox(0,0)[lb]{\smash{{\SetFigFont{7}{8.4}{\rmdefault}{\mddefault}{\updefault}{\color[rgb]{0,0,0}}}}}}
\put(9076,-511){\makebox(0,0)[lb]{\smash{{\SetFigFont{7}{8.4}{\rmdefault}{\mddefault}{\updefault}{\color[rgb]{0,0,0}}}}}}
\put(9376,-211){\makebox(0,0)[lb]{\smash{{\SetFigFont{7}{8.4}{\rmdefault}{\mddefault}{\updefault}{\color[rgb]{0,0,0}}}}}}
\put(9451,164){\makebox(0,0)[lb]{\smash{{\SetFigFont{7}{8.4}{\rmdefault}{\mddefault}{\updefault}{\color[rgb]{0,0,0}}}}}}
\put(10276,539){\makebox(0,0)[lb]{\smash{{\SetFigFont{7}{8.4}{\rmdefault}{\mddefault}{\updefault}{\color[rgb]{0,0,0}}}}}}
\end{picture} \caption{Received encoding matrices. (a) The decoding fails because all the information frames cannot be recovered \textcolor{black}{-- matrix has not full rank}. (b) The decoding is successful \textcolor{black}{-- matrix has full rank}.}
\label{fig1}
\end{figure}
As illustrated in Figure \ref{fig1}, we have the following definitions:
\begin{itemize}
\item The received frames are over , with .
\item  is such that , and denotes the number of pairwise different , . We set .
\item ,  is the rank of received frames over .
\end{itemize}
\textcolor{black}{For the coding matrix to be rank , i.e., for the decoding to be successful, it is necessary and sufficient to have (see Fig~\ref{fig1}):}
-1mm]
&&l_1\geq k_1-k_2-(l_0-(K-k_1))\nonumber\-4mm]
&&l_n\geq K-k_{n+1}-\sum_{i=0}^{n-1} l_i\nonumber\-4mm]
&&l_{j}\geq K-\sum_{i=0}^{j-1} l_i\nonumber
-4mm]
For all , i.e., for all states (number of available information frames) the source is in when transmitting,  is given by the number of transmission opportunities. Hence, to maximize the successful decoding probability, each , for all , has to be maximized. This means exactly making random linear combinations of all available information frames.
Let us now express the probability of successful delivery of the file by time , i.e., the probability of decoding of the  information frames. Let  be the fraction of nodes (excluding the destination) having a frame over  at time . Let  be the probability that exactly  frames over  be received at time :\
D_{k,i}(\tau)=\exp(-\Lambda_k)\frac{\Lambda_k^i}{i!}\;,
-4mm]
where . 
By unfolding calculations (see Appendix), we get \\Lambda_K=\lambda\left[\exp(-\lambda u t_K)\left(\tau-t_K-\frac{1}{\lambda u}\right)+\frac{1}{\lambda u}\exp(-\lambda u \tau)\right]\;.\
Then, by using some approximations (see Appendix) which are tight when  is large enough (e.g., when the frame size is a byte, i.e., ), we obtain the lower-bound on .
\endpf
Let us briefly compare the successful delivery probabilities for the different coding schemes:
\begin{itemize}
\item No coding:

\item Adding fixed amount of redundancy:\P_s ( \tau,K,H ) = \sum_{ h \in A(H,K) } \prod_{i\in h} \zeta (Z_i)\
\item Coding after :\
P_s(\tau)\geq\sum_{e=0}^K \Big\{ \Big((1-\sum_{m=0}^{K-e-1}P_m)\prod_{r=0}^{K-e-1}(1-\frac{1}{q^{K-(r+e)}})\Big)\
-3mm]
-4mm]-1mm]\label{u1}
\mathbf{u}^*=\arg\max_{\mbox{wc }\mathbf{u}} \min_{i:t_i\leq t}Z_i(t)
\label{u2}
\mathbf{u}^*=\arg\min_{\mbox{wc }\mathbf{u}} \max_{i,j:t_i,t_j\leq t}|Z_i(t)-Z_j(t)|
\sum_{i=1}^K Z_{[i]}=\sum_{i=1}^K Z^*_{[i]}\sum_{i=1}^k Z_{[i]}\geq \sum_{i=1}^k Z^*_{[i]}
s_1\leq i,&\quad& Z_{[i]}\leq Z^*_{[i]}\nonumber\\
s_2\leq i< s_1,&\quad& Z^*_{[i]}\leq Z_{[i]}\nonumber\\
i<s_2,&\quad& Z_{[i]}\leq Z^*_{[i]}\nonumber

\max_{i,j}|Z_i(t)-Z_j(t)|=Z_{[1]}-Z_{[K]}

Z_{[1]}-Z^*_{[K]}\leq Z^*_{[1]}-Z^*_{[K]}

s_1\leq i,&\quad& Z_{[i]}\leq Z^*_{[i]}\nonumber\\
1\leq i< s_1,&\quad& Z^*_{[i]}\leq Z_{[i]}\nonumber

\sum_{i=1}^{k} Z_{[i]}=\sum_{i=1}^{K} Z^*_{[i]}-\sum_{i=k+1}^{K} Z_{[i]}\geq \nonumber \\ 
\sum_{i=1}^{K} Z^*_{[i]}-\sum_{i=k+1}^{K} Z^*_{[i]}=\sum_{i=1}^{k} Z^*_{[i]} \nonumber 

x \prec y \Rightarrow x' \prec y'

\sum_{h=1}^{w-1}x_{[h]}'\leq \sum_{h=1}^{w-1}y_{[h]}'\;,\; \sum_{h=1}^{w}x_{[h]}'> \sum_{h=1}^{w}y_{[h]}'

\phi_{x'}(t)=\phi_{x'}(j-1)+(x_j+\delta/\overline \j) \, t
\label{eq:afterteq}
\Big(\frac 1n,\ldots,\frac 1n\Big) \prec (a_1,\ldots,a_n)\nonumber
\label{eq:afterteq2}
\Z^* = Z \cdot \Big(\frac 1n,\ldots,\frac 1n\Big) \prec Z \cdot (a_1,\ldots,a_n)=\Z 

\sum_{h=1}^{K-1}Z_h^*(\tau)=\sum_{h=1}^{K-1}Z_h^*(t_K) \leq \sum_{h=1}^{K-1}Z_h(t_{K})\leq\sum_{h=1}^{K-1}Z_h(\tau)

\Z^*(\tau)=\Big (Z_1^*(s),\ldots,Z_{j-1}^*(s),Z_{j}^*(s)+\delta Z^*,\ldots,Z_{j}^*(s)+\delta Z^*\Big )
\frac{d Y(t)}{dt}=u\lambda(1-Y(t))\;.Y_k(t)=0,\quad \forall t\leq t_k\;,\frac{d Y_k(t)}{dt}=u\lambda (1-Y(t)),\quad \forall t_k\leq t\leq t_{k+1}\;,
Y(t)=Y(t_{k+1}), \quad\forall t\geq t_{k+1}\;,

Y_k(t)=\exp(-\lambda u t_k)-\exp(-\lambda u t),\quad \forall t_k\leq t\leq t_{k+1}\;,

Y_k(t)=\exp(-\lambda u t_k)-\exp(-\lambda u t_{k+1}),\quad\forall t\geq t_{k+1}\;,

\mbox{and }
Y_K(t)=\exp(-\lambda u t_K)-\exp(-\lambda u t),\quad \forall t_k\leq t\;.
\mbox{Thus for  }
\Lambda_k=\lambda[\exp(-\lambda u t_k)\left(\tau-t_k-\frac{1}{\lambda u}\right)+\exp(-\lambda u t_{k+1})\left(\frac{1}{\lambda u}+t_{k+1}-\tau\right)]\;,
\mbox{ and}
\Lambda_K=\lambda\left[\exp(-\lambda u t_K)\left(\tau-t_K-\frac{1}{\lambda u}\right)+\frac{1}{\lambda u}\exp(-\lambda u \tau)\right]\;.P_s(\tau)=\sum_{j=0}^{K-1}\sum_{k_1>\dots>k_j}\sum_{l_0=K-k_1}^{K}\dots\sum_{l_{j}=K-\sum_{i=0}^{j-1} l_i}^{k_j} \prod_{i=0}^j Q_i\;,P_s(\tau)=\sum_{j=0}^{K-1}\sum_{k_1>\dots>k_j}\sum_{l_0=K-k_1}^{K}\dots\sum_{l_{j}=K-k_{j}-\sum_{i=1}^{j-1} l_i}^{k_j}\prod_{i=0}^j \left(\sum_{m=l_{i}}^{\infty}P_{m,k_i,l_i}\left(\frac{1}{q^{k_i-l_i}}\right)^{m-l_i}D_{k_i,m}(\tau)\right)\;.\sum_{m=l_{i}}^{\infty}P_{m,k_i,l_i}\left(\frac{1}{q^{k_i-l_i}}\right)^{m-l_i}D_{k_i,m}(\tau)\geq P_{l_i,k_i,l_i}D_{k_i,l_i}(\tau)\;.P_s(\tau)\geq \sum_{j=0}^{K-1}\sum_{k_1>\dots>k_j}\sum_{l_0=K-k_1}^{K}\dots\sum_{l_{j}=K-\sum_{i=0}^{j-1} l_i}^{k_j}\prod_{i=0}^j f(l_i,k_i)\;,
with

where .
Due to the above notes, the higher , the tighter this lower-bound on .
\endpf
\end{document}
