Humans are often a central element in images and videos. 
Understanding their posture, the social cues they communicate, and their interactions with the world is critical for holistic scene understanding.
Recent methods have shown rapid progress on estimating the major body joints, hand joints and facial features in \twoD \cite{cao2017realtime,insafutdinov2016deepercut,simon2017hand}. 
Our interactions with the world, however, are fundamentally \threeD and recent work has also made progress on the \threeD estimation of the major joints and rough \threeD pose directly from single images \cite{bogo2016keep,kanazawa2018end,omran2018neural,pavlakos2018learning}. 

\newcommand{\ImgEmotionsHeightXX}{0.246}
\newcommand{\ImgEmotionsHeightYY}{0.31}
\newcommand{\ImgEmotionsHeightZZ}{0.160}
\newcommand{\ImgEmotionsHSpaceXX}{-3.0mm}
\newcommand{\ImgEmotionsVSpaceXX}{-4.0mm}
\begin{figure}
	\centering
	\vspace*{-01.00em}
	\subfloat{	\includegraphics[trim=00mm 00mm 00mm 00mm,   clip=true, height=\ImgEmotionsHeightYY \textwidth]{Figures/Fig1/fig1}}
	\vspace*{-00.50em}
	\caption{
				Communication and gesture rely on the \emph{body} pose, \emph{hand} pose, and \emph{facial} expression, all \emph{together}. 
				The major joints of the body are not sufficient to represent this and current \threeD models are not expressive enough. 
				In contrast to prior work, our approach estimates a more detailed and expressive \threeD model from a single image. 
				From left to right: RGB image, major joints, skeleton, \smpl (female), \smplHF (female). 
				The hands and face in \smplHF enable more \emph{holistic} and \emph{expressive} body capture. 
	}
	\label{fig:fromDotsToModels}
\vspace*{-3mm}
\end{figure}

 
To understand human behavior, however, we have to capture more than the major joints of the body -- we need the full \threeD surface of the body, hands and the face.
There is no system that can do this today due to several major challenges including the lack of appropriate \threeD models and rich \threeD training data.
Figure \ref{fig:fromDotsToModels} illustrates the problem. 
The interpretation of expressive and communicative images is difficult using only sparse \twoD information or \threeD representations that lack hand and face detail. 
To address this problem, we need two things. 
First, we need a \threeD model of the body that is able to represent the complexity of human faces, hands, and body pose.
Second, we need a method to extract such a model from a single image.

\newcommand{\ImgEmotionsHeightCA}{0.240}
\newcommand{\ImgEmotionsHeightCB}{0.246}
\newcommand{\ImgEmotionsHeightCC}{0.249}
\newcommand{\ImgEmotionsHSpaceCC}{-3.0mm}
\newcommand{\ImgEmotionsVSpaceCC}{-4.0mm}
\begin{figure*}
	\centering
	\subfloat{	\includegraphics[trim=00mm 00mm 00mm 00mm,   clip=true, width=0.96 \textwidth]{Figures/Teaser/teaser}		}
	\vspace*{-02.00mm}
	\caption{
				We learn a new \threeD model of the human body called \emph{\smplHF} that jointly models the human body, face and hands. 
				We fit the female \emph{\smplHF} model with \emph{\smplifyPP} to single RGB images and show that it captures a rich variety of \emph{natural} and \emph{expressive} \threeD human poses, gestures and facial expressions.  
	}
	\label{fig:emotionsGETTY}
\vspace*{-3mm}	
\end{figure*} 
Advances in neural networks and large datasets of manually labeled images have resulted in rapid progress in \twoD human ``pose'' estimation.
By ``pose'', the field often means the major joints of the body.  
This is not sufficient to understand human behavior as illustrated in Fig.~\ref{fig:fromDotsToModels}.
OpenPose \cite{cao2017realtime,OpenPoseWEB,simon2017hand} expands this to include the \twoD hand joints and \twoD facial features.
While this captures much more about the communicative intent, it does not support reasoning about surfaces and human interactions with the \threeD world.

Models of the \threeD body have focused on capturing the overall shape and pose of the body, excluding the hands and face \cite{allen2003space,Allen:2006:LCM,Anguelov05,hasler2009statistical,SMPL:2015}. 
There is also an extensive literature on modelling hands \cite{MSR_2015_CVPR_learnShapeModel,Melax:2013:handPhysics,Lepetit:ICCV:2015:handCnnLoop,OikonomidisBMVC,romero2017embodied,DART-Schmidt-RSS-14,srinath_iccv2013,Tkach:SIGGRAPH:2016,Tzionas:IJCV:2016} 
and faces \cite{Amberg2008,BlanzVetter1999,Booth2017,Brunton2014_Review,Cao2014_FaceWarehouse,li2017learning,BFM2009,Vlasic2005,Yang2011} in \threeD but in isolation from the rest of the body.
Only recently has the field begun modeling the body together with hands \cite{romero2017embodied}, or together with the hands and face \cite{joo2018total}.
The \frank model \cite{joo2018total}, for example, combines a simplified version of the \smpl body model \cite{SMPL:2015}, with an artist-designed hand rig, and the \facewarehouse \cite{Cao2014_FaceWarehouse} face model.
These disparate models are stitched together, resulting in a model that is not fully realistic.

Here we learn a new, holistic, body model with face and hands from a large corpus of \threeD scans.
The new \emph{\smplHF} model (\emph{\smpl eXpressive}) is based on \smpl and retains the benefits of that model: compatibility with graphics software, simple parametrization, small size, efficient, differentiable, etc.
We combine \smpl with the \flame head model \cite{li2017learning} and the \mano hand model \cite{romero2017embodied} and then register this combined model to $5586$ \threeD scans that we curate for quality.
By learning the model from data, we capture the natural correlations between the shape of bodies, faces and hands and the resulting model is free of the artifacts seen with \frank.
The expressivity of the model can be seen in Fig.~\ref{fig:emotionsGETTY} where we fit \smplHF to  expressive RGB images, as well as in Fig.~\ref{fig:inthewild_success} where we fit \smplHF to images of the public LSP dataset \cite{johnson2010clustered}. 
\smplHF is freely available for research purposes.

Several methods use deep learning to regress the parameters of \smpl from a single image \cite{kanazawa2018end,omran2018neural,pavlakos2018learning}. 
To estimate a \threeD body with the hands and face though, there exists no suitable training dataset. 
To address this, we follow the approach of \smplify. 
First, we  estimate \twoD image features ``bottom up'' using \openpose \cite{cao2017realtime,simon2017hand,wei2016convolutional}, which detects the joints of the body, hands, feet, and face features.
We then fit the \smplHF model to these \twoD features ``top down'', with our method called \emph{\smplifyPP}. 
To do so, we make several significant improvements over \smplify.
Specifically, we learn a new, and better performing, pose prior from a large dataset of motion capture data \citeMOSH using a variational auto-encoder.
This prior is critical because the mapping from \twoD features to \threeD pose is ambiguous.
We also define a new (self-) interpenetration penalty term that is significantly more accurate and efficient than the approximate method in \smplify; it remains differentiable.
We train a gender detector and use this to automatically determine what body model to use, either male, female or gender neutral.
Finally, one motivation for training direct regression methods to estimate \smpl parameters is that \smplify is slow.
Here we address this with a \pytorch implementation that is at least $8$ times faster than the corresponding \chumpy implementation, by leveraging the computing power of modern GPUs.
Examples of this \smplifyPP method are shown in Fig.~\ref{fig:emotionsGETTY}.

To evaluate the accuracy, we need new data with full-body RGB images and corresponding \threeD ground truth bodies.
To that end, we curate a new evaluation dataset containing images of a subject performing a wide variety of poses, gestures and expressions.
We capture \threeD body shape using a scanning system and we fit the \smplHF model to the scans.
This form of pseudo \gt is accurate enough to enable quantitative evaluations for models of body, hands and faces together. 
We find that our model and method performs significantly better than related and less powerful models, resulting in natural and expressive results. 

We believe that this work is a significant step towards \emph{expressive} capture of bodies, hands and faces \emph{together} from a single RGB image. 
We make available for research purposes the \smplHF model, \smplifyPP code, trained networks, model fits, and the evaluation dataset at \websiteSMPLX.
