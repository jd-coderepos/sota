\documentclass[sigconf]{acmart}
\usepackage[german,american]{babel} 

\usepackage[T1]{fontenc}
\usepackage[latin1]{inputenc} 

\usepackage{xspace}


\newcommand{\Ni}{(1)~}
\newcommand{\Nii}{(2)~}
\newcommand{\Niii}{(3)~}
\newcommand{\Niv}{(4)~}
\newcommand{\Nv}{(5)~}

\newcommand{\Na}{(a)~}
\newcommand{\Nb}{(b)~}
\newcommand{\Nc}{(c)~}
\newcommand{\Nd}{(d)~}
\newcommand{\Ne}{(e)~}


\newcommand{\bslabel}[1]{\textsl{#1.}}


\usepackage{booktabs} 


\usepackage{graphicx}
\DeclareGraphicsRule{.ai}{pdf}{*}{}\DeclareGraphicsExtensions{.pdf,.ai,.jpg,.png}
\pdfpagebox 5\setkeys{Gin}{pagebox=artbox}\graphicspath{{./}}

\newcommand{\bsfigure}[5][scale=1.0]{\begin{figure}[tb]
    \centering
    \includegraphics[#1]{#2}
    \caption{#3}\label{#2}
    \Description[#4]{#5}
\end{figure}}

\newcommand{\bsfigureappendix}[3][scale=1.0]{\begin{figure}[b!]
  \centering
  \includegraphics[#1]{#2}
  \caption{#3}\label{#2}
\end{figure}}


\RequirePackage{type1cm}\RequirePackage{xcolor}
\RequirePackage{soul}
\setstcolor{blue}

\newcommand{\bscom}[2]{\st{#1}{\color{blue}\fontsize{8}{8}\selectfont\,#2}}

  


\setcopyright{iw3c2w3}


\settopmatter{printacmref=true}

\copyrightyear{2020}
\acmYear{2020}
\acmConference[WWW '20]{Proceedings of The Web Conference 2020}{April 20--24, 2020}{Taipei, Taiwan}
\acmBooktitle{Proceedings of The Web Conference 2020 (WWW '20), April 20--24, 2020, Taipei, Taiwan}
\acmPrice{}
\acmDOI{10.1145/3366423.3380206}
\acmISBN{978-1-4503-7023-3/20/04}

\usepackage{silence}
\WarningFilter{acmart}{ACM keywords are mandatory for papers over two pages}
\WarningFilter{acmart}{CCS concepts are mandatory for papers over two pages}


\sloppy
\frenchspacing
\raggedbottom


\begin{document}

\title{Abstractive Snippet Generation}

\settopmatter{authorsperrow=5}

\author{Wei-Fan Chen}
\affiliation{\institution{Paderborn University}
}

\author{Shahbaz Syed}
\affiliation{\institution{Leipzig University}
}

\author{Benno Stein}
\affiliation{\institution{Bauhaus-Universit\"at Weimar}
}

\author{Matthias Hagen}
\affiliation{\institution{\mbox{\kern-0.8em Martin-Luther-Universit\"at} Halle-Wittenberg}
}

\author{Martin Potthast}
\affiliation{\institution{Leipzig University}
}

\begin{abstract}
An {\em abstractive snippet} is an originally created piece of text to summarize a web page on a search engine results page. Compared to the conventional {\em extractive snippets}, which are generated by extracting phrases and sentences verbatim from a web page, abstractive snippets circumvent copyright issues; even more interesting is the fact that they open the door for personalization. Abstractive snippets have been evaluated as equally powerful in terms of user acceptance and expressiveness---but the key question remains: Can abstractive snippets be automatically generated with sufficient quality?

This paper introduces a new approach to abstractive snippet generation: We identify the first two large-scale sources for distant supervision, namely anchor contexts and web directories. By mining the entire ClueWeb09 and ClueWeb12 for anchor contexts and by utilizing the DMOZ Open Directory Project, we compile the Webis Abstractive Snippet Corpus~2020, comprising more than 3.5~million triples of the form query, snippet, document as training examples, where the snippet is either an anchor context or a web directory description in lieu of a genuine query-biased abstractive snippet of the web document. We propose a bidirectional abstractive snippet generation model and assess the quality of both our corpus and the generated abstractive snippets with standard measures, crowdsourcing, and in comparison to the state of the art. The evaluation shows that our novel data sources along with the proposed model allow for producing usable query-biased abstractive snippets while minimizing text reuse.\1ex]
\midrule
\addlinespace
\bfseries Snippet: anchor context \0.5ex]
\parbox{\columnwidth}{[\,\textellipsis] Treasury of Humor is unique in that in addition to being a working joke book, it is a treatise on the theory of humor, propounding Asimov's theory that the essence of humor is an abrupt, jarring change in emphasis and/or point of view, moving from the crucial to the trivial, and/or from the sublime to the ridiculous [\,\textellipsis]} \\
\addlinespace
\bottomrule
\end{tabular}\end{table}
 
The evaluation of generated snippets is another key component of the abstractive snippet generation pipeline. \citet{jones:1995} distinguish two fundamental types of evaluation in natural language processing: intrinsic evaluation (the performance of the system) and extrinsic evaluation (the success of achieving a goal). In the context of natural language generation, \citet{gatt:2018} discussed the popular metrics and methods to evaluate generated texts. They suggest that, in order to draw proper conclusions about the effectiveness of a proposed generation approach, it is crucial to report performance across multiple evaluation metrics. This is doubly important, since, as \citet{amidei:2018} observe, there is a general lack of a standardized evaluation framework for generated texts. Thus, employing a variety of approaches maximizes future comparability. In our paper, we extensively evaluate our corpus and the performance of our models in both intrinsic and extrinsic experiments. With respect to the former, we study the quality of the training examples and that of the generated snippets; with respect to the latter, we study if they meet the goals of abstractiveness, absence of reuse, and if they support in selecting relevant results.
 \section{Abstractive Snippet Corpus}
\label{abstractive-snippet-corpus}

For the construction of the Webis Abstractive Snippet Corpus~2020,\footnote{Corpus: \url{https://webis.de/data.html\#webis-snippet-20}}
we identified the first sources of ground truth for abstractive snippets: anchor contexts and web directories. Our mining pipeline creates the corpus automatically from scratch, given a web archive as input.\footnote{Code: \url{https://github.com/webis-de/WWW-20}}
Corpus quality is assessed via crowdsourcing.

\subsection{Anchor Contexts as Abstractive Snippets}

The first surrogate we consider for genuine abstractive snippets are \emph{anchor contexts}. An anchor context is the text surrounding the anchor text of a hyperlink on a web page (see Table~\ref{table-anchor-context-example}). Ideally, it explains what can be found on the linked web page, e.g., by summarizing its contents. The author of an anchor context personally describes the linked web page, enabling readers to decide whether to visit it or not, just like snippets on search results pages. To identify useful anchor contexts that are fluent, meaningful, and close to this ideal, we employ a multi-step mining process. Table~\ref{table-anchor-context-mining} overviews corresponding mining statistics.

\bslabel{Crawling Raw Anchor Contexts}
We mine anchor contexts from the ClueWeb09 and the ClueWeb12 web crawls,\footnote{See \url{https://lemurproject.org/clueweb09/}~~and~~\url{https://lemurproject.org/clueweb12/}}
focusing on their 1.2~billion English web pages (500~million from the ClueWeb09 and 700~million from the ClueWeb12). For every hyperlink, we extract its anchor text and 1500~characters before and after as anchor context, trading off comprehensiveness and size of the resulting data. The extracted raw 18~billion and 13~billion anchor contexts, respectively, have been fed into the following nine-step pipeline.

\bslabel{Step 1: Intra-site links}
We assume that anchor contexts of cross-site links are more likely genuine pointers to important additional information compared to intra-site links: The vast majority of the latter are found in menus, footers, buttons, and images, entirely lacking plain text context. We discard all anchor contexts of intra-site links by matching the second-level domain names of the web page containing a given context with that of the linked page. More than 96\%~of the raw anchor contexts are thus removed in this step.

\bslabel{Step 2: Non-existing pages}
We discard anchor contexts that link to pages that are not available in the ClueWeb collections; most of them are meanwhile dead links on the live web. This pertains to~75\% and~82\% of the remaining anchor contexts.

\bslabel{Step 3: Non-English pages}
All anchor contexts whose (linked) page is non-English are discarded. We rely on the language identification done for ClueWeb09 encoded in its document~IDs, whereas the ClueWeb12 is advertised as English-only collection.

\bslabel{Step 4: Spam anchors}
The Waterloo spam ranking provides spam scores for the ClueWeb09 and the ClueWeb12~\cite{cormack:2011}. As suggested, we remove anchor contexts whose (linked) pages' spam rank is~\,70\%. However, we make an exception for anchor contexts whose linked pages have a relevance judgment from one of the TREC Web tracks (2009-2014), Session tracks (2010-2014), or Tasks tracks (2015,~2016).

\begin{table}[tb]\small \centering \setlength{\tabcolsep}{4.5pt}\renewcommand{\arraystretch}{0.985}\caption{Statistics of the anchor context mining pipeline.}\label{table-anchor-context-mining}\begin{tabular}{@{}lrrrr@{}}
\toprule
\bfseries Mining pipeline & \multicolumn{2}{@{}c@{}}{\bfseries ClueWeb09}   & \multicolumn{2}{c@{}}{\bfseries ClueWeb12} \\
\cmidrule(l@{\tabcolsep}r@{\tabcolsep}){2-3}\cmidrule(l@{\tabcolsep}){4-5}
& Remaining & \multicolumn{1}{@{}c@{}}{} & Remaining & \multicolumn{1}{c@{}}{} \\
\midrule
Raw anchor contexts      & 17,977,415,779 &          & 12,949,907,331 &          \\
1. Intra-site links      &    440,605,425 &  -97.6\% &    514,337,093 &  -96.0\% \\
2. Non-existing pages    &    111,082,494 &  -74.8\% &     91,007,214 &  -82.3\% \\
3. Non-English pages     &    107,819,314 &   -2.9\% &     91,007,214 &   -0.0\% \\
4. Spam anchors          &     24,767,468 &  -77.0\% &     19,829,007 &  -78.2\% \\
5. Stop anchors          &     17,188,286 &  -30.6\% &     15,837,168 &  -20.1\% \\
6. Improper text         &      9,631,489 &  -44.0\% &      9,248,806 &  -41.6\% \\
7. Duplicated            &      6,292,317 &  -34.7\% &      5,403,893 &  -41.6\% \\
8. Text reuse            &      6,183,783 &   -1.7\% &      5,349,610 &   -1.0\% \\
9. Short web pages       &      5,651,649 &   -8.6\% &      5,114,479 &   -4.4\% \\
\midrule                                                                 
\bfseries Unique pages:  & 2,499,776 & \multicolumn{1}{@{}c@{}}{\ \ --} & 1,557,330 & \multicolumn{1}{@{}c@{}}{\quad--} \\
\bottomrule
\end{tabular}\end{table}
 
\enlargethispage{0.5\baselineskip}
\bslabel{Step 5: Stop anchors}
Anchor contexts whose anchor text is empty, or contains the words ``click'', ``read'', or ``mail'' are removed, since they led our models astray. We also remove multi-link anchor contexts to avoid ambiguous contexts not related to an individual link. As a heuristic, we require a minimum distance of 50~characters between two anchor texts, removing all others.

\bslabel{Step 6: Improper text}
To remove anchor contexts with improper text, we only keep those where
\Ni
the anchor text has at most 10~words (in pilot studies, longer anchor texts were hardly informative or resulted from HTML parsing errors),
\Nii
the anchor text is part of a longer text of at least 50~words (longer texts are a key indicator of meaningful and readable texts),
\Niii
the sentence containing the anchor text has at least 10~words (longer sentences more often resulted in meaningful anchor contexts),
\Niv
the anchor context contains at least one verb as per the Stanford POS tagger~\cite{toutanova:2003}, and
\Nv
the anchor context has a stop word ratio between~10\% and~70\% as per \citeauthor{biber:1999}'s~\cite{biber:1999} study of written English.

\bslabel{Step 7: Duplicated anchor contexts}
To avoid any training bias resulting from duplication, we remove duplicate anchor contexts linking to the same page from different pages. To quickly process all the pairs of anchor contexts for each individual page, we use locality-sensitive hashing~(LSH)~\cite{rao:2016}. We first encoded all anchor contexts as 128-dimensional binary vectors based on word unigrams, bigrams, and trigrams and then removed one of the anchor contexts as ``duplicate'' to another if the cosine similarity of their vectors was larger than~0.9 (this value was determined in pilot studies). Another 34-42\% of the anchor contexts were removed as duplicates.

\bslabel{Step 8: Text reuse}
Since our goal is {\em abstractive} snippet generation, we exclude all anchor contexts that are purely {\em extractive}. This was done by checking if the anchor context was completely copied from their respective linked pages. Partial reuse, i.e., due to reordering of phrases, however, has been retained as a mild form of abstraction.

\bslabel{Step 9: Short web pages}
Finally, we removed anchor contexts whose linked web pages contained less than 100~words to ensure a sufficient basis for summarization. Arguably, snippets need to be generated for shorter pages, too. However, we envision different, specialized snippet generators for different length classes of web pages, which we leave for future work.

Altogether, we obtained 10,766,128 anchor context, web docu\-ment tuples from the two ClueWeb collections referring to 4,057,106 unique pages. The average length of an extracted anchor contexts is 190~words (longest:~728; shortest:~50). The average linked page is 841~words long (longest:~14,339; shortest:~100) and it has 2.65~anchor contexts, while about two-thirds (2,675,980~pages) have only one, and the most often linked page has 12,925 anchor contexts.

\subsection{DMOZ Descriptions as Abstractive Snippets}

\begin{table}[tb]\small \centering \setuldepth{The}\caption{Example of a DMOZ description as training snippet.}\label{table-dmoz-example}\begin{tabular}{@{}l@{}}
\toprule
\addlinespace
\parbox{\columnwidth}{{\bfseries Query}: Customer Respect Index} \0.5ex]
\parbox{\columnwidth}{\raggedright {\color{blue}\ul{The Customer Respect Group}}: An international research and consulting firm, publishes the Online Customer Respect Index (CRI) and provides industry and company-specific research and analysis to help companies increase sales and customer retention by improving how they treat their customers online.} \\
\addlinespace
\midrule
\addlinespace
\bfseries Document \1.25ex]
\midrule
    20.5 &     4.2  &     15.4  \\
    14.3 &     1.1  &     10.5  \\
    15.6 &     1.7  &     11.4  \\
    20.8 &     2.8  &     15.6  \\
    23.0 &     5.0  &     18.0  \\
\bf 25.7 & \bf 5.2  & \bf 20.1  \\
\bottomrule
\end{tabular}\hfill \begin{tabular}[t]{@{}rrr@{}}
\multicolumn{1}{@{}l@{}}{(b)} \\
\toprule
\multicolumn{3}{@{}c@{}}{{\bfseries Quality} (autom.)}  \\
\midrule
Fluency & Fact. & Reuse  \\
\0.625ex]
\bfseries flns. \1ex]
\midrule
{\bfseries Web document} (excerpt; ClueWeb09 ID ``clueweb09-en0020-20-15833'')
\0.5ex]
\parbox{\columnwidth}{{\color{gray}All bike new England routes are available on one disk with over {\small\tt<num>} cue sheets and maps from {\small\tt<num>} years of touring in the Berkshires, the Massachusetts north shore, Cape Cod, Vermont, New Hampshire} and {\setulcolor{lightgray}\ul{Vermont}}. {\color{gray}Rides are up to~45 miles a day, with shorter loops for all levels of {\bf cycling} ability.}} \\
\addlinespace
\midrule
\addlinespace
\bfseries Paraphraser \0.5ex]
\parbox{\columnwidth}{Guided {\bf bike tours} in Massachusetts, {\setulcolor{lightgray}\ul{Massachusetts}}, Rhode island, New Hampshire, Connecticut, {\setulcolor{lightgray}\ul{Massachusetts}} and {\setulcolor{lightgray}\ul{Massachusetts}}. Includes information on {\bf tours}, {\setulcolor{lightgray}\ul{\bf tours}}, events, and contacts. \ul{Located in Boston.}} \\
\addlinespace
\midrule
\addlinespace
\bfseries DMOZ-QB\0.5ex]
\parbox{\columnwidth}{For more information on \ul{the Deerfield river bike tour }\ul{\bf cycling}, visit the \ul{Deerfield} web site. \ul{The Deerfield is a small company} offering group tour services for organizations and individuals in the north shore area of Massachusetts, southern New Hampshire and Vermont, and \ul{the popular Worcester mountains of western Massachusetts.}} \\
\addlinespace
\midrule
\addlinespace
\bfseries AnchorContext-QB \0.5ex]
\parbox{\columnwidth}{\ul{Walking} and {\bf cycling tours}. \ul{The }\ul{\bf tours}\ul{ is a great place} to start and enjoy \ul{the best of the great lakes in the United States and around the world,} as well as some of \ul{the most beautiful and }{\setulcolor{lightgray}\ul{\mbox{beautiful places}}}\ul{ in }{\setulcolor{lightgray}\ul{\mbox{the world}}}.} \\
\addlinespace
\bottomrule
\end{tabular}\end{table}
 
Altogether, despite the encouraging evaluation results, our in-depth analysis of the example as well as others reveals a lot of room for improvement. All models except the mostly reusing {\small\tt CNN-DM} model introduce language or factual errors to a greater or lesser extent, the factual errors being the most important issue to tackle in future work. The baseline models {\small\tt CNN-DM} and {\small\tt Paraphraser} disqualify themselves with respect to text reuse; they are hardly abstractive. A cause for the shortcomings of the two query-biased models {\small\tt DMOZ-QB} and {\small\tt AnchorContext-QB} may be the fact that they are forced to start generating with the query, which may not be an optimal starting point, whereas query bias is important for snippet generation. 

\subsection{Model Ranking}

Snippet usefulness---the capability of a model to generate snippets that enable humans to select relevant results---is the key measure to rank abstractive snippet generation models. Our {\small\tt AnchorContext-QB} model performs best, achieving an F-score competitive to that of extractive snippets. Nevertheless, it does not achieve the crowdsourced effectiveness and fluency scores of {\small\tt CNN-DM}, which achieves the second-highest usefulness score. The latter, however, mostly reuses text from the summarized documents: There is no practical advantage in training a neural snippet generation model that is not actually abstractive, since state-of-the-art extractive snippet generators perform competitively with little development overhead.

The {\small\tt Paraphraser} and the two DMOZ-based models are ranked third to fifth in terms of usefulness, while their ranking is reversed in terms of reuse. The {\small\tt Paraphraser} and the query-biased DMOZ model have the lowest fluency among all models, while the remaining query-unbiased DMOZ model scores second to lowest in terms of usefulness. Nevertheless, the writing style of the snippets generated by the DMOZ-based models is closest to our expectation of a well-written snippet. It is conceivable, however, that by restoring the entire DMOZ directory and by retrieving archived versions of its linked pages, a substantially higher overall performance can be attained than is possible with the comparably small amount of training examples we could obtain. That size of the training data matters,  can be observed for the query-unbiased {\small\tt AnchorContext} model, which is trained on 10~million examples and achieves the best fluency in terms of perplexity and second-best fluency as per crowd judgment, while reusing the least of the original document. However, its usefulness score is lowest of all models, showing that enforcing query bias may be necessary to ensure the model does not ``hallucinate''. Thus, increasing the number of query-biased anchor context-based training examples might allow to combine the strengths of the two anchor context-based models.

 \section{Conclusion}

With anchor contexts and web directory descriptions, we presented two new sources for distant supervision for the new task of abstractive snippet generation, constructing the first large-scale corpus of query-biased training examples. To effectively exploit this corpus, we propose a bidirectional generation model based on pointer-generator networks, which preserves query terms while generating fluent snippets with low text reuse from the source document. Intrinsic and extrinsic evaluations show that, dependent on what data the model uses for training, it generates abstractive snippets that can be used to reliably select relevant documents on a search results page. Nevertheless, several problems remain unsolved.

Is abstractive snippet generation worth the effort required to develop it further? That strongly depends on whether regulatory bodies will continue to limit fair use with respect to text reuse for extractive snippets, and whether generating abstractive snippets allows for improving users' search experience. Throughout the paper, we outlined several avenues for future work, and we plan on following at least some of them. We also hope that the IR~community and the natural language generation community will pick up this new challenge. It presents a fresh use case for abstractive summarization with the potential of changing an entire industry.


\begin{acks}
This work was partially supported by the German Research Foundation (DFG) within the Collaborative Research Center ``On-The-Fly Computing'' (SFB~901/3) under the project number~160364472.
\end{acks} 
\begin{raggedright}


\begin{thebibliography}{39}



\ifx \showCODEN    \undefined \def \showCODEN     #1{\unskip}     \fi
\ifx \showDOI      \undefined \def \showDOI       #1{#1}\fi
\ifx \showISBNx    \undefined \def \showISBNx     #1{\unskip}     \fi
\ifx \showISBNxiii \undefined \def \showISBNxiii  #1{\unskip}     \fi
\ifx \showISSN     \undefined \def \showISSN      #1{\unskip}     \fi
\ifx \showLCCN     \undefined \def \showLCCN      #1{\unskip}     \fi
\ifx \shownote     \undefined \def \shownote      #1{#1}          \fi
\ifx \showarticletitle \undefined \def \showarticletitle #1{#1}   \fi
\ifx \showURL      \undefined \def \showURL       {\relax}        \fi
\providecommand\bibfield[2]{#2}
\providecommand\bibinfo[2]{#2}
\providecommand\natexlab[1]{#1}
\providecommand\showeprint[2][]{arXiv:#2}

\balance

\bibitem[\protect\citeauthoryear{Amidei, Piwek, and Willis}{Amidei
  et~al\mbox{.}}{2018}]{amidei:2018}
\bibfield{author}{\bibinfo{person}{Jacopo Amidei}, \bibinfo{person}{Paul
  Piwek}, {and} \bibinfo{person}{Alistair Willis}.}
  \bibinfo{year}{2018}\natexlab{}.
\newblock \showarticletitle{Evaluation Methodologies in Automatic Question
  Generation 2013--2018}. In \bibinfo{booktitle}{{\em Proceedings of INLG
  2018}}. \bibinfo{pages}{307--317}.
\newblock


\bibitem[\protect\citeauthoryear{Baumel, Eyal, and Elhadad}{Baumel
  et~al\mbox{.}}{2018}]{baumel:2018}
\bibfield{author}{\bibinfo{person}{Tal Baumel}, \bibinfo{person}{Matan Eyal},
  {and} \bibinfo{person}{Michael Elhadad}.} \bibinfo{year}{2018}\natexlab{}.
\newblock \showarticletitle{Query Focused Abstractive Summarization:
  Incorporating Query Relevance, Multi-Document Coverage, and Summary Length
  Constraints into Seq2seq Models}.
\newblock \bibinfo{journal}{{\em arXiv:1801.07704\/}}.
\newblock


\bibitem[\protect\citeauthoryear{Biber, Johansson, Leech, Conrad, and
  Finegan}{Biber et~al\mbox{.}}{1999}]{biber:1999}
\bibfield{author}{\bibinfo{person}{Douglas Biber}, \bibinfo{person}{Stig
  Johansson}, \bibinfo{person}{Geoffrey Leech}, \bibinfo{person}{Susan Conrad},
  {and} \bibinfo{person}{Edward Finegan}.} \bibinfo{year}{1999}\natexlab{}.
\newblock \bibinfo{booktitle}{{\em Longman Grammar of Spoken and Written
  English}}.
\newblock \bibinfo{publisher}{Longman}.
\newblock


\bibitem[\protect\citeauthoryear{Brin and Page}{Brin and Page}{1998}]{brin:98}
\bibfield{author}{\bibinfo{person}{Sergey Brin} {and} \bibinfo{person}{Lawrence
  Page}.} \bibinfo{year}{1998}\natexlab{}.
\newblock \showarticletitle{{The Anatomy of a Large-Scale Hypertextual Web
  Search Engine}}.
\newblock \bibinfo{journal}{{\em Computer Networks\/}}  \bibinfo{volume}{30}
  (\bibinfo{year}{1998}), \bibinfo{pages}{107--117}.
\newblock


\bibitem[\protect\citeauthoryear{Cao, Wei, Li, and Li}{Cao
  et~al\mbox{.}}{2018}]{cao:2018}
\bibfield{author}{\bibinfo{person}{Ziqiang Cao}, \bibinfo{person}{Furu Wei},
  \bibinfo{person}{Wenjie Li}, {and} \bibinfo{person}{Sujian Li}.}
  \bibinfo{year}{2018}\natexlab{}.
\newblock \showarticletitle{Faithful to the Original: Fact Aware Neural
  Abstractive Summarization}. In \bibinfo{booktitle}{{\em Proceedings of AAAI
  2018}}. \bibinfo{pages}{4784--4791}.
\newblock


\bibitem[\protect\citeauthoryear{Chen, Hagen, Stein, and Potthast}{Chen
  et~al\mbox{.}}{2018a}]{stein:2018k}
\bibfield{author}{\bibinfo{person}{Wei-Fan Chen}, \bibinfo{person}{Matthias
  Hagen}, \bibinfo{person}{Benno Stein}, {and} \bibinfo{person}{Martin
  Potthast}.} \bibinfo{year}{2018}\natexlab{a}.
\newblock \showarticletitle{{A User Study on Snippet Generation: Text Reuse vs.
  Paraphrases}}. In \bibinfo{booktitle}{{\em Proceedings of SIGIR 2018}}.
  \bibinfo{pages}{1033--1036}.
\newblock


\bibitem[\protect\citeauthoryear{Cormack, Smucker, and Clarke}{Cormack
  et~al\mbox{.}}{2011}]{cormack:2011}
\bibfield{author}{\bibinfo{person}{Gordon~V. Cormack}, \bibinfo{person}{Mark~D.
  Smucker}, {and} \bibinfo{person}{Charles~L.A. Clarke}.}
  \bibinfo{year}{2011}\natexlab{}.
\newblock \showarticletitle{Efficient and Effective Spam Filtering and
  Re-ranking for Large Web Datasets}.
\newblock \bibinfo{journal}{{\em Information Retrieval\/}}
  \bibinfo{volume}{14}, \bibinfo{number}{5} (\bibinfo{year}{2011}),
  \bibinfo{pages}{441--465}.
\newblock


\bibitem[\protect\citeauthoryear{Dang}{Dang}{2005}]{dang:2005}
\bibfield{author}{\bibinfo{person}{Hoa~Trang Dang}.}
  \bibinfo{year}{2005}\natexlab{}.
\newblock \showarticletitle{Overview of DUC 2005}. In \bibinfo{booktitle}{{\em
  Proceedings of DUC 2005}}.
\newblock


\bibitem[\protect\citeauthoryear{Dang}{Dang}{2006}]{dang:2006}
\bibfield{author}{\bibinfo{person}{Hoa~Trang Dang}.}
  \bibinfo{year}{2006}\natexlab{}.
\newblock \showarticletitle{Overview of DUC 2006}. In \bibinfo{booktitle}{{\em
  Proceedings of DUC 2006}}.
\newblock


\bibitem[\protect\citeauthoryear{Dang}{Dang}{2007}]{dang:2007}
\bibfield{author}{\bibinfo{person}{Hoa~Trang Dang}.}
  \bibinfo{year}{2007}\natexlab{}.
\newblock \showarticletitle{Overview of DUC 2007}. In \bibinfo{booktitle}{{\em
  Proceedings of DUC 2007}}.
\newblock


\bibitem[\protect\citeauthoryear{Devlin, Chang, Lee, and Toutanova}{Devlin
  et~al\mbox{.}}{2019}]{devlin:2019}
\bibfield{author}{\bibinfo{person}{Jacob Devlin}, \bibinfo{person}{Ming-Wei
  Chang}, \bibinfo{person}{Kenton Lee}, {and} \bibinfo{person}{Kristina
  Toutanova}.} \bibinfo{year}{2019}\natexlab{}.
\newblock \showarticletitle{BERT: Pre-training of Deep Bidirectional
  Transformers for Language Understanding}. In \bibinfo{booktitle}{{\em
  Proceedings of NAACL-HLT 2019}}. \bibinfo{pages}{4171--4186}.
\newblock


\bibitem[\protect\citeauthoryear{Gatt and Krahmer}{Gatt and Krahmer}{2018}]{gatt:2018}
\bibfield{author}{\bibinfo{person}{Albert Gatt} {and} \bibinfo{person}{Emiel
  Krahmer}.} \bibinfo{year}{2018}\natexlab{}.
\newblock \showarticletitle{Survey of the State of the Art in Natural Language
  Generation: Core Tasks, Applications and Evaluation}.
\newblock \bibinfo{journal}{{\em Journal of Artificial Intelligence
  Research\/}}  \bibinfo{volume}{61} (\bibinfo{year}{2018}),
  \bibinfo{pages}{65--170}.
\newblock


\bibitem[\protect\citeauthoryear{Grusky, Naaman, and Artzi}{Grusky
  et~al\mbox{.}}{2018}]{grusky:2018}
\bibfield{author}{\bibinfo{person}{Max Grusky}, \bibinfo{person}{Mor Naaman},
  {and} \bibinfo{person}{Yoav Artzi}.} \bibinfo{year}{2018}\natexlab{}.
\newblock \showarticletitle{Newsroom: A Dataset of 1.3 Million Summaries with
  Diverse Extractive Strategies}. In \bibinfo{booktitle}{{\em Proceedings of
  NAACL-HLT 2018}}. \bibinfo{pages}{708--719}.
\newblock


\bibitem[\protect\citeauthoryear{Gu, Lu, Li, and Li}{Gu et~al\mbox{.}}{2016}]{gu:2016}
\bibfield{author}{\bibinfo{person}{Jiatao Gu}, \bibinfo{person}{Zhengdong Lu},
  \bibinfo{person}{Hang Li}, {and} \bibinfo{person}{Victor~O.K. Li}.}
  \bibinfo{year}{2016}\natexlab{}.
\newblock \showarticletitle{Incorporating Copying Mechanism in
  Sequence-to-Sequence Learning}. In \bibinfo{booktitle}{{\em Proceedings of
  ACL 2016}}. \bibinfo{pages}{1631--1640}.
\newblock


\bibitem[\protect\citeauthoryear{Hagen, Potthast, Beyer, and Stein}{Hagen
  et~al\mbox{.}}{2012}]{hagen:2012}
\bibfield{author}{\bibinfo{person}{Matthias Hagen}, \bibinfo{person}{Martin
  Potthast}, \bibinfo{person}{Anna Beyer}, {and} \bibinfo{person}{Benno
  Stein}.} \bibinfo{year}{2012}\natexlab{}.
\newblock \showarticletitle{Towards Optimum Query Segmentation: In Doubt
  Without}. In \bibinfo{booktitle}{{\em Proceedings of CIKM 2012}}.
  \bibinfo{pages}{1015--1024}.
\newblock


\bibitem[\protect\citeauthoryear{Hasselqvist, Helmertz, and
  K{\aa}geb{\"a}ck}{Hasselqvist et~al\mbox{.}}{2017}]{hasselqvist:2017}
\bibfield{author}{\bibinfo{person}{Johan Hasselqvist}, \bibinfo{person}{Niklas
  Helmertz}, {and} \bibinfo{person}{Mikael K{\aa}geb{\"a}ck}.}
  \bibinfo{year}{2017}\natexlab{}.
\newblock \showarticletitle{Query-Based Abstractive Summarization using Neural
  Networks}.
\newblock \bibinfo{journal}{{\em arXiv:1712.06100\/}}.
\newblock


\bibitem[\protect\citeauthoryear{Hermann, Kocisky, Grefenstette, Espeholt, Kay,
  Suleyman, and Blunsom}{Hermann et~al\mbox{.}}{2015}]{hermann:2015}
\bibfield{author}{\bibinfo{person}{Karl~Moritz Hermann}, \bibinfo{person}{Tomas
  Kocisky}, \bibinfo{person}{Edward Grefenstette}, \bibinfo{person}{Lasse
  Espeholt}, \bibinfo{person}{Will Kay}, \bibinfo{person}{Mustafa Suleyman},
  {and} \bibinfo{person}{Phil Blunsom}.} \bibinfo{year}{2015}\natexlab{}.
\newblock \showarticletitle{Teaching Machines to Read and Comprehend}. In
  \bibinfo{booktitle}{{\em Proceedings of NIPS 2015}}.
  \bibinfo{pages}{1693--1701}.
\newblock


\bibitem[\protect\citeauthoryear{Jones and Galliers}{Jones and
  Galliers}{1995}]{jones:1995}
\bibfield{author}{\bibinfo{person}{Karen~Sparck Jones} {and}
  \bibinfo{person}{Julia~R Galliers}.} \bibinfo{year}{1995}\natexlab{}.
\newblock \bibinfo{booktitle}{{\em Evaluating Natural Language Processing
  Systems: An Analysis and Review}}.
\newblock \bibinfo{publisher}{Springer}.
\newblock


\bibitem[\protect\citeauthoryear{Kaisser, Hearst, and Lowe}{Kaisser
  et~al\mbox{.}}{2008}]{kaisser:08}
\bibfield{author}{\bibinfo{person}{Michael Kaisser}, \bibinfo{person}{{Marti
  A.} Hearst}, {and} \bibinfo{person}{{John B.} Lowe}.}
  \bibinfo{year}{2008}\natexlab{}.
\newblock \showarticletitle{{Improving Search Results Quality by Customizing
  Summary Lengths}}. In \bibinfo{booktitle}{{\em Proceedings of ACL 2008}}.
  \bibinfo{pages}{701--709}.
\newblock


\bibitem[\protect\citeauthoryear{Kiesel, Stein, and Lucks}{Kiesel
  et~al\mbox{.}}{2017}]{kiesel:2017}
\bibfield{author}{\bibinfo{person}{Johannes Kiesel}, \bibinfo{person}{Benno
  Stein}, {and} \bibinfo{person}{Stefan Lucks}.}
  \bibinfo{year}{2017}\natexlab{}.
\newblock \showarticletitle{A Large-scale Analysis of the Mnemonic Password
  Advice}. In \bibinfo{booktitle}{{\em Proceedings of NDSS 2017}}.
\newblock


\bibitem[\protect\citeauthoryear{Kim, Thomas, Sankaranarayana, Gedeon, and
  Yoon}{Kim et~al\mbox{.}}{2017}]{kim:17}
\bibfield{author}{\bibinfo{person}{Jaewon Kim}, \bibinfo{person}{Paul Thomas},
  \bibinfo{person}{Ramesh Sankaranarayana}, \bibinfo{person}{Tom Gedeon}, {and}
  \bibinfo{person}{Hwan-Jin Yoon}.} \bibinfo{year}{2017}\natexlab{}.
\newblock \showarticletitle{{What Snippet Size is Needed in Mobile Web
  Search?}} In \bibinfo{booktitle}{{\em Proceedings of CHIIR 2017}}.
  \bibinfo{pages}{97--106}.
\newblock


\bibitem[\protect\citeauthoryear{Klein, Kim, Deng, Senellart, and Rush}{Klein
  et~al\mbox{.}}{2017}]{klein:2017}
\bibfield{author}{\bibinfo{person}{Guillaume Klein}, \bibinfo{person}{Yoon
  Kim}, \bibinfo{person}{Yuntian Deng}, \bibinfo{person}{Jean Senellart}, {and}
  \bibinfo{person}{Alexander~M. Rush}.} \bibinfo{year}{2017}\natexlab{}.
\newblock \showarticletitle{Open{NMT}: Open-Source Toolkit for Neural Machine
  Translation}. In \bibinfo{booktitle}{{\em Proceedings of ACL 2017 (Demos)}}. \bibinfo{pages}{67--72}.
\newblock


\bibitem[\protect\citeauthoryear{Lin}{Lin}{2004}]{lin:2004}
\bibfield{author}{\bibinfo{person}{Chin-Yew Lin}.}
  \bibinfo{year}{2004}\natexlab{}.
\newblock \showarticletitle{ROUGE: A package for Automatic Evaluation of
  Summaries}. In \bibinfo{booktitle}{{\em Proceedings of the ACL Workshop on
  Text Summarization Branches Out}}. \bibinfo{pages}{74--81}.
\newblock


\bibitem[\protect\citeauthoryear{Liu, Saleh, Pot, Goodrich, Sepassi, Kaiser,
  and Shazeer}{Liu et~al\mbox{.}}{2018}]{liu:2018}
\bibfield{author}{\bibinfo{person}{Peter~J Liu}, \bibinfo{person}{Mohammad
  Saleh}, \bibinfo{person}{Etienne Pot}, \bibinfo{person}{Ben Goodrich},
  \bibinfo{person}{Ryan Sepassi}, \bibinfo{person}{Lukasz Kaiser}, {and}
  \bibinfo{person}{Noam Shazeer}.} \bibinfo{year}{2018}\natexlab{}.
\newblock \showarticletitle{Generating Wikipedia by Summarizing Long
  Sequences}. In \bibinfo{booktitle}{{\em Proceedings of ICLR 2018 (Posters)}}.
\newblock


\bibitem[\protect\citeauthoryear{Luhn}{Luhn}{1958}]{luhn:1958}
\bibfield{author}{\bibinfo{person}{{Hans Peter} Luhn}.}
  \bibinfo{year}{1958}\natexlab{}.
\newblock \showarticletitle{{The Automatic Creation of Literature Abstracts}}.
\newblock \bibinfo{journal}{{\em {IBM} Journal of Research and Development\/}}
  \bibinfo{volume}{2}, \bibinfo{number}{2} (\bibinfo{year}{1958}),
  \bibinfo{pages}{159--165}.
\newblock


\bibitem[\protect\citeauthoryear{Maxwell, Azzopardi, and Moshfeghi}{Maxwell
  et~al\mbox{.}}{2017}]{maxwell:17}
\bibfield{author}{\bibinfo{person}{David Maxwell}, \bibinfo{person}{Leif
  Azzopardi}, {and} \bibinfo{person}{Yashar Moshfeghi}.}
  \bibinfo{year}{2017}\natexlab{}.
\newblock \showarticletitle{{A Study of Snippet Length and Informativeness:
  Behaviour, Performance and User Experience}}. In \bibinfo{booktitle}{{\em
  Proceedings of SIGIR 2017}}. \bibinfo{pages}{135--144}.
\newblock


\bibitem[\protect\citeauthoryear{Nema, Khapra, Laha, and Ravindran}{Nema
  et~al\mbox{.}}{2017}]{nema:2017}
\bibfield{author}{\bibinfo{person}{Preksha Nema}, \bibinfo{person}{Mitesh~M
  Khapra}, \bibinfo{person}{Anirban Laha}, {and} \bibinfo{person}{Balaraman
  Ravindran}.} \bibinfo{year}{2017}\natexlab{}.
\newblock \showarticletitle{Diversity Driven Attention Model for Query-based
  Abstractive Summarization}. In \bibinfo{booktitle}{{\em Proceedings of ACL
  2017}}. \bibinfo{pages}{1063--1072}.
\newblock


\bibitem[\protect\citeauthoryear{Potthast, Chen, Hagen, and Stein}{Potthast
  et~al\mbox{.}}{2018}]{stein:2018b}
\bibfield{author}{\bibinfo{person}{Martin Potthast}, \bibinfo{person}{Wei-Fan
  Chen}, \bibinfo{person}{Matthias Hagen}, {and} \bibinfo{person}{Benno
  Stein}.} \bibinfo{year}{2018}\natexlab{}.
\newblock \showarticletitle{{A Plan for Ancillary Copyright: Original
  Snippets}}. In \bibinfo{booktitle}{{\em Proceedings of the NewsIR workshop at ECIR~2018}}.
  \bibinfo{pages}{3--5}.
\newblock


\bibitem[\protect\citeauthoryear{Rao and Zhu}{Rao and Zhu}{2016}]{rao:2016}
\bibfield{author}{\bibinfo{person}{BiChen Rao} {and} \bibinfo{person}{Erkang
  Zhu}.} \bibinfo{year}{2016}\natexlab{}.
\newblock \showarticletitle{Searching Web Data using MinHash LSH}. In
  \bibinfo{booktitle}{{\em Proceedings of {SIGMOD} 2016}}.
  \bibinfo{pages}{2257--2258}.
\newblock


\bibitem[\protect\citeauthoryear{Rush, Chopra, and Weston}{Rush
  et~al\mbox{.}}{2015}]{rush:2015}
\bibfield{author}{\bibinfo{person}{{Alexander M.} Rush}, \bibinfo{person}{Sumit
  Chopra}, {and} \bibinfo{person}{Jason Weston}.}
  \bibinfo{year}{2015}\natexlab{}.
\newblock \showarticletitle{{A Neural Attention Model for Abstractive Sentence
  Summarization}}. In \bibinfo{booktitle}{{\em Proceedings of EMNLP 2015}}.
  \bibinfo{pages}{379--389}
\newblock


\bibitem[\protect\citeauthoryear{See, Liu, and Manning}{See
  et~al\mbox{.}}{2017}]{see:2017}
\bibfield{author}{\bibinfo{person}{Abigail See}, \bibinfo{person}{{Peter J.}
  Liu}, {and} \bibinfo{person}{{Christopher D.} Manning}.}
  \bibinfo{year}{2017}\natexlab{}.
\newblock \showarticletitle{{Get to the Point: Summarization with
  Pointer-Generator Networks}}. In \bibinfo{booktitle}{{\em Proceedings of ACL
  2017}}. \bibinfo{pages}{1073--1083}
\newblock


\bibitem[\protect\citeauthoryear{Syed, V{\"o}lske, Lipka, Stein, Sch{\"u}tze,
  and Potthast}{Syed et~al\mbox{.}}{2019}]{stein:2019x}
\bibfield{author}{\bibinfo{person}{Shahbaz Syed}, \bibinfo{person}{Michael
  V{\"o}lske}, \bibinfo{person}{Nedim Lipka}, \bibinfo{person}{Benno Stein},
  \bibinfo{person}{Hinrich Sch{\"u}tze}, {and} \bibinfo{person}{Martin
  Potthast}.} \bibinfo{year}{2019}\natexlab{}.
\newblock \showarticletitle{{Towards Summarization for Social Media - Results
  of the TL;DR Challenge}}. In \bibinfo{booktitle}{{\em Proceedings of INLG~2019}}. \bibinfo{pages}{523--528}
\newblock


\bibitem[\protect\citeauthoryear{Syed, V{\"o}lske, Potthast, Lipka, Stein, and
  Sch{\"u}tze}{Syed et~al\mbox{.}}{2018}]{stein:2018za}
\bibfield{author}{\bibinfo{person}{Shahbaz Syed}, \bibinfo{person}{Michael
  V{\"o}lske}, \bibinfo{person}{Martin Potthast}, \bibinfo{person}{Nedim
  Lipka}, \bibinfo{person}{Benno Stein}, {and} \bibinfo{person}{Hinrich
  Sch{\"u}tze}.} \bibinfo{year}{2018}\natexlab{}.
\newblock \showarticletitle{{Task Proposal: The TL;DR Challenge}}. In
  \bibinfo{booktitle}{{\em Proceedings of INLG 2018}}.
  \bibinfo{pages}{318--321}.
\newblock


\bibitem[\protect\citeauthoryear{Tombros and Sanderson}{Tombros and
  Sanderson}{1998}]{tombros:1998}
\bibfield{author}{\bibinfo{person}{Anastasios Tombros} {and}
  \bibinfo{person}{Mark Sanderson}.} \bibinfo{year}{1998}\natexlab{}.
\newblock \showarticletitle{{Advantages of Query Biased Summaries in
  Information Retrieval}}. In \bibinfo{booktitle}{{\em Proceedings of {SIGIR}
  1998}}. \bibinfo{pages}{2--10}.
\newblock


\bibitem[\protect\citeauthoryear{Toutanova, Klein, Manning, and
  Singer}{Toutanova et~al\mbox{.}}{2003}]{toutanova:2003}
\bibfield{author}{\bibinfo{person}{Kristina Toutanova}, \bibinfo{person}{Dan
  Klein}, \bibinfo{person}{Christopher~D. Manning}, {and}
  \bibinfo{person}{Yoram Singer}.} \bibinfo{year}{2003}\natexlab{}.
\newblock \showarticletitle{Feature-Rich Part-of-Speech Tagging with a Cyclic
  Dependency Network}. In \bibinfo{booktitle}{{\em Proceedings of NAACL-HLT
  2003}}. \bibinfo{pages}{252--259}.
\newblock


\bibitem[\protect\citeauthoryear{White, Ruthven, and Jose}{White
  et~al\mbox{.}}{2002a}]{white:2002a}
\bibfield{author}{\bibinfo{person}{Ryen White}, \bibinfo{person}{Ian Ruthven},
  {and} \bibinfo{person}{{Joemon M.} Jose}.} \bibinfo{year}{2002}\natexlab{a}.
\newblock \showarticletitle{{Finding Relevant Documents using Top Ranking
  Sentences: An Evaluation of Two Alternative Schemes}}. In
  \bibinfo{booktitle}{{\em Proceedings of {SIGIR} 2002}}.
  \bibinfo{pages}{57--64}.
\newblock


\bibitem[\protect\citeauthoryear{White, Ruthven, and Jose}{White
  et~al\mbox{.}}{2002b}]{white:2002b}
\bibfield{author}{\bibinfo{person}{Ryen White}, \bibinfo{person}{Ian Ruthven},
  {and} \bibinfo{person}{{Joemon M.} Jose}.} \bibinfo{year}{2002}\natexlab{b}.
\newblock \showarticletitle{{The Use of Implicit Evidence for Relevance
  Feedback in Web Retrieval}}. In \bibinfo{booktitle}{{\em Proceedings of ECIR
  2002}}. \bibinfo{pages}{93--109}.
\newblock


\bibitem[\protect\citeauthoryear{Wieting, Mallinson, and Gimpel}{Wieting
  et~al\mbox{.}}{2017}]{wieting:2017}
\bibfield{author}{\bibinfo{person}{John Wieting}, \bibinfo{person}{Jonathan
  Mallinson}, {and} \bibinfo{person}{Kevin Gimpel}.}
  \bibinfo{year}{2017}\natexlab{}.
\newblock \showarticletitle{Learning Paraphrastic Sentence Embeddings from
  Back-Translated Bitext}. In \bibinfo{booktitle}{{\em Proceedings of EMNLP
  2017}}. \bibinfo{pages}{274--285}
\newblock


\end{thebibliography}
 \end{raggedright}

\end{document}
