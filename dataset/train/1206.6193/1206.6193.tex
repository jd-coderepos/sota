\documentclass[oribibl,envcountsect,envcountsame]{llncs}


\usepackage{latexsym}
\usepackage{epsfig}
\usepackage{verbatim}
\usepackage{floatflt}
\usepackage{cite}
\usepackage{amssymb}
\usepackage{amsmath}
\usepackage{graphicx}

\newcommand{\ignore}[1]{}

\newtheorem{corol}[theorem]{Corollary}


\DeclareMathOperator{\dec}{dec}
\DeclareMathOperator{\pj}{proj}
\DeclareMathOperator{\lt}{lift}
\newcommand{\Vred}{V_\text{red}}
\newcommand{\B}{\mathcal B}
\newcommand{\C}{\mathcal C}
\newcommand{\U}{\mathcal U}
\newcommand{\R}{\mathbb R}
\newcommand{\N}{\mathbb N}

\newcommand{\eps}{\varepsilon}
\newcommand{\EX}{\hbox{\textbf{E}}\,}
\newcommand{\var}{\hbox{\bf var}}
\newcommand{\prob}{{\rm Prob}}
\newcommand{\reals}{{\rm I\!\hspace{-0.025em} R}}
\newcommand{\dist}{\hbox{dist}}
\newcommand{\eqdef}{:=}

\title{Data Structures on Event Graphs\thanks{A preliminary
version appeared as B. Chazelle and W. Mulzer,
\emph{Data Structures on Event Graphs} in Proc.~20th ESA, pp.~313--324, 2012}}

\date{}

\author{
Bernard Chazelle\inst{1}
\and
Wolfgang Mulzer\inst{2}
}
\institute{
Department of Computer Science, Princeton University, USA
\email{chazelle@cs.princeton.edu}
\and
Institut f{\"ur} Informatik, Freie Universit{\"a}t Berlin, Germany
\email{mulzer@inf.fu-berlin.de}
}

\begin{document} \maketitle

\begin{abstract}
We investigate the behavior of 
data structures when the input
and operations are generated by an
\emph{event graph}. 
This model is inspired by 
Markov chains.
We are given a fixed graph ,
whose nodes 
are annotated with operations of the type 
\emph{insert}, \emph{delete}, and \emph{query}.
The algorithm responds to the requests 
as it encounters them during a (random or adversarial) walk in .
We study the  limit behavior  of such a 
walk and give an efficient algorithm for recognizing which structures
can be generated.
We also give a near-optimal algorithm for successor searching if
the event graph is a cycle and the walk is adversarial. For a random
walk, the algorithm becomes optimal. 
\end{abstract}




\section{Introduction}\label{introduction}

In contrast with the traditional adversarial assumption
of worst-case analysis,
many data sources are modeled by Markov chains
(e.g., in queuing, speech, gesture, protein homology,
web searching, etc.). These models are very appealing
because they are  widely applicable and simple
to generate.
Indeed, locality of reference, an essential pillar in the
design of efficient computing systems, is often captured by 
a Markov chain modeling the access distribution.
Hence, it does not come as a surprise that 
this connection has motivated and guided much
of the research on self-organizing data 
structures and online algorithms
in a Markov setting~\cite{Chassaing93,Hotz93,KapoorRe91,KarlinPhRa00,
KonnekerVa81,LamLeSi84,PhatarfodPrDy97,SchulzSc96,ShedlerTu72,VitterKr96}.
That body of work should be seen as part of 
a larger effort to understand
algorithms that exploit the fact that
input distributions often exhibit only a small amount
of entropy. This effort is driven not only by the
hope for improvements in practical applications 
(e.g., exploiting coherence in data streams),
but it is also motivated by theoretical questions: for example, the key 
to resolving the problem of designing an optimal
deterministic algorithm for minimum spanning trees lies in
the discovery of an optimal heap for constant-entropy 
sources~\cite{Chazelle00}.
Markov chains have been studied intensively, and there
exists a huge literature on them (e.g.,~\cite{LevinPeWi09}).
Nonetheless, the focus has been on state functions
(such as stationary distribution or commute/cover/mixing times)
rather than on the behavior of complex objects evolving over them.
This leads to a number of fundamental questions which, we hope,
will inspire further research.

Let us describe our model in more detail.
Our object of interest is a structure  that evolves
over time. The structure  is defined over a
finite subset  of a universe .
In the simplest case, we have   and 
. This corresponds to the classic
dictionary problem where we need to maintain a subset of a 
given universe. We can also imagine more complicated 
scenarios such as  with 
 being the Delaunay triangulation of .
An \emph{event graph}  specifies restrictions
on the queries and updates that are applied to .
For simplicity, we assume that  is undirected and connected.
Each node  is associated with an item 
and corresponds to one of three possible requests:
(i) \texttt{insert};
(ii) \texttt{delete}; or
(iii) \texttt{query}.
Requests are specified by following a walk in ,
beginning at a designated start node of  and hopping
from node to neighboring node. We consider both \emph{adversarial}
walks, in which the neighbors can be chosen arbitrarily, and
\emph{random} walks, in which the neighbor is chosen uniformly at random.
The latter case corresponds to the classic Markov chain model. 
Let  be the node of  visited at time  and 
let  be the set of \emph{active elements},
i.e., the set of items inserted prior to time  
and not deleted after their last insertions.
We also call  an \emph{active set}.
For any , 
if the operation at  is an insertion and
 in the case of deletion.
The query at  depends on the structure under consideration
(successor, point location, ray shooting, etc.).
Another way to interpret the event graph is as a 
finite automaton that generates words over an alphabet with 
certain cancellation rules.

Markov chains are premised on forgetting the past.
In our model, however, the structure
 can remember quite a bit. In fact, we can
define a secondary graph over the much larger
vertex set , 
where  denotes those 
elements in the universe that occur as labels in , see Fig.~\ref{fig:decorated_ex}. 
We call this larger graph the \emph{decorated graph},
, since the way to think of this
secondary graph is to picture each node  of  being
``decorated'' with the subsets . 
(We define the vertex set using 
in order to allow for every possible initial subset .)
Let 
be the number of nodes in . Since , an edge 
in the original graph gives rise to up to  edges 
 in the decorated graph, 
with  derived from  in the obvious way.
A trivial upper bound on the number of states is , which is
essentially tight.
If we could afford to store all of ,
then any of the operations at the nodes of the
event graph could be precomputed and the running time per step would be constant.
However, the required space might be huge,
so the main question is 

\begin{center}
\emph{Can the decorated graph
be compressed with no loss of performance?}
\end{center}


This seems a difficult question to answer in general. 
In fact, even counting the possible active sets in decorated graphs seems
highly nontrivial, as it reduces to counting words 
in regular languages augmented 
with certain cancellation rules. Hence, in this paper we 
focus on basic properties and special cases that highlight
the interesting behavior of the decorated graph.
Beyond the results themselves, the main contribution
of this work is to draw the attention of algorithm designers 
to a more realistic
input model that breaks away from worst-case analysis.

\paragraph{Our Results.}
The paper has two main parts. In the first part, 
we investigate some basic properties of decorated graphs.
We show that the decorated graph  has a unique strongly connected
component that corresponds to the limiting phase of a walk
on the event graph , and we give characterizations
for when a set  appears as an active set 
in this limiting phase. We also show that whether  is such an
active set can be decided in linear time (in the size of ).

In the second part, we consider the problem of maintaining a dictionary
that supports successor searches during a one-dimensional
walk on a cycle. We show how to achieve linear space and constant 
expected time for a random walk. If the walk is adversarial,
we can achieve a similar result with near-linear storage.
The former result  is in
the same spirit as previous work by the authors on randomized incremental 
construction (RIC) for Markov sources~\cite{ChazelleMu09}. 
RIC is a fundamental algorithmic paradigm
in computational geometry that uses randomness for the construction
of certain geometric objects, and we showed that there is no 
significant loss of efficiency if the  randomness comes 
from a Markov chain with sufficiently high 
conductance.

\begin{figure}
\begin{center}
\includegraphics{figs/decorated_ex}
\end{center}
\caption{An event graph over four vertices and the associated
  decorated graph. Each node of the event graph is replaced by
  four nodes decorated with the subsets of .
}
\label{fig:decorated_ex}
\end{figure}



\section{Basic Properties of Decorated Graphs}

We are given a labeled,
connected, undirected graph . In this section, we 
consider only labels of the form  and , 
where  is an element from a finite universe  and \texttt{i} 
and \texttt{d} stand for \texttt{insert} and 
\texttt{delete}. We imagine an adversary that maintains a subset 
 while walking on  and performing the corresponding operations
on the nodes. Since the focus of this section is the evolution of
 over time, we ignore queries for now.

Recall that   denotes the elements that appear on the nodes of 
.
For technical convenience, we require that for every 
 there is at least one node labeled \texttt{i} and
at least one node labeled \texttt{d}. The walk on  is
formalized through the \emph{decorated graph} . 
The graph  is a directed graph on vertex set 
. The pair  is an 
edge in  if and only if  is an edge in  
and  or 
 depending on whether  is labeled 
\texttt{i} or \texttt{d}, see Fig.~\ref{fig:decorated_ex}. 

By a \emph{walk}  in a (directed or undirected) graph, we mean any finite 
sequence of nodes such that the graph contains an edge from each node in
 to its successor in  (in particular, a node may appear multiple 
times in ).  Let  be a walk in . Recall that the 
nodes in  are tuples, consisting of a node in  and a subset 
of . By taking the first elements of the nodes 
in , we obtain a walk in , the \emph{projection} of , denoted 
by . For example, in Fig.~\ref{fig:decorated_ex}, the projection
of the walk 
 in the decorated graph is the walk
 in the event graph. 
Similarly, let  be a walk in  with start node 
, and let . Then the \emph{lifting} of  with
respect to  is the walk in   that begins at node  and 
follows the steps of  in . We denote this walk by
.
For example, in Fig.~\ref{fig:decorated_ex}, we have
. 


Since  is a directed graph, it can be decomposed into
strongly connected components that induce a directed acyclic
graph . 
We call a strongly connected component of  a \emph{sink 
component} (also called essential class in Markov chain theory), 
if it corresponds to a sink 
(i.e., a node with out-degree ) in . 
First, we observe that every node of  is represented in each sink
component of , see Fig~\ref{fig:decorated_comps}.

\begin{figure}
\begin{center}
\includegraphics{figs/decorated_comps}
\end{center}
\caption{The decomposition of the decorated graph from 
  Fig.~\ref{fig:decorated_ex} into strongly connected components.
  There is a unique sink component in which each node from the
  event graph is represented.
}
\label{fig:decorated_comps}
\end{figure}


\begin{lemma}\label{lem:all-first-nodes}
Let  be a sink component of .
For each vertex  of , there exists at least one subset 
such that  is a node  in . In other words,  is the first element
of at least one node in .
\end{lemma}

\begin{proof}
Let  be any node in . Since  is connected, 
there is a walk  in  from
 to , so  ends in a node in  whose first element is
.
\qed\end{proof}


Next, we show that to understand
the  behaviour of a walk on  in the limit, it
suffices to focus on a single sink component of . 


\begin{lemma}\label{lem:uniqueSink}
In  there exists a unique sink component  such that 
for every node  in ,  is the only
sink component that  can reach. 
\end{lemma}

\begin{proof}
Suppose there is a node  in  such that   can reach two 
different sink components  and  in . 
By Lemma~\ref{lem:all-first-nodes},
both  and  must contain at least one node with first
element . Call these nodes  (for ) and
 (for ).
Furthermore, by assumption  contains a walk  from 
 to  and a walk  from 
 to . 
Let  and . Both  and  are
closed walks in  that start and end in ,
so their concatenations  and  are
valid walks in , again with start and end vertex .
Consider the lifted walks 
 and  in
. We claim that these two walks have the same end node . 
Indeed, for each , whether  appears in  or not 
depends solely on whether the label \texttt{i} or the label \texttt{d}
appears last on the original walk in . This is the same
for both  and . Hence,   and  must both contain
, a contradiction to the assumption that they are distinct sink
components. 
Thus, each node  can reach exactly one sink component. 

Now consider two distinct nodes  and 
in  and assume that they reach the sink components  and ,
respectively. Let  be a walk in  that 
goes from   to  and let , where  is 
a walk in  that 
connects  to . Since  is undirected, the reversed walk
 is a valid walk in  from  to . 
Now consider the walks  and . 
The walk  begins in
, the  walk  begins in , and they both have the same end node. 
Furthermore, for each , the label \texttt{i} appears last
in  if and only if it appears last in .
Hence, the lifted walks  and  
have the  same end node in , so .  The lemma
follows.
\qed\end{proof}

Since the unique sink component  
from Lemma~\ref{lem:uniqueSink} represents the
limit behaviour of the set  during a walk in , we will
henceforth focus on this component.
Let us begin with a few properties of .
First, we characterize the nodes in .
\begin{lemma}\label{lem:C-characterization}
Let  be a node of  and . We have
 if and only if there exists a closed walk  in  
with the following properties:
\begin{enumerate}
  \item the walk  starts and ends in :
  \item for each , there is at least one node in  with
     label \texttt{i} or \texttt{d};
  \item we have  if and only  if the last node in  referring 
  to  is an insertion and  if and only if the last node 
	in  referring to  is a deletion.
\end{enumerate}
\end{lemma}

\noindent
We call the walk  from Lemma~\ref{lem:C-characterization}
a \emph{certifying walk} for the node  of .
For example, as we can see in Fig.~\ref{fig:decorated_comps},
the sink component of our example graph contains the node
. A certifying walk for this node is
.
\begin{proof}
First, suppose there is a walk with the given properties.
By Lemma~\ref{lem:all-first-nodes}, there is at least one  node 
in  whose first element is , say . 
The properties of  immediately imply that 
the walk  ends in , which proves the 
``if''-direction of the lemma.

Now suppose that  is a node in . Since  is strongly connected,
there exists a closed walk  in  that starts and ends at  and
visits every node of  at least once. Let . 
By Lemma~\ref{lem:all-first-nodes} and our assumption on the labels
of , the walk  contains for every element  
at least one node
with label \texttt{i} and one node with label \texttt{d}.
Therefore, the walk  meets all the desired properties.
\qed\end{proof}

This characterization of the nodes in  immediately implies
that the decorated graph can have only one sink component.

\begin{corol}
The component  is the only sink component of .
\end{corol}
\begin{proof}
Let  be a node in . By Lemmas~\ref{lem:all-first-nodes} 
and~\ref{lem:C-characterization}, there exists in  a node 
of the form  and a
corresponding certifying walk . Clearly, the walk  ends 
in . Thus, every node in  can reach , so there
can be no other sink component. 
\qed\end{proof}

Next, we give a bound on the length of certifying walks, from
which we can deduce a bound on the diameter of .
\begin{theorem}
Let  be a node of  and let  be a corresponding certifying walk 
of minimum length. Then  has length at most , where  denotes 
the number of nodes in . There are examples where any certifying walk
needs  nodes. It follows that  has diameter 
and that this is tight.
\end{theorem}

\begin{proof}
Consider the reversed walk . We subdivide  into \emph{phases}: 
a new phase starts when  encounters a node labeled 
\texttt{i} or \texttt{d} for an  that it has not seen 
before. Clearly, the number of phases is at most . 
Now consider the -th phase and let  be the set of nodes in  
whose labels refer to the  distinct elements of  that have been
encountered in the first  phases. In phase , the walk  
can use only vertices in . Since  has minimum cardinality, 
the phase must consist of a shortest walk in  from the first node of
phase  to the first node of phase .
Hence, each phase consists of at most  vertices and
the length of  is .

We now describe the lower bound construction. 
Let  be an integer.
The event graph   is a path with  vertices. The first  
vertices are labeled
, in this order. 
The middle vertex is labeled , and the remaining 
 vertices are labeled , in this
order, see Fig.~\ref{fig:large-diameter}. 
Let  be the middle vertex of  and
 be the unique sink component of .
First, note that  is a node of  for every 
. Indeed, given ,
we can construct a certifying walk for  as follows:
we begin at , and for , we walk from  to
 or , depending on whether  lies in  or 
not, and back to . This gives a certifying walk for   with 

steps. 
Now, we claim that the length of a shortest certifying walk for the node 

is . Indeed, note that the set 
 
contains exactly the odd numbers between  and . Thus, a certifying 
walk for  must visit the node  after all visits to
node , the node  after all visits to 
, etc. Furthermore, the structure of  dictates that 
any certifying walk performs these visits in order from largest 
to smallest, i.e., first comes the last visit to the node for
, then the last visit to the node for , etc. 
To see this, suppose that there exist 
such that the last visit to the node for , , comes before 
the last visit to the node for , . Then the parity of  
and  must differ, because otherwise the walk must cross  
on the way from  to . However, in this case, on the way 
from  to , the certfying walk has to cross the node with the 
wrong label for  (\texttt{insert} instead of \texttt{delete}, or vice 
versa), and hence it could not be a certifying walk. It follows 
that any certifying walk for  has length .

\begin{figure}
\begin{center}
\includegraphics[scale=0.85]{figs/decorated_diameter_path}
\end{center}
\caption{The lower bound example for . The
shortest certifying walk for  goes from  to
, then to , then to , and then back to
.}
\label{fig:large-diameter}
\end{figure}

We now show that any two nodes in  are connected by a walk of
length . 
Let  and   be two such nodes and let  be a 
shortest walk from  to  in  and
 be a certifying walk for . Then  is a walk of length
 in  from  to . Hence, the diameter of
 is . Again, the lower bound example from the previous
paragraph applies: 
the length of a shortest walk in  between  and 
 
is , as can be seen by an argument similar to the argument for
the shortest certifying walk.
\qed\end{proof}

Next, we describe an algorithm 
that is given , a node , and a set  and
then decides whether  is a node of the unique sink or not.
For , let  denote the elements that appear in
the labels of the nodes in . 
For , let  denote the nodes of  whose
labels contain an element of . 

\begin{theorem}\label{thm:decide}
Given an event graph , a node  of  and a subset
, we can decide in  steps
whether  is a node of the unique sink component 
of .
\end{theorem}

\begin{proof}
The idea of the algorithm is to construct a certifying walk 
for  through a modified breadth first search. 

In the preprocessing phase, we color a vertex  of  \emph{blue} if  is 
labeled \texttt{i} and , or if  is labeled
\texttt{d} and . Otherwise, we color  \emph{red}. 
If  is colored red, then  cannot be in , and we are done. 
Otherwise, we perform 
a directed breadth first search that starts from  and tries to
construct a reverse certifying walk.
Our algorithm maintains several queues.
The main queue is called the \emph{blue fringe} . Furthermore,
for every , we have a queue , the \emph{red fringe}
for . At the beginning, the queue  contains only , and all
the red fringes are empty.

The main loop of the algorithm takes place while  is not
empty. We pull the next node  out of , and we process
 as follows: if we have not seen the element 
for  before, we color the set  of all nodes 
whose label refers to  blue, append all the nodes of 
 to , and we delete . Next, 
we process the neighbors of  as follows: if a neighbor  of  is blue,
we append it to  if  has not been inserted into  before. If  
is red and labeled with the element , we append  to , 
if necessary, see Fig.~\ref{fig:bfs_ex}. 

\begin{figure}
\begin{center}
\includegraphics[scale=0.9]{figs/bfs_ex}
\end{center}
\caption{An intermediate stage of the algorithm while deciding whether the 
  node  lies in the unique sink of the given event graph. At 
  this point, the nodes  and  have been processed.
  Since the elements  and  have been encountered, the corresponding
  nodes have been colored blue. The nodes for the other elemenents still
  have the original color. We have , , and 
  .  Suppose that in the next step,
  the algorithm processes . Then the node 
  is colored blue and added to , and  is added to
  .
}
\label{fig:bfs_ex}
\end{figure}


The algorithm terminates after at
most  iterations. In each iteration, the cost is proportional 
to the degree of the current vertex  and (possibly) the size of 
one red fringe. The latter
cost can be charged to later rounds, since the nodes of the red fringe 
are processed later on. Let  be the union of the
remaining red fringes after the algorithm terminates.

If , 
we obtain a certifying walk for  
by walking from one newly discovered vertex to the next inside the current
blue component and reversing the walk. Now suppose . 
Let  be the set of all vertices that were traversed during the BFS. Then
 has  at least two connected
components (since there must be blue vertices outside of ). Furthermore, 
.
We claim that a certifying walk for  cannot exist. Indeed, suppose
that  is such a certifying walk. Let  be the element
in the label of the last node  in  whose label refers 
to an element in . Suppose that the label of  is of the form
\texttt{i}; the other case is symmetric. Since  is a
certifying walk, we have , so  was colored blue during the
initialization phase. Furthermore,
all the nodes on  that come after  are also blue at the end. 
This implies that 
, because by assumption a neighor of  was in , and hence
 must have been added to  when this neighbor was processed. 
Hence, we get a contradiction to the fact that 
, so
 cannot exist. Therefore, .
\qed\end{proof}

The proof of Theorem~\ref{thm:decide} gives an alternative characterization of
whether a node appears in the unique sink component or not.
\begin{corol}
The node  does not appear in  if and only if 
there exists a set  with the following properties: 
\begin{enumerate}
\item  has at least two connected components.
\item , where  denotes the
vertex set of the connected component
of  that contains .
\item For all ,  contains either only labels of the form 
\texttt{i} or only labels of the form \texttt{d} (or neither). 
If  has a node with label \texttt{i}, then .
If  has a node with label \texttt{d}, 
then .
\end{enumerate}
A set  with the above properties can be found in polynomial time.
\qed
\end{corol}

\begin{lemma}
Given   and a node , it is \textup{NP}-complete to 
decide whether there exists a certifying walk for  of length at most .
\end{lemma}

\begin{proof}
The problem is clearly in NP.
To show completeness, we reduce from  Hamiltonian path
in undirected graphs. Let  be an undirected graph with  vertices,
and suppose the vertex set is . We let  and take
two copies  and  of . We label the copy of node  in 
 with \texttt{i} and the copy of node  in  with 
\texttt{d}. Then we add two nodes  and , and we connect
  to  and 
to all nodes in  and , We label  with \texttt{i}
and  with . The resulting graph  has 
nodes and meets all our assumptions about an event graph.
Clearly,  can be constructed in polynomial time.
Finally, since by definition a certifying walk must visit for
each element  either  or , it follows that
 has a Hamiltonian path if and only if the
node  has a certifying walk of length
at most . This completes the reduction.
\qed\end{proof}

\section{Successor Searching on Cycle Graphs}\label{1D}

We now consider the case that the 
event graph  is a simple cycle  and 
the item  at node  is a real number.
Again, the structure  is  itself,
and we now have three types of nodes: 
insertion, deletion, and query.
A query at time  asks for 

(or ).
Again, an example similar to Fig.~\ref{fig:large-diameter}
shows that the decorated graph can be
of exponential size: let  be even. For , 
take ,
and define the operation at  as
 for ,
and  for .
It is easy to design a walk
that produces \emph{any} subset
of  at either  or ,
which 
implies a lower bound of  on
the size of the decorated graph.

We consider two different walks on .
The \emph{random} walk starts at  and hops from a node to 
one of its neighbors with equal probability.
The main result of this section is that for random walks,  maximal compression
is possible.


\begin{theorem}\label{markov-cycle}
Successor searching in a one-dimensional random
walk can be done in constant expected time per step
and linear storage.
\end{theorem}

First, however, we consider an \emph{adversarial} walk on .
Note that we can always achieve a running time of  per step
by maintaining a van Emde Boas search structure 
dynamically~\cite{vEmdeBoasKaZi76,vEmdeBoas77}, 
so the interesting question is how little storage
we need if we are to perform each operation in constant time.


\begin{theorem}\label{adversarial-cycle}
Successor searching along an -node cycle in the adversarial model
can be performed in constant time per operation, using
 storage, for any fixed .
\end{theorem}

Before addressing the walk on , we must consider
the following range searching problem (see also~\cite{CrochemoreIlKuRaWa12}).
Let  be a sequence of  distinct numbers, and
consider the points ,  for .
A query is given by two indices  and , together with a \emph{type}.
The type is defined as follows:  
the horizontal lines  and  divide the
plane into three unbounded open strips , , and , numbered from
top to bottom.  For , let 
.
The type is specified by the number  together with
a direction  or . The former is called 
a \emph{right} query, the latter a \emph{left} query.
Let us describe the right query: if , the 
result is .  If  contains an index larger than , 
we want the minimum index in  larger than .  If all indices in  
are less than , we want the overall minimum index in .
The left query is defined symmetrically.
See Fig.~\ref{fig:fig12}(left) for an example.

Thus, there are six types of queries, and we specify a 
query by a triplet , with  to being the type. 
We need the following result, which, as a reviewer
pointed out to us, was also discovered earlier by 
Crochemore~et~al.\cite{CrochemoreIlKuRaWa12}.
We include our proof below for completeness. 


\begin{figure}
\begin{center}
\includegraphics{figs/fig1fig2}
\end{center}
\caption{Left: the query  , we want the leftmost
  point to the right of  in the strip ;
 right: 
the successor data structure. The squares at the bottom 
represent the vertices of the cycle, split at the edge 
to obtain a better picture. The dots above the cycle nodes represent
the elements . 
The node  is the current node, and  the active set. We maintain
pointers between each element  and the closest clockwise and
counterclockwise node such that the successor in  of the corresponding
element is .}
\label{fig:fig12}
\end{figure}



\begin{lemma}\label{range-search}
Any query can be answered in constant time
with the help of a data structure of size ,
for any .
\end{lemma}


\noindent
Using Lemma~\ref{range-search}, we can prove 
Theorem~\ref{adversarial-cycle}.
\begin{proof}[of Theorem~\ref{adversarial-cycle}]
At any time , the algorithm has at its disposal:
(i) a sorted doubly-linked list of the active set  
(augmented with );
(ii) a (bidirectional) pointer to each  from
the first node  on the circle clockwise from , if
it exists, such that 
(same thing counterclockwise)---see Fig.~\ref{fig:fig12}(right).
Assume now that the data structure of Lemma~\ref{range-search} has been
set up over .
As the walk enters node  at time , 
is thus readily available and we can update  in  time.
The only remaining question is how to maintain (ii). 
Suppose that the operation at node  is a successor request
and that the walk reached  clockwise.
If  is the successor, then 
we need to find the first node  on the cycle clockwise from  
such that .
This can be handled by two range search queries :
for , use the index of the current node ; and, for , 
use the node for  in the first query and the node for 's 
predecessor in  in the second query.
An insert can be handled by two such queries (one on each side of ),
while a delete requires pointer updating, but no range search queries.
\qed\end{proof}

\begin{proof}[of Lemma~\ref{range-search}]
We define a single data structure to handle all six types
simultaneously. We restrict our discussion to the type  from
Fig.~\ref{fig:fig12}(left) but kindly invite the reader to 
check that all other five types can be handled in much the same way.
We prove by induction that with  storage, for a
large enough constant , any query can be answered in at most  
table lookups.
The case  being obvious (precompute all queries),
we assume that .
Sort and partition  into consecutive groups 
of size  each. We have two sets of tables:


\begin{itemize}
\item
\textbf{Ylinks}: for each , 
link  to the highest-indexed element  to the left of  () 
within each group , wrapping around the
strip if necessary
(left pointers in Fig.~\ref{fig:fig34}(left)).
\item
\textbf{Zlinks}: for each , 
find the group  to which  belongs and,
for each , define  as the subset of 
sandwiched  between  and the smallest (resp.~largest) 
element in  if  (resp.  ).
Note that this actually defines two sets for , so that
the total number of 's is really .
Link  to the lowest-indexed  () in each 
(right pointers in Fig.~\ref{fig:fig34}(left)), again
wrapping around if necessary.

\item
Prepare a data structure of type  recursively for each .
\end{itemize}

Given a query  of type , we first 
check whether it
fits entirely within  and, if so, solve it recursively.
Otherwise, we break it down into two subqueries: 
one of them can be handled directly by using the relevant Zlink.
The other one fits entirely within a single .
By following the corresponding Ylink, we find 
and solve the subquery recursively by converting it
into another query  of appropriate type
(Fig.~\ref{fig:fig34}(right)).
By induction, it follows that this takes  total lookups and storage 

for some constant  and for  large enough, since

\qed\end{proof}

\begin{figure}
\begin{center}
\includegraphics{figs/fig3fig4}
\end{center}
\caption{Left: the recursive data structure: The Ylinks (dashed) point
to the rightmost point to the left of  in each strip.
The ZLinks point to the leftmost point in each block defined by
 and a consecutive sequence of strips; right:
a query  is decomposed into a part handled by
a ZLink and a part that is handled recursively. }
\label{fig:fig34}
\end{figure}




Using Theorem~\ref{adversarial-cycle} together
with the special properties of a random walk on ,
we can quickly derive the algorithm for Theorem~\ref{markov-cycle}.

\begin{proof}[of Theorem~\ref{markov-cycle}]
The idea is to divide up the cycle
into  equal-size paths 
and prepare an adversarial data structure for 
each one of them right upon entry. The high
cover time of a one-dimensional random walk 
is then invoked to amortize the costs.
De-amortization techniques are then used to make the costs worst-case.
The details follow. As soon as the walk enters
a new , the data structure of Lemma~\ref{range-search}
is built from scratch for , at a cost in
time and storage of .
By merging  with the doubly-linked list
storing , we can set up all the needed successor links
and proceeds just as in Theorem~\ref{adversarial-cycle}.
This takes  time per interpath transition
and requires  storage.
There are few technical difficulties that we now
address one by one.

\begin{figure}[ht]
\begin{center}
\includegraphics{figs/fig5}
\end{center}
\caption{The parallel tracks on the cycle.}
\label{fig:fig5}
\end{figure}


\begin{itemize}
\item
Upon entry into a new path , we must set up 
successor links from  to , which takes  time.
Rather than forcing the walk to a halt, we use a ``parallel track'' idea
to de-amortize these costs. (Fig.~\ref{fig:fig5}).
Cover the cycle with paths  shifted from
 clockwise by .
and carry on the updates in parallel on both tracks.
As we shall see below, we can ensure that
updates do not take place simultaneously on both tracks.
Therefore, one of them is always
available to answer successor requests in constant time.
\item
Upon entry into a new path  (or ),
the relevant range search structure must be built from scratch.
This work does not require knowledge of 
and, in fact, the only reason
it is not done in preprocessing is to save storage.
Again, to avoid having to interrupt the walk,
while in  we ensure that the needed
structures for the two adjacent paths  are already available
and those for  are under construction.
(Same with .) 
\item
On a path, we do not want our range queries to wrap around as 
in the original structure. Thus, if a right query returns an index
smaller than , or a left query returns an index larger than ,
we change the answer to .
\item
The range search structure can only handle queries  for which
{\em both}  and  are in the ground set. Unfortunately,  may not be,
for it may correspond to an item of  inserted prior
to entry into the current .
There is an easy fix: upon entering , compute and store
 for .
Then, simply replace a query  by  where 
is the successor (or predecessor) in .
\end{itemize}

The key idea now is that a one-dimensional random walk has 
a quadratic cover time~\cite{MotwaniRa95};
therefore, the expected
time between any change of paths on one track and
the next change of paths on the other track is .
This means that if we dovetail the parallel updates by
performing a large enough number of them per walking step,
we can keep the expected time per operation constant.
This proves Theorem~\ref{markov-cycle}.
\qed\end{proof}

\section{Conclusion}

We have presented a new approach to model and analyze restricted
query sequences that is inspired by Markov chains. 
Our results only scratch the surface of a rich body of questions.
For example, even for the simple problem of the adversarial walk
on a path, we still do not know whether we can beat van Emde
Boas trees with linear space. Even though there is some 
evidence that the known lower bounds for successor searching
on a pointer machine
give the adversary a lot of leeway~\cite{Mulzer09}, our
lower bound technology
does not seem to be advanced enough for this setting.
Beyond paths and cycles, of course, there are several other
simple graph classes to be explored, e.g., trees or planar
graphs.

Furthermore, there are more fundamental questions on decorated
graphs to be studied. For example, how hard is it to count
the number of distinct active sets (or the number of nodes) 
that occur in the unique sink component of ? 
What can we say about the  behaviour of the active
set in the limit as the walk proceeds randomly? And what happens
if we go beyond the dictionary problem and consider the evolution
of more complex structures during a walk on the event graph?

\section*{Acknowledgments}
We would like to thank the anonymous referees for their thorough
reading of the paper and their many helpful suggestions that have
improved the presentation of this paper, as well
as for pointing out~\cite{CrochemoreIlKuRaWa12} to us.

W. Mulzer was supported in part by DFG grant MU3501/1.

\bibliographystyle{abbrv}
\bibliography{dec}

\end{document}
