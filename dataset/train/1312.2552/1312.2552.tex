\documentclass{tlp}
\usepackage{mycommands}
\usepackage{subfig}
\usepackage{graphicx}
\usepackage{color}
\usepackage{latexsym}
\usepackage{amssymb}
\usepackage{amsmath}
\usepackage{proof} 
\usepackage{myproof}
\usepackage{listings}
\usepackage{lineno}


\usepackage{url}
\usepackage{galois}
\usepackage{verbatim}

\usepackage{tikz}
\usetikzlibrary{arrows}

\begin{document}
\long\def\comment#1{}




\title[Abstract Interpretation of Temporal CCP]{Abstract Interpretation of Temporal Concurrent Constraint Programs \footnote{This paper has been accepted for publication in Theory and Practice of Logic Programming (TPLP), Cambridge University Press. }} 

\author[M. Falaschi, C. Olarte and C. Palamidessi]{MORENO FALASCHI\\
Dipartimento di Ingegneria dell'Informazione e Scienze Matematiche\\
 Universit\`a di Siena, Italy \\
E-mail: moreno.falaschi@unisi.it
\and 
CARLOS OLARTE \\
Departamento de Electr\'onica y Ciencias de la Computaci\'on\\
Pontificia Universidad Javeriana-Cali, Colombia\\
E-mail: carlosolarte@javerianacali.edu.co
\and
CATUSCIA PALAMIDESSI\\
INRIA and LIX\\
 Ecole Polytechnique, France\\
E-mail: catuscia@lix.polytechnique.fr
}

\submitted{19 June 2012}
\revised{15 May 2013}
\accepted{3 December 2013}



\maketitle

\begin{abstract}


Timed Concurrent Constraint Programming (\tccp) is a declarative
model for concurrency offering a logic for specifying reactive
systems, i.e. systems that  continuously interact with the
environment. The universal \tccp\ formalism (\utcc)  is an extension
of \tccp\ with the ability to express mobility. Here mobility is
understood as communication of private names as typically done for
mobile  systems and security protocols. 
In this paper we consider the denotational semantics for \tccp, and
we extend it to a ``collecting"  semantics for \utcc\ based on closure
operators over sequences of constraints. Relying on this semantics,
we formalize a general framework for data flow analyses of \tccp\ and
\utcc\ programs by abstract  interpretation techniques. The concrete
and abstract semantics we propose are  compositional, thus  allowing
us to reduce the complexity of data  flow analyses. We show that our
method is sound and parametric with respect to the abstract domain. Thus,
different analyses can be performed by instantiating the framework.
We illustrate how it is possible to reuse abstract domains previously
defined for logic programming to perform, for instance,  a groundness
analysis for \tccp\ programs. We show the applicability of this
analysis in the context of  reactive systems. Furthermore, we  make
also use of the abstract semantics to exhibit a secrecy flaw in a
security protocol. We also show how it is possible
to make an analysis which may show that
\tccp\ programs are suspension free. This can be useful for several
purposes, such as for optimizing compilation or for
debugging. 
\end{abstract}
\begin{keywords}
Timed Concurrent Constraint Programming,
Process Calculi, Abstract Interpretation, Denotational Semantics, Reactive Systems\end{keywords}






\section{Introduction}
Concurrent Constraint Programming
(\ccp)  \cite{SRP91,cp-book} has emerged as a simple but
powerful paradigm for concurrency tied to logic that  extends and subsumes both
concurrent logic programming \cite{shapiro90} and constraint logic programming
\cite{DBLP:conf/popl/JaffarL87}. The \ccp\ model combines the
traditional operational view of process calculi with a
\emph{declarative} one based upon logic. This combination allows \ccp\  to benefit
from the  large body  of reasoning techniques  of  both process calculi
and  logic.  In fact, \ccp-based calculi have successfully been used in the modeling and
verification of several concurrent scenarios such as biological, security,
timed, reactive and stochastic  systems 
\cite{SRP91,Olarte:08:SAC,NPV02,tcc-lics94,JagadeesanM05} (see a survey in \cite{DBLP:journals/constraints/OlarteRV13}). 

In the \ccp\ model,
agents interact by \emph{telling} and \emph{asking} pieces of
information (\emph{constraints}) on a shared store of partial information.
The type of constraints that  agents can tell and ask is  parametric in an underlying constraint system. This makes \ccp\ a flexible model able to adapt to different application domains.

The \ccp\ model has been extended to consider the execution of processes along  time intervals or time-units. In  \texttt{tccp} \cite{bgm99}, 
 the notion of time is identified with the time needed to ask and tell information to the  store. In this model, the information in the store is carried through the time-units. On the other hand, in Timed \ccp\ (\tccp) \cite{tcc-lics94},
 stores are not automatically transferred between time-units. This way,  computations during a time-unit proceed 
monotonically but outputs of two different time-units are 
not supposed to be related to each other.
 More precisely, computations in \tccp\ take place in bursts of activity at a rate controlled by the environment. In this model,  the environment provides a stimulus (input) in the form of  a constraint. Then the system, after a finite 
number of internal reductions,  outputs the final store (a constraint) and  waits for the next interaction 
with the environment.  This view of \emph{reactive computation} is 
akin to synchronous languages such as Esterel \cite{BeGo92}  where the system 
reacts continuously 
with the environment at a rate controlled by the environment.  
Hence, these languages allow to program safety critical applications as control systems, 
for which it is fundamental to provide tools aiming at helping  to 
develop correct, secure, and efficient programs.

Universal \tccp\  \cite{Olarte:08:SAC}  (\utcc), adds to \tccp\ the expressiveness needed for \emph{mobility}. Here we understand mobility as the ability to communicate private names (or variables) much like in the -calculus \cite{milner.parrow.ea:calculus-mobile}. Roughly, a \tccp\ \emph{ask} process  executes the process  only if the constraint   can be entailed from the store. This idea is generalized in \utcc\ by  a parametric ask that executes  when the constraint  is entailed from the store. Hence the variables in  act as formal parameters of the ask operator. This simple change allowed to widen  the spectrum of application of \ccp-based languages to scenarios such as verification of security protocols \cite{Olarte:08:SAC} and service oriented computing \cite{Lopez-Places09}.



Several domains and frameworks (e.g., \cite{CC92,armstrong98two,Codish99} )  
have been proposed  for the analysis of logic programs. The particular characteristics  of  timed \ccp\  programs  pose additional difficulties 
for the development of such tools in this language. Namely, 
 the concurrent, timed nature of the language, and the synchronization mechanisms based on  entailment of constraints (blocking asks). 
 Aiming at statically analyzing \utcc\ as well as \tccp\  programs, we have to  consider the additional technical issues due to  the infinite internal computations generated by parametric asks as we shall explain later.  
 
 
We develop here a \emph{compositional} semantics for \tccp\ and \utcc\ that 
allows us to describe the behavior of programs and collects all concrete 
information needed to properly abstract the properties of interest. This 
semantics is  based on closure operators over sequences of constraints  
along the lines of \cite{tcc-lics94}.  
We show that parametric asks in \utcc\ of the form    can 
be neatly characterized as  closure operators. This characterization is 
shown to be somehow dual to the semantics for the local operator 
 that restricts the variables in  to be local to . 
We  prove  the
 semantics  to be  fully 
 abstract w.r.t.  the operational semantics for a significant fragment of the  
 calculus.


We  also propose an abstract   semantics which approximates the  concrete one.  Our  framework is formalized by  abstract interpretation techniques and is  parametric w.r.t. 
 the abstract domain. It  allows us to exploit  the work done for developing abstract domains for 
 logic programs. Moreover, we can make new analyses for reactive 
 and mobile systems, thus widening the reasoning techniques   available for   \tccp\ and \utcc, such as 
type systems \cite{Lopez09}, logical characterizations \cite{MendlerPSS95,NPV02,Olarte:08:SAC} and semantics \cite{tcc-lics94,BoerPP95,NPV02}. 
 
 
The abstraction we propose proceeds in two-levels. First, we approximate the  
constraint system leading to an abstract constraint system. We give the sufficient 
conditions which 
have to be satisfied for ensuring the soundness of the abstraction. Next, to obtain efficient analyses, we abstract the infinite sequences of (abstract) constraints obtained from the previous step. Our semantics is then computable and compositional. Thus, it allows us to  master  the complexity of the data-flow analyses. Moreover, 
the  abstraction  \emph{over-approximates} the concrete semantics, thus preserving safety properties.

To the best of our knowledge,  this is the first attempt to propose a compositional semantics and an abstract interpretation framework  for a language adhering to the above-mentioned characteristics of  \utcc.  Hence we can develop 
analyses for several applications of \utcc\ or its sub-calculus 
\tccp\  (see e.g., \cite{DBLP:journals/constraints/OlarteRV13}). In particular, we instantiate our framework in 
three different 
scenarios.  The first one presents 
an abstraction of  a cryptographic constraint system. We  use 
the abstract semantics to bound the number of messages that a spy may generate, in order  to exhibit  a secrecy flaw in a security protocol written 
in \utcc. The second one 
tailors an abstract domain for groundness and type dependency analysis in 
logic programming to perform a groundness analysis of a  \tccp\ program. This analysis is proven useful 
to derive a property of a control system specified
in \tccp.  Finally, we present an analysis that may show that a \tccp\ program is suspension free. This  analysis can be used later for optimizing compilation or for debugging purposes. 






The ideas of this paper stem mainly from the works of the authors in \cite{BoerPP95,Falaschi:97:TCS,DBLP:journals/iandc/FalaschiGMP97,NPV02,Olarte:08:PPDP}  to give semantic characterization of \ccp\ calculi and from the works in  
\cite{FalaschiGMP93,CFM94,Falaschi:97:TCS,ZaffanellaGL97,FalaschiOPV07} to provide abstract interpretation frameworks to analyze concurrent logic-based languages. A preliminary short version of this paper without proofs was 
published in \cite{Falaschi:PPDP:09}. In this paper we give many more examples and explanations. We also refine several  technical details and present full proofs. Furthermore, we develop a new application 
for analyzing suspension-free \tccp\ programs. 

The rest of the paper is organized as follows. Section \ref{sec:cc} recalls the notion of constraint 
system and the operational semantics of \tccp\ and  \utcc. 
In Section \ref{sec:denotsem}  we  develop  the denotational semantics based on 
sequences of constraints. Next, in 
Section \ref{sec:absframework}, we study the abstract interpretation framework 
for \tccp\ and \utcc\ programs.  The three instances and 
the applications of the framework 
are presented in Section \ref{sec:app}. Section \ref{sec:concluding} concludes. 




\section{Preliminaries} \label{sec:cc}
Process calculi based on the \ccp\ paradigm are parametric in a
\emph{constraint system} specifying the basic constraints  agents can tell and ask.  These constraints  represent
a piece of (partial) information  upon  which processes may act. The
constraint system hence provides a signature from which  constraints
can be built. Furthermore, the constraint system provides an
\emph{entailment} relation () specifying inter-dependencies
between constraints. Intuitively,    means that the
information  can be deduced from the information represented by
. For example, . 

Here we consider an abstract definition of constraint systems as
cylindric algebras as in \cite{BoerPP95}. The notion of constraint system as first-order formulas  \cite{DBLP:conf/ccl/Smolka94,NPV02,Olarte:08:SAC}  can be
seen as an instance of this definition. All results of this paper
still hold, of course, when more concrete systems are considered. 

\begin{definition}[Constraint System] \label{def:cs}
A cylindric constraint system  is a structure 
  s.t. 
\\\noindent{-}
  is a lattice
with  the  operation (representing the logical
\emph{and}), and ,  the least and the greatest
elements in  respectively (representing  and
). Elements in  are called \emph{constraints}
with typical elements . If  and  we write . If  and , we write . 
\\\noindent{-} is a denumerable set of variables and for each
 the function  is a
cylindrification operator satisfying:
		    (1) . 
		(2) If  then .
		(3) .
		(4) .
		(5) For an increasing chain , .
\\\noindent{-} For each , the constraint  is a
\emph{diagonal element} and it satisfies:
			(1) .
		(2) If  is different from  then .
		(3) If  is different from  then .
\end{definition}
The cylindrification operators model a sort of existential
quantification, helpful for hiding information. 
We shall use  to denote the set of free variables that occur in . If  occurs in   and , we say that  is bound in . We use  to denote the set of bound variables in . 


 Properties (1) to (4) are standard. Property (5) is shown to be required in \cite{BoerPP95} to establish the semantic adequacy of  \ccp\ languages when infinite computations are considered. Here,   the   continuity of the semantic operator 
 in Section \ref{sec:denotsem} relies on the continuity of  (see Proposition \ref{prop:cont-td}). Below we give some examples on the requirements to satisfy this property in the context of different constraint systems. 
 


 
 The diagonal element  can be thought of as the equality . Properties (1) to (3) are standard and  they allow us to define  substitutions of the form   required, for instance, to represent the substitution of formal and actual parameters in procedure call. We shall give a formal definition of them in Notation \ref{not:terms}. 



  Let us give some examples of constraint systems.  The finite domain constraint system  (FD) \cite{HentenryckSD98} assumes variables to range over finite domains and, in addition to equality, one may have predicates  that restrict the possible values of a variable to some finite set, for instance . 

The Herbrand constraint system   consists of a first-order language with equality. 
The entailment relation is the one we expect from equality, for instance,  must entail  and . 
  may contain non-compact elements to represent the limit of infinite chains. To see this, let  be the successor constructor,   be denoted as the constraint   (i.e., ) and   be the ascending chain  . We note that  for any  and then,  . 
Property (5) in Definition \ref{def:cs} dictates that 
 must be equal to  (i.e., there exists an  which is greater than any ). For that,  we need a constraint, e.g.,   (a non-compact element), to be the limit . We know that     for any 
and then,   and  as wanted.
A similar phenomenon arises  in the definition of constraint system   as Scott information systems in \cite{SRP91}. There,  constraints are represented as finite subsets of \emph{tokens} (elementary constraints) built from a given set . The entailment  is similar to that  in Definition \ref{def:cs} but   restricted to compact elements, i.e.,  a constraint can be entailed only from a finite set of elementary constraints. Moreover,    is extended to  be a continuous  function,  thus satisfying  Property (5) in Definition \ref{def:cs}. Hence, the  Herbrand constraint system in  \cite{SRP91}  considers also a non-compact element (different from )  to be the   limit of the chain .

Now consider the Kahn constraint system underlying data-flow languages where equality is assumed along with the constant  (the empty list), the predicate  ( is not  ),  and the functions  (the first element of ),  ( without its first element) and  (the concatenation of  and ). If we consider the Kahn constraint system in \cite{SRP91},  the constraint  defined as  does not entail      since the entailment relation is defined only on compact elements. In Definition \ref{def:cs}, we are free to decide if  is different or not from . If we equate them, the constraint  is not longer a compact element and then, one has to be careful to only use a compact version of ``'' in programs (see Definition \ref{tcc:syntax}). A similar situation occurs with the  Rational Interval Constraint System \cite{SRP91} and the constraints    and  . 

All in all many different constraint systems satisfy Definition \ref{def:cs}. Nevertheless, one has to be careful since the constraint systems might not be the same as what is naively expected due to the presence of non-compact elements.

We conclude this section by setting some notation and conventions
about terms, sequences of constraints, substitutions and diagonal
elements. We first lift the relation  and the cylindrification
operator to sequences of constraints.

\begin{notation}[Sequences of Constraints]\label{not:seq-constraints}
We denote  by   (resp.  the set of infinite (resp. finite) sequences of constraints with typical elements . We
use  to range over subsets of  or . 
We use  to denote the sequence .  The length of
 is denoted by  and the  empty sequence by . The
-th element in  is denoted by . 
 We write  iff  and for all , . If   and for all
 it holds , we shall write
. Given a sequence of variables , with   we mean   and 
 with  we mean the pointwise application of the
cylindrification operator to the constraints in . 
 \end{notation}
 
We shall assume that 
the diagonal element 
is  interpreted as the equality . Furthermore, 
following \cite{DBLP:journals/jlp/GiacobazziDL95}, we extend the use of  to consider terms as in . More precisely,


\begin{convention}[Diagonal elements]\label{conv:diag}
We assume that the constraint system under consideration contains an
equality theory. Then, diagonal elements  can be 
thought of as formulas of the form .  
We shall use indistinguishably both notations.  Given a variable  and
a term  (i.e., a variable, constant or -place function of  terms symbol), we shall use  to denote the equality .
Similarly, given a sequence of distinct variables  and a sequence of terms  , if  then     
denotes the constraint .
If  then . Given a set of diagonal elements  , we shall write  whenever  for some . Otherwise, we write .
\end{convention}
 
Finally,  we set the notation for substitutions.


\begin{notation}[Admissible substitutions] \label{not:terms}
Let  be a sequence of pairwise distinct variables and  be a sequence of terms s.t. . 
We denote by   the constraint 
which represents abstractly the constraint obtained from  by
replacing the variables  by .
We say that  is admissible for , notation
, if the variables in  are different from those in . 
If  then trivially
.
Similarly, we say that the substitution  is admissible iff
. 
Given an admissible
substitution , from   Property (3) of diagonal elements in Definition \ref{def:cs},  we note that   . 
\end{notation}



\subsection{Reactive Systems and  Timed CCP}
\label{sec:tcc-definition}
Reactive systems \cite{BeGo92} are those that react continuously with
their environment at a  rate controlled by the environment. 
For example, a controller or a  signal-processing system, receives a
stimulus (input) from the environment. It computes an output  and
then, waits for the next interaction with the environment. 

In the \ccp\ model,  the shared store of constraints grows
monotonically, i.e., agents cannot drop information (constraints)
from it. Then, a system that changes the state of a  variable as in  ``" and `` leads to an inconsistent store. 

Timed \ccp\   (\tccp) \cite{tcc-lics94} extends \ccp\  for
reactive  systems. Time is conceptually divided into \emph{time
intervals }(or \emph{time-units}). In a particular time
interval, a \ccp\ process   gets an input  
from the environment, it executes with this input as the initial
\emph{store}, and when it reaches
its resting point, it \emph{outputs} the resulting store  to the
environment. The resting point determines also a residual process 
which is then executed in the next time-unit. The resulting store 
is not automatically transferred to the next time-unit.
This way, computations during a time-unit proceed monotonically but
outputs of two different time-units are not supposed to be related to
each other. Therefore, the variable  in the example
above may change its value when passing from one 
time-unit to the next one.  
\begin{definition}[\tccp\  Processes]\label{tcc:syntax} The set
 of \tccp\ processes is built from the syntax

where  is a compact element of the underlying constraint system.
Let  be a set of process declarations of the form
. A \tccp\ program takes the form .  We assume  to have a unique process definition for every process name, and recursive calls to be guarded by a  process. 
\end{definition}

The process  does nothing thus representing inaction. The
process   adds  to the store in the current time
interval making it available to the other processes. 
The process  \emph{asks} if  can be deduced from the
store. If so, it behaves as . In other case, it remains blocked
until the store contains at least as much information as .
 The parallel composition of  and   is denoted by
. Given a  set of indexes , we shall use
 to denote the parallel composition . 
The process    \emph{binds}   in
 by declaring it private to .  It behaves like , except that
all the information on  the variables 
produced by  can only be seen by   and the information on the
global variables in   produced by other processes cannot be
seen by . 


The process   is a \emph{unit-delay} that executes 
in the next time-unit.  The \emph{time-out}  is
also a unit-delay, but    is executed in the next time-unit if
and only if   is not entailed by the final store at the
current time interval. We use  as a shorthand
for
 , 
with   repeated  times.  


We extend the definition of free variables to processes as follows:   ; ; ; ; ; ; ;   where  is the set of variables occurring in . 
A variable  is bound in  if  occurs in  and . We use  to denote the set of bound variables in . 


Assume a (recursive) process definition 
 where  . The call  reduces to .
Recursive calls in  are assumed to be guarded by a 
 process to avoid non-terminating sequences of recursive
calls during a time-unit  (see \cite{tcc-lics94,NPV02}). 







In the forthcoming sections  we shall use the idiom  defined as follows:
\begin{notation}[Replication]\label{rem:bang}
The replication of , denoted as 
,  is a short hand for a call to a process definition  . 
Hence,  means    . 
\end{notation}







\subsection{Mobile behavior and \utcc}\label{sec:mobility}
As we have shown, interaction of \tccp\ processes is asynchronous as
communication takes place through the shared store of partial
information. Similar to other formalisms, by defining local (or
private) variables, \tccp\ processes specify boundaries in the
interface they offer to interact with each other. Once these
interfaces are established, there are few mechanisms to modify them.
This is not the case e.g., in the -calculus \cite{milner.parrow.ea:calculus-mobile} where
processes can change their communication patterns by exchanging their
private names.  The following example illustrates the limitation of   processes to communicate values and local variables.

\begin{example}
Let   be a constraint and let  
be 
 a system that must react when receiving a stimulus (i.e., an input) of the form
 for .   We notice that    in a store  
does not execute  since   . 
\end{example}


The key point in the previous example  is that  is a free-variable and
hence,  it  does not act as a formal parameter (or place holder) for every
term   such that  is entailed by the store. 




In  \cite{Olarte:08:SAC}, \tccp\ is extended for \emph{mobile
reactive} systems leading to  \emph{universal timed} \ccp\   (\utcc).
To model mobile behavior,  \utcc\  replaces the  ask operation
 with a   parametric ask construction,
namely .  This process can be viewed as a
-\emph{abstraction} of the process  on the variables
 under the constraint (or with the \emph{guard}) .
Intuitively, for all admissible substitution  s.t. the current store entails , the process   performs . For example,    in a store entailing both  and   executes  and . 
 
\begin{definition}[\utcc\  Processes and Programs]\label{utcc:syntax}
 The \utcc\ processes and programs result from replacing in  
Definition \ref{tcc:syntax} the expression  with 
 where the variables in  are pairwise distinct. 
\end{definition}

  When
 we  write  instead of
.  
Furthermore, the process  binds  in  and . We thus extend accordingly the sets  and  of free and bound variables.  



 From a programming point of view,  we can see the variables
 in the abstraction  as the formal
parameters of    . In fact, 
the \utcc\ calculus was introduced in  \cite{Olarte:08:SAC}  
with replication () and 
without process definitions since replication and abstractions are enough to encode recursion. 
Here we add process definitions to properly deal with  \tccp\ programs with
recursion which are more expressive than those without it (see
\cite{DBLP:conf/ppdp/NielsenPV02}) and we omit replication to avoid
redundancy in the set of operators (see Notation \ref{rem:bang}). 
We thus could have  dispensed with the next-guarded restriction in Definition \ref{tcc:syntax} for  \utcc\ programs. Nevertheless,  in order to give a unified presentation of the forthcoming results, we assume that  \utcc\ programs adhere also to that restriction.



We conclude  with an example of mobile behavior where  a process  sends a local variable to  . Then,  both
processes can communicate through the shared variable. 

\begin{example}[Scope extrusion]\label{ex:mobility}
Assume two components   and  of a system such that  creates
a local variable that must be shared with . This system can be modeled
as

We shall show later that the parallel composition of
 and  evolves to a process of the form
 where  and  share the local variable  created by .
Then, any information produced by  on  can be seen by  and
vice versa. 
\end{example}



\subsection{Operational Semantics (SOS)}\label{sec:opersem}
We take inspiration on the structural operational semantics (SOS)  for {\em linear} \ccp\ in \cite{DBLP:journals/iandc/FagesRS01,DBLP:conf/fsttcs/HaemmerleFS07} to 
define the behavior of processes.  We consider \emph{transitions}  between \emph{configurations} of the form   
where  is a constraint representing the current store,  a process and  is a set of distinct variables representing the  bound
(local) variables of  and .
  We shall use  to range over configurations.  Processes 
 are  quotiented by  defined as follows. 
\begin{definition}[Structural Congruence]\label{struct} Let 
be the smallest congruence  satisfying:  
(1)   if they differ only by a renaming of bound variables (alpha-conversion); (2)  ; (3)  ; and  (4)  .
\end{definition}
The congruence relation  is extended to configurations by decreeing that  iff 
   and . 
\begin{figure}
\resizebox{\textwidth}{!}{
\mconf{\emptyset;
P;c} \redi_{{}}^{*}  \mconf{\vx; Q;d}
\not\rediP\rede{(c,\exists \vx (d))} \localp{\vx}{F(Q)}
}
\caption{\label{opersem} 
SOS.  In ,  is given in 
Definition \ref{struct}. 
In  and ,   is defined in Notation \ref{not:terms}. In ,  is assumed to be a set of diagonal elements and  is defined in Convention \ref{conv:diag}. In ,  is defined in Notation \ref{not:nf}. 
}
\end{figure}



Transitions are given by the relations  and   in Figure \ref{opersem}.   The \emph{internal} transition 

  should be read as ``  with store  reduces, in one internal step, to   with store \ ''. We shall use  as the reflexive and transitive closure of . If  and  we write . Similarly for . 


 The \emph{observable transition} {\small } should be read as ``
on input , reduces
in one \emph{time-unit} to  and outputs ''. The observable 
transitions are obtained from finite sequences of internal ones. 

The rules in Figure \ref{opersem} 
are easily seen to realize the operational  intuitions given in Section \ref{sec:tcc-definition}. As clarified below, the seemingly missing rule  for a   process is given by .  Before  explaining such rules, let us introduce the following notation needed for  .

\begin{notation}[Normal Form]\label{not:nf}
We observe that  the store  in a configuration takes the form  where each  may be an empty set of variables. The normal form of , notation , is the constraint obtained by renaming the variables in  such that for all , if   then the variables in   do not occur neither bound nor free in . It is easy to see that . 
\end{notation}


\noindent{-}  says that the process  adds  to the current store  (via the lub operator of the constraint system) and then evolves into .
\\\noindent{-}   says that if  may evolve into , this reduction also takes place when running in parallel with  . 
\\\noindent{-} The process  
adds  to the local variables of the configuration and then evolves into .  The side conditions of the rule  guarantee that  runs with a different set of variables from those in the store and those used by other processes. 

\noindent{-} We extend the transition relation to consider processes of the form  where  is a set of diagonal elements. 
If  is empty, we write  instead of . If  entails , then    is executed (Rule ).
Moreover, the abstraction persists in the current time interval to allow other potential replacements of  in . Notice that  is augmented with  
and the side condition  prevents  executing    again.   The process  is obtained by equating   and   and then, hiding the information about  , i.e., . 



\noindent{-} Rule  allows us to \emph{open} the scope of  existentially quantified constraints in the store  (see Example \ref{ex:ex-mob-sos} below). If  reduces to  using this rule then . 
\\\noindent{-} Rule  says that one can use the structural congruence on processes to continue a derivation (e.g., to do alpha conversion). It is worth noticing that we do not allow in this rule to transform the store via the relation  on configurations and then, via  on constraints. We shall discuss the reasons  behind  this choice  in  Example \ref{ex:ex-mob-sos}. 
\\\noindent{-}What we observe from  is  where the formal 
parameters are substituted by the actual parameter (Rule ). 
\\\noindent{-} Since the process  executes  in the next time-unit only if  the final store at the current time-unit  does not entail , in the rule   evolves into  if the current store  entails . 

For the observable transition relation, rule  says that an observable transition from  labeled
with   is obtained from a terminating sequence of internal transitions from  to  . The process  to be executed in the next time interval is    (the ``future'' of ).   is obtained by removing from  the  processes that could not be executed  and  by 
``unfolding'' the sub-terms within  and  expressions. Notice that 
the output of a process hides the local variables () and those variables are also hidden in the next time-unit (). 


Now we are ready to show 
 that processes in Example \ref{ex:mobility} evolve into a configuration where a (local) variable can be communicated and shared. 



\begin{example}[Scope Extrusion and Structural Rules]\label{ex:ex-mob-sos}
Let  and  be as in Example \ref{ex:mobility}. 
In the following we show the evolution of the process   starting from the store  :\\

\resizebox{\textwidth}{!}{

}\\


where 
and .  Observe that  and  share the local variable  created by . The derivation from line 2 to line 3   uses the Rule  to \emph{open} the scope of  in the store . 
Let   (store in line 2) and . We know that . 
 As we said before,  Rule   allows us to replace structural congruent processes () but it does not  modify the store via the   relation   on constraints. The reason is that if we replace  in line 2 with  , then we will not observe the execution of . 
\end{example}

\subsection{Observables and  Behavior} \label{sec:observables}
In this section we study the input-output behavior of programs and we show that such relation is a function. More precisely, we show that the input-output relation is a (partial) upper closure operator. Then, we characterize the behavior of a process by the sequences of constraints such that the process cannot add any information to them. We shall call this behavior the strongest postcondition. This relation is fundamental to later develop the denotational semantics for \tccp\ and \utcc\ programs. 

Next lemma states some fundamental properties of the internal relation. The proof  follows from simple induction on the inference . 
\begin{lemma}[Properties of ]\label{lemma:redi-properties}
Assume that . Then, . Furthermore: 
\\\noindent 1. (Internal Extensiveness): , i.e.,  the store can only be augmented. 
\\\noindent 2. (Internal Potentiality): If  and     then , i.e.,   a stronger store triggers more internal transitions. 
\\\noindent 4. (Internal Restartability): .
\end{lemma}
\subsubsection{Input-Output Behavior}
Recall that \tccp\ and \utcc\  allows for the modeling of reactive systems where processes react according to the stimuli (input) from the environment. We  define the behavior of a process  as the relation of its outputs under the influence of a sequence of inputs (constraints) from the environment. Before  formalizing this idea, it is worth noticing that unlike \tccp, some \utcc\ 
processes may exhibit infinitely many internal reductions during a time-unit due to the  operator. 

\begin{example}[Infinite Behavior]\label{ex:inf-behav}
Consider a constant symbol ``'', a function symbol , a unary predicate (constraint)  and let . Operationally,   in a store    engages in an infinite sequence of internal transitions producing the constraints  , ,  and so on. 
\end{example}
The above behavior will arise, for instance,  in applications to security as those in Section \ref{sec:appsec}. We shall see that  the model of the attacker may generate infinitely many messages (constraints) if we do not restrict the length  of the messages (i.e., the number of nested applications of  ). 





\begin{definition}[Input-Output Behavior] \label{def:behavior}
Let ,   
(resp. , )
be finite (resp. infinite) sequences of
constraints. If   
(resp.  )
, we  write  (resp. ). We define the 
\emph{input-output} behavior of  as  where

\end{definition}

We recall that  the observable transition () is defined through a finite number of internal transitions (rule  in Figure \ref{opersem}). Hence,   it may be the case that for some \utcc\ processes (e.g.,  in Example \ref{ex:inf-behav}), .  For this reason, we distinguish finite and infinite sequences in the input-output behavior relation.  We notice that if  then any finite prefix  of  belongs to .
 We shall call \emph{well-terminated}  the  processes which do not exhibit infinite internal behavior.

 \begin{definition}[Well-termination]\label{def:wellterminated}
The process  is said to be \emph{well-terminated} w.r.t. an infinite sequence  if  there exists  s.t.   
\end{definition}

 Note that  \tccp\ processes are well-terminated since recursive calls must be  guarded. The fragment of well-terminated \utcc\ processes has been shown to be a meaningful one. For instance, in \cite{Olarte:08:PPDP} the authors show that such fragment is enough to  encode  Turing-powerful formalisms and  \cite{Lopez-Places09} shows the use of this fragment in the  declarative interpretation of languages for structured communications. 

We conclude here by showing that the \utcc\ calculus is deterministic. The result follows from Lemma \ref{lemma:redi-properties} (see  \ref{app:sos}).\begin{theorem}[Determinism] \label{theo:SOS-determinism}
Let  and  be (possibly infinite) sequences of constraints. If both
,  then . 
\end{theorem}




\subsubsection{Closure Properties and Strongest Postcondition}
The  operator is the only construct in the language that exhibits 
non-monotonic input-output behavior in the following sense: Let  and  .  If , it may be the case that . For example, take ,  and  .
The reader can verify that  ,  and then,  . 

\begin{definition}[Monotonic Processes]\label{def:monotonic}
We say that  is a monotonic process if it does not have occurrences of  processes. Similarly, the program  is monotonic if  and all  in a process definition  are monotonic. 
\end{definition}

Now we  show that   is a \emph{partial upper closure operator}, i.e., it is a function satisfying  \emph{extensiveness} and  \emph{idempotence}. Furthermore, if  is \emph{monotonic},   is a \emph{closure operator} satisfying additionally monotonicity. The proof of this result follows from   Lemma \ref{lemma:redi-properties} (see details in \ref{app:sos}). 


\begin{lemma}[Closure Properties]\label{lem:COP}
Let  be a process. Then,  is a function. Furthermore,   is a  partial  upper  closure operator,  namely it satisfies:
\\ \noindent {\bf Extensiveness}: If   then .\\
\noindent {\bf Idempotence}: If   then .

Moreover, if  is monotonic, then:

\noindent {\bf Monotonicity}: If  ,    and  , then  .

\end{lemma}

A pleasant property of closure operators is that they are uniquely determined by their set of fixpoints, here called the \emph{strongest postcondition}.
\begin{definition}[Strongest Postcondition]\label{def:sp}
Given a \utcc\ process , the strongest postcondition of ,
denoted by , is defined as the set .
\end{definition}

Intuitively,    iff  under input  cannot 
add any information whatsoever, i.e.    is a quiescent sequence for .  We can also think of    as the set of sequences that  can output under the influence of an arbitrary environment. 
Therefore, proving whether  satisfies a given  property ,  in the presence of any environment, reduces to proving whether   is a subset of the set of sequences (outputs) satisfying the property . Recall that . Therefore, the sequences in  can be finite or infinite. 

We conclude here by showing that for the    monotonic fragment,   the input-output behavior can be retrieved 
from  the strongest postcondition. The proof of this result follows  straightforward from Lemma \ref{lem:COP} 
and it can be found in \ref{app:sos}. 


\begin{theorem}\label{the:col:CO}
Let  be the minimum function w.r.t. the order induced by  and   be a monotonic process. Then, 
.
\end{theorem}






\section{A Denotational model for TCC and UTCC}\label{sec:denotsem}


As we explained before,  the strongest postcondition relation fully captures the behavior of a process  considering any possible output under an arbitrary environment. In this section we develop a denotational model for the strongest postcondition. The semantics is compositional and it is the basis for the 
abstract interpretation framework that we 
develop in Section \ref{sec:absframework}. 


Our semantics is built on the closure operator semantics for \ccp\ and \tccp\ in \cite{SRP91,tcc-lics94} and \cite{deBoer:97:TOPLAS,NPV02}.
Unlike the denotational semantics for \utcc\ in \cite{Olarte:08:PPDP}, our semantics is more appropriate for the data-flow analysis due to its simpler domain based on sequences of constraints instead of sequences of temporal formulas. In  Section \ref{sec:concluding} we elaborate  more on the differences between both semantics. 

  Roughly speaking,  the semantics is  based on a continuous immediate consequence operator , which computes in a bottom-up fashion  the \emph{interpretation} of each  process definition   in  . Such an interpretation is given in terms of the set of the quiescent sequences for  .

Assume a \utcc\ program . We shall denote  the set of process names with their  formal parameters in  as . We shall call \emph{Interpretations} the set of functions in the domain . We shall define the  semantics as a function  
which  given an interpretation , associates to each process a set of  sequences of constraints.

\begin{figure}
{

}
\caption{Semantic Equations for \tccp\ and \utcc\ constructs. Operands ``'',  \ \ ,\    and  are defined in Notation \ref{not:clos-seq}.  denotes the set complement of  in . \label{tab:densem} }
\end{figure}
Before  defining the semantics, we introduce the following notation.
 \begin{notation}[Closures and Operators on Sequences]\label{not:clos-seq}
    Given a constraint , we shall use  (the upward closure)  to denote the set , i.e., the set of constraints entailing . Similarly, we shall use  to denote the set of sequences .
Given  and , we shall extend the use of  the sequences-concatenation operator ``'' by declaring that ,  and . 
Furthermore, given a set of sequences of constraints , we define:
 
 \end{notation}
The operators above are used to define the semantic equations  in Figure \ref{tab:densem} and explained in the following. 
 Recall that  aims at capturing the strongest postcondition (or quiescent sequences) of , i.e. those  sequences  such that  under input  cannot add any information whatsoever. The process  cannot add any information to any sequence and hence, its denotation is  (Equation ).    The sequences to which  cannot add information are those whose first element entails , i.e., the upward closure of  (Equation ). If neither  nor  can add any information to , then  is quiescent for . (Equation ). 
  
  We say that   is an -variant of  if
, i.e.,  and  differ only on the information about  . Let . We note that 
 if there is an -variant  of  in . 
Therefore, a sequence  is  quiescent for  if there exists an -variant  of  s.t.  is quiescent for .  Hence, if  cannot add any information to  then   cannot add any information to  (Equation ). 


The process  has no influence on the first 
element of a sequence. Hence if  is quiescent for  then  is quiescent for  for any    (Equation ). 
Recall that the process  executes  in the next time interval if and only if the guard  cannot be deduced from the store in the current time-unit. Then, a sequence  is quiescent for   if either   is quiescent for  or  entails   (Equation ). This equation can be equivalently written as  .

Recall that the interpretation  maps process names to sequences of constraints. Then, the meaning of   is directly given by the interpretation  (Rule ). 


Let . A sequence  is quiescent for  if  does not entail . If  entails , then   must be quiescent for  (rule ). In some cases, for the sake of presentation, we may write this equations as:
   
      Before explaining the Rule , let us show some properties of . First, we note that the -variables satisfying the condition 
    in the definition of  are equivalent (see the proof in \ref{app:proofs-den}). 
   
   \begin{observation}[Equality and  -variants]\label{l-vx-eq}
Let ,  and    be -variants such that ,    and . (1)  . (2)    iff . 
\end{observation}
      
Now we  establish the correspondence between 
the sets    and   which is fundamental to  understand the way we defined the operator .

   \begin{proposition}\label{prop:forall-subs}
 if and only if   for all admissible substitution . 
\end{proposition}
\begin{proof}
()Let  and   be an -variant of  s.t.  where . By definition of~ , we know that . Since  then . Hence  and we conclude . 

\noindent() Let  be an admissible substitution. Suppose, to obtain a contradiction, that , there exists  -variant of  s.t.  and  (i.e., ). Since  then .  Therefore, there exists  -variant of  s.t.  and . By Observation \ref{l-vx-eq},   and thus,  , a contradiction. 
\end{proof}


   
A sequence  is quiescent for  the process    if for all admissible substitution , either  or   is also quiescent for , i.e.,  (rule ).    Notice that we can simply write Equation  by unfolding the definition of  as follows:



 The reader may wonder why the operator  (resp. Rule ) is not entirely  dual w.r.t.  (resp. Rule ), i.e., why we only consider -variants entailing  where  is an admissible substitution.   
 To explain this issue, let  where  and . We know that 

 for a given constant .  Suppose that we were to define:


Let 
and .  Notice that   is an  -variant   of ,   but  (since ). Then  under this naive definition of . We thus consider only the -variants  s.t. each element of  entails .    Intuitively, this condition 
requires that   in Equation  
and hence that . Furthermore   realizes the operational intuition that  runs under the substitution . 
The operational rule  makes also echo in the design of our   semantics: the operator  considers   constraints of the form  where  is a (possibly empty) set of variables, thus  allowing us to open the existentially quantified constraints as shown in the following example.

\begin{example}[Scope extrusion]
Let , .
We know that . Assume that . Then,  must be in the set:

where either,  or . 
We note that: (1)  since . Similarly,  since  but the -variant  (it does not entail ).
(3)  for the same reason. (4) Let .
We note that  since  and
there is not an admissible substitution  s.t. 
. (5) Let 
. Then,  since  and the -variant . (6) Finally, if 
, then   as in  (4) and (5). 

\end{example}



 




\subsection{Compositional Semantics}
We choose as semantic domain   where  and  iff . 
The bottom of   is then  (the set of all the sequences) and 
the top element is the singleton  (recall that    is the greatest element in ()). 
Given two interpretations  and , we write  
iff for all , . 


\begin{definition}[Concrete Semantics]\label{def:conc-semantics}
Let  be defined as in Figure \ref{tab:densem}. 
The semantics of a program  is  the least fixpoint of the continuous 
operator:

We shall use   to represent  .
\end{definition}




In the following we prove some fundamental properties of the semantic operator , namely, monotonicity and continuity. Before that, 
we shall show that   is a closure operator and it is continuous on the domain .  

\begin{lemma}[Properties of ]\label{lem:prop-for-all}
 is a closure operator, i.e., it satisfies (1) {\bf Extensivity}: ; (2) {\bf Idempotency}: ; and (3)  {\bf Monotonicity}: If  then . 
Furthermore,  (4)   is continuous on .
\end{lemma}
\begin{proof}
The proofs of (1),(2) and (3) are straightforward from the definition of   . The proof of (4) proceeds as follows. Assume a non-empty ascending chain .
Lubs in  correspond to set intersection.
We shall prove that .
The ``'' part (i.e., ) is trivial since  is monotonic. As for the  part, by extensiveness we know that  for all  and then, . Let . By definition we know that    and all -variant  of  satisfying  for  belong to   and then in . Hence,  and we conclude
.
\end{proof}





\begin{proposition}[Monotonicity of  and continuity of ]\label{prop:cont-td}
Let  be a process and 
 be an 
ascending chain. Then,   ({\bf Monotonicity}). Moreover,     ({\bf Continuity}). 
\end{proposition}
\begin{proof}
Monotonicity follows easily by induction on the structure of  and it implies the the  ``'' part of continuity. As for the part ``'' we proceed by induction on the structure of .  The interesting cases are those of the local  and the abstraction operator. For , by inductive hypothesis we know that . Since  (and therefore ) is continuous (see Property (5) in Definition \ref{def:cs}),  we conclude 
.
The result for   follows similarly from the continuity of  (Lemma \ref{lem:prop-for-all}). 
\end{proof}

\begin{figure}
\resizebox{.8\textwidth}{!}{

}
\caption{Semantics of  the processes   in Example \ref{ex:reduction}.  
 ,  and . We abuse of the notation and we 
write  instead of .
\label{fig:comp-example-den-sem}}
\end{figure}
\begin{example}[Computing the semantics]\label{ex:reduction}
Assume two constraints  and , intuitively representing  outputs of names on two different channels  and . Let  be the following procedure definitions
 
 
The procedure   outputs on channel  the variables  and  in the first and second time-units respectively. The procedure   resends on channel  every message received on channel . 
The computation of  can be found in Figure \ref{fig:comp-example-den-sem}. 
  Let . 
  Then, it must be the case that  and then,   and . Since , 
  for , if  then  for any term . Hence,  and . 
\end{example}

\subsection{Semantic Correspondence}
In this section we prove the soundness and completeness of the semantics.




\begin{lemma}[Soundness]\label{lem:soundness}
Let  be as in Definition \ref{def:conc-semantics}.
If  and ,  then .
\end{lemma}
\begin{proof}
Assume that ,  .
 We shall prove that . 
	We proceed by induction on the lexicographical order on the length of the internal derivation   and the structure of  , where the predominant component is the length of the derivation. We present the interesting cases. The others can be found in \ref{app:proofs-den}. 

	
\noindent \underline{{\bf Case}  }.   Assume a derivation for  and  of the form
	
	such that for , each  (resp. ) is an evolution of  (resp.  );
	 (resp. ) are the variables added by  (resp. ); and  (resp )
	is the information added by  (resp. ). We assume by alpha-conversion that . 
	We know that   and from  we can derive:
	
	By (structural) inductive hypothesis, we know that  ) and also   . We note that   if  (see Proposition \ref{prop:den-se-ext} in \ref{app:proofs-aux}). Hence,  from the fact that   ,  we conclude: 
	 
\noindent \underline{{\bf Case}  }.   From the rule , we can show that

where   takes the form 
,  and . Hence, there is a  derivation (shorter than that for ) for each :

with  and 
. 
Therefore, by  inductive hypothesis, 

 for all . We assume, by alpha conversion,  that the variables added for each    are distinct and then, their intersection is empty.   Furthermore, we note that . Since  , we then conclude: 

Let . 
	  For an admissible 
	  , either  or . In the first case, trivially 
	  . In the second case, 
	   . Hence,    and   . 
	   Here we conclude that for all admissible ,  and by   Proposition \ref{prop:forall-subs} we derive:
	  

\noindent \underline{{\bf Case}  }. Assume that 
.    We can verify that 

where . 
By induction   and we conclude 
. \end{proof}

The previous lemma allows us to prove the soundness of the semantics. 
\begin{theorem}[Soundness]\label{theo:sound}
If  then there exists  s.t. . 
\end{theorem}
\begin{proof}
If  is well-terminated under input , let . By repeated applications of Lemma \ref{lem:soundness}, . If  is not well-terminated, then  is finite and let 
(recall that  is quiescent for any process). Via Lemma \ref{lem:soundness} we can show .
\end{proof}

Moreover, the semantics approximates any infinite computation.
\begin{corollary}[Infinite Computations]
       Assume that  and  that  Then,  . 
\end{corollary}
\begin{proof}
 Recall that procedure calls must be next guarded. Then, any infinite behavior in  is due to a process of the form 
that executes  and adds new information of the form . By an analysis  similar to that of Lemma \ref{lem:soundness}, we can show that  entails . 
\end{proof}




\begin{example}[Infinite behavior]
Let   and 
let . Starting from the store , the process    engages in infinitely many internal transitions of the form 

At any step of the computation, the observable store is  which is equivalent to . Note also that . 
\end{example}

 For the converse of Theorem \ref{theo:sound}, we have similar technical problems as in the case of \tccp,  namely: the combination of the  operator with the  constructor.  Thus, similarly to \tccp, completeness is verified only for the  fragment of \utcc\ where there are no occurrences of  processes in the body of  processes. The reader may refer \cite{BoerPP95,NPV02} for  counterexamples showing that   when  is not locally independent. 

 \begin{definition}[Locally Independent Fragment] \label{def:LI}
Let  be a program where  contains process definitions of the form .
We say that  is 
 locally independent if for each process of the form  in  and   it holds that 
(1)   does not have occurrences of  processes; and (2) if  calls to , then  satisfies also conditions (1) and (2).
\end{definition}


\begin{lemma}[Completeness]\label{theo:comp}
Let   be a locally independent program s.t. . If  then  and 
. 
\end{lemma}
\begin{proof} 
Assume that    is locally independent,  and there is a derivation of the form  . We shall prove that  and
. 
	We proceed by induction on the lexicographical order on the length of the internal derivation  ()  and the structure of  , where the predominant component is the length of the derivation. 
 The locally independent condition is used for the case . We only present the interesting cases. The others can be found in \ref{app:proofs-den}. 


\noindent \underline{{\bf Case}  }. We know that  and  and by (structural) inductive hypothesis,  there are derivations   and  s.t.  ,  ,  and . Therefore,
assuming by alpha conversion that , 
  and by  rule , 


We note that   if  (see Proposition \ref{prop:den-se-ext} in \ref{app:proofs-aux}). Since 
and ,  we conclude .






\noindent \underline{{\bf Case}  }.   
By using the rule  we can show that:
	 
where  takes the form 
 and .
In the derivation above,   represents the constraint  added by  . Note that  .  There is a derivation (shorter than that for ) for each  of the form

Since , by Proposition \ref{prop:forall-subs} we know that   and by induction,  . Furthermore,   it must be the case that . 
Let  be the constraint .  Given that , we have . Furthermore, given that  :

Since  
for all ,   we conclude 





	  








\noindent \underline{{\bf Case}  }. By alpha conversion assume . We know that there exists  (-variant of ) s.t. ,  and  . By (structural) inductive hypothesis, there is a derivation 
 and 
 and 
. We assume by alpha conversion that . Consider now the following  derivation:

where .  We know that  and by monotonicity, we have  and then,  . We then conclude  .

Since   then . Nevertheless, notice that in the above derivation of , the final process is  and not . Since  is monotonic, there are no  processes in it. Furthermore, since , it must be the case that  may contain sub-terms (in parallel composition) of the form   resulting from  a process of the form  s.t.  and . 
 Therefore, 
by Rule , it must be also the case that  and then,  . Finally, note that  is not necessarily equal to . With a  similar analysis
 we can show that in  there are possibly more  processes running in parallel than in  and then,  .
\end{proof}

By repeated applications of the previous Lemma, we show the completeness of the denotation with respect to the strongest postcondition relation. 
\begin{theorem}[Completeness]\label{theo:completeness}
Let   be a locally independent program,   and . If  then . 
Furthermore, if   then 
. 
\end{theorem}
Notice that completeness of the semantics holds only for the locally independent fragment, while soundness is achieved for the whole language. For the abstract interpretation framework we 
develop in the next section, we require the semantics to be a sound approximation of the operational semantics and then, the restriction imposed for completeness does not affect the applicability of the framework. 







\section{Abstract Interpretation Framework}\label{sec:absframework}
In this section we develop an abstract interpretation framework \cite{CC92} 
for the analysis of \utcc\ (and \tccp) programs. 
The framework is based on the above denotational semantics, thus allowing for a 
compositional analysis. 
The abstraction  proceeds as a composition of two different abstractions:  (1) we  abstract the constraint system and then (2) we abstract the  infinite sequences of \emph{abstract} constraints. The abstraction in (1) allows us to reuse the most popular abstract domains previously defined for logic programming. Adapting those domains, it is possible to perform, e.g., groundness, freeness, type and suspension analyses of \utcc\ programs. On the other hand, the abstraction in (2) along with (1) allows for computing the approximated output of the program in a finite number of steps. 

\subsection{Abstract Constraint Systems}
Let us recall some notions from \cite{Falaschi:97:TCS} and \cite{ZaffanellaGL97}. 


\begin{definition}[Descriptions] \label{def:description}
A description  between  two constraint systems 

  consists of an abstract domain   and a surjective and monotonic abstraction function . We lift  to sequences of constraints in the obvious way. 
\end{definition}

We shall use ,  to range over constraints in  and  to range over sequences in  and  (the set of finite and infinite sequences of constraints in ). To simplify the notation, we omit the 
subindex ``'' when no confusion arises.  The entailment  is defined as in the concrete counterpart, i.e.   iff . Similarly,    iff 
 and 
. 


Following standard lines in \cite{DBLP:journals/jlp/GiacobazziDL95,Falaschi:97:TCS,ZaffanellaGL97}  we impose the following restrictions over  relating  the cylindrification, diagonal and  operators of  and . 


\begin{definition}[Correctness]\label{dec:corapp}
Let  be monotonic and surjective. We say that  is \emph{upper correct} w.r.t. the constraint system 
  if for all  and :

\noindent (1)  .

\noindent (2) . 


Since  is monotonic, we also have . 


\end{definition}



In the example below we illustrate an abstract domain for the groundness analysis of \tccp\ programs. Here we give just an intuitive description of it. We shall elaborate more on this domain and its applications in  Section \ref{sec:ground}.
 
\begin{example}[Constraint System for Groundness]\label{ex:hcs}
Let the concrete constraint system  be the  Herbrand constraint system. As abstract constraint system {\bf A}, let constraints be propositional formulas 
 representing groundness information as in   that means,  is a ground variable and,   is ground iff  is ground. In this setting,   (i.e.,  is a ground variable). Furthermore,  meaning  is ground if and only if  is ground. 


\end{example}

In the following definition we  make precise the idea  when an  abstract constraint   approximates a concrete one. 

\begin{definition}[Approximations]\label{def:approximations}
Let  be a description  satisfying the conditions in Definition \ref{def:description}.   Given , we say that  is the best approximation of . Furthermore, for all  we say that  approximates  and we write .  This definition is pointwise extended  to sequences of constraints in the obvious way (see Figure \ref{fig:abs-domains}a). 


\end{definition}

\begin{figure}
\resizebox{11cm}{!}{
\subfloat[]{\includegraphics{figure1.pdf}}
\qquad
\subfloat[]{\includegraphics{figure2.pdf}} 
}
\caption{(a).  approximates  (i.e., ) and  is the best approximation of  (Definition \ref{def:approximations}). Since   is monotonic and ,  . In (b), assume that for all  s.t. ,  is not approximated by . Then, all  constraint  approximated by  (the upper cone of ) entails . In this case,  (Definition \ref{def:absconcentails}). 
 \label{fig:abs-domains}}

\end{figure}


\subsection{Abstract Semantics}\label{sec:abssemantics}
Now we define an abstract semantics that  approximates the observable behavior of a program and is adequate for modular data-flow analysis. The semantic equations are given in Figure \ref{absdensems} and they are parametric on the abstraction function  of the description . We shall dwell a little upon the description of the  rules   and . The other cases are self-explanatory.
 


\begin{figure}
{

}
\caption{Abstract denotational semantics for \utcc.   and \ \  are  in Definition \ref{def:absconcentails}.  denotes the set complement of .\label{absdensems}}

\end{figure}

Given the right abstraction of the synchronization mechanism of blocking asks in \ccp\ is crucial to give a safe approximation of the behavior of programs. In abstract interpretation, abstract elements are \emph{weaker} than the concrete ones. Hence, if we approximate the behavior of  by replacing the guard  with  , it could be the case that  proceeds in the abstract semantics but it does not in the concrete one. More precisely,  let . Notice that  from   
we cannot, in general,  conclude . Take for instance  the constraint systems in Example \ref{ex:hcs}. We know that  but . 
Assume now we were to define the abstract semantics of  ask processes as:

A correct analysis of the process
   
 should conclude that only  is definitely ground. 
 Since , 
 if  we use   Equation \ref{ask-wrong-eq},  the analysis   ends with the result , i.e., it wrongly concludes that  and  are definitely ground. 
  
  We  thus follow 
\cite{ZaffanellaGL97,FalaschiGMP93,Falaschi:97:TCS} for the abstract semantics of the ask operator. 
For this, we need to define the entailment  that relates constraints in  and . 

\begin{definition}[ relation]\label{def:absconcentails}
Let  and . 
We say that  entails , notation , if for all  s.t.  it holds that .  We shall use  to denote the set .
\end{definition}



In words, the (abstract) constraint  
entails the (concrete) constraint  if all constraints 
approximated by  entail  (see Figure \ref{fig:abs-domains}b).  Then, in Equation , 
we guarantee that if  the abstract computation proceeds
(i.e., ) then every concrete computation 
it approximates proceeds too. 




In Equations   and  we use the operators  and  analogous to those in  Notation \ref{not:clos-seq}.  In this context, they are defined on sequences of constraints in  and they use the elements  ,   and   instead of their concrete counterparts:
 

 We omitted the superindex ``'' in these operators since it can be easily inferred from the context. 

 


 

The abstract semantics of the  operator poses similar difficulties as in the case of the ask operator. Moreover, even if we 
make use of the entailment 
  in Definition \ref{def:absconcentails}, we do not obtain a safe approximation. Let us explain this. 
One could think of defining  the semantic equation for the {\bf unless} process as follows:

The problem here is that   does not imply, in general,     . 
Take for instance  in Example \ref{ex:hcs}. We know that   and . 
Now let  ,  be a constraint s.t. 
and . 
 We know by rule  that  . If , then 
by using the Equation (\ref{eq:unless-1}), we conclude that 
. Hence, we have a sequence  such that   and  and the abstract semantics cannot be shown to be   a sound approximation of the concrete semantics (see Theorem \ref{teo:corr}). 



Notice that defining  as true iff  
for  all  approximated by     does not solve the problem. This is  because 
under this definition,    does not hold 
for any  and . To see this, notice that  
 entails all the concrete constraints 
and it is approximated by any abstract constraint.
Therefore,  we cannot give a better (safe) approximation of the semantics of   than  (Rule ).




Now we can formally define the abstract semantics as we did in Section \ref{sec:denotsem}. Given a description , we choose as  abstract domain is  where 
  and  iff . 
The bottom and top of this domain are similar to the concrete domain, i.e.,   and  respectively.



\begin{definition}\label{def:tpalpha}  Let   be  as in Figure \ref{absdensems}. The abstract semantics of a program  is defined as the 
least fixpoint of the  continuous  semantic operator:

We shall use  to denote .
\end{definition} 

The following proposition shows the monotonicity of  and 
the continuity of . The proof is analogous to that of Proposition  \ref{prop:cont-td}.

\begin{proposition}[Monotonicity of  and Continuity of ]
Let  be a process and   be an ascending chain. Then, 
 ({\bf Monotonicity}). Moreover,   ({\bf Continuity}). 
\end{proposition}



\subsection{Soundness of the Approximation}
This section proves the correctness of the abstract semantics in Definition \ref{def:tpalpha}. We first establish a Galois insertion between the concrete and the abstract domains. 


\begin{proposition}[Galois Insertion]\label{prop:gc}
Let  be a description and ,   be  the concrete and  abstract domains.  If  is  upper correct w.r.t.   then there exists an upper Galois insertion . 
\end{proposition}
\begin{proof}
Let ,  and    and  be defined as follows:

where  is the pointwise extension of  over sequences. Notice that  is a monotonic and surjective function between  and  and set intersection is the lub in both  and . We conclude by the fact that any additive and surjective function between complete lattices defines a Galois insertion \cite{CC79}. 
\end{proof}

 We  lift, as  standardly done in abstract interpretations \cite{CC92},
the approximation induced by the above abstraction. 
Let , ,  be as in Proposition \ref{prop:gc} 
and  be a process definition. Then






We conclude here by showing that concrete computations are safely  approximated by the abstract semantics. 

\begin{theorem}[Soundness of the approximation]\label{teo:corr}
Let   be a description and     be upper correct w.r.t. .   Given a  \utcc\ program , if 
 then  .  
\end{theorem}
\begin{proof} 
Let  and assume that . Then,  where  is the  of . By the continuity of ,  there exists  s.t.   (the -th application of ). 
We proceed by  induction on the lexicographical order on 
the pair  and the structure of , where the predominant component is  . We only present the interesting cases. The others can be found in \ref{app-sec-abs}. 


\noindent {\underline{\bf Case }}. 
Let  be an admissible substitution.
		We shall prove that   implies . 
		The result follows from Proposition 
		 \ref{prop:forall-subs}  and from the fact that 
		  iff  for all . The proof of the previous statement is similar to that of 
		 Proposition 
		 \ref{prop:forall-subs} and it appears in   \ref{app:proofs-aux}. 

Assume that . Then,    and we distinguish two cases:

\noindent(1) 
.
		Since  then 
		. Therefore, there exists , an -variant of , s.t.
		 and . 
		By (structural) inductive hypothesis, . Furthermore, by monotonicity of  and Property (2) in Definition \ref{dec:corapp}, we derive
		 . Hence
		. Since , 
		by Property (1) in Definition \ref{dec:corapp}, we have  (i.e.,  is an -variant of ).
		Then,  and we conclude  . 
		
\noindent(2) . Hence trivially . 

We conclude by noticing that if  then 
 and therefore .


\noindent \underline{\bf Case 	 }. 
Let   in  be a process definition. 
	If  then  (recall that ). We know that  and then, 
	  where 
	  with . By induction, and continuity of ,  we know that 
	 and then 
	.
\end{proof}









\subsection{Obtaining a finite analysis}
As standard in Abstract Interpretation, it is possible to obtain an 
analysis which terminates, by imposing several alternative conditions 
(see for instance Chapter 9 in \cite{CC92}).
So, one possibility is to impose that the abstract domain is 
noetherian (also called finite ascending chain condition). Another 
possibility is to use widening operators, or to find an abstract 
domain that guarantees termination after a finite number of steps. So, our framework allows to 
use all this classical methodologies.
In the examples that we have developed 
we shall focus our attention on a special class of abstract interpretations 
obtained 
by defining 
what we call a \emph{sequence abstraction} mapping possibly infinite sequences of (abstract) 
constraints into finite ones. Actually we can define these 
abstractions 
as Galois connections.

\begin{definition}[-sequence Abstraction]
A -sequence abstraction  is given by the
following pair of functions , with 
, 
and .
As for  the function , we set  where  has length   and  for . Similarly,   where  for  and  for .
\end{definition}

It is easy to see that, for any ,  
defines 
a Galois connection between  and .
Thus it is possible to use compositions of Galois connections for 
obtaining a new abstraction \cite{CC92}.

If  in  leads to a  Noetherian abstract domain , 
then the abstraction obtained from the composition of  and any 
 above guarantees that the fixpoint of  the abstract semantics 
can be reached in a finite number of iterations. 
Actually the domain that we obtain in this way is given by  
sequences cut at length . The number  determines the length of 
the cut and hence the precision of the approximation. The bigger  
the better the approximation.









\section{Applications}\label{sec:app}
This section is devoted to show some applications of the abstract semantics developed here. We shall describe  three specific abstract domains as instances of our framework: (1) we abstract a constraint  system  representing cryptographic primitives.  Then we use the  abstract  semantics to exhibit a secrecy flaw in a security protocol modeled in \utcc.   Next, (2) we tailor two abstract domains from logic programming to perform a  groundness 
and a type analysis of a \tccp\ program. We then apply this analysis in the verification of a reactive system in \tccp. Finally, (3) we propose an abstract constraint system for the suspension analysis of \tccp\ programs. 


\subsection{Verification of Security Protocols}\label{sec:appsec}
 The ability of \utcc\ to express mobile behavior, as in Example \ref{ex:mobility},  allows for the  modeling of  security protocols. Here we describe an abstraction of a  cryptographic constraint system  in order to bound the length of the messages to be considered in a secrecy analysis. We start by recalling the constraint system in \cite{Olarte:08:SAC} whose terms represent the  messages  generated by the protocol and cryptographic  primitives are represented as functions over such terms.

\begin{definition}[Cryptographic Constraint System]\label{def:css} Let   be a signature with constant symbols in , function symbols ,  ,   and  and predicates  and  . Constraint  in  are formulas 
built from predicates in , conjunction () and . 


\end{definition}

Intuitively,  and  represent respectively the  principal identifiers, e.g.    and  keys . We use  and   respectively,  for   (encryption) and    (composition).  For the generation of keys,  stands for the private key associated to the value  and  for its public key. 


As standardly done in the verification of security protocols, a Dolev-Yao attacker \cite{dolev-yao} is presupposed, able to  eavesdrop, disassemble, compose, encrypt and decrypt messages with available keys. The ability to eavesdrop all the messages in transit in the network is implicit in our model due to the shared store of constraints. The other abilities are  modeled by the following \utcc\ processes:


 Since the final store is not automatically transferred to the next time-unit, the process  above models the ability to remember all messages  posted so far.

It is easy to see that the process  in a store   may add messages of unbounded length. Take for example the process   that will add the constraints , ,  and so on. 

To deal with the inherent state explosion problem in the model of the attacker, 
symbolic (compact) representations of the behavior of the attacker 
have been proposed, for instance in 
\cite{boreale01symbolic,compsym-fiore,Olarte:08:SAC,BBD10}. Here we  follow the approach of restricting  the number of states to be considered in the verification of the protocol, as for instance  in \cite{DBLP:journals/corr/abs-1105-5282,SongBP01,DBLP:journals/ijisec/ArmandoC08}. Roughly, we  shall cut the messages generated   of length greater  than a given , thus allowing us to model a bounded version of the attacker. 

Before defining the abstraction, we notice that the constraint system  we are considering includes existentially quantified syntactic  equations. For this kind of equations it is necessary to refer to a solved form of them  in order to have a uniform way to compute an approximation of the constraint system. We then consider constraints of the shape  where  are pairwise distinct   and . Here,  
  refers to a term where . Given a constraint, its normal form  can be obtained by applying the algorithm proposed in \cite{Mah88b} where: quantifiers are moved to the outermost position and equations of the form 
are replaced by  ; equations such as    are deleted; equation of the form  are replaced by ; and given , if  does not occur in ,  is replaced by  in  in all equation of the form .  For instance, the solved form of  is the constraint .



\begin{definition}[Abstract secure constraint system]\label{def:abs-sec-cs}
Let  be the set of terms (messages) generated from the signature  in Definition \ref{def:css}. Let    be defined as 
 if ; . 
Let  if  . Otherwise,    
where   represents  all the messages  whose length is greater than . 
We define  as  where

and  is a solved form  of the constraint .
We  omit the superscript  in the abstract operators ,  and  to simplify the notation. 
\end{definition}

We note that the previous abstraction reminds of 
the  abstractions typically done 
in the analysis of logic programs (see e.g., \cite{ST84}). 

We shall illustrate the use of the abstract constraint system above by performing a secrecy analysis on the
Needham-Schr\"oder  (NS) protocol \cite{lowe95attack}. This protocol aims at distributing two \emph{nonces} in a secure way. 
Figure \ref{fig:ns}(a) shows the steps of NS where  and  represent  the nonces generated, respectively,  by the principals  and .
The protocol initiates when 
 sends to  a new 
nonce  together with her own agent name , both encrypted with 's public key. When  receives the message,
he decrypts it with his secret private key. Once decrypted, 
 prepares an encrypted message for  that contains 
a new nonce  together with the nonce   and his name .    then 
recovers the clear text using her private key.  convinces 
herself that this message really comes from B by checking 
whether she got back the same nonce sent out in the first 
message. If that is the case, she acknowledges B by returning his nonce. 
 does a similar test. 
\begin{figure}
\resizebox{.8\textwidth}{!}{
\subfloat[]{

}
\quad
\subfloat[]{

}
}
\caption {Steps of the Needham-Schroeder Protocol \label{fig:ns}}
\end{figure}


Assume the execution of the protocol in Figure \ref{fig:ns}(b). Here  is an intruder, i.e. a malicious agent playing the role of a principal in the protocol. As it was shown in \cite{lowe95attack}, this execution leads to a secrecy flaw where the attacker  can reveal   which is meant to be known only by  and . 
In this execution, the attacker replies to  the message sent by  and  believes that he is establishing a session key with . Since the attacker knows the private key , she can decrypt the message  and  is no longer a secret between  and  as intended. 


We model the behavior of the principals of the NS protocol with the process definitions in Figure \ref{ns:utcc:procs}. 
\begin{figure}
\resizebox{\textwidth}{!}{

}
\caption{\utcc\ model of the Needham-Schr\"oder Protocol \label{ns:utcc:procs}}
\end{figure}
Nonce generation is modeled by  constructs and the process  models the broadcast of the  message . Inputs (message reception) are modeled by 
  processes as in Example \ref{ex:ex-mob-sos}. In , we use the process  to state that the nonce   cannot be revealed. Finally, the process  corresponds to the initial knowledge of the attacker:   the names of the principals, their public keys and the 
 leaked keys in the set  (e.g., the private key of  in the configuration of Figure \ref{fig:ns} (b)).









Consider the following process:



By using the composition of   (as in Definition \ref{def:abs-sec-cs}) and the sequence abstraction -, we  obtain the abstract semantics of  as showed in  Figure \ref{fig:semantics-ns}. This allows us  to exhibit the  secrecy flaw of the NS protocol pointed out in \cite{lowe95attack}: 
Let  s.t. . Then, there exist a --variant  of  s.t.
 
This means that the nonce  appears as plain text in the network and it is no longer a secret between  and  as intended. 



\begin{figure}
\resizebox{\textwidth}{!}{

}
\caption{Abstract semantics of the process  in Equation \ref{eq:ns-proc}\label{fig:semantics-ns}}
\end{figure}













\subsection{Groundness Analysis}\label{sec:ground}
In logic programming one useful  analysis is groundness. It aims at determining if a variable will always be bound to a ground term. This information can be used, e.g., for optimization in the compiler
 or as base for other data flow analyses such as independence analysis, suspension analysis, etc. Here we present a  groundness analysis for a \tccp\ program. To this end, we shall use as concrete domain the Herbrand Constraint System and the following running example. 
   \begin{figure}
\resizebox{\textwidth}{!}{

}
\caption{Appending streams (Example \ref{ex:append}). The process definition  is similar to   but replacing the constant  with . \label{fig-ex-append}}
\end{figure}
 \begin{example}[Append]\label{ex:append}
Assume the process definitions  in Figure \ref{fig-ex-append}.  The process  adds an ``'' to the stream    when the environment provides  as input. Under input ,  terminates the stream binding its tail to the empty list. The process   can be explained similarly.  The process  
persistently equates  and . Finally,   binds  to the concatenation of  and . 
\end{example}

We shall use  \cite{armstrong98two} as abstract domain for the groundness analysis.  In , positive propositional formulas 
represent groundness dependencies among variables. 
  For instance,  meaning that  is a ground variable and    meaning that     is ground if and only if both  and  are ground. 
Elements in this domain are ordered by logical implication, e.g., 
.



\begin{observation}[Precision of Pos with respect to Synchronization]
Notice that  does not distinguish between the empty list and a list of ground terms:   and then,    (see Definition \ref{def:absconcentails}).  This affects the precision of the analysis. For instance, let  and . 
One would expect that the groundness analysis of  determines that  and  are ground variables. Nevertheless, it is easy to see that   and then, the information added by  is lost.
\end{observation}

We  improve the accuracy of the analysis by using the abstract domain defined in \cite{CodishD94} to derive information about type dependencies on terms. The abstraction is defined as follows:

Informally,  means  is a list iff  is a list and    means  is the empty list. If  is a list we write  and . Elements in the domain are ordered by logical implication. 


The following constraint systems result from the reduced product  \cite{CC92} of the previous abstract domains, thus allowing us to capture groundness and type dependency information. 

\begin{definition}[Groundness-type Constraint System] \label{def:gt-domain}
Let 
. 
Given , . 
The operations  and   
correspond to logical conjunction and existential quantification on the components of the tuple and    is defined as . 
Finally,  
iff 
 and .
\end{definition}

Consider the Example \ref{ex:append} and the 
abstraction  resulting from the composition of    above and . Note that the program  makes use of guards of the form  and . Note also that     and  . Roughly speaking, this guarantees that the chosen domain is accurate w.r.t. the ask processes in the program.   

The semantics of the process  is depicted in Figure \ref{fig:sem:append}. Assume that . Let
  and assume that for  ,   and . Since , we know that  and then, we can verify that . Similarly, take  and assume that for  ,   and . We can verify that 
 . Finally, since , we can show that .  In words, the process  binds ,  and  to  ground lists whenever the environment provides as input a series of constraints  (resp. ) followed by an input  (resp.  ). 
 
 \begin{figure}
\resizebox{.8\textwidth}{!}{
}
\caption{Abstract semantics of the process . Definitions of  and   are given in Example \ref{ex:append}. Sets 
are similar to  and omitted here. 
\label{fig:sem:append}
}
\end{figure}

\subsubsection{Reactive Systems} 
Synchronous data flow languages   \cite{BeGo92} such as Esterel and  Lustre  can be encoded as \tccp\ processes \cite{tcc-lics94,Tini99}. This  makes \tccp\ an expressive declarative framework for the modeling and verification of reactive systems. 
Take for instance the program in Figure \ref{fig:micro},
taken and slightly modified from \cite{FalaschiV06}, 
 that models a control system for a microwave checking  that the door must
be closed when it is turned on. Otherwise, it must emit an error signal. In this model, , ,  and  represent the constraints  and  and the symbols , ,  denote constant symbols. 

The analyses developed here  can provide additional reasoning techniques in \tccp\ for the verification of  such systems. For instance, by using the groundness analysis   in the previous section, we can show that if    and there exists  s.t. , then, it must be the case that  , i.e.,  is  a ground variable. This means, that the system correctly binds the list  to a ground term whenever the system reaches an inconsistent state. 



\begin{figure}[t]

\caption{Model for a microwave controller (see Notation  \ref{rem:bang} for the definition of ).  \label{fig:micro} }
\end{figure}

\begin{observation}[Synchronization constraints]
 In several  applications of \tccp\ and \utcc\  the environment interact with the system by adding as input some constraints that only appear in the guard of ask processes as    in Figure \ref{fig:micro} and 
,   in the Figure \ref{fig-ex-append}. These constraints can be thought of as ``synchronization constraints''  \cite{DBLP:journals/iandc/FagesRS01}. Furthermore, since these constraints are inputs from the environment, they are not expected to be produced by the program, i.e., they do not appear in the scope of a tell process. In these situations, in order to improve the accuracy of the analyses, one can orthogonally add  those constraints in the abstract domain. This can be done,  for instance,  with a reduced product as we did in Definition \ref{def:gt-domain} to  give a finer approximation of the inputs  and  by adding type dependency information.
\end{observation}






\subsection{Suspension Analysis}
In a concurrent setting it is important to know whether  a given system 
reaches a state where no further evolution is possible. 
Reaching a deadlocked situation is something to be avoided. There are many studies on this problem and 
several works developing analyses in (logic) concurrent languages
(e.g. \cite{CFM94,CFMW97}). However, we are not aware of studies 
available for \ccp\ and its temporal extensions. A  suspended state in the context of 
\ccp\  may happen when the guard of the ask processes  are not carefully chosen and then, none of them can be entailed. In this section we develop an analysis  that 
aims at determining the  constraints that a program needs as input from 
the environment to proceed. This can be used to derive information about 
the suspension of the system. We start by   extending  the concrete semantics to a 
collecting semantics that keeps information about the suspension of processes. 
For this, we define  the following constraint system. 

 
\begin{definition}[Suspension  Constraint System]\label{def:sync-cs}
Let   s.t. . Given a constraint system , the suspension-constraint system  is defined as 

where  are pointwise defined,  and .
Given a constraint , we shall use 
  to denote the constraint  . 
\end{definition}

Let us illustrate  how    allows us to derive information about suspension. 

\begin{example}[Collecting Semantics]\label{ex:col-sem}
Let   be a complete lattice where  and , 
 and 
.  We know that 
 (note  that   does not suspend on 
 and ). Let  and  be defined over   as:

We then have:




\end{example}








where  is a shorthand for the couple of tuples  . 
The process  suspends on input  (since ) while  under input  outputs  and it does not suspend. Notice that the system   does not block on input  or  and it does on input . Notice also  that . This means that in a store , 
 at least one the ask processes in   is able to proceed. 
The key idea is that the process  in  ensures that if  and  , then it must be the case that  . This corresponds to the intuition that if an ask process can evolve on a store , it can evolve under any store greater than  (Lemma \ref{lemma:redi-properties}). 

Next we define a program transformation that allows us to scatter suspension information when we want to verify that none of the ask processes suspend. 

\begin{example} Let  and  be as in Example  \ref{ex:col-sem}. Let also  ,  and
. Therefore, 

Hence we can conclude that only under input   
 neither  nor   suspend. 
\end{example}

The previous program transformation can be arbitrarily applied to subterms of the form . Similarly, for verification purposes, a subterm of the form 
 can be replaced by 
 









We conclude with an example showing  how an abstraction of the previous collecting semantics allows us to analyze a protocol programmed in \utcc.  For this we shall use the abstraction in Definition \ref{def:abs-sec-cs} to cut the terms up to a given length. 
\begin{example}\label{ex:sus-pro}
Assume a protocol where agent  
has to send a message to  through a proxy server . This situation can be modeled as follows:


where   is the continuation of the protocol that we left unspecified.

This code is correct if  the message can flow  from  to  without any input from the environment.   
This holds if the ask process in  does not block. We shall then analyze the program above by replacing all    with   and    with 


Let  be as in  Definition  \ref{def:abs-sec-cs}. We choose as abstract domain  and  we  consider sequences of length one. 
In  Figure \ref{fig:sus-sems} we show the abstract semantics.  We notice that  where  is in the semantics  and .  We then conclude that the protocol is able to correctly deliver the message to . 

Assume now that the code for the server is (wrongly) written as 

where we changed  to . 
We can verify that    where 
. This can warn the programmer that there is a mistake in the code. 
\end{example}
\begin{figure}

\caption{Semantics of the protocol in Example \ref{ex:sus-pro}. \label{fig:sus-sems}}
\end{figure}



\section{Concluding Remarks}\label{sec:concluding}



Several frameworks and abstract domains for the analysis of logic programs 
have been defined 
(see e.g. \cite{CC92,Codish99,armstrong98two}). Those works differ from ours since  they do not 
deal with the temporal behavior and synchronization mechanisms present in \tccp-based languages.  
On the contrary,  since our framework is  parametric w.r.t. the abstract domain, it  can benefit from 
those works.

We defined in \cite{FalaschiOPV07} a framework for the declarative debugging of \ntcc\ 
\cite{NPV02} programs (a non-deterministic extension of \tccp). 
The framework presented here is 
more general since it was designed for the static analysis of  
\tccp\ and \utcc\ programs and not 
only for debugging. Furthermore, as mentioned above, it is parametric w.r.t 
an abstract domain. 
In \cite{FalaschiOPV07} we also dealt with infinite sequences of constraints and a similar finite cut over sequences  was proposed there.  


In \cite{Olarte:08:SAC} a symbolic semantics for \utcc\ was proposed to deal with the infinite internal reductions of non well-terminated processes. This semantics, by means of temporal formulas, represents finitely  the infinitely many constraints (and substitutions) the  SOS may produce. The work in  \cite{Olarte:08:PPDP} introduces a denotational semantics for \utcc\ based on (partial) closure operators over sequences of \emph{temporal logic formulas}. This semantics captures compositionally the \emph{symbolic strongest postcondition} and it  was shown to be fully abstract w.r.t. the symbolic semantics for the fragment of locally-independent (see Definition \ref{def:LI}) and abstracted-unless free processes (i.e., processes not containing occurrences of {\bf unless} processes in the scope of abstractions). 
The semantics here presented turns out to be more appropriate to develop the abstract  interpretation framework in Section \ref{sec:absframework}. Firstly, the inclusion relation between the strongest postcondition  and the semantics  is verified for the whole language (Theorem \ref{theo:sound}) -- in \cite{Olarte:08:PPDP} this inclusion is verified 
only for the abstracted-unless free fragment--. Secondly, this semantics 
makes use of the  entailment relation over constraints rather than 
the more involved entailment  over  first-order linear-time temporal 
formulas as in \cite{Olarte:08:PPDP}. Finally, our semantics allows us to capture 
the behavior of \tccp\ programs with recursion. This is not possible with the 
semantics in \cite{Olarte:08:PPDP} which was thought only for \utcc\ programs 
where recursion can be encoded. 
This work then provides the theoretical basis for building  
tools for the data-flow analyses 
of \utcc\ and \tccp\ programs. 

For the kind of 
applications that stimulated the development of \utcc, it was defined entirely 
deterministic. The semantics 
here presented could smoothly be  extended to deal with some forms of 
non-determinism like those  in  \cite{Falaschi:97:TCS}, thus widening 
the spectrum of applications of  our framework. 








A framework for the abstract diagnosis of timed-concurrent constraint  programs
has been defined in \cite{CTV11} where the authors consider a denotational 
semantics similar to ours, although with several technical
differences. The language studied in \cite{CTV11} corresponds to \texttt{tccp} \cite{bgm99},  a  temporal \ccp\ language where the stores are monotonically accumulated along the time-units and whose operational semantics 
relies on the notion of true parallelism. We note that the framework developed in \cite{CTV11}  is used for abstract diagnosis rather than for  general analyses.

Our results should foster the development of analyzers 
for different  systems modeled in \utcc\ and its sub-calculi such as security protocols, reactive and timed systems, biological systems, etc (see \cite{DBLP:journals/constraints/OlarteRV13} for a survey of applications of \ccp-based languages).  
We plan also to perform  freeness, suspension, 
type  and  independence analyses among others. It is well known that this 
kind of analyses  have many applications, e.g. for code optimization in compilers, for improving run-time 
execution, and for approximated verification. We also plan to use abstract model checking techniques based on the proposed semantics to automatically analyze \utcc\ and \tccp\ code. 
\\

\noindent{\bf Acknowledgments.}
We thank Frank D. Valencia, Fran\c cois Fages and R\'emy Haemmerl\'e for insightful discussions on different   subjects related to this work. We also thank   the anonymous reviewers for their detailed comments.
Special thanks to Emanuele D'Osualdo for his careful remarks and suggestions for improving the paper.  This work has been partially supported by grant 1251-521-28471 from Colciencias, and by Digiteo and  DGAR funds for visitors.



\begin{thebibliography}{}

\bibitem[\protect\citeauthoryear{Armando and Compagna}{Armando and
  Compagna}{2008}]{DBLP:journals/ijisec/ArmandoC08}
{\sc Armando, A.} {\sc and} {\sc Compagna, L.} 2008.
\newblock Sat-based model-checking for security protocols analysis.
\newblock {\em Internation Journal of Information Security\/}~{\em 7,\/}~1,
  3--32.

\bibitem[\protect\citeauthoryear{Armstrong, Marriott, Schachte, and
  S{\o}ndergaard}{Armstrong et~al\mbox{.}}{1998}]{armstrong98two}
{\sc Armstrong, T.}, {\sc Marriott, K.}, {\sc Schachte, P.}, {\sc and} {\sc
  S{\o}ndergaard, H.} 1998.
\newblock Two classes of {Boolean} functions for dependency analysis.
\newblock {\em Science of Computer Programming\/}~{\em 31,\/}~1, 3--45.

\bibitem[\protect\citeauthoryear{Berry and Gonthier}{Berry and
  Gonthier}{1992}]{BeGo92}
{\sc Berry, G.} {\sc and} {\sc Gonthier, G.} 1992.
\newblock The {{\sc Esterel}} synchronous programming language: Design,
  semantics, implementation.
\newblock {\em Science of Computer Programming\/}~{\em 19,\/}~2, 87--152.

\bibitem[\protect\citeauthoryear{Bodei, Brodo, Degano, and Gao}{Bodei
  et~al\mbox{.}}{2010}]{BBD10}
{\sc Bodei, C.}, {\sc Brodo, L.}, {\sc Degano, P.}, {\sc and} {\sc Gao, H.}
  2010.
\newblock Detecting and preventing type flaws at static time.
\newblock {\em Journal of Computer Security\/}~{\em 18,\/}~2, 229--264.

\bibitem[\protect\citeauthoryear{Boreale}{Boreale}{2001}]{boreale01symbolic}
{\sc Boreale, M.} 2001.
\newblock Symbolic trace analysis of cryptographic protocols.
\newblock In {\em ICALP}, {F.~Orejas}, {P.~G. Spirakis}, {and} {J.~van
  Leeuwen}, Eds. LNCS, vol. 2076. Springer, 667--681.

\bibitem[\protect\citeauthoryear{Codish and Demoen}{Codish and
  Demoen}{1994}]{CodishD94}
{\sc Codish, M.} {\sc and} {\sc Demoen, B.} 1994.
\newblock Deriving polymorphic type dependencies for logic programs using
  multiple incarnations of prop.
\newblock In {\em SAS}, {B.~L. Charlier}, Ed. LNCS, vol. 864. Springer,
  281--296.

\bibitem[\protect\citeauthoryear{Codish, Falaschi, and Marriott}{Codish
  et~al\mbox{.}}{1994}]{CFM94}
{\sc Codish, M.}, {\sc Falaschi, M.}, {\sc and} {\sc Marriott, K.} 1994.
\newblock Suspension {A}nalyses for {C}oncurrent {L}ogic {P}rograms.
\newblock {\em ACM Transactions on Programming Languages and Systems\/}~{\em
  16,\/}~3, 649--686.

\bibitem[\protect\citeauthoryear{Codish, Falaschi, Marriott, and
  Winsborough}{Codish et~al\mbox{.}}{1997}]{CFMW97}
{\sc Codish, M.}, {\sc Falaschi, M.}, {\sc Marriott, K.}, {\sc and} {\sc
  Winsborough, W.} 1997.
\newblock A {C}onfluent {S}emantic {B}asis for the {A}nalysis of {C}oncurrent
  {C}onstraint {L}ogic {P}rograms.
\newblock {\em Journal of Logic Programming\/}~{\em 30,\/}~1, 53--81.

\bibitem[\protect\citeauthoryear{Codish, S{\o}ndergaard, and Stuckey}{Codish
  et~al\mbox{.}}{1999}]{Codish99}
{\sc Codish, M.}, {\sc S{\o}ndergaard, H.}, {\sc and} {\sc Stuckey, P.} 1999.
\newblock Sharing and groundness dependencies in logic programs.
\newblock {\em ACM Transations on Programming Languages and Systems\/}~{\em
  21,\/}~5, 948--976.

\bibitem[\protect\citeauthoryear{Comini, Titolo, and Villanueva}{Comini
  et~al\mbox{.}}{2011}]{CTV11}
{\sc Comini, M.}, {\sc Titolo, L.}, {\sc and} {\sc Villanueva, A.} 2011.
\newblock Abstract diagnosis for timed concurrent constraint programs.
\newblock {\em TPLP\/}~{\em 11,\/}~4-5, 487--502.

\bibitem[\protect\citeauthoryear{Cousot and Cousot}{Cousot and
  Cousot}{1979}]{CC79}
{\sc Cousot, P.} {\sc and} {\sc Cousot, R.} 1979.
\newblock Systematic design of program analysis frameworks.
\newblock In {\em POPL}, {A.~V. Aho}, {S.~N. Zilles}, {and} {B.~K. Rosen}, Eds.
  ACM Press, 269--282.

\bibitem[\protect\citeauthoryear{Cousot and Cousot}{Cousot and
  Cousot}{1992}]{CC92}
{\sc Cousot, P.} {\sc and} {\sc Cousot, R.} 1992.
\newblock Abstract {I}nterpretation and {A}pplications to {L}ogic {P}rograms.
\newblock {\em Journal of Logic Programming\/}~{\em 13,\/}~2\&3, 103--179.

\bibitem[\protect\citeauthoryear{de~Boer, Gabbrielli, Marchiori, and
  Palamidessi}{de~Boer et~al\mbox{.}}{1997}]{deBoer:97:TOPLAS}
{\sc de~Boer, F.~S.}, {\sc Gabbrielli, M.}, {\sc Marchiori, E.}, {\sc and} {\sc
  Palamidessi, C.} 1997.
\newblock Proving concurrent constraint programs correct.
\newblock {\em ACM Transactions on Programming Languages and Systems\/}~{\em
  19,\/}~5, 685--725.

\bibitem[\protect\citeauthoryear{de~Boer, Gabbrielli, and Meo}{de~Boer
  et~al\mbox{.}}{2000}]{bgm99}
{\sc de~Boer, F.~S.}, {\sc Gabbrielli, M.}, {\sc and} {\sc Meo, M.~C.} 2000.
\newblock A timed concurrent constraint language.
\newblock {\em Inf. Comput.\/}~{\em 161,\/}~1, 45--83.

\bibitem[\protect\citeauthoryear{de~Boer, Pierro, and Palamidessi}{de~Boer
  et~al\mbox{.}}{1995}]{BoerPP95}
{\sc de~Boer, F.~S.}, {\sc Pierro, A.~D.}, {\sc and} {\sc Palamidessi, C.}
  1995.
\newblock Nondeterminism and infinite computations in constraint programming.
\newblock {\em Theoretical Computer Science\/}~{\em 151,\/}~1, 37--78.

\bibitem[\protect\citeauthoryear{Dolev and Yao}{Dolev and
  Yao}{1983}]{dolev-yao}
{\sc Dolev, D.} {\sc and} {\sc Yao, A.~C.} 1983.
\newblock On the security of public key protocols.
\newblock {\em IEEE Transactions on Information Theory\/}~{\em 29,\/}~12,
  198--208.

\bibitem[\protect\citeauthoryear{Escobar, Meadows, and Meseguer}{Escobar
  et~al\mbox{.}}{2011}]{DBLP:journals/corr/abs-1105-5282}
{\sc Escobar, S.}, {\sc Meadows, C.}, {\sc and} {\sc Meseguer, J.} 2011.
\newblock State space reduction in the maude-nrl protocol analyzer.
\newblock {\em CoRR\/}~{\em abs/1105.5282}.

\bibitem[\protect\citeauthoryear{Fages, Ruet, and Soliman}{Fages
  et~al\mbox{.}}{2001}]{DBLP:journals/iandc/FagesRS01}
{\sc Fages, F.}, {\sc Ruet, P.}, {\sc and} {\sc Soliman, S.} 2001.
\newblock Linear concurrent constraint programming: Operational and phase
  semantics.
\newblock {\em Inf. Comput.\/}~{\em 165,\/}~1, 14--41.

\bibitem[\protect\citeauthoryear{Falaschi, Gabbrielli, Marriott, and
  Palamidessi}{Falaschi et~al\mbox{.}}{1993}]{FalaschiGMP93}
{\sc Falaschi, M.}, {\sc Gabbrielli, M.}, {\sc Marriott, K.}, {\sc and} {\sc
  Palamidessi, C.} 1993.
\newblock Compositional analysis for concurrent constraint programming.
\newblock In {\em LICS}. IEEE Computer Society, 210--221.

\bibitem[\protect\citeauthoryear{Falaschi, Gabbrielli, Marriott, and
  Palamidessi}{Falaschi et~al\mbox{.}}{1997a}]{Falaschi:97:TCS}
{\sc Falaschi, M.}, {\sc Gabbrielli, M.}, {\sc Marriott, K.}, {\sc and} {\sc
  Palamidessi, C.} 1997a.
\newblock Confluence in concurrent constraint programming.
\newblock {\em Theoretical Computer Science\/}~{\em 183,\/}~2, 281--315.

\bibitem[\protect\citeauthoryear{Falaschi, Gabbrielli, Marriott, and
  Palamidessi}{Falaschi
  et~al\mbox{.}}{1997b}]{DBLP:journals/iandc/FalaschiGMP97}
{\sc Falaschi, M.}, {\sc Gabbrielli, M.}, {\sc Marriott, K.}, {\sc and} {\sc
  Palamidessi, C.} 1997b.
\newblock Constraint logic programming with dynamic scheduling: A semantics
  based on closure operators.
\newblock {\em Inf. Comput.\/}~{\em 137,\/}~1, 41--67.

\bibitem[\protect\citeauthoryear{Falaschi, Olarte, and Palamidessi}{Falaschi
  et~al\mbox{.}}{2009}]{Falaschi:PPDP:09}
{\sc Falaschi, M.}, {\sc Olarte, C.}, {\sc and} {\sc Palamidessi, C.} 2009.
\newblock A framework for abstract interpretation of timed concurrent
  constraint programs.
\newblock In {\em PPDP}, {A.~Porto} {and} {F.~J. L{\'o}pez-Fraguas}, Eds. ACM,
  207--218.

\bibitem[\protect\citeauthoryear{Falaschi, Olarte, Palamidessi, and
  Valencia}{Falaschi et~al\mbox{.}}{2007}]{FalaschiOPV07}
{\sc Falaschi, M.}, {\sc Olarte, C.}, {\sc Palamidessi, C.}, {\sc and} {\sc
  Valencia, F.} 2007.
\newblock Declarative diagnosis of temporal concurrent constraint programs.
\newblock In {\em ICLP}, {V.~Dahl} {and} {I.~Niemel{\"a}}, Eds. LNCS, vol.
  4670. Springer, 271--285.

\bibitem[\protect\citeauthoryear{Falaschi and Villanueva}{Falaschi and
  Villanueva}{2006}]{FalaschiV06}
{\sc Falaschi, M.} {\sc and} {\sc Villanueva, A.} 2006.
\newblock Automatic verification of timed concurrent constraint programs.
\newblock {\em TPLP\/}~{\em 6,\/}~3, 265--300.

\bibitem[\protect\citeauthoryear{Fiore and Abadi}{Fiore and
  Abadi}{2001}]{compsym-fiore}
{\sc Fiore, M.~P.} {\sc and} {\sc Abadi, M.} 2001.
\newblock Computing symbolic models for verifying cryptographic protocols.
\newblock In {\em CSFW}. IEEE Computer Society, 160--173.

\bibitem[\protect\citeauthoryear{Giacobazzi, Debray, and Levi}{Giacobazzi
  et~al\mbox{.}}{1995}]{DBLP:journals/jlp/GiacobazziDL95}
{\sc Giacobazzi, R.}, {\sc Debray, S.~K.}, {\sc and} {\sc Levi, G.} 1995.
\newblock Generalized semantics and abstract interpretation for constraint
  logic programs.
\newblock {\em J. Log. Program.\/}~{\em 25,\/}~3, 191--247.

\bibitem[\protect\citeauthoryear{Haemmerl{\'e}, Fages, and
  Soliman}{Haemmerl{\'e} et~al\mbox{.}}{2007}]{DBLP:conf/fsttcs/HaemmerleFS07}
{\sc Haemmerl{\'e}, R.}, {\sc Fages, F.}, {\sc and} {\sc Soliman, S.} 2007.
\newblock Closures and modules within linear logic concurrent constraint
  programming.
\newblock In {\em FSTTCS}, {V.~Arvind} {and} {S.~Prasad}, Eds. LNCS, vol. 4855.
  Springer, 544--556.

\bibitem[\protect\citeauthoryear{Hentenryck, Saraswat, and Deville}{Hentenryck
  et~al\mbox{.}}{1998}]{HentenryckSD98}
{\sc Hentenryck, P.~V.}, {\sc Saraswat, V.~A.}, {\sc and} {\sc Deville, Y.}
  1998.
\newblock Design, implementation, and evaluation of the constraint language
  cc(fd).
\newblock {\em Journal of Logic Programming\/}~{\em 37,\/}~1-3, 139--164.

\bibitem[\protect\citeauthoryear{Hildebrandt and L{\'o}pez}{Hildebrandt and
  L{\'o}pez}{2009}]{Lopez09}
{\sc Hildebrandt, T.} {\sc and} {\sc L{\'o}pez, H.~A.} 2009.
\newblock Types for secure pattern matching with local knowledge in universal
  concurrent constraint programming.
\newblock In {\em ICLP}, {P.~M. Hill} {and} {D.~S. Warren}, Eds. LNCS, vol.
  5649. Springer, 417--431.

\bibitem[\protect\citeauthoryear{Jaffar and Lassez}{Jaffar and
  Lassez}{1987}]{DBLP:conf/popl/JaffarL87}
{\sc Jaffar, J.} {\sc and} {\sc Lassez, J.-L.} 1987.
\newblock Constraint logic programming.
\newblock In {\em POPL}. ACM Press, 111--119.

\bibitem[\protect\citeauthoryear{Jagadeesan, Marrero, Pitcher, and
  Saraswat}{Jagadeesan et~al\mbox{.}}{2005}]{JagadeesanM05}
{\sc Jagadeesan, R.}, {\sc Marrero, W.}, {\sc Pitcher, C.}, {\sc and} {\sc
  Saraswat, V.~A.} 2005.
\newblock Timed constraint programming: a declarative approach to usage
  control.
\newblock In {\em PPDP}, {P.~Barahona} {and} {A.~P. Felty}, Eds. ACM, 164--175.

\bibitem[\protect\citeauthoryear{L{\'o}pez, Olarte, and P{\'e}rez}{L{\'o}pez
  et~al\mbox{.}}{2009}]{Lopez-Places09}
{\sc L{\'o}pez, H.~A.}, {\sc Olarte, C.}, {\sc and} {\sc P{\'e}rez, J.~A.}
  2009.
\newblock Towards a unified framework for declarative structured
  communications.
\newblock In {\em PLACES}, {A.~R. Beresford} {and} {S.~J. Gay}, Eds. EPTCS,
  vol.~17. 1--15.

\bibitem[\protect\citeauthoryear{Lowe}{Lowe}{1996}]{lowe95attack}
{\sc Lowe, G.} 1996.
\newblock Breaking and fixing the needham-schroeder public-key protocol using
  fdr.
\newblock {\em Software - Concepts and Tools\/}~{\em 17,\/}~3, 93--102.

\bibitem[\protect\citeauthoryear{Maher}{Maher}{1988}]{Mah88b}
{\sc Maher, M.~J.} 1988.
\newblock Complete axiomatizations of the algebras of finite, rational and
  infinite trees.
\newblock In {\em LICS}. IEEE Computer Society, 348--357.

\bibitem[\protect\citeauthoryear{Mendler, Panangaden, Scott, and Seely}{Mendler
  et~al\mbox{.}}{1995}]{MendlerPSS95}
{\sc Mendler, N.~P.}, {\sc Panangaden, P.}, {\sc Scott, P.~J.}, {\sc and} {\sc
  Seely, R. A.~G.} 1995.
\newblock A logical view of concurrent constraint programming.
\newblock {\em Nordic Journal of Computing\/}~{\em 2,\/}~2, 181--220.

\bibitem[\protect\citeauthoryear{Milner, Parrow, and Walker}{Milner
  et~al\mbox{.}}{1992}]{milner.parrow.ea:calculus-mobile}
{\sc Milner, R.}, {\sc Parrow, J.}, {\sc and} {\sc Walker, D.} 1992.
\newblock A calculus of mobile processes, {P}arts {I} and {II}.
\newblock {\em Inf. Comput.\/}~{\em 100,\/}~1, 1--40.

\bibitem[\protect\citeauthoryear{Nielsen, Palamidessi, and Valencia}{Nielsen
  et~al\mbox{.}}{2002a}]{NPV02}
{\sc Nielsen, M.}, {\sc Palamidessi, C.}, {\sc and} {\sc Valencia, F.} 2002a.
\newblock Temporal concurrent constraint programming: Denotation, logic and
  applications.
\newblock {\em Nordic J. of Computing\/}~{\em 9,\/}~1, 145--188.

\bibitem[\protect\citeauthoryear{Nielsen, Palamidessi, and Valencia}{Nielsen
  et~al\mbox{.}}{2002b}]{DBLP:conf/ppdp/NielsenPV02}
{\sc Nielsen, M.}, {\sc Palamidessi, C.}, {\sc and} {\sc Valencia, F.~D.}
  2002b.
\newblock On the expressive power of temporal concurrent constraint programming
  languages.
\newblock In {\em PPDP}. ACM, 156--167.

\bibitem[\protect\citeauthoryear{Olarte, Rueda, and Valencia}{Olarte
  et~al\mbox{.}}{2013}]{DBLP:journals/constraints/OlarteRV13}
{\sc Olarte, C.}, {\sc Rueda, C.}, {\sc and} {\sc Valencia, F.~D.} 2013.
\newblock Models and emerging trends of concurrent constraint programming.
\newblock {\em Constraints\/}~{\em 18,\/}~4, 535--578.

\bibitem[\protect\citeauthoryear{Olarte and Valencia}{Olarte and
  Valencia}{2008a}]{Olarte:08:PPDP}
{\sc Olarte, C.} {\sc and} {\sc Valencia, F.~D.} 2008a.
\newblock The expressivity of universal timed {C}{C}{P}: undecidability of
  monadic {F}{L}{T}{L} and closure operators for security.
\newblock In {\em PPDP}, {S.~Antoy} {and} {E.~Albert}, Eds. ACM, 8--19.

\bibitem[\protect\citeauthoryear{Olarte and Valencia}{Olarte and
  Valencia}{2008b}]{Olarte:08:SAC}
{\sc Olarte, C.} {\sc and} {\sc Valencia, F.~D.} 2008b.
\newblock Universal concurrent constraint programing: symbolic semantics and
  applications to security.
\newblock In {\em SAC}, {R.~L. Wainwright} {and} {H.~Haddad}, Eds. ACM,
  145--150.

\bibitem[\protect\citeauthoryear{Saraswat}{Saraswat}{1993}]{cp-book}
{\sc Saraswat, V.~A.} 1993.
\newblock {\em Concurrent Constraint Programming}.
\newblock MIT Press.

\bibitem[\protect\citeauthoryear{Saraswat, Jagadeesan, and Gupta}{Saraswat
  et~al\mbox{.}}{1994}]{tcc-lics94}
{\sc Saraswat, V.~A.}, {\sc Jagadeesan, R.}, {\sc and} {\sc Gupta, V.} 1994.
\newblock Foundations of timed concurrent constraint programming.
\newblock In {\em LICS}. IEEE Computer Society, 71--80.

\bibitem[\protect\citeauthoryear{Saraswat, Rinard, and Panangaden}{Saraswat
  et~al\mbox{.}}{1991}]{SRP91}
{\sc Saraswat, V.~A.}, {\sc Rinard, M.~C.}, {\sc and} {\sc Panangaden, P.}
  1991.
\newblock Semantic foundations of concurrent constraint programming.
\newblock In {\em POPL}, {D.~S. Wise}, Ed. ACM Press, 333--352.

\bibitem[\protect\citeauthoryear{Sato and Tamaki}{Sato and Tamaki}{1984}]{ST84}
{\sc Sato, T.} {\sc and} {\sc Tamaki, H.} 1984.
\newblock Enumeration of {S}uccess {P}atterns in {L}ogic {P}rograms.
\newblock {\em Theoretical Computer Science\/}~{\em 34}, 227--240.

\bibitem[\protect\citeauthoryear{Shapiro}{Shapiro}{1989}]{shapiro90}
{\sc Shapiro, E.~Y.} 1989.
\newblock The family of concurrent logic programming languages.
\newblock {\em ACM Comput. Surv.\/}~{\em 21,\/}~3, 413--510.

\bibitem[\protect\citeauthoryear{Smolka}{Smolka}{1994}]{DBLP:conf/ccl/Smolka94}
{\sc Smolka, G.} 1994.
\newblock A foundation for higher-order concurrent constraint programming.
\newblock In {\em CCL}, {J.-P. Jouannaud}, Ed. LNCS, vol. 845. Springer,
  50--72.

\bibitem[\protect\citeauthoryear{Song, Berezin, and Perrig}{Song
  et~al\mbox{.}}{2001}]{SongBP01}
{\sc Song, D.~X.}, {\sc Berezin, S.}, {\sc and} {\sc Perrig, A.} 2001.
\newblock Athena: A novel approach to efficient automatic security protocol
  analysis.
\newblock {\em Journal of Computer Security\/}~{\em 9,\/}~1/2, 47--74.

\bibitem[\protect\citeauthoryear{Tini}{Tini}{1999}]{Tini99}
{\sc Tini, S.} 1999.
\newblock On the expressiveness of timed concurrent constraint programming.
\newblock {\em Electr. Notes Theor. Comput. Sci.\/}~{\em 27}, 3--17.

\bibitem[\protect\citeauthoryear{Zaffanella, Giacobazzi, and Levi}{Zaffanella
  et~al\mbox{.}}{1997}]{ZaffanellaGL97}
{\sc Zaffanella, E.}, {\sc Giacobazzi, R.}, {\sc and} {\sc Levi, G.} 1997.
\newblock Abstracting synchronization in concurrent constraint programming.
\newblock {\em Journal of Functional and Logic Programming\/}~{\em 1997,\/}~6.

\end{thebibliography}






\newpage
\appendix


\section{Detailed proofs Section \ref{sec:observables}} \label{app:sos}
Before presenting the proof that  is deterministic, we shall prove the following auxiliary result. 
\begin{lemma}[Confluence]\label{lemma:confluence}
Suppose that ,
 and .  Then, there exists 
 such that  and . 
\end{lemma}
\begin{proof} 
Let . The proof proceed by structural induction on .  In each case where  has two different transitions  (up to )   and , one shows the existence of  s.t.  and . 

 Given a configuration 
 let us define the size of  as the size of    as follows:
, ,  and .
 Suppose  that , ,  and . 
 The proof proceeds by induction on the size of . 
 From the assumption , it must be the case that the transition  is not an instance of the rule ; moreover, 
    is neither  a process of the form , , 
 or   (since those processes have a unique possible transition modulo structural congruence) nor  or  (since they do not exhibit any internal derivation). 

 For the case , we have to consider three cases.
 Assume that  
 and .
 Let , 
 and
. 
We know by induction that if  and 
  then there exists
 
 such that  and .
We conclude by noticing that   and  where . The  remaining cases when  (1)  has two possible transitions and (2) when  moves to  and then  moves to  are similar. 


Let   with . One can verify that    where  takes the form  and    where  takes the form .  From the assumption , it must be the case that  . By alpha conversion we assume that . 
Let   where .  Clearly    and  as wanted. 
\end{proof}

\begin{observation}[Finite Traces]\label{obs:finite-traces}
Let   by a finite internal derivation. The 
number of possible internal transitions (up to ) in any  in the above derivation is finite.
\end{observation}
\begin{proof}
We proceed  by structural induction on . The interesting case is the {\bf abs} process. Let . 
Suppose, to obtain a contradiction, that    for infinitely many  (to have infinitely many possible internal transitions). In that case, it is easy to see that  we must have infinitely many internal derivation, thus contradicting the assumption that   . 
\end{proof}

\begin{lemma}[Finite Traces]
If there is a finite internal derivation of the form  
then, any derivation starting from  is finite. 
\end{lemma}
\begin{proof}
We observe that
recursive calls must be guarded by a {\bf next} processes. Then, any infinite behavior inside a time-unit is due to an {\bf abs} process. 
From  Observation \ref{obs:finite-traces} and Lemma \ref{lemma:confluence}, it follows that any derivation starting from  is finite. 
\end{proof}

\appResult{Theorem \ref{theo:SOS-determinism}}{Determinism}{
Let  and  be (possibly infinite) sequences of constraints. If both
,  then . 
}
\begin{proof}
Assume that , 
and let , . If  then trivially ,  and . 
Now assume that  and  where  and .  By   repeated applications of Lemma \ref{lemma:confluence}  we conclude  and then,  and . \end{proof}


\appResult{Lemma \ref{lem:COP}}{Closure Properties}{
Let  be a process. Then,
\begin{enumerate}
\item[(1)]  is a function.
\item[(2)]   is a  partial closure operator,  namely it satisfies:
\\ \noindent {\bf Extensiveness}: If   then .\\
\noindent {\bf Idempotence}: If   then .\\
\noindent {\bf Monotonicity}: Let  be a  monotonic process such that  . If  and  , then  .
\end{enumerate}
}
\begin{proof}
We shall assume here that the input and output sequences are infinite. The proof for the case when the sequences are finite is analogous. 
The proof of (1) is immediate from Theorem \ref{theo:SOS-determinism}.  For (2), assume that ,  and that . We then have a derivation of the form:

For , we also know that there is an internal derivation of the form

 where  .  

 \noindent{\bf Extensiveness} follows from  (1) in 
Lemma \ref{lemma:redi-properties}. 

 \noindent{\bf Idempotence} is proved by repeated applications of (3) in Lemma \ref{lemma:redi-properties}.
 
As for  {\bf Monotonicity}, we proceed as in  \cite{NPV02}. Let  be the minimal ordering relation on  processes satisfying: (1)  . (2) If  and  and  then 
	. (3) If , for every context , .
	Intuitively,   represents the fact that  contains ``at least as much code'' as . We have to show that for every , , ,   and  if 
  then for every  and  s.t.  there 

for some   and  with  and  .
 This can be proved by induction on the  length of the derivation using the following two properties:\\
\noindent ({\bf a}) 
 is monotonic w.r.t. the store, in the sense that,  if  then for every  and  s.t. 
, 
 where 
and .


\noindent ({\bf b}) For every monotonic process , if  then for every  and   
	such that  we have either 
  or 
  where 
  and  .
The restriction to  programs which do not contain {\bf unless}  constructs is essential  here. \end{proof}




\appResultNN{Theorem \ref{the:col:CO}}{
Let  be the minimum function w.r.t. the order induced by  and   be a monotonic process. Then, 

}
\begin{proof}
Let  be a monotonic process and 
.
	By extensiveness  and by 
	idempotence,   . 
	Let . Since  and , it must be the case that 
	. If , by monotonicity . Since ,  and then, . We conclude . 
\end{proof}

\section{Detailed Proofs Section \ref{sec:denotsem}} \label{app:proofs-den}
\appResult{Observation \ref{l-vx-eq}}{Equality and  -variants}{
Let ,  and    be -variants such that ,    and . (1)  . (2)    iff . }
\begin{proof}
(1) Let ,   and . We  prove that  and .  We know that  
,  and . Hence, . Since , we can  show that 
 and then, .
Since  (Notation \ref{not:terms})  we conclude . The  ``'' side is analogous and we conclude . \\
Property (2) follows directly from the definition of . 
\end{proof}



\appResultNN{Lemma \ref{lem:soundness}}{
Let  be as in Definition \ref{def:conc-semantics}.
If  and ,  then .
}
\begin{proof}
Assume that ,  .
 We shall prove that . 
	We proceed by induction on the lexicographical order on the length of the internal derivation   and the structure of  , where the predominant component is the length of the derivation. Here we present the missing cases in the body of the paper. 

\noindent \underline{{\bf Case} }. This case is trivial. 

\noindent \underline{{\bf Case}  }. If  then it must be the case that  and  . We conclude  . 
	

\noindent \underline{{\bf Case}  }.  Consider the following derivation 
 
 where, by alpha-conversion,   and . Assume that 
   . 
 Since the derivation starting from  is shorter than that starting from , we conclude
.
 


\noindent \underline{{\bf Case}  }. This case is trivial since
	 for any . 
	
\noindent \underline{{\bf Case }}. We distinguish two cases:
(1) If , then we have  and  we conclude . (2), the case when       is similar to the case of . 

 








\end{proof}

\appResult{Lemma \ref{theo:comp}}{Completeness}{
Let   be a locally independent program s.t. . If  then  and 
. 
}
\begin{proof} 
Assume that    is locally independent,  and there is a derivation of the form  . We shall prove that  and
. 
	We proceed by induction on the lexicographical order on the length of the internal derivation  ()  and the structure of  , where the predominant component is the length of the derivation. 
 The locally independent condition is used for the case .
 We present here the missing cases in the body of the paper. 

\noindent \underline{{\bf Case}  }. This case is trivial

\noindent \underline{{\bf Case}  }. This case is trivial since it must be the case that  and hence . 

\noindent \underline{{\bf Case}  }. This case is trivial since  for any  and  and . 


\noindent \underline{{\bf Case}  }.If   the case is trivial. If    the case is similar to that of . 




\noindent \underline{{\bf Case}  }.  Assume that 
.   If  then   . By using the rule  we can show that there is a derivation


By inductive hypothesis we know that  and 
. 

\end{proof}

\section{Detailed Proofs Section \ref{sec:absframework}} \label{app-sec-abs}
\appResult{Theorem \ref{teo:corr}}{
Soundness of the approximation}
{
Let   be a description and     be upper correct w.r.t. .   Given a  \utcc\ program , if 
 then  .  
}
\begin{proof} 
Let  and assume that . Then,  where  is the lfp of . By the continuity of ,  there exists  s.t.   (the -th application of ). 
We proceed by  induction on the lexicographical order on 
the pair  and the structure of , where the predominant component is the length . We present here the missing cases in the body of the paper. 

\noindent \underline{{\bf Case}  }. This case is trivial.


\noindent \underline{{\bf Case}   }. We must have  and by monotonicity of ,  . We conclude  .


\noindent \underline{{\bf Case}   }. We must have that 
	and .  By inductive hypothesis we know that
	 and
	 and then,
	.



\noindent \underline{{\bf Case}   }. It must be the case that there exists  -variant of  s.t.
		. Then,  by (structural) inductive hypothesis . We conclude by using the properties of  in Definition \ref{dec:corapp} to show that , i.e.,  and  are -variants, and then, . 


\noindent \underline{{\bf Case}   }. 
	We know that  and by inductive hypothesis
	. We then conclude . 
	
\noindent \underline{{\bf Case}   }. This case is trivial since  approximates every possible concrete computation.
\end{proof}

\section{Auxiliary results} \label{app:proofs-aux}
\begin{proposition}\label{prop:x-variants-free-vars}
Let  be a process such that    and let . If    is an -variant of  then . 
\end{proposition}
\begin{proof}
	The proof proceeds  by induction on the structure of . We shall use the notation  and  to denote constraints and processes where the free variables are exactly  and we shall assume that . We assume that  and  is an -variant of . 
 We consider the following cases.  The others are easy. 

\noindent \underline{{\bf Case}  }. If  then, by monotonicity,  and then . Hence, it must be the case that  and  .  By induction we conclude . If , then  (since ). Hence,  and trivially,  and so . 

\noindent \underline{{\bf Case} }. 
			We know that 
		. 
		By definition of the operator , . Since    we conclude . 
\end{proof}

\begin{proposition}\label{prop:exists-free-vars}
If  then .
\end{proposition}
\begin{proof}
		The case  is trivial by the definition of . 
		The case , follows directly from Proposition \ref{prop:x-variants-free-vars}.
\end{proof}

\begin{proposition} \label{prop:den-se-ext}
If  then .
\end{proposition}
\begin{proof}
\noindent (): Let . Then, there exists an -variant  s.t. . Then,  (by definition) and  by Proposition \ref{prop:x-variants-free-vars}.

\noindent (): Let .  Then, there exists  -variant of  s.t. . By Proposition \ref{prop:x-variants-free-vars}, 
 and therefore, . 
\end{proof}





In Theorem \ref{teo:corr}, the proof of the    case  requires the following auxiliary results (similar to those in the concrete semantics). 

   \begin{observation}[Equality and -variants]\label{l-vx-eq-abs}
Let  and  be -variants such that ,    and . Then .
\end{observation}
\begin{proof}
Let  and  with . We shall prove that  and .  We know that  
 and . We also know that 
. Since , 
we can  show that 
.
Furthermore, 
 (see Notation \ref{not:terms}). 
Hence, we conclude 
. The proof of  is analogous. 
\end{proof}


\begin{proposition}\label{prop:forall-subs-abs}
 if and only if   for all admissible substitution . 
\end{proposition}
\begin{proof}
()Let  and   be an -variant of  s.t.  where . By definition of~ , we know that . Since  then . Hence,  and we conclude . 

\noindent() Let  be an admissible substitution. Suppose, to obtain a contradiction, that , there exists  -variant of  s.t.  and  (i.e., ). Since  then .  Therefore, there exists  -variant of  s.t.  and . By Observation \ref{l-vx-eq-abs},   and thus,  , a contradiction. 
\end{proof}

 \end{document}
