

\documentclass[11pt]{article} 
\usepackage{a4wide}  








\RequirePackage[latin1]{inputenc}     
 
\usepackage[english]{babel} 
\usepackage{amsmath} 
\usepackage{amsfonts} 
\usepackage{amssymb} 
\usepackage{xspace} 
\usepackage{latexsym} 
\usepackage{url} 
\usepackage{xspace} 
\usepackage[all]{xy} 
\usepackage{semantic}
\usepackage{cmll}
\usepackage{graphics,color}              
\RequirePackage[latin1]{inputenc}   
 
 


\newenvironment{comment}{{\bf MORE WORK:}} 
 
\newenvironment{restate-proposition}[2][{}]{\noindent\textbf{Proposition~{#2}}\;\textbf{#1}\  
}{\vskip 1em} 
 
\newenvironment{restate-theorem}[2][{}]{\noindent\textbf{Theorem~{#2}}\;\textbf{#1}\  
}{\vskip 1em} 
 
\newenvironment{restate-corollary}[2][{}]{\noindent\textbf{Corollary~{#2}}\;\textbf{#1}\  
}{\vskip 1em} 
 
\newcommand{\myparagraph}[1]{\medskip\noindent\textbf{#1}} 
 
\newcommand{\Proofitemb}[1]{\medskip \noindent {\bf #1\;}} 
\newcommand{\Proofitemfb}[1]{\noindent {\bf #1\;}} 
\newcommand{\Proofitem}[1]{\medskip \noindent } 
\newcommand{\Proofitemf}[1]{\noindent } 
\newcommand{\Defitem}[1]{\smallskip \noindent } 
\newcommand{\Defitemt}[1]{\smallskip \noindent {\em #1\;}} 
\newcommand{\Defitemf}[1]{\noindent } 
 
 


 
 


\newcommand{\eqdef}{=_{\text{def}}} 
\newcommand{\concat}{\cdot}\newcommand{\Int}{\mathit{int}} 
\newcommand{\nat}{\mathit{nat}} 
\newcommand{\String}{\mathit{string}} 
\newcommand{\Ident}{\mathit{ident}} 
\newcommand{\Block}{\mathit{block}} 
\newcommand{\Signature}{\mathit{signature}} 
 
\newcommand{\pc}{\mathit{pc}} 
\newcommand{\estack}{\mathit{estack}} 
\newcommand{\Error}{\epsilon} 
 




\newcommand{\staterule}[3]{} 
 
\newcommand{\GAP}{2ex} 
 
\newcommand{\recall}[2]{} 
 
\newcommand{\hbra}{\noindent\hbox to \textwidth{\leaders\hrule height1.8mm depth-1.5mm\hfill}} 
\newcommand{\hket}{\noindent\hbox to \textwidth{\leaders\hrule height0.3mm\hfill}} 
\newcommand{\ratio}{.3} 
 
\newenvironment{display}[1]{\begin{tabbing} 
  \hspace{1.5em} \= \hspace{\ratio\linewidth-1.5em} \= \hspace{1.5em} \= \kill 
  \noindent\hbra\-.8ex] 
  \hbox to \textwidth{\leaders\hrule height1.6mm depth-1.5mm\hfill}\-.8ex]\hket 
  \end{tabbing}} 
 
 
\newcommand{\sbline}{\hfill\smash[t]{\rule[1.5em]{\textwidth}{0.2ex}\hfill\hspace*{0ex}}} 
\newcommand{\sline}{\hfill\smash[t]{\rule[1.5em]{\textwidth}{0.1ex}\hfill\hspace*{0ex}}} 
\newcommand{\sentry}[2]{\>\>\ \smash[t]{\vrule width 0.2mm height 
    1.2\baselineskip depth 1.5\baselineskip}\>#2} 
 
\newcommand{\entry}[2]{\>\>\>#2} 
\newcommand{\clause}[2]{\>\>#2} 
\newcommand{\category}[2]{\clause{#1::=}{#2}} 
\newcommand{\subclause}[1]{\>\>\>#1} 
\newcommand{\redrule}[3]{\>\>\>\>\>#3} 
 




\newtheorem{theorem}{Theorem} 
 \newtheorem{fact}[theorem]{Fact} 
 \newtheorem{definition}[theorem]{Definition} 
 \newtheorem{lemma}[theorem]{Lemma} 
 \newtheorem{corollary}[theorem]{Corollary} 
 \newtheorem{proposition}[theorem]{Proposition} 
 \newtheorem{example}[theorem]{Example} 
 \newtheorem{exercise}[theorem]{Exercise} 
 \newtheorem{remark}[theorem]{Remark} 
 \newtheorem{question}[theorem]{Question}
 \newtheorem{proviso}[theorem]{Proviso} 
  \newtheorem{conjecture}[theorem]{Conjecture}



\newcommand{\Proof}{\noindent {\sc Proof}. } 
\newcommand{\Proofhint}{\noindent {\sc Proof hint}. } 
\newcommand{\qed}{\hfill} 
\newcommand{\EndProof}{\qed}
 


\newcommand{\Figbar}{{\center \rule{\hsize}{0.3mm}}}    \newenvironment{figureplr}{\begin{figure}[t] \Figbar}{\Figbar \end{figure}} 


\newcommand{\cl}[1]{{\cal #1}}          \newcommand{\la}{\langle}               \newcommand{\ra}{\rangle} 
 
\newcommand{\lf}{\lfloor} 
\newcommand{\rf}{\rfloor} 
\newcommand{\ul}[1]{\underline{#1}}     \newcommand{\ol}[1]{\overline{#1}}      \newcommand{\ok}{~ok}                   



\newcommand{\Gives}{\vdash}             \newcommand{\IGives}{\vdash_{I}}        \newcommand{\AIGives}{\vdash_{{\it AI}}} \newcommand{\CGives}{\vdash_{C}}        


\newcommand{\Models}{\mid \! =}              

\newcommand{\emptycxt}{\On}              \newcommand{\subs}[2]{[#1 / #2]} 
\newcommand{\sub}[2]{[#2 / #1]}         \newcommand{\Sub}[3]{[#3 / #2]#1}       

\newcommand{\lsub}[2]{#2 / #1}          

\newcommand{\impl}{\supset} 
\newcommand{\arrow}{\rightarrow}        \newcommand{\trarrow}{\stackrel{*}{\rightarrow}}        \newcommand{\limp}{\multimap} \newcommand{\bang}{\oc} 
\newcommand{\limpe}[1]{\stackrel{#1}{\multimap}}
\newcommand{\hyp}[3]{#1:(#2, #3)}
\newcommand{\letm}[3]{{\sf let} \ ! #1 = #2 \ {\sf in} \ #3}    \newcommand{\tertype}{{\bf 1}}
\newcommand{\behtype}{{\bf B}}
\newcommand{\bt}[1]{{\it BT}(#1)}       \newcommand{\cxt}[1]{#1[~]}             \newcommand{\pr}{\parallel}             \newcommand{\Nat}{\mathbf{N}}                 \newcommand{\Natmax}{\mathbf{N}_{{\it max}}}  \newcommand{\Rat}{\mathbf{Q}^{+}}                 \newcommand{\Ratmax}{\mathbf{Q}^{+}_{{\it max}}}  \newcommand{\Alt}{ \mid\!\!\mid  } 
\newcommand{\isum}{\oplus} 
\newcommand{\csum}{\uplus}              \newcommand{\dpar}{\mid\!\mid} 
\newcommand{\infer}[2]{\begin{array}{c} #1 \\ \hline #2 \end{array}} 




\newcommand{\bool}{{\sf bool}}          \newcommand{\Or}{\vee}                  \newcommand{\OR}{\bigvee}               \newcommand{\AND}{\wedge}               \newcommand{\ANDD}{\bigwedge}           \newcommand{\Arrow}{\Rightarrow}        \newcommand{\IFF}{\mbox{~~iff~~}}       \newcommand{\iffArrow}{\Leftrightarrow} 



\newcommand{\dl}{[\![}                  \newcommand{\dr}{]\!]}                  \newcommand{\lam}{{\bf \lambda}}        




\newcommand{\ubis}{\approx^u}          \newcommand{\uabis}{\approx^{u}_{ccs}} 

\newcommand{\cbis}{\approx}        \newcommand{\cabis}{\approx_{ccs}}  

\newcommand{\lcbis}{\approx^{\ell}} \newcommand{\lcabis}{\approx^{\ell}_{ccs}} \newcommand{\lcbiswrong}{\approx^{\ell \Downarrow}} 







\newcommand{\maytest}{=_{\Downarrow}}
\newcommand{\musttest}{=_{\Downarrow_{S}}}


 
 


\newcommand{\prt}[1]{{\cal P}(#1)}      \newcommand{\finprt}[1]{{\cal P}_{fin}(#1)}\newcommand{\finprtp}[1]{{\cal P}_{fin}^{+}(#1)}\newcommand{\union}{\cup}               \newcommand{\inter}{\cap}               \newcommand{\Union}{\bigcup}            \newcommand{\Inter}{\bigcap}            \newcommand{\cpl}[1]{#1^{c}}            \newcommand{\card}{\sharp}              \newcommand{\minus}{\backslash}         \newcommand{\sequence}[2]{\{#1\}_{#2}}  \newcommand{\mset}[1]{\{\! | #1 |\!\}}  



\newcommand{\two}{{\bf O}}              \newcommand{\join}{\vee}                \newcommand{\JOIN}{\bigvee}             \newcommand{\meet}{\wedge}              \newcommand{\MEET}{\bigwedge}           \newcommand{\dcl}{\downarrow}           \newcommand{\ucl}{\uparrow}             \newcommand{\conv}{\downarrow}          \newcommand{\diver}{\uparrow}           \newcommand{\Conv}{\Downarrow}          \newcommand{\SConv}{\Downarrow_{S}}          \newcommand{\CConv}{\Downarrow_{C}}
\newcommand{\Diver}{\Uparrow}           \newcommand{\cpt}[1]{{\cal K}(#1)}      \newcommand{\ret}{\triangleleft}        \newcommand{\nor}{\succeq}
\newcommand{\prj}{\underline{\ret}}     \newcommand{\parrow}{\rightharpoonup}   \newcommand{\ub}[1]{{\it UB}(#1)}       \newcommand{\mub}[1]{{\it MUB}(#1)}     \newcommand{\lift}[1]{(#1)_{\bot}}      \newcommand{\forget}[1]{\underline{#1}} 

\newcommand{\rl}[1]{\;{\cal #1}\;}             \newcommand{\rel}[1]{{\cal #1}}         \newcommand{\per}[1]{\;#1 \;} 
\newcommand{\wddagger}{\natural}  

\newcommand{\pair}[2]{\langle #1 , #2 \rangle} 



 
\newcommand{\fn}[1]{{\it fn}(#1)}                       \newcommand{\bn}[1]{{\it bn}(#1)}                       \newcommand{\names}[1]{{\it n}(#1)}                     \newcommand{\true}{{\sf t}}                             \newcommand{\false}{{\sf f}}                            \newcommand{\pio}{\pi_1}                                \newcommand{\pioo}{\pi_{1}^{r}} 
\newcommand{\piom}{\pi_{1}^{-}}                         \newcommand{\pioi}{\pi_{1I}}                    \newcommand{\pifo}{\pi_{\w{1f}}}                                \newcommand{\pilo}{\pi_{\w{1l}}}                                \newcommand{\sort}[1]{{\it st}(#1)}                     \newcommand{\ia}[1]{{\it ia}(#1)}                     \newcommand{\ite}[3]{{\sf if~} #1 {\sf ~then~} #2 {\sf ~else~} #3}      \newcommand{\casep}[2]{{\sf case}^{\times}(#1, \pair{x}{y}\Arrow#2)}      \newcommand{\casel}[3]{{\sf case}^{L}(#1, #2, \s{cons}(x,y)\Arrow#3)}      \newcommand{\caseb}[3]{{\sf case}^{b}(#1, #2, \s{cons}(x,y)\Arrow#3)}      \newcommand{\nil}{{\sf nil}} 
\newcommand{\cons}{{\sf cons}} 
\newcommand{\idle}[1]{{\it Idle}(#1)}                   \newcommand{\conf}[1]{\{ #1 \}}                         \newcommand{\link}[2]{#1 \mapsto #2}                    \newcommand{\mand}{\mbox{ and }} 
\newcommand{\dvec}[1]{\tilde{{\bf #1}}}                 \newcommand{\erloc}[1]{{\it er}_{l}(#1)}                \newcommand{\w}[1]{{\it #1}}    \newcommand{\vcb}[1]{{\bf #1}} 
\newcommand{\lc}{\langle\!|} 
\newcommand{\rc}{|\!\rangle} 
\newcommand{\obj}[1]{{\it obj}(#1)}  
\newcommand{\move}[1]{{\sf move}(#1)}  
\newcommand{\qqs}[2]{\forall\, #1\;\: #2} 
\newcommand{\qtype}[4]{\forall #1 :  #2 . (#4,#3)} 
\newcommand{\xst}[2]{\exists\, #1\;\: #2} 
\newcommand{\xstu}[2]{\exists\, ! #1\;\: #2} 
\newcommand{\dpt}{\,:\,} 
\newcommand{\cond}[3]{\mathsf{if}\ #1\ \mathsf{then}\ #2\ \mathsf{else}\ #3} 
\newcommand{\s}[1]{{\sf #1}}    \newcommand{\vc}[1]{{\bf #1}} 
\newcommand{\lnorm}{\lbrack\!\lbrack} 
\newcommand{\rnorm}{\rbrack\!\rbrack} 
\newcommand{\sem}[1]{\underline{#1}} 
\newcommand{\tra}[1]{\langle #1 \rangle}
\newcommand{\trb}[1]{[ #1 ]}
\newcommand{\squn}{\mathop{\scriptstyle\sqcup}} 
\newcommand{\lcro}{\langle\!|} 
\newcommand{\rcro}{|\!\rangle} 
\newcommand{\semi}[1]{\lcro #1\rcro} 
\newcommand{\sell}{\,\ell\,} 
\newcommand{\SDZ}[1]{\marginpar{\textbf{SDZ:} {#1}}} 
 
\newcommand{\when}[3]{{\sf when}~#1~{\sf then}~#2~{\sf else}~#3}  
\newcommand{\wthen}[2]{{\sf when}~#1~{\sf then}~#2~}  
\newcommand{\welse}[1]{{\sf else}~#1}  



\newcommand{\act}[1]{\xrightarrow{#1}} 

\newcommand{\lact}[1]{\stackrel{#1}{\makebox[5mm]{\,}}}

\newcommand{\set}[1]{\{#1\}}
\newcommand{\pst}[2]{{\sf pset}(#1,#2)}
\newcommand{\st}[2]{{\sf set}(#1,#2)}
\newcommand{\chtype}[2]{{\it Ch_{#1}(#2)}}
\newcommand{\rgtype}[2]{{\it {\sf Reg}_{#1} #2}}

\newcommand{\get}[1]{{\sf get}(#1)}









\newcommand{\acteq}[1]{\stackrel{#1}{\leadsto}} 


\newcommand{\actI}[1]{\xrightarrow{#1}_{1}}

\newcommand{\actII}[1]{\xrightarrow{#1}_{2}}


 \newcommand{\wact}[1]{\stackrel{#1}{\Rightarrow}} \newcommand{\wactI}[1]{\stackrel{#1}{\Rightarrow_{1}}} \newcommand{\wactII}[1]{\stackrel{#1}{\Rightarrow_{2}}} 


\newcommand{\mact}[1]{\stackrel{#1}{\rightarrow_{m}}} \newcommand{\wmact}[1]{\stackrel{#1}{\Rightarrow_{m}}} 

\newcommand{\lwact}[1]{\stackrel{#1}{\Leftarrow}} 
 
 
 
\newcommand{\Eval}[1]{\Downarrow^{#1}} 
 
 
\newcommand{\Z}{{\bf Z}} 
\newcommand{\Real}{\mathbb{R}^{+}}  
\newcommand{\Return}{\ensuremath{\mathtt{return}}\xspace}                 
\newcommand{\Stop}{\ensuremath{\mathtt{stop}}\xspace} 
\newcommand{\Wait}{\ensuremath{\mathtt{wait}}\xspace} 
\newcommand{\Read}{\ensuremath{\mathtt{read}}\xspace} 
\newcommand{\Write}{\ensuremath{\mathtt{write}}\xspace} 
\newcommand{\Yield}{\ensuremath{\mathtt{yield}}\xspace} 
\newcommand{\Next}{\ensuremath{\mathtt{next}}\xspace} 
\newcommand{\Load}{\ensuremath{\mathtt{load}}\xspace} 
\newcommand{\Call}{\ensuremath{\mathtt{call}}\xspace} 
\newcommand{\Tcall}{\ensuremath{\mathtt{tcall}}\xspace} 
\newcommand{\Pop}{\ensuremath{\mathtt{pop}}\xspace} 
\newcommand{\Build}{\ensuremath{\mathtt{build}}\xspace} 
\newcommand{\Branch}{\ensuremath{\mathtt{branch}}\xspace} 
\newcommand{\Goto}{\ensuremath{\mathtt{goto}}\xspace} 
 
\newcommand{\hatt}[1]{#1^{+}} 
\newcommand{\Of}{\mathbin{\w{of}}} 
 
\newcommand{\susp}{\downarrow} 
\newcommand{\lsusp}{\Downarrow_L} 
\newcommand{\wsusp}{\Downarrow} 
\newcommand{\commits}{\searrow} 
 
 
\newcommand{\spi}{S\pi} 
 

 \newcommand{\pres}[2]{#1\triangleright #2} \newcommand{\present}[3]{{\sf present} \ #1 \ {\sf do } \ #2 \ {\sf  else} \ #3}


\newcommand{\tick}{{\sf tick}}          

 
 
\newcommand{\sbis}{\equiv_L} 
\newcommand{\emit}[2]{\ol{#1}#2}  
\newcommand{\match}[4]{[#1=#2]#3,#4}       

\newcommand{\matchv}[4]{[#1 \unrhd #2]#3,#4}

\newcommand{\new}[2]{\nu #1 \ #2} 
\newcommand{\outact}[3]{\new{{\bf #1}}{\emit{#2}{#3}}} 
\newcommand{\real}{\makebox[5mm]{\,}}

\newcommand{\regterm}[2]{{\sf reg}_{#1} #2}
\newcommand{\thread}[1]{{\sf thread} \ #1}
\newcommand{\store}[2]{(#1 \leftarrow #2)}
\newcommand{\pstore}[2]{(#1 \Leftarrow #2)}
\newcommand{\regtype}[2]{{\sf Reg}_{#1} #2}
\newcommand{\uregtype}[3]{{\sf Reg}_{#1}(#2, #3)}
\newcommand{\urtype}[2]{{\sf Reg}(#1, #2)}

\newcommand{\upair}[2]{[#1,#2]}
\newcommand{\letb}[3]{\mathsf{let}\;\oc #1 = #2\;\mathsf{in}\;#3}

\newcommand{\vlt}[1]{{\cal V}(#1)}
\newcommand{\prs}[1]{{\cal P}(#1)}


\bibliographystyle{abbrv} 
 
\begin{document} 
 
\title{An affine-intuitionistic system of types and effects: \\
       confluence and termination}

\author{Roberto M. Amadio 
\quad  Patrick Baillot \quad
 Antoine Madet \\ \\
{\footnotesize  Universit\'e Paris Diderot (Paris 7)} \\
{\footnotesize PPS (UMR 7126 CNRS-Paris-Diderot)} \\ 
{\footnotesize  ENS  Lyon, Univ. Lyon} \\
{\footnotesize LIP (UMR 5668 CNRS-ENSL-INRIA-UCBL)} }



\maketitle 

\begin{abstract}
We present an affine-intuitionistic system of {\em types and effects} which
can be regarded as an extension  of Barber-Plotkin {\em Dual Intuitionistic Linear Logic}
to multi-threaded programs with effects. In the
system, dynamically generated values such as references or channels are
abstracted into a finite set of {\em regions}.  We introduce a discipline of
{\em region usage} that entails the {\em confluence} (and hence determinacy) of the
typable programs.  Further, we show that a discipline of region
{\em stratification} guarantees {\em termination}.

{\bf Keywords:} Linear logic. Types and Effects. Confluence. Termination.
\end{abstract}


\section{Introduction}\label{intro-sec}
There is a well-known connection between {\em
intuitionistic proofs} and {\em typed functional programs} that goes
under the name of {\em Curry-Howard} correspondence.  Following the
introduction of {\em linear logic} \cite{Girard87}, this correspondence has
been refined to include an explicit treatment of the process of data
duplication.  Various formalisations of these ideas have been proposed
in the literature (see, {\em e.g.}, \cite{BBPH93,Benton94,Plotkin93,MOTW95,Barber96}) 
and we will focus here in particular on Affine-Intuitionistic Logic and,
more precisely, on an {\em affine} version of Barber-Plotkin {\em Dual Intuitionistic
Linear Logic} (DILL) as described in \cite{Barber96}. 

In DILL, the operation of -abstraction is
always {\em affine}, {\em i.e.}, the formal parameter is used at most
once.  The more general situation where the formal parameter has
multiple usages is handled through a constructor  (read bang) 
marking values that can be duplicated and a destructor  
filtering them and effectively allowing their
duplication. Following this idea, {\em e.g.},  an intuitionistic judgement 
is translated into an affine-intuitionistic one as follows:

{\footnotesize
}

We recall that in DILL the hypotheses are split in two zones according to their {\em usage}.
Namely, one distinguishes between the {\em affine} hypotheses 
that can be used at most once and the {\em intuitionistic} ones 
that can be used arbitrarily many times. In our formalisation, we will use 
for the former and  for the latter.

Our purpose is to explore an {\em extension} of this connection to {\em
multi-threaded programs} with {\em effects}. 
By extending the connection, we mean in particular
that the type system should guarantee confluence (and hence determinism) and termination
of the typable programs while preserving a reasonable expressive power.
By multi-threaded program, we mean a program where distinct threads of execution may be active at
the same time (as it is typically the case in concurrent programs) and by
effect, we mean the possibility of executing operations that modify
the {\em state} of a system such as reading/writing a reference or
sending/receiving a message. 


We will start by introducing a simple-minded extension of the purely
functional language with operators to run threads in parallel while
reading/modifying the state which is loosely inspired by concurrent
extensions of the ML programming language such as 
\cite{GMP89} and \cite{Reppy91}.  Following a rather
standard practice (see, {\em e.g.}, \cite{LG88,TT97}), we suppose that
dynamically generated values such as channels or references  are
{\em abstracted} into a finite number of {\em regions}. This abstraction is
reflected in the type system where the type of an address {\em
depends} on the region with which the address is associated. Thus we 
write  for the type of addresses containing values of
type  and relating to the region  of the store.


Not surprisingly, the resulting functional-concurrent language is
neither confluent nor terminating.  However, it turns out that there are reasonable
strategies to recover these properties.  The general idea is that {\em
confluence} can be recovered by introducing a proper discipline of
{\em region usage} while {\em termination} can be recovered through a
discipline of {\em region stratification}.


The notion of {\em region usage} is reminiscent 
of the one of {\em hypotheses usage} arising in affine-intuitionistic logic.
Specifically, we  distinguish the regions that can be used at most
once to write and at most once to read and those that can be used at
most once to write and arbitrarily many times to read. 

The notion of {\em region stratification} is based
on the idea that values stored in a region should only produce effects
on {\em smaller} regions.  The implementation of this idea requires a
substantial refinement of the type system that has to predict the {\em
effects} potentially generated by the evaluation of an expression.  This is 
where  {\em type and effect systems}, as introduced in
\cite{LG88}, come into play.

It turns out that the notions of region usage and region
stratification combine smoothly, leading to the definition of an
affine-intuitionistic system of types and effects. The system has
affine-intuitionistic logic as its functional core and it can be used
to guarantee the determinacy and termination of multi-threaded
programs with effects.


\paragraph{Related work}
Girard, through the introduction of {\em linear logic} \cite{Girard87}, 
has widely promoted a finer analysis of the {\em structural rules} of logic.
There have been various attempts at producing a functional programming
language based on these ideas and with a reasonably handy
syntax (see, {\em e.g.}, 
\cite{BBPH93,Benton94,Plotkin93,MOTW95,Barber96}).  The logical origin
of the notion of {\em usage} can be traced back to Girard's LU system
\cite{Girard91} and in particular it is adopted in the Barber-Plotkin system \cite{Barber96}
on which we build on.

A number of works on type systems for concurrent languages such as the
-calculus have been inspired by linear logic even though in many cases the
exact relationships with logic are at best unclear.  In particular,
Kobayashi {\em et al.} \cite{KPT99} introduce a type-system with
`use-once' channel types that guarantees {\em confluence}.  Clearly,
this approach inspires our conditions for confluence.
Let us also recall that Kobayashi
{\em et al.} (see, {\em e.g.}, \cite{K02,IK05}) have produced type
systems with a much more elaborate notion of {\em usage} than ours (a usage can
be almost as complex as a CCS process) and shown that they can 
guarantee a variety of properties of concurrent programs such as {\em absence of
deadlock}.

It is well known that intuitionistic logic is at the basis of typed
functional programming.  The {\em type and effect} system introduced
in \cite{LG88} is an enrichment of the intuitionistic system tracing
the effects of {\em imperative} higher-order programs acting on a {\em store}.  
The system has provided a successful static analysis tool
for the problem of {\em heap-memory deallocation} \cite{TT97}. 
More recently, this issue has been  revisited following the ideas of 
linear logic \cite{WW01,FMA06} .

The so called {\em reducibility candidates method} is probably the most
important technique to prove {\em termination} of typable higher-order
programs.  Extensions of the method to `functional fragments' of the
-calculus have been proposed, {\em e.g.}, in \cite{YBH04,S06}.
Boudol \cite{Boudol07} has shown that a stratification of the regions
guarantees termination for a multi-threaded higher-order functional language 
with references and cooperative scheduling. 
Our formulation of the stratification discipline is actually based on \cite{Amadio09} 
which revisits and extends \cite{Boudol07}.



\paragraph{Structure of the paper}
Section \ref{aitype-sec} introduces an affine-intuitionistic system with regions
for a call-by-value functional-concurrent language.
Section \ref{confluence-sec} introduces a discipline of region usage that guarantees
confluence of the typable programs.
Section \ref{aitype-effect-sec} enriches the affine-intuitionistic system introduced
in section \ref{aitype-sec} with a notion of effect which provides an upper bound
on the set of regions on which the evaluation of a term may produce effects.
Finally, section \ref{termination-sec} describes a discipline of region stratification
that guarantees the termination of the typable programs.
Proofs of the main results are available in appendix \ref{appendix-proof}.

\section{An affine-intuitionistic type system with regions}\label{aitype-sec}

\subsection{Syntax: programs}
Table \ref{syntax-terms} introduces the syntax of our programs.
\begin{table}
{\footnotesize
}
\caption{Syntax: programs}\label{syntax-terms}
\end{table}
We denote variables with , and  with  the values
which are included in the category  of terms. Stores are denoted by
, and programs  are combinations of terms and stores.  We comment
the main operators of the language:  is a constant inhabiting
the terminal type  (see below),  is the {\em
affine} abstraction and  the application,  marks values that
can be duplicated while  filters them and
allows their multiple usage in , in  the operator 
generates a fresh address name  whose scope is ,  and
 write the value  in a {\em volatile} address and a {\em
persistent} one, respectively, while  fetches a value from
the address  (either volatile or persistent), finally 
evaluates in parallel  and .
Note that when writing either , or , or  the
variable  is bound in . 
As usual, we abbreviate  with , where  is not free in .
{\em Evaluation contexts}  follow a {\em call-by-value} discipline.
{\em Static contexts}  are composed of parallel composition and 's.
Note that stores can only appear in a static context. Thus 
 is a legal term while   is not. 


\subsection{Operational semantics}
Table \ref{op-sem} describes the operational semantics of our language.
\begin{table}
{\footnotesize

}
\caption{Operational semantics} \label{op-sem}
\end{table}
Programs are considered up to a {\em structural equivalence}  which
is the least equivalence relation preserved by  static contexts,
and which contains the equations for  -renaming, 
for the commutativity and associativity  of parallel composition,
for enlarging the scope of the  operators to parallel programs,
and for extracting the  from an evaluation context.
We use the notation  for the substitution of the value 
for the variable .
The reduction rules apply modulo structural equivalence 
and in a static context .
For instance, the program 

is structurally equivalent (up to some renaming) to
. This transformation
exposes the term   in the 
static context , where the
evaluation context  is .





\subsection{Syntax: types and contexts}
Table \ref{syntax-types} introduces the syntax of types and contexts.
\begin{table}
{\footnotesize
}
\caption{Syntax: types and contexts}\label{syntax-types}
\end{table}
We denote regions with  and we suppose a region 
is either {\em volatile} () or {\em persistent} ().
Types are denoted with . Note that we distinguish a
special behaviour type  which is given to the entities of
the language which are
not supposed to return a value  (such as a store or several values in parallel)
while types of entities that may return a value are denoted with .
Among the types , we distinguish a terminal type , 
an affine functional type , the type  of terms of type 
that can be duplicated, and the type  of 
addresses containing values of type 
and related to the region . Hereby types may depend on regions.

Before commenting variable and region contexts, we need to define the notion of {\em usage}.
To this end, it is convenient to introduce a set with three values 
 and a {\em partial} binary operation  such
that ,  and which
is undefined otherwise.

We denote with  a {\em variable usage} and assume that  is either  (a variable to be used
at most once) or  (a variable that can be used arbitrarily many times).
Then a variable context (or simply a context)  has the  shape:
,
where  are distinct variables,  and  are types of
terms that may return a result. Writing  means that the variable 
 ranges on values of type  and can be used according to .
We  write  for the set  of
variables where the context is defined.
The sum on usages is extended to contexts componentwise.
In particular, if   and  then
 only if 
 is defined.

We are going to associate a usage with regions too, but in this case a usage
will be a two dimensional vector because we want to be able to distinguish
input and output usages. We denote with  an element of one of the following
three sets of usages:
,
,
,
where by convention we reserve the first component to describe the
output usage and the second for the input usage. Thus a region with usage
 should be written at most once while it can be 
read arbitrarily many times. 

The addition  is defined provided  and  are in the same set of usages and 
moreover the componentwise addition is defined. 
For instance, if  and  then the sum is undefined
because  and  are not in the same set while if  and
 then the sum is undefined because  is undefined.
Note that in each set of usages there is
a {\em neutral} usage  such that  for all  in the same set.

A region context  has the shape:

where  are distinct regions,  are usages in the sense just defined, 
and  are types of terms that may return a result. 
The typing system will additionally guarantee that whenever we use a type 
 the region context  contains 
an hypothesis  for some .
Intuitively, writing  means that addresses related to region
 contain values of type  and that they 
can be used according to the usage .
We  write  for the set  of the regions
where the region context is defined.
As for contexts, the sum on usages is extended to region contexts
componentwise.
In particular,  if  and  then
 only if 
 is defined. 
Moreover, for  to be defined we require that .
There is no loss of generality in this hypothesis because if, say, 
 and  then we can always add 
 to  where  is the neutral usage of the set to which
 belongs (this is left implicit in the typing rules).


\subsection{Affine-intuitionistic type system with regions}
Because types depend on regions, we have to be careful in stating in 
table \ref{type-cxt-unstratified}
when a region-context and a type are compatible (),
when a region context is well-formed (), 
when a type is well-formed in a region context () 
and when a context is well-formed in a region context ().

A more informal way to express the condition is to say that a
judgement  is well formed provided that: (1) all the region names
occurring in the types  belong to the set
 and (2) all types of the shape
 with  and occurring in the
types  are such that .
For instance, one may verify that  can be derived while
 and
 cannot.



\begin{table}
{\footnotesize
}
\caption{Type and context formation rules (unstratified)}\label{type-cxt-unstratified}
\end{table}
Next, table \ref{air-system} introduces an affine-intuitionistic type system 
{\em with regions} whose basic judgement
 attributes a type  to the program 
in the region context  and the context .
Here and in the following we omit the rule for typing a program
 which is symmetric to the one for the program .


We write  if  and
 if either  or
 and . We write  ()
if the predicate  holds for at least one (for all) the hypotheses in
. Notice that the so called {\em promotion rule} that allows to
duplicate a value requires that the related contexts are {\em not}
affine.  Because of this condition, the rule allows for a form of
weakening of the hypotheses in the conclusion.  We can then state the
following {\em weakening} lemma.

\begin{lemma}[weakening]
If  and  then
.
\end{lemma}



\begin{table}
{\footnotesize
}
\caption{An affine-intuitionistic type system with regions}\label{air-system}
\end{table}


\begin{example}
Let  and 
.
We check that: .
By the rule for affine implication, this reduces to:
.
If we define , then by the rule for the
{\sf let} we reduce to:

and 
.
The former is an axiom while the latter is derived from:
 
and
.
Note that we can actually apply the function  to a value  which 
is typed using the promotion rule as follows:

We remark that the region context and the context play two
different roles: the context counts the number of occurrences of a variable
while the region context counts the number of input-output effects. 
In our example, the variable  occurs several times but we can be sure
that there will be at most one input and at most one output in the related
region.
\end{example}

\begin{example}
We consider a {\em functional} 
which can be given the type 
 in a region
context . We can apply  to 
the functions  and  which
have the appropriate types in the compatible region contexts 
 and 
, respectively.
Such {\em affine} usages would not be compatible with an
intuitionistic implication as in this case
one has to {\em promote} (put a  in front of) 
 and  before passing them as arguments.
\end{example}


As in Barber-Plotkin system \cite{Barber96}, the preservation of typing by
substitution comes in two flavours: one for affine variables and another
for intuitionistic variables.

\begin{lemma}[substitution]\label{sub-lemma}
\Defitemf{(1)} If ,
, and 
 then
.

\Defitem{(2)} If ,
, and 
 then
.
\end{lemma}

We rely on lemma \ref{sub-lemma} to show that the basic
reduction rules in table \ref{op-sem} preserve typing.
Then, observing that typing is invariant under structural
equivalence, we can lift the property  to the reduction relation 
which is generated by the basic reduction rules.

\begin{theorem}[subject reduction]\label{sub-red-thm}
If  and  then
. 
\end{theorem}


In our formalism, a {\em closed} program is a program whose only free variables
have region types (as in, say, the -calculus). 
For {\em closed} programs one can state a {\em progress property}
saying that if a program cannot progress then, up to structural equivalence,
every thread is either a value or a term of the shape  and there
is no store in parallel of the shape  or . In particular,
we notice that a {\em closed} value of type  must have the shape  so
that in well-typed closed programs such as  or
,  is guaranteed to have the shape  
required by the operational semantics in table \ref{op-sem}.

\begin{proposition}[progress]
Suppose  is a closed typable program which cannot reduce. Then
 is structurally equivalent to a program

where  is either a value or can be uniquely decomposed as 
a term  such that no value is associated with the address
 in the stores .
\end{proposition}


\section{Confluence}\label{confluence-sec}
In our language, each thread evaluates deterministically
according to a call-by-value evaluation strategy.
The only source of non-determinism comes from a concurrent
access to the memory. More specifically, we may have a non-deterministic
program if several values are stored at the same address as in the following
example:

or if there is a race condition on a volatile address as in the following
example:

On the other hand, a race condition on a persistent address such as:

does not compromise determinism because the two possible reductions commute.
We can rule out the problematic situations \ref{value-race} and \ref{volatile-store-race} 
if we remove from our system the region usage  and if we restrict
the usages of non-persistent stores to those 
in which there is at most one read effect.
More precisely, we add a condition  to the typing rules
for volatile stores  and  as specified in
table \ref{rules-confluence}.  

\begin{table}
{\footnotesize
}
\caption{Restricted usages and restricted rules for confluence}\label{rules-confluence}
\end{table}
We denote with  provability in this restricted system.
This system still enjoys the subject reduction property and moreover
its typable programs are strongly confluent.

\begin{proposition}[subj. red. and confluence]\label{confluence-thm}
Suppose . Then:

\Defitem{(1)} If  then .

\Defitem{(2)} If  and  then either  or
there is a  such that  and .
\end{proposition}
\Proof
\Proofitemf{(1)} We just have to reconsider the case
where  and verify
that if  then 
 which entails that
 is typable in the same context as 
.

\Proofitem{(2)} The restrictions on the usages forbid the typing of
a store such as the one in \ref{value-race}  where two values are stored
in the same region. Moreover, it also forbids the typing of two parallel reads
on a volatile store. \qed \\


We note that the rules for ensuring confluence require that at most
one value is associated with a region. This is quite a restrictive
discipline but one has to keep in mind that it targets regions that
can be accessed concurrently by several threads. Of course, the
discipline could be relaxed for the regions that are accessed by one
single sequential thread.


\section{An affine-intuitionistic type and effect system}
\label{aitype-effect-sec}
We refine the type system to include {\em effects} which are
denoted with  and are finite sets of regions.
The syntax of programs (table \ref{syntax-terms}) and their 
operational semantics (table \ref{op-sem}) are unchanged.
The only modification to the syntax of types (table \ref{syntax-types}) is that 
the affine implication is now annotated with an effect
so that we write:
.
This introduces a new dependency
of types on regions and consequently the compatibility condition between
region contexts and functional types in table \ref{type-cxt-unstratified} 
becomes:

For instance, one may verify that the judgement  is 
derivable.
Also to allow for some flexibility, it is convenient to introduce a
subtyping relation on types and effects as specified in table \ref{subtyping}.
\begin{table}
{\footnotesize
}
\caption{Subtyping induced by effect containment}\label{subtyping}
\end{table}

We notice that the {\em transitivity rule} for subtyping

can be derived via a simple induction on the height of the proofs.
The typing judgements now take the shape

where the effect  provides an upper bound on the set of 
regions on which the program  may read or write when it is
evaluated. In particular, we can be sure that values and stores
produce an empty effect. As for the operations to read and write
the store, one exploits the dependency of address types on regions
to determine the region where the effect occurs (cf. \cite{LG88}).
For the sake of completeness, the typing rules are spelled out
in table \ref{ter-system}. 

\begin{table}
{\footnotesize
}
\caption{An affine-intuitionistic type and effect system}\label{ter-system}
\end{table}

We stress that these rules are the same as the ones in table
\ref{air-system} modulo the enriched syntax of the functional types and the
management of the effect  on the right hand side of the 
sequents. The management of the effects is {\em additive} as in
\cite{LG88}, indeed effects are just {\em sets} of regions.

The introduction of the subtyping rules has a limited impact
on the structure of the typing proofs. Indeed, if 
then we know that  and  may just differ in the effects 
annotating the functional types. In particular, when looking at the
proof of the typing judgement of a value such as 
,  we can always argue that 
 has the shape  and, in case the effect 
is not empty, that there is a shorter proof of the judgement
 where
, , and .


Then to prove subject reduction, we just repeat the proof of
theorem \ref{sub-red-thm} while using standard arguments to keep 
track of the effects.

\begin{proposition}[subject reduction with effects]\label{sub-red-eff-thm}
Types and effects are preserved by reduction.
\end{proposition}

It easy to check that a typable program such as  which
is ready to produce an effect on the region  associated with 
will indeed contain  in its effect. Thus the subject reduction
property stated above as proposition \ref{sub-red-eff-thm}
entails that the type and effect system does provide an upper bound on
the effects a program may produce during its evaluation.



\section{Termination}\label{termination-sec}
Terms typable in the unstratified type and effect system described in table \ref{ter-system}
may diverge. For instance, the following term  stores at the address  a function 
that, given an argument, keeps fetching itself from the store forever:

One may verify that  is typable in a region context 
.

This example suggests that in order to recover termination,
we may order regions and make sure that
a value stored in a certain region when put in an
evaluation context can only produce effects on smaller regions.
To formalise this idea, we introduce
in table \ref{type-cxt-stratified} rules for the formation of
types and contexts which are alternative to those in
table  \ref{type-cxt-unstratified}.
Assuming ,
one may check that the judgement
  is derivable
while  is {\em not}.

\begin{table}
{\footnotesize
}
\caption{Rules for the formation of types and contexts (stratified)}\label{type-cxt-stratified}
\end{table}

It is easy to verify that the stratified system is a restriction of the
unstratified one and that the subject reduction theorem
\ref{sub-red-eff-thm} still holds in the restricted stratified
system. If confluence is required, then one may add 
the restrictions spelled out in table \ref{rules-confluence}.

Concerning termination, we recall that
there is a standard forgetful translation  from
affine-intuitionistic logic to intuitionistic logic which amounts to
forget about the modality  and the usages and to regard the affine
implication as an ordinary intuitionistic implication.  Thus, for
instance, the translation of types goes as follows:
 and 
;
while the translation of terms is:
 and  \quad 
.
In table \ref{forget-translation}, we lift this translation from the
stratified {\em affine-intuitionistic} type and effect system into a
stratified {\em intuitionistic} type and effect system defined in
\cite{Amadio09}.  
\begin{table}
{\footnotesize
}
\caption{Forgetful translation}\label{forget-translation}
\end{table}

The translation assumes a {\em decoration phase} where the (free or
bound) variables with a region type of the shape  are
labelled with the region . Intuitively, the intuitionistic system
abstracts an address  related to the region  to the
region  itself so that a decorated variable  translates into a
constant . In the intuitionistic language, a region  is a term of
region type , for some  and all stores are persistent.
The full definition of the language is recalled in
appendix \ref{termination-thm}.

It turns out that a reduction in the affine-intuitionistic system is
mapped to exactly a reduction in the intuitionistic system.  Then the
termination of the intuitionistic system proved in \cite{Amadio09}
entails the termination of the affine-intuitionistic one.


\begin{theorem}[termination]\label{termination-thm}
Programs typable in the stratified affine-intuitionistic 
type and effect system terminate.
\end{theorem}


\section{Conclusion}
We have presented an affine-intuitionistic system of types and effects for 
a functional-concurrent programming language. 
The functional core of the system is based on Barbed-Plotkin 
affine-intuitionistic logic which distinguishes between affine and
intuitionistic hypotheses. 
The language also includes a `non-logical' part with operators
to read and write dynamically generated addresses of a `store'. 
In the type system, such addresses are abstracted into a 
finite number of {\em regions}. We have shown that 
suitable disciplines of region {\em usage} and region {\em stratification}
allow to regain  {\em confluence} and {\em termination}, respectively.

Beyond these crucial properties, we hope to show in future 
work that other interesting properties of the functional core can be extended
to the considered framework. We think in particular of
the construction of denotational models (see, {\em e.g}, \cite{Bierman95})
and of bounds on the computational complexity of typable  programs 
(see, {\em e.g.}, \cite{Girard98}).


{\footnotesize
\paragraph{Acknowledgements}
The first author was partially supported by ANR-06-SETI-010-02 and the second and
third authors by ANR-08-BLANC-0211-01.}

{\footnotesize

\begin{thebibliography}{99}

\bibitem{Amadio09}
R.M.~Amadio.
\newblock On stratified regions.
\newblock In Proc. {\em APLAS}, Springer LNCS (to appear), 2009.
\newblock Extended version available as {\sf arXiv:0904.2076v2}.

\bibitem{Barber96}
A.~Barber.
\newblock Dual intuitionistic linear logic.
\newblock {\em University of Edinburgh}, Technical report
ECS-LFCS-96-347, 1996.

\bibitem{BBPH93}
N.~Benton, G.~Bierman, V.~de~Paiva and M. Hyland.
\newblock A Term Calculus for Intuitionistic Linear Logic.
\newblock In Proc. {\em Typed Lambda Calculi and Applications}, 
Springer LNCS 664:75-90, 2003.

\bibitem{Benton94}
N.~Benton.
\newblock A mixed linear and non-linear logic; proofs, terms and models.
\newblock In Proc. {\em Computer Science Logic}, 
Springer LNCS 933:121-135, 2004.


\bibitem{Bierman95}
G.~Bierman.
\newblock What is a categorical model of intuitionistic linear logic?
\newblock In Proc. {\em Typed Lambda-Calculi and Applications},
\newblock Springer LNCS 902:78-93, 1995.

\bibitem{Boudol07} 
G.~Boudol.
\newblock Typing termination in a higher-order concurrent imperative 
language.
\newblock In Proc. {\em CONCUR}, Springer LNCS 4703:272-286, 2007.

\bibitem{FMA06}
M.~Fluet, G.~Morrisett, and A.~Ahmed.
\newblock Linear Regions Are All You Need. 
\newblock In Proc. {\em ESOP}, Springer LNCS 3924: 7-21, 2006.


\bibitem{GMP89}
A.~Giacalone, P.~Mishra, and  S.~Prasad.
\newblock 
FACILE: A Symmetric Integration of Concurrent and Functional Programming. 
\newblock In Proc. {\em TAPSOFT}, Springer LNCS 352:184-209, 1989.

\bibitem{Girard87}
J.-Y. Girard.
\newblock Linear Logic. 
\newblock {\em Theoretical Computer Science}, 50(1):1-102, 1987. 

\bibitem{Girard91}
J.-Y. Girard.
\newblock On the unity of logic.
\newblock {\em Ann. Pure Appl. Logic}, 59(3):201-217, 1993.

\bibitem{Girard98}
J.-Y. Girard.
\newblock Light Linear Logic. 
\newblock {\em Information and  Computation}, 143(2): 175-204, 1998.

\bibitem{IK05}
A.~Igarashi and N.~Kobayashi.
\newblock Resource usage analysis. 
\newblock {\em ACM Trans. Program. Lang. Syst.} 27(2): 264-313, 2005.

\bibitem{K02}
N.~Kobayashi.
\newblock Type systems for concurrent programs.
\newblock In Proc. {\em 10th Anniversary Colloquium of UNU/IIST}, 
Springer LNCS 2757:439-453, 2003.

\bibitem{KPT99}
N.~Kobayashi, B.~Pierce, and  D.~Turner. 
\newblock Linearity and the pi-calculus.
\newblock {\em ACM Trans. on Program. Lang. and Systems},
21(5):914-947, 1999.


\bibitem{LG88}
J.~Lucassen and D.~Gifford.
\newblock Polymorphic effect systems.
\newblock In Proc. {\em ACM-POPL}, pp 47-57, 1988.


\bibitem{MOTW95}
J.~Maraist, M.~Odersky, D.~Turner, and  Ph.~Wadler.
\newblock Call-by-Name, Call-by-Value, Call-by-Need, and the Linear Lambda Calculus.
\newblock In Proc. {\em Mathematical Foundations of Programming Semantics},  
Elect. Notes in Comp. Sci. 1(1), Elsevier, 1995.

\bibitem{Plotkin93}
G.~Plotkin.
\newblock Type theory and recursion.
\newblock In Proc. {IEEE-LICS}, Abstract, 1993.

\bibitem{Reppy91}
J.~Reppy.
\newblock CML: A higher-order concurrent language.
\newblock In Proc. {\em ACM-SIGPLAN Conf. on Prog. Language Design and Implementation}, 
pp 293-305, 1991. 

\bibitem{S06}
D.~Sangiorgi.
\newblock Termination of processes.
\newblock {\em Math. Struct. in Comp. Sci.},
16:1-39, 2006.

\bibitem{TT97}
M.~Tofte and J.-P.~Talpin.
\newblock Region-based memory management. 
\newblock {\em Information and Computation}, 132(2): 109-176, 1997.


\bibitem{Wadler93}
Ph. Wadler.
\newblock A Taste of Linear Logic. 
\newblock In Proc. {\em Mathematical Foundations of Computer Science},
Springer LNCS 711:185-210, 1993.


\bibitem{Walker05} 
D.~Walker.
\newblock Substructural type systems.
\newblock Chapter 1 of {\em Advanced topics in types and programming languages},
B. Pierce (ed.), MIT Press, 2002.

\bibitem{WW01}
D.~Walker and K.Watkins.
\newblock On Regions and Linear Types. 
\newblock In Proc. {\em Int. Conf. on Fun. Prog.}, pp 181-192,2001.

\bibitem{YBH04} 
N.~Yoshida, M.~Berger, and K.~Honda.
\newblock Strong normalisation in the -calculus. 
\newblock {\em Information and Computation}, 191(2):145-202, 2004.


\end{thebibliography}}

\newpage
\appendix

\section{Proofs}\label{appendix-proof}

\subsection{Proof of theorem \ref{sub-red-thm}}

\begin{lemma}[weakening]
  \label{weak-lem}
  If  and  then .
\end{lemma}
\Proof
  By induction on the typing of . Following table
\ref{air-system}, there are 14 rules to be considered of which 
we highlight 3.

\begin{description}

\item[] We have:
    
We notice that the composition operation  on contexts is
associative and commutative (when it is defined) and that 
 entails that 
. 
Hence, by induction hypothesis, we get 
    , 
    from which we derive:
    


\item[]  We have:
    
    We can always decompose  as  and 
     as  so that 
     and 
     .
    By induction hypothesis, we have .
    We notice that  and 
     
    (remember that  is undefined). Hence 
    we derive:
    

\item[] We have:
    
    By induction hypothesis, we have , from which we derive:
    
We notice that this argument still holds when introducing 
the restriction   in order to guarantee confluence
(cf. table \ref{rules-confluence}). Indeed, the restriction 
 is equivalent to require that the
usage of the region  ranges in the family of usages
. \qed
  \end{description}



\begin{lemma}[affine substitution lemma] \label{aff-sub-lem}
  If ,
     ,  and 
      then 
     .
\end{lemma}
\Proof
  By induction on the typing  of . We highlight 
  4 cases out of 14.

  \begin{description}

  \item[] We have:
    

Because  is an affine hypothesis, it can occur 
exclusively either in  or in . We consider both cases.
    \begin{enumerate}

   \item  and  with .
      By induction hypothesis we have . Plus  so , hence . Then we derive:
      

\item  with  and
  .

By induction hypothesis we have . Plus 
so , hence . Then we derive:
      
    \end{enumerate}


    \item[] We have:
      
      We deduce that , hence  and . By lemma \ref{weak-lem}, we get . \\


  \item[] Renaming  so that , we have:
    
    As in the case of application, we distinguish two cases.

    \begin{enumerate}

    \item  and  with .\\
      By induction hypothesis, we have . Plus  so , hence . Then we derive:
      

    \item  with  and .\\
      By induction hypothesis we have . Plus  so , hence . Then we derive:
      
    \end{enumerate}


  \item[] We distinguish two cases. \\

\begin{enumerate}

\item  If  we have:
    
    We deduce that , and by
    induction hypothesis we get , from which we
    derive:
    
    By lemma \ref{weak-lem}, 
we obtain .
    
\item    If  then ,
    , and . Moreover  must be a variable, 
thus we can derive:
    
    and by lemma \ref{weak-lem} we get . \qed

\end{enumerate}
  \end{description}




\begin{lemma}[intuitionistic substitution lemma]
\label{int-sub-lem}
  If , 
     , and 
      
  then .
\end{lemma}
\Proof
  By induction on the typing of . We highlight 4 cases out of 14.

  \begin{description}

  \item[] We have:
    
    We distinguish 3 cases.
    \begin{enumerate}

    \item 
 and 
 with .\\
     By induction hypothesis we have . Plus
      so , hence
     . Then we derive:
      

    \item 
 with  and 
.\\
      By induction hypothesis we have . Plus  so , hence . Then we derive:
      
    \item 
 and 
.\\ 
By induction hypothesis we have
       and . Moreover we have:
      
      where  and .
Hence we know that all the hypotheses of  and  are of
weakened regions and variables. Thus we also have  and
. Plus from  we get  and
, and we can derive:
      
      By lemma \ref{weak-lem} we obtain .
    \end{enumerate}


\item[] Suppose:
        
      And also:
      
      with  and
      . Hence we know that all the
      hypotheses of  and  are of weakened regions and
      variables, such that . By induction hypothesis we get  and we can derive:
        


  \item[] We have:
    
    with . We just spell out the case where  and
    .
By induction hypothesis, we have  and . Moreover we have:
       
where  and . Hence we know that all the hypotheses of  and 
      are of weakened regions and variables. Thus we also have
       and
      . Plus from  we get
       and , and
      we can derive:
      
By lemma \ref{weak-lem}, we obtain .


 \item[] We just look at the case . We
    have:
    
    We deduce that , and by
    induction hypothesis we get , from which we
    derive:
     \qed
\end{description}




\begin{lemma}[structural equivalence preserves typing] \label{sub-red-equ}
If  and  then .
\end{lemma}
\Proof
Recall that structural equivalence is the least equivalence
relation induced by the equations stated in 
table \ref{op-sem} and closed under static contexts.
Then we proceed by induction on the proof of structural equivalence.
This is is mainly a matter of reordering the pieces of the typing
proof of  so as to obtain a typing proof of .
\qed



\begin{lemma}[evaluation contexts and typing]  \label{eva-sub-lem}
Suppose that in the proof of  
we prove . Then replacing  with a 
 such that , we can still derive
.
\end{lemma}
\Proof
By induction on the structure of .
\qed


\begin{lemma}[functional redexes]\label{fun-redex}
If  where 
 has the shape  or  then
.
\end{lemma}
\Proof
If  we appeal to the affine substitution
lemma \ref{aff-sub-lem} and if  we rely on the
intuitionistic lemma \ref{int-sub-lem}. This settles the case
where the evaluation context  is trivial. If it is complex
then we also need  lemma \ref{eva-sub-lem}.
\qed


\begin{lemma}[side-effects redexes]\label{side-eff-redex}
If  where
 is one of the programs on the left-hand
side then  where
 is the corresponding program on the right-hand side:

\end{lemma}
\Proof
We proceed by case analysis.

\begin{enumerate}


\item Suppose we derive  from
.
By the typing rule for  we know that 
, ,
, and
.
It follows that .
We can decompose  into an additive part 
 and a multiplicative one 
.
Then from ,
we can derive , where
.


\item Suppose we derive  from
.
By the typing rule for  we know that 
, ,
, and
.
It follows that .
Then we reason as in the previous case.


\item Suppose  is derived from
, that ,
and that .
Then , by weakening.
Also, let  be the region associated with the address . We know
that  and that  must have a reading usage on .
It follows that  and therefore the context
 {\em cannot} contain a sub-context of the shape . 
Thus from    we
can derive .

\item  Suppose  is derived from
, 
that ,
and that .
By the promotion rule,  is a weakening of 
 such that  and 
. 
Then from  we can derive
 where  is a
weakening of 
.\qed

\end{enumerate}





\begin{theorem}[subject reduction]
  If  and   then 
  .
\end{theorem}
\Proof
We recall that  means that 
 is structurally equivalent to a program
 where  is a static context,  
is one of the programs on the left-hand side of the
rewriting rules specified in table \ref{op-sem},
 is the respective program on the right-hand side,
and  is syntactically equal to .

By lemma \ref{sub-red-equ}, we know that 
.
This entails that  for
suitable .
By lemmas \ref{fun-redex} and \ref{side-eff-redex}, we derive that
.
Then by induction on the structure of  we argue 
that . \qed



\subsection{Proof of theorem \ref{termination-thm}}
Table \ref{summary1} summarizes the main syntactic categories and
the reduction rules of the intuitionistic system. 
It is important to notice that in the intuitionistic system
regions are terms and that the operations that manipulate the store
operate directly on the regions so that we write:
, , and  rather than
, , and . 

\begin{table}
{\footnotesize
\begin{center}
{\sc Syntax: terms}
\end{center}

\begin{center}
{\sc Operational semantics}
\end{center}


\begin{center}
{\sc Syntax: types and contexts}
\end{center}
}
\caption{Intuitionistic system: syntactic categories and operational semantics}\label{summary1}
\end{table}


Table \ref{summary2} summarizes the typing rules for the 
stratified type and effect system.

\paragraph{Proviso}
To avoid confusion, in the following we write  for provability 
in the affine-intuitionistic system and  for provability
in the intuitionistic system. \\


\begin{table}
{\footnotesize
\begin{center}
\mbox{{\sc Stratified region contexts and types}}  \\
\end{center}
}
\caption{Intuitionistic system: stratified types and effects}\label{summary2}
\end{table}

The translation acts on typable programs.  In order to define it, it
is useful to go through a phase of {\em decoration} which amounts to label
each occurrence (either free or bound) of a variable  of region 
type  with the region .  
For instance,  suppose  and
suppose we have a provable judgement:

Further suppose in the proof the variable  relates to the region  for .
Then the decorated term is:

The idea is that the translation of a
decorated variable  is simply the region  so that in the previous
case we obtain the following term of the intuitionistic system:

Note that in the translation the 's disappear while the 
's and 's are simulated by the intuitionistic
's. 

Assuming the decoration phase, the forgetful translation  is defined
in table \ref{forget-translation}.


\begin{lemma} 
The forgetful translation preserves provability
in the following sense:

\begin{enumerate}

\item If  then .

\item If  then .

\item If  then .

\item If  then
.

\item If  then
.

\item If  
then .

\item If  (and  has
been decorated) then
.
\end{enumerate}
\end{lemma}
\Proof
By induction on the provability relation .

Concerning the rules for types and region contexts formation and for subtyping,
the forgetful translation provides a one-to-one mapping 
from the rules of the affine-intuitionistic system to the
rules of the intuitionistic one (the only exception are the rules
for  which become trivial in the intuitionistic framework).
Also note that . 
With these remarks in mind, the proof of (1-5) is 
straightforward.

The proof of (6) follows directly from (2). We just
notice that the forgetful translation of a context  
eliminates all the variable associated with  region types.
The point is that if these variables occur in the program
they will decorated and therefore in the translation they will be replaced
by regions, {\em i.e.}, constants.

In the proof of (7), it is useful to make a few preliminary remarks.
First, {\em weakening} is a derived rule for the intuitionistic system,
so that if we can prove  and 
 then we can
prove  too.
Second, if  is defined then 
.
The proof is then a rather direct induction on the provability
relation . 
When we discharge an assumption and when we introduce a formal
parameter with  or with  we must distinguish
the situation where the variable under consideration has region
type, say, . In this case the variable does not occur in the
translation of the related context  and
it is replaced in the term by the region .
\qed \\

Next we want to relate the reduction of a program and of its
translation. As already mentioned, in the intuitionistic system all stores are persistent.
Consequently, a reduction such as:

might be simulated by 

In other terms, the translated program may contain more values in
the store than the source program. 
To account for this, we introduce a `simulation' relation  indexed on  a pair
 such that  and  is just composed of
variables of region type:


\begin{lemma}[simulation]\label{simulation-lemma}
If  and  then
 and .
\end{lemma}
\Proof
Suppose .
Then .
Also if  then  by 
subject reduction of the affine-intuitionistic system
(incidentally, subject reduction holds for the intuitionistic 
system too \cite{Amadio09}).

By definition  means that  is structurally
equivalent to a process  which can be decomposed 
in a static context  and a {\em redex}  of the
shape described in table \ref{op-sem}.

We notice that the forgetful translation preserves structural equivalence,
namely if  then .
Indeed, the commutativity and associativity rules of the affine-intuitionistic
system match those of the intuitionistic system while the rules for commuting
the 's are `absorbed' by the translation. For instance,

with  not free in .

We also remark that the forgetful translation can be extended to static and evaluation contexts
simply by defining . Then we note that
the translation of a static (evaluation) context is an 
intuitionistic static (evaluation) context. In particular, this holds
because the translation of a value is still a value.

Following these remarks, we can derive that .
Thus it is enough to focus on the redexes  and show that each reduction
in the affine-intuitionistic system is mapped to a reduction in the intuitionistic one 
and that the resulting program is still related to the program  via the
relation . 

To this end, we notice that the translation commutes with the substitution
so that . This is a standard argument,
modulo the fact that the variable of region type have to be given a special treatment.
For instance, we have:

Then one proceeds by case analysis on the redex .
Let us look at two cases in some detail.
If  then 

On the other hand if  then

Notice that in this case we have an additional store  which
is the reason why in the definition of the relation  
we relate a program to its translation in parallel with some additional store.
\qed


\begin{theorem}[\cite{Amadio09}]\label{thm-ter-intuitionistic}
If  then all reductions starting from  terminate.
\end{theorem}


\begin{corollary}[termination]
If  then all reductions starting from  terminate.
\end{corollary}
\Proof
By contradiction. 
We have  and 
.
If there is an infinite reduction starting from 
then the simulation lemma \ref{simulation-lemma}
entails that there is an infinite reduction starting
form . 
And this contradicts the termination of the intuitionistic system
(theorem \ref{thm-ter-intuitionistic}).  \qed


\end{document}
