\documentclass[twoside,leqno,twocolumn]{article}
\usepackage{ltexpprt}

\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}

\setlength\tabcolsep{4pt}

\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{graphicx}
\usepackage{textgreek}
\usepackage{microtype}

\usepackage{url}


\newcommand{\set}[1]{\ensuremath{\{ #1 \}}}
\newcommand{\abs}[1]{\ensuremath{\lvert #1 \rvert}}
\newcommand{\Oh}[1]{\ensuremath{\mathsf{O}\!\left( #1 \right)}}
\newcommand{\oh}[1]{\ensuremath{\mathsf{o}\!\left( #1 \right)}}

\newcommand{\baseA}{\mathtt{A}}
\newcommand{\baseC}{\mathtt{C}}
\newcommand{\baseG}{\mathtt{G}}
\newcommand{\baseT}{\mathtt{T}}
\newcommand{\baseN}{\mathtt{N}}
\newcommand{\dnacomp}[1]{\ensuremath{\overline{#1}}}
\newcommand{\revcomp}[1]{\ensuremath{\overleftarrow{#1}}}

\newcommand{\rank}{\ensuremath{\mathsf{rank}}}
\newcommand{\select}{\ensuremath{\mathsf{select}}}
\newcommand{\LF}{\ensuremath{\mathsf{LF}}}
\newcommand{\find}{\ensuremath{\mathsf{find}}}
\newcommand{\locate}{\ensuremath{\mathsf{locate}}}
\newcommand{\parent}{\ensuremath{\mathsf{parent}}}
\newcommand{\countq}{\ensuremath{\mathsf{count}}}

\newcommand{\gindegree}{\ensuremath{\mathsf{in}}}
\newcommand{\goutdegree}{\ensuremath{\mathsf{out}}}
\newcommand{\glabel}{\ensuremath{\mathsf{label}}}
\newcommand{\gpred}{\ensuremath{\mathsf{pred}}}
\newcommand{\gkey}{\ensuremath{\mathsf{key}}}
\newcommand{\gvalue}{\ensuremath{\mathsf{value}}}
\newcommand{\gnode}{\ensuremath{\mathsf{node}}}
\newcommand{\gext}{\ensuremath{\mathsf{ext}}}

\newcommand{\kmer}[1]{\nobreakdash-mer}
\newcommand{\kcollection}[1]{\nobreakdash-collection}
\newcommand{\kequivalent}[1]{\nobreakdash-equivalent}
\newcommand{\orderk}[1]{order\nobreakdash-}
\newcommand{\LFmapping}{LF\nobreakdash-mapping}
\newcommand{\FMindex}{FM\nobreakdash-index}
\newcommand{\patternset}{\ensuremath{(\Sigma \setminus \set{\#, \kkX(A|B|C)YkS[0, n-1] = s_{0} \dotsm s_{n-1}\abs{S} = n\Sigma = \set{0, \dotsc, \sigma - 1}T[0, n-1]T[n-1] = \ not found anywhere else in the text. A \emph{substring} of string  is a sequence of the form . We call substrings of the type  and  \emph{prefixes} and \emph{suffixes}, respectively, and refer to substrings of length  as \kmer{k}s. Substring  is a \emph{proper} substring of string , if . We say that string  is a substring of string collection , if it is a substring of a string .

Sometimes we consider \emph{infinite} character sequences , where set  is a contiguous infinite subset of . The notion of substring generalizes to infinite sequences in a natural way. A substring of an infinite sequence  is \emph{left-infinite} if it extends infinitely to the left, and \emph{right-infinite} if it extends infinitely to the right. A substring of a finite or infinite sequence  is \emph{left-maximal} if it is left-infinite or a prefix, and \emph{right-maximal} if it is right-infinite or a suffix.

We are primarily interested in sequences over the \emph{DNA} alphabet , \baseA, \baseC, \baseG, \baseT, \baseN}\baseA\baseC\baseG\baseT\baseN\.

Given a string , we define  as the number of occurrences of character  in the prefix . We also define

as the position of the occurrence of character  with rank .\footnote{These definitions are used in the SDSL library \cite{Gog2014b}. We assume for convenience that .} A \emph{bitvector} is a binary sequence supporting efficient / queries. \emph{Wavelet trees} \cite{Grossi2003} are space-efficient data structures that use bitvectors to support / queries on arbitrary strings.

Let  be a string and  be a string or an infinite character sequence over alphabet . We say that sequences  and  \emph{prefix-match}, if  is a prefix of  or  is a prefix of . Set  of strings is \emph{prefix-free}, if no two strings  (with ) prefix-match.

\subsection{Text Indexes}

The \emph{suffix tree} \cite{Weiner1973} is the most fundamental full-text index supporting substring queries. It is formed by taking the suffixes of the text, storing them in a trie, and compacting unary paths in the trie into single edges. Although fast and versatile, suffix trees are impractical with large texts, as they require much more space than the text itself.

\emph{Suffix arrays} (SA) \cite{Manber1993} were introduced as a space-efficient alternative to the suffix tree. The suffix array of text  is an array of pointers  to the suffixes of the text in \emph{lexicographic order}. We find the occurrences of \emph{pattern} string  in the text in  time by using \emph{binary search} in the suffix array. The suffix array requires  bits of space in addition to the text, while its functionality is more limited than that of the suffix tree. See Figure~\ref{figure:indexes} for an example of the suffix array and related structures.

\begin{figure}
\includegraphics{gcsa2_text_indexes.pdf}
\caption{\protect\LFmapping, BWT, suffix array, and LCP array for text T[0, n-1]\BWT[0, n-1]\BWT[i] = T[(\SA[i]-1) \bmod n]iT[\SA[i], n-1]T[(\SA[i]-1) \bmod n, n-1]\Carray[c]c' < c\SA[\LF(i)] = (\SA[i]-1) \bmod nc \in \SigmaXiS'TS' < X\LF(i, c)S'S' < cX\rank\select\CarrayXXX[i+1, \abs{X}-1]\SA[sp, ep]X[i, \abs{X}-1]\SA[\LF(sp, X[i]), \LF(ep+1, X[i]) - 1]\Oh{\abs{X}}\rank\SA[i]\LF(i)\SA[\LF^{k}(i)]d\Oh{d}d'\set{0, \dotsc, n-1}X\Oh{\abs{X}+d'}\LCP[0, n-1]\LCP[i]T[\SA[i-1], n-1]T[\SA[i], n-1]\LCP[0] = 0G = (V, E)V = \set{0, \dotsc, \abs{V}-1}E \subseteq V \times V(u, v) \in Euv(u, v) \ne (v, u)u \ne vG.\gindegree(v)vvG.\goutdegree(v)v\Sigmav \in VG.\glabel(v) \in \SigmaP = v_{0} \dotsm v_{\abs{P}-1}(v_{i}, v_{i+1}) \in E0 \le i < \abs{P}-1v_{0}v_{\abs{P}-1}PG.\glabel(P) = G.\glabel(v_{0}) \dotsm G.\glabel(v_{\abs{P}-1})0stG.\glabel(s) = \#G.\glabel(t) = \.
\end{Definition}

\begin{Definition}[de~Bruijn graph]
Let , and let  be a \kcollection{k}. The \orderk{k} \emph{de~Bruijn graph} of  is a graph  such that
\begin{itemize}
\item each node  represents a distinct \kmer{k}  occurring in , with ;
\item each node  has a \emph{key} ; and
\item each edge  represents a \kmer{(k+1)}  occurring in .
\end{itemize}
We use  as the source node  and ^{k}t(t, s)k+1\BWTk0^{k-1} 1\bvINi\BWT[\bvIN.\select(i, 1) + 1, \bvIN.\select(i + 1, 1)]\BWT\bvIN\bvOUT\bvIN\select\bvIN\BWT\rank\bvOUTG = (V, E)v_{0} \in VP = v_{0} \dotsm v_{\abs{X}-1}XPG.\glabel(P) = X(X, V_{X})X \in \Sigma^{k}V_{X} \subseteq VkkG = (V, E)\mathcal{S}S \in \mathcal{S}P = (v_{i})_{i \in Z}\mathcal{S}.\gnode(S, i) = v_{i}i \in Z\mathcal{S}\#\
\set{ \mathcal{S}.\gnode(S, i) \mid S \in \mathcal{S}, S[i, i+k-1] = G'.\gkey(v)}.

[sp_{in}, ep_{in}] = [&\bvIN.\select(sp_{i+1}, 1) + 1, \\
 & \bvIN.\select(ep_{i+1}+1, 1)]; \\
[sp_{out}, ep_{out}] = [&\LF(sp_{in}, X[i]), \\
 & \LF(ep_{in}+1, X[i]) - 1]; \\
[sp_{i}, ep_{i}] = [&\bvOUT.\rank(sp_{out}, 1), \\
 & \bvOUT.\rank(ep_{out}, 1)].

sp_{out} & = C[X[i]] + B_{X[i]}.\rank(sp_{i+1}, 1); \\
ep_{out} & = C[X[i]] + B_{X[i]}.\rank(ep_{i+1}+1, 1) - 1; \\
[sp_{i}, ep_{i}] & = [\bvOUT.\rank(sp_{out}, 1), \bvOUT.\rank(ep_{out}, 1)].
) are compressed as sparse bitvectors \cite{Okanohara2007}.

We used a system with two 16\nobreakdash-core AMD Opteron 6378 processors and 256~gigabytes of memory for the experiments, and stored all files on a distributed Lustre file system. The system was running Ubuntu~12.04 on Linux kernel~3.2.0. We used vg version~1.3.0 for processing the graphs and GCSA2 version~0.8 using SDSL version~2.1.1 for the benchmarks. All code was compiled with gcc/g++ version~4.9.2.

\subsection{Construction}

\emph{Variation graphs}, as defined in vg, use strings as node labels. A node can be traversed in both forward and reverse complement orientations, and edges may cross between the orientations. For indexing, the graph is implicitly converted into an input graph with single-character labels. We always sample the input graph nodes corresponding to the initial offsets of variation graph node labels.

We built vg graphs from the human reference genome (GRCh37) and 1000~Genomes Project variation \cite{1000GP2015}. To avoid excessive growth, we removed paths where \kmer{16}s crossed more than  nontrivial edges with \texttt{vg mod -p -l -e 4}, and subgraphs shorter than  bases with \texttt{vg mod -S -l 100}. We extracted all paths of length  from the forward strand of the graph. There were a total of 4.80~billion paths with 1.53~billion distinct labels. We then built GCSA with 1\nobreakdash--3 doubling steps, producing \orderk{32}, \orderk{64}, and \orderk{128} indexes.

Tables~\ref{table:construction} and \ref{table:indexes} show construction requirements and index sizes, respectively. We can build a whole-genome index overnight using less than 96~gigabytes of memory, including disk cache. The index contains ~billion \kmer{k}s, but the path graph only uses 4.4\nobreakdash--5.7~billion nodes to represent them. For , GCSA2 requires 0.63~bits per \kmer{k}, out of which 0.28~bits is used for the path graph. Extensions based on suffix trees increase the size to 1.08~bits per \kmer{k}.

\begin{table}
\begin{center}
\begin{tabular}{c|ccc|cc}
\hline
 & \textbf{Time} & \textbf{Memory} & \textbf{Disk} & \textbf{Read} & \textbf{Write} \\
\hline
 32 & 7.44 h & 59.8 GB & 387 GB & 1.37 TB & 0.88 TB \\
 64 & 10.4 h & 51.9 GB & 415 GB & 2.03 TB & 1.51 TB \\
128 & 14.1 h & 52.3 GB & 478 GB & 2.78 TB & 2.25 TB \\
\hline
\end{tabular}
\caption{GCSA2 construction. Order of the path graph; construction time in hours; peak memory and disk usage in gigabytes; and disk I/O volume for reading and writing in terabytes.}\label{table:construction}
\end{center}
\end{table}

\begin{table*}[t]
\begin{center}
\begin{tabular}{c|cc|c|c|c}
\hline
 & \textbf{\kmer{k}s} & \textbf{Nodes} & \textbf{Graph} & \textbf{Index} & \textbf{With extensions} \\
\hline
 32 & 6.20G & 4.37G & 2.89 GB / 4.00 bits & 9.50 GB / 13.2 bits & 13.2 GB / 18.2 bits \\
 64 & 16.7G & 5.24G & 3.46 GB / 1.78 bits & 8.64 GB / 4.46 bits & 13.6 GB / 6.99 bits \\
128 &  116G & 5.73G & 3.78 GB / 0.28 bits & 8.58 GB / 0.63 bits & 14.6 GB / 1.08 bits \\
\hline
\end{tabular}
\caption{GCSA2 index sizes. Order of the path graph; number of \kmer{k}s and nodes in the path graph in billions; index size in gigabytes and in bits per \kmer{k} for the graph ( and ), the index (the graph, , , and ), and the index with the extensions from Appendix~\ref{appendix:extensions}.}\label{table:indexes}
\end{center}
\end{table*}

Index construction uses more memory with  than with larger values of . The \orderk{32} path graph has more nodes, where we cannot derive the values from the predecessor node. As we sample more values, we need more memory in the final phase of construction. With larger values of , the path graph resembles the input graph better, and we sample less values. For the same reason, index size decreases with larger values of , even though the graph requires more space.

\subsection{Queries}

We compared the query performance of the \orderk{128} GCSA2 to several FM-indexes for the reference sequence. SSA is the SDSL implementation (\texttt{csa\_wt<>}) of the \emph{succinct suffix array} \cite{Maekinen2005}, using a Huffman-shaped wavelet tree on top of the BWT. As the default FM-index in SDSL, it prioritizes query performance over compression. We used SSA with SA sample period 17 for good  performance. BWA is the FM-index in the \emph{Burrows-Wheeler Aligner} \cite{Li2009} (version~0.7.15 with the default SA sample period 32). Optimized for DNA sequences, BWA indexes both the reference and its reverse complement.

As building the original GCSA requires around  bytes of memory for a path graph with  nodes, we could not compare GCSA and GCSA2 directly on a system with 256~gigabytes of memory. Instead, we used \emph{RLCSA} \cite{Maekinen2010} (May~2016 version) as a proxy. The RLCSA is an FM-index for repetitive sequence collections using the same basic components as the original GCSA. Under a mixed query load, RLCSA with SA sample period 32 is 1.5x to 3x faster than GCSA, depending on algorithmic overhead and the mix of  and  queries \cite{Siren2014}.

We extracted \kmer{k}s for  from the (non-pruned) vg graphs by using \texttt{vg sim}, filtered out \kmer{k}s consisting entirely of s, and queried for the remaining \kmer{k}s using a single thread. The results can be seen in Table~\ref{table:benchmark}.

\begin{table*}[t]
\begin{center}
\begin{tabular}{cc|cccc|cccc}
\hline
 & \textbf{Patterns} & \textbf{Index} & \textbf{Found} & \textbf{Nodes} & \textbf{Occs} &  &  &  &  \\
\hline
 16 & 351584 & GCSA2 & 347453 & 2477M &  872M & 4.75 \textmu{}s & 0.42 \textmu{}s & 0.87 \textmu{}s & 5.85 \textmu{}s \\
    &        & SSA   & 301538 &    -- &  782M & 6.00 \textmu{}s &              -- &              -- & 2.43 \textmu{}s \\
    &        & BWA   & 320764 &    -- & 1564M & 3.64 \textmu{}s &              -- &              -- & 4.65 \textmu{}s \\
    &        & RLCSA & 301538 &    -- &  782M & 23.7 \textmu{}s &              -- &              -- & 8.12 \textmu{}s \\
\hline
 32 & 351555 & GCSA2 & 333258 &  112M & 34.3M & 10.8 \textmu{}s & 0.28 \textmu{}s & 0.38 \textmu{}s & 5.44 \textmu{}s \\
    &        & SSA   & 153957 &    -- & 26.6M & 10.9 \textmu{}s &              -- &              -- & 2.16 \textmu{}s \\
    &        & BWA   & 156080 &    -- & 52.9M & 6.57 \textmu{}s &              -- &              -- & 3.19 \textmu{}s \\
    &        & RLCSA & 153957 &    -- & 26.6M & 47.6 \textmu{}s &              -- &              -- & 5.87 \textmu{}s \\
\hline
  64 & 351567 & GCSA2 & 326101 & 2.63M & 1.35M & 22.5 \textmu{}s & 0.26 \textmu{}s & 0.29 \textmu{}s & 2.92 \textmu{}s \\
     &        & SSA   &  88184 &    -- & 0.84M & 17.1 \textmu{}s &              -- &              -- & 1.89 \textmu{}s \\
     &        & BWA   &  88786 &    -- & 1.60M & 10.3 \textmu{}s &              -- &              -- & 2.34 \textmu{}s \\
     &        & RLCSA &  88184 &    -- & 0.84M & 74.3 \textmu{}s &              -- &              -- & 5.97 \textmu{}s \\
\hline
 128 & 351596 & GCSA2 & 316500 & 0.32M & 0.37M & 45.3 \textmu{}s & 0.26 \textmu{}s & 0.26 \textmu{}s & 3.13 \textmu{}s \\
     &        & SSA   &  35678 &    -- & 0.08M & 23.5 \textmu{}s &              -- &              -- & 3.47 \textmu{}s \\
     &        & BWA   &  35741 &    -- & 0.12M & 14.0 \textmu{}s &              -- &              -- & 3.46 \textmu{}s \\
     &        & RLCSA &  35678 &    -- & 0.08M & 91.7 \textmu{}s &              -- &              -- & 12.9 \textmu{}s \\
\hline
\end{tabular}
\caption{Query benchmarks using an \orderk{128} GCSA2 and various FM\nobreakdash-indexes. Pattern length; number of patterns; index type; number matching patterns, matching nodes, and distinct occurrences; average time for , , and  queries in microseconds; and average time per value for  queries in microseconds.}\label{table:benchmark}
\end{center}
\end{table*}

Backward searching in an FM-index stops early if there are no matches. In order to compare the  performance of the indexes reliably, we must hence concentrate on the \kmer{16}s, where the fraction of matching patterns is similar for all indexes. GCSA2 and the fast FM-indexes (SSA and BWA) all have similar performance, while RLCSA is several times slower. As a result, we can estimate that  queries in GCSA2 are an order of magnitude faster than in GCSA.

When comparing the  performance of different FM-indexes, the distribution of the query positions should be close to uniform. Otherwise the biases from e.g.~different suffix array sampling strategies or the variation in the number of distinct occurrences per node in GCSA2 can make the results unreliable. As the \kmer{k}s have been sampled uniformly from the variation graph, we get the best results with the \kmer{16}s, where all indexes can match most of the patterns.

GCSA2 uses denser SA sampling than the other indexes, with effective sample period 10.6. On the average, GCSA2 calls  for 2.84~nodes per distinct value, making the amount of work comparable to sample period 30.2. SSA with sample period 17 is 2.4x faster than GCSA2, mostly because it has to do less work. BWA with sample period 32 is closer to GCSA2 in  performance. RLCSA is slower than the other indexes, but the difference is smaller than with  queries due to the optimizations for retrieving suffix array ranges. Assuming that  queries are 3x slower in GCSA than in RLCSA, as GCSA does not use the optimizations, we can estimate that GCSA2 is 4x faster than GCSA.

The remaining queries,  and , take a fraction of a microsecond. As a  query takes comparable time to a single step of backward searching, it will not be a bottleneck in finding maximal exact matches. Counting the number of distinct occurrences with a  query is faster than retrieving even a single occurrence.


\section{Discussion}

GCSA2 is a path index for variation graphs. It uses a de~Bruijn graph as a \kmer{k} index of the variation graph, prunes it by merging redundant subgraphs, and encodes the result with a generalization of the FM\nobreakdash-index. The index supports queries of length up to  exactly, and longer queries with false positives. GCSA2 also includes extensions based on suffix trees; other extensions have been considered but not implemented (see Appendix~\ref{appendix:hypertext}). The index is used in the variation graph toolkit vg for e.g.~read alignment based on maximal exact matches.

We can build a whole-genome index overnight on a system with 96~gigabytes of memory and a few hundred gigabytes of fast disk space. The resulting index takes less than 15~gigabytes, or 1.08~bits per \kmer{k} for the \orderk{128} index with extensions. Query performance is comparable to that of fast FM-indexes for sequences.

The primary design goals for GCSA2 were query performance and index size. The index works with arbitrary graphs, supports queries that are long enough to map short reads in one piece without false positives, and provides several options for dealing with complex regions. Other path indexes work with a more restricted class of graphs \cite{Siren2014,Huang2013,Kim2015-2016,Maciuca2016}, are at least an order of magnitude slower \cite{Huang2013,Maciuca2016}, require much more space \cite{Bowe2012,Pell2012,Cazaux2014,Marcus2014}, or are theoretical proposals that have never been implemented \cite{Thachuk2013}.

We may want to determine whether a pattern matches known \emph{haplotypes} or only their recombinations. As GCSA2 does not support this directly, vg must determine it afterwards using a separate structure \cite{Novak2016}. The \emph{FM\nobreakdash-index of alignment} \cite{Na2015,Na2016} embeds the haplotypes directly in a GCSA-like index and reports the haplotypes matching the  query. While the solution depends on specific properties of the graph, it could be possible to extend it to work with any GCSA.




\paragraph{Acknowledgements.} The author thanks Erik Garrison, Richard Durbin, and Adam Novak for the fruitful discussions while developing the GCSA2 index.


\appendix
\section{Proofs of Lemmas}\label{appendix:proofs}

\begin{proof}[Lemma~\ref{lemma:pg-fn}: No false negatives]
Let  be the \kcollection{k} used for building the path graph, and let  be a path starting from  with . The collection contains a sequence  such that  and .

For all positions  with , there is a node  with  and .
By definition, path graph  has an edge  for all such positions .
Hence  is a path in  with .
As path  starts from node , node  is included in the set .
Furthermore, .
\end{proof}

\begin{proof}[Lemma~\ref{lemma:pg-context}: Context length]
If , the statement is true by definition for . Now let  be the set of all nodes  such that substring  is a prefix of key , and assume that the set is nonempty.

Consider the set

There is an edge  if and only if key  prefix-matches string . Hence key  prefix-matches string  for all nodes .

Now let  be a node with key  prefix-matching string . If the key is a prefix of string , there is an edge  to all nodes , and hence . Otherwise let  be a substring of the \kcollection{k} used for building the path graph. As , the substring starting at  is represented by a node , and hence .

Set  is the set of all nodes  such that substring  prefix-matches key . If , string  is a proper prefix of key  for all nodes  due to the prefix-free property, and we can set . Otherwise we set  for the only node .
\end{proof}

\begin{proof}[Lemma~\ref{lemma:pg-keys}: Short keys]
(a) If node  has multiple predecessors with label , the keys of the predecessors must be longer than string , as the key set is prefix-free.

(b) By the construction in the proof of Lemma~\ref{lemma:pg-context}, the context length for pattern  in graph  is .
\end{proof}

\begin{proof}[Lemma~\ref{lemma:dbg-fp}: No short false positives]
We may assume without loss of generality that graph  is a de~Bruijn graph. Let  be a node. By Lemma~\ref{lemma:pg-keys}, pattern  prefix-matches key . For every node , there is a substring  in the \kcollection{k}  used for building graph , with . Prefix  of the substring corresponds to a path with label  starting from node  in graph .
\end{proof}

\begin{Definition}[Equivalent paths] ~\\
Let  and  be path graphs of the same graph, and let  and  be paths in graphs  and , respectively. We say that paths  and  are \emph{equivalent}, if for , keys  and  have a common prefix  such that  for all nodes  and  having  as a prefix of their keys.
\end{Definition}

\begin{proof}[Lemma~\ref{lemma:dbg-prune}: Pruning]
Let  be the path graph corresponding to the new key set, let  be the node with key , and let  be the \kcollection{k} used to define the path graphs.

Consider the edge  defined by substring  of . The same substring also defines an edge , where either (a)  or (b)  and , and the same holds for nodes  and . We can hence transform any path in graph  into an equivalent path in graph  by replacing nodes  with node .

Let  be a in graph . We transform it into an equivalent path  in graph . There are two cases for . If , we can replace it with any . Otherwise we use the node  with .

In the general case , assume that we have transformed the suffix  of path  into an equivalent path  in graph . Because , node  must have a predecessor with label . We can choose any such predecessor as node .

Consider the predecessors  and . Their keys prefix-match string . There are three cases:
\begin{enumerate}
\item If  is a prefix of , the key  of every successor  of node  prefix-matches  and hence has  as a prefix. Therefore  is the union of sets  over . If  is also a prefix of , nodes  and  have identical value sets by the same reasoning.

\item If  is a prefix of  and  is a proper prefix of , there is only one possible predecessor . Hence  and .

\item If key  is a proper prefix of string , there is only one possible predecessor . Because key  prefix-matches string , it must also be a proper prefix of the string. Hence either  or  and .
\end{enumerate}
In every case, , and we can use shorter of strings  and  as .

We can transform any path  in graph  into an equivalent path  in graph , and the other way around. Because the labels of equivalent paths and the value sets of their start nodes are identical, we have  for all patterns  with .
\end{proof}

\begin{proof}[Lemma~\ref{lemma:dbg-maximal}: Maximal pruning]
Let  the de~Bruijn graph of graph  with the same order  as graph , and let  be the \kcollection{k} used for building the path graphs. If  is a node, then  for all nodes .

Assume that  for an edge . String  must then be a prefix of key . There cannot be edges  to other nodes , as keys  and  would prefix-match.

Let  be a substring of . Because  is a substring of  and  is a pruned de~Bruijn graph, the set of nodes  over all occurrences of substring  in  is . As node  has no other successors, set  is the union of sets  over all nodes .

The above is true for all . Hence we can prune graph  further using string  as the new key in Lemma~\ref{lemma:dbg-prune}.
\end{proof}


\section{GCSA for Path Graphs}\label{appendix:gcsa2}

Let  be a path graph. We sort the nodes  by their keys in lexicographic order and generate the sequences , , and  from the nodes in that order. For each node , we append  with the predecessor labels  for all edges ;  with the indegree encoded as ; and  with the outdegree as .

If node  has lexicographic rank , the range of incoming edges  to that node is . The labels of the predecessor nodes are encoded in . Sorting the incoming edges by pairs , where  corresponds to edge , is equivalent to sorting them by strings . As multiple edges may have the same sort key, our sorting algorithm must be stable. We get the desired sorting order by using \LFmapping: .

The range of outgoing edges  from node  with lexicographic rank  is . The edges are already sorted by keys . Because graph  is a path graph, we know that key  prefix-matches string . The sorting orders are therefore compatible. For every  for a node , having  for a node  implies an edge .

We use \emph{backward searching} for query . Let  be a pattern. If , query  returns the lexicographic range  containing all nodes. Now assume that  and that . We want to find the lexicographic range , which is the union of sets  over nodes . We map the node range  to the range  of incoming edges; the incoming edges to the corresponding range of outgoing edges ; and the outgoing edges to the range :

We can think this as a generalization of \LFmapping: .

Query  retrieves the values  for nodes  and filters out duplicates. Instead of storing the values explicitly for all nodes, GCSA uses a \emph{sampling} scheme to save space. We assume that the nodes of the input graph  are conveniently chosen integers. If  is the only outgoing edge from node  and the only incoming edge to node , it should be that .

We sample the values  for a node , (a) if there are multiple incoming edges to node ; (b) if  is the source node ; or (c) if  for the only incoming edge . We may also sample the values for some nodes on long unary paths for performance reasons. If the set  has not been sampled, we can derive it from sampled values by following the incoming edges.

If node  with lexicographic rank  has only one predecessor, the lexicographic rank of the predecessor is . If the lexicographic rank  corresponding to node  is the first sampled node we encounter, we know that .

Let  be a bitvector. If we have sampled the values for the node  with lexicographic rank , we mark that as . We can then determine the rank of node  among the sampled nodes as . For each sampled node , we store the size of the value set  in another bitvector , using the same encoding as for bitvectors  and . We store the samples in array  in the same order, using  bits each. The sampled values for node  with rank  among the sampled nodes can be found at .


\section{Index Construction}\label{appendix:construction}

GCSA construction \cite{Siren2014} is based on the \emph{prefix-doubling} algorithm for suffix array construction \cite{Manber1993}. The original GCSA started from paths of length  in the input graph, and then repeatedly \emph{joined} paths of length  into paths of length , until each path had a distinct label. The resulting path graph was essentially an \orderk{\infty} pruned de~Bruijn graph and supported queries of any length.

We use a variant of that algorithm with GCSA2. Let  be the input graph. We extract all paths of length  (typically with ) from graph . For each path , we store several fields. \emph{Key}  encodes  as a sequence of lexicographic ranks of \kmer{k}s. If  is not an integer multiple of , the key consists of the \kmer{k} ranks for the lexicographically smallest \kmer{(\lceil \abs{P}/k \rceil \cdot k)} having  as a prefix, followed by the rank of the last \kmer{k} in the largest such \kmer{(\lceil \abs{P}/k \rceil \cdot k)}. \emph{Value}  is the start node  of the path. We store the set of \emph{predecessor labels}  as . For each possible \emph{extension node} , we create a separate copy of the path and store the node as .

The construction uses several supporting structures. We build an \orderk{k} \emph{de~Bruijn graph}  of the path labels and encode it as a GCSA, using the predecessor labels  for determining the edges. Let  be the nodes of the de~Bruijn graph in lexicographic order by their keys. We use two additional arrays: the \emph{LCP array} , where  is the length of the longest common prefix of keys  and  (with ), and the \emph{last character array} , where . The LCP array is stored as a wavelet tree for fast \emph{range minimum queries} \cite{Gagie2012a}.

Because we store path labels explicitly, we only do a limited number of \emph{doubling steps}, typically  or . After  doubling steps, the length of the paths is , and we can use them to build a maximally pruned \orderk{(2^{d} k)} de~Bruijn graph. Each doubling step consists of a \emph{pruning} step, followed by an \emph{extension} step. The pruning step applies a limited form of Lemma~\ref{lemma:dbg-prune} to lexicographic ranges of paths. Given two paths  and , we can determine the length of the longest common prefix of the path labels by using the keys  and  and the LCP array. If all paths sharing a prefix start from the same node, we merge them into a single path  with  based on the shared prefix and .

The extension step transforms the current set of paths of length (up to)  into a set of paths of length (up to) . If  is a path with , we use it as such. If  for paths  and , we create a new path . We set  according to the concatenation of the path labels, take  and  from path , and take  from path . If we have another path  with  such that  is a path, and if , all possible \kmer{2k'} extensions of label  are also labels of paths starting from node , and the other way around. Hence paths  and  can be represented by a single node in a pruned de~Bruijn graph.

The doubling steps are followed by the \emph{merging step}, which transforms the paths into the nodes of a maximally pruned de~Bruijn graph . We merge the paths with identical keys into the nodes of a pruned de~Bruijn graph . If paths  all have the same key, we create a node  with the shared key as  and with . We also store the union of predecessor labels as . We then apply Lemma~\ref{lemma:dbg-prune} maximally, transforming graph  into graph .

Storing the paths and the graphs may require hundreds of gigabytes of memory when indexing whole-genome variation graphs. To avoid that, we keep them on \emph{disk} when possible. The subgraph corresponding to each chromosome is stored in a separate file, with paths sorted by their labels in lexicographic order. Extension steps are done separately for each of the chromosomes. The pruning step merges the sorted files. It keeps reading paths into a buffer, until it has found a maximal range of paths that can be merged. The merged path is written into the new file for that chromosome, and the original range of paths is removed from the buffer. The merging step works in a similar way.

After creating the nodes  of the maximally pruned \orderk{k'} de~Bruijn graph , we \emph{build the index}. Sequences  and  can be generated from the predecessor sets , while the outdegree sequence  requires further processing. There is an edge  if and only if string  prefix-matches key  and . We determine the edges and produce the outdegree sequence by scanning the node file sequentially with  pointers. The pointer corresponding to node  scans the entire file, while each of the remaining  pointers scans only the range of nodes  with  for a character . We also sample the nodes for  queries during the same scans.

Checking whether key  prefix-matches string  can be done by using the GCSA for de~Bruijn graph  and the last character array . If the lexicographic rank of \kmer{k}  is , the lexicographic rank of \kmer{k}  is . If \kmer{2k}  is encoded with \kmer{k} ranks , we can encode string  as a lexicographic range of \kmer{k} rank sequences, with  as the lower bound and  as the last rank in the upper bound. String  prefix-matches key  if and only if the lexicographic ranges of the \kmer{k} rank sequences overlap.

\emph{Complex regions} of the variation graph must be pruned before indexing. While this happens before index construction begins, the construction algorithm has features that can make the pruning less destructive. Pruning heuristics often create regions that are completely missing from the index. The same mechanism that saves memory by having each chromosome in a separate file can be used to index \emph{overlapping subgraphs} without indexing any paths between them. By having the pruned graph in one file and the reference path in another file, we can guarantee that no region is completely missing from the index. We can also index \emph{selected paths} in complex regions by duplicating nodes for prefix-doubling and mapping the duplicates back to the original nodes during the merging step. If we index the paths corresponding to \emph{known haplotypes} in complex regions, we can guarantee that the index contains all observed variation.


\section{Simplified GCSA Encoding}\label{appendix:encoding}

Let  be a path graph with  for all nodes  and characters . This is true for de~Bruijn graphs, and also for maximally pruned de~Bruijn graphs (Lemmas~\ref{lemma:dbg-maximal} and \ref{lemma:pg-keys}). We can use the simplified encoding of the original GCSA \cite{Siren2014} with such path graphs.

We replace the sequences  and  with \emph{indicator bitvectors}  for all . If node  with lexicographic rank  has a predecessor with label , we set . The backward step becomes:

Two expensive queries ( and ) are replaced with a cheap .

Computing  can expensive, as we have to look at  for all  to determine the character used in the backward step. If the alphabet is small, this is still faster than the  queries in the general encoding. We can further improve the time/space trade-off by compressing the bitvectors  for rare characters (e.g.~, , and B_{c}[i]G'.\LF(i)G' = (V', E')v'_{0}, \dotsc, v'_{\abs{V'}-1}G'\LCP[0, \abs{V'}-1]\LCP[i]G'.\gkey(v'_{i-1})G'.\gkey(v'_{i})\LCP[0] = 0G'.\gkey(v')v' \in V'G'v[sp, ep]\ell(v)x\Oh{x \log_{x} \abs{V'}}\Oh{\log_{x} \abs{V'}}\frac{x}{x-1} \abs{V'} \log k\find\parent\textsf{shorter}\parentX\revcomp{X}K\revcomp{K}\parentv' \in V'\locateX2n-d-1ndv[sp, ep]\countq(v)\ell(v)v_{0}, \dotsc, v_{m-1}vR(v) = \sum_{i=0}^{m-1} \countq(v_{i}) - \countq(v)R[0, n-2]ivR[i] = R(v)R[j] = 0R[sp, ep-1]v\countq(v) = (ep+1-sp) - \sum R[sp, ep-1]Rx0^{x} 1B_{R}\sum_{i=a}^{b} R[i]\selectRA[0, \abs{V'}-1]v'_{i} \in V'A[i] = \abs{G'.\gvalue(v'_{i})}-1B_{A}R[sp,ep] = G'.\find(X)XG = (V, E)G.\glabel(v)v \in V\SigmaFRX \in \Sigma^{\ast}\abs{X} \ge 2X[i, \abs{X}-1]FX[0, i-1]R1 \le i \le \abs{X}-1iEX[0, i-1]X[i, \abs{X}-1]X\revcomp{X}\find(X[i, \abs{X}-1])\find(\revcomp{X}[\abs{X}-i, \abs{X}-1])SASBCABSCSS$ are the same sequence. One solution is to use \emph{context-free grammars}. As long as the grammar is non-nested, we can handle it with the hypertext index. We build a hypertext index for a high level graph, where each node is labeled with a nonterminal symbol, while each nonterminal expands into a subgraph indexed in GCSA.


\bibliographystyle{abbrv}
\bibliography{paper}

\end{document}
