\documentclass[11pt]{article}

\usepackage{setspace}

\usepackage{latexsym}
\usepackage{algorithm}
\usepackage[xdvi,dvips]{graphics}
\usepackage{pstricks}
\usepackage{epsfig}
\usepackage{amssymb}
\usepackage{multicol}
\usepackage{array}
\usepackage{float}
\usepackage{boxedminipage}



\marginparwidth 0pt
\oddsidemargin  0pt
\evensidemargin  0pt
\marginparsep 0pt
\topmargin  -0.6in
\textwidth   6.6in
\textheight  8.7 in
\columnseprule 0.5pt



\newenvironment{proof}{{\bf Proof. } }{{\hfill }\vspace{.5pc}}
\newtheorem{theorem}{Theorem}[section]
\newtheorem{corollary}[theorem]{Corollary}
\newtheorem{definition}[theorem]{Definition}
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{claim}[theorem]{Claim}
\newtheorem{remark}[theorem]{Remark}
\newtheorem{note}[theorem]{Note}
\newtheorem{proposition}[theorem]{Proposition}


\floatstyle{ruled}

\newfloat{algo}{thp}{lop}[section]
\floatname{algo}{Algorithm}

\newcommand{\ALGOHEADER}[3]
{
    {\textbf{#1}\\
        \begin{tabular}[t]{@{\hspace{15pt}}l}
           #2
        \end{tabular}\medskip
    }\\
}

\newcommand{\CONST}[1]      {\ALGOHEADER{Constants: }{#1}\\}\newcommand{\VAR}[1]        {\ALGOHEADER{Variables: }{#1}\\}\newcommand{\USES}[1]       {\ALGOHEADER{Uses: }{#1}\\}\newcommand{\MACRO}[1]      {\ALGOHEADER{Macros: }{#1}\\}

\newcommand{\ACTION}        {\textbf{Actions:}}

\newcommand{\BEGLIST}{\begin{list}{}{\partopsep -2pt \parsep -2pt \listparindent 0pt}}\newcommand{\ENDLIST}{\end{list}}


\newcommand{\mod}{\mbox{ mod }}

\newcommand{\mN}   {\mathcal{N}}
\newcommand{\mT}   {\mathcal{T}}
\newcommand{\mH}   {\mathcal{H}}
\newcommand{\mA}   {\mathcal{A}}
\newcommand{\mC}   {\mathcal{C}}
\newcommand{\mP}   {\mathcal{P}}
\newcommand{\mS}   {\mathcal{S}}
\newcommand{\mG}   {\mathcal{G}}
\newcommand{\mR}   {\mathcal{R}}
\newcommand{\mX}   {\mathcal{X}}
\newcommand{\bbZ}   {\mathbb{Z}}
\newcommand{\bbN}   {\mathbb{N}}
\newcommand{\bbV}   {\mathbb{V}}

\newcommand{\Rone}   {\scriptstyle {\cal R}1} 
\newcommand{\Rtwo}   {\scriptstyle {\cal R}2} 
\newcommand{\GA} {\mathcal{SSGA}}
\newcommand{\AU} {\mathcal{SSAU}}

\newcommand{\TRUE}{\mathtt{true}}
\newcommand{\FALSE}{\mathtt{false}}

\newcommand{\eg}{\emph{e.g., }}
\newcommand{\ie}{\emph{i.e., }}

\newcommand{\FIXME}[1]
{
  \noindent
  \begin{boxedminipage}{\linewidth}
    \textsl{{\bf FIXME: #1}}
  \end{boxedminipage}
}

\newcommand{\text}[1]{\mbox{#1}}







\begin{document}


\title{ Self-Stabilizing Wavelets and -Hops Coordination}



\author{
Christian Boulinier and Franck Petit\\
LaRIA, CNRS \\
Universit\'{e} de Picardie Jules Verne, France\\
}

\date{}
\maketitle

\footnotesize
\begin{abstract}
We introduce a simple tool called the \emph{wavelet} (or, -wavelet) scheme.  
Wavelets deals with coordination among processes which are at most
 hops away of each other.  
We present a self-stabilizing solution for this scheme.  Our solution requires no underlying 
structure and works in arbritrary anonymous networks, \ie no process identifier is required.  
Moreover, our solution works under any (even unfair) daemon. 

Next, we use the wavelet scheme to design self-stabilizing \emph{layer clocks}.  
We show that they provide an efficient device in the design of local coordination 
problems at distance , \ie -barrier synchronization and
-local resource allocation (LRA) such as -local mutual exclusion (LME), 
-group mutual exclusion (GME), and -Reader/Writers.  Some solutions to 
the -LRA problem (\eg -LME) also provide transformers 
to transform algorithms written assuming any -central daemon into algorithms working 
with any distributed daemon.  
\\

\textbf{Keywords}: Barrier Synchronization,  Local Synchronization, Resource Allocation, Self-Stabili\-zation, Unison. \end{abstract}
\normalsize





\section{Introduction}

Most of the distributed system are not fully connected networks.  
Each process is only directly connected with a subset of others, called neighbors.  By this way, 
the communication links organize the network in a some graph topology which is either arbitrary or 
in accordance with some global topology constraints, \eg acyclicity, constant degree, ring, grid, etc.  
Whatever the topology complexity, the design 
of a distributed task is simplified if it requires coordination mechanisms involving a process with
its neighbors only, \ie  one hop away.  Such distributed tasks are said to be \emph{local}.  
Unfortunately, many distributed tasks requires coordination farther away than the immediate neighbors, 
\ie  hops away with .  If  is equal to the diameter of the network , then
the task is said to be \emph{global}. 

In this paper, we consider problems requiring coordination among processes which are 
at most  hops away of each other. We present solutions having the desirable property of 
self-stabilization.  The concept of {\em self-stabilization}~\cite{D74,D00} is an efficient 
approach to design distributed systems to tolerate arbitrary transient faults. A
self-stabilizing system, regardless of the initial states of the processors
and initial messages in the links, is guaranteed to converge to the intended
behavior in finite time.

\paragraph{Motivation and Related Works.}

Coordination at distance  received a particular attention in recent works.  
There are various motivations for this issue.  The first one consists in the design of -local
computations~\cite{NS93}, \ie running in constant time independent of any global parameter like 
the size of the network or the diameter.  Computation in constant time  can be achieved if the processes
can collect informations from processes located within radius of  from them. 
In \cite{NS93}, the authors mainly address \emph{Local Checkable Labeling} problems. 
Local computation is also considered in~\cite{GMM04} by considering the recognition problem.  
The computing model is a relabelling system.  


Wireless networks bring new trends in distributed systems which also motivate research the local control 
of concurrency at distance .  In~\cite{DNT06}, the authors propose a generalization of the 
well-known dining philosophers problem~\cite{Dij68}.  They extends the conflict processes beyond the 
immediate neighbors of the processes.  As an application, their solution provide a solution
to the interfering transmitter problem in wireless networks.

Another motivation consists in assuming that the knowledge of the processes goes beyond their immediate neighbors 
could help in the design of non-trivial tasks~\cite{GGHK04,GHJT06}. 
An efficient self-stabilizing solution is given to the \emph{maximal 2-packing} problem assuming
the knowledge at distance  \cite{GGHK04}. (The maximal 2-packing problem consists to find a 
maximal set of nodes , such that no two nodes in  are adjacent and no two nodes in  have a common neighbor.)
The solution in \cite{GGHK04} requires process ID's and works under a central daemon.  
In \cite{GHJT06}, the authors propose a -distance knowledge transformer to
construct self-stabilizing algorithms which use a  distance 
knowledge. Again, their solution works only if the daemon is central and with process ID's.  


Note that various kinds of transformers have been proposed in the area of 
self-stabilization to refine self-stabilizing algorithms which use tight
scheduling constraints like the central daemon into the corresponding
self-stabilizing algorithm working assuming weaker daemons,\eg 
\cite{MN98,GH99,NA02,CDP03}. A popular technique consists in composing the 
algorithm with a self-stabilizing \emph{local mutual exclusion} (LME) 
algorithm~\cite{MN98,GH99,NA02}. 
LME allows to grant privileged processes to enter critical section if and only 
if none of their neighbors has the privilege, this infinitely often. 
So, Any LME-based solution does not allow concurrent execution of neighboring processes. 
The solution in~\cite{CDP03} is based on the \emph{Local Resource Allocation} (LRA), which 
allows neighboring processes to enter their critical sections concurrently provided
they do not use conflicting resources.
It transforms any algorithms written in a high-atomicity model (\eg with a central daemon)
into the distributed read/write atomicity model by allowing neighborhood concurrency.

However, none of the above solutions allows coordination farther than the immediate neighbors.
So, they are not directly applicable to the method developed in \cite{NS93,GGHK04,GHJT06,DNT06}.


\paragraph{Contributions.}

In this paper, we introduce a simple tool called the \emph{wavelet} (or, \emph{-wavelet}) scheme.  
Wavelets deals with coordination among processes which are at most  hops away of each other.  
Wavelets are related to the notion of \emph{wave} (also called \emph{Total} algorithm~\cite{T88,Tel94}).

In this paper, we present a self-stabilizing solution to the -wavelet problem.
There are several way to design the wavelet scheme depending on network properties.   
For instance, assuming a unique identifier on each process, in~\cite{DNT06}, the authors 
provides a self-stabilizing -wavelets scheme by combining a stabilizing Propagation of 
Information with Feedback (PIF)~\cite{BDPV99b} over a self-stabilizing BFS spanning tree~\cite{HC92,J97} 
rooted at each process of height equal to .  

By contrast, our solution requires no underlying structure and works in arbritrary anonymous networks, \ie
no process identifier is required.
Our solutions is based on the unison in~\cite{BPV04b} and works assuming any distributed (even unfair) daemon. 

Next, we use the wavelet scheme to design self-stabilizing \emph{layer clocks}.
The lower layer clock, in the sequel called the \emph{main} clock, provides a wavelet stream. 
The upper layer clock, so called the \emph{slave} clock, achieves a \emph{barrier} synchronization
mechanism, where no process  starts 
to execute its phase  before all processes in the ball centered in  have completed their phase .

Finally, we show that the layer clock also provides an efficient underlying device in the design of 
various local resource allocation problems at distance .  This problems include
Mutual Exclusion~\cite{D65}, Group Mutual Exclusion~\cite{Jou00}, and Readers-Writers~\cite{CHP71}.
Some of these solutions (\eg -LME) also provides transformers 
to transform algorithms written assuming any -central daemon into algorithms working 
with any distributed daemon.


\paragraph{Paper Outline.}

The remainder of the paper is organized as follows. 
We formally describe notations, definitions, and the execution model in Section~\ref{sec:prel}. We also 
state what it means for a protocol to be self-stabilizing. 
In Section~\ref{sec:wave}, we define the wavelet scheme, present our solution for this problem in an arbitrary anonymous networks, 
and show how it can be used as an infimum computation at distance . 
In Section~\ref{sec:distance_scheme},  we introduce the self-stabilizing layer clocks and show how they can be used 
to solve -local coordination problems. Finally, we make some concluding remarks in Section~\ref{sec:conclusion}.

\section{Preliminaries}
\label{sec:prel}

In this section, we first define the model of distributed systems 
considered in this paper.  We then define the execution model and various general definitions such as events, causal DAG, and Coherent Cuts.
We also state what it means for a protocol to be self-stabilizing.  

\subsection{Distributed System}

A \emph{distributed system} is an undirected connected graph, ,
where  is a set of nodes------and  is the set of edges. Nodes
represent \emph{processes}, and edges represent \emph{bidirectional
communication links}. A communication link  exists iff  and
 are neighbors.
The distributed system is considered to be arbitrary and anonymous, \ie we consider no particular topology 
nor unique identifiers on processes.

The set of neighbors of every process  is denoted as .
The \emph{degree} of  is the number of neighbors of , \ie equal to .
The distance between two processes  and , denoted by ,
is the length of the shortest path between  and .  Let  be a positive integer. Define  
as the set of processes such that , \ie the ball centered at . 
 denote the diameter of the network.

The program of a process consists of a set of registers (also referred to as variables) 
and a finite set of guarded actions of the following form: 
.
Each process can only write to 
its own registers, and read its own registers and registers owned by the neighboring processes.
The guard of an action in the program of  is a boolean
expression involving the registers of  and its neighbors. The
statement of an action of  updates one or more registers of . 
An action can be executed only if its guard evaluates to true.   
The actions are atomically executed, meaning the evaluation of a guard and the execution of
the corresponding statement of an action, if executed, are done in one atomic step.

\subsection{Execution Model}

The \emph{state} of a process is defined by the values of its registers.
The \emph{configuration} of a system is the product of the states of all processes. 
Let a distributed protocol  be a collection of binary transition
relations denoted by , on , the set of all
possible configurations of the system.   describes an
oriented graph , called the \emph{transition graph} of .
A sequence  is called an
\emph{execution} of  iff . 
A process  is said to be \emph{enabled} in a configuration
 if there exists an action  such that 
the guard of  is true in .  
Similarly, an action  is said to be enabled (in ) at 
if the guard of  is true at  (in ).
We consider that any enabled processor  is \emph{neutralized} 
in the computation step  if  is enabled in 
 and not enabled in , but does not execute any action
between these two configurations.  (The neutralization of a processor represents the
following situation: At least one neighbor of  changes its state between 
 and , and this change effectively made the guard of 
all actions of  false.)

We assume an \emph{unfair and asynchronous distributed daemon}. 
\emph{Unfairness} means that even if a 
processor  is continuously enabled, then  may never be chosen by 
the daemon unless  is the only enabled processor.
The \emph{asynchronous distributed} daemon implies that 
during a computation step, if one or more processors are enabled, then the 
daemon chooses at least one (possibly more) of these enabled processors to 
execute an action.



In order to compute the time complexity, we use the definition of
\emph{round}~\cite{DIM97a}.  This definition captures the execution rate of 
the slowest processor in any computation.
Given an execution , the \emph{first round} of  
(let us call it )
is the minimal prefix of  containing the execution of one action 
of the protocol or the neutralization of every enabled processor from the first configuration.  
Let  be the suffix of , \ie .  
Then \emph{second round} of  is the first round of , and so on.

\subsection{Events, Causal DAG's and Cuts}

\begin{definition}[Events] 
Let  be a finite or
infinite execution. 
 For all  is an event.
  Let  be a transition. If the
process  executes a guarded action during this transition, we say that 
executes an action at time .  The pair  is said to be an
event (or a -event). 
Events so that the guard does not depend on the shared registers of any neighbor are said to be \emph{internal}.
\end{definition}

\begin{definition}[Causal DAG]
The causal DAG associated is the smallest relation  on the set of events
such that the following two conditions hold:
\BEGLIST
\item [1.] Let  and  be two events such that ,  is 
the greatest integer such that . Then,
;

\item [2.] 
Let  and  be two events such that  is not an internal event, , , and  is 
the greatest integer such that .  Then, 
.
\ENDLIST
\end{definition}

Denote the \emph{causal order} on the sequence  by .  Relation  is 
the reflexive and transitive closure of the causal
relation .
The \emph{past cone} of an event  is the  causal- induced
by every event  such that . 
A past cone involves a process  iff there is a -event in the cone.  We say that a past 
cone \emph{covers} , iff every process  is involved in the cone. The \emph{cover} of an 
event , denoted by , is the set of processes  covered by the past cone of . 




\begin{definition}[Cut]
A cut  on a causal DAG is a map from  to , which associates
a process  with a time . We mix this map with its graph: .\end{definition}

The \emph{past} of , denoted by , is the set of events 
 such that . 
Similarly, we define the \emph{future} of , denoted by , as the set of 
events  such that . 
A cut is said to be \emph{coherent} if  and ,
then  .
A cut  is less than or equal to a cut , denoted by ,
if the past of  is included in the past of 

If  and  are coherent cutes such that , then  is the 
\emph{induced} causal DAG defined by the events  such
that .A \emph{sequence of events} is any segment 
where  and  are coherent cuts satisfying .  
Any event of  is called an \emph{initial event}.

\subsection{Self-Stabilization}
Let  be a set. A \emph{predicate}  is a function that has a Boolean 
value--- or ---for each element .
A predicate  is \emph{closed} for a transition graph  iff 
every state of an execution  that starts in a state satisfying  also satisfies .
A predicate  is an attractor of the predicate , denoted by ,
iff  is closed for  and for every execution  of , beginning by a state satisfying , 
there exists a configuration of  for which  is true. 
A transition graph  is \emph{self-stabilizing} for a predicate  iff  is an attractor 
of the predicate , \ie .



\section{Wavelets}
\label{sec:wave}

In this section, we first define the problem considered in this paper, followed 
by our self-stabilizing solution designed for any anonymous networks. Next, we show that 
it provides an efficient tool to compute any infimum at distance . 

\subsection{Problem Definition}
Let us assume that there exists a special internal type of events called a \emph{decide} event. Let   be an integer.
A \emph{-wavelet} is a \emph{sequence of events}  
that satisfies the following two requirements:

\BEGLIST
\item [1.] The causal DAG induced by  contains at least one decide event;

\item [2.] For each decide event , the past of  in 
 covers .
\ENDLIST


A \emph{wave} is the particular case where ,  is the diameter of the network.
There are several way to implement the -wavelet scheme if the processes have Id's, for instance using
the PIF scheme on trees with height equal to  rooted at each process.  In the following subsection,
we present a solution for the -wavelet problem in anonymous networks.  Next, we show how this solution 
provides a self-stabilizing infimum computation in a -ball.






\subsection{Solution Description}

Our solution is based on the unison developed in~\cite{BPV04b}, which  stabilizes in 
 rounds in general graphs. 
Note that in a tree, we could use the protocol proposed in~\cite{BPV06}.  It gives the better 
stabilization time complexity of at most  rounds.
In the sequel, we first borrow some basic definitions and properties introduced in~\cite{BPV04b},
followed by our solution and its correctness proof. 

\subsubsection{Unison}
\label{sub:unison}



\paragraph{Basic Definitions and Properties.}

Let  be the set of integers and  be a strictly positive integer.
Two integers  and  are said to be \emph{congruent modulo} , denoted by
 if and only if . We denote  the unique element in 
such that .   is a \emph{distance} 
on the torus  denoted by   . 
Two integers  and  are said to be \emph{locally comparable}  if and only if
 .  We then define
the \emph{local order relationship}  as follows: 
.
If  and  are two locally comparable integers,  we define  
 as follows:
.
If  is a sequence of integers such that 
,  is locally comparable to ,
then  is the \emph{local variation} of this sequence. 


Define , where  is a positive integer. 
Let  be the function from  to  defined by:
.
The pair  is called a \emph{finite incrementing system}.  is called the \emph{period} of .
Let  and  be the sets of 
``extra'' values and ``expected'' values, respectively.
The set  is equal to .
A \emph{reset} on  consists in enforcing any value of  to .  
We assume that each process  maintains a clock register  using an incrementing system . 
Let  be a system configuration, we define the predicate  as follows:
.
In the remainder, we will abuse notation, referring to the corresponding set of 
configurations simply by . 


In , the clock values of neighboring processes are locally comparable.  In the sequel of the paper,
we need the three following definitions:
\BEGLIST
\item [\textbf{Delay}.]  \label{def:delay} The delay of a path , denoted by
, is the local variation of the sequence 
, \ie  if 
,  otherwise ().
\item  [\textbf{Intrinsic Delay}.] \label{def:intrinsic}
The delay between two processes  and  is \emph{intrinsic} if it is independent on the choice
of the path from  to .  The delay is \emph{intrinsic} iff it is \emph{intrinsic} for every 
 and  in . In this case, and at time , the intrinsic delay between  and  is denoted by .
\item [\textbf{WU}.] The predicate  is true for a system configuration  iff  satisfies  
and the delay is intrinsic in .  
\ENDLIST



\paragraph{Unison Definition.}

Assume that each process  maintains a register . 
The self-stabilizing asynchronous unison problem, or simply the \emph{unison} problem, consists in the 
design of a protocol so that the following properties are true in every execution~\cite{BPV05}:  
\begin{list}{}{\partopsep -2pt \parsep -2pt \listparindent .3in \labelwidth .3in}
\item[\textbf{Safety }: ]  is closed.
\item[\textbf{Synchronization}: ] 
In , a process can increment its clock  only if the value of  is lower than or equal to
the clock value of all its neighbors. 
\item[\textbf{No Lockout (Liveness)}: ]
In , every process  increments its clock  infinitely often. 
 \item[\textbf{Convergence}: ] 
. 
\end{list}

The following guarded action solves the \emph{synchronization property} and the \emph{safety}:
\begin{center}
\end{center}
The predicate  is closed for any execution of this guarded action.  Moreover,
for any execution starting from a configuration in , the \emph{no lockout property} is
guaranteed. Generally, this property is not guaranteed in .








\subsubsection{Protocol }


\paragraph{Variable and algorithm description.} 
The protocol is shown in Algorithm~\ref{algo:SSWS}.
For each process , let  be the set of processes which are cooperating (or conflicting) with .  
Each process  is at most -hops away from  --- .
Let  be an incrementing system, such that .
In~\cite{BPV04b}, it is shown that:
\begin{enumerate}
\item   greater than or equal to   ensures the convergence property of the unison, 
where  is the \emph{size of the greatest hole} of , \ie the length of the longest chordless cycle of  if  contains
cycle,  otherwise ( is acyclic);
\item   greater than   ensures the liveness property of the unison in , 
where  is the \emph{cyclomatic characteristic} of , \ie the smallest length of the longest 
cycle in the set of all the cycle basis of . 
\end{enumerate}
Note that  is upper bounded by  and  is upper bounded by .
We assume that the above two conditions are satisfied.  






\begin{algorithm}
\begin{footnotesize}
\noindent
{\bf Constant and variable}:\\
\hspace*{0.3cm}
: the set of neighbors of process ; ;\\
\noindent
{\bf Boolean Functions}:\\
\noindent
\hspace*{0.3cm}
\begin{tabular}{@{}lcl}
& &;\\
 & & ;\\
 & & ;\\
 & &
      ;\\
\end{tabular}\\
{\bf Actions}:\\
\noindent
\hspace*{0.3cm}
\begin{tabular}{@{}rlcl}
 &   &  &  ; \\
   &&& if  then  ;\\
   &&&  ;\\

   
 &  &  &
   ;\\
 &  &  &
    (reset);\\  
   

\end{tabular}
\end{footnotesize}
\caption{() The Self-Stabilizing Wave Stream  for }
\label{algo:SSWS}
\end{algorithm}


\paragraph{Analysis of Algorithm~\ref{algo:SSWS} in .}
\label{sec:Unison_analysis}

By definition of , the delay is intrinsic---refer to Subsection~\ref{sub:unison}. 
It defines a total preordering  on the processes in , so called \emph{precedence relationship}. 
given a configuration in , the absolute value of the delay between two processes  
 and  is equal to or less than the distance  in the network. 


We will now prove that Algorithm~\ref{algo:SSWS} provides a -wavelet scheme.  We will develop a proof technique 
called \emph{lifting}.  The idea behind this term is to interpret any possible configuration in  
by another such that the register values are in , the set of the positive integers.  In this way, 
the precedence relationship becomes the natural order on . It is possible because delay is intrinsic.

Consider  be a maximal execution starting in .  
Let  be a minimal process, according to the \emph{precedence relation}in . Let  at time .
Denote the value of a register  of a process  in the state  by . Similarly,  denotes the delay between  and  in . 

For each process , we associate the virtual register . For the state ,
we initiate this virtual register by  the instruction 
. During the execution, for each  transition  the instruction  holds 
if and only if  holds during the same transition.
Denote by  the smallest time such that .  Since the delay is
bounded by , if , then  is well defined and the cut   is well defined on the network.
 
We now need to prove that for every , the cuts  are coherent.  We first claim the following obvious lemma:



\begin{lemma}
\label{lem:coherent}
If   then: 

 
Inductively, if 
   then: 

\end{lemma}

From the Lemma~\ref{lem:coherent},  
if  then . It follows:

\begin{lemma}
For every  the cut  is coherent.
\end{lemma}



\begin{lemma}
\label{lem:cover}
Let . If  is an event in the interval  
, then .
\end{lemma}

\begin{proof}
The statement holds for the initial events of . Let  be the set of events  in   such that  does not hold.  We assume that  is not empty, let  a minimal event in  according to . 
Let , and let . 
If  then , otherwise there exists  such that .  is not
an initial event, so  and there exists  such that  .  By the minimality of , 
 holds.  So,  
. Thus, .
Therefore,  is not in . Thus  , 
and the lemma is proved.
\end{proof}

As a corollary of Lemma~\ref{lem:cover}, the following result holds : 

\begin{theorem}
\label{th:unison_behavior}
Let  and  be a positive integer. Then, 
, with  as the set of decide events, 
is a -wavelet.
\end{theorem}



\subsection{Infimum Computation}
\label{ssec:infimum_calcul}

\paragraph{Problem definition.}
In \cite{T88,Tel94}, the author introduces the infimum
operators. An infimum  over a set , is an associative,
commutative and idempotent (i.e. ) binary operator. 
If  is a finite part of  and   then, from the associativity,
 means .  So, . 
Such an operator defines a partial order relation  over ,
by   if and only if .\ We assume that 
has a greatest element , such that  
for every  Hence  is an Abelian
idempotent semi-group with  as identity element for . 



\begin{theorem}[\cite{T88,Tel94}]
\label{th:infimum}
A wave can be used to compute an infimum.
\end{theorem}






\paragraph{Self-Stabilizing Infimum Computation in a -ball.}

In order to  add a initializing step, we assume . 
We consider the following problem: at time  each register  is initialized during the critical
section , precisely when the register 
 takes the value . At the end of each phase   , each process 
needs to known the infimum of the registers  of every
 in .

To reach the objective, we define for each process  two added registers 
 and . These two registers are initialized  at the date  during the critical section , by the value .

For , at the date , 
the action  is defined by:\newline
\noindent
,
with,  if  then  , and if   
then .


\begin{proposition}
For  and , at the date
, both equalities hold:\newline
\noindent 
 ,
and  . 
\end{proposition}

\begin{proof}

At  any process  satisfies 
and , it is the initializing step. Let  the set
of events in , for
which the proposition is not true. 

Assume by contradiction that  is not
empty. Let  a minimal event in . Let  such that  .
There exists  such that  and . 
We have  and . This equality is
true even if .
Now, . From the minimality of the event , the events , where , 
are not in  and are in . 
So, . We obtain a contradiction. 
\end{proof}

As a corollary, we obtain the expected theorem:

\begin{theorem} On the cut , 
  contains the infimum of the registers  in the ball centered in , according to the phase .
\end{theorem}

\section{Applications}
\label{sec:distance_scheme}

In this part, we show how to synchronize a self-stabilizing layer clock. The main clock defines a wavelet stream. 
Using the wavelet stream, we design with the slave clock a barrier synchronization at distance . 
We then show how to use this layer clock to tackle efficiently many local synchronization problems at distance .

\subsection{Self-stabilizing Layer Clock}
\label{subsec:layer_clock}

The idea is to manage the wavelet stream. A clock organizes
this stream.  The wavelets are used to compute concurrently local infimum on
each  -ball. For each process , once the infimum computed, a second
clock defines a delay notion on the network. This delay is a total
preordering useful to schedule the critical section enter of each process. 





More formally, we define two clocks, the first clock  (the master clock) and a second clock  (the slave clock).  
The incrementing systems are respectively  
and    . The behavior of the slave clock  is scheduled by
the first clock and a predicate . The predicate  depends of the problem solved. 
To distinguish the two clocks, all the registers are subscripted by  or  respectively for the
master clock and the slave clock. The predicates are superscripted by  or .  For instance, the register of the master
clock is denoted by  and the register of the slave clock is denoted
by , and the predicate  is defined on the register 
 of the process .  The predicate  is defined on
the register  of the process .  We define in the same way , ,
and   .
The stabilization of the layer clock is to guarantee 

When the system is stabilized,  the schedule of the slave clock of a process  is defined in  by 
\begin{center}

\end{center}
Predicate  is independent of the register . It is this predicate which expresses  the distance   synchronization problem solved, 
while the procedures \emph{Initialization} and \emph{Computation} are 
scheduled by the wavelet and  provide a preprocessing used by .
The procedures \emph{Initialization} and \emph{Computation} depends on the problem to be solved to the layer clock.  
We give some instances for different problems later.  

We define the predicate .

\begin{algorithm}
\begin{footnotesize}
\noindent
{\bf Constant and variable}:\\
\hspace*{0.3cm}
: the set of neighbors of the process ;  \\
\noindent
;
;\\
\noindent
{\bf Boolean Functions}:\\
\noindent
{\bf For clock }:
\noindent

\hspace*{0.3cm}
\begin{tabular}{@{}lcl}
& &;\\
 & & \\
&& ;\\
 & & ;\\
 & &
;\\
\end{tabular}\\
\noindent
\bf{ Common predicate}:\\
\noindent
\hspace*{0.3cm}
\begin{tabular}{@{}lcl}
&&;\\
\end{tabular}\\
\noindent
{\bf Actions}:\\
\noindent
\hspace*{0.3cm}
\begin{tabular}{@{}rlcll}
 &   &  & if  then &\\
      &&&  \  \ \ \text{  } Begin & \\   
     &&&  \  \ \ \text{  }  &   ;\\
     &&&                                                       & if  then   \\
     &&&\  \ \ \text{  }  ; & \\
      &&&  \  \ \ \text{  } End & \\ 
      &&& else ; & \\
    &&& ; &\\
\end{tabular}\\
\noindent
{\bf For clock }:\\
\noindent
\hspace*{0.3cm}
\begin{tabular}{@{}rlcl}  
 &  &  &
   ;\\
   
 &  &  &
    (reset);\\  
   

\end{tabular}
\end{footnotesize}
\caption{() Self-stabilizing Layer Clock}
\label{algo:layer_clock}
\end{algorithm}


Due to the lack of space, the proofs of Proposition~\ref{cor:WUstab} and~\ref{prop:nos} are left in the appendix.

\begin{proposition}
\label{cor:WUstab}
The layer clock stabilizes to .
\end{proposition}

\begin{proposition}[No starvation]
\label{prop:nos}
Once stabilized, the clock \emph{C} increments infinitely often.
\end{proposition}


\subsection{Local Comparison in a -ball}

In the network, when the layer clocks are  stabilized, the delay between two processes according to the slave clocks   defines a total preordering  on the processes. 
Unfortunately this delay is a global notion. The problem is to
find a condition such that for two processes in the same -ball, it is
possible  to calculate directly the delay with only the knowledge of the  register values, and so to decide which process precedes the other
according to the delay. 
To organize comparison between two processes lying  in a same ball of radius
equal to , it is sufficient to be able to compare the slave clock
registers  of any two  processes at distance less than or equal to . By
this way,  in each -ball , we will be able to define a total
preordering among the processes in  by comparison of the values of the
registers  of the processes. Of course we want that this total
preordering is the same than the preordering defined by the delay.
In order to reach this objective, we extend the locally comparability defined at one hop (refer to Section~{sub:unison}) 
to the distance .  For the clarity, we must be
more formal:
A local order on a set  is an antisymmetric and reflexive binary
relation on .
Let  such that . 
Let  and  be two elements of . Let us assume that . Let us define now a local ordering   by : 
.


\begin{lemma}
Let  and  be two processes satisfying  . If  and  then the delay  is
equal to  if  and is
equal to  otherwise
\end{lemma}

\begin{proof}
Since , we have .  Moreover, .  Since, , 
then  is equal to  if ,  otherwise.
\end{proof}

From this lemma, we access to the delay in each ball  So our
problem is solved. 
In the following section, we assume that ,  with  and . These assumptions ensure 
that the layer clocks are self-stabilizing, that the main clock is calibrate to defined a -wave stream , and that delay defined by the
slave clocks is computable at distance  with the only knowledge of
the  slave clock registers .

\subsection{-Local Resource Allocation}
\label{subsec:usedc}

\subsubsection{Problem Definitions}

The \emph{Resource Allocation} problem deals with resource sharing problems among
the processes.  The resource allocation allows processes to access resources,
(\ie their critical sections) concurrently, provided the resources are not
conflicting with each other.

\begin{definition}[Graph of Compatibility~\cite{CDP03}] 
Let  be a set -- sometime named the resource set--,
let  be a reflexive binary relationship on  We say that  is the
compatibility relationship on . If , then we say
that  and  are compatible. If  then we say
that  and  are conflicting.
\end{definition}

The specification of the general resource allocation problem is defined as follows:
\BEGLIST
\item  [{\bf Safety}:] if a processor requests a resource in  to enter in
critical section, then its request is eventually satisfied and it enters the
critical section.

\item  [{\bf Fairness}:] In every execution, if two processes execute their
critical section simultaneously, then both are using resources whose are
compatible.
\ENDLIST

Most of the problem requiring coordination among process sharing some resources are 
particular instances of the graph of compatibility, and then, particular safety requirements.  
For instance, the following well-known problems are particular instances of the resource allocation problem:

\BEGLIST
\item  [\textbf{Mutual exclusion}:]  is the set of processes and  The safety condition is:
\emph{In every execution, no two processes execute their critical section
simultaneously}.

\item  [\textbf{Readers-Writer}:]  is the set of 2-uples , and  is defined by
the safety condition:
\emph{ In every execution, if two processes execute their critical section
simultaneously, then both are executing a read operation}.

\item  [\textbf{Group Mutual Exclusion}:]  is a equivalence relationship over a set
of resources .  is defined by the safety condition:
\emph{In every execution, if two processes execute their critical section
simultaneously, then both are using resources in the same equivalence
class}.

\ENDLIST

We now generalize the above requirements by limiting their effect to the conflict processes 
which are at -hops away of any given process .  Obviously, if ,
then the problem comes down to the above requirements.  If 
, then the set of processes which are conflicting with a process  is reduced 
to the neighboring processes of .  The most popular of this problems is the \emph{dining philosopher} problem,
also called the \emph{Local Mutual Exclusion} (LME) problem.

\BEGLIST
\item  [\textbf{-Local mutual exclusion}:]
  is the set of processes and 

\item  [\textbf{-Local Readers-Writer}:]  is the set of 2-uples , and  is
defined by the safety condition:
\emph{  In every execution, if two -neighboring processes execute
their critical section simultaneously, then both are executing a read
operation}.

\item  [\textbf{-Local Group Mutual Exclusion}:]  is a equivalence relationship over
a set of resources  .  is defined by the safety condition:
\emph{ In every execution, if two -neighboring processes execute
their critical section simultaneously, then both are using resources in the
same equivalence class}.

\ENDLIST

The  generic version called the \textbf{-Local Resource Allocation} (-LRA) is 
specified as follows:  is a general relationship over a set
of resources . The safety condition is:
\emph{  In every execution, if two -neighboring processes execute
their critical section simultaneously, then both are using resources whose
are compatible}.












\subsubsection{Self-Stabilizing Solutions}
\label{sub:SSLRA}

Due to the lack of space, the correctness proofs of this section are left in the appendix.

\paragraph{-LRA.}

Each process  maintains three registers  where  is
any data type, and the registers  and . The
content of  is the asked resource. Let us assume that a total order  is defined on . 
We reach the two fields of the register  by  and  respectively, with .  
We define a local ordering on  by:
\begin{center}

\end{center}
Recall that  is defined by the delay, which is a total preordering. This preordering being computable at distance .    
Define the associated -local infimum in the following way:
\begin{center}
\end{center}

Define the macros \emph{Initialization} and \emph{Computation}, respectively by:
\begin{center}

\end{center}
with, if  then  and if  then . 
The preprocessing of a local infimum designates a winner  in the ball centered in . It is important to see that this process is elected
by , and perhaps it is not elected by all the processes in the  ball centered in .  
The condition  depends of the solved problem, it is the disjunction:   or  . Where   means that  is elected in the  ball centered in , the condition  is there to raise
concurrency, it depends of the solved problem.
If   is not elected by the local infimum calculation and  is true, the incrementation of the register may to be  not 
wanted. The condition  of the incrementation is: .



\paragraph{-LME.}

Assume that each process  has an identifier denoted by . The
value of  is in a total ordered set , for instance the
integers. In fact, the identities must be only a -distance
network coloring. That is to say that every node must be colored
such that two vertices lying at distance less than or equal to 
have not the same color.
We define for each process  the register  as . 
The couple  is defined for each process . The condition  is defined by  and thus .



\begin{definition}
-LME has a fairness index of , if in any computation, between
any two consecutive critical section execution of a process, any other
process can execute its critical section at most  times. The time-service
of -LME is the maximal number of critical executions by other
processes between two successive executions of the critical section by any
process.
\end{definition}

Our -LME algorithm is a barrier synchronization at distance . We deduce:


\begin{proposition}
For the -LME algorithm, the fairness index is  equal to , and 
the service time is upper bounded by .
\end{proposition}

From the definition of a phase~\cite{BPV04b}, and because  is in ,  
 is in , respectively. So,  is in . Thus:	

\begin{proposition}
 During one phase, the number of link-communications is equal to , where  is the number of edges
in the network.
 The stabilization time complexity of -LME algorithm is in  rounds, and
 The space complexity of -LME algorithm is in .
\end{proposition}

Our solution for the -LME problem provide a good technique to reduce the service time 
and the fairness index of . The price to pay is the increase of the communications between
processes.

\paragraph{-Group mutual exclusion.} 

Let  be the set of resources. Let us assume 
that the preordering  is
defined on  --an arbitrary ordering, for instance a priority ordering. The
binary relationship on , defined by:  iff    is an equivalence relationship. The equivalence classes are the
groups. The set of groups is the quotient . 
 takes its values in . An other way is to say that  is an total ordering on the groups.
To raise concurrency, if  asks a resource  and if the elected process at distance  requests a resource in the same group,   enters in critical section.
The predicate  is defined as: .  

Note that we assume that there is no identity on the processes.  However, we make the additional assumption 
that there is a total ordering on the resources. For instance, Local Mutual Exclusion problem is an instance of 
Group Mutual Exclusion where the resources are the processes.  So, there is an ordering on the processes, which equivalent 
to define process identities.



\paragraph{-Readers-Writer.}

We assume that each process has an identity denoted by . Each process has three possible requests: the process does not ask
anything, the process asks to \emph{read}, the
process asks to \emph{write}. This requests are
symbolized respectively by . In order to be able
to compare two registers  at distance , we assume that . For each -ball , the local ordering 
defines a total preordering on the registers  of processes in . 
If a process  asks  or  then the register  is initialized by
the value . If  asks   then  is initialized
by the value .  
The ordering  on  is defined by:




For each process , the predicate  is defined by matching on  as follows: 






\section{Conclusion}
\label{sec:conclusion}
We presented a self-stabilizing algorithm to solve the -wavelet scheme in arbritrary anonymous networks. 
Wavelets deals with coordination among processes which are at most  hops away of each other.  
The proposed algorithm works under any (even unfair) daemon. 
Using the wavelet scheme, we described a self-stabilizing layer clocks protocol and 
showed that it provides an efficient device in the design of local coordination 
problems at distance , \ie -barrier synchronization and
-local resource allocation (LRA) such as -local mutual exclusion (LME), 
-group mutual exclusion (GME), and -Reader/Writers.  Some solutions to 
the -LRA problem (\eg -LME) allow 
to transform algorithms written assuming any -central daemon into algorithms working 
with any distributed daemon.  

\singlespacing



\begin{small}
\bibliographystyle{alpha}
\bibliography{unison}\end{small}

\newpage

\appendix

\section{Self-stabilization of the layer clock}
We apply the convergence stair method~\cite{D00}.\begin{lemma}
The predicates  and  are closed.
\end{lemma}

\begin{proposition}
\label{pro:dc_1 }
The clock \emph{C} stabilizes to .
\end{proposition}

\begin{proof}
Let  be a maximal execution. Assume that 
is finite. Then, the last state  is a deadlock.  So, the clock  is stabilized, otherwise there should exist a process for which  or  is enable. We suppose now that  is not finite.\ The
projection  of  on the registers  is an execution of the
clock \emph{C}. If  is finite, then in the last state  is stabilized for the same reasons than above. If  is not
finite, then  is an infinite execution of , so from~\cite{BPV04b} there is a state which is in .
\end{proof}

\begin{proposition}
\label{pro:dc_2 }
The clock \emph{C} stabilizes to  .
\end{proposition}

\begin{proof}
Let  be a maximal execution. We can
assume from Proposition \ref{pro:dc_1 } that .\ So while 
is not stabilized,  does not execute any action. So  \ the projection 
 of  on the registers  is an execution of the clock \emph{C}
. If  is finite, then in the last state  is
stabilized otherwise there should exist a process for which  or  is enable. . If  is not finite, then  is an infinite
execution of , so from \cite{BPV04b} there is a state which is in .


\end{proof}

From Proposition~\ref{pro:dc_1 } and Proposition \ref{pro:dc_2 } we deduce the corollary:

\begin{corollary}
\label{cor:WUstab-appendix}
The layer clock stabilizes to .
\end{corollary}

\begin{proposition}[No starvation]
Once stabilized, the clock \emph{C} increments infinitely often.
\end{proposition}

\begin{proof}
Let  be a maximal execution. We can
suppose from Corollary~\ref{cor:WUstab-appendix} that .\ Assume that for a
process , action  is  executed only a finite number of time. Then the clock of
each process is executed only a finite time, so  is finite. But in the
last state of , minimal processes according to the precedence
relationship are enable, which is a contradiction.

While  is not stabilized,  does not execute any action. So \
the projection  of  on the registers  is an execution of
the clock \emph{C}. If  is finite, then in the last state  is stabilized otherwise there should exist a process for which 
 or  is enable. If  is not finite, then  is
an infinite execution of .  From~\cite{BPV04b} there is a state
which is in .
\end{proof}

\section{Correctness Proofs of Subsection~\ref{sub:SSLRA}}

\paragraph{-LRA.}

 In order to proof liveness and no lockout property,  we lifts the main clock, using the lifting construction defined in section~\ref{sec:Unison_analysis}.  
We use the same notation, except that the register  becomes the register . As in Section~\ref{ssec:infimum_calcul}, .

\begin{lemma}[No lockout]
In each phase , there is
at least one process which is elected and which increments.
\end{lemma}

\begin{proof}
The set of processes is finite. So there is an infimum  among the processes, 
according to  the total order relationship .   is elected during the phase  and   increments.
\end{proof}

\begin{lemma}[Liveness]
\label{lem:liveness}
Every process has the privilege infinitely often.
\end{lemma}

\begin{proof}
It is sufficient to prove that each process  has the privilege at least
one time. Assume that a process  has never the privilege. 
Let  be the some of the delays from  to
each  in . This quantity is an integer, and from the assumption that  has never the privilege,   is  strictly increasing.
So  is not upper bounded. But this quantity is upper bounded by
 . This is a contradiction. We deduce the lemma.
\end{proof}

\paragraph{-LME.}

From Section~\ref{subsec:usedc}, both the no lockout and liveness properties are verified. It remains to show the safety property.

\begin{lemma}[Safety]
If the process  has the privilege, then no process at distance less than
or equal to  from  has the privilege simultaneously. 
\end{lemma}

\begin{proof}
Assume that  has the privilege in the phase , 
 it enters critical section  when its register  satisfies . 
Any other process  at distance less than or equal to  from  has not the privilege in the phase 
.  So if  has the
privilege simultaneously, it does not have the privilege in the same phase. The absolute value of the delay,
according to the first clock, between the two processes is less than or equal to .  But when  enters critical section and while  is in critical section:
 , 
and .
 We deduce that  can enter in critical section simultaneously if and only if , thus in the same phase as , which leads to a
contradiction. 
\end{proof}



\paragraph{-Group mutual exclusion.} 

Again, from Section~\ref{subsec:usedc}, both the no lockout and liveness properties are verified. 
The next lemma directly follows from the construction of :
\begin{lemma}[Safety]
If the process  and the process  have the privilege simultaneously and are at distance less than or equal to ,
the requested resources are in the same group.
\end{lemma}





\end{document}
