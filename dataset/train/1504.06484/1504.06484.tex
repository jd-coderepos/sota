\font\manual=manfnt
\def\dbend{{\manual\char127}}
\def\Bourbaki#1#2#3{\left(#1,#2,#3\right)_{\cal B}}
\def\eqdef{\mathop{=_{\rm def}}\nolimits}
\def\tp{{\times \atop \hbox{\rm polar}}}
\def\dom{\mathop{\rm dom}\nolimits}
\def\res{\mathop{\rm res}\nolimits}
\def\disc{\mathop{\rm disc}\nolimits}
\def\lc{\mathop{\rm lc}\nolimits}
\def\Log{\mathop{\rm Log}\nolimits}
\def\RootOf{\mathop{\rm RootOf}\nolimits}
\def\arccot{\mathop{\rm arccot}\nolimits}
\def\Arctan{\mathop{\rm Arctan}\nolimits}
\def\arccosh{\mathop{\rm arccosh}\nolimits}
\def\arccoti{{\arccot_1}}
\def\arccotix{{\arccot_9}}
\def\A{{\mathbf A}}
\def\B{{\cal B}}
\def\LL{{\cal L}}
\def\LRCF{{\LL_{\rm RCF}}}
\def\C{{\mathbf C}}
\def\N{{\mathbf N}}
\def\myS{{\cal S}}
\def\PP{{\cal P}}
\def\Q{{\mathbf Q}}
\def\R{{\mathbf R}}
\def\Z{{\mathbf Z}}
\def\ii{{\bf i}}
\def\jj{{\bf j}}
\def\eqq{{\buildrel?\over=}}
\def\cupx{{\buildrel\hbox{cts}\over\cup}}
\def\d{{\rm d}}
\def\ddx{{\frac{\d}{\d x}}}
\def\ddz{{\frac{\d}{\d z}}}
\def\ddxx{{\frac{\d^2}{\d x^2}}}
\def\us{\buildrel\hbox{\rm us}\over\Leftrightarrow}
\documentclass[runningheads,a4paper]{llncs}
\usepackage{amssymb}
\setcounter{tocdepth}{3}
\usepackage{graphicx}
\usepackage{url}
\usepackage[show]{ed}
\newcommand{\keywords}[1]{\par\addvspace\baselineskip
\noindent\keywordname\enspace\ignorespaces#1}
\bibliographystyle{alpha}
\usepackage{algorithm2e}
\usepackage{qtree}



\begin{document}

\mainmatter





\title{Recent Advances in Real Geometric Reasoning}  \titlerunning{Recent advances in real geometric reasoning}
\author{James H. Davenport \and Matthew England}
\authorrunning{James H.~Davenport and Matthew England}
\institute{Departments of Computer Science \& Mathematical Sciences,
University of Bath, UK \\
 Department of Computing, Coventry University, UK \\
\email{J.H.Davenport@bath.ac.uk, Matthew.England@coventry.ac.uk}
}






\maketitle
\begin{abstract}
In the 1930s Tarski showed that real quantifier elimination was possible, and in 1975 Collins gave a remotely practicable method, albeit with doubly-exponential complexity, which was later shown to be inherent. We discuss some of the recent major advances in Collins method: such as an alternative approach based on passing via the complexes, and advances which come closer to ``solving the question asked'' rather than ``solving all problems to do with these polynomials''.
\end{abstract}

\section{Introduction}

Although methods with better asymptotic complexity are known in theory (e.g. \cite{GrigorievVorobjov1988a}), the workhorse of implemented algorithms for real geometric reasoning is Cylindrical Algebraic Decomposition. This was introduced in \cite{Collins1975} to produce a remotely practicable (complexity ``merely'' doubly exponential in the number of variables) alternative to Tarski's original method from 1930 \cite{Tarski1951}, whose complexity could not be bounded by any tower of exponentials. Tarski in fact set out to solve the \emph{quantifier elimination problem} for real algebraic geometry (Section \ref{sec:QE}): given , where  and  is a Boolean combination of relations involving polynomials , find an equivalent , where  is a Boolean combination of relations involving polynomials . In fact, we cannot solve this in the language of algebraic geometry: we need \emph{semi-algebraic} geometry, allowing  as well\footnote{Strictly speaking  is sufficient, but implementations always allow  and . In fact,  is intrinsic to the regular chains approach discussed in Section \ref{sec:RC}.} as . The \emph{necessity} of  follows from the fact of the example ; its \emph{sufficiency} is the point of Tarski's work.


\section{Cylindrical Algebraic Decomposition by Projection and Lifting}
\label{sec:PL}

\cite{Collins1975} constructs a sampled\footnote{The ``sampled'' nature is implicit in \cite[and its successors]{Collins1975}, but the authors find it helpful to be explicit about this.} \emph{Cylindrical Algebraic Decomposition} (CAD) of  which is \emph{sign-invariant} for the , where these words are defined as follows.
\begin{definition}[CAD terminology]\label{def:cad}
Note that throughout we are ordering our coordinates/\allowbreak{}vari\-ables, so that  is the ``last coordinate''.
\begin{description}
\item[decomposition:] a partition of  into cells  indexed by -tuples of natural numbers (so  and ;
\item[{\rm(semi-)}algebraic:] every  is defined by a finite set of equalities and inequalities of polynomials in the , including expressions of the form

(where  means ``the second real root, counting from '');
\item[cylindrical:] for all , if  is the projection onto the \emph{first}  coordinates, then, for all ,  and  are either equal or disjoint;
\item[sampled:] for each cell  there is an explicit point ;
\item[sign-invariant:] for the polynomials in  on each cell, every  is identically zero, or everywhere positive, or everywhere negative.
\end{description}
\end{definition}
Collins constructed such a decomposition by a process now known (at least by our colleagues) as \emph{CAD by Projection and Lifting} (for more details see \cite{Davenport2015c}).  The key property in this approach is the following.
\begin{definition}\label{def:del}
A polynomial  is \emph{delineable}\footnote{There are various, subtly different, definitions in the literature. This one is from \cite{McCallum1999a}.} over a region  if:
\begin{enumerate}
\item the portion of the real variety of  that lies in the cylinder  over  consists of the union of the graphs (called sections) of some  continuous functions  from  to  {\bf and};
\item there exist integers  such that, for every point  in , the multiplicity of the root  of , considered as a function of  alone, is  (and in particular is constant).
\end{enumerate}
A set of polynomials is delineable over  if each is delineable {\bf and} if the sections are either identical or disjoint. This is actually equivalent to saying that the product is delineable.
\end{definition}
Intuitively, if the  are delineable over , their graphs neither fold nor cross.
\par
Let  be the set of polynomials in , with coefficients from some effective\footnote{The literature often stipulates  or the algebraic numbers . The real requirement is that we can perform all the polynomial algebra we need over , and that, given expressions , we can decide the trichotomy  or  or . Once we start adding transcendental functions to our language, the effectivity of  becomes a major problem, as we run across the usual indecidability results. This is addressed in different ways in \cite{Achatzetal2008} and \cite{Vorobjov1989,Vorobjov1992}.} field .  Then Collins algorithm proceeds as follows:
\begin{description}
\item[Projection:] Given some  construct a set  such that, over each cell of a CAD sign-invariant for , the polynomials of  are delineable. Though the details depend on the algorithm, the key ingredients are leading coefficients (where these vanish some  tends to infinity), discriminants (where these vanish some  ceases to have constant multiplicity)  and resultants (where these vanish, the   from different polynomials intersect).  
\\
Repeat until we have the set of univariate polynomials .
\item[Base case:] Given , isolate the  real roots of these polynomials in , and construct a CAD consisting of the  roots, and the  intervals between them (or to the left/right of them all). The sample points for the 0-dimensional cells are the roots themselves: for the 1-dimensional intervals we choose any convenient point, generally rational and with denominator the smallest power of 2 we can find.
\item[Lifting:] Given a CAD  of , sign-invariant for , construct a CAD  of , sign-invariant for . For each cell , this is done by substituting the sample point  into , and doing the equivalent of the base case for the resulting univariate system (valid across the whole of  if the projection operator provides delineable projection polynomials).
\\
Repeat until we have the CAD  of .
\end{description}
If we suppose that  contains  polynomials, of degree (in each variable) bounded by , and coefficient length bounded by  (coefficients bounded by ), then the time  complexity is bounded  \cite[Theorem 16]{Collins1975} by
\def\foo#1#2{\hbox to 0pt{/\hskip-6pt}#1{#2}}This analysis is very sensitive to the details of the sub-algorithms involved, and a more refined analysis of the base case \cite{Davenport1985c} reduces the complexity (though not the actual running time) to 

This improvement might seem trivial, but in fact implies taking the fourth root of the  part of the complexity. 
\par
A less sensitive property (and one that reflects the cost of \emph{using} such a decomposition) is the number of cells: for the Collins method this is bounded, by an analysis similar to \cite{Bradfordetal2014a}, by

As is often the case in mathematics, we get more insight if we solve an apparently harder problem. \cite{McCallum1984} did this, demanding that the decompositions ,  be, not just sign-invariant, but 
\begin{description}
\item[order-invariant] for the polynomials in , i.e. on each cell, every  is identically zero, and vanishes to the same order throughout the cell, or everywhere positive, or everywhere negative.
\end{description}
This actually lets his  be much simpler than Collins', with the cost that the lifting procedure might fail if some element  of  \emph{nullifies} (is identically zero) over some cell in .  In this case, McCallum says that  was not \emph{well-oriented}, and has to either:
\begin{enumerate}
\item proceed by working around the problem or concluding it not relevant.  This is only possible in certain cases (e.g. the cell is dimension 0) \cite{Brown2005}.  Otherwise;
\item revert to Collins' projection (or a variant due to \cite{Hong1990b}); or,
\item add the partial derivatives of  to  and resume the projection process from there --- an operation that to the best of the authors' knowledge has never been implemented, doubtless because of the complicated backtracking involved, and the fact that, whereas we only \emph{ought} to add this polynomial in the nullifying region, the design of Collins' algorithm and its successors assume a global set of polynomials at each level.
\end{enumerate}
``Randomly'', well-orientedness ought to occur with probability 1,
but we have a family of ``real-world'' examples (simplification/branch cuts, see \cite{Beaumontetal2007}) where it often fails.
The analogy of (\ref{eq:Collinscell}) is given by \cite[Theorem 6.1.5]{McCallum1985b} as 

and a recent improved analysis in \cite[(12)]{Bradfordetal2014a} reduces this to



\section{CAD by Regular Chains}
\label{sec:RC}

This alternative to the traditional computation scheme of projection and lifting was introduced in \cite{Chenetal2009d}, then improved in \cite{ChenMorenoMaza2012a}.  The method can be described as ``going via the complexes'', since the authors first construct a cylindrical decomposition of , and then infer a CAD of .  They make use of the well developed body of theory around regular systems \cite{Wang2000} for the work over the complexes, and the algorithms are all implemented in the \texttt{RegularChains} Library\footnote{\texttt{http://www.regularchains.org}} for \textsc{Maple}, hence our designation: \emph{CAD by Regular Chains}.

We first need the following analogue of Definition \ref{def:del} (not precisely analogous, as Definition \ref{def:del} allows for non-square-free polynomials and this does not).
\begin{definition}\label{def:sep}Let  be an effective field.
Let  be a subset of  and  be a finite set of polynomials whose main variable really is . We say that  \emph{separates above}  if for each :
\begin{enumerate}
\item for each , the polynomial  does not vanish at ;
\item the polynomials , for all , are squarefree and coprime.
\end{enumerate}
Note that the empty set is trivially separable.
\end{definition}
\def\cD{{\cal D}}
We then need an analogue of Definition \ref{def:cad} for the case of complex space.  We follow \cite{ChenMorenoMaza2012a} and describe these (complex) cylindrical decompositions in terms of the tree data structure they are stored as.
\begin{definition}\label{def:ccd}
We define a \emph{cylindrical decomposition} of , and its associated tree, by induction on .
\begin{description}
\item[Base Either:] There is one set , the whole of  and ;
\item[Base Or:] there are  non-constant square-free relatively prime polynomials  such that  is the set of zeros of , and  is the complement: : .
\item[Base Tree:] The root and all the  as leaves of it.
\item[Induction:] Let  be a cylindrical decomposition of . For each , let  be a non-negative integer, and  be a set of polynomials which separates over . 
\item[Induction Either:]  and we set ;
\item[Induction Or:] we set ; 
\item[\qquad\quad];
\item[Then:] a cylindrical decomposition of  is given by

\item[Induction Tree:] If  is the tree associated to  then the tree associated to  is obtained by adding to each leaf  as children all the  such that .
\end{description}
\rm Unlike Definition \ref{def:cad}, the different roots of a given polynomial are not separated. Each cell is the zero set of a system of polynomial equations and inequations, where the main variables are all distinct: a triangular system \cite{Aubryetal1999}.
\end{definition}
\begin{definition}\label{def:ccd-f}Let  be a set of polynomials in . A cylindrical decomposition  is \emph{-invariant} if, for each cell  and each , either  vanishes at all points of  or  vanishes at no point of .
\end{definition}
The trivial decomposition, obtained by taking the ``either'' branch each time, with one cell, is -invariant. Given a cylindrical decomposition  which is -invariant, and supposing , \cite{ChenMorenoMaza2012a} shows how to refine  to a cylindrical decomposition  which is -invariant, hence the ``incremental'' in the title of their paper. The key ingredients in this process are again leading coefficients, resultants and discriminants. 
The paper \cite{Chenetal2009d} shows, assuming that , how to construct from  a cylindrical algebraic decomposition of  which is sign-invariant for .
\par
The construction of the cylindrical decomposition can be seen, as pointed out in \cite{ChenMorenoMaza2012a}, as an analogue of the projection phase of projection and lifting. Indeed, if  is small, it is often the case that the polynomials at level  in the tree corresponding to  are those in . The fundamental difference is that the  are \emph{global} structures: over the whole cylindrical algebraic decomposition of  we need to isolate all the branches of all of , whereas there is a tree structure underpinning  and the cylindrical algebraic decomposition, which means that ``polynomials are not considered when they are blatantly not relevant''.

\newpage

\noindent \textbf{Example:} Consider the parabola  and assume the variable ordering .  Suppose we were to use projection and lifting.  Then the first projection identifies the coefficients  and the discriminant with respect to : .  Subsequent projection do not identify any further projection polynomials for this example.  Lifting produces CADs sign-invariant for these 4 projection polynomials, as well as  itself.  

The regular chains approach would start by building the following tree, representing a cylindrical decomposition of :

\begin{center}
\qtreecenterfalse
\Tree [. [.{} [.{} {\quad} {\quad} ] [.{} {\quad} {\quad} ] ] 
      [.{} [.{} {\quad} {\quad} ] [.{} {\quad} {\quad} ] ] ]
\end{center}

This decomposition was produced to be sign-invariant for .  However, it does not insist on sign-invariance for the all the other projection polynomials.  In particular, it is not sign-invariant for .  The polynomial  is included in the projection set because its vanishing can determine delineability, but only when the coefficient of the higher degree terms vanish.  So, when  it is important to ensure  is sign-invariant, but not otherwise.  Hence the tree above is doing only what is necessary to make the final conclusion about .  

The next step is to apply real root isolation, extending this tree to one representing a CAD.  At the top level the case  must split into the two possibilities:  and .  For brevity we display only the branch for  below (where  and  represent the two real roots of  in the case where the leading coefficient is negative and the discriminant positive).  The full tree has 27 leaves, thus representing a CAD with 27 cells.  This compares with a minimal CAD of 115 cells produced by projection and lifting to be sign invariant for all projection polynomials.



\begin{center}
\qtreecenterfalse
\treewidth=3cm
\Tree [. 
[.{} 
	[.{} {} {} {} ] 
	[.{\vline} [.{} {} {} {} {} {} ] ]
	!\qsetw{5cm}
	[.{} ] 
]
]
\end{center}

\par
Are there significant savings in general? We refer the reader to \cite[Table 1]{Bradfordetal2014a}.  Here {\tt PL-CAD} refers to our implementation of McCallum's algorithm of Section \ref{sec:PL}; {\tt RC-INC-CAD} refers to the algorithm of \cite{ChenMorenoMaza2012a} (Section \ref{sec:RC}); and \textsc{Qepcad} \cite{Brown2003} is another, highly optimised, implementation of McCallum's algorithm. Where both terminate, \textsc{Qepcad} and {\tt PL-CAD} often, though not always, have the same cell count. {\tt RC-INC-CAD} does sometimes have the same count, but on other examples such as BC-Phisanbut-4, needs only 2007 cells, while both implementations of McCallum's algorithm need 51,763.


\section{Quantifier Elimination}
\label{sec:QE}

The original motivation for \cite{Collins1975} was the following problem.
\begin{problem}[Quantifier Elimination]Let , and  be the language of Boolean-connected equalities and inequalities concerning polynomials in , where  is an effective field with  . Given a statement (known as a Tarski statement, or a Tarski sentence if )

the \emph{Quantifier Elimination} problem is that of producing an equivalent

In particular,  is a decision problem: is  true?
\end{problem}
If we have a CAD  of  (noting that the   must be ordered in the same way in Definition \ref{def:cad} and formula (\ref{eq:Q})) sign-invariant for the polynomials of , then constructing  is conceptually easy.
\begin{enumerate}
\item The truth of  in a cell  of   is that of  at the sample point .\label{first}
\item  projects to a  CAD  of .
\item The truth of  in a cell  is then the appropriate ( for  etc.) Boolean combination of the truth of  in the cells of  that project to .\label{step:bool}
\item  is then the disjunction of the defining formulae for all the  for which  is true.\label{last}
\end{enumerate}
There is a problem in practice with the last step, first pointed out in \cite{Brown1999a}. In the lifting stage, we produce branches  of polynomials, with descriptions such as ``that branch of  which, above the sample point , has the (unique) root in '', and this is not a statement of . We could equally describe it as ``the third real branch of  above '', but again this statement is not in . Now by Thom's Lemma \cite{CosteRoy1988}, we can describe this branch in terms of the signs of  \emph{and its derivatives}, but, whereas these derivatives are in the Collins projection, they are not in the McCallum projection, or in the tree constructed by the method of Section \ref{sec:RC}. However, when it comes to describing , we can just add these (as described in \cite{Brown1999a} for projection and lifting and in \cite{CM14} for regular chains CAD construction). The additional cost is negligible, in particular, we do not need them for projection (Section \ref{sec:PL}), or for tree construction (Section \ref{sec:RC}).

Though it may depend non-linearly on polynomial degree etc., this process is linear in the number of cells in , and produces a disjunction of at most as many clauses as there are cells in . 


\section{Lower Bounds}
\label{sec:LB}

This last remark is the basis of the complexity lower bounds in \cite{DavenportHeintz1988,BrownDavenport2007}. Both constructions use the fact that

encodes . Hence applying this construct  times to  gives 

This can then be used to produce expressions with  quantifiers and having  isolated point solutions, hence needing  cells to describe them (the  terms are  in \cite{BrownDavenport2007} and  in \cite{DavenportHeintz1988}). 
An example which needs   cells for all possible variable orders is also 
produced in \cite{BrownDavenport2007}, along with another which needs  cells in one order, but a constant number in another.  Hence the great interest in variable order selection methods for CAD \cite[to name a few]{Dolzmannetal2004a,Englandetal2014c,Huangetal2014a}.
\par
The construction in (\ref{eq:DH}) uses both  and  in a way that cannot be unnested. In fact, it is possible \cite{Grigoriev1988} to decide Tarski sentences (i.e. no free variables) with a cost that is singly-exponential in , but doubly-exponential in , the number of \emph{alternations} of  and  in (\ref{eq:Q}). These methods, or any methods singly-exponential in , have, in general, not been implemented, though there has been work on the purely existential case (for example \cite{Huntington2008a}).


\section{Equational Constraints}
\label{sec:EC}

The methods described in the previous sections produce decompositions which are sign- (or order-)invariant for a set of polynomials.  In particular, we can apply steps \ref{first}--\ref{last} of Section \ref{sec:QE} to the same CAD to solve (\ref{eq:Q}) for any other   involving the same polynomials. Indeed, as long as the  stayed in the same order, we could change the  as well. \cite{Collins1998} suggested that we could do better if  was of the form , as we would not be interested in the behaviour of polynomials in  except when . This was implemented in \cite{McCallum1999a}, who produced a CAD which was sign-invariant for , and {\bf when }, sign-invariant for the polynomials in . The main effect of this is to reduce the double exponent  of  in (\ref{eq:McCcell-us}) by 1, i.e. to take the square root of this term, as shown recently in 
\cite{Bradfordetal2014a} (14).
\par
It is worth seeing how this works. Consider

Then a \cite{McCallum1984}-style projection ignoring the fact that there is an equation constraint would contain\footnote{It would also have some leading coefficients etc., but these are not the main drivers of the complexity in McCallum's projection.} three  and three . However, \cite{McCallum1999a} observes that we are not interested in  except when , and hence we need only consider  and , , half as many polynomials.

\par Consider now

A \cite{McCallum1984}-style projection ignoring the fact that there is an equation constraint would contain four discriminants  and six resultants.
Although (\ref{eq:TTI}) does not contain an \emph{overt} equational constraint,  , which is , and so the equational constraint  is implicit. If we study  in the style of (\ref{eq:EC}), and drop trivial resultants, we consider ,  and  . Using the multiplicative properties of resultants and discriminants (which we would certainly do in practice!), this is ,  and all the resultants except , i.e. two discriminants and five resultants.
\par
Intuitively  and  are redundant, but how do we achieve this in general? This was solved in \cite{Bradfordetal2013b}, where, rather than producing a sign-invariant CAD, we compute  \emph{truth table invariant} (a TTICAD) for the two propositions  and , i.e. on each cell, each of these two propositions is either identically true, or identically false. This process does indeed remove these two resultants, so we have two discriminants and three resultants.

\vspace*{0.1in}

\noindent \textbf{Example:}  Consider (\ref{eq:TTI}) with 

and

Figure \ref{fig:Ex1} shows the two dimensional cells produced for both a sign-invariant CAD and a truth-table invariant CAD, built under ordering .
The sign-invariant CAD has 231 cells (72 full-dimensional but the splitting of the final cylinder is out of view) and the TTICAD 67 (22 full-dimensional).

By comparing the figures we see two types of differences.  First, the CAD of the real line is split into fewer cells (there are not as many cylinders in ).  This is the effect of the reduction in projection polynomials identified, (less univariate polynomials with real roots to isolate).  The second difference is that the full-dimensional cylinders are no longer split over the dashed lines. This came from an improvement in the lifting phase (discussed in detail in \cite{Bradfordetal2014a}).  It leverages the projection theory to conclude that we usually only need to lift with respect to equational constraints themselves.

\vspace*{0.1in}

More recently \cite{Bradfordetal2014a} truth-table invariance has been achieved even when there is no implicit equational constraint, as with an example of the form 

The savings that can be achieved depend on the number of equational constraints involved in sub-clauses of the parent formula.
\par
It is also possible to apply equational constraints in the regular chains technology view of CAD \cite{ChenMorenoMaza2012a}, again even when there is no global equational constraint, as in (\ref{eq:TTI2}) \cite{Bradfordetal2014b}. 

\begin{figure}[t]
\caption{The left is a sign-invariant CAD, and the right a TTICAD, for (\ref{eq:TTI}) with the polynomials from the example.}
\label{fig:Ex1}
\centering
\includegraphics[width=0.48\textwidth]{Ex1Full}
\hspace*{0.02\textwidth}
\includegraphics[width=0.48\textwidth]{Ex1TTI}
\end{figure}

\section{How Reliable is this?}

Cylindrical algebraic decomposition can be used as tool in program verification, as in the MetiTarski tool \cite{Paulson2012b}. This leads to the question: who will verify the CAD, or at least the inferences we draw from it?  We note that a positive answer to a purely existential question (equally, a negative answer to a purely universal question) is easily verified since we have a witness. The converse questions are essentially questions of refutation, see \cite{JovanovicdeMoura2012a}. Questions involving a mixture of quantifiers are much harder.

Almost all current implementations of CAD are based on computer algebra systems, which are generally unverified. We can at least compare, on a fairly level playing field, the implementations in \textsc{Maple} of four algorithms: see Table \ref{tab:compare}. The classification of the amount of mathematics involved is subjective, but we note that \cite{McCallum1984}, and hence \cite{Bradfordetal2013a}, relies on \cite{Zariski1965,Zariski1975} to justify the smaller projection set compared with \cite{Collins1975}. \cite{ChenMorenoMaza2012a} and  \cite{Bradfordetal2014b} rely on, {\it inter alia\/}, \cite{Aubryetal1999}.
\begin{table}
\caption{Comparison of algorithms\label{tab:compare}}
\centering
\begin{tabular}{llrr}
Algorithm&Implementation&Code Lines&Specialist\cr
&&(above Maple)&Mathematics\cr
\cite{Collins1975}&\cite{EWBD14}&
2600&some\cr
\cite{McCallum1984}&\cite{EWBD14}&
2500&a lot\cr
\cite{ChenMorenoMaza2012a}&\cite{ChenMorenoMaza2012a}&5000&medium\cr
\cite{Bradfordetal2013a}&\cite{EWBD14}&
3000&a lot\cr
 \cite{Bradfordetal2014b}& \cite{Bradfordetal2014b}&5500&medium\cr
\end{tabular}
\end{table}
\par
There are two challenges involved in verifying a CAD algorithm.
\begin{enumerate}
\item There is a ``program verification'' question of ensuring that the algorithms produce the result that they say they will, i.e. that resultants, discriminants, real roots etc. are computed correctly.  This is non-trivial, to say the least, sitting on top of an unverified computer algebra system, but should be feasible for an implementation based on a sound kernel, such as Coq or Isabelle.
\item There is a ``mathematics verification'' question whether the resulting decomposition is truly sign-/order-/truth table-invariant for the inputs. This is where the column labelled ``Mathematics'' in Table \ref{tab:compare} comes in.  The only  attempt to produce verified CADs known to the authors, \cite[in Coq]{CohenMahboubi2012a}, is based, not on \cite{Collins1975} and its successors, but rather on \cite[chapter 2]{Basuetal2006}, itself essentially that of \cite{Tarski1951}.
\item[2a.]There is an interesting tension here between ``precomputed'' and {\it ad hoc\/} verification. An implementation based in \cite{McCallum1984} would essentially have to verify the relevant theorems from \cite{Zariski1965,Zariski1975}, but these could be imported as pre-verified lemmas. An implementation based on \cite{ChenMorenoMaza2012a} would verify that \emph{in this case} we had an appropriate cylindrical decomposition of  which \emph{in this case} translated to an appropriate cylindrical algebraic decomposition of . 
\end{enumerate}

\section{Final thoughts}

The topics we focussed on in this paper are implemented in \textsc{Maple}: 
\begin{itemize}
\item CAD by Regular Chains is implemented in the \textsc{RegularChains} Library.  A version of this ships with the core \textsc{Maple} distribution while the latest version is freely available from \texttt{http://www.regularchains.org/}.  
\item The authors' own work (equational constraints, truth-table invariance, sub-decompositions) is freely available in a \textsc{Maple} package \textsc{ProjectionCAD}.  The latest version is available from: \texttt{http://opus.bath.ac.uk/43911/}.
\end{itemize}  

\noindent Other implementations of cylindrical algebraic decomposition include:
\begin{itemize}
\item \textsc{Mathematica} \cite{Strzebonski2006}; The commands \texttt{CylindricalDecomposition} and \texttt{Reduce} can make use of an underlying CAD implementation.  These commands can be exceptionally fast but it can be hard to judge the CAD components individually as they are just one of several underlying methods available and the output is in the form of formulae rather than cells.  
\item \textsc{Qepcad} \cite{Brown2003}; a dedicated interactive command-line program available from \texttt{http://www.usna.edu/CS/qepcadweb/B/QEPCAD.html}.  One notable feature is the SLFQ program which can simplify large quantifier free formulae giving more readable output.  \textsc{Sage} now has a \textsc{Qepcad} interface.
\item \textsc{Redlog} \cite{SS03}; this \textsc{Reduce} package implements CAD along with other quantifier elimination methods such as virtual substitution. 
\item \textsc{SyNRAC} \cite{IYAY13}; a \textsc{Maple} package notable for its symbolic-numeric approach.  An older version is available for free download from: \\ 
\texttt{http://jp.fujitsu.com/group/labs/en/techinfo/freeware/synrac/} \\
with more recent advances part of the wider Todai Robot project.
\end{itemize}

\noindent The only reported experiments to cover all of these implementations were detailed in Section 4 of \cite{Bradfordetal2014b}.

Of course, this paper surveyed only a few of the recent advances in cylindrical algebraic decomposition.  Others include (but are not limited to):
\begin{itemize}
\item The use of certified numerics in the lifting phase to minimise the amount of symbolic computation required \cite{Strzebonski2006,IYAY13}.
\item Local projection schemes \cite{Strzebonski2014a}, generic projection schemes \cite{SS03} and single CAD cells \cite{Brown2013,JovanovicdeMoura2012a}.
\item Problem formulation for CAD \cite{Dolzmannetal2004a,Bradfordetal2013a,WEBD14} (projection and lifting) \cite{Englandetal2014c,EBCDMW14} (regular chains).  These all develop heuristics to help with choices, while \cite{Huangetal2014a} applies machine learning in the form of support vector machines to pick a heuristic.
\item Work on cylindrical algebraic sub-decompositions, which return only a subset of the cells in a full CAD \cite{Sei06}.  In \cite{WBDE14} algorithms are given to return cells that lie on a prescribed variety, or have a designated dimension, while in \cite{WDEB13} these techniques are combined to solve a motion planning problem.  Note that if restricting to cells of full dimension then sample points can always be chosen to be rational, greatly reducing running time.
\end{itemize}



There are numerous unsolved problems, both theoretical and practical.  Three that stand out to the authors are the following.
\begin{enumerate}
\item There is no complexity analysis of the Regular Chains method (though clearly it is subject to the lower bounds in Section \ref{sec:LB}).
\item There has been much progress in the last forty years, but implementations (at least for systems with alternations of quantifiers) are still doubly-exponential in the number of variables while the theory suggests we can do better.
\item Cylindricity is needed in step \ref{step:bool} of quantifier elimination, as  translates into  and  into . However, in fact we only need this at the points where  and  alternate, so we can weaken the definition of cylindricity from being true for all  to merely being true for those  where  and  are governed by different quantifiers (or where  is unquantified but  is quantified, a concept we can call \emph{block-cylindrical}. Unfortunately, we currently know of no way of computing a block-cylindrical algebraic decomposition without computing the full cylindrical algebraic decomposition first.
\end{enumerate}

\subsection*{Acknowledgements}

This work was supported by the EPSRC (grant number EP/J003247/1).  

The authors thank Russell Bradford,
Nicolai Vorobjov, David Wilson (University of Bath), Changbo Chen (Chinese Academy of Sciences, Chongqing), Zongyan Huang (University of Cambridge), Scott McCallum (Macquarie University) and Marc Moreno Maza (Western University).
\bibliography{../../../jhd}

\end{document}
