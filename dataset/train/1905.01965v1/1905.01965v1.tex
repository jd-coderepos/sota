\documentclass[conference]{IEEEtran}
\usepackage[noadjust]{cite}
\usepackage{graphicx}
\usepackage{array}
\usepackage{balance}
\usepackage{epsfig}
\usepackage{epstopdf}
\usepackage{subfigure}
\usepackage{multirow}
\usepackage{color}
\newcommand{\red}[1]{\textcolor{red}{#1}}
\newcommand{\blue}[1]{\textcolor{blue}{#1}}
\newcommand{\cbl}{\color{blue}}
\newcommand{\cred}{\color{red}}
\newcommand{\cb}{\color{black}}
\newcommand{\para}[1]{\medskip \noindent {\bf #1}}
\newcommand{\softpara}[1]{\smallskip \noindent \underline{#1}}

\usepackage{tikz}
\def\checkmark{\tikz\fill[scale=0.4](0,.35) -- (.25,0) -- (1,.7) -- (.25,.15) -- cycle;} 
\hyphenation{op-tical net-works semi-conduc-tor}

\usepackage{silence}
\WarningFilter{latex}{Command \InputIfFileExists}



















\usepackage{url}

\usepackage{arabtex}
\usepackage{utf8}
\usepackage{tipa}

\begin{document}
\title{Arabic Text Diacritization Using Deep Neural Networks}

\author{\IEEEauthorblockN{Ali Fadel, Ibraheem Tuffaha, Bara' Al-Jawarneh and Mahmoud Al-Ayyoub}
\IEEEauthorblockA{
Jordan University of Science and Technology, Irbid, Jordan
\\ 
\{aliosm1997, bro.t.1996, baraaaljawarneh\}@gmail.com,
maalshbool@just.edu.jo}}

\maketitle
\IEEEpubidadjcol

\begin{abstract}
Diacritization of Arabic text is both an interesting and a challenging problem at the same time with various applications ranging from speech synthesis to helping students learning the Arabic language. Like many other tasks or problems in Arabic language processing, the weak efforts invested into this problem and the lack of available (open-source) resources hinder the progress towards solving this problem. This work provides a critical review for the currently existing systems, measures and resources for Arabic text diacritization. Moreover, it introduces a much-needed free-for-all cleaned dataset that can be easily used to benchmark any work on Arabic diacritization. Extracted from the Tashkeela Corpus, the dataset consists of 55K lines containing about 2.3M words. After constructing the dataset, existing tools and systems are tested on it. The results of the experiments show that the neural Shakkala system significantly outperforms traditional rule-based approaches and other closed-source tools with a Diacritic Error Rate (DER) of 2.88\% compared with 13.78\%, which the best DER for the non-neural approach (obtained by the Mishkal tool).
\end{abstract}

\begin{IEEEkeywords}
Deep Learning,
Arabic text diacritization,
Deep Neural Network.
\end{IEEEkeywords}

\section{Introduction}
\label{sec:intro}






Arabic is among the most widely spoken languages in the world. It is the native language of hundreds of millions of people and one of the official languages for dozens of countries. The community of Arabic speakers has one of the largest growth rates on the Internet. Thus, the interest in Arabic Natural Language Processing (NLP) has increased over the years. Unfortunately, the work on Arabic NLP is lagging behind the NLP work for other languages, such as English and Chinese, due to many reasons including the poor efforts invested in Arabic NLP and the lack of linguistic resources available for researchers and developers \cite{habash2010introduction,farghaly2009arabic,asa_survey}.

The Arabic alphabet is the base alphabet used in multiple languages including: Arabic, Persian and Kurdish. The Arabic language has 36 variants (see Figure~\ref{tab1_1}) of the basic 28 letters and eight basic diacritics (see Figure~\ref{tab1_2}) \cite{abandah2015automatic}.

Two of the major aspects differentiating the Arabic language from most other languages are: the right to left (RTL) writing style and the addition of diacritics to each letter as shown in the following example:
\begin{quote}
\centering
\setcode{utf8}\<
اَلْمُسْلِمُ مَنْ سَلِمَ اَلْمُسْلِمُونَ مِنْ لِسَانِهِ وَيَدِهِ
> \\
Buckwalter Transliteration: Aalomusolimu mano salima Aalomusolimuwna mino lisaAnihi wayadihi \\
Translation: A Muslim is the one from whose tongue
and hands the Muslims are safe.
\end{quote}

The diacritics have huge influence on the meaning of the sentences and the diacritization can be affected by the context of the sentence as shown in the following example:
\begin{quote}
\centering
\<
ذهب علي ...
> \\
Buckwalter Transliteration: *hb Ely ... \\
Incomplete sentence without diacritization. \\
\<
ذَهَبَ عَلِيٌّ بَعِيداً
>\\
Buckwalter Transliteration: *ahaba EaliyN baEiydAF \\
Translation: Ali went away. \\
\<
ذَهَبُ عَلِيٍّ كَثِيرٌ
> \\
Buckwalter Transliteration: *ahabu EaliyK kaviyrN \\
Translation: Ali has a lot of gold.
\end{quote}
Given two different diacritizations, the letters
\<
ذهب 
>
represent two different words with different part of speech (POS) tags. As shown in the example above,
\<
ذَهَبَ 
>
``thahaba'' in the first sentence is the verb `went' in English, while
\<
ذَهَبُ
>
``thahabu'' in the second sentence is the noun `gold' in English.

Moreover, Arabic text can be either partially or fully diacritized. This is because in some applications there is no need to diacritize all characters. In addition, Arabic has a diglossic nature manifested through the co-existence of Standard Arabic and Colloquial Arabic. Standard Arabic is also split into two categories: Classical Arabic (CA) and Modern Standard Arabic (MSA). CA is mainly used in the Holy Quran (HQ), old books, old poetry, etc., while MSA is used in news, lectures, letters, formal speeches, etc. The Colloquial Arabic is used in daily life, and diacritization is usually not used for this type of Arabic, unlike CA and MSA \cite{habash2010introduction}.



The Arabic language is one of the most widely used languages. Yet, the attention to using it with proper grammar is very little. Hence, the idea to build an automated diacritization system to help both fluent and non-fluent Arabic speakers came to existence. Even fluent speakers cannot always correctly determine the proper diacritization to use in certain sentences. There are many books, articles, magazines and letters that lack diacritization, which makes understanding their content problematic for most Arabic speakers. Moreover, manually adding diacritization to clarify the content is time consuming and can only be reliable through linguistics experts specializing in the Arabic language. Thus, the need for an automated diacritization system is eminent \cite{abandah2015automatic,belinkov2015arabic}.



Publishers, writers, producers and news agencies all care about delivering to their audiences easy to understand Arabic content. However, the cost to produce such content is high and time consuming.
In response to this problem, our work focuses on producing a powerful tool for automated Arabic text diacritization.
More formally, given a non-empty sequence of partially or non-diacritized Arabic text, find the correct diacritization for it. One of the aims of this work is to help in benchmarking efforts invested in this field. We also aim to show the high potential of Deep Learning (DL) approaches for this problem. In fact, we show that an existing DNN approach outperforms all existing tools and systems that are publicly available on our dataset.

DL approaches are producing ground breaking results in many tasks across different fields, such as Natural Language Processing (NLP), Computer Vision, Time-Series Analysis (TSA), etc. In fact, new and exciting applications of DL in NLP are among the reasons that the NLP market is expected to grow to tens of billions of dollars soon. Unfortunately, the use of DL within the Arabic NLP community is still limited even for NLP areas in which DL approaches are becoming dominant such as machine translation and sentiment analysis \cite{special_issue}.

The rest of this paper is organized as follows.
The next section presents a general literature survey of both research papers and existing tools for Arabic text diacritization.
The methodology we follow in benchmarking these tools and systems is discussed in Section~\ref{sec:method} including the benchmark dataset preparation steps and the different tools and systems/approaches under consideration. The results and discussion are given in Section~\ref{sec:res} before concluding the paper in Section~\ref{sec:conc}.

\begin{figure}
    \centering
    \includegraphics[width=0.5\textwidth]{tab1_1.jpg}
    \caption{The 36 Arabic letter variants.}
    \label{tab1_1}
\end{figure}

\begin{figure}
    \centering
    \includegraphics[width=0.5\textwidth]{tab1_2.jpg}
    \caption{The 8 Arabic basic diacritics on the Teh letter \cite{abandah2015automatic}.}
    \label{tab1_2}
\end{figure}

\section{Diacritization Systems and Approaches}
\label{sec:related}

There are two common approaches to address the Arabic text diacritization problem: rule-based approaches and machine learning (ML) approaches. The focus of this work is on the DL approach (a sub-field of ML) and we aim to show that it is superior to its publicly available competitors. This places it as the main benchmark system to beat by any future work.
The coverage given in this section is divided into two parts: DL-based (neural) approaches and baseline tools and systems.

\subsection{Neural Diacritization}

A recent survey on DL techniques for Arabic NLP tasks noted that limited attention has been paid to neural approaches for Arabic text diacritization \cite{dl4anlp}. On the other hand, there are some work published on non-neural approaches such as \cite{zitouni2009arabic,pasha2014madamira,shahrour2015improving,alnefaie2017automatic,bebah2014hybrid,chennoufi2017morphological,darwish2017arabic,fashwan2017shakkil,azmi2015survey}.
Such works are mainly based on linguistic rules and statistical treatments. For example, the MADAMIRA analyzer built by Pasha et al.~\cite{pasha2014madamira} provides diacritization, tokenization, part-of-speech tagging and other Arabic language processing tools, using morphological analysis.
Elshafei et al.~\cite{elshafei2006statistical} applied a statistical approach using hidden Markov model (HMM) to find the best diacritization format for words. This was done using Viterbi algorithm based on words' n-grams. They used Holy Quran as dataset.
Further discussion of the details of these approaches are outside the scope of this work. The only ones we discuss later are the ones with publicly available resources, which we use for comparison with the DNN approach.

Belinkov and Glass~\cite{belinkov2015arabic} presented a language-agnostic system for Arabic text diacritization. According to \cite{darwish2017arabic}, this is the only work on Arabic text diacritization that does not employ linguistic features and tools. The authors trained their system on diacritized text extracted from Arabic Treebank dataset without relying on additional resources. They used different types of neural networks in addition to letter embeddings to automatically diacritize Arabic text. The network types they considered are Feed-Forward, Long Short-Term Memory (LSTM), Bidirectional LSTM (B-LSTM) and stacked B-LSTM.
This approach is open-sourced and its results rival those of the state-of-the-art systems that rely on language-specific tools such as the MaxEnt approach of Zitouni and Sarikaya~\cite{zitouni2009arabic}.
A similar work done by Abandah et al.~\cite{abandah2015automatic} also used stacked B-LSTM on text extracted from Arabic Treebank, Tashkeela Corpus and the Holy Quran which achieved state-of-the-art performance after applying some language-related post-processing and error correction techniques.










Finally and most importantly, the open-source project Shakkala was built by Barqawi and Zerrouki~\cite{shakkala} for Arabic text diacritization using B-LSTM networks in addition to character embeddings. The model is depicted in Figure~\ref{fig:shakkala}.
The model was trained on Tashkeela Corpus several times while removing the data with negative influence on the training process.
The system provides the diacritization service through an interactive web interface, without providing an API.\footnote{\url{https://ahmadai.com/shakkala}}
The website allows users to diacritize text containing up to 490 symbols. An error message is given if the input is longer.
The code is publicly available on Github\footnote{\url{https://github.com/Barqawiz/Shakkala}}. It has three different trained models. The first (and earliest) version is used in the website, while the third (and latest) version provides the best results but is limited to 315 characters at a time.

\begin{figure}[h]
    \centering
    \includegraphics[width=0.5\textwidth]{shakkala.png}
    \caption{Shakkala model \cite{shakkala}.}
\label{fig:shakkala}
\end{figure}



\subsection{Baseline Systems}
\label{sec:tools}

Searching through the Internet reveals few websites offering to automatically diacritize Arabic text. They are discussed in this subsection.

\softpara{Ali-Soft:}
Ali-Soft\footnote{\url{http://www.ali-soft.com}} provides simple diacritization and text to speech (TTS) services through interactive web interface with additional features to style the text while diacritizing it.
Ali-Soft allows the users to update the final diacritization results using predefined list of probable diacritizations.

After few test cases, one can easily notice that this system does not diacritize each letter in each word. In fact, most of the times, it does not diacritize the last letters. Moreover, it has some errors as shown in the following examples that prohibits us from including it in our experiments.
\begin{quote}
\centering
\<
المسلم من سلم المسلمون من لسانه ويده
> \\
Buckwalter Transliteration: Almslm mn slm Almslmwn mn lsAnh wydh \\
The sentence before diacritization. \\
\<
المُسْلِم مِن سُلَّم المُسْلِمُونَ مِن لِسانهُ وَيَدْهَ
> \\
Buckwalter Transliteration: Almusolim min sulam Almusolimuwna min lisAnhu wayadoha \\
The sentence with Ali-Soft diacritization. \\
\<
اَلْمُسْلِمُ مَنْ سَلِمَ اَلْمُسْلِمُونَ مِنْ لِسَانِهِ وَيَدِهِ
> \\
Buckwalter Transliteration: Aalomusolimu mano salima Aalomusolimuwna mino lisaAnihi wayadihi \\
The correct diacritization. \\
\end{quote}
In addition to outputting incorrect diacritizations, Ali-Soft suffers from the following issues.

\begin{itemize}
\item It duplicates some letters as shown in the following examples.
\begin{center}
\begin{tabular}{|c|c|}
\hline
Input word & Output word \\ \hline
\<يؤذن> & 
\<يؤذنن> \\ \hline
\<ودونه> & 
\<ودوننه> \\ \hline
\<ثبت> & 
\<ثبتت> \\ \hline
\<رهنا> & 
\<رهننا> \\ \hline
\end{tabular}
\end{center}

\item Adding the Dagger Alif which is written as a short vertical stroke on top of an Arabic letter. It indicates a long \textipa{/a:/} sound where Alif is normally not written as shown in the following examples.
\begin{center}
\begin{tabular}{|c|c|}
\hline
Input word & Output word \\ \hline
\<الرحمن> & 
\<الرحمٰن> \\ \hline
\<الإلهية> & 
\<الإلٰهية> \\ \hline
\<هؤلاء> & 
\<هٰؤلاء> \\ \hline
\<اللهم> & 
\<اللٰهم> \\ \hline
\end{tabular}
\end{center}

\item Puts the Wasla sign on the letter (Alif) as shown in the following examples.
\begin{center}
\begin{tabular}{|c|c|}
\hline
Input word & Output word \\ \hline
\<ابن> & 
\<ٱبن> \\ \hline
\<امرأتان> & 
\<ٱمرأتان> \\ \hline
\<انقطع> & 
\<ٱنقطع> \\ \hline
\end{tabular}
\end{center}

\item It duplicates some words as shown in the following examples.
\begin{center}
\begin{tabular}{|c|c|}
\hline
Input word & Output word \\ \hline
\<الأنصارى> & 
\<الأنصاري الأنصاري> \\ \hline
\<يسارى> & 
\<يساري يساري يساري> \\ \hline
\<نفسى> & 
\<نفسي نفسي نفسي نفسي> \\ \hline
\<أى> & 
\<أي أي أي أي أي أي> \\ \hline
\end{tabular}
\end{center}
\end{itemize}

\softpara{Farasa:}
Farasa\footnote{\url{http://alt.qcri.org/farasa}} provides multiple Arabic NLP services and one of them is partial diacritization. These services are available through a web interface, an API and a standalone executable code.\footnote{\url{http://qatsdemo.cloudapp.net/farasa}}
However, like Ali-Soft, the diacritization system of Farasa has a few issues as shown in the following examples. These issues are more manageable compared with the ones suffered by Ali-Soft and we discuss in Section~\ref{sec:systems_issues} how to handle them before including Farasa in our comparison.
\begin{center}
\begin{tabular}{|c|c|}
\hline
Input word & Output word \\ \hline
\<لِلَّهِ> & 
\<لِاللَّهِ> \\ \hline
\<لِلَّذِي> & 
\<لِالَّذي> \\ \hline
\<مِنَّةٌ> & 
\<مِنَّةْهُ> \\ \hline
\end{tabular}
\end{center}

\softpara{Harakat:}
Harakat\footnote{\url{https://harakat.ae}} provides diacritization service through an interactive web interface and an API.\footnote{\url{https://multillect.com/en/apidoc}}
The interactive web interface allows users to diacritize text containing about 650 symbols (giving an error message for a longer text) and it takes about 3 to 5 seconds to diacritize them, while the API diacritizes 1M symbols for \\sim<\sim$amaA'i, kamo hiya jamiylapN !!! \\
Translation: Look at the sky, how beautiful it is!!!.
\end{quote}
Assuming that the system misclassifies the character
`\<ظ>'
with Fatha instead of Damma, then the DER/WER will be as shown in Tables~\ref{tab:newder} and \ref{tab:newwer}.

\begin{table*}
\centering
\caption{Comparison of our definition of DER and the definition of Zitouni and Sarikaya~\cite{zitouni2009arabic}}
\label{tab:newder}
\begin{tabular}{|c|c|c|c|c|}
\hline
\multirow{2}{*}{DER} & With case ending & Without case ending & With case ending & Without case ending \\ \cline{2-5} 
 & \multicolumn{2}{c|}{Including 'no diacritic'} & \multicolumn{2}{c|}{Excluding 'no diacritic'} \\ \hline
Ours
& 4.55\% & 6.25\% & 6.25\% & 9.09\% \\ \hline
Zitouni and Sarikaya~\cite{zitouni2009arabic} & 3.85\% & 5.56\% & 6.25\% & 9.09\% \\ \hline
\end{tabular}
\end{table*}

\begin{table*}
\centering
\caption{Comparison of our definition of WER and the definition of Zitouni and Sarikaya~\cite{zitouni2009arabic}}
\label{tab:newwer}
\begin{tabular}{|c|c|c|c|c|}
\hline
\multirow{2}{*}{WER} & With case ending & Without case ending & With case ending & Without case ending \\ \cline{2-5} 
 & \multicolumn{2}{c|}{Including 'no diacritic'} & \multicolumn{2}{c|}{Excluding 'no diacritic'} \\ \hline
Ours
& 16.67\% & 16.67\% & 16.67\% & 16.67\% \\ \hline
Zitouni and Sarikaya~\cite{zitouni2009arabic} & 12.50\% & 12.50\% & 12.50\% & 12.50\% \\ \hline
\end{tabular}
\end{table*}


Both DER and WER can be calculated with/without case ending, and with/without the `no diacritic' class \cite{zitouni2009arabic}.
\begin{itemize}
\item With/Without case ending: Determines whether to take the last letter diacritic into account or not. This is used because diacritizing the last letter is considered to be a harder problem compared to diacritizing other letters.

\item With/Without `no diacritic' class: Determines whether to take letters with no diacritic in the original data into account or not. This is used because some systems provide full diacritization and others provide partial diacritization.
\end{itemize}

\subsection{Systems Compared}
\label{sec:systems_issues}

The goal of this work is to show the superiority of the neural approach compared with other approaches. The neural approach we consider is Shakkala of Barqawi and Zerrouki~\cite{shakkala}. The reason for selecting this system is because the Shakkala code and the resources used to build it are publicly available.
As for the non-neural approaches, most of the ones mentioned in Section~\ref{sec:tools} are considered in our experiments. The following points are taken into account during the testing procedure.
\begin{itemize}
\item For all systems, after-Alif cases are changed to before-Alif during DER and WER calculation process to match the original dataset diacritization standard.

\item Ali-Soft testing was omitted due to the excessive amount of issues.

\item Farasa, MADAMIRA and Mishkal testing process had some issues which were manually fixed.

\item Harakat testing process skipped all 143 lines which had issues.

\item Shakkala testing data was split into lines of lengths not exceeding 315 characters because their third model was used in testing.
\end{itemize}

\section{Results and Discussion}
\label{sec:res}

In this section, we present the results of our experiments and discuss them.
The comparison results are provided in Tables~\ref{tab:der} and \ref{tab:wer} (best results are shown in bold).

\begin{table*}
\centering
\caption{DER results}
\label{tab:der}
\begin{tabular}{|c|c|c|c|c|}
\hline
\multirow{2}{*}{DER} & With case ending & Without case ending & With case ending & Without case ending \\ \cline{2-5} 
 & \multicolumn{2}{c|}{Including 'no diacritic'} & \multicolumn{2}{c|}{Excluding 'no diacritic'} \\ \hline
Farasa & 21.43\% & 23.93\% & 24.90\% & 27.55\% \\ \hline
Harakat & 18.37\% & 17.03\% & 20.64\% & 18.55\% \\ \hline
MADAMIRA (Aramorph) & 34.38\% & 29.94\% & 40.03\% & 33.87\% \\ \hline
Mishkal & 16.09\% & 13.78\% & 17.59\% & 14.22\% \\ \hline
Tashkeela-Model & 49.96\% & 52.96\% & 58.50\% & 60.92\% \\ \hline
Shakkala & \textbf{3.73\%} & \textbf{2.88\%} & \textbf{4.36\%} & \textbf{3.33\%} \\ \hline
\end{tabular}
\end{table*}

\begin{table*}
\centering
\caption{WER results}
\label{tab:wer}
\begin{tabular}{|c|c|c|c|c|}
\hline
\multirow{2}{*}{WER} & With case ending & Without case ending & With case ending & Without case ending \\ \cline{2-5} 
 & \multicolumn{2}{c|}{Including 'no diacritic'} & \multicolumn{2}{c|}{Excluding 'no diacritic'} \\ \hline
Farasa & 58.88\% & 53.13\% & 57.28\% & 51.84\% \\ \hline
Harakat & 41.83\% & 32.03\% & 38.33\% & 28.29\% \\ \hline
MADAMIRA (Aramorph) & 76.58\% & 59.07\% & 75.39\% & 57.22\% \\ \hline
Mishkal & 39.78\% & 26.42\% & 35.63\% & 21.92\% \\ \hline
Tashkeela-Model & 96.80\% & 94.16\% & 96.03\% & 92.45\% \\ \hline
Shakkala & \textbf{11.19\%} & \textbf{6.53\%} & \textbf{10.89\%} & \textbf{6.37\%} \\ \hline
\end{tabular}
\end{table*}



The results clearly show that the DL approach (Shakkala) is significantly better than all other approaches in terms of both DER and WER. Mishkal and Harakat are the best systems among the non-neural ones, but their performance in not comparable to Shakkala. Another advantage of Shakkala is its remarkable ability to handle the difficult case of diacritizing the last letter of each word.


\section{Conclusion}
\label{sec:conc}

According to many researchers such as Taha Zerrouki, diacritizing Arabic text is among the most challenging problems in Arabic NLP. In order to move towards providing effective solutions to this problem, open-source resources are needed. In this work, we present the first free-for-all cleaned benchmark dataset for this problem. Extracted from the Tashkeela Corpus, the dataset consists of 55K lines containing about 2.3M words. Moreover, we provide a critical review for the currently existing systems and tools for Arabic text diacritization and perform an empirical study to compare the performance of six of them on our dataset. Moreover, we revise the definitions of the most common accuracy measures used for Arabic text diacritization, viz., Diacritic Error Rate (DER) and Word Error Rate (WER). The revised measures do not take into account numbers and punctuations, which make them more strict. The results of our experiments show that the neural Shakkala system significantly outperforms traditional rule-based approaches and other closed-source tools with DER and WER values as low as 2.88\% and 6.37\%, respectively, compared with the lowest DER and WER values for a non-neural system (Mishkal) which are 13.78\% and 21.92\%, respectively.

\bibliographystyle{IEEEtran}
\bibliography{main}
\balance

\end{document}
