\documentclass{llncs}
\pagestyle{plain}
\usepackage{amsmath,amssymb}
\usepackage[boxed,noline,longend]{algorithm2e}
\usepackage{xspace}
\usepackage{graphicx,subfigure}
\usepackage{xcolor}

\graphicspath{{../figures/}}

\title{Quasi-Polynomial Local Search for Restricted Max-Min Fair Allocation\thanks{This research was supported by ERC Advanced investigator grants 228021 and 226203.}}
\author{Lukas Polacek\inst{1} and Ola Svensson\inst{2}}
\institute{KTH Royal Institute of Technology, Sweden
  \email{polacek@csc.kth.se}
  \and EPFL, Switzerland
  \email{ola.svensson@epfl.ch}
}
\date{\today}

\newcommand{\res}{\ensuremath{\mathcal{R}}\xspace}
\newcommand{\players}{\ensuremath{\mathcal{P}}\xspace}
\newcommand{\conf}[1]{\ensuremath{\mathcal{C}(#1)}}
\newcommand{\hide}[1]{}

\begin{document}
\maketitle

\begin{abstract}
The restricted max-min fair allocation problem (also known as the
restricted Santa Claus problem) is one of few problems that enjoys the
intriguing status of having a better estimation algorithm than
approximation algorithm. Indeed, Asadpour et al.~\cite{AFS08} proved
that a certain configuration LP can be used to estimate the optimal
value within a factor , for any , but at
the same time it is not known how to efficiently find a solution with
a comparable performance guarantee.

A natural question that arises from their work is if the difference
between these guarantees is inherent or because of a lack of suitable
techniques. We address this problem by giving a quasi-polynomial
approximation algorithm with the mentioned performance guarantee. More
specifically, we modify the local search of~\cite{AFS08} and provide a
novel analysis that lets us significantly improve the bound on its
running time: from  to . Our techniques also
have the interesting property that although we use the rather complex
configuration LP in the analysis, we never actually solve it and
therefore the resulting algorithm is purely combinatorial.
\end{abstract}

\section{Introduction}


We consider the problem of indivisible resource allocation in the
following classical setting: a set \res of available resources shall
be allocated to a set \players of players where the value of a set of
resources for player  is given by the function .
This is a very general setting and dependent on the specific goals of
the allocator several different objective functions have been studied.

One natural objective, recently studied
in~\cite{DS06,Feige06,FV06,Vondrak08}, is to maximize the social
welfare, i.e., to find an allocation  of
resources to players so as to maximize .  However, this approach is not suitable in settings
where the property of ``fairness'' is desired.  Indeed, it is easy to
come up with examples where an allocation that maximizes the social
welfare assigns all resources to even a single player. In this
paper we address this issue by studying algorithms for finding
``fair'' allocations. More specifically, fairness is modeled by
evaluating an allocation with respect to the satisfaction of the least
happy player, i.e., we wish to find an allocation  that maximizes
. In contrast to maximizing the
social welfare, the problem of maximizing fairness is already
-hard when players have linear value functions. In order
to simplify notation for such functions we denote  by
 and hence we have that . This problem has recently received
considerable attention in the literature and is often referred to as
the \emph{max-min fair allocation} or the \emph{Santa Claus} problem.

One can observe that the max-min fair allocation problem is similar to
the classic problem of scheduling jobs on unrelated machines to
minimize the makespan, where we are given the same input but wish to
find an allocation that minimizes the maximum instead of one that
maximizes the minimum. In a classic paper~\cite{LST90}, Lenstra,
Shmoys \& Tardos gave a -approximation algorithm for the scheduling
problem and proved that it is -hard to approximate the
problem within a factor less than . The key step of their
-approximation algorithm is to show that a certain linear program,
often referred to as the assignment LP, yields an additive
approximation of .  Bez\'akov\'a and
Dani~\cite{BD05} later used these ideas for max-min fair allocation to
obtain an algorithm that always finds a solution of value at least
, where  denotes the value of an optimal
solution. However, in contrast to the scheduling problem, this
algorithm and more generally the assignment LP gives no approximation
guarantee for max-min fair allocation in the challenging cases when
.

In order to overcome this obstacle, Bansal \& Sviridenko~\cite{BS06}
proposed a stronger linear program relaxation, known as the
configuration LP, for the max-min fair allocation problem. The
configuration LP that we describe in detail in Section~\ref{sec:CLP}
has been vital to the recent progress on better approximation
guarantees.  Asadpour \& Saberi~\cite{AS07} used it to obtain a
-approximation
algorithm which was later improved by Bateni et al.~\cite{Bateni09}
and Chakrabarty et al.~\cite{Chakrabarty09} to algorithms that return
a solution of value at least  in time
.

The mentioned guarantee  is rather
surprising because the integrality gap of the configuration LP is no
better than ~\cite{BS06}. However, in
contrast to the general case, the configuration LP is significantly
stronger for the prominent special case where values are of the form
. This case is known as the \emph{restricted}
max-min fair allocation or the restricted Santa Claus problem and is the focus of our
paper. The worst known integrality gap for the restricted case is
 and it is known~\cite{BD05} that it is -hard to beat
this factor (which is also the best known hardness result for the
general case).
Bansal \& Sviridenko~\cite{BS06} first used the configuration LP to
obtain an -approximation algorithm for the restricted max-min fair
allocation problem. They also proved several structural properties
that were later used by Feige~\cite{Feige08} to prove that the
integrality gap of the configuration LP is in fact constant in the
restricted case. The proof is based on repeated use of Lov\'{a}sz
local lemma and was turned into a polynomial time algorithm~\cite{HSS10}.

The approximation guarantee obtained by combining~\cite{Feige08}
and~\cite{HSS10} is a large constant and is far away from the best
known analysis of the configuration LP by Asadpour et
al.~\cite{AFS08}.
More specifically, they proved in~\cite{AFS08} that the integrality
gap is lower bounded by  by designing a beautiful local search
algorithm that eventually finds a solution with the mentioned
approximation guarantee, but is only known to converge in exponential
time.  As the configuration LP can be solved up to any precision in
polynomial time, this means that we can approximate the value of an
optimal solution within a factor  for any  but it is not known how to efficiently find a solution with a
comparable performance guarantee. Few other problems enjoy this
intriguing status (see e.g. the overview article by
Feige~\cite{FeigeSurv08}). One of them is the restricted assignment
problem\footnote{Also here the restricted version of the  problem is the special case where  ( instead of  since we are minimizing).},
  for which the second author in \cite{SME11} developed the techniques
from~\cite{AFS08} to show that the configuration LP can be used to
approximate the optimal makespan within a factor 
improving upon the -approximation by Lenstra, Shmoys \&
Tardos~\cite{LST90}. Again it is not known how to efficiently find a
schedule of the mentioned approximation guarantee. However, these
results indicate that an improved understanding of the configuration
LP is likely to lead to improved approximation algorithms for these
fundamental allocation problems.


In this paper we make progress that further substantiates this
point. We modify the local search of~\cite{AFS08} and present
a novel analysis that allows us to significantly improve the bound on the
running time from an exponential guarantee to a quasi-polynomial
guarantee.
\begin{theorem}
\label{thm:main}
  For any , we can find a
  -approximate solution to  restricted
  max-min fair allocation in time , where .
\end{theorem}

In Section~\ref{sec:algodesc}, we give an overview of the local search
of~\cite{AFS08} together with our modifications. The main modification
is that at each point of the local search, we carefully select which step
to take in the case of several options, whereas in the original
description~\cite{AFS08} an arbitrary choice was made. We then use
this more stringent description with a novel analysis (Section~\ref{sec:algoanal})
that uses the dual of the configuration LP as in~\cite{SME11}. The
main advantage of our analysis (of the modified local search) is that
it allows us to obtain a better upper bound on the search space of the
local search and therefore also a better bound on the run-time.
Furthermore, our techniques have the interesting property that
although we use the rather complex configuration LP in the analysis,
we never actually solve it.  This gives hope to the interesting
possibility of a polynomial time algorithm that is purely
combinatorial and efficient to implement (in contrast to solving the
configuration LP) with a good approximation ratio.

Finally, we note that our approach currently has a similar dependence on
 as in the case of solving the configuration LP since, as
mentioned above, the linear program itself can only be solved
approximately. However, our hidden constants are small and for a
moderate  we  expect that our combinatorial approach is
already more attractive than solving the configuration LP.



\section{The Configuration LP}
\label{sec:CLP}
The intuition of the configuration linear program (LP) is that any
allocation of value  needs to allocate a bundle or configuration
 of resources to each player  so that .  Let
 be the set of those configurations that have value at
least  for player . In other words,  contains all
those subsets of resources that are feasible to allocate to player 
in an allocation of value . For a guessed value of , the
configuration LP therefore has a decision variable  for each
player  and configuration  with the
intuition that this variable should take value one if and only if the
corresponding set of resources is allocated to that player. The configuration LP
 is a feasibility program and it is defined as follows:

            \sum_{C\in \conf{i,T}} x_{i,C} &\geq 1  &  i \in \players \1mm]
            x & \geq 0
          
The first set of constraints ensures that each player should receive
at least one bundle and the second set of constraints ensures that a
resource is assigned to at most one player.

If  for some  is feasible, then  is also feasible for all
, because  and thus a solution to
 is a solution to  as well. Let 
be the maximum of all such values. Every
feasible allocation is a feasible solution of configuration LP, hence
 is an upper bound on the value of the optimal allocation.

We note that the LP has exponentially many constraints; however, it is
known that one can approximately solve it to any desired
accuracy by designing a polynomial time (approximate) separation algorithm for the
dual~\cite{BS06}. Although our approach does not require us to solve the linear
program, the dual shall play an important role in our analysis.  By
associating a variable  with each constraint in the first set of
constraints, a variable  with each constraint in the second set of
constraints, and letting the primal have the objective function of
minimizing the zero function, we obtain the dual program:

            \max & \mbox{  } \sum_{i\in \players} y_i - \sum_{j\in \res} z_j  && \1mm]
            y,z & \geq 0
          
\section{Local Search with Better Run-time Analysis}

In this section we modify the algorithm by Asadpour et
al.~\cite{AFS08} in order to significantly improve the run-time
analysis: we obtain a -approximate solution in
run-time bounded by  whereas the original
local search is only known to converge in time . For better
comparison, we can write . Moreover, our modification has the nice side effect
that we actually never solve the complex configuration LP --- we only
use it in the analysis.

\subsection{Description of Algorithm}
\label{sec:algodesc}
Throughout this section we assume that  --- the guessed optimal value --- is such that  is feasible. We
shall find an  approximation where  is a parameter such that
. As we will see, the selection of  has the following
trade-off: the closer  is to  the worse bound on the run-time we get.

We note that if  is not feasible and thus  is more than ,
our algorithm makes no guarantees. It might fail to find an allocation, which
means that . We can use this for a standard binary search  on the
interval  so that in the end we find an
allocation with a value at least .

\subsubsection{Max-min fair allocation is a bipartite hypergraph problem.}
Similar to~\cite{AFS08}, we view the max-min fair allocation problem as a
matching problem in the bipartite hypergraph . Graph 
has an hyperedge  for each player  and
configuration  that is feasible with respect to the desired
approximation ratio , i.e., , and minimal in the
sense that  for all . Note that the graph
might have exponentially many edges and the algorithm therefore never keeps
an explicit representation of all edges.

From the construction of the graph it is clear that a matching covering all
players corresponds to a solution with value at least . Indeed, given
such a matching  in this graph, we can assign matched resources to the
players and everyone gets resources with total value of at least .

\subsubsection{Alternating tree of ``add'' and ``block'' edges.}

The algorithm of Asadpour et al.~\cite{AFS08} can be viewed as
follows. In the beginning we start with an empty matching and then we
increase its size in every iteration by one, until all players are
matched. In every iteration we build an alternating tree rooted in a
currently unmatched player  in the attempt to find an alternating
path to extend our current matching . The alternating tree has two
types of edges: edges in the set  that we wish to \emph{add} to the
matching and edges in the set  that are currently in the matching
but intersect edges in  and therefore \emph{block} them from being
added to the matching. While we are building the alternating tree to
find an alternating path, it is important to be careful in the
selection of edges, so as to guarantee eventual termination. As
in~\cite{AFS08}, we therefore define the concept of addable and
blocking edges.

Before giving these definitions, it will be convenient to introduce
the following notation. For a set of edges , we denote by 
all resources contained in edges in  and similarly 
denotes all players contained in edges in . We also write 
instead of  for an edge  and use  to denote
the player in .

\begin{definition}
We call an edge  addable if  and
.
\end{definition}
\begin{definition}
An edge  in the matching  is blocking  if
.
\end{definition}
Note that an addable edge matches a player in the tree with resources
that currently do not belong to any edge in the tree and that the
edges blocking an edge  are exactly those in the matching that
prevent us from adding . For a more intuitive understanding of
these concepts see Figure \ref{fig:alter-tree} in Section \ref{sec:example}.

The idea of building an alternating tree is similar to standard matching
algorithms using augmenting paths. However, one key difference is that the matching can be
extended once an alternating path is found in the graph case, whereas
the situation is more complex in the considered hypergraph case, since
a single hyperedge might overlap several hyperedges in the matching. It is due
to this complexity that it is more difficult to bound the running time
of the hypergraph matching algorithm of~\cite{AFS08} and our improved
running time is obtained by analyzing a modified version where we
carefully select in which order the edges should be added to the
alternating tree and drop edges from the tree beyond certain distance.

We divide resources into 2 groups. \emph{Fat resources} have value at least
 and \emph{thin resources} have less than . Thus any edge
containing a fat resource contains only one resource and is called \emph{fat
edge}. Edges containing thin resources are called \emph{thin edges}. Our
algorithm always selects an addable edge of minimum distance to the root 
according to the following convention. The length of a thin edge in the tree is
one and the length of a fat edge in the tree is zero. Edges not in the tree have
infinite length. Hence, the \emph{distance of a vertex} from the root is the
number of thin edges between the vertex and the root and, similarly, the
\emph{distance of an edge } is the number of thin edges on the way to 
from  including  itself. We also need to refer to distance of an
addable edge that is not yet in the tree. In that case we take the distance as
if it was in the tree. Finally, by the \emph{height of the alternating tree} we
refer to the maximum distance of a resource from the root.

\subsubsection{Algorithm for extending a partial matching.}
\begin{algorithm}[h!]
\DontPrintSemicolon
\caption{Increase the size of the matching}
\label{increase-match}
\SetKwInOut{Input}{Input}\SetKwInOut{Output}{Output}
\Input{A partial matching }
\Output{A matching of increased size assuming that  is at most }
\BlankLine
 Find an unmatched player , make it a root of the alternating tree\;
\While{there is an addable edge within distance }{
  \Indp
  Find an addable edge  of minimum distance from the root\;
  \;
  \eIf { has blocking edges } {
    \Indp
    \;
    \Indm
  }(\tcp*[h]{collapse procedure})
  {
    \Indp
    \While{ has no blocking edges} {
      \Indp
      \eIf {there is an edge  such that } {
        \Indp
        \;
        \;
        \;
        Let  be the edge that  was blocking\;
        \;
        \Indm
      }
      {
        \Indp
        \;
        \Return \;
        \Indm
      }
    \Indm
    }
    Let  be the blocking edge that was last removed from \;
    Remove all edges in  of greater distance than  and the edges in  that blocked these edges\;
\Indm
  }
}
\Return  is less than 
\end{algorithm}

Algorithm \ref{increase-match} summarizes the modified procedure for increasing
the size of a given matching by also matching a previously unmatched player
. For better understanding of the algorithm, we included an example of an
algorithm execution in Figure \ref{fig:alter-tree} in Section
\ref{sec:example}.

Note that the algorithm iteratively tries to find addable edges of
minimum distance to the root. On the one hand, if the picked edge 
has blocking edges that prevents it from being added to the matching,
then the blocking edges are added to the alternating tree and the
algorithm repeatedly tries to find addable edges so as to make
progress by removing the blocking edges.

On the other hand, if edge  has no blocking edges, then this means that the set of
resources  is free, so we make progress by adding  to the matching . If the
player was not previously matched, it is the root  and we
increased the size of the matching. Otherwise the player 
was previously matched by an edge  such that
, so we remove  from  and thus
it is not a blocker anymore and can be removed
from . This removal has decreased the number of blockers for an
edge . If  has  blockers, we recurse and repeat the same
procedure as with . Note that this situation can be seen on Figure
\ref{fig:alt-2} and \ref{fig:alt-3} in Section \ref{sec:example}.


\subsection{Example of Algorithm Execution}
\label{sec:example}
\begin{figure}[h]
  \begin{center}
    \begin{tabular}{| c | c |}
      \hline
      \subfigure[Step 1]{
        \includegraphics[page=1, width=0.39\textwidth]{matching-example-1}
        \label{fig:alt-1}
      }&
      \subfigure[Step 2]{
        \includegraphics[page=2, width=0.39\textwidth]{matching-example-1}
        \label{fig:alt-2}
      }\\
      \hline
      \subfigure[Step 3]{
        \includegraphics[page=3, width=0.39\textwidth]{matching-example-1}
        \label{fig:alt-3}
      }&
      \subfigure[Step 4]{
        \includegraphics[page=4, width=0.39\textwidth]{matching-example-1}
        \label{fig:alt-4}
      }\\
      \hline
    \end{tabular}
  \end{center}
  \caption{Alternating tree visualization. The right part of every picture
  is the alternating tree and to the left we display the positions of edges in
  the tree in the bipartite graph. Gray edges are in the set  and white edges
  are in the set .}
  \label{fig:alter-tree}
\end{figure}

Figure \ref{fig:alter-tree} is a visualization of an execution of Algorithm
\ref{increase-match}. The right part of every picture is the alternating tree
and to the left we display the positions of edges in the tree in the bipartite
graph.  Gray edges are -edges and white are -edges.

In Figure \ref{fig:alt-1} we start by adding an -edge to the tree. There are
2 edges in the matching intersecting this edge, so we add them as blocking
edges. Then in Figure \ref{fig:alt-2} we add a fat edge that has no blockers, so
we add it to the matching and thus remove one blocking edge, as we can see in
Figure \ref{fig:alt-3}. Then in Figure \ref{fig:alt-4} we add a thin edge which
has no blockers. Now the  and  edges form an alternating path, so by
swapping them we increase the size of the matching and the algorithm terminates.

Note that the fat edge in step 2 is added before the thin edge from step 4,
because it has shorter distance from the root . Recall that the distance of
an edge  is the number of thin edges between  and the root including ,
thus the distance of the fat edge is 2 and the distance of the thin edge is 3.

\subsection{Analysis of Algorithm}

\label{sec:algoanal}

Let the parameter  of the algorithm equal  for some
. We first prove that Algorithm~\ref{increase-match} terminates in
time  where 
and, in the following subsection, we show that it returns a matching of
increased size if  is feasible.

Theorem~\ref{thm:main}~then follows from that, for each guessed value of ,
Algorithm~\ref{increase-match} is at most invoked  times and we can find the
maximum value  for which our algorithm finds an allocation by binary search
on the interval . Since we can assume that the numbers in the
input have bounded precision, the binary search only adds a polynomial factor to
the running time.

\subsubsection{Run-time Analysis.}
We bound the running time of Algorithm~\ref{increase-match} using that
the alternating tree has height at most
. The proof is similar to the termination proof
in~\cite{AFS08} in the sense that we associate a signature vector with
each tree and then show that its lexicographic value
decreases. However, one key difference is that instead of associating a
value with \emph{each edge} of type  in the tree, we associate a
value with each ``layer'' that consists of \emph{all edges} of a certain
distance from the root. This allows us to directly associate the
run-time with the height of the alternating tree.

When considering an alternating tree it is convenient to partition  and 
into  and  respectively by the
distance from the root, where  is the maximum distance of an edge in the
alternating tree (it is always an even number). Note that  is empty for all
odd . Also,  contains only fat edges and  only thin edges.
For a set of edges  we denote by  all the thin edges in  and by 
all the fat edges in .  For a set of edges  denote by  all the thin
edges in  and by  all the fat edges in . We also use  to
denote thin resources and  to denote fat resources.

\begin{lemma}
\label{lemma:termination}
For a desired approximation guarantee of , Algorithm~\ref{increase-match} terminates in time
.\end{lemma}
\begin{proof}
We analyze the run-time of Algorithm~\ref{increase-match} by
associating a signature vector with the alternating tree of each
iteration. The signature vector of an alternating tree is then defined to be


We prove that each addition of an edge decreases the lexicographic value of
the signature or increases the size of the matching.

On the one hand, if we add an edge with no blocking edges, we either completely
collapse the alternating tree or collapse only a part of it.
If we completely collapse the tree then the algorithm terminates. Otherwise, let
 be the last blocking edge that was removed from  by the algorithm during
the collapse procedure. Also let  and  be the sets of  blocking edges
and addable edges obtained after the collapse procedure. Note that  is a
thin edge because otherwise  was blocking a fat edge  that after the
removal of  had no more blocking edges which in turn contradicts that 
was the last blocking edge removed from . Let  be the distance of
, i.e., . As the algorithm drops all edges in  of
distance at least  and all edges in  that  blocked these edges, the
partial collapse of the tree changes its 
signature to  which equals

Thus we either
increase the size of the matching or decrease the signature of the alternating
tree.

On the other hand, if the added edge  has blocking edges, there are two
cases. We either open new layers  and  where  is a
thin edge and the signature gets smaller, since . If we do
not open a new layer, we increase the size of some  by either a thin or fat edge and
, so in this case the signature decreases too.

The algorithm only runs as long as the height of the alternating tree is at most
. This can
be rewritten as

where the equality follows from  for  and we only
consider . There are at most
 possible values for each position in a signature, so the total
number of signatures encountered during the execution of
Algorithm~\ref{increase-match} is . As adding an edge happens in polynomial time in , we conclude that Algorithm~\ref{increase-match} terminates
in time . \qed
\end{proof}


\subsubsection{Correctness of Algorithm~\ref{increase-match}.}
\label{sec:correctness}
We show that Algorithm~\ref{increase-match} is correct, i.e., that it
returns an increased matching if  is feasible.

We have already proved that the algorithm terminates in
Lemma~\ref{lemma:termination}. The statement therefore follows from
proving that the condition of the while loop always is satisfied
assuming that the configuration LP is feasible. In other words, we
will prove that there always is an addable edge within the required
distance from the root. This strengthens the analogous statement
of~\cite{AFS08} that states that there always is an addable edge (but
without the restriction on the search space that is crucial for our run-time analysis).  We shall do so by proving
that the number of thin blocking edges increases quickly with respect
to the height of the alternating tree and, as there cannot be more
than  blocking edges, this in turn bounds the height of
the tree.

We are now ready to state the key insight behind the analysis that shows that
the number of blocking edges increases as a function of  and the height
of the alternating tree.
\begin{lemma}
Let . Assuming that  is feasible, if there is no
addable edge  within distance  from the root for some integer , then

\label{lem:combinatorial}
\end{lemma}

Before giving the proof of Lemma \ref{lem:combinatorial}, let us see how it
implies that there always is an addable edge within distance  from the root assuming the configuration LP
is feasible, which in turn implies the correctness of
Algorithm~\ref{increase-match}.

\begin{corollary}
  \label{cor:height}
  If  and  is feasible, then there is always an addable edge
  within distance  from the root, where .
\end{corollary}
\begin{proof}
The proof of the corollary follows intuitively from that Lemma~\ref{lem:combinatorial} says that
the number of blocking edges increases  exponentially in terms of the height of the tree and
therefore, as there are at most  blocking edges, the height must be . We now proceed with the formal proof.

Let us first consider the case when , i.e., there are no
thin edges in the alternating tree, so its height is . Then there must be an
addable edge (of distance at most ), since otherwise, by the above lemma, we
get a contradiction .

From now on assume that  and suppose toward contradiction that
there is no addable edge within distance . Let

By Lemma~\ref{lem:combinatorial},

so  for all , which in turn implies

where the last equality follows by the selection of .  However, this is a
contradiction since the number of blocking edges and hence  is at
most the number of players .
\qed

\end{proof}
We complete the correctness analysis of the algorithm by presenting the  proof of the key lemma.

\begin{proof}[Lemma~\ref{lem:combinatorial}]
Let  be the tree formed from the original alternating tree by taking
all edges of distance at most  plus edges in the set . The
following invariant holds throughout the execution of Algorithm
\ref{increase-match} and plays an important role in the analysis:
If there is an addable edge  with respect to  within distance
, then  is an addable edge within distance  with respect to the
original tree. Hence, in the proof of this lemma we only need to consider edges
in . The invariant trivially holds in the beginning of the algorithm
and is preserved when adding an edge with blockers, because an edge of minimum
distance is selected. The situation is more complex when an edge has no
blockers. Dropping off the edges beyond certain distance in Algorithm
\ref{increase-match} ensures that the invariant remains true even in this case.

Suppose toward contradiction that there is no addable edge within
distance  and

We show that this implies that the dual of the configuration LP is
unbounded, which in turn contradicts the assumption that the primal is feasible.
Recall that the objective function of the dual is .  Furthermore, as each solution  of the dual can
be scaled by a scalar  to obtain a new solution , any
solution with positive objective implies unboundedness.

We proceed by defining such solution , that is determined by the alternating tree.
More precisely, we take

and


Let us first verify that  is indeed a feasible solution. We have
chosen all  to be non-negative, so it only remains to check the first
condition of the dual. Let  and let  be such that , i.e., . We distinguish between the two cases when  and . On the one hand, if  we have that
, since  is always non-negative.

On the other hand, if , then we have two sub-cases.
Either there is  for some  and we have
.  Otherwise , where  is the set of resources which
are assigned positive value . Suppose , then there is a set 
with  and thus  is an addable edge in
 and hence an addable edge within distance  in the original tree.
This contradicts the assumption that no such addable edges
exist, so .

Having proved that  is a feasible solution, the proof is
now completed by showing that the value of the solution is positive.
We have

since each player in the alternating tree has its unique blocking edge leading
to it except the root. For fat resources we have

since every fat edge contains only one fat resource by minimality.

For thin resources,

since the size of each thin edge is at most  and the part of each
blocking edge not contained in any other -edge is at most of size ,
because otherwise the set of resources in the blocking edge would not be a
minimal set.

We also have  for any , since each adding edge has to
have at least one blocking edge.
This implies

By the assumption toward contradiction,

This implies

so the dual is unbounded and we get a contradiction. \qed
\end{proof}

\section{Conclusions}
Asadpour et al. \cite{AFS08} raised as an open question whether their local
search (or a modified variant) can be shown to run in polynomial time. We made
progress toward proving this statement by showing that a modified local search
procedure finds a solution in quasi-polynomial time. Moreover, based on our
findings, we conjecture the stronger statement that there is a local search
algorithm that does not use the LP solution, i.e., it is combinatorial, and it
finds a -approximate solution in polynomial time for any fixed
.

\section{Acknowledgements}

We are grateful to Ji\v{r}\'{i} Sgall and Martin B\"{o}hm for pointing out a mistake in the description of the
algorithm and in the signature vector used in the runtime analysis  of an earlier version
of this paper.

\bibliographystyle{splncs03}
\bibliography{santa}



\end{document}
