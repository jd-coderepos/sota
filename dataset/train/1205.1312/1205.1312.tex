\documentclass[english, oribibl]{llncs}

\usepackage{llncsdoc}

\usepackage[T1]{fontenc}
\usepackage[latin9]{inputenc}
\usepackage{hyperref}
\usepackage{verbatim}
\usepackage{amsfonts}
\usepackage{amsmath}
\usepackage{multirow}
\usepackage{url}

\usepackage{graphicx}
\usepackage{amsfonts}
\usepackage{courier}
\usepackage[usenames]{color}
\usepackage{bm}
\usepackage{times}
\begin{comment}

\newtheorem{theorem}{Theorem}[section]
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{proposition}[theorem]{Proposition}
\newtheorem{lem}[theorem]{Lemma}
\newtheorem{fact}[theorem]{Fact}
\newtheorem{corollary}[theorem]{Corollary}
\newtheorem{conjecture}[theorem]{Conjecture}
\newtheorem{claim}[theorem]{Claim}
\newtheorem{obs}[theorem]{Observation}
\newtheorem{prop}[theorem]{Proposition}
\newtheorem{definition}[theorem]{Definition}
\newtheorem{rem}[theorem]{Remark}
\newtheorem{construction}[theorem]{Construction}

\newenvironment{remark}{\noindent{\bf Remark}\hspace*{1em}}{\bigskip}

\newenvironment{proofof}[1]{\noindent{\bf Proof
(of #1):~}}{}


\renewcommand{\paragraph}[1]{\noindent {\bf #1}}
\addtolength{\parskip}{-.0ex}


\end{comment}
\newenvironment{sketch}{\noindent{\bf Proof [Sketch]:~~}}{}


\newcommand{\dsum}{\displaystyle\sum}
\newcommand{\Exp}{\operatornamewithlimits{\mathbb{E}}}
\newcommand{\cube}{\operatorname{\{0, 1\}}}
\newcommand{\pcube}{\operatorname{\{\pm1\}}}
\newcommand{\eps}{\epsilon}
\newcommand{\lin}{\textsc{linear}}

\newcommand{\fe}{\mathbb{F}}
\newcommand{\F}{\mathbb{F}}
\newcommand{\C}{\mathbb{C}}
\newcommand{\R}{\mathbb{R}}
\newcommand{\Z}{{\mathbb Z}}
\newcommand{\N}{{\mathbb N}}
\newcommand{\calf}{{\cal F}}
\newcommand{\calA}{{\cal A}}
\newcommand{\calm}{{\cal M}}

\newcommand{\mcA}{{\mathcal A}}
\newcommand{\mcB}{{\mathcal B}}
\newcommand{\mcX}{{\mathcal X}}
\newcommand{\mcY}{{\mathcal Y}}
\newcommand{\mcR}{{\mathcal R}}
\newcommand{\mcF}{{\mathcal F}}
\newcommand{\mcD}{{\mathcal D}}

\newcommand{\red}{\mathbf{red}}
\newcommand{\blue}{\mathbf{blue}}
\newcommand{\green}{\mathbf{green}}
\newcommand{\cyan}{\mathbf{cyan}}
\newcommand{\true}{\mathbf{true}}
\newcommand{\false}{\mathbf{false}}
\newcommand{\ith}[1]{{#1}^{\text{th}}}
\newcommand{\supp}[1]{\mathrm{supp}(#1)}
\newcommand{\ord}[1]{\mathrm{ord}(#1)}

\newcommand{\mygamma}{L}



\newcommand{\rednote}[1]{\textcolor{red}{#1}}
\newcommand{\greennote}[1]{\textcolor{green}{#1}}
\newcommand{\bluenote}[1]{\textcolor{blue}{#1}}
\newcommand{\cyannote}[1]{\textcolor{cyan}{#1}}
\newcommand{\ignore}[1]{}
\newcommand{\sidenote}[1]{ \marginpar{\tiny\bf
             \begin{minipage}[t]{0.5in}
               \raggedright #1
            \end{minipage}}}

\DeclareMathOperator*{\argmax}{argmax}





\makeatother

\usepackage{babel}
\makeatother

\begin{document}

\title{Converting Online Algorithms to Local Computation Algorithms}
\author{
Yishay Mansour\inst{1} 
\thanks{\email{mansour@post.tau.ac.il}. Supported in part by the Google Inter-university center
for Electronic Markets and Auctions, by a grant from the Israel
Science Foundation, by a grant from United States-Israel Binational
Science Foundation (BSF), by a grant from Israeli Centers of Research Excellence (ICORE), and by a grant from the Israeli Ministry
of Science (MoS).}
\and
Aviad Rubinstein\inst{1}
\thanks{ \email{aviadrub@mail.tau.ac.il}.}
\and
Shai Vardi\inst{1}
\thanks{\email{shaivar1@post.tau.ac.il}. Supported in part by the Google Inter-university center
for Electronic Markets and Auctions }
\and
Ning Xie\inst{2}
\thanks{\email{ningxie@csail.mit.edu}. Supported by NSF grants CCF-0728645, CCF-0729011 and CCF-1065125.}
 \institute{School of Computer Science, Tel Aviv University, Israel
\and CSAIL, MIT, Cambridge MA 02139, USA}
}


\date{}

\setcounter{page}{1}
\setcounter{secnumdepth}{3}
\maketitle

\begin{abstract}

We propose a general method for converting online algorithms to local computation algorithms,\footnote{For a given input , \emph{local computation algorithms} support queries by a user to values of specified locations  in a legal output .} by selecting a random permutation of the input, and simulating running the online algorithm. We bound the number of steps of the algorithm using a \emph{query tree}, which models the dependencies between queries. We improve previous analyses of query trees on graphs of bounded degree, and extend the analysis to the cases where the degrees are distributed binomially, and to a special case of bipartite graphs.



Using this method, we give a local computation algorithm for maximal matching in graphs of bounded degree, which runs in time and space .

We also show how to convert a large family of load balancing algorithms (related to balls and bins problems) to local computation algorithms. This gives several local load balancing algorithms which achieve the same approximation ratios as the online algorithms, but run in  time and space.

Finally, we modify existing local computation algorithms for hypergraph -coloring and -CNF and use our improved analysis to obtain better time and space bounds, of , removing the dependency on the maximal degree of the graph from the exponent.
\end{abstract}

\section{Introduction}
\label{section:introduction}

\subsection{Background}
The classical computation model has a single processor which has
access to a given input, and using an internal memory, computes the
output. This is essentially the von Newmann architecture, which has
been the driving force since the early days of computation.
The class of polynomial time algorithms is widely accepted as the
definition of {\em efficiently computable} problems.
Over the years many interesting variations of this basic model have
been studied, focusing on different issues.




Online algorithms (see, e.g., \cite{BEY98}) introduce limitations in the time domain. An online
algorithm needs to select actions based only on the history it
observed, without access to future inputs that might influence its
performance. Sublinear algorithms (e.g. \cite{MR06, PR07}) limit the space domain, by
limiting the ability of an algorithm to observe the entire input,
and still strive to derive global properties of it.

Local computation algorithms (LCAs) \cite{RTVX11} are a variant of
sublinear algorithms.
The LCA model considers a computation problem which might have
multiple admissible solutions,  each consisting of multiple bits. The
LCA can return queries regarding parts of the output, in a consistent
way, and in poly-logarithmic time. For example, the input for an LCA
for a job scheduling problem consists of the description of  jobs
and  machines. The admissible solutions might be the allocations
of jobs to machines such that the makespan is at most twice the optimal
makespan. On any query of a job, the LCA answers quickly the job's machine.
The correctness property of the LCA guarantees that different query
replies will be consistent with some admissible solution.









\subsection{Our results}


Following  \cite{ARV+11}, we use an abstract tree structure - \emph{query trees} to bound the number of queries performed by certain algorithms. We use these bounds to improve the upper bound the time and space requirements of several algorithms introduced in \cite{ARV+11}. We also give a generic method of transforming online algorithms to LCAs, and apply it to obtain LCAs to maximal matching and several load balancing problems.


\subsubsection{Bounds on query trees}

Suppose that we have an online algorithm where the reply to a query depends
on the replies to a small number of previous queries. The reply to each of those previous queries depends on the replies to a small number of other queries and so on. These dependencies can be used to model certain problems using \emph{query trees} -- trees which model the dependency of the replies to a given query on the replies to other queries. 


Bounding the size of a query tree is central to the analyses of our algorithms.  We show that the size of the query tree is   w.h.p., where  is the number of vertices. , the degree bound of the dependency graph, appears in the constant. \footnote{Note that, however, the hidden constant is exponentially dependent on . Whether or not this bound can be improved to have a polynomial dependency on  is an interesting open question.} This answers in the affirmative the conjecture of \cite{ARV+11}.
Previously, Alon et al. \cite{ARV+11} show that the expected size of the query tree is constant, and   w.h.p.\footnote{Notice that bounding the expected size of the query tree is not enough for our applications, since in LCAs we need to bound the probability that \emph{any} query fails.} Our improvement is significant in removing the dependence on  from the exponent of the logarithm. 
 We also show that when the degrees of the graph are distributed binomially, we can achieve the same bound on the size of the query tree. In addition, we show a trivial lower bound of .
 
We use these results on query trees to obtain LCAs for several online problems -- maximal matching in graphs of bounded degree and several load balancing problems. We also use the results to improve the previous algorithms for hypergraph -coloring and -CNF. 

\subsubsection{Hypergraph -coloring}
We modify the algorithm of \cite{ARV+11} for an LCA for hypergraph -coloring, and coupled with our improved analysis of query tree size, obtain an LCA which runs in time and space , improving the previous result, an LCA which runs   time and space. 

\subsubsection{-CNF}
Building on the similarity between hypergraph -coloring and -CNF, we  apply our results on hypergraph -coloring to give an an LCA for -CNF which runs in time and space .\\

We use the query tree to transform online algorithms to LCAs. We simulate online algorithms as follows: first a random permutation
of the items is generated on the fly. Then, for each query, we simulate the online algorithm on a stream of input items arriving according to
the order of the random permutation. Fortunately, because of the nature of our graphs (the fact that the degree is bounded or distributed binomially), we show that in expectation, we will only need to query a constant number of nodes, and only  nodes w.h.p. We now state our results:

\subsubsection{Maximal matching}
We simulate the greedy online algorithm for maximal matching, to derive an LCA for maximal matching which runs in time and space .

\subsubsection{Load Balancing}
 We give several LCAs to load balancing problems which run in  time and space. Our techniques include extending 
 the analysis of the query tree size to  the case where the degrees are
selected from a binomial distribution with expectation , and further extending it to bipartite graphs which exhibit 
the characteristics of many balls and bins problems, specifically ones where each ball chooses  bins at random. We show how to convert a large class of the ``power of  choices'' 
online algorithms (see, e.g., \cite{ABK+99, BCS+06, TW07}) to efficient
LCAs.


\subsection{Related work}
Nguyen and Onak \cite{NO08} focus on transforming classical approximation algorithms into constant-time algorithms that approximate the size of the optimal solution of problems such as vertex cover and  maximum matching. They generate a random number , called the rank, for each node. These ranks are used to bound the query tree size. 

Rubinfeld et al. \cite{RTVX11} show how to construct polylogarithmic time local computation algorithms to maximal independent set computations, scheduling radio network broadcasts, hypergraph coloring and satisfying k-SAT formulas. Their proof technique uses Beck's analysis in
his algorithmic approach to the Lov{\'{a}}sz Local Lemma \cite{Bec91}, and a reduction from distributed algorithms. 
Alon et al. \cite{ARV+11}, building on the technique of \cite{NO08}, show how to extend several of the algorithms of \cite{RTVX11} to perform in polylogarithmic space as well as time. They further observe that we do not actually need to assign each query  a rank, we only need a random permutation of the queries. Furthermore, assuming the query tree is bounded by some , the query to any node depends on at most  queries to other nodes, and so a -wise independent random ordering suffices. They show  how to construct a -almost -wise independent random ordering\footnote{A random ordering  is said to be \emph{-almost -wise independent} if the statistical distance between  and some -wise independent random ordering by at most .} from a seed of length . 





Recent developments in sublinear time algorithms for sparse graph and
combinatorial optimization problems have led to new constant time
algorithms for approximating the size of a minimum vertex cover, maximal matching, 
maximum matching, minimum dominating set, and other problems (cf. \cite{PR07, MR06, NO08, YYI09}), by 
randomly querying a constant number of vertices.
A major difference between these algorithms and LCAs is that LCAs require that w.h.p., the 
output will be correct on any input, while optimization problems usually require a correct output only on \emph{most} inputs. More importantly, LCAs reuire a consistent output for each query, rather than only approximating a given global property.

There is a vast literature on the topic of balls and bins and the power of  choices. (e.g. \cite{ABK+99, BCS+06, DR96, TW07}). For a survey on the power of  choices, we refer the reader to \cite{MRR01}.





\subsection{Organization of our paper}

The rest of the paper is organized as follows:
Some preliminaries and notations that we use throughout the paper appear in Section \ref{section:preliminaries}.
In Section \ref{section:tree_size} we prove the upper bound of  on 
the size of the query tree in the case of bounded and binomially distributed degrees.
In section \ref{hypergraph}, we use this analysis to give improved algorithms for hypergraph -coloring and -CNF.
In Section \ref{section:matching} we give an LCA for finding a maximal matching in graphs of bounded degree. 
Section \ref{section:load_balancing} expands our query tree result to a special case of bipartite graphs;
we use this bound for bipartite graph to convert online algorithms for balls and bins into LCAs for the same problems.
The appendices provide in-depth discussions of the hypergraph -coloring and analogous -CNF LCAs, and a lower bound to the query tree size.




\section{Preliminaries}\label{section:preliminaries}



Let  be an undirected graph.
We denote by  
the neighbors of vertex , and by  we denote the degree of .
When it is clear from the context, we omit the  in the subscript.
Unless stated otherwise, all logarithms in this paper are to the base .
We use  to denote the set , where  is a natural number. 


We present our model of local computation algorithms (LCAs):
Let  be a computational problem and  be an input to .
Let  .
The {\em search problem} for  is to find any .


A {\em -local computation algorithm} 
is a (randomized) algorithm which solves a search problem for  for an input  of size .
However, the LCA  does not output a solution , but rather
implements query access to .  receives a sequence of queries  and for any  satisfies the following:
(1) after each query  it produces an output ,
(2) With probability at least   is \emph{consistent}, that is, the outputs  are substrings of some .
(3)  has access to a random tape and local computation memory on which
it can perform current computations as well as store and retrieve information from previous computations.

We assume that the input , the local computation tape and any
random bits used are all presented in the RAM word model, i.e.,
 is given the ability to access a word of any of these in one step.
The running time of  on any query is at most , which is sublinear in ,
and the size of the local computation memory of  is at most .
Unless stated otherwise, we always assume that the error parameter
 is at most some constant, say, .
We say that   is a {\em strongly local computation algorithm}
if both  and  are upper bounded by  for some constant .

Two important properties of LCAs are as follows.
We say an LCA  is \emph{query order oblivious} (\emph{query oblivious} for short)
if the outputs of  do not depend on the order of the queries but
depend only on the input and the random bits generated on the random tape of .
We say an LCA  is \emph{parallelizable} if 
supports parallel queries, that is  is able to answer multiple queries
simultaneously so that all the answers are consistent.



\section{Bounding the size of a random query tree}
\label{section:tree_size}

\subsection{The problem and our main results}\label{Sect:query_tree}

In online algorithms, queries arrive in some unknown order, and the reply to each query depends only on previous queries (but not on any future events). The simplest way to transform online algorithms to LCAs is to process the queries in the order in which they arrive. This, however, means that we have to store the replies to all previous queries, so that even if the time to compute each query is polylogarithmic, the overall space is linear in the number of queries. Furthermore, this means that the resulting LCA is not query-oblivious. The following solution can be applied to this problem (\cite{NO08} and \cite{ARV+11}): Each query  is assigned a random number,  , called its \emph{rank}, and the queries are performed in ascending order of rank. Then, for each query , a query tree can be constructed, to represent the queries on which  depends. If we can show that the query tree is small, we can conclude that each query does not depend on many other queries, and therefore a small number of queries need to be processed in order to reply to query .  We formalize this as follows: 


Let  be an undirected graph. The vertices of the graph represent queries, and the edges represent the dependencies between the queries.
A real number  is assigned independently and uniformly at random to every vertex
; we call  the \emph{rank} of . This models the random permutation of the vertices.
Each vertex   holds an input , where the range  is some finite set. The input is the content of the query associated with .
A randomized function  is defined inductively on the vertices of  such that
 is a (deterministic) function of  as well as the values of  at the neighbors  of 
for which .  models the output of the online algorithm.
We would like to upper bound the number of queries to vertices in the graph needed in order to compute  for any vertex , namely, the time to simulate the output of query  using the online algorithm.


To upper bound the number of queries to the graph, we turn to a simpler task of bounding the size
of a certain -regular tree, which is an upper bound on the number of queries.
Consider an infinite -regular tree  rooted at .
Each node  in  is assigned independently and uniformly at random a real number
.
For every node  other than  in ,
let  denote the \text{parent} node of .
We grow a (possibly infinite) subtree  of  rooted at  as follows:
a node  is in the subtree  if and only if  is in  and
 (for simplicity we assume all the ranks are distinct real numbers).
That is, we start from the root , add all the children of  whose ranks are smaller than that
of  to . We keep growing  in this manner where a node  is a leaf node in 
if the ranks of its  children are all larger than .
We call the random tree  constructed in this way a \emph{query tree} and
we denote by  the random variable that corresponds to the size of .
Note that  is an upper bound on the number of queries since
each node in  has at least as many neighbors as that in  and
if a node is connected to some previously queried nodes, this can only decrease
the number of queries. Therefore the number of queries is bounded by the size of .
Our goal is to find an upper bound on  which holds with high probability. 


We improve the upper bound on the query tree of  given in \cite{ARV+11}  for the case when the degrees are bounded by a constant 
and extend our new bound to the case that the degrees of  are binomially distributed, independently and identically with expectation , i.e.,
.


Our main result in this section is bounding, with high probability, the size of the query tree  as follows. 















\begin{lemma}
\label{lemma:boundomial}
Let  be a graph whose vertex degrees are bounded by  or distributed independently and identically from the binomial distribution:  . Then there exists a constant  which depends only on , such that
\begin{center}
,
\end{center}
where the probability is taken over all the possible permutations  of the vertices of , and  is a random query tree in  under .
\end{lemma}

\subsection{Overview of the proof}

Our proof of Lemma \ref{lemma:boundomial} consists of two parts. Following~\cite{ARV+11}, we partition the query tree into levels.
The first part of the proof is an upper bound on the size of a single (sub)tree on any level.
For the bounded degree case, this was already proved in ~\cite{ARV+11} (the result is restated as Proposition~\ref{lemma:bounded}).




We extend the proof of ~\cite{ARV+11} to the binomially distributed degrees case. In both cases the bound is that with high probability each subtree is of size at most logarithmic in the size of the input.

The second part, which is a new ingredient of our proof,
inductively upper bounds the number of vertices on each level, as the levels increase.
For this to hold, it crucially depends on the fact that all subtrees are generated independently and that the probability of any subtree being large is exponentially small.
The main idea is to show that although each subtree, in isolation, can reach a logarithmic size, their combination is not likely to be much larger. We use the distribution of the sizes of the subtrees, in order to bound the aggregate of multiple subtrees.





\subsection{Bounding the subtree size}



As in \cite{ARV+11}, we partition the query tree into levels and then upper bound
the probability that a subtree is larger than a given threshold.
Let  be a function of  to be determined later.
First, we partition the interval [0,1] into  sub-intervals:
,
for  and .
We refer to interval  as \emph{level} .
A vertex  is said to be on level  if .
We consider the worst case, in which .
In this case, the vertices on level  form a tree  rooted at .
Denote the number of (sub)trees on level   by .
The vertices on level  will form a set of trees ,
where the total number of subtrees is at most the sum of the children of all the vertices in 
(we only have inequality because some of the children of the vertices of 
may be assigned to levels  and above.)
The vertices on level  form a set of subtrees .
Note that all these subtrees  are generated independently by the same stochastic process, as the ranks of all nodes in  are i.i.d. random variables. In the following analysis, we will set .



For the bounded degree case, bounding the size of the subtree follows from \cite{ARV+11}:





\begin{proposition} [\cite{ARV+11}] \footnote{In \cite{ARV+11}, this lemma is proved for the case of . This immediately establishes Proposition \ref{lemma:bounded}, since the worse case is .}
\label{lemma:bounded}
Let  be a fixed integer
and let  be the -regular infinite query tree.
Then for any  and ,
,
for all , where  is some constant.
In particular, there is an absolute constant  depending on  only such that
for all ,

\end{proposition}



\subsubsection{The binomially distributed degrees case}
\label{subtree_app}

We are interested in bounding the subtree size also in the case that the degrees are not a constant , but rather selected independently and identically from a binomial distribution with mean .
\begin{proposition}
\label{lemma:binomial}
 Let  be a tree with vertex degree distributed i.i.d. binomially with . For any  and any ,
,
 for , for some constant .
\end{proposition}



\begin{proof}
The proof of Proposition~\ref{lemma:binomial} is similar to the proof of Proposition ~\ref{lemma:bounded} in \cite{ARV+11};
we employ the theory of Galton-Watson processes.
For a good introduction to Galton-Watson branching processes see e.g. \cite{Har63}.

Consider a Galton-Watson process defined by the probability function
, with  and .
Let 
be the generating function of .
For  let  be the number of offsprings in the  generation.
Clearly  and  form a Markov chain.
Let  be the expected number of children of any individual.
Let  be the sum of all offsprings in all generations of the Galton-Watson process.
The following result of Otter is useful in bounding the probability that  is large.

\begin{theorem}[\cite{Ott49}]\label{thm:Otter}
Suppose  and that there is a point  within the circle of convergence of 
for which . Let .
Let , where  stands for greatest common divisor.
Then


In particular, if the process is \emph{non-arithmetic}, i.e. ,
and  is finite, then

and consequently .
\end{theorem}




We prove Proposition \ref{lemma:binomial} for the case of tree  -- the proof actually applies
to all subtrees .
Recall that  is constructed inductively as follows:
for  in , we add  to  if
 and .
Then for each  in , we add the neighbors  in 
to  if  and .
We repeat this process until there is no vertex that can be added to .


Once again, we work with the worst case that .
To upper bound the size of , we consider a related random process which also
grows a subtree of  rooted at , and denote it by .
The process that grows  is the same as that of 
except for the following difference: if  and  is a child vertex of  in ,
then we add  to  as long as . In other words, we give up the requirement that .
Clearly, we always have  and hence .\\


Note that the random process that generates  is in fact a Galton-Watson process,
as the rank of each vertex in  is independently and uniformly distributed in .
We take vertex  to be the parent node. Since ,
then for any vertex , ,
the probability that  is a child node of  in  is

as the random process that connects  to  and
the random process that generates the rank of  are independent
(each edge is chosen with probability , and the probability that  is in ).
It follows that we have a binomial distribution for the number of child nodes of  in :

where  is the probability that a child vertex in 
appears in  when its parent vertex is in .
Note that the expected number of children of a vertex in  is ,
so from the classical result on the extinction probability of Galton-Watson processes (see e.g. \cite{Har63}),
the tree  is finite with probability one.

The generating function of  is

as the probability function  obeys the binomial distribution 
where .
In addition, the convergence radius of  is 
since  has only a finite number of non-zero terms.



Solving the equation  yields
 and hence
.
Consequently, solving for  gives


We can lower bound  as


Finally we calculate :

therefore  is a bounded constant.





Now applying Theorem~\ref{thm:Otter} to the Galton-Watson process
which generates  (note that  in our case) gives that, there exists a constant 
such that for ,
 for some constant .
It follows that 
for all .
Hence for all large enough , with probability at least , . \qed
\end{proof}


The following corollary stems directly from Propositions  \ref{lemma:bounded} and \ref{lemma:binomial}:
\begin{corollary}\label{corr:boundomial}
Let  be  any infinite -regular query tree or tree with vertex degree distributed i.i.d. binomially with .
For any  and any ,
with probability at least , .
\end{corollary}





\subsection{Bounding the increase in subtree size as we go up levels}


\label{section:increase}

From Corollary \ref{corr:boundomial} we know that the size of any subtree, in particular ,
is bounded by  with probability at least 
in both the degree  and the binomial degree cases.
Our next step in proving
Lemma \ref{lemma:boundomial} 
is to show that, as we increase the levels,
the size of the tree does not increase by more than a constant factor for each level.
That is, there exists an absolute constant  depending on  only
such that if the number of vertices on level  is at most ,
then the number of vertices on level ,  satisfies
. Since there are  levels in total, this implies that
the number of vertices on all  levels is at most
.


The following Proposition establishes our inductive step.
\begin{proposition}
\label{infinite}
For any infinite query tree  with constant bounded degree  (or degrees i.i.d. ), for any ,
there exist constants  and 
s.t. if  
then   for all ,
for some .
\end{proposition}


\begin{proof}
Denote the number of vertices on level  by  and let .
Assume that each vertex  on level  is the root of a tree of size  on level .
Notice that .

By Proposition~\ref{lemma:bounded} (or Proposition~\ref{lemma:binomial}),
there are absolute constants  and  depending on  only such that
for any subtree  on level  and any ,
.
Therefore, given  ,
the probability of the forest on level  consisting of exactly trees of size
 is at most .

Notice that, given  (the number of nodes up to level ), there are at most   vectors  that can realize . 

We want to bound the probability that  for some (large enough) constant .
We can bound this as follows:





It follows that there is some absolute constant  which depends on  only such that
.
That is, if ,
the probability that  is at most .
Adding the vertices on all  levels and applying the union bound, we
conclude that with probability at most , the size of  is at most . \qed
\end{proof}


\begin{comment}
\subsection{Tightness of the bound}
Our bound of  on the size of the tree is tight.
\begin{theorem}
For any graph  with bounded degree ,  ,
there is a constant  which depends only on  such that for all large enough ,
\begin{center}

\end{center}
\end{theorem}
\begin{proof}
Consider a path of length  from .
The probability that the rank of every vertex  on the path is less than the rank of
 is . \qed

\end{proof}

\end{comment} 





\section{\texorpdfstring{Hypergraph -coloring and -CNF}{Hypergraph 2-coloring and k-CNF}}
\label{hypergraph}
We use the bound  on the size of the query tree of graphs of bounded degree to improve the analysis of \cite{ARV+11} for hypergraph -coloring. We also modify their algorithm slightly to further improve the algorithm's complexity.
As the algorithm is a more elaborate version of the algorithm of \cite{ARV+11} and the proof is somewhat long, we only state our main theorem for hypergraph -coloring; we defer the proof to  Appendix \ref{app_hypergraph}.
\begin{theorem}
Let  be a -uniform hypergraph s.t. each hyperedge intersects at most  other hyperedges.
Suppose that . \\
Then there exists an  -local computation algorithm which, given  and any sequence of
queries to the colors of vertices  , 
with probability at least ,
returns a consistent coloring for all 's which 
agrees with a -coloring of . 
Moreover, the algorithm is query oblivious and parallelizable. 
\end{theorem}

Due to the similarity between hypergraph -coloring and -CNF, we also have the following theorem; the proof is in Appendix \ref{kcnf}.
\begin{theorem}
Let  be a -CNF formula with . 
Suppose that each clause intersects no more than  other clauses,
and furthermore suppose that .\\
Then there exists a -local computation algorithm which, given a formula  and any sequence of
queries to the truth assignments of variables , 
with probability at least ,
returns a consistent truth assignment for all 's which agrees with some 
satisfying assignment of the -CNF formula . 
Moreover, the algorithm is query oblivious and parallelizable. 
\end{theorem}

\section{Maximal matching}
\label{section:matching}

We consider the problem of \emph{maximal matching in a bounded-degree graph}. We are given a graph , where the maximal degree is bounded by some constant , and we need to find a maximal matching.A matching is a set of edges with the property that no two edges share a common vertex. The matching is maximal if no other edge can be added to it without violating the matching property. 


 Assume the online scenario in which  the edges arrive in some unknown order. The following greedy online algorithm can be used to calculate a maximal matching: When an edge  arrives, we check whether  is already in the matching. If it is not, we check if any of the neighboring edges are in the matching. If none of them is, we add  to the matching. Otherwise,  is not in the matching.

We turn to the local computation variation of this problem.  We would like to query, for  some edge , whether  is part of some maximal matching. (Recall that all replies must be consistent with some maximal matching).



We use the technique of \cite{ARV+11} to produce an almost -wise independent random ordering on the edges, using a seed length of .\footnote{Since the query tree is of size  w.h.p., we don't need a complete ordering on the vertices; an almost -wise independent ordering suffices.} When an edge  is queried, we use a BFS (on the edges) to build a DAG rooted at . We then use the greedy online algorithm on the edges of the DAG (examining the edges with respect to the ordering),  and see whether  can be added to the matching. 

As the query tree is an upper-bound on the size of the DAG,  we derive the following theorem from Lemma \ref{lemma:boundomial}.
\begin{theorem}
\label{thm:maximal}
Let  be an undirected graph with  vertices and maximum degree .
Then there is an 
   - local computation algorithm 
which, on input an edge , 
decides if  is in a maximal matching.
Moreover, the algorithm gives a consistent maximal matching
for every edge in .
\end{theorem}





\section{The bipartite case and local load balancing}
\label{section:load_balancing}

We consider a general ``power of  choices'' online algorithm for load balancing. In this setting there are  balls that arrive in an online manner, and  bins.
Each ball selects a random subset of  bins, and queries these bins. (Usually the query is simply the current load of the bin.) Given this information, the ball is assigned to one of the  bins (usually to the least loaded bin). We denote by  such a generic algorithm (with a decision rule which can depend in an arbitrary way on the  bins that the ball is assigned to). Our main goal is to simulate such a generic algorithm.

The load balancing problem can be represented by a bipartite graph ,
where the balls are represented by the vertices  and the bins by the vertices .
The random selection of a bin   by a ball  is represented by an edge.
By definition, each ball  has degree . 
Since there are random choices in the algorithm  we need to specify what we mean by a simulation. For this reason we define the input to be the following:
a graph 
  , where , , and  for some constant . We also allocate a rank  to every . This rank represents the ball's arrival time: if  then vertex  arrived before vertex . Furthermore, all vertices can have an input value . (This value represents some information about the node, e.g., the weight of a ball.)
Given this input, the algorithm  is deterministic, since the arrival sequence is determined by the ranks, and the random choices of the balls appear as edges in the graph. Therefore by a simulation we will mean that given the above input, we generate the same allocation as .





We consider the following stochastic process: 
Every vertex  uniformly and independently at random chooses  vertices in .
Notice that from the point of view of the bins,
the number of balls which chose them is distributed binomially with .
Let  and  be the random variables for the number of neighbors of vertices  and  respectively.
By definition, , since all balls have  neighbors, and hence
each  is independent of all 's.
However, there is a dependence between the 's (the number of balls connected to different bins).
Fortunately this is a classical example where the random variables are negatively dependent (see e.g. \cite{DR96}).
\footnote{We remind the reader that two random variables  and  are negatively dependent if
, for  and vice-versa.}

\subsection{The bipartite case}
Recall that in Section \ref{section:tree_size},
we assumed that the degrees of the vertices in the graph were independent.
We would like to prove an  upper bound on the query tree  for our bipartite graph.  As we cannot use the theorems of Section \ref{section:tree_size}
directly, we show that the query tree is smaller than another query tree which meets the conditions of our theorems.

The query tree for the binomial graph is constructed as follows: a root  is selected for the tree. ( is the ball whose bin assignment we are interested in determining.)            Label the vertices at depth  in
the tree by . Clearly, . At each depth , we add vertices one at a time to the tree, from left to right, until the depth is "full" and then we 
move to the next depth. Note that at odd depths () we add bin vertices and at even depths () we add ball vertices.

Specifically, at odd depths () we add, for each  its  neighbors  as children, and mark each by .\footnote{A bin can appear several times in the tree. 
It appears as different nodes, but they are all marked so that we know it is the same bin. Recall that we assume that all nodes are unique, as this assumption can only increase the size of the tree.}
At even depths () we add for each node marked by  all its (ball) neighbors  such that , if they have not already been added to the tree. Namely, all the balls that are assigned to  by time


A leaf is a node marked by a bin  for whom all neighboring balls  have a rank larger than its parent, i.e., . Namely,  is the first ball to be assigned to bin .
This construction defines a stochastic process ,
where  is (a random variable for) the size of  at time . (We start at  and  increases by  for every vertex we add to the tree).

We now present our main lemma for bipartite graphs.
\begin{lemma}
\label{lemma:bipartite}
Let  be a bipartite graph,  and  and  for some constant , such that for each
vertex  there are  edges chosen independently and at random between  and . Then there is a constant
 which depends only on  such that 
\begin{center}
,
\end{center}
where the probability is taken over all of the possible permutations  of the vertices of , and  is a random query tree in  under .
\end{lemma}


























\begin{comment}
We define the following local version of this problem:
Given  balls, 
(each with a rank chosen uniformly at random from ) and   bins, and  choices for each ball,
for each query , find a consistent allocation for  such that the maximum load on the bins is minimized.
Recall that by \emph{consistent} we mean that for each query the output is consistent with some global
allocation , in which the maximum load is minimized.
We refer to this problem as \emph{Local Balls and Bins} problem.
\end{comment}


\label{bipartite_proof}

To prove Lemma \ref{lemma:bipartite}, we look at another stochastic process , which constructs a tree :
we start with  a root . Label the vertices at depth  in
the tree by . Assign every vertex  that is added to the tree a rank  independently and uniformly at random. Similarly to , . At odd depths () we add to each ,  children (from left to right).  At even depths () we add to each node ,  children, where  and the  of different nodes are i.i.d. Of the nodes added in this level, we remove all those vertices  for which .





Importantly, the neighbor distributions of the vertices in the tree are independent of each other.
If at any point  has ``more than half the bins'', i.e., the sum of nodes on odd levels is at least , we add  bin children of rank  to some even-level node in the tree.

Given a tree  we define  to be the tree  with the
odd levels deleted, and a node  in level  is connected to node  in level  if .


\begin{lemma}
\label{lemma:T'}
There is a constant  which depends only on  such that for all large enough ,

\end{lemma}

Because , we immediately get the following corollary:

\begin{corollary}
\label{corr:T'}
There is a constant  which depends only on  such that for all large enough ,

\end{corollary}


We first make the following claim:
\begin{claim}
  has vertex degree distributed i.i.d. binomially with   .
\end{claim}

\begin{proof}
Each  has  children, each with degree distributed binomially . 
 For any independent r.v.'s  where , , we know that
 .  The Claim follows. \qed
\end{proof}


We can now turn to the proof of Lemma  \ref{lemma:T'}:

\begin{proof}

As long as , the proof of the lemma follows the proof of Lemma \ref{lemma:boundomial}
with slight modifications to constants and will therefore be omitted. 

We notice that  w.p. at least : the proof of  Lemma \ref{lemma:boundomial} is inductive - we show that at level ,
the size of the subtree is at most , and then bound the increase in tree size
as we move to the next level. 
By the level ,  w.p. at least . Therefore 
it follows that  w.p. at least . \qed
\end{proof}

Before we can complete the proof of Lemma \ref{lemma:bipartite}, we need to define the notion of first order stochastic dominance:

\begin{definition}[First order stochastic dominance]
We say a random variable  \emph{first order stochastically dominates} (\emph{dominates} for short)
a random variable  if  for all  and  for some .
If  dominates , then we write .
\end{definition}
\begin{lemma}
\label{lemma:stochastic dominance}
For every ,  first-order stochastically dominates . \end{lemma}

\begin{proof}
Assume we add a (bin) vertex  to  at time , the random variable for the number of 's neighbors
is negatively dependent on all other , . We label this variable , . 

We first show that  when  has less than  bins, and then show that  when  has more than  bins. (It is easy to see why this is enough).\\
Assume .  is dependent on at most  other random variables, . Because the dependency is negative,   is maximized when . Therefore, in the worst case,  is dependent on  bins with  children. If  bins have  children, all edges in  must be distributed between the remaining bins. Therefore , where .\\
When  has more than  bins, by the construction of , it has more than  vertices, and so  trivially dominates . \qed
\end{proof}

Combining Corollary \ref{corr:T'} and Lemma \ref{lemma:stochastic dominance} completes the proof of Lemma \ref{lemma:bipartite}. 
\subsection{Local load balancing}
The following theorem states our basic simulation result.

\begin{theorem}\label{thm:local_bb}
Consider a generic online algorithm  which requires constant time per query, for  balls and  bins, where  for some constant .
There exists an
-local computation algorithm
which, on query of a (ball) vertex ,
allocates  a (bin) vertex , such that the resulting allocation is identical to that of  with probability at least .
\end{theorem}

\begin{proof}
Let  for some constant  depending only on .
 is the upper bound given in Lemma~\ref{lemma:bipartite}.
(In the following we make no attempt to provide the exact values for  or .)

We now describe our -local computation algorithm for .
A query to the algorithm is a (ball) vertex  and the
algorithm will chose a (bin) vertex   from the  (bin) vertices  connected to .

We first build a query tree as follows:
Let  be the root of the tree. For every , add to the tree the neighbors of ,
 such that .
Continue inductively until either  nodes have been added to the random query tree
or no more nodes can be added to it.
If  nodes have been added to the query tree, this is a failure event, and assign to  a random bin in .
From Lemma~\ref{lemma:bipartite}, this happens with probability at most ,
and so the probability that some failure event will occur is at most .
Otherwise, perform  on all of the vertices in the tree,
in order of addition to the tree, and output the bin to which ball  is assigned to by . \qed
\end{proof}

A reduction from various load balancing algorithms gives us the following corollaries to Theorem \ref{thm:local_bb}.

\begin{corollary}  (Using \cite{BCS+06}) 
Suppose we wish to allocate  balls into  bins of uniform capacity, , where each ball chooses  bins independently and uniformly at random. There exists 
a  LCA which allocates the balls in such a way that the load of the most loaded bin is  w.h.p.
\end{corollary}

\begin{corollary} (Using  \cite{Voc03}) 
Suppose we wish to allocate  balls into  bins of uniform capacity, where each ball chooses  bins independently at random, one from each of  groups of almost equal size . There exists 
a  LCA, which allocates the balls in such a way that the load of the most loaded bin is  w.h.p.
\footnote{In fact, in this setting the tighter bound is
, where  is the ratio of the -step Fibonacci sequence, i.e. 
, 
where for , , , and for   }
\end{corollary}

\begin{corollary} (Using  \cite{BBFN10}) 
Suppose we wish to allocate  balls into  bins, where each bin  has a capacity , and . Each ball chooses  bins at random with probability proportional to their capacities. There exists a   LCA which allocates the balls in such a way that the load of the most loaded bin is  w.h.p.
\end{corollary}

\begin{corollary} (Using  \cite{BBFN10}) 
Suppose we wish to allocate  balls into  bins, where each bin  has a capacity , and . Assume that the size of a large bin is at least , for large enough . Suppose we have  small bins with total capacity , and that . There exists a   LCA which allocates the balls in such a way that the expected maximum load is less than .
\end{corollary}

\begin{corollary} (Using  \cite{BCM03}) 
Suppose we have  bins, each represented by one point on a circle, and  balls are to be allocated to the bins. Assume each ball needs to choose  points on the circle, and is associated with the bins closest to these points. There exists a   LCA which allocates the balls in such a way that the load of the most loaded bin is  w.h.p.
\end{corollary}


\subsection{Random ordering}
In the above we assume that we are given a random ranking for each ball.
If we are not given such random rankings
(in fact, a random permutation of the vertices in  will also suffice),
we can generate a random ordering of the balls.
Specifically, since w.h.p. the size of the random query is ,
 an \emph{-wise independent random ordering}\footnote{
 See~\cite{ARV+11} for
the formal definitions of -wise independent random ordering and almost -wise independent random ordering.}
suffices for our local computation purpose.
Using the construction in~\cite{ARV+11} of
-almost -wise independent random ordering over the vertices in 
which uses space , we obtain
  -local
computation algorithms for balls and bins.









\newpage

\bibliographystyle{plain}
\bibliography{makespan-Bib}
\newpage

\appendix


\newcommand{\polylog}[1]{\mathrm{polylog}(#1)}
\newcommand{\ttwo}{\log n}

\section{Hypergraph two-coloring}\label{Sec:hypergraph}
\label{app_hypergraph}
Recall that a \emph{hypergraph}  is a pair  where  is a finite set whose elements are
called \emph{nodes} or \emph{vertices}, and  is a family of non-empty subsets of , 
called \emph{hyperedges}. 
A hypergraph is called \emph{-uniform} if each of its
hyperedges contains precisely  vertices.
A \emph{two-coloring} of a hypergraph  is a mapping 
such that no hyperedge in  is monochromatic.
If such a coloring exists, then we say  is \emph{two-colorable}.
We assume that each
hyperedge in  intersects at most  other hyperedges.
Let  be the number of hyperedges in . Here we think of  and  as fixed constants
and all asymptotic forms are with respect to .
By the Lov{\'{a}}sz Local Lemma,
when , the hypergraph  is
two-colorable (e.g. \cite{Alo91}).

Following~\cite{RTVX11b}, we let  be the total number of vertices in . 
Note that , so .
For any vertex , we use  to denote the set of hyperedges  belongs to.
For any hypergraph ,
we define a \emph{vertex-hyperedge incidence matrix} 
so that, for every vertex  and every hyperedge , 
 if and only if .
Because we assume both  and  are constants, 
the incidence matrix  is necessarily very sparse. 
Therefore, we further assume that the matrix  is implemented via
linked lists for each row (that is, vertex ) and each column (that is, hyperedge ). 

Let  be the \emph{dependency graph} of the hyperedges in . 
That is, the vertices of the undirected graph 
are the  hyperedges of  and a hyperedge  is connected to
another hyperedge  in  if .
It is easy to see that if the input hypergraph is given in the 
above described representation, then we can find all the neighbors of any hyperedge  
in the dependency graph  (there are at most  of them) in constant time (which depends on  and ).

A natural question to ask is:
Given a two-colorable hypergraph , and a vertex ,
can we \emph{quickly} compute the coloring of ?
Alon et al. gave (\cite{ARV+11}) a -time and space LCA
based on Alon's 3-phase parallel hypergraph coloring algorithm (\cite{Alo91}),
where the exponent of the logarithm depends on .
We get rid of the dependence on  (in the exponent of the logarithm)
using the improved analysis of the query tree in section \ref{section:tree_size},
together with a modified 4-phase coloring algorithm.

Our main result in this section is,
given a two-colorable hypergraph  whose two-coloring scheme is guaranteed by
the Lov{\'{a}}sz Local Lemma (with slightly weaker parameters),
we give a  - local computation algorithm.
We restate our main theorem:

\begin{theorem}
Let  be a -uniform hypergraph s.t. each hyperedge intersects at most  other hyperedges.
Suppose that . \\
Then there exists an  -local computation algorithm which, given  and any sequence of
queries to the colors of vertices  , 
with probability at least ,
returns a consistent coloring for all 's which 
agrees with a -coloring of . 
Moreover, the algorithm is query oblivious and parallelizable. 
\end{theorem}


In fact, we only need:

Throughout the following analysis, we set: 
, and 
Notice that the theorem's premise simply implies that , as required by the Lov{\'{a}}sz Local Lemma.



\subsection{The general phase - random coloring}
In each phase we begin with subsets  and  of  and ,
such that each edge contains at least  vertices.
We sequentially assign colors at random to the vertices, as long as every monochromatic edge
has at least  uncolored vertices.
Once the phase is over we do not change this assignment.

If an edge has all of its vertices besides  colored in one color, it is labeled \emph{dangerous}. 
All the uncolored vertices in a dangerous edge are labeled \emph{saved} and we do not color them in this phase.
We proceed until all vertices in  are either red, blue, or saved.
Let the \emph{survived} hyperedges be all the edges that do not contain both red and blue vertices.
Each survived edge contains some vertices colored in one color, and at least  saved vertices.

Let  be the set of survived edges after a random coloring in Phase , and consider , the restriction of  to 
The probability that  contains a connected component of size  at most  (\cite{Alo91}).
In particular, after repeating the random coloring procedure  times, 
there is no connected component of size greater than  with probability


If the query vertex  has been assigned a color in the -th phase, we can simply return this color.
Otherwise, if it is a saved vertex we let  be the connected component containing  in .
Finally, since the coloring of  is independent of all other uncolored vertices,
we can restrict ourselves to  in the next phase.





\begin{figure*}
\begin{center}

\fbox{
\begin{minipage}{4.5in}
\small
\textbf{LCA for \emph{Hypergraph Coloring}}\\
Preprocessing:
\vspace{-2mm}
\begin{enumerate}
\item Generate  independent ensembles, consisting each of 
	-wise independent random variables in 
\item Generate , a -almost -wise independent random ordering over 
\end{enumerate}
\textbf{Phase :}\\
Input: a vertex \\
Out\=put\=: a color in \{\emph{red}, \emph{blue}\}
\vspace{-2mm}
\begin{enumerate}

\item Use BFS to find the query tree  rooted at , based on the ordering 
\item Randomly color the vertices in  according to the order defined by 
\item If  is colored \emph{red} or \emph{blue}, return the color
\item Else:
\begin{enumerate}
\item Starting from \footnote{
  Recall that  is the set of hyperedges containing .} 
  run BFS in \footnote{
   denotes the set of survived hyperedges in .}
   in order to find the connected component
    of \emph{survived} hyperedges around 
\item Let  be the set of uncolored vertices in  \\
	 Run \textbf{Phase  Coloring}(, , )
\end{enumerate}
\end{enumerate}
\end{minipage}
}
\end{center}
\caption{Local computation algorithm for \emph{Hypergraph Coloring}}
\label{Fig:coloring}
\end{figure*}



\subsection{Phase 1: partial random coloring}
In the first phase we begin with the whole hypergraph, i.e. , , and . 
Thus, we cannot even assign a random coloring to all the vertices in sublinear complexity.
Instead, similarly to the previous sections, we randomly order the vertices of the hypergraph and use a query tree
to randomly assign colors to all the vertices that arrive before  and may influence it.
Note that this means that we can randomly assign the colors only once.

If  is a saved vertex, we must compute , 
the connected component containing  in .
Notice that the size  is bounded w.h.p.


In order to compute , we run BFS on .
Whenever we reach a new node, we must first randomly assign colors to the vertices in its query tree,
like we did for 's query tree.
Since (w.h.p.) there are at most  edges in , we query for trees of vertices in at most  edges.
Therefore in total we color at most  vertices.

Finally, since we are only interested in  vertices,
we may consider a coloring which is only -wise independent,
and a random ordering which is only -almost -independent.
Given the construction in ~\cite{ARV+11}, this can be done in space and time complexity 

\begin{figure*}
\begin{center}
\fbox{
\begin{minipage}{4.5in}
\small
\textbf{Phase  Coloring(,,)} \hspace{0.1in}  \\
\vspace{0.7mm}
Input: a vertex  and subsets  and \\
Out\=put\=: a \=color in \{\emph{red}, \emph{blue}\} or \emph{FAIL}
\vspace{-2mm}
\begin{enumerate}
\item Repeat the following  times and stop if a \emph{good} coloring is found\footnote{
	Following~\cite{RTVX11b}, let  be the set of survived hyperedges in 
	after all vertices in  are either colored or are saved.
	Now we explore the dependency graph of  to find out all
	the connected components.\\
	We say a Phase  coloring is \emph{good} if all connected components 
	in  have sizes at most .\\  
	Similarly, we say a Phase  coloring is \emph{good} if all connected components 
	in  have sizes at most .\\ }
\begin{enumerate}
  	\item Sequentially try to color every vertex in  uniformly at random
  	\item Explore the dependency graph of 
  	\item Check if the coloring is \emph{good}
\end{enumerate}
\item If  is colored in the good coloring, return that color\\
	Else 
	\begin{enumerate}
	\item Compute the connected connected component  and then also 
	\item Run Phase  Coloring()
	\end{enumerate}  
\end{enumerate}  

\end{minipage}
}
\end{center}
\caption{Local computation algorithm for \emph{Hypergraph Coloring}:  Phase  and Phase }
\label{Fig:Phase2}
\end{figure*}




\subsection{Phase 2 and 3: gradually decreasing the component size}
Phase 2 and 3 are simply iterations of the general phase with parameters as described below.
With high probability we have that ,
and each edge has  uncolored vertices.
After at most  repetitions of the random coloring procedure, 
we reach an assignment that leaves a size -connected component of survived edges with probability

Similarly, in the third phase we begin with , and after  repetitions
we reach an assignment that leaves a size -connected component of survived edges with probability



\begin{figure*}
\begin{center}
\fbox{
\begin{minipage}{4.5in}
\small
\textbf{Phase  Coloring()} \\
Input: a vertex  and subsets  and \\
Out\=put\=: a \=color in \{\emph{red}, \emph{blue}\}
\vspace{-2mm}
\begin{enumerate}

\item Go over all possible colorings of the connected component 
	and color it using a feasible coloring.
\item Return the color  of  in this coloring.

\end{enumerate}
\end{minipage}
}
\end{center}
\caption{Local computation algorithm for \emph{Hypergraph Coloring}: Phase }
\label{Fig:Phase4}
\end{figure*}






\subsection{Phase 4: brute force}
Finally, we are left with a connected component of , 
and each edge has  uncolored vertices. 
By the Lovasz Local Lemma, there must exists a coloring (see e.g. Theorem 5.2.1 in ~\cite{Alo91}).
We can easily find this coloring via brute force search in time ).





\section{\texorpdfstring{-CNF}
{k-CNF}}\label{kcnf}

As another application, our hypergraph coloring algorithm can be easily modified to 
compute a satisfying assignment of a -CNF formula, 
provided that the latter satisfies some specific properties.

Let  be a -CNF formula on  Boolean variables .
Suppose  has  clauses 
and each clause consists of exactly  distinct literals.\footnote{
Our algorithm works for the case that each clause has at least  literals; 
for simplicity, we assume that all clauses have uniform size.}
We say two clauses  and  \emph{intersect} 
with each other if they
share some variable (or the negation of that variable).
As in the case for hypergraph coloring,  and  are fixed constants
and all asymptotics are with respect to the number of clauses  (and hence , since ).
Our main result is the following.

\begin{theorem}
Let  be a -CNF formula with . 
Suppose that each clause intersects no more than  other clauses,
and furthermore suppose that .\\
Then there exists a -local computation algorithm which, given a formula  and any sequence of
queries to the truth assignments of variables , 
with probability at least ,
returns a consistent truth assignment for all 's which agrees with some 
satisfying assignment of the -CNF formula . 
Moreover, the algorithm is query oblivious and parallelizable. 
\end{theorem}



\begin{sketch}
We follow a 4-phase algorithm similar to that of 
hypergraph two-coloring as presented in appendix \ref{Sec:hypergraph}.
In every phase, we sequentially assign random values to a subset of the remaining variables,
maintaining a threshold of  unassigned variables in each unsatisfied clause.
Since the same (in fact, slightly stronger) bounds that hold for the connected components
in the hyperedges dependency graph also hold for the clauses dependency graph (\cite{RTVX11b}),
we can return an answer which is consistent with a satisfying assignment with probability at least .
\end{sketch}








\section{Lower bound on the size of the query tree}
\label{section:lower_bound}
We prove a lower bound on the size of the query tree.
\begin{theorem}
\label{thm:lower_bound}
Let  be a random graph whose vertex degree is bounded by  or distributed independently and identically from the binomial distribution:   (). Then
\begin{center}
,
\end{center}
where the probability is taken over all random permutations  of the vertices, and  is the largest query tree in  (under ).
\end{theorem}\begin{proof}

For both the bounded degree and the binomial distribution cases, there exists a path of length at least  in the graph  w.h.p. Label the vertices on the path . There are  possible permutations of the weights of the vertices on the path. The probability of choosing the permutation in which  is .

Therefore,  and so the probability of the query tree having size\\  is at least . \qed

\end{proof}







\end{document}
