\documentclass[10pt,twocolumn,letterpaper]{article}

\usepackage{iccv}
\usepackage{times}
\usepackage{epsfig}
\usepackage{graphicx}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{amsthm}
\usepackage{subfig}
\usepackage{tabularx}
\usepackage{booktabs}
\usepackage{multirow}
\usepackage{multicol}
\usepackage{enumitem}
\usepackage{array}
\usepackage{color, colortbl}
\usepackage{fixltx2e}



\usepackage[pagebackref=true,breaklinks=true,letterpaper=true,colorlinks,bookmarks=false]{hyperref}

\definecolor{Gray}{gray}{0.92}
\definecolor{R}{rgb}{1.0,0.00,0.00}
\definecolor{Y}{gray}{0.85}
\definecolor{G}{gray}{1.0}

\newtheorem{proposition}{Proposition}
\newtheorem{property}{Property}
\newtheorem{note}{Note}
\newcommand{\bx}{\mathbf{x}}
\newcommand{\bc}{\mathbf{c}}
\newcommand{\bz}{\mathbf{z}}
\newcommand{\bmu}{\boldsymbol{\mu}}
\newcommand{\bsigma}{\boldsymbol{\sigma}}
\newcommand{\hmu}{\hat{\mu}}
\newcommand{\hsigma}{\hat{\sigma}}
\newcommand{\hc}{\hat{c}}
\newcommand{\cF}{\mathcal{F}}
\newcommand{\cX}{\mathcal{X}}
\newcommand{\cZ}{\mathcal{Z}}
\newcommand{\norm}[1]{\left\lVert#1\right\rVert}
\newcommand{\IR}{\mathbb{R}}
\newcommand{\IE}{\mathbb{E}}
\newcommand{\EL}{\mathcal{L}}
\DeclareMathOperator{\diag}{diag}


\DeclareRobustCommand*{\IEEEauthorrefmark}[1]{\raisebox{0pt}[0pt][0pt]{\textsuperscript{\footnotesize #1}}}

\iccvfinalcopy 

\def\iccvPaperID{6328} \def\httilde{\mbox{\tt\raisebox{-.5ex}{\symbol{126}}}}

\ificcvfinal\pagestyle{empty}\fi
\begin{document}

\title{Probabilistic Face Embeddings}


\author{
    Yichun Shi\; and\; Anil K. Jain\\
    Michigan State University, East Lansing, MI\\
{\tt\small shiyichu@msu.edu, jain@cse.msu.edu}
}

\maketitle



\begin{abstract}
   Embedding methods have achieved success in face recognition by comparing facial features in a latent semantic space. However, in a fully unconstrained face setting, the facial features learned by the embedding model could be ambiguous or may not even be present in the input face, leading to noisy representations. We propose \textit{Probabilistic Face Embeddings (PFEs)}, which represent each face image as a Gaussian distribution in the latent space. The mean of the distribution estimates the most likely feature values while the variance shows the uncertainty in the feature values. Probabilistic solutions can then be naturally derived for matching and fusing PFEs using the uncertainty information. Empirical evaluation on different baseline models, training datasets and benchmarks show that the proposed method can improve the face recognition performance of deterministic embeddings by converting them into PFEs. The uncertainties estimated by PFEs also serve as good indicators of the potential matching accuracy, which are important for a risk-controlled recognition system.
\end{abstract}

\vspace{-1.0em}\section{Introduction}



When humans are asked to describe a face image, they not only give the description of the facial attributes, but also the confidence associated with them. For example, if the eyes are blurred in the image, a person will keep the eye size as an uncertain information and focus on other features. Furthermore, if the image is completely corrupted and no attributes can be discerned, the subject may respond that he/her cannot identify this face. This kind of uncertainty (or confidence) estimation is common and important in human decision making.

On the other hand, the representations used in state-of-the-art face recognition systems are generally confidence-agnostic. These methods depend on an embedding model (\eg Deep Neural Networks) to give a deterministic point representation for each face image in the latent feature space~\cite{schroff2015facenet,wen2016discriminative,liu2017sphereface,wang2018cosface,deng2018arcface}. A point in the latent space represents the model's estimation of the facial features in the given image. If the error in the estimation is somehow bounded, the distance between two points can effectively measure the semantic similarity between the corresponding face images. But given a low-quality input, where the expected facial features are ambiguous or absent in the image, a large shift in the embedded points is inevitable, leading to false recognition (Figure~\ref{fig:front_a}).


Given that face recognition systems have already achieved high recognition accuracies on relatively constrained face recognition benchmarks,~\eg LFW~\cite{LFWTech} and YTF~\cite{YTF}, where most facial attributes can be clearly observed, recent face recognition challenges have moved on to more unconstrained scenarios, including surveillance videos~\cite{IJBA,IJBC,IJBS} (See Figure~\ref{fig:dataset}). In these tasks, any type and degree of variation could exist in the face image, where most of the desired facial features learned by the representation model could be absent. Given this lack of information, it is unlikely to find a feature set that could always match these faces accurately. Hence state-of-the-art face recognition systems which obtained over  accuracy on LFW have suffered from a large performance drop on IARPA Janus benchmarks~\cite{IJBA,IJBC,IJBS}.













\begin{figure}[t]
    \centering
    \captionsetup{font=footnotesize}
\subfloat[deterministic embedding]{\label{fig:front_a}\includegraphics[width=0.48\linewidth]{fig/frontpage_1.pdf}}\hfill
\subfloat[probabilistic embedding]{\label{fig:front_b}\includegraphics[width=0.48\linewidth]{fig/frontpage_2.pdf}}
    \caption{Difference between deterministic face embeddings and probabilistic face embeddings (PFEs). Deterministic embeddings represent every face as a point in the latent space without regards to its feature ambiguity. Probabilistic face embedding (PFE) gives a distributional estimation of features in the latent space instead. \textbf{Best viewed
in color.}}\vspace{-1.5em}
    \label{fig:frontpage}
\end{figure}

To address the above problems, we propose \textit{Probabilistic Face Embeddings (PFEs)}, which give a distributional estimation instead of a point estimation in the latent space for each input face image (Figure~\ref{fig:front_b}). The mean of the distribution can be interpreted as the most likely latent feature values while the span of the distribution represents the uncertainty of these estimations. PFE can address the unconstrained face recognition problem in a two-fold way: (1) During matching (face comparison), PFE penalizes uncertain features (dimensions) and pays more attention to more confident features. (2) For low quality inputs, the confidence estimated by PFE can be used to reject the input or actively ask for human assistance to avoid false recognition. Besides, a natural solution can be derived to aggregate the PFE representations of a set of face images into a new distribution with lower uncertainty to increase the recognition performance. The implementation of PFE is open-sourced\footnote{\url{https://github.com/seasonSH/Probabilistic-Face-Embeddings}}. The contributions of the paper can be summarized as below:
\begin{enumerate}[leftmargin=*]\vspace{-0.5em}
    \item An uncertainty-aware probabilistic face embedding (PFE) which represents face images as distributions instead of points.\vspace{-0.5em}
    \item A probabilistic framework that can be naturally derived for face matching and feature fusion using PFE.\vspace{-0.5em}
    \item A simple method that converts existing deterministic embeddings into PFEs without additional training data.\vspace{-0.5em}
    \item Comprehensive experiments showing that the proposed PFE can improve face recognition performance of deterministic embeddings and can effectively filter out low-quality inputs to enhance the robustness of face recognition systems.\vspace{-0.5em}
\end{enumerate}



\begin{figure}
    \centering
    \footnotesize
    \captionsetup{font=footnotesize}
    \newcommand{\vshrink}{\vspace{-10px}}
    \begin{minipage}{0.48\linewidth}
    \includegraphics[width=0.25\linewidth]{fig/dataset/ijba/img_709.jpg}\hfill
    \includegraphics[width=0.25\linewidth]{fig/dataset/ijba/frame_28405_00375.png}\hfill
    \includegraphics[width=0.25\linewidth]{fig/dataset/ijba/frame_28405_00435.png}\hfill
    \includegraphics[width=0.25\linewidth]{fig/dataset/ijba/frame_28405_00495.png}\\
    \includegraphics[width=0.25\linewidth]{fig/dataset/ijba/img_11272.jpg}\hfill
    \includegraphics[width=0.25\linewidth]{fig/dataset/ijba/frame_28094_00120.png}\hfill
    \includegraphics[width=0.25\linewidth]{fig/dataset/ijba/frame_28094_00205.png}\hfill
    \includegraphics[width=0.25\linewidth]{fig/dataset/ijba/frame_28094_00325.png}
    \vspace{-2.0em}\begin{center}(a) IJB-A~\cite{IJBA}\end{center}
    \end{minipage}\hfill
    \begin{minipage}{0.48\linewidth}
    \includegraphics[width=0.25\linewidth]{fig/dataset/ijbs/img_101457}\hfill
    \includegraphics[width=0.25\linewidth]{fig/dataset/ijbs/videos_703_930.jpg}\hfill
    \includegraphics[width=0.25\linewidth]{fig/dataset/ijbs/videos_703_977.jpg}\hfill
    \includegraphics[width=0.25\linewidth]{fig/dataset/ijbs/videos_703_1030.jpg}\\
    \includegraphics[width=0.25\linewidth]{fig/dataset/ijbs/img_101500.jpg}\hfill
    \includegraphics[width=0.25\linewidth]{fig/dataset/ijbs/videos_4034_16099.jpg}\hfill
    \includegraphics[width=0.25\linewidth]{fig/dataset/ijbs/videos_4034_16163.jpg}\hfill
    \includegraphics[width=0.25\linewidth]{fig/dataset/ijbs/videos_4034_16346.jpg}
    \vspace{-2.0em}\begin{center}(b) IJB-S~\cite{IJBS}\end{center}
    \end{minipage}\\
    \vspace{-0.9em}\caption{Example images from IJB-A and IJB-S. The first columns show still images, followed by video frames of the respective subjects in the next three columns. These benchmarks present a more unconstrained recognition scenario where there is a large variability in the image quality.}\vspace{-1.6em}
    \label{fig:dataset}
\end{figure}



\section{Related Work}

\paragraph{Uncertainty Learning in DNNs}
To improve the robustness and interpretability of discriminant Deep Neural Networks (DNNs), deep uncertainty learning is getting more attention~\cite{kendall2015bayesian,gal2016dropout,kendall2017uncertainties}. There are two main types of uncertainty: \textit{model uncertainty} and \textit{data uncertainty}. Model uncertainty refers to the uncertainty of model parameters given the training data and can be reduced by collecting additional training data~\cite{mackay1992practical,neal1995bayesian,kendall2015bayesian,gal2016dropout}. Data uncertainty accounts for the uncertainty in output whose primary source is the inherent noise in input data and hence cannot be eliminated with more training data~\cite{kendall2017uncertainties}. The uncertainty studied in our work can be categorized as data uncertainty. Although techniques have been developed for estimating data uncertainty in different tasks, including classification and regression~\cite{kendall2017uncertainties}, they are not suitable for our task since our target space is not well-defined by given labels\footnote{Although we are given the identity labels, they cannot directly serve as target vectors in the latent feature space.}. Variational Autoencoders~\cite{kingma2013auto} can also be regarded as a method for estimating data uncertainty, but it mainly serves a generation purpose. Specific to face recognition, some studies~\cite{gong2017capacity,khan2019striking,zafar2019face} have leveraged the model uncertainty for analysis and learning of face representations, but to our knowledge, ours is the first work that utilizes data uncertainty\footnote{Some in the literature have also used the terminology ``data uncertainty" for a different purpose~\cite{xu2014data}.} for recognition tasks.



\vspace{-0.8em}\paragraph{Probabilistic Face Representation}
Modeling faces as probabilistic distributions is not a new idea. In the field of face template/video matching, there exists abundant literature on modeling the faces as probabilistic distributions~\cite{shakhnarovich2002face,arandjelovic2005face}, subspace~\cite{cevikalp2010face} or manifolds~\cite{arandjelovic2005face,huang2015log} in the feature space. However, the input for such methods is a set of face images rather than a single face image, and they use a between-distribution similarity or distance measure,~\eg KL-divergence, for comparison, which does not penalize the uncertainty. Meanwhile, some studies~\cite{li2013probabilistic,hiremath2007modelling} have attempted to build a fuzzy model of a given face using the features of face parts. In comparison, the proposed PFE represents each single face image as a distribution in the latent space encoded by DNNs and we use an uncertainty-aware log likelihood score to compare the distributions.


\vspace{-0.8em}\paragraph{Quality-aware Pooling}
In contrast to the methods above, recent work on face template/video matching aims to leverage the saliency of deep CNN embeddings by aggregating the deep features of all faces into a single compact vector~\cite{yang2017neural,liu2017quality,xie2018multicolumn,gong2019video}. In these methods, a separate module learns to predict the quality of each face in the image set, which is then normalized for a weighted pooling of feature vectors. We show that a solution can be naturally derived under our framework, which not only gives a probabilistic explanation for quality-aware pooling methods, but also leads to a more general solution where an image set can also be modeled as a PFE representation.


\begin{figure*}[t]
    \centering
    \captionsetup{font=footnotesize}
    \begin{minipage}{0.33\linewidth}
    \includegraphics[width=1\linewidth]{fig/degrade_score_blur.pdf}\\ \centering
    \includegraphics[width=0.14\linewidth]{fig/degradation/blur_1.jpg}\;
    \includegraphics[width=0.14\linewidth]{fig/degradation/blur_17.jpg}\;
    \includegraphics[width=0.14\linewidth]{fig/degradation/blur_33.jpg}\;
    \includegraphics[width=0.14\linewidth]{fig/degradation/blur_49.jpg}\;
    \includegraphics[width=0.14\linewidth]{fig/degradation/blur_65.jpg}\vspace{-0.5em}
    \begin{center} \footnotesize(a) Gaussian Blur \end{center}\vspace{-1.2em}
    \end{minipage}\hfill
    \begin{minipage}{0.33\linewidth}
    \includegraphics[width=1\linewidth]{fig/degrade_score_occlusion.pdf}\\
    \centering
    \includegraphics[width=0.14\linewidth]{fig/degradation/occlusion_01.jpg}\;
    \includegraphics[width=0.14\linewidth]{fig/degradation/occlusion_03.jpg}\;
    \includegraphics[width=0.14\linewidth]{fig/degradation/occlusion_05.jpg}\;
    \includegraphics[width=0.14\linewidth]{fig/degradation/occlusion_07.jpg}\;
    \includegraphics[width=0.14\linewidth]{fig/degradation/occlusion_09.jpg}\vspace{-0.5em}
    \begin{center} \footnotesize(b) Occlusion \end{center}\vspace{-1.2em}
    \end{minipage}\hfill
    \begin{minipage}{0.33\linewidth}
    \includegraphics[width=1\linewidth]{fig/degrade_score_noise.pdf}\\
    \centering
    \includegraphics[width=0.14\linewidth]{fig/degradation/noise_01.jpg}\;
    \includegraphics[width=0.14\linewidth]{fig/degradation/noise_03.jpg}\;
    \includegraphics[width=0.14\linewidth]{fig/degradation/noise_05.jpg}\;
    \includegraphics[width=0.14\linewidth]{fig/degradation/noise_07.jpg}\;
    \includegraphics[width=0.14\linewidth]{fig/degradation/noise_09.jpg}\vspace{-0.5em}
    \begin{center} \footnotesize(c) Random Gaussian Noise \end{center}\vspace{-1.2em}
    \end{minipage}\hfill
    \caption{ Illustration of \textit{feature ambiguity dilemma}. The plots show the cosine similarity on LFW dataset with different degrees of degradation. Blue lines show the similarity between original images and their respective degraded versions. Red lines show the similarity between impostor pairs of degraded images. The shading indicates the standard deviation. With larger degrees of degradation, the model becomes more confident (very high/low scores) in a wrong way.}\vspace{-1.3em}
    \label{fig:dilemma}
\end{figure*}


\section{Limitations of Deterministic Embeddings}
\label{sec:motivation}

In this section, we explain the problems of deterministic face embeddings from both theoretical and empirical views. Let  denote the image space and  denote the latent feature space of  dimensions. An ideal latent space  should only encode \textit{identity-salient} features and be \textit{disentangled} from identity-irrelevant features. As such, each identity should have a unique intrinsic code  that best represents this person and each face image  is an observation sampled from . The process of training face embeddings can be viewed as a joint process of searching for such a latent space  and learning the inverse mapping . For deterministic embeddings, the inverse mapping is a Dirac delta function , where  is the embedding function. Clearly, for any space , given the possibility of noises in , it is unrealistic to recover the exact  and the embedded point of a low-quality input would inevitably shift away from its intrinsic  (no matter how much training data we have). 

The question is whether this shift could be bounded such that we still have smaller intra-class distances compared to inter-class distances. However, this is unrealistic for fully unconstrained face recognition and we conduct an experiment to illustrate this. Let us start with a simple example: given a pair of identical images, a deterministic embedding will always map them to the same point and therefore the distance between them will always be , even if these images do not contain a face. This implies that ``a pair of images being similar or even the same does not necessarily mean the probability of their belonging to the same person is high''. 

To demonstrate this, we conduct an experiment by manually degrading the high-quality images and visualizing their similarity scores. We randomly select a high-quality image of each subject from the LFW dataset~\cite{LFWTech} and manually insert Gaussian blur, occlusion, and random Gaussian noise to the faces. In particular, we linearly increase the size of Gaussian kernel, occlusion ratio and the standard deviation of the noise to control the degradation degree. At each degradation level, we extract the feature vectors with a 64-layer CNN\footnote{trained on Ms-Celeb-1M~\cite{MS-CELEB} with AM-Softmax~\cite{wang2018additive}}, which is comparable to state-of-the-art face recognition systems. The features are normalized to a hyper-spherical embedding space. Then, two types of cosine similarities are reported: (1) similarity between pairs of original image and its respective degraded image, and (2) similarity between degraded images of different identities. As shown in Figure~\ref{fig:dilemma}, for all the three types of degradation, the genuine similarity scores decrease to  while the impostor similarity scores converge to ! These indicate two types of errors that can be expected in a fully unconstrained  scenario even when the model is very confident (very high/low similarity scores): 
\begin{enumerate}[leftmargin=20pt,label={(\arabic*)}]\vspace{-0.5em}
    \item false accept of impostor low-quality pairs and\vspace{-0.5em}
    \item false reject of genuine cross-quality pairs.\vspace{-0.4em}
\end{enumerate}
To confirm this, we test the model on the IJB-A dataset by finding impostor/genuine image pairs with the highest/lowest scores, respectively. The situation is exactly as we hypothesized (See Figure~\ref{fig:ijba_fail_det}). We call this \textit{Feature Ambiguity Dilemma} which is observed when the deterministic embeddings are forced to estimate the features of ambiguous faces. The experiment also implies that there exist a \textit{dark space} where the ambiguous inputs are mapped to and the distance metric is distorted. 


\begin{figure}[t]
\setlength\tabcolsep{2.4px}
\newcommand{\hhh}{32px}
\newcommand{\vsp}{\hspace{0.28em}}
\newcolumntype{Y}{>{\centering\arraybackslash}X}
    \captionsetup{font=footnotesize}
    \footnotesize
    \centering
    \begin{tabularx}{\linewidth}{cc}
        \includegraphics[height=\hhh]{fig/failure_example/deterministic/FR_1_1.jpg}\hfill
        \includegraphics[height=\hhh]{fig/failure_example/deterministic/FR_1_2.jpg}\vsp
        \includegraphics[height=\hhh]{fig/failure_example/deterministic/FR_4_1.jpg}\hfill
        \includegraphics[height=\hhh]{fig/failure_example/deterministic/FR_4_2.jpg} &
        \includegraphics[height=\hhh]{fig/failure_example/deterministic/FA_1_1.jpg}\hfill
        \includegraphics[height=\hhh]{fig/failure_example/deterministic/FA_1_2.jpg}\vsp
        \includegraphics[height=\hhh]{fig/failure_example/deterministic/FA_4_1.jpg}\hfill
        \includegraphics[height=\hhh]{fig/failure_example/deterministic/FA_4_2.jpg} \-0.1em]
       (a) Low-similarity Genuine Pairs &  (b) High-similarity Impostor Pairs\
    p(\bz|\bx_i) = \mathcal{N}(\bz;\bmu_i,\bsigma_i^{2}\mathbf{I})

p(\bz_i=\bz_j)=\int{p(\bz_i|\bx_i)p(\bz_j|\bx_j)\delta(\bz_i-\bz_j)d\bz_id\bz_j}.
\label{eq:likelihood_def}

\begin{split}
    s(\bx_i,\bx_j)=&\log p(\bz_i=\bz_j)\\
    =&-\frac{1}{2}\sum_{l=1}^{D}(\frac{(\mu^{(l)}_i-\mu^{(l)}_j)^2}{\sigma_i^{2(l)}+\sigma_j^{2(l)}}+\log(\sigma_i^{2(l)}+\sigma_j^{2(l)}))\\
    &-const,
\end{split}\raisetag{\baselineskip}
\label{eq:likelihood}

\begin{split}
    s(\bx_i,\bx_j)=&\log\int{p(\bz|\bx_i)p(\bz|\bx_j)d\bz}\\
    =&\log\IE_{\bz\sim p(\bz|\bx_i)}[p(\bz|\bx_j)]\\
    =&\log\IE_{\bz\sim p(\bz|\bx_j)}[p(\bz|\bx_i)].
\end{split}

    p(\bz|\bx_1,\bx_2,\dots,\bx_{n+1})=\alpha\frac{p(\bz|\bx_{n+1})}{p(\bz)}p(\bz|\bx_{1},\bx_{2},\dots,\bx_{n}),
\raisetag{0.2\baselineskip}\label{eq:fusion_p}

    \hmu_n=\sum_{i=1}^{n}{\frac{\hsigma^2_n}{\sigma^2_i}\mu_i}, \label{eq:fusion_template_mu}\\
    \frac{1}{\hsigma^2_n}=\sum_{i=1}^{n}{\frac{1}{\sigma^2_i}}. \label{eq:fusion_template_c}

    \hat{\bmu}_n=\frac{\sum_{i=1}^n{q_i\bmu_i}}{\sum_j^n q_j}.

\label{eq:loss}
\EL=\frac{1}{|\mathcal{P}|}\sum_{(i,j)\in\mathcal{P}}{-s(\bx_i,\bx_j)}
-1.0em]
                                        &           &&                 &    &&         \\
\midrule            
DR-GAN~\cite{tran2017disentangled}      & 1M        &&   &  &&         \\
Yin~\etal~\cite{yin2018multi}           & 0.5M      &&   &  &&         \\
TPE~\cite{sankaranarayanan2016triplet}  & 0.5M      &&   &  &&         \\
NAN~\cite{yang2017neural}               & 3M        &&   &  &&-               \\
QAN~\cite{liu2017quality}               & 5M        &&   &   &&-              \\
Cao~\etal~\cite{cao2018vggface2}        & 3.3M      &&   &  &&-               \\
Multicolumn~\cite{xie2018multicolumn}   & 3.3M      &&   &  &&-               \\
L2-Face~\cite{ranjan2017l2}             & 3.7M      &&   & &&-               \\\hline
Baseline                                & 4.4M      && &  &&        \\
PFE\textsubscript{fuse}                 & 4.4M      && &  &&-             \\
PFE\textsubscript{fuse+match}           & 4.4M      &&  &  &&    \\
\bottomrule
\end{tabularx}
\vspace{-0.7em}\caption{Results of our models (last three rows) trained on MS-Celeb-1M  and state-of-the-art methods on CFP (frontal-profile protocol) and IJB-A.}\vspace{-1.5em}
\label{tab:ijb}
\end{center}
\end{table}
\begin{table}[t]
\newcommand{\hly}{\cellcolor{Y}}
\newcommand{\hlg}{\cellcolor{G}}
\captionsetup{font=footnotesize}
\newcommand{\mr}[1]{\multirow{2}{*}{#1}}
\footnotesize
\setlength{\tabcolsep}{4.6pt}
\begin{center}
\begin{tabularx}{1.00\linewidth}{Xc cccc}
\toprule
\mr{Method}                                  & \mr{Training Data} & \multicolumn{4}{c}{IJB-C (TAR@FAR)} \\
\cline{3-6}\-2.0em]
    \begin{center} \footnotesize(a) Gaussian Blur \end{center}\vspace{-1.2em}
    \end{minipage}\hfill
    \begin{minipage}{0.33\linewidth}
    \includegraphics[width=1\linewidth]{fig/degrade_score_uncertain_occlusion.pdf}\-2.0em]
    \begin{center} \footnotesize(c) Random Noise \end{center}\vspace{-1.2em}
    \end{minipage}\hfill
    \vspace{-0.3em}\caption{ Repeated experiments on feature ambiguity dilemma with the proposed PFE. The same model in Figure~\ref{fig:dilemma} is used as the base model and is converted to a PFE by training an uncertainty module. No additional training data nor data augmentation is used for training.}\vspace{-1.0em}
    \label{fig:dilemma_repeat}
\end{figure*}
\begin{figure}[t]
\setlength\tabcolsep{2.4px}
\newcommand{\hhh}{32px}
\newcommand{\vsp}{\hspace{0.28em}}
\newcolumntype{Y}{>{\centering\arraybackslash}X}
    \captionsetup{font=footnotesize}
    \footnotesize
    \centering
    \begin{tabularx}{\linewidth}{cc}
        \includegraphics[height=\hhh]{fig/failure_example/probabilistic/FR_1_1.jpg}\hfill
        \includegraphics[height=\hhh]{fig/failure_example/probabilistic/FR_1_2.jpg}\vsp
        \includegraphics[height=\hhh]{fig/failure_example/probabilistic/FR_4_1.jpg}\hfill
        \includegraphics[height=\hhh]{fig/failure_example/probabilistic/FR_4_2.jpg} &
        \includegraphics[height=\hhh]{fig/failure_example/probabilistic/FA_1_1.jpg}\hfill
        \includegraphics[height=\hhh]{fig/failure_example/probabilistic/FA_1_2.jpg}\vsp
        \includegraphics[height=\hhh]{fig/failure_example/probabilistic/FA_4_1.jpg}\hfill
        \includegraphics[height=\hhh]{fig/failure_example/probabilistic/FA_4_2.jpg} \-0.1em]
       (a) Low-score Genuine Pairs &  (b) High-score Impostor Pairs\-1.0em]
    \vspace{-0.2em}\caption{ Distribution of estimated uncertainty on different datasets. Here, ``Uncertainty'' refers to the harmonic mean of  across all feature dimensions. Note that the estimated uncertainty is proportional to the complexity of the datasets. \textbf{Best viewed in color}.}\vspace{-1.5em}
    \label{fig:hist_sigma}
\end{figure}

\subsection{Qualitative Analysis}

\paragraph{Why and when does PFE improve performance?} We first repeat the same experiments in Section~\ref{sec:motivation} using the PFE representation and MLS. The same network is used as the base model here. As one can see in Figure~\ref{fig:dilemma_repeat}, although the scores of low-quality impostor pairs are still increasing, they converge to a point that is lower than the majority of genuine scores. Similarly, the scores of cross-quality genuine pairs converge to a point that is higher than the majority of impostor scores. This means the two types of errors discussed in Section~\ref{sec:motivation} could be solved by PFE. This is further confirmed by the IJB-A results in Figure~\ref{fig:ijba_fail_prob}. Figure~\ref{fig:hist_sigma} shows the distribution of estimated uncertainty on LFW, IJB-A and IJB-S. As one can see, the ``variance" of uncertainty increases in the following order: LFW  IJB-A  IJB-S. Comparing with the performance in Section~\ref{sec:exp:msceleb}, we can see that PFE tends to achieve larger performance improvement on datasets with more diverse image quality.\vspace{-1.2em}

\paragraph{What does DNN see and not see?} To answer this question, we train a decoder network on the original embedding, then apply it to PFE by sampling  from the estimated distribution  of given . For a high-quality image (Figure~\ref{fig:rec} Row 1), the reconstructed images tend to be very consistent without much variation, implying the model is very certain about the facial features in this images. In contrast, for a lower-quality input (Figure~\ref{fig:rec} Row 2), larger variation can be observed from the reconstructed images. In particular, attributes that can be clearly discerned from the image (\eg thick eye-brow) are still consistent while attributes cannot (\eg eye shape) be discerned have larger variation. As for a mis-detected image (Figure~\ref{fig:rec} Row 3), significant variation can be observed in the reconstructed images: the model does not see any salient feature in the given image.

\begin{figure}[t]
\setlength\tabcolsep{0px}
\newcommand{\hhh}{33px}
\newcolumntype{Y}{>{\centering\arraybackslash}X}
    \captionsetup{font=footnotesize}
    \footnotesize
    \centering
    \begin{tabularx}{\linewidth}{Ycccccc}
 &  & mean & sample1 & sample2 & sample3 & sample4\\
\includegraphics[height=\hhh]{fig/rec_ijba/15719/96.png} &
        \includegraphics[height=\hhh]{fig/rec_ijba/15719/sigma.pdf}\, &
        \includegraphics[height=\hhh]{fig/rec_ijba/15719/mean.png} & 
        \includegraphics[height=\hhh]{fig/rec_ijba/15719/98.png} & 
        \includegraphics[height=\hhh]{fig/rec_ijba/15719/100.png} & 
        \includegraphics[height=\hhh]{fig/rec_ijba/15719/99.png} & 
        \includegraphics[height=\hhh]{fig/rec_ijba/15719/101.png} \-0.1em]
\includegraphics[height=\hhh]{fig/rec_ijba/3805/160.png} &
        \includegraphics[height=\hhh]{fig/rec_ijba/3805/sigma.pdf}\, &
        \includegraphics[height=\hhh]{fig/rec_ijba/3805/mean.png} & 
        \includegraphics[height=\hhh]{fig/rec_ijba/3805/162.png} & 
        \includegraphics[height=\hhh]{fig/rec_ijba/3805/164.png} & 
        \includegraphics[height=\hhh]{fig/rec_ijba/3805/165.png} &
        \includegraphics[height=\hhh]{fig/rec_ijba/3805/166.png} \-0.3em]
        & \raisebox{1.5\height}{L} & 
        \includegraphics[height=\hhh]{fig/filter_score/conf_lfw_389.jpg}\hfill
        \includegraphics[height=\hhh]{fig/filter_score/conf_lfw_433.jpg}\hfill
        \includegraphics[height=\hhh]{fig/filter_score/conf_lfw_479.jpg}\hfill
        \includegraphics[height=\hhh]{fig/filter_score/conf_lfw_494.jpg} &
        \includegraphics[height=\hhh]{fig/filter_score/conf_ijba_326.jpg}\hfill
        \includegraphics[height=\hhh]{fig/filter_score/conf_ijba_340.jpg}\hfill
        \includegraphics[height=\hhh]{fig/filter_score/conf_ijba_345.jpg}\hfill
        \includegraphics[height=\hhh]{fig/filter_score/conf_ijba_347.jpg} \\
        \multirow{2}{*}{\rotatebox[origin=c]{90}{MTCNN}} & \raisebox{1.5\height}{H} & 
        \includegraphics[height=\hhh]{fig/filter_score/mtcnn_lfw_1.jpg}\hfill
        \includegraphics[height=\hhh]{fig/filter_score/mtcnn_lfw_1x2.jpg}\hfill
        \includegraphics[height=\hhh]{fig/filter_score/mtcnn_lfw_1x3.jpg}\hfill
        \includegraphics[height=\hhh]{fig/filter_score/mtcnn_lfw_1x4.jpg} &
        \includegraphics[height=\hhh]{fig/filter_score/mtcnn_ijba_1.jpg}\hfill
        \includegraphics[height=\hhh]{fig/filter_score/mtcnn_ijba_1x2.jpg}\hfill
        \includegraphics[height=\hhh]{fig/filter_score/mtcnn_ijba_1x3.jpg}\hfill
        \includegraphics[height=\hhh]{fig/filter_score/mtcnn_ijba_1x4.jpg} \-1.0em]
    \end{tabularx}
    \vspace{-0.3em}\caption{Example images from LFW and IJB-A that are estimated with the highest (H) confidence/quality scores and the lowest (L) scores by our method and MTCNN face detector.}\vspace{-1.7em}
    \label{fig:quality}
\end{figure}
\begin{figure}[t]
    \centering
    \captionsetup{font=footnotesize}
    \begin{minipage}{0.48\linewidth}
    \includegraphics[width=1\linewidth]{fig/FOR_LFW_casia.pdf}\-2.0em]
    \begin{center} \footnotesize(b) IJB-A \end{center}\vspace{-1.2em}
    \end{minipage}\hfill
    \vspace{-0.3em}\caption{ Comparison of verification performance on LFW and IJB-A (not the original protocol) by filtering a proportion of images using different quality criteria.}\vspace{-1.7em}
    \label{fig:FOR}
\end{figure}
\section{Conclusion}
We have proposed probabilistic face embeddings (PFEs), which represent face images as distributions in the latent space. Probabilistic solutions were derived to compare and aggregate the PFE of face images. Unlike deterministic embeddings, PFEs do not suffer from the feature ambiguity dilemma for unconstrained face recognition. Quantitative and qualitative analysis on different settings showed that PFEs can effectively improve the face recognition performance by converting deterministic embeddings to PFEs. We have also shown that the uncertainty in PFEs is a good indicator for the ``discriminative''quality of face images. In the future work we will explore how to learn PFEs in an end-to-end manner and how to address the data dependency within face templates.

{\small
\bibliographystyle{ieee_fullname}
\bibliography{egbib}
}




\appendix
\section{Proofs}
\label{sec:proof}
\subsection{Mutual Likelihood Score}
Here we prove Equation~(3) in the main paper. For simplicity, we do not need to directly solve the integral. Instead, let us consider an alternative vector , where ,  and  are the pair of images we need to compare. Then,  ,~\ie Equation~(2) in the main paper, is equivalent to the density value of .

The  component (dimension) of , , is the subtraction of two Gaussian variables, which means:

Therefore, the mutual likelihood score is given by:

Note that directly solving the integral will lead to the same solution.

\subsection{Property 1}
Let us consider the case that  equals to a constant  for any image  and dimension . Thus the mutual likelihood score between a pair  becomes:

where  and  are both constants.

\subsection{Representation Fusion}
We first prove Equation~(5) in the main paper. Assuming all the observations  are conditionally independent given the latent code . The posterior distribution is:
\vspace{-0.3em}
where  is a normalization constant. In this case, . 

Without loss of generality, let us consider a one-dimensional case for the followings. The solution can be easily extended to a multivariate case since all feature dimensions are assumed to be independent. It can be shown that the posterior distribution in Equation~(\ref{eq:fusion_p_expand}) is a Gaussian distribution through induction. Let us assume  is a Gaussian distribution with  and  as mean and variance, respectively. Note that the initial case  is guaranteed to be a Gaussian distribution.
Let  and  denote the parameters of the noninformative prior of . Then, if we take  on both side of Equation~(\ref{eq:fusion_p_expand}), we have:
\vspace{-0.3em}
where ``const'' refers to the terms irrelevant to  and
\vspace{-0.3em}
Considering , we have
\vspace{-0.3em}
The result means the posterior distribution is a new Gaussian distribution with a smaller variance. Further, we can directly give the solution of fusing  samples:
\vspace{-0.3em}
where  and
\vspace{-0.3em}
Considering , we have


\section{Implementation Details}
\label{sec:detail}
All the models in the paper are implemented using Tensorflow r1.9. Two and Four GeForce GTX 1080 Ti GPUs are used for training base models on CASIA-Webface~\cite{CASIA-WebFace} and MS-Celeb-1M~\cite{MS-CELEB}, respectively. The uncertainty modules are trained using one GPU.

\subsection{Data Preprocessing}
All the face images are first passed through MTCNN face detector~\cite{MTCNN} to detect 5 facial landmarks (two eyes, nose and two mouth corners). Then, similarity transformation is used to normalize the face images based on the five landmarks. After transformation, the images are resized to . Before passing into networks, each pixel in the RGB image is normalized by subtracting  and dividing by . 

\subsection{Base Models}
The base models for CASIA-Webface~\cite{CASIA-WebFace} are trained for  steps using a SGD optimizer with a momentum of . The learning rate starts at , and is decreased to  and  after  and  steps, respectively. For the base model trained on Ms-Celeb-1M~\cite{MS-CELEB}, we train the network for  steps using the same optimizer settings. The learning rate starts at , and is decreased to  and  after  and  steps, respectively. The batch size, feature dimension and weight decay are set to ,  and , respectively, for both cases.

\subsection{Uncertainty Module}
\paragraph{Architecture} The uncertainty module for all models are two-layer perceptrons with the same architecture: \texttt{FC-BN-ReLU-FC-BN-exp}, where \texttt{FC} refers to fully connected layers, \texttt{BN} refers to batch normalization layers~\cite{ioffe2015batch} and \texttt{exp} function ensures the outputs  are all positive values~\cite{kendall2017uncertainties}. The first \texttt{FC} shares the same input with the bottleneck layer,~\ie the output feature map of the last convolutional layer. The output of both \texttt{FC} layers are -dimensional vectors, where  is the dimensionality of the latent space. In addition, we constrain the last \texttt{BN} layer to share the same  and  across all dimensions, which we found to help stabilizing the training. 

\paragraph{Training} For the models trained on CASIA-WebFace~\cite{CASIA-WebFace}, we train the uncertainty module for  steps using a SGD optimizer with a momentum of . The learning rate starts at , and is decreased to  after  steps. For the model trained on MS-Celeb-1M\cite{MS-CELEB}, we train the uncertainty module for  steps. The learning rate starts at , and is decreased to  after  steps. The batch size for both cases are . For each mini-batch, we randomly select  images from  different subjects to compose the positive pairs ( pairs in all). The weight decay is set to  in all cases. A Subset of the training data was separated as the validation set for choosing these hyper-parameters during development phase. 

\paragraph{Inference Speed} Feature extraction (passing through the whole network) using one GPU takes ms per image. Note that given the small size of the uncertainty module, it has little impact on the feature extraction time. Matching images using cosine similarity and mutual likelihood score takes ns and  ns
, respectively. Both are neglectable in comparison with feature extraction time. 


\begin{table}[t]
\captionsetup{font=footnotesize}
\footnotesize
\setlength{\tabcolsep}{3pt}
\begin{center}
\begin{tabularx}{\linewidth}{Xccccc}
\toprule
Base Model                      & Representation & LFW & YTF & CFP-FP & IJB-A \\
\midrule
                                                        & Original  &  &  &  & \\
\multirow{-2}{*}{\shortstack[l]{Softmax + \\Center Loss}~\cite{wen2016discriminative}}  
                                                        & PFE       &  &  &  &  \\\rowcolor{Gray}
& Original  &  &  &  &  \\\rowcolor{Gray}
\multirow{-2}{*}{Triplet~\cite{schroff2015facenet}}     & PFE       &  &  &  &  \\
& Original  &  &  &  &  \\
\multirow{-2}{*}{A-Softmax~\cite{liu2017sphereface}}      & PFE       &  &  &  &  \\\rowcolor{Gray}
& Original  &  &  &  &  \\\rowcolor{Gray}
\multirow{-2}{*}{AM-Softmax~\cite{wang2018additive}}    & PFE       &  &  &  &  \\

\bottomrule
\end{tabularx}
\vspace{-0.9em}\caption{Results of CASIA-Net models trained on CASIA-WebFace. ``Original'' refers to the deterministic embeddings. The better performance among each base model are shown in bold numbers. ``PFE'' uses mutual likelihood score for matching. IJB-A results are verification rates at FAR=.}\vspace{-2.5em}
\label{tab:loss_function_casianet}
\end{center}
\end{table}

\begin{table}[t]
\captionsetup{font=footnotesize}
\footnotesize
\setlength{\tabcolsep}{3pt}
\begin{center}
\begin{tabularx}{\linewidth}{Xccccc}
\toprule
Base Model                      & Representation & LFW & YTF & CFP-FP & IJB-A \\
\midrule
                                                        & Original  &  &  &  & \\
\multirow{-2}{*}{\shortstack[l]{Softmax + \\Center Loss}~\cite{wen2016discriminative}}  
                                                        & PFE       &  &  &  &  \\\rowcolor{Gray}
& Original  &  &  &  &  \\\rowcolor{Gray}
\multirow{-2}{*}{Triplet~\cite{schroff2015facenet}}     & PFE       &  &  &  &  \\
& Original  &  &  &  &  \\
\multirow{-2}{*}{A-Softmax~\cite{liu2017sphereface}}      & PFE       &  &  &  &  \\\rowcolor{Gray}
& Original  &  &  &  &  \\\rowcolor{Gray}
\multirow{-2}{*}{AM-Softmax~\cite{wang2018additive}}    & PFE       &  &  &  &  \\
\bottomrule
\end{tabularx}
\vspace{-0.9em}\caption{Results of Light-CNN models trained on CASIA-WebFace. ``Original'' refers to the deterministic embeddings. The better performance among each base model are shown in bold numbers. ``PFE'' uses mutual likelihood score for matching. IJB-A results are verification rates at FAR=.}\vspace{-2.5em}
\label{tab:loss_functions_lightcnn}
\end{center}
\end{table}

\section{Results on Different Architectures}
Throughout the main paper, we conducted the experiments using a 64-layer CNN network~\cite{liu2017sphereface}. Here, we evaluate the proposed method on two different network architectures for face recognition: CASIA-Net~\cite{CASIA-WebFace} and 29-layer Light-CNN~\cite{wu2015light}. Notice that both networks require different image shapes from our  preprocessed ones. Thus we pad our images with zero values and resize them into the target size. Since the main purpose of the experiment is to evaluate the efficacy of the uncertainty module rather than comparing with the original results of these networks, the difference in the preprocessing should not affect a fair comparison. Besides, the original CASIA-Net does not converge for A-Softmax and AM-Softmax, so we add an bottleneck layer to output the embedding representation after the average pooling layer. Then we conduct the experiments by comparing probabilistic embeddings with base deterministic embeddings, similar to Section 5.1 in the main paper. The results are shown in Table~\ref{tab:loss_function_casianet} and Table~\ref{tab:loss_functions_lightcnn}. Without tuning the architecture of the uncertainty module nor the hyper-parameters, PFE still improve the performance in most cases.








\end{document}
