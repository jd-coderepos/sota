\documentclass{llncs}

\usepackage{etex}
\usepackage{delarray}
\usepackage{amssymb}
\usepackage{amsmath}
\usepackage{graphicx}
\usepackage{subfig}
\usepackage[usenames,dvipsnames]{color}
\usepackage[all]{xy}

\usepackage{aicescover}

\newcommand{\lowtriruleTwoByTwo}[6]
{
  
}

\newcommand{\symmruleTwoByTwo}[6]
{
  
}

\newcommand{\ruleTwoByTwo}[6]
{
  
}

\newcommand{\ruleTwoByOne}[6]
{
  
}

\newcommand{\ruleOneByTwo}[6]
{
  
}

\newcommand{\ruleOneByOne}[3]
{
  
}

 
\usepackage{float}
\floatstyle{boxed}
\newfloat{mybox}{htb}{lob}
\floatname{mybox}{Box}
\newsubfloat{mybox}

\usepackage{booktabs}
\usepackage{colortbl}

\definecolor{known}{RGB}{0, 100, 0} \definecolor{unknown}{rgb}{1.0, 0.0, 0.0} \newcommand{\known}[1]{\textcolor{known}{#1}}
\newcommand{\unknown}[1]{\textcolor{unknown}{#1}}
\newcommand{\myboxed}[1]{\boxed{\!\!{#1}\!\!}}

\newcommand{\click}{{\sc{Cl\makebox[.58\width][c]{1}ck}}}

\DeclareCaptionType{copyrightbox}

\newcommand{\prop}[2]{{\tt{#1(}}#2{\tt{)}}}

\hyphenation{Cho-les-ky}

\begin{document}


\title{Knowledge-Based Automatic Generation\\of Partitioned Matrix Expressions}

\author{Diego Fabregat-Traver \and 
        Paolo Bientinesi}

\institute{
  AICES, RWTH Aachen, Germany \\
  \email{\{fabregat,pauldj\}@aices.rwth-aachen.de}
}

\aicescovertitle{Knowledge-Based\\Automatic Generation of\\Partitioned Matrix Expressions}
\aicescoverauthor{Diego Fabregat-Traver and Paolo Bientinesi} \aicescoverpublisher{\small{\bf * The final version published by Springer ({\url www.springerlink.com}) is available at:}\\
                    \url{http://link.springer.com/content/pdf/10.1007\%2F978-3-642-23568-9\_12.pdf}}
\aicescoverpage

\maketitle

\begin{abstract}

In a series of papers it has been shown that for many linear algebra
operations it is possible to generate families of algorithms by following
a systematic procedure.
Although powerful, such a methodology
involves complex algebraic manipulation, symbolic computations and
pattern matching, making the generation a process challenging to be
performed by hand.  We aim for a fully automated system that from the
sole description of a target operation creates multiple algorithms
without any human intervention.
Our approach consists of three main stages. The first stage yields the
core object for the entire process, the Partitioned Matrix Expression
(PME), which establishes how the target problem may be decomposed in
terms of simpler sub-problems.  In the second stage the PME is
inspected to identify predicates, the Loop-Invariants, to be used to
set up the skeleton of a family of proofs of correctness. In the third
and last stage the actual algorithms are constructed so that each of
them satisfies its corresponding proof of correctness.  In this paper
we focus on the first stage of the process, the automatic generation
of Partitioned Matrix Expressions. In particular, we discuss the steps
leading to a PME and the knowledge necessary for a symbolic system to
perform such steps. We also introduce \click{}, a prototype system
written in Mathematica that generates PMEs automatically.

\end{abstract}

\section{Introduction}

In the context of the Formal Linear Algebra Methods Environment
(FLAME) project~\cite{FLAMEOnline}, a methodology for the systematic
derivation of algorithms for matrix operations has been developed and
demonstrated. 
The approach has been successfully applied to all the 
operations included in the BLAS~\cite{level3BLAS} and 
RECSY~\cite{RECSY1,RECSY2} libraries and to
many included in the LAPACK~\cite{laug} library.
In general, the methodology
applies to any operation that can be expressed in a ``divide and
conquer'' fashion.
As opposed to the concept of ``Autotuning'', which
indicates the automatic tuning of a given
algorithm~\cite{atlas-sc98,FFTW05,Pueschel:05}, the word derivation refers to the
actual generation of both algorithms and routines to solve a given
target equation~\cite{Bientinesi:2005:SDD}.
The remarkable results achieved using this methodology are the 
subject of a series of publications. 
a) For many standard operations, e.g. the Cholesky and
the LU factorizations, all the previously known algorithms were systematically 
discovered, unifying them under a common root~\cite{FLAWN11}. 
b) For more involved operations like the Sylvester
equation and the reduction of a generalized eigenproblem to standard form,
the generated family of algorithms included new and better performing 
ones~\cite{Quintana-Orti:2003:FDA,FLAWN56}.
c) A related methodology for systematic analysis of round-off errors yielded bounds tighter than
those previously known~\cite{Paolo-MASA}.

Although successful, the approach presents some limitations. The
algorithms are generated through complex symbolic computations, steps
often too complicated to be carried out by hand. Motivated by these
difficulties, we aim for a symbolic system that, given as input the
description of a matrix equation , applies the steps dictated by
the FLAME methodology to derive a family of algorithms to solve .
As shown in Fig.~\ref{fig:steps}, the procedure
consists of three successive stages---PME Generation, Loop-Invariant Identification, Algorithm Derivation---and is entirely determined by the mathematical description of the input operation.

\begin{figure}
\centering
    \includegraphics[scale=1]{figures/diagram.pdf}
    \caption{The three main stages in the process of derivation of algorithms.} \label{fig:steps}
\end{figure}

In the first stage, the Partitioned Matrix Expression (PME) for the input 
operation is obtained. A PME is a decomposition of the original problem 
into simpler sub-problems in a ``divide and conquer'' fashion, exposing the
computation to be performed in each part of the output matrices. 
An example is shown in Box~\ref{box:PMELU}. The second 
stage of the process deals with the identification of Boolean predicates, 
the Loop-Invariants, that describe the intermediate state of computation 
for the sought-after algorithms. Loop-invariants can be extracted from the 
PME, and are at the heart of the automation of the third stage. In the third 
and last stage of the methodology, each loop-invariant is used to set up
a proof of correctness around which the algorithm is finally built.
Notice that the objective is not proving the correctness of a given
algorithm; vice-versa, the loop-invariant is chosen {\em before} the
algorithm is built. Indeed, the algorithm is constructed to 
satisfy a given proof of correctness, i.e., to possess the chosen 
loop-invariant.

\begin{mybox}
\vspace{2mm}
  \centering
	 \vspace{1mm}
	\caption{Partitioned Matrix Expression for the triangular Sylvester equation.} \label{box:PMELU}
\end{mybox}

This paper centers around the first stage of the derivation process, the generation of PMEs.
To this end we introduce a formalism to input into the
system the minimum amount of knowledge about the operation required by a system to 
perform all the subsequent stages automatically.
We then describe the process for transforming an input equation into PMEs.
As Fig.~\ref{fig:stepsPME} shows, such process involves three steps: 
1) the partitioning of the operands in the equation, 
2) matrix arithmetic involving the partitioned operands, and
3) a sequence of iterations, each consisting of algebraic manipulation and
pattern matching.
We demonstrate that the process can indeed be automated through
\click{}\footnote{The name \click{} epitomizes the idea 
that the effort a user has to make to obtain algorithms consists in just {\it one click}.}, 
a symbolic system written in Mathematica~\cite{MathematicaOnline} 
that performs all the steps for the PME generation.

\begin{figure}[t]
  \centering
  \includegraphics[scale=1.00]{figures/diagramPME.pdf}
  \caption{Steps for the automatic generation of PMEs.} \label{fig:stepsPME}
\end{figure}

The paper is organized as follows. In Sect.~\ref{sec:input} we categorize
the input needed by a symbolic system. Partitionings of the operands and 
inheritance of properties are discussed in Sect.~\ref{sec:partitioning}, 
while in Sect.~\ref{sec:PattMatch} we describe how to use partitionings 
to obtain PMEs. We draw conclusion in Sect.~\ref{sec:conclusions}.

\section{Input to the System} \label{sec:input}

Our first concern is to establish how a target operation should be
formally described.  
Since we are
aiming for a fully-automated system, i.e., without any human
intervention, we need a formalism to unequivocally describe a target
equation.
We choose the language traditionally used to reason about program correctness: 
equations shall be specified by means of the predicates Precondition () and
Postcondition ()~\cite{GrSc:92}. The precondition enumerates
the operands that appear in the equation and describes their properties, while
the postcondition specifies the equation to be solved.

The Cholesky factorization will serve as an example:
given a symmetric positive definite (SPD) matrix , the goal is to find a
lower triangular matrix  such that .
Box~\ref{box:CholOpDesc} contains the predicates  and 
relative to the Cholesky factorization; 
the notation  indicates that  is the Cholesky factor of .
\begin{mybox}
-4mm]
P_{\rm post}: \{ &  L L^T = A \}
\end{split}
\right.
X X^T = A - B C,-3mm]
\caption{Partitioning rules for structured matrices.}\label{box:partLM}
\end{center}
\end{mybox}

\subsection{Theorem-aware Inheritance}\label{subsec:theorem-aware}

Although frequent, direct inheritance of properties is only the simplest form of inheritance.
Here we expose a more complex situation.
Let A be an SPD matrix. Because of symmetry, the only admissible partitioning rules are
the ones listed in Box~\ref{box:partLM}; applying the  rule, we obtain

and both  and  are symmetric. More properties about
the quadrants of  can be stated. For example, it is well known that
{\it if  is SPD, then every principal sub-matrix of  is also
  SPD}.  As a consequence, the quadrants  and  inherit
the SPD property.  Moreover, it can be proved that given a  partitioning of an SPD matrix as in (\ref{eqn:SPDPart}), the
following matrices (known as Schur complements) are also symmetric
positive definite:\1mm]
ii) \1mm]
\caption{Application of the different combinations of partitioning rules to the postcondition.} \label{tab:partPostcond}
\end{table*}

It is apparent that some of the expressions in the
fourth column of Tab.~\ref{tab:partPostcond} are not algebraically well defined.  
The rules in the
second and third rows lead to ill-defined partitioned postconditions,
thus they should be discarded.
Despite leading to a well defined expression, the first row of the table should
be discarded too, as the goal is a {\it Partitioned} Matrix Expression
and it leads to an expression 
in which none of the operands has been partitioned.
In light of these additional restrictions, the only viable set
of rules for the Cholesky factorization is the one given in the last row of 
Tab.~\ref{tab:partPostcond}. 

In summary, partitioning rules must satisfy
both the constraints due to the nature of the individual operands, 
and those due to the operators appearing in the postcondition. 
In the next section we detail the algorithm used by \click{} to
generate only the viable sets of partitioning rules.

\subsection{Automation} \label{subsec:automation}

We show how \click{} performs the partitioning process automatically.
The naive approach would be to exhaustively search among all the
rules applied to all the operands, leading to a search space of
exponential size in the number of operands. 
Instead, \click{} utilizes an algorithm that traverses once the tree
that represents the postcondition in prefix notation and yields only
the viable sets of partitioning rules. 
The input to the algorithm is the predicates  and  for a target operation.
As an example we look at the triangular Sylvester equation

defined using our formalism as in Box~\ref{box:sylvdesc}.

\begin{mybox}
{\small
-2mm]
P_{\rm post}: \{ &  L X + X U = C \}.
\end{split}
\right.
\left[ \; \{ L_{r}, L_{c}, X_{r}, C_{r}\}, \{ U_{r}, U_{c}, X_{c}, C_{c}\} \; \right].1mm]
\caption{Viable combinations of partitioning rules for the Sylvester equation.} \label{tab:sylvPart}
\end{table}


This very same process is used to find the bound dimensions of every target
operation and, accordingly, only each and every viable combination
of partitioning rules is generated.

\section{Matrix Arithmetic and Pattern Matching} \label{sec:PattMatch}

This section covers the second and third steps in the PME generation stage (Fig.~\ref{fig:stepsPME}).
Within the {\it Matrix Arithmetic} step, symbolic arithmetic is performed and 
the = operator is distributed over the partitions, 
originating multiple equations.
In (\ref{eqn:matArit1}) we display the result of these actions for the Cholesky factorization,
where the symbol  means that the equation in the top-right quadrant
is the transpose of the bottom-left one.

{\scriptsize
\vspace{-2mm}

} 

The {\em Pattern Matching} step delivers the sought-after PME.
Success of this process is dependent
on the ability to identify expressions with known structure and properties. 
In order to facilitate pattern matching, we force equations to be in
their {\em canonical form}. We state that an equation is in canonical
form if 
a) its left-hand side only consists of those terms that contain at least one unknown object,
and 
b) its right-hand side only consists of those terms that solely contain known objects. 


This last step carries out an iterative process comprising three separate actions:
1) structural pattern matching:
equations are matched against known patterns;
2) once a known pattern is matched,
the unknown operands are flagged as known
and the equation becomes a tautology;
3) algebraic manipulation:
the remaining equations are rearranged in canonical form.
We clarify the iterative process by illustrating, action by action, how
\click{} works through the Cholesky factorization.
The first iteration is depicted in
Box~\ref{box:it1}, in
which
the top-left formula 
displays the initial state.
In all the next expressions, \known{green} and \unknown{red} are
used to highlight the known and unknown operands, respectively.

\paragraph{\bf Structural pattern matching:} 
All the equations in Box~\ref{box:it1}\subref{sbox:it1a} are in canonical form.
Through pattern matching, the top-left quadrant is the only one for which a match is found. 
\click{} identifies the equation as a Cholesky factorization (Box~\ref{box:it1}\subref{sbox:it1b}),
since the pattern in Box~\ref{box:CholOpDesc} is satisfied: the system recognizes that 
i)  is lower triangular;
ii)  is SPD; and 
iii) the structure of the equation matches the one in the postcondition ().

\paragraph{\bf Exposing new available operands:} 
Having matched the top-left equation, \click{}
turns the unknown operand \unknown{}
into \known{}, and propagates the information to all the other quadrants
(Box~\ref{box:it1}\subref{sbox:it1c}).
As a result, the top-left equation becomes a tautology.

\paragraph{\bf Algebraic manipulation:} 
All the remaining equations are still in canonical form,
 thus no operation takes place~(Box~\ref{box:it1}\subref{sbox:it1d}).

\begin{mybox} \centering
\tiny
\renewcommand{\arraystretch}{1.6}
\subfloat[Initial state.]
{ \label{sbox:it1a}
         
}
\hspace{-.1cm}
\subfloat[Top-left equation is identified as a Cholesky sub-problem.]
{ 
\label{sbox:it1b}
         
}
\\\vspace{1em}
\hspace{-.1cm}
\subfloat[ becomes a known operand for the rest of equations.]
{ 
  \begin{minipage}{5.4cm}
\label{sbox:it1c}
         
  \end{minipage}
}
\hspace{.50cm}
\subfloat[There is no need for algebraic manipulation.]
{ 
  \begin{minipage}{5.9cm}
\label{sbox:it1d}
         
  \end{minipage}
}
\caption{First iteration towards the PME generation.} \label{box:it1}
\end{mybox}


In this first iteration, one unknown operand, , has become known, 
and one equation has turned into a tautology.
The knowledge encoded in such a tautology is of importance for a subsequent iteration.
The {\bf second iteration} is shown in Box~\ref{box:it2}.

\paragraph{\bf Structural pattern matching:} 
Box~\ref{box:it2}\subref{sbox:it2a}
reproduces
the final state from the previous iteration.
Among the two outstanding equations,
the bottom-left one is identified (Box~\ref{box:it2}\subref{sbox:it2b}),
as it matches the pattern 
of a triangular system of equations with multiple right-hand sides ({\sc trsm}).
The pattern for a {\sc trsm} is

For the sake of brevity,
we assume that \click{}
had learned such pattern from a previous derivation; 
in practice, in case the system does not know the pattern,
a nested task of PME generation would be initiated, 
yielding the required pattern.

\paragraph{\bf Exposing new available operands:} 
Once the {\sc trsm} is identified, the output operand  becomes
available and turns to green in the bottom-right quadrant
(Box~\ref{box:it2}\subref{sbox:it2c}).

\paragraph{\bf Algebraic manipulation:} 
The bottom-right equation is not in canonical form anymore:
the product , now a known quantity,
does not lay in the right-hand side. A simple manipulation
brings the equation back to canonical form (Box~\ref{box:it2}\subref{sbox:it2d}).

\begin{mybox} \centering
\tiny
\renewcommand{\arraystretch}{1.6}
\subfloat[Initial state.]
{ \label{sbox:it2a}
         
}
\hspace{-.2cm}
\subfloat[Bottom-left equation is identified as a triangular system of equations.]
{ \label{sbox:it2b}
         
}
\\\vspace{1em}
\hspace{-.1cm}
\subfloat[ becomes a known operand.] 
{ \label{sbox:it2c}
         
}
\subfloat[State after the algebraic manipulation.]
{ \label{sbox:it2d}
         
}
\caption{Second iteration towards the PME generation.} \label{box:it2}
\end{mybox}


The process continues until all the equations are turned into tautologies.
The third and {\bf final iteration} for the Cholesky factorization
is shown in Box~\ref{box:it3}, where the top formula
replicates the final state from the previous iteration.

\paragraph{\bf Structural pattern matching:} Only one equation, the bottom-right one, remains unprocessed.  
At a first glance,
one might recognize a Cholesky factorization, but the corresponding
pattern in Box~\ref{box:CholOpDesc} requires  to be SPD. The question is whether the expression  represents an SPD matrix. In
order to answer the question, \click{} applies rewrite rules and
symbolic simplifications.

In Sect.~\ref{subsec:theorem-aware} we explained
that the following quantities are known to be SPD: , ,
, and .
In order to determine whether 
is equivalent to any of these expressions, \click{} makes use of the knowledge acquired throughout the previous iterations.
Specifically, in the first two iterations it was discovered that
, and .
Using these tautologies as rewrite rules, the expression  is manipulated.  First, the equality  is used to replace the instances of ,
yielding , and
equivalently, . Then, by virtue of the tautology ,
 is replaced by , yielding . Now, this expression is known to be SPD.
Thanks to these manipulations, \click{} successfully associates the
bottom right equation with the pattern for a Cholesky factorization.

\paragraph{\bf Exposing new available operands:} 
Once the expression in the bottom-right quadrant is identified, 
the system exposes the quantity  as known.
Since no equation is left, the process completes and the PME---formed by the three
tautologies---is returned as output. 

\begin{mybox} \centering
\tiny
\renewcommand{\arraystretch}{1.6}
\subfloat[Initial state.]
{ \label{sbox:it3a}
         
}
\hspace{-.1cm}
\subfloat[Bottom-right equation is identified as a Cholesky factorization.]
{ \label{sbox:it3b}
         
}
\\\vspace{-.5em}
\hspace{-.1cm}
\subfloat[ becomes a known operand.]
{ \label{sbox:it3c}
         
}
\subfloat[Final PME.]
{ \label{sbox:it3d}
         
}
\caption{Final iteration towards the PME generation.} \label{box:it3}
\end{mybox}

By means of the described process, PMEs for a target equation are automatically
generated. The PME for the Cholesky factorization is given in Box~\ref{box:PMEChol}.

\begin{mybox} \centering
\vspace{-3mm}
	\renewcommand{\arraystretch}{1.4}
	 \\
\vspace{-3mm}
	\caption{Partitioned Matrix Expression for the Cholesky factorization.} \label{box:PMEChol}
\end{mybox}

\section{Conclusions} \label{sec:conclusions}

The work we presented sets the ground for the development of a
symbolic system that, from the sole description of an operation,
generates algorithms automatically. The core of our methodology stands
in the PME.  A PME encapsulates the information about the target
operation in a way that facilitates the subsequent identification of
loop-invariants. The loop-invariants then lead to the final algorithms
through a technique based on program correctness. In this paper we
introduce a symbolic system, \click{}, that automates the generation of
PMEs.

In order to generate PMEs, \click{} first identifies how the op\-er\-ands in the
operation may be partitioned. Instead of a brute force approach of
exponential complexity, \click{} utilizes a tree-based algorithm that
yields only the viable sets of partitioning rules.
Through a process of pattern matching, each such set leads to a distinct PME. 
The key in the PME generation is \click{}'s ability to identify known patterns. 
Initially, \click{} only recognizes elementary structures, but its
knowledge expands by automatically learning the patterns associated
with the operations it tackles. Thanks to this augmenting
internal knowledge, the system may generate PMEs for increasingly
complex operations.

To illustrate \click{}, we discussed the
Cholesky factorization and, partially (due to space constraints),
the Sylvester equation. Despite the fact
that such operations differ in multiple ways---number and properties
of the operands, number of valid sets of partitioning rules, number of
PMEs---the steps performed by \click{} leading to the PMEs are
exactly the same. As future work, we plan to add support
for higher dimensional objects
and the derivative operator.

\section{Acknowledgements}
The authors gratefully acknowledge the support received from the
Deutsche Forschungsgemeinschaft (German Research Association) through
grant GSC 111.




\begin{thebibliography}{10}

\bibitem{FLAMEOnline}
{FLAME {P}roject}:
\newblock {FLAME {O}nline {R}eference}.
\newblock \\\url{http://z.cs.utexas.edu/wiki/flame.wiki/}

\bibitem{level3BLAS}
Dongarra, J.J., Du~Croz, J., Hammarling, S., Duff, I.S.:
\newblock A set of level 3 basic linear algebra subprograms.
\newblock ACM Trans. Math. Softw. \textbf{16} (March 1990)  1--17

\bibitem{RECSY1}
Jonsson, I., K{\aa}gstr\"om, B.:
\newblock Recursive blocked algorithms for solving triangular systems---part i:
  one-sided and coupled sylvester-type matrix equations.
\newblock ACM Transactions on Mathematical Software \textbf{28}(4) (2002)
  392--415

\bibitem{RECSY2}
Jonsson, I., K{\aa}gstr\"om, B.:
\newblock Recursive blocked algorithms for solving triangular systems---part
  ii: Two-sided and generalized sylvester and lyapunov matrix equations.
\newblock ACM Transactions on Mathematical Software \textbf{28}(4) (2002)
  416--435

\bibitem{laug}
Anderson, E., Bai, Z., Bischof, C., Blackford, S., Demmel, J., Dongarra, J.,
  Du~Croz, J., Greenbaum, A., Hammarling, S., McKenney, A., Sorensen, D.:
\newblock {LAPACK} Users' Guide. Third edn.
\newblock Society for Industrial and Applied Mathematics, Philadelphia, PA
  (1999)

\bibitem{atlas-sc98}
Whaley, R.C., Dongarra, J.:
\newblock Automatically tuned linear algebra software.
\newblock In: SuperComputing 1998: High Performance Networking and Computing.
  (1998)

\bibitem{FFTW05}
Frigo, M., Johnson, S.G.:
\newblock The design and implementation of {FFTW3}.
\newblock Proceedings of the IEEE \textbf{93}(2) (2005)  216--231 Special issue
  on ``Program Generation, Optimization, and Platform Adaptation''.

\bibitem{Pueschel:05}
P{\"u}schel, M., Moura, J.M.F., Johnson, J., Padua, D., Veloso, M., Singer, B.,
  Xiong, J., Franchetti, F., Gacic, A., Voronenko, Y., Chen, K., Johnson, R.W.,
  Rizzolo, N.:
\newblock {SPIRAL}: Code generation for {DSP} transforms.
\newblock Proceedings of the IEEE, special issue on ``Program Generation,
  Optimization, and Adaptation'' \textbf{93}(2) (2005)  232-- 275

\bibitem{Bientinesi:2005:SDD}
Bientinesi, P., Gunnels, J.A., Myers, M.E., Quintana-Ort\'{i}, E.S., {v}an~de
  Geijn, R.A.:
\newblock The science of deriving dense linear algebra algorithms.
\newblock {ACM} Transactions on Mathematical Software \textbf{31}(1) (March
  2005)  1--26

\bibitem{FLAWN11}
Bientinesi, P., Quintana-Ort\'{\i}, E.S., van~de Geijn, R.:
\newblock {FLAME\@lab}: A farewell to indices. {FLAME} {W}orking {N}ote \#11.
\newblock Technical Report TR-2003-11, The University of Texas at Austin,
  Department of Computer Sciences (April 2003)

\bibitem{Quintana-Orti:2003:FDA}
Quintana-Ort\'{i}, E.S., {v}an~de Geijn, R.A.:
\newblock Formal derivation of algorithms: The triangular {Sylvester} equation.
\newblock {ACM} Transactions on Mathematical Software \textbf{29}(2) (June
  2003)  218--243

\bibitem{FLAWN56}
Poulson, J., van~de Geijn, R., Bennighof, J.:
\newblock Parallel algorithms for reducing the generalized hermitian-definite
  eigenvalue problem. {FLAME} {W}orking {N}ote \#56.
\newblock Technical Report TR-11-05, The University of Texas at Austin,
  Department of Computer Sciences (February 2011)

\bibitem{Paolo-MASA}
Bientinesi, P., van~de Geijn, R.:
\newblock A goal-oriented and modular approach to stability analysis.
\newblock {SIAM} Journal on Matrix Analysis and Applications (2011) ``To
  appear''.

\bibitem{MathematicaOnline}
{Wolfram {R}esearch}:
\newblock Mathematica {R}eference {G}uide.
\newblock \\\url{http://reference.wolfram.com/mathematica/}

\bibitem{GrSc:92}
Gries, D., Schneider, F.B.:
\newblock A Logical Approach to Discrete Math.
\newblock {T}exts and {M}onographs in {C}omputer {S}cience. Springer Verlag
  (1992)

\end{thebibliography}

\end{document}
