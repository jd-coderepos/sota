In this Section we provide details about the model setups for evaluations, describe the scoring metrics, and present the results for both datasets.

\subsection{Grapher Setup}
For our base pre-trained language model we used T5 ``large'', for a total number of 770M parameters, from HuggingFace, Inc \cite{wolf2020transformers} (see Appendix for the results using other model sizes). For Query Node generation we also defined the learnable query embedding matrix , where  is the hidden size of T5 model, and  is the maximum possible number of nodes in a graph. The node generation head uses single-layer GRU decoder with  followed by linear transformation projecting to the vocabulary of size . The same GRU setup is used for the edge generation head, where we also set the maximum number of edges to be 7. Finally, for the edge classification head, we defined four fully-connected layers with ReLU non-linearities and dropouts with probability 0.5, projecting the output to the space of edge classes.

During training we fine-tuned all the model's parameters, using the AdamW optimizer with learning rate of , and default values of  and weight decay of . The batch size was set to 10 samples using a single NVIDIA A100 GPU for WebNLG and NYT training, while for \tekgen training we employed distributed training over 10 A100 GPUs, thus making the effective batch size of 100. Under these settings, it takes approximately 3,500 steps to complete a training epoch for WebNLG, together with the validations done every 1,000 steps, we get a model that reaches its top performance in approximately 6-7 hours. For NYT, the epoch takes approximately 4,600 mini-batches, achieving top performance in about 15 epochs (24 hours). Finally, \tekgen, each epoch takes approximately 54,000 steps, with the evaluations done every 1,000 steps we trained and validated the model for 150,000 iterations, taking approximately 14 days of compute time. 

\subsection{Baselines}

To evaluate the performance of Grapher, for baselines we selected the top performing teams reported on the WebNLG 2020 Challenge Leaderboard, and briefly describe them here:
\textbf{Amazon AI (Shanghai)} \cite{guo-etal-2020-2} was the Challenge winner for Text-to-RDF task. They followed a simple heuristic-based approach that first does entity linking to match the entities present in the input text with the DBpedia ontology, and then query the DBpedia database to extract the relation between them.
\textbf{BT5} \cite{agarwal-etal-2020-machine} came in second place and used large pre-trained T5 model to generate KG in a linearized form, where the object-predicate-subject triples are concatenated together and the entire text-to-graph problem is viewed as a traditional sequence-to-sequence modeling.
\textbf{CycleGT} \cite{Guo2020CycleGTUG}, third place contestant, followed an unsupervised method for text-to-graph and graph-to-text generation, where the KB construction part relies on off-the-shelf entity extractor to identify all the entities present in the input text, and a multi-label classifier to predict the relation between pairs of entities.
\textbf{Stanford CoreNLP Open IE} \cite{manning-etal-2014-stanford}: This is an unsupervised approach that was run on the input text part of the test set to extract the subjects, relations, and objects to produce the output triplets to give a baseline performance for the WebNLG 2020 Challenge.
\textbf{ReGen} \cite{dognin2021regen}: Recent work that leverages T5 pretrained language model and Reinforcement Learning (RL) for bidirectional text-to-graph and graph-to-text generation, which, similarly to  \citet{agarwal-etal-2020-machine}, also follows the linearized graph representation approach. 


\begin{table}[t!]
\centering
\caption{Evaluation results on the test set of the WebNLG+ 2020 dataset. The top four block-rows are the results taken from the WebNLG 2020 Challenge Leaderboard \cite{Ferreira2020The2B}. The bottom part shows the results of our proposed Grapher system for several architectural choices, as discussed in Section \ref{sec:method}. Bold font shows the best performing systems.}
\label{tbl:webnlg}
\resizebox{0.48\textwidth}{!}{
\begin{tabular}{ccclccc}
\multicolumn{1}{l}{} & \multicolumn{1}{l}{} & \multicolumn{1}{l}{} & \textbf{M.} & \multicolumn{1}{l}{\textbf{F1}} & \multicolumn{1}{l}{\textbf{Prec.}} & \multicolumn{1}{c}{\textbf{Rec.}} \\ \hline
\multicolumn{3}{l|}{\multirow{3}{*}{\begin{tabular}[c]{@{}c@{}}Amazon AI \end{tabular}}} & \multicolumn{1}{l|}{E} & 0.689 & 0.689 & 0.690 \\
\multicolumn{3}{c|}{}                                                              & \multicolumn{1}{l|}{P}     & 0.696          & 0.696          & 0.698          \\
\multicolumn{3}{c|}{}                                                              & \multicolumn{1}{l|}{S}      & 0.686          & 0.686          & 0.687          \\ \hline
\multicolumn{3}{l|}{\multirow{3}{*}{BT5 }}         & \multicolumn{1}{l|}{E}       & 0.682          & 0.670          & 0.701          \\
\multicolumn{3}{c|}{}                                                              & \multicolumn{1}{l|}{P}     & 0.713          & 0.700          & 0.736          \\
\multicolumn{3}{c|}{}                                                              & \multicolumn{1}{l|}{S}      & 0.675          & 0.663          & 0.695          \\ \hline
\multicolumn{3}{l|}{\multirow{3}{*}{CycleGT }}              & \multicolumn{1}{l|}{E}       & 0.342          & 0.338          & 0.349          \\
\multicolumn{3}{c|}{}                                                              & \multicolumn{1}{l|}{P}     & 0.360          & 0.355          & 0.372          \\
\multicolumn{3}{c|}{}                                                              & \multicolumn{1}{l|}{S}      & 0.309          & 0.306          & 0.315          \\ \hline
\multicolumn{3}{l|}{\multirow{3}{*}{Stanford OIE }} & \multicolumn{1}{l|}{E} & 0.158          & 0.154          & 0.164          \\
\multicolumn{3}{c|}{}                                                              & \multicolumn{1}{l|}{P}     & 0.200          & 0.194          & 0.211          \\
\multicolumn{3}{c|}{}                                                              & \multicolumn{1}{l|}{S}      & 0.127          & 0.125          & 0.130          \\ \hline
\multicolumn{3}{l|}{\multirow{3}{*}{ReGen}}   & \multicolumn{1}{l|}{E}                     & \textbf{0.723} & \textbf{0.714} & \textbf{0.738} \\
\multicolumn{3}{c|}{}                                                              & \multicolumn{1}{l|}{P}     & \textbf{0.767} & \textbf{0.755} & \textbf{0.788} \\
\multicolumn{3}{c|}{}                                                              & \multicolumn{1}{l|}{S}      & \textbf{0.720} & \textbf{0.713} & \textbf{0.735} \\ \hline \\ \hline
\multirow{12}{*}{\begin{tabular}[c]{@{}c@{}}\rotatebox{90}{\textbf{Grapher}}\end{tabular}} &
  \multirow{6}{*}{\begin{tabular}[c]{@{}c@{}}Query\\ Nodes\end{tabular}} &
  \multicolumn{1}{c|}{\multirow{3}{*}{\begin{tabular}[c]{@{}c@{}}Gen\\ Edges\end{tabular}}} & \multicolumn{1}{l|}{E} & 0.395          & 0.391          & 0.400          \\
 &                             & \multicolumn{1}{c|}{}                             & \multicolumn{1}{l|}{P}        & 0.325          & 0.318          & 0.337          \\
 &                             & \multicolumn{1}{c|}{}                             & \multicolumn{1}{l|}{S}         & 0.289          & 0.285          & 0.294          \\ \cline{3-7} 
 &                             & \multicolumn{1}{c|}{\multirow{3}{*}{\begin{tabular}[c]{@{}c@{}}Class\\ Edges\end{tabular}}}
                                                                                   & \multicolumn{1}{l|}{E}          & 0.466          & 0.463          & 0.469          \\
 &                             & \multicolumn{1}{c|}{}                             & \multicolumn{1}{l|}{P}        & 0.360          & 0.356          & 0.368          \\
 &                             & \multicolumn{1}{c|}{}                             & \multicolumn{1}{l|}{S}         & 0.347          & 0.345          & 0.351          \\ \cline{2-7} 
 & \multirow{6}{*}{\begin{tabular}[c]{@{}c@{}}Text\\ Nodes\end{tabular}} & \multicolumn{1}{c|}{\multirow{3}{*}{\begin{tabular}[c]{@{}c@{}}Gen\\ Edges\end{tabular}}}   
                                                                                   & \multicolumn{1}{l|}{E}       & 0.683          & 0.675          & 0.695          \\
 &                             & \multicolumn{1}{l|}{}                             & \multicolumn{1}{l|}{P}     & 0.713          & 0.702          & 0.730          \\
 &                             & \multicolumn{1}{l|}{}                             & \multicolumn{1}{l|}{S}      & 0.681          & 0.673          & 0.693          \\ \cline{3-7} 
 &                             & \multicolumn{1}{c|}{\multirow{3}{*}{\begin{tabular}[c]{@{}c@{}}Class\\ Edges\end{tabular}}} 
                                                                                   & \multicolumn{1}{l|}{E}       & \textbf{0.722} & \textbf{0.715} & \textbf{0.733} \\
 &                             & \multicolumn{1}{c|}{}                             & \multicolumn{1}{l|}{P}     & \textbf{0.750} & \textbf{0.741} & \textbf{0.765} \\
 &                             & \multicolumn{1}{c|}{}                             & \multicolumn{1}{l|}{S}      & \textbf{0.719} & \textbf{0.712} & \textbf{0.730}
\end{tabular}
}
\end{table}


\subsection{Evaluation Metrics}
For scoring the generated graph, we used the evaluation scripts from WebNLG 2020 Challenge \cite{Ferreira2020The2B}, which computes the Precision, Recall, and F1 scores for the output triples against the ground truth. In particular, since the order of generated and ground truth triples should not influence the result, the script searches for the optimal
alignment between each candidate and the reference triple through all possible permutation of the hypothesis-reference pairs. Then, the metrics based on Named Entity Evaluation \cite{SeguraBedmar2013SemEval2013T9} were used to measure the Precision, Recall, and F1 score in four different ways. \textbf{Exact}: The candidate triple should match exactly the reference triple, while the type (subject, predicate, object) is not important. \textbf{Partial}: The candidate triple should match at least partially with the reference
triple, while the type (subject, predicate, object) is irrelevant. \textbf{Strict}: The candidate triple matches exactly the reference triple, and the element type (subject, predicate, object) should match exactly as well. 

\subsection{WebNLG Results}


The main results for evaluating all the compared methods on WebNLG test set are presented in Table~\ref{tbl:webnlg}. As one can see, our Grapher system, based on Text Nodes and Class Edges, achieved on par top performance, as the ReGen \cite{dognin2021regen} model. Our system also uses the Focal loss to account for edge imbalance during training. We can also see that Grapher based on Text Nodes, where the T5-based model generates the nodes directly as a string, outperforms the alternative approach that generates the nodes through query vectors and permutes the features to get invariance to node ordering. A possible explanations is that the graphs at hand and the training data are both quite small. Therefore, the representational power of T5, pre-trained on textual corpora several orders of magnitude larger, can handle the entity extraction task much better. As we mentioned earlier, the ability to extract the nodes is very crucial to the overall success of the system, so if the query-based node generation constructs less reliable sets of nodes, the follow-up stage of edge generation will underperform as well.

\begin{figure}[th!]
\centering
\includegraphics[width=0.48\textwidth]{figs/attention.pdf}
\caption{Visualization of the cross-attention weights in the T5 model between the node query embedding vectors and the embeddings of the input text.}
\label{fig:node_attention}
\end{figure}



Comparing the edge generation versus classification, we see that the former approach already brings up the system to the level of the top two leaderboard performers, while the edge classification adds extra accuracy and makes Grapher one of the leading system. This again might be due to a smaller training set, in which case GRU edge decoder underperforms, generating less accurate edges, while the classifier just needs to predict a single class to construct an edge, making it a better alternative in the low-data scenarios.    




\begin{table}[t!]
\centering
\caption{Evaluation results on the test set of \tekgen dataset for different configurations of the Grapher system. The use of text-based nodes with generation edges performs the best. }
\label{tab:tekgen}
\bgroup
\def\arraystretch{1.0}\resizebox{0.48\textwidth}{!}{
\begin{tabular}{ccccccc}
\multicolumn{1}{l}{} & \multicolumn{1}{l}{} & \multicolumn{1}{l}{} & \textbf{M.} & \multicolumn{1}{l}{\textbf{F1}} & \multicolumn{1}{l}{\textbf{Prec.}} & \multicolumn{1}{c}{\textbf{Rec.}} \\ \hline
\multicolumn{3}{l|}{\multirow{1}{*}{ReGen }}   & \multicolumn{1}{l|}{E}           & 0.623 & 0.610 & 0.647 \\ \hline
\multirow{12}{*}{\begin{tabular}[c]{@{}c@{}}\rotatebox{90}{\textbf{Grapher}}\end{tabular}} &
  \multirow{6}{*}{\begin{tabular}[c]{@{}c@{}}Query\\ Nodes\end{tabular}} &
  \multicolumn{1}{c|}{\multirow{3}{*}{\begin{tabular}[c]{@{}c@{}}Gen\\ Edges\end{tabular}}} & \multicolumn{1}{l|}{E} & 0.386          & 0.361          & 0.430          \\
 &                             & \multicolumn{1}{c|}{}                             & \multicolumn{1}{l|}{P}        & 0.438          & 0.405          & 0.496          \\
 &                             & \multicolumn{1}{c|}{}                             & \multicolumn{1}{l|}{S}         & 0.386          & 0.361          & 0.430          \\ \cline{3-7} 
 &                             & \multicolumn{1}{c|}{\multirow{3}{*}{\begin{tabular}[c]{@{}c@{}}Class\\ Edges\end{tabular}}}
                                                                                   & \multicolumn{1}{l|}{E}          & 0.361          & 0.338          & 0.401          \\
 &                             & \multicolumn{1}{c|}{}                             & \multicolumn{1}{l|}{P}        & 0.408          & 0.378          & 0.463          \\
 &                             & \multicolumn{1}{c|}{}                             & \multicolumn{1}{l|}{S}         & 0.360          & 0.337          & 0.401          \\ \cline{2-7} 
 & \multirow{6}{*}{\begin{tabular}[c]{@{}c@{}}Text\\ Nodes\end{tabular}} & \multicolumn{1}{l|}{\multirow{3}{*}{\begin{tabular}[c]{@{}c@{}}Gen\\ Edges\end{tabular}}}   
                                                                                   & \multicolumn{1}{l|}{E} & \textbf{0.707}   & \textbf{0.693} & \textbf{0.730}\\
 &                             & \multicolumn{1}{l|}{}                             & \multicolumn{1}{l|}{P} & \textbf{0.741}    & \textbf{0.723} & \textbf{0.771} \\
 &                             & \multicolumn{1}{l|}{}                             & \multicolumn{1}{l|}{S} & \textbf{0.706} & \textbf{0.692} & \textbf{0.729}\\\cline{3-7} 
 &                             & \multicolumn{1}{c|}{\multirow{3}{*}{\begin{tabular}[c]{@{}c@{}}Class\\ Edges\end{tabular}}} 
                                                                                   & \multicolumn{1}{l|}{E}      & 0.700 & 0.686 & 0.722 \\
 &                             & \multicolumn{1}{c|}{}                             & \multicolumn{1}{l|}{P}      & 0.735 & 0.717 & 0.764 \\
 &                             & \multicolumn{1}{c|}{}                             & \multicolumn{1}{l|}{S}      & 0.700 & 0.685 & 0.721
\end{tabular}
}
\egroup
\end{table}


Finally, note that although the query-based node generation did not perform well in our evaluations, it is still informative to examine the behaviour of these vectors learned during the training. For this, we analyze the cross-attention weights in the T5 model between the node query vectors and the embeddings of the input text; the results are shown in Fig.~\ref{fig:node_attention}. The ground truth nodes for this sentence are `Agra Airport', `India' and `T.S. Thakur'. It can be seen that each query vector focuses on a set of words that can potentially become a node. For example, the first query vector emphasizes the words `Agra', `Airport', `T.S.' and `Thakur', but since the weight on the first two words is higher, the resulting feature vector sent to the Node GRU module correctly decodes it as `Agra Airport'. The same process happens for the third and forth query vectors. It is also interesting to see that the rest of the queries were also correctly decoded as  token, even though they had high attention weights on some of the words (e.g., weight of 0.2 on `Agra' and 0.18 on `India' for the second query vector). One potential explanation is that since no causal mask is used when feeding query vectors to the decoder, T5 has an opportunity to exchange the information between all of the query vectors across all the layers and heads. Thus, once the found nodes are assigned to specific vectors, the rest of them are suppressed and decoded into , irrespective of the attention weights.




\subsubsection{\tekgen Results}


The results on the test set of the \tekgen dataset \cite{agarwal2021knowledge} are shown in Table~\ref{tab:tekgen}. To compute the graph generation performance, we use the same scoring functions as in WebNLG 2020 Challenge \cite{Ferreira2020The2B}. As in Table~\ref{tbl:webnlg}, in this experiment we observe a similar pattern in which the Grapher based on Text Nodes outperforms the query-based system. At the same time we see now that the GRU-based edge decoding performs better than the classification edge head. Recall that for the smaller-size WebNLG dataset the classification edge head performed better, while now on the larger-size \tekgen dataset, the GRU edge generation is more accurate, outperforming the simpler classification edge head. Also, our Grapher model now outperforms the ReGen baseline from \cite{dognin2021regen}, which is based on the linearization technique to represent the graph, showing advantage of the proposed multi-stage generation approach.



\subsubsection{NYT Results}
Finally, Table \ref{tab:nyt} shows the results on NYT dataset. Similar as for the \tekgen, Grapher based on text nodes and generation edges performs the best, outperforming the other architectural choices and the baseline (note that this baseline is our own implementation similar to \cite{dognin2021regen} and \cite{agarwal-etal-2020-machine}, which uses T5 pre-trained language model on the linearized graph representation). Comparing with the results from Tables \ref{tbl:webnlg} and \ref{tab:tekgen}, we can see that for smaller datasets, the classification head has a clear advantage, while as more training data becomes available, the GRU edge decoder becomes more accurate, outperforming the classifier edge head. 

\begin{table}[t!]
\centering
\caption{Evaluation results on the test set of NYT dataset for different configurations of the Grapher system. Text-based nodes with generation edges performs the best.}
\label{tab:nyt}
\bgroup
\def\arraystretch{1.0}\resizebox{0.48\textwidth}{!}{
\begin{tabular}{ccccccc}
\multicolumn{1}{l}{} & \multicolumn{1}{l}{} & \multicolumn{1}{l}{} & \textbf{M.} & \multicolumn{1}{l}{\textbf{F1}} & \multicolumn{1}{l}{\textbf{Prec.}} & \multicolumn{1}{l}{\textbf{Rec.}} \\ \hline
\multicolumn{3}{l|}{\multirow{3}{*}{T5 + Linearized Graph}}         & \multicolumn{1}{l|}{E}     & 0.832          & 0.831          & 0.834          \\
\multicolumn{3}{c|}{}                                             & \multicolumn{1}{l|}{P}     & 0.834          & 0.832          & 0.837          \\
\multicolumn{3}{c|}{}                                             & \multicolumn{1}{l|}{S}     & 0.824          & 0.822          & 0.826          \\
\hline
\multirow{6}{*}{\begin{tabular}[c]{@{}c@{}}\rotatebox{90}{\textbf{Grapher}}\end{tabular}}
 & \multirow{6}{*}{\begin{tabular}[c]{@{}c@{}}Text\\ Nodes\end{tabular}} 
                               & \multicolumn{1}{c|}{\multirow{3}{*}{\begin{tabular}[c]{@{}c@{}}Gen\\ Edges\end{tabular}}}  
                                                                            & \multicolumn{1}{l|}{E}     & \textbf{0.918}    & \textbf{0.917} & \textbf{0.920} \\
 &                             & \multicolumn{1}{l|}{}                      & \multicolumn{1}{l|}{P}     & \textbf{0.919}    & \textbf{0.918} & \textbf{0.921}  \\
 &                             & \multicolumn{1}{l|}{}                      & \multicolumn{1}{l|}{S}     & \textbf{0.913}    & \textbf{0.911} & \textbf{0.914}  \\ \cline{3-7} 
 &                             & \multicolumn{1}{c|}{\multirow{3}{*}{\begin{tabular}[c]{@{}c@{}}Class\\ Edges\end{tabular}}} 
                                                                                   & \multicolumn{1}{l|}{E}     & 0.870 & 0.867 & 0.872 \\
 &                             & \multicolumn{1}{c|}{}                             & \multicolumn{1}{l|}{P}     & 0.871 & 0.869 & 0.874 \\
 &                             & \multicolumn{1}{c|}{}                             & \multicolumn{1}{l|}{S}     & 0.860 & 0.858 & 0.862
\end{tabular}
}
\egroup
\end{table}

