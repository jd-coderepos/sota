\begin{center}
    \Large \textbf{Appendix}  
\end{center}
\paragraph{Overview of the Appendix} For ease of reading, we submit the main body of our paper together with the appendix as supplemental material. Below we will briefly introduce the structure of our appendix for easy reading. Readers can jump from the corresponding position in the body to the corresponding content in the appendix, or jump from the following table of contents to the corresponding content of interest in the appendix.

\begin{itemize}
    \item In App. \ref{app: Abbreviation and Notation}, we briefly summarize some common notations  in this paper for the convenience of readers.
    \item In App. \ref{app: background on RL},  we  summarize and recall the background knowledge used in this paper.
    \item In App. \ref{app: Proof},  we provide theoretical proofs.

    \item In App. \ref{Sec: appendix behavior space},  we provide several implementations of LBC-based behavior sapce design to facilitate future research.

    \item In App. \ref{Sec: appendix MAB}, we provide a detailed implementation of our MAB-based meta-controller.
    \item In App. \ref{app: Algorithm Pseudocode}, we provide a detailed implementation of our core framework.
    \item In App. \ref{app: An LBC-based Version of RL}, we use our framework to introduce an LBC-based version of well-known RL methods, which leads to a better understanding of their original counterparts. 
    \item In App. \ref{sec:app Experiment Details}, we provide relevant details of our experiments.
    \item In App. \ref{Sec: appendix hyper-parameters},  we summarize the hyper-parameters used in our experiments.
    
    \item In App. \ref{appendix: experiment results}, we provides full learning curves for all games and detailed comparison tables of raw and normalized scores.
    
    \item In App. \ref{app: Ablation Study}, we provides the design of the ablation study and the overall results.

    \item In App. \ref{app: Model Architecture}, we  summarize our  model architecture in detail to for reproducibility.

\end{itemize}

\clearpage
\section{Summary of Notation and Abbreviation}
\label{app: Abbreviation and Notation}
In this section, we briefly summarize some common notations in this paper for the convenience of readers, which are concluded in Tab. \ref{tab: notation}.

\begin{table}[!hb]
	\centering
	\caption{Summary of Notation}
	\label{tab: notation}
 \resizebox{\textwidth}{!}{\begin{tabular}{l l l l }
	    \toprule
		\textbf{Symbol} &\textbf{Description} & \textbf{Symbol} &\textbf{Description}\\
		\midrule
	     & State &  & Set of all states \\
     
	     & Action &  & Set of all actions \\
     
	      &  Probability distribution &  & Behavior policy \\
     
	     & Policy &  & Cumulative discounted reward at  \\
     
	      & States visitation distribution of  &  & State value function of \\
     
	     &  State-action value function of  &  &  Advantage function of \\
     
	     & Discount-rate parameter &  & Temporal-difference error at \\

         & Behavior mapping &  & Policy models \\
        
	      & \makecell[l]{Parameters  of the policy network } &   & Set of   \\
	 
   & hyper-parameters of policy models  &  & Set of   \\
     
	     & Parameters to index  &  & Set of    \\
    
	     & Behavior policy sets/space parameterized by  
 &  & A behavior policy of \\

         & Size of set  &  &  Size of set  \\
	    
	     & Behavior selection distribution over &  & One-point distribution  \\
	    
      &  Some measurement on the value of policy  &  & Some measurement on the  diversity of policy  \\

     	       & Subspace of   &  & Reward shaping\\
	    \bottomrule	    
	\end{tabular} 
 }
\end{table}




































\clearpage
\section{Background}
\label{app: background on RL}


Similar to deep learning \citep{cl,actionr,6d,dclsr,wang2023dr,wang2022lhnn}, reinforcement learning is also a branch of machine learning.  Most of the previous work has introduced the background knowledge of RL in detail. In this section, we only summarize and recall the background knowledge used in this paper. If you are interested in the relevant content, we recommend you read the relevant material \citep{pi2,sutton}. The relevant notations and abbreviations have been documented in App. \ref{app: Abbreviation and Notation}.


\subsection{Policy Gradient}
\label{app: pg}

Policy gradient methods, denoted as PG \citep{williams1992simple,casa,entropy}, belong to the category of policy-based reinforcement learning approaches. These methods employ an optimization process to update the policy by maximizing the target function:



The Actor-Critic (AC) methods compute the policy gradient by updating the AC policy as follows \citep{sutton}:

wherein  could be   or . 

\subsection{Vtrace}
\label{app: vtrace}
V-Trace is an off-policy correction technique devised by the IMPALA framework \citep{impala} to address the dissimilarity between the target policy and behavior policy. The estimation of  in V-Trace is computed by:

wherein  and . 

\subsection{Retrace}
\label{app: retrace}
ReTrace, a methodology proposed in \citep{retrace}, computes  by the following expression:

where . 
\clearpage


\section{Proof}
\label{app: Proof}



\begin{proof}[Proof of \textbf{Proposition} \ref{proposition: Behavior Control via policy models Selection}]
\label{pf: pr 1}
When  is a pre-defined or rule-based mapping,  of actor  at each training step (wall-clock) is deterministic, namely , so each behavior of actor  can be  uniquely indexed by , namely,


where  is the same for each behavior of actor . Hence, the selection distribution of behavior can be simplified into the selection distribution over  as:

where   and  is a selection distribution of  and  is the number of policy models.
Substituting \eqref{equ: select h} into \eqref{equ: reward-diversity trade-off problem}, we can obtain



\end{proof}

\begin{Corollary}[Behavior Circling in Policy Model Selection]
\label{Corollary:Behavior Circling in policy model Selection}
    When the policy models overlap as  , all realizable behavior of actor  will overlap as . Behaviors from different model can not be distinguished by , the behavior selection via policy model selection becomes invalid. 
\end{Corollary}




\begin{proof}[Proof of \textbf{Proposition} \ref{proposition: Behavior Control via behavior mapping optimization}]
   \label{pf: pr 2} 

   When  are shared among behaviors for each actor at each training step, such as  or , each behavior for each behavior can be uniquely indexed by , namely, 
   

where  is the same among behaviors. Hence, the selection distribution of behavior can be simplified into the selection distribution of  as 

where   is a selection distribution of . Substituting \eqref{equ: select psi} into \eqref{equ: reward-diversity trade-off problem}, we can obtain




\end{proof}



The behavior mapping optimization may be a cure for the behavior circling:
\begin{Corollary}[Behavior Mapping Optimization Is An Antidote for Behavior Circling]
\label{Corollary: behavior mapping optimization is an Antidote for Behavior Circling}
As for an behavior mapping optimization method, the behavior of actor  is indexed by . When all the policy models overlap as , the realizable behavior of actor  are 

wherein  is a continuous parameter.
Assuming  can be uniquely indexed by  and , there are still infinite different behaviors that can be realized by actor .
\end{Corollary}


\begin{Proposition}[Comparison of Behavior Space]
\label{Proposition: Comparison of Behavior Space}
Given two behavior space  and , if  is a sub-space of , the space   is not less than  . Furthermore, if  is a sub-space of  and  is not equal to , the space   is larger than  .
\end{Proposition}

\begin{proof}[Proof of \textbf{Proposition} \ref{Proposition: Comparison of Behavior Space}]
    Since  and  are sets. When ,  is not larger than . When ,  is smaller than 
\end{proof}

According to the behavior space construction formulation, we can draw the following Corollary:
\begin{Corollary}
\label{Corollary: space not smaller}
        Given the same policy model structure  and the same form of behavior mapping  . Under Assumption \ref{ass: share model}, the behavior space can be fully determined by  and .  For any two behavior space  and , if  and , the behavior space  is a sub-space of . Based on that, the space   is not smaller than  .
\end{Corollary}

\begin{Corollary}
\label{Corollary: space larger}
        Given the same policy model structure  and the same form of behavior mapping  . Under Assumption \ref{ass: share model}, the behavior space can be fully determined by  and .  For any two behavior space  and , if at least one of the following conditions holds: 
        \begin{itemize}
            \item  and , 
            \item  and  ,
            \item  and  ,
        \end{itemize}
        the behavior space  is a sub-space of  and  is not equal to . Based on that, the space   is larger than  .
\end{Corollary}



\clearpage
















\section{Behavior Space Construction For More Tasks and Algorithms Via LBC}
\label{Sec: appendix behavior space}
Following the pipeline given in \eqref{equ: enlarged bs}, different implementations of LBC can be acquired by simply selecting different entropy control function  and behavior distillation function  according to the corresponding RL algorithms and tasks. 

\subsection{Selection for entropy control function}
Here we would give some examples for the selection of entropy control function .

\paragraph{Continuous Control Tasks} For tasks with continuous action spaces, the entropy control function can be selected as gaussian distribution, \ie

or uniform distribution, \ie

where  for gaussian distribution and  for uniform distribution.

\paragraph{Discrete Control Tasks and Value-Based Algorithms}

where .

\paragraph{Discrete Control Tasks and Policy-Based Algorithms}

where .

\subsection{Selection for Behavior Distillation Function}
\paragraph{Mixture Model}


\paragraph{Knowledge Distillation}
The knowledge distillation method can been seen as a  derivative form of mixture model. The mixture model is simple and straightforward, but it requires more resources for model storage and inference. To address this disadvantage, we can distill the knowledge of multiple policies into a single network using knowledge distillation.

and the knowledge distillation process  can be realized by supervised learning.

\paragraph{Parameters Fusion} 
Define  as the generated behavior policy which shares the same network structure with the policy models in the population, and is parameterized by . Define  as the parameters of policy . Then we can define the parameters fusion function ,

where .

\clearpage
\section{Adaptive Control Mechanism}
\label{Sec: appendix MAB}

In this paper, we cast the behavior control into the behavior mapping optimization, which can be further simplified into the selection of . We formalize this problem via multi-armed bandits (MAB).  In this section, we describes  the multi-arm bandit design of our method. For a more thorough explanation and analysis, we refer the readers to \citep{garivier2008upper}.




 
\subsection{Discretization}
Since  is a continuous space, the optimization of  is a  continuous optimization problem.  However, MAB usually only handle discrete control tasks. Hence, we have to discretize  into  regions according to the discretization accuracy , wherein each arm of MAB corresponds to a region of the continuous space. 

\begin{Remark}
    The discretization accuracy   is related to the accuracy of the algorithm. In general, a higher discretization accuracy indicates a higher accuracy of the algorithm, but correspondingly, a higher computational complexity of the algorithm.
\end{Remark}

\begin{Example}[Example of Discretization]
    As for a -greedy behavior mapping,  and . We can set the discretization accuracy , and we can discretize  into  regions corresponding to  arms. Each arm corresponds to an interval. For example,  corresponds to ;  corresponds to ... corresponds to .
\end{Example}





\subsection{Sample and Update} 

We adopt the Thompson Sampling \citep{garivier2008upper}.  denote a set of arms available to the decision maker, who is interested in maximizing the expected cumulative return \citep{agent57,DvD}. The optimal strategy for each actor is to pull the arm with the largest mean reward. At the beginning of each round, each actor will produce a sample mean from its mean reward model for each arm, and pulls the arm from which it obtained the largest sample. After observing the selected arm's reward, it updates its mean reward model.


In general, at each time , MAB method will choose an arm  from all possible arms  according to a sampling distribution , which is normally conditioned on the sequence of previous decisions and returns. Then we will uniformly sample the parameters  from this discretized regions.  Based on the , we can obtain the corresponding behavior according to  or . Executing the behaviors in the environment, each actor will receive a excitation/reward signal  , which will be used to update the MAB.




\subsection{Upper Confidence Bound}

The UCB \citep{garivier2008upper} are often used to encourage MAB to try more the arms with a low frequency of use. Let's first define the number of times that the arm  has been selected within T rounds as follows:



Then we can obtain the empirical mean of the arm x within T rounds as follows:



The UCB methods  encourage the decision maker (actor-wise) to maximize the UCB scores:

The optimal strategy for each actor is to pull the arm with the largest mean scores. At the beginning of each round, each actor will produce a sample mean from its mean reward model for each arm, and pulls the arm from which it obtained the largest sample. After observing the selected arm's scores, it updates its mean reward model.

\begin{Remark}
    In practical,  Z-score Normalization  are normally  used to  normalized , namely , which can be formulated as 
    
\end{Remark}


\subsection{Population-Based  MAB}
In the non-stationary scenario, the distributions of  could be shifted in the course of the lifelong learning. The standard UCB-based MAB failed  to adapt to the change of the reward distribution and thus we refer to a population-based MAB to handle this problem, which jointly train a population of MAB with different hyperparameters. The sampling and update procedure of MAB is slightly different from the origin MAB, which will be discussed in the following. The main implementation of our population-based MAB has been concluded in Algorithm \ref{alg:bva}. 

\subsubsection{MAB Population Formulation}
Assuming there are  bandits  to from a population , wherein each bandit can be uniquely indexed by its hyper-parameter  and keep other hyper-parameters remain the same such as the discretization. In this paper, , wherein  is the trade-off coefficient in \eqref{equ: ucb score}, which is uniformly sampled from , \ie randomly select a  while initializing each bandit. 

\subsubsection{Population-Based Sample}
During the sampling procedure, each bandit  will sample  arm  with the Top-D ucb-scores.  After all the bandits sample  arm, there are  sampled arms. We summarize the number of times each arm is selected, and sorted in descending order by the number of times they are selected. Then,  we can obtain an arm  that is selected the most times, which is the sample output of the population-based MAB. Finally, we uniformly sample a  from  the region indexed by .


\begin{Example}
    Assuming there are 7 bandits, and each bandit will sample  arms from . Assuming that the sample output is as follows:
    
    Then, the arm  is the arm being selected the most times, so we can get the sampled arm . 
\end{Example}

\begin{Remark}
    Noting that, if there are more than one arm that is selected the most times, we can uniformly sample one from these arms.
\end{Remark}

\subsubsection{Population-Based Update}
With , according to the behavior space \eqref{equ: behavior space with hybrid behavior mapping} , we can obtain a behavior  or .  Execute  in the environment and we can obtain obtain the return . With , we can update each bandit in the population based on \eqref{equ: N} - \eqref{equ: ucb score}.

\subsubsection{Bandit Replacement}
Similar to the sliding windows ~\citep{agent57}, to tackle the  non-stationary  problem, we have to track the changes of optimization objectives in a timely manner. To achieve this, we update the replace in the population regularly so that it captures short-term information to improve its tracking performance. 

\begin{figure}[ht]
  \centering
  \begin{minipage}{.9\linewidth}
    \begin{algorithm}[H]
      \caption{Population-Based Multi-Arm Bandits (Actor-Wise)}  
          \begin{algorithmic}
          \STATE // For Each Actor j
          \STATE // Initialize Bandits Population
            \STATE Initialize each bandit   in the population with different hyper-parameters .
                \STATE Incorporate each bandit together to form a population of bandits .
            \FOR{each episode t}
            \FOR{each  in }
            \STATE Sample  arms  with Top-D UCB Score via \eqref{equ: ucb score}.
            \ENDFOR
            \STATE Summarize  arms and count the selected times of each arm.
            \STATE Uniformly sample an arm among arms that selected the most times to obtain arm .
            \STATE Uniformly sample a  from  the region indexed by .
            \STATE Obtain a behavior  or .
            \STATE Execute  and obtain the return .
                        \FOR{each  in }
            \STATE Update  via  \eqref{equ: N} and \eqref{equ: ucb score no z-score}.
            \ENDFOR
            \STATE Update each bandit in the population via  \eqref{equ: N} and \eqref{equ: ucb score no z-score}.
            \STATE // Replace Bandit from The Population
            \IF{t mod =0}
            \STATE Remove one bandit from the bandit population Uniformly and recreate (reinitialize) one into it.
            \ENDIF
            \ENDFOR
          \end{algorithmic}  
        \label{alg:bva}
    \end{algorithm}
  \end{minipage}
\end{figure}


Noting that there are many methods to solve this non-stationary problem at present, such as the sliding windows ~\citep{agent57}. Since this is not the main proposition of this paper, we just choose a feasible implementation to handle this problem.

\clearpage

\section{Algorithm Pseudocode}
\label{app: Algorithm Pseudocode}
We concluded our algorithm in in the Algorithm. \ref{app alg:LBC}. Apart from that, we also concluded our model architecture in App. \ref{app: Model Architecture}.

\begin{figure}[ht]
  \centering
  \vspace{-0.1in}
  \begin{minipage}{\linewidth}
    \begin{algorithm}[H]
      \caption{Learnable Behavior Control}
          \begin{algorithmic}
          \STATE Initialize the Data Buffer (DB), the Parameter Sever (PS), the Learner Push Parameter Interval  and the Actor Pull Paramter Interval  .
          \STATE // LEARNER i
          \STATE Initialize the network parameter  (for model structure, see App. \ref{app: Model Architecture})
          \FOR{Training Step t}
          \STATE Load data from DB.
          \STATE Estimate  by , wherein the target policy .
          \STATE Estimate  by , wherein the target policy .
          \STATE Update  via 
          \IF{t mod }
          \STATE Push  into PS.
          \ENDIF
          \ENDFOR
          \STATE // ACTOR j
         \FOR{kth episode at training step t}
            \STATE   Sample a  via the MAB-based meta-controller (see App. \ref{Sec: appendix MAB}).
            
            \STATE \textbf{Generalized Policy Selection.} Adjusting the contribution proportion of the each learned policies for the behavior via a importance weight .
            
            \STATE \textbf{Policy-Wise Entropy Control.} Adjusting  the entropy of each policy via a , (e.g., ).
            
            \STATE \textbf{Behavior Distillation from 
            Multiple Policies.} Distilling the entropy-controlled policies into a behavior policy  via a mixture model . 
            \STATE Obtaining episode  and reward  via executing , and push  into  DB.
            \STATE Update the meta-controller  with .
          \IF{t mod  }
          \STATE Pull  from PS.
          \ENDIF
        \ENDFOR
          \end{algorithmic}
        \label{app alg:LBC}
    \end{algorithm}
  \end{minipage}
\end{figure}

\clearpage

\section{An LBC-based Version of RL}
\label{app: An LBC-based Version of RL}
The behavior space is vital for RL methods, which can be used to categorize RL algorithms. Given the model structure , and the form of , the behavior space can be fully determined by  and , which can be used to categorize RL methods. We say one algorithm belongs to LBC-- when \textbf{1)} the hyper-parameters  is a C-D vector and  has N possible values corresponding to N different policy models, and \textbf{2)}  is a K-D vector and  has L possible values corresponding to L realizable behavior mappings at each training step. Based on that, we can offer a general view to understand prior methods from the perspective of behavior control, which is illustrated in Tab. \ref{tab:lbc_rl}.
\begin{comment}
    虽然总空间是，但是这个空间是受限的，并不是每一个点都能全部取到。对于每个actor来说，他只能从N个model中做出选择。
\end{comment}
\begin{table*}[!htbp]
    \centering
    \caption{An LBC-based Version of RL Methods.}
    \label{tab:lbc_rl}
    \resizebox{\textwidth}{!}{\begin{tabular}{l l l l l l}
    \toprule
                Algorithm &  PBT  & Agent57 &  DvD  & LBC- (Ours)\\
    \midrule

                 &  &  & identical mapping &  \\

                 &  &  &  &  \\
                
                  &   &  &   &  \\
                
                     &     &  &   &         \\
                   


                  
                 Category   & LBC-H- & LBC-H- & LBC-H-& LBC-H-\\
                  &  &  &  &  \\
                 Meta-Controller () & ES    & MAB  & MAB    & Ensemble  \eqref{equ: behavior space with hybrid behavior mapping} \\
                 Meta-Controller ()  & Rule-Based  & Rule-Based   & Rule-Based & MAB                \\
\bottomrule
    \end{tabular}
    }
\end{table*}
\normalsize


\clearpage
\section{Experiment Details}
\label{sec:app Experiment Details}



\subsection{Implementation Details}


On top of the general training architecture is the Learner-Actor framework  \citep{impala}, which makes large-scale training easier. 
We employ the burn-in method  \citep{r2d2} to address representational drift and twice train each sample. The recurrent encoder with LSTM \citep{lstm} is also used to solve the partially observable MDP problem \citep{ale}. For a thorough discussion of the hyper-parameters, see App. \ref{Sec: appendix hyper-parameters}. 




\subsection{Experimental Setup}

The undiscounted episode returns averaged over 5 seeds are captured using a windowed mean across 32 episodes in addition to the default parameters. All agents were evaluated on 57 Atari 2600 games from the arcade learning environment \citep[ALE]{ale} using the population's average score from model training. Noting that episodes would end at 100K frames, like per prior baseline techniques \citep{rainbow,agent57,laser,ngu,r2d2}. 


\subsection{Resources Used}
\label{app: Resources Used}
All the experiment is accomplished using 10 workers with 72 cores CPU and 3 learners with 3 Tesla-V100-SXM2-32GB GPU.



\clearpage

\section{hyper-parameters}
\label{Sec: appendix hyper-parameters}
The hyper-parameters that we used in all experiments are like those of NGU \cite{ngu} and Agent57 \citep{agent57}. However, for completeness and readability, we detail
them below in  Tab. \ref{tab:fixed_model_hyper-parameters_atari}. We also include the hyper-parameters we used in the population-based MAB. For more details on the parameters in ALE, we refer the readers to see \citep{ale2}.


\begin{table}[H]
\begin{center}
\caption{Hyper-Parameters for Atari Experiments.}
\label{tab:fixed_model_hyper-parameters_atari}
\resizebox{\textwidth}{!}{\begin{tabular}{l l l l }
\toprule
\textbf{Parameter} & \textbf{Value} & \textbf{Parameter} & \textbf{Value}  \\
\midrule
Burn-in & 40 & Replay & 2 \\



Seq-length & 80 & Burn-in Stored Recurrent State & Yes \\



Bootstrap & Yes  & Batch size & 64 \\



-loss Scaling () & 1.0  & -loss Scaling () & 5.0 \\



-loss Scaling () & 5.0  & Importance sampling clip  & 1.05 \\



Importance Sampling Clip  & 1.05 & LSTM Units & 256 \\



Weight Decay Rate & 0.01 & Optimizer & Adam weight decay    \\



Learning Rate & 5.3e-4  & Weight Decay Schedule & Anneal linearly to 0   \\



Warmup Steps & 4000 & Learning Rate Schedule & Anneal linearly to 0 \\



AdamW  & 0.9  & Auxiliary Forward Dynamic Task & Yes  \\



AdamW  & 1e-6 & Learner Push Model Every  Steps & 25   \\



AdamW  & 0.98  & Auxiliary Inverse Dynamic Task & Yes \\



AdamW Clip Norm & 50.0  & Actor Pull Model Every  Steps & 64 \\



 & 0.997  &   &\\

 & 0.999  &  (log scaling) &  \\ 

 & 0.99 &    &  \\ 

Population Num.   & 7  &  UCB  & Uniformly sampled from \\ 

D of Top-D  & 4 & Replacement Interval   & 50   \\
Range of  &   & Range of  & \\ 
Discrete Accuracy of  & 0.2 & Discrete Accuracy of  & 0.1 \\
Max episode length   & 30  & Image Size & (84, 84) \\
Grayscaled/RGB      & Grayscaled & Life information & Not allowed  \\
Action Space & Full & Sticky action probability  & 0.0 \\
Num. Action Repeats & 4 & Random noops range  & 30\\
Num. Frame Stacks & 4 & Num. Atari Games & 57 (Full)\\
\bottomrule
\end{tabular} 
}
\end{center}
\end{table}



\clearpage



\section{Experimental Results}
\label{appendix: experiment results}




\subsection{Atari Games Learning Curves}



\renewcommand{\thesubfigure}{\arabic{subfigure}.}
\setcounter{subfigure}{0}

\begin{figure}[!ht] 
    \subfigure[Alien]{
    \includegraphics[width=0.3\textwidth,height=0.15\textheight]{./photo/main/1.pdf}
    }
    \subfigure[Amidar]{
    \includegraphics[width=0.3\textwidth,height=0.15\textheight]{./photo/main/2.pdf}
    }
    \subfigure[Assault]{
    \includegraphics[width=0.3\textwidth,height=0.15\textheight]{./photo/main/3.pdf}
    }
\end{figure}

\begin{figure}[!ht]
    \subfigure[Asterix]{
    \includegraphics[width=0.3\textwidth,height=0.15\textheight]{./photo/main/4.pdf}
    }
    \subfigure[Asteroids]{
    \includegraphics[width=0.3\textwidth,height=0.15\textheight]{./photo/main/5.pdf}
    }
    \subfigure[Atlantis]{
    \includegraphics[width=0.3\textwidth,height=0.15\textheight]{./photo/main/6.pdf}
    }
\end{figure}

\begin{figure}[!ht]
    \subfigure[Bank\_Heist]{
    \includegraphics[width=0.3\textwidth,height=0.15\textheight]{./photo/main/7.pdf}
    }
    \subfigure[Battle\_Zone]{
    \includegraphics[width=0.3\textwidth,height=0.15\textheight]{./photo/main/8.pdf}
    }
    \subfigure[Beam\_Rider]{
    \includegraphics[width=0.3\textwidth,height=0.15\textheight]{./photo/main/9.pdf}
    }
\end{figure}

\begin{figure}[!ht]
    \subfigure[Berzerk]{
    \includegraphics[width=0.3\textwidth,height=0.15\textheight]{./photo/main/10.pdf}
    }
    \subfigure[Bowling]{
    \includegraphics[width=0.3\textwidth,height=0.15\textheight]{./photo/main/11.pdf}
    }
    \subfigure[Boxing]{
    \includegraphics[width=0.3\textwidth,height=0.15\textheight]{./photo/main/12.pdf}
    }
\end{figure}

\begin{figure}[!ht]
    \subfigure[Breakout]{
    \includegraphics[width=0.3\textwidth,height=0.15\textheight]{./photo/main/13.pdf}
    }
    \subfigure[Centipede]{
    \includegraphics[width=0.3\textwidth,height=0.15\textheight]{./photo/main/14.pdf}
    }
    \subfigure[Chopper\_Command]{
    \includegraphics[width=0.3\textwidth,height=0.15\textheight]{./photo/main/15.pdf}
    }
\end{figure}


\begin{figure}[!ht]
    \subfigure[Crazy\_Climber]{
    \includegraphics[width=0.3\textwidth,height=0.15\textheight]{./photo/main/16.pdf}
    }
    \subfigure[Defender]{
    \includegraphics[width=0.3\textwidth,height=0.15\textheight]{./photo/main/17.pdf}
    }
    \subfigure[Demon\_Attack]{
    \includegraphics[width=0.3\textwidth,height=0.15\textheight]{./photo/main/18.pdf}
    }
\end{figure}

\begin{figure}[!ht]
    \subfigure[Double\_Dunk]{
    \includegraphics[width=0.3\textwidth,height=0.15\textheight]{./photo/main/19.pdf}
    }
    \subfigure[Enduro]{
    \includegraphics[width=0.3\textwidth,height=0.15\textheight]{./photo/main/20.pdf}
    }
    \subfigure[Fishing\_Derby]{
    \includegraphics[width=0.3\textwidth,height=0.15\textheight]{./photo/main/21.pdf}
    }
\end{figure}

\begin{figure}[!ht]
    \subfigure[Freeway]{
    \includegraphics[width=0.3\textwidth,height=0.15\textheight]{./photo/main/22.pdf}
    }
    \subfigure[Frostbite]{
    \includegraphics[width=0.3\textwidth,height=0.15\textheight]{./photo/main/23.pdf}
    }
    \subfigure[Gopher]{
    \includegraphics[width=0.3\textwidth,height=0.15\textheight]{./photo/main/24.pdf}
    }
\end{figure}

\begin{figure}[!ht]
    \subfigure[Gravitar]{
    \includegraphics[width=0.3\textwidth,height=0.15\textheight]{./photo/main/25.pdf}
    }
    \subfigure[Hero]{
    \includegraphics[width=0.3\textwidth,height=0.15\textheight]{./photo/main/26.pdf}
    }
    \subfigure[Ice\_Hockey]{
    \includegraphics[width=0.3\textwidth,height=0.15\textheight]{./photo/main/27.pdf}
    }
\end{figure}

\begin{figure}[!ht]
    \subfigure[Jamesbond]{
    \includegraphics[width=0.3\textwidth,height=0.15\textheight]{./photo/main/28.pdf}
    }
    \subfigure[Kangaroo]{
    \includegraphics[width=0.3\textwidth,height=0.15\textheight]{./photo/main/29.pdf}
    }
    \subfigure[Krull]{
    \includegraphics[width=0.3\textwidth,height=0.15\textheight]{./photo/main/30.pdf}
    }
\end{figure}

\begin{figure}[!ht]
    \subfigure[Kung\_Fu\_Master]{
    \includegraphics[width=0.3\textwidth,height=0.15\textheight]{./photo/main/31.pdf}
    }
    \subfigure[Montezuma\_Revenge]{
     \includegraphics[width=0.3\textwidth,height=0.15\textheight]{./photo/main/32.pdf}
    }
    \subfigure[Ms\_Pacman]{
    \includegraphics[width=0.3\textwidth,height=0.15\textheight]{./photo/main/33.pdf}
    }
\end{figure}

\begin{figure}[!ht]
    \subfigure[Name\_This\_Game]{
    \includegraphics[width=0.3\textwidth,height=0.15\textheight]{./photo/main/34.pdf}
    }
    \subfigure[Phoenix]{
     \includegraphics[width=0.3\textwidth,height=0.15\textheight]{./photo/main/35.pdf}
    }
    \subfigure[Pitfall]{
    \includegraphics[width=0.3\textwidth,height=0.15\textheight]{./photo/main/36.pdf}
    }
\end{figure}

\begin{figure}[!ht]
    \subfigure[Pong]{
    \includegraphics[width=0.3\textwidth,height=0.15\textheight]{./photo/main/37.pdf}
    }
    \subfigure[Private\_Eye]{
    \includegraphics[width=0.3\textwidth,height=0.15\textheight]{./photo/main/38.pdf}
    }
    \subfigure[Qbert]{
     \includegraphics[width=0.3\textwidth,height=0.15\textheight]{./photo/main/39.pdf}
    }
\end{figure}

\begin{figure}[!ht]
    \subfigure[Riverraid]{
    \includegraphics[width=0.3\textwidth,height=0.15\textheight]{./photo/main/40.pdf}
    }
    \subfigure[Road\_Runner]{
    \includegraphics[width=0.3\textwidth,height=0.15\textheight]{./photo/main/41.pdf}
    }
    \subfigure[Robotank]{
    \includegraphics[width=0.3\textwidth,height=0.15\textheight]{./photo/main/42.pdf}
    }
\end{figure}

\begin{figure}[!ht]
    \subfigure[Seaquest]{
    \includegraphics[width=0.3\textwidth,height=0.15\textheight]{./photo/main/43.pdf}
    }
    \subfigure[Skiing]{
    \includegraphics[width=0.3\textwidth,height=0.15\textheight]{./photo/main/44.pdf}
    }
    \subfigure[Solaris]{
    \includegraphics[width=0.3\textwidth,height=0.15\textheight]{./photo/main/45.pdf}
    }
\end{figure}

\begin{figure}[!ht]
    \subfigure[Space\_Invaders]{
     \includegraphics[width=0.3\textwidth,height=0.15\textheight]{./photo/main/46.pdf}
    }
    \subfigure[Star\_Gunner]{
    \includegraphics[width=0.3\textwidth,height=0.15\textheight]{./photo/main/47.pdf}
    }
    \subfigure[Surround]{
    \includegraphics[width=0.3\textwidth,height=0.15\textheight]{./photo/main/48.pdf}
    }
\end{figure}

\begin{figure}[!ht]
    \subfigure[Tennis]{
    \includegraphics[width=0.3\textwidth,height=0.15\textheight]{./photo/main/49.pdf}
    }
    \subfigure[Time\_Pilot]{
    \includegraphics[width=0.3\textwidth,height=0.15\textheight]{./photo/main/50.pdf}
    }
    \subfigure[Tutankham]{
    \includegraphics[width=0.3\textwidth,height=0.15\textheight]{./photo/main/51.pdf}
    }
\end{figure}

\begin{figure}[!ht]
    \subfigure[Up\_N\_Down]{
    \includegraphics[width=0.3\textwidth,height=0.15\textheight]{./photo/main/52.pdf}
    }
    \subfigure[Venture]{
    \includegraphics[width=0.3\textwidth,height=0.15\textheight]{./photo/main/53.pdf}
    }
    \subfigure[Video\_Pinball]{
    \includegraphics[width=0.3\textwidth,height=0.15\textheight]{./photo/main/54.pdf}}
\end{figure}

\begin{figure}[!ht]
    \subfigure[Wizard\_of\_Wor]{
    \includegraphics[width=0.3\textwidth,height=0.15\textheight]{./photo/main/55.pdf}
    }
    \subfigure[Yars\_Revenge]{
    \includegraphics[width=0.3\textwidth,height=0.15\textheight]{./photo/main/56.pdf}
    }
    \subfigure[Zaxxon]{
    \includegraphics[width=0.3\textwidth,height=0.15\textheight]{./photo/main/57.pdf}
    }
\end{figure}

\clearpage





\def\agentmeanhns{4762.17}
\def\agentmeanhnsle{4.76E-10}

\def\agentmedianhns{1933.49}
\def\agentmedianhnsle{1.93E-10}

\def\agentHWRB{18}
\def\agentHWRBle{1.80E-10}


\def\agentmeanHWRNS{125.92}
\def\agentmeanHWRNSle{1.26E-11}


\def\agentmedianHWRNS{43.62}
\def\agentmedianHWRNSle{4.36E-12}


\def\agentmeanSABER{76.26}
\def\agentmeanSABERle{7.63E-12}


\def\agentmedianSABER{43.62}
\def\agentmedianSABERle{4.36E-12}

\def\agentnumframes{1.00E+11}
\def\agentgametime{19290}




\def\muzeromeanhns{4994.97}
\def\muzeromeanhnsle{2.50E-09}

\def\muzeromedianhns{2041.12}
\def\muzeromedianhnsle{1.02E-09}

\def\muzeroHWRB{19}
\def\muzeroHWRBle{9.50E-10}


\def\muzeromeanHWRNS{152.10}
\def\muzeromeanHWRNSle{7.61E-11}


\def\muzeromedianHWRNS{49.80}
\def\muzeromedianHWRNSle{2.49E-11}


\def\muzeromeanSABER{71.94}
\def\muzeromeanSABERle{3.60E-11}


\def\muzeromedianSABER{49.80}
\def\muzeromedianSABERle{2.49E-11}

\def\muzeronumframes{2.00E+10}
\def\muzerogametime{3858}



\def\dreamermeanhns{642.49}
\def\dreamermeanhnsle{3.21E-08}

\def\dreamermedianhns{178.04}
\def\dreamermedianhnsle{8.90E-09}

\def\dreamerHWRB{3}
\def\dreamerHWRBle{1.50E-08}


\def\dreamermeanHWRNS{38.60}
\def\dreamermeanHWRNSle{1.93E-09}


\def\dreamermedianHWRNS{4.29}
\def\dreamermedianHWRNSle{2.14E-10}


\def\dreamermeanSABER{27.73}
\def\dreamermeanSABERle{1.39E-09}


\def\dreamermedianSABER{4.29}
\def\dreamermedianSABERle{2.14E-10}

\def\dreamernumframes{2.00E+08}
\def\dreamergametime{38.58 }

\def\simplemeanhns{194.3}
\def\simplemeanhnsle{2.58E-07}

\def\simplemedianhns{109}
\def\simplemedianhnsle{5.55E-08}

\def\simpleHWRB{0}
\def\simpleHWRBle{0.00E+00}


\def\simplemeanHWRNS{4.80}
\def\simplemeanHWRNSle{4.80E-08}


\def\simplemedianHWRNS{0.13}
\def\simplemedianHWRNSle{1.25E-09}


\def\simplemeanSABER{4.80}
\def\simplemeanSABERle{4.80E-08}


\def\simplemedianSABER{0.13}
\def\simplemedianSABERle{1.25E-09}

\def\simplenumframes{1.00E+06}
\def\simplegametime{0.19}



\def\mueslimeanhns{2538.12}
\def\mueslimeanhnsle{1.27E-07}

\def\mueslimedianhns{1077.47}
\def\mueslimedianhnsle{5.39E-08}

\def\muesliHWRB{5}
\def\muesliHWRBle{2.50E-08}


\def\mueslimeanHWRNS{75.52}
\def\mueslimeanHWRNSle{3.78E-09}


\def\mueslimedianHWRNS{24.86}
\def\mueslimedianHWRNSle{1.24E-09}


\def\mueslimeanSABER{48.74}
\def\mueslimeanSABERle{2.44E-09}


\def\mueslimedianSABER{24.86}
\def\mueslimedianSABERle{1.24E-09}

\def\mueslinumframes{2.00E+08}
\def\muesligametime{38.5}


\def\goexploremeanhns{4989.31}
\def\goexploremeanhnsle{4.99E-09}

\def\goexploremedianhns{1451.55}
\def\goexploremedianhnsle{1.45E-09}

\def\goexploreHWRB{15}
\def\goexploreHWRBle{1.50E-09}


\def\goexploremeanHWRNS{116.89}
\def\goexploremeanHWRNSle{1.17E-10}


\def\goexploremedianHWRNS{50.50}
\def\goexploremedianHWRNSle{5.05E-11}


\def\goexploremeanSABER{71.80}
\def\goexploremeanSABERle{7.18E-11}


\def\goexploremedianSABER{50.50}
\def\goexploremedianSABERle{5.05E-11}

\def\goexplorenumframes{1.00E+10}
\def\goexploregametime{1929}


\def\LBCHmeanhns{10077.52}
\def\LBCHmeanhnsle{4.81E-07 }

\def\LBCHmedianhns{1665.60}
\def\LBCHmedianhnsle{5.73E-08 }

\def\LBCHHWRB{24 }
\def\LBCHHWRBle{1.10E-07 }


\def\LBCHmeanHWRNS{154.27}
\def\LBCHmeanHWRNSle{7.71E-09 }


\def\LBCHmedianHWRNS{50.63}
\def\LBCHmedianHWRNSle{2.53E-09 }


\def\LBCHmeanSABER{71.26}
\def\LBCHmeanSABERle{3.56E-09 }


\def\LBCHmedianSABER{50.63}
\def\LBCHmedianSABERle{2.53E-09 }

\def\LBCHnumframes{1.00E+09 }
\def\LBCHgametime{192.5 }


\def\mememeanhns{4081.14}

\def\mememedianhns{1225.19}

\def\memeHWRB{24 }
\def\memeHWRBle{1.10E-07 }


\def\mememeanHWRNS{154.27}
\def\mememeanHWRNSle{7.71E-09 }


\def\mememedianHWRNS{50.63}
\def\mememedianHWRNSle{2.53E-09 }


\def\mememeanSABER{71.26}
\def\mememeanSABERle{3.56E-09 }


\def\mememedianSABER{50.63}
\def\mememedianSABERle{2.53E-09 }

\def\memenumframes{1.00E+09 }
\def\memegametime{192.5 }


\subsection{Atari Games Table of Scores Based on Human Average Scores}
\label{app: Atari Games Table of Scores Based on Human Average Records}
We present the raw score of several typical SOTA algorithms, including model-free SOTA algorithms, model-based SOTA algorithms, and additional SOTA algorithms. We provide the Human Normalized Scores (HNS) for each algorithm in the Atari 57 games in addition to presenting the raw score for each game. More details on these algorithms can see \cite{ale2,atarihuman,atari_review}.

\clearpage


\begin{table}[!hb]
\footnotesize
\begin{center}
\caption{Score table of  SOTA  model-free algorithms on HNS(\%).}
\label{Tab:Score table of SOTA  model-free algorithms on HNS.}
\setlength{\tabcolsep}{1.0pt}
\begin{tabular}{c c c c c c c cc}
\toprule
Games & RND & Average Human & AGENT57 & HNS(\%) & Ours & HNS(\%) & MEME & HNS(\%) \\
        Scale & ~ & ~ & 100B & ~ & 1B & ~ & 1B & ~\\ \midrule
        Alien & 227.8 & 7127.8 & \textbf{297638.17} & \textbf{4310.30\%} & 279703.5 & 4050.37\% & 83683.43&	1209.50\%\\  
        Amidar & 5.8 & 1719.5 & \textbf{29660.08} & \textbf{1730.42\%} & 12996.3 & 758.04\%  & 14368.9	&838.13\%\\  
        Assault & 222.4 & 742 & \textbf{67212.67} & \textbf{12892.66\%} & 62025.7 & 11894.40\% & 46635.86	& 8932.54\%\\  
        Asterix & 210 & 8503.3 & 991384.42 & 11951.51\% & \textbf{999999} & \textbf{12055.38\%} & 769803.92	& 9279.71\%\\  
        Asteroids & 719 & 47388.7 & 150854.61 & 321.70\% & \textbf{1106603.5} & \textbf{2369.60\%} & 364492.07	& 779.46\%\\  
        Atlantis & 12850 & 29028.1 & 1528841.76 & 9370.64\% & \textbf{3824506.3} & \textbf{23560.59\%} & 1669226.33	& 10238.39\%\\  
        Bank Heist & 14.2 & 753.1 & 23071.5& 3120.49\% & 1410 & 188.90\% & \textbf{87792.55}	& \textbf{11879.60\%}\\  
        Battle Zone & 236 & 37187.5 & \textbf{934134.88} & \textbf{2527.36\%} & 857369 & 2319.62\% & 776770	& 2101.50\%\\  
        Beam Rider & 363.9 & 16926.5 & 300509.8 & 1812.19\% & \textbf{457321} & \textbf{2758.97\%} & 51870.2 &	310.98\%\\  
        Berzerk & 123.7 & 2630.4 & \textbf{61507.83} & \textbf{2448.80\%} & 35340 & 1404.89\% & 38838.35	& 1544.45\%\\  
        Bowling & 23.1 & 160.7 & 251.18 & 165.76\% & 233.1 & 152.62\% & \textbf{261.74} &	\textbf{173.43\%}\\  
        Boxing & 0.1 & 12.1 & \textbf{100} & \textbf{832.50}\% & \textbf{100} & \textbf{832.50\%} & 99.85 &	831.25\%\\  
        Breakout & 1.7 & 30.5 & 790.4 & 2738.54\% & \textbf{864} & \textbf{2994.10\%} & 831.08 &	2879.79\% \\  
        Centipede & 2090.9 & 12017 & 412847.86 & 4138.15\% & \textbf{728080} & \textbf{7313.94\%} & 245892.18 & 2456.16\%\\  
        Chopper Command & 811 & 7387.8 & 999900 & 15191.11\% & \textbf{999999} & \textbf{15192.62\%} & 912225	&13858.02\%\\  
        Crazy Climber & 10780.5 & 36829.4 & \textbf{565909.85} & \textbf{2131.10\%} & 233090 & 853.43\% & 339274.67	& 1261.07\%\\  
        Defender & 2874.5 & 18688.9 & 677642.78 & 4266.80\% & \textbf{995950} & \textbf{6279.56\%} & 543979.5	& 3421.60\%\\  
        Demon Attack & 152.1 & 1971 & 143161.44 & 7862.41\% & \textbf{900170} & \textbf{49481.44\%} & 142176.58	& 7808.26\%\\  
        Double Dunk & -18.6 & -16.4 & 23.93 & 1933.18\% & \textbf{24} & \textbf{1936.36\%} & 23.7	&1922.73\%\\  
        Enduro & 0 & 860.5 & 2367.71 & 275.16\% & \textbf{14332.5} & \textbf{1665.60\%} & 2360.64	&274.33\%\\  
        Fishing Derby & -91.7 & -38.8 & \textbf{86.97} & \textbf{337.75\%} & 75 & 315.12\% & 77.05	&319.00\%\\  
        Freeway & 0 & 29.6 & 32.59 & 110.10\% & \textbf{34} & \textbf{114.86\%} & 33.97	& 114.76\%\\  
        Frostbite & 65.2 & 4334.7 & \textbf{541280.88} & \textbf{12676.32\%} & 13792.4 & 321.52\% & 526239.5	& 12324.03\%\\  
        Gopher & 257.6 & 2412.5 & 117777.08 & 5453.59\% & \textbf{488900} & \textbf{22675.87\%} & 119457.53	& 5531.58\%\\  
        Gravitar & 173 & 3351.4 & 19213.96 & 599.07\% & 6372.5 & 195.05\% & \textbf{20875}	& \textbf{651.33\%}\\  
        Hero & 1027 & 30826.4 & 114736.26 & 381.58\% & 37545.6 & 122.55\% & \textbf{199880.6}	& \textbf{667.31\%}\\  
        Ice Hockey & -11.2 & 0.9 & \textbf{63.64} & \textbf{618.51\%} & 47.53 & 485.37\% & 47.22	& 482.81\%\\  
        Jamesbond & 29 & 302.8 & 135784.96 & 49582.16\% & \textbf{623300.5} & \textbf{227637.51\%} & 117009.92	&42724.95\%\\  
        Kangaroo & 52 & 3035 & \textbf{24034.16} & \textbf{803.96\%} & 14372.6 & 480.07\% & 17311.17 & 578.58\%\\  
        Krull & 1598 & 2665.5 & 251997.31 & 23456.61\% & \textbf{593679.5} & \textbf{55464.31\%} & 155915.32 & 14455.96\%\\  
        Kung Fu Master & 258.5 & 22736.3 & 206845.82 & 919.07\% & \textbf{1666665} & \textbf{7413.57\%} & 476539.53	& 2118.90\%\\  
        Montezuma Revenge & 0 & 4753.3 & 9352.01 & 196.75\%& 2500 & 52.60\% & \textbf{12437}	& \textbf{261.65\%}\\  
        Ms Pacman & 307.3 & 6951.6 & \textbf{63994.44} & \textbf{958.52\%} & 31403 & 468.01\% & 29747.91	& 443.10\%\\  
        Name This Game & 2292.3 & 8049 & 54386.77 & 904.94\% & \textbf{81473} & \textbf{1375.45\%} & 40077.73	& 656.37\%\\  
        Phoenix & 761.5 & 7242.6 & 908264.15 & 14002.29\% & \textbf{999999} & \textbf{15417.71\%} & 849969.25	&13102.83\%\\  
        Pitfall & -229.4 & 6463.7 & 18756.01 & 283.66\% & -1 & 3.41\% & \textbf{46734.79}	& \textbf{701.68\%}\\  
        Pong & -20.7 & 14.6 & 20.67 & 117.20\% & \textbf{21} & \textbf{118.13\%} & 19.31	& 113.34\%\\  
        Private Eye & 24.9 & 69571.3 & 79716.46 & 114.59\% & 15100 & 21.68\% & \textbf{100798.9}	& \textbf{144.90\%}\\  
        Qbert & 163.9 & 13455 & \textbf{580328.14} & \textbf{4365.06\%} & 151730 & 1140.36\% & 238453.5	& 1792.85\%\\  
        Riverraid & 1338.5 & 17118 & 63318.67 & 392.79\% & 27964.3 & 168.74\% & \textbf{90333.12}	& \textbf{563.99\%}\\  
        Road Runner & 11.5 & 7845 & 243025.8 & 3102.24\% & \textbf{999999} & \textbf{12765.53\%} & 399511.83	& 5099.90\%\\  
        Robotank & 2.2 & 11.9 & 127.32 & 1289.90\% & \textbf{144} & \textbf{1461.86\%} & 114.46	& 1157.32\%\\  
        Seaquest & 68.4 & 42054.7 & 999997.63 & 2381.56\% & \textbf{1000000} & \textbf{2381.57\%} & 960181.39	& 2286.73\%\\  
        Skiing & -17098 & -4336.9 & -4202.6 &101.05\%& -5903.34 & 87.72\% & \textbf{-3273.43}	&\textbf{108.33\%}\\  
        Solaris & 1236.3 & 12326.7 & \textbf{44199.93} & \textbf{387.39\%} & 10732.5 & 85.63\% 28175.53	& 242.91\%\\  
        Space Invaders & 148 & 1668.7 & 48680.86 & 3191.48\% & \textbf{159999.6} & \textbf{10511.71\%} & 57828.45	& 3793.02\%\\  
        Star Gunner & 664 & 10250 & 839573.53 & 8751.40\% & \textbf{999999} & \textbf{10424.94\%} & 264286.33	&2750.08\%\\  
        Surround & -10 & 6.5 & 9.5 & 118.18\% & 2.726 & 77.13\% & \textbf{9.82}	&\textbf{120.12\%}\\  
        Tennis & -23.8 & -8.3 & 23.84 & 307.35\% & \textbf{24} & \textbf{308.39\%} & 22.79	&300.58\%\\  
        Time Pilot & 3568 & 5229.2 & 405425.31 & 24190.78\% & \textbf{531614} & \textbf{31787.02\%} & 404751.67	&24150.23\%\\  
        Tutankham & 11.4 & 167.6 & \textbf{2354.91} & \textbf{1500.33\%} & 436.2 & 271.96\% & 1030.27	& 652.29\%\\  
        Up N Down & 533.4 & 11693.2 & 623805.73 & 5584.98\% & \textbf{999999} & \textbf{8955.95\%} & 524631	&4696.30\%\\  
        Venture & 0 & 1187.5 & 2623.71 & 220.94\% & 2200 & 185.26\% & \textbf{2859.83}	&\textbf{240.83\%}\\  
        Video Pinball & 0 & 17667.9 & 992340.74 & 5616.63\% & \textbf{999999} & \textbf{5659.98\%} & 617640.95	&3495.84\%\\  
        Wizard of Wor & 563.5 & 4756.5 & \textbf{157306.41} & \textbf{3738.20\%} & 118900 & 2822.24\% & 71942	& 1702.33\%\\  
        Yars Revenge & 3092.9 & 54576.9 & 998532.37 & 1933.49\% & \textbf{998970} & \textbf{1934.34\%}& 633867.66	& 1225.19\% \\  
        Zaxxon & 32.5 & 9173.3 & \textbf{249808.9} & \textbf{2732.54\%} & 241570.6 & 2642.42\% & 77942.17	&852.33\%\\
        \midrule
         Mean HNS & & & &   \agentmeanhns \%  & & \textbf{\LBCHmeanhns\%}  & & \mememeanhns\\ 
         Median HNS & & & & \textbf{\agentmedianhns\%} & & \LBCHmedianhns\%  & & \mememedianhns\\ 
         \bottomrule
\end{tabular}
\end{center}
\end{table}


\clearpage  





\begin{table}[!hb]
\footnotesize
\begin{center}
\caption{Score table of  SOTA  model-based algorithms on HNS(\%).}
\label{Tab:Score table of SOTA  model-based algorithms on HNS.}
\setlength{\tabcolsep}{1.0pt}
\begin{tabular}{c cc cc cc }
\toprule
 Games & MuZero & HNS(\%) & EfficientZero & HNS(\%) & Ours & HNS(\%) \\ 
        Scale & 20B & ~ & 100K & ~ & 1B & ~ \\ 
        \midrule
        
        Alien & \textbf{741812.63} & \textbf{10747.61\%} & 808.5 & 8.42\% & 279703.5 & 4050.37\% \\  
        Amidar & \textbf{28634.39} & \textbf{1670.57\%} & 148.6 & 8.33\% & 12996.3 & 758.04\% \\  
        Assault & \textbf{143972.03} & \textbf{27665.44\%} & 1263.1 & 200.29\% & 62025.7 & 11894.40\% \\  
        Asterix & 998425 & 12036.40\% & 25557.8 & 305.64\% & \textbf{999999} & \textbf{12055.38\%} \\  
        Asteroids & 678558.64 & 1452.42\% & N/A & N/A & \textbf{1106603.5} & \textbf{2369.60\%} \\  
        Atlantis & 1674767.2 & 10272.64\% & N/A & N/A & \textbf{3824506.3} & \textbf{23560.59\%} \\  
        Bank Heist & 1278.98 & 171.17\% & 351 & 45.58\% & \textbf{1410} & \textbf{188.90\%} \\  
        Battle Zone & 848623 & 2295.95\% & 13871.2 & 36.90\% & \textbf{857369} & \textbf{2319.62\%} \\  
        Beam Rider & 454993.53 & 2744.92\% & N/A & N/A & \textbf{457321} & \textbf{2758.97\%} \\  
        Berzerk & \textbf{85932.6} & \textbf{3423.18\%} & N/A & N/A & 35340 & 1404.89\% \\  
        Bowling & \textbf{260.13} & \textbf{172.26\%} & N/A & N/A & 233.1 & 152.62\% \\  
        Boxing & \textbf{100} & \textbf{832.50\%} & 52.7 & 438.33\% & \textbf{100} & \textbf{832.50\%} \\  
        Breakout & \textbf{864} & \textbf{2994.10\%} & 414.1 & 1431.94\% & \textbf{864} & \textbf{2994.10\%} \\  
        Centipede & \textbf{1159049.27} & \textbf{11655.72\%} & N/A & N/A & 728080 & 7313.94\% \\  
        Chopper Command & 991039.7 & 15056.39\% & 1117.3 & 4.66\% & \textbf{999999} & \textbf{15192.62\%} \\  
        Crazy Climber & \textbf{458315.4} & \textbf{1718.06\%} & 83940.2 & 280.86\% & 233090 & 853.43\% \\  
        Defender & 839642.95 & 5291.18\% & N/A & N/A & \textbf{995950} & \textbf{6279.56\%} \\  
        Demon Attack & 143964.26 & 7906.55\% & 13003.9 & 706.57\% & \textbf{900170} & \textbf{49481.44\%} \\  
        Double Dunk & 23.94 & 1933.64\% & N/A & N/A & \textbf{24} & \textbf{1936.36\%} \\  
        Enduro & 2382.44 & 276.87\% & N/A & N/A & \textbf{14332.5} & \textbf{1665.60\%} \\  
        Fishing Derby & \textbf{91.16} & \textbf{345.67\%} & N/A & N/A & 75 & 315.12\% \\  
        Freeway & 33.03 & 111.59\% & 21.8 & 73.65\% & \textbf{34} & \textbf{114.86\%} \\  
        Frostbite & \textbf{631378.53} & \textbf{14786.59\%} & 296.3 & 5.41\% & 13792.4 & 321.52\% \\  
        Gopher & 130345.58 & 6036.85\% & 3260.3 & 139.34\% & \textbf{488900} & \textbf{22675.87\%} \\  
        Gravitar & \textbf{6682.7} & \textbf{204.81\%} & N/A & N/A & 6372.5 & 195.05\% \\  
        Hero & \textbf{49244.11} & \textbf{161.81\%} & 3915.9 & 9.69\% & 37545.6 & 122.55\% \\  
        Ice Hockey & \textbf{67.04} & \textbf{646.61\%} & N/A & N/A & 47.53 & 485.37\% \\  
        Jamesbond & 41063.25 & 14986.94\% & 517 & 178.23\% & \textbf{623300.5} & \textbf{227637.51\%} \\  
        Kangaroo & \textbf{16763.6} & \textbf{560.23\%} & 724.1 & 22.53\% & 14372.6 & 480.07\% \\  
        Krull & 269358.27 & 25082.93\% & 5663.3 & 380.82\% & \textbf{593679.5} & \textbf{55464.31\%} \\  
        Kung Fu Master & 204824 & 910.08\% & 30944.8 & 136.52\% & \textbf{1666665} & \textbf{7413.57\%} \\  
        Montezuma Revenge & 0 & 0.00\% & N/A & N/A & \textbf{2500} & \textbf{52.60\%} \\  
        Ms Pacman & \textbf{243401.1} & \textbf{3658.68\%} & 1281.2 & 14.66\% & 31403 & 468.01\% \\  
        Name This Game & \textbf{157177.85} & \textbf{2690.53\%} & N/A & N/A & 81473 & 1375.45\% \\  
        Phoenix & 955137.84 & 14725.53\% & N/A & N/A & \textbf{999999} & \textbf{15417.71\%} \\  
        Pitfall & \textbf{0} & \textbf{3.43\%} & N/A & N/A & -1 & 3.41\% \\  
        Pong & \textbf{21} & \textbf{118.13\%} & 20.1 & 115.58\% & \textbf{21} & \textbf{118.13\%} \\  
        Private Eye & \textbf{15299.98} & \textbf{21.96\%} & 96.7 & 0.10\% & 15100 & 21.68\% \\  
        Qbert & 72276 & 542.56\% & 14448.5 & 107.47\% & \textbf{151730} & \textbf{1140.36\%} \\  
        Riverraid & \textbf{323417.18} & \textbf{2041.12\%} & N/A & N/A & 27964.3 & 168.74\% \\  
        Road Runner & 613411.8 & 7830.48\% & 17751.3 & 226.46\% & \textbf{999999} & \textbf{12765.53\%} \\  
        Robotank & 131.13 & 1329.18\% & N/A & N/A & \textbf{144} & \textbf{1461.86\%} \\  
        Seaquest & 999976.52 & 2381.51\% & 1100.2 & 2.46\% & \textbf{1000000}& \textbf{2381.57\%} \\  
        Skiing & -29968.36 & -100.86\% & N/A & N/A & \textbf{-5903.34} & \textbf{87.72\%} \\  
        Solaris & 56.62 & -10.64\% & N/A & N/A & \textbf{10732.5} & \textbf{85.63\%} \\  
        Space Invaders & 74335.3 & 4878.50\% & N/A & N/A & \textbf{159999.6} & \textbf{10511.71\%} \\  
        Star Gunner & 549271.7 & 5723.01\% & N/A & N/A & \textbf{999999} & \textbf{10424.94\%} \\  
        Surround & \textbf{9.99} & \textbf{121.15\%} & N/A & N/A & 2.726 & 77.13\% \\  
        Tennis & 0 & 153.55\% & N/A & N/A & \textbf{24} & \textbf{308.39\%} \\  
        Time Pilot & \textbf{476763.9} & \textbf{28485.19\%} & N/A & N/A & 531614 & 31787.02\% \\  
        Tutankham & \textbf{491.48} & \textbf{307.35\%} & N/A & N/A & 436.2 & 271.96\% \\  
        Up N Down & 715545.61 & 6407.03\% & 17264.2 & 149.92\% & \textbf{999999} & \textbf{8955.95\%} \\  
        Venture & 0.4 & 0.03\% & N/A & N/A & \textbf{2200} & \textbf{185.26\%} \\  
        Video Pinball & 981791.88 & 5556.92\% & N/A & N/A & \textbf{999999} & \textbf{5659.98\%} \\  
        Wizard of Wor & \textbf{197126} & \textbf{4687.87\%} & N/A & N/A & 118900 & 2822.24\% \\  
        Yars Revenge & 553311.46 & 1068.72\% & N/A & N/A & \textbf{998970} & \textbf{1934.34\%} \\  
        Zaxxon & \textbf{725853.9} & \textbf{7940.46\%} & N/A & N/A & 241570.6 & 2642.42\% \\ \midrule
         Mean HNS & &\muzeromeanhns\% & &   \simplemeanhns\%  & & \textbf{\LBCHmeanhns\%} \\ 
         Median HNS & &\textbf{\muzeromedianhns\%} & &  \simplemedianhns\% & & \LBCHmedianhns\%  \\
         \bottomrule
\end{tabular}
\end{center}
\end{table}


\clearpage  
\begin{table}[!hb]
\footnotesize
\begin{center}
\caption{Score table of  SOTA exploration-based algorithms on HNS(\%).}
\label{Tab:Score table of SOTA  exploration-based algorithms on HNS.}
\setlength{\tabcolsep}{1.0pt}
\begin{tabular}{c cc cc }
\toprule
Games & Go-Explore & HNS & Ours & HNS   \\ 
        Scale & 10B & ~ & 1B &    \\  \midrule
                Alien & \textbf{959312} & \textbf{13899.77\%} & 279703.5 & 4050.37\% \\  
        Amidar & \textbf{19083} & \textbf{1113.22\%} & 12996.3 & 758.04\% \\  
        Assault & 30773 & 5879.64\% & \textbf{62025.7} & \textbf{11894.40\%} \\  
        Asterix & 999500 & 12049.37\% & \textbf{999999} & \textbf{12055.38\%} \\  
        Asteroids & 112952 & 240.48\% & \textbf{1106603.5} & \textbf{2369.60\%} \\  
        Atlantis & 286460 & 1691.24\% & \textbf{3824506.3} & \textbf{23560.59\%} \\  
        Bank Heist & \textbf{3668} & \textbf{494.49\%} & 1410 & 188.90\% \\  
        Battle Zone & \textbf{998800} & \textbf{2702.36\%} & 857369 & 2319.62\% \\  
        Beam Rider & 371723 & 2242.15\% & \textbf{457321} & \textbf{2758.97\%} \\  
        Berzerk & \textbf{131417} & \textbf{5237.69\%} & 35340 & 1404.89\% \\  
        Bowling & \textbf{247} & \textbf{162.72\%} & 233.1 & 152.62\% \\  
        Boxing & 91 & 757.50\% & \textbf{100} & \textbf{832.50\%} \\  
        Breakout & 774 & 2681.60\% & \textbf{864} & \textbf{2994.10\%} \\  
        Centipede & 613815 & 6162.78\% & \textbf{728080} & \textbf{7313.94\%} \\  
        Chopper Command & 996220 & 15135.16\% & \textbf{999999} & \textbf{15192.62\%} \\  
        Crazy Climber & \textbf{235600} & \textbf{863.07\%} & 233090 & 853.43\% \\  
        Defender & N/A & N/A & \textbf{995950} & \textbf{6279.56\%} \\  
        Demon Attack & 239895 & 13180.65\% & \textbf{900170} & \textbf{49481.44\%} \\  
        Double Dunk & \textbf{24} & \textbf{1936.36\%} & \textbf{24} & \textbf{1936.36\%} \\  
        Enduro & 1031 & 119.81\% & \textbf{14332.5} & \textbf{1665.60\%} \\  
        Fishing Derby & 67 & 300.00\% & \textbf{75} & \textbf{315.12\%} \\  
        Freeway & \textbf{34} & \textbf{114.86\%} & \textbf{34} & \textbf{114.86\%} \\  
        Frostbite & \textbf{999990} & \textbf{23420.19\%} & 13792.4 & 321.52\% \\  
        Gopher & 134244 & 6217.75\% & \textbf{488900} & \textbf{22675.87\%} \\  
        Gravitar & \textbf{13385} & \textbf{415.68\%} & 6372.5 & 195.05\% \\  
        Hero & \textbf{37783} & \textbf{123.34\%} & 37545.6 & 122.55\% \\  
        Ice Hockey & 33 & 365.29\% & \textbf{47.53} & \textbf{485.37\%} \\  
        Jamesbond & 200810 & 73331.26\% & \textbf{623300.5} & \textbf{227637.51\%} \\  
        Kangaroo & \textbf{24300} & \textbf{812.87\%} & 14372.6 & 480.07\% \\  
        Krull & 63149 & 5765.90\% & \textbf{593679.5} &\textbf{ 55464.31\%} \\  
        Kung Fu Master & 24320 & 107.05\% & \textbf{1666665} & \textbf{7413.57\%} \\  
        Montezuma Revenge & \textbf{24758} & \textbf{520.86\%} & 2500 & 52.60\% \\  
        Ms Pacman & \textbf{456123} & \textbf{6860.25\%} & 31403 & 468.01\% \\  
        Name This Game & \textbf{212824} & \textbf{3657.16\%} & 81473 & 1375.45\% \\  
        Phoenix & 19200 & 284.50\% & \textbf{999999} & \textbf{15417.71\%} \\  
        Pitfall & \textbf{7875} & \textbf{121.09\%} & -1 & 3.41\% \\  
        Pong & \textbf{21} & \textbf{118.13\%} & \textbf{21} & \textbf{118.13\%} \\  
        Private Eye &\textbf{ 69976} & \textbf{100.58\%} & 15100 & 21.68\% \\  
        Qbert & \textbf{999975} & \textbf{7522.41\%} & 151730 & 1140.36\% \\  
        Riverraid & \textbf{35588} & \textbf{217.05\%} & 27964.3 & 168.74\% \\  
        Road Runner & 999900 & 12764.26\% & \textbf{999999} & \textbf{12765.53\%} \\  
        Robotank & 143 & 1451.55\% & \textbf{144} & \textbf{1461.86\%} \\  
        Seaquest & 539456 & 1284.68\% & \textbf{1000000} & \textbf{2381.57\%} \\  
        Skiing & \textbf{-4185} & \textbf{101.19\%} & -5903.34 & 87.72\% \\  
        Solaris & \textbf{20306} & \textbf{171.95\%} & 10732.5 & 85.63\% \\  
        Space Invaders & 93147 & 6115.54\% & \textbf{159999.6} & \textbf{10511.71\%} \\  
        Star Gunner & 609580 & 6352.14\% & \textbf{999999} & \textbf{10424.94\%} \\  
        Surround & N/A & N/A & \textbf{2.726} & \textbf{77.13\%} \\  
        Tennis & \textbf{24} & \textbf{308.39\%} & \textbf{24} & \textbf{308.39\%} \\  
        Time Pilot & 183620 & 10838.67\% & \textbf{531614} & \textbf{31787.02\%} \\  
        Tutankham & \textbf{528} & \textbf{330.73\%} & 436.2 & 271.96\% \\  
        Up N Down & 553718 & 4956.94\% & \textbf{999999} & \textbf{8955.95\%} \\  
        Venture & \textbf{3074} & \textbf{258.86\%} & 2200 & 185.26\% \\  
        Video Pinball & \textbf{999999} & \textbf{5659.98\%} & \textbf{999999} & \textbf{5659.98\%} \\  
        Wizard of Wor & \textbf{199900} & \textbf{4754.03}\% & 118900 & 2822.24\% \\  
        Yars Revenge & \textbf{999998} & \textbf{1936.34\%} & 998970 & 1934.34\% \\  
        Zaxxon & 18340 & 200.28\% & \textbf{241570.6} & \textbf{2642.42\%} \\ \midrule
                 Mean HNS & &\goexploremeanhns\%   & & \textbf{\LBCHmeanhns\%} \\ 
         Median HNS & &\goexploremedianhns\%& & \textbf{\LBCHmedianhns\%}  \\ 
         \bottomrule
\end{tabular}
\end{center}
\end{table}





\clearpage  




\begin{table}[!hb]
\footnotesize
\begin{center}
\caption{Score Table of GDI-H and LBC- (Ours) on HNS(\%).}
\label{Tab:Score table of GDI and LBC on HNS.}
\setlength{\tabcolsep}{1.0pt}
\begin{tabular}{c cc cc }
\toprule
Games & GDI-H & HNS & Ours & HNS   \\ 
        Scale & 200M & ~ & 1B &    \\  \midrule
        Alien & 48735	             &703.00\% & \textbf{279703.5} & \textbf{4050.37\%} \\  
        Amidar &1065              &61.81\% & \textbf{12996.3} & \textbf{758.04\%} \\  
        Assault &\textbf{97155}	             &\textbf{18655.23\%}  & 62025.7 & 11894.40\% \\  
        Asterix &\textbf{{999999}}   &\textbf{{12055.38\%}} & \textbf{999999} & \textbf{12055.38\%} \\  
        Asteroids &{760005}            &{1626.94\%}  & \textbf{1106603.5} & \textbf{2369.60\%} \\  
        Atlantis &\textbf{{3837300}}           &\textbf{{23639.67\%}}   & 3824506.3 & 23560.59\% \\  
        Bank Heist &1380              &184.84\%  & \textbf{1410} & \textbf{188.90\%} \\  
        Battle Zone &824360            &2230.29\% & \textbf{857369} & \textbf{2319.62\%} \\  
        Beam Rider &422390            &2548.07\% & \textbf{457321} & \textbf{2758.97\%} \\  
        Berzerk &14649             &579.46\% & \textbf{35340} & \textbf{1404.89\%} \\  
        Bowling &205.2             &132.34\% & \textbf{233.1} & \textbf{152.62\%} \\  
        Boxing &\textbf{{100}}      &\textbf{{832.50\%}}   & \textbf{100} & \textbf{832.50\%} \\  
        Breakout &\textbf{{864}}      &\textbf{{2994.10\%}} & \textbf{864} & \textbf{2994.10\%} \\  
        Centipede &195630            &1949.80\% & \textbf{728080} & \textbf{7313.94\%} \\  
        Chopper Command &\textbf{{999999}}   &\textbf{{15192.62\%}} & \textbf{999999} & \textbf{15192.62\%} \\  
        Crazy Climber &\textbf{241170}	            &\textbf{919.76\%} & 233090 & 853.43\% \\  
        Defender &{970540}   &{6118.89\%} & \textbf{995950} & \textbf{6279.56\%} \\  
        Demon Attack &{787985}    &{43313.70\%} & \textbf{900170} & \textbf{49481.44\%} \\  
        Double Dunk &\textbf{{24 }}      &\textbf{{1936.36\%}} & \textbf{24} & \textbf{1936.36\%} \\  
        Enduro &14300             &1661.82\% & \textbf{14332.5} & \textbf{1665.60\%} \\  
        Fishing Derby &65               &296.22\% & \textbf{75} & \textbf{315.12\%} \\  
        Freeway &\textbf{{34}}      &\textbf{{114.86\%}} & \textbf{34} & \textbf{114.86\%} \\  
        Frostbite &11330	            &263.84\% & \textbf{13792.4} & \textbf{321.52\%} \\  
        Gopher &473560           &21964.01\% & \textbf{488900} & \textbf{22675.87\%} \\  
        Gravitar  &5915             &180.66\% & \textbf{6372.5} & \textbf{195.05\%} \\  
        Hero &\textbf{38225}	            &\textbf{124.83\%} & 37545.6 & 122.55\% \\  
        Ice Hockey &47.11           &481.90\% & \textbf{47.53} & \textbf{485.37\%} \\  
        Jamesbond &{620780	}  &{226716.95\%} & \textbf{623300.5} & \textbf{227637.51\%} \\  
        Kangaroo &14636           &488.90\% & 14372.6 & 480.07\% \\  
        Krull &{594540}          &{55544.92\%} & 593679.5 &55464.31\% \\  
        Kung Fu Master &\textbf{{1666665}}	          &\textbf{{7413.57\%}} & \textbf{1666665} & \textbf{7413.57\%} \\  
        Montezuma Revenge &\textbf{2500}            &\textbf{52.60\%} & \textbf{2500} & \textbf{52.60\%} \\  
        Ms Pacman &\textbf{11573}           &\textbf{169.55\%} & \textbf{31403} & \textbf{468.01\%} \\  
        Name This Game  &36296           &590.68\% & \textbf{81473} & \textbf{1375.45\%} \\  
        Phoenix &{959580 }         &	{14794.07\%} & \textbf{999999} & \textbf{15417.71\%} \\
        Pitfall  &-4.3            &3.36 & \textbf{-1} & \textbf{3.41\%} \\  
        Pong &{21}     &{118.13\%}  & \textbf{21} & \textbf{118.13\%} \\  
        Private Eye &15100           &21.68\% & 15100 & 21.68\% \\  
        Qbert &28657           &214.38\% & \textbf{151730} & \textbf{1140.36\%} \\  
        Riverraid &\textbf{28349}           &\textbf{171.17\%} & 27964.3 & 168.74\% \\  
        Road Runner &{999999	} &{12765.53\%} & \textbf{999999} & \textbf{12765.53\%} \\  
        Robotank &113.4           &1146.39\% & \textbf{144} & \textbf{1461.86\%} \\  
        Seaquest&\textbf{{1000000}}          &\textbf{{2381.57\%}} & \textbf{1000000} & \textbf{2381.57\%} \\  
        Skiing &\textbf{{-6025}}  &\textbf{{86.77\%}} & -5903.34 & 87.72\% \\  
        Solaris &9105            &70.95\% & \textbf{10732.5} & \textbf{85.63\%} \\  
        Space Invaders  &{154380}          &{10142.17\%} & \textbf{159999.6} & \textbf{10511.71\%} \\  
        Star Gunner &{677590}          &{7061.61\%} & \textbf{999999} & \textbf{10424.94\%} \\ 
        Surround  &2.606           &76.40\%  & \textbf{2.726} & \textbf{77.13\%} \\  
        Tennis &\textbf{{24}}              &\textbf{{308.39\%}}   & \textbf{24} & \textbf{308.39\%} \\  
        Time Pilot &450810	          &26924.45\%  & \textbf{531614} & \textbf{31787.02\%} \\  
        Tutankham &418.2           &260.44\%  & \textbf{436.2} & \textbf{271.96\%} \\  
        Up N Down &966590          &8656.58\% & \textbf{999999} & \textbf{8955.95\%} \\  
        Venture  &2000	            &168.42\% & \textbf{2200} & \textbf{185.26\%} \\  
        Video Pinball &978190          &5536.54\% & \textbf{999999} & \textbf{5659.98\%} \\  
        Wizard of Wor  &63735           &1506.59\% & \textbf{118900} & \textbf{2822.24\%} \\  
        Yars Revenge &968090          &1874.36\% & \textbf{998970} & \textbf{1934.34\%} \\  
        Zaxxon &216020	          &2362.89\% & \textbf{241570.6} & \textbf{2642.42\%} \\ \midrule
                 Mean HNS & &\goexploremeanhns\%   & & \textbf{\LBCHmeanhns\%} \\ 
         Median HNS & &\goexploremedianhns\%& & \textbf{\LBCHmedianhns\%}  \\ 
         \bottomrule
\end{tabular}
\end{center}
\end{table}



\clearpage

\subsection{Atari Games Table of Scores Based on Human World Records}
\label{app: Atari Games Table of Scores Based on Human World Records}

The raw score of numerous typical SOTA algorithms, including model-free SOTA algorithms, model-based SOTA algorithms, and additional SOTA algorithms, is described in this section. In addition to the raw score, we also include the Human World Records and Breakthroughs (HWRB) for each Atari 57 game, as well as the individual game scores. You may get more information about these algorithms at \cite{ale2,atarihuman}.

\clearpage


\begin{table}[!hb]
\footnotesize
\begin{center}
\caption{Score table of  SOTA  model-free algorithms on HWRB.}
\label{Tab:Score table of SOTA  model-free algorithms on HWRB.}
\setlength{\tabcolsep}{1.0pt}
\begin{tabular}{c cc cc cc cc}
\toprule
Games & RND & Human World Records & AGENT57 & HWRB & Ours & HWRB & MEME & HWRB \\ 
        Scale & ~ & ~ & 100B & ~ & 1B & ~ & 1B & ~ \\ \midrule
        Alien & 227.8 & 251916 & 297638.17 & 1  & 279703.5 & 1  & 83683.43	&0\\  
        Amidar & 5.8 & 104159 & 29660.08 & 0  & 12996.3 & 0  & 14368.9	& 0\\  
        Assault & 222.4 & 8647 & 67212.67 & 1  & 62025.7 & 1 & 46635.86	&1 \\  
        Asterix & 210 & 1000000 & 991384.42 & 0  & 999999 & 0  & 769803.92	& 0\\  
        Asteroids & 719 & 10506650 & 150854.61 & 0  & 1106603.5 & 0  & 364492.07	&0\\  
        Atlantis & 12850 & 10604840 & 1528841.76 & 0  & 3824506.3 & 0  &1669226.33	&0\\  
        Bank Heist & 14.2 & 82058 & 23071.5 & 0  & 1410 & 0  & 87792.55	&1\\  
        Battle Zone & 236 & 801000 & 934134.88 & 1  & 857369 & 1  & 776770	&0\\  
        Beam Rider & 363.9 & 999999 & 300509.8 & 0  & 457321 & 0  & 51870.2	&0\\  
        Berzerk & 123.7 & 1057940 & 61507.83 & 0  & 35340 & 0  & 38838.35	&0\\  
        Bowling & 23.1 & 300 & 251.18 & 0  & 233.1 & 0  &261.74	& 0\\  
        Boxing & 0.1 & 100 & 100 & 1  & 100 & 1  & 99.85	&0\\  
        Breakout & 1.7 & 864 & 790.4 & 0  & 864 & 1  & 831.08	& 0\\  
        Centipede & 2090.9 & 1301709 & 412847.86 & 0  & 728080 & 0  & 245892.18	& 0\\  
        Chopper Command & 811 & 999999 & 999900 & 0  & 999999 & 1  & 912225	&0\\  
        Crazy Climber & 10780.5 & 219900 & 565909.85 & 1  & 233090 & 1  & 339274.67	&1\\  
        Defender & 2874.5 & 6010500 & 677642.78 & 0  & 995950 & 0  &543979.5	&0\\  
        Demon Attack & 152.1 & 1556345 & 143161.44 & 0  & 900170 & 0 & 142176.58	&0 \\  
        Double Dunk & -18.6 & 21 & 23.93 & 1  & 24 & 1 &23.7	&1 \\  
        Enduro & 0 & 9500 & 2367.71 & 0  & 14332.5 & 1  &2360.64	&0\\  
        Fishing Derby & -91.7 & 71 & 86.97 & 1  & 75 & 1  & 77.05	&1\\  
        Freeway & 0 & 38 & 32.59 & 0  & 34 & 0  & 33.97	& 0\\  
        Frostbite & 65.2 & 454830 & 541280.88 & 1  & 13792.4 & 0  & 526239.5	& 1\\  
        Gopher & 257.6 & 355040 & 117777.08 & 0  & 488900 & 1 & 119457.53	& 0 \\  
        Gravitar & 173 & 162850 & 19213.96 & 0  & 6372.5 & 0  & 20875	& 0\\  
        Hero & 1027 & 1000000 & 114736.26 & 0  & 37545.6 & 0  & 199880.6	& 0\\  
        Ice Hockey & -11.2 & 36 & 63.64 & 1  & 47.53 & 1  & 47.22	& 1\\  
        Jamesbond & 29 & 45550 & 135784.96 & 1  & 623300.5 & 1  & 117009.92	& 1\\  
        Kangaroo & 52 & 1424600 & 24034.16 & 0  & 14372.6 & 0  & 17311.17	& 0\\  
        Krull & 1598 & 104100 & 251997.31 & 1  & 593679.5 & 1  & 155915.32	& 1\\  
        Kung Fu Master & 258.5 & 1000000 & 206845.82 & 0  & 1666665 & 1  & 476539.53	& 0\\  
        Montezuma Revenge & 0 & 1219200 & 9352.01 & 0  & 2500 & 0 & 12437	& 0 \\  
        Ms Pacman & 307.3 & 290090 & 63994.44 & 0  & 31403 & 0  & 29747.91	& 0 \\  
        Name This Game & 2292.3 & 25220 & 54386.77 & 1  & 81473 & 1 & 40077.73	& 1 \\  
        Phoenix & 761.5 & 4014440 & 908264.15 & 0  & 999999 & 0  & 849969.25	& 0\\  
        Pitfall & -229.4 & 114000 & 18756.01 & 0  & -1 & 0 & 46734.79	& 0 \\  
        Pong & -20.7 & 21 & 20.67 & 0  & 21 & 1  & 19.31	& 0\\  
        Private Eye & 24.9 & 101800 & 79716.46 & 0  & 15100 & 0 & 100798.9	& 0 \\  
        Qbert & 163.9 & 2400000 & 580328.14 & 0  & 151730 & 0  & 238453.5	& 0\\  
        Riverraid & 1338.5 & 1000000 & 63318.67 & 0  & 27964.3 & 0 & 90333.12	& 0\\  
        Road Runner & 11.5 & 2038100 & 243025.8 & 0  & 999999 & 0  & 399511.83	& 0\\  
        Robotank & 2.2 & 76 & 127.32 & 1  & 144 & 1  & 114.46	& 1\\  
        Seaquest & 68.4 & 999999 & 999997.63 & 0  & 1000000 & 1 & 960181.39	& 0 \\  
        Skiing & -17098 & -3272 & -4202.6 & 0  & -5903.34 & 0 & -3273.43	& 0 \\  
        Solaris & 1236.3 & 111420 & 44199.93 & 0  & 10732.5 & 0  & 28175.53	& 0\\  
        Space Invaders & 148 & 621535 & 48680.86 & 0  & 159999.6 & 0 & 57828.45	& 0 \\  
        Star Gunner & 664 & 77400 & 839573.53 & 1  & 999999 & 1 & 264286.33	& 1 \\  
        Surround & -10 & 9.6 & 9.5 & 0  & 2.726 & 0  & 9.82	&1\\  
        Tennis & -23.8 & 21 & 23.84 & 1  & 24 & 1  & 22.79	&1\\  
        Time Pilot & 3568 & 65300 & 405425.31 & 1  & 531614 & 1 & 404751.67	& 1 \\  
        Tutankham & 11.4 & 5384 & 2354.91 & 0  & 436.2 & 0  & 1030.27	&0\\  
        Up n Down & 533.4 & 82840 & 623805.73 & 1  & 999999 & 1 & 524631	& 1 \\  
        Venture & 0 & 38900 & 2623.71 & 0  & 2200 & 0  & 2859.83	& 0\\  
        Video Pinball & 0 & 89218328 & 992340.74 & 0  & 999999 & 0 & 617640.95	& 0 \\  
        Wizard of Wor & 563.5 & 395300 & 157306.41 & 0  & 118900 & 0  & 71942	& 0\\  
        Yars Revenge & 3092.9 & 15000105 & 998532.37 & 0  & 998970 & 0 & 633867.66	& 0  \\  
        Zaxxon & 32.5 & 83700 & 249808.9 & 1  & 241570.6 & 1  & 77942.17	&0\\ 
        \midrule
         HWRB & & & & 18 & & \textbf{24}& & 16 \\ 
        \bottomrule
\end{tabular}
\end{center}
\end{table}


\clearpage  




\begin{table}[!hb]
\footnotesize
\begin{center}
\caption{Score table of  SOTA  model-based algorithms on HWRB.}
\label{Tab:Score table of SOTA  model-based algorithms on HWRB.}
\setlength{\tabcolsep}{1.0pt}
\begin{tabular}{c cc cc cc}
\toprule
Games & MuZero &  HWRB & EfficientZero &  HWRB &Ours  &  HWRB \\ 
        Scale & 20B & ~ & 100K & ~ & 1B & ~ \\ \midrule
        Alien & 741812.63 & 1  & 808.5 & 0  & 279703.5 & 1  \\  
        Amidar & 28634.39 & 0  & 148.6 & 0  & 12996.3 & 0  \\  
        Assault & 143972.03 & 1  & 1263.1 & 0  & 62025.7 & 1  \\  
        Asterix & 998425 & 0  & 25557.8 & 0  & 999999 & 0  \\  
        Asteroids & 678558.64 & 0  & N/A & N/A & 1106603.5 & 0  \\  
        Atlantis & 1674767.2 & 0  & N/A & N/A & 3824506.3 & 0  \\  
        Bank Heist & 1278.98 & 0  & 351 & 0  & 1410 & 0  \\  
        Battle Zone & 848623 & 1  & 13871.2 & 0  & 857369 & 1  \\  
        Beam Rider & 454993.53 & 0  & N/A & N/A & 457321 & 0  \\  
        Berzerk & 85932.6 & 0  & N/A & N/A & 35340 & 0  \\  
        Bowling & 260.13 & 0  & N/A & N/A & 233.1 & 0  \\  
        Boxing & 100 & 1  & 52.7 & 0  & 100 & 1  \\  
        Breakout & 864 & 1  & 414.1 & 0  & 864 & 1  \\  
        Centipede & 1159049.27 & 0  & N/A & N/A & 728080 & 0  \\  
        Chopper Command & 991039.7 & 0  & 1117.3 & 0  & 999999 & 1  \\  
        Crazy Climber & 458315.4 & 1  & 83940.2 & 0  & 233090 & 1  \\  
        Defender & 839642.95 & 0  & N/A & N/A & 995950 & 0  \\  
        Demon Attack & 143964.26 & 0  & 13003.9 & 0  & 900170 & 0  \\  
        Double Dunk & 23.94 & 1  & N/A & N/A & 24 & 1  \\  
        Enduro & 2382.44 & 0  & N/A & N/A & 14332.5 & 1  \\  
        Fishing Derby & 91.16 & 1  & N/A & N/A & 75 & 1  \\  
        Freeway & 33.03 & 0  & 21.8 & 0  & 34 & 0  \\  
        Frostbite & 631378.53 & 1  & 296.3 & 0  & 13792.4 & 0  \\  
        Gopher & 130345.58 & 0  & 3260.3 & 0  & 488900 & 1  \\  
        Gravitar & 6682.7 & 0  & N/A & N/A & 6372.5 & 0  \\  
        Hero & 49244.11 & 0  & 3915.9 & 0  & 37545.6 & 0  \\  
        Ice Hockey & 67.04 & 1  & N/A & N/A & 47.53 & 1  \\  
        Jamesbond & 41063.25 & 0  & 517 & 0  & 623300.5 & 1  \\  
        Kangaroo & 16763.6 & 0  & 724.1 & 0  & 14372.6 & 0  \\  
        Krull & 269358.27 & 1  & 5663.3 & 0  & 593679.5 & 1  \\  
        Kung Fu Master & 204824 & 0  & 30944.8 & 0  & 1666665 & 1  \\  
        Montezuma Revenge & 0 & 0  & N/A & N/A & 2500 & 0  \\  
        Ms Pacman & 243401.1 & 0  & 1281.2 & 0  & 31403 & 0  \\  
        Name This Game & 157177.85 & 1  & N/A & N/A & 81473 & 1  \\  
        Phoenix & 955137.84 & 0  & N/A & N/A & 999999 & 0  \\  
        Pitfall & 0 & 0  & N/A & N/A & -1 & 0  \\  
        Pong & 21 & 1  & 20.1 & 0  & 21 & 1  \\  
        Private Eye & 15299.98 & 0  & 96.7 & 0  & 15100 & 0  \\  
        Qbert & 72276 & 0  & 14448.5 & 0  & 151730 & 0  \\  
        Riverraid & 323417.18 & 0  & N/A & N/A & 27964.3 & 0  \\  
        Road Runner & 613411.8 & 0  & 17751.3 & 0  & 999999 & 0  \\  
        Robotank & 131.13 & 1  & N/A & N/A & 144 & 1  \\  
        Seaquest & 999976.52 & 0  & 1100.2 & 0  & 1000000 & 1  \\  
        Skiing & -29968.36 & 0  & N/A & N/A & -5903.34 & 0  \\  
        Solaris & 56.62 & 0  & N/A & N/A & 10732.5 & 0  \\  
        Space Invaders & 74335.3 & 0  & N/A & N/A & 159999.6 & 0  \\  
        Star Gunner & 549271.7 & 1  & N/A & N/A & 999999 & 1  \\  
        Surround & 9.99 & 1  & N/A & N/A & 2.726 & 0  \\  
        Tennis & 0 & 0  & N/A & N/A & 24 & 1  \\  
        Time Pilot & 476763.9 & 1  & N/A & N/A & 531614 & 1  \\  
        Tutankham & 491.48 & 0  & N/A & N/A & 436.2 & 0  \\  
        Up N Down & 715545.61 & 1  & 17264.2 & 0  & 999999 & 1  \\  
        Venture & 0.4 & 0  & N/A & N/A & 2200 & 0  \\  
        Video Pinball & 981791.88 & 0  & N/A & N/A & 999999 & 0  \\  
        Wizard of Wor & 197126 & 0  & N/A & N/A & 118900 & 0  \\  
        Yars Revenge & 553311.46 & 0  & N/A & N/A & 998970 & 0  \\  
        Zaxxon & 725853.9 & 1  & N/A & N/A & 241570.6 & 1 \\ 
        \midrule
          HWRB & & 19 & & 0 & & \textbf{24} \\
         \bottomrule
\end{tabular}
\end{center}
\end{table}


\clearpage  
\begin{table}[!hb]
\footnotesize
\begin{center}
\caption{Score table of  SOTA exploration-based algorithms on HWRB.}
\label{Tab:Score table of SOTA  exploration-based algorithms on HWRB.}
\setlength{\tabcolsep}{1.0pt}
\begin{tabular}{c cc cc }
\toprule
Games & Go-Explore & HWRB & Ours & HWRB \\ 
        Scale & 10B & ~ & 1B &   \\ \midrule
        Alien & 959312 & 1  & 279703.5 & 1  \\  
        Amidar & 19083 & 0  & 12996.3 & 0  \\  
        Assault & 30773 & 1  & 62025.7 & 1  \\  
        Asterix & 999500 & 0  & 999999 & 0  \\  
        Asteroids & 112952 & 0  & 1106603.5 & 0  \\  
        Atlantis & 286460 & 0  & 3824506.3 & 0  \\  
        Bank Heist & 3668 & 0  & 1410 & 0  \\  
        Battle Zone & 998800 & 1  & 857369 & 1  \\  
        Beam Rider & 371723 & 0  & 457321 & 0  \\  
        Berzerk & 131417 & 0  & 35340 & 0  \\  
        Bowling & 247 & 0  & 233.1 & 0  \\  
        Boxing & 91 & 0  & 100 & 1  \\  
        Breakout & 774 & 0  & 864 & 1  \\  
        Centipede & 613815 & 0  & 728080 & 0  \\  
        Chopper Command & 996220 & 0  & 999999 & 1  \\  
        Crazy Climber & 235600 & 1  & 233090 & 1  \\  
        Defender & N/A & N/A & 995950 & 0  \\  
        Demon Attack & 239895 & 0  & 900170 & 0  \\  
        Double Dunk & 24 & 1  & 24 & 1  \\  
        Enduro & 1031 & 0  & 14332.5 & 1  \\  
        Fishing Derby & 67 & 0  & 75 & 1  \\  
        Freeway & 34 & 0  & 34 & 0  \\  
        Frostbite & 999990 & 1  & 13792.4 & 0  \\  
        Gopher & 134244 & 0  & 488900 & 1  \\  
        Gravitar & 13385 & 0  & 6372.5 & 0  \\  
        Hero & 37783 & 0  & 37545.6 & 0  \\  
        Ice Hockey & 33 & 0  & 47.53 & 1  \\  
        Jamesbond & 200810 & 1  & 623300.5 & 1  \\  
        Kangaroo & 24300 & 0  & 14372.6 & 0  \\  
        Krull & 63149 & 0  & 593679.5 & 1  \\  
        Kung Fu Master & 24320 & 0  & 1666665 & 1  \\  
        Montezuma Revenge & 24758 & 0  & 2500 & 0  \\  
        Ms Pacman & 456123 & 1  & 31403 & 0  \\  
        Name This Game & 212824 & 1  & 81473 & 1  \\  
        Phoenix & 19200 & 0  & 999999 & 0  \\  
        Pitfall & 7875 & 0  & -1 & 0  \\  
        Pong & 21 & 1  & 21 & 1  \\  
        Private Eye & 69976 & 0  & 15100 & 0  \\  
        Qbert & 999975 & 0  & 151730 & 0  \\  
        Riverraid & 35588 & 0  & 27964.3 & 0  \\  
        Road Runner & 999900 & 0  & 999999 & 0  \\  
        Robotank & 143 & 1  & 144 & 1  \\  
        Seaquest & 539456 & 0  & 1000000 & 1  \\  
        Skiing & -4185 & 0  & -5903.34 & 0  \\  
        Solaris & 20306 & 0  & 10732.5 & 0  \\  
        Space Invaders & 93147 & 0  & 159999.6 & 0  \\  
        Star Gunner & 609580 & 1  & 999999 & 1  \\  
        Surround & N/A & N/A & 2.726 & 0  \\  
        Tennis & 24 & 1  & 24 & 1  \\  
        Time Pilot & 183620 & 1  & 531614 & 1  \\  
        Tutankham & 528 & 0  & 436.2 & 0  \\  
        Up N Down & 553718 & 1  & 999999 & 1  \\  
        Venture & 3074 & 0  & 2200 & 0  \\  
        Video Pinball & 999999 & 0  & 999999 & 0  \\  
        Wizard of Wor & 199900 & 0  & 118900 & 0  \\  
        Yars Revenge & 999998 & 0  & 998970 & 0  \\  
        Zaxxon & 18340 & 0  & 241570.6 & 1 \\ 
        \midrule
          HWRB & & 15& & \textbf{24}  \\ 
         \bottomrule
\end{tabular}
\end{center}
\end{table}

\clearpage



\begin{table}[!hb]
\footnotesize
\begin{center}
\caption{Score Table of GDI-H and LBC- (Ours) on HWRB.}
\label{Tab:Score table of GDI and LBC on HWRB.}
\setlength{\tabcolsep}{1.0pt}
\begin{tabular}{c cc cc }
\toprule
Games & GDI-H & HWRB & Ours &HWRB   \\ 
        Scale & 200M & ~ & 1B &    \\  \midrule
        Alien & 48735	             & 0 & \textbf{279703.5} & 1 \\  
        Amidar &1065              & 0 & \textbf{12996.3} & 0 \\  
        Assault &\textbf{97155}	             & 1  & 62025.7 & 1 \\  
        Asterix &\textbf{{999999}}   & 0 & \textbf{999999} & 0 \\  
        Asteroids &{760005}            & 0 & \textbf{1106603.5} & 0 \\  
        Atlantis &\textbf{{3837300}}           & 0   & 3824506.3 & 0 \\  
        Bank Heist &1380              & 0  & \textbf{1410} & 0 \\   
        Battle Zone &824360            & 1 & \textbf{857369} & 1 \\  
        Beam Rider &422390            & 0 & \textbf{457321} & 0 \\  
        Berzerk &14649             & 0 & \textbf{35340} & 0 \\    
        Bowling &205.2             & 0 & \textbf{233.1} & 0 \\  
        Boxing &\textbf{{100}}      & 1  & \textbf{100} &1 \\  
        Breakout &\textbf{{864}}     & 1& \textbf{864} & 1 \\   
        Centipede &195630            & 0 & \textbf{728080} & 0 \\  
        Chopper Command &\textbf{{999999}}   & 1 & \textbf{999999} & 1 \\    
        Crazy Climber &\textbf{241170}	            & 1 & 233090 &1 \\  
        Defender &{970540}  & 0 & \textbf{995950} & 0 \\    
        Demon Attack &{787985}    & 0 & \textbf{900170} & 0 \\  
        Double Dunk &\textbf{{24 }}      & 1 & \textbf{24} & 1 \\  
        Enduro &14300            & 1 & \textbf{14332.5} & 1 \\  
        Fishing Derby &65              & 0 & \textbf{75} & 1 \\  
        Freeway &\textbf{{34}}     & 0 & \textbf{34} & 0 \\    
        Frostbite &11330	            & 0 & \textbf{13792.4} & 0 \\  
        Gopher &473560           & 1 & \textbf{488900} & 1 \\   
        Gravitar  &5915             & 0 & \textbf{6372.5} & 0 \\  
        Hero &\textbf{38225}	           & 0 & 37545.6 & 0 \\   
        Ice Hockey &47.11           & 0  & \textbf{47.53} & 1 \\  
        Jamesbond &{620780	}  & 1 & \textbf{623300.5} & 1 \\    
        Kangaroo &14636           & 0 & 14372.6 & 0 \\  
        Krull &{594540}          & 1 & 593679.5 &1 \\  
        Kung Fu Master &\textbf{{1666665}}	         & 1 & \textbf{1666665} &1 \\    
        Montezuma Revenge &\textbf{2500}            & 0 & \textbf{2500} & 0 \\  
        Ms Pacman &\textbf{11573}           & 0 & \textbf{31403} & 0 \\   
        Name This Game  &36296           & 1 & \textbf{81473} & 1\\  
        Phoenix &{959580 }        & 0 & \textbf{999999} & 0 \\  
        Pitfall  &-4.3            & 0 & \textbf{-1} & 0 \\  
        Pong &{21}     & 1 & \textbf{21} & 1 \\  
        Private Eye &15100          & 0 & 15100 & 0 \\   
        Qbert &28657          & 0 & \textbf{151730} & 0 \\  
        Riverraid &\textbf{28349}           & 0 & 27964.3 & 0 \\   
        Road Runner &{999999	} & 0  & \textbf{999999} &0 \\   
        Robotank &113.4           & 0 & \textbf{144} & 0 \\  
        Seaquest&\textbf{{1000000}}         & 1 & \textbf{1000000} & 1 \\  
        Skiing &\textbf{{-6025}}  & 0 & -5903.34 & 0 \\  
        Solaris &9105           & 0  & \textbf{10732.5} & 0 \\   
        Space Invaders  &{154380}         & 0 & \textbf{159999.6} & 0 \\  
        Star Gunner &{677590}         & 1 & \textbf{999999} & 1 \\  
        Surround  &2.606           & 0  & \textbf{2.726} & 0 \\  
        Tennis &\textbf{{24}}            & 1  & \textbf{24} & 1 \\   
        Time Pilot &450810	         & 1  & \textbf{531614} & 1 \\   
        Tutankham &418.2          & 0 & \textbf{436.2} & 0 \\   
        Up N Down &966590         & 1 & \textbf{999999} & 1\\  
        Venture  &2000	           & 0 & \textbf{2200} & 0 \\    
        Video Pinball &978190          & 0 & \textbf{999999} &0 \\  
        Wizard of Wor  &63735         & 0 & \textbf{118900} & 0 \\  
        Yars Revenge &968090         & 0& \textbf{998970} & 0 \\  
        Zaxxon &216020	          & 1 & \textbf{241570.6} & 1 \\  \midrule
                 HWRB & &22   & &\textbf{24} \\ 
         \bottomrule
\end{tabular}
\end{center}
\end{table}



\clearpage

\section{Ablation Study}
\label{app: Ablation Study}


\renewcommand{\thesubfigure}{(\alph{subfigure})}
\setcounter{subfigure}{0}



\begin{figure*}[!t]
	\centering
\includegraphics[width=\textwidth]{photo/zhuzhuangtu/Ablation_Study/Ablation_Study.pdf}
	\centering
\caption{Ablation Results on Atari Benchmark \citep{ale2}. All the results are scaled by  that of our main algorithm to improve readability. In these figures, we sequentially demonstrate how much performance (\%) will degrade after ablating each component of LBC.}
\label{app fig:ablation study}
\end{figure*}

In this section, we will demonstrate the settings of our ablation studies first . Then we will introduce the algorithms of the ablation study, which has been concluded  in Tab. \ref{tab:Summary of the ablation experimental groups in Ablation Study}. After that, we will introduce the ablation study results and case studies of t-SNE, including the results on the Atari benchmark in Fig. \ref{app fig:ablation study} and t-SNE analysis in App. \ref{app: TSNE Analysis}.

\subsection{Ablation Study Setup}
\label{app: Ablation Study Setup}

 We  summarized all the algorithms of the ablation study in Tab. \ref{tab:Summary of the ablation experimental groups in Ablation Study}.  All algorithms are tested in the same experimental setup. More details on these experimental setups can see App. \ref{sec:app Experiment Details}.  The hyper-parameters can see App. \ref{Sec: appendix hyper-parameters}. 
 

\begin{table*}[!htbp]
\small
\setlength{\tabcolsep}{2.0pt}
    \centering
    \caption{Algorithms of Ablation Study.}
    \label{tab:Summary of the ablation experimental groups in Ablation Study}
    \resizebox{\textwidth}{!}{\begin{tabular}{l l l l l}
   \toprule
                Algorithm &   Main Algorithm &  Reducing   & 
                Reducing  and  & Random Selection  \\
   \midrule
Ablation Variables & Baseline & &  and & Meta-Controller ()\\ 
   

             &  &  &  &  \\

               
                 &  &  &  & \\
                
                    
                 & &  &  &  \\
                
                  &  &  &  &  \\

                 &  &  & & \\ 
                
                     &  &  &  & \\
                   
                    
                   
                    & 3 & 1 & 1 &  3 \\
                   
                   
                   
                    &  &  &  &   \\
                   
                   
                
                  
                 Category   & LBC-H- &  LBC-H-  & LBC-H- & LBC-H-  \\
                 
                  &  &  &  &  \\
                 
                 Meta-Controller ()
                 & MAB   
                 & MAB   
                 & MAB 
                 & Random Selection             \\
    \bottomrule
    \end{tabular}
    }
\end{table*}
\normalsize

\subsection{Ablation Study Results}





The ablation study results can be found in Fig. \ref{app fig:ablation study}. From left to right, the behavior space of
the first three algorithms decreases in turn, and the final performance of these three algorithms decreases in turn. We can draw the following corollary:

\begin{Corollary}[Smaller Behavior Space, Lower Final Performance]
\label{Corollary: Smaller Behavior Space, Lower Final Performance}
    Given any RL methods, assuming each behavior can be visited infinitely, decreasing the behavior space and keeping other conditions unchanged will degrade the final performance of the algorithm,  and vice versa.
\end{Corollary}

The behavior space of Random Selection is the same as our main algorithm. Obviously, the appropriate behaviors fail to be selected with a random selection, resulting in a great decrease of the performance in limited training frames.


\subsection{t-SNE Analysis}
\label{app: TSNE Analysis}



 In this paper, we adopt the ucb-score to encourage the actors to try more different behavior. To demonstrate the effectiveness of the ucb-score, we conduct the t-SNE analysis of the methods removing the ucb-score in 1 and 2 of  Fig. \ref{fig:tsne study}. 

 To demonstrate that the behavior diversity can be boosted by our algorithm, we conducted  the t-SNE analysis of the methods with rule-based  in 2 and 3 of Fig. Fig. \ref{fig:tsne study}. 
 
 
From (a) and (b) of Fig. \ref{fig:tsne study}, we find that removing the UCB item (i.e., ) from the optimization target of behavior selection, the behavior diversity fade away. It can prove the effectiveness of the diversity control of our methods.


From (c) and (d) of Fig. \ref{fig:tsne study}, we find that compared with the rule-based , our method can acquire a diverse set of behaviors though we do not contain a diversity-based multi-objective model training which confirms the Corollary \ref{Corollary: behavior mapping optimization is an Antidote for Behavior Circling}.





\begin{figure*}[!t]
\vspace{-0.1in}
\subfigure[Main Algorithm]{
		\includegraphics[width=0.23\textwidth,height=0.2\textheight]{photo/tsne/cp/A.pdf}
	}
	\subfigure[w/o UCB Item]{
		\includegraphics[width=0.23\textwidth,height=0.2\textheight]{photo/tsne/cp/B.pdf}
	}
	\subfigure[Main Algorithm]{
		\includegraphics[width=0.23\textwidth,height=0.2\textheight]{photo/tsne/alt/A.pdf}
	}
	\subfigure[Rule-based ]{
		\includegraphics[width=0.23\textwidth,height=0.2\textheight]{photo/tsne/alt/B.pdf}
	}
\caption{Visualizing Behavior Diversity via t-SNE. (a) and (b) are drawn from the t-SNE analysis of visited states (points highlighted  with \imgintext{photo/learned_model.png}) in  Chopper Command, and (c) and (d) are drawn the t-SNE analysis of visited states in Atlantis.}
\label{fig:tsne study}
\end{figure*}






\clearpage





\section{Model Architecture}
\label{app: Model Architecture}



Since the network structure is not the focus of our work, we keep most of the components of the network, e.g., the LSTM Core, RL Head and Convolutional Layers the same as that of Agent57 \citep{agent57}. To improve the reproducibility of our work, we still summarize our  model architecture of our main algorithm in detail in Fig. \ref{fig:lbc model}.  Wherein,  is the the hyper-parameters (e.g., discounted factor  ) of policy model  and  is the parameters of the constructed behavior space (e.g.,  in -greedy). More details on the hyper-parameters of each policy model can see App. \ref{Sec: appendix hyper-parameters}.  will be adaptively selected to control the behaviors across learning process via MAB. More implementation details on the MAB can see App. \ref{Sec: appendix MAB}. It is worth noting that our framework is not limited to an implementation of report in our body. In Fig. \ref{fig:lbc model}, we show a general way of integrating multiple policy models and automatically adjusting the proportion of any multiple policy  models in the ensembled behavior policy.
 


\begin{figure*}[!ht]
	\centering
\includegraphics[width=\textwidth]{photo/app/network/n2.pdf}
	\centering
\caption{Model Architecture of our main algorithm.}
\label{fig:lbc model}
\end{figure*}


\clearpage


\section{Supplementary Material}
\label{app: Supplementary Material}


\begin{figure*}[!ht]
	\centering
\includegraphics[width=0.5\textwidth]{photo/app/hwrb_time.pdf}
	\centering
\caption{Human World Records Breakthrough of Atari RL Benchmarks.}
\label{fig:hwrb benchmark}
\end{figure*}



\begin{figure*}[!ht]
	\centering
\includegraphics[width=\textwidth]{photo/app/hns_57_games_meme.pdf}
	\centering
\caption{Performance Comparison between MEME and LBC based on HNS.(log scale)}
\label{fig:performance meme and lbc}
\end{figure*}








\begin{figure*}[!ht]
	\centering
\includegraphics[width=\textwidth]{photo/app/GDI_LBC.pdf}
	\centering
\caption{Different Learning Framework of GDI-H and LBC}
\label{fig:gdi and lbc}
\end{figure*}


\clearpage

\section{Case Study: KL Divergence}
\label{sec: KL Divergence Between policy models}


In this section, to further investigate the cause of the degradation phenomenon of the behavior space in GDI-H (i.e., due to a same learned policy  for  and  under different reward shaping) and demonstrate that in our behavior space (i.e., different learned policies for  and ), the diversity can be maintained since different policy models  are distinguishable across learning. For fairness, we designed two implementations to explore the degradation phenomenon in the behavior space of GDI-H including: i) an implementation  with two different learned policies under different reward shaping (yellow in Fig. \ref{fig:KL}) ii) an implementation that learns two advantage functions of a same target policy (i.e., the behavior policy) under different reward shaping as GDI-H (blue in Fig. \ref{fig:KL}). The learning framework of these two implementations can be found in \ref{fig:gdi and lbc}. 

For a fair comparison, we keep the two reward shaping the same as used in  GDI-H, namely,  i)  for  and ii)  for .



\begin{figure*}[!ht]
\vspace{-0.1in}
\subfigure[ and ]{
		\includegraphics[width=0.45\textwidth]{photo/app/kl/14_all.pdf}
	}
	\subfigure[ and ]{
		\includegraphics[width=0.45\textwidth]{photo/app/kl/14_all_raw.pdf}
	}

 
\subfigure[ and ]{
		\includegraphics[width=0.45\textwidth]{photo/app/kl/14_all_log.pdf}
	}
	\subfigure[ and ]{
		\includegraphics[width=0.45\textwidth]{photo/app/kl/14_all_raw_log.pdf}
	}
\caption{KL Divergence of GDI-H and LBC in Chopper Command (Smoothed by 0.9 for the ease of reading).}
\label{fig:KL}
\end{figure*}

From Fig. \ref{fig:KL}, we can find the distance between  and  of  and  decrease rapidly in GDI-H while LBC can maintain a more diverse set of policies. The optional behaviors for each actor gradually diminish, and the behavior space of GDI-H degenerates across the learning process. In contrast, LBC can maintain the capacity of the behavior space and avoid degradation since LBC maintains a population of different policy models (Corresponding to a population of different policies.)






