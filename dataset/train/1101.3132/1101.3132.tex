\documentclass[a4paper,twoside,openright]{report}

\usepackage{illcmolthesis}
\title{Reactive Valuations}
\author{Bert Christiaan Regenboog}
\birthdate{April 11, 1983}
\birthplace{Rotterdam}
\defensedate{December 15, 2010}
\supervisor{Dr Alban Ponse}
\committeemember{Dr Alban Ponse}
\committeemember{Dr Inge Bethke}
\committeemember{Prof Dr Frank Veltman}
\committeemember{Dr Yde Venema}

\usepackage{amsmath,amsthm,amssymb,latexsym,stmaryrd}
\usepackage[bookman]{quotchap}
\usepackage[all]{xy}
\usepackage{fancyhdr}
\pagestyle{fancy}
\renewcommand{\chaptermark}[1]{\markboth{\chaptername\ \thechapter.\ #1}{}}
\renewcommand{\sectionmark}[1]{\markright{\thesection\ #1}}
\fancyhf{}
\fancyhead[RO,LE]{\bfseries\thepage}
\fancyhead[LO]{\bfseries\rightmark}
\fancyhead[RE]{\bfseries\leftmark}
\renewcommand{\headrulewidth}{0.5pt}
\renewcommand{\footrulewidth}{0pt}
\addtolength{\headheight}{0.5pt}
\fancypagestyle{plain}{\fancyhead{}
	\renewcommand{\headrulewidth}{0pt}
}
\usepackage[pdftex,colorlinks=true]{hyperref}

\newcommand{\sig}{\ensuremath{\Sigma_{CP}(A)}}
\newcommand{\dd}[1]{\frac{\partial}{\partial #1}}
\newcommand{\BF}{\ensuremath{\textbf{BF}}}
\newcommand{\syn}{\bumpeq}
\newcommand{\nsyn}{\not\bumpeq}
\newcommand{\PDLI}[1]{\llbracket #1\rrbracket^\mathbf{M}}
\newcommand{\CP}[1]{\ensuremath{\mathrm{CP#1}}}
\newcommand{\CPrp}[1]{\ensuremath{\mathrm{CPrp#1}}}
\newcommand{\CPcr}[1]{\ensuremath{\mathrm{CPcr#1}}}
\newcommand{\CPcontr}{\ensuremath{\mathrm{CPcontr}}}
\newcommand{\CPstat}{\ensuremath{\mathrm{CPstat}}}
\newcommand{\FIXME}[1]{\textcolor{red}{FIXME: #1}}

\newcommand{\lef}{\ensuremath{\triangleleft}}
\newcommand{\rig}{\ensuremath{\triangleright}}

\newcommand{\leftand}{~
     \mathbin{\setlength{\unitlength}{1ex}
     \begin{picture}(1.4,1.8)(-.3,0)
     \put(-.6,0){}
     \put(-.53,-0.36){\circle{0.6}}
     \end{picture}
     }}
     
\newcommand{\bigleftwedge}[1]{
     \mathbin{\setlength{\unitlength}{1ex}
     \bigwedge_{#1}\begin{picture}(0.8,.0)(0,0)
     \thicklines
\put(-5.22,-0.78){\circle{0.6}}
     \end{picture}
     }}
     
\newcommand{\rightand}{~
     \mathbin{\setlength{\unitlength}{1ex}
     \begin{picture}(1.4,1.8)(0,0)
     \put(-.8,0){}
     \put(.72,-0.36){\circle{0.6}}
     \end{picture}
     }}

\newcommand{\leftor}{~
     \mathbin{\setlength{\unitlength}{1ex}
     \begin{picture}(1.4,1.8)(-.3,0)
     \put(-.6,0){}
     \put(-.53,1.7){\circle{0.6}}
     \end{picture}
     }}

\newcommand{\rightor}{~
     \mathbin{\setlength{\unitlength}{1ex}
     \begin{picture}(1.4,1.8)
     \put(-.8,0){}
     \put(.72,1.7){\circle{0.6}}
     \end{picture}
     }}

 \newcommand{\leftimp}{~
     \mathbin{\setlength{\unitlength}{1ex}
     \begin{picture}(1.5,1.8)
     \put(-.1,0){}
     \put(-.3,0.57){\circle{0.6}}
     \end{picture}
     ~}}
     
\newcommand{\rightimp}{~
     \mathbin{\setlength{\unitlength}{1ex}
     \begin{picture}(1.5,1.8)
     \put(-.9,0){}
     \put(1.76,0.57){\circle{0.6}}
     \end{picture}
     ~}}
     
\newcommand{\leftbiimp}{~
     \mathbin{\setlength{\unitlength}{1ex}
     \begin{picture}(1.5,1.8)
     \put(-.1,0){}
     \put(-.44,0.57){\circle{0.6}}
     \end{picture}
     ~}}
     
\newcommand{\rightbiimp}{~
     \mathbin{\setlength{\unitlength}{1ex}
     \begin{picture}(1.5,1.8)
     \put(-.9,0){}
     \put(1.76,0.57){\circle{0.6}}
     \end{picture}
     ~}}

\newtheorem{theorem}{Theorem}[chapter]
\newtheorem{clm}{Claim}[theorem]
\newtheorem{prop}[theorem]{Proposition}
\newtheorem{lem}[theorem]{Lemma}
\newtheorem{thm}[theorem]{Theorem}
\newtheorem{defn}[theorem]{Definition}
\newtheorem{cor}[theorem]{Corollary}

\begin{document}
\maketitle
\thispagestyle{empty}
~\newpage

\pagenumbering{roman}
\tableofcontents

\begin{abstract}
In sequential logic there is an order in which the atomic propositions
in an expression are evaluated. This order allows the same atomic proposition
to have different values depending on which atomic propositions have
already been evaluated. In the sequential propositional logic
introduced by Bergstra and Ponse in \cite{main}, such valuations are
called ``reactive'' valuations, in contrast to ``static'' valuations as
are common in e.g.\ ordinary propositional logic. There are many
classes of these reactive valuations e.g., we can define a class of
reactive valuations such that the value for each atomic proposition
remains the same until another atomic proposition is evaluated.

This Master of Logic thesis consists of a study of some of the properties of
this logic.

We take a closer look at some of the classes of reactive valuations mentioned in \cite{main}. We particularly focus on the relation between the axiomatization and the semantics. Consequently, the main part of this thesis focuses on proving soundness and completeness. Furthermore, we show that the axioms in the provided axiomatizations are independent i.e., there are no redundant axioms present. Finally, we show -completeness for two classes of reactive valuations.

\end{abstract}

\thispagestyle{empty}
~\newpage

\pagenumbering{arabic}

\chapter{Introduction}

\section{Introduction}
In sentential logic (also called propositional calculus), sentences are build from atomic propositions, the constants true and false, and connectives such as , , , etc. The truth of such a sentence with respect to a model, is calculated using the interpretation function associated with that model. This function not only assigns meaning to the connectives and constants but also to the individual atomic propositions.

In sentential logic the interpretation of connectives and constants is given. Hence, a model in sentential logic is uniquely defined by the interpretation of the individual atomic propositions. These atomic propositions are assigned either the value true or the value false by the interpretation, indicating whether they are true or false in the model. Such an assignment is referred to as a valuation. In sentential logic, these valuations entirely depend on the atomic propositions they assign a value to and not on other external factors. Consequently, a valuation will give an atomic proposition the same valuation no matter its location within a sentence, and this valuation will never change. These valuations are, in a manner of speaking, static.

This static behaviour can be considered a severe limitation of sentential logic. For example, sentential logic is not sufficiently expressive for modelling logical conjunction as implemented in most programming languages because the conjunction in these cases is non-commutative\footnote{We explain in the next section why this is the case.}. In order for us to effectively model these and other kinds of connectives and sequential systems, we are required to extend our notion of valuation.

This thesis is based on the work by Bergstra and Ponse in \cite{main}. They introduce a logic that uses reactive valuations instead of normal valuations. Reactive valuations allow us to take previously evaluated atomic propositions into account. Thus the valuations are in a sense ``reactive''. The use of reactive valuations necessitates the need for expressions in this logic to be evaluated in some fixed order. Hence the resulting logic has a sequential interpretation. The same atomic proposition may have a different value depending on which atomic propositions have previously been evaluated. The reactive valuations have thus an additional dependence on a sequence of atomic propositions representing the history of evaluation.

The signature of this logic consists of a finite set of atomic propositions and the constants  and  plus a ternary operator . The constants  and  denote true and false, respectively. The ternary operator denotes conditional composition i.e., an \emph{if-then-else} operator. For example,  translates to if  then  else . This then clues us to the order in which expressions of this type are evaluated i.e., the antecedent is evaluated first. The question which of the two consequents is then evaluated first is irrelevant because their value depends only on the antecedent and not on each other.

For example, take the expression

The letters  and  represent atomic propositions. The above reads thus \emph{if a then a else b}. In sentential logic, it suffices to know the value of  and  to know whether the sentence is true or false, see the following table:

However this is not the case if we are using reactive valuations. Keeping the if-then-else interpretation in mind, we intuitively begin by evaluating the middle , the antecedent. The act of evaluating this  can possibly have influence on the valuation of the left-hand  and the right-hand . We denote the value of  given a valuation  as . Furthermore, the valuation obtained after evaluating  is denoted as . So  can be viewed as a function that maps reactive valuations to other reactive valuations. The value  is determined by the values of ,  and , as illustrated in the following table: 

Compared to sentential logic, we have an extra parameter because . Note that it is not possible for the valuation of  to influence the valuation of either of the 's. Nor is it possible that the left-hand  has influence on the valuation of the middle  or the right-hand .

There are other limitations to reactive valuations. For example, take the expression . This has the following truth table:

The value of  is in this case just computed using two values  and . It is not possible to assign different values to the left-hand  and the right-hand  using reactive valuations because reactive valuations do not take into account the value of previously observed atomic propositions. Only the act of evaluating atomic propositions influences reactive valuations, regardless of what those values might have been.

The class of all reactive valuations is referred to as the free reactive valuations. We can construct different logics by constraining the type of reactive valuations we allow. For example, if we take the class of reactive valuations that ignore the sequence of previously evaluated atomic propositions, we get the static valuations. Static valuations coincide with the classical valuations in sentential logic i.e., they always give the same value for an atomic proposition independent of context.

Another example of a class of reactive valuations are the contractive valuations. In these valuations the value of an atomic proposition, say , remains the same as long as no atomic proposition other than  is evaluated. This is in contrast with the free reactive valuation where each instance of atomic proposition  in a sequence of 's can have a different value. For example, if we are using free reactive valuations it is possible to assign different values to the 's in the expression . This is not possible if we are using contractive valuations because between the first  and the second  no other atomic proposition is evaluated, and thus the valuation of  must remain the same.

We can formalize the idea of creating new logics using classes of reactive valuations. A class  of reactive valuations gives rise to an equivalence relation, -equivalence. Since reactive valuations are sensitive to the context, this -equivalence is not necessarily congruent i.e., equivalence of a term  need not be preserved when substituting equivalent subterms in the term . For example, for every reactive valuation  we have . It is however not the case that  because in the right-hand term the valuation of  depends on  which is not the case in the left-hand term. Since congruence is a necessary property, we therefore introduce -congruence as the largest congruence contained in -equivalence. -congruence thus represents our semantics.

Besides a semantical characterization, each logic can be equationally specified using a number of axioms. For example, the axiom , where  and  are arbitrary terms, is an axiom shared by every logic we present. Given these axiomatizations we can prove properties such as soundness and completeness.

In the rest of this chapter we further motivate why reactive valuations are relevant, and discuss some related work. In Chapter~2, a formal introduction is given to reactive valuations. In addition, four varieties are introduced and discussed. These varieties include the varieties of free, contractive and static valuations we mentioned earlier. This discussion includes proper axiomatizations and subsequent proofs of completeness and soundness of these varieties. In Chapter~3 a definition of -completeness is given, and we explain why -completeness is a nice property of an axiomatization. Subsequently, a proof of -completeness for the variety of free reactive valuations and the variety of static valuations is presented. The axiomatizations given in Chapter~2 might contain redundant axioms. In Chapter~4, we show that this is mostly not the case. Finally, Chapter~5 contains a summary, and a few suggestions for further research.

\section{Motivation}
Static valuations, the type of valuations used in sentential logic, are inadequate to model many sequential systems. However, we can model those systems using different classes of reactive valuations.

Using reactive valuations we can model non-commutative logical connectives. For example,  is disjunction in which the right argument is evaluated first (notation is taken from \cite{connectives}). So in the signature of our logic  is defined as . In similar fashion  is defined as . In sentential logic these two definitions would coincide. This however is not the case if we use reactive valuations i.e., this allows us to distinguish between  and . Hence, reactive valuations are suited for modelling non-commutative connectives. One area where non-commutative connectives are commonplace, is that of programming languages

In most programming languages, it is possible that a function, in addition to producing a value, also does something else. It might for example raise an exception or modify a global variable. This kind of behaviour is called a side-effect of said function. Furthermore, it is also possible that the return value of a function might depend on some external factor. For example, a database or a random number generator. Finally, expressions are evaluated sequentially. This means that if want to evaluate , the interpreter has to decide whether to evaluate  first or  first.

Combining these facts, we could get a situation in which the value of the expression  depends on whether  is evaluated first or  because  might influence the value of , and vice versa. Admittedly it is limited to situations that can be translated to boolean formulas, but this is the kind of behaviour we can model with reactive valuations and not with sentential logic.

Short-circuit evaluation is a common feature of programming languages. Short-circuit evaluation is usually limited to the evaluation of a few specific operators. Using such evaluations only the arguments that have to be evaluated, are actually evaluated. The operator \verb+&&+, logical conjunction, in C/C++ is an example of a short-circuiting operator. Consider evaluating the expression \verb+x && y+. If \verb+x+ evaluates to false, the second argument \verb+y+ is not evaluated because regardless of its value \verb+x && y+ evaluates to false. If  and  do not have any side-effects and their values are limited to true and false, this operator is commutative. However, in practice it is possible that  and  represent some computation that does not necessarily terminate. Consequently, if one of the arguments does not terminate, the value of a short-circuiting operator like \verb+&&+ might be different depending on which argument we decide to evaluate first. Hence, this is another example of a non-commutative connective with a symmetric counterpart.

Arguably the programming language with the most direct connection with reactive valuations is Prolog. Prolog is originally designed to model language through computational models based on predicate logic. This paradigm of programming in terms of predicate logic is called logic programming. As a result, programs in Prolog almost read like logical formulas, and are referred to as predicates. In the early days of logic programming, the language did not have any instructions with explicit side-effects. However, for Prolog to have some practical value extra instructions are needed. For example, the database instructions \emph{assert} and \emph{retract}. These instructions can, perhaps not surprisingly, assert and retract facts to a Prolog program. Clearly, programs using these instructions have side-effects that might influence whether predicates evaluate to true or false. For example, predicate  is true if fact  is true. In addition, predicate  retracts fact . Hence, if there is another predicate , which is true if  is true, and retracts , the predicates influence each others value by their side-effects.

Staying within the field of computer science, the ``reactive behaviour'' illustrated by the previous examples does not limit itself to programming languages. On the more lower hardware level we have the term ``sequential logic'' in circuit theory. Here sequential logic refers to logic circuits that have a memory. The output of such a circuit does not only depend on the input, but also on the history of inputs. These circuits can be used to construct finite state machines such as Moore and Mealy machines. The output of these machines depends on an internal state, which in turn depends on the previous state and input. 

In everyday reasoning, so called common-sense reasoning, the assertion and retraction of facts is fairly common. For example, while it may be true that Jack is at home in the evening, it certainly does not have to be true that he is always at home. In addition, this is not limited to the physical world but can also include the beliefs of agents. For example, one might believe that all adult swans have white plumage, until one travels to Australia and sees that there are swans with black plumage, at which point the beliefs are revised. Ordinary classical logic is not equipped to model these reactive processes i.e., the validity of propositions remains the same.

Pragmatics is a subfield of linguistics in which the interaction between utterances i.e., speech acts, is studied. One example of such interaction is that of presupposition. Presupposition refers to implicit assumptions in sentences. Take for example the sentence ``Jack drives his car to the mall''. This sentence presupposes that Jack has a car. So modelling presupposition requires we are able to deal with side-effects of posing a proposition, another example of reactive evaluation. 

In this section we presented a number of processes that might be modelled using reactive valuations as motivation why reactive valuations are interesting. In the following section most of the aforementioned examples will be examined once more except this time in the context of related work i.e., we compare existing literature on these subjects with reactive valuations.

\section{Related work}
One of the defining properties of our logic is that the valuation of the atomic propositions changes depending on what atomic propositions have been evaluated. In this section we discuss some other logics and formalisms that also demonstrate this property.

As stated earlier in this thesis is based on the work done by Bergstra and Ponse in \cite{main}. In it they introduce reactive valuations and the varieties which we will study in the next chapters. They discuss a number of topics which will not be covered in this thesis. These topics include a method of modelling a three-valued logic using reactive valuations, expressivity results, the complexity of satisfiability, and a study of the properties of infinite propositions.

Since reactive valuations are a relatively new invention with no clearly defined predecessor, there is no related work that deals specifically with reactive valuations besides the one by Bergstra and Ponse. There is, however a very large body of literature dealing with sequential reasoning. This literature ranges from computer science to philosophy and linguistics. An exhaustive literature overview is however beyond the scope of this thesis and would in all likelihood constitute a thesis all on its own. This chapter, therefore, gives a very brief overview with a few specific examples, which will hopefully offer a starting point for a more detailed account of related work.

The previous section on motivation already gave a few examples of areas where reactive valuations might be applied and hence literature dealing with the phenomena described in that section can be considered related to the theory of reactive valuations.

For example we mentioned common-sense reasoning i.e., the type of reasoning we use in our daily lives. Common-sense reasoning has been studied in many fields but it has enjoyed renewed attention the past decades with the rise of the field of artificial intelligence where it is mostly referred to as non-monotonic reasoning.

In classical logic when a statement  logically follows from a set  of premises, it is the case that  logically follows from a superset  of premises. Consequently, we call this logic monotonic. This means that once something is true it will remain so. In common-sense reasoning this is not the case. Hence this type of reasoning is called non-monotonic. Similarly reactive valuations are non-monotonic due to ever-changing valuations. See \cite{non-monotonic} and \cite{non-monotonic2} for an overview of non-monotonic reasoning.

Similarly in philosophy we have defeasible reasoning which deals with arguments that might be true but can be refuted at a later point by observing new facts, see \cite{defeasible}.

We can view the evaluation of an expression as the execution of a program. The atomic propositions would then correspond to single instructions or pieces of programs such as procedures or functions. There are many formalisms that are designed for reasoning about propositional properties of programs, e.g. Hoare logic, temporal logic of actions and propositional dynamic logic (PDL). 

For example, PDL (see \cite{PDL} for an overview) can be effectively used to model reactive valuations. In PDL we have a set of atomic propositions , a set of basic actions , a set of states , and a binary relation  on . The connection between PDL and reactive valuations becomes evident if for every atomic proposition in  there is a basic action in  that signifies the evaluation of the respective atomic proposition. Then the states  correspond to the various reactive valuations. In that context deterministic PDL i.e., the class of frames characterized by , is of particular interest because it illustrates one of the limitations of reactive valuations. Namely, that in the previously mentioned example  the value of both 's will have to be the same.

As mentioned in the previous section the programming language Prolog has special instructions for the assertion and retraction of facts.  Consider the following Prolog program
\begin{verbatim}
    p(a) :- p(b), retract(p(b)).
    p(a) :- assert(p(b)), fail.
\end{verbatim}
The statement \verb|fail| is a reserved keyword that automatically fails i.e., somewhat similar to the constant false. When repeatedly asking the interpreter \verb|p(a)| we get the output sequence 0101010101\ldots where 0 and 1 stand for \verb|no| and \verb|yes|, respectively.

In \cite{prolog_expr} the expressive power of the side effects of the assert and retract statements in Prolog is investigated. The authors main tool in this analysis are these output sequences. Much the same as we consider different varieties they consider different classes of output sequences e.g., constant sequences that represent programs with no side effect and ultimately periodic sequences where the sequence at some point starts to repeat itself. For a complete denotational semantics of Prolog, see \cite{prolog_semantics}.

Reactive valuations give rise to directed versions of connectives such as  and . In Chapter~2 we define a number of these connectives. The notation for these is taken from \cite{connectives}, where a number of many-valued logics are described. In \cite{belnap_cond} an axiomatization of Belnap's four-valued logic is given using conditional composition, which as you might recall is the only connective in the signature of the logic described in this thesis. The notation for conditional composition is taken from a paper by Hoare, \cite{hoare}. In this paper Hoare describes what we call the variety with static valuations. This variety corresponds to boolean algebra, as we shall show in Chapter~3.

In the previous section we briefly mentioned pragmatics, and more specifically presupposition. The most commonly used formalism to describe presupposition and its effects is discourse representation theory (see \cite{DHT}). There are, however, different approaches. For example, in \cite{kracht} a many-valued logic with directed connectives is used to investigate some of the main problems in presupposition.

Besides the ones we just mentioned, there are many other research areas that deal with sequentiality that we did not mention here. For example, temporal logic, substructural logics and non-commutative logics. As mentioned before this section is but a brief overview, and we hope this will prove to be a useful point of departure for a more thorough investigation into related work.

Lastly, it took more than two years to write this thesis. This year a new paper on the subject of reactive valuations by Bergstra and Ponse appeared, see \cite{future}. The new results in that paper are not discussed here nor do the results in this thesis depend on those results.



\chapter{Reactive valuations}

This chapter represents the main body of the thesis. Reactive valuations are formally introduced, which enables us to define a number of different logics. Subsequently, some basic properties such as soundness and completeness are proven. 

\section{Introduction}
In this section we introduce a sequential propositional theory starting with the language. The symbols of our language are as follows:
\begin{itemize}
\item the constants  and 
\item the ternary operator , called conditional composition
\item a finite non-empty set  of atomic propositions
\item an infinite set of variables 
\end{itemize}
The notation  for conditional composition was first introduced by Hoare in \cite{hoare}. We use the letters  to denote the variables, and the letters  to denote atomic propositions i.e., members of .  Note that  is finite and non-empty. These conditions on the set of atomic propositions are relevant because they affect the validity of certain theorems, particularly those dealing with independence and -completeness as we shall see in the next chapter. We call this signature .

The set  of all terms over signature  is defined as the smallest set such that
\begin{itemize}
\item 
\item 
\item 
\item  with 
\end{itemize}
Subsequently, the set  of all closed terms over signature  is defined as the largest subset of  such that no term in  contains a variable. The letters  are used to denote members of  whereas we use  to denote closed terms i.e., members of .

We postpone the discussion of the actual model construction until the next two sections. For now it suffices to recall the interpretation we offered in the introduction i.e.,  and  are interpreted as true and false, respectively, and  is the if-then-else operator, where the middle argument is the antecedent and the left-most and right-most argument are the consequents.





Using the language we just introduced it is now possible to give the following axiomatization:

We call this set of axioms CP. Hence when , for terms  and  from signature \sig, can be derived from CP, we denote this as

Henceforth we often omit the ``'' part except when it is not clear from the context which set of axioms is used.

It is also important to note that the equality is in fact a congruence. Consequently, equality has besides the usual properties of reflexivity, symmetry, and transitivity

also the congruence property, which in this case will have the following form


Using this axiomatization and its intended interpretation, we can define versions of the classical connectives.

where . The notation of the operators is due to Bergstra, Bethke, and Rodenburg in \cite{connectives}. The circle in the connective indicates the order in which the expression is evaluated e.g.,  indicates that we evaluate  before looking at . In the following sections we show that although e.g.  and  have the same interpretation in classical logic, they are not provably equal in CP. Also properties such as idempotency, commutativity, distributivity and absorption are not derivable in CP. However, there are some classical properties that are derivable in CP. For example we have the following property,

which implies that 

Another example is based on De Morgan's laws,


Using conditional composition, we can create the notion of sequential composition, denoted by  i.e.,

By axiom CP4 it follows that sequential composition is associative,

In the following sections we not only give a model for the discussed axiomatization CP but also show that given the provided framework, it is easy to create variations on this model.

\section{Reactive valuations}
In the classic case a valuation determines the value of all the atomic propositions  i.e., it assigns either true or false to each atomic proposition. In the case of reactive valuations, this assignment can be dependent on atomic propositions previously evaluated. In this section we will formally define the notion of reactive valuations.

Let  be the sort of boolean values with constants  and  and  be a sort of reactive valuations. Then for each  let there be a function

This function is called the yield of  and it allows us to look up the value of  using a specific reactive valuation. Furthermore, for each  there exists a function

called the -derivative. With this function we can capture the dynamic nature of reactive valuations i.e., when we evaluate an atomic proposition  the current reactive valuation can change. It is important to note that the elements in  do not just encode the value of the individual atomic propositions but also keep a history of atomic propositions previously evaluated. It is therefore possible that two reactive valuations  and  assign the same values to each atomic proposition but .

We define the signature  to consist of the sorts , , functions  and  for each , and constants  and  of sort .

A structure  over  is called a \emph{reactive valuation algebra} (RVA) if the following axioms are satisfied

for each . So the constants  and  assign either  to all the atomic propositions or  to all the atomic propositions, respectively. Furthermore, these two valuations do not change while evaluating an expression.

The value of a proposition  from signature  according to a reactive valuation  in a RVA  is denoted by

This value is determined as follows: for ,

where  is a generalized notion of the function , and is defined as follows

There are a number of observations to be made here.

The propositions  and  are always evaluated as true and false, respectively, no matter which evaluation we use. Furthermore, evaluating  and  will not change the current valuation. So, it follows that .

Also important to note is that in e.g. the proposition  the values of  and  will not depend on  as  never gets evaluated.

Finally, let us look at a few examples.

Note that if we know that  then it does not necessarily follow that  is also true because the valuations  and  are different. To emphasize this point, look at propositions  and . Although, it certainly is true that in a classical setting these two are equivalent, it immediately follows that a valuation  exists such that .

The following example has instead of a constant or an atomic proposition as a condition, another conditional statement.

This example illustrates that the value of the leftmost  does not only depend on  being evaluated but also on the actual value of  because this determines whether either  or  (the occurrence of  right next to  in the expression) is evaluated which in turn affects the value of the leftmost .

\section{Reactive valuation varieties}
In the previous section we introduced the notion of reactive valuation algebra (RVA). In this section we define a number of specific classes of RVAs. Since the signature of all RVAs is the same, we refer to these classes as varieties. We define the following varieties of RVAs:
\begin{description}
\item[Free reactive valuations] This variety of RVAs consist of all possible RVAs. So there are no requirements posed on the RVAs in this variety other than that they are RVAs. Every other variety will be a subvariety of this one.
\item[Repetition-proof valuations] The variety with repetition-proof valuations consists of all RVAs that satisfy

for all .
\item[Contractive valuations] The variety with contractive valuations is a subvariety of the variety with repetition-proof valuations i.e., every RVA in this variety will also be in the variety with repetition-proof valuations. In addition the RVAs here will satisfy

for all .
\item[Static valuations] The RVAs in the variety with static valuations satisfy the following equation

for all .
\end{description}
The definitions of these varieties were taken from \cite{main}. In Appendix A we define and examine an additional variety of our own.

Given a variety  we say that propositions  and  are -equivalent, which is denoted as

if  for all RVAs  in the variety  and valuations . Using the relation  we can define a congruence relation over propositions. We say that  and  are -congruent,

if  is the largest congruence contained in .

Given the four varieties we defined earlier we will use the abbreviations , , ,  for free, repetition-proof, contractive and static varieties, respectively

Bergstra and Ponse prove the following proposition.
\begin{prop}\label{variety relation prop}
 and  for 
\end{prop}
The first part of this proposition and  the differences between the varieties will become apparent in the following sections. The second part is best demonstrated using an example. If we take the term  then clearly
 
for all  and . However, it is not the case that for all varieties  the following holds

because in the left-hand side the value of  will depend on  but on the right-hand side this dependency is gone. This means that although for all varieties  we have , it does not follow that . In the section on static valuations, we show that congruence and equivalence do happen to coincide for that variety.

The following proposition clarifies the relationship between congruence and equivalence for arbitrary variety .
\begin{prop}\label{equiv congr prop}
If  and for all  and , 

then

\end{prop}
\begin{proof}
Assume  and , . Since  is defined as the largest congruence contained in ,  if for all closed terms  and  the following three cases are true:
\begin{itemize}
\item[(1)] 
\item[(2)] 
\item[(3)] 
\end{itemize}
We continue by proving these three cases.

Since , it follows that , . Consequently, . Hence,

So case (1) is true. Furthermore, the argument for case (3) is symmetric to the one give here. So case (3) is also true.

By assumption we know that  and . Thus,

Consequently, case (2) also holds, and .
\end{proof}

In the following sections we will further discuss the varieties we defined here. This discussion will include proper axiomatizations, and proofs of soundness and completeness.

\section{Notation and conventions}
Before continuing with the in-depth discussion of the varieties, we recap and introduce additional notation and conventions. We have encountered the following equality relations thus far:
\begin{itemize}
\item  denotes semantic equivalence with respect to variety .
\item  is the largest congruence contained in .
\item Plain  is used to denote three different types of congruences. The first type is provable equality e.g. . However we often omit the ``'' part if it is clear from the context which axiomatization we use. We also use  in the interpretation of terms given some valuation  e.g. . Finally we use  for equality between valuations e.g. . Note that no ambiguity arises from these three different interpretations because they deal with equality over three distinct classes of objects and it will be immediately clear from the arguments or the context how  is used.
\end{itemize}
Absent from this list is syntactic equality. We therefore introduce the symbol  for syntactic equality\footnote{Often  is used to denote syntactic equality. However, since  is already used for semantic equivalence, we opted to use  in order to avoid confusion.}.

We have the following conventions concerning symbols:
\begin{itemize}
\item The letters  denote atomic propositions.  is the set of all atomic propositions.
\item The letters  denote variables.  is the set of all variables.
\item The capital letters  denote closed terms.  is the set of all closed terms from signature .
\item The letters  denote terms that can possibly, but not necessarily, be open.  is the set of all terms.
\end{itemize}

\section{Free reactive valuations}
-Congruence is axiomatized by CP. The variety with free reactive valuations is the variety on which all other varieties are based. This does not mean that there are no limitations. For example if we take the term  it is not possible to distinguish between the two 's i.e., we are forced to give them the same value no matter what valuation we choose. This limitation can be found in the definition of RVA where we define  and  as functions instead of relations.

\subsection{Soundness}
We have claimed that -congruence is axiomatized by CP. We, however, have not yet proven that the resulting theory is sound and complete with respect to our model. In this section we will show that CP is sound. Soundness of a theory with respect to a model means that whatever we derive from the axiomatization of the theory is also true in that model.
\begin{thm}\label{soundness cp}
For all closed terms  and , 

\end{thm}
\begin{proof}
It suffices to show that the four axioms CP1, CP2, CP3 and CP4 are sound with respect to the variety with free reactive valuations. Let RVA  from the variety  with valuation  be given. Then, starting with CP1 we proceed as follows.

We use the semantics we defined in the previous sections to evaluate the left-hand side of CP1 with an arbitrary valuation , and end up with the right-hand side. In addition, observe that we do not pose any requirements on . Consequently, the above derivation holds for all RVAs  and . 
Furthermore, we also have the following:

Thus, by Proposition \ref{equiv congr prop}, we have proven that CP1 is sound.

Using the same strategy we prove that axioms CP2, CP3 and CP4 are sound.





Showing that axiom CP4 is sound, is a bit more complicated than the previous three axioms because of the number of cases involved.

Since

and

it is possible to e.g. replace  if ,
and  if  by the expression . So continuing from where we left off,



So all axioms are sound with respect to .
\end{proof}

\subsection{Completeness}
In this section we prove completeness. The axiomatization  is complete with respect to the variety with free reactive valuations, if two closed terms are -congruent then these terms are also provably equal in .

Before proving completeness we first introduce basic forms, which are a class of closed terms. We will show that each closed term is provably equal to a basic form. The primary reason for introducing these basic forms is that they will greatly simplify most proofs by structural induction on closed terms because their structure is less complicated. This will be especially useful in proving completeness.

\begin{defn}\label{basic form def}
The set of basic forms  is defined as the smallest set
such that , and if  then  for all atomic propositions .
\end{defn}

So e.g.  is not a basic form but  is. Similarly,  is not a basic form but  is. If conditional composition occurs in a basic form, the antecedent is always an atomic proposition.

An alternative way of looking at basic forms is to view them as labeled binary trees i.e., the basic form  corresponds to the tree

where  and  are the binary trees corresponding to  and , respectively. Hence, the nodes of the tree consist of atomic propositions and the leaves of either  or . This illustrates the simplicity of basic forms because if we would try to similarly construct a binary tree for arbitrary closed terms, the nodes themselves would have to be trees because the antecedent of conditional composition occurring in such a term can itself be an arbitrary closed term.

As mentioned before we will prove that for each closed term there exists a basic form such that they are provably equal to each other.

\begin{lem}\label{basic form theorem}
For each closed term  over signature  there exists a
term  such that .
\end{lem}
\begin{proof}
We proceed by structural induction on . Suppose  is either  or  then . Suppose  for .\footnote{Recall that  is used for syntactic equality.} Since  and ,  exists. Suppose  is . By the induction hypothesis there exist terms  such that , , and . By congruence, it follows that . We show by structural induction on  that  exists.

If , then , and  is a basic form. Similarly, if  is , then , and . If  for some  then

where  and , . Clearly, .
\end{proof}

The following lemma is needed in the Lemma \ref{completeness lemma} that shows that syntactic equality and -congruence coincide.
\begin{lem}\label{inv congr lemma}
For ,

\end{lem}
\begin{proof}
We prove the contraposition. Then either  or  implies . Assume without loss of generality that . Then the following two cases can be distinguished.

In the first case, . Consequently, there exists an algebra  and valuation  such that . Subsequently, we construct an algebra  with valuation  such that  and . Then


In the second case, . So the congruence property does not apply to  and . It follows that there are closed terms  and  such that one of the following is the case:
\begin{itemize}
\item[(1)] 
\item[(2)] 
\item[(3)] 
\end{itemize}
In each of the three the cases there is an algebra  and valuation  such that the left-hand side and the right-hand side are not equal using  valuation . Using this valuation  we know that in case (1) the following applies:

Consequently, . However, this implies that . Since we already assumed that , we have a contradiction. Hence, case (1) cannot occur. Using a similar argument, we can show that this also applies to case (2).

This leaves us with case (3). Let  and  be defined as before. Then, similarly to the case where , we construct a new algebra  and valuation  such that  and . Consequently,

So the congruence property does not hold for  and , and thus these terms are not congruent to each other, .
\end{proof}
It is perhaps interesting to observe that the other direction of the previous lemma follows from congruence i.e., if we know that  and  then .

The next lemma shows that syntactic equality and -congruence coincide.
\begin{lem}\label{completeness lemma}
For ,

\end{lem}
\begin{proof}
The direction from syntactic equality to -congruence is trivial. The other direction is proven by taking the contraposition and then proceeding by structural induction on both  and . So assume . We omit the trivial cases and the cases that follow by symmetry. 

Suppose  and  for some . If  then  by congruence. However,

Note that we can always construct an algebra  and  such that neither  nor .

Suppose  and . Then we can assume without loss of generality that . By I.H., it follows that . By Lemma \ref{inv congr lemma}, .

Of course, if  and , we can simply pick an algebra  and valuation  such that .
\end{proof}

Now the stage has been set to prove completeness for not just basic forms but for all closed terms.

\begin{thm}\label{completeness thm}
For closed terms  and ,

\end{thm}
\begin{proof}
Let . By Lemma \ref{basic form theorem}, there exist
terms  such that  and .
Furthermore, by soundness, it follows that  and , and
thus . Finally, by Lemma \ref{completeness lemma}, we get
 which implies that .
\end{proof}

\section{Repetition-proof valuations}
Recall that the variety with repetition-proof valuations is characterized by the following equation:

This restricts the type of valuations we allow in this variety. The consequences of introducing this restriction are perhaps best explained using an example. Take a look at the following evaluation of the term  using a repetition-proof valuation :

Observe that since  it follows that the case where  and  never occurs. Thus during the evaluation of  the  is never evaluated, and thus we can replace  with any term we like which in this case is another atomic proposition . However, this does not mean that  because the evaluation of  depends on both 's.

Similar to the free reactive valuations, we can define a corresponding axiomatization. In this case, the axiomatization consists of CP plus the following two axiom schemas,

for all . We call the entire axiomatization .
The axioms \CPrp1 and \CPrp2 combined with CP tell us that the value of an atomic proposition  does not change unless there is another proposition in between them.

An example of repetition-proof behaviour can be found in programming. For example, an atomic proposition corresponds with a function that updates a global variable but its output does not depend on this variable.




As in the previous section we proceed by proving soundness and completeness, starting with soundness.

\subsection{Soundness}

\begin{thm}
For closed terms  and ,

\end{thm}
\begin{proof}
According to Proposition \ref{variety relation prop}, we know that . Since we already checked the soundness of the axioms in CP in the proof for soundness of free reactive valuations, it suffices to show soundness for  and , starting with CPrp1. Let  be a RVA from variety  and valuation .


By Proposition \ref{equiv congr prop} CPrp1 is sound. Next we show soundness for CPrp2:


So CPrp2 is also sound.
\end{proof}

\subsection{Completeness}
Similar to the previous section we define a set of basic forms for this variety. Since we are working with a different variety the set of basic forms needs to change. If we were to use the set \BF\ i.e., the set of basic forms as defined in the section on free reactive valuations, as the basic forms of this variety then syntactic equality and -congruence would not coincide. For example, let the terms  and  be in \BF\ and let  then these terms are -congruent but not syntactically equal. So we need to define a new set of basic forms.
\begin{defn}
The set of repetition-proof basic forms is the smallest set  such that  and if  then
\begin{itemize}
\item if  and  then 
\item if  and  then 
\item if  and  then 
\item if  and  then 
\end{itemize}
for all .
\end{defn}
Clearly, the set  is a subset of . The four cases mentioned in the definition are based on the axioms \CPrp1 and \CPrp2. 
\begin{lem}
For each closed term  there exists a term  such
that .
\end{lem}
\begin{proof}
We prove this theorem by structural induction on . By Lemma \ref{basic form theorem} it follows that we can assume without loss of generality that  is a basic form as defined in the section on free reactive valuations i.e., .

If  is  or  then . Suppose  is . By the induction hypothesis,
there exist terms  such that 
and . Now suppose that  and . Consequently,

By definition of  we have .

Using similar reasoning we can show that there exists such a term
 for the remaining three cases:
\begin{itemize}
\item  and 
\item  and 
\item  and 
\end{itemize}
\end{proof}

In the section on free reactive valuations we needed Lemmas \ref{inv congr lemma} and \ref{completeness lemma} in order to prove completeness. Similarly, we would like to prove these lemmas for this variety. However, observe that in the proofs of Lemmas \ref{inv congr lemma} and \ref{completeness lemma}, we construct a new valuation algebra based on another algebra. In the variety with free reactive valuations this is not a problem, but in this variety we have some restrictions on our RVAs, and thus cannot automatically assume that such a construction is possible. Therefore, in the proofs of the following two lemmas we focus on showing that such an algebra exists. We call an algebra from the variety with repetition-proof valuations an rp-algebra.

\begin{lem}
For ,

\end{lem}
\begin{proof}
We prove the contraposition. We assume without loss of generality that . Then either  or .

Suppose . Then there exists an rp-algebra  and valuation  such that . We show that  holds whether  or . Consider the following four cases:
\begin{itemize}
\item Suppose  and . Since , it follows by definition of  that  and . Consequently,  whether  or .
\item Suppose  and . By similar reasoning as before, we can conclude that . Furthermore, the value of  does not depend on . Consequently,  can be either  or .
\item Suppose  and . Argument is symmetric to the previous case.
\item Suppose  and . Neither the value of  nor that of  depends on . Consequently,  is independent of the value of .
\end{itemize}
Since  regardless of whether  or , we can assume without loss of generality that . We construct an rp-algebra  with valuation  such that . Since  is an rp-algebra we know that . Hence, it follows that  because if this were not the case then  which is contrary to our assumption. It follows that .

Suppose . Then the congruence property does not hold i.e., at least one of the following three cases is true,
\begin{itemize}
\item[(1)] 
\item[(2)] 
\item[(3)] 
\end{itemize}
for closed terms  and . Using the same argument as in the proof of Lemma \ref{inv congr lemma}, it follows that cases (1) and (2) cannot occur. So suppose case (3) is true. Then there exists an rp-algebra  and valuation  such that . Using similar reasoning as in the case for , we can assume without loss of generality that . Thus we can construct an rp-algebra  and valuation  such that  and . Consequently, . Thus the congruence property does not hold and .
\end{proof}

The following two lemmas have the perhaps odd condition that there are at least two atomic propositions. At the end of this section we examine what happens if there is only one atomic proposition. Note that by definition there is at least one atomic proposition i.e.,  is non-empty.

\begin{lem}\label{rp completeness lemma}
For  and ,

\end{lem}
\begin{proof}
We use the same argument as in the proof of Lemma \ref{completeness lemma}. However, in the case of  and , we claimed that we can always construct an algebra  and valuation  such that neither  nor . This is not true in this variety. For example, take . Then , and by definition of this variety, . We can solve this by instead of taking  and  to show that  and  are not congruent, we take  and  where the existence of  is guaranteed by the assumption that . Since it is possible to construct an algebra and corresponding valuation  such that neither  nor .
\end{proof}

The argument for completeness is exactly the same as in the previous section, except that we use the lemmas proven in this section.
\begin{thm}
If  then for closed terms  and ,

\end{thm}

Look at the following proposition to understand what happens when there is only one atomic proposition i.e., .
\begin{prop}\label{prop one}
If  then for all ,  and for all , ,

\end{prop}
\begin{proof}
Proof by induction on . If  is either  or  then  follows immediately.

Suppose  then we proceed by induction on . If  is either  or  then it is trivial. If  then

If  then

Hence,  for all  and .

Suppose . Then

\end{proof}
This proposition implies for example that

In fact, Proposition \ref{prop one} implies that for  we lose any kind of reactive behaviour, and we end up with static valuations. Furthermore, this proposition is clearly true for every variety in which all valuations are repetition-proof i.e., where  is true. Hence, we have the following corollary.
\begin{cor}\label{cor one}
If  and the valuations in variety  satisfy the equation  then

for all closed terms  and .
\end{cor}
This result will also be helpful in establishing completeness for the variety with contractive valuations.

\section{Contractive valuations}
Recall that the variety with contractive valuations is characterized by the following two equations:

The first equation should be familiar since we encountered it in the previous section in the characterization of repetition-proof valuations. The second equation tells us that valuations remain constant through multiple -derivatives. Consider the following example,

In the first two steps we expand the expression using the standard free reactive semantics. In the third step we replace  with  using the definition of contractive valuations. Similarly, as in the example given in the section on repetition valuations we can eliminate the case where the example is equal to  because  must be equal to .

By looking at the definition it becomes immediately apparent that the variety with contractive valuations is a subvariety of the variety with repetition-proof valuations i.e., if  then , and similarly if  then . Of course both varieties are subvarieties of the variety with free reactive valuations. This relation between the different varieties was previously also stated in Proposition \ref{variety relation prop}.

-Congruence is axiomatized by CP and the following axiom schemas.

The entire axiomatization is called . The axioms of \CPcr1 and \CPcr2 allow us to eliminate consecutive atomic propositions in our terms. So for example the terms  and  are provably equal. This is of course a stronger version of what we have seen in the previous section, which should not come as a surprise considering that this variety is defined in terms of the repetition-proof variety.



The following two sections show soundness and completeness for this variety.

\subsection{Soundness}
\begin{thm}
For closed terms  and ,

\end{thm}
\begin{proof}
Since the variety with contractive valuations is a subvariety of the variety with free reactive valuations it suffices to show soundness for  and . Let algebra  and valuation  be given.



By Proposition \ref{equiv congr prop}, CPcr1 is sound. The proof of soundness for CPcr2 is similar to that of CPcr1.



Hence, CPcr2 is sound.
\end{proof}

\subsection{Completeness}
As we are working with a new variety we are required to define a new set of basic forms. Otherwise syntactic equality and -congruence will not coincide.
\begin{defn}
The set of contractive basic forms is the smallest set  such that  and if  then for all 
\begin{itemize}
\item if  and  then 
\item if  and  then 
\item if  and  then 
\item if  and  then 
\end{itemize}
\end{defn}
This definition differs from the one for repetition-proof basic forms. For example,  is a valid repetition-proof basic form but it is not a contractive basic form. In fact,  is a subset of .
\begin{prop}

\end{prop}
\begin{proof}
Let . Then by structural induction on  we show that . If , it follow immediately that .

Suppose . By definition, . Hence, by I.H., it follows that . By definition of contractive basic forms,  and . Consequently, .
\end{proof}

The following lemma shows that the set  is indeed the set of basic forms we want.
\begin{lem}
For each closed term  there exists a term  such
that .
\end{lem}
\begin{proof}
By structural induction on . We can assume that  because Lemma \ref{basic form theorem} is applicable.

If  is  or  then . Suppose  is . By the induction hypothesis,
there exists terms  such that 
and . Now suppose that  and . Consequently,

By definition of  we have .

Using similar reasoning we can show that there exists such a term
 for the remaining three cases:
\begin{itemize}
\item  and 
\item  and 
\item  and 
\end{itemize}
\end{proof}
The following two lemmas are needed for proving completeness for all closed terms.
\begin{lem}
For ,

\end{lem}
\begin{proof}
We use a similar proof as the one for Lemma \ref{inv congr lemma}. Note that the problems that occurred in the variety with repetition-proof valuations from having either  or  cannot occur here by construction of the contractive basic forms i.e., if either  or  are syntactically equal to those terms then  would not be true.
\end{proof}
\begin{lem}\label{cr completeness lemma}
For  and ,

\end{lem}
\begin{proof}
We use a similar proof as the one for Lemma \ref{rp completeness lemma}.
\end{proof} 
Similar to the previous varieties, now that we have proven these lemmas, completeness for all closed terms follows.
\begin{thm}
If  then for closed terms  and ,

\end{thm}
By definition there is at least on atomic proposition. In the section on repetition-proof valuation we proved Corollary \ref{cor one}. Clearly, this corollary also applies for this variety because  is also true in this variety. Hence, if , contractive congruence  coincides with static congruence .


\section{Static valuations}
Static valuations correspond with classical propositional logic. As such the value of atomic propositions does not depend on other atomic propositions.

-Congruence is axiomatized by CP and the following two axioms, due to Hoare in \cite{hoare}:

The first axiom \CPstat{} tells us that the value of atomic propositions remain the same despite their relative position in the term. The second axiom \CPcontr{} is a generalization of the axioms for contractive valuations in the previous section i.e., this axiom allows contraction of not only atomic propositions but also for terms in general. We call the axiomatization of -congruence .

The symmetric versions of the aforementioned axioms, listed below, follow from .

The key in deriving  and  is the equality  which we proved in the free reactive valuation section. For example,

One can prove  using the same technique.

Looking at the axiomatization it might not be immediately clear that this variety corresponds to classical propositional logic. One of the major differences between classical propositional logic and the varieties we have studied in the previous sections is the fact that the values of atomic propositions in a given term do not change depending on where they occur in the term. The following equality illustrates that the variety with static valuations also has this property.

So appending an arbitrary term before  will not change the value of . In the next subsection we will prove its semantical counterpart.

In the following subsections we show soundness and completeness for the static valuations, and examine the relation between static valuations and boolean algebras.

\subsection{Soundness}
In contrast to the previous sections we cannot immediately start proving soundness but first need the following lemma which will not only be useful for proving soundness for this variety but also provides some additional insight to the correspondence between this logic and classical logic. It is worth noting that although this lemma can be viewed as a generalization of the way this variety is defined i.e., , it in fact follows from the definition.
\begin{lem}\label{static gen lemma}
For all ,  and for all , ,

\end{lem}
\begin{proof}
Proof by structural induction on . If  or  then  is trivially true. 

Suppose  for . Then proceed by induction on . If  or  then  is trivially true. If  for . Then

Suppose . Then

This concludes the case for .

Suppose . Then

\end{proof}
The previous lemma shows that the valuation of terms is independent of the context in which they appear. It is directly related to the equality  which we derived in the introduction to this section, in that it similarly illustrates that the value of the atomic propositions is not dependent on what other atomic propositions might have occurred during the valuation of a term, and consequently it cannot change during the valuation.

In the previously observed varieties there is a clear distinction between equivalence and congruence. This difference was proven by using the example where  but  for  because . However, as the previous lemma shows we cannot apply this example for the static valuations. In fact the following lemma shows that in this variety equivalence and congruence coincide.
\begin{lem}\label{equiv congr lem}
For closed terms  and ,

\end{lem}
\begin{proof}
Congruence is by definition an equivalence. So it will suffice to show that the equivalence  also has the congruence property. Suppose , , and . Then

At both the *-marked steps in the derivation we apply Lemma \ref{static gen lemma}.
\end{proof}
Note that the application of Lemma \ref{static gen lemma} in the previous proof is necessary because otherwise  and  can only be replaced by  and  at which point the expression cannot be further reduced. So this line of reasoning will not work for the other varieties where we do not have this lemma. 

Now that we have proven these lemmas, soundness is relatively easy.
\begin{thm}
For closed terms  and ,

\end{thm}
\begin{proof}
By Lemma \ref{equiv congr lem}, we only need to show that

It suffices to show soundness for only  and . Take note of the frequent use of Lemma \ref{static gen lemma} in the derivations below.


Thus CPstat and CPcontr are sound. Soundness of the rest of the axioms follows by the soundness of the variety with free reactive valuations.
\end{proof}

\subsection{Completeness}
Proving completeness follows the same strategy as we have seen before i.e., we define basic forms, and prove completeness for the basic forms. However, the individual lemmas will differ significantly from what we have seen up to this point because the construction of the static basic forms is more complicated.  

In order to define the static basic forms, we first need to enumerate the members of :

Recall that a basic form i.e., a member of \BF, corresponds to a labeled binary tree. A static basic form is a member of \BF, and is a full binary tree with  levels. At level  only atomic proposition  occurs, and at level  at each leaf there is either a  or . The resulting tree is pictured below:

So an atomic proposition  occurs  times and there are  leaves. The set of static basic forms is called . 

The following two lemmas are needed to prove that there exists a static basic form for each closed term.
\begin{lem}\label{red lemma}
For  and , there exists a term  such that

\end{lem}
\begin{proof}
We proceed by induction on the number of atomic propositions. Note that since  it follows that  and  with .

If  then , and

(*) is obtained by applying \CPcontr. Since  is a static basic form, we have shown the existence of .

Suppose  and  (if  apply  and ). Then

Next take the left consequent,

where , , and both  and  are static basic forms given the set of atomic propositions  (but otherwise the same enumeration). Note that since , we could use the I.H. in the above derivation. 

We can apply the same argument for the right consequent  and obtain  and  such that they are static basic forms for this set, and  and . Consequently,

Clearly, the term  is a static basic form for the set .
\end{proof}

The rest of this section resembles the previous sections. So we start by showing that there is a static basic form for each closed term.
\begin{thm}
For each term closed term  there exists a  such
that 

\end{thm}
\begin{proof}
By structural induction on . Since we already know that there exists a provably equal basic form for each closed term  (as opposed to a static basic form), we can assume  is a basic form. If  then simply construct a static basic forms where all the leaves are either  or .
Suppose . By I.H. there exist  such that  and . Then by the previous lemma we know  exists.
\end{proof}
Next we show that for static basic forms the congruence  coincides with syntactic equality.
\begin{lem}
For static basic forms  and ,

\end{lem}
\begin{proof}
Since one direction is trivial, it suffices to prove that  implies . Assume  for static basic forms  and . By definition of static basic forms, it follows that there is at least one leaf that differs in value for  and . For example the leftmost leaf for  has value  and the leftmost leaf for  has value . It is then trivial to construct a static valuation  such that . In the example we just mentioned this valuation would assign true to all atomic propositions. Since there is a valuation  such that , it follows that . Hence, .
\end{proof}
Using the same reasoning as in the previous sections we obtain completeness for all closed terms.
\begin{thm}
For closed terms  and ,

\end{thm}

\chapter{-Completeness}
In this chapter we discuss -completeness of the different axiomatizations we encountered thus far. The following definition of -completeness is taken from \cite{fokkink}.
\begin{defn}
An axiomatization  over a signature  is -complete if an equation  with  can be derived from  if  can be derived from  for all closed substitutions .
\end{defn}
The set  is the set of all terms over signature . -Completeness is also know as \emph{inductive completeness} since we do not need an additional induction theorem to prove that  can be derived if  can be derived for all closed substitutions .

An example of an axiomatization that is not -complete is the following axiomatization of the natural numbers with addition and multiplication, taken from \cite{omega_bergstra}:

In this axiomatization every closed instance of e.g.,  can be derived. However, the theorem itself cannot be derived from the above axioms.

See \cite{omega} for a more thorough introduction to -completeness.

\section{-Completeness of CP}

We begin with proving -completeness for CP. First, however, it is necessary to distinguish between a few unique cases based on the number of elements in the set  of atomic propositions. As it turns out CP is not -complete for .

If the set  is empty, and there are no atomic propositions, it follows that every closed closed substitution  replaces the variables by terms build up from ,  and . Using axioms CP1 and CP2, this is the same as replacing the variables by either  or . If we now consider the equation , we see that for every closed substitution ,  follows from CP1 and CP2. However,  cannot be derived from CP. If it could be derived then it could also be derived in the case where  because the derivations are independent of the number of atomic propositions in . So if this is the case then by soundness , which is clearly not true.

Similarly, when there is only one atomic proposition i.e., , we take the equation . For every closed substitution , , where we can assume without loss of generality that  replaces variables either by ,  or a sequence of 's i.e., .  However, .

Therefore, in the remainder of the discussion of -completeness for CP, we assume that  has at least two atomic propositions, usually referred to as  and .

Similar to the sections where we showed completeness for the various varieties, we define a set of basic forms. However, this time the basic forms can also be open terms.
\begin{defn}\label{open basic form def}
Let the set of open basic forms  be the smallest set such that , and if  then  for all  and  for all .
\end{defn}
The set  is the set of variables. The terminology ``open basic form'' is a bit misleading because an open basic form can possibly be a closed term. This definition differs from the one for the set of closed basic forms \BF{} in that terms of the form  are also included. In addition, observe that if we substitute all the variables by atomic propositions in an arbitrary open basic form, the resulting term will be a member of \BF.

\begin{lem}\label{open basic form lem}
For all terms  there exists an open basic form  such that .
\end{lem}
\begin{proof}
Proof by structural induction, very similar to the proof of Theorem \ref{basic form theorem}.
\end{proof}

The following lemma tells us that when dealing with open basic forms, it suffices to use closed substitutions that map variables to atomic propositions instead of arbitrary closed terms.

\begin{lem}\label{substitution lemma}
For open basic forms  and , if for all closed substitutions ,\footnote{Note that with the notation  we do not imply that this substitution only works on variables but that the substitution replaces the variables in a term with members of .}

Then for all closed substitutions ,

\end{lem}
\begin{proof}
Assume there exists a closed substitution  such that  for open basic forms  and . We prove by induction on  and  that there exists a closed substitution  such that . We omit the cases where both  and  are closed terms, which are trivial, and the cases that follow by symmetry.

Suppose  and  or . Let  be the substitution that maps all variables to atomic proposition . Then , and clearly . By Lemma \ref{completeness lemma}, .

Suppose  and . Then it is trivial to see that no matter what closed substitution  we choose, . Similarly, we can reduce the case where  and , to this case by letting  and . Furthermore, the same argument can be used when one of the terms starts with a variable and the other with an atomic proposition.

Suppose  and . Since , we can assume without loss of generality that . By the induction hypothesis, it follows that there exists a closed substitution  such that . Consequently, by Lemma \ref{inv congr lemma}, . We can use the same argument for  and .
\end{proof}

Note that this lemma is trivially true when . The above lemma cannot be proven for . Take for example,

where we assume that . Then the only closed substitution  is the one that maps all variables to . Hence , and thus . However, if we pick closed substitution  such that , then clearly .

\begin{lem}\label{omega lem}
For open basic forms  and , if for all closed substitutions ,  then .
\end{lem}
\begin{proof}
We prove the contraposition i.e., given that  we show that there exists a closed substitution  such that . Note that if  and  are closed terms then , the set of closed basic forms. Since we already showed in Lemma \ref{completeness lemma} that for terms in \BF{} -congruence and syntactical equality coincide, we are done. We proceed by induction on  and , omitting the cases that follow by symmetry.

Suppose one of the following cases,
\begin{itemize}
\item  and 
\item  and 
\item  and 
\item  and 
\item  and 
\end{itemize}
Let  be a closed substitution such that  and . Regardless of which case we pick, it follows that . Furthermore, . Consequently,  by Lemma \ref{completeness lemma}.

Suppose  and . Since , we can assume without loss of generality that . By the induction hypothesis, there exists a closed substitution  such that . Consequently, by Lemma \ref{substitution lemma}, there exists a closed substitution  such that . Hence, by Lemma \ref{inv congr lemma}, . Using a similar argument, we can prove this for  and .
\end{proof}

The following theorem shows that CP is -complete.

\begin{thm}
Let  and  be open terms such that for all closed substitutions , , then .
\end{thm}
\begin{proof}
Assume that . By Lemma \ref{open basic form lem}, there exist open basic forms  and  such that . Hence, . By soundness, it follows that . Consequently, by Lemma \ref{omega lem}, , and thus . It follows that .
\end{proof}

We were not able to prove -completeness for  and . Instead we note that using the same examples as before, it follows that both  and  are not -complete for . Furthermore, proving -completeness for the case  suggests that we adjust the set of open basic forms accordingly and then prove the same lemmas as before only this time using the altered set of open basic forms. 

\section{-Completeness of }

The proof of -completeness for the axiomatization  is quite different from the previous proof. We will use a back-and-forth translation between  and an axiomatization of boolean algebra of which we know that it is -complete, to show -completeness of .

In \cite{omega_bergstra} a proof of -completeness for the axiomatization of an -valued Post algebra is given. If we take  the axiomatization is that of a Boolean algebra. We obtain the following axiomatization by taking , and removing some of the redundant axioms.

We call this axiomatization BA. The signature of BA consists of , , ,  and . Expanding the signature with a set of atomic propositions  does not affect the -completeness of this axiomatization. We call the resulting signature . We use the following two translations between  and , starting with the translation of  to .

Note that  which is perhaps more intuitive. The translation from  to  looks as follows.

Note that these are translations over all terms including open terms. The next two lemmas show that the translations are sound i.e., if two terms are provably equal in either  or BA then their respective translations are also provably equal.
\begin{lem}\label{CPst in BA lem}
For all terms  and ,

\end{lem}
\begin{proof}
It suffices to show that the translations of axioms CP1-4, CPstat and CPcontr can be derived in BA.

Using a truth table we can check that the translations of CP4, CPstat and CPcontr are correct because BA is both sound and complete.
\end{proof}
\begin{lem}\label{BA in CPst lem}
For all terms  and ,

\end{lem}
\begin{proof}
We just need to check that the translations of axioms of BA are derivable in . We omit the trivial derivations.



\end{proof}

The following two lemmas show that the translations are invariant for each logic i.e., if a term  is translated first to one logic and then back to the original it is still provably equal to .
\begin{lem}\label{trans invariance CPst lem}
For all terms , 

\end{lem}
\begin{proof}
Proof by structural induction on . If  then it is trivially true. Suppose . By the induction hypothesis, it follows that

Then

\end{proof}

\begin{lem}\label{trans invariance BA lem}
For all terms , 

\end{lem}
\begin{proof}
Proof by structural induction on . If  then it is trivially true. Suppose . Then

Suppose . Then

Suppose . Then

\end{proof}

The last lemma before proving -completeness of  is a variation of Lemma \ref{substitution lemma}.
\begin{lem}\label{trans subst lem}
If for all closed substitutions ,

Then for all closed substitutions ,

\end{lem}
\begin{proof}
Assume that  with  closed substitutions. Let . Since for all , , it follows that . Hence,

Let  be a closed substitution. Furthermore, define  to be the substitution such that  for all . By Lemma \ref{trans invariance BA lem}, it follows that  for all . Hence,  and . Consequently, by (*),

Thus, .
\end{proof}
Having done the groundwork, it is now possible to prove that  is -complete.
\begin{thm}
Let  and  be terms over  such that for all closed substitutions , , then .
\end{thm}
\begin{proof}
Assume that

where  is closed. By Lemma \ref{CPst in BA lem},

By Lemma \ref{trans subst lem},

where  is closed. By -completeness of BA,

By Lemma \ref{BA in CPst lem},

By Lemma \ref{trans invariance CPst lem}

\end{proof}

In this chapter we have shown -completeness for  and . -Completeness of the remaining two axiomatizations,  and , remains an open issue with the exception of the case where there are less than two atomic propositions in which neither ,  nor  are -complete.

\chapter{Independence of the axioms}
In this chapter we prove that the axioms are independent from each other. An axiom is independent with respect to a set of axioms if it cannot be derived from the other axioms e.g., \CP1 is independent in CP if . This is a nice property for a set of axioms to have, as it shows that there are no redundant axioms.

The standard strategy for proving that an axiom is independent consists of constructing a model such that every axiom except the one we are trying to prove independence for, is true in this model. In other words, if we want to prove that CP1 is independent in CP, we show there is a model  and interpretation  such that
\begin{itemize}
\item[(1)]  implies that 
\item[(2)] 
\end{itemize}
Hence, by contraposition of (1) it follows that . Note that this only applies if  is a model of equational logic i.e., reflexivity, symmetry, transitivity and congruence are all true in .

In the following sections independence of axioms is shown for the different varieties of RVAs.

\section{Independence of CP}
Recall that -congruence is axiomatized by the axioms in CP, listed here again for the reader's convenience:

We start by proving independence of \CP1. In order to do this we need to construct a model such that \CP2, \CP3 and \CP4 are true in this model but \CP1 is not. Take a look at the following model:

for all  with  as in sentential logic and as domain . Observe that this is a model of equational logic, in particular congruence is true. The next step in proving independence for \CP1 is to show that \CP1 does not hold under this interpretation. We do this by giving a counterexample i.e., we take a specific instantiation of this axiom and show that the left-hand and the right-hand side of \CP1 are not equal. If CP1 were true in this model then . However, , and hence unequal to . Therefore, CP1 does not hold in this model. Now we have to check whether CP2-4 do hold:

Since CP2-4 are true in this model but CP1 is not, we can conclude that CP1 is independent with respect to CP.

Proving independence for the remaining axioms requires that we repeat these steps for each axiom. So let us continue with proving independence of axiom \CP2. This time we construct a model such that it models \CP1, \CP3 and \CP4 but not \CP2.

for all . Then we check whether \CP2 does not hold. Since , this is true. It is easy to see that \CP1 and \CP3 are true in this model. That leaves us with checking \CP4:

So \CP4 also holds under this interpretation, and thus we know that \CP2 is independent.

The previous two models looked quite similar, in particular the models share the same domain i.e., . In proving the independence of \CP3 we will show that this is not always the case. The model we will be constructing here has a finite set of natural numbers as domain, and as a result differs quite a bit from the standard semantics.

The construction of this model requires that we first enumerate the atomic propositions in the set :

Using this enumeration we can define our model: 

Note that congruence is trivially true in this model. By definition there is at least one atomic proposition i.e., . So, we can always assume that  exists. Observe that . Hence, \CP3 does not follow. Checking to see that \CP1 and \CP2 are true is trivial. That leaves \CP4:

So \CP3 is also independent.

Let . Take the following interpretation:

Clearly, congruence and CP1-3 are true in this model. Furthermore, it follows that . Hence,

However,

So CP4 is not true using this interpretation. Hence axiom CP4 is also independent with respect to CP. Since this is the last axiom in CP, we have now shown independence for all the axioms in CP. Consequently, there are no redundant axioms in CP. In the next section we will be looking at an extension of CP i.e., the axiomatization of -congruence.

\section{Independence of }
The axiomatization of -congruence is an extension of CP with the following axioms:

Note that these are actually axiom schemes i.e., for each  we have an axiom CPrp1 and CPrp2. Since we have a new set of axioms, we are required, in addition to proving the independence of the two new axioms \CPrp1 and \CPrp2, to prove that CP1-4 is independent with respect to this new set of axioms. Fortunately, it is possible to reuse the models used in the previous section i.e., for the cases CP1-4 the same models are taken. It then suffices for these cases to show that \CPrp1 and \CPrp2 are true in these models.

We start by taking the same model as we did in the previous section for proving the independence of axiom \CP1, and then checking if it models \CPrp1 and \CPrp2.


Repeat this procedure for the models given for the independence-models of \CP2, \CP3 and \CP4.


We only show that \CPrp1 holds in the model given for case \CP3 because the proof that \CPrp2 is true in this model is symmetric to that of \CPrp1.


The following shows that CP4 is also independent in .


The model for showing independence of CPrp1 is based on the reactive valuation variety that satisfies

We call this variety . By definition, this is a subvariety of the variety with free reactive valuations. Thus, by soundness of free reactive valuations, it follows that the resulting congruence  (constructed similarly as , , etc.) is a model for CP. Hence, we do not have to check whether CP1-4 are true in this model.

If , it is possible that  for some  and . Consequently,

Thus, CPrp1 is not true. However, CPrp2 is.


Note that both  and  is impossible. Hence, we can replace  with  in the above derivation.

The proof for showing independence of CPrp2 is symmetric to the one in CPrp1, using the reactive valuation variety that satisfies

We call this variety  and we will use this variety in the next section.

\section{Independence of }
The axiomatization of -congruence consists of CP and the following axioms

Like in the previous section, it is possible to reuse the models given for CP, and just show that \CPcr1 and \CPcr2 are true in these models. Starting with \CP1:

For \CP2:


Similar to the previous section we omit the proof that \CPcr2 is true in the independence-model for \CP3 as it is symmetric to that of \CPcr1.


Unfortunately, we have not been able to find a model that demonstrates the independence of CP4 in . The model we used in previous sections does not work in this variety. For example, we have the following.

Hence, CPcr1 is not true in the resulting model, and thus  does not suffice. The question whether CP4 is independent in  remains therefore open.

In order to construct the model that shows independence of CPcr1, we take the variety of all algebras from variety  that satisfy

for all . We call this variety . It follows that there is an  and  such that 

Checking CPcr2:



A proof of independence for CPcr2, starts by taking the variety of all algebras from variety  (see previous section) that satisfy

for . The proof for showing independence of CPcr2 using this variety is symmetric to the previous proof of independence for CPcr1.

\section{Independence of }
In this section we show independence of the axioms CP2, CP3, CPstat and CPcontr.

The models we used in the previous sections to show independence of CP1 and CP4 cannot be used here because CPstat and CPcontr are not both true in these models. We give two counterexamples to show this. The first counterexample shows that CPstat is not true in the independence-model for CP1. By CPstat the terms  and  should be equal. However, this is not the case.
 

The second counterexample shows that CPcontr is not true in the model we used for showing independence of CP4.

Proving independence for both CP1 and CP4 in  remains an open issue.

We can use the same models we used in the previous section for showing independence of CP2 and CP3.




Showing independence of CPstat requires that we define the following subvariety of  which consists of all RVAs that satisfy

and

Note that this is a generalization of the variety . We show that CPstat is not true in this variety by constructing an algebra  and valuation  such that , ,  and . Then

Hence, CPstat is not true. Since this is a subvariety of , by Theorem \ref{soundness cp} it suffices to prove that CPcontr is true in this model.

So by Proposition \ref{equiv congr prop} CPcontr is true in this model. Since CP and CPcontr are true and CPstat is not, it follows that CPstat is independent in .

The model that shows independence of CPcontr has the integers as its domain. Similar to the independence-model for CP3, we assume that the set  is enumerated i.e., .

CPcontr is not true in this model:


The following derivations show that this is a model for CP1-4 and CPstat. The first three derivations are easy.





Checking whether CP4 and CPstat are true in this model requires some bookkeeping.



Since CP and CPstat are true in the model and CPcontr is not, CPcontr is independent.



\chapter{Conclusion}
In this final chapter we give a short summary of the previous chapters, thereby listing some of the main results. Furthermore, we discuss the open issues mentioned in the previous chapters, and finally give some suggestions for future work.

\section{Summary}
Sentential logic is limited by the static behaviour of its valuations. In Chapter~1 we introduced the reader to reactive valuations. These reactive valuations, first defined by Bergstra and Ponse in \cite{main}, are an extension of normal valuations because they allow us to take the evaluation order of the expression into account. By means of a few examples we illustrated the advantages of using reactive valuations instead of normal valuations. Similarly, we also revealed some of the limitations of using reactive valuations. At the end of the introduction section, we showed that it is possible to define several classes of reactive valuations depending on their behaviour.

As motivation for looking at reactive valuations we argued that these are interesting because they can be used to model a variety of sequential processes. In the section on motivation we provided a few examples of sequential behaviour from e.g. computer science and linguistics.

Since reactive valuations are a recent invention by Berstra and Ponse, there is no directly related work on reactive valuations, besides the main paper \cite{main}. We, therefore, opted to list some broad areas which might pertain to reactive valuations e.g., non-monotonic reasoning, program semantics and many-valued logics, thereby giving a few specific examples. 

In Chapter~2 we defined the axiomatization of reactive valuation congruence, called CP, and its semantics. The underlying semantics consists of several parts. In the first part we described reactive valuation algebras (RVAs). In the second part we showed how we can compute the value of closed term , given an RVA  and reactive valuation . The value is denoted as . By imposing limitations on the RVAs and their valuations we can define several varieties of RVAs, namely the varieties with free reactive valuations, repetition-proof valuations, contractive valuations and static valuations. The signature of all these varieties is the same, and consists of constants  and , an infinite set of variables, a finite set of atomic proposition symbols and the ternary operator  denoting conditional composition. Each variety has its own axiomatization, where the axiomatization CP corresponds to the variety with free reactive valuations. Given a variety , we say two closed terms  and  are -equivalent if  for RVAs  and valuations . Unfortunately, -equivalence does not necessarily have the congruence property. We, therefore, define -congruence as the largest congruence contained in the -equivalence relation. 

With the aim of showing soundness for the various varieties it sufficed to show that each axiom is also true under semantical congruence. So if  is an axiom of variety , we need only show that  and  are -congruent. In these proofs we took advantage of the fact that if an axiom is sound with respect to a variety  then the axiom is also sound in all subvarieties of .

In order to show completeness we introduced basic forms, where each sentence is provably equal to a unique basic form. The main advantage of basic forms is that their syntactic structure is quite simple. Consequently, structural induction on the set of basic forms is relatively easy. By showing that for basic forms syntactical equality and semantic congruence coincide we were able to prove completeness. Each variety requires its own set of basic forms.

Given an axiomatization, if for all closed substitutions  and terms  and  we can derive , we can also derive , we say that this axiomatization is -complete. In Chapter~3 we discussed -completeness of CP and , the axiomatization of -congruence.

Similar to the completeness proofs in Chapter~2, we defined a special set of terms, namely the set of open basic forms. As opposed to the various sets of basic forms used to prove completeness, the open basic forms may contain variables. Using these open basic forms we were able to prove -completeness for CP.

For , we used a different approach. This approach does not rely on a set of open basic forms but on a translation between  and a specification of boolean algebra for which we know that it is -complete. Using this translation we show that the -completeness property transfers to . We did not show -completeness for the other varieties.

Independence of an axiom with respect to a particular axiomatization entails that the axiom is not redundant in that set of axioms i.e., it is not derivable from the other axioms. In Chapter~4 we showed independence of axioms with respect to the various axiomatizations. Showing that an axiom  is independent of a set  of other axioms requires that we construct a model such that  is not true in this model but the axioms in  are. There were a few axioms for which we did not succeed in proving that they were independent e.g., CP4 for contractive valuations.

\section{Open issues and future work}
In the past chapters several specific open issues were mentioned. We will list and discuss these issues in this section. Afterwards, we give some general suggestions for future work on the subject of reactive valuations.

\subsection{Open issues}

The first set of open issues is mentioned in the chapter on -completeness. We were not able to establish -completeness for  and . In Chapter~3 we showed -completeness for CP and  using two different methods.

The method we used for  involved a translation between an equivalent -complete axiomatization and . Unfortunately, this will not work for  and  because finding an equivalent -complete axiomatization for these axiomatizations is unlikely.

Consequently, the best approach seems to be the one we used for CP, where we used open basic forms. However, first attempts at using this method failed to yield a positive result. The open basic forms as defined in Definition \ref{open basic form def} have the nice property that if we substitute each variable in an open basic form with an atomic proposition we end up with a closed basic form i.e., a member of \BF\ (see Definition \ref{basic form def}). We use this property and the results we already have for \BF\ in the lemmas leading up to the -completeness theorem. The problems arise when we define similar open basic forms for  and . For example, take the term

At first glance this seems like an excellent candidate for the set of open basic forms of both  and . However, if we substitute the  with atomic proposition , the resulting term is neither a member of  nor of . Whether it is possible to work around this problem remains to be seen. Additional tools for proving -completeness can be found in \cite{omega}.

The second set of open issues concerns the independence of axioms. We failed to show independence of CP4 in . For the axiomatization  we only showed independence of CP2, CP3, CPstat and CPcontr, which leaves CP1 and CP4.

We showed the independence of an axiom with respect to a particular axiomatization by constructing a model such that the axiom in question is not true but the rest of the axioms in the axiomatization are. Constructing such a model is regrettably a hit-or-miss affair and becomes increasingly more difficult as the number of axioms multiply. We can, however, eliminate some options. In Chapter~3 we used roughly three methods of model constructions. 

The first method involves using normal valuations as we know them from sentential logic. The constants  and  are mapped to \emph{true} and \emph{false}, and similarly the atomic propositions are mapped to either \emph{true} or \emph{false}. Conditional composition is interpreted using a combination of connectives, thereby ignoring evaluation order, e.g.,  is mapped to . We used such a method to prove that CP1 and CP2 are independent with respect to CP. Since there are only a small finite number of interpretations of conditional composition it is easy to check them all. We, therefore, wrote a small Prolog program that checks these interpretations given a set of axioms to model and the one it should not model. There were no interpretations that proved the independence of the aforementioned axioms.

The second method relies on constructing a variety of RVAs. We used this method to show independence of e.g. CPcr1 and CPcr2. The problem is that such a variety is by definition a subvariety of . Since we proved that the axioms in CP are sound in  (see Theorem \ref{soundness cp}), they are sound in all subvarieties of . The axioms for which we need to prove independence are all in CP, and therefore this method will fail automatically.

This leaves us with the third option of constructing an interpretation in the natural numbers with the usual operations of addition and multiplication. Whether or not this method will work remains an open question. Of course, there are many other possibilities that are not listed here e.g. an interpretation in an n-valued model that takes the evaluation history into account.

\subsection{Future work}
In Chapter~1 we discussed some possible application areas for reactive valuations. However, we did not go into great detail as to the specifics of such applications, and more importantly what is to be gained by the use of reactive valuations. This search for specific applications might also yield new and interesting varieties of RVAs. 

Chapter~1 also contained a discussion on related work in which we mentioned that besides the main reference \cite{main} there is no related work directly pertaining to reactive valuations. We, therefore, listed some areas of interest with possible connections to reactive valuations. These and other areas warrant a more in-depth study, which may involve translations between varieties and other logics. For example, in Chapter~3 we showed a translation between the variety with static valuations and boolean algebra.

Proposition \ref{equiv congr prop} was, despite its apparent simplicity and usefulness, discovered towards the end of writing this thesis. This proposition which given variety  describes the relationship between -equivalence and -congruence, is used extensively in the various soundness proofs throughout this thesis. We, however, have not yet fully taken advantage of this proposition in proving completeness. We feel that this proposition will in all likelihood simplify the proofs of some of the crucial lemmas we need for completeness.

Furthermore, we used basic forms to prove completeness. Alternatively, we can define a term rewriting system with convenient normal forms for each variety, and use that to prove completeness. In Appendix B we give an example of such a term rewriting system. 

In this thesis we gave some suggestions for future research. Of course, these suggestions are not exhaustive as there are many other options for further research not mentioned here e.g., results in expressivity and complexity.

On a final note, during the writing of this thesis a new paper on reactive valuations by Bergstra and Ponse appeared\footnote{In fact the main reference \cite{main} was a prior draft for this paper.}, see \cite{future}, which would be a fitting starting point for any future research.

\appendix

\chapter{Characterization of CP+CP5}

\section{Non-replicating valuations}
In this appendix we define an additional variety, which uses non-replicating valuations. It is axiomatized by CP plus the CP5 axiom,

The CP5 axiom is taken from the appendix of \cite{main}. In that appendix Bergstra and Ponse show that the symmetric version of this axiom can be derived from CP+CP5:

with .

The variety of RVAs with non-replicating valuations consists of all RVAs that satisfy the
equations:

and

for all  and . We call this variety .

The following lemmas show that the above equations imply their more general versions. Note that the  in the next lemma ranges over all closed terms not just .

\begin{lem}\label{char lem one}
For all closed terms ,

\end{lem}
\begin{proof} By structural induction on :
\begin{itemize}
\item If  then  follows directly from the definition of .
\item Suppose . Then

\end{itemize}
\end{proof}

\begin{lem}\label{char lem two}
For all closed terms  and ,

\end{lem}
\begin{proof}
By structural induction on :
\begin{itemize}
\item The case for  or  is trivial because  and
 for any valuation .
\item Suppose  for . Then by structural induction on .
\begin{itemize}
\item The case for  follows directly from
the definition of variety .
\item Suppose . Then

In the second step of this derivation Lemma \ref{char lem
one} is applied i.e., we substitute  with .
\end{itemize}
\item Suppose . Then

Note that sequential composition  is defined in Chapter~2, and .
\end{itemize}
\end{proof}

\begin{lem}\label{char lem three}
For all closed terms  and ,

\end{lem}
\begin{proof}
By structural induction on :
\begin{itemize}
\item  is  or ; trivial.
\item ; see Lemma \ref{char lem one}.
\item Suppose . Then

Now it is not only possible to apply the induction hypothesis but also
Lemma \ref{char lem two} which will result in a reduction in the
number of cases:

\end{itemize}
\end{proof}

These three lemmas will demonstrate their usefulness in the next section where we will prove soundness.

\section{Soundness}
\begin{thm}
 implies that .
\end{thm}
\begin{proof}
Since the axioms in CP are sound for the variety  of RVAs with free reactive valuations, and  is a subvariety of , it suffices to check CP5:

Now Lemma \ref{char lem two} and Lemma \ref{char lem three} can be
applied:

Furthermore, we have


Hence, by Proposition \ref{equiv congr prop}, CP5 is sound.
\end{proof}





\chapter{Term rewriting system}

\section{Term rewriting for CP}
In this appendix we define a term rewriting system for CP and prove that it is convergent. For more information on term rewriting see \cite{rewriting}. We call the term rewriting system  and it is defined as follows:


In the following lemma we show that  is terminating i.e., all terms can be reduced to a normal form. Note that this in itself does not guarantee that there is a unique normal form for each term.

\begin{lem}
 is terminating.
\end{lem}
\begin{proof}
In order to show that  is terminating, we are required to prove that an infinite derivation  does not exist. First we define the norm on terms as follows

Subsequently, we show that for each rewrite rule the norm of the left-hand side 
is strictly greater than the norm of the right-hand side.

Consequently, if  using these rules, it follows that .

Suppose that there is an infinite rewrite sequence . Then we know that if , . Since the norm is always positive and finite (we do not allow terms with an infinite number of symbols), this sequence must end. Hence, such an infinite rewrite sequence does not exist and  is terminating.
\end{proof}

The following lemma shows that  is locally confluent. If there is a term  mutually derivable from terms  and , we write  and say that  and  are \emph{joinable}. A binary relation  is then \emph{locally confluent} if for all terms ,  and , if  whenever  and .

In order to prove local confluence, we first need to define the concept of critical pair. Let  and  be two rewrite rules with variables renamed such that they do not share variables. Furthermore, let  be the most general unifier of  and a nonvariable subterm  of . A \emph{critical pair} is then the term  combined with the term resulting from replacing  with  in . A critical pair  is joinable if  and  are joinable.

\begin{lem}
 is locally confluent.
\end{lem}
\begin{proof}
 is locally confluent if all its critical pairs are joinable (see Lemma 5.15 in \cite{rewriting}). We first rename the variables in the rules so they are distinct:

Then we identify the critical pairs and check whether they are joinable.

\begin{itemize}

\item Let  be a substitution such that

and the rest of the variables map to themselves e.g.,  and . Then we have the following critical pair

which is joinable


\item Let  be a substitution such that

and the rest of the variables map to themselves. Then we have the following critical pair

which is joinable


\item Let  be a substitution such that

and the rest of the variables map to themselves. Then we have the following critical pair

which is joinable


\item Let  be a substitution such that

and the rest of the variables map to themselves. Then we have the following critical pair

which is joinable.

\item Let  be a substitution such that

and the rest of the variables map to themselves. Then we have the following critical pair

which is joinable.

\item Let  be a substitution such that

and the rest of the variables map to themselves. Then we have the following critical pair

which is joinable


\item The last critical pair requires that we rename the variables in the fourth rule a second time

Let  be a substitution such that

and the rest of the variables map to themselves. Then we have the following critical pair

which is joinable



\end{itemize}
Since every critical pair is joinable, the rewrite system  is locally confluent.
\end{proof}

By Lemma 5.13 (the so called Diamond Lemma, see \cite{newman}) in \cite{rewriting}, a terminating binary relation is Church-Rosser iff it is locally confluent. Hence,  is Church-Rosser. Furthermore, by Theorem 5.4 in \cite{rewriting} a binary relation is confluent iff it is Church-Rosser. Consequently,  is also confluent, which leads us to the final theorem.

\begin{thm}
 is convergent.
\end{thm}
\begin{proof}
By Definition 5.6 in \cite{rewriting}.
\end{proof}

This means that term rewriting system  has unique normal forms. In the next section, we list a program that uses this result to determine whether two terms are provably equal in CP.

\section{Theorem prover for CP}

In this section we list the code of a small theorem prover for CP based on the term-rewriting system  in the previous section. The program is written in Prolog, and has been tested in the \href{http://www.swi-prolog.org}{SWI-Prolog} interpreter.

Within the program we use \verb|1| and \verb|0| to denote  and , respectively. Atomic propositions have the same notation i.e. atomic proposition  is represented by \verb|a|. Conditional composition is represented as a three-place predicate \verb|c(_,_,_)| in which the middle argument is the antecedent and the first and third argument are the left- and right-consequent, respectively. So, for example, the term  is represented by the term \verb|c(a, c(1, b, c), 0)|.

After loading the program in the Prolog interpreter we can check whether two terms are equal as follows:
\begin{verbatim}
-? equals(Term1, Term2).
\end{verbatim}
where you should replace \verb|Term1| and \verb|Term2| with two terms using the notation we just discussed. The \verb|equals| predicate will compute the normal form of each term and determine if they are equal or not.

In the code below we see several other predicates. We now give a short description of each of these predicates.

The \verb|rule| predicate describes the term rewriting rules i.e., in this case the rules of .

The \verb|normal_form(+Term, -NormalForm)| predicate computes the normal form \verb|NormalForm| of the term \verb|Term|.

The \verb|subterm(-Subterm, +Term)| predicate returns a subterm \verb|Subterm| of the term \verb|Term|. 

The \verb|substitute(+Subterm1, +Subterm2, +Term1, -Term2)| predicate replaces all occurrences of \verb|Subterm1| in \verb|Term1| with \verb|Subterm2|, and returns the resulting term as \verb|Term2|.
 
\begin{verbatim}
rule(c(X, 1, _), X).
rule(c(_, 0, Y), Y).
rule(c(1, X, 0), X).
rule(c(X, c(Y, Z, U), V), c(c(X, Y, V), Z, c(X, U, V))).

normal_form(Term, Term) :-
   findall(Subterm, subterm(Subterm, Term), Subterms),
   forall(member(X, Subterms), \+ rule(X, _)).
normal_form(Term1, NormalForm) :-
   subterm(Subterm1, Term1),
   rule(Subterm1, Subterm2),
   substitute(Subterm1, Subterm2, Term1, Term2),
   normal_form(Term2, NormalForm).

subterm(T, T).
subterm(T1, T2) :-
   T2 =.. [_|T],
   member(T3, T),
   subterm(T1, T3).

substitute(Term1, Term2, Term1, Term2) :- !.
substitute(_, _, Term, Term) :-
   Term \= c(_,_,_).
substitute(Term1, Term2, c(X, Y, Z), c(NewX, NewY, NewZ)) :-
   substitute(Term1, Term2, X, NewX),
   substitute(Term1, Term2, Y, NewY),
   substitute(Term1, Term2, Z, NewZ).

equal(Term1, Term2) :-
   normal_form(Term1, NormalForm),
   normal_form(Term2, NormalForm).
\end{verbatim}





\bibliographystyle{plain}
\bibliography{thesis}

\end{document}
