\documentclass{sigplanconf}


\usepackage{latexsym, amssymb, amsmath, amsfonts,amsthm,stmaryrd}
\usepackage{graphicx}
\usepackage{semantic}


\newcommand{\draftnote}[2][{}]{#1 \marginpar
{\small
\raggedright
\textsf{\hspace*{-1.6ex}#2} }}



\newcommand{\signedcomment}[3]{\draftnote[]{{\color{#2} \small [#1] #3}} }


\newcommand{\ds}[1]{\signedcomment{DS}{blue}{#1}} \newcommand{\he}[1]{\signedcomment{HE}{magenta}{#1}}


\newcommand{\fadetext}[1]{{\color{gray}[#1]}}

\newcommand{\protectedTable}{\setName{ProtectedTable}}
\newcommand{\protectedEnvironment}{\setName{ProtectedEnv}}




\newcommand{\mySim}[3] { \relation{#1} \sim \relation{#2} }
\newcommand{\pset}{\mathcal{P}}

\newcommand{\eqdef}{\mathrel{\stackrel{{\scriptscriptstyle\mathrm{def}}}{=}}}

\DeclareMathAlphabet{\mathsc}{OT1}{cmr}{m}{sc}

	

\newcommand{\proofcase}[2][Case]{\noindent  
 \raisebox{2ex}{\mbox{}} \textbf{#1: #2}.~~}

\newcommand{\Implies}{\Longrightarrow}
\newcommand{\isimpliedby}{\Leftarrow}
\newcommand{\Iff}{\Longleftrightarrow}

\newcommand{\AND}{\wedge}
\newcommand{\OR}{\vee}

\newcommand{\ForAll}[2]
           {\forall #1 .\,#2}
\newcommand{\Exists}[2]
           {\exists #1 .\,#2}
\newcommand{\Nat}{\mathbb{N}}
\newcommand{\Real}{\mathbb{R}}

\newcommand{\RangeS}{S}

\newcommand{\Set}[1]{ \{ #1 \} }
\newcommand{\SetDef}[2]{ \{ #1 \; | \; #2 \} }
\newcommand{\Union}{\cup}

\newcommand{\relation}[1]{#1}\newcommand{\set}[1]{#1} 

\newcommand{\opSymbol}[1]{{\mathsf{#1}}} 
\newcommand{\opName}[1]{\opSymbol{#1}}
\newcommand{\setName}[1]{\mathrm{\mathbf{#1}}}
\newcommand{\varName}[1]{\mathit{#1}}


\newcommand{\codomain}{\opName{codomain}} \newcommand{\Probability}[1] {\Pr[#1]} 

\newcommand{\List}[1] {[ #1 ]} 

\newcommand{\upto}{,\!\makebox[1em][c]{.\hfil.\hfil.},} 

\newcommand{\Map}[1]{\List{#1}} \newcommand{\MapDef}[2]{\Map{#1 \; | \; #2}}

\newcommand{\pfn}{\rightharpoonup} 

\newcommand{\munion}{\upr} \newcommand{\upr}{\uplus}


\usepackage{esvect} \newcommand{\vect}[1] {\vv{#1}}





\newcommand{\Intersect}{\mathop{\cap}} 



\newcommand*{\llbrace}{\BeginAccSupp{method=hex,unicode,ActualText=2983}\textnormal{\usefont{OMS}{lmr}{m}{n}\char102}\mathchoice{\mkern-4.05mu}{\mkern-4.05mu}{\mkern-4.3mu}{\mkern-4.8mu}\textnormal{\usefont{OMS}{lmr}{m}{n}\char106}\EndAccSupp{}}
\newcommand*{\rrbrace}{\BeginAccSupp{method=hex,unicode,ActualText=2984}\textnormal{\usefont{OMS}{lmr}{m}{n}\char106}\mathchoice{\mkern-4.05mu}{\mkern-4.05mu}{\mkern-4.3mu}{\mkern-4.8mu}\textnormal{\usefont{OMS}{lmr}{m}{n}\char103}\EndAccSupp{}}

\newsavebox{\lXbrace}
\savebox{\lXbrace}{}
\newsavebox{\rXbrace}
\savebox{\rXbrace}{}

\def\lxbrace{\hstretch{0.6}{\scalerel*{\usebox{\lXbrace}}{\llbrace}}}
\def\rxbrace{\hstretch{0.6}{\scalerel*{\usebox{\rXbrace}}{\rrbrace}}}





\newcommand{\mSet}[1]{\lxbrace #1 \rxbrace}


\newcommand{\mSetBig}[1]{\scalerel{\lxbrace}{ #1 } 
                         \scalerel*{\rxbrace}{ #1 }}
\newcommand{\mSetDef}[2]{\lxbrace #1 \; \vert \; #2\, \rxbrace
}

\makeatletter
\newsavebox{\mystrut}
\newcommand{\mSetDefBig}[3][1.5ex]{
\dimen@ #1
\savebox{\mystrut}{\raisebox{-1\dimen@}{\rule{0pt}{3\dimen@}}}
\scalerel*{\lxbrace}{\usebox{\mystrut}}
  #2 \; \scalerel*{\vert}{\usebox{\mystrut}} \; #3\,
   \scalerel*{\rxbrace}{\usebox{\mystrut}}
}
\makeatother


\newcommand{\upreserving}[2] {\relation{#1} \upr \relation{#2}}

\newcommand{\filter}[2] {\relation{#1} \bullet \set{#2}}

\newcommand{\dom}[1] {\Dom(#1)}
\newcommand{\depRel}[1] {\widetilde{#1}}
\newcommand{\depFunc}[1] {\hat{#1}}

\newcommand{\apply}[2] {#1(#2)} 

\newcommand{\Table} {\setName{Table}}
\newcommand{\Tbl} {\setName{Table}}
\newcommand{\LinTbl}{\setName{ProvTable}}
\newcommand{\Rec} {\setName{Rec}}

\newcommand{\IdTable}{\opName{Id}}
\newcommand{\ConstTable}{\opName{Const}}

\newcommand{\Configuration}[3] {\langle #1, #2, #3 \rangle}
\newcommand{\Conf} {\mathds{C}}
\newcommand{\InitConf} {\setName{Init}}
\newcommand{\Configs} {\setName{Config}} 

\newcommand{\Silent} {\tau}
\newcommand{\Budget} {B}
\newcommand{\Env}[1] {#1}

\newcommand{\Program}[1] {#1}
\newcommand{\AllPrograms} {\mathds{P}}
\newcommand{\AllStates} {\setName{State}}

\newcommand{\noDep} {\bot} \newcommand{\Query}[1] {{Q_{#1}} }
\newcommand{\QueryVec}[1]{\vect{Q}, #1}  

\newcommand{\QUERY}  {Query} 

\newcommand{\QueryAct}{\opName{query}} \newcommand{\QuerySet}{\setName{Query}} 


\newcommand{\RecordSet}{\setName{Record}}
\newcommand{\Record}[1] {#1}
\newcommand{\Length}[1] {|#1|}
\newcommand{\Size}[1] {\opName{size}(#1)}

\newcommand{\DepSubset}[3] { \relation{#1} \rSub{#3} \relation{#2} }
\newcommand{\rSub}[1]{ \mathrel{\overset{#1}{\sqsubset}}}

\newcommand{\Sim}[3] {#1 \rSim{#3} #2}
\newcommand{\rSim}[1]{\mathrel{\overset{#1}{\sim}}}

\newcommand{\Init}[1] {\opName{Init}(\System{#1})}

\newcommand{\Mstep}[2] { \xRightarrow{#1}_{#2} } \newcommand{\Sstep}[2] { \xrightarrow{#1}_{#2} } \newcommand{\Pstep}[1] { \xrightarrow{#1} } 

\newcommand{\EmptyTrace} {[]} 
\newcommand{\EmptySet} {\{\}} 

\renewcommand{\epsilon}{\varepsilon} \newcommand{\Xepsilon} {\mathscr{E}} \newcommand{\Epsilon}{\Xepsilon}
\newcommand{\select}{\opSymbol{select}} 
\newcommand{\System}[1] {#1}
\newcommand{\Id}[2] {#1_{#2}}  

\newcommand{\trace} {t}
\newcommand{\compatible}[2]{#1 \vdash #2}


\newcommand{\Dom}{\opSymbol{dom}}
\newcommand{\Range}{\opSymbol{range}}
\newcommand{\TVar}{\setName{TVar}}
\newcommand{\tvar} {\varName{tv}}
\newcommand{\Expr}{\setName{Expr}}
\newcommand{\Val}{\setName{Val}}
\newcommand{\Input}{\opSymbol{input}}

\newcommand{\AllTables} {\setName{Table}}
\newcommand{\SensitivityFunc} {\opName{stability}}

\newcommand{\ProgAct} {\setName{ProgAct}} \newcommand{\Act} {\setName{Act}}         


\newcommand{\emptyenv}{\emptyset} 

\definecolor{dkgreen}{rgb}{0,0.6,0}
\definecolor{gray}{rgb}{0.5,0.5,0.5}
\definecolor{mauve}{rgb}{0.58,0,0.82}
\definecolor{light-gray}{gray}{0.25} 

\lstdefinestyle{csharp} {
aboveskip=3mm,
belowskip=3mm,
showstringspaces=false,
columns=flexible,
basicstyle={\footnotesize\ttfamily},
numberstyle={\tiny},
numbers=left,
keywordstyle=\color{blue},
commentstyle=\color{dkgreen},
stringstyle=\color{mauve},
breaklines=true,
breakatwhitespace=true,
tabsize=3,
morecomment = [l]{//},
morecomment = [l]{///},
morecomment = [s]{/*}{*/},
morestring=[b]",
sensitive = true,
morekeywords = {async, await, abstract,
event, new, struct,
as, explicit, null, switch,
base, extern, object, this,
bool, false, operator, throw,
break, finally, out, true,
byte, fixed, override, try,
case, float, params, typeof,
catch, for, private, uint,
char, foreach, protected, ulong,
checked, goto, public, unchecked,
class, if, readonly, unsafe,
const, implicit, ref, ushort,
continue, in, return, using,
decimal, int, sbyte, virtual,
default, interface, sealed, volatile,
delegate, internal, short, void,
do, is, sizeof, while,
double, lock, stackalloc,
else, long, static,
enum, namespace, string }
}






\usepackage[compact
           ]{titlesecMod} \titlespacing{\section}{0pt}{*2}{*1} 



\titleformat{\paragraph}[runin]
   {\normalfont\normalsize\bfseries}{\theparagraph}{1em}{}



\AtBeginDocument{\addtolength\abovedisplayskip{-0.4\baselineskip}\addtolength\belowdisplayskip{-0.4\baselineskip}\addtolength{\textfloatsep}{-4ex}
\addtolength{\intextsep}{-4ex}
\addtolength{\abovecaptionskip}{-2ex}
\addtolength{\belowcaptionskip}{2ex}
}



\renewcommand\floatpagefraction{.9}
\renewcommand\topfraction{.9}
\renewcommand\bottomfraction{.9}
\renewcommand\textfraction{.1}
\setcounter{totalnumber}{50}
\setcounter{topnumber}{50}
\setcounter{bottomnumber}{50}


 
\begin{document}

\conferenceinfo{POPL'06} {January 11--13, 2006, Charleston, South Carolina, USA.}
\CopyrightYear{2006}
\copyrightdata{1-59593-027-2/06/0001} 

\preprintfooter{DRAFT}


\title{On Flow-Sensitive Security Types}
\authorinfo{Sebastian Hunt}
        {Department of Computing\\ School of Informatics, City University\\ London EC1V OHB, UK}
        {seb\mbox{\rm @}soi.city.ac.uk} \authorinfo{David Sands}
        {Department of Computer Science and Engineering, \\
         Chalmers University of Technology \\
         G\"oteborg, Sweden }
        {dave\mbox{\rm @}chalmers.se}

\maketitle

\begin{abstract}

This article investigates formal properties of a family of
semantically sound flow-sensitive type systems for tracking information flow in simple
While programs. The family is indexed by the choice of flow lattice.

By choosing the flow lattice to be the powerset of program variables,
we obtain a system which, in a very strong sense, subsumes all other
systems in the family (in particular, for each program, it provides
a principal typing from which all others may
be inferred).  This distinguished system is shown to be equivalent
to, though more simply described than, Amtoft and Banerjee's
Hoare-style independence logic (SAS'04).

In general, some lattices are more expressive than others. 
Despite this, we show that no type system in the family can give
better results for a given choice of lattice than the type system
for that lattice itself.

Finally, for any program typeable in one of these systems, we show
how to construct an equivalent program which is typeable in a simple
flow-insensitive system.  We argue that this general approach could
be useful in a proof-carrying-code setting.

\end{abstract}

\category{D.3}{PROGRAMMING LANGUAGES}{}
\category{F.3.1}{LOGICS AND MEANINGS OF PROGRAMS}{Specifying and Verifying and Reasoning about Programs}
\category{F.3.2}{LOGICS AND MEANINGS OF PROGRAMS}{Semantics of Programming Languages}[Program analysis]

\terms
Languages, Security, Theory

\keywords
flow-sensitivity,
information flow,
non-interference,
static analysis,
type systems

\section{Introduction}

This article investigates formal properties of a family of
flow-sensitive type systems for tracking information flow.

The analysis of information flow in programs has received considerable
attention in recent years due to its connection to the problem of
secure information flow \cite{Sabelfeld:Myers:JSAC}. The classic
end-to-end confidentiality policy says that if certain data in a
system is considered secret from the perspective of a certain observer
of the system, then during computation there
should be no information flow from that
data to that observer. Denning and Denning
\cite{Denning:Denning:Certification} pioneered the use of program
analysis to statically determine if the information flow properties of
a program satisfy a certain confidentiality policy. 

Most of the more recent work in this area (see  \cite{Sabelfeld:Myers:JSAC} for an overview)
has
been based upon the use of \emph{security type systems} to formulate
the analysis of secure information flow, and to aid in a rigorous
proof of its correctness.

We will focus, like many works in the area, on systems in which
secrets are stored in variables. Security \emph{levels} are associated
with variables, and this describes the intended secrecy of the
contents.  The simplest instance of the problem involves two security
levels: high () which denotes secrets, and low () which denotes
public data.  A partial ordering, , denotes that the only
permitted information flow is from  to . The security problem is
to verify that there is no dependency between the initial value of the
high variables (the secret to which the program has access), and the
final value of the low variables (the outputs which are visible to the
public).

With respect to the treatment of variables, one feature of almost all
recent type based systems is that they are \emph{flow-insensitive}.
This means that the order of execution is not taken into account in
the analysis. One simple intuition for the notion of flow-insensitivity
\cite{Nielson+:Program:Analysis} is that an analysis is
flow-insensitive if the results for analysing  are the same as
that for .  In this respect the analysis of
\cite{Volpano:Smith:Irvine:Sound} (which can be viewed as a
reformulation of Denning and Denning's original analysis) is
flow-insensitive. In particular flow-insensitivity of this style of type
system means that if a program is to be typed as ``secure'' then
\emph{every} subprogram must also be typed as ``secure''. So for
example the trivial program  where  contains a
secret, and the final value of  is low (publicly observable) is
considered insecure because the subprogram  is insecure.

More generally, flow-insensitivity uses a single abstraction (in this
case a single security level) to represent each variable in the
program. Flow-sensitivity, on the other hand, increases accuracy by
providing a different abstraction at each program point.

Although there are a number of empirical/experimental analyses of the
relationship between flow-sensitive and flow-insensitive program
analyses (see e.g. \cite{Carini:Hind:Flow}), there has been very little discussion of
this dimension in connection to information flow analysis.

In this article we investigate flow-sensitive typings
for a simple While language.
We present a
family of semantically sound security type systems (parameterised
by the choice of flow lattice) which allow the type of a
variable to ``float'', assigning different security types at
different points in the program (Section~\ref{sect:family}).

Although this type system is extremely simple, it turns up some surprises. 
Our main results are the following:
\begin{itemize}
\item Although we can freely choose an arbitrarily
  complex flow lattice, there is a single ``universal'' lattice, and hence
  a single type system, from which all other typings in all other
  instances can be deduced.
In fact, all possible typings in all possible lattices
  can be obtained from one 
  principal typing in the universal lattice.
  From the principal typing, we can construct both
  the strongest (smallest) output typing for a given input typing,
  and the weakest (largest) input typing for a given output typing.
  The universal lattice is the powerset of program variables. 
\item For the universal lattice, we show that the type system is
  equivalent to Amtoft and Banerjee's 
  Hoare-like logic for program dependence
  \cite{Amtoft:Banerjee:SAS04}, which is expressed in terms of
  input-variable output-variable independence pairs. Because our
  formulation is based on dependence rather than independence, it
  is arguably simpler and admits a more straightforward correctness
  proof, without the need to resort to a non-standard trace semantics.
\item In general, some lattices are more expressive than others.
    For example, in contrast to the two-point lattice ,
  a single derivation in the type system for the universal lattice
    can identify fine-grained inter-variable dependencies of the form
  `` may depend on the initial value of  but not on ''.
  Despite this variation in expressiveness, we establish in Section \ref{sect:completeness} 
  an ``internal completeness'' result which shows that no type system in the family
  can give better results for a given choice of lattice than the
  type system for that lattice itself.
\item Finally in Section~\ref{sect:transformation} we show that for any program
  typeable in an instance of the flow-sensitive system, we are able to
  construct an equivalent program which is typeable in a simple
  flow-insensitive system. The translation is given by a
  security-type-directed translation, introducing extra variables.
  This general approach could be useful in a proof-carrying-code
  setting where the code consumer can have a simple type system, but
  the code producer is free to work in a more permissive system and
  use the translation to provide more easily checked code.
\end{itemize}

\subsection{Related Work}
A number of authors have presented flow-sensitive information flow
analyses e.g. \cite{Clark+:JCL}.
Those close in style to a type system formulation include Ban\^atre
\emph{et al} \cite{Banatre:Bryce:LeMetayer:ESORICS94}, who present a
system very similar to that of \cite{Amtoft:Banerjee:SAS04}, except
that all indirect flows are handled in a pre-pass. Andrews and Reitman 
describe a similar logic \cite{Andrews:Reitman:Axiomatic} but 
did not consider semantic soundness. 

In the treatment of information flow analysis of low level code (e.g.,
\cite{GenaimS05,Hedin:Sands:Timing}), flow-sensitivity arises as an essential
component to handle single threaded structures such as stacks and
registers, since obviously stacks and registers cannot be assigned a
fixed type throughout program execution.

The transformation we present in Section~\ref{sect:transformation} is 
related to \emph{single static assignment}(SSA)\cite{SSA}, although the perspective is quite different. We discuss this further in Section~\ref{subsec:SSA}


\section{A Family of Type Systems}
\label{sect:family}

We work with a simple While language with the usual semantics.
Program variables are drawn from a finite set .
A flow-insensitive type system, such as that in \cite{Volpano:Smith:Irvine:Sound},
has the following form: each variable is assigned a fixed security
level. When assigning an expression to a variable , all
variables in  must have an equal or lower security level.  When
assignments take place in loops or conditional branches, to avoid
indirect information flows the level of  must be at least as high
as the level of any variable in the branching expression.

To allow types to be flow-sensitive, we must allow the type of a variable to ``float''. 
For example, taking the two-point flow lattice, 
when assigning an expression to a variable , 
if  has type  before the assignment and  has type , then 
after the assignment  must be considered to have type . 

The flow-sensitive system we define is 
a family of inference systems, 
one for each choice of flow lattice  (where  may be
any finite lattice).
For a command , judgements have the form

where , and  are type environments of type .
The inference rules are shown in Table~\ref{table:version1}.
The idea is that if  describes the security levels of variables which hold 
before execution of , then  will describe the security levels of those variables after execution of .
The type  represents the usual ``program counter'' level and serves to eliminate 
indirect information flows; the derivation rules ensure that only variables which end up
(in ) with types greater than or equal to  may be changed by .
We write  to mean .
We drop the  subscript from judgements where the identity of the lattice is clear
from the context or is not relevant to the discussion.

In some of the derivation rules we write  to mean that expression  has type
 assuming type environment .
Throughout this paper the type of an expression is defined simply by
taking the lub of the types of its free variables:

This is consistent with the typings used in many systems, 
though more sophisticated typing rules for expressions would be possible in principle.
\begin{table}
\begin{center}
4ex]
        \inference[Assign]{
                \ejudge{\Gamma}{E}{t}
        }{
                \judge{p}{\Gamma}{x \<:=> E}{\Gamma[x \mapsto p \sqcup t]}
        }
\4ex]
        \inference[If]{
                \ejudge{\Gamma}{E}{t} &
                \judge{p \sqcup t}{\Gamma}{C_i}{\Gamma'} \quad i = 1,2
        }{
                \judge{p}{\Gamma}{\<if>\;E\;C_1\;C_2}{\Gamma'}
        }
\4ex]
        \inference[Sub]{
                \judge{p_1}{\Gamma_1}{C}{\Gamma'_1}
        }{
                \judge{p_2}{\Gamma_2}{C}{\Gamma'_2}
        } \quad p_2 \sqsubseteq p_1, \Gamma_2 \sqsubseteq \Gamma_1, \Gamma'_1 \sqsubseteq \Gamma'_2
\end{array}

\begin{array}{c}
        \inference[If]{
                \ejudge{\Gamma}{E}{t} &
                \judgeA{p \sqcup t}{\Gamma}{C_i}{\Gamma'_i} \quad i = 1,2
        }{
                \judgeA{p}{\Gamma}{\<if>\;E\;C_1\;C_2}{\Gamma'}
        } \quad \Gamma' = \Gamma'_1 \lub \Gamma'_2
\
\end{center}
\caption{Flow-Sensitive Type Rules: Algorithmic Version}
\label{table:version2}
\end{table*}
The rules are deterministic: given an input type environment
exactly one derivation is possible for any given .
(Well, almost. The While rule allows the chain  to be
extended arbitrarily by appending unnecessary repetitions of the limit. We may assume
that  is chosen minimally.)
\begin{theorem}[Algorithmic Correctness]\label{theorem:algo}
For all  and for all :
\begin{enumerate}

\item\label{theorem:algo:monotone}
For all , there exists a unique  such that
 and furthermore, the corresponding
function  is monotone.

\item\label{theorem:algo:complete}
If  then .

\item\label{theorem:algo:sound}
If  then .

\end{enumerate}
\end{theorem}
\begin{corollary}\label{coroll:algo}
     is the least  such that .
\end{corollary}
\begin{proof}[Proof of Algorithmic Correctness]
Proof of part~\ref{theorem:algo:monotone} of the theorem is by induction on the structure of the command.
The interesting case is .
By induction hypothesis,  is well-defined and monotone.
It follows that the sequences 
and  may be constructed
as  and ,
with  and  being monotone functions derived from ; thus these sequences
form the ascending chains shown in Figure~\ref{fig:chain}. The chains have finite height because the
lattices are finite, thus  is guaranteed to exist such that 
and it is then immediate that  for all . Put more succinctly, the While rule specifies
 as an iterative construction of the least fixed point of a monotone function on a finite lattice.
\begin{figure}
\begin{center}
    \includegraphics{chain-diagram}
\end{center}
\caption{Construction of a Minimal While Typing}
\label{fig:chain}
\end{figure}

The proofs of parts \ref{theorem:algo:complete} and \ref{theorem:algo:sound} of the theorem are then by straightforward inductions
on the  derivation and the structure of , respectively.
\end{proof}
In Section~\ref{sect:transformation} we adapt this version of the type system to define a program transformation
which allows the use of conventional fixed-type systems in place of the flow-sensitive ones.



\section{A Limiting Case: Dependency Analysis}
Given the correctness condition, it is clear that the type systems defined above
are calculating dependency relationships between program variables.
Intuitively, we might expect to gain the most precise dependency information by choosing the flow
lattice , which allows us to consider arbitrary sets of variables (including the singleton sets)
as distinct types.
In Section~\ref{sect:completeness}
we explore in detail this question of precision, with some slightly
surprising results.
Section~\ref{sect:completeness} also
formally establishes the special status of the type system for ;
anticipating this, we introduce some terminology:
\begin{definition}
The \emph{universal lattice} is the flow lattice  of sets of program variables.
The \emph{universal system} is the corresponding type system.
\end{definition}
In this section we show that the universal system is equivalent to (is, in fact, the De Morgan dual of)
Amtoft and Banerjee's Hoare-style independence logic \cite{Amtoft:Banerjee:SAS04}.

For notational clarity when comparing
the universal system with other choices of , we let  range over type
environments just in the universal system (thus
).



\pagebreak
\subsection{Comparison with Amtoft-Banerjee Hoare Logic}
In \cite{Amtoft:Banerjee:SAS04}, Amtoft and Banerjee define a Hoare-style logic for deducing independence relationships
between variables in While programs.
Judgements in the logic have the form

where  and .
The idea is roughly as follows.
Suppose that  is preceded by some previous computation on the store.
We will refer to the
value of a variable before this preceding computation as its \emph{original} value.
Then a pair
 in  represents an assertion that the value of  after  is independent
of the original value of , assuming that all the independence pairs in  are valid
for the preceding computation.
For ease of comparison, rather than sets of independence pairs ,
we present the logic in terms of mappings 
(this depends simply on the set isomorphism ).
Thus Amtoft-Banerjee (AB) judgements in our presentation have the form

The AB derivation rules are shown in Table~\ref{table:AB}.
\begin{table*}
\begin{center}
4ex]
    \inference[Seq{AB}]{
        \judge{G}{\nabla}{C_1}{\nabla'} &
        \judge{G}{\nabla'}{C_2}{\nabla''}
    }{
        \judge{G}{\nabla}{C_1 \<;> C_2}{\nabla''}
    }
\4ex]
    \inference[While{AB}]{
        \judge{G'}{\nabla}{C}{\nabla}
    }{
        \judge{G}{\nabla}{\<while>\;E\;C}{\nabla}
    } \quad
        \begin{array}{ll}
            \mbox{if} & G \subseteq G' \\
            \mbox{and} & w \not\in G' => \forall x \in \fv(E) . w \in \nabla(x)
        \end{array}
\
\end{center}
\caption{Amtoft-Banerjee Hoare Logic}
\label{table:AB}
\end{table*}
The ordering  is pointwise reverse subset inclusion, thus:

Note that the ordering used on  is just , not .

The relationship between the AB logic and the universal system is straightforward:
for each
 there is a corresponding  such that  is the complement of .
Where the universal system derives sets of dependencies, the AB logic
simply derives the complementary set of independencies.
(An AB context set , on the other hand,
corresponds directly to the \emph{same} set  in a -derivation.)
We use the following notation:

Clearly this is an order isomorphism:  and  iff
, etc.
\begin{theorem}
    The AB logic and the universal system are De Morgan duals. That is,
     is derivable in the universal system iff
     is derivable in the AB logic.
\end{theorem}
The proof amounts, essentially, to showing that each AB rule is the dual of the universal system
counterpart.
This is not quite literally true, since the way some AB rules are formulated builds in
the potential for implicit weakening,
which must be made explicit using Sub in the corresponding -derivation.
For example, consider the second side condition on the rule IfAB.
If we re-state this in its contrapositive form

it is easily seen that the two side-conditions together amount to

Note that any subderivation concluding
at a premise to
IfAB with  strictly greater than required by (\ref{eqn:weakdual}),
can have an instance of SubAB added at the end to make
.
With this caveat, the side condition for IfAB is equivalent to
the If premise in the universal system.
Similar observations apply to the side conditions for AssignAB and WhileAB.

\section{Internal Completeness}\label{sect:completeness}
In this section we explore a fundamental relationship between different members of our
family of flow-sensitive type systems.
For simplicity of presentation, we consider only ``top-level'' typing judgements, ie, those
of the form  (see Section~\ref{sect:principal} for further remarks
on this point).
We start by formalising a key notion: the sense in which one typing
can be viewed as subsuming another
(possibly in a different lattice).
Given ,
we refer to a pair  as an -typing.
If  we say that typing  is derivable for .
\begin{definition}
    An -typing  is said to subsume
    an -typing  iff, for all commands 
    
\end{definition}
Note that this is a \emph{semantic} notion of subsumption: one typing subsumes another
precisely when the non-interference property specified by the former is stronger - satisfied
by fewer programs - than that specified by the latter.
As we shall see (Theorem~\ref{theorem:internalcompleteness}),
the type systems actually faithfully reflect this semantic relationship.

As defined, subsumption appears difficult to verify, since it quantifies over all possible programs.
In fact, it suffices to compare the order relationships between the two pairs
of type environments:
\begin{theorem}\label{theorem:subsumption}
    -typing  subsumes
    -typing \; iff, for all :
    
\end{theorem}
\begin{proof}
For the \emph{only if} direction we show the contrapositive.
Assume  and .
We must find some command  such that

but .
Let  and let  be
the program

(the use of  here is arbitrary, any constant will do). It is then easy to verify that
 holds for all  but
 fails for .

For the \emph{if} direction,
Assume

We have to show, for all , .
Suppose  and 
and

and
.
We must show .
Now, for any ,
.
Hence, by (A1),
,
thus , where
.
Hence, by (A2),
,
hence
 as required.
\end{proof}
This result shows that the semantic content of a judgement
 is uniquely determined by the set of pairs
: the smaller this set, the stronger
the non-interference property. In fact, these pairs are precisely the dependencies
allowed by the typing: if  then the final value
of  after executing  \emph{may depend on} the initial value of .
Alternatively, we may consider the contrapositive form of
Theorem~\ref{theorem:subsumption}, which says that
 subsumes
\; iff

This allows us to understand a typing in
terms of \emph{independence} relations (as used by Amtoft and Banerjee).
The larger the set , the stronger
the non-interference property: if  then the final value
of  after executing  \emph{must be independent of} the initial value of .

Now suppose we have an -typing which subsumes an -typing,
and suppose we find that the -typing is \emph{not} derivable for 
in the -type system. Will it ever be possible to verify the soundness
of the -typing for  indirectly, by deriving the subsuming -typing
in the -system instead?
We might expect this to happen
in the case that  has more points, and is therefore able to make more refined
dependency distinctions, than .
Consider the examples shown
in Figure~\ref{fig:diamond}, where
 is the four point lattice depicted.
\begin{figure*}
\begin{center}
\begin{minipage}{20mm}
    \includegraphics[width=20mm]{Diamond.eps}
\end{minipage}

\end{center}
\caption{Example Derivations}
\label{fig:diamond}
\end{figure*}
It can readily be verified that the -typing
subsumes the -typing and both
judgements are derivable.
However,
the  judgement simply assigns  the most conservative typing in ,
whereas
the  judgement captures the fact
that the final value of  may depend on both  and , but not on the initial value of .
Could it be, that as part of a derivation for some larger program,
this fine-grained derivation for 
enables us to derive
a -typing subsuming an -typing which cannot be derived in the simpler
-system?
Surprisingly, the answer is No, as confirmed by the following theorem.
\begin{theorem}[Internal Completeness]\label{theorem:internalcompleteness}
        If -typing  subsumes
        -typing 
        and , then
    .
\end{theorem}
Before we can prove the theorem, we need to develop some further machinery.
As an additional benefit of this development, we find that,
for each command , there is a principal typing
from which all others can be obtained.

\subsection{Monotone Renaming of Types}
This section establishes a key technical result used in the proof of the Internal Completeness theorem.
Roughly speaking, the result says that we can take any derivation and, by consistently
renaming the security types, obtain a new one. The notion of renaming is very
general and allows us to translate a derivation for one choice
of lattice into a derivation for a different lattice;
we require only that the renaming function be monotone.
Given  and a renaming
function , we write 
for the pointwise extension of  to , thus
.

\begin{lemma}[Monotone Renaming]
Let  be monotone.
Then
.
\end{lemma}
\begin{proof}
By induction on the height of the -derivation.
We present the Assign and While cases by way of illustration.

\proofcase{Assign}
We have an - derivation of the form:

where .
We can construct an - derivation:

It suffices to show that 
(since we can then use Sub). By the definitions,  for all
 and it remains to show .
Now by monotonicity of  we have

Finally, using this and monotonicity of  again, we have
.

\proofcase{While}
We have an - derivation of the form:

By induction hypothesis we have .
As in the Assign case, we have 
and , allowing us to construct:


\end{proof}

\subsection{Canonical Derivations}
Given the Monotone Renaming lemma, we might hope to prove the
Internal Completeness theorem by a construction for a suitable
monotone renaming function to translate the -derivation
into an -derivation for the subsumed typing. However,
since an appropriate construction is not immediately obvious\footnote{Though we can read it off easily enough once we have the proof. It is:
.}, we go via an indirect route.
We begin our detour by showing how to produce any given derivation

from a particular form of 
derivation in the universal system. To do this
we construct, for each choice of , an \emph{abstract interpretation} 
 \cite{Cousot:Cousot:Abstract:Interpretation} which is given by 
a \emph{pair} of monotone renaming maps:
\begin{definition}
Given , we define the maps

and

by:

\end{definition}
These maps enjoy a special status.
Recall \cite{davey90introduction}
that a Galois Connection (GC) between  and 
is a pair of maps  with
,
 and such that
.
Key properties of a GC are that  are both monotone,
,
,
 preserves joins and  preserves meets.
Furthermore, the two component maps uniquely determine each other, thus:

\begin{lemma}
        For any , the pair
         is a Galois Connection between  and .
\end{lemma}
Our first use of these renaming functions is, given
an -typing , to construct a 
typing in the universal system
which subsumes it.
A central r\^{o}le is played by the particular  type environment
which maps each  to the singleton .
We denote this environment by .
Thus, for all
,
.
\begin{lemma}\label{lemma:shift}
    
    subsumes 
    .
\end{lemma}
\begin{proof}
    Assume .
    We must show that .
    Since , the assumption
    is just ,
    hence  by definition of .
\end{proof}
It turns out that the two related typings stand or fall together: for any , the
one is derivable if and only if the other is.
\begin{lemma}[Canonical Derivations]\label{lemma:canonical}
\mbox{} \\

\end{lemma}
\begin{proof}
The proof makes essential use of the Monotone Renaming lemma.
For the  direction, Monotone Renaming gives
.
It then suffices to show that ,
since appending a single use of Sub then gives the required derivation.
To show  we must show
 for all , and this is
just .

For the  direction, Monotone Renaming gives
.
Now, by (\ref{eqn:alpha}),
,
thus
.
By standard properties of a GC, .
Thus the required derivation follows by appending a single use of Sub.
\end{proof}

Now we can prove the theorem stated at the start of Section~\ref{sect:completeness}.
\begin{proof}[Proof of Internal Completeness]
Assume 
-typing  subsumes
-typing  and
.
We must show  which,
by the Canonical Derivations lemma, is equivalent to

Furthermore, again by the Canonical Derivations lemma, the existence
of our assumed derivation is equivalent to

It thus suffices to show

and append a single use of Sub to derive (\ref{eqn:complete-end}) from (\ref{eqn:complete-start}).
To show (\ref{eqn:complete-middle}) we must show
,
and this is just the assumed type subsumption, so we are done.
\end{proof}
As we noted above, the use of Galois Connections above
is a form of abstract interpretation, and is reminiscent 
of the study of \emph{complete} abstract interpretations
\cite{CousotCousot79-1,GiacobazziRanzatoScozzari}.
We have not explored these connections deeply, but a key difference
would appear to be in our use of a different GC for each choice of
, rather than a single GC relating all
-derivations to counterpart
derivations in the universal system.

\subsection{Principal Typings}\label{sect:principal}
As an additional corollary of the Canonical Derivations lemma, we find that, for each
command , there is a typing derivable for
 from which all others can be inferred, namely

where  is the smallest  such that 
(recall that, by Corollary~\ref{coroll:algo}, this exists and is given by
).
The Canonical Derivations lemma shows that
derivability of any given
 is equivalent
to , which unpacks to:

In fact, we can show that  is a \emph{principal} typing
for , in the sense defined by Wells \cite{Wells:ICALP-2002}.
Transposed to our setting\footnote{For this purpose, we view our family as a single type system consisting of the disjoint
union of all its members.},
Wells makes the following definitions:
\begin{itemize}
\item A pre-order on typings:  iff .
\item Principal typings: typing  is \emph{principal for}  iff , and
.
\end{itemize}
\begin{theorem}[Principal Typing]
 is principal for .
\end{theorem}
Before proving the theorem we state an easy lemma about subsumption:
\begin{lemma}\label{lemma:monotonesubsumption}
If  subsumes  and , then
 subsumes .
\end{lemma}
\begin{proof}[Proof of Principal Typing]
By definition of , . Suppose
.
We must show, for all , .
So suppose . By Internal Completeness, it suffices to show
that  subsumes .
By Lemma~\ref{lemma:shift},

subsumes
 so, by Lemma~\ref{lemma:monotonesubsumption},
it suffices to show .
By the Canonical Derivations lemma (using ),
, so by definition of ,
.
\end{proof}

As noted earlier, we have restricted attention to typing judgements
 with . While this is appropriate
when we wish to consider whole programs, it does not allow us to apply
our principal typings result compositionally. We believe the results above
extend straightforwardly to the general case, the key step being to
adjoin a ``program counter variable'' to , so the universal lattice
becomes .

\subsubsection{Polymorphism}\label{sect:polymorphism}
The principal typing result above suggests that we should be able to view
typings in the universal system as polymorphic, in some sense.
In fact, this can be done quite directly:
we may take an isomorphic view of 
which shows typings in the universal system to be polymorphic in the standard
sense of types involving type variables.
Assume given a set of type variables , ranged over by .
Assume also some particular 1-1 mapping between the two sets: we write
 for the type variable associated to program variable .
In this view,  is a type environment which assigns a unique polymorphic
variable  to each .
The application of  to  in the proof
() of the Canonical Derivations lemma amounts to an
instantiation of the type variables to produce .
In general,  interprets a set  of type
variables as the lub of the interpretations of its elements.
Thus, in this view, types in the  lattice can be thought
of as formal lubs, which can be interpreted as elements in any lattice
 by fixing an interpretation  for each .

As above, let
 be the smallest  such that .
It can be shown that fixing  and calculating
 gives us
, ie
the smallest
 such that .
More interestingly,  may also be used
in the reverse direction,
to calculate the greatest  such that 
for a given .
The idea is to construct an interpretation

which ``unifies''  and , in the sense that

for all , where .
The greatest  satisfying this equation for all  is given by

The hope is that taking  should then
give us the greatest  such that .
This is borne out by the following:
\begin{proposition}
Given ,
let  be defined as in (\ref{eqn:greatest}).
Then  is the greatest  such that .
\end{proposition}
\begin{proof}
By the Canonical Derivations lemma, it suffices to show that the 
defined is the greatest such that

Firstly, we show that (\ref{eqn:greatballsoffire}) holds by showing that
 for all .
Suppose , then we must show that
. This holds because
 implies  belongs to the set
over which the meet is taken in (\ref{eqn:greatest}).

It remains to show
that .
We show the contrapositive,
so suppose . Thus, by (\ref{eqn:greatest}),
for some ,  and ,
thus  but .
\end{proof}

\section{Transformation to Fixed-Types}
\label{sect:transformation}
We have seen that floating types enable more programs to be typed than
a standard fixed-type approach.  In this section we show that if
a program is typeable in the floating type system, then there is an
equivalent program which is typeable in a traditional fixed-type system. We
show this by construction: we extend the type system so that it also
\emph{generates} such a program. 
Take as an example the following valid judgement for the flow lattice , and the type environment 
:

A traditional security type system would not be able to handle this
example because the level of  becomes temporarily high, and then
the level of  becomes low.  To systematically transform the program to
make it typeable by a fixed-type system, we represent
each variable by a family of variables, one for each element of the
flow lattice. The idea is that at any point in the computation we will
be working with one particular member of the family.  Whenever we need
to raise the type of a variable from  to  in the original program
we represent
this in the transformed program by performing an assignment to \emph{move} 
information from  to , and by
henceforth working with .

Using this idea, the above program can be represented by the following:

where  and , for example, are distinct variables. 
The initial inputs  and  are here represented by  and  respectively. 
In a flow-insensitive security type system the program is deemed secure because
 (and ) only ever contain ``low'' information. 


\subsection{Fixed Variables}
To discuss fixed types more precisely it is convenient to 
introduce a new class of such type-indexed 
variables into the language: 
\begin{definition}
  For any given lattice of types , define the set of
  \emph{fixed variables}, ,  to be the set of type-indexed variables 

  To distinguish the
  fixed variables from the ``ordinary'' variables we will henceforth
  refer to the variables in  as \emph{floating variables}.
\end{definition}
So, for example, if we are working in the two-level flow lattice,
then for each floating variable , we have in addition two fixed
variables  and .

We will now extend the language with fixed-type variables.
Their dynamic semantics is just as for floating variables.
We are going to present a transformation by adapting the algorithmic
version of the type system, but first we must
extend it to cover fixed-type variables:
we extend the rule for expressions
and add a rule for fixed-type assignment.  We do not extend
the type environments to cover fixed variables since their type is
given by their index.

Let  denote the free floating variables (as before), and 
define  to denote the free fixed variables of expression  (and similarly for commands). 
Then the typing of expressions in the extended language is given by 

The fixed type rule is simply:

It is straightforward to extend the soundness arguments to encompass fixed variables.

Note that if we restrict our attention to programs with no free
floating variables (), then type environments are
redundant. We will use metavariable  to range over commands with no free floating variables. 
We will write  to denote
 for arbitrary .
It should be straightforward to
see that derivations of this form correspond exactly to derivations in
e.g. Volpano, Smith and Irvine's system \cite{Volpano:Smith:Irvine:Sound}, and other
Denning-style analyses, although we will not prove this formally.

\subsection{Translation}
Now we present the translation as an extension of the type system (algorithmic version) 
to judgements of the form

(we do not decorate  for this system since the form of the judgements
readily distinguish them from the previously defined systems).
First we need some basic constructions and notations. 
\begin{definition}\label{def:fassign}
\mbox{}\begin{enumerate}
\item 
For any type environments  and ,
let  denote the set

\item 
Let  be a set of variable to variable assignment statements.
We say that  is \emph{independent} if for any distinct pair 
 and  in ,
the variables
, ,  and  are all distinct.
For independent , all sequentialisations
are semantically equivalent and we
let  represent the command obtained by 
some canonical (but unspecified) sequentialisation.
\end{enumerate}
\end{definition}
\begin{lemma} 
 is an independent set of assignments
\end{lemma}
Thus we will write  to denote the command obtained by some canonical sequentialisation of the assignments.

\begin{definition}
For any type environment ,
let  denote the expression obtained by replacing each floating variable  in   with the fixed variable  where .
\end{definition}

With these definitions we are ready to introduce the translation. 
The rules are presented in Table~\ref{table:translation}.
\begin{table*}
\begin{center}
4ex]
        \inference[Assign-t]{
                \ejudge{\Gamma}{E}{t} \quad s =  p \lub t  
        }{
                \judge{p}{\Gamma}{x \<:=> E  ~>  x_{s} \<:=> E^\Gamma}{\Gamma[x \mapsto s]}
        }
\4ex]
        \inference[If-t]{
                \ejudge{\Gamma}{E}{t} &
                \judge{p \sqcup t}{\Gamma}{C_i ~> D_i}{\Gamma'_i} \quad i = 1,2
        }{
                \judge{p}{\Gamma}{\<if>\;E\;C_1\;C_2
~> \<if>\;E^\Gamma \;(D_1\<;>\fassign{\Gamma'}{\Gamma_1})\;
                     (D_2\<;>\fassign{\Gamma'}{\Gamma_2})
}{\Gamma'}
        } \quad \Gamma' = \Gamma'_1 \lub \Gamma'_2
\
\end{center}
\caption{Translation to fixed types}
\label{table:translation}
\end{table*}

The basic idea of the translation 
is that for any program point in  corresponding to a point in ,
for each variable , 
only one member of the family   will be ``in
play''. The type variables in play at any given program point are given by the type environment
at that program point. So for example if 
then  will be the -variable in play at the beginning of
the execution of . 

\begin{example}
Since a type derivation is structural in the syntax, for any derivation we can associate
a type environment with each program point.
Consider the example derivation shown in Figure~\ref{fig:translation-example}:
in the central column we write the environment update (rather than the whole environment)
yielding the environment after that program point
in the corresponding sub-derivation, and on the right-hand side we write the translated program. 
The example uses the four point lattice introduced previously
(Figure~\ref{fig:diamond}).

\begin{figure*}[htbp]
  2ex]
  \begin{array}{l|l|l} 
\text{Code} & \text{Environment change} & \text{Translated code}
\\ 
\hline \\
\<if>~x = 0~\<then>~y := y + 1; w := z & [ y \mapsto \diamH; w \mapsto \diamH] & \<if>~ x_\diamM= 0~\<then>~ y_\diamH := y_\diamM + 1 ; w_\diamH := z_\diamH \\
&  & \phantom{\<if>~ x_\diamM= 0}
~\<else>~ y_\diamH := y_\diamL; w_\diamH := w_\diamL \\
\<while>~ x > 0                &                & \<while>~ x_\diamM > 0 \\
\qquad     z := z + w          &               & \qquad z_\diamH := z_\diamH + w_\diamH \\         
\qquad     x := x - 1          &               & \qquad x_\diamM := x_\diamM - 1  \\ 
\qquad     z := x              & [z \mapsto \diamM] & \qquad z_\diamM := x_\diamM \\
                               &               & \qquad z_\diamH := z_\diamM      
\end{array}

\sigma \sim_\Gamma \rho <=> \forall x \in \Var. \sigma(x) = \rho(x_{\Gamma(x)})

\fjudge{p}{D}
 \begin{array}{l}
  \<if>~ y_1 \<then> 
\\ \qquad \<if>~y_2~ \<then>
\\ \qquad \qquad \cdots
\\ \qquad \qquad  \<if>~y_n~ \<then>
\\ \qquad \qquad\quad \<if>~h~ \<then>~ x_1 := 0; \cdots ; x_n := 0 
\end{array}

\begin{array}{l}
  \<if>~ y_{1\diamL}~ \<then> 
\\ \qquad \<if>~y_{2\diamL}~ \<then>
\\ \qquad \qquad \cdots
\\ \qquad \qquad  \<if>~y_{n\diamL}~ \<then>
\\ \qquad \qquad\qquad \<if>~h_\diamH~ \<then>~ x_{1\diamH} := 0; \cdots ; x_{n\diamH} := 0 
\\ \qquad \qquad\qquad \<else>~ X_\diamH := X_L
\\ \qquad \qquad  \<else>~ X_\diamH := X_L
\\ \qquad \qquad \cdots
\\ \<else> ~ X_\diamH := X_L
\end{array}
 \config{\fassign{\Gamma'}{\Gamma}}{\rho}\conv \rho'
\mbox{ where }   \sigma \sim_\Gamma \rho'

|[E|]\sigma = |[E^\Gamma|]\rho

\rho' = \rho[x_{\Gamma'(x)} \mapsto \rho(x_{\Gamma(x)} ) \mid x \in \Var]

\sigma(x) &= \rho(x_{\Gamma(x)}) \\
          &= \rho[x_{\Gamma'(x)} \mapsto \rho(x_{\Gamma(x)} ) \mid x \in \Var](x_{\Gamma'(x)})\\
          &= \rho'(x_{\Gamma'(x)}) 

 \inference{
                \ejudge{\Gamma}{E}{t} \quad s =  p \lub t  
        }{
                \judge{p}{\Gamma}{x \<:=> E  ~>  x_{s} \<:=> E^\Gamma}{\Gamma[x \mapsto s]}
        }
 \config{x \<:=> E}{\sigma}\conv \sigma[x\mapsto V].  \config{x_{\sigma} \<:=> E^\Gamma}{\sigma}\conv \sigma[x\mapsto V]. 
    \inference{
        |[E|]\sigma = \<true> &
        \config{C}{\sigma}\conv \sigma' &
        \config{\<while>\;E\;C}{\sigma'}\conv\sigma''
    }{
        \config{\<while>\;E\;C}{\sigma}\conv\sigma''
    }

    \inference{
            \ejudge{\Gamma'_i}{E}{t_i} &
            \judge{p \sqcup t_i}{\Gamma_i'}{C ~> D_i}{\Gamma''_i} &
            0 \leq i \leq n
    }{
            \judge{p}{\Gamma}{\<while>\;E\;C
~> \fassign{\Gamma'}{\Gamma}\<;>\<while>\;E^{\Gamma'}\; (D\<;>\fassign{\Gamma'}{\Gamma''})
}{\Gamma'}
    }
 \config{\fassign{\Gamma'}{\Gamma}\<;>W_D}{\rho}\conv\rho'' ~\text{where}~ \sigma \sim_{\Gamma'}\rho'' 
\config{\fassign{\Gamma'}{\Gamma}}{\rho}\conv\rho_1~\text{where}~ 
\sigma \sim_{\Gamma'} \rho_1\label{eq:one}

    \label{eq:two}
    \config{E^{\Gamma'}}{\rho_1}\conv\<true>.
  
    \label{eq:three}
    \config{D}{\rho_1}\conv \rho_2 ~\text{where}~ \sigma' \sim_{\Gamma''} \rho_2,
  
\config{\fassign{\Gamma'}{\Gamma''}}{\rho_2}\conv\rho_3~\text{where}~ 
\sigma' \sim_{\Gamma'} \rho_3\label{eq:four}

\judge{p}{\Gamma'}{\<while>\;E\;C
~> \fassign{\Gamma'}{\Gamma}\<;>W_D
}{\Gamma'}

  \label{eq:five}
  \config{W_D}{\rho_3}\conv \rho'' ~\text{where}~ \sigma'' \sim_{\Gamma'} \rho''

\setpremisesend{0.2em}\setpremisesspace{0.6em}
    \inference{
        \inference*{(\ref{eq:one})}{\config{\fassign{\Gamma'}{\Gamma}}{\rho}\conv\rho_1} &
        \inference{
            \inference*{(\ref{eq:two})}{\config{E^{\Gamma'}}{\rho_1}\conv\<true>} &
            \inference{
                \inference*{(\ref{eq:three})}{\config{D}{\rho_1}\conv\rho_2}
              & \inference*{(\ref{eq:four})}{\config{\fassign{\Gamma'}{\Gamma''}}{\rho_2}\conv\rho_3}
            }{
                \config{D\<;>\fassign{\Gamma'}{\Gamma''}}{\rho_1}\conv\rho_3
            } &
            \inference*{(\ref{eq:five})}{\config{W_D}{\rho_3}\conv \rho''}
        }{
            \config{W_D}{\rho_1}\conv \rho''
        }  
    }{
        \config{\fassign{\Gamma'}{\Gamma}\<;>\<while>\;E^{\Gamma'}\; (D\<;>\fassign{\Gamma'}{\Gamma''})}{\rho}
            \conv\rho''
    }

    \judgeA{p}{\Gamma}{x \<:=> E}{\Gamma[x \mapsto p \sqcup t]}

    \inference{
        \judgeA{p \sqcup t}{\Gamma}{C_i}{\Gamma'_i} \quad i = 1,2 \quad \Gamma' = \Gamma'_1 \lub \Gamma'_2
    }{
        \judgeA{p}{\Gamma}{\<if>\;E\;C_1\;C_2}{\Gamma'}
    }
 \forall x. \Gamma(x) \neq \Gamma'_i(x) => p \sqsubseteq \Gamma'_i(x) 
    \inference{
            \ejudge{\Gamma'_i}{E}{t_i} &
            \judgeA{p \sqcup t_i}{\Gamma_i'}{C}{\Gamma''_i} &
            0 \leq i \leq n
    }{
            \judgeA{p}{\Gamma}{\<while>\;E\;C}{\Gamma'_n}
    }
 
    \inference{
        \ejudge{\Gamma}{E}{t} \quad s =  p \lub t  
    }{
        \judge{p}{\Gamma}{ x \<:=> E  ~>  x_{s} \<:=> E^\Gamma}{\Gamma[x \mapsto s]}
    }

    \inference{
            \ejudge{\Gamma'_i}{E}{t_i} &
            \judge{p \sqcup t_i}{\Gamma_i'}{C ~> D_i}{\Gamma''_i} &
            0 \leq i \leq n
    }{
            \judge{p}{\Gamma}{\<while>\;E\;C
~> \fassign{\Gamma'}{\Gamma}\<;>\<while>\;E^{\Gamma'}\; (D\<;>\fassign{\Gamma'}{\Gamma''})
}{\Gamma'}
    }

\forall x. \Gamma(x) \neq \Gamma'(x) => p \sqsubseteq \Gamma'(x).

  \label{eq:gamma'gamma}
  p |- \Gamma' := \Gamma

\forall x. \Gamma'(x) \neq \Gamma''(x) => p \lub t_n \sqsubseteq \Gamma''(x).

  \label{eq:gamma'gamma''}
  p \lub t_n |- \fassign{\Gamma'}{\Gamma''}. 

  \label{eq:egamma'}
  |- E^{\Gamma'} : t_n, 

  \label{eq:ieD}
p \lub t_n |- D.
 \setpremisesend{0.2em}\setpremisesspace{0.6em}
\inference{
   \inference*{(\ref{eq:gamma'gamma})} {p |- \Gamma' := \Gamma} 
   &
   \inference{
      \inference*{(\ref{eq:egamma'})}{|- E^{\Gamma'} : t_n}   
     &\inference*{
         \inference*{(\ref{eq:ieD})}{p \lub t_n |- D}&
         \inference*{(\ref{eq:gamma'gamma''})}
                   {p \lub t_n |- \fassign{\Gamma'}{\Gamma''}}    
      }
      {p \lub t_n |- D\<;>\fassign{\Gamma'}{\Gamma''}} 
   }
   {p |- \<while>\;E^{\Gamma'}\; (D\<;>\fassign{\Gamma'}{\Gamma''})  }
}
{p |- \fassign{\Gamma'}{\Gamma}\<;> 
      \<while>\;E^{\Gamma'}\; (D\<;>\fassign{\Gamma'}{\Gamma''})
}

\end{proof}

\end{document}
