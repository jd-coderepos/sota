\subsection{Problem settings}

We denote the set of classes by  and the size of  by . We also denote the domain of datapoints by . A classifier is denoted by , where  is the set of all possible distributions over .  represents a randomized classifier such that given ,  is the probability that  maps  into class . Note that fixing the input , the randomness of a classifier is independent of everything else.




There are  datapoints . For each datapoint , there is an \emph{unknown} ground truth . We assume that there is an unknown prior distribution  over  such that  are i.i.d. samples drawn from  and 


Note that here we allow the datapoints to be ``imperfect'' instances, \ie, there still exists uncertainty for  conditioning on fully knowing . 

Traditional supervised learning aims to train a classifier  that is able to classify new datapoints into their ground truth categories with access to . However, in the setting of learning with noisy labels, instead, we \emph{only} have access to  where  is a noisy version of . 

We use a random variable  to denote the noisy version of  and  to denote the transition distribution between  and , \ie 


We use  to represent the  matrix format of . 

Generally speaking \cite{patrini2017making, ghosh2017robust,  zhang2018generalized}, label noise can be divided into several kinds according to the noise transition matrix . It is defined as \emph{class-independent (or uniform)} if a label is substituted by a uniformly random label regardless of the classes, \ie  (e.g. ). It is defined as \emph{diagonally dominant} if for every row of  , the magnitude of the diagonal entry is larger than any non-diagonal entry, \ie  (e.g. ).
It is defined as \emph{diagonally non-dominant} if it is not diagonally dominant (e.g. the example mentioned in introduction, ). 

We assume that the noise is independent of the datapoints conditioning on the ground truth, which is commonly assumed in the literature \cite{patrini2017making, ghosh2017robust, zhang2018generalized}, \ie, 

\begin{assumption}[Independent noise]
	 is independent of  conditioning on . 
\end{assumption}









We also need that the noisy version  is still informative. 
 
 \begin{assumption}[Informative noisy label]
	 is invertible, \ie, .
\end{assumption}







\subsection{Information theory concepts}


Since Shannon's seminal work \cite{shannon}, information theory has shown its powerful impact in various of fields, including several recent deep learning works~\cite{hjelm2018learning, cao2018max,kong2018water}. Our work is also inspired by information theory. This section introduces several basic information theory concepts. 

Information theory is commonly related to random variables. For every random variable , Shannon's entropy  measures the uncertainty of . For example, deterministic  has lowest entropy. For every two random variables  and , Shannon mutual information  measures the amount of relevance between  and . For example, when  and  are independent, they have the lowest Shannon mutual information, zero. 

Shannon mutual information is \emph{non-negative}, \emph{symmetric}, \ie, , and also satisfies a desired property, information-monotonicity, \ie, the mutual information between  and  will always decrease if either  or  has been ``processed''. 

\begin{fact}[Information-monotonicity \cite{csiszar2004information}]
	For all random variables , when  is less informative for  than , \ie,  is independent of  conditioning , 
\end{fact}
This property naturally induces that for all random variables ,  since  is always the most informative random variable for itself. 

Based on Shannon mutual information, a performance measure for a classifier  can be naturally defined. High quality classifier's output  should have high mutual information with the ground truth category . Thus, a classifier 's performance can be measured by . 

However, in our setting, we only have access to the i.i.d. samples of  and . A natural attempt is to measure a classifier 's performance by . Unfortunately, under this performance measure, the measurement based on noisy labels  may not be consistent with the measurement based on true labels . (See a counterexample in Supplementary Material B.) That is,
 Thus, we cannot use Shannon mutual information as the performance measure for classifiers. Here we find that, a generalized mutual information, Determinant based Mutual Information (DMI) \cite{Kong2019}, satisfies the above formula such that under the performance measure based on DMI, the measurement based on noisy labels is consistent with the measurement based on true labels.



\begin{definition}[Determinant based Mutual Information \cite{Kong2019}]\label{def:dmi}
    Given two discrete random variables , we define the Determinant based Mutual Information between  and  as 
    where  is the matrix format of the joint distribution over  and .   
\end{definition} 

DMI is a generalized version of Shannon's mutual information: it preserves all properties of Shannon mutual information, including non-negativity, symmetry and information-monotonicity and it is additionally relatively invariant. DMI is initially proposed to address a mechanism design problem \cite{Kong2019}. 



\begin{lemma}[Properties of DMI \cite{Kong2019}]
	DMI is non-negative, symmetric and information-monotone. Moreover, it is relatively invariant: for all random variables , when  is less informative for  than , \ie,  is independent of  conditioning ,   where  is the matrix format of   
\end{lemma}
\begin{proof}
The non-negativity and symmetry follow directly from the definition, so we only need to prove the relatively invariance. Note that
 
as  is independent of  conditioning on . 
Thus,  where , ,  are the matrix formats of , , , respectively. 
We have  because of the multiplication property of the determinant (\ie  for every two matrices ). Therefore, .

The relative invariance and the symmetry imply the information-monotonicity of DMI. When  is less informative for  than , \ie,  is independent of  conditioning on , 
 because of the fact that for every square transition matrix ,  \cite{seneta2006non}. 
\end{proof}

Based on DMI, an information-theoretic performance measure for each classifier  is naturally defined as . Under this performance measure, the measurement based on noisy labels  is consistent with the measurement based on clean labels , \ie, for every two classifiers  and , 
  


