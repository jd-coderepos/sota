\subsection{Problem settings}

We denote the set of classes by $\mathcal{C}$ and the size of $\mathcal{C}$ by $C$. We also denote the domain of datapoints by $\mathcal{X}$. A classifier is denoted by $h: \mathcal{X}\mapsto \Delta_{\mathcal{C}}$, where $\Delta_{\mathcal{C}}$ is the set of all possible distributions over $\mathcal{C}$. $h$ represents a randomized classifier such that given $x\in \mathcal{X}$, $h(x)_c$ is the probability that $h$ maps $x$ into class $c$. Note that fixing the input $x$, the randomness of a classifier is independent of everything else.




There are $N$ datapoints $\{x_i\}_{i=1}^N$. For each datapoint $x_i$, there is an \emph{unknown} ground truth $y_i\in \mathcal{C}$. We assume that there is an unknown prior distribution $Q_{X,Y}$ over $\mathcal{X}\times \mathcal{C}$ such that $\{(x_i,y_i)\}_{i=1}^N$ are i.i.d. samples drawn from $Q_{X,Y}$ and 
\[Q_{X,Y}(x,y)=\Pr[X=x,Y=y].\]

Note that here we allow the datapoints to be ``imperfect'' instances, \ie, there still exists uncertainty for $Y$ conditioning on fully knowing $X$. 

Traditional supervised learning aims to train a classifier $h^*$ that is able to classify new datapoints into their ground truth categories with access to $\{(x_i,y_i)\}_{i=1}^N$. However, in the setting of learning with noisy labels, instead, we \emph{only} have access to $\{(x_i,\tilde{y}_i)\}_{i=1}^N$ where $\tilde{y}_i$ is a noisy version of $y_i$. 

We use a random variable $\tilde{Y}$ to denote the noisy version of $Y$ and $T_{Y\rightarrow \tilde{Y}}$ to denote the transition distribution between $Y$ and $\title{Y}$, \ie 
\[T_{Y\rightarrow \tilde{Y}}(y,\tilde{y})=\Pr[\tilde{Y}=\tilde{y}|Y=y].\]

We use $\mathbf{T}_{Y\rightarrow \tilde{Y}}$ to represent the $C\times C$ matrix format of $T_{Y\rightarrow \tilde{Y}}$. 

Generally speaking \cite{patrini2017making, ghosh2017robust,  zhang2018generalized}, label noise can be divided into several kinds according to the noise transition matrix $\mathbf{T}_{Y\rightarrow \tilde{Y}}$. It is defined as \emph{class-independent (or uniform)} if a label is substituted by a uniformly random label regardless of the classes, \ie $\Pr[\tilde{Y}=\tilde{c} | Y=c] = \Pr[\tilde{Y}=\tilde{c}' | Y=c], \forall \tilde{c},\tilde{c}' \neq c$ (e.g. $\mathbf{T}_{Y \to \tilde{Y}} = \begin{bmatrix}
    0.7  & 0.3 \\
    0.3 & 0.7 \\
    \end{bmatrix}
    $). It is defined as \emph{diagonally dominant} if for every row of  $\mathbf{T}_{Y\rightarrow \tilde{Y}}$, the magnitude of the diagonal entry is larger than any non-diagonal entry, \ie $\Pr[\tilde{Y}=c | Y=c] > \Pr[\tilde{Y}=\tilde{c} | Y=c], \forall \tilde{c}\neq c$ (e.g. $\mathbf{T}_{Y \to \tilde{Y}} = \begin{bmatrix}
    0.7  & 0.3 \\
    0.2 & 0.8 \\
    \end{bmatrix}
    $).
It is defined as \emph{diagonally non-dominant} if it is not diagonally dominant (e.g. the example mentioned in introduction, $\mathbf{T}_{Y \to \tilde{Y}} = \begin{bmatrix}
    1  & 0 \\
    0.9 & 0.1 \\
    \end{bmatrix}
    $). 

We assume that the noise is independent of the datapoints conditioning on the ground truth, which is commonly assumed in the literature \cite{patrini2017making, ghosh2017robust, zhang2018generalized}, \ie, 

\begin{assumption}[Independent noise]
	$X$ is independent of $\tilde{Y}$ conditioning on $Y$. 
\end{assumption}









We also need that the noisy version $\tilde{Y}$ is still informative. 
 
 \begin{assumption}[Informative noisy label]
	$\mathbf{T}_{Y\rightarrow \tilde{Y}}$ is invertible, \ie, $\det(\mathbf{T}_{Y\rightarrow \tilde{Y}})\neq 0$.
\end{assumption}







\subsection{Information theory concepts}


Since Shannon's seminal work \cite{shannon}, information theory has shown its powerful impact in various of fields, including several recent deep learning works~\cite{hjelm2018learning, cao2018max,kong2018water}. Our work is also inspired by information theory. This section introduces several basic information theory concepts. 

Information theory is commonly related to random variables. For every random variable $W_1$, Shannon's entropy $\text{H}(W_1) := \sum_{w_1} \Pr[W=w_1]\log\Pr[W=w_1]$ measures the uncertainty of $W_1$. For example, deterministic $W_1$ has lowest entropy. For every two random variables $W_1$ and $W_2$, Shannon mutual information $\text{MI}(W_1,W_2):=\sum_{w_1,w_2}\Pr[W_1=w_1,W_2=w_2]\log\frac{\Pr[W=w_1,W=w_2]}{\Pr[W_1=w_1]\Pr[W_2=w_2]}$ measures the amount of relevance between $W_1$ and $W_2$. For example, when $W_1$ and $W_2$ are independent, they have the lowest Shannon mutual information, zero. 

Shannon mutual information is \emph{non-negative}, \emph{symmetric}, \ie, $\text{MI}(W_1,W_2)=\text{MI}(W_2,W_1)$, and also satisfies a desired property, information-monotonicity, \ie, the mutual information between $W_1$ and $W_2$ will always decrease if either $W_1$ or $W_2$ has been ``processed''. 

\begin{fact}[Information-monotonicity \cite{csiszar2004information}]
	For all random variables $W_1,W_2,W_3$, when $W_3$ is less informative for $W_2$ than $W_1$, \ie, $W_3$ is independent of $W_2$ conditioning $W_1$, \[\text{MI}(W_3,W_2)\leq \text{MI}(W_1,W_2).\]
\end{fact}
This property naturally induces that for all random variables $W_1, W_2$, \[\text{MI}(W_1,W_2)\leq \text{MI}(W_2,W_2)=\text{H}(W_2)\] since $W_2$ is always the most informative random variable for itself. 

Based on Shannon mutual information, a performance measure for a classifier $h$ can be naturally defined. High quality classifier's output $h(X)$ should have high mutual information with the ground truth category $Y$. Thus, a classifier $h$'s performance can be measured by $\text{MI}(h(X),Y)$. 

However, in our setting, we only have access to the i.i.d. samples of $h(X)$ and $\tilde{Y}$. A natural attempt is to measure a classifier $h$'s performance by $\text{MI}(h(X),\tilde{Y})$. Unfortunately, under this performance measure, the measurement based on noisy labels $\text{MI}(h(X),\tilde{Y})$ may not be consistent with the measurement based on true labels $\text{MI}(h(X),Y)$. (See a counterexample in Supplementary Material B.) That is,
\[ \forall h,h', \text{MI}(h(X),Y)>\text{MI}(h'(X),Y) \notleftright \text{MI}(h(X),\tilde{Y})> \text{MI}(h'(X),\tilde{Y}). \] Thus, we cannot use Shannon mutual information as the performance measure for classifiers. Here we find that, a generalized mutual information, Determinant based Mutual Information (DMI) \cite{Kong2019}, satisfies the above formula such that under the performance measure based on DMI, the measurement based on noisy labels is consistent with the measurement based on true labels.



\begin{definition}[Determinant based Mutual Information \cite{Kong2019}]\label{def:dmi}
    Given two discrete random variables $W_1, W_2$, we define the Determinant based Mutual Information between $W_1$ and $W_2$ as \[\dmi(W_1, W_2)=|\det(\mathbf{Q}_{W_1,W_2})|\]
    where $\mathbf{Q}_{W_1,W_2}$ is the matrix format of the joint distribution over $W_1$ and $W_2$.   
\end{definition} 

DMI is a generalized version of Shannon's mutual information: it preserves all properties of Shannon mutual information, including non-negativity, symmetry and information-monotonicity and it is additionally relatively invariant. DMI is initially proposed to address a mechanism design problem \cite{Kong2019}. 



\begin{lemma}[Properties of DMI \cite{Kong2019}]
	DMI is non-negative, symmetric and information-monotone. Moreover, it is relatively invariant: for all random variables $W_1, W_2, W_3$, when $W_3$ is less informative for $W_2$ than $W_1$, \ie, $W_3$ is independent of $W_2$ conditioning $W_1$,  \[\dmi(W_2,W_3)=\dmi(W_2,W_1)|\det(\mathbf{T}_{W_1\rightarrow W_3})|\] where $\mathbf{T}_{W_1\rightarrow W_3}$ is the matrix format of \[T_{W_1 \rightarrow W_3}(w_1,w_3)=\Pr[W_3=w_3|W_1=W_1].\]  
\end{lemma}
\begin{proof}
The non-negativity and symmetry follow directly from the definition, so we only need to prove the relatively invariance. Note that
 \[\Pr_{Q_{W_2,W_3}}[W_2=w_2,,W_3=w_3]=\sum_{w_1} \Pr_{Q_{W_1,W_2}}[W_2=w_2, W_1=w_1]\Pr[W_3=w_3|W_1=w_1].\]
as $W_3$ is independent of $W_2$ conditioning on $W_1$. 
Thus, \[\mathbf{Q}_{W_2,W_3}=\mathbf{Q}_{W_2,W_1} \mathbf{T}_{W_1 \rightarrow W_3}\] where $\mathbf{Q}_{W_2,W_3}$, $\mathbf{Q}_{W_2,W_1}$, $\mathbf{T}_{W_1 \rightarrow W_3}$ are the matrix formats of $Q_{W_2,W_3}$, $Q_{W_2,W_1}$, $T_{W_1 \rightarrow W_3}$, respectively. 
We have \[\det(\mathbf{Q}_{W_2,W_3}) = \det(\mathbf{Q}_{W_2,W_1}) \det (\mathbf{T}_{W_1 \rightarrow W_3}) \] because of the multiplication property of the determinant (\ie $\det(\mathbf{AB})=\det(\mathbf{A})\det(\mathbf{B})$ for every two matrices $\mathbf{A}, \mathbf{B}$). Therefore, $\dmi(W_2,W_3)=\dmi(W_2,W_1)|\det(\mathbf{T}_{W_1\rightarrow W_3})|$.

The relative invariance and the symmetry imply the information-monotonicity of DMI. When $W_3$ is less informative for $W_2$ than $W_1$, \ie, $W_3$ is independent of $W_2$ conditioning on $W_1$, 
\begin{align*}
    \dmi(W_3,W_2) = \dmi(W_2,W_3) &= \dmi(W_2,W_1)|\det(\mathbf{T}_{W_1\rightarrow W_3})|\\
     &\leq \dmi(W_2,W_1) = \dmi(W_1,W_2)
\end{align*} because of the fact that for every square transition matrix $\mathbf{T}$, $\det(\mathbf{T})\leq 1$ \cite{seneta2006non}. 
\end{proof}

Based on DMI, an information-theoretic performance measure for each classifier $h$ is naturally defined as $\dmi(h(X),\tilde{Y})$. Under this performance measure, the measurement based on noisy labels $\dmi(h(X),\tilde{Y})$ is consistent with the measurement based on clean labels $\dmi(h(X),Y)$, \ie, for every two classifiers $h$ and $h'$, 
\[ \dmi(h(X),Y)>\dmi(h'(X),Y) \Leftrightarrow \dmi(h(X),\tilde{Y})> \dmi(h'(X),\tilde{Y}). \]  


