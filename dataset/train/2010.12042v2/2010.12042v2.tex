\section{Experiments} \label{sec:exp}
\subsection{Dataset}
EdNet \cite{choi2020ednet} is the largest publicly available benchmark dataset in education domain consisting of interaction logs collected by Santa\footnote{\url{https://aitutorsanta.com}}.
We conduct experiments on an updated version of EdNet-KT1, which contains problem-solving logs from January 1st, 2019 to June 1st, 2020.
Details of the dataset statistics are provided in Table \ref{tab:ednet}.
Also, the distributions of elapsed time and lag time of the dataset are shown in Figure \ref{fig:time_hist}.
We use interaction logs of the most recent 100K students as test set and 80\% (resp. 20\%) of the remaining dataset are used as training (resp. validation) set. 

\begin{table}[ht]
\caption{Statistics of an updated version of EdNet-KT1 dataset.}
\centering
\begin{tabular}{l|c}\toprule
\# of interactions & 60294498 \\
\# of students & 678128 \\
\# of exercises & 14418 \\
\bottomrule
\end{tabular}
\label{tab:ednet}
\end{table}

\begin{figure*}
    \centering
    \begin{subfigure}{0.4\textwidth}
        \includegraphics[width=\textwidth]{figures/elapsed_time.png}
    \end{subfigure}
    \begin{subfigure}{0.4\textwidth}
        \includegraphics[width=\textwidth]{figures/lag_time_short.png}
    \end{subfigure}
    \caption{Distributions of elapsed time and lag time in an updated version of EdNet-KT1.}
    \label{fig:time_hist}
\end{figure*}

\subsection{Baseline Models}
We compare SAINT+ against benchmark knowledge tracing models, DKT \cite{piech_2015}, DKVMN \cite{zhang_2017}, SAKT \cite{pandy_2019} and SAINT \cite{choi2020towards}:
\begin{itemize}
    \item DKT is a simple RNN-based model that uses concept and response correctness as input features, and models student's knowledge status as RNN's hidden state vectors.
    We choose an LSTM \cite{hochreiter1997long} architecture.
    Also, we consider each unique exercise id as a concept associated with the exercise.
    \item DKVMN is a memory augmented neural network based model where the key matrix stores knowledge concepts and the value matrix stores students’ mastery levels of the corresponding concepts.
    We use each exercise id as a concept of the corresponding exercise.
\item SAKT is the first knowledge tracing model that utilizes Transformer's self-attention architecture. 
    It is a single encoder-based model where exercise ids are used as queries and interaction ids are used as keys and values. 
    \item SAINT is the first Transformer-based knowledge tracing model which leverages an encoder-decoder structure to process information of question and student response separately.
    The encoder takes a sequence of question embeddings and the decoder gets a sequence of encoder outputs and response embeddings to compute the final output.
\end{itemize}

\subsection{Model Training and Evaluation}
We use the accuracy (ACC) and the area under the receiver operating characteristic curve (AUC) as the performance metric. We pick the weight with the best validation AUC and evaluate them on the test set.
For SAINT+ and SAINT, we use Adam optimizer with ,  and , and set warmup steps to 4000.
The window size, number of layers, dimension of the model, dropout rate and batch size is set to 100, 4, 512, 0.0 and 64, respectively.
For other benchmark models, both embedding and hidden dimensions of DKT, DKVMN and SAKT are searched over [50, 100, 150, 200, 256, 512], and the best results are reported on the test dataset.
Also, we set the number of latent concepts as 64 for DKVMN. 


\subsection{Main Results}

Table \ref{tab:main} shows the performance comparison of SAINT+ with the benchmark knowledge tracing models.
Compared to the benchmark models, SAINT+ achieves increases of ACC and AUC maximally up to 2.72\% and 3.61\%, respectively.
Also, SAINT+ improves SAINT with 1.03\% and 1.25\% gain in ACC and AUC, respectively, demonstrating the effectiveness of integrating the temporal features for knowledge tracing. 

\begin{table}[ht]
\caption{Comparison of ACC and AUC between benchmark knowledge tracing models and SAINT+.}
\centering
\begin{tabular}{ccc}
\toprule
Model & ACC & AUC \\ 
\midrule
DKT & 0.7060 & 0.7638 \\
DKVMN & 0.7079 & 0.7668 \\
SAKT & 0.7073 & 0.7663 \\
\midrule
SAINT & 0.7178 & 0.7816 \\
SAINT+ & \textbf{0.7252} & \textbf{0.7914} \\
\bottomrule
\end{tabular}
\label{tab:main}
\end{table}

\subsection{Ablation Test}
\subsubsection{Temporal Feature Embedding: Continuous vs. Categorical}
We compare different approaches for embedding temporal features: continuous and categorical.
Modeling elapsed time in continuous (resp. categorical) fashion assumes that the relationship between a student’s knowledge status and the difficulty of a question for the student is a smooth (resp. stepwise) function of time.
Similarly, for lag time, continuous (resp. categorical) modeling addresses various aspects in a students’ learning process including forgetting, re-organizing concepts and improvement change smoothly (resp. discretely) over time.
Table \ref{tab:embedding} show that the best result is obtained when using continuous embedding for elapsed time and categorical embedding for lag time.

\begin{table}[ht]
\caption{Comparison of different approaches for temporal feature embeddings: continuous and categorical for elapsed time and lag time.}
\centering
\begin{tabular}{cccc}
\toprule
Elapsed time & Lag time & ACC & AUC \\ 
\midrule
Continuous & Continuous & 0.7239 & 0.7898 \\
Continuous & Categorical & \textbf{0.7252} & \textbf{0.7914} \\
Categorical & Continuous & 0.7245 & 0.7911 \\
Categorical & Categorical & 0.7235 & 0.7900 \\
\bottomrule
\end{tabular}
\label{tab:embedding}
\end{table}

\subsubsection{Elapsed Time vs. Lag Time}
We verify the contribution of each temporal feature by comparing performance improvements of two variants of SAINT: 1) SAINT with elapsed time only, and 2) SAINT with lag time only.
The results are described in Table \ref{tab:feature}.
When used alone, lag time increases performance more than elapsed time.
Moreover, regardless of the temporal features used, utilizing only one feature is not good as using both features together (SAINT+), while certain improvements are obtained compared to SAINT.

\begin{table}[ht]
\caption{Contribution of each temporal feature.
ET (resp. LT) stands for elapsed time (resp. lag time) and SAINT+ET (resp. SAINT+LT) only uses elapsed time (resp. lag time).}
\centering
\begin{tabular}{ccc}
\toprule
 & ACC & AUC \\ 
\midrule
SAINT & 0.7178 & 0.7816 \\
SAINT + ET & 0.7213 & 0.7858 \\
SAINT + LT & 0.7239 & 0.7898 \\
SAINT + ET + LT & \textbf{0.7252} & \textbf{0.7914} \\
\bottomrule
\end{tabular}
\label{tab:feature}
\end{table}

\subsubsection{Integrating Temporal Features: Encoder vs. Decoder}
The temporal information from the interaction logs, elapsed time and lag time, are provided as decoder features in SAINT+ as described in Figure \ref{fig:model}.
Since both elapsed time and lag time arise as a result of student response, this approach is naturally aligned with the core idea of SAINT that providing exercise information to the encoder and response information to the decoder is appropriate for knowledge tracing.
We compare SAINT+ (decoder only) with other two variants: feeding the temporal features to 1) the encoder only, and 2) both the encoder and the decoder.
Table \ref{tab:encdec} summarizes the results.
As expected, SAINT+ shows the best performance among the variants.
Also, SAINT+ and the variants show better results than SAINT, demonstrating that the temporal features provide useful information for estimating knowledge status.

\begin{table}[ht]
\caption{Comparison of methods for integrating temporal features: encoder only (Enc), decoder only (Dec) and both encoder and decoder (Enc+Dec).}
\centering
\normalsize
\begin{tabular}{ccc}
\toprule
 & ACC & AUC \\ 
\midrule
SAINT & 0.7178 & 0.7816 \\
Enc & 0.7216 & 0.7866 \\
Dec & \textbf{0.7252} & \textbf{0.7914} \\
Enc + Dec & 0.7221 & 0.7872 \\
\bottomrule
\end{tabular}
\label{tab:encdec}
\end{table}