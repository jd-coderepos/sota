\section{Experiments}

We choose representative instance segmentation methods in various paradigms and benchmark them on iShape to reveal the drawbacks of those methods on irregularly shaped objects. All the existing methods are trained and tested on six iShape sub-datasets with their recommended setting. And we further study the effect of our baseline method, ASIS. 

\textbf{Implementation of GMIS*.} Since there is no open-source implementation of GMIS \cite{liu2018affinity} available, we reproduced GMIS as GMIS*. There are only two differences between ASIS and GMIS*. One is the different affinity kernel, and another is GMIS* does not apply OHEM loss.


\textbf{Implementation Details.} The input image resolution of our framework is 512  512. The image data augmentation is flipped horizontally or vertically with a probability of 0.5. We use the ResNet-50 \cite{he2015deep} as our backbone network and the weight is initialized with ImageNet \cite{russakovsky2015imagenet} pretrained model. All experiments are trained in 4 2080Ti GPUs and batch size is set to 8. The stochastic gradient descent (SGD) solver is adopted in 50K iterations. The momentum is set to 0.9 and weight decay is set to 0.0005. The learning rate is initially set to 0.01 and decreases linearly. 

\begin{table}[t]
\caption{Qualitative results on iShape. We report the mask mmAP of six sub-datasets and the average of mmAP. All methods use ResNet-50 as the backbone. ``w/o'' denotes ``without''. \hl{For ``\textbf{62.93}{\tiny /0.05}'', the small number on the right is the standard deviation of four experiments.}} 
    \centering
    \begin{tabular}{c|cccccc|c}
    \toprule[1.5pt]
        Method & Antenna & Branch & Fence & Hanger & Log & Wire & Avg\\
    \hline
        SOLOv2 \cite{wang2020solov2}      &  6.6 & \textbf{27.5} & 0.0 & 28.8 & 22.2 & 0.0 & 14.07\\
    \hline
        PolarMask \cite{xie2020polarmask}   &  0.0 & 0.0 & 0.0 & 0.0 & 18.6 & 0.0& 3.10\\
    \hline
        SE \cite{neven2019instance}  & 38.3 & 0.0 & 0.0 & 49.8 & 20.9 & 0.0 & 18.17 \\
    \hline
        Mask RCNN \cite{maskrcnn}   &  16.9 &  4.2 & 0.0 & 22.1 & 32.6 & 0.0 & 12.63\\
    \hline
        DETR \cite{carion2020endtoend}   &  2.1 &  2.6 & 0.0 & 32.2 & 46.2 & 0.0 & 13.85\\
    \midrule[1pt]
        
        \hl{GMIS* \cite{liu2018affinity}}    & 67.6 \tiny /0.4 &  14.9 \tiny /0.2 & 30.6 \tiny /0.1 & 24.8 \tiny /0.3 & 63.2 \tiny /0.9 & 46.1 \tiny /1.1 & 41.21 \tiny /0.23\\
    \hline
        \hl{ASIS w/o OHEM}    & 82.1 \tiny /0.9 & 17.6 \tiny /0.4 & 48.0 \tiny /0.3 & 40.5 \tiny /0.4 & 66.4 \tiny /0.4 & 66.5 \tiny /0.5 &  53.51 \tiny /0.12  \\
    \hline
        \hl{ASIS(ours)}   & \textbf{88.5} \tiny /0.3  & 24.6 \tiny /0.4  & \textbf{60.4} \tiny /0.4 & \textbf{57.4} \tiny /0.2 & \textbf{69.4} \tiny /0.2 & \textbf{77.3} \tiny /0.4 & \textbf{62.93} \tiny /0.05 \\

    \bottomrule[1.5pt]
    \end{tabular}
    \label{tab:11}
\end{table}


\subsection{Experiment Results}
We evaluate the proposed ASIS and other popular approaches on iShape. The quantitative results are shown in Table \ref{tab:11} and some qualitative results are reported in Figure \ref{fig:result}.

As is shown in Table \ref{tab:11}, the performance of Mask R-CNN \cite{maskrcnn} is far from satisfactory on iShape. We think the drop in performance mainly comes from three drawbacks of the design. Firstly, the feature maps suffer from ambiguity when the IoU is large, which is a common characteristic of crowded scenes of irregular shape objects. Also, Mask R-CNN depends on the proposals of RoI, which may be abandoned by the NMS algorithm due to large IoU and lead to missing of some target objects.  Moreover, many thin objects can not be segmented by Mask R-CNN because of its RoI pooling, which resizes the feature maps and lost the view of thin objects. The recent proposed end-to-end object detection approach, DETR \cite{carion2020endtoend}, shake of the reliance of NMS and can better deal with objects with large IoU and achieve better performance, as shown in the table. However, DETR still suffers from the RoI pooling problems and performs badly on thin objects, as shown in Figure \ref{fig:result}.

We also report some qualitative results of SE \cite{neven2019instance} in Figure \ref{fig:result}. As is shown in the figure, one common failure case of SE is that when the length of irregular objects is longer than a threshold, the object will be split into multi instances,  for example, the wire in Figure \ref{fig:result}. We think that's because SE will regress a circle of the target instance and then calculate its IoU with the mask for supervision. However, for long and thin irregular objects, the radius of the center circle can not reach the length of the target object, leading to a multi-split of a long instance. Also, instances that share the same center may cause ambiguity to SE, such as hanger and fence in Figure \ref{fig:result}. Moreover, many centers of irregular objects lie outside the mask, making it hard to match them to the objects themselves. 

We evaluate SOLO v2 \cite{wang2020solov2} on the proposed iShape and find that it failed to segment instances that share the same center, for example, fences in Figure \ref{fig:result}. Also, since SOLO V2 depends on the center point as SE, it also suffers from performance drop caused by object centers that lie outside the mask. 


\begin{figure}
\centering
    {\begin{minipage}[t]{0.45\linewidth}
    \subfigure[]{
    \includegraphics[width=0.45\linewidth]{image/experiment/4104.jpg}\label{badcase-merge-one}
    }
    \subfigure[]{
    \includegraphics[width=0.45\linewidth]{image/experiment/3945.jpg}\label{badcase-messed}
    }
    \caption{Two example false cases of ASIS on iShape-Antenna. (a) Two antennas merged into one (blue and orange). (b) ASIS fails to connect the right parts of an object (red and sky blue).}
    \label{fig:badcase}
    \end{minipage}}
    \hspace{5mm}
    {\begin{minipage}[t]{0.45\linewidth}
    \subfigure[ASIS]{
    \includegraphics[width=0.45\linewidth]{image/experiment/grad-v2-3928-53.jpg}\label{asis_loss}
    }
    \subfigure[GMIS]{
    \includegraphics[width=0.45\linewidth]{image/experiment/grad-v2-3928-56.jpg}\label{gmis_loss}
    }
    \caption{\hl{Activation maps of different affinity kernels. We calculate the loss for affinities that connects to the yellow point and perform backpropagate, then visualize the gradient on the input image to reveal the activated maps.}}
    \label{fig:loss_vis}
    \end{minipage}}

\end{figure}

In Table \ref{tab:11}, we report the performance of PolarMask \cite{xie2020polarmask} on our dataset. As is shown in the table, PolarMask can not solve the instance segmentation of irregular objects. That is because PolarMask can only represent a thirty-six-side mask due to its limited number of rays. Hence, it can not handle objects with hollow, for example, the fences. Also, they distinguish different instances according to center regression, which, however, can not handle instances that share the same center. We also find that PolarMask can only tackle some cases of logs in iShape, which looks like circles on the side and fit its convex hull mask setting.  

Thanks to the perception and reasoning mechanism as well as the well-designed affinity kernels of our ASIS, it obtained the best performance on iShape. In Table \ref{tab:11}, ASIS advances GMIS* \cite{liu2018affinity} by 21.7\%, advances other popular approaches by 44.2\%. However, there are still some drawbacks to the design of ASIS and some failure cases caused by them. For example in Figure \ref{badcase-merge-one}, two instances are merged into one. We think that's because the graph merge algorithm is a kind of greedy algorithm, while the greedy algorithm makes optimal decisions locally instead of looking for a global optimum. Hence, ASIS is not robust to false-positive (FP) with high confidence. Also, ASIS fails to connect the two parts of an object if they are far away from each other, for example, the antenna on Figure \ref{badcase-messed}. We think that's because CNN is not good at learning long-range affinity. Another failure case is the branch in Figure \ref{fig:result}, ASIS results on iShape-Branch include many parts that have not been merged. Those parts lead to a large number of small FPs, which causes a serious performance drop.

\begin{figure}[h]
    \centering
    \includegraphics[width=.99\linewidth]{image/experiment/exp3.pdf}
    \caption{Qualitative results of different instance segmentation approaches on iShape. More results are shown in \url{https://ishape.github.io} or the appendix.}
    \label{fig:result}
    \vspace{-1em}
\end{figure}

\subsection{Ablation Study}


\begin{table}[h]
\caption{\hl{Ablation Study} of GMIS and ASIS on iShape-Antenna. ``SY'' and ``ASY'' indicate a centrosymmetric or asymmetric affinity kernel respectively.  denotes equipped with and  not.}
    \centering
    \begin{tabular}{c|c|c|c|c}
    \toprule[1.5pt]
         
         
        Affinity Kernel & Neighbors & Affinity GT & OHEM & mAP \\
        \hline
        \multirow{4}{*}{GMIS \cite{liu2018affinity}} & \multirow{3}{*}{56 (SY)} &  &  & 67.6\\ \cline{3-5}
         & &  &  & 81.5 \\ \cline{3-5}
         & &  &  - & 90.2 \\ 
        \cline{2-5}
         & 28 (ASY) &  &  & 77.7 \\
        \hline
        \multirow{3}{*}{ASIS(ours)} & \multirow{3}{*}{53 (ASY)} &  &  & 82.1\\
        \cline{3-5}
         & &  &  & 88.5 \\ \cline{3-5}
         & &  & - & 98.5 \\ 
    \bottomrule[1.5pt]
    \end{tabular}
    \label{tab:ablation}
\end{table}


\textbf{Effect of ASIS kernel.} In Table \ref{tab:11}, ASIS kernel advances GMIS kernel by 12.3\% in iShape. We think that is because our well-designed affinity kernels based on dataset property can better discover the connectivity of different parts of an object. While the GMIS kernel suffers from its sparsity in distance and angle, examples are shown in Figure \ref{3928gmis} \hl{and Figure \ref{fig:aff_vis} shows the reason for its failure through the affinity visualization}. In Table \ref{tab:ablation}, we also use ground truth affinity map to explore the upper bound of ASIS, where a 98.5\% mAP is achieved, showing its great potential. Moreover, we find our non-centrosymmetric design of affinity kernel outperform centrosymmetric one by 10\% in the table. We think such a design cut off the output and calculation redundancy and reduce the requirement of large receptive field from CNN, simplifying representation learning. \hl{Inspired by Grad-CAM \cite{selvaraju2017grad}, we use the gradient of the input image to visualize the model's activation map. As shown in Figure \ref{fig:loss_vis}, ASIS pays more attention to the discriminative information such as the instance outline, while GMIS focuses more on the area around the center point.}

\textbf{Effect of OHEM.} Table \ref{tab:11} and Table \ref{tab:ablation} show that OHEM boosts the performance of ASIS and GMIS by a large margin. We think firstly that is because OHEM can ease problems caused by the imbalance distribution of positive and negative affinity. Besides, affinities that connect segments of fragmented instances are important but hard to learn, which means the OHEM loss pays more attention to these important affinities. 

\begin{figure}
\centering
    {\begin{minipage}[t]{0.45\linewidth}
    \subfigure[ASIS]{
    \includegraphics[width=0.45\linewidth]{image/ASIS/3928asis.png}\label{3928asis}
    }
    \subfigure[GMIS]{
    \includegraphics[width=0.45\linewidth]{image/ASIS/3928gmis.png}\label{3928gmis}
    }
    \caption{Results compared with GMIS kernel. As shown in (b), GMIS kernel fail to connect segments that belong to one instance.}
    \label{fig:badcase}
    \end{minipage}}
    \hspace{5mm}
    {\begin{minipage}[t]{0.45\linewidth}
    \subfigure[ASIS]{
    \includegraphics[width=0.45\linewidth]{image/experiment/aff-v1-3928-53.jpg}\label{asis_aff_vis}
    }
    \subfigure[GMIS]{
    \includegraphics[width=0.45\linewidth]{image/experiment/aff-v1-3928-56.jpg}\label{gmis_aff_vis}
    }
    \caption{\hl{Affinity visualization. The yellow point is the kernel center. The ASIS kernel has a more reasonable affinity distribution and can connect the two separated parts, while GMIS fails to reach the right segment.}}
    \label{fig:aff_vis}
    \end{minipage}}
\end{figure}