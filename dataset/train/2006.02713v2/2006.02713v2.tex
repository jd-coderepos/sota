\documentclass{article}







\usepackage[final,nonatbib]{neurips_2020}





\usepackage{amsmath,amsfonts,bm}

\newcommand{\figleft}{{\em (Left)}}
\newcommand{\figcenter}{{\em (Center)}}
\newcommand{\figright}{{\em (Right)}}
\newcommand{\figtop}{{\em (Top)}}
\newcommand{\figbottom}{{\em (Bottom)}}
\newcommand{\captiona}{{\em (a)}}
\newcommand{\captionb}{{\em (b)}}
\newcommand{\captionc}{{\em (c)}}
\newcommand{\captiond}{{\em (d)}}

\newcommand{\newterm}[1]{{\bf #1}}


\def\figref#1{figure~\ref{#1}}
\def\Figref#1{Figure~\ref{#1}}
\def\twofigref#1#2{figures \ref{#1} and \ref{#2}}
\def\quadfigref#1#2#3#4{figures \ref{#1}, \ref{#2}, \ref{#3} and \ref{#4}}
\def\secref#1{section~\ref{#1}}
\def\Secref#1{Section~\ref{#1}}
\def\twosecrefs#1#2{sections \ref{#1} and \ref{#2}}
\def\secrefs#1#2#3{sections \ref{#1}, \ref{#2} and \ref{#3}}
\def\eqref#1{equation~\ref{#1}}
\def\Eqref#1{Equation~\ref{#1}}
\def\plaineqref#1{\ref{#1}}
\def\chapref#1{chapter~\ref{#1}}
\def\Chapref#1{Chapter~\ref{#1}}
\def\rangechapref#1#2{chapters\ref{#1}--\ref{#2}}
\def\algref#1{algorithm~\ref{#1}}
\def\Algref#1{Algorithm~\ref{#1}}
\def\twoalgref#1#2{algorithms \ref{#1} and \ref{#2}}
\def\Twoalgref#1#2{Algorithms \ref{#1} and \ref{#2}}
\def\partref#1{part~\ref{#1}}
\def\Partref#1{Part~\ref{#1}}
\def\twopartref#1#2{parts \ref{#1} and \ref{#2}}

\def\ceil#1{\lceil #1 \rceil}
\def\floor#1{\lfloor #1 \rfloor}
\def\1{\bm{1}}
\newcommand{\train}{\mathcal{D}}
\newcommand{\valid}{\mathcal{D_{\mathrm{valid}}}}
\newcommand{\test}{\mathcal{D_{\mathrm{test}}}}

\def\eps{{\epsilon}}


\def\reta{{\textnormal{}}}
\def\ra{{\textnormal{a}}}
\def\rb{{\textnormal{b}}}
\def\rc{{\textnormal{c}}}
\def\rd{{\textnormal{d}}}
\def\re{{\textnormal{e}}}
\def\rf{{\textnormal{f}}}
\def\rg{{\textnormal{g}}}
\def\rh{{\textnormal{h}}}
\def\ri{{\textnormal{i}}}
\def\rj{{\textnormal{j}}}
\def\rk{{\textnormal{k}}}
\def\rl{{\textnormal{l}}}
\def\rn{{\textnormal{n}}}
\def\ro{{\textnormal{o}}}
\def\rp{{\textnormal{p}}}
\def\rq{{\textnormal{q}}}
\def\rr{{\textnormal{r}}}
\def\rs{{\textnormal{s}}}
\def\rt{{\textnormal{t}}}
\def\ru{{\textnormal{u}}}
\def\rv{{\textnormal{v}}}
\def\rw{{\textnormal{w}}}
\def\rx{{\textnormal{x}}}
\def\ry{{\textnormal{y}}}
\def\rz{{\textnormal{z}}}

\def\rvepsilon{{\mathbf{\epsilon}}}
\def\rvtheta{{\mathbf{\theta}}}
\def\rva{{\mathbf{a}}}
\def\rvb{{\mathbf{b}}}
\def\rvc{{\mathbf{c}}}
\def\rvd{{\mathbf{d}}}
\def\rve{{\mathbf{e}}}
\def\rvf{{\mathbf{f}}}
\def\rvg{{\mathbf{g}}}
\def\rvh{{\mathbf{h}}}
\def\rvu{{\mathbf{i}}}
\def\rvj{{\mathbf{j}}}
\def\rvk{{\mathbf{k}}}
\def\rvl{{\mathbf{l}}}
\def\rvm{{\mathbf{m}}}
\def\rvn{{\mathbf{n}}}
\def\rvo{{\mathbf{o}}}
\def\rvp{{\mathbf{p}}}
\def\rvq{{\mathbf{q}}}
\def\rvr{{\mathbf{r}}}
\def\rvs{{\mathbf{s}}}
\def\rvt{{\mathbf{t}}}
\def\rvu{{\mathbf{u}}}
\def\rvv{{\mathbf{v}}}
\def\rvw{{\mathbf{w}}}
\def\rvx{{\mathbf{x}}}
\def\rvy{{\mathbf{y}}}
\def\rvz{{\mathbf{z}}}

\def\erva{{\textnormal{a}}}
\def\ervb{{\textnormal{b}}}
\def\ervc{{\textnormal{c}}}
\def\ervd{{\textnormal{d}}}
\def\erve{{\textnormal{e}}}
\def\ervf{{\textnormal{f}}}
\def\ervg{{\textnormal{g}}}
\def\ervh{{\textnormal{h}}}
\def\ervi{{\textnormal{i}}}
\def\ervj{{\textnormal{j}}}
\def\ervk{{\textnormal{k}}}
\def\ervl{{\textnormal{l}}}
\def\ervm{{\textnormal{m}}}
\def\ervn{{\textnormal{n}}}
\def\ervo{{\textnormal{o}}}
\def\ervp{{\textnormal{p}}}
\def\ervq{{\textnormal{q}}}
\def\ervr{{\textnormal{r}}}
\def\ervs{{\textnormal{s}}}
\def\ervt{{\textnormal{t}}}
\def\ervu{{\textnormal{u}}}
\def\ervv{{\textnormal{v}}}
\def\ervw{{\textnormal{w}}}
\def\ervx{{\textnormal{x}}}
\def\ervy{{\textnormal{y}}}
\def\ervz{{\textnormal{z}}}

\def\rmA{{\mathbf{A}}}
\def\rmB{{\mathbf{B}}}
\def\rmC{{\mathbf{C}}}
\def\rmD{{\mathbf{D}}}
\def\rmE{{\mathbf{E}}}
\def\rmF{{\mathbf{F}}}
\def\rmG{{\mathbf{G}}}
\def\rmH{{\mathbf{H}}}
\def\rmI{{\mathbf{I}}}
\def\rmJ{{\mathbf{J}}}
\def\rmK{{\mathbf{K}}}
\def\rmL{{\mathbf{L}}}
\def\rmM{{\mathbf{M}}}
\def\rmN{{\mathbf{N}}}
\def\rmO{{\mathbf{O}}}
\def\rmP{{\mathbf{P}}}
\def\rmQ{{\mathbf{Q}}}
\def\rmR{{\mathbf{R}}}
\def\rmS{{\mathbf{S}}}
\def\rmT{{\mathbf{T}}}
\def\rmU{{\mathbf{U}}}
\def\rmV{{\mathbf{V}}}
\def\rmW{{\mathbf{W}}}
\def\rmX{{\mathbf{X}}}
\def\rmY{{\mathbf{Y}}}
\def\rmZ{{\mathbf{Z}}}

\def\ermA{{\textnormal{A}}}
\def\ermB{{\textnormal{B}}}
\def\ermC{{\textnormal{C}}}
\def\ermD{{\textnormal{D}}}
\def\ermE{{\textnormal{E}}}
\def\ermF{{\textnormal{F}}}
\def\ermG{{\textnormal{G}}}
\def\ermH{{\textnormal{H}}}
\def\ermI{{\textnormal{I}}}
\def\ermJ{{\textnormal{J}}}
\def\ermK{{\textnormal{K}}}
\def\ermL{{\textnormal{L}}}
\def\ermM{{\textnormal{M}}}
\def\ermN{{\textnormal{N}}}
\def\ermO{{\textnormal{O}}}
\def\ermP{{\textnormal{P}}}
\def\ermQ{{\textnormal{Q}}}
\def\ermR{{\textnormal{R}}}
\def\ermS{{\textnormal{S}}}
\def\ermT{{\textnormal{T}}}
\def\ermU{{\textnormal{U}}}
\def\ermV{{\textnormal{V}}}
\def\ermW{{\textnormal{W}}}
\def\ermX{{\textnormal{X}}}
\def\ermY{{\textnormal{Y}}}
\def\ermZ{{\textnormal{Z}}}

\def\vzero{{\bm{0}}}
\def\vone{{\bm{1}}}
\def\vmu{{\bm{\mu}}}
\def\vtheta{{\bm{\theta}}}
\def\va{{\bm{a}}}
\def\vb{{\bm{b}}}
\def\vc{{\bm{c}}}
\def\vd{{\bm{d}}}
\def\ve{{\bm{e}}}
\def\vf{{\bm{f}}}
\def\vg{{\bm{g}}}
\def\vh{{\bm{h}}}
\def\vi{{\bm{i}}}
\def\vj{{\bm{j}}}
\def\vk{{\bm{k}}}
\def\vl{{\bm{l}}}
\def\vm{{\bm{m}}}
\def\vn{{\bm{n}}}
\def\vo{{\bm{o}}}
\def\vp{{\bm{p}}}
\def\vq{{\bm{q}}}
\def\vr{{\bm{r}}}
\def\vs{{\bm{s}}}
\def\vt{{\bm{t}}}
\def\vu{{\bm{u}}}
\def\vv{{\bm{v}}}
\def\vw{{\bm{w}}}
\def\vx{{\bm{x}}}
\def\vy{{\bm{y}}}
\def\vz{{\bm{z}}}

\def\evalpha{{\alpha}}
\def\evbeta{{\beta}}
\def\evepsilon{{\epsilon}}
\def\evlambda{{\lambda}}
\def\evomega{{\omega}}
\def\evmu{{\mu}}
\def\evpsi{{\psi}}
\def\evsigma{{\sigma}}
\def\evtheta{{\theta}}
\def\eva{{a}}
\def\evb{{b}}
\def\evc{{c}}
\def\evd{{d}}
\def\eve{{e}}
\def\evf{{f}}
\def\evg{{g}}
\def\evh{{h}}
\def\evi{{i}}
\def\evj{{j}}
\def\evk{{k}}
\def\evl{{l}}
\def\evm{{m}}
\def\evn{{n}}
\def\evo{{o}}
\def\evp{{p}}
\def\evq{{q}}
\def\evr{{r}}
\def\evs{{s}}
\def\evt{{t}}
\def\evu{{u}}
\def\evv{{v}}
\def\evw{{w}}
\def\evx{{x}}
\def\evy{{y}}
\def\evz{{z}}

\def\mA{{\bm{A}}}
\def\mB{{\bm{B}}}
\def\mC{{\bm{C}}}
\def\mD{{\bm{D}}}
\def\mE{{\bm{E}}}
\def\mF{{\bm{F}}}
\def\mG{{\bm{G}}}
\def\mH{{\bm{H}}}
\def\mI{{\bm{I}}}
\def\mJ{{\bm{J}}}
\def\mK{{\bm{K}}}
\def\mL{{\bm{L}}}
\def\mM{{\bm{M}}}
\def\mN{{\bm{N}}}
\def\mO{{\bm{O}}}
\def\mP{{\bm{P}}}
\def\mQ{{\bm{Q}}}
\def\mR{{\bm{R}}}
\def\mS{{\bm{S}}}
\def\mT{{\bm{T}}}
\def\mU{{\bm{U}}}
\def\mV{{\bm{V}}}
\def\mW{{\bm{W}}}
\def\mX{{\bm{X}}}
\def\mY{{\bm{Y}}}
\def\mZ{{\bm{Z}}}
\def\mBeta{{\bm{\beta}}}
\def\mPhi{{\bm{\Phi}}}
\def\mLambda{{\bm{\Lambda}}}
\def\mSigma{{\bm{\Sigma}}}

\DeclareMathAlphabet{\mathsfit}{\encodingdefault}{\sfdefault}{m}{sl}
\SetMathAlphabet{\mathsfit}{bold}{\encodingdefault}{\sfdefault}{bx}{n}
\newcommand{\tens}[1]{\bm{\mathsfit{#1}}}
\def\tA{{\tens{A}}}
\def\tB{{\tens{B}}}
\def\tC{{\tens{C}}}
\def\tD{{\tens{D}}}
\def\tE{{\tens{E}}}
\def\tF{{\tens{F}}}
\def\tG{{\tens{G}}}
\def\tH{{\tens{H}}}
\def\tI{{\tens{I}}}
\def\tJ{{\tens{J}}}
\def\tK{{\tens{K}}}
\def\tL{{\tens{L}}}
\def\tM{{\tens{M}}}
\def\tN{{\tens{N}}}
\def\tO{{\tens{O}}}
\def\tP{{\tens{P}}}
\def\tQ{{\tens{Q}}}
\def\tR{{\tens{R}}}
\def\tS{{\tens{S}}}
\def\tT{{\tens{T}}}
\def\tU{{\tens{U}}}
\def\tV{{\tens{V}}}
\def\tW{{\tens{W}}}
\def\tX{{\tens{X}}}
\def\tY{{\tens{Y}}}
\def\tZ{{\tens{Z}}}


\def\gA{{\mathcal{A}}}
\def\gB{{\mathcal{B}}}
\def\gC{{\mathcal{C}}}
\def\gD{{\mathcal{D}}}
\def\gE{{\mathcal{E}}}
\def\gF{{\mathcal{F}}}
\def\gG{{\mathcal{G}}}
\def\gH{{\mathcal{H}}}
\def\gI{{\mathcal{I}}}
\def\gJ{{\mathcal{J}}}
\def\gK{{\mathcal{K}}}
\def\gL{{\mathcal{L}}}
\def\gM{{\mathcal{M}}}
\def\gN{{\mathcal{N}}}
\def\gO{{\mathcal{O}}}
\def\gP{{\mathcal{P}}}
\def\gQ{{\mathcal{Q}}}
\def\gR{{\mathcal{R}}}
\def\gS{{\mathcal{S}}}
\def\gT{{\mathcal{T}}}
\def\gU{{\mathcal{U}}}
\def\gV{{\mathcal{V}}}
\def\gW{{\mathcal{W}}}
\def\gX{{\mathcal{X}}}
\def\gY{{\mathcal{Y}}}
\def\gZ{{\mathcal{Z}}}

\def\sA{{\mathbb{A}}}
\def\sB{{\mathbb{B}}}
\def\sC{{\mathbb{C}}}
\def\sD{{\mathbb{D}}}
\def\sF{{\mathbb{F}}}
\def\sG{{\mathbb{G}}}
\def\sH{{\mathbb{H}}}
\def\sI{{\mathbb{I}}}
\def\sJ{{\mathbb{J}}}
\def\sK{{\mathbb{K}}}
\def\sL{{\mathbb{L}}}
\def\sM{{\mathbb{M}}}
\def\sN{{\mathbb{N}}}
\def\sO{{\mathbb{O}}}
\def\sP{{\mathbb{P}}}
\def\sQ{{\mathbb{Q}}}
\def\sR{{\mathbb{R}}}
\def\sS{{\mathbb{S}}}
\def\sT{{\mathbb{T}}}
\def\sU{{\mathbb{U}}}
\def\sV{{\mathbb{V}}}
\def\sW{{\mathbb{W}}}
\def\sX{{\mathbb{X}}}
\def\sY{{\mathbb{Y}}}
\def\sZ{{\mathbb{Z}}}

\def\emLambda{{\Lambda}}
\def\emA{{A}}
\def\emB{{B}}
\def\emC{{C}}
\def\emD{{D}}
\def\emE{{E}}
\def\emF{{F}}
\def\emG{{G}}
\def\emH{{H}}
\def\emI{{I}}
\def\emJ{{J}}
\def\emK{{K}}
\def\emL{{L}}
\def\emM{{M}}
\def\emN{{N}}
\def\emO{{O}}
\def\emP{{P}}
\def\emQ{{Q}}
\def\emR{{R}}
\def\emS{{S}}
\def\emT{{T}}
\def\emU{{U}}
\def\emV{{V}}
\def\emW{{W}}
\def\emX{{X}}
\def\emY{{Y}}
\def\emZ{{Z}}
\def\emSigma{{\Sigma}}

\newcommand{\etens}[1]{\mathsfit{#1}}
\def\etLambda{{\etens{\Lambda}}}
\def\etA{{\etens{A}}}
\def\etB{{\etens{B}}}
\def\etC{{\etens{C}}}
\def\etD{{\etens{D}}}
\def\etE{{\etens{E}}}
\def\etF{{\etens{F}}}
\def\etG{{\etens{G}}}
\def\etH{{\etens{H}}}
\def\etI{{\etens{I}}}
\def\etJ{{\etens{J}}}
\def\etK{{\etens{K}}}
\def\etL{{\etens{L}}}
\def\etM{{\etens{M}}}
\def\etN{{\etens{N}}}
\def\etO{{\etens{O}}}
\def\etP{{\etens{P}}}
\def\etQ{{\etens{Q}}}
\def\etR{{\etens{R}}}
\def\etS{{\etens{S}}}
\def\etT{{\etens{T}}}
\def\etU{{\etens{U}}}
\def\etV{{\etens{V}}}
\def\etW{{\etens{W}}}
\def\etX{{\etens{X}}}
\def\etY{{\etens{Y}}}
\def\etZ{{\etens{Z}}}

\newcommand{\pdata}{p_{\rm{data}}}
\newcommand{\ptrain}{\hat{p}_{\rm{data}}}
\newcommand{\Ptrain}{\hat{P}_{\rm{data}}}
\newcommand{\pmodel}{p_{\rm{model}}}
\newcommand{\Pmodel}{P_{\rm{model}}}
\newcommand{\ptildemodel}{\tilde{p}_{\rm{model}}}
\newcommand{\pencode}{p_{\rm{encoder}}}
\newcommand{\pdecode}{p_{\rm{decoder}}}
\newcommand{\precons}{p_{\rm{reconstruct}}}

\newcommand{\laplace}{\mathrm{Laplace}} 

\newcommand{\E}{\mathbb{E}}
\newcommand{\Ls}{\mathcal{L}}
\newcommand{\R}{\mathbb{R}}
\newcommand{\emp}{\tilde{p}}
\newcommand{\lr}{\alpha}
\newcommand{\reg}{\lambda}
\newcommand{\rect}{\mathrm{rectifier}}
\newcommand{\softmax}{\mathrm{softmax}}
\newcommand{\sigmoid}{\sigma}
\newcommand{\softplus}{\zeta}
\newcommand{\KL}{D_{\mathrm{KL}}}
\newcommand{\Var}{\mathrm{Var}}
\newcommand{\standarderror}{\mathrm{SE}}
\newcommand{\Cov}{\mathrm{Cov}}
\newcommand{\normlzero}{L^0}
\newcommand{\normlone}{L^1}
\newcommand{\normltwo}{L^2}
\newcommand{\normlp}{L^p}
\newcommand{\normmax}{L^\infty}

\newcommand{\parents}{Pa} 

\DeclareMathOperator*{\argmax}{arg\,max}
\DeclareMathOperator*{\argmin}{arg\,min}

\DeclareMathOperator{\sign}{sign}
\DeclareMathOperator{\Tr}{Tr}
\let\ab\allowbreak
 


\usepackage[utf8]{inputenc} \usepackage[T1]{fontenc}    \usepackage{hyperref}       \usepackage{url}            \usepackage{subcaption,booktabs}
\usepackage{amsfonts}       \usepackage{nicefrac}       \usepackage{microtype}      \usepackage{amsmath}
\usepackage{algorithm}
\usepackage{algorithmic}
\usepackage[dvipsnames]{xcolor}
\usepackage{makecell}
\usepackage{graphicx}

\usepackage{lineno}
\usepackage{lipsum}




\usepackage[symbol]{footmisc}
\renewcommand{\thefootnote}{\fnsymbol{footnote}}

\hypersetup{colorlinks,linkcolor={red},citecolor={NavyBlue},urlcolor={red}}  



\usepackage{array}
\newcolumntype{C}[1]{>{\centering\arraybackslash}m{#1}}
\newcolumntype{R}[1]{>{\raggedleft\arraybackslash}m{#1}}
\newcolumntype{P}[1]{>{\raggedright\arraybackslash}p{#1}}
\newcolumntype{M}[1]{>{\centering\arraybackslash}m{#1}}
\usepackage{multirow}


\newcommand{\etal}{\textit{et al}.}
\newcommand{\ie}{\textit{i}.\textit{e}., }
\newcommand{\eg}{\textit{e}.\textit{g}., }
\newcommand{\etc}{\textit{etc}. }

\title{Self-paced Contrastive Learning with Hybrid Memory for Domain Adaptive Object Re-ID}





\author{Yixiao Ge  \quad Feng Zhu  \quad Dapeng Chen  \quad Rui Zhao  \quad Hongsheng Li \1ex]\texttt{\{yxge@link,hsli@ee\}.cuhk.edu.hk} \quad \texttt{dapengchenxjtu@gmail.com} \\
}

\begin{document}

\maketitle

\footnotetext[1]{Dapeng Chen is the corresponding author.}

\begin{abstract}
\vspace{-5pt}

Domain adaptive object re-ID aims to transfer the learned knowledge from the labeled source domain to the unlabeled target domain to tackle the open-class re-identification problems. Although state-of-the-art pseudo-label-based methods \cite{ge2020mutual,zhai2020ad,yang2019selfsimilarity,zhang2019self,ge2020structured} have achieved great success, they did not make full use of all valuable information because of the domain gap and unsatisfying clustering performance. To solve these problems, we propose a novel self-paced contrastive learning framework with hybrid memory. The hybrid memory dynamically generates source-domain class-level, target-domain cluster-level and un-clustered instance-level supervisory signals for learning feature representations. Different from the conventional contrastive learning strategy, the proposed framework jointly distinguishes source-domain classes, and target-domain clusters and un-clustered instances. Most importantly, the proposed self-paced method gradually creates more reliable clusters to refine the hybrid memory and learning targets, and is shown to be the key to our outstanding performance. Our method outperforms state-of-the-arts on multiple domain adaptation tasks of object re-ID and even boosts the performance on the source domain without any extra annotations. Our generalized version on unsupervised object re-ID surpasses state-of-the-art algorithms by considerable \textbf{16.7\%} and \textbf{7.9\%} on Market-1501 and MSMT17 benchmarks\footnotemark[2]. 


\footnotetext[2]{Code is available at \url{https://github.com/yxgeee/SpCL}.}

\end{abstract}


\section{Introduction}
\vspace{-5pt}

Unsupervised domain adaptation (UDA) for object re-identification (re-ID) aims at transferring the learned knowledge from the labeled source domain (dataset) to properly measure the inter-instance affinities in the unlabeled target domain (dataset). 
Common object re-ID problems include person re-ID and vehicle re-ID, 
where the source-domain and target-domain data do not share the same identities (classes).
Existing UDA methods on object re-ID \cite{song2018unsupervised,ge2020mutual,zhai2020ad,yang2019selfsimilarity,zhang2019self,wang2020unsupervised} generally tackled this problem following a two-stage training scheme: (1) supervised pre-training on the source domain, and (2) unsupervised fine-tuning on the target domain.
For stage-2 unsupervised fine-tuning, a pseudo-label-based strategy was found effective in state-of-the-art methods \cite{ge2020mutual,zhai2020ad,yang2019selfsimilarity,zhang2019self},
which alternates between 
generating pseudo classes by clustering target-domain instances and 
training the network with generated pseudo classes. In this way, the source-domain pre-trained network can be adapted to capture the inter-sample relations in the target domain with noisy pseudo-class labels.


Although the pseudo-label-based methods have led to great performance advances, we argue that there exist two major limitations that hinder their further improvements (Figure \ref{fig:intro} (a)). 
(1) During the target-domain fine-tuning, the source-domain images were either not considered \cite{ge2020mutual,zhai2020ad,yang2019selfsimilarity,zhang2019self} or were even found harmful to the final performance \cite{ge2020structured} because of the limitations of their methodology designs. 
The accurate source-domain ground-truth labels are valuable but were ignored during target-domain training. 
(2) Since the clustering process might result in individual outliers, to ensure the reliability of the generated pseudo labels, existing methods \cite{ge2020mutual,yang2019selfsimilarity,zhang2019self,ge2020structured} simply discarded the outliers from being used for training. However, such outliers might actually be difficult but valuable samples in the target domain and there are generally many outliers especially in early epochs. Simply abandoning them might critically hurt the final performance. 



\begin{figure}[t]
\centering
\includegraphics[width=1.0\linewidth]{./intro.pdf}
\caption{State-of-the-arts \cite{ge2020mutual,yang2019selfsimilarity,zhang2019self,zhai2020ad} on UDA object re-ID discarded both the source-domain data and target-domain un-clustered data for training, while our proposed self-paced contrastive learning framework fully exploits all available data with hybrid memory for joint feature learning.}
\label{fig:intro}
\end{figure}

To overcome the problems, we propose a \textit{hybrid memory} to encode all available information from both source and target domains for feature learning. 
For the source-domain data, their ground-truth class labels can naturally provide valuable supervisions. 
For the target-domain data, clustering can be conducted to obtain relatively confident clusters as well as un-clustered outliers. 
All the source-domain class centroids, target-domain cluster centroids, and target-domain un-clustered instance features from the hybrid memory can provide supervisory signals for jointly learning discriminative feature representations across the two domains (Figure \ref{fig:intro} (b)). 
A unified framework is developed for dynamically updating and distinguishing different entries in the proposed hybrid memory.

Specifically, since all the target-domain clusters and un-clustered instances are equally treated as independent classes, the clustering reliability would significantly impact the learned representations. 
We thus propose a \textit{self-paced contrastive learning} strategy, which initializes the learning process by using the hybrid memory with the most reliable target-domain clusters.
Trained with such reliable clusters, the discriminativeness of feature representations can be gradually improved and additional reliable clusters can be formed by incorporating more un-clustered instances into the new clusters.
Such a strategy can effectively mitigate the effects of noisy pseudo labels and boost the feature learning process.
To properly measure the cluster reliability, a novel multi-scale clustering reliability criterion is proposed, based on which only reliable clusters are preserved and other confusing clusters are disassembled back to un-clustered instances.
In this way,
our self-paced learning strategy gradually creates more reliable clusters to dynamically refine the hybrid memory and learning targets.


Our contributions are summarized as three-fold.
(1) 
We propose a unified contrastive learning framework to incorporate all available information from both source and target domains for joint feature learning. It dynamically updates the hybrid memory to provide class-level, cluster-level and instance-level supervisions.
(2) 
We design a self-paced contrastive learning strategy with a novel clustering reliability criterion to prevent training error amplification caused by noisy pseudo-class labels. It gradually generates more reliable target-domain clusters for learning better features in the hybrid memory, which in turn, improves clustering. 
(3) 
Our method significantly outperforms state-of-the-arts \cite{ge2020mutual,zhai2020ad,yang2019selfsimilarity,zhang2019self,wang2020unsupervised} on multiple domain adaptation tasks of object re-ID with up to \textbf{5.0\%} mAP gains. 
The proposed unified framework could even boost the performance on the source domain with large margins (\textbf{6.6\%}) by jointly training with un-annotated target-domain data,
while most existing UDA methods ``forget'' the source domain after fine-tuning on the target domain. 
Our unsupervised version without labeled source-domain data on object re-ID task significantly outperforms state-of-the-arts~\cite{lin2020unsupervised,wang2020unsupervised,zeng2020hierarchical} by \textbf{16.7\%} and \textbf{7.9\%} in terms of mAP on Market-1501 and MSMT17 benchmarks.



\section{Related Works}
\vspace{-5pt}

\paragraph{Unsupervised domain adaptation (UDA) for object re-ID.}
Existing UDA methods for object re-ID can be divided into two main categories, including pseudo-label-based methods~\cite{song2018unsupervised,yang2019selfsimilarity,zhang2019self,ge2020mutual,zhai2020ad,zhong2019invariance,yu2019unsupervised,wang2020unsupervised} and domain translation-based methods~\cite{deng2018image,wei2018person,chen2019instance,ge2020structured}.
This paper follows the former one since the pseudo labels were found more effective to capture the target-domain distributions.
Though driven by different motivations,
previous pseudo-label-based methods generally adopted a two-stage training scheme: 
(1) pre-training on the source domain with ground-truth IDs, and
(2) adapting the target domain with pseudo labels.
The pseudo labels can be generated by either clustering instance features~\cite{song2018unsupervised,yang2019selfsimilarity,zhang2019self,ge2020mutual,zhai2020ad} or measuring similarities with exemplar features~\cite{zhong2019invariance,yu2019unsupervised,wang2020unsupervised},
where the clustering-based pipeline maintains state-of-the-art performance to date.
The major challenges faced by clustering-based methods is how to improve the precision of pseudo labels and how to mitigate the effects caused by noisy pseudo labels.
SSG~\cite{yang2019selfsimilarity} adopted human local features to assign multi-scale pseudo labels. 
PAST~\cite{zhang2019self} introduced to utilize multiple regularizations alternately.
MMT~\cite{ge2020mutual} proposed to generate more robust soft labels via the mutual mean-teaching.
AD-Cluster~\cite{zhai2020ad} incorporated style-translated images to improve the discriminativeness of instance features.
Although various attempts along this direction have led to great performance advances,
they ignored to fully exploit all valuable information across the two domains which limits their further improvements,
\ie they simply discarded both the source-domain labeled images and target-domain un-clustered outliers when fine-tuning the model on the target domain with pseudo labels.




\vspace{-5pt}
\paragraph{Contrastive learning.}
State-of-the-art methods on unsupervised visual representation learning~\cite{oord2018representation,wu2018unsupervised,hjelm2019learning,tian2019contrastive,zhuang2019local,he2019momentum,chen2020simple} are based on the contrastive learning.
Being cast as either the dictionary look-up task~\cite{wu2018unsupervised,he2019momentum} or the consistent learning task~\cite{tian2019contrastive,chen2020simple},
a contrastive loss was adopted to learn instance discriminative representations by treating each unlabeled sample as a distinct class.
Although the instance-level contrastive loss could be used to train embeddings that can be generalized well to downstream tasks with fine-tuning,
it does not perform well on the domain adaptive object re-ID tasks which require to correctly 
measure the inter-class affinities 
on the unsupervised target domain.


\vspace{-5pt}
\paragraph{Self-paced learning.}
The ``easy-to-hard'' training scheme
is at the core of self-paced learning~\cite{kumar2010self},
which was originally found effective in supervised learning methods, especially with noisy labels~\cite{guo2018curriculumnet,jiang2018mentornet,lin2017active,ge2020self}.
Recently, some methods~\cite{tang2012shifting,guo2019adaptive,choi2019pseudo,zhang2017curriculum,zou2018unsupervised} incorporated the conception of self-paced learning into unsupervised learning tasks by starting the training process with the most confident pseudo labels.
However, the self-paced policies designed in these methods were all based on the close-set problems with pre-defined classes, which cannot be generalized to our open-set object re-ID task with completely unknown classes on the target domain.
Moreover,
they did not consider how to plausibly train with hard samples that cannot be assigned confident pseudo labels all the time.



\section{Methodology}
\vspace{-5pt}

\begin{figure}[t]
\centering
\includegraphics[width=1.0\linewidth]{./framework.pdf}
\caption{(a) The illustration of the proposed unified framework with a novel hybrid memory. 
(b) The proposed reliability criterion for measuring the cluster independence\protect\footnotemark[3] and compactness.}
\label{fig:fm}
\end{figure}

\footnotetext[3]{Throughout this paper, the term \textit{independence} is used in its idiomatic sense rather than the statistical sense.}

To tackle the challenges in unsupervised domain adaptation (UDA) on object re-ID, we propose a self-paced contrastive learning framework (Figure \ref{fig:fm} (a)), which consists of a CNN \cite{lecun1989backpropagation}-based encoder  and a novel hybrid memory. The key innovation of the proposed framework lies in jointly training the encoder with all the source-domain class-level, target-domain cluster-level and target-domain un-clustered instance-level supervisions, which are dynamically updated in the hybrid memory to gradually provide more confident learning targets. In order to avoid training error amplification caused by noisy clusters, the self-paced learning strategy initializes the training process with the most reliable clusters and gradually incorporates more un-clustered instances to form new reliable clusters. A novel reliability criterion is introduced to measure the quality of clusters (Figure \ref{fig:fm} (b)).

Our training scheme alternates between two steps: 
(1) grouping the target-domain samples into clusters and un-clustered instances by clustering the target-domain instance features in the hybrid memory with the self-paced strategy (Section \ref{sec:selfpaced}), and
(2) optimizing the encoder  with a unified contrastive loss and dynamically updating the hybrid memory with encoded features (Section \ref{sec:contrastive}).




\subsection{Constructing and Updating Hybrid Memory for Contrastive Learning}
\label{sec:contrastive}
\vspace{-5pt}

Given the target-domain training samples  without any ground-truth label, 
we employ 
the self-paced clustering strategy (Section \ref{sec:selfpaced}) to group the samples into clusters and the un-clustered outliers. 
The whole training set of both domains can therefore be divided into three parts, including the source-domain samples  with ground-truth identity labels, the target-domain pseudo-labeled data  within clusters and the target-domain instances  not belonging to any cluster, \ie . 
State-of-the-art UDA methods~\cite{ge2020mutual,zhai2020ad,yang2019selfsimilarity,zhang2019self} 
simply abandon all source-domain data and target-domain un-clustered instances, and 
utilize only the target-domain pseudo labels for adapting the network to the target domain, which, in our opinion, is a sub-optimal solution.
Instead, we design a novel contrastive loss to fully exploit available data  by treating all the source-domain classes, target-domain clusters and target-domain un-clustered instances as independent classes.  






\subsubsection{Unified Contrastive Learning} 
\vspace{-5pt}

Given a general feature vector , our unified contrastive loss is

where  indicates the positive class prototype corresponding to ,
the temperature  is empirically set as 
and  denotes the inner product between two feature vectors to measure their similarity. 
 is the number of source-domain classes,  is the number of target-domain clusters and  is the number of target-domain un-clustered instances.
More specifically, if  is a source-domain feature,  is the centroid of the source-domain class  that  belongs to. 
If  belongs to the -th target-domain cluster,  is the -th cluster centroid. 
If  is a target-domain un-clustered outlier, we would have  as the outlier instance feature corresponding to . Intuitively, the above joint contrastive loss encourages the encoded feature vector to approach its assigned classes, clusters or instances. 
Note that we utilize class centroids  instead of learnable class weights for encoding source-domain classes to match their semantics to those of the clusters' or outliers' centroids. Our experiments (Section \ref{sec:ablation}) show that, if the semantics of class-level, cluster-level and instance-level supervisions do not match, the performance drops significantly.

\vspace{-5pt}
\paragraph{Discussion.}
The most significant difference between our unified contrastive loss (Eq. (\ref{eq:joint})) and previous contrastive losses \cite{wu2018unsupervised,he2019momentum,chen2020simple,oord2018representation} is that ours jointly distinguishes classes, clusters, and un-clustered instances, while previous ones only focus on separating instances without considering any ground-truth classes or pseudo-class labels as our method does. 
They target at instance discrimination task but fail in properly modeling intra-/inter-class affinities on domain adaptive re-ID tasks.


\subsubsection{Hybrid Memory} 
\vspace{-5pt}

As the cluster number  and outlier instance number  may change during training with the alternate clustering strategy, the class prototypes for the unified contrastive loss (Eq. (\ref{eq:joint})) are built in a non-parametric and dynamic manner. 
We propose a novel hybrid memory to provide
the source-domain class centroids , target-domain cluster centroids  and target-domain un-clustered instance features 
.
For continuously storing and updating the above three types of entries,
we propose to cache source-domain \textit{class} centroids  and all the target-domain \textit{instance} features  simultaneously in the hybrid memory,
where  is the number of all the target-domain instances and .
Without loss of generality, we assume that un-clustered features in  have indices , while other clustered features in  have indices from  to .
In other words,  dynamically form the cluster centroids  while  remain un-clustered instances.




\vspace{-5pt}
\paragraph{Memory initialization.} 
The hybrid memory is initialized with the extracted features 
by performing forward computation of :
the initial source-domain class centroids  can be obtained as the mean feature vectors of each class, while the initial target-domain instance features  are directly encoded by . 
After that, the target-domain cluster centroids  are initialized with the mean feature vectors of each cluster from , \ie
\vspace{-5pt}

where  denotes the -th cluster set that contains all the feature vectors within cluster  and  denotes the number of features in the set.
Note that the source-domain class centroids  and the target-domain instance features  are only initialized once by performing the forward computation at the beginning of the learning algorithm, and then can be continuously updated during training.


\vspace{-5pt}
\paragraph{Memory update.} 
At each iteration, 
the encoded feature vectors in each mini-batch would be involved in hybrid memory updating. 
For the source-domain class centroids , the -th centroid  is updated by the mean of the encoded features belonging to class  in the mini-batch as

where  denotes the feature set belonging to source-domain class  in the current mini-batch and  is a momentum coefficient for updating source-domain class centroids.  is empirically set as .



The target-domain cluster centroids cannot be stored and updated in the same way as the source-domain class centroids, since the clustered set  and un-clustered set  are constantly changing. 
As the hybrid memory caches all the target-domain features , each encoded feature vector  in the mini-batch is utilized to update its corresponding instance entry  by

where  is the momentum coefficient for update target-domain instance features and is set as  in our experiments.
Given the updated instance memory , 
if  belongs to the cluster ,
the corresponding centroid  needs to be updated with Eq. (\ref{eq:centroid}).







\vspace{-5pt}
\paragraph{Discussion.}
The hybrid memory has two main differences from the memory used in \cite{wu2018unsupervised,he2019momentum}:
(1) Our hybrid memory caches prototypes for both the centroids and instances, while the memory in \cite{wu2018unsupervised,he2019momentum} only provides instance-level prototypes. Other than the centroids, we for the first time treat clusters and instances as equal classes;
(2) The cluster/instance learning targets provided by our hybrid memory are gradually updated and refined, while previous memory \cite{wu2018unsupervised,he2019momentum} only supports fixed instance-level targets. Note that our self-paced strategy (will be discussed in Section \ref{sec:selfpaced}) dynamically determines confident clusters and un-clustered instances.

The momentum updating strategy is inspired by \cite{he2019momentum,tarvainen2017mean}, and we further introduce how to update hybrid prototypes, \ie centroids and instances.
Note that we employ different updating strategies for class centroids (Eq. (\ref{eq:m_cen})) and cluster centroids (Eq. (\ref{eq:m_ins})\&(\ref{eq:centroid})) since source-domain classes are fixed while target-domain clusters are dynamically changed.






\subsection{Self-paced Learning with Reliable Clusters}
\label{sec:selfpaced}
\vspace{-5pt}


A simple way to split the target-domain data into clusters  and un-clustered outliers  is to cluster the target-domain instance features  from the hybrid memory by a certain algorithm (\eg DBSCAN \cite{ester1996density}).
Since all the target-domain clusters and un-clustered outlier instances are treated as distinct classes in Eq. (\ref{eq:joint}), the clustering reliability would significantly impact the learned representations.
If the clustering is perfect, merging all the instances into their true clusters would no doubt improve the final performance (denotes as ``oracle'' in Table \ref{tab:ablation}). 
However, in practice, merging an instance into a wrong cluster does more harm than good. 
A self-paced learning strategy is therefore introduced, where in the re-clustering step before each epoch, only the most reliable clusters are preserved and the unreliable clusters are disassembled back to un-clustered instances.
A reliability criterion is proposed to identify unreliable clusters by measuring the independence and compactness.


\vspace{-5pt}
\paragraph{Independence of clusters.}
A reliable cluster should be independent from other clusters and individual samples. Intuitively, if a cluster is far away from other samples, it can be considered as highly independent. However, due to the uneven density in the latent space, we cannot na\"ively use the distances between the cluster centroid and outside-cluster samples to measure the cluster independence. 
Generally, the clustering results can be tuned by altering certain hyper-parameters of the clustering criterion. 
One can \textit{loosen} the clustering criterion to possibly include \textit{more} samples in each cluster or \textit{tighten} the clustering criterion to possibly include \textit{fewer} samples in each cluster.
We denote the samples within the same cluster of  as .
We propose the following metric to measure the cluster independence, which is formulated as an intersection-over-union (IoU) score,

where 
 is the cluster set containing  when the clustering criterion becomes looser.
Larger  indicates a more independent cluster for , \ie even one looses the clustering criterion, there would be no more sample to be included into the new cluster .
Samples within the same cluster set (\eg ) generally have the same independence score.

\vspace{-5pt}
\paragraph{Compactness of clusters.}
A reliable cluster should also be {compact}, \ie the samples within the same cluster should have small inter-sample distances.
In an extreme case, when a cluster is most compact, all the samples in the cluster have zero inter-sample distances.
Its samples would not be split into different clusters even when the clustering criterion is tightened. 
Based on this assumption, we can define the following metric to determine the compactness of the clustered point  as

where  is the cluster set containing  when tightening the criterion.
Larger  indicates smaller inter-sample distances around  within , since a cluster with larger inter-sample distances is more likely to include fewer points when a tightened criterion is adopted. 
The same cluster's data points may have different compactness scores due to the uneven density.



Given the above metrics for measuring the cluster reliability,
we could compute the independence and compactness scores for each data point within clusters.
We set up  as independence and compactness thresholds for determining reliable clusters.
Specifically,
we preserve independent clusters with compact data points whose
 and ,
while the remaining data are treated as un-clustered outlier instances. 
With the update of the encoder  and target-domain instance features  from the hybrid memory,
more reliable clusters can be gradually created to further improve the feature learning. 
The overall algorithm is detailed in Alg. \ref{alg} of Appendix \ref{sec:app_alg}. 




\section{Experiments}
\vspace{-5pt}

\subsection{Datasets and Evaluation Protocol}
\vspace{-5pt}

\vspace{-10pt}
\begin{table}[h]
	\tiny
    \caption{Statistics of the datasets used for training and evaluation. (*) denotes the synthetic datasets.}
	\label{tab:dataset}
	\centering
	\begin{tabular}{P{2.3cm}|C{1.4cm}C{1.4cm}C{1.4cm}C{1.5cm}C{1.4cm}C{1.4cm}}
    Dataset & \# train IDs & \# train images & \# test IDs & \# query images & \# cameras & \# total images \\
    \Xhline{2\arrayrulewidth}
    Market-1501~\cite{market} & 751 & 12,936 & 750 & 3,368 & 6 & 32,217 \\
MSMT17~\cite{wei2018person} & 1,041 & 32,621 & 3,060 & 11,659 & 15 & 126,441 \\
    PersonX~\cite{sun2019dissecting}* & 410 & 9,840 & 856 & 5,136 & 6 & 45,792 \\
\hline
    VeRi-776~\cite{liu2016deep} & 575 & 37,746 & 200 & 1,678 & 20 & 51,003 \\
    VehicleID~\cite{liuhy2016deep} & 13,164 & 113,346 & 800 & 5,693 & - & 221,763  \\
VehicleX~\cite{naphade20204th}* & 1,362 & 192,150 & - & - & 11 & 192,150 \\
	\end{tabular}
\end{table}
\vspace{-5pt}

We evaluate our proposed method on both the mainstream realreal adaptation tasks and the more challenging syntheticreal adaptation tasks in person re-ID and vehicle re-ID problems.
As shown in Table \ref{tab:dataset},
two real-world person datasets and one synthetic person dataset, as well as two real-world vehicle datasets and one synthetic vehicle dataset, are adopted in our experiments.


\vspace{-5pt}
\paragraph{Person re-ID datasets\protect\footnotemark[2].}
The Market-1501 and MSMT17 are widely used real-world person image datasets in domain adaptive tasks, among which, MSMT17 has the most images and is most challenging.
The synthetic PersonX~\cite{sun2019dissecting} is generated based on Unity~\cite{riccitiello2015john} with manually designed obstacles, \eg random occlusion, resolution and illumination differences, \etc

\footnotetext[2]{DukeMTMC-reID \cite{dukemtmc} dataset has been taken down and should no longer be used.}

\vspace{-5pt}
\paragraph{Vehicle re-ID datasets.}
Although domain adaptive person re-ID has been long studied,
the same task on the vehicle has not been fully explored.
We conduct experiments with the real-world
VeRi-776, VehicleID and the synthetic VehicleX datasets.
VehicleX~\cite{naphade20204th} is also generated by the Unity engine~\cite{yao2019simulating,tang2019pamtri}
and further translated to have the real-world style by SPGAN~\cite{deng2018image}.


\vspace{-5pt}
\paragraph{Evaluation protocol.}
In the experiments, 
only ground-truth IDs on the source-domain datasets are provided for training. Mean average precision (mAP) and cumulative matching characteristic (CMC), proposed in \cite{market}, are adopted to evaluate the methods' performances on the target-domain datasets.
No post-processing technique, \eg re-ranking \cite{zhong2017re} or multi-query fusion \cite{market}, is adopted.


\subsection{Implementation Details}
\label{sec:imp}
\vspace{-5pt}

We adopt an ImageNet-pretrained~\cite{deng2009imagenet} ResNet-50~\cite{he2016deep} as the backbone for the encoder .
Following the clustering-based UDA methods~\cite{ge2020mutual,yang2019selfsimilarity,song2018unsupervised}, 
we use DBSCAN~\cite{ester1996density} 
for clustering before each epoch.
The maximum distance between neighbor points, which is the most important parameter in DBSCAN,
is tuned to loosen or tighten the clustering in our proposed self-paced learning strategy.
We use a constant threshold  and dynamic threshold  for identifying independent clusters with the most compact points by the reliability criterion.
More details can be found in Appendix 
\ref{sec:app_imp}.



\subsection{Comparison with State-of-the-arts}
\vspace{-5pt}




\begin{table}[t]
\tiny
    \caption{
	Comparison with state-of-the-art methods on unsupervised domain adaptation for object re-ID.
	(*) the implementation is based on the authors' code.}
	\label{tab:sota}
\begin{subtable}[t]{0.51\textwidth}
	\vspace{-5pt}
\caption{\textit{Realreal} adaptation on person re-ID datasets.}
	\label{tab:sota_a}
\begin{tabular}{P{1cm}C{0.8cm}|C{0.5cm}C{0.5cm}C{0.5cm}C{0.6cm}}
\multicolumn{2}{c|}{\multirow{2}{*}{Methods}} & \multicolumn{4}{c}{Market-1501MSMT17} \\
	\cline{3-6}
	\multicolumn{2}{c|}{} & mAP & top-1 & top-5 & top-10  \\ 
	\Xhline{2\arrayrulewidth}
    \multicolumn{1}{l|}{PTGAN~\cite{wei2018person}} & CVPR'18 & 2.9 & 10.2 & - & 24.4  \\    
    \multicolumn{1}{l|}{ECN~\cite{zhong2019invariance}} & CVPR'19 & 8.5 & 25.3 & 36.3 & 42.1  \\
    \multicolumn{1}{l|}{SSG~\cite{yang2019selfsimilarity}} & ICCV'19 & 13.2 & 31.6 &- & 49.6  \\
    \multicolumn{1}{l|}{ECN++~\cite{zhong2020learning}} & TPAMI'20 & 15.2 & 40.4 & 53.1 & 58.7  \\
    \multicolumn{1}{l|}{MMT-{\tiny means}~\cite{ge2020mutual}} & ICLR'20 & 22.9 & 49.2 & {63.1} & {68.8} \\
   \multicolumn{1}{l|}{MMCL~\cite{wang2020unsupervised}} & CVPR'20 & 15.1 & 40.8 & 51.8 & 56.7  \\
   \multicolumn{1}{l|}{DG-Net++~\cite{zou2020joint}} & ECCV'20 & {22.1} & {48.4} & {60.9} & {66.1}  \\
   \multicolumn{1}{l|}{D-MMD \cite{mekhazni2020unsupervised}}&  ECCV'20 & 13.5 & 29.1 & 46.3 & 54.1   \\
   \multicolumn{1}{l|}{JVTC \cite{li2020joint}} & ECCV'20 &   20.3 & 45.4 & 58.4 & 64.3  \\
   \multicolumn{1}{l|}{GPR \cite{luogeneralizing}} & ECCV'20 &  {20.4} & {43.7} & {56.1} & {61.9}  \\
   \multicolumn{1}{l|}{NRMT \cite{zhao2020unsupervised}} & ECCV'20 &  19.8 & 43.7 & 56.5 & 62.2   \\
    \multicolumn{1}{l|}{MMT-dbscan~\cite{ge2020mutual}*} & ICLR'20 & \underline{24.0} & \underline{50.1} & \underline{63.5} & \underline{69.3}  \\
    \hline 
    \-2.3ex]
	\multicolumn{2}{c|}{\textbf{Ours}} & \textbf{77.5} & \textbf{89.7} & \textbf{96.1} & \textbf{97.6} \\
\end{tabular}
\end{subtable}
\begin{subtable}[t]{0.51\textwidth}
	\vspace{-5pt}
	\begin{subtable}[t]{1.0\textwidth}
\caption{\textit{Syntheticreal} adaptation on person re-ID datasets.}
	\label{tab:sota_b}
\begin{tabular}{P{1cm}C{0.8cm}|C{0.5cm}C{0.5cm}C{0.5cm}C{0.6cm}}
\multicolumn{2}{c|}{\multirow{2}{*}{Methods}} & \multicolumn{4}{c}{PersonXMSMT17} \\
	\cline{3-6}
	\multicolumn{2}{c|}{} & mAP & top-1 & top-5 & top-10  \\ 
\Xhline{2\arrayrulewidth}
    \multicolumn{1}{l|}{MMT-{\tiny dbscan}~\cite{ge2020mutual}*} & ICLR'20 &  17.7 & 39.1 & 52.6 & 58.5   \\
    \hline 
    \-2.3ex]
	\multicolumn{2}{c|}{\textbf{Ours}} & \textbf{73.8} & \textbf{88.0} & \textbf{95.3} & {96.9}     \\
\end{tabular}
	\end{subtable}\\
\begin{subtable}[t]{1.0\textwidth}
\caption{\textit{Realreal} and \textit{syntheticreal} adaptation on vehicle re-ID datasets.}
	\label{tab:sota_c}
\begin{tabular}{P{1cm}C{0.8cm}|C{0.5cm}C{0.5cm}C{0.5cm}C{0.6cm}}
\multicolumn{2}{c|}{\multirow{2}{*}{Methods}} & \multicolumn{4}{c}{VehicleIDVeRi-776}  \\
	\cline{3-6}
	\multicolumn{2}{c|}{} & mAP & top-1 & top-5 & top-10  \\ 
\Xhline{2\arrayrulewidth}
    \multicolumn{1}{l|}{MMT-{\tiny dbscan}~\cite{ge2020mutual}*} & ICLR'20 & 35.3 & 74.6 & 82.6 & 87.0\\
    \hline 
    \-2.3ex]
	\multicolumn{2}{c|}{\textbf{Ours}} & \textbf{38.9} & \textbf{81.3} & \textbf{87.3} & \textbf{90.0}  \\
\end{tabular}
	\end{subtable}
	\end{subtable}
\end{table}



\begin{table}[t]
	\tiny
\vspace{-10pt}
    \caption{
    Comparison with state-of-the-art UDA methods and supervised learning methods when evaluating on the labeled source domain. 
	(*) the implementation is based on the authors' code.}
	\label{tab:source}
\centering
	\vspace{2pt}
	\begin{tabular}{P{1.6cm}C{1.2cm}|C{1.1cm}C{0.7cm}C{0.7cm}C{0.7cm}|C{1cm}C{0.7cm}C{0.7cm}C{0.7cm}}
\multicolumn{2}{c|}{\multirow{2}{*}{Methods}} & \multicolumn{4}{c|}{MSMT17\textcolor{gray}{Market-1501}} & \multicolumn{4}{c}{Market-1501\textcolor{gray}{MSMT17}} \\
	\cline{3-10}
	\multicolumn{2}{c|}{} & mAP & top-1 & top-5 & top-10 & mAP & top-1 & top-5 & top-10 \\ 
\Xhline{2\arrayrulewidth}
\multicolumn{1}{l|}{MMT-dbscan~\cite{ge2020mutual}*} & ICLR'20 & 3.2 & 9.8 & 16.8 & 20.7 & 30.7 & 59.9 & 75.7 & 81.3  \\
    \hline 
    \-2.3ex]
	\multicolumn{2}{c|}{\textbf{Ours \textit{w/o} source data}}  & \textbf{73.1} & \textbf{88.1} & \textbf{95.1} & \textbf{97.0}   \\
	\end{tabular}
 	\end{subtable}
 	\begin{subtable}{0.5\textwidth}
 	
 	\begin{subtable}{1.0\textwidth}
	\begin{tabular}{P{0.8cm}C{0.8cm}|C{0.5cm}C{0.5cm}C{0.5cm}C{0.6cm}}
\multicolumn{2}{c|}{\multirow{2}{*}{Methods}} & \multicolumn{4}{c}{MSMT17} \\
	\cline{3-6}
	\multicolumn{2}{c|}{} & mAP & top-1 & top-5 & top-10 \\ 
\Xhline{2\arrayrulewidth}
	\multicolumn{1}{l|}{MMCL~\cite{wang2020unsupervised}} & CVPR'20  & \underline{11.2}	& \underline{35.4} & 	\underline{44.8} &	\underline{49.8} \\
	\multicolumn{1}{l|}{MoCo~\cite{he2019momentum}*} & CVPR'20 & 1.6 & 4.3 & 9.7 & 13.5 \\
    \hline 
    \-2.3ex]
	\multicolumn{2}{c|}{\textbf{Ours \textit{w/o} source data}}  & \textbf{36.9} & \textbf{79.9} & \textbf{86.8} & \textbf{89.9}  \\
	\end{tabular}
 	\end{subtable}
 	
 	\end{subtable}
\end{table}


\paragraph{UDA performance on the target domain.}

We compare our proposed framework with state-of-the-art UDA methods on multiple domain adaptation tasks in Table \ref{tab:sota}, including three realreal and three syntheticreal tasks.
The tasks in Tables \ref{tab:sota_b} \& \ref{tab:sota_c} were not surveyed by previous methods, so we implement state-of-the-art MMT~\cite{ge2020mutual} on these datasets for comparison.
Our method significantly outperforms all state-of-the-arts on both person and vehicle datasets with a plain ResNet-50 backbone, achieving 2-4\%  improvements in terms of mAP on the common realreal tasks and up to 5.0\% increases on the challenging syntheticreal tasks.
An inspiring discovery is that the syntheticreal task could achieve competitive performance as the realreal task with the same target-domain dataset (\eg VeRi-776), which indicates that we are one more step closer towards no longer needing any manually annotated real-world images in the future.

\vspace{-5pt}
\paragraph{Further improvements on the source domain.}


State-of-the-art UDA methods inevitably forget the source-domain knowledge after fine-tuning the pretrained networks on the target domain,
as demonstrated by MMT \cite{ge2020mutual} in Table \ref{tab:source}.
In contrast, our proposed unified framework could effectively model complex inter-sample relations across the two domains, 
boosting the source-domain performance 
by up to 6.6\% mAP.
Note that experiments of ``Encoder train/test on the source domain'' adopt the same training objective (Eq. (\ref{eq:joint})) as our proposed method, except for that only source-domain class centroids  are available.
Our method also outperforms state-of-the-art supervised re-ID methods~\cite{ge2018fd,zheng2019joint,zhou2019osnet,sun2020circle} on the source domain
without either using multiple losses or more complex networks.
Such a phenomenon indicates that our method could be applied to improve the supervised training by incorporating unlabeled data without extra human labor.

\vspace{-5pt}
\paragraph{Unsupervised re-ID without any labeled training data.}

Another stream of research focuses on training the re-ID model without any labeled data, \ie excluding source-domain data from the training set.
Our method can be easily generalized to such a setting by discarding the source-domain class centroids  from both the hybrid memory and training objective (See Alg. \ref{alg_un} in Appendix \ref{sec:app_alg} for details).
As shown in Table \ref{tab:unsupervised}, our method considerably outperforms state-of-the-arts by up to 16.7\% improvements in terms of mAP.
We also implement state-of-the-art unsupervised method MoCo~\cite{he2019momentum}, which adopts the conventional contrastive loss, and unfortunately, it is inapplicable on unsupervised re-ID tasks.
MoCo~\cite{he2019momentum} underperforms because it treats each instance as a single class, while the core of re-ID tasks is to encode and model intra-/inter-class variations. MoCo~\cite{he2019momentum} is good at unsupervised pre-training but its resulting networks need finetuning with (pseudo) class labels.



\subsection{Ablation Studies}
\label{sec:ablation}
\vspace{-5pt}

\begin{table}[t]
	\tiny
\vspace{-10pt}
    \caption{
    Ablation studies of our proposed self-paced contrastive learning on individual components.}
	\label{tab:ablation}
\begin{subtable}[t]{0.54\textwidth}
\vspace{-5pt}
\caption{Experiments on domain adaptive person re-ID.}
\label{tab:ablation_a}
	\begin{tabular}{P{3.4cm}|C{0.4cm}C{0.5cm}C{0.5cm}C{0.6cm}}
	\multicolumn{1}{c|}{\multirow{2}{*}{Methods}} & \multicolumn{4}{c}{MSMTMarket-1501} \\
	\cline{2-5}
	\multicolumn{1}{c|}{} & mAP & top-1 & top-5 & top-10  \\ 
    \Xhline{2\arrayrulewidth}
    \multicolumn{5}{l}{\textit{analysis of the unified contrastive learning mechanism:}} \\
    \hline
    \textit{Src.} class & 25.3 & 51.3 & 69.6 & 76.6  \\
    \textit{Src.} class + \textit{tgt.} instance & 4.9 & 12.6 & 24.8 & 32.7 \\
    \textit{Src.} class + \textit{tgt.} cluster (\textit{w/o} self-paced) & 28.9 & 50.1 & 64.5 & 71.0 \\
    \textit{Src.} class + \textit{tgt.} cluster (\textit{w/} self-paced) & 69.2 & 84.9 & 94.0 & 96.4 \\
    \hline
    \textit{Src.} class  \textit{Src.} learnable weights & 70.7 & 86.9 & 94.1 & 96.3  \\
    Ours \textit{w/o} unified contrast & 68.8 & 84.6 & 94.1 & 96.2 \\
    \hline 
\multicolumn{5}{l}{\textit{analysis of the self-paced learning strategy:}} \\
    \hline
    Ours \textit{w/o}  & 74.5 & 89.1 & 95.3 & 96.8   \\
    Ours \textit{w/o}  & 75.4 & 89.3 & 95.5 & 97.1   \\
    Ours \textit{w/o}  & 76.6 & 89.5 & 95.6 & 97.3  \\
    \hline 
Oracle & 83.5 & 93.1 & 97.7 & 98.6  \\
	\textbf{Ours (full)} & \textbf{77.5} & \textbf{89.7} & \textbf{96.1} & \textbf{97.6} \\
	\end{tabular}
\end{subtable}
	\begin{subtable}[t]{0.5\textwidth}
	\vspace{-5pt}
\caption{Experiments on unsupervised person re-ID.}
\label{tab:ablation_b}
	\begin{tabular}{P{2.4cm}|C{0.4cm}C{0.5cm}C{0.5cm}C{0.6cm}}
	\multicolumn{1}{c|}{\multirow{2}{*}{Methods}} & \multicolumn{4}{c}{Market-1501} \\
	\cline{2-5}
	\multicolumn{1}{c|}{} & mAP & top-1 & top-5 & top-10  \\ 
    \Xhline{2\arrayrulewidth}
    \multicolumn{5}{l}{\textit{analysis of the unified contrastive learning mechanism:}} \\
    \hline
\textit{tgt.} instance & 3.5 & 9.1 & 18.7 & 25.8 \\
   \textit{tgt.} cluster (\textit{w/o} self-paced) & 6.7 & 16.5 & 27.9 & 33.8  \\
    \textit{tgt.} cluster (\textit{w/} self-paced) & 10.1 & 23.9 & 37.3 & 43.2  \\
    \hline
Ours \textit{w/o} unified contrast & 57.0 & 76.2 & 89.7 & 93.0 \\
    \hline 
    \multicolumn{5}{l}{\textit{analysis of the self-paced learning strategy:}} \\
    \hline
    Ours \textit{w/o}  & 68.2 & 85.0 & 93.3 & 95.3  \\
    Ours \textit{w/o}  & 68.6 & 86.2 & 93.9 & 95.8 \\
    Ours \textit{w/o}  & 71.8 & 87.5 & 95.0 & 96.8  \\
    \hline 
	Oracle & 82.3 & 92.6 & 97.2 & 98.4 \\
\textbf{Ours (full) \textit{w/o} source data} & \textbf{73.1} & \textbf{88.1} & \textbf{95.1} & \textbf{97.0} \\
	\end{tabular}
	\end{subtable}
\end{table}

We analyse the effectiveness of our proposed unified contrastive loss with hybrid memory and self-paced learning strategy in Table \ref{tab:ablation}.
The ``oracle'' experiment adopts the target-domain ground-truth IDs as cluster labels for training, reflecting the maximal performance with our pipeline.

\vspace{-5pt}
\paragraph{Unified contrastive learning mechanism.}
In order to verify the necessity of each type of classes in the unified contrastive loss (Eq. (\ref{eq:joint})),
we conduct experiments when removing any one of the source-domain class-level, target-domain cluster-level or un-clustered instance-level supervisions (Table \ref{tab:ablation_a}).
Baseline ``\textit{Src.} class'' adopts only source-domain images with ground-truth IDs for training.
``\textit{Src.} class + \textit{tgt.} instance'' 
treats each target-domain sample as a distinct class.
It totally fails with even worse results than the baseline ``\textit{Src.} class'', 
showing that directly generalizing conventional contrastive loss to UDA tasks is inapplicable.
``\textit{Src.} class + \textit{tgt.} cluster'' follows existing UDA methods~\cite{ge2020mutual,yang2019selfsimilarity,zhang2019self,ge2020structured}, by simply discarding un-clustered instances from training.
Noticeable performance drops are observed,
especially without the self-paced policy to constrain reliable clusters.
Note that the only difference between ``\textit{Src.} class + \textit{tgt.} cluster (\textit{w/} self-paced)'' and ``Ours (full)'' is whether using outliers for training and the large performance gaps are due to the facts that:
1) There are many un-clustered outliers ( half of all samples), especially in early epochs;
2) Outliers serve as difficult samples and excluding them over-simplifies the training task;
3) ``\textit{Src.} class + \textit{tgt.} cluster'' doesn’t update outliers in the memory, making them unsuitable to be clustered in the later epochs.

As illustrated in Table \ref{tab:ablation_b}, we further verify the necessity of unified training in unsupervised object re-ID tasks. We observe the same trend as domain adaptive tasks: solving the problem via instance discrimination (``\textit{tgt.} instance'') would fail. What is different is that, even with our self-paced strategy, training with clusters alone (``\textit{tgt.} cluster'') would fail. That is due to the fact that only a few samples take part in the training if discarding the outliers, undoubtedly leading to training collapse. 
Note that previous unsupervised re-ID methods \cite{lin2019aBottom,zeng2020hierarchical} which abandoned outliers did not fail, since they did not utilize a memory bank that requires all the entries to be continuously updated.

We adopt the non-parametric class centroids to supervise the source-domain feature learning,
however, conventional methods generally adopt a learnable classifier for supervised learning.
``\textit{Src.} class  \textit{Src.} learnable weights'' in Table \ref{tab:ablation_a} is therefore conducted to verify the necessity of using source-domain class centroids for training to match the semantics of target-domain training supervisions. 
We also test the effect of not extending negative classes across different types of contrasts. 
For instance, 
source-domain samples only treat non-corresponding source-domain classes as their negative classes. 
``Ours \textit{w/o} unified contrast'' shows inferior performance in both Table \ref{tab:ablation_a} and  \ref{tab:ablation_b}.
This indicates the effectiveness of the unified contrastive learning between all types of classes in Eq. (\ref{eq:joint}).

\vspace{-5pt}
\paragraph{Self-paced learning strategy.}
We propose the self-paced learning strategy to preserve the most reliable clusters for providing stronger supervisions.
The intuition is to measure the stability of clusters by hierarchical structures, \ie a reliable cluster should be consistent in clusters at multiple levels.
 and  are therefore proposed to measure the independence and compactness of clusters, respectively.
To verify the effectiveness of such a strategy,
we evaluate our framework when removing either  or , or both of them.
Obvious performance drops are observed 
under all these settings,
\eg 4.9\% mAP drops are shown when removing  in Table  \ref{tab:ablation_b}.


We illustrate the number of clusters and their corresponding Normalized Mutual Information (NMI) scores during training on MSMT17Market-1501 in Figure \ref{fig:cluster_num}. It can be observed that 
the quantity and quality of clusters are closer to the ground-truth IDs 
with the proposed self-paced learning strategy regardless of the un-clustered instance-level contrast, 
indicating higher reliability of the clusters and the effectiveness of the self-paced strategy.


\begin{figure}[th]
\centering
\vspace{-5pt}
\includegraphics[width=0.9\linewidth]{figure/cluster.png}
\vspace{-3pt}
\caption{Ablation study by observing the dynamically changing cluster numbers and their corresponding Normalized Mutual Information (NMI) scores during training on MSMT17Market-1501.}
\label{fig:cluster_num}
\end{figure}


\vspace{-10pt}
\section{Discussion and Conclusion}
\vspace{-5pt}

Our method has shown considerable improvements over a variety of unsupervised or domain adaptive object re-ID tasks. 
The supervised performance can also be promoted labor-free by 
incorporating unlabeled data for training in our framework.
The core is at exploiting all available data for jointly training with hybrid supervision.
Positive as the results are, 
there still exists a gap from the oracle,
suggesting that the pseudo-class labels may not be satisfactory enough even with the proposed self-paced strategy. 
Further studies are called for.
Beyond the object re-ID task,
our  
method
has great potential on other unsupervised learning tasks, which needs to be explored.


\clearpage
\section*{Broader Impact}



Our method can help to identify and track different types of objects (\eg vehicles, cyclists, pedestrians, \etc) across different cameras (domains), thus boosting the development of smart retail, smart transportation, and smart security systems in the future metropolises. In addition, our proposed self-paced contrastive learning is quite general and not limited to the specific research field of object re-ID. It can be well extended to broader research areas, including unsupervised and semi-supervised representation learning. 

However, object re-ID systems, when applied to identify pedestrians and vehicles in surveillance systems, might give rise to the infringement of people's privacy, since such re-ID systems often rely on non-consensual surveillance data for training, \ie it is unlikely that all human subjects even knew they were being recorded.
Therefore, governments and officials need to carefully establish strict regulations and laws to control the usage of re-ID technologies. 
Otherwise, re-ID technologies can potentially equip malicious actors with the ability to surveil pedestrians or vehicles through multiple CCTV cameras without their consent.
The research committee should also avoid using the datasets with ethics issues, \eg DukeMTMC \cite{dukemtmc}, which has been taken down due to the violation of data collection terms, should no longer be used. We would not evaluate our method on DukeMTMC related benchmarks as well. 
Furthermore, we should be cautious of the misidentification of the re-ID systems to avoid possible disturbance.
Also, note that the demographic makeup of the datasets used is not representative of the broader population.

\section*{Acknowledgements}

This work is supported in part by the General Research Fund through the Research Grants Council of Hong Kong under Grants (\textit{Nos.} CUHK14208417, CUHK14207319), in part by the Hong Kong Innovation and Technology Support Program (\textit{No.} ITS/312/18FX), in part by CUHK Strategic Fund.







\bibliographystyle{splncs04}
\small
\bibliography{neurips_2020}
\normalsize



\appendix







\section{Algorithm Details}
\label{sec:app_alg}

\begin{algorithm}[H]
\scriptsize
\caption{\small Self-paced contrastive learning algorithm on domain adaptive object re-ID} 
\label{alg}
\begin{algorithmic}
\REQUIRE Source-domain labeled data  and target-domain unlabeled data ;
\REQUIRE Initialize the backbone encoder  with ImageNet-pretrained ResNet-50;
\REQUIRE Initialize the hybrid memory with features extracted by ;
\REQUIRE  Temperature  for Eq. (\ref{eq:joint}), momentum  for Eq. (\ref{eq:m_cen}), momentum  for Eq. (\ref{eq:m_ins}); \\
\textbf{for} n in  \textbf{do}\\
\quad Group  into  and  by clustering  from the hybrid memory with the independence Eq. (\ref{eq:indep}) and compactness Eq. (\ref{eq:comp}) criterion; \\
\quad Initialize the cluster centroids  with Eq. (\ref{eq:centroid}) in the hybrid memory; \\
\quad \textbf{for} each mini-batch ,  \textbf{do}\\
\quad \quad \textbf{1:} Encode features ,  for ,  with ; \\
\quad \quad \textbf{2:} Compute the unified contrastive loss with ,  by Eq. (\ref{eq:joint}) and update the encoder  by back-propagation; \\
\quad \quad \textbf{3:} Update source-domain related class centroids  in the hybrid memory with  and momentum  (Eq. (\ref{eq:m_cen}));\\
\quad \quad \textbf{4:} Update target-domain related instance features  in the hybrid memory with  and momentum  (Eq. (\ref{eq:m_ins})); \\
\quad \quad \textbf{5:} Update target-domain related cluster centroids  with updated  in the hybrid memory (Eq. (\ref{eq:centroid})); \\
\quad \textbf{end for}\\
\textbf{end for}
\end{algorithmic}
\end{algorithm}

\begin{algorithm}[H]
\scriptsize
\caption{\small Self-paced contrastive learning algorithm on unsupervised object re-ID} 
\label{alg_un}
\begin{algorithmic}
\REQUIRE Unlabeled data ;
\REQUIRE Initialize the backbone encoder  with ImageNet-pretrained ResNet-50;
\REQUIRE Initialize the hybrid memory with features extracted by ;
\REQUIRE  Temperature  for Eq. (\ref{eq:joint}), momentum  for Eq. (\ref{eq:m_ins}); \\
\textbf{for} n in  \textbf{do}\\
\quad Group  into  and  by clustering  from the hybrid memory with the independence Eq. (\ref{eq:indep}) and compactness Eq. (\ref{eq:comp}) criterion; \\
\quad Initialize the cluster centroids  with Eq. (\ref{eq:centroid}) in the hybrid memory; \\
\quad \textbf{for} each mini-batch  \textbf{do}\\
\quad \quad \textbf{1:} Encode features  for  with ; \\
\quad \quad \textbf{2:} Compute the unsupervised-version unified contrastive loss with  as below and update the encoder  by back-propagation; \\
\vspace{-10pt}


\vspace{-5pt}
\quad \quad \textbf{3:} Update instance features  in the hybrid memory with  and momentum  (Eq. (\ref{eq:m_ins})); \\
\quad \quad \textbf{4:} Update cluster centroids  with updated  in the hybrid memory (Eq. (\ref{eq:centroid})); \\
\quad \textbf{end for}\\
\textbf{end for}
\end{algorithmic}
\end{algorithm}

\section{More Discussions}
\label{sec:app_discuss}



\paragraph{Comparison with ECN \cite{zhong2019invariance,zhong2020learning}.}
There is an existing work, ECN \cite{zhong2019invariance} with its extension version \cite{zhong2020learning}, which also adopts a feature memory for the domain adaptive person re-ID task. 
Comparison results in Table \ref{tab:sota} demonstrate the superiority of our proposed method, and there are three main differences between our method and ECN.
(1) Our proposed hybrid memory dynamically provides all the source-domain class-level, target-domain cluster-level and un-clustered instance-level supervisory signals, while the memory used in ECN only provides instance-level supervisions on the target domain.
(2) We use unified training of source classes, target clusters and target outliers,
while ECN uses multi-task learning and treats source and target classes separately.
(3) We propose a self-paced learning strategy to gradually refine the learning targets on both clusters and un-clustered instances, while ECN adopts noisy -nearest neighbors as learning targets for all the samples without consideration of uneven density in the latent space.




\section{More Implementation Details}
\label{sec:app_imp}


We implement our framework in PyTorch \cite{pytorch} and adopt 4 GTX-1080TI GPUs for training\footnotemark[2].
The domain adaptation task with both source-domain and target-domain data takes  hours for training, and the unsupervised learning task with only target-domain data takes  hours for training on Market-1501 and PersonX datasets.
When training on MSMT17, VehicleID, VeRi-776 and VehicleX datasets,
time needs to be doubled due to over  images in the training set.

\footnotetext[2]{\url{https://github.com/yxgeee/SpCL}}

\subsection{Network Optimization}


We adopt an ImageNet~\cite{deng2009imagenet}-pretrained ResNet-50~\cite{he2016deep} up to the global average pooling layer,
followed by a 1D BatchNorm layer and an -normalization layer,
as the backbone for the encoder .
Domain-specific BNs~\cite{Chang_2019_CVPR} are used in  for narrowing domain gaps.
Adam optimizer is adopted to optimize  with a
weight decay of 0.0005.
The initial learning rate is set to 0.00035 and
is decreased to 1/10 of its previous value every 20 epochs in the total 50 epochs.
The temperature  in Eq. (\ref{eq:joint}) is empirically set as 0.05.
The hybrid memory is initialized by extracting the whole training set with the ImageNet-pretrained encoder ,
and is then dynamically updated with  in Eq. (\ref{eq:m_cen})\&(\ref{eq:m_ins}) at each iteration.


\subsection{Training Data Organization}


During training, each mini-batch contains 64 source-domain images of 16 ground-truth classes (4 images for each class) and 64 target-domain images of \textit{at least} 16 pseudo classes, 
where target-domain clusters and un-clustered instances are all treated as independent pseudo classes (4 images for each cluster or 1 image for each un-clustered instance).
The person images are resized to  and the vehicle images are resized to .
Random data augmentation is applied to each image before it is fed into the network, including randomly flipping, cropping and erasing~\cite{zhong2017random}.

\subsection{Target-domain Clustering} 
\label{sec:app_cluster}


Following the clustering-based UDA methods~\cite{ge2020mutual,yang2019selfsimilarity,song2018unsupervised}, 
we use DBSCAN~\cite{ester1996density} and Jaccard distance~\cite{zhong2017re} with -reciprocal nearest neighbors for clustering before each epoch, where .
For DBSCAN,
the maximum distance between neighbors is set as  and the minimal number of neighbors for a dense point is set as .
In our proposed self-paced learning strategy described in Section \ref{sec:selfpaced},
we tune the value of  to loosen or tighten the clustering criterion.
Specifically, we adopt  to form the looser criterion and  for the tighter criterion, denoted as .
The constant threshold  for identifying independent clusters is defined by the top-  before the first epoch and remains the same for all the training process.
The dynamic threshold  for identifying compact clusters is defined by the maximum  in each cluster on-the-fly, \ie we preserve the most compact points in each cluster.


\section{Additional Experimental Results}

\subsection{Performance with IBN-ResNet \cite{pan2018two}}


\begin{table}[h]
	\scriptsize
\caption{
    Comparison of different backbones in our framework, \ie ResNet-50 and IBN-ResNet.}
	\label{tab:ibn}
	\centering
	\begin{tabular}{P{1.6cm}|P{1.6cm}|C{0.7cm}C{0.7cm}C{0.7cm}C{0.7cm}|C{0.7cm}C{0.7cm}C{0.7cm}C{0.7cm}}
	\multicolumn{1}{c|}{\multirow{2}{*}{Source}} & \multicolumn{1}{c|}{\multirow{2}{*}{Target}} & \multicolumn{4}{c|}{Ours \textit{w/} ResNet-50} & \multicolumn{4}{c}{Ours \textit{w/} IBN-ResNet} \\
	\cline{3-10}
	\multicolumn{1}{c|}{} & \multicolumn{1}{c|}{} & mAP & top-1 & top-5 & top-10 & mAP & top-1 & top-5 & top-10 \\ 
\hline \hline
Market-1501 & MSMT17 & 26.8 & 53.7 & 65.0 & 69.8 & \textbf{31.0} & \textbf{58.1} & \textbf{69.6} & \textbf{74.1} \\
	MSMT17 & Market-1501 & {77.5} & {89.7} & {96.1} & {97.6} & \textbf{79.9} & \textbf{92.0} & \textbf{97.1}& \textbf{98.1} \\
    PersonX & Market-1501 & 73.8 & 88.0 & 95.3 & 96.9 & \textbf{77.9} & \textbf{90.5} & \textbf{96.1} & \textbf{97.7} \\
    PersonX & MSMT17 & 22.7 & 47.7 & 60.0 & 65.5 & \textbf{25.4} & \textbf{50.6} & \textbf{63.3} & \textbf{68.3} \\
VehicleID & VeRi-776 & \textbf{38.9} & \textbf{80.4} & \textbf{86.8} & \textbf{89.6} & 38.0 & 79.7 & 85.8 & 88.4 \\
    VehicleX & VeRi-776 & \textbf{38.9} & \textbf{81.3} & \textbf{87.3} & \textbf{90.0} & 37.8 & 80.7 & 86.1 & 89.2 \\
    \hline
    None & Market-1501 & 73.1 & 88.1 & 95.1 & 97.0 & \textbf{73.8} & \textbf{88.4} & \textbf{95.3} & \textbf{97.3} \\
    None & MSMT17 & 19.1 & 42.3 & 55.6 & 61.2 & \textbf{24.0} & \textbf{48.9} & \textbf{61.8} & \textbf{67.1}  \\
    None & VeRi-776 & \textbf{36.9} & \textbf{79.9} & \textbf{86.8} & \textbf{89.9} & 36.6 & 79.1 & 85.9 & 89.2 \\
\end{tabular}
	
\end{table}

Instance-batch normalization (IBN) \cite{pan2018two} has been proved effective in object re-ID methods in either unsupervised \cite{ge2020mutual} or supervised \cite{luo2019bag} learning tasks. 
We evaluate our framework with IBN-ResNet as the backbone of the encoder, which is formed by replacing all BN layers in ResNet-50~\cite{he2016deep} with IBN layers.
As shown in Table \ref{tab:ibn},
the performance can be further improved with IBN-ResNet except for the vehicle datasets.





\subsection{Self-paced Learning Strategy on Other Clustering Algorithms}


\begin{table}[H]
	\scriptsize
\caption{
    Evaluate our framework over Agglomerative Clustering \cite{beeferman2000agglomerative} algorithm.
Experiments are conducted on the tasks of unsupervised person re-ID.}
	\label{tab:agg}
	\centering
	\begin{tabular}{P{5cm}|C{0.7cm}C{0.7cm}C{0.7cm}C{0.7cm}}
	\multicolumn{1}{c|}{\multirow{2}{*}{Clustering}} & \multicolumn{4}{c}{Market-1501}   \\
	\cline{2-5}
	\multicolumn{1}{c|}{}  & mAP & top-1 & top-5 & top-10  \\ 
\hline \hline
    Agglomerative Clustering \textit{w/o} {self-paced strategy} & 70.4 & 87.1 & 94.7 & 96.6  \\
	Agglomerative Clustering \textit{w/} {self-paced strategy} & \textbf{75.2} & \textbf{89.7} & \textbf{95.8} & \textbf{97.5}  \\

	\end{tabular}
	
\end{table}

In order to verify that our proposed self-paced learning strategy with cluster reliable criterion is still effective when creating pseudo labels with other clustering algorithms, we conduct experiments by replacing the original DBSCAN algorithm with Agglomerative Clustering \cite{beeferman2000agglomerative} algorithm.
As shown in Table \ref{tab:agg}, significant 4.8\% mAP improvements can be observed when applying the self-paced learning strategy. 
What is interesting is that the final performance is even better than that on DBSCAN.

\subsection{Cluster Reliable Criterion \textit{v.s.} HDBSCAN \cite{campello2015hierarchical}}

\begin{table}[H]
	\scriptsize
\caption{
    Comparison between DBSCAN \textit{w/} our cluster reliable criterion and HDBSCAN \cite{campello2015hierarchical}.
Experiments are conducted on the tasks of unsupervised person re-ID.}
	\label{tab:hdbscan}
	\centering
	\begin{tabular}{P{4.5cm}|C{0.7cm}C{0.7cm}C{0.7cm}C{0.7cm}|C{0.7cm}C{0.7cm}C{0.7cm}C{0.7cm}}
	\multicolumn{1}{c|}{\multirow{2}{*}{Clustering}} & \multicolumn{4}{c}{Market-1501}  & \multicolumn{4}{c}{MSMT17}   \\
	\cline{2-9}
	\multicolumn{1}{c|}{}  & mAP & top-1 & top-5 & top-10 & mAP & top-1 & top-5 & top-10  \\ 
\hline \hline
	DBSCAN \textit{w/} {our cluster reliable criterion} & \textbf{73.1} & \textbf{88.1} & \textbf{95.1} & \textbf{97.0} & \textbf{19.1} & \textbf{42.3} & \textbf{55.6} & \textbf{61.2}  \\
	HDBSCAN &  71.7 & 87.7 & 95.0 & 96.3 & 15.7 & 39.2 & 51.3 & 56.7 \\

	\end{tabular}
	
\end{table}

The intuition of our cluster reliable criterion is to measure the stability of clusters by hierarchical structures, which shows similar motivation as HDBSCAN \cite{campello2015hierarchical}.
So we test HDBSCAN to replace our reliability criterion and observe 1.4\%/3.4\% mAP drops on unsupervised Market-1501/MSMT17 tasks (Table \ref{tab:hdbscan}),
which indicates that DBSCAN with our cluster reliability criterion is more suitable than HDBSCAN in the proposed framework.

\section{Parameter Analysis}


We tune the hyper-parameters on the task of MSMT17Market-1501, and the chosen hyper-parameters are directly applied to all the other tasks. 


\subsection{Temperature  for Contrastive Loss}


\begin{figure}[htb]
\centering
\includegraphics[width=0.6\linewidth]{figure/temp.png}
\caption{Performance of our framework with different values of temperature .}
\label{fig:temp}
\end{figure}

As demonstrated in Figure \ref{fig:temp},
our framework achieves the optimal performance when setting the temperature  as  in Eq. (\ref{eq:joint}) on the task of MSMT17Market-1501.
One may find that the performance varies with different values of ,
but note that all methods using temperature contrastive function (\eg \cite{zhong2019invariance,zhong2020learning,wu2018unsupervised,he2019momentum,chen2020simple,oord2018representation}) have similar effects on .
We set  following \cite{zhong2019invariance,zhong2020learning} and achieve the best performance using the same  for 6 UDA tasks (Table \ref{tab:sota}) and 3 unsupervised tasks (Table \ref{tab:unsupervised}), showing the robustness of .

\subsection{Momentum Coefficients  for Hybrid Memory}


\begin{figure}[H]
\centering
\includegraphics[width=0.6\linewidth]{figure/momentum_mt.png}
\caption{Performance of our framework with different values of  when .}
\label{fig:mom_mt}
\end{figure}

\begin{figure}[H]
\centering
\includegraphics[width=0.6\linewidth]{figure/momentum_ms.png}
\caption{Performance of our framework with different values of  when .}
\label{fig:mom_ms}
\end{figure}

\begin{figure}[H]
\centering
\includegraphics[width=0.6\linewidth]{figure/momentum_eq.png}
\caption{Performance of our framework with different values of  when .}
\label{fig:mom_eq}
\end{figure}

Our proposed hybrid memory simultaneously stores and updates the source-domain class centroids with momentum  in Eq. (\ref{eq:m_cen}) and the target-domain instance features with momentum  in Eq. (\ref{eq:m_ins}).
We adopt  in our experiments by tuning such hyper-parameter on the task of MSMT17Market-1501.

We find that the value of  is critical to the optimal performance (Figure \ref{fig:mom_mt}) while 
our framework is not sensitive to the value of  (Figure \ref{fig:mom_ms}),
so we adopt the same momentum coefficient on two domains for convenience, \ie .
Despite the value of  affects the final performance,
the results of our framework are robust when  changes within a large range, \ie  in Figure \ref{fig:mom_eq}.





























\subsection{Residual  for Cluster Reliability Criterion}


\begin{figure}[htb]
\centering
\includegraphics[width=0.6\linewidth]{figure/delta_d.png}
\caption{Performance of our framework with different values of  in the cluster reliability criterion.}
\label{fig:delta_d}
\end{figure}

As described in Section \ref{sec:app_cluster},
we tune the value of the maximum neighbor distance  with a residual  to measure the cluster reliability in our self-paced learning strategy.
As shown in Figure \ref{fig:delta_d},
 can be thought of as removing the self-paced strategy from training, which is the same as ``Ours \textit{w/o} '' in Table \ref{tab:ablation}.
Our method could achieve similar performance when  changes within , which indicates that our proposed reliability criterion is not sensitive to the hyper-parameter .

\end{document}
