\def\year{2021}\relax
\documentclass[letterpaper]{article} \usepackage{aaai21}  \usepackage{times}  \usepackage{helvet} \usepackage{courier}  \usepackage[hyphens]{url}  \usepackage{graphicx} \urlstyle{rm} \def\UrlFont{\rm}  \usepackage{natbib}  \usepackage{caption} \frenchspacing  \setlength{\pdfpagewidth}{8.5in}  \setlength{\pdfpageheight}{11in}  \pdfinfo{
/Title (AAAI Press Formatting Instructions for Authors Using LaTeX -- A Guide)
/Author (AAAI Press Staff, Pater Patel Schneider, Sunil Issar, J. Scott Penberthy, George Ferguson, Hans Guesgen, Francisco Cruz, Marc Pujol-Gonzalez)
/TemplateVersion (2021.2)
} 

\usepackage{amsmath}
\usepackage{subfigure}
\usepackage{booktabs}
\usepackage{multirow}
\setcounter{secnumdepth}{2} 







\title{An End-to-End Multi-Task Learning to Link \\ Framework for Emotion-Cause Pair Extraction}

\author {
Haolin Song\textsuperscript{\rm 1} \thanks{Equal contribution},
Chen Zhang\textsuperscript{\rm 1 },
Qiuchi Li\textsuperscript{\rm 2},
Dawei Song\textsuperscript{\rm 1}\\
}
\affiliations{
\textsuperscript{\rm 1}Beijing Institute of Technology, Beijing, China\\
\textsuperscript{\rm 2}University of Padua, Padua, Italy\\
\{hlsong,czhang,dwsong\}@bit.edu.cn, qiuchili@dei.unipd.it
}


\iffalse
\title{My Publication Title --- Single Author}
\author {
Author Name \\
}
\affiliations{
    Affiliation \\
    Affiliation Line 2 \\
    name@example.com
}
\fi

\iffalse
\title{An End-to-End Multi-Task Learning to Link \\ Framework for Emotion-Cause Pair Extraction}
\author {
First Author Name,\textsuperscript{\rm 1}
    Second Author Name, \textsuperscript{\rm 1}
    Third Author Name, \textsuperscript{\rm 2} \\
}
\affiliations {
\textsuperscript{\rm 1} Affiliation 1 \\
    \textsuperscript{\rm 2} Affiliation 2 \\
    firstAuthor@affiliation1.com, secondAuthor@affiliation2.com ,thirdAuthor@affiliation1.com
}
\fi

\begin{document}

\maketitle

\begin{abstract}
Emotion-cause pair extraction (ECPE), as an emergent natural language processing task, aims at jointly investigating emotions and their underlying causes in documents. It extends the previous emotion cause extraction (ECE) task, yet without requiring a set of pre-given emotion clauses as in ECE. Existing approaches to ECPE generally adopt a two-stage method, i.e., (1) emotion and cause detection, and then (2) pairing the detected emotions and causes.  Such pipeline method, while intuitive, suffers from two critical issues, including error propagation across stages that may hinder the effectiveness, and high computational cost that would limit the practical application of the method. To tackle these issues, we propose a multi-task learning model that can extract emotions, causes and emotion-cause pairs simultaneously in an end-to-end manner. Specifically, our model regards pair extraction as a link prediction task, and learns to link from emotion clauses to cause clauses, i.e., the links are directional. Emotion extraction and cause extraction are incorporated into the model as auxiliary tasks, which further boost the pair extraction. Experiments are conducted on an ECPE benchmarking dataset. The results show that our proposed model outperforms a range of state-of-the-art approaches.
\end{abstract}

\section{Introduction}

Emotion cause extraction (ECE)\cite{lee2010text} aims to extract possible causes for a given emotion clause. While ECE has attracted an increasing attention due to its theoretical and practical significance, it requires that the emotion signals should be given. In practice emotion annotation is rather labor intensive, limiting the applicability of ECE in practical settings. To address the limitation of ECE, the emotion-cause pair extraction (ECPE) task was recently proposed in\cite{xia-ding-2019-emotion}. Unlike ECE\cite{lee2010text}, ECPE aims to extract emotions and causes without any given emotion signals, and thus better aligns with real-world applications. An illustrative example is given in Figure~\ref{fig1a}, showing that clause 4 serves as the emotion and clauses 2 and 3 are the corresponding causes. Typically, ECPE is formulated as extracting emotion-cause pairs, e.g., (clause 4, clause 2) and (clause 4, clause 3), directly from provided documents.

\begin{figure}
    \centering
    \subfigure[An example document and extracted emotion-cause pairs]{
    \label{fig1a}
    \includegraphics[width=0.9\columnwidth]{intro_a.pdf}
    }
    \subfigure[Directional graph of clauses in the document]{ 
    \label{fig1b}
    \includegraphics[width=0.9\columnwidth]{intro_b.pdf}
    }
    \caption{Extracting emotion-cause pairs from the given document via learning to link.}
    \label{fig1}
\end{figure}

ECPE is a challenging task, as it requires the extraction of emotions, causes and emotion-cause pairs. Existing work in ECPE mainly focuses on how to collaboratively extract emotions and causes and combine them in an appropriate way. Thus, a two-stage method\cite{xia-ding-2019-emotion} is typically adopted, which divides pair extraction into two steps: firstly detecting emotions and causes, and then pairing them based on the likelihood of cartesian products between them. Such pipeline method is intuitive and straightforward. However, one critical issue arises, which is the error propagation from the first step to the second.

To tackle the issue, we propose an end-to-end multi-task learning model for predicting emotion-cause pairs, namely \textbf{E2EECPE}. Our model takes an innovative perspective by viewing ECPE as a link prediction problem, and connects the emotion/cause extraction and link prediction  within one single stage.  Particularly, as shown in Figure~\ref{fig1b},  the model predicts whether there exists a directional link from an emotion clause to a cause clause. Meanwhile, we incorporate into the model two auxiliary tasks, namely emotion extraction and cause extraction, which are oriented to further enhance the expressiveness of the intermediate emotion and cause representations. These are placed in a carefully designed end-to-end multi-task learning architecture, which helps resolving the issue of error propagation.

Extensive experiments are carried out on a benchmarking ECPE dataset. The experimental results demonstrate the effectiveness of the proposed \textbf{E2EECPE} model, in comparison with a variety of state-of-the-art baselines. Moreover, a further ablation study indicates that the auxiliary tasks are beneficial. We have also shown that the model can be applied to an extended task: emotion-cause triplet extraction, and achieves a promising pewrformance.

\section{Related Work}

First of all, our work is related to extracting causes based on emotions explicitly presented in documents, i.e., ECE\cite{lee2010text}. Earlier work views ECE as a word-level sequence tagging problem and tries to solve it with corresponding tagging techniques. Therefore, primary efforts have been made on discovering refined linguistic features\cite{chen2010emotion,lee2013detecting}, yielding improved performance. In line with other tagging related tasks such as named entity recognition (NER), support vector machines (SVMs)\cite{gui2014emotion} and conditional random fields (CRFs)\cite{lafferty2001conditional} have been used for ECE. More recently, instead of concentrating on word-level cause detection, clause-level extraction\cite{gui2016event} is put forward in that the impact of individual words in a cause can span over the whole sequence in the clause.

With the emergence and development of deep representation learning, neural models has also been utilized in ECE. \cite{cheng2017emotion} leverages long short-term memory networks (LSTMs)\cite{hochreiter1997long} to promote the context awareness of clause modelling. \cite{gui2017question} views the information extraction problem as the retrieval task in question answering (QA) and examines the effect of memory networks\cite{sukhbaatar2015end} for extraction. Likewise, taking advantage of attention mechanism\cite{bahdanau2014neural}, \cite{li2018co} employs a co-attention based model and achieves the state-of-the-art performance. 

In light of recent advances in multi-task learning, joint extraction of emotions and causes is investigated \cite{chen2018joint} to exploit the mutual information between two correlated tasks. However, these works do not explicitly combine two tasks into one. Thereafter, \cite{xia-ding-2019-emotion} argues that, while co-extraction of emotions and causes is important, emotion-cause pair extraction (ECPE) is a more challenging problem that is worth putting more emphasis on. Nevertheless, \cite{xia-ding-2019-emotion} adopts a two-stage approach, which performs emotion and cause extraction first and then pairs the extracted emotions and causes. As discussed in the previous section, such two stage approach suffers from error propagation and high computation cost.



Our work aims to tackle these challenges in ECPE. Rather than processing emotion-cause pair extraction as a two stage task (as used in the existing work), we consolidate two stages into a unified multi-task learning framework, and further consider it as a link prediction task which could be solved in an end-to-end manner.

\section{Methodology}

To solve ECPE in an end-to-end fashion, we take inspiration from the link prediction problem in graph learning, which aims at predicting potential edges between unconnected vertices in a graph. Essentially, if we consider emotion-cause pairs in a document as triplets in a graph, then the extraction of such pairs is a sort of link prediction from a graph that is at first armed with no edges but only vertices. In order to achieve above procedure, we borrow the idea of learning a graph-based dependency parser\cite{dozat2016deep} and adapt it to our target task. Coupling link prediction with auxiliary emotion extraction and cause extraction tasks, our model is capable of jointly, and more effectively, extracting emotions, causes, and emotion-cause pairs. 

\begin{figure*}[t]
    \centering
    \includegraphics[width=0.65\textwidth]{model.pdf}
    \caption{An overview of E2EECPE. EE, CE stands for emotion extraction, cause extraction respectively.}
    \label{fig2}
\end{figure*}

\subsection{Problem Formulation}

Generally, for any provided document , we could split it into a sequence of clauses based on punctuation, i.e., , where  could further be decomposed into words, i.e., . Here,  is the number of clauses in the document and  is the number of words in the -th clause. ECPE aims to extract a set of  emotion-cause pairs  from the document , where  ,  represents the emotion clause and the cause clause in the -th pair, respectively.

\subsection{Overall Architecture}

An overview of the proposed \textbf{E2EECPE} approach is shown in Figure~\ref{fig2}. The bottom layer is a clause encoder (Section~\ref{sec3.3}) and a document modelling layer (Section~\ref{sec3.4}) which transform the word embeddings into the contextualized clause representations. The middle part consists of auxiliary tasks (Section~\ref{sec3.7}), i.e., emotion extraction and cause extraction. The top most part is a biaffine attention layer (Section~\ref{sec3.5}) which first encodes interaction between the emotion representation and cause representation, and then outputs a postion-weighted pair matrix for pair extraction.

\subsection{Embedding \& Clause Encoder}
\label{sec3.3}

With the purpose of integrating words into clause-level neural models, we embed each word in a clause into low-dimensional vectors\cite{bengio2003neural}, by which we could represent each word in the clause with its vector representation\footnote{If not specified, we use notations in bold as the vector representations of their original concepts.} , where  and  is the dimensionality of the embedding. 

After that, we need to attain contextualized representations of clauses. Owing to the recognized performance and local context awareness of the convolutional neural networks (CNNs) on text classification benchmarks\cite{kim2014convolutional}, we adopt CNNs as the backbone of our clause encoder. 

For an embedded clause , we apply one-dimensional convolution operations with kernels
of different sizes over the word sequence:


\noindent where  denotes the -th convolution operation and  is the output of the operation.  is the number of filters employed in one convolution operation and  used here is actually . 

Then max-pooling is used to distill the features for concatenation. Hence, we finally get context-aware features for the clause:



\noindent where  is the convoluted feature and  means vector concatenation.  is the total number of convolution operations.

\subsection{Document Modelling}

\label{sec3.4}

Since we have sequential clauses in a document, the influences brought by document-level structures become a crucial part that we should fit into our model. A straightforward idea is to leverage temporal relations among clauses with LSTMs. 

Specifically, provided with the encoded clause representations , we employ a bidirectional LSTM to update clause-level features and get :


\noindent where  and  denote the forward and backward unidirectional LSTMs, respectively.  is the dimensionality of hidden states for a unidirectional LSTM.


\subsection{Biaffine Attention}

\label{sec3.5}

Motivated by advances in link prediction\cite{schlichtkrull2018modeling}, we can directly compute the similarity scores among vertex representations (clause representations in our task), e.g.,  for any representations of vertex  and , to make predictions. However, the above predictions are only concerned with undirectional circumstances since , which is not adequate for emotion-cause pair extraction. To solve the problem, we utilize biaffine transform to complete the filling of adjacent matrices, which are called \emph{pair matrices} in our work. This idea is similar to dependency parsing\cite{dozat2016deep} that is also directional.

\subsubsection{Emotion \& Cause Representation}

According to biaffine attention mechanism, each vertex in the graph should have two independent representations, i.e., one is for pointing out and the other for pointed in. In doing so, the pair matrix output by the transformation is asymmetric and direction-aware.

The emotion representation and cause representation are separately offered as below:



\noindent where ,  and ,  are two sets of trainable weights and biases, respectively for the emotion and cause representations.

\subsubsection{Biaffine Transform}

Then, we implement biaffine transform on the collected emotion and cause representations. In other words, with the purpose of merging these two kinds of representations into our aimed pair matrices, we fold emotion-cause dynamics into two components. On the one hand, we need to perform a bilinear like operation on each possible pair of emotion and cause. On the other hand, we believe bilinear transform is not enough to deal with such complicated interactions, and thus we facilitate it by injecting bias.

More specifically, we calculate each entry in the expected pair matrix as follows:


\noindent where  and  are learnable parameters of affine transform, while  indicates an entry of the pair matrix in the -th row, -th column.

Constrained by the inherent property of an adjacent matrix, we further activate the pair matrix with the sigmoid function :


\subsection{Position Weight Matrix}

A trivial observation on the co-occurrence patterns of emotions and causes is that the emotion and the cause in a unique pair appear near each other in term of their absolute positions in the document. Thus, position embeddings are introduced to directly encode positions into vectors\cite{xia-ding-2019-emotion}. Different from the existing approaches, our work is based on graph learning, and thereby can not be aided by manipulation of embeddings. Instead, we apply proximity weights on features as in\cite{zhang2019syntax}, but extent it to matrices.

Moreover, we notice that in reality people are more likely to inform the causes before expressing emotions. This is verified in Figure~\ref{fig3}, where the matrices of ground truth pairs in all documents with document length less than 20 are visualized. In the matrix of Figure 3, the horizontal axis represents the sequence number of the emotion clauses, the vertical axis represents the sequence number of the cause clauses, and each element represents the number of emotion-cause pairs. The diagonal position indicates the number of emotion-cause pairs in the same clauses. The brighter the color, the more pairs there are. It can be seen from the figure that causes tend to appear in the clause before emotions. It implies that we should consider constraining the original matrix representations with the position bias.

\begin{figure}[h]
    \centering
    \includegraphics[width=0.8\columnwidth]{all_pairs_vis.pdf}
    \caption{Visualization of values for ground truth pair matrices with document length less than 20 in all documents.}
    \label{fig3}
\end{figure}

Therefore we propose two position weight methods: (1) Asymmetric Position
Weight Matrix, and (2) Ground Truth Weight Matrix.
\subsubsection{Asymmetric Position Weight Matrix}
We calculate asymmetric position weight matrix with all training documents:


\noindent where  is a small number for smoothing.
\subsubsection{Ground Truth Weight Matrix}
We directly use ground truth pairs in training documents to construct the weight matrix:

\noindent where  is a small number for smoothing and  is all ground truth pairs in , if there is pair (p, q) in , then .

Finally, we obtain the features for indicating pair links as follows:

\noindent where  denotes element-wise multiplication.

\subsection{Multi-task Setting}

\label{sec3.7}

As aforementioned, emotion extraction and cause extraction can be viewed as auxiliary tasks to augment the emotion and cause representations for constructing more expressive pair matrix. Hence we develop a multi-task paradigm, which shares the fundamental part of network structure for the main task with auxiliary tasks. To achieve this goal, we first acquire features dedicated for classification with following procedure: 



\noindent where ,  and ,  are again two sets of trainable weights and biases, respectively. 

Subsequently, predictions are produced by two fully connected layers followed by softmax normalization layers:



\noindent where ,  and ,  are weights and biases for learning. 

\subsection{Training Objective}

Eventually, the whole structure can be trained by standard gradient descent. Accordingly, the objective function is a combination of cross entropy with -norm regularization, formulated as below:



\noindent where  and ,  serve as enumerators over all elements. , , and  are correspondingly the ground truth.

Furthermore, we add two coefficients to balance the influences of above two objective functions. The ultimate training objective then becomes:


\noindent where the term  is used to adjust the potential influences brought by multi-task learning, which is refined according to a pilot study.  stands for all parameters that need to be optimized, while  is a coefficient for -norm regularization.

\subsection{Inference}

With the well trained model, we can infer emotion-cause pairs by comparing each entry in  with a predefined threshold 


\noindent where  is the inference result matrix with binary (1-0) indicators.

\section{Experimental Setting}

\subsection{Dataset}

We carry out experiments on a publicly available dataset released by\cite{xia-ding-2019-emotion} for emotion-cause pair extraction, which is the only publically available dataset we can currently access, and most of published papers in the area are experimented based on it. Consisting of news crawled from web, the dataset is referred to as \textsc{News} in the rest of the paper.  To facilitate a fair comparison, we use the same data split method as in \cite{xia-ding-2019-emotion}. The dataset is randomly split into ten folds, each of them has a similar amount of data. In our experiments, the evaluation is done in 10 runs where each run uses 9 folds as training data and the remaining one as test data (different for different runs), which respectively take 90\% and 10\% of the data. Table~\ref{tab1} shows some basic statistics of the dataset. A key observation is that most documents only contain one emotion-cause pair therein, implying the sparsity of the pair matrix. Therefore the issue of label imbalance will be elaborated in following discussions. Moreover, a large amount of emotion-cause pairs have the emotion and the cause within 1 relative offset, suggesting the necessity of using proximity constraints (exactly what position weight matrix does) in the predicted pair matrix.  

\begin{table}
\centering
\begin{tabular}{lr}
\toprule
  & \textsc{News}  \\
\midrule
\# of documents                                       & 1945         \\
avg. \# of clauses per document                & 14.77      \\
\# of EC pairs                             & 2167         \\
\# of documents with 1 EC pair          & 1746         \\
\# of documents with over 1 EC pairs  & 199          \\
\midrule
\# of EC pairs with 0 relative offset                      & 511           \\
\# of EC pairs with 1 relative offset                      & 1342          \\
\# of EC pairs with 2 relative offset                      & 224           \\
\# of EC pairs with over 2 relative offset                 & 90            \\
maximum EC pair offset                & 12            \\
avg. offset of EC pairs    & 0.9977        \\
\bottomrule
\end{tabular}
\caption{Statistics of the dataset. EC stands for emotion-cause, and relative offset indicates the absolute distance between the emotion and the cause of a pair in the document.}
\label{tab1}
\end{table}

\subsection{Implementation Details}
We use a RTX 2080Ti GPU with 11GB of memory as the experimental hardware base and conduct experiments on the Linux system. The programming language and deep learning framework we use are Python 3.6.3 and Pytorch 1.2.0 respectively.
\subsection{Parameter Settings}

For all our experiments, pre-trained word vectors on Weibo (a Chinese micro-bloging website) using Word2Vec\cite{mikolov2013efficient} are leveraged to initialize the word embeddings. Specifically, the skip-gram used, which is the same as used in the baseline approaches~\cite{xia-ding-2019-emotion}. The dimensionality
of the embeddings (i.e., ) is set to 200. We use 4 convolutional layers (i.e., ) whose kernel sizes are \{2,3,4,5\} for the clause encoder and the number of filters for all the convolutional layers (i.e., ) is 50, for capturing gram-level features. In order to avoid overfitting, we apply dropout to embeddings and outputs of the clause encoder, yielding 0.5 probability of randomized zeroes on features. The dimensionality for hidden states of a unidirectional LSTM (i.e., ) is 300. The dimensionalities for all fully connected layers in the main task and auxiliary tasks (i.e., ) are 100. Moreover, the batch size and learning rate are determined through grid parameter search, which are 32 and 10\textsuperscript{-3}, respectively. The number of epoch is 100 with early stop. The coefficient for -norm regularization (i.e., ) is 10\textsuperscript{-5} . Based on a pilot study, we find the best value for the threshold (i.e., ) in the inference stage is 0.3, which will be detailed in next section. The coefficient for the trade-off in objective function (i.e., ) is 1. In addition, the smoothing term in the calculation of position weight matrix (i.e.,  and ) are 1 and 0.01, respectively. Furthermore, Adam is used as the optimizer and all trainable parameters are randomly initialized with uniform distribution\cite{he2015delving}.

\begin{table*}[t]
\centering
\begin{tabular}{lrrrrrrrrr}
\toprule
\multirow{2}{*}{Models} & \multicolumn{3}{c}{emotion extraction} & \multicolumn{3}{c}{cause extraction} & \multicolumn{3}{c}{emotion-cause pair extraction}   \\
\cmidrule(lr){2-10}
~  & P & R & F1 & P & R & F1 & P & R & F1   \\
\midrule
\textbf{Indep w/o classifier}        & 0.8483 & 0.7961 & 0.8208 & 0.6898 & 0.5648 & 0.6198 & 0.5932  & 0.5094  & 0.5470      \\
\textbf{Inter-CE w/o classifier}     & 0.8458 & 0.8035 & 0.8263 & 0.6838 & 0.5754 & 0.6231 & 0.5827  & 0.5300  & 0.5531     \\
\textbf{Inter-EC w/o classifier}     & 0.8406 & {\bf 0.8097} & 0.8242 & 0.6989 & 0.5991 & 0.6426 & 0.5975  & 0.5538  & 0.5716     \\
\midrule
\textbf{Indep}          & 0.8483 & 0.7961 & 0.8208 & 0.6898 & 0.5648 & 0.6198 & {\bf 0.6943}  & 0.5047  & 0.5833      \\
\textbf{Inter-CE}        & 0.8458 & 0.8035 & 0.8263 & 0.6838 & 0.5754 & 0.6231 & 0.6780  & 0.5254  & 0.5896     \\
\textbf{Inter-EC}        & 0.8406 & {\bf 0.8097} & 0.8242 & 0.6989 & 0.5991 & 0.6426 & 0.6691  & 0.5503  & 0.6013     \\
\midrule
\textbf{E2EECPE-asw} & {\bf 0.8595}\textsuperscript{\dag} & 0.7915 & 0.8238 & {\bf 0.7062} & 0.6030 & 0.6503 & 0.6478  & 0.6105\textsuperscript{\dag}  & 0.6280\textsuperscript{\dag}     \\
\textbf{E2EECPE-gtw} & 0.8552\textsuperscript{\dag} & 0.8024 & {\bf 0.8275} & 0.7048 & {\bf 0.6159} & {\bf 0.6571}\textsuperscript{\dag} & 0.6491  & {\bf 0.6195}\textsuperscript{\dag}  & {\bf 0.6315}\textsuperscript{\dag}     \\
\bottomrule
\end{tabular}
\caption{Comparison results of emotion extraction, cause extraction, and emotion-cause pair extraction with precision, recall, and F1-measure as metrics. The results in bold are the best performing ones under each column. The results of emotion extraction and cause extraction for one-stage and two-stage models are exactly the same because one-stage models are ablated ones of two-stage models. \textsuperscript{\dag} indicates results that are significantly better than best performing baseline Inter-EC with paired t-test (\textit{p} is smaller than 0.05).}
\label{tab2}
\end{table*}

\subsection{Baselines \& Evaluation Metrics}

Our approach\footnote{Code is available in \url{https://github.com/shl5133/E2EECPE}} is compared with a range of strong baselines, which are the state-of-the-art methods proposed by\cite{xia-ding-2019-emotion} for emotion-cause pair extraction. These baselines are either one-stage or two-stage models.

The two-stage models are listed below. They first extract emotions and causes with multi-task architectures independently or interactively, then classify the cartesian products of emotions and causes extracted in the first stage into pairs or non-pairs. 

\begin{itemize}
    \item \textbf{Indep} firstly considers emotion extraction and cause extraction as independent tasks and extract emotions and causes with multi-task learning, then pairs the extracted emotions and causes with a classifier.
    \item \textbf{Inter-CE} follows the procedure of \textbf{Indep}, however, uses cause extraction to assist emotion extraction in the first stage.
    \item \textbf{Inter-EC} is same as \textbf{Inter-CE} except utilizing emotion extraction to improve cause extraction.
\end{itemize}

We also include three one-stage baseline models. Basically they drop the second stage in the two-stage models, and use the cartesian products as predictions instead of using the classifier in the second stage. The resultant one-stage baseline models are listed as follows.

\begin{itemize}
    \item \textbf{Indep w/o classifier} removes the classifier in the second stage of \textbf{Indep}.
    \item \textbf{Inter-CE w/o classifier} removes the classifier in the second stage of \textbf{Inter-CE}.
    \item \textbf{Inter-EC w/o classifier} removes the classifier in the second stage of \textbf{Inter-EC}.
\end{itemize}

Precision, recall, and macro F1 measures are adopted as effectiveness metrics in our experiments. The final results are obtained by averaging the ten folds results.

\section{Result \& Analysis}

\subsection{Results in Effectiveness}


We perform a comparison of \textbf{E2EECPE-asw} (E2ECPE with asymmetric position weight matrix) and \textbf{E2EECPE-gtw} (E2ECPE with ground truth position weight matrix) with one-stage and two-stage baseline models to quantitatively understand in what ways \textbf{E2EECPE} is more effective than the baselines.

Table~\ref{tab2} gives the results in terms of precision, recall and macro-F1 measures. The comparison results demonstrate that our model \textbf{E2EECPE-asw} and \textbf{E2EECPE-gtw} consistently outperforms the baselines for the main task (emotion-cause pair extraction) with regard to recall and F1, indicating the representation power and the effectiveness of our model. Nevertheless, we also observe that our model performs less well in precision than the two-stage baseline models. With additional observation that the baseline models are performing poorly on recall, we conjecture the existing models suffer from predicting only few testing instances as pairs. 

Furthermore, \textbf{E2EECPE} is superior on the two auxiliary tasks (emotion extraction and cause extraction). We attribute the improvement to multi-task structure in our model which combines auxiliary tasks and the main task. Apart from that, the one-stage models yield lower results than \textbf{E2EECPE} on cause extraction and emotion extraction, suggesting that error propagation is a comparably severe issue in the existing models but is alleviated in our model.


\subsection{Ablation Study}

To understand the efficacy of auxiliary tasks and position weight matrix, we conduct an ablation study on \textbf{E2EECPE-asw} and \textbf{E2EECPE-gtw}. Specifically, we separately ablate auxiliary tasks  (i.e., emotion extraction and cause extraction) and position weight matrix from \textbf{E2EECPE}, and call them \textbf{E2EECPE} \textit{w/o aux} and \textbf{E2EECPE} \textit{w/o position}, respectively.

\begin{table}[h]
\centering
\begin{tabular}{lrrr}
\toprule
Models  & P & R & F1 \\
\midrule
\textbf{E2EECPE-asw}  & 0.6478  & 0.6105  & 0.6280\\
\textbf{E2EECPE-gtw}  & {\bf 0.6491}  & {\bf 0.6195}  & {\bf 0.6315}\\
\midrule
\textbf{E2EECPE-asw} \textit{w/o aux}    & 0.5982  & 0.5340  & 0.5635  \\
\textbf{E2EECPE-gtw} \textit{w/o aux}    & 0.4562  & 0.4025  & 0.4272  \\
\textbf{E2EECPE} \textit{w/o position}   & 0.6421  & 0.6158  & 0.6275      \\
\bottomrule
\end{tabular}
\caption{Ablation study results. The results in bold are the best performing ones under each column.}
\label{tab3}
\end{table}

The results in Table~\ref{tab3} show a significant performance drop of \textbf{E2EECPE} \textit{w/o auxiliary} and a relatively minor drop of \textbf{E2EECPE} \textit{w/o position} compared with \textbf{E2EECPE-asw} and \textbf{E2EECPE-gtw},  verifying the remarkable benefit of the multi-task learning schema. Meanwhile, the results that \textbf{E2EECPE} \textit{w/o position} only differs slightly from \textbf{E2EECPE} based on all metrics, indicating that imposing position information is still of importance.

\subsection{Effect of Threshold in Inference Stage}

Inference based on pair matrix is powerful, yet we do not exactly know what threshold (i.e., ) is the most suitable one for its expressiveness. It is therefore helpful to explore the effect of the threshold by altering it and examining the results.

\begin{table}[h]
\small
\centering
\begin{tabular}{lrrr}
\toprule
\multirow{2}{*}{} & \multicolumn{3}{c}{E2EECPE-asw / E2EECPE-gtw}   \\
\cmidrule(lr){2-4}
~  & P & R & F1 \\
\midrule
0.2         & 0.5743 / 0.5887  & {\bf 0.6456 / 0.6372}  & 0.6071 / 0.6087   \\
{\bf 0.3}   & 0.6478 / 0.6491  & 0.6105 / 0.6195  & {\bf 0.6280 / 0.6315}    \\
0.4         & 0.6757 / 0.6873  & 0.5849 / 0.5780  & 0.6265 / 0.6265     \\
0.5         & 0.7185 / 0.7062  & 0.5543 / 0.5640  & 0.6255 / 0.6260     \\
0.6         & {\bf 0.7326 / 0.7301}  & 0.5385 / 0.5396  & 0.6201 / 0.6201    \\
\bottomrule
\end{tabular}
\caption{Effect of threshold. The results in bold are the best performing ones under each column.}
\label{tab4}
\end{table}

From Table~\ref{tab4}, we conclude that 0.3 is the most appropriate one for our studied task. With increases of , drops of F1 are noted, implying potential loss of extracted pairs. In addition, we also speculate that the reason why the best value is not around 0.5 (the expectation of random variables ranging uniformly from 0 to 1) is that the element-wise multiplication of a position weight matrix with the sigmoid-activated pair matrix produces a smaller expectation (as upper bound decreases). 

\subsection{Issue of Label Imbalance}

In order to measure the impact brought by label imbalance, typically in the form of pair matrix sparsity, we remove the examples containing more than one pair for test set in each fold to make up a \texttt{Hard} dataset, then record the mean results across ten folds correspondingly. 

We can observe in Table~\ref{tab5} that our model encounters a failure on the \texttt{Hard} dataset with decreases on precision and F1 measure, suggesting that further investigation is needed to solve this problem. 

\begin{table}[h]
\small
\centering
\begin{tabular}{lrrr}
\toprule
\multirow{2}{*}{Type} & \multicolumn{3}{c}{E2EECPE-asw / E2EECPE-gtw}   \\
\cmidrule(lr){2-4}
~  & P & R & F1\\
\midrule
\texttt{Full}   & 0.6478 / 0.6491  & 0.6105 / 0.6195  & 0.6280 / 0.6315  \\
\texttt{Hard}   & 0.6002 / 0.6322  & 0.6479 / 0.6078  & 0.6226 / 0.6186  \\
\bottomrule
\end{tabular}
\caption{The results for verifying the issue of label imbalance. }
\label{tab5}
\end{table}

\subsection{An Extended Task: Emotion-Cause Triplet Extraction}

Our model can also be extended to emotion-cause triplet extraction setting with minor modifications. Specifically, emotion-cause triplet differs from emotion-cause pair only on that a triplet should contain types of emotions while a pair does not. The emotion type extraction is also very important, just like in the \textit{Sentiment Analysis} task. So we adjust the output of the Biaffine Transform from a two-dimensional tensor to a three-dimensional tensor. The extra dimension represents the emotion type.

The experimental results are shown in Table~\ref{tab6}. It can be seen that using the E2EECPE model for the triplet extraction task can also achieve promising results.

\begin{table}[h]
\centering
\begin{tabular}{lrrr}
\toprule
~ & P & R & F1 \\
\midrule
triplet extraction & 0.5824 & 0.4304 & 0.4940 \\
emotion extraction & 0.8417 & 0.7875 & 0.8131 \\
cause extraction & 0.6577 & 0.5770 & 0.6133 \\
\bottomrule
\end{tabular}
\caption{Results of triplet extraction, emotion extraction, and cause extraction with precision, recall, and F1-measure as metrics.}
\label{tab6}
\end{table}

\section{Conclusions and Future Work}

The emotion-cause pair extraction task is a new and more realistic task that seeks to identify emotion-cause pairs in documents. However, previous models are inherently limited by the idea of solving the task via two stages. To this end, we propose an end-to-end multi-task learning model that regards the problem as predicting directional links between emotions and causes via biaffine attention. Additionally, we also aid the model with auxiliary tasks and position weight matrix. Experimental results prove the superiority of our model over a series of baselines.

We believe there are some promising directions yet to be explored. Firstly, the position weigh matrix used in our model is directly obtained from document information. Further models such as graph neural networks are expected to be developed to incorporate with learned position information instead of refined one. Secondly, triplet extraction is a brand new direction and is worth researching. Thirdly, the label imbalance issue should be addressed with task-specific tactics. 






\bibliography{aaai21.bib}


\end{document}
