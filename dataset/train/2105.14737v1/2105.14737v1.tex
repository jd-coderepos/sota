\begin{figure}[t!]
    \begin{center}
        \includegraphics[width=\textwidth]{mvtecad_grid_visual}
    \end{center}
    \caption{The visualization of anomaly prediction using the jet color map after the anomaly score is clamped in [0, 10]. The green lines in the fourth image indicate the ground-truth regions. More examples can be found in \fig~\ref{fig:mvtecad_vs_visual} and \ref{fig:mvtecad_all_visual}, \appx.}
    \label{fig:mvtecad_grid_visual}
\end{figure}

\paragrapht{Datasets.} The \textit{MVTec AD} dataset~\cite{Bergmann2019}, with the CC BY-NC-SA 4.0 license, consists of five texture and ten object categories with a totally 3,629 images for training and 1,725 images for testing. 
The emerging dataset for anomaly segmentation offers the real-world categories of textures and objects having multiple types of anomalies.
The test images have single or multiple types of defects, or defect-free, while the other splits only have defect-free images. We split for validation to have 10\%, while 90\% for training. We resize the images to 256x256, evaluate on this scale, and we do not apply any data augmentation strategy being consistent with the previously published works~\cite{Bergmann2019,Bergmann2020}.
The \textit{Kolektor surface-defect dataset} (KolektorSDD)~\cite{Tabernik2019JIM} consists of the 399 images of electrical commutators, where 52 defected images are annotated for microscopic fractions or cracks on the surface of the plastic embedding in electrical commutators. The dataset is publicly available~\footnote{http://www.vicos.si/Downloads/KolektorSDD} for research and non-commercial use only.
The dataset is split by three folds, where we use only anomaly-free images for unsupervised training. 
The \textit{Kolektor surface-defect dataset 2} (KolektorSDD2)~\cite{Bozic2021COMIND} is similar with the previous one, but having more samples. The train set has 2,085 negative and 246 positive images while the test set with 894 negative and 110 positive images. For the two Kolektor datasets, we resize the images to 704x256, evaluate on this scale, and do not apply any data augmentation, for the consistent comparison in \tbl~\ref{tbl:kolektor}.
The \textit{mSTC dataset}~\cite{Venkataramanan2020} is the modified ShanghaiTech Campus (STC) dataset~\cite{liu2018stc} consisting of 13 scenes with complex light conditions and camera angles having 130 abnormal events~\footnote{\url{https://svip-lab.github.io/dataset/campus_dataset.html}}. They extract every 5-th frame of the video from each scene for training (274,515 frames) and test (42,883 frames) for unsupervised anomaly segmentation task. We randomly sample 5,000 training samples following the previous work~\cite{Defard2020}, and use the same test split. We resize the images to 256x256, evaluate on this scale, and we do not apply any data augmentation strategy being consistent with the previously published works~\cite{Venkataramanan2020,Cohen2020,Defard2020}.

\paragrapht{Metric.} The previous work~\cite{Bergmann2019} proposes a threshold-free metric based on the per-region overlap (PRO). This metric is the area under the receiver operating characteristic curve (ROC) while it takes the average of true positive rates for each connected component~\footnote{One can exploit the max pooling with a  kernel for the breadth-first search to batch-compute the markers of connected components.} in the ground truth. Because the score of a single large region can overwhelm those of small regions, the PRO promotes multiple regions' sensitivity. It calculates up to the false-positive rate of 30\% (100\% for ROC, of course).
The ROC is a natural way to cost-and-benefit analysis of anomaly decision making.

\paragrapht{Multi-scale features.} For ResNet-18, we select the layer 1, 2, and 3, having the feature sizes of 64, 128, and 256, respectively, for Wide ResNet-50-2, the feature sizes of the layer 1, 2, and 3 are 256, 512, and 1024, respectively. The feature maps from the corresponding layers are concatenated for the channel dimension after interpolating spatial dimensions to . The output map of anomaly scores using the approximated Mahalanobis distance is interpolated to  and applied the Gaussian filter with the kernel size of 4 following the previous works~\cite{Cohen2020, Defard2020}. 

\paragrapht{Ablation study 1.} In the first part of \tbl~\ref{tbl:ablation_lowrank}, the alternatives using the Mahalanobis distance are compared.
First, we confirm that the localized precision matrices, \textit{full precision (local)}, outperforms a global precision matrix, \textit{full precision (global)} for both texture and object categories with a significant margin, in spite of batch-matrix inversion. Second, the truncated SVD using the -smallest eigenvalues of  where , \textit{eigenvectors (lower)}, retains the majority of original performance, compared to its counter part using the -largest eigenvalues, \textit{eigenvectors (higher)} as predicted in \thm~\ref{thm:low-rank}. These two alternatives provide the lower and upper bounds of the semi-orthogonal approximation error. Notice that =1,792 for Wide ResNet-50-2, with the multi-scale consideration, is prohibitively expensive in both computation and memory for batch-matrix inversion.

\paragrapht{Ablation study 2.} The second set of experiments is on the choice of layers providing input features. For ResNet-18, the feature sizes of layer 1, 2, and 3 are 64, 128, and 256, respectively, denoted by , , and  in \tbl~\ref{tbl:ablation_lowrank}. Notice that  and  are larger than . The results confirm the multi-scale approach using the multiple layers is crucial in anomaly segmentation. 
Especially, the layer 2 and 3 underperform our \textit{semi-orthogonal} method with a higher computational complexity.

\paragrapht{Ablation study 3.} The third part of \tbl~\ref{tbl:ablation_lowrank} compares the alternatives with the embedding size  of 100. The Gaussian random-valued embeddings, \textit{Gaussian}, significantly deteriorates the performance. The PaDiM~\cite{Defard2020} uses the same approximation as in \textit{sampled features}, however, our careful implementation gets a stronger baseline with 0.912 compared with their 0.905. One of reasons is the pre-processing where we do not use the center cropping since the center area does not perfectly cover the anomalies in some cases unlike their assumption. Notice that our evaluation protocol is consistent with previous works. Surprisingly, the approximation using our semi-orthogonal matrix outperforms the comparative methods with 0.924 considerably retaining the performance of \textit{full precision (local)} (0.934) with 1\% of computation and 5\% of memory complexities of those. For Wide ResNet-50-2, the ratio is more conversing to zero.
Also, we verify that the average of the standard deviations per category with five random semi-orthogonal matrices is lower than that of \textit{sampled features}.

\begin{table*}
  \centering
  \caption{Ablation study on low-rank methods for the anomaly segmentation task of the MVTec AD using the per-region-overlap (PRO). We use ResNet-18 to extract features and the target rank  is 100 where . The computational complexity is cubically dependent on , , or . \textit{Std.} indicates the average of the standard deviations per category with five random seeds. 
} 
  \label{tbl:ablation_lowrank}
  \begin{tabular}{lccccc}
  \toprule
  Model                             & Complexity & Texture   & Object    & Overall   & Std. \\ \midrule
  Full-rank (global)           &   & .866      & .899      & .888      & -    \\ 
  Full-rank (local)            & & .920      & \bf{.941} & \bf{.934} & -    \\ 
  Eigenvectors (higher)             & & .886      & .896      & .893      & -    \\
  Eigenvectors (lower)              & & \bf{.921} & .939      & .933      & -    \\ \midrule


  Layer 1                           && .880      & .901      & .894      & -    \\ 
  Layer 2                           && \bf{.903} & \bf{.921} & \bf{.915} & -    \\ 
  Layer 3                           && .883      & .916      & .905      & -    \\ \midrule

  Gaussian                          &  & \bf{.915} & .872      & .886      & .003      \\
  Sampled features~\cite{Defard2020}&  & .888      & .924      & .912      & .009      \\
Semi-orthogonal (ours)            &  & .909      & \bf{.931} & \bf{.924} & \bf{.002} \\
  \bottomrule
  \end{tabular}
\end{table*}

\begin{table*}
  \centering
  \caption{Comparison with the state-of-the-art for the anomaly segmentation task of the MVTec AD dataset using the two metrics, PRO and ROC. Please see the text for details.}
  \label{tbl:mvtecad_pro}
  \begin{tabular}{lccccc}
  \toprule
        &          & \multicolumn{3}{c}{PRO} & ROC   \\
  \cmidrule(lr){3-5} \cmidrule(lr){6-6}
  Model & Backbone & Texture & Object & Overall & Overall \\ \midrule
  Autoencoder (SSIM)~\cite{Bergmann2019} & - & .567 & .758 & .694 & .870 \\
  Autoencoder (L2)~\cite{Bergmann2019}   & - & .696 & .838 & .790 & .820 \\
  VAE~\cite{Defard2020}                  & - & .499 & .714 & .642 & .744  \\
  AnoGAN~\cite{Schlegl2017}              & - & .274 & .533 & .443 & .743  \\ 
  CAVGA~\cite{Venkataramanan2020}        & DC-GAN~\cite{radford2016dcgan} & - & - & - & .85\0  \\ \midrule
  Multi-KD~\cite{Salehi2021}             & VGG-16           & -    & -    & -    & .907 \\
  FCDD~\cite{Liznerski2021}              & -                & -    & -    & -    & .92\0 \\
  Patch-SVDD~\cite{Yi2020}               & -                & -    & -    & -    & .957 \\
  Uninformed Student~\cite{Bergmann2020} & ResNet-18        & .794 & .889 & .857 & -    \\
  SPADE~\cite{Cohen2020}                 & Wide ResNet-50-2 & .884 & .934 & .917 & .965 \\
  PaDiM (k=100)~\cite{Defard2020}          & ResNet-18        & .913 & .894 & .901 & .967 \\
  PaDiM (k=550)~\cite{Defard2020}          & Wide ResNet-50-2 & .932 & .916 & .921 & .975 \\ \midrule
  Ours (k=100) & MobileNetV3-Small& .924      & .885      & .898      & .968 \\
  Ours (k=100) & MobileNetV3-Large& .923      & .899      & .909      & .972 \\
  Ours (k=100) & ResNet-18        & .909      & .931      & .924      & .975 \\
  Ours (k=100) & Wide ResNet-50-2 & .925      & .938      & .934      & .979 \\
  Ours (k=300) & Wide ResNet-50-2 & \bf{.934} & \bf{.946} & \bf{.942} & \bf{.982} \\
  \bottomrule
  \end{tabular}
\end{table*} 
\begin{table*}[t!]
  \centering
  \caption{The ROC results for the unsupervised anomaly segmentation task using the KolektorSDD and KolektorSDD2 datasets. We report the score for each fold of the KolektorSDD dataset, their mean and standard deviation (Std.), and the mean score for the KolektorSDD2 dataset with the standard deviation with three random seeds.
  Notice that we reproduce the scores of PaDiM~\cite{Defard2020} with the same setting with ours except the method of approximation. We use ResNet-18 with k=100 for the setting.
  } 
  \label{tbl:kolektor}
  \begin{tabular}{lccccc}
  \toprule
  Model                                  & Fold 1    & Fold 2    & Fold 3    & Mean  Std.      & KolektorSDD2         \\ \midrule
  Uninformed student~\cite{Bergmann2020} & .904      & .883      & .902      & .896  .012      & .950  .005      \\
  PaDiM~\cite{Defard2020}                & .939      & .935      & .962      & .945  .015      & .956  .000      \\
  Semi-orthogonal (ours)                 & \bf{.953} & \bf{.951} & \bf{.976} & \bf{.960  .014} & \bf{.981  .000} \\
  \bottomrule
  \end{tabular}
\end{table*}
 
\paragrapht{State-of-the-art of MVTec AD.} We achieve a new state-of-the-art for the MVTec AD in the two major metrics, PRO and ROC, in the comparison with competing methods, with significant margins. The results consistently show that Mahalanobis distance-based methods~\cite{Defard2020} outperform the reconstruction error-based~\cite{bergmann2018improving,Bergmann2019,Schlegl2017} and knowledge distillation-based methods~\cite{Bergmann2020}.
Notably, using Wide ResNet-50-2, our method significantly outperforms PaDiM with less computational and memory complexities with =300.
It suggests that our method can readily exploit more powerful backbone networks while the computational cost is efficiently controlled by , without any fine-tuning of backbone networks.
The scores of the total 15 categories can be referred in \tbl~\ref{tbl:mvtecad_pro_category}, \appx.

\paragrapht{State-of-the-art of KolektorSDD.} In \tbl~\ref{tbl:kolektor}, we compare our method with the other comparative methods using the KolektorSDD and KolektorSDD2 datatsets. Although the third fold of the KolektorSDD dataset tends to have slightly higher score than others which impacts on the standard deviation, our method consistently outperforms the others across all folds. 
Using the more samples in the KolektorSDD2, the performance of the uninformed student~\cite{Bergmann2020} is notably improved; however, the localized Mahalanobis-based methods outperform it, and our method shows the consistence.
For this comparison, we reproduce the uninformed student~\cite{Bergmann2020} and PaDiM~\cite{Defard2020}. Notice that we use the same setting of ResNet-18 with k=100 for the PaDiM except the approximation method. For the uninformed student~\cite{Bergmann2020}, we use their model with the receptive size of 33  33 for the best result. We follow the other training settings.

\begin{table*}[t!]
  \centering
  \caption{The ROC results for the unsupervised anomaly segmentation task using the mSTC dataset. 
  Our method use ResNet-18 with k=100 for the fair comparison.
  } 
  \label{tbl:stc}
  \begin{tabular}{lcccc}
  \toprule
  Model     & CAVGA-RU~\cite{Venkataramanan2020} & SPADE~\cite{Cohen2020} & PaDiM~\cite{Defard2020} & Ours \\ \midrule
  ROC     & .85\0    & .899    & .912    & \bf{.921} \\
  \bottomrule
  \end{tabular}
\end{table*}
 
\paragrapht{State-of-the-art of mSTC.} In \tbl~\ref{tbl:stc}, our method consistently outperforms the comparative methods in the unsupervised abnormal event segmentation task, while achieving a new state-of-the-art. Notice that this dataset has different domain from the other datasets since the manufacturing product images tend to have a similar shape and are center-aligned.

\paragrapht{Visualization.} \fig~\ref{fig:mvtecad_grid_visual} visualizes an example from the \textit{Grid} category. In this case, our method shows a better prediction than the previous state-of-the-art~\cite{Defard2020}, detecting three small regions of anomalies. Please remind that the metric of PRO emphasizes to detect all small regions in the ground-truth. More examples can be found in \fig~\ref{fig:mvtecad_all_visual}, \appx.