\voc{Experimental results on Pascal VOC 2012. Improvements using AWT \underline{underlined}. Best among columns in \textbf{bold}. :~results excerpted from~\cite{zhang2022representation}. * implies results come from re-implementation. Other results come from the respective papers.}

\section{Experiments}

\subsection{Experimental settings}

\noindent\textbf{Datasets:}
We conduct experiments on the segmentation datasets namely Pascal VOC 2012~\cite{everingham2015pascal}, ADE20K~\cite{zhou2017scene} and Cityscapes~\cite{cordts2016cityscapes} using different incremental splits. Pascal VOC 2012~\cite{everingham2015pascal} covers 20 object (or \emph{things}) classes and one background class. ADE20K~\cite{zhou2017scene} is a large scale dataset containing 150 classes of both \emph{things} and \emph{stuff} (uncountable or amorphous regions like sky or grass). Cityscapes~\cite{cordts2016cityscapes} has 19 classes having both \emph{things} and \emph{stuff} and covering scenes from 21 different urban cities.

\noindent\textbf{CISS Protocols:} Two different CISS settings introduced by~\cite{cermelli2020modeling} are \emph{disjoint} and \emph{overlapped}. While the \emph{disjoint} setting assumes that the future classes are known and removes images with future classes from the current step, the \emph{overlapped} setting is more realistic and has no such assumption. Similar to~\cite{douillard2021plop, cha2021ssul}, we also follow the \emph{overlapped} setting in our experiments. We denote the different settings as X-Y where X is the number of classes in the initial step followed by Y number of classes at every step until all the classes are seen. We train 15-5 (15 classes followed by 5 classes), 15-1 (15 then 1 class in each step), 5-3 and 10-1 settings on VOC. Similarly, we train 100-50, 100-10, 100-5 and 50-50 on ADE20K and 14-1 and 10-1 settings on Cityscapes.

\noindent\textbf{Metrics:}
The mean Intersection over Union (mIoU) metric is calculated after the last step for the initial set of classes, the incremental classes, and for all the classes. The mIoU for the initial classes reflects the stability of model to catastrophic forgetting. The mIoU for the incremental classes reflects the plasticity of the model to learn new classes and the overall mIoU metric signifies the overall performance.

\noindent\textbf{Implementation Details:}
Deeplab-v3~\cite{chen2017rethinking} with a ResNet-101~\cite{he2016deep} backbone pretrained on ImageNet~\cite{deng2009imagenet} having output stride of 16 is used for the experiments. Similar to~\cite{zhang2022representation}, we use a higher initial learning rate and obtain an improved baseline for MiB. We train MiB and MiB+AWT models with SGD and a learning rate of  for the first step only and  for the incremental steps. The models are trained with a batch size of 24 using 2 GPUs for 30 epochs per step for VOC and Cityscapes and 60 epochs for ADE20K. Specific to SSUL models, we follow the same training settings as~\cite{cha2021ssul} since it performs freezing of weights and requires different training hyperparameters. The final results are reported on the validation set of the datasets. Since Cityscapes does not have a real background class, we merge the unlabeled classes into a virtual background class.

We use layer integrated gradients from~\cite{kokhlikyan2020captum} for obtaining the attributions and a threshold  to select the 25\% most significant channels for new classes based on experiments provided in the supplementary material. We obtain a unique set of channels mask for each new class for all settings having 5 or lesser class increments. For settings like 100-10, 100-50 and 50-50 on ADE20K, we use a single channel mask for all the new classes. Code is publicly available\footnote{\url{https://github.com/dfki-av/AWT-for-CISS}}.


\noindent\textbf{Baselines:} We compare our approach with the recent state-of-the-art methods ILT~\cite{michieli2019incremental}, MiB~\cite{cermelli2020modeling}, SDR~\cite{michieli2021continual}, PLOP~\cite{douillard2021plop}, SSUL~\cite{cha2021ssul}, RCIL~\cite{zhang2022representation} and UCD~\cite{yang2022uncertainty}. We apply AWT on two methods, MiB~\cite{cermelli2020modeling} and SSUL~\cite{cha2021ssul}.
We also compare with the upper bound (Joint model learned in non-incremental manner). We do not consider approaches using data from past steps~\cite{maracani2021recall} or auxiliary unlabeled data~\cite{yu2022self}.


\ade{Experimental results on ADE20K. Improvements using AWT \underline{underlined}. Best among columns in \textbf{bold}. :~results excerpted from~\cite{zhang2022representation}. * implies results come from re-implementation. Other results come from the respective papers.}

\subsection{Quantitative Evaluation}

\noindent\textbf{Pascal VOC 2012:} We show the quantitative experiments on VOC 15-5, 15-1, 5-3 and 10-1 settings in \cref{tab:voc}. We observe that while ILT struggle on all settings, other methods show significant improvements. Pooling-based distillation methods like PLOP and RCIL do better in 15-5, 15-1 and 10-1 settings but these methods perform poorly on the 5-3 setting where the number of classes is less in the initial step.

AWT with MiB outperforms MiB significantly on all the settings. On 15-5, our model outperforms MiB by 1.5 percentage point () on the overall \miou{} metric. On the 15-1 setting, our model reduces the forgetting of the initial classes by 11  while the overall performance improves by 8.7 . On the 5-3 setting having multiple class increments, AWT improves the overall \miou{} by 4.3  over MiB. On the most challenging setting of 10-1 having 11 steps, AWT reduces the forgetting of the initial classes by 19.1  and improves the learning of new classes by 4.2 . 

AWT with SSUL~\cite{cha2021ssul} performs similar to SSUL for the 15-5, 15-1 and 5-3 settings, while for the challenging 10-1 setting, it reduces forgetting of the initial classes by 1.8  and improves the performance on new classes by 1.0 . SSUL makes use of saliency maps targeted for \emph{things} or objects and moves them from background to an unknown class for representing the future classes. This label augmentation improves performance on all settings of VOC since this dataset has only object classes. On the contrary, this saliency-based modelling is not applicable for ADE20K, Cityscapes and other datasets which have both \emph{things} and \emph{stuff} classes, and SSUL suffers from high forgetting as we observe in~\cref{tab:ade20k,tab:cityscapes}.


\noindent\textbf{ADE20K:} ADE20K~\cite{zhou2017scene} is a difficult dataset with 150 classes and has the joint model \miou{} of only 38.9\%. We report the experimental results on ADE20K 100-50, 100-10 and 50-50 in \cref{tab:ade20k} with analysis of performance on the incremental sets of classes. We also consider a long setting of 100-5 (11 tasks) in \cref{tab:ade20k2}. 


\secondade{Experimental results on the 100-5 setting on ADE20K. Improvements using AWT \underline{underlined}. Best among columns in \textbf{bold}. :~results excerpted from~\cite{zhang2022representation}. * implies results come from re-implementation.}

On 100-50, our model improves the overall performance over MiB by 0.3 .
On 50-50 setting, our model achieves an overall improvement of 1.7  over MiB and 1.0  over RCIL. Moving to the longer sequence of 100-10 with 6 steps, our model improves MiB by 3.6  and PLOP+UCD by 0.9 . On the 11 step setting of 100-5, AWT improves MiB by 4.6  and its nearest contender SSUL by 1.0 . MiB+AWT achieves state-of-the-art results on all settings of ADE20K indicating the robustness towards predicting both \emph{things} and \emph{stuff} classes.

\noindent\textbf{Cityscapes:} We perform CISS experiments on two long sequence settings of 14-1 (6 tasks) and 10-1 (10 tasks) of Cityscapes~\cite{cordts2016cityscapes} dataset. We introduce the 10-1 setting where we initially train on 10 classes (road, sidewalk, building, wall, fence, pole, light, sign, vegetation, terrain) and add each of the 9 classes (sky, person, rider, car, truck, bus, train, motorcycle, bicycle) one at a time. We evaluate naive fine-tuning (FT), PLOP, RCIL, SSUL, MiB, and AWT with both SSUL and MiB, and report the \miou{} results in \cref{tab:cityscapes}.

We observe that while FT has very low overall \miou{}, PLOP, RCIL and MiB have improved overall performance on both settings. SSUL shows higher performance on incremental classes but with very high forgetting on the initial classes compared to others.
On the 14-1 setting, AWT with SSUL improves the overall \miou{} over SSUL by 0.8  and MiB+AWT outperforms MiB by 1.5  with a significant improvement of 7.3  on the performance of incremental classes (15-19). On the longer 10-1 setting, SSUL+AWT increases the overall \miou{} by 0.5  over SSUL while MiB+AWT improves over MiB by 3.0  with a good margin of 7.1  improvement on the incremental classes (11-19). AWT significantly improves the plasticity of the models to better learn the new classes in both settings.

\cityscapes{Experimental results on Cityscapes. Improvements using AWT \underline{underlined}. Best among columns in \textbf{bold}. All results come from our implementation.}


\subsection{Ablation Study}\label{sec:ablation}
We analyze the effectiveness of our approach with ablation experiments on Pascal-VOC 2012 for the 15-1 setting. 

\noindent\textbf{Selective weight transfer:} We analyze the importance of the selective weight transfer approach in \cref{tab:addablate}. 
The weight transfer proposed by MiB~\cite{cermelli2020modeling} is a better choice compared to the case when no weights are transferred. We show that our proposed AWT ensures the selection of the most significant channels for new classes by performing experiments with random selection of channels without using attributions. We observe that randomly selecting the same number of channels (25\% of total channels) and transferring their weights in the same way as AWT performs poorly on both initial and incremental sets of classes.

\noindent\textbf{Design choices:} We consider the alternative ways of selecting the significant channels and analyze them in \cref{tab:ablate}. In AWT, we take the mean of the attribution maps from all images of the current step and then perform max-pooling. Here, we consider the alternative of pooling the channels first for all the images and then take the mean of the pooled values. We also consider using average-pooling instead of max-pooling. We experimentally show that mean followed by max-pool is the best choice for channel selection.

\addablate{Ablation study for selective channel weights transfer on Pascal-VOC 2012.}

\ablate{Ablation study for different design choices using MiB~\cite{cermelli2020modeling} + AWT on Pascal-VOC 2012.}

\begin{figure}[t]
\centering
\includegraphics[width=0.95\columnwidth]{images/boxplot.pdf}
\caption{Boxplots of the \miou{} of initial, new, and all classes for 10 random class orders.}
\label{fig:boxplot}
\end{figure}

\begin{figure*}[t]
\includegraphics[width=\textwidth]{images/city_combo.pdf}
    \caption{Visualization of predictions using MiB and MiB+AWT in 14-1 setting for Cityscapes. MiB is highly biased towards the new classes and classifies the \emph{bus} as \emph{train} (row 1) while MiB+AWT correctly classifies the \emph{bus} (row 2).}
    \label{fig:combo2}
\end{figure*}

\noindent\textbf{Random class ordering:} The order of classes plays an important role in CISS settings. We experiment with 10 different class orderings on VOC 15-1 setting. We show the average performance for MiB and MiB+AWT in \cref{fig:boxplot}. We also plot the difference between MiB+AWT and MiB for every class order to demonstrate the robustness of our method using random class sequences.

\noindent\textbf{Computational Complexity:} The time taken for the attribution module depends on the number of new-class images. We use two Nvidia RTXA6000 GPUs for training the models. For each image, it takes approximately 0.68 seconds to compute the attributions.
For VOC 15-1, MiB+AWT takes 10.32 hours for training while the attribution module for all steps only takes 37 minutes (6\% of the total training time). Thus, the computational time for the attribution module is considerably less compared to the entire training process.

For further analysis, refer to the supplementary paper.

\subsection{Qualitative Evaluation}
\cref{fig:combo2} shows the predictions of MiB and MiB+AWT across time on Cityscapes 14-1 setting. MiB is biased towards the new classes and forgets the class (\emph{bus}) learned in step 2 and classifies the \emph{bus} as \emph{train} from step 3 onward. MiB+AWT still classifies the \emph{bus} correctly till step 5.

\cref{fig:ade_combo} shows the predictions for both MiB and MiB+AWT models trained in 100-5 setting on test images of ADE20K. We show that MiB+AWT improves predictions of classes like \emph{fan} (row 1), \emph{wardrobe} (row 2) and \emph{chair, chandelier} (row 3) compared to MiB.

\adecombo{}