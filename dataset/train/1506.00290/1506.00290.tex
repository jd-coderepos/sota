\documentclass[11pt]{article}
\usepackage{amssymb,amsmath,amsthm,sectsty,url,ifpdf}
\usepackage[letterpaper,hmargin=0.972in,vmargin=1.0in]{geometry}

\ifpdf
\usepackage[bookmarks=true,pdfstartview=FitH,colorlinks,linkcolor=blue,filecolor=blue,citecolor=blue,urlcolor=blue]{hyperref}
\else
\usepackage[dvipdfm,bookmarks=true,pdfstartview=FitH,colorlinks,linkcolor=black,filecolor=black,citecolor=black,urlcolor=black]{hyperref}
\fi

\usepackage{cleveref,aliascnt}

\usepackage[boxed]{algorithm}
\usepackage[labelfont=bf,small]{caption}
\usepackage{multicol}
\setlength{\columnseprule}{0.4pt}




\theoremstyle{plain}
\newtheorem{theorem}{Theorem}[section]
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{corollary}[theorem]{Corollary}
\newtheorem{observation}[theorem]{Observation}
\newtheorem{fact}[theorem]{Fact}
\crefname{fact}{Fact}{Facts}
\newtheorem{claim}[theorem]{Claim}
\crefname{claim}{Claim}{Claims}

\newtheorem{notation}[theorem]{Notation}
\theoremstyle{definition}
\newtheorem{definition}[theorem]{Definition}

\makeatletter
\newtheorem*{rep@theorem}{\rep@title}
\newcommand{\newreptheorem}[2]{\newenvironment{rep#1}[1]{\def\rep@title{#2 \ref{##1}}\begin{rep@theorem}}{\end{rep@theorem}}}
\makeatother

\newreptheorem{theorem}{Theorem}

\sectionfont{\large}
\subsectionfont{\normalsize}
\numberwithin{equation}{section} 
\newcommand{\MyParagraph}[1]{\medskip \noindent {\bf #1}}
\renewcommand{\paragraph}{\MyParagraph}


\newcommand{\pr}[1]{\Pr\! \left[ {#1} \right]}
\newcommand{\prob}[2]{\Pr_{#1}\! \left[ #2 \right]}
\newcommand{\MyAtop}[2]{\genfrac{}{}{0pt}{}{#1}{#2}}
\DeclareMathOperator*{\argmin}{arg\,min}
\DeclareMathOperator*{\argmax}{argmax}

\newcommand{\ignore}[1]{}
\newcommand{\qedsymb}{\hfill{\rule{2mm}{2mm}}}
\renewenvironment{proof}{\begin{trivlist} \item[\hspace{\labelsep}{\bf
\noindent Proof.\/}] }{\qedsymb\end{trivlist}}
\newenvironment{MyEqn}[1]{\setlength\arraycolsep{2pt}}\newenvironment{MyEqnNum}[1]{\setlength\arraycolsep{2pt}}\newenvironment{MyEnumerate}[1]{\begin{enumerate}\setlength{\itemsep}{0.1cm}
\setlength{\parskip}{-0.05cm} #1}{\end{enumerate}}
\newenvironment{MyItemize}[1]{\begin{itemize}\setlength{\itemsep}{0.1cm}
\setlength{\parskip}{-0.05cm} #1}{\end{itemize}}

\newenvironment{proofsketch}{\begin{trivlist} \item[\hspace{\labelsep}{\bf
\noindent Proof Sketch.\/}] }{\qedsymb\end{trivlist}}
\newenvironment{proofof}[1]{\begin{trivlist} \item[\hspace{\labelsep}{\bf
\noindent Proof of #1.\/}] }{\qedsymb\end{trivlist}}

\sectionfont{\large}
\subsectionfont{\normalsize}
\numberwithin{equation}{section} \newcommand{\aka} {also known as\ }
\renewcommand{\aka} {a.k.a.\ }
\newcommand{\wrt} {with respect to\ }
\newcommand{\resp}{resp.,\ }
\newcommand{\ie}  {i.e.,\ }
\newcommand{\eg}  {e.g.,\ }
\newcommand{\etal}{{et~al.\ }}
\newcommand{\etalcite}[1]{{et~al.~\cite{#1}}}

\newcommand{\abs}[1]{\left|#1\right|}
\newcommand{\norm}[1]{\lVert#1\rVert}

\newcommand\E{\mathop{\mathbb E}}
\newcommand{\Var}{{\bf Var}}
\newcommand{\Cov}{{\bf Cov}}
\newcommand{\eqdef} {\mathrel{\stackrel{\makebox[0pt]{\mbox{\normalfont\tiny
def}}}{=}}}

\newcommand{\U}{\mathbf U}
\newcommand{\N}{\mathbb N}
\newcommand{\R}{\mathbb R}
\newcommand{\Z}{\mathbb Z}
\newcommand{\C}{\mathbb C}
\newcommand{\F}{\mathbb F}
\newcommand{\Dc}{\mathcal D}
\newcommand{\Hc}{\mathcal H}
\newcommand{\Ec}{\mathcal E}
\newcommand{\Fc}{\mathcal F}
\newcommand{\Tc}{\mathcal T}
\newcommand{\Xc}{\mathcal X}
\newcommand{\Yc}{\mathcal Y}
\newcommand{\Kc}{\mathcal K}
\newcommand{\GF}{\mathbb{GF}}
\newcommand{\B}{\{ 0,1 \}}
\newcommand{\BM}{\{ -1,1 \}}

\newcommand{\cF}{\mathcal F}
\newcommand{\cX}{\mathcal X}
\newcommand{\cY}{\mathcal Y}
\newcommand{\cZ}{\mathcal Z}
\newcommand{\cC}{\mathcal C}

\newcommand{\NP}{{\class{NP}}}
\newcommand{\iocoRP}{{\class{io\textsf{-}coRP}}}
\newcommand{\coRP}{{\class{coRP}}}
\newcommand{\ioBPP}{{\class{io\textsf{-}BPP}}}
\newcommand{\PPOLY}{{\class{P/Poly}}}
\newcommand{\BPP}{{\class{BPP}}}
\newcommand{\coNP}{{\class{coNP}}}
\newcommand{\PP}{{\class{P}}}
\newcommand{\NC}{{\class{NC}^1}}
\newcommand{\mNC}{{\class{mNC}^1}}
\newcommand{\class}[1]{\mathsf{#1}}
\newcommand{\size}{\mathsf{size}}

\def\epsilon{\varepsilon}
\def\eps{\varepsilon}
\newcommand{\1}{\mathbf{1}}
\newcommand{\A}{\mathcal A}
\newcommand{\D}{\mathcal D}

\newcommand{\Adv}{\mathcal A}
\newcommand{\AdvB}{\mathcal{B}}
\newcommand{\AdvC}{\mathcal{C}}
\newcommand{\paren}[1]{\left(#1\right)}
\newcommand{\ith}[1]{{#1}\textsuperscript{th}}
\newcommand{\st}[1]{{#1}\textsuperscript{st}}
\newcommand{\negl}{{\mathsf{negl}}}
\newcommand{\poly}{{\mathsf{poly}}}
\newcommand{\polylog}{{\mathsf{polylog}}}
\newcommand{\DTIME}{{\mathsf{DTIME}}}
\newcommand{\Sc}{{\mathcal{S}}}
\newcommand{\NUL}{\mathsf{NUL}}
\newcommand{\SD}{\mathsf{SD}}
\newcommand{\minH}{{\mathsf{H}_\infty}}
\newcommand{\myand}{{\;\;\wedge\;\;}}
\newcommand{\PPT}{{\text{PPT }}}
\newcommand{\secparam}{\lambda}
\def{\right)}

\newcommand{\AND}{\mathsf{AND}}
\newcommand{\OR}{\mathsf{OR}}
\newcommand{\NOT}{\mathsf{NOT}}


\newcommand{\Inf}{\mathsf{Inf}}
\newcommand{\Ext}{\mathsf{Ext}}
\newcommand{\Sen}{\mathsf{Sens}}

\newcommand{\Th}{\mathsf{Th}}
\newcommand{\wt}{\mathsf{wt}}


\newcommand{\bias}{\mathsf{bias}}
\newcommand{\G}{\mathsf{G}} \newcommand{\GOOD}{\mathsf{Good}} 
\newcommand{\GOODc}{\mathsf{GoodRow}} \newcommand{\GOODm}{\mathsf{GoodMsg}} \newcommand{\GOODp}{\mathsf{GoodPoi}} \newcommand{\party}[1]{\mathsf{P}_{{#1}}}
\newcommand{\corr}{\textsf{corrupt}_k}
\newcommand{\cor}{\textsf{corrupt}}
\newcommand{\row}{\textsf{Row}}
\newcommand{\honest}{\textsf{honest}}
\newcommand{\spar}{\textsf{spare}}
\newcommand{\alive}{\textsf{Alive}}
\newcommand{\lo}{{\mathsf{R}}}
\newcommand{\sh}{{\mathsf{r}}}
\newcommand{\buck}{{\mathsf{b}}}
\newcommand{\CorruptAlg}{\mathsf{Corrupt}}
\newcommand{\SpareAlg}{\mathsf{Spare}}
\newcommand{\out}[3]{{\mathsf{out}(#2_{#1} \mid #3)}}
\newcommand{\success}{{\mathsf{succ}}}
\newcommand{\successset}{{\mathsf{succ_{s}}}}
\newcommand{\valI}[3]{{\success(#2_{#1} \mid #3)}}
\newcommand{\val}[2]{{\success(#2_{#1})}}
\newcommand{\valset}[2]{{\successset(#2_{#1})}}
\newcommand{\valbI}[4]{{\success_{#1}(#3_{#2 \mid #4})}}
\newcommand{\valb}[3]{{\success_{#1}(#3_{#2})}}
\newcommand{\valnI}[3]{{\success_{#1}({#2} \mid #3)}}
\newcommand{\valn}[2]{{\success_{#1}({#2})}}
\newcommand{\bucket}{{\mathsf{bucket}}}
\newcommand{\supp}{\mathsf{supp}}
\newcommand{\tmp}{\mathsf{tmp}}

\newcommand{\rt}[1]{\mathsf{root({#1})}}
\newcommand{\leftson}[1]{\mathsf{left(}{#1}\mathsf{)}}
\newcommand{\rightson}[1]{\mathsf{right(}{#1}\mathsf{)}}
\newcommand{\thr}{\mathsf{thr}}
\newcommand{\zero}{\mathbf{0}}

\newcommand{\ent}{\mathsf{entropy}}

\newcommand{\real}{\Adv}
\newcommand{\ideal}{\mathsf{ideal}}
\newcommand{\trans}{{\mathsf{Trans}}}
\newcommand{\Exp}{\mathsf{Exp}}
\newcommand{\MAP}{\mathsf{MAP}}
\newcommand{\event}{\mathsf{E}}

\theoremstyle{remark}
\newtheorem{remark}[theorem]{Remark}       

\newcommand{\CB}{\mathsf{CLIQUE}\text{--}\mathsf{BCAST}} 
\newcommand{\authnote}[4]{{\bf [{\color{#3} #1's Note:} {\color{#4} #2}]}}
\newcommand{\Inote}[1]{\authnote{Ilan}{#1}{red}{blue}}
\newcommand{\ynote}[1]{\authnote{Yael}{#1}{red}{blue}}

\def{\right)}


\title{Compressing Communication in Selection Protocols\footnote{A preliminary
    version of this work appeared in the 29th International Symposium on
    DIStributed Computing (DISC 2015), pp. 467--479.}}

\author{Yael Tauman Kalai \thanks{Microsoft Research. Email: {\tt
      yael@microsoft.com}.}
\and
Ilan Komargodski \thanks{Weizmann Institute of Science, Israel. Email: {\tt
      ilan.komargodski@weizmann.ac.il}. Part of this work done while an intern
    at MSR New England. Supported in part by a grant from the I-CORE Program of
    the Planning and Budgeting Committee, the Israel Science Foundation, BSF and
    the Israeli Ministry of Science and Technology.  } }


\date{}
\begin{document}

\maketitle

\begin{abstract}
  We show how to compress communication in selection protocols, where the goal is to agree on a sequence of random bits using only a broadcast channel. More specifically, we present a generic method for converting any selection protocol, into another selection protocol where each message is {\em short} while preserving the same number of rounds, the same output distribution, and the same resilience to error. Assuming that the output of the protocol lies in some universe of size~, in our resulting protocol each message consists of only  many bits, where  is the number of parties and  is the number of rounds.  Our transformation works in the presence of either static or adaptive Byzantine faults.

  As a corollary, we conclude that for any -round collective coin-flipping protocol, leader election protocol, or general selection protocols, messages of length  suffice (in the presence of either static or adaptive Byzantine faults).

  \bigskip \noindent {\small {\bf Keywords:} Communication complexity,
    compression, coin-flipping.}
\end{abstract}



\thispagestyle{empty}
\newpage \setcounter{page}{1}

\section{Introduction}
The resource of communication is central in several fields of computer
science. We focus on minimizing this resource for selection protocols. A
selection protocol is a protocol over  parties, each having a private source
of randomness, in which the goal of the parties is to agree on a sequence of
common random bits. We focus on the full information model \cite{BenOrL85},
where the parties communicate via a single broadcast channel. There is a global
counter which synchronizes parties in between rounds but they communicate
asynchronously withing rounds.  A selection protocol is a generalization of
several very well studied problems, including collective coin-flipping and
leader election.  

The challenge in designing such protocols is that a subset of the parties may be
corrupted and the rest of the parties should nevertheless agree on a random
output. We model faulty parties by a computationally unbounded adversary who
controls a subset of parties and whose aim is to bias the output of the
protocol. We assume that once a party is corrupted, the adversary gains complete
control over the party and can send any messages on its behalf, and the messages
can depend on the entire transcript so far.  In addition, we allow our adversary
to be \emph{rushing}, \ie it can schedule the delivery of the messages within
each round.  We consider two classes of adversaries: \emph{static} and
\emph{adaptive}. A static adversary is an adversary that chooses which parties
to corrupt ahead of time, before the protocol begins. An adaptive adversary, on
the other hand, is allowed to choose which parties to corrupt {\em adaptively}
in the course of the protocol as a function of the messages seen so far. We say
that a protocol is (statically/adaptively) \emph{secure} or \emph{resilient} if it results with a common
random output in the presence of a (statical/adaptive) adversary that corrupts parties.

We study the following question.
\begin{center}
  \textit{Is there a generic way to compress communication in selection
    protocols, without negatively affecting the round complexity,
    fault-tolerance and other resources?}
\end{center}
We give a positive answer to this question. Namely, we show how to compress
communication in selection protocols without incurring \emph{any} cost to the
round complexity or the resilience to errors. More details follow.

\paragraph{A concrete motivation: adaptively-secure coin-flipping.}
An important distributed task that was extensively studied in the full
information model, is that of \emph{collective coin-flipping}. In this problem,
a set of  parties use private randomness and are required to generate a
common random bit. The goal of the parties is to jointly output a somewhat
uniform bit even in the case that some of the parties are faulty and controlled
by a static (resp.~adaptive) adversary whose goal is to bias the output of the protocol
in some direction.

This problem was first formulated and studied by Ben-Or and Linial
\cite{BenOrL85}. In the case of static adversaries, collective coin-flipping is
well studied and almost matching upper and lower bounds are known
\cite{Feige99,RussellSZ02}, whereas the case of adaptive adversaries has
received much less attention. Ben-Or and Linial \cite{BenOrL85} showed that the
majority protocol (in which each party sends a uniformly random bit and the
output of the protocol is the majority of the bits sent) is resilient to
 adaptive corruptions. Furthermore, they conjectured that this
protocol is optimal, that is, they conjectured that any coin-flipping protocol
is resilient to at most  adaptive corruptions. Shortly afterwards,
Lichtenstein, Linial and Saks \cite{LichtensteinLS89} proved the conjecture for
protocols in which each party is allowed to send only \emph{one} bit. Very
recently, Goldwasser, Kalai and Park~\cite{GoldwasserKP15} proved a different
special-case of the aforementioned conjecture: any \emph{symmetric} (many-bit)
one-round collective coin-flipping protocol\footnote{A symmetric protocol 
  is one that is oblivious to the order of its inputs: namely, for any
  permutation  of the parties, it holds that
  .} is resilient to at
most  adaptive corruptions.  Despite all this effort,
proving a general lower bound, or constructing a collective coin-flipping
protocol that is resilient to at least  adaptive corruptions,
remains an intriguing open problem.

The result of \cite{LichtensteinLS89} suggests that when seeking for a
collective coin-flipping protocol that is resilient to at least
 adaptive corruptions, to focus on protocols that consist of
many communication rounds, or protocols in which parties send long messages.
Our main result (\Cref{lemma:many2few} below) is that long messages are not
needed in adaptively secure coin-flipping protocols with  rounds, and
messages of length  suffice.\footnote{Note that if one could show
  that these  bits can be sent bit by bit sequentially, then using
  the lower bound of \cite{LichtensteinLS89}, we could obtain that any
  collective coin flipping protocol in which each player sends  messages
  is resilient to at most  adaptive
  corruptions. However, in the adaptive setting it is not clear that security is
  preserved if messages are sent bit by bit.} This is true more generally for
leader election protocols, and for selection protocols where the output comes
from a universe of size at most quasi-polynomial in~.



\subsection{Our Results}
Our main result is that ``long'' messages are not needed for selection
protocols.  More specifically, we show how to convert any selection protocol,
whose output comes from a universe of size~, into a selection protocol
with the same communication pattern\footnote{Here, we mean that a party sends a
  message at round  of the new protocol only if it sends a message at round  of
  the original protocol.}, the same output distribution, the same
security guarantees, and where parties send messages of length .  Note that for many well studied distributed tasks, such as
coin-flipping, leader election, and more, the output is from a universe of size
at most , in which case our result says that if we consider
-round protocols, then messages of length  suffice.

\paragraph{Our results in more detail.}
Formally, we say that a selection protocol  is
\emph{-statically (\resp adaptively) secure} if for any adversary
 that \emph{statically (\resp adaptively)} corrupts at most 
parties, and any subset  of the output universe such that , it
holds that

where ``Output of '' means the output of the protocol when executed
in the presence of the adversary , ``Output of '' means the output of
the protocol when executed honestly, and the probabilities are taken over the
internal randomness of the parties. In addition, we say that a protocol 
\emph{simulates} a protocol  if the outcomes of the protocols are
statistically close (when executed honestly) and their communication patterns
are the same.

Our main result is a generic communication compression theorem which, roughly
speaking, states that -statically (\resp adaptively) secure
selection protocols \emph{do not} need ``long'' messages. Namely, we show that
any secure selection protocol which sends arbitrarily long messages can be
simulated by a protocol which is almost as secure and sends short messages. The
loss in security is a negligible (denoted by ), namely, asymptotically
smaller than any inverse polynomial function.

\begin{theorem}[Main theorem --- informal]\label{lemma:many2few}
  Any -statically (\resp adaptively) secure selection protocol
  that outputs  bits (or more generally, has an output universe of
  size~), can be simulated by a -statically (\resp
  adaptively) secure selection protocol, where  and
  parties send messages of length .
\end{theorem}

We note that the transformation in Theorem~\ref{lemma:many2few} results in a
\emph{non-uniform} protocol, even if the protocol we started with is uniform.
We elaborate on this in Section~\ref{sec:techniques}.


\subsection{Overview of Our Techniques}\label{sec:techniques}

In this section we provide a high-level overview of our main ideas and
techniques. First, we observe that in our model of communication (the full
information model where all communication is done via a broadcast channel) one
can assume, without loss of generality, that any selection protocol (in which
parties do not have private inputs except a source of randomness), can be
transformed into a public-coin protocol, in which honest parties' messages
consist only of random bits. This fact is a folklore, and for the sake of
completeness we include a proof sketch of it in \Cref{sec:public_coin}.

Our main result is a generic transformation that converts any public-coin
protocol, in which parties send arbitrarily long messages, into a protocol in
which parties send messages of length , where  is the
number of bits the protocol outputs,  is the number of parties participating
in the protocol, and  is the number of communication rounds.  The resulting
protocol simulates the original protocol, has the same round complexity, and
satisfies the same security guarantees. Next, we elaborate on how this
transformation works.

Suppose for simplicity that in our underlying protocol each message sent is of
length~ (and thus the messages come from a universe of size~), and
think of~ as being very large.  We convert any such protocol into a new
protocol where each message consists of only~ bits, where think of~
as being significantly smaller than~.  This is done by a priori choosing
 messages within the -size universe, and restricting the parties to
send messages from this restricted universe.  Thus, now each message is of
length , which is supposedly significantly smaller than~.  We note that
a similar approach was taken in \cite{Newman91} in the context of transforming
public randomness into private randomness in communication complexity, in
\cite{GoldreichS10} to reduce the number of random bits needed for property
testers, and most recently in \cite{GoldwasserKP15} to prove a lower bound for
coin-flipping protocols in the setting of strong adaptive adversaries.

A priori, it may seem that such an approach is doomed to fail, since by
restricting the honest parties to send messages from a small universe within the
large~-size universe, we give the adversary a significant amount of
information about future messages (especially in the multi-round case).
Intuitively, the reason security is not compromised is that there are {\em many}
possible restrictions, and it suffices to prove that a few (or only one) of
these restrictions is secure. In other words, very loosely speaking, since we
believe that most of the bits sent by honest parties are not ``sensitive'', we
believe that it is safe to post some information about each message ahead of
time.

For the sake of simplicity, in this overview we focus on static adversaries, and
to simplify matters even further, we assume the adversary always corrupts the
first~ parties. This simplified setting already captures the high-level
intuition behind our security proof in \Cref{sec:proof}.

Let us first consider one-round protocols. Note that for one-round protocols
restricting the message space of honest parties does not affect security at all
since we consider rushing adversaries, who may choose which messages to send
based on the content of the messages sent by all honest parties in that
round. Thus, reducing the length of messages is trivial in this case,
assuming the set of parties that the adversary corrupts is predetermined.  We
mention that even in this extremely simplified setting, we need  to be
linear in~ for correctness (``simulation''), \ie in order to ensure that the
output is distributed correctly.

Next, consider a multi-round protocol~.  We denote by~ the restricted
message space, \ie  is a subset of the message universe of size~, and
denote by  the protocol , where the messages are restricted to the
set~. Suppose that for any set~ there exists an adversary  that
biases the outcome of , say towards~.\footnote{Of course, it may be
  that for different sets~, the adversary~ biases the outcome to a
  different value. For simplicity we assume here that all the adversaries bias
  the outcome towards a fixed message, which we denote by .} We show that in
this case there exists an adversary~ in the underlying protocol that
biases the outcome towards~.  Loosely speaking, at each step the
adversary~ will simulate one of the adversaries . More
specifically, at any point in the underlying protocol, the adversary will
randomly choose a set~ such that the transcript so far is consistent (\ie
same transcript) with a run of protocol  with the adversary , and
will simulate the adversary .  The main difficulty is to show that with
high probability there exists such~ (\ie the remaining set of consistent
's is non-empty).  This follows from a counting argument and basic
probability analysis.

In our actual construction, we have a distinct set  of size~
corresponding to {\em each} message of the protocol.  Thus, if the underlying
protocol~ has~ rounds, and all the parties send a message in each round,
then the resulting (short-message) protocol is associated with  sets
 each of size~, where the message of the
 party in the  round is restricted to be in the set .
We denote all these sets by a matrix , where the row  of  corresponds to the set of
messages that the  party can send during the  round.

Note that there are  such matrices.  Each time
an honest party sends a uniformly random message in~ it reduces the set of
consistent matrices by approximately a~-factor (with high probability).
Any time the adversary  sends a message, it also reduces the set of
consistent matrices~, since his message is consistent only with some of the
adversaries , but again a probabilistic argument can be used to claim
that it does not reduce the set of matrices by too much, and hence, with high
probability there always exist matrices~ that are consistent with the
transcript so far.

We briefly mention that the analysis in the case of adaptive corruptions follows
the same outline presented above.  One complication is that the mere decision of
whether to corrupt or not reduces the set of consistent matrices~. Nevertheless, we
argue that many consistent matrices remain.

We emphasize that the above is an over-simplification of our ideas, and the actual proof is more complex.
We refer to \Cref{sec:proof} for more details.

\section{Preliminaries}\label{sec:prelim}
In this section we present the notation and basic definitions that are used in
this work. For an integer  we denote by  the set
.  For a distribution  we denote by  the
process of sampling a value  from the distribution . Similarly, for a set
 we denote by  the process of sampling a
value  from the uniform distribution over .  Unless explicitly
stated, we assume that the underlying probability distribution in our equations
is the uniform distribution over the appropriate set. We let  denote the
uniform distribution over . We use  to denote a logarithm in
base .

A function
 is said to be \emph{negligible} if for every constant  there exists
an integer  such that  for all .

The {\em statistical distance} between two random variables  and  over a
finite domain  is defined as


\subsection*{The Model}
\paragraph{The communication model and distributed tasks.}
We consider the synchronous model where a set of  parties
 run protocols. Each protocol consists of
\emph{rounds} in which parties send messages. We assume the existence of a
global counter which synchronizes parties in between rounds (but they are
asynchronous within a round). The parties communicate via a broadcast channel.

The focus of this work is on selection protocols where parties do not have any
private inputs and their goal is to agree on a sequence of random bits.
Examples of such tasks are coin-flipping protocols, leader election protocols,
etc.

Throughout this paper, we restrict ourselves to public-coin protocols.
\begin{definition}[Public-coin protocols]\label{def:public-coin}
  A protocol is \emph{public-coin} if all honest parties' messages consist only
  of uniform random bits.
\end{definition}
In \Cref{sec:public_coin} we argue that the restriction to public-coin protocols
is without loss of generality since in the full information model any selection
protocol can be converted into a public-coin one, without increasing the round
complexity and without degrading security (though this transformation may
significantly increase the communication complexity).


\paragraph{The adversarial model.}
We consider the {\em full information model} where it is assumed the adversary
is all powerful, and may see the entire transcript of the protocol.  The most
common adversarial model considered in the literature is the Byzantine model,
where a bound~ is specified, and the adversary is allowed to
corrupt up to~ parties. The adversary can see the entire transcript, has full
control over all the corrupted parties, and can broadcast any messages on their
behalf. Moreover, the adversary has control over the order of the messages sent
within each round of the protocol.\footnote{Such an adversary is often referred
  to as ``rushing''.}  We focus on the Byzantine model throughout this work.

Within this model, two types of adversaries were considered in the literature:  {\em static} adversaries, who need to specify the parties they corrupt {\em before} the protocol begins, and {\em adaptive} adversaries, who can corrupt the parties {\em adaptively} based on the transcript so far.  Our results hold for both types of adversaries.  Throughout this work, we focus on the adaptive setting, since the proof is more complicated in this setting.  In Subsection~\ref{sec:static} we mention how to modify (and simplify) the proof for the static setting.

\paragraph{Correctness and security.}
For any protocol  and any adversary , we denote by

the output of the protocol  when executed with the adversary , and where each honest party~ uses randomness~.


Let  be a protocol whose output is a string in  for some
. Loosely speaking, we say that an adversary is ``successful'' if he manages to bias the output of the protocol to his advantage.
More specifically,
we say that an adversary is ``successful'' if he chooses a predetermined subset  of some size~, and succeeds in biasing the outcome towards the set~.  To this end, for any set size~, we define

where  denotes the outcome of the protocol~ if all the parties are honest, and use randomness .

Intuitively, the reason we parameterize over the set size~ is that we may hope for different values of  for sets  of different sizes, since for a large set  it is often the case that
 is large, and hence  is inevitably small, whereas for small sets  the value  may be large.

For example, for coin-flipping protocols (where  and the outcome is a
uniformly random bit in the case that all parties are honest), often an
adversary is considered successful if it biases the outcome to his preferred bit
with probability close to~, and hence an adversary is considered successful
if  for either  or
, whereas for general selection protocols (where  is a parameter)
one often considers subsets  of size  for
some constant , and an adversary is considered successful if there
exists a constant  such that .

\begin{definition}[Security]\label{def:sec}
  Fix any constant , any , and any -party protocol
   whose output is an element in .  Fix any .  We say that
   is \emph{-adaptively secure} if
  for any adversary  that adaptively
  corrupts up to  parties, it holds that
  
\end{definition}
We note that this definition generalizes the standard security definition for coin-flipping protocols and selection protocols.
We emphasize that our results are quite robust to the specific security definition that we consider, and we could have used alternative definitions as well. Intuitively, the reason is that we  show how to transform any -round protocol~ into another -round protocol with short messages, that simulates~ (see Definition~\ref{def:sim} below), where this transformation is {\em independent} of the security definition.  Then, in order to prove that the resulting protocol is as secure as the original protocol~, we show that if there exists an adversary for the short protocol that manages to break security according to some definition, then there exists an adversary for~ that ``simulates'' the adversary of the short protocol and breaches security in the same way.
(See Section~\ref{sec:techniques} for more details, and Section~\ref{sec:proof} for the formal argument).

Finally, we mention that an analogous definition to Definition~\ref{def:sec} can be given for static adversaries.  Our results hold for the static definition as well.

\begin{definition}[Simulation]\label{def:sim}
Let  be an -party protocol with outputs in .  We say that an -party protocol~ simulates~ if

where  is a random variable that corresponds to the output of
protocol  assuming all parties are honest, and  is a random variable that corresponds to the output of protocol  assuming all parties are honest.
\end{definition}


\subsection*{Probabilistic Tools}
In the analysis we will use the following simple claims.

\begin{claim}\label{claim:prob}
  Let  be two integers. Let  and .  For every , denote
  by  Then,
  
  and for any ,
  
\end{claim}
\begin{proof}We begin with the proof of the first part. By the definition of expectation
  
 This, together with the the Cauchy-Schwarz inequality, implies that
  \frac{1}{\sqrt{M}}\sum_{i=1}^M \alpha_i \cdot \frac{1}{\sqrt{M}}
  where the last equality follows from the fact that .

  For the second part, let
  
  Then,
  
  as desired, where the first inequality follows from the union bound and the
  definition of , the second
  inequality follows from the definition of , and the third inequality follows
  from the fact that .
\end{proof}



\begin{definition}[Entropy]\label{def:entropy}
  Let  be a random variable with finite support. The (Shannon) entropy of 
  is defined as
  
\end{definition}

\begin{claim}\label{claim:ent2sd}
  Let  be a random variable with domain . If , then
  
  where  is the uniform distribution over  bits, and where  denotes the statistical distance between  and  (see Equation~\eqref{eqn:SD} for the definition of statistical distance).
\end{claim}
\newcommand{\RE}{\mathbf{D}_{\mathsf{KL}}}
\begin{proof}
  The \emph{relative entropy} (\aka the Kullback-Leibler divergence) between two
  distributions  is defined as
   \frac{\D_1(x)}{\D_2(x)}
    
  A well known relation between relative entropy and the statistical distance is
  known as Pinsker's inequality which states that for any two distributions
   as above, it holds that
  

  Thus, it remains to bound the relative entropy of  and . Let . We get that
   p_x\cdot 2^{k} \log (p_x) + k 
  Since , we get that
  
  Plugging this into Pinsker's inequality (see \Cref{eq:pinsker}), we get that
  
\end{proof}

\section{Compressing Communication in Distributed Protocols}\label{sec:proof}
In this section we show how to transform any -party -round -adaptively secure
public-coin protocol, that outputs messages of length  and sends messages of
length , into an -party -round -adaptively secure
public-coin protocol in which every party sends messages of length .

Throughout this section, we fix  to be the negligible function defined by

  and where .

\begin{theorem}\label{thm:main}
Fix any , , , and any -party -round public-coin
  selection protocol  that outputs messages in  and in which all parties send
  messages of length .  Then, for any constant , any , and any , if  is -adaptively secure then there exists an -party -round
  -adaptively secure public-coin selection protocol, that simulates~, where all parties send messages of length , and where  (and  is the negligible function defined in Equation~\eqref{eqn:mu*}).
\end{theorem}

 \begin{proof}

Fix any  , , ,  and any -party -round public-coin
  protocol  that outputs messages in  and in which all parties send
  messages of length . Fix any constant , any , and any  such that  is -adaptively secure. We start by describing the construction of the (short message) protocol. Let

Let  be the set all
possible  matrices, whose elements are from .
Note that .   We often
interpret  as a function

or as a matrix where each row is described by a pair from .  We abuse notation and denote by

As a convention, we denote by  a
message from  and by  and a message from . \\

From now on, we assume for the sake of simplicity of notation, that in protocol~, in each round, all the parties send a message.
Recall that we also assume for the sake of simplicity (and without loss of
generality) that~ is a public-coin protocol (see
Definition~\ref{def:public-coin}). For any  we define a protocol  that simulates the
execution of the protocol , as follows.

\paragraph{The Protocol~.}
In the protocol , for every  and ,
in the  round, party  sends a random string .
We denote the resulting transcript in round  by

and denote the entire transcript  by

We abuse notation, and define for every round ,

Similarly, we define

The outcome of protocol~ with transcript  is defined to be the outcome of protocol~ with transcript .\\

It is easy to see that the round
complexity of  (for every ) is the same as that of~.  Moreover, we note that with some complication in notation we could have also preserved the exact communication pattern (instead of assuming that in each round all parties send a message).

In order to prove \Cref{lemma:many2few} it suffices to prove the following two lemmas.
\begin{lemma}\label{lemma:H_secure}
  There exists a subset  of size , such that for every matrix  it holds that  is -adaptively secure for , where  is the negligible function defined in Equation~\eqref{eqn:mu*}.

\end{lemma}

\begin{lemma}\label{claim:simulation}
There exists a negligible function  such that,

\end{lemma}

Indeed, given \Cref{lemma:H_secure,claim:simulation}, we obtain that there
exists an  such that  is -adaptively secure and
it simulates .
\end{proof}

In \Cref{sec:claim_simulation} we give the proof of \Cref{claim:simulation} and
in \Cref{sec:proof_of_lemma} we give the proof of \Cref{lemma:H_secure}.

\subsection{Proof of Lemma~\ref{claim:simulation}}\label{sec:claim_simulation}
  By the definition of statistical distance, in order to prove
  Lemma~\ref{claim:simulation} it suffices to prove that there exists a
  negligible function  such that,


Note that

Therefore, it suffices to prove that there exists a negligible function 
such that for every ,

To this end, for any , we denote by 
and . Using this notation, it suffices to
prove that there exists a negligible function  such that for every
,


For any , consider the experiment, where we run the protocol 
independently  times, and check how many times the
output is~. Denote by  the identically distributed random
variables, where  if in the  run of the protocol the outcome
is~, and  otherwise.  The Chernoff bound\footnote{The Chernoff bound
  states that for any identical and independent random variables
  , such that  for each~, if we denote by
   then .} implies that for
every  and for every ,

In particular, setting  we deduce that


We next define random variables  as follows: We run the protocol
 independently  times, and we set  if in the  run the
outcome is~, and otherwise we set .  We note that the same argument
used to deduce Equation~\eqref{eqn:X} can be used to deduce that

Note that,

where the first inequality follows from the triangle inequality, the second
inequality follows from the union bound, and the third inequality
follows from Equations~\eqref{eqn:X} and~\eqref{eqn:Y}.  Thus, it suffices to
prove that there exists a negligible function~ such that

To this end, notice that for a random ,

where the first equation follows from a standard hybrid argument. The second
equation follows from the fact that  are independent of
.  The third equation follows from the fact that the
statistical distance between  and
 is maximal for .  The forth equation follows
from the fact that  and  are
identically distributed if the following event, which we denote by ,
occurs: Recall that each  depends only on  {\em random} coordinates of
. We say that  occurs if the  coordinates that 
depends on are disjoint from all the  coordinates that
 depend on. The forth equation follows from the fact that
. The rest of the equations
follow from basic arithmetics and from the definition of~ and~.

In particular, this implies that


Consider the algorithm  that given , supposedly
distributed according to  or distributed according
to , outputs~ if , and
otherwise outputs~.  Equation~\eqref{eqn:Y} implies that

This together with Equation~\eqref{eqn:SDXY}, implies that

which by the definition of , implies that

This, in particular, implies that

as desired.

\subsection{Proof of Lemma \ref{lemma:H_secure}}\label{sec:proof_of_lemma}
Assume towards contradiction that for every set  of size  there exists  such that  is
\emph{not} -adaptively secure, for . This implies that there exists a set  of size  such that for every  there exists an
adversary  that adaptively corrupts at most~ parties and satisfies 

This, in turn, implies that there exists a set  of size~
such that for at least -fraction of the
's in  the adversary  satisfies that .  We denote this
set of 's by . Notice that


The proof proceeds as follows: we show how to use these adversaries
 to construct an adversary  such that

contradicting the -adaptive security of~.

The idea is for the adversary  to simulate the execution of one of the
's. The problem is that we do not know ahead of time which  will be
consistent with the transcript of the protocol, since we have no control over the (long) random messages of the honest parties.
We overcome this problem by choosing  {\em adaptively}.  Namely, at any point in the protocol, 
simulates a random adversary , where  is a random matrix that
is consistent (in some sense that we explain later) with the transcript up to that point.


More specifically, for every  and every , we denote by
 the set of matrices that are consistent with the transcript up
until the point where the  message of the  round is about to
be sent.  Fix any round  and any . Roughly speaking, in the  round before the  message is to be sent, the adversary 
simulates  where  is chosen
uniformly at random. If  corrupts a party  then 
also corrupts .  If  sends a message  on behalf
of a corrupted party , then  will send the message
 on behalf of party .  In this case, we
define  to be all the matrices in  which are consistent
with the transcript so far and agree with  on row
.  If  asks an honest party  to send its message,
the adversary~ will also ask honest party  to send a message. Upon
receiving a message  from , we choose a random matrix  that is consistent with the transcript so far, and set  to be all the
matrices in  that are consistent with the transcript so far, and
where we fix the  row to be the  row of~.

Before giving the precise description of the adversary , we provide some
useful notation.  We denote the transcript generated in an execution of the
protocol~ with an adversary  by . Note that
 consists of  vectors (one per each round), where each vector
consists of~ pairs of the form

where  and , where the order
means that in this round party  sent his message first, then party
 sent his message, and so on (recall that in our model, the adversary has control over the scheduling of the messages within each round). We sometimes consider a partial
transcript  (\ie a prefix of a transcript) which corresponds to a
partial execution of the protocol~ with the adversary~ until after the  message in the
 round was sent. For , we denote by

the mapping that takes as input a row number  and a (long) message
in , and converts it into a (short) message  such
that .  If no such message exists,  outputs~.

Let  be a (long) partial transcript of . The corresponding
(short) transcript of , denoted by , is defined
recursively, as follows.  Let .  Then,

We initialize  and .  Using this
notation, a formal description of the adversary  is given in
Figure~\ref{fig:adv_long2short}. \\

\begin{algorithm}
  \caption{The adversary  before the  message of round
    .} \label{fig:adv_long2short}
  \center{\bf The adversary  before the
     message of round  }
  \begin{MyEnumerate}
  \item If , output  and HALT.
  \item\label{it:2} Choose  uniformly at random.  Let
     denote the (short) transcript in
    the protocol  that corresponds to the (long) transcript
    .
  \item\label{it:3} If  corrupts a party 
    then corrupt .
  \item\label{it:4} If  sends a message on behalf of a
    corrupt party , then do the following:
    \begin{MyEnumerate}{}
    \item Denote by  the message that
       sends on behalf of . Let .
    \item Send the message  on behalf of party .
    \item Add  to the partial transcript.  Namely, set
      \trans_{i,j-1},(\party{u},\lo^*)

    \item\label{it:4d} Define  to be the set of all 
      that are consistent with the transcript so far, and for which
      . Namely, set
        
      \end{MyEnumerate}
    \item\label{it:5} If  does not corrupt, and orders
      an honest party  to send a message, then do the following:
    \begin{enumerate}
    \item Do not corrupt, and order honest party  to send a
      message. Denote the message it sends by .
     \item Add  to the partial transcript.  Namely, set
      
    \item Choose a random matrix
      

    \item\label{it:5c} Define  to be the set of all  that are consistent with the transcript so far, and agree
      with  on row . That is,
      
       \end{enumerate}
  \item\label{it6} If , set  and .
  \end{MyEnumerate}
\end{algorithm}

In order to prove \Cref{lemma:H_secure} (and thus to complete the proof of
\Cref{lemma:many2few}), it suffices to prove the following lemma.
\begin{lemma}\label{lemma:reformulated}
  The adversary  makes at most  adaptively-chosen corruptions, and .
\end{lemma}
\begin{proof}
We first note that  always makes at most~ corruptions. This follows from the fact that~ is always consistent with some adversary , for some  (or else  aborts), and by our assumption, every  makes at most~ corruptions.

We next prove that
.
Recall that we denote by  the random variable that corresponds to the
  transcript generated by running the protocol  with the adversary~
  (described in Figure~\ref{fig:adv_long2short}).

  Let  be an ``ideal'' transcript, generated as follows: Choose
  a random , run the protocol  with the adversary
  .  Denote the resulting transcript by .  As above,
   consists of  vectors (one per each round), where each vector
consists of  pairs of the form

where  and .  We define
  
 where  is the transcript obtained by applying  to each element in the  row of . Formally,   is defined recursively, as follows: For every  and every , we let  denote the transcript  up until after the  message in the  round is sent.
 We define  recursively, as follows:  For , we define
 


 In order to prove Lemma~\ref{lemma:reformulated} it suffices to prove the
 following claim.

 \begin{claim}\label{claim:SD}
   
 \end{claim}




\begin{proof}We prove Claim~\ref{claim:SD} using a hybrid argument. Specifically, we define
  a sequence of  experiments.  For every  and every
  , we define the experiment  as follows:
  \begin{enumerate}
  \item Generate  and , as defined in
    Figure~\ref{fig:adv_long2short}.
  \item\label{it:12} Choose a random , and let
    .
  \item\label{it:13} Run the protocol  with the adversary , given
    the partial transcript .  Namely, run  with  from after the  message in the  round was sent, and assume the transcript up until that point is .  Denote the entire transcript
    (including ) by .
  \item\label{it:14} Output .
  \end{enumerate}
  Notice that
  
  and
  

  It remains to argue that for every  and every  the
  statistical distance between any two consecutive experiments 
  and  is small. In particular, it suffices to prove that
  
The reason is that
given this inequality, we obtain that
  
   which completes the claim.  We note that the first inequality follows from the union bound together with the fact that  for every  (see Figure~\ref{fig:adv_long2short} Item~\ref{it6}).\\

  We proceed with the proof of \Cref{eq:hybrid}. To this end, fix any 
  and .  Let .  Note that in both
   and  the first  messages are generated according
  to .

  Denote by  the event that the  message is sent by a
  corrupted party.  We first argue that
  
  This follows immediately from the definition of the two experiments.  In  (according to Figure~\ref{fig:adv_long2short}, Items~\ref{it:2}-\ref{it:4}), before sending the  message, a random function is chosen  and the  message is sent by a corrupted party if and only if  chooses the  message to be sent by a corrupted party (given the transcript so far).
  Note that in , the same exact process occurs (see
  \Cref{it:12,it:13,it:14} at the beginning of the proof of
  Claim~\ref{claim:SD}).

  We next argue
  , 
  To see why \Cref{eqn:Exp-corr} holds, note that according to
  Figure~\ref{fig:adv_long2short} (see \Cref{it:2,it:3,it:4}), the
   message in  is chosen by
  sampling a random matrix  conditioned on the fact
  that the  message sent in  with  is sent
  by a corrupted party. Denote this corrupted party by  and denote by
   the message that  sends on behalf of .  Then
  the  message in  is set to be .
  Note that the  message in  is chosen in exactly the same way (see
  \Cref{it:12,it:13,it:14} at the beginning of the proof of
  Claim~\ref{claim:SD}).  Moreover, the distribution of the set  in both cases is identical, which implies that the distributions of the rest of the messages in  and in  are identical as well.

  It remains to prove that
  

Recall that in  the  message is uniformly distributed in . Denote by  the  message in .  Recall that  is distributed as follows:  Choose a random  such that the adversary  (given the partial transcript ) orders an honest party  to send the  message in the  round.  Choose a random , and and set
.

Notice that in order to prove Equation~\eqref{eqn:hybrid-corr}, it suffices to prove that


Recall that we fixed .
We argue that in order to prove Equation~\eqref{SD:R'} it suffices to prove
that,
  
  where the probability is over the randomness of the honest parties.

To this end, suppose that
Inequality~\eqref{eqn:sizeH} holds.
Denote by  the event that

By Inequality~\eqref{eqn:sizeH},

Therefore,

This, together with the definition of  (see Equation~\eqref{eqn:mu*}), implies that in order to prove Equation~\eqref{SD:R'} it suffices to prove that

This, together with Claim~\ref{claim:ent2sd}, implies that it suffices to prove
that

To this end, let .  Then,

where the first inequality follows from Equation~\eqref{eqn:event} together with the definition of entropy (see Definition~\ref{def:entropy}), and the latter equality follows from basic arithmetics.

For every  and every , we denote by  the random variable obtained by choosing a random matrix  , and setting  to be the  row of~.
Note that

where the first inequality follows from the basic property of Shannon entropy,  that for any random variables  and , it holds that , and the second equality follows from the fact that  of the rows in  are fixed.
This, together with the equations above, implies that


Recall that  is the random variable defined by choosing  (where we assume that event  holds for ), choosing a random , and setting .
Thus,

proving \Cref{eqn:entR}, where the latter inequality follows from the definition of~ (see Equation~\eqref{eqn:N}).\\


It remains to prove Inequality~\eqref{eqn:sizeH}.  We prove that Inequality~\eqref{eqn:sizeH} holds for any .  The proof is  by induction on .
The base case is , which corresponds to .
In this case, it is always holds that

where the latter inequality follows from the definition of~ (see \Cref{eqn:H1}).

Next, assume that Inequality~\eqref{eqn:sizeH} holds for , and we prove that it holds for~.
Fix  and  such that .
By the induction hypothesis,
 
We denote by  the event that indeed
  
  Thus, by our induction hypothesis,
  

In what follows, fix {\em any}  such that event  holds.
Claim~\ref{claim:prob} (with   and ) implies
that

This, in turn, implies that

as desired.
\end{proof}
\end{proof}

\subsection{Static Adversaries}\label{sec:static}
We note that Theorem~\ref{thm:main} holds also for static adversary. For completeness, we restate the theorem for static adversaries.

\begin{theorem}
 Fix any , , , and any -party -round public-coin
  protocol  that outputs messages in  and in which all parties send
  messages of length .  Then, for any constant , any , and any , if  is -statically secure then there exists an -party -round
  -statically secure public-coin protocol that simulates~, where all parties send messages of length , and where  (where  is the negligible function defined in Equation~\eqref{eqn:mu*}).
\end{theorem}

The proof is almost identical to the proof of Theorem~\ref{thm:main} except that in the static setting, the adversary  needs to decide which~ parties to corrupt before the protocol begins.

Recall that in the proof of Theorem~\ref{thm:main}, the adversary~ simulates one of the adversaries .  In the static setting, the adversary  will choose to corrupt the  parties that are consistent with as many  as possible.
More specifically, recall that in the proof of Theorem~\ref{thm:main} we defined  to be the set of all matrices  such that  tries to bias the outcome towards a specific set~. Recall that .

In the static setting, for every  we denote by  the set of parties that the adversary   corrupts. For every set  of size~ let 
We define

and the adversary  corrupts the set of parties .
We define   to consist of all the matrices  for which  corrupts the set of parties~.
Note that


The rest of the proof is similar to that of Theorem~\ref{thm:main}, except that
the analysis is easier in the static setting, since the decision of who to
corrupt has already been made.

 \section{Public-Coin Protocols}\label{sec:public_coin}
 In this section we show how to convert any selection protocol into a
 public-coin protocol.

\begin{theorem}
  Every selection protocol  can be transformed into a protocol  which
  simulates  and such that the messages sent in  are uniformly
  random.  Moreover, the protocol  preserves the security of  and its
  round complexity.
\end{theorem}

\begin{proofsketch}
  Let  be an -party selection protocol. Let  be the number of
  communication rounds and let us assume for simplicity that each party speaks
  at each round. Assume, without loss of generality, that each party samples its
  own randomness ahead of time, when the protocol begins. That is, for every
  , party  has randomness , where we let
   be the maximum number of random bits used by all parties during the
  protocol. At each round~, party  evaluates a function 
  which depends on the transcript of the protocol so far, which we denote by
   (\ie  are the messages sent by all parties in
  rounds ), and on its own randomness . Namely, the message
  sent at round  by party  is
  

  Before we define the protocol , we introduce some notation. We say that
  a random string  is \emph{good} \wrt transcript  and party
   if when it is used as the randomness of that party, it generates
  the same exact transcript.

  Next, we define the protocol . In round , party 
  sends a uniformly random string  of length . Specifically, each
  party sends a uniformly random permutation of all possible -bit
  strings. At the end, after the  round ends, we interpret each
   as a collection of many possible random strings for party ,
  choose one (say the first), denoted by , which is \emph{good} \wrt
  the transcript so far and think of the  message as
  .



  First, we observe that the round complexity of  is the same as that of
  . Next, we claim that in an honest execution (\ie in the absence of an
  adversary), the distribution of the output of the protocol  is identical
  to that of  (namely,  simulates ). We first note that
  conditioned on the fact that a \emph{good} randomness was found for all
   messages, the above distributions are the same. This is true since
  in  each party sends all possible  bit strings in a {\em uniformly
    random} order. Second, we note that, since each party sends \emph{all}
  possible -bit strings in each round, there \emph{always} exists
  \emph{good} randomness.

  Next, we argue that the protocol  is as secure as .
  This follows by a simple hybrid argument. We define a sequence of protocols
   for  in which until (and including) the
   message, the parties act according to  and in the rest of the
  protocol they act according to . Notice that  and
  . We argue that for every , the ``advantage''
  of any  in  over any  in  is
  zero.


  To this end, observe that the first  messages are distributed exactly the
  same.
  In the next message (\ie the  one) the protocols deviate. Assume
  party  speaks in both. While in  the message sent is
  some function of the transcript so far and the initial randomness 
  has, in  it is a random permutation of all possible random
  strings. We first note that if party  is corrupted, then both the
  adversary  and  can force any message in the name of
   and thus they have the same power in both protocols (recall that
  after the  message, the protocols are identical). Hence, assume that
   is not corrupted. In this case, the adversary  sees a
  message which is a function of the transcript up to that point and the
  (private) randomness of that party, whereas  sees a message
  which is a random permutation of all possible random strings. The theorem now
  follows by observing that one adversary can simulate the view of the other,
  and recalling that the rest of the messages in both protocols are
  identically distributed.
\end{proofsketch}

\subsubsection*{Acknowledgments}
We thank Nancy Lynch, Merav Parter and David Peleg for helpful remarks and
pointers. The second author thanks his advisor Moni Naor for his continuous
support.


\addcontentsline{toc}{section}{References}
\bibliographystyle{alpha}
\bibliography{RandDist}

\end{document}
