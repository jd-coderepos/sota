\documentclass{article}





\usepackage{amsmath}
\usepackage{float}
\usepackage{graphics}
\usepackage{tikz}
\usepackage{pgfplots}
\usepackage{diagbox}
\usepackage{subcaption}
\usepackage{multirow}
\usepackage{wrapfig, lipsum}
\usepackage{enumitem}
\usepackage{xurl}
\usepackage{color}



\usepackage[final]{neurips}




\usepackage[utf8]{inputenc} \usepackage[T1]{fontenc}    \usepackage{hyperref}       \usepackage{url}            \usepackage{booktabs}       \usepackage{amsfonts}       \usepackage{nicefrac}       \usepackage{microtype}      \usepackage{xcolor}         


\title{ELASTIC: Numerical Reasoning with \\ Adaptive Symbolic Compiler}


\author{Jiaxin Zhang\\
  University of Strathclyde\\
  16 Richmond Street, Glasgow, G1 1XQ \\
  \texttt{jiaxin.zhang@strath.ac.uk} \\
\And
   Yashar Moshfeghi \\
   University of Strathclyde\\
   16 Richmond Street, Glasgow, G1 1XQ \\
   \texttt{yashar.moshfeghi@strath.ac.uk} \\
}

\begin{document}
\maketitle
\begin{abstract}
Numerical reasoning over text is a challenging task of Artificial Intelligence (AI), requiring reading comprehension and numerical reasoning abilities. Previous approaches use numerical reasoning programs to represent the reasoning process. However, most works do not separate the generation of operators and operands, which are key components of a numerical reasoning program, thus limiting their ability to generate such programs for complicated tasks. In this paper, we introduce the num\textbf{E}rica\textbf{L} re\textbf{AS}oning with adap\textbf{T}ive symbol\textbf{I}c \textbf{C}ompiler (ELASTIC) model, which is constituted of the RoBERTa as the Encoder and a Compiler with four modules: Reasoning Manager, Operator Generator, Operands Generator, and Memory Register. ELASTIC is robust when conducting complicated reasoning. Also, it is domain agnostic by supporting the expansion of diverse operators without caring about the number of operands it contains. Experiments show that ELASTIC achieves 68.96 and 65.21 of execution accuracy and program accuracy on the FinQA dataset and 83.00 program accuracy on the MathQA dataset, outperforming previous state-of-the-art models significantly.\footnote{ELASTIC code can be found at \url{https://github.com/NeuraSearch/NeurIPS-2022-Submission-3358}\label{footnote:code_url}}
\end{abstract}



\section{Introduction}

Recently, Pre-trained Language Models (PLMs) \cite{BERT,RoBERTa,XLNet,GPT-3,T5} show astonishing performance over reading comprehension tasks like SQuAD \cite{squad}. However, PLMs fall short of numerical reasoning over text  \cite{NeRd}, which requires conducting numerical reasoning based on understanding the text. Hence, numerical reasoning over text is more challenging than reading comprehension \cite{ref_24} and attracts the interest of the AI community. Previous approaches adopt the sequence-to-sequence architecture to generate the sequential format of numerical reasoning programs (see (b) in Table~\ref{tab:NumericalReasoning_Example}) \cite{Math23K, ref_22}. However, the sequential format could produce invalid expressions such as "" because of the wrong position of parentheses \cite{ref_11}. To avoid this, some methods convert the reasoning program to the binary tree, then use the tree-decoder to generate the pre/post-order traversal sequence (see (c) in Table~\ref{tab:NumericalReasoning_Example}) \cite{ref_23, ref_13, ref_28}. Alternatively, FinQANet \cite{finqa} represents the reasoning program in a flattened format and generates the right parentheses forcibly after generating two consecutive operands. To increase the scalability, NeRd \cite{NeRd} introduces the symbolic operations and generates the reasoning program as the nested compositional format (see (e) in Table~\ref{tab:NumericalReasoning_Example}). Researchers also investigate to capture valuable information between entities and numbers to improve numerical reasoning ability. Some works use PLMs \cite{ref_24, NeRd, MWP-BERT}, while others, like Li et al. \cite{Graph2Tree} and Ran et al. \cite{NumNet}, adopt graph neural network to encode the text.

Currently, proposed approaches struggle with two significant problems. Firstly, they are vulnerable to complicated numerical reasoning problems. The complicated numerical reasoning problems usually contain a long reasoning program, in which the types of operators are diverse, and the number of operands is dynamic. Since most works do not separate the generation of operators and operands, their performance is hindered by cascading errors when encountering complicated tasks. Secondly, previous works lack extensibility for the operators, which arises from either the flaw of the model architecture or the representation format of the program, making them hard to apply to different data domains.


\begin{table}[tbhp!]
\caption{An Example (from MathQA \cite{MathQA} dataset) requires solving the problem by conducting numerical reasoning. The numerical reasoning program could be represented by four different formats: sequential format, tree-traverse format, flatten format \cite{finqa}, or nested format.  refers to the executable result from the th sub-program, and  refers to the constant number 2.}
\label{tab:NumericalReasoning_Example}
\centering
\begin{tabular}{@{}p{13.5cm}}
\toprule
\textbf{Problem}: 
A small table has a length of 12 inches and a breadth of b inches. Cubes are placed on the surface of the table so as to cover the entire surface. The maximum side of such cubes is found to be 4 inches. Also, a few such tables are arranged to form a square. The minimum length of side possible for such a square is 80 inches. What is the number for b? 
\\ \midrule
\textbf{(a) Numerical Reasoning Program}:  \\ \midrule
\textbf{(b) Sequential Format}:\\  \\ \midrule
\textbf{(c) Pre-order Traverse Format}: \\ 
 \\ \midrule
\textbf{(d) Flattened Format}: \\ divide(80,4)|power(12,const\_2)|power(\#0,const\_2)|subtract(\#2,\#1)|sqrt(\#3) \\ \midrule
\textbf{(e) Nested Format}:\\ sqrt(subtract(power(divide(80, 4), const\_2), power(12, const\_2))) \\ \bottomrule
\end{tabular}
\end{table}



Hence, we present the num\textbf{E}rica\textbf{L} re\textbf{AS}oning with adap\textbf{T}ive symbol\textbf{I}c \textbf{C}ompiler (ELASTIC) model. ELASTIC separates the generation of operators and operands, allowing it to be less influenced by the cascading error from the complicated reasoning. Moreover, ELASTIC is adaptable to the number of operands following an operator, making it domain-agnostic to support diverse operators. Specifically, ELASTIC contains an Encoder part extracting the contextual representations of the passage and question and a Compiler part generating the numerical reasoning program. The Compiler consists of four modules: Reasoning Manager, Operator Generator, Operands Generator, and Memory Register. We conduct experiments on two challenging datasets: FinQA \cite{finqa}, and MathQA \cite{MathQA}. Since FinQA and MathQA are collected from different domains: annual financial reports and GRE/GMAT, ELASTIC demonstrates its adaptability by achieving state-of-the-art results on both datasets. Furthermore, our ablation studies investigate how the length of the numerical reasoning program influences the model's numerical reasoning ability, which shows that ELASTIC is less liable to being influenced by the cascading error. In addition, we introduce the maximum Memory Departing Distance (M-MDD), which measures how difficult for the mode to use the executable results from the previous sub-program. We use M-MDD to demonstrate the necessity of the Memory Register in ELASTIC. The contributions of our work are: (1) we present a numerical reasoning model ELASTIC with good adaptability and elasticity, which separates the generation of operators and operands. ELASTIC achieves state-of-the-art results on two challenging datasets: FinQA and MathQA; (2) we introduce the design of separate modules and Memory Register, making ELASTIC perform stably on complicated numerical reasoning problems; (3) the proposed ELASTIC is domain agnostic because it supports diverse operators.



\section{Related Work}

Making models to conduct numerical reasoning has attracted the AI community since the last century \cite{ref_1}. Previous research has investigated making the model do numerical reasoning over text by using statistical learning methods to find a similar equation pattern \cite{ref_4, ref_5, ref_6, ref_7}. Since deep learning has recently achieved great success in many tasks, Wang et al. \cite{ref_8} propose DNS, which is the first deep learning model for solving math word problems as far as we know. After their work, researchers try to find a better way to represent the numerical reasoning program. For example, Wang et al. \cite{ref_9}, and Wang et al. \cite{ref_10} use the expression tree to represent the reasoning program. Sun et al. \cite{ref_11} create tree-decoder GTS, which generates prefix traverse sequence of the tree. Chiang et al. \cite{ref_12}, and Qin et al. \cite{ref_13} extract the semantic information from the question and passage texts and want to connect them with the reasoning steps. In addition, Li et al. \cite{ref_14}, and Zhang et al. \cite{ref_15} introduce the graph encoder to capture the structural information or syntactic information to capture the relation between numbers and entities. Shen et al. \cite{ref_16} propose a unified model, which uses both sequential and graph as the encoder, then uses seq2seq and tree decoder to generate the reasoning program. 

Furthermore, several datasets are proposed to evaluate the model's numerical reasoning ability, such as Math23K \cite{ref_17} and HWMP \cite{ref_13}. There are also more challenging datasets, like ASdiv \cite{ref_18}, and MathQA \cite{MathQA}. At the same time, Dua et al. propose DROP \cite{ref_19}, which requires more than arithmetic operations to conduct numerical reasoning. State-of-the-art models like NeRd \cite{NeRd} and NumNet \cite{NumNet} are introduced to solve the DROP dataset. More recently, a dataset called FinQA \cite{finqa} has been proposed, which is constructed from the annual financial report.

Despite the considerable success achieved by these approaches, Patel et al. \cite{ref_21} argues that some state-of-the-art models, like GTS \cite{ref_11} and Graph2Tree \cite{ref_15}, only learn the statistical relation instead of numerical reasoning ability. Unlike previous works, our model ELASTIC separates the generation of operators and operands, allowing it to conduct complicated numerical reasoning. Moreover, ELASTIC is adaptable to the number of operands following an operator, making it domain agnostic.

\section{Approach}

Figure~\ref{fig:Model-Architecture} shows the architecture of our ELASTIC model. ELASTIC consists of an Encoder part encoding the question text and problem text into contextual vectors and a Compiler part producing the numerical reasoning programs. The Compiler part consists of four modules: Reasoning Manager, Operator Generator, Operands Generator, and Memory Register. The Reasoning Manager leverages other modules to produce the numerical reasoning program. Since a complete numerical reasoning program usually contains several sub-programs, the generation steps between operators and operands are interchangeable. To help the following sub-programs use executable results from the previous sub-programs, Memory Register stores the sub-programs executable results into corresponding pre-defined cache tokens embeddings.\footnote{See Appendix F for an example showing how different modules work.}

\begin{table}[tbhp!]
\caption{Task Definition Notation}
\label{tab:terminology}
\centering
\begin{tabular}{@{}lp{8cm}}
\toprule
\textbf{Notation}  & \textbf{Description}                        \\ \midrule
, ,       & Problem Text, Question Text, Numerical Reasoning Program        \\ \midrule
       & The numbers in  and              \\ \midrule
      & Constants defined in DSL           \\ \midrule
        & All mathematical operators \\
 & The th operator in              \\ \midrule
        & All operands               \\
        & All operands belonging to              \\
 & The th operands of                                                                                               \\ \midrule
          &  From either  or ,   constitute             \\ \midrule
                         & \begin{tabular}[c]{@{}l@{}} The i-th sub-program of \\  = \end{tabular} \\ \bottomrule
\end{tabular}
\end{table}


\paragraph{Task Definition}
Given the problem text  and question text , the task is to generate a numerical reasoning program . Both problem text  and question text  consist of words and numbers (denoted by . The Numerical reasoning program  represents the numerical reasoning process, which is a sequence of symbols (denoted by  from mathematical operators (denoted by  and operands (denoted by .Operands  are from either constant numbers (denoted by  defined in Domain Specific Language (DSL) or .  are the special numbers that do not exist in either the problem text  and question text , such as const\_pi(. Finally, the pattern of the numerical reasoning program  is defined as , where , it is the   operator in , and  contains several operands . In addition, we regard a group of one operator and its operands as the sub-program . For example,  is the  sub-program , which can be executed since it is a complete arithmetic program.\footnote{See Table~\ref{tab:terminology} for the definition of all the notations. Also, see Appendix E for an example.}

\subsection{Encoder Part}

As shown in Figure~\ref{fig:Model-Architecture} (Encoder), the Encoder takes the concatenated sequence of  and  as input. The Encoder encodes the input sequence and outputs the contextual vectors . Next,  is used for the Compiler to produce the numerical reasoning program . In this work, we use RoBERTa as the Encoder. The outputs from the final layer of RoBERTa is used as , where  is the maximum input length of the RoBERTa, and  is the hidden size of RoBERTa. Note that ELASTIC is not dependent on the specific type of encoder. Any model providing contextual vectors of the sequence can be used. 



\begin{figure}[tbph!] 
\centering
\includegraphics[width=1.0\textwidth]{model.png} 
\caption{The overall architecture of the ELASTIC model. The Encoder part takes the sequence of question text  and passage text  as input, then generates the contextual vectors . The Compiler part consists of four modules: \textbf{Reasoning Manager}, \textbf{Operator Generator}, \textbf{Operands Generator}, and \textbf{Memory Register}. The right part of the figure shows a complete process of the generation of sub-program . Firstly, Reasoning Manager sends the guidance vectors  to the Operator Generator, which guides the generation of operator . Secondly, Reasoning Manager suspends the Operator Generator, then the Operands Generator takes  and  from the Operator Generator to produce the first operand . When finish the generation of the sub-program , the Memory Register stores the results and updates the embedding vectors of cache token  by . Again, the Compiler repeats to generate next sub-program .} 
\label{fig:Model-Architecture}
\end{figure}

\subsection{Compiler Part}

\paragraph{Decoding Vocabulary and Token Embedding}

We first describe the decoding vocabulary. The decoding vocabulary consists of  and , where  can be further categorized into  and . The embedding  of symbol  of the decoding vocabulary is represented by the embedding , which is the embedding look-up function. Hence, the embedding for symbol  is defined as:

\in\in\in

The symbols embeddings of  and  are two trainable embedding matrices  and  ( and  refers sizes of  and   respectively). The embedding for the symbol of  is , where  denotes the index position in the sequence of  and .



\paragraph{Reasoning Manager}

As shown in Figure~\ref{fig:Model-Architecture} (Reasoning Manager), the Reasoning Manager outputs the vector , which guides the Operator Generator and the Operands Generator to produce  and . The inputs for the Reasoning Manager are contextual vectors  (  for generating operators) from the Encoder and embedding of the previously generated symbol . The Reasoning Manager first calculates the context vector  by the normalized vectors of  and the attention weights :












where  and , and both are trainable parameters. The  summarizes the encoded information from the Encoder according to the previous generated symbol . Next, the Reasoning Manager adopts the GRU \cite{GRU} network to generate the guidance output :



where "" represents concatenation.  is trainable parameter, and  is the activation function.  is the hidden state of GRU from the previous step, and  is .



\paragraph{Operator Generator}

As shown in Figure~\ref{fig:Model-Architecture} (Operator Generator). Firstly, the Operator Generator receives the guidance vector  from the Reasoning Manager by inputting: contextual vectors  of tokens from the question , and embedding  of the previously generated operator. Next, the Operator Generator calculates the probabilities of -th operator (denoted as - of the OP:



where  is trainable parameter. The Operator Generator selects the operator with the highest probability as the predicted . Next, unlike other models, the Reasoning Manager suspends the generation of operators and starts to generate operands  through the Operands Generator.

\paragraph{Operands Generator}

As shown in Figure~\ref{fig:Model-Architecture} (Operands Generator). The inputs from Operands Generator to the Reasoning Manager are different from Operator Generator's. Because  could be a number in  or , the contextual vectors  of all tokens are used. Furthermore, the Operands Generator initializes the embedding of the initial operand  as  (, leveraging information of  to produce . Next, the Reasoning Manager outputs  for -th step generation of operand . Finally, the probability of -th operand (denoted as - of the OE:



where  is trainable parameter. The Operands Generator selects the operand with the highest probability as the predicted . After one operand has been generated, the Operands Generator continues producing operands for the sub-program . The decoding process for the operands terminates when the token  is produced.

\paragraph{Memory Register}
\label{section: memory_register}

When generating sub-program , its operands could be the executable results from the previous sub-program . To make the Operands Generator be able to use the results from previous sub-programs. Inspired by Chen et al. \cite{finqa}, we introduce a cache token  to the  of DSL, which is used for storing the information of executable results. Unlike other constants,  does not point to a static value. It is different according to the different sub-program . As the results, ELASTIC needs to update the representation of  after the sub-program  is generated. Specifically, the Memory and Register module update the cache  by replacing its embedding with output , which is the guidance vector from Reasoning Manager to guide the generation of the last operands belonging to the sub-program .



\paragraph{Training Objective}
Given the data  with size of  containing , where  and  refer to the passage and question in the the  training data, likewise,  and  are the golden operators and operands. Our training goal is to minimize the sum of the negative log-likelihood over the entire data, so the training loss is 




\section{Experimental Set-up}



\paragraph{Datasets}
\label{section: datasets}
We conduct evaluation experiments on two datasets: FinQA \cite{finqa} and MathQA \cite{MathQA}.\footnote{We do not select other datasets because of: (1) too small in size (around 1000), e.g., MAWPS \cite{MAWPS} and ASDiv-a \cite{ref_18}, (2) language are not English. e.g. Math23K \cite{ref_22} and HMWP \cite{ref_13}, (3) lack intermediate annotated program, like DROP \cite{ref_19}.}

\begin{itemize}[leftmargin=*]
\item[] {\bf FinQA:} FinQA is a dataset created from the annual financial reports. It contains 8,281 data, split into train, eval, and test parts with 6,251, 883, and 1,147 examples. We adopt the evaluation metrics from the original FinQA paper: execution accuracy (Exe Acc) and program accuracy (Prog Acc). The program accuracy calculates the accuracy of the operators and operands between the predicted program and the golden program. The execution accuracy calculates the accuracy between the golden executable result and the result from the predicted program. Since the FinQA dataset only contains operators with two operands, we extend it by creating questions required to be solved by the operators with more than two operands. We use the extended FinQA dataset to evaluate our models' adaptability to the number of operands (See Appendix A).
    
\item[] {\bf MathQA:} MathQA is created from GRE/GMAT examinations, containing 37,200 math word problems. The dataset is split into , , and  of train, dev, and test data. Compared with the FinQA dataset, the examples of MathQA require more advanced reasoning ability, which challenges the model to conduct advanced numerical reasoning (see Appendix B). A significant difference with FinQA is that the number of operands following an operator is not explicit in the MathQA dataset. Each MathQA question contains one correct of several answer options, calculated by the reasoning program with the knowledge of the operation semantics. Since we do not have this kind of knowledge, we adopted the same way as NeRd \cite{NeRd}, by only using program accuracy to evaluate models' performances. Note that program accuracy is stricter than execution accuracy because the model could find the correct answer by spurious reasoning programs.
\end{itemize}






\paragraph{Baselines}
\label{section: baselines}
We compare our ELASTIC model with several state-of-the-art models. (1) \textbf{FinQANet} \cite{finqa}: It adopts the Encoder-Decoder architecture with a cache updating mechanism to generate the program.  Since FinQANet only supports generating operators with exact two operands, we manage to train and evaluate FinQANet on the MathQA dataset by discarding the operators containing more than two operands. (2) \textbf{NeRd} \cite{NeRd}: it uses the BERT and a pointer-generator-based model to generate the symbolic nested program. (3) \textbf{Graph2Tree} \cite{Graph2Tree}: It models the dependency information of the text sequence by the GraphSAGE \cite{GraphSAGE} like model, and generates the program in a tree-structured way. (4) \textbf{NumNet} \cite{NumNet}: NumNet models the numeracy information by a GNN network. We also train the \textbf{NumNet+}, which replaces the Encoder of the NumNet by RoBERTa-large.\footnote{\url{https://github.com/llamazing/numnet\_plus}} Note that program accuracy does not apply to NumNet, since NumNet does not generate compositional reasoning programs. (5) \textbf{Human Performance}: We also report the human performance of both experts and non-experts in the FinQA dataset. The results are taken from the original FinQA paper \cite{finqa}.

\paragraph{Implementation Details}
\label{section: implementation details}
The model is implemented by Pytorch \cite{PyTorch} and Transformer \cite{Transformers}, then trained on a server with an NVIDIA Tesla A100 GPU of 40G memory. Training epochs are set to 50 and 100 for FinQA and MathQA, respectively. The batch size for all datasets is set to 10. We use Adam as optimizer \cite{Adam} to update the parameters of the models. The initial learning rate is set to 1e-5 equally, and it would be halved in every 25 epochs and 50 epochs for FinQA and MathQA. During training, the dropout rate and the weight decay are set to 0.1 and 1e-5 to prevent over-fitting. The parameters of the RoBERTa are fine-tuned during training. For the GRU cell in the decoder, the hidden size is the same as the RoBERTa, and the GRU layers number is 4. During inference, we use greedy decoding to generate the reasoning program.

\section{Results}

\paragraph{Overall Results}
Table \ref{tab: Overall_Results} shows the performances of our ELASTIC model and baselines on FinQA and MathQA. Overall, ELASTIC (RoBERTa-large) achieves the highest scores on both datasets. In the FinQA dataset, we see a significant lead in our ELASTIC (RoBERTa-large) model compared to the best baseline FinQANet (RoBERTa-large), with 3.91 points higher execution accuracy and 1.69 points higher program accuracy. When we change the Encoder part of ELASTIC from RoBERTa-large to RoBERTa-base, it still achieves better results than FinQANet using the same size of RoBERTa. Since both ELASTIC and FinQANet use the RoBERTa as the encoder, the results demonstrate the improvements brought by separating the generation procedures for operators and operands. Both ELASTIC models outperform the NeRd with a large margin. It is worth mentioning that NeRd defines external rules for different operators in their model \cite{NeRd}, which is not the case with the ELASTIC. 
ELASTIC also outperforms the NumNet and NumNet+ by a considerable margin. This could be due to the internal structure of these models limiting their scalability in generating reasoning programs, thus struggling to produce reasoning steps in a systematic manner \cite{ref_25}.
Finally, Graph2Tree achieves only 0.37 accuracy on the FinQA test dataset, which is much lower compared to its 69.96 program accuracy on the MathQA dataset. We suspect that this is because of the data leak problem existing in FinQA train and eval data (see detailed explanation in Appendix D). Although ELASTIC surpasses the non-expert performance, we can still find a large gap between our ELASTIC model and Human Expert.


\begin{table}[tbhp!]
\caption{Overall Results for the baselines and ELASTIC on the testing data from three datasets. 
 means that the scores are taken from the original papers. 
 means that the scores are taken from the FinQA paper \cite{finqa}. 
 The program accuracy does not apply to the NumNet on FinQA and MathQA datasets because NumNet does not generate the intermediate reasoning program. In addition, NumNet could only solve reasoning program involving add and subtract operations. However, the proportions of examples only use add and subtract as operations in MahtQA are  and , respectively. As a result, we choose not to train NumNet on MathQA.\\}
\label{tab: Overall_Results}
\centering
\begin{tabular}{@{}lccc@{}}
\toprule
\multicolumn{1}{c}{\multirow{2}{*}{Datasets \& Metrics}} & \multicolumn{2}{c}{FinQA (test)} & MathQA (test) \\ \cmidrule(l){2-4} 
\multicolumn{1}{c}{}     & Exe Acc & Prog Acc & Prog Acc \\ \midrule
Graph2Tree               & 0.37    & 0.0      & 69.96\dag    \\ \midrule
NumNet                   & 2.32    & n/a      & n/a      \\
NumNet+                  & 10.29   & n/a      & n/a      \\
NeRd                     & 52.48   & 49.90    & 79.70    \\ \midrule
FinQANet (RoBERTa-base)  & 60.10\dag   & 58.38\dag    & 74.12    \\
FinQANet (RoBERTa-large) & 65.05\dag   & 63.52\dag    & 79.20    \\ \midrule
ELASTIC (RoBERTa-base)   & 62.66   & 59.28    & 82.27    \\
ELASTIC (RoBERTa-large)  & \textbf{68.96}   & \textbf{65.21}    & \textbf{83.00}    \\ \midrule
Human Expert             & 91.16\dag   & 87.49\dag    & n/a      \\
Human Non-Expert         & 50.68\dag   & 48.17\dag    & n/a      \\ \bottomrule
\end{tabular}
\end{table}

For the MathQA dataset, ELASTIC (RoBERTa-large) is the best performing model, with 3.3 higher program accuracy than NeRd and 13.04 points higher than Graph2Tree. We further investigate the performance of ELASTIC using RoBERTa-base, which still achieves higher accuracy of 82.27 than 79.7 of NeRd. The slight performance difference between ELASTIC (RoBERTa-large) and ELASTIC (RoBERTa-base) suggests that the extracted contextual semantic information of passage and question is sufficient. Finally, FinQANet achieves promising results on MathQA, 79.20\% program accuracy by FinQANet (RoBERTa-large) and 74.12\% program accuracy by FinQANet (RoBERTa-base). Note that we discarded the data of MathQA containing more than two operands for the FinQANet, so that performance of FinQANet on MathQA is the overestimation of its numerical reasoning ability. Even with such consideration, ELASTIC outperforms FinQANet significantly, demonstrating that ELASTIC is more adaptable by supporting diverse operators than FinQANet.



\paragraph{Performance Breakdown}
To demonstrate the strength of ELASTIC, we investigate the importance of the Memory Register. Also, we show ELASTIC performance when generating different lengths of program steps.

\paragraph{Necessity of Memory Register}
\label{section: necessity of memory and updating mechanism}

As discussed in the Section~\nameref{section: memory_register}, ELASTIC stores the executable results of each sub-program into a special cache token , and updates its embedding after -th sub-program is generated. The longer the reasoning program is, the higher the probability of the generating process using the previous sub-program result. This section investigates the effect of the Memory Register on improving numerical reasoning performance.

\begin{table}[tbph!]
\caption{The performances of ELASTIC with or without memory register (MR). ELASTIC with MR performs better than without MR on FinQA and MathQA datasets. Both ELASTIC with or without MR performs better than FinQANet. All models use the RoBERTa-large as the encoder.\\}
\label{tab:Cache_Comp}
\centering
\begin{tabular}{@{}cccc@{}}
\toprule
\multicolumn{1}{c}{\multirow{2}{*}{Datasets \& Metrics}} & \multicolumn{2}{c}{FinQA (test)} & MathQA (test) \\ \cmidrule(l){2-4} 
\multicolumn{1}{c}{} & Exe Acc        & Prog Acc       & Prog Acc       \\ \midrule
ELASTIC \textit{w} MR         & \textbf{68.96} & \textbf{65.21} & \textbf{83.00} \\ \midrule
ELASTIC \textit{w/o} MR       & 68.79          & 64.78          & 82.68          \\ \midrule
FinQANet             & 65.06          & 63.52          & 79.20          \\ \bottomrule
\end{tabular}
\end{table}

First, we present an ablation study of using and not using the Memory Register for ELASTIC. From Table \ref{tab:Cache_Comp}, we find that ELASTIC with Memory Register performs slightly better than it without. Similar observations can be found for the MathQA dataset. This observation demonstrates the value of the Memory Register. Next, since ELASTIC and FinQANet store the executable results from the previous sub-program in a different way, we conduct a comparison between the two models. The results from Table \ref{tab:Cache_Comp} show that the ELASTIC with Memory Register achieves significantly higher scores than FinQANet on both datasets.

\begin{figure}[tbph!] 


\begin{subfigure}[c]{.33\textwidth}
\begin{tikzpicture}[scale=0.55]
\begin{axis}[
    xtick={1,...,10},
    xlabel=Maximum MDD, 
    ylabel=Accuracy,
    tick align=outside, 
    legend style={at={(0.25,1.0)},anchor=north west, font=\tiny}
    ]
    
\addplot[smooth,mark=triangle,blue] plot coordinates {
    (1, 55.70)
    (2, 25.00)
    (3, 53.85)
};
\addlegendentry{ELASTIC (\textit{w} MR) on FinQA}

\addplot[smooth,mark=triangle,cyan] plot coordinates {
    (1, 54.17)
    (2, 20.00)
    (3, 53.85)
};
\addlegendentry{ELASTIC (\textit{w/o} MR) on FinQA}

\addplot[smooth,mark=triangle,orange] plot coordinates {
    (1, 55.70)
    (2, 15.00)
    (3, 53.85)
};
\addlegendentry{FinQANet on FinQA}

\end{axis}
\end{tikzpicture}
\caption{}
\label{fig:Cache-MCDP-FinQA}
\end{subfigure}\begin{subfigure}[c]{.35\textwidth}

\begin{tikzpicture}[scale=0.55]
\begin{axis}[
    xtick={1,...,10},
    xlabel=Maximum MDD, 
tick align=outside, 
legend style={at={(0.552,0)},anchor=south east, font=\tiny}
    ]
\addplot[smooth,mark=*,blue] plot coordinates { 
    (1, 85.40)
    (2, 84.20)
    (3, 82.34)
    (4, 83.13)
    (5, 84.11)
    (6, 83.10)
    (7, 61.54)
    (8, 85.71)
    (9, 36.36)
    (10, 85.71)
};
\addlegendentry{ELASTIC (\textit{w} MR) on MathQA}
\addplot[smooth,mark=*,cyan] plot coordinates {
    (1, 84.94)
    (2, 84.91)
    (3, 81.87)
    (4, 82.74)
    (5, 81.31)
    (6, 71.83)
    (7, 53.85)
    (8, 71.43)
    (9, 27.28)
    (10, 85.71)
};
\addlegendentry{ELASTIC (\textit{w/o} MR) on MathQA}
\addplot[smooth,mark=*, orange] plot coordinates {
    (1, 83.08)
    (2, 81.32)
    (3, 80.05)
    (4, 79.76)
    (5, 75.70)
    (6, 67.10)
    (7, 53.57)
    (8, 85.71)
    (9, 25.00)
    (10, 85.71)
};
\addlegendentry{FinQANet on MathQA}
\end{axis}
\end{tikzpicture}
\caption{}
\label{fig:Cache-MCDP-MathQA}
\end{subfigure}\begin{subfigure}[c]{.35\textwidth}
\begin{tikzpicture}[scale=0.55]
\begin{axis}[
    xtick={1,...,10,11,12},
    ymin=50,
    ymax=100,
    xlabel=Program Steps, 
tick align=outside, 
legend style={at={(0.733,0)},anchor=south east, font=\tiny}
    ]
\addplot[smooth,mark=triangle,blue] plot coordinates { 
    (1, 86.89)
    (2, 85.75)
    (3, 85.78)
    (4, 85.68)
    (5, 84.23)
    (6, 81.89)
    (7, 83.04)
    (8, 83.46)
    (9, 75.00)
    (10, 68.42)
    (11, 72.41)
    (12, 85.19)
};
\addlegendentry{ELASTIC (RoBERTa-large) Program Accuracy}
\addplot[mark=triangle,red] plot coordinates { 
    (1, 87.89)
    (2, 85.00)
    (3, 82.02)
    (4, 84.06)
    (5, 81.65)
    (6, 80.82)
    (7, 77.78)
    (8, 70.07)
    (9, 67.18)
    (10, 65.78)
    (11, 72.41)
    (12, 61.9)
};
\addlegendentry{FinQANet (RoBERTa-large) Program Accuracy}
\addplot[mark=*,orange] plot coordinates { 
    (1, 90.57)
    (2, 88.78)
    (3, 88.23)
    (4, 89.38)
    (5, 87.20)
    (6, 84.53)
    (7, 85.96)
    (8, 85.83)
    (9, 79.69)
    (10, 78.95)
    (11, 82.76)
    (12, 85.19)
};
\addlegendentry{ELASTIC (RoBERTa-large) Operator Accuracy}
\end{axis}
\end{tikzpicture}
\caption{}
\label{fig:ProgramSteps_MathQA}
\end{subfigure}\caption{(a) Program Accuracy on FinQA according to the M-MDD. (b) Program Accuracy on MathQA according to the M-MDD. (c) Program Accuracy and Operator Accuracy of ELASTIC (RoBERTa-large) on different program steps in MathQA dataset, compared with Program Accuracy of FinQANet (RoBERTa-large).}
\label{fig:mmd-program_steps}
\end{figure}

Next, given two sub-program belonging to the same : ,  (. where the executable result of  is used as the operand for . Then, we introduce the Memory Departing Distance (MDD) for  and  as , and the maximum Memory Departing Distance (M-MDD) as the longest MDD between all  of .\footnote{For example, in flatten program "", the MDD for , , and  are 3, 1, and 1. Obviously, the maximum M-MDD is 3.} The bigger M-MDD is, the more challenging to select the correct previous sub-program result, since the model tends to forget the information passing from long steps before. As the result, we investigate how models perform when dealing with different M-MDD.

From Figure \ref{fig:Cache-MCDP-FinQA} and Figure \ref{fig:Cache-MCDP-MathQA}, the ELASTIC with Memory Register performs better than ELASTIC without it at each M-MDD on FinQA and MathQA datasets. Particularly in the MathQA dataset, when M-MDD is larger than 5, ELASTIC with Memory Register can achieve better results than the ELASTIC without it. This demonstrates the importance of the Memory Register when using executable results from long steps before. Worth mentioning that ELASTIC performs better than FinQANet on both datasets, even without the Memory Register.



\paragraph{Performance on Different Program Steps}

When producing the long numerical reasoning program, ELASTIC is less influenced by the cascading error. To demonstrate this superiority of ELASTIC, we investigate how different lengths of programs influence models' performances.


\begin{table}[tbhp!]
\caption{ELASTIC and FinQANet performances on FinQA dataset in terms of different program steps. The "\# Train \& Dev" is the number of training and development data.  All models use the RoBERTa-large as the encoder. 
 means the results of that model are taken from the original FinQA \cite{finqa} paper. 
 means that the FinQANet (RoBERTa-large) is re-trained by ourselves.\\}
\label{tab:ProgramSteps_FinQA}
\centering
\begin{small}
\begin{tabular}{@{}cccccccc@{}}
\toprule
\multirow{2}{*}{Program Steps} & \multicolumn{2}{c}{ELASTIC} & \multicolumn{2}{c}{FinQANet} & \multicolumn{2}{c}{FinQANet} & \multirow{2}{*}{\# Train \& Dev} \\ \cmidrule(lr){2-7}
  & Exe Acc & Prog Acc & Exe Acc & Prog Acc & Exe Acc & Prog Acc &      \\ \midrule
1 & 76.30   & 75.66    & 70.27   & 68.77    & 73.70   & 71.25    & 4240 \\ \midrule
2 & 66.01   & 66.01    & 63.69   & 61.79    & 62.34   & 59.65    & 2300 \\ \midrule
3 & 31.78   & 31.10    & 31.65   & 31.65    & 28.57   & 23.80    & 594  \\ \bottomrule 
\end{tabular}
\end{small}
\end{table}


Table \ref{tab:ProgramSteps_FinQA} displays the models' performances when generating programs with different steps. ELASTIC (RoBERTa-large) performs better than FinQANet (RoBERTa-large) when the program step is either 1 or 2, indicating ELASTIC also performs well on the shorter program steps. Surprisingly, with the program step increasing from 3, the accuracy for both ELASTIC and FinQANet tumbles by half compared with the performances on program steps equal 2. We suspect that the FinQA dataset lacks sufficient training examples for the data with more than 3 program steps. Table \ref{tab:ProgramSteps_FinQA} shows that the number of training data with more than 2 program steps is 594 compared to the numbers of data available for program steps equal to 1 (4240) or 2 (2300). For a fair comparison, we retrained the FinQANet (RoBERTa-large) on the FinQA dataset, but ELASTIC still outperforms it in execution accuracy and program accuracy.

From Figure \ref{fig:ProgramSteps_MathQA}, ELASTIC (RoBERTa-large) surpasses the FinQANet (RoBERTa-large) on MathQA dataset almost on every program step. Meanwhile, although MathQA is challenging, ELASTIC (RoBERTa-large) still achieves program accuracy over 80.0 when program steps are less than or equal to 8. The model's performance drops when the program steps are equal to 9 and 10, but starts to soar when the program steps are bigger than 10. This demonstrates that ELASTIC performs well when generating longer program steps. As shown in Figure \ref{fig:ProgramSteps_MathQA}, we plot the accuracy for the operator generation, which ignores the correctness of operands generation. We could find that the operation accuracy is always higher than the program accuracy regarding different program steps (except for program steps equal to 12). This finding demonstrates the advantage of separating the generation procedure for operators and operands. This finding also reveals that the wrong predictions are because ELASTIC selects the wrong operands. We suspect this is due to too much noise from the context. 

Finally, our ELASTIC (RoBERTa-large) model (with approximately 500 million trainable parameters) outperforms Austin et al.'s smallest model \cite{hugeplm} (with 8 billion trainable parameters) but only marginally underperforms their largest model (with 137 billion trainable parameters). The parameter size of these models are 1600 and 274000 times bigger than our model respectively, resulting the training resources required significantly considerable.  


\section{Conclusion and Future Work}
\label{section: conclusion and future work}

This paper presents the num\textbf{E}rica\textbf{L} re\textbf{AS}oning with adap\textbf{T}ive symbol\textbf{I}c \textbf{C}ompiler (ELASTIC) model aiming to solve the numerical reasoning over text problem. ELASTIC separates the generation of operators and operands, allowing the model to generate the long and complicated reasoning program. Also, ELASTIC is domain agnostic and supports diverse operators, increasing adaptability. In addition, we introduce the Memory Register and improve the performance of the model by using executable results from the preceding sub-programs. We evaluated the performance of the ELASTIC model on FinQA and MathQA datasets and conducted an extensive comparison with state-of-the-art models. The results show ELASTIC gained significant improvement over the state-of-the-art baselines. Furthermore, We investigated the model's performance in terms of different M-MDD, demonstrating the necessity of the Memory Register. Finally, we compared models' performances regarding different lengths of numerical reasoning programs, showing ELASTIC is adept at producing long numerical reasoning programs. In the future, we plan to improve the accuracy of matching numbers and entities of the text. In addition, ELASTIC requires annotated reasoning programs, which is labor intensive. It is worth investigating how to generate reasoning programs from the trained model.



\bibliographystyle{unsrt}
\bibliography{main.bib}

\newpage

\section*{Appendix A: Training ELASTIC (RoBERTa-large) on Extended FinQA Dataset}
\label{appendix:a}



One advantage of our ELASTIC model is that it is adaptable to the number of operands of an operator. We demonstrate this by evaluating ELASTIC on the MathQA dataset in the "Overall Results" section. However, another dataset we used for the evaluation, the FinQA dataset, only contains questions solved by operators with two operands. To test the advantage of our model on the FinQA dataset, we manually extend it by adding 30 and 20 questions for train and test data (named extended FinQA dataset), respectively (see Table~\ref{tab:FinQA_Extended} for one example of the extended questions). These questions are proposed based on the original passages in the FinQA dataset. In addition, they are about superlative questions, which require to be solved by using superlative operators (i.e.,  and . As a result, unlike questions from the original FinQA dataset, the numbers of operands used to solve these extended questions are not limited to two. Next, We trained ELASTIC (RoBERTa-large) on the train data from the combination of the extended FinQA dataset and the original FinQA dataset. Since the number of operands of an operator is not determined anymore, the Reasoning Manager of ELASTIC has to manage the Operands Generator to generate the correct number of operands in terms of the specific question. This increases the difficulty for the model to generate correct operands and makes the dataset more challenging. The results are shown in Table~\ref{tab:FinQA-Most}. For the performance on the combined test data (original FinQA + extended FinQA), ELASTIC (RoBERTa-large) achieves slightly lower scores (64.5 of Exec Acc and 63.8 of Prog Acc), compared to the results of ELASTIC (RoBERTa-large) achieved on original FinQA dataset (68.96 of Exec Acc and 65.21 of Prog Acc).\footnote{See full results in "Overall Results" section.} We also report the metric scores of ELASTIC (RoBERTa-large) achieved on test data from the extended FinQA dataset: 90.0 on both Exec Acc and Prog Acc. Note that the state-of-the-art model FinQANet cannot solve the extended FinQA dataset because it can only generate operators with two operands. These results show ELASTIC model solving questions that require the capability of generating operators with diverse numbers of operands. 

\begin{table}[tbhp!]
\centering
\caption{The performances of ELASTIC (RoBERTa-large) on the test data from the combination of the original FinQA dataset and extended FinQA dataset, and only on the test data from the extended FinQA dataset. Note that the model is trained on the train data from the combination of the original FinQA dataset and the extended FinQA dataset.}
\label{tab:FinQA-Most}
\begin{tabular}{@{}lcc@{}}
\toprule
Dataset (Test)             & Exec Acc & Prog Acc \\ \midrule
original FinQA + extended FinQA  & 64.5     & 63.8     \\ 
extended FinQA  & 90.0    & 90.0     \\ \bottomrule
\end{tabular}
\end{table}

\begin{table}[tbhp!]
\centering
\caption{An example from the extended FinQA dataset. The "Prediction" refers to the generated numerical reasoning program from ELASTIC (RoBERTa-large). \dag: The passage is from the FinQA dataset, which is reorganized for better readability.}
\label{tab:FinQA_Extended}
\begin{small}
\begin{tabular}{@{}ll@{}}
\toprule
Question &
  What is the biggest obligations of payments between 2007 and 2010? \\ \midrule
Passage\dag &
  \begin{tabular}[c]{@{}l@{}}Contractual obligations and commercial commitments the following table (in thousands ):\\ The operating lease obligations of payments due by fiscal year total is \1703;\\ The operating lease obligations of payments due by fiscal year 2008 is \1035; \\ The operating lease obligations of payments due by fiscal year 2010 is \1903;\\ The total obligations of payments due by fiscal year 2008 is \1235;\\ The total obligations of payments due by fiscal year 2010 is \$" embedding with the guidance vector.

\end{document}
