[{'LEADERBOARD': {'Task': 'Question Answering', 'Dataset': 'WikiHop', 'Metric': 'Test', 'Score': '82.3'}}, {'LEADERBOARD': {'Task': 'Question Answering', 'Dataset': 'Quora Question Pairs', 'Metric': 'Accuracy', 'Score': '88.6%'}}, {'LEADERBOARD': {'Task': 'Question Answering', 'Dataset': 'TriviaQA', 'Metric': 'F1', 'Score': '80.9'}}, {'LEADERBOARD': {'Task': 'Question Answering', 'Dataset': 'HotpotQA', 'Metric': 'ANS-F1', 'Score': '0.755'}}, {'LEADERBOARD': {'Task': 'Question Answering', 'Dataset': 'HotpotQA', 'Metric': 'SUP-F1', 'Score': '0.891'}}, {'LEADERBOARD': {'Task': 'Question Answering', 'Dataset': 'HotpotQA', 'Metric': 'JOINT-F1', 'Score': '0.736'}}, {'LEADERBOARD': {'Task': 'Natural Language Inference', 'Dataset': 'QNLI', 'Metric': 'Accuracy', 'Score': '92.2%'}}, {'LEADERBOARD': {'Task': 'Natural Language Inference', 'Dataset': 'RTE', 'Metric': 'Accuracy', 'Score': '75.0%'}}, {'LEADERBOARD': {'Task': 'Natural Language Inference', 'Dataset': 'MultiNLI', 'Metric': 'Matched', 'Score': '87.5'}}, {'LEADERBOARD': {'Task': 'Semantic Textual Similarity', 'Dataset': 'MRPC', 'Metric': 'F1', 'Score': '91.5%'}}, {'LEADERBOARD': {'Task': 'Semantic Textual Similarity', 'Dataset': 'STS Benchmark', 'Metric': 'Spearman Correlation', 'Score': '.878'}}, {'LEADERBOARD': {'Task': 'Sentiment Analysis', 'Dataset': 'SST-2 Binary classification', 'Metric': 'Accuracy', 'Score': '94.6'}}, {'LEADERBOARD': {'Task': 'Text Summarization', 'Dataset': 'Pubmed', 'Metric': 'ROUGE-1', 'Score': '46.32'}}, {'LEADERBOARD': {'Task': 'Text Summarization', 'Dataset': 'Pubmed', 'Metric': 'ROUGE-2', 'Score': '20.65'}}, {'LEADERBOARD': {'Task': 'Text Summarization', 'Dataset': 'Pubmed', 'Metric': 'ROUGE-L', 'Score': '42.33'}}, {'LEADERBOARD': {'Task': 'Text Summarization', 'Dataset': 'arXiv', 'Metric': 'ROUGE-1', 'Score': '46.63'}}, {'LEADERBOARD': {'Task': 'Text Summarization', 'Dataset': 'arXiv', 'Metric': 'ROUGE-2', 'Score': '19.02'}}, {'LEADERBOARD': {'Task': 'Text Summarization', 'Dataset': 'arXiv', 'Metric': 'ROUGE-L', 'Score': '41.77'}}, {'LEADERBOARD': {'Task': 'Document Summarization', 'Dataset': 'CNN / Daily Mail', 'Metric': 'ROUGE-1', 'Score': '43.84'}}, {'LEADERBOARD': {'Task': 'Document Summarization', 'Dataset': 'CNN / Daily Mail', 'Metric': 'ROUGE-2', 'Score': '21.11'}}, {'LEADERBOARD': {'Task': 'Document Summarization', 'Dataset': 'CNN / Daily Mail', 'Metric': 'ROUGE-L', 'Score': '40.74'}}, {'LEADERBOARD': {'Task': 'Text Classification', 'Dataset': 'Hyperpartisan News Detection', 'Metric': 'Accuracy', 'Score': '92.2'}}, {'LEADERBOARD': {'Task': 'Text Classification', 'Dataset': 'arXiv', 'Metric': 'Accuracy', 'Score': '92.31'}}, {'LEADERBOARD': {'Task': 'Text Classification', 'Dataset': 'Yelp-5', 'Metric': 'Accuracy', 'Score': '72.16%'}}, {'LEADERBOARD': {'Task': 'Text Classification', 'Dataset': 'Patents', 'Metric': 'Accuracy', 'Score': '69.3'}}, {'LEADERBOARD': {'Task': 'Text Classification', 'Dataset': 'IMDb', 'Metric': 'Accuracy (2 classes)', 'Score': '95.2'}}, {'LEADERBOARD': {'Task': 'Text Classification', 'Dataset': 'IMDb', 'Metric': 'Accuracy (10 classes)', 'Score': '-'}}, {'LEADERBOARD': {'Task': 'Linguistic Acceptability', 'Dataset': 'CoLA', 'Metric': 'Accuracy', 'Score': '58.5%'}}]
