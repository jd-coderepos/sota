\documentclass{LMCS}

\def\doi{8(4:2)2012}
\lmcsheading {\doi}
{1--27}
{}
{}
{Jan.~31, 2012}
{Oct.~\phantom05, 2012}
{}
 


\usepackage{enumerate}

\usepackage{amsmath,amssymb,amsthm} \usepackage{prooftree,diagrams}

\usepackage{hyperref}






\newcommand{\comptype}[1]{\underline{#1}}

\newcommand{\VconstA}{\alpha}
\newcommand{\VconstB}{\beta}
\newcommand{\VconstC}{\gamma}

\newcommand{\CconstA}{\comptype{\alpha}}
\newcommand{\CconstB}{\comptype{\beta}}
\newcommand{\CconstC}{\comptype{\gamma}}


\newcommand{\VA}{\mathsf{A}}
\newcommand{\VB}{\mathsf{B}}
\newcommand{\VC}{\mathsf{C}}

\newcommand{\CA}{\comptype{\mathsf{A}}}
\newcommand{\CB}{\comptype{\mathsf{B}}}
\newcommand{\CC}{\comptype{\mathsf{C}}}
\newcommand{\CD}{\comptype{\mathsf{D}}}


\newcommand{\CR}{\comptype{\mathsf{R}}}
\newcommand{\CI}{\comptype{\mathsf{I}}}



\newcommand{\Vone}{1}
\newcommand{\Vprod}{\times}
\newcommand{\Vfun}{\to}

\newcommand{\lpop}{\multimap}

\newcommand{\Cone}{\comptype{1}}
\newcommand{\Cprod}{\,\&\,}
\newcommand{\Cfun}{\Rightarrow}
\newcommand{\Cbang}[1]{{! #1}}  
\newcommand{\Ccopower}[2]{! #1 \, {\otimes} \, #2}
\newcommand{\Czero}{\comptype{0}}
\newcommand{\Cplus}{\oplus}



\newcommand{\In}[2]{#1 \colon  \! #2}
\newcommand{\rIn}[2]{#1 \colon  #2}

\newcommand{\Cj}[4]{#1 \mid  \! #2 \, \vdash \, \rIn{#3}{#4}}
\newcommand{\Vj}[3]{\Cj{#1}{{-}}{#2}{#3}}

\newcommand{\Ceq}[5]{#1 \mid  \! #2 \, \vdash \, #3 = #4 \colon #5}
\newcommand{\Veq}[4]{\Ceq{#1}{-}{#2}{#3}{#4}}

\newcommand{\LCequals}{=_{\lambda_c}}
\newcommand{\BEequals}{=_{\beta\eta}}

\newcommand{\LCeq}[4]{#1 \, \vdash \, #2 =_{\lambda_c} #3 \colon #4}
\newcommand{\BEeq}[4]{#1 \, \vdash \, #2 =_{\beta\eta} #3 \colon #4}

\newcommand{\Csim}[5]{#1 \mid  \! #2 \, \vdash \, #3 \sim #4 \colon #5}
\newcommand{\Vsim}[4]{\Csim{#1}{-}{#2}{#3}{#4}}





\newcommand{\Vstar}{{*}}
\newcommand{\Vpair}[2]{\langle #1 , #2 \rangle}
\newcommand{\Vfst}[1]{\mathrm{fst}(#1)}
\newcommand{\Vsnd}[1]{\mathrm{snd}(#1)}

\newcommand{\Vlam}[3]{\lambda \In{#1}{#2}.\: #3}
\newcommand{\Vappl}[2]{#1(#2)}

\newcommand{\compop}[1]{\underline{#1}}

\newcommand{\Cstar}{\compop{*}}
\newcommand{\Cpair}[2]{\compop{\langle} #1 , #2 \compop{\rangle}}
\newcommand{\Cfst}[1]{\compop{\mathrm{fst}}(#1)}
\newcommand{\Csnd}[1]{\compop{\mathrm{snd}}(#1)}

\newcommand{\Clam}[3]{\compop{\lambda} \In{#1}{#2}.\: #3}
\newcommand{\Cappl}[2]{#1\compop{(}#2\compop{)}}

\newcommand{\bang}[1]{{! #1}}  
\newcommand{\Itop}{\top}
\newcommand{\Ilet}[2]{\mathrm{let}\: {\Itop}\:\mathrm{be}\:{#1} \;\mathrm{in}\: #2}
\newcommand{\banglet}[3]{\mathrm{let}\: {\bang #1}\:\mathrm{be}\:{#2} \;\mathrm{in}\: #3}

\newcommand{\llambda}{\lambda^{\!\circ\!}}
\newcommand{\llam}[3]{\llambda \In{#1}{#2}.\: #3}
\newcommand{\lappl}[2]{#1[#2]}

\newcommand{\copowerterm}[2]{{\bang{#1}}\! \otimes \! #2}
\newcommand{\copowerlet}[4]{\mathrm{let}\: {\copowerterm{#1}{#2}}\:\mathrm{be}\:{#3} \;\mathrm{in}\: #4}

\newcommand{\Cimage}[1]{\compop{?}(#1)}
\newcommand{\Cimagetype}[2]{\compop{?}_{#1}(#2)}
\newcommand{\Cinl}[1]{\compop{\mathrm{inl}}(#1)}
\newcommand{\Cinr}[1]{\compop{\mathrm{inr}}(#1)}
\newcommand{\Ccase}[5]{\compop{\mathrm{case}} \, #1 \,\mathrm{of}\,( \Cinl{#2}. \, #3 ; \, \Cinr{#4}. \, #5)}



\newcommand{\Lone}{1}
\newcommand{\Lprod}{\times}
\newcommand{\Lfun}{\to}

\newcommand{\Lj}[3]{#1  \, \vdash  \rIn{#2}{#3}}

\newcommand{\Lstar}{*}
\newcommand{\Lpair}[2]{\langle #1 , #2 \rangle}
\newcommand{\Lfst}[1]{\mathrm{fst}(#1)}
\newcommand{\Lsnd}[1]{\mathrm{snd}(#1)}

\newcommand{\Llam}[3]{\lambda \In{#1}{#2}.\: #3}
\newcommand{\Lappl}[2]{#1  #2}



\newcommand{\cbv}[1]{#1^{\mathrm{v}}}
\newcommand{\cbn}[1]{#1^{\mathrm{n}}}

\newcommand{\cbvLincps}[1]{#1^{\mathrm{v_{\CR}}}}
\newcommand{\cbnLincps}[1]{#1^{\mathrm{n_{\CR}}}}

\newcommand{\CpsVT}[1]{#1^{\mathcal{V}_{\CR}}}
\newcommand{\CpsCT}[1]{#1^{\mathcal{C}_{\CR}}}

\newcommand{\CpsVTcbv}[1]{\CpsVT{(\cbv{#1})}}
\newcommand{\CpsCTcbn}[1]{\CpsCT{(\cbn{#1})}}
\newcommand{\CpsVTcbn}[1]{\CpsVT{(\cbn{#1})}}


\newcommand{\CpsVVT}[1]{#1^{\mathcal{V}_{\CR}\mathcal{V}_{\CR}}}
\newcommand{\CpsCCT}[1]{#1^{\mathcal{C}_{\CR}\mathcal{C}_{\CR}}}
\newcommand{\CpsVVVT}[1]{#1^{\mathcal{V}_{\CR}\mathcal{V}_{\CR}\mathcal{V}_{\CR}}}
\newcommand{\CpsCCCT}[1]{#1^{\mathcal{C}_{\CR}\mathcal{C}_{\CR}\mathcal{C}_{\CR}}}


\newcommand{\Viso}[1]{i_{#1}}
\newcommand{\Ciso}[1]{j_{#1}}



\newcommand{\gspace}{2ex} 




\begin{document}



\title[Linear-use CPS Translations in EEC]{Linear-use CPS Translations \\ in the Enriched Effect Calculus\rsuper*}

\author[J.~Egger]{Jeff Egger\rsuper a}  
\address{{\lsuper a}Department of Physics and Atmospheric Science,
Dalhousie University, Halifax, N.S., Canada}
\email{jeffegger@yahoo.ca}
\thanks{{\lsuper a}Research carried out while Egger was at 
LFCS, University of Edinburgh.
Research supported by EPSRC Research Grant ``Linear Observations and Computational Effects'',
and by the Danish Agency for Science, Technology and Innovation.}


\author[R.~E.~M{\o}gelberg]{Rasmus Ejlers M{\o}gelberg\rsuper b}
\address{{\lsuper b}IT University of Copenhagen, Copenhagen,  Denmark}
\email{mogel@itu.dk}

\author[A.~Simpson]{Alex Simpson\rsuper c}
\address{{\lsuper c}LFCS, School of Informatics, University of Edinburgh, Scotland, UK}
\email{Alex.Simpson@ed.ac.uk}

\keywords{Continuations, Linear logic, Computational effects}

\subjclass{D3.1, F3.3, F4.1}

\titlecomment{{\lsuper*}The results in this paper first appeared 
in the proceedings of FoSSaCS 2010, \cite{EMS:fossacs}.}

\maketitle




\begin{abstract}
\noindent
The \emph{enriched effect calculus} (EEC) is an extension of Moggi's
computational metalanguage with a selection of primitives
from linear logic. This paper explores the enriched effect calculus
as a target language for continuation-passing-style (CPS) translations
in which the typing of the translations enforces the linear usage
of continuations. We first observe that 
established call-by-value and call-by name linear-use
CPS translations of simply-typed lambda-calculus into intuitionistic linear logic (ILL) 
land in the fragment of ILL given by EEC.
These two translations are
uniformly generalised by a single generic
translation of the enriched effect calculus into itself.
As our main theorem, we prove that the generic
self-translation of EEC is involutive up to isomorphism.
As corollaries, we obtain full completeness results,
both for the generic translation, and for 
the original call-by-value and call-by-name translations.
\end{abstract}

\maketitle

\section{Introduction}


Under a continuation-passing-style (CPS) interpretation, 
a call-by-value program
from  to  is interpreted as a ``continuation transformer'',
that is, as a map ,  where  represents the 
possible ``results'' of a computation.
Such maps are in one-to-one correspondence with Kleisi maps
for the \emph{continuations monad} , introduced by 
Moggi in~\cite{Moggi:89,Moggi:91}. 
In~\cite{BORT:02}, Berdine \emph{et al.}\ observe that,
in many programming situations, continuation transformers satisfy an
additional property: 
their argument, the continuation , is used just once,
that is, it is used \emph{linearly}.
Thus a call-by-value program can be more informatively modelled as a
linear function , corresponding to a
Kleisli map for the \emph{linearly-used continuations monad} 
.  

One goal of the present paper is to address the question: 
what is the natural type-theoretic context for
modelling linearly-used continuations? 
With the presence of both intuitionistic () and linear ()
arrows, \emph{intuitionistic linear logic (ILL)}~\cite{Girard:87}
seems a natural answer.
Indeed, ILL has been used as the basis of a systematic study of 
linearly-used continuations by Hasegawa. 
In~\cite{Hasegawa:Flops:02}, he presents a
continuation passing style (CPS) translation of 
Moggi's call-by-value computational -calculus into
ILL, using the linearly-used continuations monad, and establishes
a full completeness result for this. 
A follow-up paper~\cite{Hasegawa:Flops:04} considers call-by-name.

In this paper we use a more general type theory, the \emph{enriched
  effect calculus (EEC)} introduced in~\cite{EMS,EMSb}, as a target
language for linear-use CPS translations.  On the one hand, EEC can be
seen as a fragment of ILL and, as such, its models strictly generalise
models of ILL.
On the other hand, it is a conservative extension of the standard
calculi for modelling computational effects (Moggi's
\emph{computational metalanguage}~\cite{Moggi:91}, 
and Levy's \emph{call-by-push-value (CBPV)}~\cite{Levy:book}) with a
selection of constructs from linear logic. 
In fact, any \emph{adjunction model} of CBPV~\cite{Levy:models}
(and hence any model of Moggi's computational metalanguage)
expands to a model of EEC~\cite{EMS,EMSc}. This provides an abundant supply of 
computationally interesting models of EEC
that are not models of ILL.

The paper 
begins with a brief presentation of the enriched effect
calculus, in Section~\ref{section:calculus}. 
The standard call-by-value and call-by-name translations of typed -calculus
into effect calculi (cf.~Moggi~\cite{Moggi:91},
Filinski~\cite{Filinski:phd}, Levy~\cite{Levy:book})
are then reviewed in Section~\ref{section:cbv:cbn},
using EEC as the target language.
This is followed, in Section~\ref{sec:lin:cps}, by giving corresponding
linear-use CPS translations within EEC.
The starting point is the observation that Hasegawa's
call-by-value~\cite{Hasegawa:Flops:02} 
and call-by-name~\cite{Hasegawa:Flops:04} 
linear-use CPS translations of simply-typed -calculus both
fall inside the fragment of ILL corresponding to EEC. 
One contribution of the paper is to show that, 
using EEC, we can recover these translations in a particularly
interesting way. 
This is achieved by identifying, in Section~\ref{section:canonical}, a single generic linear-use
CPS-translation of the entire enriched effect calculus into itself.
In Section~\ref{section:recovering}, it is shown how
Hasegawa's call-by-value and call-by-name translations are derived
from this by composing the generic translation with the standard  
call-by-value and call-by-name encodings of typed -calculus
into effect calculi, reviewed in Section~\ref{section:cbv:cbn}.

The generic linear-use CPS-translation of EEC into itself
is the principal contribution of the paper. It
possesses a remarkable property, unexpected in the context of
CPS translations: it is involutive up to isomorphism. 
That is, the translation of a translated term equals
the original term modulo type isomorphism. 
This property is stated as Theorem~\ref{theorem:involution}, 
which is the main theorem of the paper. 
As consequences, we obtain full-completeness results, both for
the generic self-translation itself (Theorem~\ref{thm:full:complete}),
and also for the
call-by-value and call-by-name linear-use CPS translations
into EEC, mirroring Hasegawa's results for 
the translations into ILL. 

In the conference presentation of these results~\cite{EMS:fossacs},
the main syntactic theorem was given a semantic proof using  
category-theoretic models of EEC. In contrast, 
in the present paper, we provide purely syntactic proofs of all results.
It is hoped that this decision  will enlarge the potential readership of
the paper. Nevertheless, in Section~\ref{section:perspectives}, we briefly
outline the semantic context within which the syntactic results can be understood.
Even at an informal level, the semantic picture  provides an illuminating perspective
on the definition and properties of the generic self-translation of EEC.
A full treatment of the semantic side, which requires
considerable technical machinery, will be presented in a 
companion paper~\cite{EMSc}, devoted entirely to the category-theoretic model
theory of EEC. 


A few words on the style of the paper. Since the presentation
is syntactic, there are many proofs by induction. Some of
these have numerous cases. (The proof of Theorem~\ref{theorem:involution}, for example,
has 41 cases.) In order to keep the paper concise and readable, in  such proofs, we 
present only a few illustrative cases, including the most interesting.
However, we take care to establish all the side results (for example, the
substitution property of Proposition~\ref{prop:trans:subs})  needed to make completing
the main proofs routine in principle (if lengthy in practice). 












\section{The enriched effect calculus}
\label{section:calculus}


The \emph{enriched effect calculus (EEC)}~\cite{EMS,EMSb} is an extension of Moggi's 
computational metalanguage~\cite{Moggi:91}
with constructors from linear type theory. 
Similar to Filinski's effect PCF~\cite{Filinski:phd}
and Levy's CBPV~\cite{Levy:book}, it has two notions of types: \emph{value types} and
\emph{computation types}.
We use  to range over a 
set of \emph{value type constants}, and
 to range over a 
disjoint set of \emph{computation type constants}.
We then use  to range over 
\emph{value types}, and 
 to range over \emph{computation types},
which are specified by the grammar below.


As in~\cite{EMS,EMSb}, our notation has been heavily influenced by linear logic.
Indeed, EEC can be roughly understood as a fragment of intuitionistic linear logic.
However, there are some discrepancies, both in content and in syntax.
An important difference is that, in EEC, computation types are the sole source of
linearity. Thus linear function space  is defined between computation types only. 
However, the type  itself is a value type not a computation type.
As discused in \emph{op.\ cit.}, this choice seems
essential for EEC to be compatible with arbitrary (possibly non-commutative) computational effects.
A consequence is that the linear
function space cannot be iterated 
(neither  nor  is allowed).


Concerning notation, 
we remark that the type  is obtained by the application
of a single primitive binary type constructor  to a value type  and 
computation type . The hybrid notation for this constructor is chosen to emphasise the connection
with linear logic. 
In the present paper, we distinguish notationally
between products of computation types  and , and products of value
types  and . Similarly, we distinguish notationally between
computation-type function types  
(note that the the domain is a value type) and value-type function types
. These choices, while adding redundancy to the streamlined syntax of~\cite{EMS,EMSb},
have the advantage of  simplifying certain properties of the syntactic 
translations we shall give in Section~\ref{sec:lin:cps}.
A further redundancy, introduced to simplify the presentation in Section~\ref{section:canonical},
is that we introduce a primitive computation type , which plays a role analogous
to the tensor-product unit in linear logic.\footnote{Our choice of notation for units differs from
that of linear logic. In linear logic, the tensor unit, which we call ,  is written ,
and the  unit of the linear product , which we call , is written .}
This is redundant because  can be defined as .
As in linear logic, in addition to the linear isomorphism 
, the type  enjoys the further
isomorphisms , and
 in EEC
(the latter isomorphism is not linear, since  is not a computation
type).
Finally, 
in EEC, the exponential type  plays the role of 
Moggi's monadic type  and Levy's type . The linear exponential
notation is motivated by the many formal analogies between the properties of 
in EEC and in ILL. For example, EEC has the type isomorphisms
 (although only
the first is a computation type).
As in~\cite{EMS,EMSb},
we choose to make  
Levy's  type constructor (see \cite{Levy:book}) invisible by including
computation types as value types. 





\begin{figure}  \vspace*{30pt}
\gspace]
\prooftree
\Vj{\Gamma}{t}{\VA}
  \quad
\Vj{\Gamma}{u}{\VB}
\justifies 
\Vj{\Gamma}{\Vpair{t}{u}}{\VA \Vprod \VB}
\endprooftree
\qquad
\prooftree
\Vj{\Gamma}{t}{\VA \Vprod \VB}
\justifies 
\Vj{\Gamma}{\Vfst{t}}{\VA}
\endprooftree
\qquad
\prooftree
\Vj{\Gamma}{t}{\VA \Vprod \VB}
\justifies 
\Vj{\Gamma}{\Vsnd{t}}{\VB}
\endprooftree
\\gspace]
\prooftree
\justifies
\Cj{\Gamma}{\In{z}{\CA}}{z}{\CA}
\endprooftree
\qquad
\prooftree
\justifies 
\Cj{\Gamma}{\Delta}{\Cstar}{\Cone}
\endprooftree
\\gspace]
\prooftree
\Cj{\Gamma,\,\In{x}{\VA}}{\Delta}{t}{\CB}
\justifies
\Cj{\Gamma}{\Delta}{\Clam{x}{\VA}{t}}{\VA \Cfun \CB}
\endprooftree
\qquad
\prooftree
\Cj{\Gamma}{\Delta}{s}{\VA \Cfun \CB} 
  \quad
\Vj{\Gamma}{t}{\VA} 
\justifies
\Cj{\Gamma}{\Delta}{\Cappl{s}{t}}{\CB}
\endprooftree
\\gspace]
\prooftree
\Vj{\Gamma}{t}{\VA}
\justifies 
\Vj{\Gamma}{\bang{t}}{\Cbang{\VA}}
\endprooftree
\qquad
\prooftree
\Cj{\Gamma}{\Delta}{t}{\Cbang{\VA}}
\quad
\Vj{\Gamma,\, \In{x}{\VA}}{u}{\CB}
\justifies
\Cj{\Gamma}{\Delta}{\banglet{x}{t}{u}}{\CB}
\endprooftree
\\gspace]
\prooftree
\Cj{\Gamma}{\Delta}{t}{\Czero}
\justifies
\Cj{\Gamma}{\Delta}{\Cimage{t}}{\CA}
\endprooftree
\qquad
\prooftree
\Cj{\Gamma}{\Delta}{t}{\CA}
\justifies
\Cj{\Gamma}{\Delta}{\Cinl{t}}{\CA \Cplus \CB}
\endprooftree
\qquad
\prooftree
\Cj{\Gamma}{\Delta}{t}{\CB}
\justifies
\Cj{\Gamma}{\Delta}{\Cinr{t}}{\CA \Cplus \CB}
\endprooftree
\\gspace]
\prooftree
\Cj{\Gamma}{\In{z}{\CA}}{t}{\CB}
\justifies
\Vj{\Gamma}{\llam{z}{\CA}{t}}{\CA \lpop \CB}
\endprooftree
\qquad
\prooftree
\Vj{\Gamma}{s}{\CA \lpop \CB} 
 \quad
\Cj{\Gamma}{\Delta}{t}{\CA} 
\justifies
\Cj{\Gamma}{\Delta}{\lappl{s}{t}}{\CB}
\endprooftree

& \Veq{\Gamma}{t}{\Vstar}{\Vone} & & \text{if } 
\\
& \Veq{\Gamma}{\Vfst{\Vpair{t}{u}}}{t}{\VA} 
  && \text{if  and } 
\\
& \Veq{\Gamma}{\Vsnd{\Vpair{t}{u}}}{u}{\VB} 
  && \text{if  and } 
\\
& \Veq{\Gamma}{\Vpair{\Vfst{t}}{\Vsnd{t}}}{t}{\VA \Vprod \VB} 
  && \text{if }
\\
& \Veq{\Gamma}{\Vappl{(\Vlam{x}{\VA}{t})}{u}}{t[u/x]}{\VB}
  && \text{if  and }
\\
& \Veq{\Gamma}{\Vlam{x}{\VA}{(\Vappl{t}{x})}}{t}{\VA \Vfun \VB} 
  && \text{if  and }
\\
& \Ceq{\Gamma}{\Delta}{t}{\Cstar}{\Cone} & & \text{if } 
\\
& \Ceq{\Gamma}{\Delta}{\Cfst{\Cpair{t}{u}}}{t}{\CA} 
  && \text{if  and } 
\\
& \Ceq{\Gamma}{\Delta}{\Csnd{\Cpair{t}{u}}}{u}{\CB} 
  && \text{if  and } 
\\
& \Ceq{\Gamma}{\Delta}{\Cpair{\Cfst{t}}{\Csnd{t}}}{t}{\CA \Cprod \CB} 
  && \text{if }
\\
& \Ceq{\Gamma}{\Delta}{\Cappl{(\Clam{x}{\VA}{t})}{u}}{t[u/x]}{\CB}
  && \text{if  and }
\\
& \Ceq{\Gamma}{\Delta}{\Clam{x}{\VA}{(\Cappl{t}{x})}}{t}{\VA \Cfun \CB} 
  && \text{if  and }
\\
& \Veq{\Gamma}{\Ilet{\Itop}{t}}{t}{\CA}
  && \text{if }
\\
& \Ceq{\Gamma}{\Delta}{\Ilet{t}{u[\Itop/x]}}{u[t / x]}{\CA}
  && \text{if  and }
\\
& \Veq{\Gamma}{\banglet{x}{\bang{t}}{u}}{u[t/x]}{\CB}
  && \text{if  and }
\\
& \Ceq{\Gamma}{\Delta}{\banglet{x}{t}{u[\bang{x}/y]}}{u[t / y]}{\CB}
  && \text{if  and }
\\
& \Ceq{\Gamma}{\Delta}{\copowerlet{x}{y}{\copowerterm{t}{s}}{u}}{u[t,\! s / x, \! y]}{\CC} 
 && \text{if , , and}
\\
&
 && \quad\text{}
\\
& \Ceq{\Gamma}{\Delta}{\copowerlet{x}{y}{t}{u[\copowerterm{x}{y} / z]}}{u[t / z]}{\CC} 
&& \text{if  and }
\\
& \Ceq{\Gamma}{\Delta}{\Cimage{t}}{u[t/x]}{\CA}
 && \text{if  and }
\\
& {\Gamma} \! \mid \! {\Delta} \vdash {\Ccase{\Cinl{t}}{x}{u}{y}{u'}}
 && \text{if  and }
\\
& \phantom{\Gamma\mid \Delta \vdash \quad} =  {u[t/x]} \, \colon \, {\CC}
 && \quad\text{and }
\\
& {\Gamma} \! \mid \! {\Delta}  \vdash {\Ccase{\Cinr{t}}{x}{u}{y}{u'}} 
 && \text{if  and }
\\
& \phantom{\Gamma\mid \Delta \vdash \quad} = {u'[t/y]} \, \colon \, {\CC}
&& \quad \text{and }
\\
& \Gamma  \! \mid  \! \Delta \! \vdash \! \Ccase{t}{x}{u[\Cinl{x} / z]}{y}{ u[\Cinr{y} / z]} \hspace*{-50pt}\\
& \phantom{\Gamma\mid \Delta \vdash \quad} = u[t / z] \, \colon \, \CC
 && \text{if  and }
\\
& \Ceq{\Gamma}{\Delta}{\lappl{(\llam{x}{\CA}{t})}{u}}{t[u/x]}{\CB} 
  && \text{if  and }
\\
& \Veq{\Gamma}{\llam{x}{\CA}{(\lappl{t}{x})}}{t}{\CA \lpop \CB}
 && \text{if  and }

\text{(i)} \; \; & \Vj{\Gamma}{t}{\VB} 
& 
\text{(ii)} \; \; & \Cj{\Gamma}{\In{z}{\CA}}{t}{\CB} \enspace ,

\prooftree
\justifies
\Lj{\Theta,\, \In{x}{\sigma}}{x}{\sigma}
\endprooftree
\qquad
\prooftree
\justifies 
\Vj{\Theta}{\Lstar}{\Lone}
\endprooftree
\\gspace]
\prooftree
\Lj{\Theta,\,\In{x}{\sigma}}{M}{\tau}
\justifies
\Lj{\Theta}{\Llam{x}{\sigma}{M}}{\sigma \Lfun \tau}
\endprooftree
\qquad
\prooftree
\Lj{\Theta}{M}{\sigma \Lfun \tau} 
  \quad
\Lj{\Theta}{N}{\sigma} 
\justifies
\Lj{\Theta}{\Lappl{M}{N}}{\tau}
\endprooftree

\sigma \: ::= \: \alpha \, \mid \, \Lone \, \mid \, \sigma \Lprod \tau \, \mid \, \sigma \Lfun \tau \enspace ,

\cbv{\alpha} & = \alpha & \cbn{\alpha} & = \comptype{\alpha} \\
\displaybreak[0]
\cbv{\Lone} & = \Vone & \cbn{\Lone} & = \Cone \\
\displaybreak[0]
\cbv{(\sigma \Lprod \tau)} & = \cbv{\sigma} \Vprod \cbv{\tau}
 &  \cbn{(\sigma \Lprod \tau)} & = \cbn{\sigma} \Cprod \cbn{\tau} \\
\displaybreak[0]
\cbv{(\sigma \Lfun \tau)} & = \cbv{\sigma} \Vfun {\Cbang{(\cbv{\tau})}}
 &  \cbn{(\sigma \Lfun \tau)} & = \cbn{\sigma} \Cfun \cbn{\tau} \enspace .
\Vj{\In{x_1}{\cbv{\sigma_1}}, \ldots, \In{x_n}{\cbv{\sigma_n}}}{\cbv{M}}{\Cbang{\cbv{\tau}}} \enspace .
\cbv{x} \: & = \: \bang{x} \\
\cbv{\Lstar} \: & = \: \bang{\Vstar} \\
\cbv{\Lpair{M}{N}} \: & = \: \banglet{x}{\cbv{M}}{\banglet{y}{\cbv{N}}{\bang{\Vpair{x}{y}}}} \\
\cbv{(\Lfst{M})} \: & = \: \banglet{z}{\cbv{M}}{\bang{\Vfst{z}}} \\
\cbv{(\Lsnd{M})} \: & = \: \banglet{z}{\cbv{M}}{\bang{\Vsnd{z}}} \\
\cbv{(\Llam{x}{\sigma}{M})} \: & = \: \bang{(\Vlam{x}{\cbv{\sigma}}{\cbv{M}})} \\
\cbv{(\Lappl{M}{N})} \: & = \: \banglet{f}{\cbv{M}}{\banglet{x}{\cbv{N}}{\Vappl{f}{x}}} \enspace .
\Vj{\In{x_1}{\cbn{\sigma_1}}, \ldots, \In{x_n}{\cbn{\sigma_n}}}{\cbn{M}}{\cbn{\tau}} \enspace ,
\label{Mone}
\Lj{\In{f}{\Lone \Lfun \Lone },\, \In{g}{\Lone \Lfun \Lone} & }{\Lappl{\Lappl{(\Llam{x}{\Lone}{\Llam{y}{\Lone}{\Lstar}})}{(\Lappl{f}{\Lstar})}}{(\Lappl{g}{\Lstar})}}{\Lone}
\\
\label{Mtwo}
\Lj{\In{f}{\Lone \Lfun \Lone },\, \In{g}{\Lone \Lfun \Lone} & }{\Lappl{\Lappl{(\Llam{x}{\Lone}{\Llam{y}{\Lone}{\Lstar}})}{(\Lappl{g}{\Lstar})}}{(\Lappl{f}{\Lstar})}}{\Lone} \enspace ,

\cbvLincps{\alpha} \: & = \: \alpha & 
\cbnLincps{\alpha} \: & = \: \comptype{\alpha} \\
\cbvLincps{\Lone} \: & = \: \Vone & 
\cbnLincps{\Lone} \: & = \: \Czero \\
\cbvLincps{(\sigma \Lprod \tau)} \: & = \: \cbvLincps{\sigma} \Vprod \cbvLincps{\tau} &  
\cbnLincps{(\sigma \Lprod \tau)} \: & = \: \cbnLincps{\sigma} \Cplus \cbnLincps{\tau} \\
\cbvLincps{(\sigma \Lfun \tau)} \: & = \: \cbvLincps{\sigma} \Vfun ((\cbvLincps{\tau} \Cfun \CR) \lpop  \CR)
 &  \cbnLincps{(\sigma \Lfun \tau)} \: & = \: \Ccopower{(\cbnLincps{\sigma}  \lpop \CR)}{\cbnLincps{\tau}} \enspace .

\cbvLincps{\Theta} \: = \: \In{x_1}{\cbvLincps{\sigma_1}}, \ldots, \In{x_n}{\cbvLincps{\sigma_n}} \enspace .
\Vj{\cbvLincps{\Theta}}{\cbvLincps{M}}{(\cbvLincps{\tau} \Cfun \CR) \lpop \CR} \enspace ,
\cbvLincps{x} \: & = \: \llam{k}{\cbvLincps{\sigma} \Cfun \CR}{\,\Cappl{k}{x}} \\
\cbvLincps{\Lstar} \: & = \: \llam{k}{\Vone \Cfun \CR}{\,\Cappl{k}{\Vstar}} \\
\cbvLincps{\Lpair{M}{N}} \: & = \: \llam{k}{(\cbvLincps{\sigma} \Lprod \cbvLincps{\tau}) \Cfun \CR}
     {\,\lappl{\cbvLincps{M}}{\Clam{x}{\cbvLincps{\sigma}}
         {\,\lappl{\cbvLincps{N}}{\Clam{y}{\cbvLincps{\tau}}{\,\Cappl{k}{\Vpair{x}{y}}}}}}} \\
\cbvLincps{(\Lfst{M})} \: & = \: \llam{k}{\cbvLincps{\sigma} \Cfun \CR}
     {\,\lappl{\cbvLincps{M}}{\Clam{z}{\cbvLincps{\sigma} \times \cbvLincps{\tau}}{\, \Cappl{k}{\Vfst{z}}}}} \\                  
\cbvLincps{(\Lsnd{M})} \: & = \:  \llam{k}{\cbvLincps{\tau} \Cfun \CR}
     {\,\lappl{\cbvLincps{M}}{\Clam{z}{\cbvLincps{\sigma} \times \cbvLincps{\tau}}{\, \Cappl{k}{\Vsnd{z}}}}} \\ 
\cbvLincps{(\Llam{x}{\sigma}{M})} \: & = \: \llam{k}{(\cbvLincps{\sigma} \Vfun (\cbvLincps{\tau} \Cfun \CR) \lpop \CR) \Cfun \CR}
     {\, \Cappl{k}{\Vlam{x}{\cbvLincps{\sigma}{\,\cbvLincps{M}}}}} \\
\cbvLincps{(\Lappl{M}{N})} \: & = \: \llam{k}{\cbvLincps{\tau} \Cfun \CR}
     {\,\lappl{\cbvLincps{M}}{\Clam{f}{\cbvLincps{\sigma} \Vfun (\cbvLincps{\tau} \Cfun \CR) \lpop \CR}
         {\,\lappl{\cbvLincps{N}}{\Clam{x}{\cbvLincps{\sigma}}{\,\lappl{\Vappl{f}{x}}{k}}}}}} 

\cbnLincps{\Theta} \lpop \CR \: = \: \In{x_1}{\cbnLincps{\sigma_1} \lpop \CR}, \ldots, \In{x_n}{\cbnLincps{\sigma_n} \lpop \CR} \enspace .
\Vj{\cbnLincps{\Theta} \lpop \CR}{\cbnLincps{M}}{\cbnLincps{\tau} \lpop \CR} \enspace .

\cbnLincps{x} \: & = \: x \\
\cbnLincps{\Lstar} \: & = \: \llam{k}{\Czero}{\Cimage{k}} \\
\cbnLincps{\Lpair{M}{N}} \: & = \: \llam{k}{\cbvLincps{\sigma} \Cplus \cbvLincps{\tau}}
     {\,\Ccase{k}{x}{\,\lappl{\cbnLincps{M}\,}{x}}{\,y}{\,\lappl{\cbnLincps{N}\,}{y}}} \\
\cbnLincps{(\Lfst{M})} \: & = \: \llam{k}{\cbnLincps{\sigma}}
     {\,\lappl{\cbnLincps{M}\,}{\Cinl{k}}} \\
\cbnLincps{(\Lsnd{M})} \: & = \: \llam{k}{\cbnLincps{\tau}}
     {\,\lappl{\cbnLincps{M}\,}{\Cinr{k}}} \\
\cbnLincps{(\Llam{x}{\sigma}{M})} \: & = \: \llam{k}{\Ccopower{(\cbnLincps{\sigma} \lpop \CR)}{\cbnLincps{\tau}}}
     {\, \copowerlet{x}{h}{k}{\, \lappl{\cbnLincps{M}\,}{h}}} \\
\cbnLincps{(\Lappl{M}{N})} \: & = \: \llam{k}{\cbnLincps{\tau}}
     {\,\lappl{\cbnLincps{M}\,}{\copowerterm{(\cbnLincps{N})\, }{\, k}}}

\Lj{\In{f}{\cbvLincps{(\Lone \Lfun \Lone)}},\, \In{g}{\cbvLincps{(\Lone \Lfun \Lone)}} & }
{\cbvLincps{(\Lappl{\Lappl{(\Llam{x}{\Lone}{\Llam{y}{\Lone}{\Lstar}})}{(\Lappl{f}{\Lstar})}}{(\Lappl{g}{\Lstar})})}}
{\Cbang{(\cbvLincps{\Lone})}}
\\
\Lj{\In{f}{\cbvLincps{(\Lone \Lfun \Lone)}},\, \In{g}{\cbvLincps{(\Lone \Lfun \Lone)}} & }
{\cbvLincps{(\Lappl{\Lappl{(\Llam{x}{\Lone}{\Llam{y}{\Lone}{\Lstar}})}{(\Lappl{g}{\Lstar})}}{(\Lappl{f}{\Lstar})})}}
{\Cbang{(\cbvLincps{\Lone})}} \enspace .

\Vj{\In{f}{\CI},\, \In{g}{\CI} & }{\Ilet{f}{\Ilet{g}{\Itop}}}{\CI}
\\
\Vj{\In{f}{\CI},\, \In{g}{\CI} & }{\Ilet{g}{\Ilet{f}{\Itop}}}{\CI} \enspace .

\CpsVT{\VconstA} & \: = \: \VconstA  &
\CpsCT{\CconstA} & \: = \: \begin{cases} \CconstA & \text{if } \\
                                          \CI & \text{if } \end{cases}
\\
\CpsVT{\Vone} & \: = \: \Vone &
\CpsCT{\Cone} & \: = \: \Czero \\
\CpsVT{(\VA \Vprod \VB)} & \: = \: \CpsVT{\VA} \Vprod \CpsVT{\VB} &
\CpsCT{(\CA \Cprod \CB)} & \: = \:  \CpsCT{\CA} \Cplus \CpsCT{\CB} \\
\CpsVT{(\VA \Vfun \VB)} & \: = \: \CpsVT{\VA} \Vfun \CpsVT{\VB} &
\CpsCT{(\VA \Cfun \CB)} & \: = \: {\Ccopower{(\CpsVT{\VA})}{\CpsCT{\CB}}} \\
\CpsVT{\CA} & \: = \: \CpsCT{\CA} \lpop \CR &
\CpsCT{\CI} & \: = \: {\CR} \\
\CpsVT{(\CA \lpop \CB)} & \: = \:  \CpsCT{\CB} \lpop \CpsCT{\CA}  &
\CpsCT{(\Cbang{\VA})} & \: =\:  \CpsVT{\VA} \Cfun  \CR \\
& &
\CpsCT{(\Ccopower{\VA}{\CB})} & \: = \: \CpsVT{\VA} \Cfun \CpsCT{\CB} \\
& &
\CpsCT{\Czero} & \: = \: \Cone \\
& &
\CpsCT{(\CA \Cplus \CB)} & \: = \: \CpsCT{\CA} \Cprod  \CpsCT{\CB} 

\CpsCT{z}  & \: = \:  k_z
\\
\CpsCT{\Cstar}  & \: = \:  \Cimagetype{\CD}{k_z}
\\
\CpsCT{\Cpair{t}{u}}  & \: = \:  
   {\Ccase{k_z}{k_x}{\CpsCT{t}\, [k_x/k_z]}{k_y}{\CpsCT{u}\,[k_y/k_z]}} 
\\
\CpsCT{\Cfst{t}}  & \: = \:  
   \CpsCT{t}\, [\Cinl{k_z}/k_z]
\\
\CpsCT{\Csnd{t}}  & \: = \:  
   \CpsCT{t}\, [\Cinr{k_z}/k_z]
\\
\CpsCT{(\Clam{x}{\VA}{t})}  & \: = \:  
   \copowerlet{x}{h}{k_z}{\,\CpsCT{t}\,[h/k_z]} 
\\
\CpsCT{(\Cappl{s}{t})}  & \: = \:  
   \CpsCT{s}\,[\copowerterm{(\CpsVT{t})}{k_z} \, / \, k_z]
\\
\CpsCT{(\Ilet{t}{u})}  & \: = \:  
   \CpsCT{t}\,[\lappl{\CpsVT{u}\,}{k_z} \, / \, k_z]
\\
\CpsCT{(\banglet{x}{t}{u})}  & \: = \:  
   \CpsCT{t}\,[(\Clam{x}{\CpsVT{\VA}}{\,\lappl{\CpsVT{u}\,}{k_z}})\, / \, k_z]
\\
\CpsCT{(\copowerterm{t}{u})}  & \: = \:  
   \CpsCT{u}\,[\Cappl{k_z}{\CpsVT{t}} \, / \, k_z]
\\
\CpsCT{(\copowerlet{x}{y}{s}{t})}  & \: = \:  
   \CpsCT{s}\,[(\Clam{x}{\CpsVT{\VA}}{\,\CpsCT{t}\,[k_z/k_y]})\, / \, k_z] 
\\
\CpsCT{(\Cimage{t})}  & \: = \:  \CpsCT{t}\,[\Cstar \, / \, k_z]
\\
\CpsCT{(\Cinl{t})}  & \: = \:  \CpsCT{t}\,[\Cfst{k_z} \, / \, k_z]
\\
\CpsCT{(\Cinr{t})}  & \: = \:  \CpsCT{t}\,[\Csnd{k_z} \, / \, k_z]
\\ 
\CpsCT{(\Ccase{s}{x}{t}{y}{u})}  & \: = \:  
   \CpsCT{s}\,[\Cpair{\CpsCT{t}\,[k_z/k_x]}{\,\CpsCT{u}\,[k_z/k_y]} \, / \, k_z] 
\\
\CpsCT{(\lappl{s}{t})}  & \: = \:  
   \CpsCT{t}\,[\lappl{\CpsVT{s}\,}{k_z} \, / \, k_z]

\CpsVT{x}  & \: = \:  x 
\\
\CpsVT{\Vstar}  & \: = \:  \Vstar 
\\
\CpsVT{\Vpair{t}{u}}  & \: = \:  \Vpair{\CpsVT{t}}{\CpsVT{t}}
\\
\CpsVT{(\Vfst{t})}  & \: = \:  \Vfst{\CpsVT{t}}
\\
\CpsVT{(\Vsnd{t})}  & \: = \:  \Vsnd{\CpsVT{t}}
\\
\CpsVT{(\Vlam{x}{\VA}{t})} & \: = \:  \Vlam{x}{\VA}{\,\CpsVT{t}}
\\
\CpsVT{(\Vappl{t}{u})}  & \: = \:  \Vappl{\CpsVT{t}\,}{\CpsVT{u}}
\\
\CpsVT{\Cstar}  & \: = \:  \llam{k}{\Czero}{\,\Cimagetype{\CR}{k}}
\\
\CpsVT{\Cpair{t}{u}}  & \: = \:  \llam{k}{\CpsCT{\CA} \Cplus \CpsCT{\CB}}
   {\,\Ccase{k}{k_x}{\lappl{\CpsVT{t}\,}{k_x}}{k_y}{\lappl{\CpsVT{u}\,}{k_y}}} 
\\
\CpsVT{\Cfst{t}}  & \: = \:  \llam{k}{\CpsCT{\CA}}
   {\,\lappl{\CpsVT{t}\,}{\Cinl{k}}}
\\
\CpsVT{\Csnd{t}}  & \: = \:  \llam{k}{\CpsCT{\CB}}
   {\,\lappl{\CpsVT{t}\,}{\Cinr{k}}}
\\
\CpsVT{(\Clam{x}{\VA}{t})}  & \: = \:  \llam{k}{\Ccopower{\CpsVT{\VA}}{\CpsCT{\CB}}}
   {\,\copowerlet{x}{h}{k}{\,\lappl{\CpsVT{t}\,}{h}}}
\\
\CpsVT{(\Cappl{s}{t})}  & \: = \:  \llam{k}{\CpsCT{\CB}}
   {\,\lappl{\CpsVT{s}\,}{\copowerterm{(\CpsVT{t})}{k}}}
\\
\CpsVT{\Itop}  & \: = \:  \llam{k}{\CR}{\, k}
\\
\CpsVT{(\Ilet{t}{u})}  & \: = \:  \llam{k}{\CpsCT{\CA}}{\, 
   \lappl{\CpsVT{t}\,}{\lappl{\CpsVT{u}\,}{k}}}
\\
\CpsVT{(\bang{t})}  & \: = \:  \llam{k}{\CpsVT{\VA} \Cfun \CR}
   {\,\Cappl{k\,}{\CpsVT{t}}}
\\
\CpsVT{(\banglet{x}{t}{u})}  & \: = \:  \llam{k}{\CpsCT{\CB}}
   {\,\lappl{\CpsVT{t}\,}{\Clam{x}{\CpsVT{\VA}}{\,\lappl{\CpsVT{u}\,}{k}}}}
\\
\CpsVT{(\copowerterm{t}{u})}  & \: = \:   \llam{k}{\CpsVT{\VA} \Cfun \CpsCT{\CB}}
   {\,\lappl{\CpsVT{u}\,}{\Cappl{k\,}{\CpsVT{t}}}} 
\\
\CpsVT{(\copowerlet{x}{y}{s}{t})}  & \: = \:  \llam{k}{\CpsCT{\CC}}
   {\,\lappl{\CpsVT{s}\,}{\Clam{x}{\CpsVT{\VA}}{\,\CpsCT{t}\,[k/k_y]}}} 
\\
\CpsVT{(\Cimage{t})}  & \: = \:  \llam{k}{\CpsCT{\CA}}
   {\,\lappl{\CpsVT{t}\,}{\Cstar}}
\\ 
\CpsVT{(\Cinl{t})}  & \: = \:  \llam{k}{\CpsCT{\CA} \Cprod \CpsCT{\CB}}
   {\,\lappl{\CpsVT{t}\,}{\Cfst{k}}}
\\
\CpsVT{(\Cinr{t})}  & \: = \:  \llam{k}{\CpsCT{\CA} \Cprod \CpsCT{\CB}}
   {\,\lappl{\CpsVT{t}\,}{\Csnd{k}}}
\\ 
\CpsVT{(\Ccase{s}{x}{t}{y}{u})}  & \: = \:   \llam{k}{\CpsCT{\CC}}
   {\,\lappl{\CpsVT{s}\,}{\Cpair{\CpsCT{t}\,[k/k_x]}{\,\CpsCT{u}\,[k/k_y]}}} 
\\
\CpsVT{(\llam{z}{\CA}{t})}  & \: = \:  \llam{k}{\CpsCT{\CB}}{\,\CpsCT{t}\,[k/k_z]}
\\ 
\CpsVT{(\lappl{s}{t})}  & \: = \:  \llam{k}{\CpsCT{\CB}}
   {\,\lappl{\CpsVT{t}\,}{\lappl{\CpsVT{s}\,}{k}}}

\Vj{\CpsVT{\Gamma}}{\CpsVT{t}}{\CpsVT{\VA}} \enspace ,

\Cj{\CpsVT{\Gamma}}{\In{k_z}{\CpsCT{\CB}}}{\CpsCT{t}}{\CpsCT{\CA}} \enspace .

\Vj{\CpsVT{\Gamma}}{\CpsVT{t}}{\CpsVT{\VA}}
\qquad
\Vj{\CpsVT{\Gamma}, \In{x}{\CpsVT{\VB}}}{\CpsVT{t}}{\CpsVT{\VA}} \enspace ,

\Cj{\CpsVT{\Gamma}}{\In{k_z}{\CpsCT{\CB}}}{\CpsCT{t}}{\CpsCT{\CA}} 
\qquad
\Cj{\CpsVT{\Gamma}, \In{x}{\CpsVT{\VC}}}{\In{k_z}{\CpsCT{\CB}}}{\CpsCT{t}}{\CpsCT{\CA}} 
\Ceq{\CpsVT{\Gamma}}{\In{k_z}{\CpsCT{\CB}}}
   {\CpsCT{(t[u/x])}}{\CpsCT{t}\, [\CpsVT{u}\, / \, x]}{\CpsCT{\CD}} \enspace .\Veq{\CpsVT{\Gamma}}{\CpsVT{(t[u/x])}}
    {\llam{k}{\CpsCT{\CB}}{\,\lappl{\CpsVT{u}\,}{\CpsCT{t}\,[k\,/\,k_x]}}}{\CpsCT{\CB} \lpop \CR} \enspace .\Ceq{\CpsVT{\Gamma}}{\In{k_z}{\CpsCT{\CB}}}{\CpsCT{(t[u/x])}}
    {\CpsCT{u}\, [(\CpsCT{t}\,[k_z\, / k_x])\, / \, k_z]}{\CpsCT{\CD}} \enspace .
\CpsVT{((\llam{z}{\CB_1}{t'})[u/x])} \: 
&  = \: \CpsVT{(\llam{z}{\CB_1}{\, t'[u/x]})}
\\
& = \: \llam{\,k_z}{\CpsCT{\CB_2}}{\, \CpsCT{(t'[u/x])}}
\\
& = \: \llam{\,k_z}{\CpsCT{\CB_2}}{\, \CpsCT{(t')}\, [\CpsVT{u}\, / \, x]}
  && \text{by induction hypothesis}
\\
& = \: \CpsVT{(\llam{z}{\CB_1}{t'})}\, [\CpsVT{u}\, / \, x] \enspace .

\CpsVT{(t[u/x])} \: 
& = \: \CpsVT{(\Ccase{t'[u/x]}{y}{t_1}{z}{t_2})}
\\
& = \:   \llam{k}{\CB}{\, 
   \lappl{\CpsVT{(t'[u/x])}\,}{\Cpair{\CpsCT{t_1}\, [k/k_y]}{\CpsCT{t_2}\, [k/k_z]}}}
\\
& = \:  \llam{k}{\CB}{\, 
      \lappl{\CpsVT{u}\,}{\CpsCT{(t')}\,[\Cpair{\CpsCT{t_1}\, [k/k_y]}{\CpsCT{t_2}\, [k/k_z]}\,/\,k_x]}}
  && \text{by induction hypothesis}
\\
& = \: \llam{k}{\CB}{\, 
          \lappl{\CpsVT{u}\,}{\CpsCT{(\Ccase{t'}{y}{t_1}{z}{t_2})}\, [k/k_x]}}
\\
& =  \: \llam{k}{\CpsCT{\CB}}{\,\lappl{\CpsVT{u}\,}{\CpsCT{t}\,[k/k_x]}}
\enspace .

\Veq{\CpsVT{\Gamma}}{\CpsVT{(\banglet{x}{\bang{t}}{u})}}{\CpsVT{(u[t/x])}}{\CpsCT{\CB} \lpop \CR} \enspace .

\CpsVT{(\banglet{x}{\bang{t}}{u})} \:
&  = \: \llam{k}{\CpsCT{\CB}}
   {\,\lappl{\CpsVT{(\bang{t})}\,}{\Clam{x}{\CpsVT{\VA}}{\,\lappl{\CpsVT{u}\,}{k}}}}
\\
& = \:
\llam{k}{\CpsCT{\CB}}
   {\,\Cappl{(\Clam{x}{\CpsVT{\VA}}{\,\lappl{\CpsVT{u}\,}{k}})\,}{\CpsVT{t}}}
 && \text{def.~of }
\\
& = \:\llam{k}{\CpsCT{\CB}}
   {\,\lappl{\CpsVT{u}\,[\CpsVT{t}\,/\, x]\,}{k}}
 && \text{ equality}
\\
& = \: {\CpsVT{u}\,[\CpsVT{t}\,/\, x]\,}
 && \text{ equality}
\\
& = \: \CpsVT{(u[t/x])}
 && \text{Prop.~\ref{prop:trans:subs}.\ref{subs:i}} \enspace .
\Ceq{\Gamma}{\In{k_z}{\CpsCT{\CB}}}{\CpsCT{(\banglet{x}{t}{u[\bang{x}/y]})}}{\CpsCT{(u[t / y])}}{\CpsCT{\CD}}
\enspace .
\CpsCT{(\banglet{x}{t}{u[\bang{x}/y]})} \:
& = \: \CpsCT{t}\,[(\Clam{x}{\CpsVT{\VA}}{\,\lappl{\CpsVT{(u[\bang{x}/y])}\,}{k_z}})\, / \, k_z]
\\
& = \: \CpsCT{t}\,[(\Clam{x}{\CpsVT{\VA}}{\,\lappl{\CpsVT{(\bang{x})}\,}{\CpsCT{u} \,[k_z/k_y]}})\, / \, k_z]
 && \text{Prop.~\ref{prop:trans:subs}.\ref{subs:iii}}
\\
& = \: \CpsCT{t}\,[(\Clam{x}{\CpsVT{\VA}}{\, \Cappl{(\CpsCT{u} \,[k_z/k_y])}{\CpsVT{x}}})
\, / \, k_z]
 && \text{def.~of }
\\
& = \: \CpsCT{t}\,[(\Clam{x}{\CpsVT{\VA}}{\, \Cappl{(\CpsCT{u} \,[k_z/k_y])}{x}})
\, / \, k_z]
 && \text{def.~of }
\\
& = \: \CpsCT{t}\,[(\CpsCT{u} \,[k_z/k_y]) \, / \, k_z]
 && \text{ equality}
\\
& = \: \CpsCT{(u[t / y])}
 && \text{Prop.~\ref{prop:trans:subs}.\ref{subs:iv}} \enspace .
\CpsVT{(u[\bang{x}/y])} \: = \:
\llam{k}{\CpsCT{\CB}}{\,\lappl{\CpsVT{(\bang{x})}\,}{\CpsCT{u}\,[k\,/\,k_y]}} \enspace ,
\Cj{\CpsVT{\Gamma}}{\In{k_y}{\CB}}{u}{\CpsVT{\VA} \Cfun \CR} 
\qquad
\Cj{\CpsVT{\Gamma}, \In{x}{\CpsVT{\VA}}}{\In{k_y}{\CB}}{u}{\CpsVT{\VA} \Cfun \CR} 
\enspace .
\Viso{\alpha} \: & = \: \Vlam{x}{\alpha}{x} 
\\
\Viso{\Vone} \: & =  \: \Vlam{x}{\Vone}{\Vstar} 
\\
\Viso{\VA \Vprod \VB} \: & = \: \Vlam{z}{\CpsVVT{\VA} \Vprod \CpsVVT{\VB}}
      {\, \Vpair{\Vappl{\Viso{\VA}}{\Vfst{z}}}{\Vappl{\Viso{\VB}}{\Vsnd{z}}}}
\\
\Viso{\VA \Vfun \VB} \: & = \: \Vlam{f}{\CpsVVT{\VA} \Vfun \CpsVVT{\VB}}
      {\, \Vlam{x}{\VA}{\, \Vappl{\Viso{\VB}}{\Vappl{f}{\Vappl{\Viso{\VA}^{-1}}{x}}}}}
\\
\Viso{\CA} \: & = \: \Vlam{h}{\CI \lpop \CpsCCT{\CA}}
      {\, \lappl{\Ciso{\CA}\,}{\lappl{h\,}{\Itop}}}
\\
\Viso{\CA \lpop \CB} \: & = \: \Vlam{h}{\CpsCCT{\CA} \lpop \CpsCCT{\CB}}
      {\, \llam{x}{\CA}{\,\lappl{\Ciso{\CB}\,}{\lappl{h\,}{\lappl{\Ciso{\CA}^{-1}\,}{x}}}}}
\
\caption{Type isomorphisms for the involution property}
\label{fig:tiip}
\end{figure}


\begin{lem}
Suppose  is either a computation-type constant or . Then
each term  is an isomorphism, and each

is a linear isomorphism.
\end{lem}

\proof
The two statements are proved simultaneously by induction on the type,
with, in the case of a computation type , the inverse
for  being established before that of .
The assumption that  is either a computation-type constant or  implies
that , and this fact is used frequently
in the proof. We consider just two illustrative cases:
 and .

In the case of  , we have ,
and the inverse  is defined 
by

Then we have (using the obvious definition for composition):

and the verification that 
 is similarly straightforward.

In the case of  , we have 

and the inverse 
is defined by

Then:

where the third equality applies the induction hypothesis, and all others,
including the rearrangement of ``let'' expressions in the second equation, justified 
by the equalities of 
Figure~\ref{figure:effects:equalities}.
The verification that 
 is 
straightforward.
\qed

We remark that the main reason for including   as a primitive EEC construct, in the present paper,
was to permit the  uniform definition of the type isomorphisms, given in Figure~\ref{fig:tiip},
which covers both  cases of interest: when  is a computation-type constant, and when it is
. The alternative would have beeen to have omitted  from the primitive syntax, 
defining it as . Had this been done, 
we would have  obtained: , in the case that  is
a computation-type constant; and , in the case that
 is  (i.e., ). In both cases, 
linear isomorphisms between  and  still exist, 
they can no longer be given uniformly.


In order to state the fundamental involution property enjoyed
by the self-translation on EEC, for a context

we introduce the notation  for the substitution


\begin{thm}[Involution property]
\label{theorem:involution}
Suppose  is either a computation-type constant or .
\begin{enumerate}[\em(1)]
\item \label{inv:i}
\label{item:Vnat} If  then
.

\item \label{inv:ii} If  then
.
\end{enumerate}
\end{thm}
\proof
The statements are proved simultaneously, by induction on . There are 41 cases in the
proof, one for each of the equations in Figures~\ref{fig:cps:compterms} 
and~\ref{fig:cps:valterms}. By way of illustration,
we verify two of them, the second being among the most complex cases in the proof.

For the first case, suppose . We verify that:

The basic strategy is to first expand the inner , then the
outer , applying the 
definitions of  and
 until the induction hypothesis can be invoked.
Between these steps, we use 
the equalities of Figure~\ref{figure:effects:equalities} to simplify the terms as far as possible.
Henceforth, we treat applications of equalities from
Figure~\ref{figure:effects:equalities} as trivial. So, in the detailed
derivation below, we do not annotate such steps. Nor do we explain 
obvious expansions of  and .


For the second case, suppose  and 
. We verify that

Adopting a similar strategy to above, we obtain:

Here, (\ref{complicated:i}) is by Proposition~\ref{prop:trans:subs}.\ref{subs:iv},
 (\ref{complicated:ii}) is by definition of ,
 (\ref{complicated:iii}) applies the induction hypothesis for ,
 (\ref{complicated:iv}) expands  
using (\ref{banginverse}), and 
 (\ref{complicated:v}) applies the induction hypothesis for  (which is applicable only 
at this point in the argument, because  is typed 
relative to the context  rather than ).
\qed

We end the present section by applying Theorem~\ref{theorem:involution}
to derive the full completeness of
the self-translation.



\begin{thm}[Full completeness of self-translation] 
\label{thm:full:complete}
Suppose  is either a computation-type constant or .
\begin{enumerate}[\em(1)]
\item \label{fc:i}
  If  and 
 
then .

\item \label{fc:ii}
       If  
       then there exists   such that 
.

\item \label{fc:iii}
If  and  

then .

\item \label{fc:iv}
If  then there exists 
 such that \\
.
\end{enumerate}
\end{thm}
\proof
For statement~\ref{fc:i}, suppose  and . Then:

\noindent
For statement~\ref{fc:ii}, suppose .
Define . Then:

The proofs of statements~\ref{fc:iii} and~\ref{fc:iv} are similar.
\qed



\def\Groupoid{\mathbf{Grpd}}
\def\cni{{cni}}
\def\fudgey{sufficiently bicomplete}

\section{Recovering linear-use CPS translations of typed lambda-calculus}
\label{section:recovering}

In this section, we use the self-translation to establish properties
of the call-by-value and call-by-name linear-use CPS translations
of Section~\ref{sec:lin:cps}. The main property we exploit 
is that  the generic self-translation 
subsumes  the call-by-value
and call-by-name translations.
Indeed, the latter are obtained uniformly by precomposing the
generic self-translation on EEC with 
the standard call-by-value and call-by-name translations
from -calculus to EEC, given in Section \ref{section:cbv:cbn}.

\begin{thm}[Recovering ]
\label{theorem:recover:cbv}
For every simple type , we have 
; and, for
every simply-typed term , we have 
.
\end{thm}

\begin{thm}[Recovering ]
\label{theorem:recover:cbn}
Suppose  is different from , for every
simply-typed -calculus type constant .
Then, for every , 
we have 
, hence
; and, for
every term , we have 
.
\end{thm}
\noindent
The  proofs are by induction on the structure of  and . 
\proof[Proof of Theorem~\ref{theorem:recover:cbv}]
For the type equality,  we consider the case of .

And, in the case of the term , where 
and , we have:

\qed
\proof[Proof of Theorem~\ref{theorem:recover:cbn}]
First, we observe that for a type-constant , we have

where the middle equality relies on the asumption that 
 is different from .

Of the other cases, we again consider .

And the case of an application  works out as:

\qed

We comment that many of the syntactic choices of this paper have been  made 
in order to obtain Theorems~\ref{theorem:recover:cbv} and~\ref{theorem:recover:cbn}
in the simple form stated. For example, in the conference version of the paper~\cite{EMS:fossacs},
where neither value-type and computation-type products nor
value-\ and computation-type function spaces are distinguished syntactically,
Theorem~\ref{theorem:recover:cbn} holds only up to type isomorphism,
rather than up to equality. Similarly, had a different choice been made for

in Figure~\ref{figure:lincps}, for example
,
as discussed in Section~\ref{sec:lin:cps}, then Theorem~\ref{theorem:recover:cbv}
would have held only up to isomorphism. 

Using Theorems~\ref{theorem:recover:cbv} and~\ref{theorem:recover:cbn}, it is now straightforward
to provide the postponed proofs of soundness
and full completeness for the cbv and cbn linear-use CPS translations of simply-typed -calculus from
Section~\ref{sec:lin:cps}, by deriving  these
results as consequences of soundness and full completeness for the self-translation
(Theorems~\ref{thm:cps:soundness} and~\ref{thm:full:complete}).
We give the proofs for the call-by-value case only 
(Proposition~\ref{prop:cbvLincps:sound} and Theorem~\ref{thm:cbvLincps:complete}).
The proofs for the corresponding call-by-name results 
(Proposition~\ref{prop:cbnLincps:sound} and Theorem~\ref{thm:cbnLincps:complete}),
are similarly straightforward.

\proof[Proof of Proposition~\ref{prop:cbvLincps:sound} (Soundness )]
Suppose
. Proposition~\ref{prop:cbv}.\ref{cbv:i} shows
.
Whence, by Theorem~\ref{thm:cps:soundness},
.
That is, by Theorem~\ref{theorem:recover:cbv},
.
\qed

\proof[Proof of Theorem~\ref{thm:cbvLincps:complete}  (Full completeness of )]
For statement~\ref{fcl:i}, suppose  and 
.
By Theorem~\ref{theorem:recover:cbv}, this is equivalent to
.
So, by Theorem~\ref{thm:full:complete}.\ref{fc:i},
.
Whence, by Proposition~\ref{prop:cbv}.\ref{cbv:ii},
, as required.


For statement~\ref{fcl:ii}, 
suppose 
.
That is, by Theorem~\ref{theorem:recover:cbv},
.
Then, by Theorem~\ref{thm:full:complete}.\ref{fc:ii} there exists 
 such that
.
And, by Proposition~\ref{prop:cbv}.\ref{cbv:iii},
there exists  such that
.
Therefore, by Theorem~\ref{thm:cps:soundness},
.
That is, again by Theorem~\ref{theorem:recover:cbv},
, as required.
\qed


\section{Perspectives}
\label{section:perspectives}

Throughout the paper, we have taken EEC for granted. However, linear-use CPS translations
can themselves be used as a motivation for the selection of type constructors 
appearing in EEC. 
Given Hasegawa's call-by-value and call-by-name linear-use CPS translations into ILL
\cite{Hasegawa:Flops:02,Hasegawa:Flops:04}, it is natural to ask if these translations
can be encompassed within a single linear-use CPS translation of Levy's CBPV
into ILL --- since one of the \emph{raisons d'\^{e}tre} of CBPV is to have a uniform 
language generalising cbv and cbn~\cite{Levy:book}. For our \emph{effect calculus} (EC),
that is, for CBPV without value-type sums (see the discussion in 
Section~\ref{section:calculus}), the answer is provided by
our generic self-translation on EEC. A linear-use CPS translation of the effect calculus is obtained by
restricting the source of the self-translation to EC,
and by reinterpreting the target of the translation as ILL.
Having done this, one sees that
the fragment of ILL that is used in performing this translation is EEC.
Thus EEC arises as naturally the smallest fragment of ILL able to act as a target language
for a linear-use CPS translation of EC.
Value-type sums, that is the whole of CBPV, can be accommodated in the picture
by simply adding value-type sums to EEC, see~\cite{EMSb}. The 
generic self-translation of Section~\ref{section:canonical} easily extends
to a self-translation on the resulting system EEC. Thus there is a
linear-use CPS translation of full CBPV into EEC.\footnote{It 
is less straightforward to give a linear-use
CPS translation of the whole of CBPV into ILL. Because there is
no distinction between ``linear'' and ``intuitionistic'' types, analogous
to the distinction between computation and value types, there is no
natural interpretation for  value-type sums in ILL. Sums are best incorporated by
moving to a version of linear logic that includes such a type distinction~\cite{Benton:95}.}

It is a remarkable fact that EEC supports its own linear-use CPS translation as
a self-translation. As we have seen, this property does not hold of smaller 
fragments, such as the effect calculus, whose linear-use CPS translation
requires the full expressivity of EEC.  It also does not extend to ILL
itself. That is, the linear-use CPS translation of EEC cannot be extended to
obtain an analogous linear-use CPS translation from ILL to itself.
To appreciate this, it is necessary to say something about the
category-theoretic model theory underlying linear-use CPS translations.
This model theory provides an illuminating perspective on the 
syntactic material presented in the paper.



Roughly speaking, a \emph{model}  of EEC
is given by a tuple 

where:  is a category modelling functions between value types;
 is a category modelling linear functions between computation types;
and  is an adjunction, with   modelling the  type construction,
and  providing the coercion from computation types to value types.
A significant amount of 
additional structure,
all of which is determined by universal properties,
is also required on the categories, to interpret the other type constructors of EEC.
The reader is referred to~\cite{EMS,EMSb,EMSc} for further details,
which are somewhat technical --- substantial use is made of 
{enriched category theory}~\cite{Kelly:book}.
The point relevant to the content of the present paper is that 
the categorical models of EEC are closed under an interesting construction.
Given a model as above, let  be a chosen object of .
We call the structure 
 a
\emph{pointed model}. 
Such a pointed model, , has a \emph{dual (pointed) model}:

where  corresponds to the contravariant mapping  from value to computation types,
 
corresponds to the contravariant mapping  in the other direction,
and  is the object of  chosen to model the type  in .
Thus the monad  on , which models  in ,
is converted to the monad  on 
, which models  in the dual model .
Monads of the form  have been called \emph{dual monads} 
by Lawvere~\cite{Lawvere:doctrines}. In our setting, the dual terminology is particularly
apt, since we have:
\begin{fact}
\label{fact:double:dual}
Every pointed model  is isomorphic to its double dual .
\end{fact}
\noindent
Importantly, the isomorphism preserves the pointed-model structure, but only up
to coherent natural isomorphism. Up-to-isomorphism structure preservation
is taken as the basic notion of morphism of EEC models~\cite{EMS,EMSc}.
Those  special morphisms that preserve structure up to equality (``on the nose'')
are referred to as \emph{strict}.


Given the description of  as ,
a connection with linear-use CPS translations is apparent at the level 
of  monads. Accordingly, one might call  a linearly-used continuations
model relative to . By Fact~\ref{fact:double:dual},
every (pointed) model of EEC arises as a linearly-used continuations model relative
to another model, namely relative to its own dual model --- a property, which is somewhat
surprising at first sight. 

The dual monad construction also allows us to reconstruct the 
self-translation of Section~\ref{section:canonical} semantically.
There is a syntactic model  
whose objects are EEC types and whose morphisms are 
terms modulo provable equality. 
This enjoys an initiality property: for any interpretation
of type constants in a model   there is a unique
strict morphism of models from  to 
that maps type constants in the specified way. 
Let  be a chosen computation type.
Define  be the pointed model with  as 
its point.
Interpret
all type constants as themselves,  except for  which, if it is a type constant,
gets interpreted as . Then the induced strict morphism of  models
from  to the underlying model
of  is exactly the generic self-translation of 
Section~\ref{section:canonical}. That is, the action of the morphism 
on (objects and morphisms of)  is
given by  (on types and terms respectively), and its action on 
is given by .

It is now possible to substantiate the claim made earlier that the 
self-translation of EEC does not extend to the whole of ILL.
Any model of ILL (of the general form described in~\cite{Benton:95}) 
is also a model of ECC. Let  be a pointed model of ILL.
Then, in general, its dual , although still a model of EEC,
is not a model of ILL (the linear category need not be
symmetric monoidal closed). In particular, when  is the
syntactic (initial) model of ILL (with chosen ), the dual model
 is not a model of ILL.  Thus there is no induced morphism of models
from the syntactic ILL model to its dual. That is, there is no linear-use CPS
translation of ILL to itself.

Returning to the self-translation of EEC, we now outline how the semantic perspective
provides a conceptually clean proof of the involution property and full completeness.
Suppose  is either a type constant or . Then the
morphism from  to ,
described above as corresponding to the self-translation, extends (trivially) to a morphism
of pointed models from  to .
The operation of taking duals is functorial (in an appropriate 2-categorical sense), and so
we obtain a morphism of pointed models from 
 to ;
whence, by composition, a morphism from 
 to . 
The composite morphism preserves type constants. Furthermore 
enjoys a universal property with respect to non-strict morphisms: 
for any interpretation
of type constants in a model   there is a 
unique-up-to-coherent-natural-isomorphism 
morphism of models from  to 
that maps type constants (up to isomorphism) in the specified way. 
This means that, the induced morphism from  to 
 is coherently
naturally isomorphic to the morphism implementing the double-duality of Fact~\ref{fact:double:dual}.
This is literally the involution property of the self-translation (Theorem~\ref{theorem:involution}) in semantic form.
With a little more manipulation of the universal property
of , one obtains:
\begin{fact}
The morphism 
from  to  is an equivalence
of pointed models.
\end{fact}

\noindent 
This result corresponds to the full completeness of the self translation
(Theorem~\ref{thm:full:complete}). Semantically, it states the
surprising, at first sight, fact that the syntactic (pointed) model is self-dual.

There is, however,  an alternative perspective on models, from which the
self-duality of the initial model is less surprising. It is possible to omit
the adjunction  from the structure of the model, and instead
simply specify the object . The adjunction is then recovered using
the requirement that  have \emph{copowers}
(a concept from  enriched category theory), which is part of the
assumed structure of a model. The operation of taking the dual of a pointed
model, with point , then has a simple description: instead of redefining the
adjunction, the r\^{o}les of the objects  and  are simply swapped in the structure.

Detailed definitions and proofs of 
all the semantic facts referred to above in this section will appear in
a paper devoted entirely to the category-theoretic models of EEC~\cite{EMSc}.
Unfortunately, although  the high-level ideas are straightforward, 
considerable technicalities arise in getting the details correct. 
The reader who wishes to see a slightly fuller treatment
than the outline given above, but not all details, is referred to the conference
version of the present paper~\cite{EMS:fossacs}.

To finish, we return to syntax. The alternative formulation of models, referred to
above, has a syntactic counterpart. Since  is included as a primitive
computation type in our formulation of EEC, it would be possible
to omit, from the syntax of EEC, 
both the  type constructor  and the inclusion
of computation types amongst value types. The former can
be defined as . And the  value type corresponding to
a computation type  can be recovered as  . (Thus Levy's
 constructor~\cite{Levy:book} is rendered visible.) Using this 
restricted syntax, the involution property of Theorem~\ref{theorem:involution}
has a simplified form. There is no longer any need for the isomorphisms
 and , since one obtains identities
 and . 
The very mild drawback of this formulation is that it 
requires the slightly more complex definition of

in Figure~\ref{figure:cbv:cbn}. Or alternatively, one could take
,
which would fit in with redefining
, as
discussed in Section~\ref{sec:lin:cps},
leaving the 
value-type-function-space constructor, , superfluous to the translations.

However, for the present paper, we have preferred to retain 
as a primitive type construct, due to the basic r\^{o}le it plays in
related type systems: as  in Moggi's computational metalanguage~\cite{Moggi:91},
as  in Levy's CBPV~\cite{Levy:book}, and as the exponential in
linear logic~\cite{Girard:87}. For one thing, our choice of primitives
has allowed us to give the various translations of 
Sections~\ref{section:cbv:cbn} and~\ref{sec:lin:cps}
just as they appear in the literature
\cite{Moggi:91,Filinski:phd,Levy:book,Hasegawa:Flops:02,Hasegawa:Flops:04},
modulo the change  to EEC notation.
We also comment that it is perhaps the standard focus on 
 (or  or ) as the key construct in effect languages
that makes the involution property of the self-translation translation 
come as a surprise when first encountered. For, amongst computation types,
the type  has the most interesting translation --- the only one which
is not part of a dual pair. It is for this reason that the proofs of
Section~\ref{section:canonical} mainly focus on constructs associated with types of the form
 as providing  the interesting cases.

In the present paper, we have  investigated the enriched effect calculus  as a metalanguage for 
formalising one possible interaction between linearity and CPS translations.
It is the belief of the authors that EEC will prove
a useful language for modelling other ways in which linearity
and effects combine. Some potential examples of such interactions
are briefly discussed in the main paper introducing EEC~\cite{EMSb}. 
It would be interesting to see further convincing examples worked out
in detail.

\section*{Acknowledgements} 
We thank Masahito Hasegawa, Paul Levy and 
the anonymous referees for helpful suggestions.

\bibliographystyle{alpha}

\begin{thebibliography}{BORT02}

\bibitem[Bar97]{Barber:97}
A.\ Barber.
\newblock {\em Linear Type Theories, Semantics and Action Calculi}.
\newblock PhD thesis, Department of Computer Science, University of Edinburgh,
  1997.

\bibitem[Ben95]{Benton:95}
P.~N.\ Benton.
\newblock A mixed linear and non-linear logic: Proofs, terms and models.
\newblock In {\em Proc.\ Computer Science Logic (CSL) 1994}, volume 933 of {\em
  LNCS}. Springer, 1995.

\bibitem[BORT02]{BORT:02}
J.\ Berdine, P.~W.\ O'Hearn, U.\ Reddy, and H.\ Thielecke.
\newblock Linear continuation-passing.
\newblock {\em Higher Order and Symbolic Computation}, 15:181--208, 2002.

\bibitem[BW96]{BW:96}
P.~N.\ Benton and P.\ Wadler.
\newblock Linear logic, monads, and the lambda calculus.
\newblock In {\em Proc.\ 11th Annual Symposium on Logic in Computer Science
  (LICS)}, 1996.

\bibitem[EMS09]{EMS}
J.\ Egger, R.~E.\ M{\o}gelberg, and A.\ Simpson.
\newblock Enriching an effect calculus with linear types.
\newblock In {\em Proc.\ Computer Science Logic (CSL)}, volume 5771 of {\em
  LNCS}, pages 240--254. Springer, 2009.

\bibitem[EMS10]{EMS:fossacs}
J.\ Egger, R.~E.\ M{\o}gelberg, and A.\ Simpson.
\newblock Linearly-used continuations in the enriched effect calculus.
\newblock In {\em Proc.\ Foundations of Software Science and Computation
  Structures (FoSSaCS)}, volume 6014 of {\em LNCS}, pages 18--32. Springer,
  2010.

\bibitem[EMS12]{EMSb}
J.\ Egger, R.~E.\ M{\o}gelberg, and A.\ Simpson.
\newblock The enriched effect calculus: Syntax and semantics.
\newblock {\em Journal of Logic and Computation}, Advance Access published June
  19, 2012.
\newblock doi: {10.1093/logcom/exs025}.

\bibitem[EMS1x]{EMSc}
J.\ Egger, R.~E.\ M{\o}gelberg, and A.\ Simpson.
\newblock Categorical models for the enriched effect calculus, 201x.
\newblock In preparation.

\bibitem[Fil96]{Filinski:phd}
A.\ Filinski.
\newblock {\em Controlling Effects}.
\newblock PhD thesis, Carnegie Mellon University, 1996.

\bibitem[Gir87]{Girard:87}
J.-Y.\ Girard.
\newblock Linear logic.
\newblock {\em Theoretical Computer Science}, 50:1--102, 1987.

\bibitem[Has02]{Hasegawa:Flops:02}
M.\ Hasegawa.
\newblock Linearly used effects: Monadic and {CPS} transformations into the
  linear lambda calculus.
\newblock In {\em Proc.\ 6th International Symposium on Functional and Logic
  Programming (FLOPS)}, volume 2441 of {\em LNCS}, pages 167--182. Springer,
  2002.

\bibitem[Has04]{Hasegawa:Flops:04}
M.\ Hasegawa.
\newblock Semantics of linear continuation-passing in call-by-name.
\newblock In {\em Proc.\ 7th International Symposium on Functional and Logic
  Programming (FLOPS)}, volume 2998 of {\em LNCS}, pages 229--243. Springer,
  2004.

\bibitem[Kel82]{Kelly:book}
G.~M.\ Kelly.
\newblock {\em Basic Concepts of Enriched Category Theory}, volume~64 of {\em
  LMS Lecture Notes}.
\newblock Cambridge University Press, 1982.

\bibitem[Law69]{Lawvere:doctrines}
F.~W.\ Lawvere.
\newblock Ordinal sums and equational doctrines.
\newblock In {\em Seminar on Triples and Categorical Homology Theory (ETH,
  Z\"{u}rich)}, pages 141--155. Springer, 1969.

\bibitem[Lev04]{Levy:book}
P.~B.\ Levy.
\newblock {\em Call-by-push-value. A functional/imperative synthesis}.
\newblock Semantic Structures in Computation. Springer, 2004.

\bibitem[Lev05]{Levy:models}
P.~B.\ Levy.
\newblock Adjunction models for call-by-push-value with stacks.
\newblock {\em Theory and Applications of Categories}, 14:75--110, 2005.

\bibitem[Mog89]{Moggi:89}
E.\ Moggi.
\newblock Computational lambda-calculus and monads.
\newblock In {\em Proc.\ 4th Annual Symposium on Logic in Computer Science
  (LICS)}, pages 14--23, 1989.

\bibitem[Mog91]{Moggi:91}
E.\ Moggi.
\newblock Notions of computation and monads.
\newblock {\em Information and Computation}, 93:55--92, 1991.

\bibitem[Par92]{Parigot:92}
M.\ Parigot.
\newblock -calculus: an algorithmic interpretation of classical
  natural deduction.
\newblock In {\em Proc.\ Logic Programming and Automated Reasoning (LPAR)},
  volume 624 of {\em LNCS}, pages 190--201. Springer, 1992.

\bibitem[Plo75]{Plotkin}
G.~D.\ Plotkin.
\newblock Call-by-name, call-by-value and the lambda-calculus.
\newblock {\em Theoretical Computer Science}, 1:125--159, 1975.

\bibitem[RS98]{RS}
B.\ Reus and Th.\ Streicher.
\newblock Classical logic, continuation semantics and abstract machines.
\newblock {\em Journal of Functional Programming}, 8:543--572, 1998.

\end{thebibliography}




\end{document}
