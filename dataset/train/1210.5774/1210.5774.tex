\pdfpagewidth=8.5in
\pdfpageheight=11in

\pdfoutput=1

\documentclass[letterpaper,11pt]{article}

\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{graphicx}
\usepackage{wrapfig}
\usepackage[linesnumbered,algoruled,vlined]{algorithm2e}
\usepackage{xspace}
\usepackage[margin=1.2in]{geometry}
\usepackage{paralist}

\usepackage{color}
\usepackage{soul}
\newcommand{\boaz}[1]{\hl{\textbf{BPS}: #1}}

\newenvironment{denseitemize}{
\begin{list}{}{
\setlength{\topsep}{0pt}
\setlength{\partopsep}{0pt}
\setlength{\itemsep}{0pt}
}}{\end{list}}

\newcommand{\namedref}[2]{\hyperref[#2]{#1~\ref*{#2}}}
\newcommand{\sectionref}[1]{\namedref{Section}{#1}}
\newcommand{\appendixref}[1]{\namedref{Appendix}{#1}}
\newcommand{\theoremref}[1]{\namedref{Theorem}{#1}}
\newcommand{\defref}[1]{\namedref{Definition}{#1}}
\newcommand{\figref}[1]{\namedref{Figure}{#1}}
\newcommand{\lemmaref}[1]{\namedref{Lemma}{#1}}
\newcommand{\tableref}[1]{\namedref{Table}{#1}}
\newcommand{\corollaryref}[1]{\namedref{Corollary}{#1}}
\newcommand{\appref}[1]{\namedref{Appendix}{#1}}
\newcommand{\propref}[1]{\namedref{Proposition}{#1}}
\newcommand{\algref}[1]{\namedref{Algorithm}{#1}}
\newcommand{\lineref}[1]{\namedref{Line}{#1}}
\newcommand{\equalityref}[1]{\hyperref[#1]{Equality~(\ref*{#1})}}
\newcommand{\inequalityref}[1]{\hyperref[#1]{Inequality~(\ref*{#1})}}
\newcommand{\pprtyref}[1]{\hyperref[#1]{Property~(\ref*{#1})}}
\newcommand{\factref}[1]{\namedref{Fact}{#1}}

\newtheorem{theorem}{Theorem}[section]
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{definition}[theorem]{Definition}
\newtheorem{corollary}[theorem]{Corollary}
\newtheorem{remark}[theorem]{Remark}
\newtheorem{fact}{Fact}[section]

\newcommand{\blackslug}{\hbox{\hskip 1pt \vrule width 4pt height 8pt
depth 1.5pt \hskip 1pt}}
\newcommand{\QED}{\quad\blackslug\lower 8.5pt\null\par}
\newenvironment{proof}[1][Proof:]{\noindent \textbf{#1}\xspace}{\QED}

\newcommand{\N}{\mathbb{N}}
\newcommand{\R}{\mathbb{R}}
\newcommand{\E}{\mathbb{E}}
\newcommand{\BO}{\mathcal{O}}
\newcommand{\true}{\textsc{{true}}}
\newcommand{\false}{\textsc{{false}}}



\newcommand{\Set}[1]{\left\{ #1 \right\}}
\newcommand{\ceil}[1]{\left\lceil #1 \right\rceil}
\newcommand{\Seq}[1]{\left\langle #1 \right\rangle}
\newcommand{\ignore}[1]{}
\newcommand{\DEF}{\ensuremath{\stackrel{\rm def}{=}}}
\newcommand{\REM}[1]{\hfill//\emph{#1}}
\newcommand{\Rad}{\mathrm{rad}}
\newcommand{\Src}{\mathrm{source}}



\newenvironment{eqntext}{}

\def\denseformat{
\setlength{\textheight}{9in}
\setlength{\textwidth}{6.9in}
\setlength{\evensidemargin}{-0.2in}
\setlength{\oddsidemargin}{-0.2in}
\setlength{\headsep}{10pt}
\setlength{\topmargin}{-0.3in}
\setlength{\columnsep}{0.375in}
\setlength{\itemsep}{0pt}
}
\def\midformat{
\setlength{\textheight}{8.9in}
\setlength{\textwidth}{6.7in}
\setlength{\evensidemargin}{-0.2in}
\setlength{\oddsidemargin}{-0.2in}
\setlength{\headheight}{0in}
\setlength{\headsep}{10pt}
\setlength{\topsep}{0in}
\setlength{\topmargin}{0.0in}
\setlength{\itemsep}{0in}       \renewcommand{\baselinestretch}{1.1}
\parskip=0.070in
}
\def\spacyformat{
\setlength{\textheight}{8.8in}
\setlength{\textwidth}{6.5in}
\setlength{\evensidemargin}{-0.18in}
\setlength{\oddsidemargin}{-0.18in}
\setlength{\headheight}{0in}
\setlength{\headsep}{10pt}
\setlength{\topsep}{0in}
\setlength{\topmargin}{0.0in}
\setlength{\itemsep}{0in}      \renewcommand{\baselinestretch}{1.2}
\parskip=0.080in
}


\newcommand{\CONGEST}{\textbf{CONGEST}}
\newcommand{\BSP}{\mathrm{BSP}\xspace}
\newcommand{\Next}{\mathrm{next}}
\newcommand{\Paths}{\mathrm{paths}}
\newcommand{\Hd}{\mathrm{hd}}
\newcommand{\HD}{\mathrm{HD}}
\newcommand{\Wd}{\mathrm{wd}}
\newcommand{\WD}{\mathrm{WD}}
\newcommand{\SPD}{\mathrm{SPD}}
\newcommand{\Dist}{\mathit{dist}}
\newcommand{\Ball}{\mathit{ball}}
\newcommand{\cN}{\mathcal{N}}
\newcommand{\Pre}{\mbox{\sf pre}}
\newcommand{\Left}{\textrm{\sf l\_sib}}
\newcommand{\Size}{\textrm{\sf size}}
\newcommand{\Par}{\textrm{\sf par}}
\newcommand{\Lead}{Y}
\newcommand{\gsf}{\textsc{gsf}}
\newcommand{\OPT}{\mathrm{OPT}}
\newcommand{\ALG}{\mathrm{ALG}}
\newcommand{\LR}{\mathrm{LR}}
\newcommand{\cI}{\mathcal{I}}
\newcommand{\rtc}{\textsc{rtc}}
\newcommand{\Boaz}[1]{\boaz{#1}}
\newcommand{\cM}{\mathcal{M}}

\DeclareMathOperator{\polylog}{polylog}

\midformat

\hypersetup{colorlinks,linkcolor=blue,filecolor=blue,citecolor=blue,urlcolor=blue,pdfstartview=FitH}

\begin{document}
\setcounter{tocdepth}{3}
\date{}

\title{\textbf{Fast Routing Table Construction Using Small Messages}}

\author{
Christoph Lenzen\thanks{Supported by the Swiss Society of Friends of the Weizmann
Institute of Science and by the Swiss National Science Foundation (SNSF).}
\\
Dept.\ Computer Science \& Applied Mathematics\\
Weizmann Institute of Science\\
Rehovot 76100, Israel
\and
Boaz Patt-Shamir\thanks{Supported in part by the Israel Science
Foundation (grant 1372/09) and by Israel Ministry of Science and
Technology.}
\\
School of Electrical Engineering\\
Tel Aviv University\\
Tel Aviv 69978, Israel
}

\def\thepage{}
\begin{titlepage}
  
\maketitle

\begin{abstract}
We describe a distributed randomized algorithm computing approximate distances
and routes that approximate shortest paths. Let  denote the number of
nodes in the graph, and let  denote the \emph{hop diameter} of the graph,
i.e., the diameter of the graph when all edges are considered to have unit
weight. Given , our algorithm runs in  communication rounds using messages of  bits and guarantees a stretch of  with high probability. This is the first distributed
algorithm approximating weighted shortest paths that uses small messages and
runs in  time (in graphs where ). The time
complexity nearly matches the lower bounds of  in the
small-messages model that hold for \emph{stateless} routing (where routing
decisions do not depend on the traversed path) as well as approximation of the
weigthed diameter. Our scheme replaces the original identifiers of the nodes by
labels of size . We show that no algorithm
that keeps the original identifiers and runs for  rounds can
achieve a polylogarithmic approximation ratio.

Variations of our techniques yield a number of fast distributed approximation
algorithms solving related problems using small messages. Specifically, we
present algorithms that run in  rounds
for a given , and solve, with high probability, the
following problems:
\begin{compactitem}
\item -approximation for the Generalized
  Steiner Forest (the running time in this case has an additive
   term, where  is the number of terminals);
\item -approximation of weighted distances, using
  node labels of size  and
   bits of memory per node;
\item -approximation of the weighted diameter;
\item -approximate shortest paths using the labels
.
\end{compactitem}
\end{abstract}
\end{titlepage}
\pagenumbering{arabic}


\section{Introduction}

Constructing routing tables is a central task in network operation, the
Internet being a prime example. Besides being an end goal on its own
(facilitating the transmission of information from a sender to a
receiver), efficient routing and distance approximation are critical
ingredients in a myriad of other distributed applications.

At the heart of any routing protocol lies the computation of short paths in
weighted graphs, where edge weights may reflect properties such as link cost,
delay, bandwidth, reliability etc. In the distributed setting, an additional
challenge is that the graph whose shortest paths are to be computed serves also
as the platform carrying communication between the computing nodes. The result
of this double role is an intriguing interplay between two metrics: the given
shortest paths metric and the ``natural'' communication metric of the
distributed system. The first metric is used for the definition of shortest
paths, where an edge weight represents its contribution to path lengths; the
other metric is implicit, controlling the time complexity of the distributed
computation: each edge is tagged by the time it takes a message to cross it. If
these two metrics happen to be identical, then computing weighted shortest paths
to a single destination is trivial (for the all-pairs problem, see below).
For the general case, the standard normalization is that messages cross each
link in unit time, regardless of the link weight; this assumption is motivated by
network synchronization. On the other hand, the length of the message must be
taken into account as well. More precisely, in the commonly-accepted  \CONGEST\
model of network algorithms \cite{Peleg:book}, it is assumed that all link
latencies are one unit and messages have fixed size, typically 
bits, where  denotes the number of nodes.

The classical algorithm for computing shortest path distributively is the
distributed variant of the Bellman-Ford algorithm. This algorithm is used in
many networks, ranging from local to wide area networks. The Bellman-Ford
algorithm enjoys many properties that make it an excellent distributed algorithm
(locality, simplicity, self-stabilization). However, in weighted graphs, its
time complexity, i.e., the number of parallel iterations, may be as high as
 for a single destination. This is in sharp contrast with the
 time needed to compute \emph{unweighted} shortest paths to a single
destination, where  denotes the unweighted ``hop-diameter'' of the network.
The difference between  and  can be huge; suffices to say that the
hop-diameter of the Internet is estimated to be smaller than 50. Intuitively,
the problem originates in the fact that the Bellman-Ford algorithm explores
paths in a hop-by-hop fashion, and the aforementioned superposition of metrics may
result in a  path that is weight-wise short, but consists of  edges.
If shortest paths have at most  edges, then it suffices to run the
Bellman-Ford algorithm for  communication rounds. Indeed, the running time
of a few distributed algorithms is stated as a function of this or a similar
parameter for exactly this reason (e.g., \cite{DDP,KKMPT,KP-08}).

To the best of our knowledge, no distributed algorithm for computing
(approximate) weighted shortest paths in  time in the \CONGEST\ model
was known to date. In this paper we present a distributed algorithm  that
computes approximate all-pairs shortest paths and distances using small
messages, in time that nearly matches the lower bound of
.

\subsection{Detailed Contributions}

Our main technical contribution, presented in \sectionref{sec:routing}, is an
algorithm that, using messages of size , constructs, for any
, in  rounds node
labels\footnote{We remark that our use of the term differs from the common
definition in that we distinguish between the auxiliary routing information
stored by the nodes (the tables) and the (preferrably very small) labels
replacing the original node identifiers as routing address.} of size  and routing tables of size
 facilitating routing and distance estimation
with stretch . We show that
assigning new labels to the nodes is unavoidable by proving that any
(randomized) algorithm achieving polylogarithmic (expected) stretch without
relabeling must run for  rounds.
The running time of our algorithm is close to optimal, since known
results~\cite{DHKNPPW-11,Elkin-MST,PelegR-00} imply that computing such an
approximation in the \CONGEST\ model must take 
rounds.



Our algorithm comprises two sub-algorithms that we believe to be of interest in
their own right. One is used for short-range routing (roughly, for the closest
 nodes), the other for longer distances. The short-range algorithm
constructs a hierarchy in the spirit of Thorup-Zwick distance
oracles~\cite{TZ-05}: A recursive structure of uniformly sampled ``landmarks''
is used to iteratively reduce the number of routing destinations (and routes)
that need to be learned, and repeated use of the triangle inequality shows that
the stretch is linear in the number of recursion stages. While this idea is not
new, our main challenge is to implement the algorithm using small messages; to
this end, we introduce a bootstrapping technique that, combined with a
restricted variant of Bellmann-Ford (that bounds the hop range and the number of
tracked sources), allows us to construct low-stretch routing tables for nearby
nodes.


This approach runs out of steam (i.e., exceeds our target complexity)
beyond the closest  
nodes, so at that point we switch to the ``long-distance'' scheme. 
The basic idea in this scheme is to pick roughly  random
nodes we call the \emph{skeleton} nodes, and to
compute all-to-all routing tables for them. This is achieved by simulating the
spanner construction algorithm by Baswana and Sen~\cite{baswana07}.
Again, the crux of the matter is an efficient implementation of this approach
using small messages. To this end, we first construct a spanner of a
graph defined by the skeleton nodes and shortest paths between them. Due to the
small number of skeleton nodes and the reduced number of edges (thanks to the
spanner construction), we can afford to broadcast the entire skeleton-spanner
graph, thereby making skeleton routing information common knowledge. In addition, we
can mark the corresponding paths in the original graph quickly. Here too, our
main low-level tool is the restricted Bellmann-Ford algorithm
that bounds both the range and the load.

Using variants of our techniques, in \sectionref{sec-ext}
we derive efficient
solutions to several 
related problems (all statements hold with high probability).
\begin{compactitem}
\item For the Generalized Steiner Forest (\gsf) problem 
we obtain, for any , an
-approxima\-tion within
 rounds, where  is the number of
terminals. This should be contrasted with the best known distributed approximation
algorithm for \gsf\ \cite{KKMPT}, which provides -approximation in
time , where  is the ``shortest paths diameter,''
namely the maximal number of hops in any shortest path, and  is the number of
terminal components in the \gsf\ instance.
\item For any , we obtain an
  -time algorithm that
  constructs labels of size  and local tables of size
, and produces distance estimations with stretch
. Compare with the recent distributed algorithm \cite{DDP} that
attains the same local space consumption at running time  and stretch .
\item Given any , we can compute an
  -approximation of the diameter within
   rounds. We show that the standard
  construction yielding a lower bound  extends to
  this problem, implying that also for this special case our solution is close
  to optimal.
\item Employing a different routing mechanism for the short-range scheme, we can
assign the fixed labels of . This comes at the expense of a
larger stretch of  within
 rounds, for any .
\end{compactitem}


\subsection{Related Work}






There are many centralized algorithms for constructing routing tables; in these
algorithms the goal is usually to minimize space without affecting the quality
of the routes too badly. We briefly discuss them later, since our focus is the
distributed model. At this point let us just comment that a na\"\i ve
implementation of a centralized algorithm in the \CONGEST\ model requires
 time in the worst case, since the whole network topology has to be
collected at a single node just for computation.

Practical distributed routing table construction algorithms are usually
categorized as either ``distance vector'' or ``link state'' algorithm (see,
e.g., \cite{PetersonD:book}). Distance-vector algorithms are variants of the
Bellman-Ford algorithm \cite{Bellman,Ford-56}, whose worst-case time complexity
in the \CONGEST\ model is . In link-state algorithms
\cite{MQRR80,OSPF}, each routing node collects the complete graph topology and
then solves the single-source shortest path problem locally. This approach has
 time complexity. While none of these algorithms uses relabeling,
it should be noted that the Internet architecture in fact employs relabeling (IP
addresses, which are used instead of physical addresses,  encode some routing
information).

From the theoretical perspective, as mentioned above, there has not been much
progress in computing weighted shortest paths beyond the ``shortest path
diameter'' (we denote by ) even for the single-source case: see, e.g.,
\cite{DDP} and references therein. For the unweighted case, an -time
algorithm for exact all-pairs shortest-paths was recently discovered
(independently) in \cite{HW12} and \cite{PLT-12}. These algorithms do not
relabel the nodes. In addition, a randomized -approximation of  is
given in~\cite{PLT-12}, and a deterministic -approximation is
provided by~\cite{HW12}. Combining results, \cite{HW12} and \cite{PLT-12} report
a randomized -approximation of the unweighted diameter in time
.

In~\cite{DHKNPPW-11}, a lower bound of  on the
time to construct a shortest-paths tree of weight within a poly
of the optimum is shown; this immediately implies the same
lower bound on routing (more precisely, on \emph{stateless} routing,
where routing decisions depend only on the destination and not on the
traversed path). To the best of our knowledge, 
the literature does not state any further explicit lower bounds on the running
time of approximate shortest paths or distance estimation
algorithms, but  a lower bound of
 can be easily derived using the 
technique used in~\cite{DHKNPPW-11} (which in turn is based
on~\cite{PelegR-00}). 
In~\cite{FHW-12} it is shown that in the \CONGEST\ model,
approximating the diameter of unweighted graphs
to within a factor of  requires
 rounds. For the unweighted case, we extend this result
to arbitrary approximation ratios.

In the Generalized Steiner Forest problem (\gsf), the input consists of a
weighted graph and a set of \emph{terminal nodes} which is partitioned into
subsets called \emph{terminal components}. The task is to find a set of edges of
minimum weight so that the terminal components are connected. Historically, the
important special case of a minimum spanning tree (all nodes are terminals,
single terminal component) has been the target of extensive research in
distributed computation. It is known that in the \CONGEST\ model, the time
complexity of computing (or approximating) an MST is
 \cite{DHKNPPW-11,Elkin-MST,PelegR-00}. This bound
is essentially matched by an exact deterministic solution~\cite{GKP93,KP98}. An
-approximate MST is presented in \cite{KP-08}, whose running time
is , where  is the ``shortest path diameter'' mentioned
previously. For the special case of Steiner trees (arbitrary terminals, single
component), \cite{CF05} presents a 2-approximation algorithm whose time
complexity is  (which can easily be refined to ).
For the general case, \cite{KKMPT} presents an -approximation
algorithm whose time complexity is , where 
is the number of terminal components.\footnote{We note that in \cite{KKMPT}, time-optimality is claimed, up
  to factor . This comes as a consequence of~\cite{KP-08},
  which in turn builds on \cite{Elkin-MST}.  However, we comment that the latter
  construction does not scale beyond the familiar lower bound of
  , and a more precise statement would thus be that a
  minimum spanning tree (and thus also a \gsf) requires
   rounds to be approximated.  }


We now turn to a very brief overview of centralized algorithms. Thorup and Zwick \cite{TZ-routing} presented an algorithm that achieves,
for any , routes of stretch  using 
memory. In terms of memory consumption, it has been established that this scheme is optimal up to a constant factor in worst-case stretch w.r.t.\
routing~\cite{PU89}. This result has been extended to the average
stretch, and tightened to be exact up to polylogarithmic factors in memory for
the worst-case stretch~\cite{abraham06}. For distance approximation, the
Thorup-Zwick scheme is known to be optimal for  and conjectured to be
optimal for all  (see~\cite{zwick01} and references). The algorithm
requires relabeling with labels of size .
It is unclear whether stronger lower bounds apply to name-independent routing
schemes (which keep the original node identifiers); however, for ,
i.e., exact routing, trivially  bits suffice (assuming
-bit identifiers), and Abraham et al.~\cite{abraham08}
prove a matching upper 
bound of  bits for .

A closely related concept is that of \emph{sparse spanners}, introduced
by Peleg and Sch\"affer~\cite{PS89}. A -spanner of a graph is obtained by
deleting edges, without increasing the distances by more than
factor . Similarly to compact routing tables, it is known that a -spanner must
have  edges for some values of , this is
conjectured to hold for all , and a matching upper bound is obtained
by the Thorup-Zwick construction~\cite{TZ-05}. If an additive term
in the distance approximation is permitted, the multiplicative factor can be
brought arbitrarily close to ~\cite{EP04}. In contrast to routing and
distance approximation, there are extremely fast distributed algorithms
constructing sparse spanners.
Our long-range construction rests on an elegant
algorithm by Baswana and Sen~\cite{baswana07} that achieves stretch  vs.\  expected edges
within  rounds in the \CONGEST\ model. 








\section{Model}
\label{sec-model}
In this section we define the model of computation and formalize a few
concepts we use.

\subsection{The Computational Model} 
We follow the  model as described in~\cite{Peleg:book}. The 
distributed system is represented by a simple, connected weighted
graph , where  is the set of nodes,  is the set of
edges, and  is the edge weight function.\footnote{We remark
that our results can be easily extended to non-negative edge weights by
employing appropriate symmetry breaking mechanisms.}
As a convention, we use  to denote the number of nodes. We assume that all
edge weights are bounded by some polynomial in , and that each node 
has a unique identifier of  bits (we use  to denote both the
node and its identifier).

Execution proceeds in global synchronous rounds, where
in each round, each node take the following three steps:
\begin{inparaenum}[(1)]
\item Receive messages sent by neighbors at the previous round,
\item perform local computation, and
\item send messages to neighbors.
\end{inparaenum}
Initially, nodes are aware only of their neighbors; input values (if any) are
assumed to be fed by the environment at time . Output values are placed in
special output-registers. In each round, each edge can carry a message of 
bits for some given parameter  of the model; we assume that  throughout this paper.

A basic observation in this model is that we may assume, without loss
of generality, that we have a broadcast facility available, as
formalized in the following lemma.
\begin{lemma}
Suppose each  holds  messages of  bits
each, for a total of  strings. Then all nodes in the
graph can receive these  messages within  rounds.
\end{lemma}
\begin{proof}
Construct a BFS tree rooted at, say, the node  with smallest identifier
( rounds). All nodes send their messages to their parents and
forward the messages received by their children to their parent as well, until
the root holds all messages. Since over no edge more than  messages need to be
communicated, this requires  rounds. Finally all messages are
broadcast over the tree, completing in another  rounds.
\end{proof}
In the following, we will use this lemma implicitly whenever stating that some
information is ``broadcast'' or ``announced to all nodes.''

\subsection{General Concepts}
 We use  extensively ``soft'' asymptotic notation that ignores
 polylogarithmic factors. Formally, we say that  if and only if there exists a constant  such that
 for all but finitely many values of .
Anagolously,  iff , ,  iff for each fixed
 it holds that , and
 iff .

To model probabilistic computation, we assume that each node has
access to an infinite string of independent 
unbiased random bits.  When we say that a certain event occurs ``with high
probability'' (abbreviated ``w.h.p.''), we mean that the probability of the
event not occurring can be set to be less than  for any desired constant
, where the probability is taken over the strings of random bits.


\subsection{Some Graph-Theoretic Concepts} 
A \emph{path}  connecting
 is a sequence of nodes
 such that for
all ,  is an edge in . 
Let  denote  the set of all paths
connecting nodes  and .  We use the following unweighted concepts.
\begin{compactitem}
\item The \emph{hop-length} of a path , denoted
,  is the number of
edges in it.
\item The \emph{hop distance}  is defined as
.
\item The \emph{hop diameter} of a graph  is
.
\end{compactitem}
We use the following weighted concepts.
\begin{compactitem}
\item The \emph{weight} of a path , denoted , is its total
edge weight, i.e., .
\item The \emph{weighted distance} 
is defined by .
\item The \emph{weighted diameter} of  is
.
\end{compactitem}
The following concepts mix weighted and unweighted ones.
\begin{compactitem}
\item Given  and two nodes  with hop
  distance , we define the \emph{-weighted
    distance}  to be the weight of the lightest path
  connecting  and  with at most  hops, i.e.,
  . If , we define .
  (Note that   does not satisfy the
  triangle inequality.)
\item The \emph{shortest paths diameter} of a graph, denoted ,
  is the maximal number of 
    hops in shortest paths:
    .
\end{compactitem}

Finally, given a node  and an integer , we define  to be
the set  of the  nodes that are closest to  (according to , where
identifiers are used to break symmetry): . Note
that our concept of ball differs from the usual one: we define a ball by its
center and \emph{volume}, namely the number of nodes it contains (and not by its
center and radius).

We have the following immediate property.
\begin{lemma}
\label{lem:h}
Let . If  for some 
then  for all
.
\end{lemma}
\begin{proof}
Clearly , and it therefore suffices to
show that . Let  be a
shortest path from  to . Since edge weights are strictly positive, we have
that all the  nodes  are strictly closer than  to .
Hence, since , we have that . It follows that
 and we are done.
\end{proof}




\section{Problem Statement and Lower Bounds}
\label{sec:prel}
\subsection{The Routing Problem}
\label{sec:problem}
In the \emph{routing table construction} problem (abbreviated ), the local
input at a node is the weight of incident edges, and the output at each node 
consists of (i) a unique \emph{label}  and (ii) a function
``'' that takes a destination label  and produces a neighbor
of , such that given the label  of any node , and starting
from any node , we can reach  from  by following the  pointers.
Formally, the requirement is as follows. Given a start node  and a
destination label , let  and define
 for . Then for some  we must have
.

The performance of a solution is measured in terms of its \emph{stretch}: A
route is said to have stretch  if its total weight is no more than
 times the weighted distance between its endpoints, and a solution to
 is said to have stretch  if all the routes it induces have stretch
at most .

\noindent\textbf{Variants.} Routing appears in many incarnations. We list a few
important variants below.

\emph{Name-independent routing.} Our definition of 
allows for node relabeling. This is the case, as
mentioned above, in the Internet. The case where no such relabeling is allowed
(which can be formalized by requiring  to be the
identity function), is called \emph{name-independent} routing.

It can be shown that assigning new labels to the nodes is
unavoidable by proving that any (randomized) algorithm achieving polylogarithmic
(expected) stretch without relabeling must run for  rounds.
Formally, we can prove the following.
\begin{theorem}
In the \CONGEST\ model, any algorithm for  that produces
name-independent stateful routing with expected average stretch 
 requires  time.
\end{theorem}

\emph{Stateful routing.} The routing problem as defined above is
\emph{stateless} in the sense that routing a packet is done regardless of the
path it traversed so far.  One may also consider \emph{stateful} routing, where
while being routed, a packet may gather information that helps it navigate later
(one embodiment of this idea in the Internet routing today is MPLS, where
packets are temporarily piggybacked with extra headers). Note that the set of
routes to a single destination in stateless routing must constitute a tree,
whereas in stateful routing even a single route may contain a cycle. Formally,
in stateful routing the label of the destination may change from one node to
another: The  function outputs both the next hop (a neighbor node), and
a new label  used in the next hop.

\emph{Name-independent routing.} Our definition of  allows for node
relabeling. This is the case, as mentioned above, in the Internet. The case
where no such relabeling is allowed (which can be formalized by requiring
 to be the identity function), is called \emph{name-independent}
routing.

It can be shown that assigning new labels to the nodes is unavoidable by proving
that any (randomized) algorithm achieving polylogarithmic (expected) stretch
without relabeling must run for  rounds. What might come as a
surprise here is that the result also applies to stateful routing.
\begin{theorem}
In the \CONGEST\ model, any algorithm for  that produces
name-independent routing with (expected) average stretch  requires
 time.
\end{theorem}



\subsection{The Distance Approximation Problem}

The \emph{distance approximation} problem is akin to the routing problem. Again,
each node  outputs a label , but now,  needs to construct a
function  (the table) such that for all
 it holds that . The stretch of the
approximation for a given node  is , and the
solution has stretch , if  for
all .

Similarly to routing, we call a scheme name-independent if 
is the identity function. Since we require distances estimates to be
produced without communication, there is no ``stateful'' distance
approximation.

\subsection{Hardness of Name-Independent Distributed Table Construction}
\label{sec:naming}


While name-independence may be desirable, our routing and distance approximation
algorithm makes heavy use of relabeling. This is unavoidable for fast
construction, because, as the following two theorems show, any name-independent
scheme of polylogarithmic stretch requires  rounds for table
construction. The lower bound holds even for stateful routing 
and average stretch. Moreover, since the construction below is generic,
intuitively it implies that there is no reasonable restriction, be it
in terms of topology, edge weights, or node degrees, that permits fast
construction of name-independent routing tables.\footnote{The lower bound graph can be adapted to be a balanced binary
  tree, weakening the lower bound on the stretch by factor .}



\begin{theorem}\label{thm:lower_route_independent}
In the \CONGEST\ model, any name-independent routing scheme of (expected)
average stretch  requires  rounds for table
construction. This holds even if all edge weights are , the graph is a tree
of constant depth, and the node identifiers are .
\end{theorem}
\begin{proof}
We assume w.l.o.g.\ that all set sizes we use in this proof are integer and that
nodes may send no more than exactly  bits over each edge in each
round. Consider the following family of trees of depth . The root is
connected to  inner nodes, each of which has 
children; denote by  and  the respective sets of nodes. All edges have
weight , i.e., the maximal simple path weight is .

We assign the identifiers  uniformly at random to the 
leaves (w.l.o.g., we neglect that the total number of nodes is  in
the following and use  instead). Consider any deterministic algorithm
constructing routing tables within  rounds. From each node in , the
root receives at most  bits, hence there are at most  possible routing tables at the root. Now consider the 
possible partitions of the leaf identifiers to the subtrees rooted at nodes from
. We bound the number of such partitions for which a fixed routing table at
the root may serve a uniformly random routing request with probability at least 
correctly. This requirement translates to at least  identifiers being
exactly in the subtree where the routing table points to; we have
 possible choices for these identifiers. The remaining 
identifiers may be distributed arbitrarily to the remaining subtrees. Depending
on the distribution of the  identifiers we already selected, the number of
possibilities for this may vary. Using standard arguments it can be shown that this quantity is maximized if the  identifiers are
distributed evenly among the subtrees, i.e., each of them contains  of
them. We conclude that no routing table can serve a uniform request with
probability at least  for more than
 of the possible input partitions.
Considering the number possible routing tables and the total number of input
partitions , we have that


We distinguish two cases, the first being . We seek to upper
bound  in the second case as well, where . Clearly the l.h.s.\
of the above inequality is increasing in . Together with Stirling's
approximation  we can bound

The assumption that  thus implies (for sufficiently large )
that .

Now condition on the event that for the given routing request the table
does not lead to the correct subtree. We fix the (uniformly random) subset of
leaf identifiers in the subtree  the root's routing table points to, and
conclude that the set of remaining identifiers is a uniformly random subset of
 leaf identifiers plus the destination's identifier. Moreover, the
destination is uniformly random from this subset and the remaining identifiers
are uniformly distributed among the remaining subtrees. We delete  from the
graph (since clearly there is no reason to route to  again) and examine the
next routing decision of the root. We observe that the situation is identical to
the initial setting except that  is replaced by . Note also that 
contained no valuable information: We deleted  and the identifiers in 
from the graph, and any other information known to nodes in  must have been
communicated to  by the root. Hence, repeating the above arguments, we see
that the probability to find the destination in the second attempt conditioned
on the first having failed is at most  or .
By induction on the number of routing attempts, we infer that for , the probability  to succeed in the  attempt to
route from the root node to the subtree containing the destination (conditional
on the previous attempts having failed) is upper bounded by  unless
.

Overall, the probability that a deterministic algorithm constructing routing
tables within  rounds fails to serve a uniformly random
routing request at the root for uniformly distributed leaf identifiers using
fewer than  attempts (i.e., visits of the root on the routing path) is
lower bounded by


Note that an analogous argument holds for routing requests issued at other
nodes, since they have a large probability to require routing to a different
subtree. Therefore, the average stretch of any deterministic routing
algorithm running for fewer than  rounds is at least
. By Yao's principle, the expected average stretch of randomized
algorithms running for fewer than  rounds thus must also be
in . Recalling that  and , we
get that  rounds are insufficient to achieve
(expected) average stretch , proving the statement of the theorem.
\end{proof}

A streamlined version of  the argument shows that a similar lower
bound applies to distance approximation.

\begin{theorem}\label{thm:lower_dist_independent}
In the \CONGEST\ model, any name-independent distance approximation scheme of
(expected) average stretch  requires  rounds for table
construction in graphs with edge weights of  and 
only. This holds even if the graph is a star and the node identifiers are
.
\end{theorem}
\begin{proof}
Again, we assume w.l.o.g.\ that all considered values are integer and that link
capacity is  bits per round. Suppose  is a star with  leafs (we
neglect w.l.o.g.\ the center in the node count). All edges have weight
 with independent probability ; the remaining edges have
weight .

Condition on the event that some fixed node's  incident edge has weight .
Thus, there are two possible path weights to other nodes:  and
. Within  rounds, the node receives at most  bits, yielding
 possible distance estimate configurations. In order to be
-approximate for  and a given other leaf, 's
table must output an estimate of at most  in case the
leaf's edge has weight  and at least  if the leaf's edge has
weight . Thus any given table can be correct for a given leaf for
only one of the two possible choices of the leaf's edge's weight. There are
 possible edge weight assignments. By the above
observation, a fixed table is -approximate for a given destination with
probability . By Chernoff's bound, this implies that the probability that a
fixed table is correct for a fraction of  of the destinations is bounded by
. By the union bound, it follows that for the given uniformly
random edge weight assignment, the probability that the computed table is
correct for a fraction of  of the destinations is upper bounded by
. This implies that  or the
average stretch of node 's table must be .

By symmetry, the same applies to all nodes incident to an edge of weight . By
Chernoff's bound, w.h.p.\ at least one quarter of the nodes satisfies this
property, i.e., the probability mass of the events where fewer than  edges
have weight  is negligible. By linearity of expectation, it follows that any
deterministic algorithm running for  rounds exhibits average
stretch , and by Yao's principle this extends to the
expected stretch of randomized algorithms.
\end{proof}

Consequently, in the remainder of the paper we shall consider
name-dependent schemes only.


\subsection{Hardness of Diameter Estimation}
\label{sec:lb_diam}

In \cite{FHW-12}, it is shown that approximating the hop-diameter of a
network within a factor smaller than 1.5 cannot be done in the \CONGEST\ model
in  time. Here, we prove a hardness result for the weighted
diameter, formally stated as follows.
\begin{theorem}\label{thm-lb-diam}
For any , there is a function  such that the following holds. In the family of
weighted graphs of hop-diameter  and edge weights  and
 only, an (expected) -approximation of the weighted
diameter requires  communication rounds in the \CONGEST\
model.
\end{theorem}
\begin{figure}[t]
  \centering \includegraphics[width=12cm]{lb5.pdf} \caption{An
    illustration of  the graph
  used in the proof of
    \theoremref{thm-lb-diam}. Thick edges denote edges of weight
    , other edges are of weight . The shaded
    triangle represents a binary tree}
  \label{fig-lb5}
\end{figure}
\begin{proof}[Proof sketch:]
  We construct a graph  with  nodes. Let . The
  graph consists of the following three conceptual parts. \figref{fig-lb5}
  illustrates a part of the construction.
  \begin{compactitem}
  \item Nodes  for . These nodes are connected
    as  paths of length . All path edges are of weight .
  \item A star rooted at an \emph{Alice} node, where the children are
  , and similarly, a star rooted at a \emph{Bob} node,
  whose leaves are . We specify the weights of these
  edges later.
   \item For each  there is a node  connected to all
     nodes ,  in ``column'' , with edges of
     weight . In addition, there is a binary tree whose
     leaves are the nodes . All tree edges have weight . Finally, \emph{Alice}
     and \emph{Bob} are connected to  and , respectively, by edges of weight
     .
  \end{compactitem}
It is easy to see that the hop-diameter of  is :
the hop-distance from any node to one of the nodes  is ,
and the distance between any two such nodes is also .
However, the majority of the short paths guaranteeing the small diameter passes
through very few nodes close to the root of the binary tree. Consequently, it
takes a long time to exchange a large number of bits between \emph{Alice} and \emph{Bob}, implying
that it is hard to decide set disjointness for sets held
by \emph{Alice} and \emph{Bob} in the \CONGEST\ model. Specifically, the following fact is a
direct corollary from \cite{DHKNPPW-11}.
\begin{fact}[\cite{DHKNPPW-11}]
\label{lb-fact}
Let . Suppose that node \emph{Alice}
holds a set  and that node \emph{Bob} holds a set
. Then finding whether  takes
 rounds in the \CONGEST\ model, even for randomized algorithms.  
\end{fact}

We now show that if the diameter of  can be approximated within factor
 in time  in the \CONGEST\ model, then the set
disjointness problem problem can be solved in time . To this end, we set
the edge weights of the stars rooted at \emph{Alice} and \emph{Bob} as follows: for all , the edge from \emph{Alice} to  has weight  if
 and weight  else; likewise, the edge from \emph{Bob} to  has
weight  if  and weight  else.

Note that given  at \emph{Alice} and  at \emph{Bob}, we can inform the nodes 
and  of these weights in one round. Now run any algorithm that outputs
a value between  and 
(for a suitable constant ) within  rounds, and output `` and  are
disjoint'' if the outcome is at most  and output `` and 
are not disjoint'' othwerwise.

It remains to show that the outcome of this computation is correct for any
inputs  and  and the statement of the theorem will follow from
\factref{lb-fact} (recall that the number of nodes of  is ).
Suppose first that . Then for each node , there is a
path of at most  edges of weight  connecting it to \emph{Alice} or
\emph{Bob}, and \emph{Alice} and \emph{Bob} are connected to all nodes in the
binary tree and each other via  hops in the binary tree (whose
edges have weight  as well). Hence the weighted diameter of  is
 in this case and the output is correct (where we assume
that  is sufficiently large to account for the  term). Now
suppose that . In this case each path from node  to
\emph{Bob} contains an edge of weight , since the edges from
\emph{Alice} to  and \emph{Bob} to  as well as those
connecting  to  have weight . Hence, the weighted
distance from  to \emph{Bob} is strictly larger than 
and the output is correct as well. This shows that set disjointness is decided
correctly and therefore the proof is complete.
\end{proof}


\subsection{Hardness of Name-Dependent Distributed Table Construction}
\label{sec:lb}

A lower bound on name-dependent distance approximation follows directly from
\theoremref{thm-lb-diam}.
\begin{corollary}\label{coro-lb2}
For any , there is a function  such that the following holds. In the family of
weighted graphs of hop-diameter  and edge weights 
and  only, constructing labels of size  and
tables for distance approximation of (expected) stretch  requires
 communication rounds in the \CONGEST\ model.
\end{corollary}
\begin{proof}
We use the same construction as in the previous proof, however, now we need to
solve the disjointness problem using the tables and lables. Using the same
setup, we run the assumed table and label construction algorithm. Afterwards, we
transmit, e.g., the label of \emph{Alice} to all nodes . This takes
 rounds due to the size restriction of the labels. Then we
query the estimated distance to \emph{Alice} at the nodes  and collect
the results at \emph{Alice}. Analogously to the proof of \theoremref{thm-lb-diam},
the maximum of these values is large if and only if the input satisfies that
. Since transmitting the label costs only
 additional rounds, the same asymptotic lower bound as in
\theoremref{thm-lb-diam} follows.
\end{proof}

A variation of the theme shows that stateless routing requires
 time.

\begin{corollary}\label{coro-lb}
For any , there is a function  such that the following holds. In the family of
weighted graphs of hop-diameter  and edge weights 
and  only, constructing stateless routing
tables of (expected) stretch  with labels of size
 requires  communication rounds in
the \CONGEST\ model.
\end{corollary}
\begin{proof}[Proof sketch:] We consider the same graph as in the proof of
\theoremref{thm-lb-diam} and input sets  and  at \emph{Alice} and
\emph{Bob}, respectively, but we use a different assignment of edge weights.
\begin{compactitem}
  \item All edges incident to a node in the binary tree have weight
  .
  \item For each , the edge from \emph{Alice} to 
  has weight  if  and weight  else. Likewise, the edge
  from \emph{Bob} to  has weight  if  and
  otherwise weight .
  \item The remaining edges (on the  paths from  to ) have
  weight .
\end{compactitem}
Observe that the distance from \emph{Alice} to \emph{Bob} is  if
 and strictly larger than  if . Once static routing tables for routing on paths of stretch at most
 are set up, e.g.\ \emph{Bob} can decide whether 
and  are disjoint as follows. \emph{Bob} sends its label to \emph{Alice} via
the binary tree (which takes time  if the label has size
). \emph{Alice} responds with ``'' if the first
routing hop from \emph{Alice} to \emph{Bob} is node  and  (i.e., the weight of the edge is ), and ``'' else (this
takes  rounds). \emph{Bob} then outputs ``''
if \emph{Alice} responded with ``'' and  (i.e., the weight of the
routing path is  since the edge from \emph{Bob} to  has
weight ) and ``'' otherwise.

If the output is ``'', it is correct because . On the other hand, if it is ``'', the route from
\emph{Alice} to \emph{Bob} must contain an edge of weight ,
implying by the stretch guarantee that there is no path of weight 
from \emph{Alice} to \emph{Bob}. This in turn entails that 
due to the assignment of weights and we conclude that the output is correct also
in this case. Hence the statement of the corollary follows from
\factref{lb-fact}.
\end{proof}
We remark that \theoremref{thm:lower_dist_independent},
\theoremref{thm-lb-diam}, \corollaryref{coro-lb2}, and \corollaryref{coro-lb}
have in common that if edge weight  is permitted, no stretch bound faster
than the stated lower bounds even if the only other feasible edge weight is .

Finally, we note that the hop-diameter is also an obvious lower
bound on the time required to approximate the weighted diameter,
construct stateless routing tables, etc. since if the running time is smaller
than , distant parts of the graph (in the sense of hop-distance) cannot
influence the local output.

\section{Routing Algorithm}
\label{sec:routing}

\textbf{Overview.} To construct routing tables, one needs to learn about paths.
Na\"\i ve distributed algorithms explore paths sequentially, adding one edge at
a time, leading to potentially linear complexity, since shortest weighted paths
may be very long in terms of the number of edges. Our basic idea is to break
hop-wise long paths into small pieces by means of random sampling. Specifically,
motivated by the  lower bound of
\theoremref{thm-lb-diam}, we select a random subset of
 nodes we call the routing \emph{skeleton}. It follows
that, w.h.p., (1)~any simple path of hop-length 
contains a skeleton node, and (2)~any node has a skeleton node among its closest
 nodes. The route that our scheme will select from a given
source to a given destination depends on their distance: If the destination is
one of the  nodes closest to the destination, routing will
be done using a ``short range scheme'' (see below); otherwise, the short range
scheme is used to route from the source to the nearest skeleton node, from
which, using another scheme we call ``long distance routing,'' we route to the
skeleton node closest to the destination node, and finally, another application
of the short range scheme brings us to the destination. Intuitively, we can
split the problem into the following tasks:
\begin{compactenum}
\item Short range scheme: how to route efficiently from each node to its
 closest nodes including at least one
skeleton node, and, conversely, from a
skeleton node to all its ``subordinates'' (note the asymmetry in this case).
\item Skeleton routing scheme: how to route between skeleton nodes
efficiently.
\end{compactenum}

The short range scheme is described in \sectionref{sec:short}. We note that
since a straightforward application of multiple-source shortest paths may result
in linear time,  we develop a hierarchical structure to solve the short-range
routing. This hierarchy bears resemblance to the Thorup-Zwick distance oracle
algorithm \cite{TZ-05}. Our long distance routing is described in 
\sectionref{sec:skeleton}. The main challenge there is to build the skeleton
graph; since it might be too dense, we sparsify it ``on the fly'' while
constructing it. This construction is implemented by adapting the spanner
algorithm of Baswana and Sen \cite{baswana07} to our setting.

We start by describing the variant of the Bellman-Ford algorithm we use as a
basic building block in \sectionref{sec:bsp}.


\subsection{Bounded Shortest Paths}
\label{sec:bsp}


\begin{algorithm}[tb!]
\small
\SetKwInOut{Input}{input}
\SetKwInOut{Output}{computes}
\Input{
   \REM{range parameter: hop bound on path lengths, globally known}\\
   \REM{overlap parameter: number of closest sources each node needs to
  detect, globally known}\\
   \REM{each 
  knows ;  means  is not a
  source}\\
}
\Output{For all : -weighted distance and the next hop
from  to each of the closest  source node sets using paths of
  at most  edges (or all such sets, if there are at most  within 
  hops).
}
\lIf {\nllabel{bsp:init}}
  {}
\lElse
  { \nllabel{bsp:init2} \REM{initialization}}\\
\For { \KwTo \nllabel{bsp:iter}}{
  send  to all neighbors; \nllabel{bsp:repeat}\\
  \ForEach {neighbor }{
    receive \\
    \ForEach(\REM{Bellman-Ford relaxation}) {}{
      \If { s.t.\ }{
        \lIf {} {
          \REM{comparisons are lexicographical}\\
          
        }
      }
      \lElse {}
    }
  }
  truncate  to smallest  entries 
  \REM{order is lexicographical}\nllabel{bsp:truncate}
}
\Return 
\caption{: Bounded shortest paths, computed at node
.}\label{alg:bsp}
\end{algorithm}

We now describe a basic subroutine we use. Algorithm
, whose pseudo code is given in \algref{alg:bsp}, is
essentially a standard multiple-source distributed Bellman-Ford
algorithm, with two restrictions: first, the algorithm is run for
only  rounds (cf.\ \lineref{bsp:iter}); and second, nodes never
report more than  sources (cf.\
\lineref{bsp:truncate}).

We consider a slightly extended variant of the algorithm: In the original
algorithm, each node is a ``source'' and the goal is to compute the distances of
all nodes to it. Here we assume that (i) not all nodes are sources, and (ii)
sets of nodes may act as a single source, as if there were 0-weight edges
connecting them. Both extensions are modeled by the  function,
that maps a node to  if it is not a source, or multiple nodes to the same
source ID if they are in the same source set. We use  to denote the
set of \emph{sources}, i.e.,  , and for each ,
the \emph{source nodes} of  is . Note that the
source function uniquely determines the source sets and vice versa. We assume
that a source ID can be encoded using  bits.

We analyze the algorithm leveraging the correctness of the basic Bellman-Ford
algorithm. To this end, let us define \algref{alg:bsp}* by omitting
\lineref{bsp:truncate} from \algref{alg:bsp} and fixing . Observing that
\algref{alg:bsp}* is exactly the distributed Bellman-Ford algorithm, we may
conclude the following standard property.

\begin{lemma}\label{lem:bf}
Fix an execution of \algref{alg:bsp}*. Denote by  for some  and  the contents of the  variable at node  after 
iterations of \algref{alg:bsp}*. Then for each  entry in 
we have that  is a source and , namely  is the length of the shortest path that
consists of at most  edges from  to any node  in the source set of .
Moreover,  is the next node on that shortest path from  to .
\end{lemma}

\lemmaref{lem:bf} says that running only  iterations is sufficient if we
are interested in paths of  or less edges only. We now consider the effect of
repeatedly truncating the distance vector.

\begin{lemma}\label{lem:bsp_trunc}
Consider executions of \algref{alg:bsp} and of \algref{alg:bsp}* on the same
graph and with the same  function. Let  and
 denote the contents of the  variable at node  after 
iterations under \algref{alg:bsp} and under \algref{alg:bsp}*, respectively.
Then  contains exactly the smallest  entries of  with
respect to lexicographical ordering (or the entire list, if ).
\end{lemma}
\begin{proof}
By induction on . The base case is , and the lemma clearly holds upon
initialization (\lineref{bsp:init}). For the induction step, assume that the
lemma holds for  at all nodes, and consider iteration
 at some node . By the induction hypothesis, we have that the message
received by  from each neighbor  at time  under \algref{alg:bsp} is
exactly the top  entries sent by node  at time  under
\algref{alg:bsp}*, because these entries are computed at the end of iteration
. The lemma therefore follows from the fact that for any , the
smallest  entries of a union of sets are contained in the union of the
smallest  entries from each set.
\end{proof}

Note that the information provided by  is insufficient for routing:
since the  closest source node sets may differ between neighbors, it
may be the case that for some source identifier  and two neighbors  and
 we have that  is the next node from  to  in , but there is
no entry for source  in ! This occurs, for example, if in  iteration
,  learns about a source set closer than , pushing  out of
. However, since the algorithm returns  instead of
simply , we can still reconstruct the detected paths.
\begin{lemma}\label{lemma:bsp_route_stateful}
For any node  and any entry , a routing path of at
most  hops from  to a node in  of weight  can be constructed using
the  tables at the nodes and a hop counter.
\end{lemma}
\begin{proof}
The routing decision for hop  at the current node  (where )
is made by looking up the entry . We show by
induction on the length  of a shortest path from  to its closest
node  that such an entry always exists. Note that by
Lemmas~\ref{lem:bf} and~\ref{lem:bsp_trunc}, such an entry satisfies that
 and thus the constructed path has weight
. Trivially, the claim is true for  by initialization of
the lists , .

Now suppose the claim holds for  and consider node  with entry
. Suppose  is the neighbor of  which is next
on the shortest -hop path from  to . Hence it is the endpoint of a
of a shortest -hop path from  to , and there is no shorter path
from  to any node in  of at most  hops (otherwise there would
be a shorter path of at most  hops from  to a node in ).
Therefore, by \lemmaref{lem:bf},  for
some . Assuming for contradiction that
 implied, by
\lemmaref{lem:bsp_trunc}, that there are  entries  that are lexicographically smaller than .
Node  would send these smaller entries in iteration  of \algref{alg:bsp},
yielding the contradiction that . It follows
that indeed  and the proof concludes.
\end{proof}

We summarize the properties of \algref{alg:bsp} with the following
theorem. 
\begin{theorem}\label{thm:bsp}
\algref{alg:bsp} computes the -weighted distance and next hop of a shortest
path of at most  edges from each node to its closest  source sets.
Each node on the corresponding shortest path can determine the next hop on the
path out of the number of preceding hops and the output of the algorithm.
The time complexity of \algref{alg:bsp} in the \CONGEST\ model is  rounds.
\end{theorem}
\begin{proof}
Correctness follows from Lemmas \ref{lem:bf} and \ref{lem:bsp_trunc}.
\lemmaref{lemma:bsp_route_stateful} proves that the paths can be reconstructed
as stated. The time complexity follows from the fact that the algorithm runs for
 iterations, and each iteration can be implemented  in  rounds
in the \CONGEST\ model since the messages contain  IDs and
distances.
\end{proof}

\emph{Stateless routing.} 
The routing mechanism suggested by \lemmaref{lemma:bsp_route_stateful} has the
disadvantage that it is stateful, as the routing decision depends on the number
of previous routing hops. It is easy to make it stateless: at each
node, a packet is directed toward the hop that reported the best
distance estimate, i.e., the next hop to take at node  for
destination  is .
\begin{corollary}\label{coro:bsp_route_stateless}
For any node  and any entry , a routing path of at
from  to a node in  of weight  can be constructed using the local
knowledge of the nodes only.
\end{corollary}
\begin{proof}
\lemmaref{lemma:bsp_route_stateful} shows that if a node  follows the
 pointer of \emph{any} entry  for \emph{any}
, node  has an entry
. We thus can simply choose to
follow at each node  the  pointer of entry  with minimal  and are guaranteed to
eventually arrive at some node in  using a path of weight at most .
\end{proof}
Note that in general we cannot guarantee that the constructed path has at most
 hops when applying this mechanism; this holds true, however,  if we
are routing to one of the  nodes closest to the source of the
routing request (by \lemmaref{lem:h}). This observation will be crucial for
making our general routing scheme stateless.

\subsection{The Short-Range Scheme}
\label{sec:short}

With Algorithm  at hand, we can now describe our short-range routing
scheme. Our goal is to allow each node to find a route to each of its closest
 neighbors. A na\"\i ve application of Algorithm ,
where all nodes are sources, would set the overlap parameter to
 (this is the number of nodes we want to know about),
and the range parameter to  too (in order to find the
closest  nodes it suffices to go to this hop-distance,
cf.\ \lemmaref{lem:h}). However, \theoremref{thm:bsp} tells us that in this
case, the time complexity would be , a far cry
from the  lower bound from Corollaries \ref{coro-lb2} and
\ref{coro-lb}. Our solution is a hierarchical bootstrapping process that
converges in double-exponential speed. We show that the stretch is proportional
to the number of stages in the hierarchy.


\subsubsection*{The Construction}
The construction is done iteratively in  stages. In the interest of clarity
we describe the construction intuitively first and then formalize it. The idea
is that on the one hand we want to spend
at most a certain amount of time, but on the other hand with each stage try to
reduce the number of landmarks as quickly as possible. This approach is
the spirit of Thorup-Zwick distance oracles and routing
schemes~\cite{TZ-routing,TZ-05}, and it is also used in a distributed
fashion in~\cite{DDP}. The difficulty lies in constructing such a
hierarchy quickly.\footnote{In \cite{DDP}, distance sketches are constructed
  distributedly using exhaustive search with
  respect to distances, i.e., Bellmann-Ford is run for
  sufficiently many iterations until all routes become stable. This
  approach has time complexity  and therefore cannot guarantee a
  running time of  on all graphs of diameter .
}

\begin{wrapfigure}{r}{2.2in}
\centering
\includegraphics[width=1.8in]{triangle}
\caption{\small The distance from  to  is at least one third
of the length of the route from  to  via .}
\label{fig:tri}
\end{wrapfigure}
The sets of landmarks, denoted , are sampled uniformly
and independently 
at random without any coordination overhead, with , and 
 for .
In the  stage, each node finds
a route to the closest node in  as well as
to all nodes in  that are closer to it.
This property allows us to bound the routing stretch. The basic argument is a simple
application of the triangle inequality (see \figref{fig:tri}): Consider a route  from node
 to node . If there is a node  that is closer to  than
, then the route of shortest paths via  has stretch at most .
It is therefore sufficient for 
to determine (the next hop of) least-weight routes to nodes in
 that are closer to it than the closest node in 
only. Using double induction, we can bound the stretch of the
multi-stage application of this technique we employ.

To this end, in each stage we invoke \algref{alg:bsp} with source set
. We now explain how to choose the parameters  and
 for this invocation. Let  be the probability of 
a node to be selected into . Then w.h.p., each node  has a member of
 among the  nodes closest to . Hence, this is a good
choice for the distance parameter . The expected number of nodes from
 among the   nodes closest to a given node is .
Applying Chernoff's bound shows that this number is bounded by
 w.h.p. This is an upper bound on
the number of sources that need to be detected by each node and therefore is our
choice of the overlap parameter .

The resulting running time of the call to Algorithm  is
. Since this is the
dominating term in the running time in each stage, it is now easy to determine
the sampling probabilities: neglecting polylogarithmic factors, we get the
simple recursion , where  is the desired running time
and . For example, if we want to ensure a running time bound of
, we obtain: 
\begin{compactitem}
\item sampling probabilities of , i.e.,
;
\item expected set sizes of
, i.e.,  w.h.p.;
\item range parameters of , i.e., ;
\item overlap parameters of , i.e., .
\end{compactitem}
(Note that  stages suffice to ensure that  w.h.p.) Running Algorithm  with parameters as above, we
get that w.h.p., after  time, each node knows of the closest
 nodes from  and how to route to them for
all . But this is not sufficient: we also need to be able to route
back from the nodes in .

Given a node , define  to be the node closest to  in 
(symmetry broken by identifiers), and let , i.e., for each stage , the sets  are a Voronoi
decomposition of  with centers .
Note that routing from  to  is not as simple as thee other
direction: While the depth of the tree rooted at  is bounded by
, there is no non-trivial upper bound on the number of nodes in the tree.
This can be solved by a number of standard techniques for tree routing (e.g.,
\cite{SK}). To minimize space consumption, we use the technique of
\cite{TZ-routing}, which constructs routing tables of size  and
node labels of  bits in  time.
In a nutshell, the idea is first to count the sizes of subtrees (which can be
done in  rounds) and then construct ``mini routing tables'' for the
``heavy'' part of the tree, where a node is considered heavy if its subtree
contains at least  nodes. Then this process
is applied recursively in the subtrees rooted at children of heavy
nodes. From the description in~\cite{TZ-routing}, one can verify that each
recursive step of the construction can be performed in time  in
a tree of depth  in the  model. There are at most
 recursive steps, summing up to a total of
 rounds to construct labels and routing tables.

Formally, given natural numbers  and , we define the
following for .
\begin{compactitem}
\item  , and .
\item For each node ,  is  the node from  closest to
 (ties broken by hop distance and ID).
\item   For each , define
, and .
\item For each node , define .
\end{compactitem}
Our construction maintains (w.h.p.)\ the following
properties at stage .\vspace*{1ex}

\newlength{\fparwidth}\addtolength{\fparwidth}{\textwidth}\addtolength{\fparwidth}{-13pt}
\noindent\fbox{\begin{minipage}{\fparwidth}
\begin{compactenum}[(1)]
\item\label{prop-prob}  is a uniformly random subset of , 
where  and .
\item \label{prop-y}
For any node , it it is possible to route from  to 
on a least-weight path.
\item \label{prop-f}
For any node , it is possible to compute  and
 from the label of .
\item \label{prop-c}
For any node , it is possible to route from  to any node  on a least-weight path. 
\item\label{prop-h}
For any node ,   is locally known at , and it is
possible to route
from  to any node  on a least-weight path (whose weight is known
at ).
\end{compactenum}
\end{minipage}
}
\medskip

Suppose that we have such a hierarchy of  stages. Then, given the label of
any node , node  can
route a message to  as follows: First, find some  such that  for some 
(cf.\ \pprtyref{prop-f} and \pprtyref{prop-h} of the construction). The route
from  to  is then defined by the concatenation of two shortest paths:
the one from  to , and the one from  to  (cf.\ \pprtyref{prop-c} and
\pprtyref{prop-h}). Moreover, the long-range scheme will make sure that we can
always route to any destination via the closest skeleton nodes in , which
is feasible due to \pprtyref{prop-y} and \pprtyref{prop-c}. By always choosing
from the available routes such that the weight of the computed route is minimal
(which can be done by \pprtyref{prop-f} and \pprtyref{prop-h} for the
short-range construction, and will also be possible for the long-range scheme),
routing becomes stateless.

\subsubsection*{Stretch Analysis}

We now bound the weight of the routes constructed by the stated scheme with
respect to the weight of the shortest paths. We note that the argument for the
general case is similar in spirit to the simple case of  illustrated
in \figref{fig:tri}. We start with the following key lemma.
\begin{lemma}
\label{lem-sep}
Suppose that for  and  we have that
. Then (a)
, and (b) .
\end{lemma}
\begin{proof}
We prove the lemma by induction on , for a fixed .
More specifically, we show for each  that (a)  and (b) . For the basis of the
induction, consider  in Statement (b). In this case, since , we
have that,  and Statement (b) holds because .

For the inductive step, assume that Statement (b) holds for  and
consider . Since trivially , the premise of the
lemma implies that . However, , and hence we obtain
\begin{eqntext}
\Wd(v,\Lead_v(i+1))&\leq&\Wd(v,\Lead_w(i))\\
&\leq& \Wd(v,w)+\Wd(w,\Lead_w(i))& \text{triangle inequality}\\
&\leq& (2i+1)\Wd(v,w)& \text{by induction hypothesis}
\end{eqntext}
This proves part (a) of the claim. Using the above inequality we also
obtain
\begin{eqntext}
\Wd(w,\Lead_w(i+1))
&\leq&\Wd(w,\Lead_v(i+1))& \text{
for }\\
&\leq &\Wd(w,v)+\Wd(v,\Lead_v(i+1))& \text{triangle inequality}\\
&\leq &(2i+2)\Wd(v,w)& \text{by the proof of part (a)},
\end{eqntext}
which proves part (b) of the claim, completing the inductive step.
\end{proof}
\lemmaref{lem-sep} allows us to prove the following positive result.
\begin{corollary}
\label{cor-short}
Let , and let  be minimal such that
.
Then .
\end{corollary}
\begin{proof}
Note that
\begin{eqntext}
\Wd(v,\Lead_w(i_0-1))+\Wd(\Lead_w(i_0-1),w)
&\le& \Wd(v,w)+2\Wd(w,\Lead_w(i_0-1)) & \text{triangle inequality}\\
&\le& \Wd(v,w)+4(i_0-1)\Wd(v,w)& \text{\lemmaref{lem-sep}}\\
&=& (4i_0-3)\Wd(v,w)
\end{eqntext}
and the corollary is proved.
\end{proof}
On the other hand, if there is no  as in the corollary, we can conclude
from \lemmaref{lem-sep} that routing via the skeleton nodes closest to source
and destination, respectively, incurs bounded stretch.

\subsubsection*{Implementation and Time Complexity}
We now explain how to construct the hierarchy efficiently in more detail, and
analyze the time complexity of the construction. \algref{algo:close} gives the
pseudocode of the above scheme. The algorithm is parametrized by the total
number of nodes  and the number  of hierarchy stages. Appropriate
constants  and  are supposed to be predefined in accordance with the required lower bound
on the probability of success.\footnote{One can verify the properties of the construction and restart a
  failed iteration within  time if desired, implying that
  the stretch guarantee becomes deterministic and the running time
  probabilistically bounded instead.
}

\begin{algorithm}[ht!]
\small
\SetKwInOut{Input}{input}
\SetKwInOut{Output}{computes}
\Input{ \REM{number of nodes}\\
 \REM{number of stages in the hierarchy}}
\Output{ \REM{level of ; }\\
\REM{closest node in }\\
\\
 \REM{next
routing hop ( if ) and distance to }
}
\lFor{}{\\}
\nllabel{line:set}\\
\For{}{
   \REM{ and  are predefined constants
  controlling the probability of failure}\\
  \\
  \lIf{}{} \lElse{}\\
   \REM{only 
  needed}\\
  \\
  \Repeat{}{
    let  be the next entry in  in ascending
    lexicographic order\\
    \\
    ;  \REM{exact shortest paths, no distinction of
    stages needed}
  }
  
  \REM{ is the node from  closest to }\\
  construct labels of stage 
}
\caption{Distributed construction of data structure for close-distance
  routing at .
}
\label{algo:close}
\end{algorithm}

Choosing the sets  is performed locally without communication. Each node
 has level  chosen independently so that 
(\lineref{line:set}). Setting  as indicated in
the algorithm thus satisfies \pprtyref{prop-prob}. In addition, the following
properties are easily derived using the Chernoff bound, and we state them
without proof.

\begin{lemma}\label{lem-short-corr1-general}
For appropriate choices of the constants ,  in
\algref{algo:close}, for all  it holds w.h.p.\ that:
\begin{compactitem}
\item  .
\item For all , .
\item For all , .
\item For all , .
\item For all , .
\end{compactitem}
\end{lemma}

By these properties and \theoremref{thm:bsp}, \pprtyref{prop-h} is satisfied
w.h.p., because we invoke Algorithm  with sources , depth parameter
, and overlap parameter : after this invocation, each node 
can identify the set  and route to any  on a path of known
weight; since  w.h.p., these routing paths are
shortest paths. Moreover, the invocation of  allows each
node  also to learn what is  and route to it on a shortest path
of known weight, establishing \pprtyref{prop-y}. In order to satisfy
\pprtyref{prop-f}, we simply add  and
 to the label of  for all . As
discussed earlier, routing tables of size  and labels of
size  to route within  can be constructed within
 rounds using the scheme from~\cite{TZ-routing}, and we add the
respective tree label to 's label to ensure \pprtyref{prop-c}.

We can therefore summarize the complexity of the construction as follows.
\begin{lemma}
\label{lem-short-perf}
Given , constructing the -stages short-range routing
tables and labels can be done in  rounds, and the total label size of a
node is .
\end{lemma}
\begin{proof}
The implementation of stage  involves invoking  with
parameters  and , which, by 
\theoremref{thm:bsp}, takes 

rounds. In addition, we need to relabel the nodes, which, as explained above,
can be done in time , since the
depth of the shortest paths tree is bounded by . Since
there are  stages, the total number of rounds thus satisfies
the stated bounds. With respect to the label size, note that each stage  adds
to the label of node  the identifier of and distance to  and a
tree label of size , for a total of  bits per
stage.
\end{proof}

\subsection{Long-Distance Routing}
\label{sec:skeleton}

We now explain how to route between the nodes in the top level of the
hierarchy created by the short-range scheme. Our central
concept is the \emph{skeleton graph},  defined as follows.

\begin{definition}[Skeleton Graph]
Let  be a weighted graph. Given  and , the
\emph{-hop skeleton- graph} is the weighted graph
 defined by
\begin{compactitem}
\item 
\item For , define  to be the
-weighted distance between  and  in , i.e.,
.
\end{compactitem}
\end{definition}

The main idea in the long-distance scheme is to construct a skeleton
graph with  (the top level of the short-range hierarchy as constructed in
\sectionref{sec:short}). The choice of  needs to balance two goals: on the one hand, the skeleton graph needs to accurately reflect the
distances of skeleton nodes in , and on the other hand, we must be able to
quickly set up a tables that allow routing of small stretch between the skeleton
nodes.

A simple but crucial observation on skeleton graphs is that if the skeleton 
is a random set of nodes, and if , then w.h.p., the
distances in  are equal to the corresponding distances in . This
means that it suffices to consider paths of  hops in  in
order to find the exact distances in . The following lemma formalizes this
idea. (We state it for a skeleton \emph{containing} a random subset;
this generality will become useful in \sectionref{sec:steiner}.)

\begin{lemma}\label{lemma:distances}
Let  be a set of random nodes defined
by  independently for all nodes for some given
.
Let .
If   for a sufficiently large
constant , then w.h.p.,  for all .
\end{lemma}
\begin{proof}
Fix . Clearly,  because each
path in  corresponds to a path of the same weight in . We
need to show that  as well. Let
 be a shortest path
connecting  and  in , i.e., .
We show, by induction on , that 
w.h.p.

For the basis of the induction note that if , then by definition
 and we are done. For the inductive step,
assume that the claim holds for all values of  for some 
and consider a path of length . Now, , and hence,
applying Chernoff's bound, we may conclude that w.h.p.\ the intersection is
non-empty. Let . Since  is a shortest path in
, so are  and . Both these paths are of length at
most , implying by the induction hypothesis that 
and  w.h.p., respectively. Therefore
, completing the induction. Note that the total
number of events we consider throughout the induction is bounded by a
polynomial in , and since the probability of the bad events is polynomially
small, the union bound allows us to deduce that the claim holds w.h.p.
\end{proof}


Based on this observation, an obvious strategy to solve
long-distance routing is  to construct  and 
compute its all-pairs shortest paths. But implementing this approach is not
straightforward. First, the edges of the skeleton graph are virtual: each
edge represents the shortest path of up to  hops in ; and
second, the number of skeleton graph edges may be as large as
. We solve both problems together: While computing the edges of
the skeleton graph, we sparsify the graph, bringing the number of edges
down to near-linear in the skeleton size. Once we are done, we can afford to let  
each skeleton node learn the full topology of the sparsified skeleton
graph, from which approximate all-pairs routes and distances can be computed
locally.

Technically, we use  the classical concept of sparse spanners, defined
as follows.

\begin{definition}[Weighted -Spanners]
Let  be a weighted graph and let . A weighted -spanner of
 is a weighted graph  where ,
 for all , and  for
all  (where  and  denote weighted distances in 
and , respectively).
\end{definition}
We shall compute a spanner of the skeleton graph, while running
on the underlying physical graph, without ever
constructing the skeleton graph explicitly. We do this by
simulating the spanner construction algorithm of Baswana and
Sen~\cite{baswana07} on the implicit skeleton graph. Let us recall the
algorithm of~\cite{baswana07}; we use a slightly simpler variant that may select
some additional edges, albeit without affecting the probabilistic upper bound on
the number of spanner edges (cf.~\lemmaref{lem-reduce}). The input is a graph
 and a parameter .
\vspace*{1ex}\hrule
\begin{compactenum}
\item Initially, each node is a singleton \emph{cluster}:
.
\item Repeat  times (the  iteration is called ``phase ''):
\begin{compactenum}
\item Each cluster from  is \emph{marked} independently
with probability .  is defined to be the set of
clusters marked in phase .
\item \label{bs-first} If  is a node in an unmarked cluster:
\begin{compactenum}
\item Define  to be the set of edges that consists of the lightest edge
from  to each of the clusters  is adjacent to.
\item If  has no adjacent marked cluster, then  adds to the
spanner all edges in .
\item Otherwise, let  be the closest neighbor of  in a
marked cluster. In this case  adds to the spanner the edge
, and also all edges  with 
(i.e., the identifiers  break symmetry in case .
Furthermore  \emph{joins} the cluster of  (i.e., if  is in cluster ,
then ).
\end{compactenum}
\end{compactenum}
\item \label{bs-final}
Each node  adds, for each cluster  it is adjacent to, the lightest
edge connecting it to .
\end{compactenum}\smallskip
\hrule\medskip
For this algorithm, Baswana and Sen prove the following result.
\begin{theorem}[\cite{baswana07}]
\label{thm-bs}
Given a weighted graph  and an integer , the
algorithm above computes a -spanner of the graph. It has
 edges w.h.p.\footnote{In \cite{baswana07}, it is proved that the expected number of edges is
. The modified bound directly follows from
\lemmaref{lem-reduce}.}
\end{theorem}

\subsubsection*{Constructing the Skeleton Graph}

In our case, each edge considered in Steps \eqref{bs-first} and \eqref{bs-final}
of the spanner algorithm corresponds to a shortest path. Essentially, we
implement these steps in our setting by letting each skeleton node find its
closest  clusters (w.h.p.)\ by running Algorithm .
We now explain how. First, all nodes  in a cluster  use the same source
identifier  (as if they were connected by a -weight
edge to a virtual node ). This ensures that the overlap parameter needs to
account for the number of detected \emph{clusters} only, i.e., the number of
nodes per cluster is immaterial. Note that this implies that the plain version
of Algorithm  thus will not permit to determine to which node a skeleton
edge connects; hence we append to each communicated triple  the
identifier of the actual endpoint  of the respective path and store
it when adding a corresponding triple to  (without otherwise affecting the
algorithm). We refer to the modified algorithm as . Second, regarding the
range parameter, \lemmaref{lemma:distances} shows that it is sufficient to
consider paths of  hops only. Finally, the following lemma
implies that we may modify the spanner construction algorithm in a way that
allows us to use a small overlap parameter.

\begin{lemma}\label{lem-reduce}
  W.h.p., the execution of the centralized spanner construction
  algorithm yields identical results if in Steps~(\ref{bs-first})
  and~(\ref{bs-final}), each node considers the lightest edges to the
   closest clusters only (for a sufficiently large
  constant ).
\end{lemma}
\begin{proof}
Fix a node  and a phase . If  has at most 
adjacent clusters, the lemma is trivially true. So suppose that  has more
than  adjacent clusters. By the specification of
Step~(\ref{bs-first}), we are interested only in the clusters closer than the
closest marked cluster. Now, the probability that none of the closest
 clusters is marked is . In other words, choosing a sufficiently large constant
, we are guaranteed that w.h.p., at least one of the closest
 clusters is marked. Regarding Step~(\ref{bs-final}),
observe that a cluster gets marked in all of the first  iterations with
independent probability . By Chernoff's bound, the probability
that more than  clusters remain in the last iteration is
thus bounded by . Therefore, w.h.p.\ no
node is adjacent to more than  clusters in
Step~(\ref{bs-final}), and we are done.
\end{proof}
As a consequence of \lemmaref{lem-reduce}, we may invoke Algorithm  with
, and the time complexity of the invocation is
. Detailed pseudo-code of our implementation
is given in \algref{algo:skeleton}. Each skeleton node  records the ID
of its cluster in phase  as ; nodes in  or those who do
not join a cluster in some round  have . \algref{algo:edges} is
used as subroutine to implement Steps \eqref{bs-first} or \eqref{bs-final}
(Lines \ref{sk-first} or \ref{sk-final} of \algref{algo:skeleton},
respectively).


\begin{algorithm}[t!]
\small
\SetKwInOut{Input}{input}
\SetKwInOut{Output}{output}
\Input{
  : set of skeleton nodes\\
  : integer in \REM{determines approximation
  ratio and number of spanner edges}
}
\Output{
  : spanner edges of skeleton graph
  \REM{ is defined in  \lineref{spanner-h}}\\
   \REM{weights of spanner edges}
}
\REM{initial clusters are singletons of }\\
\nllabel{st-bcast}
Broadcast  to all nodes\\
\lForEach{}{\lIf{}{~}\lElse{}}
\REM{initializing leaders}\\
\REM{the constant  controls the probability of
failure}
\label{spanner-h}\\
\\
\For{ \emph{\KwTo} }{
   uniformly random subset of  of size
   \REM{select marked clusters}\nllabel{st-rand}\\
  Broadcast  to all nodes\nllabel{st-bcast2}\\
  
  \REM{select spanner edges, phase }\nllabel{sk-first}\\
  \ForEach{\nllabel{st-comp1}}{
    \If{}{
      
    }
    \Else{
      Let  be the edges incident to  in \\
      \If{}{
        Let  be the heaviest edge in \\
        \lIf{}{}
      }
      \lElse{\nllabel{st-comp2}}
    }
    Broadcast  to all nodes\nllabel{st-bcast3}
  }
}
 \REM{final phase}
\nllabel{sk-final}\\
\lForEach{} {}\\
Broadcast  and  to all
nodes\nllabel{sk-bcast}
\caption{Construction of long range routing skeleton at .}
\label{algo:skeleton}
\end{algorithm}


\begin{algorithm}[ht!]
\small
\SetKwInOut{Input}{input}
\SetKwInOut{Output}{output}
\Input{
   \REM{locally known, 's leader if  is in a
  cluster, otherwise }\\
   \REM{globally known, indicates (identifiers of leaders of)
  marked clusters}\\
   \REM{globally known, depth parameter of the search}\\
   \REM{globally known, number of closest source clusters to detect}
}
\Output{
  : edges added to the spanner\\
   edge weights
}
\ForEach{}{
  
}
\REM{variant of Algorithm  that keeps track
of path endpoints}\nllabel{ed-bsp}\\
\\
\If{}{
  //\textit{for each entry ,  is the next hop on a
  path of weight  to  in cluster }\\
  
  \REM{remove loops (clusters are in distance  of themselves)}\\
  //\textit{recall that  is ordered; first entry with
   corresponds to closest marked cluster}\\
  \ForEach{}{
    broadcast  \REM{all nodes perform
      operation!}\nllabel{ed-bcast}\\
     \nllabel{line:add}\\
    \\
    \If{}{
      break \REM{ is closest marked cluster}\nllabel{add-edges-end}
    }
  }
}
\Return
\caption{: Edge detection and announcement for long
  range routing skeleton at .}\label{algo:edges}
\end{algorithm}

To prove the algorithm correct, we show that its executions can be mapped to
executions of the centralized algorithm, and then apply \theoremref{thm-bs}.
Below, we sketch the main points of such a mapping. The implementation of
\algref{algo:skeleton} is quite straightforward. Note that the broadcast steps
in Line \ref{st-bcast}, \ref{st-bcast2}, and \ref{st-bcast3} ensure that all
nodes know the clusters and which are the active clusters in each phase. The
random choices (\lineref{st-rand}) are made by cluster leaders, namely the nodes
 for which . Lines \ref{st-comp1}--\ref{st-comp2} are local
computations each node does to get a global picture of the clusters
for the next phase. The correctness of the implementation of the edge selection
of Steps \ref{bs-first} and \ref{bs-final} of the centralized algorithm by 
\algref{algo:edges} was discussed above. We summarize with the following lemma.

\begin{lemma}\label{lemma:spanner}
Suppose the set  input to \algref{algo:skeleton} contains a uniformly random
subset  of  and set  for a
sufficiently large constant . Then w.h.p.\ the following holds.
\begin{compactitem}
\item[(i)] \algref{algo:skeleton} computes a weighted -spanner of
the skeleton graph  that is known at all nodes and has
 edges.
\item[(ii)] The weighted distances between nodes in  are identical in
 and .
\item[(iii)] The algorithm terminates in
 rounds.
\end{compactitem}
\end{lemma}
\begin{proof}
To prove Statement (i), we note that \algref{algo:skeleton} simulates
the centralized algorithm, except for considering only the closest
 clusters in Lines \ref{sk-first} and
\ref{sk-final}. By \lemmaref{lem-reduce} and by \theoremref{thm:bsp},
this results in a (simulated) correct execution of the centralized algorithm
w.h.p. Hence Statement (i) follows from \theoremref{thm-bs}.

Regarding Statement (ii), observe that if , the statement holds by
definition since shortest paths cannot contain cycles and thus
. Otherwise, we have that ,
implying by Chernoff's bound that w.h.p., the probability to select a node into
 is . As by assumption 
is sufficiently large, Statement (ii) now follows from
\lemmaref{lemma:distances}.

For Statement (iii), consider first an invocation of \algref{algo:edges}. By
\theoremref{thm:bsp}, the invocation of \algref{alg:bsp} in \lineref{ed-bsp}
takes  rounds.
The broadcast of \lineref{ed-bcast} is done globally. Each skeleton node may
communicate up to  pieces of information for a total of
 items. Doing this over a global BFS tree
takes  rounds. As , the total cost
of all invocations of \algref{algo:edges} is thus bounded by
 rounds. Consider now
\algref{algo:skeleton}. The only non-local steps other than the invocations of
\algref{algo:edges} are the broadcasts, of which the most time consuming is the
one in \lineref{sk-bcast}, which takes  rounds.
\end{proof}



\subsubsection*{Routing on the Skeleton Graph}

\algref{algo:skeleton} constructs a -spanner of the skeleton graph and
made it known to all nodes. This enables each node to determine low-stretch
routing paths between any two skeleton nodes in  by local
computation. To use this information, we must be able, for each spanner edge
, to route on a corresponding path in , i.e., a path
of weight . Since we rely on Algorithm~ during the
construction of the spanner, \theoremref{thm:bsp} shows that we can use the
computation to enable for each such edge to route from  to  \emph{or} from
 to : if, say,  added the edge to the spanner, then following the
pointers computed during the execution of Algorithm~ yields a path of
weight  from  to . However, in this case   might not
add  to the spanner as well, and hence there is no guarantee that we
have sufficient information to route in \emph{both} directions.\footnote{Note
that unidirectionality is not an artifact of the specific implementation we
picked. E.g., in a star graph, the center has degree , as it does in the
spanner. Hence we cannot expect the Bellmann-Ford pointers to give sufficient
information for bidirectional routing without further processing.} To resolve
this issue, we add a post-processing step where we ``reverse'' the
unidirectional routing paths, i.e., inform the nodes on the paths about their
predecessors. Note that this cannot be done in a purely local manner, as
exchanging the Bellmann-Ford routing pointers between neighbors will not tell a
node  which pointer to follow to reach a specific node  for
which  is part of the spanner. However, \corollaryref{thm:bsp} states
that the (unidirectional) routing paths at our disposal have at most 
hops. Taking into account that the spanner has few edges, it follows that
establishing bidirectional routing pointers can be performed sufficiently fast.

\begin{lemma}\label{lemma:spanner_routing}
Let  be an edge of the spanner  that is selected by
\algref{algo:skeleton}.  W.h.p., after completing the algorithm, 
each node 
on the least-weight -- path of at most  hops in   determine
the next hop on this path and the weight of the remaining subpath when routing
from  to  within  rounds
\end{lemma}
\begin{proof}
For each edge  added to the spanner by a node , we route a message
on the shortest path of at most  hops from  to  in . This
message initially contains the weight of the path, and each node on the path
subtracts the weight of the incoming path from this value. By
\theoremref{thm:bsp} this is feasible. When a node receives the message, it
records the immediate sender as the next hop on the path to  and the weight
for future reference. By \lemmaref{lemma:spanner}, there are at most
 edges in the constructed spanner of 
w.h.p., implying that the maximal number of messages routed over each edge of
 is bounded by  w.h.p.\ as well. Moreover, no
routing path has more than  hops. Since the
messages traverse shortest -hop paths, all of them reach their destinations
within the stated number of rounds~\cite{MP-91}.
\end{proof}

We now summarize the properties of the long-distance scheme. 
\begin{theorem}\label{theorem:spanner}
Suppose the set  input to \algref{algo:skeleton} is a superset of a
uniformly random subset  and . Then, w.h.p., 
within  rounds, there are
routing tables for routing between nodes in  with stretch .
\end{theorem}
\begin{proof}
Directly follows from Lemmas~\ref{lemma:spanner}
and~\ref{lemma:spanner_routing}.
\end{proof}


\subsection{Putting the Pieces Together}
\label{sec-tog}
Equipped with the results for the short-range and for the
long-distance routing, we can state the overall algorithm as a simple
composition of the two, linked by identifying the skeleton set from
the long-distance algorithm with the top level of the hierarchy 
of the short-range algorithm.  We run the long-range algorithm with
parameter  to construct and make globally known the routing
skeleton and apply the short-range routing scheme with parameter 
to deal with nearby nodes.

Recall that the label of a node  is
,
where  denotes the label of  in the tree on
, and  is simply . Given the label 
to a node ,  decides on the next routing hop as follows.
\begin{compactitem}
  \item If  for some , choose the next routing hop
  within  to  according to the respective tree label. In this
  case,  is the distance from  to  in the tree (which can be computed
  from the distances of  and  to the root  and whether the
  next routing hop is the parent of  or a child).  
  \item Otherwise, node  determines for each  whether . If so, it computes . Otherwise set .
  \item Next, denote by  the set of skeleton nodes  for
  which it stores a routing pointer and the corresponding path weight, and let
  for   be this weight. We define  to be the distance
  function on the spanner of the skeleton graph. Node  computes
  .
  \item Finally,  computes , and
  determines the next routing hop in accordance with the corresponding path (ties
  broken by preferring smaller ), where we use the
  routing mechanism from \corollaryref{coro:bsp_route_stateless}.
\end{compactitem}
Since  stores the tree routing tables for all trees on ,
the sets  and the distances to the nodes in , and
the complete spanner of the skeleton graph, together with the label 
it has the necessary information to perform all the above computations. Moreover, a next
routing hop is always determined, since  (by
\pprtyref{prop-y} of the short-range scheme) and therefore the set of
considered paths in the second step is non-empty. Finally, the routing decision
is stateless, since it depends on the local routing tables of  and
 only.

In order to show that indeed a route to  of bounded stretch is determined by
the above routing decisions, we will show two properties. First, the value 
computed is the weight of a path of bounded stretch whose next routing hop 
is exactly the one computed by , and second, the next node  on the path
will compute a distance of at most  to . Since edge weights
are strictly positive, the latter immediately implies that the routes are
acyclic and will eventually reach their destination.
\begin{lemma}\label{lemma:d}
Fix any choice of the parameters  and  of the short range and long
distance schemes, respectively. For any node  and label ,
consider the distance value  and next routing hop  computed by 
according to the above scheme. Then w.h.p.,  and 
will compute a value .
\end{lemma}
\begin{proof}
We show that  first. If  for some , observe that , and thus by \corollaryref{cor-short}
. Otherwise, we have that  since no other
routes are known to . By definition and \pprtyref{prop-y} of the
short-range scheme, .
We bound
\begin{eqntext}
&&\Wd(v,\Lead_L(v))+\Wd^k(\Lead_v(L),\Lead_w(L))+\Wd(\Lead_L(w),w)&\\
&\le&\Wd(v,\Lead_L(v))+(2k-1)\Wd(\Lead_L(v),\Lead_L(w))+\Wd(\Lead_L(w),w)
& \text{by \theoremref{theorem:spanner}}\\
&\le& 2k\Wd(\Lead_L(v),v)+(2k-1)\Wd(v,w))+2k\Wd(w,\Lead_L(w)) & \text{triangle
inequality}\\
&\le& (2k(4L-1)+(2k-1))\Wd(v,w) &\text{\lemmaref{lem-sep}} \\
&=& (8kL-1) \Wd(v,w),
\end{eqntext}
proving that indeed .

Now let  be the routing hop corresponding to  computed by . Due to
\pprtyref{prop-c} and \pprtyref{prop-h} of the short-range scheme, there are the
following three cases:
\begin{compactitem}
  \item  is on the shortest path from  to  for
  some  (this covers also the case that
  , and in the tree on  the
  connecting path traverses the root );
  \item  is on a path of weight  to the node  minimizing
  the expression ;
  \item  is on the shortest path from  to  for some  (i.e., , and in the tree on
   the connecting path does not traverse the root
  ).
\end{compactitem}
Regarding the first case, observe that since we are talking about shortest paths
in  (not shortest -hop paths), any source closer to  than
 will also be closer to  than . Hence
. Since
, consequently 
will compute a distance of at most  to .

In the second case,  is either the next hop on a routing path as
constructed in \corollaryref{coro:bsp_route_stateless} or as constructed by the
``path reversal'' from \lemmaref{lemma:spanner_routing}. Either way, the
statements show that  will know the next routing hop to  as well as
the weight of the path. Since it knows the entire skeleton graph, it will thus
compute a distance of at most
 to  as claimed.

For the third and final case, the statement trivially holds, since routing in
 according to the tree routing table is on shortest paths and
will clearly lead to another node in .
\end{proof}

It is fairly straightforward to set  and  to obtain a trade-off between 
the stretch of the routing scheme and the construction time. Specifically, we
can now state our main result as follows.
\begin{theorem}\label{thm-routing}
Let  be given. Define  if
, and  otherwise. Tables for stateless
routing and distance approximation with stretch
 and label size  can
be constructed in the \CONGEST\ model in  rounds.
In particular,  and  for any constant choice of .
\end{theorem}
\begin{proof}
A stretch bound of  and the fact that the destination will indeed be
reached when following the computed pointers follows from \lemmaref{lemma:d}.
By \lemmaref{lem-short-perf}, the running time of the short-range construction
is bounded by  rounds w.h.p. The time
required for the skeleton construction is, by \theoremref{theorem:spanner},
 w.h.p. To match the desired running time
bound of  rounds, it thus suffices that
 (an additive  in
the exponent maps to a constant factor). By choice of ,
this inequality holds for . The stretch
is thus bounded by


The bound on the label size follows from \lemmaref{lem-short-perf}, our
choice of , and the fact that the long-distance scheme adds only  bits to the label.
\end{proof}

The space complexity of our scheme, i.e., the number of bits of the computed
routing tables, is also straightforward to bound.

\begin{corollary}\label{coro:space}
The size of the routing table at node  computed by the algorithm referenced
in \theoremref{thm-routing} is .
\end{corollary}
\begin{proof}
Observe that the dominant terms in memory consumption are (i) storing the sets
 and the next pointers to them for the short-range routing scheme, (ii)
storing the routing information for the paths from the roots  of the
trees induced by the sets , and (iii) storing  and the
next pointers for the long-range scheme. Trivially, the encoding of
 cannot require more than  memory, as
it is broadcasted globally over the BFS tree. The routing information from
 to the nodes in its tree is  bits~\cite{TZ-routing}. The
term from (i) originates from calls to Algorithm . The routing information
that needs to be stored consists of the history of the list maintained by
Algorithm . Hence, if such a call has depth and overlap parameters  and
, the memory required is . Hence the memory bound
for (i) directly follows from the running time bound from
\lemmaref{lem-short-perf}.
\end{proof}

\section{Extensions and Applications}
\label{sec-ext}

\subsection{Distance Sketches}

The problem of distributed distance sketches requires each node to
have a label and store a small amount of information (called the
\emph{sketch}), so that each node  can estimate the distance to
each other node  when given the label of .\footnote{The formulation in \cite{DDP} permits to use \emph{both} sketches to
  approximate the distance. However, from the distributed point of
  view it is more appropriate to assume that only a minimal amount of
  information is exchanged.}
Technically speaking, we already solved this problem, since our machinery
enables to estimate distances with small stretch. However, since , the basic construction will always consume 
memory.

If we discard the routing information, we can reduce the space requirements of
the sketches at the expense of also increasing the stretch. To this end, we need
to reduce the maximal size of the sets  as well as the space consumed
for storing information on the skeleton graph. Our idea is as follows.
First, we change the sampling probabilities of the sets  so that , where  ranges from  to . With this choice, the
expected number of nodes from  that are closer to a given node than the
closest node from  is , implying that
 for all . Second, we do not choose
 as skeleton set, but rather  for , so that the
skeleton can be constructed quickly. To continue applying the short-range scheme
beyond stage  without increasing the asymptotic time complexity of the
construction, we construct temporary distance sketches and labels for the
skeleton (using the long-range scheme with skeleton set ), which
allows nodes to estimate their distance to skeleton nodes locally. Ensuring that
the  are subsets of the skeleton for , each node thus can
simulate the short-range algorithm's detection of the sets  and the
respective distance computation locally, based on its estimated distance to
skeleton nodes; the price we pay is increasing the stretch by factor 
due to imprecise distances.

\begin{theorem}\label{theorem:sketches_small}
Given any integer , distance sketches with
stretch , label size ,
and sketch size  can be constructed w.h.p.\ in
the \CONGEST\ model in  rounds.
\end{theorem}
\begin{proof}
We use the following  algorithm, parametrized by .
\begin{compactenum}
\item Run the short-range with  stages and expected set sizes
 for .
\item Run the long-range scheme on the skeleton .
\item For ,  sample set , where each node
is picked uniformly with probability  in each step. Each node in
 broadcasts its membership information.
\item For each pair  and , set
. For , compute at each node  the closest node 
w.r.t.\ , and the set . Set .
\item Store at each node , for each : (i) the set
  ; (ii) for 
each , the value  if , or  if
. Label node  by , where  if , and
 otherwise. \end{compactenum}
Given label  (which is clearly of size ), node 
estimates the distance to  by finding the smallest  so
that  and adding the respective distance estimates from
 to  (locally known) and from  to  (from the
label). Such an  always exists because . This
completes the description of the algorithm.

By \corollaryref{cor-short}, the stretch of the routes represented by the
labels and sketches would be  w.h.p.\ if all distances were
exact. The approximation ratio is obtained by multiplying this value by the
maximal stretch of any distance estimates employed in the construction. Up to
stage , all values are exact w.h.p. Thereafter, we use estimates of distances
between skeleton nodes and all other nodes. By the triangle
inequality, we have for all  and  that

On the other hand,
\begin{eqntext}
\Wd(v,\Lead_v(i_0))+\Wd^k(\Lead_v(i_0),s)&\leq & \Wd(v,s)+\Wd^k(\Lead_v(i_0),s)
& \text{by definition of } \Lead_v(i_0)\\
&\leq & 2k\cdot\Wd(\Lead_v(i_0),s) & \text{by \theoremref{theorem:spanner}}.
\end{eqntext}
Hence the stretch of the distance estimates is bounded by .

By Chernoff's bound, for all  we have that 
w.h.p. Hence, the non-local part of the construction can be performed with
overlap parameter  and distance parameter
 for all . We conclude the
claimed running time and memory bounds of  (time
 for each step of the short-range scheme, time
 for the long-range scheme, and
time  for the additional broadcast step) and
, respectively, completing the proof.
\end{proof}

We note that a distributed implementation of Thorup-Zwick distance
oracles with stretch  and  running time  was recently given by Das Sarma et al.~\cite{DDP}.
Intuitively, the reason for the discrepancy is that in \cite{DDP},
there is no use of the skeleton graph. In general, our running time and
the one from~\cite{DDP} are incomparable (one may run both algorithms in
parallel and use the output of the one that terminates first).

\subsection{Approximate Weighted Diameter}

Obtaining an approximation of the weighted diameter is simpler than constructing
distance sketches. Dropping the short-range scheme from the construction, we can
prove the following result.
\begin{theorem}\label{thm-diameter}
For any , the weighted diameter  can be approximated w.h.p.\ to
within a factor of  in the \CONGEST\ model in
 rounds.
\end{theorem}
\begin{proof}
We use the following streamlined version of our algorithm. 
\begin{compactenum}
\item Select a uniformly random skeleton  where
   independently for all .
\item \label{stD-1} Apply \algref{algo:skeleton} to construct a
  -spanner of . Let  be the weighted
  diameter of the spanner of  (which can be computed
  locally).
\item \label{stD-2} Apply Algorithm , where
  all nodes in  function as the same source:  for all
   and  for all .
Use  and  .
\item \label{stD-3} Find the maximal distance  computed by
  any node and output .
\end{compactenum}
Regarding the time complexity, note that Step \ref{stD-1} requires
 rounds by
\theoremref{theorem:spanner},
Step \ref{stD-2} requires  time by
\theoremref{thm:bsp}, and Step \ref{stD-3} takes  rounds. 

Regarding  the approximation ratio,  consider any , and let
 the nodes in  closest to  and ,
respectively. Then

and hence . 
On the other hand, we have 

where the last inequality holds w.h.p.\ by
\theoremref{theorem:spanner}. 
\end{proof}


\subsection{Distributed Approximation for Generalized Steiner Forest}
\label{sec:steiner}

In this section we explain how to utilize our routing scheme to obtain
a fast distributed algorithm for the Generalized Steiner Forest
problem (\gsf), defined as follows.

\begin{quote}\textbf{Generalized Steiner Forest} (\gsf')\\
  \textbf{Input:} A weighted graph , a set of \emph{terminals}
  , and for each terminal  a component number .\\
  \textbf{Output:} A subset of the edges  such that for all pairs
   with , we have that  is connected to 
  in the graph   .\\
  \textbf{Goal:} Minimize .
\end{quote}
We note that sometimes, the connectivity requirement  is expressed
as a set of node pairs. While the size of the input representation may differ,
the two variants are equivalent for our purposes; using our spanner
construction, we can obtain the component-based description within
 rounds from the pair-based formulation.

In the distributed setting, we assume that each node knows whether it is a
terminal, and if so, what is its component number. Clearly, we can establish
global knowledge on  and the component numbers within time  by
broadcasting the respective pairs of values over a BFS tree. 

We now present a solution to \gsf. We start with a generic reduction to a
centralized algorithm which abstracts away the underlying graph ,
and uses a graph whose nodes are just the terminals and edge weights
are inter-terminal distance estimates.

\begin{algorithm}[ht!]
\small
\SetKwInOut{Input}{input}
\SetKwInOut{Output}{output}
\Input{
  terminal components \REM{locally known:  knows whether  and if
  so, its component number}\\
}
\Output{
  : edges in the Steiner forest
}
Obtain distance estimates for all distances  with
  .\label{gsf-1}\\
Simulate  on the graph  and the same terminal components,
  where , and for all , 
   and 
  denotes the estimate of  computed at  (given the label of
  ). Denote by  the computed solution.\label{gsf-2}\\
Identify and output all edges on paths in  that correspond to edges in .
\label{gsf-3}
\caption{Distributed algorithm for \gsf.  is any centralized
approximation algorithm for \gsf'.}\label{algo:gsf}
\end{algorithm}
To analyze \algref{algo:gsf}, we consider two simple transformations of
the input instance and state their effect on the cost of the solution.
First, consider the effect of using just distances between terminals (and not
the whole graph). The following lemma bounds the effect of this 
simplification. Given an instance  for \gsf, we use  to denote
any fixed optimal solution for .
\begin{lemma}\label{lem-terminals-only}
Let  be an instance of \gsf.
Define an instance
, where  with
 
and . Then .
\end{lemma}
\begin{proof}
The proof is a generalization of the standard argument for Steiner
trees \cite{TM-80}.
Let . Let  be the connected
components of . By optimality of , the  components are trees.
Fix a component , and consider an Euler tour of
its tree. Let  be the sequence of
nodes visited by the tour. Since each edge in  is visited
exactly twice in , we have that the total weight of edges in
the tour is . Define the node
sequence  obtained from 
by omitting the second occurrences of
nodes from . Consider now the set of edges
 in . Since the edges in 
are shortest paths in , clearly the weight of  is not more than
the total weight of edges in , namely .
Finally, note that
 is a feasible solution for , and
therefore

\end{proof}
Next, consider replacing edge weights by -approximate weights.
\begin{lemma}\label{lem-gsf-appx}
Let  and
 be instances of \gsf\
differing only in the edge weights as follows: for all ,
 for some . Then .
\end{lemma}
\begin{proof}
.
\end{proof}

The preceding two lemmas show that using -approximate distances and a
centralized -approxima\-tion algorithm for , we will obtain a
distributed -approximation algorithm for .

It remains to show how to efficiently implement \algref{algo:gsf} in the
\CONGEST\ model. The key is Step \ref{gsf-1}: Steps \ref{gsf-2} and
\ref{gsf-3} will be performed locally at each node.
\begin{corollary}\label{coro:gsf_impl}
For any integer , \algref{algo:gsf} can be
executed in the \CONGEST\ model in
 rounds with stretch factor 
.
\end{corollary}
\begin{proof}
We apply the long-range routing scheme with skeleton set , where
 is sampled uniformly and independently at random with probability
 from . \lemmaref{lemma:spanner} implies that we can perform
Step~\ref{gsf-1} of \algref{algo:gsf} within
 rounds with stretch .
Moreover, at the end of this step, all nodes know the spanner of the skeleton
graph and can therefore locally compute . As remarked earlier, all nodes can
learn the terminal components within  rounds. With this information in place,
all nodes can locally simulate  on  and thus perform Step~\ref{gsf-2}
of the algorithm. According to \lemmaref{lemma:spanner_routing}, the nodes on
paths in  corresponding to edges in  can learn of their membership within
 rounds as well. Afterwards,
Step~\ref{gsf-3} of the algorithm can be completed locally as well. Summing up
the running time bounds for the individual steps, we conclude that the overall
time complexity is  as claimed.
\end{proof}

Altogether, we arrive at the following result.
\begin{theorem}
Given any integer  and any centralized -approximation
algorithm to \gsf, \gsf\ can be solved in the \CONGEST\ model with approximation
ratio  in  rounds, where 
denotes the set of terminal nodes.
\end{theorem}
\begin{proof}
\corollaryref{coro:gsf_impl} proves that \algref{algo:gsf} can be implemented in
 rounds, with distance estimates of
stretch .
The approximation guarantee therefore follows from
Lemmas~\ref{lem-terminals-only} 
and~\ref{lem-gsf-appx}.
\end{proof}

We note that one can implement Step \ref{gsf-1} also by computing distance
sketches as in \theoremref{thm-routing} without including the entire terminal
set into the skeleton (i.e.,  does not become global knowledge), and
simulate  sequentially, taking  per step. This will reduce the
overall running time in case  and  times the step
complexity of  (in terms of the number of globally synchronized steps) is
small compared to . However, this approach has two drawbacks. 
First,  cannot be arbitrary, but must admit to be simulated via a BFS tree
using small messages. Second, the approximation ratio deteriorates according to
the number of stages of the short-range scheme, as the number of stages
contributes as a multiplicative factor .

\noindent\textbf{Discussion.} It is known that the special case of MST, where
all nodes are terminals in a single component has worst-case running time of
 even if the hop-diameter is 
\cite{PelegR-00}. However, it is unclear whether this lower bound holds if the
number of terminals is small, and in turn, whether a larger number of terminal
components makes the problem harder. For instance, for a single pair of
terminals the problem reduces to selecting a single approximate shortest path;
we are not aware of any non-trivial lower bound on this problem. Khan et
al.~\cite{KKMPT} provide a -approximation to GSF within
 rounds, where  denotes the number of
terminal components. The algorithm from~\cite{KKMPT} matches this bound up to factor
 if ; our approach does
so in case , where  is the number of terminal nodes. Note
that the two running time bounds in general are incomparable: for approximation
ratio , we achieve time complexity ;
there are instances for which  as well as those
where . However, our approach is superior in
that we can, for any integer , ensure an approximation ratio of
 at the expense of a slightly larger running time of
 rounds. The authors of~\cite{KKMPT} employ
probabilistic tree embeddings, a technique for which an approximation ratio of
 is inherent \cite{FRK}.

\subsection{Tight Labels}

The presented routing scheme relabels the nodes according to the Voronoi
partition on each level. This yields suboptimal size of labels and makes it
impossible for nodes to learn all labels  quickly. We now
present a modification of our routing scheme with labels
, trading in a larger stretch.

Instead of labeling the nodes on each level of the hierarchy independently, we
do this by an inductive construction.
\begin{compactenum}
\item Define the partial order  on  given by  if (and only
if) one of the following is true:
\begin{compactitem}
\item  and the identifier of  is smaller than the identifier of
.
\item , , and  precedes  in a
fixed DFS enumeration of the tree  on
 induced by the shortest -hop paths from
each  to  detected by the
invocation of Algorithm~ in stage .
\end{compactitem}
\item \label{label-2} Set  for all . For
each level , aggregate the sums of the values
 of nodes  in subtrees of
 at the roots of these subtrees. We define for all 
the value

which can be computed from the received values. For each level , this
operation can be performed within  rounds.
\item Each skeleton node  announces  to all
other nodes. This requires  rounds using a BFS tree.
\item Each skeleton node  sets 

\item Starting from level  and proceeding inductively on decreasing , for
each , each node , and each node , we inform  of the value

Note that this step can be performed in  rounds once  is
known due to the information collected in Step~\ref{label-2}.
\end{compactenum}
From the above arguments and the results from \sectionref{sec:short} we can
immediately conclude that the time complexity of computing these labels is
negligible.
\begin{corollary}\label{coro:label_time}
Executing the above construction does not increase the asymptotic time
complexity of setting up the routing tables.
\end{corollary}

By construction, . Note that at the end of the above
construction, each node  knows  and, for each level  and each
of its children in , it knows the range of labels associated
with this child. For each , set  and define inductively for
 that . Given any label
, we can thus route from any node  to  as follows.
\begin{compactenum}
\item Set .
\item If  and , then route to , set
, and repeat this step. If  and , route to
 and proceed to the next step. If , route to  using the
long-range scheme and proceed to the next step.
\item If , then route to , set , and repeat this step.
Otherwise  and we are done.
\end{compactenum}
The constructed sequence of routing indirections is thus
, where either  is the minimal
level such that  or . As a result of these
indirections, we cannot give a bound on the stretch that is linear in the
number of levels anymore. However, we still can argue that  assuming that .
\begin{lemma}\label{lem-stretch-unique}
Suppose that for the labeling scheme stated above we have for some integer
 that  for all integers .
Then

\end{lemma}
\begin{proof}
We show by induction that  for all , which is obviously true for . Analogously to \lemmaref{lem-sep} we
have that  and . By the triangle inequality,

This completes the induction and in addition reveals that

Therefore

concluding the proof.
\end{proof}
As by \corollaryref{coro:label_time} the construction time of the routing scheme 
is not affected by the above labeling and routing mechanism and
\lemmaref{lem-stretch-unique} provides a stretch bound of  for
the modified short-range routes, we obtain the following statement.
\begin{theorem}\label{theorem:routing-unique}
Given , let  if
 and  otherwise. Tables for
stateless routing and distance approximation with stretch  with node labels  can
be constructed in the \CONGEST\ model in  rounds.
\end{theorem}

\section*{Acknowledgements}
We would like to thank David Peleg for valuable discussions.

\bibliographystyle{abbrv}
\bibliography{distance}

\end{document}