

\begin{table}[b!]
\newcommand{\myitem}{\ \ $\cdot$ }
\centering
\begin{tabular*}{\linewidth}{@{}l@{\extracolsep{\fill}}l@{}l@{}r@{}}
\toprule
& \multicolumn{3}{@{}c}{Running time} \\
\cmidrule{2-4}
Problem & This work & Prior work & \\
\midrule
matrix multiplication (semiring) & $O(n^{1/3})$ & --- & \\
matrix multiplication (ring) & $O(n^{0.158})$ & $O(n^{0.373})$ & \cite{drucker13} \\
\midrule
triangle counting & $O(n^{0.158})$ & $O(n^{1/3}/\log n)$ & \cite{tritri} \\
4-cycle detection & $O(1)$ & $O(n^{1/2}/\log n)$ & \cite{tritri} \\
4-cycle counting & $O(n^{0.158})$ & $O(n^{1/2}/\log n)$ & \cite{tritri} \\
$k$-cycle detection & $2^{O(k)} n^{0.158}$ & $O(n^{1-2/k} / \log n)$ & \cite{tritri} \\
girth & $O(n^{0.158})$ & --- & \\
\midrule
weighted, directed APSP & $O(n^{1/3} \log n)$ & --- & \\
\myitem weighted diameter $U$ & $O(Un^{0.158})$ & --- & \\
\myitem $(1+o(1))$-approximation & $O(n^{0.158})$ & --- & \\
\myitem $(2+o(1))$-approximation & & $\tilde{O}(n^{1/2})$ & \cite{nanongkai14} \\
\midrule
unweighted, undirected APSP & $O(n^{0.158})$ & --- & \\
\myitem $(2+o(1))$-approximation & & $\tilde{O}(n^{1/2})$ & \cite{nanongkai14} \\
\bottomrule
\end{tabular*}
\caption{Our results versus prior work, for the currently best known bound $\omega < 2.3729$~\cite{legall2014powers}; $\tilde O$ notation hides polylogarithmic factors.}\label{tab:results}
\end{table}

\section{Introduction}\label{sec:intro}
Algebraic methods have become a recurrent tool in centralised algorithmics, employing a wide range of techniques (e.g.,\ \cite{Bjorklund14,
BjorklundH14,
BjorklundHKK07,
BjorklundHK09,
BjorklundKK13,
BjorklundKK14,
BodlaenderCKN13,
CyganKN13,
CyganNPPRW11,
CzumajL07,
EisenbrandG04,
FominLRSR12,
FominLS14,
Koutis08,
KowalukLL11,
LokshtanovN10,
nevsetvril1985complexity,
Williams09,
vassilevska2013finding}). In this paper, we bring techniques from the algebraic toolbox to the aid of distributed computing, by leveraging fast matrix multiplication in the \emph{congested clique} model.

In the congested clique model, the $n$ nodes of a graph $G$ communicate by exchanging messages of $O(\log{n})$ size in a \emph{fully-connected} synchronous network; initially, each node is aware of its neighbours in $G$. In comparison with the traditional CONGEST model \cite{peleg00}, the key difference is that a pair of nodes can communicate directly even if they are not adjacent in graph~$G$. The congested clique model masks away the effect of \emph{distances} on the computation and focuses on the limited \emph{bandwidth}. As such, it has been recently gaining increasing attention~\cite{PemmarajuS14_MST_logloglogn,tritri,drucker13,lenzen2013optimal,lotker05,nanongkai14, LenzenW11,patt-shamir11,hegeman14,HegemanP14}, in an attempt to understand the relative computational power of distributed computing models.

The key insight of this paper is that matrix multiplication algorithms from parallel computing can be adapted to obtain an $O(n^{1-2/\omega})$ round matrix multiplication algorithm in the congested clique, where $\omega < 2.3728639$ is the matrix multiplication exponent~\cite{legall2014powers}. Combining this with well-known centralised techniques allows us to use fast matrix multiplication to solve various combinatorial problems, immediately giving $O(n^{0.158})$-time algorithms in the congested clique for many classical graph problems. Indeed, while most of the techniques we use in this work are known beforehand, their combination gives significant improvements over the best previously known upper bounds. Table~\ref{tab:results} contains a summary of our results, which we overview in more details in what follows.

\subsection{Matrix Multiplication on a Congested Clique}

As a basic primitive, we consider the computation of the product $P = ST$ of two $n \times n$ matrices $S$ and $T$ on a congested clique of $n$ nodes. We will tacitly assume that the matrices are initially distributed so that node $v$ has row $v$ of both $S$ and $T$, and each node will receive row $v$ of $P$ in the end. Recall that the matrix multiplication exponent $\omega$ is defined as the infimum over $\mmeaux$ such that product of two $n \times n$ matrices can be computed with $O(n^{\mmeaux})$ arithmetic operations; it is known that $2 \le \omega < 2.3728639$~\cite{legall2014powers}, and it is conjectured, though not unanimously, that $\omega = 2$.

\begin{restatable}{theorem}{thmmm}\label{thm:mm}
The product of two matrices $n \times n$ can be computed in a congested clique of $n$ nodes in
$O(n^{1/3})$ rounds over semirings. Over rings, this product can be computed in $O(n^{1-2/\omega+\varepsilon})$ rounds for any constant $\varepsilon>0$.
\end{restatable}

Theorem~\ref{thm:mm} follows by adapting known parallel matrix multiplication algorithms for semirings~\cite{AgarwalBGJP95_3d,mccoll1995scalable} and rings~\cite{LuoD95_layout_parallel,mccoll1996,tiskin-phd,BallardDHLS12_Strassen_upper} to the clique model, via the routing technique of~\citet{lenzen2013optimal}. In fact, with little extra work one can show that the resulting algorithm is also \emph{oblivious}, that is, the communication pattern is predefined and does not depend on the input matrices.
Hence, the oblivious routing technique of~\citet{tritri} suffice for implementing these matrix multiplication algorithms.

The above addresses matrices whose entries can be encoded with $O(\log n)$ bits, which is sufficient for dealing with integers of absolute value at most $n^{O(1)}$. In general, if $b$ bits are sufficient to encode matrix entries, the bounds above hold with a multiplicative factor of $b / \log n$; for example, working with integers with absolute value at most $2^{n^{\varepsilon}}$ merely incurs a factor $n^{\varepsilon}$ overhead in running times.

\paragraph{Distributed matrix multiplication exponent.}
Analogously with the matrix multiplication exponent, we denote by $\mme$ the exponent of matrix multiplication in the congested clique model, that is, the infimum over all values $\mmeaux$ such that there exists a matrix multiplication algorithm in the congested clique running in $O(n^{\mmeaux})$ rounds. In this notation, \theoremref{thm:mm} gives us
\[ \mme \le 1 - 2/\omega < 0.15715\,;\]
prior to this work, it was known that $\mme \leq \omega-2$~\cite{drucker13}.

For the rest of this paper, we will -- analogously with the convention in centralised algorithmics -- slightly abuse this notation by writing $n^\mme$ for the complexity of matrix multiplication in the congested clique. This hides factors up to $O(n^\varepsilon)$ resulting from the fact that the exponent $\mme$ is defined as infimum of an infinite set.

\paragraph{Lower bounds for matrix multiplication.}
The matrix multiplication results are optimal in the sense that for any sequential matrix multiplication implementation, any scheme for simulating that implementation in the congested clique cannot give a faster algorithm than the construction underlying \theoremref{thm:mm}; this follows from known results for parallel matrix multiplication~\cite{BallardDHS12_strassen_lower, IronyTT04_3d_lower,AggarwalCS90_PRAM,tiskin1998}. Moreover, we note that for the \emph{broadcast congested clique model}, where each node is required to send the same message to all nodes in any given round, recent lower bounds \cite{arXiv:1412.3445} imply that matrix multiplication cannot be done faster than $\tilde\Omega(n)$ rounds. 


\subsection{Applications in Subgraph Detection}

\paragraph{Cycle detection and counting.}
Our first application of fast matrix multiplication is to the problems of triangle counting~\cite{itai1978finding} and 4-cycle counting. 

\begin{restatable}{corollary}{thmtriangles}\label{cor:triangles}
    For directed and undirected graphs, the number of triangles and 4-cycles can be computed in $O(n^{\mme})$ rounds.
\end{restatable}

For $\mme \le 1-2/\omega$, this is an improvement upon the previously best known $O(n^{1/3})$-round triangle detection algorithm of \citet{tritri} and an $O(n^{\omega - 2 + \varepsilon})$-round algorithm of \citet{drucker13}. Indeed, we disprove the conjecture of~\citet{tritri} that any deterministic oblivious algorithm for detecting triangles requires $\tilde{\Omega}(n^{1/3})$ rounds.

When only detection of cycles is required, we observe that combining the fast distributed matrix multiplication with the well-known technique of \emph{colour-coding} \cite{alon1995color} allows us to detect $k$-cycles in $\tilde{O}(n^{\mme})$ rounds for any constant $k$. This improves upon the subgraph detection algorithm of Dolev et al.~\cite{tritri}, which requires $\tilde{O}(n^{1-2/k})$ rounds for detecting subgraphs of $k$ nodes. However, we do not improve upon the algorithm of Dolev et al. for general subgraph detection.

\begin{restatable}{theorem}{thmkcycles}\label{thm:k-cycles}
For directed and undirected graphs, the existence of $k$-cycles can be detected in $2^{O(k)} n^{\mme} \log n$ rounds.
\end{restatable}

For the specific case of $k=4$, we provide a novel algorithm that does not use matrix multiplication and detects 4-cycles in only $O(1)$ rounds.

\begin{restatable}{theorem}{thmfourcycles}\label{thm:4-cycles}
The existence of 4-cycles can be detected in $O(1)$ rounds.
\end{restatable}




\paragraph{Girth.}
We compute the girth of a graph by leveraging a known trade-off between the girth and the number of edges of the graph~\cite{Matousek02_geometry}. Roughly, we detect short cycles fast, and if they do not exist then the graph must have sufficiently few edges to be learned by all nodes. As far as we are aware, this is the first algorithm to compute the girth in this setting.

\begin{restatable}{theorem}{thmgirth}
For undirected, unweighted graphs, the girth can be computed in $\tilde{O}(n^{\mme})$ rounds.
\end{restatable}


\subsection{Applications in Distance Computation}

\paragraph{Shortest paths.}
The \emph{all-pairs shortest paths} problem (APSP) likewise admits algorithms based on matrix multiplication. The basic idea is to compute the $n^\text{th}$ power of the input graph's weight matrix over the min-plus semiring, by iteratively computing squares of the matrix~\cite{furman1970application, Munro197156, fm1971boolean}. 

\begin{restatable}{corollary}{corrapspsemi}\label{thm:apsp-semiring}
For weighted, directed graphs with integer weights in $\{0 ,\pm 1, \dotsc, \pm M \}$, all-pairs shortest paths can be computed in $O(n^{1/3} \log n \lceil\log M/\log n\rceil)$ communication rounds.
\end{restatable}

We can leverage fast ring matrix multiplication to improve upon the above result; however, the use of ring matrix multiplication necessitates some trade-offs or extra assumptions. For example, for unweighted and undirected graphs, it is possible to recover the exact shortest paths from powers of the adjacency matrix over the Boolean semiring~\cite{Seidel1995400}.

\begin{restatable}{corollary}{corseidel}
For undirected, unweighted graphs, all-pairs shortest paths can be computed in $\tilde{O}(n^{\mme})$ rounds.
\end{restatable}

For small integer weights, we use the well-known idea of embedding a min-plus semiring matrix product into a matrix product over a ring; this gives a multiplicative factor to the running time proportional to the length of the longest path.

\begin{restatable}{corollary}{cordiamapsp}
For directed graphs with positive integer weights and weighted diameter $U$, all-pairs shortest paths can be computed in $\tilde{O}(U n^{\mme})$ rounds.
\end{restatable}

While this corollary is only relevant for graphs of small weighted diameter, the same idea can be combined with weight rounding~\cite{raghavan85,zwick2002all,nanongkai14} to obtain a fast approximate APSP algorithm without such limitations.

\begin{restatable}{theorem}{thmapxapsp}
For directed graphs with integer weights in $\{0,1,\ldots,2^{n^{o(1)}}\}$, we can compute $(1 + o(1))$-approximate all-pairs shortest paths in $O(n^{\mme + o(1)})$ rounds.
\end{restatable}

For comparison, the previously best known combinatorial algorithm for APSP on the congested clique achieves a $(2+o(1))$-approximation in $\tilde{O}(n^{1/2})$ rounds~\cite{nanongkai14}.

\subsection{Additional Related Work}\label{sec:related-work}
Computing distances in graphs,
such as the diameter, all-pairs shortest paths (APSP), and single-source shortest paths (SSSP)
are fundamental problems in most computing settings.
The reason for this lies in the abundance of applications of such computations, evident also by the huge amount of research dedicated to it~\cite{Chan10_apsp,HanT12_apsp,
Han08_apsp,Takaoka04_apsp,Zwick06_APSP,Takaoka05_apsp,Chan08_apsp,Fredman76_apsp,
williams2014apsp,
Zwick01_graph_distances_survey,zwick2002all}.

In particular, computing graph distances is vital for many distributed applications and, as such, has been widely studied in the CONGEST model of computation~\cite{peleg00}, where $n$ processors located in $n$ distinct nodes of a graph $G$ communicate over the graph edges using $O(\log{n})$-bit messages. Specifically, many algorithms and lower bounds were given for computing and approximating graph distances
in this setting~\cite{DHKNPPW-11, nanongkai14, LP13:podc,HolzerW12, PelegRT12,FHW-12,LenzenP13_routing_tables,holzer14,KP98,PelegR-00}. Some lower bounds apply even for graphs of small diameter; however, these lower bound constructions boil down to graphs that contain \emph{bottleneck} edges limiting the amount of information that can be exchanged between different parts of the graph quickly.

The intuition that the congested clique model would abstract away distances and bottlenecks and bring to light only the congestion challenge has proven inaccurate.
Indeed, a number of tasks have been shown to admit sub-logarithmic or even constant-round solutions, exceeding by far what is possible in the CONGEST model with only low diameter. The pioneering work of \citet{lotker05} shows that a minimum spanning tree (MST) can be computed in $O(\log \log n)$ rounds. \citet{hegeman14} show how to construct a $3$-ruling set, with applications to maximal independent set and an approximation of the MST in certain families of graphs; sorting and routing have been recently addressed by various authors~\cite{lenzen2013optimal,LenzenW11,patt-shamir11}. A connection between the congested clique model and the MapReduce model is discussed by~\citet{HegemanP14}, where algorithms are given for colouring problems. On top of these positive results, Drucker et al.~\cite{drucker13} recently proved that essentially \emph{any} non-trivial unconditional lower bound on the congested clique would imply novel circuit complexity lower bounds.

The same work also points out the connection between fast matrix multiplication algorithms and triangle detection in the congested clique. Their construction yields an $O(n^{\omega -2+\varepsilon})$ round algorithm for matrix multiplication over rings in the congested clique model, giving also the same running bound for triangle detection; if $\omega = 2$, this gives $\mme = 0$, matching our result. However, with the currently best known centralised matrix multiplication algorithm, the running time of the resulting triangle detection algorithm is $O(n^{0.3729})$ rounds, still slower than the combinatorial triangle detection of \citet{tritri}, and if $\omega>2$, the solution presented in this paper is faster.


