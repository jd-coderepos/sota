
\documentclass[conference]{IEEEtran}

\usepackage{color}
\usepackage{algorithm,algorithmicx,algcompatible}
\usepackage{verbatim, subfigure}
\usepackage{array, calc, multicol}
\usepackage{xspace}
\usepackage{graphics, epstopdf, graphicx, epsfig, psfrag, epsf, subfigure}
\usepackage{amssymb, amsfonts, amsmath, times}
\usepackage{multicol,balance, verbatim}
\usepackage{textcomp}

\newcommand{\ie}{{\em i.e., }}
\newcommand{\Ie}{{\em I.e., }}
\newcommand{\eg}{{\em e.g., }}
\newcommand{\Eg}{{\em E.g., }}

\newtheorem{theorem}{Theorem}
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{proposition}[theorem]{Proposition}
\newtheorem{corollary}[theorem]{Corollary}
\newtheorem{definition}{Definition}
\newtheorem{example}{Example}
\newtheorem{problem}{Problem}


\DeclareGraphicsExtensions{.eps, .pdf, .png, .jpg}   \newcommand{\Jset}{\mathcal{J}}
\newcommand{\Sset}{\mathcal{S}}
\newcommand{\Kset}{\mathcal{K}}
\newcommand{\Aset}{\mathcal{A}}
\newcommand{\Pset}{\mathcal{P}}
\newcommand{\Cset}{\mathcal{C}}
\newcommand{\Nset}{\mathcal{N}}
\newcommand{\Hset}{\mathcal{H}}
\newcommand{\Iset}{\mathcal{I}}
\newcommand{\Lset}{\mathcal{L}}
\newcommand{\Zset}{\mathcal{Z}}
\newcommand{\Qset}{\mathcal{Q}}
\newcommand{\Uset}{\mathcal{U}}

\DeclareMathOperator*{\argmax}{arg\,max}

\IEEEoverridecommandlockouts





\makeatletter
\newcommand{\oset}[2]{{\mathop{#2}\limits^{\vbox to -.5\ex@{\kern-\tw@\ex@
\hbox{\scriptsize #1}\vss}}}}
\makeatother



\begin{document}

\title{TCP-Aware Backpressure Routing and Scheduling
\thanks{This work was supported by NSF grant CNS-0915988, ONR grant N00014-12-1-0064, ARO Muri grant number W911NF-08-1-0238.}
}



\author{Hulya Seferoglu and Eytan Modiano\\
{Laboratory For Information and Decision Systems}\\
{Massachusetts Institute of Technology}\\
{ \small \tt \{hseferog, modiano\}@mit.edu}\\
}



\maketitle

\begin{abstract}
In this work, we explore the performance of backpressure routing and scheduling for TCP flows over wireless networks. TCP and backpressure are not compatible due to a mismatch between the congestion control mechanism of TCP and the queue size based routing and scheduling of the backpressure framework. We propose a TCP-aware backpressure routing and scheduling that takes into account the behavior of TCP flows. TCP-aware backpressure (i) provides throughput optimality guarantees in the Lyapunov optimization framework, (ii) gracefully combines TCP and backpressure without making any changes to the TCP protocol, (iii) improves the throughput of TCP flows significantly, and (iv) provides fairness across competing TCP flows. \end{abstract}





\section{Introduction}\label{sec:intro}
The backpressure routing and scheduling paradigm has emerged from the pioneering work \cite{tass_eph1}, \cite{tass_eph2}, which showed that, in wireless networks where nodes route and schedule packets based on queue backlog differences, one can stabilize the queues for any feasible traffic. This seminal idea has generated a lot of research interest. Moreover, it has been shown that backpressure can be combined with flow control to provide utility-optimal operation \cite{neely_mod}.

The strengths of these techniques have recently increased the interest in practical implementation of the backpressure framework over wireless networks as summarized in Section~\ref{sec:related}. One important practical problem that remains open, and is the focus of this paper, is the performance of backpressure with Transmission Control Protocol (TCP) flows.



TCP is the dominant transport protocol in the Internet today and is likely to remain so for the foreseeable future. Therefore, it is crucial to exploit throughput improvement potential of backpressure routing and scheduling for TCP flows. However, TCP flows are not compatible with backpressure.
Their joint behavior is so detrimental that some flows may never get a chance to transmit. To better illustrate this point, we first discuss the operation of backpressure in the following example.

\begin{figure}[t!]
\vspace{-10pt}
\centering
\subfigure[\scriptsize Backpressure with random arrivals with rates , ]{ \label{fig:intro_example_a} \scalebox{.65}{\includegraphics[bb=0 0 165 180]{example_fig_a.eps}} }
\subfigure[\scriptsize Backpressure with TCP arrivals]{ \scalebox{.65}{\label{fig:intro_example_b}\includegraphics[bb=0 0 165 180]{example_fig_b.eps}} }
\vspace{-5pt}
\caption{\scriptsize  Example one-hop downlink topology consisting of a transmitter node , and two receiver nodes;  and . The two flows;  and  are destined to  and , respectively.  and  are per-flow queue sizes at time . (a) Backpressure with random arrivals with rates  and . (b) Backpressure with TCP arrivals.  }
\vspace{-20pt}
\label{fig:intro_example}
\end{figure}

\begin{example}\label{ex1}
Let us consider Fig.~\ref{fig:intro_example}, which shows an example one-hop downlink topology consisting of a transmitter node , and two receiver nodes;  and . The two flows;  and  are destined to  and , respectively.  and  are per-flow queue sizes at time . Let us focus on Fig.~\ref{fig:intro_example}(a). At time , packets from the two flows arrive according to random arrival rates;  and , respectively. The packets are stored in per-flow queues.
The backpressure scheduling algorithm, also known as max-weight scheduling, determines the queue (hence the flow) from which packets should be transmitted at time . The decision is based on queue backlog differences, \ie  and , where  and  are per-flow queue sizes at  and , respectively. Since  and  are the destination nodes, the received packets are immediately passed to the higher layers, so , . Therefore, the scheduling algorithm makes the scheduling decision based on  and . In particular, the scheduling decision is  such that . Note that a packet(s) from flow  is transmitted at time . It was shown in \cite{tass_eph1}, \cite{tass_eph2} that if the arrivals rates  and  are inside the stability region, the scheduling algorithm stabilizes the queues. Note that the arrival rates  and  are independent from the scheduling decisions, \ie the scheduling decisions do not affect  and . However, this is not true if the flows are regulated by TCP as explained next.\hfill 
\end{example}

The fundamental goal of TCP, which applies to all TCP variants, is to achieve as much bandwidth as possible while maintaining some level of long-term rate fairness across competing flows. By their very design, all TCP algorithms (both the widely employed loss-based versions and the delay-based ones) have their own ``clock'', which relies on end-to-end acknowledgement (ACK) packets. Based on the received ACKs, TCP determines whether and how many packets should be injected into the network by updating its window size.



{\em Example 1 - continued:} Let us consider Fig.~\ref{fig:intro_example}(b) to illustrate the interaction of backpressure and TCP. In Fig.~\ref{fig:intro_example}(b), packet arrivals are controlled by TCP. Let us consider that loss-based TCP flavor, \eg TCP-Reno or TCP-SACK, is employed. Assume that at time , the TCP congestion window size of the first flow, \ie , is small, \eg  segment, (note that 1-segment window size may be seen at the beginning of a connection or after a re-transmit timeout), while the TCP congestion window size of the second flow is  (\eg it may be the case that flow 2 has been transmitting for some time until , and it has already increased its window size). As depicted in the figure, the example queue occupancies at time  are  and . Since, , a packet(s) from the second flow is transmitted.  receives the transmitted packet, and passes it to TCP. TCP generates an ACK, and transmits it back to node . TCP source of flow  at node  increases window size after receiving an ACK. Therefore, more packets are passed to . On the other hand, since , no packets are transmitted from flow . Thus, TCP does not receive any ACKs for the st flow, does not increase its window size, and no (or sporadic) new packets are passed to . Eventually, the size of  almost never increases, so no packets are transmitted from flow . Possible sample paths showing the evolution of  and  as well as  and  over time are shown in Fig.~\ref{fig:window_queue_evolution}. As can be seen, the joint behavior of TCP and backpressure is so detrimental that flow  does not get any chance to transmit. We confirm this observation via simulations in Section~\ref{sec:performance}.\hfill 


The incompatibility of backpressure is not limited to the loss-based versions of TCP. The delay-based TCP flavors, \eg TCP Vegas is also incompatible with backpressure, as TCP-Vegas has its own clock, which relies on end-to-end ACK packets to calculate round-trip-times (RTTs). If some packets are trapped in buffers due to backpressure as in the above example, sporadic or no ACK packets are received. This increases RTTs, and reduces end-to-end rate of TCP Vegas as there is inverse relationship between RTT and rate. Furthermore, backpressure leads to timeouts which reduce the end-to-end rate in both loss-based and delay-based TCP versions, including new TCP versions; TCP-Compound \cite{tcp_compound} and TCP-Cubic \cite{tcp_cubic}.







\begin{figure}
\vspace{-10pt}
\centering
\scalebox{.4}{\includegraphics[bb=0 0 556 193]{window_queue_evolution_v2.eps}}
\vspace{-5pt}
\caption{\scriptsize Sample paths that show the evolution of , and ,  over time. Note that , are the congestion window size of the TCP flows, and  ,  are the corresponding queue sizes for the example presented in Fig.~\ref{fig:intro_example}(b). Due to backpressure,  does not increase and  does not receive or transmit any packets, and its size stays the same; .}
\label{fig:window_queue_evolution}
\vspace{-20pt}
\end{figure}


In this paper, we propose ``TCP-aware backpressure'' that helps TCP and backpressure operate in harmony. In particular, TCP-aware backpressure takes into account the behavior of TCP flows, and gives transmission opportunity to flows with short queues. This makes all TCP flows transmit their packets, so the TCP clock, which relies on packet transmissions and end-to-end ACKs, continues to operate. Furthermore, the throughput of TCP flows improves by exploiting the performance of the backpressure routing and scheduling. We note that backpressure introduces additional challenges when combined with TCP such as out of order delivery, high jitter RTTs, and packet losses due to corruption over wireless links. However, these challenges are not specific to backpressure, and exist when a multiple path routing scheme over wireless networks is combined with TCP. We address these challenges by employing network coding (in Section~\ref{sec:algs}). Yet, the main focus of this paper is the incompatibility of TCP and backpressure and developing a TCP-aware backpressure framework. The following are the key contributions of this work:


\begin{itemize}
\item We identify the mismatch between TCP and the backpressure framework; \ie their joint behavior is so detrimental that some flows may never get a chance to transmit. In order to address the mismatch between TCP and backpressure, we develop ``TCP-aware backpressure routing and scheduling''.
\item We show that (i) TCP-aware backpressure routing and scheduling stabilizes queues for any feasible traffic as the classical backpressure \cite{tass_eph1}, \cite{tass_eph2}, (ii) TCP-aware backpressure routing and scheduling provides the same utility-optimal operation guarantee when combined with a flow control algorithm as the classical backpressure \cite{neely_mod}.
\item We provide implementation details and explain how to tune TCP-aware backpressure in practice so that it complies with TCP. Moreover, we combine network coding and TCP-aware backpressure to address the additional challenges such as out of order delivery, packet loss, and jitter. Thanks to employing network coding, which makes TCP flows sequence agnostic (with respect to packet IDs), TCP-aware backpressure fully complies with TCP.
\item We evaluate our schemes in a multi-hop setting, using ns-2 \cite{ns2}. The simulation results (i) confirm the mismatch of TCP and backpressure, (ii) show that TCP-aware backpressure is compatible with TCP, and significantly improves throughput as compared to existing adaptive routing schemes, (iii) demonstrate that TCP-aware backpressure provides fairness across competing TCP flows. \end{itemize}

The structure of the rest of the paper is as follows. Section~\ref{sec:system} gives an overview of the system model. Section~\ref{sec:opt} presents TCP-aware backpressure design and analysis. Section~\ref{sec:algs} presents the implementation details of TCP-aware backpressure as well as its interaction with TCP. Section~\ref{sec:performance} presents simulation results.
Section~\ref{sec:related} presents related work. Section~\ref{sec:conclusion} concludes the paper.









\section{System Model}\label{sec:system}
We consider a general network model presented in Fig.~\ref{fig:main-example}, where flows may originate from a source in the Internet and traverse multiple hops to reach their destination in a wireless network. An end-to-end TCP connection is set up for each flow.
Our goal in this paper is to develop TCP-aware backpressure routing and scheduling algorithms that operate in the wireless network. In this direction, we first develop our algorithms using the Lyapunov optimization framework (which is presented in Section~\ref{sec:opt}) by taking into account the incompatibility of TCP and classical backpressure. In this section, we provide an overview of the system model and assumptions that we use to develop the TCP-aware backpressure. Note that the interaction and implementation of TCP-aware backpressure routing and scheduling with actual TCP flows are presented in Section~\ref{sec:algs}.

\begin{figure}
\vspace{-10pt}
\centering
\scalebox{.58}{\includegraphics[bb=0 0 400 165]{main_example_v2.eps}}
\vspace{-5pt}
\caption{\scriptsize A general network model that we consider in this paper. A flow may originate from a source in the Internet and traverse multiple hops to reach its destination in a wireless network. An end-to-end TCP connection is set up for each flow. We explore the performance of backpressure for TCP flows in the wireless network.}
\label{fig:main-example}
\vspace{-20pt}
\end{figure}


{\em Wireless Network Setup:} The wireless network consists of  nodes and  links, where  is the set of nodes and  is the set of links in the network. In this setup, each wireless node is able to perform routing and scheduling. Let  be the set of unicast flows between source-destination pairs in the network.We consider in our formulation and analysis that time is slotted, and  refers to the beginning of slot .

{\em Channel Model:} At slot ,      is the channel state vector, where  represents the edges such that ,  and . For the sake of analysis, we assume that  is the state of link  at time  and takes values from the set  according to a probability distribution which is i.i.d. over time slots. If  , packets can be transmitted with rate . Otherwise; (\ie if ), no packets are transmitted. Note that our analysis can be extended to more general channel state models \cite{neely_book}. We also consider a Rayleigh fading model in our simulations.

Let  denote the set of the link transmission rates feasible at time slot  and for channel state  and interference among wireless links. In particular, at every time slot , the link transmission vector  should be constrained such that  . Hence,  takes a value from the set  depending on the channel state and interference among multiple wireless nodes. Also note that  is determined by the scheduling algorithm.


{\em Stability Region:}
Let  be the vector of arrival rates . The network stability region  is defined as the closure of all arrival rate vectors that can be stably transmitted in the network, considering all possible routing and scheduling policies \cite{tass_eph1}, \cite{tass_eph2}, \cite{neely_mod}.  is fixed and depends only on channel statistics and interference.



{\em Flow Rates and Queue Evolution:}  Each flow  is generated at its source node according to an arrival process ,  at time slot . The arrivals are i.i.d. over the slots and , . We assume that  and  are finite. Note that we make i.i.d. arrivals assumption for the purpose of designing and analyzing our algorithms in the Lyapunov optimization framework. This assumption is relaxed in the practical setup when we combine our algorithms with TCP flows in Section~\ref{sec:algs}.

Each node  constructs a per-flow queue  for each flow . The size of the per-flow queue  at time  is .
Let  be the source node of flow . The packets generated according to the arrival process  are inserted in the per-flow queue at node , \ie in . These queues only store packets from flow . Each node  such that  and , may receive packets from its neighboring nodes and insert them in . The transmission rate of flow  from node  to node  is . Since the link transmission rate over link  is  at time , multiple flows could share the available rate, \ie . Accordingly, at every time slot , the size of per-flow queues, \ie  evolves according to the following dynamics.
 where  is an indicator function, which is  if , and , otherwise. Note that Eq.~(\ref{eq:queue_U}) is inequality, because the number of packets in the queue  may be less than .









\section{TCP-Aware Backpressure: Design and Analysis}\label{sec:opt}
In this section, we design and analyze the TCP-aware backpressure scheme. In particular, we provide a stochastic control strategy including routing and scheduling to address the incompatibility between TCP and classical backpressure.

\textbf{\underline{TCP-Aware Backpressure:}}
\begin{itemize}
\item \textbf{Routing \& Intra-Node Scheduling.} The routing \& intra-node scheduling part of TCP-aware backpressure determines a flow  from which packets should be transmitted at slot  from node , as well as the next hop node  to which packets from flow  should be forwarded. The algorithm works as follows.

  Node  observes per-flow queue backlogs in all neighboring nodes at time , and determines queue backlog difference according to:
   where  is a non-negative finite constant. Let  s.t.  and . The maximum queue backlog difference among all flows over link  is;
  
  The flow that maximizes the queue backlog differences over link  is  and expressed as;
  
  At time slot , one or more packets are selected from the queue  if    and  has enough packets for transmission. The transmission of the selected packets depends on the channel conditions and interference constraints, and determined by inter-node scheduling.

  Note that TCP-aware backpressure uses queue backlog difference  in Eq.~(\ref{eq:per_flow_difference}) instead of  in the classical backpressure. The advantage of using Eq.~(\ref{eq:per_flow_difference}) in TCP-aware backpressure is that node  may select packets from flow  even if queue size  is small.\footnote{\scriptsize Note that place-holder backlogs, such as using  instead of  has been considered in the literature \cite{neely_book}. Although place-holder algorithms are beneficial to improve end-to-end delay, they do not solve the problem we consider in this paper as they do not give transmission opportunity to small queues.} This advantage is clarified through an illustrative example later in this section.
\item \textbf{Inter-Node Scheduling.} The inter-node scheduling (as also called resource allocation \cite{neely_mod}) part of TCP-aware backpressure determines link transmission rates considering the link state information and interference constraints.

  Each node  observes the channel state  at time , and determines a transmission vector   by maximizing . Note that  should be constrained such that , \ie interference among multiple nodes should be taken into account. The resulting transmission rate  is used to transmit packets of flow  over link .
\end{itemize}
\begin{theorem}\label{theorem1}
If channel states are i.i.d. over time slots, the arrival rates ,  are interior to the stability region , and  is a non-negative finite constant, then TCP-aware backpressure stabilizes the network and the total average queue size is bounded.
\end{theorem}
{\em Proof:} The proof is provided in Appendix A. \hfill 
\begin{example}\label{ex2}
Let us consider again Fig.~\ref{fig:intro_example}(b) for the operation of TCP-aware backpressure. The example queue occupancies at time  are  and . Assume that  in Eq.~(\ref{eq:per_flow_difference}) is chosen as . According to TCP-aware backpressure, the scheduling algorithm makes a decision based on the rule   such that . Since    , , both flows get equal chance for transmission. Thus, congestion window sizes of both TCP flows evolve in time, and the TCP flows can transmit their packets. We note that one can extend this example for the case;  and . In this case, as , packets from the first flow may not get any chance for transmission. Therefore, it is crucial to determine  in practice, which we explain in Section~\ref{sec:algs}. \hfill 
\end{example}

Note that we propose TCP-aware backpressure; its routing, intra-node scheduling, and inter-node scheduling parts to work with TCP and TCP's end-to-end flow control mechanism. In the next section, we provide implementation details. However, TCP-aware backpressure can also be combined with flow control schemes other than TCP's, which is important for two reasons: (i) it may be possible or preferable to use personalized flow control mechanisms instead of TCP's in some systems, (ii) there may be both TCP and non-TCP flows in some systems, where a TCP-friendly flow control mechanism combined with non-TCP flows is crucial to accommodate both TCP and non-TCP flows. We consider the following flow control algorithm, developed in \cite{neely_mod}, to complement TCP-aware backpressure for non-TCP flows.

The flow control algorithm at node  determines the number of packets from flow  that should be passed to the per-flow queues;  at every time slot  according to;

 where  is a constant larger than the maximum outgoing rate from node ,  is a positive constant,  is the rate of packets that will be inserted to the per-flow queue , and  is the utility function of flow .

\begin{theorem}\label{theorem2}
If there are only non-TCP flows in the system and they employ the flow control algorithm in Eq.~(\ref{eq:flow_control}) and TCP-aware backpressure (with non-negative finite value of  in Eq.~(\ref{eq:per_flow_difference})), then the admitted flow rates converges to the utility optimal operating point (as the classical backpressure) in the stability region  with increasing .
\end{theorem}
{\em Proof:} The proof of Theorem~\ref{theorem2} directly follows when Appendix A and drif+penalty approach \cite{neely_mod} are combined. \hfill 






\section{TCP-Aware Backpressure: Implementation \& Interaction with TCP}\label{sec:algs}
We present practical implementation details of TCP-aware backpressure as well as its interaction with different layers in the protocol stack (summarized in Fig.~\ref{fig:protocol_stack}).

\begin{figure}
\hspace{-5pt}
\centering
\scalebox{.38}{\includegraphics[bb=0 0 576 272]{protocol_stack_v2.eps}}
\caption{\scriptsize  TCP-aware backpressure operations at edge-points and intermediate nodes. The {\em inter-node scheduling} and {\em routing and intra-node scheduling} parts of TCP are implemented on top of 802.11 MAC and in network layers, respectively. The {\em NC layer} is implemented as a slim layer above the network layer at the edge points. Transport layer, \ie TCP, only exists if the edge point is a TCP source.
}
\vspace{-10pt}
\label{fig:protocol_stack}
\vspace{-20pt}
\end{figure}


\subsection{Implementation}
\subsubsection{Inter-Node Scheduling}
The inter-node scheduling part of TCP-aware backpressure determines which links should be activated at time .  The inter-node scheduling is a hard problem, \cite{tutorial_doyle}, \cite{lin_schroff_tutorial}, so its practical implementation is challenging. Therefore, we implement its low complexity version in our system on top of IEEE 802.11 MAC as seen in Fig.~\ref{fig:protocol_stack}. The implementation details are as follows.








Each node uses 802.11 MAC to access the wireless medium. When a node  is assigned a channel by the MAC protocol, inter-node scheduling determines the neighboring node to which a selected packet should be forwarded. Let us assume that a packet is selected from flow  to be forwarded to node  by the routing and intra-node scheduling algorithm, which we explain later in this section. The next hop that the selected packet should be forwarded is  and determined by , where  and  are the estimated values of  (loss probability) and  (link transmission rate) over link , respectively.\footnote{\scriptsize  is calculated as one minus the ratio of successfully transmitted packets over all transmitted packets during a time interval  on link .  is calculated as the average of the recent (over an interval) link rates over link .}
Then, a packet from flow , \ie from the network layer queue , is removed and passed to the MAC layer for transmission. The MAC layer transmits the packet to node .





\subsubsection{Routing and Intra-Node Scheduling}
This algorithm determines the next hop(s) to which packets should be forwarded, and the packets that should be transmitted.

We construct per-flow queues, \ie , at the network layer\footnote{\scriptsize Note that constructing per-flow queues at each node may not be feasible in some systems. However, this aspect is orthogonal to the focus of this paper, and the techniques developed in the literature \cite{diffmax}, \cite{locbui} to address this problem is complementary to our TCP-aware backpressure framework.}, where the routing and intra-node scheduling algorithm operates as seen in Fig.~\ref{fig:protocol_stack}. The algorithm requires each node to know the queue size of their neighbors. To achieve this, each node  transmits a message containing the size of its per-flow queue sizes;  at time . These messages are piggy-backed to data packets. If there is no data transmission for some time duration, our algorithm uses independent control packets to exchange the queue size information. The transmitted message is overheard by all nodes in the neighborhood. The queue size information is extracted from the overheard messages and recorded for future decisions.

At node  at time , the queue backlog difference is calculated according to Eq.~(\ref{eq:per_flow_difference}). Note that, although the algorithm exactly knows  at time , it is difficult to exactly know  at time . Therefore, the most recent report (until time ) of the size of  is used instead of .
When a transmission opportunity for link  arises using inter-node scheduling algorithm, a packet from flow  is selected and passed to the MAC layer for transmission.




\subsubsection{Network Coding}
Out of order delivery, high jitter in RTTs, and packet losses over wireless links are among the challenges when backpressure and TCP are combined. We address these challenges by employing network coding \cite{NC_meets_TCP}, \cite{multipath_tcp_toledo}, \cite{i2nc}. This is an effective solution thanks to the properties of network coding such as masking wireless losses and making packets sequence agnostic in terms of packet IDs. We summarize our implementation in the following.

We implement the generation based network coding \cite{practical_NC} at the edge points of the wireless network (\eg access point, base station, proxy, or TCP source itself) as a slim network coding layer (NC layer) above the network layer as shown in Fig.~\ref{fig:protocol_stack}. Note that we do not make any updates to TCP, which makes our approach amenable to practical deployment.

The NC layer at the edge point receives and packetizes the data stream into packets   of flow . The stream of packets are divided into blocks of size , which is set to TCP congestion window size (or its average). The packets within the same block are linearly combined (assuming large enough field size) to generate  network coded packets; , , , , where ,  are network coding coefficients from a finite field. Note that network coded packets are generated incrementally to avoid coding delay \cite{practical_NC}, \cite{i2nc}. The NC layer adds network coding header including block ID, packet ID, block size, and coding coefficients. The network coded packets are routed and scheduled by TCP-aware backpressure.

At the receiver node, when the NC layer receives a packet from a new block, it considers the received packet as the first packet in the block. It generates an ACK, sends the ACK back to the NC layer at the edge point, which matches this ACK to packet , converts this ACK to 's ACK, and transmits the ACK information to the TCP source. Similarly, ACKs are generated at the receiver side for the second, third, etc. received packets. As long as the NC layer at the receiver transmits ACKs, the TCP clock moves, and the window continues to advance.


The NC layer stores the received network coded packets in a buffer. When the last packet from a block is received, packets are decoded and passed to the application layer. If some packets are lost in the wireless network, the receiver side NC layer makes a request with the block ID and the number of missing packets, and the edge point side NC layer generates additional network coded packets from the requested block, and sends to the receiver. Note that the missing packet IDs are not mentioned in the request, since the network coding makes the packets sequence agnostic in terms of packet IDs.

Network coding makes packets sequence agnostic, which solves out of order delivery problem and eliminates jitter. Network coding also corrects packet losses in the wireless network as explained above. We explain how our system and NC layer reacts to congestion-based losses later in this section.








\subsection{Interaction with TCP}

\subsubsection{Congestion Control}
Now, let us consider the interaction of TCP congestion control and TCP-aware backpressure using well-known classical TCP analysis \cite{twsly_tcp}, \cite{low_tcp}. Using the similar approach as in \cite{twsly_tcp}, \cite{low_tcp}, and as detailed in \cite{tcp_aware_bp_tech_rep}, we find the steady state TCP throughput for flow  as; , where  is the buffer overflow probability at the TCP source/edge node , and  is constant RTT.\footnote{\scriptsize The constant RTT is a common assumption in classical TCP analysis \cite{twsly_tcp}, \cite{low_tcp}, and also valid in our setup thanks to employing network coding, which reduces jitter in RTT and makes constant RTT assumption valid.}

Note that the steady state TCP throughput depends on the buffer overflow probability only at the source/edge node different from \cite{twsly_tcp}, \cite{low_tcp}, where TCP throughput depends on the buffer overflow probability over all nodes over the path of TCP flow.\footnote{\scriptsize Note that steady state TCP throughput does not depend on packet trapping events thanks to employing Eq.~(\ref{eq:per_flow_difference}). This does not hold for classical backpressure, because some packets may be trapped in buffers, which reduces TCP throughput, and should be taken into account in the steady state TCP throughput analysis.} The reason is that congestion in the wireless network is controlled by TCP-aware backpressure, and we do not expect losses due to congestion (buffer overflow) at the intermediate nodes. In particular, as TCP-aware backpressure makes transmission decisions based on queue backlog differences according to Eq.~(\ref{eq:per_flow_difference}), it would not transmit packets if the next hop queue is congested. Therefore, congestion-based losses only occur at the source/edge node. In our implementation, if the buffer at the source/edge node is congested, than a packet from the flow which has the largest queue size is dropped. This congestion-based loss information is passed to the NC layer. The NC layer creates a loss event by not masking the dropped packet so that TCP can detect the congestion-based loss event and back-off. 







\subsubsection{Selection of }
TCP-aware backpressure uses queue backlog difference in Eq.~(\ref{eq:per_flow_difference}), which depends on , to make routing and scheduling decisions. As noted in Section~\ref{sec:opt}, the selection of  is crucial in practice to make TCP and backpressure fully comply.

In particular, if  is selected too small, the number of packets that are trapped in the buffers, \ie the number of packets that do not get transmission opportunity, increases. This reduces TCP throughput. On the other hand, if  is too large, TCP-aware backpressure may not exploit the throughput improvement benefit of backpressure routing and scheduling as the ability of identifying good routing and scheduling policies reduces with large  values.



Our intuition is that flows passing through node , \ie , should share the available buffer fairly. Assume that  is the available buffer size at node . In order to give transmission opportunity to all TCP flows and provide some level of fairness across the competing TCP flows, we set  at node . In this setting, if per-flow queue sizes are smaller than , it is highly possible that packets from all TCP flows are transmitted. On the other hand, if some per-flow queue sizes are larger than , packets from the flows with smaller queue sizes may still be trapped in the buffers. However, in this case, since the total buffer occupancy is large, buffer overflow probability at the source/edge node increases. Upon buffer overflow, the TCP flow with larger queue size reduces its rate (since upon congestion a packet from the largest per-flow queue is dropped). This reduces the queue sizes, and packets from all flows could be transmitted again.

{\em Example 2 - continued:} Let us consider again Fig.~\ref{fig:intro_example}(b). If the queue occupancies are , , and , packets only from the second flow are transmitted. Since  and we set , and , the buffer size is . The total queue occupancy is  . This means that the buffer at node  is about to overflow, which will lead to back-off for the second flow (since a packet from the largest queue will be dropped). Thus, the TCP rate and queue size of the second flow will reduce, and the first flow will get transmission opportunity. \hfill 

We have observed through simulations that TCP-aware backpressure, when  is set to , significantly reduces the number of the trapped packets in the buffers. Yet, very few packets may still be trapped. Such packets are easily masked thanks to error correction capabilities of network coding. Note that network coding does not help if large number of packets are trapped in the buffers (\eg when  is selected too small), as large number of trapped packets increases end-to-end delay too much, which leads to multiple timeouts and reduces TCP throughput.





\section{Performance Evaluation}\label{sec:performance}
We simulate our scheme, TCP-aware backpressure (TCP-aware BP) as well as classical backpressure (classical BP), in ns-2 \cite{ns2}. The simulation results; (i) confirm the mismatch of TCP and classical BP, (ii) show that TCP-aware BP is compatible with TCP, and significantly improves throughput as compared to existing routing schemes such as Ad-hoc On-Demand Distance Vector (AODV) \cite{aodv}, (iii) demonstrate that TCP-aware BP provides fairness across competing TCP flows. Next, we present the simulator setup and results in detail.

\begin{figure*}[t!]
\vspace{-5pt}
\centering
\subfigure[\scriptsize  Tree topology]{ \label{fig:intro_example_a} \scalebox{.40}{\includegraphics[bb=0 0 246 164]{tree_topology.eps}} }
\subfigure[\scriptsize Diamond topology]{ \label{fig:intro_example_a} \scalebox{.45}{\includegraphics[bb=0 0 246 164]{diamond_topology.eps}} }
\subfigure[\scriptsize Grid topology]{ \label{fig:intro_example_b} \scalebox{.35}{\includegraphics[bb=0 0 299 179]{grid_topology.eps}} }
\vspace{-5pt}
\caption{\scriptsize Topologies used in simulations; (a) tree topology, (b) diamond topology, (c) grid topology.}
\vspace{-15pt}
\label{fig:topologies}
\end{figure*}





\subsection{Simulation Setup}
We consider three topologies: a tree topology, a diamond topology, and a grid topology shown in Fig.~\ref{fig:topologies}. The nodes are placed over  terrain, and ,  and ,  are possible source-receiver pairs in the tree and diamond topologies. In the grid topology,  cells are placed over a  terrain. A gateway, which is connected to the Internet, passes flows to nodes. Each node communicates with other nodes in its cell or neighboring cells, and there are  nodes randomly placed to the cells.

We consider FTP/TCP traffic, and employ TCP-SACK and TCP-Vegas in our simulations. TCP flows start at random times within the first  of the simulation and are on until the end of the simulation which is . IEEE 802.11b is used in the MAC layer. In terms of wireless channel, we simulated the two-ray path loss model and a Rayleigh fading channel with average loss rates .Channel capacity is , the buffer size at each node is set to  packets, packet sizes are set to . We have repeated each  simulation for 10 seeds.

We compare our scheme, TCP-aware BP, to the classical BP and AODV. For fair comparison, we employ the network coding mechanism explained in Section~\ref{sec:algs} in the classical BP as well as in AODV. The comparisons are in terms of per-flow and total transport level throughput (added over all flows) as well as fairness. For the fairness calculation, we use Jain's fairness index \cite{fairness_index}: , where  is the set of flows and  is the average throughput of flow .





\subsection{Simulation Results}

Fig.~\ref{fig:tree_thrpt_time_results} shows throughput vs. time graphs for TCP-aware BP and classical BP. There are two flows; Flow 1 is transmitted from node  to node , and Flow 2 is transmitted from node  to node . The links are not lossy. Fig.~\ref{fig:tree_thrpt_time_results}(a) and (b) are the results for TCP-SACK, while Fig.~\ref{fig:tree_thrpt_time_results}(c) and (d) are for TCP-Vegas. Fig.~\ref{fig:tree_thrpt_time_results}(b) shows that while Flow 1 is able to transmit, Flow 2 does not get any chance for transmission in classical BP due to the mismatch between congestion window size update mechanism of TCP and queue size-based routing and scheduling of backpressure. On the other hand, in TCP-aware BP, both flows get chance for transmission. In particular, Flow 1 and Flow 2 achieves average throughput of  and , respectively. Fig.~\ref{fig:tree_thrpt_time_results}(c) and (d) show throughput vs. time graphs of TCP-aware BP and classical BP for TCP-Vegas. Although classical BP performs better in TCP-Vegas than in TCP-SACK due to the delay based mechanism of TCP-Vegas, its performance is still quite poor as the throughput of Flow 2 frequently goes to 0 as seen in Fig.~\ref{fig:tree_thrpt_time_results}(d). On the other hand, TCP-aware BP improves throughput of both flows as seen in Fig.~\ref{fig:tree_thrpt_time_results}(c), where Flow 1 and Flow 2 achieve  and , respectively. The similar results are presented in Fig.~\ref{fig:diamond_thrpt_time_results} for the diamond topology.


\begin{figure}[t!]
\vspace{-0pt}
\begin{center}
\subfigure[\scriptsize{TCP-Aware BP with TCP-SACK}]{{\includegraphics[width=4cm]{tree_topology_tcp_bp_thrpt_vs_time.eps}}}
\subfigure[\scriptsize{BP with TCP-SACK}]{{\includegraphics[width=4cm]{tree_topology_bp_thrpt_vs_time.eps}}} \hspace{-0pt} \\
\subfigure[\scriptsize{TCP-Aware BP with TCP-Vegas}]{{\includegraphics[width=4cm]{tree_topology_tcp_bp_thrpt_vs_time_vegas.eps}}}
\subfigure[\scriptsize{BP with TCP-Vegas}]{{\includegraphics[width=4cm]{tree_topology_bp_thrpt_vs_time_vegas.eps}}} \hspace{-0pt}
\end{center}
\begin{center}
\vspace{-5pt}
\caption{\label{fig:tree_thrpt_time_results} \scriptsize  Throughput vs. time in the tree topology for TCP-SACK and TCP-Vegas. There are two flows; Flow 1 is transmitted from node  to node , and Flow 2 is transmitted from node  to node . The links are not lossy.
}
\vspace{-15pt}
\end{center}
\vspace{-10pt}
\end{figure}



Fig.~\ref{fig:diamond_thrpt_vs_loss_sack} demonstrates throughput and fairness vs. average loss rate results of TCP-aware BP and AODV in the diamond topology. There are two flows transmitted from node  to  (Flow 1) and  to  (Flow 2). The link  is a lossy link. The version of TCP is TCP-SACK. Fig.~\ref{fig:diamond_thrpt_vs_loss_sack}(a) shows that TCP-aware BP improves throughput significantly as compared to AODV thanks to adaptive routing and scheduling. The throughput improvement of TCP-aware BP as compared to AODV increases as loss probability increases thanks to loss-aware routing and scheduling mechanism of TCP-aware BP. Moreover, Fig.~\ref{fig:diamond_thrpt_vs_loss_sack}(b) shows that the fairness index is close to  (note that  is the highest possible fairness index) when TCP-aware BP is employed. This means that both TCP flows are able to survive in TCP-aware BP. Note that the fairness index of TCP-aware BP is 0.94, while the fairness index of AODV is 0.98 when the packet loss probability is 0.5. This is due to the fact that TCP-aware BP exploits loss-free links better, and slightly favors the flows transmitted over such links. However, the throughput improvement of both flows as compared to AODV is higher. In particular, TCP-aware BP improves throughput as compared to AODV by \%10 and \%40 for the first and second flows, respectively. These results confirm the compatibility of TCP and TCP-aware BP.


\begin{figure}[t!]
\vspace{-0pt}
\begin{center}
\subfigure[\scriptsize TCP-Aware BP with TCP-SACK]{{\includegraphics[width=4cm]{diamond_topology_tcp_bp_thrpt_vs_time.eps}}}
\subfigure[\scriptsize BP with TCP-SACK]{{\includegraphics[width=4cm]{diamond_topology_bp_thrpt_vs_time.eps}}} \hspace{-0pt} \\
\subfigure[\scriptsize TCP-Aware BP with TCP-Vegas]{{\includegraphics[width=4cm]{diamond_topology_tcp_bp_thrpt_vs_time_vegas.eps}}}
\subfigure[\scriptsize BP with TCP-Vegas]{{\includegraphics[width=4cm]{diamond_topology_bp_thrpt_vs_time_vegas.eps}}} \hspace{-0pt}
\end{center}
\begin{center}
\vspace{-5pt}
\caption{\label{fig:diamond_thrpt_time_results} \scriptsize Throughput vs. time in the diamond topology for TCP-SACK and TCP-Vegas. There are two flows; Flow 1 is transmitted from node  to node , and Flow 2 is transmitted from node  to node . The links are not lossy.
}
\vspace{-15pt}
\end{center}
\end{figure}


\begin{figure}[t!]
\vspace{-0pt}
\begin{center}
\subfigure[\scriptsize Throughput]{{\includegraphics[width=4cm]{diamond_tcp_sack_thrpt_loss.eps}}}
\subfigure[\scriptsize Fairness]{{\includegraphics[width=4cm]{diamond_tcp_sack_fairn_loss.eps}}}
\end{center}
\begin{center}
\vspace{-5pt}
\caption{\label{fig:diamond_thrpt_vs_loss_sack} \scriptsize Throughput and fairness vs. average packet loss rate for TCP-aware BP and AODV in the diamond topology. There are two TCP flows transmitted from node  to  (Flow 1) and  to  (Flow 2). The link  is a lossy link. The version of TCP is TCP-SACK.}
\end{center}
\vspace{-15pt}
\end{figure}


Let us consider the grid topology shown in Fig.~\ref{fig:topologies}. Four flows are transmitted from the gateway to four distinct nodes, which are randomly chosen. Half of the links, chosen at random, are lossy with loss probability ranging between . Fig.~\ref{fig:grid_thrpt_time_results} shows throughput vs. time graphs for TCP-aware BP and classical BP. It is seen that all four flows could survive in TCP-aware BP for both TCP-SACK and TCP-Vegas, while one or more flows do not survive in classical BP. Fig.~\ref{fig:grid_thrpt_vs_loss_sack} shows throughput and fairness vs. average loss probability results for TCP-aware BP and AODV for TCP-SACK. TCP-aware BP improves throughput significantly as compared to AODV without violating fairness. Fig.~\ref{fig:grid_thrpt_vs_loss_vegas} shows that TCP-aware BP improves throughput significantly as compared to AODV when TCP-Vegas is employed. This shows the effectiveness of our scheme in delay-based TCP versions.



\begin{figure}[t!]
\vspace{-0pt}
\begin{center}
\subfigure[\scriptsize TCP-Aware BP with TCP-SACK]{{\includegraphics[width=4cm]{grid_topology_tcp_bp_thrpt_vs_time.eps}}}
\subfigure[\scriptsize BP with TCP-SACK]{{\includegraphics[width=4cm]{grid_topology_bp_thrpt_vs_time.eps}}} \hspace{-0pt} \\
\subfigure[\scriptsize TCP-Aware BP with TCP-Vegas]{{\includegraphics[width=4cm]{grid_topology_tcp_bp_thrpt_vs_time_vegas.eps}}}
\subfigure[\scriptsize BP with TCP-Vegas]{{\includegraphics[width=4cm]{grid_topology_bp_thrpt_vs_time_vegas.eps}}} \hspace{-0pt}
\end{center}
\begin{center}
\vspace{-15pt}
\caption{\label{fig:grid_thrpt_time_results} \scriptsize Throughput vs. time in the grid topology for TCP-SACK and TCP-Vegas. There are four flows and the links are not lossy.
}
\end{center}
\vspace{-15pt}
\end{figure}


\begin{figure}[t!]
\vspace{-0pt}
\begin{center}
\subfigure[\scriptsize Throughput]{{\includegraphics[width=4cm]{grid_tcp_sack_thrpt_loss.eps}}}
\subfigure[\scriptsize Fairness]{{\includegraphics[width=4cm]{grid_tcp_sack_fairn_loss.eps}}}
\end{center}
\begin{center}
\vspace{-5pt}
\caption{\label{fig:grid_thrpt_vs_loss_sack} \scriptsize Throughput and fairness vs. average packet loss rate for TCP-aware BP and AODV in the grid topology. There are four TCP flows transmitted from the gateway to four distinct nodes. Half of the links are lossy. The version of TCP is TCP-SACK.
}
\end{center}
\vspace{-15pt}
\end{figure}


\begin{figure}[t!]
\vspace{-0pt}
\begin{center}
\subfigure[\scriptsize Throughput]{{\includegraphics[width=4cm]{grid_tcp_vegas_thrpt_loss.eps}}}
\subfigure[\scriptsize Fairness]{{\includegraphics[width=4cm]{grid_tcp_vegas_fairn_loss.eps}}}
\end{center}
\begin{center}
\vspace{-5pt}
\caption{\label{fig:grid_thrpt_vs_loss_vegas} \scriptsize Throughput and fairness vs. average packet loss rate for TCP-aware BP and AODV in the grid topology. There are four TCP flows transmitted from the gateway to four distinct nodes. Half of the links are lossy. The version of TCP is TCP-Vegas.}
\end{center}
\vspace{-15pt}
\end{figure}

As mentioned in Section~\ref{sec:opt}, there may be both TCP and non-TCP flows in the system, and non-TCP flows should be controlled in a TCP-friendly manner so that TCP flows could survive when non-TCP flows are on. Therefore, a flow control algorithm is presented in Eq.~(\ref{eq:flow_control}) for non-TCP flows. Now, we evaluate this scenario in the diamond topology with two flows. Flow 1 is a TCP flow (TCP-SACK) transmitted from node  to node , and Flow 2 is a non-TCP flow transmitted from node  to node . In our TCP-aware BP framework, the non-TCP flow is regulated by Eq.~(\ref{eq:flow_control}). The parameters in Eq.~(\ref{eq:flow_control}) are set as; , , . The implementation details including TCP-friendly parameter selection are provided in \cite{tcp_aware_bp_tech_rep}.
Fig.~\ref{fig:diamond_thrpt_time_results_tcp_udp} shows throughput vs. time graph of TCP-aware BP, classical BP, and AODV. The TCP flow does not survive in classical BP as packets are trapped in the buffers. It does not survive with AODV as well, because uncontrolled non-TCP flows (\ie UDP flows) occupy buffers and TCP packets are constantly dropped from the buffers, which reduces TCP throughput. Yet, both TCP and non-TCP flows survive together in in TCP-aware BP thanks to TCP-aware routing and scheduling, and TCP-friendly flow control for non-TCP flows. Fig.~\ref{fig:diamond_thrpt_vs_loss_sack_UDP_TCP} shows the throughput improvement performance of TCP-aware BP as compared to AODV in the same setup for different packet loss probabilities. At low loss probabilities, although the throughput of AODV is better than TCP-aware BP, the fairness graph (and Fig.~\ref{fig:diamond_thrpt_time_results_tcp_udp} for no-loss) shows that the fairness of AODV is very low, which means that the TCP flow does not survive. At higher loss probabilities, TCP-aware BP is better than AODV thanks to choosing better routes and schedules as compared to AODV.


\begin{figure}[t!]
\vspace{-0pt}
\begin{center}
\subfigure[\scriptsize TCP-Aware BP]{{\includegraphics[width=2.7cm]{diamond_topology_tcp_bp_thrpt_vs_time_UDP_TCP_v2.eps}}}
\subfigure[\scriptsize Classical BP]{{\includegraphics[width=2.8cm]{diamond_topology_bp_thrpt_vs_time_UDP_TCP.eps}}} \hspace{-0pt}
\subfigure[\scriptsize AODV]{{\includegraphics[width=2.8cm]{diamond_topology_aodv_thrpt_vs_time_UDP_TCP.eps}}}
\end{center}
\begin{center}
\vspace{-5pt}
\caption{\label{fig:diamond_thrpt_time_results_tcp_udp} \scriptsize Throughput vs. time in the diamond topology for TCP-SACK. There are two flows; Flow 1 is a TCP flow, transmitted from node  to node , and Flow 2 is a non-TCP flow, transmitted from node  to node . The links are not lossy.
}
\end{center}
\vspace{-15pt}
\end{figure}




\begin{figure}[t!]
\vspace{-0pt}
\begin{center}
\subfigure[\scriptsize Throughput]{{\includegraphics[width=4cm]{diamond_tcp_sack_thrpt_loss_UDP_TCP.eps}}}
\subfigure[\scriptsize Fairness]{{\includegraphics[width=4cm]{diamond_tcp_sack_fairn_loss_UDP_TCP.eps}}}
\end{center}
\begin{center}
\vspace{-5pt}
\caption{\label{fig:diamond_thrpt_vs_loss_sack_UDP_TCP} \scriptsize Throughput and fairness vs. average packet loss rate for TCP-aware BP and AODV in the diamond topology. There are two flows transmitted from node  to  (Flow 1, \ie TCP flow) and  to  (Flow 2, \ie non-TCP flow). The link  is a lossy link. The version of TCP is TCP-SACK.
}
\end{center}
\vspace{-25pt}
\end{figure}






\section{Related Work}\label{sec:related}
Backpressure, a routing and scheduling framework over communication networks \cite{tass_eph1}, \cite{tass_eph2} has generated a lot of research interest \cite{neely_book}, mainly in wireless ad-hoc networks. It has also been shown that backpressure can be combined with flow control to provide utility-optimal operation guarantee \cite{neely_mod}, \cite{stolyar_greedy}.

The strengths of backpressure have recently increased the interest on practical implementation of backpressure over wireless networks. Backpressure has been implemented over sensor networks \cite{routing_wtht_routes} and wireless multi-hop networks \cite{xpress}. The multi-receiver diversity has been explored in wireless networks using backpressure in \cite{javidi_diversity}. The 802.11 compliant version of enhanced backpressure is evaluated in \cite{choumas}. Backpressure routing and rate control for intermittently connected networks was developed in \cite{backpressure_for_icns}. 

Backpressure routing and (max-weight) scheduling with TCP over wireless has been considered in the literature. At the link layer, \cite{DiffQ}, \cite{umut_stolyar}, propose, analyze, and evaluate link layer backpressure-based implementations with queue prioritization and congestion window size adjustment. The interaction of TCP with backpressure in \cite{DiffQ} and \cite{umut_stolyar} is handled by updating the TCP congestion window evolution mechanism. In particular, if the queue size (at the TCP source) increases, the window size is reduced, otherwise, the window size is increased. Multi-path TCP scheme is implemented over wireless mesh networks \cite{horizon} for routing and scheduling packets using a backpressure based heuristic, which avoids incompatibility with TCP. Max-weight scheduling is updated in \cite{ghaderi_tcp_theoric} to make decisions based only on MAC level queue size information. Although \cite{ghaderi_tcp_theoric} considers window based flow control mechanism similar to TCP, it does not consider existing TCP flavors. The main differences in our work are: (i) we consider the incompatibility of TCP with backpressure, and develop TCP-aware backpressure framework to address the incompatibilities, (ii) TCP-aware backpressure provides the same stability and utility-optimal operation guarantees as classical backpressure, (iii) we do not make any changes at the TCP source, (iv) we employ network coding to gracefully combine TCP and TCP-aware backpressure.



Maximum weight matching (MWM) is a switch scheduling algorithm and has similar properties as the max-weight scheduling algorithm and backpressure. Similar to the backpressure, there is incompatibility between TCP and MWM \cite{TCP_MWM_switch1}, \cite{TCP_MWM_switch2}. Yet, we consider backpressure routing and scheduling over wireless networks rather than switch scheduling, and we take a holistic approach to address this problem; \ie we propose TCP-aware backpressure to make TCP and backpressure compatible.








\section{Conclusion}\label{sec:conclusion}
We proposed TCP-aware backpressure routing and scheduling to address the incompatibility of TCP and backpressure while exploiting the performance of backpressure routing and scheduling over wireless networks. TCP-aware backpressure is developed by taking into account the behavior of TCP flows, and gracefully combines TCP and backpressure without making any changes to the TCP protocol. Simulations in ns-2 demonstrate that TCP-aware backpressure improves throughput of TCP flows significantly and provides fairness across competing TCP flows.








\bibliographystyle{IEEEtran}
\begin{thebibliography}{}
\bibitem{tass_eph1} L. Tassiulas, A. Ephremides, ``Stability properties of constrained queueing systems and scheduling policies for maximum throughput in multihop radio networks,'' {\em in IEEE Trans. on Auto. Control}, vol.~37(12), Dec. 1992.

\bibitem{tass_eph2} L. Tassiulas, A. Ephremides, ``Dynamic server allocation to parallel queues with randomly varying connectivity,'' {\em in IEEE ToIT}, vol.~39(2), March 1993.

\bibitem{neely_mod} M. J. Neely, E. Modiano, C. Li, ``Fairness and optimal stochastic control for heterogeneous networks,'' {\em in IEEE/ACM ToN}, vol.~16(2), April 2008.

\bibitem{tcp_compound} K.~Tan,J.~Song, Q.~Zhang, M.~Sridharan, ``A compound TCP approach for high-speed and long distance networks,'' {\em in Proc. of IEEE INFOCOM}, Barcelona, Spain, April 2006.

\bibitem{tcp_cubic} S.~Ha, I.~Rhee, L.~Xu, ``CUBIC: a new TCP-friendly high-speed TCP variant,'' {\em in SIGOPS Oper. Syst. Rev.}, vol.~42(5), July 2008.

\bibitem{ns2} The Network Simulator - ns-2, Version 2.35, {\em available at www.isi.edu/nsnam/ns/}.

\bibitem{neely_book} M. J. Neely, ``Stochastic network optimization with application to communication and queueing systems,'' Morgan \& Claypool, 2010.



\bibitem{tcp_aware_bp_tech_rep} H.~Seferoglu, E.~Modiano, ``TCP-aware backpressure routing and scheduling,'' Tech. Report, available at {\em newport.eecs.uci.edu/{\texttildelow}hseferog/, http://www.mit.edu/{\texttildelow}hseferog/}.

\bibitem{tutorial_doyle} M. Chiang, S. T. Low, A. R. Calderbank, J. C. Doyle, ``Layering as optimization decomposition: a mathematical theory of network architectures,'' \emph{in Proceedings of the IEEE}, vol. 95(1), Jan. 2007.

\bibitem{lin_schroff_tutorial} X. Lin, N. B. Schroff, R. Srikant, ``A tutorial on cross-layer optimization in wireless networks,'' {\em in IEEE JSAC}, vol. 24(8), Aug. 2006.

\bibitem{diffmax} H.~Seferoglu, E.~Modiano, ``Diff-Max: separation of routing and scheduling in backpressure-based wireless Networks,'' {\em in Proc. of IEEE INFOFOCM}, Turin, Italy, April, 2013.

\bibitem{locbui} L.~X.~Bui, R.~Srikant, A.~Stolyar, ``A novel architecture for reduction of delay and queueing structure complexity in the back-pressure algorithm,'' {\em in IEEE/ACM Transactions on Networking}, vol.~19(6), Dec. 2011.

\bibitem{NC_meets_TCP} J. K. Sundararajan, D. Shah, M. Medard, M. Mitzenmacher, J. Barros, ``Network coding meets TCP,'' {\em in Proc. of IEEE INFOCOM}, Rio de Janeiro, Brazil, April 2009.

\bibitem{multipath_tcp_toledo} 	S. Gheorghiu, A. L. Toledo, P. Rodriguez, ``Multi-path TCP with network coding for wireless mesh networks,'' {\em in Proc. of IEEE ICC}, Cape Town, South Africa, May 2010.

\bibitem{i2nc} H. Seferoglu, A. Markopoulou, K. K. Ramakrishnan, ``INC: intra- and inter-session network coding for unicast flows in wireless networks,'' {\em in Proc. of IEEE INFOCOM}, Shanghai, China, April 2011.

\bibitem{practical_NC} P. A. Chou, Y. Wu,``Network coding for the Internet and wireless networks,'' {\em in IEEE Signal Proc. Magazine}, vol. 24(5), Sept. 2007.

\bibitem{twsly_tcp} J.~Padhye, V.~Firoiu, D.~Towsley, J.~Kurose, ``Modeling TCP throughput: a simple model and its empirical validation,'' {\em in Proc. of ACM SIGCOMM}, Vancouver, Canada, Sep. 1998.

\bibitem{low_tcp} S.~Low, ``A duality model of TCP and queue management algorithms,'' {\em in IEEE/ACM Transactions on Networking}, vol.~11(4), Aug. 2003.

\bibitem{aodv} C. Perkins, E. Belding-Royer, S. Das, ``Ad hoc on-demand distance vector (AODV) routing,'' {\em RFC 3561, IETF}, July 2003.

\bibitem{fairness_index} R. K. Jain, ``The art of computer systems performance analysis: techniques for experimental design, measurement, simulation, and modeling,'' John Wiley \& Sons, April 1991.

\bibitem{stolyar_greedy} A. L. Stolyar, ``Greedy primal dual algorithm for dynamic resource allocation in complex networks,'' {\em in Queuing Systems}, vol. 54, 2006.

\bibitem{routing_wtht_routes} S. Moeller, A. Sridharan, B. Krishnamachari, O. Gnawali, ``Routing without routes: the backpressure collection protocol,'' {\em in Proc. of ACM IPSN}, Stockholm, Sweden, April 2010.

\bibitem{xpress} R. Laufer, T. Salonidis, H. Lundgren, P. L. Guyadec, ``XPRESS: a cross-layer backpressure architecture for wireless multi-hop networks,'' {\em in Proc. of ACM MobiCom}, Las Vegas, NV, Sep. 2011.

\bibitem{javidi_diversity} A. A. Bhorkar, T. Javidi, A. C. Snoereny, ``Achieving congestion diversity in wireless ad-hoc networks,'' {\em in Proc. of IEEE INFOCOM}, Shanghai, China, April 2011.

\bibitem{choumas} K. Choumas, T. Korakis, I. Koutsopoulos, L. Tassiulas, ``Implementation and end-to-end throughput evaluation of an IEEE 802.11 compliant version of the enhanced-backpressure algorithm,'' {\em in Proc. of TridentCom},  Thessaloniki, Greece, June 2012.

\bibitem{backpressure_for_icns} J. Ryu, V. Bhargava, N. Paine, S. Shakkottai, ``Backpressure routing and rate control for ICNs,'' {\em in Proc. of ACM MobiCom}, Chicago, IL, Sep. 2010.

\bibitem{DiffQ} A. Warrier, S. Janakiraman, S. Ha, I. Rhee, ``DiffQ: practical differential backlog congestion control for wireless networks,'' {\em in Proc. of IEEE INFOCOM}, Rio de Janerio, Brazil, April 2009.

\bibitem{umut_stolyar} U. Akyol, M. Andrews, P. Gupta, J. Hobby, I. Saniee, A. Stolyar, ``Joint scheduling and congestion control in mobile ad-hoc networks,'' {\em in Proc. of IEEE INFOCOM}, Phoenix, AZ, April 2008.

\bibitem{horizon} B. Radunovic, C. Gkantsidis, D. Gunawardena, P. Key, ``Horizon: balancing TCP over multiple paths in wireless mesh network,'' {\em in Proc. of ACM MobiCom}, San Francisco, CA, Sep. 2008.

\bibitem{ghaderi_tcp_theoric} J. Ghaderi, T. Ji, R. Srikant, ``Connection-level scheduling in wireless networks using only MAC-layer information,'' {\em in Proc. of IEEE INFOCOM}, Orlando, FL, March 2012.

\bibitem{TCP_MWM_switch1} A. Shpiner, I. Keslassy, ``Modeling the interactions of congestion control and switch scheduling,'' {\em in Computer Networks}, vol. 55(6), April 2011.

\bibitem{TCP_MWM_switch2} P. Giaccone, E. Leonardi, F. Neri, ``On the interaction between TCP-like sources and throughput-efficient scheduling policies,'' {\em in Elsevier}, 2013.

\bibitem{gamma_ksi_approximization} Y. Yi, A. Prouti\`{e}re, and M. Chiang, ``Complexity in wireless scheduling: impact and tradeoffs,'' {\em in Proc. of ACM MobiHoc}, Hong Kong, China, May 2008.


\end{thebibliography}



\section*{Appendix A: Proof of Theorem~\ref{theorem1}}
The proof of Theorem~\ref{theorem1} directly follows from  (or -) approximation in \cite{gamma_ksi_approximization}, \cite{neely_book}. We provide the proof in this section for completeness. Let  be the optimal decision when  in Eq.~(\ref{eq:per_flow_difference}) (note that this is the classical backpressure), while  be the decision when . If the following inequality holds, the policy that makes decision based on  stabilizes the queues.
 where  is a finite constant. Let us first show that Eq.~(\ref{eq:app_1}) holds. Consider the inequality; . This inequality holds, because   . Also, considering that  is the optimal decision when the backlog difference is , the term    should be greater than   . Therefore, the inequality is expressed as;  . By adding and removing terms, and noting that  and  such that , the following holds;
  Eq.~(\ref{eq:app_7}) verifies that Eq.~(\ref{eq:app_1}) holds considering that     .
Note that Eq.~(\ref{eq:app_7}) is equivalent to;

Now, let us define the Lyapunov function as; , where  and  evolves according to Eq.~(\ref{eq:queue_U}). Let the Lyapunov drift be , which is equal to  .
Using the fact that , we have;    . Noting that there always exist a finite constant  such that   , we have;

When we insert Eq.~(\ref{eq:app_8}) in Eq.~(\ref{eq:lyap_6}), we have

If the vector of arrival rates are interior to the stability region, there always exist  such that  . Substituting this into Eq.~(\ref{eq:lyap_7});

The time average of Eq.~(\ref{eq:lyap_8}) yields;
 which shows that the time average of  is bounded. Thus, TCP-aware backpressure stabilizes the network and the total average backlog is bounded.





\end{document}
