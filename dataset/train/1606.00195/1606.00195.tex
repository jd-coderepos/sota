\documentclass[11pt]{article}
\usepackage[sort&compress,numbers]{natbib}\usepackage{fullpage,bm,times}
\usepackage{amsmath,amssymb,latexsym, amsopn, amsfonts}
\usepackage[boxed,ruled,vlined,algosection,linesnumbered]{algorithm2e}
\usepackage{titlesec}
\usepackage{caption}
\usepackage{graphicx}
\usepackage{wrapfig,frame}
\usepackage{framed}\usepackage{xcolor}
\usepackage{enumitem}


\newcommand{\polylog}{\mathrm{polylog}}
\newcommand{\bigO}{\mathrm{O}}
\newcommand{\remove}[1]{}
\newcommand{\rep}{state}
\newcommand{\config}{config}
\newcommand{\assert}{lemma}



\newcommand{\noReconfig}{noReco}
\newcommand{\configEstab}{estab}
\newcommand{\notif}{prp}
\newcommand{\notifSet}{notifSet}

\newtheorem{theorem}{Theorem}[section]
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{claim}[theorem]{Claim}
\newtheorem{assertion}[theorem]{Assertion}
\newtheorem{remark}{Remark}
\newtheorem{corollary}[theorem]{Corollary}
\newtheorem{definition}{Definition}[section]
\newenvironment{proof}{\noindent{\bf Proof.}}{\hfill}
\newtheorem{argument}{Argument}[section]
\newenvironment{proofsketch}{\noindent{\bf Proof Sketch.}}{\hfill}

\newcommand{\boldsubparagraph}[1]{\subparagraph{\bf #1}}
\titleformat*{\subparagraph}{\it \raggedleft}








\begin{document}
\begin{titlepage}
\renewcommand{\thefootnote}{\fnsymbol{footnote}}



\title{Self-Stabilizing Reconfiguration\\ \large{(Technical Report)}
}



\author{Shlomi Dolev~\footnote{Department of Computer Science, Ben-Gurion University of the Negev, Beer-Sheva, Israel. Email: {\tt dolev@cs.bgu.ac.il} }
\and Chryssis Georgiou~\footnote{ Department of Computer Science, University of Cyprus, Nicosia, Cyprus. Email: {\tt {\char '173}chryssis, imarco01{\char '175} @cs.ucy.ac.cy} . Supported by the University of Cyprus.} \and~Ioannis Marcoullis \and Elad M.\ Schiller~\footnote{Department of Computer Science and Engineering, Chalmers University of Technology, Gothenburg, SE-412 96, Sweden. Email: {\tt elad@chalmers.se}.}}

\date{}

\maketitle

\thispagestyle{empty}




\begin{abstract}
Current reconfiguration techniques are based on starting the system in a consistent configuration, in which all participating entities are in a predefined state. Starting from that state, the system must preserve consistency as long as a predefined churn rate of processors joins and leaves is not violated, and unbounded storage is available.
Many working systems cannot control this churn rate and do not have access to unbounded storage. System designers that neglect the outcome of violating the above assumptions may doom the system to exhibit illegal behaviors. We present the first automatically recovering reconfiguration scheme that recovers from transient faults, such as temporal violations of the above assumptions. Our self-stabilizing solutions regain safety automatically by assuming temporal access to reliable failure detectors. Once safety is re-established, the failure detector reliability is no longer needed. Still, liveness is conditioned by the failure detector's unreliable signals. We show
that our self-stabilizing reconfiguration techniques can serve as the basis for the
implementation of several dynamic services over message passing systems. 
Examples include  
self-stabilizing reconfigurable virtual synchrony, which, in turn, can be used for implementing a self-stabilizing  
reconfigurable state-machine replication and self-stabilizing reconfigurable emulation of shared memory.
\vspace{2em}

\noindent {\bf Keywords:} Self-stabilization, Dynamic Participation, Reconfiguration, Virtual Synchrony, State Machine Replication.\vspace{2em}









\end{abstract}




\end{titlepage}

\renewcommand{\thefootnote}{\arabic{footnote}}







\section{Introduction} 
\paragraph{Motivation.} 
We consider distributed systems that work in dynamic asynchronous environments, such as a shared storage system~\cite{DBLP:journals/cacm/MusialNS14}. Quorum configurations~\cite{DBLP:journals/dc/PelegW97,DBLP:series/synthesis/2012Vukolic}, 
i.e., set of active processors (servers or replicas), are typically used to provide services to the participants of the system. Since over time, the (quorum) configuration may gradually lose active participants due to voluntary leaves and stop failures, there is a need to allow the participation of newly arrived processors and from time to time to \emph{reconfigure} so that the new configuration is built on a more recent participation group. Over the last years, 
a number of reconfiguration techniques have been proposed, mainly for state machine replication and emulation of atomic memory 
(e.g.,~\cite{DynaStore,birmanMR2010,DBLP:journals/corr/BortnikovCPRSS15,RAMBO,DBLP:journals/eatcs/AguileraKMMS10,spiegelmandynamic,DBLP:journals/sigact/LamportMZ10,DBLP:conf/wdag/AttiyaCEKW15,DBLP:conf/wdag/GafniM15,DBLP:conf/wdag/JehlVM15,Baldoni09,DBLP:journals/jpdc/ChocklerGGMS09}). These reconfiguration techniques are based on starting the system in a consistent configuration, in which all processors are in their initial state. Starting from that state, the system must preserve consistency as long as a predefined churn rate of processors' joins and leaves is not violated and unbounded storage is available. Furthermore, they do not tolerate {\em transient faults} that can cause an arbitrary corruption of the system's state.


Many working systems cannot control their churn rate and do not have access to unbounded storage. System designers that neglect the outcome of violating the above assumptions may doom the system to forever exhibit a behavior that does not satisfy the system requirements. Furthermore, the dynamic and difficult-to-predict nature of distributed systems gives rise to many fault-tolerance issues and requires efficient solutions. Large-scale message passing networks are asynchronous and they are subject to transient faults due to hardware or software temporal malfunctions, short-lived violations of the assumed failure rates or violation of correctness invariants, such as the uniform agreement among all current participants about the current configuration. Fault tolerant systems that are {\em self-stabilizing}~\cite{D2K} can recover after the occurrence of transient faults (as long as the program's code is still intact).

\remove{
[[[Leslie Lamport once said: ``A distributed system is one in which the failure of a computer you did not even know existed can render your own computer unusable.''~\cite{Lamport83} This is proven in many scenarios in particular in the scope of consensus and the impossibility that consider asynchronous systems by Fischer, Lynch, and Paterson~\cite{FLP}. Fortunately, working distributed systems can overcome a single point of failure using their inherent redundancies with respect to the number of connected computing entities. Therefore, a properly programmed distributed system can exhibit a more dependable behavior than a system with a single computer. We consider distributed systems that work in dynamically changing asynchronous environments, such as a shared storage system~\cite{DBLP:journals/cacm/MusialNS14}.  Our blueprint for self-stabilizing reconfigurable distributed systems can withstand a temporal violation of such assumptions, and recover once conditions are resumed. Temporal violations of the assumption made for preserving safety can be the outcome of many reasons that we cannot anticipate upfront, for example, severe environment, and input load conditions or even a cyber-security attacks that had occurred. Our self-stabilizing solutions regain safety automatically by assuming temporal access to failure detectors that are reliable. Once safety is re-established the failure detector reliability is no longer of need; still liveness is conditioned by the failure detector unreliable signals.  We show that our self-stabilizing reconfiguration techniques are the basis for the implementation of many dynamic services over message passing systems, such as self-stabilizing reconfigurable emulation of shared memory and self-stabilizing virtually synchrony, which can be the basis for self-stabilizing state-machine replication.
We consider a dynamic system of entities named \emph{processors} that join and leave, say, via fail-stop, at a bounded churn rate. The system task is to establish a (quorum) configuration, which is a set of processors that provides (quorum) services to the system's participants, which is a set of active processors that are aware of the presence that they each have in the system (or had before they failed and stopped). Since over time, the (quorum) configuration may gradually lose active participants due to voluntary leaves and stop failures, there is a need to allow the participation of newly arrived processor and from time to time to \emph{reconfigure (the quorum)} so that the new configuration is built on a more recent participation group.
This work considers the self-stabilization design criteria by showing that, starting from an arbitrary system state and within a bounded recovery period, the system always satisfies the tasks requirements. We note that the challenge here is to \emph{always} recover and then to \emph{forever} exhibit a legal behavior. Therefore, unlike the literature that considers the (quorum) reconfiguration problem, we cannot assume that the current the (quorum) configuration includes the majority of the system participants. This paper takes into account several practical details, such as inconsistent information about the current configuration and participant set, which are difficult to detect and avoid using bounded amount of local storage and message size. The concept of random starting state of the system allows us to overcome the inherent difficulties
In the presence of {\em transient failures}, the system may be brought to an {\em arbitrary state} where each processor may have corrupt and inconsistent local information about the current system configuration. 
Our self-stabilizing (quorum) reconfiguration algorithm liberates the application designer from dealing with low-level complications, such as the possible violation of the assumption about the stop failure rate, and provide an important level of abstraction. Consequently, the application design can easily focus on its task and knowledge-driven aspects.]]]
}

\paragraph{Our contributions and approach.}
We present the first automatically recovering reconfiguration scheme that recovers from transient faults, such as temporary violations of the predefined churn rate or the unexpected activities of processors and communication channels. Our blueprint for self-stabilizing reconfigurable distributed systems can withstand a temporal violation of such assumptions, and recover once conditions are resumed. It achieves this with only a bounded amount of local storage and message size. Our self-stabilizing solutions regain safety automatically by assuming temporal access to reliable failure detectors. Once safety is re-established, the failure detector reliability is no longer needed; still, liveness is conditioned by the failure detector's unreliable signals.  We now overview our approach.\vspace{.3em} 

\noindent{\em Reconfiguration scheme:} Our scheme comprises of two layers that appear as a single ``black-box" module to an application that uses the reconfiguration service. The objective is to provide to the application a {\em conflict-free} configuration,
such that no two alive processors consider different configurations. The first layer, called {\em Reconfiguration Stability Assurance} or {\em recSA} for short (detailed in Section~\ref{sec:RSA}), is mainly responsible for detecting configuration conflicts (that could be a result of transient faults). It deploys a {\em brute-force} technique for converging to a conflict-free new configuration. 
It also employs another technique for {\em delicate} configuration replacement when a processor notifies that it wishes to replace the current configuration with a new set of participants. 
For both techniques, processors use a failure detector (detailed in Section~\ref{sec:settings}) to obtain membership information, and configuration convergence is reached when failure detectors have temporal reliability. 
Once a uniform configuration is installed, the failure detectors' reliability is no longer needed and from then on our liveness conditions consider unreliable failure detectors.  
The decision for requesting a delicate reconfiguration is controlled by the other layer, called {\em Reconfiguration Management} or {\em recMA} for short (detailed in Section~\ref{sec:reconMan}).

Specifically, if a processor suspects that the dependability of the current configuration is under jeopardy, it seeks to obtain a majority approval from the alive {\em members} of the current configuration, and request a (delicate) reconfiguration from \emph{recSA}. Moreover, in the absence of such a majority (e.g., configuration replacement was not activated ``on time'' or the churn assumptions were violated), the {\em recMA} can aim to control the recovery via an \emph{recSA} reconfiguration request. Note that the current participant set can, over time, become different than the configuration member set. As new members arrive and others leave, changing the configuration based on system membership would imply a high frequency of (delicate) reconfigurations, especially in the presence of high churn. We avoid unnecessary reconfiguration requests by requiring a weak liveness condition:  if a majority of the configuration set has not collapsed, then there exists at least one processor that is known to trust this majority in the failure detector of each alive processor.
Such active configuration members can aim to replace the current configuration with a newer one (that would provide an approving majority for prospective reconfigurations) without the use of the brute-force stabilization technique. \vspace{.3em}
\remove{Specifically, if a processor suspects that the dependability of the current configuration is under jeopardy, it seeks to obtain a majority approval from the alive {\em members} of the current configuration, and request a (delicate) reconfiguration from \emph{recSA}. Moreover, in the absence of such a majority (e.g., configuration replacement was not activated ``on time'' or the churn assumptions were violated), the {\em recMA} can aim to control the recovery via an \emph{recSA} reconfiguration request. Note that the current participant set can, over time, become different than the configuration member set. As new members arrive and other go, changing the configuration based on system membership would imply a high frequency of (delicate) reconfiguration, especially in the presence of high churn. Note that we avoid unnecessary reconfiguration requests by requiring a weak liveness condition: if a majority of the configuration set has not collapsed, then there exists at least one processor that is known to trust this majority in the failure detector of each alive processor.  
}


\noindent{\em Joining mechanism:} We complement our reconfiguration scheme with a self-stabilizing joining mechanism (detailed in Section~\ref{sec:join}) that manages and controls the inclusion of new processors into the system. Here extra care needs to be taken so that newly joining processors do not ``contaminate" the system state with stale information (due to arbitrary faults). For this, together with other techniques, we follow a snap-stabilizing data link protocol (see Section~\ref{sec:settings}). We have designed our joining mechanism so that the decision of whether new members should be included in the system or not is {\em application-controlled}. In this way, the churn (regarding new arrivals) can be ``fine-tuned" based on the application requirements; we have modeled this
by having joining processors obtaining approval from a majority of the members of the current configuration (if no reconfiguration is taking place). These, in turn, provide such approval if the application's (among other) criteria are met. 
We note that in the event of transient faults, such as an unavailable approving majority, {\em recSA} ensures recovery via brute-force stabilization that includes all alive processors.\vspace{.3em}

\noindent {\em Applications:} We demonstrate the usability and modularity of our self-stabilizing reconfiguration scheme and joining mechanism by using them to develop self-stabilizing dynamic participation versions of several algorithms: a label
algorithm for providing a bounded self-stabilizing labeling scheme (Section~\ref{sec:label}); a self-stabilizing counter increment algorithm (Section~\ref{sec:counter}); a self-stabilizing virtual synchrony algorithm that leads to self-stabilizing state machine replication and a self-stabilizing MWMR emulation of shared memory (Section~\ref{sec:VS}). 
These algorithms are derived by combining our reconfiguration scheme and joining mechanism with the corresponding self-stabilizing algorithms developed for static membership systems in~\cite{SSVS}.

\remove{provides support for two types of reconfiguration: {\em brute-force} and {\em delicate}. The objective is to maintain a consistent configuration set (a set of processors). If at least two different 
configuration sets are detected in the system, a result of a transient fault, then a brute-force reconfiguration is triggered (as we explain in Section~\ref{}, there are also other cases that can lead to such a reconfiguration).   
The system state is initialized and the procedure attempts to converge to a new configuration set, where all alive and connected processors are {\em members} of this configuration (belong in the configuration set). This procedure, besides providing self-stabilization, it also helps the system to recover when the churn assumption is temporarily violated. A delicate reconfiguration is triggered by a corresponding request from coming from the second procedure, called {\em Reconfiguration Management}. 
The delicate reconfiguration preserves the system state and attempts to converge to a configuration set proposed by the processor(s) triggering this type of reconfiguration (as we explain in Section~\ref{}, more than one processors may request such a configuration). 
A processor that suspects that the dependability of the current configuration is jeopardized, and after it obtains an approval of a majority of the members of the current configuration may trigger
a delicate reconfiguration; these checks are done at the Management procedure (this reconfiguration type essentially replaces
one configuration with another when the system is under ``normal'' operation). Note that the set of members of a configuration is not necessarily the same with the current set of system participants. As members may came and go, changing the configuration based on system membership would imply a high frequency of (delicate) reconfiguration, especially in the presence of high churn. Instead, the system uses a configuration (for decision making and coordination) despite the change of the system participants, and it proceeds to a new (delicate) reconfiguration only when this is believed to be necessary. For the Assurance procedure to converge (for both brute-force and delicate types) to a single configuration set we require a {\em temporal convergence} of the Failures Detectors used by the processors for estimating the set of system participants (the Failure Detector considered in this work is detail in Section~\ref{sec:settings}). Even under this liveness condition, the formulation and correctness of the Assurance procedure is non-trivial as...[[@@Elad, please add some main challenges @@]]. Once a configuration set is agreed and installed, then the reliability of the Failure Detectors can be relaxed. 
}

\paragraph{Related work.}
\sloppy{As mentioned, existing solutions for providing reconfiguration in dynamic systems, such as~\cite{RAMBO} and~\cite{DynaStore}, do not consider  transient faults and self-stabilization, because their correctness proofs (implicitly) depend on a coherent start~\cite{DBLP:journals/cacm/MusialNS14} and also assume that fail-stops can never prevent the (quorum) configuration to facilitate configuration updates.}
They also often use unbounded counters for ordering consensus messages (or for shared memory emulation) and by that facilitate configuration updates, e.g.,~\cite{RAMBO}. 
Our self-stabilizing solution recovers after the occurrence of transient faults, which we model as an arbitrary starting state, and guarantees a consistent configuration that provides (quorum) services, e.g., allowing reading from and writing to distributed shared memory objects, and at the same time managing the configuration providing these services.


Significant amount of research was dedicated in characterizing the fault-tolerance guarantees that can be provided by
difference quorum system designs; see~\cite{DBLP:series/synthesis/2012Vukolic} for an in depth discussion. 
In this paper we use majorities, which is regarded as the simplest form of a quorum system (each set composed of a majority of the processors is a quorum). 
Our reconfiguration scheme can be modified to support more complex, quorum systems, as long as processors have access to a mechanism (a function actually) that given a set of processors can generate the specific quorum system. 
Another important design decision is \emph{when} a reconfiguration (delicate in our case) must take place; see the related discussion
in~\cite{DBLP:journals/cacm/MusialNS14}. One simple decision would be to reconfigure when a fraction (e.g., 1/4th) of the members of a configuration appear to have failed. More complex decisions could use prediction mechanisms (possibly based on statistics). 
This issue is outside of the scope of this work; however, we have designed our reconfiguration scheme (specifically  the {\em recMA} layer) to be able to use any decision mechanism imposed by the application (via an application interface).

\remove{

}





\section{System Settings}\label{sec:settings} \label{s:sys}
\paragraph{Processing entities.} We consider an asynchronous message-passing system of processors. 
Each processor  has a unique identifier, , taken from a totally-ordered set of identifiers . 
The number of live and connected processors at any time of the computation is bounded by some  such that .  We refer to such processors as \emph{active}. 
We assume that the processors have knowledge of the upper bound , but not of the actual number of active processors.
Processors may stop-fail by crashing; a processor may crash at any point without warning, and in this event a crashed processor takes no further steps and never rejoins the computation. 
(For readability sake, we model rejoins as transient faults rather than considering them explicitly. 
Self-stabilization inherently deals with rejoins by regarding the past join information as possibly corrupted.)
New processors may join the system (using a joining procedure) at any point in time with an identifier drawn from , such that this identifier is only used by this processor forever.
A \emph{participant} is an active processor that has joined the computation.
Note that  accounts for all active processors, both participants and those that are still joining. \vspace{.3em}



\paragraph{Communication.} The network topology is that of a fully connected graph, and links have a bounded capacity .
Processors exchange low-level messages called \emph{packets} to enable a reliable delivery of high level
\emph{messages}. 
Packets sent may be lost, reordered, or duplicated but not arbitrarily created, although the channels may initially (after transient faults) contain stale packets, which due to the boundedness of the channels are also bounded in a number that is in .
We assume the availability of self-stabilizing protocols for reliable FIFO end-to-end message delivery over unreliable channels with bounded capacity, such as the ones of~\cite{DBLP:journals/ipl/DolevDPT11} or~\cite{DBLP:conf/sss/DolevHSS12}.


Specifically, when processor  sends a packet, , to processor , the operation  inserts a copy of  into the FIFO queue representing the communication channel from  to . 
Since links are bounded in capacity, the new packet might be omitted or some already sent packet may be lost. 
While we assume that packets can spontaneously be omitted, i.e., lost from the channel, a packet that is sent infinitely often is received infinitely often. Namely, the communication channels provide \textit{fair communication}.
The policy of acknowledging is that acknowledgments are sent only when a packet arrives, and not spontaneously. 
Packet  is retransmitted until more than the total capacity acknowledgments arrive, and then  starts being transmitted. 
This forms an abstraction of token carrying messages between the two processors.
In this way the two processors (sender and receiver) can continuously exchange a ``token''.
We use this token exchange technique to implement a {\em heartbeat} for detecting  whether a processor is active or not; when a processor in no longer active, the token will not be returned back to the other processor.


Due to the possibility of arbitrary faults and of the dynamic nature of the network, we cannot assume that processors have knowledge of the identifier of the processor with which they are communicating.
We employ two anti-parallel data-link protocols, where every packet of one data-link is identified by the identifiers of the sender and receiver of the data link it participates in. 
For example, if the communication link connects  and , packets of the data link in which  () acts as the sender that traverse from  to  ( to ) are identified by the label  (), while the label of packets traversing from  () are extended by adding  () to the label to form the label  (, respectively).  Any packet  arriving to  () where  () is ignored. Thus, eventually the data link in which  is the sender is implemented by packets with label  () traversing from  to  ( to ). The analogous holds for the packets implementing the data link in which  serves as the sender. Thus, both parties will eventually know the identifier of the other party and regard the token of the data link in which the sender has the greater identifier among them, to be the used token. 

Using the underlying packet exchange protocol described, a processor  that has received a packet from some processor  which did not belong to 's failure detector, engages in a two phase protocol with  in order to ``clean'' their intermediate link. 
This is done before any messages are delivered to the algorithms that handle reconfiguration, joining and applications.
We follow the snap-stabilizing data link protocol detailed in \cite{DBLP:journals/tcs/DolevT09}.
A \emph{snap-stabilizing} protocol is one which allows the system (after faults cease) to behave according to its specification upon its first invocation.
We require that every data-link established between two processors is initialized and cleaned straight after it is established.
In contrast to~\cite{DBLP:journals/tcs/DolevT09} where the protocol is run on a tree and initiated from the root, our case requires that each pair of processors takes the responsibility of cleaning their intermediate link.
Snap-stabilizing data links do not ignore signals indicating the existence of new connections, possibly some physical carrier signal from the port. 
In fact, when such a connection signal is received by the newly connected parties, they start a communication procedure that uses the bound on the packet in transit and possibly in buffers too, to clean all unknown packets in transit, by repeatedly sending the same packet until more than the round trip capacity acknowledgments arrive.\vspace{.3em}









\paragraph{-failure detector.} We consider the -failure detector that uses the token exchange and heartbeat detailed above.
This is an extension of the -failure detector used in \cite{Blanchard2013SSPaxos}. 
It allows each processor  to order other processors according to how recently they have communicated.
Each processor  maintains an ordered heartbeat count vector , with an entry corresponding to each processor  that exchanges the token (i.e., sends a heartbeat) with .
Specifically, whenever  receives the token from , it sets the count corresponding to  to  and increments the count of every other processor by one.
In this way,  manages to rank every processor  according to the token exchanges that it has performed with  in relation to the token exchanges that it has performed with some other processor .
So the processor that has most recently contacted  is the first in 's vector.

The technique enables  to obtain an estimate on the number of processors  that are active in the system; . Assuming that  is the most recently crashed processor, then every processor other than  will eventually exchange the token with  many times, and their heartbeat count will be set to zero, while 's will be increasing continuously.
Eventually, every other processor's count (given they remain alive and communicating) will become lower than 's and  will be ranked last in .
Moreover, while difference between heartbeat counts of non-crashed processors does not become large, the difference of these counts and that of  increases to form a significant ever-expanding ``gap''.
The last processor before the gap is the  processor and this provides an estimate on the number of active processors.
Since there are at most  processors in the computation at any given time, we can ignore any processors that rank below the  vector entry.
If, for example, the first 30 processors in the vector have corresponding counters of up to 30, then the  will have a count much greater than that, say 100; so  will be estimated at 30.
This estimation mechanism is suggested in \cite{DBLP:journals/cjtcs/DolevH97} and in \cite{DBLP:journals/tmc/DolevSW06}. \\








\paragraph{The interleaving model and self-stabilization.}
A program is a sequence of {\em (atomic) steps}. Each atomic step starts with local computations and ends with a communication operation, i.e., packet  or . We assume the standard interleaving model where at most one step is executed in every given moment.  An input event can either be the arrival of a  packet or a periodic timer triggering  to (re)send. Note that the system is asynchronous and the rate of the timer is totally unknown. The {\em state}, , consists of 's variable values and the content of 's incoming communication channels. A step executed by  can change the state of . The tuple of the form  is used to denote the {\em system state}. An {\em execution (or run)}  is an alternating sequence of system states  and steps , such that each , except the initial system state , is obtained from  by the execution of . A practically infinite execution is an execution with many steps, where many is defined to be proportional to the time it takes to execute a step and the life-span time of a system. The system's task is a set of executions called {\em legal executions} () in which the task's requirements hold. An algorithm is {\em self-stabilizing} with respect to  when every (unbounded) execution of the algorithm has a suffix that is in .



\remove{
\noindent{\bf The interleaving model and self-stabilization.}
Every processor, , executes a program that is a sequence of {\em (atomic) steps}, where a step starts with local computations and ends with a single communication operation, which is either  or  of a packet. For ease of description, we assume the interleaving model, where steps are executed atomically, a single step at any given time. An input event can be either the receipt of a packet or a periodic timer triggering  to (re)send. Note that the system is asynchronous and the rate of the timer is totally unknown. 
The {\em state}, , of a node  consists of the value of all the variables of the node including the set of all incoming communication channels. The execution of an algorithm step can change the node's state. The term {\em system state} is used for a tuple of the form , where each  is the state of node  (including messages in transit for ). We define an {\em execution (or run)}  as an alternating sequence of system states  and steps , such that each system state , except the initial system state , is obtained from the preceding system state  by the execution of the steps .
A practically infinite execution is an execution with many steps (and iterations), where many is defined to be proportional to
the time it takes to execute a step and the life-span time of a system. 
We define the system's task by a set of executions called {\em legal executions} () in which the task's requirements hold,
we use the term {\em safe system state} for any system state in .
An algorithm is {\em self-stabilizing} with relation to the task  when every (unbounded) execution of the algorithm reaches a safe system state with relation to the algorithm and the task. An algorithm is {\em practically stabilizing} with relation to the task
 if in any practically infinite execution a safe system state is reached.}




\section{Self-stabilizing Reconfiguration Scheme}
\label{sec:reconf}


\begin{figure}[t!]
\center
\captionsetup{margin=10pt,font=small,labelfont=bf}
\setlength{\unitlength}{4144sp}\begingroup\makeatletter\ifx\SetFigFont\undefined \gdef\SetFigFont#1#2#3#4#5{\reset@font\fontsize{#1}{#2pt}\fontfamily{#3}\fontseries{#4}\fontshape{#5}\selectfont}\fi\endgroup \begin{picture}(5457,3489)(2227,-5923)
\thinlines
{\color[rgb]{0,0,0}\put(2476,-5506){\framebox(4950,521){}}
}{\color[rgb]{0,0,0}\put(3241,-3166){\vector( 0,-1){720}}
}{\color[rgb]{0,0,0}\put(2471,-3166){\framebox(4955,720){}}
}{\color[rgb]{0,0,0}\put(6031,-4435){\framebox(1260,537){}}
}{\color[rgb]{0,0,0}\put(2611,-4421){\framebox(1260,523){}}
}{\color[rgb]{0,0,0}\put(4951,-4983){\vector( 0, 1){1817}}
}{\color[rgb]{0,0,0}\put(6661,-3166){\vector( 0,-1){720}}
}{\color[rgb]{0,0,0}\put(6661,-4434){\vector( 0,-1){540}}
}{\color[rgb]{0,0,0}\put(4951,-4156){\vector( 1, 0){1082}}
}{\color[rgb]{0,0,0}\put(4951,-4156){\vector(-1, 0){1075}}
}{\color[rgb]{0,0,0}\put(3241,-4421){\vector( 0,-1){565}}
}{\color[rgb]{0,0,0}\put(2239,-5911){\dashbox{57}(5433,2250){}}
}\put(4951,-5298){\makebox(0,0)[b]{\smash{{\SetFigFont{9}{10.8}{\rmdefault}{\mddefault}{\updefault}{\color[rgb]{0,0,0}Reconfiguration Stability Assurance}}}}}
\put(4948,-2858){\makebox(0,0)[b]{\smash{{\SetFigFont{9}{10.8}{\rmdefault}{\mddefault}{\updefault}{\color[rgb]{0,0,0}Application}}}}}
\put(3241,-4336){\makebox(0,0)[b]{\smash{{\SetFigFont{9}{10.8}{\rmdefault}{\mddefault}{\updefault}{\color[rgb]{0,0,0}Management}}}}}
\put(6661,-4111){\makebox(0,0)[b]{\smash{{\SetFigFont{9}{10.8}{\rmdefault}{\mddefault}{\updefault}{\color[rgb]{0,0,0}Joining}}}}}
\put(6661,-4336){\makebox(0,0)[b]{\smash{{\SetFigFont{9}{10.8}{\rmdefault}{\mddefault}{\updefault}{\color[rgb]{0,0,0}Mechanism}}}}}
\put(3241,-4111){\makebox(0,0)[b]{\smash{{\SetFigFont{9}{10.8}{\rmdefault}{\mddefault}{\updefault}{\color[rgb]{0,0,0}Reconfiguration}}}}}
\put(2791,-3526){\makebox(0,0)[b]{\smash{{\SetFigFont{8}{9.6}{\rmdefault}{\mddefault}{\itdefault}{\color[rgb]{0,0,0}}}}}}
\put(7111,-3526){\makebox(0,0)[b]{\smash{{\SetFigFont{8}{9.6}{\rmdefault}{\mddefault}{\itdefault}{\color[rgb]{0,0,0}}}}}}
\put(7156,-4741){\makebox(0,0)[b]{\smash{{\SetFigFont{8}{9.6}{\rmdefault}{\mddefault}{\itdefault}{\color[rgb]{0,0,0}}}}}}
\put(2881,-4741){\makebox(0,0)[b]{\smash{{\SetFigFont{8}{9.6}{\rmdefault}{\mddefault}{\itdefault}{\color[rgb]{0,0,0}}}}}}
\put(4501,-4561){\makebox(0,0)[b]{\smash{{\SetFigFont{8}{9.6}{\rmdefault}{\mddefault}{\itdefault}{\color[rgb]{0,0,0}}}}}}
\put(4501,-4786){\makebox(0,0)[b]{\smash{{\SetFigFont{8}{9.6}{\rmdefault}{\mddefault}{\itdefault}{\color[rgb]{0,0,0}}}}}}
\put(4951,-5776){\makebox(0,0)[b]{\smash{{\SetFigFont{10}{12.0}{\rmdefault}{\mddefault}{\updefault}{\color[rgb]{0,0,0}Self-stabilizing Reconfiguration Scheme}}}}}
\end{picture}








\caption{
The reconfiguration scheme modules internal interaction and the interaction with the application. 
The Reconfiguration Stability Assurance () layer provides information on the current configuration and on whether a reconfiguration is not taking place using the  and  interfaces.
This is based of local information.
The Reconfiguration Management () layer uses the prediction mechanism  which is application based to evaluate whether a reconfiguration is required.
If a reconfiguration is required,  initiates it with .
Joining only proceeds if a configuration is in place and if no reconfiguration is taking place.
When the joining mechanism has received a permission to access the application (using  ) it can then join via .
The direction of an arrow from a module  to a module  illustrates the transfer of the specific information from  to .
}

\label{fig:modules}
\end{figure}

The reconfiguration scheme is composed of the Reconfiguration Stability Assurance () layer (Section~\ref{sec:RSA}), the Reconfiguration Management () layer (Section~\ref{sec:reconMan}), and is accompanied by the Joining Mechanism (Section~\ref{sec:join}).
Figure~\ref{fig:modules} depicts the interaction between the modules and with the application. 
The Reconfiguration Stability Assurance () layer ensures that participants eventually have a common configuration set.
It also introduces processors that want to join the computation and provides information on the current configuration and on whether a reconfiguration is not taking place using the  and  interfaces, respectively.

The Reconfiguration Management () layer strives to maintain a majority of active processors of the configuration set, to this end, and may also request a reconfiguration from  via the  interface. 
This is done when a configuration majority is suspected as collapsed or if a majority of active processor configuration members appears to require a reconfiguration based on some application-defined prediction function ().
A joining mechanism gives the application the leverage required to control participation and ensure that processors enter the computation with the most recent state.
A joiner becomes a participant via  only if  of a majority of configuration members is reported as . 
We now proceed with the details. 





\remove{

\subsection{The system reconfiguration task}
We refer to the \emph{(quorum) configuration} as a bounded size set of processors, which we name .~\footnote{In the context of self-stabilization, the term (quorum) configuration must not be confused with the term (system) configuration, which we, therefore, call system state in this paper.} We say that the system has a valid configuration, i.e., \emph{conflict-free} when no two processors that are active in the system store different values in their  variables. Note that the system also prohibits from  to have the empty set for a value. The system assigns the symbol  to  whenever it detects a configuration conflict and is thus in the process of \emph{configuration reset}. By the end of the reset process, the system shall store in all  variables identical and valid configuration values. Note that the reset configuration process is recovery strategy from transient faults specifies that the above requirement is to hold \emph{eventually}. Namely, the configuration reset process might need several rounds until a single value is selected. We allow additional (temporary) synchrony conditions. These conditions refer to system states in which all active processors have identical views on the sets of trusted processors, i.e., the ones that they do not suspect to be inactive in the system. These views shall include only active processors and every active processor shall not be suspected to be inactive. Moreover, the views shall not change during the system run (until the recovery period is over). The distributed computer literature calls these sets failure detectors. We note that our requirements consider failure detectors that are \emph{eventually} and \emph{temporarily} reliable, because once the system is configuration-conflict-free, there is no need for the above recovery strategy that is designed to recover automatically after the occurrence of transient faults.
 
Once the system is conflict-free, only \emph{(system) participants} can call for the establishment of new configurations, using the  interface, where  is a non-empty participant set that one of the existing participants proposes to replace with the current configuration. We note that even though  is a non-empty participant set when calling , it can be that at a later time, some (or perhaps all) of 's members are no longer active in the system. Newly arrived processors can become a participant via the  interface. However, we do not require the system to allow this during reconfiguration periods. Namely, newly arrived processors can join the participant set as long as no reconfiguration occurs. While reconfiguration is in progress, the system may block changes to the participation set as well as stop considering any additional reconfiguration requests. Thus, when there are no configuration conflicts, and all participating processors have the same view on the participation set, the system ability to replace the existing configuration with a proposed one depends on the participant crash rate. Note that the above recovery strategy implies that the system is always able to converge to a valid configuration even when the churn rate had been too high with respect to crashing participants. In other words, we consider system that their failure detectors are \emph{eventually} and \emph{temporarily} reliable, in order to allow the recovery strategy to attain a conflict-free configuration, and after that, we merely require that the crash rate of participating processors to be such that \emph{unreliable} failure detectors can \emph{eventually} allow the system to replace the current configuration with a new one. Note that the violation of the latter assumption is a transient fault from which the system shall recover using the above assumptions about \emph{eventually} and \emph{temporarily} reliable failure detectors, in order to allow the above recovery strategy to attain a conflict-free configuration. Moreover, after the system reaches such a conflict-free configuration state, we merely require that (1) the fail-stop rate  of (participating) processors shall be such that \emph{unreliable} failure detectors can \emph{eventually} allow the system to replace the current configuration with a new one (without the need to use the recovery strategy), (2) the rate  in which new processors arrive to the system is sufficiently high \emph{eventually} and \emph{temporarily}, such that active processors are always available to become participants and join the next quorum configuration, and (3) the rate  in which new processors arrive to the system is sufficiently slow \emph{eventually} and \emph{temporarily}, such that the recovery strategy can terminate \emph{eventually} after the occurrence of transient faults. We note that these three requirements are feasible, for example, in system that for a very small number of active processors make sure that  \emph{eventually} and \emph{temporarily}, and for very high number of active processors make sure that  \emph{eventually} and \emph{temporarily}.

} 




\subsection{Reconfiguration Stability Assurance}
\label{sec:RSA}
We present the Reconfiguration Stability Assurance layer (), a self-stabilizing algorithm for assuring correct configuration while allowing the updates from the Reconfiguration Management layer (Section~\ref{sec:reconMan}). 
We first describe the algorithm (Section~\ref{sec:recSAdescr}) and then we prove its correctness (Section~\ref{sec:recSAproof}).




\remove{ 

\subsubsection{The algorithm in a nutshell}
\label{sec:RSAnut}
The  layer uses a self-stabilizing algorithm for assuring correct configuration while allowing the updates from the reconfiguration management layer (Section~\ref{sec:reconMan}). 
Algorithm~\ref{alg:SdisCongif} guarantees that (1) all active processors have eventually identical copies of a single configuration, (2) when participants notify the system that they wish to replace the current configuration with another, the algorithm selects one proposal and replaces the current configuration with it, and (3) joining processors can become participants eventually. 

\begin{algorithm}[t!]

\caption{Stabilizing Reconfiguration Stability Assurance; 's code}
\label{alg:SdisCongif}
{\bf Variables}:
Each field is held in an array that stores 's own values and 's most recently received ones.  
For example, in the case of the  field,  is 's view on the current configuration and  stores the most recently received one. Note that  assigns  (the \emph{empty configuration}) after receiving a conflicting (different) non-empty configuration value. 
 and  represent 's failure detector, and respectively, an alias to . Note that we consider only the trusted (unsuspected) processors. Namely, crashed processors eventually suspected and the  field of every message encodes also this participation info. 
The field , where  refers to 's configuration replacement proposal. The case of no proposal is denoted by . 
The field  is true when  observes that all trusted nodes notice its current (max) proposal and they hold the same value. The variable  stores the set of nodes   for which  received the  indication.\label{ln:Sdef}


\vspace{0.35em}

{\bf Interfaces}:
{\bf function} \label{ln:Sparticipate}  replaces 's configuration (which could be set to ) with . Note that this could be done only when no reconfiguration is taking place. 

{\bf function} \label{ln:SchsConfig} 
 is the current  value, or  when there is no single non- value.

{\bf function} \label{ln:SgetConfig}  \{{\bf if}  {\bf then return} {\bf else return(};\

{\bf function} \label{ln:SnoReco}  test (locally) whether  runs a reconfiguration process.

{\bf function}  \label{ln:Sestab}   \{\lIf{}{} 

\vspace{0.35em}

{\bf do forever} \label{ln:SdoForever} \Begin{

\lIf{stale info. is present, e.g., different (non- or-)  values or empty intersection between  and participant set}{reset, i.e., call \label{ln:Sclean}\label{ln:Sstale}}

\If{there is no proposal for configuration replacement\label{ln:SnoMaxNotif}}{

\lIf{}{  {once a trusted processor has sent a different (non- or ) configuration, -nullify the stored one}}\label{ln:SnullConfig} 

\lIf{}{  { once all trusted nodes trust the same nodes, use this node set as the new configuration}\label{ln:SrestartConfig}}}

\Else{ 

\lIf{all trusted participants report the same proposals and participation sets and they echo back the sent values of these fields}{\label{ln:SadoptAll}}

 \ElseIf{trusted participant  reports }{{\bf add}  {\bf to} \label{ln:SaddSaw}\;
\lIf{ include all trusted participants}{run the automaton (Figure~\ref{fig:auto}) and empty \label{ln:Sauto}}
}}

\lIf{}{send to  the state of  (including 's recently received info.)\label{ln:Ssend}}}

{\bf upon receive}  {\bf from}  {\bf do}  store 's fields as the recently received values from \label{ln:Sreceive}\;

{\bf upon interrupt} {\bf 's booting} {\bf do} 
\lForEach{}{ \label{ln:Sjoin}  during boot, nullify the stored fields and disable message transmissions}

\end{algorithm}
\setlength{\textfloatsep}{5pt}

\noindent {\bf The algorithm structure.}
The algorithm combines two techniques: one for \emph{brute force stabilization} that recovers from stale information and a complementary technique for \emph{delicate (configuration) replacement}, where participants jointly select a single new configuration that replaces the current one. We sketch the structure of Algorithm~\ref{alg:SdisCongif} before adding the details.  



\noindent{\em Combining the two techniques.~~~}
As long as a given processor is not aware of ongoing configuration replacements, Algorithm~\ref{alg:SdisCongif} merely monitors the system for stale information, e.g., it makes sure that all  fields hold the same non- value. During these periods the algorithm allows the invocation of configuration replacement processes (via the  interface) as well as the acceptance of joining processors as participants (via the  interface). During the process of configuration replacement, the algorithm selects a single configuration proposal and replaces the current one with that proposal before returning to monitor for configuration disagreements.



\noindent{\em Blocking joins to the participant sets during reconfiguration periods.~~~}
While the system reconfigures, there is no immediate need to allow joining processors to become participants. By temporarily disabling this functionality, the algorithm can focus on completing the configuration replacement using the current participant set. To that end, 
only participants broadcast their states at the end of the do forever loop (line~\ref{ln:Ssend}) and only their messages arrive to the other active processors (line~\ref{ln:Sreceive}). Moreover, we assume that the only way for a joining processor to start executing Algorithm~\ref{alg:SdisCongif} is by responding to an interrupt call (line~\ref{ln:Sjoin}), where  the assignment of  to \textnormal{config} nullifies the configuration. Thus, joining processors cannot broadcast (line~\ref{ln:Ssend}) before their safe entry to participant set via the function  (line~\ref{ln:Sparticipate}), which enables 's broadcasting. 
Note that non-participants monitor the intersection between the current configuration and the set of active participants (line~\ref{ln:Sstale}). In case it is empty, the processors (participant or not) call  and starts a reset process that ends with a brute-force stabilization, which we explain below. Thus, the  values are removed from  and there is no more blocking of joining processors to become participants.








\begin{figure*}[t!] 
\center
\includegraphics[scale=0.45,bb=96 401 486 755]{automaton.pdf}
    \caption{The configuration replacement automaton}
    \label{fig:auto}
\end{figure*} 


\noindent {\bf Brute-force stabilization.}
The proposed self-stabilizing algorithm detects the presence of stale information and recovers from these transient faults. {\em Configuration conflicts} are one of several kinds of such stale information and they refer to differences in the field , which stores the (quorum) configuration values. Processor  can signal to all processors that it had detected stale information by assigning  to  and by that start a reset process that nullifies all  fields in the system (lines~\ref{ln:Sstale} and~\ref{ln:SnullConfig}). 
Algorithm~\ref{alg:SdisCongif} uses the brute-force technique for letting processor  to assign to  its set of trusted processors (line~\ref{ln:SrestartConfig}), which the failure detector  provides. Note that brute-force stabilization removes any  value from  and all processors (joining or participant) to become a participant at the end of the brute-force process. Theorem~\ref{thm:staleFreeExecutionThm} shows that eventually all active processors share identical (non-)  values.




\noindent {\bf Delicate (configuration) replacement.}
Participants can propose to replace the current configuration with a new one, , via the  interface. This replacement uses the {\em configuration replacement} automaton (Figure~\ref{fig:auto}) that a self-stabilizing mechanism for {\em (phase transition) coordination} emulates.  


\noindent{\em The configuration replacement automaton.~~~}
When the system is free from stale information, the configuration uniformity invariant (of the  field values) holds. Then, any number of calls to the  interface starts the configuration replacement automaton (Figure~\ref{fig:auto}), which controls the configuration replacement using the following three phases: (1) selecting (deterministically and uniformly) a single proposal (while verifying the eventual absence of ``unselected'' proposals), (2) replacing (deterministically and uniformly) all  fields with the jointly selected proposal, and (3) bringing back the system to a state in which it merely tests for stale information. 

\noindent{\em A self-stabilizing mechanism for phase transition coordination.~~~}
The configuration replacement automaton (Figure~\ref{fig:auto}) requires coordinated phase transition.
Algorithm~\ref{alg:SdisCongif} lets processor  to represent proposals as , where  is the processor from which  received the proposal,  and  is a processor set or the null value, . The \emph{default proposal}, , refers to the case in which  encodes ``no proposal'' (line~\ref{ln:Sdef}). 
When  calls the function , it changes  to  (line~\ref{ln:Sestab}) as long as  is not aware of an ongoing configuration replacement process, i.e.,  returns true. Upon this change, the algorithm disseminates  and by that guarantees eventually that  returns false for any processor that calls it. Once that happens, no call to  adds a new proposal for configuration replacement and no call to  lets a joining processor to become a participant (line~\ref{ln:Sparticipate}). Algorithm~\ref{alg:SdisCongif} can then use the lexical value of the 's tuples for selecting one of them deterministically (Figure~\ref{fig:auto}). To that end, each participant makes sure that all other participants report the same tuples by waiting until they ``echo'' back the same values as the ones it had sent to them. Once that happen, the participant  makes sure that the communication channels do not include other ``unselected'' proposals by raising a flag  (line~\ref{ln:SadoptAll}) and waiting for the echoed values of these three fields, i.e., participant set,  and . This waiting continues until the echoed values match the values of any other active participant in the system (while monitoring their well-being). Before this participant proceeds, it makes sure that all active participants have noticed its phase completion (line~\ref{ln:SaddSaw}). Each processor maintains the  variable; a set of participants that have noticed its phase completion and has thus added them to the set .

The above self-stabilizing mechanism for phase transition coordination allows progression in a unison fashion. Namely, no processor starts a new phase before it has seen that all other active participants have completed the current phase and have noticed that all other have done so (because they have identical participant set,  and  values). This is the basis for emulating every step of the configuration replacement automaton (line~\ref{ln:Sauto}) and making sure that the phase 2 replacement occurs correctly before returning to phase 0, in which the system simply tests for stale information. The proof of Theorem~\ref{thm:closureThm} shows that since the failure detectors monitor the participants' well-being, this process terminates.


\newpage
}


\remove{ 

\subsubsection{The NEW proof sketch of Algorithm~\ref{alg:SdisCongif}.}
Theorem~\ref{thm:staleFreeExecutionThm} shows that the invariant of no stale information holds eventually in admissible executions. 
We say that execution  is \textit{admissible} when  throughout  the failure detector values of active processors are identical, do not change and consist of only (the set of active processors) themselves. 
I.e., ,  that are active in , we have  and    is active. The proof considers system states, , that have no stale information when (1) all (quorum) configuration proposals are valid, e.g., the proposal  is not valid when , (2) all  values are non- and the same, (3) the phase information (including ) is in synch, and (4) the  set includes active participants. 









\begin{theorem}[Lemma~\ref{thm:noConflict} in the Appendix] 
\label{thm:staleFreeExecutionThm}
Admissible executions have no stale information eventually.
\end{theorem}

\begin{proofsketch}
Lines~\ref{ln:Sclean} and~\ref{ln:SnullConfig} detect stale information and start the configuration reset. 
The proof use Claim~\ref{thm:2ConfigShort} and Lemma~\ref{thm:convDegShort} to imply this lemma's correctness by assumption that  does not include, and respectively, include (notifications about) replacement proposals.  



\begin{lemma}[Lemma~\ref{thm:noConflict} in the Appendix]
During admissible executions , reset processes terminate. 
\end{lemma}
\begin{proofsketch}
Suppose that 's starting system state does include a conflict, i.e.,  or there is a message, , in the communication channel from  to , such that the field , where both  and  are active processors. 
The proof uses claims~\ref{thm:thereBotSimShort} and~\ref{thm:onceBotShort} to show that in all of these cases, eventually  before using Claim~\ref{thm:2Config} to show that eventfully there are no configuration conflicts.
Claims~\ref{thm:thereBotSimShort} and~\ref{thm:onceBotShort} consider the values in the field  that are either held by an active processor  or in its outgoing communication channel to another active processor . We define the set  to be the set of all these values, where  and . 





\begin{claim}[Claims~\ref{thm:thereBotSim} and~\ref{thm:thereBot} in the Appendix]
\label{thm:thereBotSimShort}
Suppose that in 's starting system state, there are processors  that are active in , for which . (1)  implies that eventually the system reaches a state in which  holds. (2)  implies that eventually the system reaches a state in which  or  holds. 
\end{claim} 

\begin{proofsketch}
\noindent \textbf{Part (1).~} The proof is based on the assumption that messages from  arrive eventually, the updating of  occurs (line~\ref{ln:receive}) and the do-forever loop includes the if-statement in line~\ref{ln:nullConfig}.

\noindent \textbf{Part (2).~} 
Suppose that this part of the claim is false. The assumption messages eventually arrive the  implies that the case of part (1) of this claim holds eventually. Thus, a contradiction and the claim is true.
\end{proofsketch}


\remove{
\begin{proofsketch}
Suppose that  holds. Immediately after 's starting state, processor  has an applicable step that includes the execution of the do forever loop (line~\ref{ln:doForever} to~\ref{ln:send}). In that step, the if-statement condition 

(line~\ref{ln:nullConfig}'s if-statement) holds,  assigns  to  and the proof is done. Suppose that  holds. Upon 's arrival, processor  assigns  to  (line~\ref{ln:receive}) and the case of  holds.
\end{proofsketch}



\begin{claim}
\label{thm:thereBot}
Suppose that in 's starting system state, there are processors  that are active in , for which , where . Eventually the system reaches a state in which   or  holds. 
\end{claim} 


\begin{proofsketch}
Suppose, towards a contradiction, for any system state  neither  nor . Note that  and  exchange messages eventually, because whenever processor  repeatedly sends the same message to processor , it holds that  receives that message eventually (the fair communication assumption, Section~\ref{s:sys}) and vice versa. Such message exchange implies that the case of  (Claim~\ref{thm:thereBotSim}) holds eventually, where . Thus, we reach a contradiction and therefore eventually the system reaches a state in which 
  or  hold.
\end{proofsketch}




} 


\begin{claim}[Claim~\ref{thm:onceBot} in the Appendix]
\label{thm:onceBotShort}
Suppose that  in 's starting system state. (1) For any system state , and (2)  has a suffix, , such that  that are active in .
\end{claim} 


\begin{proofsketch}
\noindent {\bf Part (1).~~~}
Since  is admissible, 's value does not change and that .
Any step  in which  changes 's value includes the execution of line~\ref{ln:nullConfig} or line~\ref{ln:restartConfig} (note that  does not include lines~\ref{ln:adoptAll} to~\ref{ln:automatonStep}), which assign to  the values , and respectively, . 

\noindent {\bf Part (2).~~~} First consider the values in  and  before the ones in .

\noindent {\bf Part (2.1).~~~} 
Message  includes 's value (line~\ref{ln:send}). Eventually  and therefore  records correctly 's most recent value in   (line~\ref{ln:receive}).

\noindent {\bf Part (2.2).~~~}
Once  changes the value of , it holds that   thereafter (only lines~\ref{ln:nullConfig} and~\ref{ln:restartConfig} change , and part (1) of this claim while replacing the index  with ). Suppose, towards a contradiction, that  does not change that value of  throughout  and yet . 
Note that  (if-statement condition in line~\ref{ln:restartConfig}, second clause) holds throughout (admissible) . Therefore, whenever  takes a step that includes the execution of the do forever loop, its message , such that  (line~\ref{ln:send}) and  (this proof, part (2.2)). Since  sends  repeatedly,  receives eventually  (fair communication, Section~\ref{s:sys}) and . Immediately after that step, the system state allows  to take a step in which the condition in line~\ref{ln:nullConfig}'s if-statement holds.
Thus, a contradiction.
\end{proofsketch}


\begin{claim}[Claim~\ref{thm:2Config} in the Appendix]
\label{thm:2ConfigShort}
Suppose for any two active , we have that . Eventually .  
\end{claim} 

\begin{proofsketch}
Note that this claim assumptions w.r.t. 's starting states hold for any , because only lines~\ref{ln:nullConfig} and~\ref{ln:restartConfig} can change the value of  (but  (line~\ref{ln:nullConfig}) does not hold,  and 's does not change), which later  uses for sending the message  (line~\ref{ln:send}), and thus also  as well as  records correctly the most recent 's that  receives from  (line~\ref{ln:receive}).    
In step , processor  executes line~\ref{ln:restartConfig} (by similar arguments to the above) and does not include the execution of line~\ref{ln:nullConfig} (the if-statement  condition of line~\ref{ln:nullConfig} does not hold). Immediately after ,  holds. 
\end{proofsketch}
\end{proofsketch}












\begin{lemma}[Lemma~\ref{thm:convDeg} and Claim~\ref{thm:virtuallyNotExplicit} in the Appendix]
\label{thm:convDegShort}
Let  be an execution of Algorithm~\ref{alg:disCongif} that is admissible with respect to the participant sets. 
Let  be a notification in . Eventually  leaves the system.
\end{lemma}
\begin{proofsketch}
The proof assume, towards a contradiction, that notification  never leaves the system and it has a maximal lexical value among all the notifications in . The proof start by assuming that all of  notifications appear in its starting state before removing this assumption. It uses the fact that only lines~\ref{ln:readyToReplace} to~\ref{ln:automatonStep} (Claim~\ref{thm:notDec}) change the notifications and by that show non-decrease property of their lexical values. A contradiction is archived by showing that the following invariants hold.  
Suppose that  holds in  every system state . Eventually the system reaches a state , such that for any  that is an active participant in , it holds that:
(1)  and . Moreover,  and  in  eventually,
(2) ,  and   in ,
(3)   in .
(4)   in . 
(5)  in . 
(6)   in . 
(7) the if-statement condition of line~\ref{ln:readyToReplace} holds in .
Note that there exists a system state
 in which there are no notifications, because invariant (7) that there is a step  that immediately follows  and in which  for any  value contradict the assumption that  is of maximal value or that it never leave the system. We complete the proof by showing that even in executions in which not all of  notifications appear in its starting state, the above eventually holds. To that end, the proof consider all notifications that appeared in 's starting state and show that they must leave the system eventually because their (continuous) presence causes  to return false and by that disable the effect of the function  (line~\ref{ln:configEstab}). Once this is true for every active processor in the system, the conditions for invariants (1) to (7) hold and all notifications leave the system eventually.   
\hfill\end{proofsketch}
\end{proofsketch}

}










\begin{algorithm*}[t!]


\caption{Self-stabilizing Reconfiguration Stability Assurance; code for processor }
\label{alg:disCongif}
\begin{footnotesize}
{\bf Variables}:
The following arrays consider both 's own value (entry ) and 's most recently received value (entry ).  

: an array in which  is 's view on the current configuration.
Note that  assigns the \emph{empty (configuration)} value  after receiving a conflicting (different) non-empty configuration value. 

: an array in which  represents 's failure detector. 
Note that we consider only the trusted processors rather than the suspected ones. Namely, crashed processors are eventually suspected. 

 is the participant set, where  is an alias for  and  refers to the last value received from . Namely, the  field of every message encodes also this participation information.



 is an array of pairs , where  refers to 's configuration replacement notifications.
In the pair , the field  can either be  (`no value') or the proposed processor set. 


 is an array in which  is 's alias and  refers to the most recent value that  received from  after  had responded to  with the most recent values it got from .


 is an array of Booleans, where  refers to the case in which  observes that all trusted processors had noticed its current (maximal) notification and they hold the same notification. 





: a list of processors  for which  received the  indication. 

\vspace{0.35em}

{\bf Interface functions}:



{\bf function} \label{ln:chsConfig} 
 
{\bf return(choose}, where {\bf choose} else {\bf choose};\ 



{\bf function} \label{ln:getConfig}  \{{\bf if}  {\bf then return} {\bf else return(};\





{\bf function} \label{ln:\noReconfig}  \hfill invariant tests 






{\bf function}  \label{ln:configEstab}   \{\lIf{}{ } 





 
{\bf function}  \label{ln:participate}   \{\lIf{}{ }  


\vspace{0.35em}

{\bf Constants and macros}:  \label{ln:dfltNtf} \hfill {the default notification tuple} 






{\bf macro}   {} \hfill {'s most-recently-received \notif ~degree} \label{ln:degree}



{\bf macro} \label{ln:eachoNoAll}   \Return{ }  

{\bf macro} \label{ln:echoDef}   \Return{ } 

{\bf macro} \label{ln:sameK}   \Return{ }  


{\bf macro} \label{ln:maxNotif}
  \{\lIf{}{\Return{} {\bf else return }}




 
{\bf macro} \label{ln:confSetVal}  {\bf foreach} {} {\bf do} { \hfill {access to 's }   }

{\bf macro} \label{ln:incrementphs}  {\bf select} {\bf case :}  {\bf return} ; {\bf case :}  {\bf return} ;   {\bf case :}  {\bf return} ; 



{\bf macro} \label{ln:allSaw} \;

\vspace{0.35em}

{\bf do forever} \label{ln:doForever} \Begin{
\lForEach{}{ \hfill {clean after crashes} \label{ln:clean}\DontPrintSemicolon}
\PrintSemicolon
\lIf{{\em :}{\em :}{\em :}  {\bf where} {\em :}{\em :} }{\label{ln:stale}} \If(\hfill  {when no notification arrived} ){\label{ln:noMaxNotif}}{
\lIf{}{ \hfill {nullify the configuration upon conflict} \DontPrintSemicolon }\label{ln:nullConfig} 
\lIf{}{ \hfill {reset during admissible runs} \label{ln:restartConfig}}}
\Else{
\label{ln:adoptAll} 
\hfill  {test all-the-same reports} 
\lForEach{}{\label{ln:addSaw}}
\lIf{}{\label{ln:readyToReplace}}
\{{\bf select} {\bf case :} {}, {\bf case :} {}, {\bf case :} \label{ln:automatonStep}
 {}\};
}
\lIf{}{{\bf foreach} {}{ {\bf do send}\label{ln:send}}}}
{\bf upon receive}  {\bf from}  {\bf do} 
 \label{ln:receive}\;
{\bf upon interrupt} {\bf 's booting} {\bf do} 
\lForEach{}{\label{ln:join}}
\end{footnotesize}
\end{algorithm*}









\subsubsection{Algorithm Description}
\label{sec:recSAdescr}




We first present an overview of the algorithm and then proceed to a line-by-line description. 

\subsubsection*{Overview}
The  layer uses a self-stabilizing algorithm (Algorithm~\ref{alg:disCongif})  for assuring correct configuration while allowing the updates from the reconfiguration management layer.
Algorithm~\ref{alg:disCongif} guarantees that (1) all active processors have eventually identical copies of a single configuration, (2) when participants notify the system that they wish to replace the current configuration with another, the algorithm selects one proposal and replaces the current configuration with it, and (3) joining processors can become participants eventually. 

The algorithm combines two techniques: one for \emph{brute force stabilization} that recovers from stale information and a complementary technique for \emph{delicate (configuration) replacement}, where participants jointly select a single new configuration that replaces the current one. 
As long as a given processor is not aware of ongoing configuration replacements, Algorithm~\ref{alg:disCongif} merely monitors the system for stale information, e.g., it makes sure that all participants have a single (non-empty) configuration. During these periods the algorithm allows the invocation of configuration replacement processes (via the  interface, triggered by the Reconfiguration Management layer) as well as the acceptance of joining processors as participants (via the  interface, triggered by the Joining layer). During the process of configuration replacement, the algorithm selects a single configuration proposal and replaces the current one with that proposal before returning to monitor for configuration disagreements.

While the system reconfigures, there is no immediate need to allow joining processors to become participants. By temporarily disabling this functionality, the algorithm can focus on completing the configuration replacement using the current participant set. To that end, 
only participants broadcast their states at the end of the do forever loop (line~\ref{ln:send}), and only their messages arrive to the other active processors (line~\ref{ln:receive}). Joining processors receive such messages, but cannot broadcast before their safe entry to the participants' set via the function  (line~\ref{ln:participate}), which enables 's broadcasting. 
Note that non-participants monitor the intersection between the current configuration and the set of active participants (line~\ref{ln:stale}). In case it is empty, the processors (participants or not) essentially begin a brute-force stabilization (outlined below) where there is no more blocking of joining processors to become participants.









\begin{figure*}[t!] 
\center
	\includegraphics[scale=0.45,bb=96 401 486 755]{automaton.pdf}
	\caption{The configuration replacement automaton}
	\label{fig:auto}
\end{figure*} 


\noindent {\bf\em Brute-force stabilization.}
The algorithm detects the presence of stale information and recovers from these transient faults. {\em Configuration conflicts} are one of several kinds of such stale information and they refer to differences in the field , which stores the (quorum) configuration values. Processor  can signal to all processors that it had detected stale information by assigning  to  and by that start a reset process that nullifies all  fields in the system (lines~\ref{ln:stale} and~\ref{ln:nullConfig}). 
Algorithm~\ref{alg:disCongif} uses the brute-force technique for letting processor  to assign to  its set of trusted processors (line~\ref{ln:restartConfig}), which the failure detector  at processor  provides. Note that by the end of the brute-force process, all active processors (joining or participant) become  participants. We show that 
eventually all active processors share identical (non-)  values by the end of this process.




\noindent {\bf\em Delicate (configuration) replacement.}
Participants can propose to replace the current configuration with a new one, , via the  interface. This replacement uses the {\em configuration replacement} process, which for the purposes of the overview, we abstract it as the automaton depicted in Figure~\ref{fig:auto}. When the system is free from stale information, the configuration uniformity invariant (of the  field values) holds. Then, any number of calls to the  interface starts the configuration replacement process, which controls the configuration replacement using the following three phases: (1) selecting (deterministically and uniformly) a single proposal (while verifying the eventual absence of ``unselected'' proposals), (2) replacing (deterministically and uniformly) all  fields with the jointly selected proposal, and (3) bringing back the system to a state in which it merely tests for stale information. 


The configuration replacement process requires coordinated phase transition.
Algorithm~\ref{alg:disCongif} lets processor  to represent proposals as , where  is the processor from which  received the proposal,  and  is a processor set or the null value, . The \emph{default proposal}, , refers to the case in which  encodes ``no proposal''. 
When  calls the function , it changes  to  (line~\ref{ln:configEstab}) as long as  is not aware of an ongoing configuration replacement process, i.e.,  returns true. Upon this change, the algorithm disseminates  and by that guarantees eventually that  returns false for any processor that calls it. Once that happens, no call to  adds a new proposal for configuration replacement and no call to  lets a joining processor to become a participant (line~\ref{ln:participate}). The algorithm can then use the lexical value of the 's tuples for selecting one of them deterministically (Figure~\ref{fig:auto}). To that end, each participant makes sure that all other participants report the same tuples by waiting until they ``echo'' back the same values as the ones it had sent to them. Once that happens, the participant  makes sure that the communication channels do not include other ``unselected'' proposals by raising a flag () and waiting for the echoed values of these three fields, i.e., participant set,  and . This waiting continues until the echoed values match the values of any other active participant in the system (while monitoring their well-being). Before this participant proceeds, it makes sure that all active participants have noticed its phase completion (line~\ref{ln:addSaw}). Each processor  maintains the  variable; a set of participants that have noticed 's phase completion (line~\ref{ln:addSaw}) and are thus added to 's  set.

The above mechanism for phase transition coordination allows progression in a unison fashion. Namely, no processor starts a new phase before it has seen that all other active participants have completed the current phase and have noticed that all other have done so (because they have identical participants' set,  and  values). This is the basis for emulating every step of the configuration replacement process (line~\ref{ln:automatonStep}) and making sure that the phase 2 replacement occurs correctly before returning to phase 0, in which the system simply tests for stale information. We show that since the failure detectors monitor the participants' well-being, this process terminates.


\subsubsection*{Detailed Descripion}

We now proceed to a detailed, line-by-line description of Algorithm~\ref{alg:disCongif}.

\paragraph{Variables.}
The algorithm uses a number of fields
that each active participant broadcasts to all other system processors. The processor stores the values that they receive in arrays. Namely, we consider both 's own value (the -th entry) and 's most recently received value (the -th entry).  

\begin{itemize}

\item The field : an array in which  is 's view on the current configuration. Note that  assigns the \emph{empty (configuration)} value  after receiving a conflicting (not the same) non-empty configuration value, i.e., the received configuration is different than 's configuration. We use the symbol  for denoting that processor  is not a participant, i.e., .

\item The field  is  an array in which  represents 's failure detector of trusted processors (without the list of processors that are suspected to be crashed). 


\item  is the participants' set, where  is an alias for  and  refers to the last value received from . Namely, the  field of every message encodes also this participation information.


\item The field  is an array of pairs , where  refers to 's configuration replacement notifications. In the pair , the field  can either be  (`no value') or the proposed processor set. 

\item The field  is an array in which  is an alias of   and  refers to the most recent value that  has received from  after  had responded to  with the most recent values it got from .

\item The field  is an array of Booleans, where  refers to the case in which  observes that all trusted processors have noticed its current (maximal) notification and they hold the same notification. 


\item The variable  is a set that includes the processors  for which  received the  indication. 

\end{itemize}

\paragraph{Constants, functions and macros.}
The constant  (line~\ref{ln:dfltNtf}) denotes the default notification tuple .
The following functions define the interface between Algorithms~\ref{alg:disCongif} and~\ref{alg:SSQR} (Reconfiguration Management layer) and the Joining Mechanism (Algorithm~\ref{alg:join}). Note that the behavior which we specify below considers legal executions.  

\begin{itemize}

\item The function  (line~\ref{ln:chsConfig}) returns  whenever there is a single such non- value. Otherwise,  is returned.

\item The function  (line~\ref{ln:getConfig}) allows Algorithms~\ref{alg:SSQR}~and~\ref{alg:join} to retrieve the value of the current quorum configuration, i.e., . We note that during legal executions, this value is a set of processors whenever  is a participant. However, this value can be  whenever  is not a participant and  during the process of configuration reset.

\item The function  (line~\ref{ln:\noReconfig}) returns  whenever (1)  was not recognized as a trusted processor by a processor that  trusts, (2) there are configuration conflicts, (3) the participant sets have yet to stabilize, (4) there is an on-going process of brute force stabilization, or (5) there is a delicate (configuration) replacement in progress. This part of the interface allows Algorithms~\ref{alg:SSQR}~and~\ref{alg:join} to test for the presence of local evidence according to which Algorithm~\ref{alg:disCongif} shall disable delicate (configuration) replacement and joining to the participant set.


\item The function  (line~\ref{ln:configEstab}) provides an interface that allows the \emph{recMA} layer to request from Algorithm~\ref{alg:disCongif} to replace the current quorum configuration with the proposed , which is a non-empty group of participants. Note that Algorithm~\ref{alg:disCongif} disables this functionality whenever  or .


\item The function  (line~\ref{ln:participate}) provides an interface that allows the Joining Mechanism to request from Algorithm~\ref{alg:disCongif} to let  join the participant set, which is the group that can participate in the configuration and request the replacement of the current configuration with another (via the  function). Note that Algorithm~\ref{alg:disCongif} disables this functionality whenever  and thus there exists a single configuration in the system, i.e., the call to  (line~\ref{ln:chsConfig}) returns the single configuration that all active participants store as their current quorum configuration. This is except for case in which . Here,  returns , which starts a reset process in order to deal with a complete collapse where the quorum system includes no active participants. 




\end{itemize}

Algorithm~\ref{alg:disCongif} uses the following macros. 

\begin{itemize}

\item The macro  (line~\ref{ln:degree}) calculates the degree of 's most-recently-received notification degree, which is twice the notification phase plus one whenever all participants are using the same notification (and zero otherwise).
 

\item The macros  and  (lines~\ref{ln:eachoNoAll}, and~\ref{ln:echoDef} respectively) test whether  was acknowledged by all participants for the values it has sent. The former function considers just the fields that are related to its own participants' set and notification, whereas the latter considers also the field . 

\item The macro  (line~\ref{ln:sameK}) performs a similar tests to the one of , but considers only processor 's most-recently-received values rather than all participants' echoed ones.


\item The macro  (line~\ref{ln:maxNotif}) selects a notification with the maximal lexicographical value or returns  in the absence of notification that is not the default (phase 0) notification. We define our lexicographical order   between  and , as , where  can be defined using a common lexical ordering and by considering sets of processors as ordered tuples that list processors in, say, an ascending order with respect to their identifiers.

\item The macro  (line~\ref{ln:confSetVal}) acts as a wrapper function for accessing 's local copies of the field . This macro also makes sure that there are no (local) active notifications.

\item The macro  (line~\ref{ln:incrementphs}) performs the transition between the phases of the delicate configuration replacement technique.

\item The macro  (line~\ref{ln:allSaw}) tests whether all active participants have noticed that all other participants have finished the current phase.


\end{itemize}




\boldsubparagraph{The do forever loop.} 
A line-by-line walkthrough of the pseudocode of Algorithm~\ref{alg:disCongif} follows.

\subparagraph{Cleaning up, removal of stale information and invariant testing.} The do forever loop starts by making sure that non-participant nodes cannot have an impact on 's computation (line~\ref{ln:clean}) before testing that 's state does not include any stale information (line~\ref{ln:stale}). Algorithm~\ref{alg:disCongif} tests for several types of stale information (c.f. Definition~\ref{def:type}): (type-1) notifications in phase 0 must not have a , (type-2) configurations that refer to the empty set, execute configuration reset, or conflicting  configurations, (type-3) the degree gap between two notifications is greater than one, there are participants in different  phases but the one in the more advanced phase does not appear in the  set, or the local set of notifications includes more than one notification and at least one of them is in phase 2, and (type-4)
the quorum configuration includes at least one active participant (to avoid false positive error by testing only when processor  has a stable view of set of trusted processors and participants). In case any of these tests fails, the algorithm starts a configuration reset process by calling .

\subparagraph{The brute-force stabilization technique.}
As long as no active notifications are present locally (line~\ref{ln:noMaxNotif}), every processor performs this technique for transient fault recovery. In the presence of configuration conflicts, the algorithm starts the configuration reset process (line~\ref{ln:nullConfig}). Moreover, during the configuration reset process, the algorithm waits until all locally trusted processors report that they trust the same set of processors (line~\ref{ln:restartConfig}).



\subparagraph{The delicate replacement technique --- phase synchronization.}
This technique synchronizes the system phase transitions by making sure that all active participants work with the same notification.

Each active participant tests whether all other trusted participants have echoed their current participants' set and notifications and have the same values with respect to these two fields     
(line~\ref{ln:adoptAll}). The success of this test assigns  to the field . The algorithm then extends this test to include also the field  (line~\ref{ln:addSaw}). Upon the success of this test with respect to participant , the algorithm adds  to the set .
Once processor  receives reports from all participants that the current phase is over, it moves to the next phase (line~\ref{ln:readyToReplace}).

\subparagraph{The delicate replacement technique --- finite-state-machine emulation.}
Each of the three phases represent an automaton state (line~\ref{ln:automatonStep}); recall Figure~\ref{fig:auto} and the configuration replacement process discussed
in the Overview.  
During phase , the system converges to a single notification. During phase , the system replaces the current configuration with the proposed one. Next, the system returns to its ideal state, i.e., phase , which allows new participants to join, as well as further reconfigurations.


\subparagraph{Message exchange and the control of newly arrived processors.}
When a participant finishes executing the do forever loop, it broadcasts its entire state (line~\ref{ln:send}). Once these messages arrive, processor  stores them (line~\ref{ln:receive}). The only way for a newly arrived processor to start executing Algorithm~\ref{alg:disCongif} is by responding to an interrupt call (line~\ref{ln:join}). This procedure notifies the processor state and makes sure that it cannot broadcast messages (line~\ref{ln:send}). The safe entry of this newly arrived processor to the participants' set, is via the function  (line~\ref{ln:participate}), which enables 's broadcasting. Thus, non-participants merely follow the system messages until the function  returns true and allows its join to the participant set by a call (from the Joining Mechanism) to the function  (line~\ref{ln:participate}).




\subsubsection{Correctness}
\label{sec:recSAproof}

We first provide an outline of the proof and then proceed in steps to establish the correctness of the algorithm.
\subsubsection*{Outline} 
We say that system state  has no stale information when (1) all the notifications are valid, (2) there are no configuration  conflicts or active reset process, (3) the phase information (including the set ) are not out of synch, and (4) there are active participants  in . The correctness proof of Algorithm~\ref{alg:disCongif} shows that eventually there is no stale information, because they are all cleaned (line~\ref{ln:clean}) or detected and cause configuration reset by calling  (line~\ref{ln:stale}).



In the absence of notifications (line~\ref{ln:noMaxNotif}), 
Algorithm~\ref{alg:disCongif} merely tests for configuration conflicts (line~\ref{ln:nullConfig}) and during a configuration reset, it waits until all locally trusted processors report that they trust the same processors (line~\ref{ln:restartConfig}) before these processors become the configuration. I.e., it applies the brute force stabilization technique. The proof here shows that during admissible executions, the  symbol propagates to all of the  fields in the system until all active processors assign to  either  or the entire set of trusted processors. 
This reset process ends when all processors assign merely the latter value to .


In the presence of notifications, Algorithm~\ref{alg:disCongif}  synchronizes the system phase transitions by making sure that all active participants work with the same notification (lines~\ref{ln:adoptAll} to~\ref{ln:addSaw}) before moving to the next phase (line~\ref{ln:readyToReplace}). The algorithm's three phases represent an automaton state (line~\ref{ln:automatonStep}). 
During phase , the system converges to a single notification. While  holds, the system replaces the current configuration with the proposed one. Next, the system returns to its no-notifications state, i.e., , which allows new participants as well as further reconfigurations. 
When a participant finishes the do forever loop, it broadcasts its entire state (line~\ref{ln:send}).
Once these messages arrive, the receiving processor stores them (line~\ref{ln:receive}). 

The only way for a newly arrived processor to start executing Algorithm~\ref{alg:disCongif} is by responding to an interrupt call (line~\ref{ln:join}). This procedure nullifies the state of the newly arrived processor with  and by that makes sure that it cannot broadcast (line~\ref{ln:send}). The safe entry of this processor to the participating set, is via the function  (line~\ref{ln:participate}), which enables 's broadcasting. Thus, non-participants merely follow the system messages until the function  returns true and allows its join to the participant set by a call to  (line~\ref{ln:participate}). 
By controlling the new joins, the three phase structure is the basis for proving the final theorem stating that eventually a common configuration set is adopted by every active processor. We now proceed to the detailed proof.






\subsubsection*{Configuration conflicts and stale information}


We begin by classifying the stale information into four types. 


\begin{definition}
\label{def:type}
We say that processor  in system state  has a stale information in  of:
\begin{itemize}[topsep=2pt,itemsep=-.5ex,partopsep=.5ex,parsep=1ex,leftmargin=.5cm]
	\item[]{\bf type-1:} when 
 (cf. line~\ref{ln:stale}). 
	\item[]{\bf type-2:} when  (cf. line~\ref{ln:stale}) or  encodes a \emph{(configuration) conflict}, i.e., there are two active processors  and  for which , , or  in any message in the communication channel from  to .
\item[]{\bf type-3:} when , where  . 
	\item[]{\bf type-4:} when .
\end{itemize}
\end{definition} 








\begin{claim}[Eventually there is no type-1 stale information]
\label{thm:noStale}
Eventually the system reaches a state  in which the invariant of no type-1 stale information holds thereafter.
\end{claim}
\begin{proof}
Let  be a system state in which processor  has an applicable step  that includes the execution of the do forever loop (line~\ref{ln:doForever} to~\ref{ln:send}).
We note that immediately after , processor  has no type-1 stale information (line~\ref{ln:stale} removes it). Moreover, that removal always occurs before  sends any message  (line~\ref{ln:send}). Therefore, eventually for every active processor  that receives from  message  (line~\ref{ln:receive}), it holds that  as well as for every item . Once this invariant holds for every pair of active processors  and , the system reaches state . We conclude the proof by noting that Algorithm~\ref{alg:disCongif} never assigns to  a values that violates this claim invariant.    
\end{proof}



\subsubsection*{Replacement state and message; explicit and spontaneous replacements}
We say that a processor 's state encodes a \emph{(delicate) replacement} when  and we say that a message  in the channel from  to  encodes a \emph{(delicate) replacement} when its . 
Given a system execution , we say that  \emph{does not include an explicit (delicate) replacement} when throughout  no node  calls . Suppose that execution  does not include an explicit (delicate) replacement and yet there is a system state  in which a processor state or a message in the communication channels encodes a (delicate) replacement. In this case, we say that  includes a \emph{spontaneous (delicate) replacement}.














\begin{lemma}[Eventually there is no type-2 stale information]
\label{thm:noConflict}
Let  be an admissible execution that does not include explicit (delicate) replacements nor spontaneous ones. The system eventually reaches  a state  in which the invariant of no type-2 stale information holds thereafter. 
\end{lemma}
\begin{proof}
Note that any of 's steps that includes the do forever loop (line~\ref{ln:doForever} to~\ref{ln:send}) does not run lines~\ref{ln:adoptAll} to~\ref{ln:automatonStep} (since  does not include an explicit nor spontaneous replacement). If 's starting system state does not include any configuration conflicts, we are done. Suppose that 's starting system state does include a conflict, i.e.,  or there is a message, , in the communication channel from  to , such that the field , where both  and  are active processors. 
In Claims~\ref{thm:thereBotSim},~\ref{thm:thereBot} and~\ref{thm:onceBot} we show that in all of these cases, eventually  before showing that eventually there are no configuration conflicts  (Claim~\ref{thm:2Config}).



Claims~\ref{thm:thereBotSim},~\ref{thm:thereBot} and~\ref{thm:onceBot} consider the values in the field  that are either held by an active processor  or in its outgoing communication channel to another active processor . We define the set  to be the set of all these values, where  and . 





\begin{claim}
\label{thm:thereBotSim}
Suppose that in 's starting system state, there are  processors  that are active in , for which , where . Eventually the system reaches a state in which  holds. 
\end{claim} 


\begin{proof}
Suppose that  holds. Immediately after 's starting state, processor  has an applicable step that includes the execution of the do forever loop (line~\ref{ln:doForever} to~\ref{ln:send}). In that step, the if-statement condition 

(line~\ref{ln:nullConfig}'s if-statement) holds,  assigns  to  and the proof is done. Suppose that  holds. Upon 's arrival, processor  assigns  to  (line~\ref{ln:receive}) and the case of  holds.
\end{proof}



\begin{claim}
\label{thm:thereBot}
Suppose that in 's starting system state, there are processors  that are active in , for which , where . Eventually the system reaches a state in which   or  holds. 
\end{claim} 


\begin{proof}
Suppose, towards a contradiction, for any system state  that neither  nor . Note that  and  exchange messages eventually, because whenever processor  repeatedly sends the same message to processor , it holds that  receives that message eventually (the fair communication assumption, Section~\ref{s:sys}) and vice versa. Such message exchange implies that the case of  (Claim~\ref{thm:thereBotSim}) holds eventually, where . Thus, we reach a contradiction and therefore eventually the system reaches a state in which 
  or  hold.
\end{proof}






\begin{claim}
\label{thm:onceBot}
Suppose that in 's starting system state, there is a processor  that is active in , for which . (1) For any system state , it holds that . Moreover, (2)  has a suffix, , for which .
\end{claim} 


\begin{proof}
We prove each part of the statement separately. 

\noindent {\bf Part (1).~}
We start the proof by noting that , it holds that, throughout , we have that 's value does not change and that , because this lemma assumes that  is admissible.
To show that  holds in any , we argue that any step  in which  changes 's value includes the execution of line~\ref{ln:nullConfig} or line~\ref{ln:restartConfig} (see the remark at the beginning of this lemma's proof about  not including the execution of lines~\ref{ln:adoptAll} to~\ref{ln:automatonStep}), which assign to  the values , and respectively, . 

\noindent {\bf Part (2).~} In this part of the proof, we first consider the values in  and  before considering the one in .

\noindent {\bf Part (2.1).~} 
To show that in  it holds that , we note that when  loads a message  (line~\ref{ln:send}) before sending to processor , it uses 's value for the field . Thus, eventually  and therefore  records correctly in  the most recent 's value that  receives from  (line~\ref{ln:receive}).

\noindent {\bf Part (2.2).~}
To show that eventually , we note that once  changes the value of , it holds that   thereafter (due to the remark in the beginning of this lemma, which implies that only lines~\ref{ln:nullConfig} and~\ref{ln:restartConfig} can change , and by the part (1) of this claim's proof while replacing the index  with ). Suppose, towards a contradiction, that  does not change that value of  throughout  and yet . 
Note that  (see the second clause of the if-statement condition in line~\ref{ln:restartConfig}) holds throughout , because  is admissible. Therefore, whenever  takes a step that includes the execution of the do forever loop (line~\ref{ln:doForever} to~\ref{ln:send}), processor  sends to  the message , such that  (line~\ref{ln:send}) and  (see part (2.1) of this proof). Since  sends  repeatedly, processor  receives eventually  (the fair communication assumption, Section~\ref{s:sys}) and stores in . Immediately after that step, the system state allows  to take a step in which the condition 

(line~\ref{ln:nullConfig}'s if-statement) holds and  changes 's value to . Thus, this part of the proof end with a contradiction, which implies that the system reaches a state in which .
\end{proof}


\begin{claim}
\label{thm:2Config}
Suppose that in 's starting system state, it holds that for every two  processors  that are active in , we have that , where  is a message in the channel from  to . Eventually the system reaches a state in which .  
\end{claim} 

\begin{proof}
\sloppy{By this claim assumptions, we have that in 's starting system state, the if-statement condition 

(line~\ref{ln:nullConfig}) does not hold.} Moreover,  (line~\ref{ln:restartConfig}) holds throughout , because  is admissible. Therefore, this claim assumptions with respect to 's starting states actually hold for any system state , because only lines~\ref{ln:nullConfig} and~\ref{ln:restartConfig} can change the value of , which later  uses for sending the message  (line~\ref{ln:send}), and thus also  as well as  records correctly the most recent 's that  receives from  (line~\ref{ln:receive}).    

To conclude this proof, we note that immediately after any system state , processor  has an applicable step  that includes the execution of line~\ref{ln:restartConfig} (by similar arguments to the ones used by the first part of this proof). Moreover,  does not include the execution of line~\ref{ln:nullConfig}, because by the first part of this proof the condition of the if-statement of line~\ref{ln:nullConfig} does not hold. In the system state that immediately follow , the invariant  holds. 
\end{proof}



By this lemma's assumption, there is no configuration  replacement state nor replacement message. Claim~\ref{thm:2Config} implies that the system reaches a state  that has no configuration conflict eventually. Thus,  is safe.   
\end{proof}









































\begin{claim}[Eventually there is no type-4 stale information]
\label{thm:noStale4}
Let  be an admissible execution of Algorithm~\ref{alg:disCongif}.
Eventually the system reaches a state  in which the invariant of no type-4 stale information holds thereafter.
\end{claim}
\begin{proof}
Without the loss of generality, suppose that there is no system state in  that encodes a configuration conflict. (We can make this assumption without losing generality because Lemma~\ref{thm:noConflict} implies that this claim is true whenever this assumption is false.) Moreover, let  be a system state in which processor  has an applicable step  that includes the execution of the do forever loop (line~\ref{ln:doForever} to~\ref{ln:send}). 

Since  is admissible, 
 holds in . Therefore, the case in which  in  implies a call  to the function  (line~\ref{ln:stale}) in the step that immediately follows. By using Lemma~\ref{thm:noConflict}, we have that this lemma is true.
\end{proof}


\subsubsection*{Phase and degree progressions}
Let  be an execution of Algorithm~\ref{alg:disCongif} that is admissible with respect to the participant sets. Suppose that  is a processor that is active in  and that . We say that processor  is an active participant in .
Let  be processors that are active participants in  and  a system state. 
\sloppy{We denote by  the set of all pairs that includes the notification and all fields that appear in  (after excluding the default notification, , while including all the information in the processors' states and communication channels as well as their replications, e.g., the echo field).}
We denote by  the set of notifications that appear in .
We denote the \emph{degree set} of notification  by . For a given system state , notification  that appears in , we denote by  the set of all notifications  that have the same set filed as the one of  and  is the set of all notification sets in .







\begin{lemma}
\label{thm:convDeg}
Let  be an execution of Algorithm~\ref{alg:disCongif} that is admissible with respect to the participant sets and that does not include an explicit (delicate) replacement. 
Suppose that in 's starting system state, , there are notifications, i.e., . Let  be a notification for which it holds that  in  (recall the definition of  in the description of the  macro).
The system reaches eventually a state  in which .
\end{lemma}
\begin{proof}
Let  be a step that immediately precedes the system state  and  be the system state that immediately follows .
Note that when the system reaches a system state  in which , the proof is done.
Suppose, in the way of a proof by contradiction, that this lemma is false, i.e., , i.e., the notification  (and additional  notifications that have the same proposed set but different phase number) does not ``disappear'' from the system after any step and ``become'' the default notification . 
Claims~\ref{thm:general},~\ref{thm:notDec} and~\ref{thm:invar} are needed for the proof of Claim~\ref{thm:contra}, which completes this proof by contradiction.

\begin{claim}
\label{thm:general}
Suppose that .
Without the loss of generality, we can assume that (1) no step in  includes a call to , (2) 's lexical value in 's starting system state, , is the greater or equal to the lexical value of any notification in any system state , (3)  in 's starting system state, where  is an active participant in , and (4) step  that immediately follows 's starting system state includes the execution of the do forever loop (line~\ref{ln:doForever} to~\ref{ln:send}). 
\end{claim}
\begin{proof}
	We prove each part of the claim separetly. 
	
\noindent {\bf Part (1).~}
This claim's assumption that  implies that no step in  includes a call to , say, due to the if-statement condition of lines~\ref{ln:stale} or~\ref{ln:nullConfig} hold in any system state . The reason is that Claim~\ref{thm:thereBot} implies that a call to  brings the system to a state   in which . Namely,  and the proof of this  lemma is done.

\noindent {\bf Part (2).~}
We can choose a suffix of , such that 's  lexical value in 's starting system state, , is the greater or equal to the lexical value of any notification in any system state . We can do that because there is a bounded number of possible lexical values and our assumption that . 

\noindent {\bf Part (3).~}
We note that when considering the case in which  encodes a message  that has  in one of its fields, message  reaches eventually from  to  (the fair communication assumption, Section~\ref{s:sys}). Therefore, we suppose that notification  is encoded in 's state, i.e.,  in , where  are active participants in . We can make this assumption, without the loss of generality, because we can take a suffix of  (that system reaches eventually) in which this assumption holds for its starting configuration and then we take that suffix to be the execution that this lemma considers, i.e., .
Using similar arguments about generality, we also assume that step  includes the execution of the do forever loop (line~\ref{ln:doForever} to~\ref{ln:send}), and thus  in . 

\noindent {\bf Part (4).~}
Use the same arguments as for part (3) of this proof.
\end{proof}


\begin{claim}
\label{thm:notDec}
Suppose that step  includes the execution of the do forever loop (line~\ref{ln:doForever} to~\ref{ln:send}) immediately after and before the system states , and respectively, .  When  holds in , we have that  does not decrease in . 
\end{claim}
\begin{proof}
Since  changes only in lines~\ref{ln:readyToReplace} and~\ref{ln:automatonStep} (case 1), the assumption that  in any  implies that  in any  that is after . The reason is that line~\ref{ln:automatonStep} indeed does not decrease  (part (2) of Claim~\ref{thm:general}) and line~\ref{ln:readyToReplace} only decreases  when assigning  (cf. case  of the function ). However, the latter cannot occur for any  that is an active participant in  and for which  holds in  (part (3) of Claim~\ref{thm:general}).~\end{proof}

\begin{claim}
\label{thm:alwaysN}
For every system state , it holds that .
\end{claim}
\begin{proof}
Since  holds in  (Claim~\ref{thm:general}), since  is non-decreasing during step  (Claim~\ref{thm:notDec}), since  is lexically greater or equal than any other notification in any system state of  (Claim~\ref{thm:general}) and by this proof's assumption that  holds, it is true that  holds in every system state .
\end{proof}


\begin{claim}
\label{thm:invar}
The following sequence of invariants is true.
\begin{itemize}[topsep=2pt,itemsep=-.5ex,partopsep=.5ex,parsep=1ex,leftmargin=2mm]
\item []{\bf (1)} Suppose that  holds in  every system state . Eventually the system reaches a state , such that for any  that is an active participant in , it holds that  and . Moreover, 
 and  in  eventually. 

\item[]{\bf (2)} Suppose that invariant (1) holds in  every system state . Eventually the system reaches a state , such that for any  that is an active participant in , it holds that ,  and   in .

\item[]{\bf (3)} Suppose that invariants (1) and (2) hold in every system state . Eventually the system reaches a state , such that for any  that is an active participant in , it holds that   in .

\item[]{\bf (4)} Suppose that invariants (1), (2) and (3) hold in every system state . Eventually the system reaches a state , such that for any  that is an active participant in , it holds that   in . 

\item[]{\bf (5)} Suppose that invariants (1) to (4) hold in every system state . Eventually the system reaches a state , such that for any  that is an active participant in , it holds that  in . 

\item[]{\bf (6)} Suppose that invariants (1) to (5) hold in every system state . Eventually the system reaches a state , such that for any  that is an active participant in , it holds that   in . 






\item[]{\bf (7)} Suppose that invariants (1) to (6) hold in every system state . Eventually the system reaches a state , such that for all  that is an active participant in , it holds that the if-statement condition of line~\ref{ln:readyToReplace} holds in .
\end{itemize}
\end{claim}
\begin{proof} We prove items (1) to (7). 
	
\noindent {\bf (1)} Since  repeatedly sends message  to every active processor  (line~\ref{ln:send}), where , message  arrives eventually to  (line~\ref{ln:receive} and the fair communication assumption, Section~\ref{s:sys}). This causes  to store  in  (at least) as long as , i.e., in every system state  that follows  arrival to . For the case of , we have that  (Claim~\ref{thm:notDec} and line~\ref{ln:automatonStep} (case 1) as well as the fact that  has the greatest lexicographic value in every , cf. part (2) Claim~\ref{thm:general}).
The same arguments as above imply that . Moreover,  is implied by the assumption that  is admissible with respect to the participant sets.

We show that  for any . By the assumptions made in the beginning of the proof of this lemma, we do not need to consider the case of . Thus, we start by considering the case of , we have that  (Claim~\ref{thm:notDec} and line~\ref{ln:automatonStep} (case 1) as well as the fact that  has the greatest lexicographic value in every , cf. part (2) Claim~\ref{thm:general}).
We now turn to consider the case of . I.e.,  while keeping in mind that , we need to show that .
We do that by showing that whenever , the if-statement condition of line~\ref{ln:stale} holds for any value of  and we focus on the case of . Note that by showing that the if-statement condition of line~\ref{ln:stale} does hold in , we have reached  a contradiction (part (1) of Claim~\ref{thm:general}'s statement). 
For the case of , the if-statement condition of line~\ref{ln:stale} holds in  because  implies  (line~\ref{ln:adoptAll}) and the condition  (line~\ref{ln:stale} does hold due to the fact that   and ). Moreover, for the case of , the condition   (line~\ref{ln:stale}) does not hold, because  and , where .






\noindent {\bf (2)} By similar arguments to the ones that show the arrival of  in part (1) of this proof, processor   repeatedly sends the message  to , which indefinitely stores  in  and  (line~\ref{ln:receive}). The same arguments as above imply that .

\noindent {\bf (3)} The system reaches a state in which the invariants of parts (1) and (2) hold for every . In that system state, it holds that  (this claim assumption), as well as the fact that   and  (part (2) of this proof for showing that  eventually and then using part (1) for showing that 
 and ). In other words, 
(cf. line~\ref{ln:addSaw}). 
Let us look at the first step after that state in which processor  executes the do forever loop (lines~\ref{ln:doForever} to~\ref{ln:send}). Immediately after that step, the system reaches a state in which  holds (line~\ref{ln:adoptAll}).

\noindent {\bf (4)} By similar arguments that appear in parts (1) and (2) of this proof, processor  sends repeatedly the message  to processor . Once message  arrives eventually to  (line~\ref{ln:receive} and the fair communication assumption, Section~\ref{s:sys}), processor  stores  in  (as well as the notification  in ). This holds for every system state  that follows 's arrival to . 

\noindent {\bf (5)} By similar arguments that appear in parts (1) and (2) of this proof, processor  sends repeatedly the message  to processor . Once message  arrives eventually to  (line~\ref{ln:receive} and the fair communication assumption, Section~\ref{s:sys}), processor  stores  in . This holds for every system state  that follows 's arrival to . 

\noindent {\bf (6)} We show that, once the invariants of parts (1) to (5) of this proof hold, the for-each condition of line~\ref{ln:addSaw} holds as well. Moreover, we show that assuming, towards a contradiction, that  implies that there is a step in  that includes a call to   (line~\ref{ln:stale}), which is false according to part (1) of Claim~\ref{thm:general}'s statement. 
By showing both the necessity and sufficiency conditions, we can conclude that the assertion of this part in the claim even thought in Algorithm~\ref{alg:disCongif} processors  and  do not exchange  information about  in order to validate that the set  includes . 

The for-each condition of line~\ref{ln:addSaw} condition requires that for any  to have , where the index  is substituted here with . The following is true:   (part (1) of this proof and the assumption that  is admissible with respect to participant sets),  (part (5) of this proof), and  (part (1) of this proof and then apply (4) for the case of ).

We now turn to show that  implies that there is a step in  that includes a call to   (line~\ref{ln:stale}).
By the assumptions made in the beginning of the proof of this lemma, we do not need to consider the case of . Note that for  and , when the following condition holds , the condition  implies that the if-statement condition of line~\ref{ln:stale} holds in , and this contradicts part (1) of Claim~\ref{thm:general}'s statement. Thus,  in . 


\noindent {\bf (7)} Recall that part (5) of this proof says that . By taking   from part (1) and applying it to the results of parts (1) to (6), we get that  holds eventually, because this is true for every pair of processors  that are active participants in . Let us consider a system state in which invariants (1) to (6) hold for any such pair of active participants  and .
This implies that  holds (by the fact that part (4) eventually implies that ). Therefore, the if-statement condition of line~\ref{ln:readyToReplace} holds (by this lemma's assumption that  is admissible with respect to the participant sets and part (4) of this proof that shows ).
\end{proof}

\medskip


Claim~\ref{thm:contra} shows a contradiction to the assumption made in the beginning of the proof of Lemma~\ref{thm:convDeg}. 
This contradiction completes the proof of this lemma.

\begin{claim}
\label{thm:contra}
 in which .
\end{claim}
\begin{proof}
Part (7) of Claim~\ref{thm:invar} says that the if-statement condition of line~\ref{ln:readyToReplace} holds in  eventually. Let  a step that immediately follows  and in which  executes the do forever loop (line~\ref{ln:doForever} to~\ref{ln:send}).
Note that the case of  contradicts this lemma's assumption that  in which .
Suppose that  in . The step  includes an execution of line~\ref{ln:readyToReplace} that increases the lexical value of  (contradicting part (2) of Claim~\ref{thm:general}).
Suppose that  in . The step  includes an execution of line~\ref{ln:readyToReplace} that changes 's value to . Claim~\ref{thm:invar} implies that this holds for any  that is an active participant in . This is a contradiction with the assumption made in the beginning of the proof of this lemma, i.e.,  
 in which .
\end{proof}

\medskip

\noindent This completes the proof of Lemma~\ref{thm:convDeg}.\hfill\end{proof}






\subsubsection*{Algorithm~\ref{alg:disCongif} is self-stabilizing}
Let  be a step in which processor  calls the function  (line~\ref{ln:configEstab}), and in which the if-statement condition  does hold in the system state that immediately precedes . We say that  is an \emph{effective  (configuration establishment)} step in . Similarly, we consider  to be a step in which processor  calls the function  (line~\ref{ln:participate}), and in which the if-statement condition  does hold in the system state that immediately precedes .
Let  be an execution that does include explicit (delicate) replacements, where  and  are a prefix, and respectively, a suffix of . Let us consider , which is a part of execution . We say that  \emph{virtually does not include explicit (delicate) replacements} (VNER) when for any step  that includes a call the function  (line~\ref{ln:configEstab}) or  (line~\ref{ln:participate}) is ineffective. Given a system state , we say that  includes no notification if none of its active processors stores a notification and there are no notifications in transit between any two active processors. 


\begin{lemma}[Eventually there is an VNER part]
\label{thm:virtuallyNotExplicit}
Let  be an execution of Algorithm~\ref{alg:disCongif} (which may include explicit delicate replacements). Eventually the system reaches a state (1)  after which an VNER part, , starts. Moreover, after that, the system reaches eventually a state (2)  that has either (2.1) no notification or (2.2) at most one notification in the system and this notification becomes the system quorum eventually (after reaching a state in which invariants (1) to (7) of Claim~\ref{thm:invar} hold in ). 
\end{lemma}
\begin{proof}
Note that the proof of part (1) is done whenever  has a suffix  in which no processor takes a step that includes a call to the function  (line~\ref{ln:configEstab}). Let us suppose that suffix  exists and show that part (2.1) is true. The reason is that  satisfies the conditions of Lemma~\ref{thm:convDeg}, which implies that eventually  reaches . This is because Lemma~\ref{thm:convDeg} says that the lexical largest notification is removed eventually from the system. Once that happen, either the system reaches , or we can look at the suffix  that starts after that removal (of that lexical largest notification) and then we apply Lemma~\ref{thm:convDeg} again. Since  does not include steps with a call to the function , no new notifications are ``added'' to the system, and we can continue to apply Lemma~\ref{thm:convDeg} to the suffix of  until the system includes no notifications, i.e., it reaches .



For the complementary case, we show that  includes an  part, i.e., part (1) of this proof. We consider the different cases of the phase of the notification with the maximal lexical value. We show that notification must reach the phase value of  and then leaves the system eventually. For this case, we show that parts (1) and (2.1) of this lemma hold.    

Let us consider the case in which  includes an unbounded number of steps in which active processors call the function  (line~\ref{ln:configEstab}).
(Note that this is the  complementary case to the first part of this proof because here  does not exists.) Let .
(Note that the case of  is just another way to say that there are no effective steps in  and thus  exists.)
Suppose that  and let  be a notification with the largest lexical value in , where . (Note that the proof needs not consider the case of , see line~\ref{ln:configEstab}.)

In order to complete the proof of parts (1) and (2) for the complementary case, we show that, for any choice of phase, it cannot be that  and execution  does not have an VNER part, . We do that by showing that the system reaches eventually a state  in which  (line~\ref{ln:noReco}) returns false for any active processor, . Moreover,  marks the beginning of  for which we show in part (2) of the proof that  follows. 
    

\noindent \textbf{Suppose that .~~} This part of the proof considers two cases. One in which  is a proposal that never leaves the system and the another case in which it does leave eventually. 

\noindent  \textit{Suppose that  never leaves the system.}
Suppose, towards a contradiction, that (i)  never leaves the system and yet (ii) the system never reaches . By the same arguments that appear in the proof of part (1) in Claim~\ref{thm:invar} we get that invariant   
 holds, where  are any two active processors. Thus,  (line~\ref{ln:noReco}) returns false for any active processor, , and the system reaches 's first configuration, . Thus, a contradiction because the assumption that (i) and (ii) can hold together is false.

\noindent \textit{Suppose that  does leave the system.}
We note that the case in which  leaves the system eventually contradicts our assumption that  has the highest lexical values in . The reason is that only active processors can make a notification leave the system and they do so by changing their values in lines~\ref{ln:readyToReplace} to~\ref{ln:automatonStep} (Claim~\ref{thm:notDec}). But then, for the case of , the lexical value of  increases when Algorithm~\ref{alg:disCongif} takes such a step.

We note that there is no need to show part (2) of this lemma for the above two cases, because none of them is possible. 


\noindent \textbf{Suppose that .~~}
Similar to the previous case, we consider both the case in which  is a proposal that never leaves the system and the other case in which it does leave eventually. 

\noindent \textit{Suppose that  never leaves the system.}
As in the proof of the first case of   and in which  never leaves the system, we can use the same arguments as in the proof of part (1) of Claim~\ref{thm:invar} for showing that invariant   
 holds, where  are any two active processors. Thus,  (line~\ref{ln:noReco}) returns false for any active processor, , and the system reaches 's first configuration, . 
Note that once the system enters the VNER part of the execution, , we can use similar arguments to the ones used in the proof of Lemma~\ref{thm:convDeg} to show that the system removes . Thus, a contradiction with our assumption (of this case) that  never leaves the system. Moreover, there is no need to prove part (2) of this lemma (for this impossible case). 

\noindent \textit{Suppose that  does leave the system.}
We show that the only possible case is that  does leave the system. Let us  consider the set  of notifications that were present in 's starting state, . We note that , where  is the bound on the link capacity (Section~\ref{sec:settings}). Thus, even though the number of notifications in  is unbounded, the number of the notifications in  is bounded. Since this case assumes that  eventually leaves the system, and all other cases above are impossible, it must be the case that  has a suffix  that starts in a system state  the encodes no notification that appeared in 's starting state. This can be shown by induction on . Moreover, the proof can consider the case in which a given notification  leaves the system and then returns via a call to  (line~\ref{ln:configEstab}). This is done by letting the proof to decorate the notification sets in 's starting system state, say, using the color `red'. Moreover, each set in a notification that is the result of a call to  (line~\ref{ln:configEstab}) also has  decoration, but this time with another color, say `blue'. 


Let  be two notifications (with decorated sets) that become present in  but they are not present in 's starting state. The only way in which   can become present in the system is via a step  that calls  (line~\ref{ln:configEstab}). Moreover, the only way that  can become present in  is via step  that changes  to  (lines~\ref{ln:readyToReplace} to~\ref{ln:automatonStep}), such that . 
Note that after step , other steps  occur in which  disappears from the system (lines~\ref{ln:readyToReplace} to~\ref{ln:automatonStep}). This sequence of steps between  and  and the system state that immediately precedes them are depicted by invariants (1) to (7) of Claim~\ref{thm:invar} since these invariants hold in these states. Thus,  holds immediately before  and  must include an  part, because invariant (1) holds eventually in . Moreover, invariants (1) to (7) of Claim~\ref{thm:invar} imply that  is the only notification in the system, which eventually becomes the quorum configuration after all steps  are taken. Thus, part (2) of this lemma is shown.  
\end{proof}




Theorem~\ref{thm:staleFreeExecution} demonstrates the eventual absence of stale information, which implies that Algorithm~\ref{alg:disCongif} convergences eventually, i.e., it is practically-stabilizing. 

\begin{theorem}[Convergence] 
\label{thm:staleFreeExecution}
Let  be an admissible execution of Algorithm~\ref{alg:disCongif}.
Eventually the system reaches a state  in which the invariants of no type-1, type-2, type-3 and type-4 stale information hold thereafter.  
\end{theorem}
\begin{proof}
Claim~\ref{thm:noStale} shows that there is no type-1 stale information  eventually. 
Lemma~\ref{thm:noConflict} shows that there is no type-2 stale information  eventually. 
Lemmas~\ref{thm:convDeg} and~\ref{thm:virtuallyNotExplicit} say that the system either reaches a state in which there are no notifications or there is at most one notification (for which invariants (1) to (7) of Claim~\ref{thm:invar} hold) that later  becomes the system configuration. Note that both cases imply that there is no type-3 stale information  eventually. 
Claims~\ref{thm:noStale4} shows that there is no type-4 stale information  eventually. 
\end{proof} 
 


\begin{theorem}[Closure]
\label{thm:closureThm}
Let  be an execution of Algorithm~\ref{alg:disCongif}.
Suppose that execution  starts from a system state that includes no stale information. (1) for any system state , it holds that 
 includes no stale information. Suppose that the step that immediately follows  includes a call to . (2) The only way that  becomes a notification is via a call to  (line~\ref{ln:configEstab}) and the only way that a processor becomes a participant is via a call to  (line~\ref{ln:participate}). (3) The presence of notifications in  implies that one of them replaces the system configuration eventually. 
\end{theorem}

\begin{proof} The proof essentially follows from established results above.
	
\noindent \textbf{Part (1).~}~Since there is no stale information in the system state that immediately proceeds , there is no stale information in . 
This follows from a close investigation of the 
lines that can change the system state in a way that might introduce stale information; the most  
relevant lines are the ones that deal with notifications (lines~\ref{ln:adoptAll} and~\ref{ln:automatonStep}) and new participants (line~\ref{ln:join}). 
Thus, the proof is completed via parts (2) and (3). 

\noindent \textbf{Part (2).~}~This is immediate from lines~\ref{ln:configEstab} and~\ref{ln:participate}.

\noindent \textbf{Part (3).~}~It is not difficult to see that  includes an  part (Lemma~\ref{thm:virtuallyNotExplicit}, Part (1)). 
Then, the proof completes by applying part (7) of Claim~\ref{thm:invar} twice: Once for showing the selection of a single notification that has phase , 
and the second time for showing that the selected notification replaces the configuration.~\end{proof}




\subsection{Reconfiguration Management}
\label{sec:reconMan}
The Reconfiguration Management  layer shown in Algorithm~\ref{alg:SSQR} bears the weight of initiating or \emph{triggering} a reconfiguration when (i) the configuration majority has been lost, or (ii) when the prediction function  indicates to a majority of members that a reconfiguration is needed to preserve the configuration.
To trigger a reconfiguration, Algorithm~\ref{alg:SSQR} uses the  interface with the  layer.
In this perspective, the two algorithms display their modularity as to their workings.
Namely,  controls \emph{when} a reconfiguration should take place, but the reconfiguration replacement process is left to , which will install a new configuration also trying to satisfy 's proposal of the new configuration's set.
Several processors may trigger reconfiguration simultaneously, but by the correctness of Algorithm~\ref{alg:disCongif} this does not affect the delicate reconfiguration, and by the correctness of Algorithm~\ref{alg:SSQR}, each processor can only trigger once when this is needed.

In spite of using majorities, the algorithm is generalizable to other (more complex) quorum systems, while the prediction function  can be either very simple, e.g., asking for reconfiguration once  of the members are not trusted, or more complex, based on application criteria or network considerations.
More elaborate methods may also be used to define the set of processors that Algorithm~\ref{alg:SSQR} proposes as the new configuration. Our current implementation, aiming at simplicity of presentation, defines the set of trusted participants of the proposer as the proposed set for the new configuration.




\begin{algorithm*}[t]

   \caption{Self-stabilizing Reconfiguration Management; code for processor }
\label{alg:SSQR}
\begin{footnotesize}




\noindent {\bf Interfaces:}
 returns  on whether a reconfiguration is required or not by using some (possibly application-based) prediction function.
The rest of the interfaces are specified in Algorithm~\ref{alg:disCongif}.
 returns  if a reconfiguration is not taking place, or  otherwise.
 initiates the creation of a new configuration based on the .
 returns the current local configuration.
\label{SSQR:interfaces}


\noindent {\bf Variables:} \label{SSQR:var}
 is an array of size at most , composed of booleans , where   holds the last value of  that  received from  as a result of exchange (lines~\ref{SSQR:send} and \ref{SSQR:receive}) and  is an alias to  i.e., of 's last reading of .
Similarly,  is an array of booleans of size at most  on whether some trusted processor of  detects a majority of members that are active per the reading of line~\ref{SSQR:testMaj}.
 (for ) holds the last value of  that  received from . 
Finally  holds 's believed previous .
\\

\noindent {\bf Macros:} \\
 \;\label{SSQR:defCore}
 \lForEach{}{}
\noindent {\bf Do forever} \Begin{
\If{\label{SSQR:isPartpnt}}{
\; \label{SSQR:readConfig}

\;\label{SSQR:ownFlagReset}
\lIf{  }{\label{SSQR:configChanged}
}\label{SSQR:flagsResetAll}

\If{}{ \label{SSQR:configChanging}

  \; \label{SSQR:updatePrev}

\lIf{}{} \label{SSQR:testMaj}
\uIf{      \label{SSQR:checkNoMajCore}}{
\; \label{SSQR:noMajTrigger}
\;\label{SSQR:noMajResetAll}
}

\ElseIf{  \label{SSQR:gracefulQreconf}}{
\; \label{SSQR:needReconfTrigger}
\;\label{SSQR:needReconfResetAll}
}  

}

\lForEach{  }{} \label{SSQR:send}
}
}

\noindent {\bf Upon receive}  {\bf from}  \textbf{do} \label{SSQR:receive} \lIf{}{}\label{SSQR:receiveStore}





\end{footnotesize}
\end{algorithm*}
\setlength{\textfloatsep}{5pt}




\remove{
\begin{lemma}[Lemma~\ref{thQ:triggeredWhenNeeded}]
Starting from an  execution, Algorithm~\ref{alg:SSQR} guarantees that (1) if a majority of  members collapse or (2) if a majority of members require a reconfiguration as per the prediction function, a reconfiguration takes place.\vspace{-.5em}
\end{lemma}

\begin{lemma}[Lemma~\ref{thQ:triggersControlled}]
Starting from an  execution, any call to   (lines~\ref{SSQR:noMajTrigger} and~\ref{SSQR:needReconfTrigger}) related to a specific event (majority collapse or agreement of majority to change ), can only cause a one per participant trigger. After the  has been established, no triggering that relate to this event take place.\vspace{-.5em}
\end{lemma}


\begin{theorem}[\textbf{Theorem~\ref{thQ:corrUpperApp}}]
\label{thQ:corrUpper}
Let  be an execution of Algorithm~\ref{alg:SSQR} starting from an arbitrary system state.  has a suffix in which is a legal execution.\vspace{-1em}
\end{theorem}
}






\subsubsection{Algorithm Description}
\paragraph{Preserving a majority.}
The algorithm strives to ensure that a majority of the configuration is active. Although majority is a special case of a quorum, the solution in extensible to host other quorum systems that can be built on top of the  set, in which case, the algorithm aims at keeping a robust quorum system where robustness criteria are subject to the system's dynamics and application requirements. 
In this vein, the presented algorithm employs a configuration evaluation function  used as a black box, which predicts the quality of the current  and advises any participant whether a reconfiguration of  needs to take place.
Given that local information is possibly inaccurate, we prevent unilateral reconfiguration requests --that may be the result of inaccurate failure detection-- by demanding that a processor must first be informed of a majority of processors in the current  that also require a reconfiguration (lines~\ref{SSQR:gracefulQreconf}--\ref{SSQR:needReconfResetAll}). 

\paragraph{Majority failure.}
On the other hand, we ensure liveness by handling the case were either the prediction function does not manage to sustain a majority, or an initial arbitrary state lacks a majority but there are no  inconsistencies that can trigger a delicate reconfiguration (via the  interface).
Lines~\ref{SSQR:checkNoMajCore}--\ref{SSQR:noMajResetAll} tackle this case by defining the \emph{core} of a processor  to be the intersection of the failure detector readings that  has for the processors in its own failure detector, i.e., .
If this local core agrees that there is no majority, i.e. that , then  can request a new .
As a liveness condition to avoid triggering a new  due to FD inconsistencies when there actually exists a majority of active configuration members, we place the \emph{majority-supportive core} assumption on the failure detectors, as seen in Definition~\ref{def:majSupCore} below.
Simply put, the assumption requires that if a majority of the current configuration is active, then the core of every processor  that is a participant, contains at least one processor  with a failure detector supporting that a majority of  is trusted.
Furthermore,  has knowledge that  can detect a majority of trusted members.





\paragraph{Detailed description.}
The algorithm is essentially executed only by participants as the condition of line~\ref{SSQR:isPartpnt} suggests.
Line~\ref{SSQR:readConfig} reads the current configuration, while line~\ref{SSQR:ownFlagReset} initiates the local  and  variables to . 
If a change from the previous configuration has taken place, the arrays  and  are reset to  (line~\ref{SSQR:flagsResetAll}).
The algorithm proceeds to evaluate whether a reconfiguration is required by first checking whether a reconfiguration is already taking place (line~\ref{SSQR:configChanging}) through the  interface of .
If this is not the case, then it checks whether it can see a trusted majority of configuration members, and updates the local  boolean accordingly (line~\ref{SSQR:testMaj}).
If , i.e., no majority of members is active, and line~\ref{SSQR:checkNoMajCore} finds that all the processors in its core also fail to find a majority of members, then  can trigger reconfiguration using  with the current local set of participants as the proposed new  set (lines~\ref{SSQR:noMajTrigger}--\ref{SSQR:noMajResetAll}).
The  and  arrays are again reset to  to prevent other processors that will receive these to trigger.
Line~\ref{SSQR:gracefulQreconf} checks whether the prediction function  suggests a reconfiguration, and if a majority of members appears to agree on this, then the triggering proceeds as above.
Participants continuously exchange their  and  variables (lines~\ref{SSQR:send}--\ref{SSQR:receiveStore}). 










\subsubsection{Correctness}
The Reconfiguration Management algorithm is responsible for triggering a reconfiguration when either a majority of the members crash or whenever the (application-based)  evaluation mechanism  suggests to a members' majority that a reconfiguration is required. 
The correctness proof ensures that, given the assumption of majority-supportive core holds, Algorithm~\ref{alg:SSQR} can converge from a transient initial state to a safe state, namely, that after  has triggered a reconfiguration, it will never trigger a new one before the previous one is completed and only if a new event makes it necessary.

\paragraph{Terminology.} We use the term \emph{steady  state} to indicate a system state in an execution were a  has been installed by Algorithm~\ref{alg:disCongif} at least once, and the system state is conflict-free.
A \emph{legal execution}  for Algorithm~\ref{alg:SSQR}, refers to an execution that converges to a steady  state.
Moreover, a reconfiguration in  takes place only when a majority of the configuration members fails, or when a majority of the members require a reconfiguration.
The system remains conflict-free and moves to a new steady  state with a new configuration.

\begin{definition} [Majority-supportive core]
\label{def:majSupCore}
Consider a steady  state in an execution  where the majority of members of the established  never crashes.
The \emph{majority-supportive core} assumption requires that every participant  with a local core   containing more than one processor, must have a core with at least one active participant  whose failure detector trusts a majority of the , and for such a processor  throughout . 
\end{definition}

\begin{remark}
\label{rem:reconfThroughInterface}
We say that Algorithm~\ref{alg:disCongif} is \emph{triggered} when a reconfiguration is initialized. By Algorithm~\ref{alg:SSQR}, the only way that Algorithm~\ref{alg:SSQR} can cause a triggering of Algorithm~\ref{alg:disCongif} is through a call to the  interface with Algorithm~\ref{alg:disCongif} on lines~\ref{SSQR:noMajTrigger} and~\ref{SSQR:needReconfTrigger}.
\end{remark}


\begin{lemma}
\label{thQ:reachSteady}
Starting from an arbitrary initial state in an execution , where stale information exists, Algorithm~\ref{alg:SSQR} converges to a steady  state where local stale information are removed.
\end{lemma}

\begin{proof}
Consider a processor  with an arbitrary initial local state where stale information exists  (1) in the program counter, (2) in  and  and (3) in . \\
\textbf{Case 1} -- Stale information may initiate the algorithm in a line other than the first of the pseudocode.
If 's program counter starts after line~\ref{SSQR:configChanging} and if a reconfiguration is taking place, then Algorithm~\ref{alg:SSQR} may force a second reconfiguration while Algorithm~\ref{alg:disCongif} is already reconfiguring.
The counter for example could start on lines~\ref{SSQR:noMajTrigger} and~\ref{SSQR:needReconfTrigger}.
This would force a brute reconfiguration.
This triggering cannot be prevented in such a transient state, but we note that any subsequent iteration of the algorithm is prevented from accessing  lines (as in  Remark~\ref{rem:reconfThroughInterface}) before the reconfiguration is finished.



\noindent\textbf{Case 2} -- We note that after a triggering as the one described above, the fields of arrays  and  are set to . 
Moreover, in every iteration  and  are set to .
During a reconfiguration these values are propagated to other processors and  receives their corresponding values.
Therefore,  must eventually receive  () from some participant , and overwrite any transient values.
Lemma~\ref{thQ:noAbruptConfigTriggered} bounds the number of reconfigurations that may be triggered by corruption that is not local, i.e., that emerges from corrupt  () values that arrive from the communication links.

\noindent\textbf{Case 3} -- We anticipate that any reconfiguration returns a different configuration than the previous one.
In a transient state though, the previous configuration () and the current configuration  may coincide.
This ignores the check of line~\ref{SSQR:flagsResetAll} that sets  and  to  upon the detection of a reconfiguration change. 
This forms a source of a potential unneeded reconfiguration.
Nevertheless,  receives the most recent configuration value on every iteration of line~\ref{SSQR:updatePrev} and thus the above may only take place once throughout  per processor.

\noindent Eliminating these sources of corruption, we reach a steady  state without local stale information.
\end{proof}
\vspace{.5em}

\begin{lemma}
\label{thQ:noAbruptConfigTriggered}
Consider a steady  state  in an execution  where the majority-supportive core assumption holds throughout, the majority of  processors never crash and there is never a majority of members supporting . 
There is a bounded number of triggerings of the Algorithm~\ref{alg:disCongif} that are a result of stale information, namely  .
\end{lemma}

\begin{proof}
By Remark~\ref{rem:reconfThroughInterface}, the only way that the algorithm may interrupt a steady  state, is by reaching lines~\ref{SSQR:noMajTrigger} and~\ref{SSQR:needReconfTrigger} that have a call to .
We assume that some member  has triggered Algorithm~\ref{alg:disCongif} at some system state , and we examine whether and when this state is attainable from .
We note that \emph{in a complete iteration} of Algorithm~\ref{alg:SSQR},  must have no reconfiguration taking place while triggering, since this is a condition to reach the above mentioned lines imposed by line~\ref{SSQR:configChanging}.
We first prove that if there is a triggering it must be due to initial corrupt information and then argue that this can take place a bounded number of times.


\noindent \textbf{Case 1 -- The reconfiguration was initiated by line~\ref{SSQR:noMajTrigger}}. 
\sloppy{This implies that the condition of line~\ref{SSQR:checkNoMajCore} is satisfied, i.e.,
at some system state ,  has local information that satisfies      .}
Condition   may be true locally for , only due to failure detector inaccuracy, because, by the \assert, the majority of processors in the  never fails throughout . 
Condition  suggests that  has at least two participant processors in its core (without requiring ). 
By the majority-supportive core assumption and the above, we are guaranteed that  throughout  and .
But in this case,  and  which contradicts the majority supportive assumption. 
We thus reach to the result.


Note that  can reside in 's local state or in the communication links that may carry stale information. 
Because of the boundedness of our system, we can have one instance of corrupt  in 's local state, and  instances in the communication link.
I.e., such information may cause a maximum of  triggerings per processor.
Any processor that enters the system cannot introduce corrupt information to the system due to the data-links protocols and the joining mechanism.
Thus majority supportive assumption is also attainable even when starting from arbitrary states.





\noindent \textbf{Case 2 -- The reconfiguration procedure was triggered by line~\ref{SSQR:gracefulQreconf}}.
This implies that for , both conditions were true, i.e., (a)  and (b) .
We note that the  variable is always set to  upon the beginning of every iteration.
Thus the local function  due to 's failure detector and other application criteria explicitly suggested a reconfiguration \emph{in the specific iteration} in which  triggered the reconfiguration.
From the \assert, there is no majority of processors in the  that supports a reconfiguration, even at the time when  triggered the reconfiguration.


Thus  must reside in 's local state and in the communication links. 
We can have one instance of corrupt  in 's local state, and  instances in the communication links.
I.e. such information may cause a maximum of  triggerings per processor.
Note that after every such triggering, the source of triggering is eliminated by reseting  to  (lines~\ref{SSQR:flagsResetAll}, \ref{SSQR:noMajResetAll} and~\ref{SSQR:needReconfResetAll}).
From this point onwards any processor that enters the system cannot by the data-links and the joining mechanism introduce corrupt information to the system.

So the possible triggerings in the system attributed to stale information are confined to  and by Algorithm~\ref{alg:disCongif} guarantees we always reach a steady  state.
\end{proof}

\vspace{.5em}
Let  denote a \emph{safe system state} where all possible sources of triggerings  attributed to the arbitrary initial state have been eliminated.
We denote an execution starting from  as .

\begin{lemma}
\label{thQ:steadyRemainsSteady}
Consider an execution  where the majority-supportive core assumption holds throughout, the majority of  processors never crash and there is never a majority of the  with local . 
This execution is composed of only steady  states. 
\end{lemma}

\begin{proof}
By Lemma~\ref{thQ:noAbruptConfigTriggered} there is a bounded number of triggerings due to initial arbitrary information.
Given that we have reached a safe system state, these triggerings do not occur.
The last  change, has by line~\ref{SSQR:flagsResetAll} reset all the fields in  and  to  and this holds for all participants (even if they are not members of the ).
By our assumption a majority of processors does not crash. 
The majority-supportive core assumption states that throughout  there exists at least one processor  in the core of  that always has  and  has  .
Thus the condition of line~\ref{SSQR:checkNoMajCore} can never be true, and thus there is no iteration of the algorithm that can reach line~\ref{SSQR:noMajTrigger}.
Similarly, since no majority of processors in the  change to  in this execution, and the local states are exchanged continuously over the token-based data-link, line~\ref{SSQR:needReconfTrigger} cannot be true.
Thus any system state in  is a steady  state.
\end{proof}

\begin{lemma}
\label{thQ:triggeredWhenNeeded}
Starting from an  execution, Algorithm~\ref{alg:SSQR} guarantees that if (1) a majority of  members collapse or if (2) a majority of members require a reconfiguration as per the prediction function, a reconfiguration takes place.
\end{lemma}

\begin{proof} We consider the two cases separately.

\noindent \textbf{Case 1 --} 
If a majority of the members collapses, then based on the failure detector's correctness, a non-crashed participant  will eventually stop including a majority of  members in its failure detector and participants () set.
We remind that rejoins are not permitted.
Since the majority-supporting core assumption does not apply in this case, any processor in 's core must eventually reach to the same conclusion as .
Every such participating processor  propagates  in every iteration. 
By the assumption that a packet sent infinitely often arrives infinitely often (the fair communication assumption, Section~\ref{s:sys}), any processor such as  must eventually collect a  from every member like  core and thus enable a reconfiguration.

\noindent \textbf{Case 2 --} 
The arguments are similar to Case 1. 
The difference lies in that the processor  must eventually receive  from a majority of  members (rather than the local core processors) before it moves to  trigger a reconfiguration.
\end{proof}


\begin{lemma}
\label{thQ:triggersControlled}
Starting from an  execution, any triggering of Algorithm~\ref{alg:disCongif} (lines~\ref{SSQR:noMajTrigger} and~\ref{SSQR:needReconfTrigger}) related to a specific event (majority collapse or agreement of majority to change ), can only cause a one per participant concurrent trigger. After the  has been established, no triggerings that relate to this event take place.
\end{lemma}

\begin{proof}
We consider the two cases that can trigger a reconfiguration (Remark~\ref{rem:reconfThroughInterface}), and assume that  is the first processor to trigger .
Assume first that  has called Algorithm~\ref{alg:disCongif} two consecutive times, without a  being \emph{completely} established between the two calls. Note that a processor can access  in either of lines~\ref{SSQR:noMajTrigger} or~\ref{SSQR:needReconfTrigger} but not both in a single iteration.
A call to  initiates a reconfiguration and thus any subsequent check of  in line~\ref{SSQR:configChanging} returns  from 's  layer. 
Thus  cannot access lines~\ref{SSQR:noMajTrigger} or~\ref{SSQR:needReconfTrigger} until the reconfiguration has been completed. 
This implies that   can never trigger for a second time unless the new  has been established.
Note that if  triggers, another processor satisfying the conditions of line~\ref{SSQR:configChanging} may trigger concurrently, but is also subject to the trigger-once limitation.
On the other hand, due to the exchange of information in Algorithm~\ref{alg:disCongif}, when one processor triggers other processors eventually find their proposals and join the reconfiguration. 
So not every single processor's Reconfiguration Management module needs to trigger.
Convergence to a single  is guaranteed by Algorithm~\ref{alg:disCongif}.


We conclude by indicating that lines~\ref{SSQR:noMajResetAll} and~\ref{SSQR:needReconfResetAll} reset both arrays  and  immediately after .
Thus the triggering data used for this event are not used again.
Moreover, upon configuration change, the same arrays are again set to  for the processors that have not triggered Algorithm~\ref{alg:disCongif}  themselves through Algorithm~\ref{alg:SSQR}.
We thus reach a new steady  state, and no more triggerings can take place due to the same event that had caused the reconfiguration.
\end{proof}


\begin{theorem}
\label{thQ:corrUpperApp}
Let  be an execution starting from an arbitrary system state. Algorithm~\ref{alg:SSQR} guarantees that  eventually reaches an execution suffix which is a legal execution.
\end{theorem}

\begin{proof}
By Lemmas~\ref{thQ:reachSteady} and~\ref{thQ:noAbruptConfigTriggered}, we are guaranteed that we reach a safe system state  where stale information from the arbitrary initial state cannot force a triggering of new .
This is the suffix .
Lemma~\ref{thQ:steadyRemainsSteady} ensures that after we have reached , and until a new triggering takes place that is caused by a loss of majority or a majority of the  deciding to reconfigure, the current  will not be changed for any other reason.
Lemma~\ref{thQ:triggersControlled} guarantees that after a change, we return to a steady  state.
Hence,  is a legal execution.
\end{proof}





















\remove{
A \emph{legal execution}  of Algorithm~\ref{alg:SSQR}, refers to an execution composed by steady  states and delicate configurations triggered due to loss of majority of configuration members, or due to the need of the majority of the members to reconfigure. 
The following lemmas give the outline of the proof, leading to the proof of Theorem~\ref{thm:corrupper}. The omitted details and proofs can be found in Appendix~\ref{app:upper}.\vspace{-.5em}



\begin{theorem}
\label{thm:corrupper}
Let  be an execution of Algorithm~\ref{alg:SSQR} starting from an arbitrary system state.  reaches a legal execution.\vspace{-1em}
\end{theorem}

}







\subsection{Joining Mechanism}
\label{sec:join}
Every processor that wants to become a participant, uses the snap stabilizing data-link protocol (see Section~\ref{s:sys}) so as to avoid introducing stale information after it establishes a connection with the system's processors. 
Algorithm~\ref{alg:disCongif} enables a joiner to obtain the agreed  when no reconfiguration is taking place.
Note that, in spite of having knowledge of this , a processor should only be able to participate in the computation if the application allows it.
In order to sustain the self-stabilization property, it is also important that a new processor initializes its application-related local variables to either default values or to the latest values that a majority of the configuration members suggest.
The joining protocol, Algorithm~\ref{alg:join}, illustrates the above and introduces joiners to the system, but only as \emph{participants} and not as  \emph{members}.

The critical difference between a participant and a joiner is that the first is allowed to send configuration information via the  layer, whereas the latter may only receive.





\setlength{\intextsep}{0pt}
\begin{algorithm}[t]

\caption{Self-stabilizing Joining Mechanism; code for processor }
\label{alg:join} \begin{footnotesize}

\noindent {\bf Interfaces.}
The algorithm uses following interfaces from Algorithm~\ref{alg:disCongif}.
 returns  if a reconfiguration is not taking place.
 makes  a participant. 
 returns the agreed configuration from Algorithm~\ref{alg:disCongif} or  if reconfiguration is taking place.
The  interface to the application, returns a  in response to granting a permission to a joining processor.


{\bf Variables.}
 as defined in Algorithm~\ref{alg:disCongif}.
 is array of containing application states, where  represents 's local variables and  the state that  most recently received by .  collects all the passes that  receives from configuration members.

{\bf Functions.}  initializes all variables related to the application based on default values.
 initializes all variables related to the application based on states exchanged with the configuration members.\\ 



{\bf procedure}  \Begin{\label{JOIN:start}
\lForEach{}{} \label{JOIN:resetPass}
{\bf do forever} \Begin{\label{JOIN:doForever}
\If{\label{JOIN:checkPart}}{
\; \label{JOIN:resetVars}
\Repeat{}{
\label{JOIN:repeatStart}
\textbf{let} \; \label{JOIN:readConfig}
\If{   \label{JOIN:checkConfig}}{
\; \label{JOIN:initVars}
\; \label{JOIN:bePartpnt}
} 

\lForEach{}{\textbf{send}} \label{JOIN:send}}
\label{JOIN:repeatEnd}
}
}
}


{\bf upon receive}  \textbf{from}  {\bf do} \Begin{
\lIf{  \label{JOIN:assessPass}}
{\textbf{send}\label{JOIN:sendPass}}
}
{\bf upon receive}  \textbf{from}  {\bf do} \Begin{
\lIf{}{
} \label{JOIN:receiveJoiner} 
}

\end{footnotesize}
\end{algorithm}





\subsubsection{Algorithm description}
The algorithm is executed by non-participants and participants alike.

\paragraph{The joiner's side.}
Upon a call to the  procedure, a joiner sets all the entries of its  array to  (line~\ref{JOIN:resetPass}) and resets application-related variables to default values, (lines~\ref{JOIN:resetVars}).
The processor then enters a do-forever loop, the contents of which it executes only while it is not a participant (line~\ref{JOIN:checkPart}).
A joiner then enters a loop in which it tries to gather enough support from a majority of configuration members.
In every iteration, the joiner sends a  request (line~\ref{JOIN:send}) and stores the  responses by any configuration member  in , along with the latest application  that  has send. 
If a majority of active members has granted a  and there is no reconfiguration taking place, then  is called to allow the joining processor to become a participant.


\paragraph{The participant's side.}
A participant only executes the do--forever loop (line~\ref{JOIN:doForever}), but none of its contents since it always fails the condition of line~\ref{JOIN:checkPart}. 
Participants however respond to join requests (line~\ref{JOIN:assessPass}) by checking whether a joining processor has the correct configuration, and whether a reconfiguration is not taking place, as well as if the application can accept a new processor.
If the above are satisfied then the participant sends a  and its applications' , otherwise it responds with . 



\subsubsection{Correctness}
\label{app:join}
The term \emph{legal join initiation} indicates a processor's attempt to become a participant by initiating Algorithm~\ref{alg:join} on line~\ref{JOIN:start}, and not on any other line of the  procedure. If the latter case occurred it would indicate a corruption to the program counter.

\begin{lemma}
\label{thJ:boundedCorruptJoins}
Consider an arbitrary initial state in an execution . 
There are up to  possible instances of processors introducing corruption to the system.
\end{lemma}

\begin{proof}
Processors may be found with an uninitialized or falsely initialized local state due to a transient fault in their program counter which allowed them to reach line~\ref{JOIN:initVars} without a legal join initiation.
In an arbitrary initial state, any processor with stale information may manage to become a participant.
There can be up to  such processors, i.e., the maximal number of active processors.
Nevertheless, a processor trying to access the system after this, is forced to start the execution of  from line~\ref{JOIN:start}.


\end{proof}


\begin{claim}
\label{thJ:noReconfJoin}
Consider any processor  performing a legal join initiation. 
In the existence of other participants in the system, this processor never becomes a participant through the  procedure during reconfiguration.
\end{claim}

\begin{proof}
We consider the situation where participants exist and reconfiguration is taking place, thus  is .
In order for  to become a participant, it needs to gather a pass from at least a majority of the configuration members.
This can only happen if a configuration is in place, and if each of these members is not reconfiguring.
Thus if a pass is granted, it must be that during the execution more than a majority of  passes have arrived at .
Note that since the propagation of passes is continuous if a reconfiguration starts, then passes can also be retracted.
Finally, since getting a majority of passes can coincide with the initialization of a reconfiguration, we note that due to asynchrony this processor is considered a participant of the previous configuration, since it has full knowledge of the system's state and is also known by the previous configuration members.
\end{proof}



\begin{lemma}
\label{thQ:noReconfByJoiner}
Consider an execution  where Lemma~\ref{thJ:noReconfJoin} holds, such that during , a processor  becomes a participant. 
Then  cannot cause a reconfiguration, unless there exists a majority of the configuration set, or if there is no majority of the  that requires a reconfiguration.
\end{lemma}

\begin{proof}
We assume that  enters the computation with a legal join initiation. 
If  triggers a reconfiguration in the absence of the above two cases, then this implies that  has managed to become a participant while carrying corrupt information which have triggered a reconfiguration either directly or indirectly (through Algorithm~\ref{alg:SSQR}).
Corruption can either be local or in the communication links.
Since the snap-stabilizing data-link protocol runs before the processor calls , this removes data-link corruption for newly joining participants. 
We turn to the case of a corrupt local state.
By the legal join initiation assumption,  must have reset its state on line~\ref{JOIN:resetVars}.
Before joining, the majority of members must acknowledge the latest state of  and  initiates its variables to legal values.
It is therefore impossible that  can become a participant while it carries a corrupt state.
Therefore,  cannot cause a reconfiguration.
\end{proof}

\begin{theorem}
\label{thJ:finalApp}
Consider an arbitrary initial state of an execution  of Algorithm~\ref{alg:join}. 
We eventually reach an execution suffix in which every joining processor  will continue trying to join a participant if the application allows it. Additionally, this new processor cannot trigger a delicate reconfiguration before becoming a participant and cannot trigger a delicate reconfiguration without majority loss or majority agreement after it becomes a participant.
\end{theorem}

\begin{proof}
By Lemma~\ref{thJ:boundedCorruptJoins}, we eventually reach an execution suffix where all joining processors enter the computation with a legal join initiation.
We assume that a reconfiguration is not taking place, that messages sent infinitely often are eventually received infinitely often, and that the application interface invoked by the participating processors allows  to join. 
Then  will eventually have a failure detector including a majority of member processors and will send its  request to a majority (line~\ref{JOIN:send}).
Since there is no reconfiguration taking place,  must learn the current configuration from Algorithm~\ref{alg:disCongif}, which should agree with the  held by other processors.
Thus each member must grant a pass to  by sending  through line~\ref{JOIN:sendPass}.
Therefore,  will gather a majority supporting its entrance and will eventually satisfy line~\ref{JOIN:checkConfig}.
This allows it to reach line~\ref{JOIN:bePartpnt} and thus  becomes a participant.
Notice that if the application does not give permission of entry via , then  cannot become a participant unless this changes, but  will continue sending requests.
Finally, Lemma~\ref{thQ:noReconfByJoiner} ensures that the new participant does not cause perturbations to the current configuration, and hence the result. 
\end{proof}





\section{Applications of the Reconfiguration Scheme}
\label{sec:labelCounter}
Using our self-stabilizing reconfiguration scheme, we present a collection of applications designed for more static settings (with a known fixed set of crash-prone processors) and adapt them to be able to run on the more dynamic setting that we describe here.
We first present a general purpose labeling and counter scheme (Sections~\ref{sec:label} and~\ref{sec:counter}) and then proceed to show how to build a  \emph{self-stabilizing} reconfigurable virtually synchronous replicated state machine (Section~\ref{sec:VS}). 





\subsection{Labeling Scheme and Algorithm}
\label{sec:label}
Many distributed applications assume access to an unbounded counter, e.g., to provide ballot numbers for consensus in Paxos, tag numbers for distributed shared memory emulation or view identifiers for virtually synchronous reliable multicast~\cite{SSVS}.
An unbounded counter implemented as a 64-bit integer, for example, is practically inexhaustible when initiated at 0 for the lifetime of most known systems.
Transient failures, nevertheless, can immediately drive the counter (\emph{sequence number} or ) to its maximal value (e.g., ) causing it to wrap. 
Recently, we extended an existing labeling and counter increment scheme to enable any processor of a fixed processor set to increment a counter integer attached to an epoch ~\cite{SSVS}.
When the counter is exhausted, a new maximal label is used with a non-exhausted . 
We now adjust that solution to benefit from our reconfiguration mechanism. 
In this scheme, configuration members are the ones that run the labeling algorithm and maintain a globally maximal label and counter.
The labeling and counter increment algorithms consider every new configuration as a new instance of the corresponding algorithms of~\cite{SSVS}.
To this end, Algorithm~\ref{alg:configLabeling} is a wrapper of the self-stabilizing labeling algorithm of~\cite{SSVS} that retains the initial algorithm as a module (Algorithm~\ref{alg:receiveLabels}) allowing it to cope with reconfiguration. 
We first provide the labeling algorithm, and then extend labels to counters, presenting how counter increments take place.


\begin{algorithm*}[t!]
\caption{{Self-Stabilizing Labeling Algorithm for Reconfiguration; code for }}
\label{alg:configLabeling}


\begin{footnotesize}

{\bf Variables:} Let  be the size of the configuration  as returned by .\\
 of label pairs , :  is 's largest label pair,  refers to 's  label pair that was last sent to  (canceled when ).
: an array of queues of label pairs, where  holds the labels created by . For , 's queue size is limited to  w.r.t. label pairs, where  is the maximum number of label pairs that can be in transit in the system. The 's queue size is limited to  pairs.

{\bf Interfaces:}
 returns  (from the reconfiguration module) when a reconfiguration is taking place, and  otherwise.
 returns the current configuration if one exists.
 maintains the label arrays by calling the receive function of Algorithm~\ref{alg:receiveLabels}.\\
{\bf Operators:}
 rebuilds the  array of queues and  to have  entries. It also adjusts the queue size for the new .
 clears all  queues.
 returns  if a reconfiguration has taken place, and  otherwise, by comparing the current label structures with the result of .

{\bf Macros:}\\  {\bf if}    {\bf then return}  {\bf else return }; 
\label{LAB:cleanLP}



{\bf function}  \lForEach{}{} \label{LAB:cleanMax}




{\bf do forever} \label{LAB:doForever}\Begin{

\If{ \label{LAB:uponConfChange}}{
\; \label{LAB:newSize}
\; \label{LAB:rebuild}
\;\label{LAB:emptyQs}
\;\label{LAB:cleanUponReconf}
\; \label{LAB:findNewMax}
}
}

{\bf upon} \label{LAB:beginTransmit} \Begin{
\If{}{{
\bf transmit}\label{LAB:transmit}}
}


{\bf upon}  {\bf from}  \Begin{  \label{LAB:uponReceive}
\If{}{
\; \label{LAB:receiveCleanMax}
\;\label{LAB:cleanReceived}
\; \label{LAB:receiveAction}
} 
}


\end{footnotesize}
\end{algorithm*}



\begin{algorithm*}[t!]
\caption{{Self-Stabilizing Labeling Algorithm receipt action; code for }}
\label{alg:receiveLabels}


\begin{small}

{\bf Variables:} For a configuration  with \\
 of , :  is 's largest label pair,  refers to 's label pair (canceled when ).\\

: an array of queues of the most-recently-used label pairs, where  holds the labels created by . For , 's queue size is limited to  w.r.t. label pairs, where  is the maximum number of label pairs that can be in transit in the system. The 's queue size is limited to  pairs. The operator  adds  to the front of the queue, and  clears all  queues. We use  for removing the record . Note that an element is brought to the queue front every time this element is accessed in the queue.\\
 creates a label that is greater than any other label in .\\










{\bf Notation:} Let  and  be two records that include the field . We denote        \\

{\bf Macros:}\\
    ~~~\\
  {\Return{}}\\
~~~\\ \label{ln:double}
~~~\\ \label{ln:staleInfo}
~~~\\
    ~~~\\
      ~~~\\
~~\\
~\label{ln:legitLabels}~\\
      ~\label{ln:useOwnLabelDef}
\tcp{For every , we pass in  both  and .}


{\bf function} 
\Begin{
  \; \label{ln:exposeStore}
\lIf{  }{} \label{ln:lastSentCancel}

    \lIf{}{} \label{LBLln:clean}

     \lForEach{}{} \label{ln:add}

        \lForEach{}{} \label{ln:cancelLabels}

        \lForEach{}{} \label{ln:receivedCanceled}

        \lForEach{}{} \label{ln:remove}

        \lForEach{}{} \label{ln:cancelMax}

    \lIf{}{} \label{ln:adopt}

    \lElse{}  \label{ln:useOwnLabel} 


}

\end{small}

\end{algorithm*}


\subsubsection{Description of Algorithm~\ref{alg:configLabeling}}



\noindent{\bf Outline.} 
The algorithm is run only by configuration members.
Each label is marked by its creator's identifier and any two labels are compared first as to their creator identifier and then as to a set of integers using the operator . 
Labels by the same processor can be \emph{incomparable}.
A processor that is aware of a set of labels with its own identifier, can always create a greater label.
The aim is for members to learn of any valid label in the system and finally result to the globally greatest one, and to this end, members exchange labels.
We refer the reader to~\cite{SSVS} for more details on the label structure. 
The algorithm ignores labels by non-member creators by setting them to .
If Algorithm~\ref{alg:disCongif} reports that a reconfiguration is taking place (via ), no actions are taken.
Upon the completion of a reconfiguration, every member's local label storage is rebuilt to reflect the new configuration set, and all the label queues are emptied. 
Newly joined processors are assumed to join with initialized links and empty label structures and thus cannot introduce corrupt information. 
If a reconfiguration is not reported, member  of the configuration periodically sends and receives its locally maximal labels with all the other members.
Whenever it sends or receives a new label pair, it checks whether this has the identifier of one of the current members. 
The received label pairs are passed to the receive function (Algorithm~\ref{alg:receiveLabels}), which is exactly the same as the one in~\cite{SSVS}.
This always returns a local maximal label either by some other member or by the caller itself. 
We underline that for every configuration we can find a greatest label, but it cannot be guaranteed that the label of a configuration will continue being the greatest in a following configuration.










\paragraph{Variables.} Processor  that belongs to a configuration  with , has an array , where  contains the local maximal label  knows, and  the last value that  member  has send.
The array of label queues  holds a queue of size  in  for labels concerning processor , and queues of size  for all other configuration members in .

\paragraph{Interfaces and Operators.}
The  interface of Algorithm~\ref{alg:disCongif}  returns  when a reconfiguration is taking place, and  otherwise. It also returns the current configuration if one exists via .
 maintains the label arrays by calling the receive function of Algorithm~\ref{alg:receiveLabels}.
 clears all  queues.
 returns  if a reconfiguration has taken place, and  otherwise, by comparing the current label structures with the result of .

\paragraph{During reconfiguration.}  The conditions  and   of lines~\ref{LAB:uponReceive} and~\ref{LAB:transmit} prevent transition and reception of labels during reconfiguration and before the label structures have been reset after reconfiguration has taken place.  

\paragraph{After reconfiguration.} Lines~\ref{LAB:uponConfChange}--\ref{LAB:findNewMax} are only executed upon a completed reconfiguration.
Line~\ref{LAB:newSize} gets the new configuration from Algorithm~\ref{alg:disCongif}, and line~\ref{LAB:rebuild} uses  to adjust  array so that it holds the entries of any processor that also belonged to the previous configuration, removing the ones by old removed members and adding new fields for the labels of new  members.
Line~\ref{LAB:cleanUponReconf} removes labels from the new  that were not created by configuration members. 
The effect is analogous for , where -sized label queues are added and removed to reflect the changes in the  composition, but noting that  is now the cardinality of the new configuration set.
These queues are emptied by line~\ref{LAB:emptyQs}.
Finally, the processor finds a new local maximal label either from the ones that it has in , or by creating a new one with its one creator identifier (line~\ref{LAB:findNewMax}).

\paragraph{Label exchange and maintenance.} If a reconfiguration is not taking place, then a member periodically sends to every other configuration member  its own local maximal label and the last label that  sent for the local maximal label.
Note that messages from non-members are discarded before being sent, so they are not propagated (lines~\ref{LAB:beginTransmit}--\ref{LAB:transmit}).

Similarly when  receives a message as the one described above, it cleans its  array and the received two labels from non-member labels and passes them to the  (Algorithm~\ref{alg:receiveLabels}).
The description of the inner workings of the  is given in great detail in~\cite{SSVS}. 
As an overview, it first stores 's value in  and processes it along with the other label that was received which reflected 's maximal label that was received most recently by .
In general terms, it performs housekeeping of labels in  and  such that only the greatest label per processor is considered before a local maximal label is chosen by .

\subsubsection{Correctness}
\textbf{Outline.} We first establish that after a full iteration, of Algorithm~\ref{alg:receiveLabels} every configuration member does not sustain and does not introduce  any label that has a creator identifier by a non-member.
It is then possible to map every configuration of an execution to an instance of the fixed-set labeling algorithm of~\cite{SSVS} and thus induce the correctness proof therein.
This ensures that eventually a maximal label is found.
Since the algorithm is aware of configuration changes (that exist after reconfigurations), it can use this events to achieve more efficient convergence for a configuration that follows a reconfiguration (in contrast to one that is in place in an initial arbitrary state). 
We thus reach to the above bounds where  is an upper bound on the system and thus a possible upper bound for the configuration size.


{\em Note about participants that are not members.} Algorithms~\ref{alg:configLabeling} and~\ref{alg:receiveLabels} are run by processors that are strictly \emph{members} of the current configuration and only if a reconfiguration is not taking place.
Members send, receive and take into account only labels that come from and concern processors that are members.
In this perspective, it should not be possible for a non-member processor to add labels to the system in a way that will affect the system.
If a processor for any reason stops being a member after a configuration but remains an active participant, then once reconfiguration takes place, the member processors stop considering labels from this processor and \textit{void} (set to ) any label pair from this processor. 







\begin{lemma}
\label{thL:staleInfo}
Consider an arbitrary starting system state of an execution  where a configuration does not change throughout , a processor  reaches a local state where there are no labels from any processor , immediately after the first iteration of Algorithm~\ref{alg:configLabeling} that includes a receive event. 
Moreover, a label by  can never be introduced to the local state of  at any point after the configuration is established.
\end{lemma}

\begin{proof}
Notice that while the configuration does not change because the reconfiguration module finds that this configuration can serve the system, there could be corruption relating to the local variables of the labeling algorithm.
We first establish that at any point after a complete execution of lines~\ref{LAB:uponReceive}--\ref{LAB:receiveAction}, 's local state never contains a label by a non-member .
Assume for contradiction that such a label exists at some system state after the execution of these lines.
This label can exist either in (i) the  array or (ii) the  array.

Member  acknowledges that , since the configuration is agreed and any inconsistency will cause a reconfiguration in Algorithm~\ref{alg:disCongif}. 
We have already assumed for the purposes of the proof that a reconfiguration does not happen throughout .
Labels arriving from  cannot start a receive event by the conditions line~\ref{LAB:uponReceive}. 
If a label created by  is received from some processor  then this is set to  by line~\ref{LAB:cleanReceived}. 
So no incoming labels can enter the local state.

We now consider the system state immediately after line~\ref{LAB:receiveAction} returns from executing Algorithm~\ref{alg:receiveLabels}.
Line~\ref{LAB:receiveCleanMax} of Algorithm~\ref{alg:configLabeling} guarantees that  is cleaned of labels that appear as created by .
Assume that a label by  exists in the  structure.
There are two cases depending on the structure of the  array of queues.\\
\noindent {\bf Case 1 --} \textbf{Processor  does not have an entry for  in .}
This must be true for a legal state, since a member processor should only keep queues in  that relate to member processors.
So 's label must reside in a queue of  that is not intended for 's labels. 
In such a case since , line~\ref{LBLln:clean} of Algorithm~\ref{alg:receiveLabels} will cause the flushing of the queues because .

\noindent {\bf Case 2 --} \textbf{Processor  has an entry for  in .}
This is the result of transient fault and implies that the label structures queues where not prepared for the new configuration.
Nevertheless, in a complete iteration of lines~\ref{LAB:doForever}--\ref{LAB:receiveCleanMax},  of line~\ref{LAB:uponConfChange} will return  because of this discrepancy between  and the composition of the label structures.
But this causes the algorithm to move to line~\ref{LAB:uponConfChange} and so execute lines~\ref{LAB:newSize}--\ref{LAB:cleanUponReconf} thus emptying the  and cleaning  of -created labels.

Therefore, immediately after a receive is completed for Case~1 or after the execution of line~\ref{LAB:cleanUponReconf} in Case~2, there cannot be a label created by  inside 's local state.
Furthermore, we have established that such incoming labels cannot enter 's state.
Hence we reach to the result.
It is evident that once 's state is cleaned, it cannot transmit any such labels via line~\ref{LAB:transmit}.
\end{proof}


\begin{lemma} \label{thL:map2SSVS}
Consider an execution  of Algorithm~\ref{alg:configLabeling} where Lemma~\ref{thL:staleInfo} holds and no reconfiguration takes place throughout . 
It holds that this instance of the problem of providing a self-stabilizing labeling scheme in the dynamic setting can be reduced to the one of the problem of a fixed processor set self-stabilizing labeling scheme problem, where the fixed set is the common configuration. 
\end{lemma}

\begin{proof}
Note that the fixed-set version allows for processors from a specific non-changing set to crash but not rejoin.
We identify the agreed configuration set to this fixed set of possibly active processors.
Processors of the configuration may crash but may not rejoin.
Algorithms~\ref{alg:configLabeling} and~\ref{alg:receiveLabels} are run only by member processors.
As established by Lemma~\ref{thL:staleInfo}, labels can have the identifier of any of the processors in this set but of no other processor.
The communication links between configuration members are of bounded capacity and no labels from a non-member can be added to the local state of the member processors (since they are not considered by line~\ref{LAB:uponReceive}) nor can be added to the communication links between the processors (line~\ref{LAB:transmit}).
Hence, the algorithm reduces every execution  to an instance of providing self-stabilizing labels. 
\end{proof}
\vspace{.5em}

The corollary follows since we can use the solution to the fixed processor set problem to solve each instance of the problem whenever a reconfiguration is not taking place.
In particular Algorithm~\ref{alg:receiveLabels} and line~\ref{LAB:transmit} comprise of the solution given in~\cite{SSVS} to solve the fixed-set problem.




\begin{corollary}
\label{thL:maxReached}
Consider an execution  of Algorithm~\ref{alg:configLabeling} starting in an arbitrary state.  
While a reconfiguration is not taking place, the solution provided by~\cite{SSVS} can be used to guarantee that a maximal label created by a member of the configuration will eventually be adopted by all active members.
\end{corollary}

\noindent The theorem follows. 

\begin{theorem}
\label{thL:finalApp}
\label{thL:uniqueLabel}
Starting in an arbitrary state, Algorithm~\ref{alg:configLabeling} provides a maximal label. If a reconfiguration does not take place then there can be up to  label creations before a maximal label is established. If a reconfiguration takes place then there can be up to  label creations.
\end{theorem}

\begin{proof}
By Corollary~\ref{thL:maxReached} Algorithm~\ref{alg:configLabeling} reaches a maximal label.
By the results of Dolev et al~\cite{SSVS} the worse case takes place when starting in an arbitrary state which requires at most  label creations, where  is the system's communication link capacity in labels and in our case .
A processor may create a label with its own identifier the label it considers as maximal is canceled and it knows of no other labels.
Labels that are possibly unknown to some processor and may cancel its maximal label, are found either in the local state (  and ), or in transit between configuration members.
Note that in an arbitrary state, the configuration may happen to be valid and not require a change, although the labels in the system may be corrupt.
This is a worse case scenario that requires possibly  label creations until the maximal label is reached.

Nevertheless, if a reconfiguration takes place, then the snap stabilizing link will clear the  labels found in the communication links and any active participant will empty their local queues in . 
The only source of labels that could possibly force a processor to create new labels in order to find a maximal, are the  arrays.
There are up to  such arrays of size at most , and hence  possible label creations.
\end{proof}


\subsection{Counter Increment Algorithms}
\label{sec:counter} 
Using the labeling algorithm, we implement a practically infinite self-stabilizing counter, inexhaustible for the lifetime of most known systems (e.g., with upper bound of ).
We first show how to move from labels to counters and then provide a description of the algorithm along with a correctness proof.




\subsubsection{Description}

\begin{algorithm}
\caption{{Self-stabilizing Counter Management Algorithm for Reconfiguration; code for }}
\label{alg:configCounting}


\begin{footnotesize}
(Let  be the size of the configuration  as returned by ).\\
{\bf Variables:}
A counter is a triple  where  is a label of the labeling scheme,  is the sequence number related to , and  is the identifier of the creator of this . A counter pair  extends a label pair.  is a canceling counter for , such that  or . 
We rename structures  and  of Alg.~\ref{alg:receiveLabels} to   and  that hold counter pairs instead of label pairs.
Array  of counter pairs , :  is 's largest counter pair,  refers to 's  counter pair that was last sent to  (canceled when ).
: an array of queues of the counter pairs, where  holds the counters with labels created by . 
For , 's queue size is limited to  w.r.t. counter pairs, where  is the maximum number of counter pairs that can be in transit in the system. 
The 's queue size is limited to  pairs.
\label{CCT:var} \\

{\bf Interfaces:}
 returns  (from the reconfiguration module) when a reconfiguration is taking place, and  otherwise.
 returns the current configuration if one exists.
 - executes the function  of Algorithm~\ref{alg:receiveLabels} adjusted for counter structures and handling counters.
For counter pairs with the same  label, only the instance with the greatest counter w.r.t.  is retained. 
In case where one counter is canceled, we keep the canceled.
For ease of presentation we assume that a counter with a label created by  in line~\ref{ln:useOwnLabel} of Algorithm~\ref{alg:receiveLabels}, is initiated with a  and . A call of  (without arguments) essentially ignores lines~\ref{ln:exposeStore} and~\ref{ln:lastSentCancel} of Alg.~\ref{alg:receiveLabels}.

{\bf Operators:} 
 rebuilds the  array of queues and  to have  entries. It also adjusts the queue size for the new .
 clears all  queues.
 returns  if a reconfiguration has taken place, and  otherwise, by comparing the current counter structures with the result of .
 - places a counter pair  at the front of a queue. 
If  already exists in the queue, it only maintains the instance with the greatest counter w.r.t. , placing it at the front of the queue. 
If one counter pair is canceled then the canceled copy is the one retained. \label{CCT:operations}\\ 
{\bf Notation:} Let  and  be two records that include the field . We denote        .\\



{\bf Macros:}\\  {\bf if}    {\bf then return}  {\bf else return }; \\
    ~~~\\
	\\	
 {}\\  
	 	\lForEach{}{}  
	 \label{CCT:cancExh}




{\bf function}  \lForEach{}{} 




{\bf do forever} \Begin{

\If{}{
\; \; \;\;\; }
}

{\bf upon}  \Begin{
\If{}{{
\bf transmit}}
}


{\bf upon}  {\bf from}  \Begin{  \If{}{
\; \;\; } 
}

\textbf{upon request to increment counter } \Begin{ 
\lIf{}{\textbf{return} } \label{CCT:incr}}

\end{footnotesize}
\end{algorithm}








\paragraph{Counters.}
The labeling scheme used above, can be used to implement counters.  
The idea is to extend the labeling scheme to handle {\em counters}, where a counter is a triple , where  is an integer {\em sequence number}, ranging from  to , where  is large enough, say ; and  the processor identifier of the  creator (not necessarily the same as the 's creator). 
Specifically, we say that counter  is {\em smaller} than counter , and write that , if (), or (() and ()), or ) and () and (. 
Note that when processors have the same label, the above relation forms a total ordering and processors can increment a shared counter also when attempting to do so concurrently. 
Also, when the labels of the two counters from the same processor are incomparable, the counters are also incomparable.

\paragraph{Outline.} 
Algorithm~\ref{alg:configCounting} maintains counters as Algorithm~\ref{alg:configLabeling} maintains labels. 
Counter increment for a participant that is not a configuration member is seen in Algorithm~\ref{alg:cntrIncrNonMember}, and for a member, which also bears the responsibility to maintain the maximal counter, in Algorithm~\ref{alg:cntrIncrMember}. A participant that wants to increment the counter, first queries the configuration for the maximal counter.
It only needs to consider the responses of the majority, because the intersection property of majorities guarantees at least one member that holds the most recent value of a completed counter increment.
Having this maximal counter,  is incremented and written back to the configuration, awaiting for acknowledgments from a majority.
This is, in spirit, similar to the two-phase write operation of MWMR register implementations, focusing on the sequence number rather than on an associated value. 

Configuration members have the extra task of retaining the maximal value and ensuring the convergence property.
To that end, they exchange their maximal counter and update their counter structures in the same way as in the labeling algorithm. 
The maximal counter needs to have the maximal label held by the configuration members and the highest sequence number, breaking symmetry with the writer identifier. 
If this maximal sequence number is {\em exhausted}, members proceed to find a new maximal label, using the maximal sequence number known for this epoch label (possibly 0 if it is a newly created or unused label). 

\paragraph{Variables.} The counter management algorithm (Algorithm~\ref{alg:configCounting}) uses the same structures and procedures as the labeling algorithm, but now with counters instead of labels. 
Specifically we name the  array to  and the  array of label queues to  array of counter queues.
Processors only hold one copy of a counter with the same label, namely the one with the highest  (breaking ties with ). 
Processors send and receive pairs of counters  where the first is the believed \emph{maximal} counter, and the second a \emph{cancelling} counter.
While  then  is not-cancelled and can be considered as a valid candidate for the local maximal counter.
When a counter becomes exhausted, i.e., its  exceeds ,  becomes canceled by assigning .


\paragraph{Interfaces and Operators.}
 is an interface to Algorithm~\ref{alg:receiveLabels} which now acts on and maintains counter pairs rather than label pairs.
It concludes by naming a local maximal label.
We do not present this algorithm again as it is essentially the same, less naming ``counter'' in place of ``label".
The rest of the interfaces and operators are detailed at the beginning the algorithms in which they are being used for the first time.


\paragraph{Maintaining a maximal counter.} Algorithm~\ref{alg:configCounting} presents how Algorithm~\ref{alg:configLabeling} is modified to maintain a largest counter (rather than just the largest label), by exchanging the local maximal counters with other configuration members.
The conditions that prevent send/receive during reconfiguration are the same.
Similarly, the above actions do not take place after reconfiguration, until the structures are rebuild and reset in exactly the same way as described by the labeling algorithm.
In addition, the same conditions that prevent send/receive also prevent incrementing the counter (line~\ref{CCT:incr}).

\begin{algorithm*}[t!]
   \caption{Counter Increment for configuration member ; code for }

\label{alg:cntrIncrMember}
\begin{footnotesize}
{\bf Variables, Interfaces and Macros} are found in Algorithm~\ref{alg:configCounting}. \\
\textbf{Operator:}  aborts the procedure and returns 

{\bf Notation:} Let  and  be two records that include the field . We denote        .\\
{\bf Macros:}\\  {\bf return} \\
	  \\
 {\bf return} 
	
\BlankLine



{\bf procedure}  \Begin{
	\;
	\Repeat{}{; }{\bf let} \label{CIM:incrCntr}\; 
	\lIf{} {\; }\textbf{return} \;
}

{\bf procedure}  \Begin{ \label{CIM:majRead}
\lForEach {}{{\bf send} }
	\While{waiting for responses from majority of }{{\bf upon receipt of}  {\bf from}  {\bf do}\\
\lIf{}{ \textbf{else}  \nllabel{CIM:readCntrs}} 
	}
}	


{\bf upon request for}  {\bf from}  \Begin{
	\If{}{\; 
	{\bf send}  {\bf to} ;}\lElse{\textbf{send} }
}
\vspace{.1em}
{\bf procedure}  \Begin{		
		\;\; 
;}



{\bf procedure}  \Begin{
	\lForEach{}{{\bf send} } 	
	{{\bf wait for  from majority of }\; 
	\lIf{ {\bf received}}{}}
}

{\bf upon request for}  {\bf from}  \Begin{ 
\If{}{\nllabel{CIM:getGreatest}\;
	\lIf{}{}\lIf{}{}{\bf send  to} \;
	}
	\lElse{\textbf{send} }
}


\end{footnotesize}
\end{algorithm*} 




\paragraph{Counter increment for configuration members.} Algorithm~\ref{alg:cntrIncrMember} shows how configuration members increment the counter. 
A member  first sends a query to all other members requesting the counter that they consider as the global maximum and awaits for responses from a majority.
These counters are gathered and passed to the counter structures (line~\ref{CIM:readCntrs}). 
Using the  the algorithm eventually finds the maximal epoch label and the maximal sequence number it knows for this label. 
In other words, it collects counters and finds the counter(s) with the largest global label; there can be more than one such counter, in which case it returns the one with the highest sequence number, breaking symmetry with the sequence number processor ids. 
Then it checks whether this maximal sequence number is {\em exhausted}.
When this is the case, it proceeds to find a new maximal label  until it finds one that is not exhausted and uses the maximal sequence number it knows for this epoch label. 
The processor then increments the sequence number by one, sets its identifier as the writer of the sequence number (line~\ref{CIM:incrCntr}) and sends the new counter to all members, awaiting for acknowledgments from a majority.
Note that read and write requests during reconfigurations are answered with .
When the processor requesting the read/write receives an  it immediately terminates the increment procedure returning .




\paragraph{Counter increment for non-member participants.} 
As per Algorithm~\ref{alg:cntrIncrNonMember}, participants that do not  belong to the configuration, request counters from a majority of configuration members.
They request the greatest with respect to  counter that is non-exhausted and legit. They then increment and write this to a majority of the configuration.
If at any point during read or write they receive an , they stop the procedure and return .
The same happens if they do not manage to find a maximal counter after the read.
They can expect though that because of the counter propagation and the correctness of the labeling algorithm, such a counter will eventually appear.

\begin{algorithm*}[t!]
   \caption{Counter Increment for non-member participant ; code for }

\label{alg:cntrIncrNonMember}
\begin{footnotesize}


{\bf procedure} \label{CtNM:beginIncrement} \Begin{
	\textbf{let} \label{CtNM:qRead}\;
	\If{ }{\textbf{let}  \textbf{else let} }
	\If{}{
	{\bf let} \label{CtNM:cntIncr}\; 
	\lIf{\label{algCtNM:qWrite}}{\textbf{return}  \textbf{else return} }
	}
	\lElse{\textbf{return} }
}\label{CtNM:end}

{\bf procedure}  \label{CtNM:qReadDef}\Begin{
\textbf{let} \;
	\lForEach {}{{\bf send} }
	\While{ }{\label{CtNM:qDataBookkeep}
{\bf upon receipt of}  {\bf from}  {\bf do}
\lIf{}{ \textbf{else} } 
	}
\label{CtNM:majReadEnd}
	\textbf{return} ;
}	


{\bf procedure}  \label{CtNM:qWriteSend}
\Begin{
	\lForEach{}{{\bf send} } 
	{\bf if  from majority of  received then wait\; else if  received then \;}
\label{algCt:waitQWrite}
}
\end{footnotesize}
\end{algorithm*} 




\subsubsection{Correctness}
\begin{lemma}
\label{thCNT:convLab}
Starting from an arbitrary state, in an execution  of Algorithm~\ref{alg:configCounting}, configuration members eventually converge to a global maximal label.
\end{lemma}

\begin{proof}
We note that the result asks that configuration members reach to a global maximal label, and thus it is not assume that they all hold the same  and  corresponding to this label.
We prove in a step-by-step fashion, following the labeling algorithm lemmas and explaining how the new algorithms allow do not affect the correctness.\\
\noindent (i) Initially we note that labels by non-members are in an identical way as in the labeling algorithm excluded and cannot be reintroduced to the system (Lemma~\ref{thL:staleInfo}).
This is immediate for Algorithm~\ref{alg:configCounting}.
Also lines~\ref{CIM:readCntrs} and~\ref{CIM:getGreatest} of Algorithm~\ref{alg:cntrIncrMember} guarantee that counters read during reads or writes are set to  if they have labels by processors not in the current configuration.\\
\noindent (ii) In the same way as the labeling algorithm here is reduced the algorithm of \cite{SSVS} we perform the same reduction on the counter algorithm, by running the algorithm on the configuration member set and having each instance of the counter algorithm correspond to the fixed-set case.
\noindent (iii) By this we conclude that we reach to a global maximal label for all active members.
The bounds given by Theorem~\ref{thL:uniqueLabel} are still relevant, since as we have explained, counters with a corrupted  and counters with a corrupt label are bounded by the same numbers.
Thus a counter may be adopted but then be exhausted very quickly, because it was initialized near its maximum.
Thus eventually any corrupt counters will be removed.
\end{proof}

\begin{theorem}
\label{thCNT:finalApp}
Starting from an arbitrary state, Algorithms~\ref{alg:configCounting}, \ref{alg:cntrIncrMember} and~\ref{alg:cntrIncrNonMember} eventually establish a monotonically increasing counter within the configuration that they are being executed.
\end{theorem}

\begin{proof}
We first note that Lemma~\ref{thCNT:convLab} ensures that processors reach to a maximal label.
We establish that any two calls to  return a strictly ordered counter value. 
Consider a processor  performing a counter increment.
Given that no reconfiguration takes place and thus no aborts take place during counter reads or writes, then if a majority has received the global counter  then by the intersection property of majorities,  must receive at least one copy of  when it reads (line~\ref{CIM:majRead} for Alg.~\ref{alg:cntrIncrMember} and line~\ref{CtNM:qReadDef} for Alg.~\ref{alg:cntrIncrNonMember}).
For Algorithm~\ref{alg:cntrIncrNonMember} if any of the counters collected is legit and not exhausted it is incremented, and written back to a majority of configuration members with the writer's .
In the members' algorithm, a member can always find a maximal counter (with Algorithm~\ref{alg:configCounting}, even if the majority did not manage to return a legit, non-exhausted counter.
Note that members always hold the greatest counter and discard of the smaller one. 
This ensures that after the write completes, any subsequent call to  will return at least one copy of this new greatest value. 
Concurrent calls to  may return to two processors  and  the same global maximal counter.
This will be incremented by both to the same , but will will be written with different 's, so assuming , any subsequent comparison will give the counter by  as the maximal.
Hence the counter algorithm establishes a monotonically increasing counter.
Also note, that for non-members, the algorithm will return a greater counter than the last completed call at the time of the call, or will return a , in cases where reconfiguration is taking place, or where it is impossible to find a maximal counter, since the labels have yet to converge (and therefore incomparable counters exist).
\end{proof}





\subsection{Reconfigurable Virtually Synchronous State Machine Replication} 
\label{sec:VS}







The self-stabilizing reconfiguration service together with the self-stabilizing labeling and counter scheme, can extend the capabilities of various applications to run on more dynamic settings.
Virtual synchrony is an established technique for achieving state machine replication (SMR).
We have recently presented a self-stabilizing virtually synchronous SMR algorithm for a fixed set of processors~\cite{SSVS}.
We now discuss how this virtually synchronous SMR solution can benefit from the reconfiguration service to run on more dynamically changing environments.
We note that applications can use the reconfiguration service to guarantee continuous service, only when a delicate reconfigurations take place between periods of steady configuration and not when brute reconfiguration takes place. 
Nevertheless, brute reconfiguration guarantees that, after a transient fault, the service will eventually return to the desired behavior. 

A \emph{view} is a the set of processors with a unique identifier, that allows to the view members to achieve reliable multicast within the view.
The self-stabilizing reconfigurable virtually synchronous SMR task is specified such that any two processors that are together in any two consecutive views will deliver the same messages in their respective views and preserve the same state.
Moreover, the two views can be belong to two different consecutive configurations when the second configuration was the result of delicate reconfiguration. 
A pseudocode is found in Algorithm~\ref{alg:rvs} and a description and correctness proof follows.

\subsubsection{Description} 

\paragraph{Obtaining a coordinator.}
The virtual synchrony algorithm of~\cite{SSVS} is coordinator-based and works on the primary component given the \emph{supportive majority} assumption on the failure detectors.
This assumption states that a majority of processors of the (fixed) processor set mutually never suspect some processor on their failure detectors throughout an infinite execution, given that this processor does not crash.
The proof of~\cite{SSVS} establishes that such a supported processor eventually becomes the coordinator throughout the execution.

We modify the definition of supportive majority so that a majority of the configuration members' set () needs to provide such support to the coordinator.
Out of the current , any  member with supporting majority can obtain a counter from the labeling and counter algorithms that are run on . 
The processor with the greatest counter, becomes the coordinator and establishes a \emph{view} reflecting its own local failure detector, and with the counter as its view identifier{\footnote{We may occasionally refer to view members and this should not be confused with configuration members, although a majority of configuration members must belong to the view}}.
In doing so it also collects the states from view members as well as undelivered messages and synchronizes to create the most up-to-date state for the view members to replicate.
The coordinator changes the view when the view set does not reflect its failure detector set.
View members follow the view composition and state of the coordinator.
Upon coordinator collapse, the same process provides a new coordinator and preserves the state. Note that the correctness for this is immediate from the correctness proofs of~\cite{SSVS}.

\paragraph{Coordinator-controlled joins.}
By the joining protocol, before a joiner tries to become a participant, it has any application-related local data set to . The coordinator is the one that controls whether the application may or may not allow joining processors to become participants.
Several approaches may be used to give permission to joiners.
The coordinator may allow joining whenever it detects that more participants are required, by raising a flag and warning  members that they can allow access to the application. 
This can be easily applied to our current joining protocol (Algorithm~\ref{alg:join}) where configuration members implement the  interface, simply by returning their most recent  value they have for the coordinator's flag.
Another approach would be for a configuration member to provide the coordinator's details to the joiner so that joiners may, by directly communicating with the coordinator, gain permission to become participants.

Note that in both cases, joiners may become participants but they have yet to gain access to the application.
This takes place if they are part of the coordinator's FD and are subsequently included in the next view.
In becoming part of the view they also acquire a copy of the most recent state and begin state replication.
This gives leverage to the application when controlling the number of processors that are allowed to access the application. 


\begingroup
\LinesNumberedHidden
\begin{algorithm}[t!]

\caption{Coordinator-led delicate reconfiguration; code for processor }
\label{alg:coordUpper}

\begin{footnotesize}

\nlset{1} \noindent {\bf Interfaces:}
 returns  on whether  is the coordinator and whether application criteria requires and is ready for a  a reconfiguration.
\label{coordUpper:interfaces}

\tcc{Replaces line~\ref{SSQR:gracefulQreconf} of Reconfiguration Management layer}
\vspace{.3em}

\nlset{17} \uElseIf{\label{coordUpper:delicate}}{
}


\end{footnotesize}
\end{algorithm}
\endgroup





\paragraph{Coordinator-initiated reconfiguration.}
The coordinator can be given the authority to initiate delicate reconfigurations.
This implies that there is no need for the prediction functions of a majority of processors to support a reconfiguration before it can take place, but it only suffices for a coordinator to be in place, in order to take the decision for reconfiguration based on application-specific criteria and suspend changes to the state during reconfiguration. To this end, line~\ref{SSQR:gracefulQreconf} of Algorithm~\ref{alg:SSQR} that triggers the delicate reconfiguration in Algorithm~\ref{alg:disCongif} is replaced with line~\ref{coordUpper:delicate} of Algorithm~\ref{alg:coordUpper}.
The  flag is rendered unnecessary for this cause.


\begin{algorithm*}[t!]

   \caption{Self-stabilizing reconfigurable VS SMR; code \textbf{for participant} }
\label{alg:rvs}
\begin{footnotesize}




\noindent {\bf Interfaces:}
 next multicast message, 
 applies the step  to  (while producing side effects), 
 returns a replica consolidated state, 
 returns a consolidated array of last delivered messages, 
 returns a counter from the increment counter algorithm,
 returns the latest configuration and  returns  on whether a reconfiguration is \emph{not} taking place (Algorithm~\ref{alg:disCongif}),
 is the reconfiguration prediction function returning .
\nllabel{VSln:inter} 

\noindent {\bf Variables:} \nllabel{VSln:var}
The following arrays consider both 's own value (the -th entry) and 's most recently received value (the -th entry).  
  , , 
  , , , 
   , 
 ,        ,       , 
  , ,    ,    : an array of state variables. 
 returns the last reported identifier of 's local coordinator which is continuously propagated using the token exchange (see Section~\ref{s:sys}). It is  if  has no coordinator. 

\textbf{Function}  \; 
 \nllabel{VSln:go4reconf}

\noindent {\bf Do forever} \Begin{

\textbf{let} ; \tcp{Gets latest \config ~set}
{\bf let}        
     
   
 
   
                   \; \nllabel{VSln:seemCrd}

{\bf let}              \; \nllabel{VSln:valCrd}

    ; \; \nllabel{VSln:noCrd}


\lIf{  \nllabel{VSln:updSuspMult}}{\nllabel{VSln:noCrdSusp}} 
\lElseIf{}{\nllabel{VSln:updSuspNoCrd}}
\lIf{}{ \nllabel{VSln:suspOnRecon}} 

\lIf{
 
 
             
    
  
 
}
{  , , } \nllabel{VSln:incrCntr}

\ElseIf{         , ,   , ,             \nllabel{ln:switch}}{
\If{\nllabel{VSln:mulC}}{
; \; \nllabel{VSln:evalSuspend}
\If{  \nllabel{VSln:setReconfReady}} 
{
\; \nllabel{VSln:fetchCrd}
\lForEach{}{{\bf if} ~{\bf then}  {\bf else} \nllabel{ln:collect}}
\; \nllabel{VSln:rndIncr}
}
}
\lElseIf{\nllabel{VSln:proC}}{}
\lElseIf{\nllabel{VSln:insC}}{, 0, )}}


\ElseIf{\nllabel{VSln:repF}}{
\If{\nllabel{VSln:optCond}}{
\tcc*{also adopts suspend flag}\nllabel{VSln:replicate} 
\tcc*{for the sake of side-effects} \nllabel{VSln:applyF}\lIf{}{ \nllabel{ln:fetchFol}}
}
\lElseIf{\nllabel{ln:adoptRep}}{}
\lElseIf{}{}
\nllabel{VSln:adoptProp}
}






{\bf let}                      \nllabel{VSln:sendSet}

\lForEach{  }{} \nllabel{VSln:send}
} 

\noindent {\bf Upon message arrival}  {\bf from}  {\bf do} \; \nllabel{VSln:receive}


\end{footnotesize}
\end{algorithm*}




\paragraph{Before reconfiguration.}
In order to initiate a reconfiguration that will not result in loss of the state of the replicas, the coordinator must ensure that all view processors have the most recent state and that the exchange of messages is suspended.
We require that for the state to survive to the first view of the next configuration, at least one replica 
of the last view before reconfiguration must not crash. 


When the coordinator is informed by its prediction function that reconfiguration is required, it performs a multicast round to gather the most recent state and received messages, but also raises a  flag that it propagates with the current state. 
It waits until all view members return their current state and messages and that they have suspended new messages.
Upon receiving this information it performs a final multicast round to ensure that the last state with the messages have been received and applied and then calls the reconfiguration through Algorithm~\ref{alg:SSQR}. 
Note that in case of coordinator crash, a new view coordinator needs to be established before the reconfiguration can take place, which adds an extra delay.





\paragraph{After reconfiguration.}
Once the labeling and increment counter algorithm have stabilized to a new max counter any member of the new configuration has access to a counter value in order to become the coordinator.
Processors propagate their state which can be either the last before reconfiguration or  in case they are newly joining processors.
The new coordinator will synchronize the states and messages and establish the new view so that the service can continue, and will also resume the application for new messages to be fetched.
This is in essence a mere view installation with nothing additional to the algorithm of~\cite{SSVS}.

\paragraph{Providing service.} 
Inside the view, the basic functionality of the algorithm of~\cite{SSVS}, i.e., reliable multicast and state replication, are not in any way obstructed by the underlying reconfiguration service when a reconfiguration is not taking place. 
Additionally, view changes are not affected when reconfiguration is not taking place.








\subsubsection{Correctness}
We establish the correctness of the algorithm, by extending the correctness results of~\cite{SSVS}. 
We first prove that the proposed service (Algorithm~\ref{alg:rvs}), when working in an established configuration, is an execution of the algorithm of~\cite{SSVS} and thus the correctness for that case follows.
We then consider the stabilization of the application after a reconfiguration, and conclude by establishing that state replication is unaffected as to its correctness when a delicate reconfiguration that was initiated by the coordinator takes place.


\begin{lemma}
\label{thVS:noStaleRecon}
Starting in an arbitrary state in an execution , stale information can only cause a single reconfiguration throughout , unless the prediction mechanism  allows it. 
\end{lemma}

\begin{proof}
We note that stale information relating to reconfiguration consist of  and the copies of  exchanged with every other processor, and , as well as  that may result from stale information as per lines~\ref{VSln:seemCrd} and~\ref{VSln:valCrd}. 
We pay attention to when the conditions are satisfied for the  interface (line~\ref{VSln:go4reconf}). 
This is called by a processor that believes itself to be the coordinator (), in order to initiate a delicate reconfiguration in the modified Algorithm~\ref{alg:coordUpper}.
The three conditions are:
\emph{(i)}  returns ,
\emph{(ii)} All processors of the view have ,
\emph{(iii)} The caller believes itself to be the coordinator, i.e., .
We will refer to a coordinator as one who has established its view in the primary component of the , and other  members follow this processor in performing state replication.
We study the following three complementary cases.\\
{\bf Case 1 -- A non-coordinator  that does not believe itself to be the coordinator.} (I.e., ) In this case,  cannot initiate a reconfiguration since condition (iii) will always fail.\\
{\bf Case 2 -- A non-coordinator  that believes it is the coordinator.} (I.e.,  locally for , but  for a set of other processors greater than the majority of the .) In~\cite{SSVS} processors such as  are proved to eventually stop believing to be the coordinator due to propagation of information assumption.
Nevertheless, before information may be propagated, such a processor's stale information, can cause a reconfiguration if the conditions are satisfied. 
Note that after reconfiguration takes place, this processor needs to again establish its (alleged) coordinatorship before it reconfigures again and in the process it needs to reset its  variables (line~\ref{VSln:updSuspNoCrd}.\\
{\bf Case 3 -- A coordinator  with corrupt initial state}, cannot cause a reconfiguration in case . 
It may cause a reconfiguration if also satisfies condition \emph{(ii)} due to corruption and .
This cannot be distinguished from the non-transient case.
As already noted, after reconfiguration takes place, this coordinator needs to again establish its coordinatorship and in the process it needs to reset its  variables (line~\ref{VSln:updSuspNoCrd}).
\end{proof}

\begin{lemma}
\label{thVS:reduction}
Consider an execution  of Algorithm~\ref{alg:rvs} in which the following hold throughout: (i) the supportive majority assumption, (ii) no reconfiguration takes place (and therefore a valid configuration  is in place) and (iii) .
Then this execution is a reduction to the execution of the self-stabilizing virtually synchronous SMR algorithm 
of~\cite{SSVS}.
\end{lemma}

\begin{proof}
The mapping of the fixed set of processors of~\cite{SSVS} (that was named  where ) to the set of , creates the fixed set (throughout ) that provides the supportive majority (of ) for at least one processor of the configuration to eventually become the coordinator. 
While the views can also include non-member processors (that are participants), safety is provided by the majority of  members.
We note that the algorithm in its structure has not changed less the fact of replacing the old fixed set with , and the addition of the suspend mechanism which is not activated at any point, since  throughout .
We thus deduce that the lemma is a reduction to the non-reconfigurable VS SMR and we deduce the following corollary.
\end{proof}

\begin{corollary}
\label{thVS:redCorollary}
Consider an execution  of Algorithm~\ref{alg:rvs} in which the following hold throughout: (i) the supportive majority assumption, (ii) no reconfiguration takes place (and therefore a valid configuration  is in place) and (iii) . 
Then, by Lemma~\ref{thVS:reduction} and the correctness of~\cite{SSVS},  starting from an arbitrary state, Algorithm~\ref{alg:rvs} simulates state machine replication preserving the virtual synchrony property.
\end{corollary}

\begin{lemma}
\label{thVS:eventReconf} 
\sloppy Consider an infinite execution  of Algorithm~\ref{alg:rvs} with an established coordinator . 
If  from some system state  onwards, then we reach another system state  in which a reconfiguration eventually take place (and after which ). 
\end{lemma}

\begin{proof}
From  onwards, the established coordinator  receives  whenever it calls .
This implies that because of line~\ref{VSln:evalSuspend}  always.
This value is sent in every iteration of the Algorithm by  (lines~\ref{VSln:sendSet}--\ref{VSln:send}) to every processor in the view, and adopted by every processor in the view through lines~\ref{VSln:receive} and~\ref{VSln:replicate}.
Every view member  adopting 's state in  (along with ) propagates  back to .
Due to assumption that a message sent infinitely often is received infinitely often, eventually the coordinator learns that every processor in its view has adopted .

If during this process the coordinator needs to change the view (due to failure detector changes), then this should take place and the above procedure starts again after the view installation (because installation by line~\ref{VSln:proC} forces .
The same takes place if the coordinator is lost, in which case by line~\ref{VSln:noCrdSusp} and the previous remark about installation falsify  flags, and the procedure for reconfiguring should be taken up by the next coordinator.

If every processor in the view has  and  has been informed of this, then line~\ref{VSln:setReconfReady} sets  to  for the coordinator, and line~\ref{VSln:updSuspMult} retains this value since  by assumption.
Hence, whenever the coordinator uses the reconfiguration manager (Algorithm~\ref{alg:coordUpper}) to run line~\ref{coordUpper:delicate}, it will find that all conditions of  are satisfied, thus the coordinator can move on to initiate the reconfiguration using the  interface of the reconfiguration scheme, and hence the result.~\end{proof}

\begin{lemma} 
\label{thVS:stabAfterReconf}
Consider an infinite execution  of Algorithm~\ref{alg:rvs}, starting from a system state  as in Lemma~\ref{thVS:eventReconf}. 
We eventually reach a new state  in which a new configuration is installed and a new valid coordinator is established in the primary component of .
\end{lemma}

\begin{proof}
Starting from system state , a coordinator  has already initiated a reconfiguration.
During reconfiguration,  cannot proceed to increment the round number since line~\ref{VSln:setReconfReady} allows no round increments if reconfiguration is taking place.
Note that since it is the coordinator that triggers the reconfiguration, this processor is immediately informed about a reconfiguration through .
By the correctness of the reconfiguration and stability assurance layer, we are guaranteed that the reconfiguration will complete and so we move from a configuration  to a new one .

When the reconfiguration completes, every processor in the new configuration  should try to establish that there is a coordinator installed.
Even if  survives to , it will need to change the view because of the change in configuration, although it will still consider itself as the coordinator.
By the second set of conditions that allow view proposal, if    
  , namely if there is a majority of active maembers that follow the previously proposed view of , then  is eligible to create a new view.
Otherwise, any processor  may trigger, given that the following conditions are satisfied. 
(i)  ( can trust a majority of the configuration).
(ii) The set of processors in  that  trusts and  knows to have their trust must state that they have no coordinator.
Note that by our majority supportive assumption and the eventual reception of messages, some processor will reach a state in which it will be able to propose.

The correctness arguments of~\cite{SSVS} complete the proof (by Corollary~\ref{thVS:redCorollary}), and so some processor manages to become the coordinator.
\end{proof}

\begin{lemma}
Consider an infinite execution  of Algorithm~\ref{alg:rvs} that contains a system state  as defined in Lemma~\ref{thVS:eventReconf} and a following state  as guaranteed by Lemma~\ref{thVS:stabAfterReconf}. 
The replica state is preserved from  to .
\end{lemma}

\begin{proof}
We examine how the state at the time of reconfiguration triggering, during and after reconfiguration remains unchanged until a coordinator is in place and initiates multicasting.\\
\textbf{Step 1 --} We establish that the state of the replicas \textbf{before} reconfiguration, is preserved.
By Lemma~\ref{thVS:eventReconf}, processor are led to turn their flag  to , when the coordinator  suggests that a reconfiguration must take place.
In the next multicast round when every non-coordinator processor receives 's  it adopts the last state (line~\ref{VSln:replicate}), applies changes to the state~\ref{VSln:applyF} and fetches multicast messages \emph{only if the suspend flag is }.
Similarly, the coordinator applies the changes to the state~\ref{VSln:applyF} after all the view members have adopted its state, and renews its suspend flag (which should always return , otherwise the suspension process stops). 
If all the participants have suspended (otherwise condition      , ,   , ,   of line~\ref{VSln:incrCntr} would not hold), then line~\ref{VSln:setReconfReady} must return  so  and the coordinator does not fetch new messages (line~\ref{VSln:fetchCrd}) and stops incrementing round numbers. \\
\textbf{Step 2 -- } \textbf{During} reconfiguration, no new multicasts and message  may take place, since non-coordinators of  cannot access line~\ref{VSln:optCond} due to the conditions of \ref{VSln:repF}.
They also cannot propose a new view during reconfiguration, by the last condition of line~\ref{VSln:incrCntr}.
So their  flags are preserved to  throughout the reconfiguration (also by line~\ref{VSln:suspOnRecon}).
The coordinator's flag is also maintained to  if reconfiguration is taking place. \\
\textbf{Step 3 --} \textbf{After} the new configuration  is in place, new processors are assumed to access the computation with default values in their state, and cannot therefore introduce new messages or replica state.
Processors coming from , carry the last state and for liveness we assume a single of these processors is alive and included in the proposed view set of the next coordinator. That a new proposal takes place, it is suggested by Lemma~\ref{thVS:stabAfterReconf}.
So the new coordinator (possibly the same as the one before reconfiguration) will gather all available states and messages and create a synchronized state (which is only for stabilization purposes here, since no new messages were allowe to be fetched and there should be only one version of last state).
Note that the  flags are set to  for every processor when reconfiguration finishes and when a valid view proposal is found (line~\ref{VSln:updSuspNoCrd}).
\end{proof}\\



\noindent The above lemmas lead to the following theorem.

\begin{theorem}
\label{thVS:finalApp}
Starting in an arbitrary state in an execution  of Algorithm~\ref{alg:rvs}, the algorithm simulates state machine replication preserving the virtual synchrony property, even in the case of reconfiguration when this is delicate, i.e., when initiated by .
\end{theorem}

\paragraph{Self-stabilizing reconfigurable emulation of shared memory.} Birman et al.~\cite{birmanMR2010} show how a virtual synchrony solution can lead to a reconfigurable emulation of shared memory. 
Following this approach, and using our self-stabilizing reconfigurable SMR solution discussed in this section, and our increment counter scheme (Section~\ref{sec:counter}), we can obtain a self-stabilizing reconfigurable emulation of shared memory.
Given a conflict-free configuration, a typical two-phase read and write protocol can be used for the shared memory emulation.
In the event of a delicate reconfiguration, the coordinator (of the virtual synchrony algorithm) suspends reads and writes on the register and once a new configuration is established, the emulation continues.
Virtual synchrony ensures that the state of the system, in this case the state of the object, is preserved (c.f., Theorem~\ref{thVS:finalApp}).
In the event of a brute force reconfiguration (e.g. due to transient faults or violation of the churn rate), the system will automatically recover and eventually reach a legal execution (in this case the state of the system may be lost).

We note that our proposed self-stablizing reconfigurable SMR and shared memory emulation solutions are suspending, in the sense that 
they do not provide service during a reconfiguration. With some extra care and under certain conditions we believe that they
can be modified to provide continuous service, but in general, it remains an interesting open question whether a \emph{self-stabilizing} 
service, such as reconfigurable SMR or distributed shared memory that does not suspend, is possible. In~\cite{birmanMR2010}, Birman et al. discuss the tradeoffs of suspending and non suspending reconfiguration (such as the ones provided in \cite{RAMBO} and \cite{DynaStore}). It is argued, that suspending services provide some simpler solutions, and may be enhanced for more efficient reconfiguration decisions so that the time for reconfiguration and state transfer before reconfiguration can be reduced.





\section{Conclusion}We presented the first self-stabilizing reconfiguration scheme that recovers automatically from transient faults, such as temporary violation of the predefined churn rate or the unexpected activities of processors and communication channels, using a bounded amount of local storage and message size. We showed how this scheme can be used for the implementation of several dynamic distributed services, such as a self-stabilizing reconfigurable virtual synchrony, which in turn can be used for developing self-stabilizing reconfigurable SMR and shared memory emulation solutions. We use a number of bootstrapping techniques for allowing the system to always recover from arbitrary transient faults, for example, when the current configuration includes no active processors. We believe that the presented techniques provide a generic blueprint for different solutions that
are needed in the area of self-stabilizing high-level communication and synchronization primitives, which need to deal with processor joins and leaves as well as transient faults.
\begin{thebibliography}{10}

\bibitem{DBLP:journals/eatcs/AguileraKMMS10}
Marcos~K. Aguilera, Idit Keidar, Dahlia Malkhi, Jean{-}Philippe Martin, and
  Alexander Shraer.
\newblock Reconfiguring replicated atomic storage: {A} tutorial.
\newblock {\em Bulletin of the {EATCS}}, 102:84--108, 2010.

\bibitem{DynaStore}
Marcos~Kawazoe Aguilera, Idit Keidar, Dahlia Malkhi, and Alexander Shraer.
\newblock Dynamic atomic storage without consensus.
\newblock {\em J. {ACM}}, 58(2):7, 2011.

\bibitem{DBLP:conf/wdag/AttiyaCEKW15}
Hagit Attiya, Hyun~Chul Chung, Faith Ellen, Saptaparni Kumar, and Jennifer~L.
  Welch.
\newblock Simulating a shared register in an asynchronous system that never
  stops changing - (extended abstract).
\newblock In {\em Distributed Computing - 29th International Symposium, {DISC}
  2015, Tokyo, Japan, October 7-9, 2015, Proceedings}, pages 75--91, 2015.

\bibitem{Baldoni09}
R.~Baldoni, S.~Bonomi, A.~M. Kermarrec, and M.~Raynal.
\newblock Implementing a register in a dynamic distributed system.
\newblock In {\em Distributed Computing Systems, 2009. ICDCS '09. 29th IEEE
  International Conference on}, pages 639--647, June 2009.

\bibitem{birmanMR2010}
Ken Birman, Dahlia Malkhi, and Robbert van Renesse.
\newblock Virtually synchronous methodology for dynamic service replication.
\newblock Technical Report MSR-TR-2010-151, Microsoft Research, 2010.

\bibitem{Blanchard2013SSPaxos}
Peva Blanchard, Shlomi Dolev, Joffroy Beauquier, and Sylvie Dela{\"{e}}t.
\newblock Practically self-stabilizing paxos replicated state-machine.
\newblock In {\em In Revised Selected Papers of the Second International
  Conference on Networked Systems, {NETYS} 2014}, volume 8593 of {\em Lecture
  Notes in Computer Science}, pages 99--121. Springer, 2014.

\bibitem{DBLP:journals/corr/BortnikovCPRSS15}
Vita Bortnikov, Gregory Chockler, Dmitri Perelman, Alexey Roytman, Shlomit
  Shachor, and Ilya Shnayderman.
\newblock Reconfigurable state machine replication from non-reconfigurable
  building blocks.
\newblock {\em CoRR}, abs/1512.08943, 2015.

\bibitem{DBLP:journals/jpdc/ChocklerGGMS09}
Gregory~V. Chockler, Seth Gilbert, Vincent Gramoli, Peter~M. Musial, and
  Alexander~A. Shvartsman.
\newblock Reconfigurable distributed storage for dynamic networks.
\newblock {\em J. Parallel Distrib. Comput.}, 69(1):100--116, 2009.

\bibitem{D2K}
Shlomi Dolev.
\newblock {\em Self-stabilization}.
\newblock The MIT press, 2000.

\bibitem{DBLP:journals/ipl/DolevDPT11}
Shlomi Dolev, Swan Dubois, Maria Potop{-}Butucaru, and S{\'{e}}bastien Tixeuil.
\newblock Stabilizing data-link over non-fifo channels with optimal
  fault-resilience.
\newblock {\em Inf. Process. Lett.}, 111(18):912--920, 2011.

\bibitem{SSVS}
Shlomi Dolev, Chryssis Georgiou, Ioannis Marcoullis, and Elad~Michael Schiller.
\newblock Self-stabilizing virtual synchrony.
\newblock In {\em Proceedings of the 17th International Symposium on
  Stabilization, Safety, and Security of Distributed Systems, {SSS} 2015},
  pages 248--264, 2015.

\bibitem{DBLP:conf/sss/DolevHSS12}
Shlomi Dolev, Ariel Hanemann, Elad~Michael Schiller, and Shantanu Sharma.
\newblock Self-stabilizing end-to-end communication in (bounded capacity,
  omitting, duplicating and non-fifo) dynamic networks - (extended abstract).
\newblock In {\em Proceedings of the 14th International Symposium
  Stabilization, Safety, and Security of Distributed Systems, {SSS} 2012},
  pages 133--147, 2012.

\bibitem{DBLP:journals/cjtcs/DolevH97}
Shlomi Dolev and Ted Herman.
\newblock Superstabilizing protocols for dynamic distributed systems.
\newblock {\em Chicago J. Theor. Comput. Sci.}, 1997, 1997.

\bibitem{DBLP:journals/tmc/DolevSW06}
Shlomi Dolev, Elad Schiller, and Jennifer~L. Welch.
\newblock Random walk for self-stabilizing group communication in ad hoc
  networks.
\newblock {\em {IEEE} Trans. Mob. Comput.}, 5(7):893--905, 2006.

\bibitem{DBLP:journals/tcs/DolevT09}
Shlomi Dolev and Nir Tzachar.
\newblock Empire of colonies: Self-stabilizing and self-organizing distributed
  algorithm.
\newblock {\em Theor. Comput. Sci.}, 410(6-7):514--532, 2009.

\bibitem{DBLP:conf/wdag/GafniM15}
Eli Gafni and Dahlia Malkhi.
\newblock Elastic configuration maintenance via a parsimonious speculating
  snapshot solution.
\newblock In {\em Distributed Computing - 29th International Symposium, {DISC}
  2015, Tokyo, Japan, October 7-9, 2015, Proceedings}, pages 140--153, 2015.

\bibitem{RAMBO}
Seth Gilbert, Nancy~A. Lynch, and Alexander~A. Shvartsman.
\newblock Rambo: a robust, reconfigurable atomic memory service for dynamic
  networks.
\newblock {\em Distributed Computing}, 23(4):225--272, 2010.

\bibitem{DBLP:conf/wdag/JehlVM15}
Leander Jehl, Roman Vitenberg, and Hein Meling.
\newblock Smartmerge: {A} new approach to reconfiguration for atomic storage.
\newblock In {\em Distributed Computing - 29th International Symposium, {DISC}
  2015, Tokyo, Japan, October 7-9, 2015, Proceedings}, pages 154--169, 2015.

\bibitem{DBLP:journals/sigact/LamportMZ10}
Leslie Lamport, Dahlia Malkhi, and Lidong Zhou.
\newblock Reconfiguring a state machine.
\newblock {\em {SIGACT} News}, 41(1):63--73, 2010.

\bibitem{DBLP:journals/cacm/MusialNS14}
Peter~M. Musial, Nicolas~C. Nicolaou, and Alexander~A. Shvartsman.
\newblock Implementing distributed shared memory for dynamic networks.
\newblock {\em Commun. {ACM}}, 57(6):88--98, 2014.

\bibitem{DBLP:journals/dc/PelegW97}
David Peleg and Avishai Wool.
\newblock Crumbling walls: {A} class of practical and efficient quorum systems.
\newblock {\em Distributed Computing}, 10(2):87--97, 1997.

\bibitem{spiegelmandynamic}
Alexander Spiegelman, Idit Keidar, and Dahlia Malkhi.
\newblock Dynamic reconfiguration: A tutorial.
\newblock {\em OPODIS 2015}, 2015.

\bibitem{DBLP:series/synthesis/2012Vukolic}
Marko Vukolic.
\newblock {\em Quorum Systems: With Applications to Storage and Consensus}.
\newblock Synthesis Lectures on Distributed Computing Theory. Morgan {\&}
  Claypool Publishers, 2012.

\end{thebibliography}

\clearpage








\end{document}
