

\documentclass[final]{cvpr}

\usepackage{times}
\usepackage{epsfig}
\usepackage{graphicx}
\usepackage{amsmath}
\usepackage{amssymb}

\usepackage{epsfig}
\usepackage{graphicx}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{multirow}
\usepackage{caption}
\usepackage{subcaption}
\usepackage[skip=0.5\baselineskip]{caption}
\usepackage{booktabs}
\usepackage[dvipsnames]{xcolor}
\usepackage[colorlinks=true,linkcolor=red, citecolor=RoyalBlue]{hyperref}






\def\cvprPaperID{8378} \def\confYear{CVPR 2021}



\begin{document}

\title{Localization Uncertainty Estimation for Anchor-Free Object Detection}




\author{Youngwan Lee\ \ \ Joong-Won Hwang\ \ \ Hyung-Il Kim\ \ \ Kimin Yun\ \ \ Yongjin Kwon\\
  Electronics and Telecommunications Research Institute (ETRI)\\
  South Korea \\
  \tt\small\texttt{\textbraceleft yw.lee, jwhwang, hikim, kimin.yun, scocso\textbraceright@etri.re.kr} \\
}

\maketitle









\begin{abstract}
Since many safety-critical systems, such as surgical robots and autonomous driving cars, are in unstable environments with sensor noise and incomplete data, it is desirable for object detectors to take into account the confidence of localization prediction.
There are three limitations of the prior uncertainty estimation methods for anchor-based object detection. 
1) They model the uncertainty based on object properties having different characteristics, such as location (center point) and scale (width, height).
2) they model a box offset and ground-truth as Gaussian distribution and Dirac delta distribution, which leads to the model misspecification problem.
Because the Dirac delta distribution is not exactly represented as Gaussian, i.e., for any  and .
3) Since anchor-based methods are sensitive to hyper-parameters of anchor, the localization uncertainty modeling is also sensitive to these parameters.
Therefore, we propose a new localization uncertainty estimation method called Gaussian-FCOS for anchor-free object detection.
Our method captures the uncertainty based on four directions of box offsets~(left, right, top, bottom) that have similar properties, which enables to capture which direction is uncertain and provide a quantitative value in range~[0, 1].
To this end, we design a new uncertainty loss, negative power log-likelihood loss, to measure uncertainty by weighting IoU to the likelihood loss, which alleviates the model misspecification problem.
Experiments on COCO datasets demonstrate that our Gaussian-FCOS reduces false positives and finds more missing-objects by mitigating over-confidence scores with the estimated uncertainty.
We hope Gaussian-FCOS serves as a crucial component for the reliability-required task.







\begin{figure}[t]
\centering
  \scalebox{0.7}{
  \includegraphics{gaussian.pdf} 
  }
  \caption{\textbf{Examples of 4-directions uncertainty for anchor-free object detection.} C\_L, C\_R, C\_T, and C\_B denote the estimated certainty in [0, 1] value with respect to left, right, top, and bottom. For example, Gaussian-FCOS estimates lower top-direction certainty due to its ambiguous head boundary of the cat wearing a hat.
This demonstrates that our method makes it possible to quantify which direction is uncertain due to unclear or obvious objects.}


\label{fig:gaussian}
\end{figure}




\begin{figure*}[t]
\centering
\includegraphics[width=\textwidth]{vis.pdf} 
\caption{\textbf{ Example of over-confidence problem resolved by Gaussian-FCOS~(proposed).}
The colors of bounding boxes are chosen by its detection score (a) and certainty score (b), (c).
Specifically, the higher score (up to 1.0) is, the box color is to be red otherwise blue, where `conf\_th' denotes confidence threshold for the visualization.
`C' in (b), (c) denotes the estimated certainty score.
Gaussian-FCOS captures localization uncertainty for each bounding box which means how certain box location is.
For example, each detected person has a higher certainty score over 90\% whereas the false positive~(cyan box) due to the overlap between persons gets a lower certainty score (45\%).
Unlike FCOS~(a), Gaussian-FCOS~(c) filters out the false positive by decaying the detection score with the estimated certainty score.
compared to FCOS, Gaussian-FCOS localizes the person with a tennis racket more accurately~(tightly).
}

\label{fig:vis}
\end{figure*}




\end{abstract}

\section{Introduction}
Object detection based on CNN is widely used in many automated systems such as autonomous vehicles and surgical robots~\cite{sarikaya2017detection}.
In such a safety-related system, it is very important to know how reliable the estimated output is as well as good performance.
Object detection is a task that combines object localization and classification, however, most of the state-of-the-art methods~\cite{cai2018cascade,Tian_2019_ICCV,zhang2019bridging} provide the reliability of their algorithm as a single value~(\eg, confidence) for each bounding box.
That is, they only use the classification score as the detection quality without the localization uncertainty.
As a consequence, these methods produce mislocalized detection boxes with over-confidence~\cite{he2019bounding}.
For example, as shown in Fig.~\ref{fig:vis}(a), the mislocalized detection with the confidence score of 50\% (green box) is not removed because its classification confidence score is higher than the threshold.
Therefore, in addition to the classification confidence score, the confidence of the bounding box's localization is also necessary for the detection certainty. 

Recently, efforts~\cite{kraus2019uncertainty,he2019bounding,le2018uncertainty,harakeh2019bayesod} to estimate uncertainty for object detection have been attempted.
All of these efforts model the uncertainty of location (center point) and scale (width, height) as Gaussian distribution in the anchor-based methods by adding four channels in the regression output.
However, since center point, width, and height have semantically different characteristics~\cite{kraus2019uncertainty}, this approach considering each value equally is inadequate for modeling localization uncertainty.
For example, the estimated distributions of center point and scale shows different shapes in ~\cite{kraus2019uncertainty}.
Besides, since anchor-based methods are sensitive to hyper-parameters of anchor, the localization uncertainty modeling on the anchor-based methods is also sensitive to these parameters.



Recently, anchor-free methods~\cite{law2018cornernet,Duan_2019_ICCV,zhou2019bottom,zhou2019objects,Tian_2019_ICCV} that do not need the heuristic anchor-box tuning~(e.g., scale, aspect ratio) surpassed conventional anchor-box based methods such as Faster R-CNN~\cite{ren2015faster}, RetinaNet~\cite{lin2018focal}, and their variants~\cite{cai2018cascade,zhang2018single}.
As a representative anchor-free method, FCOS~\cite{Tian_2019_ICCV} adopts the concept of centerness to filter out false positive boxes.
That is, the centerness can be interpreted as the implicit localization uncertainty of a proposal box.
However, FCOS~\cite{Tian_2019_ICCV} heuristically measures the localization uncertainty by how well the predicted box fits the center, which does not reflect full information for localization uncertainty of box~(e.g., scale).


In terms of the loss function for uncertainty modeling, the conventional methods~\cite{kraus2019uncertainty,le2018uncertainty,harakeh2019bayesod} use the negative log-likelihood loss to regress output as Gaussian distribution.
He~\etal~\cite{he2019bounding} introduce KL divergence loss for Gaussian distribution of box prediction and Dirac delta function for a ground-truth box.
In the perspective of cross-entropy, however, these methods face the model misspecification problem~\cite{holmes2017assigning} in that the Dirac delta function is not exactly represented as Gaussian distribution, \textit{i.e.}, for any  and , .



To deal with these limitations, in this paper, we propose a method, called \textit{Gaussian-FCOS}, that estimates \textit{explicitly} localization uncertainty for anchor-free method, FCOS~\cite{Tian_2019_ICCV}.
Unlike centerness in FCOS, we model the uncertainty for each of the four box offsets~(left, right, top, bottom) from the center of the box to fully describe the localization uncertainty.
Moreover, unlike conventional anchor-based methods~\cite{kraus2019uncertainty,he2019bounding,le2018uncertainty,harakeh2019bayesod} for localization uncertainty, our method estimates the uncertainty of the four box offsets having a similar semantic characteristic.
It makes possible to inform which direction of a box boundary is uncertain as a quantitative value~in [0,1] independently from the overall box uncertainty as shown in Fig.~\ref{fig:gaussian}.~(more examples are illustrated in Fig.~\ref{fig:example}.)
To do this, we model the box offset and its uncertainty of FCOS through Gaussian distribution with the newly desgined uncertainty loss by adding the uncertainty branch.






To resolve the model misspecification~\cite{holmes2017assigning} between Dirac delta and Gaussian distribution, we design a novel uncertainty loss, \textit{negative power log-likelihood loss}, inspired by Power likelihood~\cite{holmes2017assigning}~(NPLL), to enable the uncertainty branch to learn to estimate localization uncertainty by weighing IoU to the log-likelihood loss.
In particular, this new loss creates a synergy with the existing box regression loss, which tells the difference between the ground truth and the predicted box offset, enabling more accurate box prediction.
For example, as illustrated in Fig.~\ref{fig:vis}(a) and (c), we can see that Gaussian-FCOS localizes objects more accurately~(tightly) than FCOS by comparing the detected box of the person with a tennis racket. 
Furthermore, we calibrate the detection score through the localization uncertainty. 
In detail, we compute certainty from the estimated uncertainty and then multiply it to the classification score to get the final detection score.
Fig.~\ref{fig:vis}(b)-(c) shows the effectiveness of uncertainty calibration.
Unlike the detection result from FCOS in Fig.~\ref{fig:vis}(a), Gaussian-FCOS calibrates~(or penalizes) the detection score with the certainty, which can filter out the mislocalized box~(cyan box) between two persons.




The main contributions are summarized as below:

\begin{itemize}
\item We propose a simple and effective four-directions localization uncertainty estimation for anchor-free object detection that can serve as a detection quality measure and provide which direction is uncertain as a quantitative value in [0, 1].
\item We newly design the uncertainty loss function, inspired by \textit{power likelihood}, that has IoUs as weights of negative log-likelihood loss that resolves the model misspecification problem.
\item We analyze the influence of uncertainty on object localization and confirm that it improves mislocalization and reduces missing objects on challenging COCO dataset.
\end{itemize}




\begin{figure*}[t]
\centering
\scalebox{0.75}{
  \includegraphics[width=\textwidth]{architecture.pdf} 
}
  \caption{\textbf{ Architecture of Gaussian-FCOS.} 
Different from FCOS~\cite{Tian_2019_ICCV}, Gaussian-FCOS estimates localization uncertainty from \textit{uncertainty} branch that outputs four uncertainties of box offsets (left, right, top, and bottom.)}
\label{fig:architecture}
\vspace{-0.3cm}
\end{figure*}




\section{Related Works}
\subsection{Anchor-Free Object Detection}
Recently, anchor-free object detectors~\cite{law2018cornernet,zhou2019bottom,Duan_2019_ICCV,zhou2019objects,Tian_2019_ICCV} have attracted attention beyond anchor-based methods~\cite{ren2015faster,lin2018focal,cai2018cascade,zhang2018single} that need to tune sensitive hyper-parameters related to anchor box~(e.g., scale, aspect ratio, etc).
CornerNet~\cite{law2018cornernet} predicts an object location as a pair of keypoints~(top-left and bottom-right).
CenterNet~\cite{Duan_2019_ICCV} extends CornerNet as a triplet instead of a pair of key points to boost performance.
ExtremeNet~\cite{zhou2019bottom} locates four extreme points (top, bottom, left, right) and one center point to generate the object box.
Zhu~\etal~\cite{zhou2019objects} utilizes keypoint estimation to predict center point objects and regresses to other attributes including size, orientation, pose, and 3D location.
FCOS~\cite{Tian_2019_ICCV} views all points inside the ground-truth box as positive samples and regresses four distances~(left, right, top, bottom) from the object boundary.
We propose to endow FCOS with localization uncertainty due to its simplicity and performance.

\subsection{Uncertainty Estimation}
Uncertainty in deep neural networks can be estimated in two types~\cite{gal2016uncertainty,kendall2017uncertainties,le2018uncertainty}: epistemic (sampling-based) and aleatoric (sampling-free) uncertainty.
Epistemic uncertainty measures the model uncertainty in the models' parameters through Bayesian neural networks~\cite{shridhar2019comprehensive}, Monte Carlo dropout~\cite{gal2016dropout}, and Bootstrap Ensemble~\cite{lakshminarayanan2017simple}.
As they need to be re-evaluated several times and store several sets of weights for each network, it is hard to apply them for real-time applications. 
Aleatoric uncertainty is data and problem inherent such as sensor noise and ambiguities in data.
It can be estimated by explicitly modeling it as model output.

Recent works~\cite{he2019bounding,le2018uncertainty,harakeh2019bayesod,lakshminarayanan2017simple} have adopted uncertainty estimation for object detection.
Lakshminarayanan~\etal~\cite{lakshminarayanan2017simple} and Harakeh~\etal~\cite{harakeh2019bayesod} use Monte Carlo dropout in Epistemic based methods.
As described above, since epistemic uncertainty needs to inference several times, it is not suitable for real-time object detection.
Le~\etal~\cite{le2018uncertainty} and Choi~\etal~\cite{choi2019gaussian} are aleatoric based methods and jointly estimate the uncertainties of four parameters of bounding box from SSD~\cite{liu2016ssd} and YOLOv3~\cite{redmon2018yolov3}.
He~\cite{he2019bounding} estimates the uncertainty of bounding box by minimizing the KL-divergence loss for Gaussian distribution of predicted box and Dirac delta distribution of ground-truth box on the Faster R-CNN~\cite{ren2015faster}~(anchor-based method).
From the cross-entropy perspective, however, Dirac delta distribution cannot be represented Gaussian distribution, which results in a misspecification problem~\cite{holmes2017assigning}.
To overcome this problem, we adopt the power likelihood concept~\cite{holmes2017assigning} to the Gaussian log-likelihood loss.
The latest concurrent work is Generalized Focal loss~(GFocal)~\cite{li2020generalized} that represents jointly localization quality and classification and model bounding box as arbitrary distribution.
The distinct difference from GFocal~\cite{li2020generalized} is that our method estimates 4-directions uncertainties as quantitative values in the range [0, 1] thus these estimated values can be used as an informative cue for decision-making.


\section{Proposed Method}
For the uncertainty estimation for object detector, we choose anchor-free detector, FCOS~\cite{Tian_2019_ICCV} based on two reasons:
1) \textbf{Simplicity}. FCOS directly regresses the target bounding boxes in a pixel-wise prediction manner without heuristic anchor tuning~(aspect ratio, scales, etc).
2) \textbf{Semantic symmetry of regression}. anchor-based methods regress center point~(,), width, and height based on each anchor box, while FCOS directly regresses four boundaries~(left, right, top, bottom) of a bounding box at each location.
Although the center, width, and height from anchor-based methods have different characteristics, the distances between four boundaries and each location are semantically symmetric. 
In terms of modeling, it is easier to model the values sharing semantic meanings that have similar properties. 
Furthermore, it enables to notify which direction of a box boundary is uncertain separately from the overall box uncertainty.


In this section, we first introduce the localization step of FCOS~\cite{Tian_2019_ICCV}.
Then, we present \textit{uncertainty loss} for modeling the uncertainty of the object coordinates in FCOS as the Gaussian parameters~(i.e., the mean and variance).
Next, we introduce the new uncertainty branch that estimates the localization uncertainty in addition to FCOS branches. 
Finally, we show how the estimated localization uncertainty is applied to provide localization confidence.



\subsection{FCOS detector}



In FCOS~\cite{Tian_2019_ICCV}, if the location belongs to the ground-truth box area, it is regarded as a positive sample and as a negative sample otherwise.
On each location~(, ), the box offsets are regressed as 4D vector  that is the distances from the location to four sides of the bounding box~(i.e., left, right, top, and bottom).
The regression targets  are computed as,

where (, ) and (, ) denote the coordinates of the left-top and right-bottom corners of the ground-truth box, respectively. 
Then, for all locations of positive samples, the IoU loss~\cite{yu2016unitbox} is measured between the predicted  and the ground truth  for the regression loss.

FCOS also adopts centerness to suppress low quality detected boxes in the inference stage.
The main concept of centerness is to estimate not only the position of the object but also how well it fits with the center.
That is, it provides confidence that the box predicted in the test step fits the center of the object well.
Also, this centerness value is used as uncertainty to penalize the detection score.





\subsection{Gaussian-FCOS}
FCOS~\cite{Tian_2019_ICCV} predicts the class score, box offsets =(), and centerness. 
In FCOS, centerness can be regarded as implicit uncertainty because centerness is used to filter predicted boxes, but centerness alone is insufficient to measure localization uncertainty.
In other words, centerness is a single value that simply shows the localization uncertainty as to how well the center of the box fits, but for accurate modeling of localization uncertainty, it is necessary to consider the four positions that make up the box.
Therefore, we propose Gaussian-FCOS that estimates localization uncertainty of the box, based on the regressed box offsets~.
To predict the uncertainties of four box offsets, we model the box offsets through Gaussian distribution and train the network to estimate its uncertainty (standard deviation).
Assuming each instance of box offsets is independent, we use multivariate Gaussian distribution of output  with diagonal covariance matrix  to model each box offset :

where  is the learnable network parameters, and  is the dimension of  (i.e., ).
 and
 denote the predicted box offset and its \textit{uncertainty}, respectively.


\medskip

\noindent
\textbf{Power likelihood.}
Prior works~\cite{kraus2019uncertainty,le2018uncertainty,he2019bounding,choi2019gaussian} also model box offset and ground-truth box as Gaussian distribution and Dirac delta distribution.
\cite{kraus2019uncertainty,le2018uncertainty,choi2019gaussian} adopt negative log-likelihood loss~(NLL) and \cite{he2019bounding} use KL-divergence loss (KL-Loss).
In cross-entropy perspective, minimizing NLL and KL-loss is equivalent as below:

where  and  are Dirac delta function and Gaussian probability density function, respectively.
When the box offset is located in a ground-truth box, the  is  then Eq.~\ref{eq:3} becomes negative log-likelihood loss.
However, there is a significant problem that Dirac delta distribution does not belong to the family of Gaussian distributions, called the model misspecification problem~\cite{holmes2017assigning}. 
In a number of statistical literature, to estimate parameters of interest in a robust way when the model is misspecified, the Power likelihood~(), which raises the likelihood~() to a power~() that controls how influential the data is, has been proposed~\cite{holmes2017assigning}. 
Thus, to fill the gaps between Dirac delta distribution and Gaussian distribution, inspired by Power likelihood, we introduce a novel uncertainty loss, \textit{negative power log-likelihood loss~(NPLL)}, that exploits Intersection-over-Union (IoU) as the power since the offset that has higher IoU should be more influential.
By multiplying IoU term to the log-likelihood, the new uncertainty loss is defined as :

\noindent
where  denotes the number of positive samples,  ( in this paper) is the balance weight for ,  is the intersection-over-union between the predicted box and the ground-truth box at location  and  is in .
The summation is calculated over all positive locations on the feature maps.
From this uncertainty loss, when the predicted coordinate  from the regression branch is inaccurate, the network is trained to estimate larger uncertainty .
For the rest of the losses, following FCOS~\cite{Tian_2019_ICCV}, we use focal loss~\cite{lin2018focal} for classification~(), binary cross-entropy loss for centerness~(), and IoU loss~\cite{yu2016unitbox} for regression~().
The total loss is defined as:

It is noted that unlike centerness, our network is trained to directly estimate four localization uncertainties~ of each box offsets.
Also, it can be estimated which direction of a box boundary is uncertain separately apart from the overall box uncertainty.

\medskip

\noindent
\textbf{Uncertainty branch.} To implement our idea, we redesign the FCOS~\cite{Tian_2019_ICCV} network structure by adding the uncertainty branch as shown in Fig.~\ref{fig:architecture}.
Our network predicts a probability distribution instead of only box coordinates.
The mean values  of each box offsets are predicted from the regression branch in FCOS.
The new uncertainty branch with sigmoid function outputs four uncertainty values  in .
The regression branch and the uncertainty branch shares same feature (4 \texttt{conv} layers) as their inputs to estimate two kinds of statistic parameters~(i.e. , ).


\medskip

\noindent
\textbf{Uncertainty calibration.} With the uncertainty branch, Gaussian-FCOS can obtain the localization uncertainty  and utilize it to infer the box confidence.
Concretely, box confidence is interpreted as the certainty that is defined as , where the  is obtained by averaging  for all . 
In the post-processing step, Non-Maximum-Supression~(NMS) is applied for removing overlapped box proposals. 
The class confidence score is widely adopted to decide the boxes to be removed, but this does not reflect localization uncertainty.
Thus, for NMS, we calibrate the detection score by multiplying the class score by the our box confidence  that considers the localization uncertainty.
Fig.~\ref{fig:vis}(b) shows that the false positive (cyan box) has lower box confidence~(45\%) than other true positives~(over 90\%), which means Gaussian-FCOS estimates localization uncertainty well.
As shown in Fig.~\ref{fig:vis}(c), Gaussian-FCOS removes the false positive through the calibrated (penalized) the detection score.



\begin{figure}[t]
  \centering
  \scalebox{1.0}{
    \includegraphics[width=\linewidth]{loss_graph.pdf}
  }
  \caption{
    \textbf{Comparison of the regression Loss.} 
    Regression loss of Gaussian-FCOS tends to be lower than that of FCOS. 
In other words, training with the proposed uncertainty loss further reduces the regression loss and helps the trained network estimate better object position.
    }
  \label{fig:loss}
\end{figure}




\section{Experiments}
In this section, we evaluate the effectiveness of Gaussian-FCOS on the challenging COCO~\cite{lin2014microsoft} dataset which has 80 object categories.
We use the COCO \texttt{train2017} set (80k images) for training and \texttt{val2017} set (5k images) for ablation studies.
Final results are evaluated on \texttt{test-dev2017} in the evaluation server for the comparison with state-of-the-arts.
There are two key metrics for object detection evaluation, the one is average precision (AP) and the other is average recall (AR).
AP reflects how boxes are proposed properly without duplication and how proposed box are correctly classified.
AR means how many objects our detector have detected without missing.
Thus, AR is a crucial metric for safety-critical applications such as autonomous cars and surgical robots where missing can cause serious problem.
AP and AR are averaged over IoU thresholds (.5 : .95), and the higher IoU is, the more accurate localization needs. 



\begin{table}[t]
  \centering
  \scalebox{0.95}{
    \begin{tabular}{lllll}
    \toprule
    \multicolumn{1}{l}{Method}         & \multicolumn{1}{l}{AP} & \multicolumn{1}{l}{AP\textsubscript{75}} & \multicolumn{1}{l}{AR}   & \multicolumn{1}{l}{AR\textsubscript{75}}  \\ \hline
    FCOS                             & 41.2                   & 44.4                             & 59.0             & 63.2 \\
    +               & 41.5\tiny{+0.3}        & 45.4\tiny{+1.0}                  & 60.2\tiny{+1.2}      & 66.6\tiny{+3.4} \\
    + w/ IoU power    & 42.0\tiny{+0.8}        & 46.2\tiny{+1.8}              & 60.8\tiny{+1.8}      & 67.0\tiny{+3.8}       \\
    \bottomrule
    \end{tabular}
  }
    \caption{\textbf{Effectiveness of power likelihood.}  denotes negative{\hspace{0.2ex}}log-likelihood{\hspace{0.2ex}}loss{\hspace{0.2ex}}(NLL).{\hspace{0.2ex}}The{\hspace{0.2ex}}proposed{\hspace{0.2ex}}uncertainty loss with IoU power term (NPLL) improves the baseline.
    \label{tab:uncertainty}
  }
\end{table}


\subsection{Implementation details}
We train Gaussian-FCOS by using Stochastic Gradient Descent (SGD) for  iterations (3 schedule~\cite{He_2019_ICCV}) with a mini-batch of 16 images.
An initial learning rate is 0.01, and it is decreased by a factor of 10 at  and  iterations, respectively.
Unless specified, the scale-jitter~\cite{He_2019_ICCV} augmentation is applied where the shorter image side is randomly sampled from [640, 800] pixels.
As a backbone network, we use ResNet-50 with ImageNet pre-trained weights in the ablation study.







\subsection{Ablation study}
\noindent
\textbf{Uncertainty loss with power likelihood.}
We first validate the effectiveness of the proposed uncertainty loss compared to the baseline, Negative log-Likelihood Loss~(NLL), in Table~\ref{tab:uncertainty}.
We can find that adopting IoU power term in the NLL improves performance AP as well as AR, suggesting that power likelihood with IoU alleviates effectively the misspecification problem. 
Fig.~\ref{fig:loss} also shows that the regression loss of Gaussian-FCOS tends to be lower than FCOS.
It means that uncertainty loss helps the regression branch learn to reduce the error with the ground-truth location.
As a result, both AP and AR are improved from FCOS~\cite{Tian_2019_ICCV}.
Besides, uncertainty calibration also boosts the performance, which means the detection score calibrated by localization uncertainty alleviates the over-confidence problem.


\medskip

\noindent
\textbf{Uncertainty calibration.}
Table~\ref{tab:calibration} shows the effect according to the order of the usage of NMS and uncertainty calibration.
The first row `w/o Calibration' is the same as `FCOS + Uncertainty Loss'.
We find that the AR gain of `Calibration before NMS' is bigger than that of `Calibration after NMS'. 
It means that the uncertainty calibration prevents more well-localized objects from being filtered out by NMS.
In addition, the AP of `Calibration before NMS' is more improved that of `Calibration after NMS'.
In other words, the NMS may remove the well-localized box that has low confidence, while the proposed method can preserve this box by score calibration.
This means that the score calibration before NMS makes the incorrectly located box with over-confidence removed in the NMS step.





\begin{table}
  \centering
  \scalebox{0.95}{
    \begin{tabular}{lllll}
    \toprule
    Method                 & AP               & AP\textsubscript{75}  & AR            & AR\textsubscript{75}      \\ \hline
    w/o Calibration        & 41.7             & 45.1          & 59.4          & 63.7              \\
    Calib. after NMS         & 41.5             & 45.2          & 59.4          & 63.7                  \\
    Calib. before NMS        & 42.0\tiny{+0.3}  & 46.2\tiny{+1.1}     & 60.8\tiny{+1.4} & 67.0\tiny{+3.3}     \\
    \bottomrule
    \end{tabular}
  }
  \caption{\textbf{Uncertainty calibration with NMS.} Calibrating the detection score before NMS prevents well-localized boxes from being filtered out while inaccurately located boxes with over-confidence are removed in NMS step.}
  \label{tab:calibration}
\end{table}


\medskip

\noindent
\textbf{Backbone network.}
We validate Gaussian-FCOS with various backbone networks such as ResNet~\cite{he2016deep} and VoVNet~\cite{lee2019centermask}.
Table~\ref{tab:backbone} shows that Gaussian-FCOS achieves the consistent performance gains of both AP and AR on various backbone networks.
It is noted that Gaussian-FCOS obtains a large improvement of AR, which demonstrates our certainty estimation helps to prevent objects from being missed. 
Also, through the difference in operation time is very insignificant, (12 ms), our uncertainty branch and calibration efficiently model the localization uncertainty without computational overhead. 


\begin{table}[t]
\centering
\scalebox{0.87}{
  \begin{tabular}{@{}lcllllc@{}}
  \toprule
  Backbone                                                  & Uncertainty               & AP                 & AP\textsubscript{75}    & AR    & AR\textsubscript{75}                     & Time \\ \hline
  \multirow{2}{*}{ResNet-50}                        &                           & 41.2               & 44.4                & 59.0  & 63.2                    & 0.041         \\
                                                            & \footnotesize      & 42.0         & 46.2              & 60.8  & 67.0         & 0.042         \\ \hline
  \multirow{2}{*}{ResNet-101}                       &                           & 43.1               & 46.7                & 60.6  & 65.4                     & 0.054         \\
                                                            & \footnotesize      & 43.7         & 47.8            & 61.9  & 67.8         & 0.055         \\ \hline
  \multirow{2}{*}{VoVNet-39}                    &                           & 43.5               & 47.2                & 61.4  & 66.2                    & 0.042         \\
                                                            & \footnotesize      & 44.3         & 48.8            & 62.8  & 69.1         & 0.044         \\ \hline
  \multirow{2}{*}{VoVNet-57}                    &                           & 44.4               & 47.6                & 61.6  & 66.2                     & 0.048         \\
                                                            & \footnotesize      & 45.2         & 49.7            & 63.2  & 69.7         & 0.049         \\ 
  \bottomrule
  \end{tabular}
}
\caption{\textbf{Comparison of different backbones on Gaussian-FCOS.} }
\label{tab:backbone}
\vspace{-0.5cm}

\end{table}



\begin{table*}[t]
\centering
\scalebox{0.90}{
  \begin{tabular}{@{}llllllllll@{}}
  \toprule
  Method                              & AP                        & AP\textsubscript{50}  & AP\textsubscript{60} & AP\textsubscript{70}& AP\textsubscript{80} & AP\textsubscript{90} & AP\textsubscript{S}  & AP\textsubscript{M}  & AP\textsubscript{L} \\ \midrule
  Faster R-CNN~\cite{ren2015faster}   & 40.2                      & \textbf{61.0}   & \textbf{56.6}   & 49.1                      & 36.7                      & 13.7                      & 24.2                      & 43.5                      & 52.0                      \\
  RetinaNet~\cite{lin2018focal}       & 38.7                      & 58.0            & 53.6            & 46.4                      & 34.7                      & 15.7                      & 23.3                      & 42.3                      & 50.3                      \\ \midrule
  FCOS~\cite{Tian_2019_ICCV}          & 41.2                      & 60.0            & 55.7            & 49.4                      & 38.1                      & 18.5                      & 25.7                      & 44.8                      & 52.0                      \\
  \textbf{Gaussian-FCOS}              & \textbf{42.0}\tiny{+0.8}  & 58.7\tiny{-0.3} & 55.2\tiny{-0.5} & \textbf{50.3}\tiny{+0.9}  & \textbf{40.4}\tiny{+2.3}  & \textbf{20.7}\tiny{+2.2}  & \textbf{26.3}\tiny{+0.8}  & \textbf{45.8}\tiny{+1.0}  & \textbf{53.9}\tiny{+1.9}  \\ \bottomrule
  \end{tabular}
}
\caption{\textbf{Comparison of Average Precision (AP) at different IoUs and object scales.} Note that for fair comparison, all models are trained using same training protocol~\cite{He_2019_ICCV} (e.g., 3 schedule, scale jitter) and same backbone~(ResNet-50).\\
}
\label{tab:AP}
\vspace{-0.5cm}
\end{table*}


\begin{table*}[t]
\centering
\scalebox{0.90}{
  \begin{tabular}{@{}llllllllll@{}}
  \toprule
  Method        & AR   & AR\textsubscript{50}  & AR\textsubscript{60} & AR\textsubscript{70}& AR\textsubscript{80} & AR\textsubscript{90} & AR\textsubscript{S}  & AR\textsubscript{M}  & AR\textsubscript{L} \\ \midrule
  Faster R-CNN~\cite{ren2015faster}   & 54.0                      & 78.1                      & 73.6                      & 64.6                      & 50.3                      & 23.9                      & 35.9                      & 57.4                      & 67.8                      \\
  RetinaNet~\cite{lin2018focal}       & 55.4                      & 80.1                      & 75.5                      & 65.6                      & 49.7                      & 26.2                      & 37.2                      & 58.9                      & 70.5                      \\ \midrule
  FCOS~\cite{Tian_2019_ICCV}          & 59.0                      & 81.9                      & 77.7                      & 70.1                      & 55.0                      & 31.2                      & 40.4                      & 62.8                      & 74.1                      \\
  \textbf{Gaussian-FCOS}              & \textbf{60.8}\tiny{+1.8}  & \textbf{82.3}\tiny{+0.4}  & \textbf{78.5}\tiny{+0.8}  & \textbf{72.2}\tiny{+2.1}  & \textbf{59.2}\tiny{+4.2}  & \textbf{32.5}\tiny{+1.3}  & \textbf{42.8}\tiny{+2.4}  & \textbf{64.9}\tiny{+2.1}  & \textbf{76.1}\tiny{+2.0}  \\ \bottomrule
  \end{tabular}
}
\caption{\textbf{Comparison of Average Recall (AR) at different IoUs and object scales.}
These results demonstrate how well Gaussian-FCOS preserves objects without missing.
Due to uncertainty calibration, Gaussian-FCOS keeps well-localized objects from being filtered out. 
\\
} 
\label{tab:AR}
\vspace{-0.6cm}
\end{table*}



\begin{figure*}[t]
\centering
\includegraphics[width=\textwidth]{example.pdf} 
\caption{\textbf{ Estimated uncertainty examples of the proposed Gaussian-FCOS.} Since there is no supervision of uncertainty, we analyze the estimated uncertainty qualitatively. 
  Gaussian-FCOS captures lower certainties on unclear or occluded sides. For example, the left-directional certainty of the bird in the top-left image diminishes (66\%) since it is occluded by a branch of a tree. Both the surfboard and the person in the top-center image have much lower bottom-directional certainties (5\% and 33\%) since their shapes are quite unclear due to the water. The leftmost giraffe in the bottom-left image, occluded by another girraffe. also has lower right- and bottom-directional certainties (41\% and 8\%).
}
  \label{fig:example}
\end{figure*}


\subsection{Localization analysis}
We investigate how Gaussian-FCOS improves the object localization (AP) and preserves objects without missing (AR).
In particular, we compare Gaussian-FCOS with not only FCOS~\cite{Tian_2019_ICCV} but also Faster R-CNN~\cite{ren2015faster} and RetinaNet~\cite{lin2018focal} in that both are representative baselines in object detection field.
First, we analyze Average Precision (AP) at different IoU thresholds and object scales in Table~\ref{tab:AP}.
At soft-metric with 0.5 and 0.6 IoU thresholds, Faster R-CNN achieves better AP than the others because Region Proposal Network (RPN) helps Faster R-CNN to remove more false positives.
On the other hand, due to RPN, Faster R-CNN tends to be a lower recall rate than others as shown in Table~\ref{tab:AR}.
From strict metrics with 0.7 over IoU thresholds, Gaussian-FCOS shows better performance than the others.
This is because the estimated uncertainty enables the network to detect more accurate localized objects by calibrating the detection score.
In particular, Gaussian-FCOS obtains bigger AP gain on large objects.
We conjecture that this is because mislocalization occurs more frequently in larger objects than in smaller objects.

We also explore the influence of Gaussian-FCOS on preventing objects from being missed~(AR).  
Table~\ref{tab:AR} shows anchor-free methods (FCOS~\cite{Tian_2019_ICCV} and Gaussian-FCOS) tend to achieve better Average Recall (AR) than anchor-based methods (Faster-RCNN~\cite{ren2015faster} and RetinaNet~\cite{lin2018focal}) at overall IoUs and scales.
This is because anchor-free methods uses more positive samples than anchor-based methods, which increases the recall rate.
we can also find that Gaussian-FCOS outperforms FCOS at all metrics.
We speculate that the network can re-order the calibrated scores by reflecting localization uncertainty, which keeps well-localized objects from the NMS.
For small objects, which are more likely to be missed, Gaussian-FCOS can preserve more small objects compared to FCOS.



\begin{table}[t]
 \centering
\scalebox{0.9}{
  \begin{tabular}{lllllll}
  \toprule
  FCOS                              & AP         & AP\textsubscript{75} & AP\textsubscript{S}   & AP\textsubscript{M}   & AP\textsubscript{L}   \\ \midrule
  + centerness-branch~\cite{Tian_2019_ICCV}         & 38.5           & 41.6             & \textbf{22.4}         & 42.4              & 49.1              \\
  + IoU-branch~\cite{jiang2018acquisition,wu2020iou}    & 38.7           & 42.0             & 21.6          & 43.0              & 50.3              \\
  + QFL~\cite{li2020generalized}                & 39.0           & 41.9             & 22.0              & 43.1              & 51.0              \\ \midrule
  + \textbf{ours}                     & \textbf{39.2}  & \textbf{43.2}    & 21.9              & \textbf{43.2}     & \textbf{51.0}     \\ \bottomrule
  \end{tabular}
}
  \caption{\textbf{Comparison between box quality estimation methods.}}
  \label{tab:qaulity}\vspace{-0.3cm}
\end{table}

\begin{table}[t]
  \centering
  \scalebox{0.85}{
    \begin{tabular}{lllllll}
    \toprule
    Distribution & AP      & AP\textsubscript{75} & AP\textsubscript{S}   & AP\textsubscript{M}   & AP\textsubscript{L} \\
    \midrule
    Dirac delta~\cite{Tian_2019_ICCV}                     & 38.5        & 41.6       & 22.4       & 42.4         & 49.1 \\
    Gaussian~\cite{choi2019gaussian,kraus2019uncertainty,he2019bounding}  & 38.6        & 41.6       & 21.7       & 42.5         & 50.0 \\
    General w/ DFL~\cite{li2020generalized}                         & 39.0        & 42.3       & \textbf{22.6}  & 43.0         & 50.6 \\ \midrule
    \textbf{Gaussian with NPLL (ours)}                      & \textbf{39.2} & \textbf{43.2}  & 21.9       & \textbf{43.2}  & \textbf{51.0} \\
    \bottomrule
    \end{tabular}}
  \caption{\textbf{Comparison with representations of box location.} NPLL denotes the proposed negative power log-likelihood loss.}
  \label{tab:distribution}\vspace{-0.3cm}
\end{table}




\begin{table}[t]
\centering
\scalebox{0.84}{
\begin{tabular}{@{}llcccccc@{}}
\toprule
Method                              & Backbone      & AP                    & AP\textsubscript{75} & AP\textsubscript{S} & AP\textsubscript{M} & AP\textsubscript{L} \\ \midrule
\textit{anchor-based:}              &               &                       &                      &                     &                     &                     \\
RetinaNet~\cite{lin2018focal}       & ResNet-101    & 39.1                  & 42.3                 & 21.8                & 42.7                & 50.2                \\
ATSS~\cite{zhang2019bridging}       & ResNet-101    & 43.6                  & 47.4                 & 26.1                & 47.0                & 53.6                \\ 
GFL~\cite{li2020generalized}        & ResNet-101    & 45.0                  & 48.9                 & 27.2                & 48.8                & 54.5                \\ \midrule
\textit{anchor-free:}               &               &                       &                      &                     &                     &                     \\
ExtremeNet~\cite{zhou2019bottom}    & Hourglass-104 & 40.2                  & 43.2                 & 20.4                & 43.2                & 53.1                \\
CornerNet~\cite{law2018cornernet}   & Hourglass-104 & 40.5                  & 43.1                 & 19.4                & 42.7                & 53.9                \\
CenterNet~\cite{Duan_2019_ICCV}     & Hourglass-104 & 44.9                  & 49.0                 & 26.6                & 48.6                & 57.5                \\
FCOS~\cite{Tian_2019_ICCV}          & ResNet-101    & 41.5                  & 45.0                 & 24.4                & 44.8                & 51.6                \\
FCOS~\cite{Tian_2019_ICCV}          & ResNeXt-101   & 44.7                  & 48.4                 & 27.6                & 47.5                & 55.6                \\ \midrule
\textit{ours:}                      &               &                       &                      &                     &                     &                     \\
Gaussian-FCOS                       & ResNet-101    & 43.8                  & 48.1                 & 25.6                & 46.9                & 54.5                \\
Gaussian-FCOS                       & ResNeXt-101   & 45.5                  & 49.5                 & 28.2                & 48.5                & 56.1                \\
Gaussian-FCOS                       & VoVNet-99     & \textbf{46.0}         & \textbf{50.6}        & \textbf{28.4}       & \textbf{49.0}       & \textbf{56.4}       \\ \bottomrule
\end{tabular}
}
\caption{\textbf{Comparison to state-of-the-art methods on COCO \texttt{test-dev2017}.} These results are tested without multi-scale testing.\\
}
\label{tab:sota}
\end{table}



\subsection{Comparison with other methods.}
We also validate Gaussian-FCOS with other methods.
For a fair comparison, we adopt 1x learning schedule for 12 epochs without multi-scale training.
Table~\ref{tab:qaulity} and Table~\ref{tab:distribution} show the comparison results in terms of box quality estimation~\cite{Tian_2019_ICCV,jiang2018acquisition,wu2020iou,li2020generalized} and the target box representation~\cite{choi2019gaussian,kraus2019uncertainty,he2019bounding,li2020generalized}, respectively.
In Table~\ref{tab:qaulity}, our method achieves better performance than other methods.
Compared to center-point~\cite{Tian_2019_ICCV} and IoU~\cite{jiang2018acquisition,wu2020iou,li2020generalized} that are confined to only overall quality, our 4-directions uncertainty values can reflect more degrees~() of box uality.
Table~\ref{tab:distribution} show that our method outperforms other box representation methods including non-parametric General distribution~\cite{li2020generalized}.
Our Gaussian-FCOS exploits the \textit{explicit} uncertainty loss with the proposed negative power log-likelihood loss~(NPLL) that helps better understand the underlying distribution.


Lastly, we evaluate Gaussian-FCOS on COCO~\cite{lin2014microsoft} \texttt{test-dev2017} dataset for other detection methods.
Table~\ref{tab:sota} summarizes the results.
Compared to the state-of-the-art methods, Gaussian-FCOS with VoVNet-99 achieves the best performance.
In case of same ResNet-101 backbone, GFL shows the best performance because GFL uses the better baseline~(i.e., ATSS) that our baseline~(i.e., FCOS).
It is expected that applying our method for the anchor-based ATSS~\cite{zhang2019bridging} would boost performance but it is out of our research scope.




















\section{Conclusion}

We have proposed Gaussian-FCOS that estimates 4-directions uncertainty for anchor-free object detector.
To this end, We design the new uncertainty loss, negative Power log-likelihood loss~(NPLL) to train the network that produces the localization uncertainty and enables accurate localization.
Gaussian-FCOS captures not only the quality of the detected box but also which direction is uncertain by quantified value~[0,1].
This localization uncertainty is also utilized as box confidence with which the detection score is calibrated, boosting localization quality and preventing objects from being missed.
Experiments on challenging COCO dataset demonstrate that our Gaussian-FCOS improves the overall performance and especially improves the average recall by reducing the missing objects.
We can expect the proposed Gaussian-FCOS can serve as a component providing an important cue for safety-critical application or decision-making system.






{\small
\bibliographystyle{ieee_fullname}
\bibliography{ref}
}

\end{document}
