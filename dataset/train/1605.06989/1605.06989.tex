

\documentclass[runningheads,a4paper]{llncs}






\usepackage{epsfig,amsbsy}
\usepackage{amssymb,amsfonts}
\usepackage{graphicx}\graphicspath{{../../thesis_new/fig/pdf/}{../../thesis_new/fig/eps/}{../../thesis_new/fig/1_3/}{../../thesis_new/fig/3_1/}{../../thesis_new/fig/4_1/}{../../thesis_new/fig/5_1/}{../../thesis_new/fig/5_2/}{../../thesis_new/fig/6_1/}{../../thesis_new/fig/capsm/}{../../thesis_new/fig/literature/}{../../thesis_new/fig/mwbm/}}
\usepackage{mathtools}

\usepackage{multirow} 

\usepackage{color}
\newcommand{\red}{\color{red}\bf} \usepackage[rightcaption]{sidecap}
\usepackage{caption}
\usepackage{subcaption}
\usepackage{wrapfig} 

\usepackage{cite}


\usepackage{algorithm,algorithmic}
\usepackage{graphics}
\usepackage{enumerate}
\usepackage{bm}      

\usepackage{soul}	\usepackage{url}
\usepackage[pdfpagemode={UseOutlines},bookmarks=true,bookmarksopen=true,
   bookmarksopenlevel=0,bookmarksnumbered=true,hypertexnames=false,
   colorlinks=true,linkcolor={blue},citecolor={red},urlcolor={magenta},
   pdfstartview={FitV},unicode,breaklinks=true, pdftex]{hyperref} 





\usepackage{etoolbox} \AtEndEnvironment{example}{\null\hfill\qed}


\newtheorem{experiment}{Experiment}
\AtEndEnvironment{experiment}{\null\hfill\qed}




\AtEndEnvironment{remark}{\null\hfill\qed}
\AtEndEnvironment{proof}{\null\hfill\qed}
\newcommand{\W}{\textit{Wt}}

\newcommand{\Ga}{\mathcal{G}_{m,\sigma}}
\newcommand{\Gl}{\mathcal{G}_{m < \sigma}}
\newcommand{\Gg}{\mathcal{G}_{m \geq \sigma}}



\newcommand{\nint}{\mathbb{N}_0}
\newcommand{\nrat}{\mathbb Q_0^+}
\newcommand{\nreal}{\mathbb R_0^+}
\newcommand{\cln}{\text{:\;}}
\newcommand{\Hh}{\textit{H}} \newcommand{\SmP}{\varSigma_P^m}
\newcommand{\SmT}{\varSigma_T^m}
\newcommand{\SnT}{\varSigma_T^n}

\newcommand{\todo}[1]{\marginpar{\textsc{Todo:}\color{blue} \footnotesize #1}}

\newcommand{\EP}{\clearpage\thispagestyle{empty}\mbox{}}



\usepackage[T1]{fontenc}
\usepackage[utf8]{inputenc}





\begin{document}

\mainmatter

\title{Experimental Evaluation of\\Modified Decomposition Algorithm for\\Maximum Weight Bipartite Matching\thanks{A preliminary version of this paper has been presented in the  International Conference on Theory and Applications of Models of Computation (TAMC 2014)~\cite{das14}. The current expanded version includes a better bound of the parameter  and the experimental evaluation of the theoretical claims made in previous version.}}



\titlerunning{Experimental Evaluation of Modified Decomposition Algo.\ for MWBM}

\author{Shibsankar Das}

\institute{Department of Mathematics\\
Institute of Science, Banaras Hindu University, Varanasi - 221\ 005, India.\\
\email{reach\_shibsankardas@yahoo.com, shibsankar@bhu.ac.in}
}

\date{\today}


\maketitle              

\begin{abstract}
Let  be an undirected bipartite graph with 
positive integer weights
on the edges. We refine the existing decomposition
theorem originally proposed by Kao et al., for computing
maximum weight bipartite matching. We apply it to design an efficient version of the decomposition algorithm to compute the weight of
a maximum weight bipartite matching of  in -time
by employing an algorithm designed by Feder and Motwani as a subroutine, 
where  and   denote the number of nodes and
the maximum edge weight of , respectively and .
The parameter  is smaller than the total edge weight  
essentially when the largest edge weight differs by more than one from the second largest edge weight in the current working graph in any decomposition step of the algorithm. In best case  where  be the number of edges of  and 
in worst case  that is, 
In addition, we talk about a scaling property of the algorithm and research a better bound of the parameter . 
An experimental evaluation on randomly generated data shows that the proposed improvement is significant in general.

\keywords{Graph algorithm, maximum weight bipartite matching, graph decomposition, minimum weight vertex cover, Combinatorial optimization}
\end{abstract}


\section{Introduction}
Let 
be an undirected, weighted bipartite graph 
where  and  are two non-empty partitions of the vertex set  of , and  is the edge set of  with
positive integer weights on the edges which are given by the weight function 
, where  is the set of positive integers.  
Throughout the paper, we use the symbols  and    to denote the largest weight of any edge and  the total weight of , respectively.  
The weight of the graph   is defined by
. 
We also assume that the graph does not have any isolated vertex. 
For uniformity we treat an unweighted
graph as a weighted graph having unit weight for all edges.


We use the notation  for an edge  between  and , and its weight is denoted by .
We also say that  is \textit{incident} on vertices  and ;
and  and  are each \textit{incident} with .
Two vertices  of  are \textit{adjacent} if there exists an edge  of  to which they are both incident. 
Two edges  of   are  \textit{adjacent} if there exists a vertex  to which they are both incident. 

A subset  of edges is a \emph{matching} if no two edges of 
share a common vertex. A vertex  is said to be \emph{covered} or
\emph{matched} by the matching  if it is incident with an edge of
; otherwise  is \emph{unmatched}~\cite{bondy82,bondy08}.

A matching  of  is called a \textit{maximum} (\textit{cardinality}) \textit{matching} if there
does not exist any other matching of  with greater cardinality. We denote such a
matching by . The weight of a matching  is defined as
. A matching  of  is a \emph{maximum weight
matching}, denoted as , if  for every other matching
 of the graph .



Observe that, if  is an unweighted graph then  is a , which we write as  in short and its
weight is given by  . Similarly, if  is an
undirected and weighted graph with  for all edges  in 
and  is a constant then also we have  with weight of the
matching as .
\subsection{Our Contribution}
In~\cite{kao99,kao02}, Kao et al.\ proposed a decomposition theorem and algorithm for computing weight of a Maximum Weight Bipartite Matching (MWBM) of the bipartite graph .
Our contribution in this paper is a revised version of the existing decomposition theorem
and use it efficiently to design an improved version of the decomposition algorithm to estimate the weight of a MWBM of  in time
 by taking algorithm designed by Feder and
Motwani~\cite{feder95} as base algorithm, where
. 


This algorithm bridges a gap between the best known time complexity of computing a Maximum Cardinality Matching (MCM) and that of computing a MWBM of a bipartite graph.
In best case, computation of weight of a MWBM takes 
 time which is the same as the complexity of the Feder and Motwani's algorithm~\cite{feder95} for computing MCM of unweighted bipartite graph;  whereas
in worst case it takes , i.e.,\ . 
Further, we provide an interesting scaling property of the algorithm and a better bound of the parameter .
However, it seems to be a challenging problem to get rid of  or  from the complexity.



The modified algorithm works well for general  but is best known for
. We also design a revised algorithm to construct
minimum weight cover of a bipartite graph in time  

to identify the edges involved in maximum weight bipartite matching.
It is also possible to use other algorithms as a subroutine,
for example, algorithms given by Hopcroft and Karp \cite{hopcroft73} and
Alt et al.~\cite{alt91} in which case the running times of our algorithm will be  and 
, respectively.
An experimental evaluation on randomly generated bipartite
graphs shows that the proposed improvement is significant in general.
\subsection{Roadmap}
In Section~\ref{mwbm:Survey},
we give a detailed summary of existing maximum matching algorithms and
their complexities for unweighted and weighted bipartite graphs.
Section~\ref{Decomposition} describes modified decomposition theorem and an
algorithm to compute the weight of a MWBM. The complexity analysis of the
algorithm is discussed in Section~\ref{mwbm:Complexity_analysis}. The algorithm to compute minimum weight cover of a bipartite graph is given in Section~\ref{Find_MWC}, which is used to find the edges of a MWBM. 
Section~\ref{mwbm:Experiments} provides the experimental comparisons between the modified algorithm and Kao et al.'s algorithm for randomly generated bipartite graphs.
We summarize the results in Section~\ref{mwbm:Conclusion}.

\section[Survey of Maximum Matching in Bipartite Graph]{Survey of Maximum Matching in Bipartite Graph}
\label{mwbm:Survey}
The problem of computing maximum matching in a given graph is one of
the fundamental algorithmic problem that has played an important role
in the development of combinatorial optimization and algorithmics.
A survey of some of the well known existing maximum (cardinality) matching and maximum weight  matching algorithms for bipartite graph are summarized in
Table \ref{Table:MUWBM}  and Table \ref{Table:MWBM}, respectively.
The algorithms with best asymptotic bound are indicated by ``''
in these tables. A more detailed and technical discussion of the algorithms can be found
in textbooks~\cite{korte07,schrijver03,douglas00}.

\subsection{Maximum Cardinality Matching}
For unweighted bipartite graphs, Hopcroft-Karp \cite{hopcroft73}
algorithm, which is based on augmenting path technique, offers
the best known performance for finding maximum matching in time
. In case of dense unweighted bipartite graphs, that is with
, slightly better algorithms exist.
An algorithm by Alt et al.~\cite{alt91} obtains a maximum matching in
 time. In case of , this
becomes  and is also 
-factor
faster than Hopcroft-Karp algorithm. This speed up is obtained by an
application of the fast adjacency matrix scanning technique of Cheriyan,
Hagerup and Mehlhorn~\cite{cheriyan90}. The algorithm proposed by Feder-Motwani~\cite{feder95} has the time complexity 
, where
.
\vfill
\begin{table*}[htpb]\centering
\caption{Complexity survey of maximum unweighted bipartite matching algorithms.}
\label{Table:MUWBM}
\begin{tabular}{|l|l|l|} 	\hline
\multicolumn{1}{|c|}{\bf Year}	& \multicolumn{1}{|c|}{\bf Author(s)}	& \multicolumn{1}{|c|}{\bf Complexity}\\
\hline
1973  & Hopcroft and Karp \cite{hopcroft73}  		& 	\\
\hline
1991 & Alt, Blum, Mehlhorn and Paul \cite{alt91} 	&  \\
\hline
1995  &Feder and Motwani \cite{feder95}	  		&  \\
\hline
\end{tabular}
\end{table*}






\vspace*{1cm}
\subsection{Maximum Weight Bipartite Matching}
Several algorithms have also been proposed for computing maximum weight
bipartite matching, improving both theoretical and practical running
times. The well known Hungarian method, the first polynomial time
algorithm, was introduced by Kuhn \cite{kuhn55} and Munkres
\cite{munkres57}. Fredman and Tarjan \cite{fredman87} improved this with
running time  for sparse graph by using Fibonacci heaps. An 
-time scaling algorithm was proposed by
Gabow \cite{gabow85} under the assumption
that edge weights are integers. A different and faster scaling algorithm was given by
Gabow and Tarjan~\cite{gabow89} with running time
. Kao et al.~\cite{kao02} proposed an
-time decomposition technique
under the assumptions that weights on the edges are positive and .


In addition to the above exact algorithms, several randomized and approximate algorithms
are also proposed, see for example~\cite{duan10,sankowski09}.
For a tight lower bound for the weights of maximum weight matching in bipartite graph, please refer to~\cite{das16_TLB_arXiv}.


\begin{table*}[htpb]
\centering
\caption{Complexity survey of maximum weight bipartite matching algorithms.}
\label{Table:MWBM}
\begin{tabular}{|l|l|l|} 	\hline
 \multicolumn{1}{|c|}{\bf Year(s)}		&  \multicolumn{1}{|c|}{\bf Author(s)}	& \multicolumn{1}{|c|}{\bf Complexity} \\
\hline
1955,				& Kuhn \cite{kuhn55},				&  		\\
1957				& Munkres \cite{munkres57} 				& (Hungarian method)	\\
\hline
1960				& Iri \cite{iri60,schrijver03} 			& 	\\
\hline
1969				& Dinic and Kronrod \cite{dinic69,schrijver03} 			& 	\\
\hline
1984, 1987 	&Fredman and Tarjan \cite{fredman87}  	& 	\\
\hline
1985  			&Gabow \cite{gabow85} 					& 	\\
\hline
1989 			& Gabow and Tarjan \cite{gabow89}	 	& 	\\
\hline
1999 			& Kao, Lam, Sung and Ting \cite{kao99}		 		&   \\
\hline
2001	 			& Kao, Lam, Sung and Ting \cite{kao02} 				&   \\
\hline
2014  & 		 & \\
\cline{3-3}
(This work)	& 	& 	\\
\cline{3-3}
			& 	& 	\\
\cline{3-3}
\hline
\end{tabular}
\end{table*}







\section[Refined Decomposition Theorem for MWBM]
{Refined Decomposition Theorem for Maximum Weight Bipartite Matching}
\label{Decomposition}
We now propose a modified decomposition theorem which is a generalization of the existing decomposition theorem originally proposed by Kao et al.~\cite{kao02,kao99}
and use it to develop a revised  version of the decomposition algorithm to decrease the
number of iterations and speed up the computation of the weight of a MWBM.
Let  be an undirected, weighted bipartite graph 1
having  and  as partition
of vertex set . Further, let  be set of
edges of  with weights  for , where   are
not necessarily distinct. As defined earlier, let  be the maximum edge
weight, that is, for all , , and
  be the total weight of  .


Our algorithm considers several intermediate graphs with  lighter edge weights. During this process it is possible that weights of some of the
edges may 
become zero. 
An edge  is said to be {\it active} if
its weight , otherwise it is said to be {\it inactive}, that is when . Let there be  distinct edge weights in current
working graph where .
We denote the first two distinct maximum edge weights in current
working graph by  and , respectively.
Assign  in case .

We first build two new graphs referred to as  and  from
a given weighted bipartite graph . For any integer , we decompose the graph  into two lighter weighted bipartite graph  and
 as proposed by Kao et al.~\cite{kao99,kao02}. A minimum weight cover is a dual of maximum weight matching \cite{kao02}. A \emph{cover}
of  is a function  such that
. Let . A cover  is \emph{minimum weight cover} if  is minimum.
\begin{description}

\item[Formation of  from :] The graph
 is formed by including those edges  of  whose weights
  lie in the range . Each edge  in graph
 is assigned weight . For illustration,  is
constructed by the maximum weight edges of  and assigned unit weight
to each edge.

\item[Formation of  from :] Let
 be the minimum weight cover of . The graph  is
formed by including every edge  of  whose weight satisfies the condition 
 
The weight assigned to such an
edge is .
\end{description}

\begin{theorem}[The Decomposition Theorem \cite{kao02}]
\label{DecompositionTh}
Let  be an undirected, weighted bipartite graph.
Then
\begin{enumerate}[(a)]
\item for any integer , 
\item in particular (trivial), for ,

\end{enumerate}
\end{theorem}

Note that the Theorem \ref{DecompositionTh}(b) is derived from
Theorem \ref{DecompositionTh}(a), since for , we have  and 
 
The Theorem
\ref{DecompositionTh}(b) is used recursively in the Algorithm~\ref{Algorithm0_Kao}~\cite{kao02},
to compute the weight of a maximum weight matching of the graph .




\begin{algorithm}[H]
{\caption[Kao et al.'s algorithm to compute weight of a MWBM.]{Kao et al.'s algorithm~\cite{kao02} to compute weight of a MWBM.}
\label{Algorithm0_Kao}
\begin{description}
\item[\it Input:] A weighted, undirected, complete bipartite graph  with
positive integer weights on the edges.
\item[\it Output:] Weight of a maximum weight matching of , that is, .
\end{description}
\begin{tabbing}
123\=\kill
{Compute-}\+\\
1: \= Construct  from .\\
2:   \> Compute  and find a minimum weight cover  of .\\
3:   \> Construct  from  and .\\
4:   \> \textbf{if}  is empty,\\
5:\>~~~ \textbf{then} \textbf{return} ;\\
6:\> \textbf{else} \textbf{return} +Compute-.
\end{tabbing}
}
\end{algorithm}



\begin{remark}
A graph  may not have all edge weights distinct. Consider the set of distinct edge
weights of . The Algorithm~\ref{Algorithm0_Kao} works efficiently only when the largest
edge weight differs by exactly one from the second largest edge weight of the current graph during an invocation of Theorem~\ref{DecompositionTh}(b) in each iteration.  
\end{remark}



\begin{remark}
Observe that for arbitrary ,  need not be equal
to , that is, we cannot always conclude that .
\end{remark}

One of our objectives is to investigate those values of  for which
 is equal to  apart from
the trivial value of 
as 1 in each iteration of the Algorithm~\ref{Algorithm0_Kao} to generate  having all its
edge weights as 1.

In order to get the speed up whenever possible, by decreasing the number of iterations whenever possible, we revise
the Theorem~\ref{DecompositionTh}(b) and propose Theorem~\ref{DecompositionTh_Modified} which gives a
domain of  where  and as a consequence of that 
we can write 
 
It works for 
and performs well especially when the largest edge weight differs  by
more than one from the second largest edge weight in the current graph
in a decomposition step during an iteration.

\begin{theorem}[The Modified Decomposition Theorem]
\label{DecompositionTh_Modified}
The following equalities hold for any integer  where
 and  are the first two distinct maximum edge weights of graph
, respectively. We assign  in case all edge weights are
equal.
\begin{enumerate}[(a)]
\item \label{thm:dt:a} ,

\item

\end{enumerate}
\end{theorem}

\begin{proof}
The proof of the above statements are based on the construction of new
graphs  and  from  and Theorem \ref{DecompositionTh}(a).
\begin{enumerate}[(a)]
\item To prove that for any integer  where ,
 holds true, it is enough to prove the
same for the maximum value\footnote{
For illustration,
consider  where . Then as per the
formation of  from ,  is built by choosing those edges
of  that have weight . Since, 
and  for any ,  has only
the heaviest edges of . For optimization, choose ,
the maximum possible value of .} of
, that is, for . As specified earlier, the
construction of  is done by choosing those edges  of  that have weight 

Since ,  has only the heaviest edges of
 and each such edge is assigned the same weight.
Thus,  for .

\item Observe that  and .
So, by using Theorem \ref{DecompositionTh}(a) we have, ,

Also by using the Theorem~\ref{DecompositionTh_Modified}(\ref{thm:dt:a}),
 for all .
Weight of each edge\footnote{Only maximum weight edges of  are included in .}  in  is exactly . Therefore,

Hence for any integer , 
2pt]
			 & = h * \textit{Wt}(\textit{mm}(G_h))+ \textit{Wt}(\textit{mwm}(G_h^\Delta)).\textit{Wt}(u,v)-(N-h) = H_1-(H_1-h) = h\textit{Wt}(u,v)-(N-h) = H_2-(H_1-h) =
(H_2-H_1)+h=(1-h)+h=1.
l_1h_1+l_2h_2+ \cdots + l_ph_p=W \quad\text{and}\quad 
l_1+l_2+ \cdots + l_p=W'.
h_i'=H'_{i1}-H'_{i2}=\alpha*H_{i1} - \alpha*H_{i2}=
\alpha h_i \quad\text{where}\quad i=1,2,\ldots,p, 
l_1h'_1+l_2h'_2+ \cdots + l_ph'_p
= l_1 \alpha h_1+l_2 \alpha h_2+ \cdots + l_p \alpha h_p
=\alpha W,  
l_1+l_2+ \cdots + l_p=W'.
|E| \leq W' \leq \frac{W}{ \textit{GCD}(w_1,w_2,\ldots,w_{|E|})} \leq W.
& l_1h_1+l_2h_2+ \cdots + l_ph_p=W, \text{~where~} h_i=H_{i1}-H_{i2} 
\quad\text{and}\quad \\
& l_1+l_2+ \cdots + l_p=W'.

\therefore~~W' 
& =    l_1+l_2+ \cdots + l_p  \\
& \leq l_1(h_1/g)+l_2(h_2/g)+ \cdots + l_p(h_p/g) \\
& \leq (l_1h_1+l_2h_2+ \cdots + l_ph_p)/g = \frac{W}{g} \leq W.
\begin{array}{ll}
& T(|V|,W',{N})= O(\sqrt{|V|}l_1) + T(|V|,W'',N'') \
4pt]
 & = O\left(\sqrt{|V|}\sum\limits_{i=1}^p l_i\right) 
   = O(\sqrt{|V|}W').\\
\end{array}
l_1h_1+l_2h_2+ \cdots + l_ph_p=W.
& T(|V|,W',{N})= O(\sqrt{|V|}l_1/k(|V|,l_1)) + T(|V|,W'',N'') \quad\mbox{and}\
4pt]
	&~~~= O\left(\dfrac{\sqrt{|V|}l_1}{k(|V|,l_1)}\right) + O\left(\dfrac{\sqrt{|V|}l_2}{k(|V|,l_2)}\right) + \cdots + O\left(\dfrac{\sqrt{|V|}l_p}{k(|V|,l_p)}\right) \4pt]
	&~~~= O\left(\dfrac{\sqrt{|V|}}{\log |V|} \left(\log |V|^2 \sum \limits_{i=1}^p l_i - \sum \limits_{i=1}^p l_i \log l_i \right)\right)
f\left(\sum_0^n \mu_i x_i\right) \leq
\sum_{i=0}^n  \mu_i f(x_i).\begin{array}{l}
\sum\limits_{i=1}^p l_i \log l_i = \sum\limits_{i=1}^p f(l_i) \geq p f\left(\dfrac{\sum\limits_{i=1}^p l_i}{p}\right)
 = p f\left(\dfrac{W'}{p}\right)\
This lead to the running time complexity as follows.
5pt]
&~~~= O\left(\dfrac{\sqrt{|V|}}{\log |V|} \left( W'\log {|V|^2} -  W' \log \dfrac{W'}{{N}} \right)\right) \5pt]
&~~~= O(\sqrt{|V|}W'/k(|V|,W'/{N})).
\end{array}

This is better than the  time as
mentioned in~\cite{kao02}. 

The parameter  is smaller than  which is the total weight of , 
 essentially when the heaviest edge weight differs by more than one unit from the
second heaviest edge weight in a current working graph 
during a decomposition in any iteration of the algorithm. 
In best case the algorithm
takes  time to compute a maximum weight matching  
and in worst case ,
that is,  .
This time complexity bridges a gap between the best known time complexity for computing a 
Maximum Cardinality Matching (MCM) of unweighted bipartite graph and that of computing a MWBM of a weighted bipartite graph.

However, it is very difficult and challenging to get rid of  or  from the complexity.
This modified algorithm works well for general  but is  best known for . 










\end{document}