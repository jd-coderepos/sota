\documentclass[submission,copyright,creativecommons]{eptcs}
\providecommand{\event}{QAPL 2013} 
\usepackage{aliascnt} \def\mynewtheorem#1[#2]#3{\newaliascnt{#1}{#2}\newtheorem{#1}[#1]{#3}\aliascntresetthe{#1}\expandafter\def\csname #1autorefname\endcsname{#3}}
\usepackage{amsthm}
\let\theorem\relax
\newtheorem{theorem}{Theorem}
\newtheorem*{unnumbered_theorem}{Theorem}
\mynewtheorem{lemma}[theorem]{Lemma}
\mynewtheorem{corollary}[theorem]{Corollary}
\mynewtheorem{proposition}[theorem]{Proposition}
\theoremstyle{definition}
\mynewtheorem{remark}[theorem]{Remark}
\mynewtheorem{convention}[theorem]{Convention}
\mynewtheorem{fact}[theorem]{Fact}
\mynewtheorem{example}[theorem]{Example}
\mynewtheorem{definition}[theorem]{Definition}
\mynewtheorem{property}[theorem]{Property}
\mynewtheorem{notation}[theorem]{Notation}

\def\sectionautorefname{Section}
\def\subsectionautorefname{Subsection}

\usepackage{subcaption}


\usepackage{pdfpages}

\usepackage{graphics}
\usepackage[latin1]{inputenc} 
\usepackage[english]{babel} 
\usepackage{amsmath} 
\usepackage{amsfonts} 
\usepackage{amssymb} 
\usepackage{xspace} 
\usepackage{latexsym} 
\usepackage{url} 
\usepackage{xspace} 
\usepackage{graphics,color}              
\usepackage{array}
\usepackage{listings}
\lstdefinelanguage{IMP}
    {morekeywords={while,do,skip,goto,if,then,else},
     keywordstyle=\sffamily,
     moredelim=**[is][\color{blue}]{|}{|},
     mathescape,
     literate=*{'a}{}1 {'b}{}1 {'c}{}1,
     basicstyle=\small,
    }
\lstset{language=IMP}
\usepackage{multirow}
\newcolumntype{b}{@{}>{{}}}
\newcolumntype{B}{@{}>{{}}c<{{}}@{}}
\newcolumntype{h}[1]{@{\hspace{#1}}}
\newcolumntype{L}{>{}}
\newcolumntype{C}{>{}}
\newcolumntype{R}{>{}}
\newcolumntype{S}{>{}}
\newcolumntype{n}{@{}}

\usepackage[disable,
    colorinlistoftodos]{todonotes}
\usepackage{enumerate}
\usepackage{tikz}



\newcommand{\eqdef}{=_{\text{def}}} 
\newcommand{\Int}{\mathit{int}} 
\newcommand{\nat}{\mathit{nat}} 
\newcommand{\String}{\mathit{string}} 
\newcommand{\Ident}{\mathit{ident}} 
\newcommand{\Block}{\mathit{block}} 
\newcommand{\Signature}{\mathit{signature}} 
 
\newcommand{\pc}{\mathit{pc}} 
\newcommand{\estack}{\mathit{estack}} 
\newcommand{\Error}{\epsilon} 





\newcommand{\staterule}[3]{} 
 
\newcommand{\GAP}{2ex} 
 
\newcommand{\recall}[2]{} 
 
\newcommand{\hbra}{\noindent\hbox to \textwidth{\leaders\hrule height1.8mm
depth-1.5mm\hfill}} 
\newcommand{\hket}{\noindent\hbox to \textwidth{\leaders\hrule
height0.3mm\hfill}} 
\newcommand{\ratio}{.3} 
 
\newenvironment{display}[1]{\begin{tabbing} 
  \hspace{1.5em} \= \hspace{\ratio\linewidth-1.5em} \= \hspace{1.5em} \= \kill 
  \noindent\hbra\-.8ex] 
  \hbox to \textwidth{\leaders\hrule height1.6mm depth-1.5mm\hfill}\-.8ex]\hket 
  \end{tabbing}} 
 
 
\newcommand{\sbline}{\hfill\smash[t]{\rule[1.5em]{\textwidth}{0.2ex}
\hfill\hspace*{0ex}}} 
\newcommand{\sline}{\hfill\smash[t]{\rule[1.5em]{\textwidth}{0.1ex}
\hfill\hspace*{0ex}}} 
\newcommand{\sentry}[2]{\>\>\ \smash[t]{\vrule width 0.2mm height 
    1.2\baselineskip depth 1.5\baselineskip}\>#2} 
 










\newcommand{\Figbar}{{\center \rule{\hsize}{0.3mm}}}
\newenvironment{figureplr}[1][t]{\begin{figure}[#1] \Figbar}{\Figbar \end{figure}}


\newcommand{\cl}[1]{{\cal #1}}          \newcommand{\la}{\langle}               \newcommand{\ra}{\rangle} 
 
\newcommand{\lf}{\lfloor} 
\newcommand{\rf}{\rfloor} 
\newcommand{\ul}[1]{\underline{#1}}     \newcommand{\ol}[1]{\overline{#1}}      \newcommand{\ok}{~ok}                   



\newcommand{\Gives}{\vdash}             \newcommand{\IGives}{\vdash_{I}}        \newcommand{\AIGives}{\vdash_{{\it AI}}} \newcommand{\CGives}{\vdash_{C}}        


\newcommand{\Models}{\mid \! =}              

\newcommand{\emptycxt}{\On}              \newcommand{\subs}[2]{[#1 / #2]} 


\newcommand{\Sub}[3]{[#3 / #2]#1}       

\newcommand{\lsub}[2]{#2 / #1}          

\newcommand{\impl}{\supset} 
\newcommand{\arrow}{\rightarrow}        \newcommand{\trarrow}{\stackrel{*}{\rightarrow}}        \newcommand{\limp}{\multimap} \newcommand{\bang}{\, !} 
\newcommand{\limpe}[1]{\stackrel{#1}{\multimap}}
\newcommand{\hyp}[3]{#1:(#2, #3)}
\newcommand{\letm}[3]{{\sf let} \ ! #1 = #2 \ {\sf in} \ #3}    \newcommand{\lets}[3]{{\sf let} \ #1 = #2 \ {\sf in} \ #3}    \newcommand{\letp}[3]{{\sf let} \ \S #1 = #2 \ {\sf in} \ #3}    \newcommand{\tertype}{{\bf 1}}
\newcommand{\behtype}{{\bf B}}
\newcommand{\bt}[1]{{\it BT}(#1)}       \newcommand{\cxt}[1]{#1[~]}             \newcommand{\pr}{\parallel}             \newcommand{\Nat}{\mathbf{N}}                 \newcommand{\Natmax}{\mathbf{N}_{{\it max}}}  \newcommand{\Rat}{\mathbf{Q}^{+}}                 \newcommand{\Ratmax}{\mathbf{Q}^{+}_{{\it max}}}  \newcommand{\Alt}{ \mid\!\!\mid  } 
\newcommand{\isum}{\oplus} 
\newcommand{\csum}{\uplus}              \newcommand{\dpar}{\mid\!\mid} 
\newcommand{\infer}[2]{\begin{array}{c} #1 \\ \hline #2 \end{array}} 




\newcommand{\bool}{{\sf bool}}          

\newcommand{\dl}{[\![}                  \newcommand{\dr}{]\!]}                  \newcommand{\lam}{{\bf \lambda}}        




\newcommand{\ubis}{\approx^u}          \newcommand{\uabis}{\approx^{u}_{ccs}} 

\newcommand{\cbis}{\approx}        \newcommand{\cabis}{\approx_{ccs}}  

\newcommand{\lcbis}{\approx^{\ell}} \newcommand{\lcabis}{\approx^{\ell}_{ccs}} \newcommand{\lcbiswrong}{\approx^{\ell \Downarrow}} 







\newcommand{\maytest}{=_{\Downarrow}}
\newcommand{\musttest}{=_{\Downarrow_{S}}}


 
 


\newcommand{\prt}[1]{{\cal P}(#1)}      \newcommand{\finprt}[1]{{\cal P}_{fin}(#1)}\newcommand{\finprtp}[1]{{\cal P}_{fin}^{+}(#1)}\newcommand{\inter}{\cap}               \newcommand{\Union}{\bigcup}            \newcommand{\Inter}{\bigcap}            \newcommand{\cpl}[1]{#1^{c}}            \newcommand{\card}{\sharp}              \newcommand{\minus}{\backslash}         \newcommand{\sequence}[2]{\{#1\}_{#2}}  \newcommand{\comp}{\circ}               \newcommand{\mset}[1]{\{\! | #1 |\!\}}  



\newcommand{\two}{{\bf O}}              \newcommand{\meet}{\wedge}              \newcommand{\MEET}{\bigwedge}           \newcommand{\dcl}{\downarrow}           \newcommand{\ucl}{\uparrow}             \newcommand{\conv}{\downarrow}          \newcommand{\diver}{\uparrow}           \newcommand{\Conv}{\Downarrow}          \newcommand{\SConv}{\Downarrow_{S}}          \newcommand{\CConv}{\Downarrow_{C}}
\newcommand{\Diver}{\Uparrow}           \newcommand{\cpt}[1]{{\cal K}(#1)}      \newcommand{\ret}{\triangleleft}        \newcommand{\nor}{\succeq}
\newcommand{\prj}{\underline{\ret}}     \newcommand{\parrow}{\rightharpoonup}   \newcommand{\ub}[1]{{\it UB}(#1)}       \newcommand{\mub}[1]{{\it MUB}(#1)}     \newcommand{\lift}[1]{(#1)_{\bot}}      \newcommand{\forget}[1]{\underline{#1}} 

\newcommand{\rl}[1]{\;{\cal #1}\;}             \newcommand{\per}[1]{\;#1 \;} 
\newcommand{\wddagger}{\natural}  

\newcommand{\pair}[2]{\langle #1 , #2 \rangle} 



 
\newcommand{\fn}[1]{{\it fn}(#1)}                       \newcommand{\bn}[1]{{\it bn}(#1)}                       \newcommand{\names}[1]{{\it n}(#1)}                     \newcommand{\pio}{\pi_1}                                \newcommand{\pioo}{\pi_{1}^{r}} 
\newcommand{\piom}{\pi_{1}^{-}}                         \newcommand{\pioi}{\pi_{1I}}                    \newcommand{\pifo}{\pi_{\w{1f}}}                                \newcommand{\pilo}{\pi_{\w{1l}}}                                \newcommand{\sort}[1]{{\it st}(#1)}                     \newcommand{\ia}[1]{{\it ia}(#1)}                     \newcommand{\ite}[3]{{\sf if~} #1 {\sf ~then~} #2 {\sf ~else~} #3}      \newcommand{\casep}[2]{{\sf case}^{\times}(#1, \pair{x}{y}\Arrow#2)}      \newcommand{\casel}[3]{{\sf case}^{L}(#1, #2, \s{cons}(x,y)\Arrow#3)}      \newcommand{\caseb}[3]{{\sf case}^{b}(#1, #2, \s{cons}(x,y)\Arrow#3)}      \newcommand{\nil}{{\sf nil}} 
\newcommand{\cons}{{\sf cons}} 
\newcommand{\idle}[1]{{\it Idle}(#1)}                   \newcommand{\conf}[1]{\{ #1 \}}                         \newcommand{\link}[2]{#1 \mapsto #2}                    \newcommand{\mand}{\mbox{ and }} 
\newcommand{\dvec}[1]{\tilde{{\bf #1}}}                 \newcommand{\erloc}[1]{{\it er}_{l}(#1)}                \newcommand{\vcb}[1]{{\bf #1}} 
\newcommand{\lc}{\langle\!|} 
\newcommand{\rc}{|\!\rangle} 
\newcommand{\obj}[1]{{\it obj}(#1)}  
\newcommand{\move}[1]{{\sf move}(#1)}  
\newcommand{\qqs}[2]{\forall\, #1\;\: #2} 
\newcommand{\qtype}[4]{\forall #1 :  #2 . (#4,#3)} 
\newcommand{\xst}[2]{\exists\, #1\;\: #2} 
\newcommand{\xstu}[2]{\exists\, ! #1\;\: #2} 
\newcommand{\dpt}{\,:\,} 
\newcommand{\cond}[3]{\mathsf{if}\ #1\ \mathsf{then}\ #2\ \mathsf{else}\ #3} 
\newcommand{\s}[1]{{\sf #1}}    \newcommand{\vc}[1]{{\bf #1}} 
\newcommand{\lnorm}{\lbrack\!\lbrack} 
\newcommand{\rnorm}{\rbrack\!\rbrack} 
\newcommand{\sem}[1]{\underline{#1}} 
\newcommand{\tra}[1]{\langle #1 \rangle}
\newcommand{\trb}[1]{[ #1 ]}
\newcommand{\squn}{\mathop{\scriptstyle\sqcup}} 
\newcommand{\lcro}{\langle\!|} 
\newcommand{\rcro}{|\!\rangle} 
\newcommand{\semi}[1]{\lcro #1\rcro} 
\newcommand{\sell}{\,\ell\,} 
\newcommand{\SDZ}[1]{\marginpar{\textbf{SDZ:} {#1}}} 
 
\newcommand{\when}[3]{{\sf when}~#1~{\sf then}~#2~{\sf else}~#3}  
\newcommand{\wthen}[2]{{\sf when}~#1~{\sf then}~#2~}  
\newcommand{\welse}[1]{{\sf else}~#1}  



\newcommand{\act}[1]{\xrightarrow{#1}} 

\newcommand{\lact}[1]{\stackrel{#1}{\makebox[5mm]{\,}}}

\newcommand{\pst}[2]{{\sf pset}(#1,#2)}
\newcommand{\st}[2]{{\sf set}(#1,#2)}
\newcommand{\wrt}[2]{{\sf w}(#1,#2)}

\newcommand{\chtype}[2]{{\it Ch_{#1}(#2)}}
\newcommand{\rgtype}[2]{{\it {\sf Reg}_{#1} #2}}

\newcommand{\get}[1]{{\sf get}(#1)}









\newcommand{\acteq}[1]{\stackrel{#1}{\leadsto}} 


\newcommand{\actI}[1]{\xrightarrow{#1}_{1}}

\newcommand{\actII}[1]{\xrightarrow{#1}_{2}}


 \newcommand{\wact}[1]{\stackrel{#1}{\Rightarrow}} \newcommand{\wactI}[1]{\stackrel{#1}{\Rightarrow_{1}}} \newcommand{\wactII}[1]{\stackrel{#1}{\Rightarrow_{2}}} 


\newcommand{\mact}[1]{\stackrel{#1}{\rightarrow_{m}}} \newcommand{\wmact}[1]{\stackrel{#1}{\Rightarrow_{m}}} 

\newcommand{\lwact}[1]{\stackrel{#1}{\Leftarrow}} 
 
 
 
\newcommand{\eval}{\Downarrow} 
\newcommand{\Eval}[1]{\Downarrow^{#1}} 
 
 


\newcommand{\hatt}[1]{#1^{+}} 
\newcommand{\Of}{\mathbin{\w{of}}} 
 
\newcommand{\susp}{\downarrow} 
\newcommand{\lsusp}{\Downarrow_L} 
\newcommand{\wsusp}{\Downarrow} 
\newcommand{\commits}{\searrow} 
 
 
\newcommand{\spi}{S\pi} 
 

 \newcommand{\pres}[2]{#1\triangleright #2} \newcommand{\present}[3]{{\sf present} \ #1 \ {\sf do } \ #2 \ {\sf  else} \ #3}


\newcommand{\tick}{{\sf tick}}          

 
 
\newcommand{\sbis}{\equiv_L} 
\newcommand{\emit}[2]{\ol{#1}#2}  
\newcommand{\match}[4]{[#1=#2]#3,#4}       

\newcommand{\matchv}[4]{[#1 \unrhd #2]#3,#4}

\newcommand{\new}[2]{\nu #1 \ #2} 
\newcommand{\outact}[3]{\new{{\bf #1}}{\emit{#2}{#3}}} 
\newcommand{\real}{\makebox[5mm]{\,}}

\newcommand{\regterm}[2]{{\sf reg}_{#1} #2}
\newcommand{\thread}[1]{{\sf thread} \ #1}
\newcommand{\store}[2]{(#1 \leftarrow #2)}
\newcommand{\pstore}[2]{(#1 \Leftarrow #2)}

\newcommand{\regtype}[2]{{\sf Reg}_{#1} #2}
\newcommand{\uregtype}[3]{{\sf Reg}_{#1}(#2, #3)}
\newcommand{\urtype}[2]{{\sf Reg}(#1, #2)}

\newcommand{\upair}[2]{[#1,#2]}
\newcommand{\letb}[3]{\mathsf{let}\;\oc #1 = #2\;\mathsf{in}\;#3}

\newcommand{\vlt}[1]{{\cal V}(#1)}
\newcommand{\prs}[1]{{\cal P}(#1)}

\newcommand{\imp}{{\sf Imp}}            \newcommand{\vm}{{\sf Vm}}              \newcommand{\mips}{{\sf Mips}}          \newcommand{\Clight}{{\sf Clight}}        \newcommand{\Cminor}{{\sf Cminor}}
\newcommand{\RTLAbs}{{\sf RTLAbs}}
\newcommand{\RTL}{{\sf RTL}}
\newcommand{\ERTL}{{\sf ERTL}}
\newcommand{\LTL}{{\sf LTL}}
\newcommand{\LIN}{{\sf LIN}}
\newcommand{\access}[1]{\stackrel{#1}{\leadsto}}
\newcommand{\ocaml}{{\sf ocaml}}
\newcommand{\coq}{{\sf Coq}}
\newcommand{\compcert}{{\sf CompCert}}
\newcommand{\cil}{{\sf CIL}}
\newcommand{\scade}{{\sf Scade}}
\newcommand{\absint}{{\sf AbsInt}}
\newcommand{\framac}{{\sf Frama-C}}
\newcommand{\powerpc}{{\sf PowerPc}}
\newcommand{\lustre}{{\sf Lustre}}
\newcommand{\esterel}{{\sf Esterel}}
\newcommand{\ml}{{\sf ML}}

\newcommand{\codeex}[1]{\texttt{#1}}   

\newcommand{\spanr}[2]{\multicolumn{1}{Rn}{\multirow{#1}{*}{(#2)}}}
\def\nocol{\multicolumn{1}{ncn}{}}

\newcommand{\tern}[3]{#1\mathrel ? #2 : #3}
\newcommand{\sop}[1]{\s{#1}\ }
\newcommand{\sbin}[1]{\ \s{#1}\ }
\newcommand{\Ell}{\mathcal L}
\newcommand{\alphab}{A}
\newcommand{\betab}{B}
\newcommand{\gramm}{\mathrel{::=}}
\newcommand{\ass}{\mathrel{:=}}
\newcommand{\setof}[1]{\{\,#1\,\}}
\renewcommand{\to}[1][]{\stackrel{#1}{\rightarrow}}

\newcommand{\eg}{\emph{e.g.\ }}
\newcommand{\ie}{\emph{i.e.\ }}

\newcommand{\inde}{\hspace{20pt}}


\usetikzlibrary{decorations.pathreplacing}
\usetikzlibrary{calc}
\usetikzlibrary{positioning}
\newcommand{\tikztarget}[2]{\tikz[remember picture, baseline={(#1.base)}]{
  \node (#1) [inner sep = 0pt]{#2};}}
\newcommand{\tikztargetm}[2]{\tikz[remember picture, baseline={(#1.base)}]{
  \node (#1) [inner sep = 0pt]{};}}
\def\lbl#1:{\mbox{\color{blue}}:}
\def\Lbl#1<#2>:{\mbox{\color{blue}}:}

\tikzset{
    every picture/.style={
        baseline={([yshift=-.5ex]current bounding box)},
        remember picture,
    },
    lstnode/.style={inner ysep=-4pt,inner xsep=3pt,outer sep=3pt,draw,rounded corners=5pt},
}
\lstset{basicstyle=\footnotesize}
\lstnewenvironment{lstnode}[3][]
{
 \node[lstnode,#1] (#2)
 \bgroup
 \minipage{#3}
}
{\endminipage\egroup;}

\let\oldparagraph\paragraph
\makeatletter
\def\paragraph{\@ifnextchar*\new@paragraph@star\new@paragraph}
\def\new@paragraph@star*#1{\oldparagraph*{#1.}}
\def\new@paragraph#1{\oldparagraph{#1.}}
\makeatother


 
\title{Indexed Labels for Loop Iteration Dependent Costs}
\def\titlerunning{Indexed Labels for Loop Iteration Dependent Costs}
\author{Paolo Tranquilli\footnote{This work is funded by the CerCo FET-Open EU Project.}\institute{DISI (Dipartimento di Informatica -- Scienza e Ingegneria)\\Universit\`a di Bologna Alma Mater}\email{tranquil@cs.unibo.it}}
\def\authorrunning{Paolo Tranquilli}

 
\begin{document}

\maketitle

\begin{abstract}
We present an extension to the labelling approach, a technique for lifting
resource consumption information from compiled to source code. This approach,
which is at the core of the annotating compiler from a large fragment of C to
8051 assembly of the CerCo project, loses preciseness when differences arise
as to the cost of the same portion of code, whether due to code transformation
such as loop optimisations or advanced architecture features (\eg cache). We
propose to address this weakness by formally indexing cost labels with the
iterations of the containing loops they occur in. These indexes can be
transformed during the compilation, and when lifted back to source code they
produce dependent costs.

The proposed changes have been implemented in CerCo's untrusted prototype
compiler from a large fragment of C to 8051 assembly.
\end{abstract}
\listoftodos

\section{Introduction}
\label{sec:intro}
Recent years have seen impressive advancements in the field of formal description
and certification of software components. In the fields of compilers a well-documented
example is CompCert, a project which has spawned the proof of correctness of a
compiler from a large fragment of C to assembly~\cite{CompCert}. The success
of this endeavour is also supported by a comparison with other compilers as
to the number of bugs found with testing tools~\cite{findingbugs}.

The CerCo project~\cite{cerco} strives to add a significant aspect to the
picture: certified resource consumption. More precisely our aim is to build
a certified C compiler targeting embedded systems that produces, apart
from object code functionally equivalent to the input, an \emph{annotation} of the
source code which is a sound and precise
description of the execution cost of the compiled code. Time and stack are the
immediate resources on which the method can be applied.

The current state of the art in commercial products that analyse
reaction time or memory usage of programs installed in embedded systems
(\eg Scade~\cite{scade} or AbsInt~\cite{absint}) is that the estimate is based
upon an abstract interpretation of the object code that may require explicit and
untrusted annotations of the binaries stating how many times loops are iterated
(see \eg \cite{WCETsurvey}). Our aim, on the other hand, is to lift cost information
of small fragments of object code, so that these bits of
information may be compositionally combined at the source level,
abstracting away the specifics of the architecture and only having to reason
about standard C semantics the programmer will be familiar with. This
information can be used to decide complexity
assertions either with pencil and paper or
with a tool for automated and formal reasoning about C programs such as
Frama-C~\cite{framac}.

The theoretical basis of the CerCo compiler has been outlined by Amadio \emph{et al}~\cite{labeling},
where in particular the labelling approach is described.
Summarising, the proposal consists in `decorating' the source code by inserting
labels at key points.
These labels are preserved as compilation progresses, from one intermediate language to another.
Once the final object code is produced, such labels should correspond to the parts of the compiled code that have a constant cost. This cost can then be assigned to blocks of source code.

Two properties must hold of any cost estimate given to blocks of code.
The first property, paramount to the correctness of the method, is \emph{soundness}---the actual execution cost must be bounded by the estimate.
In the labelling approach, this is guaranteed if every loop in the control flow of the compiled code passes through at least one cost label. Were it not the case, the cost of the loop would be taken in charge by a label external to it, so that any constant cost assignment
would be invalidated by enough iterations of the loop.
The second property, optional but desirable, is \emph{preciseness}---the estimate
\emph{is} the actual cost. This is of particular importance for embedded real-time
systems, where in particular situations we may care that a code runs for \emph{at least}
some clock cycles.
In the labelling approach, this is true if, for every label, every possible execution of the compiled code starting from such a label yields the same cost before hitting another one.
In simple architectures such as the 8051 micro-controller which is targeted by the
current stage of the CerCo project, this can be guaranteed by placing labels at the
start of any branch in the control flow, and by ensuring that no labels are duplicated.

The reader should note that the above mentioned requirements state properties
that must hold for the code obtained \emph{at the end} of the compilation chain.
Even if one is careful about injecting the labels at suitable places in the source
code, the requirements might still fail because of two main obstacles.
\begin{itemize}
\item
The compilation process might introduce important changes in the control flow, inserting loops or branches.
This might happen for example when replacing operations that are unavailable in the target architecture, such as
generic shift and multi-byte division in the 8051 architecture\footnote{The reader might see the work outlined in \cite{D2.2} to get a grasp of how we tackle this problem in CerCo's compiler.}.
\item
Even when the compiled code \emph{does}---as far as the the syntactic control flow graph is concerned---respect the conditions for soundness and preciseness, the cost of blocks of instructions might not be
independent of context and thus not compositional, so that different passes through a label might have different costs.
This becomes a concern if one wishes to apply the approach to more complex architectures, for example one with caching or pipelining.
\end{itemize}
Even if we solved the problem outlined in the first point for our current compilation chain, the point remains
a weakness of the current labelling approach when it comes to some common code transformations.
In particular, most \emph{loop optimisations} change the control flow graph duplicating code and adding or changing the branches.
An example optimisation of this kind is \emph{loop peeling}, where a first iteration of the loop is hoisted out of and before its body.
This optimisation is employed by compilers in order to trigger other optimisations, such as dead code elimination or invariant code motion.
Here, the hoisted iteration might possibly be assigned a different cost than later iterations.

The second point above highlights another weakness. Different tools allow to predict up to a certain extent the behaviour of cache.
For example, the \s{aiT} tool~\cite{absint} allows the user to estimate the worst-case execution time taking into account advanced features of the target architecture. While
such a tool is not fit for a compositional approach which is central to CerCo's project\footnote{\s{aiT} assumes the cache is empty at the start of computation, and treats each procedure call separately, unrolling a great part of the control flow.},
\s{aiT}'s ability to produce tight estimates of execution costs would still enhance the effectiveness of the CerCo compiler, \eg{} by integrating such techniques in its development.
A typical case where cache analysis yields a difference in the execution cost of a block is in loops: the first iteration will usually stumble upon more cache misses than subsequent iterations.

If one looks closely, the source of the two weaknesses of the regular labelling approach of~\cite{labeling} outlined above is common: the inability to state different costs for different occurrences of labels in the execution trace. The difference in cost might be originated by labels being duplicated along the compilation, or by the costs being sensitive to the current state of execution.

The work we present here addresses this weakness by introducing cost labels that are dependent on which iteration of its containing loops it occurs in.
This is achieved by means of \emph{indexed labels}; all cost labels are decorated with formal indexes coming from the loops containing such labels.
These indexes allow us to rebuild, even after multiple loop transformations, which iterations of the original loops in the source code a particular label occurrence belongs to.
During the annotating stage, this information is presented to the user by means of \emph{dependent costs}.

Here we concentrate on integrating the labelling approach with two loop transformations---\emph{loop peeling} and \emph{loop unrolling}.
They will be presented for a toy language in \autoref{sec:defimp},
For general information on compiler optimisations (and loop optimisations in particular) we refer the reader to the vast literature on the subject (\eg\cite{muchnick,morgan}).

The proposed changes have been implemented in CerCo's untrusted prototype compiler
available on CerCo's homepage\footnote{\url{http://cerco.cs.unibo.it/}}. For
lack of space the present work will not delve into the details of the implementation.

Whilst we cover only two loop optimisations in this paper, we argue that the work presented herein poses a good foundation for extending the labelling approach, in order to cover more and more common optimisations, as well as gaining insight into how to integrate advanced cost estimation techniques, such as cache analysis, into the CerCo compiler.
Moreover loop peeling itself has the fortuitous property of enhancing and enabling other optimisations.
Experimentation with CerCo's untrusted prototype compiler, which implements constant propagation and partial redundancy elimination~\cite{PRE,muchnick}, show how loop peeling enhances those other optimisations.

\paragraph*{Outline}
We will present our approach on a minimal `toy' imperative language, \imp{} with \s{goto}s, which we present in \autoref{sec:defimp} along with formal definitions of the loop transformations.
This language already presents most of the difficulties encountered when dealing with C,
so we stick to it for the sake of this presentation.
In \autoref{sec:labelling} we summarize the labelling approach as presented in~\cite{labeling}.
\hyperref[sec:indexedlabels]{Section~\ref*{sec:indexedlabels}} presents \emph{indexed labels}, our proposal for dependent labels which are able to describe precise costs even in the presence of the various loop transformations we consider, together with a more detailed example
(\autoref{ssec:detailedex}).
Finally \autoref{sec:future} speculates on further work on the subject.

\section{The minimal imperative language \imp{}}\label{sec:defimp}
We briefly outline the toy language, the minimalist imperative language \imp{}.
Its syntax
is presented in~\autoref{fig:minimp}.
\begin{figure}

\caption{The syntax
of \imp.}
\label{fig:minimp}
\end{figure}
We may omit the \s{else} clause of a conditional if it leads to a \s{skip} statement.
The precise grammar for expressions is not particularly relevant so we do not give one in full.
We will use the notation
 for \imp's small-step semantics
of which we skip the unsurprising definition.
 is the statement being executed,
 is a continuation (\ie a stack of statements to be executed after )
and  is the store (\ie a map from variables to integers).


\paragraph*{Further down the compilation chain}
We abstract over the rest of the compilation chain.
We posit the existence, for every language  further down the compilation chain, of a suitable notion of `sequential instructions', wherein each instruction has a single natural successor. To these sequential instructions we can add our own.

\paragraph*{Loop transformations}
We present the loop transformations we deal with in \autoref{fig:loop_transformations}.
These transformations are local, \ie they target a single loop and transform it.
Which loops are targeted may be decided by some \emph{ad hoc} heuristic.
However, the precise details of which loops are targeted and how is not important here.
\begin{figure}
 \centering
\begin{tabular}{n*{5}{cn}}
\begin{tikzpicture}[lstnode]
\begin{lstnode}{peel2}{3.2cm}
if  then
    ;
    while  do 
\end{lstnode}
\end{tikzpicture}
&
\tikz[baseline={([yshift=-.5ex]n.mid)}]\node(n)[inner sep=0,rotate=180]{};
&
\begin{tikzpicture}[lstnode]
\begin{lstnode}{peel1}{2.3cm}
while  do 
\end{lstnode}
\end{tikzpicture}
&

&
\begin{tikzpicture}[lstnode]
\begin{lstnode}{lblunroll2}{3.2cm}
while  do
    ;
    if  then
        ;
        
        if  then
            
\end{lstnode}
\end{tikzpicture}
\end{tabular}
\caption{Loop peeling (left) and loop unrolling (right).}
\label{fig:loop_transformations}
\end{figure}

As already mentioned in the introduction, loop peeling consists in preceding the loop with a copy of its body, appropriately guarded.
This is usually done to trigger further optimisations.
Integrating this transformation into the labelling approach would also allow, in the future, the integration of a common case of cache analysis, as predicting cache hits and misses benefits from a form of \emph{virtual} loop peeling~\cite{cacheprediction}.

Loop unrolling consists of the repetition of several copies of the body of the loop inside the loop itself (inserting appropriate guards, or avoiding them altogether if enough information about the loop's guard is available at compile time).
This can limit the number of (conditional or unconditional) jumps executed by the code and trigger further optimisations dealing with pipelining, if appropriate for the architecture.
Notice that we present unrolling in a wilfully \emph{na\"{i}ve} version.
On the one hand usually
less general loops and more well-behaving loops are targeted; on the other hand,
conditionals are seldom used to cut up the body of the unrolled loop.
However we are mainly interested in the changes to the control flow the transformation
does. The problem this transformation poses to CerCo's labelling approach are
independent of the sophistication of the actual transformation.

We decided to apply transformations in the front-end in order to only target loops explicitly
written by the programmer. This is because we need to output source code annotations that are
meaningful to the user, and in order to do so we only transform loops that were explicitly
written as so.


\begin{example}
In \autoref{fig:example1} we show a program (a wilfully inefficient computation of the
sum of the first  factorials) and a possible combination of transformations
applied to it (again for the sake of presentation rather than efficiency).
\begin{figure}[!ht]
\begin{tikzpicture}
\begin{lstnode}{code1}{3.21cm}
;
;
while  do
    ;
    ;
    while  do
        ;
        ;
    ;
    ;
\end{lstnode}
\begin{lstnode}[right=1em of code1]{code2}{6cm}
;
;
if  then
    ;
    ;
    while  do
        ;
        ;
    ;
    ;
    while  do
        ;
        ;
        if  then
            ;
            ;
            if  then
                ;
                ;
                while  do
                    ;
                    ;
                    if  then
                        ;
        ;
        ;
        if  then
            ;
            ;
            while  do
                ;
                ;
                if  do
                    ;
                    ;
            ;
            ;
\end{lstnode}
\draw [thick,|->] (code1) -- (code2);
\coordinate (a) at ([shift={(8pt,-5pt)}]code2.north west);
\coordinate (b) at ([shift={(8pt,7.5pt)}]code2.south west);
\foreach \x/\y/\s/\t in 
    {19.625/24.75/0/unrolled,13.325/24.75/1/peeled,29.875/36/0/unrolled,
     10.25/38/2/unrolled,2/38/3/peeled} {
     \foreach \a/\b in {\x/a,\y/b}
        \draw [ultra thin, gray, densely dashed]
            () coordinate (tmp_\b) --
            (tmp_\b-|code2.east) -- ++() coordinate (tmp_\b);
     \draw[solid,thick,decorate, decoration={brace, amplitude = 7.5pt}]
         (tmp_a) -- node[sloped, anchor = base, yshift = 9pt]{\t} (tmp_b);
}
\end{tikzpicture}
\caption{An example of loop transformations. Blocks are delimited by indentation.}
\label{fig:example1}
\end{figure}
\end{example}

\section{Labelling: a quick sketch of the previous approach}
\label{sec:labelling}
Plainly labelled \imp{} is obtained by adding to the code \emph{cost labels}
(with metavariables ), and cost-labelled statements:

Cost labels allow us to track some program points along the compilation chain.
For further details we refer to~\cite{labeling}.

The small step semantics turns into a labelled transition system
and a natural notion of trace (\ie lists of labels) arises. The small-step rules
of \imp{} remain as unlabelled steps, while adding the rule

Cost labels are thus emitted by cost-labelled statements only\footnote{In the general case,
because of the conditional ternary operator, any evaluation of expressions can emit cost labels too.}.
We then write  for the transitive closure of the small step semantics which produces by concatenation the trace .

\paragraph*{Labelling}
Given an \imp{} program  its \emph{labelling}
in \imp{} is defined by ,
putting cost labels after every branching statement, at the start of both branches, and a cost label at the beginning of the program.
The relevant recursive cases for the definition of  are

where  are fresh cost labels.
In all other cases the definition just passes to substatements. Notice that
labelling enjoys soundness (a label is added inside each loop) and preciseness
(there is a label at all branches, included the loop-exiting one).

\paragraph*{Labels in the rest of the compilation chain}
All languages further down the chain get a new sequential statement  whose effect is to be consumed in a labelled transition while keeping the same state.
All other instructions guard their operational semantics and do not emit cost labels.

Preservation of semantics throughout the compilation process is restated, in rough terms, as:

Here  is a program of a language along the compilation chain, starting and halting states depend on the language, and  is any of the compilation passes\footnote{The case of divergent computations needs to be addressed too.
Also, the requirement can be weakened by demanding a weaker form of equivalence of the traces than equality.
Both of these issues are beyond the scope of this presentation.}. This must in
particular be true for any optimisation pass the compilation undergoes.

\paragraph*{Instrumentations}
Let  be the whole compilation from  to the labelled version of some low-level language .
Supposing such compilation has not introduced any new loop or branching, we have that:
\begin{itemize}
\item
every loop contains at least a cost label;
\item
every branching has different labels for the two branches.
\end{itemize}
With these two conditions, we have that each and every cost label in  for any  corresponds to a block of sequential instructions, to which we can assign a constant \emph{cost}\footnote{This in fact requires the machine architecture to be `simple enough', or for some form of execution analysis to take place.}.
As we have explained in the \hyperref[sec:intro]{introduction}, the two
properties above ensure \emph{soundness} and \emph{preciseness} of this
cost estimate respectively.
We therefore may assume the existence of a \emph{cost mapping}  from cost labels to natural numbers, assigning to each cost label  the cost of the block containing the single occurrence of .

Given any cost mapping , we can enrich a labelled program so that a particular fresh variable (the \emph{cost variable} ) keeps track of the summation of costs during the execution.
We call this procedure \emph{instrumentation} of the program, and it is defined recursively by:

In all other cases the definition passes to substatements. One can then reason
on the instrumented version of the code like he would on any program, asserting
statements about complexity by inspecting .

\paragraph*{The problem with loop optimisations}
Let us take loop peeling, and apply it to the labelling of a program without any prior adjustment:

What happens is that the cost label  is duplicated with two distinct occurrences.
If these two occurrences correspond to different costs in the compiled code, the best the cost mapping can do is to take the maximum of the two, preserving soundness (\ie the cost estimate still bounds the actual one) but losing preciseness (\ie the actual cost could be strictly less than its estimate).

\section{Indexed labels}
\label{sec:indexedlabels}
This section presents the core of the new approach.
In brief points it amounts to the following:
\edef\ssec{ssec}
\label{ssec7}\begin{enumerate}[\bfseries\expandafter\ref\expandafter{\expandafter \ssec\arabic{enumi}}.]
\item
Enrich cost labels with formal indexes stating, for each loop containing the label
in the source code, what iteration it occurs in.
\item
Each time a loop transformation is applied and a cost labels is split in different occurrences, each of these will be reindexed so that every time they are emitted their position in the original loop will be reconstructed.
\item
Along the compilation chain, alongside the \s{emit} instruction we add other instructions updating the indexes, so that iterations of the original loops can be rebuilt at the operational semantics level
even when the original structure of loops is lost.
\item
The machinery computing the cost mapping will still work, but assigning costs to indexed cost labels, rather than to cost labels as we wish.
However, \emph{dependent costs} can be calculated, where dependency is on which iteration of the containing loops we are in.
\end{enumerate}

\subsection{Indexing the cost labels}
\label{ssec:indlabs}
\label{ssec1}

\paragraph*{Formal indexes and }
Let  be a sequence of distinguished fresh identifiers that will be used as loop indexes.
A \emph{simple expression} is an affine arithmetical expression in one of these indexes, that is  with .
\label{pag:exprcomp}Simple expressions  and  in the same index can be composed---substituting  in the  of  we have , and this operation has an identity element  (which we will denote simply by ).
Constants can be expressed as simple expressions, so that we identify a natural  with .

An \emph{indexing} (with metavariables , , \ldots) is a list of transformations of successive formal indexes dictated by simple expressions, that is a mapping\footnote{Here we restrict each mapping to be one from an index to a
    simple expression \emph{on the same index}. This might not be the case if more loop
    optimisations are accounted for (for example, interchanging two nested
    loops could give rise to an indexing like ).}


An \emph{indexed cost label} (metavariables , , \ldots) is the combination of a cost label  and an indexing , written .
The cost label underlying an indexed one is called its \emph{atom}.

\imp{} with indexed labels (from now on ) is defined by
having loops with a formal index attached to them and by allowing statements to
be labelled by indexed labels:

Notice that unindexed loops may still exist in the language: though it does not
concern this simple toy example, they would correspond to multi-entry loops which
are ignored by indexing and optimisations in a scenario with gotos.

We will discuss \imp{}'s semantics later, in \autoref{ssec:inlabsem}.

\paragraph*{Indexed labelling}
In order to compute the \emph{indexed labelling}  of a program, we
need to keep track of the nesting of indexed loops as we visit the program
abstract syntax tree.

Let  be the indexing of length  made from identity simple expressions,
\ie the sequence .
We define the tiered indexed labelling  by recursion setting:

Here, as usual,  and  are fresh cost labels, and other cases just keep making the recursive calls on the substatements.
The \emph{indexed labelling} of a program  is then defined as , \ie a further fresh unindexed cost label is added at the start, and we start from level .

In plainer words: each loop is indexed by  where  is the number of other loops containing this one, and all cost labels under the scope of a loop indexed by  are indexed by all indexes , without any transformation.

\subsection{Indexed labels and loop transformations}\label{ssec2}
We define the \emph{reindexing}  as an operator on indexed labels by setting\footnote{If mappings are not restricted to only depend on the index being mapped,
    reindexing should be substituted in each occurrence of .}:

We extend this definition to statements in 
by applying the above transformation to all indexed labels contained in a statement.

We can now finally redefine loop peeling and loop unrolling, taking into account indexed labels.
The attentive reader will notice that no assumptions will be made as to the
labelling of the statements that are involved.
This ensures that the transformation can be repeated and composed at will.
Also, notice that after erasing all labelling information (\ie indexed cost labels and loop indexes) we recover exactly the same transformations presented in~\autoref{sec:defimp}. The transformations
are presented in \autoref{fig:indexed_loop_transformations}.

\begin{figure}
\centering
\begin{tabular}{l@{}l}
\begin{tikzpicture}[lstnode]
\begin{lstnode}{lblpeel1}{2.9cm}
 while  do 
\end{lstnode}
\end{tikzpicture}
&
\begin{tikzpicture}[lstnode]
\begin{lstnode}[right=1em of lblpeel1]{lblpeel2}{8.5cm}
if  then ;  while  do 
\end{lstnode}
\end{tikzpicture}
\
\alphab|_{i_0\mapsto c_0,\ldots, i_{k-1}\mapsto c_{k-1}} \ass \alphab\circ(i_0\mapsto c_0)\circ\cdots\circ(i_{k-1}\mapsto c_{k-1})
\begin{aligned}
   (\lbl\alphab : S,K,s,C) &\to[\alphab|_C] (S,K,s,C)\\
   (\lbl{i_k}:\sop{while}b\sbin{do}S,K,C) &\to
    \begin{cases}
     (S,\lbl{i_k}:\sop{while}b\sbin{do}S\sbin{then} K,s,C[i_k{\downarrow}0])
     &\text{if ,}\\
     (\s{skip}, K, s, C) &\text{otherwise,}
    \end{cases}\\
   (\s{skip}, \lbl{i_k}:\sop{while}b\sbin{do}S\sbin{then}K,C) &\to
    \begin{cases}
     (S,\lbl{i_k}:\sop{while}b\sbin{do}S\sbin{then} K,s,C[i_k{\uparrow}])
      & \text{if ,}\\
     (\s{skip}, K, s, C) & \text{otherwise.}
    \end{cases}
  \end{aligned} p \gramm  {i_k=n} | {i_k\ge n} | {i_k\bmod a = b\wedge i_k\ge n} 
\begin{gathered}
p(0*i_k+b)\ass ({i_k = b})
\qquad\qquad
p(1*i_k+b)\ass ({i_k \ge b})\\
p(a*i_k+b)\ass ({i_k\bmod a = b' \wedge i_k \ge b)}\quad\text{if , where }.
\end{gathered}
\mathbb S\ass \setof{S \mid S\subseteq \setof{i_h\mapsto e_h,\dots,i_k\mapsto e_k}
\text{for some  and 's}},
\kappa^\alpha_L(\emptyset) \ass 0\qquad
\kappa^\alpha_L(\{\varepsilon\}) \ass \kappa(\alpha\la L\ra) \qquad
\kappa^\alpha_L((i_h\mapsto e)S'+S'') \ass \tern{p(e)}{\kappa^\alpha_{L(i_k\mapsto e)}(S')}{\kappa^\alpha_L(S'')}

\label{eq:dependentcost}
\kappa(\alpha)\ass\kappa^\alpha_\varepsilon(\{\,L\mid \alpha\la L\ra \text{ appears in the compiled code}\,\})

\begin{aligned}
\mathcal I^\iota(\lbl{\alpha\la Id_k\ra}:S) &= c\ass c + \kappa(\alpha);\mathcal I^\iota(S)\\
\mathcal I^\iota(\lbl i_k : \sop{while}b\sbin{do}S) &=
  i_k \ass 0; \sop{while}b\sbin{do}(\mathcal I^\iota (S); i_k \ass i_k + 1)
\end{aligned}
\alpha\la\ra\,\beta\la 0 \ra\, \delta\la 0\ra\,\beta\la 1\ra\,\gamma\la 1,0\ra\,
\delta\la 1\ra\,\beta\la 2\ra\,\gamma\la 2,0\ra\,\gamma\la 2, 1\ra\,\delta\la 2\ra\,
\epsilon\la\ra\forall C\text{ constant indexing}.\forall \alpha\la I\ra\text{ appearing in the compiled code}.
  \kappa(\alpha)|_{I_C} = \kappa(\alpha\la I \ra).
i_0\mapsto n - i_0\quad\text{or}\quad i_0\mapsto i_1, i_1\mapsto i_0.
In particular dependency over actual variables of the code would enter the frame, as indexings would depend on the number of iterations of a well-behaving guarded loop (the  in the first example).

Finally, as stated in the introduction, the approach should allow some integration of techniques for cache analysis, a possibility that for now has been put aside as the standard 8051 target architecture for the CerCo project lacks a cache.
Two possible developments for this line of work present themselves:
\begin{enumerate}
\item
One could extend the development to some 8051 variants, of which some have been produced with a cache.
\item
One could make the compiler implement its own cache: this cannot apply to \textsc{ram} accesses of the standard 8051 architecture, as the difference in cost of accessing the two types of \textsc{ram} is only one clock cycle, which makes any implementation of cache counterproductive.
So for this proposal, we could either artificially change the accessing cost of \textsc{ram} of the model just for the sake of possible future adaptations to other architectures, or otherwise model access to an external memory by means of the serial port of the microcontroller.
\end{enumerate}


\bibliographystyle{eptcs}
\bibliography{inc/bib}


\end{document}
