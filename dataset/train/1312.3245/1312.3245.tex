Mobile device owners, enterprise IT administrators, and vendors of
anti-malware tools would all benefit from techniques that can provide
early warnings about the susceptibility to malware infection. In this
section, we report on the in-depth analyses of our data and look at factors
that have a strong influence on the risk of malware infection.


\ifwww
\subsection{Energy and Number of Applications}
We first considered two factors: the extent of energy consumption on the
device, and the number of applications installed on a device.
Our dataset exhibits the patterns one might expect: the average
battery life of infected devices was less than that of clean devices
and the average number of installed applications on infected devices
was larger than that in clean devices.  However, the differences were
not always significant.  

To examine the relationship between infection and energy consumption,
we analyzed the mean battery life between infected devices and the
subset of clean devices that match the models and OS versions of
infected devices.  The mean battery life after outlier removal for the
infected devices was  hours (median ), and  hours
for the clean devices (median ) for Mobile Sandbox. A Wilcoxon
rank sum test indicated statistical significance in the lifetime
distributions (Z = -4.2215, p < 0.01).  For McAfee, the mean battery
life was  hours for infected (median ) and  hours
for clean (median ). The difference was marginally significant (Z
= -1.199, p = 0.23).

The average number of applications observed on the infected devices
(, median  for Mobile Sandbox / , median  for McAfee)
was higher than the average number of applications on the clean
devices , median  for Mobile Sandbox / , median  for
McAfee) during our observation period. This would match with the
intuition that every newly installed application is an opportunity for
infection and that users who install and run more applications would
therefore be more likely to become infected. To assess this hypothesis
more rigorously, we used the Wilcoxon rank sum test to compare the
number of installed packages between infected and clean devices. The
difference was statistically significant for McAfee (Z = -3.086946, p
< 0.01) and marginally significant for Mobile Sandbox (Z = -1.287166,
p = 0.1980). More details of these analyses are found in the full
version of this paper~\cite{TruongMobileMalware2013}.



\else
\subsection{Energy Consumption}
\label{subsec:predictions:energy}
\begin{table}[!htb]
\centering
\small{
\begin{tabular}{|l|c c|c c|}
\hline
& \multicolumn{2}{c|}{\textbf{Mobile Sandbox}} & \multicolumn{2}{c|}{\textbf{McAfee}} \\
\hline
\textit{Statistic} & \textit{Infected} & \textit{Clean} & \textit{Infected} & \textit{Clean} \\
\hline
\multicolumn{5}{c}{\textbf{All Models and OS Versions}} \\
\hline
Mean & 7.28 & 9.84 & 	 8.37 & 9.84 \\ 
Median & 6.39 & 8.14 & 	 8.08 & 8.13 \\ 
Difference (\%) & \multicolumn{2}{c|}{26} & \multicolumn{2}{c|}{14.9} \\ 
Wilcoxon & \multicolumn{2}{c|}{p < 0.01, Z=-5.26} & 	 \multicolumn{2}{c|}{p=0.177, Z=-1.35} \\ 
Pearson corr & \multicolumn{4}{c|}{-0.0471}\\ 
\hline
\multicolumn{5}{c}{With 95th percentile high outlier removal} \\ 
\hline
Mean & 6.56 & 8.36 & 	 7.88 & 8.35 \\ 
Median & 6.06 & 7.94 & 	 7.74 & 7.94 \\ 
Difference (\%)  & \multicolumn{2}{c|}{21.5} & 	 \multicolumn{2}{c|}{5.63} \\ 
Wilcoxon & \multicolumn{2}{c|}{p < 0.01, Z=-5.68} & 	 \multicolumn{2}{c|}{p=0.152, Z=-1.43} \\ 
Pearson corr & \multicolumn{2}{c|}{0.0202}& 	 \multicolumn{2}{c|}{0.0202}\\ 
\hline
\multicolumn{5}{c}{\textbf{Matching Models and OS Versions}} \\
\hline
Mean & 7.28 & 9.03 & 	 8.37 & 9.52 \\ 
Median & 6.39 & 7.68 & 	 8.08 & 8.08 \\ 
Difference (\%)  & \multicolumn{2}{c|}{19.3} & 	 \multicolumn{2}{c|}{12.1} \\ 
Wilcoxon & \multicolumn{2}{c|}{p= < 0.01, Z=-3.89} & 	 \multicolumn{2}{c|}{p=0.261, Z=-1.12} \\ 
Pearson corr & \multicolumn{2}{c|}{-0.0481}& 	 \multicolumn{2}{c|}{-0.0477}\\ 
\hline
\multicolumn{5}{c}{With 95th percentile high outlier removal} \\ 
\hline
Mean & 6.56 & 7.88 & 	 7.88 & 8.27 \\ 
Median & 6.06 & 7.5 & 	 7.74 & 7.9 \\ 
Difference (\%)  & \multicolumn{2}{c|}{16.8} & 	 \multicolumn{2}{c|}{4.67} \\ 
Wilcoxon & \multicolumn{2}{c|}{p < 0.01, Z=-4.22} & 	 \multicolumn{2}{c|}{p=0.23, Z=-1.2} \\ 
Pearson corr & \multicolumn{2}{c|}{-0.0401}& 	 \multicolumn{2}{c|}{-0.0161}\\
\hline
\end{tabular}
}
\caption{Statistics on battery life.\label{tbl:battresults}}
\end{table}
\caratapp{} provides accurate estimates of the average battery life of
a device as long as a sufficient number of samples submitted
by the device is available. We use these estimates to compare
differences in battery life between infected and clean (uninfected)
devices. There was sufficient data for \caratapp{} battery life estimates on  infected devices (out of )
for Mobile Sandbox, and  infected devices (out of ) for McAfee. To ensure
software and hardware variations did not cause bias in the analysis,
only those clean devices that have the same model and OS version as at
least one of the infected devices were included in the analysis,
resulting in a sample of  clean devices for Mobile Sandbox and 
for McAfee.

We removed outliers beyond the 95th percentile of battery life.
481 outliers were removed from 
clean and 6 from infected data for Mobile Sandbox. For McAfee,
we removed 638 from clean and 6 from infected battery life data.


The mean battery life after outlier removal for the infected devices
was  hours (median ), and  hours for the clean devices
(median ) for Mobile Sandbox. A Wilcoxon rank sum test indicated
statistical significance in the lifetime distributions (Z = -4.2215, p
< 0.01).

For McAfee, the mean battery life was  hours for infected (median
) and  hours for clean (median ). The difference was
marginally significant (Z = -1.199, p = 0.23).

Without outlier removal, and without limiting the OS and device model
of clean devices, the same relationship holds; the difference in battery
life between infected and clean is significant for Mobile Sandbox and
marginally significant for McAfee (see Table~\ref{tbl:battresults} for
details).









The reduced lifetime for the infected devices could be caused by a
difference in the number of applications that are used on the
devices. To demonstrate that this is not the case, we next investigate
the relationship between battery consumption and application
usage. Pearson's correlation coefficient between the two was 
for Mobile Sandbox and  for McAfee, suggesting they are
uncorrelated. A small positive value was observed for all models and
OSes with outlier removal, however, the magnitude indicates no
correlation.  Furthermore, there are examples of clean devices with
more than 200 apps and a higher than average battery life.  An
infected device with over 300 applications installed had 16 hours of
battery life, over 6 hours more than the mean for clean devices 
in all the cases. The number of applications does not
seem to correlate with high energy use.


This is also illustrated in Figure~\ref{fig:pkg-installed}, which
shows the average battery life for the two device groups.  The
detailed statistics are shown in Table~\ref{tbl:battresults}.




\begin{figure*}[!htb]
  \centering
  \begin{minipage}{0.42\textwidth}
    \centering
    \includegraphics[width=0.8\textwidth]{figures/mobsand_energy.pdf}
    \subcaption{Mobile Sandbox dataset}
    \label{fig:package-device-dc-package-MB}
  \end{minipage}  
\begin{minipage}{0.42\textwidth}
    \centering
    \includegraphics[width=0.8\textwidth]{figures/mcafee_energy.pdf}
    \subcaption{ McAfee dataset}
    \label{fig:package-device-dc-package-MC}
  \end{minipage}  
  \caption{Average battery life. \label{fig:energy}}
\end{figure*}






\begin{figure*}[!htb]
  \centering
  \begin{minipage}{0.42\textwidth}
    \centering
    \includegraphics[width=0.8\textwidth]{figures/mobsand_A_D.pdf}
    \subcaption{Mobile Sandbox dataset}
    \label{fig:package-device-dc-package-MB}
  \end{minipage}  
\begin{minipage}{0.42\textwidth}
    \centering
    \includegraphics[width=0.8\textwidth]{figures/mcafee_A_D.pdf}
    \subcaption{ McAfee dataset}
    \label{fig:package-device-dc-package-MC}
  \end{minipage}  
  \caption{Distribution of number of installed packages. \label{fig:pkg-installed}}
\end{figure*}











\subsection{Number of Installed Packages}
\label{subsec:predictions:pkg-number}
\begin{table}
\centering
\small{
\begin{tabular}{|l|c c|c c|}
\hline
& \multicolumn{2}{c|}{\textbf{Mobile Sandbox}} & \multicolumn{2}{c|}{\textbf{McAfee}} \\
\hline
\textit{Statistic} & \textit{Infected} & \textit{Clean} & \textit{Infected} & \textit{Clean} \\
\hline
\multicolumn{5}{c}{\textbf{All Models and OS Versions}} \\
\hline
Mean & 111 & 78.3  & 	 136 & 78.3  \\ 
Median & 85.5 & 53 & 	 97.5 & 53 \\ 
Wilcoxon & \multicolumn{2}{c|}{p < 0.01, Z=-4.57} & 	 \multicolumn{2}{c|}{p < 0.01, Z=-6.33} \\ 
\hline
\multicolumn{5}{c}{With 95th percentile high outlier removal} \\ 
\hline
Mean & 93.6 & 65.9 & 	 115 & 65.8 \\ 
Median & 83 & 50 & 	 93 & 50 \\ 
Wilcoxon & \multicolumn{2}{c|}{p < 0.01, Z=-4.83} & 	 \multicolumn{2}{c|}{p < 0.01, Z=-6.65} \\ 
\hline
\multicolumn{5}{c}{\textbf{Matching Models and OS Versions}} \\
\hline
Mean & 111 & 101  & 	 136 & 105  \\ 
Median & 85.5 & 80 & 	 97.5 & 79 \\ 
Wilcoxon & \multicolumn{2}{c|}{p=0.206, Z=-1.27} & 	 \multicolumn{2}{c|}{p < 0.01, Z=-2.97} \\ 
\hline
\multicolumn{5}{c}{With 95th percentile high outlier removal} \\
\hline
Mean & 93.6 & 88.3 & 	 115 & 90.7 \\ 
Median & 83 & 73 & 	 93 & 72 \\ 
Wilcoxon & \multicolumn{2}{c|}{p=0.198, Z=-1.29} & 	 \multicolumn{2}{c|}{p < 0.01, Z=-3.09} \\ 
\hline
\end{tabular}
}
\caption{Statistics on applications installed.\label{tbl:appresults}}
\end{table}
We did similar outlier removal to applications as to battery life data.
We removed 484 outliers from clean and 6 from infected application data for Mobile Sandbox,
and 640 outliers from clean and 6 from infected application
data for McAfee.

The average number of applications observed on the infected devices
(, median  for Mobile Sandbox / , median  for McAfee) was higher than the average number of applications on the clean devices
, median  for Mobile Sandbox / , median  for McAfee) during our observation period. This would match with the
intuition that every newly installed application is an opportunity for
infection and that users who install and run more applications would therefore
be more likely to become infected. To assess this hypothesis more
rigorously, we used the Wilcoxon rank sum test to compare the number of installed
packages between infected and clean devices. The
difference was statistically significant for McAfee (Z = -3.086946, p < 0.01) and marginally significant for Mobile Sandbox (Z = -1.287166, p = 0.1980).
 
This is also illustrated in Figure~\ref{fig:pkg-installed}, which
shows the distributions of the number of installed packages for the
two device groups.  The detailed statistics are shown in
Table~\ref{tbl:appresults}.
\fi



\subsection{Applications Used on a Device}
\label{subsec:predictions:applications}




The density of malware in different application stores tends to vary
considerably, with some stores having a high malware incidence
rate~\cite{yajin_zhou_hey_2012}. The set of applications used on a
device can serve as a (weak) proxy for the application stores used by
the user of the device, thus potentially providing information about
the device's susceptibility to malware. Cross-application promotions
and on-device advertising are other factors that can affect
susceptibility to malware infections. As the next step of analysis, we
examined how much information about malware infection the applications
run on the device can provide.

We conduct our investigation by considering malware detection as a
classification task where the goal is to classify the device as
infected or clean using the set of applications used on the
device as the input feature. As discussed earlier, each anti-malware
vendor may have their own proprietary algorithm to classify
applications as malware or not.  Therefore, we report our detection
experiments separately for each malware dataset.

Analogously to, e.g., some spam filters, we rely on (Multinomial)
Na{\"i}ve Bayes classifiers in our experiments. Despite making a strong
independence assumption, Na{\"i}ve Bayes classifier is a powerful and
computationally efficient tool for analyzing sparse, large-scale
data. As the input features to the classifier we consider
bag-of-applications vectors, i.e., sparse binary vectors containing
value one for each application run on the device and the value zero
otherwise.  If a device contains an application that is present within
the list of known malware applications, we label the device as
infected. Otherwise, the device is labeled as clean.

As we are interested in looking at associations between malware and
other applications, and as anti-malware tools would easily detect
known malware applications, all applications known as malware were
removed from the data before carrying out the classification
experiments (they are used only to label devices). Since our data has
been collected over a period of multiple months, we also removed all
applications that corresponded to earlier (or newer) versions of one
of the malware applications (i.e., which have the same devcert and
package key, but different version code) to avoid any potential
temporal effects.

We start with a simple cross-validation experiment (detecting
infection by known malware) and then describe two variants of
detecting infection by new malware.  Finally we report
on a real-life scenario of detecting infection by previously
undetected malware.  In each experiment, the baseline for detection
is the success rate of finding an infected device by randomly
selecting a subset of supposedly clean devices.




\subsubsection{Cross-Validation}
\label{subsubsec:predictions:applications:cross}

We used stratified -fold cross-validation. Accordingly, the set of devices was
partitioned into five subsets, each having a similar class distribution as
the entire dataset. Four of the subsets were used to train the
classifier and the remaining subset was used for testing. This process
was repeated five times so that each subset served once as the test
set.  Classification results were aggregated over the five folds. The
results are shown in 
\ifwww
Table~\ref{tbl:infdetect} (lines 1-2).
\else
Tables~\ref{tbl:5cv_MB} and
\ref{tbl:5cv_MC}.
\fi

The results clearly indicate the difficulty in accurately distinguishing malware
infections solely on the basis of applications run
on the device. Only a small number of the actually infected devices were
correctly identified, however, the classification algorithm also made
relatively few false detections (approximately 1000 devices out of
over ).  The precision is significantly better than
baseline (1.37\% and 1.07\%), random chance (it is also comparable to
what some anti-virus tools provide for these
applications~\cite{zhou_dissecting_2012}). More importantly, considering
the relatively low level of false positives, the results indicate that
applications run on the device could potentially be used as one of the
features for detecting likelihood of malware infection.

\ifwww
\newcounter{magicrownumbers}
\newcommand\rownumber{\stepcounter{magicrownumbers}\arabic{magicrownumbers}}
\begin{table*}[!htb]
\centering
   {\small  
   \begin{minipage}{\linewidth}
   \begin{tabularx}{\linewidth}{| l|p{1cm}|p{1cm}|p{1.4cm}|p{1.4cm}|l|l|l|}
\toprule
      
      Experiments 
      & TP
      & FN
      & FP
      & TN
      & Precision 
      & Baseline
      & Gain\\
      \cmidrule{1-8}


\rownumber. (\ref{subsubsec:predictions:applications:cross}) Mobile Sandbox, Cross-validation  & 
      14 &
      140 & 
      1008 & 
      54116 &
      1.37\% &
      0.28\% &
      3.8 times \\

\rownumber. (\ref{subsubsec:predictions:applications:cross}) McAfee, Cross-validation  & 
      11 &
      133 & 
      1020 & 
      54114 &
      1.07\% &
      0.26\% &
      4.1 times \\

\rownumber. (\ref{subsubsec:predictions:applications:new}) Mobile Sandbox, new malware & 
      53 &
      687 & 
      5100 & 
      267450 &
      1.03\% &
      0.05\% &
      3.8 times \\

\rownumber. (\ref{subsubsec:predictions:applications:new}) McAfee, new malware & 
      40 &
      680 & 
      5146 & 
      267654 &
      0.77\% &
      0.26\% &
      2.9 times \\

\rownumber. (\ref{subsubsec:predictions:applications:undetected}) Mobile Sandbox, undetected malware & 
      5 &
      132 & 
      5098 & 
      270572 &
      0.10\% &
      0.05\% &
      2.0 times \\

\rownumber. (\ref{subsubsec:predictions:applications:undetected}) McAfee, undetected malware & 
      7 &
      120 & 
      5044 & 
      270721 &
      0.14\% &
      0.05\% &
      3.0 times \\

\rownumber. (\ref{subsubsec:predictions:applications:reallife}) Mobile Sandbox, real-life set &
      4 &
      71 & 
      609 & 
      54515 &
      0.65\% &
      0.14\% &
      4.8 times \\

\rownumber. (\ref{subsubsec:predictions:applications:reallife}) McAfee, real-life set &
      4 &
      112 & 
      407 & 
      54727 &
      0.97\% &
      0.21\% &
      4.6 times \\
     
      \bottomrule
    \end{tabularx}
    \end{minipage}
  }
  \caption{Detection of infection based on the set of applications
    used on a device. TP -- True Positive, FN -- False Negative, FP -- False Positive, TN -- True Negative.}
  \label{tbl:infdetect}
\end{table*}
\else
\begin{table*}[htbp]
    \centering   
    \begin{minipage}{0.35\textwidth}      
        \begin{tabular}{|c | c | c | c |}
          \hhline{~~|--|}
          \multicolumn{2}{c |}{} & \multicolumn{2}{ c |}{\cellcolor{mygray} Detected class} \\
          \hhline{~~|-|-|}
          \multicolumn{2}{c |}{} & \multicolumn{1}{ c |}{ \cellcolor{mygray} Infected } & \cellcolor{mygray} Clean \\
          \hline
          \cellcolor{mygray} Actual & \cellcolor{mygray} Infected &  14  & 140 \\
          \hhline{|>{\arrayrulecolor{mygray}}->{\arrayrulecolor{black}}|-|-|-|}
\cellcolor{mygray} class & \cellcolor{mygray} Clean   & 1,008 & 54,116 \\
          \hline
        \end{tabular}
        \subcaption{Mobile Sandbox, cross-validation, baseline 0.28\%,
          precision 1.37\%, 4.9X improvement. \label{tbl:5cv_MB}}     
    \end{minipage}
\begin{minipage}{0.45\textwidth}
      \begin{adjustwidth}{1.5cm}{}      
        \begin{tabular}{|c | c | c | c |}
          \hhline{~~|--|}
          \multicolumn{2}{c |}{} & \multicolumn{2}{ c |}{\cellcolor{mygray} Detected class} \\
          \hhline{~~|-|-|}
          \multicolumn{2}{c |}{} & \multicolumn{1}{ c |}{ \cellcolor{mygray} Infected } & \cellcolor{mygray} Clean \\
          \hline
          \cellcolor{mygray} Actual & \cellcolor{mygray} Infected &  11  & 133 \\
          \hhline{|>{\arrayrulecolor{mygray}}->{\arrayrulecolor{black}}|-|-|-|}
\cellcolor{mygray} class & \cellcolor{mygray} Clean   & 1,020 & 54,114 \\
          \hline
        \end{tabular}    
        \subcaption{McAfee, cross-validation, baseline 0.26\%, precision 1.07\%, 4.1X improvement.\label{tbl:5cv_MC}}      
      \end{adjustwidth}
        \end{minipage}



     \begin{minipage}{0.35\textwidth}      
        \begin{tabular}{|c | c | c | c |}
          \hhline{~~|--|}
          \multicolumn{2}{c |}{} & \multicolumn{2}{ c |}{\cellcolor{mygray} Detected class} \\
          \hhline{~~|-|-|}
          \multicolumn{2}{c |}{} & \multicolumn{1}{ c |}{ \cellcolor{mygray} Infected } & \cellcolor{mygray} Clean \\
          \hline
          \cellcolor{mygray} Actual & \cellcolor{mygray} Infected &  53  & 687 \\
          \hhline{|>{\arrayrulecolor{mygray}}->{\arrayrulecolor{black}}|-|-|-|}
\cellcolor{mygray} class & \cellcolor{mygray} Clean   & 5,100 & 267,450 \\
          \hline
        \end{tabular}
        \subcaption{Mobile Sandbox, new malware, baseline 0.27\%, precision 1.03\%, 3.8X improvement. \label{tbl:new_MB}} 
    \end{minipage}
\begin{minipage}{0.45\textwidth}
      \begin{adjustwidth}{1.5cm}{}      
        \begin{tabular}{|c | c | c | c |}
          \hhline{~~|--|}
          \multicolumn{2}{c |}{} & \multicolumn{2}{ c |}{\cellcolor{mygray} Detected class} \\
          \hhline{~~|-|-|}
          \multicolumn{2}{c |}{} & \multicolumn{1}{ c |}{ \cellcolor{mygray} Infected } & \cellcolor{mygray} Clean \\
          \hline
          \cellcolor{mygray} Actual & \cellcolor{mygray} Infected &  40  & 680 \\
          \hhline{|>{\arrayrulecolor{mygray}}->{\arrayrulecolor{black}}|-|-|-|}
\cellcolor{mygray} class & \cellcolor{mygray} Clean   & 5,146 & 267,654 \\
          \hline
        \end{tabular}    
        \subcaption{McAfee, new malware, baseline 0.26\%, precision 0.77\%, 2.9X improvement. \label{tbl:new_MC}}      
      \end{adjustwidth}
   \end{minipage}



   \begin{minipage}{0.35\textwidth}      
        \begin{tabular}{|c | c | c | c |}
          \hhline{~~|--|}
          \multicolumn{2}{c |}{} & \multicolumn{2}{ c |}{\cellcolor{mygray} Detected class} \\
          \hhline{~~|-|-|}
          \multicolumn{2}{c |}{} & \multicolumn{1}{ c |}{ \cellcolor{mygray} Infected } & \cellcolor{mygray} Clean \\
          \hline
          \cellcolor{mygray} Actual & \cellcolor{mygray} Infected &  5  & 132 \\
          \hhline{|>{\arrayrulecolor{mygray}}->{\arrayrulecolor{black}}|-|-|-|}
\cellcolor{mygray} class & \cellcolor{mygray} Clean   & 5,098 & 270,572 \\
          \hline
        \end{tabular}
        \subcaption{Mobile Sandbox, undetected malware, baseline 0.05\%, precision 0.10\%, 2.0X improvement. \label{tbl:undetected_MB}}
    \end{minipage}
\begin{minipage}{0.45\textwidth}
      \begin{adjustwidth}{1.5cm}{}      
        \begin{tabular}{|c | c | c | c |}
          \hhline{~~|--|}
          \multicolumn{2}{c |}{} & \multicolumn{2}{ c |}{\cellcolor{mygray} Detected class} \\
          \hhline{~~|-|-|}
          \multicolumn{2}{c |}{} & \multicolumn{1}{ c |}{ \cellcolor{mygray} Infected } & \cellcolor{mygray} Clean \\
          \hline
          \cellcolor{mygray} Actual & \cellcolor{mygray} Infected &  7  & 120 \\
          \hhline{|>{\arrayrulecolor{mygray}}->{\arrayrulecolor{black}}|-|-|-|}
\cellcolor{mygray} class & \cellcolor{mygray} Clean   & 5,044 & 270,721 \\
          \hline
        \end{tabular}    
        \subcaption{McAfee, undetected malware, baseline 0.05\%, precision 0.14\%, 3.0X improvement. \label{tbl:undetected_MC}}      
      \end{adjustwidth}
    \end{minipage}



   \begin{minipage}{0.35\textwidth}      
        \begin{tabular}{|c | c | c | c |}
          \hhline{~~|--|}
          \multicolumn{2}{c |}{} & \multicolumn{2}{ c |}{\cellcolor{mygray} Detected class} \\
          \hhline{~~|-|-|}
          \multicolumn{2}{c |}{} & \multicolumn{1}{ c |}{ \cellcolor{mygray} Infected } & \cellcolor{mygray} Clean \\
          \hline
          \cellcolor{mygray} Actual & \cellcolor{mygray} Infected &  4  & 71 \\
          \hhline{|>{\arrayrulecolor{mygray}}->{\arrayrulecolor{black}}|-|-|-|}
\cellcolor{mygray} class & \cellcolor{mygray} Clean   & 609 & 54,515 \\
          \hline
        \end{tabular}
        \subcaption{Mobile Sandbox, train with ``original'' set,
          detect infection wrt ``new'' set, baseline 0.14\%,
          precision 0.65\%, 4.8X improvement. \label{tbl:real_MB}}
    \end{minipage}
\begin{minipage}{0.45\textwidth}
      \begin{adjustwidth}{1.5cm}{}      
        \begin{tabular}{|c | c | c | c |}
          \hhline{~~|--|}
          \multicolumn{2}{c |}{} & \multicolumn{2}{ c |}{\cellcolor{mygray} Detected class} \\
          \hhline{~~|-|-|}
          \multicolumn{2}{c |}{} & \multicolumn{1}{ c |}{ \cellcolor{mygray} Infected } & \cellcolor{mygray} Clean \\
          \hline
          \cellcolor{mygray} Actual & \cellcolor{mygray} Infected &  4  & 112 \\
          \hhline{|>{\arrayrulecolor{mygray}}->{\arrayrulecolor{black}}|-|-|-|}
\cellcolor{mygray} class & \cellcolor{mygray} Clean   & 407 & 54,727 \\
          \hline
        \end{tabular}    
        \subcaption{McAfee, train with ``original'' set,
          detect infection w.r.t ``new'' set, baseline 0.21\%, precision 0.97\%, 4.6X improvement. \label{tbl:real_MC}}      
      \end{adjustwidth}
    \end{minipage}
\caption{Detection of infection based on the set of applications
      on a device.}    
\end{table*}
\fi


\subsubsection{Infection by New Malware}
\label{subsubsec:predictions:applications:new}

Next we evaluate the potential of using the set of applications used
on a device as an {\predictor}  for infection by \textit{new, previously
  unknown} malware.  To do this, we partitioned the set of clean devices
into a training set consisting of  and a test set consisting of
20\%, chosen randomly. We partitioned the malware five ways, according to the number of infected devices.
These
groups therefore correspond to roughly equal number of infected
devices. 

In each run (of a total of five runs), four groups were used as ``known
malware'' and the devices they infected were combined with the
training set ( clean devices).  The remaining group was used as
``unknown malware'' and its infected devices combined with the test
set ( clean devices).


No two devices infected by the same malware application appear in both
(training and test) sets in the same run to ensure that malware
applications for testing are truly unknown. In line with our other
experiment, we also removed all application features corresponding to
newer or older versions of a malware application. Lastly, to mitigate
the influence of random partitioning, we repeated the entire experiment
five times and report the summed results (the aggregation was done
over 25 runs). Results are reported in 
\ifwww
Table~\ref{tbl:infdetect} (lines 3-4).
\else
Tables~\ref{tbl:new_MB} and
\ref{tbl:new_MC}.
\fi

The classification results for detecting infection
by new malware are 3.8 (Mobile Sandbox) and 2.9 (McAfee) times better
than baseline.

In the experiment, all the devices that had an application from the
set of ``undetected malware'' were always assigned to the test set.
While this is reasonable for truly new, unknown malware, in reality,
it is possible that undetected malware was present on some devices in
the set of devices used to train the model (naturally those devices
would have been classified as ``clean'' at the time of training). We
next investigate the potential for detecting infection by previously
undetected malware.


\subsubsection{Infection by Previously Undetected Malware}
\label{subsubsec:predictions:applications:undetected}

Infection by previously undetected malware (including new as well as
old but previously undetected malware) may also be detectable using
the same classification approach.  To evaluate this possibility, we
ran a new experiment.
We partitioned the
set of \textit{all} devices randomly into two sets: a training set
containing 80\% of the devices and a test set containing the remaining
20\%.  Next, we partitioned the set of malware applications five ways
according to the number of infected devices. 
In each run, only the
malware applications from four malware sets (i.e., ``known malware''
sets) were used to label ``infected'' devices in the training set.
Any device in the training set that contains an application from the
remaining malware set (i.e., ``undetected malware'') was labeled as
``clean'' to reflect the fact that at the time of training such
devices were not known to be infected.  We moved any device in the
test set that is infected by ``known malware'' to the training set.
To minimize the effect of random partitioning, as before, we repeated
the entire experiment five times, with five runs in each round, and report
the summed results of 25 runs in 
\ifwww
Table~\ref{tbl:infdetect} (lines 5-6).
\else
Tables~\ref{tbl:undetected_MB}
and \ref{tbl:undetected_MC}.
\fi 
The results are 2 (Mobile Sandbox) and 3
(McAfee) times better than the baseline.


\subsubsection{Detection of `Real life'' Infections}
\label{subsubsec:predictions:applications:reallife}

So far, we simulated ``new'' or ``previously undetected'' malware by
dividing our malware datasets randomly.  For each of our malware
datasets we received a first version (the ``original'' set) in March
2013 and an updated version (the ``updated'' set) in subsequently (in
September 2013 for Mobile Sandbox and November 2013 for McAfee).  This
allowed us to validate our model for detection of infection by
previously undetected malware under ``real life'' conditions.  Let us
denote the difference between the updated set and the original set as
the ``new'' set.  We labeled the full set of devices using the
original malware set, trained our model using the resulting set and
used the set of all ``clean'' devices (with respect to the original
set) as the test set to detect infection. We compared the results
with respect to infections labeled by the ``new'' set.
The results are shown in 
\ifwww
Table~\ref{tbl:infdetect} (lines 7-8).
\else
Tables~\ref{tbl:real_MB} and
\ref{tbl:real_MC}.
\fi 
The detection performance is 4.8 (Mobile Sandbox)
and 4.6 (McAfee) times better than the baseline of random selection.
