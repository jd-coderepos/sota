\begin{figure*}
    \centering
    \includegraphics[width=0.95\textwidth]{Method.pdf}
    \vspace{-10pt}
    \caption{Overview of our 
method. 
At learning step  an image is processed by the old (top) and current (bottom) models, mapping the image to their respective output spaces. As in standard \icl\ methods, we apply a cross-entropy loss to learn new classes (blue block) and a distillation loss to preserve old knowledge (yellow block). In this framework, we model the semantic changes of the background 
 across different learning steps by (i) initializing the new classifier using the weights of the old background one (left), (ii) comparing the pixel-level background ground truth in the cross-entropy with the probability of having either the background (black) or an old class (pink and grey bars) and (iii) relating the background probability given by the old model in the distillation loss with the probability of having either the background or a novel class (green bar).  \vspace{-10pt}}
    \label{fig:method}
\end{figure*}
 
\section{Method}
\label{sec:method}


\subsection{Problem Definition and Notation}
\label{sec:problem}


Before delving into the details of \icl\ for semantic segmentation, we first introduce the task of semantic segmentation.
Let us denote as  the input space (\ie the image space) and, without loss of generality, let us assume that each image  is composed by a set of pixels  with constant cardinality . The output space is defined as , with the latter denoting the product set of -tuples with elements in a label space . Given an image  the goal of semantic segmentation is to assign each pixel  of image  a label , representing its semantic class. Out-of-class pixels can be assigned a special class, \ie the background class . 
{Given a training set , the mapping is realized by learning a model  with parameters  from the image space  to a pixel-wise class probability vector, \ie .
The output segmentation mask is obtained as , where  is the probability for class  in pixel .}

In the \icl\ setting, training is realized over multiple phases, called \textit{learning steps}, and each step introduces novel categories to be learnt. In other terms, during the  learning step, the previous label set  is expanded with a set of new {classes} , yielding a new label set .
At learning step  we are also provided with a training set  that is used in conjunction to the previous model  to train an updated model .
As in standard \icl, in this paper we assume the sets of labels  that we obtain at the different learning steps to be disjoint, except for the special void/background class . 











\subsection{Incremental Learning for Semantic Segmentation with Background Modeling}
\label{sec:our-method}
A naive approach to address the \icl\ problem consists in retraining the model  on each set  sequentially. When the predictor  is realized through a deep architecture, this corresponds to fine-tuning the network parameters on the training set  initialized with the parameters  from the previous stage. This approach is simple, but it leads to catastrophic forgetting. Indeed, when training using  no samples from the previously seen object classes are provided. This biases the new predictor  towards the novel set of categories in  to the detriment of the classes from the previous sets. In the context of \icl\ for image-level classification, a standard way to address this issue is coupling the supervised loss on  with a regularization term, either taking into account the importance of each parameter for previous tasks \cite{kirkpatrick2017overcoming,shin2017continual}, or by distilling the knowledge using the predictions of the old model  \cite{li2017learning,rebuffi2017icarl,castro2018end}. We take inspiration from the latter solution to initialize the overall objective function of our problem. In particular, we  minimize a loss function of the form:

where  is a standard supervised loss (\eg cross-entropy loss),  is the distillation loss and  is a \hyper balancing the importance of the two terms. 


As stated in Sec. \ref{sec:problem}, differently from standard \icl\ settings considered for image classification problems, in semantic segmentation we have that two different label sets  and   share the common void/background class . However, {the distribution of the background class} changes across different incremental steps. In fact, background annotations given in  refer to classes not present in , that might belong to the set of seen classes  and/or to still unseen classes \ie  with   (see Fig. \ref{fig:teaser}). In the following, we show how we account for the semantic shift in the distribution of the background class by revisiting standard choices for the general objective defined in Eq. \eqref{eq:obj-general}. 


\myparagraph{Revisiting Cross-Entropy Loss. } In Eq.\eqref{eq:obj-general}, a possible choice for  is the standard cross-entropy loss computed over all image pixels: 
 
where  is the ground truth label associated to pixel  and . 

The problem with Eq.\eqref{eq:CE} is that the training set  we use to update the model only contains information about novel classes in . However, the background class in  might include also pixels associated to the previously seen classes in . In this paper, we argue that, without explicitly taking into account this aspect, the catastrophic forgetting problem would be even more severe. In fact, we would drive our model to predict the background label  for pixels of old classes, further degrading the capability of the model to preserve semantic knowledge of past categories. To avoid this issue, in this paper we propose to modify the cross-entropy loss in Eq.\eqref{eq:CE} as follows: 

 where:


Our intuition is that by using Eq.\eqref{eq:our-CE} we can update the model to predict the new classes and, at the same time, account for the uncertainty over the actual content of the background class. In fact, in Eq.\eqref{eq:our-CE} the background class ground truth is not directly compared with its probabilities  obtained from the current model , but with the probability of having \textit{either an old class or the background}, as predicted by  (Eq.\eqref{eq:cases-ce}). {A schematic representation of this procedure is depicted in Fig.~\ref{fig:method} (blue block).}
It is worth noting that the alternative of ignoring the background pixels within the cross-entropy loss is a sub-optimal solution. In fact, this would not allow to adapt the background classifier to its semantic shift and to exploit the information that new images might contain about old classes. 





















\myparagraph{Revisiting Distillation Loss.} In the context of incremental learning, distillation loss \cite{hinton2015distilling} is a common strategy to transfer knowledge from the old model  into the new one, preventing catastrophic forgetting. Formally, a standard choice for the distillation loss  is:

where  is defined as the probability of class  for pixel  given by  but re-normalized across all the classes in  \ie:



The rationale behind  is that  should produce activations close to the ones produced by . This regularizes the training procedure in such a way that the parameters  are still anchored to the solution found for recognizing pixels of the previous classes, \ie . 

The loss defined in Eq.\eqref{eq:std-distill} has been used either in its base form or variants in different contexts, from incremental task \cite{li2017learning} and class learning \cite{rebuffi2017icarl,castro2018end} in object classification to complex scenarios such as detection \cite{shmelkov2017incremental} and segmentation \cite{michieli2019incremental}. Despite its success, it has a fundamental drawback in semantic segmentation: it completely ignores the fact that the background class is shared among different learning steps. While with Eq.\eqref{eq:our-CE} we tackled the first problem linked to the semantic shift of the background (\ie  contains pixels of ), we use the distillation loss to tackle the second: {annotations for background in  with  might include pixels of classes in .}


{From the latter considerations, the background probabilities assigned to a pixel by the old predictor  and by the current model  do not share the same semantic content.} More importantly,  might predict as background pixels of classes in  that we are currently trying to learn. Notice that this aspect is peculiar to the segmentation task and it is not considered in previous incremental learning models. However, in our setting we must explicitly take it into account to perform a correct distillation of the old model into the new one. To this extent we define our novel distillation loss by rewriting  in Eq.\eqref{eq:cases-kd} as: 
Similarly to Eq.\eqref{eq:std-distill}, we still compare the probability of a pixel belonging to seen classes assigned by the old model, with its counterpart computed with the current parameters . However, differently from classical distillation, in Eq.\eqref{eq:cases-ukd} the probabilities obtained with the current model are kept unaltered, \ie normalized across the whole label space  and not with respect to the subset  (Eq.\eqref{eq:cases-kd}). More importantly, the background class probability as given by  is not directly compared with its counterpart in , but with the probability of having \textit{either a new class or the background}, as predicted by  ({see Fig. \ref{fig:method}, yellow block}).  

We highlight that, with respect to Eq.\eqref{eq:cases-kd} and other simple choices (\eg excluding  from Eq.\eqref{eq:cases-kd}) this solution has two advantages. First, we can still use the full output space of the old model to distill knowledge in the current one, without any constraint on pixels and classes. Second, we can propagate the uncertainty we have on the semantic content of the background in  without penalizing the probabilities of new classes we are learning in the current step . 




\myparagraph{Classifiers' Parameters Initialization.} As discussed above, the background class  is a special class devoted to collect the probability that a pixel belongs to an unknown object class. In practice, at each learning step , the novel categories in  are unknowns for the old classifier . As a consequence, unless the appearance of a class in  is very similar to one in , it is reasonable to assume that  will likely assign pixels of  to . Taking into account this initial bias on the predictions of  on pixels of , it is detrimental to randomly initialize the classifiers for the novel classes. In fact a random initialization would provoke a misalignment among the features extracted by the model (aligned with the background classifier) and the random parameters of the classifier itself. Notice that this could lead to possible training instabilities while learning novel classes since the network could initially assign high probabilities for pixels in  to . 



To address this issue, we propose to initialize the classifier's parameters for the novel classes in such a way that given an image  and a pixel , the probability of the background  is uniformly spread among the classes in , \ie , where  is the number of new classes (notice that ). 
To this extent, let us consider a standard fully connected classifier and let us denote as  the classifier parameters for a class  at learning step , with  and  denoting its weights and bias respectively. We can initialize  as follows:

where  are the weights and bias of the background classifier at the previous learning step. The fact that the initialization defined in Eq.\eqref{eq:init-cases} and \eqref{eq:init-cases2} leads to  is easy to obtain from . 

As we will show in the experimental analysis, this simple initialization procedure brings benefits in terms of both improving the learning stability of the model and the final results, since it eases the role of the supervision imposed by Eq.\eqref{eq:our-CE} while learning new classes and follows the same principles used to derive our distillation loss (Eq.\eqref{eq:cases-ukd}).





