\documentclass{article}

\usepackage{hyperref}
\newcommand{\theHalgorithm}{\arabic{algorithm}}
\usepackage[accepted]{icml2020}


\usepackage[utf8]{inputenc} \usepackage[T1]{fontenc}    \usepackage{url}            \usepackage{hyperref}
\usepackage{booktabs}       \usepackage{amsfonts}       \usepackage{nicefrac}       \usepackage{microtype}
\usepackage{graphicx}
\graphicspath{{./figures/}}
\usepackage{amsfonts}
\usepackage{mathtools}
\usepackage{amsmath}
\usepackage{amsthm}
\usepackage{amssymb}
\usepackage{bm}

\newcommand{\av}{\mathbf{a}} \newcommand{\Av}{\mathbf{A}}
\newcommand{\bv}{\mathbf{b}} \newcommand{\Bv}{\mathbf{B}}
\newcommand{\cv}{\mathbf{c}} \newcommand{\Cv}{\mathbf{C}}
\newcommand{\dv}{\mathbf{d}} \newcommand{\Dv}{\mathbf{D}}
\newcommand{\ev}{\mathbf{e}} \newcommand{\Ev}{\mathbf{E}}
\newcommand{\fv}{\mathbf{f}} \newcommand{\Fv}{\mathbf{F}}
\newcommand{\gv}{\mathbf{g}} \newcommand{\Gv}{\mathbf{G}}
\newcommand{\hv}{\mathbf{h}} \newcommand{\Hv}{\mathbf{H}}
\newcommand{\iv}{\mathbf{i}} \newcommand{\Iv}{\mathbf{I}}
\newcommand{\jv}{\mathbf{j}} \newcommand{\Jv}{\mathbf{J}}
\newcommand{\kv}{\mathbf{k}} \newcommand{\Kv}{\mathbf{K}}
\newcommand{\lv}{\mathbf{l}} \newcommand{\Lv}{\mathbf{L}}
\newcommand{\mv}{\mathbf{m}} \newcommand{\Mv}{\mathbf{M}}
\newcommand{\nv}{\mathbf{n}} \newcommand{\Nv}{\mathbf{N}}
\newcommand{\ov}{\mathbf{o}} \newcommand{\Ov}{\mathbf{O}}
\newcommand{\pv}{\mathbf{p}} \newcommand{\Pv}{\mathbf{P}}
\newcommand{\qv}{\mathbf{q}} \newcommand{\Qv}{\mathbf{Q}}
\newcommand{\sv}{\mathbf{s}} \newcommand{\Sv}{\mathbf{S}}
\newcommand{\tv}{\mathbf{t}} \newcommand{\Tv}{\mathbf{T}}
\newcommand{\uv}{\mathbf{u}} \newcommand{\Uv}{\mathbf{U}}
\newcommand{\wv}{\mathbf{w}} \newcommand{\Wv}{\mathbf{W}}
\newcommand{\xv}{\mathbf{x}} \newcommand{\Xv}{\mathbf{X}}
\newcommand{\yv}{\mathbf{y}} \newcommand{\Yv}{\mathbf{Y}}
\newcommand{\zv}{\mathbf{z}} \newcommand{\Zv}{\mathbf{Z}}

\newcommand{\alphav}{\boldsymbol{\alpha}} \newcommand{\Alphav}{\mathbf{A}}
\newcommand{\betav}{\boldsymbol{\beta}} \newcommand{\Betav}{\mathbf{B}}
\newcommand{\gammav}{\boldsymbol{\gamma}} \newcommand{\Gammav}{\boldsymbol{\Gamma}}
\newcommand{\deltav}{\boldsymbol{\delta}} \newcommand{\Deltav}{\boldsymbol{\Delta}}
\newcommand{\epsilonv}{\boldsymbol{\epsilon}} \newcommand{\Epsilonv}{\mathbf{E}}
\newcommand{\varepsilonv}{\boldsymbol{\varepsilon}}
\newcommand{\zetav}{\boldsymbol{\zeta}} \newcommand{\Zetav}{\mathbf{Z}}
\newcommand{\etav}{\boldsymbol{\eta}} \newcommand{\Etav}{\mathbf{H}}
\newcommand{\thetav}{\boldsymbol{\theta}} \newcommand{\Thetav}{\boldsymbol{\Theta}}
\newcommand{\varthetav}{\boldsymbol{\vartheta}}
\newcommand{\iotav}{\boldsymbol{\iota}} \newcommand{\Iotav}{\mathbf{I}}
\newcommand{\kappav}{\boldsymbol{\kappa}} \newcommand{\Kappav}{\mathbf{K}}
\newcommand{\lambdav}{\boldsymbol{\lambda}} \newcommand{\Lambdav}{\boldsymbol{\Lambda}}
\newcommand{\muv}{\boldsymbol{\mu}} \newcommand{\Muv}{\mathbf{M}}
\newcommand{\nuv}{\boldsymbol{\nu}} \newcommand{\Nuv}{\mathbf{N}}
\newcommand{\xiv}{\boldsymbol{\xi}} \newcommand{\Xiv}{\boldsymbol{\Xi}}
\newcommand{\piv}{\boldsymbol{\pi}} \newcommand{\Piv}{\boldsymbol{\Pi}}
\newcommand{\varpiv}{\boldsymbol{\varpi}}
\newcommand{\rhov}{\boldsymbol{\rho}} \newcommand{\Rhov}{\mathbf{P}}
\newcommand{\varrhov}{\boldsymbol{\varrho}}
\newcommand{\sigmav}{\boldsymbol{\sigma}} \newcommand{\Sigmav}{\boldsymbol{\Sigma}}
\newcommand{\varsigmav}{\boldsymbol{\varsigma}}
\newcommand{\tauv}{\boldsymbol{\tau}} \newcommand{\Tauv}{\mathbf{T}}
\newcommand{\upsilonv}{\boldsymbol{\upsilon}} \newcommand{\Upsilonv}{\boldsymbol{\Upsilon}}
\newcommand{\phiv}{\boldsymbol{\phi}} \newcommand{\Phiv}{\boldsymbol{\Phi}}
\newcommand{\varphiv}{\boldsymbol{\varphi}}
\newcommand{\chiv}{\boldsymbol{\chi}} \newcommand{\Chiv}{\mathbf{X}}
\newcommand{\psiv}{\boldsymbol{\psi}} \newcommand{\Psiv}{\boldsymbol{\Psi}}
\newcommand{\omegav}{\boldsymbol{\omega}} \newcommand{\Omegav}{\boldsymbol{\Omega}}

\newcommand{\zerov}{\boldsymbol{0}}

\newcommand{\yhat}{\hat{y}}
\newcommand{\ytilde}{\tilde{y}}

\newcommand{\defEq}{\stackrel{\textrm{def}}{=}}
\newcommand{\ud}{\mathrm{d}}
\newcommand{\diag}{\mathrm{diag}}
\newcommand{\risk}{\mathcal{R}}
\newcommand{\ep}{\mathbb{E}}
\newcommand{\prob}{\mathcal{P}}
\newcommand{\st}{\mathrm{s.t.}}
\newcommand{\B}{\mathrm{Beta}}
\newcommand{\M}{\mathrm{Mult}}
\newcommand{\Ber}{\mathrm{Bernoulli}}
\newcommand{\N}{\mathcal{N}}
\newcommand{\model}{\mathbf{M}}
\newcommand{\ms}{\mathcal{M}}
\newcommand{\data}{\mathcal{D}}
\newcommand{\D}{\scriptscriptstyle}
\newcommand{\F}{\mathcal{F}}
\newcommand{\xG}{\mathcal{G}}
\newcommand{\xD}{\mathcal{D}}
\newcommand{\uV}{\mathcal{V}}
\newcommand{\uU}{\mathcal{U}}
\newcommand{\uR}{\mathcal{R}}

\newcommand{\ty}{\bm{y}}
\newcommand{\tu}{\bm{u}}
\newcommand{\tc}{\bm{c}}
\newcommand{\tth}{\bm{h}}
\newcommand{\ttheta}{\bm{\theta}}
\newcommand{\tphi}{\bm{\phi}}

\newcommand{\fY}{\bm{Y}}
\newcommand{\fU}{\bm{U}}
\newcommand{\fC}{\bm{C}}
\newcommand{\fH}{\bm{H}}
\newcommand{\fT}{\bm{T}}
\newcommand{\fM}{\bm{M}}
\newcommand{\fTheta}{\bm{\Theta}}
\newcommand{\fPhi}{\bm{\Phi}}

\newcommand{\Real}{\mathbb{R}}
\newcommand{\Complex}{\mathbb{C}}
\newcommand{\Nor}{\mathcal{N}}
\newcommand{\Exp}{\mathbb{E}}
\newcommand{\ZeroOne}{\{0,1\}}

\newcommand{\indicator}{\mathbbm{1}}

\newcommand{\fig}[1]{Fig.~\ref{fig:#1}}
\newcommand{\tabl}[1]{Table~\ref{tab:#1}}
\newcommand{\eqn}[1]{Eqn.~\eqref{eqn:#1}}
\newcommand{\secref}[1]{Sec.~\ref{sec:#1}} \usepackage{wrapfig}
\usepackage{subfig}
\usepackage{algorithm}
\usepackage{algorithmic}
\usepackage{wrapfig,booktabs}


\newtheorem{assumption}{Assumption}
\newtheorem{proposition}{Proposition}

\newtheorem{lemma}{Lemma}
\newtheorem{theorem}{Theorem}
\newtheorem{prop}{Proposition}
\newtheorem{definition}{Definition}
\theoremstyle{definition}
\newtheorem{myexp}{Example}
\newenvironment{myexpcont}
{\addtocounter{myexp}{-1}\begin{myexp}{\textit{\textbf{{(continued)}}}}}
{\end{myexp}}
\newcommand{\tabincell}[2]{\begin{tabular}{@{}#1@{}}#2\end{tabular}}


\usepackage{amssymb}\usepackage{pifont}\newcommand{\xmark}{\ding{55}}











\begin{document}

\twocolumn[
\icmltitle{Understanding and Stabilizing GANs' Training Dynamics using Control Theory}
\icmlsetsymbol{equal}{*}
\begin{icmlauthorlist}
	\icmlauthor{Kun Xu}{thu}
	\icmlauthor{Chongxuan Li}{thu}
	\icmlauthor{Jun Zhu}{thu}
	\icmlauthor{Bo Zhang}{thu}
\end{icmlauthorlist}

\icmlaffiliation{thu}{Dept. of Comp. Sci. \& Tech., Institute for AI, BNRist Center, Tsinghua-Bosch ML Center, THBI Lab, Tsinghua University, Beijing, China}

\icmlcorrespondingauthor{Jun Zhu}{dcszj@mail.tsinghua.edu.cn}
\icmlkeywords{Machine Learning, ICML}
\vskip 0.3in
]



\printAffiliationsAndNotice{} 

\begin{abstract}
Generative adversarial networks~(GANs) are effective in generating realistic images but the training is often unstable.
There are existing efforts that model the training dynamics of GANs in the parameter space but the analysis cannot directly motivate practically effective stabilizing methods.
To this end, we present a conceptually novel perspective from control theory to directly model the dynamics of GANs in the function space and provide simple yet effective methods to stabilize GANs' training.
We first analyze the training dynamic of a prototypical Dirac GAN and adopt the widely-used closed-loop control (CLC) to improve its stability.
We then extend CLC to stabilize the training dynamic of normal GANs, where CLC is implemented as a squared  regularizer on the output of the discriminator.
Empirical results show that our method can effectively stabilize the training and obtain state-of-the-art performance on data generation tasks.
\end{abstract}

\section{Introduction}\label{sec:introduction}


Generative adversarial networks~(GANs)~\citep{goodfellow2014generative} have shown promise in generating realistic natural images~\citep{brock2018large} and facilitating unsupervised and semi-supervised learning~\citep{chen2016infogan,chongxuan2017triple,donahue2019large}.
In GANs, an implicit generator  is defined by mapping a noise distribution to the data space. 
Since no density function is defined for the implicit generator, the maximum likelihood estimate is infeasible for GANs. Instead, a discriminator  is introduced to estimate the density ratio between the data distribution  and the generating distribution  by telling the real samples from fake ones.  aims to recover the data distribution by maximizing this ratio. This framework is formulated as a minimax optimization problem, which can be solved by optimizing  and  alternately.
In practice, however, GANs suffers from the instability of training~\cite{goodfellow2016nips}, where divergency and oscillations are often observed~\citep{liang2018generative,chavdarova2018sgan}.

Early methods~\citep{mao2017least,gulrajani2017improved, arjovsky2017wasserstein,du2018learning} introduce different types of divergences to improve the training process of GANs. Their theoretical analyses assume that  achieves its optimum when training .
However, the practical training process (e.g., alternative stochastic gradient descent) often violates the above assumption and therefore is not guaranteed to converge to the desired equilibrium. Several empirical regularizations~\cite{miyato2018spectral,gulrajani2017improved,zhang2019consistency} are used to improve the training process whereas no stability can be guaranteed.

Recently, \citet{mescheder2017numerics} and \citet{nagarajan2017gradient} directly model the training dynamics of GANs, i.e. how the parameters develop over time. 
Formally, the dynamic is defined as the gradient flow of the parameters.
The stability of the dynamic is fully determined by the eigenvalues of the Jacobian matrix of the gradient flow.
Indeed, the stability analysis in a linear prototypical GAN (i.e. Dirac GAN~\cite{mescheder2018training}) is elegant. 
However, this analysis does not directly motivate effective algorithms to stabilize GANs' training.
To our knowledge, such methods do not report competitive image generation results to the state-of-the-art GANs~\cite{miyato2018spectral}.


In this paper, we understand and stabilize GANs' training dynamics from the perspective of control theory.
Based on the recipe for control theory, we can not only analyze the dynamics of Dirac GAN formally, but also develop practically effective stabilizing methods for nonlinear dynamics~\cite{khalil2002nonlinear}.
Specifically, we start from revisiting the Dirac GAN example with the WGAN's objective function in \secref{dirac_gan}. By utilizing the Laplace transform~\cite{widder2015laplace}~(LT), the training dynamics of both  and  can be modeled in the {\it frequency domain} instead of the {\it time domain} in previous methods~\cite{mescheder2017numerics, mescheder2018training}.
These types of dynamics are well studied in control theory and the stability can be easily inferred. The analysis can be simply generalized to other objective functions with {\it local linearization}. Given the instability of GANs, the recipe for control theory provides a set of tools to stabilize their dynamics.
We first adopt the {\it closed-loop control}~(CLC) to successfully stabilize the dynamic of Dirac GAN with theoretical guarantee.
Besides, extensive empirical results in control theory show that the CLC is also helpful in nonlinear settings~\cite{khalil2002nonlinear}.
It inspires us to extend our proposal to normal GANs by modeling  and 's dynamics in the function space where these dynamics and Dirac GAN's dynamics share similar forms and characters.
The CLC is implemented as a regularization term to 's objective function which penalizes the squared  norm of the output of  as we described in \secref{implementation}.
We therefore refer our method as CLC-GAN.
CLC-GAN is verified on an 1-dimension toy example as well as the natural images including CIFAR10~\citep{krizhevsky2009learning} and CelebA~\citep{liu2015faceattributes}. The results demonstrate that our method can successfully stabilize the dynamics of GANs and achieve state-of-the-art performance.


Our contributions are summarized as:
\begin{itemize}
\setlength\itemsep{-2pt}
	\item We formally analyze the training dynamics of GANs from a novel perspective of control theory, which is generally applicable to different objective functions.
	\item We propose to use the CLC as an effective method to stabilize the training of GANs, while other advanced control methods can be explored in future. \item The simulated results on Dirac GAN agree with the theoretical analysis and CLC-GAN achieves the state-of-the-art performance on natural image generations.
\end{itemize}


\section{Preliminary}
\label{sec:preliminary}


In this section, we present the recipe for control theory, especially under the Laplace transform, which is powerful to model dynamic systems and design stabilizing methods.

\subsection{Modeling Dynamic Systems }
\label{sec:dynamicmodeling}


In control theory, a {\it signal} is represented as a function over time , i.e., in the {\it time domain}~\cite{kailath1980linear}. 
A dynamic\footnote{For simplicity, we use {\it dynamic} for dynamic system.} represents how one signal (i.e., output, denoted by ) develops with respect to another signal (i.e., input, denoted by ) over time. A natural representation of a dynamic is a differential equation~(DE)\footnote{We consider ordinary differential equations in this paper.}:

together with an initial condition .
Note that ,  and  can be vector valued functions. 
We assume  unless specified.
A dynamic is {\it linear} if  is a linear function.




Besides the time domain, a signal can also be represented as a function of frequency , i.e., in the {\it frequency domain}.
A DE of a linear dynamic in the time domain can be converted to a simple algebraic equation in the frequency domain, which can largely simplify the solving process and stability analysis of a dynamic. Laplace transform~\cite{widder2015laplace}~(LT) is a widely-adopted operator to convert signals from the time domain to the frequency domain. Formally, LT is given by:

where  is a signal in the time domain, and  with real numbers  and . The real and imaginary parts of  denote the gain and phase of the frequency  in . In this paper, we use bold lowercase letters (e.g., ) to denote signals in the time domain and bold capital letters (e.g. ) to denote signals in the frequency domain.

Leveraging LT, the derivation over time  can be represented as multiplying a factor  in the frequency domain:

Therefore, by applying LT to both sides of a DE in \eqn{general_dynamic}, a linear dynamic can be solved by the formal rules of algebra and represented in the form of , where  is a simple rational fraction called {\it transfer function}~\cite{kailath1980linear}.
The transfer function can facilitate the stability analysis, as detailed in \secref{stability_analysis}.









\subsection{Stability Analysis}
\label{sec:stability_analysis}

In general, we require a dynamic to be {\it stable}. Although different definitions exist, we consider the widely adopted asymptotic stability\footnote{This definition is consistent with existing work in \citet{mescheder2017numerics} and \citet{mescheder2018training}.}~\cite{kailath1980linear} in this paper.
\begin{definition}
	For a constant input , a point  is called an equilibrium point of a dynamic represented in \eqn{general_dynamic}, if . A dynamic is called asymptotically stable if for every  > 0, there exists  such that if , then for every ,  and . Here  is a norm defined in the vector space of .
\end{definition}


In the frequency domain, the stability can be directly inferred from the transfer function. Formally, we define {\it poles} as the roots of the denominator in a transfer function. The stability of a linear dynamic is fully determined by its poles as summarized in the following proposition.\newpage

\begin{prop}(Theorm 2.6-1 in \citet{kailath1980linear})
\vspace{-.15cm}
\begin{enumerate}
	\setlength\itemsep{-2pt}
	\item A dynamic is asymptotic stable if all poles have negative real parts.
	\item A dynamic is oscillatory (i.e., bounded output but not stable) if one or more poles are purely imaginary.
	\item A dynamic is diverged (unbounded output) if one or more poles have positive real parts.
\end{enumerate}
\label{prop_stability}
\end{prop}



\subsection{Control Methods}
\label{sec:control_method}


For an unstable dynamic, control theory provides a set of methods to improve its stability. Among them, 
the {\it closed-loop control}~\cite{kailath1980linear}~(CLC) is one of the most popular ones and robust to nonlinearity in dynamics practically. 

The central idea is to modify the transfer function by feeding the output back to the input such that all poles have negative real parts.
Specifically, we introduce an additional dynamics called {\it controllers} with transfer functions  to adjust the output signal and input signal respectively. The controller takes  as input and output the feedback signal . We then substitute the difference between  and  (i.e., ) for input in the original dynamics, resulting the output signal as . The relationship between the input  and the output  is:

Further, the whole controlled dynamic is given as:

With a properly designed , the poles of the dynamic in \eqn{feedback_transfer} can have negative real parts and the dynamic is stabilized. In the following, we first model and stabilize the training dynamic of Dirac GAN: a simplified GAN with linear dynamics in \secref{dirac_gan} and then we generalize it to the realistic setting in \secref{normal_gan}.

\section{Analyzing Dirac GAN by Control Theory}\label{sec:dirac_gan}


In this section, we focus on the Dirac GAN~\cite{mescheder2018training}, which is a widely adopted example to analyze the stability of GANs.
Previous work~\cite{mescheder2017numerics,gidel2018negative} uses the Jacobian matrix to analyze the stability of dynamics whereas does not directly provide an approach to stabilize it. Instead, we revisit this example from the perspective of control theory and develop a principled method that not only analyzes but also improves the stability of various GANs.




\subsection{Modeling Dynamics}
\label{sec:gan_dynamic_model}



We first model the dynamics of the Dirac GANs in the language of control theory, which can facilitate the stability analysis and improvement in \secref{ana_imp_stability}.
In Dirac GAN,  is defined as   where  is the Dirac delta function, and  is defined as .  and   are the parameters of  and  respectively. The data distribution is  with a constant . 
Generally, the objective functions of  and  can be written as:

Here  is a scalar function for .  
Assuming that the equilibrium point of  is a zero function as in most GANs~\cite{goodfellow2014generative,arjovsky2017wasserstein}, it is required that  and  are increasing functions and  is a decreasing function around zero. For instance, when  and  with  denoting the sigmoid function, we obtain the vanilla GAN~\cite{goodfellow2014generative}.



Since  and  are updated using gradient descent, we can denote the training trajectories as signals  and . The dynamics are defined by the following gradient flow:

Specifically, for the dynamics of , we have:

Similarly, for the dynamics of , we have:

Substituting  to \eqn{dynamic_dirac_D} and \eqn{dynamic_dirac_G}, the dynamics of Dirac GAN can be summarized as:

where  denotes the derivative of  for .


From the perspective of control theory (see details in \secref{dynamicmodeling}), \eqn{dynamic_dirac_summarize} represents a dynamic in the time domain, which is natural to understand but difficult to analyze. Converting it to the frequency domain by the Laplace transform~(LT) can simplify the analysis. It requires a case by case derivation for different GANs due to the specific forms of the objective functions~(i.e., different choices of ).
We will first use WGAN as an example to present the analyzing process and then generalize it to other objectives via the local linearization technique in \secref{local_linearize}.



In WGAN\footnote{We ignore the Lipschitz continuity of  for simplicity but the equilibrium point and its local convergence do not change. See theoretical analysis and empirical evidence in Appendix~B.}, we have  and . Let the output  and the input . Then, the dynamic in \eqn{dynamic_dirac_D} and \eqn{dynamic_dirac_G} is instantiated as:

Applying LT  in \eqn{lap_definition} to both sides of \eqn{dirac_gan}, the dynamic can be represented in the frequency domain as:

where  represent  in the frequency domain, e.g., .
Then we can solve the dynamics of  and  according to the formal rules of algebra as:

In the frequency domain, the output signal can be represented as a multiplication between the transfer function (see \secref{dynamicmodeling}) and the input signal.
Specifically, in \eqn{dynamic_frequency_parameter}, the transfer function of  is  and the transfer function of  is .
According to Proposition \ref{prop_stability}, the stability of a dynamic is fully characterized by the poles of the transfer function (i.e., the roots of the denominator).
The poles of both  and  are  according to \eqn{dynamic_frequency_parameter}. Therefore, both  and  are oscillatory instead of converging to the equilibrium point . The simulated dynamic of Dirac GAN is illustrated in \fig{simulated_diracgan}. 




\subsection{Analyzing and Improving Stability}
\label{sec:ana_imp_stability}

\begin{figure}
	\centering
	\includegraphics[width=0.22\textwidth]{figures/NegativeFeedback.pdf}
	\includegraphics[width=0.22\textwidth]{figures/NegativeFeedbackd.pdf}
	\caption{The simulated dynamic of Dirac GAN for  (left) and  (right) with . The curve of WGAN shows the oscillation while Other curves of CLC-GAN show that the closed loop control helps convergence.}
	\label{fig:simulated_diracgan}
\end{figure}

Control theory provides extensive methods~\cite{khalil2002nonlinear} to improve the stability of dynamics without changing the desired equilibrium. In this paper, the widely used closed-loop control~(CLC) is introduced in \secref{control_method} for its simplicity. We emphasize that advanced control methods can potentially result in more stable GANs and we leave it as future work.

Before applying the CLC, we emphasize that there are two requirements to be satisfied simultaneously: 1) applying the CLC needs to stabilize the dynamics of  and ; 2) it should not change the equilibrium point of , i.e., . 

For the first requirement, the dynamic of  in Dirac GAN is , which indicates that stabilizing  to zero can also stabilize the dynamic of . Therefore, we only need to introduce the CLC to .
The central idea of the CLC is to adjust the transfer function by introducing an auxiliary controller. Here we adopt a simple and widely used controller . Intuitively, it is an amplifier with negative feedback from output to input according to \eqn{feed_back_negative} and \footnote{ is a hyperparameter and we analyze its sensitivity in \secref{experiment}.} is the coefficient for the amplitude of the feedback.
Substituting  with  in \eqn{feedback_transfer}, the transfer function  of the controlled  is given by:

With a positive , all of poles in the controlled dynamic have negative real parts, and hence it is a stable dynamic. We also demonstrate the simulated results of the controlled dynamic with different values of  in \fig{simulated_diracgan}.

For the second requirement, the CLC will not change the equilibrium point of Dirac GAN. In the time domain, the CLC is equivalent to adjust the dynamics of  as:

Since the equilibrium point of  is a zero function, i.e., , then we still have  at .


\setlength{\tabcolsep}{1.4mm}{
\begin{table*}[htbp]
		\centering
		\caption{The stability characters for the widely-used GANs. Please refer to Appendix A for detailed derivation, which adopts the local linearization technique introduced in \secref{local_linearize}.
			With CLC, the training dynamics of Dirac GANs are stable theoretically (see \fig{simulated_diracgan} and Appendix~A), and those of normal GANs are stable empirically (see \fig{learning_curve}).}
		\begin{tabular}{ccccc}
			\toprule
			&   & \tabincell{c}{Stability \\ Dirac GAN/normal GAN}&  & \tabincell{c}{Stability with CLC \\ Dirac GAN/normal GAN}\\
			\midrule
			WGAN  &  & \xmark/\xmark &   & / \\
			Hinge-GAN &  & \xmark/\xmark &  & / \\
			SGAN  &  & /\xmark &  & / \\
			LSGAN &  & /\xmark &  & / \\
			\bottomrule
		\end{tabular}\label{tab:summarize_dynamic}\end{table*}}

\subsection{Extending to Other Objectives}
\label{sec:local_linearize}

The proposed method is not limited to WGAN but can be generalized to other GANs~\cite{goodfellow2014generative, mao2017least}, which may have nonlinear objective functions.

We leverage a standard technique called {\it local linearization}~\cite{khalil2002nonlinear} to approximate the original dynamics as a linear one around the equilibrium point.
For example, the objective function of  in the vanilla GAN is:

The dynamic of  is nonlinear because of the sigmoid function, which is given by:

where  is the derivative of .
Local linearization approximates the original dynamic by the first order Taylor expansion at the equilibrium point :


Note that the stability is determined by the local character of the equilibrium point, around which the residual in \eqn{local_linear} is negligible. Therefore, we have a linear approximation and the the analysis in \secref{ana_imp_stability} applies. We summarize the stability characters for all GANs in \tabl{summarize_dynamic}.




\begin{algorithm}[t]
	\begin{algorithmic}[1]
\caption{Cloosed-loop Control GAN}\label{algo:NFGAN}
		\STATE {\bfseries Input:} Buffer size , feedback coefficient , batch size , initialized  and , learning rate .
		\STATE Initialize  and  for real samples and fake samples respectively.
		\REPEAT
		\STATE Sample a batch of ,  of  samples.
		\STATE Update  with . Update  with .
		\STATE Sample a batch of ,  of  samples respectively.
		\STATE Estimate the objective of :\\
		
		\STATE Update  to maximize  with learning rate .
		\STATE Estimate the objective of :
		.
		\STATE Update  to maximize  with learning rate .
		\UNTIL{Convergence}
	\end{algorithmic}
\end{algorithm}

\section{Extensions to Normal GANs}\label{sec:normal_gan}


In \secref{dirac_gan}, we show that the dynamic of Dirac GAN can be formally analyzed and stabilized based on the recipe for control theory.
Besides, the CLC can successfully stabilize nonlinear dynamics in control theory~\cite{khalil2002nonlinear}.
This two facts inspire us to stabilize the training dynamic of a normal GAN (i.e., parameterized by neural networks) by incorporating the CLC.
Unlike previous methods~\cite{mescheder2018training} which mainly focus on the dynamics of parameters of  and , we instead model the dynamics of  and  in the function space, i.e.,  and . It can simplify the analysis and build the connections between the Dirac GAN and the normal GANs.


Following the notation in \secref{dirac_gan}, the objective function of a general GAN is:

According to the calculus of variations~\citep{gelfand2000calculus}, the gradient of  with respect to the function  is:

where  for .
The gradient of  with respect to  is:

where .


Therefore, the dynamics of  and  in normal GANs can be denoted generally as:

Note that the above dynamics is quiet similar to the dynamic of Dirac GAN by substituting  and  for  and  in \eqn{dynamic_dirac_D} and \eqn{dynamic_dirac_G} respectively.
Specifically, in both dynamics, the discriminators take the weighted summation of  and . For the generator, both of them depend on the .
The above similarity between Dirac GANs and normal GANs inspires us to directly apply the CLC in nonlinear settings. Our empirical results in various settings (see \secref{experiment}) demonstrate the effectiveness of the proposed method, which agrees with the above analysis and \tabl{summarize_dynamic}.




\subsection{Implementing CLC in GANs}
\label{sec:implementation}



According to \secref{ana_imp_stability}, we apply the CLC with a controller  to normal GANs. 
The resulting dynamic of  is

Note that  will be optimized by gradient descent in the implementation and we need to design a proper objective function whose gradient flow is equivalent to \eqn{dynamic_con_D}.
Therefore, we introduce an auxiliary regularization term to the original GANs and get:

where  denotes the space of , e.g.,  for image generation of size .
Below, we denote , which is the squared 2-norm of the function  over the space of . Intuitively, minimizing  encourages  to converge to a zero function.


The regularization term  is proportional to the expectation of  with respect to a uniform distribution  defined on , i.e., .
However, directly estimating  is not sample efficient since most of samples in  is meaningless and do not provide useful training signals to stabilize .
Instead, we maintain two buffers  and  of fix size  to store the old real samples and fake samples, respectively. We define a uniform distribution  on  to approximate  as:

where  denotes the regularization term at time .
 is estimated using Monte Carlo and these buffers are updated with replacement. As analyzed below, using  to approximate  will not change the equilibrium and stability.
The training procedure is presented in Alg.~\ref{algo:NFGAN}.



\begin{figure}[t]
\centering
	\includegraphics[width=0.48\textwidth]{Curve_IS_CIFAR.pdf}
\includegraphics[width=0.48\textwidth]{Curve_FID_celeba.pdf}
\caption{The learning curve of the baselines and our proposed method. Top: The Inception Score of CIFAR10. Bottom: The FID score of CelebA. We plot the curves with respect to the time for better representation of the computational cost.}
	\label{fig:learning_curve}
\end{figure}

\subsection{Theoretical Analysis}
Below, we first prove that the regularization term in \eqn{clc_regularization} will not change the desirable equilibrium point of GANs, i.e., , as summarized in Lemma~1.

\begin{lemma}
Under the non-parametric setting, CLC-GAN has the same equilibrium as the original GAN, i.e,  and  for all x.
\end{lemma}

Here we follow the identical assumption as in~\citet{goodfellow2014generative}.
Further, under mild assumptions as in~\citet{mescheder2018training}, CLC-GAN locally converges to the equilibrium, as summarized in Theorem~1.


\begin{theorem}(Proof in Appendix C)
Under the Assumptions 1, 2 and 3 in Appendix C with sufficient small learning rate and large , the parameters of CLC-GAN locally converge to the equilibrium with alternative gradient descent.
\end{theorem}

We provide the experimental results in \secref{experiment} to empirical validate our method.







\section{Related Work}\label{sec:related_work}




Some recent work directly models the training process of GANs.
\citet{mescheder2017numerics} and \citet{nagarajan2017gradient} model the dynamics of GANs in the parameter space and stabilize the training dynamics using gradient-based regularization. However, the above methods do not model the whole training dynamics explicitly and cannot generalize to natural images.
Then \citet{mescheder2018training} propose a prototypical example Dirac GAN to understand GANs' training dynamics and stabilize GANs using simplified gradient penalties. 
\citet{gidel2018negative} analyze the effect of momentum based on the Dirac GAN and propose the negative momentum.
Though the above methods provide an elegant understanding of the training dynamics, this understanding does not provide a practically effective algorithm to stabilize nonlinear GANs' training and they fail to report competitive results to the state-of-the-art~(SOTA) methods~\cite{miyato2018spectral}. 
Instead, we revisits the Dirac GAN from the perspective of control theory, which provides a set of tools and extensive experience to stabilize it.
Based on the recipe, we advance the previous SOTA results on image generation.


\citet{feizi2017understanding} is another related work that analyzes the stability of GANs using the Lyapunov function, which is a general approach in control theory. However, it only focuses on the stability analysis whereas cannot provide stabilizing methods. In our paper, we are interested in building SOTA GANs in practise and therefore we leverage the classical control theory.





\section{Experiments}\label{sec:experiment}


We now empirically verify our method on the widely-adopted CIFAR10~\citep{krizhevsky2009learning} and CelebA~\citep{liu2015faceattributes} datasets. 
CIFAR10 consists of 50,000 natural images of size  and CelebA consists of 202,599 face images of size .
The quantitative results are from the corresponding papers or reproduced on the official code for fair comparison.
Specifically, we use the exactly same architectures for both  and  with our baseline methods, where the ResNet~\citep{he2016deep} with the ReLU activation~\citep{glorot2011deep} is adopted\footnote{Our code is provided \href{https://github.com/taufikxu/GAN_PID}{HERE}.}.
The batch size is 64, and the buffer size  is set to be 100 times of the batch size for all settings. 
We manually select the coefficient  among  in Reg-GAN's setting and among  in SN-GAN's setting.
We use the Inception Score~(IS)~\citep{salimans2016improved} to evaluate the image quality on CIFAR10 and FID score~\citep{gulrajani2017improved} on both CIFAR10 and CelebA. 
More details about the experimental setting and further results on a synthetic dataset can be found in Appendix~E. 


We compare with two typical families of GANs. The first one is referred as unregularized GANs, including WGAN~\cite{arjovsky2017wasserstein}, SGAN~\cite{goodfellow2014generative}, LSGAN~\cite{mao2017least} and Hinge-GAN~\cite{miyato2018spectral}.The second one is referred as reguarlized GANs, including Reg-GAN~\cite{mescheder2018training} and SN-GAN~\cite{miyato2018spectral}.
We emphasize that the regularzied GANs are the previous SOTA methods and our implementations are based on the officially released code. 
For clarity, we refer to our method as CLC-GAN with the hyperparameter  denoted in the parentheses.

In the following, we will demonstrate that (1) the CLC can stabilize GANs using less computational cost than competitive regularizations and is applicable to various objective functions ; (2) CLC-GAN provides a consistent improvement on the quantitative results in different settings compared to related work~\cite{mescheder2018training} and surpasses previous state-of-the-art~(SOTA) GANs~\cite{miyato2018spectral,zhang2019consistency}.


\begin{table}
\centering
	\caption{The FID Score on CIFAR10. The results reported here are the best results over the training process and are averaged over 3 runs.}
\begin{tabular}{ccc}
		\toprule
		Method   & \multicolumn{1}{c}{WGAN} & \multicolumn{1}{c}{SGAN} \\
		\midrule
		No Regularization &  &  \\
		Reg-GAN &  &  \\
		Gradient Penalty &  &  \\
		\midrule
		CLC-GAN(2)&  &  \\
		CLC-GAN(5)&  &  \\
		CLC-GAN(10)&  &  \\
		\bottomrule
	\end{tabular}\label{tab:FID_results}
\end{table} 

\setlength{\tabcolsep}{1.mm}{
\begin{table}[t]
	\centering
	\caption{The Inception score on CIFAR10. ~\cite{yang2017lr}, ~\cite{miyato2018spectral}, ~\cite{zhang2019consistency}. Results of CLC-GAN are averages over 3 runs. }
	\begin{tabular}{cccc}
		\toprule
		Method  & WGAN  & SGAN & Hinge \\
		\midrule
		LR-GAN & - &  & - \\
		SN-GAN & - & - & \\
		CR-GAN & - &  & - \\
		\midrule
		Gradient Penalty &   & - & - \\
		Reg-GAN   &   &   &  \\
		CLC-GAN(2) &   &  &  \\
		CLC-GAN(5) &   &  & \\
		CLC-GAN(10) &   &  &  \\
		\midrule
		SN-GAN & &  &  \\
		\tabincell{c}{CLC-SN-\\GAN(0.1)} &  &  &  \\
		\bottomrule
	\end{tabular}\label{tab:is_cifar10}
\end{table}}

\subsection{CLC-GAN is stable}
\label{sec:stability_improvement}

\begin{figure}
	\centering
	\includegraphics[width=0.2\textwidth]{cifar_wgan_gp.png}
	\includegraphics[width=0.2\textwidth]{cifar_wgan_realreg.png}
	\includegraphics[width=0.2\textwidth]{cifar_wgan_p1i5.png}
	\includegraphics[width=0.2\textwidth]{cifar_sgan_p1i5.png}
	\caption{The generated results of CIFAR10 dataset. From top left to bottom right: WGAN-GP, Reg-WGAN, CLC-WGAN(5), CLC-SGAN(5).}
\label{fig:cifar_generation}
\end{figure}

\begin{figure}[t]
	\centering
	\includegraphics[width=0.2\textwidth]{celebA_wgangp.png}
	\includegraphics[width=0.2\textwidth]{celebA_wgan_realreg.png}
	\includegraphics[width=0.2\textwidth]{celebA_wgan_nf15.png}
	\includegraphics[width=0.2\textwidth]{celebA_sgan_nf15.png}
\caption{The generated results of CelebA dataset. From top left to bottom right: WGAN-GP, Reg-WGAN, CLC-WGAN(15), CLC-SGAN(15).}
\label{fig:celeba_generation}
\end{figure}

In the linear case, the simulated results in \fig{simulated_diracgan} demonstrate that CLC-GAN can stabilize the Dirac GAN, which agrees with our theoretical analysis in \secref{ana_imp_stability}. 

In normal GANs, we compare CLC-GAN with a wide range of GANs~\cite{arjovsky2017wasserstein,goodfellow2014generative,mao2017least,miyato2018spectral} and their regularized version in \cite{mescheder2018training} in terms of training stability qualitatively.
The learning curves are shown in \fig{learning_curve}. The top panel shows the IS on CIFAR10 and the bottom one shows FID on CelebA.

In both panels, the training dynamics of unregularized GANs are not stable. On CIFAR10, the unregularized GANs all diverge from the data distribution and on CelebA they even diverge at the very beginning.
Indeed, their FID results on CelebA are over  which is too large to be shown in the figure. 
Among unregularized GANs, LSGAN and SGAN are more stable than WGAN on CIFAR10 which is consistent to our analysis in \tabl{summarize_dynamic}.
However, none of them provide converged results, nor can they generalize to larger images in CelebA.
We hypothesize that the nonlinearity in neural networks is the main reason for the divergence behaviour.
Instead, CLC-GAN can succetssfully avoid the oscillatory behaviour and regularize GANs towards the data distribution. 
The robustness of CLC-GAN in the nonlinear dynamics agrees with the theoretical analysis in \tabl{summarize_dynamic} and the experience in control theory, which are the main motivations of our paper.
In conclusion, the comparison between the unregularized GANs and their controlled versions show the effectiveness of the proposed method.


Indeed, Reg-GAN can also stabilize the training dynamics.
In comparison, the CLC-GANs are computationally efficient and achieve better results after convergence.
First, unlike the gradient penalty which implies a non-trivial running time~\cite{kurach2018large}, CLC-GANs directly regularize the activation of  and require less computational cost.
For instance, our method can conduct approximate  iterations per second of training on CelebA whereas Reg-GAN can only conduct  iterations per second on Geforce 1080Ti. 
Second, CLC-GANs provide higher IS on CIFAR10 and lower FID on CelebA as qualitatively shown in the learning curves. The quantitative results are summarized in the following subsection.

\fig{cifar_generation}~\&~\fig {celeba_generation} show the generated samples. Those from CLC-GAN are semantically meaningful in all setting and are at least competitive to the ones from very strong baselines.






\subsection{Quantitative Results}
\label{sec:quantative_results}

We now present the quantitative results on CIFAR10 in the settings that include different objective functions, neural network architectures and the values of . The IS and FID are shown in \tabl{is_cifar10} and \tabl{FID_results} respectively. The comparisons among different settings are given within the tables.



First, our method provides a consistent improvements on both IS and FID on CIFAR10. For FID, CLC-GANs decrease it from  to  compared to Reg-GAN. 
For IS, CLC-GANs surpass previous SOTA GANs. Specifically, CLC-GANs achieve IS over  with various objectives without using spectral normalization, which is a significant improvement compare to related works, including SN-GAN~\cite{miyato2018spectral} and CR-GAN~\cite{zhang2019consistency}. 

Second, CLC-GAN is also applicable to SN-GAN's architecture and improve its performance, whereas most gradient-based regularizations fail to introduce significant improvement~\cite{kurach2018large}.
Unlike SN-GAN whose performance largely depends on the objective functions, CLC-SN-GAN provides stable training dynamics consistently. 

Finally, CLC-GAN is not very sensitive to the hyperparameter  given the normalization used in . When batch normalization is adopted, CLC-GANs with  all achieve SOTA IS and a large improvement on FID. When spectral normalization~\cite{miyato2018spectral} is used, a relatively smaller  is required. 
Besides the reported results with , CLC-SN-GANs with  achieves IS over  consistently using Hinge loss.
The underlying mechanism of the difference between the two types of normalizations is unclear. We hypothesize that it is because  is a Lipschitz-1 function with spectral normalization.
	


\section{Conclusions and Discussions}



In this paper, we propose a novel perspective to understand the dynamics of GANs and a stabilizing method called CLC-GAN. We model the dynamics of the Dirac GAN with linear objectives theoretically in the frequency domain and extend the analysis to nonlinear objectives using local linearization.
By leveraging the recipe for control theory, we propose a stabilizing method called CLC to improve Dirac GAN's stability and generalize CLC to normal GANs. The simulated results on Dirac GAN and empirical results on normal GANs demonstrate that our method can stabilize a wide range of GANs and provide better convergence results.

Although CLC-GAN provides promising results, further analyses can be done to achieve better results. On one hand, our analysis mainly focuses on the continuous cases, where the practical implementation optimizes both  and  in discrete time steps. In this case, the -transform is a better tool than LT used in this paper. On the other hand, we approximate the dynamics in the function space using the update in the parameter space, which can be improved by recent analyses of GANs in the function space~\citep{johnson2018composite}.
Finally, modern control theory and non-linear control methods~\citep{khalil2002nonlinear} can potentially help GANs to achieve better performance. These are promising directions for the future work.

\section*{Acknowledgements}
This work was supported by the National Key Research and Development Program of China (No. 2017YFA0700904), NSFC Projects (Nos. 61620106010, U19B2034, U181146), Beijing NSF Project (No. L172037), Beijing Academy of Artificial Intelligence, Tsinghua-Huawei Joint Research Program, Tiangong Institute for Intelligent Computing, and NVIDIA NVAIL Program with GPU/DGX Acceleration. C. Li was supported by the Chinese postdoctoral innovative talent support program and Shuimu Tsinghua Scholar.

\bibliographystyle{icml2020}
\bibliography{references} 


\appendix

\section{Dynamics for different GANs.}



In this section, we apply the local linearization technique to Dirac GANs with various objective functions, including vanilla GAN, non-saturation GAN~\cite{goodfellow2014generative}, LS-GAN~\cite{mao2017least} and Hinge-GAN~\cite{miyato2018spectral}. Following the notations in the main body, the training dynamics of general Dirac GANs are given by:

By applying the local linearization technique to both  and  around the equilibrium point , the dynamic can be approximated as:

and  can be denoted as:

Here  is the second order derivative of  for .
Below we assume  and start the case by case analysis for various types of GANs.

\subsection{Vanilla GAN}
In vanilla GAN, we have:

where  denotes the sigmoid function.
Then we have:

and for :

It indicates that 

Then we can solve the dynamics of vanilla GAN as:


\subsection{Non-saturation GAN}
Non-saturation GAN~(NS-GAN) shares the same equilibrium point and the objective function for the discriminator. It modifies  as  and we have:

By substituting the above equation to , the dynamic of NS-GAN is equivalent to vanilla GAN and therefore shares the same transfer function.

\subsection{Hinge GAN}
For Hinge GAN, we have:

Then we have:

Therefore the Hinge GAN actually shares the same dynamics as WGAN around the equilibrium point.

\subsection{Least Square GAN}

The objective function of least square GAN~(LS-GAN) is:

In this case, there's no equilibrium point. We modify the discriminator as  which is equilvalent to convert the objective functions as follows: 

and therefore we have:

Then the  can be denoted as:

We have:

Then we can solve the dynamics of LSGAN as:



\section{Dynamics with Lipschitz Continuity}

In this section, we prove that around the equilibrium, the dynamics of regularized  with Lipschitz constraint is equivalent to the unregularized  as in Eqn. (20). 
With the dynamics defined by the corresponding gradient flow, we only need to prove that updating  according to Eqn. (20) will not violate the Lipschitz constraints, at least locally around the equilibrium. Here we make the following assumptions:
\begin{enumerate}
    \item Both  and  are -smooth:  and  exists and is continuous .
    \item  and  when  for .
    \item There exists an  such that  for .
\end{enumerate}
The above assumptions are satisfied for most probability density functions.

The distance in the function space is defined as  which always exists because of the 2-nd conditions above. We define  and .
Then we have the follow proposition:

\begin{proposition}
There exists , such that , we have . 
\end{proposition}

\begin{proof}
By denoting , We have:

Therefore, we have 

By letting , we have . Therefore we have .
\end{proof}

The above proposition indicates that when  is sufficient close to the equilibrium and the learning rate is sufficient small, then the dynamics of  still follows Eqn.~(11) for Dirac GAN and Eqn.~(22) for normal GANs. The simulated results of Dirac GAN in Fig.~1 and the bad performance of SN-GAN with WGAN's objective in Sec.~6.2 agree with this argument.

\section{Theoretical Analysis of CLC-GAN}

\subsection{Proof of Lemma 1}

Under the non-parametric setting following~\citet{goodfellow2014generative}, the equilibrium of GAN's minimax problem is achieved when  and  for all . Besides, for the regularization term introduced by CLC-GAN:

it also achieves optimum when  for all . Therefore, regularizing 's training dynamic with \eqn{clc-reg} will not change the equilibrium of GANs. This argument for other variants of GANs remains the same under the condition that the equilibrium of unregularized GANs' minimax problem is achieved when  for all  around the data distribution. This assumption is meet by most variants of GANs~\cite{arjovsky2017wasserstein,mao2017least,miyato2018spectral,zhang2019consistency}.

\subsection{Proof of Theorem 1}

In this subsection, we provide the proof of Theorem 1, whose proof procedure mainly follows~\citet{mescheder2018training}. We first denote that  is the generator parameterized by  and  is the discriminator parameterized by .
Before going to the proof of Theorem 1, we first provide the assumptions we made, which are similar to~\cite{mescheder2018training}.

We first assume the data distribution can be captured by the generator , which is identical to the Assumption I in~\cite{mescheder2018training} as:
\begin{assumption}
There exists a discriminator  parameterized by  and a generator  parameterized by , such that  for all  and  in some local neighbourhood of the support of the data distribution .
\label{ass1}
\end{assumption}

Besides, we define 

Then we define a manifold over the parameter space of  and  as follows:

Here we use  to denote the generator parameterized by . To state the second assumption, we need

Then we provide the second assumption by follow~\citet{mescheder2018training} as follows:
\begin{assumption}
There are -balls around  and  around  and , such that  and  define -manifolds. Moreover, the following conditions hold:
\begin{itemize}
    \item if  is not in the tangent space of  at , then we have .
    \item if  is not in the tangent space of  at , then we have .
\end{itemize}
\label{ass2}
\end{assumption}


The validness of GAN's training dynamics requires the following assumption:
\begin{assumption}
	The functions , ,  requires the following conditions:
	\begin{itemize}
		\item ,  and .
		\item .
	\end{itemize}
	Here  denotes the absolute value.
	\label{ass3}
\end{assumption}


The formal statement of Theorem 1 is given as follows:
\setcounter{theorem}{0}
\begin{theorem}
	Assume the assumptions \ref{ass1}, \ref{ass2} and \ref{ass3} hold for  and . For small enough learning rate and , training GANs with objectives formulated in Eqn. (19) and the regularization term in Eqn. (25) ensures locally convergence with alternative gradient descent.
\end{theorem}

\begin{proof}
	The gradient flow defined by GAN's objective function is given as:
	
	Here we have:
	
	and 
	
	
	Then the Jacobian matrix of the gradient flow is:
		
	Note that at the equilibrium point , we have  around the support the data distribution. Therefore, we have  and  for . It is easy to verify that , i.e., , is a zero matrix. Similar, we have:
	
	and
	
	Since , we have .
		
	Note that with sufficient small learning rate, we have  around the equilibrium. Then we provide the gradient flow and it's Jacobian matrix of the regularization term 
	
	Since  is simply a function of ,  is a zero vector. The Jacobian matrix of the regularization term is given as:
	
	
	With the Jacobian matrix of the regularized dynamics formulated as:
	
	We can directly follow the proof of Theorem 4.1 in~\citet{mescheder2018training} in Appendix D.
\end{proof}



\subsection{Interpreting CLC-GAN in the parameter space}
In this paper, we mainly analyze our proposed method in the function space, including dynamic analysis and controller designing. Instead, our proposed method can also be interpreted as certain regularization terms on the Jacobian matrix of the training dynamics. Below we provide a formal demonstration.

First, we denote the equilibrium of  and  as , where  and  for all . Note that  is also a global minimum point of the regularization term . Then we have .

We denote  as the objective function of the minimax optimization problem in WGAN without CLC regularization. Then the Jacobian matrix of the training dynamic can be denoted as:

Because of the linearity of the derivation operation, the training dynamics of the WGAN with CLC regularization is denoted as:

where we abuse the  to denote the zero matrix with certain size to match the size of .
Since , we have . Therefore, the CLC regularization introduces a negative semi-definite matrix to the original Jacobian matrix, which is helpful to stabilize the training dynamics of GANs.


\section{Understanding Existing Work as Closed-loop Control}


A side contribution of this paper is to understand existing methods~\cite{gidel2018negative} uniformly as certain CLC controllers.
The momentum is an example where \citet{gidel2018negative} provide some theoretical analysis of momentum in training GANs. Here we re-analyze the momentum using Dirac GAN under the perspective of control theory. 

The momentum method~\citep{qian1999momentum} is powerful when training neural networks, whose theoretical formulation is given by:

where  is the input of 's dynamic, i.e., .
The  is the coefficient for the exponential decay.
However, momentum instead is not helpful when training GANs~\cite{radford2015unsupervised,mescheder2018training,brock2018large,gulrajani2017improved} where smaller  or even zero is recommended to achieve better performance.




In control theory, the momentum is equivalent to adding an exponential decay to the input of the dynamics~\citep{an2018pid}:

The LT of an exponential decay dynamic is , i.e., .  denotes the decay coefficient which depends on .
Therefore, we can formulate the dynamics of Dirac GAN in the following:

By applying LT, we have  and  can be represented as:

With a positive , there is at least one pole of this dynamic whose real part is larger than , indicating the instability of the dynamics for GANs with momentum.
The result is consistent with~\cite{gidel2018negative}.




















\section{Further Experimental Results on Synthetic Data}

\begin{figure*}
    \centering
    \includegraphics[width=\textwidth]{results_TOY.pdf}
\caption{The generated samples for mixture of gaussian distribution. The red points demonstrate the location of data distribution and the blue points are generated samples. Each distribution is plotted using kernel density estimation with 50,000 samples. }
    \label{fig:result_toy}
\end{figure*}

In this section, we evaluate our proposed method on a mixture of Gaussian on the two dimensions. The data distribution consists of  2D isotropic Gaussian distributions arranged in a ring, where the radius of the ring is , and the deviation of each component Gaussian distribution is . For the coefficient , we follow the setting in the spectral normalization as . We adopt two-layer MLPs for both the generator and the discriminator which consist of  units. The batch size is is 512.

The generated results are illustrated in \fig{result_toy} and we further provide the dynamics of the generator distribution in \fig{dynamic_toy}. As we can see, the unregularized WGAN and SGAN suffer from severe model collapse problem and cannot cover the whole data distribution. Besides, the oscillation can be observed during the training process of WGAN: the generator distribution oscillates among the modes of data distribution.
Our method can successfully cover all modes compared to the WGAN and SGAN and the dynamics are converged instead of oscillation.



\begin{figure*}
    \centering
    \includegraphics[width=\textwidth]{Dynamics_toy.pdf}
    \caption{The training dynamics of various GANs on synthetic data.}
    \label{fig:dynamic_toy}
\end{figure*}
























\end{document}
