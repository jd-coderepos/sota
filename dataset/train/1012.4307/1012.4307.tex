\documentclass[mathpazo]{cicp}
\usepackage{color}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{amsthm}
\usepackage{amsfonts}
\usepackage{graphicx}

\usepackage{algorithm}
\usepackage{subfigure}
\usepackage{units}
\usepackage{multirow}
\usepackage{graphicx, epsfig}

\usepackage{bm}
\usepackage[colorlinks=true]{hyperref}
\newtheorem{thm}{Theorem}[section]
\newtheorem{cor}[thm]{Corollary}
\newtheorem{lem}[thm]{Lemma}
\newtheorem{prop}[thm]{Proposition}
\newtheorem{alg}[thm]{Algorithm}
\newtheorem{ex}[thm]{Example}
\theoremstyle{definition}
\newtheorem{model}[thm]{Model problem}
\newtheorem{defn}[thm]{Definition}
\newtheorem{rem}[thm]{Remark}
\newtheorem{conj}[thm]{Conjecture}
\numberwithin{equation}{section}
\def\bsA{\boldsymbol{A}}
\newcommand{\theHalgorithm}{\arabic{algorithm}}
\newcommand{\ol}[1]{\mbox{}}


\providecommand{\wv}{}
\providecommand{\hbz}{}
\providecommand{\edt}{}
\begin{document}
\title[Iterative solution of Sch\"odinger equation]{A preconditioned iterative solver for the scattering solutions of the Schr\"odinger equation}



\author[Hisham bin Zubair et.~al.]{Hisham bin Zubair\affil{1}\comma\corrauth, Bram Reps\affil{2}, and Wim Vanroose\affil{2}}
\address{\affilnum{1}\ Department of Mathematical Sciences, Faculty of Computer Science, Institute of Business Administration, University Rd., 75270 Karachi, Pakistan. \\
\affilnum{2}\ Department of Mathematics and Computer Science, Universiteit Antwerpen, Middelheimlaan 1, B-2020 Antwerpen, Belgium.}
\emails{\\{\tt h.binzubair@gmail.com} (H.~bin Zubair) \\ {\tt bram.reps@ua.ac.be} (B.~Reps) \\ {\tt wim.vanroose@ua.ac.be} (W.~Vanroose)}





\begin{abstract}
The Schr\"odinger equation defines the dynamics of quantum particles which
 has been an area of unabated interest in physics. We demonstrate how simple 
transformations of the Schr\"odinger equation leads to a coupled linear system,
 whereby each diagonal block is a high frequency Helmholtz problem. Based on this model, 
we derive indefinite Helmholtz model problems \hbz{with strongly varying wavenumbers. We employ the iterative approach for their solution. In particular, we develop} a  preconditioner that has its spectrum restricted to a quadrant \hbz{(of the complex plane) thereby making 
it easily invertible by multigrid methods with standard components. This multigrid preconditioner is used in conjuction with suitable Krylov-subspace methods for solving the indefinite Helmholtz model problems. The aim of this study is to report the feasbility of this preconditioner for the model problems.} We compare this idea with the other prevalent preconditioning ideas, \hbz{and discuss its merits}. Results of numerical experiments are presented, which complement the proposed ideas, and show that this preconditioner may be used in an automatic setting.
\end{abstract}




\keywords{Scattering, Schr\"odinger equation, Exterior Complex Scaling, Preconditioning, Multigrid,
 Complex-shifted Laplacian (), Complex-scaled Grid (), Quadrant-definite ()}
\maketitle


\section{Introduction}
\label{sec1}
Acoustic, electromagnetic or seismic waves can all be modeled by a
Helmholtz equation with a wave number that has properties specific to
the problem area.  In some acoustic scattering applications, for
example, the wave number is space independent but the boundary of the
domain can be very complicated depending on the shape of the object.
In electromagnetic scattering there are jumps in the material
parameters which lead to a piecewise constant wavenumber.  In a
similar way, the wavenumber in seismic waves will contain information
about the geological layers in the earths crust.  Each of these
problems pose different challenges to the numerical methods.

In this article, we focus on the iterative solution of the Helmholtz
equations with a wave number that is specific to models for breakup
problems in chemical systems. These breakup dynamics are described by
a Schr\"odinger equation that reduces, in the energy range of breakup
problems, to Helmholtz equation with a wavenumber that is continuous
in the space variables and can become very large near the boundary of
the domain. One example is the disintegration into four charged
particles of the H molecule when it is hit with a single photon
\cite{Wim05}.

The \hbz{prevalent practice for solving this type of problem} requires massively parallel
computers \cite{taylor2002computational} and \hbz{they use}
a significant portion of the resources of large computer
facilities.  The long term aim of \hbz{this research} is
to replace this practice by efficient iterative methods.

The Helmholtz equation \hbz{has often} outgoing wave boundary conditions.
Fixing homogeneous Dirichlet boundary conditions, on the boundaries of
the truncated numerical domain, leads to artificial reflections in the
domain of interest. These reflections are numerical errors and must be
diminished by damping the outgoing waves at the domain boundaries. To
bring this about in our numerical solution method, we employ {\it
  exterior complex scaled} \cite{S79} absorbing boundary layers
(henceforth ECS-ABL). There is a long history of this type of
absorbing boundary condition for chemical reactions
\cite{moiseyev1998}. This treatment is equivalent to the use of
perfectly matched layers (PML) \cite{B94,CW94} and leads to a
non-Hermitian discrete problem \cite{reps2009}.  For a review on
transparant and absorbing boundary conditions for the Schr\"odinger
equaton we refer to \cite{antoine2008review}.
  
For \hbz{Krylov-subspace methods, the main challenge is to} find a good preconditioner.
Over the years there have been different approaches to preconditioning the \hbz{indefinite} Helmholtz equation. One line of research is based on a shifted Laplacian preconditioner that started with the work \cite{Bayliss83, Bayliss85} ( Bayliss, Goldstein and Turkel).  
They used the Laplacian and the positively shifted Laplacians as preconditioner. 

This was later successfully generalized into a robust method, known as
the {\it complex shifted laplacian} () preconditioner, by Erlangga,
Vuik and Oosterlee using complex valued shifts in
\cite{Yogi04,Yogi06}. Introducing a complex shift pushes the spectrum
of the Helmholtz operator into a region \hbz{that is favorable} for multigrid methods \cite{Achi77,Stu82,Trot01} to
approximately invert the preconditioning problem. It is well-known that multigrid efficiency can readily be exploited \hbz{only} for problems having (positive or negative) definite \hbz{spectra}. In the indefinite case \cite{Trot01}, both vital components of multigrid, i.e., smoothing, and coarse grid correction suffer severe degradation, and consequently this results in
divergence of the method \cite{EEL01}.

An alternative preconditioner that, in addition to shift, also scales
the Laplacian was derived from frequency shift time integration by
Meerbergen and Coyette \cite{meerbergen2009}.  By appropriately
choosing the shift and the scale it is possible to restrict the
spectrum of preconditioning matrix into one quadrant of the complex
plane.  We call this type of preconditioner a {\it quadrant definite}
() preconditioner.

In \cite{reps2009}, we proposed the {\it complex-scaled grid}\, () preconditioner, 
and demonstrated its utility in connection with indefinite Helmholtz 
problems constructed with ECS-ABL. Both the  and the  preconditioners have similar performance 
and are based on similar ideas. The  \textit{translates} the spectrum, while the  \textit{rotates}
 it, \hbz{thereby placing it in a region which is multigrid favorable}. Both of these preconditioners depend on the 
translation magnitude or the rotation angle which has to be tuned for specific problems. 

This paper \wv{studies} a preconditioner based on a scaled translation
of the spectrum \wv{that} restricts it to one quadrant of the complex
plane. \wv{We evaluate it on a set of model problems representative for
breakup problems that are derived in the paper.}  \hbz{While its efficiency is found to be between that of the Laplacian
preconditioner and the / preconditioners, the main merit is its ease of invertibility by multigrid methods that use well-known standard components. This is a clear advantage of using the  method, as for the / preconditioners, multigrid has to be tuned for different wavenumbers. Moreover, a shift for the  preconditioner (or equivalently, a rotation angle for the  preconditioner) is apparantly only available through a hit-and-trial rule. In comparison, the  preconditioner may be used in an automatic setting.}

\wv{Both the discretisation and the absorbing boundary conditions used
  in this paper are of low order of accuracy. Both can be replaced by
  higher order methods, however, the focus of the paper is on the
  working of the iterative methods and this can be studied with the
  low order methods since the higher order discretisation and
  boundary conditions have similar spectral properties.}

In Section \ref{sec:derive}, we give the transformation of the
Schr\"odinger equation to a coupled Helmholtz problem, and derive the
model problems for this study. The details of ECS-ABL and \hbz{the discretization} are given in Section \ref{sec:discretize}. Also reviewed
here, are the spectral properties of the discrete operator. Next, in
Section \ref{sec:precmg}, we describe the  preconditioner in detail,
and give the multigrid algorithm which we use for approximate
inversion of the preconditioners. This is followed by numerical
experiments, which are given in Section \ref{sec:numex}. Some
conclusions mark the end of the paper in Section \ref{sec:conclude}.
 
\section{From the Schr\"odinger equation to a coupled Helmholtz problem}
\subsection{The model problem}
\label{sec:derive}
In this section we derive the model Helmholtz problem that we use in
this paper to benchmark iterative solvers.  The model problem is \wv{

where  ABC denotes outgoing wave boundary conditions, see Section \ref{sec:discretize}, and 
}

\wv{ 
denotes the radial part of the Laplacian in spherical coordinates with , .
The wavenumber  depends on a potential
 that} \hbz{varies continuously in} \wv{ and }
\hbz{in the domain }\wv{ ,   is the energy and  is the mass of the system.  The right hand side  is assumed
to be zero outside  with  so that the Helmholtz problem becomes a
 homogeneous problem  in a strip near the boundaries with the ABC.}
\subsection{The Schr\"odinger equation}
To derive this model we start from the driven Schr\"odinger equation

\wv{with , } and where  denotes the Hamiltonian and is given by

with  and  local potentials that only depend on magnitude of
. The potential  depends, \wv{usually,} on the relative
distance between  and . \wv{The mass  scales the Laplacians.} The right hand
side of \eqref{eq:schrodinger}, \wv{,
 is assumed zero if  or ,} and can
model an incoming electron that impacts in the system \cite{rescigno1999}, \hbz{or alternately, represents the dipole operator working on a groundstate if the model is used to compute photo-ionization \cite{Wim05}}. 

For these breakup problems the solution
 is  an outgoing wave in any
direction similar to the Sommerfeld radiation condition.  This leads to a six dimensional problem on an unbounded
domain.  The problem can also be interpreted as a 6D Helmholtz problem

where  with 
denotes the sum of all potentials.  This becomes a Helmholtz problem
with a constant wave number, , in the regions of space
where the potentials go to zero. This  6D problem is hard to solve with the current generation of numerical methods.

\subsection{Expansion of the solution in partial waves.}
In this section we discuss the reduction of the 6D problem to a
coupled set of 2D problems.  At large distances \hbz{the} solution behaves as
a spherical \hbz{wave} emerging from the center of mass of the system.  It
is therefore common practice \cite{baertschy2001,vanroose2006double}
to rewrite the equation \eqref{eq:schrodinger} in spherical
coordinates.  \wv{The Laplacian operator then splits into a radial
operator and the angular operator differential  \cite{arfken}.}  The coordinates are
written as  and , where  denotes .
\wv{The solution is then written} as a series

where  are the spherical harmonics, \wv{the
  eigenfunctions of the angular differential operator of the Laplacian
  in spherical coordinates \cite{arfken}.  In physics this decomposition is referred
  to as the partial wave expansion and the functions
   are called partial waves.}

When this proposal, \eqref{eq:proposal}, is \hbz{substituted} in \eqref{eq:schrodinger} we find
an equation for  for all
 that is
coupled to all other partial waves.

where the coupling potentials are calculated as

and  is partial wave of the right hand side.

When the potentials ,  and  are spherical\hbz{ly} symmetric
the system decouples. When it is c\hbz{y}lindrical\hbz{ly} symmetric the different
 and  are decoupled. \wv{But in general the system is fully coupled.} Furthermore, it is common practice to
truncate the infinite series in  at a finite  so that it
becomes a finite system of coupled partial differential equations.


\wv{ The boundary conditions \hbz{for Equation} \eqref{eq:schrodinger} translate in spherical coordinates into
  homogeneous Dirichlet  for all  and
   for all .  \wv{This is typical for radial problem since  and  is now the origin of the coordinate system \cite{arfken}.} The outgoing boundary conditions
  translate then into outgoing boundary conditions  or . We will \hbz{elaborate on this
  topic in Section \ref{sec:discretize}}.}

\wv{The partial wave expansion can also be written down for a single
  particle Hamiltonian. It then involves an expansion over \hbz{a} single
  angular function  \hbz{and subsequently} leads to a coupled system of
  ordinary differential equations. On the other hand, the Hamiltonians
   currently studied in the physics and chemistry communit\hbz{ies involve}
  three or more particles.  For three particles the driven
  Schr\"odinger equation is a 9-dimensional equation that, after
  expansion in partial waves, becomes a set of coupled 3D PDEs.}

\subsection{Blocked structure and Iterative methods}
The system \eqref{eq:coupled} has a very particular structure.  Since
the differential operators are block diagonal in the spherical
expansion, they only appear on the diagonal blocks of the
equation. The blocks are only coupled by the potentials \wv{defined in
  equation \eqref{eq:coupled_potential}}. \wv{The Hamiltonian
   can be written in blocked matrix notation as
}
where the  are the radial differential operators
defined in \eqref{eq:definition_delta}. This can be written as a
coupled Helmholtz operator  \wv{}

After discretization of the differential operators on a grid \hbz{discussed in detail in Section \ref{sec:discretize}, we arrive at a system of linear equations,} . The matrix \hbz{} will have the same blocked structure as the coupled system of partial differential equations above and we can write:

where the discretized differential operators will only appear in the
diagonal blocks . Since the differential operators
will lead to the largest eigenvalues, the condition number of the full matrix  will also be determined
predominantly by the diagonal blocks . \edt{
After discretization of
 on  grid points and  on  grid points, a single
block is a sparse matrix of size . }

\hbz{The solution method for solving this type of breakup problems as employed in \cite{Wim05} is iterative. This method was developed in \cite{baertschy2001solution} and exploits the particular block structure of .} A block diagonal preconditioning matrix  is constructed that contains only the diagonal blocks .  Since the largest eigenvalues and eigenvectors of  and  are very similar,  has a smaller condition number, \hbz{and therefore,  proves to be a good preconditioner for any suitable Krylov-subspace method. However, note here in particular, that the strategy in used in \cite{Wim05} is to exactly invert the blocks \edt{(each of size )} within the preconditioning step. Inasmuch as each diagonal block represents a two-dimensional system, the diagonal block matrices can be inverted \edt{possibly} on a single processor. The coupled system, however, requires the inversion of many diagonal blocks and requires a cluster.}

\wv{
However, the problems currently under investigation in the physics and
chemistry communities such as the impact-ionization problems or
problems where electronic motion and nuclear motion are combined
described in section \ref{sec:impactionisation}, each diagonal block
\hbz{constitutes} a three dimensional problem and \hbz{renders itself too unwieldy for exact inversion}}. 

We therefore study in this paper the \hbz{multigrid-preconditioned iterative solution of the diagonal block only, and not the entire problem as a whole. The diagonal blocks \eqref{eq:blocked} corresponds closely to the model problem \eqref{eq:modelproblem}. It is important to understand that the complete process now involves two independent iterative schemes, the outer scheme for approximately inverting the entire system via a preconditioned Krylov process, and the inner iterative scheme which uses multigrid preconditioning for approximately inverting the diagonal blocks within the outer preconditioner. The latter alone forms the subject matter of this paper. We have chosen to restrict the dimensions to two for this study.}


\subsection{Examples}
\wv{To illustrate the significance of the coupled system of partial
differential equations we give a few example physical systems that are
currently studied with the approach. We cite the relevant papers.}
\subsubsection{The dynamics of two electrons in  a Helium atom}
The Helium atom is a quantum system that has two electrons with a negative charge
and one nucleus \hbz{which} has a positive charge of unit two.
Since the nucleus is much heavier than each electron, the position of the
nucleus is taken as the center of the coordinate system.
In this coordinate system the first electron is at  and the second electron at
 The potentials in equation \eqref{eq:schrodinger} are then

To arrive at the potentials in the coupled problem \eqref{eq:coupled_potential} the multipole expansion

is used to expand . Where  and  denote,
respectively, the smallest and largest of  and . The
angle  is between the vectors  and
.  Since  and  are central potentials they
will appear as  and  on the diagonal blocks of
\eqref{eq:coupled_potential} when  and
.  The multipole expansion \eqref{eq:multipole},
however, will lead to potentials that couple the blocks with different
 values in equations \eqref{eq:coupled}.  Since the problem is
symmetric around the  axis, different  blocks are
decoupled. Recent processes in Helium studied with this approach are
one and two-photon double ionization
\cite{mccurdy2004theoretical,horner2007two}.

\subsubsection{The dynamics of two electrons in the Hydrogen molecule}
The Hydrogen molecule consist of two negatively charged electrons and
two protons with a positive charge. The two protons are much heavier
than the electrons.  After the Born-Oppenheimer approximation \wv{the two protons can be considered fixed in space}. The
dynamics of the two electrons are governed by equation
\eqref{eq:schrodinger}, where the potential is given by the static
field of the charged protons.  If we take a coordinate system around
the center of mass of the protons and  is the vector
connecting the two protons \wv{and  and  the coordinates of the electrons}, the potentials in \eqref{eq:schrodinger}
are


The first is the attraction of the first electron to the two
protons. The second is the same attraction but for the second
electron.  The third potential is the electron-electron repulsion
because both have a negative charge.  To derive the potentials in the
coupled basis we use, again, the multipole expansion
\eqref{eq:multipole} for each of the potentials.  \wv{Now all potentials 
couple the blocks.}  Again, an example of a process studied in this
approach is one-photon double ionization \cite{Wim05}.

\subsubsection{Impact ionization of Helium or the Hydrogen molecule}\label{sec:impactionisation}
  When an \wv{additional} electron with sufficient energy collides and breaks up the
  Helium atom or Hydrogen molecule \wv{that have already two electrons, we are tracking three particles}. We then have a 9D problem.
  If we denote the coordinate of the third, impacting, electron as
   we end up with Helmholtz operator

After \wv{the partial wave expansion} we end up, again, with a coupled problem 

where  is a diagonal block potential while
 couples the blocks.  Because of the scale of
these problem there are currently no converged results for this
problem.  A similar high dimensional problem can be formulated for
Hydrogen molecule when no Born-Oppenheimer approximation is applied.
Then the motion of the electrons,  and
, is coupled to the motion of the protons
.  \wv{Solving these problems is a great interest in the
scientific community.}

\section{Discretization}\label{sec:discretize}
\subsection{Absorbing boundary conditions}
In order to solve equations, such as the Helmholtz equation, defined on an unbounded domain  numerically, an assumption is made on the asymptotic behavior of the solution. The truncated computational domain is a bounded subset  of the original one, with artificially introduced boundary conditions that imply the postulated asymptotic behavior. A commonly used example are the first order Sommerfeld radiation boundary conditions applied to the homogeneous Helmholtz problem, , where  is the outward normal on the boundary . An exponential decay of the solution depending on the constant wave number  is assumed towards the boundary.

In more complicated Helmholtz models such as the one derived from the Schr\"odinger equation \eqref{eq:modelproblem} more robust techniques are preferable. In the \emph{perfectly matched layer} (PML) approach \cite{B94} a small boundary layer  is added beyond any point of domain truncation. On this finite layer the continuous model is adapted to capture the asymptotic behavior, with trivial boundary conditions at the end of the layers . This idea is equivalent to a complex coordinate stretching \cite{CW94,R95,TC98} in the boundary layers, where the original equation is used in the new coordinate system  with homogeneous Dirichlet boundary conditions at the end , also known as \emph{exterior complex scaling} (ECS) \cite{NB78,S79}. In general we can define an analytic continuation on the layers by

with  increasing (e.g. linear, quadratic, \ldots) and . We
denote the image of the layer  and call it the \emph{complex contour}. This boundary layer method does not need an explicit input of the wave number and it can easily be tuned in numerical experiments. Because of the straightforward mathematical meaning the ECS method is interesting in numerical analysis.

\subsection{Finite difference }
ECS boundary conditions and their application in chemical reactions
have been used in finite difference, B-spline and spectral element
discretization \cite{mccurdyTR2004}. \wv{Finite Elments methods are
  hardly used for this type of problems because the computational
  domain is often a square or a rectangular strip.} In this article we
use finite differences \wv{since this low order discretisation can
  already help us to understand the convergence of the iterative
  method.} We define a one-dimensional uniform grid  on the real interval  with  and 
and mesh width . Starting in , we apply
linear ECS, so the absorbing layer is a line connecting  and
 henceforth denoted by . A second uniform
grid  discretized this complex contour, with
 and complex mesh width . The
union of these two grids is the ECS grid

in the entire ECS domain. We will denote the fraction .
\begin{figure}[htbp!]
\begin{center}
\includegraphics[width=12cm]{fig01}\caption{Discretized ECS domain . The ECS domain is discretized with complex mesh widths on the complex contour.}\label{fig:disecs}
\end{center}
\end{figure}

A thorough numerical analysis of the negative Laplace operator  discretized on this ECS domain yields some important insights for the use of ECS on more general operators. To approximate the second derivative we \hbz{employ the following standard formula for un-equal mesh sizes, and non-uniform grids:}

for non-uniform grids in grid point , where  and  are the left and right mesh widths respectively, and may belong either to the  category or to the  category. \wv{The formula can be easily derived as \edt{an} exercise in Taylor expansions} and it reduces to regular second order central differences when , i.e., in the interior real region , and in the interior of the complex contour  because the scaling function  is taken to be linear. The only exception is the point  where at most we lose an order of accuracy, however with ample discretization steps, the overall accuracy is anticipated to match up to second order. We will denote the resulting discretization matrix .


\subsection{Spectral properties}
\wv{The hardest model problem, from a\edt{n iterative point} of view, is 
the problem with  and  since the problem is then \edt{at its} most
indefinite \edt{state}. For larger  and  the problem becomes more
definite. Therefore we focus on the remainder of the paper on the
problem with  and .}

The spectrum of the discretization matrix  determines the
convergence behavior of iterative methods such as Krylov subspace
methods and multigrid schemes for solving any system . The spectrum  is drastically different from the
spectrum  of the continuous operator, on the undiscretized
ECS grid . Indeed, , is an infinite set
of points on the complex line , with
 and  the complex angle of the
complex boundary . The shape of the spectrum  of the
discretization matrix is less obvious as follows from the next lemma,
that is proved in \cite{reps2009}.

\begin{lem}\label{lem:eigdis}
Consider the ECS grid \eqref{eq:ecsgrid} and the discretization matrix . Define . Then the eigenvalues of  are the solutions of

with , .
\end{lem}

For the Laplace problem the ECS discretized spectrum has the typical Y-shape of a pitchfork. There is a clear complex branch associated to eigenvectors located on the complex contour, along the complex line , and a branch closer to the real line  that corresponds to eigenvectors located on the real domain. The smallest eigenvalues, in the small tail of the pitchfork, belong to the smoothest eigenvectors spread over the entire ECS domain. They lie close to the smallest \edt{eigenvalue} of the continuous ECS operator  (Figure \ref{fig:dowsingrod}), that is along the complex line , where  is the complex mesh width, belonging to a straight complex grid connecting  and .
\begin{figure}[h!]
\begin{center}
\includegraphics[width=9cm]{fig02}\caption{
\wv{ The eigenvalues of the ECS Laplacian discretization matrix () lie along a pitchfork with a  shape, a result in Lemma~\ref{lem:eigdis}. 
 A part of the eigenvalues lie close to the eigenvalues the same Laplace problem restricted to the interior real domain ().  In a similar way part of the eigenvalues lie close to the eigenvalues when the Laplacian is restricted to the complex contour ().} \wv{The inset shows the area around the origin where the smallest eigenvalues are approximated by the smallest eigenvalues of the Laplace problem defined on the complex line } ().
 (color online)}
\label{fig:dowsingrod}
\end{center}
\end{figure}

\section{The  preconditioner and multigrid} \label{sec:precmg}
\subsection{The preconditioner} \label{subsec:precon}
We use a preconditioning operator that has a spectrum bounded by a single quadrant such that it 
can be approximately inverted with standard multigrid components, which are clearly unstable for indefinite problems.

In this article we compare the use of a preconditioner  which is a scaled 
and shifted version of the original Helmholtz operator  defined in equation \eqref{eq:modelproblem}.
We propose to use

where  is chosen such that  is definite. This preconditioner is very similar to the
one proposed in \cite{meerbergen2009}.
 Suppose  is that eigenvalue of the original operator  which has the smallest real part.
We can then choose  such that .  For a Helmholtz problem with a constant wave number 
\wv{and  and } this would mean that .






The eigenvalues of the preconditioned operator \wv{} lie inside a circle of radius
 centered around
.  We
can readily see this with the following arguments. The preconditioner
 has the same
eigenvectors as the . The eigenvalues of the
preconditioned system \wv{} are therefore given by

where  is an eigenvalue of \wv{}. We assume that
the eigenvalues of  are located in the lower half of the complex
plane, . Then  is
inside the circle that is the image of the real axis of the transform
\eqref{eq:eigMA}. This circle goes through ,
 and , so the
center  is the crossing point of the lines 
and ,

And so the radius is .

\subsection{Multigrid}
\label{subsec:mg}
Heuristically, we note that multigrid (for convergence and efficiency), has more stringent requirements on 
the condition number of the spectrum when it crosses into different quadrants of the complex plane, than when 
it does not. The preconditioner in Section \ref{subsec:precon} has the property that its spectrum is 
restricted to the fourth quadrant. It can therefore be very efficiently inverted by multigrid using the standard 
components, which include -Red Black Jacobi, with , Full Weighting averaging for restriction, 
Bilinear interpolation for prolongation, and rediscretization on the coarse grids; in a simple V(1,1) cycle set-up.
 For experimental purposes we compare the performance of this quadrant-definite () preconditioner with the  and 
the  preconditioners.
 In \cite{reps2009}, we showed that the  and the  preconditioner can be inverted efficiently using multigrid based on matrix components, such as ILU-smoother and the Galerkin coarse grid operator in a V(0,1) cycle set-up. This study is more focused on using matrix-free components, which leaves only the -Jacobi smoother, and the discretization coarse grid operator for the  and the  preconditioners. Moreover, this multigrid has to be employed in an F(1,1) cycle set-up. 

\begin{algorithm}
\centering {.}
\caption{\bf ~~ Multigrid pseudocode}
\label{alg:mg}
\begin{enumerate} \sf 
\item[\bf (0)] \sf  {\bf Initialization} \1.0ex]
\begin{tabular}{lll}
-- &   Compute the residual  &  \enspace.\1.0ex]
-- &   Compute the approximate error \\
   &    from the \textit{defect equation}. & \\
   &   & \\	
   &	by the following recursion& \\
\end{tabular}

\hspace*{5ex}\framebox[10cm]{
\begin{minipage}{8cm}
\vspace{2mm}
 \sf 
\hspace{-7mm}\underline{If} ,  \textbf{exact} ();  \underline{endif}\\ \sf 
\hspace{-7mm}\underline{If} , approximate  recursively:\\
\hspace{-5mm} ; \\
\hspace{-4mm}\underline{do}  to   \\
\hspace{-2mm} \underline{If}  ,\\
\hspace{1mm} \\
\hspace{-2mm} \underline{else} \\
\hspace{1mm} \\
\hspace{-2mm} \underline{endif}\\
\hspace{-4mm}\underline{continue} i\\
\hspace{-7mm}\underline{endif}
\end{minipage}}
\vspace*{2mm}

\begin{tabular}{lll}
-- & \sf  Interpolate the correction \hspace*{8ex} 
      & \enspace.\
 \mathcal{Z} &= -\Delta - k^2 & \text{MP1} \\
 \mathcal{Z} &= -\Delta - \nu(\frac{1}{e^{x^2}}+\frac{1}{e^{y^2}}) - k^2 & \text{MP2}\\
 \mathcal{Z} &= -\Delta -\frac{1}{x} - \frac{1}{y} - k^2 & \text{MP3}

 \mathcal{M}_{CSL} &= -\Delta + (\beta_1 + i\beta_2)k^2,\\
 \mathcal{M}_{CSG} &= Z, & {\scriptstyle \text{on the grid rotated by angle  in the complex plane, see \cite{reps2009}}}\\
 \mathcal{M}_{QD} &= (1-i)I + \frac{1}{\lvert \text{Re}(\lambda_0) \rvert}Z & {\scriptstyle \text{ is the eigenvalue of  with the smallest real part.}}


\hbz{ is the \textit{Complex-shifted Laplacian} as appears in \cite{Yogi06}. A small complex shift is added to the Laplacian operator. This imparts a rectangular translational effect on the operator spectrum.  is the original operator discretized on the so-called \textit{Complex-scaled Grid} and appears in detail in \cite{reps2009}. The basic mesh size has been multiplied with . This imparts a rotation to the operator spectrum about the origin by an angle equal to .  is as efficient as  in general, and slightly better for the current problems. }

\begin{table}
 \begin{tabular}{|c|c|c|c|c|} \hline 
  \multirow{2}{*}{Preconditioner} & \multicolumn{2}{c|}{Multigrid} & mg cyc. & Bi-CGSTAB\\ \cline{2-3}
 & cyc, smooth.,  & mg-conv. , \# cycles & per prec. & iter , cputime \\ \hline
 & F(1,1), -Jacobi & 0.43 , 17 & \multirow{2}{*}{1} & \multirow{2}{*}{60 , 2m 11s}\\
 &  & 4.21s & & \\ \hline
 & F(1,1), -Jacobi & 0.39 , 15 & \multirow{2}{*}{1} & \multirow{2}{*}{62 , 2m 2s}\\
 &  & 3.18s & & \\ \hline
 & V(1,1), -RB Jacobi & 0.09 , 6 & \multirow{2}{*}{1} & \multirow{2}{*}{170 , 5m 39s}\\
 &  & 1.2s & & \\ \hline
 \end{tabular}
\caption{Multigrid performance and comparison of the three precondtioners for MP1 with ,  cells in the interior region, and  cells in ECS-ABL on all four sides of the domain. ECS angle used is .}
\label{tab:exp1}
\end{table}

\begin{table}
 \begin{tabular}{|c|c|c|c|c|} \hline 
  \multirow{2}{*}{Preconditioner} & \multicolumn{2}{c|}{Multigrid} & mg cyc. & Bi-CGSTAB\\ \cline{2-3}
 & cyc, smooth.,  & mg-conv. , \# cycles & per prec. & iter , cputime \\ \hline
 & F(1,1), -Jacobi & 0.53 , 22 & \multirow{2}{*}{1} & \multirow{2}{*}{137 , 7m 34s}\\
 &  & 13.4s & & \\ \hline
 & F(1,1), -Jacobi & 0.53 , 22 & \multirow{2}{*}{1} & \multirow{2}{*}{143 , 7m 36s}\\
 &  & 14.4s & & \\ \hline
 & V(1,1), -RB Jacobi & 0.15 , 8 & \multirow{2}{*}{1} & \multirow{2}{*}{357 , 19m 40s}\\
 &  & 5.2s & & \\ \hline
 \end{tabular}
\caption{Multigrid performance and comparison of the three precondtioners for MP2 with , . The domain is a square of 50 units.  cells are used in the interior region, and  cells in ECS-ABL on the east and the north side of the domain. ECS angle used is .}
\label{tab:exp2}
\end{table}

\begin{table}[!h]
 \begin{tabular}{|c|c|c|c|c|} \hline 
  \multirow{2}{*}{Preconditioner} & \multicolumn{2}{c|}{Multigrid} & mg cyc. & Bi-CGSTAB\\ \cline{2-3}
 & cyc, smooth.,  & mg-conv. , \# cycles & per prec. & iter , cputime \\ \hline
 & F(1,1), -Jacobi & 0.32 , 13 & \multirow{2}{*}{1} & \multirow{2}{*}{60 , 3m 9s}\\
 &  & 6.45s & & \\ \hline
 & F(1,1), -Jacobi & 0.32 , 13 & \multirow{2}{*}{1} & \multirow{2}{*}{61 , 3m 10s}\\
 &  & 6.3s & & \\ \hline
 & V(1,1), -RB Jacobi & 0.17 , 8 & \multirow{2}{*}{1} & \multirow{2}{*}{164 , 9m}\\
 &  & 1.2s & & \\ \hline
 \end{tabular}
\caption{Multigrid performance and comparison of the three preconditioners for MP3 with . The domain is a square of 50 units.  cells are used in the interior region, and  cells in ECS-ABL on the east and the north sides of the domain. ECS angle used is .}
\label{tab:exp3}
\end{table}

\begin{table}
 \begin{tabular}{|c|c|c|c|c|} \hline 
  \multirow{2}{*}{Preconditioner} & \multicolumn{2}{c|}{Multigrid} & mg cyc. & Bi-CGSTAB\\ \cline{2-3}
 & cyc, smooth.,  & mg-conv. , \# cycles & per prec. & iter , cputime \\ \hline
 & F(1,1), -Jacobi & 0.32 , 13 & \multirow{2}{*}{1} & \multirow{2}{*}{210 , 18m 20s}\\
 &  & 15.8s & & \\ \hline
 & F(1,1), -Jacobi & 0.31 , 12 & \multirow{2}{*}{1} & \multirow{2}{*}{160 , 14m 14s}\\
 &  & 14.6s & & \\ \hline
 & V(1,1), -RB Jacobi & 0.13 , 7 & \multirow{2}{*}{1} & \multirow{2}{*}{545 , 46m 40s}\\
 &  & 9.4s & & \\ \hline
 \end{tabular}
\caption{Multigrid performance and comparison of the three precondtioners for MP3 with , The domain is a square of 75 units.  cells are used in the interior region, and  cells in ECS-ABL on the north and the east sides of the domain. ECS angle used is .}
\label{tab:exp4}
\end{table}

\begin{figure}
\centering
\subfigure[Solution computed in Exp. 1]{\psfig{figure=fig04, width=6cm}}
\subfigure[Solution computed in Exp. 2]{\psfig{figure=fig05, width=6cm}}\\ 
\subfigure[Solution computed in Exp. 3]{\psfig{figure=fig06, width=6cm}}
\subfigure[Solution computed in Exp. 4]{\psfig{figure=fig07, width=6cm}}
\caption{All these four solutions were computed for each of the 4 numerical experiments listed in the tables. The first solution as spherical waves ensuing out from the domain center. The other three solutions show evanescent waves, also known as single ionization, near the west and the south boundaries of the domain. At these edges the spatially dependent wavenumber grows exponentially in the model problems. (color online)}
\label{fig:solplots}
\end{figure}

\hbz{Numerical experiment results are reported for multigrid invertibility of the preconditioner and the observed efficiency of preconditioned Bi-CGSTAB. Multigrid invertibility is reported as the average multigrid convergence factor (mg-conv.) and the total number of cycles that the algorithm required to converge for the preconditioner taken as a stand-alone problem. mg-conv. is actually the geometric mean of the observed residual decay \edt{rates during multigrid cycles}, computed over the last  cycles. The CPU-time is also reported. Bi-CGSTAB efficiency takes into account the number of iterations of the algorithm for convergence. Note that each Bi-CGSTAB iteration has two embedded multigrid cycles for preconditioning, i.e., one in each preconditioning step. The overall solution time is given as well.}

Results of the first experiment are listed in Table \ref{tab:exp1}. It is important to clarify that beating the  or the  precondtioner is not the aim of this work. We rather focus on obtaining a preconditioner which can come in close comparison to them in performance, and is comparatively much easier to invert. The  preconditioner takes around 3 times the number of iterations compared to the other choices. For this model problem (only) we also found that feeding in the preconditioner solution computed to a tolerance of \edt{10}, to the Krylov method, as the starting guess, gives us a benefit of 50 iterations.

The rest of the experiments are listed in Tables \ref{tab:exp2},\ref{tab:exp3},\ref{tab:exp4}. They depict that the  preconditioner's performance comes within a factor of 3 of the other preconditioners even with strong spatial dependence in the wavenumber. The tuning effort is also much less, in fact, the relaxation parameters, the smoothing and the grid transfer methods can all stay constant. \hbz{To date, the authors are not aware of any scientific method that minimizes the  shift or the  rotation angle for different problems, without extra overhead. Note that these tunable parameters have a pivotal role in establishing / superiority in speed over the  preconditioner. The experimental tables show the best cases for the / preconditioners after they were hand-tuned for these parameters.} This points to the possibility that the  preconditioner might be used in an automatic solver setting. We tested the  preconditioner against the Laplacian preconditioner \hbz{(which can also be used in an automatic setting)} and found the  to be much superior in performance.

For multidimensional Helmholtz operators (including the 2D operator), the critical eigenvalue  used in the  preconditioner may be obtained from a one-dimensional counterpart, as is done in the current experiments. For Helmholtz problems with piecewise constant wavenumber, the maximum discrete wavenumber value may be used as a rough approximation of . However, this is also apt to bias the  preconditioner spectrum more to the right than is really required.

\section{Conclusions and Outlook}
\label{sec:conclude}
In this paper we showed that the Schr\"odinger equation for ionization problems can be decomposed into a coupled Helmholtz problem. This diagonal blocks of this coupled system consists of two-dimensional and three-dimensional Helmholtz problems. We propose Helmholtz model problems from these diagonal blocks. The blocks have homogeneous dirichlet boundaries at one side and exterior complex scaling absorbing layers  (ECS-ABL) at the other side. Finite difference discretization (for non-uniform grids) results in a pitchfork-shaped spectrum which is largely distributed in the fourth quadrant, but also has some parts crossing over in the third. Another property is that the spectrum is rather close to the real axis, and discrete problems are thus very challenging to solve iteratively. We solved them iteratively using the preconditioned Bi-CGSTAB method and also presented the quadrant definite () preconditioner, which we derive from a time integration scheme for the Schr\"odinger equation. \edt{We tried using GMRES and restarted GMRES but found that for the current problems these methods failed to reach their superlinear convergence phase.} As a gross estimate we rate the efficiency of this preconditioner between the /  preconditioners and the Laplacian preconditioner, and it has the added advantage of having a multigrid favorable spectrum, i.e., its spectrum lies entirely in the fourth quadrant. This preconditioner can potentially be used in a automatic Helmholtz solver.  \wv{The advantage of the  preconditioner is that \edt{it} can be \edt{built} from standard multigrid components and it can be \edt{implemented} matrix-free which significantly reduces the memory use}.

\wv{Although we have used a low order discretization  of the differential operators and a low order absorbing boundary conditions, we believe that calculations with higher order methods will lead to \edt{similar} conclusions on the performance of the iterative method.}

Helmholtz problems, from an iterative perspective, can roughly be categorized into two classes which can be defined according to the available computational resources. One, where storing matrix operators is a possibility, and the other, where an iterative solution might have to be worked out using vectors alone. In the first situation, ILU(0) smoothing, and the Galerkin coarse grid operator used in a V(0,1) cycle render a very attractive multigrid method for preconditioner inversion. 

However, for the other class, the situation is comparatively much worse. First, for all preconditioners with a spectrum that leads to an efficient Krylov-subspace convergence, there is no appropriate smoother for multigrid.  Second, we have to do with re-discretizing the Helmholtz operator on the coarse grid. This seems to work with non-standard F-cycles (with multiple coarse grid recursions), which are expensive. In future, we intend to investigate, how smoothing may be enhanced for matrix-free Helmholtz solution contexts, as well as how to bring multigrid down to work in V cycles for preconditioner inversion. 
\section*{Acknowledgments}
This research was funded partially by \textit{Fonds voor Wetenschappelijk Onderzoek (FWO Belgium)} projects G.0174.08 and 1.5.145.10, by the \textit{Universiteit Antwerpen}, and by the Institute of Business Administration, Karachi, Pakistan. We wish to thank the sponsors sincerely for their support.

\bibliographystyle{elsarticle-num}
\bibliography{zubair}

\end{document}
