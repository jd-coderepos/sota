\documentclass{tlp}
\pdfoutput=1






\usepackage{xspace}
\usepackage{latexsym}
\usepackage{amssymb}   \usepackage{amsmath}

\usepackage{ifthen}
\newboolean{commentsaon}         \setboolean{commentsaon}{true}
  \setboolean{commentsaon}{false}  

\newboolean{commentson} \setboolean{commentson}{true}


\newcommand{\comment}[1]
{\ifthenelse{\boolean{commentson}\AND\boolean{commentsaon}}
   {{\par\noindent\mbox{}{\small\blue[ *** #1 ]\par}\noindent\par}}{}}

\newcommand{\commenta}[1]
{\ifthenelse{\boolean{commentsaon}}
   {{\par\noindent\mbox{}{\small\color[rgb]{0, .5, 0}[ *** #1 ]\par}\noindent\par}}{}}


\usepackage[ddmmyyyy]{datetime}
\renewcommand{\dateseparator}{-}

\renewcommand{\today}{18-04-2017}

\pagestyle{myheadings}
\markboth{\today}{\today}






\newcommand{\myhalfmagnification}{0.003}



\addtolength{\textheight}{\myhalfmagnification\textheight}
\addtolength{\textheight}{\myhalfmagnification\textheight}

\addtolength{\topmargin}{-\myhalfmagnification\textheight}
\addtolength{\oddsidemargin}{-\myhalfmagnification\textwidth}
\addtolength{\evensidemargin}{-\myhalfmagnification\textwidth}


\usepackage{color}
\newcommand\blue     {\color{blue}}
\newcommand\red     {\color{red}}

\usepackage{hyperref}
\usepackage[hyphenbreaks]{breakurl}
\usepackage{pgf}



\newtheorem{theorem}{Theorem}
\newtheorem{corollary}[theorem]{Corollary}
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{proposition}[theorem]{Proposition}
\newtheorem{example}[theorem]{Example}
\newtheorem{definition}[theorem]{Definition}


\newcommand{\PARAGRAPH}[1]{\paragraph{#1}
}

\newcommand*{\seq}[2][n]  {{#2_{1}, \allowbreak \ldots, \allowbreak #2_{#1}}}

\newcommand*{\notmodels}{\mathrel{\,\not\!\models}}
\newcommand*{\partto}{\hookrightarrow}





\newcommand*{\mydash}{{\mbox{\tt-}}}
\newcommand*{\HU}{{\ensuremath{\cal{H U}}}\xspace}
\newcommand*{\HB}{{\ensuremath{\cal{H B}}}\xspace}
\newcommand*{\TU}{{\ensuremath{\cal{T U}}}\xspace}
\newcommand*{\TB}{{\ensuremath{\cal{T B}}}\xspace}
\newcommand*{\M}{{\ensuremath{\cal M}}\xspace}

\usepackage[mathscr]{euscript} 
\renewcommand*{\S}{{\ensuremath{\mathscr S}}\xspace}

\newcommand*{\NN}{{\ensuremath{\mathbb{N}}}\xspace}

\newcommand*{\mylonger}[1]{\makebox[0pt][l]{#1}}



\title[Logic + control]
{Logic + control:  \\ 
  On program construction and  verification}




\author[W. Drabent]
    {
W{\l}odzimierz Drabent\\        
         Institute of Computer Science,
         Polish Academy of Sciences
\\
IDA, Link\"oping University, Sweden \\
         {\tt drabent\,{\it at}\/\,ipipan\,{\it dot}\/\,waw\,{\it dot}\/\,pl}
}

\submitted{\dots }
\revised{\today }
\accepted{\dots }


\begin{document}
\maketitle


\begin{abstract}
This paper presents an example of formal reasoning about the semantics of a
Prolog program of practical importance (the SAT solver of Howe and King).
The program is treated as a definite clause logic program with added control.
The logic program is constructed by means of stepwise refinement, hand in
hand with its correctness and completeness proofs.
The proofs are declarative -- they do not refer to any
operational semantics. 
Each step of the logic program construction follows a systematic approach to
constructing programs which are provably correct and complete.
We also prove that correctness and completeness of the logic
program is preserved in the final Prolog program.
Additionally, we prove termination, occur-check freedom and non-floundering.


Our example shows how dealing with ``logic'' and with ``control'' 
can be separated. 
Most of the proofs
can be done at the ``logic'' level, abstracting from any operational semantics.

The example employs approximate specifications; they are crucial in
simplifying reasoning about logic programs.
It also shows that the paradigm of semantics-preserving program
transformations may be not sufficient.  
We suggest considering transformations which preserve correctness and
completeness with respect to an approximate specification.

\end{abstract}
\begin{keywords}
logic programming,
declarative programming,
program completeness,
program correctness,
specification,
program transformation,
floundering,
occur-check

\end{keywords}


\section{Introduction}

The purpose of this paper is to show that 1.~the correctness-related
issues of Prolog programs can, in practice, be dealt with mathematical
precision, 
and 2.~most of the reasoning can be declarative
(i.e.\ not referring to any operational semantics,
in other words depending only on the logical reading of programs).
We present a construction of a useful Prolog program.
We view it as a logic program with added control
\cite{DBLP:journals/cacm/Kowalski79}. 
The construction of the logic program is guided by
(and done together with)
a proof that the program conforms to its specification.
The Prolog program is obtained from the logic program by adding control.
We prove that adding control preserves the conformity with the specification.
The proofs follow the approach presented and discussed in
\cite{drabent.tocl16}. 
   We believe that the employed proof methods are not difficult and can be used
in actual practical programming.




 

The notion of partial correctness of programs
(in imperative and functional programming) 
divides in logic programming into correctness and completeness.
Correctness means that all answers of the program are compatible with the specification,
completeness -- that the program  produces all the answers required by the
specification. 
A specification may be {\em approximate}\/:
 for such a specification
some answers are allowed, but not required to be computed.
The program construction presented in this paper illustrates 
the usefulness of approximate specifications.


For proving correctness we use the method of \cite {Clark79}.
The method should be well known, but is often neglected.
For proving completeness a method of \cite{drabent.tocl16}
is used.  It introduces a notion of {\em semi-completeness}\/;
semi-completeness and termination imply completeness.
We also employ an approach from \cite{drabent.tocl16} 
for proving that completeness is preserved under pruning of SLD-trees.
We use the sufficient condition for termination
from \cite{DBLP:journals/jlp/Bezem93},
and introduce a sufficient condition for non-floundering.


 We are interested in treating logic programming as a declarative paradigm,
 and in reasoning about programs declaratively, i.e.\ 
 independently from their operational semantics.
 Correctness, semi-completeness and completeness are declarative properties
 of programs.
To prove them this paper uses purely declarative methods.
The employed sufficient condition for completeness of pruned SLD-trees
 abstracts, to a substantial extent, from details of the operational semantics.





The program dealt with in this paper is the SAT solver of 
Howe and King \citeyear{howe.king.tcs-shorter}.
It is an elegant and
concise Prolog program of 22 lines.  Formally it is not a logic program, as it includes
{\tt non{}var/1} and the if-then-else construct of Prolog;
it was constructed as an
implementation of an algorithm, using logical variables and
coroutining.  The algorithm is
DPLL
\cite{DBLP:journals/cacm/DavisLL62},
 with watched literals and unit propagation 
(see \cite{handbook-SATsolvers,howe.king.tcs-shorter} and references therein). 
Here we look at the program from
a declarative point of view.
We show how it
can be obtained by adding control to a definite clause logic program.




We first present a simple logic program of four clauses, and then
modify it (in two steps) in order to obtain a logic program
on which the intended control can be imposed.
The construction of each program begins with a specification,
describing the relations to be defined by the program.
The construction is guided by a proof of the program's
correctness and semi-completeness,
and is performed hand in hand with the proof.
We formulate a general approach to such program construction.
The control imposed on the last logic program involves modifying the
selection rule (by means of delay declarations)
and pruning some redundant fragments of the search space.
Such control preserves correctness, and we
prove that completeness is also preserved
(which in general may be violated by pruning, or by floundering). 











It is important
that logic and control are separated in the construction.
Most of the work has been done at the level of logic programs.
Their correctness and completeness could be treated formally, independently
from the operational semantics.
All the considerations related to the operational semantics,
program behaviour and efficiency
 are independent from those related to the declarative
semantics, correctness and completeness.







\paragraph{Related work.}
For an overview of work on proving correctness and completeness of logic
programs see \cite{drabent.tocl16,DBLP:journals/tplp/DrabentM05shorter}.  In
particular, little work has been done on program completeness.
The author is not aware of published correctness (or completeness)
proofs that are declarative, and deal with practical logic programs
(not smaller than the program dealt with here).\footnote{\label{footnote:nondeclarative}
The proof methods employed in
  \cite{Apt-Prolog,DBLP:journals/jlp/PedreschiR99} are not declarative. 
  In particular, they depend on the order of atoms in clause bodies.
  They prove certain properties of LD-derivations, from which 
  program correctness, in the sense considered here, follows.
  (In the case of the latter paper, also program completeness
can be concluded.)

  Similarly, the approach of \citeN{Deville} is not declarative.
Also,
  it deals with constructing programs from specifications;
  correctness and completeness follow from construction.  Thus
  reasoning about correctness or completeness of arbitrary programs is not
  dealt with.  



}
A possible exception is a correctness proof of a toy compiler 
of 7 clauses \cite{Deransart.Maluszynski93}.




A preliminary version of this article was \cite{drabent12.iclp};
that paper presented basically the same program construction, however 
some proofs presented here were missing.  In particular preserving
completeness under pruning was dealt with only informally.
The methods for dealing with completeness and correctness are presented and
discussed in \cite{drabent.tocl16}; 
here we augment that paper by a more substantial example.






Our approach differs from semantics-preserving program transformations 
 \cite[and the references therein]{PettorossiPS10shorter}.
The latter is focused on formal steps for transforming programs into more
efficient ones with the same semantics (of their main predicates).
The initial program is treated as a specification.
In our example, the role of intermediate programs is to illustrate the
informal development process, and support explaining the design decisions.
Correctness and completeness are considered for each program separately.
An interesting feature of our example is that the consecutive programs
are not equivalent -- their main predicates define different
relations, satisfying however the same approximate specification.
We argue
(Section \ref{sec:transformations})
that the paradigm of semantics-preserving transformations is inapplicable
to this case.
This suggests that it should be useful to generalize the paradigm 
to transformations which preserve
correctness and completeness w.r.t.\ an approximate specification.




\paragraph{Preliminaries.}
This paper considers definite clause logic programs
(then implemented as Prolog programs).
We use the standard notation and definitions \cite{Apt-Prolog}.
As we deal with clauses as data, and clauses of programs, the latter will be
called {\em rules} to avoid confusion.
Given a predicate symbol , by a {\em -atom} (or {\em atom for} )
 we mean an atom whose
predicate symbol is , and by a {\em rule for}  -- a rule whose head
is a -atom.
The set of the rules for  in the program under consideration is called
{\em procedure} .








We assume a fixed alphabet of function and predicate symbols.
The alphabet may contain symbols not occurring in the considered program.
The Herbrand universe (the set of ground terms) will be denoted by \HU, the
Herbrand base (the set of ground atoms) by \HB. 
For an expression (a program) 
by  we mean the set of ground instances
of  (ground instances of the rules of ).
 denotes the least Herbrand model of a program .
An expression is {\em linear} if every variable occurs in it at most once.





  By a computed (respectively correct) answer for a program  and a
  query  we mean an instance  of  where  is a computed
  (correct) answer substitution \cite{Apt-Prolog} for  and .
(So we use ``computed/correct answer'' instead of
 ``computed/correct instance of a query'' of \cite{Apt-Prolog}.)
  We often say just
   {\em answer}
as each computed answer is a correct one, 
and each correct answer (for ) is a computed answer
(for  or for some instance of ).
  Thus, by soundness and completeness of SLD-resolution,
   is an answer for  iff .


We also deal with a generalization of standard 
SLD-resolution, allowing the selection rule to be a partial function
(a {\em partial selection rule}).
Thus in some queries no atom may be selected, 
such a query is called {\em floundered}.
Obviously, such a generalization preserves correctness, but not completeness of
SLD-resolution. 
By the Prolog selection rule we mean selecting the first atom in each query.
(So most of Prolog implementations also implement other selection rules; this
is called delays or coroutining.)
LD-resolution means SLD-resolution under the Prolog selection rule.


By ``declarative'' (property, reasoning, \ldots) 
we mean referring only to the logical reading of programs, 
thus abstracting from any operational semantics.
So  being an answer for  is a declarative property.
In particular,
properties depending on the order of atoms in rules will not be considered
declarative, as the logical reading does not distinguish equivalent formulae,
like 
 and .


  Names of variables begin with an upper-case letter.
  We use the list notation of Prolog.  So 
    () stands for the list of elements .
  Only a term of this form is considered a list.
(Thus terms like , or   where  is a constant distinct
  from , are not lists).
The set of natural numbers will be denoted by \NN.

\paragraph{Outline of the paper.}
Sections \ref{sec:corr-compl} and \ref{sec:compl-pruning}
present theoretical results showing how to, respectively, prove correctness
and completeness of programs, and prove that completeness is preserved under
pruning of SLD-trees.
Sections \ref{sec:logicProgram1} and
\ref{sec:program}
develop a SAT-solver as a logic program, hand in hand with its correctness
and completeness proof.
Additionally, the latter section proves non-floundering and occur-check
freedom, and discusses semantics-preserving transformations in the context
of our example.
Section \ref{sec:prologprogram}
converts the logic program into a Prolog program with the intended control
imposed.  It also shows that the Prolog program preserves the correctness and
completeness of the logic program.
The last section contains a discussion.




\section{Correctness and completeness of programs}
\label{sec:corr-compl}
This section introduces the notions of specification, correctness and
completeness.  Then it presents a way of proving that definite logic programs
are correct and complete.  The approach is declarative.  
It does not depend on any operational semantics, and
programs are viewed as sets of logic formulae.
In particular, the reasoning is independent from the order of atoms in rules.
We conclude with presenting a way of constructing programs which are provably
correct and semi-complete.
The presentation here is rather brief,
for a more comprehensive treatment see  \cite{drabent.tocl16}.
This section lacks examples,
as the concepts introduced here are employed later on in the paper.
In particular, Section \ref{sec:logicProgram1} provides examples 
for most of the definitions and results presented here.



\subsection{The notions}
\label{subsec:notions}

\paragraph{Specifications.}
From a declarative point of view, logic programs compute relations. 
A specification should describe these relations.
It is convenient to assume that the relations are over the Herbrand universe. 
A handy way for describing such relations is a Herbrand interpretation;
it describes, as needed, a relation for each predicate symbol of the program.
\begin{definition}
  \label{def:specification}
  By a {\bf specification} we mean a Herbrand interpretation, i.e.\ a
  subset of \HB.

The relation described by a specification  for a predicate 
  of arity  is
  {}.
The atoms from a specification  will be called the 
  {\bf specified} atoms (by ).
\sloppy
\end{definition}
Obviously,
 the relations actually defined by a program  are described by its
least {Herbrand} model ; the relation for a predicate  is
{.}


\paragraph{Correctness and completeness.}
In imperative and functional programming, (partial) correctness usually means
that the program results are as specified (provided the program terminates).
  In logic programming, due to its non-deterministic nature,
we actually have two issues: {\em correctness} (all the results are
compatible with the specification) and {\em completeness} (all the results
required by the specification are produced). 
In other words, correctness means that the relations defined by the program are
subsets of the specified ones, and completeness means inclusion in the
opposite  direction. 
Formally:
\begin{definition}
\label{def:corr:compl}
Let  be a program and  a specification.
 is {\bf correct} w.r.t.\  when ;
it is {\bf complete} w.r.t.\  when .
\end{definition}
We will sometimes skip the specification when it is clear from the context.
For a program  correct w.r.t.\ ,
if a query  is an answer of  then .
(Remember that  is an answer of  iff .)
When  is complete w.r.t.\  and  is ground,
then  implies that  is an answer of . 
More generally, this implication holds for arbitrary queries such that
 implies 
(for sufficient conditions,
see \cite{DBLP:books/mk/minker88/Maher88,Apt-Prolog,drabent.tocl16,drabent.Herbrand.2016}).
In particular, the implication holds when the alphabet of function symbols is infinite.












\pagebreak[3]
It is sometimes useful to consider local versions of these notions:

\pagebreak[3]
\begin{definition}
\nopagebreak
\label{def:corr:compl:local}
\nopagebreak
A {\bf predicate}  in  is
{\bf correct} w.r.t.\  when each -atom of  is in , and 
 {\bf complete} w.r.t.\  when each -atom of  is in .

An {\bf answer}  is  {\bf correct} w.r.t.\  when .

 is {\bf complete for a query}  w.r.t.\  
when
 implies that  is an answer for ,
for any ground instance  of .
\end{definition}
Informally,   is complete for 
when 
all the answers for  required by the specification  are answers of .
Note that a program is complete w.r.t.\ 
 iff it is complete w.r.t.\  for any query
 iff it is complete w.r.t.\  for any query .

\ifthenelse{\boolean{commentsaon}}{\pagebreak[3]}{}


\paragraph{Approximate specifications.}
It happens quite often in practice that a programmer
does not know exactly the relations defined by a program
and, moreover, such knowledge is unnecessary.
For example, it is irrelevant whether 
 is an answer of a list appending program or not.
In such cases, it is
 sufficient to specify the program's semantics approximately.
More formally, to provide distinct specifications, say
 and , for completeness and correctness
of the considered program .
The intention is that  .
So the specification for completeness says what the program has to compute,
and the specification for correctness -- what it may compute;
in other words, the program should not produce any answers
incorrect w.r.t.\ the specification for correctness. 
It is irrelevant whether atoms from 
 are, or are not, answers of the program.
For example the standard \mbox{APPEND} program does not define the list
concatenation relation, but its superset
(and  is an answer of the program,
but  is not).
In this case,  describes the list concatenation relation;
see \cite{drabent.tocl16}
for   and further discussion.





\begin{definition}
An {\bf approximate specification} is 
a pair  of specifications, where
.

A program  is {\bf fully correct} w.r.t.\  
when  .
A predicate  in  is fully correct w.r.t.\ 
when each -atom of  is in ,
and each -atom of  is in .
\end{definition}
Correctness (respectively completeness) w.r.t.\ 
 will mean
correctness w.r.t.\  (completeness w.r.t.\ ). 
By abuse of terminology,
a single specification may be called
approximate when the intention is that the specification is
distinct from~.






In many cases, the atoms from  
may be (formally or informally) considered as ill-typed.
For instance, in 
terms  and  are not lists. 
In the context of typed logic programming \cite{types.lp.92-short},
the need for approximate specifications may disappear.
For instance, in an appropriate
typed logic the standard APPEND program may define the list concatenation exactly.
However in practice we usually deal with untyped logic programming.
In particular, the programming language Prolog is untyped.
See \cite{drabent.tocl16} for further discussion, including the need
for approximate specifications in typed logic programming. 





The main example of this paper employs approximate specifications.
In particular,
  various versions of the constructed program define different relations
  for the same predicate symbols, but the programs 
  are correct and complete w.r.t.\ the same approximate specification.
(More precisely, their common predicates are
fully correct w.r.t.\ the same approximate specification.)
The example shows that employing approximate specifications
results in simplifying the construction of specifications and proofs.
It is useful \cite{drabent.tocl16} in declarative diagnosis
(also known as algorithmic debugging \cite{Shapiro.book}).
For further discussion and examples see 
\cite{drabent.tocl16,DBLP:journals/tplp/DrabentM05shorter}.  












\subsection{Reasoning about correctness}
The following sufficient condition for program correctness
will be used.
\begin{theorem}
\label{th:correctness}
Let  be a program and  be a specification.
If    then   is correct w.r.t.\ .
\end{theorem}
\pagebreak[3]
In other words, the sufficient condition for correctness of  is that
     for each ground instance 
    
    of a rule of ,
     if  then .



\citeN{DBLP:journals/tcs/Deransart93} attributes this result to \cite{Clark79}.
It  should be well known, but is often unacknowledged.
Often more complicated correctness proving methods, based on the operational
semantics, are proposed, e.g.\ in  \cite{Apt-Prolog}.
See \cite{DBLP:journals/tplp/DrabentM05shorter,drabent.tocl16}
for further comparison, examples and discussion.



\subsection{Reasoning about completeness}
\label{subsec:completeness}
Little work has been devoted to reasoning about completeness of programs.
See \cite{drabent.tocl16} for an overview.  We summarize the approach
of \cite{drabent.tocl16}, stemming from that of
\cite{DBLP:journals/tplp/DrabentM05shorter}.
It is based on an auxiliary notion of semi-completeness.


\pagebreak[3]
\begin{definition}
\nopagebreak
A program  is {\bf semi-complete} 
w.r.t.\ a specification  if
 is complete w.r.t.\  for any query 
such that there exists a finite SLD-tree for  and .
\end{definition}


Less formally, the existence of a finite SLD-tree means
that  with  terminates under some selection rule
(-terminates in the terms of \cite{PedreschiRS02.TPLP.terminating}).
For a semi-complete program , if a computation for a query 
terminates then all the answers for  required by the specification have
been obtained.
So establishing completeness is divided into showing completeness and
termination. 
Obviously, a complete program is semi-complete.
We immediately obtain:
\begin{proposition}[completeness]
\label{prop:completeness:trivial}
Assume that a program  is semi-complete w.r.t.\ a specification .
Then  is complete w.r.t.\   if
  \begin{enumerate}
  \item each atom  is a root of a finite SLD-tree for , or
  \item each atom  is an instance of an atom  which is a root of a
    finite SLD-tree for .
  \end{enumerate}
\end{proposition}
\pagebreak[3]

Our sufficient condition for semi-completeness employs the
following notion, stemming from \cite{Shapiro.book}.
\begin{definition}
  A ground atom  is
  {\bf covered by a rule}  w.r.t.\ a specification 
if  is the head of a ground instance  
  
  () of , such that all the atoms  are in .




  A ground atom  is {\bf covered} {\bf by a program}  w.r.t.\ 
  if it is covered w.r.t.\  by some rule .
\end{definition}

Informally,  covered by  w.r.t.\  means that  can produce  out
of the atoms in .
The following sufficient condition provides a method of proving
semi-completeness. 

\begin{theorem}[semi-completeness {\rm\cite{drabent.tocl16}}]
\label{th:semi-complete}
If all the atoms from a specification  are covered w.r.t.~
 by a program  
then  is semi-complete w.r.t.~.
\end{theorem}

We will say that a procedure  of 
{\em satisfies the sufficient condition for semi-completeness} w.r.t.\ 
if each -atom of  is covered by  w.r.t.\ .

To prove program completeness, the theorem has to be augmented by a way of
proving termination.  Fortunately, for the purposes of this paper 
a simple method of \cite{DBLP:journals/jlp/Bezem93} is sufficient.

\begin{definition}
A {\bf level mapping} is a
function  assigning natural numbers to ground atoms.

A program  is  {\bf recurrent} {w.r.t.\ a level mapping}~
\cite{DBLP:journals/jlp/Bezem93,Apt-Prolog} if, in
every ground instance   of its rule (),
 for all .

A program is {recurrent}
if it is recurrent w.r.t.\ some level mapping.   
A rule  is {recurrent} (w.r.t.\ ) if program 
is {recurrent} (w.r.t.\ ).


A query  is {\bf bounded} w.r.t.\ a level mapping   if, 
for some ,  for each ground instance  of an atom of .
\end{definition}
\vspace{-4pt}
\begin{theorem}
[termination {\rm\cite{DBLP:journals/jlp/Bezem93}}]
\label{th:termination}
Let  be a program recurrent w.r.t.\ a level mapping ,
and  be a query bounded w.r.t.\ .
Then all SLD-derivations for  and  are finite.
\end{theorem}




From the theorem and Proposition \ref{prop:completeness:trivial} we
immediately obtain: 
\begin{corollary}
[completeness]
\label{cor:completeness:recurrent}
If a program  is semi-complete w.r.t.\ a specification  and
recurrent
then  is complete w.r.t.~.
\end{corollary}

Note that the sufficient conditions for correctness (Theorem \ref{th:correctness})
and semi-completeness (Theorem \ref{th:semi-complete}) are declarative.  So is
the sufficient condition for completeness of Corollary
\ref{cor:completeness:recurrent}.
Thus the correctness and completeness proofs presented later on in this paper
are declarative. 
In general, the presented approach for proving completeness is not declarative,
as termination (finiteness of SLD-trees) depends on the selection rule.
For instance, the well-known method of \citeN{AP93} of proving termination,
depends on the order of atoms in program rules.
{\sloppy\par}

We mention another declarative way of showing program
completeness \cite{Deransart.Maluszynski93}
(see also \cite{drabent.tocl16}),
applicable also to non-terminating programs.
In that approach a level mapping is employed, however it may be defined only
on atoms 
from the specification .
\begin{theorem}
[completeness]
\label{th:completenessDeransart}
Let  be a program,  a specification, and .
If each atom  is covered w.r.t.\  by some ground
instance  such that 
 for 
then  is complete w.r.t.\ .
  
\end{theorem}



Note the similarity of this condition to that of Theorem \ref{th:semi-complete}
together with  Corollary \ref{cor:completeness:recurrent}.
The difference is that here only a fragment of  is required to be
recurrent.  The fragment consists of a rule instance covering  for each
.\linebreak[3]
Due to this similarity, the amount of work to prove program completeness by 
Theorem \ref{th:completenessDeransart}
is often similar to that of proving it 
by showing semi-completeness and termination.
So in practice the latter is usually preferable, as the termination 
has to be shown anyway
(under the selection rule used by the implementation of the program).









\subsection{Program construction}
\label{sec:construction}
The presented sufficient conditions suggest a systematic (informal) method
of constructing programs which are provably correct and semi-complete.
A guiding principle is that the program should satisfy the sufficient
condition for semi-completeness.
The construction results in a program together with proofs of its
correctness and semi-completeness.

Assume that specifications  and  are given 
for, respectively, completeness and correctness of a program  to be built. 
For each predicate  occurring in  consider the set

of the specified -atoms from the specification.
To construct a procedure  of , provide rules such that
\begin{enumerate}
\item 
\label{requirement1}
  each atom  is covered w.r.t.\  by some rule, and
\item
  each rule satisfies the sufficient condition for correctness
  w.r.t.\  of Theorem~\ref{th:correctness}.
\end{enumerate}
(In other words, the first requirement states that the constructed procedure
{satisfies the sufficient condition for semi-completeness}.)
The constructed program  is the union of the procedures for all  from
.  
It satisfies the conditions of Theorems \ref{th:correctness},
\ref{th:semi-complete}.  Thus  is correct w.r.t.\  and
semi-complete w.r.t.\ .

In practice, semi-completeness is not sufficient.  The actual task is 
to obtain a program which is complete;  also in most cases the program should
terminate for the intended class of initial queries.   
So the constructed program rules
should additionally satisfy some sufficient condition
for completeness (like that of Theorem \ref{th:completenessDeransart}) or
for termination
(like the program being recurrent).
In this way the method of the previous paragraph may be augmented to ensure
not only correctness and semi-completeness, but also completeness. 


The approach presented here will be used throughout the program constructions
presented in this paper. 



\section{SAT solver -- first logic program}
\label{sec:logicProgram1}

We are ready to begin the main subject of this paper -- a construction of a
program implementing a SAT solver.
The construction is divided in several steps, three definite clause logic
programs and a final Prolog program are constructed.
An interesting feature is that the construction is not a case of
semantics-preserving program transformation. 
The programs define different relations (for
the common predicates); however the common predicates are correct and
complete w.r.t.\ the same approximate specification.

This section explains the data structures used by the programs, 
provides a specification, 
and presents a construction of the first program, hand in hand with 
a correctness and semi-completeness proof.








\paragraph{Representation of propositional formulae.}

We first describe the form of data used by our programs, namely
the encoding of propositional formulae in CNF as terms,
proposed by \cite{howe.king.tcs-shorter}.

Propositional variables are represented as logical variables;
truth values -- as constants {\tt true}, {\tt false}.
A literal of a clause is represented as a pair of a truth value and a variable;
a positive literal, say , as {\tt true-X}
and a negative one, say , as  {\tt false-X}.
A clause is represented as a list of (representations of) literals,
and a conjunction of clauses as a list of their representations.
For instance a formula
 is represented as 
{\tt[[true-X,false-Y,true-Z],[false-X,true-V]]}.

An assignment of truth values to variables can be represented as a substitution.
Thus a clause (represented by a term)  is true under an assignment (represented
by)  iff the list  
has an element of the form  , i.e.\ 
{\tt false-false} or {\tt true-true}.  A formula in CNF is satisfiable
iff
its representation has an instance whose
elements (being lists) contain a   each.
We will often say ``formula~\/'' for a formula in CNF represented as a
term , similarly for clauses etc.



\paragraph{Specification.}
Now let us describe the sets to be defined by the predicates of our first 
SAT-solving program.  

Note that  are arbitrary ground terms; the reason for
such generality will be explained further on.
The following holds for  and .

Let us require that predicates {\it sat\_cl},  define
in our program the sets .
So the specification is 

From  (\ref{property.spec}) it follows that each program
which is correct and complete w.r.t.\  works as a SAT solver:
for any CNF formula  and any (substitution representing an) assignment
,





We are ready with the specification for our first program.
However, it is not necessary that a SAT-solving program defines the set .
Another choice may be

as (\ref{property.spec}) holds for .
(Note that   and ;
for simplicity, we allow arbitrary terms , not only 
{\tt false}, {\tt true}.)
This leads to a specification
  
Moreover, any sets 
,  such that 
and  will do,
as such ,  satisfy (\ref{property.spec}).\footnote{Because
   if a clause  has an instance  then ,
   and
   if a CNF formula  has an instance  then .
} Hence any program complete w.r.t.\  and correct w.r.t.\  has
property (\ref{property.program}), and thus can be used as a SAT solver.

We have chosen   as the set defined by our first program
(so  is its specification both for correctness and for completeness).
  This leads to a simpler program
-- a check is avoided that certain terms are lists, and that their elements
are of the form .
However our further programs will define a set  as above,
employing  as an approximate specification
(for predicates  ).\footnote{Our choice of the approximate specification is rather arbitrary.
     could be shrunk by additionally requiring
    in the definition of 
         that 
            for .
         can be extended by setting 
         
        \cite{drabent12.iclp}.
  However, the chosen  seem more convenient.

  Let us also note that in a suitable typed logic 
  the need for an approximate specification
  would disappear for this particular problem.  Roughly speaking,
  if the argument of  is restricted to the type of
  (representations of) CNF formulae then 
  the set to be defined by  is unique.
The set is specified by the shrunk , described above
  in this footnote.
} 


















\paragraph{The first program.}
Now we construct a program , hand in hand with its correctness and
semi-completeness proofs.
We follow the program construction approach described in Section
\ref{sec:construction}.
So we construct program rules such that
each atom from  is covered w.r.t.\  by some of the rules.
Additionally, care is taken that the rules are recurrent.
(This is not made explicit in our text.)
For each rule the sufficient condition for correctness of 
Theorem \ref{th:correctness} will be checked.
At the end we prove that the constructed program is recurrent, 
hence complete and terminating.






By (\ref{L1L2}),
a ground {\it sat\_cl}-atom is in  iff it is of the form
 or
 where .
For the first case, we provide a rule
Obviously the rule covers each such  , and the sufficient condition for
correctness w.r.t.\  (Theorem \ref{th:correctness}) is satisfied
(as each ground instance  of
(\ref{satcl1}) is in ).
For the second case, a rule
{\sloppy
    
}covers each such 
(as  is the head of a ground instance
 of (\ref{satcl2}),
where  ).
The sufficient condition for correctness holds for each ground instance of 
(\ref{satcl2}), as   implies 
, hence , and .








A ground -atom is in  iff it is  or of the form
 where  and .
The following rules cover  , respectively  w.r.t.\ , 
(simple details are left to the reader).

If  then , ,
hence .
So the sufficient condition of Theorem \ref{th:correctness}
holds for rule (\ref{satcnf2}).  It obviously holds for rule (\ref{satcnf1}).
So we constructed program , consisting of rules
(\ref{satcl1}), (\ref{satcl2})
(\ref{satcnf1}), (\ref{satcnf2}), and proved that it is semi-complete and
correct w.r.t.\ .


\paragraph{Termination and completeness of .}


To show that the program is complete we show that it is recurrent
(cf.\ Corollary \ref{cor:completeness:recurrent}).
Let us define a level mapping  \mbox{}
(and an auxiliary mapping   for terms):

for any ground terms , and any function symbol . 
Note that , and that
 for any term .
It is easy to show that the program  is recurrent under the level
mapping , i.e.\ 
for each ground instance  of a rule of  ,
we have .  For example, for a ground instance 

of (\ref{satcnf2}) we have
, which is greater both than
 and .
(We leave further details to the reader.)
By Corollary \ref{cor:completeness:recurrent},  is complete w.r.t.\ .


As a side effect, we obtain termination of  for the intended queries
(as for any CNF formula ,  for any its instance ;
thus query  is bounded  w.r.t.\ , 
and by Theorem \ref{th:termination} ~terminates for ).


\paragraph{Summary.}
We chose, out of a few possibilities, the specification  of a SAT solver
program, and then constructed such a program, namely .
The construction was guided by the sufficient condition for semi-completeness
and performed hand in hand with a semi-completeness and correctness proof.

Note that the program is not correct w.r.t.\  (another 
specification considered here)
as, for instance,  is an answer
of . 
The reader is encouraged to construct a program correct and complete w.r.t.\ 
,
in order to see that the program is more complicated (and most likely less
efficient), as it contains additional checks 
(that the argument of {\it sat\_cl} is a list and each its element is of the
form ).






\section{Towards adding control}
\label{sec:program}





To be able to influence the control of program  in the intended way,
in this section
we construct a more sophisticated logic program , with a program 
 as an intermediate stage.
(An impatient reader may find
 on page \pageref{final.program}.)
The construction is guided by a formal specification, and done together with
a correctness and semi-completeness proof.\
It follows the approach of Section \ref{sec:construction}.
We only partially discuss the reasons for particular design decisions in
constructing the logic programs
  and in adding control, as the algorithmic and efficiency
  issues are outside of the scope of this work.
The constructed program is proved to be recurrent, from which its
completeness and termination follow.
The last two subsections concern occur-check freedom of ,
and inapplicability of correctness-preserving transformations to our example. 




In this section not only the program, but also the specifications
are built incrementally
Our proofs will
remain valid under such changes of specifications by a rather obvious
property: 
\begin{lemma}
  Let  be specifications and  a program.

  If an atom  is covered by  w.r.t.\  then it is covered by
   w.r.t.~. 

  If  does not contain any predicate symbol occurring in
  , and
  the sufficient condition for correctness
  from Theorem \ref{th:correctness}
  holds for  w.r.t.\  
   then 
  the condition holds for  w.r.t.\ .
\end{lemma}






Program  is correct and complete w.r.t.\ .  However,
as explained in Section \ref{sec:logicProgram1}, 
   it is sufficient that predicate  
   is correct w.r.t.\  and complete w.r.t.\ .
So now our program construction will be guided by an approximate
specification.   
Predicates  , and  are going to be
correct w.r.t.\  and complete w.r.t.~.



In what follows, SC1 stands for the sufficient condition
for correctness,
and SC2 stands for the fact that the considered procedure satisfies the
sufficient condition for semi-completeness
(cf.\ Theorem \ref{th:correctness} and the comment after
Theorem \ref{th:semi-complete}).
Let SC stand for SC1 with SC2.
We leave to the reader a simple check of SC2 for 
and  (in Section \ref{sec:logicProgram1} this was done for  ).



\subsection{Preparing for adding control}
\label{sec:P2}






Program  performs inefficient search by means of backtracking.
We are going to improve the search by changing the control.
The intended control cannot be applied directly to ;
so in this section we transform   to a program .
The construction of  has two aspects, formal and informal.
Formally, we extend the
specification in some steps (to describe new predicates), and apply the
augmented specifications to construct the rules of 
together with proofs of semi-completeness and correctness.
At an informal level, the construction of the specifications
(and to a certain extent of the program rules) is guided by the
intended control, to be eventually added to the program in Section
\ref{sec:prologprogram}.  





Program  includes the rules for  from ,
i.e.\,(\ref{satcnf1}),\,(\ref{satcnf2}).
It contains a new definition of , and some new predicates.
The new predicates and  would define the same set 
(or its subset  ),
where 
(cf.\,(\ref{L1L2}),\,(\ref{L10})).
However they would represent elements of   in a different way.


We are going to improve the search by delaying certain actions.
Invoking   is to be delayed when 
is a clause with the two first literals non-ground.
      (Note that a literal being non-ground means that it has no logical
      value assigned.)
In this way the technique of watched literals (cf.\ \cite{handbook-SATsolvers})
will be implemented. 
Unification of a non-ground pair  (by applying rule (\ref{satcl1})) 
is to be performed only if the argument of  is a unit clause,
that is .
This contributes to implementing unit propagation
(cf.\ \cite{handbook-SATsolvers}).
Removing a literal from a clause (done in  by rule (\ref{satcl2})) is to
be performed only when the literal is ground.
Also, if this literal is true then further search is unnecessary for this
clause.





This idea will be implemented 
 by separating two cases: the clause has one literal, or more.
For efficiency reasons we want to distinguish these two cases by means of
indexing the main symbol of the first argument of a predicate.
So the argument should be the tail of the list.  (The main symbol is 
for a one element list, and  for longer lists.)
We redefine  , 
introducing an auxiliary predicate .
It defines the same set as , but a clause 
 is represented as three arguments 
of  .
More formally, its specifications for respectively correctness and
completeness are

A new procedure for   is obvious:

SC are trivially satisfied
(w.r.t.\ specifications ,
and ,
we leave the simple details to the reader).

Following \cite{howe.king.tcs-shorter} we will use in the program
an auxiliary predicate  defining equality.  It will turn out necessary
when the final Prolog program is constructed.  Its specification 
(for correctness and completeness)
is obvious:

As its definition, rule

will do
(as it covers each atom from , and satisfies the sufficient condition 
for correctness of Theorem \ref{th:correctness}.)



Procedure   has to cover each atom 

i.e.\ each  such that
 and  for
some .
Assume first .  Then ; this suggests a rule

Its ground instance 
\  \ 
covers  w.r.t.\ .  Conversely, each instance of  (\ref{satcl31})
with the body atom in  is of this form, its head is in ,
hence SC1 holds.



When the first argument of  is not , then we want
to delay  until  or the first
variable of  is bound.
In order to do this by means of {\tt block} declarations of SICStus
\cite{sicstus.Carlsson.tplp12},
we need to make the two variables to be separate arguments of a
predicate.  So we introduce a five-argument predicate ,
which is going to be delayed.
It defines the set of the lists from  of length greater than 1;
however a list  is
represented as the five arguments
of  .
The intention is to delay selecting  until its first or third
argument is bound (is not a variable).
The specifications for correctness and completeness for  is as
follows.  (As we soon will need another predicate with the same semantics,
the specifications describe both predicates).
{\sloppy
    2ex]  S_{sat\_cl5}^0  = \left\{\, \left.
          \begin{array}[c]{@{}l@{\:}}
           sat\_cl5(v_1,p_1,v_2,p_2,s), \\
           sat\_cl5a(v_1,p_1,v_2,p_2,s)
          \end{array}
          \right|
          [p_1\mydash v_1,p_2\mydash v_2|s]\in L_1^0
    \right\}.
    \end{array}
    
\begin{array}{l}
  S_2 = S_1\cup S_=\cup S_{sat\_cl3}\cup S_{sat\_cl5}\ \
      \mbox{(for correctness), and} \\
  S_2^0 = S_1^0\cup S_=\cup S_{sat\_cl3}^0\cup S_{sat\_cl5}^0\ \
      \mbox{(for completeness).}
\end{array}

      \begin{array}l
         sat\_cl3([Pol2\mydash {\it Var}2 | {\it Pairs}], {\it Var}1, Pol1) \gets 
         \\
          \qquad\qquad   sat\_cl5({\it Var}1, Pol1, {\it Var}2, Pol2, {\it Pairs}). 
      \end{array}
     \label{satcl32}
    
    &&
    sat\_cl5({\it Var}1, Pol1, {\it Var}2, Pol2, Pairs) \gets \nonumber
    \\&&
    \qquad
        sat\_cl5a({\it Var}1, Pol1, {\it Var}2, Pol2, Pairs).
    \label{satcl51}
    \\
    &&
    sat\_cl5({\it Var}1, Pol1, {\it Var}2, Pol2, Pairs) \gets \nonumber
    \\
    &&\qquad
        sat\_cl5a({\it Var}2, Pol2, {\it Var}1, Pol1, Pairs).
    \label{satcl52}
    
  &&\hspace{-2em}
  sat\_cl5a({\it Var}1, Pol1, {\it Var}2, Pol2, {\it Pairs}) \gets {\it Var}1 = Pol1.
  \label{satcl5a1}
  \\
  &&\hspace{-2em}
  sat\_cl5a({\it Var}1, Pol1, {\it Var}2, Pol2, {\it Pairs}) \gets sat\_cl3( {\it Pairs}, {\it Var}2, Pol2).
  \label{satcl5a2}
  
sat\_cl5a(p, p, v_2, p_2, s)
 \gets p= p.

sat\_cl5a(v_1, p_1, v_2, p_2, s) \gets sat\_cl3( s, v_2, p_2).

  \begin{array}{@{}c@{}}
  sat(u,l),   \mbox{ where}
  \begin{array}[t]{l@{}}
    u \mbox{ is a (representation of a) propositional formula in CNF}
    \\
    l \mbox{ is the list of the variables in }u.
  \end{array}
  \end{array}
  \label{initial.query}

\begin{array}{c}
S_{\it sat} = \{\, sat(u,t) \mid u\in L_2,\ t\in{\it T F L} \,\},
\\
S_{\it sat}^0 = \{\, sat(u,t) \mid u\in L_2^0,\ t\in{\it T F L} \,\},
\end{array}
\vspace{-1ex}

{\it T F L} =
 \{\, [\seq t] \mid n\geq0,\
                     t_i={\tt true} \mbox{ or } t_i={\tt false} 
\mbox{ for } i=1,\ldots,n  \,\}.

S_3^0 = S_2^0\cup S_{\it sat}^0 \cup S_{\it t f},
    \qquad
     \qquad\qquad
    S_3 = S_2\cup S_{\it sat} \cup S_{\it t f},
\vspace{-1.5ex plus 1ex}

      S_{\it t f} =
      \{\,    {\it t f list}(t) \mid t\in {\it T F L}  \,\}
\cup {} 
\{\, {\it t f}({\tt true}),   {\it t f}({\tt false}) \,\}  

    &&
    \mynegskip
    sat(Clauses, {\it Vars}) \gets
        {\it sat\_c n f}(Clauses), {\it t f list}({\it {\it Var}s}).   
    \label{sat}
    \\
    &&
   \mynegskip
    {\it t f list}([\,]). 
    \label{tflist1}
    \\&&
   \mynegskip
    {\it t f list}([{\it Var} | {\it Vars}]) \gets
        {\it t f list}({\it Vars}), {\it t f}({\it Var}).
    \\&&
   \mynegskip
{\it t f}({\tt true}). \\&&     \mynegskip  {\it t f}({\tt false}).
    \label{tf2}
    
&
      {\it sat\_c n f}([\,]).   \\
&
      {\it sat\_c n f}([Clause | Clauses]) \gets
        sat\_cl(Clause),
        {\it sat\_c n f}(Clauses). 
      \\
&
    sat\_cl([Pol\mydash {\it Var} | {\it Pairs}]) \gets sat\_cl3({\it Pairs}, {\it Var}, Pol). 
      \\
\mysymbol\ \ &
{=}(X,X).
      \\
&
        sat\_cl3([\,], {\it Var}, Pol) \gets {\it Var} = Pol. 
\\
&
      sat\_cl3([Pol2\mydash {\it Var}2 | {\it Pairs}], {\it Var}1, Pol1) \gets 
         sat\_cl5({\it Var}1, Pol1, {\it Var}2, Pol2, {\it Pairs}). 
    \\
\mysymbol\ \ &
sat\_cl5({\it Var}1, Pol1, {\it Var}2, Pol2, Pairs) \gets
sat\_cl5a({\it Var}1, Pol1, {\it Var}2, Pol2, Pairs).
\\
\mysymbol\ \ &
sat\_cl5({\it Var}1, Pol1, {\it Var}2, Pol2, Pairs) \gets 
sat\_cl5a({\it Var}2, Pol2, {\it Var}1, Pol1, Pairs).
\\
\mysymbol\ \ &
sat\_cl5a({\it Var}1, Pol1, {\it Var}2, Pol2, {\it Pairs}) \gets {\it Var}1 = Pol1.
\\
\mysymbol\ \ &
sat\_cl5a({\it Var}1, Pol1, {\it Var}2, Pol2, {\it Pairs}) \gets sat\_cl3( {\it Pairs}, {\it Var}2, Pol2).
    
\label{property-queryvars}
  \parbox{.66\textwidth}
  {
  if a variable  occurs in an -atom  in   ()
  then  occurs in an -atom  in .
  }

\label{property-stepvars}
  \parbox{.86\textwidth}
{
           Assume that in a resolution step an -atom  in a query 
           is replaced by  (where  is an mgu of 
           and the head  of a rule with body ).

  If
           a variable  occurs in  then  occurs in
           . 
         }

\label{property-stepvars2}
  \parbox{.86\textwidth}
         {
           Assume that  is an -atom and, apart from this,
            are as in 
           (\ref{property-stepvars}).
           If a variable  occurs in  then   occurs in
           . 
         }

\begin{array}{l}
|sat(t,u) | = \max\left(\, 3|t|,\,list size(u)\, \right) + 2,    \\
  | {\it sat\_c n f}(t) | = 3|t|+1, \\
    | sat\_cl(t)| = 3|t|+1,  \\
| sat\_cl3(t,u_1,u_2)| = 3|t|+1,  \\
\end{array}
\quad
\begin{array}{l}
| sat\_cl5(u_1,u_2,u_3,u_4,t)| = 3|t|+3,  \\
| sat\_cl5a(u_1,u_2,u_3,u_4,t)| = 3|t|+2,  \\
| {\it t f list}(u) |      = list size(u), \\
 |t=u| = | {\it t f}(t) | = 0,
\end{array}

    \label{block}
      \mbox{\tt:- block sat\_cl5(-, ?, -, ?, ?)}.
    
 \begin{array}{l}
 sat\_cl5({\it Var}1, Pol1, {\it Var}2, Pol2, {\it Pairs}) \gets
 sat\_cl5a({\it Var}1, Pol1, {\it Var}2, Pol2, {\it Pairs}).
 \\
 sat\_cl5({\it Var}1, Pol1, {\it Var}2, Pol2, {\it Pairs}) \gets
 sat\_cl5a({\it Var}2, Pol2, {\it Var}1, Pol1, {\it Pairs}).
 \end{array}
 
\label{satcl5P}
 \begin{array}{l}
   sat\_cl5({\it Var}1, Pol1, {\it Var}2, Pol2, {\it Pairs}) \gets  
   \\\qquad
   non var({\it Var}1) 
   \begin{array}[t]{cl}
\to & sat\_cl5a({\it Var}1, Pol1, {\it Var}2, Pol2, {\it Pairs})
       \\
; &    sat\_cl5a({\it Var}2, Pol2, {\it Var}1, Pol1,  {\it Pairs}).
   \end{array}
 \end{array}

 \begin{array}{l}
  sat\_cl5a({\it Var}1, Pol1, {\it Var}2, Pol2, {\it Pairs}) \gets {\it Var}1 = Pol1.
\\
  sat\_cl5a({\it Var}1, Pol1, {\it Var}2, Pol2, {\it Pairs}) \gets sat\_cl3( {\it Pairs}, {\it Var}2, Pol2).
 \end{array}
 
\label{satcl5aP}
  \begin{array}{l}
  sat\_cl5a({\it Var}1, Pol1, {\it Var}2, Pol2, {\it Pairs}) \gets
  \\\qquad
   {\it Var}1 \mathop= Pol1 \, \to \, true \ ;  \
   sat\_cl3( {\it Pairs}, {\it Var}2, Pol2).
  \end{array}

\begin{array}{l@{}l}
\Pi_1 = \{\, (\ref{satcl51}) \,\},
& 
S'_1 = S'_2 =  S_3^0\cap\{\, sat\_cl5(t_1,\ldots,t_5)  \mid 
                   t_1,\ldots,t_5\in \HU   \,\}
\\
\Pi_2 = \{\, (\ref{satcl52}) \,\}, 
&
\quad\ 
 = \{\, sat\_cl5(v_1,p_1,v_2,p_2,s)  \mid 
                    [p_1\mydash v_1,p_2\mydash v_2|s]\in L_1^0 \,\},
\\
\Pi_3 = \{\, (\ref{satcl5a1}) \,\},
& 
    S'_3 = \{\, sat\_cl5a(p,p,v_2,p_2,s) \mid 
                     [p\mydash p,p_2\mydash v_2|s]\in L_1^0 \,\},
\\
\Pi_4 = \{\, (\ref{satcl5a2}) \,\},
& 
    S'_4 = \{\, sat\_cl5a(v_1,p_1,v_2,p_2,s) \mid v_1\neq p_1,\
                     [p_2\mydash v_2|s]\in L_1^0\,\},
\\
\Pi_5 = P_3\setminus\bigcup_{i=1}^4\Pi_i,
&
\qquad\
    S'_5 = S_3^0\setminus (S'_1\cup S'_3\cup S'_4).
\end{array}

Note that  does not contain any -atoms or -atoms,
and that .
In particular,  is the set of all -atoms from .
To apply Theorem \ref{th:completeness:pruned}
we need to show that
for  each atom of  is covered by  w.r.t.\ .
A proof of this fact has already been
done; 
it consists of the relevant fragments of the proof that 
each atom  is covered by , spread over Sections
\ref{sec:logicProgram1},~\ref{sec:program}.












In what follows let us consider
a pruned tree  with the root of the form (\ref{initial.query}).  It
can be seen as a csSLD-tree for .  The c-selection rule
selects  or  for  -atoms, 
 for -atoms with the first two arguments unifiable,
 for the remaining -atoms,
and  for the atoms with the other predicate symbols.



We now show that the tree  is compatible with \S.
When  , where ,  is selected for a -atom  then
the corresponding specification  contains all the -atoms from .
So .
It remains to consider  being a -atom.
Due to the delays implemented by (\ref{block}) and 
pruning implemented in (\ref{satcl5P}), when a -atom  is
selected in a node of the tree then its first argument is not a variable,
say it is   ().
In Section \ref{sec:occur-check} we showed that the second argument is a
constant  (which is {\tt true} or {\tt false}).  
So .
Thus either 
(when the first two arguments in  are unifiable, hence are equal)
and  is selected for , or
 (otherwise)
and  is selected for .
Remember that in Section \ref{sec:nonfloundering} we showed 
that in each non-empty query of the tree some atom is selected (there is no
floundering). 
Thus  is compatible with  \S.





Remember also that  is recurrent. 
So the premises of Theorem \ref{th:completeness:pruned}
are satisfied, and each pruned tree with the root of the form
(\ref{initial.query}) is complete w.r.t.\ .


\paragraph{Remarks.}
The Prolog program constructed in this section
is correct w.r.t.\ specification  and, for initial queries of the form 
(\ref{initial.query}), it terminates under any selection rule,
does not flounder, and is occur-check free.  These properties follow from
those of logic program , proved in Section \ref{sec:program}.
Here we proved that, for queries of this form,
the Prolog program preserves the completeness 
of  w.r.t.~.
In practice, this means that the program will produce
all the answers required by the specification.
Thus, by (\ref{property.program}), the program will find all the solutions to
the SAT problem represented by the query.



\section{Conclusions}

\paragraph{The example.}
This paper presents a construction of a non-toy Prolog program,
together with proofs of its correctness, completeness,
termination, occur-check freedom, and non-floundering.
The program is the SAT solver of \citeN{howe.king.tcs-shorter}.  
It is seen as a definite clause logic program with added control.
Starting from a formal specification, a 
sequence of definite clause programs, called ,
is constructed hand in hand with proofs of their correctness and completeness 
(Section \ref{sec:logicProgram1},\,\ref{sec:program}).
The construction is guided by the proofs, mainly those of semi-completeness.
This suggests a general approach (Section \ref{sec:construction})
to constructing programs which are provably correct and semi-complete.
The author believes that the approach, possibly treated informally,
should be useful in practice.


Additionally, for the assumed class of initial queries
program  is proved to terminate, not flounder, and be occur-check free;
  termination and occur-check freedom hold for arbitrary selection rules,
  and non-floundering -- for a class of selection rules including that to be
  used in the final Prolog program.







The Prolog program is obtained from  by adding control --
imposing a specific selection rule and pruning the SLD-trees.
The pruning is done by means of the if-then-else
construct (and can equivalently be done by means of the cut).
Such control preserves correctness; it also preserves 
occur-check freedom, and termination 
(as in this particular case they are independent from the selection rule).
However it may violate completeness due to pruning 
and floundering.  Non-floundering has already been proven for .
In Section \ref{sec:prologprogram} 
we prove that the completeness is preserved under pruning.




















\paragraph{Proof methods.}
We applied general methods to prove correctness  \cite{Clark79},
completeness \cite{drabent.tocl16}, termination \cite{DBLP:journals/jlp/Bezem93},
and completeness under pruning  \cite{drabent.tocl16}.
The known methods for proving non-floundering and occur-check freedom seem
inapplicable in our case
(cf.\ Sections \ref{sec:occur-check}, \ref{sec:nonfloundering}).
To deal with non-floundering,
we introduced a sufficient condition, suitable for a certain class of programs.
The proof of occur-check freedom is rather {\em ad hoc}.
It should be added that non-floundering and termination can be
determined by means of automatic tools, see
\cite{king.non-suspension2008} for the former,
and e.g.\ \cite[and the references therein]{NguyenSGS11-termination-shorter} 
for the latter.
{\sloppy\par}




The employed proof methods for correctness and completeness were described
and discussed in \cite{drabent.tocl16}.
The method for program correctness  \cite{Clark79} is simple, natural,
  should be well-known, but is often neglected.
  Instead, more complicated methods are proposed, like that of
  \cite{Apt-Prolog}. 
  Moreover, these methods are not declarative
  (cf.\ footnote \ref{footnote:nondeclarative}, see
  \cite{DBLP:journals/tplp/DrabentM05shorter,drabent.tocl16}
  for further discussion).
The methods for program completeness, and 
for completeness of pruned SLD-trees are due to \cite{drabent.tocl16}.
  The approach for completeness introduces a notion of semi-completeness.
  Roughly speaking, semi-completeness and termination imply completeness.
Semi-completeness alone may be useful -- if a semi-complete program
terminates then all the answers required by the
  specification have been obtained.
  The presented sufficient condition for semi-completeness
  is a necessary condition for program completeness
  (in a sense made precise in  \cite{drabent.tocl16});
  so semi-completeness may be understood as a necessary step when dealing
  with completeness.


A subject for future work is formalization and automation of the presented
proof methods.  This requires introducing a particular language to
express (a chosen class of) specifications.  The next issue is devising
formal methods of checking the sufficient conditions used here.


In the author's opinion,
the sufficient conditions for correctness and semi{-}com\-pleteness
are simple and natural.  
For correctness one has to show that the rules of
the program produce specified atoms (cf.\ Definition \ref{def:specification})
 out of specified ones.
For semi-completeness -- that each specified atom can be produced by some rule of
the program out of some specified atoms.
The author believes
  that the two proof methods
  and the program construction approach of Section \ref{sec:construction}
  are a practical and useful tool.  They should be applicable,
  possibly at a less formal level, in actual every-day programming, 
   and in teaching logic programming.
The program development case of Sections
\ref{sec:logicProgram1},~\ref{sec:program},
maybe dealt with less formally, can be considered a practical example.
Conversely,
the two proof methods can be understood as a formalization of a usual way in
which competent programmers reason declaratively about their logic programs.





\paragraph{Declarativeness.}
Logic programming could not be considered a declarative programming paradigm
unless there exist
declarative ways of reasoning about program correctness
and completeness.
(We remind that by declarative we mean referring only to logical reading of 
programs, thus abstracting from any operational semantics.)
The methods for proving correctness and semi-completeness
are purely declarative.  
So is the completeness proving method used in this paper; however it is 
applicable to a restricted class of programs.



In general, completeness proofs based on semi-completeness
 may be not declarative, as 
they refer, maybe indirectly, to program termination.
So we have a compromise between declarative and non-declarative reasoning:
declarative proofs of correctness and semi-completeness, and a
non-declarative step from semi-completeness to completeness.
Nevertheless, such compromise 
should be useful in the practice of declarative programming,
as usually termination has to be established anyway.
This is also supported by the fact that
a declarative method for proving completeness \cite{Deransart.Maluszynski93}
results in a proof similar to a proof of semi-completeness together with a
proof of termination (Section \ref{subsec:completeness});
however such proof does not imply termination.




\paragraph{Approximate specifications.}
  We point out usefulness of approximate specifications.
They are crucial for avoiding unnecessary
  complications in constructing specifications and in
   correctness and completeness proofs.
  They are natural:  when starting construction of a program, 
  the relations it should compute are often known only approximately.
  Sections \ref{sec:logicProgram1}, \ref{sec:program} provide an example.
Also, it is often cumbersome (and unnecessary) to exactly establish the
  relations computed by a program, 
  This is the case in our example, as discussed in Section
  \ref{sec:transformations}. 
  See \cite{drabent.tocl16} for further examples and discussion.
  

\paragraph{Program transformations.}
The program development example presented here differs from those
employing semantics-preserving transformations
\cite[and the references therein]{PettorossiPS10shorter}.
In our example,
  the semantics of (the common predicates in) the consecutive versions 
of the program differ.  What is unchanged, is the correctness
  and completeness w.r.t.\ an approximate specification.
In Section \ref{sec:transformations}
  we argue that the paradigm of semantics-preserving transformations
  is inapplicable to our case.
  This suggests introducing a more general paradigm of program transformations which 
  preserve correctness and completeness w.r.t.\ an approximate specification.




\paragraph{Final remarks.}
We are interested in declarative programming.
The example presented here
  is intended to show how much of the programming task can be
  done declaratively, 
  without considering the operational semantics; how 
   ``logic'' could be separated from ``control.''  A substantial part of work
  could be done at the stage of a pure logic program.
At this stage, correctness, completeness, termination, non-floundering, and
  occur-check freedom were formally proven;
the reasoning about correctness and completeness was declarative.
  It is important that all the
  considerations and decisions about the program execution and efficiency
  (only superficially treated in this paper) are independent from those related
  to the declarative semantics,
  in particular to the correctness and completeness of the program.





  We argue that the employed proof methods 
  and the program construction approach 
  are simple, and
correspond to a natural way of declarative thinking about programs.
We believe that they can be actually used -- maybe at an informal level -- in
  practical programming; this is supported 
  (in addition to rather small examples in the previous work)
  by the main example of this article.











\paragraph{\bf Acknowledgement}
Extensive comments of anonymous referees were helpful in improving the
presentation. 













\bibliographystyle{acmtrans}
\bibliography{bibshorter,bibpearl,bibmagic,bibcut}


\end{document}
