In this section we use a general combinatorial approach for solving prize-collecting problems introduced by Hajiaghayi and Jain \cite{Hajiaghayi}. In their work they obtained the primal-dual -approximation algorithm for edge-weighted Prize-collecting Steiner Forest problem. We repeat their argumentation in planar node-weighted setting resulting in the -approximation algorithm. 

Consider a graph  with a non-negative cost function on nodes , a set of pairs of vertices (demands)  and a non-negative penalty function . In the Node-weighted Prize-collecting Steiner Forest problem we are asked to find a set of vertices  which minimizes the sum of costs of vertices in  plus penalties for pairs of vertices which are not connected in a subgraph of  induced by .

Note that we can give an equivalent definition of demands and penalties by specifying penalties for each unordered pair of vertices. Simply set penalties for pairs of vertices which are not in  to . From now on we will use values  to denote penalties. Let also  denote the set of vertices in  incident to vertices from  and let  means that  (i.e.,  separates vertices  and )
Using this notation, we can formulate our problem with the following integer program

Setting  corresponds to buying a vertex  (including  into solution ) and setting  corresponds to paying a penalty instead of connecting vertices  and .

The dual of the linear relaxation of this program is:

The problem with this dual program is that it has many different variables for each pair of vertices. Hence in a moat growing approach we have to decide how to split the growth of a moat corresponding to a set  between variables . It seems to be a difficult task (see \cite{Hajiaghayi} for a detailed discussion) and may require decreasing some dual variables throughout the course of the algorithm.

Fortunately Hajiaghayi and Jain in \cite{Hajiaghayi} proposed a general approach of handling this issue of different variables induced by prize-collecting setting by circumventing it using Farkas' Lemma. The following arguments are repetitions of their work in the node-weighted setting and we conduct them for the sake of the completeness.

First, we create new variables . Now the dual  becomes

\begin{fact}
Linear programs  and  are equivalent
\end{fact}
\begin{proof}
Take a feasible solution  to . Let . This together with  constitutes a feasible solution to  of the same cost.\\
To see the other direction, take a feasible solution  to . We can assume that the first constraint in  is tight, because otherwise we could decrease  until  without affecting the objective function and not violating other constraints. The  is feasible to  and the objective function is the same. \qed
\end{proof}

Now we will use Farkas' Lemma to get a rid of dual variables . Observe that they are not included in the objective function of . The idea is to replace constraints involving  with different inequalities which for fixed  check whether feasible  exists.

\begin{fact} Farkas' lemma (variant)\\
	\label{FarkasLemma}
	Consider a matrix  and a vector . The system  has a solution , if and only if for all  with  one has .
\end{fact}

Consider a feasible solution to  and a system defined by constraints of  containing , i.e.

Farkas Lemma (see Fact~\ref{FarkasLemma}) says that this system has a solution  if and only if for each vector  with  (for each  such that ) we have that .
Notice that we can safely replace  with  which gives us the following constraint:

So our new dual is

and it has only one dual variable  for each set . On the other hand, it has infinitely many constraints. However, as the lemma below says, many of them are redundant.
\begin{lemma} (Lemma 2.2 in \cite{Hajiaghayi})
It is sufficient to consider  having only one positive value in its range.
\end{lemma}

The above lemma allows us to think about 's as families of subsets of . Hence we can write our dual as follows

where  denotes that there exists  such that  (we say that family  separates vertices  and  if and only if there exists at least one set  which separates vertices  and ).

Note that  is a family of subsets of vertices and our dual has double exponential number of constraints. But we have now only one dual variable for each set. Intuitively this double exponential number of constraints implicitly ensures that for given variables  there exist feasible variables  of the former dual program which sum to .

Although the double exponential number of constraints does not sound good, we will be able to construct polynomial-time primal-dual algorithm based on this dual.

We can define a function  which for every family  define  to be the right-hand side of the corresponding constraint, i.e.:

In their paper, Hajiaghayi and Jain show that  is submodular. This property allows them to prove the following fact.
\begin{fact} (Corollary 2.2 in \cite{Hajiaghayi})
\label{SumTight}
Suppose  is a feasible solution to dual . Suppose the constraints corresponding to families  and  are tight. Then the constraint corresponding to the family  is also tight.
\end{fact}
\newpage
\subsection{Algorithm}
Without loss of generality we can assume that each terminal  belongs to exactly one demand and its weight  is . To see this, construct a new graph where for each vertex  of each demand  we have additional two vertices  and  connected by a single edge to original vertices ( and  correspondingly). The penalties are now only between vertices  and . Weights of new vertices are now  while weights of original vertices  remain the same. It is easy to see that every solution for the new graph can be used to construct a solution of the same cost for the original graph and vice-versa.

Now we are ready to give a primal-dual algorithm for the NWPCSF problem on planar graphs.
The algorithm starts with an initial solution  in which there are all vertices of cost  (hence all terminals). In each iteration the algorithm maintains moats which are the connected components of graph  induced by the vertices of the current solution . Demands can be marked (meaning that we decide to pay a penalty for them) or unmarked. At the beginning all demands are unmarked. Once demand is marked, it stays marked forever. A moat (denoted by the corresponding set ) is active in the current iteration if and only if there is at least one unmarked demand  such that . Now in each iteration we simultaneously grow each active moat until one of the following two events occur:
\begin{itemize}
	\item a vertex  goes tight (constraint (\ref{ForestConstraint1}) becomes equality), or
	\item a family  goes tight (constraint (\ref{ForestConstraint2}) becomes equality).
\end{itemize}

In the first case we simply add  to our solution  (which may make some moats inactive) and continue to the next iteration.

In the second case, we mark each demand  such that . Hence in the following iterations all moats from  will be inactive, and we will not violate any constraint during the growth process. We repeat this process until all moats become inactive.

After that we have an additional pruning phase in which we process all vertices of  in the reverse order of buying. We remove a vertex  from  if after its removal from , all unmarked demands are still connected in the graph induced by . We output this pruned set of vertices as  which is our final solution.

Obtaining  and a tight vertex in line  is straightforward. On the other hand obtaining  in line  and a tight family  seems to be much harder, since the number of corresponding constraint is double exponential. Fortunately Hajiaghayi and Jain in section  of \cite{Hajiaghayi} gave a polynomial time algorithm for computing  and the corresponding tight family .

Since the algorithm terminates after at most  iterations (in each iteration the number of active moats or the number of connected components decreases), the running time of this algorithm is polynomial.

\begin{algorithm}[H]
	\SetKwData{Left}{left}\SetKwData{This}{this}\SetKwData{Up}{up}
	\SetKwInOut{Input}{input}\SetKwInOut{Output}{output}
	\Input{A planar graph  with non-negative weights  on the nodes and non-negative penalties  between each pair of vertices such that if  then  and }
	\Output{A set of vertices  representing a forest and a set of pairs  representing not connected demands}
	\BlankLine
	\Begin{
		\;
		 \tcp{set all demands unmarked}
		 \tcp{implicitly}
		\BlankLine
		\BlankLine
		\;
		\tcp{identify active moats as components of subgraph of  induced by vertices  for which there is at least one unmarked demand  which is separated by the corresponding set}
		\BlankLine
		\BlankLine
		\While{AM }{
			find minimum  s.t if we increase  for each  by  we get a new tight vertex \;
			find minimum  s.t if we increase  for each  by  we get a new tight family \;
			\;
			 for all \;
			\eIf{}{
				\;
			}{
				
			}
			\;
		}
		\tcp{pruning phase}
		Derive  from  by removing vertices in reverse order of purchase so that every unmarked demand is connected in .\\
		Let  be all demands not connected via 
	}
	\caption{Primal-Dual Algorithm for NWPCSF on planar graphs}
\end{algorithm}


\subsection{Analysis}
\begin{theorem}
\label{4aprox}
The algorithm outputs a set of vertices  and a set of demands  which are not connected via  such that

\end{theorem}
In order to prove Theorem~\ref{4aprox} it is enough to prove the following two lemmas:
\begin{lemma}
\label{pc1lemma}

\end{lemma}
\begin{proof}
First observe that  where  are marked pairs. Now consider families  which went tight during the run of the algorithm. Observe that each marked pair was separated by some .\\
Hence family  separates each marked pair.
From Fact~\ref{SumTight} the union of tight families is tight. Putting it all together gives:\\
 \qed
\end{proof}

\begin{lemma}
\label{general3lemma}

\end{lemma}
To prove Lemma~\ref{general3lemma} we will use an auxiliary lemma. But first, let us introduce one definition.\\
For a set of nodes  and the set of unmarked demands  define a minimal feasible augmentation  of  with respect to  to be a set of vertices  containing  as a subset such that every pair of vertices from  is connected in the subgraph of  induced by  and such that removal of any  from  disconnects some pair from .

\begin{lemma}
\label{Carsten3lemma}
Let  be planar,  be the set of unmarked demands after running the above algorithm,  be the set of bought vertices before running iteration  and  be a minimal feasible augmentation of  with respect to . Let also  be the set of active moats before running iteration . Then\\

\end{lemma}

Before we prove Lemma~\ref{Carsten3lemma} we will show how it helps us in proving Lemma~\ref{general3lemma}.\\
\begin{proof}[Proof of Lemma~\ref{general3lemma}]\\
Since we add a vertex  to  only if it is tight, and after that we do not modify variables corresponding to sets adjacent to , we have the following equality

(in the last step we changed the order of the summation).

Now let  be the output of the algorithm,  be the set of all unmarked demands,  be the set of bought vertices before iteration ,  be the set of active moats before running iteration  and  be the increase of the dual variables in iteration . Then for each  we have  hence the following holds:

and


Observe now, that  is a minimal feasible augmentation of  with respect to . Obviously, every demand from  is connected in . Consider any vertex . Removing  from  will make some pair from  disconnected because otherwise  would be deleted in the pruning phase. Hence we can use Lemma~\ref{Carsten3lemma}:

Since  we have
 \qed
\end{proof}

Now we conclude with the sketch of the proof of Lemma~\ref{Carsten3lemma}.
\begin{proof}[of Lemma~\ref{Carsten3lemma}]
The proof is conducted in a similar way as the proof of Lemma~\ref{lemMainCC} and the analysis is essentially the same as in \cite{Moldenhauer}.
We need to count the adjacencies between active moats and vertices from . Consider the graph  obtained from  in the following way:
\begin{enumerate}
	\item take the subgraph of  induced by vertices from 
	\item discard isolated inactive moats
	\item contract each inactive moat with a neighboring vertex 
	\item contract each active moat
\end{enumerate}
Next color vertices of  in two colors:
\begin{itemize}
	\item white color for vertices obtained from contracting active moats
	\item black color for all other vertices, i.e. 
\end{itemize}
Observe now that deleting a black vertex in  disconnects two white vertices, because otherwise it would be deleted in the pruning phase.  remains planar, since deletions and contractions preserve planarity. Moreover, it is easy to see that the number of adjacencies  in  is the same as the number of edges between white and black vertices in . To bound this number we use Lemma~\ref{lemma-graph-white-black} for each component of . Therefore we have  \qed
\end{proof}
