
Differential privacy is a  formal framework to quantify to what extent individual privacy in a statistical database is preserved while releasing useful aggregate information about the database.
It provides strong privacy guarantees by requiring the indistinguishability of whether an individual is in the dataset or not based on the released information. The key idea of differential privacy is that the presence or absence
of any individual data in the database should not affect the final released statistical information significantly, and thus it can give strong privacy guarantees against an adversary with arbitrary auxiliary information. For motivation and background of differential privacy, we refer the readers to the  survey \cite{DPsurvey} by Dwork.

Since its introduction in \cite{DMNS06} by Dwork et.\ al., differential privacy has spawned  a large body of research in  differentially private data-releasing mechanism design and performance analysis in various settings. Differential privacy is a privacy-preserving constraint imposed on the query output releasing mechanisms, and to make use of the released information, it is important to understand the fundamental tradeoff between utility(accuracy) and privacy.



In many existing works on studying the tradeoff between accuracy and privacy in differential privacy, the usual metric of accuracy is in terms of the variance, or magnitude expectation of the noise added to the query output.  For example, Hardt and Talwar \cite{geometry} study the tradeoff between privacy and error for answering a set of linear queries over a histogram in a differentially private way, where the error is defined as the worst  expectation of the -norm of the noise among all possible query output.  \cite{geometry} derives lower and upper bounds on the error given the differential privacy constraint. Nikolov, Talwar and Zhang \cite{NTZ12} extend the result on the tradeoff between privacy and error to the case of  -differential privacy. Li et. al. \cite{Li10} study how to optimize linear counting queries under differential privacy, where the error is measured by the mean squared error of query output estimates, which corresponds to the variance of the noise added to the query output to preserve differential privacy.

More generally, the error can be a general function depending on the additive noise (distortion) to the query output.  Ghosh, Roughgarden,  and Sundararajan \cite{Ghosh09}  study a very general utility-maximization framework for a single count query with sensitivity one under differential privacy, where the utility (cost) function can be a general function depending on the noise added to the query output. \cite{Ghosh09} shows that there exists a universally optimal mechanism (adding geometric noise) to preserve differential privacy for a general class of utility functions under a Bayesian framework.  Brenner and Nissim \cite{Nissim10} show that for general query functions, no universally optimal differential privacy mechanisms exist. Gupte and Sundararajan  \cite{minimax10} generalize the result of \cite{Ghosh09}  to a minimax setting.


In this work, we study the fundamental tradeoff between utility and privacy under differential privacy, and derive the optimal differentially private mechanism for  general single real-valued query function, where the utility model is the same as the one adopted in \cite{Ghosh09} and \cite{minimax10}, and the real-valued query function can have arbitrary sensitivity.  Our results can be viewed as a generalization of  \cite{Ghosh09} and \cite{minimax10} to general real-valued query functions with arbitrary sensitivity. We discuss the relations of our work and the existing works in detail in Section \ref{subsec:connection}.



\subsection{Background on Differential Privacy}

The basic problem setting in differential privacy for statistical database is as follows: suppose a dataset curator is in charge of a statistical database which consists of records of many individuals, and an analyst sends a query request to the curator to get some aggregate information about the whole database. Without any privacy concerns, the database curator can simply apply the query function to the dataset, compute the query output, and send the result to the analyst. However, to protect the privacy of individual data in the dataset, the dataset curator should use a randomized query-answering mechanism such that the probability distribution of the query output does not differ too much whether any individual record is in the database or not.

Formally, consider a real-valued query function

where  is the set of all possible datasets. The real-valued query function  will be applied to a dataset, and query output is a real number. Two datasets  are called neighboring datasets if they differ in at most one element, i.e.,  one is a proper subset of the other and the larger dataset contains just one additional element \cite{DPsurvey}. A randomized query-answering mechanism  for the query function  will randomly output a number with probability distribution depends on query output , where  is the dataset.

\begin{definition}[-differential privacy \cite{DPsurvey}]
	A randomized mechanism  gives -differential privacy if for all data sets  and  differing on at most one element, and all ,
	
	 where  is the random output of the  mechanism  when the query function  is applied to the dataset .
\end{definition}


The differential privacy constraint \eqref{eqn:dpgeneral} essentially requires that for all neighboring datasets, the probability distributions of the output of the randomized mechanism should be approximately the same. Therefore, for any individual record, its presence or absence in the dataset will not significantly affect the output of the mechanism, which makes it hard for adversaries with arbitrary background knowledge to make inference on any individual from the released query output information. The parameter  quantifies how private the mechanism is: the smaller  is , the more private the randomized mechanism is.






\subsubsection{Operational Meaning of -Differential Privacy in the Context of Hypothesis Testing}


As shown by \cite{Zhou08}, one can interpret the   differential privacy constraint  \eqref{eqn:dpgeneral} in the context of hypothesis testing in terms of false alarm probability and missing detection probability. Indeed, consider a binary hypothesis testing problem over two neighboring datasets,  versus , where an individual's record is in  only. Given a decision rule, let  be the decision region such that when the released output lies in ,  will be rejected, and when the released output lies in  (the complement of ),  will be rejected. The false alarm probability  and the missing detection probability  can be written as


Therefore, from \eqref{eqn:dpgeneral} we get

Thus


Switch  and  in \eqref{eqn:dpgeneral}, and we get
	

Therefore,

and thus


In conclusion,  we have


The -differential privacy constraint implies that in the context of hypothesis testing,   and  can not be both too small.











\subsubsection{Laplacian Mechanism}



The standard approach to preserving -differential privacy is to perturb the query output by adding random noise with Laplacian distribution proportional to the sensitivity  of the query function , where the  sensitivity of a real-valued query function is defined as

\begin{definition}[Query Sensitivity \cite{DPsurvey}]
	For a real-valued query function , the sensitivity of  is defined as
	
for all  differing in at most one element.
\end{definition}


Formally, the  Laplacian mechanism is:
\begin{definition}[Laplacian Mechanism \cite{DMNS06}]
	For a real-valued query function  with sensitivity , Laplacian mechanism will output
	
 	where  is a random variable with probability density function
 	
\end{definition}





Consider two neighboring datasets  and  where . It is easy to compute the tradeoff between the false alarm probability  and the missing detection probability   under  Laplacian mechanism, which is











Since its introduction in \cite{DMNS06},  the Laplacian mechanism has become the standard tool in differential privacy and has been used as the basic building block in a number of works on differential privacy analysis in other more complex problem settings, e.g., \cite{HLM12, MM09, Xiao11, Huang12, McSherry10, Li10, Barak07, DKMMN06, DL09, Roth10, LO11, Smith2011, CM08, continual, Ding11, Hardt2010, Geo12, Ka11, Mironov12bit, Sarathy2011, Xiao2011ireduct, Dankar12, Friedman10, zhang2012functional, lei2011differentially, wasserman2010, dwork2010pan, Guptadp2010, blum2011fast, hsu2012distributed, hsu2012dp, blocki2012johnson, hardt2012beyond, hardt2012private, gupta2012iterative, kasi13, karwa2011private, cormode2012differentially}. Given this near-routine use of the query-output independent adding of Laplacian noise,  the following two questions are natural:
\begin{itemize}
	\item Is  query-output independent perturbation optimal?
	\item Assume query-output independent perturbation,  is Lapacian noise distribution optimal?
\end{itemize}

In this work we answer the above two questions. Our main result is that given an -differential privacy constraint, under a general utility-maximization (equivalently, cost-minimization) model:
\begin{itemize}
	\item adding query-output independent noise is indeed optimal (under a mild technical condition),
	\item the optimal noise distribution is {\em not} Laplacian distribution; instead, the optimal one has a {\em staircase-shaped} probability density function.
\end{itemize}

These results are derived under the following settings:
\begin{itemize}
\item when the domain of the query output is the entire real line or the set of integers;
\item nothing more about the query function is known beyond its global sensitivity;
\item either local sensitivity \cite{NRS07} of the query function is unknown or it is the same as global sensitivity (as in the important case of count queries).
\end{itemize}
If any of these conditions are violated (the output domain has sharp boundaries, or the local sensitivity deviates from the global sensitivity \cite{NRS07}, or we are restricted to specific query functions \cite{CM08}), then the optimal privacy mechanism need not be data or query output dependent.







\subsection{Problem Formulation}

We formulate a utility-maximization (cost-minimization) problem under the differential privacy constraint.

\subsubsection{Differential Privacy Constraint}
A general randomized releasing mechanism  is a family of noise probability distributions indexed by  the query output (denoted by ), i.e.,

and given dataset , the mechanism  will release the query output  corrupted by additive random noise with probability distribution :

where  is a random variable with probability distribution .


The differential privacy constraint \eqref{eqn:dpgeneral}    on  is that for any  such that  (corresponding to the query outputs for two neighboring datasets) ,

where for any ,  .

\subsubsection{Utility Model}

The utility model we use in this work is a very general one, which is also used in the works by Ghosh, Roughgarden, and Sundararajan \cite{Ghosh09}, Gupte and  Sundararajan \cite{minimax10}, and Brenner and Nissim \cite{Nissim10}.

Consider a cost function , which is a function of the additive noise. Given additive noise , the cost is . Given query output , the additive noise is a random variable with probability distribution , and thus the expectation of the cost is


The objective is to minimize the worst case cost among all possible query output , i.e.,



\subsubsection{Optimization Problem}

Combining the differential privacy constraint \eqref{eqn:diffgeneralnoise1} and the objective function \eqref{eqn:objective}, we formulate a functional optimization problem:















\subsection{An Overview of Our Results}













\subsubsection{Optimal Noise Probability Distribution}

When the query output domain is the real line or the set of integers, we show (subject to some mild technical conditions on the family of differentially private mechanisms) that adding query-output-independent noise is optimal. Thus we only need to study what  the optimal noise probability distribution is. Let  denote the probability distribution of the noise added to the query output. Then the optimization problem \eqref{eqn:objecinopt} and \eqref{eqn:diffgeneralnoise} is reduced to




Consider a staircase-shaped probability distribution with probability density function (p.d.f.)  defined as

where

is a normalizing constant to make .


Our main result is
\begin{theorem}
	If the cost function  is symmetric and increasing, and  for some , the optimal noise probability distribution has a staircase-shaped probability density function , where
	
	
\end{theorem}

We plot the probability density functions of Laplace mechanism and staircase mechanism in Figure \ref{fig:probdf}. Figure \ref{fig:fgamma} in Section \ref{sec:result} gives a precise description of staircase mechanism.

The staircase mechanism is specified by three parameters: , , and  which is determined by  and the cost function . For certain classes of cost functions, there are closed-form expressions for the optimal .



\begin{figure}[h]
\begin{subfigure}[b]{0.5\linewidth}
\centering
\includegraphics[width=0.8\textwidth]{fig_laplace.pdf}
\caption{ Laplace Mechanism }
\end{subfigure}
\begin{subfigure}[b]{0.5\linewidth}
\centering
\includegraphics[width=0.8 \textwidth]{fig_stair.pdf}
\caption{ Staircase Mechanism}
\end{subfigure}
\caption{Probability Density Functions of Laplacian Mechanism and Staircase Mechanism}
\label{fig:probdf}
\end{figure}



\subsubsection{Applications: Minimum Noise Magnitude and Noise Power}

We apply our main result Theorem \ref{thm:main} to two typical cost functions  and , which measure noise magnitude and noise power, respectively. We derive the closed-form expressions for the optimal parameters  for these two cost functions. Comparing the optimal performances with those of the Laplacian mechanism, we show that in the high privacy regime ( is small), the Laplacian mechanism is asymptotically optimal as ;  in the low privacy regime ( is large), the minimum expectation of noise amplitude  and minimum noise power are  and  as , while  the expectation of noise amplitude and power using the Laplacian mechanism are  and , respectively, where  is the sensitivity of the query function. We conclude that the gains are more pronounced in the low privacy regime.



\subsubsection{Extension to the Discrete Setting}

Since for many important practical applications query functions are integer-valued, we also derive the optimal differentially private mechanisms for answering a single integer-valued query function.
 We show that adding query-output independent noise is optimal under a mild technical condition, and the optimal noise probability distribution has a staircase-shaped probability mass function, which can be viewed as the discrete variant of the staircase mechanism in the continuous setting.

 This result helps us directly compare our work and the existing works \cite{Ghosh09, minimax10} on integer-valued query functions. Our result shows that for integer-valued query function, the optimal noise probability mass function is also  staircase-shaped, and in the case the sensitivity , the optimal probability mass function is reduced to the geometric distribution, which was derived in \cite{Ghosh09, minimax10}. Therefore, this result can be viewed as a generalization of \cite{Ghosh09, minimax10} in the discrete setting for query functions with arbitrary sensitivity.













\subsection{Connection to the Literature}\label{subsec:connection}

In this section, we discuss the relations of our results and some directly related works in the literature, and the implications of our results on  other works.

\subsubsection{Laplacian Mechanism vs Staircase Mechanism}



The Laplacian mechanism is specified by two parameters,  and the query function sensitivity .  and  completely characterize the  differential privacy constraint. On the other hand, the staircase mechanism is specified by three parameters, , , and  which is determined by  and the utility function/cost function. For certain classes of utility functions/cost  functions, there are closed-form expressions for the optimal .

From the two examples given in Section \ref{sec:application}, we can see that although the Laplacian mechanism is not strictly optimal, in the high privacy regime (), Laplacian mechanism is asymptotically optimal:
\begin{itemize}
	\item For the expectation of noise amplitude, the additive gap from the optimal values goes to 0 as ,
	\item For noise power, the additive gap from the optimal values is upper bounded by a constant  as .
\end{itemize}
 However, in the low privacy regime (), the multiplicative gap from the optimal values can be arbitrarily large. We conclude that in the high privacy regime, the Laplacian mechanism is nearly optimal, while in the low privacy regime significant improvement can be achieved by using the staircase mechanism. We plot the multiplicative gain of staircase mechanism over Laplacian mechanism for expectation of noise amplitude and noise power in Figure  \ref{fig:comparison}, where  is the optimal (minimum) cost, which is achieved by staircase mechanism, and  is the cost of Laplacian mechanism. We can see that for , the staircase mechanism has about 15-fold and 23-fold improvement, with noise amplitude and power respectively. While  corresponds to really low privacy, our results show that low privacy can be had very cheaply (particularly when compared to the state of the art Laplacian mechanism).


Since the staircase mechanism is derived under the same problem setting as Laplacian mechanism, the staircase mechanism can be applied {\em wherever} Laplacian mechanism is used, and it performs {\em strictly better} than Laplacian mechanism (and significantly better in low privacy scenarios).



\begin{figure}[h]
\begin{subfigure}[b]{0.5\linewidth}
\centering
\includegraphics[width=1.1\textwidth]{fig1.pdf}
\caption{ }
\label{fig:compare1}
\end{subfigure}
\begin{subfigure}[b]{0.5\linewidth}
\centering
\includegraphics[width=1.1\textwidth]{fig2.pdf}
\caption{ }
\label{fig:compare2}
\end{subfigure}
\caption{Multiplicative Gain of the Staircase Mechanism over the Laplacian Mechanism. }
\label{fig:comparison}
\end{figure}


\subsubsection{Relation to Shamai and Verdu, \cite{SV92}}
Shamai and Verdu \cite{SV92} consider the minimum variance noise for a fixed value of the average of false alarm and missed detection probabilities of binary hypothesis testing. In \cite{SV92}, the binary hypotheses correspond to the signal being in a binary set . Their solution involved the noise being discrete and, further, having a pmf on the integer lattice (scaled by ). Our setting is related, but is differentiated via the following two key distinctions:
\begin{itemize}
\item Instead of a constraint on the sum of false alarm and missed detection probabilities, we have constraints on symmetric weighted combinations of the two error probabilities (as in Equations~\eqref{eq:famd1} and~\eqref{eq:famd2}).
\item Instead of the binary hypotheses corresponding to the signal being in a binary set  we consider all possible binary hypotheses for the signal to be in  where  are arbitrtary.
\end{itemize}



\subsubsection{Relation to Ghosh et. al. \cite{Ghosh09} }


Ghosh, Roughgarden, and Sundararajan  \cite{Ghosh09} show that for a single count query with sensitivity , for a general class of utility functions, to minimize the expected cost under a Bayesian framework the optimal mechanism to preserve differential privacy is the geometric mechanism, which adds noise with geometric distribution.

We discuss the relations and differences between \cite{Ghosh09} and our work in the following: Both \cite{Ghosh09} and our work are similar in that,  given the query output, the cost function only depends on the additive noise magnitude, and is an increasing function of noise magnitude. On the other hand, there are two main differences:
\begin{itemize}

	\item \cite{Ghosh09}  works under a Bayesian setting, while ours is to minimize the worst case cost.

	\item \cite{Ghosh09} studies a count query where the query output is integer-valued, bounded and sensitivity is unity.  In our work,  we first study general real-valued query function where the query output can take any real value, and then generalize the result to discrete setting where query output is integer valued.  In both cases, the sensitivity of query functions can be arbitrary, not restricted to one.
\end{itemize}


\subsubsection{Relation to  Gupte and Sundararajan  \cite{minimax10}  }

  Gupte and Sundararajan \cite{minimax10} derive the optimal noise probability distributions for a single count query with sensitivity  for minimax (risk-averse) users. Their model is the same as the one in \cite{Ghosh09} except that their objective function is to minimize the worst case cost, the same as our objective.  \cite{minimax10} shows that although there is no universally optimal solution to the minimax optimization problem in \cite{minimax10} for a general class of cost functions, each solution (corresponding to different cost functions) can be derived from the same geometric mechanism by randomly remapping.

  As in \cite{Ghosh09}, \cite{minimax10} assumes the query-output is bounded. Our result shows that when the query sensitivity is one, without any boundedness knowledge about the query-output, the optimal mechanism is to add random noise with geometric distribution to the query output.


\subsubsection{Relation to Brenner and Nissim  \cite{Nissim10}  }

While \cite{Ghosh09} shows that  for a single count query with sensitivity , there is a universally optimal mechanism for a general class of utility functions  under a Bayesian framework, Brenner and Nissim  \cite{Nissim10}  show that for general query functions no universally optimal mechanisms exist. Indeed, this follows directly from our results:  under our optimization framework, the optimal mechanism is adding noise with staircase-shaped probability distribution which is specified by three parameters  and , where in general  depends on the cost function.  Generally, for different cost functions, the optimal noise probability distributions have staircase-shaped probability density functions specified by different parameters.


\subsubsection{Relation to   Nissim, Raskhodnikova and Smith \cite{NRS07}  }

Nissim, Raskhodnikova and Smith \cite{NRS07} show that for certain nonlinear query functions, one can improve the accuracy by adding data-dependent noise calibrated to the smooth sensitivity of the query function, which is based on the local sensitivity of the query function. In our model, we use   the global sensitivity of the query function only, and assume that the local sensitivity is the same as the global sensitivity, which holds for a general class of query functions, e.g., count, sum.





\subsubsection{Relation to Hardt and Talwar  \cite{geometry}  }


Hardt and Talwar \cite{geometry} study the tradeoff between privacy and error for answering a set of linear queries over a histogram in a differentially private way. The  error is defined as the worst  expectation of the -norm of the noise. The lower bound given in \cite{geometry} is , where  is the number of linear queries. An immediate consequence of our result is that for fixed d, when , an upper bound of  is achievable by adding independent staircase-shaped noise with parameter  to each component.


\subsubsection{Relation to Other Works}

There are many existing works on studying how to improve the accuracy for answering more complex queries under differential privacy, in which the basic building block is the standard Laplacian mechanism. For example, Hay et. al. \cite{Hay10} show that  one can improve the accuracy for a general class of histogram queries, by exploiting the consistency constraints on the query output, and Li et. al. \cite{Li10}  study how to optimize linear counting queries under differential privacy by carefully choosing the set of linear queries to be answered. In these works, the error is measured by the mean squared error of query output estimates, which corresponds to the variance of the noise added to the query output to preserve differential privacy. In terms of , the error bound in these works scales linearly to , because of the use of Laplacian noise. If Laplacian distribution is replaced by staircase distribution in these works, one can improve the error bound to  (for some constant  which depends on the number of queries) when  (corresponding to the low privacy regime).










\subsection{Organization}

The paper is organized as follows. We show the optimality of query-output independent perturbation in Section \ref{sec:optimality}, and present the optimal differentially private mechanism, staircase mechanism, in Section \ref{sec:result}. In Section \ref{sec:application}, we apply our main result to derive the optimal noise probability distribution with minimum expectation of noise amplitude and power, respectively, and  compare the performances with the Laplacian mechanism.  Section \ref{sec:gammaproperty} presents the asymptotic properties of  in the staircase mechanism for momentum cost functions, and suggests a heuristic choice of  that appears to work well for a wide class of cost functions. Section \ref{sec:discrete} generalizes the staircase mechanism for integer-valued query function in the discrete setting, and Section \ref{sec:abstractsetting} extends the staircase mechanism to the abstract setting. Section \ref{sec:conclusion} concludes this paper.





