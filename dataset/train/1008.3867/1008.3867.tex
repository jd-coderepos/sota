


\documentclass{sigplanconf}



\usepackage{stmaryrd} \usepackage{amsthm, amssymb} \usepackage{verbatim}
\usepackage{hyperref}



\newcommand{\toy}{\mathcal{TOY}} \newcommand{\NAT}{\mathbb{N}} \newcommand{\REAL}{\mathbb{R}} 

\newcommand{\qdom}{\mathcal{D}} \newcommand{\dqdom}{D \setminus \{\bot\}} \newcommand{\bqdom}{(D \setminus \{\bot\}) \uplus \{?\}} 

\newcommand{\B}{\mathcal{B}}
\newcommand{\U}{\mathcal{U}}
\newcommand{\W}{\mathcal{W}}
\newcommand{\Set}{\mathcal{S}}

\newcommand{\simrel}{\mathcal{R}} 

\newcommand{\SL}{\mathcal{T}} \newcommand{\GL}{\mathcal{G}} 

\newcommand{\cdom}[1]{\mathcal{C}_{#1}} \newcommand{\rdom}{\mathcal{R}} 

\newcommand{\qlp}[1]{QLP({#1})} \newcommand{\slp}[2]{SLP({#1,#2})} \newcommand{\sqlp}[2]{SQLP({#1,#2})} \newcommand{\bqlp}[1]{BQLP({#1})} \newcommand{\clp}[1]{CLP({#1})} 

\newcommand{\trans}[2]{S_{#1}(#2)} 

\newcommand{\extended}[2]{H_{#1}(#2)} \newcommand{\abstracted}[2]{{#1}_{#2}} 

\newcommand{\MAProg}{\mathcal{P}_{E, \simrel}}

\newcommand{\diff}{芴镱珈彐趄殓梏狎蝻鬟茼狒栩睇溴纨 \newcommand{\eqdef}{竭茼狒栩睇溴纨 \newcommand{\tmin}{{\vartriangle}} \newcommand{\tmax}{\triangledown} \newcommand{\union}{\bigcup} \newcommand{\inter}{\bigcap} \newcommand{\supr}{\bigsqcup} \newcommand{\infi}{\bigsqcap} \newcommand{\Dentail}{荏蹉沣躜禊羼啕荞滹睚 \newcommand{\DentailSim}{荏蹉沣躜禊羼啕ㄜ箝眚屐荞滹愆 \newcommand{\app}{荑狒 

\newcommand{\Prog}{\mathcal{P}} \newcommand{\UProg}{\mathcal{P_U}}
\newcommand{\WProg}{\mathcal{P_W}}
\newcommand{\BProg}{\mathcal{P_B}}
\newcommand{\UWProg}{\mathcal{P_{\U \times \W}}}
\newcommand{\Var}{\mathcal V\!ar} \newcommand{\War}{\mathcal W\!ar} \newcommand{\elemset}[2]{\mathrm{#1}(#2)} \newcommand{\varset}[1]{\elemset{var}{#1}} \newcommand{\warset}[1]{\elemset{war}{#1}} \newcommand{\domset}[1]{\elemset{dom}{#1}} \newcommand{\Tp}{\mathrm{T}_{\Prog}} \newcommand{\Tpd}{\mathrm{T}_{\Prog,\qdom}} \newcommand{\Mp}{\mathcal{M}_{\Prog}} \newcommand{\M}[1]{\mathcal{M}_{#1}} \newcommand{\Atz}{\mathrm{At}_{\Sigma}} \newcommand{\QAtz}{\mathrm{At}_{\Sigma}(\qdom)} \newcommand{\intd}{\mathrm{Int}_{\Sigma}(\qdom)} \newcommand{\intrd}{\mathrm{Int}_{\Sigma}(\simrel,\qdom)} \newcommand{\sust}{\mathrm{Subst}_{\Sigma}} \newcommand{\sustd}{\sust(\qdom)} \newcommand{\I}{\mathcal{I}} \newcommand{\J}{\mathcal{J}} \newcommand{\at}[2]{#1\,\sharp\,#2} \newcommand{\ats}[1]{\overline{#1}} \newcommand{\qgets}[1]{\gets\!#1\!-} \newcommand{\sep}{荇犰祜忪镱琮 \newcommand{\true}{\texttt{tt}} \newcommand{\false}{\texttt{ff}} \newcommand{\linear}[1]{#1_\ell} 

\newcommand{\sld}[1]{SLD({#1})} \newcommand{\qhl}[1]{QHL({#1})} \newcommand{\sqhl}[2]{SQHL({#1,#2})} \newcommand{\sqhlx}[3]{\vdash_{\mathrm{SQHL}(#1,#2)}^{#3}} \newcommand{\sqhlrd}{\sqhlx{\simrel}{\qdom}{}} \newcommand{\sqhlrdn}[1]{\sqhlx{\simrel}{\qdom}{#1}} \newcommand{\qhlx}[2]{\vdash_{\mathrm{QHL}(#1)}^{#2}} \newcommand{\qhld}{\qhlx{\qdom}{}} \newcommand{\qhldn}[1]{\qhlx{\qdom}{#1}} \newcommand{\resx}{\Vdash}
\newcommand{\qres}[1]{\resx_{#1}}
\newcommand{\qresn}[2]{\resx^{#1}_{#2}}
\newcommand{\qsol}[1]{QSol_{\Prog}(#1)}
\newcommand{\qsoln}[2]{QSol_{\Prog}^{#1}(#2)}
\newcommand{\MALP}{{\em MALP }}
\newcommand{\malp}{{\em MALP}}

\theoremstyle{definition}
\newtheorem{definition}{Definition}

\theoremstyle{plain}
\newtheorem{lemma}{Lemma}
\newtheorem{proposition}{Proposition}
\newtheorem{theorem}{Theorem}
\newtheorem{example}{Example}

\begin{document}

\conferenceinfo{PPDP'08,} {July 15--17, 2008, Valencia, Spain.}
\CopyrightYear{2008}
\copyrightdata{978-1-60558-117-0/08/07}

\titlebanner{banner above paper title}        \preprintfooter{short description of paper}   

\title{Similarity-based Reasoning in Qualified Logic Programming}
\subtitle{Revised Edition}

\authorinfo{Rafael Caballero \and Mario Rodr\'iguez-Artalejo \and Carlos A. Romero-D\'iaz}
           {Departamento de Sistemas Inform\'aticos y Computaci\'on \\ Universidad Complutense de Madrid, Spain}
           {rafa,mario@sip.ucm.es, cromdia@fdi.ucm.es}

\maketitle

\begin{abstract}
{\em Similarity-based Logic Programming} (briefly, ) has been proposed to enhance the  paradigm with a kind of approximate reasoning which supports flexible information retrieval applications. This approach uses a fuzzy similarity relation  between symbols in the program's signature,  while keeping the syntax for program  clauses as in classical . Another recent proposal is the   scheme for {\em Qualified Logic Programming}, an extension of the  paradigm which supports approximate reasoning and more. This approach uses annotated program clauses and a parametrically given domain   whose elements  qualify logical assertions by measuring their closeness to various users' expectations. In this paper we propose  a more expressive scheme  which subsumes both  and  as particular cases. We also show that  programs can be transformed into semantically equivalent  programs.  As a consequence, existing  implementations can be used to give efficient support for similarity-based reasoning.
\end{abstract}

\category{D.1.6}{Programming Techniques}{Logic Programming}
\category{D.3.2}{Programming Languages}{Language Classifications}[Constraint and logic languages]
\category{F.3.2}{Theory of Computation}{Logics and Meanings of Programs}[Algebraic approaches to semantics]

\terms Algorithms, Languages, Theory

\keywords
Qualification Domains, Similarity Relations

\section{Introduction} \label{Introduction}

The historical evolution of the research on uncertainty in {\em Logic Programming} () has been described in a recent recollection by V. S. Subrahmanian \cite{Sub07}. Early approaches include the quantitative  treatment of uncertainty in the spirit of fuzzy logic, as in van Emden's classical paper \cite{VE86} and two subsequent papers by Subrahmanian \cite{Sub87,Sub88}. The main contribution of \cite{VE86} was a rigorous declarative semantics for a  language with program clauses  of the form , where the head  is an atom, the body  is a conjunction of atoms, and the so-called {\em attenuation} factor  attached to the clause's implication is used to propagate
to the head the certainty factor , where  is the minimum of the certainty factors  previously computed for the various atoms occurring in the body. The papers \cite{Sub87,Sub88} proposed to use a special lattice  in place of the lattice of the real numbers in the interval  under their natural ordering.  includes two isomorphic copies of  whose elements are incomparable under 's ordering and can be used separately to represent degrees of {\em truth} and {\em falsity}, respectively, thus enabling a simple treatment of
negation. Other main contributions of \cite{Sub87,Sub88} were the introduction of annotated program clauses and goals (later generalized to a much more expressive framework in \cite{KS92}), as well as goal solving procedures more convenient and powerful than those given in \cite{VE86}.

A more recent line of research is {\em Similarity-based Logic Programming}  (briefly, ) as presented in \cite{Ses02} and previous related works such as \cite{AF99,GS99,FGS00,Ses01}. This approach also uses the lattice  to deal with uncertainty in the spirit of fuzzy logic. In contrast to approaches based on annotated clauses, programs in  are just sets of definite Horn clauses as in classical . However, a {\em similarity relation}  (roughly, the fuzzy analog of an equivalence relation) between predicate and function symbols is used to enable the
unification terms that would be not unifiable in the classical sense, measured by some degree . There are different proposals for the operational semantics of  programs. One possibility is to apply  classical  resolution w.r.t. a transformation of the original program \cite{GS99,Ses01,Ses02}. Alternatively, a -based -resolution procedure relying on -unification can be applied w.r.t. to the original program, as proposed in \cite{Ses02}. Propositions 7.1 and 7.2 in \cite{Ses02} state a correspondence between the answers computed by
-based  resolution w.r.t. a given logic program  and the answers computed by classical  resolution w.r.t. the two transformed programs  (built by adding to  new clauses -similar to those in  up to the degree ) and  (built by replacing all the function and predicate symbols in  by new symbols that represent
equivalence classes modulo -similarity up to ). The  system  \cite{LSS04} has been developed to implement  and to support applications related to flexible information retrieval from the web.

The aim of the present paper is to show that similarity-based reasoning can be expressed in , a programming scheme for {\em Qualified}  over a parametrically given {\em Qualification Domain}  recently presented in \cite{RR08} as a generalization and improvement of the classical approach by van Emden \cite{VE86} to  . Qualification domains are lattices satisfying certain natural axioms. They include the lattice  used both in \cite{VE86} and in \cite{Ses02}, as well as other lattices whose elements can be used to qualify logical
assertions by measuring their closeness to different kinds of users' expectations. Programs in  use -attenuated clauses of the form  where  is an atom,  a finite conjunction of atoms and  is the {\em attenuation value} attached to the clause's implication, used to propagate to the head the {\em qualification value} , where  is the infimum in  of the qualification values  previously computed for the various atoms occurring in the body, and   is an {\em attenuation operator} coming
with . As reported in \cite{RR08,RR08TR}, the classical results in  concerning the existence of least Herbrand models of programs and the soundness and completeness of the   resolution procedure (see e.g.\cite{VEK76,AVE82,Apt90}) have been extended to the  scheme, and potentially useful instances of the scheme have been implemented on top of the {\em Constraint Functional Logic Programming} () system  \cite{toy}.

The results presented in this paper can be summarized as follows: we consider generalized similarity relations over a set  as mappings  taking values in the carrier set  of an arbitrarily  given qualification domain , and we  extend  to a more expressive scheme  with two parameters for programming modulo -similarity with -attenuated Horn clauses. We present a declarative semantics for  and a program transformation mapping each  program  into a
 program  whose least Herbrand model corresponds to that of . Roughly,  is built adding to  new clauses obtained from the original clauses in  by computing various new heads -similar to a linearized version of the original head, adding also -similarity conditions   to the body and suitable clauses for  the  new predicate  to
emulate -based unification. Thanks to the  transformation, the sound and complete procedure for solving goals in  by -qualified  resolution and its implementation in the  system \cite{RR08} can be used to implement  computations, including as a particular case  computations in the sense of \cite{Ses02}.

Another recent proposal for reducing the  approach in \cite{Ses02} to a fuzzy  paradigm can be found in \cite{MOV04}, a  paper which relies on  the multi-adjoint framework for Logic Programming ({\MALP} for short) previously proposed in \cite{MOV01a,MOV01b}. {\MALP} is a quite general framework supporting  with {\em weighted program rules} over different multi-adjoint lattices, each of which provides a particular choice of operators for implication, conjunction  and aggregation of atoms in rule bodies. In comparison to the  scheme, the multi-adjoint framework differs in motivation and scope. Multi-adjoint lattices and qualification domains are  two different classes of algebraic structures. Concerning declarative and
operational semantics, there are also some significant differences between  and \malp. In particular, \MALP's goal solving procedure relies on a costly computation of {\em reductant clauses}, a technique borrowed from \cite{KS92} which can be avoided in , as discussed in the concluding section of \cite{RR08}.

In spite of these differences, the results in \cite{MOV04} concerning the emulation of similarity-based  can be compared to those in the present paper. Theorem 24 in \cite{MOV04} shows that  every classical logic  program  can be transformed into a \MALP program  which can be executed using only syntactical unification and emulates the successful computations of  using the  resolution with -based unification
introduced  in \cite{Ses02}.  works over a particular multi-adjoint lattice  with carrier set  and implication and conjunction operators chosen according to the so-called G\"{o}del's semantics \cite{Voj01}.  also introduces clauses for a binary predicate  which emulates -based unification, as in our transformation . Nevertheless,    is defined for a more general class of programs and uses the -similarity predicate  only if the source program  has some clause whose head is non-linear. More detailed comparisons between the program transformations ,  ,  and  will be given in Subsection \ref{sec:RA}.

The rest of the paper is structured as follows: In Section \ref{Domains} we recall the qualification domains   first introduced in \cite{RR08} and we define similarity relations  over an arbitrary qualification domain. In Section \ref{Language} we recall the scheme  and we introduce its extension  with its declarative semantics, given by a logical calculus which characterizes the least
Herbrand model  of each  program . In Section \ref{Reduction} we define the transformation  of any given  program  into a  program  such that , we give some comparisons to previously known program transformations, and we illustrate the application of
 to similarity-based computation by means of a simple example. Finally, in Section \ref{Conclusions} we summarize conclusions and comparisons to related work and we point to planned lines of future work.

\section{Qualification Domains and Similarity Relations} \label{Domains}

\subsection{Qualification Domains} \label{QD}
{\em Qualification Domains}  were introduced in \cite{RR08} with the aim of using their elements to qualify logical assertions in different ways. In this subsection we recall their axiomatic definition and some significant examples.


\begin{definition}  \label{defQD}
A  {\em Qualification Domain} is any structure   verifying the following requirements:
\begin{enumerate}
    \item  is a lattice with extreme points  and  w.r.t. the partial ordering . For given elements  , we  write  for the {\em greatest lower bound} () of  and  and  for the {\em least upper bound} () of  and . We also write  as abbreviation for .
    \item , called {\em attenuation operation}, verifies the following axioms:
        \begin{enumerate}
            \item  is associative, commutative and monotonic w.r.t. .
            \item .
            \item .
            \item .
            \item . \qed
        \end{enumerate}
\end{enumerate}
\end{definition}

In the rest of the paper,  will generally denote an arbitrary qualification domain. For any finite , the  of  (noted as ) exists and can be computed as  (which reduces to  in the case ). As an easy consequence of the axioms, one gets the identity .  The  scheme presented in \cite{RR08} supports  over a parametrically given qualification domain .

\begin{example} \label{someDomains}
Some examples of  qualification domains are presented below. Their intended use for qualifying logical assertions will become more clear in Subsection \ref{QLP}.
\begin{enumerate}
\item
, where  and  stand for the two classical truth values  \emph{false} and \emph{true},  is the usual numerical ordering over , and  stands for the classical conjunction operation over . Attaching  to  an atomic formula   is intended to qualify  as `true' in the sense of classical .
\item
, where ,  is the usual numerical ordering, and  is the multiplication operation. In this domain,  the top element  is  and the greatest lower bound  of a finite  is the minimum value min(S), which is  if . Attaching an  element   to an atomic formula   is intended to qualify  as `true with certainty  degree ' in the spirit of fuzzy logic, as done in the classical paper \cite{VE86} by van Emden. The computation of qualifications  as certainty degrees in  is due to the interpretation of  as  and  as .
\item
, where ,  is the reverse of the usual numerical ordering (with  for any ), and  is the addition operation (with  for any ). In this domain,  the top element  is  and the greatest lower bound  of a finite  is the maximum value max(S), which is  if . Attaching an element  to an atomic formula  is intended to qualify  as `true with weighted proof depth '. The computation of qualifications  as weighted proof depths in  is due to the interpretation  of  as  and  as .
\item
Given 2 qualification domains   (), their {\em cartesian product}  is , where  , the partial ordering  is defined as  and , , , and the attenuation operator  is defined as
. The product of two given qualification domains is always another  qualification domain, as proved in \cite{RR08}. Intuitively, each value  belonging to  imposes the qualification  {\em and also} the qualification . For instance, values  belonging to  impose two qualifications, namely: a certainty degree greater or equal than  and a weighted proof depth less or equal than . \qed
\end{enumerate}
\end{example}

For technical reasons that will become apparent in Section \ref{Reduction}, we consider the two structures  resp.  defined analogously to   resp. , except that  behaves as  in  and as  in . Note that almost all the axioms for qualification domains enumerated in Definition \ref{defQD} hold in  and , except that axiom  holds only in the relaxed form
. Therefore, we will refer to  and  as {\em quasi} qualification domains.

\subsection{Similarity relations} \label{SR}

{\em Similarity relations} over a given set   have been defined in \cite{Ses02} and related literature as mappings  that satisfy three axioms analogous to those required for classical equivalence relations. Each value  computed by a similarity relation  is called the {\em similarity  degree} between  and . In this paper we use a natural extension of the definition given in \cite{Ses02}, allowing elements of an arbitrary qualification domain   to serve as similarity degrees. As in \cite{Ses02}, we  are especially interested in similarity relations over sets  whose elements are variables and symbols of a given signature.

\begin{definition} \label{defSR} Let a qualification domain  with carrier set  and a set  be given.
\begin{enumerate}
\item A {\em -valued similarity relation} over  is any mapping   such that the three following axioms hold for all :
    \begin{enumerate}
        \item {\em Reflexivity:} .
        \item {\em Symmetry:} .
        \item {\em Transitivity:} .
    \end{enumerate}
\item The mapping  defined as  for all  and  for all ,  is trivially a -valued similarity relation called the \emph{identity}.
\item A -valued similarity relation  over  is called {\em admissible} iff  (where the three mutually disjoint sets ,  and  stand for a countably infinite collection of {\em variables}, a set of {\em constructor symbols} and a set of {\em predicate symbols}, respectively) and the two following requirements are satisfied:
    \begin{enumerate}
        \item  restricted to  behaves as the identity, i.e.  for all  and  for all , .
        \item  holds only if some of the following three cases holds : either  are both the same variable; or else  are constructor symbols with the same arity; or else  are predicate  symbols with the same arity. \qed
    \end{enumerate}
\end{enumerate}
\end{definition}

The similarity degrees computed by a -valued similarity relation must be interpreted w.r.t. the intended role of -elements as qualification values. For example, let   be an admissible similarity relation, and let  be two nullary constructor symbols (i.e., constants). If  is -valued, then  can be interpreted as a {\em certainty degree} for the assertion that  and  are similar. On the other hand, if  is -valued, then  can be interpreted as a {\em cost} to be paid for  to play the role of . These two views are coherent with the different interpretations of the operators  and  in  and , respectively.

In the rest of the paper we assume that any admissible similarity relation  can be extended to act over terms, atoms and clauses. The extension, also called , can be recursively defined as in \cite{Ses02}. The following definition specifies the extension of  acting over terms. The case of atoms and clauses is analogous.

\begin{definition} ( acting over terms). \label{def:ER}
\begin{enumerate}
    \item For  and for any term  different from :\\
     and .

    \item For  with different arities , :\\
    .

    \item For  with the same arity :\\
    .
\end{enumerate}
\end{definition}

\section{Similarity-based Qualified Logic Programming}\label{Language}

In this section  we extend our previous scheme    to a more expressive scheme called \emph{Similarity-based Qualified Logic Programming} over  --abbreviated as -- which supports both qualification over  in the sense of \cite{RR08} and -based similarity in the sense of \cite{Ses02} and related research. Subsection \ref{QLP} presents a quick review of the main results concerning syntax and declarative semantics of  already presented in \cite{RR08}, while the extensions needed to conform the new  scheme are presented in subsection \ref{SQLP}.


\subsection{Qualified Logic Programming} \label{QLP}

 was proposed in our previous work \cite{RR08} as a generic scheme for qualified logic programming over a given qualification domain . In that scheme, a \emph{signature}  providing constructor and predicate symbols with given arities is assumed. \emph{Terms} are built from constructors and \emph{variables} from a countably infinite set  (disjoint from )  and \emph{Atoms} are of the form  (shortened as  or simply ) where  is a -ary predicate symbol and  are terms. We write , called the \emph{open Herbrand base}, for the set of all atoms. A  program  is a finite set of \emph{-qualified definite Horn clauses} of the form  where  is an atom,  a finite conjunction of atoms and  is the \emph{attenuation value} attached to the clause's implication.

As explained in  \cite{RR08}, in our aim to work with qualifications we are not only interested in just proving an atom, but in proving it along with a qualification value. For this reason, \emph{-qualified atoms} ( where  is an atom and ) are introduced to represent the statement that the atom  holds for \emph{at least} the qualification value . For use in goals to be solved, \emph{open -annotated atoms} ( where  is an atom and  a \emph{qualification variable} intended to take values over ) are also introduced, and a countably infinite set  of qualification variables (disjoint from  and ) is postulated. The \emph{annotated Herbrand base} over  is defined as the set  of all -qualified atoms. A \emph{-entailment relation} over , defined as  iff there is some substitution  such that  and , is used to formally define an \emph{open Herbrand interpretation} over  --from now on just an \emph{interpretation}-- as any subset  which is closed under -entailment. We write  for the family of all interpretations. The notion of model is such that given any clause  in the  program , an interpretation  is said to be a \emph{model} of  iff for any substitution  and any qualification values  such that  for all , one has . The interpretation  is also said to be a model of the  program  (written as ) iff it happen to be a model of every clause in .

As technique to infer formulas (or in our case -qualified atoms) from a given  program , and following traditional ideas, we consider two alternative ways of formalizing an inference step which goes from the body of a clause to its head: both an interpretation transformer , and a qualified variant of Horn Logic, noted as , called \emph{Qualified Horn Logic} over . As both methods are equivalent and correctly characterize the least Herbrand model of a given program , we will only be recalling the logic , although we encourage the reader to see Section 3.2 in \cite{RR08}, where the fix-point semantics is explained.

The logic  is defined as a deductive system consisting just of one inference rule: , called \emph{Qualified Modus Ponens} over . Such rule allows us to give the following inference step given that there were some , some substitution  such that  and  for all  and some  such that :

Roughly, each  inference step using an instance of a program clause  has the effect of propagating to the head the {\em qualification value} , where  is the infimum in  of the qualification values   previously computed for the various atoms occurring in the body. This helps to understand the claims made in Example \ref{someDomains} above about the intended use of elements of the domains  and  for qualifying logical assertions. We use the notations  (resp. ) to indicate that  can be inferred from the clauses in program  in finitely many steps (resp.  steps). The \emph{least Herbrand model of } happens to be , as proved in \cite{RR08}.

\subsection{Similarity-based Qualified Logic Programming} \label{SQLP}

\begin{figure}
\begin{center}
\tt
\begin{tabular}{|r@{\hspace{0.2cm}}l|}
\hline
&\\
\scriptsize 1 & wild(lynx) <-0.9- \\
\scriptsize 2 & wild(boar) <-0.9- \\
\scriptsize 3 & wild(snake) <-1.0- \\
&\\
\scriptsize 4 & farm(cow) <-1.0- \\
\scriptsize 5 & farm(pig) <-1.0- \\
&\\
\scriptsize 6 & domestic(cat) <-0.8- \\
\scriptsize 7 & domestic(snake) <-0.4- \\
&\\
\scriptsize 8 & intelligent(A) <-0.9- domestic(A) \\
\scriptsize 9 & intelligent(lynx) <-0.7- \\
&\\
\scriptsize 10 & pacific(A) <-0.9- domestic(A) \\
\scriptsize 11 & pacific(A) <-0.7- farm(A) \\
&\\
\scriptsize 12 & pet(A) <-1.0- pacific(A), intelligent(A) \\
&\\
\hline
&\\
&(farm,domestic) = 0.3 \\
&(pig,boar) = 0.7 \\
&(lynx,cat) = 0.8 \\
&\\
\hline
\end{tabular}
\end{center}
\caption{ program.\label{fig:example}}
\end{figure}

The scheme  presented in this subsection has two parameters  and , where  can be any qualification domain and  can be any admissible -valued similarity relation, in the sense of Definition \ref{defSR}. The new scheme subsumes the approach in \cite{RR08} by behaving as  in the case that   is chosen as the identity, and it also subsumes similarity-based  by behaving as the approach in \cite{Ses02} and related papers in  the case that  is chosen as .

Syntactically,  presents almost no changes w.r.t. , but the declarative semantics must be extended to account for the behavior of the parametrically given similarity relation .  As in the previous subsection, we assume a signature  providing again constructor and predicate symbols. \emph{Terms} and \emph{Atoms} are built the same way they were in , and  will stand again for the set of all atoms, called the \emph{open Herbrand base}. An atom  is called {\em linear} if there is no variable with multiple occurrences in ; otherwise  is called {\em non-linear}. A  program  is a finite set of \emph{-qualified definite Horn clauses} with the same syntax as in , along with a -valued admissible similarity relation  in the sense of Definition \ref{defSR}, item 2. Figure \ref{fig:example} shows a simple  program built from the similarity relation  given in the same figure and the qualification domain  for certainty values. This program will be used just for illustrative purposes in the rest of the paper. The reader is referred to Section \ref{Domains} for other examples of qualification domains, and to the references \cite{LSS04,MOV04} for suggestions concerning practical applications of similarity-based .

\emph{-qualified atoms} ( with  an atom and ) and \emph{open -annotated atoms} ( with  and atom and  a qualification variable intended to take values in ) will still be used here. Similarly, the \emph{annotated open Herbrand base} over  is again defined as the set  of all -qualified atoms. At this point, and before extending the notions of -entailment relation and interpretation to the  scheme, we need to define what an -instance of an atom is.  Intuitively, when building -instances of an atom , signature symbols occurring in  can be replaced by similar ones, and different occurrences of the same variable in  may be replaced by different terms, whose degree of similarity must be taken into account. Technically, -instances of an atom  are built from a linearized version of  which has the form  and is constructed as follows:  is a linear atom built from  by replacing each  additional occurrences of a variable  by new fresh variables  ; and  is a set of \emph{similarity conditions}  (with ) asserting the similarity of all variables in  that correspond to the same variable  in . As a concrete illustration, let us show the linearization of two atoms. Note what happens when the atom  is already linear as in the first case:  is just the same as  and  is empty.

    \begin{itemize}
        \item  \\
        

        \item  \\
        
    \end{itemize}

Now we are set to formally define the -instances of an atom.

\begin{definition}\label{def:r-instance-atom}
(-instance of an atom). Assume an atom  and its linearized version . Then, an atom  is said to be an -instance of  with similarity degree , noted as , iff there are some atom  and some substitution  such that  and .
\end{definition}

Next, the \emph{-entailment relation} over  is defined as follows:  iff there is some similarity degree  such that  and . Finally, an \emph{open Herbrand interpretation} --just \emph{interpretation} from now on-- over  is defined as any subset  which is closed under -entailment. That is, an interpretation  including a given -qualified atom  is required to include all the `similar instances'  such that , because we intend to formalize a semantics in which all such similar instances are valid whenever  is valid. This complements the intuition given for the -entailment relation in  to include the similar instances (obtainable due to ) of each atom, and not only those which are true because we can prove them for a better (i.e. higher in ) qualification. Note that -entailment is a refinement of -entailment, since:   there is some substitution  such that  and    and   .

As an example of the closure of interpretations w.r.t. -entailment, consider the -qualified atom \texttt{domestic(cat)\#0.8}. As a trivial consequence of Proposition \ref{prop:least-model} below,  this atom belongs to the least Herbrand model of the program in Figure \ref{fig:example}. On the other hand, we also know that  \texttt{lynx} is similar to  \texttt{cat} with a similarity degree of  w.r.t. the similarity relation  in Figure \ref{fig:example}. Therefore, \texttt{domestic(lynx)} is a -instance of  \texttt{domestic(cat)} to the degree . Then, by definition of -entailment, it turns out that \texttt{domestic(cat)\#0.8}  \texttt{domestic(lynx)\#0.64}, and the -qualified atom \texttt{domestic(lynx)\#0.64} does also belong to the least model of the example program. Intuitively,  is the best -qualification which can be inferred from the -qualification  for  \texttt{domestic(cat)} and the -similarity  between  \texttt{domestic(cat)} and  \texttt{domestic(lynx)}.

We will write  for the family of all interpretations over , a family for which the following proposition can be easily proved from the definition of an interpretation and the definitions of the union and intersection of a family of sets.

\begin{proposition}\label{prop:lattice}
The family  of all interpretations over  is a complete lattice under the inclusion ordering , whose extreme points are  as maximum and  as minimum. Moreover, given any family of interpretations , its lub and glb are  and , respectively.
\end{proposition}

Similarly as we did for the -instances of an atom, we will define what the -instances of a clause are. The following definition tells us so.

\begin{definition}\label{def:r-instance-clause}
(-instance of a clause). Assume a clause  and the linearized version of its head atom . Then, a clause  is said to be an -instance of  with similarity degree , noted as , iff there are some atom  and some substitution  such that   and .
\end{definition}

Note that as an immediate consequence from Definitions \ref{def:r-instance-atom} and \ref{def:r-instance-clause} it is true that given two clauses  and  such that , and assuming  to be head atom of  and  to be the head atom of , then we have that .

Let  be any clause  in the program , and  any interpretation over . We say that  is a model of  iff for any clause  such that  and any qualification values  such that  for all , one has  where . And we say that  is a model of the  program  (also written ) iff  is a model of each clause in .



We will provide now a way to perform an inference step from the body of a clause to its head. As in the case of  , this can be formalized in two alternative ways, namely an interpretation transformer and a variant of Horn Logic. Both approaches lead to equivalent characterizations of least program models. Here we focus on the second approach, defining what we will call \emph{Similarity-based Qualified Horn Logic} over  --abbreviated as --, another variant of Horn Logic and an extension of the previous . The logic  is also defined as a deductive system consisting just of one inference rule , called \emph{Similarity-based Qualified Modus Ponens} over :

If  for some clause  with attenuation value , then the following inference step is allowed for any  such that :


We will use the notations  (respectively ) to indicate that  can be inferred from the clauses in program  in finitely many steps (respectively  steps). Note that  proofs can be naturally represented as upwards growing \emph{proof trees} with -qualified atoms at their nodes, each node corresponding to one inference step having the children nodes as premises.

The following proposition contains the main result concerning the declarative semantics of the  scheme. A full proof can be developed in analogy to the  case presented in \cite{RR08,RR08TR}.

\begin{proposition}\label{prop:least-model}
Given any  program . The \emph{least Herbrand model} () of  is 
\end{proposition}

The following example serves as an illustration of how the logic  works over  using the example program displayed in Figure  \ref{fig:example}.

\begin{example}\label{ex:least-model}
The following proof tree proves that the atom \emph{\texttt{pet(ly\-nx)}} can be inferred for at least a qualification value of  in the  program  of Figure \ref{fig:example}. Let's see it:



\noindent where the clauses and qualification values used for each inference step are:

\begin{enumerate}
    \item[(1)] \emph{\texttt{pet(lynx) <-1.0- pacific(lynx),intelligent(lynx)}} is an instance of clause  in  and   . Note that the first  in the minimum is the one which comes from the similarity relation as for this step we are just using a plain instance of clause  in .
    \item[(2)] \emph{\texttt{pacific(lynx) <-0.9- domestic(lynx)}} is a plain instance of clause  in  and .
    \item[(3)] \emph{\texttt{intelligent(lynx) <-0.7-}} is clause  in  and .
    \item[(4)] The clause \emph{\texttt{domestic(lynx) <-0.8-}} is an -instance of clause  with a similarity degree of  and we have . \qed
\end{enumerate}
\end{example}

\section{Reducing Similarities to Qualifications} \label{Reduction}

\subsection{A Program Transformation} \label{sec:PT}

In this section we prove that any  program  can be transformed into an equivalent  program which will be denoted by . The program transformation is defined as follows:

\begin{definition} \label{def:trans}
Let  be a  program. We define the transformed program  as:

where the auxiliary sets of clauses , ,  are defined as:
\begin{itemize}
\item For each clause  and for each  such that 

where .
\item  
       of arity , 
\item  for each atom  occurring in 
\end{itemize}
\end{definition}

Note that the linearization of clause heads in this transformation is motivated by the role of linearized atoms in the  logic defined in Subsection \ref{SQLP} to specify the declarative semantics of  programs. For instance, assume  a  program  including the clause  and two nullary constructors ,  such that . Then,  supports the derivation , and the transformed program  will include the clauses

thus enabling the corresponding derivation  in .



In general,  and  are semantically equivalent in the sense that   holds for any -qualified atom , as stated in Theorem \ref{th:equivalence} below. The next technical lemma will be useful for the proof of this theorem.

\begin{lemma} \label{lema:equiv}
Let  be a  program and  its transformed program according to Definition \ref{def:trans}. Let  be two terms in 's signature and . Then:
\begin{enumerate}
    \item \label{lema:equiv:1} 
    \item \label{lema:equiv:2} 
\end{enumerate}
\end{lemma}

\begin{proof} We prove the two items separately.


\begin{enumerate}
    \item Let  be a  proof tree witnessing  We prove by induction on number of nodes of  that . The basis case, with  consisting of just one node, must correspond to some inference without premises, i.e., a clause with empty body for . Checking  we observe that  is the only possibility. In this case  and  must be the same term and by the reflexivity of  (Def. \ref{defSR}), , which means  for every . In the inductive step, we consider  with more than one node. Then the inference step at the root of  uses some clause , and must be of the form:
        
        where , , , , , and  s.t. , i.e., . By induction hypothesis  for . Then  implies    and hence  (Def. \ref{def:ER}, item 3).

    \item If , , we prove that  by  induction on the syntactic structure of . The basis corresponds to the case  for some constant , or  for some variable . If  then  for some other constant . By Definition \ref{def:trans} there is a clause in  of the form . Using this clause and the identity substitution we can write the root inference step of a proof for  as follows:
        
        The condition required by the inference rule  is in this particular case , and . Proving the only premise   in  is direct from its definition. If , with  a variable, then  and  (otherwise ). Then  can be proved by using the clause  with substitution .

In the inductive step,  must be of the form , with , and then  must be of the form  (otherwise ). From  (hypotheses of the lemma) and Definition \ref{def:ER} we have that . Then, by Definition \ref{def:trans}, there is a clause in  of the form: {\small  } By using the substitution  we can write the root inference step in  as:
    

The inference can be applied because the condition  reduces to  which holds by Definition \ref{def:ER}, item 3. Moreover, the premises , , hold in  due to the inductive hypotheses, and proving  is straightforward from its definition.\qedhere
\end{enumerate}
\end{proof}

Now we can prove the equivalence between semantic inferences in  w.r.t.  and semantic inferences in  w.r.t. .

\begin{theorem} \label{th:equivalence}
Let  be a  program,   an atom in 's signature and . Then:

\end{theorem}

\begin{proof}
Let  be a  proof tree for some annotated atom  in 's signature witnessing . We prove that  by induction on the number of nodes of .

The inference step at the root of   must be of the form

with  for some clause  (observe that the case  corresponds to the induction basis). By Definition \ref{def:r-instance-clause}, ,  for some substitution  and atom  such that  , with . This means in particular that , which by Definition \ref{def:trans} implies that  there is a clause  in  of the form . Then the root inference step of the deduction proving  will use the inference rule  with  and substitution  (such that ) as follows:

where , and  for .

Next we check that the premises can be proved from  in :
\begin{itemize}
    \item , since  is a nullary predicate for every . Therefore  is immediate from the definition of  in Definition \ref{def:trans}.

    \item For each , we observe that  because  has been computed above as the infimum of a set including  among its members. Then  holds by Lemma \ref{lema:equiv}, item \ref{lema:equiv:2}.

    \item For each , (1) shows that  with a proof tree having less nodes that . Therefore,  by induction hypothesis.
\end{itemize}

In order to perform the inference step (2), the QMP() inference rule also requires that . This follows from the associativity of  since:
\begin{itemize}
    \item As defined above,  , i.e.  .
    \item By the   inference (1) we know that .
\end{itemize}
\medskip

Let  be a  proof tree witnessing    for some atom  in 's signature.  We prove by induction on the number of nodes of  that .

Since  is in 's signature, the clause employed at the inference step at the root of  must be in the set  of Definition \ref{def:trans}, and the inference step at the root of  have of the form of the inference (2) above. Hence this clause must have been constructed from a clause  and some atom  such that  and , where .

Then we can use  and  to prove  by  a  inference like (1) using the -instance  of . The premises can be proved in  by induction hypotheses, since all of them are also premises in (2). Finally, we must check that the conditions required by (1) hold:   for some ,  s.t. . This is true for , with  for . Observe that in the premises of (2) we have  proofs of  for . Therefore , by Lemma \ref{lema:equiv}, item \ref{lema:equiv:1}. Then


We must still prove that . Observe that by the distributivity of  w.r.t.  (Def. \ref{defQD}, axiom 2.(e)): 

Therefore  and from  we obtain  which implies  due to axiom 2.(c) in Definition \ref{defQD}. This completes the proof.
\end{proof}

\subsection{ Comparison to Related Approaches} \label{sec:RA}

Other program transformations have been proposed in the literature with the aim of supporting -based reasoning while avoiding explicit -based unification. Here we draw some comparisons between the program transformation  presented in the previous subsection, the program transformations  and  proposed  in \cite{Ses02}, and the program transformation  proposed in \cite{MOV04}. These three transformations are applied to a classical logic program  w.r.t. a fuzzy similarity relation  over symbols in the program's signature. Both  and  are classical logic programs to be executed by  resolution, and their construction depends on a fixed similarity degree . On the other hand,  is a multi-adjoint logic program over a particular multi-adjoint lattice , providing the uncertain truth values in the interval  and two operators for conjunction and disjunction in the sense of G\"{o}del's fuzzy logic (see \cite{Voj01} for technical details). As in the case of our own transformation , the construction of   does not depend on any fixed similarity degree. The transformation  proposed in this paper is more general in that it can be applied to an arbitrary  program
, yielding a  program  whose least Herbrand model is the same  as that of .

We will restrict our comparisons  to the case that  is chosen as a similarity-based logic program in the sense of \cite{Ses02}. As an illustrative example, consider  the simple logic program  consisting of the following four clauses:
\begin{itemize}
    \item 
    \item 
    \item 
    \item 
\end{itemize}

Assume an admissible similarity relation defined by  and consider the goal  for . Then, -based -resolution as defined in \cite{Ses02} computes the answer substitution  with similarity degree . This computation succeeds because -based unification can compute the   with similarity degree  to unify the two atoms  and . Let us now examine the behavior of the the transformed programs , ,  and  and when working to emulate this computation without  explicit use of a -based unification procedure.

\begin{enumerate}

    \item  is defined in \cite{Ses02} as the set of all clauses  such that  for some clause . In this case  includes the four clauses of  and the two additional clauses  and , derived by similarity from  and , respectively. Solving  w.r.t.  by means of classical  resolution produces two possible answer substitutions, namely  and . They are both similar to  to a degree greater or equal than , but none of them is  itself, contrary to the claim in Proposition 7.1 (i) from \cite{Ses02}. Therefore, this Proposition seems to hold only in a somewhat weaker sense than the statement in \cite{Ses02}. This problem is due to the possible non-linearity of a clause's head, which is properly taken into account by our transformation .

    \item According to \cite{Ses02},  is computed from  by replacing all the constructor and predicate symbols by new symbols that represent the equivalence classes of the original ones modulo -similarity to a degree greater or equal than . In our example these classes are , , ,  and , that can be represented by the symbols , , ,  an , respectively. Then,  replaces the two clauses  and  by  and , respectively, leaving the other two clauses unchanged. Solving  w.r.t.  by means of classical  resolution produces the answer substitution , which corresponds to  modulo the replacement of the symbols in the original program by their equivalence classes. This is consistent with the claims in Proposition 7.2 from \cite{Ses02}.

    \item Note that  can be trivially converted into a semantically equivalent a  program, just by replacing each occurrence of the implication sign  in 's clauses by . Then  can be built as a  program by the method explained in Subsection \ref{sec:PT}. It includes three clauses corresponding to ,  and  of  plus the following three new clauses:
        \begin{itemize}
            \item 
            \item 
            \item 
        \end{itemize}
        where  resp.  come from replacing the linear heads of  resp.  by similar heads, and  comes from linearizing the head of , which allows no replacements by similarity.  includes also the proper clauses for  and , in particular the following three ones:
    \begin{itemize}
        \item 
        \item 
        \item 
    \end{itemize}
    Solving goal  w.r.t.  by means of the -qualified  resolution procedure described in \cite{RR08} can compute the answer substitution  with qualification degree . More precisely, the initial goal can be stated as , and the computed answer is . The computation emulates -based unification of  and  to the similarity degree  by solving  with the clauses , ,  and .

    \item The semantics of the \MALP framework depending on the chosen multi-adjoint lattice is presented in \cite{MOV04}. A comparison
with the semantics of the  scheme (see \cite{RR08} and Subsection \ref{QLP} above) shows that \MALP programs over the multi-adjoint lattice  behave as  programs, where  is the quasi qualification domain analogous to  introduced at the end of Subsection \ref{QD} above. For this reason, we can think of the transformed program  as presented with he syntax of a  program. The original program  can also be  written as a  program just by replacing each the implication sign  occurring  in  by . As explained in \cite{MOV04},  is built by extending  with clauses for  a new binary predicate  intended to emulate the behaviour of -based unification between terms. In our example,  will include (among others) the following clause
for :
    \begin{itemize}
        \item 
    \end{itemize}
In comparison to the clause   in , clause  needs no call to a  predicate at its body, because the similarity degree  can be attached directly to the clause's implication. This difference corresponds to the different interpretations of , which behaves as  in  and as  in .

Moreover,  is defined to include a clause of the following form for each pair of -ary predicate symbols  and  such that :
\begin{itemize}
    \item 
\end{itemize}
In our simple example, all the clauses of this form correspond to the trivial case where  and  are the same predicate symbol and . Solving goal  w.r.t. by means of the procedural semantics described in Section 4 of \cite{MOV04}
can compute the answer substitution  to the similarity degree . More generally, Theorem 24 in \cite{MOV04} claims that for any choice of ,  can emulate any successful computation performed by  using -based  resolution.
\end{enumerate}

In conclusion, the main difference between   and   pertains to the techniques used by both program transformations
in order to emulate the effect of replacing the head of a clause in the original program by a similar one.  always relies on the clauses of the form  {\em and}  the clauses for , while  can avoid to use the clauses for  as long as all the clauses involved in the computation have linear heads. In comparison to the two transformations  and , our transformation  does not depend on a fixed similarity degree  and does not replace the atoms in clause bodies by similar ones.

\subsection{A Goal Solving Example } \label{sec:GS}

\begin{figure}[ht]
\begin{center}
\tt
\begin{tabular}{|r@{\hspace{0.2cm}}l|}
\hline
&\\
\scriptsize  1 & wild(lynx) <-0.9- \\
\scriptsize  2 & wild(boar) <-0.9- \\
\scriptsize  3 & wild(snake) <-1.0- \\
\scriptsize  4 & wild(cat) <-0.9- \\
\scriptsize  5 & wild(pig) <-0.9- \\
&\\
\scriptsize  6 & farm(cow) <-1.0- \\
\scriptsize  7 & farm(pig) <-1.0- \\
\scriptsize  8 & farm(boar) <-1.0-  \\
\scriptsize  9 & farm(cat) <-0.8-  \\
\scriptsize 10 & farm(lynx) <-0.8-  \\
\scriptsize 11 & farm(snake) <-0.4-  \\
&\\
\scriptsize 12 & domestic(cat) <-0.8-  \\
\scriptsize 13 & domestic(snake) <-0.4-  \\
\scriptsize 14 & domestic(lynx) <-0.8-  \\
\scriptsize 15 & domestic(cow) <-1.0-  \\
\scriptsize 16 & domestic(pig) <-1.0-  \\
\scriptsize 17 & domestic(boar) <-1.0-  \\
&\\
\scriptsize 18 & intelligent(A) <-0.9- ,domestic(A) \\
\scriptsize 19 & intelligent(lynx) <-0.7-  \\
\scriptsize 20 & intelligent(cat) <-0.7-  \\
&\\
\scriptsize 21 & pacific(A) <-0.9- ,domestic(A) \\
\scriptsize 22 & pacific(A) <-0.7- ,farm(A) \\
&\\
\scriptsize 23 & pet(A) <-1.0- ,pacific(A),intelligent(A) \\
&\\
\scriptsize 24 &  <-1.0- \\
\scriptsize 25 &  <-0.8- \\
\scriptsize 26 &  <-0.7- \\
\scriptsize 27 &  <-0.3- \\
& \\
\hline
\end{tabular}
\end{center}
\caption{Example of transformed program. (Note: no clauses for  are needed because the original program was left-linear). \label{fig:exampletrans}}
\end{figure}

In order to illustrate the use of  the transformed program  for golving goals w.r.t. the original program , we consider the case where  is the  program displayed in Figure \ref{fig:example}. The transformed program  obtained by applying Definition \ref{def:trans} is shown in Figure \ref{fig:exampletrans}.  The following observations are useful to understand how the transformation has worked in this simple case:

\begin{itemize}
    \item The value  in the domain  corresponds to the real number  and hence by reflexivity  for any atom in the signature of the program. Therefore, and as a consequence of Definition \ref{def:trans}, every clause in the original program gives rise to a clause in the transformed program with the same head and with the same body except for a new, first atom . For instance, clauses 1, 2 and 3 in Figure \ref{fig:exampletrans} correspond to the same clause numbers in Figure \ref{fig:example}.

    \item Apart of the clauses corresponding directly to the original clauses, the program of Figure \ref{fig:exampletrans} contains new clauses obtained by  similarity with some clause heads in the original program. For instance,  lines 4 and 5  are obtained by similarity with clauses at lines 1 and 2 in the original program, respectively. The  subindexes at literal  correspond to , , respectively.

    \item Analogously, for instance the clause at line 10 (with head {\tt farm(lynx)}) is obtained by head-similarity with the clause of line 6 in the  program (head {\tt domestic(cat)}), and the subindex at  is obtained from
 

    \item There is no clause for predicate  since all the heads in the original program were already linear and therefore  can be left empty in practice.

    \item The clauses  for  correspond to the fragment  in Definition \ref{def:trans}.
\end{itemize}

In the rest of this subsection, we will show an execution for the goal \texttt{pet(A)\#W | W >= 0.50} over the program  (see Figure \ref{fig:exampletrans}) with the aim of obtaining all those animals that could be considered a \texttt{pet} for at least a qualification value of .

We are trying this execution in the prototype developed along with \cite{RR08} for the instances  and . Although this prototype hasn't been released as an integrated part of , you can download\footnote{Available at: \texttt{http://gpd.sip.ucm.es/cromdia/qlpd}. There you will also find specific instructions on how to install and run it as well as text files with the program examples tried in here.} the prototype to try this execution. Please notice that the prototype does not automatically do the translation process from a given  program  to its transformed program , because it was developed mainly for \cite{RR08}. Therefore, the transformed program shown in Figure \ref{fig:exampletrans} has been computed manually.

We will start running  and loading the  instance with the command \texttt{/qlp(u)}:

\begin{verbatim}
Toy> /qlp(u)
\end{verbatim}

\noindent this will have the effect of loading the \emph{Real Domain Constraints library} and the  library into the system, the prompt \texttt{QLP(U)>} will appear. Now we have to compile our example program (assume we have it in a text file called \texttt{animals.qlp} in \texttt{C:/examples/}) with the command \texttt{/qlptotoy} (this command will behave differently based on the actual instance loaded).

\begin{verbatim}
QLP(U)> /qlptotoy(c:/examples/animals)
\end{verbatim}

Note that we didn't write the extension of the file because it \emph{must} be \texttt{.qlp}. This will create the file \texttt{animals.toy} in the same directory as our former file. And this one will be an actual  program. We run the program with \texttt{/run(c:/examples/animals)} (again without the extension --although this time we are assuming \texttt{.toy} as extension--) and we should get the following message:

\begin{verbatim}
PROCESS COMPLETE
\end{verbatim}

And finally we are set to launch our goal with the command \texttt{/qlpgoal}. The solutions found for this program and goal are:

\begin{verbatim}
QLP(U)> /qlpgoal(pet(A)#W | W>=0.50)
      { A -> cat,
        W -> 0.5599999999999999 }

sol.1, more solutions (y/n/d/a) [y]?
      { A -> cat,
        W -> 0.7200000000000001 }

sol.2, more solutions (y/n/d/a) [y]?
      { A -> lynx,
        W -> 0.5760000000000002 }

sol.3, more solutions (y/n/d/a) [y]?
      { A -> lynx,
        W -> 0.5760000000000002 }

sol.4, more solutions (y/n/d/a) [y]?
      no
\end{verbatim}

At this point and if you remember the inference we did in Example \ref{ex:least-model} for \texttt{pet(lynx)\#0.50}, we have found a better solution (as you can see there are two solutions for \texttt{lynx}, and this is due to the two different ways of proving \texttt{intelligent(lynx)}: \texttt{intelligent(lynx)\#0.7} using clause 19, and \texttt{intelligent (lynx)\#0.576} using clauses 18 and 14.

\section{Conclusions} \label{Conclusions}

Similarity-based  has been proposed in \cite{Ses02} and related works to enhance the  paradigm with a kind of approximate reasoning which supports flexible information retrieval applications, as argued in \cite{LSS04,MOV04}. This approach keeps the syntax for program  clauses as in classical , and supports uncertain reasoning by using a fuzzy similarity relation  between symbols in the program's signature. We have shown that similarity-based  as presented in \cite{Ses02} can be reduced to Qualified  in the  scheme introduced in \cite{RR08}, which supports  logic programming with attenuated program clauses over a parametrically given domain   whose elements  qualify logical assertions by measuring their closeness to various users' expectations. Using  generalized similarity relations taking values in the carrier set of an
arbitrarily  given qualification domain ,  we  have extended  to a more expressive scheme  with two parameters, for programming modulo -similarity with -attenuated Horn clauses. We have presented a declarative semantics for  programs and a semantics-preserving program transformation which embeds  into . As a consequence, the sound and complete procedure for solving goals in  by -qualified  resolution and its implementation in the
 system \cite{RR08} can be used to implement  computations via the transformation.

Our framework is quite general due to the availability of different qualification domains, while the similarity relations proposed in \cite{Ses02} take fuzzy values in the interval . In comparison to the multi-adjoint framework proposed in \cite{MOV04}, the  and  schemes have a different motivation and scope, due to the differences between multi-adjoint algebras and qualification domains as algebraic structures. In contrast to the goal solving procedure used in the multi-adjoint framework, -qualified  resolution does not
rely on costly computations of reductant clauses and has been efficiently implemented.

As future work, we plan to investigate an extension of the -based  resolution procedure proposed in \cite{Ses02} to be used within the  scheme, and to develop an extension of this scheme which supports lazy functional programming and constraint programming facilities. The idea of  similarity-based unification has been already applied in \cite{MP06a} to obtain an extension of {\em needed narrowing}, the main goal solving procedure of functional logic languages. As in the case of \cite{Ses02}, the similarity relations considered in \cite{MP06a} take fuzzy values in the real interval .

\acks
The authors have been partially supported by the Spanish National Projects MERIT-FORMS (TIN2005-09027-C03-03) and PROME-SAS--CAM (S-0505/TIC/0407).


\bibliographystyle{plainnat}
\begin{thebibliography}{22}

\bibitem{Apt90}
K.R. Apt.
\newblock Logic programming.
\newblock In J. van Leeuwen, editor, {\em Handbook of Theoretical Computer Science}, volume B: Formal Models and Semantics, pages 493-574. Elsevier and The MIT Press, 1990.

\bibitem{AVE82}
K.R. Apt and M.H. van Emden.
\newblock Contributions to the theory of logic programming.
\newblock {\em Journal of the Association for Computing Machinery (JACM)}, 29(3):841-862, 1982.

\bibitem{AF99}
F. Arcelli and F. Formato.
\newblock Likelog: A logic programming language for flexible data retrieval.
\newblock In {\em Proceedings of the 1999 ACM Symposium on Applied Computing (SAC'99)}, pages 260-267, New York, NY, USA, 1999. ACM Press.

\bibitem{toy}
P. Arenas, A.J. Fern\'andez, A. Gil, F.J. L\'opez-Fraguas, M. Rodr\'iguez-Artalejo and F. S\'aenz-P\'erez.
\newblock , a multiparadigm declarative language. Version 2.3.1, 2007.
\newblock R. Caballero and J. S\'anchez (Eds.), available at \texttt{http://toy.sourceforge.net}.

\bibitem{FGS00}
F. Formato, G. Gerla and M.I. Sessa.
\newblock Similarity-based unification.
\newblock {\em Fundamenta Informaticae}, 41(4):393-414, 2000.

\vfill\eject

\bibitem{GS99}
G. Gerla and M.I. Sessa.
\newblock Similarity in logic programming.
\newblock In G. Chen, M. Ying and K. Cai, editors, {\em Fuzzy Logic and Soft Computing}, pages 19-31. Kluwer Academic Publishers, 1999.

\bibitem{KS92}
M. Kifer and V.S. Subrahmanian.
\newblock Theory of generalized annotated logic programs and their applications.
\newblock {\em Journal of Logic Programming}, 12(3\&4):335-367, 1992.

\bibitem{LSS04}
V. Loia, S. Senatore and M.I. Sessa.
\newblock Similarity-based SLD resolution and its role for web knowledge discovery.
\newblock {\em Fuzzy Sets and Systems}, 144(1):151-171, 2004.

\bibitem{MOV01a}
J. Medina, M. Ojeda-Aciego and P. Vojt\'a\v{s}.
\newblock Multi-adjoint logic programming with continuous semantics.
\newblock In T. Eiter, W. Faber and M. Truszczyinski, editors, {\em Logic Programming and Non-Monotonic Reasoning (LPNMR'01)}, volume 2173 of {\em LNAI}, pages 351-364. Springer-Verlag, 2001.

\bibitem{MOV01b}
J. Medina, M. Ojeda-Aciego and P. Vojt\'a\v{s}.
\newblock A procedural semantics for multi-adjoint logic programming.
\newblock In P. Brazdil and A. Jorge, editors, {\em Progress in Artificial Intelligence (EPIA'01)}, volume 2258 of {\em LNAI}, pages 290-297. Springer-Verlag, 2001.

\bibitem{MOV04}
J. Medina, M. Ojeda-Aciego and P. Vojt\'a\v{s}.
\newblock Similarity-based unification: A multi-adjoint approach.
\newblock {\em Fuzzy Sets and Systems}, 146:43-62, 2004.

\bibitem{MP06a}
G. Moreno and V. Pascual.
\newblock Programming with fuzzy logic and mathematical functions. In A.P.I. Bloch and A. Tettamanzi, editors, {\em Proceedings of the 6th International Workshop on Fuzzy Logic and Applications (WILF'05)}, volume 3849 of {\em LNAI}, pages 89-98. Springer-Verlag, 2006.

\bibitem{RR08TR}
M. Rodr\'iguez-Artalejo and C.A. Romero-D\'iaz.
\newblock A generic scheme for qualified logic programming (Technical Report SIC-1-08).
\newblock Technical Report, Universidad Complutense, Departamento de Sistemas Inform\'aticos y Computaci\'on, Madrid, Spain, 2008.

\bibitem{RR08}
M. Rodr\'iguez-Artalejo and C.A. Romero-D\'iaz.
\newblock Quantitative logic programming revisited.
\newblock In J. Garrigue and M. Hermenegildo, editors, {\em Functional and Logic Programming (FLOPS'08)}, volume 4989 of {\em LNCS}, pages 272-288. Springer-Verlag, 2008.

\bibitem{Ses01}
M.I. Sessa.
\newblock Translations and similarity-based logic programming.
\newblock {\em Soft Computing}, 5(2), 2001.

\bibitem{Ses02}
M.I. Sessa.
\newblock Approximate reasoning by similarity-based SLD resolution.
\newblock {\em Theoretical Computer Science}, 275(1\&2):389-426, 2002.

\bibitem{Sub87}
V.S. Subrahmanian.
\newblock On the semantics of quantitative logic programs.
\newblock In {\em Proceedings of the 4th IEEE Symposium on Logic Programming}, pages 173-182, San Francisco, 1987.

\bibitem{Sub88}
V.S. Subrahmanian.
\newblock Query processing in quantitative logic programming.
\newblock In {\em Proceedings of the 9th International Conference on Automated Deduction}, volume 310 of {\em LNCS}, pages 81-100, London, UK, 1988. Springer-Verlag.

\bibitem{Sub07}
V.S. Subrahmanian.
\newblock Uncertainty in logic programming: Some recollections.
\newblock {\em Association for Logic Programming Newsletter}, 20(2), 2007.

\bibitem{VE86}
M.H. van Emden.
\newblock Quantitative deduction and its fixpoint theory.
\newblock {\em Journal of Logic Programming}, 3(1):37-53, 1986.

\bibitem{VEK76}
M.H. van Emden and R.A. Kowalski.
\newblock The semantics of predicate logic as a programming language.
\newblock {\em Journal of the Association for Computing Machinery (JACM)}, 23(4):733-742, 1976.

\bibitem{Voj01}
P. Vojt\'a\v{s}.
\newblock Fuzzy logic programming.
\newblock {\em Fuzzy Sets and Systems}, 124:361:370, 2001.
\end{thebibliography}

\end{document}
