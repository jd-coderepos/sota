\documentclass{LMCS}

\def\doi{9(1:16)2013}
\lmcsheading {\doi}
{1--16}
{}
{}
{Mar.~16, 2012}
{Mar.~31, 2013}
{}

\usepackage{amssymb,latexsym}
\usepackage{graphicx, amsmath, amssymb, pstricks}
\usepackage{bussproofs}
\usepackage{hyperref}
\usepackage{phuong}
\usepackage{pdfsync}
\usepackage{pifont}




\usepackage{mathrsfs} \usepackage{enumerate}
\usepackage{stmaryrd}
\renewcommand{\l}{\ell}
\newcommand{\reals}{{\mathbb{R}}}
\newcommand{\R}{{\mathbb{R}}}
\newcommand{\C}{{\mathbb{C}}}
\newcommand{\Q}{{\mathbb{Q}}}
\newcommand{\zah}{{\mathbb{Z}}}
\newcommand{\Z} {\mathbb{Z}}
\newcommand{\nat}{{\mathbb{N}}}
\newcommand{\Nat}{\ensuremath \mathbb N}
\newcommand{\pow}[1]{{\mathfrak{P}}(#1)}
\newcommand{\fin}[1]{{\mathfrak{F}}(#1)}
\newcommand{\scr}[1]{{\mathcal #1}}
\newcommand{\cat}[1]{{\mbox{\bf #1}}}
\newcommand{\Nbd}{\mbox{Nbd}}
\newcommand{\cl}[1]{\mbox{cl}(#1)}
\newcommand{\K}{\mathbb{K}}
\newcommand{\Cont}{\mbox{Cont}}
\newcommand{\BCont}{\mbox{BCont}}
\newcommand{\Bd}{\mbox{Bd}}
\newcommand{\lip}{\mbox{lip}}
\newcommand{\lcm}{\mbox{lcm}}
\newcommand{\Lip}{\mbox{Lip}}
\newcommand{\App}{\mbox{App}}
\newcommand{\filt}{\mbox{filt}}
\newcommand{\Part}{\mbox{Part}}
\newcommand{\Rng}{\mathrm{Rng}}
\newcommand{\Img}{\mathrm{Img}}
\newcommand{\map}[3]{\mbox{}}
\newcommand{\iso}[3]{#1\;:\;#2 \cong #3}
\newcommand{\seq}[2]{\{ #1_{#2} \}_{#2 = 0}^\infty}
\newcommand{\weakly}{\rightharpoonup}
\newcommand{\T}[1]{\mathbf T_{#1}}
\renewcommand{\prob}[2]{\item[{\bf #1}] {\sl #2}}
\newcommand{\E}{{\mathbb E}}
\renewcommand{\P}{{\mathbb P}}
\newcommand{\comb}[1]{\mathsf #1}
\newcommand{\rst}{\!\!\upharpoonright\!}
\newcommand{\mbf}[1]{\mbox{{#1}}}   \newcommand{\myatop}[2]{\mbox{\tiny #1}\atop{\mbox{\tiny #2}}}

\newcommand{\abs}[1]{\left\vert#1\right\vert}
\newcommand{\set}[1]{\left\{#1\right\}}
\newcommand{\mc}[1]{\mathcal{#1}}
\newcommand{\Real}{\mathbb R}
\newcommand{\F}{\mathbb F}
\newcommand{\eps}{\varepsilon}
\newcommand{\To}{\longrightarrow}
\newcommand{\BX}{\mathbf{B}(X)}
\newcommand{\A}{\mathcal{A}}
\newcommand {\pf}[2]{\vdash_{#1}^{#2}}
\newcommand {\dpt}[1]{\mathrm{dp}(#1)}
\newcommand {\cd}{\cdot}
\newcommand {\zo}{\set{0,1}}
\newcommand {\OrDots} {\Or\cdots\Or}
\newcommand {\PlusDots} {+\ldots +}
\newcommand {\CommaDots} {,\ldots,}
\newcommand {\ML}[1] {\mathbf{M}\!\left[#1\right]} \newcommand {\sm} {\setminus}
\newcommand {\se}{\subseteq}
\newcommand {\Gam}{\Gamma}
\newcommand {\Del}{\Delta}
\newcommand {\dto} {\leftrightarrow}
\newcommand {\norm}[1]{\abs{\abs #1}}
\newcommand {\pred}[1]{{\textsc{#1}}}
\newcommand {\numo}{\mbox{\textit{numones}}}
\newcommand {\NUMO}{\ensuremath{\mathsf{NUMONES}}}
\newcommand{\Base}{\mbox{}\\ \ind{\textit{Base case: }}}
\newcommand{\Induction}{\mbox{}\\ \ind{\textit{Induction step: }}}
\newcommand{\case}[1]{\ind\textbf{Case #1}:\,}
\newcommand{\induction}{\Induction}

\newcommand{\eqarrow}[3]{
{\mbox{}
   \atop{
      \mbox{ }
          \atop{
              \uparrow
                  \atop
                     \begin{minipage}{#3}
                        \tiny #2
                     \end{minipage}
              }
    }
} }
\newcommand{\eqarrowabove}[3]{
{
 {\begin{minipage}{#3}
    \tiny #2
  \end{minipage}
   \atop{
    \downarrow
     \atop{
      \mbox{}
      }
    }
  }
  \atop
   \mbox{}
} }

\newcommand {\foo} {\footnotesize}
\newcommand {\ind} {\noindent}
\newcommand {\med} {\medskip}
\newcommand {\bigs} {\bigskip}
\newcommand {\sml}   {\smallskip}
\newcommand {\vx}   {\vec{x}}
\newcommand {\bx}   {\bar{x}}
\newcommand {\para}[1] {\paragraph{#1}}
\newcommand {\er}[1] {(\ref{eq#1})}
\newcommand {\subpara}[1] {\subparagraph{#1}}
\def\vr#1#2#3{{\mbox{}}} \DeclareMathAlphabet{\mathitbf}{OML}{cmm}{b}{it}

\newcommand{\BigO}{{\mathop{\rm O}}}
\newcommand{\SmallO}{{\mathop{\rm o}}}

\newcommand{\LogSpace}{\mbf{L}}     \newcommand{\PolyTime}{\mbf{P}}     \newcommand{\EXP}{\mbf{EXP}}        \newcommand{\BPP}{\textbf{BPP}}
\newcommand{\NP}{\mbf{NP}}
\newcommand{\PSPACE}{\mbf{PSPACE}}
\newcommand{\SPACE}{\mbf{SPACE}}
\newcommand{\FSPACE}{\mbf{FSPACE}}
\newcommand{\TIME}{\mbf{TIME}}
\newcommand{\FTIME}{\mbf{FTIME}}

\newcommand{\cost}{\mbf{COST}}
\newcommand{\MCC}[1]{\textrm{mCC}(#1)}

\newcommand{\blank}{\mbox{}}

\font\sf=cmss10
\newcommand{\Nats}{{\hbox{\sf I\kern-.13em\hbox{N}}}}   \newcommand{\Reals}{{\hbox{\sf I\kern-.14em\hbox{R}}}}  \newcommand{\Ints}{{\hbox{\sf Z\kern-.43emZ}}}          \newcommand{\CC}{{\hbox{\sf C\kern -.48emC}}}           \newcommand{\QQ}{{\hbox{\sf C\kern -.48emQ}}}           \newcommand{\such}{\;|\;}

\renewcommand{\And}{\land}
\newcommand{\Or}{\lor}
\newcommand{\Not}{\neg}
\newcommand{\Xor}{\oplus}
\newcommand{\Equiv}{\;\Longleftrightarrow\;}
\newcommand{\Imply}{\;\Longrightarrow\;}
\newcommand{\BigOr}{\bigvee}
\newcommand{\BigAnd}{\bigwedge}

\newcommand{\dotminus}{\mathbin{\setbox0\hbox{}\setbox2\hbox to\wd0{\hss\hss}\wd2=0pt\box2\box0}}




\ifx\theorem\undefined

\newtheorem{theorem}{Theorem}[section]
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{proposition}[theorem]{Proposition}
\newtheorem{corollary}[theorem]{Corollary}
\newtheorem{definition}{Definition}[section]
\newtheorem{NumberedRemark}{Remark}
\newtheorem{assumption}{Assumption}
\newtheorem{comment}{Comment}
\fi

\newtheorem{claim}[theorem]{Claim}
\newenvironment{notation}{\QuadSpace\par\noindent{\bf Notation}:}{\HalfSpace}
\newenvironment{note}{\QuadSpace\par\noindent{\bf Note}:}{\HalfSpace}
\newenvironment{notes}{\QuadSpace\par\noindent{\bf Notes}:}{\HalfSpace}
\newenvironment{importantnote}{\QuadSpace\par\noindent{\bf Important
note}:}{\HalfSpace}
\newenvironment{convention}{\QuadSpace\par\noindent{\bf
Convention}:}{\HalfSpace}
\newenvironment{example}{\QuadSpace\par\noindent{\bf Example}:}{\HalfSpace}
\newenvironment{remark}{\HalfSpace\par\noindent{\bf Remark}:}{\HalfSpace}
\newenvironment{observation}{\QuadSpace\par\noindent{\bf
Observation}:}{\HalfSpace}
\newenvironment{conjecture}{\QuadSpace\par\noindent{\bf
Conjecture}:}{\HalfSpace}
\newenvironment{conclusion}{\QuadSpace\par\noindent{\bf
Conclusion}:}{\HalfSpace}

\ifx\proof\undefined
\newenvironment{proof}{\QuadSpace\par\noindent{\bf
Proof}:}{\EndProof\HalfSpace} \fi

\newenvironment{question}{\QuadSpace\par\noindent{\bf
Question}:}{\HalfSpace}
\newenvironment{proofsketch}{\QuadSpace\par\noindent{\textit{Proof
sketch}}:}{\EndProof\HalfSpace}
\newenvironment{abbreviation}{\QuadSpace\par\noindent{\bf
Abbreviation}:}{\HalfSpace}
\newenvironment{intuition}{\begin{quote}\par\noindent{\bf
Intuition}:}{\end{quote}}
\newenvironment{proofclaim}{\QuadSpace\par\noindent{\bf Proof of claim}:}
{\vrule width 1ex height 1ex depth 0pt  \HalfSpace}
\newenvironment{proofcor}{\QuadSpace\par\noindent{\bf Proof of
corollary}:}{\EndProof\HalfSpace}

\newcommand{\QuadSpace}{}\newcommand{\HalfSpace}{}\newcommand{\FullSpace}{}\newcommand{\EndProof}{ \hfill \vrule width 1ex height 1ex depth 0pt }
\newcommand{\dom}{\mbox{dom}}
\newcommand{\conc}{\hat{ \ }}
\newcommand{\BCite}[1]{{\bf{\cite{#1}}}}

\def\Res#1{{\mbox{Res}(#1)}}
\def\Resk{{\Res k}}
\def\Reskp{{\Res {k+1}}}
\def\odd{\mbox{Odd}}
\def\even{\mbox{Even}}
\def\RL0{{\mbox{\rm R(lin)}}}
\def\RZ0{{\mbox{\rm R(lin)}}}
\def\RC0{R(lin) with constant coefficients}
\def\RCD0#1{{\mbox{\rm R(lin)}}}
\def\clique#1#2#3{{\mbox{\textsc{clique}}}}
\def\Tse0{{\mbox{\textsc{Tseitin}}}}

\newcommand{\sq}{\Rightarrow} 

\def\expect{\mathbb{E}}
\newcommand{\pr}[1]{\mathbf{Pr}\left[#1\right]}
\def\Vars#1{{\mbox{Vars}(#1)}}

\definecolor{bluetxt}{rgb}{0,0,.5}
\definecolor{myred}{rgb}{0.6,0.0,0.1}
\definecolor{greentxt}{rgb}{0,.5,0}
\definecolor{redtxt}{rgb}{0.1,0.1,0.65}
\definecolor{purpletxt}{rgb}{0.6,0.1,0.7}
\definecolor{black}{rgb}{.0,.0,.0}
\definecolor{verydarkblue}{rgb}{.0,.0,.2}
\definecolor{lightgray}{rgb}{.7,.7,.7}
\definecolor{bgcolor}{rgb}{.8,.8,.5}
\definecolor{lightkhaki}{rgb}{0.945,.946,.355}


\ifx\proof\undefined
\newenvironment{proof}{

\smallskip
\noindent\emph{Proof.}}{\hfill
\bigskip
} \fi

\newtheorem{NoNumThm}{Theorem}

\newlength{\defbaselineskip}
\setlength{\defbaselineskip}{\baselineskip}
\newcommand{\setlinespacing}[1] {\setlength{\baselineskip}{#1
\defbaselineskip}}
\newcommand{\singlespacing}{\setlength{\baselineskip}{.97\defbaselineskip}}
\newcommand{\doublespacing}{\setlength{\baselineskip}{1.0\defbaselineskip}}

\newcommand{\Comment}[1]{}
\newcommand {\mar}[1]{}
\renewcommand{\footnote}[1]{}


\newcommand{\modexp}{\ensuremath \mathsf{modexp}}
\newcommand{\numones}{\ensuremath \mathsf{numones}}



\title{Polylogarithmic Cuts in Models of \VZ}

\author[S.~M\"uller]{Sebastian M\"uller}
\address{Faculty of Mathematics and Physics \\
        Charles University,  Prague}
\email{muller@karlin.mff.cuni.cz}
\thanks{Supported by the Marie Curie Initial
    Training Network in Mathematical Logic -  MALOA - From MAthematical LOgic to Applications, PITN-GA-2009-238381}


\keywords{Proof Complexity, Bounded Arithmetic, Cuts, Subexponential Simulation}

\ACMCCS{[{\bf Theory of computation}]: Logic---Proof theory}
\subjclass{F.4.1}
\amsclass{03B30, 03B70, 03C62, 03D15.}

\begin{document}


\begin{abstract}
  We study initial cuts of models of weak two-sorted Bounded
  Arithmetics with respect to the strength of their theories and show
  that these theories are stronger than the original one. More
  explicitly we will see that polylogarithmic cuts of models of 
  are models of  by formalizing a proof of Nepomnjascij's
  Theorem in such cuts.  This is a strengthening of a result by Paris
  and Wilkie.

  We can then exploit our result in Proof Complexity to observe that
  Frege proof systems can be sub exponentially simulated by bounded
  depth Frege proof systems. This result has recently been obtained by
  Filmus, Pitassi and Santhanam in a direct proof. As an
  interesting observation we also obtain an average case separation of
  Resolution from -Frege by applying a recent result
  with Tzameret.
\end{abstract}


\maketitle


\section{Introduction}

This article is on the one hand on models of weak arithmetics and on the other on proof complexity, i.e. the
question of how long formal proofs of tautologies have to be in given proof systems. Therefore the introduction
will consist of two parts, one for each subject.

Models of weak arithmetics, like , have been extensively studied for several reasons. They are
possibly the simplest objects whose theories bear enough strength to do a good part of mathematics in, yet they
are weak enough to allow for a certain kind of constructiveness. The latter has been demonstrated over and over
again by various results connecting weak arithmetic theories with complexity classes and computability. We are
interested in the strength of the theory obtained by restricting our objects of reasoning to a small initial
part of a given model. Since a two-sorted theory, such as \VZ, is much stronger on its number part than on its
set part, it is likely that such a cut is a model of a supposedly much stronger theory. Indeed we will see in
Section~\ref{Sec:Polylog Cuts} that certain cuts of models of \VZ\ are models of the provably stronger theory
. This strengthens a result by Paris and Wilkie \cite{PW87}\cite{PW85}, who show that such cuts are
models of . In fact they work in a more general setting and, following our argumentation, their
result readily implies the sub exponential simulation of -Frege by -Frege from
Bonet, Domingo, Gavald\`a, Maciel, and Pitassi \cite{BDGMP04}.

Proof Complexity, on the other hand, more or less began when Cook and Reckhow \cite{CR79} discovered the close
connection between the lengths of formal proofs in propositional proof systems and standard complexity classes.
This connection yields a possibility of dealing with the  question by asking, whether there
exists a propositional proof system that is polynomially bounded. We will not directly address this question
here, but rather explore the relative strengths of two major proof systems, Frege and bounded depth Frege. These
proof systems have been extensively studied, due to their natural appearance as classical calculi, such as
Gentzen's PK, and it is well known that Frege systems are stronger than bounded depth Frege systems, as the
former system has polynomial size proofs for the Pigeonhole Principle (see \cite{Bu87}), while the latter does
not (see \cite{KPW95} and \cite{PBI93}). Lately, Filmus, Pitassi and Santhanam \cite{FPS11} have proved a sub
exponential simulation of Frege by bounded depth Frege using a combinatoric argument. In Section~\ref{Sec:Impl
Proof Cmpl} we will obtain the same result by an application of our result about cuts to the provability of the
Reflection Principle for Frege in bounded depth Frege. Currently Cook, Ghasemloo and Nguyen \cite{CGN12} are
working on a purely syntactical proof that gives a slightly better result with respect to the strength of the
simulated proof system.

The paper is built-up as follows. In section \ref{Sec:Preliminaries} we briefly recapture some basics about
Complexity Theory, Bounded Arithmetic, Proof Complexity and the various connections between them. As this is
only expository it might be helpful to consult some of the references for a more detailed introduction (see
\cite{AB09}, \cite{CN10} and \cite{Kra95}). After that, in Section~\ref{Sec:Polylog Cuts} we prove a
formalization of Nepomnjascij's Theorem in the polylogarithmic cut of a model of . Using a standard
algorithm for evaluating circuits and then applying the formalized version of Nepomnjascij's Theorem we can
conclude that this cut is indeed a model of . Finally, in Section~\ref{Sec:Impl Proof Cmpl}, we apply
this result to prove that a version of the Bounded Reflection Principle of Frege is provable in . This,
together with a standard argument linking the provability of Reflection Principles with simulation results,
yields the sub exponential simulation of Frege by bounded depth Frege.


\section{Preliminaries}\label{Sec:Preliminaries}

We assume familiarity with Turing machines, circuits and standard complexity classes such as ,
, , ,  and so on. See for example
\cite{AB09} for an introduction. We will not work a lot within these classes, but rather apply known relations
between such classes and weak arithmetic theories.

We will work in a two-sorted arithmetic setting, having one sort of variables representing numbers and the
second sort representing bounded sets of numbers. We identify such bounded subsets with strings. See \cite{CN10}
for a thorough introduction. The underlying language, denoted \LTwoA, consists of the following relation,
function and constant symbols:

An  \LTwoA-structure  consists of a first-sort universe  of numbers and a second-sort universe 
of bounded subsets of numbers.  If  is a model of the two-sorted theory  (see \ref{sec VZ}), then the
functions  and  are the addition and multiplication on the universe of numbers.  and  are
interpreted as the appropriate elements zero and one with respect to addition and multiplication. The relation
 is an ordering relation on the first-sort universe. The function  maps an element of the set
sort to its largest element plus one (i.e. to an element of the number sort). The relation  is interpreted
as equality between numbers,  is interpreted as equality between bounded sets of numbers. The relation
 holds for a number  and a set of numbers  if and only if  is an element of . The standard
model of two-sorted Peano Arithmetic will be denoted as . It consists of a first-sort universe
 and a second-sort universe  of all finite subsets of . The symbols are interpreted in the
usual way.

We denote the first-sort (number) variables by lower-case letters , and the second-sort (set)
variables by capital letters . In case it helps to describe the meaning of a variable we will use lower case words for first-sort and words starting with a capital letter for second-sort variables. We can build formulas in the usual way, using two sorts of
quantifiers, number quantifiers and string quantifiers. A number quantifier  () is bounded
if it is of the form  () for some number
term . A string quantifier  () is bounded if it is of the form  () for some number term . A formula is bounded iff
all its quantifiers are. All formulas in this paper will be bounded. A formula  is in  (or
) if it uses no string quantifiers and all number quantifiers are bounded. A formula  is a
 (or ) if it is of the form 
(or ), where  (or ,
respectively). If a relation or predicate can be defined by both a  and a  formula, then we
call it  definable. The {\em depth} of a formula is the maximal number of alternations of its
logical connectives and quantifiers.

As mentioned before we will represent a bounded set of numbers  by a finite string  such that  if and only if . We will abuse notation and identify bounded sets
and strings, i.e.  and .

Further, we will encode monotone propositional formulas inductively as binary trees in the standard way, giving
a node the value  if it corresponds to a conjunction and the value , if it corresponds to a disjunction.
Binary trees are encoded as strings as follows. If position  contains the value of a node ,
then the value of its left successor is contained in position , while the value of its right successor is in
.

\subsection{Elements of Proof Complexity}\label{Sec:Elements Proof Cmpl}

We restate some basic definitions introduced in \cite{CR79}.

\begin{definition}\label{def pps}
  A {\em propositional proof system (pps)} is a surjective polynomial-time function
  , where  is the set of propositional tautologies (in
  some natural encoding). A string  with  is called a {\em -proof} of .
\end{definition}

We can define a quasi ordering on the class of all pps as follows.

\begin{definition}\label{def:simulation}
  Let  be propositional proof systems.
  \begin{iteMize}{}
    \item  simulates  (in symbols ), iff there is a polynomial , such that for all  there is a
     with , such that for all  with , .
    \item If there is a polynomial time machine that takes -proofs and produces -proofs for the same
    formula we say that
     p-simulates  (in symbols ).
    \item If  and  mutually (p-)simulate each other, we say that they are (p-)equivalent (in symbols
     and , respectively).
  \end{iteMize}\smallskip
\end{definition}

\noindent In this article we will be mainly interested in bounded depth Frege systems and some of their extensions. A
Frege system is a typical textbook proof system, such as Gentzen's propositional calculus PK. We will only
sketch a single rule of such a system as an example and refer the interested reader to standard logic textbooks.

   \begin{prooftree}
     \AxiomC{}
     \AxiomC{}
     \RightLabel{(Cut)}
     \BinaryInfC{}
   \end{prooftree}\smallskip
Here,  and  are sets of formulas while  is a formula.  is read
as "The conjunction of all formulas in  implies the disjunction of all formulas in ". The Cut
Rule therefore says that, if  implies  or , and  and  imply , then
 already implies . The formula  is called the {\em Cut Formula}.

In a bounded depth Frege system the depths of all formulas in a derivation are bounded by some global constant.
This is equivalent to being representable by an  circuit. Thus we also call bounded depth Frege
-Frege. If the formulas are unbounded, we speak of -Frege or simply of Frege. We
readily get

\begin{fact}
  .
\end{fact}

A pps  is {\em polynomially bounded} iff there is a polynomial  such that every tautology  has a
-proof  with .

We are interested in the existence of polynomially bounded pps. This is, at least in part, due to the following
theorem.

\begin{fact}[\cite{CR79}]
  
\end{fact}

An easier task than searching for a polynomially bounded pps might be to find some pps with sub exponential
bounds to the lengths of proofs. This corresponds to the question, whether sub exponential time nondeterministic
Turing machines can compute -complete languages. To explore the existence of such systems we
generalize Definition~\ref{def:simulation}.

\begin{definition}
    Let  be propositional proof systems and  a family of increasing functions on .
  \begin{iteMize}{}
    \item  -simulates  (in symbols ), iff there is a function , such that for all  there is a
     with , such that for all  with , .
    \item If there is an -machine that that takes -proofs and produces -proofs for the same
    formula we say that
     -computably simulates  (in symbols ).
    \item If  and  mutually -(computably) simulate each other, we say that they are -(computably) equivalent (in symbols
     and , respectively).
  \end{iteMize}\smallskip
\end{definition}

\noindent We say a pps  {\em sub exponentially simulates} a pps  iff the above  can be chosen as a class of
 functions.

\subsection{The theory \VZ}\label{sec VZ}
The base theory we will be working with is . It consists of the following axioms:
\begin{center}
\framebox[\textwidth]{
\parbox{335pt}{


   }
  }
\end{center}
Here, the Axioms {\bf Basic 1} through {\bf Basic 12} are the usual axioms used to define Peano Arithmetic
without induction (), which settle the basic properties of Addition, Multiplication, Ordering,
and of the constants 0 and 1. The Axiom {\bf L1} says that the length of a string coding a finite set is an
upper bound to the size of its elements. {\bf L2} says that  gives the largest element of  plus . {\bf SE} is the extensionality axiom for strings which states that two strings are equal if they code the
same sets. Finally, {\bf -COMP} is the comprehension axiom schema for -formulas (it is
an axiom for each such formula) and implies the existence of all sets, which contain exactly the elements that
fulfill any given  property.

\begin{fact}
The theory \VZ\ proves the Induction Axiom schema for  formulas :

\end{fact}

When speaking about theories we will always assume that the theories are two-sorted theories as in \cite{CN10}.

The following is a basic notion:
\begin{definition}[Two-sorted definability]\label{def:Two-sorted definabilty}
Let  be a theory over the language  and let  be a set of
formulas in the language . A number function  is -definable in a theory  iff
there is a formula  in  such that  proves
  
  and it holds that

A string function  is -definable in a theory  iff there is a formula  in  such that  proves
  
  and it holds that
  
Finally, a relation  is -definable iff there is a formula  in  such that it holds that
  
\end{definition}

Moreover we wish to talk about sequences coded by strings or numbers. For a string  we let  be the
th bit of . Assuming a tupling function  we can also talk of -ary
relations for any constant . We refer to , to say that the objects
 are in the relation  (which is equivalent to saying that the predicate  holds for the
number , i.e. that the  contains that number as an element). For the sake
of simplicity we also refer to  by .

Using -ary relations we can also encode sequences of bounded numbers  by  in binary. Matrices and so on can obviously be
formalized in the same way.

Given a string  representing a -ary relation, we denote the -ary
substring with parameters  by .
For example we refer to the element  of a given matrix  as , a string representing  in binary. Observe that
this substring can be  defined in .

Given a number  we denote by  the th number in the  sequence encoded by . To do
this we assume a fixed  definable encoding of numbers that is injective. The sequence itself will be
addressed as . As above, we can also talk about matrices, etc. in this way, i.e. read such a
sequence as a sequence of -tuples.

We want to identify strings of short length with sequences of numbers. Thus, given a string  of length 
we can -define (in ) a number  that codes a sequence , such
that  for all  and vice versa. We will use  and
 to denote the above identification. Observe that  has to be very small in
order to be able to do the above in .


\subsubsection{Computations in models of }\label{Secsub:Comp in VZ}

Given a polynomially bounded Turing machine  in a binary encoding, we can  define a predicate
, that states that  is accepted by . This can readily be observed, since, provided some
machine , there is a constant number of states  and the whole computation can be
written into a matrix  of polynomial size. That  is indeed a correct computation can then be easily
checked, because the computations are only local.

More precisely let  be given, where the  are
different states, with  being the initial state and  being the accepting state and 
is the transition function with domain  and range
, which describes what the
machine does. I.e. if , then if the machine is in state  and reads , it replaces 
by , goes into state  and moves one position on the tape in the direction . For our formalization we
will assume a function  and interpret it in the following way,
, where we identify .

Let the polynomial  bound the running time of , then we can formalize  as follows




\noindent Thus, in plain English,  says that there exists a matrix  of pairs of numbers that
witnesses an accepting computation of . Here,  is supposed to
code the th cell on the Turing machine's tape after  steps of computations on input . As noted above,
 is a binary number, which is the value of the cell,  is a number coding the state the machine is in iff the pointer is on that
cell.

The second and third line of the definition say that the tape in the initial step contains  padded with
zeroes in the end to get the proper length  and that the read/write head is in its starting state
and position. The fourth line says that if the read/write head is not on cell , then nothing happens to the
content of cell . The fifth line says that the content of the cell, where the read/write head is in step ,
is changed according to . The next three lines tell us where the read/write head moves. The last line
says that there is at most one position on the tape where the read/write head may be at any step and that the
state after the last step is accepting.

We also define a -predicate  that says that  reaches configuration 
from configuration  in at most  many steps. This is essentially the same predicate as
, with the constraints on the initial and accepting state lifted and instead a constraint added
that the first line of computation is  and the last is . We omit the details as it does not severely
differ from the above definition of .




\subsection{Extensions of \VZ}\label{Sec:Ext of VZ}

The Theory \VZ\ serves as our base theory to describe complexity classes by arithmetical means.

The problem, whether a given monotone formula  of size  and depth  is
satisfiable under a given assignment  is -complete for . Therefore Cook and
Nguyen (\cite{CN10}) define the class  as  augmented by the axiom , where

So,  states that there is an evaluation  of the monotone formula represented by  under the assignment
given by  of length at most . More specifically,  is a tree-encoding of the formula, where  is
true, if node  is  and false, if  is . The evaluation  takes the value of the variables
given by  and then evaluates the formula in a bottom-up fashion using a standard tree encoding. Thus, the
value of the formula can be read at .

It is interesting to observe that  does not hold in . This is, since an application of the Witnessing
Theorem for  to a proof of  would yield an -definition of satisfaction for monotone
 circuits. This implies that monotone , which is known to be
false.


\subsection{Relation between Arithmetic Theories and Proof Systems}\label{Sec:Rel BA pps}

In this section we will remind the reader of a connection between the Theory  and some of its extensions
and certain propositional proof systems (see also \cite{CN10}\cite{Kra95}).


\begin{definition}The following predicates will be subsequently used. They are definable with respect to 
 (see \cite{Kra95}).
  \begin{iteMize}{}
    \item  is a  formula that says that the the string  codes a
    formula.
    \item  is the  definable property that the truth assignment  satisfies the formula .
    \item  is the  formula , where  is an upper bound to the number of variables in formulas coded by strings of length .
    \item  is a  definable predicate meaning  is a
    depth  Frege proof for .
    \item  is a  definable predicate meaning  is a Frege
    proof for .
  \end{iteMize}
\end{definition}

The following holds

\begin{fact}[see \cite{CN10}]\label{fact:VZ and bd Frege}
  The Theory  proves that -Frege is sound, i.e. for every  
\end{fact}

\begin{fact}[see \cite{CN10}]\label{fact:VNC1 and NC1 Frege}
  The Theory  proves that Frege is sound, i.e. 
\end{fact}

On the other hand, provability of the universal closure of  formulas in  and  implies
the existence of polynomial size proofs of their propositional translations in -Frege and Frege,
respectively.

The propositional translation  of a 
formula  is a family of propositional formulas built up inductively (on the logical
depth) as follows. If  is atomic and does not contain second sort variables, we evaluate  in
, if it contains second sort variables, we have to introduce propositional variables. If  is a
boolean combination of formulas  of lower depth, the translation is simply the same boolean combination
of the translations of the . If  is  or  we translate it to the
disjunction or conjunction of the translations, respectively. For a proper definition see \cite{CN10}.

\begin{fact}
  \label{fact:polynomial simulation}
  There exists a polynomial  such that for all  formulas  the
  following holds
  \begin{iteMize}{}
    \item If , then there exist bounded depth Frege
    proofs of all  of length at most , for
    any .
    \item If , then there exist Frege
    proofs of all  of length at most , for
    any .
  \end{iteMize}
  These proofs are effective in the sense that for any such  there exists a polynomial-time computable
  function  that maps any tuple  to the above proofs of .
\end{fact}

Facts~\ref{fact:VZ and bd Frege} and \ref{fact:VNC1 and NC1 Frege} are examples of general principles, the so
called {\em Reflection Principles}, which are defined as follows.

\begin{definition}
  [Reflection Principle] Let  be a pps. Then the {\em Reflection Principle}
  for , , is the -formula (w.r.t. )  where  is a -predicate formalizing
  -proofs.
\end{definition}

Reflection Principles condense the strength of propositional proof systems. In what follows we will summarize
some such results for the proof systems and theories used here. A detailed exposition can be found in
\cite{CN10}, chapter X, or in \cite{Kra95}, chapter 9.3.


\begin{theorem}\label{Thm Simulation by Reflection}
  If  then bounded depth Frege
  p-simulates Frege.
\end{theorem}
We will only give a brief sketch of the proof here and leave out the technical details.
\begin{proof}[Sketch]
Let  be a formula and  a Frege proof of  which is witnessed by a Turing machine
 (cf Def~\ref{def pps}). Since  proves , by Facts~\ref{fact:VZ and bd Frege} and
\ref{fact:polynomial simulation} we have polynomial size proofs of its translations  in bounded depth Frege. Bounded depth Frege itself, however, is strong enough to
verify that a proper encoding of the computation of  on input  is correct. Thus it
can verify that  is a Frege-proof and, using the translation of the Reflection Principle and the
Cut rule, conclude . From this  follows, cf.~\cite{Kra95}
Lemma~9.3.7.
\end{proof}

Given a term  and a variable , we can also introduce the  -bounded version of the Reflection Principle
for some given pps ,  that claims soundness only for -bounded proofs.

\begin{definition}
  [Bounded Reflection] Let  be a -term, 
  a first-sort variable and  a pps. Then the {\em Bounded
  Reflection Principle}  is the formula
  
\end{definition}



We can now generalize Theorem~\ref{Thm Simulation by Reflection} in the following way.

\begin{theorem}
  \label{Thm Simulation by Bounded Reflection}
  Let  be a -term and 
  a number variable. If  for  large enough
  and if  then for every
  propositional formula  with a Frege proof of length
   there is a bounded depth Frege proof of  of length
  . This proof can be efficiently constructed.
\end{theorem}

\begin{proof}
  The proof is the same as that of Theorem~\ref{Thm Simulation by
  Reflection}. Using the Bounded Reflection Principle we can encode
  Frege proofs of length  as bounded depth Frege proofs of length .
\end{proof}

As a corollary we get



\begin{corollary}
  If  for all , then
  bounded depth Frege sub exponentially simulates Frege:
  For all  exists , such that the existence of a Frege proof of length  of a depth  formula
  implies the existence of a depth  Frege proof of length at most .
\end{corollary}


\section{Polylogarithmic Cuts of Models of  are Models of .}\label{Sec:Polylog Cuts}

We will first introduce the notion of a cut  of a given two-sorted arithmetic model .
This model theoretic approach provides a very good insight on what actually happens semantically with the small
elements of arithmetical models.

\begin{definition}
  [Cut] Let  be a two-sorted arithmetic theory and
   a model of .
  A {\em cut}  of  is any substructure
  such that
  \begin{iteMize}{}
    \item , ,
    \item , ,
    \item  is closed under  and downwards with respect to ,
    \item , and
    \item  is the restriction of  to  and  for all
          relation and function symbols .
  \end{iteMize}
  We call this cut the {\em Polylogarithmic Cut} iff
  
\end{definition}

To examine the strength of the theory of such cuts of models of , we will show that a formal connection
between efficient computability and -definability holds. This stands in contrast to general bounded
subsets, where the connection is presumably only with respect to -definability via the predicate
 (see \eqref{Def ACC} on page \pageref{Def ACC}). The intended theorem is a formalization of
Nepomnjascij's Theorem \cite{Nep70} (see also \cite{Kra95} pg.20). We will sketch the original proof before
starting the formalization.

\begin{theorem}[Nepomnjascij \cite{Nep70}]
  \label{Thm Nepomnjascij} Let  and  be
  constants. Then if the language ,
  the relation  is definable by a -formula over .
\end{theorem}

\proof
  We will prove the theorem by induction on  for
  .

  Let  and .
  For any  the whole computation can be coded by a number  of size
  . The existence of such a computation gives the desired -definability.

  For  we write a sequence 
  of intermediate results coding the computation, where  codes the starting configuration
  on input , such that we can verify
  that  is computable from  in
  .
  By assumption there exists a -formula  such that
   holds iff  is computed
  from . Additionally, the whole sequence has length 
  and so we can write the sequence of intermediate results  as a number  of length .
  Now, the -definition of  is simply
  

\noindent We will now formalize this result in  as follows

\begin{theorem}\label{Thm Nepomnjascij_formalized} Let .
  Let  for some  and let  and . If
   (for strings of length ) is computed by Turing machine , then there exists a 
  definition in  of the -predicate  on the interval . I.e. any ,
  bounded by  is -definable in  and therefore exists in the polylogarithmic cut of .
\end{theorem}
  The following version of the proof stems from a discussion with Stephen Cook and Neil Thapen during the SAS
  programme in Cambridge. It is more explicit than the original one and clarifies the argument.

\begin{proof}
  We will inductively on  define a  relation 
  that states that the th cell of the work tape of , starting on configuration  and computing
  for  steps via the computation  is . We will bound the
  quantifiers in such a way that we can conclude that both variables can be of the number sort. As  depends
  only on  and  we will be doing this induction outside of the theory to construct  many formulas. We
  will then prove the above mentioned properties of  by  induction
  on .

  Keep in mind that a cell is given as a pair , where  is the actual
  value of the cell and  is a number  coding the state the Turing machine is in iff the
  pointer is on that cell and  otherwise. As before the transition function is denoted by . We let
   be a string coding the input at the start of the computation. That is,  is a sequence of length
  , such that ,  for all  and  is the th input bit.
  We let  be a sequence encoding the computation of , such that
   is the state, the machine is in after  steps (0 denotes that the
  read/write head is not on cell , while a greater number gives the
  state and witnesses that the read/write head is on cell ). 
  is the value of cell  after  steps of the computation. Observe that this also implies that the
  computation can be encoded as a number, that is, it has to be very short. This is straight forward from the
  quantifier bounds.

  We can now define





  \noindent It is straightforward to prove by induction on the number of lines in  that 
  is uniquely defined by
  . We let 
  where  is some polynomial depending on the encoding. Here it is vital that  can be defined such that
   is a number in . This is possible due to the quantifier bounds we used when defining
  . Thus,  is defined by a  formula.

  Informally  formalizes that there is a computation
  
  that is correct in the sense that we can verify that we get from line to line via the transition function of  and gives the appropriate values of the cell at . Observe that the size of the whole computation as presented above is linear in , i.e. that it can be coded as a number in .

  We will now proceed by inductively defining  and . Assume that
   has already been defined by a  formula over . We then let
  
  Again, we can prove uniqueness of the computation by induction on the number of its lines and let
   That this is a  definition follows by
  induction and the same argument as for . Here, the predicate  takes the role of the transition function in witnessing that each line follows from the preceding one. The total size again is linear in .


  We now can give a
   definition of the predicate  coding the computation as in  on input  of length . We let 
  
  where  is a polynomial depending on the encoding and  is the starting configuration of  on input
  .

  Informally the above formula says that we compute the configurations of  by using the predicates
   through . That is, after the application of 
  (i.e. after making the biggest steps) we have reached
  configuration , which we plug into  to get configuration  and so on.
  It remains to show that this definition of  coincides with the real one, i.e. that  follows from an application of the transition
  function of  from .

  We will prove this inductively, depending on . Again let  be such that .
  If  the assumption follows straightforwardly from the definition of
  . Now for bigger . If the , given as above, is bigger then  then
  again the assumption follows from the definition of . Now let  be the first index
  with . We the have to argue that  has the desired property.
  This, however, follows straightforward if we can verify this assertion for .
  Observe that  is a constant depending only on  and , so we need to make this argument only a
  constant number of steps to reach , where we know that the assertion holds.

  Since we can code the whole computation as a -formula (in ), we can easily deduce a
  -definition of the related set by simply stating that the computation accepts (i.e. that in the
  last line of the computation the state is accepting). This concludes the proof.
\end{proof}


We can now prove our main result.
\begin{theorem}\label{thm:conclusion Nepo}
  Let  and  be the polylogarithmic cut. Then
  .
\end{theorem}


\begin{proof}
  We have to prove that for all strings , representing a formula  as a tree and
  assignments  to its variables (i.e. leafs in the tree representation) a string  exists in  that
  contains all values of 's subformulas as in the definition of  in Section~\ref{Sec:Ext of VZ}
  and satisfies the inductive conditions of .



  However, by -comprehension and the formalized
  Nepomnjascij's Theorem it suffices to describe an algorithm that
  computes, for given  and , whether  belongs to   in
  
  for some  and . 



The following is a recursive algorithm computing the value of , given  and .


\verb"NodeValue(G,I,i)"

{\small
\begin{itemize}
  \item \verb"boolean left; boolean right;"
  \item \verb"If i>2"\verb"|G|"
  \begin{itemize}
    \item \verb"Output (0); End;"
  \end{itemize}
  \item \verb"Else If i>|G|"
  \begin{itemize}
    \item \verb"Output (I[i-|G|]); End;"
  \end{itemize}
  \item \verb"Else If G[i]=1"
  \begin{itemize}
    \item \verb"left := NodeVal(G,I,2i);"
    \item \verb"right := NodeVal(G,I,2i+1);"
    \item \verb"Output (left AND right); End;"
\end{itemize}
  \item \verb"Else If G[i]=0"
  \begin{itemize}
    \item \verb"left := NodeVal(G,I,2i);"
    \item \verb"right := NodeVal(G,I,2i+1);"
    \item \verb"Output (left OR right); End;"
\end{itemize}
    \item \verb"Else"
  \begin{itemize}
    \item \verb"Output (0); End;"
  \end{itemize}
\end{itemize}
} 
\noindent Observe that the algorithm at any given point only stores a
constant amount of data per level of the tree  and therefore uses
only  space. The number steps the algorithm makes is
clearly polynomial in the size of . Therefore by Theorem~\ref{Thm
  Nepomnjascij_formalized}, for every monotone formula ,
representable as a tree in , we get a  formula
, such that
. Observe that
 depends on the size of  and on its
logical depth, as the first is essentially the size of the input for
the machine, that  codes, while the latter determines
the longest iterations in the recursive algorithm. Applying the
Comprehension Schema in , i.e. in , this verifies the
existence of a  as in  for all formulas represented by trees
in .Therefore  holds in  and so .
\end{proof}





\section{Implications for Proof Complexity}\label{Sec:Impl Proof Cmpl}

We now wish to apply the above results to propositional proof systems. More precisely we wish to show that
theories of small cuts of a model of a given theory  correspond to stronger proof systems than
 does. An elegant way of showing such a statement is via the {\em Reflection Principles} of the
given proof systems, i.e. the statement that the proof system is correct, as explained in Section~\ref{Sec:Rel
BA pps}. With their help we can conclude the following recent result of Filmus, Pitassi and Santhanam
\cite{FPS11}.

\begin{theorem}[\cite{FPS11}]\label{thm FilPitSat}
  Every Frege system is sub exponentially simulated
  by -Frege systems.
\end{theorem}

\begin{proof}
  By Theorem~\ref{Thm Simulation by Bounded Reflection} we have to prove the polylogarithmically bounded Reflection
  Principle for Frege in . This, by Theorem~\ref{thm:conclusion Nepo} however,
  corresponds to proving the Reflection Principle for Frege in , which holds by
  Fact~\ref{fact:VNC1 and NC1 Frege}. It also follows from Theorem~\ref{Thm Simulation by Bounded Reflection} that this proof can be efficiently computed from the Frege proof.
\end{proof}

Another, related, application is in the separation of propositional proof systems. In \cite{MT11} we proved the
following.
\begin{proposition}\label{Prop Iddo me}
  For almost every random 3CNF  with  variables and  clauses, where  is a large
  constant,  has polynomially bounded -Frege proofs.
\end{proposition}
On the other hand it is well known (see for example \cite{CS88}) that such formulas have no subexponential
refutation in Resolution. Thus, this yields an average case separation between Resolution and
-Frege. We can now extend this result to an average case separation between Resolution and
-Frege as follows.
\begin{theorem}
  For almost every random 3CNF  with  variables and  clauses, where  is a large
  constant,  has subexponentially bounded -Frege proofs.
\end{theorem}
\begin{proof}
  By Theorem~\ref{thm:conclusion Nepo} the polylogarithmic Cut of any -model is a model of ,
  therefore also of . This yields, as in our proof of Theorem~\ref{thm FilPitSat}, that
  -Frege subexponentially simulates -Frege. The result now follows from
  Proposition~\ref{Prop Iddo me}.
\end{proof}


\section{Conclusion and Discussion}

As we have seen cuts of models of weak arithmetics constitute an appropriate way for reasoning about
super-polynomial simulations between proof systems. An advantage in comparison to syntactic arguments is the
possible applicability of results in Model Theory and a more uniform treatment. This can readily be observed as
with our argument, e.g. the work of Paris and Wilkie \cite{PW85}\cite{PW87} immediately imply the simulation
results from Bonet et al. \cite{BDGMP04}.

This leads to interesting possibilities for further research, especially towards the weak automatizability of
weak propositional proof systems such as Resolution. The underlying theory, which was  in our argument,
must be significantly weakened, however. If we could take  as our base theory, we could reason
about whether  has the feasible interpolation property in the same way as Kraj\' i\v cek and Pudl\'
ak \cite{KP98}, Bonet, Pitassi and Raz \cite{BPR00} or Bonet, Domingo, Gavald\`a, Maciel, and Pitassi
\cite{BDGMP04}. Now, if  does not have quasi-polynomial feasible interpolation we know by a result
from Atserias and Bonet \cite{AB04} that Resolution is not weakly automatizable, so we would be finished.
Whether we can actually do it depends on the strength of the theory the polylogarithmic cut of 
models and if we can formalize some sort of iterated multiplication (such as in \cite{ABH02}) in that theory.
Also, the security of Diffie-Hellman seems to be a more appropriate assumption than that of RSA, as the
computational power needed to verify the correctness of Diffie-Hellman seems to be lower.




\section{Acknowledgements}

I want to thank Steve Cook, Jan Kraj\' i\v cek and Neil Thapen for helpful suggestions and discussion, Emil Je\v
r\' abek for his comments and for answering my questions and the participants of the MALOA Special Semester in
Proof Complexity in Prague 2011 for enduring a sloppy and sometimes faulty exposition of this proof and still
coming up with helpful comments. I also want to thank the anonymous referees for pointing out various mistakes
and for giving interesting suggestions.
A similar construction can be extracted from \cite{Zam97} and leads to similar results, if perceived in the way we did it here. I want to thank Leszek Kolodziejczyk for pointing this out.


\begin{thebibliography}{10}


\bibitem{AB09}
S.~Arora and B.~Barak.
\newblock Computational Complexity.
\newblock {\em Cambridge University Press}, 2009.

\bibitem{AB04}
A.~Atserias and M.~L.~Bonet.
\newblock On the Automatizability of Resolution and Related Propositional Proof
Systems.
\newblock {\em Information and Computation}, Vol. {\bf 189}(2), 2004, pp. 182-201.



\bibitem{BDGMP04}
M.L.~Bonet, C.~Domingo, R.~Gavald\`a, A.~Maciel, and T.~Pitassi.
\newblock Non-Automatizability of Bounded-Depth Frege Proofs.
\newblock {\em Computational Complexity}, Vol. {\bf 13}, 2004, pp.47-68.

\bibitem{BPR00}
M.L.~Bonet, T.~Pitassi, and R.~Raz.
\newblock On interpolation and automatization for Frege systems.
\newblock {\em SIAM Journal of Computing},  Vol. {\bf 29 (6)}, 2000, pp. 1939-1967.


\bibitem{Bu87}
S.~Buss.
\newblock Polynomial Size Proofs of the Propositional Pigeonhole Principle.
\newblock {\em Journal of Symbolic Logic}, Vol. {\bf 52}, 1987, pp. 916-927.

\bibitem{CGN12}
S.~Cook, K.~Ghasemloo and P.~Nguyen.
\newblock Subexponential Size Bounded Depth Frege Proofs and Subsystems of .
\newblock Manuscript, 2012.

\bibitem{CN10}
S.~Cook and P.~Nguyen.
\newblock Logical Foundations of Proof Complexity.
\newblock {\em Cambridge University Press}, 2010.


\bibitem{CR79}
S.~Cook and R.~Reckhow.
\newblock The Relative Efficiency of Propositional Proof Systems.
\newblock {\em Journal of Symbolic Logic}, Vol. {\bf 44}(1), 1979, pp.36-50.

\bibitem{CS88}
V.~Chv{\'a}tal and E.~Szemer{\'e}di.
\newblock Many Hard Examples for Resolution.
\newblock {\em Journal of the Association for Computing Machinery}, Vol. {\bf 35}(4), 1988, pp. 759-768.

\bibitem{FPS11}
Y.~Filmus, T.~Pitassi,  and R.~Santhanam.
\newblock Exponential Lower Bounds for AC-Frege Imply Superpolynomial Frege Lower
Bounds.
\newblock {\em Proceedings ICALP}, Vol. {\bf 1}, 2011, pp.618-629.

\bibitem{ABH02}
W.~Hesse, E.~Allender and D.~Barrington.
\newblock Uniform Constant-Depth Threshold Circuits for Division and
Iterated Multiplication.
\newblock {\em Journal of Computer and System Sciences}, Vol. {\bf 65}, 2002,
pp.695-716.

\bibitem{Kra95}
J.~Kraj\' i\v cek.
\newblock Bounded Arithmetic, Propositional Logic, and Complexity Theory.
\newblock {\em Cambridge University Press}, 1995.

\bibitem{KP98}
J.~Kraj\' i\v cek and P.~Pudl\' ak.
\newblock Some Consequences of Cryptographical Conjectures for  and .
\newblock {\em Information and Computation}, Vol. {\bf 140 (1)}, 1998, pp.82-94.

\bibitem{KPW95}
J.~Kraj\' i\v cek, P.~Pudl\' ak and A.~Woods.
\newblock Exponential lower bound to the size of bounded depth Frege proofs
of the Pigeon Hole Principle.
\newblock {\em Random Structures and Algorithms}, Vol. {\bf 7}(1), 1995, pp.15-39.

\bibitem{MT11}
S.~M\" uller and I.~Tzameret.
\newblock Short Propositional Refutations for Dense Random 3CNF Formulas.
\newblock Manuscript, 2011.

\bibitem{Nep70}
V.A.~Nepomnjascij.
\newblock Rudimentary Predicates and Turing Calculations.
\newblock {\em Doklady AN SSSR}, Vol. {\bf 195}, 1970.

\bibitem{PW85}
J.~Paris and A.~Wilkie.
\newblock Counting Problems in Bounded Arithmetic.
\newblock {\em Methods in Mathematical Logic}, LNM {\bf 1130}, 1985, pp.317-340.

\bibitem{PW87}
J.~Paris and A.~Wilkie.
\newblock Counting  Sets.
\newblock {\em Fundamenta Mathematica}, Vol. {\bf 127}, 1987, pp.67-76.

\bibitem{PBI93}
T.~Pitassi, P.~Beame, R.~Impagliazzo.
\newblock Exponential Lower Bounds for the Pigeonhole Principle.
\newblock {\em Computational Complexity}, Vol. {\bf 3}, 1993, pp.97-140.

\bibitem{Zam97}
D.~Zambella.
\newblock End extensions of models of linearly bounded arithmetic.
\newblock {\em Annals of Pure and Applied Logic}, Vol. {\bf 88}, 1997, pp.263-277.

\end{thebibliography}

\end{document}
