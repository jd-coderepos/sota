\documentclass[10pt]{llncs}
\usepackage[T1]{fontenc}
\usepackage[latin9]{inputenc}
\usepackage{color}
\usepackage{float}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{graphicx}

\makeatletter

\floatstyle{ruled}
\newfloat{algorithm}{tbp}{loa}
\providecommand{\algorithmname}{Algorithm}
\floatname{algorithm}{\protect\algorithmname}




\usepackage{llncsdoc}\@ifundefined{definecolor}
 {\usepackage{color}}{}
\usepackage{float}\usepackage{amsfonts}\usepackage{multicol}


\newtheorem{defn}{Definition}
\newtheorem{lem}{Lemma}
\newtheorem{thm}{Theorem}
\newtheorem{prop}{Proposition}
\newtheorem{cor}{Corollary}
\newtheorem{rem}{Remark}

\makeatother

\begin{document}

\title{Constrained Fault-Tolerant Resource Allocation\thanks{Part of section 5 of this paper has appeared in \cite{kewen2011cocoon}.}}


\author{\author{Kewen Liao, Hong Shen and Longkun Guo }}


\institute{\institute{School of Computer Science \\ The University of Adelaide, Adelaide, Australia  \\  School of Computer and Information Technology\\ Sun Yat-sen University, Guangzhou, China \\ \email{\{kewen, hong\}@cs.adelaide.edu.au} \\ \email{longkun.guo@gmail.com}}}
\maketitle
\begin{abstract}
In the Constrained Fault-Tolerant Resource Allocation () problem,
we are given a set of sites containing facilities as resources, and
a set of clients accessing these resources. Specifically, each site
 is allowed to open at most  facilities with cost 
for each opened facility. Each client  requires an allocation
of  open facilities and connecting  to any facility at
site  incurs a connection cost . The goal is to minimize
the total cost of this resource allocation scenario.

\quad{}\enskip{} generalizes the Unconstrained Fault-Tolerant
Resource Allocation () \cite{kewen2011cocoon} and
the classical Fault-Tolerant Facility Location () \cite{Jain00FTFL}
problems: for every site ,  does not have the
constraint , whereas  sets . These problems
are said to be uniform if all 's are the same, and general
otherwise.

\quad{}\enskip{}For the general metric , we first give an
LP-rounding algorithm achieving an approximation ratio of 4. Then
we show the problem reduces to , implying the ratio of 1.7245
from \cite{JaroslawFTFL1.725}. For the uniform , we provide
a 1.52-approximation primal-dual algorithm in \textcolor{black}{
time, where  is the total number of sites and clients.} We also
consider the Constrained Fault-Tolerant -Resource Allocation (-)
problem where additionally the total number of facilities can be opened
across all sites is bounded by . For the uniform -,
we give the first constant-factor approximation algorithm with a factor
of 4. Note that the above results carry over to  and
-.
\end{abstract}
\markboth{Kewen Liao, Hong Shen and Longkun Guo}{Constrained Fault-Tolerant
Resource Allocation }\thispagestyle{empty}


\section{Introduction}

In the \textit{Constrained Fault-Tolerant Resource Allocation} ()
problem introduced in \cite{kewen2011cocoon}, we are given a set
 of sites and a set \textcolor{black}{}
of clients, where , 
and . Each site  contains at most
 () facilities to open as resources and each
client  is required to be allocated  ()
open facilities. Note that in , facilities at the same site
are different and .
Moreover, opening a facility at site  incurs a cost  and
connecting  to any facility at  costs . The objective
of the problem is to minimize the sum of facility opening and client
connection costs under the resource constraint . This problem
is closely related to the \textit{Unconstrained Fault-Tolerant Resource
Allocation} ()\footnote{The problem was also called \textit{Fault-Tolerant Facility Allocation
}() in \cite{shihongftfa} and \textit{Fault-Tolerant Facility
Placement }() in \cite{yan2011approximation}. Nevertheless,
we reserve our names for identifying the different application-oriented
resource allocation scenarios. Our naming convention also follows
from \cite{fujito2005better,hua2009exact,kolliopoulos2003approximating}
for the set cover problems.} \cite{kewen2011cocoon}, the classical \textit{Fault-Tolerant Facility
Location }() \cite{Jain00FTFL} and\textit{ Uncapacitated Facility
Location }() \cite{Shmoys97FL} problems. Both 
and  are special cases of :  is unbounded in
, whereas  in
. These problems are said to be \textit{uniform} if all 's
are same, and\textit{ general} otherwise. If ,
they all reduce to . Fig. 1 displays an  instance with
a feasible solution. We notice that both  and 
have potential applications in numerous distributed systems such as
cloud computing, content delivery networks, Web services provision
and etc. The fault-tolerance attribute () can be also viewed
as the parallel processing capability of these systems. Unless elsewhere
specified, we consider the problems in metric space, that is, the
connection costs 's satisfy the metric properties like the
triangle inequality and etc.\textcolor{black}{{} Note that even the
simplest non-metric  is hard to approximate better than 
unless }
\cite{Sviridenko02improved1.58}.

\begin{figure}
\begin{centering}
\includegraphics[scale=0.7]{FTRA}
\par\end{centering}

\caption{An  instance with a feasible solution}
\end{figure}


\textbf{Related Work.} Primal-dual and LP-rounding are two typical
approaches in designing approximation algorithms for the facility
location problems. Starting from the most basic and extensively studied
 problem, there are JV \cite{jain01approximation}, MMSV \cite{Mohammad1.861}
and JMS \cite{Jain02greedy} primal-dual algorithms obtaining approximation
ratios of 3, 1.861 and 1.61 respectively. In addition, Charikar and
Guha \cite{Charikar051.7281.853} improved the result of the JV algorithm
to 1.853 and Mahdian et al. \cite{Mohammad06FLP} improved that of
the JMS algorithm to 1.52, both using the standard cost scaling and
greedy augmentation techniques. Shmoys et al. \cite{Shmoys97FL} first
gave a filtering based LP-rounding algorithm achieving the constant
ratio of 3.16. Following this, Guha and Khuller \cite{Guha99greedy}
improved the factor to 2.41 with greedy augmentation. Later, Chudak
and Shmoys \cite{Chudak0312e} came up with the clustered randomized
rounding algorithm which further reduces the ratio to 1.736. Based
on their algorithm, Sviridenko \cite{Sviridenko02improved1.58} applied
pipage rounding to obtain 1.582-approximation. Byrka \cite{jaroslaw2010optimal}
achieved the ratio of 1.5 using a bi-factor result of the JMS algorithm.
Recently, Li's more refined analysis in \cite{Li2011} obtained the
current best ratio of 1.488, which is close to the 1.463 lower bound
established by Guha and Khuller \cite{Guha99greedy}. For the \textcolor{black}{non-metric
, there are two  approximation algorithms
\cite{Hochbaum-1982,Lin92filting} based on the greedy and LP-rounding
approaches respectively.}

Comparing to ,  seems more difficult to approximate.
For the general , the primal-dual algorithm in \cite{Jain00FTFL}
yields a non-constant factor \textcolor{black}{}.
Constant results exist only for the uniform case. In particular, Jain
et al. \cite{Jain03dualfitting,MohammadThesis2004} showed their MMSV
and JMS algorithms for  can be adapted to the uniform 
while preserving the ratios of 1.861 and 1.61 respectively. Swamy
and Shmoys \cite{Swamy08FTFL2.076} improved the result to 1.52. On
the other hand, LP-rounding approaches are more successful for the
general . Guha et al. \cite{Guha03FTFL2.41} obtained the first
constant factor algorithm with the ratio of 2.408. Later, this was
improved to 2.076 by Swamy and Shmoys \cite{Swamy08FTFL2.076} with
several rounding techniques. Recently, Byrka et al. \cite{JaroslawFTFL1.725}
used dependent rounding and laminar clustering techniques to get the
current best ratio of 1.7245.

Allowing parallel connections to multiple facilities at the same site,
 was first introduced by Xu and Shen \cite{shihongftfa}
and they claimed a 1.861 approximation algorithm which runs in pseudo-polynomial
time for the general case. Liao and Shen \cite{kewen2011cocoon} studied
the uniform case of the problem and presented a 1.52 approximation
algorithm using a star-greedy approach. The general case of the problem
was also studied by Yan and Chrobak \cite{yan2011approximation} who
gave a 3.16-approximation LP-rounding algorithm based on \cite{Shmoys97FL,Chudak0312e},
and recently claimed the ratio of 1.575 \cite{yan2012lp} built on
the work of \cite{Chudak0312e,jaroslaw2010optimal,jaroslaw2012lp,Guha03FTFL2.41}.
They aim to close the approximation gap between  and
. On the other hand, due to the difficulties both inherited
from  and , it is still unknown what the approximation
gap between  and  is.

In this paper, we strive to close this gap. However, there are several
difficulties. First, despite the similar combinatorial structures
of  and , the existing LP-rounding algorithms
\cite{yan2011approximation,yan2012lp} for  can not
be adopted for . This is because these algorithms produce infeasible
solutions that violate the constraint  in . In particular,
the recent work of \cite{yan2012lp} requires liberally splitting
facilities and randomly opening them. This can not be done for both
 and  as the splitting may cause more than 
facilities to open, which is not a problem for . Second,
in , , while 
can be much larger than  in both  and .
Therefore, the naive reduction idea of splitting the sites of an 
instance and then restrict each site to have at most one facility
will create an equivalent  instance with a possibly exponential
size. Third, significantly more insights and heuristics are needed
in addition to the previous work for solving  (both the general
and the uniform cases) in polynomial time.

\textbf{Our Contribution.} For the general , we first develop
a \textit{unified LP-rounding algorithm }through modifying and extending
the 4-approximation LP-rounding algorithm \cite{Swamy08FTFL2.076}
for . The algorithm can directly solve , 
and  with the same approximation ratio of 4. This is achieved
by: 1) constructing some useful \textit{properties} of the unified
algorithm which enable us to directly round the optimal fractional
solutions with values that might exceed one while ensuring the feasibility
of the rounded solutions and the algorithm correctness; 2) exploiting
the primal and dual complementary slackness conditions of the 
problem's LP formulation. Then we show  reduces to 
using an \textit{instance shrinking technique} inspired from the splitting
idea of \cite{yan2011newresults} for . It implies
that these two problems may share the same approximability in weakly
polynomial time. Hence, from the  result of \cite{JaroslawFTFL1.725},
we obtain the ratio of 1.7245\textcolor{black}{. For the non-metric
, we get }the first approximation factor of \textcolor{black}{
deduced from the work of \cite{Jain00FTFL,Lin92filting}. Note that,
although our first rounding algorithm attains a worse approximation
ratio, it could be more useful than the second to be adapted for other
variants of the resource allocation problems.}

For the uniform , better results are obtained. We first present
a naive \textit{primal-dual algorithm} that runs in pseudo-polynomial
time. To analyze the algorithm, we adopt a \textit{constraint-based
analysis} to derive the ratio of 1.61. Compared to dual fitting \cite{Jain03dualfitting}
and inverse dual fitting \cite{shihongftfa}, our analysis approach
is simpler and more convenient for handling more complicated dual
constructions. Later, with a carefully designed \textit{acceleration
heuristic} applied to the primal-dual algorithm, we obtain the first
strongly polynomial time algorithm for  that has the same ratio
of 1.61 but runtime \textcolor{black}{. }Moreover,
by applying another similar heuristic to the greedy augmentation technique
\cite{Guha03FTFL2.41}, \textcolor{black}{the 3.16-approximation rounding
result of \cite{yan2011approximation} for the general 
is improved to 2.408, and the previous 1.61 ratio for the uniform
} \textcolor{black}{reduces to 1.52.}

Lastly, we consider an important variant of  -- the Constrained
Fault-Tolerant -Resource Allocation (-) problem which
adds an extra global constraint that at most  facilities across
all sites can be opened as resources. For the uniform -,
based on the work of \cite{jain01approximation,Jain03dualfitting,Swamy08FTFL2.076},
we give the first constant-factor approximation algorithm for this
problem with a factor of 4. In particular, the algorithm relies on
a polynomial time \textit{greedy pairing} \textit{procedure} we develop
for efficiently splitting sites into paired and unpaired facilities.

The results shown directly hold for  and -,
and the techniques developed will be useful for other variants of
the resource allocation problems. For ease of analysis and implementation,
the algorithms presented mostly follow the pseudocode style. Furthermore,
we distinguish among pseudo-, weakly and strongly polynomial time
algorithms w.r.t. the problem size .


\section{LP Basics and Properties}

The  problem has the following ILP formulation, in which \textcolor{black}{solution
variable  denotes the number of facilities to open at site
, and  the number of connections between client 
and site . From the ILP, we can verify that the problem becomes
the special cases  if all 's are uniform and equal
to , and  if the third resource constraint is
removed.} 

\textit{\small 

}{\small \par}

The problem's LP-relaxation (primal LP) and dual LP are the following:

\textit{\small 

}{\small \par}

{\small 

}{\small \par}

Now we let 
and 
be the optimal fractional primal and dual solutions of the LPs, and
 and 
be the cost functions (objective value functions) of any primal and
dual solutions respectively. By the strong duality theorem, .
Moreover, the primal complementary slackness conditions (CSCs) are:

(C1) If  then .

(C2) If  then .

Dual CSCs are:

(C3) If  then .

(C4) If  then .

(C5) If  then .

W.l.o.g., 
and 
have the following properties:

(P1)  and .

(P2)  is 'almost'
complete, i.e.  if  then
 (the complete condition) or there is at most
one  s.t.  where  is the farthest
site connecting . (cf. \cite{Chudak0312e,Swamy08FTFL2.076} for
more details)


\section{A Unified LP-Rounding Algorithm}

The algorithm ULPR (Algorithm 1) starts by solving the primal and
dual LPs to get the optimal solutions 
and 
to work with. In order to utilize the dual LP for analyzing the approximation
ratio of the output solution ,
we need to first deal with how to bound the 
term in the dual objective function, introduced by imposing the new
resource constraint 
in the primal LP. To resolve this, we exploit the dual CSC (C5). This
condition guides us to come up with Stage 1 of the algorithm ULPR
which fully opens all (facilities of) sites with 
and put these sites into the set  for pruning in the
future. Moreover, for successfully deriving the bound stated in Lemma
\ref{lem:1}, in the algorithm the client connections 
with the opened sites in  are rounded up to ;
in the analysis the other primal and dual CSCs are also exploited.
At the end of Stage 1, for each , we calculate its established
connection , residual connection requirement 
and record its connected sites not in  as set 
for the use of next stage.

\begin{algorithm}[H]
\caption{ULPR: Unified LP-Rounding Algorithm}


\textbf{\textcolor{black}{Input}}\textcolor{black}{: }.\textbf{\textcolor{black}{{}
Output: }}

\textbf{\textcolor{black}{Initialization}}\textcolor{black}{: }Solve
LPs \eqref{eq:ftra-lp} and \eqref{eq:ftra-dual} to obtain the optimal
fractional solutions 
and .


\textbf{\textcolor{black}{Stage 1}}\textcolor{black}{: Pruning and
Rounding}

\textbf{for} 

\qquad{}\textbf{if}  \textbf{do}

\qquad{}\qquad{}

\qquad{}\qquad{}

\qquad{}\qquad{}\textbf{for}  

\qquad{}\qquad{}\qquad{}\textbf{if}  \textbf{do}

\qquad{}\qquad{}\qquad{}\qquad{}

\textbf{set} 

\medskip{}


\textbf{\textcolor{black}{Stage 2}}\textcolor{black}{: Clustered Rounding}

\textbf{set} 

\textbf{while }

\qquad{}\textbf{//2.1}: Construct a cluster  centered
at 

\qquad{},
order  by non-decreasing site facility costs

\qquad{}choose  starting
from the cheapest site in  s.t. just 

\qquad{}\textbf{if} 
\textbf{do}

\qquad{}\qquad{}split the last most expensive site 
into  and : , 

\qquad{}\qquad{};\textbf{
forall }:\textbf{ }set  s.t.
,  

\qquad{}\qquad{} and update ;\textbf{
}
(now )\medskip{}


\qquad{}//\textbf{2.2}: Rounding around  and 

\qquad{}//\textbf{2.2.1}: Finish rounding 

\qquad{}\textbf{for  }//from the cheapest site

\qquad{}\qquad{} 

\qquad{}\qquad{}
//maintain a set of already rounded sites

\qquad{}\qquad{}\textbf{if }

\qquad{}\qquad{}\qquad{}
(resetting  to make )

\qquad{}\qquad{}\qquad{}\textbf{break}\medskip{}


\qquad{}//\textbf{2.2.2}: Finish rounding 

\qquad{}\textbf{for}  //including 

\qquad{}\qquad{}if 

\qquad{}\qquad{}\qquad{}\textbf{for  }//order
does not matter, could connect to the closest

\qquad{}\qquad{}\qquad{}\qquad{}

\qquad{}\qquad{}\qquad{}\qquad{}

\qquad{}\qquad{}

\qquad{}\textbf{update }
\end{algorithm}


While most LP-rounding algorithms round optimal solutions with values
in , for , our approach directly rounds
the solutions with values in  and later
we shall analyze its correctness via establishing some useful properties.
Like the major LP-rounding algorithms \cite{Sviridenko02improved1.58,jaroslaw2010optimal,jaroslaw2012lp,Li2011}
for , Stage 2 of our algorithm also inherits the classical iterative
clustering idea \cite{Shmoys97FL,Chudak0312e}. The clustering and
rounding here terminate when all 's are satisfied, i.e.
the set of not-fully-connected clients 
in the algorithm. Stage 2 consists of two substages 2.1 and 2.2, dealing
with cluster construction and cluster guided rounding respectively.
Stage 2.1 essentially adopts the facility cloning idea \cite{Swamy08FTFL2.076}
for the deterministic rounding of . Nevertheless, here we are
splitting sites. In each iteration, it first picks the cluster center
 with the smallest optimal dual value, and then builds a cluster
 around it which contains a subset of ordered sites
in , starting from the cheapest site until .
In order to maintain the invariant 
in every iteration, the stage then splits the last site 
into  and , updates the client connections w.r.t.
 and , and in  includes  while
excluding  to keep .
Stage 2.2 does the final rounding steps around  in addition
to Stage 1 to produce a feasible integral solution .
This stage modifies and generalizes the rounding steps for .
Its substage 2.2.1 rounds up the sites ()
from the cheapest site in  until 
(the set of sites rounded so far) just satisfies \textbf{}
(now these 's are already integral). To make sure 
for bounding the site facility opening cost (cf. Lemma \ref{lem: boc}),
the integral facility opening  of the last site  in 
is reset to ,
which is also integral. After the facilities at the sites in 
are opened according to the 's constructed in stage 2.2.1,
stage 2.2.2 then connects every client  in 
which has connections to the sites in  (according to
the 's) to 
of these open facilities. It does this by iterating through all sites
in , setting 's and updating 's
as described in the algorithm. At the end, for the run of next iteration,
the sites in the cluster  are excluded from ,
implying all clusters chosen in the iterations are disjoint; and 
is updated (at least  is removed from the set). 

In the analysis, we first demonstrate the overall correctness of the
algorithm ensured by the following properties. Note that some of the
proofs in this section frequently refer to the content of Section
2.

\medskip{}


(P3) After Stage 1, 
 and .
\begin{proof}
The first part of the property is obvious since  or .
For the second part,  if all 
are integers, we are done. Now we only need to consider 's fractional
 connecting with . By the previous
property (P2), there is at most one fractional  with
 because all 's in  are integers.
Therefore, in Stage 1, at most one fractional  is rounded
up which will not make  exceed .
\end{proof}


(P4) Stage 2.2.1 rounds  (the optimal fractional opening
of the last site  in  which is included in Stage
2.1) to at most . 
\begin{proof}
If  is integral, the property clearly holds. Otherwise
if  is fractional, Case 1): if \textbf{
}before resetting the last site  in Stage 2.2.1, this  definitely
appears before  in  because otherwise 
will exceed , therefore  is left unrounded;
Case 2): If \textbf{},
the last site  is possibly  and if it is then ,
and from the algorithm we have rounded 
after resetting. If 
we get 
which is not possible since 
(because  is fractional). Hence, 
is rounded to at most .
\end{proof}


(P5)  given ,
then we have .
\begin{proof}
We first have 
and , so
.
Now if  is integral, because 
is also integral, .
Otherwise if  is fractional, .
The property then follows from .
\end{proof}
\medskip{}


In summary, property (P3) shows the correctness of Stage 1 before
going into Stage 2, (P4) and (P5) together ensure the splitting in
Stage 2.1 and the rounding in Stage 2.2.1 produce feasible 's
for . This is because for any split sites  and 
from , (P4) guarantees at  at most 
facilities are open, and (P5) makes sure that even 
facilities are opened at  in the subsequent iterations of
the algorithm, no more than  facilities in total actually
get opened at . Note that, (P5) also covers the situation that
a site is repeatedly (recursively) split. Furthermore, in each iteration,
Stage 2 at least fully connects the client  and considers
all sites in the cluster  centered at . More
importantly, the invariant 
is maintained for choosing the feasible cluster  in
Stage 2.1. This is true in the first iteration. In the subsequent
iterations, the invariant still preserves because for any  with
 that is not fully connected
in the current iteration, in the next iteration, 
is decreased by at most  (because Stage 2.1 splits
sites to maintain 
and  is excluded from  in Stage 2.2.2)
and  is decreased by exactly  (from
Stage 2.2.2). Therefore, the overall algorithm is correct.

Furthermore, the time complexity of the rounding stages of Algorithm
1 is  since each iteration of Stage 2 at least
fully connects one of  clients which takes time .
In the following, we separately bound the partial solution costs incurred
in the stages involving rounding and then combine these costs for
achieving the approximation ratio.
\begin{lemma}
After pruning and rounding, the partial total cost from Stage 1 is
.
\label{lem:1}\end{lemma}
\begin{proof}





The first equality is due to the condition (C1), the third, fourth
and fifth is because by (C4) we have 
if  then , so 
implies  (by the contraposition in logic) and also
. The last
equality is obtained from (C2), and the fact that .

Summing both sides over all , we can then bound
the cost of Stage 1:





The second equality follows from Stage 1 that ,
and the condition (C5): if  then ,
so  implies .\end{proof}
\begin{lemma}
After rounding , the partial site facility opening
cost from Stage 2.2.1 is at most .
\label{lem: boc}\end{lemma}
\begin{proof}
Facilities at sites 
are opened in 's non-decreasing order in Stage 2.2.1: In any
iteration of the algorithm with picked cluster , before
rounding we have ;
after rounding set  is formed starting from the
cheapest site in  s.t. .
This makes the opening cost of all sites in cluster 
at most . The lemma then follows
from the fact that all chosen clusters are disjoint in the algorithm.\end{proof}
\begin{lemma}
After rounding , the partial connection cost from
Stage 2.2.2 is at most .
\label{lem: conn} \end{lemma}
\begin{proof}
Let site  lie in the cluster  centered at .
If  is already connected to  (), then 
from the condition (C1). Otherwise, if  connects to  after
rounding, from the algorithm, it implies 
(because  with the smallest  is always chosen
as ) and . Fig.
2 then displays the case 
where initially  connects to  and it is connected to 
after rounding. By the triangle inequality, we have .
Also, it is true that ,
so from (C1) we have  and .
Hence, .
Since each  makes  connections, the total partial
connection cost bound is 
and the lemma follows. Note that Fig. 2 does not show multiplicity
of the connection between any client and site in an  solution.
It is merely for simplicity and will not affect the correctness of
the proof.
\begin{figure}
\begin{centering}
\includegraphics{boundConCost}
\par\end{centering}

\caption{Illustration of bounding the connection costs}
\end{figure}
\end{proof}
\begin{theorem}
Algorithm ULPR is 4-approximation for .\end{theorem}
\begin{proof}
Adding up the partial cost bounds stated in the previous lemmas, the
total cost  is
therefore at most .
Also, we have ,
so .
The last inequality follows from the fact that 
is the cost of Stage 1 (cf. Lemma \ref{lem:1}) which is nonnegative.
\end{proof}

\section{Reduction to }

Recently, the authors in \cite{yan2011newresults} presented a splitting
idea that is able to reduce any  instance with arbitrarily
large  to another small  instance with polynomially
bounded . The direct consequence of this is that 
is then reducible to , since we are able to naively split the
sites of the small  instance and the resulting instance
is equivalent to an  instance with a polynomial size. Because
 and  have similar combinatorial structures
where  is a special case, the question then becomes
whether the more general  reduces to  as well. In the
following, we give an affirmative answer to this with an instance
shrinking technique.

Compared to the reduction in \cite{yan2011newresults} for ,
first, the instance shrinking technique is more general. This is because
the technique reduces any  instance with arbitrarily large
 to another small  instance with polynomially bounded
, which works for  as well since an 
instance can be treated as an  instance with all 's
set to be . The small  instance
is then equivalent to an  instance with a polynomial size (),
implying  and  share the same approximability in weakly
polynomial time. Second, the reduction for  does not
have a mechanism for bounding  polynomially in .
Therefore, it can not directly yield a reduction result for .
On the other hand, our technique initially includes the following
\textit{crucial} instance shrinking mechanism for bounding .
\begin{claim}
 remains to
be the optimal solution even if  is replaced with 
in LP \eqref{eq:ftra-lp}. \end{claim}
\begin{proof}
Denote the instance with parameter  as ,
and  after replacing  with .
On one hand, solving  will not yield any better optimal
solution 
with ,
because this 
is also feasible to , which contradicts the optimality
of  for .
On the other hand, 
is not possible since 
is also a feasible solution to  as ,
which contradicts the optimality of 
for . Hence, 
stays optimal for .
\end{proof}
With this mechanism, instead we can consider the equivalent 
instance  with 
and the same optimal solution .
Then in the reduction, 
is split into a large integral solution with 
and ,
and a small fractional solution with 
and , for all .
Let the tuple 
represent the instance , the reduction then proceeds
by splitting  into a large instance :

and a small instance : 
according to 
and . In particular,
these two instances differ at two parameters  and
, where we let ,
 and , .
Note that although the above splitting idea of the instance shrinking
technique is inspired from the reduction for , the
focus on splitting  is essentially different from reducing
. Also, here we can see that the construction of the shrunken
instance  with 
is crucial for bounding , since if the original 
is used,  can not be bounded and the technique will not
work. In the following, the first lemma mostly results from the original
splitting idea where we provide a simpler proof for it. The second
is directly from our instance shrinking and splitting on .
As shown later in the proof of Theorem \ref{reduction-theorem}, these
lemmas are necessary for the approximation preserving reduction from
 to .
\begin{lemma}
 is a feasible
integral solution to  and 
is a feasible fractional solution to .\label{lem:splitting}\end{lemma}
\begin{proof}
According to the LP \eqref{eq:ftra-lp}, it is trivial to see the
feasibility of the integral solution .
For the fractional solution ,
since , ,
 and ,
we have  and the first
constraint of the LP holds. Further, it is easy to see 
and we are left to show the second constraint 
holds, i.e. .
Consider two cases: 1) ,
then the inequality obviously follows from ;
2) , the inequality
, and 
after substituting . Now again consider two sub cases:
2.1) , then 
while , so  and the inequality follows; 2.2)
, then ,
and since , 
and , then the inequality follows. Overall, 
is a feasible solution.\end{proof}
\begin{lemma}
For the instances  and  the following
holds: \label{lem: ss-bounds}

\textup{(i)} 
and .

\textup{(ii)} .\end{lemma}
\begin{proof}
(i) The previous lemma and the constraints of the LP \eqref{eq:ftra-lp}
together ensure the bounds that 
and .

(ii) We have 
after the substitution of . If ,
then ,
otherwise if , then .\end{proof}
\begin{theorem}
If there is a -approximation polynomial-time algorithm 
for the general  with polynomially bounded , which
always produces an integral solution that approximates the fractional
optimal solution with factor . Then there is also a polynomial-time
-approximation algorithm  for the general .\label{reduction-theorem}\end{theorem}
\begin{proof}
We will describe such an algorithm . It first does
the instance shrinking and splitting as described before for any instance
 of . From (i) of Lemma \ref{lem: ss-bounds},
the split instances  and  are
valid. From (ii),  has polynomially bounded .
Note that if , we can safely remove this site  in
, and set the solution 
when later combining it with . Then, 
uses  as a subroutine to solve  to
obtain a feasible integral solution 
that approximates the fractional optimum. Also, from Lemma \ref{lem:splitting},
 is feasible
to , so .
Finally,  combines 
with the readily available constructed integer solution 
for . Because 
is a feasible integral solution to , then when combined,
they form a feasible integral solution to  as 
and .
The only thing left is to prove the combined solution from 
is -approximation, i.e., .
This follows from 
and , .\end{proof}
\begin{corollary}
The general  is reducible to the general  in weakly
polynomial time.\end{corollary}
\begin{proof}
Any instance of  with polynomially bounded  can be
treated as an equivalent  instance with facility size 
which is polynomial. Then any polynomial time algorithm solves 
with ratio  (w.r.t. the fractional optimum) can become the
algorithm  for  in the previous theorem
to solve  with the same ratio. In addition, the reduction requires
solving the LP first to obtain 
which takes weakly polynomial time.
\end{proof}
Therefore, from the above corollary and the result of \cite{JaroslawFTFL1.725}
for the metric , we get the ratio of 1.7245 for the metric
. Also, \textcolor{black}{from the results of \cite{Jain00FTFL,Lin92filting},
we can deduce that the non-metric  has an approximation ratio
of . This is because Jain and Vazirani \cite{Jain00FTFL}
proved that  reduces to  with a ratio loss of ,
and Lin and Vitter \cite{Lin92filting} showed that the non-metric
 can be approximated with the ratio of 
w.r.t. the fractional optimum. For the non-metric , we can
subsequently achieve the same ratio due to its reduction to 
first. Moreover, in future, any improved ratio for the general 
might directly hold for the general .}


\section{The Uniform }

Interestingly, the reduction results in the previous section does
not imply that the uniform  reduces to the uniform 
in weakly polynomial time. This is because the instance shrinking
technique may split a uniform instance into two general/non-uniform
instances. As a consequence, the ratio of 1.52 in \cite{Swamy08FTFL2.076}
for the uniform  does not directly hold for the uniform .
Nevertheless, in this section, we show this ratio can still be preserved
for the uniform  in strongly polynomial time with a primal-dual
algorithm and two acceleration heuristics. Note that the following
algorithms are generic which work for the general  as well.
The uniform condition is only necessary in the analysis (Lemma \ref{lem:tri}). 

We begin with a naive primal-dual (PD) algorithm \textcolor{black}{(Algorithm
2)} for  with an approximation ratio of 1.61 and then present
the first acceleration heuristic to improve the complexity of the
algorithm to strongly polynomial \textcolor{black}{.
W.l.o.g., the PD algorithm assumes that each client  makes 
connections and each connection is associated with a }\textit{\textcolor{black}{port}}\textcolor{black}{{}
of  denoted by }\textcolor{black}{{} .
Also, the function  represents
the facility/site a client 's -th port is connected with and
the variable  keeps track of the port of the client  to
be connected. The algorithm then gradually connects clients in the
port order from  to , as well as increasing the solution
 from 
in its }\textit{\textcolor{black}{actions}}\textcolor{black}{{} in response
to some }\textit{\textcolor{black}{events }}\textcolor{black}{controlled
by a global time  that increases monotonically from . All
events }\textit{\textcolor{black}{repeatedly}}\textcolor{black}{{} occur
until all clients are fully-connected, i.e., the not-fully-connected
clients s}et \textcolor{black}{. At any ,
the }\textit{\textcolor{black}{payment}}\textcolor{black}{{} of any
client  to a site  is defined as , and the }\textit{\textcolor{black}{contribution}}\textcolor{black}{{}
is  for the clients in 
and 
for the clients in . As  increases,
the action that a client  connects to a facility of  (
is increased by ) happens under two events: Event 1. 's payment
reaches the connection cost  of an already opened facility
at  that  is not connected to (implying at this time );
Event 2. sum of contributions of all clients to a closed facility
at  reaches its opening cost . In particular, if ,
Event 2 triggers the action that a new facility at  is opened
first ( is increased by 1). Then any client 
with }
will switch one of its most expensive connections from 
to ; and the \textcolor{black}{client in  with
 will connect to . In addition, for analyzing
the approximation ratio of PD, each port }\textcolor{black}{{}
is associated with a dual variable  which is assigned
the time  at which }\textcolor{black}{{} gets
connected. From the algorithm, it should be obvious that .
Note that Event 2 on  stops occurring once  and
this introduces some difficulties to the analysis. To tackle these
difficulties, we use an extra variable  to
store the amounts of the clients' connections when they just become
fully-connected. Compared with the phase-connection approach in \cite{shihongftfa}
in which each phase constructs multiple stars connecting sites and
cities at the same port number in increasing order globally, our algorithm
constructs the most cost efficient star in increasing order of port
number confined within each star.}

\begin{algorithm}[H]
{\small \caption{PD: Primal-Dual Algorithm}
}{\small \par}

\textbf{\textcolor{black}{Input}}\textcolor{black}{: }.\textbf{\textcolor{black}{{}
Output: }}.

\textbf{\textcolor{black}{Initialization}}\textcolor{black}{: }Set
, .

\medskip{}


\textbf{\textcolor{black}{while}}\textcolor{black}{{} ,
increase time  uniformly and execute the events below:} 
\begin{itemize}
\item \textcolor{black}{Event 1: :
 and }.\\
\textcolor{black}{Action 1: }\textbf{\textcolor{black}{set}}\textcolor{black}{{}
}, 
and ; If , then\textbf{
} and
, otherwise .\textcolor{black}{{}
}\smallskip{}

\item \textcolor{black}{Event 2: : }
and .\\
\textcolor{black}{Action 2: }\textbf{\textcolor{black}{set}}\textcolor{black}{{}
}; 
s.t. 
\textbf{set} ,
, 
and ;
 s.t.  \textbf{do}
Action 1.\end{itemize}
\end{algorithm}


\begin{rem} \textcolor{black}{If more than one event happen at time
, the PD algorithm processes all of them in an arbitrary order.}
Also, the events themselves may repeatedly happen at any  because
more than one facilities at a site are allowed to open.\end{rem}
\begin{lemma}
Algorithm PD computes a feasible solution to the uniform  and
runs in .\label{lem:time-PD}\end{lemma}
\begin{proof}
The solution is feasible because 
produced from PD is feasible to LP \eqref{eq:ftra-ip}. Each iteration
of PD at least connects a port of a client, so there are maximum 
iterations. In addition, \textcolor{black}{similar to Theorem 22.4
of \cite{JensVygenFL06Book} and Theorem 8 of \cite{jain01approximation}
for , }the client switching in Action 2 dominates\textcolor{black}{{}
the time complexity. In each iteration, the switching takes time 
to update clients' contributions to other facilities for computing
the anticipated times of the events. Hence, the total time is ,
i.e. .\medskip{}
}
\end{proof}
The PD algorithm produces a feasible primal solution 
to  but an infeasible dual solution 
if we simply let , 
and  in LP \eqref{eq:ftra-dual}. This is because although
the LP's second constraint holds, the first constraint fails to hold
since the algorithm only guarantees \textcolor{black}{:

where .} In order to get around this
feasibility issue, there are ways like the classical dual fitting
\cite{Jain03dualfitting} and inverse dual fitting \cite{shihongftfa}
analyses. However, we observe that these approaches are actually both
based on constraints of the LP. Therefore, in the following we develop
a simple and step-by-step constraint-based analysis for the ease of
handling more complicated dual constructions. Together with the factor-revealing
technique of \cite{Jain03dualfitting}, we derive the ratio of 1.61
for .

In the analysis, first, we use the following dual constructions of
 to bound the primal solution
cost  with the
dual solution cost .


where .

\medskip{}


In this setting, \textcolor{black}{} stores
the primary connection amounts of the clients after they become fully-connected
but before they switch any of their connections. 
 denotes the last port of  \textit{connecting to }
before switching, so  is the dual value of the
port ;  is the dual of 's last port
and  can be interpreted as the conditional marginal dual/price
depending on whether  reaches  or not. 
 is therefore the sum of marginal duals of all clients w.r.t.
. The other dual variable  is to be constructed
later in the analysis.
\begin{lemma}

where  is the feasible
primal solution produced from the PD algorithm and 
is constructed from above. \label{lem: pdb}\end{lemma}
\begin{proof}
{\small 

}{\small \par}

Hence, .
\end{proof}
Second, we exploit the dual constraints of the LP \eqref{eq:ftra-dual}
by relaxing their feasibilities with some relaxation factors. Before
going into this, we have the basic definition below.
\begin{definition}
An algorithm is bi-factor  or single
factor -approximation for ,
iff for every instance  of  and any feasible
solution  (possibly fractional) of  with facility
cost  and connection cost  the total cost produced
from the algorithm is at most  (
are both positive constants greater than or equal to one).
\end{definition}
In the definition, let any feasible solution be ,
then , 
and .
In the following, we consider the feasibility relaxed dual constraints
with the relaxation factors  and :

\medskip{}


(C6) .

(C7) .

\medskip{}


Next, we show that if the dual variables 
satisfies these relaxed constraints, the corresponding dual cost will
be bounded by any feasible primal cost scaled by the factors 
and .
\begin{lemma}
If 
satisfies (C6) and (C7) while 
is any feasible primal solution, then .\label{lem:dual-bound}\end{lemma}
\begin{proof}
Since  is any feasible
solution, all constraints of the LP \eqref{eq:ftra-lp} should hold
first. Together with (C6) and (C7), we have:

{\small 

}{\small \par}
\end{proof}
The previous two lemmas and the definition immediately imply the next
lemma.
\begin{lemma}
The PD Algorithm is -approximation
if 
satisfies (C6) and (C7).\label{lem:appro}
\end{lemma}
In the last step, we show 
indeed satisfies (C6) and (C7), so the algorithm is -approximation.
To satisfy (C6), obviously we can set 
(because ), thereby finishing constructing .
The rest is to find the actual values of the factors  and
 to make (C7) hold as well. The next lemma and corollary
are more specific forms of the previous lemma, after substituting
the setting of 
into (C7).
\begin{lemma}
The PD Algorithm is -approximation
if \linebreak{}

where .\label{lem:s-appro}\end{lemma}
\begin{proof}
After the substitution, (C7) becomes:





.

Therefore, since , it is sufficient to prove 
where 
to satisfy the original (C7).
\end{proof}
If we set ,
then  and we have the corollary below.
\begin{corollary}
W.l.o.g., for every site , order the corresponding 
clients in 
s.t. . Then the PD Algorithm is
-approximation if .
\label{cor:s-appro}
\end{corollary}
In addition, for each , any subset of the clients are ordered
from  to  s.t. . Now,
we proceed the proof to find  and  with the
following lemmas. These lemmas are needed for the factor-revealing
technique and they capture the properties of the PD algorithm for
the uniform .
\begin{lemma}
For every site , at time  
let , then .\label{lem:r}\end{lemma}
\begin{proof}
If , then 
(at time ) . Otherwise,
 implies , so 
is fully-connected at time  since . Therefore,
 because a fully-connected
client's ports always reconnect to the sites with less connection
cost, so its maximum connection cost will never increase. The lemma
follows.\end{proof}
\begin{lemma}
For any site  and ordered  clients, \linebreak{}
.\label{lem:contri}\end{lemma}
\begin{proof}
For any site  and at time , if  client
's contribution is set to be .
In particular, from the previous lemma and the setting of ,
if , it implies  is fully-connected at time
 and the contribution is .
In addition, if  the contribution is .
Note that under this case,  still might be fully-connected at
time , but because  and following the algorithm,
its contribution should not be set to 
for ensuring the lemma. On the other hand, if ,  is
not fully-connected since , so we set the contribution
to , i.e. .
From the execution of the algorithm, at any time, the sum of these
contributions will not exceed the facility's opening cost at site
, hence the lemma follows.\end{proof}
\begin{lemma}
For any site  and clients  s.t. 
, then .\label{lem:tri}\end{lemma}
\begin{proof}
At time  if all facilities at site  are already
open, then  and the lemmas holds. Otherwise, if
not all facilities are open, then at time  every client 
is fully-connected. This is because  implies 
or  at the time . Since  can only connect
to less than  facilities at , this contradicts the condition
 for the setting of , so 
In addition,  itself is not fully-connected at , whereas 
is fully-connected and has already connected to  facilities. There
is at least a facility to which  is connected but not . (This
is where we must enforce all clients have the uniform connection .)
Denote this facility (site) by , we have 
and . Lastly, by the triangle inequality
of the metric property,  and then
we have the lemma.
\end{proof}
{\small 

}Consider the above factor-revealing program series (25) of \cite{Jain03dualfitting}.
If we let ,
from the previous lemmas it is clear that 
and  constitute a feasible solution. Also, from Lemma 5.4
and Theorem 8.3 of \cite{Jain03dualfitting}, and Lemma 4 of \cite{Mohammad06FLP}
we can directly get 
and . Furthermore,
because  and  represents
the size of any subset of the clients, Lemma \ref{lem:time-PD} and
Corollary \ref{cor:s-appro} directly lead to the following theorem.
\begin{theorem}
Algorithm PD is 1.61-, (1.11, 1.78)- and (1,2)-approximation in time
 for the uniform
. \label{thm: multifactor}
\end{theorem}
\begin{algorithm}[H]
\caption{APD: Acceleration of Primal-Dual Algorithm}


\textbf{\textcolor{black}{Input}}\textcolor{black}{: }.\textbf{\textcolor{black}{{}
Output: }}.

\textbf{\textcolor{black}{Initialization}}\textcolor{black}{: S}et
, .

\medskip{}


\textbf{\textcolor{black}{while}}\textcolor{black}{{} ,
increase time  uniformly and execute the events below:} 
\begin{itemize}
\item \textcolor{black}{Event 1: 
s.t.  and }.\\
\textcolor{black}{Action 1-a: };\\
Action 1-b: \textbf{set}  and ;\\
Action 1-c: If  then\textbf{ }.\textcolor{black}{{}
}\medskip{}

\item \textcolor{black}{Event 2:} \textcolor{black}{:
}
and .\\
\textcolor{black}{Action 2-a: }
and ;
\\
Action 2-b: ,

and ; \\
Action 2-c: \textbf{\textcolor{black}{set}}\textcolor{black}{{} }
and ; \\
Action 2-d:  
and ; \\
Action 2-e:  \textbf{do}
Action 1-b; \\
Action 2-f:  \textbf{do}
Action 1-c.
\end{itemize}
\begin{rem} \textcolor{black}{For convenience of analysis, sequential
actions of the events are separated as above. If more than one event
happen at the same time, the algorithm process Event 2 first so that
no repeated events are needed.}\end{rem}
\end{algorithm}


The previous PD algorithm runs in pseudo-polynomial time depending
on . With the acceleration heuristic described in the following,
the algorithm can then change to an essentially identical algorithm
APD (Algorithm 3) which is strongly polynomial. In the heuristic,\textcolor{black}{{}
 is able to increase
at a }faster rate\textcolor{black}{{} }rather than , through combining
the repeated events into a single event to reduce the total number
of events to process and hence achieve fast connections. In particular,
for \textcolor{black}{Event }2, once a facility of a site  is
opened and connected with a group of clients' ports, according to
the PD algorithm, additional facilities at  may subsequently open
and connect with this group of clients' other ports until their sum
of contributions (SOC) becomes insufficient to pay , or .
The SOC is not enough \textcolor{black}{any more if} a client in 
appears to be fully-connected, so 
will decrease, or the most expensive connection of a client in 
differs (after switching all such connections), in this case \footnote{For simplicity of the algorithm description, we replace the term \textcolor{black}{}
in the PD algorithm with essentially the same term here.} will decrease. Similarly, for \textcolor{black}{Event }1, once a
client 's port starts to connect to an already opened facility
at a site , its other ports may get connected to  at the same
time until either there are no remaining open facilities at  or
 reaches  connections. 

Formally in the APD Algorithm,  denotes the number of established
connections of client  and  the total number of connections
decided to make according to the heuristic. The incremental rate of
\textcolor{black}{}
can then be determined by  instead of . Moreover, in the
more complicated Event 2 on a site ,  denotes the maximum
number of connections to make until one of the clients in 
gets fully-connected, and  the maximum number of switches until
the most expensive connection of a client in 
changes. Therefore,  is calculated as ,
the maximum number of connections until the SOC becomes insufficient
or . Similarly, for \textcolor{black}{Event }1, 
is calculated as .
\begin{lemma}
With the acceleration heuristic decided by \textup{}, the numbers
of Event 1 and Event 2 in the APD algorithm are bounded by \textcolor{black}{}
and \textcolor{black}{} respectively
which are independent of .\label{lem:suh}\end{lemma}
\begin{proof}
In the APD algorithm, the number of Event 1 is \textcolor{black}{at
most  because for any client  and site  only
when ,  exhaustively gets connected to open facilities
at site , and there are  sites and  clients in
total. }Moreover, \textcolor{black}{each Event 2 will cause at least
one of the following 3 cases: (1) a client  in }\textcolor{black}{{}
becomes fully-connected; (2) a client  in }\textcolor{black}{{}
switches all of its most expensive connections; (3) a site opens all
its facilities. It is easy to see that there are maximum 
and  cases (1) and (3) respectively, so we are left to bound
the number of case (2). For this case, it is important to observe
that any client  has at most  possible sets of connections
where connections in each set associate to the same site. So there
are at most  such possible sets in total, and each case
(2) removes at least one set of a client with currently most expensive
connection cost, effectively reducing the number of possible sites
for switching, since clients only switch to cheaper connections. Therefore,
there are at most  case (2) and Event 2 is bounded by
.}\end{proof}
\begin{lemma}
Algorithm APD computes a feasible solution to the  and runs
in .\label{lem:time-SPD}\end{lemma}
\begin{proof}
The solution is feasible because APD is essentially the same as the
PD algorithm for  except the implementation of the acceleration
heuristic. In addition,\textcolor{black}{{} }from the previous lemma,
the number of Event 1 is \textcolor{black}{at most ,
so the numbers of both Action 1-a and 1-b are bounded by ,
while Action 1-c is bounded by  since there are  clients
to be connected in total. In addition, the number of Event 2 is bounded
by , so the numbers of Action
2-a, 2-b, 2-c, 2-d and 2-e are bounded by 
while Action 2-f is included in Action 1-c. Although the presented
APD algorithm is continuous on , in real implementation, it can
be easily discretized through finding the the smallest  that satisfy
the conditions of events. Naively, finding such  for Event 1 takes
time , and Event 2 takes time ,
so the algorithm runs in }. However, \textcolor{black}{similar
to Theorem 22.4 of \cite{JensVygenFL06Book} and Theorem 8 of \cite{jain01approximation}
for , we can maintain two heaps to reduce the time to find .
In particular,} each Action 2-d \textcolor{black}{actually requires
extra time  after }the client switchings\textcolor{black}{{}
to change clients' contributions to all facilities. This is for later
eventually updating the anticipated times of the events in the heaps
(that takes time ) following
}each Action \textcolor{black}{1-c. This} action dominates\textcolor{black}{{}
the overall runtime complexity. Hence the total time is .}
\end{proof}
The algorithm computes the same solution as the PD algorithm, so we
have the following theorem.
\begin{theorem}
Algorithm APD is 1.61-, (1.11, 1.78)- and (1,2)-approximation in time
 for the uniform .
\end{theorem}
In order to further achieve the factor of 1.52 in strongly polynomial
time that matches the best result \cite{Swamy08FTFL2.076} for the
uniform , it is necessary to apply the cost scaling and greedy
augmentation (GA) techniques \cite{Swamy08FTFL2.076,Guha03FTFL2.41}
for  to . However, like in \cite{kewen2011cocoon,yan2011approximation},
the difficulty encountered is the application of greedy augmentation
(GA) in polynomial time, since the naive way of treating an 
instance as an equivalent  instance and then directly applying
GA after cost scaling will result in weakly polynomial or pseudo-polynomial
time algorithms, depending on whether using the instance shrinking
technique in the previous section or not. 

\begin{algorithm}[H]
\caption{AGA: Acceleration of Greedy Augmentation}


\textbf{\textcolor{black}{Input}}\textcolor{black}{: }\textcolor{black}{,}\textbf{\textcolor{black}{{}
}}. \textbf{\textcolor{black}{Output:
}}.

\textbf{\textcolor{black}{Initialization}}\textcolor{black}{: }

\textbf{for  }//optimize the total connection cost
first

\qquad{}\textbf{for  }and , in the increasing
order of distances w.r.t 

\qquad{}\qquad{}

\qquad{}\qquad{}

\textbf{set} residual vector 
//for detecting the case  reaches 

\textbf{set} 
as the current total connection cost

\textbf{invoke} calculateGain

\medskip{}


\textbf{while} : //if
, then  from the calculateGain
function

\qquad{}\textbf{pick} 

\qquad{}

\qquad{} 

\qquad{},


\qquad{}\textbf{\textcolor{black}{set}} 

\qquad{} // stores the total decrease
in the connection cost after all switches

\qquad{}\textbf{for }

\qquad{}\qquad{}

\qquad{}\qquad{}\textbf{\textcolor{black}{set}} 
and 

\qquad{}\textbf{\textcolor{black}{set}} 

\qquad{}\textbf{update }

\qquad{}\textbf{invoke} calculateGain

\medskip{}


\textbf{function} calculateGain

\qquad{}\textbf{for }

\qquad{}\qquad{} //for each , 
stores the total connection cost after connections 

\qquad{}\qquad{}are switched to 

\qquad{}\qquad{}

\qquad{}\qquad{}\textbf{if }

\qquad{}\qquad{}\qquad{}\textbf{for }

\qquad{}\qquad{}\qquad{}\qquad{}\textbf{if }

\qquad{}\qquad{}\qquad{}\qquad{}\qquad{}

\qquad{}\qquad{}\qquad{}
\end{algorithm}


Nevertheless, if GA is applied with another similar acceleration heuristic,
it changes to the algorithm AGA\textit{ }(Algorithm 4) which runs
in strongly polynomial time. Before describing AGA, we take a brief
look at GA in \cite{Guha03FTFL2.41} for . It defines 
of a facility  to be the decrease in total cost (decrease in total
connection cost minus increase in facility cost of ) of the solution
after adding a facility  to open and connecting clients to their
closest facilities. Note that once a set of open facilities are fi{}xed,
the total connection cost can be easily computed since every client
simply chooses these facilities in increasing order of distance. GA
then iteratively picks the facility with the largest gain ratio 
to open until there is no facility  with 
left. On the other hand, AGA computes  in the
same way as GA. The difference is in  there are \textcolor{black}{
facilities in total, therefore it is slow to consider one facility
at a time (in each iteration of AGA). Fortunately, there is also an
acceleration heuristic: because all facilities at a site  has
, once a facility at site  with} \textcolor{black}{{}
is selected to open, additional facilities at  may also open
at the same time until either (1) this maximum} \textcolor{black}{}
reduces due to insufficient decrease in the total connection cost;
or (2)  reaches . Moreover, (1) \textcolor{black}{happens
once a client has appeared to switch all of its most expensive connections
to , which is similar to the switching case in the previous
algorithm APD.}

Formally in the AGA algorithm,  denotes the current total connection
cost and  the connection cost after  is opened and client
connections are switched. The calculateGain function computes 
and the while loop implements GA with the described heuristic. In
each loop iteration, for updating ,  stores the total
decrease in the connection cost after client switching. Following
the heuristic,  and  are defined similarly as in the APD
algorithm. Note that in the initialization phase of AGA, the total
connection cost is optimized first so that every client connects to
its closest facilities. This is to ensure that in every iteration
only the client connections with the largest costs need to be considered
in computing the best possible connection cost .
\begin{lemma}
Algorithm AGA runs in  for .\label{lem:time-GA}\end{lemma}
\begin{proof}
Each iteration of the while loop runs in 
due to the calculateGain function. Now, we bound the the total number
of iterations. Similar to the acceleration heuristic analysis of the
algorithm APD (c.f. Lemma \ref{lem:suh}), in AGA once a site 
with the maximum gain is chosen, AGA opens the facilities at 
until either  is reached, or \textcolor{black}{a client
has appeared to switch all of its most expensive connections, causing
reduced maximum gain. Further, there are at most  chances
to reach }\textcolor{black}{{} and  possible
sets of connections for all clients. Since clients also only switch
to cheaper connections, there are maximum 
iterations.} The total time is therefore .
\end{proof}
Now the important observation/trick for the analysis is that applying
AGA to an  instance (with solution) obtains essentially
the \textit{same solution} (also the same cost) as treating this instance
as an equivalent  instance (by naively splitting sites) and
then directly applying GA. The difference is, with the acceleration
heuristic, AGA is able to arrive at this solution faster, in strongly
polynomial time. The observation then implies that AGA alone improves
the 3.16-approximation result of \cite{yan2011approximation} for
the general  to 2.408 in polynomial time using the
GA results \cite{Guha03FTFL2.41} for . Similarly, for the
uniform , AGA combined with cost scaling further improves on
the (1.11, 1.78)-approximation algorithm APD according to the results
of \cite{Swamy08FTFL2.076} for the uniform .
\begin{theorem}
The uniform  can be approximated with a factor of 1.52 in time
. \label{thm:1.52uniform}
\end{theorem}

\section{The Uniform -}

Lastly, we consider the Constrained Fault-Tolerant -Resource Allocation
(-) problem and show its uniform case achieves an approximation
ratio of 4. In this important variant of , there is an additional
constraint that at most  facilities (
and ) across all sites can be opened
as resources. This problem has the following formulation.

\textit{

}

Its LP-relaxation (primal LP) and dual LP are:

\textit{

}




It is clear that - generalizes the well studied -
\cite{jain01approximation,Jain03dualfitting} and - \cite{Swamy08FTFL2.076}
problems. In the following, besides adapting the algorithms and analyses
therein, we also develop a greedy pairing (GP) procedure which in
polynomial time constructs paired and unpaired sets of facilities
from sites for randomly opening them afterwards.

\textbf{Algorithm Description. }The algorithm PK (Algorithm 5) consists
of three sequential procedures: Binary Search (BS), Greedy Pairing
(GP) and Randomized Rounding (RR). BS utilizes the previous -approximation
algorithm APD (Algorithm 3) for  with the \textit{modified}
input facility cost , i.e. the cost is
increased by  first and then scaled by . As we will see
later in the analysis, this modification is necessary for two reasons:
1) the Lagrangian relaxation of - is ; 2) the scaling
of the facility cost enables us to build on the approximation ratio
 of  for getting the ratio of -.
For simplicity, let APD denote the
parameterized APD algorithm with the input facility cost perturbing
factor  and scaling factor , so APD
produces the same solution as APD. From LP \eqref{eq:ftra-ip} and
\eqref{eq:kftra-ip}, it is clear that APD produces an almost feasible
integral solution to - except that it has to guarantee
at most  facilities to open ()
from all sites. This guarantee might not be even possible, but fortunately
we can use APD to get two solutions
 and 
with the small one having 
and the large one  facilities
open. A convex combination of these two solutions is able to give
a feasible \textit{fractional} solution 
to - instead, i.e. 
with  and . The solutions can be obtained
by binary searching two values ( and ) of
 over the interval 
where  and
invoking APD and APD.
This specific interval is chosen because as the value of 
increases, the number of open facilities from APD
will decrease. So if , the algorithm
will only open the minimum number of 
facilities.\footnote{We noticed that the binary search interval 
(c.f. the third paragraph of Section 7 of \cite{Swamy08FTFL2.076})
for - can be reduced to ,
because once the minimum number of 
facilities are opened and all facility costs are at least ,
from the primal-dual algorithm, all clients are already fully-connected.} Moreover, as shown later, if  and  become
sufficiently close ( where 
is the smallest positive connection cost and 
\footnote{The algorithm analysis also holds if .}) in BS, the approximation ratio of APD is almost preserved for building
a ratio for -.

\begin{algorithm}
\caption{PK: Procedures for -}


\textbf{\textcolor{black}{Input}}\textcolor{black}{: }A -
instance \textcolor{black}{.}\textbf{\textcolor{black}{{}
Output: }}

\textbf{\textcolor{black}{Initialization}}\textcolor{black}{:} 

\textbf{\textcolor{black}{Procedure 1}}\textcolor{black}{: }Binary
Search (BS)



\textbf{\textcolor{black}{while}}\textcolor{black}{{} 
}\textbf{\textcolor{black}{do}}\textcolor{black}{:}

\qquad{}

\qquad{}\textbf{invoke} APD with 
and output 

\qquad{}

\qquad{}\textbf{if }

\qquad{}\qquad{}\textbf{set }

\qquad{}\textbf{else if }

\qquad{}\qquad{}\textbf{set }

\qquad{}\textbf{else}

\qquad{}\qquad{}\textbf{return  }//if here reached, all procedures
afterwards can be safely ignored

\textbf{invoke} APD with 
and output 

\textbf{invoke} APD with 
and output 

 and 

\medskip{}


\textbf{\textcolor{black}{Procedure 2}}\textcolor{black}{: Greedy
Pairing (GP)}

//vectors representing numbers of constructed paired and unpaired
facilities in 

\textbf{set} ,  

\textbf{for }

\qquad{}if  and 

\qquad{}\qquad{}

\qquad{}\qquad{}//updating vectors and store them in 
and  for the next pairing steps

\qquad{}\qquad{}

\qquad{}\qquad{}

\textbf{for  }in arbitrary order

\qquad{}\textbf{if} 

\qquad{}\qquad{}\textbf{for  }in
the order of closest to 

\qquad{}\qquad{}\qquad{}\textbf{if} 

\qquad{}\qquad{}\qquad{}\qquad{}

\qquad{}\qquad{}\qquad{}\qquad{}

\qquad{}\qquad{}\qquad{}\qquad{}


//at this time  and 

\medskip{}


\textbf{\textcolor{black}{Procedure }}\textcolor{black}{3: Randomized
Rounding (RR)}

\textbf{choose }probabilities  and
 so  and 

\textbf{set}  with probability
 and  with probability
 //disjoint cases both open  facilities

\textbf{select }a random subset of  facilities to open from
 and add these to  //at
this time  and each facility in 
is opened with probability 

//connects each client  to its closest  opened facilities

\textbf{for }

\qquad{}\textbf{for  }in the order of closest to


\qquad{}\qquad{}

\qquad{}\qquad{}
\end{algorithm}


However, for a feasible \textit{integral} solution 
with  open facilities, the algorithm instead relies on our\textit{
efficient} GP and RR procedures. These procedures extend the matching
and rounding procedures (cf. the paragraph before Lemma 7.1 in \cite{Swamy08FTFL2.076})
for - respectively. In particular, based on the solution
vectors  and  obtained from
BS, GP splits the vector  into 
and  s.t. 
and .
Note that each of these integral vectors represents the facility opening
amounts of all sites. To be precise, GP greedily constructs the paired
() and unpaired facilities ()
from  against the small solution .
It first pairs the facilities of the corresponding sites in 
and  (both sites with open facilities) and records
the pairing result in . Next, for each left unpaired
site  in  in arbitrary order, GP
exhaustively pairs the facilities at  with the facilities of the
unpaired sites in  in the order of closest
to . In this pairing step,  is updated accordingly.
At the end,  is simply set to be .
To be more precise, we consider a simple example with 
and  from BS before
running GP. After the first pairing step, ,
 and .
Now for simplicity, we assume that the distance between sites 
and  is  where we follow the ascending order
of indices 's in resolving the ties of the closest distances.
Therefore, after the second step, ,
 and ,
since both the unpaired  and  (1-based
index) are paired to the closest unpaired .

From the ,  and 
obtained, the last procedure RR then randomly opens  facilities
in a way that the expected facility opening cost of 
is the \textit{same} as the facility opening cost of the convex combination
solution . In addition, RR connects each client
 to its closest  open facilities in ,
ensuring the expected connection cost of  is\textit{
bounded} by the connection cost of .

\textbf{Algorithm Analysis. }The basic idea of the analysis is to
first bound 
by 
where 
is a constructed feasible dual solution to LP \eqref{eq:kftra-dual}.
Then we bound the expected total cost 
with  to further
establish the approximation ratio  s.t. .
Finally, by the weak duality theorem, 
where 
is the optimal fractional solution to - (displayed as LP
\eqref{eq:kftra-lp}).

In the first step, we focus on analyzing the BS procedure to bound
 by .
Suppose APD produces the primal solution
 with
 open facilities. We let the cost of 
w.r.t. the \textit{original} input instance be ,
where in the separate costs ,
 is the total
facility cost and 
is the connection cost. Similarly, w.r.t. the modified instance, the
cost is .
From the analysis (cf. the paragraph before Theorem \ref{thm: multifactor})
of the factor revealing program of the PD algorithm, for APD,
we get 
where , i.e.,


 

where 
is the corresponding constructed dual values of 
from the PD algorithm. Further, from Lemma \ref{lem: pdb}, we have
a bound for ,
i.e.,



Note that the dual solution 
is used only in the analysis. Also, because APD only speeds up PD
by combining its events, we can use the dual solution produced from
PD for analyzing APD. If we set 
and ,
the inequality (7) then becomes ,
implying 
is a feasible dual solution to LP \eqref{eq:kftra-dual}. Furthermore,
(8) becomes


The analysis here reveals the Lagrangian relation between -
and  from the dual perspective, whereas the Lagrangian relaxation
framework (cf. Section 3.6 of \cite{jain01approximation}) starts
from the primal. Therefore, if , 
is 2-approximation from the inequality (9), the bound 
and the feasibilities of 
and .
However, as mentioned before, we may never encounter the situation
. Instead, the BS procedure finds 
and  until .
It then runs APD to obtain the solution
 with 
and the cost  w.r.t. the original instance;
and APD to get the solution 
with  and . Hence, from (9)
we have




and




where 
and 
are constructed as 
to be feasible duals.

Now we are ready to bound 
by .
The proof of the following lemma builds on the idea of Lemma 9 in
\cite{jain01approximation} for -median.
\begin{lemma}
\textup{,}
where ,\textup{ ,
 ,
},
,
,
 and .
Moreover, 
is a feasible dual solution to the - problem.\label{lem:1bound}\end{lemma}
\begin{proof}
From the constructions of 
and ,
we get 
and ,
then 
after multiplying the first inequality by , the second by 
and adding them together. In addition, with the setting ,
we get the feasibility of 
to LP \eqref{eq:kftra-dual}. Next, we aim to derive the following
bound 

 

from the inequality (10). For now, suppose this bound holds, from
(11), we have


After multiplying (12) by , (13) by  and adding them together,
we get 


This then yields the lemma together with the feasibility of 
and . The
last thing left is to verify in the following that (12) indeed holds
from the inequality (10), the termination condition of the algorithm
 and the
fact that .




For simplicity, let .
Because  and , we get .
Hence, the inequality (12) is verified.
\end{proof}
For runtime, our BS procedure totally makes 
probes ( is the number of bits of the input costs) over the interval
 until the interval becomes
the size of . Moreover, each probe takes
 to invoke the APD algorithm, so the total
time is  which dominates
the overall runtime of the algorithm PK.

In the next step, we focus on analyzing the GP and RR procedures to
bound  with
 where
we denote  and  as the expected total facility and connection
costs respectively from the randomized procedure RR. This procedure
can also be derandomized using the method of conditional expectation
as in \cite{jain01approximation} for the -median problem. In
the following, we bound  with  and  with  separately.
With probability 1, RR opens exactly  facilities. Specifically,
it randomly opens each facility in  with probability
, and each facility in  with probability
 which is also . Since GP properly
splits the vector  into 
and  s.t. ,
we can conclude that each facility in  is opened
with probability . In addition, RR randomly opens each facility
in  with probability , therefore the total
expected opening cost is  which is .
\begin{lemma}
The total expected facility opening cost  satisfies .
\end{lemma}


Now we bound  with . Suppose two  instances with the
solutions 
and  are produced
from the BS procedure. Afterwards, for getting a feasible solution
to - from these solutions, instead we consider a naive
pseudo-polynomial time algorithm. The algorithm first treats the 
instances with the solutions 
and  as equivalent
 instances (by naively splitting sites and keeping the clients
unchanged) with the transformed solutions 
and \footnote{W.l.o.g., the solutions can be easily transformed between 
and  as shown in Theorem 7 of \cite{kewen2011cocoon}. } respectively. Then, it uses the matching and rounding procedures
\cite{Swamy08FTFL2.076} on 
and 
to get a feasible solution 
to -. Finally, the solution 
can be easily transformed to a feasible solution 
to -. Now, the important observation is that directly applying
GP and RR to these  instances with the solutions 
and  from BS
obtains essentially the \textit{same solution} 
(also the same cost) to - as the naive algorithm does.
It is mainly because for the  instances of size ,
our designed GP procedure pairs the integer vectors in polynomial
time. This is the acceleration of the matching procedure therein \cite{Swamy08FTFL2.076}
applied to the equivalent  instances of size .
Therefore, \textit{only in the analysis}, we can consider the naive
algorithm instead to get the following bound for . This analysis
trick is similar to the trick used for analyzing the algorithm AGA
(cf. the paragraph before Theorem \ref{thm:1.52uniform}).
\begin{lemma}
The total expected connection cost  satisfies .\end{lemma}
\begin{proof}
For the equivalent  instances, we let  be
the set of split facilities with size 
and use  to index these facilities. After the matching and rounding
procedures in \cite{Swamy08FTFL2.076} on the transformed solutions

and ,
we get the solution 
to -. Also from its Lemma 7.2, we can directly obtain the
bound \footnote{Note that from proof of the lemma therein, we can easily get the bound
coefficient  rather than .} where , i.e.
the expected connection cost of any client . Since ,

and  are transformed
from , 
and 
respectively with the same costs, we have

which concludes the lemma.
\end{proof}
Adding up the separate bounds in the previous two lemmas, we get .
Relating this bound to the bound 
in Lemma \ref{lem:1bound}, we obtain


The last inequality is from the fact that 
(achieved when  and ), and 
(achieved when  and ). Therefore, 
and .
By the weak duality theorem, the approximation ratio is 4. For runtime,
from the algorithm PK, both GP and RR take . 
\begin{theorem}
Algorithm PK is 4-approximation for the uniform - in polynomial
time .
\end{theorem}

\section{Concluding Remarks}

In this paper, we studied the Constrained Fault-Tolerant Resource
Allocation () problem and its important variant Constrained
Fault-Tolerant -Resource Allocation (-) problem. In
particular, although  generalizes the classical Fault-Tolerant
Facility Location () problem, we have shown that it can achieve
the same approximation ratios as , for the general and the
uniform cases respectively. 

From the practical side, our developed resource allocation models
inherited from  and  are more general and applicable
for optimizing the performances of many contemporary distributed systems.
Therefore, in future, it is worth looking at these models' other important
variants such as the capacitated variant in \cite{kewen2011cocoon},
the Reliable Resource Allocation () problem in \cite{kewen2012cats}
and etc. From the theoretical side, two grand challenges on the classical
problems still remain today: 1) close the approximation gap between
 (1.7245) and  (1.488) or show  is more difficult
than ; 2) reduce the ratio of 1.488 to the established lower
bound 1.463 for .

\section*{Acknowledgement} This research was partially supported by Australian Research Council Discovery Project grant \#DP0985063, National Science Foundation of China under its General Projects funding \#61170232 and Research Initiative Grant of Sun Yat-sen University.

\bibliographystyle{plain} \bibliographystyle{plain}
\bibliography{facilityLocation_new}

\end{document}
