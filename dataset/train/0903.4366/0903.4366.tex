A program is productive if it evaluates to a finite or infinite constructor normal form.
This rather vague description leaves open several choices 
that can be made to obtain a more formal definition. 
We explore several definitions and determine the degree of undecidability for each of them.
See~\cite{endr:grab:hend:isih:klop:2007}
for more pointers to the literature on productivity.

The following is a productive specification of the (infinite) stream of zeros:

Indeed, there exists only one maximal 
rewrite sequence from  and this ends in the infinite constructor normal form 
.
Here and later we say that a rewrite sequence  
\emph{ends in} a term  if either  is finite with its last term being ,
or  is infinite and then  is the limit of the sequence of terms~, i.e.\
.
We consider only rewrite sequences starting from finite terms, thus all
terms occurring in  are finite. Nevertheless, the limit  of the terms 
may be an infinite term.
Note that, if  ends in a constructor normal form, 
then every finite prefix will be evaluated after finitely many steps.

The following is a slightly modified specification of the stream of zeros:

This specification is considered productive as well,
although there are infinite rewrite sequences that do not even end in a normal form,
let alone in a constructor normal form: e.g.\ by 
unfolding  only we get the limit term 
.
In general, normal forms can only be reached by outermost-fair rewriting sequences.
A rewrite sequence  is \emph{outermost-fair}~\cite{terese:2003}
if there is no  containing an outermost redex which remains an outermost redex infinitely long,
and which is never contracted.
For this reason it is natural to consider productivity of terms with respect to outermost-fair strategies.

What about stream specifications that admit rewrite sequences to constructor normal forms, 
but that also have divergent rewrite sequences:

This example illustrates that, for non-orthogonal stream specifications,
reachability of a constructor normal form depends on the evaluation strategy.
The term  is only productive
with respect to strategies that always apply the first rule.

For this reason we propose to think of productivity as
a property of individual terms 
\emph{with respect to} a given rewrite strategy.
This reflects the situation in functional programming,
where expressions are evaluated according to an inbuilt strategy.
These strategies are usually based on a form of outermost-needed rewriting 
with a priority order on the rules.


\subsection{Productivity with respect to Strategies}
  \label{sec:productivity:subsec:strategies}

For term rewriting systems (TRSs) \cite{terese:2003}
we now fix definitions of the notions of 
(history-free) strategy and history-aware strategy.
Examples for the latter notion are outermost-fair strategies,
which typically have to take history into account.


\begin{definition}\normalfont
Let  be a TRS with rewrite relation .

  A \emph{strategy for } is a relation 
   with the same normal forms
  as .

  The \emph{history-aware rewrite relation  for }
  is the binary relation on  
  that is defined by:

We identify  with ,
  and for  we write  
  whenever  for some history .
A \emph{history-aware strategy for } is a strategy for
  .

  A strategy  is \emph{deterministic} if 
   and  implies . 
  A strategy  is \emph{computable} if the function mapping
  a term (a term/history pair) to its set of -successors
  is a total recursive function, after coding into natural numbers. 
\end{definition}

\begin{remark}
Our definition of strategy for a rewrite relation
  follows \cite{toya:1992}.
  For abstract rewriting systems, 
  in which rewrite steps are first-class citizens,
  a definition of strategy is given in \cite[Ch.\,9]{terese:2003}.
  There, history-aware strategies for a TRS~ are defined in terms of 
  `labellings' for the `abstract rewriting system' underlying .
  While that approach is conceptually advantageous, our definition
  of history-aware strategy is equally expressive.  
\end{remark}

\begin{definition}\normalfont
A \emph{(TRS-indexed) family of strategies } 
  is a function that assigns to every TRS  
  a set   of strategies for .
We call such a family  of strategies \emph{admissible} 
  if  
  is non-empty for every orthogonal TRS .
\end{definition}

\newcommand{\strategy}{\leadsto}

Now we give the definition of productivity with respect to a strategy.
\begin{definition}\normalfont\label{def:productivity}
  A term  is called \emph{productive with respect to a strategy }
  if all maximal  rewrite sequences starting from  end in a constructor normal form.
\end{definition}
In the case of non-deterministic strategies we require here that all maximal rewrite sequences end in a constructor normal form.
Another possible choice could be to require only the existence of 
one such rewrite sequence (see Section~\ref{sec:productivity:subsec:strong}).
However, we think that productivity should be a practical notion.
Productivity of a term should entail that arbitrary finite parts of the constructor normal form can indeed be evaluated.
The mere requirement that a constructor normal form exists
leaves open the possibility that such a normal form 
cannot be approximated to every finite precision in a computable way.

For orthogonal TRSs outermost-fair (or fair) rewrite strategies
are the natural choice for investigating productivity
because
they guarantee to find (the unique) infinitary constructor normal form whenever it exists (see~\cite{terese:2003}).

Pairs and finite lists of natural numbers can be encoded using the well-known G\"{o}del encoding.
Likewise terms and finite TRSs over a countable set of variables
can be encoded.
A TRS is called \emph{finite} if its signature and set of rules
are finite.
In the sequel we restrict to (families of) computable strategies,
and assume that strategies are represented by
appropriate encodings.

Now we define the productivity problem in TRSs with respect to families
of computable strategies, and prove a -completeness result.


\paragraph{\textsc{Productivity Problem} \normalfont 
  with respect to a family  of computable strategies}\ 

\emph{Instance}:
  Encodings of a finite TRS , 
  a strategy  
  and a term .

\emph{Answer}:
  `Yes' if  is productive with respect to . 

\begin{theorem}\label{thm:strategy}
  For every family of admissible, computable strategies ,
  the productivity problem with respect to  
  is -complete.
\end{theorem}

\begin{proof}{
  \newcommand{\from}{\funap{\msf{from}}}
  \newcommand{\run}{\funap{\msf{M}}}
  A (deterministic) Turing machine is called \emph{total} (encodes a total function ) 
  if it halts on all inputs encoding natural numbers.
  The problem of deciding whether a deterministic Turing machine is \emph{total} is well-known to be -complete, see~\cite{hinman:1978}.
  Let  be an arbitrary Turing machine.
  Employing the encoding of deterministic Turing machines into orthogonal TRSs from~\cite{jw:handbook},
  we can define a TRS  that simulates  such that
  for every  it holds:
  every reduct of the term  contains at most one redex occurrence,
  and the term  rewrites to  
  if and only if the Turing machine  halts on the input .
  Note that the rewrite sequence starting from  is deterministic.
  We extend the TRS  to a TRS  with the following rule:

and choose the term .
  Then  is orthogonal and 
  by construction every reduct of  contains at most one redex occurrence
  (consequently all strategies for  coincide on every reduct of ).
  The term  is productive
  if and only if
   rewrites to  for every 
  which in turn holds if and only if
  the Turing machine  is total.
  This concludes -hardness.

  For -completeness let  be a family of computable strategies,
   a TRS,~ and  a term. 
  Then productivity of  can be characterised as:
-0.5ex]
      &\text{is a constructor normal form up to depth }
\end{aligned}

  \tfunap{\msf{run}}{\tmT}{\picknok{x}}{\picknok{y}} \to \tfunap{\msf{run}}{\bfunap{\tm}{x}{y}}{\picknok{y}}{\pickn}

\pickn &\to \fc{\pickn} &\quad
\pickn &\to \picknok{\tmzer{\tmiblank}} &\quad
\fc{\picknok{x}} &\to \picknok{\fs{x}}\punc.

  \random &\to \strcns{0}{\random} &
  \random &\to \strcns{1}{\random}

Every rewrite sequence starting from  ends in a normal form. 
However, these normal forms are not unique. In fact, there are uncountably many of them.
We did not include uniqueness of normal forms
into the definition of productivity since
non-uniqueness only arises in non-orthogonal TRSs 
when using non-deterministic strategies.
However, one might want to require uniqueness of normal forms even in the case of non-orthogonal TRSs.

\begin{theorem}\label{thm:unique}
The problem of determining, for TRSs~ and terms  in , 
  whether  has a unique (finite or infinite) normal form 
  is -complete.
\end{theorem}

\begin{proof}
  For -hardness, we extend the TRS constructed in the proof of Theorem~\ref{thm:weak} by the rules:
  ,
  ,
  , and
  .
  Then  has a unique normal form 
  if and only if  is well-founded.
  For -completeness, we observe that
  the property can be characterised by a -formula:
  we quantify over two infinite rewrite sequences, 
  and, in case both of them end in a normal form, we compare them.
  Note that consecutive universal quantifiers can be compressed into one. \qed
\end{proof}

Let us consider the impact on computational complexity 
of taking up the condition of uniqueness of normal forms
into the definition of productivity.
Including uniqueness of normal forms without considering the strategy
would increase the complexity of productivity with respect to a family of strategies to .
However, we think that doing so would be contrary to the spirit 
of the notion of productivity.
Uniqueness of normal forms should only be required 
for the normal forms
reachable by the given (non-deterministic) strategy.
But then the complexity of productivity remains unchanged,
-complete.
The complexity of strong productivity
remains unaltered, -complete,
when including uniqueness of normal forms.
However, the degree of undecidability of weak productivity increases.
From the proofs of Theorems~\ref{thm:weak} and~\ref{thm:unique}
it follows that the property would then both be
-hard and -hard,
then being in .

