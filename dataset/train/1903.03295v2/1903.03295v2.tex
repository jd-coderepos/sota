The anomalous human-related events in a surveillance video scene can
be identified by the irregular human movement patterns observed in
the video. Our method detects those anomalies by learning a regularity
model of the dynamic skeleton features found in training videos. We
assume the skeleton trajectories have already been extracted from
the videos. At each time step , a skeleton is represented by a
set of joint locations in image coordinates ,
where  is the number of skeleton joints. This set of temporal
sequences is the input to our anomaly detection algorithm.

\subsection{Skeleton Motion Decomposition\label{subsec:Skeleton-Motion-Decomposition}}

\begin{figure}[h]
\begin{centering}
\includegraphics[width=0.95\columnwidth]{images/global_local_decomposition}
\par\end{centering}
\caption{Global and local decomposition of a skeleton in a frame. Based on
the canonical local reference frame defined by the green bounding
box, the location vector of the left knee joint (dashed red)
is decomposed into global (dashed blue) and local 
(dashed green) components. The bounding box's width and height are
included as global features and used to normalize local features.}

\label{fig:global_local_decomposition}
\end{figure}
Naturally, human motion consists of two factors: rigid movement of
the whole body and non-rigid deformation of the skeleton joints. The
simplest way to model human motion using a recurrent network is by
feeding it the raw sequence of skeleton trajectories in image coordinates
 \cite{fragkiadaki2015recurrent,villegas2017learning},
implicitly merging the global and local factors together. This solution
performs well in videos with uniform skeleton scales and types of
activities where the contribution of the two factors is consistent.
On realistic surveillance videos, however, the scales of human skeletons
vary largely depending on their location and actions. For skeletons
in the near field, the observed motion is mainly influenced by the
local factor. Meanwhile, for skeletons in the far field, the motion
is dominated by the global movement while local deformation is mostly
ignored. 

Inspired by the natural composition of human skeleton motion and motivated
by the factorization models widely used in statistical modeling, we
propose to decompose the skeletal motion into ``global'' and ``local''
components. The global component carries information about the shape,
size and rigid movement of the human bounding box. The local component
models the internal deformation of the skeleton and ignores the skeleton's
absolute position in relation to the environment. 

Geometrically, we set a canonical reference frame attached to the
human body (called \emph{local frame}), which is rooted at the center
of the skeleton's bounding box. The global component is defined as
the absolute location of the local frame center within the original
image frame. On the other hand, the local component is defined as
the residue after subtracting the global component from the original
motion. It represents the relative position of skeleton joints with
respect to the bounding box. This decomposition is illustrated in
Figure~\ref{fig:global_local_decomposition} and can be written in
2D vector space as: 


In 2D image space, xy-coordinates alone poorly represent the real
location in the scene because the depth is missing. However, the size
of a skeleton's bounding box is correlated with the skeleton's depth
in the scene. To bridge this gap, we augment the global component
with the width and height of the skeleton's bounding box 
and use them to normalize the local component .
These features can be calculated from the input features as:

 

The global and local dynamics can be modeled separately as two concurrent
sub-processes. In generic videos, these two processes can even manifest
independently. For example, a person can move her limbs around while
keeping her global location relatively still. Similarly, a person
riding a motorbike can move around while having a relatively fixed
pose. However, given a specific context, regular human activities
contain a strong correlation between these two components. Therefore
breaking the cross-component correlation is also a sign of abnormality.
In the previous examples, if those actions occurred in the scene where
people were normally walking, they would be valid anomaly events.
In the next section, we present how both individual dynamic patterns
and the relationship between these two components are modeled in our
MPED-RNN model.
\begin{center}
\begin{figure*}[h]
\centering{}\includegraphics[width=0.95\textwidth]{images/mped-rnn}\caption{MPED-RNN consists of two interacting branches for two skeleton feature
components. The local branch is drawn in green with shaded GRU blocks
and the global branch is drawn in blue with transparent GRU blocks.
The two components interact through messages (purple dashed) exchanged
between the branches. The outputs are generated by a set of MLPs,
represented by black rectangles.\label{fig:comprae_architecture}}
\end{figure*}
\par\end{center}

\subsection{MPED-RNN Architecture}

MPED-RNN models the global and local components as two interacting
sub-processes where the internal state of one process is used as extra
features to the input of the other process. More specifically, the
model consists of two recurrent encoder-decoder network branches,
each of them dedicated to one of the components. Each branch of the
model has the single-encoder-dual-decoder architecture with three
RNNs: Encoder, Reconstructing Decoder and Predicting Decoder. This
structure is similar to the composite LSTM autoencoder (LSTM AE) of
Srivastava \etal \cite{srivastava2015unsupervised}. However, unlike
LSTM AE, MPED-RNN does not only model the dynamics of each individual
component, but also the interdependencies between them through a cross-branch
message-passing mechanism. We use Gated Recurrent Units (GRU) \cite{cho2014learning}
in every segment of MPED-RNN for its simplicity and similar performance
to LSTM \cite{greff2017lstm}. At each time step, the GRU unit of
one branch receives a message from the other branch informing its
internal state at the previous time step. This message is incorporated
into the GRU structure by treating it as an additional input. The
same procedure is applied to the other branch. MPED-RNN's architecture
is depicted in Figure~\ref{fig:comprae_architecture}.

Given an input skeleton segment of length , we first initialize
the hidden states of all the GRUs to null. Then, for each time step
, the skeleton  is decomposed into  and 
(using Eqs.~(\ref{eq:decompose_vector}), (\ref{eq:decompose_global})
and (\ref{eq:decompose_local})), which are input to the global encoder
() and to the local encoder (), respectively. The
messages to be exchanged between the global and local branches are
computed as specified by Eqs. \ref{eq:msg_local_to_global} and \ref{eq:msg_global_to_local}
below.


For , the global and local segments are encoded using
Eqs. \ref{eq:global_enc} and \ref{eq:local_enc}: 


After encoding the input segments, the global and local Reconstructing
Decoders initialize their hidden states as 
and , respectively, and for ,
we have:


Similarly, the global and local Predicting Decoders initialize their
hidden states as  and ,
respectively, and for , we have:


In training, the dual decoders in the MPED-RNN's architecture jointly
enforce the encoder to learn a compact representation rich enough
to reconstruct its own input and predict the unseen future. Meanwhile,
in testing, the abnormal patterns cannot be properly predicted because
they were neither seen before nor follow the normal dynamics.

In each decoder network, the projected features of the corresponding
decoders,  and , are independently
generated from the hidden states  and  by
fully-connected layers. These two projected features are concatenated
and input to another fully-connected layer, which generates the projected
perceptual feature  in the original image space. Ideally,
 can be calculated from  and 
by inverting Eqs.~(\ref{eq:decompose_global}) and (\ref{eq:decompose_local}).
However, by being projections into low-dimensional subspaces, a direct
computation is unlikely to be optimal. Thus, using a fully-connected
layer to learn the inverse mapping allows the computation to be robust
to noise. These projected features are used to evaluate the conformity
of an input sequence of skeletons to the learned normal behavior and
hence are used to build the loss function for training and score function
for testing. These procedures are detailed next.

\subsection{Training MPED-RNN\label{subsec:Training-MPED-RNN}}

\paragraph*{Training setup}

The trajectory of a person can span many frames in a video. However,
recurrent networks are trained on fixed-size sequences. To cope with
this issue, we extract fixed-size segments from every skeleton's trajectory
using a sliding-window strategy. Therefore, each segment is computed
as:

where  and  are beginning and ending indices of the
-th segment calculated from the chosen sliding stride  and
segment length :


During training, batches of training segments are decomposed into
global and local features, which are input to MPED-RNN. 

\paragraph*{Loss functions}

We consider three loss functions defined in three related coordinate
frames. The Perceptual loss  constrains MPED-RNN to produce
the normal sequences in the image coordinate system. The Global loss
 and the Local loss  act as regularization terms that
enforce that each encoder-decoder branch of MPED-RNN work as designed.
Each of the losses includes the mean squared error made by the reconstructing
and predicting decoders:

where  denotes the prediction length and  represents one of
,  or . In case of  notice that it makes 
equal to  of Section \ref{subsec:Skeleton-Motion-Decomposition}.
The prediction loss is truncated if the end of trajectory is reached
within the prediction length.

The three losses contribute to the combined loss by a weighted sum:

where 
are corresponding weights to the losses. 

In training, we minimize the combined loss in Eq.~(\ref{eq:loss})
by optimizing the parameters of GRU cells of the RNN networks, message
building transformations in Eqs. \ref{eq:msg_local_to_global} and
\ref{eq:msg_global_to_local}, and the output MLPs. 

\paragraph*{Model regularization}

When training autoencoder style models for anomaly detection, a major
challenge is that even if the model learns to generate normal data
perfectly, there is still no guarantee that the model will produce
high errors for abnormal sequences \cite{liu2018anopred}. In training
MPED-RNN, we address this challenge by empirically searching for the
smallest latent space that still adequately covers the normal patterns
so that outliers fall outside the manifold represented by this subspace.

We implement this intuition by splitting the normal trajectories into
training and validation subsets, and use them to regularize the network's
hyperparameters that govern the capacity of the model (\eg number
of hidden units). More specifically, we train a high capacity network
and record the lowest loss on the validation set. The validation set
is also used for early stopping. Then, we train a network with lower
capacity and record the lowest loss on the validation set again. We
repeat this procedure until we find the network with the smallest
capacity that is still within 5\% of the initial validation loss attained
by the high capacity network.

\subsection{Detecting Video Anomalies}

To estimate the anomaly score of each frame in a video, we follow
a four-step algorithm:
\begin{enumerate}
\item \emph{Extract segments}: With each trajectory, we select the overlapping
skeleton segments by using a sliding window of size  and stride
 on the trajectory, similar to Eqs.~(\ref{eq:sliding_window})
and (\ref{eq:window_ends}). 
\item \emph{Estimate segment losses}: We decompose the segment using Eq.~(\ref{eq:decompose_vector})
and feed all segment features to the trained MPED-RNN, which outputs
the normality loss as in Eq.~(\ref{eq:loss}).
\item \emph{Gather skeleton anomaly score: }To measure the conformity of
a sequence to the model given both the past and future context, we
propose a voting scheme to gather the losses of related segments into
an anomaly score for each skeleton instance:

 where  denotes the set of decoded segments that contain 
from both reconstruction and prediction. For each of those segments
, the corresponding perceptual loss, , is calculated
by Eq.~(\ref{eq:loss_calculation}).
\item \emph{Calculate frame anomaly score:} The anomaly score of a video
frame  is calculated from the score of all skeleton instances
appearing in that frame by a max pooling operator:

where  stands for the set of skeleton instances
appearing in the frame. The choice of max pooling over other aggregation
functions is to suppress the influence of normal trajectories present
in the scene, since the number of normal trajectories can vary largely
in real surveillance videos. We then use  as the
frame-level anomaly score of  and use it to calculate all
accuracy measurements. 
\end{enumerate}

\subsection{Implementation Details}

To detect skeletons in the videos, we utilized Alpha Pose \cite{fang2017rmpe}
to independently detect skeletons in each video frame. To track the
skeletons across a video, we combined sparse optical flow with the
detected skeletons to assign similarity scores between pairs of skeletons
in neighboring frames, and solved the assignment problem using the
Hungarian algorithm \cite{kuhn1955hungarian}. The global and local
components of the skeleton trajectories are standardized by subtracting
the median of each feature, and scaling each feature relative to the
10\%-90\% quantile range. All recurrent encoder-decoder networks have
similar architectures but are trained with independent weights. The
regularization of MPED-RNN's hyperparameters is done for each data
set, following the method described in Section \ref{subsec:Training-MPED-RNN}.
