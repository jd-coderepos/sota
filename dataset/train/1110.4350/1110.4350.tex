\documentclass[12pt]{article}

\usepackage[margin=1in]{geometry}  
\usepackage{graphicx}              
\usepackage{amsmath}               
\usepackage{amsfonts}              
\usepackage{amsthm}                
\usepackage{amssymb}
\usepackage{mathrsfs}
\usepackage{enumerate}
\usepackage{algorithmic}
\usepackage{url}
\usepackage{seqsplit}

\theoremstyle{plain}
\newtheorem{theorem}{Theorem}
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{corollary}[theorem]{Corollary}
\newtheorem{proposition}[theorem]{Proposition}

\theoremstyle{definition}
\newtheorem{definition}[theorem]{Definition}
\newtheorem{conjecture}[theorem]{Conjecture}
\newtheorem{example}[theorem]{Example}
\newtheorem*{remark}{Remark}
\newtheorem*{note}{Note}



\renewcommand{\algorithmicrequire}{\textbf{Input:}}
\renewcommand{\algorithmicensure}{\textbf{Output:}}
\algsetup{linenodelimiter=.}



\newcommand{\refchapter}[1]{Chapter \ref{#1}}
\newcommand{\refsection}[1]{Section \ref{#1}}
\newcommand{\refequation}[1]{Equation (\ref{#1})}
\newcommand{\reftheorem}[1]{Theorem \ref{#1}}
\newcommand{\reflemma}[1]{Lemma \ref{#1}}
\newcommand{\refcorollary}[1]{Corollary \ref{#1}}
\newcommand{\refproposition}[1]{Proposition \ref{#1}}
\newcommand{\refalgorithm}[1]{Algorithm \ref{#1}}
\newcommand{\refstep}[1]{Step \ref{#1}}


\newcommand{\romnum}[1]{\romannumeral #1}
\newcommand{\Romnum}[1]{\uppercase\expandafter{\romannumeral #1}}




\DeclareMathOperator{\fieldchar}{char}
\DeclareMathOperator{\ringofend}{End}
\DeclareMathOperator{\trace}{tr}
\DeclareMathOperator{\gal}{Gal}
\DeclareMathOperator{\order}{ord}
\DeclareMathOperator{\lcm}{lcm}
\DeclareMathOperator{\divisor}{div}
\DeclareMathOperator{\supp}{supp}
\providecommand{\abs}[1]{\left\vert#1\right\vert}

\def\F{\mathbb{F}}
\def\K{\mathbb{K}}
\def\M{\mathsf{M}}
\def\CC{\mathsf{C}}
\def\R{\mathsf{R}}


\makeatletter
\newcounter{algorithm}
\setcounter{algorithm}{0}
\renewcommand{\thealgorithm}{\arabic{algorithm}}
\def\algorithm{\@ifnextchar[{\@algorithma}{\@algorithmb}}
\def\@algorithma[#1]{\refstepcounter{algorithm}
  \trivlist
  \leftmargin\z@
  \itemindent\z@
  \labelsep\z@
  \item[\parbox{\columnwidth}{\hrule
    \hrule
    \noindent\strut\textbf{Algorithm \thealgorithm} #1
    \hrule
  }]\hfil\vskip0em}
\def\@algorithmb{\@algorithma[]}
\def\endalgorithm{\hfil\vskip-1em\hrule\endtrivlist}
\makeatother


\renewcommand{\qedsymbol}{}



\newcommand{\keywords}[1]{\begin{description} \item[\textbf{Keywords.}] #1 \end{description}}



\title{Taking Roots over High Extensions \\ of Finite Fields}

\author{Javad Doliskani \\ \texttt{jdoliska@uwo.ca} 
\and
\'{E}ric Schost \\ \texttt{eschost@uwo.ca}}

\date{}

\begin{document}

\maketitle

\begin{abstract}
We present a new algorithm for computing -th roots over the finite
field , where , with  a prime, and  any positive
integer. In the particular case , the cost of the new algorithm
is an expected  operations in
, where  and  are bounds for the cost of
polynomial multiplication and modular polynomial composition. Known
results give  and , so our algorithm is subquadratic in .  
\keywords{Root extraction; square roots; finite field arithmetic.}
\textbf{Mathematics Subject Classification 2010.} Primary 11Y16, 12Y05, Secondary 68W30.
\end{abstract}



\section{Introduction}\label{section:intro}

Beside its intrinsic interest, computing -th roots over finite
fields (for  an integer at least equal to ) has found many
applications in computer science. Our own interest comes from elliptic
and hyperelliptic curve cryptography; there, square root computations
show up in pairing-based cryptography~\cite{BaKiLySc02} or
point-counting problems~\cite{GaSc10}.


Our result in this paper is a new algorithm for computing -th roots
in a degree  extension  of the prime field , with  a
prime. Our emphasis is on the case where  is thought to be small,
and the degree  grows. Roughly speaking, we reduce the problem to
-th root extraction in a lower degree extension of  (when
, we actually reduce the problem to square root extraction over
 itself).



\paragraph{Our complexity model.}
It is possible to describe the algorithm in an abstract manner,
independently of the choice of a basis of  over . However,
to give concrete complexity estimates, we have to decide which
representation we use, the most usual choices being monomial and
normal bases. We choose to use a monomial basis, since in particular
our implementation is based on the library NTL~\cite{NTL2009}, which
uses this representation.  Thus, the finite field  is
represented as , for some monic irreducible
polynomial  of degree ; elements of  are
represented as polynomials in  of degree less than . We
will briefly mention the normal basis representation later on.

The costs of all algorithms are measured in number of operations
 in the base field  (that is, we are using an
algebraic complexity model).

We shall denote upper bounds for the cost of {\em polynomial
  multiplication} and {\em modular composition} by respectively
 and . This means that over any field , we can
multiply polynomials of degree  in  in  base field
operations, and that we can compute  in 
operations in , when  are degree  polynomials. We
additionally require that both  and  are super-linear
functions, as in~\cite[Chapter~8]{GaGe03}, and that .
In particular, since we work in the monomial basis, multiplications
and inversions in  can be done in respectively  and
 operations in , see again~\cite{GaGe03}.

The best known bound for  is , achieved
by using Fast Fourier Transform~\cite{Schonhage1971,CaKa91}.  The most
well-known bound for  is , due to Brent
and Kung~\cite{BrKu78}, where  is such that matrices of size
 over any field  can be multiplied in  operations
in ; this estimate assumes that , otherwise some
logarithmic terms may appear. Using the algorithm of Coppersmith and
Winograd~\cite{CoWi90}, we can take  and thus
; an algorithm by Huang and Pan~\cite{HuPa98}
actually achieves a slightly better exponent of , by means of
rectangular matrix multiplication.

\paragraph{Main result.}
We will focus in this paper on the case of -th root extraction,
where  is a prime divisor of ; the general case of -th root
extraction, with  arbitrary, can easily be reduced to this case
(see the discussion after Theorem~\ref{theo:main}).

The core of our algorithm is a reduction of -th root extraction in
 to -th root extraction in an extension of  of smaller
degree. Our algorithm is probabilistic of Las Vegas type, so 
its running time is given as an expected number of operations. With
this convention, our main result is the following.

\begin{theorem}\label{theo:main}
  Let  be a prime factor of , with , and let  be the
  order of  in . Given , one
  can decide if  is a -th power in , and if so compute
  one of its -th roots, by means of the following operations:
  \begin{itemize}
  \item an expected  operations in
    ;
  \item a -th root extraction in .
  \end{itemize}
\end{theorem}

Thus, we replace -th root extraction in a degree  extension by a
-th root extraction in an extension of degree .
The extension degree  is the largest one for which  still
divides , so iterating the process does not bring any
improvement: the -th root extraction in  must be dealt
with by another algorithm. The smaller  is, the better.

A useful special case is , that is, we are taking square roots;
the assumption that  divides  is then satisfied for all odd
primes  and all . In this case, we have , so the second
step amounts to square root extraction in . Since this can be
done in  expected operations in , the total running
time of the algorithm is an expected 
operations in . 

A previous algorithm by Kaltofen and Shoup~\cite{KaltofenShoup1997}
allows one to compute -th roots in  in expected time
; we discuss
it further in the next section. This algorithm requires no assumption
on , so it can be used in our algorithm in the case , for
-th root extraction in . Then, its expected running time
is .

The strategy of using Theorem~\ref{theo:main} to reduce from  to
 then using the Kaltofen-Shoup algorithm over 
is never more expensive than using the Kaltofen-Shoup algorithm
directly over . For , both strategies are within a
constant factor; but even for the smallest case , our algorithm
has advantages (as explained in the last section). For larger , the
gap in our favor will increase for cases when  is small (such 
as when  divides , corresponding to ).

\medskip

Finally, let us go back to the remark above, that for any , one can
reduce -th root extraction of  to computing -th
roots, with  dividing ; this is well known, see for
instance~\cite[Chapter~7.3]{BachSh1996}. We write  with  and  for every prime divisor  of , and
we assume that  is indeed an -th power.
\begin{itemize}
\item We first compute the -th root  of  as
   by computing the inverse  of
  , and computing an -th power in . This
  takes  operations in .
\item Let  be the prime
  factorization of , which we assume is given to us. Then, for , we compute an -th root  of 
  using Theorem~\ref{theo:main}, so that  is an
  -th root of .

  One should be careful in the choice of the -th roots (which are
  not unique), so as to ensure that each  is indeed an
  -th power: if the given  is not such a power, we can
  multiply it by a -th root of unity until we find a suitable
  one.  The root of unity can be found by the algorithm of
  Theorem~\ref{theo:main}.

  Once we know , the same process can be applied to
  compute an -th root of , and so on.
\end{itemize}

The first step, taking a root of order , may actually be the
bottleneck of this scheme. When  is small compared to , it may
be better to use here as well the algorithm by Kaltofen and Shoup
mentioned above.



\paragraph{Organization of the paper.} 
The next section reviews and discusses known algorithms;
Section~\ref{section:newRootEx} gives the details of the root
extraction algorithm and some experimental results. In all the paper,
 denotes the set of -th powers in .

\paragraph{Acknowledgments.} We thank NSERC and the Canada Research
Chairs program for financial support.



\section{Previous work}

Let  be a prime factor of .  In the rest of this section, we discuss
previous algorithms for -th root extraction, with a special focus
on the case  (square roots), which has attracted most attention
in the literature.

We shall see in \refsection{section:newRootEx} that given such a prime
, the cost of testing for -th power is always dominated by the
-th root extraction; thus, for an input , we always
assume that .

All algorithms discussed below rely on some form of exponentiation in
, or in an extension of , with exponents that grow
linearly with . As a result, a direct implementation using binary
powering uses  multiplications in , that is,
 operations in . Even using fast
multiplication, this is quadratic in ; alternative techniques
should be used to perform the exponentiation, when possible.

\paragraph{Some special cases of square root computation.}
If  is a group with an odd order , then the mapping ,  is an automorphism of ; hence, every
element  has a unique square root, which is . Thus, if , the square root of any  is ; this is because  is a
group of odd order .

More complex schemes allow one to compute square roots for some
increasingly restricted classes of prime powers . The following
table summarizes results known to us; in each case, the algorithm uses
 exponentiations and  additions / multiplications in
. The table indicates what exponents are used in the
exponentiations.

  \begin{table}[h]
    \caption{Some special cases for square roots}\label{table1}
\begin{center}
\begin{tabular}{c|c|c}
Algorithm &  & exponent \\\hline
folklore  &  &  \\
Atkin     &  &  \\
M\"uller~\cite{Muller04} &  &  and \\
Kong {\it et al.}~\cite{KoCaYuLi06} &  &  and 
\end{tabular}
\end{center}
  \end{table}
\noindent As was said above, using a direct binary powering approach to
exponentiation, all these algorithms use  operations
in .

\paragraph{Cipolla's square root algorithm.} 
To compute the square root of , Cipolla's algorithm
uses an element  in  such that  is not a square in
. Then, the polynomial  is irreducible over
, hence  is a field. Let  be the
residue class of  modulo .  Since  is the
minimal polynomial of  over , , ensuring
that .

Finding a quadratic nonresidue of the form  by choosing a
random  requires an expected  attempts~\cite[page
  158]{BachSh1996}. The quadratic residue test, and the norm
computation take  and 
multiplications in  respectively. Therefore, the cost of the
algorithm is an expected  operations in .

Algorithms extending Cipolla's to the computation of -th roots in ,
where  is a prime factor of , are
in~\cite{Williams72,WiHa93,NiHaSuKu09}.

\paragraph{The Tonelli-Shanks algorithm.}
We will describe the algorithm in the case of square roots, although
the ideas extend to higher orders. Tonelli's
algorithm~\cite{Tonelli1891} and Shanks' improvement~\cite{Shanks1972}
use discrete logarithms to reduce the problem to a subgroup of
 of odd order. Let  with  and
let  be the unique subgroup of  of order . Assume we
find a quadratic nonresidue ; then, the square root of
 can be computed as follows: we can express  as  by solving a discrete logarithm in ;  is
necessarily even, so that .

According to \cite{Pohlig1978}, the discrete logarithm requires
 multiplications in ; all other steps take
 operations in . Hence, the expected running
time of the algorithm is  operations in
. Thus, the efficiency of this algorithm depends on the
structure of : there exists an infinite sequence of primes for
which the cost is , see~\cite{Tornaria2002}.



\paragraph{Improving the exponentiation.}
All algorithms seen before use at best  operations
in , because of the exponentiation. Using ideas going back
to~\cite{ItTs88}, Barreto {\it et al.}~\cite{BaKiLySc02} observed that
for some of the cases seen above, the exponentiation can be improved,
giving a cost subquadratic in .

For instance, when taking square roots with , the
exponentiation  can be reduced to computing
, with , plus two (cheap)
exponentiations with exponents  and . The special
form of the exponent  makes it possible to
apply a binary powering approach, involving 
multiplications and exponentiations, with exponents that are powers of
.

Further examples for square roots are discussed
in~\cite{KoCaYuLi06,HaChKi09}, covering the entries of
Table~\ref{table1}. These references assume a normal basis
representation; using (as we do) the monomial basis and modular
composition techniques (which will be explained in the next section),
the costs become . Some cases of higher
index roots are in~\cite{BaVo06}: if  is a factor of , such
that  does not divide , and if , then -th
root extraction can be done using 
operations in .

\paragraph{Kaltofen and Shoup's algorithm.}
Finally, we mention what is, as far as we know, the only algorithm
achieving an expected subquadratic running time in  (using the
monomial basis representation), without any assumption on .

Consider a factor  of . To compute a -th root of
, the idea is simply to factor 
using polynomial factorization techniques. Since we know that  is a
-th power, this polynomial splits into linear factors, so we
can use an Equal Degree Factorization (EDF) algorithm.

A specialized EDF algorithm, dedicated to the case of high-degree
extension of a given base field, was proposed by Kaltofen and Shoup
\cite{KaltofenShoup1997}. It mainly reduces to the computation of a
trace-like quantity , where  is a
random element in . Using a binary
powering technique similar to the one of the previous paragraph, this
results in an expected running time of  operations in ; remark that this
estimate is faster than what is stated in~\cite{KaltofenShoup1997} by
a factor , since here we only need one root, instead of the
whole factorization. In the particular case , this becomes
. This achieves a running time
subquadratic in~.

This idea actually allows one to compute a -th root, for arbitrary
: starting from the polynomial , we apply the above
algorithm to ; computing  modulo  can
be done by the same binary powering techniques.





\section{A new root extraction algorithm}\label{section:newRootEx}

In this section, we focus on -th root extraction in , for 
a prime dividing  (as we saw in \refsection{section:intro},
-th root extraction, for an integer , reduces to taking 
-th roots, where  is a prime factor of  dividing ).

The algorithm we present uses the trace , for some
subfield  to reduce -th root extraction in
 to -th root extraction in . We assume as before
that the field  is represented by a quotient , with  a monic irreducible polynomial of
degree . We let  be the residue class of  modulo .

Since we will handle both  and , conversions may be
needed. We recall that the minimal polynomial  of an
element  can be computed in 
operations in ~\cite{Shoup1994}. Then,  is a subfield of ; given , written as a polynomial in , we obtain its representation
on the monomial basis of  by means of a modular composition, in
time . We will write this operation .
Note that when  is in , all these operations are actually
free.



\subsection{An auxiliary algorithm}

We first discuss a binary powering algorithm to solve the following
problem. Starting from , we are going to compute
 for given integers . This question is similar to (but
distinct from) some exponentiations and trace-like computations we
discussed before; our solution will be a similar binary powering 
approach, which will perform  multiplications and
exponentiations by powers of . Let
 where all quantities are computed in , that is, modulo ;
for simplicity, in this paragraph, we will write , 
and . Note that , and that we
have the following relations:

and

Because we are working in a monomial basis, computing exponentiations
to powers of  is not a trivial task; we will perform them using the
following modular composition technique from~\cite{GaSh92}.

Take  and , and let  and  be the
canonical preimages of respectively  and  in ;
then, we have
 see for instance~\cite[Chapter
  14.7]{GaGe03}. We will simply write this as , and note
that it can be computed using one modular composition, in time
. These remarks give us the following recursive algorithm,
where we assume that  and  are already
known.

\begin{algorithm}
[XiZetaDelta]
\label{algorithm:xizetadelta}
\begin{algorithmic}[1]
\REQUIRE , a positive integer , , 
\ENSURE , , 
\IF {} 
\RETURN , , 
\ENDIF
\STATE 
\STATE  
\STATE 
\STATE 
\STATE 
\IF { is even} 
\RETURN , , 
\ENDIF
\STATE 
\STATE 
\STATE 
\RETURN , , 
\end{algorithmic}
\end{algorithm}
We deduce the following algorithm for computing .

\begin{algorithm}
[Alpha]
\label{algorithm:alpha}
\begin{algorithmic}[1]
\REQUIRE , a positive integer 
\ENSURE 
\STATE 
\STATE 
\STATE , ,  
\RETURN 
\end{algorithmic}
\end{algorithm}

\begin{proposition}
  \refalgorithm{algorithm:alpha} computes  using
   operations in .
\end{proposition}
\begin{proof}
  To compute  and  we first compute  and
   using  multiplications in , and then
  do  modular compositions modulo . The depth of the
  recursion in Algorithm~\ref{algorithm:xizetadelta} is ;
  each recursive call involves  additions, multiplications and
  modular compositions modulo , for a total time of  per
  recursive call.
\end{proof}

As said before, the algorithm can also be implemented using a normal
basis representation. Then, exponentiations to powers of  become
trivial, but multiplication becomes more difficult. We leave these
considerations to the reader.



\subsection{Taking -th roots} 

We will now give our root extraction algorithm. As said before, we now
let  be a prime factor of , and we let  be the order of 
in . Then  divides , say .

We first explain how to test for -th powers. Testing whether  is a -th power is equivalent to testing whether
. Let ; then . Computing 
requires , and computing  using \refalgorithm{algorithm:xizetadelta}
requires  operations in
. Therefore, testing for a -th power takes  operations in .

In the particular case when  divides , we can actually do
better: we have , where  is the resultant
function. The resultant can be computed using 
operations in , so the whole test can be done using
 operations in .

In any case, we can now assume that we are given ,
with -th root . 
Defining , where
 is the trace linear form and
, we have

Let , so that
\refequation{equation:tr-square} gives .  Taking the
-th power in both sides results in the equation 
over . Since we know , and we can compute , we can thus
determine  by -th root extraction in . Then, if we
assume that  (or equivalently that ), we deduce
; to resolve the issue that  may be
zero, we will replace  by , for a random element .

Computing the -th root of  in  is done as follows.
We first compute the minimal polynomial  of , and
let  be the residue class of  in .
Then, we compute a -th root  of  in , and
embed  in . The computation of  is done by a black-box
-th root extraction algorithm, denoted by .

It remains to explain how to compute  efficiently. Let ; then, one verifies that , so we can use the algorithm of the
previous subsection. Putting all together, we obtain the following
algorithm

\begin{algorithm}
[-th root in ]
\label{algorithm:new}
\begin{algorithmic}[1]
\REQUIRE 
\ENSURE a -th root of 
\STATE  the order of  in 
\STATE 
\REPEAT
\STATE choose a random 
\STATE 
\STATE 
\STATE 
\UNTIL {}
\STATE 
\STATE  in 
\RETURN 
\end{algorithmic}
\end{algorithm}

The following proposition proves Theorem~\ref{theo:main}.

\begin{proposition}
  \refalgorithm{algorithm:new} computes a -th root of  using an
  expected  operations in ,
  plus a -th root extraction in .
\end{proposition}
\begin{proof}
  Note first that  means that . There are  values of  for which this is the case, so
  we expect to have to choose  elements in  before exiting
  the repeat \dots until loop. Each pass in the loop uses
   operations in  to compute  and
  , and  operations in 
  to compute .

  Given  and , one obtains  and  using another
   operations in ; then, computing  takes
  time . 

  After the black-box call to -th root extraction modulo ,
  embedding  in  takes time . We can then deduce
   by two divisions in , using 
  operations in ; this is negligible compared to the cost of all
  modular compositions.
\end{proof}





\subsection{Experimental results}
We have implemented our root extraction algorithm, in the case 
(that is, we are taking square roots); our implementation is based on
Shoup's NTL~\cite{NTL2009}. Figure~\ref{figure:sqrtTiming} compares
our algorithm to Cipolla's and Tonelli-Shanks' algorithms over ,
with , for the randomly selected prime , and different values of
the extension degree~. 

\begin{figure}[ht]
\begin{center}
\includegraphics[width = 9cm]{sqrtTiming.pdf}
\end{center}
\caption{\small Our square root algorithm vs. Cipolla's and
  Tonelli-Shanks' algorithms.}
\label{figure:sqrtTiming}
\end{figure}

Remember that the bottleneck in Cipolla's and Tonelli-Shanks'
algorithms is the exponentiation, which takes 
operation in . As it turns out, NTL's implementation of modular
composition has ; this means that with this implementation
we have , and our algorithm takes expected time
. Although this implementation is not
subquadratic in , it remains faster than Cipolla's and
Tonelli-Shanks' algorithms, in theory and in practice.

Next, Figure~\ref{figure:sqrtTimingKvN} compares our NTL
implementation of the EDF algorithm proposed by Kaltofen and Shoup,
and our square root algorithm (note that the range of reachable degrees
is much larger that in the first figure). We have ran the algorithms
for several random elements for each extension degree. The vertical dashed
lines, and the green line show the running time range, and the average 
running time of Kaltofen and Shoup algorithm respectively. In the case of 
our algorithm (the red graph), the vertical ranges are invisible because the 
deviation from the average is  seconds. 

\begin{figure}[ht]
\begin{center}
\includegraphics[width = 9cm]{sqrtTimingKvN.pdf}
\end{center}
\caption{\small Our algorithm vs.\ Kaltofen and Shoup's algorithm.}
\label{figure:sqrtTimingKvN}
\end{figure}

This time, the results are closer. Nevertheless, it appears that the
running time of our algorithm behaves more ``smoothly'', in the sense that
random choices seem to have less influence. This is indeed the
case. The random choice in Kaltofen and Shoup's algorithm succeeds
with probability about ; in case of failure, we have to run to
whole algorithm again. In our case, our choice of an element  in
 fails with probability ; then, there is still
randomness involved in the -th root extraction in , but this
step was negligible in the range of parameters where our experiments
were conducted. 

Another way to express this is to compare the standard deviations in
the running times of both algorithms. In the case of Kaltofen-Shoup's
algorithm, the standard deviation is about  of the average
running time of the whole algorithm. For our algorithm, the standard
deviation is no more than  of the average running time of the
trace-like computation (which is the dominant part), plus 
of the average running time of the root extraction in  (which is cheap).



\bibliographystyle{plain}
\bibliography{references}

\end{document}
