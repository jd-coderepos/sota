\documentclass{llncs}
\pdfminorversion=4

\usepackage{graphicx}
\usepackage{fancyvrb}
\usepackage{comment}
\usepackage{float,xspace}
\usepackage{multirow,multicol}
\usepackage[linesnumbered,boxed,algoruled,slide,noresetcount]{myalgorithm2e}
\usepackage{setspace}

\newcommand{\START}{{\scriptsize{START}}\xspace}
\newcommand{\DONE}{{\scriptsize{DONE}}\xspace}
\renewcommand{\baselinestretch}{0.97}

\title{A Wait-Free Stack}
\author{Seep Goel, Pooja Aggarwal and Smruti R. Sarangi \\
E-mail: seep.goyal@gmail.com, \{pooja.aggarwal, srsarangi\}@cse.iitd.ac.in
\institute{Indian Institute of Technology, New Delhi, India} }



\begin{document}
\maketitle
\begin{abstract}
In this paper, we describe a novel algorithm to create a concurrent wait-free stack. To the best
of our knowledge, this is the first wait-free algorithm for a general purpose stack. In the past,
researchers have proposed restricted wait-free implementations of stacks, lock-free implementations,
and efficient universal constructions that can support wait-free stacks. The crux of our
wait-free implementation is a fast  operation that does not modify the stack top; instead,
it walks down the stack till it finds a node that is unmarked. It marks it but does not delete it.
Subsequently, it is lazily deleted by a  operation. 
This operation keeps the size of the stack in check by not allowing the size of the stack to 
increase beyond a factor of  as compared to 
the actual size. All our operations are wait-free and linearizable.
\end{abstract}
\section{Introduction}
\label{sec:intro}
In this paper, we describe an algorithm to create a wait-free stack. A concurrent data structure is said to be
wait-free if each operation is guaranteed to complete within a finite number of steps. In comparison, the data
structure is said to be lock-free if at any point of time, at least one operation is guaranteed to complete
in a finite number of steps. Lock-free programs will not have deadlocks but can have starvation, whereas
wait-free programs are starvation free. Wait-free stacks have not received
a lot of attention in the past, and we are not aware of algorithms that are particularly tailored to creating
a generalized wait-free stack. However, approaches have been proposed to create wait-free stacks with certain
restrictions~\cite{arrayBased}, ~\cite{restrictedStack}, ~\cite{WaitFreeSharedCounter1},~\cite{WaitFreeSharedCounter2}, 
and with universal constructions~\cite{oldUniversal}, ~\cite{newUniversal}. The main reason that it has been 
difficult to create a wait-free stack is because there
is a lot of contention at the stack top between concurrent  and  operations. It has thus been
hitherto difficult to realize the gains of additional parallelism, and also guarantee completion in a finite
amount of time.

The crux of our algorithm is as follows. We implement a stack as a linked list, where the  pointer
points to the stack top. Each  operation adds an element to the linked list, and updates the  pointer.
Both of these steps are done atomically, and the overall operation is linearizable (appears
to execute instantaneously). However, the  
operation does not update the  pointer. This design decision has been made to enable more parallelism,
and reduce the time per operation. It instead scans the list starting from the  pointer till
it reaches an unmarked node. Once, it reaches an unmarked node, it marks it and returns the node as the result
of the  operation. Over time, more and more nodes get marked in the stack. To garbage collect such
nodes we implement a  operation that can be invoked by both the  and  operations.
The cleanup operation removes a sequence of  consecutively marked nodes from the list. In our algorithm,
we guarantee that at no point of time the size of the list is more than  times the size of the stack
(number of pushes - pops). This property ensures that  operations complete within a finite amount of
time. Here,  is a user defined parameter and it needs to be set to an optimal value to ensure the best
possible performance. 

The novel feature of our algorithm is the  operation that always keeps the size of the stack
within limits. It does not allow the number of marked nodes that have already been popped to indefinitely
grow. The other novel feature is that concurrent  and  operations do not cross each others' paths. 
Moreover, all the  operations can take place concurrently. This allows us to have a linearizable operation. 
In this paper, we present our basic algorithm along with proofs of important results. Readers can find
the rest of the pseudo code, asymptotic time complexities, and proofs in the appendices. 

\section{Related Work}
\label{sec:rel}
\vspace{-2mm}
In 1986, Treiber~\cite{CopingWithPara} proposed the first lock-free
implementation of a concurrent stack.  He employed a linked list based data
structure, and in his implementation, both the  and 
operations modified the  pointer using CAS instructions.  
Subsequently, Shavit et
al.~\cite{combiningFunnels} and Hendler et al.~\cite{flatCombining} designed a
linearizable concurrent stack using the concept of software combining. Here,
they group concurrent operations, and operate on the entire group.


In 2004, Hendler et al.~\cite{LockFree} proposed a highly scalable lock-free
stack using  an array of lock-free exchangers known as an elimination array.
If a  operation is paired with a  operation, then the baseline data structure need
not be accessed. This greatly enhances the amount of available parallelism, and
is known to be one of the most efficient implementations of a lock-free stack. 
This technique can be incorporated in our design as well.
Subsequently, Bar-Nissan et al.~\cite{DECS} have augmented this proposal with
software combining based approaches. 
Recently, Dodds et al.~\cite{timestamp} proposed a fast lock-free stack, which uses a
timestamp for ordering the  and  operations.

The restricted wait-free algorithms for the stack data structure proposed so far by the researchers are summarized
in Table ~\ref{tab:rel}.

\begin{table*}[!htb]
\scriptsize
\begin{center}

\begin{tabular}{|l|l|l| }
\hline
                                                         
{\em Author}			&{\em Primitives}	&{\em Remarks}\\\hline 

  
\hline  
\multirow{2}{*}{Herlihy 1991~\cite{oldUniversal}}		&\multirow{2}{*}{CAS}	&1. Copies every global update to the
private copy of every thread.
\\
	&							&2. Replicates the stack data structure  times ( \# threads).
\\\hline

Afek et al.~\cite{arrayBased}  	&F\&A,	 		&1. Requires a semi-infinite array (impractical).
\\  
2006]				&TAS			&2. Unbounded stack size.
\\\hline 

Hendler et al.~\cite{WaitFreeSharedCounter1}	&\multirow{2}{*}{DCAS}	&1. DCAS not supported in modern hardware 
\\  
2006]						&			& 2. Variation of an implementation of a shared counter. 
\\\hline 


Fatourou et al.~\cite{newUniversal}	&LL/SC,	&1. Copies every global update to the private copy of every thread. \\
2011]			&F\&A	&2. Relies on wait-free implementation of F\&A in hardware.
\\\hline 
David et al. 2011 ~\cite{restrictedStack}		&BH Object		&1. Supports at the most two concurrent pop operations
\\\hline      
\hline
\multicolumn{3}{||c||}{CAS  compare-and-set, TAS  test-and-set, LL/SC 
load linked-store conditional} \\
\multicolumn{3}{||c||}{DCAS  double location CAS, F\&A  fetch-and-add, BH Object (custom
object~\cite{restrictedStack})} \\
\hline
\end{tabular}
\caption{ Summary of existing restricted wait-free stack algorithms  \label{tab:rel}}
\end{center}

\vskip -3mm
\end{table*}

The - stack proposed in~\cite{arrayBased} employs a semi-infinite
array as its underlying data structure. A  operation obtains a unique index in the
array (using getAndIncrement()) and writes its value to that index. A 
operation starts from the top of the stack, and traverses the stack towards the bottom.
It marks and returns the first unmarked node that we find. Our  operation
is inspired by this algorithm. Due to its unrestricted stack size, this algorithm
is not practical.

David et al.~\cite{restrictedStack} proposed another class of
 restricted stack implementations.
Their implementation can support a maximum of two concurrent  operations.
Kutten et al.~\cite{WaitFreeSharedCounter1,WaitFreeSharedCounter2} suggest an
approach where a wait-free shared counter can be adapted to
create wait-free stacks. However, their algorithm requires the DCAS (double
CAS) primitive, which is not supported in contemporary hardware. 

Wait-free universal constructions are generic algorithms that can be used to create linearizable implementations of any
object that has valid sequential semantics.  The inherent drawback of these approaches is that they typically have
high time and space overheads (creates local copies of the entire (or partial) data structure).
  A recent proposal by Fatourou et al.~\cite{newUniversal} can be used to implement stacks
and queues.  The approach derives its performance improvement over the widely accepted universal construction of
Herlihy~\cite{oldUniversal} by optimizing on the number of shared memory accesses. 
\section{The Algorithm}

\subsection{Basic Data Structures}
Algorithm~\ref{alg:node} shows the  class, which represents a node in a stack. 
It has a , and pointers to the next () and previous nodes () respectively.
Note that our stack is not a doubly linked list, the next pointer  is only used for reaching consensus on which node will be added next in the stack. 

 To support  operations, every node has a  field. The  field contains 
the id of the thread that created the request. The  field and  is an atomic integer and is used 
to clean up the stack.
\vspace{-6mm}
\begin{algorithm}
\scriptsize
\SetAlgoLined
\textbf{class Node}{}\\
		\hspace{5mm} \\
		\hspace{5mm} \\
		\hspace{5mm} \\
		\hspace{5mm} \\
		\hspace{5mm} \\
		\hspace{5mm} \\	
		\hspace{5mm}   /* initially set to 0 */\\ 	
\caption{The Node Class} \label{alg:node}
\end{algorithm}
\vspace{-6mm}


\begin{comment}
\begin{figure}[!htb]
\begin{center}
\includegraphics[width=0.5\textwidth]{list}
\caption{The underlying data structure of the stack with  and  nodes \label{fig:wfstack}}
\end{center}
\end{figure}
\end{comment}
In our wait-free stack, the nodes are arranged as a linked list. Initially, the list contains 
only the  node, which is a dummy node. As we push elements, the list starts to grow. 
The  pointer points to the current stack top. 


\begin{comment}
\begin{algorithm}
\scriptsize
 \\
  \\

\textbf{WFstack}() \{ \\
	\hspace{5mm}   \\
	\hspace{5mm}   \\
	.... \\
\}
\caption{Class WFStack \label{alg:wfs}}
\end{algorithm}
\end{comment}

\normalsize
\begin{comment}
\begin{algorithm}


\SetAlgoLined



\textbf{WFstack}(){}\\
		\hspace{5mm}   \\
		\hspace{5mm}   \\
		\hspace{5mm}   \\
		\hspace{5mm}   \\
		\hspace{5mm}   \\
		\hspace{5mm}   \\
		\hspace{5mm}    (\_)\\
		\hspace{5mm}    [\_]\\

		\hspace{5mm}\For{  0 ;   \_ ;   +1}
		 {
			\hspace{10mm} ,  \\
			\hspace{10mm} ,  \\
		 }

		\hspace{5mm}\\

\end{algorithm}
\end{comment}
\vspace{-4mm}
\subsection{High level Overview}

The  operation starts by choosing a phase number (in a monotonically increasing manner), which is greater than
the phase numbers of all the existing push operations in the system. This phase
number along with a reference to the node to be pushed and a flag indicating
the status of the  operation are saved in the  array in an
atomic step. After this, the thread  scans the  array and finds
out the thread , which has a  request with the least phase
number. Note that, the thread  found out by  in the last step might
be  itself. Next,  helps  in completing 's operation. At
this point of time, some threads other than  might also be trying to help
, and therefore, we must ensure that 's operation is applied exactly
once. This is ensured by mandating that for the completion of any 
request, the following steps must be performed in the exact specified order:

\begin{enumerate} 
\item Modify the state of the stack in such a manner
that all the other  requests in the system must come to know that a
 request  is in progress and additionally they should be able to figure out
the details required by them to help .  
\item Update the status flag to
 in 's entry in the  array.  
\item Update the 
pointer to point to the newly pushed node.  
\end{enumerate}




The  operation has been designed in such a manner that it does not update
the  pointer. This decision has the dual benefit of eliminating the
contention between concurrent  and  operations, as well as enabling the
parallel execution of multiple  operations. The  operation starts by
scanning the linked list starting from the stack's top till it reaches an
unmarked node. Once, it gets an unmarked node, it marks it and returns the node
as a result of the  operation.  Note that there is no helping in the case
of a  operation and therefore, we do not need to worry about a 
operation being executed twice. Over time, more and more nodes get marked in
the stack. To garbage collect such nodes we implement a  operation
that can be invoked by both the  and  operations. 



\vspace{-4mm}

\subsection{The Push Operation}
The first step in pushing a node is to create an instance of the  class. It contains the 
reference to a Node (), a Boolean variable  that indicates the status of the 
request, and a phase number () to indicate the age of the request.
Let us now consider the  method (Line~\ref{line:push}).
 We first get the phase number by atomically incrementing a global counter. 
Once the  is created and its phase is initialized, it is saved in the  array. 
Subsequently, we call the function  to actually execute the  request. 

The  function (Line~\ref{line:help}) finds the request with the least phase number that has 
not been pushed yet. If there is no such request, then it returns. Otherwise it helps that request 
() to complete by calling the  method. After helping , we check if the request that was helped is the same as the request that was 
passed as an argument to the  function () in Line~\ref{line:help}. If they are 
different requests, then we call  for the request  in Line~\ref{line:attachreq}. 
This is a standard construction to make a lock-free method wait-free (refer to ~\cite{artOfMulti}).

In the  function, we first read the value of the  pointer, and its  field. 
If these fields have not changed between Lines~\ref{read1} and~\ref{line:notlast}, then we try to find the status of the request in Line~\ref{line:ifdone}. 
Note that we check that  is equal to null, and  is equal to false in the previous line 
(Line~\ref{line:nextnull}). The  field is made true after the  pointer has been updated. Hence, in 
Line~\ref{line:nextnull}, if we find it to be true then we need to abort the current iteration and read the 
 pointer again.
\vspace{-6mm}
\begin{algorithm}[!htb]
\scriptsize
\SetAlgoLined

\textbf{class PushOp}{}\\
		\hspace{5mm} \\
		\hspace{5mm} \\
		\hspace{5mm} \\
 \\
\textbf{push}(, ){} \label{line:push}\\
		  \\
		  new (,, (,)) \\
		announce[tid]  \\
		()\\


\caption{The Push Method} \label{alg:PushOp}



\SetAlgoLined
\textbf{help}(){} \label{line:help}\\
		(, )    \{ (, )  , ,
!req.pushed  \} \\
		\If{ (minReq  null)  ()} {
			 
		}
		attachNode() \\
		\If{  }{
			attachNode() \label{line:attachreq}
		}




\scriptsize
\SetAlgoLined	
\textbf{attachNode}(){}\\
		\While{!}
		{
			  ()\\
			(, )  ()\\ \label{read1}
			\If{ == () \label{line:notlast}} 
			{
				\If{ ==  \&\&  = \textbf{false} \label{line:nextnull}}
				{
					\If{!  	\label{line:ifdone}}  
					{
						  \\
						  ( (,\textbf{false}), (, \textbf{false})) \label{line:pushcas} \\
						
						\If{res}
						 {
							
							()\\
							last.nextDone.compareAndSet ( (, \textbf{false}), (null,\textbf{true})) \\
							
						}
					}
				}
					() \label{line:otherupdatetop}
			}
		}

\end{algorithm}
\vspace{-8mm}

After, we read the status of the request, and find that it has not completed, we proceed to update the  
field of the stack top in Line~\ref{line:pushcas} using a compare-And-Set (CAS) instruction. The aim is to change the pointer in 
the  field from  to the node the push request needs to add. 
If we are successful, then we need to update the  pointer by calling the 
function, . After the  pointer has been updated, we do not really need the  field for 
subsequent  requests. It will not be used. However, concurrent requests need to see that  
has been updated. The additional compulsion to delete the contents of the pointer in the  field is that 
it is possible to have references to deleted nodes via the  field. The garbage collector in this case will 
not be able to remove the deleted nodes. Thus, after updating the top pointer, we set the  field's 
pointer to , and set the  to true. If a  concurrent request reads the mark to be true, then it can be 
sure, that the  pointer has been updated, and it needs to read it again.

If the CAS instruction fails, then it means that another concurrent request has successfully performed a CAS 
operation. However, it might not have updated the  pointer. It is thus necessary to call the  
function to help the request complete. 

\vspace{-8mm}
\begin{algorithm}
\scriptsize
\SetAlgoLined	
\textbf{updateTop}(){}\\
		  ()\\
		(, )  ()\\
		\If{   \label{line:nextnonnull} }
		{
	    	  (.) \\
			\If{() \&\& }
			{
/* Add the request to the stack and update the top pointer */ \\
				(, ) \label{line:push_prev} \\
				   +1 \label{line:index}\\
				  \textbf{true} \label{line:announce} \\
				  top.compareAndSet(, ) \label{line:updatetop} \\
/* Check if any cleaning up has to be done */ \\
				\If{next.index \%  == 0 \&\&  == \textbf{true} \label{line:onethread}} 
				{
					tryCleanUp(next) \label{line:trycleanup}
				}
			}
		}
\caption{The  method} \label{alg:updatetop} 
\end{algorithm}


\vspace{-8mm}
\normalsize
The  method is shown in Algorithm~\ref{alg:updatetop}. We read the  pointer, and the  
pointer. If  is non-null, then the request has not fully completed. It is necessary to help it complete. 
After having checked the value of the  pointer, and the value of the  field, we proceed to connect 
the newly attached node to the stack by updating its  pointer. We set the value of its  pointer in 
Line~\ref{line:push_prev}. Every node in the stack has an index that is assigned in a monotonically increasing 
order. Hence, in Line~\ref{line:index}, we set the index of  to 1 plus the index of .
Next, we set the  field 
of the  equal to true. The point of
linearizability is Line~\ref{line:updatetop}, 
where we update the  pointer to point to  instead of
. This completes the  operation. 

We have a cleanup mechanism that is invoked once the index of a node becomes a multiple of a constant, . 
We invoke the  method in Line~\ref{line:trycleanup}. It is necessary that the  method
be called by only one thread.  Hence, the thread that successfully performed a CAS on the top pointer
calls the  method if the index is a multiple of . 

\vspace{-3mm} 
\subsection{The Pop Operation}
Algorithm~\ref{alg:pop} shows the code for the  method. We read the value of 
the  pointer and save it in the local variable, . This is the only instance
in this function, where we read the value of the  pointer. Then, we walk back
towards the sentinel node by following the  pointers (Lines~\ref{line:popwhile} --
\ref{line:popwhileend}). We stop when we are successfully able to set the mark of a node
that is unmarked. This node is logically ``popped'' at this instant of time. 
If we are not able to find any such node, and we reach the sentinel node, then we throw
an . 

\vspace{-6mm}
\begin{algorithm}[!htb]
\scriptsize
\SetAlgoLined

\textbf{pop}(){}\\
	    ()\\ \label{alg:prev_top}
	    \\
	\label{alg:while_mark}
	\While{  }  {  \label{line:popwhile} 
			   ()\\  
			\If{}
			{
				
			}
			   
	} \label{line:popwhileend}

	\If{}
	{
/* Reached the end of the stack */ \\
			  () 
	}
/* Try to clean up parts of the stack */ \\
	tryCleanUp(curr) \label{line:popclean}

	return 
\caption{The Pop Method} \label{alg:pop}
\end{algorithm}
\vspace{-6mm}

After logically marking a node as popped, it is time to physically delete it. We thus
call the  method in Line~\ref{line:popclean}. The  method returns the
node that it had successfully marked.
\vspace{-3mm}
\subsection{The CleanUp Operation}

The aim of the  method is to clean a set of  contiguous entries in the list (indexed by 
the  pointers). Let us start by defining some terminology. Let us define a range of  
contiguous entries, which has four distinguished nodes as shown in Figure~\ref{fig:rangew}.

A range starts with a node termed the , whose index is a multiple of . Let us now define
 as . The node at the end of a range is . Its index is equal to 
. Let us now define a node  such that . 
Note that for a given range, the  and  nodes are fixed, whereas the  and
 nodes keep changing.  is the base of another range, and its index is
a multiple of . 

The  and the  methods call the function . The  method calls it when
it pushes a node whose index is a multiple of . This is a valid . It walks back 
and increments the counter of the  node of the previous range. We ensure that only one thread
(out of all the helpers) does this in Line~\ref{line:onethread}. Similarly, in the  function,
whenever we mark a node, we call the  function. Since the  function does not
have any helpers, only one thread per node calls the  function. Now, inside
the  function, we increment the counter of the  node. Once, a thread increments it to 
, it invokes the  function. Since only one thread will increment the counter to , 
only one thread will invoke the  function for a range. 
\vspace{-4mm}
\begin{figure}[!htb]
\begin{center}
\includegraphics[width=0.75\columnwidth]{rangew}
\caption{A range of  entries \label{fig:rangew} }
\end{center}
\end{figure}
\vspace{-8mm}


\vspace{-7mm}
\begin{algorithm}
\scriptsize
\SetAlgoLined
\textbf{tryCleanUp(myNode)} \\
	  \\
	\While{  }
	{
		\If{()  W == 0}
		{
			\If{ == W + 1}
			{
				(getTid(), ) \label{line:callclean}
			}
			\\
		}
		  \\
	}
\caption{The  method} \label{alg:tryClean}
\end{algorithm}
\vspace{-7mm}
\begin{comment}
\begin{algorithm}
\scriptsize
\SetAlgoLined
\textbf{class DeleteRequest}{}\\
		\hspace{5mm} \\
		\hspace{5mm} \\
		\hspace{5mm} \\
        \hspace{5mm}  \\	

\vskip 1mm
AtomicReferenceArrayDeleteRequest allDeleteRequests

\caption{ } \label{alg:deleteclasses}
\end{algorithm}
\end{comment}
The functionality of the  function is very similar to the  function. 
Here, we first create a  that has four fields:  (similar to phase in ), 
,  (whether the delete has been finished or not), and  the value of the  node. 
Akin to the  function, we add the newly created  to a global array of s.
Subsequently, we find the pending request with the minimum phase in the array . 


\begin{comment}
\vspace{-5mm}
\begin{algorithm}
\scriptsize
\SetAlgoLined
\textbf{clean}(, ){}\\
  ()\\
    DeleteRequest(, , , ) \\
[]    \label{line:alldel}\\
()\\


\textbf{helpDelete}(){}\\
			(, )    \{ ,   ,  = ,
 = \textbf{true} \} \\
			\If{()  (  )}{
				break
			}
			() \\
			\If{} {
				
			}
\caption{ and  methods} \label{alg:clean}
\end{algorithm}
\end{comment}
\begin{comment}
\vspace{-5mm}	
\begin{algorithm}
\scriptsize
\SetAlgoLined
\textbf{uniqueDelete}(){}\\
		\While{}
		{
			  ()\\
			\If{! \label{line:deluniquepending} }
			{
				\If{}
				{
					  () ? . (,
) :
\textbf{true} \label{line:cleanCAS}\\
					()\\
					\If{} {
						
					}
				}
			}
		\Else{
				()
			}
		}
\caption{The  method} \label{alg:clean2}
\end{algorithm}
\end{comment}


Note that at this stage it is possible for multiple threads to read the same value of the request with the 
minimum phase number. It is also possible for different sets of threads to have found different requests
to have the minimum phase. For example, if a request with phase 2 () got added to the array before the 
request with phase 1 (), then a set of threads might be trying to complete , and another set might 
be trying to complete . To ensure that our stack remains in a consistent state, we want that only one 
set goes through to the next stage.

To achieve this, we adopt a strategy similar to the one adopted in the function . 
Interested readers can refer to the appendices for a detailed explanation of how this is done.
Beyond this point, all the threads will be working on the same  which we term as . 
They will then move on to call the  function that will actually finish the delete request.

Let us describe the  function in Algorithm~\ref{alg:helpfinishdelete}. 
We first read the current request from the atomic variable,  in Line~\ref{line:currread}. If
the request is not pending, then some other helper has completed the request, and we can return from the function.
However, if this is not the case, then we need to complete the delete operation. Our aim now is to find the ,
, and . We search for these nodes starting from the stack top.

The index of the  is equal to the index of the node in the current request () + . 
 is set to this value in Line~\ref{line:endidx}.
Subsequently, in Lines~\ref{line:right}--\ref{line:sentinel}, we start from the top of the stack, and keep traversing the 
pointers till the index of  is equal to . Once, the equality condition is satisfied,
Lines~\ref{line:right} and \ref{line:left} give us the pointers to the  and  respectively. If
we are not able to find the , then it means that another helper has successfully deleted the nodes. We can
thus return. \\

\vspace{-8mm}
\begin{algorithm}
\scriptsize
\SetAlgoLined
\textbf{helpFinishDelete}(){}\\
		  () \label{line:currread} \\
		\If{}
		{
			
		}
  	 \label{line:endidx}\\

			
			                   /* Search for the request from the  */ \\
		       \\	
			\While{  } {
				   \label{line:right} \\
				   \label{line:left}
			}
			\If{} {
				 /* some other thread deleted the nodes */
			} \label{line:sentinel}
/* Find the target node */ \\
		    \label{line:targetstart}\\
		\For{i=0; i ; i++}{
			  	
		} \label{line:targetend}
 /* Perform the CAS operation and delete the nodes */ \label{line:rightcas} \\
  \textbf{false} /* Set the status of the delete request to not pending*/ \label{line:setpending}\\

\caption{The  method} \label{alg:helpfinishdelete}
\end{algorithm}
\vspace{-8mm}

\begin{comment}
We define a global atomic
variable, . If a delete is not pending 
on , we read its contents, and try to perform a CAS operation on it. We try to atomically
replace its current contents with the argument, . Note that at this stage, only one set of threads
will be successful. Beyond this point, all the threads will be working on the same DeleteRequest. 
They will then move on to call the  function that will finish the delete request. 
For threads that are not successful in the CAS operation, or threads that find that the current request
contained in  has a delete pending will also call the  function. This 
is required to ensure wait freedom. 
\end{comment}

The next task is to find the . The  is  hops away from the .
Lines~\ref{line:targetstart}--\ref{line:targetend} run a loop  times to find the target. Note that we shall never
have any issues with null pointers because  is set to  itself. Once, we have found the
target, we need to perform a CAS operation on the  pointer of the . We accomplish this in
Line~\ref{line:rightcas}. If the  pointer of  is equal to , then we set it to .
This operation removes  entries (from  to ) from the list. The last step is to set the 
status of the  field in the current request () to false (see Line~\ref{line:setpending}).




\section{Proof of Correctness}
\vspace{-3mm}
The most popular correctness criteria for a concurrent shared object is {\em
linearizability}~\cite{linearizability}. Linearizability ensures that within the execution interval of every operation
there is a point, called the linearization point, where the operation seems to
take effect instantaneously and the effect of all the operations on the object
is consistent with the object's sequential specification. 
By the property of compositional linearizability, if each method of an object is linearizable we can 
conclude that the complete object is linearizable.
Thus, if we identify the point of linearization for both the push and the pop method in our implementation, 
we can say that our implementation is linearizable and thus establish its correctness.

Interested readers can refer to the appendices, where we show that our 
implementation is legal and push and pop operations complete in a bounded number of steps.


\begin{theorem}
The  and  operations are linearizable.
\end{theorem}

\begin{proof}
Let us start out by defining the notion of ``pass points''. The pass point of a  
operation is when it successfully updates the  pointer in the function 
(Line~\ref{line:updatetop}). The pass point of the  operation, is when it successfully marks a node,
or when it throws the {\em EmtpyStackException}.
Let us now try to prove by mathematical
induction on the number of requests
that it is always possible to construct a linearizable execution that is equivalent to
a given execution. In a linearizable execution all the operations are arranged in a sequential
order, and if request  precedes  in the original execution, then  precedes 
in the linearizable execution as well.

\noindent \textbf{Base Case:} Let us consider an execution with only one pass point. Since
the execution is complete, we can conclude that there was only one request in the system.
An equivalent linearizable execution will have a single request. The outcome of the request
will be an {\em EmptyStackException} if it is a  request, otherwise it will push a node
to the stack. Our algorithm will do exactly the same in the  and  methods
respectively. Hence, the executions are equivalent. \\
\noindent \textbf{Induction Hypothesis:} Let us assume that all executions with  requests
are equivalent to linearizable executions. \\
\noindent \textbf{Inductive Step:} Let us now prove our hypothesis for executions with 
requests. Let us arrange all the requests in an ascending order of the execution times 
of their pass points. Let us consider the last () request just after the pass point of the
 request. Let the last request be a . If the  request is also a , 
then the last request will use the  pointer updated
by the  request. Additionally, in this case 
the  request will not see any changes made by the
last request. It will update  and the  pointer, before the last request updates
them. In a similar manner we can prove that no prior  request will see the last request.
Let us now consider a prior  request. A  request scans all the nodes between the
 pointer and the sentinel. None of the pop requests will see the updated  pointer
by the last request because their pass points are before this event. Thus, they have no
way of knowing about the existence of the last request. Since the execution of the first 
requests is linearizable, an execution with the  push request is also linearizable
because it takes effect at the end (and will appear last in the equivalent sequential order). 

Let us now consider the last request to be a  operation. A  operation writes
to any shared location only after its pass point. Before its pass point, it does not do
any writes, and thus all other requests are oblivious of it. 
Thus, we can remove the last request, and the responses of the first  requests will remain the same.
Let us now consider an execution fragment consisting of the first  requests. It is equivalent to
a linearizable execution, . This execution is independent of the  request. 

Now, let us try to create a linearizable execution, , which has an event corresponding
to the last request. Since the linearizable execution is sequential, let us represent the request
and response of the last  operation by a single event, . 
Let us try to modify  to create . Let the sequential execution corresponding
to  be .

Now, it is possible that  could have read the  pointer long ago, and
is somewhere in the middle of the stack. In this case, we cannot assume that  is the last
request to execute in the equivalent linearizable execution. Let the state of the stack before the 
 reads the top pointer be . The state  is independent of the  request.
Also note that, all the operations that have arrived after the  operation have read the  pointer, and 
overlap with the  operation. The basic rule of  states that, if any operation  
precedes  then  should precede  in the equivalent sequential execution also. Whereas, in case 
the two operations overlap with each other, then their relative order is undefined and any ordering of these 
operations is a valid ordering~\cite{artOfMulti}. 

In this case, we have two possibilities: (I)  returns the node that it had read as the top pointer as an output
of its  operation, or (II) it returns some other node. 

\noindent \underline{Case I:} In this case, we can consider the point at which  reads the top pointer as the point
at which it is {\em linearized}.  in this case reads the stack top, and pops it.

\noindent \underline{Case II:} In this case, some other request, which is concurrent must have popped the node that
 read as the top pointer. Let  return node  as its return value. This node must be between the top pointer
that it had read (node ), and the beginning of the stack. Moreover, while traversing the stack from 
to ,  must have found all the nodes in the way to be marked. At the end it must have found  to be unmarked,
or would have found  to be the end of the stack (returns exception).

Let us consider the journey for  from  to . Let  be the last node before  that has been
marked by a concurrent request, . We claim that if  is linearized right after , and the rest of the
sequences of events in  remain the same, we have a linearizable execution (). 

Let us consider request  and its position in the sequential execution, . At its point of
linearization, it reads the top of the stack and returns it (according to ). This node 
is the successor of . At that point  becomes the top of the stack. At this position, if we insert
 into , then it will read and return  as the stack top, which is the correct value. Subsequently,
we can insert the remaining events in  into the sequential execution. They will still return the same set
of values because they are unaffected by  as proved before. 

This proof can be trivially extended to take cleanup operations into account. 
\end{proof}







\section{Conclusion}
The crux of our algorithm is the  routine, which ensures that the size of the 
stack never grows beyond a predefined factor, . This feature allows for
a very fast  operation, where we need to find the first entry from the top of the
stack that is not marked. This optimization also allows for an increased amount of parallelism, and
also decreases write-contention on the  pointer because it is not updated by  operations. 
As a result, the time 
per  operation is very low. The  operation is also designed to be very fast. It simply
needs to update the  pointer to point to the new data. To provide wait-free guarantees
it was necessary to design a  function that is slow.
Fortunately, it is not invoked for an average of  out of  invocations of  and . 
We can tune the frequency of the  operation by varying
the parameter,  (to be decided on the basis of the workload). 


























\vspace{-2mm}
\bibliographystyle{splncs03}
\begin{thebibliography}{10}
\providecommand{\url}[1]{\texttt{#1}}
\providecommand{\urlprefix}{URL }

\bibitem{arrayBased}
Afek, Y., Gafni, E., Morrison, A.: Common2 extended to stacks and unbounded
  concurrency. Distributed Computing  20(4),  239--252 (2007)

\bibitem{DECS}
Bar-Nissan, G., Hendler, D., Suissa, A.: A dynamic elimination-combining stack
  algorithm. In: Principles of Distributed Systems, pp. 544--561. Springer
  (2011)

\bibitem{restrictedStack}
David, M., Brodsky, A., Fich, F.: Restricted stack implementations. In:
  Fraigniaud, P. (ed.) Distributed Computing, Lecture Notes in Computer
  Science, vol. 3724, pp. 137--151. Springer Berlin Heidelberg (2005)

\bibitem{timestamp}
Dodds, M., Haas, A., Kirsch, C.M.: A scalable, correct time-stamped stack
  (2014)

\bibitem{newUniversal}
Fatourou, P., Kallimanis, N.D.: A highly-efficient wait-free universal
  construction. In: SPAA (2011)

\bibitem{flatCombining}
Hendler, D., Incze, I., Shavit, N., Tzafrir, M.: Flat combining and the
  synchronization-parallelism tradeoff. In: Proceedings of the 22nd ACM
  symposium on Parallelism in algorithms and architectures. pp. 355--364. ACM
  (2010)

\bibitem{WaitFreeSharedCounter1}
Hendler, D., Kutten, S.: Constructing shared objects that are both robust and
  high-throughput. In: Distributed Computing, pp. 428--442. Springer (2006)

\bibitem{WaitFreeSharedCounter2}
Hendler, D., Kutten, S., Michalak, E.: An adaptive technique for constructing
  robust and high-throughput shared objects-technical report (2010)

\bibitem{LockFree}
Hendler, D., Shavit, N., Yerushalmi, L.: A scalable lock-free stack algorithm.
  In: Proceedings of the Sixteenth Annual ACM Symposium on Parallelism in
  Algorithms and Architectures. pp. 206--215. SPAA '04, ACM, New York, NY, USA
  (2004)

\bibitem{oldUniversal}
Herlihy, M.: Wait-free synchronization. ACM Trans. Program. Lang. Syst.  13(1),
   124--149 (Jan 1991)

\bibitem{artOfMulti}
Herlihy, M., Shavit, N.: The Art of Multiprocessor Programming. Elsevier (2012)

\bibitem{linearizability}
Herlihy, M.P., Wing, J.M.: Linearizability: A correctness condition for
  concurrent objects. ACM Trans. Program. Lang. Syst.  12(3),  463--492 (Jul
  1990)

\bibitem{michaelScottLocked}
Michael, M.M., Scott, M.L.: Nonblocking algorithms and preemption-safe locking
  on multiprogrammed shared memory multiprocessors. Journal of Parallel and
  Distributed Computing  51(1),  1 -- 26 (1998)

\bibitem{combiningFunnels}
Shavit, N., Zemach, A.: Combining funnels: a dynamic approach to software
  combining. Journal of Parallel and Distributed Computing  60(11),  1355--1387
  (2000)

\bibitem{CopingWithPara}
Treiber, R.K.: Systems programming: Coping with parallelism. International
  Business Machines Incorporated, Thomas J. Watson Research Center (1986)

\end{thebibliography}

\newpage
\section* {\textbf{Appendices of A Wait-Free Stack}}
\begin{appendix}

\section{Asymptotic Worst-Case Time Complexity }
Let us now consider the asymptotic worst-case time complexity of the ,  and  methods
in terms of the number of concurrent threads in the system (), the actual size of the
stack() and the parameter . 

\subsection{The  method}
The time complexity of the  method is the same as that of the
 function. The  function finds the  
request with the minimum phase number, which requires  steps. 
After having found the request with the minimum phase number, it calls 
the  function. The  function contains a  
loop. In the worst case this  loop might execute  times. Now, when 
we look into the body of this  loop, everything except the call to 
the  function has O(1) time complexity. The  
function contains two loops. The first is a  loop, which traverses 
the stack from the top to the point it finds the desired node. In the 
worst possible case, this loop might end up traversing the complete stack.
We do not allow the size of the stack to increase by more than 
a factor of  as compared to , the worst case time complexity of this loop is therefore
O(). 
The other loop in the function is a  loop, with time complexity O(W). 
So, the worst case time complexity of the  function is O() 
and therefore, the worst case time complexity of the clean function is O().
The high time complexity of this method is an achilles heel of our algorithm; hence, we
are working on reducing its complexity as well as practical run time.
However, it should be noted that this function is meant to be called infrequently (1 in
 times). 


\subsection{The  method}
In the  method, everything except the  loop and the call to the 
 function take O(1) time. The  loop is iterated over till 
the time an unmarked mode is encountered. In our algorithm, as soon as  
consecutive nodes get marked, we issue a  request for it and at 
any point of time there can be at most   requests in the system. 
Thus after having traversed at most  nodes, a  request is assured to 
find an unmarked node. Now, if we analyze the  method, 
in the worst case scenario, the  loop inside the function will be iterated over 
 times but the  method will only be called at most once. In fact, the  
method is called only once for a group of  operations, and therefore, the worst case 
time complexity of the  function, which is O(), will be incurred very infrequently
(1 in ). 
Nevertheless the worst case time complexity of the  operation is O(), and the
amortized time complexity (across  pop operations is . 

\subsection{The  method \label{push_time_complexity}}
The time complexity of the  method is the same as that of the  function. 
Since the  function is supposed to find the request with the least phase number, 
it takes at least O() time. After having found the request with the minimum 
phase number, the  function calls the  function. Note that for any 
 request, the maximum number of times the  loop in the  
function could possibly execute is of O(). Also note that everything inside the  loop, 
except the call to the  function requires only a constant amount of 
time for execution. If the index of the newly pushed node is not a multiple of 
, the 's time complexity is O(1), and therefore the time complexity
of the  operation is O(), but if this is not the case, the time complexity 
of the  function becomes dependent on the time 
complexity of the  function, which is O() in the worst case. 

All our methods: ,  and  are bounded wait-free.

\section{Background}
\label{sec:back}

A  is a data structure that provides  and  operations with ((Last-in-First-Out) semantics.  A
data structure is said to respect LIFO semantics, if the last element inserted is the first to be removed.

\subsection{Correctness}
\label{subsec:linearizability}
The most popular correctness criteria for a concurrent shared object is {\em
linearizability}~\cite{linearizability}. Let us define it formally.

Let us define two kinds of events in a
method call namely {\em invocations (inv)} and {\em responses (resp)}. A
chronological sequence of {\em invocations (inv)} and {\em responses (resp)}
events in the entire execution is known as a {\em history}.  Let a matching
invocation-response pair with a sequence number  be referred to as request
. Note that in our system, every invocation has exactly one matching
response.  A request  precedes request , if
's response comes before 's invocation.  This is denoted by  
. A history, , is said to be sequential if an invocation is immediately
followed by its response. A subhistory  is the subsequence of 
containing all the events of thread . Two histories,  and , are
equivalent if for every thread ,   . 
A complete history - {\em
complete(H)} is a history that does not have any pending invocations. 
The
{\em sequential specification} of an object constitutes of the set of all sequential
histories that are correct. A sequential history is {\em legal} if for every object
x,  is in the sequential specification of x. 


A history  is linearizable if {\em complete(H)} is equivalent to a legal
sequential history, . Additionally, if    in
{\em complete(H)}, then    in S also. Alternatively we can say,
linearizability ensures that within the execution interval of every operation
there is a point, called the linearization point, where the operation seems to
take effect instantaneously and the effect of all the operations on the object
is consistent with the object's sequential specification. 

\subsection{Progress}
\label{subsec:progress}

Generally, there are two kinds of implementations for a concurrent object:
 and -. Blocking algorithm use locks. Approaches
that protect critical sections with locks unnecessarily limit parallelism
and are known to be inefficient.


In comparison non-blocking implementations can prove to be much faster.
Such algorithms rely on atomic primitives such as 
compare-And-Set(CAS), LL/SC, and getAndIncrement. They do not have
critical sections.
In this context,  lock-freedom is defined as a property that ensures
that at any point of time at least one thread makes progress.
Or in other words, the system as a whole is always making progress. They
can still have problems of starvation.

Wait-free algorithms provide starvation freedom in addition
to being lock-free. They ensure that every process completes
its operation in a finite number of steps. The wait-free algorithms
have a notion of inherent {\em fairness}, where {\em fairness} measures the degree of 
imbalance across different threads. We quantify fairness as the ratio of the average number
of operations completed by an thread divided by the number of operations completed by the fastest
thread. Figure~\ref{fig:fairness} shows a comparison of the fairness
of our wait-free stack  with the lock-free stack  in~\cite{LockFree} 
and the locked stack in~\cite{michaelScottLocked} . 
For the  version, the average {\em fairness} is around 80\%, whereas for  the {\em fairness} 
goes as low as 50\%, and for , it even drops to 25\%.
Also, as shown in figure ~\ref{fig:pdfLF} and ~\ref{fig:pdfWF},
in the case of , almost all the threads have completed more than 90\% of their work,
whereas for  only 11 out of 64 threads have completed more than 90\% of their work
and for some threads the percentage of work done is as low as 40\% only.


\begin{figure*}[!htb]
\begin{center}
\begin{tabular}{cc}

\begin{minipage}{.33\textwidth}
\includegraphics[width=0.99\textwidth]{fairness}
\caption {Fairness \label{fig:fairness} }
\end{minipage}

\begin{minipage}{.33\textwidth}
\includegraphics[width=0.99\textwidth]{pdfLockfree}
\caption {Operations done by various threads : Lock-free \label{fig:pdfLF} }
\end{minipage}

\begin{minipage}{.33\textwidth}
\includegraphics[width=0.99\textwidth]{pdfwaitfree}
\caption {Operations done by various threads : Wait-free\label{fig:pdfWF} }
\end{minipage}

\end{tabular}
\end{center}
\end{figure*}



\section{Proof of Correctness}

\begin{lemma}
Every  request is inserted at Line~\ref{line:pushcas} at most once.
\label{lemm:atmost}
\end{lemma}

\begin{proof}
To the contrary, let us assume that the same request is inserted at least twice in Line~\ref{line:pushcas}.
Let us consider the sequence of steps that need to take place. 
\begin{description}
\item [Step 0:] Read the value of  and , and observe that . 
\item [Step 1:] We read the status as \START in Line~\ref{line:ifdone}.
\item [Step 2:] The CAS succeeds in Line~\ref{line:pushcas}.
\item [Step 3:] Some thread reads {\em next  null} in Line~\ref{line:nextnonnull} ( function).
\item [Step 4:] The status of the node is updated to \DONE by some thread in Line~\ref{line:announce}.
\item [Step 5:] The top pointer is changed in Line~\ref{line:updatetop}.
\end{description}

Let us now explain the steps and mention why these steps need to be performed
in a sequence (not necessarily by the same thread). To insert any node in
Line~\ref{line:pushcas} it is necessary to perform steps 0, 1 and 2 because to
reach Line~\ref{line:pushcas}, it is necessary to satisfy the condition of the
{\em if} statement in Line~\ref{line:ifdone}.  At this point, the 
pointer has been updated, and the  pointer has not been updated.  It is
not possible to insert any other request till the  pointer does not
become . This is only possible when we update the  pointer. To
update the  pointer some thread -- either the thread that is doing the
 operation, or some other thread --  needs to successfully perform the
 operation. This can only be achieved if a thread executes Lines
~\ref{line:nextnonnull} to ~\ref{line:updatetop}, or in other words, performs steps 3, 4,
and 5. Before the  pointer is updated in Line~\ref{line:updatetop},
another concurrent  request cannot be successful because two 
requests cannot simultaneously perform a successful CAS operation in step 2.  

Now we have proved that if any  operation has successfully completed step
2 (performed the CAS on the  pointer), then till steps 3, 4, and 5 are
performed no other  request can be successful. This means that between
any two successful  operations, the status of the request needs to be
changed (step 4).  Let us now assume that two  requests for the same node
are successful. Let the request that performs step 2 first be , and let
the other request be . We denote this fact as: . 

 must read a different value of the stack top in step 0. Otherwise, it
will find  to be non-null and it will not proceed beyond step 0.
Subsequently, it will try to read the status of the request in step 1.  Note
that this step is preceded by step 4 of . Thus  will read the status
to \DONE, and it will not be able to proceed to step 2. Consequently, 
will not be able to do the  operation done by  once again. 

Hence, the lemma stands proved.
\end{proof}

\begin{lemma}
A  request always adds an entry to the top of the stack in Line~\ref{line:pushcas} in
a bounded number of steps. 
\label{lemm:atleast}
\end{lemma}

\begin{proof}
Let us assume that a  request,  never gets fulfilled. This can
happen because it either fails the  conditions in Lines~\ref{line:notlast} and \ref{line:nextnull}, 
or the CAS operation in Line~\ref{line:pushcas}. This can only happen if some other 
request makes progress. Now, let us assume that  has the least phase
number out of all the  requests that remain unfulfilled for an unbounded
amount of time. 

Since  has the least phase number out of all the unfulfilled requests, all
other request with a lower phase number must have gotten fulfilled. This means
that there is a point of time at which  has the least phase in the 
array. At this point all the threads must be helping  to complete its request.
One of the threads needs to perform a successful CAS in Line~\ref{line:pushcas}. Either that thread
or some other thread can update the  pointer. In this manner, request  will
get satisfied. 

Hence, it is not possible to have a request,  that waits for an infinite amount
of time to get fulfilled. 
\end{proof}

\begin{theorem}
A  request adds an entry only once to the stack in a bounded
number of steps. Futhermore, if we
just consider the  pointers,  the stack 
is always a linked list without duplicate nodes. 
Thus, the  operation is lock-free.
\end{theorem}

\begin{proof}
Lemma~\ref{lemm:atmost} and Lemma~\ref{lemm:atleast} prove that an entry is added
only once (in a bounded number of steps).
Secondly, we are allowed to modify the  pointer of a node only once.
It cannot only point to another node. Each node points to another node that is pushed
to the stack after it because steps 2-5 are executed in sequence. Thus the stack
at all times has a structure similar to a linked list. The end of the linked list
is the stack top. The  method does not touch the  pointer; hence, this
property is maintained.
\end{proof}



\begin{lemma}
Every  operation pops just one element or returns an EmptyStackException.
\label{lemm:poponce}
\end{lemma}

\begin{proof}
We start at the stack top (), and proceed towards the
bottom of the stack. If we get any unmarked node, then we mark it. After marking a node
the  operation is over. Note that there is no helping in the case of a  
operation. Hence, other threads do not work on behalf of a thread. As a result only
one node is marked (or popped). If we are not able to mark a node then we return
an EmtpyStackException. 
\end{proof}

\section{The  Method}




Let us consider the  method first. It is called by the  method in Line~\ref{line:callclean}.
The aim of the  method is to clean a set of  contiguous entries in the list (indexed by 
the  pointers). Let us start out by defining some terminology. Let us define a range of  
contiguous entries, which has
four distinguished nodes (see Figure~\ref{fig:rangewa}).

\begin{figure}[!htb]
\begin{center}
\includegraphics[width=1.0\columnwidth]{rangew}
\caption{A range of  entries \label{fig:rangewa} }
\end{center}
\end{figure}

A range starts with a node termed the , whose index is a multiple of . Let us now define
 as . The node at the end of a range is . Its index is equal to 
. Let us now define a node  such that . 
Note that for a given range, the  and  nodes are fixed, whereas the  and
 nodes keep changing.  is the base of another range, and its index is
a multiple of . 

The  and the  methods call the function . The  method calls it when
it pushes a node whose index is a multiple of . This is a valid . It walks back 
and increments the counter of the  node of the previous range. We ensure that only one thread
(out of all the helpers) does this in Line~\ref{line:onethread}. Similarly, in the  function,
whenever we mark a node, we call the  function. Since the  function does not
have any helpers, only one thread per node calls the  function. Now, inside
the  function, we increment the counter of the  node. Once, a thread increments it to
 ,
it invokes the  function. Since only one thread will increment the counter to , only one thread
will invoke the  function for a range. 



\begin{algorithm}
\small
\SetAlgoLined
\textbf{class DeleteRequest}{}\\
		\hspace{5mm} \\
		\hspace{5mm} \\
		\hspace{5mm} \\
        \hspace{5mm}  \\	

\vskip 2mm
AtomicReferenceArrayDeleteRequest allDeleteRequests

\caption{ } \label{alg:deleteclasses}
\end{algorithm}



\begin{algorithm}
\small
\SetAlgoLined
\textbf{clean}(, ){}\\
  ()\\
    DeleteRequest(, , , ) \\
[]    \label{line:alldel}\\
()\\


\textbf{helpDelete}(){}\\
			(, )    \{ ,   ,  = ,
 = \textbf{true} \} \\
			\If{()  (  )}{
				break
			}
			() \\
			\If{} {
				
			}
	
\textbf{uniqueDelete}(){}\\
		\While{}
		{
			  ()\\
			\If{! \label{line:deluniquepending} }
			{
				\If{}
				{
					  () ? . (,
) :
\textbf{true} \label{line:cleanCAS}\\
					()\\
					\If{} {
						
					}
				}
			}
		\Else{
				()
			}
		}
\caption{, , and  methods} \label{alg:clean}
\end{algorithm}
	
\normalsize
Let us now consider the , , and  functions. Their functionality at a high level
is very similar to the  and  methods.  Here, we first create a 
that has four fields:  (similar to phase in ), ,  (whether the delete
has been finished or not), and  the value of the  node. Akin to the  function,
we add the newly created  to a global array of s in Line~\ref{line:alldel}.
Subsequently, we call the  function. This function finds a pending request with the minimum phase
in the array , and returns the request as . Subsequently, we invoke .

Note that at this stage it is possible for multiple threads to read the same value of the request with the 
minimum phase number. It is also possible for different sets of threads to have found different requests
to have the minimum phase. For example, if a request with phase 2 () got added to the array before the request with
phase 1 (), then a set of threads might be trying to perform  on , and another set might
be trying to perform  on . Our aim in the  function is to ensure that only
one set goes through to the next stage. It takes two arguments:  (request) and  (phase number).

We adopt a strategy similar to the one adopted in the function . We define a global atomic
variable, . If a delete is not pending (Line~\ref{line:deluniquepending}) 
on , we read its contents, and try to perform a CAS operation on it. We try to atomically
replace its current contents with the argument, . Note that at this stage, only one set of threads
will be successful. Beyond this point, all the threads will be working on the same DeleteRequest. 
They will then move on to call the  function that will finish the delete request. 
For threads that are not successful in the CAS operation, or threads that find that the current request
contained in  has a delete pending will also call the  function. This 
is required to ensure wait freedom. 


\begin{algorithm}
\small
\SetAlgoLined
\textbf{helpFinishDelete}(){}\\
		  () \label{line:currreada} \\
		\If{}
		{
			
		}
\vskip 2mm
			  	 \label{line:endidxa}\\

			/* Search for the request from the  */ \\
			   \\
		       \\	
			\While{  } {
				   \label{line:righta} \\
				   \label{line:lefta}
			}
			\If{} {
				 /* some other thread deleted the nodes */
			} \label{line:sentinela}
		
\vskip 2mm
		/* Find the target node */ \\
		    \label{line:targetstarta}\\
		\For{i=0; i ; i++}{
			  	
		} \label{line:targetenda}

\vskip 2mm
		/* Perform the CAS operation and delete the nodes */\\
		 \label{line:rightcasa}

\vskip 2mm
		/* Set the status of the delete request to not pending*/ \\
		  \textbf{false} \label{line:setpendinga}

\caption{The  method} \label{alg:helpfinishdeletea}
\end{algorithm}
\normalsize
Lastly, let us describe the  function in Algorithm~\ref{alg:helpfinishdeletea}. 
We first read the current request from the atomic variable,  in Line~\ref{line:currreada}. If
the request is not pending, then some other helper has completed the request, and we can return from the function.
However, if this is not the case, then we need to complete the delete operation. Our aim now is to find the ,
, and . We search for these nodes starting from the stack top.

The index of the  is equal to the index of the node in the current request () + . 
 is set to this value in Line~\ref{line:endidxa}.
Subsequently, in Lines~\ref{line:righta}--\ref{line:sentinela}, we start from the top of the stack, and keep traversing the 
pointers till the index of  is equal to . Once, the equality condition is satisfied
Lines~\ref{line:righta} and \ref{line:lefta} give us the pointers to the  and  respectively. If
we are not able to find the , then it means that another helper has successfully deleted the nodes. We can
thus return. 

The next task is to find the . The  is  hops away from the .
Lines~\ref{line:targetstarta}--\ref{line:targetenda} run a loop  times to find the target. Note that we shall never
have any issues with null pointers because  is set to  itself. Once, we have found the
target, we need to perform a CAS operation on the  pointer of the . We accomplish this in
Line~\ref{line:rightcasa}. If the  pointer of  is equal to , then we set it to .
This operation removes  entries (from  to ) from the list. The last step is to set the 
status of the  field in the current request () to false (see Line~\ref{line:setpendinga}).


\end{appendix}

\end{document}
