\section{Experiments}




\begin{table}[t]
    \centering\setlength{\tabcolsep}{6pt}
    \footnotesize
    \renewcommand{\arraystretch}{1.2}
    \resizebox{0.95\linewidth}{!}
    {
        \begin{tabular}{l|c|c|c}
        \shline
        Method &  & \#epochs  & AP \\
        \shline
        Conditional DETR-C5~\cite{conditional} & 0 & 36 & 39.4 \\ 
        Conditional DETR-C5~\cite{conditional} & 1 & 36 & 41.5\color[RGB]{17, 122, 101}{\textbf{(+2.1)}} \\ 
        Conditional DETR-C5~\cite{conditional} & 2 & 36 & 41.8\color[RGB]{17, 122, 101}{\textbf{(+2.4)}} \\ 
        \hline
        DAB-DETR-C5~\cite{dab} & 0 & 36 & 41.2 \\ 
        DAB-DETR-C5~\cite{dab} & 1 & 36 & 43.1\color[RGB]{17, 122, 101}{\textbf{(+1.9)}} \\ 
        DAB-DETR-C5~\cite{dab} & 2 & 36 & 43.5\color[RGB]{17, 122, 101}{\textbf{(+2.3)}} \\ 
        \hline
        Deformable-DETR~\cite{deformable} & 0 & 12 & 37.1 \\ 
        Deformable-DETR~\cite{deformable} & 1 & 12 & 42.3\color[RGB]{17, 122, 101}{\textbf{(+5.2)}} \\ 
        Deformable-DETR~\cite{deformable} & 2 & 12 & 42.9\color[RGB]{17, 122, 101}{\textbf{(+5.8)}} \\ 
        \hline
        Deformable-DETR~\cite{deformable} & 0 & 36 & 43.3 \\ 
        Deformable-DETR~\cite{deformable} & 1 & 36 & 46.8\color[RGB]{17, 122, 101}{\textbf{(+3.5)}} \\ 
        Deformable-DETR~\cite{deformable} & 2 & 36 & 46.5\color[RGB]{17, 122, 101}{\textbf{(+3.2)}} \\ 
        \shline
        \end{tabular}
    }
    \vspace{-2mm}
    \caption{\small{Results of plain baselines on COCO \texttt{val}.}
    }
    \label{tab:plain_results}
\end{table}
 
\subsection{Setup}

\vspace{1mm}
\noindent\textbf{Datasets and Evaluation Metrics.}
Our experiments are conducted on the MS COCO 2017 dataset~\cite{coco} and LVIS v1.0 dataset~\cite{lvis}. The COCO dataset consists of 115K labeled images for training and 5K images for validation. 
We report the detection results by default on the \texttt{val} subset. 
The results of our largest model evaluated on the \texttt{test-dev} (20K images) are also reported. 
LVIS v1.0 is a large-scale and long-tail dataset with 1203 categories for large vocabulary instance segmentation.
To verify the scalability of o-DETR, we further apply it to a large-scale object detection benchmark, namely Objects365~\cite{objects365}. 
There are 1.7M labeled images used for training and 80K images for validation in the Objects365 dataset. 
All results follow the standard mean Average Precision(AP) under IoU thresholds ranging from 0.5 to 0.95 at different object scales.

\vspace{1mm}
\noindent\textbf{Implementation Details.}
We incorporate our o-DETR into the current DETR-like pipelines and keep the training setting consistent with the baselines.
We adopt ATSS and Faster-RCNN as the auxiliary heads for  and only keep ATSS for .
More details about our auxiliary heads can be found in the supplementary materials. 
We choose the number of learnable object queries to 300 and set  to  by default.
For o-DINO-Deformable-DETR++, we use large-scale jitter with copy-paste~\cite{copypaste}.




\subsection{Main Results}
In this section, we empirically analyze the effectiveness and generalization ability of o-DETR on different DETR variants in Table~\ref{tab:plain_results} and Table~\ref{tab:main_results}.
All results are reproduced using mmdetection~\cite{mmdet}.
We first apply the collaborative hybrid assignments training to single-scale DETRs with C5 features.
Surprisingly, both Conditional-DETR and DAB-DETR obtain 2.4\% and 2.3\% AP gains over the baselines with a long training schedule.
For Deformable-DETR with multi-scale features, the detection performance is significantly boosted from 37.1\% to 42.9\% AP.
The overall improvements (+3.2\% AP) still hold when the training time is increased to 36 epochs.
Moreover, we conduct experiments on the improved Deformable-DETR (denoted as Deformable-DETR++) following~\cite{hybrid}, where a +2.4\% AP gain is observed.
The state-of-the-art DINO-Deformable-DETR equipped with our method can achieve 51.2\% AP, which is +1.8\% AP higher than the competitive baseline. 


We further scale up the backbone capacity from ResNet-50 to Swin-L~\cite{swin} based on two state-of-the-art baselines.
As presented in Table \ref{tab:main_results}, o-DETR achieves 56.9\% AP and surpasses the Deformable-DETR++ baseline by a large margin (+1.7\% AP).
The performance of DINO-Deformable-DETR with Swin-L can still be boosted from 58.5\% to 59.5\% AP.






\begin{table}[t]
    \centering\setlength{\tabcolsep}{6pt}
    \footnotesize
    \renewcommand{\arraystretch}{1.2}
    \resizebox{\linewidth}{!}
    {
        \begin{tabular}{l|c|c|c}
        \shline
        Method &  & \#epochs  & AP \\
        \shline
Deformable-DETR++~\cite{deformable} & 0 & 12 & 47.1 \\ 
        Deformable-DETR++~\cite{deformable} & 1 & 12 & 48.7\color[RGB]{17, 122, 101}{\textbf{(+1.6)}} \\
        Deformable-DETR++~\cite{deformable} & 2 & 12 & 49.5\color[RGB]{17, 122, 101}{\textbf{(+2.4)}} \\
\hline
        DINO-Deformable-DETR{}~\cite{dino} & 0 & 12 & 49.4  \\ 
        DINO-Deformable-DETR{}~\cite{dino} & 1 & 12 & 51.0\color[RGB]{17, 122, 101}{\textbf{(+1.6)}} \\ 
        DINO-Deformable-DETR{}~\cite{dino} & 2 & 12 & 51.2\color[RGB]{17, 122, 101}{\textbf{(+1.8)}} \\ 
        \hline 
        Deformable-DETR++{}~\cite{deformable} & 0 & 12 & 55.2 \\ 
        Deformable-DETR++{}~\cite{deformable} & 1 & 12 & 56.4\color[RGB]{17, 122, 101}{\textbf{(+1.2)}} \\
        Deformable-DETR++{}~\cite{deformable} & 2 & 12 & 56.9\color[RGB]{17, 122, 101}{\textbf{(+1.7)}} \\
        \hline
        DINO-Deformable-DETR{}{}~\cite{dino} & 0 & 12 & 58.5 \\ 
        DINO-Deformable-DETR{}{}~\cite{dino} & 1 & 12 & 59.3\color[RGB]{17, 122, 101}{\textbf{(+0.8)}} \\
        DINO-Deformable-DETR{}{}~\cite{dino} & 2 & 12 & 59.5\color[RGB]{17, 122, 101}{\textbf{(+1.0)}} \\ 
        \shline
        \end{tabular}
    }
    \vspace{-2mm}
    \caption{\small{Results of strong baselines on COCO \texttt{val}. Methods with  use 5 feature levels.  refers to Swin-L backbone.}
    }
    \label{tab:main_results}
\end{table}
 \begin{table*}[htbp]
    \centering
    \setlength{\tabcolsep}{6pt}
    \footnotesize
    \renewcommand{\arraystretch}{1.2}
    \resizebox{\linewidth}{!}
    {
        \begin{tabular}{l|l|c|c|c|cccccc}
        \shline
        Method  & Backbone & Multi-scale & \#query & \#epochs  & AP & AP & AP & AP & AP & AP \\
        \shline
        Conditional-DETR~\cite{conditional} & R50 & \xmark & 300 & 108 & 43.0 & 64.0 & 45.7 & 22.7 & 46.7 & 61.5 \\
        Anchor-DETR~\cite{anchordetr} & R50 & \xmark & 300 & 50 & 42.1 & 63.1 & 44.9 & 22.3 & 46.2 & 60.0 \\
        DAB-DETR~\cite{dab} & R50 & \xmark & 900 & 50 & 45.7 & 66.2 & 49.0 & 26.1 & 49.4 & 63.1 \\
        AdaMixer~\cite{adamixer} & R50 & \cmark & 300 & 36 & 47.0 & 66.0 & 51.1 & 30.1 & 50.2 & 61.8 \\
Deformable-DETR~\cite{deformable} & R50 & \cmark & 300 & 50 & 46.9 & 65.6 & 51.0 & 29.6 & 50.1 & 61.6 \\
        DN-Deformable-DETR~\cite{dn} & R50 & \cmark & 300 & 50 & 48.6 & 67.4 & 52.7 & 31.0 & 52.0 & 63.7 \\
        DINO-Deformable-DETR{}~\cite{dino} & R50 & \cmark & 900 & 12 & 49.4 & 66.9 & 53.8 & 32.3 & 52.5 & 63.9 \\ 
        DINO-Deformable-DETR{}~\cite{dino} & R50 & \cmark & 900 & 36 & 51.2 & 69.0 & 55.8 & 35.0 & 54.3 & 65.3 \\ 
        DINO-Deformable-DETR{}~\cite{dino} & Swin-L (IN-22K) & \cmark & 900 & 36 & 58.5 & 77.0 & 64.1 & 41.5 & 62.3 & 74.0 \\ 
        Group-DINO-Deformable-DETR~\cite{group} & Swin-L (IN-22K) & \cmark & 900 & 36 & 58.4 & - & - & 41.0 & 62.5 & 73.9 \\
        -Deformable-DETR~\cite{hybrid} & R50 & \cmark & 300 & 12 & 48.7 & 66.4 & 52.9 & 31.2 & 51.5 & 63.5 \\
-Deformable-DETR~\cite{hybrid} & Swin-L (IN-22K) & \cmark & 900 & 36 & 57.9 & 76.8 & 63.6 & 42.4 & 61.9 & 73.4 \\
        \hline
        \rowcolor[gray]{.9}
        o-Deformable-DETR & R50 & \cmark & 300 & 12 & 49.5 & 67.6 & 54.3 & 32.4 & 52.7 & 63.7 \\
        \rowcolor[gray]{.9}
        o-Deformable-DETR & Swin-L (IN-22K) & \cmark & 900 & 36 & 58.5 & 77.1 & 64.5 & 42.4 & 62.4 & 74.0 \\
        \hline
\rowcolor[gray]{.9}
        o-DINO-Deformable-DETR{} & R50 & \cmark & 900 & 12 & 52.1 & 69.4 & 57.1 & 35.4 & 55.4 & 65.9 \\
\rowcolor[gray]{.9}
        o-DINO-Deformable-DETR{} & Swin-L (IN-22K) & \cmark & 900 & 12 & 58.9 & 76.9 & 64.8 & 42.6 & 62.7 & 75.1 \\
        \rowcolor[gray]{.9}
        o-DINO-Deformable-DETR{} & Swin-L (IN-22K) & \cmark & 900 & 24 & 59.8 & 77.7 & 65.5 & 43.6 & 63.5 & 75.5 \\
        \rowcolor[gray]{.9}
        o-DINO-Deformable-DETR{} & Swin-L (IN-22K) & \cmark & 900 & 36 & 60.0 & 77.7 & 66.1 & 44.6 & 63.9 & 75.7 \\
        \hline
        \rowcolor[gray]{.9}
        o-DINO-Deformable-DETR++{} & R50 & \cmark & 900 & 12 & \textbf{52.1} & 69.3 & 57.3 & 35.4 & 55.5 & 67.2 \\
        \rowcolor[gray]{.9}
        o-DINO-Deformable-DETR++{} & R50 & \cmark & 900 & 36 & \textbf{54.8} & 72.5 & 60.1 & 38.3 & 58.4 & 69.6 \\
        \rowcolor[gray]{.9}
        o-DINO-Deformable-DETR++{} & Swin-L (IN-22K) & \cmark & 900 & 12 & \textbf{59.3} & 77.3 & 64.9 & 43.3 & 63.3 & 75.5 \\
        \rowcolor[gray]{.9}
        o-DINO-Deformable-DETR++{} & Swin-L (IN-22K) & \cmark & 900 & 24 & \textbf{60.4} & 78.3 & 66.4 & 44.6 & 64.2 & 76.5 \\
        \rowcolor[gray]{.9}
        o-DINO-Deformable-DETR++{} & Swin-L (IN-22K) & \cmark & 900 & 36 & \textbf{60.7} & 78.5 & 66.7 & 45.1 & 64.7 & 76.4 \\
        \shline
        \multicolumn{11}{l}{: 5 feature levels.}
        \end{tabular}
    }
    \vspace{-3mm}
    \caption{\small{Comparison to the state-of-the-art DETR variants on COCO \texttt{val}.}
    }
    \label{tab:coco_sota}
    \vspace{-0.1cm}
\end{table*} 

\begin{table}[t]
    \centering\setlength{\tabcolsep}{6pt}
    \footnotesize
    \renewcommand{\arraystretch}{1.3}
    \resizebox{\linewidth}{!}
    {
        \begin{tabular}{l|c|c|c|c}
        \shline
        \multirow{2}*{Method} & \multirow{2}*{Backbone} & enc. & \texttt{val} & \texttt{test-dev} \\
         & & \#params &  &  \\
        \shline
         HTC++~\cite{htc} & SwinV2-G~\cite{swinv2} & 3.0B & 62.5 & 63.1 \\
         DINO~\cite{dino} & Swin-L~\cite{swin} & 218M & 63.2 & 63.3 \\
         BEIT3~\cite{beit3} & ViT-g~\cite{vit} & 1.9B & - & 63.7 \\
         FD~\cite{fd} & SwinV2-G~\cite{swinv2} & 3.0B & - & 64.2 \\
         DINO~\cite{dino} & FocalNet-H~\cite{focalnet} & 746M & 64.2 & 64.3 \\
         Group DETRv2~\cite{groupv2} & ViT-H~\cite{vit} & 629M & - & 64.5 \\
         EVA-02~\cite{eva02} & ViT-L~\cite{vit} & 304M & 64.1 & 64.5 \\
         DINO~\cite{dino} & InternImage-G~\cite{intern} & 3.0B & 65.3 & 65.5 \\
\hline
        \rowcolor[gray]{.9}
        o-DETR & ViT-L~\cite{vit} & \textbf{304M} & \textbf{65.9} & \textbf{66.0} \\
        \shline
        \end{tabular}
    }
    \vspace{-2mm}
    \caption{Comparison to the state-of-the-art frameworks on COCO.}
    \vspace{-0.3cm}
    \label{tab:sota}
\end{table} \subsection{Comparisons with the state-of-the-art}
We apply our method with  to Deformable-DETR++ and DINO.
Besides, the quality focal loss~\cite{gfl} and NMS are adopted for our o-DINO-Deformable-DETR.
We report the comparisons on COCO \texttt{val} in Table \ref{tab:coco_sota}.
Compared with other competitive counterparts, our method converges much faster.
For example, o-DINO-Deformable-DETR readily achieves 52.1\% AP when using only 12 epochs with ResNet-50 backbone.
Our method with Swin-L can obtain 58.9\% AP for 1 scheduler, even surpassing other state-of-the-art frameworks on 3 scheduler.
More importantly, our best model o-DINO-Deformable-DETR++ achieves 54.8\% AP with ResNet-50 and 60.7\% AP with Swin-L under 36-epoch training, outperforming all existing detectors with the same backbone by clear margins.


To further explore the scalability of our method, we extend the backbone capacity to 304 million parameters.
This large-scale backbone ViT-L~\cite{vit} is pre-trained using a self-supervised learning method (EVA-02~\cite{eva02}).
We first pre-train o-DINO-Deformable-DETR with ViT-L on Objects365 for 26 epochs, then fine-tune it on the COCO dataset for 12 epochs.
In the fine-tuning stage, the input resolution is randomly selected between 4802400 and 15362400.
The detailed settings are available in supplementary materials.
Our results are evaluated with test-time augmentation. 
Table \ref{tab:sota} presents the state-of-the-art comparisons on the COCO \texttt{test-dev} benchmark.
With much fewer model sizes (304M parameters), o-DETR sets a new record of 66.0\% AP on COCO \texttt{test-dev}, outperforming the previous best model InternImage-G~\cite{intern} by +0.5\% AP.

We also demonstrate the best results of o-DETR on the long-tailed LVIS detection dataset.
In particular, we use the same o-DINO-Deformable-DETR++ as the model on COCO but choose FedLoss~\cite{centernet2} as the classification loss to remedy the impact of unbalanced data distribution.
Here, we only apply bounding boxes supervision and report the object detection results.
The comparisons are available in Table~\ref{tab:sota_lvis}.
o-DETR with Swin-L yields 56.9\% and 62.3\% AP on LVIS \texttt{val} and \texttt{minival}, surpassing ViTDet with MAE-pretrained~\cite{mae} ViT-H and GLIPv2~\cite{glipv2} by +3.5\% and +2.5\% AP, respectively.
We further finetune the Objects365 pretrained o-DETR on this dataset.
Without elaborate test-time augmentation, our approach achieves the best detection performance of 67.9\% and 71.9\% AP on LVIS \texttt{val} and \texttt{minival}.
Compared to the 3-billion parameter InternImage-G with test-time augmentation, we obtain +4.7\% and +6.1\% AP gains on LVIS \texttt{val} and \texttt{minival} while reducing the model size to 1/10.


\begin{table}[t]
    \centering\setlength{\tabcolsep}{6pt}
    \footnotesize
    \renewcommand{\arraystretch}{1.3}
    \resizebox{\linewidth}{!}
    {
        \begin{tabular}{l|c|c|c|c}
        \shline
        \multirow{2}*{Method} & \multirow{2}*{Backbone} & enc. & \texttt{val} & \texttt{minival} \\
         & & \#params &  &  \\
        \shline
         -DETR~\cite{hybrid} & Swin-L~\cite{swin} & 218M & 47.9 & - \\
         ViTDet~\cite{vitdet} & ViT-L~\cite{vit} & 307M & 51.2 & - \\
         ViTDet~\cite{vitdet} & ViT-H~\cite{vit} & 632M & 53.4 & - \\
         GLIPv2~\cite{glipv2} & Swin-H~\cite{swin} & 637M & - & 59.8 \\
         DINO~\cite{dino} & InternImage-G~\cite{intern} & 3.0B & 63.2 & 65.8 \\
         EVA-02~\cite{eva02} & ViT-L~\cite{vit} & 304M & 65.2 & - \\
\hline
        \rowcolor[gray]{.9}
        o-DETR & Swin-L~\cite{swin} & 218M & 56.9 & 62.3 \\
        \rowcolor[gray]{.9}
        o-DETR & ViT-L~\cite{vit} & \textbf{304M} & \textbf{67.9} & \textbf{71.9} \\
        \shline
        \end{tabular}
    }
    \vspace{-2mm}
    \caption{Comparison to the state-of-the-art frameworks on LVIS.}
    \vspace{-0.2cm}
    \label{tab:sota_lvis}
\end{table} 
\subsection{Ablation Studies}
Unless stated otherwise, all experiments for ablations are conducted on Deformable-DETR with a ResNet-50 backbone.
We choose the number of auxiliary heads  to 1 by default and set the total batch size to 32.
More ablations and analyses can be found in the supplementary materials.

\vspace{1mm}
\noindent\textbf{Criteria for choosing auxiliary heads.}
We further delve into the criteria for choosing auxiliary heads in Table \ref{tab:multi_head} and \ref{tab:heads_ablation}.
The results in Table \ref{tab:heads_ablation} reveal that \textit{any} auxiliary head with one-to-many label assignments consistently improves the baseline and ATSS achieves the best performance. 
We find the accuracy continues to increase as  increases when choosing  smaller than 3.
It is worth noting that performance degradation occurs when , and we speculate the severe conflicts among auxiliary heads cause this.
If the feature learning is inconsistent across the auxiliary heads, the continuous improvement as  becomes larger will be destroyed.
We also analyze the optimization consistency of multiple heads next and in the supplementary materials.
In summary, we can choose any head as the auxiliary head and we regard ATSS and Faster-RCNN as the common practice to achieve the best performance when .
We do not use too many different heads, \eg, 6 different heads to avoid optimization conflicts.






\begin{table}[t]
    \centering\setlength{\tabcolsep}{6pt}
    \footnotesize
    \renewcommand{\arraystretch}{1.3}
    \resizebox{\linewidth}{!}
    {
        \begin{tabular}{l|c|c|c|c|c}
        \shline
        \multirow{2}{*}{Method} & \multirow{2}{*}{} & Auxiliary & Memory & GPU & \multirow{2}{*}{AP}  \\
        & & head & (MB) & hours & \\         
        \shline
        Deformable-DETR++ & 0 & - & 12808 & 70 & 47.1 \\ 
        \hline
        -Deformable-DETR & 0 & - & 15307 & 104 & 48.4 \\
        \hline
        \cellcolor{gray!20}Deformable-DETR++ & \cellcolor{gray!20}1 & \cellcolor{gray!20}ATSS & \cellcolor{gray!20}13947 & \cellcolor{gray!20}86 & \cellcolor{gray!20}48.7 \\ 
        \hline
        Deformable-DETR++ & 2 & ATSS + PAA & 14629 & 124 & 49.0 \\ 
        \hline
        \cellcolor{gray!20}Deformable-DETR++ & \cellcolor{gray!20}2 & \cellcolor{gray!20}ATSS + Faster-RCNN & \cellcolor{gray!20}14387 & \cellcolor{gray!20}120 & \cellcolor{gray!20}\textbf{49.5} \\ 
        \hline
        \multirow{2}{*}{Deformable-DETR++} & \multirow{2}{*}{3} & ATSS + Faster-RCNN & \multirow{2}{*}{15263} & \multirow{2}{*}{150} & \multirow{2}{*}{\textbf{49.5}} \\ 
         & & + PAA & & & \\
\hline
        \multirow{3}{*}{Deformable-DETR++} & \multirow{3}{*}{6} & ATSS + Faster-RCNN & \multirow{3}{*}{19385} & \multirow{3}{*}{280} & \multirow{3}{*}{48.9} \\ 
         & & + PAA + RetinaNet & & & \\
         & & + FCOS + GFL & & & \\
\shline
        \end{tabular}
    }
    \vspace{-2mm}
    \caption{\small{Experimental results of  varying from 1 to 6.}
    }
    \label{tab:multi_head}
\end{table} \begin{table}[t]
    \centering\setlength{\tabcolsep}{6pt}
    \footnotesize
    \renewcommand{\arraystretch}{1.2}
    \resizebox{0.9\linewidth}{!}
    {
        \begin{tabular}{l|c|c|c|c}
        \shline
        Auxiliary head  & \#epochs  & AP & AP & AP \\
        \shline
        Baseline & 36 & 43.3 & 62.3 & 47.1 \\ 
        \hline
        RetinaNet~\cite{retina} & 36 & 46.1 & 64.2 & 50.1 \\
        Faster-RCNN~\cite{faster} & 36 & 46.3 & 64.7 & 50.5 \\
        Mask-RCNN~\cite{mask} & 36 & 46.5 & 65.0 & 50.6 \\
        FCOS~\cite{fcos} & 36 & 46.5 & 64.8 & 50.7 \\
        PAA~\cite{paa} & 36 & 46.5 & 64.6 & 50.7 \\
        GFL~\cite{gfl} & 36 & 46.5 & 65.0 & 51.0 \\
\cellcolor{gray!20}ATSS~\cite{atss} & \cellcolor{gray!20}36 & \cellcolor{gray!20}\textbf{46.8} & \cellcolor{gray!20}\textbf{65.1} & \cellcolor{gray!20}\textbf{51.5} \\
        \shline
        \end{tabular}
    }
    \vspace{-2mm}
    \caption{\small{Performance of our approach with various auxiliary one-to-many heads on COCO \texttt{val}.}
    }
    \label{tab:heads_ablation}
    \vspace{-3mm}
\end{table} 


\vspace{1mm}
\noindent\textbf{Conflicts analysis.} 
The conflicts emerge when the same spatial coordinate is assigned to different foreground boxes or treated as background in different auxiliary heads and can confuse the training of the detector. 
We first define the distance between head  and head , and the average distance of  to measure the optimization conflicts as:


where , , ,  refer to KL divergence, dataset, the input image, and class activation maps (CAM)~\cite{cam}. 
As illustrated in Figure~\ref{fig:cam}, we compute the average distances among auxiliary heads for  and the distance between the DETR head and the single auxiliary head for .
We find the distance metric is \textit{insignificant} for each auxiliary head when  and this observation is consistent with our results in Table~\ref{tab:heads_ablation}: the DETR head can be collaboratively improved with any head when .
When  is increased to 2, the distance metrics increase \textit{slightly} and our method achieves the best performance as shown in Table~\ref{tab:multi_head}.
The distance \textit{surges} when  is increased from 3 and 6, indicating severe optimization conflicts among these auxiliary heads lead to a decrease in performance. 
However, the baseline with 6 ATSS achieves 49.5\% AP and can be decreased to 48.9\% AP by replacing ATSS with 6 various heads. 
Accordingly, we speculate \textit{too many} diverse auxiliary heads, \eg, more than 3 different heads, exacerbate the conflicts.
In summary, optimization conflicts are influenced by the number of various auxiliary heads and the relations among these heads.

\begin{figure}[t] 
    \centering
    \includegraphics[width=0.9\linewidth]{cam_bar.pdf}
    \vspace{-0.1cm}
    \caption{The distance when varying  from 1 to 6.}
    \label{fig:cam}
\end{figure}
\begin{table}[t]
    \centering
\footnotesize
    \renewcommand{\arraystretch}{1.2}
    \resizebox{1.0\linewidth}{!}
    {
        \begin{tabular}{c|c|c|c|c|c}
        \shline
        aux head & pos queries & \#epochs & AP & AP & AP \\
        \shline
        \multirow{2}*{\xmark}  & \multirow{2}*{\xmark} & 12 & 37.1 & 55.5 & 40.0 \\
         & & 36 & 43.3 & 62.3 & 47.1 \\
        \hline
        \multirow{2}*{\cmark}  & \multirow{2}*{\xmark} & 12 & 41.6\color[RGB]{17, 122, 101}{\textbf{(+4.5)}} & 59.8 & 45.6 \\
         & & 36 & 46.2\color[RGB]{17, 122, 101}{\textbf{(+2.9)}} & 64.7 & 50.9 \\
        \hline
        \multirow{2}*{\xmark}  & \multirow{2}*{\cmark} & 12 & 40.5\color[RGB]{17, 122, 101}{\textbf{(+3.4)}} & 58.8 & 44.4 \\
         & & 36 & 45.3\color[RGB]{17, 122, 101}{\textbf{(+2.0)}} & 63.5 & 49.8 \\
        \hline
        \multirow{2}*{\cmark}  & \multirow{2}*{\cmark} & 12 & 42.3\color[RGB]{17, 122, 101}{\textbf{(+5.2)}} & 60.5 & 46.1 \\
         & & 36 & 46.8\color[RGB]{17, 122, 101}{\textbf{(+3.5)}} & 65.1 & 51.5 \\
        \shline
        \end{tabular}
    }
    \vspace{-3mm}
    \caption{``aux head'' denotes training with an auxiliary head and ``pos queries'' means the customized positive queries generation.
    }
    \label{tab:component}
    \vspace{-2mm}
\end{table} 
\vspace{1mm}
\noindent \textbf{Should the added heads be different?}
Collaborative training with two ATSS heads (49.2\% AP) still improves the model with one ATSS head (48.7\% AP) as ATSS is complementary to the DETR head in our analysis.
Besides, introducing a diverse and complementary auxiliary head rather than the same one as the original head, \eg, Faster-RCNN, can bring better gains (49.5\% AP).
Note that this is \textit{not contradictory} to above conclusion; instead, we can obtain the best performance with \textit{few different heads} () as the conflicts are insignificant, but we are faced with severe conflicts when using \textit{many different heads} ().



























\vspace{1mm}
\noindent\textbf{The effect of each component.}
We perform a component-wise ablation to thoroughly analyze the effect of each component in Table \ref{tab:component}. 
Incorporating the auxiliary head yields significant gains since the dense spatial supervision enables the encoder features more discriminative.
Alternatively, introducing customized positive queries also contributes remarkably to the final results, while improving the training efficiency of the one-to-one set matching.
Both techniques can accelerate convergence and improve performance.
In summary, we observe the overall improvements stem from more discriminative features for the encoder and more efficient attention learning for the decoder.

\begin{table}[t]
    \centering\setlength{\tabcolsep}{6pt}
    \footnotesize
    \renewcommand{\arraystretch}{1.2}
    \resizebox{1.0\linewidth}{!}
    {
        \begin{tabular}{l|c|c|c|c}
        \shline
Method &  & \#epochs & GPU hours & AP \\
\shline
        Deformable-DETR & 1 & 36 & 288 & 46.8 \\ 
        \hline
        Deformable-DETR & 0 & 50 & 333 & 44.5 \\
        Deformable-DETR & 0 & 100 & 667 & 46.0 \\ 
        Deformable-DETR & 0 & 150 & 1000 & 45.9 \\ 
        \shline
        \end{tabular}
}
    \vspace{-2mm}
    \caption{Comparison to baselines with longer schedule.}
    \label{tab:longer_schedule}
\end{table} \begin{table}[t]
    \centering\setlength{\tabcolsep}{6pt}
\footnotesize
    \renewcommand{\arraystretch}{1.2}
    \resizebox{1.0\linewidth}{!}
    {
        \begin{tabular}{l|c|c|c|c}
        \shline
        Branch & NMS &  &  &  \\
        \shline
        Deformable-DETR++ & \xmark & 47.1 & 48.7\color[RGB]{17, 122, 101}{\textbf{(+1.6)}} & 49.5\color[RGB]{17, 122, 101}{\textbf{(+2.4)}} \\
        ATSS & \cmark & 46.8 & 47.4\color[RGB]{17, 122, 101}{\textbf{(+0.6)}} & 48.0\color[RGB]{17, 122, 101}{\textbf{(+1.2)}} \\
        Faster-RCNN & \cmark & 45.9 & - & 46.7\color[RGB]{17, 122, 101}{\textbf{(+0.8)}} \\
        \shline
        \end{tabular}
    }
    \vspace{-2mm}
    \caption{Collaborative training consistently improves performances of all branches on Deformable-DETR++ with ResNet-50.}
    \vspace{-1mm}
    \label{tab:cotrain}
\end{table}
%
 
\vspace{1mm}
\noindent\textbf{Comparisons to the longer training schedule.}
As presented in Table \ref{tab:longer_schedule}, we find Deformable-DETR can not benefit from longer training as the performance saturates.
On the contrary, o-DETR greatly accelerates the convergence as well as increasing the peak performance.

\vspace{1mm}
\noindent\textbf{Performance of auxiliary branches.}
Surprisingly, we observe o-DETR also brings consistent gains for auxiliary heads in Table \ref{tab:cotrain}.
This implies our training paradigm contributes to more discriminative encoder representations, which improves the performances of both decoder and auxiliary heads.

\vspace{1mm}
\noindent\textbf{Difference in distribution of original and customized positive queries.}
We visualize the positions of original positive queries and customized positive queries in Figure~\ref{fig:query}.
We only show one object (green box) per image. 
Positive queries assigned by Hungarian Matching in the decoder are marked in red. 
We mark positive queries extracted from Faster-RCNN and ATSS in blue and orange, respectively.
These customized queries are distributed around the center region of the instance and provide sufficient supervision signals for the detector.

\vspace{1mm}
\noindent\textbf{Does distribution difference lead to instability?}
We compute the average distance between original and customized queries in Figure~\ref{fig:distance}.
The average distance between original negative queries and customized positive queries is significantly larger than the distance between original and customized positive queries.
As this distribution gap between original and customized queries is marginal, there is no instability encountered during training.

\begin{figure}[t]
    \begin{minipage}[t]{0.45\linewidth}
        \centering
        \includegraphics[width=1\textwidth]{query.pdf}
        \subcaption{Visualizations of queries.}
        \label{fig:query}
    \end{minipage}
    \hspace{2mm}
    \begin{minipage}[t]{0.45\linewidth}
        \centering
        \includegraphics[width=1\textwidth]{distance.pdf}
        \subcaption{Normalized distances.}
        \label{fig:distance}
    \end{minipage}
    \label{fig:distribution}
    \vspace{-0.2cm}
    \caption{
    Distribution of original and customized queries.}
    \vspace{-0.1cm}
\end{figure}



%
