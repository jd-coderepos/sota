\section{Experiments}

We conduct experiments on 4 datasets: PASCAL VOC 2012 (VOC12)~\cite{everingham2010pascal}, COCO~\cite{lin2014microsoft}, PF-PASCAL~\cite{ham2016proposal}, PASCAL 3D+~\cite{xiang2014beyond}. 
We test instance segmentation on VOC12 and COCO, and semantic correspondence on the other two.

\subsection{Datasets and metrics}

\textbf{COCO.} COCO contains 80 semantic categories. We follow the standard partition which includes train2017 (115K images) and val2017 (5K images) for training and validation. We also report our results on the test-dev split. During training, we only use the box annotations.

\textbf{VOC12.} VOC12 consists of 20 categories with a training set of around 10,500 images and a validation set of around 5,000 images. Around 1,500 images of the validation set contain the instance segmentation annotations.

\textbf{PF-PASCAL.} The PF-PASCAL dataset contains a selected subset of object-centric images from PASCAL VOC. It contains around 1,300 image pairs with 700 pairs for the training set and 300 pairs for the validation set, and 300 image pairs for the test sets respectively. There is only one conspicuous object in the middle of the image. Each image pair contain two intra-class objects.

\textbf{PASCAL 3D+.} PASCAL 3D+ contains the annotations of object poses, landmarks and 3D CAD models in addition to bounding boxes, and consists of 12 rigid categories where each has 3,000 object instances on average. We evaluate multi-object correspondence on PASCAL 3D+ dataset. The availability of both bounding boxes and landmarks, as well as other 3D information makes it an ideal dataset to evaluate multi-object semantic correspondence. We construct the benchmark on the 12 rigid categories of PASCAL 3D+ and follow the official VOC12 partitioning of the validation set, where images only containing the 8 non-rigid classes are removed. For training, we still preserve the full VOC12 training set and annotations (20 classes).

As PASCAL 3D+ does not provide image pairs, we need to generate image pairs and keypoint pairs on PASCAL for the correspondence evaluation. We enumerate all pairwise combinations of two images on the PASCAL 3D+ validation set. For any pairwise images, if both contain at least one intra-class object in common, we mark them as matched and keep this pair for evaluation. The second step is to generate the sparse correspondence ground truths on top of the matched image pairs using the provided keypoints. For any pairwise images, we find all combinations of intra-class object pairs and use the keypoint pairs between these object pairs as the correspondence ground-truth. Due to occlusion, some keypoints may be missing and are ignored during the evaluation. Note that we also ignore any pairwise objects where the difference between their 3D orientations is greater than 60 degrees, since a large orientation gap often results in very few valid keypoint pairs.

\textbf{Multi-object correspondence metric.} Similar to object detection, we introduce a precision-recall based metric with average precision (AP). We assume that there is a confidence associated with each predicted correspondence, and we define it as the multiplication of the pairwise box confidence in this work. This allows us to compute precision and recall by defining true positive (), false positive () and false negative (). Since PASCAL 3D+ only provides sparse correspondence ground truths, the challenge here is to correctly ignore some of the correspondence predictions that are far away from any ground truth but are correct. To this end, we follow a keypoint transfer setting where we always define a \textit{source} side  and a \textit{target} side  for any pairwise objects. Given a ground truth , a predicted correspondence  and a distance threshold :

\begin{small}
\vspace{-0.2cm}
6pt]
    \text{FP}_i &= \frac{\sum_j \mathbbm{1}[|\bm{p}_i^s - \bm{g}_j^s| \leq \alpha] \times \mathbbm{1}[|\bm{p}_i^t - \bm{g}_j^t| > \alpha]}{\sum_j \mathbbm{1}[|\bm{p}_i^s - \bm{g}_j^s| \leq \alpha] + \mathbbm{1}[\sum_j \mathbbm{1}[|\bm{p}_i^s - \bm{g}_j^s| \leq \alpha]=0]}\
\end{small}\\
We term the average precision as  where  is a threshold relative to the box diagonal. We then define the final AP as: .



\begin{table*}[t]
\centering
\resizebox{\textwidth}{!}{
\addtolength{\tabcolsep}{3pt}
\begin{tabular}{lccccccccccc}
\toprule
Method & Backbone & Type & Arch  & Sup & FPS &  &  &  &  &  &  \\
\midrule
MNC~\cite{dai2016instance} & ResNet-101 & Two-stage & MNC & Mask & 2.8 & 24.6 & 44.3 & 24.8 & 4.7 & 25.9 & 43.6 \\
FCIS~\cite{li2017fully} & ResNet-101 & Two-stage & FCIS & Mask & 6.6 &  29.2 & 49.5 & - & 7.1 & 31.3 & 50.0\\
Mask R-CNN~\cite{he2017mask} &  ResNet-101 & Two-stage & Mask R-CNN & Mask & 5 &  35.7 & 58.0 & 37.8 & 15.5 & 38.1 & 52.4 \\
Mask R-CNN~\cite{he2017mask} &  ResNeXt-101 & Two-stage & Mask R-CNN & Mask & 5 &  37.1 & 60.0 & 39.4 & 16.9 & 38.9 & 53.5 \\
YOLACT-550~\cite{bolya2019yolact} &  ResNet-50 & One-stage & YOLACT & Mask & \textbf{45} & 28.2 & 46.6 & 29.2 & 9.2 & 29.3 & 44.8 \\
YOLACT-700~\cite{bolya2019yolact} &  ResNet-101 & One-stage & YOLACT & Mask & 23.4 & 31.2 & 50.6 & 32.8 & 12.1 & 33.3 & 47.1 \\
PolarMask~\cite{xie2020polarmask} &  ResNet-101 & One-stage & PolarMask & Mask & 12.3 & 32.1 & 53.7 & 33.1 & 14.7 & 33.8 & 45.3 \\
YOLACT-550++~\cite{bolya2020yolact++} & ResNet-50-DCN & One-stage & YOLACT++ & Mask & 33.5 & 34.1 & 53.3 & 36.2 & 11.7 & 36.1 & 53.6 \\
YOLACT-550++~\cite{bolya2020yolact++} & ResNet-101-DCN & One-stage & YOLACT++ & Mask & 27.3 & 34.6 & 53.8 & 36.9 & 11.9 & 36.8 & 55.1 \\
SOLOv2~\cite{wang2020solov2} & ResNet-101-DCN & One-stage & SOLOv2 & Mask & 10.3 & \textbf{41.7} & \textbf{63.2} & \textbf{45.1} & \textbf{18.0} & \textbf{45.0} & \textbf{61.6} \\
\midrule
BBTP~\cite{hsu2019weakly} & ResNet-101 & Two-stgae & Mask R-CNN  & Box & 5 & 21.1 &  45.5  & 17.2   & 11.2 & 22.0 & 29.8\\
BoxInst~\cite{tian2021boxinst} & ResNet-101-DCN & One-stage & CondInst~\cite{tian2020conditional} & Box & - & 35.0 & 59.3 & 35.6 & 17.1 &37.2 & 48.9 \\
\textsc{DiscoBox} (Ours) & ResNet-50-DCN & One-stage & YOLACT++ & Box & \textbf{34.5} & 26.9 & 48.6 & 26.3 & 9.6 & 27.8 & 42.1 \\
\textsc{DiscoBox} (Ours) & ResNet-50 & One-stage & SOLOv2 & Box & 18.5 & 31.4 & 52.6 & 32.2 & 11.5 & 33.8 & 50.1 \\
\textsc{DiscoBox} (Ours) & ResNet-50 & One-stage & SOLOv2 & Box & 18.5 & 32.0 & 53.6 & 32.6 & 11.7 & 33.7 & 48.4 \\
\textsc{DiscoBox} (Ours) & ResNet-101-DCN & One-stage & SOLOv2 & Box & 10.3 & 35.8 & 59.8 & 36.4
& 16.9 & 38.7 & 52.1 \\
\textsc{DiscoBox} (Ours) & ResNeXt-101-DCN & One-stage & SOLOv2 & Box & 7.4 & \textbf{37.9} & \textbf{61.4} & \textbf{40.0} & \textbf{18.0} & \textbf{41.1} & \textbf{53.9} \\
\bottomrule
\end{tabular}
}
\vspace{0.05cm}
\caption{Main results on COCO.  indicates that the results are on the COCO validation 2017 split. The rest results are on COCO test-dev. \textsc{DiscoBox} with SOLOv2/ResNet-50 outperforms BBTP~\cite{hsu2019weakly} by 10.3\% on COCO validation 2017. Our best model achieves 37.9\% mAP on test-dev, which outperforms some competitive supervised methods such as Mask R-CNN in absolute performance.
}
\label{tab:coco_exp}
\end{table*}

\begin{table}[t]
\centering
\resizebox{\linewidth}{!}{
\begin{tabular}{lcccccccc}
\toprule
\textbf{Method} & \textbf{Backbone} & \textbf{Arch} &  &  &  &  \\
\midrule
SDI~\cite{khoreva2017simple} & VGG-16 & DeepLabv2 & - & 44.8 & - & 16.3 \\
BBTP~\cite{hsu2019weakly} & ResNet-101 & Mask R-CNN & 75.0 & 58.9 & 30.4 & 21.6 \\
Arun et al.~\cite{arun2020weakly} & ResNet-101 & Mask R-CNN & 73.1 & 57.7 & 33.5 & 31.2 \\
BoxInst~\cite{tian2021boxinst} & ResNet-50 & CondInst &- & 59.1 & - & 34.2 \\
BoxInst~\cite{tian2021boxinst} & ResNet-101 & CondInst & - & 61.4 & - & 37.0 \\
\textsc{DiscoBox} & ResNet-50-DCN & YOLACT++ & \textbf{75.2}& \textbf{63.6} & 41.6 & 34.1 \\
\textsc{DiscoBox} & ResNet-50 & SOLOv2 & 71.4 & 59.8 & 41.7 & 35.5 \\
\textsc{DiscoBox} & ResNet-101 & SOLOv2 & 72.8 & 62.2 & \textbf{45.5} & \textbf{37.5} \\
\bottomrule
\end{tabular}
}
\vspace{0.05cm}
\caption{Main results on the VOC12 validation set. \textsc{DiscoBox} outperforms all previous methods with state-of-the-art results.
}
\label{tab:voc_exp}
\end{table}

\subsection{Implementation details} \label{sec:exp_impl}

\textbf{Training.} We use stochastic gradient descent (SGD) for network optimization. For loss weights, we set , ,   as  on YOLACT++ and set , ,  as  on SOLOv2. Kindly refer to Appendix~\ref{sec:add_impl} for additional implementation details.

\subsection{Weakly supervised instance segmentation} \label{sec:wssc}

\textbf{Main results.} We evaluate instance segmentation on COCO and VOC12, with the main results reported in Tab.~\ref{tab:coco_exp} and~\ref{tab:voc_exp}, respectively. \textsc{DiscoBox} outperforms BBTP~\cite{hsu2019weakly} by  mAP on the COCO validation 2017 split with a smaller backbone (ResNet-50). \textsc{DiscoBox} also outperforms BoxInst~\cite{tian2021boxinst} which is the current state-of-the-art box-supervised method on both COCO and VOC12. Notably, BoxInst/ResNet-101-DCN also adopts BiFPN~\cite{tan2020efficientdet}, an improved variant of FPN~\cite{lin2017feature}. Fig.~\ref{fig:vis:inst} and Appendix~\ref{sec:add_vis} additionally visualize the instance segmentation results.

\begin{figure*}[t]
\centering
\includegraphics[width=\linewidth]{images/fig4.pdf}\\
\caption{Visualization of instance segmentation on COCO (YOLACT++/ResNet-50-DCN).}
\label{fig:vis:inst}
\vspace{-0.15cm}
\end{figure*}

\begin{figure*}[t]
\centering
\includegraphics[width=\linewidth]{images/fig5.pdf}
\caption{Visualization of multi-object semantic correspondence on PASCAL 3D+ (YOLACT++/ResNet-50-DCN).}
\label{fig:vis:corr}
\end{figure*}

\textbf{Analysis.} We perform ablation study on VOC12 with ,  and . The results in Tab.~\ref{tab:ablation} show consistent improvements from  and , demonstrating the benefit of the structured teacher. We also conduct sensitivity analysis with the loss weights on both instance segmentation (VOC12)\footnote{Here, the AP follows COCO evaluation: mean(AP@\{50,55,...,95\}).}
and semantic correspondence (PASCAL 3D+, see Sec.~\ref{sec:exp_corr}). The results in Fig.~\ref{fig:alpha} show that \textsc{DiscoBox} is not sensitive to weight changes.

\begin{table}[t]
\centering
\resizebox{\linewidth}{!}{
\addtolength{\tabcolsep}{1pt}
\begin{tabular}{ccccccccccc}
\toprule
 &  &  &   &  &  &  &  &  \\
\midrule
\checkmark & - & - & 43.3 & 18.3 & 17.0 & 42.1 & 18.0 & 17.3 \\ 
\checkmark & \checkmark & -  & 62.0 & 40.1 & 33.5 & 58.1 & 40.9 & 34.9  \\ 
\checkmark & \checkmark & \checkmark & \textbf{63.6} & \textbf{41.6} & \textbf{34.1} & \textbf{59.8} & \textbf{41.7} & \textbf{35.5}\\
\bottomrule
\end{tabular}
}
\vspace{0.05cm}
\caption{Ablation study on VOC12, where `y' denotes the results obtained by YOLOCT++/ResNet-50-DCN and `s' denotes the results obtained by SOLOv2/ResNet-50.}
\label{tab:ablation}
\end{table}

\begin{table}[]
\centering
\resizebox{\linewidth}{!}{
\begin{tabular}{lcccc}
\hline
Signal & Methods  & PCK@0.05 & PCK@0.1 & PCK@0.15 \\
\hline
none & PF~\cite{han2017scnet} & 31.4 & 62.5 & 79.5 \\
\hline
image-level & WeakAlign~\cite{rocco2018end} & 49.0 & 74.8 & 84.0 \\
image-level & RTNs~\cite{kim2018recurrent} & 55.2 & 75.9 & 85.2 \\
image-level & NC-Net~\cite{rocco2018neighbourhood} & 54.3 & 78.9 & 86.0 \\
image-level & DCC-Net~\cite{huang2019dynamic} & 55.6 & 82.3 & 90.5 \\
\midrule
mask & SF-Net~\cite{lee2019sfnet} & 53.6 & 81.9 & 90.6 \\
mask & DHPF~\cite{min2020learning} & 56.1 & 82.1 & 91.1 \\
\midrule
box & \textsc{DiscoBox} &  &  &  \\
\bottomrule
\end{tabular}
}
\vspace{0.05cm}
\caption{Results on PF-PASCAL. \textsc{DiscoBox} outperforms previous state-of-the-art methods on weakly supervised semantic correspondence without bells-and-whistles.}
\label{tab:pf-pascal}
\end{table}

\subsection{Weakly supervised semantic correspondence} \label{sec:exp_corr}

\textbf{PF-PASCAL (Object-Centric).} We first evaluate \textsc{DiscoBox} on PF-PASCAL~\cite{ham2016proposal} using YOLACT++/ResNet-50-DCN, with the main results presented in Tab.~\ref{tab:pf-pascal}. We do not  directly train the \textsc{DiscoBox} model on PF-PASCAL. Instead, we train it on the VOC12 training set, excluding those images that are present in the PF-PASCAL validation set. It is worth noting that many existing semantic correspondence methods can not be similarly trained on VOC12 without major changes, even though some of them do consider certain level of localization information such as attention. During inference, we use instance segmentation to obtain object masks, and use the structured teacher to produce dense pixel-wise correspondence by taking the masks as input. Our approach outperforms the previous weakly supervised semantic correspondence approaches with considerable margins. Such improvement can be attributed to three main factors: 1) The improved design of structured teacher which renders good correspondence quality at object-level. 2) The box-supervised learning framework which makes it possible to scale up the training using more data and obtain improved correspondence representation. 3) The high quality object localization as a result of the coupled learning framework that help to guide the correspondence.

\begin{figure}[t]
\vspace{-0.1cm}
\centering
\includegraphics[width=1.0\linewidth]{images/fig6.pdf}
\caption{Sensitivity analysis with the loss weights on instance segmentation (VOC12) and semantic correspondence (PASCAL 3D+). Analysis conducted on YOLACT++/ResNet-50-DCN.}
\label{fig:alpha}
\end{figure}

\textbf{PASCAL 3D+ (Multi-Object).} Finally, we benchmark \textsc{DiscoBox} and several baselines on PASCAL 3D+. Tab.~\ref{tab:nocc} lists the main results and Fig.~\ref{fig:vis:corr} visualizes some predicted correspondence. The comparing methods in Tab.~\ref{tab:nocc} are defined as follows: \textbf{Identity:} We align each pair of images only considering the positions of pixels. \textbf{SCOT:} A modified version of~\cite{liu2020semantic} by removing beam search and keeping their matching module on our RoI features. \textbf{\textsc{DiscoBox-}:} Our model trained on VOC12 without dense NCE loss, but using teacher during inference for correspondence. \textbf{\textsc{DiscoBox}:} Our full approach. We use YOLACT++/ResNet-50-DCN for all methods. Our method does not include beam search with the validation data and label~\cite{liu2020semantic}, and is therefore purely box-supervised. The results show the effectiveness of our proposed teacher and dense contrastive learning.

\begin{table}[]
\centering
\resizebox{\linewidth}{!}{
\addtolength{\tabcolsep}{2pt}
\begin{tabular}{lcccccc} 
\toprule
Methods & ~AP~ &  &  &  &  & \\ 
\midrule
Identity & 26.6 & 10.5 & 16.3 & 26.2 & 34.2 & 46.0  \\ 
SCOT~\cite{liu2020semantic} & 29.3 & 13.2 & 19.8 & 29.8 & 36.0 & 47.3  \\ 
\textsc{DiscoBox-} & 30.9 & 15.6  & 21.3 & 30.6 & 38.0 & 48.9 \\ 
\textsc{DiscoBox} & \textbf{31.7} & \textbf{15.8} & \textbf{21.4} & \textbf{31.8} & \textbf{39.5} & \textbf{50.3} \\
\bottomrule
\end{tabular}
}
\vspace{0.05cm}
\caption{Results of multi-object correspondence on PASCAL 3D+, where , , , , and  represent  with thresholds  relative to the box diagonal. AP is defined as .}
\label{tab:nocc}
\vspace{-0.2cm}
\end{table}