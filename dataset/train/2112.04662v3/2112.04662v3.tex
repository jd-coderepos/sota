

\documentclass[10pt,twocolumn,letterpaper]{article}

\usepackage[pagenumbers]{cvpr} 



\usepackage[pagebackref,breaklinks,colorlinks]{hyperref}
\usepackage{graphicx}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{booktabs}
 \usepackage{multirow}
 \usepackage{booktabs}
\usepackage{threeparttable}
\usepackage{color} 
\definecolor{Grey}{rgb}{0.5,0.5,0.5}      

\usepackage{algorithm}  
\usepackage{algorithmicx}  
\usepackage{algpseudocode} 
\renewcommand{\algorithmicensure}{\textbf{Output:}}

\usepackage[capitalize]{cleveref}
\crefname{section}{Sec.}{Secs.}
\Crefname{section}{Section}{Sections}
\Crefname{table}{Table}{Tables}
\crefname{table}{Tab.}{Tabs.}


\def\cvprPaperID{6316} \def\confName{CVPR}
\def\confYear{2022}


\begin{document}
\title{Dual Cluster Contrastive learning for Object Re-Identification}

\author{Hantao Yao, Changsheng Xu\\
National Laboratory of Pattern Recognition, Institute of Automation, CAS\\
{\tt\small hantao.yao@nlpr.ia.ac.cn}
}
\maketitle

\begin{abstract}
Recently, cluster contrastive learning has been proven effective for object ReID by computing the contrastive loss between the individual features and the cluster memory.
However, existing methods that use the individual features to momentum update the cluster memory will fluctuate over the training examples, especially for the outlier samples.  
Unlike the individual-based updating mechanism, the centroid-based updating mechanism that applies the mean feature of each cluster to update the cluster memory can reduce the impact of individual samples.   
Therefore, we formulate the individual-based updating and centroid-based updating mechanisms in a unified cluster contrastive framework, named Dual Cluster Contrastive framework (DCC), which maintains two types of memory banks: individual and centroid cluster memory banks.
Significantly, the individual cluster memory considers just one individual at a time to take a single step for updating.
The centroid cluster memory applies the mean feature of each cluster to update the corresponding cluster memory.
During optimization, besides the vallina contrastive loss of each memory, a cross-view consistency constraint is applied to exchange the benefits of two memories for generating a discriminative description for the object ReID.
Note that DCC can be easily applied for unsupervised or supervised object ReID by using ground-truth labels or the generated pseudo-labels. 
Extensive experiments on three benchmarks, \emph{e.g.,} Market-1501, MSMT17, and VeRi-776, under \textbf{supervised Object ReID} and \textbf{unsupervised Object ReID} demonstrate the superiority of the proposed DCC.
\end{abstract}


\section{Introduction}\label{sec:intro}
Object Re-identification (ReID), such as person ReID and vehicle ReID, aims to search the probe image from different camera-views, attracting increasing attention because of the growing demands in practical video surveillance.
Based on whether using the human-annotated labels, object ReID can be divided into supervised object ReID and unsupervised object ReID.
The supervised object ReID aims to infer a discriminative description with the annotated labels~\cite{Zhang_2020_CVPR, Chen_2021_ICCV, zhang2021person, xia2019second, chen2019mixed, quadruplet, large-margin-learning,he2019part,he2020multi,He_2021_ICCV,meng2020parsing}.
Since collecting the massive identity annotations is time-consuming and expensive, unsupervised object ReID infers the description with the pseudo-labels~\cite{Chen_2019_ICCV, Liu_2019_CVPR, zhong2018generalizing, fu2019self, Zhang_2019_ICCV, ge2020mutual,DBLP:conf/nips/Ge0C0L20,dai2021cluster,DBLP:conf/cvpr/ZhangG0021}, \emph{e.g.,} the pseudo-labels inferred by clustering methods from the unlabeled data are used for unsupervised ReID. 

Recently, contrastive learning has been widely exploited for unsupervised representation learning~\cite{DBLP:conf/nips/Ge0C0L20,DBLP:conf/icml/ChenK0H20,DBLP:conf/nips/CaronMMGBJ20,DBLP:conf/cvpr/ChenH21,chen2021joint}, aiming to learn the invariance feature with a self-supervised mechanism based on sample self-augmented, \emph{e.g.}, Zhong~\emph{et al.}~\cite{zhong2019invariance} save features of all the images in the unlabeled training set in the memory bank for vallina contrastive learning.
Inspired by vallina contrastive learning, cluster contrastive learning has received more attention for ReID~\cite{dai2021cluster,li2021cluster,DBLP:conf/cvpr/XiaoLWLW17,DBLP:conf/nips/Ge0C0L20}.
The cluster contrastive learning in object ReID builds a cluster-level memory in which a single feature vector represents each cluster~\cite{dai2021cluster}, shown in Figure~\ref{fig1}(a).
For example, Dai~\emph{et al.}~\cite{dai2021cluster} store the feature vectors and compute contrast loss at the cluster level.
Li~\emph{et al.}~\cite{li2021cluster} propose an asymmetric contrastive learning framework to exploit both the cluster structure and the individual feature to conduct effective contrastive learning.
Cluster-wise Contrastive Learning (CCL)~\cite{isobe2021towards} is proposed by iterative optimization of feature learning and cluster refinery to learn noise-tolerant representations.
However, previous methods maintain the individual cluster memory by considering just one individual at a time to take a single step for updating.
The cluster contrastive with individual-based updating mechanism will fluctuate over the training examples, especially for the outlier samples.  

\begin{figure*}
  \centering
   \includegraphics[width=0.95\linewidth]{./figure/fig1.pdf}
   \caption{\small Comparison with the Vallina Cluster Contrastive learning (a), and the Dual Cluster Contrastive Learning (b). Feature vectors in different shades of green are of the same identity.}
   \label{fig1}
\vspace{-1.0em}
\end{figure*}

To address the above problem, we consider dual complementary updating mechanisms for the cluster contrastive learning.
Besides the \emph{individual-based update mechanism} of the vanilla cluster contrastive, we also introduce a novel \emph{centroid-based update mechanism} to produce a centroid-based cluster memory that has a different embedding space from the individual-based cluster memory.
Unlike the individual-based updating mechanism that uses the individual feature to update the cluster memory, the centroid-based update mechanism applies the mean feature of each cluster to update the corresponding cluster memory, shown in Figure~\ref{fig1}(b).
Although the provided labels might contain some incorrect labels, most of them are correct.
Therefore, using the mean feature to represent each cluster can reduce the effect of the outlier samples.
From the perspective of optimization,  the individual-based updating mechanism can be treated as the Stochastic Gradient Descent, which considers just one individual at a time to take a single step for updating the parameters.
However, considering just an individual sample will fluctuate over the training examples, especially for the outlier samples.
The centroid-based updating mechanism is similar to the Batch Gradient Descent, which is proposed to reduce the impact of individual samples by considering all training data in a single step, \emph{e.g.,} it takes the average of the gradients of all the training examples and then uses the mean gradient to update the parameters.
Furthermore, the individual-based update mechanism constructs the embedding space by considering all individual samples, and the centroid-based updating mechanism aims to generate a stable embedding space by considering the mean description of each cluster.
Therefore, the cluster contrastive learning with the centroid-based updating mechanism can complement the individual-based updating mechanism.
Consequently, by jointly considering those two updating mechanisms, dual cluster contrastive learning can improve the stability and discrimination of descriptions.

Based on the above motivation, we propose a novel Dual Cluster Contrastive learning (DCC) framework, in which an \emph{individual cluster memory} and a \emph{centroid cluster memory} are employed to implement the individual-based and centroid-based updating mechanism.
As shown in the left part of Figure~\ref{fig1}(b), the individual cluster memory uses the individual features and their labels to update the corresponding cluster memory.
Meanwhile, the centroid cluster memory applies the average of features belonging to the same cluster for momentum updating.
Especially, using the individual cluster memory and centroid cluster memory can embed the instance's features into the individual-level prediction and centroid-level prediction, respectively, as shown in Figure~\ref{fig2}.
To boost the discriminative of each memory, we apply two different feature extraction modules, \emph{i.e.,} \emph{individual backbone}, and \emph{centroid backbone}, to extract the independent features for updating the individual cluster memory and centroid cluster memory, and the standard contrastive loss, \emph{i.e., }clusterNCE loss,  is applied for optimization.
Besides the standard contrastive loss for each memory bank, a cross-view contrastive loss is also used to exchange the benefit knowledge of the individual cluster memory and centroid cluster memory.
For example, the contrastive loss of the individual cluster memory and centroid cluster memory is used to optimize the centroid backbone and individual backbone, respectively.
In the inference stage, the combination of the features generated by the individual backbone and centroid backbone is used for retrieval.
The DCC can be easily applied for unsupervised or supervised object ReID by using ground-truth labels or pseudo-labels generated with the clustering method, respectively.

In summary, to overcome the limitation of vanilla cluster contrastive learning, we propose a novel Dual Cluster Contrastive learning framework for object ReID, consisting of the individual-level and centroid-level cluster contrast. 
The evaluation on three benchmarks under supervised and unsupervised settings show the effectiveness of the DCC. 1) \textbf{supervised object ReID}: DCC         with ResNet50/RestNet50-ibn obtain the mAP of 89.9\%/90.6\%, 65.5\%/69.6\%, and 82.6\%/83.5\% for Market-1501, MSMT17, and VeRi-776, respectively. 2) \textbf{unsupervised object ReID}: DCC with ResNet50/RestNet50-ibn obtain the mAP of 83.4\%/85.8\%,  35.9\%/36.6\%, and 41.4\%/42.1\% for Market-1501, MSMT17, and VeRi-776, respectively. 
The experiment also shows that DCC has the advantages of fast training convergence, insensitivity to batch size, and high generalization. 


\begin{figure*}
  \centering
   \includegraphics[width=0.75\linewidth]{./figure/fig2.pdf}
   \caption{\small The framework of proposed Dual Cluster Contrastive learning for supervised object ReID. Given the training images, we apply the Individual Backbone and Centroid Backbone to extract the corresponding Individual-level Feature  and Centroid-level Feature . Then, Individual Cluster Memory  and Centroid Cluster Memory  are used to represent two types of cluster centers with the Individual-based updating mechanism and Centroid-based updating mechanism, respectively. The Centroid-based updating mechanism uses the mean feature of each cluster to momentum update the Centroid Cluster Memory. The vallina contrastive loss and cross-view contrastive loss are used for optimization. Feature vectors in different shades of green are of the same identity.}
   \label{fig2}
\end{figure*}

\section{Related Work}\label{sec:rela}
This section gives a brief review of the object Re-identification (ReID) and the contrastive learning for object ReID.
\subsection{Object Re-identification}
Based on manually annotated labels, many methods have been proposed for supervised object ReID and achieved promising performance.
For example, Zheng \textit{et al.}~\cite{zheng2019pyramidal} and Fu \textit{et al.}~\cite{fu2019self} extract local features from several horizonal stripes to explore the discriminative clues. 
Furthermore, many novel attention modules have been proposed for supervised person ReID~\cite{Zhang_2020_CVPR, Chen_2021_ICCV, zhang2021person, xia2019second, chen2019mixed}. 
Recently, inspired by the success of transformer structure, He \textit{et al.}~\cite{He_2021_ICCV} and Lai \textit{et al.}~\cite{Lai_2021_ICCV} adopt transformer structure to explore the discriminative clues for supervised person ReID.

As manual annotations are expensive and unavailable in real-world applications, unsupervised person ReID has attracted much more attention. 
Some researchers use extra labeled images to assist the unsupervised training on unlabeled person ReID by transferring labeled images to the unlabeled domains with GAN-based models~\cite{Chen_2019_ICCV, wei2018person, Liu_2019_CVPR, zhong2018generalizing} or narrowing the distribution gap in feature space~\cite{liu2020domain, Huang2020aaai, dai2021idm}. 
For example, Liu \textit{et al.}~\cite{Liu_2019_CVPR} use three GAN models to reduce the discrepancy between different domains in illumination, resolution, and camera-view, respectively.
To handle the lack of annotation, many methods have been proposed to acquire reliable pseudo labels~\cite{yu2019unsupervised, zeng2020hierarchical,  lin2019bottom, ding2019towards, zheng2021group}. For example, Lin \textit{et al.}~\cite{lin2019bottom} propose a bottom-up unsupervised clustering method that simultaneously considers both diversity and similarity.

\subsection{Contrastive Learning for Object ReID}
Recently, several methods further adopt memory bank and contrastive loss for object ReID~\cite{isobe2021towards,zhong2019invariance, DBLP:conf/nips/Ge0C0L20,chen2021ice,DBLP:conf/cvpr/XiaoLWLW17,dai2021cluster,li2021cluster}. 
For example, Zhong~\emph{et al.}~\cite{zhong2019invariance} save features of all the images in the unlabeled training set in the memory bank for contrastive learning. Chen \textit{et al.}~\cite{chen2021ice} save a proxy feature for each class in the memory bank, and Ge \textit{et al.}~\cite{DBLP:conf/nips/Ge0C0L20} propose a hybrid memory bank that saves both instance features and class proxy.
Dai~\emph{et al.}~\cite{dai2021cluster} present the Cluster Contrast mechanism, which stores feature vectors and compute contrast loss in cluster level memory dictionary.
Li~\emph{et al.}~\cite{li2021cluster} propose an asymmetric contrastive learning framework to exploit both the cluster structure and the invariance in augmented data to conduct effective contrastive learning for person ReID.
Chen~\emph{et al.}~\cite{chen2021joint} apply the Generative Adversarial Network (GAN) for data augmentation and propose a view-invariant loss to facilitate contrastive learning between original and generated views. 
To reduce the effect of noisy labels, Cluster-wise Contrastive Learning (CCL)~\cite{isobe2021towards} is proposed by iterative optimization of feature learning and cluster refinery to learn noise-tolerant representations.

However, these methods update the memory bank with every single feature in training batches, making features in memory easily affected by noisy samples.
Compared with previous methods, DCC additionally introduces a centroid updated memory bank that updates based on class mean features of each cluster in training batches.
As mean features are robust against minority noisy samples, updating the memory bank with class centroids will enhance the robustness of the memory bank against label noise and improve the training efficiency and the ReID performance.
Experiments also show that DCC has the advantages of fast training convergence, insensitivity to batch size, and high generalization. 

\section{Methodology}\label{sec:method}
Given a training dataset , the object re-identification (ReID) aims to learn a robustness backbone  for retrieval, where  and  denote the -th training image and its label, respectively.
 is the number of the training images, and  denotes the number of identities. 
For convenience, we use  and  to represent the set of training images and labels, respectively.
The supervised and unsupervised object ReID can be formulated with the same unified framework once providing the annotated labels   or generating the pseudo-labels .
For example, the ground-truth  is annotated by the human for the supervised object ReID, and the pseudo-labels  can be generated with a clustering algorithm for the unsupervised object ReID.
For convenience, we denote  as the obtained annotations for both supervised and unsupervised object ReID tasks to describe the proposed methodology.

\subsection{Vallina Cluster Contrastive}\label{sec:vcc}
With the above definition, we firstly review of the vallina cluster contrastive.
It contains two components: backbone , and cluster memory , in which each cluster is represented by a mean feature, and all cluster feature vectors are updated based on the individual feature, as shown in Figure~\ref{fig1}(a).
Given all training images , the backbone  is used to extract the corresponding features .
Then, cluster memory bank  is initialized with the mean feature of each class, where  and  are the feature dimension and the number of classes, respectively.
Based on the pretrained feature ,  the visual center  of the -th class is initialized with Eq.~\eqref{Eq:initize},

where  denotes the feature set of images belonging to the -th class,  represents the number of features in set ,  is an image feature,
 and  denotes the -th cluster feature in .

Since the cluster memory  can be treated as a non-parametric classifier, it can produce the class prediction used for contrastive loss, formulated as Eq.~\eqref{Eq:L},

where  is a temperature hyper-parameter~\cite{DBLP:conf/cvpr/WuXYL18}, and  is the corresponding label for the image feature . 
When the feature  has a higher similarity to its ground-truth visual centers  and dissimilarity to all other cluster features, the objective loss  has a lower  value.

In vanilla cluster contrastive learning, the individual feature is applied to momentum update the cluster memory  during backward propagation with Eq.~\eqref{Eq:momentum},

where  and  is the feature and label for image , respectively. 
 is the -th cluster feature in cluster memory .

Although the cluster contrastive learning can generate discriminative descriptions, it will fluctuate over the training samples because it considers just one individual at a time to take a step for updating the cluster memory with Eq.~\eqref{Eq:momentum}. 
Specificially,  is usually set to a lower value for the cluster contrastive learning for object ReID, \emph{e.g.,}  =0.1 in ~\cite{dai2021cluster}.
From Eq.~\eqref{Eq:momentum}, we can observe that the mean feature in the cluster memory  is severely affected by the individual feature, leading to a severe negative impact.  
An intuitive illustration is shown in Figure~\ref{fig:ccc}.

\subsection{Dual Cluster Contrastive}
To overcome the limitation of the vallina cluster contrastive, we propose a novel Dual Cluster Contrastive (DCC) framework, as shown in Figure~\ref{fig2}.
The significant difference between the Dual Cluster Contrastive and the vallina cluster contrastive is that DCC maintains two types of memory banks to model the feature distribution from two perspectives, \emph{i.e.,} \emph{individual cluster memory}, and \emph{centroid cluster memory}. 
Similar to the vallina cluster contrastive, the individual cluster memory is updated based on each individual at each step.
Besides, the centroid cluster memory is used to model the class distribution based on the mean feature of each class, which can reduce the impact of individual samples.
In Dual Cluster Contrastive, the individual cluster memory and the centroid cluster memory are defined as  and , respectively.
Note that  and  are both initialized based on the mean pretrained feature of each cluster with Eq.~\eqref{Eq:initize}.
The critical of the Dual Cluster Contrastive is how to update the individual cluster memory  and centroid cluster memory .

\begin{figure}
  \centering
   \includegraphics[width=0.8\linewidth]{./figure/ccc.pdf}
   \caption{\small The update process of the Individual-based (\textcolor{Grey}{Grey arrow line}) and Centroid-based updating mechanism (\textcolor{blue}{Blue arrow line}). Individual-based updating mechanism is easily affected by individual feature, especially outlier samples. \textcolor{red}{} and  \textcolor{green}{} denote the individual feature belonging to the same class from different batches, respectively. \textcolor{red}{} and  \textcolor{green}{} are the corresponding center features.}
   \label{fig:ccc}
\end{figure}


To boost the discriminative of each memory, we apply two different feature extraction modules, \emph{i.e.,} \emph{individual backbone} , and \emph{centroid backbone} , to extract the independent features for updating the individual cluster memory  and centroid cluster memory .
Given the training dataset, we sample the batch training images () and (). 
For example, the images  and labels  are used to optimize the individual backbone  and update the individual cluster memory .
Meanwhile, the images  and labels  are used for the centroid branch.
Specially, we generate the individual feature  by feeding the images  into the individual backbone .
Similarly, the centroid features are denoted as .
Furthermore,  the features  and  are applied for updating the corresponding memories and optimizing the backbones.

During training, once obtaining the feature  and , using the cluster memories  and  can generate the corresponding predictions  and  .
Meanwhile, the cross-view contrastive prediction can be represented as  and  .
With the predictions , , , and , we can compute the contrastive loss, \emph{i.e.,} NCEloss.
Formally, the final loss  is defined as:
 
where  and  are the loss computed based on the features  and , respectively. 
 is a weight to balance the effect of different losses, where  and  denote the current and total epochs.
For convenience, we use  and  to represent  and , which is computed as:

where  is the ground-truth label for the feature .
Note that the above equation consists of two terms. 
The first term represents the loss between the individual features  and its own individual cluster memory , which is consistent with the vallina cluster contrastive. 
Here, ``own” emphasizes that the  individual cluster memory is updated with the individual-based updating mechanism.
The second term in Eq.~\eqref{eq:loss_i}, which can be treated as a cross-view contrastive loss, apply the centroid cluster memory to embed the individual features.
Since centroid cluster memory is independent to the individual features,  using the cross-view contrastive loss can enhance the discriminative of the individual backbone.

Similar to ,  also contains two terms:

where the second term is also a cross-view contrastive loss between the centroid feature  and the individual cluster memory  for knowledge transfering.

\begin{algorithm}[t]
\small
\caption{The procedure of DCC}
\label{alg}
 \begin{algorithmic}[1]
	\Require Given the dataset 
	\Require Initialize the individual backbone  and centroid backbone  with ResNet-50 pretrained on the ImageNet.
	\Require Initialize the individual cluster memory  and centroid cluster memory  with the mean feature of each cluster.
	\While { } 
		\State Sample training images  and  from ;
		\State Extracting the corresponding features  and  with backbone  and , respectively;
		\State Computing contrastive loss with Eq.~\eqref{eq:loss_i} and Eq.~\eqref{eq:loss_c};
		\State Updating the individual cluster memory  with Eq.~\eqref{Eq:momentum_i};
		\State Updating the centroid cluster memory  with Eq.~\eqref{Eq:momentum_c}; 
	\EndWhile

\Ensure The trained model  and . 
 \end{algorithmic}
\label{alg}
\end{algorithm}

The above description is the \emph{forward process} of the Dual Cluster Contrastive(DCC). 
However, the other problem of DCC is how to update the individual cluster memory  and the centroid cluster memory  \emph{during backward}, which is a critical aspect of contrastive learning.
Given the feature  along with its label ,  the individual cluster memory  is momentum updated with Eq.~\eqref{Eq:momentum_i},


For the centroid cluster memory, we apply the mean feature of each class for momentum updating.
Given the centroid feature  and labels  of the batch images, we first compute each class's mean feature during training, and then update the centroid cluster memory with the obtained mean feature.
Therefore, the cluster memory  is updated with Eq~\eqref{Eq:momentum_c},

where  denotes the mean feature of -th class,

where   denotes the subset of centroid features   belonging to the -th class(),  represents the number of features in set ,  is an instance feature.
L2-normalization is used to normalize the .
The algorithm is illustrated in Algorithm~\ref{alg}.

\textbf{Inference:} After training, we can obtain the inferred individual backbone  and centroid backbone .
Given the testing image , the final feature used for retrieval is defined as :

where  is the L2-normalization, and the final feature is .
Once extracting all features for gallery and query images, the Euclidean distance is used to compute the similarity for retrieval. 
\subsection{Generalization to unsupervised object ReID}
Existing unsupervised object ReID commonly uses clustering methods to generate the pseudo-labels for unlabeled images, and then perform supervised training based on the generated pseudo-labels.
With the pseudo-labels, the proposed Dual Cluster Contrastive can be easily applied for unsupervised object ReID.

Specifically, given the unlabeled training images, we firstly apply the backbone to extract the corresponding features.
Similar to~\cite{dai2021cluster}, we apply DBSCAN to group all training features into several groups.
Then, the cluster ID is assigned to each training image as the pseudo-label, and the unclustered outlier images are discarded from training.
With the pseudo-labels, the proposed Dual Cluster Contrastive is conducted for representation learning, shown in Figure~\ref{fig:un_reid}.

\section{Experiments}\label{sec:experiment}
\subsection{Datasets}
We conduct experiments on two person ReID datasets, Market-1501~\cite{zheng2015scalable}, MSMT17~\cite{wei2018person}, and one vehicle ReID dataset, VeRi-776, under the supervised and unsupervised settings to evaluate the effectiveness of the proposed Dual Cluster Contrastive.
The details of these datasets are summarized in Table~\ref{tab:dataset}.

\begin{figure}
  \centering
   \includegraphics[width=0.8\linewidth]{./figure/un_reid.pdf}
   \caption{\small The framework of proposed Dual Cluster Contrastive learning for unsupervised object ReID.}
   \label{fig:un_reid}
\end{figure}

\begin{table}
\footnotesize
\begin{center}
\begin{tabular}{c|cccc}
\toprule
Datasets         & Object& \#ID & \#image & \#cam\\
\midrule
Market-1501 & Person & 1,501 & 32,668 & 6 \\
MSMT17 & Person & 4,101 & 126,441 & 15 \\
VeRi-776 & Vehicle & 776 & 49,357 & 20 \\ \bottomrule
\end{tabular}
\caption{\small Statistics of datasets used in our evaluation.}
\label{tab:dataset}
\end{center}
\end{table}

\subsection{Implementation Details}
The proposed Dual Cluster Contrastive is implemented based on the existing cluster contrastive framework~\cite{dai2021cluster}\footnote{https://github.com/alibaba/cluster-contrast-reid}.
We adopt the ResNet-50~\cite{he2016deep} pretrained on ImageNet~\cite{deng2009imagenet} as the backbone.
Inspired by ~\cite{DBLP:conf/cvpr/0004GLL019}, all sub-module layers after layer4-1 are removed, and a GEM pooling followed by batch normalization layer~\cite{DBLP:conf/icml/IoffeS15} and L2-normalization layer is added. 
Therefore, the feature dimension  is 2,048.
For the \emph{person ReID}, all input images are resized 256128 for training and evaluation.
For the \emph{vehicle ReID}, all input images are resized 256256 for training and evaluation.
The temperature coefficient  is set to 0.05.
For the supervised object ReID, the adam optimizer sets the weight decay as 0.0005, and the learning rate is initially set as 0.00035 and decreased to one-tenth of every 50 epochs up to 150 epochs. 
Inspired by ~\cite{dai2021cluster}, for the unsupervised object ReID,  DBSCAN is used to generate pseudo labels for the Dual Cluster Contrastive, and the learning rate is initially set as 0.00035 and decreased to one-tenth of every 20 epochs up to 60 epochs.
We sample  person identities and a fixed number  instances for each identity during training. 
Therefore, the batch size is .
In this work, we set =16, and =8 for training.
\subsection{Baselines}
In this section, we give a brief definition of the baselines used for evaluation in the following.
\begin{enumerate}
\item ICC: The vallina cluster contrastive  introduced in Sec.~\ref{sec:vcc}.
\item CCC: The vallina cluster contrastive  by replacing the individual update policy (Eq.~\eqref{Eq:momentum}) with centroid cluster updating policy(Eq.~\eqref{Eq:momentum_c}). 
\item DCC: The proposed Dual Cluster Contrastive employes the individual feature  generated by the individual backbone for evaluation.
\item DCC: The proposed Dual Cluster Contrastive employes the centroid feature  generated by the centroid backbone for evaluation.
\item DCC: The proposed Dual Cluster Contrastive does not consider the cross-view contrastive loss, \emph{i.e.,} ignoring the second term in Eq.~\eqref{eq:loss_i} and Eq.~\eqref{eq:loss_c}.
\item DCC: The proposed Dual Cluster Contrastive modules.
\end{enumerate}
\subsection{Ablation Studies}
In this section, we conduct some ablation studies on Market-1501, MSMT17, and VeRi-776 to evaluate the effectiveness of the proposed component in Dual Cluster Contrastive.

\begin{table}
\footnotesize
\begin{center}
\begin{tabular}{c|ccccccc}
\toprule
BatchSize          & 48& 64 & 80 & 96 & 128 & 160 & 192\\
\midrule
CCC& 83.7 & 87.0 & 87.4 & 87.2 & 87.0 & 86.3 & 86.1\\
ICC &72.8&83.7&86.9&87.6& 88.4&88.3&88.3\\
DCC &\textbf{86.0} & \textbf{88.6} & \textbf{89.6} & \textbf{89.9} & \textbf{89.9} & \textbf{89.4} & \textbf{89.4}\\ \bottomrule
\end{tabular}
\caption{\small Effect of batch size in DCC, CCC, and ICC on Market-1501.}
\label{tab:effect_ccc}
\end{center}
\end{table}

\textbf{Effect of Dual Cluster Contrastive:}
As mentioned above, Dual Cluster Contrastive(DCC) consists of the individual-level cluster contrastive(ICC) and centroid-level cluster contrastive(CCC), where CCC is the significant contribution module from existing methods.
Therefore, we analyze the effectiveness of the centroid-level cluster contrastive and Dual Cluster Contrastive, and summarize the results in Table~\ref{tab:effect_ccc}.
We observe that the ICC model obtains a higher performance than the CCC model, \emph{e.g.,} ICC obtains the best mAP of 88.4\% by setting the batch size as 128.
However, the centroid-level cluster contrastive is more effective for the smaller batch size, \emph{e.g.,} CCC obtains a higher performance than ICC for the batch size from 48 to 80.
Especially for the batch size of 48, ICC only obtains the performance of 72.8\%,  which has a large gap with its best performance of 88.4\%.
Different from ICC, CCC obtains the mAP of 83.7\% by setting the batch size as 48.
Therefore, we can conclude that the CCC model is more robust to the smaller batch size, and ICC can obtain higher performance.

Furthermore, DCC that combines two types of cluster contrastive learning obtains the best performance on all batch sizes, proving the centroid-level cluster contrastive complements the individual-level cluster contrastive.
From Table~\ref{tab:effect_ccc}, we also observe that DCC is insensitive to changes in batch size.
For example, the ICC model obtains the mAP of 88.6\% for the batch size of 128.
However, once reducing the batch size to 64, its mAP quickly plummets to 83.7\%.
Differently, DCC obtains the mAP 89.9\% and 88.6\% for the batch size of 128 and 64, respectively.  


\begin{figure}
\centering
\begin{subfigure}{0.475\linewidth}
\includegraphics[width=1.0\linewidth]{./figure/loss.pdf}
\caption{Loss}
\label{fig:loss}
\end{subfigure}
\begin{subfigure}{0.475\linewidth}
\includegraphics[width=1.0\linewidth]{./figure/acc_change.pdf}
\caption{mAP}
\label{fig:map}
\end{subfigure}
\caption{The change of loss and mAP during training on Market1501.}
\end{figure}

\begin{table}
\footnotesize
\begin{center}
\begin{tabular}{c|ccc}
\toprule
Datasets          & Market-1501& MSMT17 & VeRi-776\\
\midrule
DCC& 88.3 & 61.7 & 75.8\\
DCC &89.9&65.5&82.6\\ \bottomrule
\end{tabular}
\caption{\small Effect of cross-view contrastive loss. DCC denotes the model without considering the cross-view contrastive loss.}
\label{tab:effect_cvl}
\end{center}
\end{table}

\textbf{Training Convergence:}
We further analyze the training convergence process of DCC.
Figure~\ref{fig:loss} summarizes the training loss of different models, \emph{e.g.,} ICC, CCC, and DCC.
We can observe that the CCC has faster convergence and lower loss than CCC and DCC, and the DCC is a trade-off between the ICC and CCC. 
Furthermore, we summarize the change in mAP of different models in Figure~\ref{fig:map}.
It can see that the DCC achieves a lower loss and a higher performance with a faster convergence speed.
For example, DCC obtains the mAP of 89.1\% for the -th epoch, higher than the ICC and CCC models.
Therefore, the proposed DCC can obtain a higher performance with a faster convergence speed during the training process.

\textbf{Effect of the Cross-view Contrastive Embedding:}
As mentioned above, the Individual-level Cluster Contrastive (ICC) and Centroid-level Cluster Contrastive(CCC) have different properties, such as convergence speed and sensitivity to batch size. 
Therefore, the DCC and ICC can generate two different identity embedding spaces for the same dataset.
To min the benefit knowledge of each model, the cross-view contrastive embedding is applied for optimizing the backbone, \emph{i.e.,} the second term in Eq.~\eqref{eq:loss_i} and Eq.~\eqref{eq:loss_c}.
As shown in Table~\ref{tab:effect_cvl}, the Dual Cluster Contrastive (DCC) obtains a higher mAP than  DCC that does not consider the cross-view contrastive loss.
Furthermore, the advantage of the cross-view constrastive loss is that it can exchange the benefit between the individual cluster memory and centroid cluster memory to boost the performance, \emph{e.g.,} DCC and DCC consistently outperformed the ICC and CCC during training, shown in Figure~\ref{fig:map}. 
Significantly, the mAP of DCC, which is the branch of the centroid backbone of the DCC, has been improved from 87.0\% of CCC to 89\%.
The reason is that the cross-view contrastive loss can use the discriminative individual cluster memory to increase the discriminative of the centroid backbone.
Otherwise, the benefits of the centroid cluster memory can also be used to improve the robustness of individual backbone, \emph{e.g.,} improving the mAP from 88.6\% of ICC to 89.3\% of DCC.

\begin{figure}
\centering
\includegraphics[width=0.6\linewidth]{./figure/effect_omega.pdf}
\vspace{-1.0em}
\caption{\small The effect of  for DCC and ICC.}
\label{fig:effect_omega}
\end{figure}

\textbf{Effect of momentum value :}
Similar to existing contrastive learning, momentum updating strategies are applied to update cluster features in individual-level  and centroid-level  memories.  
Note that the individual-level and centroid-level cluster memory banks use the same momentum value .
As shown in Figure~\ref{fig:effect_omega}, the smaller  performs better than higher , \emph{e.g.,} =0.1 obtains the highest performance. 
Furthermore, we observe that the DCC is insensitive to  during memory updating, \emph{e.g.,} by setting  from 0.1 to 0.7, the mAP is slightly dropped from 89.9\% to 88.8\%, which is still higher than the best performance of ICC. 
From Figure~\ref{fig:effect_omega}, it can also be seen that the vallina cluster contrastive (ICC) obtains the best performance by setting =0.3.

\textbf{Effect of Batch Size:}
To evaluate the impact of batch size for Dual Cluster Contrastive, we compare the batch size from 64 to 160 on Market-1501 and VeRi-776 datasets.
As shown in Table~\ref{fig:effect_bs}, increasing the batch size would first increase and then decrease performance, \emph{e.g.,} using the batch size of 128 obtains the highest mAP of 89.9\% and 82.6\% of Market-1501 and VeRi-776, which is higher than the batch size of 64 and 160.



\begin{figure}
\centering
\begin{subfigure}{0.49\linewidth}
\includegraphics[width=1.0\linewidth]{./figure/effect_bs_market.pdf}
\caption{Market-1501}
\end{subfigure}
\begin{subfigure}{0.49\linewidth}
\includegraphics[width=1.0\linewidth]{./figure/effect_bs_duke.pdf}
\caption{VeRi-776}
\end{subfigure}
\caption{The effect of batch size on Market1501 and MSMT17.}
\label{fig:effect_bs}
\end{figure}

\textbf{Effect of  for training identities sampling:}
During training, we sample  person identities and a fixed number  instances for each person identity for each training batch. 
We thus analyze the effect of  for training identities sampling by setting the batch size as 128. 
As shown in Table~\ref{tab:effect_k}, setting =16 obtains the best performance on all three datasets.

 \begin{table}
\footnotesize
\begin{center}
\begin{tabular}{c|cccc}
\toprule
          & 4& 8 & 16 & 32\\
\midrule
Market-1501&86.6&88.6&89.9& 89.3\\
MSMT17 &59.5&63.3&65.5&63.6\\
VeRi-776 &76.5&80.0&82.6&82.0\\
\bottomrule
\end{tabular}
\caption{\small Effect of  for training identities sampling.}
\label{tab:effect_k}
\end{center}
\end{table}

\subsection{Comparison with existing methods}
In this section, we conduct the comparison with existing methods following two settings: \emph{supervised Object ReID}, and \emph{unsupervised Object ReID} on three benchmarks, \emph{i.e.,} Market-1501, MSMT17, and VeRi-776.

\textbf{Comparision on Supervised Object ReID:}
We first compare the Dual Cluster Contrastive with existing supervised ReID methods on three benchmarks and summarize the results in Table~\ref{tab:supervised_market}, Table~\ref{tab:supervised_msmt}, and Table~\ref{tab:supervised_veri} for Market-1501, MSMT17, and VeRi-776, respectively.
We conduct the comparison from three aspects to prove the effectiveness of the proposed DCC.

\begin{table}
\footnotesize
\begin{center}
\begin{threeparttable}
\begin{tabular}{c|cccc}
\toprule
Methods           & mAP& R1 & R5 & R10\\
\midrule
CAR~\cite{zhou2019omni} & 84.9&94.8&-&-\\
SCAL~\cite{chen2019mixed} & 85.0&95.1&98.1&98.9\\
MGN~\cite{wang2018learning} & 86.9 & 95.7 &-& 98.93\\
CAL~\cite{DBLP:journals/corr/abs-2108-08728} & 87.0 & 94.5 & 97.9 & -\\
Circle Loss~\cite{sun2020circle} & 87.4&96.1&-&-\\
CLA~\cite{DBLP:journals/corr/abs-2008-06810} &88.0&95.4&-&-\\
FastReID(ResNet50)~\cite{he2020fastreid}& 88.2&95.4&-&-\\
RGA-SC~\cite{DBLP:conf/cvpr/ZhangLZJ020} & 88.4 & 96.1 & -&- \\
Pyramid-Net~\cite{zheng2019pyramidal} & 88.2 & 95.7 & 98.4 & 99.0  \\
ABDNet~\cite{chen2019abd} & 88.28&95.6&-&-\\
SONA~\cite{xia2019second}& 88.8& 95.58&98.5&99.1\\
TransReID~\cite{He_2021_ICCV}~\tnote{*} & 88.9&95.2&-\\
DCC(ResNet50) &89.9&95.7&\textbf{98.5}&99.0\\
\midrule
CLA(ResNet50-ibn)~\cite{DBLP:journals/corr/abs-2008-06810} &88.9&95.7&-&-\\
FastReID(ResNet50-ibn)~\cite{he2020fastreid}& 89.3& 95.7&-&-\\
DCC(ResNet50-ibn) &\textbf{90.6}&\textbf{96.1}&98.4&\textbf{99.1}\\
\bottomrule
\end{tabular}
\begin{tablenotes}
\item[*] The performance of the TransReID is the input size of , which is similar to our setting.
\end{tablenotes}
\end{threeparttable}
\caption{\small Comparison of \textcolor{blue}{Supervised} Person ReID on Market-1501.}
\label{tab:supervised_market}
\end{center}
\end{table}

Firstly, we can observe that the proposed Dual Cluster Contrastive is significantly better than existing methods with the same backbone, proving the effectiveness of the proposed DCC, \emph{e.g.,} with the backbone of ResNet50, DCC obtains the mAP of 89.9\%, 61.2\%, and 82.6\% for Market-1501, MSMT17, and VeRi-776, respectively.
As shown in Table~\ref{tab:supervised_msmt}, DCC(ResNet-50) obtains the worse performance than TransReID~\cite{He_2021_ICCV} on MSMT17, \emph{e.g.,} 65.5\% vs 67.4\%.
The reason is that TransReID applies the transformer-based network as the backbone for object ReID, which is stronger than the ResNet used in DCC.
However, by replacing the ResNet-50 with a stronger backbone ResNet50-ibn, DCC achieves a performance of 69.6\%, which is higher than 67.4\% of TransReID.
Otherwise, the DCC(ResNet-50) obtains a higher performance than TransReID~\cite{He_2021_ICCV} on both Market-1501 and VeRi-776.

\begin{table}
\footnotesize
\begin{center}
\begin{threeparttable}
\begin{tabular}{c|cccc}
\toprule
Methods           & mAP& R1 & R5 & R10\\
\midrule
MGN~\cite{wang2018learning}+CircleLoss & 52.1 & 76.9 & - & -\\
Circle Loss~\cite{sun2020circle} & 52.1&76.9&-&-\\
DG-Net~\cite{zheng2019joint} & 52.3 & 77.2 & 87.4 & 90.5 \\
CAR~\cite{zhou2019omni} & 52.9&78.7&-&-\\
CAL~\cite{DBLP:journals/corr/abs-2108-08728} & 56.2 & 79.5 & 89.0 & -\\
RGA-SC~\cite{DBLP:conf/cvpr/ZhangLZJ020} & 57.5 & 80.3 & -&- \\
FastReID(ResNet50)~\cite{he2020fastreid}& 59.9&83.3&-&-\\
ABDNet~\cite{chen2019abd} & 60.8 & 82.3 & - &-\\
TransReID~\cite{He_2021_ICCV}~\tnote{*} &67.4&85.3&-\\
\textbf{DCC}(ResNet50) &65.5&85.1&92.1&94.0\\
\midrule
FastReID(ResNet50-ibn)~\cite{he2020fastreid}& 61.2&84.0&-&-\\
FastReID-MGN(ResNet50-ibn) ~\cite{wang2018learning}& 65.4 & 85.1 & - & -\\
\textbf{DCC}(ResNet50-ibn) &\textbf{69.6}&\textbf{87.2}&\textbf{93.3}&\textbf{95.0}\\
\bottomrule
\end{tabular}
\end{threeparttable}
\caption{\small Comparison of  \textcolor{blue}{Supervised} Person ReID on MSMT17.}
\label{tab:supervised_msmt}
\end{center}
\end{table}


\begin{table}
\footnotesize
\begin{center}
\begin{threeparttable}
\begin{tabular}{c|ccc}
\toprule
Methods           & mAP& R1 & R5 \\
\midrule
PRReID~\cite{he2019part} & 74.3 & 94.3 &98.7\\
UMTS~\cite{jin2020uncertainty} & 75.9 & 95.8 & \\
PGAN~\cite{zhang2019part} & 79.3 & 96.5 &98.3\\
PVEN~\cite{meng2020parsing} & 79.5 & 95.6 &98.4\\
SAVER~\cite{khorramshahi2020devil} & 79.6 & 96.4 &98.6\\
HPGN~\cite{DBLP:journals/corr/abs-2005-14684} & 80.18 & 96.72& - \\
GLAMOR~\cite{suprem2020looking} & 80.3 & 96.5 &98.6\\
GFDIA~\cite{DBLP:conf/iccv/Li0Z21} &  81.0 & 96.7 & 98.6 \\
TransReID~\cite{He_2021_ICCV}~\tnote{*} &81.4&96.8\\
\textbf{DCC}(ResNet50) &82.6&96.3&98.5\\
\midrule
FastReID(ResNet-ibn)~\cite{he2020fastreid} & 81.9 & 97.0 & 99.0 \\
HRCN(ResNet-ibn)~\cite{DBLP:conf/iccv/ZhaoZ0Y021} & 83.1& 97.3 & 98.9 \\
\textbf{DCC}(ResNet50-ibn) &\textbf{83.5}&\textbf{97.6}&\textbf{99.0}\\
\bottomrule
\end{tabular}
\end{threeparttable}
\caption{\small Comparison of  \textcolor{blue}{Supervised} Vehicle ReID on VeRi-776.}
\label{tab:supervised_veri}
\end{center}
\end{table}

\begin{table}
\footnotesize
\begin{center}
\begin{tabular}{c|cccc}
\toprule
Methods           & mAP& R1 & R5 & R10\\
\midrule
SSG~\cite{fu2019self} & 58.3& 80.0 & 90.0 & 92.4\\
UGA~\cite{wu2019unsupervised} & 70.3 & 87.2 & - & -\\
NRMT~\cite{zhai2020multiple} & 71.7 & 87.8& 94.6 & 96.5\\
JVTC+~\cite{chen2021joint} &75.4&90.5&96.2&97.1\\
MMT~\cite{ge2020mutual} & 75.6 & 89.3 & 95.8& 97.5 \\
SPCL~\cite{DBLP:conf/nips/Ge0C0L20} & 77.5 & 89.7 & 96.1 & 97.6 \\
ICE~\cite{chen2021ice} & 79.2 & 92.0 & 97.0& 98.1 \\
GLT~\cite{zheng2021group} & 79.5 & 92.2 & 96.5 & 97.8 \\
FastReID~\cite{he2020fastreid} & 80.5& 92.7 & - &- \\
CACAL~\cite{li2021cluster} & 80.9 & 92.7 & 97.4 & 98.5 \\
ClusterContrastive(DBSCAN)~\cite{dai2021cluster} & 82.1 & 92.3 & 96.7 & 97.9 \\
ClusterContrastive(Infomap)~\cite{dai2021cluster} & 83.0 & 92.9 & 97.2 & 98.0 \\
CCL~\cite{isobe2021towards} & 83.4 & 94.2 & - & - \\
\textbf{DCC}(ResNet50) &83.4&93.5&97.1&98.3\\
\textbf{DCC}(ResNet50-ibn) &\textbf{85.8}&\textbf{94.3}&\textbf{97.6}&\textbf{98.6}\\
\bottomrule
\end{tabular}
\caption{\small Comparison of \textcolor{red}{Unsupervised} Person ReID on Market-1501.}
\label{tab:unsupervised_market}
\end{center}
\end{table}


Secondly, based on whether considering the local features or additional information, existing methods can be divided into two groups: backbone-independent methods and feature-fusion methods.
The feature-fusion methods propose an additional module to min the multi-level discriminative clues for object ReID.
The backbone-indpependent methods propose and add a backbone-indpependent modules on the backbone for inferring the discriminative description, \emph{e.g.,} Contrastive Learning~\cite{dai2021cluster}, Circle Loss~\cite{sun2020circle}, Triplet Loss, and Classification Loss. 
\emph{Therefore, all backbone-independent methods use the same backbone for inferencing,  \emph{e.g.,} ResNet50, or ResNet50-ibn, and making a comparison among them be a fair comparison.}
Therefore, Dual Cluster Contrastive can be treated as a novel backbone-independent module.
Compared with existing backbone-independent methods, we can observe that DCC obtains a noticeable improvement upon the existing methods, \emph{e.g.,} improving the mAP from 87.4\%, and 52.1\% of Circle Loss~\cite{sun2020circle} to 89.9\%, and 65.5\%. 
The superior performance demonstrates the effectiveness of the proposed DCC. 


Finally, we evaluate the proposed DCC with different backbones to show its better generability.
Since Instance normalization(IN)~\cite{DBLP:conf/cvpr/UlyanovVL17} and Batch normalization (BN)~\cite{DBLP:conf/icml/IoffeS15} can capture the appearance invariance and the content-related information, the Instance-batch normalization (IBN)~\cite{DBLP:conf/eccv/PanLST18} combining the advantage of the above-mentioned normalization has been proven to be effective for person ReID~\cite{he2020fastreid}.
Therefore, by replacing the BN operation in ResNet50 with IBN operation,  the ResNet50-ibn is treated as a strong backbone.
From Table~\ref{tab:supervised_market}, Table~\ref{tab:supervised_msmt} and Table~\ref{tab:supervised_veri}, we can observe that ResNet50-ibn obtain a higher performance than ResNet50, \emph{e.g.,} compared with the ResNet50, using ResNet50-ibn improves the mAP from 89.9\%, 65.5\%, and 82.6\% to 90.6\%, 69.6\%, and 83.5\% for Market-1501, MSMT17, and VeRi-776, respectively.

\textbf{Comparision on Unsupervised Object ReID:}
In addition to the supervised object ReID, we further compare the Dual Cluster Contrastive with existing unsupervised object ReID methods and summarize the related results in Table~\ref{tab:unsupervised_market}, Table~\ref{tab:unsupervised_msmt}, and Table~\ref{tab:unsupervised_veri} for Market-1501, MSMT17, and VeRi-776, respectively.
We can observe that DCC is significantly better than existing methods, proving the effectiveness of the Dual Cluster Contrastive.

\textbf{Disscussion}
The most related work to ours is the vallina cluster contrastive.
Compared with the vallina cluster contrastive, the Dual Cluster Contrastive has the following benefits based on the above analyses.
Firstly, Dual Cluster Contrastive (DCC) is insensitive to the batch size and momentum factor.
Secondly, DCC has a faster convergence speed during the training process. 
Thirdly, DCC has better generalization capabilities, \emph{e.g.,} DCC achieves better performance for both supervised and unsupervised object ReID on three benchmarks. 


\begin{table}
\footnotesize
\begin{center}
\begin{tabular}{c|cccc}
\toprule
Methods           & mAP& R1 & R5 & R10\\
\midrule
ECN~\cite{fu2019self} & 10.2& 30.2 & 41.5 & 46.8\\
CACL~\cite{li2021cluster} & 21.0 & 45.4 & 55.6 & 63.6\\
UGA~\cite{wu2019unsupervised} & 21.7 & 49.5 & - & -\\
MMT~\cite{ge2020mutual} & 24.0 & 50.1 & 63.5& 69.3 \\
SPCL~\cite{DBLP:conf/nips/Ge0C0L20} & 26.8 & 53.7 & 65.0 & 69.8 \\
FastReID~\cite{he2020fastreid} & 27.7& 59.5 & - &- \\
RLCC~\cite{DBLP:conf/cvpr/ZhangG0021} & 27.9 & 56.5 & 68.4 & 73.1 \\
JVTC+~\cite{chen2021joint} &29.7&54.4&68.2&74.2\\
ClusterContrastive(DBSCAN)~\cite{dai2021cluster} & 27.6 & 56.0 & 66.8 & 71.5 \\
ICE~\cite{chen2021ice} & 29.8 & 59.0 & 71.7 & 77.0 \\
ClusterContrastive(Infomap)~\cite{dai2021cluster} & 31.2 & 61.5 & 71.8 & 76.7 \\
\textbf{DCC}(ResNet50) &35.9&64.3&74.8&78.8\\
\textbf{DCC}(ResNet50-ibn) &\textbf{36.6}&\textbf{64.9}&\textbf{74.9}&\textbf{78.5}\\
\bottomrule
\end{tabular}
\caption{\small Comparison of \textcolor{red}{Unsupervised} Person ReID on MSMT17.}
\label{tab:unsupervised_msmt}
\end{center}
\end{table}


\begin{table}
\footnotesize
\begin{center}
\begin{tabular}{c|cccc}
\toprule
Methods           & mAP& R1 & R5 & R10\\
\midrule
MMT~\cite{ge2020mutual} & 35.3 & 74.6 & 82.6& 87.0 \\
FastReID~\cite{he2020fastreid} & 27.7& 59.5 & - &- \\
SPCL~\cite{DBLP:conf/nips/Ge0C0L20} & 38.9 & 80.4 & 86.8 & 89.6 \\
RLCC~\cite{DBLP:conf/cvpr/ZhangG0021} & 39.6 & 83.4 & 88.8 & 90.9 \\
VACP-DA~\cite{DBLP:journals/corr/abs-2011-09099} & 40.3 & 77.4 & 84.6 & - \\
ClusterContrastive(DBSCAN)~\cite{dai2021cluster} & 40.3 & 84.6 & 89.2 & 91.6 \\
ClusterContrastive(Infomap)~\cite{dai2021cluster} & 40.8 & 86.2 & 90.5 & 92.8 \\
\textbf{DCC}(ResNet50) &41.4&86.4&89.7&91.7\\
\textbf{DCC}(ResNet50-ibn) &\textbf{42.1}&\textbf{87.9}&\textbf{90.8}&\textbf{92.9}\\
\bottomrule
\end{tabular}
\caption{\small Comparison of \textcolor{red}{Unsupervised} Vehicle ReID on VeRi-776.}
\label{tab:unsupervised_veri}
\end{center}
\end{table}



\section{Conclusion}\label{sec:conclusion}
To overcome the limitation of the vallina cluster contrastive for Object ReID, we propose a novel Dual Cluster Contrative framework, which consists of the individual-level cluster contrastive and centroid-level cluster contrastive.
The individual-level cluster contrastive updates its memory bank based on the individual feature with the momentum update strategy, and the centroid-level cluster contrastive updates its memory bank with the mean feature of each class.
The evaluations on three benchmarks under the supervised and unsupervised settings demonstrate the effectiveness of the proposed DCC.
Although the proposed DCC is a practical framework, it maintains two different memory banks, with certain limitations in applying a large-scale dataset.
In the future, we will explore how to use one memory bank to achieve the benefits of the two memory banks through adaptive optimization strategies. 

 





{\small
\bibliographystyle{ieee_fullname}
\bibliography{main}
}

\end{document}
