\def\year{2019}\relax
\documentclass[letterpaper]{article} \usepackage{aaai19}  \usepackage{times}  \usepackage{helvet}  \usepackage{courier}  \usepackage{url}  \usepackage{graphicx}  \frenchspacing  \setlength{\pdfpagewidth}{8.5in}  \setlength{\pdfpageheight}{11in}  \pdfinfo{
/Title (TopicEq)
/Author ()}
\setcounter{secnumdepth}{0}
\usepackage[normalem]{ulem}
\usepackage{enumitem,setspace}
\usepackage{amsmath,amssymb,amsthm}
\usepackage{color}
\usepackage[compact]{titlesec}
\titlespacing{\paragraph}{0pt}{0.15\baselineskip}{0.8em}

\usepackage{pifont}
\usepackage[dvipsnames]{xcolor}
\definecolor{mydarkgreen}{HTML}{008000}
\definecolor{mydarkred}{HTML}{dc143c}
\definecolor{mydarkyellow}{HTML}{ff8c00}


\def\given{\,|\,}
\newcommand\eq{\mbox{\it eq}}
\def\heading#1{\paragraph{\it\bfseries #1}}


\usepackage{array, makecell}
\usepackage{arydshln, cellspace}
\usepackage{booktabs}
\usepackage{multirow}
\usepackage{makecell}
\newcommand{\citet}[1]{\citeauthor{#1} \shortcite{#1}}


\begin{document}
\setlength{\abovedisplayskip}{4pt}
\setlength{\belowdisplayskip}{4pt}

\title{TopicEq: A Joint Topic and Mathematical Equation Model for Scientific Texts}

\author{Michihiro Yasunaga
\,
\quad
John D. Lafferty
\
    \label{eq:theta_prior}
    \eta \sim \mathcal{N} (0,I), ~~~ \theta = g(\eta)

    & w_n^{(c)} \mid \theta \sim \text{Mult}(\theta^T\beta) \label{eq:wn_theta}\\
    & \eq \mid \theta \sim \text{LSTM}(\theta)  \label{eq:lstm_theta}

    i_t &= \sigma \left (W_i [x_t ; h_{t-1}; \theta] + b_i \right )\-0pt]
    \tilde{c}_t &= \tanh \left (W_c [x_t ; h_{t-1}; \theta] + b_c \right )\\vspace{-5.7mm}

Here  denotes the concatenation of the current input, previous state and topic proportion vector;  is the sigmoid function and  denotes
the Hadamard product.
The probability of the next token in the equation is   .
Thus, the TE-LSTM embeds  inside the LSTM cell to reflect
the topic knowledge for equation generation.
As a joint topic-equation model, it is similar to the
topic-language model of \cite{wang2017topic}.


Writing the equation as a sequence of tokens
, the training objective is the marginal likelihood of  and \
p(C, y_{1:T}) = \int_\eta p(\eta) p(C |\eta)
	\prod_{t=1}^{T}  p(y_t \hspace{0.5pt}|\hspace{0.5pt} y_{1:t-1}, \eta)  d\eta  -2.5mm]
Since its direct optimization is intractable, we employ variational inference \cite{jordan1999introduction}.
Denoting the variational distribution by , we
maximize the variational lower bound (ELBO) for the log-likelihood, :\\
~\
	\mathcal{L} &=   \mathbb{E}_{q(\eta)} \bigl[ \log p( C | \eta ) \bigr]- D_{\text{KL}}\bigl( q(\eta) \,\|\, p( \eta) \bigr)  ~~~ \nonumber\\
	& \hspace{8mm}+ \mathbb{E}_{q(\eta)} \left[ \sum_{t=1}^{T}\log p(y_t \,|\, y_{1:t-1}, \eta) \right]
    \label{eq:elbo}
-2.5mm]
Following recent approaches to neural topic-language models \cite{miao2017_disc,dieng2016topicrnn,wang2017topic},
we compute  as a function of the context 
using the variational autoencoder technique \cite{kingma2013auto}.
Specifically, we use a feed-forward neural network (FFNN) as an
inference network to
parameterize the mean and variance vectors of the (diagonal) Gaussian variational
distribution . We then
use samples from 
to optimize Eq \ref{eq:elbo}.
The parameters of the inference network, the topic model, and the equation model are jointly trained by stochastic gradient descent.

We also include a topic diversity regularization term
to Eq \ref{eq:elbo}, following \cite{xie2015diversifying}.
We observed that this technique prevents learning generic, redundant topics.





\section{Experiments}
We study the performance of the proposed model on a corpus of
context-equation pairs constructed from arXiv articles.
We quantitatively show that our joint topic-equation model provides superior fits than alternative topic models and equation models.
We further demonstrate its efficacy through qualitative analyses and novel applications, such as equation generation and equation topic inference.


\subsection{Dataset Construction (\textit{ContextEq-400K})}
\label{sec:dataset}
To obtain a dataset of context-equation pairs, we used scientific articles
published on arXiv.org.  We sampled 100k articles from all
domains in the past 5 years, and split them into train, validation
and test sets (80\%, 10\%, 10\%).  For each article, we parsed its
\LaTeX\ source and extracted single-line display equations that have
five consecutive sentences both before and after the
equation, which are used to define the word context.  Following
\cite{deng2017image}, we further tokenized each equation into a
sequence of \LaTeX\ tokens (e.g., \verb|\sigma|, \verb|^|, \verb|{|,
\verb|2|, \verb|}|) and kept those of length 20--150, yielding the final corpus
of 400K equation-context pairs.
An equation has 63 tokens on average. The context size of 10 sentences is similar to the document size used in recent work of topic-language models
\cite{dieng2016topicrnn,wang2017topic}.



\subsection{Experimental Setup}

We fit the TopicEq model end-to-end on the train set and evaluate its performance on the test set.

\paragraph{Preprocessing.}
For the topic modeling of context passages, we first removed all the inline math expressions in the text. We then followed the preprocessing steps in \cite{wang2017topic} to tokenize and lowercase all words, exclude stopwords
and words appearing in fewer than 100 documents; this resulted in a vocabulary size of 8,660.
For equations, we use the 1,000 most frequent \LaTeX\ tokens as our vocabulary.


\begin{table}[t!]
\renewcommand{\arraystretch}{1.05}
\addtolength{\tabcolsep}{0pt}
\hspace{-2mm}
\centering
\scalebox{0.90}{
\begin{tabular}{l||cl}
\Xhline{2.5\arrayrulewidth}
     \multicolumn{1}{c||}{\textbf{Topic Model} \vrule width 0pt height 11.5pt depth 0pt} & ~\textbf{50}~ & ~\textbf{100}~  \scalebox{0.7}[0.75]{(\# Topics)\!\!\!\!}\\\Xhline{2.5\arrayrulewidth}
 \!LDA (context only)~\vrule width 0pt height 12.5pt depth 0pt &  .085 & .083 \\
 \!Ours (context only) \vrule width 0pt height 0pt depth 0pt & .085 & .084  \\
 \!Ours (context + Eq BOW)~\vrule width 0pt & .087   &  .086 \\
 \!Ours (context + Eq LSTM) \vrule width 0pt & {\bf .097} & {\bf .094} \\
 \!Ours (context + Eq LSTM shuffled)\! \vrule width 0pt height 0pt depth 5pt & .086 & .085  \\
 \Xhline{2.5\arrayrulewidth}
\end{tabular}
}\vspace{-2mm}
\caption{Topic coherence of different topic models, evaluated on the held-out arXiv data.
\uline{Our full TopicEq model is shown as
``Ours (context + Eq LSTM).''}
}\vspace{0mm}
\label{tbl:coherence_eval}
\end{table}




\begin{table}[t!]
\addtolength{\tabcolsep}{0pt}
\setlength\cellspacetoplimit{3.5pt}
\setlength\cellspacebottomlimit{2.5pt}
\hspace{-2mm}
\scalebox{0.77}{
\begin{tabular}{Sc|Sl}
\Xhline{1.2pt}
	\!\!\scalebox{0.95}{{\bf Quantum physics}} & \scalebox{0.98}[1]{spin energy field electron magnetic state states hamiltonian}\!\!\!\\
\hdashline[2pt/1.5pt]
	\!\scalebox{0.95}{{\bf Particle physics}}& \scalebox{0.98}[1]{higgs neutrino coupling decay scale masses mixing quark}\\
\hdashline[2pt/1.5pt]
	\!\scalebox{0.95}{{\bf Astrophysics}}& \scalebox{0.98}[1]{mass gas star stellar galaxies disk halo radius luminosity}\!\!\!\\
\hdashline[2pt/1.5pt]
	\!\scalebox{0.95}{{\bf Relativity}} & \scalebox{0.98}[1]{black metric hole schwarzschild gravity holes einstein}\!\!\!\!\\
\hdashline[2pt/1.5pt]
	\!\scalebox{0.95}{{\bf Number theory}} & \scalebox{0.98}[1]{prime integer numbers conjecture integers  degree modulo}\\
\hdashline[2pt/1.5pt]
	\!\scalebox{0.95}{{\bf Graph theory}} & \scalebox{0.98}[1]{graph vertex vertices edges node edge number set tree}\\
\hdashline[2pt/1.5pt]
	\!\scalebox{0.95}{{\bf Linear algebra}} & \scalebox{0.98}[1]{matrix matrices vector basis vectors diagonal rank linear\!\!}\\
\hdashline[2pt/1.5pt]
	\!\scalebox{0.95}{{\bf Optimization}} & \scalebox{0.98}[1]{problem optimization algorithm function solution gradient\!\!}\\
\hdashline[2pt/1.5pt]
	\!\scalebox{0.95}{{\bf Probability}} & \scalebox{0.98}[1]{random probability distribution process measure time}\!\!\!\!\\
\hdashline[2pt/1.5pt]
	\!\!\scalebox{0.95}{{\bf Machine learning}} & \scalebox{0.98}[1]{layer word image feature sentence model cnn lstm training}\\
\Xhline{1.2pt}
\end{tabular} }
\vspace{-3mm}
\caption{Topics learned by the TopicEq model. Left: topic name (summarized by us). Right: top words in topic.}
\label{tb:topics}\vspace{-3mm}
\end{table}








\paragraph{Model setting.}
For the inference network  , we use a 2-layer FFNN
with 300 units, similar to \cite{miao2016neural,miao2017_disc}.
The equation TE-LSTM architecture has two layers and state size 500,
with dropout rate
0.5 applied to each layer \cite{JMLR:v15:srivastava14a}.
The parameters of the TopicEq model are jointly optimized by Adam \cite{kingma2015adam}, with batch size 200, learning rate 0.002, and gradient clipping 1.0 \cite{Pascanu2012}.


\subsection{Topic Model Evaluation}
\label{sec:tm_eval}



We first study the topic modeling performance of TopicEq, by
evaluating the coherence of the learned topics  \cite{chang2009reading,newman2010automatic,mimno2011optimizing}.
Specifically, following \cite{lau2014machine}, we compute the normalized PMI metric on the held-out test set.
As our TopicEq model incorporates {joint}, {RNN-based} equation model, to analyze its effect, we compare the full TopicEq model with the following baseline topic models:
\begin{itemize}[topsep=1pt]
    \setlength{\itemsep}{0mm}
    \setlength{\leftskip}{0mm}
    \item LDA (context only): we apply LDA to the word text
    \item Ours (context only): TopicEq without the equation model
    \item Ours (context + Eq BOW): TopicEq's joint LSTM equation model (Eq \ref{eq:lstm_theta}) is replaced by a baseline bag-of-tokens model similar to that for context words.
\end{itemize}
The evaluation results are summarized in Table \ref{tbl:coherence_eval}.
The full TopicEq model is shown as ``Ours (context + Eq LSTM)'' in the table.
We observe that TopicEq's topic model component (2nd row) performs on a par with LDA (1st row),
but it achieves a significant boost (+0.01) when trained together with the LSTM
equation model (4th row).
Adding equations as bag of tokens (3rd row) does improve topic models marginally (+0.002), but the improvement made by using joint LSTM equation model is 5 times greater.
These results show that a joint RNN equation model provides significant information to aid topic modeling of scientific texts.

\begin{table}[t!]
\renewcommand{\arraystretch}{1.05}
\addtolength{\tabcolsep}{0pt}
\hspace{-1.5mm}
\centering
\scalebox{0.9}{
\begin{tabular}{l||cc|c}
\Xhline{2.5\arrayrulewidth}
    \multirow{2}{*}{\hspace{9mm}\textbf{Equation Model} }  &\multicolumn{2}{c|}{\textbf{Perplexity} \vrule width 0pt height 11pt depth 0pt} & \!\textbf{Error \scalebox{0.6}[0.8]{(\%)}}\!\!\!\\
    \multicolumn{1}{c||}{\textbf{} \vrule width 0pt height 9pt depth 4pt} & ~\textbf{50}~ & ~\textbf{100}~ & ~\textbf{100}~\\
     \Xhline{2.5\arrayrulewidth}
 \hspace{-2mm}\scalebox{0.95}{\textbf{No joint training}} \vrule width 0pt height 12pt depth 4.5pt &   &  &  \\
 \!LSTM (no topic)~\vrule width 0pt height 0pt depth 0pt & 5.81 & 5.81   & 15.3 \\\!LSTM + LDA~\vrule width 0pt depth 0pt & 5.54 & 5.52  & 13.4 \\\hspace{-2mm}\scalebox{0.95}{\textbf{Joint training with topic model}} \vrule width 0pt height 10pt depth 4.5pt &     &  \\
 \!TD-LSTM ~~\,(Lau et al. 2017)\vrule width 0pt height 0pt depth 0pt & 5.44 & 5.41  & 12.5\\
 \!TE-LSTM ~~~(\textbf{Ours}) \vrule width 0pt depth 5pt & {\bf 5.36} & {\bf 5.34}  & {\bf 11.7}\\
 \Xhline{2.5\arrayrulewidth}
\end{tabular}
}\vspace{-2mm}
\caption{Performance of different equation models, evaluated on held-out arXiv data.
We report the perplexity metric (for \# topics 50, 100 if topic info is used), and the syntax error rate of generated \LaTeX\  equations (for \# topics 100).}\vspace{-3mm}
\label{tbl:eq_model_eval}
\end{table}



\paragraph{Why is the RNN helpful?\!\!}

We hypothesize that one
reason why the joint RNN equation model is more helpful than the bag-of-tokens equation model is that the
RNN also captures syntax-level information in equations.
But one might argue that
the introduction of the RNN itself was useful for topic modeling (e.g. as a form of regularization).
To study our hypothesis,
we re-trained TopicEq with each equation's token {order} randomly shuffled in the training data---thus corrupting the syntactic information of each equation.
The result is shown in Table
\ref{tbl:coherence_eval} as ``Ours (context + Eq LSTM shuffled).''
This time, the topic model performance degrades severely and falls to the level of the baseline topic model, ``Ours (context only)''.
This result supports the claim that the original TopicEq's joint RNN actually captured syntactic features of equations, providing more effective help for topic modeling than a bag-of-token equation model does.

This idea also makes intuitive sense. Mathematical equations use a much smaller vocabulary (symbols / variables) than word texts, and thus often need phrase or syntax-level information to aid topic modeling.
For example, in the equations in Figure \ref{fig:context_exm}, phrases like  (use of super/sub-scripts for a tensor) and  (regularization term) provide rich information to identify the topics (relativity and optimization), while
the corresponding bags of tokens
 and  themselves do not provide as much help.



\paragraph{Learned topics.}
To
visualize the topic modeling performance, we sampled 10 topics learned by TopicEq
(Table \ref{tb:topics}).
They intuitively reflect the scientific topics of arXiv articles.



\begin{table}[t!]
    \hspace{-0.5mm}
    \includegraphics[width=0.485\textwidth]{tbl_geneq_more.pdf}\vspace{-3mm}
    \caption{
    The TopicEq model generates equations that
    reflect the characteristics of given topics. Left: topic (picked from Table \protect\ref{tb:topics}). Right: equations {generated by the model} conditioned on the given topic (one-hot topic vector ).
    }\vspace{-3mm}
    \label{tbl:gen_eq}
\end{table}


\subsection{Equation Model Evaluation}
\label{sec:eq_model_eval}

Next, we evaluate the equation model component of TopicEq by measuring the test set perplexity.
Additionally, as the grammaticality of equations can be measured using the \LaTeX\ compiler, we also evaluate the syntax error rate of generated equations.
We compare our TE-LSTM with
\begin{itemize}[topsep=1pt]
    \setlength{\itemsep}{0mm}
    \setlength{\leftskip}{2mm}
    \item a generic LSTM (no topic knowledge)
    \item LSTM\,+\,LDA: the topic vector  obtained from a pre-trained LDA is concatenated to the output of LSTM
\end{itemize}
and a recent topic-dependent LSTM applied to our task
\begin{itemize}[topsep=1pt]
    \setlength{\itemsep}{0mm}
    \setlength{\leftskip}{2mm}
    \item TD-LSTM \cite{lau2017topically}:  is added to the output of LSTM via a dense layer.
\end{itemize}
TD-LSTM and our TE-LSTM are jointly trained with our topic model component.
As Table \ref{tbl:eq_model_eval} shows, all the topic-dependent LSTMs
are superior to the vanilla LSTM in both the perplexity metric and syntax error metric.
Moreover, our TE-LSTM outperforms TD-LSTM, suggesting that the model
better incorporates topic knowledge by embedding  inside the LSTM.
We also find that
compared to \cite{wang2017topic}'s Mixture-of-Expert LSTM, our model achieves similar performance in this task while requiring fewer parameters and much less training time (40\% reduction).
In total, compared to the generic LSTM, our TE-LSTM equation model reduces test perplexity by 8\% (relative) and syntax error rate by 3.5\% (absolute).
This result suggests that incorporating context/topic information can improve the quality and grammaticality of equation modeling.



\section{Qualitative Analysis \& Applications}
\label{sec:applications}


\begin{table}[t!]
\centering
    \includegraphics[width=0.47\textwidth]{tbl_geneq_gradation.pdf}\vspace{-3mm}
    \caption{
    We let the TopicEq model greedily generate equations
    while smoothly changing  between two topics (via linear interpolation).
    Left: given topic pair and its interpolation. Right: generated equation (for the first topic pair, we let the model generate from ; for the second pair, from ).
    }\vspace{-2mm}
    \label{tbl:gen_eq_gradation}
\end{table}


\begin{table}[t!]
\hspace{-6mm}
    \includegraphics[width=0.51\textwidth]{tbl_geneq_mix.pdf}\vspace{-3mm}
    \caption{
    Given a set of context words picked from an article abstract (1st column), we let TopicEq {infer its topic proportions} (2nd col) and {generate equations} (3rd col).
    }\vspace{-3mm}
    \label{tbl:gen_eq_mix}
\end{table}


\begin{table*}[!ht]
\definecolor{mydarkgreen}{HTML}{008000}
\definecolor{mydarkred}{HTML}{dc143c}
\definecolor{mydarkyellow}{HTML}{ff8c00}
\newcommand\bunsuu[2]{
\dfrac{\,\lower.44ex\hbox{}\,}{\,\lower-.1ex\hbox{}\,} }

\centering
\renewcommand\cellalign{lc}
\setlength\cellspacetoplimit{2pt}
\setlength\cellspacebottomlimit{2pt}
\addtolength{\tabcolsep}{0pt}
\scalebox{0.96}{
\begin{tabular}{Sl || Sl | Sl} \Xhline{2\arrayrulewidth}
\multicolumn{1}{Sc ||}{
\multirow{2}{*}{
\makecell{\vrule width 0pt height 11pt depth 5pt
\hspace{15mm}\scalebox{0.9}{\textbf{Given Equation}}\-1.3mm]
    \scalebox{0.8}[0.82]{interaction, wave}~~\raisebox{-2pt}{\textcolor{mydarkgreen}{\ding{51}}}
    } &
    \makecell{
    \scalebox{0.8}[0.82]{time, operator, space, }\-1.3mm]
    \scalebox{0.8}[0.82]{motion, force}~~\raisebox{-2pt}{\textcolor{mydarkgreen}{\ding{51}}}
    }
    &
    \makecell{
    \scalebox{0.8}[0.82]{time, velocity, particle,}\-1.3mm] \scalebox{0.8}[0.82]{strain, stress}~~~~\raisebox{-2pt}{
    \scalebox{1.5}[1]{\textcolor{mydarkyellow}{\textbf{\textit{?}}}}
    }
    }
    &
    \makecell{
    \scalebox{0.8}[0.82]{method, order, solution, }\-1.3mm]
    \scalebox{0.8}[0.82]{feature, network}~~\raisebox{-2pt}{\textcolor{mydarkgreen}{\ding{51}}}
    }
    &
    \makecell{
    \scalebox{0.8}[0.82]{function, section, problem,}\-1.3mm]
    \scalebox{0.8}[0.82]{distribution, entropy}~~\raisebox{-2pt}{\textcolor{mydarkgreen}{\ding{51}}}\!\!\!
    }
    &
    \makecell{
    \scalebox{0.8}[0.82]{probability, random, theorem\!\!}\-1.2mm] ~~~~
    \scalebox{0.55}{[\![Central Limit Theorem]\!]}\!\!\vspace{-0.5mm} \vspace{-0.5mm}
    } &
    \makecell{
    \scalebox{0.8}[0.82]{measure, random, process,}\-1.3mm]
    \scalebox{0.8}[0.82]{variable, distribution}~~\raisebox{-0pt}{\scalebox{0.6}[0.6]{\textcolor{mydarkyellow}{\ding{51}}}}\!\!\!
    }
\\ \hdashline[2pt/1.5pt]
 \makecell{
    \!\scalebox{0.9}{\textbf{\#7}} ~ \scalebox{0.9}[0.9]{} \-1.3mm]
    \scalebox{0.8}[0.82]{fourier, polynomial}~~\raisebox{-2pt}{\textcolor{mydarkgreen}{\ding{51}}}\!\!\!
    }
    &
    \makecell{
    \scalebox{0.8}[0.82]{polynomial, series, function,}\-1.2mm] ~~~~
    \scalebox{0.55}{[\![Taylor Expansion]\!]}\vspace{-1mm}
    } &
    \makecell{
    \scalebox{0.8}[0.82]{coefficients, series, expansion}\-1.3mm]
    \scalebox{0.8}[0.82]{point, solution}~~\raisebox{-2pt}{\scalebox{1.1}{\textcolor{mydarkred}{\ding{55}}}
    }\!\!\!
    \raisebox{-1pt}{\textcolor{mydarkred}{\scalebox{0.8}{{ \sf \sl (fooled)}}}}\!\!\!
    }\!\!\!
\\\Xhline{2\arrayrulewidth}
\end{tabular}}\vspace{-1.5mm}
    \caption{The TopicEq model can infer the appropriate topic for equations from various domains, with better precision and consistency than bag-of-token baseline. Left: given equation. Right: topic {inferred by our model} and the baseline.
    \textcolor{mydarkgreen}{\ding{51}} indicates that the inferred topic is correct; \textcolor{mydarkred}{\ding{55}} not good.
    We verified that the {\it exact} same equations did not appear in the training data.
    }\vspace{-3mm}
    \label{tbl:eq_cap}
\end{table*}


\subsection{Topic-aware Equation Generation}
The TopicEq model can
generate meaningful equations from specified topics, using Eq \ref{eq:lstm_theta} (TE-LSTM).
For example, given a topic , we let  be the one-hot vector representing the topic;
conditioned on , and
starting from \scalebox{0.7}[0.9]{\texttt{\textbf{<START>}}} token, we keep sampling the next \LaTeX\ token until the \scalebox{0.7}[0.9]{\texttt{\textbf{<END>}}} token is generated.
Table \ref{tbl:gen_eq}
shows
several topics picked from Table \ref{tb:topics} (left), and
equations generated from each of these topics (right).
We see that the artificial equations generated by the model
clearly reflect the distinctive characteristics of the given topics.
For instance, derivatives, and number\,+\,units are generally used for physics; electron configuration \scalebox{0.8}{} for quantum physics;
series of tensors like  for relativity;
prime number  for number theory;
,  clauses for probability.
We also note that the equations generated by our TE-LSTM use not only topic-specific symbols but also topic-specific phrases and syntax (e.g., a set definition is used for linear algebra; `` subject to'' clause for optimization).
These qualitative results support that TopicEq is capable of fully incorporating topic information for equation modeling.


\paragraph{Mixtures of topics.}
The model can also generate equations from a mixture of topics by setting  accordingly.
To qualitatively analyze the space of the topic vector  in terms of equation generation,
we let the model generate equations while smoothly changing  between two topics (i.e., one-hot vectors  and ) via linear interpolation:  for .
In Table \ref{tbl:gen_eq_gradation}, for two examples we
show the given topic pair and its interpolation (left), and the equation greedily decoded from each  (right).
We let the model start all equations from  in the first example (astrophysics and graph theory), and from  in the second example (optmization and statistics).
In both cases
we observe that the generated equations make a smooth transition from one topic to the other --- e.g., for the first example,
from using  (astrophysics) to
using linear algebraic term ,
and finally a set notation (graph theory).
In the second example, where the two topics optimization and statistics are closely related, the generated equations make a very intuitive transition:
from an optimization objective with norms and regularization terms (top),
to using summation terms (middle) and finally expectations (bottom; statistics topic).
These observations support that {TopicEq  learns smooth representations for the latent topic vector } (especially for a mixture of closely related topics), regarding equation generation.





Finally, we illustrate that the model can generate  equations from a given set of context words.
Specifically, we let the model infer the topic proportion  of the context words via the inference network , and then generate equations from  via Eq \ref{eq:lstm_theta} (TE-LSTM).
As Table \ref{tbl:gen_eq_mix} shows,
the model is able to infer the right topic mixture (2nd column)
and generate equations
that reflect those topics (e.g., solar mass  and radius  are used for the top example; loss function , , and  for the bottom example).







\subsection{Equation Topic Inference}

Identifying the topic of equations is an important task that allows readers to obtain semantic descriptions for equations unfamiliar to them.
However, while some work \cite{schubotz2016semantification,stathopoulos2018variable} has studied the task of identifying the meaning of individual mathematical symbols, no prior work has succeeded in providing descriptions to entire equations from various domains.

Our TopicEq model can be utilized
to identify the topic of given equations. Specifically,
with a trained TopicEq model,
for a given equation , we find the topic 
(so  is a one-hot vector) that maximizes the likelihood
 in Eq \ref{eq:lstm_theta}, which is parametrized by our topic-dependent LSTM.
Table \ref{tbl:eq_cap} shows examples of equations across different domains (1st column), and the most likely topic inferred by our model for each equation (2nd column). We used  topics in this task.
We observe that the TopicEq model correctly identifies the domains or even finer topics
(e.g., note the distinction between \textbf{\#5} and \textbf{\#6}) for most of the
given equations.

\begin{table*}[h]
\centering
\renewcommand\cellalign{lc}
\setlength\cellspacetoplimit{1pt}
\setlength\cellspacebottomlimit{1pt}
\addtolength{\tabcolsep}{1pt}
\scalebox{0.78}{
\begin{tabular}{Sc || Sc || Sc | Sc | Sc} \Xhline{3\arrayrulewidth}
\multirow{2}{*}{
\makecell{ \vrule width 0pt height 12pt depth 0pt
\textbf{Math}\-0.7mm] transfer matrix}
 &
 \makecell{stopping time, test statistic}
 &
 \makecell{temperature,\-0.7mm] triangulation}
 \\ \hdashline[2pt/1.5pt]
 \makecell{\vrule width 0pt height 12pt depth 0pt \scalebox{1.15}{}}
 &
 \makecell{potential, voltage, visibility, volume}
 &
 \makecell{variance, volatility}
 &
 \makecell{voltage, potential energy}
 &
 \makecell{vertex, volume, \scalebox{1}[1]{SVD}}
 \\ \hdashline[2pt/1.5pt]
 \makecell{}
 &
 \makecell{conductivity, variance,\-0.7mm] normal distribution}
 &
 \makecell{conductivity,\
    w \sim \text{Mult}(\text{softmax}(A \boldsymbol{s}))

    A(\theta) = W_a \cdot \text{diag} (W_b \theta) \cdot W_c

where , , 
are parameters to estimate.  is the number of factors, which we set to be equal to the number of topics .
To jointly perform topic modeling and alignment learning, we consider a variant of TopicEq, where we just replace Eq \ref{eq:lstm_theta} by this topic-dependent alignment model. We train it on the \textit{ContextEq} corpus.







\subsection{Results and Discussion}

Table \ref{tbl:alignmnet_eval} shows the perplexity of the baseline \!/\! topic-aware alignment models evaluated on the held-out test set.
We observe that the
topic information significantly
improves the alignment between math symbols and word descriptions, reducing the perplexity by more than 33\% (relative).

\begin{table}[t!]
\renewcommand{\arraystretch}{1.05}
\addtolength{\tabcolsep}{0pt}
\hspace{-2mm}
\centering
\scalebox{0.85}{
\begin{tabular}{l||cl}
\Xhline{2.5\arrayrulewidth}
     \multicolumn{1}{c||}{\textbf{Alignment Model} \vrule width 0pt height 11pt depth 5pt} & ~\textbf{50}~ & \textbf{100}~  \scalebox{0.7}[0.75]{(\# Topics)\!\!\!\!}\\\Xhline{2.5\arrayrulewidth}
 Baseline (no topic) \vrule width 0pt height 11pt depth 0pt &  602 & 602 \\
 Topic-Aware  \vrule width 0pt depth 4.5pt &  \textbf{406} &  \textbf{387} \\
 \Xhline{2.5\arrayrulewidth}
\end{tabular}
}\vspace{-2mm}
\caption{Test perplexity for phrase prediction.
}\vspace{-4mm}
\label{tbl:alignmnet_eval}
\end{table}

\begin{table}[t!]
\renewcommand{\arraystretch}{1.05}
\addtolength{\tabcolsep}{0pt}
\centering
\scalebox{0.85}{
\begin{tabular}{l||cl}
\Xhline{2.5\arrayrulewidth}
     \multicolumn{1}{c||}{\textbf{Topic Model} \vrule width 0pt height 11pt depth 5pt} & ~\textbf{50}~ &  ~\textbf{100}~  \scalebox{0.7}[0.75]{(\# Topics)\!\!\!\!}\\\Xhline{2.5\arrayrulewidth}

 \!Context Only \vrule width 0pt height 11pt depth 0pt & .085 & .084  \\
 \!with joint \scalebox{1}[1]{Alignment Model}~\vrule width 0pt depth 4.5pt & \textbf{.088}   &  \textbf{.087} \\
 \Xhline{2.5\arrayrulewidth}
\end{tabular}
}\vspace{-2mm}
\caption{Topic coherence evaluation for each topic model.}\vspace{-4mm}
\label{tbl:topic_alignmnet_eval}
\end{table}


~\vspace{-3mm}

\noindent
\textbf{Qualitative results.~~}
Table \ref{tbl:alignment_demo} shows the actual top phrases predicted by the alignment models for several math symbols that are used in a wide range of domains.
The proposed TopicEq variant indeed learns the topic-dependent alignment between symbols and words. For instance,
it associates  with ``expectation'' for the probability topic, ``electric field'' for quantum physics, and ``edge'' for graph theory, which makes intuitive sense.
On the other hand,
the baseline (no topic) model associates  with ``energy'', which is simply the description that appears most frequently across all articles.\\
This is another example where the TopicEq framework can be used to capture the relation of topics and mathematics.


\paragraph{Utility.}
We also note that our topic-aware alignment model can be conditioned on a mixture of topics by setting  accordingly.
Given a context text and equation, this model can infer the topic proportion by the topic model component, and then use the topic-aware alignment component to infer
the most probable meaning of each variable in the given equation.
This could aid readers to comprehend scientific documents containing mathematics unfamiliar to them.


\paragraph{Effect on topic modeling.}
In Table \ref{tbl:topic_alignmnet_eval}, we compare  our baseline topic model (top) and this TopicEq variant with the alignment component (bottom).
The joint alignment model provides moderate improvements for topic modeling quality.








\section{Conclusion}
Motivated by the topical correspondence between text and mathematical equations observed in scientific documents,
we proposed \textit{TopicEq}, a joint topic-equation model that generates the text by a topic model and the equations by a topic-dependent RNN.
This joint model outperforms
existing topic models and equation models for scientific texts.
We also qualitatively analyzed TopicEq, and showed its applications and extensions, such as
equation topic inference and topic-aware alignment of mathematical symbols and words.







\subsection*{Acknowledgments}
We thank Matt Bonakdarpour, Paul Ginsparg, Samuel Helms, and
Kriste Krstovski for their assistance, and Jungo Kasai as well as the anonymous reviewers for their feedback.
This work was supported in part by a grant from the Alfred P. Sloan Foundation.




\bibliography{aaai19}
\bibliographystyle{aaai}

\end{document}
