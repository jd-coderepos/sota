

\documentclass[10pt,twocolumn,letterpaper]{article}

\usepackage{cvpr}              

\usepackage{graphicx}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{booktabs}
\usepackage{algorithm}
\usepackage{algorithmic}
\usepackage{enumitem}
\usepackage[table]{xcolor}
\usepackage{multirow}



\usepackage{ntheorem}
\newtheorem{theorem}{Theorem}[section]
\newtheorem*{proof}{Proof}
\newtheorem{lemma}{Lemma}
\newtheorem{corollary}{Corollary}
\newtheorem{definition}{Definition}


\usepackage[pagebackref,breaklinks,colorlinks]{hyperref}


\usepackage[capitalize]{cleveref}
\crefname{section}{Sec.}{Secs.}
\Crefname{section}{Section}{Sections}
\Crefname{table}{Table}{Tables}
\crefname{table}{Tab.}{Tabs.}


\def\cvprPaperID{453} \def\confName{CVPR}
\def\confYear{2023}


\begin{document}

\title{Curvature-Balanced Feature Manifold Learning for Long-Tailed Classification}

\author{Yanbiao Ma, Licheng Jiao, Fang Liu, Shuyuan Yang, Xu Liu and Lingling Li\\
\normalsize {Key Laboratory of Intelligent Perception and Image Understanding of the Ministry of Education, Xidian University}\\
{\tt\normalsize ybmamail@stu.xidian.edu.cn, lchjiao@mail.xidian.edu.cn}}

\iffalse
\author{\setlength{\baselineskip}{12.5pt}{\name Yanbiao Ma, Licheng Jiao, Fang Liu, Yuxin Li, Shuyuan Yang, Xu Liu \\
      \addr \normalsize Key Laboratory of Intelligent Perception and Image Understanding of the Ministry of Education, Xidian University \\ 
      \email \normalsize ybmamail@stu.xidian.edu.cn, lchjiao@mail.xidian.edu.cn, \\ f63liu@163.com, syyang@xidian.edu.cn, xuliu361@163.com 
}}
\fi

\iffalse
\author{Yanbiao Ma\\
Institution1\\
Institution1 address\\
{\tt\small firstauthor@i1.org}
\and
Second Author\\
Institution2\\
First line of institution2 address\\
{\tt\small secondauthor@i2.org}
}
\fi

\maketitle

\begin{abstract}
To address the challenges of long-tailed classification, researchers have proposed several approaches to reduce model bias, most of which assume that classes with few samples are weak classes. However, recent studies have shown that tail classes are not always hard to learn, and model bias has been observed on sample-balanced datasets, suggesting the existence of other factors that affect model bias. In this work, we systematically propose a series of geometric measurements for perceptual manifolds in deep neural networks, and then explore the effect of the geometric characteristics of perceptual manifolds on classification difficulty and how learning shapes the geometric characteristics of perceptual manifolds. An unanticipated finding is that the correlation between the class accuracy and the separation degree of perceptual manifolds gradually decreases during training, while the negative correlation with the curvature gradually increases, implying that curvature imbalance leads to model bias. Therefore, we propose curvature regularization to facilitate the model to learn curvature-balanced and flatter perceptual manifolds. Evaluations on multiple long-tailed and non-long-tailed datasets show the excellent performance and exciting generality of our approach, especially in achieving significant performance improvements based on current state-of-the-art techniques. Our work opens up a geometric analysis perspective on model bias and reminds researchers to pay attention to model bias on non-long-tailed and even sample-balanced datasets. The code and model will be made public.
\end{abstract}
\vspace{-20pt}
\section{Introduction}

The imbalance of sample numbers in the dataset gives rise to the challenge of long-tailed visual recognition. Most previous works assume that head classes are always easier to be learned than tail classes, e.g., class re-balancing \cite{paper4,paper2,paper14,paper3,paper36,paper37,paper9}, information augmentation \cite{paper38,paper39,paper40,paper41,paper42,paper12,paper43,paper44,paper47}, decoupled training \cite{paper35,paper29,paper1,paper10,paper11,paper46}, and ensemble learning \cite{paper5,paper30,paper31,paper32,paper33,paper7,paper34} have been proposed to improve the performance of tail classes. However, recent studies \cite{paper27, paper28} have shown that classification difficulty is not always correlated with the number of samples, e.g., the performance of some tail classes is even higher than that of the head classes. Also, \cite{paper45} observes differences in model performance across classes on non-long-tailed data, and even on balanced data. Therefore, it is necessary to explore the impact of other inherent characteristics of the data on the classification difficulty, and then improve the overall performance by mitigating the model bias under multiple sample number distribution scenarios.

\begin{figure}[t]
\vskip -0.15in
\centering
\centerline{\includegraphics[width=1\columnwidth]{1}}
\vskip -0.1in
\caption{Curvature regularization reduces the model bias present in multiple methods on CIFAR-100-LT and ImageNet-LT. The model bias is measured with the variance of the accuracy of all classes, and it is zero when the accuracy of each class is the same.}
\label{fig1}
\vskip -0.2in
\end{figure}

\renewcommand{\thefootnote}{}
\footnotetext{This work was supported in part by
the Key Scientific Technological Innovation Research Project by Ministry of Education,
the State Key Program and the Foundation for Innovative Research Groups of the National Natural Science Foundation of China (61836009),
the Major Research Plan of the National Natural Science Foundation of China (91438201, 91438103, and 91838303),
the National Natural Science Foundation of China (U22B2054, U1701267, 62076192, 62006177, 61902298, 61573267, 61906150, and 62276199),
the 111 Project,
the Program for Cheung Kong Scholars and Innovative Research Team in University (IRT 15R53),
the ST Innovation Project from the Chinese Ministry of Education,
the Key Research and Development Program in Shaanxi Province of China(2019ZDLGY03-06),
the National Science Basic Research Plan in Shaanxi Province of China(2022JQ-607),
the China Postdoctoral fund(2022T150506),
the Scientific Research Project of Education Department In Shaanxi Province of China (No.20JY023),
the National Natural Science Foundation of China (No. 61977052).}

Focal loss \cite{paper3} utilizes the DNN's prediction confidence on instances to evaluate the instance-level difficulty. \cite{paper27} argues that for long-tailed problems, determining class-level difficulty is more important than determining instance-level difficulty, and therefore defines classification difficulty by evaluating the accuracy of each class in real-time. However, both methods rely on the model output and still cannot explain why the model performs well in some classes and poorly in others. Similar to the number of samples, we would like to propose a measure that relies solely on the data itself to model class-level difficulty, which helps to understand how deep neural networks learn from the data. The effective number of samples \cite{paper4} tries to characterize the diversity of features in each class, but it introduces hyperparameters and would not work in a sample-balanced dataset.

Most data distributions obey the manifold distribution law \cite{paper48,paper49}, i.e., samples of each class are distributed near a low-dimensional manifold in the high-dimensional space. The manifold consisting of features in the embedding space is called a perceptual manifold \cite{paper50}. The classification task is equivalent to distinguishing each perceptual manifold, which has a series of geometric characteristics. We speculate that some geometric characteristics may affect the classification difficulty, and therefore conduct an in-depth study. \textbf{The main contributions of our work are:} \textbf{(1)} We systematically propose a series of measurements for the geometric characteristics of point cloud perceptual manifolds in deep neural networks (Sec \ref{sec3}). \textbf{(2)} The effect of learning on the separation degree (Sec \ref{sec4.1}) and curvature (Sec \ref{sec4.2}) of perceptual manifolds is explored. We find that the correlation between separation degree and class accuracy decreases with training, while the negative correlation between curvature and class accuracy increases with training (Sec \ref{sec4.3}), implying that existing methods can only mitigate the effect of separation degree among perceptual manifolds on model bias, while ignoring the effect of perceptual manifold complexity on model bias. \textbf{(3)} Curvature regularization is proposed to facilitate the model to learn curvature-balanced and flatter feature manifolds, thus improving the overall performance (Sec \ref{sec5}). Our approach effectively reduces the model bias on multiple long-tailed (Fig \ref{fig1}) and non-long-tailed datasets (Fig \ref{fig8}), showing excellent performance (Sec \ref{sec6}).

\section{Related Work (Appendix \textcolor{red}{A})}



\section{The Geometry of Perceptual Manifold}
\label{sec3}
In this section, we systematically propose a series of geometric measures for perceptual manifolds in deep neural networks, and all the pseudocode is in Appendix \textcolor{red}{C}.

\subsection{Perceptual Manifold}
\label{sec3.1}
A perceptual manifold is generated when neurons are stimulated by objects with different physical characteristics from the same class. Sampling along the different dimensions of the manifold corresponds to changes in specific physical characteristics. It has been shown \cite{paper48,paper49} that the features extracted by deep neural networks obey the manifold distribution law. That is, features from the same class are distributed near a low-dimensional manifold in the high-dimensional feature space. Given data  from the same class and a deep neural network , where  represents a feature sub-network with parameters  and  represents a classifier with parameters . Extract the p-dimensional features  of  with the trained model, where . Assuming that the features  belong to class , the  features form a -dimensional point cloud manifold , which is called a perceptual manifold \cite{paper51}. 

\subsection{The Volume of Perceptual Manifold}
\label{sec3.2}
We measure the volume of the perceptual manifold  by calculating the size of the subspace spanned by the features . First, the sample covariance matrix of  can be estimated as 
Diagonalize the covariance matrix  as , where  and .  and  denote the -th eigenvalue of  and its corresponding eigenvector, respectively. Let the singular value of matrix  be . According to the geometric meaning of singular value \cite{paper52}, the volume of the space spanned by vectors  is proportional to the product of the singular values of matrix , i.e., . Considering , the volume of the perceived manifold is therefore denoted as .

However, when  is a non-full rank matrix, its determinant is . For example, the determinant of a planar point set located in three-dimensional space is 0 because its covariance matrix has zero eigenvalues, but obviously the volume of the subspace tensed by the point set in the plane is non-zero. We want to obtain the ``area'' of the planar point set, which is a generalized volume. We avoid the non-full rank case by adding the unit matrix  to the covariance matrix .  is a positive definite matrix with eigenvalues . The above operation enables us to calculate the volume of a low-dimensional manifold embedded in high-dimensional space. The volume  of the perceptual manifold is proportional to . Considering the numerical stability, we further perform a logarithmic transformation on  and define the volume of the perceptual manifold as  where  is the mean of . When , . Since  is a positive definite matrix, its determinant is greater than 0. In the following, the degree of separation between perceptual manifolds will be proposed based on the volume of perceptual manifolds.

\subsection{The Separation Degree of Perceptual Manifold}
\label{sec3.3}
\iffalse
Euclidean or cosine distances between class centers are often applied to measure inter-class distances, and these two distances are also commonly used as loss functions when constructing sample pairs. However, maximizing the distance between proxy points or samples cannot keep a class away from all the remaining classes at the same time, and the distance between class centers does not reflect the degree of overlap of the distribution. In this section, we propose a measure of the separation degree between perceptual manifolds.
\fi

Given the perceptual manifolds  and , they consist of point sets  and , respectively. The volumes of  and  are calculated as  and . Consider the following case, assuming that  and  have partially overlapped, when , it is obvious that the overlapped volume accounts for a larger proportion of the volume of , when the class corresponding to  is more likely to be confused. Therefore, it is necessary to construct an asymmetric measure for the degree of separation between multiple perceptual manifolds, and we expect this measure to accurately reflect the relative magnitude of the degree of separation.

Suppose there are  perceptual manifolds , which consist of point sets . Let , , we define the degree of separation between the perceptual manifold  and the rest of the perceptual manifolds as 

The following analysis is performed for the case when  and . According to our motivation, the measure of the degree of separation between perceptual manifolds should satisfy . 

If  holds, then we can get 
\begin{small}

\end{small}
We prove that  holds when  and the detailed proof is in Appendix \textcolor{red}{B}. The above analysis shows that the proposed measure meets our requirements and motivation. The formula for calculating the degree of separation between perceptual manifolds can be further reduced to 



\begin{figure}[t]
\centering
\centerline{\includegraphics[width=1\columnwidth]{2}}
\vskip -0.12in
\caption{The variation curve between the separation degree of two spherical point clouds and the distance between spherical centers.}
\label{fig2}
\vskip -0.25in
\end{figure}

The detailed derivation is in Appendix \textcolor{red}{B}. Next, we validate the proposed measure of the separation degree between perceptual manifolds in a 3D spherical point cloud scene. Specifically, we conducted the experiments in two cases: 

(1) Construct two 3D spherical point clouds of radius , and then increase the distance between their spherical centers. Since the volumes of the two spherical point clouds are equal, their separation degrees should be symmetric. The variation curves of the separation degrees are plotted in Fig \ref{fig2}, and it can be seen that the experimental results satisfy our theoretical predictions.

(2) Change the distance between the centers of two spherical point clouds of radius  and radius . Observe their separation degrees, the separation degrees of these two spherical point clouds should be asymmetric. Fig \ref{fig2} shows that their separation degrees increase as the distance between their centers increases. Also, the manifold with a larger radius has a greater separation degree, and this experimental result conforms to our analysis and motivation.

The separation degree between perceptual manifolds may affect the model's bias towards classes. In addition, it can also be used as the regularization term of the loss function or applied in contrast learning to keep the different perceptual manifolds away from each other.

\subsection{The Curvature of Perceptual Manifold}
\label{sec3.4}

Given a point cloud perceptual manifold , which consists of a -dimensional point set , our goal is to calculate the Gauss curvature at each point. First, the normal vector at each point on  is estimated by the neighbor points. Denote by  the -th neighbor point of  and  the normal vector at . We solve for the normal vector by minimizing the inner product of  and  \cite{paper53}, i.e.,  where  and  is the number of neighbor points. Let , then the optimization objective is converted to

 is the covariance matrix of  neighbors of . Therefore, let  and . The optimization objective is further equated to

Construct the Lagrangian function  for the above optimization objective, where  is a parameter. The first-order partial derivatives of  with respect to  and  are

Let  and  be , we can get . It is obvious that solving for  is equivalent to calculating the eigenvectors of the covariance matrix , but the eigenvectors are not unique. From  we can get , so the optimization problem is equated to . Performing the eigenvalue decomposition on the matrix  yields  eigenvalues  and the corresponding -dimensional eigenvectors , where , , . The eigenvector  corresponding to the smallest non-zero eigenvalue of the matrix  is taken as the normal vector  of  at . 

Consider an -dimensional affine space with center , which is spanned by . This affine space approximates the tangent space at  on . We estimate the curvature of  at  by fitting a quadratic hypersurface in the tangent space utilizing the neighbor points of . The  neighbors of  are projected into the affine space  and denoted as 
\begin{small}

\end{small}
Denote by  the -th component  of . We use  and  neighbor points to fit a quadratic hypersurface  with parameter . The hypersurface equation is denoted as

further, minimize the squared error

Let  yield a nonlinear system of equations, but it needs to be solved iteratively. Here, we propose an ingenious method to fit the hypersurface and \textbf{give the analytic solution of the parameter } directly. Expand the parameter  of the hypersurface into the column vector

Organize the  neighbor points  of  according to the following form:
\begin{scriptsize}

\end{scriptsize}
The target value is
\begin{small}

\end{small}
We minimize the squared error

and find the partial derivative of  for :
\begin{small}

\end{small}
Let , we can get

Thus, the Gauss curvature of the perceptual manifold  at  can be calculated as



\begin{figure}[t]
\centering
\centerline{\includegraphics[width=1\columnwidth]{3}}
\vskip -0.05in
\caption{The surface equations in the first and second rows are  and , respectively. We increase the curvature of the surface by increasing  and calculate the complexity of the two-dimensional point cloud surface. Also, we investigate the effect of the number of neighbors  on the complexity of the manifold.}
\label{fig3}
\vskip -0.1in
\end{figure}

Up to this point, we provide an approximate solution of the Gauss curvature at any point on the point cloud perceptual manifold . \cite{paper56} shows that on a high-dimensional dataset, almost all samples lie on convex locations, and thus the complexity of the perceptual manifold is defined as the average  of the Gauss curvatures at all points on . Our approach does not require iterative optimization and can be quickly deployed in a deep neural network to calculate the Gauss curvature of the perceptual manifold. Taking the two-dimensional surface in Fig \ref{fig3} as an example, the surface complexity increases as the surface curvature is artificially increased. This indicates that our proposed complexity measure of perceptual manifold can accurately reflect the changing trend of the curvature degree of the manifold. In addition, Fig \ref{fig3} shows that the selection of the number of neighboring points hardly affects the monotonicity of the complexity of the perceptual manifold. In our work, we select the number of neighboring points to be .

\section{Learning How to Shape Perceptual Manifold}
\label{sec4}

The perceptual manifolds in feature space are further decoded by the classification network into predicted probabilities for classification. Intuitively, we speculate that a perceptual manifold is easier to be decoded by the classification network when it is farther away from other perceptual manifolds and flatter. We provide more geometric views on classification and object detection in Appendix \textcolor{red}{I}. A model is usually considered to be biased when its performance on classes is inconsistent. In the following, we investigate the effect of the geometry of the perceptual manifold on the model bias and summarize three experimental discoveries.

\subsection{Learning Facilitates The Separation}
\label{sec4.1}

Learning typically leads to greater inter-class distance, which equates to greater separation between perceptual manifolds. We trained VGG-16 \cite{paper16} and ResNet-18 \cite{paper21} on F-MNIST \cite{paper55} and CIFAR-10 \cite{paper25} to explore the effect of the learning process on the separation degree between perceptual manifolds and observed the following phenomenon.

\begin{figure}[b]
\vskip -0.1in
\centering
\centerline{\includegraphics[width=1\columnwidth]{4}}
\vskip -0.10in
\caption{The variation curves between the separation degree of perceptual manifolds and training epochs on both datasets.}
\label{fig4}
\vskip -0.07in
\end{figure}

As shown in Fig \ref{fig4}, each perceptual manifold is gradually separated from the other manifolds during training. It is noteworthy that the separation is faster in the early stage of training, and the increment of separation degree gradually decreases in the later stage. Separation curves of perceptual manifolds for more classes are presented in Appendix \textcolor{red}{D}.

\subsection{Learning Reduces The Curvature}
\label{sec4.2}

\begin{figure}[h]
\centering
\centerline{\includegraphics[width=1\columnwidth]{5}}
\vskip -0.1in
\caption{The variation curves between the complexity of perceptual manifolds and training epochs on both datasets.}
\label{fig5}
\vskip -0.2in
\end{figure}

Experiments are conducted with VGG-16 and ResNet-18 trained on F-MNIST and CIFAR-10, and we find that the perceptual manifold gradually flattens out during training. As shown in Fig \ref{fig5}, the curvature of the perceptual manifold decreases faster in the early stage of training, and it gradually becomes flat with further training. The curvature change curves of perceptual manifolds for more classes are shown in Appendix \textcolor{red}{E}.

\subsection{Curvature Imbalance and Model Bias}
\label{sec4.3}

Since learning separates perceptual manifolds from each other and also makes perceptual manifolds flatter, it is reasonable to speculate that the separation degree and curvature of perceptual manifolds correlate with class-wise classification difficulty. Experiments are conducted with VGG-16 and ResNet-18 trained on F-MNIST and CIFAR-10.

\begin{figure}[h]
\centering
\vskip -0.05in
\centerline{\includegraphics[width=1\columnwidth]{7}}
\vskip -0.1in
\caption{The Pearson correlation coefficients (PCCs) between the accuracy of all classes and the separation degree and complexity of the corresponding perceptual manifolds, respectively.}
\label{fig6}
\vskip -0.07in
\end{figure}

Each class corresponds to a perceptual manifold. As shown in Fig \ref{fig6}, we observe that the negative correlation between the separation degree of the perceptual manifolds and the accuracy of the corresponding class decreases with training, while the correlation between the curvature and the accuracy increases. This implies that existing methods can only mitigate the effect of the separation degree between perceptual manifolds on the model bias, while ignoring the effect of perceptual manifold complexity on the model bias.

\section{Curvature-Balanced Feature Learning}
\label{sec5}


The above study shows that it is necessary to focus on the model bias caused by the curvature imbalance among perceptual manifolds. In this section, we propose curvature regularization, which can reduce the model bias and further improve the performance of existing methods.

\subsection{Design Principles of The Proposed Approach}
\label{sec5.1}

The proposed curvature regularization needs to satisfy the following three principles to learn curvature-balanced and flat perceptual manifolds.

\textbf{(1)} The greater the curvature of a perceptual manifold, the stronger the penalty for it. Our experiments show that learning reduces the curvature, so it is reasonable to assume that flatter perceptual manifolds are easier to decode.
\textbf{(2)} When the curvature is balanced, the penalty strength is the same for each perceptual manifold.
\textbf{(3)} The sum of the curvatures of all perceptual manifolds tends to decrease.


\iffalse
\begin{itemize}
    \item The greater the curvature of a perceptual manifold, the stronger the penalty for it.
    \item When the curvature is balanced, the penalty strength is the same for each perceptual manifold.
     \item The sum of the curvatures of all perceptual manifolds tends to decrease.
\end{itemize}
\fi


\subsection{Curvature Regularization (CR)}
\label{sec5.2}

Given a  classification task, the -dimensional feature embeddings of images from each class are represented as . The mean Gaussian curvature  of the corresponding perceptual manifold is calculated with the feature embeddings of each class (Appendix \textcolor{red}{C}.Algorithm \ref{alg5}). First, take the inverse of the curvature  and perform the maximum normalization on it. Then the negative logarithmic transformation is executed on the normalized curvature, and the curvature penalty term of the perceptual manifold  is . Further, the overall curvature regularization term is denoted as 

The detailed derivation is shown in Appendix \textcolor{red}{F}. In the following, we verify whether  satisfies the three principles one by one.

\begin{itemize}
\item[\textbf{(1)}] When the curvature  of the perceptual manifold is larger,  is smaller. Since  is monotonically decreasing,  increases with  increases.  is consistent with Principle 1.

\item[\textbf{(2)}] When , , so .  follows Principle 2.

\item[\textbf{(3)}] The curvature penalty term of the perceptual manifold  is  when . Since the greater the curvature, the greater the penalty, our method aims to bring the curvature of all perceptual manifolds down to . Obviously, , so our approach promotes curvature balance while also making all perceptual manifolds flatter, which satisfies Principle 3.
\end{itemize}

The curvature regularization can be combined with any loss function. Since the correlation between curvature and accuracy increases with training, we balance the curvature regularization with other losses using a logarithmic function with a hyperparameter , and the overall loss is denoted as
\begin{small}

\end{small}

The term  aims to make the curvature regularization loss of the same magnitude as the original loss. We investigate reasonable values of  in experiments (Sec \ref{sec6.2}). The design principle of curvature regularization is compatible with the learning objective of the model, and our experiments show that the effect of curvature imbalance on model bias has been neglected in the past. Thus curvature regularization is not in conflict with , as evidenced by our outstanding performance on multiple datasets.


\subsection{Dynamic Curvature Regularization (DCR)}
\label{sec5.3}

The curvature of perceptual manifolds varies with the model parameters during training, so it is necessary to update the curvature of each perceptual manifold in real-time. However, there is a challenge: only one batch of features is available at each iteration, and it is not possible to obtain all the features to calculate the curvature of the perceptual manifolds. If the features of all images from the training set are extracted using the current network at each iteration, it will greatly increase the time cost of training.

\begin{algorithm}[h]
\caption{End-to-end training with DCR}
\label{alg1}
\footnotesize{
\textbf{Require}: Training set . A CNN , where  and  denote the feature sub-network and classifier, respectively. The training epoch is .
\begin{algorithmic}[1] \STATE Initialize the storage pool Q
\FOR{ to }
\FOR{ to }
\STATE Sample a mini-batch  from .
\STATE Calculate feature embeddings .
\STATE Store  and label  into .
\IF {}
\IF {}
\STATE \textcolor{blue}{Dequeue the oldest batch of features from .}
\ENDIF 
\STATE \textcolor{blue}{Calculate loss .}
\ELSE
\STATE \textcolor{red}{Dequeue the oldest batch of features from .}
\STATE \textcolor{red}{Calculate the curvature of each perceptual manifold.}
\STATE \textcolor{red}{Calculate loss: \\ .}
\ENDIF
\STATE Perform back propagation: .
\STATE .
\ENDFOR
\ENDFOR
\end{algorithmic}}
\end{algorithm}

Inspired by \cite{paper15,paper28}, we design a first-in-first-out storage pool to store the latest historical features of all images. The slow drift phenomenon of features found by \cite{paper54} ensures the reliability of using historical features to approximate the current features. We show the training process in Algorithm \ref{alg1}. Specifically, the features of all batches are stored in the storage pool at the first epoch. To ensure that the drift of the features is small enough, it is necessary to train another  epochs to update the historical features. Experiments of \cite{paper28} on large-scale datasets show that  taken as  is sufficient, so  is set to  in this work. When , the oldest batch of features in the storage pool is replaced with new features at each iteration, and the curvature of each perceptual manifold is calculated using all features in the storage pool. The curvature regularization term is updated based on the latest curvature.
\textbf{It should be noted} that for decoupled training, CR is applied in the feature learning stage. Our method is employed in training only and does not affect the inference speed of the model.




\section{Experiments}
\label{sec6}

\subsection{Datasets and Implementation Details}
\label{sec6.1}

We comprehensively evaluate the effectiveness and generality of curvature regularization on both long-tailed and non-long-tailed datasets. The experiment is divided into two parts, the first part tests curvature regularization on four long-tailed datasets, namely CIFAR-10-LT, CIFAR-100-LT \cite{paper4}, ImageNet-LT \cite{paper4,paper26}, and iNaturalist2018 \cite{paper24}. The second part validates the curvature regularization on two non-long tail datasets, namely CIFAR-100 \cite{paper25} and ImageNet \cite{paper26}. For a fair comparison, the training and test images of all datasets are officially split, and the Top-1 accuracy on the test set is utilized as a performance metric. In addition, we train models on CIFAR-100, CIFAR-10/100-LT with a single NVIDIA 2080Ti GPU and ImageNet, ImageNet-LT, and iNaturalist2018 with eight NVIDIA 2080Ti GPUs. Please refer to Appendix \textcolor{red}{G} for a detailed description of the dataset and experimental setup.

\subsection{Effect of }
\label{sec6.2}

When , , so the selection of  is related to the number of epochs. When the correlation between curvature and accuracy exceeds the correlation between the separation degree and accuracy, we expect , which means that the curvature regularization loss is greater than the original loss. Following the \cite{paper8} setting, all models are trained for  epochs, so  is less than . To search for the proper value of , experiments are conducted for CE + CR with a range of , and the results are shown in Fig \ref{fig7}. Large-scale datasets require more training epochs to keep the perceptual manifolds away from each other, while small-scale datasets can achieve this faster, so we set  on CIFAR-10/100-LT and CIFAR-100, and  on ImageNet, ImageNet-LT, and iNaturalist2018.


\subsection{Experiments on Long-Tailed Datasets}
\label{sec6.3}
\subsubsection{Evaluation on CIFAR-10/100-LT}

\begin{figure}[t]
\centering
\centerline{\includegraphics[width=1.04\columnwidth]{6}}
\vskip -0.16in
\caption{The effect of  on accuracy for both datasets.}
\label{fig7}
\vskip -0.09in
\end{figure}


\begin{table}[t]
\caption{Comparison on CIFAR-10-LT and CIFAR-100-LT. The accuracy (\%) of Top-1 is reported. The best and second-best results are shown in \underline{\textbf{underlined bold}} and \textbf{bold}, respectively.}
\label{table1}
\vskip -0.07in
\centering  
\begin{small}
\renewcommand\arraystretch{1.05}
\setlength{\tabcolsep}{2.3pt} \begin{tabular}{l|cccc|cccc}
\hline \toprule 
Dataset   &\multicolumn{4}{c|}{CIFAR-10-LT}   &\multicolumn{4}{c}{CIFAR-100-LT}  \\ \hline
Backbone Net  &\multicolumn{8}{c}{ResNet-32} \\ \hline
imbalance factor   &200   &100   &50   &10  &200   &100   &50   &10 \\ \hline
MiSLAS \cite{paper1}  &77.3  &82.1 &\textbf{85.7} &\underline{\textbf{90.0}} &42.3 &47.0 &52.3 & \underline{\textbf{63.2}}    \\ 
LDAM-DRW \cite{paper2}  & \multicolumn{1}{c}{-}  &77.0 &81.0 &88.2 & \multicolumn{1}{c}{-} &42.0 &46.6 & 58.7   \\ \hline

Cross Entropy   & 65.6  &70.3  &74.8  &86.3   &34.8  & 38.2   & 43.8   &55.7   \\ 
\rowcolor{blue!5}+ CR     & 67.9  &72.6  &76.2  &89.5   &36.9  & 40.5   & 45.1   &57.4  \\  \hline

Focal Loss \cite{paper3} & 65.2  &70.3  &76.7  &86.6   &35.6  & 38.4   & 44.3   &55.7   \\ 
\rowcolor{blue!5}+ CR   & 67.3  &71.8  &79.1  &88.4   &37.5  & 40.2   & 45.2   &58.3   \\  \hline

CB Loss \cite{paper4} & 68.8  &74.5  &79.2  &87.4   &36.2  & 39.6   & 45.3   &57.9   \\ 
\rowcolor{blue!5}+ CR     & 70.3  &75.8  &79.8  &89.1   &38.5  & 40.7   & 46.8   &59.2   \\  \hline

BBN \cite{paper5}     & \multicolumn{1}{c}{-}   & 79.8  &82.1   &88.3   & \multicolumn{1}{c}{-}   &42.5  &47.0  &59.1 \\ 
\rowcolor{blue!5}+ CR \cite{paper9}     & \multicolumn{1}{c}{-}   & 81.2  &83.5   &89.4   & \multicolumn{1}{c}{-}   &43.7 &48.1  &60.0 \\  \hline

De-c-TDE \cite{paper6} & \multicolumn{1}{c}{-}  &80.6  &83.6  &88.5   &\multicolumn{1}{c}{-}  & 44.1   & 50.3   &59.6   \\ 
\rowcolor{blue!5}+ CR    &\multicolumn{1}{c}{-}  &81.8  &84.5  &\textbf{89.9}   &\multicolumn{1}{c}{-}  & 45.7   & 51.4   &60.3   \\  \hline

RIDE (4*) \cite{paper7} & \multicolumn{1}{c}{-}  &\multicolumn{1}{c}{-}   &\multicolumn{1}{c}{-}   &\multicolumn{1}{c|}{-}   & \multicolumn{1}{c}{-}   &  48.7  & \textbf{59.0}  & 58.4   \\ 
\rowcolor{blue!5}+ CR & \multicolumn{1}{c}{-}  &\multicolumn{1}{c}{-}   &\multicolumn{1}{c}{-}   &\multicolumn{1}{c|}{-}   & \multicolumn{1}{c}{-}  & 49.8   & \underline{\textbf{59.8}}   &59.5   \\  \hline

RIDE + CMO \cite{paper8}   & \multicolumn{1}{c}{-} &\multicolumn{1}{c}{-} &\multicolumn{1}{c}{-} &\multicolumn{1}{c|}{-} &\multicolumn{1}{c}{-} &\textbf{50.0} &53.0 &60.2   \\  
\rowcolor{blue!5}+ CR & \multicolumn{1}{c}{-} &\multicolumn{1}{c}{-} &\multicolumn{1}{c}{-} &\multicolumn{1}{c|}{-} &\multicolumn{1}{c}{-} &\underline{\textbf{50.7}} &54.3 &\textbf{61.4}  \\ \hline

GCL \cite{paper9}    &\textbf{79.0}  & \textbf{82.7}  &85.5  &\multicolumn{1}{c|}{-}  &\textbf{44.9}  &48.7  &53.6  &\multicolumn{1}{c}{-}     \\
\rowcolor{blue!5}+ CR    &\underline{\textbf{79.9}}  & \underline{\textbf{83.5}}  &\underline{\textbf{86.8}}  &\multicolumn{1}{c|}{-}  &\underline{\textbf{45.6}}  &49.8  &55.1  &\multicolumn{1}{c}{-}  \\

\bottomrule \hline
\end{tabular}
\end{small}
\vskip -0.18in
\end{table}


Table \ref{table1} summarizes the improvements of CR for several state-of-the-art methods on long-tailed CIFAR-10 and CIFAR-100, and we observe that CR significantly improves all methods. For example, in the setting of IF , CR results in performance gains of , , and  for CE, Focal loss \cite{paper3}, and CB loss \cite{paper4}, respectively. When CR is applied to feature training, the performance of BBN \cite{paper5} is improved by more than  on each dataset, which again validates that curvature imbalance negatively affects the learning of classifiers. When CR is applied to several state-of-the-art methods (e.g., RIDE + CMO \cite{paper8} (2022) and GCL \cite{paper9} (2022)), CR achieves higher classification accuracy with all IF settings.

\subsubsection{Evaluation on ImageNet-LT and iNaturalist2018}

\begin{table}[t]
\caption{Top-1 accuracy (\%) of ResNext-50 \cite{paper20} on ImageNet-LT and Top-1 accuracy (\%) of ResNet-50 \cite{paper21} on iNaturalist2018 for classification. The best and the second-best results are shown in \underline{\textbf{underline bold}} and \textbf{bold}, respectively. }
\label{table2}
\vskip -0.08in
\centering  
\begin{small}
\renewcommand\arraystretch{1}
\setlength{\tabcolsep}{1.1pt} \begin{tabular}{l|cccc| cccc}
\hline \toprule
\multirow{3}{*}{Methods}    & \multicolumn{4}{c|}{ImageNet-LT}  & \multicolumn{4}{c}{iNaturalist 2018}  \\ \cline{2-9}
& \multicolumn{4}{c|}{ResNext-50}  & \multicolumn{4}{c}{ResNet-50}  \\ \cline{2-9}
& H   &M  &T   &Overall   &H   &M   &T   &Overall \\ \hline
OFA \cite{paper10}    &47.3 & 31.6 & 14.7 & 35.2 & \multicolumn{1}{c}{-}  & \multicolumn{1}{c}{-} & \multicolumn{1}{c}{-} & 65.9 \\
DisAlign \cite{paper11}  &59.9 &49.9 &31.8 &52.9 &68.0 &71.3 &69.4 &70.2  \\
MiSLAS \cite{paper1}   &65.3 &50.6 & 33.0 & 53.4 &\underline{\textbf{73.2}}  &72.4 & 70.4 & 71.6 \\ 
DiVE \cite{paper12} &64.0 & 50.4 & 31.4 & 53.1 & 70.6  & 70.0 & 67.5 & 69.1 \\  
PaCo \cite{paper13} &63.2 & 51.6 & 39.2 & 54.4 & 69.5  & 72.3 & 73.1 & 72.3 \\ 
GCL \cite{paper9} &\multicolumn{1}{c}{-}  & \multicolumn{1}{c}{-} & \multicolumn{1}{c}{-} & 54.9 &\multicolumn{1}{c}{-}  & \multicolumn{1}{c}{-} & \multicolumn{1}{c}{-} &72.0  \\ \hline

CE &65.9 & 37.5 & 7.70 & 44.4 & 67.2  & 63.0 & 56.2 & 61.7 \\
\rowcolor{blue!5} + CR &65.1 & 40.7 & 19.5 & 47.3 & 67.3  & 62.6 & 61.7 & 63.4 \\ \hline

Focal Loss \cite{paper3} &67.0 & 41.0 & 13.1 & 47.2 & \multicolumn{1}{c}{-}  & \multicolumn{1}{c}{-} & \multicolumn{1}{c}{-} & 61.1 \\
\rowcolor{blue!5} + CR  &67.3 & 43.2 & 22.5 &49.6 &69.4  &61.7 &57.2 &62.3 \\ \hline

BBN \cite{paper5}   &43.3 & 45.9 & \textbf{43.7}  & 44.7 & 49.4  & 70.8 & 65.3 & 66.3 \\  
\rowcolor{blue!5} + CR & 45.2& 46.8 & \underline{\textbf{44.5}} & 46.2 &50.6 & 71.5 &66.8 & 67.6\\  \hline

LDAM \cite{paper2} &60.0 & 49.2 & 31.9 & 51.1 & \multicolumn{1}{c}{-}  & \multicolumn{1}{c}{-} & \multicolumn{1}{c}{-} & 64.6\\
\rowcolor{blue!5} + CR &60.8 & 50.3 &33.6 &52.4 & 69.3  &66.7  &61.9 &65.7 \\ \hline

LADE \cite{paper14} &62.3 & 49.3 & 31.2 & 51.9 & \multicolumn{1}{c}{-}  & \multicolumn{1}{c}{-} & \multicolumn{1}{c}{-} & 69.7\\
\rowcolor{blue!5} + CR &62.5 & 50.1 &33.7 &53.0 &72.5  &70.4  &65.7  &70.6 \\ \hline

MBJ \cite{paper15} &61.6 & 48.4 & 39.0 & 52.1 & \multicolumn{1}{c}{-}  & \multicolumn{1}{c}{-} & \multicolumn{1}{c}{-} & 70.0 \\
\rowcolor{blue!5} + CR &62.8 & 49.2 & 40.4 &53.4 &\textbf{73.1}  &70.3 &66.0 & 70.8 \\ \hline

RIDE (4*) \cite{paper7}  &\underline{\textbf{67.8}} &53.4 &36.2 &56.6 &70.9 &72.4 &73.1 &72.6 \\ 
\rowcolor{blue!5} + CR  &\underline{\textbf{68.5}} &54.2 &38.8 &\underline{\textbf{57.8}} &71.0 & \underline{\textbf{73.8}} &\textbf{74.3} &\textbf{73.5} \\ \hline

RIDE + CMO \cite{paper8}  &66.4 & \underline{\textbf{54.9}} & 35.8 & 56.2 &70.7  & 72.6 &73.4 & 72.8 \\ 
\rowcolor{blue!5} + CR      &67.3 & \textbf{54.6} &38.4 & \textbf{57.4} &71.6  &\textbf{73.7} &\underline{\textbf{74.9}} &\underline{\textbf{73.8}} \\
\bottomrule \hline
 \end{tabular}
 \end{small}
 \vskip -0.2in
 \end{table}


The results on ImageNet-LT and iNaturalist2018 are shown in Table \ref{table2}. We not only report the overall performance of CR, but also additionally add the performance on three subsets of Head (more than 100 images), Middle (20-100 images), and Tail (less than 20 images). From Table \ref{table2}, we observe the following three conclusions: first, CR results in significant overall performance improvements for all methods, including  and  improvements on ImageNet-LT for CE and Focal loss, respectively. Second, when CR is combined with feature training, the overall performance of BBN \cite{paper5} is improved by  and  on the two datasets, respectively, indicating that curvature-balanced feature learning facilitates classifier learning. Third, our approach still boosts model performance when combined with advanced techniques (RIDE \cite{paper7} (2021), RIDE + CMO \cite{paper8} (2022)), suggesting that curvature-balanced feature learning has not yet been considered by other methods.


\subsection{Experiments on Non-Long-Tailed Datasets}
\label{sec6.4}



Curvature imbalance may still exist on sample-balanced datasets, so we evaluate CR on non-long-tailed datasets. Table \ref{table3} summarizes the improvements of CR on CIFAR-100 and ImageNet for various backbone networks, and we observe that CR results in approximately  performance improvement for all backbone networks. In particular, the accuracy of CE + CR exceeds CE by  on CIFAR-100 when using ResNet-18 \cite{paper21} as the backbone network. The experimental results show that our proposed curvature regularization is applicable to non-long-tailed datasets and compatible with existing backbone networks and methods.

\begin{table}[t]
\small
\renewcommand\arraystretch{1.08}
\setlength{\tabcolsep}{2.6pt} \caption{Comparison on ImageNet and CIFAR-100.}
\vskip -0.06in
\label{table3}
\centering  
\begin{small}
\begin{tabular}{l|ccc|ccc}
\hline  \toprule
   & \multicolumn{3}{c|}{ImageNet}  &  \multicolumn{3}{c}{CIFAR-100}  \\ \hline
Methods & CE  & CE + CR &  & CE & CE + CR &  \\ \hline
VGG16 \cite{paper16}&  71.6 & 72.7 & \textcolor[RGB]{0,201,87}{+1.1} & 71.9 & 73.2 & \textcolor[RGB]{0,201,87}{+1.3} \\
BN-Inception \cite{paper17} &  73.5 & 74.3 & \textcolor[RGB]{0,201,87}{+0.8} & 74.1 & 75.0 & \textcolor[RGB]{0,201,87}{+0.9} \\
ResNet-18 \cite{paper21} &  70.1 & 71.3 & \textcolor[RGB]{0,201,87}{+1.2}  &75.6   & 77.1 & \textcolor[RGB]{0,201,87}{+1.5}  \\
ResNet-34 \cite{paper21} &  73.5 & 74.6 & \textcolor[RGB]{0,201,87}{+1.1}  & 76.8 & 78.0 & \textcolor[RGB]{0,201,87}{+1.2}  \\
ResNet-50 \cite{paper21} &  76.0 & 76.8 & \textcolor[RGB]{0,201,87}{+0.8} & 77.4 & 78.3 & \textcolor[RGB]{0,201,87}{+0.9}  \\
DenseNet-201 \cite{paper18} &  77.2 & 78.0 & \textcolor[RGB]{0,201,87}{+0.8}  & 78.5 & 79.7 & \textcolor[RGB]{0,201,87}{+1.2}  \\
SE-ResNet-50 \cite{paper19} &  77.6 & 78.3 & \textcolor[RGB]{0,201,87}{+0.7}  & 78.6 & 79.5 & \textcolor[RGB]{0,201,87}{+0.9}  \\
ResNeXt-101 \cite{paper20} &  78.8 & 79.7 & \textcolor[RGB]{0,201,87}{+0.9}  & 77.8  & 78.9 & \textcolor[RGB]{0,201,87}{+1.1}  \\
 \bottomrule \hline
 \end{tabular}
\end{small}
\vskip -0.14in
\end{table}


\subsection{Curvature Regularization Reduces Model Bias}

Here we explore how curvature regularization improves the model performance. Measuring the model bias with the variance of the accuracy of all classes \cite{paper27}, Fig \ref{fig1} and Fig \ref{fig8} show that curvature regularization reduces the bias of the models trained on CIFAR-100-LT, Image-Net-LT, CIFAR-100, and ImageNet. By combining Tables \ref{table1} and \ref{table2}, it can be found that curvature regularization reduces the model bias mainly by improving the performance of the tail class and does not compromise the performance of the head class, thus improving the overall performance. In addition, In Appendix \textcolor{red}{H} we answer the following two questions: (1) Is the curvature more balanced after training with CR? (2) Did the correlation between curvature imbalance and class accuracy decrease after training with CR?

\begin{figure}[h]
\vskip -0.1in
\centering
\centerline{\includegraphics[width=1\columnwidth]{8}}
\vskip -0.05in
\caption{Curvature regularization reduces the bias of multiple backbone networks trained on ImageNet and CIFAR-100.}
\label{fig8}
\vskip -0.2in
\end{figure}

\section{Conclusion}
This work mines and explains the impact of data on the model bias from a geometric perspective, introducing the imbalance problem to non-long-tailed data and providing a geometric analysis perspective to drive toward fairer AI.


\bibliographystyle{ieee_fullname}
\bibliography{CVPR2023}




\clearpage

\section*{Appendix A: Related Work}
\label{secA}

In practice, the dataset usually tends to follow a long-tailed distribution, which leads to models with very large variances in performance on each class. It should be noted that most researchers default to the main motivation for long-tail visual recognition is that classes with few samples are always weak classes. Therefore, numerous methods have been proposed to improve the performance of the model on tail classes. \cite{paper58} divides these methods into three fields, namely class rebalancing, information augmentation, and module improvement. Unlike the above, \cite{paper27} and \cite{paper28} observe that the number of samples in the class does not exactly show a positive correlation with the accuracy, and the accuracy of some tail classes is even higher than the accuracy of the head class. Therefore, they propose to use other measures to gauge the learning difficulty of the classes rather than relying on the sample number alone. In the following, we first present past research up to \cite{paper27}\cite{paper28} and lead to our work.


\subsection*{Class Rebalancing}
\label{secA.1}

The motivation for class rebalancing is intuitive; researchers have argued that tail classes with fewer samples lead to an imbalance in class-level loss and thus an inconsistent degree of learning for each class. Therefore cost-sensitive learning \cite{paper59,paper60,paper61,paper62} and resampling \cite{paper63, paper31,paper64,paper65} are proposed to rebalance the losses.

Cost-sensitive learning is proposed to balance the losses incurred by all classes, usually by applying a larger penalty to the tail classes on the objective function (or loss function) \cite{paper37,paper45,paper36,paper27,paper4,paper3}. \cite{paper36} proposes to adjust the loss with the label frequencies to alleviate class bias. \cite{paper3} not only assigns weights to the loss of each class, but also assigns higher weights to hard samples. Recent studies have shown that the effect of reweighting losses by the inverse of the number of samples is modest \cite{paper66,paper67}. Some methods that produce more ``smooth'' weights for reweighting perform better, such as taking the square root of the number of samples as the weight \cite{paper66}. \cite{paper4} attributes the better performance of this smoother method to the existence of marginal effects. In addition, \cite{paper68}proposes to learn the classifier with class-balanced loss by adjusting the weight decay and MaxNorm in the second stage.

Resampling methods are divided into oversampling and undersampling \cite{paper69,paper29,paper64}. The idea of oversampling is to randomly sample the tail classes to equalize the number of samples and thus optimize the classification boundaries. The undersampling methods balance the number of samples by randomly removing samples from the head classes. For example, \cite{paper7} finds that training with a balanced subset of a long-tailed dataset is instead better than using the full dataset. In addition, \cite{paper29,paper5} fine-tune the classifier via a resampling strategy in the second phase of decoupled training. \cite{paper70} continuously adjusts the distribution of resampled samples and the weights of the two-loss terms during training to make the model perform better. \cite{paper71} employs the model classification loss from an additional balanced validation set to adjust the sampling rate of different classes.


\subsection*{Information Augmentation}
\label{secA.2}

Class rebalancing is inherently unable to handle missing information because no additional information is introduced. Information augmentation aims to improve the performance on tail classes by introducing additional information into the model training. This method is classified into two types: knowledge transfer and data augmentation.

There are four main schemes of knowledge transfer, which are head-to-tail knowledge transfer, model pre-training, knowledge distillation, and self-training. Head-to-tail knowledge transfer aims to transfer knowledge from the head classes to the tail classes to improve the performance of the tail classes. FTL \cite{paper38} assumes that the feature distributions of the common and UR classes (i.e., rare classes) have the same variance, so the variance from the head classes is used to guide the feature enhancement of the tail classes. LEAP \cite{paper39} transfers the intra-class angle distribution of features to the tail classes and constructs a ``feature cloud'' centered on each feature to expand the distribution of the tail classes. Similar to the adversarial attack, M2m \cite{paper42} proposes to transform some samples from the head class into the tail samples by perturbation-based optimization to achieve tail augmentation. OFA \cite{paper10} decomposes the features of each class into class-generic features and class-specific features. During training, the tail class-specific features are fused with the head class-generic features to generate new features to augment the tail classes. GIST \cite{paper41} proposes to transfer the geometric information of the feature distribution boundaries of the head classes to the tail classes by increasing the classifier weights of the tail classes. The motivation of the recently proposed CMO \cite{paper8} is very intuitive, it argues that the images from the head classes have rich backgrounds, so the images from the tail classes can be pasted directly onto the rich background images of the head classes to increase the richness of the tail images. The remaining three types of schemes are relatively few. \cite{paper72} first pre-trains the model with all the long-tailed samples, and then fine-tunes the model on a balanced training subset. \cite{paper73} proposes to pre-train the model with self-supervised learning and perform standard training on the long-tailed data. LST \cite{paper74} utilizes knowledge distillation to overcome catastrophic forgetting in incremental learning.

Data augmentation in long-tailed recognition improves the performance of tail classes by improving conventional data augmentation methods. MiSLAS \cite{paper1} suggests adopting mixup to augment feature learning, while not using mixup in classifier learning. FASA \cite{paper71} proposes to generate features based on Gaussian prior and evaluate weak classes on a balanced dataset to adjust the sampling rate. MetaSAug \cite{paper43} generates augmented features for tail classes with ISDA.


\subsection*{Module Improvement}
\label{secA.3}

In addition to information enhancement to improve performance from a data perspective, researchers have designed numerous network modules for long-tailed recognition. The methods in this section can be divided into representation learning, classifier design, decoupled training, and ensemble learning. Decoupled training divides the training process into representation learning and classifier learning. LMLE \cite{paper75}, CRL \cite{paper76}, KCL \cite{paper46} and PaCo \cite{paper13} introduce metric learning methods to increase the differentiation of the representation and make the model more robust to data distribution shifts. HFL \cite{paper78} proposes to hierarchically cluster all classes into leaves of a tree and then improve the generalization performance of the tail classes by sharing the parameters of the parent nodes or similar leaves.

Ensemble learning has shown great potential in long-tailed recognition. BBN \cite{paper5} designed a two-branch network to rebalance the classifier, which is consistent with the idea of decoupled training. To avoid decoupled training damaging the performance of the head class, SimCal \cite{paper31} trained networks with dual branches, one for rebalancing the classifier and the other for maintaining the performance of the head class. ACE \cite{paper77}, RIDE \cite{paper7}, and TADE \cite{paper34} introduced multiple experts with specific complementary capabilities, which led to a significant improvement in the overall performance of the model.

\subsection*{Class-Difficulty Based Methods}
\label{secA.4}

\textbf{The study of class difficulty is most relevant to our work}. The methods in the three domains presented above almost all assume that classes with few samples are the most difficult classes to be learned, and therefore more attention is given to these classes. However, recent studies \cite{paper27,paper28} have observed that the performance of some tail classes is even higher than that of the head classes, and that the performance of different classes varies on datasets with perfectly balanced samples. These phenomena suggest that the sample number is not the only factor that affects the performance of classes. The imbalance in class performance is referred to as the ``bias'' of the model, and \cite{paper27} defines the model bias as  where  denotes the accuracy of the -th class. When the accuracy of each class is identical, bias = 0. \cite{paper27} computes the difficulty of class c using  and calculates the weights of the loss function using a nonlinear function of class difficulty. Unlike \cite{paper27}, \cite{paper28} proposes a model-independent measure of classification difficulty, which directly utilizes the data matrix to calculate the semantic scale of each class to represent the classification difficulty. As with the sample number, model-independent measures can help us understand how deep neural networks learn from data. When we get data from any domain, if we can measure the difficulty of each class directly from the data, we can guide the researchers to collect the difficult classes in a targeted manner instead of blindly, greatly facilitating the efficiency of applying AI in practice. 

In this work, we propose to consider the classification task as the classification of perceptual manifolds. The influence of the geometric characteristics of the perceptual manifold on the classification difficulty is further analyzed, and feature learning with curvature balanced is proposed. 


\section*{Appendix B: The Proof and Derivation of Section \ref{sec3.3}}
\label{secB}

First, recall the definition of the degree of separation of the perceptual manifold as follows.

\begin{definition}
(The Separation Degree of Perceptual Manifold). Suppose there are  perceptual manifolds , which consist of point sets . Let , , we define the degree of separation between the perceptual manifold  and the rest of the perceptual manifolds as 
\end{definition}

The following analysis is performed for the case when  and . According to our motivation, the measure of the degree of separation between perceptual manifolds should satisfy . 

If  holds, then we can get 
\begin{small}

\end{small}
We prove that  holds when , and the details are as follows. 

\begin{proof}
Since the function  is strictly concave, the real symmetric positive definite matrices  and  satisfy \cite{paper57}
\begin{small}

\end{small}
Also because

and

We can get 

i.e.,  holds.
\end{proof}

The above analysis shows that the proposed measure meets our requirements and motivation. The formula for calculating the degree of separation between perceptual manifolds can be further reduced to 




\section*{Appendix C: Pseudocode for Measure The Geometry Properties of Perceptual Manifold}
\label{secC}

In Section \ref{sec3} we propose measures for the perceptual manifold's volume, separation, and curvature. We provide the pseudo-code below to show how to apply these methods in practice. Our approach can be applied not only to calculate the geometric properties of feature manifolds but also to the image space. In addition to image data, other types of data also obey the manifold distribution law, so our method can be employed to evaluate them as well.


\begin{algorithm*}[t]
\caption{Pseudocode for The Volume of Perceptual Manifold}
\label{alg2}
\textbf{Input:} Training set  with the total number  of classes. A CNN , where  and  denote the feature sub-network and classifier, respectively. \\
\textbf{Output:} The volume of all perceptual manifolds.
\begin{algorithmic}[1] \FOR{ to }
   \STATE Select the sample set  for class  from ,  is the number of samples for class .
   \STATE Calculate the feature embedding  of , .
   \STATE .
   \STATE Calculate the covariance matrix .
   \STATE Calculate the volume  of the perceptual manifold corresponding to class .
   \ENDFOR
\end{algorithmic}
\end{algorithm*}


\begin{algorithm*}[t]
\caption{Pseudocode for The Volume of Data Manifold}
\label{alg3}
\textbf{Input:} Training set  with the total number  of classes. A CNN , where  and  denote the feature sub-network and classifier, respectively. \\
\textbf{Output:} The volume of all data manifolds.
\begin{algorithmic}[1] \FOR{ to }
   \STATE Select the sample set  for class  from ,  is the number of samples for class . 
   \STATE Resize the image to (, , 3). 
   \STATE Flatten the image into a vector of length  and store it in . 
   \STATE .  
   \STATE Calculate the covariance matrix .  
   \STATE Calculate the sample volume  for class .   
   \ENDFOR
\end{algorithmic}
\end{algorithm*}

\subsection*{Pseudocode for The Volume of Perceptual Manifold}
We give the calculation procedure of perceptual manifold volume in Algorithm \ref{alg2}. In addition, the volume of the data manifold can also be calculated directly in image space (Algorithm \ref{alg3}). Unlike the method for calculating the volume of the perceptual manifold, it is necessary to shrink and flatten the image into vectors. The reason for this is that the dimensionality of the image space is often very high, so we alleviate the dimensionality catastrophe by simply downsampling the dimensions.

\begin{algorithm*}[t]
\caption{Pseudocode for The Separation Degree of Perceptual Manifold}
\label{alg4}
\textbf{Input:} Training set  with the total number  of classes. A CNN , where  and  denote the feature sub-network and classifier, respectively. \\
\textbf{Output:} The volume of all data manifolds. 
\begin{algorithmic}[1] \FOR{ to }
\STATE Select the sample set  for class  from ,  is the number of samples for class .
\STATE Calculate the feature embedding  of , .
\ENDFOR
 \STATE There exist  perceptual manifolds , which consist of point sets . Let . \\
\FOR{ to }
   \STATE Let .
   \STATE Calculate the degree of separation  for perceptual manifold .
   \ENDFOR
\end{algorithmic}
\end{algorithm*}


\begin{algorithm*}[t]
\caption{Pseudocode for the Mean Gaussian Curvature of The Perceptual Manifold}
\label{alg5}
\textbf{Input:} Given a point cloud perceptual manifold , which consists of a -dimensional point set . Denote by  the -th neighbor point of  and  the normal vector at . \\
\textbf{Output:} The mean Gaussian curvature of the perceptual manifold . 
\begin{algorithmic}[1] \FOR{ to }
\STATE Select  neighbor points  of  and let .
\STATE .
\STATE Calculate the local covariance matrix .
\STATE Diagonalize  as  with .
\STATE Let .
\STATE The  neighbors of  are projected into the affine space  and denoted as .
\STATE Denote by  the -th component  of . We use  and  neighbor points to fit a quadratic hypersurface  with parameter . The hypersurface equation is denoted as .
\STATE Expand the parameter  of the hypersurface into the column vector .
\STATE Organize the  neighbor points  of  according to the following form:
Organize the  neighbor points  of  according to the following form:

\STATE The target value is .
\STATE Solve for  to get .
\STATE The Gauss curvature of the perceptual manifold  at  can be calculated as .
\ENDFOR
\STATE The average Gaussian curvature  of the perceptual manifold  is the average of the Gauss curvatures at all points on .
\end{algorithmic}
\end{algorithm*}



\subsection*{Pseudocode for The Separation Degree of Perceptual Manifold}
The distributions of different classes are far from each other to give the model higher discriminative power. Euclidean distance or cosine distance between class centers is often used as the measure of distance between classes, and these two distances are also commonly used as loss functions when constructing sample pairs. However, maximizing the distance between proxy points or samples does not keep one class away from all the remaining classes at the same time, and the distance between class centers does not reflect the degree of overlap of distributions.
\begin{figure}[h]
\centering
\centerline{\includegraphics[width=1\columnwidth]{12}}
\vskip -0.08in
\caption{The curve of the degree of separation of two spherical point cloud that varies with the distance between spherical centers.}
\label{fig9}
\end{figure}
\textbf{Therefore, we define the degree of separation of the perceptual manifold based on the volume of the perceptual manifold}, which is applicable to the case of multiple perceptual manifolds and is an asymmetric measure. Algorithm \ref{alg4} shows in detail how to calculate the degree of separation of the perceptual manifold in practice. In addition, we add more results to Fig \ref{fig2} in Fig \ref{fig9}, where it can be clearly observed that as the difference in volume between the two spherical point cloud manifolds becomes larger, the difference in the degree of separation between the two increases, a result that is fully consistent with our motivation.




\subsection*{Pseudocode for the Mean Gaussian Curvature of The Perceptual Manifold}
The complexity of the perceptual manifold reflects the extraction ability of the deep neural network for the input image \cite{paper51}. \cite{paper49} proposed to decompose the manifold into multiple pieces, each of which is homogeneously mapped to a linear space, and the lower limit of the number of pieces in all decomposition methods defines the complexity of the manifold. However, there is no way to know the quantitative expression of the point cloud perceptual manifold, and it is difficult to find its homogeneous mapping. 

We give the analytical solution for estimating the curvature of the perceptual manifold in Section \ref{sec3.4}, but the whole derivation process is complicated. Therefore, we clearly list the steps for calculating the curvature of the perceptual manifold in Algorithm \ref{alg5}, so that it can be easily understood and used by other researchers.

\section*{Appendix D: More Experimental Results and Analysis for Section \ref{sec4.1}}
\label{secD}

\begin{figure}[t]
\centering
\centerline{\includegraphics[width=1\columnwidth]{D.1}}
\vskip -0.1in
\caption{Curves of the separation degree of perceptual manifolds with training epoch on CIFAR-10.}
\label{fig10}
\vskip -0.2in
\end{figure}

\begin{figure}[t]
\centering
\centerline{\includegraphics[width=1\columnwidth]{D.2}}
\vskip -0.1in
\caption{The degree of separation and corresponding class accuracy of all perceptual manifolds on CIFAR-10.}
\label{fig11}
\vskip -0.1in
\end{figure}

We observed on Fashion-MNIST and CIFAR-10 that learning led to a progressive increase in the separation degree of the perceptual manifolds, and more results are added in Fig \ref{fig10}. It can be seen that the separation degree of all perceptual manifolds in CIFAR-10 increases with the training epoch. Section \ref{sec4.3} presents the Pearson correlation coefficient between the separation degree of the perceptual manifold and the class accuracy over  in the early stages of training, which we further validate. ResNet-18 was trained on CIFAR-10, and when the epoch reached , features of samples from all classes were extracted with ResNet-18, and the accuracy of each class was tested. The separation degree of each perceptual manifold is calculated utilizing the features, and then the separation degree of all perceptual manifolds and the corresponding class accuracy are plotted in Fig \ref{fig11}. We found that the two were indeed highly correlated, and additional experimental results provide a more detailed analysis for the discovery shown in Fig \ref{fig6}.


\section*{Appendix E: More Experimental Results and Analysis for Section \ref{sec4.2}}
\label{secE}

\begin{figure}[t]
\centering
\centerline{\includegraphics[width=1\columnwidth]{E.1}}
\vskip -0.1in
\caption{Curves of the complexity of perceptual manifolds with training epochs on CIFAR-10.}
\label{fig12}
\vskip -0.1in
\end{figure}

We add more results in Fig \ref{fig12}. The experiments amply show that learning makes each perceptual manifold flatter, which confirms our speculation that the flatter the perceptual manifold is, the easier it is to decode. It is important to note that the curvature of the different perceptual manifolds shows differences as the training epoch increases. The correlation between curvature of different magnitudes and class accuracy increases with increasing training epochs. We train ResNet-18 on CIFAR-10 and use ResNet-18 to extract features from all samples when the training epoch is . The inverse of the curvature of each perceptual manifold is calculated, while the accuracy of each class is tested, and both are plotted in Fig \ref{fig13}. It can be seen that the inverse of the curvature of perceptual manifold does have a high correlation with the corresponding class accuracy in the late training phase. 

\begin{figure}[t]
\centering
\centerline{\includegraphics[width=1\columnwidth]{E.2}}
\vskip -0.1in
\caption{The inverse of the mean Gaussian curvature of all perceptual manifolds and the accuracy of all classes on CIFAR-10.}
\label{fig13}
\vskip -0.15in
\end{figure}

\section*{Appendix F: The Derivation of Curvature Regularization (Section \ref{sec5.2})}
\label{secF}

Here, we will derive the final result step by step according to three design principles of curvature regularization. First recall the three principles.
\begin{itemize}
    \item[(1)] The greater the curvature of a perceptual manifold, the stronger the penalty for it.
    \item[(2)] When the curvature is balanced, the penalty strength is the same for each perceptual manifold.
    \item[(3)] The sum of the curvatures of all perceptual manifolds tends to decrease.
\end{itemize}

In order to propose curvature regularization in a reasonable way, we start from softmax cross-entropy loss to inspire our method. Given a  classification task, suppose a sample  is labeled as  and it is predicted as each class with probabilities , respectively. The cross-entropy loss generated by sample  is calculated as , where . The goal of  is to make  converge to , i.e.,  converges to , at which point  converges to . Unlike cross-entropy loss, which can pull apart the difference between  and other probabilities, we expect the mean Gaussian curvature of the  perceptual manifolds to converge to equilibrium.

\begin{figure}[h]
\centering
\centerline{\includegraphics[width=1\columnwidth]{14}}
\caption{All curvatures smaller than  gradually increase driven by the loss function, and the smaller the curvature, the greater the resulting loss.}
\label{fig14}
\vskip -0.12in
\end{figure}

Assume that the mean Gaussian curvatures of the  perceptual manifolds are , and perform the maximum normalization on them. The  loss can make  converge to . Therefore, perform a negative logarithmic transformation on the curvature of all perceived manifolds and use it as loss, which can make each curvature converge to  and thus achieve curvature balance. However, the above operation violates the third design principle of curvature regularization, which is that the sum of curvatures of all perceptual manifolds tends to decrease. As shown in Fig \ref{fig14}, all curvatures smaller than  gradually increase driven by the loss function, and the smaller the curvature, the greater the resulting loss. To solve this problem, we update each curvature to the inverse of itself before performing the maximum normalization of the curvature. Eventually, the curvature penalty term of the perceptual manifold  is denoted as . Further, the overall curvature regularization term is denoted as  As shown in Fig \ref{fig15}, the perceptual manifold with the smallest curvature produces no loss, and the larger the curvature, the larger the loss.  causes the curvature of all the perceptual manifolds to converge to the value with the smallest curvature while achieving equilibrium.

\begin{figure}[h]
\centering
\centerline{\includegraphics[width=1\columnwidth]{15}}
\caption{The perceptual manifold with the smallest curvature produces no loss, and the larger the curvature, the larger the loss.}
\label{fig15}
\vskip -0.1in
\end{figure}


\section*{Appendix G: Datasets and Implementation Details (Section \ref{sec6})}
\label{secG}

\subsection*{Datasets and Evaluation Metrics}
\label{secG.1}

We conducted experiments on artificially created CIFAR-10-LT, CIFAR-100-LT \cite{paper4}, ImageNet-LT \cite{paper4,paper26}, and real-world long-tailed iNaturalist2018 \cite{paper24} to validate the effectiveness and generalizability of our method. For a fair comparison, the training and test images of all datasets are officially split, and the Top-1 accuracy on the test set is utilized as a performance metric.

\begin{itemize}
  \item \textbf{CIFAR-10-LT} and \textbf{CIFAR-100-LT} are long-tailed datasets including five imbalance factors (IF = ) generated based on CIFAR-10 and CIFAR-100, respectively. The imbalance factor (IF) is defined as the value of the number of the most frequent class training samples divided by the number of the least frequent class training samples.

  \item \textbf{ImageNet-LT} is a long-tailed subset of ILSVRC 2012 with an imbalance factor of , which contains  classes totaling  images, with a maximum of  images and a minimum of  images per class. The balanced k images were used for testing.

  \item The \textbf{iNaturalist} species classification dataset is a large-scale real-world dataset that suffers from an extremely unbalanced label distribution. The  version we selected consists of  images from  classes. The maximum class is  images and the minimum class is  images (IF = ).
  \item We use the \textbf{ILSVRC2012} split contains  training and  validation images. Each class of \textbf{CIFAR-100} contains  images for training and  images for testing.
\end{itemize}

\subsection*{Implementation Details}
\label{secG.2}

\textbf{CIFAR-10/100-LT.} To set up a fair comparison, we used the same random seed to make CIFAR-10/100-LT, and followed the implementation of \cite{paper2}. We trained ResNet-32 by SGD optimizer with a momentum of , and a weight decay of .

\textbf{ImageNet-LT and iNaturalist2018.} We use ResNext-50 \cite{paper20} on ImageNet-LT and ResNet-50 \cite{paper21} on iNaturalist2018 as the network backbone for all methods. And we conduct model training with the SGD optimizer based on batch size  (for ImageNet-LT) /  (for iNaturalist), momentum , weight decay factor , and learning rate  (linear LR decay).

\textbf{ImageNet and CIFAR-100.} On ImageNet, we use random clipping, mixup \cite{paper22}, and cutmix \cite{paper23} to augment the training data, and all models are optimized by Adam with batch size of , learning rate of , momentum of , and weight decay factor of . On CIFAR-100, we set the batch size to  and augment the training data using random clipping, mixup, and cutmix. An Adam optimizer with learning rate of  (linear decay), momentum of , and weight decay factor of  is used to train all networks.


\section*{Appendix H: More Analysis of Dynamic Curvature Regularization}
\label{secH}

Here, we explored the following two questions:
\begin{itemize}
\item[(1)] Is the curvature more balanced after training with CR? 
\item[(2)] Did the correlation between curvature imbalance and class accuracy decrease after training with CR?
\end{itemize}

Recall that in Section \ref{sec6.4}, we trained multiple backbone networks on ImageNet and CIFAR-100. The features of all samples were extracted using ResNet-18 that was trained on ImageNet and CIFAR-100 with CE and with CE + CR, respectively, and the curvature of each perceptual manifold was calculated. The degree of imbalance is measured by the variance of the curvature of all perceived manifolds; the larger the variance, the more imbalanced the curvature. The experimental results are shown in Table \ref{table4}, where the curvature of the perceptual manifolds represented by the ResNet-18 trained with curvature regularization is more balanced.

\begin{table}[h]
\centering 
\renewcommand\arraystretch{1.0}
\vskip -0.05in
\setlength{\tabcolsep}{17pt} \caption{The variance of the curvature of all perceptual manifolds.}
\vskip -0.07in
\label{table4}
\begin{tabular}{l|cc}
\hline  \toprule
                              & \multicolumn{1}{c|}{ImageNet} & CIFAR-100 \\ \hline
                              & \multicolumn{2}{c}{ResNet-18}            \\ \hline
\multicolumn{1}{c|}{CE}      & \multicolumn{1}{c|}{25.7}     & 20.4      \\ \hline
\multicolumn{1}{c|}{CE + CR} & \multicolumn{1}{c|}{14.2 \textcolor[RGB]{255,0,0}{\textbf{(-11.5)}}}     & 11.8 \textcolor[RGB]{255,0,0}{\textbf{(-8.6)}}      \\  \hline

                              & \multicolumn{2}{c}{VGG-16}            \\ \hline
\multicolumn{1}{c|}{CE}      & \multicolumn{1}{c|}{27.4}     & 23.5      \\ \hline
\multicolumn{1}{c|}{CE + CR} & \multicolumn{1}{c|}{13.8 \textcolor[RGB]{255,0,0}{\textbf{(-13.6)}}}     & 13.3 \textcolor[RGB]{255,0,0}{\textbf{(-10.2)}}      \\ 
\bottomrule \hline
\end{tabular}
\vskip -0.2in
\end{table}



\begin{table}[h]
\centering 
\renewcommand\arraystretch{1.0}
\setlength{\tabcolsep}{11.7pt} \caption{The Pearson correlation coefficient between the curvature of the perceptual manifold and the corresponding class accuracy.}
\vskip -0.07in
\label{table5}
\begin{tabular}{l|cc}
\hline  \toprule
                              & \multicolumn{1}{c|}{ImageNet} & CIFAR-100 \\ \hline
                              & \multicolumn{2}{c}{ResNet-18}            \\ \hline
\multicolumn{1}{c|}{CE}      & \multicolumn{1}{c|}{-0.583}     & -0.648      \\ \hline
\multicolumn{1}{c|}{CE + CR} & \multicolumn{1}{c|}{-0.257 \textcolor[RGB]{0,201,87}{\textbf{(+0.326)}}}    & -0.285 \textcolor[RGB]{0,201,87}{\textbf{(+0.363)}}     \\  \hline

                              & \multicolumn{2}{c}{VGG-16}            \\ \hline
\multicolumn{1}{c|}{CE}      & \multicolumn{1}{c|}{-0.569}     & -0.635      \\ \hline
\multicolumn{1}{c|}{CE + CR} & \multicolumn{1}{c|}{-0.226 \textcolor[RGB]{0,201,87}{\textbf{(+0.343)}} }    & -0.251 \textcolor[RGB]{0,201,87}{\textbf{(+0.384)}}     \\ 
\bottomrule \hline
\end{tabular}
\vskip -0.05in
\end{table}

We still use CE and CE + CR to train ResNet-18 on ImageNet and CIFAR-100, respectively, and then test the accuracy of two ResNet-18 on each class. The features of all samples were extracted using two ResNet-18 and the mean Gaussian curvature of each perceptual manifold was calculated. We calculated the Pearson correlation coefficients between the class accuracy and the curvature of the corresponding perceptual manifold for ResNet-18 trained with CE and with CE + CR, respectively. The experimental results are presented in Table \ref{table5}, where it can be seen that the negative correlation between the mean Gaussian curvature of the perceptual manifold and the class accuracy decreases significantly after using curvature regularization. The same experiments are performed for VGG-16 and ResNet-18 in Tables \ref{table4} and \ref{table5}.


\section*{Appendix I: Future Work}
\label{secI}

\subsection*{The model-independent measure of data difficulty}

The performance of the model on different classes will vary. The bias is not introduced by the model structure, but by the characteristics of the data itself which affect the model's performance. Therefore, it is very important to propose model-independent measurements to characterize the data itself, and this work will greatly contribute to our understanding of deep neural networks. In this paper, the effect of volume, separation and curvature of data manifolds on the model bias is explored from a geometric perspective. It provides a new direction for future work, namely the geometric analysis of deep neural networks.

\subsection*{The geometric perspective of data classification}

Natural datasets have intrinsic patterns that can be generalized to the manifold distribution principle: the distribution of a class of data is close to a low-dimensional manifold. Data classification can be regarded as the unwinding and separation of manifolds. When a data manifold is entangled with other perceptual manifolds, the difficulty of classifying that manifold increases. Typically, a deep neural network consists of a feature extractor and a classifier. Feature learning can be considered as manifold unwinding, and a well-learned feature extractor is often able to unwind multiple manifolds for the classifier to decode. In this view, all factors about the manifold complexity may affect the model's classification performance. Therefore, we suggest that future work can explore the inter-class long-tailed problem from a geometric perspective.

\subsection*{The geometric perspective of object detection}

In the field of object detection, it is often encountered that although a class does not appear frequently, the model can always detect such instances efficiently. It is easy to observe that classes with simple patterns are usually easier to learn, even if the frequency of such classes is low. Therefore, classes with low frequency in object detection are not necessarily always harder to learn. We believe that it is a valuable research direction to analyze the richness of the instances contained in each class, and then pay more attention to the hard classes. The dimensionality of all images or feature embeddings in the image classification task is the same, which facilitates the application of the semantic scale proposed in this paper. However, the non-fixed dimensionality of each instance in the field of object detection brings new challenges, so we have to consider the effect of dimensionality on the semantic scale, which is a direction worthy of further study.





\end{document}
