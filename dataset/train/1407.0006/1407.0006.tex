

\begin{comment}
A Sprinklers switch adopts the same 3-stage architecture (shown in Fig.~\ref{fig:load balance}) and 
executes the same periodic sequences of connections in the two switching fabrics,
as a baseline load-balanced switch.   It is different from a baseline load-balanced switch only in the way it routes
and schedules packets for service
at the input and the intermediate ports.  
\end{comment}

\begin{comment}
A Sprinklers switch adopts the same baseline load-balanced switch architecture
(as shown in Fig.~\ref{fig:load balance}) with two fixed switching stages, but
differs in the way that it routes and schedules packets for service at the input
and intermediate ports.
In this section, we first provide some intuition behind the Sprinklers approach.
We then describe how the Sprinklers switch operates,
including the striping mechanism for routing packets through the switch
and the companion stripe scheduling policy.
Then we explain how they enable a Sprinklers switch to eliminate
the packet reordering
problem without paying a hefty price in performance or 
implementation cost.  
\end{comment}

Sprinklers has the same architecture as the baseline load-balanced switch
(see Fig.~\ref{fig:load balance}), but it differs in the way that
it routes and schedules packets for service at the input
and intermediate ports. Also, Sprinklers have $N$ VOQs at each input port.
In this section, we first provide some intuition behind the Sprinklers approach,
followed by how the Sprinklers switch operates,
including the striping mechanism for routing packets through the switch
and the companion stripe scheduling policy.


\subsection{Intuition Behind the Sprinklers Approach}

The Sprinklers approach is based on three techniques for balancing traffic evenly across all $N$ intermediate ports:
permutation, randomization, and variable-size striping.
To provide some intuition as to why all three techniques are necessary, we use
an analogy from which the name Sprinklers is derived.
Consider the task of watering a lawn consisting of $N$ identically sized areas using $N$ sprinklers with different pressure.
The objective is to distribute an (ideally) identical amount of water to each area.  This
corresponds to evenly distributing traffic inside the $N$ VOQs (sprinklers) entering a certain input port to the $N$ intermediate
ports (lawn areas)  
under the above-mentioned constraint that all traffic inside a VOQ must go through the same 
set of intermediate ports (i.e., the stripe interval) to which the VOQ is mapped.



An intuitive and sensible first step is to aim exactly one sprinkler at each lawn area,
since aiming more than one sprinklers at one lawn area
clearly could lead to it being flooded.
In other words, the ``aiming function,'' or ``which sprinkler is aimed at which lawn area,'' 
is essentially a permutation over the set $\{1, 2, \cdots, N\}$.
This permutation alone however cannot do the trick, because the water pressure (traffic rate) is 
different from one sprinkler to another, and the lawn area aimed at by a sprinkler with high water 
pressure will surely be flooded.
To deal with such disparity in water pressures, we 
set the ``spray angle range'' of a sprinkler, which corresponds to the size (say $L$) of the stripe interval for the
corresponding VOQ, proportional to its water pressure, and evenly distribute this water pressure 
across the 
$L$ ``streams'' of water that go to the target lawn area and $L-1$ ``neighboring'' lawn areas.


However, such water pressure equalization (i.e., variable stripe sizing) alone does not prevent all scenarios of load-imbalance 
because it shuffles water around only ``locally."
For example, if a larger than average 
number of high pressure sprinklers are aimed at a cluster of lawn areas close to one another, some area within 
this cluster will be flooded.   Hence, 
a simple yet powerful randomized algorithm is brought in 
to shuffle water around globally: we simply sample this permutation 
at uniform random
from the set of all $N!$ permutations.





Besides load-balancing, there is another important reason for the size of a stripe interval to be set roughly 
proportional to the traffic rate of the corresponding VOQ.  In 
some existing solutions to the packet reordering
problem with load-balanced switches, each VOQ has to accumulate a full frame of $N$ packets before the frame can depart from the 
input port.  For a VOQ with low traffic rate, this buffering delay could be painfully long.  By adopting
rate-proportional
stripe sizing, a Sprinklers switch significantly reduces the buffering delays experienced by the low-rate VOQs.

As far as the Sprinklers analogy goes, the combination of randomized permutation and water pressure equalization,
with proper ``manifoldization'' (i.e., considering $N + 1$ as $1$),
will provably ensure that the amount of water going to each lawn area is very even with high 
probability.   However, because the servicing of any two stripes cannot interleave in a Sprinklers switch (to ensure correct
packet order), two stripes have to be serviced in two different frames ($N$ time slots),
even if their stripe intervals overlap only slightly.  
A rampant occurrence of such slight overlaps, which can happen if the stripe interval size of a VOQ is set strictly proportional
to the rate of the VOQ (rounded to an integer), 
will result in gross waste of service capacity, and significantly reduce the maximum achievable throughput.


Therefore, we would like any two stripe intervals to either ``bear hug"
(i.e., one contained entirely in the other) or does not touch (no overlap between the intervals) 
each other.  Our solution is a classical ``computer science'' one: making $N$ a power of 2 (very reasonable 
in the modern switching literature) and every stripe interval a dyadic one (resulting from dividing the 
whole interval (0, N] into $2^k$ equal-sized subintervals for an integer $k \le \log_2 N$).  
Now that the spray angle range of a sprinkler has 
to be a power of 2, the water pressure per stream could vary from one sprinkler to another by a maximum factor of 2.  
However, as shown later in Sec.~\ref{sec:stability},
strong statistical load-balancing guarantees can still be rigorously proven
despite such variations.



\begin{comment}
We will show this coordination can be mathematically characterized as an Orthogonal Latin Square (OLS).  
While how to generate a (strongly) random OLS has been an open problem in combinatorics and theoretical computer science for 
decades, we fortunately are able to circumvent it, because Sprinklers will provably work with 
a weakly random (defined later) OLS, which is 
straightforward to generate.
\end{comment}

 




\begin{comment}
With near-perfect load-balancing, a Sprinklers switch pays only a modest price for guaranteeing correct packet
order.   While all other load-balanced switching solutions can guarantee 100\% throughput, the achievable throughput of our approach
is slightly less than 100\%.
For example, in a $2048 \times 2048$ switch, it can be rigorously proven that our solutions can 
achieve a throughput of about 95\% with high probability; see Table~\ref{tbl:example of bounds} in 
Sec.~\ref{sec:stability} for details.  And since there are slacks in the involved
mathematical inequalities, the actual achievable throughput is likely much closer to 100\%.   

Moreover, we will show that the provably achievable throughput of our solutions approaches
100\% asymptotically as the size of the switch $N$ increases.
This is because the load balancing capability of our solution, closely related to its throughput guarantee, 
builds upon the statistical multiplexing of flows that come from 
different input ports going to different output ports, in any intermediate ports, and this statistical multiplexing gain
grows with the number of input/output ports.  
We will show that, compared with existing load-balanced switching solutions,
each of which has to pay in one way or another for guaranteeing packet ordering,
the price paid by our solution, namely a few percent in throughput, appears to be the lowest.
\end{comment}











\subsection{Operations of the Sprinklers Switch}


As just explained, traffic inside each of the $N^2$ VOQs is switched through
a dyadic interval of intermediate ports that is just large enough to bring the load imposed by the VOQ on any intermediate port 
within this interval (i.e., ``water pressure per stream") below a certain threshold.  
The sizes of the corresponding $N^2$ stripe intervals are determined by the respective rates of the corresponding VOQs,
and their placements to consecutive intermediate ports are performed using a randomized algorithm.
Once generated, their placements remain fixed thereafter, while their sizes 
could change when their respective rates do.
Our goal in designing this randomized algorithm is that, 
when switched through the resulting (random) stripe intervals,  
traffic going out of any input port or going into any output port is near-perfectly balanced 
across all $N$ intermediate ports, with overwhelming probabilities.  


Once the $N^2$ stripe intervals are generated and fixed, packets in each VOQ will be striped across its
corresponding interval of intermediate ports as follows.  
Fix an arbitrary VOQ, and let its stripe size and interval be $2^k$ and $(\ell, \ell+2^k]
\equiv \{\ell+1, \ell+2, \cdots, \ell+2^k\}$, respectively.
(The integer $\ell$ must be divisible by $2^k$ for the interval to be dyadic, as discussed earlier.)
Packets in this VOQ are divided, chronologically according to their arrival times, 
into groups of $2^k$ packets each and,
with a slight abuse of the term, we refer to each such group also as a stripe.  Such a
stripe will eventually be switched through the set of intermediate ports $\{\ell+1, \ell+2, \cdots, \ell+2^k\}$
as follows. Assume this switching operation starts at time (slot) $t$, when the corresponding input port 
is connected to the intermediate port $\ell+1$ by the first switching fabric.  Then, following the periodic connection 
sequence of the first switching fabric, the input port forwards the first packet in the stripe to 
the intermediate port $\ell+1$ at time $t$, the second packet to the intermediate port $\ell+2$ at time $t + 1$, and so on,
until it forwards the last packet in the stripe to the intermediate port $\ell+2^k$ at time $t+ 2^k -1$.  That is, packets in this stripe
go out of the input port to consecutive intermediate ports in consecutive time slots (i.e., ``continuously").  The same can be said about other stripes from this and other VOQs.
This way, at each input port, the (switching) service is rendered by the first switching fabric in a stripe-by-stripe manner (i.e., finish serving 
one stripe before starting to serve another).   








At each input port, packets from the $N$ VOQs originated from it compete for (the switching) service by the first switching fabric
and hence must be arbitrated by a scheduler.   However, since the service is rendered stripe-by-stripe, as explained above, the scheduling
is really performed among the competing stripes.  In general, two different scheduling policies are needed in a Sprinklers switch, one used
at the input ports and the other at intermediate ports.  
Designing stripe scheduling policies that are well suited for a Sprinklers switch 
turns out to be a difficult undertaking because two tricky design requirements have to be met simultaneously.  

The first requirement is that the resulting scheduling policies must facilitate a highly efficient utilization of the switching capacity of both switching fabrics.
To see this, consider input port $i$, whose input link has a normalized rate of 1, and intermediate port $\ell$.  
As explained in 
Sec.~\ref{sec:intro}, these two ports are connected only once every $N$ time slots, by the first switching fabric.  
Consider the set of packets at input port $i$ that needs to be switched to the intermediate port $\ell$.  
This set can be viewed and called a queue (a queueing-theoretic concept), because 
the stripe scheduling policy naturally induces a service order (and hence a service process)
on this set of packets, and the arrival time of each packet is simply that of the stripe containing the packet.
Clearly, the service rate of this queue is exactly $1/N$.  Suppose this input port is heavily loaded 
say with a normalized arrival rate of 0.95.  Then even with perfect load-balancing, the arrival rate to this queue is $0.95/N$, only slightly below the service rate $1/N$.  
Clearly, for this queue to be stable,
there is no room for any waste of this service capacity.
In other words, the scheduling policy must be throughput optimal.

The second requirement is exactly why we force all packets in a VOQ to go down the same fat path (i.e., stripe interval) 
through a Sprinklers switch, so as to guarantee that no packet reordering
can happen.  
It is 
easy to verify
that for packet order to be preserved within every stripe (and hence within every VOQ),
it suffices to guarantee that packets in every stripe go into their destination output port from
consecutive intermediate ports in consecutive time slots (i.e., continuously).  However, it is much harder for a stripe of $2^k$ packets to arrive at an output port continuously (than to leave an input port),
because these packets are physically located at a single input port when they leave the input port, but 
across $2^k$ different intermediate
ports right before they leave for the output port.  

After exploring the entire space of stripe-by-stripe scheduling policies,
we ended up adopting the same stripe scheduling policy, namely Largest Stripe First (LSF),
at both input ports and intermediate ports, but not for the same set of reasons.
At input ports, LSF is used because it is throughput optimal.
At intermediate ports,
LSF is also used because it seems to be the only policy that makes every stripe of packets arrive at their destination output port
continuously without incurring significant internal communication costs between the input and intermediate ports.
In Sec.~\ref{sec: lsf scheduling},
we will describe the LSF policies at the input and intermediate ports.



















\subsection{Generating Stripe Intervals}
\label{sec:stripe generation}



As we have already explained, the random permutation and the variable dyadic stripe sizing techniques are used to
generate the stripe intervals for the $N$ VOQs originated from a single input port, with the objective of 
balancing the traffic coming out of this input port very evenly across all $N$ intermediate ports.
In Sec.~\ref{subsec: size determination}, 
we will specify this interval generating process precisely and provide detailed rationales for it.  
In Sec.~\ref{sec:stripe size eq}, we will 
explain why and how the interval generating processes at $N$ input ports should be carefully coordinated.

 
\subsubsection{Stripe interval generation at a single input port}
\label{subsec: size determination}

Suppose we fix an input port and number the $N$ VOQs originated from it as $1, 2, \cdots, N$, respectively.  
VOQ $i$ is first mapped to a distinct {\it primary intermediate port}
$\sigma(i)$, where $\sigma$ is a permutation chosen uniformly randomly from the set of all permutations on the set $\{1, 2, \cdots, N\}$.  
Then the stripe interval for a VOQ $i$ whose primary intermediate port is $\sigma(i)$ and
whose interval size is $n$, which must be a power of 2 as explained earlier, is simply the unique dyadic
interval of size $n$ that contains $\sigma(i)$.  A dyadic interval is one resulting from dividing the whole port number range 
$(0, N] \equiv \{1, 2, \cdots, N\}$ evenly by a power of 2, which takes the form
$(2^{k_0} m, 2^{k_0} (m + 1)]$ where
$k_0$ and $m$ are nonnegative integers.

\begin{figure}[htb]
  \centering
    \includegraphics[width=0.48\textwidth]{fromPrimaryToStripe.pdf}
    \caption{An example of VOQs being mapped to stripe intervals.}
\label{fig:stripe-interval-mapping}
\end{figure} 

In Fig.~\ref{fig:stripe-interval-mapping}, we show an example of mapping 8 VOQs at a single input port to their stripe intervals
in an 8 by 8 switch.  The middle column stands for the 8 intermediate ports and the columns
on the left and on the right correspond to VOQs 1, 3, 5, 7 and VOQs 2, 4, 6, 8, respectively.  Mapping a VOQ to 
its primary intermediate port is indicated by a solid arrow connecting the two.  Its stripe interval is indicated by 
the ``fanout" shadow that contains the solid line and is bounded at both ends by two dashed lines.  For example, 
VOQ 7 (bottom one on the left) is mapped to the primary intermediate 
port 1 and its stripe size is 4.  Therefore, its stripe interval is $(0, 4]$, the size-4 dyadic interval that contains intermediate
port 1.







\subsubsection{Stripe Size Determination}
\label{sec:stripe size eq}


As mentioned
in the ``water pressure equalization" analogy, for a VOQ, the size of its stripe interval is 
roughly proportional to the (current) traffic rate of the VOQ.  More precisely, the stripe interval size for
a VOQ of traffic rate $r$, is determined by the following function:
\begin{align}
  \label{eqn:stripe size rule}
F(r) = \min\left\{N, 2^{\ceil{\log_2 (rN^2)}}
  \right\}.
\end{align}
The stripe size determination rule~(\ref{eqn:stripe size rule}) 
tries to bring the amount of traffic each intermediate port within the stripe interval receives from 
this VOQ below $1/N^2$ while requiring that the stripe size 
be a power of 2. 
However, if the rate $r$ is very high, say $>\frac{1}{N}$, then the stripe size $F(r)$ is simply $N$.


The initial sizing of the $N^2$ stripe intervals may be set based on historical switch-wide traffic matrix
information, or to some default values.  
Afterwards,
the size of a stripe interval will be adjusted based on the measured rate of the corresponding VOQ.  
To prevent the size of a stripe from ``thrashing" between $2^k$ and $2^{k+1}$, we can delay the 
halving and doubling of the stripe size.  Although our later mathematical derivations assume the perfect
adherence to the above stripe size determination rule, the change in the provable load-balancing guarantees
is in fact negligible when a small number of stripe sizes are a bit too small (or too large) for the respective rates of 
their corresponding VOQs.




  
















\subsubsection{Coordination among all $N^2$ stripe intervals}
\label{sec:OLS}



Like an input port, an output port is connected to each intermediate port also exactly once every $N$
time slots, and hence needs to near-perfectly balance the traffic load coming into it.  That is, roughly $\frac{1}{N}$ of 
that load should come from each intermediate port.  In this section, we show how to achieve such load balancing at
an output port, by a careful coordination among the (stripe-interval-generating) permutations $\sigma_i$, $i = 1, 2, \cdots, N$.

Now consider an arbitrary output port $j$.  There are precisely $N$ VOQs destined for it, one originated from 
each input port.  Intuitively, they should ideally be mapped (permuted) to $N$ distinct primary intermediate ports 
-- for the same reason why the $N$ VOQs originated from an
input port are mapped (permuted) to $N$ distinct primary intermediate ports --
by the permutations $\sigma_1$, $\sigma_2$, $\cdots$, $\sigma_N$, respectively.  We will show this property 
holds for every output port $j$ if and only if the matrix representation of these permutations is an
Orthogonal Latin Square (OLS).

Consider an 
$N \times N$
matrix $A = (a_{ij})$, $i, j = 1, 2, \cdots, N$,  
where $a_{ij} = \sigma_i(j)$.
Consider the $N$ VOQs originated at input port $i$, one destined for each output port.  
We simply number 
each VOQ by its corresponding output port.
Clearly row $i$ of the matrix $A$ is the primary intermediate 
ports of these $N$ VOQs.   Now consider the above-mentioned $N$ VOQs destined for output port $j$, one originated from
each input port.   It is easy 
see that the $j_{th}$ column of matrix $A$, namely 
$\sigma_1(j)$, $\sigma_2(j)$, $\cdots$, $\sigma_N(j)$, is precisely the primary intermediate ports to which these
$N$ VOQs are mapped.  As explained earlier, we would like these numbers also to be distinct, i.e., a permutation of the set $\{1, 2, \cdots, N\}$.
Therefore, every row or column of the matrix $A$ must be a permutation of $\{1, 2, \cdots, N\}$.  Such a matrix is called an 
OLS in the combinatorics literature~\cite{colbourn1996crc}.




Our worst-case large deviation analysis in Sec.~\ref{sec:stability} requires the $N$ VOQs at the same input port or 
destined to the same output port
select their primary intermediate ports according to a uniform random permutation.
Mathematically, we only require the marginal distribution of the permutation represented by each row or column 
of the 
OLS
$A$ to be uniform.  
The use of the word ``marginal" here emphasizes that
we do not assume any dependence structure, or the lack thereof, among the $N$ random permutations 
represented by the $N$ rows and among those represented by the $N$ columns.  We refer to such an OLS as being weakly uniform random, to 
distinguish it from an OLS sampled uniformly randomly from the space of all
OLS' over the alphabet set $\{1, 2, \cdots, N\}$, which we refer to as being strongly uniform random.  
This distinction is extremely important for us, since  
whether there exists a polynomial time randomized algorithm for generating an OLS that is approximately strongly
uniform random has been an open problem in theoretical computer science and combinatorics 
for several decades~\cite{drizen2012generating,jacobson1996generating}.
A weakly uniform random OLS,
on the other hand, can be generated in $O(N \log N)$ time, shown as following.

We first generate two 
uniform random permutations $\sigma^{(R)}$
and $\sigma^{(C)}$ over the set $\{1, 2, \cdots, N\}$ that are mutually independent,
using a straightforward randomized algorithm~\cite{durstenfeld1964algorithm}.  
This process, which involves generating
$\log_2 N!$ = $O(N \log N)$ random bits needed to ``index" 
$\sigma^{(R)}$ and $\sigma^{(C)}$ each,  has $O(N \log N)$ complexity in total.  Then each matrix 
element $a(i, j)$ is simply set to $(\sigma^{(R)}(i) + \sigma^{(C)}(j) \mod N) + 1$.   It is not hard 
to verify that each row or column is a uniform random permutation.







\subsection{Largest Stripe First Policy}
\label{sec: lsf scheduling}







In this section, we describe our stripe scheduling policy called Largest Stripe First (LSF), which is used at both
input and intermediate ports of a Sprinklers switch.  LSF can be implemented in a straightforward
manner, at both input and intermediate ports, using $N (\log_2 N + 1)$ FIFO queues (a data structure concept).
Using an $N \times (\log_2 N + 1)$ 2D-bitmap to indicate the status of each queue (0 for empty, 1 for nonempty),
the switch can identify the rightmost bit set in each row of the bitmap in constant time,
which is used by LSF to identify the largest stripe to serve at each port.


We first provide a brief description of the periodic sequences of connections executed at both switching fabrics shown in Fig.~\ref{fig:load balance}.
The first switching fabric executes a periodic ``increasing'' sequence, that is, at any time slot $t$, each input port $i$ is connected
to the intermediate port $((i + t) \mod N) + 1$.  
The second switching fabric, on the other hand, will execute a periodic ``decreasing" sequence, that is, 
at any time slot $t$, each intermediate port $\ell$ is connected to the output port $((\ell - t) \mod N)+1$.  

In the rest of the paper, we make the following standard homogeneity assumption about a Sprinklers switch.  
Every input, intermediate, or output port
operates at the same speed.  That is, each can process and transmit exactly one packet per time slot.  We refer to this speed
as $1$.  Every connection made in a switching fabric also has speed of $1$ (i.e., one packet can be switched per time slot).
Since $N$ connections are made by a switching fabric at any time slot, up to $N$ packets can be switched during the time 
slot.













\subsubsection{Stripe Scheduling at Input Ports}
\label{sec:scheduling input}







\begin{algorithm}
\caption{LSF policy on ``Who is next?"}
\label{alg:select next VOQ to serve}
  \begin{algorithmic}[1]
  \State $l = (i + t \mod N) + 1$; 
    \If {No stripe is being served at time $t$}
      \State Let $S$ be the set of stripes with interval $(l-1, *]$;
      \If {$S$ is not empty}
        \State Start serving the largest stripe in $S$;
\EndIf
    \EndIf
  \end{algorithmic}
\end{algorithm}



The above pseudocode describes the Largest stripe first (LSF) policy used at input port $i$ to make
a decision as to, among multiple competing stripes, which one to serve next.   
Note that by the stripe-by-stripe nature of the scheduler, it is asked to make such a policy decision only 
when it completely finishes serving a stripe.
The policy is simply to pick among the set of stripes
whose dyadic
interval starts at intermediate port $\ell$ -- provided that the set is nonempty --  the largest one (FCFS for tie-breaking) to start serving immediately.  
The LSF policy is clearly throughput optimal because it is work-conserving in the sense whenever a connection is made between input port $i$ and intermediate port $\ell$, a packet will be served
if there is at least one stripe at the input port 
whose interval contains $\ell$.  
Using terms from queueing theory~\cite{kleinrock1975queueing}
we say this queue is served by a work-conserving server with service rate $1/N$.


























A stripe service schedule, which is the outcome of a scheduling policy acting on the stripe arrival process, 
is represented by a schedule grid, as shown in Fig.~\ref{fig: instance}.
There are $N$ rows in the grid, each corresponding
to an intermediate port.  Each tiny square in the column represents a time slot. 
The shade in the square represents a packet scheduled to be transmitted in that slot and
different shade patterns mean different VOQs.  Hence each ``thin vertical bar" of squares with the same shade 
represents a stripe in the schedule.
The time is progressing
on the grid from right to left in the sense that packets put inside the rightmost column 
will be served in the first cycle ($N$ time slots), the next column to the left in the second
cycle, and so on.  Within each column, time is progressing from up to down in the sense
that packet put inside the uppermost cell will be switched to intermediate port 1 say at
time slot $t_0$, packet put inside the cell immediately below it will be switched to intermediate
port 2 at time slot $t_0+1$, and so on.  Note this up-down sequence is consistent with the above-mentioned
periodic connection pattern between the input port and the intermediate ports.
Therefore, the scheduler is ``peeling" the grid from right to left and from up to down.

For example, Fig.~\ref{fig: instance}
corresponds to the statuses of the scheduling grid at time $t_0$ and $t_0 + 8$, 
where LSF is the scheduling policy.  We can see that
the rightmost
column 
in the left part of Fig.~\ref{fig: instance}, representing a single stripe of size $8$, 
is served by the first switching fabric in the meantime, 
and hence disappears in the right part of the figure.  
The above-mentioned working conservation nature of the LSF server for any input port is
also clearly illustrated in Fig.~\ref{fig: instance}:  
There is no ``hole" in any row.  

\begin{figure}[htb]
  \centering
    \includegraphics[width=0.48\textwidth]{serviceInstance.pdf}
    \caption{Statuses of the stripe scheduling at time $t_0$ (left) and $t_0+8$ (right) respectively.}
\label{fig: instance}
\end{figure}	 














While the scheduler always peels the grid from right to left and from up to down, 
the scheduler may insert a stripe ahead of other stripes smaller than it in size.  
In this case, the planned service time of all cells and bars to the left of the inserted vertical bar 
are shifted to the left by 1 column, meaning that their planned service time will 
be delayed by $N$ time slots.
For example, we 
can see from comparing the two parts of Fig.~\ref{fig: instance}
that a stripe of size 4 is inserted in the lower part of the 
3rd column in the right part of Fig.~\ref{fig: instance}, 
after two other stripes of size 4, but before some other stripes of smaller sizes.




















\subsubsection{Implementation of LSF at an Input Port}
\label{subsec:data strucutre lsf}

In this section, we describe data structures and algorithms for implementing the Longest 
Stripe First scheduling policy at an input port.  Again we use input port 1 as an illustrative example.
The LSF policy at input port 1 can be implemented using $N (\log_2 N+1)$ 
FIFO queues as shown in Fig.~\ref{fig:data structure}.  Conceptually, these FIFO queues are arranged into an array with 
$N$ rows and $\log_2 N + 1$ columns.  Row $\ell$ corresponds to FIFO queues that buffer packets 
to be sent to intermediate port $\ell$.  Each column of FIFO queues is used to buffer stripes of a certain size.  
The last column is for stripes of size $N$, the second last for stripes of size $N/2$, and so on.  
The very first column is for stripes of size $1$.  Therefore, the FIFO on the $\ell$th row and $k$th column
is to queue packets going to intermediate port $\ell$ and from stripes of size
$2^{k-1}$.

\begin{figure}[htb]
  \centering
    \includegraphics[width=0.48\textwidth]{datastructure.pdf}
    \caption{Data structure to implement LSF.}
\label{fig:data structure}
\end{figure}



The implementation of LSF with this data structure is straightforward.  Each VOQ will have a ready queue 
to buffer packets that have not filled up a stripe yet.  Once a stripe is full, depending on the size of the stripe, 
it will be ``plastered" into the corresponding interval in the corresponding column.  At each column,
stripes sent into the same interval will be queued in the FIFO order.  For example, the contents of 
these FIFO queues at time $t_0+8$, that correspond to the scheduling grid shown as the right part of Fig.~\ref{fig: instance}, 
are shown in Fig.~\ref{fig:data structure}.

During each time slot $t$, the scheduler either starts or is in the middle of serving the longest stripe that contain the intermediate
port $t \mod N$.  However, the scheduler 
does not need to be stripe-aware.  At each time $t$, it only needs to scan the $(t \mod N)th$ row 
from right to left and serve the packet at the head of the first nonempty queue.  If for each queue, we use a bit to encode whether it
is empty, our problem boils down to looking for the ``first one from right" in a bitmap $\log_2 N + 1$ bits long.  This kind of operation
can be done in one to a few clock cycles on modern processors or ASIC chip.  Overall $N$ such bitmaps are needed, one for each 
row (intermediate port).

Careful readers may note that it is unnecessary to maintain $N \log_2 N$ FIFO queues.  Rather, we need only one FIFO queue for all 
stripes of size $N$, two for all stripes of size $N/2$, -- namely one for the interval (0, N/2] and the other for $(N/2, N]$), -- four for all stripes of size
$N/4$, and so on.  The total number of FIFO queues we need is indeed $1 + 2 + 4 + \cdots + N/2 + N = 2N-1$.  
For example, in the above figure, we need only 15 queues: one FIFO queue for all stripes of size 8, two for all stripes of size 4, 
four for all stripes of size 2, and 8 for all stripes of size 1.  We will indeed adopt such a simplified implementation for the 
input port.  However, we still present the data structure in this ``verbose" manner because this data structure will be modified for use at
the intermediate ports, and there such a simplifying collapse is no longer possible, as will become clear next.








\subsubsection{Stripe Scheduling at Intermediate Ports}
\label{sec:scheduling intermediate}

In Sprinklers, an intermediate port also adopts the LSF policy for two reasons.  First, throughput-optimality is needed also at an intermediate port for the same reason stated above.  Second, given the distributed nature
in which any scheduling policy at an intermediate port is implemented, LSF 
appears to be the easiest and least costly to implement.


The schedule grids at intermediate ports take a slightly different form.
Every output port $j$ is associated with a schedule grid also consisting of $N$ rows. 
Row $i$ of the grid corresponds to the tentative schedule in which packets destined for output port 
$j$ at intermediate port $i$ will follow.  This schedule grid is really a virtual one, of which the $N$ rows are physically distributed across $N$ different intermediate ports respectively.  All stripes heading to output 
$j$ show up on this grid.  The LSF policy can be defined with respect to this virtual grid in 
almost the same way as in the previous case.  

The data structure for implementing LSF at intermediate ports is the same as that at input ports, except 
components of each instance are distributed across all $N$ intermediate ports, thus requiring some 
coordination.  This coordination however requires only that, for each packet switched over the first switching fabric, 
the input port inform the intermediate port of the size of the stripe to which the packet belongs.  This 
information can be encoded in just $\log_2 \log_2 N$ bits, which is a tiny number (e.g., $=4$ bits 
when $N = 4096$), and be included in the internal-use header
of every packet transmitted across the first switching fabric.



\begin{comment}

The aforementioned data structure  
for implementing LSF at input ports can be used for implementing the above virtual output LSF policy.  
Like in the earlier case, each intermediate port maintains a instance of the data structure, namely, 
$N \log N$ FIFO queues and a $N \times \log N$ bitmap.   
Unlike in the previous case, however, these 
instances need to work in a coordinated manner to make sure all packets inside any stripe will be served
in contiguous time slots.
Since these instances are physically distributed
any information necessary for the coordination needs to be communicated.  
It turns out that the only information necessary for this coordination, is for every 
packet, the size of the stripe in which the packet belongs.  
Since there are only $\log_2 N$ 
possible stripe sizes, this information can be encoded into $\log_2 \log_2 N$ bits, which is a tiny number.
For example, when $N = 4096$, only 4 bits are needed. 
The input ports, which have this knowledge, can include it
as a part of the internal-use header used in all existing LBS to indicate, among other things, 
the output port the packet should be directed to.

\end{comment}





