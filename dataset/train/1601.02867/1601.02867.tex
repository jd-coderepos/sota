\documentclass[runningheads,a4paper]{llncs}
\usepackage[english]{babel}
\usepackage[T1]{fontenc}
\usepackage[utf8]{inputenc}
\usepackage{algorithm}
\usepackage[noend]{algpseudocode}
\usepackage{amsmath,amssymb}
\usepackage{caption}
\usepackage{hyperref}
\usepackage{makeidx}
\usepackage{multirow}
\usepackage{ragged2e}
\usepackage{rotating}
\usepackage{siunitx}
\usepackage[labelformat=simple]{subcaption}
\usepackage{tabularx}
\usepackage{todonotes}
\usepackage{tikz}
\usepackage{sidecap,wrapfig}

\newcolumntype{C}{>{\setlength\hsize{1\hsize}\centering}X}
\newcolumntype{R}{>{\raggedleft\arraybackslash}X}

\setlength{\textfloatsep}{15pt}

\renewcommand\thesubfigure{(\alph{subfigure})}
\renewcommand\thesubtable{(\alph{subtable})}

\renewcommand\floatpagefraction{.9}
\renewcommand\dblfloatpagefraction{.9} \renewcommand\topfraction{.9}
\renewcommand\dbltopfraction{.9} \renewcommand\bottomfraction{.9}
\renewcommand\textfraction{.1}
\setcounter{totalnumber}{50}
\setcounter{topnumber}{50}
\setcounter{bottomnumber}{50}

\usetikzlibrary{arrows,calc,fit,shapes}

\title{A Sidetrack-Based Algorithm For Finding the  Shortest Simple Paths in a Directed Graph}
\author{Denis Kurz, Petra Mutzel}
\institute{Department of Computer Science, TU Dortmund, Germany\\
\email{\{denis.kurz,petra.mutzel\}@tu-dortmund.de}}

\pagestyle{plain}

\newcommand{\keywords}[1]{\par\addvspace\baselineskip
\noindent\keywordname\enspace\ignorespaces#1}

\newcommand{\spath}{\text{path}}
\newcommand{\dev}{\text{dev}}
\newcommand{\dist}{d}
\newcommand{\pref}{\text{pref}}
\newcommand{\suff}{\text{suff}}

\newcommand{\norm}[1]{\left|#1\right|}

\begin{document}
\def\sectionautorefname{Section}
\def\figureautorefname{Figure}
\def\tableautorefname{Table}
\def\theoremautorefname{Theorem}

\mainmatter
\maketitle

\begin{abstract}
We present an algorithm for the  shortest simple path problem on weighted directed graphs (SSP) that is based on Eppstein's algorithm for a similar problem in which paths are allowed to contain cycles.
In contrast to most other algorithms for SSP, ours is not based on Yen's algorithm \cite{CUSTOM:journals/networks/Yen71} and does not solve replacement path problems.
Its worst-case running time is on par with state-of-the-art algorithms for SSP.
Using our algorithm, one may find  simple paths with a single shortest path tree computation and  additional time per path in well-behaved cases, where  is the number of nodes and  is the number of edges.
Our computational results show that on random graphs and large road networks, these well-behaved cases are quite common and our algorithm is faster than existing algorithms by an order of magnitude.
Further, the running time is far better predictable due to very small dispersion.
\keywords{directed graph, -best, shortest path, simple path, weighted graph}
\end{abstract}


\section{Introduction}
\label{sec:introduction}

The \emph{ shortest path problem} in weighted, directed graphs (SP) asks for a set of  paths from a \emph{source}  to a target \emph{target}  in a graph with  nodes and  edges.
Every path that is not output by an algorithm should be at least as long as any path in the output.
Algorithms for this problem can be useful tools when it is hard to specify constraints that a solution should satisfy.
Instead of computing only one shortest path, SP algorithms generate  paths, and the user can then pick the one that suits their needs best.
The best known algorithm for this problem runs in time  and is due to Eppstein~\cite{DBLP:journals/siamcomp/Eppstein98}.
In the initialization phase, the algorithm builds a data structure that contains information about all - paths and how they interrelate with each other, in time .
This can even be reduced to  if the shortest path tree (SP tree) is given in the input or if the SP tree can be computed in time .
In the enumeration phase, a \emph{path graph} is constructed.
The path graph is a quaternary min-heap where every path starting in the root correlates to an - path in the original graph.
We require  time for the enumeration phase if we want the output paths to be ordered by length.
If the order in which the paths are output does not matter, Frederickson's heap selection algorithm~\cite{DBLP:journals/iandc/Frederickson93} can be used to enumerate the paths after the initialization phase in time .

The \emph{ shortest simple path problem} (SSP), introduced by Clarke, Krikorian and Schwartz~\cite{CUSTOM:journals/jsiam/ClarkeKR63}, seems to be more expensive, computationally.
In contrast to SP, the computed paths are required to be simple, i.e., they must not contain a cycle.
The extra effort may be well-invested if many of the  shortest paths are non-simple and we are only interested in simple paths.
The algorithm by Yen~\cite{CUSTOM:journals/networks/Yen71} used to have the best theoretical worst-case running time of  for quite some time.
Gotthilf and Lewenstein~\cite{DBLP:journals/ipl/GotthilfL09} improved upon this bound recently.
They observed that SSP can be solved by solving  all pairs shortest path (APSP) instances.
Using the APSP algorithm by Pettie~\cite{DBLP:journals/tcs/Pettie04}, they obtain a new upper bound of .
Vassilevska Williams and Williams~\cite{DBLP:conf/focs/WilliamsW10} showed that, for constant , an algorithm for SSP with running time  for some positive  (\emph{truly subcubic}) would also yield algorithms with truly subcubic running times for some other problems, including APSP.
A recent survey of the field is due to Eppstein~\cite{CUSTOM:arxiv/Eppstein14}.
The SSP on undirected graphs seems to be significantly easier.
Katoh et al.~\cite{DBLP:journals/networks/KatohIM82} proposed an algorithm that solves SSP on undirected graphs in time .

A subproblem occurring in Yen's algorithm is the (restricted) \emph{replacement path problem}.
Given a shortest - path  in a graph, it asks for a set of paths as follows.
For each , the set has to include a shortest simple path that uses the first  edges of , but not the th.
This problem has to be solved  times to find the  shortest simple paths using Yen's algorithm.
In the original version of Yen's algorithm, the replacement paths are found using  shortest path computations, resulting in time .
Hershberger et al.~\cite{DBLP:journals/talg/HershbergerMS07} compute one SP tree rooted in  and one reversed SP tree rooted in , respectively.
They use these two trees to find a replacement path in constant time per edge on , cutting down the time required to find all replacement paths to  when Dijkstra's algorithm is used.
However, the paths generated this way are not guaranteed to be simple.
Such non-simple paths can be detected in constant time and repaired by falling back to Yen's replacement path computation for the path edge in question.
Since they do not provide an upper bound for the number of non-simple paths that may occur using this method, the worst-case running time is again .

Some approaches reuse one fixed reversed SP tree  rooted in  and computed during the initialization of their SSP algorithm, in contrast to  SP trees per replacement path instance.
Pascoal~\cite{Pascoal06implementationsand} noticed that the replacement path that deviates from  at node  might be one that uses an edge  to an unused successor  of  and then follows the path from  to  in .
Therefore, they test whether the shortest such path is simple, and fall back to a full shortest path computation if it is not.
Although they do not describe in detail how this check is done, it can be done in time  per replacement path instance by partitioning the nodes into blocks as described by Hershberger et al.~\cite{DBLP:journals/talg/HershbergerMS07}.
Feng~\cite{DBLP:journals/networks/Feng14} uses the reversed SP tree to partition  into three classes.
For each edge  on  for which we want to compute a replacement path, \emph{red} nodes have already been used to reach  via .
A \emph{yellow} node  is a non-red upstream node of some red node in , i.e., the path from  to  in  contains a red node.
All other nodes are \emph{green}.
They then do shortest path computations from  using Dijkstra's algorithm like Yen.
However, they are able to restrict the search to yellow nodes, resulting in a significantly smaller search space.
Feng does not provide upper bounds on the size of this search space, resulting again in a worst-case running time of  for each replacement path instance.

\emph{Our contribution.}
We propose an algorithm that was derived from Eppstein's notion of a path graph~\cite{DBLP:journals/siamcomp/Eppstein98}.
Our algorithm achieves the same worst-case running time as Yen's algorithm.
Like Yen, we rely on shortest path (tree) computations.
In contrast to Yen-based algorithms, however, our algorithm may draw  simple paths from one shortest path tree computation.
If the underlying graph is acyclic, the revised algorithm at the end of this paper requires  without further modifications.
Alternatively, one could test whether the graph is acyclic and then use Eppstein's algorithm.
However, this method fails if the graph has just a single cycle, in which case our algorithm appears to be a good choice.
Our algorithm works on multigraphs without modification.
This is also true for every other SSP algorithm we know of.
After some definitions in~\autoref{sec:definitions}, we propose a simplified version of our algorithm with running time  in~\autoref{sec:simple-algo}.
In~\autoref{sec:improve}, we show how this running time can be reduced to , and how to reduce the number of shortest path tree computations in practice.
Finally, we present the results of our computational studies in~\autoref{sec:experiments} to prove the efficiency of our algorithm.


\section{Definitions}
\label{sec:definitions}

Let  be a directed graph with \emph{node} set  and \emph{edge} set .
Let  be \emph{source} and \emph{target} nodes, respectively.
We assume an implicit edge weight function  throughout this paper.
We denote the number of nodes  by  and the number of edges  by .
A \emph{path} connecting  to  in , or - path, is an edge sequence , , with ,  and  for .
For the sake of simplicity, we only consider combinations of ,  and  such that there exists an - path and a - path in  for every .
A node  is said to be on the path , denoted by , if  or  for some .
If  for ,  is a \emph{simple} path.
The \emph{prefix}  is a - path and denoted by .
The \emph{length}  of the path  is the sum of edge weights of its edges.
If every - path is at least as long as , it is called a \emph{shortest - path}.
We write  to denote the induced subgraph .

The \emph{ shortest simple path problem} (SSP) is an enumeration problem.
Given a directed graph  with source node , target node , edge weights , and some , we want to compute a set  comprising  simple paths from  to  in  such that  for every pair ,  of simple paths.
We obtain the \emph{ shortest path problem} (SP) if we do not require the computed paths to be simple.

A \emph{shortest path tree} (SP tree)  of  is a subtree of  with node set  such that each  has exactly one outgoing edge, which lies on a shortest - path, or no outgoing edges if no - path in  exists.
We denote the latter case by  even if  is in the node set of .
Our algorithm will compute several SP trees, the first of which we call \emph{initial SP tree} .
An edge  is called \emph{sidetrack} w.r.t. ; we will omit  in most cases.
For a sidetrack , the \emph{sidetrack cost}  is defined as , where  is the length of the unique - path in .
The sidetrack cost is therefore the difference between the length of a shortest - path and the length of a shortest - path that starts with .
The sidetrack set  of a node  is the set of all sidetracks w.r.t.  with tails on the unique - path in .
When sidetracks are organized in heaps, we use sidetrack costs for comparison.

Let ,  be two - paths, and .
Then, with respect to ,  is the \emph{deviation index}, the tail of  is the \emph{deviation node} , and  is the \emph{deviation edge} of .
As is quite usual for SSP algorithms, we will discover paths in a hierarchical fashion: a path  is added to the candidate set after  was extracted from the candidate set.
In such cases,  is called the \emph{parent path} of .
When  is omitted, the terms deviation node and edge are w.r.t. the parent path of .
By removing the deviation edge of  from ,  is split into its \emph{prefix path}  starting in , and its \emph{suffix path}  ending in .
The initial - path  in  has no parent path and thus no deviation edge.
We define its suffix path to be  itself.

We introduce a generalization of Eppstein's representation \cite{DBLP:journals/siamcomp/Eppstein98} for paths.
Eppstein represented paths as sequences of sidetracks, which were all sidetracks w.r.t. the same shortest path tree.
In our representation, every sidetrack  in a sidetrack sequence may be associated with a different shortest path tree .
The path represented by a sidetrack sequence  can then be reconstructed as follows.
Starting in , we follow the initial SP tree  until we reach the tail of .
After reaching the tail of , we traverse  and follow  until we reach the tail of , or, in case , until we reach .
Note that Eppstein's representation is the special case where  for each  in a sidetrack sequence, and that both Eppstein's sidetrack sequences and our generalized ones may represent non-simple paths.
The distance from a node  to  in a shortest path tree  associated with a sidetrack  is denoted by .


\section{Basic Algorithm}
\label{sec:simple-algo}

In this section, we propose a rather simple way to enumerate the  shortest simple paths.
We will describe later how to modify this algorithm to achieve our proclaimed running time guarantee.

We initialize an empty priority queue  that is going to manage candidate paths.
The key of a path in  is its length.
We compute the initial shortest path tree  and push its unique - path, represented by an empty sidetrack sequence, to .
We now process the paths in  in order of increasing length until we found  simple paths.

Let  be a sidetrack sequence extracted from , and  the path that is represented by this sequence.
Although the first path that is pushed to  is always simple, we will eventually push non-simple paths to , too.
Therefore, we first have to determine whether  is simple in a \emph{pivot step}.
This check can be done by simply walking  and marking every visited node.

We first describe how to handle the simple case.
We start by outputting .
For every sidetrack  with , we discover a new path  represented by the sequence .
We set , and push  to .
The length of  can easily be computed as .
If  is undefined because  does not contain a - path, we simply ignore .
By choosing , we simply reuse the shortest path tree that is also associated with the last sidetrack in the sequence representing .
Note that sidetracks emanating from  can safely be ignored.

\begin{figure}[tb]
\centering
\begin{subfigure}[b]{0.59\textwidth}
\centering
\begin{tikzpicture}[auto=right,every node/.style={minimum size=0.65cm}]
\draw (180:3cm) node[draw,circle] (s) {};
\draw (135:1.73cm) node[draw,circle] (v1) {};
\draw (225:1.73cm) node[draw,circle] (v2) {};
\draw (45:1.73cm) node[draw,circle] (v3) {};
\draw (-45:1.73cm) node[draw,circle] (v4) {};
\draw (0:3cm)   node[draw,circle] (t) {};

\draw[->,ultra thick] (s) -- (v1);
\draw[->,dashed] (s) -- node {} (v2);
\draw[->,ultra thick] (v1) -- (v3);
\draw[->,ultra thick] (v2) -- (v1);
\draw[->,dashed] (v2) -- node {} (v4);
\draw[->,dashed] (v3) -- node {} (v2);
\draw[->,ultra thick] (v3) -- (t);
\draw[->,ultra thick] (v4) -- (v3);
\draw[->,dashed] (v4) -- node{} (t);
\end{tikzpicture}
\caption{Example graph}
\label{fig:basic-example-graph}
\end{subfigure}
\begin{subfigure}[b]{0.39\textwidth}
\centering
\begin{tikzpicture}
\draw (0.1875, 0) node (empty) {};
\draw (-1.125,-1.2) node (a) {};
\draw (1.5,-1.2) node (c) {};
\draw (1.5,-2.4) node (cprime) {};
\draw (-2,-2.4) node (ab) {};
\draw (-0.25,-2.4) node (ac) {};
\draw (-2.7,-3.6) node (abc) {};
\draw (-1.3,-3.6) node (abd) {};

\draw[->] (empty) -- (a);
\draw[->] (empty) -- (c);
\draw[->] (a) -- (ab);
\draw[->] (a) -- (ac);
\draw[->] (ab) -- (abc);
\draw[->] (ab) -- (abd);
\draw[->] (c) -- (cprime);
\end{tikzpicture}
\caption{Sidetrack sequences}
\label{fig:basic-example-heap}
\end{subfigure}
\caption{Example for the basic algorithm. In \autoref{fig:basic-example-graph}, the thick, solid edges belong to . In \autoref{fig:basic-example-heap}, every sidetrack is associated with  except for , which is associated with the SP tree  comprising the edges  and . An arrow from sequence  to sequence  indicates that  is the parent path of .}
\label{fig:basic-example}
\end{figure}

Consider the example in \autoref{fig:basic-example}.
The sidetrack sequence  with  represents a simple path  that passes the nodes  in this order.
The suffix of this path is its - sub-path, and the sidetracks  and  have tails on this suffix.
Therefore, when  is extracted from ,  is output and the sequences  and  with  are pushed to .

Now assume we extracted a non-simple path  represented by the sidetrack sequence .
We try to extend the concatenation of the prefix path of  and  to a simple - path.
Let .
Any valid extension has to avoid the nodes of  after , and we are only interested in shortest extensions.
Therefore, we compute a new SP tree  and distances , but in  instead of  to make sure that nodes of the prefix path of  are not used again.
If ,  cannot be extended to a simple - path, and we simply discard .
Otherwise, we push the sequence  to  again.
In this new sequence, however, we associate  with  instead of  from the old sequence.
The sequence represents a path  obtained by concatenating the simple prefix path of , the edge , and the - path in  that, by construction, avoids all nodes of .
The suffix itself is simple, too, because it is a shortest path in a subgraph of .
Hence,  is simple.
The length of this path is .

Consider again the example in \autoref{fig:basic-example}.
The sidetrack sequence  with  represents a non-simple path  that visits the nodes , , , , , , ,  in this order.
The deviation node of  is , its deviation edge , and its prefix path is .
We compute a new SP tree  in , which only consists of the edge .
Therefore,  does not contain a - path, and  is discarded.

In contrast, assume the sequence  with  was just extracted from .
It represents almost the same path as the sequence above, but it skips the first visit of .
Again,  is the deviation node and  the deviation edge.
The prefix path comprises the nodes ,  and .
After removing them temporarily, a new shortest path tree  is computed, consisting only of the edges  and .
The sequence  with  is pushed to .
This new sequence represents the simple path , i.e., the concatenation of the prefix path of , the last sidetrack  in the extracted sequence, and the unique - path in .

Finally, when  with  is extracted, the represented path is output.
The sidetracks emanating from its prefix are  and .
Since , these sidetracks are ignored and no new path is pushed to .

\begin{lemma}
	The above algorithm computes the  shortest simple - paths of a weighted, directed graph .
\end{lemma}
\begin{proof}
	The algorithm uses the same idea of shortest deviations as existing SSP algorithms or Eppstein's SP algorithm.
	We only have to show that a non-simple path  is processed before its simple enhancement , resulting from the suffix repair in the non-simple case, is actually needed.
	The set of nodes that are forbidden when the SP tree for  is computed is a proper subset of the node set that the SP tree for  may not use.
	The suffix of  is therefore not longer than that of , and  is extracted from  (and subsequently,  is pushed) before we need to extract .
	\qed
\end{proof}

In terms of running time, the above algorithm requires too many computations of SP trees.

\begin{lemma}
	The running time of the above algorithm is .
\end{lemma}
\begin{proof}
	While processing a non-simple path, at most one new path is pushed to , which is always simple.
	Thus, the parent of a non-simple path is always simple.
    We have to process at most  simple paths, each of which requires  running time.
	Every simple path may have  sidetracks extensions.
	In the worst case, all of them represent non-simple paths, yielding  SP tree computations with a total running time of  if Dijkstra's algorithm with Fibonacci heaps is used.
	The running time for the non-simple cases clearly dominates.

	For every subset of , there is at most one permutation of this subset that represents a simple - path.
    The maximum number of paths enumerated by the algorithm is therefore .
    We can limit the size of  efficiently to  using a double-ended priority queue~\cite{CUSTOM:book/sahni1999}.
    We push  paths to  and extract  paths from it; both operations require  time on interval heaps.
    The total time spent on processing  is then .

    The pivot step requires  running time for each of the  extracted paths.
    \qed
\end{proof}


\section{Improvements}
\label{sec:improve}

We show how the number of SP tree computations can be reduced to  in the worst case, and seemingly even further in practice.

So far, we were only able to bound the number of SP tree computations by  for each extracted simple path.
This stems from the fact that there may be  sidetracks from such a path, each of them requiring a subsequent SP tree computation in the worst case.

Consider two sidetrack sequences ,  that were added when a path  represented by  was processed.
Let ,  be the paths represented by these sequences, respectively.
Assume that both sequences represent non-simple paths, and therefore both require a new SP tree.
We assume w.l.o.g. that  is extracted from  before .

When  is extracted from , we discover that it contains a cycle.
We then have to compute an SP tree  for the graph , where  is the - sub-path of .
We push  back to , updating .
When  is extracted, the basic algorithm computes an SP tree for the exact same graph.
This computation may be skipped.
We check if an SP tree for this graph has already been computed, and reuse it if it exists.
In our case, we simply push  with  to .

We obtain the following result.

\begin{lemma}
    Excluding the time spent on , the algorithm proposed in~\autoref{sec:simple-algo} in conjunction with SP tree reuse requires  time to process non-simple paths.
\end{lemma}
\begin{proof}
    There are still  many sequences in  that represent non-simple paths, but only  of them trigger an SP tree computation.
    Let  be a non-simple path extracted from .
    The initial pivot step requires time .
    If each path in  manages a pointer to its parent path as well as a pointer to the SP tree for  for every prefix path , already computed SP trees can be accessed in constant time.
    \qed
\end{proof}

The total running time of  spent on  is now no longer dominated.
Instead of using a priority queue for the candidate paths, we organize all computed paths in a min-heap in the following way.
The shortest path is the root of the min-heap.
Whenever a path  is computed while a path  is processed, we insert  into the min-heap as a child of .
\autoref{fig:basic-example-heap} shows an example of such a min-heap.

We want to extract the  smallest elements from this heap using Fredericksons heap selection algorithm~\cite{DBLP:journals/iandc/Frederickson93}.
The heap described above has maximum degree , again yielding a running time of .
Let  be the set of paths found during the processing of .
Instead of inserting every  as a heap child of , we heapify  to obtain the heap , using the lengths of the paths for keys again.
The root of  is then inserted into the global min-heap as a child of .
Note that the parent path of every path in  is not its heap parent in , but still  itself.

Every simple path  in the min-heap now has at most two heap successors with the same parent path as , and at most one heap successor whose parent is  itself.
Every non-simple path has at most one simple path as heap processor.
The maximum degree of the global min-heap is therefore bounded by three and Frederickson's heap selection can be done in time .

\begin{corollary}
    The algorithm proposed in~\autoref{sec:simple-algo} in conjunction with SP tree reuse and Frederickson's heap selection algorithm computes the  shortest simple - paths of a weighted, directed graph , , in  time.
\end{corollary}

We propose two more modifications that do not change the asymptotic worst-case running time.
We provide evidence that these changes make the algorithm faster in practice.

Consider one of the  simple - paths  represented by sidetracks  with ,  and .
When  is processed, we push the set  of paths to , with .
The basic algorithm tests for each  if  is simple in time , leading to a total time of  for these tests.

Let .
By removing all  from , the SP tree decomposes into a set of trees  such that  is rooted in .
The \emph{block } is the node set of .
Observe that the path  represented by a sequence , , with ,  in block , , respectively, is simple iff .
If , we follow  until we reach , traverse  and follow  to reach  again.
Otherwise, the first node on  we hit after deviating from it via  is .
Since , the - subpath of  does not contain , and therefore,  is simple.
The partition of  into blocks can be computed in time .
We can then collect all sidetracks deviating from  and check for each of them if their heads belong to a smaller block than their tails in  total time.
We store this information along with the corresponding sidetrack sequences in .
The pivot turn is replaced by a constant time lookup.
All tests for simplicity then require time  instead of .

Finally, we want to reduce the number of SP tree computations in practice.
Let  be a non-simple path represented by the sequence  with .
After we discover that  is not simple, the basic algorithm computes an SP tree in .
Only then does the algorithm check if .

Obviously, there is a shortest - path in , i.e., , iff there is \emph{some} directed path from  to  in .
Latter can be checked by a much simpler reachability check in time .
A naive approach checks reachability for every combination of some node  and one of the  nodes on the output simple paths, yielding time .
Of course, for a fixed prefix  of some simple path , we can also check reachability in  in  time for every node in  simultaneously, and obtain  total time.

Let  be the number of edges in , and consider sidetracks .
To determine whether the SP path computation for this sidetrack is necessary, we have to check whether there is a path in , where  is the number of edges of , and .
We determine reachability in  by starting a reverse depth-first search from , ignoring every node that lies on .
After this search, - reachability can be evaluated in constant time per sidetrack .
If  turns out to be separated from , the path represented by  is non-simple and cannot be repaired to a simple path.
In this case, we discard the sidetrack, which in turn cannot trigger an SP tree computation as it is never extracted from .

After collecting sidetracks emanating from  on , we continue with sidetracks emanating from the predecessor .
We conduct a depth-first search again, this time starting in  and reusing the reachability information computed before.
This way, we only process nodes that were unreachable before.
In other words, we solve an incremental series of reachability instances.
This procedure terminates when  is the deviation node of , and takes total time .


\section{Experiments}
\label{sec:experiments}

\begin{table}[tb]
\scriptsize
\centering
\begin{tabularx}{1\textwidth}{p{0.8cm}p{0.8cm}|RR|RR|RR|RR|RR}
& & \multicolumn{2}{c|}{} & \multicolumn{2}{c|}{} & \multicolumn{2}{c|}{} & \multicolumn{2}{c|}{} & \multicolumn{2}{c}{} \\
 \centering  & & Med &  & Med &  & Med &  & Med &  & Med &  \\
\hline
\centering\multirow{3}{*}{2,000} & \centering NC & 0.91 & 2.24 & 0.41 & 1.06 & 0.35 & 1.14 & 0.41 & 1.39 & 1.95 & 3.41 \\
& \centering SB-r  & 0.18 & 0.23 & 0.27 & 0.29 & 0.72 & 0.75 & 3.70 & 3.86 & 8.94 & 9.08 \\
& \centering SB-o  & \textbf{0.09} & \textbf{0.17} & \textbf{0.07} & \textbf{0.09} & \textbf{0.09} & \textbf{0.12} & \textbf{0.11} & \textbf{0.16} & \textbf{0.16} & \textbf{0.29} \\
\hline
\centering\multirow{3}{*}{4,000} & \centering NC & 0.90 & 2.63 & 0.76 & 2.39 & 0.75 & 1.79 & 1.24 & 4.61 & 1.92 & 4.92 \\
& \centering SB-r  & 0.35 & 0.40 & 0.53 & 0.58 & 1.39 & 1.60 & 7.26 & 7.31 & 17.46 & 17.64 \\
& \centering SB-o  & \textbf{0.16} & \textbf{0.21} & \textbf{0.12} & \textbf{0.17} & \textbf{0.13} & \textbf{0.20} & \textbf{0.17} & \textbf{0.22} & \textbf{0.27} & \textbf{0.38} \\
\hline
\centering\multirow{3}{*}{6,000} & \centering NC & 2.99 & 5.88 & 0.47 & 1.53 & 0.65 & 3.06 & 1.93 & 7.14 & 2.07 & 8.37 \\
& \centering SB-r  & 0.54 & 0.61 & 0.81 & 0.83 & 2.11 & 2.18 & 10.95 & 11.08 & 26.53 & 26.70 \\
& \centering SB-o  & \textbf{0.23} & \textbf{0.30} & \textbf{0.21} & \textbf{0.26} & \textbf{0.20} & \textbf{0.27} & \textbf{0.27} & \textbf{0.37} & \textbf{0.31} & \textbf{0.50} \\
\hline
\centering\multirow{3}{*}{8,000} & \centering NC & 1.62 & 7.16 & 0.62 & 2.52 & 1.79 & 4.27 & 3.29 & 9.23 & 2.45 & 8.94 \\
& \centering SB-r  & 0.69 & 0.86 & 1.08 & 1.11 & 2.81 & 2.89 & 14.66 & 15.35 & 34.84 & 35.50 \\
& \centering SB-o  & \textbf{0.28} & \textbf{0.46} & \textbf{0.23} & \textbf{0.26} & \textbf{0.32} & \textbf{0.41} & \textbf{0.34} & \textbf{0.54} & \textbf{0.39} & \textbf{0.47} \\
\hline
\centering\multirow{3}{*}{10,000} & \centering NC & 1.70 & 10.86 & 1.09 & 5.00 & 2.46 & 8.77 & 5.83 & 12.19 & 8.96 & 23.97 \\
& \centering SB-r  & 0.87 & 0.92 & 1.37 & 1.48 & 3.63 & 3.81 & 18.42 & 18.64 & 43.59 & 43.92 \\
& \centering SB-o  & \textbf{0.35} & \textbf{0.40} & \textbf{0.30} & \textbf{0.42} & \textbf{0.33} & \textbf{0.38} & \textbf{0.37} & \textbf{0.44} & \textbf{0.45} & \textbf{0.61} \\
\end{tabularx}
\vspace{2mm}
\caption{Median and 90\% quantile  of running times in seconds on random graphs with .}
\label{table:random}
\end{table}

To demonstrate the effectiveness of our algorithm, we conducted a series of experiments.
Feng~\cite{DBLP:journals/networks/Feng14} showed recently that their algorithm is the most efficient one in practice.
We therefore only compare our algorithm to Feng's node classification algorithm (NC).
Our implementation of NC does not use express edges and achieves better running times than the implementation of Feng, who appears to have used the same processor as we did.
We implemented two variants of our algorithm, both of which determine simplicity of all sidetracks of a simple path at once by partitioning the nodes into blocks as discussed above.
The first version, SB-r, tries to reduce the number of SP tree computations by solving some reachability problems; the second version, SB-o, spares this measure and is thus more optimistic.
None of the implementations uses Frederickson's heap selection algorithm, resulting in an additional running time  for SB-r and SB-o, but not for NC.
For space restrictions, we contented ourselves with two graph classes that Feng used in their experiments, including road graphs that are especially relevant in practice.

We implemented all algorithms in C++, using forward and reverse star representation for directed graphs.
Shortest paths (NC) and SP trees (SB-r, SB-o) are computed using a common implementation of Dijkstra's algorithm; tentative labels are managed by a pairing heap.
Our implementation of Dijkstra's algorithm stops as soon as the label of  is made permanent if only a single pair shortest path is needed, which is essential for NC.
The queue of candidate paths  is implemented as an interval heap, a form of double-headed priority queues, which allows us to limit its size efficiently to the number of simple paths that have yet to be output.
Special care has to be taken here for SB-r and SB-o since  also has to manage non-simple paths.
The experiments ran on an Intel Core i7-3770 @ 3.40GHz with 16GB of RAM on a GNU/Gentoo Linux with kernel version \texttt{4.2.5} and TurboBoost turned off.
Source code was compiled using the GNU C++ compiler \texttt{g++-4.9.3} and \texttt{-O3} optimization.

\subsection{Random Graphs}
\label{sec:random-graphs}

\begin{table}[tb]
\scriptsize
\centering
\begin{tabularx}{1\textwidth}{p{0.8cm}p{0.8cm}p{0.8cm}|RR|RR|RR}
 & & & \multicolumn{2}{c|}{} & \multicolumn{2}{c|}{} & \multicolumn{2}{c}{} \\
 \centering  & \centering  & & Dijkstra & Polls & Dijkstra & Polls & Dijkstra & Polls \\
\hline
\centering\multirow{15}{*}{} & \centering\multirow{3}{*}{} & \centering NC &  &  &  &  &  &  \\
 & & \centering SB-r  &  &  &  &  &  &  \\
 & & \centering SB-o  &  &  &  &  &  &  \\
\cline{2-9}
 & \centering\multirow{3}{*}{} & \centering NC &  &  &  &  &  &  \\
 & & \centering SB-r  &  &  &  &  &  &  \\
 & & \centering SB-o  &  &  &  &  &  &  \\
\cline{2-9}
 & \centering\multirow{3}{*}{} & \centering NC &  &  &  &  &  &  \\
 & & \centering SB-r  &  &  &  &  &  &  \\
 & & \centering SB-o  &  &  &  &  &  &  \\
\cline{2-9}
 & \centering\multirow{3}{*}{} & \centering NC &  &  &  &  &  &  \\
 & & \centering SB-r  &  &  &  &  &  &  \\
 & & \centering SB-o  &  &  &  &  &  &  \\
\cline{2-9}
 & \centering\multirow{3}{*}{} & \centering NC &  &  &  &  &  &  \\
 & & \centering SB-r  &  &  &  &  &  &  \\
 & & \centering SB-o  &  &  &  &  &  &  \\
\end{tabularx}
\vspace{2mm}
\caption{Median number of Dijkstra calls and polls for random graphs.}
\label{table:dijkstras}
\end{table}

We first considered random graphs generated by the \texttt{sprand} generator provided on the website of the ninth DIMACS implementation challenge~\cite{CUSTUM:dimacs9}.
The generator draws at random a fixed amount of edges, possibly resulting in a multigraph.
For each combination of graph size  and \emph{linear density} , we generated 20 random graphs, and enumerated  simple paths.

In \autoref{table:random}, the median and 90\% quantile  (90\% of the running times were at most ) of execution times for some densities are summarized.
For small densities, we observe that SB-r is faster than NC, but becomes much slower as the density grows.
The running time of SB-r increases by a factor of 50 between  and , but only by a factor of 2 for NC.
SB-o is about twice as fast as SB-r for very small densities, and is even more robust against density changes than NC.
SB-o is thus the fastest of the three algorithms for all graph sizes and densities.
Also note the very low dispersion of SB running times.
For NC, the 90\% quantile of the running time is regularly three times the median running time, and even exceeds a factor of 6 for  and .
In contrast, this quotient is always much closer to 1 for SB-o and assumes its maximum of 1.87 for , .
We can therefore predict the running time of SB-o much more accurate than that of NC.
The  running time of SB-o is still well below the median running time of both SB-r and NC.
The dispersion of SB-r is even lower.

\begin{table}[tb]
\centering
\begin{subtable}[b]{1\textwidth}
\scriptsize
\centering
\begin{tabularx}{0.7\textwidth}{XRRRR}
Graph & NY & BAY & COL & FLA \\
\hline
 &  &  &  &  \\
 &  &  &  &  \\
\end{tabularx}
\caption{Sizes of four road graphs.}
\label{table:tiger-sizes}
\end{subtable}
\begin{subtable}[b]{1\textwidth}
\scriptsize
\centering
\begin{tabularx}{1\textwidth}{p{0.8cm}p{0.8cm}|RR>{\RaggedLeft}p{1.4cm}|RR>{\RaggedLeft}p{1.5cm}|RR>{\RaggedLeft}p{1.5cm}}
& & \multicolumn{3}{c|}{} & \multicolumn{3}{c|}{} & \multicolumn{3}{c}{} \\
 & & Med &  & Polls & Med &  & Polls & Med &  & Polls \\
\hline
\centering\multirow{3}{*}{NY} & \centering NC & 2.06 & 12.14 &  & 3.77 & 24.11 &  & 5.40 & 35.17 &  \\
 & \centering SB-r  & 1.38 & 3.60 &  & 2.64 & 7.62 &  & 3.88 & 11.43 &  \\
 & \centering SB-o  & \textbf{0.55} & \textbf{2.77} &  & \textbf{0.97} & \textbf{5.91} &  & \textbf{1.38} & \textbf{9.10} &  \\
\hline
\centering\multirow{3}{*}{BAY} & \centering NC & 5.11 & 17.09 &  & 9.27 & 33.81 &  & 13.84 & 49.54 &  \\
 & \centering SB-r  & 1.76 & 8.43 &  & 3.15 & 18.52 &  & 4.77 & 28.18 &  \\
 & \centering SB-o  & \textbf{0.79} & \textbf{7.62} &  & \textbf{1.49} & \textbf{17.67} &  & \textbf{1.99} & \textbf{24.97} &  \\
\hline
\centering\multirow{3}{*}{COL} & \centering NC & 6.53 & 25.13 &  & 11.65 & 44.08 &  & 15.98 & \textbf{58.83} &  \\
 & \centering SB-r  & 2.10 & \textbf{18.06} &  & 4.01 & 38.40 &  & 6.00 & 62.28 &  \\
 & \centering SB-o  & \textbf{0.80} & 18.43 &  & \textbf{1.42} & \textbf{37.98} &  & \textbf{2.02} & 60.62 &  \\
\hline
\centering\multirow{3}{*}{FLA} & \centering NC & 30.15 & 67.43 &  & 58.13 & 126.24 &  & 83.00 & 188.03 &  \\
 & \centering SB-r  & 5.53 & 9.68 &  & 10.60 & 33.13 &  & 15.73 & 55.29 &  \\
 & \centering SB-o  & \textbf{2.54} & \textbf{6.81} &  & \textbf{4.65} & \textbf{27.72} &  & \textbf{6.78} & \textbf{47.00} &  \\
\end{tabularx}
\caption{Median and 90\% quantile  of running times in seconds, median number of polls.}
\label{table:tiger-times}
\end{subtable}
\vspace{-4mm}
\caption{Sizes and metrics for four large TIGER road graphs.}
\label{fig:tiger}
\end{table}

\autoref{table:dijkstras} shows the median number of Dijkstra calls.
The numbers are relatively stable across the various densities, but the Dijkstra counts for the SB algorithms is orders of magnitudes smaller than the count for the NC algorithm.
Note, however, that SB needs to compute the complete SP tree every time.
In contrast, NC only solves single pair shortest path problems on rather small subgraphs.
We also provide the number of polls, i.e.,  the total number of nodes that were extracted from Dijkstra's priority queue, for comparability.
NC still requires an order of magnitude more polls compared to SB.
Further, there are only small differences in the median number of polls for SB-r and SB-o for .
Solving incremental reach for each of the  output simple paths only reduced the number of SP tree computations by at most three for , .
The extra effort involved to reduce SP tree computations ranges from 50\% of the total running time on very sparse graphs to 98\% on very dense graphs, and does not pay off.
Therefore, SB-o is clearly the fastest algorithm on random graphs.

\subsection{Road Graphs}
\label{sec:road-graphs}

We considered road graphs of various areas in the USA called TIGER graphs, again provided by the DIMACS website~\cite{CUSTUM:dimacs9}.
In particular, we used the road networks of New York (NY), the San Francisco Bay Area (BAY), Colorado (COL), and Florida (FLA).
The sizes of these graphs are shown in \autoref{table:tiger-sizes}.
We drew 20 - pairs at random and enumerated  paths.

The resulting running times are summarized in \autoref{table:tiger-times}, along with the median number of polls.
The median running time of NC is clearly dominated by both SB variants.
SB-o achieves a minimum speedup around 4 on NY across all values of ; on FLA, the speedup is roughly 12.
SB-r takes approximately twice the time of SB-o and is still much faster than NC.
The ratio of  and median running time is worse for SB, but the  time itself of SB-o is still better than that of NC except for 300 paths on COL.
On FLA, the largest graph, the 90\% quantile of SB-o is much better than the median running time of NC.

\bibliography{literature}
\bibliographystyle{splncs03}

\appendix





\begin{sidewaystable}
\scriptsize
\centering
\begin{tabularx}{1\textwidth}{p{0.8cm}p{0.8cm}|RR|RR|RR|RR|RR|RR|RR|RR|RR}
& & \multicolumn{18}{c}{} \\
  & & \multicolumn{2}{c|}{} & \multicolumn{2}{c|}{} & \multicolumn{2}{c|}{} & \multicolumn{2}{c|}{} & \multicolumn{2}{c}{} & \multicolumn{2}{c}{} & \multicolumn{2}{c}{} & \multicolumn{2}{c}{} & \multicolumn{2}{c}{} \\
\centering  & & Med &  & Med &  & Med &  & Med &  & Med &  & Med &  & Med &  & Med &  & Med &  \\
\hline
\centering\multirow{3}{*}{} & \centering NC & 0.22 & 0.56 & 0.14 & 0.29 & 0.10 & 0.27 & 0.06 & 0.20 & 0.08 & 0.27 & 0.11 & 0.39 & 0.10 & 0.35 & 0.23 & 0.54 & 0.47 & 0.84 \\
 & \centering SB-r  & 0.04 & 0.06 & 0.05 & 0.07 & 0.07 & 0.07 & 0.11 & 0.13 & 0.18 & 0.19 & 0.49 & 0.51 & 0.92 & 0.95 & 1.50 & 1.53 & 2.22 & 2.26 \\
 & \centering SB-o  & \textbf{0.02} & \textbf{0.04} & \textbf{0.02} & \textbf{0.03} & \textbf{0.02} & \textbf{0.02} & \textbf{0.02} & \textbf{0.03} & \textbf{0.02} & \textbf{0.03} & \textbf{0.03} & \textbf{0.05} & \textbf{0.03} & \textbf{0.04} & \textbf{0.03} & \textbf{0.04} & \textbf{0.04} & \textbf{0.07} \\
\hline
\centering\multirow{3}{*}{} & \centering NC & 0.22 & 0.65 & 0.15 & 0.51 & 0.19 & 0.60 & 0.20 & 0.55 & 0.18 & 0.43 & 0.71 & 1.21 & 0.31 & 1.14 & 0.29 & 1.24 & 0.48 & 1.27 \\
 & \centering SB-r  & 0.09 & 0.10 & 0.11 & 0.13 & 0.13 & 0.15 & 0.24 & 0.26 & 0.35 & 0.38 & 0.96 & 0.99 & 1.81 & 1.83 & 2.96 & 3.60 & 4.34 & 4.74 \\
 & \centering SB-o  & \textbf{0.04} & \textbf{0.04} & \textbf{0.03} & \textbf{0.05} & \textbf{0.03} & \textbf{0.05} & \textbf{0.04} & \textbf{0.06} & \textbf{0.03} & \textbf{0.05} & \textbf{0.04} & \textbf{0.06} & \textbf{0.04} & \textbf{0.06} & \textbf{0.05} & \textbf{0.08} & \textbf{0.05} & \textbf{0.08} \\
\hline
\centering\multirow{3}{*}{} & \centering NC & 0.74 & 1.47 & 0.13 & 0.95 & 0.12 & 0.39 & 0.30 & 0.75 & 0.17 & 0.78 & 0.28 & 1.87 & 0.48 & 1.78 & 0.39 & 1.86 & 0.51 & 2.09 \\
 & \centering SB-r  & 0.14 & 0.15 & 0.16 & 0.17 & 0.20 & 0.21 & 0.34 & 0.36 & 0.52 & 0.54 & 1.44 & 1.56 & 2.74 & 2.76 & 4.40 & 4.44 & 6.56 & 6.59 \\
 & \centering SB-o  & \textbf{0.06} & \textbf{0.07} & \textbf{0.05} & \textbf{0.06} & \textbf{0.05} & \textbf{0.06} & \textbf{0.05} & \textbf{0.06} & \textbf{0.05} & \textbf{0.07} & \textbf{0.06} & \textbf{0.11} & \textbf{0.07} & \textbf{0.09} & \textbf{0.07} & \textbf{0.09} & \textbf{0.07} & \textbf{0.11} \\
\hline
\centering\multirow{3}{*}{} & \centering NC & 0.40 & 1.78 & 0.51 & 1.21 & 0.15 & 0.62 & 0.27 & 1.53 & 0.44 & 1.06 & 0.36 & 2.06 & 0.82 & 2.20 & 0.76 & 2.56 & 0.62 & 2.46 \\
 & \centering SB-r  & 0.17 & 0.20 & 0.22 & 0.24 & 0.27 & 0.28 & 0.46 & 0.47 & 0.71 & 0.75 & 1.94 & 2.18 & 3.64 & 3.72 & 5.93 & 6.21 & 8.72 & 9.69 \\
 & \centering SB-o  & \textbf{0.07} & \textbf{0.10} & \textbf{0.06} & \textbf{0.09} & \textbf{0.06} & \textbf{0.07} & \textbf{0.06} & \textbf{0.07} & \textbf{0.07} & \textbf{0.09} & \textbf{0.07} & \textbf{0.09} & \textbf{0.08} & \textbf{0.12} & \textbf{0.09} & \textbf{0.13} & \textbf{0.09} & \textbf{0.11} \\
\hline
\centering\multirow{3}{*}{} & \centering NC & 0.42 & 2.73 & 0.36 & 1.97 & 0.28 & 1.24 & 0.38 & 2.25 & 0.61 & 2.09 & 0.80 & 2.35 & 1.45 & 3.01 & 1.48 & 3.81 & 2.25 & 5.89 \\
 & \centering SB-r  & 0.21 & 0.23 & 0.27 & 0.31 & 0.34 & 0.38 & 0.58 & 0.60 & 0.91 & 0.99 & 2.44 & 2.67 & 4.61 & 4.62 & 7.42 & 7.59 & 10.88 & 10.93 \\
 & \centering SB-o  & \textbf{0.08} & \textbf{0.10} & \textbf{0.08} & \textbf{0.11} & \textbf{0.07} & \textbf{0.11} & \textbf{0.08} & \textbf{0.09} & \textbf{0.08} & \textbf{0.10} & \textbf{0.10} & \textbf{0.13} & \textbf{0.09} & \textbf{0.12} & \textbf{0.10} & \textbf{0.13} & \textbf{0.11} & \textbf{0.15} \\
\hline
\\
  & & \multicolumn{18}{c}{} \\
  & & \multicolumn{2}{c|}{} & \multicolumn{2}{c|}{} & \multicolumn{2}{c|}{} & \multicolumn{2}{c|}{} & \multicolumn{2}{c}{} & \multicolumn{2}{c}{} & \multicolumn{2}{c}{} & \multicolumn{2}{c}{} & \multicolumn{2}{c}{} \\
\centering  & & Med &  & Med &  & Med &  & Med &  & Med &  & Med &  & Med &  & Med &  & Med &  \\
\hline
\centering\multirow{3}{*}{} & \centering NC & 0.91 & 2.24 & 0.58 & 1.18 & 0.41 & 1.06 & 0.30 & 0.81 & 0.35 & 1.14 & 0.46 & 1.54 & 0.41 & 1.39 & 0.99 & 2.22 & 1.95 & 3.41 \\
 & \centering SB-r  & 0.18 & 0.23 & 0.22 & 0.26 & 0.27 & 0.29 & 0.46 & 0.50 & 0.72 & 0.75 & 1.97 & 2.04 & 3.70 & 3.86 & 6.10 & 6.32 & 8.94 & 9.08 \\
 & \centering SB-o  & \textbf{0.09} & \textbf{0.17} & \textbf{0.07} & \textbf{0.11} & \textbf{0.07} & \textbf{0.09} & \textbf{0.06} & \textbf{0.11} & \textbf{0.09} & \textbf{0.12} & \textbf{0.10} & \textbf{0.17} & \textbf{0.11} & \textbf{0.16} & \textbf{0.14} & \textbf{0.20} & \textbf{0.16} & \textbf{0.29} \\
\hline
\centering\multirow{3}{*}{} & \centering NC & 0.90 & 2.63 & 0.58 & 2.04 & 0.76 & 2.39 & 0.72 & 1.78 & 0.75 & 1.79 & 2.88 & 4.78 & 1.24 & 4.61 & 1.19 & 5.00 & 1.92 & 4.92 \\
 & \centering SB-r  & 0.35 & 0.40 & 0.44 & 0.49 & 0.53 & 0.58 & 0.95 & 1.02 & 1.39 & 1.60 & 3.85 & 3.95 & 7.26 & 7.31 & 11.87 & 12.56 & 17.46 & 17.64 \\
 & \centering SB-o  & \textbf{0.16} & \textbf{0.21} & \textbf{0.13} & \textbf{0.19} & \textbf{0.12} & \textbf{0.17} & \textbf{0.16} & \textbf{0.23} & \textbf{0.13} & \textbf{0.20} & \textbf{0.17} & \textbf{0.26} & \textbf{0.17} & \textbf{0.22} & \textbf{0.21} & \textbf{0.34} & \textbf{0.27} & \textbf{0.38} \\
\hline
\centering\multirow{3}{*}{} & \centering NC & 2.99 & 5.88 & 0.49 & 3.78 & 0.47 & 1.53 & 1.20 & 2.93 & 0.65 & 3.06 & 1.18 & 7.44 & 1.93 & 7.14 & 1.58 & 7.28 & 2.07 & 8.37 \\
 & \centering SB-r  & 0.54 & 0.61 & 0.66 & 0.68 & 0.81 & 0.83 & 1.36 & 1.45 & 2.11 & 2.18 & 5.79 & 6.46 & 10.95 & 11.08 & 17.62 & 17.84 & 26.53 & 26.70 \\
 & \centering SB-o  & \textbf{0.23} & \textbf{0.30} & \textbf{0.20} & \textbf{0.22} & \textbf{0.21} & \textbf{0.26} & \textbf{0.22} & \textbf{0.27} & \textbf{0.20} & \textbf{0.27} & \textbf{0.22} & \textbf{0.35} & \textbf{0.27} & \textbf{0.37} & \textbf{0.26} & \textbf{0.32} & \textbf{0.31} & \textbf{0.50} \\
\hline
\centering\multirow{3}{*}{} & \centering NC & 1.62 & 7.16 & 1.98 & 4.97 & 0.62 & 2.52 & 1.05 & 6.24 & 1.79 & 4.27 & 1.40 & 8.22 & 3.29 & 9.23 & 3.04 & 10.36 & 2.45 & 8.94 \\
 & \centering SB-r  & 0.69 & 0.86 & 0.88 & 0.96 & 1.08 & 1.11 & 1.85 & 1.87 & 2.81 & 2.89 & 7.77 & 8.57 & 14.66 & 15.35 & 23.78 & 24.95 & 34.84 & 35.50 \\
 & \centering SB-o  & \textbf{0.28} & \textbf{0.46} & \textbf{0.26} & \textbf{0.34} & \textbf{0.23} & \textbf{0.26} & \textbf{0.24} & \textbf{0.27} & \textbf{0.32} & \textbf{0.41} & \textbf{0.30} & \textbf{0.34} & \textbf{0.34} & \textbf{0.54} & \textbf{0.38} & \textbf{0.47} & \textbf{0.39} & \textbf{0.47} \\
\hline
\centering\multirow{3}{*}{} & \centering NC & 1.70 & 10.86 & 1.56 & 7.75 & 1.09 & 5.00 & 1.56 & 9.06 & 2.46 & 8.77 & 3.18 & 9.55 & 5.83 & 12.19 & 5.92 & 15.18 & 8.96 & 23.97 \\
 & \centering SB-r  & 0.87 & 0.92 & 1.09 & 1.25 & 1.37 & 1.48 & 2.33 & 2.39 & 3.63 & 3.81 & 9.83 & 10.28 & 18.42 & 18.64 & 29.76 & 29.86 & 43.59 & 43.92 \\
 & \centering SB-o  & \textbf{0.35} & \textbf{0.40} & \textbf{0.30} & \textbf{0.47} & \textbf{0.30} & \textbf{0.42} & \textbf{0.30} & \textbf{0.37} & \textbf{0.33} & \textbf{0.38} & \textbf{0.37} & \textbf{0.47} & \textbf{0.37} & \textbf{0.44} & \textbf{0.41} & \textbf{0.49} & \textbf{0.45} & \textbf{0.61} \\
\hline
\\
  & & \multicolumn{18}{c}{} \\
  & & \multicolumn{2}{c|}{} & \multicolumn{2}{c|}{} & \multicolumn{2}{c|}{} & \multicolumn{2}{c|}{} & \multicolumn{2}{c}{} & \multicolumn{2}{c}{} & \multicolumn{2}{c}{} & \multicolumn{2}{c}{} & \multicolumn{2}{c}{} \\
\centering  & & Med &  & Med &  & Med &  & Med &  & Med &  & Med &  & Med &  & Med &  & Med &  \\
\hline
\centering\multirow{2}{*}{} & \centering NC & 0.91 & 2.24 & 0.58 & 1.18 & 0.41 & 1.06 & 0.30 & 0.81 & 0.35 & 1.14 & 0.46 & 1.54 & 0.41 & 1.39 & 0.99 & 2.22 & 1.95 & 3.41 \\
 & \centering SB-o  & \textbf{0.07} & \textbf{0.15} & \textbf{0.04} & \textbf{0.09} & \textbf{0.05} & \textbf{0.07} & \textbf{0.05} & \textbf{0.09} & \textbf{0.08} & \textbf{0.12} & \textbf{0.10} & \textbf{0.16} & \textbf{0.11} & \textbf{0.16} & \textbf{0.15} & \textbf{0.20} & \textbf{0.17} & \textbf{0.29} \\
\hline
\centering\multirow{2}{*}{} & \centering NC & 0.90 & 2.63 & 0.58 & 2.04 & 0.76 & 2.39 & 0.72 & 1.78 & 0.75 & 1.79 & 2.88 & 4.78 & 1.24 & 4.61 & 1.19 & 5.00 & 1.92 & 4.92 \\
 & \centering SB-o  & \textbf{0.09} & \textbf{0.13} & \textbf{0.07} & \textbf{0.12} & \textbf{0.06} & \textbf{0.10} & \textbf{0.10} & \textbf{0.18} & \textbf{0.08} & \textbf{0.14} & \textbf{0.14} & \textbf{0.21} & \textbf{0.15} & \textbf{0.18} & \textbf{0.19} & \textbf{0.28} & \textbf{0.22} & \textbf{0.32} \\
\hline
\centering\multirow{2}{*}{} & \centering NC & 2.99 & 5.88 & 0.49 & 3.78 & 0.47 & 1.53 & 1.20 & 2.93 & 0.65 & 3.06 & 1.18 & 7.44 & 1.93 & 7.14 & 1.58 & 7.28 & 2.07 & 8.37 \\
 & \centering SB-o  & \textbf{0.15} & \textbf{0.22} & \textbf{0.10} & \textbf{0.16} & \textbf{0.10} & \textbf{0.14} & \textbf{0.13} & \textbf{0.17} & \textbf{0.12} & \textbf{0.19} & \textbf{0.16} & \textbf{0.28} & \textbf{0.21} & \textbf{0.29} & \textbf{0.21} & \textbf{0.26} & \textbf{0.25} & \textbf{0.41} \\
\hline
\centering\multirow{2}{*}{} & \centering NC & 1.62 & 7.16 & 1.98 & 4.97 & 0.62 & 2.52 & 1.05 & 6.24 & 1.79 & 4.27 & 1.40 & 8.22 & 3.29 & 9.23 & 3.04 & 10.36 & 2.45 & 8.94 \\
 & \centering SB-o  & \textbf{0.11} & \textbf{0.33} & \textbf{0.12} & \textbf{0.21} & \textbf{0.10} & \textbf{0.14} & \textbf{0.12} & \textbf{0.15} & \textbf{0.13} & \textbf{0.21} & \textbf{0.17} & \textbf{0.23} & \textbf{0.20} & \textbf{0.33} & \textbf{0.26} & \textbf{0.36} & \textbf{0.28} & \textbf{0.35} \\
\hline
\centering\multirow{2}{*}{} & \centering NC & 1.70 & 10.86 & 1.56 & 7.75 & 1.09 & 5.00 & 1.56 & 9.06 & 2.46 & 8.77 & 3.18 & 9.55 & 5.83 & 12.19 & 5.92 & 15.18 & 8.96 & 23.97 \\
 & \centering SB-o  & \textbf{0.12} & \textbf{0.20} & \textbf{0.10} & \textbf{0.26} & \textbf{0.10} & \textbf{0.23} & \textbf{0.12} & \textbf{0.17} & \textbf{0.14} & \textbf{0.19} & \textbf{0.19} & \textbf{0.29} & \textbf{0.21} & \textbf{0.29} & \textbf{0.26} & \textbf{0.33} & \textbf{0.33} & \textbf{0.44} \\
    \hline
\end{tabularx}
\caption{Median and 90\% quantile  of running times in seconds of NC, SB-r and SB-o on random graphs of all tested sizes for .}
\end{sidewaystable}



\begin{sidewaysfigure}[tb]
\centering
\includegraphics[height=0.65\textwidth]{density-grows}
\caption{Boxplots of running times in seconds for random graphs with  nodes and . Plus signs represent outliers. A red square marks the mean, but was omitted for the SB algorithms as they would completely cover their corresponding boxes.}
\label{fig:sprand-boxplot}
\end{sidewaysfigure}

\begin{sidewaysfigure}[tb]
\centering
\includegraphics[height=0.65\textwidth]{large-cities}
\caption{Boxplots of running times in seconds for TIGER graphs. Plus signs represent outliers. A red square marks the mean. The interquartile range of SB on FLA for  is so small that the boxes appear as lines.}
\label{fig:large-cities}
\end{sidewaysfigure}


\end{document}
