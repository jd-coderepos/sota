\begin{figure*}
\centering
    \begin{subfigure}[b]{0.33\textwidth}
        \centering
        \includegraphics[width=\textwidth]{gfx/Discrete_Recovery_OOD.png}
        \caption{TransFuser (NC conditioned)}
        \label{fig:discrete_target_point_failure}
    \end{subfigure}
    \begin{subfigure}[b]{0.33\textwidth}  
        \centering 
        \includegraphics[width=\textwidth]{gfx/TP_Recovery_OOD.png}
        \caption{TransFuser (TP conditioned)}
        \label{fig:target_point_success}
    \end{subfigure}
    \begin{subfigure}[b]{0.33\textwidth}
        \centering
        \includegraphics[width=\textwidth]{gfx/lav_v2_TP_recovery.png}
        \caption{LAV~\cite{Chen2022CVPRa} (TP conditioned)}
        \label{fig:target_point_success_lav}
    \end{subfigure}
    \vspace{-0.7cm}
   \caption{\textbf{Extrapolation to target point.} In unknown situations, TP conditioned methods extrapolate their \textcolor{blue}{waypoints} towards \textcolor{red}{target points}. This periodically resets steering errors and is a form of implicit map based recovery. However, relying on extrapolation is a shortcut that can lead to catastrophic errors in certain situations (see \figref{fig:target_point_failure_tcp} and \figref{fig:target_point_failure}).}
\label{fig:TP_Recovery_OOD}
\vspace{-0.3cm}
\end{figure*} 
\section{Hidden Biases of End-to-End Driving}
\label{sec:secrets}

We consider the task of urban navigation from point A to B~\cite{Chitta2022PAMI}. The goal is to complete routes with dense traffic, multiple lanes and complex geometries (\eg roundabouts) without incurring infractions. Along the way, the agent encounters manually designed pre-crash traffic scenarios. Each route is a list of GNSS coordinates called target points (TPs) which can be up to 50 m apart (30m on average).

\boldparagraph{Metrics} We use the CARLA online metrics. Route Completion (RC) is the percentage of the route completed. Infraction Score (IS) is a penalty factor starting at 1.0 that gets reduced multiplicatively for every infraction. Our main metric is the Driving Score (DS) which multiplies RC with the IS. Where insightful, we report infraction per kilometer metrics. For a comprehensive description, refer to \cite{Chitta2022PAMI}.

\boldparagraph{Baseline} As a baseline, we reproduce TransFuser~\cite{Chitta2022PAMI}. This is a simple method representative of current SotA driving systems on CARLA. The main differences in our reproduction are a 360\textdegree\ field of view (FOV) LiDAR to enable safe lane changes and a dataset where the expert is driving 2 faster to speed up evaluation. A list of other minor changes is provided in the supplementary material.

\boldparagraph{Benchmark} For all experiments in this section, we train on CARLA towns 01, 03, 04, 06, 07 and 10. We use the 16 validation routes from LAV~\cite{Chen2022CVPRa} in the withheld towns 02 and 05 for evaluation. In order to reduce the influence of training and evaluation variance which can be large in CARLA~\cite{Behl2020IROS, Chitta2022PAMI}, every experiment reports the average of 3 training seeds, evaluated 3 times each. We additionally report the training standard deviation for the main metrics.

\subsection{A shortcut for recovery}
\label{sec:tp_shortcut}
While current SotA CARLA methods have fundamentally different architectures~\cite{Chitta2022PAMI, Shao2022CORL, Wu2022NeurIPS, Chen2022CVPRa}, they are all trained with conditional IL using fixed pre-recorded datasets. The evaluation task involves challenging routes which are 1.5km long, so it would be expected that these methods suffer from \textit{compounding errors}, a well-known problem for IL~\cite{Ross2011AISTATS}. Geometric shift augmentations~\cite{Bojarski2016ARXIV} are a common approach to teach IL methods how to recover from such compounding steering errors~\cite{Bojarski2016ARXIV,Codevilla2019ICCV}. Surprisingly, even though such augmentations are not employed by SotA methods on CARLA, they report high RCs, demonstrating that they are not prone to this expected failure mode.

All the aforementioned methods condition their predictions using the next target point (TP) along the route. To understand the importance of the TP, we train 2 versions of our reproduction of TransFuser: one with the original TP conditioning and another with a discrete (NC) condition. This is a one hot vector that indicates whether the car should follow the lane, turn right at the next intersection, etc. It contains no geometric information about the center of the lanes, but still removes the inherent task ambiguity of inner-city driving~\cite{Codevilla2018ICRA}. For the NC conditioned model, we also implement shift and rotation augmentations by collecting augmented frames during data collection. We deploy a second camera in the simulator, that changes its position and orientation randomly at every time-step. The output labels are transformed accordingly for training the model (implementation details and examples can be found in the supplementary material). The results are shown in \tabref{tab:discrete_command}. 

\begin{table}[h]
\small
\centering
    \begin{tabular}{l | c | c c | c }
        \toprule
        \textbf{Cond.} & \textbf{Aug.} & \textbf{DS}  & \textbf{RC}  & \textbf{Dev}  \\
        \midrule
        NC & {-} & {32} \pmsd {8} & 56 \pmsd {12} & {0.86} \\
        NC & {} & {35} \pmsd {3} & 54 \pmsd {4} & {0.99} \\
        TP & {-} & \textbf{39} \pmsd {9} & \textbf{84} \pmsd {7} & \textbf{0.00}\\
        \bottomrule
    \end{tabular}
    \caption{\textbf{Conditioning and Augmentation.}}
    \label{tab:discrete_command}
    \vspace{-0.3cm}
\end{table} 
\begin{figure*}
\centering
    \begin{subfigure}[b]{0.33\textwidth}
        \centering
        \includegraphics[width=\textwidth]{gfx/TCP_harmful_TP_extrapolation.png}
        \caption{TCP~\cite{Wu2022NeurIPS} follows a shortcut.}
        \label{fig:target_point_failure_tcp}
    \end{subfigure}
    \begin{subfigure}[b]{0.33\textwidth}
        \centering
        \includegraphics[width=\textwidth]{gfx/Harmful_TP_extrapolation.png}
        \caption{TransFuser follows a shortcut.}
        \label{fig:target_point_failure}
    \end{subfigure}
    \begin{subfigure}[b]{0.33\textwidth}  
        \centering 
        \includegraphics[width=\textwidth]{gfx/TF_decoder_not_overfitting.png}
        \caption{A transformer decoder fixes this.}
        \label{fig:target_point_success_2}
    \end{subfigure}
    \vspace{-0.7cm}
   \caption{\textbf{Target point shortcut.} When TP conditioned methods extrapolate to spatially distant waypoints, they incur large steering errors. Replacing global average pooling in TransFuser with a cross-attention mechanism mitigates the issue.}
\label{fig:target_point}
\vspace{-0.3cm}
\end{figure*} 
We observe a significant difference in RC of 28 points when switching between TP and NC conditioning. The TP conditioned model has 0 route deviations per km (``Dev"), which indicates that it never takes a wrong turn or drives too far away (more than 30m) from the lane. However, this is not the case for NC conditioned models. While we do see a small improvement in DS with augmentation, its RC is still unsatisfactory. This indicates that the geometric information regarding the lane center available with the TP aids recovery in SotA IL methods, prompting further investigation. We inspect the TransFuser and LAV~\cite{Chen2022CVPRa} models by constructing situations where the car is forcefully steered out of lane. \figref{fig:TP_Recovery_OOD} visualizes these scenarios with the camera, LiDAR and ground truth HD maps. For TP conditioned models, the predicted waypoints (shown in blue) extrapolate towards the nearest TP (red) even though the situation is out of distribution. This shows that one reason for their strong route following is that the bird's eye view (BEV) TP resets steering errors periodically: methods learn to steer towards nearby TPs because the expert trajectory in the dataset always goes through them. This has the effect that TP conditioned methods periodically drive back to the center of the lane, resetting any accumulated errors. Furthermore, it suggests that SotA IL approaches strongly rely on pre-specified geometric information regarding lane centers for recovery.

We identify this as a form of shortcut learning, which can be useful when the car is close to a target point, but can also lead to catastrophic steering errors when the target point is further away. An example would be directly extrapolating to a target point behind a turn, which leads to cutting the turn. In \figref{fig:target_point_failure_tcp} and \figref{fig:target_point_failure}, we show instances where this happens for TCP~\cite{Wu2022NeurIPS} and TransFuser~\cite{Chitta2022PAMI} in a validation town at nighttime. TransFuser also predicts the BEV segmentation as an auxiliary task, which we overlay in the figure (gray: route, yellow: lane marking). For TCP, we render the ground truth map and omit the LiDAR, since it does not use LiDAR and does not predict BEV segmentation. Both methods predict waypoints that are tilted towards the TP instead of following the street. As a result, they drive into the opposing lane. We refer to this as the \textit{TP shortcut}.

\begin{figure}[t]
\begin{center}
   \includegraphics[width=\linewidth]{gfx/pooling.pdf}
\end{center}
\vspace{-0.3cm}
\caption{\textbf{Pooling.} Existing approaches vectorize feature grids either by global average pooling (top, \eg~\cite{Chitta2022PAMI,Chen2022CVPRa}) or with attention mechanisms (bottom, \eg~\cite{Shao2022CORL,Wu2022NeurIPS}). The latter retains spatial information gained via auxiliary tasks.}
\label{fig:pooling}
\vspace{-0.3cm}
\end{figure} 
\subsection{Improved pooling and data augmentation}
\label{sec:mitigating_tp}

One design choice which differs across SotA architectures is the pooling applied between the encoder and decoder. In \figref{fig:pooling}, we summarize these. In particular, TransFuser~\cite{Chitta2022PAMI} and LAV~\cite{Chen2022CVPRa} employ global average pooling (GAP) followed by an MLP. InterFuser~\cite{Shao2022CORL} pools features via the cross-attention mechanism of a transformer decoder. Finally, TCP~\cite{Wu2022NeurIPS}, which has two decoders, uses GAP for one decoder and attention-based pooling for the other.

As shown in \figref{fig:pooling}, the networks are encouraged to learn spatially meaningful feature grids through auxiliary convolutional decoders that predict outputs such as BEV semantic segmentation. However, GAP does not maintain the spatial information in the features. \figref{fig:target_point_failure} shows the BEV road segmentation predicted by TransFuser overlaid by its LiDAR input. Unlike the waypoints, the BEV predictions are quite accurate. This indicates strong features coming from the encoder. Nevertheless, the final conditional waypoint predictions focus on the TP signal in this situation. We hypothesize that the GAP operation makes it difficult for the downstream decoder to utilize the strong BEV features. Note that attention-based pooling, such as the transformer decoder of Interfuser, preserves spatial information through the use of positional encodings.

We compare the original TransFuser GAP approach with the spatially preserving design of Interfuser in \tabref{tab:feature_pooling}. For the latter variant, we remove the GAP operation and MLP in TransFuser. We then process the 88 BEV feature grid as tokens with a transformer decoder. Implementation details can be found in the supplementary material. 

\begin{table}[h]
\small
\centering
    \begin{tabular}{l | c | c c | c}
        \toprule
        \textbf{Pooling} & \textbf{Aug.} & \textbf{DS}  & \textbf{RC}  & \textbf{Stat}  \\
        \midrule
        GAP + MLP & - & {39} \pmsd {9} & {84} \pmsd {7} & {1.04}\\
        Transformer Decoder & -  & {43} \pmsd {6} & \textbf{93} \pmsd {3} & {0.55} \\
        Transformer Decoder &  & \textbf{49} \pmsd {8} & {90} \pmsd {4} & \textbf{0.10} \\
        \bottomrule
    \end{tabular}
    \caption{\textbf{Pooling and augmentation.}}
    \label{tab:feature_pooling}
    \vspace{-0.3cm}
\end{table} 
After replacing GAP with the transformer decoder, the RC increases by 9 points and collisions per km with static objects (``Stat") reduce by a factor of 2. Static objects (such as poles) only occur outside lanes in CARLA, implying that the network manages to stay in the lane far more consistently. \figref{fig:target_point_success_2} provides qualitative evidence that the transformer decoder can succeed in situations where GAP failed due to the TP shortcut (additional examples in supplementary). In addition, we investigate the inclusion of shift and rotation augmentations designed to aid lateral recovery (as described in \secref{sec:tp_shortcut}). Collisions with the static environment are reduced further by a factor of 5 indicating that augmentation provides strong benefits.

\subsection{The ambiguity of waypoints}
\label{sec:disentanglement}

Waypoints are used in many SotA systems as outputs~\cite{Chen2022CVPRa, Wu2022NeurIPS, Chitta2022PAMI}. They are obtained by recording an expert driver's GNSS locations at fixed time intervals (\eg 0.5s) and transforming them into a local coordinate frame. The model is then trained to predict future waypoints, typically with an  regression objective. Waypoints entangle both the path and the future velocities of the vehicle. The velocity after a specific time interval extracted from the waypoints is used by a downstream controller as a target speed. 

In \figref{fig:histogram}, we plot a histogram comparing the target speeds of the expert algorithm (\ie training dataset) to those extracted from TransFuser (best model in \tabref{tab:feature_pooling}). Interestingly, the distributions are quite different. By design, the expert chooses one of four target speeds: 29, 18, 7, or 0 km/h. These values cover behaviors needed for city driving, corresponding to four situations: regular driving, slowing down in intersections, slowing down near pedestrians, and stopping. In contrast, for TransFuser, the predicted target speeds cover the entire 0-29 km/h range.

While the future path that our expert follows is deterministic and unambiguous (center of the lane, lane change at pre-defined locations), future velocities are multi-modal. As both are jointly represented by waypoints, this leads to an ambiguous entangled representation. However, existing methods which utilize this entangled waypoint representation predict only point estimates (\ie, a single set of waypoints) as output, hence only a single mode is modeled. From \figref{fig:histogram}, we observe that the waypoint based TransFuser model indeed interpolates between modes, a behavior that is expected when modeling multi-modal outputs deterministically. We illustrate this behavior in detail using the examples of (1) approaching an intersection with a green light (\figref{fig:conservative_mode}), and (2) a cyclist cutting into the vehicle's path (\figref{fig:aggressive_mode}). TransFuser slows down in these situations since it is uncertain, \eg, the light may turn red in \figref{fig:conservative_mode}. The car stops in time in \figref{fig:aggressive_mode} because of the decreased speed.

\begin{figure}[t]
\vspace{-0.7cm}
\begin{center}
   \includegraphics[width=\linewidth]{gfx/target_speed_histogram.png}
\end{center}
\vspace{-0.5cm}
\caption{\textbf{Transfuser interpolates between modes.}}
\label{fig:histogram}
\vspace{-0.5cm}
\end{figure} 
\begin{figure*}[t]
\centering
    \begin{subfigure}[b]{0.33\textwidth}
        \centering
        \includegraphics[width=\textwidth]{gfx/anticipate_red_light.pdf}
        \caption{Slowing down at a green light.}
        \label{fig:conservative_mode}
    \end{subfigure}
    \begin{subfigure}[b]{0.33\textwidth}  
        \centering 
        \includegraphics[width=\textwidth]{gfx/WP_interpolation_route_26_1557.pdf}
        \caption{Slowing down in an intersection.}
        \label{fig:aggressive_mode}
    \end{subfigure}
    \begin{subfigure}[b]{0.33\textwidth}  
        \centering 
        \includegraphics[width=\textwidth]{gfx/interpolation_for_merging.pdf}
        \caption{Disentangling route and target speed.}
        \label{fig:interpolating_modes}
    \end{subfigure}
    \vspace{-0.7cm}
   \caption{\textbf{Waypoints are ambiguous.} The model's output representation forces it to predict a single mode for future velocities. There is a possibility that the traffic light might turn red in the future, or that the cyclist either cuts in or yields to the agent. The particular mode (or interpolation thereof) that the model converges to, depends on the training run and dataset.}
\label{fig:waypoint_problem}
\vspace{-0.3cm}
\end{figure*}  
While this averaging is indeed beneficial in some situations, an entangled representation is undesirable as it is less interpretable and does not explicitly expose uncertainty. Moreover, when stopped (all waypoints collapsed to one location), the steering signal is undefined which requires additional heuristics in the controller. To resolve this, we disentangle the future velocities from the path by sampling the expert's position at fixed distances instead of fixed time intervals for training a (deterministic) \textit{path predictor}. However, when predicting the path instead of time-dependent trajectories, one requires an additional method to determine a target speed for the car. We propose to predict the target speed by simple classification using an additional MLP head. We incorporate the prediction uncertainties into the final output by using a confidence weighted average of the predicted target speed as input to the controller. Note that this is just one example of how the resulting confidence estimates may be leveraged by a vehicle controller.

\begin{table}[h]
\small
\centering
    \begin{tabular}{l | c c | c c}
        \toprule
        \textbf{Output} & \textbf{DS}  & \textbf{RC}  & \textbf{Veh}  & \textbf{Stat}  \\
        \midrule
        Waypoints & {49} \pmsd {8} & \textbf{90} \pmsd {4} & \textbf{0.70} & {0.10} \\
        Path + Argmax &  {40} \pmsd {1} & {88} \pmsd {2} & {1.25} & {0.03} \\
        Path + Weighted &  \textbf{50} \pmsd {3} & {88} \pmsd {1} & {0.83} & \textbf{0.02} \\
        \bottomrule
    \end{tabular}
    \caption{\textbf{Output representation.}}
    \label{tab:disentanglement}
    \vspace{-0.5cm}
\end{table} 
Compared to the waypoint representation, naively converting the predicted classes to a target speed via the most likely class (Argmax) increases vehicle collisions (``Veh"), as seen in \tabref{tab:disentanglement}. Employing the proposed weighting (Weighted) achieves lower collisions. Moreover, the path-based model steers better as indicated by the lower static obstacle collisions (``Stat"). The disentangled representation achieves the same driving score as the entangled waypoint representation, providing an alternative with a simpler and more interpretable controller: (1) it eases design since it has identical parameters to the controller in the expert, (2) it has access to an unambiguous path representation even when driving slowly, and (3) it explicitly exposes and makes use of uncertainties with regard to target speeds.

\figref{fig:interpolating_modes} shows a qualitative example. The car is slowing down due to its uncertainty. The lower target speed allows it successfully merge behind the cyclist.

\begin{figure}[t]
\begin{center}
   \includegraphics[width=\linewidth]{gfx/full_arch_iccv.pdf}
\end{center}
\vspace{-0.3cm}
\caption{\textbf{TransFuser++ architecture.}}
\label{fig:architecture}
\vspace{-0.1cm}
\end{figure} 
\subsection{Scaling up to TransFuser++}

By incorporating these insights, we obtain a significantly improved version of TransFuser~\cite{Chitta2022PAMI} that we call TransFuser++ (\figref{fig:architecture}). We now describe two important implementation changes compared to~\cite{Chitta2022PAMI} that involve scaling.

\begin{table}[ht]
\small
\centering
    \begin{tabular}{c | c | c c | c }
        \toprule
        \textbf{Two stage} & \textbf{Frozen} & \textbf{DS}  & \textbf{RC}  & \textbf{Veh}   \\
        \midrule
        {-} & {-} & {50} \pmsd {3} & {88} \pmsd {1} & {0.83}\\
         & {-} & \textbf{54} \pmsd {1} & {92} \pmsd {5} & \textbf{0.79}\\
         &  &  {44} \pmsd {6} & \textbf{97} \pmsd {1} & {1.21}\\
        \bottomrule
    \end{tabular}
    \caption{\textbf{Two stage training.}}
    \label{tab:two_stage}
    \vspace{-0.5cm}
\end{table} 
\boldparagraph{Training schedule} We observe no benefits from simply doubling the number of training epochs for a single training stage. However, in \tabref{tab:two_stage}, we double the training time with a two-stage approach. First, we pre-train the encoder with only the perception losses (2D depth, 2D and BEV semantic segmentation, and vehicle bounding boxes, as shown in \figref{fig:architecture}) for the usual number of epochs. We then fine-tune the resulting checkpoint with all losses, after including the GRU decoder and MLP classifier. Initializing the backbone with features that are pre-trained on the auxiliary tasks leads to a 4 DS improvement, consistent with the claims of LAV~\cite{Chen2022CVPRa}. We also experiment with freezing the pre-trained backbone and only training the transformer decoder and its heads in the second stage. This leads to a drop of 10 DS, indicating that end-to-end optimization is important.

\boldparagraph{Dataset scale} Recent work on CARLA~\cite{Renz2022CORL} shows large improvements by scaling the dataset size. However, \cite{Renz2022CORL} considers planning models with privileged inputs on training towns. We investigate the impact of scaling when evaluating on held-out validation towns for end-to-end models. We start with 185k  training samples (as in~\cite{Chitta2022PAMI}) and scale it up by re-running the training routes 3 times with different traffic (555k frames). \tabref{tab:scaling} shows a clear improvement of 6 DS via scaling. This shows that current IL approaches can still benefit from larger datasets. We train for the same amount of epochs, which implies that this improvement comes at the cost of 3 longer training.

\begin{table}[h]
\small
\centering
    \begin{tabular}{c | c c | c}
        \toprule
        \textbf{Dataset size} & \textbf{DS}  & \textbf{RC}  & \textbf{Veh}  \\
        \midrule
        185k  & {54} \pmsd {1} & {92} \pmsd {5} & {0.79}\\
        555k &  \textbf{60} \pmsd {6} & \textbf{98} \pmsd {1} & \textbf{0.73} \\
        \bottomrule
    \end{tabular}
    \caption{\textbf{Effects of scale.}}
    \label{tab:scaling}
    \vspace{-0.4cm}
\end{table} 