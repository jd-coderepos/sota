


\documentclass{article}
\usepackage{amsthm}
\usepackage{graphicx,pstricks}
\usepackage{moreverb}
\usepackage{epsfig}
\usepackage{setspace}
\usepackage{fullpage}
\usepackage{enumerate}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{graphicx}
\usepackage{amsmath}
\usepackage{array}
\usepackage{url}

\newcommand{\F}[0]{\mathcal{F}}
\newcommand{\C}[0]{\mathcal{C}}
\newcommand{\Fin}[0]{\mathcal{F}_\text{in}}
\newcommand{\Cin}[0]{\mathcal{C}_\text{in}}
\newcommand{\Vin}[0]{V_\text{in}}
\newcommand{\G}[0]{\mathcal{G}}
\newcommand{\Hh}[0]{\mathcal{H}}
\newcommand{\A}[0]{\mathcal{A}}
\newcommand{\V}[0]{\mathcal{V}}
\newcommand{\K}[0]{\mathbb{K}}
\newcommand{\R}[0]{\mathbb{R}}
\newcommand{\bs}[0]{\backslash}
\newcommand{\ep}[0]{\epsilon}
\newcommand{\mytie}{\mathrel{\rhd\mspace{-10mu}\lhd}}

\newtheorem{thm}{Theorem}
\newtheorem{lem}[thm]{Lemma}
\newtheorem{prop}[thm]{Proposition}
\newtheorem{cor}[thm]{Corollary}
\newtheorem{conj}[thm]{Conjecture}
\newtheorem{defn}[thm]{Definition}

\begin{document}








\title{\textbf{On the robust hardness of \\
Gr\"{o}bner basis computation}}







\author{
\textbf{David Rolnick}\\
       Massachusetts Institute~of Technology\\
       Cambridge, MA\\
       \url{drolnick@mit.edu}\\
\and
\textbf{Gwen Spencer}\\
       Smith College\\
       Northampton, MA\\
       \url{gwenspencer@gmail.com}
}
\date{}

\maketitle
\begin{abstract}
The computation of Gr\"obner bases is an established hard problem. By contrast with many other problems, however, there has been little investigation of whether this hardness is robust.  In this paper, we frame and present results on the problem of approximate computation of Gr\"obner bases. We show that it is NP-hard to construct a Gr\"obner basis of the ideal generated by a set of polynomials, even when the algorithm is allowed to discard a  fraction of the generators, and likewise when the algorithm is allowed to discard variables (and the generators containing them). Our results shows that computation of Gr\"obner bases is robustly hard even for simple polynomial systems (e.g.~maximum degree 2, with at most 3 variables per generator). We conclude by greatly strengthening results for the Strong \nobreakdash-Partial Gr\"obner problem posed by De Loera et al.~\cite{deloera}. Our proofs also establish interesting connections between the robust hardness of Gr\"obner bases and that of SAT variants and graph-coloring.
\end{abstract}









\noindent\textbf{Keywords:} Gr\"{o}bner Basis, Polynomial System, Complexity, Approximation, Hardness, Combinatorial Optimization, Satisfiability\\

\section{Introduction}
A classic problem in computational algebra is producing a Gr\"{o}bner basis for an ideal. Given a field  and a system of polynomials , let  denote the ideal generated by the polynomials of . For a given term order, a \emph{Gr\"{o}bner basis} for the ideal  is a set of generators for which the leading terms generate the ideal of leading terms in .

Given a Gr\"{o}bner basis for an ideal, important problems such as ideal membership can easily be resolved; for more background, see Cox, Little, and O'Shea \cite{cox}.
The existence of a polynomial-time algorithm for computing Gr\"{o}bner bases is precluded by a number of hardness results. For general , the problem is EXPSPACE-complete \cite{kuehnle, mayr:survey}. The maximum degree of polynomials in a Gr\"{o}bner basis can also grow exponentially, even for zero-dimensional ideals \cite{giusti,mayr,moller,ritscher}.

Despite strong hardness results for the general problem of computing a Gr\"{o}bner basis, there is hope for efficient methods for restricted classes of polynomial systems. De Loera et al.~\cite{deloera} give a polynomial-time algorithm for Gr\"{o}bner basis computation in the case where  encodes the problem of properly coloring a chordal graph. Recent work of Cifuentes and Parrilo \cite{parrilo} in computational algebraic geometry has begun to unearth rich connections between restrictions on the graphical representation of the structure of a system of polynomials and efficient algorithmic methods for Gr\"{o}bner basis computation. For a related problem about computing Nullstellensatz certificates, Faug\^ere et al.~\cite{Faugere} have shown that for certain quadratic \textit{fewnomial} systems with empty varieties, imposing an extra inequality constraining the matching number of a graphical representation of the system allows polynomial-time computation of a certificate of inconsistency (and furthermore, such a certificate has linear size, while in the general case the best size bounds are exponential).

Where is the boundary between polynomial systems for which the highly-useful tool of a Gr\"{o}bner basis can be efficiently produced for , and those systems for which this is impossible? Can weaker restrictions on  than those studied in \cite{parrilo} and \cite{deloera} still guarantee existence of an efficient method for Gr\"{o}bner basis computation? Conversely, can even  with quite simple representations generate ideals whose Gr\"{o}bner bases  evade efficient computation?

Instead of asking how much time and space are required to solve a problem exactly, we can ask whether the problem can be solved approximately in limited time and space.  That is, is the problem is ``robustly hard,'' resisting even approximate solution? In combinatorial optimization, the hardness of obtaining approximate solutions has been studied extensively for problems such as Graph Coloring, Traveling Salesman, Satisfiability, Maximum Cut, and Steiner Tree. For Gr\"{o}bner basis computation, however, much study has been devoted to exact hardness, but apparently little attention has been devoted to robust hardness.

Given a polynomial system  for which we would like to compute a Gr\"{o}bner basis for  , what does it mean to give an approximate answer? One natural answer is to allow  itself to be approximated. In this paper, we show that even selectively throwing out a constant fraction of the generators does not allow us to compute a Gr\"{o}bner basis for the ideal corresponding to the remaining generators in polynomial time.


In the following definitions, we assume that we are given as input:  a set of polynomials  within the ring  and a value . We let  denote the set of all variables in our polynomial ring.
\begin{defn}[\textbf{\nobreakdash-Fractional Gr\"obner problem}]
\label{def:fractional}
Given the input above, output:
\begin{itemize}
\item A subset  such that .
\item A Gr\"{o}bner basis for the ideal  with respect to some lexicographic order.
\end{itemize}
\end{defn}

\begin{defn}[\textbf{Restricted \nobreakdash-Fractional Gr\"{o}bner problem}]
\label{def:restricted}
Given the input above, output:
\begin{itemize}
\item Subsets  and  such that (i) , and (ii)  is exactly those elements of  containing only variables within .
\item A Gr\"{o}bner basis for the ideal  with respect to some lexicographic order.
\end{itemize}
\end{defn}

\noindent Note that for , both problems reduce to finding a Gr\"{o}bner basis for  itself.

In Section \ref{sec:fractional}, we prove that the \nobreakdash-Fractional Gr\"obner problem is NP-hard for every  if we are working over an infinite field.  Moreover, this statement for an infinite field holds true even when ``polynomial-time'' is considered to include a dependence on the size of the Gr\"obner basis to be outputted. This is notable since in general the time to write down a Gr\"obner basis explicitly can be doubly exponential in the size of the description of the ideal.  We also show that the \nobreakdash-Fractional Gr\"{o}bner problem is NP-hard over any field for .  Both these results hold even for polynomials with maximum degree 3.



\begin{thm}\label{thm:main1}
For infinite fields , the \nobreakdash-Fractional Gr\"obner problem is NP-hard for every fixed . This still holds true even if we require only an algorithm that runs in time polynomial in the larger of\\
\hspace*{4mm}(i) The size of input polynomial system ,\\
\hspace*{4mm}(ii) The size of the Gr\"{o}bner basis output for . \\ 
Further, in this particular theorem the condition of a lexicographic order may be omitted. Also, this statement holds true (regardless of term order) even when each polynomial from   has maximum degree 3.  \end{thm}

\begin{thm}\label{thm:main2}
The \nobreakdash-Fractional Gr\"obner problem is NP-hard for any  (for any field ). This statement holds true even if each element of  contains at most 3 variables and even when  has maximum degree 3.
\end{thm}



In Section \ref{sec:restricted} we show that the Restricted \nobreakdash-Fractional Gr\"obner problem is NP-hard for every , assuming the field does not have characteristic 2. This result holds even if polynomials are constrained to have at most 3 variables and degree at most 3. A similar result holds for  for any field and with polynomials constrained to have degree at most 2.



\begin{thm}
\label{extfrachard}
Assuming , the Restricted \nobreakdash-Fractional Gr\"{o}bner Basis Problem is NP-Hard for any . This statement holds true even when each polynomial from  contains at most 3 variables, and even when  has maximum degree 3.
\end{thm}



\begin{thm}
\label{extfracharddeg2}
The Restricted \nobreakdash-Fractional Gr\"{o}bner Basis Problem is NP-Hard for any  (and for any field ). This statement holds true even when each polynomial from  contains at most 3 variables, and even when  has maximum degree 2.
\end{thm}

Finally, in Section \ref{sec:partial} we recall the notions of approximate hardness posed in De Loera, et al.~\cite{deloera}.  The authors define the \textit{Weak \nobreakdash-Partial Gr\"obner} problem, in which the algorithm may ignore any  variables (and all generators containing them), and the \textit{Strong \nobreakdash-Partial Gr\"{o}bner} problem in which the algorithm may ignore  independent sets of variables, where an \emph{independent set} of variables is a set such that no pair co-occur in any generator.

\begin{defn}
Given a set  of polynomials on a set  of variables, we say that  is an \emph{independent set}  of variables if no two variables from  appear in a single element of .
\end{defn}

\begin{defn}[\textbf{Strong \nobreakdash-Partial Gr\"{o}bner problem} - De Loera et al.~\cite{deloera}]
Given as input, a set  of polynomials on a set  of variables and a parameter , output the following:
\begin{itemize}
\item disjoint , such that  and each  is an independent set of variables,
\item a Gr\"{o}bner basis for  over  (i.e., we have taken away at most  independent sets of variables), where the monomial order of  is restricted to a monomial order on .
\end{itemize}
\end{defn}


De Loera et al.~\cite{deloera} showed that for any system of polynomials subject to degree bound , the Strong \nobreakdash-Partial Gr\"{o}bner problem is NP-hard. That is, even giving an algorithm the freedom to choose to ignore  independent sets of variables (and all of the polynomials in which they appear) doesn't necessarily yield a polynomial system with an ideal for which Gr\"{o}bner basis computation is possible in polynomial time.










We show that a rather stronger statement may be proved with a simpler (though less interesting) construction, in which we follow the proof of De Loera et al.~\cite{deloera} showing NP-hardness for the Weak \nobreakdash-Partial Gr\"obner problem. Further, while the result in ~\cite{deloera} required a lexicographic term order, the following result holds true for any polynomial term order.

\begin{thm} 
The Strong \nobreakdash-Partial Gr\"obner problem is NP-hard for every , even for polynomials of degree 3.  This still holds true even if we require only an algorithm that runs in time polynomial in the \emph{size of the Gr\"{o}bner basis} it outputs.
\label{thm:stronger}
\end{thm}

The reduction used to prove this result is perhaps not as instructive as that in De Loera et al.~\cite{deloera}. We therefore also provide an adaptation of the original method. Our statement below gives a stronger parameter for  than in De Loera et al.~and furthermore does not require lexicographic order.

\begin{thm}\label{prop:lundgroebner}
For every constant , there is a constant  such that the following problem is NP-hard: Given a polynomial system of maximum degree , solve the Strong \nobreakdash-Partial Gr\"{o}bner problem for some term order. This still holds true even if each generator in  contains at most 2 variables.
\end{thm}

The more interesting construction which proves Theorem \ref{prop:lundgroebner} can be adapted in a straightforward way to cast results very much like Theorem 9 as consequences of recent (unresolved) conjectures related to the Unique Games Conjecture \cite{Khot02}.

Our theorems apply even for polynomial systems that belong to a highly restricted classes.  In the case of Theorem \ref{thm:main2}, none of the generators contains more than 3 variables, and all coefficients come from the set . Qualitatively, our robust hardness results hold true even for very simple . In fact, we can even gain another significant restriction on  without compromising our robust hardness result.

\begin{thm}[Extension of Theorem \ref{thm:main2}] \label{thm:main3}
The \nobreakdash-Fractional Gr\"{o}bner problem is NP-hard for every , even when the input contains only polynomials of the form  or .
\end{thm}



\noindent\textbf{A remark on graphical representations of  and .}
Graphical representations of polynomial systems have been previously studied in connection with efficient Gr\"obner basis computation  (see \cite{parrilo} and \cite{deloera}). 
Given a polynomial system , construct a multigraph  as follows. For each variable  create a node . For each polynomial, , create a clique on the nodes corresponding to variables that appear in .
It has been shown that when  satisfies very special conditions, a Gr\"obner basis for  can be efficiently computed. Could it be that a much wider class of polynomial systems with simple graphical representations generate ideals that admit efficient Gr\"obner basis computation? 

Our results suggest insight in the negative direction. In our Theorems \ref{thm:main1}, \ref{thm:main2}, \ref{extfrachard}, and \ref{extfracharddeg2}, the graphical representation of the input  (prior to discarding any polynomials) is already remarkably simple: each polynomial of  gives rise to a single triangle in . That is,  is the union of a ``small number'' of triangles.
Discarding  produces a subgraph, . For our unrestricted problem (Definition \ref{def:fractional}), our theorems describe the ability to select arbitrary triangles for removal from the graphical representation of . For our restricted problem (Definition \ref{def:restricted}), choosing variables to ignore corresponds to node removals that force the removal of certain triangles from . Qualitatively, our results say that any efficient method for choosing a constant fraction of the triangles to remove from (an already quite simple)  will not guarantee efficient computation of a Gr\"{o}bner basis for the ideal generated by the remaining subsystem with graphical representation .\\












\section{Proofs for the \nobreakdash-Fractional Gr\"obner problem.}
\label{sec:fractional}

Our proofs of Theorems \ref{thm:main1} and \ref{thm:main2} are by reduction from one of the most famous problems in combinatorial optimization, 3SAT. Results are known about the hardness of producing approximate solutions for many variants of this problem, even when the inputs are highly restricted. Such results play a key role in our arguments in this section. Recall the following problem statements:

\begin{defn}
Let  be a Boolean formula over a set of variables .  Suppose that  is in 3\nobreakdash-conjunctive normal form (3\nobreakdash-CNF). In other words,  is the conjunction of a set  of clauses, where each clause is the disjunction of three literals (of the form either  or ).  

\begin{itemize}
\item \textbf{3\nobreakdash-Satisfiability} (3SAT): Determine whether there exists a truth assignment to  satisfying the formula .

\item \textbf{Maximum 3\nobreakdash-Satisfiability} (MAX-3SAT): Output a truth assignment for  that satisfies the maximum fraction of the clauses in .
\end{itemize}
\end{defn}



\begin{proof}[Proof of Theorem \ref{thm:main1}]
We prove the theorem by reduction from 3SAT.  Let  be a 3\nobreakdash-CNF Boolean formula in variables , with clauses . For each , define a polynomial  as the product of three terms chosen as follows: For each positive literal  in , include the term ; and for each negative literal , include the term . Thus, for example, the clause  gives us the function . This gives a set of  polynomials of maximum degree 3.

Observe that truth assignments satisfying  correspond to simultaneous roots of the system , where  corresponds to , and  to . In particular, this means that  is satisfiable if and only if the set  defines a nontrivial variety.

Pick , and pick  distinct elements .  Construct the  matrix:



Observe that any  distinct rows  of  form a Vandermonde matrix , which has determinant .  This determinant is nonzero by our choice of , and hence is  invertible.

Let  denote the vector , and define the polynomials  as the entries of the vector .  For  a subset of , let  denote the  submatrix of  obtained by taking exactly those rows corresponding to elements of , and let  be the ideal generated by .

Suppose that  has cardinality at least . Then, since each  submatrix of  is invertible, the only solution to the vector equality  is when the vector  is identically zero.  By the definition of , then, simultaneous roots of  must correspond to simultaneous roots of .  Thus,  is nontrivial exactly when  defines a nontrivial variety, and hence exactly when  is satisfiable.  To complete the argument, note that  is trivial exactly when its Gr\"obner basis is .

Since this argument holds for every subset  with , we conclude that solving the \nobreakdash-Fractional Gr\"obner Basis Problem for input system  permits a polynomial-time reduction\footnote{Notice that bit-wise representations of entries in  have polynomial size.} for 3SAT and hence is NP-hard.  Moreover, our reduction uses 
degree-3 generators and merely requires us to determine whether some large-enough subset of the generators from  has Gr\"obner basis  (or not). Therefore, if there existed an algorithm  for the \nobreakdash-Fractional Gr\"obner problem that ran in time polynomial in the size of Gr\"obner basis to be outputted, then we could simply run  until the time required for the output .  If  did not terminate by this time or outputted a different Gr\"obner basis, then we would conclude that  has no solution.  This shows that such an algorithm  is possible only if P=NP. 
\end{proof}



We prove Theorem \ref{thm:main2} by reduction from MAX-3SAT, using H{\aa}stad's celebrated hardness-of-approximation result for satisfiable instances \cite{hast01}.  We use the fact that under a lexicographic order, possession of a Gr\"obner basis  will allow efficient computation of a point in the variety of the corresponding polynomial system by iterative elimination of one variable at a time.

\begin{defn}
An algorithm  is called a \emph{\nobreakdash-approximation algorithm} for an optimization problem if  returns a solution whose value is within a -multiplicative factor of the optimal value.
\end{defn}

\begin{thm}[Theorem 6.5 in H{\aa}stad \cite{hast01}] \label{hastad}
Assuming that PNP, and , there is no polynomial-time -approximation algorithm for MAX-3SAT.  This holds even when instances are guaranteed to be satisfiable - that is, when \emph{all} clauses of the Boolean formula can be satisfied.
\end{thm}

\begin{proof}[Proof of Theorem \ref{thm:main2}]
Assume towards contradiction that  is some polynomial-time algorithm that solves the \nobreakdash-Fractional Gr\"obner problem for some .  Let  be a satisfiable 3\nobreakdash-CNF Boolean formula in variables , with clauses . For each , define a polynomial  as in the proof of Theorem \ref{thm:main1}. As above,  is satisfiable if and only if the set  defines a nontrivial variety in the variables . We now run  on . Let  denote the set of generators that  picks from within .  Thus, . The algorithm  must compute a Gr\"{o}bner basis  for the ideal generated by the polynomials in .

We claim that from  we can reconstruct a solution in the variety of .  By the Elimination Theorem (Theorem 2 in \S3.1 of \cite{cox}), the set  is a Gr\"obner basis for . Given , let  be the element of  formed by projecting . By the Closure Theorem (Theorem 3 in \S3.2 of \cite{cox}), the variety of solutions to  is the smallest affine variety containing  for every . Note that by our construction of , the variety  is the union of a finite number of sets , where each  is the product of sets of the form  or  or the entire completion of .  This is because, if we fix all the variables but one, the remaining variable is either constrained to  or  or is completely unconstrained.

Hence, every projection of  is itself an affine variety; thus, every solution to  extends to a solution to . Therefore, in order to reconstruct a solution , we can iteratively extend a partial solution in . Specifically, we pick some value of  that solves , given that we have already picked values for .

This solution  is a vector of length  which is a mutual zero of all polynomials in . Each entry in the vector corresponds to some variable in our original MAX\nobreakdash-3SAT instance: if , we assign the corresponding variable  to be true. If , we assign  to be false. For values of  other than  or  an arbitrary assignment is made for . By construction, the fact that  causes every polynomial in  to evaluate to 0 means that every corresponding clause evaluates as true under the truth assignment constructed so far, so that the number of true clauses is at least .

Thus, our constructed truth assignment is guaranteed to satisfy more clauses than Theorem \ref{hastad} permits.  Moreover, our reduction uses generators that have maximum degree 3 and contain at most 3 variables per generator (so that  is relatively sparse).  Since the reduction we have described is clearly polynomial-time (assuming that  is itself polynomial-time), we obtain a contradiction and conclude that the \nobreakdash-Fractional Gr\"obner problem is NP-hard, as desired. 
\end{proof}



\noindent\textbf{An extension for very simple : Theorem \ref{thm:main3}}. 
We can, in fact, gain a significant additional restriction on  (without losing anything in our robust hardness result) by using a more recent inapproximability result of Guraswami and Khot \cite{guruswamikhot} for a specialized variant of MAX\nobreakdash-3SAT known as ``Max Non-Mixed Exactly 3SAT." In this variant, each clause must contain exactly 3 literals, and each clause either has all three literals in positive form or all three literals in negated form (there is ``no mixing" of positive-form and negated-form literals within clauses). Guraswami and Khot match H{\aa}stad's result for the general case: even this specialized variant is NP-hard to approximate within multiplicative factor better than , and this is true even for instances guaranteed to be satisfiable. Our reduction works in the same way as before, but the polynomial system constructed from the arbitrary Max Non-Mixed Exactly 3SAT instance has an even simpler form. Thus, for , the \nobreakdash-Fractional Gr\"{o}bner problem is NP-hard even for this more restricted class of polynomial systems.

Further,  shifting to the Restricted \nobreakdash-Fractional Gr\"{o}bner Model, even for the simple clause form in Theorem \ref{thm:main3}, the result can be improved to . Since this parameter is weaker than our parameter in Theorem \ref{extfrachard}, we omit an explicit proof. 

\section{Proofs for the Restricted \nobreakdash-Fractional Gr\"{o}bner problem}
\label{sec:restricted}

Compared with the \nobreakdash-Fractional Gr\"{o}bner problem, our definiton of the  Restricted \nobreakdash-Fractional Gr\"{o}bner problem  imposes additional structure on the set of generators that the algorithm can ignore from . In this section, we give proofs of Theorems 5 and 6 that exploit this additional constraint on structure to give reductions from other logical satisfiability problems (where the hardness of approximation bounds are lower than for MAX-3SAT). 
Reductions in this section will be more involved because the form of the polynomials that encode \textit{Not-2} and \textit{OXR} clauses don't naturally force the variety of the constructed polynomial system to be contained in  (as we had for disjunctions in Section \ref{sec:fractional}). 





For a polynomial system  and subset of variables , let  denote the subset of polynomials from  which contain at least one variable from .
Referring to Definition \ref{def:restricted}, we write   to correspond to a set of variables chosen by the algorithm to be ignored. The set of polynomials containing at least one variable from , denoted by , is ignored, and the algorithm need only compute a Gr\"{o}bner basis for the remaining set of polynomials  (the set of polynomials that each contain only \textit{retained variables} from ). 




We prove Theorem \ref{extfrachard} by reducing from the \textit{Max-Not-2 Problem for satisfiable instances of arity 3}. The input to the Max-Not-2 Problem is a set of logical predicates  over a set of literals . Specifying \textit{arity 3} means that each predicate contains at most 3 signed literals (a ``signed literal" is a literal in either negated or positive form), e.g.  where . For a truth assignment to the literals, a predicate is ``satisfied" if the number of its signed literals that are true is not exactly 2. If exactly 2 of its signed literals are true, then the predicate is not satisfied.\footnote{For example, the predicate  is satisfied by a truth assignment where  is true,  is true, and  is false (all three of the signed literals in the predicate are true for this truth assignment). On the other hand, consider a truth assignment in which  is true,  is true, and  is true: for this truth assignment exactly 2 of the signed literals in the predicate are true, so the predicate is not satisfied.} The objective is to compute a truth assignment that satisfies the highest possible fraction of predicates in . When we study the problem \textit{for satisfiable instances} we are guaranteed that some truth assignment for  satisfies every predicate in .

H{\aa}stad recently showed that fair coin-flipping gives a tight approximation guarantee for this problem:
\begin{thm}[H{\aa}stad \cite{hast14}]\label{hastadnot2}
For any , given a satisfiable instance of Max-Not-2 of arity 3, there is no polynomial-time algorithm to find a truth assignment that satisfies a -fraction of the predicates (unless ). 
\end{thm}
\vspace{-1mm}

Before the proof of Theorem \ref{extfrachard}, we recall the key fact our reduction will invoke from computational algebra. Given a Gr\"{o}bner basis for   with respect to a lexicographic order, if the variety of   (the set of mutual roots of all polynomials in ) is finite, then a point in the variety of  (a mutual root of all polynomials in ) can be computed efficiently by iteratively eliminating the variables one at a time. These classic results in elimination theory are covered in the textbook of Cox, Little and O'Shea \cite{cox}.


\vspace{2mm}
\begin{proof}[Proof of Theorem \ref{extfrachard}] Assume, for  contradiction, that the  asserted in Theorem \ref{extfrachard} does exist with . Define  so that . Given an arbitrary satisfiable input  of the \textit{Max-Not-2 Problem of arity 3} we compute a truth assignment of forbidden quality in polynomial time as follows. Our assignment will be determined over the course of three stages: instance preprocessing, polynomial encoding, and supplemental random assignment.

\vspace{2mm}

\noindent \textbf{Stage 1. Instance Preprocessing.} The form of a Not-2 predicate sometimes unequivocally dictates a literal's truth value in all satisfying assignments. For example,  must have  false in every satisfying assignment. Further, if some literal appears in only one Not-2 predicate, then manipulating that literal's truth value can always satisfy the predicate (regardless of the truth values of all other literals).  

In Appendix 1, we use simple arguments like these to prove that an arbitrary satisfiable \textit{Max-Not-2} instance may be preprocessed (fixing some literals to be true/false and removing some predicates) so that
WLOG the remaining instance is still satisfiable, an -approximate truth assignment for the updated instance is at minimum -approximate for the original Max-Not-2 instance, and the following two convenient properties hold:

\vspace{1mm}

\noindent \textbf{Property 1.} \textit{Any predicate  that has multiple occurrences of the same literal must have a very specific form: either  contains two identical signed literals and a third signed literal corresponding to a different index, or   contains two identical signed literals and a third literal whose truth value has been permanently fixed to either false or true.}
\vspace{1mm}


\noindent \textbf{Property 2.} \textit{After the updates in Stage 1, Every literal  appears in some form (either negated or positive) in at least two predicates from .}

\vspace{1mm}

\noindent 
Thus, to obtain a contradiction, it is sufficient to show that for a preprocessed satisfiable Max-Not-2 instance (where Properties 1 and 2 hold)  we can satisfy a  fraction of the predicates. First, we derive an immediate consequence of Property 2 that will be used in Stage 2. Later, in Stage 3, we will use Property 1 to analyze a final stage of supplemental random truth assignment. 
\begin{lem} \label{twofifths} An instance of \textit{Max-Not-2} of arity  over literals  and predicates  for which each literal appears in at least 2 predicates has .
\end{lem}


\begin{proof}[Proof of Lemma] Since there are  literals, and each appears at least twice (from Property 2), then there must be at least  appearances of literals. Each predicate contains at most 3 appearances of literals, so at minimum there are  predicates in :
\vspace{-4mm}

\end{proof}

\noindent \textbf{Stage 2. Polynomial Encoding and Gr\"{o}bner-based partial assignment.} 
First we take a convenient (and equivalent) algebraic view of Max-Not-2 predicates.  Consider each literal  to be a  variable  (where  corresponds to  true, and  corresponds to  false). Translate each predicate into a sum:  if a predicate contains a signed literal in positive form, a positive copy of the corresponding variable is added. If a predicate contains a signed literal in negated form, a term is added in which the corresponding variable is subtracted from 1. For example, the predicate  becomes the sum . It is easy to check that the original predicate is satisfied exactly when its corresponding sum is not 2 (and hence the sum has total value 0, 1, or 3). We will say each predicate has at most three \emph{acceptable totals}, and exactly one \emph{unacceptable total}.\footnote{If the predicate has fewer than three signed literals, the number of achievable acceptable totals maybe be less than 3.}


Now, define a polynomial system based on  as follows. Create a variable  corresponding to the th literal of . Denote this new set of variables by . These  will replicate the  in the algebraic view of Max-Not-2: for each  create a polynomial . This gives a set of  \emph{literal polynomials} whose mutual roots are exactly .


Next, create a polynomial corresponding to each predicate in . In the algebraic view of Max-Not-2, each predicate  corresponds to a sum with at most 3 acceptable totals (some subset of  gives the acceptable totals for which the sum corresponds to a satisfied predicate). 
Each acceptable total for the sum 
will be used to define a linear term, and the product of these linear terms will give the \emph{predicate polynomial} corresponding to . Each linear term is 's sum (with the fixed variables from Stage 1 substituted in, e.g.  fixed true implies ) minus an acceptable total for the sum. For example, recall that the algebraic view of the Not-2 predicate  is the sum .
If none of  were fixed in Stage 1, then this yields the following polynomial:

The first term in this product corresponds to acceptable total sum of 0, etc.
Since there are always at most 3 acceptable totals for 's sum, the polynomial constructed is the product of at most 3 linear terms, and hence has degree at most 3. Since each predicate has at most 3 signed literals, each polynomial will contain at most 3 variables. When restricted to the mutual roots for the set of literal polynomials defined above, 0s for 's polynomial correspond exactly to the cases in which 's sum takes on an acceptable total. This encoding of the Not-2 requirement can fail only when some term in the product evaluates to 0 in a misleading way (when a sum is 2), which can only arise if  is .

All properties still hold when some variables in 's sum were fixed during pre-processing in Stage 1. For example, if in Stage 1,  were not fixed but  was fixed to false, then , so 's sum becomes  and consequently 's polynomial construction is:


This constructs a set of predicate polynomials of size . Let  denote the system of polynomials containing both the literal polynomials and the predicate polynomials. Notice that every satisfying assignment for  can be interpreted as a point in the variety of  (aka, a mutual root of all 's polynomials). In particular, since  is satisfiable,  is non-empty.

Apply algorithm  to solve the \nobreakdash-Fractional Gr\"{o}bner Problem for  for  for some fixed . Let  denote the variables that  selects to ignore. From the definition of a Restricted \nobreakdash-Fractional Gr\"{o}bner Basis,  was chosen so that the set of ignored polynomials, , has bounded size:

The second line follows from the first due to Lemma \ref{twofifths}. 

Let  denote the set of ignored predicate polynomials that are in , and  denote the set of retained predicate polynomials that are in . Clearly , so:
That is,  computes a Gr\"{o}bner basis with respect to a lexicographic order for the ideal generated by the polynomials in , and inequality (\ref{quarter}) says that at least a  fraction of all predicate polynomials must be in . 

The satisfiability of  ensures that a mutual root of the polynomials of  exists. Thus,  the polynomials from  must also have a mutual root.
Since we have a Gr\"{o}bner basis for  with respect to a lexicographic order, we can solve efficiently for a mutual root of the polynomials in  via successive elimination of the variables. In particular, since the variety of  is finite (it is a subset of , all partial solutions extend, and for each successive variable elimination only 2 options must be checked to find some  that works. The resulting solution is a vector  of length  which is a mutual zero of all polynomials in . Each entry in the vector corresponds to some literal variable in our Max-Not-2 instance: if  is 1 in , assign the corresponding literal variable  to be 1, if  is 0 in , assign the corresponding literal variable  to be 0.\footnote{Because of the inclusion of the literal polynomials, and the fact that by definition  contains all the literal polynomials corresponding to variables in , this routine makes an assignment for every  corresponding to a  ).} 

The vector  is a mutual zero of polynomials in : substituting  into any predicate polynomial in  gives 0. By our construction of the predicate polynomials, this implies that our partial assignment for  based on  yields an acceptable total for every predicate polynomial in . That is, every predicate whose polynomial is in  is satisfied by our current partial assignment for  (and from inequality (\ref{quarter}),  corresponds to strictly more than  of the predicates from ).

\vspace{2mm}

\noindent \textbf{Stage 3. Supplemental Random Assignment.} Let  denote a
predicate corresponding to an ignored polynomial in . From the form of ,  contains at least one literal corresponding to a .   
Literals corresponding to variables in  have not yet been assigned truth values.
We exploit this to ensure that a modest fraction of predicates corresponding to polynomials from  are satisfied. 

For literals corresponding to ignored variables , consider an independent coin-flip procedure that assigns  (a.k.a.  true) with probability , and  (a.k.a.  false) with probability . 
We will argue that regardless of the partial assignment constructed for  in Stage 2 (and effectively in Stage 1, through literal fixing), in expectation this random procedure satisfies at least half of the predicates corresponding to the polynomials in . 


At least one of 's signed literals has a truth value that is not-yet-assigned and will be decided by the coin-flipping procedure. Using the algebraic view of  as a sum (e.g. becomes sum ), we
analyze the probability that  has an acceptable total sum at the end of the coin-flip procedure (so that  is satisfied). The key point in the following case analysis is that  has some \textit{current achieved sum} at the end of Stage 2 (before random coin-flipping begins), and for  to be satisfied, 's total sum must avoid exactly one unacceptable total (namely 2). Say that 's unacceptable total minus 's current achieved sum is 's \textit{forbidden margin}. For example, if  enters Stage 3 with no signed literals fixed, 's forbidden margin will be 2. If  enters Stage 3 with exactly 2 signed literals fixed to be true, and one signed literal not yet fixed, then 's forbidden margin will be 0.  

First, suppose that all signed literals in  correspond to unique literals. Coin flips are independent, so the possible probability spaces are as follows.

\renewcommand\arraystretch{1.2} 

\begin{tabular}{|l|l|l|} \hline
's Number of Un-fixed Signed  & 's Realized Margin: Additional Signed  & Probability  \\
Literals Entering Stage 3 & Literals True After Coin-flipping& Distribution  \\
\hline
3 & & \\ 
\hline
2 & & \\ 
\hline
1 & & \\ 
\hline
\end{tabular}

\vspace{2mm}

Regardless of the number of un-fixed signed literals in  entering Stage 3, there is no single outcome whose probability is strictly more than .  Thus, regardless of the value of 's forbidden margin, the probability that 's total sum is acceptable (that is, the realized margin avoids 's forbidden margin) is at least . Thus, if all signed literals in  correspond to unique literals, the probability  is satisfied is at least .



Otherwise, the signed literals in  do not correspond to unique literals. Since  Property 1 holds WLOG (as noted in Stage 1 and proved in Appendix 1), there are only two possible forms for . We argue that in either case, the probability that  reaches an acceptable total is at least :

\vspace{-3mm}

\begin{enumerate}
\item Suppose  contains two identical signed literals with a third signed literal that was fixed to 0 or 1 in Stage 1. Since at least one of 's signed literals has not-yet-assigned truth value, 
it must be that the two identical signed literals are un-assigned entering Stage 3. If the fixed third signed literal has value 0, then the probability that  avoids unacceptable total sum of 2 is . If the fixed third signed literal has value 1, then the probability that  avoids unacceptable total sum is .

\vspace{-2mm}

\item Suppose  contains two identical signed literals with a third term that is a signed literal corresponding to an unrelated index. Again  has a specific forbidden margin. Consider the possible probability spaces:


\begin{tabular}{|l|l|l|} \hline
State Entering Stage 3 & 's Realized Margin: Additional Signed  & Probability  \\
 & Literals True After Coin-flipping& Distribution  \\
\hline
(pair fixed at 0 or 2, single un-fixed)& &\\  
\hline
(pair un-fixed, single fixed at 0 or 1) & & \\ 
\hline
(pair un-fixed, single un-fixed) & & \\ 
\hline
\end{tabular}

Again, regardless of 's current achieved sum at the end of Stage 2, the probability of 's forbidden margin being realized in Stage 3 is at most . Thus, the probability of  being satisfied (by reaching an acceptable total) is greater than or equal to .
\end{enumerate}

\vspace{-2mm}
\noindent Thus, for arbitrary predicate  corresponding to , the probability  is satisfied at the end of Stage 3 is at least . Since the expectation of the sum is the sum of the expectations, we have that the expected number of predicates satisfied by the coin-flipping procedure is at least .  

Such a randomized assignment procedure can then be derandomized via the well-known method of conditional expectations to obtain a deterministic assignment algorithm with quality that matches the expected guarantee.
Namely, given a list of the variables  to be randomly assigned, proceed through the list deterministically fixing truth values of one variable at a time as follows: for each variable , compare the conditional expected values of the number of clauses satisfied given assignments of true / false for . One of these conditional expectations must be at least as large as the expected value when  also is decided uniformly at random.  Thus, assigning  the truth value with the larger conditional expectation can be used to iteratively compute a deterministic solution of quality at least as high as the original expected value of half of .

We finally have a full truth assignment for the literals  that satisfies every predicate in  and at least  of the predicates in :



From the second to third line, inequality (\ref{quarter}) is applied. As , let  to get the final statement about . This reduction runs in polynomial time. The
final inequality shows that our method exceeds the hardness-of-approximation bound of H{\aa}stad for Max-Not-2 (listed as Theorem \ref{hastadnot2} earlier). Thus we have a contradiction, and Theorem \ref{extfrachard} is proved.
\end{proof}

Next we prove the first hardness result for approximate Gr\"{o}bner basis computation for polynomial systems of maximum degree 2 (matching the degree bound for NP-hardness of exact Gr\"{o}bner basis computation).  



Our proof of Theorem \ref{extfracharddeg2} is closely inspired by our proof of Theorem \ref{extfrachard}. Some notation and language introduced there will be directly reused. Differences arise from the form of the logical predicates considered: properties from preprocessing in Stage 1 are slightly different, the polynomial system constructed has lower-degree predicate polynomials, and the polynomials' form impacts our analysis of both the Gr\"{o}bner-Basis-based partial truth assignment and the final coin-flip-based portion of the truth assignment.

We rely on an earlier 2001 hardness result due to H{\aa}stad for a problem involving logical predicates of arity 3 where the system of predicates is satisfiable.  The predicates are now of the following form:


Here  are signed literals which represent positive or negated forms of literals from a set . This predicate is satisfied if at least one of  or  is true.  The second option  is often called an ``xor" or ``exclusive or." This exclusive or is true when exactly one of  or  is true. Describing (\ref{oxrform}) above, we will say that  is in the \textit{special position} of  and that  and  are in the \textit{symmetric positions} of . 

\begin{thm} [H{\aa}stad \cite{hast01}] \label{hastad2}
For any , given a satisfiable instance of Max-OXR of arity 3, there is no polynomial-time algorithm to find a truth assignment that satisfies a -fraction of the predicates (unless ). 
\end{thm}



\begin{proof}[Proof of Theorem \ref{extfracharddeg2}]  Assume, for contradiction, that an  as described in Theorem \ref{extfracharddeg2} does exist with . Define  so that . Given an arbitrary satisfiable input  of the \textit{Max-OXR Problem of arity 3} we compute a truth  assignment of forbidden quality in polynomial time. Similar to the proof of Theorem \ref{extfracharddeg2}, the assignment is constructed over three stages.\\

\noindent \textbf{Stage 1. Instance Preprocessing.} The form of OXR predicates sometimes unequivocally dictates a literal's truth value in all satisfying assignments. For example, if  is satisfied, then  must be true. Further, if some literal appears in only one OXR predicate, then manipulating that literal's truth value can always satisfy the predicate (regardless of the position in which the literal appears or the truth values of all other literals).  

In Appendix 2,  we use simple arguments like these to prove that an arbitrary satisfiable \textit{Max-OXR} instance may be preprocessed (fixing some literals to be true/false and removing some predicates) so that
WLOG the remaining instance is still satisfiable, an -approximate logical assignment for the updated instance is at minimum -approximate for the original Max-OXR instance, and
the following two convenient properties hold:

\vspace{1mm}
\noindent \textbf{Property 1.} \textit{If , then the two signed literals in 's symmetric positions correspond to unique literals.} 
\vspace{1mm}


\noindent \textbf{Property 2.} \textit{After the updates in Stage 1, Every literal  appears in some form (negated or positive) in at least two predicates from .}

\vspace{1mm}
\noindent As an immediate consequence of Property 2, we can derive Lemma \ref{twofifths} (as in our proof of Theorem \ref{extfracharddeg2}): . This inequality will be used in Stage 2. Later, in Stage 3, we will use Property 1 to analyze a final round of supplemental random truth assignment.

\vspace{2mm}
\noindent \textbf{Stage 2.  Polynomial Encoding and Gr\"{o}bner-based partial assignment. } Define a polynomial system based on  as follows. Create a variable  corresponding to the th literal of . Denote this set of variables by . Create a polynomial . This gives a set of  literal polynomials whose mutual roots are exactly . As in the previous proof,  implies  is false, and  implies  is true. 

Next create a set of predicate polynomials. Consider .
We create a polynomial corresponding to  as follows: it will be the product of 2 terms.  The first term will correspond to 's special position. If the signed literal in the special position of  corresponds to literal  and appears in positive form, then the first term in 's polynomial will be . If the signed literal in the special position of  corresponds to literal  and appears in negated form, then the first term in 's polynomial will be . The second term in 's polynomial will correspond to 's xor.  For 's xor to be true, using language from the proof of Theorem \ref{extfrachard}, there is only one \textit{acceptable sum} for variables corresponding to 's symmetric-position signed literals (namely 1). Let  and  denote the literals corresponding to the signed literals in the symmetric positions of  ( by Property 1).  We summarize the construction of the second term of 's polynomial below:\\

\begin{tabular}{l|l}
Form of 's xor & Form of second term in product-defined polynomial for \\ \hline
 &  \\
 &  \\
 &  \\
 & \\
\end{tabular}

\vspace{2mm}
The product of the two described terms gives the polynomial for . Note that  and  must be different literals from Property 2, but that  might match one of  or .  Since the literals fixed in Stage 1 already have permanently-fixed truth values, the corresponding 0s or 1s are substituted into the predicate polynomials defined above.  
For example, the predicate  gives polynomial  which simplifies to 
For further example, if  was set to true (a.k.a. 1) in Stage 1, and  and  remain unfixed, then  would produce the simple predicate polynomial 

The constructed a set of predicate polynomials has cardinality .
Each predicate polynomial is the product of two terms each of degree at most 1: each predicate polynomial has maximum total degree at most 2. Also, as in the previous reduction, each predicate polynomial contains at most 3 variables (corresponding to a limit of three signed literals per OXR predicate).

Let  denote the system of polynomials containing both the literal polynomials and the predicate polynomials. By our construction, every satisfying assignment for  can be interpreted as a mutual root of the polynomials in . 
Since  is satisfiable, at least one mutual root exists. Apply algorithm  to solve the \nobreakdash-Fractional Gr\"{o}bner problem for  for  for some fixed . Let  denote the variables  selects to ignore:  was chosen so that

\vspace{-5mm}



\noindent The third line follows from the second line due to Lemma \ref{twofifths}. Let  denote the set of predicate polynomials in , and  denote the set of predicate polynomials in . Since ,







That is,  computes a Gr\"{o}bner basis with respect to a lexicographic order for the ideal generated by the polynomials in , and inequality (\ref{half}) says that at least a  fraction of all predicate polynomials must be in . 
As in the proof of Theorem \ref{extfrachard}, given the Gr\"{o}bner Basis for  with respect to a lexicographic order, a mutual root, , of the polynomials in  can be efficiently computed via successive elimination of the variables. Each entry in  corresponds to some literal variable in our Max-OXR instance:
if  is 1 in , assign the corresponding literal  to be true, if  is 0 in , assign the corresponding literal  to be false. Since , this routine makes an assignment for every  corresponding to a  . 

The vector  is a mutual zero of all polynomials in .
Consider the factored form of the predicate polynomials we constructed: such polynomials evaluate to 0 under our constructed truth assignment if, and only if, either: (a) the signed literal corresponding to 's special position is True or (b) the xor over 's symmetric-position signed literals is True (or both). Thus, 
our -based partial truth assignment satisfies every predicate whose polynomial is in .

\vspace{2mm}

\noindent \textbf{Stage 3. Supplemental Random Assignment.} Literals corresponding to variables in  have not yet been assigned truth values. For these literals, consider an independent coin-flip procedure that assigns True with probability , and False with probability . We argue that regardless of the partial truth assignment constructed in Stage 2 (and effectively in Stage 1), in expectation, after this procedure, at least half of the predicates corresponding to the polynomials in  are satisfied. Such a procedure can be derandomized via the method of conditional expectations.

Let  denote an OXR predicate corresponding to a polynomial in . From the form of ,   contains (some form of) at least one literal corresponding to a : before the coin-flip procedure, the truth value of such a literal has not yet been decided. Through case analysis, we show that the probability that  is satisfied at the end of the coin-flip procedure is always at least .
Suppose that before coin-flipping:
\begin{itemize}
\item The truth value of the signed literal in 's special position has not yet been decided. The coin-flip procedure sets this special-position signed literal to be true with probability . Thus, the probability that  is satisfied at the end of the coin-flip procedure is at least . 
\item Otherwise, the truth value of the signed literal in 's special position was already decided. Then either:

\vspace{-3mm}

\begin{itemize}
\item Exactly one of the signed literals in a symmetric position of  has not yet been decided. Since the signed literal in 's other symmetric position has a fixed value, the probability that 's xor over the two symmetric positions is true as a result of the coin-flip procedure is . Thus, the probability that  is satisfied at the end of the coin-flip procedure is at least . 
\item Otherwise, both of the signed literals in the symmetric positions of  have not yet been decided. From Property 1 (proved to hold WLOG in Appendix 2), these symmetric-position signed literals correspond to unique literals. Thus, the probability that 's xor over the two symmetric positions is true as a result of the coin-flip procedure is  ('s xor is satisfied by exactly half of the possible truth assignments). Thus, the probability that  is satisfied at the end of the coin-flip procedure is at least . 
\end{itemize}
\end{itemize}

\vspace{-3mm}

\noindent Thus, if predicate  corresponds to a polynomial from , the probability  is satisfied at the end of Stage 3 is at least . The expectation of the sum is the sum of the expectations, so  the expected number of predicates from   that are satisfied after the coin-flip procedure is at least . Finally, we have a full truth assignment for literals  that satisfies all predicates in  and at least half of 's predicates, so:




Using inequality (\ref{half}),







\noindent 
Since , let  to get the final statement about . This reduction runs in polynomial time. Thus we violate the hardness-of-approximation bound of H{\aa}stad for Max\nobreakdash-OXR (listed as Theorem \ref{hastad2} earlier), obtaining a contradiction.
\end{proof}






\section{Proofs for the Strong \nobreakdash-Partial Gr\"{o}bner problem}
\label{sec:partial}

\begin{proof}[Proof of Theorem \ref{thm:stronger}]
As in the proofs of Theorem \ref{thm:main1} and \ref{thm:main2}, consider a 3-CNF Boolean formula  and define functions  for each clause  of . Let  denote the family of such functions, and, as in De Loera et al.~\cite{deloera}, define  copies  of  on disjoint sets of variables, such that . Then, the system  has a solution if and only if  has a solution.

Now, let  denote the polynomial , where  is a new variable that does not appear in any other polynomial. Observe that the system  has a solution if and only if  does, since for each solution of  there exists a (unique) value of  that yields a solution for .  Moreover, for any subset  with , the system  still has a solution if and only if  does, because there must be at least one  which is disjoint from . Since  has a solution exactly when  is satisfiable, we conclude that  has  as its Gr\"obner basis if and only if  is satisfiable.

Therefore, solving the Strong \nobreakdash-Partial Gr\"obner problem enables us to solve 3SAT with a polynomial-time reduction, using degree-3 polynomials and requiring only that we distinguish the (polynomial-size) Gr\"obner basis . 
\end{proof}

In our proof of Theorem \ref{prop:lundgroebner} we use a result on graph coloring due to Lund and Yannakakis \cite{lund}.

\begin{thm}[Theorem 2.8 in \cite{lund}]\label{lundy}  For every constant , there is a constant  such that the following problem is NP-hard. Given a graph , distinguish between the case that  is colorable with  colors and the case that the chromatic number of  is at least .
\end{thm}

\begin{proof}[Proof of Theorem \ref{prop:lundgroebner}]
Our proof is by contradiction. For arbitrary fixed , assume that for every possible degree bound  there exists a polynomial-time algorithm  to solve the Strong \nobreakdash-Partial Gr\"{o}bner problem for polynomial systems of maximum degree .

Let , so that . Applying Theorem \ref{lundy}, we conclude there exists a constant  such that it is NP-hard to distinguish whether a graph is -colorable or has chromatic number at least . Given a graph  that is guaranteed to be one of these two types, we will present a polynomial-time method to distinguish between the two possible types.

As in \cite{deloera}, write the -coloring ideal for , . This coloring ideal is a polynomial system with  variables and  polynomials of maximum degree . From our initial assumption, there exists a polynomial-time algorithm  to solve the Strong \nobreakdash-Partial Gr\"{o}bner Problem in polynomial systems of maximum degree , so apply  to .  The algorithm  returns a Gr\"{o}bner basis  for  and a list of at most  independent sets of variables . Let .

Consider the form of . Each variable  corresponds to a node  from . By construction of ,  appears in two types of polynomials. First,  is the sole variable in a \emph{node polynomial} that encodes that  must be assigned some th root of unity by any point in the variety of . Second, for each edge that contains node , variable  appears in an \emph{edge polynomial} that encodes that  and some neighbor must be assigned different th roots of unity by any point in the variety of . When all polynomials that contain variables in  are removed from  to get  the result is a coloring ideal for a subgraph  of  obtained by removing  independent sets of nodes and all edges containing these nodes from . In particular,  is the coloring ideal that describes proper colorings of such a subgraph  by  colors, .

If  is , then  must be empty. This means that no \nobreakdash-coloring of  exists. Then, since  is a subgraph of , no -coloring of  exists. Since  is guaranteed to be either \nobreakdash-colorable or have , it must be that . Thus, if  contains 1, we may conclude that  has chromatic number at least .

Suppose that  is not . We argue that this implies the \emph{existence} of a proper coloring of  by strictly less than  colors (so that, in fact, we can conclude  is \nobreakdash-colorable). Since  does not contain 1, the variety of   is non-empty. Thus, some coloring of  by  colors must exist. Each of the  independent sets of variables, , returned by  corresponds to an independent set of nodes in . Every node of  is either in such an independent set or in . Consider coloring each such independent set of nodes by a unique color, and using  additional colors to properly color the nodes of . This would produce a complete proper coloring of  by 
at most

Thus, if  is not , then there exists some proper coloring of  by  colors.
So, it can not be that . Since we were guaranteed that  was either \nobreakdash-colorable or had , it must be that  is \nobreakdash-colorable. So we conclude that  is \nobreakdash-colorable.

For arbitrary , to distinguish between the two possible cases our method constructs a polynomially-sized input to , which from our initial assumption has polynomial running time. Therefore, in polynomial time our method accurately solves a problem we know to be NP-hard from Theorem \ref{lundy}. Thus (unless PNP) we have a contradiction, and must reject our initial assumption. 
\end{proof}

Our decision rule in this reduction depends only on whether or not the Gr\"{o}bner basis is . Thus, again, our reduction applies whether   is polynomial in the size of our constructed polynomial system, , or polynomial in the size of the Gr\"{o}bner basis that should be returned. Namely, if  is the Gr\"{o}bner basis this information will be returned in polynomial time regardless. Otherwise, if  is not returned in polynomial time it is clear that  is not  and we must conclude that  is \nobreakdash-colorable.

































\section*{Acknowledgments}
\noindent The authors would like to thank David Cox and Jes\'us De Loera for constructive input on these ideas.  D.R.~was partially supported by NSF Grant No.~1122374. G.S. was supported  by NSF Grant No. DMS-1440140 while in residence at the Mathematical Sciences Research Institute in Berkeley, California during the Fall 2017 semester.

\bibliographystyle{plain}
\bibliography{references}

\section*{Appendix 1:  Max Not-2 Instance Preprocessing \for Proof of Theorem \ref{extfracharddeg2}, Stage 1) }

Conceptually the following appendix provides arguments highly analogous to those in Appendix 1. Details vary from Appendix 1 because of the different form of the predicates (OXR rather than Not-2 predicates) so we include them for completeness.

Suppose that we are given an arbitrary satisfiable input  for the \textit{Max-OXR Problem of arity 3}. We argue that the instance may be preprocessed (removing some predicates and fixing some literals to be true/false) so that several useful properties hold.
Each predicate removal and literal assignment we make to  preserves the properties that a satisfying assignment exists and that if we obtain an -approximate logical assignment for the updated instance, then this logical assignment is \emph{at minimum} -approximate for the original instance.

For an OXR predicate of form:
\vspace{-2mm}

we say that  is in the \textit{special position} of  and that  and  are in the \textit{symmetric positions} of . Iterate through the predicates in .  Consider the signed literals in the symmetric positions of : if both of these signed literals correspond to the same literal, then update  according to which of the following cases applies.

\begin{enumerate}
\item If the signed literals in the symmetric positions of  are identical, then their xor must be false (either both of the symmetric-position signed literals are true, or both of the symmetric-position signed literals are false). Thus, in every satisfying assignment the special-position signed literal of  must be true. 
Let  denote the literal corresponding to the signed literal in the special position of . Substitute the forced value of  into every predicate containing a signed form of . Say  has been permanently fixed. Remove 
 from . 

\item Otherwise the signed literals in the symmetric positions of  are in opposing forms (one positive, one negated). In this case their xor is true for every possible assignment. Since  is trivially satisfied, remove  from .
\end{enumerate}
    
   Call the set of all literals fixed during this procedure , and the set of all predicates removed from the original  by .
After executing the above procedure for every , observe that  now has the following property.  \\

\noindent \textbf{Property 1.} \textit{If , then the two signed literals in the symmetric positions of  correspond to unique literals.}\\

Literals were only permanently fixed (and removed) when we could reason unequivocally about the truth value they must take in every satisfying assignment. Thus, since the original  was satisfiable, the updated  is still satisfiable. A predicate was only removed from  when we could be certain that it would be satisfied by any assignment that extends the partial assignment already fixed for .
    
As in the previous proof, we make a final update to   to remove literals that appear in only one predicate (and the predicates that contain such literals). Call any literal  which appears in at most one predicate from  a \textit{loner literal}. Call the set of predicates from  which contain a loner literal by .  We consider temporarily ignoring predicates in  until all non-loner literals have been fixed. For , suppose that the truth values for all literals in , except one loner-literal , have already been fixed.\footnote{If more than one signed loner literal in  remains unfixed, then fix all but one arbitrarily, then proceed.} Then:
\begin{itemize}
\item If  corresponds to the signed literal in the special position of , then clearly  may be set so 's special-position signed literal is true (and  is satisfied). By definition, this choice for  (a loner literal) affects no other predicates.
\item If  corresponds to a signed literal in a symmetric position of , then, regardless of the truth value of the signed literal in 's other symmetric position\footnote{From Property 1, this other signed literal is not a form of .}, there is a truth assignment for  that makes 's xor true (so that  is satisfied). By definition, this choice for  affects no other predicates. 
\end{itemize}

Thus, we ignore OXR predicates containing loner literals for now: given an arbitrary partial assignment for  that fixes every literal \textit{except for the loner literals}, a predicate   that contains one or more loner literals can be satisfied by manipulating the  value of the contained loner literal. 
Thus, if a predicate contains a loner literal, remove that predicate from . Next remove all loner literals from . 

Removing predicates may cause additional literals to become loner literals. Successively remove additional rounds of loner-containing predicates and loner literals. Mark each loner literal by the round in which it was removed: once we have created a partial assignment for the remaining system we will fix the values of the loner literals in an order that reverses the order in which they were removed from  such that all loner-containing predicates are satisfied. 

We now have the  that we will argue about for the remainder of the reduction. As in the previous proof, observe that: \\

\noindent \textbf{Property 2.} \textit{After the updates in Stage 1, Every literal  appears in some form (negated or positive) in at least two predicates from .}\\

As in the proof of Theorem \ref{extfrachard}, since  of the predicates removed from  in Stage 1 can be polynomial-time satisfied after any partial assignment is fixed for the remaining instance , it is sufficient to show that for this remaining instance we can satisfy a  fraction of the predicates in polynomial time. We construct such an assignment for the remaining literals over stages 2 and 3.
\end{document}
