\documentclass{article}
\usepackage{INTERSPEECH2016}
\usepackage{amsmath,graphicx}
\usepackage{graphicx}
\usepackage{amssymb,amsmath,bm}
\usepackage{textcomp}
\usepackage{enumitem}
\usepackage{arabtex}
\usepackage{url}
\usepackage[table,xcdraw]{xcolor}
\usepackage{placeins}
\usepackage{float}
\usepackage{esvect}
\restylefloat{table}
\usepackage{placeins}
\usepackage[export]{adjustbox}
\usepackage{color,soul}
\usepackage{fixltx2e}
\usepackage{hyperref} \hypersetup{
  colorlinks   = true, urlcolor     = blue, linkcolor    = red, citecolor   = blue }
\usepackage{kbordermatrix}
\usepackage{booktabs}

\usepackage{graphics}
\usepackage{graphicx}
\newcommand\scalemath[2]{\scalebox{#1}{\mbox{\ensuremath{\displaystyle #2}}}}

\newcommand{\ra}[1]{\renewcommand{\arraystretch}{#1}}
\DeclareMathOperator*{\argmin}{arg\,min}
\DeclareMathOperator*{\argmax}{arg\,max}

\def\x{{\mathbf x}}
\def\L{{\cal L}}

\title{Automatic Dialect Detection in Arabic Broadcast Speech}
\name{{\em Ahmed Ali, Najim Dehak, Patrick Cardinal, Sameer Khurana, Sree Harsha Yella, Peter Bell, Steve Renals}}
\address{Qatar Computing Research Institute, HBKU, Doha, Qatar \\Centre for Speech Technology Research,School of Informatics \\
University of Edinburgh, Edinburgh EH8 9AB, UK \\
{\small \tt amali@qf.org.qa, \{peter.bell, s.renals\}@ed.ac.uk
}}
\begin{document}
\maketitle


\begin{abstract}
In this paper, we investigate different approaches for dialect identification in Arabic broadcast speech. These methods are based on phonetic and lexical features obtained from a speech recognition system, and bottleneck features using the i-vector framework. We studied both generative and discriminative classifiers, and we combined these features using a multi-class Support Vector Machine (SVM). We validated our results on an Arabic/English language identification task, with an accuracy of 100\%. We also evaluated these features in a binary classifier to discriminate between Modern Standard Arabic (MSA) and Dialectal Arabic, with an accuracy of 100\%.  We further reported results using the proposed methods to discriminate between the five most widely used dialects of Arabic: namely Egyptian, Gulf, Levantine, North African, and MSA, with an accuracy of 59.2\%. We discuss dialect identification errors in the context of dialect code-switching between Dialectal Arabic and MSA, and compare the error pattern between manually labeled data, and the output from our classifier. All the data used on our experiments have been released to the public as a language identification corpus.  \end{abstract}

\begin{keywords}
Dialect Identification, Vector Space Modelling
\end{keywords}


\section{Introduction}
\label{sec:intro}

The task of Dialect Identification (DID) is a special case of the more general problem of Language Identification (LID). LID refers to the process of automatically identifying the language class for given speech segment or text document.  DID is arguably a more challenging problem than LID, since it consists of identifying the different dialects within the same language class. The importance of addressing DID can be gauged from its growing interest in the Automatic Speech Recognition (ASR) community~\cite{liu2010dialect}. A good DID system can facilitate the identification of dialectal segments from an untranscribed mixed-speech dataset. This process can help reduce the ASR word error rate (WER) for dialectal data by training ASR systems for each dialect, or by adapting the ASR models to a particular dialect.

The natural language processing (NLP) community has aggregated dialectal Arabic into five regional language groups: Egyptian (EGY), North African or Maghrebi (NOR), Gulf or Arabian Peninsula (GLF), Levantine (LAV), and Modern Standard Arabic (MSA). An objective comparison of the varieties of Arabic dialects could potentially lead to the conclusion that Arabic dialects are historically related, but not synchronically, and are mutually unintelligible languages like English and Dutch. Normal vernacular can be difficult to understand across different Arabic dialects~\cite{holes2004modern}. Arabic dialects are thus sufficiently distinctive, and it is reasonable to regard the DID task in Arabic as similar to the LID task in other languages.  Table~\ref{tab:lexical_difference} shows two phrases across the different dialects, it is clear from this example that there are lexical variations across the different dialects which motivates us to consider it.

Two broad LID approaches have been investigated in the literature:  low-level acoustic features, and high-level phonetic and lexical features. In the lexical area, words, roots, morphology, and grammars~\cite{reynolds2008lid,ambikairajah2011language} have been studied. Acoustic features such as shifted delta cepstral coefficients~\cite{dehak2011language} and prosodic features ~\cite{martinez2012ivector} using Gaussian mixture models (GMMs), i-vector representations and support vector machine (SVM) classifiers ~\cite{dehak2011language} have been shown to be effective for LID. More recent work explored the use of frame-by-frame phone posteriors (PLLRs) ~\cite{plchot2014pllr} as new features for LID. New subspace approaches based on non-negative factor analysis (NFA) for GMM weight decomposition and adaptation~\cite{bahari2014non} were also applied to both LID and DID tasks. GMM weight adaptation subspaces seem to provide complementary information to the classical i-vector framework. Finally, phoneme sequence modeling and its n-gram subspace have been studied for both Arabic DID ~\cite{soltau2011modern} and LID ~\cite{soufifar2012discriminative}.

\FloatBarrier
\begin{table}[ht]
\label{lexicalExamples}
\caption{\textit{Lexical examples in Arabic and Buckwalter format.}}
\resizebox{0.5\textwidth}{!}{\begin{tabular}{|l|l|l|l|l|l|}
\hline
EGY     & GLF    & LAV           & MSA      & NOR     & Translation \\ \hline
\begin{tabular}[x]{@{}c@{}} \novocalize \RL{AzAyk} \\AzAYk\end{tabular}                                                               &
\begin{tabular}[x]{@{}c@{}} \novocalize \RL{A^slwnk} \\ A\lwnk \end{tabular}      & \begin{tabular}[x]{@{}c@{}} \novocalize \RL{kyf .hAlk} \\ kyf HAlk\end{tabular}                            &  \begin{tabular}[x]{@{}c@{}} \novocalize \RL{wA^s rAk} \\ wA\n \le 4\mathbf{u}\mathbf{\vv{u}}f(u,s_{i})s_{i}uAtf.idf\mathbf{U_{s}} \in \mathbb{R}^{d \times N}\mathbf{U_{s}}dN\mathbf{U_{w}}\mathbf{u}\mathbf{\vv{u}}f(u,w_{i})w_{i}uA\mathbf{U_{s}}uTvvTw_{0}=w_{-1}=**xx_{i}01ix^{*}\thetacx^{*}A\vv{u}55d = 300d = 600d = 1200d = 1600ACCPRCRCLACCPRCRCLACCPRCRCLACCPRCRCL\mathbf{U_{w}^{i}}\mathbf{U_{w}^{tfidf}}\mathbf{U_{s}^{i}}\mathbf{U_{s}^{tfidf}}dd\mathbf{U_{iVec}^{bnf}}\mathbf{U_{iVec+LDA+WCNN}^{bnf}}\mathbf{U_{iVec+LDA+WCNN+LNORM}^{bnf}}\mathbf{U_{iVec+LDA+WCNN}^{bnf} + U_{s}^{i}(600d)}d\mathbf{U_{w}^{i}}A5530060012001600\mathbf{U_{w}^{tf.idf}}Atf.idf\mathbf{U_{s}^{i}}A\mathbf{U_{s}^{tf.idf}}Atf.idftf.idfU_{s}^{i}(600d)U_{w}^{tfidf}(1200d)\mathbf{U_{iVec}^{bnf}}400d\mathbf{U_{iVec+LDA+WCNN}^{bnf}}\mathbf{U_{iVec+LDA+WCNN}^{bnf} + U_{s}^{i}(600d)}$: Finally we concatenate the best senone-based VSM with the best i-vector-based VSM, to form a concatenated vector representation for each utterance and see slight improvements in the results. As the lexical and senone-based representations encode the same information about the dialect, we do not experiment with concatenated lexical and i-vector representations.
\end{itemize}






\subsection{One Vs All classification (Sanity Check)}
We  constructed a senone-based utterance VSM (section~\ref{sec:svsm}) based on 20 hours of speech; 10 hours English (which we got from~\cite{glass2004analysis}) and 10 hours Arabic (randomly sampled from our training data, section~\ref{sec:data}). Binary classification (English vs Arabic) using an SVM classifier, was then performed and it yielded 100\% accuracy on the 1.5 hour test set. The reason to choose the senone-based feature space and not the i-vector-based feature space for classification is to avoid channel mismatch, as the English data came from a different source domain. We did a similar experiment to classify MSA versus all dialectal Arabic and again obtained 100\% classification accuracy.

\subsection{System Output Combination}
We fused the scores of the best senone system and the SVM-based i-vector system. In the fusion steps, the original scores of each system were normalized and combined using the same fusion weights for both systems. This approach yielded a final accuracy of 60.2\%, which is the best performance we achieved. One explanation for this gain is that the error patterns for the two feature spaces are quite different, and we were able to confirm that by analyzing the confusion matrix for each system.

 
\section{Conclusions}
This paper presents our efforts on automatic dialect identification for Arabic broadcast speech. We have demonstrated a dialect classifier with an accuracy of 60.2\% using system combination. We also achieved 100\% accuracy on two binary classification tasks; MSA vs Dialectal Arabic and English vs Arabic. We studied the potential code-switching pattern in our classifier and its correlation with the manual annotation. Further work for this research is to study the code-switch between MSA and dialectal Arabic without considering speaker diarization or silence between speech segments in what can be called dialect diarization. We shall also study deep neural network approaches of classification to learn a more complex non-linear decision boundary.
 



\bibliographystyle{IEEEbib}
\bibliography{refs}

\end{document}
