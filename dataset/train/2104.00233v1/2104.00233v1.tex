
        
\subsection{Problem Formalization}


We consider multi-class visual categorization, where a specific example $x$ belongs to one of $k$ predefined visual concepts. Ground truth of $x$ is indicated by $y$, a $k$-dimensional one-hot vector. A deep visual classification network $G$ classifies $x$ by first employing a feature extractor $F$ to obtain a vectorized feature representation $z$ from its raw pixels. Then, $z$ is fed into a $k$-way classifier $C$ to produce a categorical probability vector $\hat{y}$, where the value of its $i$-th dimension is the probability of the example belonging to the $i$-th concept, \ie
\begin{equation} \label{eq:clf}
\left\{
\begin{array}{lll}
z & = & F(x), \\
\hat{y} & = & C(z).
\end{array} \right.
\end{equation}
Such a paradigm as expressed in Eq. \ref{eq:clf} remains valid to this day, even though $F$ and $C$ have now been jointly deployed and end-to-end trained by deep learning.



As UDE is derived from UDA, we adopt common notations from the latter for the ease of consistent description. 
For both UDE and UDA, we have access to a set of $n_s$ labeled training examples $\{(x_{s,i}, y_{s,i})\}_{i=1}^{n_s}$ from a source domain $D_s$ and a set of $n_t$ unlabeled training examples $\{x_{t,i}\}_{i=1}^{n_t}$ from a target domain $D_t$. However, different from UDA that focuses on $D_t$, UDE treats the expanded domain $D_s + D_t$ as its ``target'' domain. Therefore, our goal is to train a unified model that can accurately classify novel examples regardless of their original domains.









\subsection{UDE by Knowledge Distillation} \label{ssec:kdde_model}

We propose a knowledge distillation based method for UDE, which we term \textit{KDDE}. As illustrated in Fig. \ref{fig:method}, KDDE is performed in two steps. In the first step, two domain-specific classifiers, denoted as $G_s$ and $G_{s\rightarrow t}$, are trained for the source and target domains, respectively. Note that we use the notation $s\rightarrow t$ to emphasize that as $D_t$ is unlabeled, any domain-adapted classifier shall departure from $D_s$. In the second step, we treat $G_s$ and $G_{s\rightarrow t}$ as two teacher models and transfer their ``dark'' knowledge into a student model $G_{s+t}$ via a knowledge distillation process. In particular, by mimicking $G_s$ for classifying examples from $D_s$ and $G_{s\rightarrow t}$ for $D_t$, $G_{s+t}$ essentially becomes domain-invariant.  We detail the two steps as follows.


\begin{figure*}[tbh!]
\setlength{\abovecaptionskip}{5pt}
\centering
\includegraphics[width=\textwidth]{diagrams/kdde}
\caption{\textbf{Conceptual diagram of the proposed KDDE method for UDE}. KDDE is run in two steps. First, a model $G_s$ is trained on the \textit{labeled} source domain by standard supervised learning, while another model $G_{s\rightarrow t}$ for the \textit{unlabeled} target domain is trained by unsupervised domain adaptation (here CDAN~\cite{nips18-cdan} as a running example). Then, knowledge distillation is performed to transfer ``dark'' knowledge from the two domain-specific models into a student model $G_{s+t}$ to make it applicable to both domains.}
\label{fig:method}
\end{figure*} 

\subsubsection{Step 1(a): Training a source-only model $G_s$}

Learning a classifier from labeled data is relatively simple. We adopt the cross-entropy loss, a common classification loss used for training a multi-class deep neural network. Given $(X_s,Y_s)$ as $\{(x_{s,i}, y_{s,i})\}_{i=1}^{n_s}$, the classification loss is written as
\begin{equation} \label{eq:clf-loss}
L_{clf}(X_s, Y_s, G) = \frac{1}{n_s} \sum_{(x_s,y_s)\in (X_s,Y_s)} y_s \log (G(x_s)).
\end{equation} 
By minimizing $L_{clf}(X_s, Y_s, G)$, we obtain a domain-specific model for $D_s$ as
\begin{equation} \label{eq:g_s}
G_s = \argmin{G}  L_{clf}(X_s, Y_s, G).
\end{equation}




\subsubsection{Step 1(b): Training a domain-adapted model $G_{s\rightarrow t}$}





Recall that KDDE, as a two-stage solution, is agnostic to the implementation of a specific UDA model used in its first stage.
Hence, for obtaining $G_{s\rightarrow t}$, any method for unsupervised domain adaptation can, in principle, be adopted. 
A typical process of model adaptation tries to strike a proper balance between a model's discriminability, as reflected by the classification loss on $D_s$, and its domain-invariant representation ability, as measured by inter-domain discrepancy between $D_s$ and $D_t$. More formally, we have 
\begin{equation}\label{eq:general-da}
G_{s\rightarrow t} = \argmin{G} \underbrace{L_{clf}(X_s, Y_s, G)}_{\mbox{discriminative}} + \lambda \cdot \underbrace{L_{da}(X_s, X_t, G)}_{\mbox{domain-invariant}},
\end{equation}
where $L_{da}$ is a domain discrepancy based loss, and $\lambda$ is a positive hyper-parameter. Algorithm \ref{alg:da} describes the domain adaptation process at a high level. In what follows, we use the state-of-the-art CDAN model~\cite{nips18-cdan} as a running example to instantiate $L_{da}$. 

\begin{algorithm}
\caption{Training a domain-adapted model $G_{s\rightarrow t}$}
\label{alg:da}
\KwIn{$(X_{s}, Y_{s})$, $X_{t}$}
\KwOut{$G_{s\rightarrow t}$}
Set hyper-parameters: $\lambda, MAX\_EPOCHS, BATCH\_SIZE$\;
Compute the number of iterations per epoch $MAX\_ITERS$, given $|X_s|$ and  $BATCH\_SIZE$\;
Initialize {$G_{s\rightarrow t}$} with an ImageNet-pretrained model\;
\For{$i\leftarrow 1,\ldots, MAX\_EPOCHS$}{
    \For{$j\leftarrow 1, \ldots, MAX\_ITERS$}{
      Sample a mini-batch $(X_{s,j}, Y_{s,j})$ from $(X_{s}, Y_{s})$\;
      Sample a mini-batch $X_{t,j}$ from $X_t$\;
      Compute the classification loss $L_{clf}(X_{s,j}, Y_{s,j}, G_{s\rightarrow t})$ \;
      Compute the inter-domain discrepancy $L_{da}(X_{s,j}, X_{t,j}, G_{s\rightarrow t})$ \;
      Update $G_{s\rightarrow t}$ by back propagation based on $L_{clf}+\lambda*L_{da}$
      }
    }
\end{algorithm}
 





CDAN reduces domain discrepancy by adversarial learning, where a feed-forward neural network is used as a discriminator $D$ to disentangle the source examples $X_s$ from the target examples $X_t$. Different from previous adversarial learning based methods where only the intermediate features $F(x_s)$ and $F(x_t)$ are considered, CDAN uses multilinear conditioning of the features and class prediction $F(x)\otimes \hat{y}$ as the input of $D$. The output of $D$ is the probability of a given example coming from the source domain. Accordingly, we have the discriminator reward $R$ as 
\begin{equation}
R(X_s,X_t,G,D) = \sum_{x_s \in X_s} \log D(F(x_s)\otimes \hat{y}_s) + \sum_{x_t \in X_t} \log (1 - D(F(x_t) \otimes \hat{y}_t))
\end{equation} 
The training process of CDAN is implemented as a two-player minimax game as follows:
\begin{equation} \label{eq:cdan}
    (G_{s\rightarrow t}, D)=\argmin{G} \underset{D}{\max}\; L_{clf}(X_s, Y_s, G) + \lambda \cdot R(X_s, X_t, G, D).
\end{equation}















\subsubsection{Step 2. Training a domain-expanded model $G_{s+t}$}

Given the domain-specific models $G_s$ and $G_{s\rightarrow t}$, we now transfer their capabilities in their own domains into a new model $G_{s+t}$ by knowledge distillation. 

In a standard scenario where one wants to distill the knowledge in a big teacher model into a relatively small student model~\cite{nips15-kd}, both ground-truth hard labels and soft labels predicted by the teacher model are available for computing the distillation loss. By contrast, in the setting of UDE, the expanded domain has only partial ground-truth labels by definition. More importantly, in order to make $G_{s+t}$ domain-invariant, we shall not only treat $G_s$ and $G_{s\rightarrow t}$ equally, but also exploit training examples from $D_s$ and $D_{s\rightarrow t}$ in the same manner. To that end, we opt to compute the distillation loss fully based on the soft labels. 

Specifically, we adopt the Kullback-Leibler (KL) divergence, as previously used to quantify how a student's output matches with its teacher~\cite{nips15-kd,zhang2018deep_mutual}. Per training example, the soft labels produced by the teacher / student model is essentially a probability distribution over the $k$ concepts. The KL divergence provides a natural measure of how the probability distribution produced by the student is different from that of the teacher, making it a popular loss for knowledge distillation \cite{nips15-kd,zhang2018deep_mutual,mirzadeh2020improved,tian2019contrastive,goldblum2020adversarially,zhang2019your,shi2019knowledge}. Indeed, our ablation study in Section \ref{sssec:kd-loss} shows that the KL divergence loss is better than other losses such as cross-entroy and $l_2$. Let $P(G(X))$ be a $k$-dimensional categorical distribution estimated based on soft labels of an example set $X$ produced by a specific network $G$. Accordingly, the KL divergence from $G$ to each of the two teachers is defined as $KL(P(G_s(X_s)) || P(G(X_s)))$ and $KL(P(G_{s\rightarrow t}(X_t)) || P(G(X_t)))$, respectively. 
The knowledge distillation loss $L_{kd}$ is defined as 
\begin{equation} \label{eq:loss-kd}
L_{kd}(X_s, X_t, G_s, G_{s\rightarrow t}, G) = KL(P(G_s(X_s)) || P(G(X_s)))  + KL(P(G_{s\rightarrow t}(X_t)) || P(G(X_t))).
\end{equation}

Note that the $KL$ terms in Eq. \ref{eq:loss-kd} are practically computed by a mini-batch approach. As demonstrated in Fig. \ref{fig:method}, in each iteration two mini-batches are independently and randomly sampled from $D_s$ and $D_t$. They are then fed into $G_s$ and $G_{s\rightarrow t}$ to get the soft labels, which are used to approximate $P(G_s(X_s))$ and $P(G_{s\rightarrow t}(X_t))$, respectively. Meanwhile, the two batches are also fed to the student model. Minimizing $L_{kd}$ lets the student model mimic the teachers' behaviors on both $D_s$ and $D_t$. 
Consequently, we obtain the domain-invariant model as 
\begin{equation} \label{eq:general-de}
    G_{s+t}=\argmin{G} L_{kd}(X_s, X_t, G_s, G_{s\rightarrow t}, G).
\end{equation}

A high-level description of the training process is given in Algorithm \ref{alg:kdde}. Note that during training, we need to store three models (two teachers $G_s$ and $G_{s\rightarrow t}$ and one student $G_{s+t}$). We consider such storage overhead affordable as one typically has access to more computational resources in the training stage than in the inference stage. Moreover, as the teachers are only used to product the soft labels, their weights are frozen, meaning the GPU footprint is much less than simultaneously training all the three models. Also note that in the inference stage. $G_{s+t}$ has the same model size and computation overhead as its teachers. Hence, the proposed method is feasible in real-world scenarios.

\begin{algorithm}
\caption{Training a domain-expanded model $G_{s+t}$ by KDDE}
\label{alg:kdde}
\KwIn{$X_s, X_t, G_s, G_{s\rightarrow t}$}
\KwOut{$G_{s+t}$}
Set hyper-parameters: $MAX\_EPOCHS, BATCH\_SIZE$\;
Compute $MAX\_ITERS$ given $max(|X_s|,|X_t|)$ and  $BATCH\_SIZE$\;
Initialize {$G_{s+t}$} with an ImageNet-pretrained model\;
\For{$i\leftarrow 1,MAX\_EPOCH$}{
    \For{$j\leftarrow 1,MAX\_ITER$}{
        Sample $X_{s,j}$ from $X_s$\; 
        Sample $X_{t,j}$ from $X_t$\;
        Compute $L_{kd}(X_{s,j}, X_{t,j}, G_s, G_{s\rightarrow t}, G_{s+t})$ using Eq. \ref{eq:loss-kd}\;
        Update $G_{s+t}$ by back propagation based on $L_{kd}$\;
        }
    }
\end{algorithm}
 
\subsection{Theoretical Analysis}

Comparing Eq. \ref{eq:general-da} and Eq. \ref{eq:general-de}, we see that UDA essentially tries to simultaneously optimize two distinct and sometimes conflictive objectives, \ie discriminability and domain-invariance. By contrast, our KDDE optimizes a single objective. We believe such a property improves the cross-domain generalization ability of KDDE. Nonetheless, because $G_{s+t}$ is learned from the source model $G_s$ and the domain-adapted model $G_{s\rightarrow t}$ in an unbiased manner, domain expansion is obtained at the cost of certain performance drop in the source domain. In other words, $G_{s+t}$ will be less effective than its teacher $G_{s}$ on the source domain, but perform better on the expanded domain, which is the goal of this research.

As for the target domain, $G_{s+t}$ will be better than its teacher $G_{s\rightarrow t}$. According to Ben-David \etal \cite{ben2007analysis}, the target domain error of a UDA model is bounded mainly by its classification error in the source domain and the divergence between the induced source marginal and the induced target marginal. In theory, a UDA model shall be trained to simultaneously minimize the two terms and reduce accordingly the up bound of the target domain error. In practice, however, the classification error in the source domain is not effectively reduced when compared to the source-only model. This is confirmed by our experiments in Section \ref{sec:exp} that a number of present-day UDA models including DDC~\cite{ddc}, DANN~\cite{jmlr16-dann}, DAAN~\cite{icdm19-daan} and CDAN~\cite{nips18-cdan} suffer performance loss in the source domain. With knowledge distillation, $G_{s+t}$ effectively integrates the merits of $G_{s\rightarrow t}$ for minimizing the domain divergence and $G_s$ for minimizing the source error, and thus lowers the up bound of the target domain error. 

Through knowledge distillation, KDDE injects the dark knowledge of the source-only model $G_s$, which performs well on the source domain, and the domain-adapted model $G_{s\rightarrow t}$, which is supposed to perform well on the target domain, into a single model $G_{s+t}$. The effect of knowledge distillation on $G_{s+t}$ is visualized in Fig. \ref{fig:heatmaps}. By contrast, although CDAN also uses one classifier for both domains, the classifier is essentially $G_{s\rightarrow t}$ used in KDDE. Hence, it is less effective than $G_{s+t}$ to handle the expanded domain. Also notice that the purpose of knowledge distillation is not to reduce the difference between the two teacher models, see Eq. \ref{eq:loss-kd}. Therefore, KDDE is conceptually different from Maximum classifier discrepancy (MCD) \cite{cvpr2018-mcd}, which is to reduce the discrepancy between two domain-adapted classifiers via a novel adversarial learning mechanism.


\begin{figure*}[tbh!]
\setlength{\abovecaptionskip}{5pt}
\centering
\includegraphics[width=0.55\textwidth]{diagrams/heatmaps}
\caption{\textbf{Grad-CAM heatmaps of ResNet-50, CDAN and KDDE}. Heatmaps highlight regions important for a model to make predictions. Test images in the first three rows are from the source domain (\textit{clipart}), while images in the last three rows are from the target domain (\textit{real}). Activated regions of KDDE ($G_{s+t}$) match well with those of ResNet-50 ($G_s$) on the source domain and those of CDAN ($G_{s\rightarrow t}$) on the target domain, suggesting the ability of KDDE to adaptively learn from the two domain-specific models. Data from DomainNet.}
\label{fig:heatmaps}
\end{figure*} 














%
