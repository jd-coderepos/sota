In this section, we will derive the scaling laws for the performance of the system when transmissions are modeled as continuous. We model the arrivals at each receiver as a Poisson process and analyze the behavior of completion time as the number of receivers  grow.

Each of the  users needs to receive  or more coded packets from a single transmitting node. In time  packet lengths, each of the  nodes \textit{independently} receives a number of packets that is Poisson distributed, on the time scale of integral numbers of packet lengths, with parameter , where , and  is the packet erasure probability. The probability that user  receives  or more coded packets within time  is thus:


Hence the probability that all  users receive at least  coded packets in time  or earlier is (\ref{one-user}) raised to the power of . As in Section \ref{sec:Disc_Model} we define  to be the probability that \textit{all} of the  users received  or more coded packets within time . This probability , which is also the probability that the transmitter can stop sending coded packets, is:


We select the first feedback time so that there is a significant probability that every receiver has completed the download and there is no need for retransmissions. In other words,  is a time whose corresponding  has reached a certain reliability threshold. Let us use  to denote this threshold. Thus: 


Rearranging terms in (\ref{eq:cont_model}) and substituting  and  for  and  yields:


we then have:

where the Gamma functions are defined as:


\begin{figure} [ht]
\centering
\includegraphics[scale=0.63,clip=true]{Gamma_function_for_cont_model.eps}
\caption{Calculating  from the  function.}
\label{fig:Gamma_function_for_cont_model}
\end{figure}
Fig. \ref{fig:Gamma_function_for_cont_model} illustrates equation (\ref{gamma_eqn}). Notice that  is strictly decreasing in  and is thus invertible. As a result, given a set of parameters , a unique  can be determined that is the amount of time that it takes for all  users to receive the  packet file, with probability . The right hand side of (\ref{gamma_eqn}) corresponds to the horizontal line in Fig. \ref{fig:Gamma_function_for_cont_model}, and is the probability that any given user has not received the file by time . For large  and even a modest , this probability, and hence the resulting horizontal line, would be quite low, resulting in the selection of a  such as that shown in the figure. Alternatively, if the function  is considered at time , rather than at time , then raising  to the power of  yields a continuous model version of the the probability function  plotted in Fig. \ref{fig:diff_k_and_n}. Taking the  power of  for large  renders  close to 1 only if  is very close to 1, thereby yielding the sharp transition in time seen in Fig. \ref{fig:diff_k_and_n}.

We are interested in sensitivity of  to  for a given value of . A better understanding of this sensitivity can be achieved by looking at the reverse problem. Let us see how many nodes  we can accommodate after  transmissions for a given value of . Rearranging terms in (\ref{eq:exact_sensitivity_parameters}) and solving for  yields: 


Figure \ref{fig:accomodated_nodes_for_a_given_t_k_100} provides the number of users that can be accommodated by time , for a range of . The figure was computed according to (\ref{eq:exact_sensitivity_for_figures}) for a file size of  packets and packet erasure probability of . Fig. \ref{fig:accomodated_nodes_for_a_given_t_k_100} can be used to determine the  that will ensure a given reliability  for a given  and . The dashed black lines in the figure illustrate how to determine this time for the example case of  = .9 and .

The number of nodes  that can be accommodated increases rapidly, as emphasized by the logarithmic scale of the vertical axis and the linear scale of the horizontal axis. In fact a much larger group of users can be accommodated with a relatively short extra transmission time. For example, when , an increase of approximately  in  (from  to ) can accommodate  times as many users (from 10 to 1000 users). Because of the convexity exhibited in the figure, ever larger groups can be accommodated with the same number of extra transmissions. 

It should also be noted that  is not very sensitive to , and the sensitivity decreases as  increases. For example, the figure shows that in order to accommodate  users, with reliabilities  and , we need  and  respectively (a 15.7\% increase in  to reach the higher ). Accommodating  users for the same values of  will require  and  respectively (a 9.2\% increase in ). 
\begin{figure} [ht]
\centering
\includegraphics[scale=0.62,clip=true]{Affordable_number_of_nodes_vs_time_k_is_100.eps}
\vspace{-0.8cm}
\caption{The number of nodes  that can be accommodated for a given transmission time . The figure was computed according to (\ref{eq:exact_sensitivity_for_figures}) with  packets and . An example of how the time  can be obtained from these curves is illustrated by the dashed lines for the case of  = .9 and .}
\label{fig:accomodated_nodes_for_a_given_t_k_100}
\end{figure}

Similar numerical results hold for larger file sizes and can be verified by plotting (\ref{eq:exact_sensitivity_for_figures}) for larger values of . As  increases, the \textit{per packet} time required to reliably transmit a file to a fixed number of receivers decreases. This favorable gain comes from the ability to code across larger files, and shows the robustness of SMART to increases in the file size. 



