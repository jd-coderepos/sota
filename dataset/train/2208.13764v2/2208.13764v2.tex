\documentclass[nohyperref]{article}
\usepackage[dvipsnames]{xcolor}

\usepackage[accepted]{icml2022}



\usepackage{amsmath,amsfonts,bm}

\newcommand{\figleft}{{\em (Left)}}
\newcommand{\figcenter}{{\em (Center)}}
\newcommand{\figright}{{\em (Right)}}
\newcommand{\figtop}{{\em (Top)}}
\newcommand{\figbottom}{{\em (Bottom)}}
\newcommand{\captiona}{{\em (a)}}
\newcommand{\captionb}{{\em (b)}}
\newcommand{\captionc}{{\em (c)}}
\newcommand{\captiond}{{\em (d)}}

\newcommand{\newterm}[1]{{\bf #1}}


\def\figref#1{figure~\ref{#1}}
\def\Figref#1{Figure~\ref{#1}}
\def\twofigref#1#2{figures \ref{#1} and \ref{#2}}
\def\quadfigref#1#2#3#4{figures \ref{#1}, \ref{#2}, \ref{#3} and \ref{#4}}
\def\secref#1{section~\ref{#1}}
\def\Secref#1{Section~\ref{#1}}
\def\twosecrefs#1#2{sections \ref{#1} and \ref{#2}}
\def\secrefs#1#2#3{sections \ref{#1}, \ref{#2} and \ref{#3}}
\def\eqref#1{equation~\ref{#1}}
\def\Eqref#1{Equation~\ref{#1}}
\def\plaineqref#1{\ref{#1}}
\def\chapref#1{chapter~\ref{#1}}
\def\Chapref#1{Chapter~\ref{#1}}
\def\rangechapref#1#2{chapters\ref{#1}--\ref{#2}}
\def\algref#1{algorithm~\ref{#1}}
\def\Algref#1{Algorithm~\ref{#1}}
\def\twoalgref#1#2{algorithms \ref{#1} and \ref{#2}}
\def\Twoalgref#1#2{Algorithms \ref{#1} and \ref{#2}}
\def\partref#1{part~\ref{#1}}
\def\Partref#1{Part~\ref{#1}}
\def\twopartref#1#2{parts \ref{#1} and \ref{#2}}

\def\ceil#1{\lceil #1 \rceil}
\def\floor#1{\lfloor #1 \rfloor}
\def\1{\bm{1}}
\newcommand{\train}{\mathcal{D}}
\newcommand{\valid}{\mathcal{D_{\mathrm{valid}}}}
\newcommand{\test}{\mathcal{D_{\mathrm{test}}}}

\def\eps{{\epsilon}}


\def\reta{{\textnormal{}}}
\def\ra{{\textnormal{a}}}
\def\rb{{\textnormal{b}}}
\def\rc{{\textnormal{c}}}
\def\rd{{\textnormal{d}}}
\def\re{{\textnormal{e}}}
\def\rf{{\textnormal{f}}}
\def\rg{{\textnormal{g}}}
\def\rh{{\textnormal{h}}}
\def\ri{{\textnormal{i}}}
\def\rj{{\textnormal{j}}}
\def\rk{{\textnormal{k}}}
\def\rl{{\textnormal{l}}}
\def\rn{{\textnormal{n}}}
\def\ro{{\textnormal{o}}}
\def\rp{{\textnormal{p}}}
\def\rq{{\textnormal{q}}}
\def\rr{{\textnormal{r}}}
\def\rs{{\textnormal{s}}}
\def\rt{{\textnormal{t}}}
\def\ru{{\textnormal{u}}}
\def\rv{{\textnormal{v}}}
\def\rw{{\textnormal{w}}}
\def\rx{{\textnormal{x}}}
\def\ry{{\textnormal{y}}}
\def\rz{{\textnormal{z}}}

\def\rvepsilon{{\mathbf{\epsilon}}}
\def\rvtheta{{\mathbf{\theta}}}
\def\rva{{\mathbf{a}}}
\def\rvb{{\mathbf{b}}}
\def\rvc{{\mathbf{c}}}
\def\rvd{{\mathbf{d}}}
\def\rve{{\mathbf{e}}}
\def\rvf{{\mathbf{f}}}
\def\rvg{{\mathbf{g}}}
\def\rvh{{\mathbf{h}}}
\def\rvu{{\mathbf{i}}}
\def\rvj{{\mathbf{j}}}
\def\rvk{{\mathbf{k}}}
\def\rvl{{\mathbf{l}}}
\def\rvm{{\mathbf{m}}}
\def\rvn{{\mathbf{n}}}
\def\rvo{{\mathbf{o}}}
\def\rvp{{\mathbf{p}}}
\def\rvq{{\mathbf{q}}}
\def\rvr{{\mathbf{r}}}
\def\rvs{{\mathbf{s}}}
\def\rvt{{\mathbf{t}}}
\def\rvu{{\mathbf{u}}}
\def\rvv{{\mathbf{v}}}
\def\rvw{{\mathbf{w}}}
\def\rvx{{\mathbf{x}}}
\def\rvy{{\mathbf{y}}}
\def\rvz{{\mathbf{z}}}

\def\erva{{\textnormal{a}}}
\def\ervb{{\textnormal{b}}}
\def\ervc{{\textnormal{c}}}
\def\ervd{{\textnormal{d}}}
\def\erve{{\textnormal{e}}}
\def\ervf{{\textnormal{f}}}
\def\ervg{{\textnormal{g}}}
\def\ervh{{\textnormal{h}}}
\def\ervi{{\textnormal{i}}}
\def\ervj{{\textnormal{j}}}
\def\ervk{{\textnormal{k}}}
\def\ervl{{\textnormal{l}}}
\def\ervm{{\textnormal{m}}}
\def\ervn{{\textnormal{n}}}
\def\ervo{{\textnormal{o}}}
\def\ervp{{\textnormal{p}}}
\def\ervq{{\textnormal{q}}}
\def\ervr{{\textnormal{r}}}
\def\ervs{{\textnormal{s}}}
\def\ervt{{\textnormal{t}}}
\def\ervu{{\textnormal{u}}}
\def\ervv{{\textnormal{v}}}
\def\ervw{{\textnormal{w}}}
\def\ervx{{\textnormal{x}}}
\def\ervy{{\textnormal{y}}}
\def\ervz{{\textnormal{z}}}

\def\rmA{{\mathbf{A}}}
\def\rmB{{\mathbf{B}}}
\def\rmC{{\mathbf{C}}}
\def\rmD{{\mathbf{D}}}
\def\rmE{{\mathbf{E}}}
\def\rmF{{\mathbf{F}}}
\def\rmG{{\mathbf{G}}}
\def\rmH{{\mathbf{H}}}
\def\rmI{{\mathbf{I}}}
\def\rmJ{{\mathbf{J}}}
\def\rmK{{\mathbf{K}}}
\def\rmL{{\mathbf{L}}}
\def\rmM{{\mathbf{M}}}
\def\rmN{{\mathbf{N}}}
\def\rmO{{\mathbf{O}}}
\def\rmP{{\mathbf{P}}}
\def\rmQ{{\mathbf{Q}}}
\def\rmR{{\mathbf{R}}}
\def\rmS{{\mathbf{S}}}
\def\rmT{{\mathbf{T}}}
\def\rmU{{\mathbf{U}}}
\def\rmV{{\mathbf{V}}}
\def\rmW{{\mathbf{W}}}
\def\rmX{{\mathbf{X}}}
\def\rmY{{\mathbf{Y}}}
\def\rmZ{{\mathbf{Z}}}

\def\ermA{{\textnormal{A}}}
\def\ermB{{\textnormal{B}}}
\def\ermC{{\textnormal{C}}}
\def\ermD{{\textnormal{D}}}
\def\ermE{{\textnormal{E}}}
\def\ermF{{\textnormal{F}}}
\def\ermG{{\textnormal{G}}}
\def\ermH{{\textnormal{H}}}
\def\ermI{{\textnormal{I}}}
\def\ermJ{{\textnormal{J}}}
\def\ermK{{\textnormal{K}}}
\def\ermL{{\textnormal{L}}}
\def\ermM{{\textnormal{M}}}
\def\ermN{{\textnormal{N}}}
\def\ermO{{\textnormal{O}}}
\def\ermP{{\textnormal{P}}}
\def\ermQ{{\textnormal{Q}}}
\def\ermR{{\textnormal{R}}}
\def\ermS{{\textnormal{S}}}
\def\ermT{{\textnormal{T}}}
\def\ermU{{\textnormal{U}}}
\def\ermV{{\textnormal{V}}}
\def\ermW{{\textnormal{W}}}
\def\ermX{{\textnormal{X}}}
\def\ermY{{\textnormal{Y}}}
\def\ermZ{{\textnormal{Z}}}

\def\vzero{{\bm{0}}}
\def\vone{{\bm{1}}}
\def\vmu{{\bm{\mu}}}
\def\vtheta{{\bm{\theta}}}
\def\va{{\bm{a}}}
\def\vb{{\bm{b}}}
\def\vc{{\bm{c}}}
\def\vd{{\bm{d}}}
\def\ve{{\bm{e}}}
\def\vf{{\bm{f}}}
\def\vg{{\bm{g}}}
\def\vh{{\bm{h}}}
\def\vi{{\bm{i}}}
\def\vj{{\bm{j}}}
\def\vk{{\bm{k}}}
\def\vl{{\bm{l}}}
\def\vm{{\bm{m}}}
\def\vn{{\bm{n}}}
\def\vo{{\bm{o}}}
\def\vp{{\bm{p}}}
\def\vq{{\bm{q}}}
\def\vr{{\bm{r}}}
\def\vs{{\bm{s}}}
\def\vt{{\bm{t}}}
\def\vu{{\bm{u}}}
\def\vv{{\bm{v}}}
\def\vw{{\bm{w}}}
\def\vx{{\bm{x}}}
\def\vy{{\bm{y}}}
\def\vz{{\bm{z}}}

\def\evalpha{{\alpha}}
\def\evbeta{{\beta}}
\def\evepsilon{{\epsilon}}
\def\evlambda{{\lambda}}
\def\evomega{{\omega}}
\def\evmu{{\mu}}
\def\evpsi{{\psi}}
\def\evsigma{{\sigma}}
\def\evtheta{{\theta}}
\def\eva{{a}}
\def\evb{{b}}
\def\evc{{c}}
\def\evd{{d}}
\def\eve{{e}}
\def\evf{{f}}
\def\evg{{g}}
\def\evh{{h}}
\def\evi{{i}}
\def\evj{{j}}
\def\evk{{k}}
\def\evl{{l}}
\def\evm{{m}}
\def\evn{{n}}
\def\evo{{o}}
\def\evp{{p}}
\def\evq{{q}}
\def\evr{{r}}
\def\evs{{s}}
\def\evt{{t}}
\def\evu{{u}}
\def\evv{{v}}
\def\evw{{w}}
\def\evx{{x}}
\def\evy{{y}}
\def\evz{{z}}

\def\mA{{\bm{A}}}
\def\mB{{\bm{B}}}
\def\mC{{\bm{C}}}
\def\mD{{\bm{D}}}
\def\mE{{\bm{E}}}
\def\mF{{\bm{F}}}
\def\mG{{\bm{G}}}
\def\mH{{\bm{H}}}
\def\mI{{\bm{I}}}
\def\mJ{{\bm{J}}}
\def\mK{{\bm{K}}}
\def\mL{{\bm{L}}}
\def\mM{{\bm{M}}}
\def\mN{{\bm{N}}}
\def\mO{{\bm{O}}}
\def\mP{{\bm{P}}}
\def\mQ{{\bm{Q}}}
\def\mR{{\bm{R}}}
\def\mS{{\bm{S}}}
\def\mT{{\bm{T}}}
\def\mU{{\bm{U}}}
\def\mV{{\bm{V}}}
\def\mW{{\bm{W}}}
\def\mX{{\bm{X}}}
\def\mY{{\bm{Y}}}
\def\mZ{{\bm{Z}}}
\def\mBeta{{\bm{\beta}}}
\def\mPhi{{\bm{\Phi}}}
\def\mLambda{{\bm{\Lambda}}}
\def\mSigma{{\bm{\Sigma}}}

\DeclareMathAlphabet{\mathsfit}{\encodingdefault}{\sfdefault}{m}{sl}
\SetMathAlphabet{\mathsfit}{bold}{\encodingdefault}{\sfdefault}{bx}{n}
\newcommand{\tens}[1]{\bm{\mathsfit{#1}}}
\def\tA{{\tens{A}}}
\def\tB{{\tens{B}}}
\def\tC{{\tens{C}}}
\def\tD{{\tens{D}}}
\def\tE{{\tens{E}}}
\def\tF{{\tens{F}}}
\def\tG{{\tens{G}}}
\def\tH{{\tens{H}}}
\def\tI{{\tens{I}}}
\def\tJ{{\tens{J}}}
\def\tK{{\tens{K}}}
\def\tL{{\tens{L}}}
\def\tM{{\tens{M}}}
\def\tN{{\tens{N}}}
\def\tO{{\tens{O}}}
\def\tP{{\tens{P}}}
\def\tQ{{\tens{Q}}}
\def\tR{{\tens{R}}}
\def\tS{{\tens{S}}}
\def\tT{{\tens{T}}}
\def\tU{{\tens{U}}}
\def\tV{{\tens{V}}}
\def\tW{{\tens{W}}}
\def\tX{{\tens{X}}}
\def\tY{{\tens{Y}}}
\def\tZ{{\tens{Z}}}


\def\gA{{\mathcal{A}}}
\def\gB{{\mathcal{B}}}
\def\gC{{\mathcal{C}}}
\def\gD{{\mathcal{D}}}
\def\gE{{\mathcal{E}}}
\def\gF{{\mathcal{F}}}
\def\gG{{\mathcal{G}}}
\def\gH{{\mathcal{H}}}
\def\gI{{\mathcal{I}}}
\def\gJ{{\mathcal{J}}}
\def\gK{{\mathcal{K}}}
\def\gL{{\mathcal{L}}}
\def\gM{{\mathcal{M}}}
\def\gN{{\mathcal{N}}}
\def\gO{{\mathcal{O}}}
\def\gP{{\mathcal{P}}}
\def\gQ{{\mathcal{Q}}}
\def\gR{{\mathcal{R}}}
\def\gS{{\mathcal{S}}}
\def\gT{{\mathcal{T}}}
\def\gU{{\mathcal{U}}}
\def\gV{{\mathcal{V}}}
\def\gW{{\mathcal{W}}}
\def\gX{{\mathcal{X}}}
\def\gY{{\mathcal{Y}}}
\def\gZ{{\mathcal{Z}}}

\def\sA{{\mathbb{A}}}
\def\sB{{\mathbb{B}}}
\def\sC{{\mathbb{C}}}
\def\sD{{\mathbb{D}}}
\def\sF{{\mathbb{F}}}
\def\sG{{\mathbb{G}}}
\def\sH{{\mathbb{H}}}
\def\sI{{\mathbb{I}}}
\def\sJ{{\mathbb{J}}}
\def\sK{{\mathbb{K}}}
\def\sL{{\mathbb{L}}}
\def\sM{{\mathbb{M}}}
\def\sN{{\mathbb{N}}}
\def\sO{{\mathbb{O}}}
\def\sP{{\mathbb{P}}}
\def\sQ{{\mathbb{Q}}}
\def\sR{{\mathbb{R}}}
\def\sS{{\mathbb{S}}}
\def\sT{{\mathbb{T}}}
\def\sU{{\mathbb{U}}}
\def\sV{{\mathbb{V}}}
\def\sW{{\mathbb{W}}}
\def\sX{{\mathbb{X}}}
\def\sY{{\mathbb{Y}}}
\def\sZ{{\mathbb{Z}}}

\def\emLambda{{\Lambda}}
\def\emA{{A}}
\def\emB{{B}}
\def\emC{{C}}
\def\emD{{D}}
\def\emE{{E}}
\def\emF{{F}}
\def\emG{{G}}
\def\emH{{H}}
\def\emI{{I}}
\def\emJ{{J}}
\def\emK{{K}}
\def\emL{{L}}
\def\emM{{M}}
\def\emN{{N}}
\def\emO{{O}}
\def\emP{{P}}
\def\emQ{{Q}}
\def\emR{{R}}
\def\emS{{S}}
\def\emT{{T}}
\def\emU{{U}}
\def\emV{{V}}
\def\emW{{W}}
\def\emX{{X}}
\def\emY{{Y}}
\def\emZ{{Z}}
\def\emSigma{{\Sigma}}

\newcommand{\etens}[1]{\mathsfit{#1}}
\def\etLambda{{\etens{\Lambda}}}
\def\etA{{\etens{A}}}
\def\etB{{\etens{B}}}
\def\etC{{\etens{C}}}
\def\etD{{\etens{D}}}
\def\etE{{\etens{E}}}
\def\etF{{\etens{F}}}
\def\etG{{\etens{G}}}
\def\etH{{\etens{H}}}
\def\etI{{\etens{I}}}
\def\etJ{{\etens{J}}}
\def\etK{{\etens{K}}}
\def\etL{{\etens{L}}}
\def\etM{{\etens{M}}}
\def\etN{{\etens{N}}}
\def\etO{{\etens{O}}}
\def\etP{{\etens{P}}}
\def\etQ{{\etens{Q}}}
\def\etR{{\etens{R}}}
\def\etS{{\etens{S}}}
\def\etT{{\etens{T}}}
\def\etU{{\etens{U}}}
\def\etV{{\etens{V}}}
\def\etW{{\etens{W}}}
\def\etX{{\etens{X}}}
\def\etY{{\etens{Y}}}
\def\etZ{{\etens{Z}}}

\newcommand{\pdata}{p_{\rm{data}}}
\newcommand{\ptrain}{\hat{p}_{\rm{data}}}
\newcommand{\Ptrain}{\hat{P}_{\rm{data}}}
\newcommand{\pmodel}{p_{\rm{model}}}
\newcommand{\Pmodel}{P_{\rm{model}}}
\newcommand{\ptildemodel}{\tilde{p}_{\rm{model}}}
\newcommand{\pencode}{p_{\rm{encoder}}}
\newcommand{\pdecode}{p_{\rm{decoder}}}
\newcommand{\precons}{p_{\rm{reconstruct}}}

\newcommand{\laplace}{\mathrm{Laplace}} 

\newcommand{\E}{\mathbb{E}}
\newcommand{\Ls}{\mathcal{L}}
\newcommand{\R}{\mathbb{R}}
\newcommand{\emp}{\tilde{p}}
\newcommand{\lr}{\alpha}
\newcommand{\reg}{\lambda}
\newcommand{\rect}{\mathrm{rectifier}}
\newcommand{\softmax}{\mathrm{softmax}}
\newcommand{\sigmoid}{\sigma}
\newcommand{\softplus}{\zeta}
\newcommand{\KL}{D_{\mathrm{KL}}}
\newcommand{\Var}{\mathrm{Var}}
\newcommand{\standarderror}{\mathrm{SE}}
\newcommand{\Cov}{\mathrm{Cov}}
\newcommand{\normlzero}{L^0}
\newcommand{\normlone}{L^1}
\newcommand{\normltwo}{L^2}
\newcommand{\normlp}{L^p}
\newcommand{\normmax}{L^\infty}

\newcommand{\parents}{Pa} 

\DeclareMathOperator*{\argmax}{arg\,max}
\DeclareMathOperator*{\argmin}{arg\,min}

\DeclareMathOperator{\sign}{sign}
\DeclareMathOperator{\Tr}{Tr}
\let\ab\allowbreak
 
\usepackage{hyperref}
\usepackage{url}
\usepackage{tikz}
\newif\ifdrafting 
\draftingtrue       
\ifdrafting
\newcommand{\AP}[1]{{\textbf{\color{purple}Alizee: #1}}}
\newcommand{\HY}[1]{{\textbf{\color{RoyalBlue}Hugo: #1}}}
\newcommand{\RK}[1]{{\textbf{\color{red}Rita: #1}}}
\newcommand{\GR}[2]{{\textbf{\color{green}Gunnar: #1\marginpar{#2}}}}
\newcommand{\TODO}[1]{{\textbf{\color{green} TODO: #1}}}
\newcommand{\update}[1]{{\color{RoyalBlue} #1}}

\else
\newcommand{\AP}[1]{}
\newcommand{\HY}[1]{}
\newcommand{\RK}[1]{}
\newcommand{\TODO}[1]{}
\newcommand{\update}[1]{{\color{RoyalBlue} #1}}

\fi





\usepackage[utf8]{inputenc} \usepackage[T1]{fontenc}    \usepackage{hyperref}       \usepackage{url}            \usepackage{booktabs}       \usepackage{amsfonts}       \usepackage{nicefrac}       \usepackage{microtype}      \usepackage{amsmath}
\usepackage{multirow}
\usepackage{graphicx}
\usepackage{subcaption}
\usepackage{comment}
\usepackage{booktabs}
\usepackage{graphicx}
\usepackage{amsthm}
\usepackage{stmaryrd}
\usepackage{wrapfig}
\usepackage{dsfont}
\usepackage{pifont}\newcommand{\cmark}{\ding{51}}\newcommand{\xmark}{\textcolor{lightgray}{\ding{55}}}\DeclareMathOperator{\X}{\mathbf{X}}
\newtheorem{theorem}{Proposition}
\setcitestyle{numbers,open={[},close={]}}
\usepackage{listings}
\newcommand{\fix}{\marginpar{FIX}}
\newcommand{\new}{\marginpar{NEW}}

\lstset{frame=tb,
  language=python,
  aboveskip=3mm,
  belowskip=3mm,
  showstringspaces=false,
  columns=flexible,
  basicstyle={\small\ttfamily},
  numbers=none,
  numberstyle=\tiny\color{gray},
  keywordstyle=\color{blue},
  commentstyle=\color{dkgreen},
  stringstyle=\color{mauve},
  breaklines=true,
  breakatwhitespace=true,
  tabsize=4
}
\definecolor{dkgreen}{rgb}{0,0.6,0}
\definecolor{gray}{rgb}{0.5,0.5,0.5}
\definecolor{mauve}{rgb}{0.58,0,0.82}


\icmltitlerunning{Temporal Label Smoothing }
\begin{document}


\twocolumn[
\icmltitle{Temporal Label Smoothing for Early Event Prediction}


\icmlsetsymbol{equal}{*}
\icmlsetsymbol{co-sup}{+}

\begin{icmlauthorlist}
\icmlauthor{Hugo Yèche}{equal,eth}
\icmlauthor{Alizée Pace}{equal,eth,aic,mpi}
\icmlauthor{Gunnar Rätsch}{co-sup,eth}
\icmlauthor{Rita Kuznetsova}{co-sup,eth}
\end{icmlauthorlist}


\icmlaffiliation{eth}{Department of Computer Science, ETH Zürich, Switzerland}
\icmlaffiliation{mpi}{Max Planck Institute for Intelligent Systems, Tübingen, Germany}
\icmlaffiliation{aic}{ETH AI Center, ETH Zürich,Switzerland}

\icmlcorrespondingauthor{Hugo Yèche}{hyeche@ethz.ch}

\icmlkeywords{Machine Learning, ICML}

\vskip 0.3in
]



\printAffiliationsAndNotice{\icmlEqualContribution}
\begin{abstract}
Models that can predict the occurrence of events ahead of time with low false-alarm rates are critical to the acceptance of decision support systems in the medical community. This challenging task is typically treated as a simple binary classification, ignoring temporal dependencies between samples, whereas we propose to exploit this structure. We first introduce a common theoretical framework unifying dynamic survival analysis and early event prediction. Following an analysis of objectives from both fields, we propose Temporal Label Smoothing (TLS), a simpler, yet best-performing method that preserves prediction monotonicity over time. By focusing the objective on areas with a stronger predictive signal, TLS improves performance over all baselines on two large-scale benchmark tasks. Gains are particularly notable along clinically relevant measures, such as event recall at low false-alarm rates. TLS reduces the number of missed events by up to a factor of two over previously used approaches in early event prediction.









\end{abstract}

\section{Introduction}




Early event prediction (EEP) is a time-series task concerned with determining whether an event will occur within a fixed time horizon. Key to safety-critical operations such as environmental monitoring \citep{DiGiuseppe2016}, EEP is also highly relevant to clinical decision-making, where the deployment of in-patient risk stratification models can significantly improve patient outcomes and facilitate resource planning \citep{sutton2020}. For instance, the National Early Warning Score (NEWS), a simple rule-based model predicting acute deterioration in critical care units, has been demonstrated to reduce in-patient mortality \citep{smith2013, pullyblank2020implementation}. Deteriorating patient signals are often identified by mining large quantities of existing medical data and associated patient outcomes, which has sparked a growing interest in machine learning and medical literature. Applications of such adverse event prediction models include alarm systems for delirium~\citep{wong2018development}, septic shock~\citep{fagerstrom2019lisep}, as well as circulatory or kidney failure in the intensive care unit (ICU)~\citep{hyland2020, tomavsev2019}.

Still, prediction systems often suffer from high false-alarm rates with limited usefulness in a practical context \citep{sutton2020}, despite the development of deep learning architectures addressing issues of high dimensionality, irregular sampling, or informative missingness in time-series~\citep{fagerstrom2019lisep,tomavsev2019,DBLP:conf/icml/HornMBRB20,DBLP:conf/iclr/ShuklaM21}. The typically rare occurrence and noisy definition of events of interest induce challenging, highly imbalanced datasets for model training~\citep{tomavsev2019}, yet early event prediction remains largely considered as a simple binary classification task~\citep{hyland2020, Lauritsen2020, DBLP:conf/icml/HornMBRB20, roy2021multitask}. 

In this work, we systematically study different choices of objective functions for this task and outline a novel, simple, yet best-performing approach to early event prediction. In particular, we argue that leveraging the temporal structure of early event prediction is critical to improving model performance. The dynamic survival analysis (DSA) framework~\citep{van2007dynamic}, for instance, which aims to regress the time until a unique event of interest occurs, enforces structural properties across timepoints and studied horizons~\cite{lee2019dynamic,jarrett2019dynamic}. Inspired by this, we propose to induce monotonicity in model predictions over time with Temporal Label Smoothing (TLS). This novel regularization strategy also mirrors our expected confidence in the strength of prediction signals over time.















\begin{figure}[th] \centering
  \includegraphics[width=0.9\linewidth]{figures/plot_tls_exp_small_jan23.pdf}      
\caption{\textbf{Illustration of temporal label smoothing} for early event prediction. Predictions are carried out over a horizon  and  is the time of the next event, shaded in grey. True labels in black.  controls the smoothing strength of surrogate labels .}
  \label{fig:gamma_TLS}
  \vspace{-1em}
\end{figure}

\vspace{-1em}

\paragraph{Contributions.} The contributions of our work are threefold: 
(i) First, we adapt and benchmark existing approaches from the survival literature to early event prediction, highlighting theoretical similarities between these frameworks. We bridge the gap with prior work \citep{tomavsev2019,van2007dynamic, parast2014landmark}, showing that these enforce temporal structure properties in model predictions. (i) Next, we introduce a simple method to achieve this for our single-horizon prediction framework\footnote[1]{All code is made publicly available at \url{https://anonymous.4open.science/r/tls/}.}.
(iii) Finally, we explore real-world event prediction tasks and demonstrate the performance gains of our method, particularly on clinically relevant metrics. Ablations show that this effectively focuses training on datapoints with a stronger predictive signal.











\begin{table*}[t]
    \centering
    \caption{\textbf{Related work.} Comparison of different relevant training objectives. Early event labels and model predictions at time  are denoted  and , dropping horizon  when fixed. Hazard function labels and predictions are denoted  and . Temporal structure properties are time monotonicity (Eq. \ref{eq:time_monotonous}), horizon monotonicity (Eq. \ref{eq:horizon_monotonous}), and consistency (Eq. \ref{eq:time_consistency}). Additional details are provided in Appendix \ref{appendix:relatedwork}.} \label{tab:related_work}
\begin{tabular}{lccccc}
    \toprule
        \multirow{2}{*}{Training objective} & Previously used  & \multicolumn{3}{c}{Temporal structure} &Loss function, \\  & for event prediction & \hspace*{1mm}(\ref{eq:time_monotonous}) \hspace*{1mm} & \hspace*{1mm}(\ref{eq:horizon_monotonous}) \hspace*{1mm}& \hspace*{1mm}(\ref{eq:time_consistency}) \hspace*{1mm}& summed over label values\\ \midrule 
         Cross-entropy \citep{Lauritsen2020, hyland2020} & \cmark & \xmark & \xmark& \xmark& \\ Balanced cross-entropy \cite{king2001logistic} & \cmark & \xmark & \xmark& \xmark& \\ 

        Focal loss \cite{lin2017,wang2020feature, roy2022disability}  & \cmark & \xmark& \xmark&\xmark & \\ 

        Label smoothing \cite{DBLP:conf/cvpr/SzegedyVISW16}  & \xmark & \xmark & \xmark& \xmark& \\ 

        Multi-horizon prediction \cite{tomavsev2019, jarrett2019dynamic} & \cmark & \xmark& \cmark& \xmark &  \\ \midrule
        Survival analysis likelihood \citep{cox1972,kalbfleisch2011statistical}  & \xmark & \xmark & \cmark& \xmark&  \\
        
        Landmarking \citep{van2007dynamic,parast2014landmark} & \xmark&  \xmark  & \cmark & \cmark &   \\ 

        TCSR \citep{Maystre2022}  & \xmark& \xmark&\cmark & \cmark   &  \\

        \midrule
        \textbf{Temporal label smoothing}  &  \cmark &  \cmark& \xmark & \xmark &  \\ \bottomrule
    \end{tabular}
\end{table*}

\section{Problem formalism and related work}\label{sec:pf_relatedwork}


We start by formalizing the early event prediction task and highlight its similarities and distinctions with survival analysis. After discussing its typical training objectives, we outline some temporal structure properties induced by label definition -- which lead to novel optimization objectives.


\subsection{Early event prediction (EEP)}\label{sec:problem_formalism}

We assume access to a dataset of irregular time series of covariates  and binary event labels  encoding whether an event of interest is occurring at time  in series of index . Each sample is a sequence  of length . In the clinical setting, this could correspond to individual patient trajectories as time series of observations, with labeled events such as organ failure or death. For clarity, we drop index  unless explicitly needed.

For each point  along a time series, the covariates observed up to this point are denoted  and the absolute time of the next event is given by . Our task consists of modeling the probability of this event occurring within a fixed prediction horizon : . In practice, we only access hard, binary labels . Estimates of this event probability, denoted , are typically obtained by maximizing label likelihood through binary classification. As our task focuses specifically on early modeling, no prediction is carried out if the event is currently occurring. 



\paragraph{Comparison to survival analysis.} Both early event prediction and survival analysis are concerned with modeling the occurrence of an event of interest. These tasks differ in their variable of interest when applied to time series. Survival analysis is focused on studying event probability as a function of time-to-event  for a fixed timepoint . It aims at modeling the survival function . Early event prediction, in contrast, is concerned with event probability as a function of time  for a fixed horizon . As a result, for a fixed  and under the assumption of an event occurring only once, we have: . A dynamic survival analysis (DSA) model could therefore be used for EEP, fixing the horizon to that of interest.  This leads to a first experimental question: can the survival objective, which considers all event horizons, improve performance on early event prediction at fixed ?





\subsection{Optimization objectives for EEP} 

We compare relevant training objectives for early event prediction in Table \ref{tab:related_work}, with further detail in Appendix~\ref{appendix:relatedwork}. Prior work on EEP typically focuses on addressing issues of class imbalance through loss reweighting techniques. Static class reweighting was used for sepsis or circulatory failure prediction~\citep{futoma2017learning,hyland2020} through a balanced cross-entropy, which assigns a higher weight to samples from the minority class~\citep{king2001logistic}. Still, performance improvements with this objective remain limited on highly imbalanced prediction tasks~\citep{yeche2021}. In contrast, dynamic reweighting methods such as focal loss and extensions~\citep{lin2017, polyloss} induce a learning bias towards samples with high model uncertainty, typically harder to classify. This approach can improve the prediction of disease progression from imbalanced datasets~\citep{wang2020feature,roy2022disability} but does not consider patterns of sample informativeness over time. Whereas class-imbalance techniques are not designed to account for any temporal structure between samples, these methods give higher importance to positive samples from the minority class, which are located closer to the event.

\subsection{Preserving temporal structure}
\label{sec:temp_structure}
In this section, we highlight how different frameworks for early event prediction or dynamic survival analysis enforce some temporal structure properties induced by the task.

\paragraph{Temporal structure.} Another important distinction must be made between early event prediction and typical classification tasks, in which data is independent and identically distributed (i.i.d.). Both in EEP and in survival analysis, labels are dependent over time. Within a patient stay, the design of our task induces the following temporal structure properties:
 
for . Note that each property can be obtained from the other two.






\paragraph{Temporally structured objectives.} Some early event prediction and survival analysis objectives induce the above structural properties in model predictions.


In multi-horizon prediction (MHP), the EEP framework is modified to output event predictions over multiple horizons~\cite{tomavsev2019,tomavsev2021,roy2021multitask}. Predictions are enforced to be monotonically decreasing over the horizon~\citep{tomavsev2019}, such that if , then , as in Eq. \ref{eq:horizon_monotonous}. This has been shown to improve event prediction performance on the horizon of interest . 


Survival analysis also enforces horizon monotonicity if the survival function is modeled through the hazard function, defined as .
The survival likelihood can then be maximized through binary cross-entropy on the hazard function~\cite{kalbfleisch2011statistical,craig2021survival}, recovering survival as follows: . Equation~\ref{eq:horizon_monotonous} is enforced by the positivity of the hazard. Interestingly, recent works in DSA directly model the survival function~\cite{lee2019dynamic,jarrett2019dynamic}, and lose this temporal inductive bias.


Methods extending survival analysis to the dynamics setting~\cite{van2007dynamic}, where  is allowed to vary, are designed to enforce temporal consistency across horizons (Eq.~\ref{eq:time_consistency} can also be written in terms of the hazard function). 
For each timestep  in the training data, landmarking adjusts the prediction horizon to , learning the hazard distribution for all horizons and timesteps jointly~\cite{van2007dynamic, parast2014landmark}. A parallel can be drawn between multi-horizon prediction in EEP and landmarking in DSA, with a key difference in the likelihood considered: MHP maximizes event prediction probability, whereas landmarking deals with hazards.


Finally, whereas landmarking induces temporal consistency across labels, \citet{Maystre2022} directly enforces consistency across hazard predictions . This can be achieved through dynamic programming, substituting ground truth labels with predictions from following time steps.






Overall, all methods discussed enforce forms of temporal monotonicity or consistency over \textit{horizons} (Eqs. \ref{eq:horizon_monotonous} and  \ref{eq:time_consistency}). In contrast, Equation \ref{eq:time_monotonous} is most relevant to early event prediction, where  is fixed: we propose a training objective explicitly designed to preserve this form of temporal structure.
















\begin{figure*}[t]
    \centering
    \begin{subfigure}[b]{0.45\textwidth}
      \includegraphics[width=\textwidth]{figures/smoothing_time.pdf}\vspace{-0.5em}
      \caption{Parametrization .}
    \end{subfigure} \hspace{1em}
    \begin{subfigure}[b]{0.45\textwidth}
      \includegraphics[width=\textwidth]{figures/step_smoothing_time.pdf}\vspace{-0.5em} \caption{Parametrization .}\label{fig:smoothing_MHP} 
    \end{subfigure}
    \caption{\textbf{Label smoothing strength over time} under different parametrizations, with . Note that  corresponds to the difference in optimum  between the smoothed objective and cross-entropy. The black dashed line represents  this difference for regular label smoothing. Smoothing function  is equivalent to multi-horizon prediction with a unique output.}
    \label{fig:smoothing_strength}
    \vspace{-1em}
\end{figure*}

\section{Temporal label smoothing}\label{sec:TLS} 

We introduce temporal label smoothing, our approach to enforce the structural property most relevant to our task (Eq.~\ref{eq:time_monotonous}). Thanks to prior knowledge of the labels' structure, our approach focuses training on relevant timesteps and overcomes issues with noisy label boundaries. 

Temporal label smoothing substitutes the original label distribution  in the cross-entropy objective with a time-dependent distribution . We constrain this surrogate target to be \textit{monotonically increasing with time}. In practice, as illustrated in Figure~\ref{fig:smoothing_strength}, this increases smoothing strength around the label boundary , reducing prediction certainty in this region, which we show to be prone to high error rates in Section \ref{sec:perf-results}.

Recent work in dynamic survival analysis also proposes to replace labels in the training objective \citep{Maystre2022}, this time with predictions at different time points to enforce temporal consistency (Eq. \ref{eq:time_consistency}). In practice, as demonstrated experimentally in Section \ref{sec:results}, we find this approach to be unstable and to converge poorly on real datasets with long time series and large event horizons. In contrast, we propose to replace labels with a prediction-independent distribution fixed \textit{a priori}, and thus less prone to optimization challenges. 

\paragraph{Smoothing parametrizations.} We propose various temporal smoothing parametrizations for  in Appendix \ref{appendix:temporal_smoothing_fn}. Experimental results suggest that an exponential parametrization, defined as follows, performs best on considered tasks. 
Parameters  and  define the time range over which we apply smoothing, namely , . Under this constraint, parameters  are defined to enforce  to be continuous at boundary points (see Appendix \ref{appendix:temporal_smoothing_fn}). Finally,  controls the smoothing strength at a given time. 

\subsection{Link with label smoothing}
A comparison must be drawn with label smoothing~\citep{DBLP:conf/cvpr/SzegedyVISW16} which replaces binary cross-entropy labels  with a smooth version  between 0 and 1. By shifting the optimum from  to , label smoothing prevents models overconfidence, which could improve robustness against the noisy nature of event prediction \citep{DBLP:conf/icml/LukasikBMK20, DBLP:conf/nips/MullerKH19}. Still, despite recent extensions \cite{DBLP:conf/aistats/LiDB20,DBLP:conf/acl/MeisterSC20,DBLP:conf/aaai/LienenH21}, label smoothing remains designed for i.i.d. classification problems. Based on prior knowledge of the temporal structure in our task, our approach also modulates smoothing as a function of time. To the best of our knowledge, we are the first work to introduce a temporal dependence to label smoothing. 

\subsection{Link with multi-horizon prediction}\label{sec:link_mhp}

Temporal label smoothing effectively adapts the contribution of each sample to reflect prior knowledge about the structure of event prediction labels. Under simplifying assumptions justified empirically in Section \ref{sec:Ablations}, we show that MHP can be seen as a special case of temporal label smoothing.  Unlike this method, TLS does not require any architectural change. 




\begin{theorem}
\label{prop:MHP}
Under the assumption that model outputs are \textbf{equal} for all horizons  (rather than monotonically increasing), MHP is equivalent to temporal label smoothing parameterized with :
\end{theorem}
\begin{comment}\begin{figure}
    \centering
    \includegraphics[width=0.36 \textwidth]{figures/step_smoothing_time.pdf}
    \caption{\textbf{Label smoothing strength over time}, with staircase parametrization and .}
    \label{fig:smoothing_MHP}
\end{figure}
\end{comment}
\begin{proof} See Appendix \ref{appendix:MHP_link}.\end{proof}

Proposition~\ref{prop:MHP} frames MHP as a special case of TLS with parametrization . This function is defined as a sequence of step functions in time and is illustrated in Figure \ref{fig:smoothing_MHP}. 


\section{Experimental setup}\label{sec:exp_setup}
\subsection{Early prediction tasks} \label{sec:tasks}

We demonstrate the effectiveness of our method on different clinical early prediction tasks to understand its added value. These tasks are established in existing literature and published benchmarks and deal with electronic health records from the ICU, where early prediction of organ failure or acute deterioration is critical to patient management~\citep{sutton2020}. Clinical events are labeled following internationally accepted criteria \citep{harutyunyan2019multitask, yeche2021}. 

Our work is first evaluated on the prediction of acute circulatory failure within the next  hours, as defined in the HiRID-ICU-Benchmark (HiB)~\citep{yeche2021}. This task is based on the publicly available HiRID dataset~\citep{hyland2020}, containing high-resolution observations of over 33,000 ICU admissions. We also investigate early prediction of patient mortality, or \textit{decompensation}, within a horizon of  hours -- a widely studied task in the machine learning literature~\citep{bellamy2020evaluating}. We use the framework defined in the MIMIC-III Benchmark (M3B) \citep{harutyunyan2019multitask} for the MIMIC-III dataset~\citep{johnson2016}, counting approximately 40,000 patient stays. Positive label prevalence is 4.3\% and 2.1\% of time points for circulatory failure and decompensation prediction respectively. Further details on task definition and data pre-processing are provided in Appendix~\ref{appendix:dataset_details}.

\paragraph{Alternative tasks.} To investigate a third clinical event prediction task, we also considered predicting respiratory failure in intensive care patients~\citep{yeche2021}. Unfortunately, ambiguous labeling led to close to random performance for all considered methods. Instead, we benchmarked TLS and baselines on a subtask with better defined labels, prediction of the onset of mechanical ventilation and reached similar conclusions to other tasks in Section~\ref{sec:results}. Experimental details are included in Appendix~\ref{appendix:resp}.




















\subsection{Benchmarking strategy}
\paragraph{Baselines.} We quantify the added value of our method by comparing its performance to alternative learning approaches used for early event prediction (EEP) and dynamic survival analysis (DSA), discussed in Section~\ref{sec:pf_relatedwork}. 
Our first baselines consist of {balanced cross-entropy} \citep{king2001logistic} and {focal loss} \citep{lin2017}, popular sample reweighting methods for imbalanced tasks.
We also implement {multi-horizon prediction} as a multi-output model trained to predict event occurrence over different horizons between  and . Note that for a fair comparison, we set  in TLS. As in \citet{tomavsev2019}, a cumulative distribution function layer on logits enforces the monotonicity of predictions (Eq.~\ref{eq:horizon_monotonous}). We also compare to DSA objectives, with landmarking~\citep{van2007dynamic} and the recently proposed TCSR~\citep{Maystre2022}.
Finally, we also compare our method to conventional label smoothing~\citep{DBLP:conf/cvpr/SzegedyVISW16} to confirm that our method's performance can be attributed to its temporal dependency.

\paragraph{Architecture choice.} As our method and baselines are model-agnostic and only vary in terms of optimization objective, a unique model architecture is used for each task, selected through a random search on cross-entropy validation performance. Following a published benchmark on the HiRID dataset \citep{yeche2021}, we use a GRU \citep{DBLP:journals/corr/ChungGCB14} architecture for the {circulatory failure} task. For {decompensation} prediction, transformers \citep{DBLP:conf/nips/VaswaniSPUJGKP17} outperform the LSTM-based models \citep{hochreiter1997long} originally proposed in the M3B benchmark \citep{harutyunyan2019multitask}, and are thus used in our work. As recommended by \citet{tomavsev2019}, we apply -regularization to input embedding layers, which improves performance on both tasks. 

Hyperparameters introduced by baselines or by our method, such as strength term~ in smoothing parametrization , are optimized through grid searches on the validation set. Further implementation details are provided in Appendix \ref{appendix:implementation_details}.


\subsection{Evaluation metrics}
To account for the highly imbalanced nature of clinical early prediction tasks, the area under the precision-recall curve (AUPRC) provides more insight than the area under the receiver operating characteristic curve (AUROC): under a low prevalence of positive samples, precision is more sensitive to false alarms than specificity \citep{saito2015precision}. Still, "area under the curve" metrics can be poorly representative of clinical usefulness, as improvements in low precision regions can dominate such global metrics but remain incompatible with the low false alarm rates required for clinical deployment. Thus, to better assess model performance in this context, we also measure performance at a clinically motivated operating point through recall at 50\% precision ~\cite{tomavsev2021}. To ensure that conclusions made for this operating point also hold at higher precision constraints, we also plot full precision-recall curves. 

In addition to \textit{timestep-level} metrics, which measure prediction performance at each data point, we also evaluate models in an event-based approach~\cite{hyland2020,tomavsev2019}. Following \citet{tomavsev2019}'s definition, an event prediction is positive if the model outputs a positive prediction at any time over the  hours before the event. The threshold defining a positive prediction is chosen based on a precision lower bound. We also use a stepwise criterion with a 50\% precision. This allows us to measure the event recall of our approach in comparison to published baselines. Unless stated otherwise, we always report mean performance with 95\% confidence intervals on the mean computed over ten training runs.

\begin{figure}[hbt]
    \centering
    \includegraphics[width=0.45\textwidth]{figures/recall_decay.pdf}
    \caption{\textbf{Comparison of naive performance as a function of time} on both tasks using cross-entropy. Events should be predicted at a horizon  from an event at time . Performance is reported at time increments .}
    \label{fig:tasks_perf_v_time}
\end{figure}


\begin{table*}[t] \centering
    \caption{\textbf{Performance of different training objectives for early prediction.} Recall is reported at a 50\% timestep-level precision. {In \textbf{bold}, we highlight best-performing methods with statistically significant -values () under paired Student's t-tests~\citep{student1908probable}} compared with the next-best method marked italic (last row). Note that cross-entropy is a special case of weighted cross-entropy and focal loss, which performs best in this setting. Hence, the first three lines are identical.}
    \label{tab:perf_results}
\resizebox{\textwidth}{!}{\begin{tabular}{lcccccc}
\toprule

 Task & \multicolumn{3}{c}{Circulatory Failure (HiRID)} & \multicolumn{3}{c}{Decompensation (MIMIC-III)} \\
 \cmidrule(lr){2-4} \cmidrule(lr){5-7}
Training objective &         AUPRC & Timestep  Recall & Event Recall &        AUPRC &  Timestep Recall &Event Recall \\
\midrule
Cross-entropy   \citep{Lauritsen2020, hyland2020}     &             39.1  0.4 &             29.3  0.9 &   82.8  1.3 &        34.5  0.4 &             28.2  0.5 & 69.7  1.0\\
Weighted CE  \cite{king2001logistic} &             39.1  0.4 &             29.3  0.9 &  82.8  1.3  &         34.5  0.4 &             28.2  0.5 & 69.7  1.0 \\
Focal loss  \cite{lin2017,wang2020feature, roy2022disability} &             39.1  0.4 &             29.3  0.9 & 82.8  1.3 &            34.5  0.4 &             28.2  0.5 & 69.7  1.0\\
Label smoothing \citep{DBLP:conf/cvpr/SzegedyVISW16}      &             39.3  0.4 &             29.9  0.8 &     83.8  1.3 &       33.9  0.3 &             27.7  0.5 & 68.8  1.0 \\
Multi-horizon \citep{tomavsev2019,jarrett2019dynamic} &             {\it 39.6}  0.5 &             {\it 30.3}  1.0 & 85.2  1.7      &      {\it 34.9}  0.3 &             {\it 28.6}  0.5 & {\it 70.3}  0.6 \\\midrule
 Landmarking \cite{van2007dynamic,parast2014landmark} &             {\it 39.6}  0.3 &           30.1  0.6 & {\it 89.1}  0.8&   34.0  0.5 &           27.2  0.6 &  68.8  1.1 \\
 TCSR \cite{Maystre2022} &         36.0   0.4  &	26.5   0.8  &  89.0  2.1&  28.6  1.2 &           19.9  1.4 & 68.4  1.0\\
\midrule
\textbf{Temporal label smoothing}     &    0.3 &    0.7 & \textbf{92.5}  0.5 &  0.3 &    0.4 & \textbf{71.8}  0.8\\
\midrule
{-value}  & \textbf{0.002} & \textbf{0.004}  &  \textbf{<0.001} & \textbf{0.004} & {\textbf{0.02}}  &  \textbf{0.002}\\
\bottomrule
\end{tabular}}
\end{table*}

\section{Results}\label{sec:results}

In this section, we validate the following claims: (1) temporal label smoothing yields practical performance improvement along clinically-motivated metrics, and (2) achieves this by leveraging temporal structure and modulating prediction confidence as a function of event proximity.

\subsection{Prediction performance}\label{sec:perf-results}

Overall, our results highlight that TLS improves performance over other approaches proposed to address the challenges of early clinical prediction. We occasionally focus on circulatory failure prediction for brevity; see Appendix~\ref{appendix:add_exp} for similar conclusions on decompensation.


\paragraph{Necessity of temporal inductive biases.} As visualized in Figure~\ref{fig:tasks_perf_v_time}, training EEP as a simple binary classification with a cross-entropy objective shows a reduction in recall between event time  and prediction horizon . This suggests a weakening in the discriminative signal associated with events and an increase in noise close to the label boundary, where performance is the poorest. In fact, we argue that correct predictions in this region, close to , are not as critical as ones near : missing an imminent event is more severe. Mirroring the decrease in both signal strength and clinical importance of predictions as the time-to-event increases, model confidence should also decrease, focusing instead on more critical time windows.





\begin{figure}[h]
\centering
    \centering
    \includegraphics[width=0.9\linewidth]{figures/gridsearch_focal_CIRC_VAL_final.pdf}
\caption{\textbf{Performance loss with class reweighting methods} on circulatory failure prediction (validation). Balanced cross-entropy corresponds to .}
\label{fig:focal+weighted}
\end{figure}

\paragraph{Timestep-level performance.} In Table \ref{tab:perf_results}, we find TLS to outperform baselines across all metrics for circulatory failure and decompensation\footnote{Despite overlapping confidence intervals between multi-horizon and TLS on decompensation due to individual training run variability, we can reject the null hypothesis that MHP has a higher performance than our method (-values )}. The full precision-recall curve of models trained with the best objectives is shown in Figure \ref{fig:PR_curve}: TLS improves recall for all precision thresholds beyond 50\%, a low false-alarm region of particular clinical relevance~\citep{sutton2020}.

\begin{figure*}[t]
\centering
\begin{subfigure}[b]{0.46\textwidth}
  \centering
  \includegraphics[width=\linewidth]{figures/plot_event_level_circ.pdf}
  \caption{\centering Event-level performance for a 50\% timestep-level precision threshold.} \label{fig:event-based}
\end{subfigure}
\begin{subfigure}[b]{0.46\textwidth}
 \centering
  \includegraphics[width=\linewidth]{figures/plot_auprc_circ.pdf}
  \caption{\centering Precision-recall curve. Inset shows the clinically-applicable region with precision \%.}
  \label{fig:PR_curve}
\end{subfigure}
\caption{\textbf{Clinically-oriented performance analysis} of different training objectives on circulatory failure prediction (CE: cross-entropy, MHP: multi-horizon prediction, TLS: temporal label smoothing).}

\label{fig:clinical_performance_circ}
\end{figure*}

In contrast, loss reweighting methods designed to tackle class imbalance were found to reduce performance on all tasks over traditional cross-entropy, as shown in Figure~\ref{fig:focal+weighted}. For weighted cross-entropy, we attribute it to the increase in false alarms resulting from the drive to improve recall. This further reduces the low precision of all models, thus negatively affecting the AUPRC. On the other hand, focal loss down-weighs confident samples in training, constraining the model to focus on samples with uncertain predictions. In the context of noisy labeling, as is the case close to our class boundary, data points with ambiguous signals cannot be correctly predicted and thus dominate the loss, impeding improvements in other regions of input space. We analyze model performance over time in Section~\ref{sec:Ablations} to further support this hypothesis.


\paragraph{Empirical comparison to dynamic survival analysis.} Despite the similarities between the tasks of early event prediction and dynamic survival analysis, survival objectives were not found to markedly improve performance on the former, as shown in the second block of Table \ref{tab:perf_results}. A likely explanation for this is that the survival likelihood is trained to predict events potentially occurring at horizons much greater than that of interest in EEP. As signal strength decreases with the time-to-event, errors from distant events dominate the loss -- leading to poor performance on long time series. This finding goes in the direction of recent works \cite{jarrett2019dynamic,lee2019dynamic} in dynamic survival analysis, which train a fixed (multi-)horizon model as in EEP. 


Finally, the prediction-dependent label smoothing in TCSR~\citep{Maystre2022}, designed to improve survival performance on short-sequence survival tasks, did not improve performance our EEP tasks either. Training was found to be unstable due to error propagation over long sequences.





\paragraph{Clinically relevant performance.} As highlighted in Figure \ref{fig:event-based}, TLS improves performance over other training objectives in predicting overall adverse event episodes throughout a stay. For circulatory failure, temporal label smoothing is able to predict 7.4\% more events than the closest baseline designed for EEP (multi-horizon prediction): this corresponds to reducing the number of missed events by a factor of 2, from 303 to 152 out of 2045 events in the test set on average. Within the events captured by TLS but not by MHP, models trained with our objective predict them on average 104 minutes before their occurrence, giving clinicians sufficient time to take action and avoid patient degradation. We also note here the benefit of adapting dynamic survival analysis to the EEP setting, with landmarking and TCSR performing best in circulatory failure event recall, after TLS. As these methods also enforce temporal structure, this result further motivates our approach, which achieves even greater performance gains, and suggests promise in using survival likelihood objectives for early event prediction. 


\subsection{Illustrative insights}
\label{sec:Ablations}

We propose ablations to build intuition around our proposed method. In particular, we aim to understand how temporal smoothing works and why it outperforms other training approaches for early prediction tasks.

\begin{table*}[t]
    \centering
    \caption{\textbf{Do MHP's multiple outputs improve performance over TLS with ?} We provide -values for the paired Student-t test \citep{student1908probable} on the null hypothesis :MHP  TLS. With no statistically significant improvements (), we justify our assumption in Proposition~\ref{prop:MHP}.} \label{tab:ablation_MHP_step}
\footnotesize
\begin{tabular}{lcccccc}
\toprule
Task & \multicolumn{3}{c}{Circulatory Failure (HiRID)} & \multicolumn{3}{c}{Decompensation (MIMIC-III)} \\
 \cmidrule(lr){2-4} \cmidrule(lr){5-7}
Training objective &         AUPRC & Timestep  Recall & Event Recall &        AUPRC &  Timestep Recall &Event Recall \\
\midrule
MHP &             39.6  0.5 &             30.3  1.0 & 85.2  1.7      &      34.9  0.3 &            28.6  0.5 & 70.3  0.6  \\
TLS ()                  &             39.3  0.2 &             29.4  0.8 & 
83.4  1.2 &         35.2  0.3 &             29.2  0.4 &      70.4  0.7    \\ \midrule
p-value ()     &                       0.11 &                       0.10 &      \textbf{0.03}  &             0.95 &                       0.97 &      0.40 \\
\bottomrule
\end{tabular}\end{table*}


\paragraph{Empirical comparison to multi-horizon prediction.} In our theoretical discussion in Section \ref{sec:link_mhp}, we demonstrated how MHP is a restriction of label smoothing with a step function . This claim relies on the constraint to produce a unique prediction across all considered horizons, reflecting the design of our method. We verify the impact of this assumption by measuring performance gains afforded by learning distinct predictions per horizon. As shown in Table~\ref{tab:ablation_MHP_step}, we only find statistical evidence for slight performance gain over using  on event recall for circulatory failure. Thus, models do not appear to leverage this additional flexibility offered by MHP. With superior results on all event- and timestep-based experiments, and a simpler implementation, we find temporal label smoothing to be a superior training objective to MHP in early prediction tasks.


\paragraph{Performance over time.} To better understand the mechanism of action of TLS, we study the difference in performance between TLS and the cross-entropy objective over time in Figure~\ref{fig:plot_delta}. TLS results in a significant increase in true positive and negative rates when prediction time is far from the label boundary ( or ). In particular, the performance gains close to the event time  explains the better recall of imminent events in Figure~\ref{fig:event-based}.

\begin{figure}[h]
\begin{subfigure}[b]{0.47\textwidth}
  \centering
  \includegraphics[width=\linewidth]{figures/plot_delta_tnr_circ_v4.pdf}\caption{True negative rate (TNR).}
  \label{fig:delta_tnr_circ}
\end{subfigure} \hfill
\begin{subfigure}[b]{0.47\textwidth}
 \centering
  \includegraphics[width=\linewidth]{figures/plot_delta_tpr_circ_v4.pdf}\caption{True positive rate (TPR).}
  \label{fig:delta_tpr_circ}
\end{subfigure}
\caption{\textbf{Performance improvement over time} for TLS over cross-entropy on circulatory failure.
Timestep-level metrics computed for precision of  over two-hour bins.}
\label{fig:plot_delta}
\end{figure}


In contrast, the prediction model trained with TLS is less competitive where smoothing is strongest, near , but, as expected, this performance loss remains minor. This result validates our hypothesis that the signal is too noisy in the boundary region for any model to recover the original label distribution. From a clinical perspective, errors made in the boundary region are less critical, as they result in the latest false positives or earliest false negatives. Overall, TLS not only improves global event prediction performance but allows these gains to occur at more critical times for clinicians.



\section{Conclusion}


Early event prediction is paramount to the development of clinical decision support systems, with a demonstrated potential to improve patient outcomes \citep{smith2013}. Still, this task remains relatively poorly studied in the machine learning literature, with few training solutions tailored to address its challenges or to exploit its intrinsic temporal structure. We demonstrate that this can be achieved by adapting and significantly improving approaches from the survival analysis literature~\citep{van2007dynamic, parast2014landmark}. This also motivates us to design a simple, yet top-performing training framework that leverages the structure of event signals over time. We show that multi-horizon prediction, a heuristic used to improve early prediction, can be formalized as a realization of our framework. 

{\it Temporal label smoothing empirically outperforms all considered baselines} on various tasks and datasets, {\it with significant improvements} in clinically-relevant evaluation metrics. Our ablation studies show that it effectively focuses training on data points with a stronger predictive signal.





Promising avenues of further work include combining TLS with survival objectives and using temporal label smoothing for survival regression tasks, to explore the relative benefits of different temporal inductive biases. Looking ahead, we expect that temporal label smoothing will be leveraged to develop more clinically reliable systems for risk prediction of infrequent adverse events. Further research on tailored machine learning solutions to improve real-world decision support holds promise for better clinical care and operations management.


\newpage
\bibliographystyle{unsrtnat}
\bibliography{references}

\appendix
\newpage
\onecolumn



\section{Theoretical details} 

\subsection{Multi-Horizon prediction: proof of Proposition \ref{prop:MHP}}
\label{appendix:MHP_link}
\paragraph{Equivalency between MHP and TLS objectives.}
Recalling the formalism of multi-horizon prediction outlined in Section~\ref{sec:link_mhp}, true labels and model predictions at time  can be rewritten as  and , where  is the number of horizons considered. The training objective for this datapoint becomes:
    

The assumption that   is \textbf{equal} for all  allows to rewrite the objective as follows:
    
with  being the common prediction shared across all horizons. This equation can now be viewed as a temporal label smoothing objective with smoothed labels :
    
    
\paragraph{Smoothing parametrization.}
Next, we aim to recover the explicit form of . Without loss of generality, we assume that horizons  are in ascending order. The temporal dependency between samples, formalized in Equation~\ref{eq:time_monotonous}), results in the following relationship between predictions at horizons  and  :


Thanks to the above property, we can determine  by studying three cases of multi-horizon labels, illustrated in Figure \ref{fig:appendix_MHP}. For notational simplicity, we define the time-to-event as .

\begin{figure}[h]
    \centering
    \includegraphics[width =0.9\linewidth]{figures/appendix_MHP.pdf}
    \caption{\textbf{Label values for multi-horizon prediction}, and conversion to smoothed labels .}
    \label{fig:appendix_MHP}
\end{figure}
\definecolor{lightgreen}{HTML}{2ca02c}
\definecolor{tabblue}{HTML}{1f77b4}
\definecolor{tabred}{HTML}{d62728}
\textcolor{lightgreen}{\textbf{Case 1: }.}\\
From label definition. we have that  if . As  is the smallest horizon, following Equation~\ref{eq: mhp_predictions_order_1}, we have . We can rewrite the objective as:
    
where .

\textcolor{tabred}{\textbf{Case 2: }.} \\
Similarly, if , then  which implies  from Equation~\ref{eq: mhp_predictions_order_0}. The objective can be rewritten as:
    
where .

\textcolor{tabblue}{\textbf{Case 3: }.}\\
Following the same reasoning as in the first two cases, we now have a specific index  which separates positive and negative labels. We have  and . This allows to rewrite the objective as follows:
    
where


This defines a new smoothing parametrisation : 

Thus, , we find that  when smoothed labels are defined as . This concludes our proof. \hfill \qedsymbol

\subsection{Temporal label smoothing functions}
\label{appendix:temporal_smoothing_fn}

\begin{figure}[h]
\centering
\begin{subfigure}{0.49\textwidth}
  \centering
  \includegraphics[width=\linewidth]{figures/plot_tls_shift.pdf}
  \caption{\centering {}} \label{fig:qshift}
\end{subfigure}
\hspace{2pt}
\begin{subfigure}{0.49\textwidth}
  \centering
  \includegraphics[width=\linewidth]{figures/plot_tls_step.pdf}
  \caption{\centering  and }
  \label{fig:step_TLS}
\end{subfigure}
\vspace{0.5em}

\begin{subfigure}{0.49\textwidth}
  \centering
  \includegraphics[width=\linewidth]{figures/plot_tls_concave.pdf}
  \caption{{\centering }} \label{fig:concave}
\end{subfigure}
\hspace{2pt}
\begin{subfigure}{0.49\textwidth}
  \centering
  \includegraphics[width=\linewidth]{figures/plot_tls_sigmoid.pdf}
  \caption{\centering \centering }
  \label{fig:sigmoid_TLS}
\end{subfigure}
\caption{\textbf{Illustration of temporal label smoothing} with alternative smoothing parametrizations.} \label{fig:TLS_other}
\end{figure}

Motivated by prior work \citep{tomavsev2019, cox1972}, we compare the performance of various smoothing functions . All proposed parametrizations are continuous and monotonous increasing functions that satisfy boundary conditions  and . As evidenced in Table \ref{tab:other_fn}, we find exponential label smoothing to perform best or as well as others across all tasks and metrics. {Performance as a function of hyperparameter setting can be visualized in Figure \ref{fig:smoothing_hyperparams}. All model and hyperparameter selection were carried out on the validation set, including the final choice of parametrization function.
}


\begin{figure}[h]
\centering
\begin{subfigure}[b]{0.9\textwidth}
  \centering
  \includegraphics[width=\linewidth]{figures/hp_search_circ.pdf}
  \caption{\centering {Circulatory failure.}} 
  \label{fig:smoothing_hypers_circ}
\end{subfigure}
\vspace{0.5em}
\begin{subfigure}[b]{0.9\textwidth}
  \centering
    \includegraphics[width=\linewidth]{figures/hp_search_decomp.pdf}
  \caption{\centering {Decompensation.}} 
  \label{fig:smoothing_hypers_decomp}
\end{subfigure}
\caption{{\textbf{Validation AUPRC performance of temporal label smoothing as a function of smoothing hyperparameters}, with different smoothing parameterizations. (Left) Performance for different smoothing strengths  with ; (Right)  Performance for different prediction horizons  with  smoothing.}} \label{fig:smoothing_hyperparams}
\end{figure}
\begin{comment}
    \vspace{0.5em}
\begin{subfigure}[b]{0.9\textwidth}
  \centering
    \includegraphics[width=\linewidth]{figures/hp_search_resp.pdf}
  \caption{\centering {Respiratory failure.}} 
  \label{fig:smoothing_hypers_resp}
\end{subfigure}
\end{comment}


\begin{table}[h] \centering
    \caption{\textbf{Performance of different smoothing functions on early prediction tasks.} Timestep-level recall is reported at a 50\% precision.} \label{tab:other_fn}
\begin{tabular}{lcccc}
\toprule

 Task & \multicolumn{2}{c}{Circulatory Failure} & \multicolumn{2}{c}{Decompensation} \\
 \cmidrule(lr){2-3} \cmidrule(lr){4-5}
Method &         AUPRC &   Recall &         AUPRC &   Recall \\
\midrule
              &             39.3  0.2 &             29.4  0.8 &             35.2  0.3 &             29.2  0.4  \\
{} & {} & {} & {34.5  0.4} &  {28.2  0.5}  \\
      &  39.4  0.3 &             29.7  0.8 &             35.1  0.4 &             29.2  0.6  \\
     & 39.4  0.3 &             29.7  0.8 &             34.9  0.4 &             28.8  0.5 \\
{}      &  {39.4  0.3} &             {29.7  0.8} &             {35.1  0.4} &             {29.2  0.6}  \\
   &    0.3 &    0.7 &    0.3 &    0.4  \\
\bottomrule
\end{tabular}\end{table}

{
\paragraph{Shifted boundary labels.}
Shifting the prediction horizon or label boundary in training can be viewed as a form of temporal label smoothing, in which class labels are inverted within a prediction window of interest. This defines the following smoothing parametrization :

where  is a hyperparameter controlling the horizon of the smoothed labels ( corresponds to cross-entropy training). The strength of this smoothing function is illustrated in Figure~\ref{fig:qshift}.

Figure \ref{fig:smoothing_hyperparams} outlines the performance of this alternative smoothing parametrization as a function of . For decompensation, shifting the label boundary closer to the event time decreases performance. On circulatory failure, performance does improve over traditional cross-entropy training as the label horizon is brought closer to the event of interest, which can be interpreted as an inductive bias similar to that induced by the exponential smoothing function.

}

\paragraph{Linear label smoothing.}
The most straightforward extension to the step function  described in Section~\ref{sec:link_mhp} is a linear label smoothing corresponding to the case .\\
Our parametrization  is thus defined as follows:

We illustrate the impact of the number of steps  in Figure~\ref{fig:step_TLS}.

\paragraph{Sigmoidal label smoothing.}
Another natural direction to explore is to smooth labels starting from the true distribution, a unique step function at . This can be achieved by defining  as a generalized logistic function \citep{richards1959flexible}:



where ,  and  are three constants fixed by imposing the boundary conditions at  and , as well as . This yields:


As shown in Figure~\ref{fig:sigmoid_TLS},  controls the smoothing strength, interpolating between the true distribution \ as  and  when .


\paragraph{Exponential label smoothing.}
The smoothing function we find to perform best is the exponential decay one. This idea is motivated by survival analysis, where patient survival probability can be modeled as the exponential decay of a cumulative hazard function \cite{cox1972, collett2015modelling}. In practice, as defined in Section~\ref{sec:TLS}, our exponential smoothing function  is defined as follows:


where parameters  are set to satisfy boundary conditions:


Here,  also controls the smoothing strength between  when  and  when .

{Overall, despite  achieving good results on circulatory failure,  statistically outperforms this smoothing parameterization for both tasks on validation metrics. An interesting avenue for further work would be to combine exponential smoothing with the boundary shift approach, or effectively change , which was fixed to  in our work for a fair comparison to multi-horizon prediction.}




\paragraph{Concave exponential label smoothing.}

Finally, to mirror the behavior of the exponential smoothing function away from linear interpolation and investigate its effect on performance, we designed the following concave smoothing function :

Parameters  are identical to the convex smoothing function parameters, set to satisfy boundary conditions. The strength of this concave smoothing function is illustrated Figure \ref{fig:concave}.

No performance gains were obtained through temporal label smoothing with a concave function, as shown in Figure \ref{fig:smoothing_hyperparams}. This smoothing function effectively penalizes false positives harder than false negatives, which is less adapted to our tasks of interest (in contrast to the convex ). As a result, the best-performing concave parametrization is consistently obtained with the lowest value of , closer to a linear function choice.



\subsection{Related time-series tasks} \label{appendix:related_tasks}

\begin{comment}
    

\paragraph{Comparison to survival analysis.} 
\TODO{}
Survival analysis consists of statistical methods concerned with predicting the probability of a certain event taking place over time \citep{collett2015modelling}. In our formalism outlined in Section \ref{sec:problem_formalism}, the corresponding task is to regress the time of the next event  based on patient information accumulated up to time . To recover early event prediction, a threshold on the hazard model can thus be applied to determine whether an event will happen within our horizon of interest . Modeling constraints imposed in survival analysis improve time-to-event prediction performance over traditional regression methods, which supports our approach to leverage the temporal structure of our comparable task. Interestingly, recent developments in survival modeling to deal with dynamic predictions have been addressed with multi-horizon prediction \citep{jarrett2019dynamic}.

Still, distinctions must be highlighted between our adverse event prediction problem and the typical experimental setup for survival analysis: in our case, multiple events can occur over the course of a patient's stay, with unknown patient states during and immediately after event occurrence. This results in complex, informative censoring patterns and challenges common assumptions in survival analysis, which can therefore not be directly applied to our task.
\end{comment}

{ \paragraph{Comparison to early time-series classification.} 

A distinction must be drawn between our task of early event prediction and that of early time-series classification. The latter has been more extensively explored in the literature \citep{Xing2009,He2013,Yang2021dir}, but addresses a distinct problem. 

Considering a time series up to timestep , early event prediction is concerned with classifying \textit{whether} a particular event will occur between  and , for a fixed horizon . Predictions are made at each timepoint over the entire time series: as multiple samples arise from the same time series and therefore depend on one another over time, these should not be considered as i.i.d.

In contrast, early classification of time series aims to regress \textit{the first timepoint}  at which a label for the entire time series can be predicted with a desired accuracy~\citep{Xing2009}. A single prediction is made, as soon as possible, for the entire series -- which can be considered an independent sample from the dataset of time series. This latter task can be framed as an early prediction of the event “prediction is possible”, where , given a separate time-series classifier. As a result, an interesting avenue of further work would be to apply temporal label smoothing to the latter task.

On the other hand, early event prediction cannot be translated into a simple early classification problem. As a result, methods designed for early time-series classification are therefore not applicable to this problem setting. 

}

\subsection{EEP Objective Functions} \label{appendix:relatedwork}

In this section, we clarify the mathematical formalism behind our EEP baselines to facilitate comparison to temporal label smoothing. Most baselines explored effectively propose a modification of the cross-entropy objective often used for binary classification tasks, .

\paragraph{Weighted cross-entropy.} To facilitate learning from highly imbalanced datasets, a common adjustment to the training objective consists of reweighting terms in the cross-entropy objective:

where hyperparameter  determines the contribution of each class to the loss. Balanced cross-entropy is a special case of this objective, where weights are based on the prevalence of each class ( is set as the inverse of the proportion of positive labels). Regular cross-entropy corresponds to the case where .


\paragraph{Focal loss.} Denoting our output prediction as , the focal loss objective for binary classification of target  is a variant on the balanced cross-entropy loss:

where  is a balancing weight for class  and  is the focal loss weight.


\paragraph{Multi-horizon prediction.} As highlighted in Section \ref{sec:link_mhp}, multi-horizon training can be formalized as the following objective:
    
where true labels and model predictions are given by  and , for  distinct horizons.

\paragraph{Label smoothing.} As introduced by \citet{DBLP:conf/cvpr/SzegedyVISW16}, label smoothing consists of substituting the original label distribution  in the cross-entropy objective  by a smoothed version . This surrogate distribution over classes  is defined as follows :

In the original approach,  is uniform and  controls the smoothing strength. By shifting the minimum of the objective function away from , labels smoothing prevents the model from becoming overconfident during training. Alternative designs for  have been proposed \citep{DBLP:conf/aistats/LiDB20,DBLP:conf/acl/MeisterSC20,DBLP:conf/aaai/LienenH21} but are incompatible with the binary nature of adverse event prediction. In binary tasks, labeling is defined according to the positive class such that  and . Label smoothing therefore becomes a linear interpolation with parameter  such that :

As suggested by \citet{DBLP:conf/icml/LukasikBMK20}, label smoothing can be used to regularize early prediction models due to the inherently noisy nature of the task. It does not, however, account for the time dependency between samples of a given stay -- highlighted in our problem formalism (Section~\ref{sec:problem_formalism}). In contrast, temporal label smoothing modulates smoothing based on time  to infuse this prior knowledge into the training objective.


\subsection{DSA Objective Functions}

In this section, we detail how despite existing differences between EEP and DSA, we can train a model with a DSA objective while using it for EEP tasks at inference time. We then describe in detail the two baselines we consider from DSA: landmarking and TCSR.
\paragraph{From Survival Analysis to Early Event Prediction.} Survival analysis is a statistical framework to model the time  until an event of
interest occurs. This event is considered to be terminal, thus, it is \textbf{unique} and no observation is carried after it. In survival analysis, we assume access only to an initial observation of a patient state , a survival time  and a censoring indicator . If a patient was (right-)\textit{censored}, thus did not experience an event before the last know survival time at , then . Otherwise, we have that , which means the patient reached a terminal state at . Given these, we can define three probability functions:

Then, if we consider only non-censored and right-censored patients, the survival likelihood can be defined as follows:

Thus, when maximizing , we aim to maximize the probability of failure at time  if the event occurred, or the probability of survival until at least  if the patient is censored. 
It has been shown~\citep{kalbfleisch2011statistical,craig2021survival} that MLE on  is equivalent to minimizing the binary cross-entropy between hazard function estimates and labels of the form . Thus, in practice when training a model with a survival likelihood, we minimize .
As mentioned in Section~\ref{sec:pf_relatedwork}, using existing relation between  and , such as  and  , we can recover the model's probability estimate for an event to occur within a fixed horizon  as .


\paragraph{Landmarking.} When multiple observations are available for a given patient, thus , as in EEP, existing works \cite{van2007dynamic,parast2014landmark} have extended survival analysis to this dynamic context. This field is referred to as "dynamic survival analysis". As mentioned in Section~\ref{sec:pf_relatedwork}, the most prominent technique to leverage these additional observations is landmarking, where the model is fitted with new triplets of the form . As in regular survival analysis, when using landmarking, we minimize binary cross-entropy on the hazard function of the form    with  .
As in regular survival analysis, we can recover the model's probability estimate for an event to occur within a fixed horizon  from a given timepoint  as , which is the probability of interest in EEP tasks.


\paragraph{Temporally consistent survival regression.} Concurrently to our work, \citet{Maystre2022} proposed TCSR, a method based on a temporally consistent dynamic sample reweighting  and label softening. Indeed, to enforce models estimate to match constraints from Equation~\ref{eq:time_consistency}, TCSR proposes to replace landmarking labels  by . In addition, they also apply a reweighting according to the model estimate of the survival function, such that  and . 

\paragraph{Handling of non-terminal events.} Certain tasks in EEP tackles event that are terminal such as decompensation. There, the underlying assumption made in survival analysis regarding the terminality of states holds allowing to rely on a DSA approach for EEP as described above. However, in practice, most events from EEP, such as circulatory failure, are not terminal. This means that observations are carried out during and after an event. It also means other events of the same type can occur. To still use a survival analysis method for these tasks, we further split patient stays into episodes.
Using EEP notations, for a patient indexed by  experiencing  events at times , respectively ending at times , we consider as distinct samples the episodes . Note that this approach is consistent with EEP, where no prediction is carried out during an event. 


\section{Dataset details}
\label{appendix:dataset_details}
\subsection{Task definition}
\label{appendix:task definition}

In this section, we provide more details on the definition of our early prediction tasks for {circulatory failure} from HiB \citep{yeche2021} and {decompensation} from M3B \citep{harutyunyan2019multitask}. A breakdown of event prevalence for each clinical endpoint is given in Table \ref{tab:event_prevalence}.

\begin{table}[h]
    \centering
    \caption{\textbf{Event prevalence analysis}, highlighting class imbalance. Positive timesteps are counted for 12-hour and 24-hour horizons for circulatory failure and decompensation respectively. Statistics are computed on the training set.}
    \label{tab:event_prevalence}
\begin{tabular}{lccc}
    \toprule
        \multirow{2}{*}{Task} & \multirow{2}{*}{Positive timesteps (\%)} & Patients undergoing  & Number of events \\
        & & event (\%) & per positive patient\\\midrule
        Circulatory Failure (HiRID) & 4.3 & 25.6 & 1.9 \\
        Decompensation (MIMIC) & 2.1 & 8.3 & 1.0\\
        \bottomrule
    \end{tabular}\end{table}

\textbf{Circulatory failure} is a failure of the cardiovascular system, detected in practice through elevated arterial lactate ( mmol/l) and either low mean arterial pressure ( mmHg) or administration of a vasopressor drug. \citet{yeche2021} defines a patient to be experiencing a circulatory failure event at a given time if those conditions are met for  of time points in a surrounding two-hour window. Early prediction labels are then derived from these event labels as outlined in Section~\ref{sec:problem_formalism}.

\textbf{Decompensation} refers to the death of a patient. Event labels are directly extracted from the MIMIC-III \citep{johnson2016} metadata about the time of death of a patient. Early prediction labels are also extracted following Section~\ref{sec:problem_formalism}. Note that decompensation can occur outside of the ICU stay if a patient is sent to a palliative unit, for instance, which can result in patient stays with fewer than 24 positive samples.



\subsection{Pre-processing}

We describe the pre-processing steps we applied to both datasets, HiRID and MIMIC-III.

\paragraph{Imputation.}
Diverse imputation methods exist for ICU time series. For simplicity, we follow the approach of original benchmarks \citep{harutyunyan2019multitask,yeche2021} by using forward imputation when a previous measure existed. The remaining missing values are zero-imputed after scaling, corresponding to a mean imputation. 

\paragraph{Scaling.} Whereas prior work explored clipping the data to remove potential outliers \citep{tomavsev2019}, we do not adopt this approach as we found it to reduce performance on early prediction tasks. A possible explanation is that, due to the rareness of events, clipping extreme quantiles may remove parts of the signal rather than noise. Instead, we simply standard-scale data based on the training sets statistics. 


\section{Implementation details}
\label{appendix:implementation_details}

\paragraph{Training details.} For all models, we set the batch size according to the available hardware capacity. Because transformers are memory-consuming, we train the {decompensation} models with a batch size of 8 stays. On the other hand, we train the GRU model for {circulatory failure} with a batch size of 64. We early stopped each model training according to their validation loss when no improvement was made after 10 epochs. 

\paragraph{Libraries.} A full list of libraries and the version we used is provided in the \texttt{environment.yml} file. The main libraries on which we build our experiments are the following: pytorch 1.11.0 \citep{NEURIPS2019_9015}, scikit-learn 0.24.1\citep{scikit-learn}, ignite 0.4.4, CUDA 10.2.89\citep{cuda}, cudNN 7.6.5\citep{chetlur2014cudnn}, gin-config 0.5.0 \citep{gin}.

\paragraph{Infrastructure.}
We follow all guidelines provided by \texttt{pytorch} documentation to ensure the reproducibility of our results. However, reproducibility across devices is not ensured. Thus we provide here the characteristics of our infrastructure. We trained all models on a single \texttt{NVIDIA RTX2080Ti} with a \texttt{Xeon E5-2630v4} core. Training took between 3 and 10 hours for a single run.

\paragraph{Uncertainty estimation.} We compute uncertainty estimates over a population of 10 training instances with different seeds. This widely-used approach has the advantage to account for the stochasticity of the training procedure, which we found to be predominant in early prediction tasks. This approach differs from other work \citep{roy2021multitask,roy2022disability,tomavsev2019,tomavsev2021} which computes uncertainty estimate by bootstrapping the test population. We found that using a pivot bootstrap estimator decreases confidence intervals by effectively increasing the population size. To be conservative with our results, we retained the former approach to compute statistics across 10 training instances. We report the 95\% confidence interval over the population means in all experiments. 

\paragraph{Architecture choices} We used the same architecture and hyperparameters reported giving the best performance on {circulatory failure} in \citet{yeche2021} and only optimized embedding regularization parameters \citep{tomavsev2019}. Exact parameters are reported in Table~\ref{tab:hp-search-gru}. For {decompensation}, as we found a transformer architecture to perform better than originally proposed models \citep{harutyunyan2019multitask}, we carried out our own random search on validation AUPRC performance. The exact parameters for this task are reported in Table~\ref{tab:hp-search-decomp}. 





\begin{table}[tbh!]
    \centering
\caption{\textbf{Hyperparameter search range} for {circulatory failure} with GRU \citep{DBLP:journals/corr/ChungGCB14} backbone. In \textbf{bold} are parameters selected by random search.}
\begin{tabular}{lc}
\toprule
Hyperparameter & Values\\
\midrule
\midrule
Learning Rate & (1e-5, 3e-5, 1e-4, \textbf{3e-4}) \\
\midrule
Drop-out & (\textbf{0.0}, 0.1, 0.2, 0.3, 0.4) \\
\midrule
Depth &   (1, \textbf{2}, 3) \\
\midrule
Hidden Dimension & (32, 64, 128, \textbf{256}) \\
\midrule
L1 Regularization &  (1e-2, 1e-1, 1, \textbf{10}, 100)\\
\bottomrule
\end{tabular}
\label{tab:hp-search-gru}
\end{table}




\begin{table}[tbh!]
    \centering
\caption{\textbf{Hyperparameter search range} for {decompensation} with Transformer \citep{DBLP:conf/nips/VaswaniSPUJGKP17} backbone. In \textbf{bold} are parameters selected by random search.}
\begin{tabular}{lc}
\toprule
Hyperparameter & Values\\
\midrule
\midrule
Learning Rate & (1e-5, 3e-5, \textbf{1e-4}, 3e-4) \\
\midrule
Drop-out & (0.0, 0.1, 0.2, \textbf{0.3}, 0.4) \\
\midrule
Attention Drop-out &   (0.0, \textbf{0.1}, 0.2, 0.3, 0.4) \\
\midrule
Depth &   (1, \textbf{2}, 3) \\
\midrule
Heads &  (\textbf{1}, 2, 4) \\
\midrule
Hidden Dimension &  (32, \textbf{64}, 128, 256) \\
\midrule
L1 Regularization &  (1e-2, \textbf{1e-1}, 1, 10)\\
\bottomrule
\end{tabular}
\label{tab:hp-search-decomp}
\end{table}


\subsection{Baseline implementation}


\paragraph{Balanced cross-entropy.}
In the binary setting, the only hyperparameter of balanced cross-entropy is the relative contribution of the minority class to the loss, . As discussed in Section~\ref{sec:Ablations}, no value of  was found to improve validation performance over the non-balanced case .

\paragraph{Focal loss.}
A grid search over focal loss hyperparameters was also carried out.
Similarly to balanced cross-entropy, on all tasks, no values of focal loss weight  or balancing weight  were found to outperform regular cross-entropy corresponding to  and .

\paragraph{Multi-horizon prediction.} Following \citet{tomavsev2019}, we consider  horizons on both side of the true horizon  between  and . As we didn't find , to increase performance, we selected  (including true horizon ) compared to  in \citet{tomavsev2019}, which we found to perform slightly worse. This means we made a prediction every  hours for circulatory failure and every  hours for {decompensation}. 

\paragraph{Label smoothing.} Label smoothing \citep{DBLP:conf/cvpr/SzegedyVISW16}, as defined in Section~\ref{sec:TLS}, is normally used in multi-class setting. We still compared our method to it for two reasons. First, to explore if it can help when dealing with a noisy signal as we claim is the case for early event detection. Second, to ablate the impact of adding a temporal dependency to the method. Again, we select the hyperparameter  through a grid search. Interestingly, we found label smoothing to slightly improve performance over the validation set for all tasks as opposed to the results reported for the test set in Table~\ref{tab:perf_results}. We found  to perform best for both {circulatory failure} and {decompensation}.

\paragraph{Landmarking.} For all tasks, landmarking was trained with the same architecture and parameters with the exception that our model return hazard estimates. In theory, we should make predictions until  corresponding to 2016 and 2805, for respectively circulatory failure and decompensation. Due to computing limation, as is common in practice, we truncated this horizon to 1000 for circulatory failure.


\paragraph{TCSR.}
As for landmarking, we considered  to be 1000 and 2805 for respectively circulatory failure and decompensation. In practice, we found that the dynamic nature of the label and weight assignment lead to great instability. To be able to train correctly models with this objective, we had to reduce learning rates to 5e-5 and 3e-5. More importantly, for circulatory failure, we used stop-gradient operation for predictions such that . A similar approach for decompensation resulted in worse results, thus we did not use it for this task.

\subsection{TLS implementation}

\begin{figure}[hbtp]
\begin{lstlisting}
def get_smoothed_labels(event_label_patient, smoothing_fn, h_true, h_min,
                        h_max, **kwargs):
                        
    # Find when event label changes
    diffs = np.concatenate([np.zeros(1), 
                event_label_patient[1:] - event_label_patient[:-1]], axis=-1)
    pos_event_change = np.where((diffs == 1) & (event_label_patient == 1))[0]
    
    # Handle patients with no events
    if len(pos_event_change) == 0: 
        pos_event_change = np.array([np.inf])

    # Compute distance to closest event for each time point
    time_array = np.arange(len(event_label_patient))
    dist_all_event = pos_event_change.reshape(-1, 1) - time_array
    dist_to_closest = np.where(dist_all_event > 0,
                                  dist_all_event, np.inf).min(axis=0)

    return smoothing_fn(dist_to_closest, h_true=h_true, h_min=h_min, h_max=h_max,
                                                                    **kwargs)
\end{lstlisting}
\caption{\textbf{Temporal label smoothing algorithm.} Python-style code to obtain smooth early prediction labels from event labels.}
\label{fig:code_snippet}
\end{figure}
\begin{comment}
\begin{lstlisting}
        def q_exp(dt, h_true, h_min, h_max, delta_h, gamma):
    """Returns q(t) for alpha_exp.
    
    dt: (int) distance to next event in steps.
    h_true: (int) true horizon of prediction in steps.
    h_min: (int) minimum horizon to apply smoothing in steps.
    h_max: (int) maximum horizon to apply smoothing in steps.
    delta_h: (int) number of steps per hour.

    """
    if dt <= h_min:
        return 1
    elif dt > h_max:
        return 0
    else:
        h_min_scaled = h_min / delta_h
        h_max_scaled = h_max / delta_h
        dt_scaled = dt / delta_h

        d = -(1 / gamma) * np.log(np.exp(-gamma * (h_min_scaled)) - np.exp(-gamma * (h_max_scaled)))
        A = -np.exp(-gamma * (h_max_scaled - d))
        return np.exp(-gamma * (dt_scaled - d)) + A
\end{lstlisting}
\end{comment}

TLS depends on two components, the temporal range over which we smooth labels, defined by  and , and the smoothing function . Concerning the temporal range, for a fair comparison, we fix it to match MHP, thus for all experiments, we set  and . For the smoothing function, we perform a grid search over the type of function discussed in Appendix~\ref{appendix:temporal_smoothing_fn} and the smoothing strength parameter . For all experiments, we found  to outperform other considered functions. Given validation performance, we used  for {circulatory failure} and  for {decompensation}.

As discussed in Section~\ref{sec:TLS}, contrary to MHP, TLS does not require any change to the architecture leading to a computational overhead. The smoothing of the labels can be easily integrated into the data loader, as shown in Figure~\ref{fig:code_snippet}. 

\begin{figure}[h]
\centering
\begin{subfigure}[b]{0.49\textwidth}
 \centering
  \includegraphics[width=\linewidth]{figures/plot_event_level_decomp.pdf}
  \caption{\textit{Event recall} at 50\% timestep-level precision.} \label{fig:event_decomp}
\end{subfigure}
\begin{subfigure}[b]{0.49\textwidth}
  \centering
  \includegraphics[width=\linewidth]{figures/plot_auprc_decomp.pdf}
  \caption{\textit{Precision-recall curve.}}
  \label{fig:PR_curve_decomp}
\end{subfigure}
\caption{\textbf{Clinically relevant performance} on decompensation. Inset in (b) shows the clinically-applicable region with precision greater than 50\%.}
\label{fig:clinical_performance_decomp}
\end{figure}

\section{Additional experiments and ablation studies}
\label{appendix:add_exp}

This section provides additional results and experiments to complete our findings from the main manuscript. Unless otherwise stated, mean results are shown with a 95\% confidence interval on the mean shaded or in error bars.

\subsection{Performance analysis for decompensation prediction}
\label{appendix:decomp_results}
Event-level performance for decompensation prediction is given in Figure \ref{fig:event_decomp}. Results are similar to those on circulatory failure discussed in Section \ref{sec:perf-results}: temporal label smoothing improves recall of adverse event episodes over cross-entropy and MHP. Note that the improvements observed over the baselines in terms of event-recall between 0 and  are smaller than for circulatory failure, but are statistically significant as shown in Table\ref{tab:perf_results}

\begin{figure}[h]
\begin{subfigure}[b]{0.47\textwidth}
  \centering
  \includegraphics[width=\linewidth]{figures/plot_delta_tnr_decomp_v4.pdf}\vspace{-0.5em}\caption{True negative rate (TNR).}
  \label{fig:delta_tnr_decomp}
\end{subfigure} \hfill
\begin{subfigure}[b]{0.47\textwidth}
 \centering
  \includegraphics[width=\linewidth]{figures/plot_delta_tpr_decomp_v4.pdf}\vspace{-0.5em}\caption{True positive rate (TPR).}
  \label{fig:delta_tpr_decomp}
\end{subfigure}
\caption{\textbf{Performance improvement over time} for TLS over traditional cross-entropy on decompensation prediction. Timestep-level metrics computed for precision of  over two-hour bins.}
\vspace{-1em}
\label{fig:plot_delta_decomp}
\end{figure}

The precision-recall curve obtained for timestep-level event prediction on this task is also given in Figure \ref{fig:PR_curve_decomp}. As for circulatory failure prediction, recall gains are concentrated in regions of low false-alarm rates (>50\% precision) which are most clinically relevant. 

Likewise, whereas recall near the label boundary  is slightly negatively affected by temporal label smoothing in Figure \ref{fig:plot_delta_decomp}, true positive rates are significantly improved leading up to the event time . This mirrors the temporal smoothing pattern which favors higher model confidence away from the label boundary. As discussed in Section \ref{sec:Ablations}, this is aligned with clinical priorities in terms of model performance, as it ensures imminent events are better predicted.


\subsection{Sub-group analysis}
Populations in the intensive care unit are often heterogeneous. This has motivated recent works to focus on the fairness of deep learning across these sub-populations. In this analysis, we ensure that temporal label smoothing does not negatively affect performance in specific subgroups, compared to the objectives commonly used in the literature \citep{tomavsev2019, hyland2020, Lauritsen2020}. To achieve this, we measured event prediction performance across genders and age groups (below 50, between 50 and 70, and over 70 years old). As shown in Table~\ref{tab:sg-circ}, TLS matches or outperforms baseline performance across all studied subgroups, suggesting that the overall population-wide improvements are not achieved by disproportionally favouring specific cohorts. While some algorithmic bias can be observed across all methods, for instance in poorer decompensation performance amongst female patients, TLS does not appear to be amplifying this issue. In further work, we look forward to extending this analysis to more specific subgroups and studying the fairness of early event prediction methods for clinical applications.




\begin{table}[h]
{
 \centering
    \caption{\textbf{Sub-group performance analysis.} We color improvement above the 95\% confidence interval in {\color{Green} green}.} \label{tab:sg-circ}
\resizebox{\textwidth}{!}{\begin{tabular}{lcccccccccc}
\toprule
 Circulatory Failure & \multicolumn{2}{c}{Age } & \multicolumn{2}{c}{ Age } & \multicolumn{2}{c}{Age  } & \multicolumn{2}{c}{Female} & \multicolumn{2}{c}{Male}\\
 \cmidrule(lr){2-3} \cmidrule(lr){4-5}\cmidrule(lr){6-7}\cmidrule(lr){8-9}\cmidrule(lr){10-11}
Method &         AUPRC &   Recall &         AUPRC &   Recall &         AUPRC &   Recall & AUPRC &   Recall & AUPRC &   Recall\\
\midrule
CE     &             40.4  0.5 &             29.4  0.6 &             38.8  0.6 &             29.6  1.1 &             39.2  0.3 &             29.0  1.0 &             39.3  0.6 &             30.0  0.7 &             39.1  0.4 &             29.0  1.0 \\
\textbf{TLS}     & 40.4  0.5 &    1.0 &    0.4 &    0.7 &    0.3 &    0.7 &    0.3 &    0.6 &    0.3 &    0.8 \\
(TLS-CE)    &  {0.0}&  {\color{Green}+ 3.3} &  {\color{Green}+ 2.3} &  {\color{Green}+ 3.0} &  {\color{Green}+ 0.9} &  {\color{Green}+ 2.7} &  {\color{Green}+ 1.8} &  {\color{Green}+ 2.9} &  {\color{Green}+ 1.3} &  {\color{Green}+ 3.0} \\
\bottomrule
\end{tabular}}
    \centering
\resizebox{\textwidth}{!}{\begin{tabular}{lcccccccccc}

\toprule
 Decompensation & \multicolumn{2}{c}{Age } & \multicolumn{2}{c}{ Age } & \multicolumn{2}{c}{Age  } & \multicolumn{2}{c}{Female} & \multicolumn{2}{c}{Male}\\
 \cmidrule(lr){2-3} \cmidrule(lr){4-5}\cmidrule(lr){6-7}\cmidrule(lr){8-9}\cmidrule(lr){10-11}
Method &         AUPRC &   Recall &         AUPRC &   Recall &         AUPRC &   Recall & AUPRC &   Recall & AUPRC &   Recall\\
\midrule
CE     &              29.2  0.8 &             25.3  1.2 &             34.9  0.9 &             27.4  0.6 &             35.8  0.2 &             29.4  0.6 &             30.9  0.4 &             24.8  0.6 &             38.3  0.6 &             31.4  0.5 \\
\textbf{TLS}     &    0.5 &             26.2  1.1 &    0.5 &    0.5 &    0.3 &    0.4 &    0.3 &    0.5 &    0.5 &    0.6 \\
(TLS-CE)    &  {\color{Green}+ 1.3} &  {\color{Green}+ 1.0} &  {\color{Green}+ 1.8} &  {\color{Green}+ 1.7} &  {\color{Green}+ 0.5} &  {\color{Green}+ 0.9} &  {\color{Green}+ 0.7} &  {\color{Green}+ 0.9} &  {\color{Green}+ 1.3} &  {\color{Green}+ 1.4} \\
\bottomrule
\end{tabular}}}
\end{table}

\begin{comment}
\resizebox{\textwidth}{!}{\begin{tabular}{lcccccccccc}
\toprule
  Respiratory Failure & \multicolumn{2}{c}{Age } & \multicolumn{2}{c}{ Age } & \multicolumn{2}{c}{Age  } & \multicolumn{2}{c}{Female} & \multicolumn{2}{c}{Male}\\
 \cmidrule(lr){2-3} \cmidrule(lr){4-5}\cmidrule(lr){6-7}\cmidrule(lr){8-9}\cmidrule(lr){10-11}
Method &         AUPRC &   Recall &         AUPRC &   Recall &         AUPRC &   Recall & AUPRC &   Recall & AUPRC &   Recall\\
\midrule
CE     &            0.2 &             70.3  0.8 &    0.3 &    0.5 &    0.3 &    0.8 &    0.2 &    0.8 &    0.2 &    0.6 \\
\textbf{TLS}     &  51.9  0.4 &    0.7 &             62.4  0.2 &             77.8  0.3 &             63.2  0.3 &             81.1  0.6 &             53.9  0.2 &             72.3  0.6 &             63.7  0.2 &             79.8  0.4 \\
(TLS-CE)     &  {\color{red} - 0.3} &  {\color{red} + 0.3} &  {\color{red} - 0.1} &  {\color{red} - 0.3} &  {\color{red} 0.0} &  {\color{red} - 0.6} &  {\color{red} - 0.3} &  {\color{red} - 0.6} &  {\color{red} - 0.1} &  {\color{red} 0.0} \\
\bottomrule
\end{tabular}}

\subsection{Uncertainty Estimation with Pivot Bootstrap}\label{sec:bootstrap}
As mentioned in Appendix~\ref{appendix:implementation_details}, our uncertainty estimation approach was based on measuring standard error across 10 training runs. With the uncertainty evaluation framework from \citet{tomavsev2019}, bootstrapping patients from our test set 200 times for each training instance, we obtained similar means to Table~\ref{tab:perf_results} but with confidence intervals all smaller than or equal to 0.1\%. Variance within bootstrap samples from the same training instance is therefore much smaller than across instances. Our alternative uncertainty estimation approach, measuring variability between training runs, returns more conservative estimates, and was thus chosen for all results reported in this work.


\end{comment}
\begin{comment}
  \newpage
\begin{table}[t] \centering
    \caption{\textbf{Timestep-level performance with pivot bootstrap uncertainty estimation.} Recall is reported at a 50\% precision. Circulatory and respiratory failure are predicted on the HiB dataset, decompensation on M3B. In \textbf{bold}, we highlight best-performing methods).} \label{tab:perf_results-bs}
\resizebox{\textwidth}{!}{\begin{tabular}{lcccccc}
\toprule

 Task & \multicolumn{2}{c}{Circulatory Failure} & \multicolumn{2}{c}{Decompensation} & \multicolumn{2}{c}{Respiratory Failure} \\
 \cmidrule(lr){2-3} \cmidrule(lr){4-5}\cmidrule(lr){6-7}
Method &         AUPRC &   Recall &         AUPRC &   Recall &         AUPRC &   Recall\\
\midrule
Cross-entropy      &             39.3  0.1 &             29.4  0.1 &             34.6  0.1 &             28.2  0.1 &    0.0 &    0.0 \\
Multi-horizon \citep{tomavsev2019} &             39.8  0.1 &             30.4  0.1 &             35.0  0.1 &             28.6  0.1 &             60.2  0.0 &             76.7  0.0 \\
\textbf{Temporal Label Smoothing}     &    0.1 &    0.1 &    0.1 &    0.1 &             60.3  0.0 &             77.1  0.0 \\
\bottomrule
\end{tabular}}
\vspace{-0.5em}
\end{table}  
\end{comment}
\subsection{Loss reweighting methods}
\label{appendix:loss_reweight}

Hyperparameter grid search results on decompensation prediction for different loss reweighting methods are shown in Figure~\ref{fig:grid_focal_decomp}. Weighted cross-entropy and focal loss were also found to negatively affect performance in comparison to traditional cross-entropy. Likely explanations for these results are provided in Section \ref{sec:Ablations}: focal loss focuses training on noisily labeled samples, and weighted cross-entropy largely reduces precision.

We validate the latter hypothesis by visualizing precision-recall curves of models trained with this objective in Figure \ref{fig:additional_PR_reweight}. With a relative weight for the positive class , weighted cross-entropy encourages a greater number of true positives to improve recall. Doing so also increases the of false positives, impairing precision. In Figure \ref{fig:additional_PR_reweight}, as the starting precision of all cross-entropy models is poor, no discernible improvements in the recall can be observed as class weights are increased, whereas precision is markedly reduced in low-recall regions. This explains the overall reduction in AUPRC with this method.

\begin{figure}[h]
\centering
\begin{subfigure}[b]{0.32\textwidth}
  \centering
\includegraphics[width=\linewidth]{figures/gridsearch_focal_DECOMP_VAL_patch.pdf} 
  \caption{\textit{Reduction in AUPRC (validation).}}
\label{fig:grid_focal_decomp}
\end{subfigure} \hspace{4em}
\begin{subfigure}[b]{0.32\textwidth}
  \centering
  \includegraphics[width=\linewidth]{figures/plot_auprc_reweight_decomp.pdf}
  \caption{\textit{Reduction in precision.}}
  \label{fig:rw_PR_curve_decomp}
\end{subfigure}
\caption{\textbf{Performance loss with class reweighting methods}, on decompensation prediction. (a) Balanced cross-entropy corresponds to , focal loss to . (b) Loss reweighting does not improve AUPRC because it significantly reduces precision. Balance weights correspond to . Similar results for circulatory failure prediction.}
\label{fig:additional_PR_reweight}
\end{figure}

\begin{comment}
\subsection{{Visual comparison of TLS with  and MHP performance}}

{In Figure~\ref{fig:additional_PR_mhp_step}, we compare the precision-recall curve of multi-horizon prediction and temporal label smoothing with  smoothing, ensuring that there is no area where MHP is superior. In complement to Table~\ref{tab:ablation_MHP_step} and to the analysis in Section \ref{sec:Ablations}, this confirms that predicting a single horizon with a step function smoothing is sufficient to match the performance of multi-horizon prediction.}
\begin{figure}[h]
\centering
\begin{subfigure}[b]{0.32\textwidth}
  \centering
  \includegraphics[width=\linewidth]{figures/plot_auprc_circ_step_mhp.pdf}
  \caption{\textit{Circulatory Failure}}
  \label{fig:step_mh_PR_curve_circ}
\end{subfigure} \hspace{4em}
\begin{subfigure}[b]{0.32\textwidth}
  \centering
  \includegraphics[width=\linewidth]{figures/plot_auprc_decomp_step_mhp.pdf}
  \caption{\textit{Decompensation}}
  \label{fig:step_mh_PR_curve_decomp}
\end{subfigure}
\caption{{\textbf{Precision-recall curves of multi-horizon prediction and temporal label smoothing with }. Both curves overlap, as suggested by metrics in Table \ref{tab:ablation_MHP_step}, further demonstrating that the multiple outputs of multi-horizon prediction do not lead to superior performance, and supporting assumptions in Proposition~\ref{prop:MHP}. }}
\label{fig:additional_PR_mhp_step}
\end{figure}


\subsection{Combining TLS with other methods}

\begin{figure}[h]
    \centering
    \begin{subfigure}[c]{0.9\textwidth}
    \centering
    \includegraphics[width=\linewidth]{figures/wce_tls_circ.pdf}
    \caption{Circulatory failure.}
    \end{subfigure}
        \begin{subfigure}[c]{0.9\textwidth}
        \includegraphics[width=\linewidth]{figures/wce_tls_decomp.pdf}
        \caption{Decompensation failure.}

    \end{subfigure}
    \caption{{\textbf{AUPRC performance of temporal label smoothing combined with weighted cross-entropy}. (Left) Test set performance. (Right) Validation set performance.}}
    \label{fig:tls_wce}
\end{figure}

Finally, we investigated whether temporal label smoothing could be combined with other objective functions to leverage their respective added value and further improve prediction performance. {The performance of temporal label smoothing combined with a weighted cross-entropy objective is given in Figure \ref{fig:tls_wce}. Balanced reweighting per class results in a performance drop, as observed when applied to traditional cross-entropy (see Section \ref{sec:perf-results}, Figure \ref{fig:focal+weighted}). Another possible approach to combine these methods would be to leverage temporal information in sample re-weighting, and we reserve this investigation for further work. 

Similarly, no additional performance gains were obtained from combining multi-horizon prediction or focal loss with temporal label smoothing over using TLS with cross-entropy loss.}
\end{comment}

\newpage
\section{Alternative early prediction tasks}\label{appendix:resp}

As a third task to benchmark our method, we studied early prediction of respiratory failure, defined in \citet{yeche2021}. Unfortunately, this task has vague labels which result in all methods performing close to random. For transparency, we first provide results on this task and motivate our belief that this label ambiguity is caused by a very noisy estimate of a certain clinical variable (FIO). See Section \ref{sec:label-issues} for details. 

As a related, alternative dataset, we define a related sub-task that does not rely on FIO: prediction of the onset of mechanical ventilation. For this task, we show that: (1) models do perform much better than random, which confirms our hypothesis on respiratory failure labeling, and (2) TLS improves again significantly over EEP baselines, with similar results to in Section~\ref{sec:perf-results}.

 \paragraph{Implementation details.} For respiratory failure prediction, we used the transformer architecture and hyperparameters for {respiratory failure} reported in \citet{yeche2021}. For ventilation onset, we used a GRU model and selected hyperparameters based on a grid search over the validation AUPRC. This resulted in a 2-layer GRU with a hidden space dimensionality of 128 and no dropout. In both cases, we chose 10.0 as the  regularization strength for the embedding module and used a batch size of 8 stays. For label smoothing, we found  to give the best validation performance. We used  (respiratory failure) and  (ventilation onset) for temporal label smoothing with exponential parametrization.
 
\subsection{Labeling issues for respiratory failure}
\label{sec:label-issues}

Respiratory failure is defined as a P/F ratio (arterial pO over FIO) below  mmHg \citep{yeche2021}. This includes mild failure events, which results in high event prevalence in the HIRID dataset \citep{hyland2020}: 38.6\% of timepoints have a positive label, and 83\% of patients undergo at least one event, with on average 1.8 events per positive patient. Despite this high prevalence, all EEP methods have a performance close to  AUPRC, as shown in Table~\ref{tab:perf_results_resp_vent} and as in~\citet{yeche2021}. This corresponds to an enrichment factor (ratio of AUPRC of predictor vs.\ random classifier) with respect to a random classifier () of  for this task, compared to factors of  and  for circulatory failure and decompensation, respectively. Such a low performance suggests an inherent issue with labeling. Our hypothesis is that the estimation of FIO is highly error-prone, which challenges the quality of respiratory failure labels and causes the low performance of all machine learning models considered. For completeness, we nevertheless show the results for respiratory failure (in addition to ventilation onset in this section and circulatory failure as well as decompensation in the main part).

\subsection{Ablation study: onset of mechanical ventilation}
 To verify the above hypothesis, we define a similar task independent of FIO estimates and verify we can recover a better baseline performance. We focus on predicting whether a patient will be mechanically ventilated within the next 12 hours. Ventilation is a good proxy for severe respiratory distress but is not labeled based on a P/F ratio estimate. With a 5.6\% timestep-level prevalence, baseline performance at  AUPRC in Table \ref{tab:perf_results_resp_vent} is roughly 6.2 times better than a random classifier. This confirms that poor FIO estimation underlies poor performance on respiratory failure prediction across all methods. 


\begin{comment}
\begin{table}[tbh!]
    \centering
\caption{\textbf{Hyperparameter search range} for {respiratory failure} with Transformer \citep{DBLP:conf/nips/VaswaniSPUJGKP17} backbone. In \textbf{bold} are parameters selected by random search.}
\begin{tabular}{lc}
\toprule
Hyperparameter & Values\\
\midrule
\midrule
Learning Rate & (1e-5, 3e-5, \textbf{1e-4}, 3e-4) \\
\midrule
Drop-out & (0.0, 0.1, 0.2, \textbf{0.3}, 0.4) \\
\midrule
Attention Drop-out &   (\textbf{0.0}, 0.1, 0.2, 0.3, 0.4) \\
\midrule
Depth &   (1, \textbf{2}, 3) \\
\midrule
Heads &  (\textbf{1}, 2, 4) \\
\midrule
Hidden Dimension &  (32, \textbf{64}, 128, 256) \\
\midrule
L1 Regularization &  (1e-2, 1e-1, 1, \textbf{10}, 100)\\
\bottomrule
\end{tabular}
\label{tab:hp-search-resp}
\end{table}
\end{comment}




\begin{table*}[h] \centering
    \caption{\textbf{Performance of different training objectives for early prediction of respiratory failure and ventilation onset.} Recall is reported at a 50\% timestep-level precision. {In \textbf{bold}, we highlight best-performing methods with statistically significant -values () under paired Student's t-tests~\citep{student1908probable}} compared with the next-best method marked in italic.}
    \label{tab:perf_results_resp_vent}
\resizebox{\textwidth}{!}{
\begin{tabular}{lcccccc}
\toprule
 Task & \multicolumn{3}{c}{Respiratory Failure (HiRID)} & \multicolumn{3}{c}{Ventilation Onset (HiRID)} \\
 \cmidrule(lr){2-4} \cmidrule(lr){5-7}
Training objective &         AUPRC & Timestep  Recall & Event Recall & AUPRC & Timestep  Recall & Event Recall  \\
\midrule
Cross-entropy   \citep{Lauritsen2020, hyland2020}  &  {60.5}  0.2 &  {77.3}  0.5 & 94.9  0.2 & 34.1  0.4 &           {\it 23.0}  1.1& 64.2  1.8 \\
Multi-horizon \citep{tomavsev2019,jarrett2019dynamic} &             {60.3}  0.1 &               0.5  & {\it 95.0}  0.1 &  {\it 34.4}  0.5 &           {\it 23.0}  0.6 & {\it 64.3}  0.9 \\
\textbf{Temporal Label Smoothing}    &   {\it 60.4}  0.2 &  {\it 77.0}  0.3  & \textbf{95.3}  0.1   & 34.7  0.4 &          \textbf{ 24.2}  0.7 &	\textbf{67.8}  0.9\\
\midrule
-value & {0.15} & {0.14} &  \textbf{0.04} & 0.25 & \textbf{0.008} & 
\textbf{<0.001} \\
\midrule
 Enrichment Factor & \multicolumn{3}{c}{\textbf{1.5}} & \multicolumn{3}{c}{\textbf{6.2}}\\
\bottomrule
\end{tabular}}
\end{table*}





    





























\subsection{Temporal label smoothing performance for onset of mechanical ventilation}

In this final section, we verify the benefits of TLS in predicting the onset of mechanical ventilation -- a feasible task relative to the respiratory system. In Table~\ref{tab:perf_results_resp_vent}  and Figure~\ref{fig:based_vent}, we find that TLS again improves performance in both timestep and event recall over multi-horizon prediction, and performs on par in terms of AUPRC. This is likely due to its lower performance at very low recall in Figure~\ref{fig:PR_curve_vent}. Finally, TLS again improves the true negative and positive rates away from the label boundary  in Figure~\ref{fig:plot_delta_vent}, which corresponds to more clinically relevant regions. All conclusions agree with our analysis on other tasks in Section \ref{sec:Ablations}.

\begin{figure}[h]
\centering
\begin{subfigure}[b]{0.49\textwidth}
 \centering
  \includegraphics[width=\linewidth]{figures/plot_event_recall_vent.pdf}
  \caption{\textit{Event recall} at 50\% timestep-level precision.} \label{fig:based_vent}
\end{subfigure}
\begin{subfigure}[b]{0.49\textwidth}
  \centering
  \includegraphics[width=\linewidth]{figures/plot_auprc_vent.pdf}
  \caption{\textit{Precision-recall curve.} Inset shows the clinically-applicable region with precision greater than }
  \label{fig:PR_curve_vent}
\end{subfigure}
\caption{\textbf{Clinically relevant performance} on ventilation onset.}
\label{fig:clinical_performance_vent}
\end{figure}

\begin{figure}[h]
\begin{subfigure}[b]{0.47\textwidth}
  \centering
  \includegraphics[width=\linewidth]{figures/plot_delta_tnr_vent.pdf}\vspace{-0.5em}\caption{True negative rate (TNR)}\vspace{-0.25em}
  \label{fig:delta_tnr_vent}
\end{subfigure} \hfill
\begin{subfigure}[b]{0.47\textwidth}
 \centering
  \includegraphics[width=\linewidth]{figures/plot_delta_tpr_vent.pdf}\vspace{-0.5em}\caption{True positive rate (TPR)}\vspace{-0.25em}
  \label{fig:delta_tpr_vent}
\end{subfigure}
\caption{\textbf{Performance improvement over time} for TLS over traditional cross-entropy on onset ventilation prediction. Timestep-level metrics computed for precision of  over two-hour bins.}
\vspace{-1em}
\label{fig:plot_delta_vent}
\end{figure}


\end{document}