\pdfoutput=1

\documentclass[11pt]{article}

\usepackage{EMNLP2023}

\usepackage{times}
\usepackage{latexsym}

\usepackage[T1]{fontenc}

\usepackage[utf8]{inputenc}

\usepackage{microtype}

\usepackage{inconsolata}

\usepackage{multirow}
\usepackage{tabularx}
\usepackage{amsmath}
\usepackage{amsxtra}
\usepackage{amsfonts}
\usepackage{booktabs}
\usepackage{graphicx}
\usepackage{textcomp}
\usepackage{footnote}
\usepackage{hyperref}
\usepackage{balance}
\makesavenoteenv{tabular}
\makesavenoteenv{table}
\usepackage[all]{nowidow}
\usepackage{float} \usepackage{refcount}
\usepackage{enumitem}
\usepackage{footmisc}
\usepackage{subcaption}

\clearpage{}





\newcommand{\co}[1]{\textcolor{blue}{#1}} \newcommand{\eat}[1]{} 

\newcommand{\red}[1]{\textcolor{red}{#1}}
\newcommand{\blue}[1]{\textcolor{blue}{#1}}
\newcommand{\green}[1]{\textcolor{green}{#1}}
\newcommand{\dgreen}[1]{\textcolor{green!70!black}{#1}}
\newcommand{\orange}[1]{\textcolor{orange}{#1}}
\newcommand{\yellow}[1]{\textcolor[rgb]{102, 77, 0}{#1}}

\newcommand{\sz}[1]{\lvert#1\rvert}   \newcommand{\card}[1]{\lvert#1\rvert} \newcommand{\Sz}[1]{\lVert#1\rVert}   \newcommand{\Card}[1]{\lVert#1\rVert} 

\newcommand{\eqdef}{\stackrel{\mathrm{def}}{=}} \newcommand{\eqdot}{\doteq} \newcommand{\eqdist}{\equiv} 

\newcommand{\floor}[1]{\left\lfloor#1\right\rfloor} \newcommand{\floorn}[1]{\lfloor#1\rfloor} \newcommand{\ceil}[1]{\left\lceil#1\right\rceil} \newcommand{\ceiln}[1]{\lceil#1\rceil} 

\newcommand{\abs}[1]{\left\lvert#1\right\rvert} \newcommand{\absn}[1]{\lvert#1\rvert} 

\newcommand{\td}[2]{\if*#1\else^{#1}\fi\if*#2\else_{#2}\fi} 

\newcommand{\xpr}[2]{p\td{#1}{#2}} \newcommand{\uxpr}[2]{\tilde p\td{#1}{#2}} \newcommand{\pr}[1]{\xpr**\!\left(#1\right)} \newcommand{\prn}[1]{\xpr**\!(#1)} \newcommand{\prbig}[1]{\xpr**\!\bigl(#1\bigr)} \newcommand{\prBig}[1]{\xpr**\!\Bigl(#1\Bigr)} \newcommand{\prbigg}[1]{\xpr**\!\biggl(#1\biggr)} \newcommand{\prBigg}[1]{\xpr**\!\Biggl(#1\Biggr)} 

\newcommand{\prf}[3]{\xpr{#1}{#2}\!\left(#3\right)} \newcommand{\uprf}[3]{\uxpr{#1}{#2}\!\left(#3\right)} 

\newcommand{\prs}[1]{\xpr**\!\left(#1\right)} \newcommand{\prsn}[1]{\xpr**\!(#1)} 

\newcommand{\Pa}{\operatorname{Pa}}
\newcommand{\Nd}{\operatorname{NonDescendants}}

\newcommand\macrospace{}

\newcommand{\xev}[2]{\operatorname{E}\td{#1}{#2}} 

\newcommand{\evf}[3]{\xev{#1}{#2}{\left[\macrospace{}#3\macrospace{}\right]}} \newcommand{\evfn}[3]{\xev{#1}{#2}{[\macrospace{}#3\macrospace{}]}} \newcommand{\evfbig}[3]{\xev{#1}{#2}{\bigl[\macrospace{}#3\macrospace{}\bigr]}} \newcommand{\evfBig}[3]{\xev{#1}{#2}{\Bigl[\macrospace{}#3\macrospace{}\Bigr]}} \newcommand{\evfbigg}[3]{\xev{#1}{#2}{\biggl[\macrospace{}#3\macrospace{}\biggr]}} 

\newcommand{\ev}[1]{\evf**{#1}} \newcommand{\evn}[1]{\evfn**{#1}} \newcommand{\evbig}[1]{\evfbig**{#1}} \newcommand{\evBig}[1]{\evfBig**{#1}} \newcommand{\evbigg}[1]{\evfbigg**{#1}} 

\newcommand{\xbias}[2]{\operatorname{bias}\td{#1}{#2}} \newcommand{\bias}[1]{\xbias**\left[\macrospace{}#1\macrospace{}\right]} \newcommand{\biasn}[1]{\xbias**[\macrospace{}#1\macrospace{}]} 

\newcommand{\xvar}[2]{\operatorname{var}\td{#1}{#2}} \newcommand{\var}[1]{\xvar**\left[\macrospace{}#1\macrospace{}\right]} \newcommand{\varn}[1]{\xvar**[\macrospace{}#1\macrospace{}]} \newcommand{\varbig}[1]{\xvar**\bigl[\macrospace{}#1\macrospace{}\bigr]} \newcommand{\varBig}[1]{\xvar**\Bigl[\macrospace{}#1\macrospace{}\Bigr]} 

\newcommand{\xhatvar}[2]{\operatorname{\hat{v}ar}\td{#1}{#2}} \newcommand{\hatvar}[1]{\xhatvar**\left[\macrospace{}#1\macrospace{}\right]} \newcommand{\hatvarn}[1]{\xhatvar**[\macrospace{}#1\macrospace{}]} \newcommand{\hatvarBig}[1]{\xhatvar**\Bigl[\macrospace{}#1\macrospace{}\Bigr]} 

\newcommand{\varf}[3]{\xvar{#1}{#2}{\left[\macrospace{}#3\macrospace{}\right]}} \newcommand{\varfn}[3]{\xvar{#1}{#2}{[\macrospace{}#3\macrospace{}]}} \newcommand{\varfbig}[3]{\xvar{#1}{#2}{\bigl[\macrospace{}#3\macrospace{}\bigr]}} \newcommand{\varfBig}[3]{\xvar{#1}{#2}{\Bigl[\macrospace{}#3\macrospace{}\Bigr]}} \newcommand{\varfbigg}[3]{\xvar{#1}{#2}{\biggl[\macrospace{}#3\macrospace{}\biggr]}} 

\newcommand{\xcov}[2]{\operatorname{Cov}\td{#1}{#2}} \newcommand{\cov}[1]{\xcov**\left[\macrospace{}#1\macrospace{}\right]} \newcommand{\covn}[1]{\xcov**[\macrospace{}#1\macrospace{}]} \newcommand{\covBig}[1]{\xcov**\Bigl[\macrospace{}#1\macrospace{}\Bigr]} 

\newcommand{\xhatcov}[2]{\operatorname{\hat{C}ov}\td{#1}{#2}} \newcommand{\hatcov}[1]{\xhatcov**\left[\macrospace{}#1\macrospace{}\right]} \newcommand{\hatcovn}[1]{\xhatcov**[\macrospace{}#1\macrospace{}]} \newcommand{\hatcovBig}[1]{\xhatcov**\Bigl[\macrospace{}#1\macrospace{}\Bigr]} 


\newcommand{\xse}[2]{\operatorname{SE}\td{#1}{#2}} \newcommand{\se}[1]{\xse**\left[\macrospace{}#1\macrospace{}\right]} \newcommand{\sen}[1]{\xse**[\macrospace{}#1\macrospace{}]} 

\newcommand{\xhatse}[2]{\operatorname{\hat{S}E}\td{#1}{#2}} \newcommand{\hatse}[1]{\xhatse**\left[\macrospace{}#1\macrospace{}\right]} \newcommand{\hatsen}[1]{\xhatse**[\macrospace{}#1\macrospace{}]} 


\newcommand{\xsd}[2]{\operatorname{SD}\td{#1}{#2}} \newcommand{\sd}[1]{\xsd**\left[\macrospace{}#1\macrospace{}\right]} \newcommand{\sdn}[1]{\xsd**[\macrospace{}#1\macrospace{}]} 

\newcommand{\xhatsd}[2]{\operatorname{\hat{S}D}\td{#1}{#2}} \newcommand{\hatsd}[1]{\xhatsd**\left[\macrospace{}#1\macrospace{}\right]} \newcommand{\hatsed}[1]{\xhatsd**[\macrospace{}#1\macrospace{}]} 


\newcommand{\xcv}[2]{\operatorname{CV}\td{#1}{#2}} \newcommand{\cv}[1]{\xcv**\left[\macrospace{}#1\macrospace{}\right]} \newcommand{\cvn}[1]{\xcv**[\macrospace{}#1\macrospace{}]} \newcommand{\cvbig}[1]{\xcv**\bigl[\macrospace{}#1\macrospace{}\bigr]} \newcommand{\cvBig}[1]{\xcv**\Bigl[\macrospace{}#1\macrospace{}\Bigr]} 

\newcommand{\xmse}[2]{\operatorname{mse}\td{#1}{#2}} \newcommand{\mse}[1]{\xmse**\left[\macrospace{}#1\macrospace{}\right]} \newcommand{\msen}[1]{\xmse**[\macrospace{}#1\macrospace{}]} 

\newcommand{\xrmse}[2]{\operatorname{rmse}\td{#1}{#2}} \newcommand{\rmse}[1]{\xrmse**\left[\macrospace{}#1\macrospace{}\right]} \newcommand{\rmsen}[1]{\xrmse**[\macrospace{}#1\macrospace{}]} 

\newcommand{\xare}[2]{\operatorname{ARE}\td{#1}{#2}} \newcommand{\are}[1]{\xare**\left[\macrospace{}#1\macrospace{}\right]} \newcommand{\aren}[1]{\xare**[\macrospace{}#1\macrospace{}]} 


\newcommand{\pbinom}[3]{B\!\left(#1;\,#2,#3\right)} 

\newcommand{\phyper}[4]{H\!\left(#1;\,#2,#3,#4\right)} 


\renewcommand\:{\colon} \newcommand{\sset}[1]{\left\{\,#1\,\right\}} \newcommand{\ssets}[1]{\left\{#1\right\}} \newcommand{\ssetn}[1]{\{\,#1\,\}} 

\newcommand{\comp}[1]{\bar{#1}} 

\newcommand{\powerset}[1]{\cP\!\left(#1\right)} 

\newcommand\adots{{\ensuremath ..}} 

\newcommand{\Nat}{{\ensuremath \bN}}
\newcommand{\Bool}{{\ensuremath \{0,1\}}}

\newcommand\true{\text{true}} \newcommand\false{\text{false}} 

\newcommand\join\Join 

\DeclareSymbolFont{txsymbolsC}{U}{txsyc}{m}{n}
\SetSymbolFont{txsymbolsC}{bold}{U}{txsyc}{bx}{n}
\DeclareFontSubstitution{U}{txsyc}{m}{n}
\DeclareMathSymbol{\ljoin}{\mathrel}{txsymbolsC}{88}
\DeclareMathSymbol{\rjoin}{\mathrel}{txsymbolsC}{89}

\newcommand{\sql}[1]{\texttt{#1}}

\newcommand\mcup{\uplus}       \newcommand\bigmcup{\biguplus} \newcommand\mcap{\nplus}       \newcommand\bigmcap{\nbigplus} 

\newsavebox\setminusbox
\newlength\setminuslen
\newcommand\msetminus{{\savebox{\setminusbox}{$\setminus$}\settowidth{\setminuslen}{\usebox{\setminusbox}}\,\usebox{\setminusbox}\hspace{-.5\setminuslen}^+}} \newcommand\msetminusl{{\savebox{\setminusbox}{$_\setminus$}\settowidth{\setminuslen}{\usebox{\setminusbox}}\setminus\hspace{-.5\setminuslen}^+}} 


\newcommand\xdiag{\operatorname{diag}}
\newcommand\diag[1]{\xdiag\left(#1\right)}    \newcommand\diagn[1]{\xdiag(#1)}    \newcommand\xrank{\operatorname{rank}}
\newcommand\rank[1]{\xrank\left(#1\right)}
\newcommand\rankn[1]{\xrank(#1)}


\newcommand\T{\top}
\newcommand\transpose[1]{#1^{\T}}
\newcommand\tr[1]{#1^{\textrm{T}}}
\newcommand\normn[1]{\lVert #1 \rVert}
\newcommand\fnorm[1]{\left\lVert #1 \right\rVert_\text{F}}
\newcommand\fnormn[1]{\lVert #1 \rVert_\text{F}}
\newcommand\rsim{\stackrel{\mathrm{row}}{\sim}}
\newcommand\csim{\stackrel{\mathrm{col}}{\sim}}



\newcolumntype{C}{>{$\displaystyle}c<{$}} \newcolumntype{L}{>{$\displaystyle}l<{$}} \newcolumntype{R}{>{$\displaystyle}r<{$}} \newcolumntype{H}{>{\setbox0=\hbox\bgroup}c<{\egroup}@{}} 

\newcommand{\mathls}{\addlinespace[5pt]}

\newcommand{\mlsideways}[1]{\begin{sideways}\centering\begin{tabular}{c}#1\end{tabular}\end{sideways}} 

\newcommand{\func}[1]{\textsc{#1}} 

\newcommand{\GQ}[2]{Q_{#1}(#2)} \newcommand{\GP}[2]{P_{#1}(#2)} \newcommand{\B}[3]{B\if*#1\else_{#1}\fi(#2,#3)} \newcommand{\I}[3]{I\if*#1\else_{#1}\fi(#2,#3)} \newcommand{\Digamma}[1]{\Psi(#1)} \newcommand{\harmonic}[1]{H_{#1}} 

\makeatletter
\def\imod#1{\allowbreak\mkern10mu({\operator@font mod}\,\,#1)}
\makeatother

\newcommand{\bigO}[1]{O\!\left(#1\right)} \newcommand{\bigOn}[1]{O(#1)} \newcommand{\bigObig}[1]{O\bigl(#1\bigr)} \newcommand{\bigOmega}[1]{\Omega\!\left(#1\right)} \newcommand{\bigOmegan}[1]{\Omega(#1)} \newcommand{\bigTheta}[1]{\Theta\!\left(#1\right)} \newcommand{\smallo}[1]{o\!\left(#1\right)} 

\newcommand{\toas}{\xrightarrow{\text{a.s.}}}

\newcommand{\dd}{\; \mathrm{d}} 



\newlength\hspaceoflen
\newcommand\hspaceof[1]{\settowidth\hspaceoflen{#1}\hspace\hspaceoflen}

\newcommand{\vcentered}[1]{\begingroup\setbox0=\hbox{#1}\parbox{\wd0}{\box0}\endgroup}

\newcommand\vect[1]{{\boldsymbol{#1}}}
\newcommand\va{\vect{a}}
\newcommand\vb{\vect{b}}
\newcommand\vc{\vect{c}}
\newcommand\vd{\vect{d}}
\newcommand\ve{\vect{e}}
\newcommand\vf{\vect{f}}
\newcommand\vg{\vect{g}}
\newcommand\vh{\vect{h}}
\newcommand\vi{\vect{i}}
\newcommand\vj{\vect{j}}
\newcommand\vk{\vect{k}}
\newcommand\vl{\vect{l}}
\newcommand\vm{\vect{m}}
\newcommand\vn{\vect{n}}
\newcommand\vo{\vect{o}}
\newcommand\vp{\vect{p}}
\newcommand\vq{\vect{q}}
\newcommand\vr{\vect{r}}
\newcommand\vs{\vect{s}}
\newcommand\vt{\vect{t}}
\newcommand\vu{\vect{u}}
\newcommand\vv{\vect{v}}
\newcommand\vw{\vect{w}}
\newcommand\vx{\vect{x}}
\newcommand\vy{\vect{y}}
\newcommand\vz{\vect{z}}
\newcommand\vzero{\vect{0}}
\newcommand\vone{\vect{1}}

\newcommand\valpha{\vect{\alpha}}
\newcommand\vbeta{\vect{\beta}}
\newcommand\veps{\vect{\epsilon}}
\newcommand\vdelta{\vect{\delta}}
\newcommand\veta{\vect{\eta}}
\newcommand\vgamma{\vect{\gamma}}
\newcommand\vtau{\vect{\tau}}
\newcommand\vtheta{\vect{\theta}}
\newcommand\vmu{\vect{\mu}}
\newcommand\vsigma{\vect{\sigma}}
\newcommand\vpi{\vect{\pi}}
\newcommand\vlambda{\vect{\lambda}}

\newcommand\mA{\vect{A}}
\newcommand\mB{\vect{B}}
\newcommand\mC{\vect{C}}
\newcommand\mD{\vect{D}}
\newcommand\mE{\vect{E}}
\newcommand\mF{\vect{F}}
\newcommand\mG{\vect{G}}
\newcommand\mH{\vect{H}}
\newcommand\mI{\vect{I}}
\newcommand\mJ{\vect{J}}
\newcommand\mK{\vect{K}}
\newcommand\mL{\vect{L}}
\newcommand\mM{\vect{M}}
\newcommand\mN{\vect{N}}
\newcommand\mO{\vect{O}}
\newcommand\mP{\vect{P}}
\newcommand\mQ{\vect{Q}}
\newcommand\mR{\vect{R}}
\newcommand\mS{\vect{S}}
\newcommand\mT{\vect{T}}
\newcommand\mU{\vect{U}}
\newcommand\mV{\vect{V}}
\newcommand\mW{\vect{W}}
\newcommand\mX{\vect{X}}
\newcommand\mY{\vect{Y}}
\newcommand\mZ{\vect{Z}}
\newcommand\mzero{\vect{0}}

\newcommand{\mEps}{{\ensuremath{\vect{\Epsilon}}}}
\newcommand{\mSigma}{{\ensuremath{\vect{\Sigma}}}}
\newcommand{\mLambda}{{\ensuremath{\vect{\Lambda}}}}
\newcommand{\mPsi}{{\ensuremath{\vect{\Psi}}}}

\newcommand\bA{\mathbb{A}}
\newcommand\bB{\mathbb{B}}
\newcommand\bC{\mathbb{C}} \newcommand\bD{\mathbb{D}}
\newcommand\bE{\mathbb{E}}
\newcommand\bF{\mathbb{F}}
\newcommand\bG{\mathbb{G}}
\newcommand\bH{\mathbb{H}}
\newcommand\bI{\mathbb{I}}
\newcommand\bJ{\mathbb{J}}
\newcommand\bK{\mathbb{K}}
\newcommand\bL{\mathbb{L}}
\newcommand\bM{\mathbb{M}}
\newcommand\bN{\mathbb{N}} \newcommand\bO{\mathbb{O}}
\newcommand\bP{\mathbb{P}}
\newcommand\bQ{\mathbb{Q}} \newcommand\bR{\mathbb{R}} \newcommand\bS{\mathbb{S}}
\newcommand\bT{\mathbb{T}}
\newcommand\bU{\mathbb{U}}
\newcommand\bV{\mathbb{V}}
\newcommand\bW{\mathbb{W}}
\newcommand\bX{\mathbb{X}}
\newcommand\bY{\mathbb{Y}}
\newcommand\bZ{\mathbb{Z}} 


\newcommand\xA{\mathscr{A}}
\newcommand\xB{\mathscr{B}}
\newcommand\xC{\mathscr{C}}
\newcommand\xD{\mathscr{D}}
\newcommand\xE{\mathscr{E}}
\newcommand\xF{\mathscr{F}}
\newcommand\xG{\mathscr{G}}
\newcommand\xH{\mathscr{H}}
\newcommand\xI{\mathscr{I}}
\newcommand\xJ{\mathscr{J}}
\newcommand\xK{\mathscr{K}}
\newcommand\xL{\mathscr{L}}
\newcommand\xM{\mathscr{M}}
\newcommand\xN{\mathscr{N}}
\newcommand\xO{\mathscr{O}}
\newcommand\xP{\mathscr{P}}
\newcommand\xQ{\mathscr{Q}}
\newcommand\xR{\mathscr{R}}
\newcommand\xS{\mathscr{S}}
\newcommand\xT{\mathscr{T}}
\newcommand\xU{\mathscr{U}}
\newcommand\xV{\mathscr{V}}
\newcommand\xW{\mathscr{W}}
\newcommand\xX{\mathscr{X}}
\newcommand\xY{\mathscr{Y}}
\newcommand\xZ{\mathscr{Z}}

\DeclareMathAlphabet{\mathcal}{OMS}{cmsy}{m}{n}
\newcommand\cA{\mathcal{A}}
\newcommand\cB{\mathcal{B}}
\newcommand\cC{\mathcal{C}}
\newcommand\cD{\mathcal{D}}
\newcommand\cE{\mathcal{E}}
\newcommand\cF{\mathcal{F}}
\newcommand\cG{\mathcal{G}}
\newcommand\cH{\mathcal{H}}
\newcommand\cI{\mathcal{I}}
\newcommand\cJ{\mathcal{J}}
\newcommand\cK{\mathcal{K}}
\newcommand\cL{\mathcal{L}}
\newcommand\cM{\mathcal{M}}
\newcommand\cN{\mathcal{N}}
\newcommand\cO{\mathcal{O}}
\newcommand\cP{\mathcal{P}}
\newcommand\cQ{\mathcal{Q}}
\newcommand\cR{\mathcal{R}}
\newcommand\cS{\mathcal{S}}
\newcommand\cT{\mathcal{T}}
\newcommand\cU{\mathcal{U}}
\newcommand\cV{\mathcal{V}}
\newcommand\cW{\mathcal{W}}
\newcommand\cX{\mathcal{X}}
\newcommand\cY{\mathcal{Y}}
\newcommand\cZ{\mathcal{Z}}

\DeclareMathAlphabet\mathbfcal{OMS}{cmsy}{b}{n}
\newcommand\tA{\mathbfcal{A}}
\newcommand\tB{\mathbfcal{B}}
\newcommand\tC{\mathbfcal{C}}
\newcommand\tD{\mathbfcal{D}}
\newcommand\tE{\mathbfcal{E}}
\newcommand\tF{\mathbfcal{F}}
\newcommand\tG{\mathbfcal{G}}
\newcommand\tH{\mathbfcal{H}}
\newcommand\tI{\mathbfcal{I}}
\newcommand\tJ{\mathbfcal{J}}
\newcommand\tK{\mathbfcal{K}}
\newcommand\tL{\mathbfcal{L}}
\newcommand\tM{\mathbfcal{M}}
\newcommand\tN{\mathbfcal{N}}
\newcommand\tO{\mathbfcal{O}}
\newcommand\tP{\mathbfcal{P}}
\newcommand\tQ{\mathbfcal{Q}}
\newcommand\tR{\mathbfcal{R}}
\newcommand\tS{\mathbfcal{S}}
\newcommand\tT{\mathbfcal{T}}
\newcommand\tU{\mathbfcal{U}}
\newcommand\tV{\mathbfcal{V}}
\newcommand\tW{\mathbfcal{W}}
\newcommand\tX{\mathbfcal{X}}
\newcommand\tY{\mathbfcal{Y}}
\newcommand\tZ{\mathbfcal{Z}}





\newcommand\Ahat{{\hat A}}
\newcommand\Bhat{{\hat B}}
\newcommand\Chat{{\hat C}}
\newcommand\Dhat{{\hat D}}
\newcommand\Ehat{{\hat E}}
\newcommand\Fhat{{\hat F}}
\newcommand\Ghat{{\hat G}}
\newcommand\Hhat{{\hat H}}
\newcommand\Ihat{{\hat I}}
\newcommand\Jhat{{\hat J}}
\newcommand\Khat{{\hat K}}
\newcommand\Lhat{{\hat L}}
\newcommand\Mhat{{\hat M}}
\newcommand\Nhat{{\hat N}}
\newcommand\Ohat{{\hat O}}
\newcommand\Phat{{\hat P}}
\newcommand\Qhat{{\hat Q}}
\newcommand\Rhat{{\hat R}}
\newcommand\Shat{{\hat S}}
\newcommand\That{{\hat T}}
\newcommand\Uhat{{\hat U}}
\newcommand\Vhat{{\hat V}}
\newcommand\What{{\hat W}}
\newcommand\Xhat{{\hat X}}
\newcommand\Yhat{{\hat Y}}
\newcommand\Zhat{{\hat Z}}

\newcommand\ahat{{\hat a}}
\newcommand\bhat{{\hat b}}
\newcommand\chat{{\hat c}}
\newcommand\dhat{{\hat d}}
\newcommand\ehat{{\hat e}}
\newcommand\fhat{{\hat f}}
\newcommand\ghat{{\hat g}}
\newcommand\hhat{{\hat h}}
\newcommand\ihat{{\hat i}}
\newcommand\jhat{{\hat j}}
\newcommand\khat{{\hat k}}
\newcommand\lhat{{\hat l}}
\newcommand\mhat{{\hat m}}
\newcommand\nhat{{\hat n}}
\newcommand\ohat{{\hat o}}
\newcommand\phat{{\hat p}}
\newcommand\qhat{{\hat q}}
\newcommand\rhat{{\hat r}}
\newcommand\shat{{\hat s}}
\newcommand\that{{\hat t}}
\newcommand\uhat{{\hat u}}
\newcommand\vhat{{\hat v}}
\newcommand\what{{\hat w}}
\newcommand\xhat{{\hat x}}
\newcommand\yhat{{\hat y}}
\newcommand\zhat{{\hat z}}

\newcommand\rhohat{{\hat\rho}}


\accentedsymbol\Abar{{\bar A}}
\accentedsymbol\Bbar{{\bar B}}
\accentedsymbol\Cbar{{\bar C}}
\accentedsymbol\Dbar{{\bar D}}
\accentedsymbol\Ebar{{\bar E}}
\accentedsymbol\Fbar{{\bar F}}
\accentedsymbol\Gbar{{\bar G}}
\accentedsymbol\Hbar{{\bar H}}
\accentedsymbol\Ibar{{\bar I}}
\accentedsymbol\Jbar{{\bar J}}
\accentedsymbol\Kbar{{\bar K}}
\accentedsymbol\Lbar{{\bar L}}
\accentedsymbol\Mbar{{\bar M}}
\accentedsymbol\Nbar{{\bar N}}
\accentedsymbol\Obar{{\bar O}}
\accentedsymbol\Pbar{{\bar P}}
\accentedsymbol\Qbar{{\bar Q}}
\accentedsymbol\Rbar{{\bar R}}
\accentedsymbol\Sbar{{\bar S}}
\accentedsymbol\Tbar{{\bar T}}
\accentedsymbol\Ubar{{\bar U}}
\accentedsymbol\Vbar{{\bar V}}
\accentedsymbol\Wbar{{\bar W}}
\accentedsymbol\Xbar{{\bar X}}
\accentedsymbol\Ybar{{\bar Y}}
\accentedsymbol\Zbar{{\bar Z}}

\accentedsymbol\abar{{\bar a}}
\accentedsymbol\bbar{{\bar b}}
\accentedsymbol\cbar{{\bar c}}
\accentedsymbol\dbar{{\bar d}}
\accentedsymbol\ebar{{\bar e}}
\accentedsymbol\fbar{{\bar f}}
\accentedsymbol\gbar{{\bar g}}
\makeatletter
\@ifundefined{hbar}{}{
        \let\oldhbar\hbar \let\hbar\@undefined
}
\makeatother
\accentedsymbol\hbar{{\bar h}}
\accentedsymbol\ibar{{\bar i}}
\accentedsymbol\jbar{{\bar j}}
\accentedsymbol\kbar{{\bar k}}
\accentedsymbol\lbar{{\bar l}}
\accentedsymbol\mbar{{\bar m}}
\accentedsymbol\nbar{{\bar n}}
\makeatletter
\@ifundefined{obar}{}{
        \let\oldobar\obar \let\obar\@undefined
}
\makeatother
\accentedsymbol{\obar}{{\bar o}}
\accentedsymbol\pbar{{\bar p}}
\accentedsymbol\qbar{{\bar q}}
\accentedsymbol\rbar{{\bar r}}
\accentedsymbol\sbar{{\bar s}}
\accentedsymbol\tbar{{\bar t}}
\accentedsymbol\ubar{{\bar u}}
\accentedsymbol\vbar{{\bar v}}
\accentedsymbol\wbar{{\bar w}}
\accentedsymbol\xbar{{\bar x}}
\accentedsymbol\ybar{{\bar y}}
\accentedsymbol\zbar{{\bar z}}

\newcommand\eps{\epsilon}



\accentedsymbol\mAhat{{\hat\mA}}
\accentedsymbol\mBhat{{\hat\mB}}
\accentedsymbol\mChat{{\hat\mC}}
\accentedsymbol\mDhat{{\hat\mD}}
\accentedsymbol\mEhat{{\hat\mE}}
\accentedsymbol\mFhat{{\hat\mF}}
\accentedsymbol\mGhat{{\hat\mG}}
\accentedsymbol\mHhat{{\hat\mH}}
\accentedsymbol\mIhat{{\hat\mI}}
\accentedsymbol\mJhat{{\hat\mJ}}
\accentedsymbol\mKhat{{\hat\mK}}
\accentedsymbol\mLhat{{\hat\mL}}
\accentedsymbol\mMhat{{\hat\mM}}
\accentedsymbol\mNhat{{\hat\mN}}
\accentedsymbol\mOhat{{\hat\mO}}
\accentedsymbol\mPhat{{\hat\mP}}
\accentedsymbol\mQhat{{\hat\mQ}}
\accentedsymbol\mRhat{{\hat\mR}}
\accentedsymbol\mShat{{\hat\mS}}
\accentedsymbol\mThat{{\hat\mT}}
\accentedsymbol\mUhat{{\hat\mU}}
\accentedsymbol\mVhat{{\hat\mV}}
\accentedsymbol\mWhat{{\hat\mW}}
\accentedsymbol\mXhat{{\hat\mX}}
\accentedsymbol\mYhat{{\hat\mY}}
\accentedsymbol\mZhat{{\hat\mZ}}

\accentedsymbol\vahat{{\hat\va}}
\accentedsymbol\vbhat{{\hat\vb}}
\accentedsymbol\vchat{{\hat\vc}}
\accentedsymbol\vdhat{{\hat\vd}}
\accentedsymbol\vehat{{\hat\ve}}
\accentedsymbol\vfhat{{\hat\vf}}
\accentedsymbol\vghat{{\hat\vg}}
\accentedsymbol\vhhat{{\hat\vh}}
\accentedsymbol\vihat{{\hat\vi}}
\accentedsymbol\vjhat{{\hat\vj}}
\accentedsymbol\vkhat{{\hat\vk}}
\accentedsymbol\vlhat{{\hat\vl}}
\accentedsymbol\vmhat{{\hat\vm}}
\accentedsymbol\vnhat{{\hat\vn}}
\accentedsymbol\vohat{{\hat\vo}}
\accentedsymbol\vphat{{\hat\vp}}
\accentedsymbol\vqhat{{\hat\vq}}
\accentedsymbol\vrhat{{\hat\vr}}
\accentedsymbol\vshat{{\hat\vs}}
\accentedsymbol\vthat{{\hat\vt}}
\accentedsymbol\vuhat{{\hat\vu}}
\accentedsymbol\vvhat{{\hat\vv}}
\accentedsymbol\vwhat{{\hat\vw}}
\accentedsymbol\vxhat{{\hat\vx}}
\accentedsymbol\vyhat{{\hat\vy}}
\accentedsymbol\vzhat{{\hat\vz}}\clearpage{}
\newcommand\checkyes{\parbox{.3cm}{\centering \checkmark}}
\newcommand\checkno{\parbox{.3cm}{\centering $\times$}}
\newcommand\checkmaybe{\parbox{.3cm}{\centering $\circ$}}
\newcommand\ak[1]{\red{\fbox{AK} #1}}
\newcommand\as[1]{\orange{\fbox{AS} #1}}
\newcommand\rg[1]{\red{\fbox{RG} #1}}
\newcolumntype{L}[1]{>{\raggedright\arraybackslash}p{#1}}



\title{A Benchmark for Semi-Inductive Link Prediction in Knowledge Graphs}


\author{Adrian Kochsiek \\
  University of Mannheim \\
  Germany \\
  \texttt{akochsiek@uni-mannheim.de} \\\And
  Rainer Gemulla \\
  University of Mannheim \\
  Germany \\
  \texttt{rgemulla@uni-mannheim.de} \\}

\begin{document}
\maketitle
\begin{abstract}
  Semi-inductive link prediction (LP) in knowledge graphs (KG) is the task of
  predicting facts for new, previously unseen entities based on context
  information. Although new entities can be integrated by retraining the model
  from scratch in principle, such an approach is infeasible for large-scale KGs,
  where retraining is expensive and new entities may arise frequently. In this
  paper, we propose and describe a large-scale benchmark to evaluate
  semi-inductive LP models. The benchmark is based on and extends Wikidata5M: It
  provides transductive, k-shot, and 0-shot LP tasks, each varying the available
  information from (i) only KG structure, to (ii) including textual mentions,
  and (iii) detailed descriptions of the entities. We report on a small study of
  recent approaches and found that semi-inductive LP performance is far from
  transductive performance on long-tail entities throughout all experiments. The
  benchmark provides a test bed for further research into integrating context and
  textual information in semi-inductive LP models.
\end{abstract}

\section{Introduction}
\label{sec:introduction}
A knowledge graph (KG) is a collection of facts describing relations between
real-world entities. Facts are represented in the form of
subject-relation-object triples such as (\emph{Dave Grohl}, \emph{memberOf},
\emph{Foo Fighters}). In this paper, we consider link prediction (LP) tasks, i.e.,
the problem of inferring missing facts in the KG. LP can be transductive (TD;
all entities known a priori), semi-inductive (SI; some entities known a priori),
and inductive (no entities known a priori).
We concentrate on semi-inductive and transductive LP. 

SI-LP focuses on modeling entities that are unknown or unseen during LP, such
as out-of-KG entities (not part or not yet part of the KG) or newly created
entities, e.g., a new user, product, or event. Such previously unknown entities
can be handled by retraining in principle. For large-scale KGs, however,
retraining is inherently expensive and new entities may arise frequently.
Therefore, the goal of SI-LP is to avoid retraining and perform LP directly,
i.e., to generalize beyond the entities seen during training.

To perform LP for unseen entities, context information about these entities is needed.
The amount and form of context information varies widely and may take the form
of facts and/or textual information, such as an entity mention and/or its
description. For example, a new user in a social network may provide a name,
basic facts such as gender or country of origin, and perhaps a textual
self-description.



In this paper, we introduce the \emph{Wikidata5M-SI} benchmark for SI-LP. Our
benchmark is based on the popular Wikidata5M~\cite{wang2021KEPLER} benchmark and
has four major design goals: (G1) It ensures that unseen entities are long tail
entities since popular entities (such as, say, \emph{Foo Fighters}) and/or types
and taxons (such as human and organization) are unlikely to be unseen. (G2) It
allows to evaluate each model with varying amounts of contextual facts (0-shot,
few-shot, transductive), i.e., to explore individual models across a range of
tasks. (G3) It provides a controlled amount of textual information (none,
mention, full description), where each setting demands different modeling
capabilities. Finally, (G4) the benchmark is large-scale so that retraining is
not a suitable approach. All prior SI-LP benchmarks violate at least one of
these criteria.


We report on a small experimental study with recent LP approaches.
In general, we found that
\begin{enumerate}[itemsep=0em]
  \item SI performance was far behind TD performance in all experiments for long-tail entities,
  \item there was generally a trade-off between TD and SI performance,
  \item textual information was highly valuable,
  \item proper integration of context and textual information needs further exploration, and
  \item facts involving less common relations provided more useful context.
\end{enumerate}
Our benchmark provides directions and a test bed for further research into SI-LP.


\section{Related Work}
\label{sec:related_work}

Multiple SI-LP datasets have been proposed in the literature. The benchmarks of
\citet{daza2021inductive}, \citet{albooyeh2020out}, and
\citet{galkin2021nodepiece} are obtained by first merging the splits of smaller
transductive LP datasets and subsequently sampling unseen entities uniformly to
construct validation and test splits. These benchmarks do not satisfy goals
G1--G4. \citet{shi2018open} follow a similar approach but focus on only
0-shot evaluation based on textual features. \citet{xie2016representation} and
\citet{shah2019open} select entities from Freebase with connection to entities
in FB15k~\cite{bordes2013translating}, also focussing on 0-shot evaluation using
rich textual descriptions. These approaches do not satisfy G2 and G3. Finally,
\citet{wang2019logic} and \citet{hamaguchi2017knowledge} uniformly sample test
triples and mark occurring entities as unseen. These approaches do not focus on
long-tail entities (and, in fact, the accumulated context of unseen entities may
be larger than the training graph itself) and they do not satisfy G1--G3.



There are also several of fully-inductive LP
benchmarks~\cite{teru2020inductive,wang2021KEPLER} involving KGs. While SI-LP
aims to connect unseen entities to an existing KG, fully-inductive LP reasons
about a new KG with completely separate entities (but shared relations). We do
not consider this task in this work.

\section{The \emph{Wikidata5M-SI} Benchmark}
\label{sec:dataset}



\emph{Wikidata5M-SI} is based on the popular Wikidata5M~\cite{wang2021KEPLER}
benchmark, which is induced by the 5M most common entities of Wikidata. Our
benchmark contains trans\-duc\-tive and semi-inductive valid/test splits; see
Tab.~\ref{tab:dataset_statistics} for an overview. Generally, we aimed to keep
Wikidata5M-SI as close as possible to Wikidata5M. We did need to modify the
original transductive valid and test splits, however, because they
unintentionally contained both seen and unseen entities (i.e., these splits were
not fully transductive). We did that by simply removing all triples involving
unseen entities.

\textbf{Unseen entities.} To ensure that unseen entities in the semi-inductive
splits are from the long tail (G1), we only considered entities of degree $20$
or less. To be able to provide sufficient context for few-shot tasks (G2), we
further did not consider entities of degree 10 or less. In more detail, we
sampled 500 entities of degrees 11--20 (stratified sampling grouped by degree)
for each semi-inductive split. All sampled entities, along with their facts, were
removed from the train split. Note that these entities (naturally) have a
different class distribution than all entities; see
Sec.~\ref{sec:entity_type_bias} for details.

\begin{table}
  \centering
  \resizebox{\columnwidth}{!}{\begin{tabular}{lrrrrr}
    \toprule
    & & \multicolumn{2}{c}{\textbf{Transductive}} & \multicolumn{2}{c}{\textbf{Semi-inductive}} \\
    \cmidrule{3-6}
    & \textbf{Train} & \textbf{Valid} & \textbf{Test} & \textbf{Valid} & \textbf{Test} \\
    \midrule
    Triples & 20,600,187 & 4,983 & 4,977 & 5,500 & 5,500 \\
    Entities & 4,593,103 & 7,768 & 7,760 & 3,722 & 3,793 \\
    Entities unseen & - & 0 & 0 & 500 & 500 \\
    Relations & 822 & 217 & 211 & 126 & 115 \\
    \bottomrule
  \end{tabular}
  }
  \caption{Statistics of the Wikidata5M-SI splits.}
  \label{tab:dataset_statistics}
\end{table}

\begin{table*}
  \centering
  \begin{tabular}{lL{10cm}ll}
    \toprule
    ID & Q18918 \\
    \midrule
    Mention & Sam Witwer \\
    \midrule
    Description & \multicolumn3{p{12.3cm}}{Samuel Stewart Witwer (born October 20, 1977) is an American actor and musician. He is known for portraying Crashdown in Battlestar Galactica, Davis Bloome in Smallville, Aidan Waite in Being Human, and Ben Lockwood in Supergirl. He voiced the protagonist Galen Marek / Starkiller in Star Wars: The Force Unleashed, the Son in Star Wars: The Clone Wars and Emperor Palpatine in Star Wars Rebels, both of which he has also voiced Darth Maul.} \\
    \midrule
    Context triples & instance of | human & M: \checkmaybe & D: \checkmaybe \\
    & country of citizenship | United States of America & M: \checkno & D: \checkmaybe \\
    & occupation | musician & M: \checkno & D: \checkyes \\
    & occupation | actor  & M: \checkno & D: \checkyes \\
    & place of birth | Glenview & M: \checkno & D: \checkno \\
    & given name | Samuel & M: \checkmaybe & D: \checkyes \\
    & given name | Sam  & M: \checkyes & D: \checkmaybe \\
    & cast member | Battlestar Galactica & M: \checkno & D: \checkyes \\
    & cast member | Being Human - supernatural drama television series & M: \checkno & D: \checkyes \\
    & cast member | Star Wars: The Force Unleashed II & M: \checkno & D: \checkmaybe \\
    & cast member | The Mist & M: \checkno & D: \checkno \\
    \bottomrule
  \end{tabular}
  \caption{
    Example of an entity from the semi-inductive validation set of Wikidata5M-SI.
    For each triple, we annotated whether the answer is contained in (\checkmark), deducible from ($\circ$), or not contained in ($\!\times\!$) mention (M) or description (D).
  }
  \label{tab:example_mention_description}
\end{table*}


\textbf{Tasks and metrics.} For TD tasks, we follow the standard protocol of
Wikidata5M. To construct SI tasks, we include 11 of the original facts of each
unseen entity into its SI split; each split thus contains 5,500 triples. This
enables up to 10-shot SI tasks (1 fact to test, up to 10 facts for context). For
entities of degree larger than 11, we select the 11 facts with the most frequent
relations; see Tab.~\ref{tab:example_mention_description} for an example.
The rationale is that more common relations (such as \emph{instanceOf} or
\emph{country}) may be considered more likely to be provided for unseen entities
than rare ones (such as \emph{militaryBranch} or \emph{publisher}). We then
construct a single $k$-shot task for each triple $(s,p,o)$ in the SI split as
follows. When, say, $s$ is the unseen entity, we consider the LP task $(s,p,?)$
and provide $k$ additional facts of form $(s,p',o')$ as context. Context facts
are selected by frequency as above, but we also explored random and infrequent-relation context in our study. Models are asked to provide a ranking of
predicted answers, and we determine the filtered mean reciprocal rank (MRR) and Hits@K of the
correct answer ($o$).

\textbf{Textual information.} For each entity, we provide its principal mention
and a detailed description (both directly from Wikidata5M); see
Tab.~\ref{tab:example_mention_description}. This allows to differentiate
model evaluation with varying amounts of textual information per entity (G3):
(A) atomic, i.e., no textual information, (M) mentions only, and (D) detailed
textual descriptions as in~\cite{kochsiek2023friendly}. This differentiation is
especially important in the SI setting, as detailed text descriptions might not
be provided for unseen entities and each setting demands different modeling
capabilities. In fact, (A) performs reasoning only using graph structure,
whereas (D) also benefits from information extraction to some extent. We discuss
this further in Sec.~\ref{sec:experimental_study}.







\section{Semi-Inductive Link Prediction Models}
\label{sec:model_selection}

We briefly summarize recent models for SI-LP; we considered these models in our experimental study.

\textbf{Graph-only models.} \emph{ComplEx}~\cite{trouillon2016complex} is
the best-performing transductive KGE model on
Wikidata5M~\cite{kochsiek2023start}. To use ComplEx for SI-LP, we follow an approach explored
by~\citet{jambor2021exploring}. In particular, we represent each entity as the
sum of a local embedding (one per entity) and a global bias embedding. For
0-shot, we solely use the global bias for the unseen entity. For k-shot, we
obtain the local embedding for the unseen entity by performing a single training
step on the context triples (keeping all other embeddings fixed). An
alternative approach is taken by \emph{oDistMult-ERAvg}~\cite{albooyeh2020out},
which represents unseen entities by aggregating the embeddings of the relations
and entities in the context.\footnote{To address the high memory
  footprint~\cite{galkin2021nodepiece} of oDistMult-ERAvg, we extend it with
  neighborhood sampling.}
A more direct approach is taken by \emph{HittER}~\cite{chen2021hitter}, which
contextualizes the query entity with its neighborhood for TD-LP. The approach
can be used for SI-LP directly by using a masking token (akin to the global
bias above) for an unseen entity.
We originally planned to consider \emph{NodePiece}~\cite{galkin2021nodepiece}
(entity represented by a combination of anchor embeddings) and
\emph{NBFNet}~\cite{nbfnet} (a GNN-based LP model); both support SI-LP directly.
However, the available implementations did not scale to Wikidata5M-SI (out of
memory).\footnote{For NBFNet~\cite{nbfnet}, the large memory footprint is inherent to the model; it is a full-graph GNN and hard to scale. For NodePiece~\cite{galkin2021nodepiece}, however, the problem mainly lies in the expensive evaluation. All intermediate representations are precomputed, leading to a large memory overhead.}


\textbf{Text-based models.} As a baseline approach to integrate textual
information directly into KGE models, we consider the approach explored in the
WikiKG90M benchmark~\cite{hu2021ogblsc}; see Sec.~\ref{sec:text_kge} for
details. The remaining approaches are purely textual.
\emph{SimKGC}~\cite{wang2022simkgc}
utilizes two pretrained BERT Transformers: one to embed query entities (and
relations) based on their mention or description, and one for tail entities.
Using a contrastive learning approach, it measures cosine similarity between
both representations for ranking.
\emph{KGT5}~\cite{saxena2022sequence} is a sequence-to-sequence link prediction
approach, which is trained to generate the mention of the answer entity using
the mention or description of the query entity and relation as input. Both
approaches support 0-shot SI-LP when textual information is provided for the
query entity. They do not utilize additional context, however, i.e., do not
support k-shot SI-LP. \emph{KGT5-context}~\cite{kochsiek2023friendly} is an
extension of KGT5, which extends the input of KGT5 by the one-hop neighborhood
of the query entity and consequently supports k-shot LP directly.



\section{Experimental Study}
\label{sec:experimental_study}


\begin{table*}
  \centering
  \resizebox{\textwidth}{!}{\begin{tabular}{@{}lrrrrrrrc@{}}
    \toprule
    & \multicolumn{2}{c}{\textbf{Transductive}} & \multicolumn{5}{c}{\textbf{Semi-inductive (num. shots)}}
    & \multirow{2}{*}{\begin{tabular}[l]{@{}c@{}}\textbf{Pre-}\\\textbf{trained}\end{tabular}}
    \\
    \cmidrule{2-8}
    \textbf{Model} & \textbf{All} & \textbf{Long tail} & \textbf{0} & \textbf{1} & \textbf{3} & \textbf{5} & \textbf{10} \\
    \midrule
    ComplEx + Bias + Fold in~\cite{jambor2021exploring} & \underline{0.308} & 0.523 & 0.124 & 0.151 & 0.176 & 0.190 & 0.206 & no\\
    DistMult + ERAvg~\cite{albooyeh2020out} & 0.294 & 0.512 & - & 0.171 & 0.246 & 0.295 & \underline{0.333} & no\\
    HittER~\cite{chen2021hitter} & 0.284 & 0.512 & 0.019 & 0.105 & 0.153 & 0.179 & 0.221 & no \\
    \midrule
    DistMult + ERAvg + Mentions & 0.299 & 0.535 & - & 0.187 & 0.235 & 0.258 & 0.280 & yes \\
    SimKGC (mentions only) & 0.212 & 0.361 & 0.220 & - & - & - & - & yes \\
    KGT5~\cite{saxena2022sequence} & 0.281 & 0.542 & 0.310 & - & - & - & - & no \\
    KGT5-context~\cite{kochsiek2023friendly} & \underline{0.374} & 0.678 & 0.220 & 0.217 & 0.236 & 0.259 & \underline{0.311} & no \\
    \midrule
    DistMult + ERAvg + Descriptions & 0.313 & 0.585 & - & 0.278 & 0.281 & 0.285 & 0.292 & yes \\
    SimKGC + Descriptions~\cite{wang2022simkgc} & 0.353& 0.663 & 0.403 & - & - & - & - & yes \\
    KGT5 + Descriptions~\cite{kochsiek2023friendly} & 0.364 & 0.728 & \textbf{0.470} & - & - & - & - & no \\
    KGT5-context + Descriptions~\cite{kochsiek2023friendly} & \textbf{0.420} & 0.777 & 0.417 & 0.420 & 0.416 & 0.420 & 0.437 & no \\
    \bottomrule
  \end{tabular}
  }
  \caption{
    Transductive and semi-inductive link prediction results in terms of MRR on the dataset Wikidata5M-SI.
    The first group presets results on the atomic, the second on the mentions and the third on the descriptions dataset.
    Best per TD/SI in bold.
    Best per group underlined.
  }
  \label{tab:si_results}
\end{table*}

We evaluated all presented baseline models in the TD and SI setting on the atomic, mentions, and descriptions dataset.
Further, we evaluated in detail which context was most useful and what information was conveyed by textual mentions and descriptions.


\begin{table}[ht]
  \centering
  \resizebox{0.9\columnwidth}{!}
  {
  \aboverulesep = 0.20ex
  \belowrulesep = 0.20ex
  \begin{tabular}{lrr}
    \toprule
    & \textbf{Mention} & \textbf{Description} \\
    \midrule
    Contained & 10\% & 44\% \\
    Deducible & 7\% & 10\% \\
    Not contained & 83\% & 46\% \\
    \bottomrule
  \end{tabular}
  }
  \caption{
    Information about a query answer contained in mentions and descriptions.
    Annotated for 100 sampled triples from 0-shot valid.
    For an example, see Tab.~\ref{tab:example_mention_description}.
  }
  \label{tab:text_information}
\end{table}



\textbf{Setup.}
Source code, configuration, and the benchmark itself are available at \url{https://github.com/uma-pi1/wikidata5m-si}.
For further details on hyperparameter tuning and training see Sec.~\ref{sec:experimental_setup}.



\textbf{Main results.}
Transductive and SI performance in terms of MRR of all models is presented in Tab.~\ref{tab:si_results};
Hits@K  in Tab.~\ref{tab:si_results_h1}-\ref{tab:si_results_h10} (Sec.~\ref{sec:appendix}).
Note that overall transductive performance was oftentimes below best reported SI performance.
This is due to varying degrees of query entities between both settings.
Typically, models perform better predicting new relations for an entity (e.g., the birthplace) than predicting additional objects for a known relation (e.g., additional awards won by a person)~\cite{saxena2022sequence,kochsiek2023friendly}.
For a direct comparison between both settings, we additionally report TD performance on long tail query entities.\footnote{We define long tail query entities as entities with degree $\leq$ 10 as in the SI setting.}

\textbf{Atomic.}
TD performance on the long tail was considerably higher than SI performance.
As no information was provided for unseen entities, 0-shot was not reasonably possible.
Without text-based information, context was a necessity.
A simple neighborhood aggregation---entity-relation average (ERAvg)---offered the best integration of context.


\textbf{Mentions.}
Integrating mentions did not improve performance on its own, as provided text information was still limited.
However, additionally providing context information during inference (KGT5-context) simplified the learning problem and improved TD performance significantly.
But for 0-shot, the limited text information provided with mentions allowed for reasonable performance.
To analyze what information is conveyed for 0-shot, we annotated 100 valid
triples; see Tab.~\ref{tab:text_information}. In 10\% of cases, the answer was
already contained in the mention, and it was deducible in at least 7\%. This
enabled basic reasoning without any further information. In contrast to the TD
setting, KGT5 outperformed its context extension. KGT5-context was reliant on
context which was lacking especially during 0-shot. This showed a trade-off
between best performance in the SI and TD setting. This trade-off could be
mitigated by applying (full and partial) context hiding. With such adapted
training, KGT5-context reached a middle ground with a transductive MRR of
0.366 and 0-shot MRR of 0.283.\footnote{In 25\%/25\%/50\% of cases, we hid the full
  context/sampled between 1-10 neighbors/used the full
  context, respectively.} However, even with full context (10-shot), performance was still
only on par with KGT5. Therefore, context information did not bring any further
benefits when text was provided.


\textbf{Descriptions.}
Further, integrating descriptions improved performance for both settings, TD and SI, considerably; see Tab.~\ref{tab:si_results}.
Similar to the mentions-only setting, KGT5-context performed best in TD and KGT5 in the SI setting.
Applying the same trade-off with context-hiding reached a middle ground with 0.418 TD-MRR and 0.449 SI-MRR.

Descriptions were very detailed and partially contained the correct answer as
well as the same information as contained in context triples; see
Tab.~\ref{tab:text_information}. Therefore, performance did not further improve
with context size. In such cases, models mainly benefit from information
extraction capabilities. To judge how much information extraction helps, we
grouped performance of KGT5+description in the 0-shot setting on validation data
into the groups \textit{contained}, \textit{deducible} and \textit{not
  contained} in description; see Fig.~\ref{fig:prediction_per_annotation} in
Sec.~\ref{sec:appendix}. When contained, the correct answer was extracted in
$\approx70\%$ of cases.


















\textbf{Context selection.} We selected the most common relations as context
triples so far, as this may be a more realistic setting. To investigate the
effect of this selection approach, we compared the default selection of choosing
\emph{most common} relations to \emph{least common} and \emph{random}. Results
for KGT5-context are shown in Tab.~\ref{tab:context_selection}; for all other
models in Tab.~\ref{tab:context_selection_all} in Sec.~\ref{sec:appendix}. We
found that the less common the relations of the provided context, the better the
SI performance. More common context relations often described high-level
concepts, while less common provided further detail; see the example in
Tab.~\ref{tab:example_mention_description}. While more common context may
be more readily available, less common context was more helpful to describe a new
entity.





\begin{table}
  \centering
  \resizebox{0.9\columnwidth}{!}
  {
  \aboverulesep = 0.20ex
  \belowrulesep = 0.20ex
  \begin{tabular}{lrrr}
    \toprule
    \textbf{Context selection} & \textbf{1} & \textbf{3} & \textbf{5} \\
    \midrule
    Most common & 0.217 & 0.236 & 0.259 \\
    Least common & 0.253 & 0.273 & 0.290 \\
    Random & 0.237 & 0.260 & 0.281 \\
    \bottomrule
  \end{tabular}
  }
  \caption{Influence of context selection. Semi-inductive test MRR of KGT5-context.}
  \label{tab:context_selection}
\end{table}

\section{Conclusion}
\label{sec:conclusion}

We proposed the new WikiData5M-SI large-scale benchmark for semi-supervised link
prediction. The benchmark focuses on unseen entities from the long tail and
allows to evaluate models with varying and controlled amounts of factual and
textual context information.
In our experimental evaluation, we found that semi-inductive LP performance fell
behind transductive performance for long-tail entities in general, and that
detailed textual information was often more valuable than factual context
information. Moreover, current models did not integrate these two types of
information adequately, suggesting a direction for future research.




\section*{Limitations}

This study was performed on Wikidata5M-SI, i.e., a subset of a single knowledge
graph. Model performance and insights may vary if graph structure and/or
availability and usefulness of mentions and description is different. In particular, the entity descriptions provided with Wikidata5M-SI partly contained
information relevant for link prediction so that models benefited from information extraction capabilities.




\section*{Ethics Statement}
This research adapts publicly available data, benchmarks, and codebases for evaluation.
We believe that this research was conducted in an ethical manner in compliance with all relevant laws and regulations.


\bibliography{anthology,custom}
\bibliographystyle{acl_natbib}

\appendix

\section{Appendix}
\label{sec:appendix}





\subsection{Distribution of Unseen Entities}
\label{sec:entity_type_bias}

Long-tail entities have a different distribution than entities from the whole
KG; see Tab.~\ref{tab:entity_type_distribution} for an overview of the
distribution shift for the top 10 entity types. This difference is
natural. In particular, high-degree entities in a KG such as Wikidata often
refer to types/taxons (e.g, human, organization, ...) as well as popular named
entities (e.g., Albert Einstein, Germany, ...). These entities are fundamental
to the KG and/or of high interest and have many facts associated with them. For
this reason, they do not form suitable candidates for benchmarking unseen or new
entities. In addition, removing high-degree entities for the purpose of
evaluating SI-LP is likely to distort the KG (e.g., consider removing type
"human" or "Germany"). In contrast, Wikidata5M-SI focuses on entities for which
knowledge is not yet abundant: long-tail entities are accompanied by no or few
facts (at least initially) and our SI-LP benchmark tests reasoning capabilities
with this limited information.


\subsection{Integrating Text into KGE Models}
\label{sec:text_kge}


To integrate text into traditional KGE models, we follow the baseline models of the WikiKG90M link prediction challenge~\cite{hu2021ogblsc}.
We embed mentions combined with descriptions using MPNet~\cite{song2020mpnet}, concatenate the resulting descriptions embedding with the entity embedding, and project it with a linear layer for the final representation of the entity.
In combination with oDistMult-ERAvg~\cite{albooyeh2020out}, we apply the aggregation of neighboring entities and relations on the entity embedding part only.
The resulting aggregation is then concatenated with its description and finally projected.

\balance
This approach is closely related to BLP~\cite{daza2021inductive}.
The main differences to BLP are:
\begin{enumerate}
\item~\citet{hu2021ogblsc} use MPNet, BLP uses BERT.
  \item In combination with DistMult-ERAvg, we concatenate a learnable "structural embedding" to the CLS embedding of the language model, whereas BLP does not.
\end{enumerate}



\subsection{Experimental Setup}
\label{sec:experimental_setup}

For hyperparameter optimization for ComplEx~\cite{trouillon2016complex}, DistMult~\cite{yang2015embedding}, and HittER~\cite{chen2021hitter}, we used the multi-fidelity approach GraSH~\cite{kochsiek2023start} implemented in LibKGE~\cite{libkge} with 64 initial trials and trained for up to 64 epochs.
For fold-in, we reused training hyperparameters and trained for a single epoch on the provided context.
For text-based approaches, we used the hyperparameters and architectures proposed by the authors for the transductive split of Wikidata5M.
We trained on up to 5 A6000-GPUs with $49$GB of VRAM.





\begin{table*}
  \centering
  \begin{tabular}{llrr}
    \toprule
    \textbf{WikidataID} & \textbf{Mention} & \textbf{All entities} & \textbf{Long-tail entities} \\
    \midrule
    Q5 & human & 39\% & 61\% \\
    Q11424 & film & 3\% & 8\% \\
    Q484170 & commune of France & 1\% & 7\% \\
    Q482994 & album & 3\% & 1\% \\
    Q16521 & taxon & 9\% & 1\% \\
    Q134556 & single & 1\% & 1\% \\
    Q747074 & commune of Italy & 0\% & 1\% \\
    Q2074737 & municipality of Spain & 0\% & 1\% \\
    Q571 & book & 1\% & 1\% \\
    Q7889 & video game & 1\% & 1\% \\
    \bottomrule
  \end{tabular}
  \caption{Distribution of top 10 entity types over long-tail entities with degree between 11 and 20 compared to all entities.}
  \label{tab:entity_type_distribution}
\end{table*}





\begin{figure*}
  \centering
  \includegraphics[width=0.65\textwidth]{img/predictions_per_annotation}
\caption{
  Number of correct (rank=1) and incorrect predictions by KGT5+descriptions on annotated examples per annotation label.
}
\label{fig:prediction_per_annotation}
\end{figure*}


\begin{table*}
  \centering
  \begin{tabular}{lrrrrrr}
    \toprule
    & & \multicolumn{5}{c}{\textbf{Semi-inductive (num. shots)}}\\
    \cmidrule{3-7}
    \textbf{Model} & \textbf{Trans}. & \textbf{0} & \textbf{1} & \textbf{3} & \textbf{5} & \textbf{10} \\
    \midrule
    Complex + Bias + Fold in~\cite{jambor2021exploring} & 0.260 & 0.058 & 0.097 & 0.118 & 0.124 & 0.132 \\ DistMult + ERAvg~\cite{albooyeh2020out} & 0.237 & - & 0.115 & 0.151 & 0.185 & 0.209 \\ HittER~\cite{chen2021hitter} & 0.234 & 0.005 & 0.076 & 0.115 & 0.132 & 0.153 \\ \midrule
    DistMult + ERAvg + Mentions & 0.239 & - & 0.106 & 0.142 & 0.153 & 0.167 \\ SimKGC (mentions only) & 0.182 & 0.187 & - & - & - & -\\
    KGT5~\cite{saxena2022sequence} & 0.249 & 0.263 & - & - & - & -\\ KGT5-context~\cite{kochsiek2023friendly} & 0.347 & 0.184 & 0.177 & 0.195 & 0.218 & 0.263  \\ \midrule
    DistMult + ERAvg + Descriptions & 0.252 & - & 0.152 & 0.153 & 0.153 & 0.161 \\ SimKGC + Descriptions~\cite{wang2022simkgc} & 0.311 & 0.349 & - & - & - & -\\
    KGT5 + Descriptions & 0.332 & 0.430 & - & - & - & - \\ KGT5-context + Descriptions & 0.400 & 0.379 & 0.382 & 0.373 & 0.378 & 0.393 \\ \bottomrule
  \end{tabular}
  \caption{Transductive and semi-inductive link prediction results in terms of H@1 on the dataset Wikidata5M-SI.}
  \label{tab:si_results_h1}
\end{table*}

\begin{table*}
  \centering
  \begin{tabular}{lrrrrrr}
    \toprule
    & & \multicolumn{5}{c}{\textbf{Semi-inductive (num. shots)}}\\
    \cmidrule{3-7}
    \textbf{Model} & \textbf{Trans}. & \textbf{0} & \textbf{1} & \textbf{3} & \textbf{5} & \textbf{10} \\
    \midrule
    ComplEx + Bias + Fold in~\cite{jambor2021exploring} & 0.337 & 0.165 & 0.180 & 0.202 & 0.219 & 0.242 \\ DistMult + ERAvg~\cite{albooyeh2020out} & 0.328 & - & 0.190 & 0.292 & 0.352 & 0.401 \\ HittER~\cite{chen2021hitter} & 0.309 & 0.013 & 0.109 & 0.158 & 0.188 & 0.242 \\ \midrule
    DistMult + ERAvg + Mentions & 0.332 & - & 0.239 & 0.289 & 0.314 & 0.340 \\ SimKGC (mentions only) & 0.223 & 0.227 & - & - & - & -\\
    KGT5~\cite{saxena2022sequence} & 0.296 & 0.332 & - & - & - & -\\ KGT5-context~\cite{kochsiek2023friendly} & 0.390 & 0.236 & 0.234 & 0.257 & 0.278 & 0.335  \\ \midrule
    DistMult + ERAvg + Descriptions & 0.344 & - & 0.368 & 0.373 & 0.378 & 0.380 \\ SimKGC~\cite{wang2022simkgc} & 0.367 & 0.421 & - & - & - & -\\
    KGT5 + Descriptions & 0.385 & 0.490 & - & - & - & - \\ KGT5-context + Descriptions & 0.432 & 0.441 & 0.443 & 0.443 & 0.447 & 0.463 \\ \bottomrule
  \end{tabular}
  \caption{Transductive and semi-inductive link prediction results in terms of H@3 on the dataset Wikidata5M-SI.}
  \label{tab:si_results_h3}
\end{table*}



\begin{table*}
  \centering
  \begin{tabular}{lrrrrrr}
    \toprule
    & & \multicolumn{5}{c}{\textbf{Semi-inductive (num. shots)}}\\
    \cmidrule{3-7}
    \textbf{Model} & \textbf{Trans}. & \textbf{0} & \textbf{1} & \textbf{3} & \textbf{5} & \textbf{10} \\
    \midrule
    ComplEx + Bias + Fold in~\cite{jambor2021exploring} & 0.387 & 0.231 & 0.245 & 0.282 & 0.309 & 0.336 \\ DistMult + ERAvg~\cite{albooyeh2020out} & 0.389 & - & 0.270 & 0.409 & 0.493 & 0.564 \\ HittER~\cite{chen2021hitter} & 0.376 & 0.050 & 0.157 & 0.226 & 0.270 & 0.359 \\ \midrule
    DistMult + ERAvg + Mentions & 0.411 & - & 0.320 & 0.392 & 0.440 & 0.478 \\ SimKGC (mentions only) & 0.266 & 0.283 & - & - & - & -\\
    KGT5~\cite{saxena2022sequence} & 0.344 & 0.398 & - & - & - & -\\ KGT5-context~\cite{kochsiek2023friendly} & 0.423 & 0.293 & 0.295 & 0.310 & 0.336 & 0.400  \\ \midrule
    DistMult + ERAvg + Descriptions & 0.425 & - & 0.465 & 0.472 & 0.484 & 0.491 \\ SimKGC~\cite{wang2022simkgc} & 0.432 & 0.504 & - & - & - & -\\
    KGT5 + Descriptions & 0.416 & 0.544 & - & - & - & - \\ KGT5-context + Descriptions & 0.455 & 0.484 & 0.489 & 0.489 & 0.495 & 0.516 \\ \bottomrule
  \end{tabular}
  \caption{Transductive and semi-inductive link prediction results in terms of H@10 on the dataset Wikidata5M-SI.}
  \label{tab:si_results_h10}
\end{table*}


\begin{table*}
  \centering
  {
    \aboverulesep = 0.20ex
  \belowrulesep = 0.20ex
    \begin{tabular}{llrrr}
      \toprule
      \textbf{Model} & \textbf{Context selection} & \textbf{1} & \textbf{3} & \textbf{5} \\
      \midrule
      \multirow{3}{*}{ComplEx + fold-in} & Most common & 0.151 & 0.161 & 0.168 \\
      & Least common & \textbf{0.166} & 0.185 & 0.195 \\
      & Random & 0.164 & \textbf{0.187} & \textbf{0.196} \\
      \midrule
      \multirow{3}{*}{DistMult + ERAvg} & Most common & 0.171 & 0.246 & 0.295 \\
      & Least common & \textbf{0.217} & 0.299 & \textbf{0.323} \\
      & Random & 0.215 & \textbf{0.303} & 0.318 \\
      \midrule
      \multirow{3}{*}{oDistMult + ERAvg + Mentions} & Most common & 0.187 & 0.235 & 0.258 \\
      & Least common & \textbf{0.237} & \textbf{0.274} & \textbf{0.279} \\
      & Random & 0.232 & 0.265 & 0.272 \\
      \midrule
      \multirow{3}{*}{HittER} & Most common & 0.105 & 0.153 & 0.179 \\
      & Least common & \textbf{0.151} & \textbf{0.195} & \textbf{0.216} \\
      & Random & 0.136 & 0.190 & 0.206 \\
      \midrule
      \multirow{3}{*}{KGT5-context} & Most common & 0.217 & 0.236 & 0.259 \\
      & Least common & \textbf{0.253} & \textbf{0.273} & \textbf{0.290} \\
      & Random & 0.237 & 0.260 & 0.281 \\
      \midrule
      \multirow{3}{*}{KGT5-context + Desc.} & Most common & 0.420 & 0.416 & 0.420 \\
      & Least common & \textbf{0.423} & 0.424 & \textbf{0.430} \\
      & Random & 0.422 & \textbf{0.430} & \textbf{0.430} \\
      \bottomrule
    \end{tabular}
  }
  \caption{Influence of context selection. Semi-inductive test MRR. Best per model in bold.}
  \label{tab:context_selection_all}
\end{table*}



\end{document}
