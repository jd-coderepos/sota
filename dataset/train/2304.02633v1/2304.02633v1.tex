

\documentclass[10pt,twocolumn,letterpaper]{article}

\usepackage{cvpr}              

\usepackage{graphicx}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{booktabs}
\usepackage{multirow}
\usepackage{subcaption}
\usepackage[accsupp]{axessibility}  

\newcommand{\VS}{\textit{vs}.\xspace}

\usepackage[pagebackref,breaklinks,colorlinks]{hyperref}


\usepackage[capitalize]{cleveref}
\crefname{section}{Sec.}{Secs.}
\Crefname{section}{Section}{Sections}
\Crefname{table}{Table}{Tables}
\crefname{table}{Tab.}{Tabs.}


\def\confName{CVPR}
\def\confYear{2023}


\begin{document}

\title{HNeRV: A Hybrid Neural Representation for Videos}

\author{Hao Chen\quad Matthew Gwilliam \quad Ser-Nam Lim\quad Abhinav Shrivastava\
  \begin{aligned}
    \mu_i = \text{Round}\left(\frac{\mu_i - \mu_\text{min}}{\text{scale}}\right) &* \text{scale} + \mu_\text{min} , \text{where } \\
    \text{scale} = & \frac{\mu_\text{max} - \mu_\text{min}}{2^{b} - 1} ,
    \label{equa:quant}
  \end{aligned}

    L_\text{inpainting} = (1 - M) * \text{Loss}(x, p)
    \label{equa:inpaint-loss}

  \begin{aligned}
    \mu_i &= \text{Round}\left(\frac{\mu_i - \mu_\text{min}}{\text{scale}}\right) * \text{scale} + \mu_\text{min} ,
    \text{where } \\
    \text{scale} &= \frac{\mu_\text{max} - \mu_\text{min}}{2^\text{b} - 1}
    \label{equa:quant}
  \end{aligned}

 is one vector element, `Round' is a function that rounds to the closest integer, `b' is the bit length for quantization,  and  are the max and min value of vector , and `scale' is the scaling factor.
For scaling factor and zero points at this step, we can also try other methods instead of current min-max one, like choosing  evenly-distributed values to minimum the mean square error.

\textit{3) Entropy encoding.}
Finally, we use entropy encoding to further reduce the size.
Specifically, we leverage Huffman coding~\cite{huffman1952method} for quantized weights and get lossless compression.




\section{Weight Pruning for Model Compression.}
We appreciate this concern, which has been unresolved since the original NeRV paper.
By applying entropy encoding (assigning fewer bits for frequent symbols), we can store pruned weights with limited bits, since all pruned weights share a frequent symbol: .
We provide corrected model compression results in  \cref{tab:compression-entropy}, and will update the paper accordingly.
We use 2 baselines (models with no pruning) -- one where the model is only quantized, and another where we apply entropy encoding after quantization.
As we prune more parameters, entropy encoding enables us to use fewer bits to store the sparse model weights.

\begin{table}[h]
\centering
\vspace{-1em}
\caption{Compression results. 
``Size ratio'' compares to model with quant. only, and ``Sparsity'' indicates amount of weights pruned. }
\label{tab:compression-entropy}
\vspace{-0.8em}
\resizebox{.98\linewidth}{!}{
    \begin{tabular}{@{}l|c|ccccc@{}}
    \toprule
  Compression  & Quant & \multicolumn{5}{c}{Prune + Quant + Entropy coding} \\
  \hline
Sparsity          & 0\% & 0\%  & 10\%   & 15\%   & 20\%   & 25\%   \\

    \midrule
PSNR                 & 37.61 & 37.56  & 37.51  & 37.32  & 37.02  & 36.61  \\
Size (bits) & 11.54M & 10.94M  & 10.41M  & 10.09M  & 9.77M   & 9.36M     \\
Size ratio & 100\% & 94.8\% & 90.2\% & 87.4\% & 84.7\% & 81.1\% \\

    \bottomrule
    \end{tabular}
}
\end{table}




\section{HNeRV architecture details}
We also provide architecture details for HNeRV models in various tasks and datasets in 
Table~\ref{append-tab:archi-details}, with total size, strides list, encoder dimension , embedding dimension , channel width of decoder input , channel reduction , lowest channel width , min and max kernel size K, K
.
\begin{table}[h!]
\centering
\footnotesize
\caption{HNeRV architecture details }
\label{append-tab:archi-details}
\resizebox{.98\linewidth}{!}{
    \begin{tabular}{@{}l|cccccccc@{}}
    \toprule
Video size & size & strides & c1 & d & c2 & r & Ch & K, K \\
\midrule
6401280 & 0.35 & 5,4,4,2,2 & 64 & 16 & 32 & 1.2 & 12 & 1,5 \\
6401280 & 0.75 & 5,4,4,2,2 & 64 & 16 & 48 & 1.2 & 12 & 1,5 \\
6401280 & 1.5 & 5,4,4,2,2 & 64 & 16 & 68 & 1.2 & 12 & 1,5 \\
6401280 & 3 & 5,4,4,2,2 & 64 & 16 & 97 & 1.2 & 12 & 1,5 \\
480960 & 3 & 5,4,3,2,2 & 64 & 16 & 110 & 1.2 & 12 & 1,5 \\
9601920 & 3 & 5,4,4,3,2 & 64 & 16 & 92 & 1.2 & 12 & 1,5 \\
    \bottomrule
    \end{tabular}
}
\end{table}

\section{Per-video compression results}
We also show video compression results for \textbf{UVG} videos in Figure~\ref{append-fig:all-videos-compression}.
\begin{figure*}
    \centering
      \includegraphics[width=.8\textwidth]{figures/hnerv_all.pdf}
      \caption{\textbf{Compression} results averaged across all \textbf{UVG} videos, and for each specific videos.}  
    \label{append-fig:all-videos-compression}
\end{figure*}


\section{More visualizations}
We show more visualizations for video regression (Figure~\ref{append-fig:regression}), video interpolation (Figure~\ref{append-fig:interpolate}), and video inpainting (Figure~\ref{append-fig:inpaint}).

\begin{figure*}[h!]
    \centering    
    \includegraphics[width=.98\textwidth]{figures/gt_nerv_hnerv_bmx_nerv.pdf}
    \includegraphics[width=.98\textwidth]{figures/gt_nerv_hnerv_camel_nerv.pdf}
    \includegraphics[width=.98\textwidth]{figures/gt_nerv_hnerv_jockey_nerv-blur.pdf}
    \includegraphics[width=.98\textwidth]{figures/gt_nerv_hnerv_setgo_nerv.pdf}
    \caption{\textbf{Video regression} results. 
    \textbf{Left)} ground truth.
    \textbf{Middle)} NeRV output.
    \textbf{Right)} HNeRV output.}
    \label{append-fig:regression}
\end{figure*}


\begin{figure*}[h!]
    \centering
    \includegraphics[width=.98\textwidth]{figures/swan-interpolate.pdf}
    \caption{\textbf{Interpolation} results.}
    \label{append-fig:interpolate}
\end{figure*}

\begin{figure*}[h!]
    \centering    ----------
    \includegraphics[width=.98\textwidth]{figures/inpaint_dog_short.pdf}
    \includegraphics[width=.98\textwidth]{figures/inpaint_dog_rm_short.pdf}  
    \caption{\textbf{Inpainting} results.}
    \label{append-fig:inpaint}
\end{figure*}

\end{document}
