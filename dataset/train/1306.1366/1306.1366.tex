\documentclass[envcountsame,runningheads]{llncs}
\usepackage{pscproc2}
\usepackage{graphics}

\usepackage[boxruled,vlined]{algorithm2e}
\usepackage{arydshln}





\usepackage{slashbox}
\usepackage{tikz}
\usetikzlibrary{matrix}


\sloppy

\begin{document}
\title{Sorting suffixes of a text \\ via its Lyndon Factorization\thanks{Submitted to the Prague Stringology Conference 2013 (PSC 2013)}}

\author{Sabrina Mantaci, Antonio Restivo,\\
Giovanna Rosone and Marinella Sciortino}
\institute{
University of Palermo, Dipartimento di Matematica e Informatica, Italy\\
\email{\{sabrina,restivo,giovanna,mari\}@math.unipa.it}
}

\newcommand{\ppom} {\preceq_\omega}
\newcommand{\pplex}{\leq_{lex}}

\newcommand{\pom} {\prec_\omega}
\newcommand{\plex}{<_{lex}}



\def\lbwt(#1){{bwt}(#1)}
\def\lbwt{{bwt}}


\def\bigT{W}

\def\bwtS#1{\textsf{bwt}_{#1}(\mathcal{S})}
\def\lcpS#1{\textsf{lcp}_{#1}(\mathcal{S})} \def\bwtw#1{\textsf{bwt}_{#1}({w})}
\def\lcpw#1{\textsf{LCP}_{#1}({w})}
\def\rank{\textsf{rank}}
\def\bigS{\mathcal{S}}
\def\BCR{\texttt{BCR}}
\def\BWT{BWT} \def\LCP{LCP} \def\SA{SA} \def\GSA{GSA} \def\BCRLCP{\texttt{extLCP}}
\def\EMBWT{\texttt{BCRext} }
\def\EMBWTpp{\texttt{BCRext++} }
\def\BWTE{\texttt{bwte}}
\def\sort#1{\textrm{sort}(#1)}


\newcommand{\fbwt}{{\mathcal B}{\mathcal W}{\mathcal T}}


\maketitle

\begin{abstract}
The process of sorting the suffixes of a text plays a fundamental role in Text Algorithms. They are used for instance in the constructions of the Burrows-Wheeler transform and the suffix array, widely used in several fields of Computer Science. For this reason, several recent researches have been devoted to finding new strategies to obtain effective methods for such a sorting. In this paper we introduce a new methodology in which an important role is played by the Lyndon factorization, so that the local suffixes inside factors detected by this factorization keep their mutual order when extended to the suffixes of the whole word. This property suggests a versatile technique that easily can be adapted to different implementative scenarios.
\end{abstract}

\begin{keywords}
Sorting Suffixes, BWT, Suffix Array, Lyndon Words, Lyndon Factorization
\end{keywords}


\section{Introduction}


The sorting of the suffixes of a text plays a fundamental role in Text Algorithms with several applications in many areas of Computer Science and Bioinformatics.
For instance, it is a fundamental step, in implicit or explicit way, for the construction of the suffix array () and the Burrows-Wheeler Transform ().
The , introduced in 1990 (cf. \cite{Manber:1990}), is a sorted array of all suffixes of a string, where the suffixes are identify by using their positions in the string. Several strategies that privilege the efficiency of the running time or the low memory consumption have been widely investigated (cf. \cite{Puglisi:2007,GrossiSurvey2011}).
The , introduced in  (cf. \cite{bwt94}), permutes the letters of a text according to the sorting of its cyclic rotations, making the text more compressible (cf. \cite{bookBWTAdjeroh:2008}). A recent survey on the combinatorial properties that guarantee such a compressibility after the application of  can be found in \cite{RosoneSciortino_CiE2013} (cf. also \cite{RestivoRosoneTCS2011}).
Moreover, in the last years the  and the , besides being important tools in Data Compression, have found many applications well beyond its original purpose (cf. \cite{AbouelhodaKurtzOhlebusch2002,Ferragina:2000,FerraginaManzini2001,MantaciRRS08,Simpson2010,CoxJakobiRosoneST2012,bookBWTAdjeroh:2008}).

The goal of this paper is to introduce a new strategy for the sorting of the suffixes of a word that opens new scenarios of the computation of the  and the .

Our strategy uses a well known factorization of a word  called the \emph{Lyndon factorization} and is based on a combinatorial property proved in this paper, that allows to sort the suffixes of  (``global suffixes'') by using the sorting of the suffixes inside each block of the decomposition (``local suffixes'').


The Lyndon factorization is based on the fact that any word  can be written uniquely as , where
\begin{itemize}
  \item the sequence  is non-increasing with respect to lexicographic order;
  \item each  is strictly less than any of its proper cyclic shift (Lyndon words).
\end{itemize}

This factorization was introduced in \cite{ChenFoxLyndon1958} and a linear time algorithm is due to Duval \cite{Duval1983}.
The intuition that the knowledge of Lyndon factorization of a text can be used for the computation of the suffix array of the text itself has been introduced in \cite{BonomoMRRSDLT2013}. Conversely, a way to find the Lyndon factorization from the suffix array can be found in \cite{HohlwegReutenauer2003}.

If  is a factor of a word  we say that the sorting of the local suffixes of  is \emph{compatible} with the sorting of the global suffixes of  if the mutual order of two local suffixes in  is kept when they are extended as global suffixes. The main theorem in this paper states that if  is a concatenation of consecutive Lyndon factors, then the local suffixes in  are compatible with the global suffixes. This suggests some new algorithmic scenarios for the constructions of the  and the . In fact, by performing the Lyndon factorization of a word  by Duval's algorithm, one does not need to get to the end of the whole word in order to start the decomposition into Lyndon factors. Since our result allow to start the sorting of the local suffixes (compatible with the sorting of the global suffixes) as soon as the first Lyndon word is discovered, this may suggest an online algorithm, that do not require to read the entire word to start sorting. Moreover, the independence of the sorting of the local suffixes inside the different Lyndon factors of a text suggests also a possible parallel strategy to sort the global suffixes of the text itself.

In Section \ref{sec:prel} we give the fundamental notions and results concerning combinatorics on words, the Lyndon factorization, the Burrows-Wheeler transform and the suffix array. In Section \ref{sec:method} we first introduce the notion of global suffix on a text and local suffix inside a factor of the text. Then we prove the compatibility between the ordering of local suffixes and the ordering of global suffixes.
In Section \ref{sec:algo} we describe an algorithm that uses the above result to incrementally construct the  of a text. Such a method can be also used to explicitly construct the  of the text.
In Section \ref{sec:conclusion} we discuss about some possible improvements and developments of our method, including implementations in external memory or in place constructions. Finally, we compare our strategy for sorting suffixes with the method proposed in \cite{FerraginaGagieManzini2012} in which a lightweight computation of the  of a text is performed by partitioning it into factors having the same length.


\section{Preliminaries}\label{sec:prel}

Let  be a finite alphabet with .
Given a finite word ,  for ,
a \emph{factor} of  is written as . A factor  is called a \emph{prefix}, while a factor  is called a \emph{suffix}.
In this paper, we also denote by  as the suffix of  starting from position . We omit  when there is no danger of ambiguity.
We say that  are {\em conjugate} (or \emph{cyclic shift}) or \emph{ is a conjugate of } if  and  for some . Recall that conjugacy is an equivalent relation.

A {\em Lyndon} word is a primitive word which is also the minimum in its conjugacy class, with respect to the lexicographic order relation.
In \cite{Lothaire:2005,Duval1983}, one can find a linear algorithm that for any word  computes the Lyndon word of its conjugacy class.
We call it the Lyndon word of .
Lyndon words are involved in a nice and important factorization property of words.
\begin{theorem}\cite{ChenFoxLyndon1958}
Every word  has a unique factorization  such that  is a non-increasing sequence of Lyndon words.
\end{theorem}
We call this factorization the \emph{Lyndon factorization}  of a word and it can be computed in linear time (see for instance \cite{Duval1983,Lothaire:2005}).
Duval in \cite{Duval1983} presents two variants of an algorithm of factorization of a word into Lyndon words in time linear in the length of the word.
The first variant of the algorithm uses only three variables for a complete computation and it requires no more than  comparisons between two letters.
The second one is slightly faster in that sense that it requires no more than  comparisons but it uses an auxiliary storage of size .
The basis idea for both these variants is finding each factor of the decomposition of the word  from left to right by eventually reading a long enough prefix of the next Lyndon factor.

Lyndon factorization has been realized also in parallel (cf. \cite{ApostolicoCrochemore1995}) and in external memory (cf. \cite{RohCrochemoreIliopoulosPark:2008}).

One way to define the Burrows-Wheeler Transform () \cite{bwt94} of a string  of length  (although not the most efficient way to compute it) is to construct all  cyclic shifts of  and sort them lexicographically. The output of  consists of the pair (, ), where  is the sequence of the last character of each rotation in the sorted list and  is an integer denoting the position of the original word in the list.\\
Another more efficient way consists in the concatenating at the the input string  a symbol bwt\bigT\in \Sigma^*\lbwt(\bigT)\bigT\ is different, but, as consequence of the properties of Lyndon words, when the word  is the Lyndon word, then the two sorting coincide (cf. \cite[Lemma 12]{GRS2007}).
A study of the combinatorial aspects that connect these two sorting can be found in \cite{BonomoMRRSDLT2013}. In this study an important role is played by the notion of Lyndon word.

Given a text  of length , the suffix array  (SA) for  is an array of integers of range  to  specifying the lexicographic ordering of the suffixes of the string . It will be convenient to assume that \
\begin{array}{c|c|ccccccccccccc}
SA    & bwt   &       & \multicolumn{12}{c}{Suffixes}                                                            \\
\hline
12    & s     &       & \    &  \\
7     & m     &       & a     & t     & i     & c     & s     & \    &       &       &       &       &       &       &       &       &  \\
5     & h     &       & e     & m     & a     & t     & i     & c     & s     & \    &       &       &  \\
9     & t     &       & i     & c     & s     & \    &       & m     & a     & t     & h     & e     & m     & a     & t     & i     & c     & s     & \    &       &       &       &       &  \\
10    & c     &       & s     & \    &       &  \\
8     & a     &       & t     & i     & c     & s     & \mathematics\ is depicted in Figure \ref{fig:bwt}.




\section{Local and global suffixes of a text}\label{sec:method}

Let  and let  be its Lyndon Factorization.
For each factor , we denote by  and  the position of the first and the last character, respectively, of the factor  in . Let  be a factor of . We denote by  and we call it \emph{local suffix} at the position  with respect to . Note that  and we call it \emph{global suffix} of  at the position . We write  instead of  when there is no danger of ambiguity.

\begin{definition}
Let  be a word and let  be a factor of . We say that the sorting of suffixes of  is \emph{compatible} with the sorting of suffixes of  if for all  with ,

\end{definition}

Notice that in general taken an arbitrary factor of a word , the sorting of its suffixes is not compatible with the sorting of the suffixes of . Consider for instance the word  and its factor . Then  whereas .

\begin{theorem}\label{th:SufOrder}
Let  and let  be its Lyndon factorization.
Let .
Then the sorting of the suffixes of  is compatible with the sorting of the suffixes of .
\end{theorem}
\begin{proof}
Let  and  be two indexes with  both contained in . We just need to prove that .
Let  and .

Suppose that . Then  by the definition of lexicographic order. If  there is nothing to prove.
If , then  is prefix of , so by the definition of lexicographic order .


Suppose now that . This means that . If  there is nothing to prove. If , the index  is in some Lyndon factor  with , then . We denote  . Then  , since  (because  is a Lyndon word) and  (since the factorization is a sequence of non increasing factors). \qed
\end{proof}

The above theorem states, in other words, that mutual order of the suffixes of  starting in two positions  and  is the same as the mutual order of the ``local'' suffixes starting in  and  inside the block obtained as concatenation of the consecutive Lyndon factors including  and .



As particular case, the theorem is also true when the two suffixes start in the same Lyndon factor.

We recall that, if  and  denote two sorted lists of elements taken from any well ordered set, the operation  consists in obtaining the sorted list of elements in  and 

A consequence of previous theorem is stated in the following proposition.
\begin{proposition}
Let  and  denote the sorted lists of the suffixes of   and the suffixes , respectively. Then .
\end{proposition}

This proposition suggests a possible strategy for sorting the list of the suffixes of some word :
\begin{itemize}
\item find the Lyndon decomposition of , ;
\item find the sorted list of the suffixes of  and, separately, the sorted list of the suffixes of ;
\item merge the sorted lists in order to obtain the sorted lists of the suffixes of ;
\item find the sorted list of the suffixes of  and  merge it to the previous sorted list;
\item keep on this way until all the Lyndon factors are processed;
\end{itemize}

This kind of strategy could have several advantages: first of all, one can work online, i.e. one can start sorting suffixes as soon as the first Lyndon factor is individuated. This also allow to integrate the sorting process with the Duval's Algorithm for Lyndon decomposition that outputs Lyndon factors online as well.

The second advantage is that this kind of strategy allows parallelization, since every Lyndon factor can be processed separately for sorting its suffixes. These kind of application would require an efficient algorithm to perform the merging of two sorted lists.


A detailed algorithmic description of this method in order to obtain the  of a text is given in next section.





\section{An incremental algorithm to sort suffixes of a text}\label{sec:algo}

In this section we propose an algorithm that incrementally constructs the suffix array  and the Burrows-Wheeler transform  of the text  by using its Lyndon factorization. In particular, here we detail the construction of the  but an analogous reasoning can be done in order to obtain the suffix array.
We assume that  is the Lyndon factorization of the word .
So  .
Such an hypothesis, although strong, is not restrictive because one can obtain the Lyndon factorization of any word in linear time (cf. \cite{Duval1983,Lothaire:2005}).
As shown in previous section, the hypothesis that  is factorized in Lyndon words suggests to connect the problem to the sorting of the local suffixes of  to the lexicographic sorting of the global suffixes of .

Our algorithm, called {\sc Bwt\_Lynd}, considers the input text  as logically partitioned into  blocks, where each block corresponds to a Lyndon word, and computes incrementally the )k\bigTi\lbwt(L_1 \cdots L_{i}\ given )\lbwt(L_i\ and )SA(L_i\ range in . This means that we sum the amount  to the values of the usual suffix array of \lbwt(L_1 \cdots L_{i}\ from   )L_{i}\lbwt(L_1 \cdots L_{i-1}\ in the same mutual order as they appear in )\ which are lexicographically smaller than the -th suffix of \lbwt(L_1 \cdots L_{i-1}\ and )\lbwt(L_1 \cdots L_{i-1}L_{i}\.
\end{enumerate}


\begin{example}\label{ex:merge}
Let .
The Lyndon factorization of  is , where .
Figure \ref{fig:1} illustrates how Step \ref{it:merge} of the algorithm works.
Note that the positions of the suffixes in SA(L_2  are shifted of  positions.
Notice that in the algorithm {\sc Bwt\_Lynd} we do not actually compute the sorted list of suffixes, but we show it in Figure \ref{fig:1} to ease the comprehension of the algorithm. Moreover, the algorithm can be simply adapt to compute the suffix array of , so in Figure \ref{fig:1} the suffix arrays are also shown.

\begin{figure}[!htb]
{\scriptsize
  
}   \caption{
Iteration  of the computation of the  of the text  on the alphabet .
The two columns represent the s before and after the iteration.
Note that the first row (the underlined letter) in the table relative to L_2\.
Indeed, the suffix bL_1L_2\ which are lexicographically smaller than the suffix of jA[1]=0L_i[1,|L_i|]\ between the suffixes of L_{i-1}(|L_{i-1}|)L_1\cdots L_{i-1}L_i\ and the suffix L_1 \cdots L_{i-1}\ lexicographically smaller than . Let  be the first symbol of the suffix . Then, 
\end{proposition}
\begin{proof}

Since  is the first symbol of the suffix , then . All the suffixes of cL_i[j,|L_i|+1]C(\lbwt(L_1 \cdots L_{i-1}\. Let us count now the number of suffixes that starting with  and are smaller than . This is equivalent to counting how many 's occur in )[1,A[j+1]]rank(\lbwt(L_1 \cdots L_{i-1}\.\qed
\end{proof}

It is easy to verify that we can obtain the array  by using the array  and the suffix array )G[i] = A[SA(L_i\. Note that the array  contains the partial sums of the values of the  array used in \cite{CrauserF02,FerraginaGagieManzini2012}. However, we could directly compute the array  by using the notion of inverse suffix array \footnote{The inverse suffix array  of a word SAISA[SA[i]] = ii \in [1, |w|+1]ISA[j]jO(\sum_{j=1,\ldots,i}{|L_j|})O(1)\lbwt(L_1 \cdots L_{i-1}\. The same time complexity is obtained if the rank queries are executed over )G\lbwt(L_1 \cdots L_{i}\ by merging )\lbwt(L_1 \cdots L_{i-1}\ computed at the previous iteration. Such a step implicitly constructs the lexicographically sorted list of suffixes starting in  and extending up to end of  together with the suffixes of . In order to do this we keep the mutual order between the suffixes of L_i\ thanks to Theorem \ref{th:SufOrder}. From the definition of the array , it follows that the first two positions of the array )\lbwt(L_{i}\ and the first symbol of )j = 3, \ldots, |L_{i}|G[j]\lbwt(L_1 \cdots L_{i-1}\ followed by the value )[j]O(\sum_{j=1,\ldots,i}{|L_j|})k\lbwt(L_1 \cdots L_{k}\. Each iteration  runs in  time. The overall time complexity is , where .
\end{proposition}


\section{Discussions and conclusions}\label{sec:conclusion}

The goal of this paper is to propose a new strategy to compute the  and the  of a text by decomposing it into Lyndon factors and by using the compatibility relation between the sorting of its local and global suffixes. At the moment, the quadratic cost of the algorithm could make it impractical. However, from one hand, in order to improve our algorithm, efficient dynamic data structure for the rank operations and for the insertion operations could be used. Navarro and Nekrich's recent result \cite{NNsoda13} on optimal representations of dynamic sequences shows that one can insert symbols at arbitrary positions and compute the rank function in the optimal time  within essentially  bits of space, for a sequence  of length .
On the other hand, our technique, differently from other approaches in which partitions of the text are performed, is quite versatile so that it easily can be adapted to different implementative scenarios.

For instance, in \cite{FerraginaGagieManzini2012} the authors describe an algorithm, called {\sc bwte}, that logically partitions the input text  of length  into blocks of the same length , i.e.  and computes incrementally the  of  via  iterations, one per block of .
Text blocks are examined from right to left so that at iteration , they compute and store on disk  given . In this case the mutual order of the suffixes in each block depends on the order of the suffixes of the next block. Our algorithm {\sc Bwt\_Lynd} builds the  of a text or its  by scanning the text \emph{from left to right} and it could run online, i.e. while the Lyndon factorization is realized. One of the advantages is that adding new text to the end does not imply to compute again the mutual order of the suffixes of the text analyzed before, unless for the suffixes of the last Lyndon word that could change by adding characters on the right. Moreover, as described in the previous section, the text could be partitioned into several sequences of consecutive blocks of Lyndon words, and the algorithm can be applied \emph{in parallel} to each of those sequences. Furthermore, also the Lyndon factorization can be performed in parallel, as shown in \cite{ApostolicoCrochemore1995}. Alternatively, since we read each symbol only once, also an in-place computation could be suggested by the strategy proposed in \cite{CGKL_CPM2013}, in which the space occupied by text  is used to store the .

Finally, in the description of the algorithm we did not mention the used workspace. In fact, it could depend on the time-space trade-off that one should reach. For instance, the methodologies used in \cite{BauerCoxRosoneTCS2013,FerraginaGagieManzini2012} where disk data access are executed only via sequential scans could be adapted in order to obtain a lightweight version of the algorithm. An external memory algorithm for the Lyndon factorization can be found in \cite{RohCrochemoreIliopoulosPark:2008}.
We remark that that the method proposed in \cite{FerraginaGagieManzini2012} could be integrated into {\sc Bwt\_Lynd} in the sense that one can apply {\sc bwte} to compute at each iteration the  and the  of each block of the Lyndon partition.

In conclusion, our method seems lay out the path towards a new approach to the problem of sorting the suffixes of a text in which partitioning the text by using its combinatorial properties allows it to tackle the problem in local portions of the text in order to extend efficiently solutions to a global dimension.

\bibliographystyle{psc}          

\begin{thebibliography}{10}

\bibitem{AbouelhodaKurtzOhlebusch2002}
{\sc M.~Abouelhoda, S.~Kurtz, and E.~Ohlebusch}:
\newblock {\em The enhanced suffix array and its applications to genome
  analysis}, in Algorithms in Bioinformatics, vol.~2452 of LNCS, Springer
  Berlin Heidelberg, 2002, pp.~449--463.

\bibitem{bookBWTAdjeroh:2008}
{\sc D.~Adjeroh, T.~Bell, and A.~Mukherjee}:
\newblock {\em {The Burrows-Wheeler Transform: Data Compression, Suffix Arrays,
  and Pattern Matching}}, Springer Publishing Company, Incorporated, first~ed.,
  2008.

\bibitem{ApostolicoCrochemore1995}
{\sc A.~Apostolico and M.~Crochemore}:
\newblock {\em Fast parallel lyndon factorization with applications}.
\newblock Mathematical systems theory, 28(2) 1995, pp.~89--108.

\bibitem{BauerCoxRosoneTCS2013}
{\sc M.~J. Bauer, A.~J. Cox, and G.~Rosone}:
\newblock {\em Lightweight algorithms for constructing and inverting the {BWT}
  of string collections}.
\newblock Theoretical Computer Science, 483(0) 2013, pp.~134 -- 148.

\bibitem{BonomoMRRSDLT2013}
{\sc S.~Bonomo, S.~Mantaci, A.~Restivo, G.~Rosone, and M.~Sciortino}:
\newblock {\em {Suffixes, Conjugates and Lyndon words}}, in DLT, vol.~7907 of
  LNCS, Springer, 2013, pp.~131--142.

\bibitem{bwt94}
{\sc M.~Burrows and D.~J. Wheeler}:
\newblock {\em A block sorting data compression algorithm}, tech. rep., DIGITAL
  System Research Center, 1994.

\bibitem{ChenFoxLyndon1958}
{\sc K.~T. Chen, R.~H. Fox, and R.~C. Lyndon}:
\newblock {\em Free differential calculus. {IV}. {T}he quotient groups of the
  lower central series}.
\newblock Ann. of Math. (2), 68 1958, pp.~81--95.

\bibitem{CoxJakobiRosoneST2012}
{\sc A.~J. Cox, T.~Jakobi, G.~Rosone, and O.~B. Schulz-Trieglaff}:
\newblock {\em Comparing {DNA} sequence collections by direct comparison of
  compressed text indexes}, in WABI, vol.~7534 LNBI of LNCS, Springer, 2012,
  pp.~214--224.

\bibitem{CrauserF02}
{\sc A.~Crauser and P.~Ferragina}:
\newblock {\em A theoretical and experimental study on the construction of
  suffix arrays in external memory}.
\newblock Algorithmica, 32(1) 2002, pp.~1--35.

\bibitem{CGKL_CPM2013}
{\sc M.~Crochemore, R.~Grossi, J.~K\"{a}rkk\"{a}inen, and G.~Landau}:
\newblock {\em {Constant-Space Comparison-Based Algorithm for Computing the
  Burrows-Wheeler Transform}}, in CPM, LNCS, Springer, 2013, In press.

\bibitem{Duval1983}
{\sc J.-P. Duval}:
\newblock {\em Factorizing words over an ordered alphabet}.
\newblock Journal of Algorithms, 4(4) 1983, pp.~363 -- 381.

\bibitem{FerraginaGagieManzini2012}
{\sc P.~Ferragina, T.~Gagie, and G.~Manzini}:
\newblock {\em {Lightweight Data Indexing and Compression in External Memory}}.
\newblock Algorithmica, 63(3) 2012, pp.~707--730.

\bibitem{Ferragina:2000}
{\sc P.~Ferragina and G.~Manzini}:
\newblock {\em Opportunistic data structures with applications}, in FOCS 2000,
  IEEE Computer Society, 2000, pp.~390--398.

\bibitem{FerraginaManzini2001}
{\sc P.~Ferragina and G.~Manzini}:
\newblock {\em An experimental study of an opportunistic index}, in SODA 2001,
  SIAM, 2001, pp.~269--278.

\bibitem{GRS2007}
{\sc R.~Giancarlo, A.~Restivo, and M.~Sciortino}:
\newblock {\em From first principles to the {B}urrows and {W}heeler transform
  and beyond, via combinatorial optimization}.
\newblock Theoret. Comput. Sci., 387(3) 2007, pp.~236 -- 248.

\bibitem{GrossiSurvey2011}
{\sc R.~Grossi}:
\newblock {\em A quick tour on suffix arrays and compressed suffix arrays}.
\newblock Theoretical Computer Science, 412(27) 2011, pp.~2964 -- 2973.

\bibitem{HohlwegReutenauer2003}
{\sc C.~Hohlweg and C.~Reutenauer}:
\newblock {\em Lyndon words, permutations and trees}.
\newblock Theoretical Computer Science, 307(1) 2003, pp.~173 -- 178.

\bibitem{Lothaire:2005}
{\sc M.~Lothaire}:
\newblock {\em Applied Combinatorics on Words (Encyclopedia of Mathematics and
  its Applications)}, Cambridge University Press, New York, NY, USA, 2005.

\bibitem{Manber:1990}
{\sc U.~Manber and G.~Myers}:
\newblock {\em Suffix arrays: a new method for on-line string searches}, in
  Proceedings of the first annual ACM-SIAM symposium on Discrete algorithms,
  SODA '90, Philadelphia, PA, USA, 1990, SIAM, pp.~319--327.

\bibitem{MantaciRRS08}
{\sc S.~Mantaci, A.~Restivo, G.~Rosone, and M.~Sciortino}:
\newblock {\em A new combinatorial approach to sequence comparison}.
\newblock Theory Comput. Syst., 42(3) 2008, pp.~411--429.

\bibitem{NNsoda13}
{\sc G.~Navarro and Y.~Nekrich}:
\newblock {\em Optimal dynamic sequence representations}, in Proc. 24th Annual
  ACM-SIAM Symposium on Discrete Algorithms (SODA), 2013, pp.~865--876.

\bibitem{Puglisi:2007}
{\sc S.~J. Puglisi, W.~F. Smyth, and A.~H. Turpin}:
\newblock {\em A taxonomy of suffix array construction algorithms}.
\newblock ACM Comput. Surv., 39 2007.

\bibitem{RestivoRosoneTCS2011}
{\sc A.~Restivo and G.~Rosone}:
\newblock {\em Balancing and clustering of words in the {B}urrows-{W}heeler
  transform}.
\newblock Theoret. Comput. Sci., 412(27) 2011, pp.~3019 -- 3032.

\bibitem{RohCrochemoreIliopoulosPark:2008}
{\sc K.~Roh, M.~Crochemore, C.~S. Iliopoulos, and K.~Park}:
\newblock {\em External memory algorithms for string problems}.
\newblock Fundam. Inf., 84(1) 2008, pp.~17--32.

\bibitem{RosoneSciortino_CiE2013}
{\sc G.~Rosone and M.~Sciortino}:
\newblock {\em {The Burrows-Wheeler Transform between Data Compression and
  Combinatorics on Words}}, in CiE, vol.~7921 of LNCS, Springer, 2013,
  pp.~353--364.

\bibitem{Simpson2010}
{\sc J.~T. Simpson and R.~Durbin}:
\newblock {\em {Efficient construction of an assembly string graph using the
  FM-index}}.
\newblock Bioinformatics, 26(12) 2010, pp.~i367--i373.

\end{thebibliography}




\end{document}
