\documentclass[nocopyrightspace]{sigplanconf}
\usepackage[nocompress]{cite} \usepackage{amsmath,amssymb, latexsym}



\usepackage{graphicx}
\usepackage[usenames,dvipsnames]{color}
\usepackage{enumerate}
\usepackage{hyperref}
\def\url{}
\usepackage{xspace}
\usepackage{epsfig}
\usepackage{mathpartir}
\usepackage{booktabs}
\usepackage{extarrows}
\usepackage{pgf,tikz}
\usetikzlibrary{arrows,automata}

\usepackage{ifthen}

\newcommand{\isTechReport}{true} \newcommand{\includeProof}[1]{
  \ifthenelse{\equal{\isTechReport}{true}}{
    #1
  }{
  }
}





\def\qed{\hfill}

\def\@envspa{\hspace{0.3em}}
\def\@sa{\hspace{-0.2em}}
\def\@sb{\hspace{0.5em}}
\def\@sc{\hspace{-0.1em}}

\def\sk{\smallskip}		

\newtheorem{notation}{Notation}{\itshape}{}
\newtheorem{theoremstar}{Theorem}{\bfseries\upshape}{\itshape}
\newtheorem{@protheo}{Theorem}
\newenvironment{theorem}[1]{\begin{@protheo}{\rm \bf #1}\it}{\end{@protheo}}
\newtheorem{remark}{Remark}{\bfseries\upshape}{\rm}
\newtheorem{definition}{Definition}{\bfseries\upshape}{\itshape}
\newtheorem{proposition}{Proposition}{\bfseries\upshape}{\itshape}
\newtheorem{lemma}{Lemma}{\bfseries\upshape}{\itshape}
\newtheorem{corollary}{Corollary}{\bfseries\upshape}{\itshape}
\newtheorem{invariant}{Invariant}



\newcommand{\LLOC}{XXX}
\newcommand{\figbegin}{}
\newcommand{\figend}{}
\newcommand{\defeq}{\doteq\ }
\newcommand{\st}{\; | \;}
\newcommand{\fa}{\forall \,}
\newcommand{\ex}{\exists \ }

\newcommand{\bottom}{\perp}
\newcommand{\dbrkts}[1]{[\![#1]\!]}


\def\myexsh{\smallskip\noindent\textbf{\emph{Example.}\xspace}}
\def\myex#1{\smallskip\noindent\textbf{\emph{Example: {#1}.}}}
\def\mypara#1{\smallskip\noindent\textbf{#1}}

\def\mynote#1{{\sf  #1}}

\def\jhala#1{{\sf RJ: #1}}
\def\rupak#1{{\sf RM: #1}}
\def\andrey#1{{\sf AR: #1}}
\def\set#1{{\{ #1\}}}


\def\jtuple#1{{\mathtt{\langle}#1 \mathtt{\rangle}}}
\def\tuple#1{{\langle #1 \rangle}}
\def\explain#1{\text{\set{#1 \xspace}}}

\newcommand{\zp}{{0 (0\%)}}
\newcommand{\ie}{\textit{i.e.,}\xspace}
\newcommand{\eg}{\textit{e.g.,}\xspace}
\def\etc{{\it etc.}}

\def\T{{\mathcal{T}}} \def\G{{\mathcal{G}}} \newcommand{\translate}[1]{\dbrkts{#1}}
\newcommand{\Convert}{\alpha}
\newcommand{\Soln}{S}


\newcommand\Java{\textsc{Java}\xspace}
\newcommand\ML{\textsc{ML}\xspace}
\newcommand\HMC{\textsc{RTI}\xspace}
\newcommand\yices{\textsc{Yices}\xspace}
\newcommand\DML{\textsc{DML}\xspace}
\newcommand\lang{\mathsf{ML_\mu}\xspace}
\newcommand\ocaml{\textsc{Ocaml}\xspace}
\newcommand\bitv{\textsc{Bitv}\xspace}
\newcommand\BLAST{\textsc{Blast}\xspace}
\newcommand\dsolve{\textsc{Dsolve}\xspace}
\newcommand\SLAM{\textsc{Slam}\xspace}
\newcommand\ARMC{\textsc{ARMC}\xspace}
\newcommand\ASTREE{\textsc{Astree}\xspace}
\newcommand\SATURN{\textsc{Saturn}\xspace}

\def\pred{\varphi}
\def\true{{\it true}}
\def\false{{\it false}}

\newcommand{\ExpSet}{\mathsf{Exp}}
\newcommand{\PredSet}{\mathsf{Pred}}
\newcommand{\CMDS}{\mathit{Cmd}}
\newcommand{\TYPES}{\mathsf{Types}} 
\newcommand{\EXPRS}{\ExpSet} 
\newcommand{\BEXPRS}{\PredSet}


\newcommand{\ttneg}{\mathtt{neg}}
\newcommand{\ttzero}{\mathtt{0}}
\newcommand{\ttone}{\mathtt{1}}
\newcommand{\ttloop}{\mathtt{loop}}
\newcommand{\ttfun}{\mathtt{fun}}
\newcommand{\ttlength}{\mathtt{length}}
\newcommand{\ttf}{\mathtt{f}}
\newcommand{\ttg}{\mathtt{g}}
\newcommand{\tts}{\mathtt{s}}
\newcommand{\ttxs}{\mathtt{xs}}
\newcommand{\ttxsp}{\mathtt{xs'}}
\newcommand{\ttc}{\mathtt{c}}

\newcommand{\ttt}{\mathtt{t}}
\newcommand{\ttitr}{\mathtt{itr}}
\newcommand{\ttvs}{\mathtt{vs}}
\newcommand{\ttgetValidSamples}{\mathtt{getValidSamples}}
\newcommand{\ttsumValidSamples}{\mathtt{sumValidSamples}}

\newcommand{\ttw}{\mathtt{w}}
\newcommand{\ttx}{\mathtt{x}}
\newcommand{\tty}{\mathtt{y}}
\newcommand{\ttY}{\mathtt{Y}}
\newcommand{\ttn}{\mathtt{n}}
\newcommand{\ttm}{\mathtt{m}}
\newcommand{\ttb}{\mathtt{b}}
\newcommand{\tta}{\mathtt{a}}
\newcommand{\tti}{\mathtt{i}}
\newcommand{\ttj}{\mathtt{j}}
\newcommand{\ttk}{\mathtt{k}}
\newcommand{\ttv}{\mathtt{v}}
\newcommand{\ttmax}{\mathtt{max}}

\newcommand{\ttfoldn}{\mathtt{foldn}}
\newcommand{\ttArray}{\mathtt{Array}}
\newcommand{\ttList}{\mathtt{List}}
\newcommand{\ttget}{\mathtt{get}}
\newcommand{\ttset}{\mathtt{set}}

\newcommand{\ttamax}{\mathtt{arraymax}}
\newcommand{\ttam}{\mathtt{am}}
\newcommand{\ttsum}{\mathtt{sum}}
\newcommand{\ttassert}{\mathtt{assert}}
\newcommand{\ttharmonic}{\mathtt{harmonic}}
\newcommand{\ttsequence}{\mathtt{range}}
\newcommand{\ttoff}{\mathtt{off}}
\newcommand{\ttadder}{\mathtt{adder}}
\newcommand{\ttinsert}{\mathtt{insert}}
\newcommand{\ttinsertsort}{\mathtt{insertsort}}
\newcommand{\ttsortcheck}{\mathtt{sortcheck}}
\newcommand{\ttappend}{\mathtt{append}}

\newcommand{\ttjlist}{\mathtt{List}}
\newcommand{\ttjiter}{\mathtt{Iterator}}
\newcommand{\ttiteri}{\mathtt{iteri}}
\newcommand{\ttmask}{\mathtt{mask}}



\def\mname{\mathtt{m}}
\def\meas{M}
\def\mexp{\varepsilon}
\def\meastup{(\mname, \mybar{\tcons{i}{\mybar{x_i}} \mapsto \mexp_i},\rsum{x_i}{\typ_i})}

\def\tte{\mathtt{e}}
\def\ttp{\mathtt{p}}
\def\ttl{\mathtt{l}}

\def\ttr{\mathtt{ret}}
\def\ttis{\mathtt{is}}
\def\ttxs{\mathtt{xs}}
\def\ttys{\mathtt{ys}}
\def\ttarr{\mathtt{\rightarrow}}
\def\ttasg{\mathtt{:=}}

\newcommand{\ttfoldl}{\mathtt{List.fold\_left}}


\newcommand{\ttlenl}{{\ttlen}\xspace}
\newcommand{\ttlena}{{\ttlen}\xspace}



\newcommand{\transrel}{\hookrightarrow}
\def\trans{{\delta}}
\def\goesto#1{\smash{\stackrel{#1}{\transrel}}}
\def\labarrow#1{\smash{\xrightarrow{#1}}}
\def\zug#1{{\langle #1 \rangle}}

\makeatletter
\begingroup \catcode `|=0 \catcode `[= 1
\catcode`]=2 \catcode `\{=12 \catcode `\}=12
\catcode`\\=12 |gdef|@xcomment#1\end{comment}[|end[comment]]
|endgroup
\def\@comment{\let\do\@makeother \dospecials\catcode`\^^M=10\def\par{}}
\def\begincomment{\@comment\@xcomment}
\makeatother
\newenvironment{comment}{\begincomment}{}





\renewcommand{\implies}{\Rightarrow}
\def\pf{\mathtt{pf}}
\def\falsee{\mathtt{falsee}}
\def\andi{\mathtt{andi}}
\def\ande{\mathtt{ande}}
\def\alli{\mathtt{alli}}
\def\impdist{{\text{\tt imp-dist}}}
\def\ori{\mathtt{ori}}
\def\oril{\mathtt{oril}}
\def\orir{\mathtt{orir}}
\def\ore{\mathtt{ore}}
\def\impi{\mathtt{impi}}
\def\impe{\mathtt{impe}}


\newcommand{\tpar}{t}
\newcommand{\cpar}{c}
\newcommand{\leteq}[2]{\textbf{let }#1 = #2\textbf{ in}}
\newcommand{\While}[1]{\textbf{while }#1 \textbf{\ do}}
\newcommand{\IfP}{\textbf{if }}
\newcommand{\Then}{\textbf{then }}
\newcommand{\Else}{\textbf{else }}
\newcommand{\ttmatch}{\mathtt{match}}
\newcommand{\ttwith}{\mathtt{with}}
\newcommand{\match}[1]{\textbf{match}\ #1\ \textbf{with}}
\newcommand{\imposs}{\textbf{Failure}}
\newcommand{\when}{\textbf{ when }}
\newcommand{\AS}{\textbf{ as }}
\newcommand{\idx}[2]{{#1[#2]}}
\newcommand{\htab}{\hspace{0.4cm}}

\newcommand{\xdiff}[1]{#1_f}
\newcommand{\setv}[1]{\mathbb{#1}}
\newcommand{\incode}[1]{\verb|#1|}  

\setlength{\doublerulesep}{\arrayrulewidth}
\newcommand\TT{\rule{0pt}{2.6ex}}
\newcommand\BB{\rule[-1.2ex]{0pt}{0pt}}

\def\colon{\smash{\stackrel{\circ}{\circ}}}
\def\subt{<:}
\def\valu{\nu} 
\def\placev{\star}
\def\tvalu{v}

\newcommand{\qexp}[2]{[{#1}]{#2}}
\newcommand{\qtyp}[2]{\forall {#1}.{#2}}
\newcommand{\ftyp}[2]{{{#1}\!:\!{#2}}}
\newcommand{\SUBST}[3]{{#1}[{#3}/{#2}]}


\newcommand{\dom}[1]{{\mathsf{Dom}}(#1)}
\newcommand{\rng}[1]{{\mathsf{Rng}}(#1)}
\newcommand{\FV}[1]{{\mathsf{FreeVar}}(#1)}
\newcommand{\AV}[1]{{\mathsf{Var}(#1)}}
\newcommand{\KV}[1]{{\mathsf{LiquidVars}}(#1)}

\newcommand{\EXT}[2]{{#1;\!#2}}
\newcommand{\EXTT}[3]{\EXT{\EXT{#1}{#2}}{#3}}
\newcommand{\UPD}[3]{{#1}[{#2} \mapsto {#3}]}
\newcommand{\GUPD}[2]{\EXT{{#1}}{\langle{#2}\rangle}}
\newcommand{\SOLUPD}[3]{{\mathsf{SolUpd}}({#1},{#2},{#3})}
\newcommand{\ty}{\mathit{ty}}
\newcommand{\recty}{\mathit{rty}}

\newcommand{\typecast}[3]{\zug{{#1} \triangleright {#2}}\ {#3}}
\newcommand{\ASSERT}[2]{\{{#1}\}\ {#2}}
\newcommand{\ITE}[3]{{\ttif\ {#1 }\ \ttthen\  {#2}\ \ttelse\ {#3}}}

\newcommand{\ttval}{\mathtt{val}}
\newcommand{\ttif}{\mathtt{if}}
\newcommand{\ttthen}{\mathtt{then}}
\newcommand{\ttelse}{\mathtt{else}}
\newcommand{\ttoption}{\mathtt{option}}
\newcommand{\ttlet}{\mathtt{let}}
\newcommand{\ttletrec}{\mathtt{let\ rec}}
\newcommand{\ttin}{\mathtt{in}}
\newcommand{\LET}[3]{{\ttlet\ {#1}\ =\ {#2}\ \ttin\ {#3}}}
\newcommand{\LETREC}[3]{{\ttletrec\ {#1}\ =\ {#2}\ \ttin\ {#3}}}
\newcommand{\qualdec}[2]{\mathtt{qualifier}\ {#1}\ =\ {#2}}

\newcommand{\tttrue}{{\mathtt{true}}}
\newcommand{\ttfalse}{{\mathtt{false}}}
\newcommand{\ttnot}{{\mathtt{not}}}
\newcommand{\ttfix}{{\mathtt{fix}}}
\newcommand{\tterr}{{\mathtt{error}}}
\newcommand{\emb}[1]{\dbrkts{#1}}
\newcommand{\ttarray}{\xspace \mathtt{array}}
\newcommand{\ttfarray}{\xspace \mathtt{float[]}}
\newcommand{\ttlist}{\ \mathtt{list}}
\newcommand{\ttsome}[1]{{\mathtt{Some}\ {#1}}}
\newcommand{\ttnone}{{\mathtt{None}}}
\newcommand{\myfun}[3]{{\ftyp{#1}{#2} \rightarrow {#3}}}
\newcommand\UNFOLD[2]{\SUBST{#1}{t}{#2}}
\newcommand{\hastype}{::}
\newcommand{\tcons}[2]{\mathtt{C}_{#1}{#2}}

\newcommand{\falset}[1]{\overline{#1}}
\newcommand{\mybar}[1]{\zug{#1}}
\newcommand{\SEQ}[2]{(\EXT{#1}{#2})}
\newcommand{\ftypbar}[2]{\mybar{\ftyp{#1}{#2}}}
\newcommand{\mytup}[2]{\ftypbar{#1}{#2}}

\newcommand{\mysum}[2]{\Sigma_i \tcons{i}{\mytup{#1}{#2}}}
\newcommand{\mysumnot}[3]{\Sigma_{i \not = {#3}} \tcons{i}{\mytup{#1}{#2}}}
\newcommand{\rtype}[2]{\mu {#1}.{#2}}
\newcommand{\rsum}[2]{\rtype{\rvar}{\mysum{#1}{#2}}}
\newcommand{\mguard}[3]{\wedge_\mname \mname({#1}) = \mexp_{#2}(\mybar{#3})} 
\newcommand{\ttmid}{\mathtt{\mid}}
\newcommand{\MATCHWITH}[4]{\mathtt{match}\ {#2}\ \mathtt{with}\
\ttmid_{#1}\ \tcons{#1}{\mybar{{#3}_{#1}}} \mapsto  {#4}_{#1}}
\newcommand{\MATCHWITHEX}{\MATCHWITH{i}{e}{x}{e}}

\newcommand{\ctx}{\mathcal{C}}
\newcommand{\ttfold}{\mathtt{fold}}
\newcommand{\ttunfold}{\mathtt{unfold}}
\newcommand{\ufold}[1]{\ttunfold\ {#1}}
\newcommand{\fold}[1]{\ttfold\ {#1}}

\newcommand{\poten}[1]{\mathcal{P}({#1})}
\newcommand{\ERROR}{\mathit{Error}}
\newcommand{\impl}[4]{({#1}\wedge{#2}\wedge{#3}) \Rightarrow {#4}}
\newcommand{\sol}{\mathcal{S}}
\newcommand{\solstar}{\sol^{*}}

\newcommand{\atomt}{\beta}
\newcommand{\datat}{\delta}
\newcommand{\tvar}{\alpha}
\newcommand{\tvarb}{\beta}
\newcommand{\rvar}{t}

\newcommand{\kvar}{\kappa}
\newcommand{\tyB}{B}
\newcommand{\tyQ}{Q}
\newcommand{\tyE}{E}
\newcommand{\qs}{{qs}}
\newcommand{\quals}{\mathbb{Q}}
\newcommand{\qualstar}{\quals^\star}
\newcommand{\vars}{\mathbb{X}}
\newcommand{\consts}{\mathbb{C}}
\newcommand{\kvars}{\mathbb{K}}

\newcommand{\Fgamma}{\Gamma}
\newcommand{\tenv}{\Gamma}
\newcommand{\renv}{G}
\newcommand{\univ}[1]{\mathcal{U}({#1})}

\def\ttreal{\mathtt{real}}
\def\ttunint{\mathtt{ui}}
\def\ttint{\mathtt{int}}
\def\ttbool{\mathtt{bool}}

\newcommand{\tmeta}{\mathbb{T}}
\newcommand{\typ}{\tau}

\newcommand{\aliqs}{A}
\newcommand{\tliqs}{T}
\newcommand{\tliq}{\hat{\tliqs}}

\newcommand{\smeta}{\mathbb{S}}
\newcommand{\styp}{\sigma}
\newcommand{\stliqs}{S}
\newcommand{\stliq}{\hat{\stliqs}}


\newcommand{\tplt}{F}

\newcommand{\atom}{L}
\newcommand{\cons}{\mathsf{Cons}}

\newcommand{\shape}[1]{\mathsf{Shape}({#1})}
\newcommand{\embed}[1]{\mathsf{Emb}({#1})}
\newcommand{\VALID}[2]{{#1} \models {#2}}
\newcommand{\valid}[1]{\mathsf{Valid}({#1})}

\newcommand{\propn}[1]{{\sf{P}}\xspace}
\newcommand{\solve}{{\mathsf{Solve}}}

\newcommand{\mlinfer}{{\mathsf{HM}}}
\newcommand{\tinfer}{{\mathsf{Infer}}}
\newcommand{\refine}{\mathsf{Weaken}}
\newcommand{\sat}[2]{\mathsf{Sat}({#1},{#2})}

\newcommand{\qualinst}{\mathsf{Inst}}

\newcommand{\itpowtwo}{\mathit{pow2}}
\newcommand{\itloop}{\mathit{loop}}
\newcommand{\itfoldn}{\mathit{foldn}}
\newcommand{\itexone}{x_1}
\newcommand{\itextwo}{x_2}


\newcommand{\itxs}{\mathit{xs}}
\newcommand{\itprime}{\mathit{prime}}
\newcommand{\itabs}{\mathit{abs}}
\newcommand{\itmapfilter}{\mathit{mapfilter}}
\newcommand{\itpos}{\mathit{pos}}
\newcommand{\itneg}{\mathit{neg}}
\newcommand{\ittrunc}{\mathit{trunc}}
\newcommand{\itgenerate}{\mathit{generate}}
\newcommand{\itdouble}{\mathit{double}}
\newcommand{\itbsearch}{\mathit{bsearch}}
\newcommand{\itlook}{\mathit{look}}
\newcommand{\itmin}{\mathit{min}}
\newcommand{\itdot}{\mathit{dotprod}}
\newcommand{\itmult}{\mathit{loop}}
\newcommand{\itappend}{\mathit{append}}
\newcommand{\itfilter}{\mathit{filter}}

\newcommand{\itnull}{\mathit{nil}}
\newcommand{\itmag}{\mathit{magnitude}}
\newcommand{\itsum}{\mathit{sum}}
\newcommand{\ttunit}{\mathtt{unit}}
\newcommand{\ttinput}{\mathtt{input}}

\newcommand{\ttdatatype}{\mathtt{type}}


\newcommand{\myabs}[1]{\mid\! {#1} \! \mid}

\newcommand{\ssreftyp}[3]{\set{{#3}}}
\newcommand{\reftyp}[3]{\set{\ftyp{{#1}}{{#2}} \mid {#3}}}
\newcommand{\sreftyp}[1]{\set{{#1}}}
\newcommand{\deriv}{\vdash\ }
\newcommand{\derivl}{\vdash_{\quals}\ }
\newcommand{\sto}{\rho}
\newcommand{\toolname}{\textsc{Dsolve}\xspace}
\newcommand{\typesys}{{Recursive Refinements}\xspace}

\newenvironment{sitemize}{\begin{list}
   {}
   {\setlength{\topsep}{0pt}
    \setlength{\itemsep}{0pt}
    \setlength{\leftmargin}{15pt}
    }
    
  }
  {\end{list}}



\newcommand{\ttnil}{{\mathtt{Nil}}}
\newcommand{\ttcons}{{\mathtt{Cons}}}
\newcommand{\CONS}[2]{{\ttcons({#1},{#2})}}
\newcommand{\zugseq}[1]{\zug{{#1}}}
\newcommand{\rrlist}[1]{\zugseq{\EXT{\zugseq{}}{\zugseq{\EXT{#1}{\true}}}}}

\newcommand{\rela}{\bowtie}
\newcommand{\rrsort}[1]{\rrlist{{#1} \leq \valu}}
\newcommand{\rrsortbow}[1]{\rrlist{{#1} \rela \valu}}
\newcommand{\rrtop}{\rr_{\top}}


\newcommand{\rrbal}{\rr_{\mathsf{bal}}}
\newcommand{\rrcol}{\rr_{\mathsf{col}}}
\newcommand{\rrleq}{\rr_{\leq}} 
\newcommand{\rrbow}{\rr_{\rela}} 
\newcommand{\rrebow}[1]{\rrbow^{#1}} 
\newcommand{\rreleq}[1]{\rrleq^{#1}} 
\newcommand{\tliqsleq}{\tliqs_{\leq}} 
\newcommand{\polylist}{\qtyp{\tvar}{\mu t.\ttnil\ +\ \ttcons \zug{\ftyp{x_1}{\tvar},\ftyp{x_2}{t}}}}


\newcommand{\sITE}[3]{{#1} ? {#2} : {#3}} 

\newcommand{\ttP}{\mathtt{P}}
\newcommand{\ttPR}{\mathtt{PR}}
\newcommand{\ttPL}{\mathtt{PL}}
\newcommand{\ttemp}{\mathtt{E}}
\newcommand{\ttnode}{\mathtt{N}}
\newcommand{\ttR}{\mathtt{R}}
\newcommand{\ttB}{\mathtt{B}}
\newcommand{\ttblacks}{\mathtt{bht}}
\newcommand{\ttcolor}{\mathtt{col}}
\newcommand{\ttlen}{\mathtt{len}}
\newcommand{\ttht}{\mathtt{ht}}

\newcommand{\notred}{e_{\mathtt{EB}}}
\newcommand{\notpur}{e_{\mathtt{EBR}}}





\newcommand{\salist}{\tvar \ttlist}

\newcommand{\styplist}{\typ \ttlist}
\newcommand{\sintlist}{\ttint \ttlist}
\newcommand{\intlist}{\mu t.\ttnil\ +\ \ttcons \zug{\ftyp{x_1}{\ttint},\ftyp{x_2}{t}}}
\newcommand{\refintlist}[1]{\mu t. \ttnil\ +\ \ttcons \zug{\ftyp{x_1}{\reftyp{\valu}{\ttint}{{#1}}},\ftyp{x_2}{t}}}

\newcommand{\rreftyplist}[2]{\mu t. \ttnil\ +\ \ttcons \zug{\ftyp{x_1}{{#1}},\ftyp{x_2}{\rrapp{#2}{t}}}}
\newcommand{\rrefintlist}[1]{\rreftyplist{\ttint}{#1}}
\newcommand{\rrefalist}[1]{\rreftyplist{\tvar}{#1}}
\newcommand{\frameintlist}[3]{\rrapp{#1}{\mu t. \ttnil\ +\ \ttcons \zug{\ftyp{x_1}{\ttint},
             \ftyp{x_2}{\reftyp{\valu}{\rrapp{#2}{t}}{#3}}}}}








\def\NONDET{\mathtt{nondet}}
\newcommand{\ilang}{\textsc{Imp}\xspace}
\newcommand{\istate}{s}
\newcommand{\istates}{\Sigma}
\newcommand{\rstate}{\istate^{\sharp}}
\newcommand{\rstates}{\istates^{\sharp}}

\newcommand{\ASSIGN}[2]{{#1} \leftarrow {#2}}
\newcommand{\TASSIGN}[2]{{#1} \leftarrow {#2}}
\newcommand{\HAVOC}[1]{\ASSIGN{#1}{\NONDET()}}
\def\ASSUME{{{\mathtt{assume}}}}
\def\ASSERT{{{\mathtt{assert}}}}
\newcommand{\GET}[2]{\TASSIGN{#2}{#1}}
\newcommand{\SET}[2]{\TASSIGN{#1}{#2}}

\def\SKIP{{{\mathtt{skip}}}}
\def\LOOP{{{\mathtt{loop}}}}

\def\vals{V}
\def\val{v}

\def\CHOOSE{{[\!]}}
\def\instr{\mathtt{I}}
\def\prgm{\mathtt{P}}
\def\rkvar{{\kvar}}


\def\RELSEM{{Relational}\xspace}
\def\IMPSEM{{Imperative}\xspace}
\def\REFREL{relation\xspace}

\def\ERROR{{\mathcal{E}}}
\def\CHOICE{{\mathrm{[\!] }}}
\def\EXPAND{{\sf Expand}}
\def\CLONE{{\sf Clone}}
\def\rpost{\mathsf{Post}^{\sharp}}
\def\rreach{\mathsf{Reach}^{\sharp}}
\def\ipost{\mathsf{Post}}
\def\ireach{\mathsf{Reach}}



\sloppy

\begin{document}

\title{Refinement Type Inference via Abstract Interpretation}

\authorinfo{Ranjit Jhala}{UCSD}{jhala@cs.ucsd.edu}
\authorinfo{Rupak Majumdar}{UCLA}{rupak@cs.ucla.edu}
\authorinfo{Andrey Rybalchenko}{TUM}{rybal@in.tum.de}
\maketitle

\begin{abstract}
Refinement Types are a promising approach for checking behavioral
properties of programs written using advanced language features like
higher-order functions, parametric polymorphism and recursive datatypes.
The main limitation of refinement type systems to date is the  
requirement that the programmer provides the types of all functions, 
after which the type system can {\em check} the types and hence, verify the program.

In this paper, we show how to automatically {\em infer} refinement types, using
existing abstract interpretation tools for imperative programs. 
In particular, we demonstrate that the problem of refinement type 
inference can be reduced to that of computing invariants of simple, 
first-order imperative programs without recursive datatypes.
As a result, our reduction shows that any of the wide variety of 
abstract interpretation techniques developed for imperative programs, 
such as polyhedra, counterexample guided predicate abstraction 
and refinement, or Craig interpolation,
can be directly applied to verify behavioral properties of 
modern software in a fully automatic manner.
\end{abstract}


\section{Introduction}
\label{sec:intro}

Automatic verification of semantic properties of modern programming languages
is an important step toward reliable software systems.
For higher-order programming languages with inductive datatypes
or polymorphic instantiation, the main verification tool has been type systems,
which traditionally capture only coarse data-type properties (such as s are
only added to s),
and require the programmer to explicitly annotate program invariants if
more precise invariants about program computations are required. 

For example, \emph{refinement} type systems \cite{XiPfenning99} 
associate data types with refinement predicates that capture richer properties of
program computation.
Using refinement types, one can state, for instance, that a program variable  has the refinement type
``non-zero integer," or that the integer division function has the refinement type 
 
which states that the second argument must be non-zero.
Then if a program with refinement type type-checks, one can assert that there is no
division-by-zero error in the program.
The idea of refinement types to express precise program invariants is
well-known~\cite{XiPfenning99,Ou2004,ATS,Dunfield,Flanagan06,GordonRefinement09}.
However, in each of the above systems, the programmer must provide refinements for
each program type, and the type system {\em checks} the provided type refinements for
consistency.
We believe that this burden of annotations has limited the widespread adoption of refinement
type systems.

For {\em imperative} programming languages, algorithms based on abstract interpretation
can be used to {\em automatically infer} many program invariants 
\cite{SLAMPOPL02,HJMM04,CousotPLDI03}, thereby proving many semantic properties of practical interest.
However, these tools do not precisely model modern programming features such as closures
and higher-order functions or inductive datatypes, and so in practice, they
are too imprecise when applied to higher-order programs.

In this paper, we present an algorithm to {\em automatically} 
verify properties of higher-order programs through
refinement type inference (RTI) by
combining refinement type systems for higher-order programs
with invariant synthesis techniques for first-order programs.
Our main technical contribution is a translation 
from type constraints derived from a refinement type system for
higher-order programs to a first-order imperative program with assertions,
such that the assertions hold in the first-order program
iff there is a refinement type that makes the higher-order program
type-check.
Moreover, a suitable type refinement for the higher-order program
can be constructed from the invariants of the first-order program.
Thus, our algorithm replaces the manual annotation burden for refinement types with
automatically constructed program invariants on the translated program,
thus enabling fully automatic verification of programs written 
in modern languages.


\begin{figure}[t]
\vspace{1ex}
  \centering
\begin{minipage}[t]{.8\columnwidth}
\tikzset{
    state/.style={
           rectangle,
           rounded corners,
           draw=black, thick, 
           minimum height=2em,
           minimum width=10em,
           inner sep=2pt,
           text centered,
           },
}
\begin{tikzpicture}[->,>=stealth',shorten >=1pt,auto, node distance=1.2cm,
                    semithick]
  \tikzstyle{every state}=[draw=black]


  \node[draw=none] (ML) {
    \begin{minipage}[t]{.9\columnwidth}
      \centering
      OCaml Program\\ftyp{\ttx}{\reftyp{\valu}{\ttint}{\valu\geq 0}} \rightarrow \reftyp{\valu}{\ttint}{\valu = \ttx+1}
& \ftyp{\tta}{\alpha \ttarray} \rightarrow 
{\reftyp{\valu}{\ttint}{0 \leq \valu < \ttlena(\tta)}} \rightarrow 
\alpha\ , \\
& \ftyp{\tta}{\alpha \ttarray} \rightarrow
{\reftyp{\valu}{\ttint}{0 \leq \valu < \ttlena(\tta)}} \rightarrow
\alpha \rightarrow 
\ttunit\ ,

\begin{array}{rl}
\ttiteri \hastype & \ftyp{\tti}{\ttint} \rightarrow
	 	      \ftyp{\ttxs}{\reftyp{\valu}{\alpha\ \ttlist}{0 \leq \ttlenl(\valu)}} \rightarrow \\
         	    & (\ftyp{\ttj}{\sreftyp{\tti \leq \valu < \ttlenl(\ttxs)}} \rightarrow \alpha \rightarrow \ttunit) \rightarrow \ttunit\\
\ttg \hastype & \ftyp{\ttj}{\sreftyp{0 \leq \valu < \ttlena(\tta)}} \rightarrow \ttbool \rightarrow \ttunit\\
\end{array}

&\ftyp{\tti}{\ttint} 
 \rightarrow \ftyp{\ttxs}{\alpha\ \ttlist} 
 \rightarrow (\ftyp{\ttj}{\ttint} \rightarrow \alpha \rightarrow \ttunit) \rightarrow
 \ttunit \\
& \ftyp{\ttj}{\ttint} \rightarrow \ttbool \rightarrow \ttunit
\intertext{we would generate the respective templates}
& \ftyp{\tti}{\ttint} 
  \rightarrow \ftyp{\ttxs}{\sreftyp{0 \leq \ttlenl(\valu)}} 
  \rightarrow (\ftyp{\ttj}{\sreftyp{\kvar_1}} \rightarrow \alpha \rightarrow \ttunit) \rightarrow
  \ttunit \\
& \ftyp{\ttj}{\sreftyp{\kvar_2}} \rightarrow \ttbool \rightarrow \ttunit

\ftyp{\tti}{\ttint}; \ftyp{\ttxs}{\alpha\ \ttlist} \deriv & \reftyp{\valu}{\ttint}{\kvar_1} \label{eq:w1} \tag{w1} \\
\ftyp{\tta}{\ttbool\ \ttarray}; \ftyp{\ttxs}{\alpha\ \ttlist} \deriv & \reftyp{\valu}{\ttint}{\kvar_2} \label{eq:w2} \tag{w2} 

\renv \deriv & \tliqs_1 \subt \tliqs_2 \notag 
\intertext{where  is an \emph{environment} comprising a sequence of type bindings,
and  and  are refinement templates.
The constraint intuitively states that under the environment , the
type  must be a subtype of .
The subtyping constraints are generated syntactically from the code.
First consider the function .
The call to  generates}
\renv \deriv & \sreftyp{\valu = \tti} \subt \set{\kvar_1} \label{eq:c1} \tag{c1} 
\intertext{where the environment  comprises the bindings}
\renv \defeq & \ftyp{\tti}{\sreftyp{\true}};\ \ftyp{\ttxs}{\sreftyp{0 \leq \ttlenl(\valu)}}; \notag \\ 
& \ftyp{\ttx}{\sreftyp{\true}};\ \ftyp{\ttxsp}{\sreftyp{0 \leq \ttlenl(\valu) = \ttlenl(\ttxs) - 1}}
  \notag
\intertext{the constraint ensures that at the callsite, 
the type of the actual is a subtype of the formal.
The bindings in the environment
are simply the refinement templates for the variables in scope at the point
the value flow occurs. The type system yields the information 
that the length of  is one less than  as the former is the
tail of the latter \cite{XiPfenning99,LiquidPLDI09}.
Similarly, the recursive call to  generates}
\renv \deriv & \set{\ftyp{\ttj:\kvar_1} \rightarrow \alpha \rightarrow \ttunit} \subt \notag \\	
	     & \set{(\ftyp{\ttj}{\kvar_1} \rightarrow \alpha \rightarrow
	     \ttunit)[\tti+1/\tti][\ttxsp/\ttxs]}
\notag
\intertext{which states that type of the actual  is 
a subtype of the third formal parameter of 
after applying substitutions
 and 
that capture the passing in of the actuals 
 and  for the first two parameters respectively.
By pushing the substitutions inside and applying the standard rules for 
function subtyping, this constraint simplifies to}
\renv \deriv & \set{\SUBST{\SUBST{\kvar_1}{\tti+1}{\tti}}{\ttxsp}{\ttxs}} \subt
\set{\kvar_1} \label{eq:c2} \tag{c2}

\renv'; \ftyp{\ttj}{\set{\kvar_2}}; \ftyp{\tty}{\sreftyp{\true}} \deriv & \sreftyp{\valu = \ttj} \subt 
\sreftyp{0 \leq \valu < \ttlena(\tta)} \label{eq:c3} \tag{c3} 
\intertext{where  
has bindings for the other variables in scope. 
Finally, the flow due to the third parameter for the call to  yields}
\renv'; \ttlen(\tta) = \ttlenl(\ttxs) \deriv 
& \set{\ftyp{\ttj}{\kvar_2} \rightarrow \typ} \subt \notag \set{\SUBST{(\ftyp{\ttj}{\kvar_1} \rightarrow \typ)}{\tti}{0}} 
\intertext{where for brevity we write  for , and omit the trivial substitution  due to
the second parameter.
The last conjunct in the environment captures the guard
from the  under whose auspices the call occurs. 
By pushing the substitutions inside and 
applying standard function subtyping, the above reduces to}
\renv'; \ttlen(\tta) = \ttlenl(\ttxs) \deriv 
& \set{\SUBST{\kvar_1}{\tti}{0}} \subt \set{\kvar_2}
\label{eq:c4} \tag{c4} 

\set{t_0 \mid \exists (t_1,\ldots,t_n) \mbox{ s.t.\ }
  \begin{array}[t]{@{}l}
    (t_0, t_1,\ldots,t_n) \in R_p \mathrel{\wedge} \\
    \quad t_1 = \ttx_1 \wedge \ldots t_n = \ttx_n
  \end{array}
}
\set{t_0 \mid \exists t_1 \mbox{ s.t.\ } (t_0, t_1) \in R_{\leq} \wedge t_1 = \tti}\ ,
& \rkvar_1.1 \leq \rkvar_1.0 \wedge \rkvar_1.0 < \ttlen(\rkvar_1.2)  \\
& 0 \leq \kvar_2.0 < \ttlen (\rkvar_2.1)

\kvar_1 \defeq  \tti \leq \valu < \ttlen(\ttxs) \ \ \ 
\kvar_2 \defeq  0 \leq \valu < \ttlen (\tta)

\begin{array}{rl}
\LOOP\{ & \mathtt{{/*} c1 {*/}} \\
	& \HAVOC{\tti};\\
        & \HAVOC{\ttxs};\ \ASSUME(0 \leq \ttlen(\ttxs));\\
	& \HAVOC{\ttxsp};\ \ASSUME(0 \leq \ttlen(\ttxsp) = \ttlen(\ttxs)-1);\\
	& \HAVOC{\valu};\ \ASSUME(\valu = \tti);\\
	& \SET{\rkvar_1}{(\valu,\tti,\ttxs)}\4pt]
\CHOICE & \mathtt{{/*} c3 {*/}}\\
	& \HAVOC{\tta};\\
        & \HAVOC{\ttxs};\ \ASSUME(0 \leq \ttlen(\ttxs));\\
  	& \GET{\rkvar_2}{(t_0, t_1, t_2)};\\ 
  	& \ASSIGN{\ttj}{t_0};\\
	& \ASSERT(0 \leq j < \ttlen(\tta))\
\end{small}
\caption{Translated Program}
\label{ex-ml-imperative}
\end{figure}

\section{Constraints}\label{sec:constraints}

We start by formalizing constraints over types refined with predicates. 
To this end, we make precise the notions of 
refinement predicates (Section~\ref{sec:logic}),
refinement types 
(Section~\ref{sec:reftypes}),
constraints over refinement types 
and the notion of satisfaction 
(Section~\ref{sec:refconstr}).

A discussion of how such constraints can be generated in a syntax-guided
manner from program source
is outside the scope of this paper; we refer the reader to the large body
of prior research that addresses this 
issue~\cite{XiPfenning99,Knowles07,LiquidPLDI08,GordonRefinement09}.

\mypara{Notation.}
We use uppercase () to denote sets, lowercase  to denote
elements, and  for a sequence of elements in~. 

\subsection{Refinement Logic}
\label{sec:logic}

Figure~\ref{fig:logic} shows the syntax of refinement predicates. 
In our discussion, we restrict the predicate language to the typed quantifier-free
logic of linear integer arithmetic and uninterpreted functions.
However, it is straightforward to extend the logic to include 
other domains equipped with effective decision procedures 
and abstract interpreters.

\mypara{Types and Environments.}
Our logic is equipped with a fixed 
set of \emph{types} denoted , 
comprising the basic types
 for \emph{integer} values, 
 for \emph{boolean} values,
and , a family of \emph{uninterpreted types} that are used to
encode complex source language types such as products, sums, polymorphic 
type variables, recursive types \etc.
We assume there is a fixed set of uninterpreted functions.
Each uninterpreted function  has a fixed type 
.
An \emph{environment} is a sequence of variable-type bindings.

\mypara{Expressions and Predicates.}
In our logic, \emph{expressions}  comprise variables, linear arithmetic
(\ie addition and multiplication by constants), and applications of 
uninterpreted functions . 
Note that as is standard in semantic program analyses, complex
operations like division or non-linear multiplication be modelled using 
uninterpreted functions.
Finally, \emph{predicates} comprise atomic comparisons of expressions, or
boolean combinations of sub-predicates.
We write  (resp. ) as abbreviations for  (resp. ).

\mypara{Well-formedness.}
We say that a predicate  is \emph{well-formed} in an environment
 if every variable appearing in  is bound in  and
 is ``type correct'' in the environment .

\mypara{Validity.}
For each type , we write  to denote the set of
concrete values of~.
An \emph{interpretation}  is a map from 
variables  to concrete values, and 
functions  to maps from  to .
We say that  is \emph{valid} under  if 
for each , we have .
We say that a predicate  is \emph{valid} in an environment , 
if  evaluates to  for 
every  valid under . 

\subsection{Refinement Types}
\label{sec:reftypes}

Figure~\ref{fig:constraints} shows the syntax of refinement types and 
environments. 

\mypara{Refinements.}
A \emph{refinement}  is either a predicate  drawn from our logic,
or a \emph{refinement variable with pending substitutions}
. 
Intuitively, the former represent \emph{known} refinements (or invariants), 
while the latter represent the \emph{unknown} invariants that hold 
of different program values. 
The notion of pending substitutions~\cite{AbadiCardelliCurienLevy,Knowles07} offers a
flexible way of capturing the value flow that arises in the context of
function parameter passing (in the functional setting), or assignment 
(in the imperative setting), even when the underlying 
invariants are unknown.



\mypara{Refinement Types and Environments.}
A \emph{refinement type}  is a triple
consisting of a \emph{value variable}  denoting the value being
described by the refinement type, a type  describing the
underlying type of the value, and a refinement . 
A \emph{refinement environment}  is a sequence of refinement type
bindings.

The value variables are special variables distinct from the program
variables, and can occur inside the refinement predicates.
Thus, intuitively, the refinement type describes the set of
concrete values of the underlying type  which additionally 
satisfy the refinement predicate. For example, the refinement type:
	
describes the set of non-zero integers and,
	
describes the set of integers whose value equals 
the sum of the values of the (program) variables  and .

Note that path-sensitive branch information can be captured by adding 
suitable bindings to the refinement environment. 
For example, the fact that some expression is only evaluated under 
the if-condition that  can be captured in the
environment via a refinement type binding 
.

\subsection{Refinement Constraints and Solutions}
\label{sec:refconstr}

Figure~\ref{fig:constraints} shows the syntax of refinement constraints.
Our refinement type system has two kinds of constraints. 


\mypara{Subtyping Constraints} are of the form

Intuitively, a subtyping constraint states that when the program variables satisfy
the invariants described in , the set of values described by
the refinement  must be \emph{subsumed by} 
the set of values described by the refinement type .

\mypara{Well-formedness Constraints} are of the form 
. 
Intuitively, a well-formedness constraints states that the refinement 
must be a well-typed predicate in the environment  extended with the
binding  for the value variable.


\mypara{Embedding.}
To formalize the notions of constraint validity and satisfaction, we embed subtyping
constraints into our logic. We define the function  that maps
refinement types, environments and subtyping constraints to predicates in
our logic.

Similarly, we define the function  that maps refinement
types and environments to types and environments in our logic.




\mypara{Validity.}
A subtyping constraint  
that does not contain refinement variables
is \emph{valid} if the predicate 
 
is valid under environment .
A well-formedness constraint  
that does not contain refinement variables
is \emph{valid} if the predicate  is well-formed 
in the environment .

\mypara{Relational Interpretations.}
We assume, without loss of generality, that each refinement variable  
is associated with a unique well-formedness constraint
 
called the well-formedness constraint for .
In this case, we say  has \emph{arity} .
Furthermore, we assume that wherever a  of arity  appears in 
a subtyping constraint, it appears with a sequence of  pending
substitutions .
This assumption is without loss of generality, as we can enforce it
with trivial substitutions of the form .
A \emph{relational interpretation} for  of arity , is 
an -ary relation in .
A \emph{relational model} is a map from refinement variables 
 to relational interpretations.

\mypara{Constraint Satisfaction.}
A set of constraints  is \emph{satisfiable} if 
for all interpretations for uninterpreted functions ,
there exists a relational model  such that,
when each occurrence of a refinement type 
 in  
is substituted with 

every subtyping constraint after the substitution is valid. 
In this case, we say that  is a \emph{solution} for .


\begin{figure}[t]
\figbegin
4pt]

\tenv & ::= & 				& \textbf{Environments:} \\
  & \mid & \EXT{\ftyp{x}{\typ}}{\tenv}  & \mbox{binding} \\
  & \mid & \emptyset 			& \mbox{empty} \4pt]

p & ::=  &         			& \textbf{Predicates:} \\
  & \mid & e_1 \rela e_2  		& \mbox{comparison} \\
  & \mid & \neg p 			& \mbox{negation} \\
  & \mid & p_1 \wedge p_2		& \mbox{conjunction} \\
  & \mid & p_1 \Rightarrow p_2		& \mbox{implication} \4pt]
\tliqs & ::= &	\reftyp{\valu}{\typ}{r}	& \textbf{Refinement Types} \4pt]
c & ::= & \renv \deriv \tliqs_1 \subt \tliqs_2 	
					& \textbf{Subtype Constraints} \
\figend
\caption{\textbf{Predicates, Refinements and Constraints.}}
\label{fig:logic}
\label{fig:constraints}
\end{figure}





\section{Imperative Programs}\label{sec:imp}

\HMC translates the satisfiability problem for refinement type constraints
to the question of checking the safety of an imperative program in a simple
imperative language \ilang.
In this section, we formalize the syntax of \ilang programs 
and define the \RELSEM semantics 
and the \IMPSEM semantics. 




\subsection{Syntax}
\label{sec:impsyntax}

Figure~\ref{fig:impsyntax} shows the syntax of \ilang programs. 
An \emph{instruction} () is a sequence of assignments, assumptions 
and assertions. 
A \emph{program} () is an infinite loop over a block, whose body
is a non-deterministic choice between a finite number of instructions
.
Next, we describe the different kinds of instructions.
For ease of notation, we assume that there is only one base type ,
and let  denote the set of values of type .

\mypara{Variables.} \ilang programs have two kinds of variables. 
(1)~\emph{base} variables, denoted by 
, ,  and  (and subscripted versions thereof), 
which range over values of type .
(2)~\emph{\REFREL} variables, denoted by ,
each of which have a fixed arity  and range over tuples of values
or sets of -tuples of values depending on the semantics.

\mypara{Base Assignments.}
\ilang programs have two kinds of assignments to base variables. 
Either
(1)~an expression over base variables (cf. Figure~\ref{fig:logic}) 
is evaluated and assigned to the base variable, or,
(2)~an arbitrary value of the appropriate base type is assigned to the base
variable, \ie the variable is ``havoc-ed" with a non-deterministically
chosen value.


\mypara{Tuple Assignments.}
The operations \emph{get tuple} and \emph{set tuple} 
respectively read a tuple from and write a tuple to a \REFREL 
variable.

\mypara{Assumes and Asserts.}
\ilang programs have the standard assume and assert instructions using 
predicates over the base variables (cf. Figure~\ref{fig:logic}).
We write  as an abbreviation for .


\begin{figure}[t]
\begin{small}
\figbegin
4pt]
\prgm   & ::=  & \LOOP \{\instr_1 \CHOOSE \ldots \CHOOSE \instr_n \} & \mbox{Program}
\end{array}
\rpost(\hat{\rstates}, \instr) \defeq \bigcup \set{\rpost(\rstate, \instr)\mid \rstate \in \hat{\rstates}}
\begin{array}{ll}
\rreach(\prgm, 0)   & \defeq  \set{\rstate_0}\\
\rreach(\prgm, m+1) & \defeq  \bigcup \set{\rpost(\rreach(\prgm, m), \instr_j) \mid 1 \leq j \leq n}\\
\rreach(\prgm)      & \defeq  \bigcup \set{\rreach(\prgm, m) \mid 0 \leq m}
\end{array}
\begin{array}{ll}
\multicolumn{2}{l}{\textbf{Common Operations}}\\
\rpost(\ERROR, \instr) 	& \defeq  \set{\ERROR} \\ 
\rpost(\rstate,\instr_1;\instr_2) & \defeq  \rpost(\rpost(\rstate, \instr_1), \instr_2) \\ 
\rpost(\rstate,\ASSIGN{x}{e})  & \defeq  \set{\UPD{\rstate}{x}{\rstate(e)}} \\
\rpost(\rstate,\HAVOC{x}) 	& \defeq  \set{\UPD{\rstate}{x}{c} \mid c \in \vals}\\
\rpost(\rstate,\ASSUME(p)) 	& \defeq  \begin{cases} 
					    	\set{\rstate}   & \mbox{if }\rstate(p) = \true\\
                                       		\emptyset & \mbox{otherwise}
                          	   	  \end{cases}\\
\rpost(\rstate,\ASSERT(p)) 	& \defeq  \begin{cases} 
						\set{\rstate}   & \mbox{if } \rstate(p) = \true\\
                                        	\set{\ERROR} & \mbox{otherwise}
                          	   	  \end{cases}\0.2in]
\multicolumn{2}{l}{\textbf{Tuple Operations: \IMPSEM Semantics}}\\
\ipost(\istate,\GET{\rkvar}{(t_0,\ldots,t_n)})	
& \defeq \begin{cases}
	 \set{\UPD{\istate}{t_0}{v_0}\ldots\UPD{}{t_n}{v_n}} & \mbox{if } \istate(\rkvar) = (v_0,\ldots,v_n) \\
	 \emptyset & \mbox{if } \istate(\rkvar) = \bot \\
\end{cases} \\			
\ipost(\istate, \SET{\rkvar}{(x_0,\ldots,x_n)}) & \defeq \set{\UPD{\istate}{\rkvar}{(\istate(x_0),\ldots,\istate(x_n))}}
\end{array}
\begin{array}{ll}
\ireach(\prgm, 0)   & \defeq  \set{\istate_0}\\
\ireach(\prgm, m+1) & \defeq  \bigcup \set{\ipost(\ireach(\prgm, m), \instr_j) \mid 1 \leq j \leq n}\\
\ireach(\prgm)      & \defeq  \bigcup \set{\ireach(\prgm, m) \mid 0 \leq m}
\end{array}

\begin{array}{rll}
\multicolumn{3}{l}{\mbox{\textbf{Refinement Type Translation}}}  \4pt]

\translate{\reftyp{\valu}{\typ}{p}}_{set} 	
& \defeq & \ASSERT(p) \4pt]

\translate{\reftyp{\valu}{\typ}{\SUBST{\kvar}{x_1 \ldots x_n}{y_1 \ldots y_n}}}_{set} 
& \defeq & \SET{\rkvar}{(\valu,y_1,\ldots,y_n)} \4pt]
\translate{\EXT{\ftyp{x}{\tliqs}}{\renv}} 
& \defeq & \translate{\tau}_{get};\ \ASSIGN{x}{\valu};\ \translate{\renv} \8pt]


\multicolumn{3}{l}{\mbox{\textbf{Constraint Translation}}}  \8pt]

\multicolumn{3}{l}{\mbox{\textbf{Constraint Set Translation}}}  \
\figend
\caption{\textbf{Translating Constraints to \ilang Programs}}
\label{fig:translate}
\end{figure}

Figure~\ref{fig:translate} formalizes the translation 
from (a set of) refinement type constraints  to an \ilang program .
We use the WF constraints to translate each \REFREL 
variable  of arity  into a corresponding 
tuple variable  of arity .

The translation is syntax-driven.
We translate each subtyping constraint
 
into a straight-line block of instructions with three parts: 
a sequence of instructions that establishes 
the environment bindings
(),
a sequence of instructions that ``gets" the 
values corresponding to the LHS 
()
and a sequence of instructions that ``sets" the (LHS) values
into the appropriate RHS
().
The translation for a set of constraints is an infinite loop
that non-deterministically chooses among the blocks for each constraint.

Each environment binding gets translated as a ``get". 
Bindings with unknown refinements are translated into tuple-get operations,
followed by  statements that establish the equalities
corresponding to the pending substitutions.
Bindings with known refinements are translated into non-deterministic assignments
followed by a  that enforces that the refinement holds on the
non-deterministic value.

Each ``set" operation to an unknown refinement is translated into a
tuple-set instruction that writes the tuple corresponding to the pending
substitutions into the translated tuple variable.
Finally, each ``set" operation corresponding to a known refinement is
translated to an  instruction; intuitively, in such constraints 
the RHS defines an upper bound on the set of values populating the type, 
and the  serves to enforce the upper bound requirement in the
translated program.



The correctness of the procedure is stated by the following theorem.

\begin{theorem}{}\label{th:translate}
 is satisfiable iff  is \emph{\RELSEM-safe}.
\end{theorem}

The proof of this theorem follows from the properties of the 
following function  that maps a set 
of \RELSEM-states to constraint solutions:

The function  enjoys the following property, which can be
proven by induction on the construction of , that relates the
satisfying solutions of the constraints to the \RELSEM-reachable states 
of the translated program. 
Theorem~\ref{th:translate} follows from the following observations.
If  satisfies  then 
      
for all .
If  then
       satisfies .



\subsection{Read-Write-Once Programs}
\label{sec:rwo}

At this point, via Theorem~\ref{th:translate}, we have reduced 
checking satisfiability of type constraints to the problem of
verifying assertions of \ilang programs under the 
(non-standard) \RELSEM semantics.
Unfortunately, under these semantics, the program contains variables 
() which range over \emph{sets} of tuples. 
This makes it inconvenient to directly apply abstract-interpretation
based techniques for imperative programs which typically assume the
(standard) \IMPSEM semantics; each technique has to be painstakingly
adapted to the non-standard semantics.

We would be home and dry if we could prove the equivalence of the 
\RELSEM and \IMPSEM semantics; that is, if we could show that 
an \ilang program was \RELSEM-safe if and only if it was \IMPSEM safe.
Unfortunately, this is not true.

\myexsh 
Consider the \ilang program:

This program \emph{is not} \RELSEM-safe as the set-operation in the first
instruction populates  with the set of all integers,
and the get-operation in the second instruction can assign different values
to integer values to  and .
However the program \emph{is} \IMPSEM-safe as whenever the second
instruction executes,  will be undefined or contain 
some arbitrary integer that is assigned to both  and , 
which causes the assert to succeed.

This example pinpoints exactly why the two semantics differ. 
In the \RELSEM semantics, in any given loop iteration, 
different gets on the same  can return 
\emph{different} tuples, while in the \IMPSEM 
semantics the gets are correlated and return the same tuple.

\mypara{Read-Write-Once Programs.} 
An \ilang instruction is a \emph{read-write-once} instruction if
any \REFREL variable  is read from and written 
to at most once in the instruction. 
That is, read-write-once means at most one write and at most one read
(and not at most one read or write).
An \ilang program is a \emph{read-write-once} program if each instruction 
in its loop is a read-write-once instruction.
We can show that for Read-Write-Once \ilang programs 
the \RELSEM and \IMPSEM semantics are equivalent.

\begin{theorem}{}\label{th:rwo-equiv}
If  is a \emph{read-write-once}  program then   
 is \emph{\RELSEM-safe} iff  is \emph{\IMPSEM-safe}.
\end{theorem}

To prove this theorem, we formalize the connection between the
reachable states under the two different semantics, using the function
, which maps a \RELSEM-state to a set of \IMPSEM states:

Next, we can show that read-write-once instructions enjoy the following
property, by case splitting on the form of .

\begin{lemma}{\textbf{[Step]}}\label{lemma:step-lemma}
If  is a read-write-once instruction then
.
\end{lemma}



We use this property to show that the reachable states under the different
semantics are equivalent.

\begin{lemma}{}\label{lemma:expand}
If  
is a read-write-once program, then .
\end{lemma}
\includeProof{
\begin{proof}
To prove that , 
we show 

by straightforward induction on , noting that
, and 
 for
any \RELSEM-state , instruction , and any
program  (not necessarily read-write-once).

To show inclusion in the other direction, 
we prove
 
by induction on .
For the base case, 

by the definition of the initial states.
By induction, assume that 
 
Let . 
By Lemma~\ref{lemma:step-lemma}, either 
 is already in , 
in which case the inductive hypothesis applies and 
hence , or
 
for some . That is, there is a 
 such that 
.
From the induction hypothesis 
. 
As  is closed under , 
we conclude .
\end{proof}
}




\subsection{Cloning}
\label{sec:cloning}

At this point, we have shown that the \IMPSEM semantics of
read-write-once programs are equivalent to the \RELSEM semantics.
All that remains is to show that the translation procedure of
Figure~\ref{fig:translate} produces read-write-once programs.
Unfortunately, this is not true.

\myexsh
Consider the following constraints:

It is easy to check that on the above constraints, the translation
procedure yields the \ilang program from the previous example, which is not
read-write-once.

The reason the translated program is not a read-write-once program is that 
there can be constraints  
in which  occurs in multiple places within  and .

To solve this problem, we can simply \emph{clone} the  variables 
that occur multiple times inside a constraint, and use different clones 
at each occurrence!
We formalize this as a procedure  that maps a finite set of 
constraints to another finite set. The procedure works as follows. 
For each  that is read upto  times in some constraint, we 
make  clones, , and 
\begin{enumerate}
\item for the  occurence of  within any constraint, 
    we use the  clone  (instead of ), and,
\item for each constraint where  appears on the right hand side, 
    we make  clones of the constraints where in the  cloned constraint, 
    we use  (instead of ). 
\end{enumerate}
The first step ensures that each  is read-once in any constraint, and
the second step ensures that the clones correspond to exactly the same set of tuples 
as the original variable .
We can prove that  enjoys the following properties.

\begin{theorem}{}\label{th:clone}
Let  be a finite set of constraints.
\begin{enumerate}
\item  is a read-write-once program.
\item  is satisfiable iff  is satisfiable.
\end{enumerate}
\end{theorem}

It is easy to verify that  is a read-write-once
program. 
Furthermore, any satisfying solution for the original
constraints can be mapped directly to a solution for 
the cloned constraints. 
To go in the other direction, we must map a solution that satisfies the
cloned constraints to one that satisfies the original constraints.
This is trivial if the solution for the cloned constraints 
maps each clone  to the same set of tuples.
We show that if the cloned constraints have a satisfying solution,
they have a solution that satisfies the above property.
To this end, we prove the following lemma that states 
that for \emph{any} set of constraints, the satisfying 
solutions are closed under intersection.

\begin{lemma}{}\label{lemma:solnintersect}
If  and  are solutions that satisfy  
then 
satisfies .
\end{lemma}

Thus if  satisfies the cloned constraints
then by symmetry and Lemma~\ref{lemma:solnintersect} 
the solution that maps \emph{each} cloned variable 
to  also satisfies 
the cloned constraints, and hence, directly yields 
a solution to the original constraints.

Finally, as a corollary of 
Theorems~\ref{th:translate},\ref{th:rwo-equiv},\ref{th:clone} 
we get our main result that reduces the question 
of refinement type constraint satisfaction,
to that of safety verification.

\begin{theorem}{}\label{th:equiv}
 is satisfiable iff  is \IMPSEM-safe.
\end{theorem}

While we state Theorems \ref{th:translate} and \ref{th:clone} as
preserving satisfiability, the proof shows how the solutions can be
effectively mapped between  and  (or
. 
In particular, while the intersection of two non-trivial solutions can
be a trivial solution, it would be guaranteed that in that case, the
trivial solution satisfies~. 
Stated in terms of invariants, Lemma \ref{lemma:solnintersect} states
the observation that that there may be several non-comparable
inductive invariants to prove a safety property, but in that case, the
intersection of all the inductive invariants is also an inductive
invariant. 





\section{Experiments}\label{sec:experiments}


\newcommand{\invpage}[1]{
  \begin{minipage}[h]{.35\linewidth}
    \jot]
      \end{array}
    
      \begin{array}{c@{\;\defeq\;}l}
        #1\
  \end{minipage}
}

\newcommand{\mathpage}[1]{
  \begin{minipage}[h]{.3\linewidth}
    \jot]
    \jot] 
      0\leq \rkvar_6.0 \wedge \rkvar_g.0 < \mathtt{len}(\rkvar_g.1)
    }
    & 
    \typepage{
      \rkvar_4 & 0 \leq v, \rkvar_5 \defeq 0 \leq v,\\jot]
      0 \leq \rkvar_2.0 \wedge \rkvar_2.0 < \mathtt{len}(\rkvar_2.3)
    }
    & 
    \typepage{
      \rkvar_1 & v < i+\mathtt{len(xs)} \wedge i \leq v, \\jot]
      0 \leq \rkvar_3.0 \wedge \rkvar_3.0 < \mathtt{len}(\rkvar_3.3) \mathrel{\wedge} \\jot]
      \rkvar_3 & 0 \leq v \wedge v < \mathtt{len(a)}, \\jot] 
      0\leq \rkvar_6.0 \wedge \rkvar_g.0 < \mathtt{len}(\rkvar_g.1)
    }
    & 
    \typepage{
      \rkvar_4 & 0 \leq v, \rkvar_5 \defeq 0 \leq v,\\jot]
      0 \leq \rkvar_2.0 \wedge \rkvar_2.0 < \mathtt{len}(\rkvar_2.3)
    }
    & 
    \typepage{
      \rkvar_1 & v < i+\mathtt{len(xs)} \wedge i \leq v, \\jot]
      0 \leq \rkvar_3.0 \wedge \rkvar_3.0 < \mathtt{len}(\rkvar_3.3) \mathrel{\wedge} \\jot]
      \rkvar_3 & 0 \leq v \wedge v < \mathtt{len(a)}, \
\begin{array}{lrcl}
\mbox{(c0)} & \ftyp{\ttb}{\ttfarray} & \deriv & \sreftyp{\valu=0} \subt \kvar_6\\
\mbox{(c1)} & \ftyp{\ttb}{\ttfarray},\ftyp{\tti}{\kvar_6}, 
	      \ftyp{\ttl}{\ttList{\tuple{\kvar_2}}}, \tti < \ttlena(\ttb) & \deriv &
             \sreftyp{\valu=\tti} \subt \sreftyp{0 \leq \valu < \ttlena(\ttb)}\\
\mbox{(c2)} & \ftyp{\ttb}{\ttfarray}, \ftyp{\tti}{\kvar_6},\ftyp{\ttl}{\ttList\tuple{\kvar_2}},
              \tti < \ttlena(\ttb) & \deriv & \sreftyp{\valu=\tti} \subt \kvar_2\\
\mbox{(c3)} & \ftyp{\ttb}{\ttfarray}, \ftyp{\tti}{\kvar_6},
              \ftyp{\ttl}{\ttList\tuple{\kvar_2}},
              \tti < \ttlena(\ttb) & \deriv  & \sreftyp{\valu=\tti+1} \subt \kvar_6\\
\mbox{(c4)} &  \ftyp{\ttb}{\ttfarray}, \ftyp{\tti}{\kvar_6} & \deriv & 
		\ttList\tuple{\kvar_2} \subt \ttList\tuple{\kvar_1}\\
\mbox{(c5)} & \ftyp{\tta}{\ttfarray} & \deriv & 
		\ttList\tuple{\SUBST{\kvar_1}{\ttb}{\tta}} \subt \ttList\tuple{\kvar_3}\\
\mbox{(c6)} & \ftyp{\tta}{\ttfarray}, \ftyp{\ttvs}{\ttList\tuple{\kvar_3}} & \deriv & 
		\ttjiter\tuple{\kvar_3} \subt \ttjiter\tuple{\kvar_4}\\
\mbox{(c7)} &  	\ftyp{\tta}{\ttfarray}, 
		\ftyp{\ttvs}{\ttList\tuple{\kvar_3}},   
		\ftyp{\ttitr}{\ttjiter\tuple{\kvar_4}} & \deriv & \kvar_4 \subt \kvar_5\\
\mbox{(c8)} &   \ftyp{\tta}{\ttfarray}, 
		\ftyp{\ttvs}{\ttList\tuple{\kvar_3}},   
		\ftyp{\ttitr}{\ttjiter\tuple{\kvar_4}},
		\ftyp{\ttj}{\kvar_5} & \deriv & 
                \set{\valu=\ttj} \subt \set{0 \leq \valu < \ttlena(\tta)}
\end{array}
\begin{array}{l} 
\ttList\tuple{\kvar_1}\ \ttgetValidSamples(\ttfarray\ \ttb);\\
\ttList\tuple{\kvar_2}\ \ttl;\\
\sreftyp{\kvar_6}\ \tti;\\
\ttList\tuple{\kvar_3}\ \ttvs;\\
\ttjiter\tuple{\kvar_4}\ \ttitr;\\
\sreftyp{\kvar_5}\ \ttj;\\
\end{array}
\begin{array}{cl}
	\mbox{(w1)}  & \ftyp{\ttb}{\ttfarray} \deriv \ttList\tuple{\kvar_1}\\
	\mbox{(w2)}  & \ftyp{\ttb}{\ttfarray} \deriv \kvar_6\\
	\mbox{(w3)}  & \ftyp{\ttb}{\ttfarray}, \ftyp{\tti}{\ttint} \deriv \ttList\tuple{\kvar_2} \\
\\
	\mbox{(w4)}  & \ftyp{\tta}{\ttfarray} \deriv \kvar_3\\
	\mbox{(w5)}  & \ftyp{\tta}{\ttfarray}, \ftyp{\ttvs}{\ttList\tuple{\ttint}} \deriv \kvar_4\\
	\mbox{(w6)}  & \ftyp{\tta}{\ttfarray},
	\ftyp{\ttvs}{\ttList\tuple{\ttint}},\ftyp{\ttitr}{\ttjiter\tuple{\ttint}} \deriv \kvar_5\\
\end{array}

\begin{array}{cl}
	\mbox{(c0)} & b:\ttfarray \deriv \set{\valu=0} \subt \kvar_6\\
	\mbox{(c1)} & b:\ttfarray, i:\kvar_6, l:List\tuple{int}, i < L(b) \deriv \\
                    & \htab \set{\valu=i} \subt \set{0 \leq \valu < L(b)}\\
	\mbox{(c2)} & b:\ttfarray, i:\kvar_6, l:List\tuple{int}, i < L(b) \deriv \set{\valu=i} \subt \kvar_2\\
	\mbox{(c3)} & b:\ttfarray, i:\kvar_6, l:List\tuple{int}, i < L(b) \deriv \set{\valu=i+1} \subt \kvar_6\\
	\mbox{(c5)} &   a:\ttfarray \deriv \kvar_2[a/b] \subt \kvar_3\\
	\mbox{(c8)} &    a:\ttfarray, vs:List\tuple{int}, itr:Iterator\tuple{int}, j:\kvar_3 \deriv \\
                    & \htab \set{\valu=j} \subt \set{0 \leq \valu < L(a)}
\end{array}

\begin{array}{ll}
\LOOP \{ \\
// c0\\
& b := \NONDET; \ASSUME(L(b)\geq 0);\\
& \valu := 0;\\
& \kvar_6 := \SET(\valu, b);\\
\CHOICE // c1 \\
& b := \NONDET; \ASSUME(L(b)\geq 0);\\
& t[\valu, b] := \GET(\kvar_6);\\
& i := t.\valu;\\
& l := \NONDET; \ASSUME(L(l) \geq 0);\\
& \ASSUME(i < L(b));\\ 
& \valu := i;\\
& \ASSERT(0 \leq \valu < L(b));\\
\CHOICE // c2 \\
& b := \NONDET; \ASSUME(L(b)\geq 0);\\
& t[\valu, b] := \GET(\kvar_6);\\
& i := t.\valu; \\
& l := \NONDET; \ASSUME(L(l)\geq 0);\\
& \ASSUME(i < L(b));\\
& \valu := i ;\\
& \kvar_2 := \SET(\valu, b, i);\\
\CHOICE // c3 \\
& b := \NONDET; \ASSUME(L(b)\geq 0);\\
& t := \GET(\kvar_6);\\
& i := t.\valu;\\
& l := \NONDET; \ASSUME(L(l)\geq 0);\\
& \ASSUME(i < L(b));\\
& \valu := i + 1;\\
& \kvar_6 := \SET(\valu, b, i);\\
\CHOICE // c5'\\
& a := \NONDET; \ASSUME(L(a)\geq 0);\\
& t[\valu,b,i] := \GET(\kvar_2);\\
& \ASSUME(t.b = a);\\
& \kvar_3 := \SET(t.\valu, a);\\
\CHOICE // c8 \\
& a := \NONDET; \ASSUME(L(a)\geq 0);\\
& vs := \NONDET; \ASSUME(L(vs)\geq 0);\\
& itr := \NONDET;\\
& t[\valu,a] := \GET(\kvar_3);\\
& j := t.\valu;\\
& \valu := j;\\
& \ASSERT(0\leq \valu < L(a));\\
\}
\end{array}

(\ttx: \reftyp{\valu}{\ttbool}{\kappa_1}\rightarrow \set{\kappa_2}) \rightarrow \set{\kappa_3} \rightarrow \set{\kappa_4}\rightarrow \ttunit

\begin{array}{cl}
\bigwedge & \begin{array}{l}
            (\ttx: \ttbool \rightarrow \set{\valu = \ttx})\rightarrow \set{\lnot \valu}\rightarrow \set{\lnot\valu}\rightarrow \ttunit\\
            (\ttx: \ttbool \rightarrow \set{\valu = \lnot\ttx})\rightarrow \set{\lnot \valu}\rightarrow \set{\valu}\rightarrow \ttunit
            \end{array}
\end{array}

It is important to note that Theorems~\ref{th:translate} and~\ref{th:rwo-equiv} 
hold for \emph{any} set of constraints.
Thus, one way to get completeness in the finite state case 
is to generate refinement templates using intersection types, 
perform the translation to \ilang programs, 
and then using a complete invariant generation 
technique for finite state systems.
The key observation (made in \cite{KobayashiPOPL09}) 
that ensures a finite number of constraints, is 
that there is at most a finite number of ``contexts'' in the finte state case,
and hence a finite number of terms in the intersection types.
The bad news is that the bound on the number of contexts is 
, where  is the highest order of any 
function in the program,  is the maximum arity of any function in the program,
and  is a stack of  exponentials, defined by 
, and .

Fully context-sensitive constraints are used in \cite{KobayashiPOPL09}
to show completeness in the finite case, at the price of
 in {\em every case}, not just the worst case.
In our exposition and our implementation, we have traded 
off precision for scalability: while we lose precision 
by generating context-insensitive constraints, we avoid 
the  blow-up that comes with full context sensitivity.
However, it has been shown through practical benchmarks that since the types themselves capture
relations between the inputs and outputs, the context-insensitive
constraint generation suffices to prove a variety of complex programs safe
\cite{LiquidPLDI08, LiquidPLDI09, GordonRefinement09}.

When considering completeness properties in special cases, we point
out completeness wrt.~the discovery of refinement predicates in
octagons/difference bounds abstract domains~\cite{MineOctagon06} and
template-based invariant generation for linear
arithmetic~\cite{ColonCAV03} and extensions with uninterpreted
function symbols~\cite{BeyerVMCAI07}, which carries over from
respective verification approaches. 



\subsection{Related Work}

\mypara{Higher-Order Programs.}
Kobayashi \cite{KobayashiPOPL09,KobayashiLICS09} gives an algorithm
for model checking arbitrary -calculus properties of finite-data
programs with higher order functions by a reduction to model checking
for higher-order recursion schemes (HORS)~\cite{Ong}.
For safety verification, \HMC shows a promising alternative.

First, the reduction to HORS critically depends on a finite-state abstraction of the data.
In contrast, our reduction defers the data abstraction to the abstract interpreter working
on the imperative program, thus enabling the direct application of abstract interpreters working
over infinite domains. 
Since abstract interpreters over infinite abstract domains are strictly 
more powerful than (infinite families of) finite ones \cite{CousotCousot92comparison}, 
our approach can be strictly more powerful for infinite-state programs.


Second, in the translation of an abstracted program to a HORS,
this algorithm eliminates Boolean variables by enumerating 
all possible assignments to them, giving an exponential
blow-up from the program to the HORS. 
In contrast, our technique preserves the Boolean state \emph{symbolically}, 
enabling the use of efficient symbolic algorithms for verification.
For example, for the simple example:
\begin{verbatim}
let f b1 ... bn x = 
  if (b1 || ... || bn) then lock x;
  if (b1 || ... || bn) then unlock x 
in let f (*) ... (*) (newlock ()) 
\end{verbatim}
where we wish to prove that lock and unlock alternate. 
Kobayashi's translation \cite{KobayashiPOPL09} gives an {\em exponential} sized HORS,
with a version of  for each assignment to \verb+b1,...,bn+.
In contrast, our reduction preserves the source-level expressions and is linear, 
and amenable to symbolic verification techniques (e.g., BDDs).
Previous experience with software model checking \cite{SLAMPOPL02,HJMM04,fsoft06} 
shows that the number of reachable states is often drastically 
smaller than  where  is the number of Booleans.  
Thus, the pre-processing step that enumerates Booleans 
may not lead to a scalable implementation.

Might \cite{Might07} describes {\em logic-flow analysis}, a general safety verification 
algorithm for higher-order languages, which is the product 
of a -CFA like call-strings analysis and a form of SMT-based
predicate abstraction (together with widening).
In contrast, our work shows how higher-order
languages can be analyzed directly via 
abstract analyses designed for first-order imperative languages.

Inference of refinement types using conterexample-guided techniques
was recentrly identified as a promising
direction~\cite{UnnoPPDP09,TerauchiPOPL2010}.
In contrast, our approach is not limited to CEGAR and facilitates the
applicability of a wide range abstract interpretation techniques for
precise reasoning about program data.

\mypara{Software Verification.}
This work was motivated by the recent success in 
software model checking for first-order imperative
programs \cite{SLAMPOPL02,HJMM04,CousotPLDI03,McMillan06}, 
and the desire to apply similar techniques to modern programming
languages with higher order functions.
Our starting point was refinement types \cite{FreemanPfenning91,Knowles07},
implemented in dependent ML \cite{XiPfenning99} to give strong static guarantees, 
and the work on liquid types \cite{LiquidPLDI08,LiquidPLDI09}
that applied predicate abstraction to infer refinement types.
By enabling the application of automatic invariant generation from software
model checking,
\HMC reduces the need for programmer annotations in refinement type systems.


\bibliographystyle{plain}
\bibliography{sw}

\end{document}
