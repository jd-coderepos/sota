

\documentclass[10pt,twocolumn,letterpaper]{article}

\usepackage[pagenumbers]{cvpr} 

\usepackage{graphicx}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{booktabs}
\usepackage[linesnumbered, ruled,nofillcomment]{algorithm2e}
\usepackage{tabularx}
\usepackage{array}
\usepackage{multirow}
\usepackage{multicol}
\usepackage{xcolor}
\usepackage{xspace}
\usepackage{colortbl}
\usepackage{makecell}
\usepackage{float}
\usepackage{marvosym}

\makeatletter
\newcommand{\algorithmfootnote}[2][\footnotesize]{\let\old@algocf@finish\@algocf@finish \def\@algocf@finish{\old@algocf@finish \leavevmode\rlap{\begin{minipage}{\linewidth}
    #1#2
    \end{minipage}}}}
\makeatother

\usepackage[pagebackref,breaklinks,colorlinks]{hyperref}


\usepackage[capitalize]{cleveref}
\crefname{section}{Sec.}{Secs.}
\Crefname{section}{Section}{Sections}
\Crefname{table}{Table}{Tables}
\crefname{table}{Tab.}{Tabs.}
\Crefname{algorithm}{Algorithm}{Algorithms}
\crefname{algorithm}{Alg.}{Algs.}

\newcommand\blfootnote[1]{\begingroup
  \renewcommand\thefootnote{}\footnote{#1}\addtocounter{footnote}{-1}\endgroup
}





\begin{document}

\title{SportsMOT: A Large Multi-Object Tracking Dataset in Multiple Sports Scenes}

\author
{
Yutao Cui \quad
Chenkai Zeng \quad
Xiaoyu Zhao \quad
Yichun Yang \quad
Gangshan Wu \quad
Limin Wang\textsuperscript{~\Letter}
\
	M=\alpha\cdot\text{IoU}+(1-\alpha)\cdot V
    \label{eq:M}

	h_{xy}=\exp (-\frac{(x-c_x)^2+(y-c_y)^2}{2\sigma^2})

	L=-\sum_{xy}\begin{cases}
		(1-\hat h_{xy})^\gamma\log(\hat h_{xy})&, h_{xy}=1;\\
		(1-h_{xy})^\beta(\hat h_{xy})^\gamma\log(1-\hat h_{xy})&,\text{otherwise.}
	\end{cases}

where  and  are hyper-parameters in focal loss, and we set  following CornerNet.

\vspace{-4mm}
\paragraph{Inference.}
For each track, we maintain only one template for keeping a balance between accuracy and speed. When a detection is matched to an existing track, we directly replace the original template to the new detection, if and only if the ratio of its uncovered (\ie overlapping with any detected objects) area is larger than a certain threshold, so as to reduce the impact of misleading representations.

\section{Experiments and Analysis}

\subsection{Experiment Setup}
\paragraph{Dataset Split.}
In benchmark experiments, we follow the default split described in \cref{sec:dataset}. In exploration study, we split the original MOT17 training set into two sets, used for training and validation respectively following CenterTrack.

\vspace{-4mm}
\paragraph{Implementation Details.}
Following ByteTrack and OC-SORT, we use YOLOX~\cite{ge2021yolox} as our detector. Using COCO-pretrained model as the initialized weights, we first train the model on CrowdHuman~\cite{shao2018crowdhuman} for 80 epochs and then train on SportsMOT for another 80 epochs. The remaining settings are the same as that in ByteTrack.

For MixFormer, we initialize the backbone with the model trained on VOT datasets and then fine-tune it on SportsMOT for 300 epochs with learning rate initialized as  and decreased to  at epoch 200. The optimizer is ADAM\cite{kingma2014adam} with weight decay . The sizes of search images and templates are  and  respectively. The max sample interval is set to 10.
For every tracking result, we apply linear interpolation as post-processing, with maximum gap set to 20.

\subsection{Benchmark Results}

\begin{table*}[!t]
\begin{center}{
\resizebox{\linewidth}{!}{
\begin{tabular}{l|c|cccccccc}
\toprule

&Training Setup&HOTA & IDF1 & AssA & MOTA & DetA& LocA & IDs  & Frag  \\ 

\midrule
CenterTrack~\cite{zhou2020tracking} & Train           & 62.7 & 60.0 & 48.0 & 90.8 & 82.1& 90.8 & 10481  & 5750 \\
FairMOT~\cite{zhang2021fairmot}       & Train           & 49.3 & 53.5 & 34.7 & 86.4  & 70.2& 83.9 & 9928  & 21673 \\
QDTrack~\cite{pang2021quasi}      & Train          & 60.4 & 62.3 & 47.2 & 90.1 & 77.5 & 88.0 & 6377  & 11850 \\
TransTrack~\cite{sun2020transtrack}    & Train         & 68.9 & 71.5 & 57.5 & 92.6  & 82.7 & 91.0 & 4992  & 9994 \\
GTR~\cite{zhou2022global}      & Train             & 54.5 & 55.8 & 45.9  & 67.9 & 64.8 & 89.0 & 9567  &  14525 \\ 
ByteTrack~\cite{zhang2022bytetrack}    & Train           & 62.8 & 69.8 & 51.2 & 94.1 & 77.1 & 85.6 & 3267 &  4499 \\
OC-SORT~\cite{cao2022observation}   & Train            & 71.9 & 72.2 & 59.8 & 94.5 & 86.4 & 92.4 & 3093 &  3474 \\
ByteTrack & Train+Val & 64.1 & 71.4& 52.3 & 95.9  & 78.5 & 85.7 &  3089 & 4216\\
OC-SORT & Train+Val & 73.7 & 74.0 & 61.5 & 96.5 & 88.5 & 92.7 & 2728 & \textbf{3144} \\
\midrule
MixSort-Byte  & Train+Val    & 65.7~\textcolor{green}{(+1.6)} & 74.1~\textcolor{green}{(+2.7)}& 54.8~\textcolor{green}{(+2.5)} & 96.2  & 78.8 & 85.7 & \textbf{2472} &  4009 \\
MixSort-OC    & Train+Val    & \textbf{74.1}~\textcolor{green}{(+0.4)} & \textbf{74.4}~\textcolor{green}{(+0.4)}  & \textbf{62.0}~\textcolor{green}{(+0.5)} & \textbf{96.5} & \textbf{88.5} & \textbf{92.7}& 2781  & 3199  \\
\bottomrule
\end{tabular}}}
\end{center}
\vspace{-6mm}
\caption{Tracking performance of investigated algorithms on our proposed SportsMOT. The best results are shown in~\textbf{bold}.}
\vspace{-4mm}
\label{table_mot}
\end{table*}

We evaluate several representative methods of three kinds on our dataset. ByteTrack\cite{zhang2022bytetrack}, OC-SORT\cite{cao2022observation} and QDTrack\cite{pang2021quasi} are trackers in tracking-by-detection paradigm. CenterTrack\cite{zhou2020tracking} and FairMOT\cite{zhang2021fairmot} perform joint detection and tracking in one stage. TransTrack\cite{sun2020transtrack} and GTR\cite{zhou2022global} are trackers based on Transformer. Most of the current best multi-object tracking algorithms belong to tracking-by-detection paradigm, however, due to the separation of detection and tracking, the information cannot be shared completely. Joint-detection-and-tracking paradigm couples the two modules, with the goal of boosting the performance of each. Transformer-based-tracking methods are relatively new but have achieved great performance. Despite its huge potential, the model complexity and calculation cost are much higher, resulting in large memory and long training time.

All training settings including the number of epochs and change of learning rate are consistent with original papers. According to different default settings, we follow the commonly used pretraining datasets, such as CrowdHuman\cite{shao2018crowdhuman}, COCO\cite{lin2014microsoft} and ImageNet\cite{deng2009imagenet}, and apply SportsMOT-train with or without other datasets for finetuning for different methods. We compare the results in \cref{table_mot}.

In sports scenes, the clear appearance and sparse density of objects allow current mature detection frameworks to generate bounding boxes with high accuracy. However, specialized detectors need to be trained for not detecting audience and referees. The key challenges are fast speed and motion blur, which forces us to pay more attention to improve the association performance. Besides, The wide range of HOTA and MOTA denotes SportsMOT is more distinguishable among different kinds of algorithms. 

Tracking-by-detection paradigm methods like ByteTrack and OC-SORT outperform most of the methods in the table. But their association performance is still not satisfactory enough. Thus we propose MixSort that can be applied to any trackers following this paradigm and achieve state-of-the-art performance on SportsMOT.
Besides, to further validate the effectiveness of MixSort, we compare MixSort with the state-of-the-art trackers on MOT17 validation set and test set under the private detection protocol in \cref{fig:mot17testval}. Our MixSort-byte and MixSort-OC outperform these trackers in HOTA, IDF1 and AssA metrics.


\subsection{Exploration Study}
\label{exploration_sec}
In this section, we perform extensive studies on the proposed MixSort and SportsMOT. 

\vspace{-4mm}
\paragraph{Effectiveness of the proposed association module.}
We evaluate the effectiveness of MixSort by applying it to two state-of-the-art trackers, OC-SORT\cite{cao2022observation} and ByteTrack\cite{zhang2022bytetrack}, which follow the tracking-by-detection paradigm and use YOLOX as their detector. The evaluation is conducted on the SportsMOT test set, and the results are presented in \cref{table_mot}. Our experiments show that MixSort significantly improves the performance of both trackers, with OC-SORT achieving a 0.4 HOTA increase and ByteTrack achieving a 1.6 HOTA increase on SportsMOT. This demonstrates the effectiveness of MixSort in enhancing the association.

\vspace{-4mm}
\paragraph{Appearance-based \textit{vs}. Motion-based association.}
\begin{table}[pt]
\centering
\resizebox{\linewidth}{!}{
\begin{tabular}{@{}l|ccccccccccc@{}}
\toprule
   & 1    & 0.9  & 0.8  & 0.7  & 0.6  & 0.5  & 0.4  & 0.3  & 0.2  & 0.1  & 0    \\ \midrule
basketball & 65.9 & 66.1 & \textbf{66.2} & 65.9 & 65.3 & 64.8 & 63.6 & 60.7 & 56.7 & 47.1 & 26.9 \\
volleyball & 76.0 & 76.8 & 76.5 & 76.4 & 76.5 & \textbf{76.9} & 76.4 & 75.5 & 73.7 & 69.1 & 40.9 \\
football   & 71.9 & 72.4 & 72.3 & 72.4 & 72.5 & 72.8 & \textbf{73.2} & 72.9 & 72.6 & 71.4 & 65.7 \\ \bottomrule
\end{tabular}}
\vspace{-2mm}
\caption {Comparison of the HOTA metric of basketball, volley and football under different fusion parameters  on SportsMOT test set. The models are trained on SportsMOT training set.}
\label{tab:alpha}
\vspace{-6mm}
\end{table}
We have demonstrated that MixSort can improve association performance. 
In this paragraph, we investigate the impact of the fusion weight  on the ability of appearance cues to aid in conventional motion-based association. We evaluate OC-SORT with MixSort on the three categories in the SportsMOT test set using  values ranging from 1 to 0 in \cref{eq:M}. The results, presented in \cref{tab:alpha}, reveal that pure motion-based association () outperforms pure appearance-based association () in all categories, underscoring the significance of motion cues in sports scenes. Moreover, fused association surpasses both pure motion-based and appearance-based association, suggesting that both motion and appearance cues should be considered jointly for optimal results.

Our analysis of the three categories reveals that appearance cues provide the most significant improvement for football videos (+1.3), followed by volleyball (+0.9) and basketball (+0.3). Combining this with \cref{fig:iou}, which indicates that the adjacent IoU of football games is the smallest (i.e., motion is fastest) among the three categories, we can conclude that scenes with faster motion are more dependent on appearance cues.

\begin{table*}[ht]
\resizebox{\linewidth}{!}{
\begin{tabular}{l|cccccc|cccccc}
\toprule
\multicolumn{1}{l|}{\multirow{2}{*}{}} & \multicolumn{6}{c|}{MOT17-test} & \multicolumn6{c}{MOT17-val} \\
\multicolumn{1}{l|}{} & HOTA & IDF1 & AssA & MOTA & DetA & IDs & HOTA & IDF1 & AssA & MOTA & DetA & IDs\\
\midrule
QDTrack~\cite{pang2021quasi} & 53.9 & 66.3 & 52.7 & 68.7 & 55.6 & 3378 & - & - & - & - & - & -\\
MOTR~\cite{zeng2022motr} & 57.2 & 68.4 & 55.8 & 71.9 & 58.9 & 2115 & - & - & - & - & - & -\\
GTR~\cite{zhou2022global} & 59.1 & 71.5 & 57.0 & 75.3 & 61.6 & 2859 & 63.0 & 75.9 & 66.2 & 71.3 & 60.4 & -\\
ByteTrack~\cite{zhang2022bytetrack} & 63.1 & 77.3 & 62.0 & \textbf{80.3} & \textbf{64.5} & 2196 & - & 79.7 & - & 76.7 & - & 159\\
OC-SORT~\cite{cao2022observation} & 63.2 & 77.5 & 63.4 & 78.0 & 63.2 & 1950 & 68.0 & 79.3 & 69.9 & 77.9 & - & -\\
\midrule
MixSort-Byte & \textbf{64.0} & \textbf{78.7} & \textbf{64.2} & 79.3 & 64.1 & 2235 & \textbf{69.4} & \textbf{81.1} & 71.3 & \textbf{79.9} & \textbf{68.2} & 155\\
MixSort-OC & 63.4 & 77.8 & 63.2 & 78.9 & 63.8 & \textbf{1509} & 69.2 & 80.6 & \textbf{71.5} & 78.9 & 67.4 & \textbf{135}\\
\bottomrule
\end{tabular}}
\vspace{-3mm}
\caption{Comparison of the state-of-the-art methods under the “private detector” protocol on MOT17-test set and MOT17-val set.}
\vspace{-4mm}
\label{fig:mot17testval}
\end{table*}

\vspace{-4mm}
\paragraph{Analysis on different categories of SportsMOT.}
While the three SportsMOT categories share some common characteristics such as fast motion and similar appearance, they also have distinct features due to the different types of games. In this section, we analyze the results of our experiments on the three categories.

We first use the best HOTA metric from \cref{tab:alpha} to represent the \textit{overall difficulty} of a category. Based on this metric, we find that basketball videos (66.17) are the most difficult, followed by football (73.19), and finally volleyball (76.91).

Next, we consider the \textit{appearance-based} association (\ie  in \cref{tab:alpha}). We observe a notable gap between the HOTA metrics of the three categories, where basketball (26.94) has a much lower HOTA than volleyball (40.94) and football (65.65). Similarly, basketball remains the most difficult in the \textit{motion-based} association (\ie  in \cref{tab:alpha}), while the volleyball becomes the easiest.

We believe that the differences in difficulty arise from several factors, including the size of the game court and the degree of physical confrontation among players. For instance, basketball scenes are played on smaller courts and involve more physical contact between players than football scenes. This can lead to more occlusion and blur in basketball videos, making the association task more challenging than in football scenes.

\begin{table}[pt]
\resizebox{\linewidth}{!}{
\begin{tabular}{@{}ccc|ccccc@{}}
\toprule
IoU        & Motion     & Mix.    & HOTA & IDF1 & AssA & MOTA & IDs  \\ \midrule
\checkmark &            &            & 71.5 & 71.2 & 58.1 & 95.9 & 4329 \\
           &            & \checkmark & 64.2 & 63.9 & 48.7 & 91.1 & 25947 \\
\checkmark & \checkmark &            & 64.1 & 71.4 & 52.3 & 95.9 & 3089 \\
\checkmark &            & \checkmark & \textbf{73.8} & \textbf{74.4} & \textbf{61.6} & \textbf{96.6} & 3203 \\
\checkmark & \checkmark & \checkmark & 65.7 & 74.1 & 54.8 & 96.1 & \textbf{2469} \\ \bottomrule
\end{tabular}}
\vspace{-3mm}
\caption{Results of the ablation experiment on SportsMOT test set. IoU means computing IoU between detections and the last location of existing tracks for association, while Motion means using Kalman filter to predict the location of tracks. The models are trained on SportsMOT training and validation set.}
\vspace{-6mm}
\label{fig:ablation}
\end{table}

\vspace{-4mm}
\paragraph{Ablation study on MixSort.}
We ablate important components of our tracker (MixSort based on ByteTrack) including \textit{IoU}, \textit{Motion} (Kalman Filter) and \textit{MixSort} on SportsMOT test set. The results are presented in \cref{fig:ablation}.
Surprisingly, we found that simple IoU without using motion prediction outperformed IoU with motion prediction by a large margin (from 64.1 HOTA to 71.5 HOTA), indicating that the Kalman filter, which assumes linear motion models, performed poorly on SportsMOT, where the motion patterns are far more complex than in previous datasets.

Furthermore, we observed that MixSort played a crucial role in boosting the performance of the tracker significantly. By fusing the IoU and MixSort cues, our method achieved the best performance of 73.8 HOTA compared to 71.5 HOTA of simple IoU in our experiments.

\vspace{-4mm}
\paragraph{Comparison with SoccerNet.}
We conducted experiments to compare SoccerNet that focuses only on soccer scenes with SportsMOT. Results shown in \cref{fig:sportssoccer} suggest that SportsMOT is a challenging dataset with varying levels of difficulty across different sports categories. Specifically, basketball is proved to be the most difficult with the lowest HOTA of 60.8, while volleyball and football are relatively easier. 
MixSort obtains higher HOTA on SportsMOT than on SoccerNet. This is mainly because all the elements on the court are to be tracked in SoccerNet, leading to more false detections and much lower DetA (71.5 vs 78.8). However, it still obtains higher AssA on SoccerNet than on SportsMOT, in spite of the more false detections, which demonstrates that SportsMOT yields challenging association and is valuable for tracking in sports.
\begin{table}[pt]
\resizebox{\linewidth}{!}{
\begin{tabular}{@{}cc|ccccc@{}}
\toprule
                                                &            & HOTA & IDF1 & AssA & MOTA & DetA \\ \midrule
\multicolumn{1}{c|}{\multirow{4}{*}{SportsMOT}} & overall    & 65.7 & 74.1 & 54.8 & 96.1 & 78.8 \\
\multicolumn{1}{c|}{}                           & basketball & \textbf{60.8} & \textbf{67.8} & \textbf{46.8} & 97.3 & 79.1 \\
\multicolumn{1}{c|}{}                           & volleyball & 72.5 & 87.0 & 66.8 & 96.5 & 78.7 \\
\multicolumn{1}{c|}{}                           & football   & 66.4 & 73.6 & 56.3 & 94.9 & 78.5 \\ \midrule
\multicolumn{2}{c|}{SoccerNet}                               & 62.9 & 73.9 & 55.5 & \textbf{87.8} & \textbf{71.5} \\ \bottomrule
\end{tabular}
}
\vspace{-3mm}
\caption{Results of MixSort-Byte on SportsMOT and SoccerNet test set. The models are trained on SportsMOT training and validation set and SoccerNet training set respectively and the hyper-parameters are the same. }
\label{fig:sportssoccer}
\end{table}

\vspace{-3mm}
\paragraph{Comparison with DanceTrack.}
We evaluate MixSort-Byte on the DanceTrack validation set and compare the results with that of ByteTrack as shown in \cref{fig:dance}. Unlike the results on SportsMOT where MixSort brings significant improvement, on DanceTrack the original ByteTrack performs better instead, with HOTA, MOTA and DetA metrics all higher than MixSort-Byte. This indicates that appearances in our proposed dataset SportsMOT are \textit{similar yet distinguishable}, while those in DanceTrack are much harder to distinguish. Therefore SportsMOT highlights both the motion-based and appearance-based associations.
\begin{table}[pt]
\vspace{-1mm}
\resizebox{\linewidth}{!}{\begin{tabular}{@{}c|ccccc@{}}
\toprule
             & HOTA & IDF1 & AssA & MOTA & DetA \\ \midrule
ByteTrack    & \textbf{47.1} & 51.9 & 31.5 & \textbf{88.2} & \textbf{70.5} \\
MixSort-Byte & 46.7 & \textbf{53.0} & \textbf{31.9} & 85.8 & 68.6 \\ \bottomrule
\end{tabular}}
\vspace{-2.8mm}
\caption{Comparison of ByteTrack and MixSort-Byte on DanceTrack validation set. For MixSort-Byte, the fuse parameter  is 0.9, which results in the highest HOTA among \{0.6, 0.7, 0.8, 0.9, 0.95\}. The models are trained on DanceTrack training set.}
\vspace{-4mm}
\label{fig:dance}
\end{table}


\paragraph{Comparison Between MixSort and ReID models.}
To verify the effectiveness of the proposed MixSort with introducing a MixFormer-like model to model appearance association cues, we take experiments as in Table~\ref{tab:sup1}. 
We use the same ReID model as in DeepSORT and finetune it on our SportsMOT. 
We can see that, the HOTA, IDF1 and AssA of ByteTrack with ReID model are higher than that of original ByteTrack without ReID model, which demonstrate the importance of appearance-based association on the proposed SportsMOT.
Moreover, the proposed MixSort-Byte imporves ByteTrack with ReID model by 0.9, 1.9 and 1.4 on HOTA, IDF1 and AssA respectively.
This proves the superiority of MixSort's appearance model over the original ReID model, since it can extract more extensive and discriminative representations, and also allows more effective offline learning.

\begin{table}[pt]
\resizebox{\linewidth}{!}{\begin{tabular}{@{}c|ccccc@{}}
\toprule
             & HOTA & IDF1 & AssA & MOTA & DetA \\ \midrule
ByteTrack    & 64.1 & 71.4 & 52.3 & 95.9 & 78.5 \\
ByteTrack+ReID    & 64.8 & 72.2 & 53.4 & \textbf{96.1} & \textbf{78.8} \\
MixSort-Byte &  \textbf{65.7} & \textbf{74.1} & \textbf{54.8} & \textbf{96.1} & \textbf{78.8} \\ \bottomrule
\end{tabular}}
\vspace{-3mm}
\caption{Comparison of ByteTrack, ByteTrack with ReID model and MixSort-Byte on SportsMOT test set. The ReID model is the same as in DeepSORT~\cite{bewley2016simple} and finetuned on SportsMOT. The models are trained on SportsMOT training set and the best results are shown in \textbf{bold}.}
\vspace{-4mm}
\label{tab:sup1}
\end{table}






\section{Conclusion}
In this paper, we have introduced~\emph{SportsMOT}, a large-scale multi-object tracking dataset in sports scenes.
SportsMOT is characterized with two key properties: 1) fast and variable-speed motion and 2) similar yet distinguishable appearance. 
We have empirically investigated several prevailing MOT trackers on the SportsMOT dataset.
We have also proposed a new MOT framework~\emph{MixSort}, introducing a MixFormer-like association module. 
Hopefully, SportsMOT can provide a platform for facilitating both sports analysis and multi-object tracking.




{\small
\bibliographystyle{ieee_fullname}
\bibliography{egbib}
}

\end{document}
