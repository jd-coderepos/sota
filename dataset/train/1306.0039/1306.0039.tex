\documentclass[a4paper]{article}

\usepackage{amsmath,amsthm}
\usepackage{amssymb,latexsym}
\usepackage{comment}
\usepackage{amsfonts}
\usepackage{tikz}
\usepackage[utf8]{inputenc}
\usepackage[english]{babel}
\usepackage[all]{xy}
\usepackage{fullpage}
\usepgflibrary{arrows}

\newcommand\norm[1]{\|#1\|}
\newcommand\bary[1]{\mathrm{bar}(#1)}
\newcommand\dm{d_{\mu,m}}
\newcommand\dPm{d_{\mu,m}^P}
\newcommand\dmP{d_{\mu_P,m}}
\newcommand\dPP{d_{\mu_P,m}^P}
\newcommand\dPW{d_{\mu_P,m}^W}
\newcommand\X{\mathbb{X}}
\newcommand\R{\mathbb{R}}
\newcommand\U{\mathbb{U}}
\newcommand\V{\mathbb{V}}
\newcommand\W{\mathbb{W}}
\newcommand\dX[2]{d_\X(#1,#2)}
\newcommand\dXp[2]{d_{\X'}(#1,#2)}

\newcommand\Dgm[1]{\mathrm{Dgm}(#1)}
\newcommand\Sub[2]{\mathrm{Sub}_#1(#2)}
\newcommand\Supp[1]{\mathrm{Supp}(#1)}
\newcommand\dy{\mathrm{d}y}
\newcommand\dbl{d_B^{\mathrm{log}}}


\newcommand\ForAuthors[1]{\par\smallskip                     \begin{center}\fbox {\parbox{0.9\linewidth}{\raggedright\sc--- #1}}\end{center}\par\smallskip                     }


\newtheorem{theorem}{Theorem}[section]
\newtheorem{definition}[theorem]{Definition}
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{corollary}[theorem]{Corollary}
\newtheorem{proposition}[theorem]{Proposition}
\newtheorem{remark}{Remark}

 \newenvironment{algorithm}[1]{\begin{center}\rule{120mm}{0.3mm}\\\textsc{\textbf{#1}}\end{center}}
{\begin{center}\rule{120mm}{0.3mm}\end{center}}



\newcommand{\e}{\varepsilon}
\newcommand{\Z}{\mathbb{Z}}
\newcommand{\Rnn}{\R_{\ge 0}}
\newcommand{\ball}{\mathrm{ball}}
\newcommand{\dist}{\mathrm{dist}}
\newcommand{\ir}{\lambda}
\newcommand{\net}{N}
\newcommand{\cl}[1]{\overline{#1}}
\newcommand{\ff}{\mathrm{f}}
\newcommand{\proj}{\pi}
\newcommand{\Rips}{\mathrm{Rips}}
\newcommand{\Hom}{\mathrm{H_*}}
\DeclareMathOperator\argmin{argmin}
\DeclareMathOperator\argmax{argmax} 
\title{Efficient and Robust Persistent Homology for Measures}
\author{
      Micka\"{e}l Buchet\footnote{mickael.buchet@inria.fr}
    \and
      Fr\'{e}d\'{e}ric Chazal\footnote{frederic.chazal@inria.fr}
    \and 
      Steve Y. Oudot\footnote{steve.oudot@inria.fr}
    \and
      Donald R. Sheehy\footnote{don.r.sheehy@gmail.com}
  }


\begin{document}
\maketitle

A new paradigm for point cloud data analysis has emerged recently, where point clouds are no longer treated as mere compact sets but rather as empirical measures. 
  A notion of distance to such measures has been defined and shown to be stable with respect to perturbations of the measure. 
  This distance can easily be computed pointwise in the case of a point cloud, but its sublevel-sets, which carry the geometric information about the measure, remain hard to compute or approximate.
  This makes it challenging to adapt many powerful techniques based on the Euclidean distance to a point cloud to the more general setting of the distance to a measure on a metric space.
 
  We propose an efficient and reliable scheme to approximate the topological structure of the family of sublevel-sets of the distance to a measure. 
  We obtain an algorithm for approximating the persistent homology of the distance to an empirical measure that works in arbitrary metric spaces. 
  Precise quality and complexity guarantees are given with a discussion on the behavior of our approach in practice.
 
\section{Introduction} Given a sample of points  from a metric space , the distance function  maps each  to the distance from  to the nearest point of .
  The related fields of geometric inference and topological data analysis have provided a host of theorems about what information can be extracted from the distance function, with a particular focus on discovering and quantifying intrinsic properties of the shape underlying a data set~\cite{stcsesCCL,fhshcrsNSW}.
  The flagship tool in topological data analysis is persistent homology and the most common goal is to apply the persistence algorithm to distance functions, either in Euclidean space or in metric spaces~\cite{carlsson09topology,tpsELZ, cphCZ}.
  From the very beginning, this line of research encountered two major challenges.
  First, distance functions are very sensitive to noise and outliers (Fig.~\ref{fig:d_mu} left).
  Second, the representations of the sublevel sets of a distance function become prohibitively large even for moderately sized data.
  These two challenges led to two distinct research directions.
  First, the distance to the data set was replaced with a distance to a measure induced by that data set~\cite{gipmCCM}.
  The resulting theory is provably more robust to outliers, but the sublevel sets become even more complex to represent (Fig.~\ref{fig:d_mu} center).
  Towards more efficient representations, several advances in \emph{sparse filtrations} have led to linear-size constructions~\cite{ctpsmDFW,ZZZ,lsavrfS}, but all of these methods exploit the specific structure of the distance function and do not obviously generalize.
  In this paper, we bring these two research directions together by showing how to combine the robustness of the distance to a measure, with the efficiency of sparse filtrations.

  \begin{figure}[htbp]
    \centering
      \includegraphics[width=.3\textwidth]{pictures/d_mu_0}
      \includegraphics[width=.3\textwidth]{pictures/d_mu_1}
      \includegraphics[width=.3\textwidth]{pictures/d_mu_2}
    \caption{From left to right, two sublevel sets for , , and  with .
    The first is too sensitive to noise and outliers.
    The second is smoother, but substantially more difficult to compute.
    The third is our approximation, which is robust to noise, efficient to compute, and compact to represent.}
    \label{fig:d_mu}
  \end{figure}

\paragraph{Contributions:}
\begin{enumerate}
  \item \textbf{A Generalization of the Wasserstein stability and persistence stability of the distance to a measure for triangulable metric spaces.}
  \item \textbf{A general method for approximating the sublevel sets of the distance to a measure by a union of balls.}  
  Our method uses  balls for inputs of  samples.  
  Known methods for representing the exact sublevel sets can require  balls. 
  Existing approximations using a linear number of balls are only applicable in Euclidean space~\cite{wkdGMM}.
\item \textbf{A linear size approximation to the weighted Rips filtration.}
  For intrinsically low-dimensional metric spaces, we construct a filtration of size  that achieves a guaranteed quality approximation.  
  Specifically, if the doubling dimension of the metric is  then the size complexity is  if one considers simplices up to dimension  (see Def.~\ref{def:doubling_dimension} for the formal definition of doubling dimension).
  This is a significant improvement over the full weighted Rips filtration, which has size  in general or size  if one considers only simplices up to dimension .
  It also has the advantage that the sparsification is independent of the weights.
  Thus, the (geo)metric preprocessing phase can be reused for any weighting of the points.
  If one attempted to use previous methods directly, this preprocessing phase would have to be repeated for each set of weights.
  This is especially useful if one is interested in several different weight functions such as when approximating the distance to a measure for several different values of the mass parameter.
  \item \textbf{An effective implementation with experimental results.} 
\end{enumerate}




\paragraph{Overview of the paper} 

Originally, the distance to a measure was introduced to capture information about both scale and density in a Euclidean point cloud.
We extend the distance to a measure to any metric space .
We write  to denote the closed ball with center  and radius .
The distance to a measure is then defined as follows.
\begin{definition}
Let  be a probability measure on a metric space  and let  be a mass parameter. We define the distance  to the measure  as

where  is defined as

\end{definition}



The distance to a measure has interesting inference and stability results in the Euclidean setting~\cite{gipmCCM}.
That is, the sublevel sets of the function can be used to infer the topology of the support of the underlying distribution (inference), and also, the output for similar inputs will be similar (stability).
In Section~\ref{sPersStabDtm}, we extend these stability results to any metric space.
The results about the stability of persistence diagrams apply to any triangulable metric space, i.e. metric spaces homeomorphic to a locally finite simplicial complex (the persistence diagram may not exist for non-triangulable metric spaces).


We then give a new way to approximate the distance to a measure.
Using a sampling of the support of a measure, we are able to compute accurately the sublevel sets of the distance to a measure in any metric space, using power distances.
We show in Section~\ref{sApd} that these functions have adequate stability and approximation properties.
Then, in Section~\ref{sRestrict}, we give the practical implications for computing persistence diagram for finite samples.

The \emph{witnessed -distance} is another approach to approximating the distance to a measure proposed in~\cite{wkdGMM}.
This approach works only in Euclidean spaces as it relies on the existence of barycenters of points.
The analysis links the quality of the approximation to the underlying topological structure.
In this paper, we look at bounds independent of intrinsic geometry.
When restricted to the Euclidean setting in section~\ref{ssEc}, our method improves the approximation bounds from~\cite{wkdGMM}.
The new bounds match the quality of approximation achieved by our method of Section~\ref{sApd}, which has the added advantage that it is valid in any metric spaces..


In Section~\ref{sWRips}, we introduce the \emph{weighted Rips complex}.
Given a parameter, the sublevel set of a power distance associated with this parameter is a union of balls.
Generalizing the Vietoris-Rips complex, we define the weighted Rips complex as the clique complex whose -skeleton is the same as the one of the nerve of this union of balls.
The induced filtration has important stability properties and can be used to approximate  persistence diagrams.


Unfortunately, the weighted Rips filtration is too large to construct in full for large instances.
This problem already exists with the usual Rips filtration.
Sparsifying schemes have been recently proposed in~\cite{ctpsmDFW,lsavrfS}.
Extending the approach used in~\cite{lsavrfS}, we construct a sparse approximation that has linear size in the number of points (Section~\ref{sec:sparse_rips}).
This can be used to approximate persistence diagrams even for high dimensional inputs if the data is intrinsically low dimensional.
As we show in Section~\ref{sec:sparse_rips}, there are very simple examples where the input metric is intrinsically low-dimensional and yet the weight function can cause the weighted distance function to be high-dimensional.  
Our approach has the advantage over previous methods in that the size complexity will only depend on the dimension of the input metric, rather than the dimension of points under the weighted distance.

The combination of these approaches makes it possible to use the distance to a measure to infer topology on real instances.
In Section~\ref{sNumeric}, we illustrate the theory with some examples and results from an implementation.








\section{Background} In this paper, we consider a metric space  with distance .
In a slight abuse of notation, we also write  to denote the distance between a point and a set defined as .
The Hausdorff distance between two sets  and  will be denoted .
We write  for the open ball of center  and radius  in , and we write  for the corresponding closed ball.

\paragraph{Metric Spaces and doubling dimension}
For metric spaces that are not embedded in Euclidean space, the doubling dimension gives a useful way to describe the intrinsic dimension of the metric space by bounding the size of certain covers of subsets.
Formally it is defined as follows.

\begin{definition}\label{def:doubling_dimension}
  The \emph{doubling constant}  of a metric space  is the maximum over all balls  with  of the minimum number of balls of radius  required to cover .
  The \emph{doubling dimension} is defined to be .
\end{definition}

\paragraph{Wasserstein distance\\}
To compare measures, we use the Wasserstein distance, also called the earth-mover distance.
Intuitively, it is the minimal cost to move all the mass from one measure to another.
To state the formal definition we first introduce some notation.

Given a measure  on a metric space , we write  to denote the set of all Borel subsets of .
Given , we define the \emph{mass of } as .
Similarly  is called the \emph{total mass} of .
We write  for the support of the measure .


\begin{definition}
Let  and  be positive measures with the same total mass on a metric space .
A \emph{transport plan} between  and  is a measure  on  such that for all ,

\end{definition}

We denote by  the set of all transport plans between  and .
The th order cost of the transport plan  is defined as

The Wasserstein distance between  and  is the minimum cost over all transport plans.

\begin{definition}
Let  and  be positive measures with the same total mass on a metric space . 
The \emph{Wasserstein distance} of order  between  and  is defined as

\end{definition}

The Wasserstein distance is finite if both probability measures have finite -moments, which is always the case for measures with compact support.

\paragraph{Persistence theory\\}
  A \emph{filtration}  is a sequence of spaces such that  whenever .
  Persistence theory studies the evolution of the homology of the sets  for  ranging from  to .
  More precisely, the filtration induces a family of vector spaces connected by linear maps at the homology level, called a \emph{persistence module}.
  More generally, a persistence module is a pair  where each  is a vector space and  is a linear map  such that  for all  and  is the identity.
  A persistence module is said to be \emph{q-tame} if  has finite rank for every .
  A filtration is said to be q-tame if its corresponding persistence module is q-tame.
  The algebraic structure of a q-tame persistence module  can be described and visualized by the \emph{persistence diagram} , a multiset of points in the plane.
  If  comes from a filtration , a point  in  indicates a nontrivial homology class that exists in the filtration between the parameter values  and .
  
  We overload notation and write  to denote the persistence diagram of the persistence module defined by the filtration .
  Moreover, for a real-valued function , we write  to denote , the persistence diagram of the sublevel sets filtration of .
  For an introduction to persistent homology, the reader is directed to~\cite{sspmCDGO,ctaiEH}.


\paragraph{Bottleneck distance\\}
  We put a metric on the space of persistence diagrams as follows.
  First, a partial matching  between diagrams  and  is a subset of  in which each element of  appears in at most one pair.
  The bottleneck cost of  is .
  We say  is an -matching if the bottleneck cost is  and every  in  or  with  is matched.
  The \emph{bottleneck distance} between  and  is defined as
  

  It is often useful to look at persistence diagrams on a logarithmic scale, because the distance does no longer depend on the scale at which the object is seen.
  The \emph{log-bottleneck distance}, denoted  is the bottleneck distance between diagrams after the change of coordinates .

\paragraph{Filtration interleaving\\}
One way to prove that two persistence diagrams are close is to prove that the filtrations inducing them are interleaved.
Two filtrations  and  are said to be \emph{-interleaved} if for any ,

The following classic result~\cite{ppmdCCGGO,sspmCDGO,spdCEH} about stability of persistence diagrams says that interleaved filtrations yield similar persistence diagrams.

\begin{theorem}\label{tstability}
Let  and  be two -tame and -interleaved filtrations. Then, the persistence diagrams of these filtrations are -close in bottleneck distance, i.e.,

\end{theorem}


We work with the persistence theory on functions, which means studying the persistence of \emph{the sublevel sets filtration} defined as  for any real-valued function.
To simplify notation, we write  to denote the persistence diagram of the sublevel sets filtration of .

\paragraph{Persistence module interleaving\\}
The notion of interleaving can be extended to persistence modules as seen in~\cite{psgcCDO}.
Given two persistence modules  and  and a real , an \emph{-homomorphism} from  to  is a collection of linear maps  such that for all , . 
Two -homomorphisms  from  to  and  from  to  can be composed to build a -homomorphism  from  to  whose linear maps are obtained by composing the linear maps of  and .
Among -homomorphisms from , one has a particular role.
The \emph{-shift map}  is the collection of maps  given in the persistence module .
We use it to define the interleaving of two persistence modules as follows.

\begin{definition}
Let  and  be two q-tame persistence modules.  and  are \emph{-interleaved} if there exists -homomorphisms  and  such that  and .
\end{definition}

Note that the definition is equivalent to the commutativity of the following diagrams for any , where  and .

\begin{center}
\begin{tikzpicture}[scale=.7]
\draw (-1,1) node {};
\draw (-6,1) node {};
\draw (-6,3) node {};
\draw (-1,3) node {};
\draw[->] (-5.4,1) --node[below] {} (-1.6,1);
\draw[->] (-5.4,3) --node[above] {} (-1.6,3);
\draw[->] (-6,2.5) --node[left] {} (-6,1.5);
\draw[->] (-1,2.5) --node[right] {} (-1,1.5);

\draw (-1,-1) node {};
\draw (-6,-1) node {};
\draw (-6,-3) node {};
\draw (-1,-3) node {};
\draw[->] (-5.4,-1) --node[above] {} (-1.6,-1);
\draw[->] (-5.4,-3) --node[below] {} (-1.6,-3);
\draw[->] (-6,-1.5) --node[left] {} (-6,-2.5);
\draw[->] (-1,-1.5) --node[right] {} (-1,-2.5);

\draw (3,3) node {};
\draw (7,3) node {};
\draw (5,1) node {};
\draw[->] (3.6,3) --node[above] {} (6.4,3);
\draw[->] (3.3,2.7) --node[left] {} (4.7,1.3);
\draw[->] (5.3,1.3) --node[right] {} (6.7,2.7);

\draw (3,-1) node {};
\draw (7,-1) node {};
\draw (5,-3) node {};
\draw[->] (3.6,-1) --node[above] {} (6.4,-1);
\draw[->] (3.3,-1.3) --node[left] {} (4.7,-2.7);
\draw[->] (5.3,-2.7) --node[right] {} (6.7,-1.3);
\end{tikzpicture}
\end{center}

The following theorem is an algebraic analog of Theorem~\ref{tstability}.
The proof can be found in~\cite{sspmCDGO}.

\begin{theorem}\label{tModStability}
Let  and  be two q-tame and -interleaved persistence modules. 
Then,

\end{theorem}

\paragraph{Contiguous simplicial maps\\}
Let  and  be simplicial complexes.
A \emph{simplicial map}  is a map between the corresponding vertex sets so that for every simplex ,  is a simplex in .
Two simplicial maps  and  are \emph{contiguous} if  implies that .
 If two simplicial maps are contiguous, then they induce the same homomorphism at the homology level~\cite[Chapter 1]{munkres84elements}.

A \emph{clique complex} is a simplicial complex whose simplices are the cliques of a graph.
Many of the simplicial complexes considered in this paper are clique complexes.
We will use the following simple lemma to construct contiguous simplicial maps between clique complexes.

\begin{lemma}\label{lem:contiguity_and_cliques}
Let  and  be clique complexes and let  and  be two functions from the vertex set of  to the vertex set of .
If for every edge , the tetrahedron  is in , then  and  induce contiguous simplicial maps from  to .
\end{lemma}

\begin{proof}
  Let  be a simplex of .
  Every pair in  is of the form , , or  for some vertices  and  in .
  Since , the tetrahedron hypothesis of the lemma implies that all of these pairs are edges of .
  Thus,  is a simplex in  because  is a clique complex.
  Moreover,  and  because simplices are closed under taking subsets.
  Therefore,  and  are indeed contiguous simplicial maps as desired.
\end{proof}



\section{Persistence and Stability of the Distance to a Measure in a Metric Space} \label{sPersStabDtm}

In this section, we prove that, if we have two close probability measures, then the persistence diagrams of the sublevel sets filtration of their distance to measure functions are close.
The result applies to \emph{triangulable} metric spaces, i.e., those that are homeomorphic to a locally finite simplicial complex.
The persistence diagrams considered in this paper are well defined in this class of spaces.
In particular, every compact Riemannian manifold is triangulable.

  If the persistence diagram is to be meaningful, one might expect that it is stable with respect to perturbations in the underlying measure.
  The following theorem shows that this is indeed the case.
  Two measures that are close in the quadratic Wasserstein distance,  yield persistence diagrams that are close in bottleneck distance,  (see~\cite[Sec. 7.1]{villani2003tot}).

\begin{theorem}\label{tStabPersDtm}
Let  and  be two probability measures on a triangulable metric space  and let  be a mass parameter. 
Then  and  are well-defined and

\end{theorem}

To prove this theorem, we first show that the distance to measure functions are stable with respect to the Wasserstein distance.
Then, we prove that their diagrams are well-defined and are close using Theorem~\ref{tstability}.

\subsection{Wasserstein stability}

A measure  is a \emph{submeasure} of a measure  if for every .
Let  be the set of all submeasures of , which have a total mass .

The distance to a measure  at point a  can be expressed as the Wasserstein distance between two measures,
the Dirac mass  on 
and a submeasure of  of mass .
Using this view, we generalize the stability result from~\cite{gipmCCM} as follows. 

\begin{proposition}\label{Wwriting}
Let  be a probability measure on a metric space , and let  be a mass parameter. Then,

\end{proposition}

Given  and , let  be the set of the submeasures of  with total mass  whose support is contained in the closed ball  and whose restriction to the open ball  coincides with .
The proof shows that  is exactly the set of minimizers of Proposition~\ref{Wwriting}. 


In order to prove this theorem we need to introduce a few definitions.
The \emph{cumulative function}  of a measure  on  is the non-decreasing function defined by .
Its \emph{generalized inverse}  is left-continuous. 

\begin{proof}
If  is a measure of total mass  on  then there exists only one transport plan between  and the Dirac mass .
It transports every point of  to .
Hence we get


Let  denote the distance function to the point  and let  be the pushforward of  by the distance function to .
That is, for any subset  of . 
Note that .
Using the change of variable formula and the definition of the cumulative function we get:


Suppose further that  is a submeasure of , then  for all . 
So,  for all , and thus,

This inequality implies that  is smaller than  for any .

Consider the case when the inequality in (\ref{cumulineq}) is tight.
Such a case happens when for almost every .
Since these functions are increasing and left-continuous, equality must hold for every such .
By the definition of the pushforward, this implies that , i.e., all the mass of  is contained in the closed ball , and that .
Because  is a submeasure of  this is true if and only if  is in the set  described before the proof.
Thus  is exactly the set of submeasures  such that .

To conclude the proof we need only show that there exists at least one measure  in the set .
If , then  is an obvious choice.
The only difficulty is when the boundary  of the ball has too much mass.
In this case we uniformly rescale the mass contained in the bounding sphere such that the measure  has total mass . 
More precisely we let:

We hence have .
\end{proof}


From this result, we have the following Wasserstein stability guarantee for the distance to a measure.

\begin{theorem}\label{stability}
Let  and  be two probability measures on a metric space  and let  be a mass parameter. 
Then:

\end{theorem}

\begin{proof}
Using Proposition~\ref{Wwriting}, we get that , where . 
Let  be an optimal transport plan between  and , i.e., a transport plan between  and  such that


Let us consider the submeasure  of .
Then there exists  a submeasure of  that transports  to a submeasure  of .
We get that:

Using Proposition~\ref{Wwriting} again, we get that for any , .
Thus,

The roles of  and  can be reversed to conclude the proof.
\end{proof}

Another consequence of Proposition~\ref{Wwriting} is that  is -Lipschitz with respect to .

\begin{proposition}\label{pLipschitz}
Let  be a probability measure on a metric space  and let  be a mass parameter. Then  is 1-Lipschitz.
\end{proposition}

\begin{proof}
Let  and  be two points of . 
Using Proposition~\ref{Wwriting}, there exists a submeasure  of  such that .
The same proposition applied to  gives .
Knowing that , we can conclude that .
The choice of  and  is arbitrary, so by symmetry, .
Therefore,  is 1-Lipschitz.
\end{proof}

\subsection{Persistence}
For persistence diagrams of sublevel sets filtrations of distance to measure functions to be well-defined, we need to prove that they are q-tame.
\begin{proposition}\label{pQtame}
Let  be a triangulable metric space, let  be a probability measure on , and let  be a mass parameter. 
Then, the sublevel sets filtration of  is -tame.
\end{proposition}



\begin{proof}According to Proposition~\ref{pLipschitz}  is 1-Lipschitz and thus continuous. 
Also,  is nonnegative by definition.
Moreover,  is proper, i.e., the preimage of any compact set is compact. 
As the function is nonnegative and continuous, it suffices to show that any sublevel set  is compact.

Suppose for contradiction that for a fixed ,  is not compact.
Then there exists a sequence  of points of  such that  when .
Hence we can extract a sub-sequence  such that for any  and , .
Let us remark that .
So,

The function  is nonnegative and increasing with  and therefore .
Using the definition of , this implies that .
Measures are countably additive, so 

However,  is a probability measure and therefore .
This contradiction implies that  is compact.

As  is triangulable, there exists a homeomorphism  from  to a locally finite simplicial complex .
Then for any , we can restrict the simplicial complex  to a finite simplicial complex  that contains  as  is compact.
The function  is continuous on .
Thus its sublevel sets filtration is -tame by Theorem~2.22 of~\cite{sspmCDGO}.

The construction extends to any  and therefore the sublevel sets filtration of  is -tame.
Furthermore, homology is preserved by homeomorphisms and thus we can say that the sublevel sets filtration of  is -tame.
\end{proof}


Theorem~\ref{tStabPersDtm} is now obtained by combining Theorem~\ref{tstability} and Proposition~\ref{pQtame}.

\begin{proof}[Proof of Theorem~\ref{tStabPersDtm}]
Theorem~\ref{stability} guarantees that:

The sublevel sets filtrations are therefore interleaved since for all ,

Therefore, applying Theorem~\ref{tstability} gives

\end{proof}



\section{Approximating the Distance to a Measure} \label{sec:approximating_the_distance_to_a_measure}

Computing the persistence diagram of the sublevel sets filtration of  requires knowing the sublevel sets. 
They are not generally easy to compute. 
We propose an approximation paradigm for  that replaces the sublevel sets by a union of balls.
The approach works in any metric space and yields equivalent guarantees as the witnessed -distance approach used in~\cite{wkdGMM} for Euclidean spaces.

\subsection{Power distances}\label{sApd}



\begin{definition}
  Given a metric space , a set  and a function , we define the \emph{power distance}  associated with  as
  
  where  is the value of  at the point .
\end{definition}

The function  can be defined on a superset of .
Moreover, the sublevel set  is the union of the closed balls centered on the points  of  with radius .
By convention, we assume the ball is empty when the radius is imaginary.

\paragraph{Stability\\}
Power distances are stable under small perturbations of the points.



The following lemma states a result about inclusions between balls.
It allows another stability result on power distances (Proposition~\ref{pPowerBalls}) and will be useful for studying the stability of the weighted Rips filtration in Section~\ref{sWRips}.

  \begin{lemma}\label{lPowerBalls}
    Let  be such points such that , and let  be a -Lipschitz function.
    For all ,
    
  \end{lemma}
  \begin{proof}
    First, observe that  can be bounded as follows.
    
    Next, we relate  and  as follows.
    
    The requirement that  allows us to take the square root of both sides of the inequality since both will be nonnegative.
  \end{proof}
\noindent
  As a consequence, we obtain the following.

  \begin{proposition}\label{pPowerBalls}
    Let  be a metric space and let  be a function.
    Let  and  be two compact subsets of .
    Let  and  be the power distances associated with  and .
    If  is -Lipschitz, then
    
  \end{proposition}
  \begin{proof}
    Let  be any point of .
    There exists  such that .
    There also exists  such that .
    By Lemma~\ref{lPowerBalls} and the triangle inequality, .
    Thus, .
     and  are interchangeable therefore .
\end{proof}

\paragraph{Approximation\\}
To approximate the distance to a probability measure , we introduce the following function.

\begin{definition}\label{dDpd}
  Let  be a probability measure on a metric space  and let  be a mass parameter.
  Given a subset  of , we define  as the power distance associated with .
  
\end{definition}
That is, the weight of each point is its distance to the empirical measure.
If  is close to , we obtain an approximation of .

\begin{theorem}\label{tPbound}
Let  be a probability measure on a metric space  and let  be a mass parameter.
Let  be a subset of .
If  is an -sample of , then

\end{theorem}

A multiplicative approximation implies a multiplicative interleaving of the sublevel sets filtrations that becomes an additive interleaving on a logarithmic scale.
Theorem~\ref{tstability} thus guarantees that the persistence diagrams are close in the bottleneck distance on a logarithmic scale.

\begin{proof}
Let  be a point of . 
Using the previous notations we get

Let us now fix a point .
Since  is a submeasure of  of total mass ,

The third inequality follows from the triangle inequality and the relation .

As the above inequality holds for any point  in  we can conclude that


To show the other inequality, let  be a point of .
Then by definition we get:

By the definition of the distance to a measure, .
Consequently, there exists a point  such that .
Hence,

\end{proof}

\subsection{Measures with finite support}\label{sRestrict}

We now assume that the data are given as a finite set of points  in a metric space .
We define the following measure to study the point set .

\begin{definition}
Given a finite point set  in a metric space , the \emph{empirical measure}  on  is defined as a normalized sum of Dirac measures:

\end{definition}

Let  be a point of . 
We introduce the parameter .
To simplify the exposition we will assume that  is an integer.
See Remark~\ref{rkNotInteger} for the generalization.

We reorder the points of  such that  and 

If two points are at the same distance of , we order them arbitrarily.
We define the set 

and call it the set of  nearest neighbors of .
The set  consists of all -tuples of points of .

\begin{lemma}\label{Ewriting}
Let  be a finite point set in a metric space  then for any :

\end{lemma}

\begin{proof}
Since  has finite support, all its submeasures also have finite support.

Let  be an element of .

Combined with the relation~(\ref{eOrdering}), we get

As , we are done.
\end{proof}

The distance to the empirical measure, , is thus defined as a lower envelope of quadratic functions.
It is generally costly if not impossible to compute its sublevel sets.

However, we can directly use the approximation presented in Section~\ref{sApd}.
Using  in Definition~\ref{dDpd} and Theorem~\ref{tPbound}, we get the following.

\begin{corollary}\label{cPbound}
Let  be a finite point set of a metric space  and  be a mass parameter.
Then,

\end{corollary}

The multiplicative approximation gives a closeness result between persistence diagrams on a logarithmic scale.

\begin{corollary}\label{cLogbound}
Let  be a finite point set of a triangulable metric space  and  be a mass parameter.
Then,

\end{corollary}

\begin{proof}
Corollary~\ref{cPbound} implies that

The sublevel sets of  and  are thus -interleaved and Theorem~\ref{tstability} applies.
\end{proof}

Moreover, these bounds cannot be improve.

\begin{proposition}
The bounds of Corollary~\ref{cPbound} are tight.
\end{proposition}

\begin{proof}
We are looking for a worst case scenario where inequalities become equalities for at least one point.  
We consider the space  with the -norm, denoted .
For any fixed dimension , we build the set of  points whose coordinates have the form . 
These points are marked by triangles in the following drawing in dimension .
\begin{center}
\begin{tikzpicture}
\draw[thin] (-4,0) -- (4,0);
\draw[thin] (0,-2) -- (0,2);
\draw[red,thick] (-1.1,-.1) -- (-.9,-.1) -- (-1,.1) -- (-1.1,-.1);
\draw[red,thick] (1.1,-.1) -- (.9,-.1) -- (1,.1) -- (1.1,-.1);
\draw[red,thick] (-.1,-1.1) -- (.1,-1.1) -- (0,-.9) -- (-.1,-1.1);
\draw[red,thick] (0,1.1) -- (-.1,.9) -- (.1,.9) -- (0,1.1);
\draw[blue,thick] (-3,0) circle (3pt);
\draw[blue,thick] (0,0) circle (3pt);
\draw (-3,.3) node {};
\draw (-1,.3) node {};
\draw (1,.3) node {};
\draw (.3,1.3) node {};
\draw (.3,-.7) node {};
\draw (.3,.3) node {};
\end{tikzpicture}
\end{center}
We fix  and we study  and  at points  and .
First we compute the value of  for any :

Now we compute the value of  at  and :


All the points  have the same value for .
It is easy to compute  at  and 

 When  increases,
the ratio  tends to , while
 tends to .  
Thus, the bounds of Corollary~\ref{cPbound} are reached at the limit for a same data set, although at two different points.
\end{proof}

\begin{remark}\label{rkNotInteger}
If  is not an integer, it suffices to do the same construction with a careful weighting of the point .
The results stay exactly the same after replacing  by .
\end{remark}

\subsection{Euclidean case}\label{ssEc}

We consider the standard Euclidean space  with the -norm.
Considering the finite point set  and its empirical measure in , we are able to express the distance to the empirical measure  as a power distance. 
This restricted settings allows us to improve the bounds of Corollary~\ref{cPbound} as follows.
\begin{theorem}\label{tPboundEuc}
Let  be a finite point set in  and let  be a mass parameter.
Then the following relation is tight.

Moreover, it implies a relation between persistence diagrams:

\end{theorem}

We first present a way to express the distance to a measure as a power distance to the set of all barycenters of -tuples of .
Then we prove Theorem~\ref{tPboundEuc} before comparing it with the previous approximation, called the witnessed -distance proposed in~\cite{wkdGMM}.
We improve the bounds on the witnessed -distance and show that the quality of the approximation is the same for both functions.

\subsubsection{Power distance expression of }
For a fixed integer , the barycenter associated with a point  is the barycenter of its -nearest neighbors.
It is also the center of the cell of the -order Voronoi diagram that contains .

\begin{definition}
For a point set  in  and an integer , the \emph{barycenter associated with } is

\end{definition}

Any subset of  elements from  is uniquely associated with a barycenter. 
We identify the two objects and define a cell energy that describes how clustered the points are.

\begin{definition}
Let  be a point set of  and let .
Given , we fix  and define the cell energy as

\end{definition}

Notice that the set  is not necessarily the set  and that .
We can now write  in the following form.

\begin{lemma}\label{lempiricaldef}
Let  be a finite point set of  let  be a mass parameter.
For any ,

\end{lemma}

\begin{proof}
Fix  and write . 
We adapt Lemma~\ref{Ewriting} to the Euclidean setting to get

This requires the inner product as follows.


Lemma~\ref{Ewriting} guarantees that

and thus,

\end{proof}

In Euclidean space, it is possible to compute the sublevel sets of  exactly.
The function is a power distance and its sublevel sets are unions of balls.
However, the complexity problem pointed out in section~\ref{sRestrict} is still valid. 
The number of balls required to describe a sublevel set is ~\cite{arscgCS}.

\subsubsection{Proof of Theorem~\ref{tPboundEuc}}

\begin{proof}
The first inequality is exactly the same as the one from Theorem~\ref{tPbound}.
For the second inequality, let  be a point in , and let  be a point of .
Thus,


Using Lemma~\ref{lempiricaldef}, we get, 

and with the inner product, this becomes

Note that 

Then we can write the following relation. 


This relation holds for any point of . 
In particular it holds for any of the  nearest neighbors of . 
If we take the average over the  nearest neighbors of  and eliminate the negative term , we obtain


Using the definitions of the cell energy and of the distance to the measure, we can write: 
where .
We conclude that 


The relation between persistence diagrams is follows exactly as in the proof of Corollary~\ref{cLogbound}.

\paragraph{Tightness\\}
The tight example is the point set  of two points  and  on the real line with coordinates  and .
\begin{center}
\begin{tikzpicture}
\draw (-3,0) -- (3,0);
\draw[red,thick] (-1.1,0)--(-.9,0) (-1,.1)--(-1,-.1);
\draw[red,thick] (1.1,0)--(.9,0) (1,.1)--(1,-.1);
\draw[blue,thick] (-.1,0)--(.1,0) (0,.1)--(0,-.1);
\draw (-1,-.4) node {-1};
\draw (0,-.4) node {0};
\draw (1,-.4) node {1};
\draw (-1,.4) node {};
\draw (1,.4) node {};
\draw (0,.4) node {};
\end{tikzpicture}
\end{center}

Fix the mass parameter  equal to  so that . 
It follows that

and


We now compute the last interesting value:

We can thus conclude that .
\end{proof}

\subsubsection{Comparison with witnessed -distance}\label{ssCompWkd}

Another way of approximating  was proposed in~\cite{wkdGMM}.
Taking advantage of the power distance expression of , it reduced the set of barycenters to consider.
Selecting only the barycenter which are associated with the  nearest neighbors of a point of  gives a set of size at most .

\begin{definition}
Let  be a finite point set of  and let  be a mass parameter.
The \emph{witnessed -distance} is defined as

\end{definition}

A bound on the quality of the approximation was given in Lemma 3.3 of~\cite{wkdGMM}.
We improve this bound and prove it to be at least as good as our approximation. 
We are not able to prove the tightness of this bound.
However, we can give a lower bound on the precision.
Using  will not improve the results compared to the witnessed -distance but will not downgrade the quality either.
Moreover it can be used in a more general setting as we do not need the existence of the barycenters.

\begin{theorem}\label{tWbound}
Let  be a finite point set of  and let  be a mass parameter.
Then,

\end{theorem}

The previous version of this theorem used a  instead of the .

\begin{proof}
The first inequality is obtained by noticing that  is a minimum over a smaller set than .
We thus get .

Let  be a point in .
Thus for any ,


Hence using Theorem~\ref{tPboundEuc} we can conclude that:

\end{proof}

\paragraph{Tightness}
The tightness of the lower bound is obvious as it suffices to take  to get an equality between  and .

However, we do not know if the upper bound is tight.
The bound  can not be improved more than to , whose value is greater than .

Let us introduce the following example in . 
We fix  and .
The point cloud  consists of  points located at the coordinates  with multiplicity  when  or  and multiplicity  when  or .

The following figure is its representation in dimension  where the triangles have multiplicity  and the circles have multiplicity .
\begin{center}
\begin{tikzpicture}
\draw (-3,0) -- (3,0) (0,-3) -- (0,3);
\draw[blue,thick] (-2.414,0) circle (3pt);
\draw[red,thick] (-1.1,-.1) -- (-.9,-.1) -- (-1,.1) -- (-1.1,-.1);
\draw[blue,thick] (2.414,0) circle (3pt);
\draw[red,thick] (1.1,-.1) -- (.9,-.1) -- (1,.1) -- (1.1,-.1);
\draw[red,thick] (-.1,-1.1) -- (.1,-1.1) -- (0,-.9) -- (-.1,-1.1);
\draw[blue,thick] (0,-2.414) circle (3pt);
\draw[red,thick] (0,1.1) -- (-.1,.9) -- (.1,.9) -- (0,1.1);
\draw[blue,thick] (0,2.414) circle (3pt);
\draw[green,thick] (0,-.1) -- (0,.1) (-.1,0) -- (.1,0);
\end{tikzpicture}
\end{center}
The points are placed such that the  nearest neighbors of any triangle are itself and the  points located at the nearest circle.
These  nearest neighbors are also the ones from the circles.

Let us now take a look to the value of the functions at the origin .
Each of the  nearest neighbors of  are distance exactly  from .
This allows us to conclude that: 

The construction induced that the structure is perfectly symmetric and the set of barycenters  we consider in the witnessed -distance contains exactly  points.
These points are located at the coordinates  where  or the opposite. 

Let  be a member of .
Thus we can compute its cell energy: 


All of the points of  are located at the same distance to .
Thus, the witnessed -distance at the point  is


Since we can take  as small as we want and make the dimension grow, this relation assures us that we cannot find a better constant than  in Theorem~\ref{tWbound}.



\section{The Weighted Rips Filtration} \label{sWRips}

 Given a weighted set  and the associated power distance  (as in~\eqref{eq:power_distance}), one can introduce a generalization of the Rips filtration that is adapted to the weighted setting as has been done in~\cite{wkdGMM}.
  This construction allows us to approximate the persistence diagram of  in some cases. 
  Moreover, we show that it is stable with respect to perturbation of the underlying sample (Theorem~\ref{tPQsamespace}) and that it gives a guaranteed approximation to the persistence diagram of the distance to an empirical measure (Theorem~\ref{thm:approximating_dPP_with_weighted_rips}). 
Furthermore, it has an interest of its own as it is stable for close weighted sets and can therefore be used as a shape signature.


Let us consider the sublevel set .
It is the union of the balls centered on the points  of  with radius .
By convention, we consider that the ball is empty when the radius is imaginary.
We can define the nerve of this union:

\begin{definition}
Let  be a weighted set in a metric space , then the \emph{weighted \v Cech complex}  for parameter  is defined as the union of simplices  such that .
\end{definition}

  However, the \v Cech complex can be difficult to compute due the problem of testing if a collection of metric balls has a common intersection.
  Instead, we define a weighted version of the Rips complex, which only requires distance computations.

  \begin{definition}
  For a weighted set  in a metric space , the \emph{weighted Rips complex}  for a parameter  is the maximal simplicial complex whose 1-skeleton has an edge for each pair  such that .
  The \emph{weighted Rips filtration} is the sequence  for all .
  \end{definition}

Remark that if all weights are equal to , we are in the classical case of balls with equal radii.
We use the weighted Rips filtration to approximate the weighted \v{C}ech filtration thanks to the following interleaving.
For simplicity, the notation  indicating the point set  with weights  is omitted in the notation.

\begin{proposition}
If  is a weighted set on a metric space , then for all :

\end{proposition}

\begin{proof}
Let  be a real number.
The first inclusion is obtained by the definition of the weighted Rips complex that gives .

For the other inclusion, let  be a simplex of .
We fix  to be the point of  with the greatest weight. 
This implies especially that for any , .

Since , we get that, for all  and  in , we have  with both radius real.
To prove that  we need to prove that:


It will suffice to prove that  belongs to this intersection.
For each :

\end{proof}

\paragraph{Stability\\}
The persistence diagram of a weighted Rips filtration  is stable under small perturbations of the set . 
It can thus be used in applications like signatures in the spirit of~\cite{ghssspCCGMO}.

Speaking of the persistence diagram of a weighted Rips filtration requires that the filtration is q-tame.
This is always the case when the set  is compact as shown in the following proposition.

\begin{proposition}\label{pCompQTame}
Let  be a subset of a metric space  and let  be a function.
If  is compact, then  is q-tame.
\end{proposition}
This will be deduced from the following technical lemma.

\begin{lemma}\label{lHausInter}
Let ,  be two subsets of a metric space  and let  be a -Lipschitz function.
Then  and  are -interleaved for .
\end{lemma}

\begin{proof}
We need to show that the there exists -homomorphisms  and  such that  and .

To do so, we need three steps.
First, we build simplicial maps  and  for every .
Then, we show that these simplicial maps induce -homomorphisms.
Finally, we show that the simplicial maps are contiguous and thus the two persistence modules are -interleaved.



The simplicial maps  and  for  are induced by the canonical inclusion. 
We consider two maps  and  such that  and  for any  and .
By definition of the Hausdorff distances, such maps always exist.
Let us show that these maps induce simplicial maps.

Let us consider the function  and let us fix .
Let  be an edge of . 
It means that .
Lemma~\ref{lPowerBalls} implies that  for any .
Thus,  is an edge of  because:


As  is a clique complex for any , this is sufficient to prove that  induce a family of simplicial maps .
The roles of  and  are symmetric.
Therefore, the result holds for  as well.





Furthermore  induces an -homomorphism  at the homology level. 
For any , = because the maps  and  are induced by the the canonical inclusion while the two others simplicial maps are induced by the same map .
Hence the two compositions are contiguous and thus guarantees that  is an -homomorphism. 
Again, this results can be applied to  to get an -homomorphism .

To prove that , we prove that  and  are contiguous for any .

Let us fix  and let  be an edge of .
By definition, .
Moreover, using Lemma~\ref{lPowerBalls} we get:

The same holds for  and thus:

Thus the tetrahedron  is in .
Lemma~\ref{lem:contiguity_and_cliques} guarantees that  and  are contiguous.

From before,  induces the -homomorphism .
By definition,  induces .
By contiguity of the simplicial maps, we have equality of the -homomorphisms and therefore .

By symmetry of the roles of  and ,  and  are -interleaved.
\end{proof}

\begin{proof}[Proof of Proposition~\ref{pCompQTame}]
We will show that, for any , one can build a finite persistence module which is -interleaved with the persistence module of .
A finite persistence module is a fortiori locally finite and Theorem 4.19 of~\cite{sspmCDGO} induces the q-tameness of .

Let us fix .
 is compact.
As a consequence, there exists a finite point set  of  such that .
The persistence module of  is finite and therefore locally finite.
Moreover, using Lemma~\ref{lHausInter},  and  are -interleaved.
Hence  is q-tame using Theorem 4.19 of~\cite{sspmCDGO} induces the q-tameness of .
\end{proof}

Notice that the simplicial maps  and  are not necessarily uniquely defined.
However, if  and  are two maps verifying the construction property, then the induced simplicial maps are contiguous and therefore the induced homomorphisms are identical.

The persistence diagrams of weighted Rips filtrations are related by the following:

\begin{theorem}\label{tPQsamespace}
Let  and  be two compact subsets of a metric space .
Let  be a -Lipschitz function.
Then,

\end{theorem}

\begin{proof}
 and  are two compact sets and thus the diagrams are well-defined thanks to Proposition~\ref{pCompQTame} that guarantees the q-tameness of the filtrations. 
Lemma~\ref{lHausInter} implies that  and  are -interleaved.
The relation between the persistence diagrams is then obtained by applying Theorem~\ref{tModStability}.
\end{proof}

\begin{remark}
When  and  are two compact metric spaces, Theorem~\ref{tPQsamespace} can be extended using the notion of correspondence as in~\cite{psgcCDO}.
Notice that the correspondence has to induce bounded distortion on the weights as well as on the distances.
\end{remark}

\paragraph{Approximation\\}
To use the weighted Rips filtration to approximate the persistence diagram of the distance to a measure, we need to restrict the class of spaces considered.
If the intersection of any finite number of balls in  is either contractible or empty,  is said to have the \emph{good cover property}.
Then the \v{C}ech complex has the same homology as the union of balls, of which it is the nerve, by the Nerve Theorem~\cite{atH}.
We can also compute the persistence diagram thanks to the Persistent Nerve Lemma~\cite{tpbresCO}.
We obtain an approximation of  using the weighted Rips filtration.

\begin{theorem}\label{thm:approximating_dPP_with_weighted_rips}
Let  be a triangulable metric space with the good cover property and let  be a finite point set of , then on a logarithmic scale:

\end{theorem}

\begin{proof}
Given that  is triangulable, we know that the sublevel sets filtration of  is -tame by Proposition~\ref{pQtame}.
The persistence diagram  is thus well-defined.
Recall that  is a -Lipschitz function (see Proposition~\ref{pLipschitz}).
 is a compact subset of  and therefore  is well-defined according to Proposition~\ref{pCompQTame}.

We approximate  with . 
The result of Theorem~\ref{tPbound} gives us a  multiplicative interleaving.
For any ,

So, Theorem~\ref{tstability} implies


By the Persistent Nerve Lemma, the sublevel sets filtration of  (a union of balls of increasing radii) has the same persistent homology as nerve filtration.
Thus, we can use weighted Rips filtration to approximate the persistence diagram:


The triangle inequality for the bottleneck distance gives the desired inequality.
\end{proof}







\section{The Sparse Weighted Rips filtration} \label{sec:sparse_rips}

The weighted Rips filtration presented in the previous section has the desired approximation guarantees, but like the Rips filtration for unweighted points, it usually grows too large to be computed in full.
In~\cite{lsavrfS}, it was shown how to construct a filtration  called the \emph{sparse Rips filtration} that gives a provably good approximation to the Rips filtration and has size linear in the number of points for metrics with constant doubling dimension (see Section~\ref{sec:sparse_rips_revisited} for the construction).
Specifically, for a user-defined parameter , the log-bottleneck distance between the persistence diagrams of the Sparse Rips filtration and the Rips filtration is at most .
The goal of this section is to extend that result to weighted Rips filtrations.

The sparse Rips filtration cannot be used directly here, since the power distance does not induce a metric.
Indeed, even the case of setting all weights to some large constant yields a persistence diagram that is far from the persistence diagram of the Rips filtration of any metric space.
This follows because individual points in a Rips filtration appear at time zero, but this is not the case in the weighted Rips filtration.

Even if one were to construct a metric whose Rips filtration exactly matched that of the weighted Rips filtration, there are simple examples where that metric would necessarily have very high doubling dimension, making previous methods unsuitable.
For example, consider a set of points in the unit interval , with a constant weight function that assigns a weight of  to every point.
Although the points lie in a -dimensional space, the weighted distance function has doubling dimension  because all of the points are within a weighted distance of , whereas every pair has weighted distance at least .
So the doubling constant would be  and the doubling dimension would be  despite that the input was -dimensional.
Thus, any construction that depends on low doubling dimension will blowup when confronted with such weighted examples.





For the rest of this section, we fix a weighted point set  in a metric space , where the weight function  is -Lipschitz, for some constant .
To simplify notation, we let  denote the weighted Rips complex .


The \emph{sparse weighted Rips filtration}, , is defined as

The (unweighted) sparse Rips filtration  captures the underlying metric space and the weighted Rips filtration  captures the structure of the sublevel sets of the power distance function.
Computing  can be done efficiently by first computing  and then reordering the simplices according to the birth time in .
This is equivalent to filtering the complex .
Note that the sparsification depends only on the metric, and not on the weights.
Thus, the same sparse Rips complex can be used as the underlying complex for different weight functions.
We also simplify the construction of  by using a furthest point sampling instead of the more complex structure of net tree.





The technical challenge is to relate the persistence diagram of this new filtration to the persistence diagram of the weighted Rips filtration as in the following theorem.

\begin{theorem}\label{thm:sparse_weighted_rips}
  Let , be a finite, weighted subset of a metric space  with -Lipschitz weights.
  Let  be a fixed constant used in the construction of the sparse weighted Rips filtration .
  Then,
  
\end{theorem}

Since these filtrations are not interleaved, the only hope is to find an interleaving of the persistence modules, which requires finding suitable homomorphisms between the homology groups of the different filtrations.
After detailing the construction of the sparse Rips filtration with the furthest point sampling, the rest of this section proves Theorem~\ref{thm:sparse_weighted_rips}.
\subsection{Sparse Rips complexes}\label{sec:sparse_rips_revisited}

Let  be a greedy permutation of the points  in a finite metric space .
That is, , where  is the  prefix.
  We define the \emph{insertion radius}  of point  to be
  
  
To avoid excessive superscripts, we write  in place of  when we know the index of .
We adopt the convention that  and .
The greedy permutation has the nice property that each prefix  is a \emph{-net} in the sense that 
  \begin{enumerate}
    \item      for all .
    \item       for all .
  \end{enumerate}
  We extend these nets to an arbitrary parameter  as
  
  Note that for all ,  and .
  
One way to get a sparse Rips-like filtration is to take a union of Rips complexes on the nets .
However, this can add significant noise to the persistence diagram compared to the Rips filtrations.
This noise can be diminished by a careful perturbation of the distance.
For a point , the perturbation varies with the scale and is defined as follows:
  
  
\begin{center}
\begin{tikzpicture}[scale=.5]
\draw (0,0) -- (10,0);
\draw (0,0) -- (0,6);
\draw[red,thick] (0,0) -- (3,0) -- (6,3) -- (10,5);
\draw[red,dashed] (0,0) -- (6,3);
\node[below] at (0,0) {};
\node[left] at (0,0) {};
\node[below] at (3,0) {};
\node[below] at (6,0) {};
\node[above] at (9.5,5) {};
\end{tikzpicture}
\end{center}
  
  Note that  is -Lipschitz.
  The resulting perturbed distance is defined as
  
  
  For any fixed  and , the Lipschitz property of  and  implies that for all :
  

\begin{definition}
Given the nets  and the distance function , we define the \emph{sparse Rips complex} at scale  as
  
  \end{definition}
  
  On its own, the sequence of complexes  does not form a filtration.
  However, we can build a natural filtration by defining 
  
\begin{definition}
The \emph{sparse Rips filtration} is defined as:
  
\end{definition}

\subsection{Projection onto Nets} \label{sub:projection_onto_nets}
To relate sparse Rips complexes with Rips complexes, we build a collection of projections of the points onto the nets.
  
  For any scale , the projection  maps the points of  to the net .
  Note that  is a retraction onto .
  
  The following are the four main lemmas we will use with respect to the perturbed distance functions and projections.
  The projections will be used extensively to induce maps between simplicial complexes.
  
First, we prove that edges do not disappear as the filtration grows.  
  \begin{lemma}\label{lem:filtration}
    If  then .
  \end{lemma}
  \begin{proof}
    The proof follows from the definitions  and , the Lipschitz property of the perturbations  and , and the hypothesis as follows.
    
  \end{proof}
 
Next, we show that the distance between a point and its projection is at most the change in the perturbed distance.
  \begin{lemma}\label{lem:distance_to_proj} 
    For all , , and in particular, .
  \end{lemma}
  \begin{proof}
    Both statements are trivial if , because that would imply that .
    So, we may assume that  is the nearest point to  in 
    It follows that 

Moreover, , and thus .    
    Also, since , it must be that  and so .
    Combining these statements, we get
    
  \end{proof}

Now, we prove that replacing a point with its projection does not increase the perturbed distance.
  \begin{lemma}\label{lem:distances_dont_grow}
    For all  and all , .\qedhere
  \end{lemma}
  \begin{proof}
    The statement follows from the definition of , the triangle inequality, and Lemma~\ref{lem:distance_to_proj} as follows.
    
  \end{proof}

We want to use the sparse Rips filtration in the weighted setting. 
Recall that for a weighted point , .

We consider the effect on the ``edge lengths'' when projecting the endpoints of an edge to nearby points.
This is the situation when we project the metric onto an -net. 
The following lemma guarantees that a ball centered at the image of the projection quickly covers the ball centerd at the original point.
It is a similar approach to the Proposition~\ref{pPowerBalls}.
  
\begin{center}
\begin{tikzpicture}
\draw[fill] (0,0) circle (1pt);
\draw[fill] (.5,0) circle (1pt);
\node[below] at (0,0) {};
\draw (.5,-.5) node {};

\draw (0,0) circle (55pt);
\draw[dashed] (0,0) circle (70pt);
\draw[red] (.5,0) circle (85pt);
\draw[->] (0,0) -- node[left] {} (.2,1.9) ;
\draw[->,dashed] (.2,1.9) -- node[right] {} (.25,2.4);
\draw[->,dashed] (0,0) -- node[above] {} (.5,0);
\draw[->,red] (.5,0) -- node[above] {} (3.5,.3);
\end{tikzpicture}
\end{center}






\subsection{Sometimes the projections induce contiguous simplicial maps} \label{sub:sometimes_the_projections_induce_contiguous_simplicial_maps}

  In this section, we look at the maps between simplicial complexes that are induced by the projection functions .
  We are most interested in the case when a pair of projections  and  induce contiguous simplicial maps between sparse Rips complexes (Lemma~\ref{lem:proj_and_Q}) or weighted Rips complexes (Lemma~\ref{lem:proj_and_R}).
  First, we need a couple lemmas that describe the effect of different projections on the endpoints of an edge in sparse or weighted Rips complexes.

  \begin{lemma}\label{lem:proj_and_Q_for_one_edge}
    Let , , , and  be such that .
    If an edge  is in  for some  then the edge .
  \end{lemma}
  \begin{proof}
    First, it is easy to check that the conditions on , , , and  imply that  and  are in , which is the vertex set of .
    So, it will suffice to prove that .
    Next we consider three cases depending on the value of  in relation to  and .
  
    \noindent\textbf{Case 1:} If  then  and .
    So, using Lemma~\ref{lem:filtration} and the assumption , we see that .
  
    \noindent\textbf{Case 2:} If  then  and Lemma~\ref{lem:filtration} implies that .
    
  
    \noindent\textbf{Case 3:} If  then Lemma~\ref{lem:filtration} implies that .
    
  \end{proof}



  \begin{lemma}\label{lem:proj_and_R_for_one_edge}
Let  be an edge of  with , then , where .
  \end{lemma}
  \begin{proof}
    First, note that the projection functions satisfy the following inequalities.
    
    So, by applying the triangle inequality, the definition of an edge in , and Lemma~\ref{lPowerBalls}, we get the following.
    
    This is precisely the condition necessary to guarantee that  as desired.
  \end{proof}

  The following two lemmas follow easily from repeated application of the preceding lemmas.

  \begin{lemma}\label{lem:proj_and_Q}
    Two projections  and  induce contiguous simplicial maps from  whenever  and there exists  so that .
  \end{lemma}
  
\begin{proof}
Let us fix  and take  an edge from . 
Given that  and  are cliques complexes, we can get the result from Lemma~\ref{lem:contiguity_and_cliques} if we show that the tetrahedron  is in .
We only need to prove that all edges of the tetrahedron belongs to .

We apply Lemma~\ref{lem:proj_and_Q_for_one_edge}, while replacing  by  and  by . Thus we obtain .
Let us repeat this operation with  thus we get .
The last two edges are given by replacing  by  and choosing correctly the role of  and .
\end{proof}

  \begin{lemma}\label{lem:proj_and_R}
    Two projections  and  induce contiguous simplicial maps from , where  whenever .    
  \end{lemma}
  
\begin{proof}
The previous proof can be applied to get the result, while replacing Lemma~\ref{lem:proj_and_Q_for_one_edge} by Lemma~\ref{lem:proj_and_R_for_one_edge}.
\end{proof}



%
 
\subsection{Sparse filtrations and power distance functions} \label{sec:rips_interleaving}


We define a sparse filtration that gives a good approximation to the weighted Rips filtration  in terms of persistent homology.
  It is simply the intersection of the weighted Rips complex and the union of sparse Rips complexes at different scales.
  

  Our main goal is to show that the filtration  has a persistence diagram that is similar to that of .
  To do this we will demonstrate a multiplicative interleaving between these filtrations, where the interleaving constant is 
  
  Specifically, we show that for all , the following diagram commutes at the homology level. 
  
  

  We first need to check that the projection  indeed induces a simplicial map from  to .

  \begin{lemma}\label{lem:proj_is_simplicial_R_to_T}
    For all , the projection  induces a simplicial map from , where .
  \end{lemma}
  \begin{proof}
    We show that for each edge , there is a corresponding edge .
    Since the latter complex is a clique complex, this will imply that for all , we have  as desired.
    First,  as a direct consequence of Lemma~\ref{lem:proj_and_R}.

    Next, we need to show that .
    It suffices to show that .
    
  \end{proof}
  
  Now, we give conditions for when two projections induce contiguous simplicial maps between the sparse weighted Rips complexes  and .

  \begin{lemma}\label{lem:proj_and_T}
    Two projections  and  induce contiguous simplicial maps from , where  whenever  and there exists  so that .
  \end{lemma}
  \begin{proof}
    We simply observe that for any ,  for some .
    If  then Lemma~\ref{lem:proj_and_Q} implies .
    Otherwise .
    So in either case, we have .
    Now, by Lemma~\ref{lem:proj_and_R}, we have that .
    So, we have that  as desired.
  \end{proof}

  We can now give the proof of the interleaving which will imply the desired approximation of the persistent homology.

  \begin{lemma}\label{lem:interleaving}
    For all , the following diagram commutes the homology level.
    
  \end{lemma}
  \begin{proof}
    By Lemma~\ref{lem:proj_and_R}, the projection  and the inclusion  are contiguous and thus produce identical homomorphisms at the homology level.
    For the lower triangle it will suffice to show that homomorphism induced by  commutes with that produced by the inclusion .
    Let  for .
    Now, Lemma~\ref{lem:proj_and_T} implies that  and  are contiguous.
    So, choosing  such that , we can apply Lemma~\ref{lem:proj_and_T} repeatedly to conclude that
    
  \end{proof}

%
 

\section{Numerical illustration} \label{sNumeric}


In this section, we illustrate our results three different perspectives:
the quality of the approximation,
the stability of the diagrams with respect to noise, and
the size of the filtration after sparsification.

We used the ANN library~\cite{annMS} for the -nearest neighbors search and code from Zomorodian following~\cite{cphCZ} for the persistence.
The topology of the union of balls is acquired through the -shapes implementation from the CGAL library~\cite{cgalAlphaShapes3D}.

\paragraph{Datasets\\}
For the first two parts, we consider the set of points in  obtained by sampling regularly the skeleton of the unit cube with 116 points.
Then we add four noise points in the center of four of its faces such that two opposite faces are empty.

\begin{figure}[!ht]
\centering
\includegraphics[height=10em]{pictures/smallskeleton}
\caption{Skeleton of a cube with outliers}
\end{figure}

We would like to compute the persistence diagram of the skeleton of the cube. 
We write this diagram .
It contains five homology classes in dimension 1 and one in dimension 2, and it has the barcode representation given in Figure~\ref{fDgmSkel}.

\begin{figure}[!ht]
\centering
\includegraphics[height=10em]{pictures/smSkelNoNoise.pdf}
\caption{Persistence diagram of a cube skeleton without noise}\label{fDgmSkel}
\end{figure}

For sparsification, we use a slightly bigger dataset composed of 10000 points regularly distributed on a curve rolled around a torus.
The point set is shown on Figure~\ref{fSpiral}.

\begin{figure}[!ht]
\centering
\includegraphics[height=10em]{pictures/spiral}
\caption{Spiral on a torus}\label{fSpiral}
\end{figure}

\paragraph{Approximation}

We work from now on with a mass parameter  such that . 
The persistence diagram of  is given in Figure~\ref{fPersDmP}:

\begin{figure}[!ht]
\centering
\includegraphics[height=10em]{pictures/smSkelDistToMeaK5.pdf}
\caption{ for the cube skeleton with outliers with }\label{fPersDmP}
\end{figure}

The diagrams obtained with our various approximations have very similar looks.
We only show the one obtained with the sparse Rips filtration with a parameter  in Figure~\ref{fPersSpars}.

\begin{figure}[!ht]
\centering
\includegraphics[height=10em]{pictures/smSkelSparseK5E5.pdf}
\caption{ for the cube skeleton with outliers with  and }\label{fPersSpars}
\end{figure}

To compare diagrams, we use the bottleneck distances between the diagrams.
Figure~\ref{fMatrix} shows the distance matrix between the various diagrams, while Figure~\ref{fBottle} shows some bottleneck distances between persistence diagrams of different dimensions.
Note that  corresponds to the diagram obtained by using the distance function to the point cloud.

\begin{figure}[!ht]
\centering
\begin{tabular}{|c|cccccc|}
\hline
&  &  &  &  &  &  \\
\hline
 & 0 & .1528 & .1473 & .1473 & .1817 & .25 \\
 & .1528 & 0 & .09872 & .0865 & .1183 & .2543 \\
 & .1473 & .09872 & 0 & .0459 & .1084 & .2642 \\ 
 & .1473 & .0865 & .0459 & 0 & .1128 & .2598 \\
 & .1817 & .1183 & .1084 & .1128 & 0 & .2484 \\
 & .25 & .2543 & .2642 & .2598 & .2484 & 0 \\
\hline
\end{tabular}
\caption{Matrix of distances for the bottleneck distance}\label{fMatrix}
\end{figure}


\begin{figure}[!ht]
\centering
\begin{tabular}{|c|c|c|c|c|}
\hline
 &  & dim  & dim  & dim  \\
\hline
 &  & .05202 & .1528 & .1495\\
 &  & .09872 & .0195 &  .0972\\
 &  & .0007 & .0044 & .0459 \\
 &  & .0872 & .1128 & .0026 \\
\hline
 &  & .0405 & .1473 & .0982 \\
 &  & .1026 & .1817 & .098 \\
 &  & .25 & .2071 & .1481 \\
\hline
\end{tabular}
\caption{Bottleneck distances between diagrams}\label{fBottle}
\end{figure}

The largest difference is between  and .
This is partly due to an effect of shifting while using the distance to a measure.
After this initial shift, the distance are small compared to the theoretical bounds. 
Notice that the different steps of the approximation do not have the same effect on all dimensions.

\begin{figure}[!ht]
\centering
\includegraphics[height=10em]{pictures/smSkelNoisy.pdf}
\caption{ for the cube skeleton with outliers}\label{fDiagDP}
\end{figure}

All diagrams obtained by the different approximations are closer to  than the persistence diagram of the distance to the point cloud,  given in Figure~\ref{fDiagDP}.
For inference purposes, one crucial parameter is the \emph{signal-to-noise ratio}.
We define it as the ratio between the smallest lifespan of topological feature we aim to infer and the longest lifespan of noise features.
A ratio of  corresponds to a signal that is not differentiable from the noise and  corresponds to a noiseless diagram.
In our example, only the dimensions  and  are relevant as the dimension  diagram corresponding to connected components has only one relevant feature and its lifespan is infinite.
Results are listed in Figure~\ref{fRatio}.

\begin{figure}[!ht]
\centering
\begin{tabular}{|c|c|c|}
\hline
Diagram & dim  & dim  \\
\hline
 &  &  \\
 &  &   \\
 &  &  \\
 &  &  \\
 &  &  \\
 &  &  \\
\hline
\end{tabular}
\caption{Signal to noise ratios}\label{fRatio}
\end{figure}

Signal-to-noise ratios are clearly better than the one of .
Some of the approximation steps improve the ratio.
This is due to two phenomena.

When one goes from  to , the filtration eliminates the cells of the  order Voronoi diagram that are far from the point cloud.
These cells induce local minima that produce noise features in the diagrams.
Removing them cleans parts of the diagram.
The same phenomenon happens with the witnessed -distance perviously mentioned.

Using the Rips filtration instead of the \v{C}ech also reduces some noise.
It eliminates artifacts from simplices that are introduced and almost immediately killed in the \v{C}ech complex due to balls that intersect pairwise but have no common intersection.

\paragraph{Stability\\}

The weighted Rips filtration is stable with respect to noise. 
We illustrate this by studying the effect of an isotropic noise on our skeleton of a cube. 
We consider three different standard deviations for our noise.
Figure~\ref{fGauss} shows the bottleneck distances between the persistence diagram of the sparse weighted Rips structure with the Gaussian noise and the one without Gaussian noise.

\begin{figure}[!ht]
\centering
\begin{tabular}{|c|c|c|c|}
\hline
Standard deviation &  &  &  \\
\hline
 in dimension  &  &  &  \\
 in dimension  &  &  &  \\
\hline
\end{tabular}
\caption{ between  with and without Gaussian noise}\label{fGauss}
\end{figure}

Unsurprisingly, the bottleneck distance is increasing with standard deviation of the noise.
The signal-to-noise ratio shown in Figure~\ref{fGaussRatio} is more interesting.

\begin{figure}[!ht]
\centering
\begin{tabular}{|c|c|c|c|c|}
\hline
Standard deviation & 0 & .05 & .1 & .5 \\
\hline
Ratio in dimension 1 & 132 & 8.27 & 3.17 & 1.04 \\
Ratio in dimension 2 &  &  & 100.2 &  \\
\hline
\end{tabular}
\caption{Signal to noise ratio of  depending on noise intensity}\label{fGaussRatio}
\end{figure}

Inferring correctly the homology of the cube skeleton is possible with standard deviation  and .
Figure~\ref{fPersGaus.1} shows the persistence diagram obtained with a standard deviation of .
The  in the  case in dimension  is not relevant as there is no noise but the feature is too small compared to the rest of the diagram as shown in Figure~\ref{fPersGaus.5}.
Note that  corresponds to half of the side of the cube, and thus, it is logical to be unable to retrieve any useful information.

\begin{figure}[!ht]
\centering
\includegraphics[height=10em]{pictures/diagG_1k5e5.pdf}
\caption{Persistence diagram of  with ,  and a Gaussian noise with standard deviation }\label{fPersGaus.1}
\end{figure}

\begin{figure}[!ht]
\centering
\includegraphics[height=10em]{pictures/diagG_5k5e5.pdf}
\caption{Persistence diagram of  with ,  and a Gaussian noise with standard deviation }\label{fPersGaus.5}
\end{figure}

Some structure appears even with standard deviation as large as . 
The three bigger features in dimension  are relevant. 
However, we miss two elements and it is difficult to decide where to draw the frontier between relevant and irrelevant features.

\paragraph{Sparsification efficiency\\}
We introduced sparsification in Section~\ref{sec:rips_interleaving} to reduce the size of the Rips filtration.
The method introduced a new parameter , and  the size of the filtration depends heavily on .
The evolution of the size of the filtration depending on the parameter  is given in Figure~\ref{fStatsSpiral}.

\begin{figure}[!ht]
\centering
\includegraphics[height=15em]{pictures/stats_spiral}
\caption{Size of the filtration depending on  for the spiral}\label{fStatsSpiral}
\end{figure}

The minimum size is reached around .
This minimum depends on the structure of the dataset.
For example, considering a set of points uniformly sampled in a square, we obtain decreasing size of the filtration.

The filtration size is nearly constant after a rapid decrease. 
In this example, the size is of order  simplices for an input of  vertices.
Computing persistent homology is tractable for any value in this range.
Structure in the data helps reduce the complexity of the sparse filtration.



\section{Conclusion} \label{sec:conclusion}

  In this paper, we generalize several aspects of the existing theory on the persistent homology of distances to measures from Euclidean space to general metric spaces.
  Then, we showed how to efficiently approximate the sublevels these distance functions with a linear number of metric balls.
  We gave a detailed analysis of the tightness of this approximation.
  
  We then showed how to give a sparse filtration that gives a guaranteed close approximation to the persistent homology of the distance to the measure.
  This last construction was given in the more general context of power distances.
  Thus, we have given a way to efficiently compute the persistent homology of the sublevel set filtration of any power distance function built on points in metric space of low doubling dimension.
  Since power distances can be used to approximate many different kinds of functions, we expect this technique will find many more uses in the future.
  
  A different perspective on our approach is that we use the sparse Rips filtration analogously to how one might use a grid in Euclidean space.
  It provides a structure over which one can go on to study many different functions.
  
  Lastly, we showed that this approach can be made practical, by providing some experimental results and analysis.



\bibliographystyle{plain}
\bibliography{sparserips}

\end{document}
