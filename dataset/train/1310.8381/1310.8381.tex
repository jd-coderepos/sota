\documentclass[11pt]{article}
\usepackage[reqno,tbtags]{amsmath}
\usepackage{fullpage}
\usepackage{amsthm}
\usepackage{amsfonts}
\usepackage{enumerate}
\newcommand{\remm}[1]{*** #1 ***}  \newenvironment{remmm}{\ifhmode\newline\fi ***}{*** \newline}
\newenvironment{ident}{\begin{list}{}{} \item[]}{\end{list}}
\DeclareMathOperator{\Int}{Int} \DeclareMathOperator{\E}{E}
\DeclareMathOperator{\App}{App} \DeclareMathOperator{\Pro}{Pr}
\DeclareMathOperator{\Op}{Op}
\DeclareMathOperator{\Symb}{Symb}
\newcommand{\raw}{\rightarrow}
\newcommand{\tfr}{\tfrac1}
\newcommand{\lp}{\left(}
\newcommand{\rp}{\right)}
\newcommand{\lb}{\left[}
\newcommand{\rb}{\right]}
\newcommand{\lB}{\left\{}
\newcommand{\rB}{\right\}}
\newcommand{\la}{\left|}
\newcommand{\ra}{\right|}
\newcommand{\lA}{\left\|}
\newcommand{\rA}{\right\|}
\newcommand{\li}{\left\langle}
\newcommand{\ri}{\right\rangle}
\newcommand{\argmin}{\mathrm{argmin}}
\newcommand{\argmax}{\mathrm{argmax}}
\newcommand{\bGamma}{\boldsymbol{\Gamma}}
\newcommand{\su}{\mbox{\rm succ}}
\newcommand{\PP}{\mathbb{P}}
\newcommand{\RR}{\mathbb{R}}
\newcommand{\CC}{\mathbb{C}}
\newcommand{\ZZ}{\mathbb{Z}}
\newcommand{\NN}{\mathbb{N}}
\newcommand{\eps}{\varepsilon}
\newcommand{\grad}{\nabla}
\newcommand{\laplacian}{\Delta}
\newcommand{\LCP}{\mathrm{LCP}}
\newcommand{\eqdef}{\mathrel{:=}}
\theoremstyle{plain}
\newtheorem{thm}{Theorem}[section]
\newtheorem{cor}[thm]{Corollary}
\newtheorem{lem}[thm]{Lemma}
\newtheorem{prop}[thm]{Property}
\theoremstyle{definition}
\newtheorem{defin}[thm]{Definition}
\theoremstyle{remark}
\newtheorem{remark}[thm]{Remark}
\newtheorem{rems}[thm]{Remarks}
\newtheorem{conjs}[thm]{Conjecture}

\usepackage{epsfig}
 \usepackage{ifpdf}
 \ifpdf\setlength{\pdfpagewidth}{8.5in}\setlength{\pdfpageheight}{11in}\fi
\numberwithin{equation}{section}
\renewcommand{\today}{\relax}



 \DeclareMathOperator{\glex}{\prec}
 \DeclareMathOperator{\geqlex}{\preceq}
 \DeclareMathOperator{\llex}{\succ}
 \DeclareMathOperator{\leqlex}{\succeq}



\let\olditemize=\itemize
\def\itemize{
\olditemize
\setlength{\itemsep}{-1ex}
}
\let\oldenumerate=\enumerate
\def\enumerate{
\oldenumerate
\setlength{\itemsep}{-1ex}
}

\newcommand{\ignore}[1]{}

\begin{document}
\title{A Labeling Approach to Incremental Cycle Detection}

\author{Edith Cohen\thanks{Microsoft Research -- SVC, USA. {\tt
      edith@cohenwang.com}}   \and Amos Fiat\thanks{Tel Aviv
    University, Tel Aviv, Israel. {\tt  \{fiat,haimk\}@cs.tau.ac.il}}
\and Haim Kaplan \and Liam
Roditty\thanks{Bar Ilan University, Ramat Gan, Israel. {\tt liam.roditty@biu.ac.il}}}

\maketitle

\begin{abstract}
In the \emph{incremental cycle detection} problem arcs are added to
a directed acyclic graph and the algorithm has to report if the new
arc closes a cycle. One seeks to minimize the total time to process
the entire sequence of arc insertions, or until a cycle appears.

In a recent breakthrough, Bender, Fineman, Gilbert and
Tarjan~\cite{BeFiGiTa11} presented two different algorithms, with
time complexity   and , respectively.

In this paper we introduce a new technique for incremental cycle
detection that allows us to obtain both bounds (up to a logarithmic
factor). Furthermore, our approach seems more amiable for
distributed implementation.
\end{abstract}\textbf{}

\thispagestyle{empty}

\newpage
\setcounter{page}{1}


\section{Introduction}


Let  be a directed acyclic graph (DAG). In the
\emph{incremental cycle detection} problem edges are being added to
 and the algorithm has to report on a cycle once a cycle is
formed.

This problem has a very extensive history
\cite{AlpernHRSZ90,Marchetti-SpaccamelaNR96,PearceK06,KatrielB06,LiuC07,AjwaniFM08,AjwaniF10,DBLP:journals/corr/abs-0711-0251,HKMST:Talg12,BFG:SODA09}.
For a thorough discussion of this work see~\cite{HKMST:Talg12}.  In
a recent breakthrough, Bender, Fineman, Gilbert and
Tarjan~\cite{BeFiGiTa11} presented an algorithm with 
total running time. They also presented a different algorithm with a
running time of .

In this paper we present a new and completely different technique
that allows us to obtain all the results of Bender et al. (up to
poly-logarithmic factors and randomization). Although we are not
getting any improved running times our technique is interesting from
several perspectives. We believe that our approach unifies all
previous algorithms into one algorithmic framework. Furthermore, our
algorithm seems (to us) much simpler than previous proposals.
Finally, because of highly local nature, it seems that it is trivial
to implement our incremental cycle detection algorithm in a
distributed environment, within certain caveats.

Roughly speaking, our framework works in the following way. As long
as a cycle is not formed we maintain a certain label  for
each vertex  so that the labels constitute  a {\em weak
topological order}: That is, for every arc , . These labels are useful to rule out the existence of paths
from a vertex  to a vertex  if .

The development of our new labeling technique is inspired by the
work of Cohen~\cite{Cohen:1997} on estimating the size of the
transitive closure of a directed graph. More specifically,
Cohen~\cite{Cohen:1997} showed that if the vertices of an  vertex
digraph  get random ranks from the range  then the
minimum rank vertex that can reach to every vertex  can be
computed in  time for every . We can view the rank of
the minimal rank vertex that reaches  as the label of .
This label is a good estimate of the number of vertices that reach
 . A label of small value indicates that the reachability set
is probably large.

In this paper we give a recursive version of the labels described
above. Let . Given an  vertex DAG, assign a random
permutation of the ranks  to a randomly selected set of
 vertices. Other vertices are {\sl unranked}. The label of a
vertex  is defined to be a sequence of vertices, the first of
which, , is the vertex of minimal rank amongst all ranked
vertices that can reach .  The second vertex in the label of 
is the vertex of minimal rank amongst all ranked vertices , such that  is reachable from  and  is
reachable from . Subsequent vertices in the label of  are
defined analogously. Notice that the first coordinate of each label
in our extended definition is the label from~\cite{Cohen:1997}.

Such random recursive labels have several properties of possible
interest:
\begin{enumerate}
  \item The expected length of such labels is logarithmic.
\item For every vertex , consider the sequence of ranks associated with the vertices in the label of , with  appended at the end. Such sequences are lexicographically descending along any path through a DAG. Thus, in certain cases comparison of two labels can rule out the existence of a path.
\item For any vertex , the set of vertices  such that  and  have the same label and  is reachable from  is ``small". With high probability this set is .
\end{enumerate}

As in several previous papers, we do both forward and backwards
searches to determine if a cycle has been formed. One difference
between previous approaches and ours is that local criteria allow us
to prune both forward and backward searches. The labels contain
sufficient information so as to make this pruning efficient.
Moreover, the labels can be maintained over the sequence of insertions within the same
time bounds.



Using the labels, setting appropriate parameters, and some simple
data structures, we get a family of possible algorithms, which
unifies the results of several previous papers:

\begin{itemize}
\item For graphs with , choosing  gives us an algorithm with total time .
For denser graphs, we draw a random rank for each arc with
probability  and set the rank of the vertex to be the
rank of its minimum incoming arc. This gives the analogous bound of
.

\item Choosing  balances the forward and backward search times to be .
\item Choosing  requires no backward search, as vertices have
  unique labels, and the total time for forward searches and label updates is .

\end{itemize}

All of these variants can be implemented using message passing
algorithms, if one allows bidirectional communications and one
assumes perfect synchrony. With respect to distributed
implementation, it is often important to minimize the number of
messages.
 We remark that for each of these
variants, one can optimize  so as to minimize the number of
messages.






\smallskip
\noindent {\bf Related work:}

A directed graph is acyclic if and only if it has a topological
order; a more recent generalization is that the strong components of
a directed graph can be ordered topologically
\cite{harary1965structural}. We can find a cycle in a directed graph
or a topological order in linear time either by repeatedly deleting
 vertices with no
predecessors \cite{KnuthS74} or by performing a depth-first search
\cite{Tarjan72dfs}. Depth-first search can also be used to find the
strong components and a topological order of these components in
 time \cite{Tarjan72dfs}.





  The
  digraph cycle detection problem has an extensive history
  \cite{AlpernHRSZ90,Marchetti-SpaccamelaNR96,PearceK06,KatrielB06,LiuC07,AjwaniFM08,AjwaniF10,DBLP:journals/corr/abs-0711-0251,HKMST:Talg12,BFG:SODA09}.
    The current state-of-the-art
time bounds by centralized algorithms are   by Haeupler
 et al.\ \cite{HKMST:Talg12}
 and  by Bender  et al.\ \cite{BFG:SODA09}.
  The two-way search  algorithm of  Haeupler
 et al.\ maintains a complete topological order.
    When
an insertion occurs which is inconsistent with the order,  nodes are
shuffled to correct this.


 Bender et
al.\ \cite{BFG:SODA09} suggested a simpler algorithm that runs in
  time. This algorithm maintains only a
 weak topological order. It partitions
 the vertices  into levels and when an arc is inserted it performs a
 backward search within a level and a forward search across levels.
 This algorithm stops the backward search when it reaches a
prespecified number of arcs.


There has been little work on distributed cycle detection, even when
the graph is static. Fleischer et al.\ \cite{FleischerHP00}
suggested a divide and conquer based randomized algorithm for
finding strongly connected components that is easier to parallelize
and sequentially runs in expected  time. The distributed
cycle detection problem also arises in the context of model checking
on large flow graphs. Barnat et al.\ \cite{BarnatBC05} gave a
distributed algorithm based on breadth first search which is
quadratic in the worst case. A distributed implementation of our
algorithm, which is subquadratic, is interesting even for a static
graph.


\smallskip
\noindent {\bf Organization of this paper:}

In Section \ref{prelim:sec} we give basic definitions and properties
of our labeling. In Section \ref{labels:sec} we consider the case
when ranked vertices and ranks are determined probabilistically and
give some properties that hold in expectation and with high
probability.
 In Section
\ref{sec:2directions} we present a dynamic algorithm for maintenance
of labels and analyze its complexity (time and message complexity).
In Section \ref{nsquare:sec} we give a variant of the dynamic
algorithm that gives us the  time result.


\section{Preliminaries} \label{prelim:sec}

Let  be a directed acyclic graph with vertices  and arcs ,  and  .
We define   to be the set of all predecessors of  ({\sl
i.e.}, for all  there is a path from  to ),  and
 to be the set of all successors of  ({\sl i.e.}, for all
 there is path from  to ). We include  in its
predecessors and successors sets, that is, . Also, define 

Let  be a subset of , .  Let   be such that  is one to
one and  for all . We say that the
vertices in  are {\em ranked}.

We define  and , the set of ranked predecessors of
. If  then we define , 
, and  . If  then we define , , and  .  We continue in the same way and for all  such that  we define , ,  and
. We define  to be  if  and
 we define  to be the largest  for which .




 We define the
\emph{label} of a vertex  to be the sequence  Figure~\ref{graph:fig} in the Appendix presents an example of this labeling.

The following
properties stem directly from the definitions above:
\begin{prop}
For all ,
\begin{itemize}
\item For all , .
\item For every  such that ,
  and .
\end{itemize}
\end{prop}

We now define a partial order  of the labels.  The order
  corresponds to a
{\em decreasing} lexicographic order on 
That is, for , \overset{>}{\mbox{\rm\tiny lex}},
which happens if either of the following holds:
\begin{description}
\item[Case 1:] For some  we have that , and for all : , or,
\item[Case 2:]  and for all :
.
\end{description}

For , define  to  be the longest
common prefix of  and . By definition, both 
and  are reachable from every vertex in . In
particular, if  is a prefix of  and 
(which implies that ) then  is reachable from .
Next, we show that in certain cases the labels can be used to rule out the existence of a path. This will be used later on by our cycle detection algorithm.

\begin{thm}\label{T-no-path}
If  then there is no path from  to .
\end{thm}
\begin{proof}
Assume that case 1 holds and let  be minimal such that
. Note that  is the vertex of
minimal rank in  and  is the vertex of minimal
rank in . If there is a path from  to  then it must be
that , which implies that , a contradiction.

Now, assume that case 2 holds and consider the vertex  (), and the vertex . There is a path from  to ,  and there is a path
from  to . If there is also a path from  to  we have that , but , a contradiction.
\end{proof}

\begin{figure}[t]
\centering
\ifpdf
\includegraphics[width=0.4\textwidth]{graph}
\else
\epsfig{figure=graph.eps,width=0.4\textwidth}
\fi

\caption{Example graph. The nodes with numbers are the ranked nodes .  For node  we have , , , , , ,  , , .  For node  we have , , .
Therefore  and . \label{graph:fig}}
\end{figure}

\section{Properties of labels}  \label{labels:sec}

In this section we give properties of our new labelings when ranks are assigned at random. In particular we show that
\begin{itemize}
  \item Labels are ``short'', see Lemma \ref{L-label-size}.
  \item The set of predecessors of a vertex  that have the same label as  is ``small'', see Lemma \ref{lem:backsize}.
\end{itemize}
These properties are used in Section 4 for the analysis of our algorithms.


Let  be a subset of , , and let  be
the set of all one to one mappings . In this section we first analyze the size of
the labels when  is chosen uniformly at random from .

Let , every mapping  determines  ,
,  for  and . We omit the mapping 
when clear from the context (as done above). For any sequence of
subsets of ranked vertices    define the subset
of mappings


We now show:
\begin{lem}\label{L-set-size} For any  , any ,
 and a sequence of
subsets of ranked vertices     such that
 we have that

\end{lem}
\begin{proof}
 The set of mappings  are partitioned into
  equal size equivalence classes. Each class
contains  all the rankings that induce the same
 relative order of the ranks
, . That is,  rankings  and  are in
the same class  iff for any pair of vertices ,
.

Consider some (arbitrary, fixed) topological order on ,
. For  let , {\sl i.e.}, the
position in the topological order of the vertex in  with minimum rank value.
It follows that for all ,
   

It follows that
  
\end{proof}

 We are now
ready to bound the label size.

\begin{lem}\label{L-label-size}
For any ,  the probability that there exists  whose
label has more than  vertices is at most 
.
 \end{lem}
\begin{proof}
Consider tne distribution on the ratio .  From
Lemma~\ref{L-set-size}, 
this distribution is
dominated by the uniform disribution , in the sense that
.  The
distribution on the logarithm of the ratio is dominated by  ,
where .  This is an exponential distribution with
parameter .  We now consider the product of these ratios over ,
which is the ratio .
The negated logarithm of the product,   is
the sum of the negated  logarithms of the
ratios  , which is dominated by the random variable  that is the
sum of  i.i.d exponential random variables.  This is a gamma distribution
which has cummulative distribution function (CDF) 
.  From this domination relation, it
follows that the
probability that the label size is more than  is at most 
.  Substituting  in the
CDF  we obtain the bound
.  We substitute   and use the Stirling bound

obtaining, for , a bound of .
To complete the proof for , 
note that the label size can be at most .
\end{proof}



The previous lemma applies for any set  of labeled vertices. We now
consider the setting in which the set  itself is also chosen at
random. The labels of the vertices are computed as before.
 Given a digraph , a -labeling of  is the following:
 \begin{itemize}
 \item Each  vertex chooses to be ranked independently with probability , {\sl i.e.}, .
 \item The ranks of the ranked vertices is a random permutation
  of  (by choosing ranks at random from a set of size , we can assume that the ranks are distinct and the relative order between them is a random permutation).
 \end{itemize}

 Given any graph , any labeling , and for any , let u, note that  for all , , and .

 Given  and labeling , define  to be the maximum over  of .




 \begin{lem} \label{lem:backsize}
   For any graph  with  vertices, , and ,  where the distribution  is the space of -labelings.
 \end{lem}
 \begin{proof}
   Consider a vertex  with label . The set  is exactly the set of unranked vertices such that  and there is a path from  to .
   Let . Every vertex  must be unranked. To see this, consider what happens if  had rank, and  then  will not appear in , if  had rank and  then  would not be last in .

  The probability that no vertex  has rank is . For  we have .
  From the union bound, the probability that no vertex  has  is at most  as there are at most  possible pairs , .

\end{proof}

\begin{cor}\label{cor:backsize}
  Over any sequence of insertions of edges, amongst  vertices, resulting in graphs , 
\end{cor}
\begin{proof}
  This follows again from the union bound and as .
\end{proof}

\ignore{
\begin{lem} \label{lem:backsizeexp}
   For any graph  with  vertices, a vertex ,  and  , 
 where the distribution  is the space of -labelings.
 \end{lem}
 \begin{proof}
Selecting a -labeling is equivalent to each vertex drawing independently
a rank  and treating as ranked only vertices with
, by order of increasing rank.  
In turn, this is equivalent to each vertex selecting
an independent exponentially distributed rank  with parameter ,
and taking all vertices with rank .
Note that this is equivalent to drawing ranks uniformly and
using .  We have  if and only if
.

 This is equivalent to the following process applied to a pair 
.
Initially, we have the set  of  all predecessors of  and 
 .  Select a node  uniformly at random.
Let  be exponentially distributed random variable with parameter .
If  we stop and return .  Otherwise, we set
 and .
The equivalence follows from the memoryless property of the exponential
distribution, so the conditional distribution on , given that  is also exponential with same parameter.  
It also follows from the fact that the distribution of the minimum of  exponential random variables with parameter  is an
exponential random variable with parameter .


For all , define   to be 
the maximum, over all acyclic directed graphs  with  vertices
such that all vertices are in  for a node , of the
expected number of vertices when this process terminates.

We now compute upper bounds .
Since  for all , we can use the correct upper
bound  when  .



We first relate  to , where   and all .
The probability that we stop with  at the current step
is .   
 Otherwise, using Lemma \ref{L-set-size},
the distribution on the size of  is dominated by
a uniform one on .  Since clearly   is monotone
non-decreasing with  and , and ,  we obtain the relation

(Recall that  is the distribution function of an exponential
random variable with parameter .)

In particular, if we substitute upper bounds  on  in the RHS, we obtain an
upper bound on .

 Therefore, to establish our claim that 

(we can replace it with the mean of a truncated by- geometric distribution
with parameter )
is a valid upper bound, it suffices to show that it satisfies the relation

From monotonicity in , it suffices to look at 
which corresponds to .

  We now upper bound

  When
 we have  

   Otherwise, using the approximation
 and separately treating  the
intervals 
and , we have 

(using ).
Combining it all, we are ready to bound .

 \end{proof}
}


\section{Preserving labels dynamically} \label{sec:2directions}


Consider a set of vertices  and let  be a sequence of arcs inserted over time. We seek to
maintain the labels  defined above, over this sequence of
insertions. (Extending the algorithm to allow addition of new
singleton vertices is straightforward.)

When adding an arc , we update all labels if no cycle was
formed. If a cycle is created we halt.


\emph{Insert():}
\begin{itemize}
\item If  then we do nothing and return.
\item Cycle-Detect().
\item If no cycle is detected and  call Update(), where Update() is a recursive procedure defined below.
\end{itemize}

\emph{Cycle-Detect():}
\begin{itemize}
\item {\bf Backward search:} Starting from ,
send a message  to all in-neighbors of . When a vertex  gets such a
message  over an edge  then it performs one of the
followings.\\
1) If ,   and  gets  for the first time, then  sends   to all its in-neighbors. \\
2) If  or  has no in-neighbors then 
sends a ``no-cycle'' message back over the edge .\\
3) If  then  sends a ``cycle'' message back on the edge .


When  gets a ``cycle'' message  for the first time then it
forwards it to one of its out-neighbors from which it got  and
stop sending messages. When  gets a ``no-cycle'' message from all
 its in-neighbors then it sends a ``no-cycle'' message to all its
out-neighbors from which it got ,  and stop sending messages.

A cycle is detected if  gets back a ``cycle'' message. If there
is no cycle then  gets a ``no-cycle'' message back from all its
in-neighbors.

\smallskip

\item{\bf Forward search:}
 If  then  sends the message
  to its out-neighbors.
When a vertex  gets  over an edge  then it
performs one of the followings. \\
1) If  also got a message  during
 the backward search it sends a ``cycle'' message back over . \\
2) If    and  gets  for the first time
then it sends   to all its out-neighbors.\\
3) If  
 or  has no
out-neighbors then  sends a ``no-cycle'' message back on .

When  gets a ``cycle'' message  for the first time then it
forwards it to one of its in-neighbor from which it got 
and stop sending messages. When  gets a ``no-cycle'' message from
all of its out-neighbors then it sends a ``no-cycle'' message to all
its in-neighbors from which it got  and stop sending
messages.

A cycle is detected if  gets back a ``cycle'' message. If there
is no cycle then  gets a ``no-cycle'' message back from all its
out-neighbors.

\end{itemize}

\emph{Update():}
\begin{itemize}
\item Let  be such that  , {\sl i.e.}, the label of  is the concatenation of the longest common prefix with , followed by .
\item Let  be the longest prefix of  such that  for .
\item \label{alg:update} If  is ranked set , otherwise set .
\item\label{update:recurse} If  was updated then for all arcs , recursively apply update().
\end{itemize}


We start by proving the correctness of the  Algorithm Insert
assuming that it halts. We show that it halts and  bound the number
of messages that it sends in Section \ref{sec:analysis}.

\begin{lem}
Given a correct labeling of the vertices of an acyclic graph,
\begin{itemize}
  \item Insert() will detect a cycle if the insertion of  creates one.
  \item Insert() will produce a correct labeling if the insertion of arc  into the graph does not create a cycle.
\end{itemize}
\end{lem}
\begin{proof}

We start by showing that the algorithm detects a cycle if and only
if the insertion of  creates one. If 
then from Theorem~\ref{T-no-path} it follows that there is no path
from  to . Thus, the insertion of  does not create a
cycle, and the algorithm is correct. Consider now the case that
. In this case it follows from
Theorem~\ref{T-no-path} that if there is a path from  to  then
all its vertices must have the same label and thus if a cycle exists
all its vertices have the same label. The algorithm detects such a
cycle during the backward search which would reach . In this case
 will send a cycle message that will reach . If such a cycle
does not exist the search terminates at vertices with no
in-neighbors or with a smaller label. In both cases a ``no-cycle''
message will be sent back by each such vertex. Eventually  will
get a ``no-cycle'' message from all its in-neighbors.

Consider now the case that  and there is a
path (or more) from  to . Let  be a vertex on such a path
 for which  for the first time when traversing
 from . Since the path terminates at ,   must exist. By
the definition of the backward search   gets the message
 during the backward search from .  By the
definition of the forward search   will also get a message
   during the forward search and will send back a ``cycle'' message that will reach .
  If there is
no cycle then the forward search terminates at vertices  such
that either  or  has no out-neighbors. In
both cases a ``no-cycle'' message is sent back by each such vertex.
Eventually,  gets  a ``no-cycle'' message from each of its
out-neighbors.

We now turn to show that the labels are correctly maintained. For
every  let  be the label of   before the
insertion of  and let  be the correct label of
 after the change. We show that  is indeed the
label of any  when the algorithm halts.

First notice that the predecessor set, , of each vertex 
uniquely defines its label. So for vertices  such that 
does not change by adding  we should have
.

By its definition, the algorithm changes the label only of vertices
 such that . So if   then
 is the label of  after the
insertion as required.


Let  be the vertices in  ordered by a
topological order. We prove by induction on this order that the
labels are correct. The basis of the induction holds for  as
the algorithm updates  if  and
the update is correct by the definition of the labels. Assume that
when the algorithm updated the label  of  for the last time then the label of  was
, for each . We prove that the
algorithm updates the label of  to . Let
 be all the in-neighbors of  that are in . If
  then  at least one of
 changed its label as well. By
the induction and the definition of the algorithm, each of
  eventually transmits its
correct new label to  and as the update  procedure implements
the label definition the claim follows.

\end{proof}


\subsection{Analysis of the number of messages required}
\label{sec:analysis}

For a vertex , an update to  means that the value of
 has changed. This is distinct from the number of update
messages to , because update messages may have no effect on
. Note that the insertions of a single arc may produce
several updates to , this is because updates propagate
through the network at different rates.

Following an insertion of an arc  (that did not close a cycle)
many calls to the update procedure are made. We define the {\em
schedule} of an arc  to be the chronologically ordered sequence
of these calls (breaking ties arbitrarily). The schedule (and it's
length) depends on the arbitrariness of the choices in line
\ref{update:recurse} of Update() above, and by variable message
timing in distributed environments. The length of the schedule is
the total number of messages sent in order to update the labels
following an arc insertion. Note that not every such message can
cause a label update at the target node so the total number of label
changes may be smaller than the schedule.


Fix the set of ranked vertices  and the assignment  of ranks
to vertices in . Consider any vertex . Let  be
the set of all sequences of arc insertions, such that: after
inserting the arcs in ,   has   ranked
predecessors. Define  to be the maximal number of updates
to , for any sequence of arc insertions , and any schedule of updates for each of these
insertions.

 Let  be the sequence of arcs . Let ,  be the (possibly empty) set of vertices that became predecessors to  following
the insertion of arc , but were not predecessors to  after the insertion of .
Let
,  be the ranked predecessors of  after the insertion of all the arcs in , in the order in which they became predecessors of . {\sl I.e.}, where the vertices of  are a consecutive subsequence of  and appear before the vertices of  for . The vertices of  are ordered arbitrarily.

Let  be some topological ordering of the ranked predecessors of  that is consistent with the final set of arcs.
Let  be a
permutation of  such that  appears before
 in the topological ordering induced by . Define  to be such that .

\begin{lem}
\label{lem:mapping} Fix some ,
  let ,  be as above. Choose a worst case : that is , in conjunction with appropriate schedules, maximizes the number of updates to .
  This defines the sequence   of ranked predecessors of  as defined above.
  Let  be the ranked predecessor of  of minimal rank. Then, 
\end{lem}
\begin{proof}
  Let  be such that .
  We split the updates to  into three chronologically consecutive groups:
  \begin{itemize}
    \item Updates to  from the insertion of arcs . Let , there are no more than  updates to  associated with these insertions.
    \item The first update to  subsequent to the insertion of arc .
    \item \label{split:hard} All subsequent updates to , let the number of such updates be denoted by . To prove this lemma we need to show that
    .
  \end{itemize}

  We now consider a new graph consisting of  vertices, and initially containing no edges.
  For every ranked vertex  we add a new (unranked) vertex  to , let , the rank of  remains unchanged.
   We build a sequence of arc insertions, , (arcs between vertices of ), and appropriate schedules, such that  has no more than
    ranked predecessors, and the number of updates to  in  is .

   The sequence  is as follows:
   \begin{enumerate}
   \item Set .
   \item For every arc  where  is not ranked add arc  to .
   \item For every arc  such that \begin{enumerate} \item   and  is ranked, and, \item   is reachable from  (after adding ), and, \item  is reachable from  (after adding ):
   \end{enumerate}  add arc  to .
   \item Inserting the arcs of , in any order, never updates , nor do they introduce ranked predecessors to . Let  be insertions of the arcs of  in some arbitrary order.
   \item \label{tau:ui} Following the arcs above we add arcs  to , for all ranked predecessors of , , in order of decreasing rank (not ordered by ).
   \item Subsequently, we add arcs ,  to , if  and  is reachable from . These arcs appear in the same order as in .
   \end{enumerate}

We claim that if for every arc in  we use the worst case
schedule (resulting in the maximal number of updates to )
then the number of label updates is at least .

Consider the updates to , as a consequence of inserting the
arc  in the original graph. The updated values of
 are all of the following form  where these vertices lie along a path from
 to , and  is the vertex of minimal rank
along the subpath from  to .
   We can classify such updates to  according to the rank of . When we add the arc  to the new graph, we generate updates to  with labels that start with .

Specifically, consider all changes of  (in the original
graph following the insertion of ) to a label with
 as the first vertex and  as the second
vertex for some fixed . Every such label corresponds a path 
as above, all ranked vertices along  (excluding ) have
rank greater than the rank of . In the new graph, when adding
the edge  there is a path analogous to the path  in
which each ranked vertex  is replaced by the edge . So we
construct the following schedule for .
\begin{enumerate}
\item
Consider a message from  to  in the schedule of 
with a label  containing  as the second vertex (following
). In the schedule of   we send a message
with a label equal to  with  removed from  to
. If the label of  changes as a result of receiving this
message from  then  sends a message to  containing its
new label. We send these messages in the same relative order as of
their corresponding messages in the schedule of .
Each message from
a vertex  is sent following a change in the label of  since
this was the case in the schedule of .
\item
We continue the schedule arbitrarily until all labels are
consistent.
\end{enumerate}
The first part of this schedule generates an update to  for
every update to  with a label whose second vertex is 
that was generated by the schedule of . Thus,  for all
arcs  together we generate at least as many updates
caused by the insertion of .

For each insertion of an arc  the
worst case schedule which we use runs over the same subgraph as the
subgraph used by the schedule of the  original insertion which each
ranked vertex replaced by an arc. Therefore it generated at least as
many updates.
    \end{proof}



Our next goal is to show the following:


\begin{lem} \label{lem:changes}
For all , 
\end{lem}

\begin{proof}

Let . As the ranks are assigned randomly,
we have that for all , . By Lemma \ref{lem:mapping} we have that






Let , we prove by induction that , Assuming  for all , we get that
\vspace*{-6pt}
    
\vspace*{-10pt}
 \end{proof}

We are now ready to bound the total amount of messages.

\begin{thm} \label{thm:32}
For an appropriate choice of a -labeling, the expected total
number of messages that the algorithm described above sends is
. Each message contains  bits
with high probability. It takes  time to process a
message with high probability.
\end{thm}
\begin{proof}
We prove the lemma for a constant degree graph (which in particular
implies that ) and then indicate the changes required
to extend the proof to general graphs.
 For constant degree graphs to minimize the number of messages we use a -labeling with
 which implies that . By Lemma \ref{lem:changes}, for any vertex  the
expected number of updates to  is at most . Furthermore, by Lemma \ref{lem:backsize} the
 number of vertices reached during a backward search from
 is  with high probability.

Consider the insertion of all edges except the last if it closes a
 cycle. Since our graph is of constant degree
the  number of messages sent by the backward search initiated by
each such insertion is . Therefore the number
of messages sent by all backward searches is .
The forward search initiated by such an insertion traverses the same
edges that the following label-update process traverses. So the
total number of messages of forward searches equals  the total
number of messages required to update the labels which is . We conclude that the total number of messages for
backward searches, forward searches and label updates is .



Consider now the last insertion if it closes a cycle. The backward
search of this insertion also traverses 
 vertices and sends  messages. The forward search of
 this insertion traverses each edge at most twice so it sends 
 messages. We do not update the labels in this case.

To handle the general case of arbitrary indegrees we slightly change
the labeling as follows. We define a -arc labeling to be an
assignment of ranks to vertices obtained as follows: Each arc
chooses to be ranked with probability , if the arc is ranked then
it chooses a random rank so that with high probability the ranked
vertices have unique ranks and the ranks are small. The rank of a
vertex is the minimum rank of its ranked incoming arcs, if any.

One can modify proofs that depend on the number of ranked
predecessors ({\sl e.g.}, ) to depend on the number of ranked
predecessor arcs. In Lemma \ref{L-set-size} the number of ranked
predecessors (vertices) goes down by a constant factor. In the
arc-ranked variant of this Lemma, the number of incoming ranked arcs
to predecessor vertices goes
 down by a constant factor. In Lemma \ref{lem:backsize}, rather
 than bound the number of vertices in  we can bound the
 number of incoming arcs to vertices of .

 Using these modified Lemma and a -arc labeling with  we get the  bound.

{\bf Remark:} If we want arcs to be ranked with probability
, then  has to be known (or at least approximately
known).
 In the distributed setting, this can  be justified using
standard techniques to recompute and distribute  whenever it
doubles. Let  be the current estimate of the
number of arcs. If following an insertion of an arc , vertex
 initiates a recount of the arcs with probability
 then indeed each vertex would know 
approximately up to a factor of . (There are other deterministic
ways to achieve this.)
\end{proof}

When doing a backwards search from , we need only  time per
vertex by  maintaining for each vertex  a list of its immediate
predecessors that have the same label as . This can be maintained
over time by having , whenever it changes its label, store a list
of all immediate predecessors that sent it an update message with
this new label.

In the theorem above we choose  so as to minimize the number of
messages. To minimize time, and assuming that backward searches take
 time per vertex, we choose slightly different  and get the
time bounds stated in the introduction.

We also obtain the following theorem by observing the modified
backward search requires  time, this follows from
 Corollary~\ref{cor:backsize}.

\begin{thm} \label{thm:33}
Using a - (vertex) labeling with , and
the modification to the backward search above, the expected running
time of the algorithm is .
\end{thm}




\section{Using queues to improve forward propagation} \label{nsquare:sec}


Every vertex  maintains  a value  for
all  such that . The value  is the label
of  when  last communicated with . {\sl I.e.}, whenever
vertex  sends an update message to , it receives in return the
current label of  and updates . Note that  may
update  following the message from , or not, but in any
case it sends back to  the (possibly new) . Every vertex
 maintains a priority queue ordered by  for all 
such that .

We modify the propagation algorithm as follows: \begin{itemize} \item When vertex  updates its label from  to ,  (),  sends a message containing  to all vertices  in the priority queue such that . Such messages from  to  are called {\sl update messages}.
\item When vertex  receives an update message from  with ,  will
 update it's own label  if  and transmits the (possibly new)  to .
 \item Vertex  sets  and updates the priority queue accordingly.
 \end{itemize}

We apply the algorithm of Section \ref{sec:2directions} with this
modified propagation method and with all vertices ranked. Since when
all vertices are ranked each vertex has a different label the
backward search from  degenerates and contains only . The
total number of messages required by the update procedure to update
the labels is . The following theorem gives an
 upper bound of  on the total number of messages of
 the modified algorithm which is better for dense graphs.

\begin{thm}
If all vertices are ranked then the modified algorithm described
above sends  messages on average. Each message
consists
 of  bits with high probability, and it takes  time to process a message with high probability.
\end{thm}
\begin{proof}
Although we run the algorithm with all vertices ranked, our analysis
is more general and bounds the number of update messages send to
each vertex  as a function of the number of ranked predecessors
 has at the end.

We use the notations and definitions of Section \ref{sec:analysis}
with the following modifications. We define  to be the
set of insertion sequences such that  ends up with  ranked
predecessors and with at most  incoming neighbors. We define
  to be
the maximal number of update messages sent  to  (we count both
those that trigger a change of  and futile ones that do
not), for any sequence of arc insertions ,
and any schedule of updates for each of these insertions.

We prove that   satisfies the recurrence

The solution to this recurrence is  so by summing up
over all vertices and substituting the worst case  the theorem
follows.

Fix some , and consider the worst case :
that is , in conjunction with appropriate schedules,
maximizes the number of update messages to . Let
  be the final ranked predecessors of  in the order
 in which they became predecessors of  (as in Section \ref{sec:analysis}).
  Let  be the ranked predecessor of  of minimal rank.
Let  be such that .
  We split the update messages sent to  into three chronologically consecutive groups:
  \begin{itemize}
    \item Updates from the schedules of the arcs . Let , there are no more than 
    update messages sent to  associated with these insertions.

    \item Each in-neighbor  of  may send  a single update
    message to  such that before sending this message 
    did not start with  and after sending this message 
starts with
    . Since the number of in-neighbors
    is at most  for every  we get that there are
    at most  messages sent to  of this kind.


    \item \label{split:hard2} All other messages sent to . These are the messages from the schedules of
     that were not counted in the previous item. Let the number of such messages be denoted by . As in the proof of Lemma \ref{lem:mapping} we now show that
    .
  \end{itemize}


As in the proof of Lemma \ref{lem:mapping} we consider a new graph
consisting of  vertices (recall that  is the set of
ranked vertices), and initially containing no arcs. For every ranked
vertex  we add a new unranked vertex , the rank of 
remains unchanged. We consider the sequence of arc insertions,
,  defined in the proof of Lemma \ref{lem:mapping}. At the end
of this sequence  has at most  ranked
predecessors and at most  incoming arcs. We claim
that the schedules for the insertions of  defined in the
proof of Lemma \ref{lem:mapping} are valid schedules. This
immediately implies that the insertions of these arcs generate as
many update messages to  as were generated by the insertion of
.

Consider the schedule of . The first message in this
schedule is from  to  and it updates the label of 
to contain  (i.e.\ to be the same as the label of ).
 To prove that the rest of this schedule  is
valid  we need to argue that if a message with a label  that
starts with ``'' was sent from  to  by the
schedule of , then we can send message with the same label
with  removed from  to . Each time a vertex  is
updated it sends a message to  so that they always have the same
label (it is obvious that these messages can be sent since they
cause real updates).

So consider such a message  that was sent from  to  by
the schedule of . Let  be the corresponding message
with  removed that is to be sent by the schedule of
.  In the schedule of  if
  does not start with  then it
must start with a vertex with rank greater than the rank of 
(vertices of smaller rank still cannot reach any other vertex) which
implies that  is lexicographically smaller than
 and therefore  can be sent. Otherwise, 
has already sent to  a message earlier in this schedule. In this
case  must be lexicographically smaller than 
because this schedule is a subsequence of the schedule of
.
\end{proof}





\bibliographystyle{plain}
\bibliography{bibcycle}
\end{document}
