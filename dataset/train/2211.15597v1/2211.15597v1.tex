\documentclass[10pt,twocolumn,letterpaper]{article}

\usepackage{cvpr}

\usepackage[utf8]{inputenc} \usepackage[T1]{fontenc}    \usepackage[pagebackref]{hyperref}       \usepackage{url}            \usepackage{booktabs}       \usepackage{amsfonts}       \usepackage{nicefrac}       \usepackage{microtype}      \usepackage{xcolor}         \usepackage{amsmath}
\usepackage{amssymb}
\usepackage{multirow}
\usepackage{caption}
\usepackage{graphicx}


\title{\vspace{-0.7cm}Lightning Fast Video Anomaly Detection via Adversarial Knowledge Distillation}

\author{Nicolae-C\u{a}t\u{a}lin Ristea, Florinel-Alin Croitoru, Dana D\u{a}sc\u{a}lescu, Radu Tudor Ionescu\thanks{corresponding author: raducu.ionescu@gmail.com}\;,\\ 
Fahad Shahbaz Khan, Mubarak Shah\\
University of Bucharest, Romania, University Politehnica of Bucharest, Romania,\\
SecurifAI, Romania, MBZ University of Artificial Intelligence, UAE,\\
Link\"{o}ping University, Sweden, University of Central Florida, US\vspace*{-0.3cm}
}

\def\cvprPaperID{8300} \def\confName{CVPR}
\def\confYear{2023}

\begin{document}

\maketitle

\begin{abstract}
\vspace{-0.3cm}
We propose a very fast frame-level model for anomaly detection in video, which learns to detect anomalies by distilling knowledge from multiple highly accurate object-level teacher models. To improve the fidelity of our student, we distill the low-resolution anomaly maps of the teachers by jointly applying standard and adversarial distillation, introducing an adversarial discriminator for each teacher to distinguish between target and generated anomaly maps. 
We conduct experiments on three benchmarks (Avenue, ShanghaiTech, UCSD Ped2), showing that our method is over 7 times faster than the fastest competing method, and between 28 and 62 times faster than object-centric models, while obtaining comparable results to recent methods. Our evaluation also indicates that our model achieves the best trade-off between speed and accuracy, due to its previously unheard-of speed of 1480 FPS. In addition, we carry out a comprehensive ablation study to justify our architectural design choices. \vspace{-0.6cm}
\end{abstract}

\setlength{\abovedisplayskip}{3.0pt}
\setlength{\belowdisplayskip}{3.0pt}

\section{Introduction}

\begin{figure}[!t]
\begin{center}
\centerline{\includegraphics[width=0.95\linewidth]{pipeline.pdf}}
\vspace{-0.25cm}
\caption{Our pipeline comprising an efficient student model that learns to distill knowledge from two object-centric teachers via a combination of direct and adversarial losses. The pipeline can be trivially extended to any number of teachers. For simplicity, we do not represent the multi-frame input and multi-resolution output of our student. Best viewed in color.}
\label{fig_pipeline}
\vspace{-1.1cm}
\end{center}
\end{figure}

Video anomaly detection is a difficult task, being actively studied in recent years \cite{Acsintoae-CVPR-2022,Dong-Access-2020,Doshi-CVPRW-2020a,Georgescu-CVPR-2021,Georgescu-TPAMI-2021,Gong-ICCV-2019,Ionescu-CVPR-2019,Ionescu-WACV-2019,Ionescu-ICCV-2017,Ji-IJCNN-2020,Lee-TIP-2019,Li-ECCV-2022,Liu-ICCV-2021,Lu-ECCV-2020,Nguyen-ICCV-2019,Pang-CVPR-2020,Park-CVPR-2020,Ramachandra-WACV-2020a,Ramachandra-PAMI-2020,Ristea-CVPR-2022,Smeureanu-ICIAP-2017,Sun-ACMMM-2020,Tang-PRL-2020,Vu-AAAI-2019,Wang-ACMMM-2020,Wu-TNNLS-2019,Yu-ACMMM-2020,Yu-CVPR-2022,Zaheer-CVPR-2020,Zaheer-ECCV-2020,Zaheer-CVPR-2022} due to its increasing importance. The difficulty of the task stems from the fact that abnormal events depend on the context and occur rarely. To illustrate the scarcity and reliance on context of abnormal events, we consider the truck deliberately driven into the Berlin Christmas market\footnote{\url{https://en.wikipedia.org/wiki/2016_Berlin_truck_attack}} in 2016 as a relevant example. A truck driven on the road is labeled as a normal event, but, as soon as the truck intrudes into a pedestrian area, \eg a market, the event becomes abnormal. This example confirms that labeling an event as normal or abnormal depends on the context. Moreover, according to Wikipedia\footnote{\url{https://en.wikipedia.org/wiki/Vehicle-ramming_attack}}, there are about 170 vehicle ramming attacks registered since 1953 to date, but many of them are too old to be caught on video. Hence, our example also confirms that such events rarely occur.

Due to the rarity and reliance on context of abnormal events, it is nearly impossible to collect a sufficiently representative set of such events, eliminating the possibility of applying traditional approaches based on supervised learning to perform video anomaly detection. With the supervised option thrown out the window, researchers turned their attention to alternative solutions, the most prominent alternative being based on outlier detection \cite{Antic-ICCV-2011,Cheng-CVPR-2015,Cong-CVPR-2011,Dong-Access-2020,Dutta-AAAI-2015, Hasan-CVPR-2016,Ionescu-WACV-2019,Kim-CVPR-2009,Lee-TIP-2019,Li-PAMI-2014,Liu-CVPR-2018,Lu-ICCV-2013,Luo-ICCV-2017,Mahadevan-CVPR-2010,Mehran-CVPR-2009,Park-CVPR-2020,Ramachandra-WACV-2020a,Ramachandra-WACV-2020b,Ramachandra-MVA-2021,Ramachandra-PAMI-2020,Ravanbakhsh-WACV-2018,Ravanbakhsh-ICIP-2017,Ren-BMVC-2015,Sabokrou-IP-2017,Tang-PRL-2020,Wu-TNNLS-2019,Xu-CVIU-2017,Zhao-CVPR-2011,Zhang-PR-2020, Zhang-PR-2016, Zhong-CVPR-2019, Fan-CVIU-2020}. Methods based on outlier detection learn a normality model from training videos containing only normal events, labeling test samples that deviate from the model as abnormal. Our approach falls within the same line of research, being based on distilling knowledge from object-centric outlier detection systems \cite{Georgescu-CVPR-2021,Georgescu-TPAMI-2021}, which reported state-of-the-art performance levels in anomaly detection. We hereby emphasize that top scoring abnormal event detection systems such as \cite{Ionescu-CVPR-2019,Georgescu-CVPR-2021,Georgescu-TPAMI-2021} operate at the object level, relying on a pre-trained object detector which limits the real-time processing to only a single video stream per GPU. Although it might seem sufficient to process one video stream at about 20-30 FPS on one GPU, the cost of computational resources to process tens or hundreds of video streams (as expected in real-world surveillance scenarios) quickly becomes very high, considering that the price range of one GPU is around \5\%5\%m167\times 732641282563\times 321P \in \mathbb{R}^{h\times w\times c}hwcPmPQKVPQKV2563\times 32KV1Q64Q \in \mathbb{R}^{n_q \times d}K \in \mathbb{R}^{n_k \times d}V \in \mathbb{R}^{n_v \times d}n_q = h \cdot wn_k = n_v = \frac{h \cdot w}{4}d=64K^\topKZn_q\times dZh\times w\times dZ^{\circ}h\times w \times (d\cdot s)sZ^{\circ}cPZ^*4\cdot ccZ^*3\times 364t\left[x^{i-t}, x^{i},  x^{i+t}\right]\hat{x}^i = D\left(E\left(\left[x^{i-t}, x^{i},  x^{i+t}\right]\right)\right)EDt=3EDT_1T_2x_Tx_Sxry=T(x_T)\hat{y}=S(x_S)TSTh_kw_ky^k\hat{y}^kkr=3T_1T_2\lambda_1\lambda_2\lambda_1=\lambda_2=101D_TTD_TSSD_Tx_Tx_Sp_Tp_STp_Tp_Sx_T=x_SD_{T_1}D_{T_2}T_1T_2\alpha=0.1^,\;\;m=5s=531\times14\times 416\times 161\times130\times 3060\times 60356410^{-4}10^{-5}T_1T_2T_1T_2T_1T_288.2\%T_1T_25\%T_1T_22.8\%5.1\%T_1T_25\%4\times 4T_1s=5mm \in \{3,4,5,6,7\}m=5m=5s \in \{3,4,5,6,7\}s=5m=5s=5msms1\times14\times416\times1664\times641\times14\times41\times14\times416\times161\times 14 \times 41\times 14 \times 416 \times 16\mathcal{L}_{\mbox{\scriptsize{AE}}}\mathcal{L}_{\mbox{\scriptsize{KD}}}\mathcal{L}_{\mbox{\scriptsize{AKD}}}\mathcal{L}_{\mbox{\scriptsize{AE}}}\mathcal{L}_{\mbox{\scriptsize{KD}}}\mathcal{L}_{\mbox{\scriptsize{AKD}}}\alpha\mathcal{L}_{\mbox{\scriptsize{AE}}}\mathcal{L}_{\mbox{\scriptsize{KD}}}\mathcal{L}_{\mbox{\scriptsize{AKD}}}T_1T_2T_1+T_2T_1+T_2T_1+T_2T_1+T_2\alpha=0.1\alpha\alpha0.10.70.1\alpha=0\alpha0.10.5\alpha=0\alphaT_1T_1T_2T_1T_2T_iT_iT_i\mathcal{L}_{\mbox{\scriptsize{AKD}}}\;\;T_1+T_2T_1+T_2T_1T_216\times 16T_1T_2T_1T_23\%T_112\%97.46\%98.63\%T_1T_2T_2$ outputs high anomaly scores without reason. In the end, we believe that the most remarkable ability of our student is to detect anomalies where object detectors with a limited number of known classes fail.

\end{document}