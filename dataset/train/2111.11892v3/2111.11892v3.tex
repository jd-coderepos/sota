\section{Experimental Analysis}
Below we detail our experimental setup and results, including implementation details of our approach, considered datasets and baselines, quality metrics, and ablations.





\subsection{Implemention Details}

\myparagraph{Tracking Graph}
We use CenterTrack~\cite{zhou2020tracking}, one of current state-of-the-art single-camera trackers, to create tracklets for each camera.
These tracklets will be aligned again with the provided public detections to eliminate duplicated ones and retain detections that were not tracked, e.g.\ due to occlusion.
We apply DG-Net~\cite{zheng2019joint} for extracting embedding vectors for detections and train it on visible detections (Eq.~\ref{eq:occlusion-filtering}) obtained by running the proposed pre-clustering algorithm over training video sequences.
Finally, we train three basic multi-layer deep networks for the three networks $f_{\mathrm{split}}$, $f_{\mathrm{spatial}}$, and $f_{\mathrm{temporal}}$ which handle splitting up initial tracklets, generating affinity costs for spatial and temporal edges respectively.

\myparagraph{Lifted Multicut Solver}
For solving the proposed lifted multicut problem (Eq. \ref{eq:proposed-lmp}), we use the efficient GAEC+KLj heuristic solver from~\cite{keuper2015lifted}.
We adapt a two-stage optimization approach. First, the initial tracklets are used as nodes in the tracking graph and compute trajectories through the lifted multicut.
Second, we initialize the computed trajectories again as nodes in the tracking graph and recompute costs to obtain the final trajectories. The second step improves the trajectories computed in the first pass by allowing to compute costs on longer trajectories and joining trajectories together where a connection was not initially detected. For a long-time video, this process can be iterated until converged. More details of our implementations are described in Subsection \ref{sec:implement} Appendix.


\subsection{Datasets \& Metrics}
We perform experiments on three datasets with a wide range of different camera configurations, densities, and video/bounding box qualities.
For all datasets, we use the provided detections for a fair comparison.

\begin{packed_description}
\item[- \normalfont\textit{WILDTRACK}~\cite{chavdarova2018wildtrack}:]
The largest-scale dataset for the multi-camera setting is currently with a dense group of $313$ pedestrians standing and walking.
There is a total of $400$ frames observed from seven cameras that are annotated with 3D positions.
The first $360$ of those frames is used for training and the rest for testing. 
\item[- \normalfont\textit{Campus}~\cite{xu2016multi}:] We have chosen the two sequences \textit{Garden~1} and \textit{Parking~Lot} which had camera calibration parameters and a ground plane for 3D-projection. There are 15 - 25 pedestrians in each video observed by four cameras captured at a 30fps rate.
For each video, we use the first $10\%$ for training and the remaining frames for testing. 
\item[- \normalfont\textit{PETS-09}~\cite{ellis2009pets2009}:]
Contains three sequences with increasing level of difficulty:
low density (S2.L1) - $19$ objects in $795$ frames, medium density (S2.L2) - $43$ pedestrians spreading in $436$ frames and high density (S2.L3) - $44$ pedestrians moving together in $240$ frames.
While PETS-09 is not as dense as WILDTRACK, its main challenge lies in its poor video acquisition conditions with cameras far away from targets and low-quality bounding boxes. 
\end{packed_description}
\vspace{-0.1in}
We report results for the following metrics:
\begin{packed_description}
\item[- \normalfont MOTA~\cite{bernardin2008evaluating}:] the multiple objects tracking accuracy measuring a number of false negatives (FN), false positives (FP), and identity switches (IDs) focusing on the coverage of detections. 
\item[- \normalfont MOTP~\cite{bernardin2008evaluating}:]
the multiple object tracking precision penalizes the overall dissimilarity between true positives and the ground truth objects.
\item[- \normalfont IDF1~\cite{ristani2014tracking}:] 
measure through the F1 score agreement between computed and ground truth trajectories.
\item[- \normalfont MT \cite{li2009learning}:] number of mostly tracked objects for at least $80\%$ of its life span.
\item[- \normalfont ML \cite{li2009learning}:] number of mostly lost objects for at most $20\%$ of its life span.
\end{packed_description}
\subsection{Algorithms}
We compare against state-of-the-art baselines for each respective dataset.
To study the effectiveness of our approach and judge the effectiveness of each proposed component, we run experiments on multiple configurations. All algorithms are listed below.
\begin{packed_description}
\item[\normalfont\texttt{Baselines}:]
For each dataset, we compare against the most recent approaches for which we found experimental results.
In particular, we compare against KPS-DO,  KSP-DO-ptrack  \citep{chavdarova2018wildtrack}, GLMB-YOLOv3, GLMB-DO  \citep{9242263}, DMCT, DMCT Stack \cite{you2020real}, HJMV~\cite{hofmann2013hypergraphs}, STVH~\cite{wen2017multi}, MLMRF~\cite{lan2020semi}, HCT~\cite{xu2016multi}, STP~\cite{xu2017cross}, TRACTA~\cite{he2020multi} and DyGLIP~\cite{quach2021dyglip}.
All baseline performances are taken from the respective original papers. 
\item[\normalfont Our configurations are:]
\item[\normalfont\texttt{- LMGP w/o Pre-Clustering}:] see Section \ref{sec:pre-clustering}.
\item[\normalfont\texttt{- LMGP w/o Tracklet Split}:] no tracklet splitting using information from pre-clustering (Section \ref{sec:spatial-temporal-tracking-graph}, Splitting Tracklets).
\item[\normalfont\texttt{- LMGP w/o Enhanced Affinities}:] do not use pre-clustering in affinity cost computation (Eq. \ref{eq:appearance-affinity},
\ref{eq:pre-clustering-affinity}).
\item[\normalfont\texttt{- LMGP}:] our approach with everything enabled.
For the \textit{Campus} dataset we also provide as comparison \texttt{LMGP-DeepSort} using DeepSort~\cite{wojke2017simple} for generating tracklets.
Note that CenterTrack outperforms DeepSort on single camera benchmarks.
\end{packed_description}

\subsection{Results}
\vspace{-0.1in}
\begin{table}[!hbt]
\scalebox{0.63}{
\begin{tabular}{c|c|c|c|c|c|c|c}
\Xhline{2\arrayrulewidth}
Method& IDF1 $\uparrow$ & MOTA  $\uparrow$ & MT  $\uparrow$   & ML  $\downarrow$  & FP $\downarrow$ & FN $\downarrow$ & IDs $\downarrow$ \\ \Xhline{2\arrayrulewidth}
\small KSP-DO  \citep{chavdarova2018wildtrack}        & 73.2          & 69.6                               & 28.7          & 25.1        & 1095        & 7503        & 85           \\ 
\small KSP-DO-ptrack \citep{chavdarova2018wildtrack} & 78.4          & 72.2                               & 42.1         & 14.6         & 2007        & 5830        & 103          \\ 
\small GLMB-YOLOv3      \citep{9242263}       & 74.3          & 69.7                               & 79.5          & 21.6         & 424         & 1333        & 104          \\ 
\small GLMB-DO     \citep{9242263}      & 72.5          & 70.1                               & 93.6         & 22.8         & 960         & 990         & 107          \\ 
\small DMCT  \citep{you2020real}                   & 77.8          & 72.8                               & 61.0            & 4.9         & 91          & 126         & 42           \\ 
\small DMCT Stack  \citep{you2020real}              & 81.9          & 74.6                               & 65.9          & 4.9          & 114         & 107         & 21           \\ \hdashline
\small LMGP w/o Pre-Clustering             & 79.4     & 73.6                        & 76.4      & 24.3     & 570   & 506  & 76    \\ 
\small LMGP w/o Tracklet Split & 92.4    & 89.7                        & 92.6      & 8.3     & 285  & 119  & 45   \\
\small LMGP w/o Enhanced Affinities & 95.1   & 94.8                         & 95.5       & 5.7      & 95  & 103  & 27   \\
\small LMGP            & \textbf{98.2} & \textbf{97.1}                      & \textbf{97.6} & \textbf{1.3} & \textbf{71} & \textbf{7}  & \textbf{12}  \\ \Xhline{2\arrayrulewidth}
\end{tabular}}
\vspace{-0.1in}
\caption{Our LMGP performance compared to state-of-the-art baselines on \textit{WILDTRACK}.}
\label{tab:multi-wildtrack}
\end{table}
\vspace{-0.2in}
\begin{table}[!hbt]
  \centering
  \scalebox{0.62}{
  \begin{tabular}{c|c|c|c|c|c|c}
\Xhline{2\arrayrulewidth}
   \multicolumn{1}{c|}{Sequence}   & \multicolumn{1}{c|}{Method} & \multicolumn{1}{c|}{MOTA $\uparrow$} & \multicolumn{1}{c|}{MOTP $\uparrow$} & \multicolumn{1}{c|}{MT $\uparrow$} & \multicolumn{1}{c|}{ML $\downarrow$} &
     \multicolumn{1}{c}{IDs $\downarrow$}\\ \Xhline{2\arrayrulewidth}
     \multirow{5}{*}{\STAB{\rotatebox[origin=c]{0}{S2-L1}}}
     & HJMV  \citep{hofmann2013hypergraphs}                   &   91.7                        &     79.4                      &  94.7                         &  \textbf{0.0 }                      & 45 \\
     & STVH   \citep{wen2017multi}              &   95.1                        &          79.8                  &  \textbf{100.0}                         &  \textbf{0.0 }                      & 13  \\
     & MLMRF      \citep{lan2020semi}               &  96.8                         &       79.9                    &  \textbf{100.0}                        &   \textbf{0.0 }                    & \textbf{2} \\ 
\hdashline
     & LMGP w/o Pre-Clustering                     &                  97.5       &        79.6                     &  96.3                         &   \textbf{0.0}                       & 6 \\
     & LMGP w/o Tracklet Split                      &    97.3                       &         82.1                  &                       97.2    &    \textbf{0.0}                      & 6 \\
     & LMGP w/o Enhanced Affinities                     &  97.6                         &    82.1                       &     98.1                     &        \textbf{0.0}                & 4 \\
     & LMGP                      &   \textbf{ 97.8}                     &          \textbf{82.4}                  &      \textbf{100.0}                     &   \textbf{0.0 }                      & \textbf{2} \\\Xhline{2\arrayrulewidth}

          \multirow{5}{*}{\STAB{\rotatebox[origin=c]{0}{S2-L2}}}
     & HJMV  \citep{hofmann2013hypergraphs}                &   58.9                       &    66.0                         &  30.2                         &  2.3                      & 388  \\
     & STVH   \citep{wen2017multi}                       &     65.2                       &     61.8                    &  44.2                         & \textbf{ 0.0 }                       & 249  \\
     & MLMRF      \citep{lan2020semi}                  &      \textbf{ 72.1 }                  &     58.3                   &    \textbf{72.1 }                     &     2.3                     & 142 \\ \hdashline
     & LMGP w/o Pre-Clustering                      &                  66.8        &            64.3                &   67.4                        &    2.1                      &  158 \\
     & LMGP w/o Tracklet Split &    70.1                       &    68.5                       &             67.2              &    2.1                      & 97 \\
     & LMGP w/o Enhanced Affinities                      &  71.6                       &  \textbf{73.2 }                        &   68.2                       &   2.0                       & 81 \\
     & LMGP                               &  70.4   &    \textbf{73.2}                          &       69.6                    &      1.7                  & \textbf{75}\\\Xhline{2\arrayrulewidth}
          \multirow{5}{*}{\STAB{\rotatebox[origin=c]{0}{S2-L3}}}
& HJMV  \citep{hofmann2013hypergraphs}              &   40.2                        &   49.5               &  29.6                         &  25.0                     & 123 \\
     &STVH   \citep{wen2017multi}                & 49.8                        &        63.0                   &    29.6                       &      20.5                    &   92\\
     & MLMRF      \citep{lan2020semi}                & \textbf{54.4}                         &    54.9                         &   36.4                        &      6.8                    & 82 \\
\hdashline
     & LMGP w/o Pre-Clustering                     &     49.1                     &      55.7                      & 33.2                          &    13.6                      &  92 \\
     & LMGP w/o Tracklet Split                       & 52.7                          &   63.6                         &      33.4                     &   11.2                       & 86 \\
      & LMGP w/o Enhanced Affinities                      &         53.5                 &     64.7                     &    31.8                      &          8.7                & 82 \\
     & LMGP                      &              \textbf{54.4 }             &           \textbf{66.5}               &   \textbf{40.2}                        &  \textbf{5.3 }                       & \textbf{78}\\ 
\Xhline{2\arrayrulewidth}
\end{tabular}}
\vspace{-0.1in}
\caption{Our LMGP performance compared to other baselines in \textit{PETS-09}.}
\label{tab:pets09}
\end{table} 
\vspace{-0.2in}
\begin{table}[!hbt]
  \centering
  \scalebox{0.65}{
  \begin{tabular}{c|c|c|c|c|c}
\Xhline{2\arrayrulewidth}
   \multicolumn{1}{c|}{Sequence}   & \multicolumn{1}{c|}{Method} & \multicolumn{1}{c|}{MOTA $\uparrow$} & \multicolumn{1}{c|}{MOTP $\uparrow$} & \multicolumn{1}{c|}{MT $\uparrow$} & \multicolumn{1}{c}{ML $\downarrow$} \\ \Xhline{2\arrayrulewidth}
     \multirow{5}{*}{\STAB{\rotatebox[origin=c]{0}{Garden 1}}}
     & HCT  \citep{xu2016multi}                   &   49.0                       &     71.9                     &  31.3                         &  6.3                     \\
     & STP   \citep{xu2017cross}              &   57                       &          75                  &  -                       & -                \\
     & TRACTA      \citep{he2020multi}               &  58.5                        &       74.3                    &  30.6                        &   1.6              \\ 
      & DyGLIP      \citep{quach2021dyglip}               &  71.2                      &       91.6                   &  31.3                        &   \textbf{0.0 }                   \\ 
     \hdashline
      & LMGP-DeepSort                    &   75.6                     &          93.4                 &      46.7                     &   1.6                      \\
     & LMGP                      &   \textbf{ 76.9}                     &          \textbf{95.9}                  &      \textbf{62.9}                     &   1.6                      \\\Xhline{2\arrayrulewidth}
          \multirow{5}{*}{\STAB{\rotatebox[origin=c]{0}{Parking Lot}}}
     & HCT  \citep{xu2016multi}                &   24.1                      &    66.2                         &  6.7                         &  26.6                     \\
     & STP   \citep{xu2017cross}                       &     28                       &     68                    & -                      & -                \\
     & TRACTA      \citep{he2020multi}                  &     39.4              &     74.9                   &   15.5                   &     10.3                 \\ & DyGLIP      \citep{quach2021dyglip}               &  72.8                         &       \textbf{98.6}                  &  26.7                        &   \textbf{0.0 }                   \\ 
     \hdashline
      & LMGP-DeepSort                             &  76.7   &    98.0                       &       51.7                    &    5.1         \\
     & LMGP                               &  \textbf{78.1}   &    97.3                       &       \textbf{62.1}                    &     \textbf{0.0  }          \\\Xhline{2\arrayrulewidth}
  \end{tabular}}
\vspace{-0.1in}
\caption{Our LMGP performance compared to other baselines on \textit{Campus}.}
\label{tab:campus}
\end{table} 
\vspace{-0.2in}
We report quantitative results for \textit{WILDTRACK} in Table~\ref{tab:multi-wildtrack}, for \textit{PETS-09} in Table~\ref{tab:pets09}  and  for \textit{Campus} in Table~\ref{tab:campus}.
Some qualitative results are presented in Figures~\ref{fig:qualitative-results},\,\ref{fig:qualitative-results-campus} Appendix.

On \textit{WILDTRACK} we obtain almost perfect metric scores with \texttt{LMGP}. Our results on \textit{Campus} significantly outperform the state-of-the-art on both sequences even when using weak tracklets (DeepSort).
On \textit{PETS-09} we achieve comparable results.
We argue that the differing performance of our algorithms is mostly due to poor bounding boxes and camera calibration for \textit{PETS-09} and, to a lesser extent, for \textit{Campus}.
\subsection{Efficacy of Individual Components \& Ablations}
\label{sub:ablation-study}
To assess the performance of individual parts in our approach and their contribution to our overall performance, we give more experimental details.

\myparagraph{Ablations w.r.t.\ Pre-Clustering/Enhanced Affinities/Tracklet Splitting}
In Tables~\ref{tab:multi-wildtrack} and~\ref{tab:pets09} we report results of the ablated versions \texttt{LMGP w/o Pre-Clustering}, \texttt{LMGP w/o Tracklet Split} and \texttt{LMGP w/o Enhanced Affinities} of our solver. 
In most cases (except for \textit{S2-L1} of \textit{PETS-09}, where nearly perfect results can be obtained with any baseline), we see significant improvements w.r.t.\ all ablated versions of our solvers, validating the efficacy of all steps. 
\textit{The greatest performance drop can be observed by turning of the pre-clustering}, showing its important role for obtaining improved results.
More fine-grained ablations for the enhanced affinity costs can be found in Table~\ref{tab:temporal-costs-performance} and~\ref{tab:spatial-costs-performance} Appendix.

\myparagraph{Pre-Clustering Accuracy}
In Figure~\ref{fig:result-2Dclustering}, we report performance of our Pre-Clustering (Section~\ref{sec:pre-clustering}) for all considered datasets.
Since our Pre-Clustering is purely based on geometry, we also see experimentally that its performance is dependent upon the accuracy of bounding box coordinates.
In the high-quality \textit{WILDTRACK} dataset, we obtain almost perfect results.
For \textit{Campus} and \textit{PETS-09} we achieve precision higher than $80\%$.
We argue that the \textit{confident connection} in our pre-clustering helps in these more challenging and noisy settings.
More details on the reduction of ID-switch errors can be found in Table~\ref{tab:center-tracktor} Appendix.
\vspace{-0.15in}
\begin{figure}[!hbt]
\centering
\includegraphics[width=0.38\textwidth]{./imgs/Pre-Clustering_Performance_v2}
\vspace{-0.15in}
\caption{Our pre-clustering performance measured by accuracy, precision and recall w.r.t.\ correctly estimated correspondences between detections across cameras. On the top we give the total detections of objects in each dataset.
}
\label{fig:result-2Dclustering}
\vspace{-0.2in}
\end{figure}

\myparagraph{Joint Optimization Model}
In order to assess the performance of our joint spatio-temporal optimization model (Eq.\ref{eq:proposed-lmp}) as compared to a stage-wise optimization, we provide an experiment in  Table~\ref{tab:joint-spatial-temporal-optimize}.
The variant \texttt{LMGP w/o spatial edges} first solves an ordinary single view MOT problem. After obtaining computed single-camera trajectories, they are linked across cameras in a second step. To validate the effect of lifted long-range edges vs. a simpler model without them, we also provide an ablation \texttt{LMGP w/o lifted edges}. These ablations are tested on \textit{WILDTRACK} and \textit{S2-L1} of \textit{PETS-09}. The results 
indicate that significant improvement can be gained by optimizing jointly over temporal and camera affinities, especially in dense scenes like WILDTRACK. Also, the long-range edges contribute to better performance in both cases.
\begin{table}[!hbt]
\vspace{-0.1in}
  \centering
  \scalebox{0.6}{
  \begin{tabular}{c|c|c|c|c|c|c}
\Xhline{2\arrayrulewidth}
    \multicolumn{1}{c|}{\small Dataset} & \multicolumn{1}{c|}{\small Method } & \multicolumn{1}{c|}{\small MOTA $\uparrow$} & \multicolumn{1}{c|}{\small IDF1 $\uparrow$} & \multicolumn{1}{c|}{\small MT $\uparrow$} &
    \multicolumn{1}{c|}{\small ML $\downarrow$} &
    \multicolumn{1}{c}{\small IDs $\downarrow$}\\ \Xhline{2\arrayrulewidth}
     \multirow{2}{*}{\STAB{\rotatebox[origin=c]{0}{\small{\textit{WILDTRACK}} 
     }}}
     & \small {LMGP full}                      &   \textbf{97.1}                        &  \textbf{98.2}                         &  \textbf{97.6}                         &  \textbf{1.3}                   &  \textbf{12} \\
       & \small{LMGP w/o lifted edges}                      &   95.4                        &  96.4                         &  93.6                         &  2.7                  & 41  \\
     & \small{LMGP w/o spatial edges}                      &   93.2                        &  94.1                         &  91.7                         &  6.9                  & 85  \\
 \hline
          \multirow{2}{*}{\STAB{\rotatebox[origin=c]{0}{\small{\textit{S2-L1}}}}}
     & \small{LMGP full}                      &     \textbf{97.8}                      &  \textbf{82.4}                         &  \textbf{100.0}                        &  \textbf{0.0}                   &   \textbf{2}  \\
       & \small{LMGP w/o lifted edges}                      &  96.2                        &  81.1                         &  98.7                         &  1.3                    & 5 \\
     & \small{LMGP w/o spatial edges}                      &  95.6                        &  80.2                         &  98.7                         &  1.3                    & 8 \\
\Xhline{2\arrayrulewidth}
  \end{tabular}}
  \vspace{-0.1in}
  \caption{An ablation study of different edge types}
  \label{tab:joint-spatial-temporal-optimize}
\end{table} 
\vspace{-0.25in}
\subsection{Discussion}
We have demonstrated that nearly perfect multiple object tracking results can be obtained in crowded scenes given the right conditions (as for \textit{WILDTRACK}), i.e.\ high bounding box quality and a large enough number of well-calibrated cameras observing the same scene.
Even when these conditions are not met, as in \textit{Campus} and \textit{PETS-09} which use old detectors, our \texttt{LMGP} still delivers better results than competitors in most cases.
Specifically, the \textit{pre-clustering is crucial in our framework} because it allows exploiting multi-camera information through repairing efficiently trajectories computed by single-camera trackers and can be used to enhance affinity costs.
Also, our lifted multicut model jointly optimizing over inter- and intra-camera affinities, short- and long-range interactions is essential and can effectively correct erroneous associations and continue trajectories which would be lost when only a single camera is used and severe occlusions are present.





































































%
