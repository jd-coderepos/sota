\documentclass[11pt, letterpaper]{article}
\usepackage{amssymb}
\usepackage{amsmath}
\usepackage{amsthm}
\usepackage[title]{appendix}
\setcounter{tocdepth}{3}
\usepackage{graphicx}
\usepackage{fullpage}
\usepackage{color}
\usepackage[letterpaper]{geometry}
\geometry{left=1in,right=1in,top=1in,bottom=1in}



\newtheorem{lemma}{Lemma}
\newtheorem{theorem}{Theorem}
\newtheorem{observation}{Observation}
\newenvironment{oldthm}[1]{\par\noindent{\bf Theorem #1:} \em \noindent}{\par}
\newenvironment{oldlem}[1]{\par\noindent{\bf Lemma #1:}
  \em \noindent}{\par}
\newenvironment{oldcor}[1]{\par\noindent{\bf Corollary #1:} \em \noindent}{\par}
\newenvironment{oldpro}[1]{\par\noindent{\bf Proposition #1:} \em \noindent}{\par}

\newcommand{\ethm}{\end{theorem}}
\newcommand{\commentout}[1]{}
\newcommand{\othm}[1]{\begin{oldthm}{\ref{#1}}}
\newcommand{\eothm}{\end{oldthm} \medskip}
\newcommand{\olem}[1]{\begin{oldlem}{\ref{#1}}}
\newcommand{\eolem}{\end{oldlem} \medskip}
\newcommand{\ocor}[1]{\begin{oldcor}{\ref{#1}}}
\newcommand{\eocor}{\end{oldcor} \medskip}
\newcommand{\opro}[1]{\begin{oldpro}{\ref{#1}}}
\newcommand{\eopro}{\end{oldpro} \medskip}





\setlength{\parskip}{.5ex}
\def\beginsmall#1{\vspace{-\parskip}\begin{#1}\itemsep-\parskip}
\def\endsmall#1{\end{#1}\vspace{-\parskip}}

\usepackage{url}


\urldef{\mailt}\path|chhaya.dhingra@gmail.com|
\urldef{\mailv}\path|h.vandierendonck@qub.ac.uk|
\urldef{\mailk}\path|G.Karakonstantis@qub.ac.uk|
\urldef{\mailn}\path|d.nikolopoulos@qub.ac.uk|
\newcommand{\keywords}[1]{\par\addvspace\baselineskip
\noindent\keywordname\enspace\ignorespaces#1}

\begin{document}



\title{Energy optimization of memory intensive parallel workloads\thanks{Regular Paper}}
\date{Queen's University of Belfast, Belfast, UK}




\author{Chhaya Trehan \thanks{\mailt (Corresponding Author)} \and Hans Vandierendonck\thanks{\mailv} \and Georgios Karakonstantis\thanks{\mailk}\and Dimitrios S. Nikolopoulos\thanks{\mailn}}








\begin{titlepage}
\maketitle


\begin{abstract}
Energy consumption is an important concern in modern multicore processors. The energy consumed during the execution of an application can be minimized by tuning the hardware state utilizing knobs such as frequency, voltage etc. The existing theoretical work on energy minimization using Global DVFS (Dynamic Voltage and Frequency Scaling), despite being thorough, ignores the energy consumed by the CPU on memory accesses and the dynamic energy consumed by the idle cores. This article presents an analytical model for the performance and the overall energy consumed  by the CPU chip on CPU instructions as well as the memory accesses without ignoring the dynamic energy consumed by the idle cores. We present an analytical framework around our energy-performance model to predict the operating frequencies for global DVFS that minimize the overall CPU energy consumption within a performance budget. Finally, we suggest a scheduling criteria for energy aware scheduling of memory intensive parallel applications.
\end{abstract}
\end{titlepage}

\section{Introduction}
While Silicon is available in abundance to build processors, the energy required to power them is not. Energy consumption and performance turn out to be the two most important and contradicting design criteria for the modern multicore processors~\cite{EnergyCost1, EnergyCost2, EnergyCost3}. The practice of dealing with the two contradicting goals by optimizing one while imposing a threshold on the other leads to two flavors of energy-performance optimization called the \emph{laptop problem} and the \emph{server problem}. In the laptop problem, the goal is to maximize the performance given a fixed energy budget and in the server problem, the goal is to minimize the energy consumption given a fixed performance budget~\cite{ServerLaptopProblem, ServerProblem}. We deal with the \emph{server problem} in this article.

 The energy consumed by a CMP(Chip Multi Processor) is an increasing function of the operating voltage and frequency of the chip and can be reduced by reducing one of them. Dynamic Voltage and Frequency Scaling (DVFS) is thus a popular energy minimization technique for multicore platforms.


While the raison d'etre of a multicore platform is to maximize the performance by maximizing the parallelism, the inherent parallelism of a workload is not easy to determine. It is thus becoming increasingly common to divide an application into a set of parallel tasks with precedence constraints so as to make the possible parallelism explicit. We consider a \emph{task dependency graph}~\cite{TaskGraphs1, TaskGraphs2} as our model for the workload. Often when we think of parallelism, we think of performance gains and we tend to ignore its ramifications on energy consumption. The fact that we can gain performance by increasing parallelism allows one to save energy by reducing frequency without violating a performance constraint. Gerards et al formalized the problem of energy consumption for task graphs in their recent article~\cite{ConvexAndScheduling} and studied the interplay between global DVFS and scheduling of parallel applications to minimize the CPU energy consumption. An interesting find of their work is that using a single clock frequency during the execution of an application does not lead to optimal energy consumption and they present an approach for varying the frequency during execution to minimize energy. The frequency is varied according to the variations in the amount of parallelism and a separate frequency is assigned to each number of active cores (parallelism).

The analytical model of~\cite{ConvexAndScheduling} for energy consumption and performance, however, completely ignores the energy consumed by the CPU while it waits for data accesses to the main memory. Since it does not account for the time overhead of the access latency of memory, it can lead to an imprecise estimate of the slack between the time to completion and the given performance budget. The CPU energy optimization techniques that save energy by decreasing the operating frequencies of the cores at the cost of an increased delay need to be tuned to account for the memory access latencies. Precisely accounting for the memory access delays of the application helps exploit the slack and avoids an over optimistic selection of operating frequencies. Another assumption in~\cite{ConvexAndScheduling} is that the frequency of the idle cores can be brought down to zero by techniques like clock gating. This is not always possible in reality, the idle cores can't be completely shut down and  do consume some  dynamic energy. In this article, we present a new model for the energy and performance of multicore systems that accounts for the energy consumed by the CMP while waiting for memory accesses in addition to the energy consumed on CPU instructions without ignoring the dynamic energy consumed by the idle cores. We provide an analytical framework around our energy-performance model to predict the operating frequencies for global DVFS to minimize the overall CPU energy consumption of a given application.

\paragraph{Related Work:}
A common approach to reduce the energy consumption of an application is to reduce the operating frequency of the cores~\cite{DVFS, DVFS2, DVFS3} which incurs a cost in terms of increased execution time. Most of the theoretical work on the energy-delay trade off deals with the \emph{local} DVFS~\cite{Local1, Local2, Local3}, where every core's voltage and frequency can be set separately. We study the problem of energy minimization under a performance constraint using global DVFS where the voltage and frequency are set for the entire chip. While local DVFS has more freedom in choosing clock frequencies and can therefore save more energy, it is not easy to implement~\cite{GlobalEasy}. Global DVFS being easier and cheaper to implement leads to much simpler and practical algorithms for choosing the frequencies for energy optimization problem. The relationship of parallelism with energy and performance was first studied by Sangyeun and Melhem in~\cite{ParallelizationEnergy}.  In their recent paper, Gerards et al~\cite{ConvexAndScheduling} show that using a single clock frequency during the execution of a \emph{parallel} application with precedence constraints does not lead to optimal energy consumption and present an approach for varying the frequency during execution to minimize energy. Li in his pioneering work~\cite{LiSchedulingAndEnergy} presents heuristic algorithms for energy optimization that treat scheduling and frequency selection as two independent subtasks performed one after the other. Further, Gerards et al~\cite{ConvexAndScheduling} show that the tasks of determining a schedule and frequencies that together minimize the energy consumption should not be considered separately and study the relation between the two. They define a scheduling criterion for energy optimization and show how to determine frequencies that minimize energy consumption. They characterize a schedule in terms of \emph{parallelism}, which gives for each number of cores the number of clock cycles 
for which exactly that many cores are active. Given a schedule, this model abstracts from the tasks and their precedence constraints and determines a clock frequency for each "number of active cores''.






\paragraph{Outline of the paper:}
The rest of the paper is organized as follows. Section~\ref{Model} describes the system, the application and the power model under consideration. Section~\ref{EnergyOptimizationProblem} formulates the energy optimization problem as a constrained convex optimization problem. Section~\ref{AffectMemoryAccesses} describes how memory accesses of a given application affect the optimal frequencies for energy optimization. In Section~\ref{SelectionScheduling}, we give analytical formulas for optimal frequencies for memory intensive workloads. Finally, Section~\ref{Conclusion} concludes the paper along with some research questions for future.
\section{Model}\label{Model}
Our application and system model is similar to the one presented in~\cite{ConvexAndScheduling}. 
The model presented here differs from that of~\cite{ConvexAndScheduling} in considering the memory accesses as being part of workload and the treatment of idle cores.
\paragraph{Application:}
We consider an application running on a multicore processor. The application itself consists of a set  of  tasks, denoted by . We consider an overall deadline  for the entire application. A task  is characterized by two attributes, namely: the \emph{compute workload:}  and the \emph{data workload} . The compute work load is the number of clock cycles required to perform the computations of the task. The data workload is the number of memory accesses a task has to make during its execution. We assume an application wide parameter called \emph{data to CPU} quotient  which is the ratio of data to compute workloads of the application. It can be viewed as the number of memory accesses per CPU instruction cycle of the application. For a task  with compute workload of , its data workload can be inferred as the product of  and . We assume that the memory accesses of a task are distributed uniformly throughout the task.
The application can be depicted as a labeled DAG (Directed Acyclic Graph) where nodes represent the tasks and the (\emph{Directed}) edges represent the precedence constraints (Figure~\ref{figure:TaskDependenyGraph} in Appendix). Each node carries a label depicting the CPU workload  of the associated task. 


\paragraph{Computing Platform:} The Application runs on a Chip Multiprocessor system with  homogeneous processing cores. All the cores have similar capabilities and run at the same frequency. Instead of using a single frequency throughout the application, we assume that the frequency can be changed at any time. We assume a frequency function  which maps a given point in time to the frequency to be used at that time. Unlike~\cite{ConvexAndScheduling}, we do not assume that the frequency of inactive cores can be brought down to zero using clock gating. Therefore, one can not ignore the dynamic power consumption of inactive cores. We instead assume that the inactive cores run at the same frequency as the active cores, but their average activity factor is much less compared to the active cores. 


\paragraph{Power:}
As is common in literature, we consider two components of power, the \emph{dynamic power} and the \emph{static power}. Assuming  is the frequency of all the cores at some time , the dynamic power of an active core at time  can be expressed as an increasing function of frequency as follows:

The constant  is a characteristic of the computing platform and the exponent  is a constant().
At any given point in time, an inactive core consumes relatively less dynamic power owing to its reduced activity factor. We model this difference in dynamic power of active and inactive cores by assuming that the constant  for inactive cores is less than the  for active cores.
Assuming  to be the constant for inactive cores such that the ratio , the dynamic power of an inactive core can be expressed as:

The static power which is a function of voltage can also be expressed as an affine function of frequency (since voltage and frequency are almost linearly related) as follows:

At a given point in time, with  active cores running at an operating frequency of , the total power of the processor chip can be expressed as:

where  is the total number of cores on the chip.
Expressing  as , the equation for the total power with  cores active at frequency  is:

This is a convex and increasing function in . From this point on, we will denote  as  for the sake of brevity. 
Dividing equation~\ref{PowerEquation} on both sides by  gives energy per CPU cycle which we will denote as   henceforth



In~\cite{ConvexAndScheduling}, Gerards and others use the convex nature of the power function to prove that for an interval during which a constant number of cores are active, a constant frequency is optimal in terms of energy consumption. 


Before we go into the details of selecting the optimal frequencies in our model, we take a short diversion to understand what an interval  in our model looks like and how the presence of  memory accesses during an interval change the dynamics of energy optimization. In any interval during the execution in our model, all the active cores are performing some memory accesses uniformly interleaved with the CPU instruction cycles. Therefore, not all of the CPU cycles produced during such an interval can be counted towards the work done (instructions) by the CPU. Moreover the time spent on memory accesses is independent of frequency whereas the time spent on executing the instructions can be increased (decreased) by decreasing (increasing) the frequency.  DVFS schemes for energy optimization exploit this ability to stretch an interval by decreasing the frequency to minimize energy consumption at the cost of increased delays. An interval with memory accesses can be thought of as composed of many springs with some rigid material placed between them. Applying a force (a change in frequency) can only compress or decompress the springs and the rigid material (memory accesses) does not yield at all to the changes in frequency. Only a portion of interval containing instruction cycles and memory accesses can be stretched by decreasing the frequency thus leading to a lesser potential for reduction in energy by decreasing the frequency. Coming back to the question of the optimal frequencies for an interval in our model during which a fixed number of cores are active, one can divide such an interval into many CPU only intervals separated by memory accesses stacked between them. Applying Lemma 1 of~\cite{ConvexAndScheduling} on each such interval, we deduce that we can use the same constant clock frequency during each such CPU only intervals. What we are left to decide is the frequencies to be used during memory accesses. We may wish to bring the frequency further down during these portions of the interval to get some energy savings. But the assumption that the memory accesses are uniformly interleaved throughout does not leave much room for reduction as the overhead of changing the frequency uniformly throughout the interval can offset the potential energy savings. We therefore stick to the idea of using a constant frequency for an interval during which a fixed number of cores are active.
\paragraph{Parallelism and Energy-Performance model:}
 The overall energy consumption of an application can be expressed in terms of the amount of parallelism. In interest of brevity, we refer the reader to go through~\cite{ConvexAndScheduling} to fully appreciate the concept of power modeling in terms of parallelism. For an application with  tasks running on a processor with  cores, its amount of parallelism for a given schedule can be defined formally  as a vector , where  is the total number of CPU cycles for which exactly  cores are active. Using the idea that a constant frequency for a fixed number of cores (parallelism) leads to an optimal energy consumption,the task of global DVFS for energy optimization is reduced to finding a vector  of frequencies where  is the optimal frequency to be used when  cores are active. Energy consumed when  cores are active can be expressed as the product of energy per cycle  from equation\ref{EnergyPerCycleEquation} and .
 Thus the total energy consumption of the application without considering the memory accesses can be expressed as:
   
For a given amount of parallelism  ,  accesses to memory are made, where  is the application wide data to CPU workload ratio. The CPU keeps clocking at a frequency  for the duration of these  memory accesses. If  is the latency of memory accesses,  is the duration for which the CPU waits for memory accesses. The additional cycles expended per core on memory accesses for  is thus  . Replacing  with  in the energy equation~\ref{EnergyNoMemory} leads to a new energy equation that accounts for the CPU energy consumed not only on the actual CPU work done but also the addition clock cycles expended on waiting for the memory accesses. 

 
  The time to completion of an application for a given schedule can also be expressed in terms of parallelism. The time taken when considering memory accesses has a frequency dependent and a constant component. The constant component of the time to completion is the memory overhead of the application. The time to completion in terms of parallelism is:
  
 
\section{Energy Optimization}\label{EnergyOptimizationProblem}
Given an application and its schedule, the problem of energy optimization under a performance constraint can be formulated as one of finding an optimal set of frequencies,   corresponding to the parallelism, . Denoting as , the deadline or the performance constraint of the application, the problem of energy minimization can be expressed as: 

Substituting the energy per cycle function  in equation~\ref{OptimizationFirst} with its expansion in equation~\ref{EnergyPerCycleEquation}, we get:

 Note that the decision variable  can only take positive values, i.e. , thus making both the objective function and the constraint of the optimization problem(equation~\ref{TotalEnergyFrequecy}) convex~\cite{Boyd}. The solution to this problem is only a matter of typing in a few lines of code in any convex optimization solver.
\section{Memory accesses and the optimal frequencies}\label{AffectMemoryAccesses}
 The main goal of this work is to study the effect of memory accesses on CPU energy consumption and how does their presence alter the optimal frequencies. 
Gerards et al show in~\cite{ConvexAndScheduling} that for any given number of active cores , the frequency  is inversely proportional to . In this section, we will investigate how do the optimal frequencies relate to the memory intensity (data to CPU workload ratio, ) of an application and whether and how the relationship between optimal frequencies and the number of active cores change in the presence of memory accesses. Recall that in addition to  accounting for the energy consumption on memory accesses, we also account for the dynamic energy consumed by idle cores in our model.
 
 \begin{lemma}\label{UnconstrainedOptimization}
  On a given hardware platform the unconstrained minimizer  of energy is same for all the applications with a fixed data to CPU workload ratio.
 \end{lemma}
\begin{proof}
The unconstrained optimization problem is:
 
According to the optimality condition for unconstrained convex function~\cite{Boyd}, Gradient  at the optimal point. Due to the separable nature of the objective function, one can easily get optimal  for  active cores by equating to zero the derivative of  summand of the objective w.r.t. .
 One can get  by: 
 
 
 thus,  can be obtained by solving the following polynomial:
  
 The workload term  gets canceled out. The only characteristic of the application in this polynomial is its memory intensity , all other terms in the coefficients are characteristics of the underlying hardware on which the application runs. Hence all applications with a given memory intensity  running on a given hardware platform will have same optimal value for . The same holds true for all the other frequencies.
\end{proof}
A deadline constraint can change the optimal frequencies if the unconstrained minimizer does not meet the deadline. The frequencies however should have some relationship to each other based on their relative number of active cores (parallelization).

\begin{theorem}\label{TheoremRange}
It holds for every pair  such that  and  that:
 \begin{enumerate}
 \item for an optimal solution  to the constrained energy optimization problem (equation~\ref{TotalEnergyFrequecy}),  lies in the interval .
  \item for an optimal solution  to the constrained energy optimization problem without the static energy,
   lies in the interval .
 \end{enumerate}
\end{theorem}
\begin{proof}
 For an arbitrary pair  with , both  and  are positive, hence there exists a positive constant  such that .
 Let  be the total time for which  or  cores are active. One can increase one of  or  and decrease the other such that the total time , remains constant. 
 The total time  can be expressed in terms of  and  as:
 
Substituting  for  each of  and  can be expressed as a function of  as follows:


Let  be the total energy consumed by the CPU during the time .

Rearranging the terms, we get:

As highlighted in equation~\ref{EnergyNMParts}, the total energy  is composed of three components, the first two terms constitute the CPU energy consumed on the memory accesses, the next two terms constitute the CPU energy consumed on CPU instructions and rest of the terms constitute the static energy which is independent of number of active cores.
Note that each of the three components is convex and nondecreasing in , and  and  are convex~\cite{Boyd} in , thus making these components convex functions of .
We can therefore find the optimal ratio  which minimizes the total energy , by evaluating 



Making , we get:

Making the first component of~\ref{MinimzerParts} labeled `Memory Accesses' zero, we get  that minimizes the energy spent on memory accesses. Similarly making the  second and the third components of equation~\ref{MinimzerParts} labeled `CPU instructions' and `Static Energy' zero respectively, we get  that minimizes the energy spent on CPU instructions and  that minimizes the static energy respectively.
Let us represent by ,  and , the values of  that minimize the energy consumed on memory accesses, CPU instructions and static energy respectively.
Thus we have, , ,  .
Since each of the three components of  are convex in  with each having a unique minimum different from the other two, the minimizer of the total energy lies somewhere in the interval ~\cite{Boyd}. Since we assumed that , the minimizer of total energy lies in the range .
Dropping the component for static energy in~\ref{MinimzerParts}, we get the sum of the  dynamic energy consumed by the CPU on memory accesses and CPU instructions respectively and its minimizer lies in the range .
\end{proof}
The implication of theorem~\ref{TheoremRange} is that the presence of memory accesses affects the frequency selection in two ways. First the memory accesses add to the CPU energy consumption a dynamic component which increases more sharply with frequency than the dynamic energy consumed on CPU instructions, thus pushing the optimal ratio further away. Second, it adds to the total energy consumption a static component that varies linearly with frequency and this component is minimized when . The minimizer of the overall energy tends to be closest to the minimizer of the most dominating component in the mix. It is well known that the static energy despite being an unavoidable portion of the overall energy is a much smaller component of the total energy compared to the dynamic energy.
In rest of this section, we focus our attention on the dynamic energy component of the overall energy.

\begin{lemma}\label{Relation}
for an optimal solution  to the constrained energy optimization problem(equation~\ref{TotalEnergyFrequecy}) without the static energy, the following holds for every pair  with :\\
 
\end{lemma}
 Refer the Appendix for the proof. \\
This Lemma shows the relationship between the frequencies for two different parallel regions of a given schedule of an application. This is in contrast to the corresponding relationship in~\cite{ConvexAndScheduling}, which is, . 


Having a relationship between the optimal frequencies for different parallel regions of a schedule, the next natural step is to be able to analytically relate an optimal frequency for a parallel region to the optimal frequency of the serial region.  Lemma~\ref{CubicEquation} gives such a relation for . 


\begin{lemma}\label{CubicEquation}
 For , the ratio , of the optimal frequency  for a parallel region of the schedule with  active cores and the optimal frequency  for the serial region is a solution to the following cubic equation:
 
 where  is a constant equal to 
\end{lemma}
Refer the appendix for the proof.\\
Note that it is possible for a schedule to have no serial region at all (). The purpose of expressing  in terms of  and  is to help understand by how much does the frequency for a given parallelization differ from . One can think of  as a \emph{reference frequency} for a given hardware and application combination such that each of the optimal parallel frequencies  is related to  by a multiplicative factor .
Coming back to equation~\ref{RelativeCritical}, the coefficient of the cubic term is a product of the parallelization , the memory characteristic  of the workload and the critical serial frequency  and the memory intensity of the application. For the sake of analysis, we call the term , the memory overload factor. 
Plotting  against the memory overload factor, (Figure~\ref{figure: ReductionRatio} in Appendix), one can observe that as   changes from  to , the optimal ratio changes very quickly and attains the mid point of  and  and then it changes more slowly and later becomes almost constant close to . So, as memory overhead increases, the optimal frequency for  active cores tends to be inversely proportional to . Without accounting for the memory accesses or for CPU intensive applications on the other hand the optimal frequency for  active cores is inversely proportional to . Thus accounting for memory accesses does not allow as much reduction in frequencies for parallel regions as predicted by the model in~\cite{ConvexAndScheduling}. 
This confirms that the energy savings predicted by~\cite{ConvexAndScheduling} are over optimistic especially in the case of memory intensive applications (with a high memory intensity, ) running on a slow hardware (with a high access 
delay, ) on a tight performance budget (with a high critical frequency, ).
In general, from theorem~\ref{TheoremRange} and generalizing the above exposition, it can be established that the optimal frequency for  active cores for a memory intensive application (with  sufficiently large) is inversely proportional to .

\section{Frequency Selection and Scheduling criteria for memory intesive workloads}\label{SelectionScheduling}
In this section, we look at the problem of frequency selection for a memory intensive application analytically to investigate the relationship between optimal frequencies and the distribution of workload or schedule of the application. As demonstrated in Section~\ref{AffectMemoryAccesses}, the optimal frequency  for a memory intensive application considering only the dynamic energy is inversely proportional to  and one can consider the existence of a reference frequency such that each of the optimal frequencies can be expressed as a product of  and the reference frequency. Let us denote the reference frequency by . Substituting  with  in the dynamic energy only part of optimization problem given in equation~\ref{TotalEnergyFrequecy}, we get



where  .
One can apply the KKT conditions~\cite{Boyd} on the above convex optimization problem to find an analytical formula for the optimal reference frequency. The optimal reference frequency for dynamic energy is:

Refer Lemma~\ref{DynamicOptimizer} in the appendix for the proof.

If one were to minimize the total energy consumption including the static energy, the optimal ratio  would lie between  and  (Theorem\ref{TheoremRange}). Since static energy is only a small portion of the overall energy, we can assume . Substituting   with  in equation~\ref{TotalEnergyFrequecy} and applying KKT conditions we get:

where  and \\

 Refer Lemma~\ref{TotalOptimizer} in the appendix for the proof.
 
\paragraph{Schedule}
We should make an observation about the \emph{makespan}~\cite{Brucker} (commonly used as a performance measure of scheduling algorithms). Gerards et al show in~\cite{ConvexAndScheduling} that defining the makespan of an application as the number of CPU cycles required, instead of the time required to run the application ()  gives us a definition independent of frequency. Accounting for the CPU cycles produced during memory accesses, the definition of makespan becomes  which is not independent of frequency.
\paragraph{Scheduling Criteria:} The reference frequency is the largest of all the optimal frequencies and the dynamic energy is an increasing function of frequencies. Thus minimizing the minimum allowed reference frequency minimizes the dynamic energy. Therefore, when looking for a schedule that minimizes the energy under a performance constraint, one should pick the one which minimizes the minimum allowed reference frequency.
 Therefore a schedule that minimizes the following quantity is optimal in terms of energy consumption:
 
  where  is the weighted sum of the parallelism vector,   and  is the sum of the parallelism vector.
  Note that the above scheduling criteria is different from the one suggested in~\cite{ConvexAndScheduling} which suggests minimizing   , which the authors define as the weighted makespan. Traditionally, scheduling algorithms minimize the makespan~\cite{MinMakespan1, MinMakespan2, Pinedo} and Gerards et al compare the traditional performance measure which is makespan with their scheduling criteria to suggest that minimizing the weighted makespan minimizes the energy consumption. The scheduling criteria we suggest here in contrast combines the criteria of~\cite{ConvexAndScheduling} with that of the traditional measure.

\section{Conclusion and Future Work}\label{Conclusion}
We have presented a comprehensive study on the frequency selection and workload distribution (scheduling) for energy optimization of memory intensive parallel workloads. In this work, we assume that all the tasks in a workload have the same data to CPU workload ratio. In future, we plan to extend this work by allowing the tasks to have different memory intensities.




\pagebreak
\bibliographystyle{abbrv}
\bibliography{EnergyEfficiency.bib} 

\pagebreak

\appendix
\renewcommand{\thesection}{\Alph{section}}\section{Figures}
\begin{figure}[h!]
  \begin{center}
   \includegraphics[scale=0.30]{TaskDependencyGraph.pdf}
  \end{center}
  \vspace*{-15mm}
  \caption{A task dependency graph}
   \label{figure:TaskDependenyGraph}
 \end{figure}
 
 \begin{figure}[h!]
  \begin{center}
   \includegraphics[scale=0.21]{RedcutionRatioVsMemoryAccessCharacteristic.jpg}
  \end{center}
  \vspace*{-15mm}
   \caption{Optimal ratio vs memory overload}
   \label{figure: ReductionRatio}
 \end{figure}
 
 
 
\section{Proofs}

\olem{Relation}
for an optimal solution  to the constrained energy optimization problem(equation~\ref{TotalEnergyFrequecy}) without the static energy, the following holds for every pair  with :\\
 
\eolem

\begin{proof}
 To prove the relation between optimal  and  for dynamic energy, we take the `Memory Accesses' and the `CPU instructions' components of the equation~\ref{MinimzerParts}.
  
  at the optimal point.
  
 
\end{proof}

\olem{CubicEquation}
 For , the ratio , of the optimal frequency  for a parallel region of the schedule with  active cores and the optimal frequency  for the serial region is a solution to the following cubic equation:
 
 where  is a constant equal to 
\eolem
\begin{proof}
 From equation~\ref{RelationEquation} we have
 
 Replacing  by  throughout, where  we get
 
 We now have the ratio of two optimal frequencies expressed in terms of one of the two frequencies  and their relative parallelization  and the memory intensity of the application in question. 
 Substituting  with ,  with  for serial region,  where   and  with 2, we get 
 
\end{proof}

\begin{lemma}\label{DynamicOptimizer}
The optimal reference frequency for minimizing the dynamic energy consumption of memory intensive applications  is:

where .
\end{lemma}
\begin{proof}
As explained in Section~\ref{SelectionScheduling}, the optimization problem for the dynamic energy, considering  is:


where .

Denoting the objective function by , the \emph{Lagrangian}~\cite{Boyd} for this optimization problem is:


where  and  are the Lagrange multipliers for the inequality constraints.
The differential of the Lagrangian w.r.t.  is:

Applying KKT condition   at the optimal point, we get:

Note that , since  is an increasing function of .
Applying the complementary slackness condition on the second constraint (), we get, ,  can't be zero, therefore we get  . It follows thus from equation~\ref{LambdaSum1}  that:

Applying complementary slackness on the the first constraint, we get , which further implies that .
Thus the optimal point is:

\end{proof}

\begin{lemma}\label{TotalOptimizer}
The optimal reference frequency for minimizing the overall energy consumption of memory intensive applications  is:

where  and \\

\end{lemma}
\begin{proof}
The optimization problem for the total energy, considering  is:



where .

Denoting the objective function by , the \emph{Lagrangian}~\cite{Boyd} for this optimization problem is:


where  and  are the Lagrange multipliers for the inequality constraints.
The differential of the Lagrangian w.r.t.  is:

Applying KKT condition   at the optimal point, we get:

Applying the complementary slackness condition on the second constraint (), we get, ,  can't be zero, therefore we get  . It follows thus from equation~\ref{LambdaSum2}  that:

Note that, unlike Lemma~\ref{DynamicOptimizer}, the total energy function  is not an increasing function of .  Here we can't say with certainity that .
Applying complementary slackness on the the first constraint, we get , either  or the first constraint is met with a slack. 

If the unconstrained optimizer of the total energy obtained by  meets the deadline constraint with a slack, i.e. the unconstrained optimizer ,  becomes zero. Otherwise,  at  as in Lemma~\ref{DynamicOptimizer}

Thus the optimal point is:

\end{proof}
\end{document}
