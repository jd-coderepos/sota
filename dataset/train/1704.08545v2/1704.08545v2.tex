

\documentclass[runningheads]{llncs}
\usepackage{graphicx}
\usepackage{amsmath,amssymb} \usepackage{color}
\usepackage{epsfig}
\usepackage{epstopdf}
\usepackage{booktabs}
\usepackage{wrapfig}
\usepackage{sidecap}
\usepackage{colortbl}
\definecolor{Gray}{gray}{0.8}
\usepackage[ruled,vlined]{algorithm2e}
\newcommand{\etal}{\textit{et al}.}
\newcommand{\ie}{\textit{i}.\textit{e}.}
\newcommand{\eg}{\textit{e}.\textit{g}.}
\usepackage{nonfloat}


\begin{document}
\title{ICNet for Real-Time Semantic Segmentation\\ on High-Resolution Images}


\titlerunning{ICNet for Real-Time Semantic Segmentation}
\author{Hengshuang Zhao, Xiaojuan Qi, Xiaoyong Shen, Jianping Shi, Jiaya Jia}
\authorrunning{H. Zhao, X. Qi, X. Shen, J. Shi, J. Jia}


\institute{The Chinese University of Hong Kong,  Tencent Youtu Lab, SenseTime Research
\email{\{hszhao,xjqi,leojia\}@cse.cuhk.edu.hk, \\dylanshen@tencent.com, shijianping@sensetime.com}
}

\maketitle              \setcounter{footnote}{-1}
\begin{abstract}
We focus on the challenging task of real-time semantic segmentation in this paper. It finds many practical applications and yet is with fundamental difficulty of reducing a large portion of computation for pixel-wise label inference. We propose an image cascade network (ICNet) that incorporates multi-resolution branches under proper label guidance to address this challenge. We provide in-depth analysis of our framework and introduce the cascade feature fusion unit to quickly achieve high-quality segmentation. Our system yields real-time inference on a single GPU card with decent quality results evaluated on challenging datasets like Cityscapes, CamVid and COCO-Stuff.
\keywords{Real-Time, High-Resolution, Semantic Segmentation}
\end{abstract}
\section{Introduction}
Semantic image segmentation is a fundamental task in computer vision. It predicts dense labels for all pixels in the image, and is regarded as a very important task that can help deep understanding of scene, objects, and human. Development of recent deep {\it convolutional neural networks} (CNNs) makes remarkable progress on semantic segmentation~\cite{long2015fully,chen2015semantic,badrinarayanan2015segnet,noh2015learning,zhao2017pspnet,wu2016wider}. The effectiveness of these networks largely depends on the sophisticated model design regarding depth and width, which has to involve many operations and parameters.

CNN-based semantic segmentation mainly exploits \textit{fully convolutional networks} (FCNs). It is common wisdom now that increase of result accuracy almost means more operations, especially for pixel-level prediction tasks like semantic segmentation. To illustrate it, we show in Fig.~\ref{fig:accuracytime-timeimageresolution}(a) the accuracy and inference time of different frameworks on Cityscapes~\cite{cordts2016cityscapes} dataset.

\subsubsection{Status of Fast Semantic Segmentation}
Contrary to the extraordinary development of high-quality semantic segmentation, research along the line to make semantic segmentation run {\it fast} while not sacrificing too much quality is left behind. We note actually this line of work is similarly important since it can inspire or enable many practical tasks in, for example, automatic driving, robotic interaction, online video processing, and even mobile computing where running time becomes a critical factor to evaluate system performance.

Our experiments show that high-accuracy methods of ResNet38~\cite{wu2016wider} and PSPNet~\cite{zhao2017pspnet} take around 1 second to predict a  high-resolution image on one Nvidia TitanX GPU card during testing. These methods fall into the area illustrated in Fig. \ref{fig:accuracytime-timeimageresolution}(a) with high accuracy and low speed. Recent fast semantic segmentation methods of ENet~\cite{paszke2016enet} and SQ~\cite{treml2016speeding}, contrarily, take quite different positions in the plot. The speed is much accelerated; but accuracy drops, where the final mIoUs are lower than 60\%. These methods are located in the lower right phase in the figure.

\begin{figure}[t]
	\begin{minipage}[t]{0.43\linewidth}
		\centering
		\includegraphics[width=0.94\linewidth]{figure/accuracytime.eps}
		{\scriptsize \\label{eq:time}
	O(\varPhi) \approx c'ck^{2}hw/s^{2}.
\label{eq:loss}
	\mathcal{L} = - \sum_{t=1}^{\mathcal{T}}\lambda_t\frac{1}{\mathcal{Y}_t \mathcal{X}_t}\sum_{y=1}^{\mathcal{Y}_t}\sum_{x=1}^{\mathcal{X}_t}\log{\frac{e^{\mathcal{F}^{t}_{\hat{n},y,x}}}{\sum_{n=1}^{\mathcal{N}} e^{\mathcal{F}^{t}_{n,y,x}}}}.
_1\times\times\times\times\times\times\times\times3 \times 35 \times 57 \times 7\times\times3 \times 35 \times 57 \times 71024 \times 2048256 \times 512\dag^\dag1024 \times 2048720 \times 960640 \times 640R_{i}S_{i}s_{i}p_{i}R_{i}{s_{i}}/{S_{i}}S_{i}\mathcal{H}\mathcal{K}p_{i}\mathcal{K}S_{i}720 \times 960$. For easy comparison with prior work, we adopt the split of Sturgess et al.~\cite{sturgess2009combining}, which partitions the dataset into 367, 100, and 233 images for training, validation and testing respectively. 11 semantic classes are used for evaluation.

The testing results are listed in Table~\ref{tab:camvid}, our base-model is no compressed PSPNet50. ICNet gets much faster inference speed than other methods on this high resolution, reaching the real-time speed of 27.8 fps, 5.7 times faster than the second one and 5.1 times faster compared to the basic model. Apart from high efficiency, it also accomplishes high quality segmentation. Visual results are provided in the supplementary material.


\subsection{COCO-Stuff}
COCO-Stuff~\cite{caesar2016coco} is a recently labeled dataset based on MS-COCO~\cite{lin2014microsoft} for stuff segmentation in context. We evaluate ICNet following the split in \cite{caesar2016coco} that 9K images are used for training and another 1K for testing. This dataset is much more complex for multiple categories -- up to 182 classes are used for evaluation, including 91 thing and 91 stuff classes.

Table~\ref{tab:cocostuff} shows the testing results. ICNet still performs satisfyingly regarding common thing and stuff understanding. It is more efficient and accurate than modern segmentation frameworks, such as FCN and DeepLab. Compared to our baseline model, it achieves 5.4 times speedup. Visual predictions are provided in the supplementary material.


\iffalse
\begin{figure}[bpt]
	\centering
	\includegraphics[width=0.99\linewidth]{figure/cocostuffvisual.eps}
	\caption{Visual results of ICNet on COCO-Stuff dataset.}
	\label{fig:cocostuffvisual}
\end{figure}
\fi

\section{Conclusion}
We have proposed a real-time semantic segmentation system ICNet. It incorporates effective strategies to accelerate network inference speed without sacrificing much performance. The major contributions include the new framework for saving operations in multiple resolutions and the powerful fusion unit.

We believe the optimal balance of speed and accuracy makes our system important since it can benefit many other tasks that require fast scene and object segmentation. It greatly enhances the practicality of semantic segmentation in other disciplines.

\clearpage

\bibliographystyle{splncs}
\bibliography{egbib}
\end{document}
