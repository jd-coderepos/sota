

\documentclass{article}
\usepackage[preprint]{spconfa4}
\usepackage{cite}
\usepackage{amsmath,amssymb,amsfonts}
\usepackage{textcomp}
\usepackage[table,xcdraw]{xcolor}
\usepackage{multirow}
\usepackage{acronym} 
\usepackage{svg}
\usepackage[hypcap=true]{subcaption, caption}
\usepackage{graphicx}
\usepackage{tabularx}

\usepackage[citecolor=black,colorlinks=true,
            linkcolor=black,urlcolor  = black,
            pdfpagelabels={true},
            pdftitle={Utterance Weighted Multi-Dilation Temporal Convolutional Networks for Monaural Speech Dereverberation},
            pdfauthor={William Ravenscroft, Stefan Goetze, Thomas Hain},
            pdfkeywords={speech dereverberation, temporal convolutional network, speech enhancement, receptive field, deep neural network},
            pdfsubject={speech dereverberation, temporal convolutional network, speech enhancement, receptive field, deep neural network}]
            {hyperref}
\usepackage{orcidlink}



\acrodef{AC}    {acoustic conditions}
\acrodef{ASR}   {automatic speech recognition}
\acrodef{BLSTM} {bidirectional long short term memory}
\acrodef{CB}    {convolutional block}
\acrodef{Conv-TasNet} {convolutional \ac{TasNet}}
\acrodef{CSM}   {clean speech mixtures}
\acrodef{cLN}   {channelwise layer normalization}
\acrodef{DAE}   {denoising autoencoder}
\acrodef{WD-Conv} {weighted multi-dilation depthwise-separable convolution}
\acrodef{DL}    {deep learning}
\acrodef{DNN}   {deep neural network}
\acrodef{DPRNN} {dual path recurrent neural network model}
\acrodef{DPTNet}{dual path Transformer network}
\acrodef{WD-TCN}  {weighted multi-dilation temporal convolutional network}
\acrodef{DS-Conv}{depthwise-separable convolution}
\acrodef{D-Conv}{depthwise convolution}
\acrodef{E2E}   {end-to-end}
\acrodef{ER}    {early reflection}
\acrodef{gLN}   {global layer normalization}
\acrodef{LSTM}  {long short term memory}
\acrodef{LR}    {late reflection}
\acrodef{MHA}   {multihead attention}
\acrodef{LMHSA} {linear multihead self attention}
\acrodef{MOS}   {Mean Opinion Score}
\acrodef{MR}    {mask refinement}
\acrodef{NMF}   {non-negative matrix factorization}
\acrodef{NSM}   {noisy speech mixture}
\acrodef{NRSM}  {noisy reverberant speech mixture}
\acrodef{PESQ}  {perceptual evaluation of speech quality}
\acrodef{PIT}   {permutation invariant training}
\acrodef{PM}    {post-masking}
\acrodef{PReLU} {parametric rectified linear unit}
\acrodef{P-Conv}{pointwise convolution}
\acrodef{ReLU}  {rectified linear unit}
\acrodef{RF}    {receptive field}
\acrodef{RIR}   {room impulse response}
\acrodef{RSM}   {reverberant speech mixture}
\acrodef{SE}    {squeeze-and-excite}
\acrodef{SISDR} {scale-invariant signal-to-distortion ratio}
\acrodef{SISDRi} {\ac{SISDR} improvement}
\acrodef{SDR}   {signal-to-distortion ratio}
\acrodef{SNR}   {signal-to-noise ratio}
\acrodef{SRMR}  {speech-to-reverberation modulation energy ratio}
\acrodef{SP}    {signal processing}
\acrodef{STFT}  {short-time Fourier transform}
\acrodef{STOI}  {short-time objective intelligibility}
\acrodef{ESTOI} {extended short-time objective intelligibility}
\acrodef{TasNet}{Time-domain audio separation network}
\acrodef{TCN}   {temporal convolutional network}
\acrodef{UPGMA} {unweighted pair group method with arithmetic mean}
\acrodef{WER}   {word error rate}
\acrodef{WPE}   {weighted prediction error}

\newcommand{\mat}[1]{\mathbf{#1}}
\newcommand{\vek}[1]{\ensuremath{\mathbf{#1}}}    \newcommand{\vekc}[1]{\ensuremath{\boldsymbol{\mathcal{#1}}}}
\newcommand{\bs}[1] {\mbox{\boldmath}}         \newcommand{\bsF}[1] {\mbox{}}         \newcommand{\scalF}[1]{\ensuremath{\mathsf{#1}}}
\newcommand{\scalFsymb}[1]{\ensuremath{\sansmath{#1}}}
\newcommand{\vekF} [1]{\ensuremath{\mathbfsf{#1}}}\newcommand{\E}[1]{\ensuremath{\mathrm{E}\left\{#1\right\}}}
\newcommand{\ex}[1]{\ensuremath{e^{#1}}}
\newcommand{\ejO}{\ex{j\Omega}}
\newcommand{\Real}{\mathbb{R}}
\newcommand{\Complex}{\mathbb{C}}
\newcommand{\Htop}{\textsf {H}}
\newcommand{\etal}{\textit{et al.} }
\newcommand{\ivector}{\textit{i}-vector}
\newcommand{\ivectors}{\textit{i}-vectors}










\copyrightnotice{978-1-6654-6867-1/22/\^{\orcidlink{0000-0002-0780-3303}}^{\orcidlink{0000-0003-1044-7343}}^{\orcidlink{0000-0003-0939-3464}}i\asth[i]s[i]s_\mathrm{dir}[i]=\alpha s[i-\tau]\tau\alphax[i]L_\vek{x}L_\mathrm{BL}\ell \in \{1,\ldots,L_\vek{x}\}\mat{B}\in\Real^{L_\mathrm{BL}\times N}L_\mathrm{BL}N\vek{x}_\ell\mat{w}_\ell\mathcal{H}_\mathrm{enc}:\Real^{1\times N} \rightarrow \Real^{ 1\times N}\mat{m}_\ell\vek{w}_\ell\odot\vek{w}_\ellNBXRXf\{2^0,2^1,\ldots,2^{X-1}\}f\vek{Y}\in\Real^{G \times L_{\vek{x}}}G\vek{K}_{\mathcal{D}}\in\mathbb{R}^{G \times P}Pg\vek{Y}\vek{K}_\mathcal{D}\vek{y}_g\vek{k}_g\mathbf{K}_{\mathcal{P}}\in\mathbb{R}^{G\times H}Q=2f=2^{X-1}Qa_q\sum_{q=1}^Q a_q=1Q=2f=1fXXf=1L_\vek{x}1H442\vek{v}_{\ell}N1L_\mathrm{BL}\vek{U}\in\Real^{N\times L_\mathrm{BL}}\hat{\vek{s}}_{\ell}\hat{\vek{s}}\vek{s}_\mathrm{dir}XRX\in\{4,5,6,7,8\}R\in\{4,5,6,7,8\}L_\mathrm{BL}=16N=512B=128H=512P=30.001x[i]s_\mathrm{dir}[i]x[i]XR(\cdot)\{X,R\} = \{5,7\}\{X,R\}=\{8,8\}\{X,R\}=\{6,8\}XR>XRXRa_qa_1f\in\{1,2,\ldots,2^{X-1}\}a_2=f=1a_q\bar{a}_q, q\in \{1,2\}\bar{a}_1\bar{a}_2\bar{a}_qX\in\{4,\ldots,8\}R\in\{4,\ldots,8\}$.}
    \label{fig:meanvsT60}
\end{figure}
\section{Conclusions}
\label{sec:conclusions}
In this work, the \ac{WD-TCN} model was proposed for \ac{TCN}-based speech dereverberation by replacing depthwise-separable convolutions with weight multi-dilation depthwise-separable convolutions. It was shown that the \ac{WD-TCN} consistently outperformed a conventional \ac{TCN} across 25 different model configurations and that using the \ac{WD-TCN} was a more parameter efficient approach to improving model performance than increasing the number of convolutional blocks in the \ac{TCN}.




\bibliographystyle{IEEEbib}
\bibliography{refs}

\end{document}