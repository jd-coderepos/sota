\documentclass[letterpaper]{article} \usepackage{aaai23}  \usepackage{times}  \usepackage{helvet}  \usepackage{courier}  \usepackage[hyphens]{url}  \usepackage{graphicx} \urlstyle{rm} \def\UrlFont{\rm}  \usepackage{natbib}  \usepackage{caption} \usepackage{multirow}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{booktabs}
\usepackage{threeparttable}
\usepackage{nicefrac}
\usepackage[symbol]{footmisc}
\frenchspacing  \setlength{\pdfpagewidth}{8.5in}  \setlength{\pdfpageheight}{11in}  \usepackage[justification=centering]{caption}
\usepackage{algorithm}
\usepackage{algorithmic}

\usepackage{newfloat}
\usepackage{listings}
\DeclareCaptionStyle{ruled}{labelfont=normalfont,labelsep=colon,strut=off} \lstset{basicstyle={\footnotesize\ttfamily},numbers=left,numberstyle=\footnotesize,xleftmargin=2em,aboveskip=0pt,belowskip=0pt,showstringspaces=false,tabsize=2,breaklines=true}
\floatstyle{ruled}
\newfloat{listing}{tb}{lst}{}
\floatname{listing}{Listing}
\pdfinfo{
/TemplateVersion (2023.1)
}



\setcounter{secnumdepth}{0} 





\title{Spatio-Temporal Meta-Graph Learning for Traffic Forecasting}
\author{
Renhe Jiang\textsuperscript{*\rm 1,2},
    Zhaonan Wang\textsuperscript{*\rm 2},
    Jiawei Yong\textsuperscript{\rm 3},
    Puneet Jeph\textsuperscript{\rm 2},
    Quanjun Chen\textsuperscript{\rm 2},   \\
    Yasumasa Kobayashi\textsuperscript{\rm 3},
    Xuan Song\textsuperscript{\rm 2},
    Shintaro Fukushima\textsuperscript{\rm 3},
    Toyotaro Suzumura\textsuperscript{\rm 1}
}
\affiliations{
\textsuperscript{\rm 1} Information Technology Center, The University of Tokyo \\
    \textsuperscript{\rm 2} Center for Spatial Information Science, The University of Tokyo \\ 
    \textsuperscript{\rm 3} Toyota Motor Corporation \\
\{jiangrh, znwang, songxuan\}@csis.u-tokyo.ac.jp;
     \{jiawei\_yong, s\_fukushima\}@mail.toyota.co.jp




}

\iffalse
\title{My Publication Title --- Single Author}
\author {
    Author Name
}
\affiliations{
    Affiliation\\
    Affiliation Line 2\\
    name@example.com
}
\fi

\iffalse
\title{My Publication Title --- Multiple Authors}
\author {
First Author Name,\textsuperscript{\rm 1,\rm 2}
    Second Author Name, \textsuperscript{\rm 2}
    Third Author Name \textsuperscript{\rm 1}
}
\affiliations {
\textsuperscript{\rm 1} Affiliation 1\\
    \textsuperscript{\rm 2} Affiliation 2\\
    firstAuthor@affiliation1.com, secondAuthor@affilation2.com, thirdAuthor@affiliation1.com
}
\fi


\usepackage{bibentry}
\begin{document}
\maketitle
\footnotetext{* Corresponding authors who contributed equally.} 


\begin{abstract}
Traffic forecasting as a canonical task of multivariate time series forecasting has been a significant research topic in AI community. To address the spatio-temporal heterogeneity and non-stationarity implied in the traffic stream, in this study, we propose Spatio-Temporal Meta-Graph Learning as a novel Graph Structure Learning mechanism on spatio-temporal data. Specifically, we implement this idea into Meta-Graph Convolutional Recurrent Network (MegaCRN) by plugging the Meta-Graph Learner powered by a Meta-Node Bank into GCRN encoder-decoder. We conduct a comprehensive evaluation on two benchmark datasets (i.e., METR-LA and PEMS-BAY) and a new large-scale traffic speed dataset called EXPY-TKY that covers 1843 expressway road links in Tokyo. Our model outperformed the state-of-the-arts on all three datasets. Besides, through a series of qualitative evaluations, we demonstrate that our model can explicitly disentangle the road links and time slots with different patterns and be robustly adaptive to any anomalous traffic situations. Codes and datasets are available at \url{https://github.com/deepkashiwa20/MegaCRN}.
\end{abstract}

\section{Introduction}


Spatio-temporal data, streamed by sensor networks, are widely studied in both academia and industry given various real-world applications. Traffic forecasting \cite{yu2018spatio, li2018diffusion, zheng2020gman, bai2020adaptive, lee2021learning}, as one canonical task, has been receiving increasing attention with rapid developing Graph Convolutional Networks (GCNs) \cite{defferrard2016convolutional, kipf2016semi, velivckovic2017graph}. This spatio-temporal modeling task can be formulated similarly to multivariate time series (MTS) forecasting \cite{wu2020connecting, cao2020spectral, shang2021discrete}, but with extra prior knowledge from the geographic space (\textit{e.g.} sensor locations, road networks) to imply the dependency among sensor signals. Compared with ordinary MTS, traffic data (\textit{e.g.} traffic speed and flow) potentially contain \textbf{spatio-temporal heterogeneity}, as traffic condition differs over roads (\textit{e.g.} local road, highway, interchange) and time (\textit{e.g.} off-peak and rush hours). Moreover, \textbf{non-stationarity} makes the task even more challenging when X factors, including accident and congestion, present.

\begin{figure}[t]
	\centering
	\includegraphics[width=1\linewidth]{./figure/LearningSTG-new1.png}
	\caption{Progression of Graph Structure Learning for Spatio-Temporal Modeling}
	\vspace{-12pt}
	\label{fig:intro}
\end{figure}

For more effective traffic forecasting, the existing works have made tremendous progress by modeling latent spatial correlation among sensors and temporal autocorrelation within time series. Since these two relationships can be naturally represented by graph and sequence respectively, the mainstream models handle them by leveraging GCN-based modules \cite{diao2019dynamic, guo2019attention, geng2019spatiotemporal, zhang2021traffic} and sequence models, such as Recurrent Neural Networks (RNNs) \cite{li2018diffusion, bai2020adaptive, ye2021coupled}, WaveNet \cite{wu2019graph}, Transformer \cite{zheng2020gman, wang2020traffic, xu2020spatial}. Particularly, to perform convolution-like operations on graphs, GCNs require an auxiliary input that characterizes the topology of the underlying spatial dependency. This essential part is defined based on certain metrics in early works, such as inverse-distance Gaussian kernel \cite{yu2018spatio, li2018diffusion}, cosine similarity \cite{geng2019spatiotemporal}. 

However, this pre-defined graph not only relies on empirical laws (\textit{e.g.} Tobler's first law of geography) which does not necessarily indicate an optimal solution, but ignores the dynamic nature of traffic networks. This twofold limitation has stimulated explorations in two lines of research. The first one aims to find the optimal graph structure that facilitates the forecasting task. GW-Net \cite{wu2019graph} pioneers along this direction by treating the adjacency matrix as free variables (\textit{i.e.} parameterized node embedding ) to train, which generates a so-called \textit{adaptive} graph (in Figure \ref{fig:intro}). Models including MTGNN \cite{wu2020connecting}, AGCRN \cite{bai2020adaptive}, GTS \cite{shang2021discrete} fall into this category, integrating MTS and traffic forecasting with Graph Structure Learning (GSL) \cite{zhu2021deep}. In the other line of research, attempts have been made to tackle network dynamics using matrix or tensor decomposition \cite{diao2019dynamic, ye2021coupled} and attention mechanisms \cite{guo2019attention, zheng2020gman}. Motivated by GSL, recent models like SLCNN \cite{zhang2020spatio}, StemGNN \cite{cao2020spectral} further try to learn a time-variant graph structure from observational data. The spatio-temporal graph (STG) derived in this way is essentially input-conditioned, in which parameters denoted by  project observations into node embeddings (termed as \textit{momentary} graph in Figure \ref{fig:intro}).

Thus far, while spatio-temporal regularities have been studied systematically, spatio-temporal heterogeneity and non-stationarity have not been tackled properly. Although the heterogeneity issue can be alleviated to some extent by applying attentions over the space and time \cite{guo2019attention, zheng2020gman}, sensor signals of different natures are still left entangled, not to mention that incidents are simply untreated. Therefore, we are motivated to propose a novel spatio-temporal meta-graph learning framework. The term \textit{meta-graph} is coined to describe the generation of node embeddings (similar in \textit{adaptive} and \textit{momentary}) for GSL. Specifically, our STG learning consists of two steps: (1) querying node-level prototypes from a Meta-Node Bank; (2) reconstructing node embeddings with Hyper-Network \cite{ha2016hypernetworks}. This localized memorizing capability empowers our modularized Meta-Graph Learner to essentially distinguish traffic patterns on different roads over time, which is even generalizable to incident situations. Our contributions are highlighted as follows:
\begin{itemize}
\item We propose a novel Meta-Graph Learner for spatio-temporal graph (STG) learning, to explicitly disentangles the heterogeneity in space and time.
\item We present a generic Meta-Graph Convolutional Recurrent Network (MegaCRN), which simply relies on observational data to be robust and adaptive to any traffic situation, from normal to non-stationary.
\item We validate MegaCRN quantitatively and qualitatively over a group of state-of-the-art models on two benchmarks (METR-LA and PEMS-BAY) and our newly published dataset (EXPY-TKY) that has larger scale and more complex incident situations.
\end{itemize}




\section{Related Work}
\noindent\textbf{Traffic Forecasting.} Traffic forecasting has been taken as a significant research problem in transportation engineering~\cite{huang2014deep,lv2014traffic,ma2015large}. As a canonical case of multivariate time series forecasting~\cite{lai2018modeling}, it also has drawn a lot of attention from machine learning researchers. At the very beginning, statistical models including autoregressive model (AR)~\cite{hamilton1994autoregressive}, vector autoregression (VAR)~\cite{stock2001vector}, autoregressive integrated moving average (ARIMA)~\cite{pan2012utilizing} were applied. Then deep learning methods come to dominate the time series prediction by automatically extracting the non-linear complex features from the data. First, LSTM~\cite{hochreiter1997long} and GRU~\cite{chung2014empirical} demonstrated superior performance in traffic modeling~\cite{ma2015long,lv2018lc,li2018diffusion,zhao2019t,wang2020traffic,bai2020adaptive,ye2021coupled,shang2021discrete,lee2021learning} as well as multivariate time series forecasting~\cite{lai2018modeling,shih2019temporal}. Second, instead of the RNNs, Temporal Convolution~\cite{yu2015multi} and WaveNet~\cite{oord2016wavenet} with long receptive field were also utilized as the core component in~\cite{yu2018spatio,wu2019graph,wu2020connecting,lu2020spatiotemporal,deng2021st} for temporal modeling. Third, motivated by~\cite{vaswani2017attention}, a series of traffic transformers~\cite{zheng2020gman,xu2020spatial} and time series transformers~\cite{li2019enhancing,zhou2021informer,xu2021autoformer} were proposed to do the long sequence time series modeling. Due to the space limitation, we refer you to the recent surveys~\cite{jiang2021dl,jiang2021graph,li2021dynamic} on traffic forecasting with deep learning.




\noindent\textbf{Graph Structure Learning.} Besides the sequence modeling, research efforts have been made to capture the correlations among variables (road links in traffic data) via generic graph structures~\cite{kipf2018neural}.
Early methods either rely on the natural topology of the road network (i.e., binary adjacency graph) or pre-defined graphs in certain metrics (e.g., Euclidean distance)~\cite{li2018diffusion,yu2018spatio}. Then, GW-Net~\cite{wu2019graph} first proposed to use two learnable embedding matrices to automatically build an adaptive graph based on the input traffic data. Following GW-Net~\cite{wu2019graph}, MTGNN~\cite{wu2020connecting} and GTS~\cite{shang2021discrete} further proposed to learn a parameterized k-degree discrete graph, while AGCRN~\cite{bai2020adaptive} introduced node-specific convolution filters according to the node embedding and CCRNN~\cite{ye2021coupled} learned multiple adaptive graphs for multi-layer graph convolution. StemGNN~\cite{cao2020spectral} took the self-attention~\cite{vaswani2017attention} learned from the input as the latent graph. Our work distinguishes itself from these methods by augmenting the spatio-temporal graph learning with memory network (Meta-Node Bank) to discover latent node-level prototypes and construct memory-tailored node embedding.





\section{Problem Definition}
Without loss of generality, we formulate our problem as a multi-step-to-multi-step forecasting task as follows: 

where   ,  is the number of spatial units (i.e., nodes, grids, regions, road links, etc.), and  is the number of the information channel. In our case,  is equal to 1 as we only forecast the traffic speed; the spatial unit is road link. To be simple, we omit  in the rest of our paper. Given previous  steps of observations [,...,,], 
we aim to infer the next  horizons [,,...,] by training a forecasting model  with parameter . 


\section{Methodology}
In this section, we present a generic framework for spatio-temporal meta-graph learning, namely Meta-Graph Convolutional Recurrent Network (\textbf{MegaCRN}), built upon Graph Convolutional Recurrent Unit (GCRU) Encoder-Decoder and plugin Meta-Graph Learner, as illustrated in Figure \ref{fig:architecture}.
\begin{figure*}[h]
	\centering
	\includegraphics[width=0.9\textwidth]{./figure/Framework-MegaCRN5.png}
	\caption{Framework of \textbf{\underline{Me}}ta-\textbf{\underline{G}}r\textbf{\underline{a}}ph \underline{\textbf{C}}onvolutional \textbf{\underline{R}}ecurrent \textbf{\underline{N}}etwork (\textbf{MegaCRN})}
	\label{fig:architecture}
\end{figure*}

\subsection{Preliminaries}
\noindent\textbf{Graph Convolutional Recurrent Unit.} Motivated by the success of Graph Convolutional Networks (GCNs) as a class in representation learning on graph-structured data (\textit{e.g.} social and road networks), a recent line of research \cite{li2018diffusion, bai2020adaptive, shang2021discrete, ye2021coupled} has explored the possibility of injecting graph convolution operation into recurrent cell (\textit{e.g.} LSTM). The derived Graph Convolutional Recurrent Unit (GCRU) can thereby simultaneously capture spatial dependency, represented by an input graph topology, and temporal dependency in a sequential manner. Without loss of generality, we take the widely adopted definitions of graph convolution operation and Gated Recurrent Unit (GRU) to denote GCRU, as the basic unit for spatio-temporal modeling:



In Equation (\ref{eq:gcn}),  and  denote the input and output of graph convolution operation (), in which  or  are the kernel parameters approximated with the Chebyshev polynomials to the order of  \cite{defferrard2016convolutional} and  is an activation function. In Equation (\ref{eq:gcru}), subscripts \textit{u}, \textit{r}, and \textit{C} denote update gate, reset gate, and candidate state in a GCRU cell, in which  denote the gate parameters. Besides observation , GCRU requires an auxiliary input  for the topology of graph .

\noindent\textbf{Graph Structure Learning.} Matrix  is conventionally defined based on certain metrics (\textit{e.g.} inverse distance, cosine similarity) and empirical laws \cite{yu2018spatio, li2018diffusion, geng2019spatiotemporal}. However, choice of metric can be arbitrary and suboptimal, which motivates a line of research \cite{wu2020connecting, zhang2020spatio, shang2021discrete, bai2020adaptive, ye2021coupled} to integrate Graph Structure Learning (GSL) into spatio-temporal modeling for simultaneous optimization. Here we adopt the canonical formulation \cite{wu2019graph, bai2020adaptive, wang2022event} for spatio-temporal graph learning, namely \textit{adaptive} graph (in Figure \ref{fig:intro}), denoted by:

where  is derived by random walk normalizing the non-negative part of matrix product of trainable node embedding  to its transpose. The other GSL strategy, \textit{momentary} graph \cite{zhang2020spatio} (in Figure \ref{fig:intro}), can be defined in a similar fashion with input signal  or hidden state . Taking the latter as an example:

where parameter matrix  essentially projects  to another embedding space. Notably, \textit{momentary} graph has other variants, such as replacing the projection with self-attention operation \cite{cao2020spectral}, but they still follow Equation (\ref{eq:momG}) as a general form.

\subsection{Spatio-Temporal Meta-Graph Learner}
Here we formally describe a new spatio-temporal graph (STG) learning module. The term \textit{meta-graph} is coined to represent the generation of node embedding for graph structure learning, which is different from its definition in heterogeneous information networks (HIN) \cite{zhao2017meta, ding2021diffmg}. According to the definition in Equation (\ref{eq:adaG}) and (\ref{eq:momG}), \textit{adaptive} graph relies on parameterized node embedding  alone, while \textit{momentary} graph is in fact input-conditioned (either projecting  or  with parameter ). Apparently, this generation process determines the properties of the derived graphs, as the former is time-invariant but the latter is sensitive to input signals. This motivates us to further enhance the node embeddings for STG generation, as the real-world networks are more complex, manifesting spatio-temporal heterogeneity and non-stationarity.

We are inspired by a line of research in memory networks, which aims to memorize typical features in seen samples for further pattern matching. This technique has been largely employed on computer vision tasks, such as few-shot learning \cite{vinyals2016matching, santoro2016meta} and anomaly detection \cite{gong2019memorizing, park2020learning}. In our case, we would like inject the memorizing and distinguishing capabilities into spatio-temporal graph learning. We thereby leverage the idea of memory networks and build a \textbf{Meta-Node Bank} . Here  and  denote the number of memory items and the dimension of each item, respectively. We further define the main functions of this memory bank as follows:

\vspace{-0.3cm}

where we use superscript  as row index. For instance,  represents -th node vector in . Equation (\ref{eq:mem-query}) denotes a fully connected (FC parameter ) layer to project hidden state  to a localized query . Equation (\ref{eq:mem-recon}) denotes the memory reading operation by matching  with each memory  to calculate a scalar , which physically represents the similarity between vector  and memory item . A meta-node vector  can be further recovered as a combination of memory items. Here a common practice is to utilize the reconstructed representation  to augment the encoded hidden representation , denoted by  ( denotes a concatenation operation) \cite{yao2019learning, lee2021learning}. We further leverage a Hyper-Network \cite{ha2016hypernetworks} that essentially puts generation of GSL node embeddings conditioned on Meta-Node Bank. This memory-augmented node embedding generation can be formulated as:

where  denotes a Hyper-Network. Without loss of generality, we implement it with one FC layer (parameter ). Then, \textit{meta-graph}  can be constructed, as an alternative to \textit{adaptive} and \textit{momentary} graphs (defined in Equation (\ref{eq:adaG}) an (\ref{eq:momG})) to feed back to GCRU encoder-decoder. 


\subsection{Meta-Graph Convolutional Recurrent Network}
With Meta-Graph Learner as described, we present the proposed Meta-Graph Convolutional Recurrent Network (\textbf{MegaCRN}) as a generic framework for spatial-temporal modeling. MegaCRN learns node-level prototypes of traffic patterns in Meta-Node Bank for updating  the auxiliary graph adaptively based on the observed situation. To further enhance its distinguishing power for diverse scenarios on different roads over time, we regulate the memory parameters with two constraints \cite{gong2019memorizing, park2020learning}, including a contrastive loss  and a consistency loss , denoted by:

where  denotes the total number of sequences (\textit{i.e.} samples) in the training set and  denote the top two indices of memory items by ranking  in Equation~\ref{eq:mem-recon} given localized query . By implementing these two constraints, we treat  as anchor, its most similar prototype  as positive sample, and the second similar prototype  as negative sample ( denotes the margin between the positive and negative pairs). Here the idea is to keep memory items as compact as possible, at the same time as dissimilar as possible. These two constraints guide memory  to distinguish different spatio-temporal patterns on node-level. In practice, we find adding them into the objective criterion (\textit{i.e.} MAE) facilitates the convergence of training (with balancing factors ):



\section{Experiment}\label{sec:experiment}
\begin{table}[h]
  \footnotesize
  \centering
  \caption{Summary of Datasets}
  \label{tab:datasummary}
  \begin{tabular}{llll}
    \hline
	Dataset & METR-LA & PEMS-BAY & EXPY-TKY\\
    \hline
    Start Time & 2012/3/1 & 2017/1/1 & 2021/10/1\\
    End Time & 2012/6/30 & 2017/5/31 & 2021/12/31\\
    Time Interval & 5 minutes & 5 minutes & 10 minutes\\
    \#Timesteps & 34,272 & 52,116 & 13,248 \\
    \#Spatial Units & 207 sensors & 325 sensors & 1,843 road links\\
\hline
\end{tabular}
\end{table}
\begin{table*}[h]
    \footnotesize
    \centering
\caption{Forecasting Performance}
	\label{tab:benchmark}
	\resizebox{!}{73mm}{
	\begin{tabular*}{17.6cm}{@{\extracolsep{\fill}}cccccccccc}
\hline
		\multirow{2}{*}{\textbf{METR-LA}} & \multicolumn{3}{c}{15min / horizon 3} &
		\multicolumn{3}{c}{30min / horizon 6} &
		\multicolumn{3}{c}{60min / horizon 12} \\
		\cline{2-4} \cline{5-7} \cline{8-10}
		\multicolumn{1}{l}{} & 
		\multicolumn{1}{c}{MAE} & 
		\multicolumn{1}{c}{RMSE} &
		\multicolumn{1}{c}{MAPE} &
		\multicolumn{1}{c}{MAE} & 
		\multicolumn{1}{c}{RMSE} &
		\multicolumn{1}{c}{MAPE} &
		\multicolumn{1}{c}{MAE} & 
		\multicolumn{1}{c}{RMSE} &
		\multicolumn{1}{c}{MAPE} \\
		\hline
		HA\cite{li2018diffusion} & 4.16 & 7.80 & 13.00\% & 4.16 & 7.80 & 13.00\% & 4.16 & 7.80 & 13.00\% \\
		STGCN\cite{yu2018spatio} & 2.88 & 5.74 & 7.62\% & 3.47 & 7.24 & 9.57\% & 4.59 & 9.40 & 12.70\% \\
		DCRNN\cite{li2018diffusion} & 2.77 & 5.38 & 7.30\% & 3.15 & 6.45 & 8.80\% & 3.60 & 7.59 & 10.50\% \\
		GW-Net\cite{wu2019graph} & 2.69 & 5.15 & 6.90\% & 3.07 & 6.22 & 8.37\% & 3.53 & 7.37 & 10.01\% \\
		STTN\cite{xu2020spatial} & 2.79 & 5.48 & 7.19\% & 3.16 & 6.50 & 8.53\% & 3.60 & 7.60 & 10.16\% \\
GMAN\cite{zheng2020gman} & 2.80 & 5.55 & 7.41\% & 3.12 & 6.49 & 8.73\% & 3.44 & 7.35 & 10.07\% \\ MTGNN\cite{wu2020connecting} & 2.69 & 5.18 & 6.86\% & 3.05 & 6.17 & 8.19\% & 3.49 & 7.23 & 9.87\% \\
		StemGNN\cite{cao2020spectral} & 2.56 & 5.06 & 6.46\% & 3.01 & 6.03 & 8.23\% & 3.43 & 7.23 & 9.85\% \\
		AGCRN\cite{bai2020adaptive} & 2.86 & 5.55 & 7.55\% & 3.25 & 6.57 & 8.99\% & 3.68 & 7.56 & 10.46\% \\
        CCRNN\cite{ye2021coupled} & 2.85 & 5.54 & 7.50\% & 3.24 & 6.54 & 8.90\% & 3.73 & 7.65 & 10.59\% \\
GTS\cite{shang2021discrete} & 2.65 & 5.20 & 6.80\% & 3.05 & 6.22 & 8.28\% & 3.47 & 7.29 & 9.83\% \\
		PM-MemNet\cite{lee2021learning} & 2.65 & 5.29 & 7.01\% & 3.03 & 6.29 & 8.42\% & 3.46 & 7.29 & 9.97\% \\
\textbf{MegaCRN (Ours)} & \textbf{2.52} & \textbf{4.94} & \textbf{6.44\%} & \textbf{2.93} & \textbf{6.06} & \textbf{7.96\%} & \textbf{3.38} & \textbf{7.23} & \textbf{9.72\%} \\
\hline
		\multirow{2}{*}{\textbf{PEMS-BAY}} & \multicolumn{3}{c}{15min / horizon 3} &
		\multicolumn{3}{c}{30min / horizon 6} &
		\multicolumn{3}{c}{60min / horizon 12} \\
		\cline{2-4} \cline{5-7} \cline{8-10}
		\multicolumn{1}{l}{} & 
		\multicolumn{1}{c}{MAE} & 
		\multicolumn{1}{c}{RMSE} &
		\multicolumn{1}{c}{MAPE} &
		\multicolumn{1}{c}{MAE} & 
		\multicolumn{1}{c}{RMSE} &
		\multicolumn{1}{c}{MAPE} &
		\multicolumn{1}{c}{MAE} & 
		\multicolumn{1}{c}{RMSE} &
		\multicolumn{1}{c}{MAPE} \\
		\hline
		HA\cite{li2018diffusion} & 2.88 & 5.59 & 6.80\% & 2.88 & 5.59 & 6.80\% & 2.88 & 5.59 & 6.80\% \\
		STGCN\cite{yu2018spatio} & 1.36 & 2.96 & 2.90\% & 1.81 & 4.27 & 4.17\% & 2.49 & 5.69 & 5.79\% \\
		DCRNN\cite{li2018diffusion} & 1.38 & 2.95 & 2.90\% & 1.74 & 3.97 & 3.90\% & 2.07 & 4.74 & 4.90\% \\
		GW-Net\cite{wu2019graph} & 1.30 & 2.74 & 2.73\% & 1.63 & 3.70 & 3.67\% & 1.95 & 4.52 & 4.63\% \\
		STTN\cite{xu2020spatial} & 1.36 & 2.87 & 2.89\% & 1.67 & 3.79 & 3.78\% & 1.95 & 4.50 & 4.58\% \\
GMAN\cite{zheng2020gman} & 1.35 & 2.90 & 2.87\% & 1.65 & 3.82 & 3.74\% & 1.92 & 4.49 & 4.52\% \\ MTGNN\cite{wu2020connecting} & 1.32 & 2.79 & 2.77\% & 1.65 & 3.74 & 3.69\% & 1.94 & 4.49 & 4.53\% \\
		StemGNN\cite{cao2020spectral} & 1.23 & 2.48 & 2.63\% & \multicolumn{3}{c}{N/A from \cite{cao2020spectral}} & \multicolumn{3}{c}{N/A from \cite{cao2020spectral}} \\
		AGCRN\cite{bai2020adaptive} & 1.36 & 2.88 & 2.93\% & 1.69 & 3.87 & 3.86\% & 1.98 & 4.59 & 4.63\% \\
        CCRNN\cite{ye2021coupled} & 1.38 & 2.90 & 2.90\% & 1.74 & 3.87 & 3.90\% & 2.07 & 4.65 & 4.87\% \\
GTS\cite{shang2021discrete} & 1.34 & 2.84 & 2.83\% & 1.67 & 3.83 & 3.79\% & 1.98 & 4.56 & 4.59\% \\
PM-MemNet\cite{lee2021learning} & 1.34 & 2.82 & 2.81\% & 1.65 & 3.76 & 3.71\% & 1.95 & 4.49 & 4.54\% \\
\textbf{MegaCRN (Ours)} & \textbf{1.28} & \textbf{2.72} & \textbf{2.67\%} & \textbf{1.60} & \textbf{3.68} & \textbf{3.57\%} & \textbf{1.88} & \textbf{4.42} & \textbf{4.41\%} \\
		\hline
		\multirow{2}{*}{\textbf{EXPY-TKY}} & \multicolumn{3}{c}{10min / horizon 1} &
		\multicolumn{3}{c}{30min / horizon 3} &
		\multicolumn{3}{c}{60min / horizon 6} \\
		\cline{2-4} \cline{5-7} \cline{8-10}
		\multicolumn{1}{l}{} & 
		\multicolumn{1}{c}{MAE} & 
		\multicolumn{1}{c}{RMSE} &
		\multicolumn{1}{c}{MAPE} &
		\multicolumn{1}{c}{MAE} & 
		\multicolumn{1}{c}{RMSE} &
		\multicolumn{1}{c}{MAPE} &
		\multicolumn{1}{c}{MAE} & 
		\multicolumn{1}{c}{RMSE} &
		\multicolumn{1}{c}{MAPE} \\
		\hline
		HA\cite{li2018diffusion} & 7.63 & 11.96 & 31.26\% & 7.63 & 11.96 & 31.25\% & 7.63 & 11.96 & 31.24\% \\
		STGCN\cite{yu2018spatio} & 6.09 & 9.60 & 24.84\% & 6.91 & 10.99 & 30.24\% & 8.41 & 12.70 & 32.90\%\\
		DCRNN\cite{li2018diffusion} & 6.04 & 9.44 & 25.54\% & 6.85 & 10.87 & 31.02\% & 7.45 & 11.86 & 34.61\%\\
		GW-Net\cite{wu2019graph} & 5.91 & 9.30 & 25.22\% & 6.59 & 10.54 & 29.78\% & 6.89 & 11.07 & 31.71\% \\
		STTN\cite{xu2020spatial} & 5.90 & 9.27 & 25.67\% & 6.53 & 10.40 & 29.82\% & 6.99 & 11.23 & 32.52\%\\
		GMAN\cite{zheng2020gman} & 6.09 & 9.49 & 26.52\% & 6.64 & 10.55 & 30.19\% & 7.05 & 11.28 & 32.91\%\\
		MTGNN\cite{wu2020connecting} & 5.86 & 9.26 & 24.80\% & 6.49 & 10.44 & 29.23\% & \textbf{6.81} & \textbf{11.01} & 31.39\% \\
		StemGNN\cite{cao2020spectral} & 6.08 & 9.46 & 25.87\% & 6.85 & 10.80 & 31.25\% & 7.46 & 11.88 & 35.31\%\\
		AGCRN\cite{bai2020adaptive} & 5.99 & 9.38 & 25.71\% & 6.64 & 10.63 & 29.81\% & 6.99 & 11.29 & 32.13\% \\
		CCRNN\cite{ye2021coupled} & 5.90 & 9.29 & 24.53\% & 6.68 & 10.77 & 29.93\% & 7.11 & 11.56 & 32.56\%\\
GTS\cite{shang2021discrete} & - & - & - & - & - & - & - & - & - \\
		PM-MemNet\cite{lee2021learning} & 5.94 & 9.25 & 25.10\% & 6.52 & 10.42 & 29.00\% & 6.87 & 11.14 & 31.22\% \\
\textbf{MegaCRN (Ours)} & \textbf{5.81} & \textbf{9.20} & \textbf{24.49\%} & \textbf{6.44} & \textbf{10.33} & \textbf{28.92\%} & \underline{6.83} & \underline{11.04} & \textbf{31.02\%} \\
		\hline
	\end{tabular*}
	}
	\centering
\end{table*}

\subsection{Datasets and Settings}\label{sec:experiment-setup}
\noindent\textbf{Datasets.} We first evaluate our model by using two standard benchmark datasets from \cite{li2018diffusion}: \textbf{METR-LA} and \textbf{PEMS-BAY}. They contain the traffic speed data from 207 sensors in Los Angeles and 325 sensors in Bay Area respectively. For the two benchmarks, we follow the tradition~\cite{li2018diffusion,wu2019graph,shang2021discrete,lee2021learning} by splitting the datasets in chronological order with 70\% for training, 10\% for validation, and 20\% for testing (namely 7:1:2). Besides, in this study, we publish a new traffic dataset called \textbf{EXPY-TKY}, that contains the traffic speed information and the corresponding traffic incident information in 10-minute interval for 1843 expressway road links in Tokyo over three months (2021/102021/12). We use the first two months (Oct. 2021 and Nov. 2021) as the training and validation dataset, and the last one month (Dec. 2021) as the testing dataset. The specific spatio-temporal information of our datasets are summarized in Table \ref{tab:datasummary}. 


\noindent\textbf{Settings.}
For EXPY-TKY, the Encoder and Decoder of our model consist of 1 RNN-layer respectively, where the number of hidden states is 32. We reserve 10 prototypes (i.e., meta-nodes) in the memory, each of which is a 32-dimension learnable vector. For METR-LA and PEMSBAY, each RNN layer in Encoder and Decoder has 64 units and the memory bank has 20 meta-nodes with 64-dimension. The observation step  and prediction horizon  are both set to 12 on METR-LA and PEMS-BAY, while / are both set to 6 on EXPY-TKY. Such settings can give us 1-hour lead time forecasting, which follow the tradition in previous literatures~\cite{yu2018spatio,li2018diffusion,wu2019graph,bai2020adaptive,shang2021discrete}. Adam was used as the optimizer, where the learning rate was set to 0.01 and the batch size was set to 64. The optimizer would either be early-stopped if the validation error was converged within 20 epochs or be stopped after 200 epochs. L1 Loss is used as the loss function. Root Mean Square Error (RMSE), Mean Absolute Error (MAE), and Mean Absolute Percentage Error (MAPE) are used as metrics. All experiments were performed with four GeForce RTX 3090 GPUs. 


\subsection{Quantitative Evaluation}\label{sec:experiment-overall}


We compare our model with the following baselines: 1) Historical Average (HA) averaged values of the same time slot from historical days~\cite{li2018diffusion}; 2) STGCN~\cite{yu2018spatio}, 3) DCRNN~\cite{li2018diffusion}, and 4) GW-Net~\cite{wu2019graph}, the most representative deep models for traffic forecasting, respectively embed spectral~\cite{yu2018spatio} or diffusion graph convolution~\cite{li2018diffusion,wu2019graph} into temporal convolution (i.e., TCN or WaveNet)\cite{yu2018spatio,wu2019graph} or recurrent unit (e.g., GRU)\cite{li2018diffusion}; 5) STTN~\cite{xu2020spatial} and 6) GMAN~\cite{zheng2020gman} are two Transformer-based SOTAs; 7) MTGNN~\cite{wu2020connecting} is an extended version of GW-Net that extends the adaptive graph leaning part;
8) StemGNN~\cite{cao2020spectral} first learns a latent graph via self-attention and performs the spatiotemporal modeling in spectral domain; 9) AGCRN~\cite{bai2020adaptive} adaptively learns node-specific parameters for graph convolution; 10) CCRNN~\cite{ye2021coupled} learns multiple parameterized matrices for multiple layers of graph convolution; 11) GTS~\cite{shang2021discrete} learns each link's (edge's) probability based on each variable's (node's) long historical data; 12) PM-MemNet~\cite{lee2021learning} also utilizes memory networks for traffic pattern matching. 9)12) are built based upon GCRN~\cite{seo2018structured,li2018diffusion}. 



\noindent\textbf{Overall Comparison.} Most of the baselines' results on the benchmarks are reported from their original papers. However, due to the reproducibility problem ( in Table~\ref{tab:benchmark}), we report the results of GMAN, GTS, and PM-MemNet either from our own experiments or other literature (e.g., GMAN on METR-LA~\cite{shao2022pre}). Through Table~\ref{tab:benchmark}, we can find our model outperformed the state-of-the-arts in almost all cases (dataset/horizon/metric). Among the SOTAs, GW-Net\cite{wu2019graph} and MTGNN~\cite{wu2020connecting} marked relatively good performances thanks to the WaveNet backbone. CCRNN~\cite{ye2021coupled} delivered better performance on our dataset than the benchmarks. Because it requires the 0-1 adjacency matrix of the road network to get a good initialization for the learnable graphs, which is not available in the benchmark datasets. GMAN~\cite{zheng2020gman} and StemGNN~\cite{cao2020spectral} gave a worse performance on our dataset, because the number of nodes  in ours is around 69 times larger than the benchmarks and the self-attention in them struggled to work on such a large scale. GTS~\cite{shang2021discrete} could not even be applicable on our dataset, because it requires to parameterize an  matrix ( edges and  nodes) for edge generation based on each node's features. StemGNN is considered to have a \textit{data leakage} problem as it averages all the graphs in minibatch for both training and testing (sample interaction). 



\begin{table}[h]
    \footnotesize
    \centering
	\caption{Ablation Test across All Horizons}
	\label{tab:ablationstudy}
	\setlength{\tabcolsep}{0.8mm}{
	\begin{tabular*}{8.2cm}{@{\extracolsep{\fill}}lccc}
		\hline
		\multirow{2}{*}{Ablation} & METR-LA & PEMS-BAY & EXPY-TKY \\
		\cline{2-4}
		\multicolumn{1}{l}{} & 
		\multicolumn{1}{c}{MAE / RMSE} & 
		\multicolumn{1}{c}{MAE / RMSE} & 
		\multicolumn{1}{c}{MAE / RMSE} \\
		\hline
		Adaptive & 3.01 / 6.25 & 1.61 / 3.73 & 6.79 / 10.76\\
            Momentary & 2.96 / 6.16 & 1.62 / 3.75 & 6.68 / 10.59 \\		
            Memory & 2.97 / 6.21 & 1.60 / 3.70 & 6.55 / 10.48 \\
		\hline
		\textbf{MegaCRN} & \textbf{2.89} / \textbf{6.02} & \textbf{1.54} / \textbf{3.59}  & \textbf{6.44} / \textbf{10.35} \\
		\hline
	\end{tabular*}}
\end{table}
\noindent\textbf{Ablation Study.} To evaluate the actual performance of each component of our model, we create a series of variants as follows: (1) \textbf{Adaptive GCRN}. It only keeps the GCRN encoder-decoder of MegaCRN and lets the encoder and decoder share a same \textit{adaptive} graph, similar graph structure learning mechanism to GW-Net~\cite{wu2019graph}, MTGCNN~\cite{wu2020connecting}, and AGCRN~\cite{bai2020adaptive}; 
(2) \textbf{Memory GCRN}. It excludes the Hyper-Network from MegaCRN and just uses a Memory Network (i.e., same as the Meta-Node Bank) to get an augmented hidden states  (from the encoder) for the decoder, which shares the same \textit{adaptive} graph  with the encoder.
(3) \textbf{Momentary GCRN}. It excludes the Meta-Node Bank from MegaCRN and directly uses a Hyper-Network (i.e., FC layer) to take the encoder's hidden states  to generate a \textit{momentary} graph for the decoder.  Through Table \ref{tab:ablationstudy}, we can see that compared to Momentary GCRN, Memory GCRN brings a higher performance gain to Adaptive GCRN. Because Momentary GCRN is obtained from , it has to learn a separate graph for each sample in minibatch, which is non-trivial. All these demonstrate that MegaCRN is a complete and indivisible set.


\begin{figure}[h]
	\centering
	\includegraphics[width=0.9\linewidth]{./figure/scatters_aaai23.png}
	\caption{Efficiency Evaluation}
	\label{fig:efficiency}
\end{figure}
\begin{figure*}[h]
	\centering
	\includegraphics[width=0.98\textwidth]{./figure/Spaio-Temporal-Disentangling-newnew.png}
	\caption{Spatio-Temporal Disentangling Effect of Meta-Graph Learning}
	\label{fig:case-distangle}
\end{figure*}
\begin{figure*}[h]
	\centering
	\includegraphics[width=0.98\textwidth]{./figure/Incident-Aware-new-1.png}
	\caption{Incident Awareness of MegaCRN}
	\label{fig:case-incident}
\end{figure*}

\noindent\textbf{Efficiency Study.} We also evaluate the efficiency of our model by comparing with the-state-of-the-arts. Here we just report the results on EXPY-TKY, because the spatial domain of our data is 59 times larger than the benchmarks. A scatter plot is shown as Figure \ref{fig:efficiency}, where the x-axis of is the total number of parameters and the y-axis is the overall MAE. We can see that our model has the second-fewest parameters (merely 133,597) but the smallest overall MAE. For a large-scale dataset like EXPY-TKY, our model could be very memory-efficient. In contrast, some models, especially Transformer-based models including GMAN~\cite{zheng2020gman} and STTN~\cite{xu2020spatial}, are very memory/time-consuming due to the dot-product operation on big tensor. Although our model tends to need more epochs to converge, each round of training could be finished in very little time. To sum up, our model can achieve the state-of-the-art precision while keeping comparatively efficient.
\subsection{Qualitative Evaluation} \label{sec:experiment-casestudy}
\textbf{Spatio-Temporal Disentanglement.} We qualitatively evaluate the quality of node embeddings by visualizing them in a low-dimensional space with t-SNE. Compared with \textit{adaptive} GSL illustrated as Figure \ref{fig:case-distangle}(a), \textit{meta-graph} can automatically learn to cluster nodes (i.e., road links) as shown in Figure \ref{fig:case-distangle}(b)(c). Interestingly, as time evolves from t to t+1, this clustering effect persists but the cluster shape changes, which confirms the spatio-temporal disentangling capability as well as the time-adaptability of our approach. In addition, we map out the physical locations of the road links in discovered clusters with different colors (cluster 1 in blue, cluster 2 in red) in Figure \ref{fig:case-distangle}(d). We observe a strong correlation between the spatial distribution of cluster 2 (in red) and interchanges/toll gates. From the daily averaged time series plot in the bottom of Figure \ref{fig:case-distangle}(d), we can clearly tell the inter-cluster difference. While road links in cluster 1 (in blue) share a strong rush hour pattern, the other cluster (in red) has a lower speed on average but higher variations, which is characterized by large amount of speed change near interchanges/toll gates. These observations validate the power of Meta-Graph Learner to explicitly distinguish spatio-temporal heterogeneity. 


\noindent\textbf{Incident-Awareness.} We qualitatively study the robustness of MegaCRN to various traffic situations in Figure \ref{fig:case-incident}. Here we select an incident case that occurred at 21:50 at road link 1, marked in red in Figure \ref{fig:case-incident}(a), on December 13th, 2021. In terms of the prediction results (in 60-minute lead time), compared with two baselines, GW-Net~\cite{wu2019graph} and CCRNN~\cite{ye2021coupled}, our model can not only better capture normal fluctuations, but adapt to more complex situations including rush hour and traffic accident (in shaded red). Such sudden disturbance inevitably results in delay or failure of detection for other models. From the visualization of memory query weight in Figure \ref{fig:case-incident}(b), we can tell that the pattern querying to the Meta-Node Bank is different between normal situations and rush hour or incident case. This observation confirms the distinguishing power and generalizability to diverse traffic scenarios. We further visualize the learned local \textit{meta-graph} as Figure \ref{fig:case-incident}(d), in which thicker line represents higher edge weight and bigger node size means larger weighted outdegree. Intuitively, we can find the \textit{meta-graph} is changing with time. At 21:40 before the accident happened, node 1 (road link 1) held the biggest impact in the local \textit{meta-graph} as road link 1 lies right at the center of the large road intersection. Then at 21:50 after the accident happened, the impact of node 1 dropped significantly and the graph became dominated by road link 7, 8, 9, and 10 that formed a separated subgraph at 21:40. This case study verifies the superior adaptability of our approach. 







\section{Conclusion}\label{sec:conclusion}
In this study, we propose Meta-Graph Convolutional Recurrent Network (MegaCRN) along with a novel spatio-temporal graph structure learning mechanism for traffic forecasting. Besides two benchmarks, METR-LA and PEMS-BAY, we further generate a brand-new traffic dataset called EXPY-TKY from large-scale car GPS records and collect the corresponding traffic incident information. Our model outperformed the state-of-the-arts to a large degree on all three datasets. Through a series of visualizations, it also demonstrated the capability to disentangle the time and nodes with different patterns as well as the adaptability to incident situations. We will further generalize our model for Multivariate Time Series forecasting tasks in the future.



\section{Acknowledgments}
This work was supported by Toyota Motor Corporation and JSPS KAKENHI Grant Number JP20K19859.

\bibliography{aaai23}
\end{document}