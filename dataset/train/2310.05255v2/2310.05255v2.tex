\documentclass[conference]{IEEEtran}
\IEEEoverridecommandlockouts
\usepackage{cite}
\usepackage{amsmath,amssymb,amsfonts}
\usepackage{graphicx}
\usepackage{textcomp}
\usepackage{xcolor}
\usepackage{framed,multirow}
\usepackage{booktabs}
\usepackage{algorithm}
\usepackage{algpseudocode}
\usepackage{latexsym}
\usepackage{threeparttable}
\usepackage{tabu}
\usepackage{multicol}
\usepackage{fancyhdr}

\def\BibTeX{{\rm B\kern-.05em{\sc i\kern-.025em b}\kern-.08em
T\kern-.1667em\lower.7ex\hbox{E}\kern-.125emX}}


\fancypagestyle{firstpage} {
\fancyhf{}
\fancyhead[C]{12th International Conference on Computer and Knowledge Engineering (ICCKE 2022), November 17-18, 2022, Ferdowsi University of Mashhad, Iran}
\fancyfoot[L]{978-1-6654-7613-3/22/\\timesNumFonts \gets 60 datasetSize \gets 10000  eachFontSamples \gets PFRdataset \gets  textLevel \gets text \gets textCoordinate \gets mskTextColor \gets mskBackgr \gets  mask \getslabel \gets textColor \gets typeBackgr \gets imgBackgr \gets  image \gets\gets  image \getsmy\hat{y_i}AB>>\times>>$75 \%}  & \textbf{Dice \%}  \\
\midrule

\multirow{1}{*}{Image Segmentation} &
 80.4  &  79.2  &  58.7 \\  
\bottomrule
\end{tabular}
\end{table}
\begin{table}[h]
\centering
\caption{Experimental results of the classification model with grayscale images. \label{tab:exp2-2}}\begin{tabular}{cccc}
\toprule
& \multicolumn{3}{@{}c@{}}{\textbf{Metrics}} \\ \cmidrule{2-4}
\textbf{Model}
& \textbf{Top-5 \%}  & \textbf{Top-3 \%}  & \textbf{Top-1 \%}  \\
\midrule
\multirow{1}{*}{Image Classification} &
86.5  &  80.9  &  65.2 \\  
\bottomrule
\end{tabular}
\end{table}
 \subsection{Experiment 3}
We compare the time performance of our proposed pipeline with recent studies. However, most recent studies report time only for the feature extraction steps, while our pipeline based on CNN models is free of these steps, making direct comparisons difficult.


In addition to time, we report the processors and environments used in the recent articles. All reported times are for one sample, and both the feature extraction and whole process columns are in seconds. We report the mean time of 100 predictions of our pipeline on one sample, both on GPU and CPU. The results of this experiment are shown in Table \ref{tab:speed}. \subsection{Experiment 4}
To enable meaningful comparisons with future studies, we provide essential metrics for our pipeline, specifically the Floating Point Operations (FLOPs) and the number of trainable parameters. FLOPs quantify the number of operations necessary to execute a single instance on a deep learning model \cite{app12125902}.
For our pipeline, the total FLOPs count and the number of trainable parameters are recorded as 8,596,611 and 8,593,949, respectively.  \section{Conclusion}\label{sec5}
In this paper, we introduced the first public datasets for Persian font recognition to address the limitations of previous datasets. Alongside these datasets, we propose a pipeline based on CNN models for Persian font recognition. Notably, these neural network types have not been employed in recent papers.
Our method leverages the CNN models' ability to be content- and background-independent, eliminating the need for handcrafted features such as Gabor features, which have been utilized in recent studies.

The experimental results demonstrate that our proposed pipeline achieves a top-1 accuracy of 78.0\% on our new datasets, 89.1\% on the IDPL-PFOD dataset, and 94.5\% on the KAFD dataset. Moreover, the average processing time for a single sample in our proposed datasets is 0.54 seconds for CPU and 0.017 seconds for GPU. For future research, we recommend exploring the design of new CNN architectures or incorporating recently proposed CNN blocks from recent papers. 

\bibliographystyle{IEEEtran}
\bibliography{references}


\end{document}
