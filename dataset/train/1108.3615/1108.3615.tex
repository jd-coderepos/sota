We refer to Lothaire \cite{lothaire1} for the basic terminology and notation about words on a finite alphabet $\Alphabet$. It includes  the {\it empty} word $\varepsilon$, {\it length, , conjugate, factor, prefix, suffix, proper factor,  free monoid $\Alphabet^*$,  morphism, antimorphism, occurrences, palindrome, period, power, primitive, reversal}.
The set of all factors of $w$ is denoted by  $\Fact(w),$  those of
length  $n$ is $\Fact_n(w) = \Fact(w) \cap \Alphabet^n,$ $\Pref(w)$ is
the set of all prefixes of $w$, and  the set of its palindromic factors is $\Pal(L)$.  If $w=pu$, with $|w|=n$ and $|p|=k$, then 
$p^{-1}w = w[k..n-1] = u$ is the word obtained by erasing from $w$ its prefix $p$.
The  class of a word $w$ is denoted $\Class{w}$. Every  word contains palindromes, the letters and $\varepsilon$ being necessarily part of them. This justifies the introduction of the function $\LPS : \Alphabet^* \to \Alphabet^*$ which associates  to any  word $w$  its longest palindromic suffix $\LPS(w)$.
Given a  total order $<$ on $\Alphabet$, the \emph{lexicographic ordering} is defined as usual. 
\paragraph{Lyndon words}
Introduced as \emph{standard lexicographic sequences} by Lyndon in 1954, Lyndon words have several characterizations (see \cite{lothaire1}). We shall define them as words being strictly smaller than any of their circular permutations. 
\begin{definition}
A Lyndon word $l \in \Alphabet^+$ is a word such that $l = uv$ with $u,v \in \Alphabet^+$ implies that $l<vu$. 
\end{definition}

Note that Lyndon words are always primitive. The most important result about Lyndon words is the following unique factorization theorem (see Lothaire \cite{lothaire1} Theorem 5.1.1).
\begin{theorem}  Any word $w\in \Alphabet^+$  admits a unique factorization as a sequence of decreasing Lyndon words:
\begin{equation}\label{factoLyndon}
w = l_1^{n_1} l_2^{n_2} \cdots l_k^{n_k}, \quad l_1 > l_2 > \dots > l_k
\end{equation}
where  $n_i\geq 1$ and $l_i$ is a Lyndon word, for all $i$ such that $1\leq i\leq k$. 
\end{theorem}
There exist several algorithms for factorizing a word $w=w_1w_2\cdots w_n$ into Lyndon words and the more efficient are linear . 
An  elegant one was invented by Duval \cite{Duv}. It works by reading from left to right, with at most $2n$ comparisons of letters (see also \cite{Reu}, Section 7.4). 
Another one, uses the concept of \emph{suffix standardization} of the word $w$, and builds a \emph{suffix array} of $w$, which may be computed in linear time \cite{CroHanLec}. Then the Lyndon factorization of $w$ is obtained by cutting $w$ just before each left-to-right minimum of its suffix-array.




\paragraph*{A quadtree with a radix tree structure for points in the integer plane {\rm(\cite{BKPproc,BKP})}}
Let $\Base=\{0,1\}$ be the base  for writing  integers. Words in $\Base^*$ are conveniently represented in the {\em radix order} by a complete binary tree (see for instance \cite{knuth3,lothaire3}), where the level $k$ contains all the binary words of length $k$, and the order is given by the breadth-first traversal of  the tree. To distinguish a natural number $x\in \N$ from its representation we write $\bx\in \Base^*$.  The edges are defined inductively by the rewriting rule $\bx \to \bx\cdot 0 + \bx\cdot 1,$ with the convention that  $0$ and $1$ are the labels of, respectively,  the left and right edges of the node having value $\bx$. This representation  is extended to $\Base^*\times \Base^*$ as follows. As usual, the concatenation is extended to the cartesian product of words by setting for $(\bx,\by) \in \Base^*\times \Base^*$, and $(\alpha,\beta) \in \Base\times \Base$
$$(\bx,\by)\cdot(\alpha,\beta)= (\bx\cdot\alpha,\by\cdot\beta).$$
Let $\bx$ and $\by$ be two binary words having same length.  Then the rule 
\begin{equation}(\bx,\by) \to (\bx\cdot 0, \by\cdot 0) + (\bx\cdot 0, \by\cdot 1)  + (\bx\cdot 1, \by\cdot 0)  +(\bx\cdot 1, \by\cdot 1) \label{TreeRule}
\end{equation}
defines a   $\G' =(N,R)$, sub-graph  of  $\G = (N,R,T)$,   such that :
\begin{enumerate}[\rm (i)]
 \item the root is labeled $(0, 0)$;
 \item each  node (except the root) has four sons;
 \item if a node is labeled $(\bx,\by)$ then $|\bx|=|\by|;$ 
 \item edges are undirected, e.g. may be followed in both directions.
 \end{enumerate}
 By convention, edges leading to the sons have labels from the ordered set $\{(0,0), (0,1), (1,0), (1,1)\}$. These labels equip  the quadtree  with a \emph{radix tree} structure for Equation \eqref{TreeRule} implies that $(x', y')$ is a son of $(x,y)$, if and only if
\[(x', y') = (2x+ \alpha, 2y+\beta),\] 
for some   $(\alpha, \beta) \in  \Base\times \Base$. Observe that any pair $(x, y)$ of nonnegative integers is represented exactly once in this tree. Indeed, if  $|\bx| =|\by|$  (by filling with zeros at the left of the shortest one), the sequence of pairs of digits (the two digits in first place, the two digits in second place, and so on) gives the unique path in the tree leading to this pair. Of course the root may have up to three sons since no edge labeled $(0,0)$  starts from the root.\\ 
\begin{figure}[h!]
\centering
\includegraphics[width=2.75in]{radixTreeVoisins.eps}
\caption{The  point $(2,1)$ with its neighbors.}\label{RadixTree}
\end{figure}
\paragraph{Neighboring links {\rm\cite{BKPproc,BKP}}}
Given  $(x,y) \in \Z^2$, a point $(x',y')$ is an {\em \bse-neighbor} of  $(x,y)$ if there exists $\epsilon \in \Freeman$ such that  
$(x',y') = (x,y)+\emph{\bse}=(x+\epsilon_1,y+\epsilon_2).$\smallskip

We superpose  on $G'$  the neighboring relation given by the edges of $T$ (dashed lines). More precisely, for each elementary translation $\epsilon\in\Freeman$, each  node $\txtc{z}=(x,y)$ is linked  to its  $\epsilon$-neighbor  $\txtc{z} +\bse$, when it exists. 
If a level $k$ is fixed, it is easy to construct the graph 
\[\G^{(k)} = (N^{(k)} ,R^{(k)} ,T^{(k)} )\]
 such that 
\begin{enumerate}[\rm (i)]
\item if $(\bx,\by)\in N^{(k)}$, then  $|\bx| =|\by|=k$; 
\item the functions  $N^{(k)} \hookrightarrow  \N\times\N  \hookrightarrow  \Base^*\times\Base^* $ are injective;
\item $R^{(k)}$ is the radix-tree representation :  $(\Base^{<k}\times\Base^{<k})\times  (\Base\times\Base)\stackrel{\bullet}{\to} \Base^{\leq k}\times\Base^{\leq k}$;\smallskip
\item the neighboring relation is $T^{(k)} \subseteq N\times(\Base\times\Base)\times N$.
\end{enumerate}


Note that the labeling in Fig. \ref{RadixTree} is superfluous:  each node represents indeed an integer unambiguously determined by the path from the root using edges in $R$; similarly for the ordered edges.
Moreover, if a given subset $M\subset \N\times\N$ has to be represented, then one may trim the unnecessary nodes so that  the corresponding graph  $\G_M$ is not necessarily complete. \smallskip
 
Recall that adding $1$ to an integer $\bx \in \Base^k$  is easily performed by a sequential function. 
Indeed, every positive integer can be written $\bx = u 1^i 0^j$, where $i\geq 1$,  $j\geq 0$, with 
$u\in \{\varepsilon\} \cup \left\{\Base^{k-i-j-1}\cdot 0\right\}.$ In other words, $1^j$ is the last run of $1$'s.
The piece of code for adding 1 to an integer written in base 2 is\medskip
$
\ind{1}{0}{{\bf If} $j\not = 0 $ {\bf then} Return $u1^i0^{j-1}1;$}
\ind{2}{5}{{\bf else If} $u= \varepsilon$ {\bf then} Return $1\cdot 0^i;$}
\ind{3}{13}{{\bf else}  Return $u\cdot 0^{-1}\cdot 1\cdot 0^i;$}
\ind{4}{8}{{\bf end if}}
\ind{5}{0}{{\bf end if}}
$\medskip


\noindent where $0^{-1}$ means to erase a $0$. Clearly, the computation time of this algorithm  is proportional to the length of the last run of $1$'s.  Much better is achieved with  the radix tree structure, where, given a node $\txtc{z}$, its {\em father} is denoted  $f(\txtc{z})$, and we write $f(x,y)$ or $f(\bx,\by)$ if its label is $(x,y)$.
The following technical lemma is a direct  adaptation to $\Base^*\times\Base^*$  of the addition above.
\begin{lemma}\label{condition} Let $G^{(k)}$ be the complete graph representing $\Base^{\leq k}\times\Base^{\leq k}$ for some $k\geq 1$,  $\epsilon \in \Freeman$, and $\txtc{z} = (\emph{\bx, \by})$ be a node of $N^{k}$. If one of the four conditions holds:
\[\begin{array}{rlcccrlcc}
 \text{\rm(i) } &\epsilon = \0 & \text{\rm and} &  \emph{\bx[k]} = 0, & &
\text{\rm(ii) }  &\epsilon = \2 & \text{\rm and} & \emph{\bx[k]} = 1, \\
\text{\rm(iii) }  &\epsilon = \1 & \text{\rm and} & \emph{\by[k]} = 0, & &
\text{\rm(iv) }  &\epsilon = \3 & \text{\rm and} & \emph{\by[k]} = 1,
\end{array} \]
then $f(\txtc{z}) = f\left(\txtc{z} +\bse\right)$. Otherwise, $f(\txtc{z}) + \bse = f(\txtc{z} + \bse)$.
\end{lemma}
\medskip
\begin{floatingfigure}[h!r]{3in}
\centering
\includegraphics[height=1in]{exemple.eps}
\end{floatingfigure}
\noindent  The process is illustrated for case (i) in the diagram on the right
where the nodes\vspace{4pt} 
\hbox{$\,(10110, \bullet)~$ and  $\,(10111, \bullet)\,$}\medskip
\\
share the same father while fathers of neighboring nodes\medskip\\
\smallskip
 $(\bullet, 01011)~$ and $~(\bullet, 01011)$\\
\smallskip \hbox{are distinct but share the same neighboring relation.}


\paragraph{A representation for paths in the square grid}





Here, we encode paths with the so-called \emph{Freeman chain code}\cite{freeman1} based on the  alphabet $\Freeman=\{\0,\1,\2,\3\}$, considered as the additive group of integers $\bmod~4$. 
Basic transformations on $\Freeman$ are rotations $\rho^i:x\mapsto x+i$ and reflections $\sigma_i:x\mapsto i - x$,  which extend uniquely to morphisms (w.r.t  concatenation) on $\Freeman^*$. 
Given a nonempty word $w\in\Freeman^*$, the \emph{first differences word} $\Delta(w)\in\Freeman^*$ of $w$ is
\begin{equation}\label{Delta}
\Delta(w) = (w_2-w_1)\cdot (w_3-w_2) \cdots (w_n - w_{n-1}).
\end{equation}
One may verify that if $z \in\Freeman^*$, then $\Delta(wz)=\Delta(w)\Delta (w_nz_1)\Delta(z)$.
Words in $\Freeman^*$ are interpreted as paths in the square grid, so that we indistinctly talk of any word $w\in\Freeman^*$ as the \emph{path} $w$. 
\begin{figure}[ht]
\centering
\begin{tabular}{ccc}



\begin{tikzpicture}[xscale=.5pt, yscale=.5pt,inner sep=0mm,point/.style={circle,draw=black,fill=black, minimum size=4pt}]

\def\ub{ -- ++(0,1)}
\def\ua{ -- ++(1,0)}
\def\uA{ -- ++(-1,0)}
\def\uB{ -- ++(0,-1)}
\def\chemin{\ua\ub\ua\ub\uA\uA\uA\uB\uA\ub\ub}
\draw[step=1cm,black,thin,dotted] (-2,0) grid (2,3);

\draw[black,line width=1,->](0,0)\chemin;
\node at (0,0)[point]{};

\foreach \i in {(0.5,-0.3), (1.5,0.7)}
    \node at \i{\scriptsize{\0}};
\foreach \i in {(1.2,0.5), (2.2,1.5),(-2.2,1.5),(-2.2,2.5)}
    \node at \i{\scriptsize{\1}};
\foreach \i in {(-0.5,2.3),(0.5,2.3),(1.5,2.3),(-1.5,0.7)}
    \node at \i{\scriptsize{\2}};
\foreach \i in {(-1.2,1.5)}
    \node at \i{\scriptsize{\3}};
\node at (-3,0.5){(a)};

\end{tikzpicture}


&



\begin{tikzpicture}[xscale=.5pt, yscale=.5pt,inner sep=0mm,point/.style={circle,draw=black,fill=black, minimum size=4pt}]

\def\ub{ -- ++(0,1)}
\def\ua{ -- ++(1,0)}
\def\uA{ -- ++(-1,0)}
\def\uB{ -- ++(0,-1)}
\def\chemin{\ua\ub\ua\ub\uA\uA\uA\uB\uA\ub\ub}
\draw[step=1cm,black,thin,dotted] (-2,0) grid (2,3);

\draw[black,line width=1,->](0,0)\chemin;
\node at (0,0)[point]{};

\draw[->,color=black!70] (0.9,-0.2) arc (-95:5:10pt);
\draw[->,color=black!70] (0.8,0.8) arc (185:85:10pt);
\draw[->,color=black!70] (1.9,0.8) arc (-95:5:10pt);
\draw[->,color=black!70] (2.2,1.8) arc (-5:95:10pt);
\draw[->,color=black!70] (-.8,2.2) arc (85:185:10pt);
\draw[->,color=black!70] (-0.8,1.2) arc (5:-95:10pt);
\draw[->,color=black!70] (-1.8,.8) arc (280:175:10pt);



\foreach \i in {(1,2.35),(0,2.35),(-2.2,2)}
    \node at \i{\scriptsize{\0}};
    
\foreach \i in {(1.3,-.3),(2.3,0.7),(2.3,2.3),(-1.1,2.35)}
    \node at \i{\scriptsize{\1}};
    
\foreach \i in {(0.8,1.3),(-.8,.7),(-2.2,0.7)}
    \node at \i{\scriptsize{\3}};
\node at (-3.25,0.5){(b)};

\end{tikzpicture}


&


\begin{tikzpicture}[xscale=.5pt, yscale=.5pt,inner sep=0mm,point/.style={circle,draw=black,fill=black, minimum size=4pt}]

\def\ub{ -- ++(0,1)}
\def\ua{ -- ++(1,0)}
\def\uA{ -- ++(-1,0)}
\def\uB{ -- ++(0,-1)}
\def\chemin{\ua\ub\ua\ub\uA\uA\uA\uB\uA\ub\ub}
\draw[step=1cm,black,thin,dotted] (-2,0) grid (2,3);

\draw[black,line width=1,<-](0,0)\chemin;
\node at (-2,3)[point]{};

\foreach \i in {(0.5,-0.3), (1.6,0.7)}
    \node at \i{\scriptsize{\2}};
\foreach \i in {(1.25,0.45), (2.2,1.5),(-2.2,1.5),(-2.2,2.5)}
    \node at \i{\scriptsize{\3}};
\foreach \i in {(-0.5,2.3),(0.5,2.3),(1.5,2.3),(-1.5,0.7)}
    \node at \i{\scriptsize{\0}};
\foreach \i in {(-1.2,1.5)}
    \node at \i{\scriptsize{\1}};

\node at (-3.5,0.5){(c)};
\end{tikzpicture}

\end{tabular}
 \caption{(a)  $w=\gras{01012223211}$. (b)  $\Delta(w) = \gras{1311001330}$. (c)  $\hat{w}=\gras{33010003232}$.}
\label{figdelta}
\end{figure}
Moreover, the word $\hat{w}:=\rho^2(\widetilde{w})$ is \emph{homologous} to $w$, i.e.,   in direction opposite to that of $w$ (Figure~\ref{figdelta}). 
A word $u\in\Freeman^*$ may contain factors in $\Cancel=\Forbidden$, corresponding to cancelling steps on a path.  Nevertheless, each word $w$ can be reduced in a unique way to a word $w'$,  by sequentially applying the rewriting rules in $\{u\mapsto \varepsilon \mid u \in \Cancel\}$. The \emph{reduced word}  $w'$ of $w$ is nothing but a word in $\mathcal P=\Freeman^*\setminus\Freeman^*\Cancel\Freeman^*$.
The \emph{turning number}\footnotemark[1] of $w$ is defined by $\Turns(w)=\left(|\Delta(w')|_\1 -|\Delta(w')|_\3 \right)/4$.
\footnotetext[1]{In \cite{bll2,bll3}, the authors introduced the notion of  \emph{winding number}  of $w$ which is $4\Turns(w)$.}\medskip

A path $w$ is \emph{closed}  if it satisfies $|w|_\0 = |w|_{\2}$ and $|w|_\1 = |w|_{\3}$, and it  is \emph{simple} if no proper factor of $w$ is  closed. 
A \emph{boundary word} is a simple and closed path, and a \emph{polyomino} is a subset of $\Z^2$ contained in some boundary word.  It is convenient to represent each closed path $w$  by its conjugacy class $\Class{w}$, also called \emph{circular word}. An adjustment is necessary to the function $\Turns$, for we take into account the closing turn. The first differences also noted $\Delta$ is defined on any closed path $w$ by setting
\[\Delta(\Class{w})\equiv \Delta(w) \cdot (w_1 - w_n), \]
which is also a closed word.
By applying the same rewriting rules, a circular word $\Class{w}$ is \emph{circularly-reduced} to a unique  word $\Class{w'}$. If $w$ is a closed path, then the \emph{turning number}\footnotemark[1] of $w$ is 
\[\oTurns(w)=\Turns(\Class{w})=\left(|\Delta(\Class{w'})|_\1 -|\Delta(\Class{w'})|_\3 \right)/4.\]
 It corresponds to its total curvature divided by $2\pi$. Clearly, the turning number $\Turns(\Class{w})$ of a closed path $w$ belongs to $\Z$  (see \cite{bll2,bll3}). 




\paragraph{The convex hull of a finite set of points}The lexicographic order $<$ on points of $\Reals^2$ or $\Z^2$ is such
 that $(x,y) < (x',y')$ when either $x < x'$ or $x=x'$ and $y<
 y'$. The {\em convex hull} of a finite set $S$ of points in $\Reals^2$
 is the intersection of all
 convex sets containing these points and is denoted by
 $\ConvHull(S)$. $S$ being finite, it is clearly a polygon in the
 plane whose vertices are elements of $S$. The {\em upper convex
 hull} of $S$, denoted by $\UpConvHull(S)$, is the clockwise oriented
 sequence of consecutive edges of $\ConvHull(S)$ starting from the
 lowest vertex and ending on the highest vertex. The {\em lower
 convex hull} of $S$, denoted by $\LoConvHull(S)$, is the clockwise
 oriented sequence of consecutive edges of $\ConvHull(S)$ starting
 from the highest vertex and ending on the lowest vertex.


