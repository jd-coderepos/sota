\documentclass{article} \usepackage{iclr2019_conference,times}



\usepackage{amsmath,amsfonts,bm}
\usepackage{ dsfont }

\newcommand{\figleft}{{\em (Left)}}
\newcommand{\figcenter}{{\em (Center)}}
\newcommand{\figright}{{\em (Right)}}
\newcommand{\figtop}{{\em (Top)}}
\newcommand{\figbottom}{{\em (Bottom)}}
\newcommand{\captiona}{{\em (a)}}
\newcommand{\captionb}{{\em (b)}}
\newcommand{\captionc}{{\em (c)}}
\newcommand{\captiond}{{\em (d)}}

\newcommand{\newterm}[1]{{\bf #1}}


\def\figref#1{figure~\ref{#1}}
\def\Figref#1{Figure~\ref{#1}}
\def\twofigref#1#2{figures \ref{#1} and \ref{#2}}
\def\quadfigref#1#2#3#4{figures \ref{#1}, \ref{#2}, \ref{#3} and \ref{#4}}
\def\secref#1{section~\ref{#1}}
\def\Secref#1{Section~\ref{#1}}
\def\twosecrefs#1#2{sections \ref{#1} and \ref{#2}}
\def\secrefs#1#2#3{sections \ref{#1}, \ref{#2} and \ref{#3}}
\def\eqref#1{equation~\ref{#1}}
\def\Eqref#1{Equation~\ref{#1}}
\def\plaineqref#1{\ref{#1}}
\def\chapref#1{chapter~\ref{#1}}
\def\Chapref#1{Chapter~\ref{#1}}
\def\rangechapref#1#2{chapters\ref{#1}--\ref{#2}}
\def\algref#1{algorithm~\ref{#1}}
\def\Algref#1{Algorithm~\ref{#1}}
\def\twoalgref#1#2{algorithms \ref{#1} and \ref{#2}}
\def\Twoalgref#1#2{Algorithms \ref{#1} and \ref{#2}}
\def\partref#1{part~\ref{#1}}
\def\Partref#1{Part~\ref{#1}}
\def\twopartref#1#2{parts \ref{#1} and \ref{#2}}

\def\ceil#1{\lceil #1 \rceil}
\def\floor#1{\lfloor #1 \rfloor}
\def\1{\bm{1}}
\newcommand{\train}{\mathcal{D}}
\newcommand{\valid}{\mathcal{D_{\mathrm{valid}}}}
\newcommand{\test}{\mathcal{D_{\mathrm{test}}}}

\def\eps{{\epsilon}}


\def\reta{{\textnormal{}}}
\def\ra{{\textnormal{a}}}
\def\rb{{\textnormal{b}}}
\def\rc{{\textnormal{c}}}
\def\rd{{\textnormal{d}}}
\def\re{{\textnormal{e}}}
\def\rf{{\textnormal{f}}}
\def\rg{{\textnormal{g}}}
\def\rh{{\textnormal{h}}}
\def\ri{{\textnormal{i}}}
\def\rj{{\textnormal{j}}}
\def\rk{{\textnormal{k}}}
\def\rl{{\textnormal{l}}}
\def\rn{{\textnormal{n}}}
\def\ro{{\textnormal{o}}}
\def\rp{{\textnormal{p}}}
\def\rq{{\textnormal{q}}}
\def\rr{{\textnormal{r}}}
\def\rs{{\textnormal{s}}}
\def\rt{{\textnormal{t}}}
\def\ru{{\textnormal{u}}}
\def\rv{{\textnormal{v}}}
\def\rw{{\textnormal{w}}}
\def\rx{{\textnormal{x}}}
\def\ry{{\textnormal{y}}}
\def\rz{{\textnormal{z}}}

\def\rvepsilon{{\mathbf{\epsilon}}}
\def\rvtheta{{\mathbf{\theta}}}
\def\rva{{\mathbf{a}}}
\def\rvb{{\mathbf{b}}}
\def\rvc{{\mathbf{c}}}
\def\rvd{{\mathbf{d}}}
\def\rve{{\mathbf{e}}}
\def\rvf{{\mathbf{f}}}
\def\rvg{{\mathbf{g}}}
\def\rvh{{\mathbf{h}}}
\def\rvu{{\mathbf{i}}}
\def\rvj{{\mathbf{j}}}
\def\rvk{{\mathbf{k}}}
\def\rvl{{\mathbf{l}}}
\def\rvm{{\mathbf{m}}}
\def\rvn{{\mathbf{n}}}
\def\rvo{{\mathbf{o}}}
\def\rvp{{\mathbf{p}}}
\def\rvq{{\mathbf{q}}}
\def\rvr{{\mathbf{r}}}
\def\rvs{{\mathbf{s}}}
\def\rvt{{\mathbf{t}}}
\def\rvu{{\mathbf{u}}}
\def\rvv{{\mathbf{v}}}
\def\rvw{{\mathbf{w}}}
\def\rvx{{\mathbf{x}}}
\def\rvy{{\mathbf{y}}}
\def\rvz{{\mathbf{z}}}

\def\erva{{\textnormal{a}}}
\def\ervb{{\textnormal{b}}}
\def\ervc{{\textnormal{c}}}
\def\ervd{{\textnormal{d}}}
\def\erve{{\textnormal{e}}}
\def\ervf{{\textnormal{f}}}
\def\ervg{{\textnormal{g}}}
\def\ervh{{\textnormal{h}}}
\def\ervi{{\textnormal{i}}}
\def\ervj{{\textnormal{j}}}
\def\ervk{{\textnormal{k}}}
\def\ervl{{\textnormal{l}}}
\def\ervm{{\textnormal{m}}}
\def\ervn{{\textnormal{n}}}
\def\ervo{{\textnormal{o}}}
\def\ervp{{\textnormal{p}}}
\def\ervq{{\textnormal{q}}}
\def\ervr{{\textnormal{r}}}
\def\ervs{{\textnormal{s}}}
\def\ervt{{\textnormal{t}}}
\def\ervu{{\textnormal{u}}}
\def\ervv{{\textnormal{v}}}
\def\ervw{{\textnormal{w}}}
\def\ervx{{\textnormal{x}}}
\def\ervy{{\textnormal{y}}}
\def\ervz{{\textnormal{z}}}

\def\rmA{{\mathbf{A}}}
\def\rmB{{\mathbf{B}}}
\def\rmC{{\mathbf{C}}}
\def\rmD{{\mathbf{D}}}
\def\rmE{{\mathbf{E}}}
\def\rmF{{\mathbf{F}}}
\def\rmG{{\mathbf{G}}}
\def\rmH{{\mathbf{H}}}
\def\rmI{{\mathbf{I}}}
\def\rmJ{{\mathbf{J}}}
\def\rmK{{\mathbf{K}}}
\def\rmL{{\mathbf{L}}}
\def\rmM{{\mathbf{M}}}
\def\rmN{{\mathbf{N}}}
\def\rmO{{\mathbf{O}}}
\def\rmP{{\mathbf{P}}}
\def\rmQ{{\mathbf{Q}}}
\def\rmR{{\mathbf{R}}}
\def\rmS{{\mathbf{S}}}
\def\rmT{{\mathbf{T}}}
\def\rmU{{\mathbf{U}}}
\def\rmV{{\mathbf{V}}}
\def\rmW{{\mathbf{W}}}
\def\rmX{{\mathbf{X}}}
\def\rmY{{\mathbf{Y}}}
\def\rmZ{{\mathbf{Z}}}

\def\ermA{{\textnormal{A}}}
\def\ermB{{\textnormal{B}}}
\def\ermC{{\textnormal{C}}}
\def\ermD{{\textnormal{D}}}
\def\ermE{{\textnormal{E}}}
\def\ermF{{\textnormal{F}}}
\def\ermG{{\textnormal{G}}}
\def\ermH{{\textnormal{H}}}
\def\ermI{{\textnormal{I}}}
\def\ermJ{{\textnormal{J}}}
\def\ermK{{\textnormal{K}}}
\def\ermL{{\textnormal{L}}}
\def\ermM{{\textnormal{M}}}
\def\ermN{{\textnormal{N}}}
\def\ermO{{\textnormal{O}}}
\def\ermP{{\textnormal{P}}}
\def\ermQ{{\textnormal{Q}}}
\def\ermR{{\textnormal{R}}}
\def\ermS{{\textnormal{S}}}
\def\ermT{{\textnormal{T}}}
\def\ermU{{\textnormal{U}}}
\def\ermV{{\textnormal{V}}}
\def\ermW{{\textnormal{W}}}
\def\ermX{{\textnormal{X}}}
\def\ermY{{\textnormal{Y}}}
\def\ermZ{{\textnormal{Z}}}

\def\vzero{{\bm{0}}}
\def\vone{{\bm{1}}}
\def\vmu{{\bm{\mu}}}
\def\vtheta{{\bm{\theta}}}
\def\va{{\bm{a}}}
\def\vb{{\bm{b}}}
\def\vc{{\bm{c}}}
\def\vd{{\bm{d}}}
\def\ve{{\bm{e}}}
\def\vf{{\bm{f}}}
\def\vg{{\bm{g}}}
\def\vh{{\bm{h}}}
\def\vi{{\bm{i}}}
\def\vj{{\bm{j}}}
\def\vk{{\bm{k}}}
\def\vl{{\bm{l}}}
\def\vm{{\bm{m}}}
\def\vn{{\bm{n}}}
\def\vo{{\bm{o}}}
\def\vp{{\bm{p}}}
\def\vq{{\bm{q}}}
\def\vr{{\bm{r}}}
\def\vs{{\bm{s}}}
\def\vt{{\bm{t}}}
\def\vu{{\bm{u}}}
\def\vv{{\bm{v}}}
\def\vw{{\bm{w}}}
\def\vx{{\bm{x}}}
\def\vy{{\bm{y}}}
\def\vz{{\bm{z}}}

\def\evalpha{{\alpha}}
\def\evbeta{{\beta}}
\def\evepsilon{{\epsilon}}
\def\evlambda{{\lambda}}
\def\evomega{{\omega}}
\def\evmu{{\mu}}
\def\evpsi{{\psi}}
\def\evsigma{{\sigma}}
\def\evtheta{{\theta}}
\def\eva{{a}}
\def\evb{{b}}
\def\evc{{c}}
\def\evd{{d}}
\def\eve{{e}}
\def\evf{{f}}
\def\evg{{g}}
\def\evh{{h}}
\def\evi{{i}}
\def\evj{{j}}
\def\evk{{k}}
\def\evl{{l}}
\def\evm{{m}}
\def\evn{{n}}
\def\evo{{o}}
\def\evp{{p}}
\def\evq{{q}}
\def\evr{{r}}
\def\evs{{s}}
\def\evt{{t}}
\def\evu{{u}}
\def\evv{{v}}
\def\evw{{w}}
\def\evx{{x}}
\def\evy{{y}}
\def\evz{{z}}

\def\mA{{\bm{A}}}
\def\mB{{\bm{B}}}
\def\mC{{\bm{C}}}
\def\mD{{\bm{D}}}
\def\mE{{\bm{E}}}
\def\mF{{\bm{F}}}
\def\mG{{\bm{G}}}
\def\mH{{\bm{H}}}
\def\mI{{\bm{I}}}
\def\mJ{{\bm{J}}}
\def\mK{{\bm{K}}}
\def\mL{{\bm{L}}}
\def\mM{{\bm{M}}}
\def\mN{{\bm{N}}}
\def\mO{{\bm{O}}}
\def\mP{{\bm{P}}}
\def\mQ{{\bm{Q}}}
\def\mR{{\bm{R}}}
\def\mS{{\bm{S}}}
\def\mT{{\bm{T}}}
\def\mU{{\bm{U}}}
\def\mV{{\bm{V}}}
\def\mW{{\bm{W}}}
\def\mX{{\bm{X}}}
\def\mY{{\bm{Y}}}
\def\mZ{{\bm{Z}}}
\def\mBeta{{\bm{\beta}}}
\def\mPhi{{\bm{\Phi}}}
\def\mLambda{{\bm{\Lambda}}}
\def\mSigma{{\bm{\Sigma}}}

\DeclareMathAlphabet{\mathsfit}{\encodingdefault}{\sfdefault}{m}{sl}
\SetMathAlphabet{\mathsfit}{bold}{\encodingdefault}{\sfdefault}{bx}{n}
\newcommand{\tens}[1]{\bm{\mathsfit{#1}}}
\def\tA{{\tens{A}}}
\def\tB{{\tens{B}}}
\def\tC{{\tens{C}}}
\def\tD{{\tens{D}}}
\def\tE{{\tens{E}}}
\def\tF{{\tens{F}}}
\def\tG{{\tens{G}}}
\def\tH{{\tens{H}}}
\def\tI{{\tens{I}}}
\def\tJ{{\tens{J}}}
\def\tK{{\tens{K}}}
\def\tL{{\tens{L}}}
\def\tM{{\tens{M}}}
\def\tN{{\tens{N}}}
\def\tO{{\tens{O}}}
\def\tP{{\tens{P}}}
\def\tQ{{\tens{Q}}}
\def\tR{{\tens{R}}}
\def\tS{{\tens{S}}}
\def\tT{{\tens{T}}}
\def\tU{{\tens{U}}}
\def\tV{{\tens{V}}}
\def\tW{{\tens{W}}}
\def\tX{{\tens{X}}}
\def\tY{{\tens{Y}}}
\def\tZ{{\tens{Z}}}


\def\gA{{\mathcal{A}}}
\def\gB{{\mathcal{B}}}
\def\gC{{\mathcal{C}}}
\def\gD{{\mathcal{D}}}
\def\gE{{\mathcal{E}}}
\def\gF{{\mathcal{F}}}
\def\gG{{\mathcal{G}}}
\def\gH{{\mathcal{H}}}
\def\gI{{\mathcal{I}}}
\def\gJ{{\mathcal{J}}}
\def\gK{{\mathcal{K}}}
\def\gL{{\mathcal{L}}}
\def\gM{{\mathcal{M}}}
\def\gN{{\mathcal{N}}}
\def\gO{{\mathcal{O}}}
\def\gP{{\mathcal{P}}}
\def\gQ{{\mathcal{Q}}}
\def\gR{{\mathcal{R}}}
\def\gS{{\mathcal{S}}}
\def\gT{{\mathcal{T}}}
\def\gU{{\mathcal{U}}}
\def\gV{{\mathcal{V}}}
\def\gW{{\mathcal{W}}}
\def\gX{{\mathcal{X}}}
\def\gY{{\mathcal{Y}}}
\def\gZ{{\mathcal{Z}}}

\def\sA{{\mathbb{A}}}
\def\sB{{\mathbb{B}}}
\def\sC{{\mathbb{C}}}
\def\sD{{\mathbb{D}}}
\def\sF{{\mathbb{F}}}
\def\sG{{\mathbb{G}}}
\def\sH{{\mathbb{H}}}
\def\sI{{\mathbb{I}}}
\def\sJ{{\mathbb{J}}}
\def\sK{{\mathbb{K}}}
\def\sL{{\mathbb{L}}}
\def\sM{{\mathbb{M}}}
\def\sN{{\mathbb{N}}}
\def\sO{{\mathbb{O}}}
\def\sP{{\mathbb{P}}}
\def\sQ{{\mathbb{Q}}}
\def\sR{{\mathbb{R}}}
\def\sS{{\mathbb{S}}}
\def\sT{{\mathbb{T}}}
\def\sU{{\mathbb{U}}}
\def\sV{{\mathbb{V}}}
\def\sW{{\mathbb{W}}}
\def\sX{{\mathbb{X}}}
\def\sY{{\mathbb{Y}}}
\def\sZ{{\mathbb{Z}}}

\def\emLambda{{\Lambda}}
\def\emA{{A}}
\def\emB{{B}}
\def\emC{{C}}
\def\emD{{D}}
\def\emE{{E}}
\def\emF{{F}}
\def\emG{{G}}
\def\emH{{H}}
\def\emI{{I}}
\def\emJ{{J}}
\def\emK{{K}}
\def\emL{{L}}
\def\emM{{M}}
\def\emN{{N}}
\def\emO{{O}}
\def\emP{{P}}
\def\emQ{{Q}}
\def\emR{{R}}
\def\emS{{S}}
\def\emT{{T}}
\def\emU{{U}}
\def\emV{{V}}
\def\emW{{W}}
\def\emX{{X}}
\def\emY{{Y}}
\def\emZ{{Z}}
\def\emSigma{{\Sigma}}

\newcommand{\etens}[1]{\mathsfit{#1}}
\def\etLambda{{\etens{\Lambda}}}
\def\etA{{\etens{A}}}
\def\etB{{\etens{B}}}
\def\etC{{\etens{C}}}
\def\etD{{\etens{D}}}
\def\etE{{\etens{E}}}
\def\etF{{\etens{F}}}
\def\etG{{\etens{G}}}
\def\etH{{\etens{H}}}
\def\etI{{\etens{I}}}
\def\etJ{{\etens{J}}}
\def\etK{{\etens{K}}}
\def\etL{{\etens{L}}}
\def\etM{{\etens{M}}}
\def\etN{{\etens{N}}}
\def\etO{{\etens{O}}}
\def\etP{{\etens{P}}}
\def\etQ{{\etens{Q}}}
\def\etR{{\etens{R}}}
\def\etS{{\etens{S}}}
\def\etT{{\etens{T}}}
\def\etU{{\etens{U}}}
\def\etV{{\etens{V}}}
\def\etW{{\etens{W}}}
\def\etX{{\etens{X}}}
\def\etY{{\etens{Y}}}
\def\etZ{{\etens{Z}}}

\newcommand{\pdata}{p_{\rm{data}}}
\newcommand{\ptrain}{\hat{p}_{\rm{data}}}
\newcommand{\Ptrain}{\hat{P}_{\rm{data}}}
\newcommand{\pmodel}{p_{\rm{model}}}
\newcommand{\Pmodel}{P_{\rm{model}}}
\newcommand{\ptildemodel}{\tilde{p}_{\rm{model}}}
\newcommand{\pencode}{p_{\rm{encoder}}}
\newcommand{\pdecode}{p_{\rm{decoder}}}
\newcommand{\precons}{p_{\rm{reconstruct}}}

\newcommand{\laplace}{\mathrm{Laplace}} 

\newcommand{\E}{\mathbb{E}}
\newcommand{\Ls}{\mathcal{L}}
\newcommand{\R}{\mathbb{R}}
\newcommand{\emp}{\tilde{p}}
\newcommand{\lr}{\alpha}
\newcommand{\reg}{\lambda}
\newcommand{\rect}{\mathrm{rectifier}}
\newcommand{\softmax}{\mathrm{softmax}}
\newcommand{\sigmoid}{\sigma}
\newcommand{\softplus}{\zeta}
\newcommand{\KL}{D_{\mathrm{KL}}}
\newcommand{\Var}{\mathrm{Var}}
\newcommand{\standarderror}{\mathrm{SE}}
\newcommand{\Cov}{\mathrm{Cov}}
\newcommand{\normlzero}{L^0}
\newcommand{\normlone}{L^1}
\newcommand{\normltwo}{L^2}
\newcommand{\normlp}{L^p}
\newcommand{\normmax}{L^\infty}

\newcommand{\parents}{Pa} 

\DeclareMathOperator*{\argmax}{arg\,max}
\DeclareMathOperator*{\argmin}{arg\,min}

\DeclareMathOperator{\sign}{sign}
\DeclareMathOperator{\Tr}{Tr}
\let\ab\allowbreak
 \usepackage[utf8]{inputenc} \usepackage[T1]{fontenc}    \usepackage{hyperref}       \usepackage{url}            \usepackage{booktabs}       \usepackage{amsfonts}       \usepackage{nicefrac}       \usepackage{microtype}      \usepackage{amsmath,graphicx}
\usepackage{amssymb}
\usepackage{amsthm}
\usepackage{enumitem}
\usepackage{overpic}
\usepackage{color}
\usepackage{tikz}
\usepackage{adjustbox}
\usepackage{enumerate}
\usepackage{wrapfig}
\usepackage{lipsum}
\usepackage{hyperref}
\usepackage{url}
\usepackage{tikz}
\usepackage{adjustbox}
\usepackage{subfig}
\usepackage{enumerate}
\usepackage{epstopdf}

\captionsetup[figure]{font=small,labelsep=period,subrefformat=parens}


\newcommand{\theHalgorithm}{\arabic{algorithm}}
\newcommand {\HH} {{\mathbb{H}}}
\newcommand {\M} {{\mathcal{M}}}
\newcommand {\ba} {{\mathcal A}}
\newtheorem{theorem}{Theorem}[section]
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{corollary}[theorem]{Corollary}
\newtheorem{conjecture}[theorem]{Conjecture}
\newtheorem{prop}[theorem]{Proposition}
\newtheorem{definition}[theorem]{Definition}
\newtheorem{remark}[theorem]{Remark}
\newtheorem{df}{Definition}
\newcommand{\expe}{\mathbb{E}}
\newcommand{\prob}{\mathbb{P}}



\title{Supervised Community Detection with Line Graph Neural Networks}


\author{Zhengdao Chen, Lisha Li,
Joan Bruna\thanks{Corresponding emails: \href{mailto:zc1216@nyu.edu}{zc1216@nyu.edu} and \href{mailto:bruna@cims.nyu.edu}{bruna@cims.nyu.edu}.}\L(\theta) = \frac{1}{T} \sum_{t \leq T} \ell( \Phi_{\theta}(G_t), y_t)~
\label{gnneq}
{z^{(k+1)}} = \rho \left[ \sum_{O_i \in \mathcal{F}} O_i x^{(k)} \theta_i \right], \hspace{10pt}
{\overline{z}^{(k+1)}} = \sum_{O_i \in \mathcal{F}} O_i x^{(k)} \theta_i
B_{(i\to j), (i'\to j')}=\left\{ 
\begin{array}{cc}
1 & \text{if } j=i' \text{ and } j'\neq i\,,\\
0 & \text{otherwise.}
\end{array} \right.
\label{gnneqline}
\begin{aligned}
z^{(k+1)} &= \rho \left[ \sum_{O_i \in \mathcal{F}} O_i x^{(k)} \theta_i + \sum_{O''_j \in \mathcal{F}''} O''_j y^{(k)} \theta''_i \right] \\
w^{(k+1)} &= \rho \left[ \sum_{O'_l \in \mathcal{F}'} O'_l y^{(k)} \theta'_i + \sum_{O''_j \in \mathcal{F}''} (O''_j)^T x^{(k+1)} \theta'''_j \right]
\end{aligned}

\label{lossfunction}
\ell( \theta ) =  \min_{ \pi \in S_{C}} - \sum_{i \in V} \log o_{i, \pi(y_i)}~,

\label{gygy}
\hat{Y} = \frac{e}{\|e\|}\,,\text{ with } e = \left(\prod_{k =1}^K \sum_{q \leq Q} \theta_q^{(k)} A_q \right) w \,.  

\label{loss}
    L_n(\beta) =1-\mathbb{E}_{X_n,Y_n} \frac{\beta^\top Y_n \beta}{ \beta^\top X_n \beta}~,\text{with }
Y_n = z_n z_n^\top \in \R^{M \times M}\,,\,(z_n)_j = \langle O_j w, y \rangle\,\text{ and } X_n = U_n U_n^\top\in \R^{M \times M} \,,U_n = \begin{bmatrix}
(O_1 w)^\top \\
\dots \\
(O_M w)^\top 
\end{bmatrix}\,.

    overlap(y, \hat{y}) = \max_{\pi \in S_C} \big(\frac{1}{n}\sum_u \delta_{\pi(y(u)), \hat{y}(u)} - \frac{1}{C}\big)/(1-\frac{1}{C})

\label{first_bound}
    |L_n(\beta_l) - L_n(\beta_g)| \leq |L_n(\beta_l) - \tilde{L}_n(\beta_l)| + |\tilde{L}_n(\beta_l) - \tilde{L}_n(\beta_g)| + |\tilde{L}_n(\beta_g) - L_n(\beta_g)|

    |L_n(\beta_l) - L_n(\beta_g)| \leq |L_n(\beta_l) - \tilde{L}_n(\beta_l)| + |\tilde{L}_n(\beta_l) - \tilde{L}_n(\tilde{\beta}_g)| + |\tilde{L}_n(\beta_g) - L_n(\beta_g)|
\nabla^2 S_n(\gamma_l) = \nabla^2 \tilde{S}_n(\gamma_l) + (\nabla^2 S_n(\gamma_l) - \nabla^2 \tilde{S}_n(\gamma_l))0 \geq \lambda_{1}(\nabla^2 S_n(\gamma_l)) \geq \lambda_{1}(\nabla^2 \tilde{S}_n(\gamma_l)) - \|\nabla^2 S_n(\gamma_l) - \nabla^2 \tilde{S}_n(\gamma_l)\|
\label{first_ineq}
\lambda_{1}(\nabla^2 \tilde{S}_n(\gamma_l)) \leq \|\nabla^2 S_n(\gamma_l) - \nabla^2 \tilde{S}_n(\gamma_l)\|
\lambda_{1}(\nabla^2 \tilde{S}_n(\gamma)) \geq \frac{2}{\| \gamma \|^2}\{[1 - \cos^2(\gamma, \tilde{\gamma}_g)] \cdot [\lambda_1(\bar{A}_n) - \lambda_2(\bar{A}_n)] - 2 \| \gamma\| \cdot \| \nabla \tilde{S}_n(\gamma) \|\}

\label{noiseless_hess}
\begin{split}
    \nabla^2 \tilde{S}_n(\gamma) =& 2 \expe \left[\frac{(\gamma^T \gamma) A_n - (\gamma^T A_n \gamma) I}{(\gamma^T \gamma)^2} + \frac{4 (\gamma^T A_n \gamma) \gamma \gamma^T - 4 (\gamma^T \gamma) A_n \gamma \gamma^T}{(\gamma^T \gamma)^3}\right]\\
    =& 2 \expe \left[\frac{(\gamma^T \gamma) A_n - (\gamma^T A_n \gamma) I}{(\gamma^T \gamma)^2} + \frac{4 [(\gamma^T \gamma) A_n - (\gamma^T A_n \gamma) I] \gamma \gamma^T }{(\gamma^T \gamma)^3}\right] \\
    =& 2 \left[\frac{(\gamma^T \gamma) \bar{A}_n - (\gamma^T \bar{A}_n \gamma) I}{(\gamma^T \gamma)^2} + \frac{4 [(\gamma^T \gamma) \bar{A}_n - (\gamma^T \bar{A}_n \gamma) I] \gamma \gamma^T }{(\gamma^T \gamma)^3}\right]
\end{split}

    \nabla^2 \tilde{S}_n(\gamma) = \frac{2}{\| \gamma \|^6} (Q_1 - Q_2)

    \begin{split}
        \lambda_{1}(Q_1) =& (\gamma^T \gamma) \left[l_1 \sum_{i=1}^M \alpha_i^2 - \sum_{i=1}^M l_i \alpha_i^2\right] \\
        \geq& (\gamma^T \gamma)\left[\left((\sum_{i=1}^M \alpha_i^2) - \alpha_1^2\right) (l_1 - l_2)\right]\\
        =& (\gamma^T \gamma)^2 [(1 - \bar{\alpha}_1^2) (l_1 - l_2)]
    \end{split}

    \begin{split}
        [(\gamma^T \gamma) \bar{A}_n - (\gamma^T \bar{A}_n \gamma) I] \gamma 
        = \sum_{k=1}^M \left[l_k \sum_{i=1}^M \alpha_i^2 - \sum_{i=1}^M l_i \alpha_i^2\right] \alpha_k \hat{\gamma}_k 
    \end{split}

\| v \cdot w^T \| = |v^T w|

    \begin{split}
        \|Q_2\| =& 4 \left|\left(\sum_{k=1}^M \alpha_k \hat{\gamma}_k\right)^T \left(\sum_{k=1}^M [l_k(\sum_{i=1}^M \alpha_i^2) - (\sum_{i=1}^M l_i \alpha_i^2)] \alpha_k \hat{\gamma}_k \right)\right| \\
        =& 4 \left|\frac{(\gamma^T \gamma)^2}{2} \gamma^T \nabla \tilde{S}(\gamma)\right| \\
        \leq & 2 (\gamma^T \gamma)^2 \| \gamma \| \| \nabla \tilde{S}(\gamma)\|
    \end{split}

    \begin{split}
        \lambda_{1}(Q_1 - Q_2) \geq& \lambda_{1}(Q_1) - \| Q_2\| \\
        \geq& (\gamma^T \gamma)^2 ([(1 - \bar{\alpha}_1^2) (l_1 - l_2)] - 2 \| \gamma \| \| \nabla_\gamma S(\gamma)\|) \end{split}

\label{bound_on_cos}
1-\cos^2(\gamma_l, \tilde{\gamma}_g) \leq \frac{ 2 \| \gamma_l \| \cdot \| \nabla \tilde{S}_n(\gamma_l)\| + \frac{\| \gamma_l \|^2}{2} \|\nabla^2 S_n(\gamma_l) - \nabla^2 \tilde{S}_n(\gamma_l)\|}{\lambda_1(\bar{A}_n)- \lambda_2(\bar{A}_n)}

    \|\gamma_l \| \cdot \| \nabla \tilde{S}_n(\gamma_l)\| \leq 2 \mu_n \nu_n \delta_n (1 + 3 \nu_n + \delta \nu_n)

\label{noised_grad}
    \nabla S_n(\gamma) = 2 \expe \frac{A_n \gamma}{\gamma^T B_n \gamma} - 2 \expe \frac{(\gamma^T A_n \gamma) B_n \gamma}{(\gamma^T B_n \gamma)^2}

\label{noiseless_grad}
    \nabla \tilde{S}_n(\gamma) = 2 \expe \frac{A_n \gamma}{\gamma^T \gamma} - 2 \expe \frac{(\gamma^T A_n \gamma) \gamma}{(\gamma^T \gamma)^2}

    \nabla S_n(\gamma) - \nabla \tilde{S}_n(\gamma) =
    \expe \left[ \frac{2 (\gamma^T \gamma - \gamma^T B_n \gamma) A_n \gamma}{(\gamma^T B_n \gamma)(\gamma^T \gamma)} - \frac{2 (\gamma^T A_n \gamma)[(\gamma^T \gamma)^2 B_n \gamma - (\gamma^T B_n \gamma)^2 \gamma]}{(\gamma^T B_n \gamma)^2 (\gamma^T \gamma)^2} \right]

    \begin{split}
        \| \nabla \tilde{S}_n(\gamma_l) \| =& \left\| \expe \left[ \frac{2 (\gamma_l^T \gamma_l - \gamma_l^T B_n \gamma_l) A_n \gamma_l}{(\gamma_l^T B_n \gamma_l)(\gamma_l^T \gamma_l)} - \frac{2 (\gamma_l^T A_n \gamma_l)[(\gamma_l^T \gamma_l)^2 B_n \gamma_l - (\gamma_l^T B_n \gamma_l)^2 \gamma_l]}{(\gamma_l^T B_n \gamma_l)^2 (\gamma_l^T \gamma_l)^2} \right] \right\| \\
        \leq& \frac{2}{\| \gamma_l \|} \expe \left[\frac{|\lambda_1(A_n)| \| \Delta B_n\|}{|\lambda_M(B_n)|} + 3 \frac{|\lambda_1(A_n)| \| \Delta B_n\|}{\lambda_M^2(B_n)} + \frac{|\lambda_1(A_n)| \| \Delta B_n\|^2}{\lambda_M^2(B_n)} \right]
    \end{split}

\begin{split}
\| \nabla \tilde{S}_n(\gamma_l) \| \leq & \frac{2}{\| \gamma_l \|} \Big[\left(\expe |\lambda_1(A_n)|^3 \expe \|\Delta B_n \|^3 \expe  \frac{1}{|\lambda_M(B_n)|^3}\right)^{\frac{1}{3}} \\
&+ 3 \left(\expe |\lambda_1(A_n)|^3 \expe \|\Delta B_n \|^3 \expe  \frac{1}{|\lambda_M(B_n)|^6}\right)^{\frac{1}{3}} \\
 &+ \left(\expe |\lambda_1(A_n)|^3 \expe \|\Delta B_n \|^6 \expe  \frac{1}{|\lambda_M(B_n)|^6}\right)^{\frac{1}{3}} \Big]~.
\end{split}

\begin{split}
\| \gamma_l \| \cdot \| \nabla \tilde{S}_n(\gamma_l) \| \leq & 
2 (\mu_n \nu_n \delta_n + 3 \mu_n \nu_n^2 \delta_n + \mu_n \delta_n^2 \nu_n^2) \\
=& 2 \mu_n \nu_n \delta_n (1 + 3 \nu_n + \delta \nu_n)
\end{split}

    \begin{split}
        \expe |\lambda_1(B_n)|^6 = & \expe \| B_n \|^6 \\
        = & \expe \| I + \Delta B_n \|^6 \\
        \leq & \expe (\| I \| + \| \Delta B_n \|)^6 \\
        = & \expe (1 + \| \Delta B_n \|)^6
    \end{split}
gma
    \begin{split}
        \expe (1 + X)^6 = \expe X^6 + 6 \expe X^5 + 15 \expe X^4 + 20 \expe X^3 + 15 \expe X^2 + 6 \expe X + 1 
    \end{split}

    \begin{split}
        \expe X^k = & \mathds{1}_{X > 1} \expe X^k + \mathds{1}_{X \leq 1} \expe X^k \\
        \leq & 1 + \mathds{1}_{X \leq 1} \expe X^6 \\
        \leq & 1 + \expe X^6
    \end{split}

\begin{split}
\| \gamma_l \|^2 \cdot \|\nabla^2 S_n(\gamma) - \nabla^2 \tilde{S}_n(\gamma) \| \leq & \mu_n \nu_n \delta_n (10 + 14 \nu_n + 2 \delta_n \nu_n + 16 \nu_n^2 + 16 \delta'_n \nu_n \\ & + 8 \delta'_n \nu_n^2 + 8 \delta'_n \nu_n + 8 \delta_n \delta'_n \nu)
\end{split}

    \begin{split}
        \nabla^2 S_n(\gamma) - \nabla^2 \tilde{S}_n(\gamma) =&
        2 \expe [H_1] - 2 \expe [H_2] + 8 \expe [H_2] - 8 \expe [H_4]
    \end{split}

    H_1 = \frac{(\gamma^T \gamma) A_n - (\gamma^T B_n \gamma) A_n}{(\gamma^T B_n \gamma)(\gamma^T \gamma)}

    H_2 = \frac{(\gamma^T A_n \gamma) [(\gamma^T \gamma)^2 B_n - (\gamma^T B_n \gamma)^2] I)}{(\gamma^T B \gamma)^2 (\gamma^T \gamma)^2}

    H_3 = \frac{(\gamma^T A_n \gamma) [(\gamma^T \gamma)^3 B_n \gamma \gamma^T B_n^T - (\gamma^T B_n \gamma)^3 \gamma \gamma^T]}{(\gamma^T B_n \gamma)^3 (\gamma^T \gamma)^3}

    H_4 = \frac{(\gamma^T \gamma)^2 A_n \gamma \gamma^T B_n - (\gamma^T B_n \gamma)^2 A \gamma \gamma^T}{(\gamma^T B_n \gamma)^2 (\gamma^T \gamma)^2}

    \| H_1 \| \leq \frac{1}{\| \gamma \|^2} \frac{\| \Delta B_n \| |\lambda_1(A_n)|}{|\lambda_M(B_n)|}

    \begin{split}
        \|\gamma\|^2 \cdot \expe \| H_1\| \leq &  \left(\expe \frac{1}{|\lambda_M(B_n)|^3}\right)^\frac{1}{3} (\expe |\lambda_1(A_n)|^3)^\frac{1}{3} (\expe \| \Delta B_n \|^3)^\frac{1}{3} \\
        \leq & \mu_n \nu_n \delta_n~.
    \end{split}

    H_2 = \frac{(\gamma^T A_n \gamma)[(\gamma^T \gamma)^2 \Delta B_n - 2 (\gamma^T \gamma) (\gamma^T \Delta B_n \gamma) I - (\gamma^T \Delta B_n \gamma)^2 I]}{(\gamma^T B_n \gamma)^2 (\gamma^T \gamma)^2}

    \| H_2 \| \leq \frac{1}{\| \gamma \|^2} \frac{1}{\lambda_M^2 (B_n)} |\lambda_1(A_n)| (3 \| \Delta B_n \| + \| \Delta B_n \|^2)

    \begin{split}
        \|\gamma\|^2 \cdot \expe \| H_2\| \leq &  \left(\expe \frac{3}{|\lambda_M(B_n)|^6}\right)^\frac{1}{3} (\expe |\lambda_1(A_n)|^3)^\frac{1}{3} (\expe \| \Delta B_n \|^3)^\frac{1}{3} \\
        & + \left(\expe \frac{3}{|\lambda_M(B_n)|^6}\right)^\frac{1}{3} (\expe |\lambda_1(A_n)|^3)^\frac{1}{3} (\expe \| \Delta B_n \|^6)^\frac{1}{3} \\
        \leq & \mu_n \nu_n \delta_n (3 \nu_n + \delta_n \nu_n)
    \end{split}

\begin{split}
    (\gamma^T \gamma)^3 B_n \gamma \gamma^T B_n^T - (\gamma^T B_n \gamma)^3 \gamma \gamma^T =& 
    (\gamma^T \gamma)^3 (B_n - I) \gamma \gamma^T B_n + (\gamma^T \gamma)^3 \gamma \gamma^T (B_n - I)\\
    & + [(\gamma^T \gamma)^3 - (\gamma^T B_n \gamma)^3] \gamma \gamma^T \\
    =& (\gamma^T \gamma)^3 \Delta B_n \gamma \gamma^T B_n + (\gamma^T \gamma)^3 \gamma \gamma^T \Delta B_n \\
    & + [(\gamma^T B_n \gamma)^2 (-\gamma^T \Delta B_n \gamma) \gamma \gamma^T + (\gamma^T B_n \gamma) (-\gamma^T \Delta B_n \gamma) \gamma \gamma^T \\
    & + (-\gamma^T \Delta B_n \gamma) \gamma \gamma^T]
\end{split}

    \begin{split}
        H_3 =& (\gamma^T A_n \gamma) \Big[\frac{(\gamma^T \gamma)^3 \Delta B_n \gamma \gamma^T B_n + (\gamma^T \gamma)^3 \gamma \gamma^T \Delta B_n + (-\gamma^T \Delta B_n \gamma) \gamma \gamma^T}{(\gamma^T B_n \gamma)^3 (\gamma^T \gamma)^3} \\
        & + \frac{(-\gamma^T \Delta B_n \gamma) \gamma \gamma^T}{(\gamma^T B_n \gamma)^2(\gamma^T \gamma)} + \frac{(-\gamma^T \Delta B_n \gamma) \gamma \gamma^T}{(\gamma^T B_n \gamma)(\gamma^T \gamma)^2}\Big]
    \end{split}

    \|H_3\| \leq \frac{|\lambda_1(A_n)|}{\| \gamma \|^2} \left[\frac{1}{|\lambda_M^3(B_n)|}(\| \Delta B_n \| |\lambda_1(B_n)| + 2 \| \Delta B_n \|) + \frac{1}{\lambda_M^2(B_n)} \| \Delta B_n\| + \frac{1}{|\lambda_M(B_n)|}\| \Delta B_n \|\right]

    \begin{split}
        \|\gamma\|^2 \cdot \expe \| H_3\| \leq & \left(\expe \frac{1}{|\lambda_M(B_n)|^6}\right)^\frac{1}{2} (\expe |\lambda_1(A_n)|^6)^\frac{1}{6} (\expe \| \Delta B_n \|^6)^\frac{1}{6} (\expe |\lambda_1(B_n)|^6)^\frac{1}{6} \\
        &+ 2\left(\expe \frac{1}{|\lambda_M(B_n)|^6}\right)^\frac{1}{2} (\expe |\lambda_1(A_n)|^3)^\frac{1}{3} (\expe \| \Delta B_n \|^6)^\frac{1}{6} \\
        &+ \left(\expe \frac{1}{|\lambda_M(B_n)|^6}\right)^\frac{1}{3} (\expe |\lambda_1(A_n)|^3)^\frac{1}{3} (\expe \| \Delta B_n \|^3)^\frac{1}{3} \\
        &+ \left(\expe \frac{1}{|\lambda_M(B_n)|^3}\right)^\frac{1}{3} (\expe |\lambda_1(A_n)|^3)^\frac{1}{3} (\expe \| \Delta B_n \|^3)^\frac{1}{3} \\
        \leq & \mu_n \nu_n \delta_n (\delta'_n \nu_n^2 + 2 \nu_n^2 + \nu_n + 1)
    \end{split}

    H_4 = \frac{[-2(\gamma^T \gamma)(\gamma^T \Delta B_n \gamma) I - (\gamma^T \Delta B_n \gamma)^2 I] A_n \gamma \gamma^T B_n + (\gamma^T B_n \gamma)^2 A_n \gamma \gamma^T \Delta B_n}{(\gamma^T B_n \gamma)^2 (\gamma^T \gamma)^2}

    \| H_4 \| \leq \frac{1}{\| \gamma \|^2} \left[ \frac{1}{\lambda_M^2(B_n)}(2 \| \Delta B_n \| + \| \Delta B_n \|^2) |\lambda_1(A_n)| |\lambda_1(B_n)| + \frac{1}{\lambda_M^2(B_n)} |\lambda_1^2 (B_n)| |\lambda_1(A_n)| \| \Delta B_n\| \right]

\begin{split}
    \|\gamma\|^2 \cdot \expe \| H_4 \| \leq & 2 \left(\expe \frac{1}{|\lambda_M(B_n)|^6}\right)^\frac{1}{3} (\expe |\lambda_1(A_n)|^3)^\frac{1}{3} (\expe \| \Delta B_n \|^6)^\frac{1}{6} (\expe |\lambda_1(B_n)|^6)^\frac{1}{6} \\
    & + \left(\expe \frac{1}{|\lambda_M(B_n)|^6}\right)^\frac{1}{3} (\expe |\lambda_1(A_n)|^6)^\frac{1}{6} (\expe \| \Delta B_n \|^6)^\frac{1}{3} (\expe |\lambda_1(B_n)|^6)^\frac{1}{6} \\
    & +  \left(\expe \frac{1}{|\lambda_M(B_n)|^6}\right)^\frac{1}{3} (\expe |\lambda_1(A_n)|^6)^\frac{1}{6} (\expe \| \Delta B_n \|^6)^\frac{1}{6} (\expe |\lambda_1(B_n)|^6)^\frac{1}{3} \\
    \leq & \mu_n \nu_n \delta_n (2 \nu_n \delta'_n + \delta_n \delta'_n \nu_n + {\delta'_n}^2 \nu_n)
\end{split}

    \begin{split}
        \| \gamma_l \|^2 \cdot \|\nabla^2 S_n(\gamma) - \nabla^2 \tilde{S}_n(\gamma) \|
        \leq & \mu_n \nu_n \delta_n (10 + 14 \nu_n + 2 \delta_n \nu_n + 16 \nu_n^2 + 16 \delta'_n \nu_n \\ & + 8 \delta'_n \nu_n^2 + 8 \delta'_n \nu_n + 8 \delta_n \delta'_n \nu)
    \end{split}

    \begin{split}
        1-\cos^2(\gamma_l, \tilde{\gamma}_g) \leq & \eta_n [4 \mu_n \nu_n \delta_n (1 + 3 \nu_n \delta_n \mu_n) + \frac{1}{2}\mu_n \nu_n \delta_n (10 + 14 \nu_n + 2 \delta_n \nu_n + 16 \nu_n^2 \\ & + 16 \delta'_n \nu_n + 8 \delta'_n \nu_n^2 + 8 \delta'_n \nu_n + 8 \delta_n \delta'_n \nu)] \\
        = & \mu_n \nu_n \delta_n \eta_n ( 9 + 19 \nu_n + 5 \delta_n \nu_n + 8 \nu_n^2 + 8 \delta'_n \nu_n + 4 \delta'_n {\nu_n}^2 + 4 \delta'_n \nu_n + 4 \delta_n \delta'_n \nu_n)
    \end{split}

\label{bound_cos_2}
    1-\cos^2(\gamma_l, \tilde{\gamma}_g) \leq \mu_n \nu_n \delta_n \eta_n C(\delta_n, \nu_n)

    \begin{split}
        \tilde{L}_n(\beta_l) =& \tilde{S}_n(\gamma_l) \\
        =& \frac{\sum_{i=1}^M \alpha_i^2 l_i}{\sum_{i=1}^M \alpha_i^2} 
        = \sum_{i=1}^M \bar{\alpha}_i^2 l_i
    \end{split}

\label{bound_second_term_ito_cos}
    |\tilde{L}_n(\tilde{\beta_g}) - \tilde{L}_n(\beta_l)| \leq (1 - \bar{\alpha}_1^2) l_1 \leq (1 - \cos^2(\gamma_l, \tilde{\gamma}_g)) \lambda_1 (\bar{A}_n)

\label{bound_1_and_3}
    |L_n(\beta) - \tilde{L}_n(\beta)| \leq (\expe \| \Delta B_n \|^3)^{\frac{1}{3}} \cdot (\expe |\lambda_1(A_n)|^3)^{\frac{1}{3}} \cdot \left(\expe |\frac{1}{\lambda_M(B_n)}|^3\right)^{\frac{1}{3}}

\begin{split}
    |L_n(\beta) - \tilde{L}_n(\beta)| =& S_n(\gamma) - \tilde{S}_n(\gamma) \\
    =& \left|\expe \frac{(\gamma^T \Delta B_n \gamma)(\gamma^T A_n \gamma)}{(\gamma^T B_n \gamma)(\gamma^T \gamma)}\right| \\
    \leq& \expe \frac{\| \Delta B_n \| |\lambda_1(A_n)|}{|\lambda_M(B_n)|}
\end{split}

\begin{split}
    |L_n(\beta_l) - L_n(\beta_g)| \leq & 2 (\expe \| \Delta B_n \|^3)^{\frac{1}{3}} \cdot (\expe |\lambda_1(A_n)|^3)^{\frac{1}{3}} \cdot \left(\expe \left|\frac{1}{\lambda_M(B_n)}\right|^3\right)^{\frac{1}{3}} + (1 - \cos^2(\gamma_l, \tilde{\gamma}_g)) \lambda_1 (\bar{A}_n) \\
    \leq & 2 \mu_n \nu_n \delta_n + \mu_n \nu_n \delta_n \eta_n C(\delta_n, \nu_n) \cdot \lambda_1 (\bar{A}_n)
\end{split}

    \begin{split}
        |L_n(\beta_g) - \tilde{L}_n(\tilde{\beta}_g)| \leq & \max\{ |L_n(\beta_g) - \tilde{L}_n(\beta_g)|, |L_n(\tilde{\beta}_g) - \tilde{L}_n(\tilde{\beta}_g)| \} \\
        \leq & (\expe \| \Delta B_n \|^3)^{\frac{1}{3}} \cdot (\expe |\lambda_1(A_n)|^3)^{\frac{1}{3}} \cdot (\expe |\frac{1}{\lambda_M(B_n)}|^3)^{\frac{1}{3}} \\
        \leq & \mu_n \nu_n \delta_n
    \end{split}

    \begin{split}
        L_n(\beta_g) \geq & \tilde{L}_n(\tilde{\beta}_g) - \mu_n \nu_n \delta_n \\
        \geq & \lambda_1(\bar{A}_n) - \mu_n \nu_n \delta_n \\
        \geq & \eta_n^{-1} - \mu_n \nu_n \delta_n 
    \end{split}

    \lambda_1(\bar{A}_n) \leq L_n(\beta_g) + \mu_n \nu_n \delta_n

    \begin{split}
        |L_n(\beta_l) - L_n(\beta_g)| \leq & 2 \mu_n \nu_n \delta_n + (1 - \cos^2(\gamma_l, \tilde{\gamma}_g)) [L_n(\beta_g) + \mu_n \nu_n \delta_n] \\
        \leq & \mu_n \nu_n \delta_n [2 + \eta_n \mu_n \nu_n \delta_n C(\delta_n, \nu_n)] + \eta_n \mu_n \nu_n \delta_n C(\delta_n, \nu_n) L_n(\beta_g) \\
        \leq & L_n(\beta_g) \left\{ \frac{\mu_n \nu_n \delta_n [2 + \eta_n \mu_n \nu_n \delta_n C(\delta_n, \nu_n)]}{\eta_n^{-1} - \mu_n \nu_n \delta_n} + \eta_n \mu_n \nu_n \delta_n C(\delta_n, \nu_n) \right\} \\
        =& \frac{2 \eta_n \mu_n \nu_n \delta_n [2 + C(\delta_n, \nu_n)]}{1 - \eta_n \mu_n \nu_n \delta_n} L_n(\beta_g)
    \end{split}
\sum_{i,j} (1 - s(i) s(j)) A_{i,j} \min_{s(i) = \pm 1} s^T (D - A) s = s^T \Delta sy^{(n)} = \tilde{A} w^{(n-1)}~~,~w^{(n)} = \frac{y^{(n)} - \langle y^{(n)}, v \rangle v}{\| y^{(n)} - \langle y^{(n)}, v \rangle v \| }~.
     \mathbb{P}(\sigma) = \frac{1}{\mathcal{Z}} \displaystyle \prod_{i \in V} \phi_i(\sigma_i) \displaystyle \prod_{ij \in E} \psi_{ij}(\sigma_i, \sigma_j).

\label{bpeqs}
     b_{i \rightarrow j}(\sigma_i) = \frac{1}{Z_{i\rightarrow j}} \phi_i(\sigma_i) \displaystyle \prod_{k \in \mathcal{N}(i)\setminus \{j\}} \displaystyle \sum_{\sigma_k \in X}\psi_{ik}(\sigma_i, \sigma_k) b_{k \rightarrow i}(\sigma_k).

    b_i(\sigma_i) = \prod_{k \in \mathcal{N}(i)} b_{k \rightarrow i}(\sigma_i)~,
G \sim SBM(n=1000, p = k\bar{d} - q, q \sim \text{Unif}(0, \bar{d} - \sqrt{\bar{d}}), C=2)~,
where the average degree  is either fixed constant or also randomized with . 
Figure \ref{fig:BH2} shows the overlap obtained by our model compared with several baselines. Our GNN model is either competitive with or outperforming the spectral method using Bethe Hessian (BH), which is the state-of-the-art spectral method \cite{saade2014spectral}, despite not having any access to the underlying generative model (especially in cases where GNN was trained on a mixture of SBM and thus must be able to generalize the  parameter in BH). They all outperform by a wide margin spectral clustering methods using the symmetric Laplacian and power method applied to  using the same number of layers as our model. Thus GNN's ability to predict labels goes beyond approximating spectral decomposition via learning the optimal  for . The model architecture could allow it to learn a higher dimensional function of the optimal perturbation of the multiscale adjacency basis, as well as nonlinear power iterations, that amplify the informative signals in the spectrum. 


\begin{figure*}
     \centering
     \includegraphics[width=0.95\linewidth,height=2.4in]{GNN_mixture.png}
\caption{GNN mixture (Graph Neural Network trained on a mixture of SBM with average degree 3), GNN full mixture (GNN trained over different SNR regimes),  and . {\it left: }. We verify that  models cannot perform detection at both ends of the spectrum simultaneously.}
     \label{fig:BH2}
\end{figure*}

\subsection{Ablation studies of GNN and LGNN}
\label{ablations}
\begin{table}[h]


{\small 
\begin{tabular}{lllllllll}
 & & \#layers & \#features & J &  & \#parameters & Avg. & Std. Dev. \\
(a) & GNN & 30 & 8 & 2 &  & 8621 & 0.1792 & 0.0385 \\
(b) & GNN & 30 & 8 & 4 &  & 12557 & 0.1855 & 0.0438 \\
(c) & GNN & 30 & 8 & 11 &  & 26333 & 0.1794 & 0.0359 \\
(d) & GNN & 30 & 15 & 2 &  & 28760 & 0.1894 & 0.0388 \\
(e) & GNN & 30 & 12 & 4 &  & 27273 & 0.1765 & 0.0371 \\
(f) & LGNN & 30 & 8 & 2 &  & 25482 & 0.2073 & 0.0481 \\
(g) & LGNN-L & 30 & 8 & 2 &  & 25482 & 0.1822 & 0.0395 \\
(h) & LGNN & 30 & 8 & 2 &  & 21502 & 0.1981 & 0.0529 \\
(i) & LGNN & 30 & 8 & 2 &  & 21502 & 0.2212 & 0.0581 \\
(j) & LGNN & 30 & 8 & 2 &  & 17622 & 0.1954 & 0.0441 \\
(k) & LGNN & 30 & 8 & 1 &  & 21502 & 0.1673 & 0.0437 \\
(l) & LGNN-S & 30 & 8 & 2 &  & 21530 & 0.1776 & 0.0398
\end{tabular}
  }
  \caption{\footnotesize{The effects of different architectures and choices of the operator family for GNN and LGNN, as demonstrated by their performance on the 5-class disassortative SBM experiments with the exact setup as in Section \ref{SBMsec2}. For LGNN,  is the same as  except for changing  to .}}
  \label{ablations-table}
  \centering
\end{table}

Compared to , each of ,  and  has one fewer operator in , and  has two fewer. We see that with the absence of ,  has much worse performance than the other four, indicating the importance of the power graph adjacency matrices. Interestingly, with the absence of ,  actually has better average accuracy than . One possibly explanation is that in SBM, each node has the same expected degree, and hence  may be not very far from , which might make having both  and  in the family redundant to some extent. 

Comparing GNN models ,  and , we see it is not the case that having larger  will always lead to better performance. Compared to , GNN models ,  and  have similar numbers of parameters but all achieve worse average test accuracy, indicating that the line graph structure is essential for the good performance of LGNN in this experiment. In addition,  also performs worse than , indicating the significance of the non-backtracking line graph compared to the symmetric line graph. 

\end{document}
