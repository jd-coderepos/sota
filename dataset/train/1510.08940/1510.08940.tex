




\documentclass[final,10pt,a5paper]{phdimt}
\pdfoutput=1



\pdfinfo{ 
	/Title  (Combining Peer-to-Peer and Cloud Computing for Large Scale On-line Games)
	/Creator (TeXShop - Made on a Mac)
	/Producer (pdfTeX)
	/Author (Emanuele Carlini)
	/CreationDate (T:20120214193000)
	/ModDate (D:20120214193000)
	/Subject (Computer Science)
}
\pdfcatalog{
	/PageMode (/UseOutlines)
      /OpenAction (fitbh)
}




\title{Combining Peer-to-Peer and Cloud Computing for Large Scale On-line Games}
\author{Emanuele Carlini}
\mail{emanuele.carlini@imtlucca.it}
\program{Computer Science and Engineering}
\coordinator{Prof. Ugo Montanari}
\coordinatorinst{University of Pisa}
\cycle{XXIV}
\year{2012}



\supervisor{Prof. Laura Ricci}
\supervisorinst{University of Pisa}
\cosupervisor{Prof. Massimo Coppola}
\cosupervisorinst{Istituto di Scienza e Tecnologie della Informazione (ISTI), CNR, Pisa}
\cosupervisortwo{Prof. Alberto Montresor}
\cosupervisorinsttwo{University of Trento}

\tutor{Prof. Marzia Buscemi}
\tutorinst{IMT Institute for Advanced Studies Lucca}




\firstreviewer{Prof. Paolo Costa}
\firstreviewerinst{Imperial College London}
\secondreviewer{Prof. Alexey Vinel}
\secondreviewerinst{Tampere University of Technology}
\thirdreviewer{}
\thirdreviewerinst{}


\newcommand{\timeWait}{\Delta t}


\theoremstyle{definition}
\newtheorem{mydef}{Definition}


\begin{document}

\graphicspath{
{mainmatter/chapter-Related/}
{mainmatter/graphs/}
{mainmatter/./}
}

\def\vec#1{{\bf #1}}

\renewcommand\baselinestretch{1}
\baselineskip=14pt

\hyphenation{Ein-ste-in}
\hyphenation{a-ch-ie-ved}
\hyphenation{ap-pro-ach-es}
\hyphenation{mo-del}

\frontmatter

\pagestyle{empty} \maketitle
\makereviewerspage
\pagestyle{plain} 

\tableofcontents
\listoffigures
\listoftables
\clearpage{}

\begin{acknowledgements}
\addcontentsline{toc}{chapter}{Acknowledgements}

Let me be clear from the beginning. This thesis wouldn't have been possible without all the people I have met along the path. And the list is quite long. I would express my infinite gratitude to Prof. Laura Ricci and Dr. Massimo Coppola not only for their scientific guidance but also for continuous support and encouragement. A special thank goes to Prof. Alberto Montresor for all the accurate advices and the fruitful discussions. I would like to thank Prof. Alexey Vinel and Prof. Paolo Costa for their precise feedback and comments. Many thanks to all the people at IMT Lucca, especially to colleagues of the XXIV cycle, with whom I shared most of my time at IMT. I would like to thank Dr. Raffaele Perego, Ranieri Baraglia and all the other friends and colleagues at HPC lab at CNR-ISTI. It has been an immense privilege working with you guys. I wish to thank in particular Dr. Patrizio Dazzi, Stefania Lombardi and Matteo Mordacchini for their support and for an infinite number of fruitful discussions. A particular thank goes also to my friends Beniamino, Daniele, Luca and Iacopo. This thesis wouldn't have been possible without the continuous encouragement of my family, to whom I ex- tend my most deep thanks. Last, but definitely not least, I thank Anna for being on my side all the time and completing my life with her love.

\end{acknowledgements}
\clearpage{}
\clearpage{}



\begin{center}
\vspace*{0.5cm}
{\Large \bf  Vita}
\addcontentsline{toc}{chapter}{Vita and Publications}
\end{center}
\begin{table}[h!]
\begin{center}
\renewcommand{\arraystretch}{1.25}
\begin{tabular*}{1\textwidth}{l p{8.5cm}}


{\bf August 13, 1981} & Born, La Spezia, Italy \\
& \\
{\bf 2004} & Bachelor of Applied Science Degree \\  
& Final mark: 105/110\\
& University of Pisa, Italy \\
& \\
{\bf 2008} & Master Degree\\  
& Final mark: 108/110\\
& University of Pisa, Italy \\
& \\
{\bf 2009} & Graduate Fellow\\  
& Istituto di Scienza e Tecnologie dellInformazione (ISTI), National Research Council\\
& Pisa, Italy \\
& \\
{\bf 2009} & PhD Student in Computer Science and Engineering \\  
& IMT Institute for Advanced Studies Lucca \\
& Lucca, Italy\\



\end{tabular*}
\end{center}
\end{table}
\clearpage
\begin{center}
\vspace*{0.5cm}
{\Large \bf  Publications}
\end{center}
\vspace*{0.5cm}
{\small
\begin{enumerate}



\item Carlini, E., M. Coppola, P. Dazzi, D. Laforenza, S. Martinelli, and L. Ricci, ``Service and Resource Discovery Supports over P2P Overlays", in \emph{Proceedings of International Conference on Ultra Modern Telecommunications (ICUMT)}, IEEE, pp.1-8, 2009.

\item Carlini, E., M. Coppola, and D. Laforenza, ``XtreemOS, an Open-Source Grid Operating System Targeting the Future Internet", in \emph{III Conferenza Italiana sul Software Libero}, 2009.

\item Carlini, E., M. Coppola, D. Laforenza, and L. Ricci, ``Reducing Traffic in DHT-based Discovery Protocols for Dynamic Resources, in \emph{Grids, P2P and Services Computing}, Springer, pp.73-87, 2010.

\item Carlini, E., M. Coppola, and L. Ricci. ``Integration of P2P and Clouds to Support Massively Multiuser Virtual Environments", in \emph{Proceedings of the 9th Annual Workshop on Network and Systems Support for Games (NetGames)}, ACM/IEEE, pp.1-6, 2010.

\item Carlini, E., M. Coppola, P. Dazzi, L. Ricci, and G. Righetti, ``Cloud Federations in Contrail. in \emph{Euro-Par 2011: Parallel Processing Workshops}, Springer, pp.159-168, 2011.

\item  Carlini, E., M.Coppola, and L.Ricci,`` Evaluating compass routing based AOI-cast by MOGs mobility models", in \emph{Proceedings of the 4th International Conference on Simulation Tools and Techniques}, ICST, pp.328-335, 2011.

\item Carlini, E., M. Coppola, and L. Ricci, ``Probabilistic Dropping in Push and Pull Dissemination over Distributed Hash Tables", in \emph{Proceedings of the 11th International Conference on Computer and Information Technology (CIT)}, IEEE, pp.47-52, 2011.

\item Ricci, L., E. Carlini, L. Genovali, and M. Coppola, ``AOI-cast by Compass Routing in Delaunay Based DVE Overlays", in \emph{Proceedings of International Conference on High Performance Computing and Simulation (HPCS)}, IEEE, pp.135-142, 2011.

\item Ricci, L. and Carlini, ``Distributed Virtual Environments: From Client Server to P2P Architectures", in \emph{In High Performance Computing and Simulation (HPCS), 2012 International Conference on}, pages 817. IEEE, 2012.

\item Carlini, E., L. Ricci, and M.Coppola. ``Flexible load distribution for hybrid distributed virtual environments", in \emph{Future Generation Computer Systems}, Elsevier, \url{http://dx.doi.org/10.1016/j.bbr.2011.03.031}, 2012.

\item Ricci, L., L. Genovali, E. Carlini, and M. Coppola. ``AOI-CastinDistributed Virtual Environments: an Approach Based on Delay Tolerant Reverse Compass Routing, in \emph{Concurrency and Computation: Practice and Experience}, to appear.


\item E. Carlini, L. Ricci, and M. Coppola. ``Reducing Server Load in MMOG via P2P Gossip, \emph{Proceedings of the ACM Workshop on Network and System Support for Games (NetGames 2012)}, Venice, Italy, to appear.


\end{enumerate}
}
%
\clearpage{}
\clearpage{}

\begin{abstract} 


This thesis investigates the combination of Peer-to-Peer (P2P) and Cloud Computing to support Massively Multiplayer On-line Games (MMOGs). MMOGs are large-scale distributed applications where a large number of users concurrently share a real-time virtual environment. Commercial MMOG infrastructures are sized to support peak loads, incurring in high economical cost. Cloud Computing represents an attractive solution, as it lifts MMOG operators from the burden of buying and maintaining hardware, while offering the illusion of infinite machines. However, it requires balancing the tradeoff between resource provisioning and operational costs. P2P- based solutions present several advantages, including the inherent scalability, self-repairing, and natural load distribution capabilities. They require additional mechanisms to suit the requirements of a MMOG, such as backup solutions to cope with peer unreliability and heterogeneity. We propose mechanisms that integrate P2P and Cloud Computing combining their advantages. Our techniques allow operators to select the ideal tradeoff between performance and economical costs. Using realistic workloads, we show that hybrid infrastructures can reduce the economical effort of the operator, while offering a level of service comparable with centralized architectures.

\end{abstract}
\clearpage{}

\mainmatter

\clearpage{}
\chapter{Introduction}



On-line gaming entertainment has acquired lots of popularity in the last years from both industry and research communities.
This attention is justified by the economic growth of the field, where Massively Multiplayer Online Games (MMOGs, \cite{wow-site,sl-site}) represent a remarkable member.
The market size of MMOG has received a 5 billion \ababS_1S_2S_3C_1S_1S_2S_3C_1C_1C_1S_1S_2S_3C_1mm-1m2^{160}O(logN)NddPCPCPPCPPCPCPPCABABACAAACAACACABBAAAACBA\log NAVBAVBVABBVVVBVBAVVAABy(x) = Kx^{-\alpha}K=0.5\alpha =1.4\log NVS\forall v \in VSv_{load}(t)vt-1tv_{load}(0) = 0\forall v \in VSv_{obj}(t)vtv_{obj}(0) = 0VSN(t)tn \in Nn_{cap}n_{bcost}n_{rcost}n_{fprob}\Delta{t}\gamma(t)t\gamma_{R}\gamma_{MAX}nV_nnnnlf_n(t) >= 1t\beta(t)x_{n,v}1v \in V_n0u_n1|V_n| \geq 10u_n\Delta_trisk_{limit}\Delta t\tau_{epoch}\tau_{epoch}\Delta t \approx \tau_{epoch}v(v,L_v)L_vL_vv\xi_{est}L_vL_vvs\_poolL_vvv \in\leftarrow| \Lv - \Load | \geq \xi_{est}L_v \leftarrow\leftarrowvL_v\neq\Delta t\timeWaitv,L_vL_vvL_v\leftarrow<v, \Lv>(v, \Lv) \in\xi_{est}\timeWaitLF_{up}LF_{bot}L_vvs_{pool}node_{pool}node^2_{pool}P_{size}\in > \leftarrow\leftarrow\cup<\in<\leftarrow<\leftarrowLF_{up}vs_{pool}vs_{pool}vs_{pool}P_{size}LF_{bot}vs_{pool}P_{size}vs_{pool}LF_{up}LF_{bot}L_vvs_{pool}node_{pool}node^2_{pool}risk\_{limit}v \in\leftarrow\in\oplus<\emptyset\leftarrow\leftarrow\in\oplus<\emptyset\leftarrow\leftarrow\leftarrowvvs_{pool}vvs_{pool}vLF_{up}\oplusvvrisk_{limit}O(n)O(n^3)nt\Delta teeetEM_{len}e_{AOI}(t)ettP_{max}\lambdap_{hot}1 - p_{hot}H_{num}p_{hot}p_{den}1 - p_{den}p_{dens}tO_{num}p_{obj}M_{len}\lambdaP_{max}O_{num}P_{obj}H_{num}p_{den}p_{hot}\Delta tP_{max}risk_{limit}0.1\epsilon_{est}\epsilon_{est}0.050.051005000risk_{limit}0.10.9risk_{limit}100100\epsilon_{est}=0.05risk_{limit} = 0.50.90.1risk_{limit}=0.1100risk_{limit}100\epsilon_{est}=0.05risk_{limit} = 0.9risk_{limit} = 0.1\epsilon_{est}=0.051002000risk_{limit} = 0.9\epsilon_{est}=0.05\epsilon_{est}\epsilon_{est}\epsilon_{est}\epsilon_{est}\epsilon_{est}100\epsilon_{est}0.050.51.0100\epsilon_{est} = 1.0\epsilon_{est} = 0.5LF_{up} = 0.8\epsilon_{est}\epsilon_{est} = 1.0\epsilon_{est} = 1.0100T_snmnmT_sT_ST_sT_s = 0.25 per GB, Amazon EC2 prices, July 2012}, the deployment would cost 30\T_s = 1 per day.
This simple experiment shows how even a little reduction on the  can result in a relevant saving for the virtual environment operator.


\section{PAM Overlay}

The construction of the PAM overlay has been driven by protocols based on epidemic diffusion of information.
These protocols (also known as as \textit{gossip} protocols) are the current reference point to build overlays in a pure distributed fashion. Gossip-based protocols provide seamless techniques for the initial bootstrap of the overlay and recovery node failures, as well as other interesting properties.

Our proposed overlay has been build with a mechanism inspired by T-Man \cite{Jelasity2008}.
T-Man has been one of the first approaches to fully describe the potential of gossip-based protocols in building overlays. 
Here we describe what are the main principles behind the creation of an overlay with gossip protocols, using T-Man as the main reference.

T-Man proposes a gossip-based probabilistic approach whose goal is to build, starting from an arbitrary initial peer configuration, a target overlay characterized by a set of well defined properties. 
These may be inferred by the profiles of the peers or directly characterize the topology of the target overlay. 
In the former case, for instance, a metrics based on the geographical location or on the semantic profile of the peer may be considered to define a  proximity-aware target overlay. An example of the latter scenario is a topology where the nodes are organized in a ring in increasing order with respect to their identifier. 

The definition of a proper {\em ranking function} is a core element to build the target overlay.
Each peer maintains a local view storing the descriptors of its neighbours. At each gossip cycle each peer exchanges a subset of its view with a subset of its neighbours. The ranking function is exploited to select the "best neighbours" according to the properties of the target topology. Hence, using only local gossip messages, the current topology gradually evolves towards the desired target structure with the help of the ranking function.

In large diameter topologies, an underlying random peer
sampling protocol should be exploited in order to speed up the convergence  toward the target topology. The random peer sampling 
serves also in the initial gossip cycles, when the local view of
the peer is empty and a peer needs to know a random sample of
peers to bootstrap on the network. 
Finally, a gossip-based approach for overlay construction is light-weighted, scalable and, when paired with a peer sampling service, it exhibits good convergence speed.


\subsection{Gossip-based Overlay Construction}

The effectiveness of our approach depends on the definition of a proper ranking function. In our case,
it should favour neighbours which may offer a larger number of entities in the interest set of a peer. To this end,
we will consider the spatial coverage of the AOIs of a peer's neighbours.
Unlike most existing T-Man-like approaches, our goal is to build a continuing evolving overlay rather than predefined one. The view of a peer changes continuously in order to reflect the position updates of the peers in the virtual space. In our case, instead of evolving toward a predefined target topology, peer continuously gossip to each other to support the retrieval of new avatars and objects in their AOI.


Our technique to build an overlay supporting IM is based on the following reasoning. 
Let us consider a given peer .
At an arbitrary point in time it has in its local representation of the environment the replicas of the entities that belong to its AOI. 
When  moves, its AOI changes accordingly.
Hence, to maintain its local representation up-to-date,  must discover the new entities belonging to the new AOI.
In order to dynamically acquire this information,  builds an overlay by considering a set relevant neighbours. 

The creation of the overlay poses two issues.
First,  needs to know the identifier of its candidate neighbours; 
second,  needs a mechanism to discriminate among peers, in order to choose the more
promising neighbours from the set of candidates.

The first issue is resolved by continuously refreshing candidate knowledge.
This is obtained with a two-layer gossiping architecture, where each layer runs a gossip protocol (the structure of these layers is shown in Figure \ref{fig:pam-overlay}).
In the underlying layer, called \textit{random peer sampling}, each client runs a random peer sampling protocol, which provide a subset of all the nodes in the system.
This layer enables each peer to maintain a set of long range links that guarantees the connectivity of the overlay.
In the second layer, called \textit{coverage peer sampling}, a gossip protocol connects peers by exploiting a ranking function based on spatial AOI coverage. 
Since the selection of the neighbours is done according the proximity, entities are progressively discarded by the second layer gossip if they disappear from its AOI. 
The two gossip layers are independent, in the sense that layers execute their gossip cycle at their own rate.
The random peer sampling layer communicates newly entered peers to the proximity layer. 
These communications are exploited in situation where a client has few knowledge about its nearby candidate
neighbours and must incrementally acquire new information.
These situations include the bootstrap phase and avatars teleportation, i.e. an avatar "jumping" from one place to another of the virtual environment.


The second issue is related to the AOI coverage offered by the neighbours of a peer. 
Each peer should choose the best configuration of its neighbours in order to optimize the number of entities which may be retrieved from them.
At each iteration the peer adapts its overlay neighbours set by providing a partial order from multiple configurations of neighbour sets. 
Since avatars are continuously moving, a large part of the
IM performances depends on the freshness of peers knowledge. In order to maintain the selection of the neighbours as
fresh as possible, each entry in the view of the peers is marked
with a time-stamp. Time-stamps provide an estimation on the
freshness of the entry. Our mechanism considers the age of the
entries in two situations. First, before to
rank the neighbour candidates, all the candidates whose age is
greater than a certain threshold are not considered. Second,
during the ranking, fresh configurations are favoured with
respects to the stale ones. In principle, the internal clock of the
peers can be used as the source for the time stamp. However,
for simulation purposes, we model the time as a discrete
successions of iterations. The simulation starts at iteration zero
for all the nodes, and for each gossip-cycle the count is
increased by one. When an entry is created, the iteration count
is used as time-stamp for such entry.


\subsection{Ranking Function}

In this section we explore in details the principles behind the ranking functions.
The definition of our ranking function posed two distinct challenges: (i) to measure the amount of area covered by neighbours peers and (ii) to determine the best subset of neighbour peers that maximize the area coverage. In the rest of this section we formalize these two problems and we provide a description of the adopted solutions.

\paragraph{Measuring Coverage}

\begin{mydef}[AOI coverage]
\emph{
Given a set of AOIs  and an AOI  such that  we define as the coverage of P given , , as the area of  that is overlapped by the AOIs contained in .}
\end{mydef}


Computing  requires to compute all the unique intersections of AOIs in  with 's AOI and to evaluate their area.
In trivial situations this is easy to compute. For example, Figure \ref{fig:simple} depicts a simple scenario where .
In this case the coverage is just the sum of the intersections of A and B with P, i.e. . 
However, in real situations, computing the AOI coverage is far from a trivial problem.
For instance, in the case depicted by Figure \ref{fig:app-cont} we have that .


\begin{figure}[tbh]
\centering
\includegraphics[width=0.45\textwidth]{images/intersection.pdf}
\caption{Simple continuous  with .}
\label{fig:simple}
\end{figure}


When many peers are close to each other, to compute the effective coverage may be prohibitively expensive in terms of computational effort. Practically, this happens for two reasons. First, the number of the intersections grows quadratically with the number of peers. Second, it might be computationally costly to evaluate the area of an intersection resulting from many AOIs. 
For this reasons, we approach this issue considering an approximation.
The idea is to approximate the continuous surface of the AOI as a grid of disjoint tiles. In this way, instead of dealing with custom-shaped areas, we consider the tiles as the units to compute the coverage. This approximation reduces the complexity of the problem, since it makes easy to compute the area of each tile.
Moreover, the amount of tiles is a parametric value and does not depends on the number of peers.
Figure \ref{fig:app-cont} shows an example on how to compute the coverage of a given AOI (P in the figure) considering a 3x3 approximation.
The number of tiles varies proportionally with the degree of the approximation. A high number of tiles leads to higher precision, in principle increasing the performance of our mechanism. Besides, since the AOI to approximate is a circle, tiles at the corners of the approximation square might be out of the actual AOI area. In this case we do not consider such tiles for the coverage area estimation.


The pseudo code of the function  that realizes the tile-based coverage approximation is presented in Algorithm \ref{alg:approximate-coverage}. For each AOI  and for each tile, we check whether the AOI intersects with the tile. If it is, we check the counter associated to the tile. If the tile counter is zero, it means the tile is overlapped for the first time so we increase the \textit{covered\_tiles} counter. If the tile counter is greater than zero, we just increment it. Besides the number of the tiles covered, this function also counts the number of AOIs that cover each tile. It is easy to show that the complexity of the function is , where  is the cardinality of  and  is the number of tiles.



\begin{figure}[tb]
\centering
\includegraphics[width=0.9\textwidth]{images/int3.pdf}
\caption{Continuous and approximate coverage with . In this case the AOI coverage is approximated to }\label{fig:app-cont}
\end{figure}

\begin{algorithm}[h]
\SetKwInOut{Input}{Input}
\SetKw{Return}{return}
\SetKwInOut{Output}{Output}

\Input{P, the considered peer}
\Input{, the set of neighbours AOIs}
\Output{the approximated coverage given  and }

\BlankLine

\KwData{covered\_tiles  0}
\ForEach{AOI  }
{
  \ForEach{tile  getTiles(P)}
  {
    \If {intersect(AOI, tile)}
    {
      \If {tile.count = 0}
      {
      covered\_tiles  covered\_tiles + 1;
      }
      tile.count  tile.count + 1;
    }
  }
}
\Return covered\_tiles\;

\caption{Coverage(P, )}\label{alg:approximate-coverage}
\end{algorithm}


\paragraph{Maximizing AOI Coverage}

The aim of the network is to discover the larger amount of objects in the AOI of the peer (possibly all of them). The straightforward solution is to to keep links with the neighbours that maximizes the coverage. This indeed requires peers to make a choice, due to the bound imposed by the gossip view size. Hence, very often a peer needs to choose what is the best subset of peers to keep in its view. This subset is defined as follows:

\begin{mydef}[Maximum AOI coverage]
\emph{
Given a set  of AOIs,  and a natural number  and an AOI , we define , find the set  that maximizes the coverage of .}
\end{mydef}


This problem is NP-complete. To prove that, we show how it corresponds to an instance of the \textit{set cover} problem. 
The set cover problem has been proved to be NP-complete by Karp in 1972 \cite{karp1972reducibility} and it is defined as follows.


\begin{mydef} 
[Set cover problem]  
\emph{Given a set  of elements (called the universe) and  sets of elements whose union comprises the universe, identify the smallest number of sets whose union contains all elements in .}
\end{mydef}

The correspondence with the Maximum AOI coverage problem is resolved by considering: (i)  as , (ii) elements as the tiles, and (iii)  as the tiles covered by the AOIs in the optimal solution.


A naive solution to this problem would be to enumerate the possible combinations of peers and for each of them compute the coverage.
Unfortunately, this is highly impracticable since the combinatorial nature of the problem. 
Hence we propose two heuristics algorithms with different characteristics, a score-based and a greedy one.




\paragraph{Score-based Heuristics}
The rationale behind this heuristics algorithm is to assign a score to each tile. The tiles that intersect with few peers will receive a higher score than tiles intersected by a larger amount of peers. The idea is then to favour such peers that overlap high score tiles. The heuristics works as in the pseudo code in Algorithm \ref{alg:score-heuristic}. 

First, it computes the coverage of the AOI by considering all the peers in . 
Each tile has a score that is the reciprocal of the number of intersected AOIs.
Second, it computes the score for each AOI as the sum of the scores of each intersected tiles.
Finally, it sorts the AOIs in descending order according to their score, and it chooses the first  entries.



\begin{algorithm}[tbh]
\SetKwInOut{Input}{Input}
\SetKw{Return}{return}
\SetKwInOut{Output}{Output}

\Input{P, the considered peer}
\Input{, the set of neighbours AOIs}
\Input{d, the size of the returned set}
\Output{a subset of  with cardinality }
\BlankLine


coverage(P, )\;

\ForEach{AOI  }
{
  \ForEach{tile  getTiles(P)}
  {
    \If {intersect(AOI, tile)}
    {
      AOI.score  AOI.score + \;   
    }
  }
}

sort AOIs in descending order according to score\;
\Return the first  AOIs\;

\caption{Score-based Heuristics}\label{alg:score-heuristic}
\end{algorithm}


The complexity analysis of the score-based algorithm heuristics goes as following: 
(i) the coverage procedure, which we have already seen to be , 
(ii) the computation of the score, that can be considered as , 
and (iii) the sorting, which is . 



Figure \ref{graph:score} shows a graphical execution of the score-based heuristic algorithm. 
For example, the central tile has a score of 0.3 since A and B and C intersect with it. If we consider , the heuristics chooses the combination , which is also the best combination possible. However, the heuristics not always finds the optimum. Let us consider the example in Figure \ref{fig:gheur}. In this case the score-based heuristic algorithm chooses as the best combination  that covers 4 tiles instead of  or  that cover 5 tiles each.

\begin{figure}
\centering
\includegraphics[width=0.7\textwidth]{images/tile-score.pdf}
\caption{Graphical examples of the score-based heuristic}\label{graph:score}
\end{figure}



\paragraph{Greedy Heuristics}
The idea behind the greedy heuristics is simple: at each step to choose the peer that yields the higher increment on the number of unique tiles covered. The pseudo-code of the greedy heuristic algorithm is represented at Algorithm \ref{alg:greedy-heuristic}.
For each peer in the view, it is selected the AOI that maximizes the number of further covered tiles considering the already chosen AOIs. Note that: (i) an AOI can be selected only once as, upon selection, it is removed from the list of candidates, and (ii) to evaluate the number of tiles covered we use the function  described and evaluated in the previous section. 

\begin{algorithm}[tbh]
\SetKwInOut{Input}{Input}
\SetKwInOut{Output}{Output}
\SetKw{Return}{return}

\Input{P, the considered peer}
\Input{, the set of neighbour peers}
\Input{d, the size of the returned set}
\Output{a subset of  with cardinality }

\KwData{C }
\BlankLine

\While{} 
{\label{greedy:outer}
  chosen \;
  max\_score  0\;
  \ForEach{AOI  }  
  {\label{greedy:inner}
    score  coverage(P, C  AOI)\;
    \If{score  max\_score}
    {
       max\_score  score\;
       chosen  AOI\;
    }
  }
  remove chosen from \;
  add chosen to C\;
}
\Return C\;
\caption{Greedy Heuristics}\label{alg:greedy-heuristic}
\end{algorithm} 


The complexity analysis of the greedy heuristic algorithm goes as following.
The outer cycle (line \ref{greedy:outer}) is repeated  times. 
The inner cycle (line \ref{greedy:inner}) is repeated at maximum  times. 
The function  has a complexity of .
Hence, the total complexity in time is .

Figure \ref{fig:gheur} shows a graphical execution of the greedy heuristic algorithm. At the first step, the heuristics chooses , as it is the AOI that covers the most tiles. At the second step,  is chosen so that the current combination becomes . At the third step  is chosen, and the final combination is . Note that at the second step, the heuristics could have chosen .
In such case the second combination was  that would have lead to the same results (i.e ).

\begin{figure}[tbh]
\centering
\includegraphics[width=0.7\textwidth]{images/tile-greedy.pdf}
\caption{Greedy and Score Heuristic with }\label{fig:gheur}
\end{figure}


To prove approximation guarantees of the greedy heuristics, first we have to introduce \textit{submodular} function \cite{nemhauser1978analysis}. 
Consider  to be a finite set and an arbitrary function , we can say  is submodular if it satisfies the following property: the marginal gain of adding an element to a set  is at least as high as the marginal gain from adding the same element to a superset of . 
More formally a submodular function must satisfy 



for all elements  and for all pairs .
Now, suppose  to be submodular, \textit{non-negative} (i.e. takes only positive values) and \textit{monotone} (i.e. adding an element to a set cannot cause  to decrease). Let also suppose that our aim is to find a set  of cardinality  such that  is maximized. It has been proved in \cite{nemhauser1978analysis} that a greedy algorithm resolves this problem with a worst-case approximation of , where  is the base of the natural logarithm. In other words, if the optimum value is 100, the greedy algorithm is guaranteed to find a solution with a value of \textit{at least} 63.

In order to apply this result to our greedy algorithm,  must be submodular, non-negative and monotone. Non-negativity is immediate, since we measure an (approximation of). Monotonicity is also immediate, since adding an AOI to a set cannot change the number of tiles already counted. 
To prove submodularity, we show how it satisfies (\ref{eq1}). Let us consider what happens when we add an arbitrary AOI  to a set  whose  is a superset of: (i)  neither intersects with AOIs in  or AOIs in . In this case the equality holds since the marginal gain for both sides of the equation is zero; (ii)  intersects only with AOI's in . In this case we possibly have an increment on the left side, so the equality holds; (iii)  intersects only with AOI's in . In this case the left part of the equation is greater, since it considers all the area covered by , whereas the right part is incremented only of the part that is non overlapping, so the equation holds; (iv)  intersects with both  and . The equation holds since for the left side it counts also the intersection of the AOI's with the elements in , that it would not count for the right side.
Finally, since we have proved that our greedy algorithm is submodular, non-negative and monotone we can assert that in the worst case we obtain an approximation of .



\section{Result}


This section presents the description of the metrics and a selection of experimental results evaluating the key performances of the approach.



\subsection{Metrics}

To evaluate our approach we considered two different metrics. 
The first metric evaluates the coverage of peers AOI. We refer to this metric as \textit{AC}. \textit{AC} is a value in the interval  and, given a peer at an arbitrary iteration, is defined as  the ratio between the AOI coverage obtained by the P's view and the best AOI coverage defined by considering all the peers in the virtual environment. 
The second metrics measures the difference between the local replica of the peer' state against the server state.
To measure this difference, we exploit a slightly modified version of the \textit{Jaccard similarity coefficient} \cite{lee1999measures}.
Let us consider  as the local replica of a peer and  as the remote replica of the server.
The original Jaccard coefficient is computed as .
However, this formulation either does not take in account the difference of the positions of the entities, or considers entities with different positions as distinct.
In order to take into account at the same time the difference in position and the presence of the entities we exploit the following formula to compute the Jaccard coefficient (in short \textit{JC}):



\noindent
where  is the diameter of the peer's AOI.
A peer with  has its local replica perfectly synchronized with the state of the server while
 implies that the replica is completely out-of-sync with that of the server. Any value in between 0 and 1 gives a quantitative evaluation on the quality of the synchronization.

While AC measures how good the heuristics performs in a dynamic environment, JC measures the quality of the approach in terms of the quality of the application. A direct correlation between AC and JC would be desirable. 
The experimental results supports the existence of this correlation.



\subsection{Behaviour over }

\begin{figure}[tbh]
\centering
\includegraphics[width=0.8\textwidth]{heuristic}
\caption{Comparison between score-based heuristics and greedy-based heuristics}
\label{graph:heur}
\end{figure}


In this section we discuss the result of several simulation runs by varying the interval of time () between two consecutive communications to the central server. A gossip cycle and a query to the overlay are executed every 0.25 seconds. For instance, with  there is a server communication followed by three requests to overlay in row and then another server communication. 
Where it is not indicated differently, the simulations consider: 500 nodes with a cache of 10 elements each, 1000 objects, and an AOI approximation of 32x32 tiles. 
Figure \ref{graph:heur} shows the comparison of the JC between the greedy heuristic and the score heuristic algorithms.
In general, we can observe how the reduction in the JC is limited even with high values of .
For instance, with  the average JC value for both the heuristic algorithms is around 0.9.
From an application point of view, this means that the mechanism is able to fully support IM.
As expected, further increments of  imply a JC reduction. Note however, that even with the  and the support of the PAM-overlay, the JC is still around 0.8.
The effectiveness of the mechanism is further supported by the values of the JC when using only the server.
In other words, increasing  would be problematic if not supported by the PAM-overlay. For example, with , the JC with the support of the overlay is around 0.9, whereas is 0.65 using only the server.

As regards the comparison between heuristic algorithms, the greedy slightly outperforms the score heuristics.
With these simulation parameters, the AC, which is independent from , is 0.8 and 0.85 respectively for the greedy and the score heuristics. This suggests a correlation between AC and the JC.


Figure \ref{graph:ts} shows the JC when selecting the more fresh entries during a gossip iteration. The ranking algorithm considered is the score, but similar results have been obtained with the the greedy heuristics. The results are evident and not surprising: to prefer fresh entries gives a neat increment on the performance. 
As the previous, even this result indicates a  correlation between AC and JC as the score's  with stale control and  without.

\begin{figure}[tbh]
\centering
\includegraphics[width=0.8\textwidth]{stale}
\caption{Score heuristics, comparison between considering or not freshness of entries}
\label{graph:ts}
\end{figure}





\begin{figure}[tbh]
\centering
\includegraphics[width=0.8\textwidth]{multi}
\caption{AC and JC with different number of tiles}
\label{graph:tiles}
\end{figure}


\subsection{Tiles Variation}

Figure \ref{graph:tiles} shows the JC and the AC of the greedy and score heuristics with various degree of AOI approximation (from 16 to 1024 tiles). The data in the plot have been obtained by averaging the outcome of 20 independent simulation runs with a .
The results show that the score-based heuristics is basically agnostic to the approximation whereas the increment in the number of tiles implies an increment of the performance of the greedy-based heuristics. From the graph it is clear how with approximations larger than 400 tiles for AC and 600 for JC, the greedy-based heuristics outperforms the score-based.
The reason why it happens lies on the order used by the greedy heuristics for choosing the areas. Indeed, with higher approximation, the greedy has greater chance to choose a worse area. When the approximation is reduced, the greedy heuristics performance increases.


\begin{figure}[tbh]
\centering
\includegraphics[width=0.8\textwidth]{nodes}
\caption{JC with different values for network sizes}
\label{graph:scal}
\end{figure}


The reason of this can be explained clearly with a simple example, depicted in Figure \ref{fig:approx}.
Let us consider the same case with two different AOI approximation degrees, and also consider the maximize coverage problem with
 and . In the first case (4 tiles) the greedy heuristic would choose either ,  or . This is because at the first greedy step, either  or  would be selected, even if  has a better coverage then .
In the case with a better approximation (16 tiles), the greedy-heuristic would choose , which leads to  or  that are both optimal solutions. When the approximation is further reduced, then the greedy-based heuristic works better than the score-base one, due to the better performance with respect to the optimum.


\begin{figure}[tbh]
\centering
\includegraphics[width=0.8\textwidth]{images/approx.pdf}
\caption{Impact on the heuristics with different tiles approximation}\label{fig:approx}
\end{figure}



\subsection{Number of Peers}

Figure \ref{graph:scal} shows how the amount of peers affects the JC of greedy and score heuristics.
Each point in the plot is the average of the outcome of 20 independent runs. The simulations have been run with a 32x32 AOI approximation, a fixed cache size of 10 elements, and a .

As expected, the greedy overcomes the score, but they show a similar behaviour. 
Their performance are essentially independent from the number of nodes, even with a fixed-size cache.
In fact, there is a slight increment on the JC as the number of peers increases, due to the higher changes of crowded zones with more nodes.
This situation allows the node to exploit the knowledge of the neighbours more often.




\section{Conclusion}

In this chapter we described a gossip-based mechanism to build overlay for best-effort Neighbours Discovery in MMOGs.
Conversely to the other approach in the field, we trade some precision in the result to keep the mechanism fast, simple and lightweight.
The simulations have shown encouraging results: even when the delay between two consecutive communications with the server is very large the PAM overlay is able to obtain good results. Further, an increasing in the number of nodes increases the performance of the overlay.


Our proposal can be further extended and studied.
To this end, we plan to improve the precision of the result by considering additional information when ranking peers, such as movement forecasts and different neighbours selection functions. As to further validate our solution, we intend to test it with movement traces from different mobility models and to compare it with the non best-effort work presents in literature.
Part of these lines have been further studied, and they are explained in
Chapter \ref{chap:architecture}.
In any case, we expect that other solutions will be proposed following this line.
Indeed, techniques and mechanisms to combine Peer-to-Peer approaches (including best-effort ones) and centralized solutions (like on-demand computing) are one of the research topics for the next-generation MMOG infrastructures.


\clearpage{}
\clearpage{}

\chapter{Toward a Complete Architecture}
\label{chap:architecture} 

MMOG architectures must support a number of features whose requirements are often in contrast with each other.
A single MMOG can be accessed by multiple user concurrently, therefore the architecture must account for maintaining consistency.
To scale up to thousands of users, interest management and load balancing schemas are a necessity. Since the nodes of the network can potentially be untrustworthy and unreliable, security and fault tolerance mechanisms must be considered.
As we have described in detail these aspects in Chapter \ref{chap:background}, here we focus on the design of a full, concrete architecture for MMOGs.


The State Action Manager (SAM) and the Positional Action Manager (PAM) were presented through this work as two stand-alone components. The SAM (see Chapter \ref{chap:sam}) manages the state actions, by exploiting a Distributed Hash Table to distribute the effort on management of the entities to multiple resources, including user-provided and on-demand resources. The PAM (see Chapter \ref{chap:pam}) is the component devoted to the management of the positional actions. It employs a combination of a centralized server and gossip protocols to acquire the position of relevant entities in the proximity of the users.

This chapter presents a preliminary study on the combination of SAM and PAM in a concrete architecture.
This combination is described more in detail in the next section, where we consider a client-centric perspective.
A seamless integration of PAM and SAM also requires that they share the same mechanisms to recruit and release on-demand computing resources. 
The PAM-server presented in Chapter \ref{chap:pam} is described as a single server architecture.
Section \ref{sec:multiserver} presents a multi-server version of the PAM, with an insight of possible mechanisms for load distribution in PAM.





\section{Combining PAM and SAM}




The combination of PAM and SAM in a seamless architecture exposes two main issues.
First, it is mandatory the definition of a client capable of correctly exploiting SAM and PAM, in order to be able to participate to a virtual environment. Second, a common infrastructural platform that comprehend SAM and PAM must be defined. For example, the same instance of an on-demand resource may run the SAM or the PAM component in different moments. 
Before entering in the details of the this second issue, we provide the description of the PAM that includes the multi server support.


\subsection{Client's Perspective}

From a client perspective, PAM and SAM should be used together to provide a MMOG.
In this section we describe the interaction that a client has with the two components to reach this goal.
The interactions are presented as messages, which are depicted in Figure \ref{fig:interest-management}.


\begin{figure}[tbh]
\centering
\includegraphics[width=0.7\textwidth]{images/interest-management2}
\caption{Client-centric view of the proposed architecture}\label{fig:interest-management}
\end{figure}


\paragraph{Positional actions}
Clients periodically send its current position to the PAM server. The frequency rate of the positional action depends on the particular virtual environment. It is expectable that fast-paced MMOGs have an higher frequency with respect to slow-paced MMOGs. In any case, the PAM-server can employ an \textit{optimistic} approach to compute the position of the avatar between two positional actions. This kind of approaches, of which the most popular is Dead Reckoning \cite{pantel2002suitability}, are explained in Chapter \ref{chap:background}. 


\paragraph{Positions updates}
The client receives from the PAM the positions of the entities in its AOI.
This information can be provided either by the PAM-server or by the PAM-overlay, as described in Chapter \ref{chap:pam}.
The frequency whereby the PAM server sends position updates to the clients is defined by the game operator.
Either way, the client considers a larger sized AOI with respect to the one actually visualized by the players.
This allows the client to perform a sort of pre-fetching for possible interesting entities for the player.
With this optimization, the client can visualize it immediately to the player, as soon as the entity enters in the player's real AOI.
However, the size of the pre-fetching AOI must be correctly chosen.
It must be defined a trade-off between the increment in performances and the overhead due to the maintaining of a larger AOI.


\paragraph{Subscription}
In order to receive state updates from the SAM, clients must subscribe to the entities contained in their AOI.
From a client's perspective, the subscription process consists of: (i) providing the client's IP to the servers that manages the entities, so it can receive state updates and (ii) store the IP of the server, to send possible modifications of the state of the entity.
To explain the subscription process, let us proceed with an example.
Let us assume that a generic client needs to subscribe for the entity .
To do so, the client can contact an arbitrary node in SAM.
This is possible since internally the SAM is organized like a Distributed Hash Table (see Chapter \ref{chap:sam}). 
In a DHT overlay, each node of the DHT is able to find the node that manages any entity in  steps, where  is the number of nodes. However, even few hops may result in a high latency delay.
Fortunately, the client already considers a larger pre-fetching AOI, which can also be used to mask (part of) this latency.
Another issue is the definition of the node to contact for subscribing.
It could be either a specific node, or a server currently serving the client.
Further, it can stay the same or change over time. All these matters must be verified with additional simulations.
When an entity leaves the (pre-fetching) AOI of a player, the client must unsubscribe from the server.
Compared with the subscription, this action is rather simple. The client sends the proper message to server, of which it knows the IP already, and the server removes the client from the list of the subscribers.

\paragraph{State modification}
The client sends \textit{state actions} (Chapter \ref{chap:background}) to the PAM-server. Upon the reception of the state actions, the SAM server resolve possible conflicts and computes the authoritative version of the state of the entities. 

\paragraph{State updates}
Periodically, the SAM server sends state updates to the clients. Note that the updates are sent for the entities in the larger pre-fetching AOI, so to have them available as soon as they are needed. Upon reception of this message, the client updates the internal state of the local entities.\\






The combination of PAM and SAM implies the entities descriptor (as defined in Chapter \ref{chap:background}) to be split between the two components. Figure \ref{fig:sam-pam-desc} graphically compares the two descriptors. In particular, the PAM descriptor considers the position of the entity, whereas the SAM descriptor stores the list of the attributes.


\begin{figure}[tbh]
        \centering
        \begin{subfigure}[b]{0.45\textwidth}
                \centering
                \includegraphics[width=\textwidth]{images/pam-descriptor}
                \caption{PAM descriptor}
                \label{fig:pam-descriptor}
        \end{subfigure}\quad
        \begin{subfigure}[b]{0.45\textwidth}
                \centering
                \includegraphics[width=\textwidth]{images/sam-descriptor}
                \caption{SAM descriptor}
                \label{fig:sam-descriptor}
        \end{subfigure}
        \caption{The entity descriptor is split between PAM and SAM}\label{fig:sam-pam-desc}
\end{figure}



Another important step in the combination of PAM and SAM is to employ a common provisioner for the on-demand resources.
The idea is to extend the SAM's manager with the capability to provision also for the PAM.
The definition of a cost model for the PAM is a fundamental requisite for this task.
This model must represent and, if possible predict, the amount of bandwidth necessary to satisfy the players requests.
Also, by employing a prediction mechanism similar to the one in SAM, it would be possible to pro-actively provision on-demand resources.




\section{Multi-Server PAM}
\label{sec:multiserver}

In Chapter \ref{chap:pam} we described PAM by considering an infrastructure composed by a single server.
However, even if PAM's scalability is increased by the gossip network, a single server may be a bottleneck when the number of players overtakes certain limit. Here we propose the design of a multi-server architecture for PAM.
The management of the MMOG among multiple server requires a strategy to distribute the virtual environment.
Since PAM manages only the positional actions, it makes sense to employ a spatial distribution of the area. 


We enable this distribution by employing the CAN DHT \cite{ratnasamy2001scalable}.
CAN considers a bi-dimensional address space, which is divided into squared areas, called regions.
Each regions is associated to a node. Every data is represented by a 2-dimensional point.
Each node handles all the data whose point lies in the managed region.
CAN handles the joining and the leaving of a node by recursively merging (when joining) or splitting (when leaving) the regions.
In our context, we exploit CAN by creating a correspondence between the CAN and the virtual environment regions.
Any entity of the MMOG is managed according to its virtual position, as it was data in the original CAN.
Figure \ref{fig:can-original} shows an example of space in CAN.


In order to fully exploit the CAN DHT for our purposes, we extends some of its basic behaviour.
First, we have made possible for a node to manage more regions (Figure \ref{fig:can-super}).
There is no limit on the number of region a node can manage, and it can manage regions that are non-adjacent.
The mechanism is similar to the virtual server in SAM (Chapter \ref{chap:sam}), and so are the benefits.
However, here we apply the concept in a spatial address space, rather that the flat one considered in SAM.
The immediate advantage of this design is the possibility for the server to migrate regions between themselves.
This allows the infrastructure a mean to orchestrate the load, so to optimize the performances.

Second, we have provided CAN nodes with the ability of resolving \textit{spatial range queries}.
Conversely to a basic single item query, a spatial range query requires to find all items in an area.
Spatial range queries are periodically resolved to provide the with the entities in their AOIs.
In the single server PAM this operation is straightforward as the server has knowledge of all the positions of the entities.
However, in the multi-server PAM an avatar's AOI can overlap one or more servers.

In the original CAN overlay each node has a link with the servers that manage the adjacent neighbour regions. (Figure \ref{fig:can-original}). To support spatial range queries we have improved the base CAN overlay, by adding also links with the diagonal regions (Figure \ref{fig:can-super}).
This simple addition greatly improves the efficiencies of spatial queries. 
To clarify this point, let us consider a player whose avatar is in the region managed by S3 in Figure \ref{fig:can-vs}. 
Let us also consider that the player's AOI overlap with the server S7.
In the original CAN, S3 would have contacted S1, which in turn would have contacted S7.
Conversely, in the improved CAN S1 can directly contact S7.

To be sure that every spatial query is resolved within a single hop, we put a limit on the dimension of a region, so that it cannot be smaller than the AOI of a player. In this way, by imposing the minimum size of regions as the AOI size, and being the regions squared, an arbitrary AOI can overlap at maximum four regions.


\begin{figure}[tbh]
        \centering
        \begin{subfigure}[b]{0.45\textwidth}
                \centering
                \includegraphics[width=\textwidth]{images/can-original}
                \caption{Original CAN. Servers can manage only a single region, and have link with side neighbours}
                \label{fig:can-original}
        \end{subfigure}\quad
        \begin{subfigure}[b]{0.45\textwidth}
                \centering
                \includegraphics[width=\textwidth]{images/can-super}
                \caption{Enhanced CAN. Servers can manage more regions, and have link with side and diagonal neighbours}
                \label{fig:can-super}
        \end{subfigure}
        \caption{Original vs Enhanced CAN}\label{fig:can-vs}
\end{figure}







\paragraph{Avatar Movement}

As soon as a client connects to the PAM, it contacts a bootstrap node (which can be any node arbitrary node of the CAN DHT) to know the server to connect. The client maintains a direct connection with this server for two purposes. The client pushes the position of the avatar, and the server informs the clients with the entity in the avatar's AOI. However, when an avatars move to another region, it has to switch the connection to the new server. This change is fully handled server-side.

When the server receives a position update, it checks if the avatar is still in the same region. 
If it is the case, then it just updates the new position of the client.
Otherwise, the server identifies the neighbour server that is the new server for the avatar.
If we assume that the player cannot move larger that the size of a region in a single step, all this information is enough to find the new server. 
Now the server sends an hand-off message to the new server, by communicating the new incoming avatar and its position.
Afterwards, it removes the avatar from its own list. The new server adds the client to its list, and notifies to the client the successful operation. 
It can be the case that the new zone belongs to the same server. In this case the operation is completely transparent to the client.




\subsection{PAM Load Distribution}

In this section we analyse a load balancing mechanism for the multi servers PAM.
How we have seen during the whole thesis, the load in a MMOG follows seasonal patters.
Hence, here we consider not only load balancing, but also the orchestration of the on-demand resources for the multi-server PAM.


As we have seen in Chapter \ref{chap:pam}, an average server can manage few thousands players concurrently.
Even if the gossip-based interest management of PAM help increasing this limit, it eventually comes the time when a server is overloaded.
Here we consider a single node, let us call it \textit{orchestrator} managing  the load balancing and the recruit/releases of the on-demand resources. 
Here, we do not specifically address how the node for the orchestrator is selected. Consider for example that the first server to participate to PAM takes the role of orchestrator.

The initial consideration is on the definition of load.
For a PAM server, the load mostly originates from the resolution of the range queries.
Hence we measure the load as the average number of range query resolved per period of time.
This number should also include the requests that come from neighbours regions.
Also, we argue that the orchestrator should control the load per region, rather than per server.
This would give the possibility to have a finer control on the load distribution.


By considering the load of the region, and the assignment regions to servers, the orchestrator performs the following actions:

\begin{itemize}
\item In case of unbalanced load, the orchestrator either migrates a region from a heavy loaded server to an unloaded server, or splits up the region and migrates only part of it.
\item In case the number of servers was not enough to support the load, the orchestrator would recruit a new on-demand resource. The new server can be assigned with a newly created region (by splitting a overloaded region) or by migrating an existing region from a heavy loaded server. In the situation where the capacity of the servers is too high (over-provisioning), the orchestrator can release a server by assigning its regions to under-loaded servers.
\end{itemize}


Whatever the decision of the orchestrator, an important factor is the migration of servers.
In particular, it is important to consider and mask the migration time as much as possible.
In this case, it comes in help the design of the PAM.
The servers inform the players periodically, with a period defined as  in Chapter \ref{chap:pam}.
If we were able to keep the migration time shorter than , than the migration would be completely hidden from the user.




\section{Cheating}

As we pointed out in Chapter \ref{chap:background}, cheating is defined in \cite{Neumann2007} as "an unauthorized interaction with the system aimed at offering an advantage to the cheater".
In this section we provide an overview on possible cheating exploitation in SAM and PAM, as long as possible solutions to mitigate the issue. 
As in general in security, the following ideas are based on the principle of making the cheating hard to exploit, rather than providing bulletproof data protection.


\subsection{SAM}

A malicious player can exploit two possibilities to cheat in SAM:
\begin{itemize}
\item By taking advantage of her role as a client, and exploiting well-known cheating techniques used for centralized MMOGs, such as the \textit{suppressed update} (see Chapter \ref{chap:background}). We will refer to this kind of cheating as \textit{client-cheating}.

\item By taking advantage of her role as the server, in case virtual servers are assigned to her machine. 
For instance, it would be possible to favour updates of an ally player against updates from an enemy player.
We will refer to this kind of cheating as \textit{server-cheating}
\end{itemize}

As discussed in \cite{Webb}, employing a referee-based schema provides a good level of protection against client-cheating.
In a referee-based mechanism, entity updates must pass through a special node called \textit{referee}, whose task is to validate those updates.
In case of invalid updates, these are discarded. 
This schema fits the SAM architecture, as every server can play the role of referee.
In case of cheating evidence, the cheater can be reported or disconnected.


Allowing user-provided server to play the referee role exposes the architecture to server-cheating. 
For instance, a malicious server can mark as invalid the updates of a player, just to force her disconnection or reporting.
In this case, further measures should be taken into consideration.
For instance, backup nodes might perform checks on a sample of the updates, in place of the user-provided servers.
However, information exposure on the state of the other players can still provide an unfair advantage to players running a server.
A possible solution in this case would be to encrypt the entity values, so that only the backup server and the clients can decrypt the content. 
Due to the rapid staleness of entities' information, the encryption/decryption algorithm can be relatively simple, provided that the encryption key is refreshed often.
Also, we would a user-provided server to not manage an entity if the respective client is currently accessing it.
These ideas can also be integrated with rewarding mechanisms for virtuous user-provided servers, so to diminishing the value of the cheating.



\subsection{PAM}

As in the SAM, a referee-based approach is useful to mitigate the client cheating, with the servers playing the role of the referees.
However, differently from the SAM, players' nodes of the PAM communicate directly with each other.
In this scenario, it would be important to provide the authenticity of the sender and the integrity of the information.
A possible solution would be to use signed certificates to guarantee the provenance of data.
However, even if this mechanism is robust, it may be too clumsy for fast-paced applications like MMOGs.


A more flexible approach would be to apply a distributed reputation-based mechanism.
In this case, a node has the ability to report a malicious node to the nodes in its proximity.
In order to mark an arbitrary node  as malicious, nodes check 's information against the authoritative version of information coming by the server. If the difference between the two is suspicious (e.g. the information provided by  is not compatible with the information from the server) then a report about  is spread in the network.
When nodes receive enough reports about  they could ignore the information coming from , and, possibly, remove  from the peer sampling, in fact isolating it from the network.

\section{Conclusion}


In perspective, our independent analysis of PAM and SAM have obtained encouraging results.
In this Chapter we have provided ideas to combine PAM and SAM in a complete architecture for MMOGs.
However, to fully validate this approach several pieces are still absent.
First, a unifying cost model for PAM and SAM must be designed to properly orchestrate the resource between the two components. Further, an extensive evaluation must be performed to fully validate the solution.














\clearpage{}
\clearpage{}
\chapter{Related Work}
\label{chap:related}




This thesis considers the integration of pure distributed and on-demand computing models to effectively support MMOGs.
The application of these two aspects has requested a wide and detailed study of the related work on the field.
In this chapter we discuss and, when possible, compare the approaches that, to the best of our knowledge, are more relevant with respect to our work. 

Due to the inherent heterogeneity of the aspects discussed, this chapter has been divided in several sections to ease its fruition.
Section \ref{centralized} offers an overview on the design of centralized infrastructures for MMOGs. In particular, we discuss the emerging research issues of the last few years, that is the application of on-demand platform to MMOG infrastructures.
Section \ref{p2p} collects a summary of work tackling the problem of building MMOG infrastructures in a pure distributed fashion.
Section \ref{hybrid} concludes the part dedicated to the infrastructure design, by describing the approaches that employ a combination of centralized and distributed computing models for MMOGs. 
Section \ref{mobilitymodels} shows an overview on the mobility models for virtual environments.
Section \ref{casestudies} selects several interesting case studies, which enclose most of the problematic discussed in the Chapter.
Finally, Section \ref{related-conc} concludes the chapter.



\section{Centralized Infrastructures}
\label{centralized}


One of the main design choice for a MMOG is related to the distribution of the virtual environment.
On one hand, centralized infrastructures rely a server or a cluster of servers to manage the system.
On the other hand, user-assisted systems exploit the resource provided by the users, mostly using P2P technologies. In this section we provide an overview of the characteristics of centralized infrastructures MMOGs.




Centralized infrastructures rely on a cluster of servers, typically located in a single data center, to manage the virtual environment.
In such systems a set of client machines, paired with the users, share the game state by connecting directly to the cluster, which acts as a point of centralization. Whenever a client issues an action, this is sent to the server that updates the state of the world accordingly, and notifies the new state to the interested set of clients.

In a centralized infrastructure, clients merely work as interfaces to present the virtual world to the users. 
Differently from user-assisted infrastructures (which we discuss in the following) clients of a centralized infrastructure do not manage any part of the state that is not related directly with their user. Also, in centralized infrastructure there are no direct connections among the users.

The first proposals for centralized multi-user virtual environment go back to the middle nineties.
Most of such works, have focused on how to overcome the lack of scalability of a single server machine.
One of the principal method, which is still used nowadays, is to limit the communications between the server and user by sending only the necessary set of entities. For example, \cite{funkhouser1995ring} presents detailed algorithms to compute users visibility in the virtual environment, and avoids to broadcast updates to the user that are not in their proximity.

Centralized architectures exploit multiple servers, often organized in clusters, to manage the virtual environment. When considering multiple severs, the first issue is to properly distribute the virtual environment among the servers and to setup a pattern of communication among the servers. Multiple distribution schemas have been proposed in the last decade.
A common classification \cite{prodan2009prediction,glinka2007rtf}  considers these as the most frequently used models: \textit{Instancing}, \textit{Mirroring} and \textit{Zoning}.


\begin{figure}[tbh]
        \begin{subfigure}[b]{0.3\textwidth}
                \centering
                \includegraphics[width=\textwidth]{images/instancing}
                \caption{Instancing}
                \label{fig:instancing}
        \end{subfigure}
        \quad
        \begin{subfigure}[b]{0.3\textwidth}
                \centering
                \includegraphics[width=\textwidth]{images/mirroring}
                \caption{Mirroring}
                \label{fig:mirroring}
        \end{subfigure}
        \quad
        \begin{subfigure}[b]{0.3\textwidth}
                \centering
                \includegraphics[width=\textwidth]{images/zoning}
                \caption{Zoning}
                \label{fig:zoning}
        \end{subfigure}
        \caption{Distribution strategies}\label{fig:dist-strategies}
\end{figure}



\paragraph{Instancing}
In this solution, the issues in managing the concurrency between multiple servers is avoided.
In practice, a portion of the virtual environment is replicated on multiple servers, each one maintaining an independent version of the state.
Each client is connected to a single server, and share the virtual environment only with the client connected to the same server.
For instance, in Figure \ref{fig:instancing} the clients  and  share a copy of the virtual environment on the server , while  and  share another copy of the virtual environment on .
In other words this solution basically replicate the centralized solution on more instances.
This solution is used in commercial applications as well as in several research work, such as in \cite{Barri2011}.

\paragraph{Mirroring}
In mirroring, as in instancing, the state of the VE is replicated in multiple servers.
However, unlike instancing, multiple servers can manage the same portion of the virtual environment.
Also, the servers are connected to each other in order to synchronize the state.
Each client connects to one server, but multiple clients in the same region can be connected to different servers.
Figure \ref{fig:mirroring}  shows an example of mirroring. 
In this case, all the clients share the same virtual environment using two servers.
Clients  and  are connected to the server , while  and  are connected to .
In case  modifies the state of ,  will synchronize with  in order to share the same modification also with  and . This technique has been explored in different research works, such as \cite{cronin2004efficient,mauve2002generic}. 

\paragraph{Zoning}
In zoning, the virtual environment is divided into a set of regions, normally contiguous and non overlapping.
The shape of the regions is generally squared or hexagonal. 
One or more regions are assigned to a server, but the same region is assigned only to a single server.
Clients connect to one or more servers according to their position. In fact, if the area of interest of a user overlap multiple regions, the client must connect to the corresponding servers.
Zoning is depicted in Figure \ref{fig:zoning}, where  and  are connected to  and  at the same time.
This techniques has been studied in various research works, such as \cite{carlini2010integration,Kim2004,greenhalgh1995massive,lee2002atlas}.\\



These techniques are not exclusive to each other, rather a combination of them is possible. For instance, it is possible to divide the virtual environment into regions and for each regions apply mirroring. In fact, several proposal employ mixed approach to distribute the state of the virtual environment.



\subsection{On-demand Platforms}
\label{cloud}

Exploiting on-demand resources for MMOGs is a relatively young but very active line of resources.
Here we present two of the most relevant paper regarding this field.

To exploit the potential of on-demand provisioning, \cite{Marzolla} proposes a multi-tier cloud architecture. The first layer of the architecture contains a set of gateways, responsible for handling basic gaming protocol
checking and verification. The second level exploits Zone Partitioning by defining a set of cell servers each one  controlling a small area of the virtual environment.
Finally, the database servers manage the persistent game state information. Each layer of the architecture contains a set of parallel servers whose number is elastically defined at run time.
To this end, a monitor periodically collects several system statistics, and triggers the provisioner when the system response time deviates from a given threshold. A Queueing Network performance model is exploited where each server is modelled  with exponentially distributed inter-arrival times, exponentially distributed service times and FIFO service discipline. Finally, a greedy algorithm computes the number of servers in each level required for maintaining the response time under a given threshold and reserves the corresponding resources on the cloud.


In the same context, \cite{IosupTPDS} proposes an analytical load model
for MMOGs taking into account the main resources used by MMOGs: CPU, memory, and network. 
The model describes the machine load that has to consider the computation of the interaction
between pairs of entities, the reception of event messages from each client, and the update of entity states received from/sent to another machine.
\cite{IosupTPDS} also shows that, even if simple prediction algorithms are computationally inexpensive,
they exhibit a low predictive power. More elaborated prediction algorithms like autoregressive (AR), integrated (I), moving
average (MA) models, and combinations of these are time consuming and resource intensive, so that they are
not suitable for highly dynamic MMOGs. \cite{IosupTPDS} proposes an alternative approach, based on low complexity neural networks and shows that this approach enables precise resource provisioning.


\section{User-assisted Infrastructures}
\label{p2p}

In user-assisted infrastructures, clients actively participate at the management of the virtual environment. 
In other words, clients manage a part of the virtual environment, in fact by assuming the role of the server for that part.
User-assisted infrastructures are characterized by a pattern of communication between client nodes, which we generally refer to as \textit{overlay}. The nature and type of the overlay change according to the kind of infrastructure considered; in fact, user-assisted infrastructures can be classified in two ways, according to the clients that cover the role of server.

In \textit{hierarchical infrastructures} a set of (super) clients, also called \textit{Super Peers (SP)}, have enhanced knowledge with respect to regular clients. Normally SPs are connected by means of a dedicated overlay.
In \textit{flat} approaches, there is no neat distinction between super and regular clients.
These approaches typically employ an overlay that is common to all the clients in the network.




\subsection{Super-Peers Infrastructures}


\begin{table}[tbh]
\centering
\begin{tabular}{|c|p{1.3cm}|p{1.4 cm}|p{1.8cm}|p{1.7 cm}|}
\hline
Name & SP \newline overlay & Non-local \newline SPs & Event \newline notification & Space \newline Partitioning \\
\hline
\hline
HYMS \cite{Kim2004} & none & no & unicast SP & Square\\
\hline
VSM \cite{hu2008voronoi} & Voronoi & yes & unicast SP & dynamic \\
\hline
P2P-Arch \cite{Hampel2006} & DHT & yes & unicast SP & hexagonal\\
\hline
MOPAR \cite{Vuong2005} & DHT & yes & unicast P2P & hexagonal\\
\hline
\end{tabular}
\caption{Super Peer Approaches}\label{tab:sp}
\end{table}


In Super-Peer infrastructures, a selection of clients actively participate to the management of the virtual environment.
In the last years, several SP-based approaches have been proposed \cite{Kim2004,hu2008voronoi,Hampel2006,Vuong2005}.
These works perform a partitioning of the virtual world into regions.
Each region is managed by a super peer (sometimes called \textit{region controller} \cite{Hampel2006} or \textit{arbitrator} \cite{hu2008voronoi}) along with a set of backup SPs in order to increase robustness in case of failure of the main super peer.
To be considered as a super peer, a regular peer must satisfy particular requirements in term of hardware capability (bandwidth, CPU, RAM) and in term of stability. 
Regular peers receive state updates from the SP that manages their regions.


In \cite{Kim2004} the world is divided into square regions that, at the beginning, are assigned to a central server.
The first peer with enough computational and bandwidth capabilities to enter a region manages the region.
No overlay is provided between super peers, i.e. super peers do not have the possibility to communicate.
This represents a limit of the approach, as the view of a user is limited to a single region.
Also, this work performs local SP assignment, i.e. a peer can become a Super Peer for an arbitrary region  only if the correspondent avatar is in .  This can increase the probability of cheating.
Conversely, In \cite{Hampel2006} and \cite{Vuong2005} hexagonal regions are assigned to Super Peers in a random fashion, by exploiting a DHT.
Because of the random mapping, it is unlikely that a Super Peer manages a region where the correspondent user in playing.
This non-local SP assignment helps to reduce the possibility of cheating.

Voronoi State Management \cite{hu2008voronoi} partitions the virtual environment with a Voronoi tessellation.
Given a number  of points on a two-dimensional plane, a Voronoi diagram partitions the space into  non-overlapping regions and each region contains all the points closer to the region site. 
In a Voronoi overlay network each site corresponds to a peer in the network. 
Each peer  maintains a Voronoi diagram of a subset of the space and connections with its Voronoi neighbours in the two-dimensional space.
The result is an unstructured overlay where each peer manages the space correspondent to its Voronoi region.
Each Super Peer manages a Voronoi cell, by receiving and communicating the updates to the clients in the cell.
A big advantage of the Voronoi partitioning is the possibility to resize the region managed by super peers, which helps to balance and distribute the load.


\subsection{Peer-to-Peer Infrastructures}

\begin{table}[tbh]
\centering
\begin{tabular}{|p{2.2cm}|p{1.3cm}|p{2.1cm}|p{2.2cm}|p{1.2cm}|}
\hline
Name & Space \newline Part. & P2P \newline Overlay & Event \newline Notification & Objects \newline Mngmt. \\
\hline
\hline
SOLIPSIS \cite{Frey2008} & Voronoi & Delauney & P2P unicast & yes \\ \hline
VON \cite{Hu2006} & none & unstructured & P2P unicast & no \\
\hline 
Colyseus \cite{Bharambea} & -- & DHT & pubsub over DHT & yes \\ \hline
SimMud \cite{Knutsson2004} & regions (static) & DHT & Positions: P2P multicast & yes \\ \hline
APOLO \cite{lee2006apolo} & none & unstructured (quadrant) & Controlled Flooding & no \\
\hline
Compass \cite{ricci2011aoi} & voronoi & delauney & P2P multicast trees & no \\
\hline
Peer Clustering \cite{Chen} & regions (static) & DHT & region manager unicast &  yes \\ 
\hline
\end{tabular}
\caption{Flat approaches. Other works cited in the section, like VON-Forwarding \cite{chen2007forwarding} and FiboCast \cite{Jiang2009} are optimization of VON.}\label{tab:flat}
\end{table}


In this kind of solutions, neither supernodes or servers are considered. 
All users participating to the virtual environment manage a portion of it.
These infrastructures are typically structured considering the position of the user in the virtual environment.
Flat approaches can be classified according to the degree of structuredness of the overlay between nodes.

Several works exploits Distributed Hash Tables (DHTs) as the main server overlay \cite{Chen,Bharambea,Knutsson2004}.
For instance, \cite{Chen} exploits the randomness of DHT objects placement in order to assign regions to their controller.
Each controller receives the notification of updates and forward them to the interested node.
Similarly, SimMud \cite{Knutsson2004} divides the virtual world into regions, and each region has assigned a coordinator.
The coordinator serves two tasks.
First, it permits the creation of a full connected overlay between nodes. 
This overlay is then used by the node to notify each other their movements.
Second, the coordinator works as the root of a multicast tree for the region. To create the multicast paths, SimMud exploits Scribe \cite{Castro2002}, a well know approach to build multicast infrastructures over structured P2P networks. Peers generate events and notify them to their region coordinator, which in turn forward them along the multicast tree.
Even if from a structural point of view Scribe is able to manage dynamic membership and large groups, a potential problem is the latency of messages. In fact, the number of hops and the length of the paths may dramatically increase the latency. 
Also, it has been pointed out in \cite{Bharambe2005} that application-level multicast may saturate the bandwidth of nodes in presence of heterogeneous bandwidth capability, which is the case in wide distributed MMOGs.
This strategy assures low values for messages latency, since each recipient is always one or two hops away from the source. However, as the number of recipient nodes grows, this method may oversaturate the bandwidth capability of the source. 

Another kind of solutions consider a dynamic partitioning of the virtual environments.
These solutions are based on the Voronoi tessellation.
They employ an event forwarding schema, in order to deliver events to other possible interested recipients.
These solutions have usually high scalability, since the necessary bandwidth to deliver events is split among a number of nodes. On the other hand, forwarding-based solutions may increase latency since event source and recipient may be separated by multiple hops.
Compared with DHT-based approach, these mechanisms yield two relevant advantages. First, they have no overhead for peer churn, since they work without any long term and synchronized structure. Second, only local peer information is exploited to forward messages.

One of the first solutions based on unstructured overlay is APOLO \cite{lee2006apolo}. Each peer divides its space of interest into quadrants and maintains a link to the closest neighbour in each quadrant. In order to notify an event, a peer sends the message to these four neighbours, which in turn recursively forward the message until it reaches all the possible interested peers. This solution strictly bounds the number of outgoing connections per peer, nevertheless, it may dramatically increase the number of hop and the bandwidth consumption in case of crowded situations.

A later approach, VON-forwarding \cite{chen2007forwarding}, divides the space according to a Voronoi diagram.
Each peer broadcasts a message to all its Voronoi neighbours in order to notify the peer in its AOI. This solution exploits that, on average, a peer in a Voronoi diagram has six neighbours. Compared with the direct link approach, VON-forwarding helps reduce the number of messages per event sent by peers. 
Compared with APOLO, the number of hops decreases due to the wider degree of the AOI-cast tree.
In spite of that, the bandwidth usage is not efficient due the elevated number of messages replication in the network.
This model has been subsequently refined with VoroCast and FiboCast \cite{Jiang2009}.
VoroCast builds a multicast spanning tree using the underlying Delauney network and sends the notifications of events along the edges of this tree. FiboCast is a further optimization of VoroCast. It models messages frequency rates using the Fibonacci sequence, in a way that farthest nodes from the source receive updates less frequently than nearby nodes.
The main disadvantage of these systems is the fact that they require non-local information to correctly forward messages. 
In particular they need to know the neighbours of the neighbour of a node, and since it depends on the position of the peers, this information has to be updated frequently. This may cause an increasing of bandwidth consumption, especially in crowded situation, where the Voronoi diagram change rapidly. Another aspect to consider is that VoroCast and FiboCast do not take into account the effects of the latency when considering the position of the peers (i.e. the positional drift). Due to this reasons, delivered messages may be duplicated and travel along path that are longer than necessary.

Ricci et al \cite{ricci2011aoi} propose a Delauney-based AOI-cast that copes with these two drawbacks. First, they employ a forwarding schema based on compass routing that exploits only information local to peers, i.e. theirs one-hop neighbours. This avoids the extra-usage of bandwidth for maintaining n-hop neighbours, which happens in approaches like VoroCast. Second, their solution takes into account the latency in information diffusion, by considering the possible positional drift occurred to the peer when computing AOI-cast paths. This reduces messages redundancy and decreases the probability of message losses.


\subsection{Anti-Cheating}


The mechanisms to contrast cheating are called Anti-Cheating (AC).
One of the first AC solutions, Lockstep \cite{Baughman2007}, divides the time into rounds and requires every player to submit its moves for that round before the next round is allowed to begin. 
Unfortunately this approach slows down the experience and it is not applicable for fast-paced virtual environment.
Asynchronous Synchronization \cite{Baughman2007} (AS) and Sliding Pipeline \cite{Cronin} (SP) strive to improve the performance of Lockstep. 
AS relaxes the constraints of Lockstep by requiring only players in a region to work as Lockstep. 
SP permits the updates to be pipelined and the use of dead reckoning in order to improve the smoothness of the simulation. However, both these approaches suffer of the same problem of Lockstep, i.e. they force a user to wait until the duration of a round before validate its state.
New Event Ordering (NEO, \cite{Gauthierdickey}) aims to reach a distributed consensus among a set of distributed clients. NEO explicitly bounds the round duration, and each round is divided into two halves. 
Clients must send the actions to half of a group within the half of a round duration, in order to consider the update committed.
In the other half of the round, players send their key for security checks. 
In \cite{Webb}, authors propose the Referee Anti-Cheat Schema (RACS), an anti-cheating schema suitable for centralized and hybrid approaches. RACS uses a central server, called \textit{referee}, to receive, simulate and validate the events. 

\section{Hybrid}
\label{hybrid}

Hybrid architectures aim for the combination of user-assisted and centralized infrastructures. A wide-used method divides the \textit{Virtual Environment} (VE) into \textit{regions} or \textit{cells}, whose dimension can be either fixed or variable. These regions are in turn assigned to a peer or a server, which becomes the \textit{manager} of the entities in that region.
Region assignment in hybrid architecture mostly follows two different approaches: (i) a region can be assigned to either a peer or
to a server without any restriction, or (ii) only a subset of cells can be assigned to peers.

The work proposed in \cite{Kim2004} belongs to the first category. The authors consider square cells, which are initially managed by a central server. The first peer with enough computational and bandwidth capabilities to enter a cell becomes the cell manager. Afterwards,
a fixed number of peers that enters the same cell act as backup managers in order to increase failure robustness. Similarly, \cite{Barri2010} proposes an hybrid system, including a central server and a pool of peers. The central server runs the MMOG and, as soon as it reaches the maximum of its capacity, delegates part of the load to the peers. 


The same authors of \cite{Barri2010} propose in \cite{Barri2011} an approach belonging to the second category. A central server executes the main game whereas the peer run \textit{auxiliary games} which are typical of certain games genres, such as Massively Multiplayer Online Role-Playing Games (commonly called MMORPGs). Auxiliary games are separated instance of the MMOG, shared only by a fixed (and usually not high) number of players. 
In a similar way, \cite{Chen} proposes a functional partition of the DVE tasks. Central servers operate user authentication, game persistence and manage regions characterized by high-density user interactions, whereas peer support only low-density interaction regions. 
Authors of \cite{Jardine2008} provide an interesting distinction between \textit{positional} and \textit{state-changing} actions. They propose an hybrid architecture where peers manage positional actions, which are more frequent and prone to be maintained locally. Central servers handle state-changing actions, that are not transitory and require a larger amount computational power. 

The idea of distinguishing positional and state-changing actions is in fact an interesting idea which we have exploited 
in the design of our architecture.
However, rather than assigning different actions to different type of nodes, we define two different and independent distributed structures that manage, respectively, positional and state-changing actions.
The management of the nodes can be assigned  to a peer or to a cloud node.

In other words, we exploit an intermediate approach. On one hand, some functionalities, like authentication, must be handled by centralized and full controllable servers. On the other hand, other functionalities may be mapped
to central servers or to peers. This requires a complete dynamic strategy allowing for more flexibility in load distribution, which requests a fine-grained management of the resources by the MMOG operator. Resources control is very important for our approach, since the seamless combination of Cloud and P2P requires to keep under control the cost and to effectively deal with the implicit uncertainty related to peers. 
Therefore, a basic issue for the exploitation of hybrid architectures is the definition
of effective load distribution mechanisms. 


\section{Mobility Models in MMOGs}
\label{mobilitymodels}

The evaluation of the fist generation of  MMOG architectures was generally performed by exploiting mobility models originally designed to reproduce the movements of human beings, such as those exploited to evaluate ad-hoc wireless networks.


The {\em Random Way Point model} RWPM \cite{Hong1999} was one of the most widely exploited mobility model.
In RWPM a set of {\em way points} are placed uniformly at random locations in the virtual environment.
Each entity independently moves toward them.  As soon as an entity reaches a way point, it stops there for a time interval. 
Afterwards, it chooses another way point, and so on. 
RWPM has been adapted to describe different kind of scenarios in a MMOG by tuning the spatial distribution and the number of the waypoints, the speed of the entities and the criteria to select the waypoints at each step.
While most mobility models for ad-hoc wireless mobile networks focus on the  motion behaviour of each entity separately, mobility models taking into account the behaviour of {\em group of entities} have been proposed.
The {\em Reference Point Group Mobility model (RPGM)} \cite{Hong1999} has been proposed as an extension of the RWPM, by 
introducing in the model the concept of group. The model can be exploited to simulate the behaviour of teams of players.

Although very simple to generate, the mobility patterns created with RWPM-based mobility models are not precise enough 
to represent the characteristics of nowadays MMOGs.
Indeed, since players participating to large scale MMOGs usually have the possibility to move freely around the virtual world, the distribution of the players in MMOGs is usually not uniform \cite{La2008}.
Players tend to gather in well determined positions of the virtual environments, creating the so called hotspots.
Furthermore, players behaviour inside hotspots results to be highly non-uniform: players move slowly and chaotically within the hotspots, while the movement between hotspots is straight and fast \cite{Liang2008}.

These considerations lead to the design of mobility models specifically developed for MMOGs.
For example, \cite{Tan2005} provides a design and evaluation of a mobility model based on a popular on-line game\footnote{Quake II, http://www.idsoftware.com/games/quake/quake2}. The model is based on a RWPM whose parameters are evaluated by using model fitting techniques on traces. These traces have been used also in \cite{Bharambea} in order to evaluate their solution. They propose a model based on real traces where players tend to move between popular regions of the map and the popularity distribution of these regions follows a well specific trend. 
\textit{Blue Banana} \cite{Legtchenko2010} provides the design of a mobility model based on Second Life \cite{sl-site}.
This model characterizes the virtual environment between desert areas and hotspots.
The model assumes the movement of the avatars to be slow and chaotic in the hotspots, while fast and predictable in the desert areas of the MMOG. The model exploits an automaton defined by three states, the {\em halted state}, where the avatar does not move, the {\em exploring state} where the avatar moves within a hotspot and the {\em travelling state} where
the avatar moves from one hotspot toward another one.
The definition of hotspot as an invariant for a MMOG mobility model is also one of main finding of the work of  Miller and Crowcroft \cite{Miller2009}. They measure and analyse players movements in a World of Warcraft (WOW, \cite{wow-site}) scenario, which is representative of the team-oriented interaction that modern MMOGs encourage into the game. 
However, \cite{Miller2009} does not define any mobility model. The main findings of their work state that a way point-based model is not enough to describe complex movements of MMOGs, that the level of gathering of players in groups is less than expected and that hotspots based mobility is a realistic pattern of movement in MMOGs.



\section{Case Studies}
\label{casestudies}

In this section we describe several core proposal in the field of the distributed virtual environment.
We chose three different and heterogeneous approach that, in our opinion, best represent the issues in designing a distributed virtual environment. 


\subsection{SimMud}
SimMud \cite{Knutsson2004} is a support for Massively Multiplayer Games built on top of the Pastry DHT \cite{rowstron2001pastry}. SimMud uses Scribe \cite{Castro2002}, an application-layer multicast built on top of Pastry, as the main communication pattern to disseminate game state. The design of SimMud is based upon the limited movement speed and sensing capabilities of the avatars, so that the locality of interest can be exploited. SimMud maps both the participating peers and the MMOG's objects onto uniformly distributed IDs in the circular 128-bit namespace of the DHT. Object insertions and lookup are done by exploiting the classical DHT primitives.
Objects are managed by nodes whose ID is numerically closest to the object ID. In SimMud, "closeness" it is related to the numerical ID and no geographical or topological optimizations are considered.

Scribe is a scalable multicast infrastructure that maps the information about multicast groups to the Pastry DHT. A multicast tree associated with the group is built by merging the Pastry routes from each group member to the group ID's root, which also acts as the root of the multicast tree. A multicast message from the root reaches the members by following the reverse paths of the multicast tree.




The world is statically partitioned into rectangular regions and the nodes in the same region form an interest group for that portion of the map. The region updates are sent within the group only. Whenever a player goes from a region to another, the group membership changes accordingly. 
A node whose ID is the closest to the region ID serves as the \emph{coordinator} for that region. The coordinator manages all the objects in its region and also acts as the root of the multicast tree. The load can be distributed by creating a different ID for each type of objects in the region, thus mapping them on to different peers.
     
SimMud defines different classes of game state and pairs different consistency maintenance strategies with each class.
\begin{itemize}
\item The \emph{player state} is accessed according to a single-writer multiple-reader pattern. Each player updates its own location as it moves around. Player-player interactions, such as fighting and trading, only affect the states (e.g. the life points) of the players involved. Since position change is the most common event in a game, the position of each player is disseminated through multicast messages at fixed intervals to all other players in the same region. The interval is determined during game design, according to the requirements of the game.

\item The \emph{object state} is managed by a coordinator-based mechanism to keep shared objects consistent. A certain degree of replication is provided. Each object is assigned to a coordinator that manages its updates. A replica is maintained by a node close to the coordinator in the DHT space. 
The coordinator both resolves conflicting updates, and stores the current object value. 
Successful updates are multicasted to the region to update each player's local copy.
\end{itemize}

SimMud exploits shared state replication to manage peer failures. 
The copies are kept consistent, in spite of node and network failures, through a lightweight primary-backup mechanism that tolerates failures of the network and nodes. These failures are detected by exploiting messages of regular game events (i.e. peer movements), without any additional network traffic.

\subsection{Colyseus}


The main focus of Colyseus \cite{Bharambea} is the management of the game state. The world is seen as a collection of objects, both mutable (e.g. items, characters) and immutable (e.g. map geometry, graphics). Colyseus manages the collection of mutable objects through a component called \textit{global object store}. Each mutable object is associated with a \textit{think} function that determines the behaviour of the object.
The architecture of a generic peer is composed by the following modules:
\begin{itemize}
\item a \textit{local object store} i.e. the collection of primary objects and replicas
\item a \textit{replica manager} that manages the synchronization of primary and replicas
\item a \textit{object placer} that decides where to place and migrate primary replicas
\item a \textit{object locator} that connects to a DHT overlay indexing all the objects in the game. 
\end{itemize}



Each object in the global object store has one \textit{primary} copy that resides onto one node. Updates to an object are sent to the primary node, which takes care of the ordering of updates.
A node executes only the think function associated with primary objects in its local store. The execution of such functions may require access to objects that a node is not the primary owner of. In order to facilitate the execution of this code, a node create a secondary \textit{replica}. The node periodically registers an interest with the node hosting the primary object. Replicas are weakly consistent and are synchronized with the primary copy. In detail, at each frame, whenever the primary object is modified, an update is sent to all the replicas. Similarly, whenever a secondary replica is modified, an update is shipped to the primary owner.

The replicas are fetched using a multi-attribute range query DHT. Colyseus proposes two approaches in order to guarantee low latency on lookup queries. First, it exploits spatial and temporal locality in object movements in order to obtain prediction of subscriptions. This allow the DHT to execute speculative pre-fetching of replicas. 
Second, it enables soft caching of both publications of the objects and subscriptions. By storing publications, a subscription can immediately match with a recent publication. 

\subsection{Voronoi Based Overlay Network}
\label{sec-von}

Voronoi based Overlay Network (VON) \cite{Hu2006} is a P2P overlay network based on Voronoi Diagrams which preserves high consistency of the overlay topology. 
The initial proposal of VON defines a direct connection model, where each node of the  virtual environment is directly connected to all the nodes located in its AOI. Due to the limited bandwidth of each node, this model may constrain the number of neighbours that may appear within the area of interest of a given node. VON defines different kinds of neighbours of a node. The enclosing neighbours of a node  are the nodes whose regions immediately surround the Voronoi region defined by .
The boundary neighbours are the nodes whose Voronoi regions intersect the border of AOI(n).
Finally, the AOI neighbours are all further nodes belonging to AOI(n).  Each node keeps a Voronoi Diagram including its enclosing, boundary and AOI neighbours. In VON, each node acts as a "watchman" for another one in discovering approaching neighbours. When an entity moves, it sends its new position to all the neighbours belonging to its Voronoi Diagram. If the receiver is a boundary neighbour, it performs an overlap-check, i.e. checks whether the Voronoi region of one of its enclosing neighbours overlaps the AOI of the mover. The receiver notifies the mover if a new overlap occurs, i.e. previously disjoint regions currently overlap. In this case the boundary neighbour explicitly notifies the mover about the new neighbours.
The moving entity becomes aware of neighbours outside its AOI with minimal network overhead, since position notification may be exploited to discover new neighbours.
Whenever a node leaves the virtual environment or fails, its neighbours update their Voronoi Diagram by removing that node.
The direct connection model may require a large amount of bandwidth, especially when crowding occurs. 
Event notifications are propagated to each AOI neighbour by forwarding notification through neighbour nodes.



\subsection{On-demand Provisioning}

The work in \cite{prodan2009prediction} has been one of the fist proposal for dynamic provisioning of on-demand resources for MMOGs applications.
Its architecture is composed by two core services: a \textit{load prediction service}, and a \textit{resource allocation service}.

The load prediction service has the task of predicting the future distribution of avatars in an area of the MMOG. 
The load prediction service exploits a \textit{neural network} to estimate the numbers of avatars in an arbitrary region.
The number of avatars is then used to compute the CPU time requirements for the region.
The neural network is trained with a series of traces that are implemented by the authors.
The traces consider different avatar's profile, such as aggressive (frequently interact with opponents), team player (mostly acts in groups), scout (mostly acts alone) and camper (hides and waits for opponents). Their result shows that the neural network over-performs other prediction mechanisms, such as Moving average and Exponential smoothing.


The resource allocation service (presented in \cite{Nae2008}) exploits the prediction results to drive the on-demand allocation of resources. The resource allocation service executes two main tasks.
First, it recruits more servers to accommodate more players during peak hours. 
The new servers are recruited considered the prediction on the CPU load made by the neural network.
Second, the resources allocation service releases under-utilized servers to optimize the resource utilization.






\section{Conclusion}
\label{related-conc}

This chapter has provided an analysis of the state of the art in several research fields on MMOGs.
A clear trend of the research related to MMOGs emerges from this analysis.
The first pioneering works in late '90 have considered centralized approaches.
At the time, issues on interest management and on consistency-interactivity tradeoff have emerged.
In the early 2000, MMOGs research turned on widely distributed infrastructure, together with the concurrent explosion of the P2P computing. P2P and widely distributed infrastructures have posed new challenged that had not been considered before.
Extensive load distribution, overlay maintenance and fault tolerance are few examples of the issues faced in that period.


Nowadays, the next-generation MMOG platforms definitely leads forward to on-demand computing models.
This trend is evident since most of the recent works on MMOGs architectures strive with this thematic. 
However, we believe that a decade of research in P2P-based MMOGS architecture have still its role to play. 
For this reason, this thesis treats the combination of P2P and on-demand computing models, and, as far as we know, we are the first in this direction.














\clearpage{}
\clearpage{}
\chapter{Conclusion}
\label{chap:conclusion}




This thesis has presented two different and independent components for a MMOGs architecture that integrates the illusion of infinite resources provided by the Cloud, with the few cost associated to the exploitation of user-provided resources. We designed the two components by allowing the MMOG operator to control the trade-off between performance and economical cost.

The idea of combining these two different computing models came from some work we carried out in the field of cloud computing \cite{carlini2012cloud} and P2P architecture for on-line gaming infrastructures \cite{ricci2011aoi}. We first proposed the general concepts in \cite{carlini2010integration}, along with several preliminary ideas.
In \cite{ricci2012tutorial} we presented a comprehensive state of the art on on-line games infrastructures, also considering emerging computing models as the Cloud.
However, at the best of our knowledge, we are among the first that have proposed the \textit{combination of Cloud and P2P} for large scale MMOGs infrastructures.


The Positional Action Manager (PAM) is based on a combination of a cloud server and a best-effort P2P overlay providing support for interest management in large scale online games. To build the P2P overlay, PAM employs a \textit{two-layer gossip-based} protocol. 
PAM is fully described in \cite{gossipim,netgames12}.
As far as we know, this is the first time a gossip protocol is used as an active mean to resolve interest management. Besides its originality, the PAM-overlay has provided encouraging results. 
Experimental results show that PAM is able to obtain performance comparable to a server solution, while reducing the expenses for the game operator. In accordance with our view, the operator can further tune the tradeoff between performances and economical cost, by trading some precision in the result for a more economic infrastructure.



The State Action Manager (SAM) exploits a Distributed Hash Table, equipped with Virtual Servers to distribute the effort on management of the entities to multiple resources, including user-provided ones. 
We presented an initial version of the SAM \cite{pos}, where we exploited the knowledge acquired with our prior work on the distributed hash tables \cite{carlini2010reducing,carlini2011probabilistic}. In the thesis, we have presented a refined and enhanced version of the SAM. 
In order to pro-actively distribute the entities of a MMOG among the nodes of the SAM, we employed a \textit{greedy heuristics} that minimizes the operational costs while keeping the availability and the fraction of non overloaded nodes above the given threshold. 


In order to test and evaluate the two components, we built a \textit{realistic bandwidth consumption workload}. 
We considered both the load from direct players interactions and the load from the interactions of the players with the objects of the virtual environment. 
This represents a difference with work in literature, that tends to considers these approaches separately.
The movement traces of the avatars were obtained by exploiting a Second Life mobility model.
We have observed in \cite{carlini2011evaluating} that this model assures a fair balancing in players movements.


Finally, we proposed some future work, having the common goal to unify the two aforementioned components in a full infrastructure for MMOGs.
The design of a smart client would allow the players to exploit the advantages of SAM and PAM at the same time. A multi server PAM would be able to scale up to ten thousands of players, while keeping the economical costs acceptable. 
We strongly believe that the combination of Cloud Computing and Peer-to-Peer is the next milestone for MMOGs architectures.

\clearpage{}


{\small
	\renewcommand{\bibname}{References} 
	\bibliographystyle{alpha}
	\bibliography{backmatter/bib/thesis}
}

\makecopyright

\end{document}