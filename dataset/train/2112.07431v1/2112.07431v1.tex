\begin{table*}[h]
\begin{centering}
\begin{tabular}{ccc|ccc}
\hline 
Method & Backbone & Supervision & VOC12 val & VOC12 test & COCO14 val\tabularnewline
\hline 
\hline 
BFBP \cite{saleh2016built} & \textcolor{grey}{VGG16} &  & \textcolor{grey}{46.6} & \textcolor{grey}{48.0} & \textcolor{grey}{20.4}\tabularnewline
    SEC \cite{kolesnikov2016seed} & \textcolor{grey}{VGG16} &  & \textcolor{grey}{50.7} & \textcolor{grey}{51.7} & \textcolor{grey}{22.4}\tabularnewline
AffinityNet \cite{ahn2018learning} & \textcolor{grey}{ResNet-38} &  & \textcolor{grey}{61.7} & \textcolor{grey}{63.7} & -\tabularnewline
IRNet \cite{8953768} & \textcolor{grey}{ResNet-50} &  & \textcolor{grey}{63.5} & \textcolor{grey}{64.8} & -\tabularnewline
OAA \cite{jiang2019integral} & ResNet-101 &  & 63.9 & 65.6 & -\tabularnewline
ICD \cite{fan2020learning} & ResNet-101 &  & 64.1 & 64.3 & -\tabularnewline
{SEAM \cite{Wang_2020_CVPR}} & \textcolor{grey}{ResNet-38} &  & \textcolor{grey}{64.5} & \textcolor{grey}{65.7} & \textcolor{grey}{31.7} -\tabularnewline
SSDD \cite{shimoda2019self} & ResNet-101 &  & 64.9 & 65.5 & -\tabularnewline
CONTA \cite{zhang2020causal} & \textcolor{grey}{ResNet-38} &  & \textcolor{grey}{66.1} & \textcolor{grey}{66.7} & \textcolor{grey}{32.8}\tabularnewline
SC-CAM \cite{chang2020weakly} & ResNet-101 &  & 66.1 & 65.9 & -\tabularnewline
Sun et al. \cite{sun2020mining} & ResNet-101 &  & 66.2 & 66.9 & -\tabularnewline
PMM\cite{li2021pseudo} & \textcolor{grey}{ResNet-38} &  & \textcolor{grey}{\underline{68.5}} & \textcolor{grey}{\underline{69.0}} & \textcolor{grey}{\underline{36.7}}\tabularnewline
PMM\cite{li2021pseudo} & \textcolor{grey}{ScaleNet-101} &  & \textcolor{grey}{\underline{67.1}} & \textcolor{grey}{\underline{67.7}} & \textcolor{grey}{\underline{40.2}}\tabularnewline
PMM\cite{li2021pseudo} & \textcolor{grey}{Res2Net-101} &  & \textcolor{grey}{\underline{70.0}} & \textcolor{grey}{\underline{70.5}} & \textcolor{grey}{\underline{35.7}}\tabularnewline
\hline
DSRG \cite{huang2018weakly} & ResNet-101 & +ESnE+MSRA-B & 61.4 & 63.2 & \textcolor{grey}{26.0}\tabularnewline
FickleNet \cite{lee2019ficklenet} & ResNet-101 & + & 64.9 & 65.3 & -\tabularnewline
SDI \cite{Khoreva_2017_CVPR} & ResNet-101 & ++BSDS & 65.7 & 67.5 & -\tabularnewline
OAA \cite{jiang2019integral} & ResNet-101 & + & 65.2 & 66.4 & \tabularnewline
SGAN \cite{yao2020saliency} & ResNet-101 & + & 67.1 & 67.2 & \underline{33.6}\tabularnewline
ICD \cite{fan2020learning} & ResNet-101 & + & 67.8 & 68.0 & -\tabularnewline
Li et al. \cite{li2020group} & ResNet-101 & + & \underline{68.2} & \underline{68.5} & \textcolor{grey}{28.4}\tabularnewline
LIID \cite{liu2020leveraging} & ResNet-101 & +SOP & 66.5 & 67.5 & -\tabularnewline
LIID \cite{liu2020leveraging} & \textcolor{grey}{Res2Net-101} & +SOP & \textcolor{grey}{69.4} & \textcolor{grey}{70.4} & -\tabularnewline
\hline
URN & \textcolor{grey}{ResNet-38} &  & \textcolor{grey}{\textbf{69.4}} & \textcolor{grey}{\textbf{70.6}} & \textcolor{grey}{\textbf{40.5}}\tabularnewline
URN & ResNet-101 &  & \textbf{69.5} & \textbf{69.7} & \textbf{40.7}\tabularnewline
URN & \textcolor{grey}{ScaleNet-101} &  & \textcolor{grey}{\textbf{70.1}} & \textcolor{grey}{\textbf{70.8}} & \textcolor{grey}{\textbf{40.8}}\tabularnewline
URN & \textcolor{grey}{Res2Net-101} &  & \textcolor{grey}{\textbf{71.2}} & \textcolor{grey}{\textbf{71.5}} & \textcolor{grey}{\textbf{41.5}}\tabularnewline
\hline 
\end{tabular}
\par\end{centering}
\caption{\label{tab:results}Performance companion with state-of-the-art WSSS methods on VOC 2012 and COCO 2014. The middle part lists the methods with extra supervision. , ,  indicate supervisions of image-level tag, saliency, detection respectively. SOP is segment-based object proposals. Other extra information is about data.  indicates backbone of VGG. Results of ResNet-101 are in the color of black and others are of grey. For each backbone, the second result has an underline and the best is bold with gain in blue.}
\end{table*}


\section{Experiments}
\subsection{Datasets}
\textbf{PASCAL VOC 2012}: It is the most prevalent dataset in Weakly-supervised Semantic Segmentation, because of the moderate difficulty and quantity. To be specific, it is consisted of 20 foreground categories and one background class, divided into train set, validation set and test set at the quantities of 1464 images, 1449 images, 1456 images respectively. Besides the original data, additional images and annotations from SBD \cite{hariharan2011semantic} are used which is called trainaug set at number 10582. In WSSS, all the pixel-level annotations are converted to image-level multi-label annotations in classification phase.

\noindent \textbf{MS COCO 2012}: MS COCO is the main dataset in object detection, also some works in WSSS report their results on the version of 2012. It is a challenging dataset which provides more categories than PASCAL VOC, and it is smaller in average object size. MS COCO 14 dataset ranges from 0 to 90, among them, 80 categories are valid foreground with one background, and other 10 categories are not evaluated. The train set contains 82081 images and the number of validation set is 40137. Save to PASCAL VOC 2012, the evaluation metric is Mean intersection over union (mIoU).


\subsection{Implementation Details}
\noindent \textbf{Baseline}: We apply our method on PMM \cite{li2021pseudo}. It improves the generation and utilization of pseudo-masks based on SEAM \cite{Wang_2020_CVPR}. The backbone is ResNet-38 \cite{wu2019wider}, besides PMM uses Res2Net-101 \cite{gao2019res2net} and ScaleNet-101 \cite{li2019data} and achieve state-of-the-art results on both VOC and COCO. In this paper, we verify our methods on these three backbones and ResNet-101\cite{he2016deep}. Our settings are same to PMM. The different is that, we add our URN in this segmentation codebase. Specifically, the codebase is MMSegmentation \cite{mmseg2020}, and PMM uses PSPnet \cite{zhao2017pyramid} to get same results reported in the paper of SEAM. For VOC, the batch size is 16 on 8 GPUs at learning rate 0.005 for 20000 iterations in ploy policy. And training COCO requres 32 GPUSs at batch size 64 and learning rate 0.02. The iteration number is 40000. For the augmentation, the resized image is limited between 512 to 2048 with crop size 512512 for training. Besides, random flip and distortion are applied as transformation. The crop size of test phase is same as train phase, with dense-CRF as post-processing. For the classification part, use the original code, because we only focus on the segmentation phase. Note that, all the models are pretrained from imagenet.

\noindent \textbf{URN}: The weight mask is saved offline in PNG format to save storage space. For easily implementation, we concatenate pseudo-mask and weight mask into one image to aviod multiple ground-truths and multiple preprocessing. We split the weight mask and restore its range to 1 from 0 during rewight.
The scale factors  in Eq.(\ref{eq:scaling}) are set to \{0.15,0.2,0.25,4,5,6\} in VOC and \{0.4,0.5,0.6,2,3,4\} in COCO. The specific numbers are set by visualization without strict requirements. The minimum loss value  which divide uncertain and uncertain pixels is determined by experiment at 0.05.

\noindent \textbf{Pseudo-mask Distillation}: As the segmentation model  is not the final deploy model, which returns prediction feature map and cyclic mask. Thus, we propose a practical and effective distillation scheme based on the cyclic pseudo-mask. If we have a teacher segmentation model  whose prediction  is in high quality, we train student models via this pseudo-mask for better guidance. In this paper, we set Res2Net-101 as the teacher model in VOC, and ScaleNet-101 is the teacher model in COCO. We also analyze the gains of Pseudo-mask Distillation in Tab.\ref{tab:distill}.



\subsection{Comparison with State-of-the-Art}
We conduct experiments on PASCAL VOC 2012 and MS COCO 2014 as Tab.\ref{tab:results}. The results in the top part are all trained from image-level annotations. And the works in the middle part introduce extra models or datasets. Except \cite{Khoreva_2017_CVPR} we don't list the methods supervised by bounding box, as we focus on image-level supervision methods. We organize the results by datasets and compare our method to the previous state-of-the-arts as follows.

\noindent \textbf{PASCAL VOC 2012}: We list the results on both validation set and test set on VOC. The most used backbone is ResNet-101, so we divide these results from others by color. For ResNet-101 our URN surpass the works in 2020 more than 3\% at 69.5\% on validation set. Another prevalent backbone is ResNet-38 which is wider than ResNet-101. Our result on this backbone is 70.6\% on test set. It is higher than our baseline PMM by 1.6\% and is about 4\% higher than CONTA which iterates 3 times on both classification and segmentation. Also, it is 4.9\% higher than SEAM. For the two stronger backbones ScaleNet-101 and Res2Net-101, we achieve 70.1\% and 71.2\% respectively.

\noindent \textbf{MS COCO 2014}: Compare to VOC, COCO is more challenging. There are 4 times categories and the training images are 8 times more, also the object size is smaller than VOC. Due to these difficulties, a few of works report the results on it, and there are results from validation set only before. For ResNet-38, SEAM's result is 31.7\% and PMM is at 36.7\%, while our URN achieve SOTA at 40.5\%. As well as other backbones, our results are higher than 40.5\%, among them the best mIoU is 41.5\%.

\noindent \textbf{Comparison with Methods with Extra Information}: In the middle part of Tab.\ref{tab:results}, we list some latest methods based on saliency, object proposals or extra datasets. We can see that these works are higher than the methods without extra information in average. But our results still beyond them at every dataset and backbone. Especially, URN is 7.1\% higher than SGAN on ResNet-101 on COCO, which demonstrates the strong effectiveness of our method.


\subsection{Ablation Studies}
\textbf{Effectiveness of URN}:
To verify the effectiveness of our method, we set experiments based on our baseline PMM which is the current state-of-the-art. We want to show that, our method works well even on a high baseline. The evaluated dataset is PASCAL VOC 2012 on the validation set with the metric of mIoU. We compare the results between baseline and ours on four backbones in Tab.\ref{tab:baseline}. It shows that our method achieves significant improvements on the all backbones. We push the previous state-of-the-art to 71.2\% from 70.0\%, and the gains on ResNet-101, ResNet-38 are 1.4\% and 0.9\% respectively. Among them, ScaleNet-101 raise most with a growth of 2.9\%. These results suggest that our method is effective and it works well on varied backbones.

\begin{table}[ht]
\begin{centering}
\setlength\tabcolsep{15pt}
\begin{tabular}{ccc}
\hline 
Backbone  & Baseline  & Ours\tabularnewline
\hline 
\hline 
ResNet-38  & 68.5  & 69.4\tabularnewline
ResNet-101  & 68.1  & 69.5\tabularnewline
ScaleNet-101  & 67.2  & 70.1\tabularnewline
Res2Net-101  & 70.0  & 71.2\tabularnewline
\hline 
\end{tabular}
\par\end{centering}
\caption{\label{tab:baseline}Comparison with baselines on PASCAL VOC 2O12 validation set.}
\end{table}

\noindent \textbf{Weight Threshould}: There is an important hyper paramter in URN which controls the intensity of reweight. To select the optimal value of  in Eq.(\ref{eq:end}), we search it via experiments as shown in Tab.\ref{tab:thresh}. The backbone is Res2Net on PASCAL VOC 2012 validation set. If  is set to 1, the weights are same to original weights, and 0 means droping all the uncertain pixels. It suggets that the pixels under uncertain area are useful, thus it is not wise to drop all of them. 0.05 is the optimal value, it means the weights of certain pixels is 20 times than the uncertain pixels, and it works best.
\begin{table}[htb]
\begin{centering}
\setlength\tabcolsep{15pt}
\begin{tabular}{cc}
\hline
  & mIoU\tabularnewline
\hline
\hline
1  & 70.0\tabularnewline
0.5  & 70.3\tabularnewline
0.1  & 70.8\tabularnewline
0.05  & \textbf{71.2}\tabularnewline
0  & 70.2\tabularnewline
\hline
\end{tabular}
\par\end{centering}
\caption{\label{tab:baseline}Selection of threshold  in Eq.(\ref{eq:end}).}
\label{tab:thresh}
\end{table}

\noindent \textbf{Pseudo-mask Distillation}:
Distillation is a widely used technique. In this paper we apply the mechanism by a very simple but practical way. We select the pseudo-masks whose quality are best as teacher and train other student models via them. Since student models are the deployed models, and they are able to learn the knowledge from teacher masks without increasing inference time. We verify the gains of Pseudo-mask Distillation in Tab. \ref{tab:distill}. We can see that the ScaleNet-101 and Res2Net-101 both raise 1.2\% after applying URN without PD, and ScaleNet-101 raises 1.8\% from Pseudo-mask Distillation. Note that Res2Net is the teacher in VOC, thus there is no result with PD. 
\begin{table}[t]
\begin{centering}
\setlength\tabcolsep{10pt}
\begin{tabular}{cccc}
\hline 
Backbone  & Basline & without PD  & with PD\tabularnewline
\hline 
\hline 
ScaleNet-101  & 67.1  & 68.3 & 70.1\tabularnewline
Res2Net-101  & 70.0  & 71.2 & -\tabularnewline
\hline 
\end{tabular}
\par\end{centering}
\caption{\label{tab:distill}Results of Pseudo-mask Distillation (PD). Note: Res2Net is the teacher model without PD.}
\end{table}

\noindent \textbf{Probability vs. Uncertainty}: As the uncertainty estimation replies on the prediction of segmentation, and some reweight methods use probability as metric in tasks like classification. We try to use the probability as loss weight for comparison. Specifically, we detach the prediction feature map and apply softmax to make the probability as loss weight. As shown in Tab.\ref{tab:prob}, in the same settings, the mIoU on VOC validation is 70.5\%, while our URN is 71.2\%. So probability has positive correlation to noise, but URN works better. Because in WSSS there are many false pixels with high probability.
\begin{table}[t]
\begin{centering}
\begin{tabular}{ccc}
\hline 
Method  & Backbone & VOC val\tabularnewline
\hline 
\hline 
Probability & Res2Net-101 & 70.5\tabularnewline
URN & Res2Net-101  & 71.2\tabularnewline
\hline 
\end{tabular}
\par\end{centering}
\caption{\label{tab:prob}Comparison of two reweight schemes.}
\end{table}

\subsection{Visual Comparison}
To verifies the effectiveness of our methods, we compare our results with SEAM and PMM on VOC12 validation set in Fig.\ref{fig:voc_vis}, and the visualizations of COCO are shown in Fig.\ref{fig:coco_vis}. In these two figures, we can see that our method performs better than these two baselines.

\begin{figure}[h!]
\begin{centering}
\includegraphics[width=2cm,height=1.7cm]{pic/voc_comp/gt/2007_000837_0.jpg} \includegraphics[width=2cm,height=1.7cm]{pic/voc_comp/seam/2007_000837_0.jpg} \includegraphics[width=2cm,height=1.7cm]{pic/voc_comp/pmm/2007_000837_0.jpg} \includegraphics[width=2cm,height=1.7cm]{pic/voc_comp/urn/2007_000837_0.jpg}

\includegraphics[width=2cm,height=1.7cm]{pic/voc_comp/gt/2008_001439_0.jpg} \includegraphics[width=2cm,height=1.7cm]{pic/voc_comp/seam/2008_001439_0.jpg} \includegraphics[width=2cm,height=1.7cm]{pic/voc_comp/pmm/2008_001439_0.jpg} \includegraphics[width=2cm,height=1.7cm]{pic/voc_comp/urn/2008_001439_0.jpg}

\includegraphics[width=2cm,height=1.7cm]{pic/voc_comp/gt/2010_004382_0.jpg} \includegraphics[width=2cm,height=1.7cm]{pic/voc_comp/seam/2010_004382_0.jpg} \includegraphics[width=2cm,height=1.7cm]{pic/voc_comp/pmm/2010_004382_0.jpg} \includegraphics[width=2cm,height=1.7cm]{pic/voc_comp/urn/2010_004382_0.jpg}
  
\includegraphics[width=2cm,height=1.7cm]{pic/voc_comp/gt/2007_002268_0.jpg} \includegraphics[width=2cm,height=1.7cm]{pic/voc_comp/seam/2007_002268_0.jpg} \includegraphics[width=2cm,height=1.7cm]{pic/voc_comp/pmm/2007_002268_0.jpg} \includegraphics[width=2cm,height=1.7cm]{pic/voc_comp/urn/2007_002268_0.jpg}
\hspace*{0.25cm}GT\hspace*{1.2cm}SEAM\hspace*{1.2cm}PMM\hspace*{1.2cm}URN
\par\end{centering}
\begin{centering}
\caption{Visual comparison on PASCAL VOC 2012 validation set.}
\label{fig:voc_vis} 
\par\end{centering}
\centering{} 
\end{figure}

\begin{figure}[h!]
\begin{centering}
\includegraphics[width=2cm,height=1.7cm]{pic/coco_comp/gt/000000576939_0.jpg} \includegraphics[width=2cm,height=1.7cm]{pic/coco_comp/seam/000000576939_0.jpg} \includegraphics[width=2cm,height=1.7cm]{pic/coco_comp/pmm/000000576939_0.jpg}
\includegraphics[width=2cm,height=1.7cm]{pic/coco_comp/urn/000000576939_0.jpg}

\includegraphics[width=2cm,height=1.7cm]{pic/coco_comp/gt/000000545293_0.jpg} \includegraphics[width=2cm,height=1.7cm]{pic/coco_comp/seam/000000545293_0.jpg} \includegraphics[width=2cm,height=1.7cm]{pic/coco_comp/pmm/000000545293_0.jpg}
\includegraphics[width=2cm,height=1.7cm]{pic/coco_comp/urn/000000545293_0.jpg}

\includegraphics[width=2cm,height=1.7cm]{pic/coco_comp/gt/000000516750_0.jpg} \includegraphics[width=2cm,height=1.7cm]{pic/coco_comp/seam/000000516750_0.jpg} \includegraphics[width=2cm,height=1.7cm]{pic/coco_comp/pmm/000000516750_0.jpg}
\includegraphics[width=2cm,height=1.7cm]{pic/coco_comp/urn/000000516750_0.jpg}

\includegraphics[width=2cm,height=1.7cm]{pic/coco_comp/gt/000000173350_0.jpg} \includegraphics[width=2cm,height=1.7cm]{pic/coco_comp/seam/000000173350_0.jpg} \includegraphics[width=2cm,height=1.7cm]{pic/coco_comp/pmm/000000173350_0.jpg}
\includegraphics[width=2cm,height=1.7cm]{pic/coco_comp/urn/000000173350_0.jpg}

\includegraphics[width=2cm,height=1.7cm]{pic/coco_comp/gt/000000132001_0.jpg} \includegraphics[width=2cm,height=1.7cm]{pic/coco_comp/seam/000000132001_0.jpg} \includegraphics[width=2cm,height=1.7cm]{pic/coco_comp/pmm/000000132001_0.jpg}
\includegraphics[width=2cm,height=1.7cm]{pic/coco_comp/urn/000000132001_0.jpg}
\hspace*{0.25cm}GT\hspace*{1.2cm}SEAM\hspace*{1.2cm}PMM\hspace*{1.2cm}URN
\par\end{centering}
\begin{centering}
\caption{Visual comparison on MS COCO 2014 validation set.}
\label{fig:coco_vis} 
\par\end{centering}
\centering{} 
\vspace{-4mm}
\end{figure}

\section{Conclusion}


In summary, the noise is closely connected with the response scale, and we estimate the uncertainty by response scaling to simulate the various response scale. Then we mitigate the noise in segmentation optimization with the uncertainty from scaling. Besides, we later propose Pseudo-mask Distillation for the weaker backbones in implementation. Experimentally, we verify the improvements in obligation studies and compare our results to the previous state-of-the-art methods, which demonstrates the effectiveness of our method.
