\documentclass{article}

\PassOptionsToPackage{numbers, compress}{natbib}






\usepackage[final]{neurips_2020}



\usepackage[utf8]{inputenc} \usepackage[T1]{fontenc}    \usepackage{hyperref}       \usepackage{url}            \usepackage{booktabs}       \usepackage{amsfonts}       \usepackage{nicefrac}       \usepackage{microtype}      \usepackage{graphicx}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{wrapfig}
\usepackage{pifont}
\usepackage{float}
\usepackage{tabularx}
\newcommand{\ie}{\textit{i.e.}}
\newcommand{\eg}{\textit{e.g.}}
\newcommand{\etal}{\textit{et al.}}
\newcommand{\st}{\textit{s.t. }}
\newcommand{\etc}{\textit{etc.}}
\newcommand{\wrt}{\textit{w.r.t. }}
\newcommand{\aka}{\textit{a.k.a. }}
\newcommand{\cf}{\textit{cf. }}
\newtheorem{theorem}{Assumption}
\DeclareMathOperator*{\argmax}{arg\,max}

\title{Long-Tailed Classification
by Keeping the Good and Removing the Bad Momentum Causal Effect}



\author{Kaihua Tang\textsuperscript{1}, \quad Jianqiang Huang\textsuperscript{1,2}, \quad Hanwang Zhang\textsuperscript{1}\\
{\small \textsuperscript{1}Nanyang Technological University,\quad \textsuperscript{2}Damo Academy, Alibaba Group}\\
{\tt\small kaihua001@e.ntu.edu.sg, \quad jianqiang.jqh@gmail.com,\quad hanwangzhang@ntu.edu.sg}\\
}

\begin{document}
\maketitle



\begin{abstract}
As the class size grows, maintaining a balanced dataset across many classes is challenging because the data are long-tailed in nature; it is even impossible when the sample-of-interest co-exists with each other in one collectable unit, \eg, multiple visual instances in one image. Therefore, long-tailed classification is the key to deep learning at scale. However, existing methods are mainly based on re-weighting/re-sampling heuristics that lack a fundamental theory. In this paper, we establish a causal inference framework, which not only unravels the whys of previous methods, but also derives a new principled solution. Specifically, our theory shows that the SGD momentum is essentially a confounder in long-tailed classification. On one hand, it has a harmful causal effect that misleads the tail prediction biased towards the head. On the other hand, its induced mediation also benefits the representation learning and head prediction. Our framework elegantly disentangles the paradoxical effects of the momentum, by pursuing the direct causal effect caused by an input sample. In particular, we use causal intervention in training, and counterfactual reasoning in inference, to remove the ``bad'' while keep the ``good''. We achieve new state-of-the-arts on three long-tailed visual recognition benchmarks\footnote{Our code is available on \url{https://github.com/KaihuaTang/Long-Tailed-Recognition.pytorch}}: Long-tailed CIFAR-10/-100, ImageNet-LT for image classification and LVIS for instance segmentation.
\end{abstract}



\section{Introduction}
Over the years, we have witnessed the fast development of computer vision techniques~\cite{he2016deep, xie2017aggregated, ren2015faster}, stemming from large and balanced datasets such as ImageNet~\cite{russakovsky2015imagenet} and MS-COCO~\cite{lin2014microsoft}. Along with the growth of the digital data created by us, the crux of making a large-scale dataset is no longer about where to collect, but how to balance. However, the cost of expanding them to a larger class vocabulary with balanced data is not linear --- but exponential --- as the data will be inevitably long-tailed by Zipf's law~\cite{reed2001pareto}. Specifically, a single sample increased for one data-poor tail class will result in more samples from the data-rich head. Sometimes, even worse, re-balancing the class is impossible. For example, in instance segmentation~\cite{gupta2019lvis}, if we target at increasing the images of tail class instances like ``remote controller'', we have to bring in more head instances like ``sofa'' and ``TV'' simultaneously in every newly added image~\cite{wu2020distribution}.


Therefore, long-tailed classification is indispensable for training deep models at scale. Recent work~\cite{liu2019large, zhou2019bbn, kang2019decoupling} starts to fill in the performance gap between class-balanced and long-tailed datasets, while new long-tailed benchmarks are springing up such as Long-tailed CIFAR-10/-100~\cite{cao2019learning, zhou2019bbn}, ImageNet-LT~\cite{liu2019large} for image classification and LVIS~\cite{gupta2019lvis} for object detection and instance segmentation. Despite the vigorous development of this field, we find that the fundamental theory is still missing. We conjecture that it is mainly due to the paradoxical effects of long tail. On one hand, it is bad because the classification is severely biased towards the data-rich head. On the other hand, it is good because the long-tailed distribution essentially encodes the natural inter-dependencies of classes --- ``TV'' is indeed a good context for ``controller'' --- any disrespect of it will hurt the feature representation learning~\cite{zhou2019bbn}, \eg, re-weighting~\cite{cui2019class, khan2017cost} or re-sampling~\cite{shen2016relay, mahajan2018exploring} inevitably causes under-fitting to the head or over-fitting to the tail. 

Inspired by the above paradox, latest studies~\cite{zhou2019bbn, kang2019decoupling} show promising results in disentangling the ``good'' from the ``bad'', by the na\"ive two-stage separation of \emph{imbalanced} feature learning and \emph{balanced} classifier training.  However, such disentanglement does not explain the whys and wherefores of the paradox, leaving critical questions unanswered: given that the re-balancing causes under-fitting/over-fitting, why is the re-balanced classifier good but the re-balanced feature learning bad? The two-stage design clearly defies the end-to-end merit that we used to believe since the deep learning era; but why does the two-stage training significantly outperform the end-to-end one in long-tailed classification?

In this paper, we propose a causal framework that not only fundamentally explains the previous methods~\cite{shen2016relay, mahajan2018exploring, tan2020equalization, liu2019large, kang2019decoupling, zhou2019bbn}, but also provides a principled solution to further improve long-tailed classification. The proposed causal graph of this framework is given in Figure~\ref{fig:1}~(a). We find that the momentum  in any SGD optimizer~\cite{sutskever2013importance, qian1999momentum} (also called betas in Adam optimizer~\cite{kingma2014adam}), which is indispensable for stabilizing gradients, is a confounder who is the common cause of the sample feature  (via ) and the classification logits  (via ).  In particular,  denotes the 's projection on the head feature direction that eventually deviates . We will justify the graph later in Section~\ref{sec:causal_graph}. Here, Figure~\ref{fig:1}~(b\&c) sheds some light on how the momentum affects the feature  and the prediction . From the causal graph, we may revisit the ``bad'' long-tailed bias in a causal view: the backdoor~\cite{pearl1995causal} path  causes the spurious correlation even if  has nothing to do with the predicted , \eg, misclassifying a tail sample to the head. Also, the mediation~\cite{pearl2001direct} path  mixes up the pure contribution made by . For the ``good'' bias,  respects the inter-relationships of the semantic concepts in classification, that is, the head class knowledge contributes a reliable evidence to filter out wrong predictions. For example, if a rare sample is closer to the head class ``TV'' and ``sofa'', it is more likely to be a living room object (\eg, ``remote controller'') but not an outdoor one (\eg, ``car'').

Based on the graph that explains the paradox of the ``bad'' and ``good'', we propose a principled solution for long-tailed classification. It is a natural derivation of pursuing the direct causal effect along  by removing the momentum effect. Thanks to causal inference~\cite{pearl2016causal}, we can elegantly keep the ``good'' while remove the ``bad''. First, to learn the model parameters, we apply de-confounded training with  causal intervention: while it removes the ``bad'' by \emph{backdoor adjustment}~\cite{pearl1995causal} who cuts off the backdoor confounding path , it keeps the ``good'' by retaining the mediation . Second, we calculate the direct causal effect of  as the final prediction logits. It disentangles the ``good'' from the ``bad'' in a \emph{counterfactual} world, where the bad effect is considered as the 's indirect effect when  is zero but  retains the value when . In contrast to the prevailing two-stage design~\cite{kang2019decoupling} that requires unbiased re-training in the 2nd stage, our solution is one-stage and re-training free. Interestingly, as discussed in Section~\ref{subsec: revisiting}, we show that why the re-training is inevitable in their method and why ours can avoid it with even better performance.

\begin{figure}[t]
   \includegraphics[width=\linewidth]{img/fig1.pdf}
   \caption{(a) The proposed causal graph explaining the causal effect of momentum. See Section~\ref{sec:causal_graph} for details. (b) The mean magnitudes of feature vectors for each class  after training with momentum , where  is ranking from head to tail.  (c) The relative change of the performance on the basis of  shows that the few-shot tail is more vulnerable to the momentum.}
   \label{fig:1} \vspace{-5mm}
\end{figure}

On image classification benchmarks Long-tailed CIFAR-10/-100~\cite{cao2019learning, zhou2019bbn} and ImageNet-LT~\cite{liu2019large}, we outperform previous state-of-the-arts~\cite{zhou2019bbn, kang2019decoupling} on all splits and settings, showing that the performance gain is not merely from catering to the long tail or a specific imbalanced distribution. In object detection and instance segmentation benchmark LVIS~\cite{gupta2019lvis}, our method also has a significant advantage over the former winner~\cite{tan2020equalization} of LVIS 2019 challenge. We achieve 3.5\% and 3.1\% absolute improvements on mask AP and box AP using the same Cascade Mask R-CNN with R101-FPN backbone~\cite{cai2018cascade}.




















\section{Related Work}

\textbf{Re-Balanced Training.} The most widely-used solution for long-tailed classification is arguably to re-balance the contribution of each class in the training phase. It can be either achieved by re-sampling~\cite{chawla2002smote, drummond2003c4, shen2016relay, mahajan2018exploring, hu2020learning} or re-weighting~\cite{cui2019class, khan2017cost, cao2019learning, tan2020equalization}. However, they inevitably cause the under-fitting/over-fitting problem to head/tail classes. Besides, relying on the accessibility of data distribution also limits their application scope, \eg, not applicable in online and streaming data.

\textbf{Hard Example Mining.} The instance-level re-weighting~\cite{lin2017focal, shu2019meta, ren2018learning} is also a practical solution. Instead of hacking the prior distribution of classes, focusing on the hard samples also alleviates the long-tailed issue, \eg, using meta-learning to find the conditional weights for each samples~\cite{jamal2020rethinking}, enhancing the samples of hard categories by group softmax~\cite{li2020overcoming}.

\textbf{Transfer Learning/Two-Stage Approach.} Recent work shows a new trend of addressing the long-tailed problem by transferring the knowledge from head to tail. The sharing bilateral-branch network~\cite{zhou2019bbn}, the two-stage training~\cite{kang2019decoupling}, the dynamic curriculum learning~\cite{wang2019dynamic} and the transferring memory features~\cite{liu2019large} / head distributions~\cite{liu2020deep} are all shown to be effective in long-tailed recognition, yet, they either significantly increase the parameters or require a complicated training strategy.

\textbf{Causal Inference.} Causal inference~\cite{pearl2016causal, Judea2018thebookofwhy} has been widely adopted in psychology, politics and epidemiology for years~\cite{mackinnon2007mediation, keele2015statistics, richiardi2013mediation}. It doesn't just serve as an interpretation framework, but also provides solutions to achieve the desired objectives by pursing causal effect. Recently, causal inference has also attracted increasing attention in computer vision society~\cite{tang2020unbiased, qi2019two, niu2020counterfactual, yang2020deconfounded, zhang2020causal, yue2020interventional} for removing the dataset bias in domain-specific applications, \eg, using pure direct effect to capture the spurious bias in VQA~\cite{niu2020counterfactual} and NWGM for Captioning~\cite{yang2020deconfounded}. Compared to them, our method offers a fundamental framework for general long-tailed visual recognition.





\section{A Causal View on Momentum Effect}
\label{sec:causal_graph}
To systematically study the long-tailed classification and how momentum affects the prediction, we construct a \textbf{causal graph}~\cite{pearl2016causal,pearl2001direct} in Figure~\ref{fig:1}~(a) with four variables: momentum (, object feature (, projection on head direction (, and model prediction (. The causal graph is a directed acyclic graph used to indicate how variables of interest  interacting with each other through causal links. The nodes  and  constitute a confounder and a mediator, respectively. A \emph{confounder} is a variable that influences both correlated and independent variables, creating a spurious statistical correlation. Considering a causal graph , the elder people spend more time on physical exercise after retirement and they are also easier to get cancer due to the elder age, so the confounder  creates a spurious correlation that more physical exercise will increase the chance of getting cancer. The example of a \emph{mediator} would be , where mediator  is the side effect of taking   that prevents us from getting the direct effect of .

Before we delve into the rationale of our causal graph, let's take a brief review on the SGD with momentum~\cite{qian1999momentum}. Without loss of generality, we adopt the Pytorch implementation~\cite{pytorchSGD}: 

where the notations in the -th iteration are: model parameters , gradient , velocity , momentum decay ratio , and learning rate . Other versions of SGD~\cite{sutskever2013importance, qian1999momentum} only change the position of some hyper-parameters and we can easily prove them equivalent with each other. The use of momentum considerably dampens the oscillations caused by each single sample. In our causal graph, momentum  is the overall effect of  at the convergence , which is the exponential moving average of the gradient over all past samples with decay rate . Eq.~\eqref{equ:1} shows that, given fixed hyper-parameters  and , each sample  is a function of the model initialization and the mini-batch sampling strategy, that is,  has infinite samples. 

In a balanced dataset, the momentum is equally contributed by every class. However, when the dataset is long-tailed, it will be dominated by the head samples, emerging the following causal links:

\begin{wrapfigure}{r}{8cm}
\includegraphics[width=8cm]{img/fig2.pdf}
\vspace{-3mm}
\caption{Based on Assumption 1, the feature vector  can be decomposed into a discriminative feature  and a projection on head direction }
\label{fig:2}
\vspace{-5mm}
\end{wrapfigure}
 This link says that the backbone parameters used to generate feature vectors , are trained under the effect of . This is obvious from Eq.~\eqref{equ:1} and can be illustrated in Figure~\ref{fig:1}~(b), where we visualize how the magnitudes of  change from head to tail. 


 This link denotes that the momentum also causes feature vector  deviates to the head direction , which is also determined by . In a long-tailed dataset, few head classes possess most of the training samples, who have less variance than the data-poor but class-rich tail, so the moving averaged momentum will thus point to a stable head direction. Specifically, as shown in Figure~\ref{fig:2}, we can decompose any feature vector  into , where . In particular, the head direction  is given in Assumption 1, whose validity is detailed in Appendix A.
\begin{theorem}
The head direction  is the unit vector of the exponential moving average features with decay rate  like momentum, \ie, , where  and  is the number of the total training iterations.
\label{assp:1}
\end{theorem}
Note that Assumption 1 says that the head direction is exactly determined by the sample moving average  in the dataset, which does not need the accessibility of the class statistics at all. In particular, as we show in Appendix A, when the dataset is balanced, Assumption 1 also holds but suggests that  is naturally not affected by . 


 These links indicate that the effect of  can be disentangled into an indirect (mediation) and a direct effect. Thanks to the above orthogonal decomposition: , the indirect effect is affected by  while the direct effect is affected by , and they together determine the total effect. As shown in Figure~\ref{fig:3}, when we change the scale parameter  of , the performance of the tail classes monotonically increases with , which inspires us to remove the mediation effect of  in Section~\ref{subsec:total_direct_effect}.














\section{The Proposed Solution}
\label{sec:proposed_method}
Based on the proposed causal graph in Figure~\ref{fig:1} (a), we can delineate our goal for long-tailed classification:  the pursuit of the direct causal effect along . In causal inference, it is defined as Total Direct Effect (TDE)~\cite{vanderweele2013three, pearl2001direct}:



\begin{wrapfigure}{r}{6cm}
\includegraphics[width=6cm]{img/fig4.pdf}
\vspace{-3mm}
\caption{The TDE inference (Eq.~\eqref{equ:0.2}) for the long-tailed classification after de-confounded training. Subtracted left: , minus right: .}
\label{fig:4}
\vspace{-5mm}
\end{wrapfigure}
where  denotes a null input (0 in this paper). We define the causal effect as the prediction logits  for the -th class. Subscript  denotes that the mediator  always takes the value  in the \emph{deconfounded} causal graph model of Figure~\ref{fig:1} (a) with , where the -operator denotes the causal intervention~\cite{pearl2016causal} that modifies the graph by . Thus, Eq.~\eqref{equ:0.2} shows an important principle in long-tailed classification: before we calculate the final TDE (Section~\ref{subsec:total_direct_effect}), we need to first perform de-confounded training (Section~\ref{subsec: deconfound}) to estimate the ``modified'' causal graph parameters.

We'd like to highlight that Eq.~\eqref{equ:0.2} removes the ``bad'' while keeps the ``good'' in a reconcilable way. First, in training, the -operator removes the ``bad'' confounder bias while keeps the ``good'' mediator bias, because the -operator retains the mediation path. Second, in inference, the mediator value  is imposed in both terms to keep the ``good'' of the mediator bias (towards head) in logit prediction; it also removes its ``bad'' by subtracting the second term: the prediction when the input  is null () but the mediator  is still the value  when  had been . Note that such a \emph{counterfactual} minus elegantly characterizes the ``bad'' mediation bias, just like how we capture the tricky placebo effect: we cheat the patient to take a placebo drug, setting the direct drug effect  to zero; thus, any cure observed must be purely due to the non-zero placebo effect .


\subsection{De-confounded Training}
\label{subsec: deconfound}
The model for the proposed causal graph is optimized under the causal intervention , which aims to preserve the ``good'' feature learning from the momentum and cut off its ``bad'' confounding effect. We apply the backdoor adjustment~\cite{pearl1995causal} to derive the de-confounded model:

As there are infinite number of , it is prohibitively to achieve the above backdoor adjustment. Fortunately, the Inverse Probability Weighting~\cite{pearl2016causal} formulation in Eq.~\eqref{equ:2.2} provides us a new perspective in approximating the infinite sampling . For a finite dataset, no matter how many  there are, we can only observe one  given one . In such cases, the number of  values that Eq.~\eqref{equ:2.2} would encounter is equal to the number of samples  available, not to the number of possible  values, which is prohibitive. In fact, thanks to the backdoor adjustment, which connects the equivalence between the originally confounded model  and the deconfounded model  with , we can collect samples from the former, that act as though they were drawn from the latter. Therefore, Eq.~\eqref{equ:2.2} can be approximated as

where  is the inverse weighted probability and we will drop  in the rest of the paper for notation simplicity and bear in mind that  still depends on . In particular, compared to the vanilla trick, we apply a multi-head strategy~\cite{vaswani2017attention} to equally divide the channel (or dimensions) of weights and features into  groups, which can be considered as  times more fine-grained sampling. 

We model  in Eq.~\eqref{equ:2.3} as the softmax activated probability of the energy-based model~\cite{lecun2006tutorial}:

where  is a positive scaling factor akin to the inverse temperature in Gibbs distribution. Recall Assumption 1 that . The numerator, \ie, the unnormalized effect, can be implemented as logits , and the denominator is a normalization term (or propensity score~\cite{austin2011introduction}) that only balances the magnitude of the variables:  , where the first term is a class-specific energy and the second term is a class-agnostic baseline energy.

Putting the above all together, the logit calculation for  can be formulated as:

Interestingly, this model also explains the effectiveness of normalized classifiers like cosine classifier~\cite{gidaris2018dynamic, qi2018low}. We will further discuss it in Section~\ref{subsec: revisiting}.


\subsection{Total Direct Effect Inference}
\label{subsec:total_direct_effect}

After the de-confounded training, the causal graph is now ready for inference. The TDE of  in Eq.~\eqref{equ:0.2} can thus be depicted as in Figure~\ref{fig:4}. By applying the counterfactual consistency rule~\cite{pearl2010consistency}, we have . This indicates that we can use Eq.~\eqref{equ:3} to calculate the first term of Eq.~\eqref{equ:0.2}. Thanks to Assumption 1, we can disentangle  by , where . Therefore, we have 
 that replaces the  in Eq.~\eqref{equ:3} with zero vector, just like ``cheating'' the model with a null input but keeping everything else unchanged.  Overall, the final TDE calculation for Eq.~\eqref{equ:0.2} is

where  controls the trade-off between the indirect and direct effect as shown in Figure~\ref{fig:3}.


\begin{table}
\centering
\scalebox{0.9}
{
\begin{tabular}{c |c |c |c |c }
\hline
\hline
Methods & Two-stage & Re-balancing ( & De-confound ( & Direct Effect \\ 
\hline
Cosine~\cite{gidaris2018dynamic, qi2018low} & - & - & \ding{52} & - \\
LDAM~\cite{cao2019learning} & - & \ding{52} & \ding{52} & CDE \\
OLTR~\cite{liu2019large} & \ding{52} & \ding{52} & - & NDE            \\
BBN~\cite{zhou2019bbn} & \ding{52} & \ding{52} & - & NDE              \\
Decouple~\cite{kang2019decoupling} & \ding{52} & \ding{52} & - & NDE \\
EQL~\cite{tan2020equalization} & - & \ding{52} & - & - \\
\hline
Our method & - & - & \ding{52} & TDE \\
\hline
\hline
\end{tabular}
}
\caption{Revisiting the previous state-of-the-arts in our causal graph. CDE: Controlled Direct Effect. NDE: Natural Direct Effect. TDE: Total Direct Effect.}
\label{tab:1}
\vspace{-5mm}
\end{table}

\subsection{Background-Exempted Inference}
\label{subsec: bgfixtde}
\begin{wrapfigure}{r}{6cm}
   \includegraphics[width=\linewidth]{img/fig3.pdf}
   \vspace{-3mm}
   \caption{The influence of parameter  in Eq.~\eqref{equ:4} on ImageNet-LT val set~\cite{liu2019large} shows how  controls the head/tail preference.}
   \label{fig:3} \vspace{-5mm}
\end{wrapfigure}
Some classification tasks need a special ``background'' class to filter out samples belonging to none of the classes of interest, \eg, object detection and instance segmentation use the background class to remove non-object regions~\cite{ren2015faster, cai2018cascade}, and recommender systems assume that the majority of the items are irrelevant to a user~\cite{rendle2012bpr}. In such tasks, most of the training samples are background and hence the background class is a good head class, whose effect should be kept and thus exempted from the TDE calculation. To this end, we propose a \emph{background-exempted} inference that particular uses the original inference (total effect) for background class. The inference can be formulated as:

where  is the background class,  is the de-confounded probability that we defined in Section~\ref{subsec: deconfound},  is the softmax activated probability of the original  in Eq.~\eqref{equ:4}. Note that Eq.~\eqref{sp-equ:2} adds up to 1 from  to .


\subsection{Revisiting Two-stage Training}
\label{subsec: revisiting}
The proposed framework also theoretically explains the previous state-of-the-arts as shown in Table~\ref{tab:1}. Please see Appendix B for the detailed revisit for each method.


\textbf{Two-stage Re-balancing.}  Na\"ive re-balanced training fails to retain a natural mediation  that respects the inter-dependencies among classes. Therefore, the two-stage training is adopted by most of the re-balancing methods: imbalanced pre-training the backbone with natural  and then balanced re-training a fair classifier with the fixed backbone for feature representation. Later, we will show that the second stage re-balancing essentially plays a counterfactual role, which reveals the reason why the stage-2 is indispensable.


\textbf{De-confounded Training.} Technically, the proposed de-confounded training in Eq.~\eqref{equ:3} is the multi-head classifier with normalization. The normalized classifier, like cosine classifier, has already been embraced by various methods~\cite{gidaris2018dynamic, qi2018low, liu2019large, kang2019decoupling} based on empirical practice. However, as we will show in Table~\ref{tab:2}, without the guidance of our causal graph, their normalizations perform worse than the proposed de-confounded model. For example, methods like decouple~\cite{kang2019decoupling} only applies normalization in the 2nd stage balanced classifier training, and hence its feature learning is not de-confounded.

\textbf{Direct Effect.} The one-stage re-weighting/re-sampling training methods, like LDAM~\cite{cao2019learning}, can be interpreted as calculating Controlled Direct Effect (CDE)~\cite{pearl2016causal}: , where  is a dummy vector and  is a constant vector. CDE performs a physical intervention --- re-balancing --- on the training data by setting the bias  to a constant. Note that the second term of CDE is a constant that does not affect the classification. However, CDE removes the ``bad'' at the cost of hurting the ``good'' during representation learning, as  is no longer a natural mediation generated by .

\begin{table}
\centering
\scalebox{0.9}
{
\begin{tabular}{c |c |c |c |c }
\hline
\hline
Methods & Many-shot & Medium-shot & Few-shot & Overall \\ 
\hline 
Focal Loss~\cite{lin2017focal} & 64.3 & 37.1 & 8.2 & 43.7 \\
OLTR~\cite{liu2019large} & 51.0 & 40.8 & 20.8 & 41.9       \\
Decouple-OLTR~\cite{liu2019large, kang2019decoupling} & 59.9 & 45.8 & 27.6 & 48.7       \\
Decouple-Joint~\cite{kang2019decoupling} & 65.9 & 37.5 & 7.7 & 44.4 \\
Decouple-NCM~\cite{kang2019decoupling} & 56.6 & 45.3 & 28.1 & 47.3 \\
Decouple-cRT~\cite{kang2019decoupling} & 61.8 & 46.2 & 27.4 & 49.6 \\
Decouple--norm~\cite{kang2019decoupling} & 59.1 & 46.9 & 30.7 & 49.4\\
Decouple-LWS~\cite{kang2019decoupling} & 60.2 & 47.2 & 30.3 & 49.9\\
\hline
Baseline & 66.1 & 38.4 & 8.9 & 45.0 \\
Cosine~\cite{gidaris2018dynamic, qi2018low}   & 67.3 & 41.3 & 14.0 & 47.6 \\
Capsule~\cite{liu2019large, sabour2017dynamic} & 67.1 & 40.0 & 11.2 & 46.5 \\
(Ours) De-confound & \textbf{67.9} & 42.7 & 14.7 & 48.6 \\
(Ours) Cosine-TDE & 61.8 & 47.1 & 30.4 & 50.5 \\
(Ours) Capsule-TDE & 62.3 & 46.9 & 30.6 & 50.6 \\
(Ours) De-confound-TDE & 62.7 & \textbf{48.8} & \textbf{31.6} & \textbf{51.8} \\
\hline
\hline
\end{tabular}
}
\caption{The performances on ImageNet-LT test set~\cite{liu2019large}. All models were using the ResNeXt-50 backbone. The superscript  denotes being re-implemented by our framework and hyper-parameters. }
\label{tab:2}
\vspace{-5mm}
\end{table}


The two-stage methods~\cite{zhou2019bbn, kang2019decoupling} are essentially Natural Direct Effect (NDE), where the stage-2 re-balanced training is actually an intervention on  that forces the direction  do not head to any class. Therefore, when attached with the stage-1 imbalanced pre-trained features, the balanced classifier calculates the NDE:  , where  and  are dummy vectors, because the stage-2 balanced classifier forces the logits to nullify any class-specific momentum direction;  as stage-1 backbone is frozen and ; the second term can be omitted as it is a class-agnostic constant. Besides that their stage-1 training is still confounded, as we will show in experiments, our TDE is better than NDE because the latter completely removes the entire effect of  by setting , which is however sometimes good, \eg, mis-classifying ``warthog'' as the head-class ``pig'' is better than ``car''; TDE admits the effect by keeping  as a baseline and further compares the fine-grained difference via the direct effect, \eg, by admitting that ``warthog'' does look like ``pig'', TDE finds out that the tusk is the key difference between ``warthog'' and ``pig'', and that is why our method can focus on more discriminative regions in Figure~\ref{fig:5}.























\section{Experiments}
\label{sec:experiments}
The proposed method was evaluated on three long-tailed benchmarks: Long-tailed CIFAR-10/-100, ImageNet-LT for image classification and LVIS for object detection and instance segmentation. The consistent improvements across different tasks demonstrate our broad application domain.

\textbf{Datasets and Protocols.} We followed~\cite{cao2019learning, zhou2019bbn} to collect the long-tailed versions of CIFAR-10/-100 with controllable degrees of data imbalance ratio (, where  is number of samples in each category), which controls the distribution of training sets. ImageNet-LT~\cite{liu2019large} is a long-tailed subset of ImageNet dataset~\cite{russakovsky2015imagenet}. It consists of 1k classes over 186k images, where 116k/20k/50k for train/val/test sets, respectively. In train set, the number of images per class is ranged from 1,280 to 5, which imitates the long-tailed distribution that commonly exists in the real world. The test and val sets were balanced and reported on four splits: Many-shot containing classes with  images, Medium-shot including classes with  images, Few-shot covering classes with  images, and Overall for all classes. LVIS~\cite{gupta2019lvis} is a large vocabulary instance segmentation dataset with 1,230/1,203 categories in V0.5/V1.0, respectively. It contains a 57k/100k train set (V0.5/V1.0) under a significant long-tailed distribution, and relatively balanced 5k/20k val set (V0.5/V1.0) and 20k test set.

\begin{figure}[t]
   \includegraphics[width=\linewidth]{img/fig5.pdf}
   \caption{The visualized activation maps of the linear classifier baseline, Decouple-LWS~\cite{kang2019decoupling} and the proposed method on ImageNet-LT using the Grad-CAM~\cite{selvaraju2017grad}.}
   \label{fig:5} \end{figure}


\begin{table}
\centering
\scalebox{0.9}
{
\begin{tabular}{c| c | c | c | c | c | c}
\hline
\hline
Dataset & \multicolumn{3}{c}{Long-tailed CIFAR-100} & \multicolumn{3}{|c}{Long-tailed CIFAR-10} \\ 
\hline 
\textbf{Imbalance ratio} & 100 & 50 & 10 & 100 & 50 & 10 \\
\hline
\hline
Focal Loss~\cite{lin2017focal} & 38.4 & 44.3 & 55.8 & 70.4 & 76.7 & 86.7   \\
Mixup~\cite{zhang2018mixup} & 39.5 & 45.0 & 58.0 & 73.1 & 77.8 & 87.1 \\
Class-balanced Loss~\cite{cui2019class} & 39.6 & 45.2 & 58.0 & 74.6 & 79.3 & 87.1 \\
LDAM~\cite{cao2019learning} & 42.0 & 46.6 & 58.7 & 77.0 & 81.0 & 88.2 \\
BBN~\cite{zhou2019bbn} & 42.6 & 47.0 & 59.1 & 79.8 & 82.2 & 88.3 \\
\hline
(Ours) De-confound & 40.5 & 46.2 & 58.9 & 71.7 & 77.8 & 86.8\\
(Ours) De-confound-TDE & \textbf{44.1} & \textbf{50.3} & \textbf{59.6} & \textbf{80.6} & \textbf{83.6} & \textbf{88.5}\\
\hline
\hline
\end{tabular}
}
\caption{Top-1 accuracy on Long-tailed CIFAR-10/-100 with different imbalance ratios. All models are using the same ResNet-32 backbone. We further adopted the same warm-up scheduler from BBN~\cite{zhou2019bbn} for fair comparisons.}
\label{tab:rebuttal_1}
\vspace{-5mm}
\end{table}


\textbf{Evaluation.} For Long-tailed CIFAR-10/-100~\cite{cao2019learning, zhou2019bbn}, we evaluated Top-1 accuracy under three different imbalance ratios: 100/50/10. For ImageNet-LT~\cite{liu2019large}, the evaluation results were reported as the percentage of accuracy on four splits. For LVIS~\cite{gupta2019lvis}, the evaluation metrics are standard segmentation mask AP calculated across IoU threshold 0.5 to 0.95 for all classes. These classes can also be categorized by the frequency and independently reported as AP, AP, AP: subscripts  stand for rare (appeared in  images), common (appeared in  images), and frequent (appeared in  images). Since we can use the LVIS to detect bounding boxes, the detection results were reported as AP.


\textbf{Implementation Details.} For image classification on ImageNet-LT, we used ResNeXt-50-32x4d~\cite{xie2017aggregated} as our backbone for all experiments. All models were trained by using SGD optimizer with momentum  and batch size 512. The learning rate was decayed by a cosine scheduler~\cite{loshchilov2016sgdr} from 0.2 to 0.0 in 90 epochs. Hyper-parameters were chosen by the performances on ImageNet-LT val set, and we set . For Long-tailed CIFAR-10/-100, we changed the backbone to ResNet-32 and the training scheduler to warm-up scheduler like BBN~\cite{zhou2019bbn} for fair comparisons. All parameters except for  are inherited from ImageNet-LT, which was set to  for CIFAR-10/-100 respectively. For instance segmentation and object detection on LVIS, we chose Cascade Mask R-CNN framework~\cite{cai2018cascade} implemented by \cite{mmdetection}. The optimizer was also SGD with momentum  and we used batch size 16 for a R101-FPN backbone. The models were trained in 20 epochs with learning rate starting at 0.02 and decaying by the factor of 0.1 at the 16-th and 19-th epochs. We selected the top 300 predicted boxes following~\cite{gupta2019lvis, tan2020equalization}. The hyper-parameters on LVIS were directly adopted from the ImageNet-LT, except for . The main difference between image classification and object detection/instance segmentation is that the latter includes a background class , which is a head class used to make a binary decision between foreground and background. As we discussed in Section.~\ref{subsec: bgfixtde}, the Background-Exempted Inference should be used to retain the good background bias. The comparison between with and without Background-Exempted Inference is given in Appendix C.


\textbf{Ablation studies.} To study the effectiveness of the proposed de-confounded training and TDE inference, we tested a variety of ablation models: 1) the linear classifier baseline (no biased term); 2) the cosine classifier~\cite{gidaris2018dynamic, qi2018low}; 3) the capsule classifier~\cite{liu2019large}, where  is normalized by the non-linear function from \cite{sabour2017dynamic}; 4) the proposed de-confounded model with normal softmax inference; 5) different versions of the TDE. As reported in Table~(\ref{tab:2},\ref{tab:3}), the de-confound TDE achieves the best performance under all settings. The TDE inference improves all three normalized models, because the cosine and capsule classifiers can be considered as approximations to the proposed de-confounded model. To show that the mediation effect removed by TDE indeed controls the preference towards head direction, we changed the parameter  as shown in Figure~\ref{fig:3}, resulting the smooth increasing/decreasing of the performances on tail/head classes, respectively. 

\begin{table}
\centering
\scalebox{0.85}
{
\begin{tabular}{c| c | c  c  c | c  c  c | c}
\hline
\hline
Methods & LVIS Version & AP & AP & AP & AP & AP & AP & AP \\ 
\hline 
Focal Loss~\cite{lin2017focal} & V0.5 & 21.1 & 32.1 & 22.6 & 3.2 & 21.1 & 28.3 & 22.6    \\
(2019 Winner) EQL~\cite{tan2020equalization} & V0.5 & 24.9 & 37.9 & 26.7 & 10.3 & 27.3 & 27.8 & 27.9 \\
\hline
Baseline & V0.5 & 22.6 & 33.5 & 24.4 & 2.5 & 23.0 & 30.2 & 24.3    \\
Cosine~\cite{gidaris2018dynamic, qi2018low} & V0.5 & 25.0 & 37.7 & 27.0 & 9.3 & 25.5 & 30.8 & 27.1    \\
Capsule~\cite{liu2019large, sabour2017dynamic} & V0.5 & 25.4 & 37.8 & 27.4 & 8.5 & 26.4 & \textbf{31.0} & 27.1    \\
(Ours) De-confound & V0.5 & 25.7 & 38.5 & 27.8 & 11.4 & 26.1 & 30.9 & 27.7    \\
(Ours) Cosine-TDE & V0.5 & 28.1 & 42.6 & 30.2 & 20.8 & 28.7 & 30.3 & 30.6    \\
(Ours) Capsule-TDE & V0.5 & \textbf{28.4} & 42.1 & \textbf{30.8} & 21.1 & \textbf{29.7} & 29.6 & 30.4    \\
(Ours) De-confound-TDE & V0.5 & \textbf{28.4} & \textbf{43.0} & 30.6 & \textbf{22.1} & 29.0 & 30.3 & \textbf{31.0}    \\
\hline
Baseline & V1.0 & 21.8 & 32.7 & 23.2 & 1.1 & 20.9 & 31.9 & 23.9 \\
(Ours) De-confound & V1.0 & 23.5 & 34.8 & 25.0 & 5.2 & 22.7 & \textbf{32.3} & 25.8    \\
(Ours) De-confound-TDE & V1.0 & \textbf{27.1} & \textbf{40.1} & \textbf{28.7} & \textbf{16.0} & \textbf{26.9} & 32.1 & \textbf{30.0}    \\
\hline
\hline
\end{tabular}
}
\caption{All models are using the same Cascade Mask R-CNN framework~\cite{cai2018cascade} with R101-FPN backbone~\cite{lin2017feature}. The reported results are evaluated on LVIS val set~\cite{gupta2019lvis}.}
\label{tab:3}
\vspace{-5mm}
\end{table}

\textbf{Comparisons with State-of-The-Art Methods.} The previous state-of-the-art results on ImageNet-LT are achieved by the two-stage re-balanced training~\cite{kang2019decoupling} that decouples the backbone and classifier. However, as we discussed in Section~\ref{subsec: revisiting}, this kind of approaches are less effective or efficient. In Long-tailed CIFAR-10/-100, we outperform the previous methods~\cite{cui2019class, cao2019learning, zhou2019bbn} in all imbalance ratios, which proves that the proposed method can automatically adapt to different data distributions. In LVIS dataset, after a simple adaptation, we beat the champion EQL~\cite{tan2020equalization} of LVIS Challenge 2019 in Table~\ref{tab:3}. All reported results in Table~\ref{tab:3} are using the same Cascade Mask R-CNN framework~\cite{cai2018cascade} and R101-FPN backbone~\cite{lin2017feature} for fair comparison. The EQL results were copied from \cite{tan2020equalization}, which were trained by 16 GPUs and 32 batch size while the proposed method only used 8 GPUs and half of the batch size. We didn't compare the EQL results on the final challenge test server, because they claimed to exploit external dataset and other tricks like ensemble to win the challenge. Note that EQL is also a re-balanced method, having the same problems as~\cite{kang2019decoupling}. We also visualized the activation maps using Grad-CAM~\cite{selvaraju2017grad} in Figure~\ref{fig:5}. The linear classifier baseline and decouple-LWS~\cite{kang2019decoupling} usually activate the entire objects and some context regions to make a prediction. Meanwhile, the de-confound TDE only focuses on the direct effect, \ie, the most discriminative regions, so it usually activates on a more compact area, which is less likely to be biased towards its similar head classes. For example, to classify a ``kimono'', the proposed method only focuses on the discriminative feature rather than the entire body, which is similar to some other clothes like ``dress''.




\vspace{-2mm}
\section{Conclusions}
\vspace{-2mm}
In this work, we first proposed a causal framework to pinpoint the causal effect of momentum in the long-tailed classification, which not only theoretically explains the previous methods, but also provides an elegant one-stage training solution to extract the unbiased direct effect of each instance. The detailed implementation consists of de-confounded training and total direct effect inference, which is simple, adaptive, and agnostic to the prior statistics of the class distribution. We achieved the new stage-of-the-arts of various tasks on both ImageNet-LT and LVIS benchmarks. As moving forward, we are going to 1) further validate our theory in a wider spectrum of application domains and 2) seek better feature disentanglement algorithms for more precise counterfactual effects.   


\section*{Broader Impact}

The positive impacts of this work are two-fold: 1) it improves the fairness of the classifier, which prevents the potential discrimination of deep models, \eg, an unfair AI could blindly cater to the majority, causing gender, racial or religious discrimination; 2) it allows the larger vocabulary datasets to be easily collected without a compulsory class-balancing pre-processing, \eg, to train autonomous vehicles, by using the proposed method, we don't need collecting as many ambulance images as normal van images do.  The negative impacts could also happen when the proposed long-tailed classification technique falls into the wrong hands, \eg, it can be used to identify the minority groups for malicious purposes. Therefore, it's our duty to make sure that the long-tailed classification technique is used for the right purpose.



\appendix

\section{Additional Explanations of Assumption 1}
\label{sp-sec:assumption1}
To better understand the  and Assumption 1, let's take a simple example. Given a learnable parameter , and its gradients of instances for class A, B approximate to (1, 1) and (-1, 1) respectively. If each of these two classes has 50 samples, the mean gradient would be  (0, 1), which is the optimal gradient direction shared by both A and B. The momentum will thus accelerate on this direction that optimizes the model to fairly discriminate two classes. However, if there are 99 samples from class A and only 1 sample from class B (long-tailed dataset), the mean gradient would be (0.98, 1). In this case, the momentum direction now approximates to the class A (head) gradients, encouraging the backbone parameters to generate head-like feature vectors, \ie, creating an unfair deviation towards the head. 

\begin{wrapfigure}{r}{6cm}
   \includegraphics[width=\linewidth]{img/spfig1.pdf}
   \caption{The magnitudes of classifier weights  for each class after training with momentum , where  is ranking by the number of training samples in a descending order.}
   \label{spfig:1} \end{wrapfigure}
Since the momentum in SGD~\cite{pytorchSGD, sutskever2013importance, qian1999momentum} usually dominates the gradient velocity, the effect of such a deviation is not trivial, which will eventually create the head projection  on all feature vectors generated by the backbone. It's worth noting that although there are non-linear activation layers in the backbone, due to the central limit theorem~\cite{montgomery2010applied}, the overall effect of these deviated parameters is still following the normal distribution, which means we can use the moving averaged feature to approximate this head direction, \ie, the Assumption 1 in the original paper.

In addition, even in a balanced dataset, the Assumption 1 still holds. Considering the above example, the mean gradient is (0, 1) for balanced A and B, which is not biased towards either direction: (1, 1) or (-1, 1). In other word, the  still exists for the balanced dataset, but the  should be almost the same for all classes. Therefore, the  won't cause any preference in the balanced dataset, which naturally allows  free from the effect of . It's also intuitively easy to understand, because when the dataset is balanced, the mean feature only represents the common patterns shared by all classes, \eg, the  in a balanced face recognition dataset is the mean face, which would be a contour of human head that not biased towards any specific face categories. 


\section{Revisiting Previous Methods in Long-Tailed Classification}
In this section, we will revisit the previous state-of-the-arts in two aspects: the normalized classifiers and the re-balancing strategies. 

\textbf{Normalized Classifiers.} The normalized classifiers~\cite{gidaris2018dynamic, qi2018low, kang2019decoupling, liu2019large} have already been widely adopted in long-tailed classification based on empirical practice. As we discussed in the Section~4, the correctly applied normalized classifiers are approximations of the proposed de-confounded training. However, without the guidance of the proposed causal framework, most of them are not utilized in a proper way.  We define the general normalized classifier as the following equation:

Since in most of the previous methods,  is set to 1, so we slightly abuse the notation to omit the superscript  for simplicity.


The cosine classifier~\cite{gidaris2018dynamic, qi2018low} is defined based on the cosine similarity, which has . It is commonly used in the tasks like few-shot learning~\cite{chen2019closer}. In Table~2,3 of original paper, we have proved its effectiveness in the long-tailed classification. The capsule classifier is proposed by Liu~\etal~\cite{liu2019large} as the replacement of vanilla cosine classifier in OLTR. It changes the  norm of  into the squashing non-linear function proposed in Capsule Network~\cite{sabour2017dynamic}, which allows the normalized  having a magnitude range from 0 to 1, representing the probability of  in its direction. The final normalization term can thus be defined as . However, the OLTR~\cite{liu2019large} doesn't use it to de-confound the visual feature. Instead, its  is the joint embedding of the feature vector and an attentive memory vector. The Decouple~\cite{kang2019decoupling} also invents two different types of normalized classifiers: -norm classifier and Learnable Weight Scaling (LWS) classifier. They empirically found that the  norm of  is not uniform in the long-tailed dataset, and has a positive correlation with the number of training samples for class , as shown in Figure~\ref{spfig:1}. Therefore, their normalized classifiers only normalize the : the -norm classifier is defined as  while LWS is  where  is a learnable parameter. Yet, these decouple classifiers fail to de-confound the  for two reasons: 1) they don't considering the confounding effect on ; 2) they only apply the normalized classifiers on the 2nd stage when the backbone has already been frozen. 



\textbf{Re-balancing Strategies.} Both OLTR~\cite{liu2019large} and Decouple~\cite{kang2019decoupling} adopt the same class-aware sampler in their 2nd stage training, which forces each class to contribute the same number of samples regardless of the size. To dynamically combine the two training stages, the BBN~\cite{zhou2019bbn} utilizes a bilateral-branch design to smoothly transfer the sampling strategy from the imbalanced branch to the re-balancing branch, where two branches share the same set of parameters but learn from different sampling strategies, which has the same spirit as two-stage design in OLTR~\cite{liu2019large} and Decouple~\cite{kang2019decoupling}. As to the EQL~\cite{tan2020equalization}, since the re-sampling is complicated in the object detection and instance segmentation tasks, where objects from different classes co-exist in one image, they choose the re-weighted loss to balance the contributions of different classes. 

\begin{table}
\centering
{
\begin{tabular}{c| c | c  c  c | c  c  c | c}
\hline
\hline
Methods & BG-Exempted & AP & AP & AP & AP & AP & AP & AP \\
\hline
De-confound & \ding{55} & 25.7 & 38.5 & 27.8 & 11.4 & 26.1 & \textbf{30.9} & 27.7    \\
De-confound-TDE & False & 23.4 & 35.7 & 24.9 & 13.1 & 23.6 & 27.1 & 24.8    \\
De-confound-TDE & True & \textbf{28.4} & \textbf{43.0} & \textbf{30.6} & \textbf{22.1} & \textbf{29.0} & 30.3 & \textbf{31.0}    \\
\hline
\hline
\end{tabular}
}
\caption{The results of the proposed TDE with/without Background-Exempted Inference on LVIS~\cite{gupta2019lvis} V0.5 val set. The Cascade Mask R-CNN framework~\cite{cai2018cascade} with R101-FPN backbone~\cite{lin2017feature} is used.}
\label{sp-tab:1}
\end{table}


\section{Background-Exempted Inference}
The results with and without Background-Exempted Inference are reported in Table~\ref{sp-tab:1}. As we can see, the Background-Exempted strategy successfully prevents the TDE from hurting the foreground-background selection. It is the key to apply TDE in tasks like object detection and instance segmentation that include one or more legitimately biased head categories, \ie, this strategy allows us to conduct TDE on a selected subset of categories.


\section{The Difference Between Re-balancing NDE and The Proposed TDE}

\begin{figure}[t]
   \includegraphics[width=\linewidth]{img/spfig2.pdf}
   \caption{A simple one-dimensional binary classification example of conventional classifier, one-/two-stage re-balancing classifiers, and the proposed TDE.}
   \label{spfig:2} \end{figure}


In this section, we will further discuss the relationship between two-stage re-balancing NDE and the proposed TDE. As we discussed in Section~4.3 of original paper, the 2nd-stage re-balanced classifier essentially calculates the , where the second term can be omitted because  is a dummy vector and the moving averaged  in a balanced set won't point to any specific classes, so it is actually a constant offset. Therefore, the crux of understanding the NDE would be why the 2nd-stage re-balanced training equals to the first term . It is because when the backbone is frozen, it breaks the dependency between , which is a straightforward implementation of causal intervention . The original OLTR~\cite{liu2019large} violates this intervention by fine-tuning the backbone parameters in the 2nd stage, and it thus performs much worse than the Decouple-OLTR in the Table 2 of original paper, which freezes the backbone parameters. Meanwhile, the balanced re-sampling also brings a fair  as we discussed in the third paragraph of Section~\ref{sp-sec:assumption1}.

To better illustrate both the similarity and the difference between re-balancing NDE and the proposed TDE, we constructed a one-dimensional binary classification example for conventional classifier, one-/two-stage re-balancing classifiers, and the proposed TDE in Figure~\ref{spfig:2}, where the gaussian distribution curve represents the feature distribution generated by the backbone, and the 0 point is the classifier's decision boundary. The conventional classifier and one-stage re-balancing are fundamentally problematic, because they either cause the mismatching in the inference or learn a bad backbone model. In the meantime, both two-stage re-balancing and the proposed TDE are able to correctly remove the bias by proper adjustments. The 2nd-stage re-balanced training (NDE) fixes the backbone parameters  learnt from 1st-stage imbalanced training, \ie, the frozen curve in the image, and then re-samples an artificially balanced data distribution to create a fair . The overall re-balancing NDE can be considered as subtracting a bias offset from original decision boundary. Meanwhile, the proposed TDE removes the bias effect (head projection) from feature vectors. Both two types of adjustments can properly remove the head bias in this example. That's why TDE and NDE should be theoretically identical in the long-tailed classification scenario. However, the 2nd-stage re-balancing NDE has two disadvantages: 1) its adjustment requires an additional training stage to fine-tune the classifier weights, which relies on the accessibility of data distribution; 2) if non-linear modules are applied to the feature vectors, \eg, a global context layer that conducts interactions among all objects  in an image, the NDE can only remove a linear approximation of this non-linear activated head bias, while the TDE would be able to maintain the natural interactions of features in both original logit term and the subtracted counterfactual term. It explains why the Decouple-OLTR in Table 2 of original paper doesn't perform as good as Decouple--norm or Decouple-LWS, because OLTR involves non-linear interactions between feature vectors and memory vectors, so a linear adjustment on classifier's decision boundary cannot completely remove the head bias.


\begin{table}
\centering
{
\begin{tabular}{c |c |c |c |c |c |c |c }
\hline
\hline
 &  &  &  & Many-shot & Medium-shot & Few-shot & Overall \\ 
\hline 
\textbf{1} &  16.0 & 1/32.0 & \ding{55} & 69.8 & 42.8 & 14.9 & 49.4 \\
\textbf{4} &  16.0 & 1/32.0 & \ding{55} & 69.0 & 42.3 & 13.1 & 48.6 \\
\hline
2 &  \textbf{8.0} & 1/32.0 & \ding{55}  & 69.5 & 31.3 & 1.6  & 42.0 \\
2 &  \textbf{32.0} & 1/32.0 & \ding{55} & 68.6 & 41.3 & 13.0 & 47.9 \\
\hline
2 &  16.0 & \textbf{1/16.0} & \ding{55} & 69.3 & \textbf{44.0} & 14.2 & 49.7\\
2 &  16.0 & \textbf{1/64.0} & \ding{55} & \textbf{69.9} & 43.3 & 14.7 & 49.6 \\
\hline
\textbf{2} &  \textbf{16.0} & \textbf{1/32.0} & \ding{55} & 69.5 & 43.9 & \textbf{15.2} & \textbf{49.8} \\
\hline
2 &  16.0 & 1/32.0 & \textbf{2.5} & \textbf{66.2} & 49.8 & 29.4 & \textbf{53.3} \\
2 &  16.0 & 1/32.0 & \textbf{3.0} & 64.5 & \textbf{50.0} & 32.6 & \textbf{53.3} \\
2 &  16.0 & 1/32.0 & \textbf{3.5} & 62.5 & 49.9 & \textbf{36.0} & 52.9 \\
\hline
\hline
\end{tabular}
}
\caption{Hyper-parameters selection based on performances of ImageNet-LT val set, where \ding{55} for  means that TDE inference is not included. The backbone we used here is ResNeXt-50-32x4d.}
\label{sp-tab:2}
\end{table}




\begin{table}
\centering
{
\begin{tabular}{c |c |c |c |c |c }
\hline
\hline
Methods & \#heads  & Many-shot & Medium-shot & Few-shot & Overall \\ 
\hline
Cosine~\cite{gidaris2018dynamic, qi2018low} & 1 & 67.3 & 41.3 & 14.0 & 47.6 \\
Cosine~\cite{gidaris2018dynamic, qi2018low} & 2 & 67.5 & 42.1 & 14.1 & 48.1 \\
Capsule~\cite{liu2019large, sabour2017dynamic} & 1 & 67.1 & 40.0 & 11.2 & 46.5 \\
Capsule~\cite{liu2019large, sabour2017dynamic} & 2 & 67.7 & 41.3 & 12.6 & 47.6 \\
(Ours) De-confound & 1 & 67.3 & 41.8 & 15.0 & 47.9 \\
(Ours) De-confound & 2 & \textbf{67.9} & 42.7 & 14.7 & 48.6 \\
(Ours) Cosine-TDE & 1 & 61.8 & 47.1 & 30.4 & 50.5 \\
(Ours) Cosine-TDE & 2 & 63.0 & 47.3 & 31.0 & 51.1 \\
(Ours) Capsule-TDE & 1 & 62.3 & 46.9 & 30.6 & 50.6 \\
(Ours) Capsule-TDE & 2 & 62.4 & 47.9 & 31.5 & 51.2 \\
(Ours) De-confound-TDE & 1 & 62.5 & 47.8 & \textbf{32.8} & 51.4 \\
(Ours) De-confound-TDE & 2 & 62.7 & \textbf{48.8} & 31.6 & \textbf{51.8} \\
\hline
\hline
\end{tabular}
}
\caption{The performances of cosine classifier~\cite{gidaris2018dynamic, qi2018low} and capsule classifier~\cite{liu2019large, sabour2017dynamic} under different number of head  on ImageNet-LT test set. Other hyper-parameters are fixed. }
\label{sp-tab:3}
\end{table}


\begin{table}
\centering
{
\begin{tabular}{c |c |c |c |c |c }
\hline
\hline
Methods & Backbone & Many-shot & Medium-shot & Few-shot & Overall \\ 
\hline
Baseline & ResNeXt-50 & 66.1 & 38.4 & 8.9 & 45.0 \\
De-confound & ResNeXt-50 & 67.9 & 42.7 & 14.7 & 48.6 \\
De-confound-TDE & ResNeXt-50 & 62.7 & 48.8 & 31.6 & 51.8 \\
\hline 
Baseline & ResNeXt-101 & 68.7 & 42.5 & 11.8 & 48.4 \\
De-confound & ResNeXt-101 & \textbf{68.9} & 44.3 & 16.5 & 50.0 \\
De-confound-TDE & ResNeXt-101 & 64.7 & \textbf{50.0} & \textbf{33.0} & \textbf{53.3} \\
\hline
\hline
\end{tabular}
}
\caption{The performances of the proposed method under different backbones in ImageNet-LT test set.}
\label{sp-tab:4}
\end{table}



\begin{table}
\centering
{
\begin{tabular}{c| c | c  c  c | c  c  c | c}
\hline
\hline
Methods & Backbone & AP & AP & AP & AP & AP & AP & AP \\
\hline
Baseline & R101-FPN & 22.6 & 33.5 & 24.4 & 2.5 & 23.0 & 30.2 & 24.3     \\
De-confound & R101-FPN & 25.7 & 38.5 & 27.8 & 11.4 & 26.1 & 30.9 & 27.7    \\
De-confound-TDE & R101-FPN & 28.4 & 43.0 & 30.6 & \textbf{22.1} & 29.0 & 30.3 & 31.0    \\
\hline
Baseline & X101-FPN & 26.4 & 39.5 & 28.4 & 7.4 & 28.1 & 32.0 & 28.5    \\
De-confound & X101-FPN & 28.4 & 41.9 & 30.6 & 13.3 & 29.5 & \textbf{32.9} & 30.5    \\
De-confound-TDE & X101-FPN & \textbf{30.4} & \textbf{45.1} & \textbf{32.9} & 21.1 & \textbf{31.8} & 32.3 & \textbf{33.1}    \\
\hline
\hline
\end{tabular}
}
\caption{The performances of the proposed method under different backbones in LVIS V0.5 val set.}
\label{sp-tab:5}
\end{table}


\begin{table}[ht!]
\centering
{
\begin{tabular}{c| c  c  c | c  c  c }
\hline
\hline
Methods & AP & AP & AP & AP & AP & AP \\
\hline
Baseline & 19.4 & 29.8 & 20.6 & 3.9 & 21.9 & 30.8    \\
De-confound & 20.8 & 31.8 & 22.1 & 7.4 & 22.7 & \textbf{31.2}    \\
De-confound-TDE & \textbf{23.0} & \textbf{35.2} & \textbf{24.1} & \textbf{12.7} & \textbf{24.5} & 30.7  \\
\hline
\hline
\end{tabular}
}
\caption{The single model performances of the proposed method on LVIS V0.5 evaluation test server~\cite{LVISeval}.}
\label{sp-tab:6}
\end{table}


\section{Additional Ablation Studies}
The hyper-parameters used in original paper are selected according to the performances on ImageNet-LT val set as shown in Table~\ref{sp-tab:2}. To further study the multi-head strategy on different normalized classifiers, we tested the  on cosine classifier~\cite{gidaris2018dynamic, qi2018low} and capsule classifier~\cite{liu2019large, sabour2017dynamic} in Table~\ref{sp-tab:3}. It proves that the advantage of the proposed de-confounded model doesn't come from larger K, and the multi-head fine-grained sampling can generally improves the de-confounded training, no matter what kind of normalization function we choose.

As shown in Table~\ref{sp-tab:4},\ref{sp-tab:5}, we tested the proposed method on different backbones. After equipped with ResNeXt-101-32x4d and ResNeXt-101-64x4d~\cite{xie2017aggregated} for ImageNet-LT~\cite{liu2019large} and LVIS~\cite{gupta2019lvis} V0.5, respectively, the proposed method gains additional improvements. In ImageNet-LT dataset, we changed some hyper-parameters ( and increased the training epochs to 120, because of the significantly increased number of model parameters. The hyper-parameters for LVIS are still the same as original paper.

We also reported the performances of the proposed method on LVIS V0.5 evaluation test server~\cite{LVISeval} in Table~\ref{sp-tab:6}, where we used ResNeXt-101-64x4d backbone and the original hyper-parameters. It's worth noting that these are single model performances, which neither exploited external dataset nor utilized any model enhancement tricks.


\small

\bibliographystyle{unsrt}  
\bibliography{references}

\end{document}
