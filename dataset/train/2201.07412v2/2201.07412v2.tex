

\documentclass[runningheads]{llncs}



\usepackage{pdfpages}




\usepackage{booktabs}
\usepackage{graphicx}



\usepackage{float}
\usepackage{graphicx}
\usepackage{comment}
\usepackage{amsmath,amssymb} \usepackage{color}
\usepackage{xspace}
\usepackage{textcomp}
\usepackage{cite}
\usepackage{mathtools}
\usepackage{bbm}
\usepackage{makecell, verbatim, sidecap}
\usepackage{subfig}
\usepackage{multirow}
\usepackage{pifont}


\usepackage[capitalize]{cleveref}
\crefname{section}{Sec.}{Secs.}
\Crefname{section}{Section}{Sections}
\Crefname{table}{Table}{Tables}
\crefname{table}{Table}{Tabs.}

\def\eg{{e.g.\xspace}}
\def\ie{{i.e.\xspace}}
\def\etal{{et al.\xspace}}
\def\cf{\emph{cf.}\xspace}

\newcommand{\XL}[1]{{\textcolor{teal}{[XL: #1]}}}
\newcommand{\myparagraph}[1]{{\vspace{0.5em} \noindent \bf #1}}
\newcommand{\tabincell}[2]{\begin{tabular}{@{}#1@{}}#2\end{tabular}}  
\def\handle{{Poseur}\xspace}
\def\R{{\mathbb R}}
\def\Loc{{\boldsymbol{\mu}}}
\def\loc{{\boldsymbol{\mu}}}
\def\a{\mathbf{a}}
\def\b{{\boldsymbol{b}}}
\def\KPF{{\hat{\mathbf{\Loc}}_f}}
\def\kpf{{\mathbf{\loc}_f}}
\def\kpn{{\hat{\mathbf{\loc}}_n}}
\def\KBF{{\hat{\mathbf{\b}}_f}}
\def\KPQ{{\hat{\mathbf{\Loc}}_q}}
\def\kpq{{\hat{\mathbf{\loc}}_q}}
\def\KBQ{{\hat{\mathbf{\b}}_q}}
\def\Q{{\mathbf{Q}}}
\def\QZ{{\Q_z}}
\def\Qc{{\Q_c}}
\def\PQZ{{\mathbf{P}_0}}
\def\p{{\mathbf{p}}}
\def\x{{\mathbf{x}}}
\def\A{{\mathbf{A}}}
\def\W{{\mathbf{W}}}
\def\BTheta{{\boldsymbol{\Theta}}}
\def\BPhi{{\boldsymbol{\Phi}}}
\newcommand{\cmark}{\ding{51}}\newcommand{\xmark}{\ding{55}}




\begin{document}
\pagestyle{headings}
\mainmatter
\def\ECCVSubNumber{4552}  

\title{Poseur: Direct Human Pose Regression with Transformers\thanks{WM and YG contributed equally.
YG's contribution was in part made when visiting Alibaba.
ZT is now with Meituan Inc.
CS is the corresponding author.
\it 
Accepted to Proc.\ Eur. Conf. Computer Vision 2022.
}} 

\author{Weian Mao\textsuperscript{}
        ~ Yongtao Ge\textsuperscript{}
        ~ Chunhua Shen\textsuperscript{} 
        ~ Zhi Tian\textsuperscript{} 
        ~ Xinlong Wang\textsuperscript{} 
        ~ Zhibin Wang\textsuperscript{} 
        ~ Anton van den Hengel\textsuperscript{} }
\institute{ The University of Adelaide
~
 Alibaba Damo Academy 
~
 Zhejiang University }


\authorrunning{W.\  Mao et al.}

\begin{comment}
\titlerunning{Abbreviated paper title}
\author{First Author\inst{1}\orcidID{0000-1111-2222-3333} \and
Second Author\inst{2,3}\orcidID{1111-2222-3333-4444} \and
Third Author\inst{3}\orcidID{2222--3333-4444-5555}}
\authorrunning{F. Author et al.}
\institute{Princeton University, Princeton NJ 08544, USA \and
Springer Heidelberg, Tiergartenstr. 17, 69121 Heidelberg, Germany
\email{lncs@springer.com}\\
\url{http://www.springer.com/gp/computer-science/lncs} \and
ABC Institute, Rupert-Karls-University Heidelberg, Heidelberg, Germany\\
\email{\{abc,lncs\}@uni-heidelberg.de}}
\end{comment}
\maketitle

\begin{abstract}
We propose a 
direct,
regression-based approach to 2D human pose estimation from single images.
We formulate the problem as a sequence prediction 
task,  
which we solve using a Transformer network. 
This network {\it directly} learns a regression mapping from images to the keypoint coordinates, without resorting to intermediate representations such as heatmaps.
This approach avoids much of the complexity associated with heatmap-based approaches. 
To overcome the feature misalignment issues 
of previous regression-based methods, 
we propose an attention mechanism that adaptively attends to the features
that are 
most relevant to the target keypoints, 
considerably improving the  accuracy.
Importantly, our framework is end-to-end differentiable, and naturally learns to exploit the dependencies 
between keypoints.
Experiments on MS-COCO and MPII, two predominant pose-estimation datasets, demonstrate that our method significantly improves upon the state-of-the-art in regression-based pose estimation.
More notably, ours is the first regression-based approach to perform
favorably 
compared to the best heatmap-based pose estimation methods. 
Code is available at:
\def\UrlFont{\tt \color{blue}}
{\url{\tt https://github.com/aim-uofa/Poseur}}


\keywords{2D Human Pose Estimation, Keypoint Detection, Transformer}

\end{abstract}


\section{Introduction}


Human pose estimation is one of the core challenges in computer vision, not least due to its importance in understanding human behaviour.  It is also a critical pre-process to a variety of human-centered challenges including activity recognition, video augmentation, and human-robot interaction.
Human pose estimation 
requires estimating the location of a set of keypoints in an image, in order that the pose of a simplified human skeleton might be recovered.

Existing methods for human pose estimation can be broadly categorized into heatmap-based and regression-based methods.
Heatmap-based methods first predict a heatmap, or classification score map, that reflects the likelihood that each pixel in a region corresponds to a particular skeleton keypoint. The current state-of-the-art methods use a fully convolutional network (FCN) to estimate this heatmap. The final keypoint location estimate corresponds to the peak in the heatmap intensity. Most current pose estimation methods are heatmap-based because this approach has thus far achieved higher accuracy than regression-based approaches. Heatmap-based methods have their disadvantages, however. 
1) The ground-truth heatmaps need to be manually designed and heuristically tuned.  The noise inevitably introduced impacts on the final results~\cite{luo2020rethinking,sun2017compositional,huang2020devil}. 
2)  A post-processing operation is required to find a single maximum of the heatmap. This operation is often
heuristic, and non-differentiable, which precludes end-to-end training-based approaches. 3) The resolution of heatmaps predicted by the FCNs is usually lower than the resolution of the input image. The reduced resolution results in a quantization error and limits the precision of keypoint localization. This quantization error might be ameliorated somewhat by various forms of interpolation, but this makes the framework less differentiable, more complicated and introduces some extra hyper-parameters.







\begin{figure}
	\centering
	\begin{minipage}[t]{0.45\linewidth}
		\centering
		\includegraphics[width=2.1in]{figures/trade_off.pdf}
		\caption{
        \textbf{Comparing the proposed \handle against heatmap-based methods} with various backbone networks on COCO \emph{val.}\ set. Baseline refers to heatmap-based methods. Heatmap-based baseline of MobileNet-V2 and ResNet use the same deconvolutional head as SimpleBaseline~\cite{xiao2018simple}.
        }
        \label{fig:trade_off}
	\end{minipage}
	\hspace{.2em}
	\begin{minipage}[t]{0.45\linewidth}
		\centering
		\includegraphics[width=2.1in]{figures/issue_fig.pdf}
		\caption{
        \textbf{Comparison of \handle and previous regression-based methods.}  `GAP' indicates global average pooling. (a) shows the feature misalignment issue. (b) shows crucial spatial information is inevitably lost with GAP. We alleviate both issues with the design in (c). \;\;\;\;\;\;
        }
        \label{fig:difference}
	\end{minipage}
\end{figure}











Regression-based methods directly map the input image to the coordinates of body joints, typically using a fully-connected (FC) prediction layer, eliminating the need for heatmaps. The pipeline of regression-based methods is much more {straightforward} than heatmap-based methods, as pose estimation is 
naturally
formulated
as a process of predicting a set of 
coordinate values. 
A regression-based approach also alleviates the need for non-maximum suppression, heatmap generation, and quantization compensation, and is inherently end-to-end differentiable.


Regression-based pose-estimation has received less attention than heatmap-based methods due to its inferior performance. 
There are a variety of causes of this performance deficit. First, in order to reduce the number of parameters in the
final FC
prediction layer, models such as DeepPose~\cite{2014deeppose} and RLE~\cite{li2021rle}
employ 
a global average pooling that is applied to reduce the CNN feature map's resolution before the FC layers, as illustrated in \cref{fig:difference}(b).
This global average pooling destroys the spatial structure of the convolutional feature maps, and has a significantly negative impact on performance. Next, as shown in \cref{fig:difference}(a), the convolutional features and predictions of some regression-based models (e.g.  DirectPose~\cite{tian2019directpose} and SPM~\cite{nie2019single}) are misaligned, which consequently reduces localization precision. Lastly, regression-based methods only regress the coordinates of body joints and do not exploit the structured dependency between them~\cite{sun2017compositional}. 




Recently, Transformers have been applied to a range of tasks in computer vision, achieving impressive results~\cite{zhu2020deformable,dosovitskiy2020image,carion2020end}. This, and the fact that transformers were originally designed for sequence-to-sequence tasks, motivated our formulation of single person pose estimation as a sequence prediction problem.  Specifically, we pose the problem as that of predicting a length- sequence of coordinates, where  is the number of body joints for one person. This leads to a simple and novel regression-based pose estimation framework, that we label as \textbf{\handle}.


As shown in~\cref{fig:framework}, taking as inputs the feature maps of an encoder CNN, the transformer predicts  coordinate pairs. In doing so, \handle alleviates the aforementioned difficulties of regression-based methods. First, it does not need global average pooling to reduce feature dimensionality (\cf RLE~\cite{li2021rle}). Second, \handle eliminates the misalignment between the backbone features and predictions with the proposed efficient cross-attention mechanism.
Third, since the self-attention module is applied across the keypoint queries, the transformer naturally captures the structured dependencies among the keypoints.
Lastly, as shown in~\cref{fig:trade_off}, \handle outperforms heatmap-based methods with a variety of backbones. The improvement is more significant for the backbones using low-resolution representation, e.g., MobileNet V2 and ResNet. The results indicate that \handle can be deployed with fast backbones of low-resolution representation without large performance drop, which is difficult to be achieved for heatmap-based methods. We refer readers to \cref{sec:main_result} for more details.






Our main contributions are as follows.
\begin{itemize}




\item  We propose a transformer-based framework (termed \textbf{\handle}) for directly human pose regression, which is lightweight and can work well with the backbones using low-resolution representation. For example, with 49\% fewer FLOPs, ResNet-50 based \handle outperforms the heatmap-based method SimpleBaseline~\cite{xiao2018simple} by  AP on the COCO \emph{val} set.
\item \handle significantly improves the performance of regression-based methods, to the point where it is comparable to the state-of-the-art heatmap-based approaches. For example, it improves on the previously best regression-based method (RLE~\cite{li2021rle}) by  AP with the ResNet-50 backbone on the COCO \emph{val} set and outperforms the previously best heatmap-based method UDP-Pose~\cite{sun2019deep} by  AP with HRNet-W48 on the COCO \emph{test-dev} set.
\item Our proposed framework can be easily extended to an end-to-end pipeline without manual crop operation, for example, we integrate \handle into Mask R-CNN~\cite{he2017mask}, which is end-to-end trainable and can overcome many drawbacks of the heatmap-based methods. In this end-to-end setting, our method outperforms the previously best end-to-end top-down method PointSet Anchor~\cite{wei2020point} by  AP with the HRNet-W48 backbone on the COCO \emph{val} set.




\end{itemize}




\section{Related Work}


\noindent\textbf{Heatmap-based pose estimation.}
Heatmap-based 2D pose estimation methods\cite{chen2018cascaded,xiao2018simple,sun2019deep,cai2020learning,li2019rethinking,cao2019openpose,cheng2020higherhrnet,he2017mask,newell2016stacked} estimate per-pixel likelihoods for each keypoint location, and currently dominate in the field of 2D human pose estimation. 
A few works~\cite{newell2016stacked,sun2019deep,cai2020learning} attempt to design powerful backbone networks which can maintain high-resolution feature maps for heatmap supervision.
Another line of works~\cite{sun2017compositional,Zhang_2020_CVPR,huang2020devil} focus on alleviating biased data processing pipeline for heatmap-based methods. Despite the good performance, the heatmap representation bears a few drawbacks in nature, e.g. , non-differentiable decoding pipeline~\cite{sun2018integral,tian2019directpose} and quantization errors~\cite{huang2020devil,Zhang_2020_CVPR} due to the down sampling of feature maps.







\noindent\textbf{Regression-based pose estimation.}
2D human pose estimation is naturally a regression problem\cite{sun2018integral}. However, regression-based methods have historically not been as accurate as heatmap-based methods, and it has received less attention as a result\cite{2014deeppose,sun2018integral,sun2017compositional,carreira2016human,tian2019directpose,nie2019single}. 
Integral Pose~\cite{sun2018integral} proposes integral regression, which shares the merits of both heatmap representation and regression approaches, to avoid non-differentiable post-processing and quantization error issues. However, integral regression is proven to have an underlying bias compared with direct regression according to~\cite{gu2021removing}.
RLE~\cite{li2021rle} develops a regression-based method using maximum likelihood estimation and flow models. RLE~\cite{li2021rle} is the first to push the performance of the regression-based method to a level comparable with that of the heatmap-based methods. However, it is trained on the backbone that pre-trained by the heatmap loss.


\noindent\textbf{Transformer-based architectures.} Transformers have been applied to the pose estimation task with some success. 
TransPose~\cite{yang2021transpose} and HRFormer~\cite{yuan2021hrformer} enhance the backbone via applying the Transformer encoder to the backbone; TokenPose~\cite{li2021tokenpose} designs the pose estimation network in a ViT-style fashion by splitting image into patches and applying class tokens, which makes the pose estimation more explainable. These methods are all heatmap-based and use a heavy transformer encoder to improve the model capacity. In contrast, Poseur is a regression-based method with a lightweight transformer decoder. Thus, Poseur is more computational efficient while can still achieve high performance. 







PRTR~\cite{li2021PRTR} leverage the encoder-decoder structure in transformers to perform pose regression. PRTR is based on DETR~\cite{carion2020end}, i.e., it uses Hungarian matching strategy to find a bipartite matching between non class-specific queries and ground-truth joints.  It brings two issues: 1) heavy computational cost; 2) redundant queries for each instance. In contrast, \handle can alleviate both issues while achieving much higher performance.















\section{Method}


\begin{figure*}[t]
\centering 
\includegraphics[width=0.98\textwidth]{figures/arch.pdf}
\caption{\textbf{The architecture of \handle.}
The model directly predicts a sequence of keypoint coordinates in parallel by combining (a) backbone network with (b) keypoint encoder and (c) query decoder. (d) Residual Log-likelihood Estimation~\cite{li2021rle}. (e) The proposed uncertainty score for our method.
}
\label{fig:framework}
\end{figure*}

















\subsection{\handle Architecture}\label{sec:Architecture}






Our proposed pose estimator \handle aims to predict  human keypoint coordinates from a cropped single person image.
As shown in \cref{fig:difference}(c), The core idea of our method is to represent human keypoints with queries, \ie, each query corresponds to a human keypoint. The queries are input to the deformable attention module~\cite{zhu2020deformable}, which adaptively attends to the image features that most relevant to the query/keypoint. In this way, the information about a specific keypoint can be summarized and encoded into a single query, which is used to regress the keypoint coordinate later. As such, the issue of losing spatial information caused by the global average pooling in RLE~\cite{li2021human} (As shown in \cref{fig:difference}(b)) is well addressed.





Specifically, in \handle framework (shown in \cref{fig:framework}), two main components are added upon the backbone: a keypoint encoder and a query decoder. An input image is first encoded as dense feature maps with the backbone, which are followed by an FC layer to predict the rough keypoint coordinates, used as a set of rough proposals.
We denote the proposal coordinates as . Then, those proposals are used to initialize the keypoint-specific query  (where  is the embedding dimension) in the keypoint encoder. Finally, the feature maps from the backbone and  are sent into the query decoder to obtain the final features for the keypoints, each of which is sent into a linear layer to predict the corresponding keypoint coordinates.
In addition, unlike previous methods simply regressing the keypoint coordinates and applying the  loss for supervision, 
\handle, following RLE ~\cite{li2021human}, predicts a probability distribution reflecting the probability of the ground truth appearing in each location and supervise the network by maximum the probability on the ground truth location. Specifically, a location parameter  and a scale parameter  are predicted by \handle () for shifting and scaling the distribution generated by a flow model  (refer to~\cref{sec:loss}).  is the center of the distribution and can be regarded as the predicted keypoint coordinates.


\noindent\textbf{Backbone.} Our method is applicable to both CNN (e.g. ResNet~\cite{he2016deep}, HRNet~\cite{sun2019deep}) and transformer backbones (e.g. HRFormer~\cite{yuan2021hrformer}).  Given the backbone, multi-level feature maps are extracted and then fed into the query decoder. At the same time, a global average pooling operation is conducted in the last stage of the backbone and followed by an FC layer to regress the coarse keypoint coordinates  (normalized in ) and the corresponding scale parameter , supervised by Residual Log-Likelihood Estimation (RLE) process introduced in~\cref{sec:loss}.


\noindent\textbf{Keypoint encoder.} 
The keypoint encoder is used to initialize each query  for the query decoder. For initializing the query better, two keypoints' attributes, location and category, are encoded into the query in the keypoint encoder.
Specifically, first, for location attribute, we encode the rough x-y keypoint coordinates  with the fixed positional encodings, transforming the x-y coordinates to the sine-cosine positional embedding following ~\cite{vaswani2017attention}. The obtained tensor is denoted by ; second, for the category attribute,  learnable vectors , called class embedding, is used to represent K different categories separately. Finally, the initial queries  are generated by fusing the location and category attribute through element-wise addition of the positional and class embedding, \ie . 


However,  is just a coarse proposal, which sometimes goes wrong during inference. To make our model more robust for the wrong proposal, we introduce a query augmentation process, named \textit{noisy reference points sampling strategy}, used only during training. The core idea of noisy reference points sampling strategy is to simulate the case that the coarse proposals  goes wrong and force the decoder to located correct keypoint with wrong proposal. Specifically, during training, we construct two types of keypoint queries. The first type of keypoint query is initialized with the proposal ; the second type of keypoint query is initialized with normalized random coordinates  (noisy proposal). And then, both of two types query are processed equally in all following training stages. Our experiment shows that training the decoder network with noisy proposal  improves its robustness to errors introduced by coarse proposal  during the inference stage. Note, that during inference randomly initialized keypoint queries are not used.











\noindent\textbf{Query decoder.} 
In query decoder, query and feature map are mainly used to module the relationship between keypoints and input image. As shown in \cref{fig:framework}, the decoder follows the typical transformer decoder paradigm, in which,
there are N identical layers in the decoder, each layer consisting of self-attention, cross-attention and feed-forward networks (FFNs). The query  goes through these modules sequentially and generates an updated  as the input to the next layer. As in DETR\cite{carion2020end}, the self-attention and FFNs are a multi-head self-attention~\cite{vaswani2017attention} module and MLPs, respectively. 
For the cross-attention networks, we propose an efficient multi-scale deformable attention (EMSDA) module, based on MSDA proposed by Deformable DETR~\cite{zhu2020deformable}. Similar to MSDA, in EMSDA, each query learns to sample relevant features from the feature maps by given the sampling offset around a reference point (a pair of coordinates, and which will be introduced later); and then, the sampled features are summarized by the attention mechanism to update the query. Different from MSDA, which applies a linear layer to the entire feature maps and thus is less efficient, we found that it is enough to only apply the linear layer to the sampled features after bilinear interpolation. Experiments show that the latter can have a similar performance while being much more efficient. Specifically, EMSDA can be written as 

where ,  and  are the -th input query vector, the reference point offset of -th query and -th level of feature maps from the backbone; the dimension of each feature vector in  is .  represents -th attention head. ,  and  represent the number of feature map levels used in the decoder, the number of attention heads and the number of sampling points on each level feature map, respectively.  and  represent the attention weights and the sampling offsets of the -th head, -th level, -th query and -th sampling point, respectively; The query feature  is fed to a linear projection to generate  and .
 satisfies the limitation, .  is the function transforming the  to the coordinate system of the -th level features.  represents sampling the feature vector located in offset  on the feature map  by bilinear interpolation.  and  are two groups of trainable weights. The reference point  will be updated at the end of each decoder layer by applying a linear layer on . Note, the FC output  is leveraged as reference point for the initial query . For more details and computational complexity, we refer readers to our supplementary material. 




To sum up, the relations between different keypoints are modeled through a self-attention module, and the relations between the input image and keypoints are modeled through EMSDA module. Notably, the problem of feature misalignment in fully-connected regression is solved by EMSDA. 









\subsection{Training Targets and Loss Functions}\label{sec:loss}
Following RLE~\cite{li2021rle}, we calculate a probability distribution  reflecting the probability of the ground truth appearing in the location  conditioning on the input image , where  is the parameters of \handle and  is the parameters of a flow model. As shown in~\cref{fig:framework}(d), The flow model  is leveraged to reflect the deviation of the output from the ground truth  by mapping a initial distribution  to a zero-mean complex distribution . 
Then  is obtained by adding a zero-mean Laplace distribution  to .
The regression model  predictions the center , and scale  of the distribution. Finally, the distribution  is built upon  by shifting and rescaling  into , where . We refer readers to~\cite{li2021rle} for
more details.

Different from RLE~\cite{li2021rle}, we only use the proposal  for coarse prediction. This prediction is then updated by the query-based approach described above to generate an improved estimate . Both coarse proposal  and query decoder preditions  are supervised with the maximum likelihood estimation (MLE) process. The learning process of MLE optimizes the model parameters so as to make the observed ground truth  most probable. The loss function of FC predictions  can be defined as:

where  and  are the parameters of the backbone and flow model, respectively.
Similarly, the loss of distribution associated with query decoder preditions  can be defined as:

where  and  are the parameters of the query decoder and another flow model, respectively.
Finally, we sum the two loss functions to obtain the total loss:

where  is a constant and used to balance the two losses. We set  by default.







\subsection{Inference}\label{sec:score}
\noindent\textbf{Inference pipeline.} 
During the inference stage, \handle predicts the  for each keypoint as mentioned;  is taken as the predicted keypoint coordinates and  is used to calculate the keypoint confidence score.

\noindent\textbf{Prediction uncertainty estimation.} 
For heatmap-based methods,  e.g.  SimpleBaseline~\cite{xiao2018simple}, the prediction score of each keypoint is combined with a bounding box score to enhance the final human instance score:

where  is the final prediction score of the instance;  is the bounding box score predicted by the person detector,  is the -th keypoint score predicted by the keypoint detector and  is the total keypoint number of each human. 
Most previous regression-based methods~\cite{2014deeppose,sun2018integral} ignore the importance of the keypoint score.
As a result, compared to heatmap based methods, regression methods typically achieve higher recall but lower precision.
Given the same well-trained \handle model, adding the keypoint score brings  AP improvement ( AP vs.  AP) due to the significantly reduced number of false positives, and both of the models achieve almost the same average recall (AR).


Our model predicts a probability distribution over the image coordinates for each human keypoint. 
We define the -th keypoint prediction score  to be the probability of the keypoint falling into the region () near the prediction coordinate , \ie

where  is a hyperparameter that controls the size of the -adjacent interval, and  are the coordinates of the corresponding keypoint predicted by \handle.
In practice, running the normalization flow model during the inference stage would add more computational cost. We found that comparable performance can be achieved by shifting and re-scaling the zero-mean Laplace distribution  with query decoder predictions . So the probability density function can be rewritten as:

where  is the center of the Laplacian distribution and the predicted keypoint coordinates, and  is the scale parameter predicted by \handle. Finally,  can be written as:

Note that the score  on x-axis and y-axis will be calculated separately and then merged by a multiplication operation.





\section{Experiments}










\subsection{Implementation Details}
\noindent\textbf{Datasets.} 
Our experiments are mainly conducted on COCO2017 Keypoint Detection\cite{wang2018mscoco} benchmark, which contains about  person instances with 17 keypoints. 
We report results on the \emph{val} set for ablation studies and compare with other state-of-the-art methods on both of the \emph{val} set and \emph{test-dev} sets. The Average Precision (AP) based on Object Keypoint Similarity (OKS) is employed as the evaluation metric on COCO dataset. We also conduct experiments on MPII~\cite{mpii} dataset with Percentage of Correct Keypoint (PCK) as evaluation metric.



\noindent\textbf{Model settings.} 
Unless specified, ResNet-50\cite{he2016deep} is used as the backbone in ablation study. 
The size of input image is .
The weights pre-trained on ImageNet\cite{deng2009imagenet} are used to initialize the ResNet backbone. The rest parts of our network are initialized with random parameters. All the decoder embedding size is set as 256; 3 decoder layers are used by default.


\noindent\textbf{Training.}  All the models are trained with batch size 256 (batch size 128 for HRFormer-B due to the limited GPU memory), and are optimized by AdamW\cite{loshchilov2017decoupled} with a base learning rate of  decreased to  and  at the 255-th epoch and 310-th epoch and ended at the 325-th epoch; 
 and  are set to  and , respectively;
Weight decay is set to . 
Following Deformable DETR~\cite{zhu2020deformable}, the learning rate of the the linear projections for sampling offsets and reference points are multiplied by a factor of . Following RLE~\cite{li2021rle}, we adopt RealNVP~\cite{realnvp} as the flow model. Other settings follow that of mmpose~\cite{mmpose2020}. For HRNet-W48 and HRFormer-B, cutout~\cite{devries2017improved} and color jitter augmentation are applied to avoid over-fitting.


\noindent\textbf{Inference. }
Following conventional settings, we use the same person detector as in SimpleBaseline~\cite{xiao2018simple} for COCO evaluation.
According to the bounding box generated by the person detector, the single person image patch is cropped out from the original image and resized to a fix resolution, e.g.  . The flow model is removed during the inference. We set  in~\cref{equation:score} by default.













        

























        




\subsection{Ablation Study}



























\noindent\textbf{Initialization of keypoint queries.} 
We conduct experiments to verify the impact of initialization of keypoint queries. Deformable DETR~\cite{zhu2020deformable} introduces reference points that represent the location information of object queries. In their paper, reference points are 2-d tensors predicted from the 256-d object queries via a linear projection. We set this configuration as our baseline model. As shown in ~\cref{tab:source_of_init_ref_points}, the baseline model achieves 72.3 AP with 3 decoder layers, which is  AP lower than keypoint queries which initialized from coarse proposal .
This indicates that coarse proposal  provide a good initialization for the keypoint queries.



\setlength{\tabcolsep}{0.3pt} \begin{table*}[t]
    \caption{Ablation of proposed \handle on COCO \texttt{val2017} split. ``Ours": Using the fully convolutional layer at the end of backbone to regress the coarse proposal ; ``Noisy Reference Points": applying the noisy reference points sampling strategy in the keypoint encoder; ``Res-": -th level feature map of ResNet; ``": the number of decoder layers}
	\begin{center}
		\subfloat[Varying Initial Reference Points Methods\label{tab:source_of_init_ref_points}]{
            \begin{tabular}{c|c}
                \hline
                Initial Ref. Points   & {AP} \\
                \Xhline{2\arrayrulewidth}
                Def. DETR\cite{zhu2020deformable}  & 72.3 \\
                Ours   & 72.9 \\ \hline
            \end{tabular}
		}
		\hspace{1em}
		\subfloat[Varying the Noisy Reference Points \label{tab:cls_embed_noisy_sampling_robustness}]
		{
                \begin{tabular}{c|c}
                    \hline
                    Noisy Ref. Points & {AP} \\
                    \Xhline{2\arrayrulewidth}
                    \xmark  & 73.7 \\
                    \cmark & 74.3 \\
                    \hline
                \end{tabular}
		}
		\hspace{1em}
		\subfloat[Varying the Uncertainty Estimation \label{tab:score_estimation}]
		{
                    \begin{tabular}{c|c}
                        \hline
                        Uncertainty Esti.   & {AP} \\
                        \Xhline{2\arrayrulewidth}
                        RLE~\cite{li2021rle}   & 73.6 \\
                        Ours  & 74.7 \\
                        \hline
                    \end{tabular}
		}
		\hspace{1em}
		\subfloat[Varying the scale levels of input feature map for decoder \label{tab:feature_levels}]
		{
            		\begin{tabular}{cccc|cc|c}
                    \hline
                    Res2\;        & Res3\;       & Res4\;       & Res5\;        & Params & GFLOPs   & {AP} \\
                    \Xhline{2\arrayrulewidth}
                                &            &            & \cmark & 28.3M & 4.12 & 73.7 \\
                                &            & \cmark & \cmark & 28.7M & 4.18 & 74.2 \\
                                & \cmark & \cmark & \cmark & 28.9M & 4.28 & 74.4 \\
                    \cmark & \cmark & \cmark & \cmark & 29.0M & 4.48 & 74.7 \\
                    \hline
                    \end{tabular}
		}
		\hspace{0.1em}
		\subfloat[Varying the numbers of decoder layers \label{table: num_dec_layers}]
		{
                	\begin{tabular}{c|cc|l|ll}
                	\hline
                	 & Params & GFLOPs & AP & AP & AP \\
                	\Xhline{2\arrayrulewidth}
3 & 28.8M & 4.48 & 74.7  & 90.2 & 81.6 \\
                	4 & 30.2M & 4.51 & 75.3  & 90.5 & 82.1 \\
                	5 & 31.6M & 4.54 & 75.4  & 90.3 & 82.2 \\
                	6 & 33.1M & 4.57 & 75.4  & 90.5 & 82.2 \\
                	\hline
                	\end{tabular}
		}
	\end{center}
\end{table*}
\setlength{\tabcolsep}{0.4pt}














\noindent\textbf{Noisy reference points sampling strategy.} As mentioned in~\cref{sec:Architecture}, we apply the noisy reference points sampling strategy during the training. To validate its effectiveness, we perform ablation experiment on COCO, as show in ~\cref{tab:cls_embed_noisy_sampling_robustness}. The experiment result shows that the noisy reference points sampling strategy can improve the accuracy by 0.6 AP without adding any extra computational cost during inference.







\noindent\textbf{Varying the levels of feature map.} 
We explore the impact of feeding different levels of backbone features into the proposed query decoder. As shown in~\cref{tab:feature_levels}, the performance grows consistently with more levels of feature maps, \textit{e.g.},   73.7 AP, 74.2 AP,  74.4 AP,
74.7 AP for 
1, 2, 3, 4 levels of feature maps, respectively.







\noindent\textbf{Uncertainty estimation.} 
As mentioned in ~\cref{sec:score}, we redesign the prediction confidence score proposed in~\cite{li2021rle}. To study the effectiveness of the proposed score , we compare it with predictions without re-score and predictions with RLE score~\cite{li2021rle} using the same model. As shown in~\cref{tab:score_estimation}, the proposed method brings significant improvement (4.7 AP) to the model without uncertainty estimation, and outperforms the RLE score~\cite{li2021rle} by 1.0 AP.









\noindent\textbf{Varying decoder layers.} Here we study the effect of query decoder's depth.
Specifically, we conduct experiments by varying the number of decoder layers in Transformer decoder. 
As shown in ~\cref{table: num_dec_layers}, the performance grows at the first three layers and saturates at the sixth decoder layer. 




\begin{table*}[t] \caption{Comparison with heatmap methods by varying the backbone and the input resolution on the COCO \emph{val} set. ``SimBa": SimpleBaseline~\cite{xiao2018simple}. For (a), the input resolution is 256192 and the number of decoder layers is 5. For (b), we use ResNet-50 as backbone and the number of decoder layers is 3.}
	\begin{center}
		\subfloat[Varying the backbone\label{tab:com_hr_sb_tf}]{
            \begin{tabular}{c|c|c|l}
                \hline
                {Method} & {Backbone}  & GFLOPs & {AP}   \\
                \Xhline{2\arrayrulewidth}
                SimBa.  & MobileNet-V2   &4.55  & 65.9   \\
                \handle &MobileNet-V2    &0.52  & 71.9   \\
                \hline
                SimBa.  & ResNet-50      &8.27  & 72.4   \\
                \handle & ResNet-50      &4.54  & 75.4   \\
                \hline
                HRNet   & HRNet-W32      &7.68  &75.0 \\
                \handle & HRNet-W32      &7.95  & 76.9  \\ 
                \hline
        
            \end{tabular}
		}
\subfloat[Varying the input resolution \label{tab:input_size}]
		{
            \begin{tabular}{c|cccl}
                \hline
                Method & Input size & Params & GFLOPs  & AP \\
                \Xhline{2\arrayrulewidth}
                SimBa.~\cite{xiao2018simple} & 6464 & 34.0M & 0.69 & 31.4  \\
                \handle  & 6464 &28.8M & 0.49 & \textbf{47.9}   \\
                \hline
                SimBa.~\cite{xiao2018simple}  & 128128 & 34.0M &2.76 &59.3  \\
                \handle & 128128 & 28.8M & 1.55 & \textbf{67.1}  \\
                \hline
                SimBa.~\cite{xiao2018simple}  & 256192 & 34.0M & 8.26 & 71.0 \\
                \handle  & 256192 & 28.8M & 4.48 & \textbf{74.7}  \\
                \hline
            \end{tabular}
		}
	\end{center}
\end{table*}

\noindent\textbf{Varying the input size.} We conduct experiments to explore the robust of \handle under different input resolutions.~\cref{tab:input_size} compares \handle with SimpleBaseline, showing that our method consistently outperforms SimpleBaseline in all input sizes.
The results also indicate that heatmap-based method suffers larger performance drop with the low-resolution input. For example, the proposed method outperforms SimpleBaseline by 14.6 AP in 6464 input resolution. 









\subsection{Extensions: End-to-End Pose Estimation}
Our framework can easily extend to end-to-end human pose estimation, \ie, detecting multi-person poses without the manual crop operation. With \handle as a plug-and-play scheme, end-to-end top-down keypoint detectors can obtain additional improvement. Here, we take Mask-RCNN as example to show the superiority of our method. The original keypoint head of Mask R-CNN is stacked 8 convolutional layers, followed by a deconv layer and 2× bilinear upscaling, producing an output resolution of 5656. We replace the deconv layer by an average pooling layer and an FC layer like~\cite{li2021rle}. The output of the FC layer is used to produce initial coarse proposal . Then coarse proposal  is feed into the keypoint encoder and query decoder as described in \cref{sec:Architecture}. We randomly sample 600 queries per image for training efficiency. Note that we conduct EMSDA on multi-scale backbone feature maps, rather than on ROI features. The output of FC layer and transformer decoder are both supervised with RLE loss~\cite{li2021rle}.
We perform scale jittering~\cite{ghiasi2021simple} with random crops during training.
We train the entire network for 180,000 iterations, with a batchsize of 32 in total. Other parameters are the same as the Detectron2~\cite{wu2019detectron2}.
As shown in~\cref{tab:maskrcnn}, \handle outperforms the heatmap-based Mask R-CNN with ResNet 101 by 1.9 AP. \handle outperforms the state-of-the-art regression-based method, PointSet Anchor with HRNet-W48 by  AP.















\begin{table}[t]
	\centering
	\begin{minipage}[t]{0.52\linewidth}
		\centering
	    \caption{Comparison with \textbf{end-to-end top-down methods} on the COCO \emph{val} set. 
 denote flipping and multi-sacle testing. Reg: regression-based approach; HM: heatmap-based approach}\label{tab:maskrcnn}
	    \resizebox{1\linewidth}{!}{
		\begin{tabular}{c|c|c|ccc}
        \hline
        Method & Backbone & Type & AP & AP & AP \\
        \Xhline{2\arrayrulewidth}
        PRTR~\cite{li2021PRTR} & HRNet-W48 & Reg. & 64.9 & 87.0 & 71.7 \\
        Mask R-CNN~\cite{he2017mask} & ResNet-101 & HM. & 66.0 & {86.9} & 71.5 \\
        Mask R-CNN + RLE~\cite{li2021rle} & ResNet-101 & Reg. & {66.7} & 86.7 & {72.6} \\
        PointSet Anchor~\cite{wei2020point} & HRNet-W48 & Reg. & 67.0 & 87.3 & 73.5 \\
        {Mask R-CNN + \handle} & ResNet-101 & Reg. & {68.6} & {87.5} & {74.8} \\
{Mask R-CNN + \handle} & HRNet-W48 & Reg. & {70.1} & \textbf{88.0} & {76.5} \\
        {Mask R-CNN + \handle} & HRNet-W48 & Reg. & \textbf{70.8} & {87.9} & \textbf{77.0} \\
        \hline
        \end{tabular}}
	\end{minipage}
	\hspace{.2em}
	\begin{minipage}[t]{0.4\linewidth}
		\centering
		\caption{Comparisons on MPII validation set (PCKh@0.5). SimBa: SimpleBaseline~\cite{xiao2018simple}. Reg: regression-base approach; HM: heatmap-based approach}\label{tab:mpii}
		\resizebox{1\linewidth}{!}{
    	\begin{tabular}{l|c|c|c}
    	\hline
    	Method & Backbone& Type & Mean \\
        \Xhline{2\arrayrulewidth}
SimBa.~\cite{xiao2018simple}        & ResNet-152    &HM.&   \\
        HRNet~\cite{sun2019deep}            & HRNet-W32     &HM.&    \\
        TokenPose~\cite{li2021tokenpose}    & L/D       &HM.&  \\
Integral~\cite{sun2018integral}     & ResNet-101    &Reg.&87.3 \\
        PRTR~\cite{li2021PRTR}              & HRNet-W32     &Reg.&89.5 \\
        \handle                             & HRNet-W32     &Reg.& \textbf{90.5} \\
        \hline
\end{tabular}}
	\end{minipage}
\end{table}

\begin{table}[!t]
    \small
    \centering
	\caption{\textbf{Comparisons with state-of-the-art methods} on the COCO \emph{val} set.  Input size and the GFLOPs are calculated under top-down single person pose estimation setting. Unless specified, the number of decoder layers is set to 6. ``3 Dec.": three decoder layers.
}
    \resizebox{0.9\columnwidth}{!}{
		\smallskip\begin{tabular}{r |c|c|c|c|c|c|c|c}
		\hline
	    Method                                   & Backbone / Type  & Input Size   & GFLOPs   & AP & AP & AP & AP & AP \\
	    \hline
	    \multicolumn{5}{c}{\textbf{Heatmap-based methods}} \\
	    \hline
        SimBa.~\cite{xiao2018simple}  & ResNet-50        &  &  8.9         & 70.4 & 88.6 & 78.3 & 67.1 & 77.2 \\
        SimBa.~\cite{xiao2018simple}  & ResNet-152       &  &  15.7        & 72.0 & 89.3 & 79.8 & 68.7 & 78.9 \\
        HRNet~\cite{sun2019deep}          & HRNet-W32        &  &  7.1         & 74.4 & 90.5 & 81.9 & 70.8 & 81.0 \\
        HRNet~\cite{sun2019deep}          & HRNet-W48        &  &  32.9        & 76.3 & 90.8 & 82.9 & 72.3 & 83.4 \\
        TransPose~\cite{yang2021transpose}       & H-A6             &  &  21.8        & 75.8 &   -  &   -  &   -  &   -  \\
        TokenPose~\cite{li2021tokenpose}         & S-V2             &  &  11.6        & 73.5 & 89.4 & 80.3 & 69.8 & 80.5 \\
        TokenPose~\cite{li2021tokenpose}         & B                &  &  5.7         & 74.7 & 89.8 & 81.4 & 71.3 & 81.4 \\
        TokenPose~\cite{li2021tokenpose}         & L/D6             &  &  9.1         & 75.4 & 90.0 & 81.8 & 71.8 & 82.4 \\
        TokenPose~\cite{li2021tokenpose}         & L/D24            &  &  11.0        & 75.8 & 90.3 & 82.5 & 72.3 & 82.7 \\
HRFormer~\cite{yuan2021hrformer}       & HRFormer-T       &  &  1.3         & 70.9 & 89.0 & 78.4 & 67.2 & 77.8 \\
        HRFormer~\cite{yuan2021hrformer}       & HRFormer-S       &  &  2.8         & 74.0 & 90.2 & 81.2 & 70.4 & 80.7 \\
        HRFormer~\cite{yuan2021hrformer}       & HRFormer-B       &  &  12.2        & 75.6 & 90.8 & 82.8 & 71.7 & 82.6 \\
        HRFormer~\cite{yuan2021hrformer}       & HRFormer-B       &  &  26.8        & 77.2 & 91.0 & 83.6 & 73.2 & 84.2 \\
        UDP-Pose~\cite{huang2020devil}           & HRNet-W32       &  &  7.2        & 76.8 & 91.9 & 83.7 & 73.1 & 83.3 \\
        UDP-Pose~\cite{huang2020devil}           & HRNet-W48       &  &  33.0        & 77.8 & 92.0 & 84.3 & 74.2 & 84.5 \\
        \hline
        \multicolumn{5}{c}{\textbf{Regression-based methods}} \\
	    \hline
PRTR~\cite{li2021PRTR}                      & ResNet-50  &  & 11.0     & 68.2 & 88.2 & 75.2 & 63.2 & 76.2 \\
	    PRTR~\cite{li2021PRTR}                      & HRNet-W32  &  & 21.6     & 73.1 & 89.4 & 79.8 & 68.8 & 80.4 \\
        PRTR~\cite{li2021PRTR}                      & HRNet-W32  &  & 37.8     & 73.3 & 89.2 & 79.9 & 69.0 & 80.9 \\
		RLE~\cite{li2021human}                      & ResNet-50         &  & 4.0      & 70.5 & 88.5 & 77.4 & -    &  -   \\
		RLE~\cite{li2021human}                      & HRNet-W32 &  & ~7.1 & 74.3 & 89.7& 80.8 & -   & - \\
		Ours                                        & MobileNet-v2         &  &  0.5   & 71.9 & 88.9 & 78.6 & 65.2 & 74.3 \\
Ours                                          & ResNet-50         &  &  4.6     & 75.4 & 90.5 & 82.2 & 68.1 & 78.6 \\ Ours                                          & ResNet-152      &  &  11.9    & 76.3 & 91.1 & 83.3 & 69.1 & 79.5 \\ Ours                                        & HRNet-W32         &  &   7.4   & 76.9 & 91.0 & 83.5 & 70.1 & 79.7 \\ Ours                                        & HRNet-W48         &  &   33.6   & 78.8 & 91.6 & 85.1 & 72.1 & 81.8 \\ Ours (3 Dec.)                               & HRFormer-T         &  &  1.4    & 74.3 & 90.1 & 81.4 & 67.5 & 76.9 \\ Ours (3 Dec.)                               & HRFormer-S         &  &  3.0     & 76.6 & 91.0 & 83.4 & 69.8 & 79.4 \\ Ours                                        & HRFormer-B         &  & 12.6     & 78.9 & 92.0 & 85.7 & 72.3 & 81.7 \\ Ours                                        & HRFormer-B         &  & 27.4     & 79.6 & 92.1 & 85.9 & 72.9 & 82.9 \\ \hline
	\end{tabular}}
\label{tab:comparisons_with_sota_on_val}
\end{table}


\begin{table}[!t]
    \begin{center}
    \caption{\textbf{Comparison with top-down methods} on the COCO \emph{test-dev} set. The proposed paradigm outpeforms heatmap-based methods in various settings.
The input resolution of all methods is .}
    \resizebox{0.65\linewidth}{!}
    {\begin{tabular}{l|c|c|c|c|c|c}
		\hline
	    Method & Backbone  & AP & AP & AP & AP & AP \\
	    \hline
	    \multicolumn{7}{c}{\textbf{Heatmap-based methods}} \\
	    \hline
SimBa~\cite{xiao2018simple}          & ResNet-152        & 73.7 & 91.9 & 81.1 & 70.3 & 80.0 \\ HRNet~\cite{sun2019deep}                 & HRNet-W32         & 74.9 & 92.5 & 82.8 & 71.3 & 80.9 \\ HRNet~\cite{sun2019deep}                 & HRNet-W48         & 75.5 & 92.5 & 83.3 & 71.9 & 81.5 \\ TokenPose~\cite{li2021tokenpose}                & L/D24             & 75.9 & 92.3 & 83.4 & 72.2 & 82.1 \\ HRFormer~\cite{yuan2021hrformer}              & HRFormer-B        & 76.2 & 92.7 & 83.8 & 72.5 & 82.3 \\ UDP-Pose~\cite{huang2020devil}                  & HRNet-W48         & 76.5 & 92.7 & 84.0 & 73.0 & 82.4 \\ \hline
        \multicolumn{7}{c}{\textbf{Regression-based methods}} \\
	    \hline
	    PRTR~\cite{li2021PRTR}                          & ResNet-101        & 68.8 & 89.9 & 76.9 & 64.7 & 75.8 \\ PRTR~\cite{li2021PRTR}                          & HRNet-W32         & 71.7 & 90.6 & 79.6 & 67.6 & 78.4 \\ RLE~\cite{li2021human}                          & ResNet-152        & 74.2 & 91.5 & 81.9 & 71.2 & 79.3 \\ RLE~\cite{li2021human}                          & HRNet-W48 & 75.7 & 92.3 & 82.9 & 72.3 & 81.3 \\ Ours (6 Dec.)                                  & HRNet-W48         & 77.6 & 92.9 & 85.0 & 74.4 & 82.7 \\
Ours (6 Dec.)                                 & HRFormer-B        & \textbf{78.3} & \textbf{93.5} & \textbf{85.9} & \textbf{75.2}  & \textbf{83.4} \\
    \hline
	\end{tabular}
    }
    \end{center}
\label{tab:comparisons_with_sota_on_coco_test}
\end{table}

\subsection{Main Results}\label{sec:main_result}




\noindent\textbf{Gains on low-resolution backbone.}
In this part, we show the great improvement of \handle on non-HRNet paradigm backbone which encode the input image as low-resolution representation. All models and training settings are tightly aligned. The input resolution of all models is .

In~\cref{tab:com_hr_sb_tf}, \handle with ResNet-50 significantly outperforms SimpleBaseline, and \textit{it is even higher than HRNet-W32}, while the computational cost is much lower. Apart from that, \handle with the lightweight backbone MobileNet-V2 can achieve comparable performance with SimpleBaseline using ResNet-50 backbone. In contrast, the performance of the MobileNet-V2 based SimpleBaseline is much worse,  AP lower than our method with the same backbone. It is worth noting that the computational cost of \handle with MobileNet-V2 is only about one-ninth that of SimpleBaseline with the same backbone.

\noindent\textbf{Comparison with the state-of-the-art methods.}
We compare the proposed \handle with state-of-the-art methods on COCO and MPII dataset.
\handle outperforms all regression-based and heatmap-based methods when using the same backbone, and achieves state-of-the-art performance with HRFormer-B backbone, \ie,  AP on the COCO \emph{val} set and  AP on the COCO \emph{test-dev} set.  
\handle with HRFormer-B can even outperform the previous state-of-the-art UDP-Pose () by 1.1 AP on the COCO \emph{val} set, when using lower input resolution (). Quantitative results are reported in~\cref{tab:comparisons_with_sota_on_val} and \cref{tab:comparisons_with_sota_on_coco_test}.
On the MPII \emph{val} set, \handle with HRNet-W32 is 0.4 PCKh higher than heatmap-based method with HRNet-W32. Quantitative results are reported in~\cref{tab:mpii}.





























\section{Conclusion}

We have proposed a novel pose estimation framework named \handle built upon Transformers, which largely improves the performance of the regression-based pose estimation and bypasses the drawbacks of heatmap-based methods such as the non-differentiable post-processing and quantization error.
Extensive experiments on the MS-COCO and MPII benchmarks show that \handle can achieve state-of-the-art performance among both regression-based methods and heatmap-based methods.





\clearpage
\bibliographystyle{splncs04}
\bibliography{egbib}




\includepdf[pages=-]{supp.pdf}




\end{document}
