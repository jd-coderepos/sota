\documentclass{llncs}

\usepackage[T1]{fontenc}
\usepackage[latin2]{inputenc}
\usepackage[english]{babel}

\usepackage{dsfont, complexity} \usepackage{amsmath}
\usepackage{amssymb}
\usepackage{lmodern}
\usepackage{float}
\usepackage{graphicx}
\usepackage{tikz}
\usepackage{xcolor}
\usepackage{paralist}
\usetikzlibrary{arrows,decorations.markings,patterns,calc, positioning}

\newtheorem{ex}[theorem]{Example}
\newtheorem{cor}[theorem]{Corollary}
\newtheorem{defi}[theorem]{Definition}
\newtheorem{con}{Conjecture}
\newtheorem{ques}{Question}
\usepackage{algpseudocode}
\usepackage[ruled]{algorithm} 

\newcommand{\mycaption}[2]
 {\begin{center} \parbox{4in}{\caption{\small #2 \label{#1}}} \end{center}}

\begin{document}

\title{Improved Algorithmic Results for Unsplittable Stable Allocation 
Problems}
\author{\'{A}gnes Cseh\inst{1} \and Brian C. Dean\inst{2}}


\institute{Institute for Mathematics, TU Berlin
\and School of Computing, Clemson University}

\maketitle

\begin{abstract}
The stable allocation problem is a many-to-many generalization of the
well-known stable marriage problem, where we seek a bipartite
assignment between, say, jobs (of varying sizes) and machines (of
varying capacities) that is ``stable'' based on a set of underlying
preference lists submitted by the jobs and machines.  Building on the
initial work of \cite{dean_unsplit}, we study a natural
``unsplittable'' variant of this problem, where each assigned job must
be fully assigned to a single machine.  Such unsplittable bipartite
assignment problems generally tend to be NP-hard, including
previously-proposed variants of the unsplittable stable allocation
problem \cite{DBLP:journals/jco/McDermidM10}.  Our main result is to
show that under an alternative model of stability, the unsplittable
stable allocation problem becomes solvable in polynomial time;
although this model is less likely to admit feasible solutions than
the model proposed in \cite{DBLP:journals/jco/McDermidM10}, we show
that in the event there is no feasible solution, our approach computes
a solution of minimal total congestion (overfilling of all machines
collectively beyond their capacities).  We also describe a technique
for rounding the solution of a stable allocation problem to produce
``relaxed'' unsplit solutions that are only mildly infeasible, where
each machine is overcongested by at most a single job.  
\iffalse
\noindent \textbf{Keywords.} stable matchings, stable allocations,
rotations, unsplittable assignments
\fi
\end{abstract}







\section{Introduction}
Consider a bipartite assignment problem over a graph  involving the assignment of a set of jobs  to a set of
machines . Each job  has a processing time , 
each machine  has a capacity , and there is a capacity
 for each edge  governing the maximum amount of job
 that can be assigned to machine .  A feasible assignment of
jobs to machines is described by a function  such that 
\begin{enumerate}
\item  for all edges ,
\item  for all jobs , and
\item  for all machines .
\end{enumerate}
If  for all , we say the assignment
is \emph{unsplit}, since each assigned job is assigned in its entirety
to a single machine. We often forgo the use of edge capacities 
when discussing unsplit assignments, since an edge  can simply be
deleted if .

Problems of the form above have been extensively studied in the
algorithmic literature, where typical objectives are to find a
feasible assignment or one of maximum weight (maximizing a linear
objective function , where  is the
weight of edge ).  While the fractional (splittable)
variants of these problems are easy to solve in polynomial time via
network flow techniques, the unsplittable variants are somewhat more
interesting.  In linear time, one can greedily assign jobs arbitrarily
to machines until no further assignments are possible, thereby
producing a {\em maximal} assignment.  However, if we care about
finding an unsplit assignment of measurably good quality, the problem
becomes substantially harder.  It is NP-hard to find an unsplit
assignment of either maximum total size 
or of maximum weight; the former is a variant of the multiple subset
sum problem \cite{Caprara2000111}, and the latter is known as the
multiple knapsack problem \cite{DBLP:journals/siamcomp/ChekuriK05}.

In contrast to problems with explicit edge costs, the \emph{stable
  allocation problem} is an ``ordinal'' problem variant where the
quality of an assignment is expressed in a more game theoretic setting
via ranked preference lists submitted by the jobs and machines, with
respect to which we seek an assignment that is \emph{stable} (defined
shortly).  In this paper, we study the stable allocation problem in
the unsplittable setting, which was shown to be NP-hard in
\cite{DBLP:journals/jco/McDermidM10} using one natural definition for
stability.  We show here that by contrast, a different and more strict
notion of stability, proposed initially in \cite{dean_unsplit}, leads
to an  algorithm for the unsplit problem.  The tradeoff is
that under this different notion of stability, it is unlikely that
feasible solutions will exist.  However, we show that by relaxing the
problem to allow mildly infeasible solutions, our algorithm 
computes a ``relaxed'' unsplit stable solution (in~which each machine
is filled beyond its capacity by at most the allocation of a single
job) in which the total amount of overcongestion across all machines,
, is minimized (so
in particular, if there is a feasible solution with no congestion, we
will find it).

Through the work of several former authors
\cite{DinitzGG99,Skutella00,ShmoysT93}, the ``relaxed'' model has
become relatively popular in the context of unsplittable bipartite
assignment and unsplittable flow problems.  The standard approximation
algorithm framework (finding an approximately-optimal, feasible
solution) typically does not fit these problems, since finding any
feasible solution is typically NP-hard.  Instead, authors tend to
focus on pseudo-approximation results with minimal congestion per
machine or per edge.  Analogous results were previously developed for
unsplit stable allocation problems in \cite{dean_unsplit}, where an
unsplit stable allocation can be found in linear time in which each
machine is overcongested by at most a single job.  The model of
stability proposed in \cite{dean_unsplit} is the one we further
develop in this paper, and among all of these prior approaches
(including those for standard unsplittable bipartite assignment and
flows), it seems to be the only unsplit model studied to date in which
minimization of {\em total} congestion is possible in polynomial time.
Hence, there is a substantial algorithmic incentive to consider this
model, even though its notion of stability is less natural than in
\cite{DBLP:journals/jco/McDermidM10}.

In our ``relaxed'' unsplit model, we develop new structural and
algorithmic results by showing how to compute in  time a
``job-optimal'' assignment that maximizes the total size  of all
assigned jobs, and a ``machine-optimal'' assignment that minimizes
.  It is this machine-optimal solution that we show also
minimizes total congestion.  In order to produce potentially other
solutions (e.g., that might be more fair to both sides), we show also
a technique for ``rounding'' a solution of the fractional stable
allocation problem to obtain a relaxed unsplit solution.  Finally, we
comment on several mathematical properties of the set of all relaxed
unsplit solutions, showing that while they unfortunately seem to lack
the nice distributed lattice structure satisfied by solutions of the
stable matching and allocation problems, they do at least adhere to a
weakened form of the so-called ``rural hospital'' theorem, defined
shortly.

\iffalse

We review preliminary concepts and background material in the next
section, then introduce our structural and algorithmic results for
computing relaxed unsplit solutions maximizing or minimizing ,
showing how these can be used to solve the unsplittable stable
allocation problem in linear time.  Finally, we discuss our rounding
method for producing additional relaxed unsplit assignments.

\fi

\section{Background and Preliminaries}

\subsection{Stable Matching and Allocation Problems}

{\bf Stable Marriage.} The stable marriage (or stable matching)
problem takes place on a bipartite graph with men on one side and
women on the other, where each individual submits a strictly-ordered,
but possibly incomplete preference list of the members of the opposite
sex.  The goal is to find a matching that is \emph{stable}, containing
no \emph{blocking pair} -- an unmatched (man, woman) pair 
where  is either unmatched or prefers  to his current partner,
and likewise for .  

In their seminal paper~\cite{GS:1962}, Gale and Shapley describe a
simple  algorithm to find a stable matching for any instance.
The most typical incarnation of their algorithm generates a solution
that is ``man-optimal'' and ``woman-pessimal'', where each man is
matched with the best possible partner he could receive in any stable
matching, and each woman is matched with the worst possible partner
she could receive in any stable matching.  By reversing the roles of
the men and women, the algorithm can also generate a solution that is
simultaneously woman-optimal and man-pessimal.

\noindent {\bf Stable Allocation.} The stable allocation problem was
introduced by Ba\"iou and Balinski \cite{DBLP:journals/mor/BaiouB02}
as a high-multiplicity variant of the stable matching problem, where
we match non-unit elements with non-unit elements -- here, we speak of
matching jobs of varying size with machines of varying capacity.  Just
as before, jobs and machines submit strict preferences over their
outgoing edges in the bipartite assignment graph.  If job 
prefers machine  to machine , we write
.  A stable allocation in
this setting is a feasible allocation (as defined in the introduction)
where for every edge  with , either  is
fully assigned to machines at least as good as , or  is fully
assigned to jobs at least as good as~.  That is, there can be no
blocking edge  where  and both  and  would
prefer use more of this edge.  For sake of simplicity, we say that
edges with positive  value are in~. Machines with 
are \emph{saturated}. Later, when  occurs in the relaxed
version of the problem, we talk about \emph{over-capacitated}
machines. If any job prefers machine  to any of its allocated
machines, then  is called \emph{popular}, otherwise  is
\emph{unpopular}. Note that all popular machines must be saturated in
any stable allocation.

The stable allocation problem can be solved in  time
\cite{DBLP:journals/algorithmica/DeanM10}.  There can be many
different solutions for the same instance, but they all have the same
total allocation , and even stronger, the values of  and
 for each job and machine remain unchanged across all stable
allocations.  This holds for both stable marriage and stable
allocation, moreover, even for stable roommate, the non-bipartite version of the problem, and is known as the {\em rural hospital theorem}.  A
common application of stable matching in practice is the National
Resident Matching Program (NRMP), where medical school graduates in
the USA are matched with residency positions at hospitals via a
centralized stable matching procedure.  A consequence of the rural
hospital theorem is that if a less-preferred (typically rural)
hospital cannot fill its quota in some stable assignment, then there
is no stable assignment in which its quota will be filled.

Like the stable marriage problem, one can always find job-optimal,
machine-pessimal and job-pessimal, machine-optimal solutions.  To
define these notions for the stable allocation problem, Ba\"iou and
Balinski \cite{DBLP:journals/mor/BaiouB02} define an order on stable
solutions based on a {\em min-min criterion}, where a job  prefers
allocation  to allocation  if  implies
 for every  worse than  for .  A similar
relation can be defined for machines as well.  Stable
matchings~\cite{Knuth:1976:MSR} and stable
allocations~\cite{DBLP:journals/mor/BaiouB02} both form distributive
lattices with an ordering relation based on the min-min criterion.

\iffalse
Ba\"iou and Balinski
prove that each agent can compare any two fractional stable
allocations as a consequence of the rural hospital theorem.  
\fi

\subsection{Unsplittable Stable Allocation Problems}
An unsplit allocation  satisfies  for all
, so each job is assigned in its entirety to one machine.
For simplicity, we introduce a ``dummy'' machine  with high
capacity, which acts as the last choice for every job.  This lets us
assume without loss of generality that an unsplittable assignment
always exists in which every job is assigned.  In this context,
we define the size  of an assignment so that jobs assigned
to  do not count, since they are in reality unassigned.
In addition to the application of scheduling jobs in a non-preemptive
fashion, a motivating application for the unsplittable stable
allocation problem is in assigning personnel with ``two-body''
constraints.  For example, in the NRMP, a married pair of medical
school graduates might act as an unsplittable entity of size 2 (this
particular application has been studied in substantial detail in the
literature
\cite{Biro_emp,couples_survey,journals/jal/Ronn90,Roth84theevolution}).

From an algorithmic standpoint, one of the main results of this paper
is that how we define stability in the unsplit case seems quite
important.  In \cite{DBLP:journals/jco/McDermidM10}, the following
natural definition was proposed: an edge  is blocking if 
prefers  to its current partner, and if  prefers  over 
units of its current allocation.  Unfortunately, it was shown in
\cite{DBLP:journals/jco/McDermidM10} that this definition makes the
computation of an unsplit stable assignment NP-hard.  We therefore
consider an alternate, stricter notion of stability where edge  is
blocking if  prefers  to its current partner, and if  prefers
 over {\em any amount} of its current allocation.  That is, if 
would prefer to be assigned to  over its current partner, than 
must be saturated with jobs  prefers to .  As in the splittable
case, popular machines must therefore be saturated. Practice shows~\cite{Roth96} that if a hospital is willing to hire one person in a couple, but it has no free job opening for the partner, it is most likely amenable to make room for both applicants. Therefore, our definition of a blocking pair serves practical purposes.

The existence of an unsplit stable allocation cannot be guaranteed. A
simple instance where the unique stable allocation is fractional is
shown in Figure \ref{label5}.  The quota of
each job and machine is displayed next to the vertex, while the preference lists are displayed on the edges.

\begin{figure}[t]
\begin{center}
\begin{tikzpicture}[scale=0.75, transform shape]
\tikzstyle{vertex} = [circle, draw=black]
\tikzstyle{edgelabel} = [rectangle, fill=white]

\node[vertex, label={[label distance=0.1cm]180:{1}}] (j_1) at (0, 0) {};
\node[vertex, label={[label distance=0.1cm]0:{1}}] (m_1) at (4, 0) {};
\node[vertex, label={[label distance=0.1cm]180:{2}}] (j_2) at (0, 2) {};
\node[vertex, label={[label distance=0.1cm]0:{2}}] (m_2) at (4, 2) {};

\draw [] (j_2) -- node[edgelabel, near start] {2} node[edgelabel, near end] {1} (m_2);
\draw [] (j_2) -- node[edgelabel, near start] {1} node[edgelabel, near end] {1} (m_1);
\draw [] (j_1) -- node[edgelabel, near start] {1} node[edgelabel, near end] {2} (m_1);

\end{tikzpicture}
\mycaption{label5}{This instance admits an unsplit assignment, but 
the unique stable allocation is fractional.}
\end{center}
\end{figure}

\noindent {\bf Relaxed Unsplit Assignments.}  The downside of our
alternate definition of stability is that it is unlikely to allow
feasible unsplit stable allocations to exist in most large instances.
Therefore, we consider allowing mildly-infeasible solutions where each
machine can be over-capacitated by a single job -- a model popularized
by previous results in the approximation algorithm literature for
standard unsplittable assignment problems
\cite{DinitzGG99,Skutella00,ShmoysT93}, and introduced in the context
of unsplittable stable allocation by Dean et al.~\cite{dean_unsplit}.
Specifically, we say  is a \emph{relaxed unsplit assignment} if
 for every edge , and if for each
machine , removal of the least-preferred job assigned to  would
cause \footnote{The model introduced in
  \cite{dean_unsplit} allows , but we believe strict
  inequality is actually a better choice -- for mathematical reasons
  as well as from a modeling standpoint.  For example, the old
  definition applied to a hospital-resident matching scenario with
  married couples might cause a hospital to accept two more residents
  than its quota, while the new definition would only require
  accepting one more resident.  All of the
  results in \cite{dean_unsplit} hold with either definition.}.  Our
definition of stability extends easily naturally to the relaxed
setting: we say a relaxed unsplit assignment  is stable if for
every edge  with , either  is assigned to a machine
 prefers to , or 's quota is filled or exceeded with jobs 
prefers to .  Otherwise, if edge  with  is preferred
by  to its allocated machine and 's quota is not filled up with
better edges than~, then  \emph{blocks}~.

Note that the relaxed unsplit model differs from the non-relaxed
unsplit model with capacities inflated by , since stability
is still defined with respect to the original capacities.  It may be
best to regard ``capacities'' in this setting as constraints governing
start time, rather than completion time of jobs, since a machine below
its capacity is always willing to launch a new job, irrespective of
job size.  Similarly, a machine  views an edge  as blocking if
the machine is not fully saturated with jobs  prefers to , as
in this case  is willing to accept .  The ``capacity'' of a
machine therefore reflects the cutoff at which it feels content to
receive additional assignment versus when it can no longer accept
additional load.

\section{Machine-Optimal Relaxed Unsplit Assignments}
\label{sec:jmopt}

In \cite{dean_unsplit}, a version of the Gale-Shapley algorithm is
described to find the job-optimal relaxed unsplit stable
assignment~.  In this context, job-optimal means that
there is no relaxed unsplit stable assignment  such that any job
is assigned to a better machine in  than in~.
The implementation described in \cite{dean_unsplit} runs in  time, but  is also easy to achieve.  In this
section, we show how to define and compute a \emph{machine-optimal}
relaxed unsplit stable allocation  also in 
time, and we prove the following:

\begin{theorem}
\label{thm:card}
Among all relaxed unsplit stable allocations ,  is maximized
at  and minimized at .
\end{theorem}

\begin{figure}[t]
\begin{center}
\begin{minipage}{.3\textwidth}
\begin{tikzpicture}[scale=0.85, transform shape]
	\tikzstyle{vertex} = [circle, draw=black]
	\tikzstyle{edgelabel} = [rectangle, fill=white]

	\node[vertex, label={[label distance=0.1cm]180: {2}}] (j_1) at (0, 0) {};
	\node[vertex, label={[label distance=0.1cm]180: {1}}] (j_2) at (0, 2) {};
	\node[vertex, label={[label distance=0.1cm]180: {2}}] (j_3) at (0, 4) {};
	\node[vertex, label={[label distance=0.1cm]0: {2}}] (m_1) at (3, 1) {};
	\node[vertex, label={[label distance=0.1cm]0: {1}}] (m_2) at (3, 3) {};

	\draw [dashed] (j_3) -- node[edgelabel, near start] {2} node[edgelabel, near end] {1} (m_1);
	\draw [dashed] (j_2) -- node[edgelabel, near start] {2} node[edgelabel, near end] {1} (m_2);
	\draw [] (j_3) --node[edgelabel, near start] {1} node[edgelabel, near end] {2} (m_2);
	\draw [] (j_2) --  node[edgelabel, near start] {1} node[edgelabel, near end] {2}(m_1);
	\draw [] (j_1) -- node[edgelabel, near start] {1} node[edgelabel, near end] {3} (m_1);
	
\end{tikzpicture}

\vspace{0.8cm}

\begin{tikzpicture}[scale=0.85, transform shape]
	\tikzstyle{vertex} = [circle, draw=black]
	\tikzstyle{edgelabel} = [rectangle, fill=white]

	\node[vertex, label={[label distance=0.1cm]180: {2}}] (j_1) at (0, 0) {};
	\node[vertex, label={[label distance=0.1cm]180: {3}}] (j_2) at (0, 2) {};
	\node[vertex, label={[label distance=0.1cm]180: {1}}] (j_3) at (0, 4) {};
	
	\node[vertex, label={[label distance=0.1cm]0: {1}}] (m_1) at (3, 0) {};
	\node[vertex, label={[label distance=0.1cm]0: {3}}] (m_2) at (3, 2) {};
	\node[vertex, label={[label distance=0.1cm]0: {1}}] (m_3) at (3, 4) {};

	\draw [dashed] (j_3) -- node[edgelabel, near start] {1} node[edgelabel, near end] {2} (m_2);
	\draw [dashed] (j_2) -- node[edgelabel, near start] {1} node[edgelabel, near end] {2} (m_3);
	\draw [] (j_3) -- node[edgelabel, near start] {2} node[edgelabel, near end] {1} (m_3);
	\draw [] (j_2) -- node[edgelabel, near start] {2} node[edgelabel, near end] {1} (m_2);
	\draw [dashed] (j_1) -- node[edgelabel, near start] {1} node[edgelabel, near end] {3} (m_2);
	\draw [] (j_1) -- node[edgelabel, near start] {2} node[edgelabel, near end] {1} (m_1);
\end{tikzpicture}

\end{minipage}\hspace{3mm}\begin{minipage}{.3\textwidth}

\begin{tikzpicture}[scale=0.85, transform shape]
	\tikzstyle{vertex} = [circle, draw=black]
	\tikzstyle{edgelabel} = [rectangle, fill=white]
	\pgfmathsetmacro{\d}{1.8}

	\node[vertex, label={[label distance=0.1cm]180: {1}}] (j_1) at (0, 0) {};
	\node[vertex, label={[label distance=0.1cm]180: {2}}] (j_2) at (0, \d) {};
	\node[vertex, label={[label distance=0.1cm]180: {2}}] (j_3) at (0, \d*2) {};
	\node[vertex, label={[label distance=0.1cm]180: {1}}] (j_4) at (0, \d*3) {};
	\node[vertex, label={[label distance=0.1cm]180: {1}}] (j_5) at (0, \d*4) {};
	\node[vertex, label={[label distance=0.1cm]180: {2}}] (j_6) at (0, \d*5) {};
	\node[vertex, label={[label distance=0.1cm]180: {1}}] (j_7) at (0, \d*6) {};
	
	\node[vertex, label={[label distance=0.1cm]0: {1}}] (m_1) at (3, \d*1) {};
	\node[vertex, label={[label distance=0.1cm]0: {2}}] (m_2) at (3, \d*2) {};
	\node[vertex, label={[label distance=0.1cm]0: {2}}] (m_3) at (3, \d*3) {};
	\node[vertex, label={[label distance=0.1cm]0: {2}}] (m_4) at (3, \d*4) {};
	\node[vertex, label={[label distance=0.1cm]0: {1}}] (m_5) at (3, \d*5) {};
	
	\draw [dashed] (j_1) -- node[edgelabel, near start] {2} node[edgelabel, near end] {1} (m_1);
	\draw [dashed] (j_2) -- node[edgelabel, near start] {2} node[edgelabel, near end] {1} (m_2);
	\draw [dashed] (j_3) -- node[edgelabel, near start] {1} node[edgelabel, near end] {3} (m_3);
	\draw [dashed] (j_4) -- node[edgelabel, near start] {2} node[edgelabel, near end] {2} (m_3);
	\draw [dashed] (j_5) -- node[edgelabel, near start] {1} node[edgelabel, near end] {3} (m_4);
	\draw [dashed] (j_6) -- node[edgelabel, near start] {1} node[edgelabel, near end] {2} (m_5);
	\draw [dashed] (j_7) -- node[edgelabel, near start] {1} node[edgelabel, near end] {2} (m_4);
	
	\draw [] (j_1) -- node[edgelabel, near start] {1} node[edgelabel, near end] {2} (m_2);
	\draw [] (j_2) -- node[edgelabel, near start] {1} node[edgelabel, near end] {2} (m_1);
	\draw [] (j_3) to[out=0,in=-110] node[edgelabel, near start] {1} node[edgelabel, near end] {3}  (m_3);
	\draw [] (j_4) -- node[edgelabel, near start] {1} node[edgelabel, near end] {3} (m_2);
	\draw [] (j_5) -- node[edgelabel, near start] {2} node[edgelabel, near end] {1} (m_3);
	\draw [] (j_6) -- node[edgelabel, near start] {2} node[edgelabel, near end] {1} (m_4);
	\draw [] (j_7) -- node[edgelabel, near start] {2} node[edgelabel, near end] {1} (m_5);
\end{tikzpicture}
\end{minipage}\hspace{3mm}\begin{minipage}{.35\textwidth}
\begin{tikzpicture}[scale=0.85, transform shape]
	\tikzstyle{vertex} = [circle, draw=black]
	\tikzstyle{edgelabel} = [rectangle, fill=white]
	\pgfmathsetmacro{\d}{1.8}
	\pgfmathsetmacro{\b}{3}

	\node[vertex, label={[label distance=0.1cm]180: {1}}] (j_1) at (0, 0) {};
	\node[vertex, label={[label distance=0.1cm]180: {2}}] (j_2) at (0, \d) {};
	\node[vertex, label={[label distance=0.1cm]180: {1}}] (j_3) at (0, \d*2) {};
	\node[vertex, label={[label distance=0.1cm]180: {2}}] (j_4) at (0, \d*3) {};
	\node[vertex, label={[label distance=0.1cm]180: {3}}] (j_5) at (0, \d*4) {};
	\node[vertex, label={[label distance=0.1cm]180: {1}}] (j_6) at (0, \d*5) {};
	\node[vertex, label={[label distance=0.1cm]180: {2}}] (j_7) at (0, \d*6) {};
	
	\node[vertex, label={[label distance=0.1cm]0: {1}}] (m_1) at (\b, \d*0.5) {};
	\node[vertex, label={[label distance=0.1cm]0: {2}}] (m_2) at (\b, \d*1.5) {};
	\node[vertex, label={[label distance=0.1cm]0: {2}}] (m_3) at (\b, \d*2.5) {};
	\node[vertex, label={[label distance=0.1cm]0: {3}}] (m_4) at (\b, \d*3.5) {};
	\node[vertex, label={[label distance=0.1cm]0: {1}}] (m_5) at (\b, \d*4.5) {};
	\node[vertex, label={[label distance=0.1cm]0: {1}}] (m_6) at (\b, \d*5.5) {};
	
	\draw [dashed] (j_1) -- node[edgelabel, near start] {2} node[edgelabel, near end] {1} (m_1);
	\draw [dashed] (j_2) -- node[edgelabel, near start] {2} node[edgelabel, near end] {1} (m_2);
	\draw [dashed] (j_3) -- node[edgelabel, near start] {2} node[edgelabel, near end] {2} (m_3);
	\draw [dashed] (j_4) -- node[edgelabel, near start] {1} node[edgelabel, near end] {3} (m_4);
	\draw [dashed] (j_5) -- node[edgelabel, near start] {1} node[edgelabel, near end] {2} (m_5);
	\draw [dashed] (j_6) -- node[edgelabel, near start] {1} node[edgelabel, near end] {2} (m_4);
	\draw [dashed] (j_7) -- node[edgelabel, near start] {2} node[edgelabel, near end] {1} (m_6);
	\draw [dotted] (j_7) -- node[edgelabel, very near start] {1} node[edgelabel, very near end] {3} (m_3);
	
	\draw [] (j_1) -- node[edgelabel, near start] {1} node[edgelabel, near end] {2} (m_2);
	\draw [] (j_2) -- node[edgelabel, near start] {1} node[edgelabel, near end] {2} (m_1);
	\draw [] (j_3) -- node[edgelabel, near start] {1} node[edgelabel, near end] {3} (m_2);
	\draw [] (j_4) -- node[edgelabel, near start] {2} node[edgelabel, near end] {1} (m_3);
	\draw [] (j_5) -- node[edgelabel, near start] {2} node[edgelabel, near end] {1} (m_4);
	\draw [] (j_6) -- node[edgelabel, near start] {2} node[edgelabel, near end] {1} (m_5);
	\draw [] (j_7) to[in=130, out=30] node[edgelabel, near start] {2} node[edgelabel, near end] {1}  (m_6);
	
\end{tikzpicture}
\end{minipage}
\mycaption{label6}{The upper-left instance admits two relaxed unsplit solutions differing in
cardinality.  The lower-left example is evidence against a rural hospital theorem.  The graph in the middle shows two incomparable relaxed unsplit solutions. The last instance is a counterexample showing the difficulty of formulating join and meet operations. The first and third graphs illustrate instances of NRMP.}
\end{center}
\end{figure}

One of the main challenges with computing a machine-optimal assignment
is defining machine-optimality.  In the stable allocation problem,
existence of a machine-optimal solution follows from the fact that all
stable solutions form a distributive lattice under the standard
min-min ordering relationship introduced in
\cite{DBLP:journals/mor/BaiouB02}.  However, this ordering seems to
depend crucially on the existence of a rural hospital theorem, which
no longer holds in the relaxed unsplit case, since relaxed unsplit
stable assignments may differ in cardinality, as shown in the
upper-left example in Figure \ref{label6}.  The dashed edges form a
stable solution of size~3, while the remaining edges build another
stable solution of size~6. Even an appropriately relaxed version of
the rural hospital theorem seems difficult to formulate over 
relaxed instances: machines can be saturated or even over-capacitated
in one relaxed unsplit stable solution, while being empty in another
one. The lower-left example in the figure shows such an instance: the
two stable assignments are denoted with the same line types, and 
is the machine that has different positions in them.  Nonetheless,
we can still prove a result in the spirit of the rural hospital theorem,
which we discuss further in Section \ref{rural_hospital}.

Without an ``exact'' rural hospital theorem, comparing two allocations
using the original min-min ordering seems problematic, and indeed one
can construct instances where two relaxed unsplit stable solutions are
incomparable according to this criterion.  For example, the instance
on the right in Figure \ref{label6} shows two relaxed unsplit
solutions (indicated with dotted and solid edges) that are
incomparable for machine~. We therefore adopt a different but
nonetheless natural ordering relation: \emph{lexicographical
  order}. We say that machine  prefers unsplit allocation  to
allocation  if the best edge in  belongs
to~, where  denotes the symmetric difference
operation.  The opposite ordering relation is based on the position of
jobs, and since jobs are always assigned to machines in an unsplit
fashion, the lexicographic and min-min relations are actually the same
from the job's perspectives; hence, ``job optimal'' means the same
thing under both.  The lexicographical position of the same agent in
different allocations can always be compared, and we say a relaxed
stable solution  is \emph{machine-optimal} if it is at least as
good for all machines as any other relaxed stable assignment (although
we still need to show that such a solution always exists).

\subsection{The Reversed Gale-Shapley Algorithm}

For the classical stable marriage problem, the Gale-Shapley algorithm
can be reversed easily, with women proposing instead of men, to obtain
a woman-optimal solution.  We show that this idea can be generalized
(carefully accounting for multiple assignment and congestion among
machines) to compute a machine-optimal relaxed unsplit stable
assignment.  Pseudocode for the algorithm appears in Figure \ref{rev_gs}.

\begin{figure}[t]
\begin{center}
\begin{algorithmic}[1]
	\State  for all ,  for every other  
	\While{ with a non-empty preference list}
		\State  proposes to its best job  with 
		\If{ prefers  to its current partner}
			\State 
			\State  for 
		\EndIf
			\State delete  from 's preference list
	\EndWhile
\end{algorithmic}
\vspace*{-0.1in}
\end{center}
\mycaption{rev_gs}{Reversed relaxed unsplit Gale-Shapley algorithm.}
\end{figure}

\begin{claim}
The algorithm terminates in  time.
\end{claim}

\begin{proof}
In each step, a job is deleted from a machine's preference
list. 
\end{proof}

\begin{claim}
The algorithm produces an allocation  that is a relaxed unsplit
stable assignment.
\end{claim}

\begin{proof}
First, we check the three feasibility constraints for~. Since
proposals are always made with  and refusals are always full
rejections, the quota constraints of the jobs may not be
violated. Moreover, each job is assigned to exactly one
machine. Machines can be over-capacitated, but deleting the worst job
from their preference list results in an allocation under their quota. Otherwise the machine would not have proposed along
the last edge.
	
If  is unstable, then there is an empty edge 
blocking~. During the execution,  must have proposed
to~. This offer was rejected, because  already had a better
partner in the current allocation. Since jobs monotonically improve
their position in the assignment, this leads to a contradiction.
\end{proof}

\begin{claim}
The output  is the machine-optimal relaxed unsplit stable
assignment. That is, no machine has a better lexicographical position
in any other relaxed unsplit stable assignment than in~.
\end{claim}

\begin{proof}
Assume that there is a relaxed unsplit stable assignment~, where
some machines come better off than in~. To be more precise, in the
symmetric difference , the best edge incident to these
machines belongs to~. When running the reversed relaxed unsplit
Gale-Shapley algorithm, there is a step when the first such edge
 carries a proposal from  but gets rejected. Otherwise,
 filled up or exceeded its quota in  with only better edges
than~. Let us consider only this edge first and denote the
feasible, but possibly unstable relaxed allocation produced by the
algorithm so far by~.

When  refused~, it already had a partner  in~,
better than~. Even if there is no guarantee that , it
is sure that  and  does not block~, though
 for~. It is
only possible if  is saturated or over-capacitated in  with
edges better than~. Since ,  may not contain
all of these edges, otherwise  is congested in  beyond the
level required for a relaxed unsplit assignment. During the execution
of the reversed relaxed unsplit Gale-Shapley algorithm,  proposed
along all of these edges and got rejected by at least one of
them. This edge is never considered again, it may not enter 
later. Thus,  is not the first edge in  that was
rejected in the algorithm.
\end{proof}

With this, we completed the constructive proof of the following theorem:

\begin{theorem}
\label{m_opt}
The machine-optimal relaxed unsplit stable assignment
 can be computed in  time.
\end{theorem}

\subsection{Properties of the Job- and Machine-Optimal Solutions}

\begin{theorem}
\label{th:opt_pess}
The job-optimal relaxed unsplit stable assignment  is
the machine-pessimal relaxed unsplit stable assignment and vice versa,
the machine-optimal relaxed unsplit stable assignment
 is the job-pessimal relaxed unsplit stable
assignment.
\end{theorem}

\iffalse
\begin{figure}[t]
\begin{center}
\begin{minipage}{.45\textwidth}
\begin{tikzpicture}[scale=0.75, transform shape]
	\tikzstyle{vertex} = [circle, draw=black]
	\pgfmathsetmacro{\d}{1.8}

	\node[vertex, label={[label distance=1cm]180:{}}] (j) at (0, 0) {};
	\node[vertex, label={[label distance=1cm]0:{x_0 \cap x'}}] (m_1) at (4, 0) {};
	\node[vertex, label={[label distance=1cm]0:{x'}}] (m_0) at (4, 2) {};

	\draw [dashed] (j) -- node[above] {} node[below = 1cm] {\bf (a)} (m_1);
	\draw [] (j) -- node[above] {} (m_0);
	\draw [] (m_1) -- (3.1, -0.5);
	\draw [dashed] (m_0) -- (3.3, 1.3);
	\draw [dashed] (m_0) -- (3.6, 1.2);
\end{tikzpicture}
\vspace{6cm}
\begin{tikzpicture}[scale=0.75, transform shape]
	\tikzstyle{vertex} = [circle, draw=black]
	\node[vertex,  label={[label distance=0.5cm]180:{}}]  (j) at (0, 0) {};
	\node[vertex]  (j') at (0, -2) {};
	\node[vertex,  label={[label distance=0.5cm]0:{}}]  (m) at (4, 0) {};
	\node[]  (m') at (4, 2) {
	\sum_{m \in M}{x(m)} &\geq \sum_{m \in M}{x_{\text{mopt}}(m)}\\
	\sum_{m \notin M_u} {x(m)} + \sum_{m \in M_u} {x(m)} &\geq \sum_{m \notin M_u} {x_{\text{mopt}}(m)} + \sum_{m \in M_u} {x_{\text{mopt}}(m)}\\
	\sum_{m \notin M_u} {x(m)} - \sum_{m \notin M_u} {x_{\text{mopt}}(m)}&\geq \sum_{m \in M_u} {x_{\text{mopt}}(m)} - \sum_{m \in M_u} {x(m)}\\
	\sum_{m \notin M_u} {(x(m)-q(m))} - \sum_{m \notin M_u} {(x_{\text{mopt}}(m)-q(m))}&\geq \sum_{m \in M_u} {x_{\text{mopt}}(m)} - \sum_{m \in M_u} {x(m)}
	
At this point, we investigate the sign of both sides of the last
inequality. The core of our proof is to show that for each 
and relaxed stable solution~, . This
result, proved below, has two benefits. On one hand, the term
on the right hand-side of the last inequality is
non-negative. Therefore, the inequality implies that the total
congestion on machines in  is minimized at~. On the other hand, no machine in  is
over-capacitated in any relaxed solution. Thus, the total congestion
is minimized~at~.
\end{proof}

\begin{lemma}
\label{rh_part1}
 For every  and relaxed solution~, the inequality
  holds.
\end{lemma}
	
\begin{proof}
Suppose that there is a machine  for which
 for some relaxed solution~. Since 
is unsaturated in , it is unpopular. On the other
hand, there is at least one job  for which . As  is unpopular in~,  is
allocated to a better machine in  than in~. Since
 is the job-pessimal solution, we derived a
contradiction.
\end{proof}

\subsection{A Variant of the ``Rural Hospital'' Theorem}
\label{rural_hospital}
In the relaxed unsplit case, we have provided counterexamples against
an exact rural hospital theorem (e.g., where all machines have the
same amount of allocation in all relaxed unsplit allocations) or even
a weakened theorem stating that all unsaturated / congested machines
have the same status in all relaxed unsplit allocations. The examples in Figure~\ref{label6} also show that no similar property holds for the jobs' side either. Lemma~\ref{rh_part1} above however suggests an alternate variant of ``rural
hospital'' theorem that does hold.

\begin{theorem}
A machine  that is not saturated in  will not be
saturated in every relaxed unsplit stable solution, and a machine 
that is over-capacitated in  must at least be
saturated in every relaxed unsplit stable solution.
\end{theorem}

\begin{proof}
The first part is shown by Lemma \ref{rh_part1}.  For the second part,
consider a machine  that is over-capacitated in 
but has  in some relaxed unsplit allocation .
Consider any job  in , and note that
since  is job-optimal,  prefers  to its partner
in .  Hence,  blocks .
\end{proof}

As of the jobs' side, Theorem~\ref{th:opt_pess} already guarantees that if a job is unmatched in , then it is unmatched in all relaxed stable solutions and similarly, if it is matched in , then it is matched in all relaxed stable solutions.



\section{Rounding Algorithms}
\label{sec:rot}

We have seen now how to compute  and
 in linear time.  We now describe how to find
potentially other relaxed unsplit solutions by ``rounding'' solutions
to the (fractional) stable allocation problem.  For example, this
could provide a heuristic for generating relaxed unsplit solutions
that are more balanced in terms of fairness between the jobs and
machines.  Our approach is based on augmentation around
\emph{rotations}, alternating cycles that are commonly used in stable
matching and allocation problems to move between different stable
solutions (see, e.g., \cite{DBLP:journals/algorithmica/DeanM10,GusfieldI89}).

We begin with a stable allocation  with  for every job
, thanks to the existence of a dummy machine.  For each job 
that is not fully assigned to its first-choice machine, we define its
\emph{refusal edge}  to be the worst edge  incident to 
with . Jobs with refusal edges also have \emph{proposal
  edges} -- namely all their edges ranked better than .  Recall
that a machine with incoming proposal edges is said to be
\emph{popular}.  We call a machine {\em dangerous} if it is
over-capacitated and has zero assignment on all its incoming proposal
edges.

\begin{claim}
\label{claim:structure_of_h}
Consider a popular machine  in some fractional stable
allocation~. Amongst all proposal edges incoming to , at most
one has positive allocation value in , and this positive proposal
edge is ranked lower on 's preference list than any other edge
into  with positive allocation.
\end{claim}

\begin{proof} Let  be proposal 
edges such that  and  are both positive. Note that
 blocks , since  and  have worse allocated edges
in~. A similar argument implies the last part of the claim.
\end{proof}

Our algorithm proceeds by a series of augmentations around rotations,
defined as follows.  We start from a popular, non-dangerous machine
 (if no such machine exists, the algorithm terminates, having
reached an unsplit solution).  Since  is popular and non-dangerous,
it has incoming proposal edges with positive allocation, and due to
the preceding claim, it must have exactly one such edge .  We
include  as well as 's refusal edge  in our partial
rotation, then continue building the rotation from  (again finding
an incoming proposal edge, etc.).  We continue until we close a cycle,
visiting some machine  visited earlier (in which case we
keep just the cycle as our rotation, not the edges leading up to the
cycle), or until we reach a machine  that is unpopular or
dangerous, where our rotation ends.

To enact a rotation, we increase the allocation on its proposal edges
by  and decrease along the refusal edges by
, where  is chosen to be as large as
possible until either (i) a refusal edge along the rotation reaches
zero allocation, or (ii) a dangerous machine at the end of the
rotation drops down to being exactly saturated from being
over-capacitated, and hence ceases to be dangerous.  We call case (i)
a ``regular'' augmentation.  This concludes the algorithm description.

\iffalse

\begin{algorithm}[H]
\renewcommand{\thealgorithm}{}
\caption{Relaxed unsplit stable assignment via rotations}
\label{alg:unsplit_rot}
\begin{algorithmic}[1]
	\State initialize , , 
	\While{ with a proposal edge  with  }
	\While{ has a best proposal edge }
		\State\label{add_edge} , , 
		\If{ is unpopular}
			\State \Call{augment}{, }
		\ElsIf{ is listed twice on }
			\State  part of  between the two appearances of 
			\State \Call{augment}{, }
		\ElsIf{ is dangerous}
			\If{}
				\State \Call{augment}{, }
			\EndIf
		\EndIf
		\EndWhile
		\State \Call{augment}{, }
	\EndWhile
\end{algorithmic}
\end{algorithm}

\begin{algorithmic}
	\Procedure{augment}{, }
		\State augment along  with value 
		\State update , , 
	\EndProcedure
\end{algorithmic}


\fi

\begin{claim}
\label{cl:rot_term}
The algorithm terminates after  augmentations.
\end{claim}

\begin{proof} 
Jobs remain fully allocated during the whole procedure, and their
lexicographical positions never worsen.  With every regular
augmentation, some edge stops being a refusal edge, and will never
again be increased or serve as a proposal or refusal edge.  We can
therefore have at most  regular augmentations.  Furthermore, a
machine can only become dangerous if one of its incoming refusal
pointers reaches zero allocation, so the number of newly-created
dangerous machines over the entire algorithm is bounded by .
Hence, the number of non-regular augmentations is at most .
\end{proof}

\begin{claim}
The final allocation  is a feasible relaxed unsplit assignment.
\end{claim}
	
\begin{proof} 
Since we start with a feasible assignment and jobs never lose or gain
allocation, the quota condition on jobs cannot be harmed. If there is
any edge  with , then  has at least two
positive edges, the better one must be a positive proposal edge. This
contradicts the termination condition, and hence  is unsplit.
	
We now show that deleting the worst job from each machine results in
an allocation strictly below the machine's quota. It is clearly true
at the beginning, where no machine is over-capacitated (since 
starts out as a feasible stable allocation). The only case when 
increases is when  is the first machine on a rotation. As such, 
has a positive proposal edge , which is also its worst allocated
edge, due to our earlier claim.  
\begin{itemize}
\item If  is not over-capacitated when choosing the
  rotation, then even if  rises as high as , this
  increases  by strictly less than . Thus, deleting~,
  the worst allocated edge of , guarantees that  sinks
  under~.
\item If  is saturated or over-capacitated when choosing the
  rotation, then  would have been the best proposal edge of 
  earlier, when  was not greater than~. Thus, assigning
   entirely to  does not harm the relaxed quota condition. Let
  us consider the last step as  exceeded~. Again,  was
  the starting vertex of an augmenting path, having a positive
  proposal edge. If it was~, our claim is proved. Otherwise 
  became over-capacitated while  was zero, and then increased
  the allocation on~. But between those two operations, 
  had to become dangerous, because it switched its best proposal edge
  to~. Dangerous machines never start alternating paths. Thus, we
  have a contradiction to the fact that we considered the last step
  when  exceeded~.
\end{itemize}\end{proof}

\begin{claim}
The final allocation  is stable.
\end{claim}

\begin{proof} 
Suppose some edges block~. Since we started with a stable
allocation, there was a step during the execution of the algorithm
when the first edge  became blocking. Before this step, either 
or  was saturated or over-capacitated with better edges
than~. The change can be due to two reasons:
\begin{enumerate}
	\item  gained allocation on an edge worse than , or
	\item  gained allocation on an edge worse than~.
\end{enumerate}
As already mentioned, 's lexicographical position never worsens:
 always holds. The second
event also may not occur, because machines always play their best
response strategy. An edge  that becomes blocking when allocation
is increased on an edge worse than it, was already a proposal edge
before. Thus,  would have chosen~, or an edge better than 
to add it to the augmenting path.
\end{proof}

Since each augmentation requires  time and there are 
augmentations, our rounding algorithm runs in  total time.
If desired, dynamic tree data structures can be used (much like in
\cite{DBLP:journals/algorithmica/DeanM10}) to augment in 
time, bringing the total time down to just .  

Although jobs improve their lexicographical position in each rotation,
the output of the algorithm is not necessarily~. In
fact, even  can be reached via this approach.
Ideally, this approach can serve as a heuristic to generate many other
relaxed unsplit stable allocations, if run from a variety of different
initial stable solutions .

\iffalse
 since
Machines always increase the allocation value on their best positive
proposal edge. Thus, if the stable fractional allocation in the input
was close to the machine-optimal stable solution, then these
fractional edges might well be amongst the worst choices of the
jobs. A stable unsplit assignment can be reached before any
augmentation would be performed along empty proposal edges.
\fi

\iffalse

\begin{center}
\begin{tikzpicture}[scale=0.75, transform shape]
\tikzstyle{vertex} = [circle, draw=black]

\node[vertex, label={[label distance=0.1cm]180:{2}}, label={[label distance=0.8cm]180:{}}] (j_1) at (0, 0) {};
\node[vertex, label={[label distance=0.1cm]0:{1}}, label={[label distance=0.8cm]0:{}}] (m_1) at (4, 0) {};
\node[vertex, label={[label distance=0.1cm]180:{2}}, label={[label distance=1cm]180:{}}] (j_2) at (0, 2) {};
\node[vertex, label={[label distance=0.1cm]0:{1}}, label={[label distance=1cm]0:{}}] (m_2) at (4, 2) {};

\draw [dashed] (j_2) -- (m_2);
\draw [] (j_2) -- (m_1);
\draw [] (j_1) -- (m_2);
\draw [dashed] (j_1) -- (m_1);

\end{tikzpicture}
\end{center}



\section{Conclusions and Open Questions}
While we have shown how to efficiently compute job-optimal and
machine-optimal relaxed unsplit stable solutions, it remains an open
question whether there are efficient methods for computing relaxed
unsplit stable solutions that are provably ``fair'' to both sides, or
possibly that also optimize a linear edge weight function.  The
apparent lack of an underlying lattice structure seems to create
difficulties here.  One can also consider generalizations of the
unsplit stable allocation model that have been considered more
extensively for stable marriages, such as ties or restricted edges.

There are also some more fundamental modeling questions to sort out,
regarding what is the ideal ``unsplit'' model for stable allocation.
The relaxed model seems well behaved from an algorithmic standpoint,
but produces mildly-infeasible solutions.  The definition of unsplit
stability in \cite{DBLP:journals/jco/McDermidM10} leads to an NP-hard
problem, where our definition leads to a linear-time solution but its
more restrictive nature is likely to cause many real-world instances
not to admit unsplit stable solutions.  Perhaps there are even better
ways to balance algorithmic tractability with model flexibility.
\fi

\iffalse

\section{Conclusion and open questions}

In our present work, we reformulated the definition of stable unsplit
allocations. Several basic properties of stable matchings and
allocations are discussed on the relaxed setting. Most of them carry
over to unsplit allocations, but we also showed examples for certain
structural properties that do not hold in the unsplittable case.

We proved that the reversed relaxed unsplit Gale-Shapley algorithm can
be used to decide in polynomial time whether a regular instance admits
an unsplit stable assignment. If not, relaxed solutions can be
searched for. Besides constructing the job-optimal and the
machine-optimal solutions, we also showed a method that rounds any
fractional stable solution to a relaxed unsplit stable allocation.

On the other hand, we mentioned that the well-known rural hospital
theorem has no generalization for unsplit assignments: relaxed stable
solutions can have different cardinality and the same vertex can have
various lexicographical position in them. The set of relaxed solutions
also has been investigated: the distributive lattice structure known
for matchings and allocations cannot be observed here. Although
rotations can be used to derive an unsplit solution from a fractional
one, moving form one unsplit solution to another one is impossible
just by rotations along cycles.

This latter obstacle raises a problem about optimizing over the set of
solutions. If the instance contains cost on edges, how to find a
minimum-value stable solution? Rounding the optimal fractional
assignment does not necessarily lead to an optimal unsplit
allocation. A similar question can be addressed about fair
allocations. Aside from these, any combination with well-known notions
in stability problems can be studied: ties, restricted edges,
etc. Another straightforward generalization would be to define
-splittable allocations and investigate their properties.

\fi

\bibliographystyle{plain}
\bibliography{mybib2}
\end{document}