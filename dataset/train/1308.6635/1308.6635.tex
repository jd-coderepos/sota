\chapter{Listing cycles and st-paths}
\label{chapter:cycles}

Listing all the simple cycles (hereafter just called cycles) in a
graph is a classical problem whose efficient solutions date back to
the early 70s. For a graph with  vertices and  edges, containing
 cycles, the best known solution in the literature is given by
Johnson's algorithm~\cite{Johnson1975} and takes 
time. This solution is surprisingly not optimal for undirected graphs:
to the best of our knowledge, no theoretically faster solutions have
been proposed in almost 40 years.

\begin{figure}[t]
\centering
\subfigure[Graph ]{
\begin{tikzpicture}[shorten >=1pt,->,scale=1.0]
  \tikzstyle{vertex}=[shape=circle,draw,thick,fill=black,minimum size=2pt,inner sep=2pt]
  \node[vertex,label=right:] (A) at (0,0) {};
  \node[vertex,label=left:] (B) at (-1,-1)   {};
  \node[vertex,label=left:] (C) at (-1,-2)  {};
  \node[vertex,label=right:] (D) at (1,-2)  {};
  \node[vertex,label=right:] (E) at (1,-1)  {};
  \draw (A) -- (B) -- (C) -- (D) -- (E) -- (A) -- cycle;
  \draw (B) -- (E) -- cycle;
\end{tikzpicture}
} 
\quad
\subfigure[-paths of ]{
\begin{tikzpicture}[shorten >=1pt,->,scale=1.0]
  \tikzstyle{vertex}=[shape=circle,draw,thick,fill=black,minimum size=2pt,inner sep=2pt]
  \node[vertex,label=right:] (A) at (0,0) {};
  \node[vertex,label=left:] (B) at (-1,-1)   {};
  \node[vertex,label=right:] (D) at (1,-2)  {};
  \node[vertex,label=right:] (E) at (1,-1)  {};
  \draw (B) -- (A) -- (E) -- (D) -- cycle;
\end{tikzpicture}
\begin{tikzpicture}[shorten >=1pt,->,scale=1.0]
  \tikzstyle{vertex}=[shape=circle,draw,thick,fill=black,minimum size=2pt,inner sep=2pt]
  \node[vertex,label=left:] (B) at (-1,-1)   {};
  \node[vertex,label=right:] (D) at (1,-2)  {};
  \node[vertex,label=right:] (E) at (1,-1)  {};
  \draw (B) -- (E) -- (D) -- cycle;
\end{tikzpicture}
\begin{tikzpicture}[shorten >=1pt,->,scale=1.0]
  \tikzstyle{vertex}=[shape=circle,draw,thick,fill=black,minimum size=2pt,inner sep=2pt]
  \node[vertex,label=left:] (B) at (-1,-1)   {};
  \node[vertex,label=left:] (C) at (-1,-2)  {};
  \node[vertex,label=right:] (D) at (1,-2)  {};
  \draw (B) -- (C) -- (D) -- cycle;
\end{tikzpicture}
}

\subfigure[Cycles of ]{
\begin{tikzpicture}[shorten >=1pt,->,scale=1.0]
  \tikzstyle{vertex}=[shape=circle,draw,thick,fill=black,minimum size=2pt,inner sep=2pt]
  \node[vertex,label=right:] (A) at (0,0) {};
  \node[vertex,label=left:] (B) at (-1,-1)   {};
  \node[vertex,label=left:] (C) at (-1,-2)  {};
  \node[vertex,label=right:] (D) at (1,-2)  {};
  \node[vertex,label=right:] (E) at (1,-1)  {};
  \draw (A) -- (B) -- (C) -- (D) -- (E) -- (A) -- cycle;
\end{tikzpicture}
\begin{tikzpicture}[shorten >=1pt,->,scale=1.0]
  \tikzstyle{vertex}=[shape=circle,draw,thick,fill=black,minimum size=2pt,inner sep=2pt]
  \node[vertex,label=right:] (A) at (0,0) {};
  \node[vertex,label=left:] (B) at (-1,-1)   {};
  \node[vertex,label=right:] (E) at (1,-1)  {};
  \draw (A) -- (B) -- (E) -- (A) -- cycle;
\end{tikzpicture}
\begin{tikzpicture}[shorten >=1pt,->,scale=1.0]
  \tikzstyle{vertex}=[shape=circle,draw,thick,fill=black,minimum size=2pt,inner sep=2pt]
  \node[vertex,label=left:] (B) at (-1,-1)   {};
  \node[vertex,label=left:] (C) at (-1,-2)  {};
  \node[vertex,label=right:] (D) at (1,-2)  {};
  \node[vertex,label=right:] (E) at (1,-1)  {};
  \draw (B) -- (C) -- (D) -- (E) -- cycle;
  \draw (B) -- (E) -- cycle;
\end{tikzpicture}
}

\caption{Example graph , its st-paths and cycles}
\label{fig:cyclesstpathsexample}

\end{figure}

 
\subsubsection{Results}  

Originally introduced in \cite{ferreira2013}, we present the first
optimal solution to list all the cycles in an undirected graph~.
Specifically, let  denote the set of all these cycles
().  For a cycle ,
let  denote the number of edges in~. Our algorithm requires
 time and is asymptotically
optimal: indeed,  time is necessarily required to read 
as input, and  time is
necessarily required to list the output. Since , the cost
of our algorithm never exceeds  time.

Along the same lines, we also present the first optimal solution to
list all the simple paths from  to  (shortly, -paths) in an
undirected graph . Let  denote the set of
-paths in  and, for an -path ,
let  be the number of edges in .  Our algorithm lists
all the -paths in~ optimally in  time, observing that  time is necessarily required to
list the output.  

We prove the following reduction to relate
 and  for some suitable choices
of vertices : if there exists an optimal algorithm to list the
-paths in , then there exists an optimal algorithm to list the
cycles in .  Hence, we can focus on listing -paths.

\subsubsection{Previous work}

The classical problem of listing all the cycles of a graph has been
extensively studied for its many applications in several fields,
ranging from the mechanical analysis of chemical
structures~\cite{Sussenguth65} to the design and analysis of reliable
communication networks, and the graph isomorphism
problem~\cite{Welch66}.
In particular, at the turn of the seventies several algorithms for
enumerating all cycles of an undirected graph have been proposed.
There is a vast body of work, and the majority of the algorithms
listing all the cycles can be divided into the following three classes
(see~\cite{Bezem87,Mateti76} for excellent surveys).

\begin{enumerate}
\item \textit{Search space algorithms.}
According to this approach, cycles are looked for in an appropriate
search space.  In the case of undirected graphs, the \emph{cycle
vector space} \cite{Diestel} turned out to be the most promising
choice: from a basis for this space, all vectors are computed and it
is tested whether they are a cycle. Since the algorithm introduced
in~\cite{Welch66}, many algorithms have been proposed: however, the
complexity of these algorithms turns out to be exponential in the
dimension of the vector space, and thus in . For planar graphs, an
algorithm listing cycles in  time was presented in
\cite{Syslo81}.

\item \textit{Backtrack algorithms.} 
By this approach, all paths are generated by backtrack and, for each
path, it is tested whether it is a cycle. One of the first algorithms
is the one proposed in~\cite{Tiernan70}, which is however exponential
in . By adding a simple pruning strategy, this algorithm has
been successively modified in~\cite{Tarjan73}: it lists all the cycles
in  time. Further improvements were proposed
in~\cite{Johnson1975,Szwarcfiter76,Read75}, leading to
-time algorithms that work for both directed and
undirected graphs. 


\item \textit{Using the powers of the adjacency matrix.} 
This approach uses the so-called \emph{variable adjacency matrix},
that is, the formal sum of edges joining two vertices. A non-zero
element of the -th power of this matrix is the sum of all walks of
length : hence, to compute all cycles, we compute the th power
of the variable adjacency matrix. This approach is not very efficient
because of the non-simple walks. Algorithms based on this approach
(e.g.\mbox{} \cite{Ponstein66,Yau67}) basically differ only on the way
they avoid to consider walks that are neither paths nor cycles.
\end{enumerate}

Almost 40 years after Johnson's algorithm~\cite{Johnson1975}, the
problem of efficiently listing all cycles of a graph is still an
active area of research
(e.g.~\cite{birmele2012,Halford04,Horvath04,Liu06,Sankar07,Wild08,Schott11}).  New
application areas have emerged in the last decade, such as
bioinformatics: for example, two algorithms for this problem have been
proposed in~\cite{Klamt06,Klamt09} while studying
biological interaction graphs. Nevertheless, no significant
improvement has been obtained from the theory standpoint: in
particular, Johnson's algorithm is still the theoretically most
efficient. His -time solution is surprisingly not
optimal for undirected graphs as we show in this chapter.

\subsubsection{Difficult graphs for Johnson's algorithm}

\begin{figure}[t]
\centering
\definecolor{cqcqcq}{rgb}{0,0,0}
\begin{tikzpicture}[scale=1.0,line cap=round,line join=round,>=triangle 45,x=1.0cm,y=1.0cm]
\draw (-2,2)-- (-1,3);
\draw [dash pattern=on 5pt off 5pt] (-2,2)-- (-1,2.52);
\draw [dash pattern=on 5pt off 5pt] (-2,2)-- (-1,2);
\draw (-1,3)-- (0,2);
\draw [dash pattern=on 5pt off 5pt] (-1,2.52)-- (0,2);
\draw [dash pattern=on 5pt off 5pt] (-1,2)-- (0,2);
\draw (-2,2)-- (-1,1);
\draw (-1,1)-- (0,2);
\draw (0,2)-- (1,3);
\draw [dash pattern=on 5pt off 5pt] (0,2)-- (1.04,2.48);
\draw [dash pattern=on 5pt off 5pt] (0,2)-- (1,2);
\draw (0,2)-- (1,1);
\draw (1,3)-- (2,2);
\draw [dash pattern=on 5pt off 5pt] (1.04,2.48)-- (2,2);
\draw [dash pattern=on 5pt off 5pt] (1,2)-- (2,2);
\draw (1,1)-- (2,2);
\draw [dash pattern=on 5pt off 5pt] (-2,2)-- (-1,1.48);
\draw [dash pattern=on 5pt off 5pt] (-1,1.48)-- (0,2);
\draw [dash pattern=on 5pt off 5pt] (0,2)-- (1,1.44);
\draw [dash pattern=on 5pt off 5pt] (1,1.44)-- (2,2);
\draw [shift={(0,2)}] plot[domain=0:3.14,variable=\t]({1*2*cos(\t r)+0*2*sin(\t r)},{0*2*cos(\t r)+1*2*sin(\t r)});
\begin{footnotesize}
\fill [color=black] (-2,2) circle (1.5pt);
\draw[color=black] (-2,2) node[left] {};
\fill [color=black] (-1,3) circle (1.5pt);
\draw[color=black] (-1,3) node[above] {};
\fill [color=black] (-1,2) circle (1.5pt);
\fill [color=black] (-1,1) circle (1.5pt);
\draw[color=black] (-1,1) node[below] {};
\fill [color=black] (-1,1.48) circle (1.5pt);
\fill [color=black] (-1,2.52) circle (1.5pt);
\fill [color=black] (0,2) circle (1.5pt);
\draw[color=black] (0,2) node[above] {};
\fill [color=black] (1,3) circle (1.5pt);
\draw[color=black] (1,3) node[above] {};
\fill [color=black] (1,2) circle (1.5pt);
\fill [color=black] (1.04,2.48) circle (1.5pt);
\fill [color=black] (1,1) circle (1.5pt);
\draw[color=black] (1,1) node[below] {};
\fill [color=black] (2,2) circle (1.5pt);
\draw[color=black] (2,2) node[right] {};
\fill [color=black] (1,1.44) circle (1.5pt);
\end{footnotesize}
\end{tikzpicture}
\caption{Diamond graph.}
\label{fig:johnsoncounter}
\end{figure}

It is worth observing that the analysis of the time complexity of Johnson's algorithm
is not pessimistic and cannot match the one of our algorithm for
listing cycles.  For example, consider the sparse ``diamond'' graph
 in Fig.~\ref{fig:johnsoncounter} with 
vertices in . There
are  edges in , , ,
, , for , and three kinds of
(simple) cycles:
(1)~ for ;
(2)~ for ;
(3)~ for ,
totalizing  cycles.
Our algorithm takes 
time to list these cycles.  On the other hand, Johnson's algorithm
takes  time, and the discovery of the  cycles
in~(1) costs  time each: the backtracking
procedure in Johnson's algorithm starting at , and passing through
,  and  for some , arrives at : at that point, it
explores all the vertices   even if they do not lead
to cycles when coupled with , , , , and .

\section{Preliminaries}

Let  be an undirected connected graph with  vertices
and  edges, without self-loops or parallel edges. For a vertex
, we denote by  the neighborhood of  and by
 its degree.   denotes the subgraph \emph{induced}
by , and  is the induced subgraph  for . Likewise for edge , we adopt
the notation . For a vertex ,
the \emph{postorder} DFS number of  is the relative time in which
 was \emph{last} visited in a DFS traversal, i.e. the position of
 in the vertex list ordered by the last visiting time of each
vertex in the DFS.

Paths are simple in  by definition: we refer to a path  by its
natural sequence of vertices or edges.  A path  from  to ,
or -\emph{path}, is denoted by . Additionally,
 is the set of all paths in  and
 is the set of all -paths in .  When
 we have cycles, and  denotes the set of all
cycles in . We denote the number of edges in a path  by
 and in a cycle~ by . In this chapter, we consider the following
problems.

\begin{problem}[Listing st-Paths]
	\label{prob:liststpaths}
	Given an undirected graph  and two distinct vertices
	, output all the paths .
\end{problem} 

\begin{problem}[Listing Cycles]
	\label{prob:listcycles}
	Given an undirected graph , output all the cycles .
\end{problem} 

\begin{figure}[t]
\centering
\begin{tikzpicture}
[nodeDecorate/.style={shape=circle,inner sep=1pt,draw,thick,fill=black},lineDecorate/.style={-,dashed},elipseDecorate/.style={color=gray!30},
  scale=0.6]
\fill [elipseDecorate] (5,10) circle (2);
\fill [elipseDecorate] (9,10) circle (2);
\fill [elipseDecorate] (2,10) circle (1);
\fill [elipseDecorate] (-1,10) circle (2);
\fill [elipseDecorate,rotate around={-55:(-1,8)}] (-1,7) circle (1);

\draw (5,10) circle (2);
\draw (9,10) circle (2);
\draw (2,10) circle (1);
\draw (-1,10) circle (2);
\draw (5,7) circle (1);
\draw (9,7) circle (1);
\draw [rotate around={55:(-1,8)}] (-1,7) circle (1);
\draw [rotate around={-55:(-1,8)}] (-1,7) circle (1);
\draw (13,10) circle (2);
\draw (13,7) circle (1);
\draw (-4,10) circle (1);
\begin{footnotesize}
\node (7) at (-2,7) [nodeDecorate,label=above:] {};
\node (14) at (9,11) [nodeDecorate,label=above:] {};
\end{footnotesize}
\foreach \nodename/\x/\y in {
  0/7/10, 1/5/11,
  2/3/10, 3/1/10, 4/-3/10, 5/-1/10, 6/-1/8, 7/-2/7, 8/-1/11,
  9/0/7,
  11/5/10, 12/4/9, 13/5/8, 14/9/11, 15/11/10, 16/9/9,
  17/9/7 , 18/9/8, 50/5/7, 51/13/11, 52/13/8, 53/13/7, 54/-4/10}
{
  \node (\nodename) at (\x,\y) [nodeDecorate] {};
}

\path
\foreach \startnode/\endnode in {6/7, 6/9, 5/6, 5/3, 5/8, 4/5, 3/2,
2/11, 1/11, 11/12, 11/0, 11/13, 13/50, 0/14, 14/15, 15/16, 16/18,
18/17, 15/51, 15/52, 51/52, 52/53, 54/4}
{
  (\startnode) edge[lineDecorate] node {} (\endnode)
};

\path
\foreach \startnode/\endnode/\bend in { 8/3/20, 6/3/20, 4/8/10,
12/13/20, 1/0/20, 2/1/20, 13/0/20, 0/18/10}
{
  (\startnode) edge[lineDecorate, bend left=\bend] node {} (\endnode)
};

\end{tikzpicture}
\caption{Block tree of  with bead string  in gray.}
\label{fig:beadstring}
\end{figure}

Our algorithms assume without loss of generality that the input graph
 is connected, hence , and use the decomposition of 
into biconnected components. Recall that an \emph{articulation point}
(or cut-vertex) is a vertex  such that the number of
connected components in  increases when  is removed.  is
\emph{biconnected} if it has no articulation points. Otherwise, 
can always be decomposed into a tree of biconnected components, called
the \emph{block tree}, where each biconnected component is a maximal
biconnected subgraph of  (see Fig.~\ref{fig:beadstring}), and
two biconnected components are adjacent if and only if they share an
articulation point.

\section{Overview and main ideas}
\label{sec:overview}

While the basic approach is simple (see the binary partition in
  point~\ref{item:abstract:3}), we use a number of non-trivial ideas to
  obtain our optimal algorithm for an undirected (connected) graph 
  as summarized in the steps below.
  \begin{enumerate}
  \item Prove the following reduction. If there exists an optimal
    algorithm to list the -paths in , there exists an optimal
    algorithm to list the cycles in . This relates
     and  for some choices .



  \item Focus on listing the -paths. Consider the decomposition of
    the graph into biconnected components ({\bcc}s), thus forming a
    tree  where two {\bcc}s are adjacent in  iff they share an
    articulation point. Exploit (and prove) the property that if 
    and  belong to distinct {\bcc}s, then  there is a unique
    \emph{sequence}  of adjacent {\bcc}s in  through
    which each -path must necessarily pass, and  each
    -path is the concatenation of paths connecting the
    articulation points of these {\bcc}s in .

  \item \label{item:abstract:3} Recursively list the -paths in
     using the classical binary partition (i.e.\mbox{}
    given an edge  in , list all the cycles containing
    , and then all the cycles not containing~): now it suffices to
    work on the \emph{first} \bcc\ in , and efficiently
    maintain it when deleting an edge , as required by the binary
    partition.

  \item Use a notion of \emph{certificate} to avoid recursive calls
    (in the binary partition) that do not list new -paths.  This
    certificate is maintained dynamically as a data structure
    representing the first \bcc\ in , which guarantees
    that there exists at least one \emph{new} solution in the current
    .

  \item Consider the binary recursion tree corresponding to the binary
    partition.  Divide this tree into \emph{spines}: a spine
    corresponds to the recursive calls generated by the edges 
    belonging to the same adjacency list in .  The
    amortized cost for each listed -path  is  when
    there is a guarantee that the amortized cost in each spine  is
    , where  is a lower bound on the number of -paths
    that will be listed from the recursive calls belonging to~. The
    (unknown) parameter~, which is different for each spine~, and the
    corresponding cost , will drive the design of the proposed
    algorithms.
  \end{enumerate}

\subsection{Reduction to -paths}
\label{sub:reduction-paths}

We now show that listing cycles reduces to listing -paths while
preserving the optimal complexity.  

\begin{lemma}
  \label{lemma:reduction}
  Given an algorithm that solves Problem~\ref{prob:liststpaths} in
  \mbox{}
  time, there exists an algorithm that solves
  Problem~\ref{prob:listcycles} in \mbox{} time.
\end{lemma}
\begin{proof}
  Compute the biconnected components of  and keep them in a list
  . Each (simple) cycle is contained in one of the biconnected
  components and therefore we can treat each biconnected component
  individually as follows. While  is not empty, extract a biconnected
  component  from  and repeat the following three
  steps:  compute a DFS traversal of  and take any back edge
   in ;  list all -paths in , i.e.~the
  cycles in  that include edge~;  remove edge  from
  , compute the new biconnected components thus created by removing
  edge~, and append them to . When  becomes empty, all the
  cycles in  have been listed.

  Creating  takes  time. For every , steps  and
   take  time.  Note that step  always outputs
  distinct cycles in  (i.e.~-paths in ) in
   time.
  However,  is then decomposed into biconnected components whose
  edges are traversed again. We can pay for the latter cost: for any
  edge  in a biconnected component , there is always a
  cycle in  that contains both  and  (i.e.\mbox{} it is an
  -path in ), hence  dominates the term ,
  i.e.~.  Therefore steps -- take  time. When  becomes empty,
  the whole task has taken 
  time.
\end{proof}


\subsection{Decomposition in biconnected components}
\label{sec:decomposition}


We now focus on listing -paths
(Problem~\ref{prob:liststpaths}). We use the decomposition of  into
a block tree of biconnected components.  Given vertices , define
its \emph{bead string}, denoted by , as the unique
sequence of one or more adjacent biconnected components (the
\emph{beads}) in the block tree, such that the first one contains 
and the last one contains  (see Fig.~\ref{fig:beadstring}): these
biconnected components are connected through articulation points,
which must belong to all the paths to be listed.

\begin{lemma}
  \label{lemma:beadstring}
  All the -paths in  are contained in the
  induced subgraph  for the bead string
  . Moreover, all the articulation points in
   are traversed by each of these paths.
\end{lemma}
\begin{proof}
  Consider an edge  in  such that 
  and . Since the biconnected components of a
  graph form a tree and the bead string  is a path in
  this tree, there are no paths  in  for any  because the biconnected components in  are maximal
  and there would be a larger one (a contradiction).
Moreover, let  be the biconnected components
  composing , where  and . If
  there is only one biconnected component in the path (i.e.~),
  there are no articulation points in .  Otherwise, all
  of the  articulation points in  are traversed by
  each path : indeed, the articulation
  point between adjacent biconnected components  and  is
  their only vertex in common and there are no edges linking  and
  .
\end{proof}

We thus restrict the problem of listing the paths in
 to the induced subgraph ,
conceptually isolating it from the rest of . For the sake of
description, we will use interchangeably  and
 in the rest of the chapter.

\subsection{Binary partition scheme}
\label{sec:basic-scheme}

We list the set of -paths in , denoted by
, by applying the binary partition
method (where 
by Lemma~\ref{lemma:beadstring}): we choose an edge 
incident to~ and then list all the -paths that include  and
then all the -paths that do not include . Since we delete some
vertices and some edges during the recursive calls, we proceed as follows.

\smallskip

\noindent{\it Invariant:} At a generic recursive step on vertex 
(initially, ), let  be the path discovered
so far (initially,  is empty ). Let  be the
current bead string (initially, ). More precisely,  is defined as follows:
~remove from  all the vertices in  but , and
the edges incident to  and discarded so far; ~recompute the
block tree on the resulting graph; ~ is the unique
bead string that connects  to  in the recomputed block tree.

\smallskip

\noindent{\it Base case:} When , output the -path .

\smallskip

\noindent{\it Recursive rule:} Let  denote the set of -paths to be
		listed by the current recursive call. Then, it is the
		union of the following two disjoint sets, for an edge
		 incident to~:
\begin{itemize}
\item \emph{Left branching:} the -paths in  that use , where  is the unique
  bead string connecting  to  in the block tree resulting from
  the deletion of vertex  from .
\item \emph{Right branching:} the -paths in  that do \emph{not} use~, where  is
  the unique bead string connecting  to  in the block tree
  resulting from the deletion of edge  from .
\end{itemize}

\noindent
Hence,  (and so
) can be computed by invoking . The correctness and completeness of the above approach
is discussed in Section~\ref{sec:intro-cert}.

At this point, it should be clear why we introduce the notion of bead
strings in the binary partition. The existence of the partial path
 and the bead string  guarantees that there surely
exists at least one -path. But there are two sides of the coin
when using .

\begin{enumerate}
\item One advantage is that we can avoid useless recursive calls:
If vertex  has only one incident edge , we just perform the left
branching; otherwise, we can safely perform both the left and right
branching since the \emph{first} bead in  is always a
biconnected component by definition (thus there exists both an
-path that traverses  and one that does not).

\item \label{side_coin:2} The other side of the coin is that we have to maintain the
bead string  as  in the left branching and
as  in the right branching by
Lemma~\ref{lemma:beadstring}. Note that these bead strings are surely
non-empty since  is non-empty by induction (we only
perform either left or left/right branching when there are solutions by
item~1).
\end{enumerate}

To efficiently address point~\ref{side_coin:2}, we need to introduce the notion of
certificate as described next. 


\subsection{Introducing the certificate}
\label{sec:intro-cert}

Given the bead string , we call the \emph{head} of
, denoted by , the first biconnected component in
, where . Consider a DFS tree of
 rooted at  that changes along with , and
classify the edges in  as tree edges or back edges (there
are no cross edges since the graph is undirected).

\begin{figure}[t]
	\centering
\begin{tikzpicture}
[nodeDecorate/.style={shape=circle,inner sep=1pt,draw,thick,fill=black},lineDecorate/.style={-,dashed},elipseDecorate/.style={color=gray!30},
  scale=0.25]
\draw (10,22) circle (9);
\draw (5,11.1) circle (3);

\node (s) at (10,34) [nodeDecorate,color=lightgray,label=above left:] {};
\node (u) at (10,31) [nodeDecorate,label=above left:{ }] {};

\node (tp) at (6.2,13.9) [nodeDecorate,label=above right:{ }] {};
\node (t) at (5.5,11) [nodeDecorate,label=below:] {};

\path {
	(s) edge[snake,-,color=lightgray] node {\quad\quad} (u)
	(u) edge node {} (tp)
	(tp) edge node {} (t)
};

\node (a) at (9.3,28) [nodeDecorate,label=left:] {};
\node (b) at (7.1,18) [nodeDecorate,] {};
\node (c) at (13,25) [nodeDecorate,] {};
\node (d) at (14.5,22) [nodeDecorate,label=right:] {};
\node (e) at (11,22) [nodeDecorate,label=below:] {};
\node (f) at (16,19) [nodeDecorate,label=below:] {};
\node (g) at (13,19) [nodeDecorate,] {};
\node (h) at (10,16) [nodeDecorate,] {};

\path {
	(a) edge node {} (c)
	(c) edge node {} (d)
	(d) edge node {} (f)
	(c) edge node {} (e)
	(d) edge node {} (g)
	(b) edge node {} (h)
};

\path {
	(u) edge[dashed,bend left=-40] node {} (tp)
	(f) edge[dashed,bend left=-40] node {} (u)
	(g) edge[dashed,bend left=10] node {} (c)
	(e) edge[dashed,bend left=-10] node {} (u)
	(d) edge[dashed,bend left=-20] node {} (u)
	(a) edge[dashed,bend left=5] node {} (h)
};

\end{tikzpicture}
\caption{Example certificate of  \label{fig:Certificate}}
\end{figure}

To maintain  (and so ) during the recursive calls,
we introduce a \emph{certificate}  (see Fig.~\ref{fig:Certificate}): It is a suitable data structure that uses the above
classification of the edges in , and supports the
following operations, required by the binary partition scheme.
\begin{itemize}
\item : returns an edge  with  such that  is an
	-path such that  is inside .
	Note that  always exists since  is biconnected.
	Also, the chosen  is the last one in DFS postorder among the
	neighbors of : in this way, the (only) tree edge  is
	returned when there are no back edges leaving from~.  (As
	it will be clear in Sections~\ref{sec:recursion-amortization}
	and~\ref{sec:certificate}, this order facilitates the analysis
	and the implementation of the certificate.)
\item : for the given , it obtains
	 from  as discussed in
	Section~\ref{sec:basic-scheme}. This implies updating also
	, , and the block tree, since the recursion
	continues on~. It returns bookkeeping information  for
	what is updated, so that it is possible to revert to
	, , , and the block tree, to their
	status before this operation.
\item : for the given , it obtains
	 from  as discussed in
	Section~\ref{sec:basic-scheme}, which implies updating also
	, , and the block tree. It returns bookkeeping
	information  as in the case of .
\item : reverts the bead string to ,
	the head , the certificate , and the block tree, to
	their status before operation  or  was issued (in the same recursive call).
\end{itemize}

Note that a notion of certificate in listing problems has been
introduced in~\cite{Ferreira11}, but it cannot be directly applied to
our case due to the different nature of the problems and our use of more
complex structures such as biconnected components. 

Using our certificate
and its operations, we can now formalize the binary partition and its
recursive calls  described in
Section~\ref{sec:basic-scheme} as Algorithm~\ref{alg:liststpaths},
where  is replaced by its certificate .

\begin{algorithm}[t]
	\caption{\label{alg:liststpaths} }
\begin{algorithmic}[1]
	\IF{}
		\STATE  \label{code:base}
		\STATE  \label{code:returnbase}
	\ENDIF
	\STATE  \label{code:choose}
	\IF{  \label{code:if_back}}
		\STATE   \label{code:right_update}
		\STATE  \label{code:right_branch}
		\STATE  \label{code:right_undo}
	\ENDIF
        \STATE  \label{code:left_update}
        \STATE  \label{code:left_branch}
        \STATE  \label{code:left_undo}
\end{algorithmic}
\end{algorithm}

The base case () corresponds to lines~1--4 of
Algorithm~\ref{alg:liststpaths}. During recursion, the left branching
corresponds to lines~5 and~11-13, while the right branching to
lines~5--10. Note that we perform only the left branching when there is
only one incident edge in , which is a tree edge by definition of
. Also, lines~9 and~13 are needed to restore the
parameters to their values when returning from the recursive
calls.

\begin{lemma}
  \label{lemma:correctness_algo_listpaths}
Algorithm~\ref{alg:liststpaths} correctly lists all the -paths in
  .
\end{lemma}
\begin{proof}
  For a given vertex  the function  returns an
  edge  incident to . We maintain the invariant that  is
  a path , since at the point of the recursive call in
  line~\ref{code:left_branch}: (i) is connected as we append edge
   to  and; (ii) it is simple as vertex  is removed
  from the graph  in the call to  in
  line~\ref{code:left_update}. In the case of recursive call in
  line~\ref{code:right_branch} the invariant is trivially maintained
  as  does not change.
The algorithm only outputs -paths since  is
  a  path and  when the algorithm outputs, in
  line~\ref{code:base}. 

  The paths with prefix  that do not use  are listed by
  the recursive call in line~\ref{code:right_branch}. This is done by
  removing~ from the graph (line~\ref{code:right_update}) and thus
  no path can include . Paths that use  are listed in
  line~\ref{code:left_branch} since in the recursive call  is added
  to . Given that the tree edge incident to  is the last one
  to be returned by , there is no path that does not
  use this edge, therefore it is not necessary to call
  line~\ref{code:right_branch} for this edge.
\end{proof}

A natural question is what is the time complexity: we must account for
the cost of maintaining~ and for the cost of the recursive calls of
Algorithm~\ref{alg:liststpaths}. Since we cannot always maintain the
certificate in  time, the ideal situation for attaining an
optimal cost is taking  time if at least  -paths are
listed in the current call (and its nested calls). Unfortunately, we
cannot estimate~ efficiently and cannot design
Algorithm~\ref{alg:liststpaths} so that it takes  adaptively.
We circumvent this by using a different cost scheme in
Section~\ref{sub:recursion-tree-cost} that is based on the recursion
tree induced by Algorithm~\ref{alg:liststpaths}.
Section~\ref{sec:certificate} is devoted to the efficient
implementation of the above certificate operations according to the
cost scheme that we discuss next.


\subsection{Recursion tree and cost amortization}
\label{sub:recursion-tree-cost}

We now show how to distribute the costs among the several recursive
calls of Algorithm~\ref{alg:liststpaths} so that optimality is
achieved. Consider a generic execution on the bead string
. We trace this execution by using a binary recursion
tree . The nodes of  are labeled by the arguments of 
Algorithm~\ref{alg:liststpaths}: specifically, we denote a node
in  by the triple  iff it
represents the call with arguments , , and~.\footnote{For
clarity, we use ``nodes'' when referring to  and ``vertices'' when
referring to .}  The left branching is represented by the
left child, and the right branching (if any) by the right child of the
current node. 

\begin{lemma}
\label{lem:properties_recursion}
The binary recursion tree  for  has the following properties: 
\begin{enumerate}
	\setlength{\itemsep}{0pt} 
\item \label{item:R1} There is a one-to-one correspondence between the
  paths in  and the leaves in the recursion
  tree rooted at node .
\item \label{item:R2} Consider any leaf and its corresponding -path
  : there are  left branches in
  the corresponding root-to-leaf trace.
\item \label{item:R3} Consider the instruction 
  in Algorithm~\ref{alg:liststpaths}: unary (i.e.\mbox{} single-child)
  nodes correspond to left branches ( is a tree edge) while binary
  nodes correspond to left and right branches ( is a back
  edge).
\item \label{item:R4} The number of binary nodes is
  .
\end{enumerate}
\end{lemma}
\begin{proof}
We proceed in order as follows.
\begin{enumerate}
\item We only output a solution in a leaf and we only do recursive
  calls that lead us to a solution. Moreover every node partitions the
  set of solutions in the ones that use an edge and the ones that do
  not use it. This guarantees that the leaves in the left subtree of
  the node corresponding to the recursive call and the leaves in the
  right subtree do not intersect. This implies that different leaves
  correspond to different paths from  to , and that for each
  path there is a corresponding leaf.
\item Each left branch corresponds to the inclusion of an edge in the
  path .
\item Since we are in a biconnected component, there is always a left
  branch. There can be no unary node as a right branch: indeed for any
  edge of  there exists always a path from  to 
  passing through that edge. Since the tree edge is always the last
  one to be chosen, unary nodes cannot correspond to back edges and
  binary nodes are always back edges.
\item It follows from point \ref{item:R1} and from the fact that the recursion tree is
  a binary tree. (In any binary tree, the number of binary nodes is
  equal to the number of leaves minus 1.)
\end{enumerate}
\end{proof}

\begin{figure}[t]
	\centering
\begin{tikzpicture}
[nodeDecorate/.style={shape=circle,inner sep=4pt,draw,fill=white},lineDecorate/.style={-,dashed},elipseDecorate/.style={color=gray!30},
  scale=0.25]

  \node (a) at (0,0) [nodeDecorate,label=above:] {};
  \node (b) at (4,-1) [nodeDecorate] {};
  \node (c) at (8,-2) [nodeDecorate] {};
  \node (d) at (12,-3) [nodeDecorate] {};
  \node (e) at (16,-4) [nodeDecorate] {};

  \node (a2) at (-2,-5) [nodeDecorate,label=below:] {};
  \node (b2) at (2,-6) [nodeDecorate,label=below:] {};
  \node (c2) at (6,-7) [nodeDecorate,label=below:] {};
  \node (d2) at (10,-8) [nodeDecorate,label=below:] {};
  \node (e2) at (14,-9) [nodeDecorate,label=below:] {};

\path {
	(a) edge node {} (b)
	(b) edge node {} (c)
	(c) edge node {} (d)
	(d) edge node {} (e)
	(a) edge node {} (a2)
	(b) edge node {} (b2)
	(c) edge node {} (c2)
	(d) edge node {} (d2)
	(e) edge node {} (e2)
};
\end{tikzpicture}
\caption{Spine of the recursion tree \label{fig:spine}}
\end{figure}
We define a \emph{spine} of  to be a subset of 's nodes linked
as follows: the first node is a node  that is either the left child
of its parent or the root of , and the other nodes are those
reachable from  by right branching in . Let  be the first node in a spine . The nodes in 
correspond to the edges that are incident to vertex  in
: hence their number equals the degree  of  in
, and the deepest (last) node in  is always a tree
edge in  while the others are back edges.
Fig.~\ref{fig:spine} shows the spine corresponding to  in
Fig.~\ref{fig:Certificate}. Summing up,  can be seen as composed by
spines, unary nodes, and leaves where each spine has a unary node as
deepest node. This gives a global picture of  that we now exploit
for the analysis.



We define the \emph{compact head}, denoted by \mbox{}, as the (multi)graph obtained by compacting the maximal chains
of degree-2 vertices, except , , and the vertices that are the
leaves of its DFS tree rooted at~.

The rationale behind the above definition is that the costs defined in
terms of  amortize well, as the size of  and the
number of -paths in the subtree of  rooted at node  are intimately related (see
Lemma~\ref{lemma:lower_bound_paths_beadstring} in
Section~\ref{sec:recursion-amortization}) while this is not
necessarily true for .

Recall that each leaf corresponds to a path  and each spine
corresponds to a
compact head . We now define the following abstract
cost for spines, unary nodes, and leaves of , for a sufficiently
large constant , that Algorithm~\ref{alg:liststpaths} must
fulfill:


\begin{lemma}
  \label{lemma:total_cost_recursion_tree}
  The sum of the costs in the nodes of the recursion tree .
\end{lemma}

Section~\ref{sec:recursion-amortization} contains the proof of
Lemma~\ref{lemma:total_cost_recursion_tree} and related properties.
Setting , we obtain that the cost in
Lemma~\ref{lemma:total_cost_recursion_tree} is optimal, by
Lemma~\ref{lemma:beadstring}.

\begin{theorem}
  \label{theorem:optimal_paths}
  Algorithm~\ref{alg:liststpaths} solves problem
  Problem~\ref{prob:liststpaths} in  time.
\end{theorem}

By Lemma~\ref{lemma:reduction}, we obtain an optimal result for
listing cycles.

\begin{theorem}
  \label{theorem:optimal_cycles}
  Problem~\ref{prob:listcycles} can be optimally solved in \mbox{} time. 
\end{theorem}

\section{Amortization strategy}
\label{sec:recursion-amortization}


We devote this section to prove
Lemma~\ref{lemma:total_cost_recursion_tree}. Let us split the sum
in Eq.~\eqref{eq:abstrac_cost} in three parts, and bound each part
individually, as


We have that , since there are
 leaves, and the root-to-leaf trace leading to
the leaf for  contains at most  unary nodes by
Lemma~\ref{lem:properties_recursion}, where each unary node has cost
 by Eq.~\eqref{eq:abstrac_cost}.

Also, , since the leaf  for  has cost
 by Eq.~\eqref{eq:abstrac_cost}.

It remains to bound . By
Eq.~\eqref{eq:abstrac_cost}, we can rewrite this cost as
, where the sum ranges over the
compacted heads  associated with the spines . We use the
following lemma to provide a lower bound on the number of -paths
descending from .

\begin{lemma}
  \label{lemma:lower_bound_paths_beadstring}
  Given a spine , and its bead string  with head
  , there are at least  -paths in 
  that have prefix  and suffix 
  internal to , where the compacted head is .
\end{lemma}
\begin{proof}
    is biconnected. In any biconnected graph 
   there are at least  -paths for any . Find an ear decomposition \cite{Diestel} of  and consider
   the process of forming  by adding ears one at the time, starting
   from a single cycle including  and . Initially 
    and there are 2 -paths. Each new ear forms a path
   connecting two vertices that are part of a -path, increasing
   the number of paths by at least 1. If the ear has  edges, its
   addition increases  by ,  by , and the number of
   -paths by at least 1. The result follows by induction.
\end{proof}

The implication of Lemma~\ref{lemma:lower_bound_paths_beadstring} is
that there are at least  leaves descending from the
given spine . Hence, we can charge to each of them a cost of
. Lemma~\ref{lemma:density} allows us to prove that the latter
cost is  when  is different from a single edge or a
cycle. (If  is a single edge or a cycle,  is a
  single or double edge, and the cost is trivially a constant.)
\begin{lemma}
  \label{lemma:density}
  For a compacted head , its density is
  .
\end{lemma}
\begin{proof}
	Consider the following partition  where:  is the root;  is the set of vertices with
	degree 2 and; , the vertices with degree .  Since
	 is compacted DFS tree of a biconnected graph, we have
	that  is a \emph{subset} of the leaves and  contains
	the set of internal vertices (except ). There are no vertices
	with degree 1 and . Let  and .  We can write the
	density as a function of  and , namely,
	

	Note that  as the vertices in 
	have at least degree 3,  as vertices in
	 have degree exactly 2. Since , we derive the
	following bound
	

	Consider any graph with  and its DFS tree rooted at
        . Note that: (i) there are no tree edges between any two
        leaves, (ii) every vertex in  is a leaf and (iii) no leaf
        is a child of .  Therefore, every tree edge incident in a
        vertex of  is also incident in a vertex of . Since
        exactly half the incident edges to  are tree edges (the
        other half are back edges) we get that .

	With  there exists at least one internal vertex in
	the DFS tree and therefore .
 

 Since for any  the function is minimized by the maximum  s.t.
  and for any  by the minimum , we get
  
\end{proof}


Specifically, let  and write  for a constant : we have that . Thus, we can charge each
leaf with a cost of . This motivates the
definition of , since Lemma~\ref{lemma:density} does not
necessarily hold for the head  (due to the unary nodes in its
DFS tree).

One last step to bound : as noted
before, a root-to-leaf trace for the string storing  has 
left branches by Lemma~\ref{lem:properties_recursion}, and as many
spines, each spine charging  to
the leaf at hand. This means that each of the 
leaves is charged for a cost of , thus bounding the sum as
. This completes the
proof of Lemma~\ref{lemma:total_cost_recursion_tree}. As a corollary,
we obtain the following result.

\begin{lemma}
  \label{lemma:amortized_cost_per_path}
  The recursion tree  with cost as in Eq.~\eqref{eq:abstrac_cost}
  induces an  amortized cost for each -path .
\end{lemma}


\section{Certificate implementation and maintenance}
\label{sec:certificate}

We show how to represent and update the certificate  so that the
time taken by Algorithm~\ref{alg:liststpaths} in the recursion tree
can be distributed among the nodes as in Eq.~\eqref{eq:abstrac_cost}:
namely, (i)~ time in unary nodes; (ii)~ time in the
leaf corresponding to path ; (iii)~ in each
spine.

The certificate  associated with a node  in the recursion tree is a compacted and augmented DFS tree
of bead string , rooted at vertex~. The DFS tree
changes over time along with , and is
maintained in such a way that  is in the leftmost path of the tree.

We augment the DFS tree with sufficient information to implicitly
represent articulation points and biconnected components.  
Recall that, by the properties of a DFS tree of an undirected graph,
there are no cross edges (edges between different branches of the
tree).

We compact the DFS tree by contracting the vertices that have
degree~2, except , , and the leaves (the latter surely have
incident back edges). Maintaining this compacted representation is not
a difficult data-structure problem. From now on we can assume
w.l.o.g.\mbox{} that  is an augmented DFS tree rooted at  where
internal nodes of the DFS tree have degree , and each vertex
 has associated the following information.

\begin{enumerate}
	\setlength{\itemsep}{0pt} 
	\item A doubly-linked list  of back edges linking 
          to its descendants  sorted by postorder DFS numbering.
	\item A doubly-linked list  of back edges linking 
          to its ancestors  sorted by preorder DFS numbering.
        \item \label{item:point3} An integer , such that if  is an
                ancestor of  then .
	\item \label{item:point4} The smallest  over all
          , such that  is a back edge and  is in the
          subtree of , denoted by .
\end{enumerate}

Given three vertices  such that  is the parent of 
and  is not in the subtree\footnote{The second condition is always
  satisfied when  is not in the leftmost path, since  is not in
  the subtree of .} of , we can efficiently test if  is an
articulation point, i.e.\mbox{} . (Note that we adopt a variant of  using
 in place of the preorder numbering~\cite{Tarjan72}: it has
the same effect whereas using  is preferable since it is
easier to dynamically maintain.)

\begin{lemma}
  \label{lem:certificate_scratch}
 The certificate associated with the root of the recursion can be
 computed in  time.
\end{lemma}

\begin{proof}
	In order to set  to be in the leftmost path, we perform a
        DFS traversal of graph  starting from  and stop when we
        reach vertex . We then compute the DFS tree, traversing the
        path  first. When visiting vertex , we set
         to depth of  in the DFS. Before going up on the
        traversal, we compute the lowpoints using the lowpoints of the
        children. Let  be the parent of . If
         and  is not in the
        leftmost path in the DFS, we cut the subtree of  as it does
        not belong to .  When first exploring the
        neighborhood of , if  was already visited,
        i.e.  is a back edge, and  is a descendant of ;
        we add  to . This maintains the DFS preordering in
        the ancestor back edge list. Now, after the first scan of
         is over and all the recursive calls returned (all the
        children were explored), we re-scan the neighborhood of
        . If  is a back edge and  is an ancestor of
        , we add  to . This maintains the DFS
        postorder in the descendant back edge list. This procedure
        takes at most two DFS traversals in  time.  This DFS
        tree can be compacted in the same time bound.  
\end{proof}

\begin{lemma}
	\label{lem:choose}
	Operation  can be implemented in  time.
\end{lemma}
\begin{proof}
If the list  is empty, return the tree edge  linking 
to its only child  (there are no other children).  Else,
return the last edge in . 
\end{proof}

We analyze the cost of updating and restoring the
certificate . We can reuse parts of~,
namely, those corresponding to the vertices that are not in the
compacted head  as defined in
Section~\ref{sub:recursion-tree-cost}.
We prove that, given a unary node  and its tree edge , the
subtree of  in~ can be easily made a certificate for the left
branch of the recursion.

\begin{lemma}
	\label{lem:unary_left}
	On a unary node,  takes 
	time.
\end{lemma}
\begin{proof}
	Take edge . Remove edge  and set  as the root
	of the certificate. Since  is the only edge incident in
	, the subtree  is still a DFS tree. Cut the list of children
	of  keeping only the first child. (The other children are no
	longer in the bead string and become part of .) There is
	no need to update . 
\end{proof}

We now devote the rest of this section to show how to efficiently
maintain  on a spine.  Consider removing a back edge  from :
the compacted head  of the bead string can be divided
into smaller biconnected components.  Many of those can be excluded
from the certificate (i.e. they are no longer in the new bead string,
and so they are bookkept in ) and additionally we have to update
the lowpoints that change. We prove that this operation can be
performed in  total time on a spine of the recursion tree.

\begin{lemma}
	\label{lem:removebackedge}
	The total cost of all the operations  in a
        spine is  time.
\end{lemma}
\begin{proof}
	In the right branches along a spine, we remove all back edges
        in . This is done by starting from the last edge in
        , i.e.~proceeding in reverse DFS postorder.
For back edge , we traverse the vertices in the
	path from  towards the root , as these are the only lowpoints
	that can change.
While moving upwards on the tree, on each vertex , we
        update . This is done by taking the
        endpoint  of the first edge in  (the back edge that
        goes the topmost in the tree) and choosing the minimum between
         and the lowpoint of each child\footnote{If
           does not change we cannot pay to
          explore its children. For each vertex we dynamically
          maintain a list  of its children that have lowpoint
          equal to . Then, we can test in constant time if
           and  is not the root . If both
          conditions are true  changes,
          otherwise it remains equal to  and we stop.} of
        . We stop when the updated  since it implies that the lowpoint of the vertex
        can not be further reduced.  Note that we stop before ,
        except when removing the last back edge in .

	To prune the branches of the DFS tree that are no longer in
        , consider again each vertex  in the path from
         towards the root  and its parent . We check if the
        updated  and  is not
        in the leftmost path of the DFS. If both conditions are
        satisfied, we have that , and therefore we
        cut the subtree of  and keep it in  to restore later. We
        use the same halting criterion as in the previous paragraph.
	
	The cost of removing all back edges in the spine is
	: there are  tree edges and, in the paths
	from  to , we do not traverse the same tree edge twice
	since the process described stops at the first common ancestor
	of endpoints of back edges . Additionally, we take 
	time to cut a subtree of an articulation point in the DFS tree. 
\end{proof}


To compute  in the binary nodes of a spine, we use
the fact that in every left branching from that spine, the graph is
the same (in a spine we only remove edges incident to  and on a
left branch from the spine we remove the vertex ) and therefore its
block tree is also the same. However, the certificates on these nodes
are not the same, as they are rooted at different vertices. Using
the reverse DFS postorder of the edges, we are able to traverse
each edge in  only a constant number of times in the spine.


\begin{lemma}
	\label{lem:promotebackedge}
	The total cost of all operations  in a
        spine is amortized .
\end{lemma}
\begin{proof}
	Let  be the last vertex in the path  s.t.
	. Since  is an articulation point, the subtree
        of the DFS tree rooted in  is maintained in the
	case of removal of vertex . Therefore the only modifications
	of the DFS tree occur in the compacted head  of .
Let us compute the certificate : this is the certificate
	of the left branch of the th node of the spine where we
	augment the path with the back edge  of
	 in the order defined by .

	For the case of , we remove  and rebuild the
	certificate starting form  (the last edge in )
	using the algorithm from Lemma~\ref{lem:certificate_scratch}
	restricted to  and using  as target and 
	as a baseline to  (instead of the depth). This takes
	 time.  

	For the general case of  with  we also rebuild
	(part) of the certificate starting from  using the
	procedure from Lemma~\ref{lem:certificate_scratch} but we use
	information gathered in  to avoid exploring useless
	branches of the DFS tree. The key point is that, when we reach
	the first bead in common to both  and
	, we only explore edges internal to this bead.
	If an edge  leaving the bead leads to , we can reuse
	a subtree of . If  does not lead to , then it
	has already been explored (and cut) in  and there is
	no need to explore it again since it will be discarded.
	Given the order we take , each bead is
	not added more than once, and the total cost over the
	spine is .

	Nevertheless, the internal edges  of the first bead in
	common between  and  can be explored
	several times during this procedure.\footnote{Consider the
	case where  are all in the same bead after
	the removal of . The bead strings are the same, but the
	roots  are different, so we have to compute
	the corresponding DFS of the first component  times.}
	We can charge the cost  of exploring those edges to
	another node in the recursion tree, since this common bead is
	the head of at least one certificate in the recursion subtree
	of the left child of the th node of the spine.
	Specifically, we charge the first node in the \emph{leftmost}
	path of the th node of the spine that has exactly the
	edges  as head of its bead string: (i) if 
	it corresponds to a unary node or a leaf in the recursion tree
	and therefore we can charge it with  cost; (ii)
	otherwise it corresponds to a first node of a spine and
	therefore we can also charge it with . We use this
	charging scheme when  and the cost is always charged
	in the leftmost recursion path of th node of the spine.
	Consequently, we never charge a node in the recursion tree more
	than once.  
\end{proof}

\begin{lemma}
	\label{lem:restore} On each node of the recursion tree,
	 takes time proportional to the size of the
	modifications kept in .
\end{lemma}
\begin{proof}
	We use standard data structures (i.e.~linked lists) for the
        representation of certificate .  Persistent versions of
        these data structures exist that maintain a stack of
        modifications applied to them and that can restore its
        contents to their previous states.  Given the modifications in
        , these data structures take  time to restore the
        previous version of .

        Let us consider the case of performing . We
        cut at most  edges from . Note that, although we
        conceptually remove whole branches of the DFS tree, we only
        remove edges that attach those branches to the DFS tree. The
        other vertices and edges are left in the certificate but, as
        they no longer remain attached to , they will never
        be reached or explored. In the case of , we
        have a similar situation, with at most ) edges being
        modified along the spine of the recursion tree. 
\end{proof}


From Lemmas~\ref{lem:choose} and
\ref{lem:removebackedge}--\ref{lem:restore}, it follows that on a
spine of the recursion tree we have the costs:
 on each node which is bounded by  time as there
are at most  back edges in ; ,
 take  time;  and
 are charged  time.  We thus have the following
result,  completing the proof of Theorem~\ref{theorem:optimal_paths}.

\begin{lemma}
	\label{lem:algo_cost}
	Algorithm~ can be implemented with a
        cost fulfilling Eq.~\eqref{eq:abstrac_cost}, thus it takes
        total \mbox{} time.
\end{lemma}

\section{Extended analysis of operations}
\label{app:extend-analys-oper}

In this suplementary section, we present all details and illustrate
with figures the operations  and 
that are performed along a spine of the recursion tree. In order to
better detail the procedures in Lemma~\ref{lem:removebackedge} and
Lemma~\ref{lem:promotebackedge}, we divide them in smaller parts.  We
use bead string  from Fig.~\ref{fig:Certificate} and the
respective spine from Fig.~\ref{fig:spine} as the base for the
examples. This spine contains four binary nodes corresponding to the
back edges in  and an unary node corresponding to the tree edge
. Note that edges are taken in order of the endpoints
 as defined in operation .

By Lemma~\ref{lemma:beadstring}, the impact of operations
 and  in the certificate is
restricted to the biconnected component of . Thus we mainly focus
on maintaining the compacted head  of the bead
string~.

\subsection{Operation right\_update(C,e)} 

\begin{figure*}[!t]
\centering
\subfigure[Step 1]{
\begin{tikzpicture}
[nodeDecorate/.style={shape=circle,inner sep=1pt,draw,thick,fill=black},lineDecorate/.style={-,dashed},elipseDecorate/.style={color=gray!30},
  scale=0.18]

\draw (10,22) circle (9);
\draw (5,11.1) circle (3);

\node (s) at (10,34) [nodeDecorate,color=lightgray,label=above left:] {};
\node (u) at (10,31) [nodeDecorate,label=above left:{ }] {};

\node (tp) at (6.2,13.9) [nodeDecorate,label=right:{ }] {};
\node (t) at (5.5,11) [nodeDecorate,label=left:] {};

\path {
	(s) edge[snake,-,color=lightgray] node {\quad\quad} (u)
	(u) edge node {} (tp)
	(tp) edge node {} (t)
};

\node (a) at (9.3,28) [nodeDecorate,label=left:] {};
\node (b) at (7.1,18) [nodeDecorate,] {};
\node (c) at (13,25) [nodeDecorate,] {};
\node (d) at (14.5,22) [nodeDecorate,label=right:] {};
\node (e) at (11,22) [nodeDecorate,label=below:] {};
\node (f) at (16,19) [nodeDecorate,label=below:] {};
\node (g) at (13,19) [nodeDecorate,] {};
\node (h) at (10,16) [nodeDecorate,] {};

\path {
	(a) edge node {} (c)
	(c) edge node {} (d)
	(d) edge node {} (f)
	(c) edge node {} (e)
	(d) edge node {} (g)
	(b) edge node {} (h)
};

\path {
	(u) edge[dashed,bend left=-40] node {} (tp)
	(f) edge[dashed,bend left=-40] node {} (u)
	(g) edge[dashed,bend left=10] node {} (c)
	(e) edge[dashed,bend left=-10] node {} (u)
	(a) edge[dashed,bend left=5] node {} (h)
};
\end{tikzpicture}
}
\subfigure[Step 2]{
\begin{tikzpicture}
[nodeDecorate/.style={shape=circle,inner sep=1pt,draw,thick,fill=black},lineDecorate/.style={-,dashed},elipseDecorate/.style={color=gray!30},
  scale=0.18]
\draw (10,22) circle (9);
\draw (5,11.1) circle (3);

\node (s) at (10,34) [nodeDecorate,color=lightgray,label=above left:] {};
\node (u) at (10,31) [nodeDecorate,label=above left:{ }] {};

\node (tp) at (6.2,13.9) [nodeDecorate,label=right:{ }] {};
\node (t) at (5.5,11) [nodeDecorate,label=left:] {};

\path {
	(s) edge[snake,-,color=lightgray] node {\quad\quad} (u)
	(u) edge node {} (tp)
	(tp) edge node {} (t)
};

\node (a) at (9.3,28) [nodeDecorate,label=left:] {};
\node (b) at (7.1,18) [nodeDecorate,] {};
\node (c) at (13,25) [nodeDecorate,] {};
\node (e) at (11,22) [nodeDecorate,label=below:] {};
\node (h) at (10,16) [nodeDecorate,] {};

\path {
	(a) edge node {} (c)
	(c) edge node {} (e)
	(b) edge node {} (h)
};

\path {
	(u) edge[dashed,bend left=-40] node {} (tp)
	(e) edge[dashed,bend left=-10] node {} (u)
	(a) edge[dashed,bend left=5] node {} (h)
};

\end{tikzpicture}
}
\subfigure[Step 3]{
\begin{tikzpicture}
[nodeDecorate/.style={shape=circle,inner sep=1pt,draw,thick,fill=black},lineDecorate/.style={-,dashed},elipseDecorate/.style={color=gray!30},
  scale=0.18]
\draw (10,22) circle (9);
\draw (5,11.1) circle (3);

\node (s) at (10,34) [nodeDecorate,color=lightgray,label=above left:] {};
\node (u) at (10,31) [nodeDecorate,label=above left:{ }] {};

\node (tp) at (6.2,13.9) [nodeDecorate,label=right:{ }] {};
\node (t) at (5.5,11) [nodeDecorate,label=left:] {};

\path {
	(s) edge[snake,-,color=lightgray] node {\quad\quad} (u)
	(u) edge node {} (tp)
	(tp) edge node {} (t)
};

\node (a) at (9.3,28) [nodeDecorate,label=left:] {};
\node (b) at (7.1,18) [nodeDecorate,] {};
\node (h) at (10,16) [nodeDecorate,] {};

\path {
	(b) edge node {} (h)
};

\path {
	(u) edge[dashed,bend left=-40] node {} (tp)
	(a) edge[dashed,bend left=5] node {} (h)
};

\end{tikzpicture}
}
\subfigure[Step 4 (final)]{

\begin{tikzpicture}
[nodeDecorate/.style={shape=circle,inner sep=1pt,draw,thick,fill=black},lineDecorate/.style={-,dashed},elipseDecorate/.style={color=gray!30},
  scale=0.18]
\draw (10,22) circle (9) [color=gray!30];
\draw (5,11.1) circle (3);
\draw (9.6,29.5) circle (1.5);
\draw (8,23) circle (5);
\draw (6.7,15.9) circle (2.1);

\node (s) at (10,34) [nodeDecorate,color=lightgray,label=above left:] {};
\node (u) at (10,31) [nodeDecorate,label=above left:{ }] {};

\node (tp) at (6.2,13.9) [nodeDecorate,label=right:{ }] {};
\node (t) at (5.5,11) [nodeDecorate,label=left:] {};

\path {
	(s) edge[snake,-,color=lightgray] node {\quad\quad} (u)
	(u) edge node {} (tp)
	(tp) edge node {} (t)
};

\node (a) at (9.3,28) [nodeDecorate,label=below left:] {};
\node (b) at (7.1,18) [nodeDecorate,] {};
\node (h) at (10,19) [nodeDecorate,] {};

\path {
	(b) edge node {} (h)
};

\path {
	(a) edge[dashed,bend left=5] node {} (h)
};

\end{tikzpicture}
}

\caption{Application of  on a spine of the recursion tree}
\label{fig:oracleleftexample}
\end{figure*}
\begin{lemma}
	\emph{(Lemma~\ref{lem:removebackedge} restated)} In a spine of
	the recursion tree, operations  can be
	implemented in  total time.
\end{lemma}

	In the right branches along a spine, we remove all back edges
	in . This is done by starting from the last edge in
	, i.e. proceeding in reverse DFS postorder. In the
	example from Fig.~\ref{fig:Certificate}, we remove the back
	edges . To update the certificate
	corresponding to , we have to (i) update the
	lowpoints in each vertex of ; (ii) prune vertices that
	cease to be in  after removing a back edge. For a
	vertex  in the tree, there is no need to update~.

	Consider the update of lowpoints in the DFS tree.  For
	a back edge , we traverse the vertices in the
	path from  towards the root . By definition of
	lowpoint, these are the only lowpoints that can change.
	Suppose that we remove back edge  in the example from
	Fig.~\ref{fig:Certificate}, only the lowpoints of the vertices
	in the path from  towards the root  change.
	Furthermore, consider a vertex  in the tree that is an
	ancestor of at least two endpoints  of back edges
	, . The lowpoint of  does not change when we
	remove .  These observations lead us to the following
	lemma.

\begin{lemma}
	In a spine of the recursion tree, the update of lowpoints in
	the certificate by operation  can be done
	in  total time.  \label{lem:lowpoints}
\end{lemma}
\begin{proof}
	Take each back edge  in the order defined by
        . Remove  from  and .
        Starting from , consider each vertex  in the path from
         towards the root .  On vertex , we update
         using the standard procedure: take the
        endpoint  of the first edge in  (the back edge that
        goes the nearest to the root of the tree) and choosing the
        minimum between  and the lowpoint of each child of
        .  When the updated , we
        stop examining the path from  to  since it implies
        that the lowpoint of the vertex can not be further reduced
        (i.e.  is both an ancestor to both  and
        ).

	If  does not change we cannot pay to
	explore its children. In order to get around this, for each
	vertex we dynamically maintain, throughout the spine, a list
	 of its children that have lowpoint equal to
	. Then, we can test in constant time if  and  (the endpoint of the first edge in )
	is not the root . If both conditions are satisfied
	 changes, otherwise it remains equal to
	 and we stop. The total time to create the lists is
	 and the time to update is bounded by the number of
	tree edges traversed, shown to be  in the next
	paragraph.

	The cost of updating the lowpoints when removing all
	back edges  is : there are  tree
	edges and we do not traverse the same tree edge twice since
	the process described stops at the first common ancestor of
	endpoints of back edges  and . By contradiction:
	if a tree edge  would be traversed twice when removing
	back edges  and , it would imply that both 
	and  are ancestors of  and  (as edge 
	is both in the path  to  and the path  to
	) but we stop at the first ancestor of  and
	.
\end{proof}

Let us now consider the removal of vertices that
are no longer in  as consequence of operation
 in a spine of the recursion tree. By removing a
back edge , it is possible that a vertex  previously
in  is no longer in the bead string  (e.g.  is no
longer biconnected to  and thus there is no simple path ). 


\begin{lemma}
	In a spine of the recursion tree, the branches of the DFS that
	are no longer in  due to operation
	 can be removed from the certificate in
	 total time.
	\label{lem:cutbranches}
\end{lemma}
\begin{proof}
	To prune the branches of the DFS tree that are no longer in
        , consider again each vertex  in the path from 
        towards the root  and the vertex , parent of . It is
        easy to check if  is an articulation point by verifying if
        the updated  and there
        exists  not in the subtree of . If  is not in the
        leftmost path, then  is not in the subtree of . If that
        is the case, we have that , and therefore we
        cut the subtree of  and bookkeep it in  to restore
        later. Like in the update the lowpoints, we stop examining the
        path  towards  in a vertex  when
         (the lowpoints and
        biconnected components in the path from  to  do not
        change).  When cutting the subtree of , note that there are
        no back edges connecting it to  ( is an
        articulation point) and therefore there are no updates to the
        lists  and  of the vertices in .  Like in the
        case of updating the lowpoints, we do not traverse the same
        tree edge twice (we use the same halting criterion). 
\end{proof}

With Lemma~\ref{lem:lowpoints} and Lemma~\ref{lem:cutbranches} we
finalize the proof of Lemma~\ref{lem:removebackedge}. 
Fig.~\ref{fig:oracleleftexample} shows the changes the bead string 
from Fig.~\ref{fig:Certificate} goes through in the corresponding spine
of the recursion tree.


\subsection{Operation~left\_update(C,e)} 
In the binary nodes of a spine, we use
the fact that in every left branching from that spine the graph is
the same (in a spine we only remove edges incident to  and on a
left branch from the spine we remove the vertex ) and therefore its
block tree is also the same. In Fig.~\ref{fig:blocktree_without_u},
we show the resulting block tree of the graph from
Fig.~\ref{fig:Certificate} after having removed vertex . However,
the certificates on these left branches are not the same, as they are
rooted at different vertices. In the example we must compute the
certificates  corresponding to bead strings . We do not account for the cost of the left
branch on the last node of spine (corresponding to ) as the
node is unary and we have shown in Lemma~\ref{lem:unary_left} how to
maintain the certificate in  time.

By using the reverse DFS postorder of the back edges, we are able
to traverse each edge in  only an amortized constant number of
times in the spine.
\begin{lemma}
	\emph{(Lemma~\ref{lem:promotebackedge} restated)} The calls to
	operation  in a spine of the recursion tree
	can be charged with a time cost of  to that spine. 
\end{lemma}

To achieve this time cost, for each back edge , we
compute the certificate corresponding to  based on the
certificate of . Consider the compacted head  of the bead string . We use  time to
compute the first certificate  corresponding to bead string
. Fig.~\ref{fig:spine-left-update} shows bead string
 from the example of Fig.~\ref{fig:Certificate}.

\begin{lemma}
	The certificate , corresponding to bead string
	, can be computed in  time.
\end{lemma}
\begin{proof}
	Let  be the last vertex in the path  s.t.
	. Since  is an articulation point, the subtree
	of the DFS tree rooted in  is maintained in the case of
	removal vertex . Therefore the only modifications of the
	DFS tree occur in head  of .

	To compute , we remove  and rebuild the certificate
	starting form  using the algorithm from
	Lemma~\ref{lem:certificate_scratch} restricted to  and
	using  as target and  as a baseline to
	 (instead of the depth). In particular we do
	the following.
	To set  to be in the leftmost path, we perform a
	DFS traversal of graph  starting from  and stop when
	we reach vertex . Then compute the DFS tree, traversing
	the path  first.
	
	{\it Update of .} For each tree edge  in the
	 path, we set , using
	 as a baseline.  During the rest of the traversal,
	when visiting vertex , let  be the parent of  in the
	DFS tree. We set . This maintains the
	property that  for any  ancestor of
	.

	{\it Lowpoints and pruning the tree.}  Bottom-up in
	the DFS-tree, compute the lowpoints using the
	lowpoints of the children.  For  the parent of , if
	 and  is not in the
	leftmost path in the DFS, cut the subtree of  as it does
	not belong to~.

	{\it Computing  and .} In the traversal, when finding
	a back edge , if  is a descendant of  we append
	 to . This maintains the DFS preorder in the
	ancestor back edge list. After the first scan of  is
	over and all the recursive calls returned, re-scan the
	neighborhood of . If  is a back edge and  is an
	ancestor of , we add  to . This maintains the DFS
	postorder in the descendant back edge list.  This procedure
	takes  time.
\end{proof}

\begin{figure}[t!]
\centering
\begin{tikzpicture}
[nodeDecorate/.style={shape=circle,inner sep=1pt,draw,thick,fill=black},lineDecorate/.style={-,dashed},elipseDecorate/.style={color=gray!30},
  scale=0.35]
\draw (5,11.1) circle (3);
\draw[rotate around={-10:(8,23)}] (8,23) ellipse (3 and 5);
\draw[rotate around={-23:(12.6,26.5)}] (12.6,26.5) ellipse (4 and 1);
\draw[rotate around={55:(15,23.5)}] (15,23.5) ellipse (2.1 and 0.5);
\draw (6.7,15.9) circle (2.1);
\draw (17.5,23.5) circle (2.0);
\draw (20.8,23) circle (1.5);

\node (s) at (10,34) [nodeDecorate,color=lightgray,label=above left:] {};
\node (u) at (10,31) [nodeDecorate,color=lightgray,label=above left:{ }] {};

\node (tp) at (6.2,13.9) [nodeDecorate,label=right:{ }] {};
\node (t) at (5.5,11) [nodeDecorate,label=below:] {};
\node (a) at (9.3,28) [nodeDecorate,label=below left:] {};

\path {
	(s) edge[snake,-,color=lightgray] node {\quad\quad} (u)
	(u) edge[color=lightgray] node {} (a)
	(a) edge node {} (tp)
	(tp) edge node {} (t)
};

\node (b) at (7.1,18) [nodeDecorate,] {};
\node (c) at (16,25) [nodeDecorate,] {};
\node (d) at (19.3,23.5) [nodeDecorate,label=above:] {};
\node (e) at (14,22) [nodeDecorate,label=below:] {};
\node (f) at (22,22.2) [nodeDecorate,label=right:] {};
\node (g) at (17,22) [nodeDecorate,] {};
\node (h) at (10,22) [nodeDecorate,] {};

\path {
	(a) edge node {} (c)
	(c) edge node {} (d)
	(d) edge node {} (f)
	(c) edge node {} (e)
	(d) edge node {} (g)
	(b) edge node {} (h)
};

\path {
	(g) edge node {} (c)
	(a) edge node {} (h)


	(u) edge[bend left=-50,color=lightgray!50] node {} (tp)
	(f) edge[bend left=-40,color=lightgray!50] node {} (u)
	(e) edge[bend left=-10,color=lightgray!50] node {} (u)
	(d) edge[bend left=-20,color=lightgray!50] node {} (u)
};

\end{tikzpicture}
\caption{Block tree after removing vertex }
\label{fig:blocktree_without_u}
\end{figure}

To compute each certificate , corresponding to bead string
, we are able to avoid visiting most of the edges that
belong . Since we take  in reverse DFS
postorder, on the spine of the recursion we visit  edges
plus a term that can be amortized.

\begin{lemma}
	For each back edge  with , let 
	be the edges in the first bead in common between 
	and . The total cost of computing all
	certificates  in a spine of the recursion tree is:
	.
	\label{lem:cost-spine-not-amortized}
\end{lemma}
\begin{proof}
	Let us compute the certificate : the certificate
	of the left branch of the th node of the spine where we
	augment the path with back edge  of
	.

	For the general case of  with  we also rebuild
	(part) of the certificate starting from  using the
	procedure from Lemma~\ref{lem:certificate_scratch} but we use
	information gathered in  to avoid exploring useless
	branches of the DFS tree. The key point is that, when we reach
	the first bead in common to both  and
	, we only explore edges internal to this bead.
	If an edge  that leaves the bead leads to , we can reuse
	a subtree of . If  does not lead to , then it
	has already been explored (and cut) in  and there is
	no need to explore it again since it is going to be discarded.

	In detail, we start computing a DFS from  in 
	until we reach a vertex . Note that the
	bead of  has one entry point and one exit point in
	. After reaching  we proceed with the traversal
	using only edges already in . When arriving at a
	vertex  that is not in the same bead of , we stop the
	traversal. If  is in a bead towards , we reuse the
	subtree of  and use  as a baseline of the
	numbering . Otherwise  is in a bead towards
	 and we cut this branch of the certificate. When all
	edges in the bead of  are traversed, we proceed with visit
	in the standard way.

	Given the order we take , each bead is not added more
	than once to a certificate , therefore the total cost
	over the spine is .
	Nevertheless, the internal edges  of the first bead
	in common between  and  are explored
	for each back edge .
\end{proof}

\begin{figure}[t]
\centering
\subfigure[] {

\begin{tikzpicture}
[nodeDecorate/.style={shape=circle,inner sep=1pt,draw,thick,fill=black},lineDecorate/.style={-,dashed},elipseDecorate/.style={color=gray!30},
  scale=0.25]
\draw (10,23.5) circle (2.5);
\draw (10,19.5) circle (1.5);
\draw (10,14) circle (4);
\draw (10,8) circle (2);
\draw (10,3) circle (3);

\node (s) at (10,34) [nodeDecorate,color=lightgray,label=above left:] {};

\node (z2) at (10,26) [nodeDecorate,label=left:] {};
\node (a) at (10,21) [nodeDecorate] {};
\node (b) at (12,23) [nodeDecorate] {};
\node (v) at (10,18) [nodeDecorate,label=left:] {};
\node (c) at (10,14) [nodeDecorate] {};
\node (d) at (10,10) [nodeDecorate] {};
\node (z4) at (10,6) [nodeDecorate,label=right:] {};
\node (t) at (10,2) [nodeDecorate,label=right:] {};

\path {
	(s) edge[snake,-,color=lightgray] node {\quad\quad} (z2)
	(z2) edge node {} (a)
	(a) edge node {} (b)
	(a) edge node {} (v)
	(v) edge node {} (c)
	(c) edge node {} (d)
	(d) edge node {} (z4)
	(z4) edge node {} (t)
};

\path {
	(d) edge[dashed,bend left=-50] node {} (v)
	(b) edge[dashed,bend left=-30] node {} (z2)
};
\end{tikzpicture}
}
\quad
\subfigure[] {

\begin{tikzpicture}
[nodeDecorate/.style={shape=circle,inner sep=1pt,draw,thick,fill=black},lineDecorate/.style={-,dashed},elipseDecorate/.style={color=gray!30},
  scale=0.25]
\draw (10,28) circle (2);
\draw (10,23.5) circle (2.5);
\draw (10,19.5) circle (1.5);
\draw (10,14) circle (4);
\draw (10,8) circle (2);
\draw (10,3) circle (3);

\node (s) at (10,34) [nodeDecorate,color=lightgray,label=above left:] {};

\node (z1) at (10,30) [nodeDecorate,label=left:] {};
\node (z2) at (10,26) [nodeDecorate,label=left:] {};
\node (a) at (10,21) [nodeDecorate] {};
\node (b) at (12,23) [nodeDecorate] {};
\node (v) at (10,18) [nodeDecorate,label=left:] {};
\node (c) at (10,14) [nodeDecorate] {};
\node (d) at (10,10) [nodeDecorate] {};
\node (z4) at (10,6) [nodeDecorate,label=right:] {};
\node (t) at (10,2) [nodeDecorate,label=right:] {};

\path {
	(s) edge[snake,-,color=lightgray] node {\quad\quad} (z1)
	(z1) edge node {} (z2)
	(z2) edge node {} (a)
	(a) edge node {} (b)
	(a) edge node {} (v)
	(v) edge node {} (c)
	(c) edge node {} (d)
	(d) edge node {} (z4)
	(z4) edge node {} (t)
};

\path {
	(d) edge[dashed,bend left=-50] node {} (v)
	(b) edge[dashed,bend left=-30] node {} (z2)
};
\end{tikzpicture}
}
\quad
\subfigure[] {

\begin{tikzpicture}
[nodeDecorate/.style={shape=circle,inner sep=1pt,draw,thick,fill=black},lineDecorate/.style={-,dashed},elipseDecorate/.style={color=gray!30},
  scale=0.25]
\draw (10,23.5) circle (2.5);
\draw (10,19.5) circle (1.5);
\draw (10,14) circle (4);
\draw (10,8) circle (2);
\draw (10,3) circle (3);

\node (s) at (10,34) [nodeDecorate,color=lightgray,label=above left:] {};

\node (z3) at (10,26) [nodeDecorate,label=left:] {};
\node (a) at (10,21) [nodeDecorate] {};
\node (v) at (10,18) [nodeDecorate,label=left:] {};
\node (c) at (10,14) [nodeDecorate] {};
\node (d) at (10,10) [nodeDecorate] {};
\node (z4) at (10,6) [nodeDecorate,label=right:] {};
\node (t) at (10,2) [nodeDecorate,label=right:] {};

\path {
	(s) edge[snake,-,color=lightgray] node {\quad\quad} (z3)
	(z3) edge node {} (a)
	(a) edge node {} (v)
	(v) edge node {} (c)
	(c) edge node {} (d)
	(d) edge node {} (z4)
	(z4) edge node {} (t)
};

\path {
	(d) edge[dashed,bend left=-50] node {} (v)
};
\end{tikzpicture}
}
\quad
\subfigure[] {

\begin{tikzpicture}
[nodeDecorate/.style={shape=circle,inner sep=1pt,draw,thick,fill=black},lineDecorate/.style={-,dashed},elipseDecorate/.style={color=gray!30},
  scale=0.18]
\draw (10,3) circle (3);

\node (s) at (10,34) [nodeDecorate,color=lightgray,label=left:] {};

\node (z4) at (10,6) [nodeDecorate,label=right:] {};
\node (t) at (10,2) [nodeDecorate,label=right:] {};

\path {
	(s) edge[snake,-,color=lightgray] node {\quad\quad} (z4)
	(z4) edge node {} (t)
};

\end{tikzpicture}
}
\caption{Certificates of the left branches of a spine}
\label{fig:spine-left-update}
\end{figure}

Although the edges in  are in a common bead between
 and , these edges must be visited. The
entry point in the common bead can be different for  and
, the DFS tree of that bead can also be different. For an
example, consider the case where  are all in the
same bead after the removal of . The bead strings  are the same, but the roots  of the
certificate are different, so we have to compute the corresponding DFS
of the first bead  times. Note that this is not the case for
the other beads in common: the entry point is always the same.

\begin{lemma}
	The cost  on a spine of the
	recursion tree can be amortized to .
	\label{lem:left-amortize}
\end{lemma}
\begin{proof}
	We can charge the cost  of exploring the edges
	in the first bead in common between  and
	 to another node in the recursion tree. Since
	this common bead is the head of at least one certificate in
	the recursion subtree of the left child of the th node of
	the spine.  Specifically, we charge the first and only node in
	the \emph{leftmost} path of the th child of the spine that
	has exactly the edges  as head of its bead string:
	(i) if  it corresponds to a unary node or a
	leaf in the recursion tree and therefore we can charge it with
	 cost; (ii) otherwise it corresponds to a first node of
	a spine and therefore we can also charge it with
	. We use this charging scheme when 
	and the cost is always charged in the leftmost recursion path
	of th node of the spine, consequently we never charge a
	node in the recursion tree more than once. 
\end{proof}

Lemmas~\ref{lem:cost-spine-not-amortized} and~\ref{lem:left-amortize}
finalize the proof of Lemma~\ref{lem:promotebackedge}. 
Fig.~\ref{fig:spine-left-update} shows the certificates of bead strings
 on the left branches of the spine from
Figure~\ref{fig:spine}.




