\documentclass[a4paper]{article}


\usepackage{a4wide}
\usepackage{amsmath,amssymb,amsthm}
\usepackage{graphicx}

\usepackage[ruled]{algorithm}
\usepackage{algorithmicx}
\usepackage{paralist}
\usepackage[noend]{algpseudocode}
\usepackage{color}
\usepackage{ifthen}

\newcommand{\marekscomment}[1]{{\color{red}{\textbf{Marek's comment:} #1}}}
\renewcommand{\baselinestretch}{1.05}


\title{Online Algorithms for Multi-Level Aggregation\thanks{Research partially supported by NSF grants CCF-1536026, CCF-1217314 and OISE-1157129,
	Polish NCN grants DEC-2013/09/B/ST6/01538, 2015/18/E/ST6/00456,
	project 14-10003S of GA \v{C}R and GAUK project 548214.
}}

\author{Marcin Bienkowski\thanks{Institute of Computer Science, University of Wroc{\l}aw, Poland}
\and
Martin B\"{o}hm\thanks{Computer Science Institute, Charles University, Czech Republic}
\and
Jaroslaw Byrka\footnotemark[2]
\and
Marek Chrobak\thanks{Department of Computer Science, University of California at
  Riverside, USA}
\and
Christoph D\"{u}rr\thanks{Sorbonne Universit\'{e}s, UPMC Univ Paris 06, CNRS, LIP6, Paris, France}
\and
Luk\'{a}\v{s} Folwarczn\'{y}\footnotemark[3]
\and
{\L}ukasz Je\.{z}\footnotemark[2]
\and
Ji\v{r}\'{\i} Sgall\footnotemark[3]
\and
Nguyen Kim Thang\thanks{IBISC, Universit\'{e} d'Evry Val d'Essonne, France}
\and
Pavel Vesel\'{y}\footnotemark[3]}


\newtheorem{theorem}{Theorem}[section]
\newtheorem{definition}[theorem]{Definition}
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{corollary}[theorem]{Corollary}

\newcommand{\etal}{et~al.}



\newcommand{\hatc}{{\widehat{c}}}
\newcommand{\hatr}{{\widehat{r}}}
\newcommand{\hatx}{\hat{x}}
\newcommand{\haty}{\hat{y}}
\newcommand{\hatz}{{\hat{z}}}
\newcommand{\barj}{{\bar{\jmath}}}

\newcommand{\bare}{{\bar e}}
\newcommand{\barx}{{\bar x}}
\newcommand{\bary}{\bar y}
\newcommand{\barz}{{\bar z}}
\newcommand{\barr}{{\bar r}}

\newcommand{\tilder}{{\tilde r}}
\newcommand{\tildeX}{{\tilde X}}


\newcommand{\bara}{{\bar a}}
\newcommand{\barm}{{\bar m}}
\newcommand{\bart}{{\bar t}}

\newcommand{\barA}{{\overline A}}
\newcommand{\barC}{\overline{C}}
\newcommand{\barQ}{\overline{Q}}
\newcommand{\barO}{\overline{O}}
\newcommand{\barP}{\overline{P}}
\newcommand{\barT}{\overline{T}}
\newcommand{\barX}{\overline{X}}
\newcommand{\barY}{\overline{Y}}
\newcommand{\barZ}{\overline{Z}}

\newcommand{\UU}[3]{{\bar U_{{#1},{#2},{#3}}}}
\newcommand{\PP}[4]{{\bar P_{{#1},{#2},{#3},{#4}}}}
\newcommand{\EE}[1]{{\bar E}_{#1}}
\newcommand{\barbeta}{{\bar \beta}}

\newcommand{\bfv}{{\bf v}}
\newcommand{\bfx}{{\bf x}}
\newcommand{\bfy}{{\bf y}}
\newcommand{\bfz}{{\bf z}}
\newcommand{\bfQ}{{\bf Q}}
\newcommand{\bfR}{{\bf R}}
\newcommand{\bfS}{{\bf S}}
\newcommand{\bfT}{{\bf T}}
\newcommand{\bfV}{{\bf V}}

\newcommand{\calA}{{\cal A}}
\newcommand{\calB}{{\cal B}}
\newcommand{\calD}{{\cal D}}
\newcommand{\calG}{{\cal G}}
\newcommand{\calH}{{\cal H}}
\newcommand{\calJ}{{\cal J}}
\newcommand{\calK}{{\cal K}}
\newcommand{\calL}{{\cal L}}
\newcommand{\calM}{{\cal M}}
\newcommand{\calN}{{\cal N}}
\newcommand{\calO}{{\cal O}}
\newcommand{\calP}{{\cal P}}
\newcommand{\calR}{{\cal R}}
\newcommand{\calU}{{\cal U}}
\newcommand{\calX}{{\cal X}}
\newcommand{\calI}{{\cal I}}
\newcommand{\calT}{{\cal T}}

\newcommand{\bbI}{\mathbb{I}}

\newcommand{\vecS}{{\bar S}}
\newcommand{\vecT}{{\bar T}}

\newcommand{\eps}{{\varepsilon}}

\newcommand{\tstar}{{t^\ast}}

\newcommand{\e}{\mathrm{e}}



\newcommand{\braced}[1]{{ \left\{ #1 \right\} }}
\newcommand{\angled}[1]{{ \left\langle #1 \right\rangle }}
\newcommand{\brackd}[1]{{ \left[ #1 \right] }}
\newcommand{\parend}[1]{{ \left( #1 \right) }}
\newcommand{\barred}[1]{{ \left| #1 \right| }}
\newcommand{\ceiling}[1]{{ \lceil #1 \rceil }}
\newcommand{\floor}[1]{{ \lfloor #1 \rfloor}}



\newcommand{\cc}[1]{\overline{#1}} \newcommand{\suchthat}{{\;:\;}}
\newcommand{\assign}{\,{\leftarrow}\,}
\newcommand{\COST}{\mbox{\rm\textsc{Cost}}}
\newcommand{\cost}{\mbox{\rm\textsf{cost}}}
\newcommand{\tcost}{\mbox{\rm\textsf{tcost}}}
\newcommand{\wcost}{\mbox{\rm\textsf{wcost}}}
\newcommand{\scost}{\mbox{\rm\textsf{scost}}}
\newcommand{\opt}{\mbox{\rm\textsf{opt}}}
\newcommand{\alg}{\mbox{\rm\textsf{alg}}}
\newcommand{\onephasecost}{\mbox{\rm\textsf{c}}}
\newcommand{\init}{{\mbox{\tiny\it init}}}
\newcommand{\tr}{{\sf trl}}
\newcommand{\deficiency}{{\mbox{dfc}}}
\newcommand{\deadline}{{\mbox{ddl}}}
\newcommand{\length}{\ell}
\newcommand{\depth}{\textit{depth}}
\newcommand{\parent}{\textit{parent}}
\newcommand{\surplus}{{\delta}}

\newcommand{\nat}{\mathbb{N}}
\newcommand{\reals}{{\mathbb R}}
\newcommand{\rational}{{\mathbb Q}}
\newcommand{\posreals}{{\mathbb R}^+}
\newcommand{\complex}{\mathbb{C}}
\newcommand{\half}{{\mbox{}}}
\newcommand{\first}{{\mbox{\it first}}}
\newcommand{\malymin}{{\mbox{\tiny\rm min}}}
\newcommand{\malymax}{{\mbox{\tiny\rm max}}}
\newcommand{\LHS}{{\mbox{\rm LHS}}}
\newcommand{\RHS}{{\mbox{\rm RHS}}}
\newcommand{\Prob}{\textrm{Pr}}
\newcommand{\rounddn}[2]{\lfloor #1\rfloor_{#2}}
\newcommand{\roundup}[2]{\lceil #1\rceil_{#2}}


\newcommand{\algAfive}{\mbox{\sc Balance}}
\newcommand{\algDoubling}{\mbox{\sc OnlDoubling}}
\newcommand{\algCovSubT}{\mbox{\sc CovSubT}}
\newcommand{\algLBL}{\mbox{\sc OffLByL}}
\newcommand{\OnAlgTreesDeadlines}{{\sc OnlTreeD}}
\newcommand{\OnAlgTreesGeneral}{{\sc OnlTree}}
\newcommand{\DLINE}{\mbox{\textsc{OnlLine}}}


\newcommand{\NP}{{\mathbb{NP}}}
\newcommand{\APX}{{\mathbb{APX}}}
\newcommand{\JRPD}{\mbox{\rm\textsf{JRP-D}}}
\newcommand{\JRP}{\mbox{\rm\textsf{JRP}}}
\newcommand{\TCPAP}{\mbox{\rm\textsf{TCP-AP}}}
\newcommand{\MLAP}{\mbox{\rm\textsf{MLAP}}}
\newcommand{\MLAPL}{\mbox\rm{\textsf{MLAP-L}}}
\newcommand{\MLAPD}{\mbox{\rm\textsf{MLAP-D}}}
\newcommand{\SPMLAP}{\mbox{\rm\textsf{1P-MLAP}}}
\newcommand{\SPMLAPD}{\mbox{\rm\textsf{1P-MLAP-D}}}
\newcommand{\SPMLAPL}{\mbox{\rm\textsf{1P-MLAP-L}}}


\newcommand{\schedL}{\mbox{\rm\textsf{L}}}
\newcommand{\schedS}{\mbox{\rm\textsf{S}}}
\newcommand{\optschedS}{\mbox{\rm\textsf{S}}^\ast}
\newcommand{\pseudoschedS}{\overline{\mbox{\rm\textsf{S}}}}
\newcommand{\schedG}{\mbox{\rm\textsf{G}}}
\newcommand{\schedH}{\mbox{\rm\textsf{H}}}


\newcommand{\optx}{x^\ast}
\newcommand{\opty}{y^\ast}

\newcommand{\optO}{O^\ast}
\newcommand{\compl}[1]{\overline{#1}}

\newcommand{\treeroot}[1]{r_{#1}}
\newcommand{\leaves}{\textit{leaves}}
\newcommand{\expiration}{\theta}
\newcommand{\noftransm}{{\textit{ont}}}
\newcommand{\shift}{{\textit{shift}}}

\newcommand{\trignode}{\sigma}
\newcommand{\advtrans}{\mbox{\rm\textsf{nos}}}
\newcommand{\urgentnodes}{\mbox{\rm\textsf{Urgent}}}
\newcommand{\treematurity}{\mu}
\newcommand{\vertmaturity}{M}
\newcommand{\children}{\mbox{\rm\textsf{Chld}}}
\newcommand{\prv}[2]{\mbox{\rm Prev}^#1(#2)}
\newcommand{\nxt}[3]{\mbox{\rm Next}^#1(#2,#3)}
\newcommand{\matvt}{{t^\ast}}


\newcommand{\emdash}{\hspace{1mm}---\hspace{1mm}}
\newcommand{\ALG}{\textsc{Alg}}
\newcommand{\OPT}{\textsc{Opt}}
\newcommand{\CALG}{\ensuremath{C_\textnormal{ALG}}}
\newcommand{\COPT}{\ensuremath{C_\textnormal{OPT}}}



\newcommand{\onehalf}{{\textstyle\frac{1}{2}}}
\newcommand{\threehalfs}{{\textstyle\frac{3}{2}}}
\newcommand{\onethird}{{\textstyle\frac{1}{3}}}

\newcommand{\twothirds}{{\textstyle\frac{2}{3}}}
\newcommand{\fourthirds}{{\textstyle\frac{4}{3}}}
\newcommand{\fivethirds}{{\textstyle\frac{5}{3}}}

\newcommand{\onefourth}{{\textstyle\frac{1}{4}}}
\newcommand{\threefourths}{{\textstyle\frac{3}{4}}}

\newcommand{\onefifth}{{\textstyle\frac{1}{5}}}
\newcommand{\twofifths}{{\textstyle\frac{2}{5}}}
\newcommand{\threefifths}{{\textstyle\frac{3}{5}}}

\newcommand{\onesixth}{{\textstyle\frac{1}{6}}}
\newcommand{\oneeight}{{\textstyle\frac{1}{8}}}
\newcommand{\oneeighteenth}{{\textstyle\frac{1}{18}}}
\newcommand{\onethirtysixth}{{\textstyle\frac{1}{36}}}



\begin{document}

\maketitle


\begin{abstract}
In the \emph{Multi-Level Aggregation Problem} ({\MLAP}), requests arrive at
the nodes of an edge-weighted tree , and have to be served 
eventually.  A \emph{service} is defined as a subtree  of  that 
contains its root. This subtree~ serves all
requests that are pending in the nodes of , and the cost of this service is
equal to the total weight of . Each request also incurs waiting cost
between its arrival and service times. The objective is to minimize the total
waiting cost of all requests plus the total cost of all service subtrees.
{\MLAP} is a generalization of some well-studied optimization problems; for
example, for trees of depth , {\MLAP} is equivalent to the TCP
Acknowledgment Problem, while for trees of depth , it is equivalent to the
Joint Replenishment Problem. Aggregation problems for trees of arbitrary depth
arise in multicasting, sensor networks, communication in organization
hierarchies, and in supply-chain management. The instances of {\MLAP}
associated with these applications are naturally online, in the sense that
aggregation decisions need to be made without information about future
requests.

Constant-competitive online algorithms are known for {\MLAP} with one or two
levels. However, it has been open whether there exist constant competitive
online algorithms for trees of depth more than .  Addressing this open
problem, we give the first constant competitive online algorithm for trees
of arbitrary (fixed) depth. The competitive ratio is ,
where  is the depth of . The algorithm works for arbitrary waiting
cost functions, including the variant with deadlines.
We include several additional results in the paper. We show that a standard
lower-bound technique for {\MLAP}, based on so-called \emph{Single-Phase}
instances, cannot give super-constant lower bounds (as a function of the tree
depth). This result is established by giving an online algorithm with optimal
competitive ratio  for such instances on arbitrary trees. 
We prove that, in the offline case, these instances can be solved to
optimality in polynomial time.
We also study the {\MLAP} variant when the tree is a path, for which we give
a lower bound of  on the competitive ratio, improving the lower bound known 
for general {\MLAP}.  We complement this with a matching upper bound for the 
deadline setting. 
In addition, for arbitrary trees,
we give a simple 2-approximation algorithm for offline {\MLAP} 
with deadlines.
\end{abstract}




\section{Introduction}
\label{sec: introduction}

Certain optimization problems can be formulated as aggregation problems. They
typically arise when expensive resources can be shared by multiple agents, who
incur additional expenses for accessing a resource. 
For example, costs may be associated with
waiting until the resource is accessible, or, if the resource is not in the
desired state, a costly setup or retooling may be required.


\paragraph{1-level aggregation.}

A simple example of an aggregation problem is the \emph{TCP Acknowledgment
Problem ()}, where control messages (``agents'') waiting for transmission across a
network link can be aggregated and transmitted in a~single packet (``resource''). 
Such aggregation can
reduce network traffic, but it also results in undesirable delays. A reasonable compromise
is to balance the two costs, namely the number of transmitted
packets and the total delay, by minimizing their weighted sum~\cite{tcp-ack-det-journal}.
Interestingly,  is equivalent to the classical Lot Sizing Problem studied in the operations research literature
since the 1950s. (See, for example, \cite{wagner_whitin_58}.) In the offline variant of , that is
when all arrival times of control messages are known beforehand, an optimal schedule for
aggregated packets can be computed with dynamic programming in time ~\cite{aggarwal_park_93}.
In practice, however, packet aggregation decisions must be done on the fly,
without any information about future message releases. This scenario is captured by the
online variant of  that has also been well studied; it is known that the optimal competitive
ratio is  in the deterministic case \cite{tcp-ack-det-journal}
and  in the randomized
case~\cite{tcp-ack,online-primal-dual-book,tcp-ack-lower-bound}.
Online variants of  that use different assumptions or objective functions 
were also examined in the literature~\cite{tcp-ack-logp,tcp-ack-long-delays}.


\paragraph{2-level aggregation.}

Another optimization problem involving aggregation is the \emph{Joint Replenishment Problem
()}, well-studied in operations research.
 models tradeoffs that arise in supply-chain management.
One such scenario involves optimizing shipments of goods from a
supplier to  retailers, through a shared warehouse, in response to their
demands.  In , aggregation takes place at two levels: items addressed to
different retailers can be shipped together to the warehouse, at a fixed cost,
and then multiple items destined to the same retailer can be shipped  from the warehouse to
this retailer together, also at a fixed cost, which can be  different for different
retailers. Pending demands accrue waiting cost until they are satisfied by a shipment.
The objective is to minimize the sum of all shipment costs and all waiting costs.

 is known to be -hard~\cite{jrp-arkin}, and
even -hard~\cite{jrp-deadlines-nonner,bienkowski_jrpd_2013}.
The currently best approximation,
due to Bienkowski~{\etal}~\cite{jrp-soda-2014}, achieves a factor of ,
improving on earlier work by
Levi~{\etal}~\cite{jrp-owmr-levi-soda,jrp-owmr-levi-journal,jrp-owmr-levi-approx}.
In the deadline variant of , denoted ,
there is no cost for waiting, but each demand needs to be satisfied before its deadline.
As shown in~\cite{bienkowski_jrpd_2013},  can be approximated with ratio .

For the online variant of ,
Buchbinder~{\etal}~\cite{jrp-online-buchbinder} gave a -competitive algorithm using
a primal-dual scheme (improving an earlier bound of  in~\cite{aggregation-bkv})
and proved a lower bound of , that was subsequently
improved to ~\cite{jrp-soda-2014}.
The optimal competitive ratio for  is ~\cite{jrp-soda-2014}.


\paragraph{Multiple-level aggregation.}  

 and  can be
thought of as aggregation problems on edge-weighted trees of depth  and ,
respectively. In , this tree is just a single edge between the sender 
and the recipient. In , this tree consists of the root (supplier),
with one child (warehouse), and any number of grandchildren (retailers).
A shipment can be represented by a subtree of this tree and edge weights represent
shipping costs. These trees capture the general
problem on trees of depth  and , as the children of the root can
be considered separately (see Section~\ref{sec: preliminaries}).

This naturally
extends to trees of any depth , where aggregation is allowed at each level.
Multi-level message aggregation has been, in fact, studied in 
communication networks in several contexts. In multicasting, protocols for aggregating
control messages (see \cite{bortnikov_cohen_infocom_98,badrinath_sudame_gathercast_00}, for example)
can be used to reduce the so-called \emph{ack-implosion}, the
proliferation of control messages routed to the source.
A similar problem arises in energy-efficient data aggregation and fusion in
sensor networks~\cite{hu_cao_may_sensors_05,yuan_et_al_data_fusion_03}.
Outside of networking, tradeoffs between the cost of communication and delay arise in
message aggregation in organizational hierarchies~\cite{Papadimitriou_96}.
In supply-chain management, multi-level variants of lot sizing have been
studied~\cite{wallance_et_al_multistage_assembly_73,kims_multilevel_lot_sizing_97}.
The need to consider more tree-like (in a broad sense) supply hierarchies
has also been advocated in~\cite{Lambert_Cooper_issues_chain_management_00}.

These applications have inspired research on offline and online
approximation algorithms for multi-level aggregation problems.
Becchetti~{\etal}~\cite{packet-aggregation-becchetti} gave a -approximation
algorithm for the deadline case. (See also~\cite{aggregation-bkv}.)
Pedrosa~\cite{lehilton-note} showed, adapting an algorithm of
Levi~{\etal}~\cite{jrp-levi-2-approx} for the multi-stage assembly problem,
that there is a -approximation algorithm for general waiting cost functions, 
where  can be made arbitrarily small.

In the online case,
Khanna~{\etal}~\cite{khanna-message-aggregation} gave a rent-or-buy solution
(that serves a group of requests once their waiting cost reaches the cost
of their service) and showed that their algorithm is -competitive,
where  is defined as the sum of all edge weights. 
However, they assumed that
each request has to wait at least one time unit. This assumption is crucial for their
proof, as demonstrated by Brito~{\etal}~\cite{aggregation-bkv}, who showed that
the competitive ratio of a rent-or-buy strategy is , even
for paths with  edges. 
The same assumption of a minimal cost for a request and a ratio dependent
on the edge-weights is also essential in the work of
Vaya~\cite{Vaya_delay_deliver_12}, who studies a variant of the
problem with bounded bandwidth (the number of packets that can be
served by a single edge in a single service).

The existence of a primal-dual -approximation algorithm \cite{lehilton-note, jrp-levi-2-approx}
for the offline problem suggests the possibility of constructing an online algorithm along the lines of \cite{online-primal-dual-book}. Nevertheless, despite substantial effort of many researchers,
the online multi-level setting remains wide open.
This is perhaps partly due to impossibility of direct emulation of
the cleanup phase in primal-dual offline algorithms in the online setting, 
as this cleanup is performed in the ``reverse time'' order.

The case when the tree is just a path has also been studied.
An offline polynomial-time algorithm that computes an optimal schedule was given in~\cite{aggregation_wads_2013}.
For the online variant,
Brito {\etal}~\cite{aggregation-bkv} gave an -competitive algorithm.
This result was improved by Bienkowski {\etal}~\cite{aggregation_wads_2013} who showed that
the competitive ratio of this problem is between  and .


\subsection{Our Contributions}

We study online competitive algorithms for multi-level aggregation. Minor technical
differences notwithstanding, our model is equivalent to those studied
in~\cite{aggregation-bkv,khanna-message-aggregation}, also extending the
deadline variant in~\cite{packet-aggregation-becchetti} and the assembly
problem in~\cite{jrp-levi-2-approx}. We have decided to choose a more generic
terminology to emphasize general applicability of our model and techniques.

Formally, our model consists of a tree  with positive weights assigned to edges,
and a set  of requests that arrive in the nodes of  over time. These
requests are served by subtrees rooted at the root of . Such a
subtree  serves all requests pending at the nodes of  at cost equal to
the total weight of . Each request incurs a waiting cost, defined by 
a~non-negative and non-decreasing function of time, which may be different for
each request. The objective is to minimize the sum of the total
service and waiting costs. We call this the \emph{Multi-Level Aggregation
Problem} ({\MLAP}).

In most earlier papers on aggregation problems, the waiting cost function is
linear, that is, it is
assumed to be simply the delay between the times when a request arrives and
when it is served. We denote this version by  {\MLAPL}.
However, most of the algorithms for this model extend naturally to arbitrary cost
functions.
Another variant is  {\MLAPD}, where each request is given a certain deadline,
has to be served before or at its deadline, and there is no penalty associated
with waiting. This can be modeled by the waiting cost function that is  up to
the deadline and  afterwards.

In this paper, we mostly focus on the online version of {\MLAP}, where an algorithm needs to
produce a schedule in response to requests that arrive over time.
When a request appears, its waiting cost function is
also revealed. At each time , the online algorithm needs to decide whether to
generate a service tree at this time, and if so, which nodes should be included in this tree.


\begin{table}
\begin{center}
\begin{tabular}{r|l|l|l|l|}
	& \multicolumn{2}{c|}{\MLAP\ and \MLAPL} & \multicolumn{2}{c|}{\MLAPD} \\
\hline
 & upper & lower & upper & lower \\
\hline
depth 1 & ~\cite{tcp-ack-det-journal} & 2~\cite{tcp-ack-det-journal}
& 1 & 1 \\
rand.~alg.~for depth 1 & ~\cite{tcp-ack} &
1.582~\cite{tcp-ack-lower-bound} &
1 & 1 \\
depth 2 & 3~\cite{jrp-online-buchbinder} & 2.754~\cite{jrp-soda-2014} & 2~\cite{jrp-soda-2014} & 2~\cite{jrp-soda-2014} \\
fixed depth  &  & 2.754 &  & 2 \\
paths of arbitrary depth & ~\cite{aggregation_wads_2013} & 3.618~\cite{aggregation_wads_2013}, {\bf 4} & {\bf 4} & {\bf 4} \\
\hline
\end{tabular}
\end{center}
\caption{Previous and current bounds on the competitive ratios for {\MLAP} for trees of various depths.
Ratios written in bold are shown in this paper. Unreferenced results are either immediate consequences of
other entries in the table or trivial observations.
Asterisked ratios represent results for {\MLAP} with arbitrary waiting cost functions, which, though
not explicitly stated in the respective papers,  are straightforward extensions of the
corresponding results for {\MLAPL}. Some values in the table are approximations:
 represents  and  represents , where  is the golden ratio.
}
\label{tab:results}
\end{table}

The main result of our paper is an -competitive algorithm
for {\MLAP} for trees of depth , presented in 
Section~\ref{sec: competitive algorithm for mlap}.  A simpler -competitive
algorithm for {\MLAPD} is presented in Section~\ref{sec: competitive algorithm for mlap-d}. 
No competitive algorithms have been known so far
for online {\MLAP} for arbitrary depth trees, even for the special case of
{\MLAPD} on trees of depth .


For both results we use a reduction, described in Section~\ref{sec: reduction to L-decreasing trees},
of the general problem to the special case of trees with fast decreasing weights described. 
For such trees we then provide an explicit competitive algorithm. 
While our algorithm is compact and elegant, it is not a straightforward
extension of the 2-level algorithm.  (In fact, we have been able to show that na\"{\i}ve 
extensions of the latter algorithm are not competitive.)
It is based on carefully constructing a sufficiently large service tree
whenever it appears that an urgent request must be served. The specific structure of the service 
tree is then heavily exploited in an amortization argument that constructs a
mapping from the algorithm's cost to the cost of the optimal schedule.
We believe that these three new techniques: the reduction to trees with fast decreasing weights,
the construction of the service trees, and our charging scheme, 
will be useful in further studies of online aggregation problems.

In Section~\ref{sec: one-phase MLAP} we study a version of
, that we refer to as \emph{Single-Phase} {\MLAP} (or
), in which all requests arrive at the beginning, but they
also have a common \emph{expiration time} that we denote by
.  Any request not served by time~ pays
waiting cost at time~ and does not need to be served
anymore. In spite of the expiration-date feature, it can be shown that
 can be represented as a special case of .  
 is a crucial tool in all the lower bound proofs in the literature
for competitive ratios of {\MLAP}, including those in~\cite{jrp-online-buchbinder,aggregation_wads_2013}, 
as well as in our lower bounds in Section~\ref{sec: mlap on paths}. 
It also has a natural interpretation in the context of  (-level ), if we
allow all orders to be canceled, say, due to changed market
circumstances.  In the online variant of  all requests are
known at the beginning, but the expiration time  is
unknown.  For this version we give an online algorithm with
competitive ratio , matching the lower bound.
Since  can be expressed as a special case of , our result
implies that the techniques
from~\cite{jrp-online-buchbinder,aggregation_wads_2013} cannot be used
to prove a lower bound larger than  on the competitive ratio for ,
and any study of the dependence of the competitive
ratio on the depth  will require new insights and techniques.

In Section~\ref{sec: mlap on paths} we consider  on paths.
For this case, we give a -competitive algorithm for {\MLAPD} and we provide
a matching lower bound.  We show that the same lower bound of  applies to 
 as well, improving the previous lower bound of 
from~\cite{aggregation_wads_2013}.

In addition, we provide two results on offline algorithms (for arbitrary trees).  
In Section~\ref{sec: mlap with deadlines} we provide a 2-approximation
algorithm for , significantly simpler than the LP-rounding
algorithm in~\cite{packet-aggregation-becchetti} with the same ratio.
In Section~\ref{sec: 1p-mlap with deadlines}, we give a polynomial
time algorithm that computes optimal solutions for .

Finally, in Section~\ref{sec: general waiting costs}, we discuss
several technical issues concerning the use of general functions as
waiting costs in . In particular, when presenting our algorithms for 
we assume that all waiting cost functions are continuous (which cannot directly capture some
interesting variants of ).
This is done, however, only for technical convenience; as explained in Section~\ref{sec: general waiting costs},
these algorithms can be extended to left-continuous
functions, which allows to model {\MLAPD} as a special case
of {\MLAP}. We also consider two alternative models for {\MLAP}: the
discrete-time model and the model where not all requests need to be
served, showing that our algorithms can be extended to these models as well.

An extended abstract of this work appeared in the proceedings of  
24th Annual European Symposium on Algorithms (ESA'16)~\cite{Bienkowski_etal_multilevel_esa_2016}.


\section{Preliminaries}
\label{sec: preliminaries}

\paragraph{Weighted trees.}

Let  be a tree with root .
For any set of nodes  and a node ,  denotes
the set of all descendants of  in ; in particular,  is 
the \emph{induced subtree} of  rooted at .
The parent of a node  is denoted .
The \emph{depth of }, denoted , is
the number of edges on the simple path from  to . In
particular,  is at depth . The depth  of  is the
maximum depth of a node of .

We will deal with weighted trees in this paper. For , by
 or  we denote the weight of the edge
connecting node  to its parent. For the sake of convenience,
we will often refer to  as the weight of .
We assume that all these weights
are positive. We extend this notation to  by setting .
If  is any set of nodes of , then the weight of  is
.


\paragraph{Definition of .}

A \emph{request}  is specified by a triple , where  is the
node of  in which  is issued,  is the non-negative
\emph{arrival time} of , and  is the waiting cost
function of . We assume that  for  and  is non-decreasing for . 
 is the variant of  with linear waiting costs; that is,
for each request  we have
, for .
In , the variant with deadlines,
we have  for  and
 for , where  is called
the \emph{deadline} of request .

In our algorithms for  with general costs we will be assuming that 
all waiting cost functions are continuous.
This is only for technical convenience and we discuss more general waiting cost
functions in Section~\ref{sec: general waiting costs};
we also show there that {\MLAPD} can be considered a special case of {\MLAP},
and that our algorithms can be extended to the discrete-time model.

A \emph{service} is a pair , where  is a subtree of 
rooted at  and  is the time of this service. We will
occasionally refer to  as the service tree (or just service) at
time , or even omit  altogether if it is understood from
context.

An instance  of the \emph{Multi-Level
Aggregation Problem} ({\MLAP}) consists of a weighted tree 
with root  and a set  of requests arriving at the nodes of
.  A \emph{schedule} is a set  of services. For a
request , let  be the service in  with minimal
 such that  and .  We then say
that  \emph{serves}  and the \emph{waiting cost} of
 in  is defined as
. Furthermore, the request 
is called \emph{pending} at all times in the interval .
Schedule  is called \emph{feasible} if all requests in
 are served by .

The cost of a feasible schedule , denoted , is
defined by

where  is the total service cost and  is the total waiting cost, that is

The objective of  is to compute a feasible schedule 
for  with minimum .


\paragraph{Online algorithms.}

We use the standard and natural definition of online algorithms and the competitive ratio. 
We assume the continuous time model. The computation starts at time  and from then on the
time gradually progresses. At any time  new requests can arrive. If the current time is
, the algorithm has complete information about the requests that arrived up until time ,
but has no information about any requests whose arrival times are after time .
The instance includes a time horizon  that is not known to the online algorithm, which
is revealed only at time . At time , all requests that are still pending must be served.
(In the offline case,  can be assumed to be equal to the maximum request arrival time.)

If  is an online algorithm and , we say that  is \emph{-competitive}\footnote{Definitions of competitiveness in the literature often
allow an additive error term, independent of the request sequence. 
For our algorithms, this additive term is not needed. Our lower bound proofs can be
easily modified (essentially, by iterating the adversary strategy) to remain valid
if an additive term is allowed, even if it is a function of .}
if  for any instance  of ,
where  is the schedule computed by  on  and  is the
optimum cost for .


\paragraph{Quasi-root assumption.}

Throughout the paper we will
assume that , the root of , has only one child. This
is without loss of generality, because if we have an algorithm (online
or offline) for  on such trees, we can apply it independently to each
child of  and its subtree. This will give us an algorithm for  on
arbitrary trees with the same performance. From now on, let us call
the single child of  the \emph{quasi-root} of  and denote it by
.  Note that  is included in every (non-trivial) service.


\paragraph{Urgency functions.}

When choosing nodes for inclusion in a service, our online algorithms
give priority to those that are most ``urgent''.  For {\MLAPD},
naturally, urgency of nodes can be measured by their deadlines, where
a deadline of a node  is the earliest deadline of a request pending
in the subtree , i.e., the induced subtree rooted at .
But for the arbitrary instances of {\MLAP} we need a more general
definition of urgency, which takes into account the rate of increase
of the waiting cost in the future.  To this end, each of our
algorithms will use some \emph{urgency function} , which also depends on the set of pending
requests and the current time step, and which assigns some time value
to each node. The earlier this value, the more urgent the node is.

Fix some urgency function . Then,
for any set  of nodes in  and a real number , let
 be the set of nodes obtained by choosing the
nodes from  in order of their increasing urgency value, until either their total weight exceeds 
or we run out of nodes.
More precisely, we define  as the
smallest set of nodes in  such that 
(i)  for all , and  we have , 
and 
(ii) either  or
.
In case of ties in the values of  there may be multiple choices for
; we choose among them arbitrarily.



\section{Reduction to -Decreasing Trees}
\label{sec: reduction to L-decreasing trees}

One basic intuition that emerges from earlier works on trees of depth
 (see \cite{jrp-online-buchbinder,aggregation-bkv,jrp-soda-2014})
is that the hardest case of the problem is when , the
weight of the quasi-root, is much larger than the weights of
leaves. For arbitrary depth trees, the hard case is when the weights
of nodes quickly decrease with their depth. We show that this is
indeed the case, by defining the notion of -decreasing trees that
captures this intuition and showing that {\MLAP} reduces to the
special case of {\MLAP} for such -decreasing trees, increasing the
competitive ratio by a factor of at most .  This is a general
result, not limited only to algorithms in our paper.

Formally, for , we say
that  is \emph{-decreasing} if for each node  and
each child  of  we have .
(The value of  used in our algorithms will be fixed later.) 
 
Note that the -decreasing condition corresponds to the usual
definition of hierarchically well-separated trees (HSTs); however, for our
purposes we do not need any balancing condition usually also required from HSTs.


\begin{theorem}\label{thm:reduction}
Assume that there exists an -competitive algorithm  for
{\MLAP} (resp.~{\MLAPD}) on -decreasing trees (where  can be a
function of , the tree depth).  Then there exists a
-competitive algorithm  for {\MLAP} (resp.~{\MLAPD}) on
arbitrary trees.
\end{theorem}

\begin{proof}
Fix the underlying instance , where  is
a tree and  is a sequence of requests in .  In our
reduction, we convert  to an -decreasing tree  on
the same set of nodes. We then show that any service on  is
also a service on  of the same cost and, conversely, that any
service on  can be converted to a slightly more expensive
service on .

We start by constructing 
an -decreasing tree  on the same set of nodes. For any node
, the parent of  in  will be the
lowest (closest to ) ancestor  of  in  such that
; if no such  exists, we take
. Note that  may violate the quasi-root assumption, which
does not change the validity of the reduction, as we may use
independent instances of the algorithm for each child of  in
.
Since in  each node  is connected to one of its ancestors
from , it follows that  is a tree rooted at  with
depth at most . Obviously,  is -decreasing.

The construction implies that if a set of nodes 
is a service subtree of , then it is also a service subtree for
.  (However, note that the actual topology of
the trees with node set  in  and  may be very different.
For example, if  and  is a path with costs
(starting from the leaf) , then in  the
node of weight  is connected to the node of weight ,
except for the last three nodes that are connected to . Thus the
resulting tree consists of three paths ending at  with roughly
the same number of nodes.)
Therefore, any schedule for  is also a schedule for , which gives us that .

The algorithm  for  is defined as follows: On a request
sequence , we simulate  for  in , and
whenever  contains a service ,  issues the service
, created from  as follows:
Start with . Then,
for each , if  is the parent of  in , then
add to  all inner nodes on the path from  to  in
. By the construction of , for each  we add at most
 nodes, each of weight less than . It follows that
.

In total, the service cost of  is at most  times the
service cost of . Any request served by  is served by
 at the same time or earlier, thus the waiting cost of 
is at most the waiting cost of  (resp.~for {\MLAPD}, 
produces a valid schedule for ). 
Since  is -competitive, we obtain 

and thus  is -competitive.
\end{proof}





\section{A Competitive Algorithm for {\MLAPD}}
\label{sec: competitive algorithm for mlap-d}


In this section we present our online algorithm for {\MLAPD} with 
competitive ratio at most .
To this end, we will give an online algorithm that achieves
competitive ratio  for -decreasing trees.
Taking  and using the reduction to -decreasing trees from
Theorem~\ref{thm:reduction}, we obtain a
-competitive algorithm for arbitrary trees.


\subsection{Intuitions} 

Consider the optimal -competitive algorithm for {\MLAPD} for
trees of depth~~\cite{jrp-soda-2014}. Assume that the tree is -decreasing, 
for some large . (Thus , for each leaf .)
Whenever a pending request
reaches its deadline, this algorithm serves a subtree  consisting
of  and the set of leaves with the earliest deadlines and total
weight of about .  This is a~natural strategy: We
have to pay at least  to serve the expiring request, so
including an additional set of leaves of total weight  can
at most double our overall cost. But, assuming that no new requests arrive,
serving this  can significantly reduce the cost in the future,
since servicing these leaves individually is expensive: it would
cost  per each leaf , compared to the
incremental cost of  to include  in .

For -decreasing trees with three levels (that is, for ), 
we may try to iterate this idea. 
When constructing a service tree , we start by adding to 
the set of most urgent children of  whose total weight is roughly
.  Now, when choosing nodes of depth , we have two
possibilities: (1) for each  we can add to 
its most urgent children of combined weight  (note that
their total weight will add up to roughly , because of the
-decreasing property), or (2) from the set of \emph{all} children
of the nodes in , add to  the set of total weight
roughly  consisting of (globally) most urgent children. 

It is not hard to show that option (1) does not lead to a
constant-competitive algorithm: The counter-example involves an
instance with one node  of depth  having many children with
requests with early deadlines and all other leaves having requests
with very distant deadlines. Assume that ,
, and that each leaf has weight . 
The example forces the
algorithm to serve the children of  in small batches of size 
with cost more than  per batch or  per each child of , while the
optimum can serve all the requests in the children of  at once with cost  per
request, giving a lower bound  on the competitive ratio.
(The requests at other nodes can be ignored in the optimal
solution, as we can keep repeating the above strategy in a manner
similar to the lower-bound technique for {\SPMLAP}
that will be described in Section~\ref{sec: one-phase MLAP}.
Reissuing requests at the 
nodes other than  will not increase the cost of the optimum.) 
A more intricate example
shows that option (2) by itself is not sufficient to guarantee
constant competitiveness either.

The idea behind our algorithm, for trees of depth , is to do 
\emph{both} (1) and (2) to obtain . This increases the cost of each
service by a constant factor, but it protects the algorithm against
both bad instances. The extension of our algorithm to depths 
 carefully iterates the
process of constructing the service tree , to ensure that for each
node  and for each level  below  we add to 
sufficiently many urgent descendants of  at that level.


\subsection{Notations}

To give a formal description, we need some more notations.
For any set of nodes , let  denote the set of
nodes in  of depth  in tree . (Recall
that  has depth ,  has depth , and leaves have depth at
most .) Let also  and . These notations can be combined with the notation
, so, e.g.,  is the set of all descendants of  that
belong to  and whose depth in  is smaller than .

We assume that all the deadlines in the given instance are
distinct. This may be done without loss of generality, as in case of
ties we can modify the deadlines by infinitesimally small
perturbations and obtain an algorithm for the general case. 

At any given time  during the computation of the algorithm, for
each node , let  denote the earliest deadline among all
requests in  (i.e., among all descendants of ) that are
pending for the algorithm; if there is no pending request in
, we set .  We will use the function  as
the urgency (see Section~\ref{sec: preliminaries})
of nodes at time , i.e., a node  will be
considered more urgent than a node  if .


\subsection{Algorithm~{\OnAlgTreesDeadlines}}

At any time  when some request expires, that is when  , the
algorithm serves a~subtree  constructed by first initializing
, and then incrementally augmenting 
according to the following pseudo-code:

\begin{tabbing}
aaa \= aaa \= aaa \= aaa \= aaa \= aaa \= \kill
\> \textbf{for each} depth \\
\> \>  set of all children of nodes in  \\
\> \> \textbf{for each}  \\
\> \> \>  \\
\> \> \> 
\end{tabbing}

In other words, at depth , we restrict our attention to , the
children of all the nodes in , i.e., of the nodes that we
have previously selected to  at level . (We start with 
and .) Then we iterate over all  and
we add to  the set  of nodes from 
(descendants of  at depth ) whose parents are in , one by
one, in the order of increasing deadlines, stopping when either their
total weight exceeds  or when we run out of such
nodes. Note that these sets do not need to be disjoint.

The constructed set  is a service tree, as we are adding to it only
nodes that are children of the nodes already in .

Let  be the request triggering the service at time , i.e.,
satisfying .  (By the assumption about different deadlines,
 is unique.)  Naturally, all the nodes  on the path from 
to  have  and qualify as the most urgent,
thus the node  is included in . Therefore every
request is served before its deadline.




\subsection{Analysis}

Intuitively, it should be clear that Algorithm~{\OnAlgTreesDeadlines}
cannot have a better competitive ratio than : If all
requests are in , the optimum will serve only , while our
algorithm uses a set  with many nodes that turn out to be
useless. As we will show, via an iterative charging argument, the ratio
 is actually achieved by the algorithm.

Recall that .
We now prove a bound on the cost of the service tree.

\begin{lemma}\label{l:d:complete} 
Let  be the service tree produced by
Algorithm~{\OnAlgTreesDeadlines} at time .  Then .
\end{lemma}

\begin{proof}
We prove by induction that  for all .

The base case of  is trivial, as  and
.  For ,  is the~union of the sets 
over all nodes . Since  is -decreasing, each
node in the set  has weight at most .  Thus
the total weight of  is at most
.
Therefore, by the inductive assumption, we get that

proving the induction step and completing the proof that 
.
\end{proof}



The competitive analysis uses a charging scheme. Fix some optimal
schedule . Consider a service  of
Algorithm~{\OnAlgTreesDeadlines}.  We will identify in  a subset of
``critically overdue'' nodes (to be defined shortly) of total weight
at least , and we will show that for each
such critically overdue node  we can charge the portion 
of the service cost of  to an earlier service in  that
contains .  Further, any node in service of  will be
charged at most once.  This implies that the total cost of our
algorithm is at most  times the optimal cost, giving us an upper
bound of  on the competitive ratio for -decreasing trees.

In the proof, by  we denote the time of the first
service in 
that includes  and is strictly after time ; we
also let  if no such service exists  
( stands for \emph{next optimal service}).
For a service  of the algorithm, we say that a node  is
\emph{overdue} at time  if . Servicing of
such  is delayed in comparison to , because
 must have served  before or at time .  Note
also that  and  are overdue at time , as  by
the choice of the service time.  We define  to be \emph{critically
  overdue} at time  if (i)  is overdue at , and (ii)
there is no other service of the algorithm in the time interval
 in which  is overdue.

We are now ready to define the charging for a service .  For
each  that is critically overdue, we charge its weight
 to the last service of  in  before or at
time .  This charging is well-defined as, for each overdue ,
there must exist a previous service of  in . The
charging is obviously one-to-one because between any two services in
 that involve  there may be at most one service of the
algorithm in which  is critically overdue.  The following lemma
shows that the total charge from  is large enough.


\begin{lemma}\label{l:d:charge}
Let  be a service of Algorithm~{\OnAlgTreesDeadlines} and
suppose that  is overdue at time . 
Then the total weight of critically overdue nodes in  at time 
is at least~.
\end{lemma}

\begin{proof}
The proof is by induction on the depth of , the induced
subtree rooted at . 

The base case is when  has depth , that is when  is a
leaf.  We show that in this case  must be critically overdue, which
implies the conclusion of the lemma.  Towards contradiction, suppose
that there is some other service at time 
in which  is overdue.  Since  is a leaf, after the service at
time  there are no pending requests in .  This
would imply that there is a request  with 
such that .  But this is not
possible, because  does not serve  in the time
interval .  Thus  is critically overdue and the
base case holds.

Assume now that  is not a leaf, and that the lemma holds for all
descendants of .  If  is critically overdue, the conclusion of
the lemma holds.

Thus we can now assume that  is not critically overdue. This means
that there is a~service  of Algorithm~{\OnAlgTreesDeadlines}
with  which contains  and such that  is
overdue at .  Thus .

Let  be the request with , i.e., the most
urgent request in  at time .


\begin{figure}
\begin{center}
\includegraphics[height=2.3in]{fig1}
\caption{Illustration of the proof of Lemma~\ref{l:d:charge}.}
\label{fig: online mlapd analysis}
\end{center}
\end{figure}

We claim that , i.e.,  arrived no later than
at time . Indeed, since  is overdue at time , it follows
that .  The optimal schedule
 cannot serve  after time , as  has no
service from  in the interval . Thus  must
have served  before or at , and hence , as
claimed.

Now consider the path from  to  in .  (See
Figure~\ref{fig: online mlapd analysis}.)  As  is pending
for the algorithm at time  and  is not served by ,
it follows that .  Let  be the last node
on this path in . Then  is well-defined and , as
. Let  be the depth of .  Note that the parent of  is
in , so  in the algorithm when  is constructed.

The node  is in  and  is pending at
, thus we have .  Since  but  was
not added to  at time , we have that  and each  is at least as urgent as .
This implies that such  satisfies

thus  is overdue at time . By the inductive assumption, the
total weight of critically overdue nodes in each induced 
subtree  is at
least . Adding these weights over all ,
we obtain that the total weight of critically overdue nodes in  is at
least , completing the proof.
\end{proof}

Now consider a service  of the algorithm. The quasi-root  is
overdue at time , so Lemmata~\ref{l:d:charge} and~\ref{l:d:complete}
imply that the charge from  is at least
. Since
each node in any service in  is charged at most once, we
conclude that Algorithm~{\OnAlgTreesDeadlines} is -competitive for any
-decreasing tree .

From the previous paragraph, using Theorem~\ref{thm:reduction}, we now
obtain that there exists a -competitive
algorithm for general trees. For , choosing  yields a competitive
ratio bounded by
.
(For  there is a trivial -competitive algorithm for {\MLAPD}.)
Summarizing, we obtain the following result. 

\begin{theorem}
There exists a -competitive online algorithm for {\MLAPD}.
\end{theorem}



\section{A Competitive Algorithm for {\MLAP}}
\label{sec: competitive algorithm for mlap}


In this section we show that there is an online algorithm for {\MLAP} 
whose competitive ratio for trees of depth  is . 
As in Section~\ref{sec: competitive algorithm for mlap-d}, we will
assume that the tree  in the instance is -decreasing.
Then, for -decreasing trees, we will present a competitive algorithm,
which will imply the existence of a competitive algorithm for
arbitrary trees by using Theorem~\ref{thm:reduction}
and choosing an appropriate value of .


\subsection{Preliminaries and Notations}
\label{subsec: mlap notations}

Recall that  denotes the waiting cost function of a request
. As explained in Section~\ref{sec: preliminaries}, we assume that 
the waiting cost functions are continuous. 
(In Section~\ref{sec: general waiting costs} we discuss how to extend our
results to arbitrary waiting cost functions.)
We will overload this notation, so that we can talk about the waiting
cost of a set of requests or a set of
nodes. Specifically, for a set  of requests and a set  of
nodes, let

Thus  is the total waiting cost of the requests from
 that are issued in . 
We sometimes omit , in which case the notation refers to the set of
all requests in the instance, that is . 
Similarly, we omit  when  contains all nodes,
that is .


\paragraph{Maturity time.}

In our algorithm for {\MLAPD} in Section~\ref{sec: competitive algorithm for mlap-d}, 
the times of services and the
urgency of nodes are both naturally determined by the deadlines. For
{\MLAP} with continuous waiting costs there are no hard deadlines. 
Nevertheless, we can still introduce the notion of \emph{maturity
  time} of a node, which is, roughly speaking, the time when some 
subtree rooted at this node has its waiting cost equal to its
service cost; this subtree is then called \emph{mature}.
This maturity time will be our urgency function, as discussed 
earlier in Section~\ref{sec: preliminaries}. We use the maturity
time in two ways: one, the maturity times of the 
quasi-root determine the service times, and two, maturity times
of other nodes are used to prioritize them for inclusion in
the service trees. We now proceed to define these notions.

Consider some time  and any set  of requests. A
subtree  of  (not necessarily rooted at ) is called
\emph{-mature} at time  if .
Also, let  denote the minimal time  such
that ; we let  if such  does not exist. In other words,
 is the earliest  at which  is
-mature. Since  and  is a
non-decreasing and continuous function of ,  is
well-defined.

For a node , let the \emph{-maturity time of }, denoted
, be the minimum of values 
over all subtrees  of  rooted at .  The tree  that
achieves this minimum will be denoted  and called the
\emph{-critical subtree rooted at }; if there are more such trees,
choose one arbitrarily. Therefore we have
.

The following simple lemma guarantees that the maturity time of any
node in the -critical subtree  is upper bounded by the maturity time of .


\begin{lemma}
\label{lem: maturity-critical}
Let  and let  be the induced subtree of 
 rooted at . Then 
.
\end{lemma}


\begin{proof}
The first inequality follows directly from the definition of . 
To show the second inequality, we proceed by contradiction. 
Let .
If the second inequality does not
hold, then  and . 
Take , which is a tree rooted at .
Since , we have that 
. 
This in turn implies that , which is a
contradiction with the definition of .
\end{proof}

Most of the references to maturity of a node or to its critical set
will be made with respect to the set of requests pending for our
algorithm at a given time.  For any time , we will use notation
 and  to denote the time
 and the -critical subtree , where 
is the set of requests pending for the algorithm at time ; if the
algorithm schedules a service at some time ,  is the set of
requests that are pending at time  \emph{right before} the service
is executed. Note that in general it is possible that
. However, our algorithm will maintain the
invariant that for the quasi-root  we will have
 at each time .


\subsection{Algorithm}

We now describe our algorithm for -decreasing trees.
A service will occur at each maturity
time of the quasi-root  (with respect to the pending requests), 
that is at each time  for which .
At such a time, the algorithm chooses a service that contains the critical subtree
 of  and an extra set , whose service cost is not much more
expensive than that of . The extra set is constructed similarly as
in Algorithm~{\OnAlgTreesDeadlines}, where the urgency of nodes is now measured
by their maturity time. In other words, our urgency function
is now  (see Section~\ref{sec: preliminaries}.)
As before, this extra set will be a union of a
system of sets  for  and , except that now, for technical reasons,
the sets  will be mutually disjoint and also disjoint from .

\paragraph{Algorithm~{\OnAlgTreesGeneral}.}

At any time  such that , serve the set 
 constructed according to the following pseudo-code:
\begin{tabbing}
aaa \= aaa \= aaa \= aaa \= aaa \= aaa \= \kill
\>

\\
\> 
\\
\> \textbf{for each} depth 
\\
\> \>  set of all nodes in  whose parent is in 
\\
\> \> \textbf{for each}  
\\
\> \> \>  
\\
\> \> \> 
\\
\> \> \> 
\end{tabbing}
At the end of the instance (when , the time horizon), if there
are any pending requests, issue the last service that contains
all nodes  with a pending request in .



\medskip

Note that  is indeed a service tree, as it contains  and we are
adding to it only nodes  that are children of the nodes already in .
The initial choice and further changes of  imply that the sets
 are pairwise disjoint and disjoint from  -- a fact that will
be useful in our analysis. 


We also need the following fact.

\begin{lemma}\label{lem: maturity times of q}
	(a) Suppose that Algorithm~{\OnAlgTreesGeneral} issues a service at
	a time , that is .
	Denote by  the maturity time of  right
	after the service at time . Then .
(b) At any time  we have	.
\end{lemma}

To clarify the meaning of ``right after the service''
in this lemma,  is defined formally as the 
limit of , with  approaching  from the right.

\begin{proof}
(a) 
Let  and let  be the service at time
. This means that we have  and
 for all subtrees  of  rooted at
.  Consider any subtree  of  rooted at  different from
.  Denoting by  the waiting cost of the packets that
are pending in  right after the service , it is sufficient
to prove that .

Towards contradiction, suppose that .
Then we have

where the last (strict) inequality follows from  and
.
But  is a subtree of  rooted at , so
the inequality 
contradicts our assumption that .	

(b)
The lemma holds trivially at the beginning, at time . In any time interval
without new requests released nor services, the inequality
 is preserved, by the definition of
the service times and continuity of waiting cost functions.
Releasing a request  at a time  
cannot decrease  to below , because the waiting cost function
of  is identically 0 up to  and thus
releasing  does not change the waiting costs at time  or before. 
Finally, part~(a) implies that the inequality is also preserved when
services are issued.
\end{proof}

By Lemma~\ref{lem: maturity times of q} (and the paragraph before),
the definition of the algorithm is sound, that is the sequence of
service times is non-decreasing. In fact, the lemma
shows that no two services can occur at the same time.
 

\subsection{Competitive Analysis}

We now present the proof of the existence of an
-competitive algorithm for  for
trees of depth~. The overall argument is quite intricate, so we 
will start by summarizing its main steps:

\begin{itemize}

\item First, as explained earlier, we will assume that the tree
 in the instance is -decreasing. 
For such  we will show that Algorithm~{\OnAlgTreesGeneral}
has competitive ratio , where
. Our bound on the competitive ratio for
arbitrary trees will then follow, by using Theorem~\ref{thm:reduction}
and choosing an appropriate value of  (see Theorem~\ref{thm: general mlap competitive}).

\item For -decreasing trees,
	the bound of the competitive ratio of Algorithm~{\OnAlgTreesGeneral}
	involves four ingredients:
	
	\begin{itemize}
		
		\item We show (in Lemma~\ref{lem: mlap, cost <= 2*service})
		that the total cost of Algorithm~{\OnAlgTreesGeneral}
			is at most twice its service cost.
			
		\item Next, we show that the service cost of
			Algorithm~{\OnAlgTreesGeneral} can be bounded 
			(within a constant factor) by the total cost of all
			critical subtrees  of the service trees in its schedule.
			
		\item To facilitate the estimate of the adversary cost, 
			we introduce the concept of a \emph{pseudo-schedule}
			denoted . The pseudo-schedule
                         is a collection of 
			\emph{pseudo-services}, which include the services
			from the original adversary schedule .
			We show (in Lemma~\ref{lem: bound on pseudo sched})
			that the adversary pseudo-schedule has service
			cost not larger than  times the cost of .
			Using the pseudo-schedule allows us to ignore the waiting cost in the
			adversary's schedule.
			
		\item With the above bounds established, it remains to
			show that the total cost of critical subtrees in the
			schedule of Algorithm~{\OnAlgTreesGeneral}
			is within a constant factor of the service cost of the
			adversary's	pseudo-schedule. This is accomplished through a 
			charging scheme that charges nodes (or, more precisely,
			their weights) from each critical subtree of
			Algorithm~{\OnAlgTreesGeneral} to their appearances
			in some earlier adversary pseudo-services.
		
	\end{itemize}
	
\end{itemize}


\paragraph{Two auxiliary bounds.}
We now assume that  is -decreasing and proceed with our
proof, according to the outline above.

The definition of the
maturity time implies that the waiting cost of all the requests
served is at most the service cost , as otherwise
 would be a good candidate for a critical subtree at some
earlier time. Denoting by  the schedule computed by
Algorithm~{\OnAlgTreesGeneral}, we thus obtain:


\begin{lemma}\label{lem: mlap, cost <= 2*service}
.
\end{lemma}

Using Lemma~\ref{lem: mlap, cost <= 2*service},
 we can restrict ourselves to bounding the service
cost, losing at most a factor of .  We now bound the cost of 
a given service ; recall that .


\begin{lemma}\label{l:complete}
Each service tree  constructed by the algorithm satisfies
.
\end{lemma}

\begin{proof}
Since  is -decreasing, the weight of each node that is a
descendant of  is at most  and thus
.

We now estimate . We claim and prove by induction for
 that

The base case for  is trivial, as . For , the set
 consists of  and the sets ,
for . Each of these sets  has
weight at most . Therefore

Now, using (\ref{eqn: complete mlap aux ineq}) and the
inductive assumption (\ref{eqn: complete mlap main ineq}) for ,
we get

Taking  in~(\ref{eqn: complete mlap main ineq}), the lemma follows.
\end{proof}


\paragraph{Waiting costs and pseudo-schedules.}

Our plan is to charge the cost of Algorithm~{\OnAlgTreesGeneral} to
the optimal (or the adversary's) cost. Let  be an optimal
schedule.  To simplify this charging, we extend  by adding
to it pseudo-services, where a \emph{pseudo-service from a node }
is a partial service of cost  that consists only of the
edge from  to its parent.  We denote this modified schedule
 and call it a \emph{pseudo-schedule}, reflecting the
fact that its pseudo-services are not necessarily subtrees of 
rooted at . Adding such pseudo-services will allow us to
ignore the waiting costs in the optimal schedule.

We now define more precisely how to obtain  from .
For each node  independently we define the times when new
pseudo-services of  occur in . Intuitively, we introduce
these pseudo-services at intervals such that the waiting cost
of the requests that arrive in  during these intervals adds
up to .  The formal description of this process is given in
the pseudo-code below, where we use notation  for the set of
requests  with  (i.e., requests issued after
time ). Recall that  denotes the time horizon.

\begin{tabbing}
aaa \= aaa \= aaa \= aaa \= aaa \= aaa \= \kill
\>

\\
\> \textbf{while} 
\\
\> \>
let  be the earliest time such that

\\
\> \>
add to  a pseudo-service of  at  
\\
\> \>
 
\end{tabbing}

We apply the above procedure to all the nodes 
such that  contains a request in . The new
pseudo-schedule  contains all the services of
 (treated as sets of pseudo-services of all served nodes)
and the new pseudo-services added as above.  The service cost of the
pseudo-schedule, , is defined naturally as the
total weight of the nodes in all its pseudo-services.


\begin{lemma}\label{lem: bound on pseudo sched}
.
\end{lemma}

\begin{proof}
It is sufficient to show that the total service cost of the new
pseudo-services added inside the while loop is at most
: Adding
 once more to account for the service cost of the
services of  that are included in , and
using our assumption that , we obtain , thus the lemma follows.

To prove the claim, consider some node , and a pair of times
 from one iteration of the while loop, when a new
pseudo-service was added to  at time .  This
pseudo-service has cost .  In , either there is
a service in  including , or the total waiting cost of the
requests within  released in this interval is equal to
.  In the first case, we
charge the cost of  of this pseudo-service to any service
of  in  in .  Since we consider here only the
new pseudo-services, created by the above pseudo-code, this charging
will be one-to-one.  In the second case, we charge  to the
total waiting cost of the requests in  released in the
interval .  For each given , the charges of the second
type from pseudo-services at  go to disjoint sets of requests in
, so each request in  will receive at most one
charge from .  Therefore, for each request , its waiting cost
in  will be charged at most  times, namely at most once
from each node  on the path from  to .  From the
above argument, the total cost of the new pseudo-services is at most
, as claimed.
\end{proof}


Using the bound in Lemma~\ref{lem: bound on pseudo sched}
will allow us to use  as an estimate of
the optimal cost in our charging scheme, losing at most a factor of  in the
competitive ratio. 



\paragraph{Charging scheme.}

According to Lemma~\ref{lem: mlap, cost <= 2*service}, to establish constant
competitiveness it is sufficient
to bound only the service cost of Algorithm~{\OnAlgTreesGeneral}.
By Lemma~\ref{l:complete}
for any service tree  of the algorithm we have .  
Therefore, it is in fact sufficient to bound the total weight of the critical
sets in the algorithm's services. 
Further, using Lemma~\ref{lem: bound on pseudo sched}, instead of 
using the optimal cost in this bound, we can use the pseudo-service cost.
Following this idea, we will show how we can charge, at a constant rate,
the cost of
all critical sets  in the algorithm's services to the adversary
pseudo-services. 

The basic idea of our charging method is similar to that for {\MLAPD}.
The argument in Section~\ref{sec: competitive algorithm for mlap-d}
can be interpreted as an iterative charging scheme, where we have a
charge of  that originates from , and this charge is
gradually distributed and transferred down the service tree, through
overdue nodes, until it reaches critically overdue nodes that can be
charged directly to adversary services.  For {\MLAP} with general
waiting costs, the charge of  will originate from the
current critical subtree . Several complications arise when we attempt to
distribute the charges to nodes at deeper levels.
First,
due to gradual accumulation of waiting costs, it does not seem
possible to identify nodes in the same service tree that can be used
as either intermediate or final nodes in this process.  Instead, when
defining a charge from a node , we will charge descendants of  in 
\emph{earlier} services of
. Specifically, the weight  will be charged to the set
 for some , where  is the time of the previous
service of the algorithm that includes .  The nodes --- or, more
precisely, services of these nodes --- that can be used as
intermediate nodes for transferring charges will be called
\emph{depth-timely}.  As before, we will argue that each charge will
eventually reach a node  in some earlier service that can be
charged to some adversary pseudo-service directly.  Such service of
 will be called \emph{-local}, where the name reflects the property
that this service has an adversary pseudo-service of  nearby (to
which its weight  will be charged).

\smallskip

We now formalize these notions.
Let  be some service of Algorithm~{\OnAlgTreesGeneral} that includes ,
that is .
By  we denote the time of the last service of  before
 in the schedule of the algorithm; if it does not exist, set
.
By  we denote the time of the th service of 
following  in the schedule of the algorithm; if it does not exist,
set .

We say that the service of  at time  is \emph{-timely}, if
; furthermore, if  is
-timely, we will say simply that this service of  is
\emph{depth-timely}.
We say that the service of  at time  is \emph{-local}, if
this is either the first service of  by the algorithm, or if
there is an adversary pseudo-service of  in the interval
.


Given an algorithm's service , we now define the outgoing
charges from .  For any , its outgoing charge is
defined as follows:
\begin{description}
	
\item{(C1)} If  and the service of  at time  is both
  depth-timely and -local, charge  to the first
  adversary pseudo-service of  after time .

\item{(C2)} If  and the service of  at time  is 
  depth-timely but not -local, charge  
  to the algorithm's service at time .

\item{(C3)} If  and the service of  at time  is not
  depth-timely, the outgoing charge is .

\item{(C4)} If  and , we charge  to the
first adversary pseudo-service of .
\end{description}

We first argue that the charging is well-defined. 
To justify (C1) suppose that this service is depth-timely and
-local.  If  is the first service of  then  and the charge goes to the first pseudo-service of 
which exists as all the requests must be served. Otherwise there
is an adversary pseudo-service of  in the interval
 and rule (C1) is well-defined.
For (C2), note that if the service  of  is not -local
then there must be an earlier service including .  (C3) is
trivial. For (C4), note again that an adversary transmission of 
must exist, as all requests must be served.

The following lemma implies that
all nodes in the critical subtree will have an outgoing charge, as needed.

\begin{lemma}\label{lem: each v in C is depth-timely}
For a transmission time , each  is 1-timely, and
thus also depth-timely.
\end{lemma}

\begin{proof}
From Lemma~\ref{lem: maturity-critical}, each  satisfies 
,
where the sharp inequality follows from Lemma~\ref{lem: maturity times of q}.
\end{proof}

The following lemma captures the key property of our charging scheme.  For any
depth-timely service of  that is not -local, it identifies
a set  in the previous service  including 
that is suitable for receiving a charge. It is important that each such set is
used only once, has sufficient weight, and contains only depth-timely
nodes.  As we show later, these properties imply that in this charging scheme
the net charge (the difference between the outgoing and incoming charge)
from each service  is at least as large as
the total weight of its critical subtree.

As in the argument for {\MLAPD}, we need to find an urgent node 
 which is not in  and has its parent in . There
are two important issues caused by the fact that the urgency is
given by the maturity times instead of deadlines. The first issue is
that the maturity time can decrease due to new packet arrivals --- to
handle this, we argue that if the new requests had large waiting
costs, they would guarantee the existence of a pseudo-service of node  in the given
time interval and thus the algorithm's service of
 would be -local. The second issue is that the
maturity time is not given by a single descendant but by adding the node
contributions from the whole tree --- thus instead of searching for  on
a single path, we need a more subtle, global argument to identify such .


\begin{lemma}\label{l:charge}
Assume that the service of  at time  is depth-timely and
not -local.  Let , and let  be
the previous service of Algorithm~{\OnAlgTreesGeneral} including , that is
. Then there exists  such that all the nodes in
the set  from the construction of  in the
algorithm are depth-timely and .
\end{lemma}

\begin{proof}
Let  and let  be the 
critical subtree of  at time .
Since the service of  at time  is -timely, we have .
(It may be the case that , but that does not
hamper our proof in any way.)
Also, since the service of  at time  is not -local,
 it is not the first service of , thus  and
 are defined.  

Let  be the set of requests pending right after
time  (including those with arrival time  but not those
served at time ), and let  be the set of requests 
with arrival time in the interval .
The key observation is that the total waiting cost of all the requests
in  that arrived after  satisfies

To see this, simply note that 
would imply that .
This in turn would
imply the existence of a pseudo-service of  in the interval
, which would
contradict the assumption that the service of  at time 
is not -local. (Note that if  then 
as  is before the arrival time of any request in  and the
inequality holds trivially.)



\begin{figure}
\begin{center}
\includegraphics[height=2in]{fig2}
\caption{Illustration of the proof of Lemma~\ref{l:charge}.}
\label{fig: online mlap analysis}
\end{center}
\end{figure}


Since  contains all the requests pending at time ,
the choice of  and  implies that

 does not contain any requests in , as those were served at time ;
therefore .
Letting  be the set of all nodes  for which ,
we have , where all sets , for ,
are disjoint. (See Figure~\ref{fig: online mlap analysis}.)
Also, . Combining these observations, and
using inequalities~(\ref{eq:new}) and~(\ref{eq:all}), we get

It follows that there exists  such that 

Equation~(\ref{eq:old}) implies that , 
using also the fact that  was not served at , so
 contains exactly all the requests used to define
.  Let ; note that  as 
is a descendant of . Since  but , and
 is finite, the definition of the extra sets for 
implies that  has sufficient weight and all its nodes
are more urgent than . More precisely,  and any  has . 


It remains to show that every  is depth-timely at time .
Indeed, since  and any service containing  contains also , we get

where the last step uses the inequality 
derived in the previous paragraph. Thus  is depth-timely, as needed.
The proof of the lemma is now complete.
\end{proof}



\paragraph{Competitive analysis.} 

We are now ready to complete our competitive analysis of .

\begin{theorem}\label{thm: general mlap competitive}
There exists an -competitive algorithm for  on 
trees of depth~.
\end{theorem}

\begin{proof}
We will show that Algorithm~{\OnAlgTreesGeneral}'s competitive ratio
for -decreasing trees of depth 
is at most , where . 
By applying Theorem~\ref{thm:reduction}, this implies that
there is an online algorithm for arbitrary trees with ratio
at most . For , this
ratio is bounded by , implying the theorem (together with the
fact that for , constant-competitive algorithms are known).

So now we fix an -decreasing tree  and focus our attention
on Algorithm~{\OnAlgTreesGeneral}'s schedule  and on the
adversary pseudo-schedule . Define the \emph{net charge
  from} a service  in  to be the difference between
the outgoing and incoming charge of .  Our goal is to show that
each pseudo-service in  is charged only a constant
number of times and that the net charge from each service  in
 is at least .

Consider first an adversary pseudo-service of  at a time . We
argue that it is charged at most : If this is the
first pseudo-service of , charged once from both the first service
of  by rule (C1) and from the last service of  at time  by
rule (C4). In addition, by rule (C1) it may be charged  times from
the last  services of  before , and once from the first
service at or after . All the charges are equal to .

Now consider a service  of Algorithm~{\OnAlgTreesGeneral}. For
, all the nodes of  have an outgoing charge by rule (C4)
and there is no incoming charge. Thus the net charge from  is
.

For , let , where  is the critical subtree and 
is the extra set. From Lemma~\ref{lem: each v in C is depth-timely},
all nodes in  are depth-timely, so they generate outgoing charge of
at least  from .  Next, we show that the net charge
from the extra set  is non-negative.  Recall that  is a disjoint
union of sets of the form  and  is disjoint from .  If
a future service of a node  generates the charge of 
to  by rule (C2), it must be the service at time ,
so such a charge is unique for each .  Furthermore,
Lemma~\ref{l:charge} implies that one of the extra sets ,
for , has  and consists of
depth-timely nodes only. Thus these nodes have outgoing charges adding
up to at least ; these charges go either to the adversary's
pseudo-services or the algorithm's services before time .  We have
shown that the net charge from each extra set  is
non-negative; therefore, the net charge from  is non-negative as
well.  We conclude that the net charge from  is at least
. Applying Lemma~\ref{l:complete}, we obtain that this net
charge is at least .

Summing over all the services  in , we get a bound for
the service cost of schedule : .  Applying Lemmata~\ref{lem: mlap,
  cost <= 2*service} and~\ref{lem: bound on pseudo sched}, we get

We have thus shown that Algorithm~{\OnAlgTreesGeneral}'s competitive
ratio for -decreasing trees is at most , which, as
explained earlier, is sufficient to complete the proof.
\end{proof}


\section{Single-Phase {\MLAP}}
\label{sec: one-phase MLAP}

We now consider a restricted variant of  that we refer to as
\emph{Single-Phase} {\MLAP}, or . In  all requests arrive at the beginning, at time . 
The instance also
includes a parameter  representing the  common \emph{expiration time}
for all requests. We do not require that all requests are served. Any unserved
request pays only the cost of waiting until the expiration time . 

In the online variant of , all requests, including their waiting cost functions,
are known to the online algorithm at time . The only unknown is the expiration time .

Although not explicitly named, variants of  have
been considered in~\cite{jrp-online-buchbinder,aggregation_wads_2013}, where they 
were used to show lower bounds on competitive ratios for . These proofs
consist of two steps, first showing a lower bound for online  and then arguing
that, in the online scenario,  can be expressed as a special case of .
(A corresponding property holds in the offline case as well, but is quite trivial.)
We also use the same general approach in Section~\ref{sec: mlap on paths} to show our lower bounds.

To see that (in spite of the expiration feature)  can be thought of as a special case
of , we map an instance  of  into the instance
 of  with the property that any -competitive algorithm for 
can be converted into an -competitive algorithm for .
We will explain the general idea when the cost function is linear; the construction
for arbitrary cost functions is based on the same idea, but it involves some minor
technical obstacles. Let  be the expiration time from .
Choose some large integers  and .  The constructed instance 
 consists of  ``nested'' and ``compressed'' copies of , that we
also refer to as \emph{phases}.
In the -th phase we multiply the waiting cost function of each node by . 
We let this phase start at time 
(that is, at this time the requests from this phase are released) and
end at time . Thus the length of phase  is .
The main trick is that, in , at time  the adversary can serve
all pending requests (from all phases) at the cost that is independent of , 
so the contribution of this service cost to the cost of each phase is negligibly small. 
Following this idea, any -competitive
algorithm for  can be converted into an -competitive algorithm
for , except for some vanishing additive constant.
(See \cite{jrp-online-buchbinder,aggregation_wads_2013} for more details.)



\subsection{Characterizing Optimal Solutions}

Suppose that the expiration value is . Then the optimal solution is to serve some
subtree  (rooted at ) already at time~0 and wait until the end of the phase at time  with the remaining 
requests in . 
So now we consider schedules of this form, that consist of one 
service subtree  at time .
The cost of this schedule (that we identify with  itself) is

where, for any set , 
denotes the waiting cost of all requests in  (see Section~\ref{subsec: mlap notations}.)

Our first objective
is to characterize those subtrees  that are optimal for . 
This characterization will play a critical role in our online algorithm for
, provided later in this section
and it also leads to an offline polynomial-time algorithm for computing optimal
solutions, given in Section~\ref{sec: 1p-mlap with deadlines}.

The lemma below 
can be derived by expressing  as a linear program and using strong duality. We
provide instead a simple combinatorial proof. For each subtree  of , we
denote its root by . (Also, recall that  is the induced
subtree of  rooted at , that is,  contains all descendants of  in .)


\begin{lemma}\label{lem: 1-phase optimal schedules}
A service  is optimal for an expiration time  if and only if 
it satisfies the following two conditions:
\begin{description}
\item{{\rm (a)}}  for each , and
\item{{\rm (b)}}  for each subtree , disjoint with ,
			such that  .
\end{description}
\end{lemma}

\begin{proof}

We begin by proving that (a) and (b) are necessary conditions for optimality
of .

(a) Suppose that there is a  for which .
Let . Then  is a service tree (empty if ), and we have

contradicting the optimality of .

(b) Suppose that there is a subtree  that violates condition (b), that is ,
, but .
Let . Then  is a service tree and

contradicting the optimality of .


We now prove sufficiency of conditions (a) and (b). Suppose that  satisfies
(a) and (b), and let  be any other service subtree of .
From (b), for any node  with 
we have . 
Since both  and  are rooted at , any node in 
is in some induced subtree , for some  such that .
This implies that .
Similarly, from (a), for any node  with 
we have . This implies that
. These inequalities  give us that

proving the optimality of .
\end{proof}


Following the terminology from Section~\ref{subsec: mlap notations}, 
a subtree  of  (not necessarily rooted at )
is called \emph{mature at time } if . (We do not need to specify
the set of requests in , as all requests are released at time .)
In this section we will simplify this notation and write ``-mature'', instead of
``mature at time ''.
We say that  is \emph{-covered} if each induced subtree 
, for , is -mature. (Note that in this definition
 itself is not required to be -mature.)
We now make two observations. First, if  is -covered then
the definition implies that each induced subtree  of  is -covered as well.
Two, if , that is if  consists of only one node,
then  is vacuously -covered; thus any subtree 
of  has a -covered subtree rooted at . 


\begin{lemma}\label{lem: Ot unique}
If  and  are -covered service subtrees of  then
the service subtree  is also -covered.
\end{lemma}

\begin{proof}
If  the lemma is trivial, so assume .
Choose any  with .
Without loss of generality, we can assume that .
By definition,  is -mature and disjoint with . 

Take .  is a service subtree of . 
We claim that  is -covered. To justify this claim, choose any . 
If  and , then  is -mature because .
If  then  is -mature because .
The remaining case is when  and .
Then
,
so  is -mature in this case as well. 
Thus indeed  is -covered, as claimed.

We can now update  by setting  and applying the above argument again.
By repeating this process, we will end up with , completing the proof.
\end{proof}

Choose  to be the inclusion-maximal -covered service subtree of  (that is, 
a subtree rooted at ). By Lemma~\ref{lem: Ot unique},  is well defined and unique.
Also, from Lemma~\ref{lem: 1-phase optimal schedules} we obtain that  is optimal for 
expiration time . Thus the optimal cost when  is

Trivially, if a subtree  is -mature and  then  is -mature as well.
This implies the following corollary.


\begin{corollary}\label{cor:optima-grow}
For every  it holds that .
\end{corollary}





\subsection{An Online Competitive Algorithm}  

Without loss of generality, we can assume that
; otherwise the distances
together with the waiting costs can be rescaled to satisfy this
property. To simplify the presentation we will assume that for
 the optimum cost grows to .  (Any
instance can be modified to have this property, without changing the
behavior of the algorithm on , by adding an infinite path to
the root of , where the nodes on this path have waiting cost
functions that are initially  and then gradually increase.)


\paragraph{Algorithm~.}
For any , define  to be the first time when .
At each time  serve .

\smallskip

Algorithm~ is in essence a doubling algorithm~\cite{doubling-sigact}. However, although 
obtaining \emph{some} constant ratio using doubling is not difficult, the formulation that achieves 
the optimal factor of  relies critically on the structure of optimal solutions that we elucidated 
earlier in this section. For example, note that the sequence of service costs of the algorithm 
does not necessarily grow exponentially.


\paragraph{Analysis.}

By our assumption that , we have
; that is, until time  the optimum solution will not make any services and will
only pay the waiting cost. This also implies that .

We now estimate the cost of Algorithm~, for a given expiration time .
Suppose first that , by which we mean that the expiration is right after the algorithm's service at 
time . The total service cost of the algorithm is trivially .
To estimate the waiting cost, consider some node . If , for some , then
the waiting cost of  is . Otherwise, for , the waiting cost of 
is .
Thus {\algDoubling}'s total cost is

as needed. 

Next, suppose that  is between two service times, say .
From the optimality of  at expiration time , we have
.
Using this bound,
the increase of the optimum cost from time  to time  can be estimated 
as follows:

where the last expression is the increase in Algorithm~'s cost from time
 to time . This implies that the ratio at expiration time  cannot be larger than the
ratio at expiration time .

Finally, we have the case when . Thus . By our assumption that all
weights are greater than , this implies that , and thus
 is the same as the cost of the algorithm.


Summarizing, we obtain our main result of this section.

\begin{theorem}\label{thm:doubling-for-phase}
	{\algDoubling} is -competitive for the Single-Phase .
\end{theorem}




\subsection{An Offline Polynomial-Time Algorithm}
\label{sec: 1p-mlap with deadlines}

The offline algorithm for computing the optimal solutions is based on
the above-established properties of optimal sets .
It proceeds bottom up,
starting at the leaves, and pruning out subtrees that are not
-covered.  The pseudo-code of our algorithm is shown below.


\begin{algorithm}[ht]
\caption{{\algCovSubT}}\label{alg:paidsubtree}
\begin{algorithmic}[0]
\State 
\State 
\For{each child  of }
    \State 
	\If{}
    	\State 
    	\State 
	\EndIf
\EndFor
\State \textbf{return} 
\end{algorithmic}
\end{algorithm}


For each node  the algorithm outputs a pair
, where  denotes the maximal (equivalently w.r.t. inclusion or cardinality)
-covered subtree of  rooted at , and 
, that
is  is the ``surplus'' waiting cost of  at time . (Note that
we do not account for  in this formula.)
To compute , the algorithm returns {\algCovSubT}.

By a routine argument, the running time of Algorithm~{\algCovSubT} is
, where  is the size of the instance (that is, the number of nodes
in  plus the number of requests). Here, we assume that the
values  can be computed in time proportional to the number of
requests in .




\section{{\MLAP} on Paths}
\label{sec: mlap on paths}

We now consider the case when the tree is just a path. For simplicity we will
assume a~generalization to the~continuous case, that we refer to as 
\emph{the {\MLAP} problem on the line}, when the path is represented by the half-line
; that is the requests can occur at any point . Then
the point  corresponds to the root, each node is a point ,
and each service is an interval of the form .
We say that an algorithm {\em delivers from}~ if it serves the interval .

We provide several results for the {\MLAP} problem on the line.
We first prove
that the competitive ratio of {\MLAPD} (the variant with deadlines) on
the line is exactly , by providing matching upper and lower
bounds. Then later we will show that the lower bound of  can be
modified to work for {\MLAPL} (that is, for linear waiting costs).


\paragraph{Algorithm~{\DLINE}.}

The algorithm creates a service only when a deadline of a pending request is reached.
If a~deadline of a request at  is reached, then {\DLINE} delivers from .


\begin{theorem}
Algorithm~{\DLINE} is -competitive for {\MLAPD} on the line.
\end{theorem}

\begin{proof}
The proof uses a charging strategy. We represent each adversary service, say when the 
adversary delivers from a point , by an interval . The cost of each
service of {\DLINE} is then charged to a segment of one of those adversary service intervals.

Consider a service triggered by a deadline  of a request  at some point .
When serving , {\DLINE} delivered from .
The adversary must have served  between its arrival time and its
deadline~. Fix the last such service of the adversary, where at a time  the
adversary delivered from a point . We charge the
cost  of the algorithm's service to the segment  of the
adversary's service interval  at time . 

We now claim that no part of the adversary's service is charged twice.
To justify this claim, suppose that there are two services of {\DLINE}, at 
times , triggered by requests from points  and , respectively, 
that both charge to an adversary's service from  at time . 
By the definition of charging, the request at  was 
already present at time . As  was not served 
by {\DLINE}'s service at , it means that , and thus
the charged segments  and  of the adversary service
interval at time  are disjoint.

Summarizing, for any adversary service interval , its charged
segments are disjoint. Any charged segment receives the charge equal to
 times its length. Thus this interval receives the total charge
at most . This implies that the competitive ratio is at most~.
\end{proof}


\paragraph{Lower bounds.}

We now show lower bounds of  for {\MLAPD} and {\MLAPL} on the line.
In both proofs we show the bound for the corresponding
variant of {\SPMLAP}, using a reduction from the online bidding
problem~\cite{doubling-sigact,online-bidding}. Roughly speaking, in online
bidding, for a given universe  of real numbers, the adversary chooses a secret
value  and the goal of the algorithm is to find an upper-bound
on . To this end, the algorithm outputs an increasing sequence of numbers
. The game is stopped after the first  that is at
least  and the bidding ratio is then defined as .

Chrobak et al.~\cite{online-bidding} proved that the optimal bidding ratio is exactly , even if it is 
restricted to sets   of the form , for some integer . 
More precisely, they proved the following result.

\begin{lemma}
\label{lem:online_bidding}
For any , there exists , such that any sequence of integers 
 has an index  with
.
\end{lemma}


\begin{theorem}
\label{thm:mlapd_path_lower_bound}
There is no online algorithm for {\MLAPD} on the line with competitive ratio smaller than .
\end{theorem}


\begin{proof}
We show that no online algorithm for {\SPMLAPD} (the deadline variant of {\SPMLAP}) 
on the line can attain competitive ratio smaller than . 
Assume the contrary, i.e., that there exists a deterministic algorithm  that is -competitive,
where . 
Let  be the integer whose existence is guaranteed by Lemma~\ref{lem:online_bidding}.
We create an instance of {\SPMLAPD}, where, at time ,
for every   there is a~request at  with deadline .

Without loss of generality, {\ALG} issues services only at integer times .
The strategy of {\ALG} can be now defined as a sequence of services at times 
, where at time  it delivers from 
.  Without loss of
generality, . We may assume that  (otherwise
the algorithm is not competitive at all); we also add a~dummy service from  at time .

The adversary now chooses some  and stops the game at the expiration time that is right after
the algorithm's th service, say .
{\ALG}'s cost is then . 
The request at  is not served at time , so, to meet the deadline of this request,
the schedule of  must satisfy .  
This implies that , that is,
all requests at points  expire 
before their deadlines and do not need to be served.
Therefore, to serve this instance, 
the optimal solution may simply deliver from  at time~. 
Hence, the competitive ratio of {\ALG} is at least 
. By Lemma~\ref{lem:online_bidding}, it is possible to choose~
such that this ratio is strictly greater than , a contradiction with 
-competitiveness of {\ALG}.
\end{proof}

Next, we show that the same lower bound applies to {\MLAPL}, the version of
{\MLAP} where the waiting cost function is linear. This improves the lower
bound of  from~\cite{aggregation_wads_2013}.


\begin{theorem}
\label{thm:mlapl_path_lower_bound}
There is no online algorithm for {\MLAPL} on the line with competitive ratio smaller than .
\end{theorem}

\begin{proof}
Similarly to the proof of Theorem~\ref{thm:mlapd_path_lower_bound}, we create an instance of 
{\SPMLAPL} (the variant of {\SPMLAP} with linear waiting cost functions)
that does not allow a better than -competitive online algorithm.
Fix any online algorithm {\ALG} for 
and, towards a contradiction, suppose that it is -competitive, for some .
Again, let  be the integer whose existence is guaranteed by Lemma~\ref{lem:online_bidding}.
In our instance of {\SPMLAPL}, there are  requests at  for any 
. 

Without loss of generality, we make the same assumptions as in the proof of
Theorem~\ref{thm:mlapd_path_lower_bound}: algorithm {\ALG} is defined by
a sequence of services at times ,
where at each time  it delivers from some point . Without loss of generality,
we can assume that . 

Again, the strategy of the adversary is to stop the game at some expiration time 
that is right after some time , say , for some small .
The algorithm pays  for serving the requests. The  
requests at  waited for time~ in {\ALG}'s schedule 
and hence {\ALG}'s waiting cost is at least . 

The adversary delivers from point  at time .
The remaining, unserved requests at points 
pay time  each for waiting. 
There are  
such requests and hence the adversary's waiting cost is at most 
.

Therefore, the algorithm-to-adversary ratio on the waiting costs is 
at least . For any  we can choose a sufficiently small 
so that this ratio is larger than .
By Lemma~\ref{lem:online_bidding}, it is possible to choose~ for which
the ratio on servicing cost is strictly greater than . 
This yields a contradiction to the -competitiveness of {\ALG}.
\end{proof}

We point out that
the analysis in the proof above gives some insight into the behavior of any
-competitive algorithm for {\SPMLAPL} (we know such an algorithm
exists, by the results in Section~\ref{sec: one-phase MLAP}), namely that,
for the type of instances used in the above proof,
its waiting cost must be negligible compared to the service cost.


\section{An Offline 2-Approximation Algorithm for {\MLAPD}}
\label{sec: mlap with deadlines}

In this section we consider the offline version of , for which Becchetti~\etal~\cite{packet-aggregation-becchetti}
gave a polynomial-time -approximation algorithm based on LP-rounding. We give a
much simpler argument that does not rely on linear programming. 

We will use an alternative specification of schedules that
is easier to reason about in the context of offline approximations.
If  is a schedule, for each node
 we can specify the set  of times  for which
 contains a service  with . Then the set
 uniquely determines .  Note
that we have  whenever  is the parent
of .  Further, we can now write the service cost as
.  It is easy to
see that (without loss of generality) in an optimal (offline) schedule
 each service time is equal to some deadline, and we will
make this assumption in this section; in particular,
 can be assumed to be the set of all deadlines.

Let  be the given instance. For each node , define  to be the set of all intervals , 
for requests  issued in . 


\paragraph{Algorithm~.}

We proceed level by level, starting at the root and in order of increasing depth, computing the service 
times  for all nodes . 
For the root ,  is the set of the deadlines of all requests.
Consider now some node  with parent  for which  has already been computed. 
Using the standard earliest-deadline algorithm, compute  as the minimum cardinality subset of 
that intersects all intervals in .

\medskip


Algorithm~ clearly runs in polynomial time; in fact it can be implemented in time 
, where  is the total size of .

We now show that the approximation ratio of Algorithm~ is at most . (It is easy to find an
example showing that this ratio is not better than .)
Denote by  an optimal schedule for . According to our
convention,  is then the set of times when  is served in . Since
 and the optimum cost 
is , it
is sufficient to show that  for each .
This is quite simple: if  is the father of  then  intersects all intervals in . 
We construct  as follows.
For each , choose the maximal  such that  , and
the minimal  such that  .
Add  to . (More precisely, each of them is added only if it is defined.)
Then   and .
Further, any interval  contains some  and intersects ,
so it also must contain either  or . Therefore   intersects all intervals in . Since
we pick  optimally from , we have ,
completing the proof.



\section{General Waiting Costs}
\label{sec: general waiting costs}

Our model of {\MLAP} assumes full continuity, namely that the time is
continuous and that the waiting costs are continuous functions of
time, while in some earlier literature authors use the discrete model.
Thus we still need to show that our algorithms can be applied in the
discrete model without increasing their competitive ratios. We also
consider the model where some request may remain unserved.  We
explain how our results can be extended to these models as well. 
We will also show that our results can be extended to functions that
are left-continuous, and that {\MLAPD} can be represented as a special
case of {\MLAP} with left-continuous functions. While those reductions
seem intuitive, they do involve some pesky technical challenges, and they
have not been yet formally treated in the literature.


\paragraph{Extension to the discrete model.} 

In the discrete model (see~\cite{jrp-online-buchbinder}, for example), 
requests arrive and services may happen only at integral
points , where  is the time horizon. The waiting
cost functions  are also specified only at integral
points. (The model in~\cite{jrp-online-buchbinder} also allows waiting costs to be
non-zero at the release time. However we can assume that , since
increasing the waiting cost function uniformly by an additive constant can only decrease the
competitive ratio.)

We now show how to simulate the discrete time model in the model where time
and waiting costs are continuous. Suppose that  is an
-competitive online algorithm for the model with continuous time and continuous 
waiting cost functions.  We construct an -competitive
algorithm  for the discrete time model.

Let  be an instance given to . We
extend each waiting cost function  to non-integral
times as follows: for each integral  we define
 for  so that it continuously
increases from  to  (e.g., by linear interpolation);
 for all ; and
 for all . 

Algorithm  presents the instance 
with these continuous waiting cost functions to . At each
integral time ,  simulates  on the whole
interval .  If  makes one or more services, 
makes a single service at time  which is their union. This is
possible, since no request arrives in . At time ,
algorithm  issues the same service as .

Overall,  produces a feasible schedule in the discrete time model. 
The cost of  does not exceed the cost of
.  On the other hand, any feasible (offline) schedule 
in the discrete time model is also a feasible schedule in the
continuous time model with the same cost. Thus  is
-competitive.


\paragraph{Unserved requests with bounded waiting costs.}

In our definition of {\MLAP} we require that all the requests are
eventually served. However, if the waiting cost of a request  is
bounded, it is natural to allow a possibility that  is not
served in  a schedule ; in that case it incurs waiting cost 
. In
this variant, there is no time horizon in the instance.

Our algorithm {\OnAlgTreesGeneral} works in this model as well, with
the competitive ratio increased at most by one. The only modification of
the algorithm is that there is no final service at the time
horizon.  Instead we let the time proceed to infinity, issuing
services at the maturity times of  (the quasi-root of ). 

To modify our charging scheme to this variant, the key observation is
that if a node  is never serviced both in {\OnAlgTreesGeneral}
and in an optimal schedule , then the requests at  pay
the same waiting costs in both schedules. Thus we can ignore such
nodes and requests at them. We claim that for each remaining node
, the pseudo-schedule  contains at least one
pseudo-service of : Indeed, otherwise  is not served in
 and the total (limit of the) waiting cost of all the
(unserved) requests in the induced subtree  is less than ,
which implies that the maturity time of  is always infinite and
thus  is never serviced in {\OnAlgTreesGeneral} either,
contradicting the fact that  was not ignored before. Now consider
all the remaining unserved requests and add to the schedule of
{\OnAlgTreesGeneral} one last service that serves all these requests.
As the unserved requests do not cause  to mature, this increases
the cost of {\OnAlgTreesGeneral}; at the same time the service of
each node can be charged to a pseudo-service of the same node
in , which increases the competitive ratio by at most~1.


\paragraph{Extension to left-continuous waiting costs.}  

We now argue that we can modify our algorithms to handle
\emph{left-continuous} waiting cost functions, i.e., functions that
satisfy 
for each time .  Left-continuity enables an online algorithm
to serve a request at the last time when its waiting cost is at or
below some given threshold.

Some form of left-continuity is also necessary for constant
competitiveness.  To see this, think of a simple example of a tree of
depth  and with , and a sequence of requests in  with release times
approaching , and waiting cost functions defined by
 and  for . If
an online algorithm serves one such request before time , the
adversary immediately releases another. The sequence stops either
after  requests or after the algorithm serves some
request at or after time , whichever comes first. 
The optimal cost is at most ,
while the online algorithm pays at least .

The basic (but not quite correct) idea of our argument for left-continuous waiting
cost functions is this:
For any time point  where some waiting cost function has a discontinuity,
we replace point  by a ``gap interval'' , for some . 
The release times after time  and the values of all
waiting cost functions after  are shifted to the right by .
In the interval , for each request , its waiting
cost function is filled in by any non-decreasing continuous curve with value
 at  and  at , for 
and .
Thus the waiting cost functions that are continuous at  are simply
``stretched'' in this gap interval, where their values remain constant.
This will convert the original instance  into an instance
 with continuous waiting cost functions; then we can apply
a simulation similar to the one for the discrete model, with the
behavior of an algorithm  on  inside  mimicked
by the algorithm  on  while staying at time .

The above construction, however, has a flaw: as  is online, for each
newly arrived request  it would need to know the future requests
in order to correctly modify 's waiting cost function (which needs
to be fully revealed at the arrival time). Thus, inevitably,  will
need to be able to modify waiting cost functions of earlier
requests, but the current state of  may depend on these functions.
Such changes could make the computation of  meaningless. 
To avoid this problem, we
will focus only on algorithms  for continuous cost functions that
we call \emph{stretch-invariant}. Roughly, those are algorithms whose
computation is not affected by the stretching operation described above.

To formalize this, let 
be a finite set of \emph{gap intervals}, where all times  are distinct.
(For now we can allow the 's to be any positive reals; their purpose will
be explained later.)
Let  denote the time  shifted right by
inserting intervals  on the time axis. We extend this operation to
requests in a natural way: for any request  with a 
continuous waiting cost function,
 denotes the request modified by inserting 
on the time axis and filling in the values of  in the
inserted intervals by constant functions, as described earlier. For a set
of requests ,  the stretched set of requests
 is the set consisting of requests  for
all .

Consider an online algorithm  for {\MLAP} with
continuous waiting cost functions.
We say that  is {\em stretch-invariant} if for every instance  and any set of gap intervals , the
schedule produced by  for the instance
 is obtained from the schedule
produced by  for  by shifting it according to ,
namely every service  is
replaced by service .

Most natural algorithms for {\MLAP} are stretch-invariant. In case of
{\OnAlgTreesGeneral}, observe that its behavior depends only on the
maturity times  where  is the set of pending requests and
; in particular
stretching does not change the order of the maturity times. 
Using induction on the current time , we observe 
{\OnAlgTreesGeneral} creates a service  in its schedule for the request set 
if and only if
{\OnAlgTreesGeneral} creates a service  in its schedule
for the request set .

Suppose that  is an -competitive online
algorithm for continuous waiting cost functions that is stretch-invariant.  
We convert  into an
-competitive algorithm  for left-continuous waiting costs.
Let  be an instance given to .
Algorithm  maintains the set of gap intervals , and
a set of requests  presented to ; both sets are
initially empty.  Algorithm  at time  simulates the
computation of  at time .

If a new request  is released at time ,
algorithm  obtains  from  by
replacing the discontinuities of  by new gap intervals 
on which  is defined so that it continually
increases. (If a gap interval already exists in  at the
given point, it is used instead of creating a new one, to maintain the
starting points distinct.) We set
, which is the current time in . We update
 to ; this does not change the current
time in  as all  new gap intervals start at or after
.  We stretch the set of requests  by ; this
does not change the past output of , because  is
stretch-invariant. (Note that the state of  at time  may change, but
this does not matter for the simulation.)
Finally, we add the new request  to . 

If the current time  in  is at a start point of a
gap interval, i.e., , algorithm  simulates the
computation of  on the whole shifted gap interval
. If  makes one or more
services in ,  makes a
single service at time  which is their union.

The cost of  for requests  does not exceed the cost of
 for requests .  Any adversary schedule  for
 induces a schedule  for  with the same
cost. Since 's cost is at most , we
obtain that 's cost is at most ;
hence  is -competitive.

In the discussion above we assumed that the instance has a finite number
of discontinuities. Arbitrary left-continuous waiting
cost functions may have infinitely many discontinuity points, but the
set of these points must be countable. The construction described
above extends to arbitrary left-continuous cost functions, as long as
we choose the  values so that their sum is finite.


\paragraph{Reduction of {\MLAPD} to {\MLAP}.}

We now argue that  can be expressed as a
variant of  with left-continuous waiting cost functions. The idea
is simple: a
request  with deadline  can be assigned a waiting cost
function  that is  for times  and 
for  -- 
except that we cannot really use , so we need to replace it by
some sufficiently large number.
If , we let 
, where  is the sum of all
weights on the path from  to  (the ``distance'' from  to ).
This will convert an instance  of  into an
instance  of  with left-continuous waiting cost functions.

We claim that, without loss of generality, any online algorithm
 for  serves any request  before or at time .
Otherwise,  would have to pay waiting cost of  for 
(where ),
so we can modify  to serve  at time  instead,
without increasing its cost.
We can then treat  as an algorithm for .
 will meet all deadlines in  and its cost on  will be
the same as its cost on , which means that
its competitive ratio will also remain the same.

Note that algorithm {\OnAlgTreesGeneral} (or rather its extension to
the left-continuous waiting costs, as described above) does
not need this modification, as it already guarantees that when the
waiting cost of a request at  reaches , all the nodes on
the path from  to  are mature and thus the whole path is served.

\bibliographystyle{abbrv}
\bibliography{references}

\end{document}
