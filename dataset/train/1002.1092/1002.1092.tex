\documentclass{patmorin}
\usepackage{graphicx,amsmath}
\usepackage{pat}
\usepackage[mathlines]{lineno}
\listfiles


\newtheorem{defn}{Definition}
\newcommand{\deflabel}[1]{\label{defn:#1}}
\newcommand{\defref}[1]{Definition~\ref{defn:#1}}
\newcommand{\eps}{\epsilon}
\newcommand{\depth}{\mathrm{depth}}
\newcommand{\poly}{\includegraphics{poly}}


\title{\MakeUppercase{Odds-On Trees}}

\author{Prosenjit~Bose, 
        Luc~Devroye,
	Karim~Dou\"{\i}eb, 
	Vida~Dujmovi\'c, 
	James~King, and 
	Pat~Morin}

\begin{document}
\maketitle

\begin{abstract}
  Let  be a query problem over 
  for which there exists a data structure  that can compute
   in  time for any query point .
  Let  be a probability measure over  representing a distribution
  of queries.  We describe a data structure , called
  the \emph{odds-on tree}, of size  that can be used as a
  filter that quickly computes  for some query values in
   and relies on  for the remaining queries.  With an
  odds-on tree, the expected query time for a point drawn according to
   is , where  is a lower-bound on the expected cost
  of any linear decision tree that solves .

  Odds-on trees have a number of applications, including
  distribution-sensitive data structures for point location in 2-d,
  point-in-polytope testing in  dimensions, ray shooting in simple
  polygons, ray shooting in polytopes, nearest-neighbour queries in
  , point-location in arrangements of hyperplanes in ,
  and many other geometric searching problems that can be solved in the
  linear-decision tree model.  A standard lifting technique extends these
  results to algebraic decision trees of constant degree.  A slightly
  different version of odds-on trees yields similar results for orthogonal
  searching problems that can be solved in the comparison tree model.
\end{abstract}

\section{Introduction}

Geometric search problems have a long and rich history
\cite{ae99,g00chapter,ms05}. In these problems, we are typically
given a collection  of  geometric objects in  and asked
to store them in a data structure so that we can efficiently answer
queries about these objects. Until quite recently, the performance of
these data structures was typically measured, at least theoretically,
in terms of the worst-case (over all possible choices of  and )
query time as a function of .  A worst-case query time of  is typically viewed as the gold standard for such search problems,
at least in models of computation that only allow binary decisions.

Somewhat more recently, researchers have begun studying geometric
search problems under the lens of \emph{distribution-sensitivity}. In
this setting, one assumes that there is a probability measure  over
the set of possible queries, and one attempts to optimize the expected
query time when queries are distributed according to .  For example,
given a planar triangulation  and a distribution  over ,
one can construct an  sized data structure that can determine
the face of  that contains any query point .  The expected
query time of this structure is , where

and  denotes the probability that  is contained in the th face
of  \cite{acmr00,amm00,amm01a,amm01b,ammw07,i01,i04}.  Information
theory tells us that this result is optimal in any \emph{dichotomous}
model of computation where any execution branching has at most 2 possible
outcomes.

More recently, Collette \etal\ \cite{cdilm08,cdilm09} have shown that a
similar result holds for point location in any simple connected planar
subdivision .  Note that this involves more than simply triangulating
 and applying the results for triangulations.  Triangulating 
increases the number of faces and therefore also increases the value of
 in \eqref{entropy-faces}.  On the other hand, we can not expect to
always achieve a query time of  since this would imply, for
example, an  query-time data structure for testing if a point
is contained in a simple polygon.  The result of Collette \etal\  is
a data structure whose expected query time is  where 
is a lower-bound on the expected cost of any linear decision tree for
point location in  with queries distributed according to .

Dujmovi\'c \etal\ \cite{dhm09} study distribution-sensitive 2-sided
2-dimensional orthogonal range counting.  They describe a data
structure, called a biased range tree, that preprocesses an  point
set  and a query distribution  over .  A biased
range tree uses  preprocessing time and space and can
answer 2-sided 2-dimensional orthogonal range counting queries over
 in expected time , where  is a lower-bound on the
expected cost of any comparison tree for 2-sided range queries over 
with queries distributed according to .

The results of Collette \etal\ \cite{cdilm08,cdilm09} and Dujmovi\'c
\etal\ \cite{dhm09} use similar techniques to prove their optimality,
but each requires their own \textit{ad hoc} arguments.  For example, the point
location results are achieved by finding near-minimum-entropy Steiner
triangulations and then applying existing distribution-sensitive results
for point location in triangulations.  Biased range trees on the other
hand, mix -d trees, fractional cascading, and biased binary search
trees to achieve their running time.

In the current paper, we describe a general and low-overhead method
of taking any  query-time data structure and making it
distribution-sensitive.  Let  be a query
problem over  for which there exists a data structure 
that can compute  in  time for any query
point .\footnote{There is no natural definition of  for
the abstract problem .  Nevertheless, all the problems
we will eventually consider arise from a set of  objects in 
and, for all these problems  is the optimal worst-case
query time in the models of computation we will consider.}  Let 
be a probability measure over  representing a distribution
of queries.  We describe a data structure ,
called the \emph{odds-on tree},\footnote{\textbf{odds-on} 
\textit{adj.}\ having a better than even chance of success ``the odds-on
favourite''}  of size  that can be used as a filter that
quickly computes  for some query values in  and
relies on  for the remaining queries.  With an odds-on tree,
the expected query time for a point drawn according to  is ,
where  is a lower-bound on the expected cost of any linear decision
tree that solves .

For any constant integer , a standard lifting technique allows us
to lift queries from  into , with 
so that there is a correspondence between -variate linear inequalities
(halfspaces in ) and -variate polynomial inequalities of
maximum degree  \cite{yy85}.  This technique yields the same result,
except that  becomes a lower-bound on the expected cost of any
degree  algebraic decision tree that solves .

Odds-on trees have a plethora of applications, including
distribution-sensitive data structures for point location in 2-d,
point-in-polytope testing in  dimensions, ray shooting in simple
polygons, ray shooting in polytopes, nearest-neighbour queries in ,
point-location in arrangements of hyperplanes in , and many other
geometric searching problems that can be solved in the linear-decision
tree model.  Furthermore, a variant of the odds-on tree that works in
the comparison tree model provides distribution-sensitive data structures
for orthogonal searching problems in the comparison tree model.

The remainder of this paper is organized as follows:
\Secref{prelim} presents some preliminary definitions and background
material. \Secref{data-structure} presents the odds-on tree and
algorithms for constructing it.  \Secref{analysis} proves that the
odds-on tree matches the query time of any linear decision tree.
\Secref{applications} presents some of the geometric applications of this
data structure. Finally, \secref{conclusions} summarizes and concludes
with directions for future work.

\section{Preliminaries}
\seclabel{prelim}

Throughout this paper, the underlying dimension, , is a constant, and
other constants defined in the paper may (implicitly) depend on .
A \emph{simplex} in  is the common intersection of a set of at most
 closed halfspaces in . Note that, under this definition,
simplices need not be bounded and , as well as , are
both simplices.


Throughout this paper, we assume an underlying probability measure
 over .  All expectations and probabilities are (implicitly)
with respect to .  For any subset ,  refers
to .  We use the notation  to denote the distribution 
conditioned on , i.e., 
for all .  If  are non-overlapping
subsets of  then the \emph{entropy} of , denoted  is

where for any set ,  denotes .
The probability measure  is used as an input to our algorithms.
We assume that the algorithm has access to  through a \emph{Sampling
Oracle} that allows us to draw a random sample  from the
distribution .

A \emph{query problem} over  is a function
 where  is some set of \emph{answers}.
We assume the existence of two oracles that allow access to .
The \emph{Backup Oracle} allows us to compute  for
any query point , but requires  time to do so.  The
\emph{Interference Oracle} allows us to test, for any simplex ,
if there exists  with .
The running time of the Interference Oracle will be unspecified.

The oracles are used in the following ways:  The Backup Oracle is used to
answer any queries that can not be answered directly by the odds-on tree.
The Sampling Oracle and the Interference Oracle are used only during
the construction of the odds-on tree. The running times in theorems in
Sections~\ref{sec:data-structure} and \ref{sec:analysis} all specify
the number of invocations of the Sampling and Interference Oracle
used. When discussing applications in \secref{applications}, efficient
implementations of the Interference Oracle for specific problems will
be described.

A \emph{decision tree} for  is a rooted ordered binary
tree in which each internal node  is labelled with a function
 and each leaf  is labelled with an element
.  A query point  follows a root-to-leaf path,
proceeding to the right child of  if  and the left
child of  if .  For a decision tree  and a point
, we denote by  the label of the leaf on the root-to-leaf
path for  in .  A decision tree \emph{solves}  if
 for all . The \emph{depth} of a node 
in a rooted tree , denoted , is the number of edges
on the path from  to the root of .  The \emph{(expected) cost}
of a decision tree, denoted , is the expected depth of the
leaf reached when  is drawn according to the probability measure .

Decision trees are classified based on the types of functions, ,
used at their nodes.  In a \emph{linear decision tree}, each  is
a linear inequality.  In a \emph{degree  algebraic decision tree},
each  is a -variate polynomial inequality of degree .  In a
\emph{comparison tree},  is a simple comparison that compares one
coordinate of a query point  to some value.

Entropy, query problems, and decision trees are all related by (half of)
Shannon's Source Coding Theorem \cite{s48}:

\begin{thm}[Shannon 1948]\thmlabel{shannon}
  Let  be a query problem and define
  , for any . Then, for any decision tree  that solves ,
  
\end{thm}


\section{The Data Structure}
\seclabel{data-structure}

In this section we describe a data structure  called
the \emph{odds-on tree} that, in conjunction with a Backup Oracle, yields
a data structure that solves  and has expected query time
that is within a constant factor of the expected cost of any linear
decision tree  for .   For a reader familiar with
Matou\v{s}ek's efficient partition trees \cite{m92},  the executive
summary of this section is as follows: An odds-on tree is essentially
a partition tree on a sample of  points drawn according
to the distribution .  A complete description follows.

\begin{thm}[Matou\v{s}ek 1992]\thmlabel{point-partition}
There exists a constant  such that, for any set  of 
points in  and any constant , there exists a sequence
 of closed simplices such that
,
  \begin{enumerate}
    \item , where , and
    \item For any hyperplane , there are at most  elements of
   whose interiors intersect .
  \end{enumerate}
  The sequence of simplices  can be computed
  in  time.
\end{thm}

Note that Condition~1 of \thmref{point-partition} is not in the original
statement of the theorem, but follows from Matou\v{s}ek's incremental
construction of  \cite{m92}.



Let  be a set of  points in . Then the \emph{partition
tree}  for  is a rooted ordered tree obtained by recursively
applying \thmref{point-partition}.  The root of  has  children
corresponding to the simplices  obtained
by applying \thmref{point-partition} to . The th child of the
root is itself the root of the partition tree 
for . This recursive process stops when the set 
contains at most 1 point or when the depth exceeds some pre-specified
maximum depth .

Next we define some regions, , , and ,
that are associated with each node  of .  Every node  in
, except the root of , is naturally associated with a simplex
 that was obtained from \thmref{point-partition} and that
generated .  For the root of , we define .

For a node  of  whose ancestors are 
we define .  Note that
, and that  is a convex polytope
that has  vertices since
it is the intersection of at most  halfspaces \cite{m70}.

For a point , the \emph{search path} for  in  starts
at the root and proceeds to the first child  such that 
(note that this implies ) and this process is applied
recursively until reaching a leaf of .  In this way, for every node
 of the partition tree there is a maximal subset  such that the search path for every point  contains .
Note that , but that 
is not necessarily convex or even connected.

We extend the definitions of , , and  to sets of
nodes in  in the natural way; if  is a set of nodes in ,
then , , and
.

The following theorem summarizes the properties of the partition tree
 \cite{m92} (each property is inherited from the corresponding
property of the simplicial partition in
\thmref{point-partition}):

\begin{thm}\thmlabel{point-partition-tree}
  Let  be a set of  points in , let  denote the partition
  tree described above, and let  denote the set of at most 
  nodes of  at depth .  There exists a constant , independent
  of  and , such that the partition tree  has the following
  properties, for every :
  \begin{enumerate}
    \item For every node , , and 
    \item For any hyperplane , the number of elements in
       whose interiors intersect  is at most
      .
    \end{enumerate}
    The partition tree  can be constructed from  in
     time.
\end{thm}

The following is a sampling version of \thmref{point-partition-tree} that we
will use in the construction of an odds-on tree:

\begin{thm}\thmlabel{prob-partition-tree} 
  Let  be a sample of  points in  i.i.d.\ according
  to , let  denote the partition tree
  given by \thmref{point-partition-tree}, and let  denote the set
  of at most  nodes of  at depth .  There exists a constant ,
  independent of ,  and , such that with probability at least
  ,  has the following properties, for every
  :
  \begin{enumerate}
    \item For every node , ,
         and
    \item For any hyperplane , the number of elements in
       whose interiors intersect  is at most
      .
  \end{enumerate}
  The sample partition tree  can be constructed in 
  time plus the cost of  calls to the Sampling Oracle.
\end{thm}

\def\isdef{\buildrel {\rm def} \over =}
\def\PROB{\Pr}

\begin{proof}
  Condition~2 follows with certainty from \thmref{point-partition-tree}.
  In this proof we bound the probability of failure for Condition~1.
  Let .

  We will use  to denote the empirical measure of a set
  :
    
  From \thmref{point-partition-tree} we have
  
  Now,
  
  where  are sets formed by taking the intersection of 
  closed simplices and subtracting   (possibly empty) simplices
  from this intersection.  This is because .
  We can actually handle all levels  of the tree
  at once with the inequality
  
  The class  for  and  is the class of all
  simplices in .   Since a simplex in  is the common
  intersection of  halfspaces in , it helps to first consider
  halfspaces.  The set of halfspaces in  has Vapnik-Chervonenkis
  dimension  (this follows from Radon's Theorem \cite{e93}).
  By Sauer's lemma \cite{s72}\cite[pages~28--29]{dl01}, the number of
  subsets of an -point set that can be obtained by intersections
  with halfspaces does not exceed .  A simple combinatorial
  argument then implies that the number of subsets of an -point set
  that can be obtained by intersections with simplices does not exceed
  .

  Assume now general  and . Then the number of subsets of an
  -point set that can be obtained by intersections with sets from
   does not exceed , by the same
  combinatorial argument.  By a version of the Vapnik-Chervonenkis
  inequality \cite{vc71} shown by Devroye \cite{d82},
  
  for all .
  Thus, 
  
  since .
\end{proof}

Note that, so far, we have not considered the query problem 
at all;  the sample partition tree  of \thmref{prob-partition-tree}
is defined completely in terms of the probability measure .
The \emph{odds-on tree}  for 
is obtained in the following way:  We start by constructing a sample
partition tree  as described in \thmref{prob-partition-tree}
using the value  for some parameter  and setting
the maximum depth to .

Next, we trim some nodes of . We use the
Interference Oracle to test, for each node  of , if
 for all pairs of points .  If so, we remove all the subtrees rooted at the children
of , we call  a \emph{terminal leaf}, and we label  with the
label .  Note that the Interference Oracle works
for simplices, but  is a polytope. Thus, this test requires
decomposing  into simplices and using the Interference
Oracle on each simplex. Using the \emph{bottom vertex triangulation}
\cite{c88} for this decomposition allows us to decompose  into
 simplices in  time.  This yields the following lemma:

\begin{lem}\lemlabel{odds-on-tree-construction}
  For any  and any , an odds-on tree of size ,
  with maximum depth , and having the
  properties of \thmref{prob-partition-tree} can be constructed in
   time plus the cost of  calls
  to the Sampling Oracle and  calls to the
  Interference Oracle.
\end{lem}

Using an odds-on tree to answer a query , is easy: We follow
the search path for  in  until we either reach
a terminal leaf , in which case we output , or we reach a
non-terminal leaf  after  steps, in which case we rely
on the Backup Oracle to report  in  time.
The correctness of this procedure follows immediately from the definition
of terminal and non-terminal nodes.  In the next section, we analyze
the performance of odds-on trees.



\section{Analysis}
\seclabel{analysis}

In this section, our goal is to lower-bound the expected cost of any
linear decision tree that solves  in terms of the odds-on
tree .  We accomplish this by decomposing the nodes
of  into subsets with some helpful combinatorial
properties.

An \emph{-set} of a rooted tree  is a set of vertices in  all of
which are at depth at most  and in which no vertex in the set is the
ancestor of any other vertex in the set.  We say that a set of regions
, , is in \emph{-general
position} if there is no hyperplane that intersects  or more elements
of .

\begin{lem}\lemlabel{independent}
  Let  be the odds-on tree defined in
  \secref{data-structure}, let  be an -set of ,
  and let  be a constant.  Then  contains a subset  such that the elements of  are pairwise disjoint and  in
  -general position and ,
  where  is a decreasing function of .
\end{lem}

\begin{proof}
  We will first use the probabilistic method \cite{as08} to establish
  the existence of a (not necessarily disjoint) set  satisfying the
  size and -general position requirements and then show that 
  contains a large subset  whose elements are also pairwise disjoint.

  Let  be a Bernoulli sample of  where each element is selected
  independently with probability . We
  will prove that
  
  Consider any hyperplane . Condition~2 of
  \thmref{prob-partition-tree} implies that  intersects the
  interior of at most  elements of  for some
  constant .  The probability that  intersects the interior of
   or more elements of  is therefore no more than
  
  For each node ,  has 
  vertices, and the number of nodes in  is at most .
  Therefore, the elements of  define a \emph{test set}  of
   hyperplanes such that
   is in -general position if and only if no hyperplane in
   intersects  or more elements of . The probability
  that \emph{any} hyperplane in  intersects  or more elements of
   is therefore at most
  
  for any .
  The above argument shows that the nodes in
   are quite likely to be in -general position. To see that
   is sufficiently large, we simply observe that  is a
   random variable and therefore has median
  value at least .
  Therefore,
  
  This establishes the existence of a sufficiently large set 
  such that  is in -general position.

  Finally, we select  so that the elements of
   are pairwise disjoint.  To do this, imagine
  sweeping a hyperplane  from
   to .  Associate with each element , the
  maximal interval  such that  intersects 
  for all . This yields a set  of real intervals
  such that no point is contained in  or more elements of .
  Dilworth's Theorem \cite{d50} implies that  contains a subset
  of size at least  of non-overlapping intervals. This subset
  corresponds to a subset  with 
  and such that the elements of  are pairwise
  disjoint. The set  satisfies all the conditions of the lemma.
\end{proof}

We are now ready to show that the expected search time in the odds-on
tree is a lower bound on the expected cost of any linear decision tree
that solves .

\begin{lem}\lemlabel{lower-bound}
  Let  be the odds-on tree defined in
  \secref{data-structure} and assume  satisfies
  Conditions~1 and 2 of \thmref{prob-partition-tree}.  Let  denote
  the set of leaves of , and let  be any linear
  decision tree that solves .  Then
  
\end{lem}

\begin{proof}
  This proof mixes the ideas from the proofs of Lemma~3 by Dujmovi\'c
  \etal\ \cite{dhm09} and Lemma~4 by Collette \etal\ \cite{cdilm08}.
  For an -set  of nodes in , we define the
  shorthands  and .  Let 
  be the tree obtained from  by removing all terminal
  leaves, and let  denote the set of leaves of .  Note that
  
  since each leaf in  has at most  children in . 

  We first partition  into groups , where 
  contains all leaves  such that .  Note that Condition~1 of \thmref{prob-partition-tree}
  implies that the depth of a node in  is at most .

  We then further partition each group  into subgroups
  . For each ,
  , for some constant 
  and the elements of  are pairwise disjoint and in
  -general position.  Furthermore, the final subgroup, 
  has size at most , for some constant .

  This partitioning is accomplished by repeatedly applying
  \lemref{independent} to remove a subset 
  that is in -general position and has size ,
  stopping the process once the size of  drops below . This works provided that we choose , , and 
  so that  and
  set .
  For example, by choosing  and  to be sufficiently large,
   and .

  Consider the linear decision tree  that solves .
  The leaves of  partition  into cells whose closures are
  convex polytopes.  For a leaf  of  we denote its polytope
  by . If the depth of  is , then  is
  the intersection of  at most  halfspaces.  This implies that
   intersects at most  elements of  since,
  otherwise,  contains  for some non-terminal node
  .  (This would contradict the assumption that 
  solves .)

  Let  be some leaf of  such that  intersects 
  elements of .  Then, by the discussion in the previous
  paragraph, .  We can easily create a
  subtree  of  whose height is at most  and with the property
  that  intersects at most one element of 
  for each leaf  of .\footnote{For example, making the root of
   correspond to the bisector of two polyhedra of 
  that intersect  means that each of the children of the root
  intersect at most  elements of . Applying this
  recursively yields a subtree of height at most .  A slightly more
  involved argument can produce a tree  of depth .} If
  we do this for every leaf  of  we obtain a tree 
  such that every leaf of  intersects at most one element
  of .

  Let  denote the distribution
   conditioned on .  Note that the leaves of
   could be relabeled so that they indicate which element of
   (if any) that they intersect.  By Shannon's Theorem
  (\thmref{shannon}), this implies that
  
  It follows \cite[Lemma~3]{cdilm09} that
  
  Thus, all that remains is to upper-bound the contribution of
  ,
  as follows:
  
  Thus, we have 
  
  so , as required.
\end{proof}

\noindent\textbf{Remark:}  By more carefully handling the constants
in the proof of \lemref{lower-bound}, and allowing  and  to be
arbitrarily large, one can obtain the tighter lower-bound

where  can be made arbitrarily close to  by increasing 
and .

\begin{thm}\thmlabel{odds-on}
  Let  be a decision problem for which we
  have a ( time) Backup Oracle and an Interference Oracle,
  and let  be any probability measure over  for which we have
  a Sampling Oracle.  Then, for any constant ,  an odds-on
  tree of size  can be constructed in  time
  plus the cost of  calls to the Sampling Oracle and
   calls to the Interference Oracle.

  This odds-on tree can, in conjunction with the Backup Oracle, compute
   for any  drawn according to  in 
  expected time, where  for any linear decision tree
   that solves .
\end{thm}

\begin{proof}
  Applying \lemref{odds-on-tree-construction} with 
  yields the stated bounds on the construction time and the use of the
  Sampling and Interference Oracles.

  If  satisfies Conditions~1 and 2 of
  \thmref{prob-partition-tree} then, by \lemref{lower-bound}, the expected
  time to answer queries using  is
  
  Otherwise, the expected time to answer queries using 
  is .  Therefore, the expected time (where the expectation
  is taken over  and the random sampling used to generate  in
  \thmref{prob-partition-tree}) to answer a query using an odds-on tree is
  
  On the other hand, by \lemref{lower-bound} the expected cost of any
  linear decision tree  that solves  is
  
  which completes the proof.
\end{proof}

Using a standard lifting of query points \cite{yy85}, any degree 
algebraic decision tree that solves a problem  can be implemented as a linear decision tree in , with
.  Applying this yields the following corollary:

\begin{cor}\corlabel{odds-on-algebraic}
  Let  be a decision problem for which we
  have an ( time) Backup Oracle and an Interference Oracle,
  and let  be any probability measure over  for which we have a
  Sampling Oracle.  Then, for any constants  and ,
  using  calls to the Sampling Oracle and 
  calls to the Interference Oracle, an odds-on tree can be constructed in
   time and  space.  This odds-on tree can,
  in conjunction with the backup oracle, answer -queries
  drawn according to  in  expected time, where  for any degree  algebraic decision tree  that
  solves .
\end{cor}


\section{Applications}
\seclabel{applications}

In this section, we discuss a few of the many potential applications of
odds-on trees.  In all of our applications, the problem  is a
query problem over some set of  geometric objects in .  In order
to shorten the statements of the theorems in this section, we say that a
data structure for a problem  is \emph{distribution-sensitive
(in the linear decision tree model)} if the expected query time of
the data structure is  for any linear decision tree
 that solves . Before delving into the details of the
applications, we first outline some general strategies for implementing
the Interference Oracle needed to build an odds-on tree.

An odds-on tree can be made to have size  for any
constant .  Furthermore, the number of calls to the
Interference Oracle made during the construction of an odds-on tree is
.  In almost all of our applications, the Interference
Oracle can be trivially implemented to run in  time by testing
the query simplex  against each input element.  This means
that, even with no preprocessing, the contribution of calls to the
Interference Oracle to the construction time of an odds-on tree is no more
than .  Some of the subsequent theorems in this paper
will use this fact implicitly.

In other cases, the Interference Oracle corresponds to a natural query for
which there exists (or we can develop) an  query-time
 preprocessing-time data structure.  In these cases, the time
to construct the odds-on tree becomes .  One particularly
common instance of this occurs when Interference Oracle queries can
be reduced to  simplex range counting queries in  for
some constant dimension .  In this case, Matou\v{s}ek's partition
trees \cite{m92} yield an Interference Oracle that can be constructed in
 time and that can answer queries in 
time. 

\subsection{Point Location Problems}

The \emph{planar point location problem} is to determine which face
of a planar straight line graph  contains a query point .
A number of authors have considered distribution-sensitive algorithms for
this problem \cite{acmr00,amm00,amm01a,amm01b,ammw07,cdilm08,i01,i04}
and have mostly solved it.  The most general such result is due to
Collette \etal\ \cite{cdilm08} and gives a distribution-sensitive
data structure for point location in connected planar subdivisions.
This leaves open the case where the graph, , of the subdivision is not
connected.  Since there are several  query-time, 
preprocessing-time data structures for planar point location in (possibly
disconnected) planar subdivision \cite{as98,egs86,k83,m90,st86} we can
apply odds-on trees.

To obtain a fast preprocessing time, we can use an
implementation of the Interference Oracle based on partition trees.  For
this problem, the Interference Oracle must answer queries of the form:
``Does the interior of query triangle  intersect more than one face
of ?''  We can build a data structure for this problem by first removing
from  any edges and vertices not on the boundary of more than 1 face to
obtain a graph .  The interior of  intersects more than one
face of  if and only if the interior of  intersects an edge of
.

If  intersects an edge of  then  contains a vertex of
 or some edge of  intersects some edge of .  Determining if
 contains a vertex of  is the classic 2-dimensional
simplex-range counting problem that can be solved in 
time after  preprocessing using partition trees.  To determine
if some edge  of  intersects some edge  of , we observe
that  and  intersect if and only if

or

where  and , are predicates that are true if and
only if the sequence of points  form a left turn, respectively, a
right turn.  If we fix  and , then each of the above predicates is
the sign of a linear function over the variables , , ,
and .  Therefore, we can treat each edge of  as a point in
, yielding a point set  such that testing if
edge  intersects some edge of  can be reduced to two simplex
range counting queries over .  Again, partition trees allow us to
do this in  time after  preprocessing.
Therefore, the Interference Oracle for point location can be implemented
to run in  time after  preprocessing.
This yields our first theorem:

\begin{thm}\thmlabel{planar-point-location}\thmlabel{first-app}\thmlabel{a}
  There exists a distribution-sensitive data structure for the planar
  point location problem that uses  preprocessing time and
   space.
\end{thm}

The \emph{3-d point in polytope problem} is the problem of determining if
a query point  is contained in a 3-dimensional polytope .
The Dobkin-Kirkpatrick hierarchy \cite{dk83} gives an 
query-time,  preprocessing-time data structure for this problem.
Furthermore, Interference Oracle queries (which involve testing if a
tetrahedron intersects the boundary of ) can also be answered in  time by the Dobkin-Kirkpatrick hierarchy.

\begin{thm}\thmlabel{b}
  There exists a distribution-sensitive data structure for the
  3-dimensional point in polytope problem that uses  preprocessing
  time and space.
\end{thm}

These results can be extended to higher dimensions, though with more
space \cite{c88}:

\begin{thm}
  There exists a distribution-sensitive data structure for
  the -dimensional point in polytope problem that uses
   preprocessing time and space.
\end{thm}

The problem of \emph{point-location in an arrangement of hyperplanes} is
the problem of determining which cell in an arrangement of  hyperplanes
in  contains a query point .  Liu gives an 
space and preprocessing-time,  query-time data structure for
this problem \cite{l04}.

\begin{thm}
  There exists a distribution-sensitive data structure for point location
  in an arrangement of hyperplanes that uses  preprocessing time
  and space.
\end{thm}

\subsection{Post-Office Queries}

For an  point set , the \emph{-dimensional post-office
problem} asks for a point of  that minimizes the Euclidean
distance  for a query point .

The post-office problem can be solved efficiently through the use of
point location in Voronoi diagrams.  In 2-dimensions, Voronoi diagrams
are planar graphs of size  and can be computed in  time
\cite{ps85}.  Combining this with \thmref{planar-point-location} gives
a distribution-sensitive data structure for the 2-d post-office problem:

\begin{thm}\thmlabel{c}
  There exists a distribution-sensitive data structure for the
  2-dimensional post office problem that uses  preprocessing
  time and  space.
\end{thm}

In  dimensions, the post-office problem can still be solved using
Voronoi diagrams, but the space and preprocessing costs are higher
\cite{c88postoffice}:

\begin{thm}
  There exists a distribution-sensitive data structure for the
  2-dimensional post office problem that uses 
  preprocessing time and space.
\end{thm}

\subsection{Ray Shooting}

The \emph{ray shooting in a polygon problem} asks for the first point
on the boundary of a polygon  intersected by a query ray.  A query
ray can be represented as a pair of points in  (the source and
any other point on the ray), so this is a query problem over .
Several  preprocessing time  query time solutions to
this problem exist \cite{cegghss94,hs95}.

\begin{thm}
  There exists a distribution-sensitive data structure for the ray shooting
  in a polygon problem that uses  preprocessing time and
   space.
\end{thm}

The \emph{ray shooting in a -dimensional polytope problem}
asks for the first point on the boundary of a convex polytope
 intersected by a query ray.  For polytopes in ,
the Dobkin-Kirkpatrick hierarchy \cite{dk83} can perform ray shooting
in  time per query.

\begin{thm}
  There exists a distribution-sensitive data structure for the
  ray shooting in a -dimensional polytope problem that uses
   preprocessing time and  space.
\end{thm}

Schwarzkopf \cite{s92} gives an  space,
 query time solution for the problem of ray shooting in a
-dimensional polytope with .

\begin{thm}
  There exists a distribution-sensitive data structure for the
  ray shooting in a -dimensional polytope problem that uses
   preprocessing time and space.
\end{thm}

\subsection{Orthogonal Range Counting}

The \emph{2-d orthogonal range counting problem} is the problem
of counting the number of points of a data set  that
are contained in a query rectangle . (Note
that this produces a query point .) Bentley's range trees
\cite{b75}, with fractional cascading \cite{cg86,l78}, yield an  preprocessing time and space,  query time data structure
for this problem.  Interference Oracle queries for 2-d orthogonal
range counting require determining if any rectangle represented by a
point in a 4-dimensional simplex has some point of  on its boundary.
This problem can be decomposed into  simplex range counting queries
in  in a manner similar to that used for the point location problem.
Thus, an Interference Oracle for this problem can be implemented in
 time after  preprocessing.

\begin{thm}\thmlabel{d}
  There exists a distribution-sensitive data structure for the 2-d
  orthogonal range counting problem that uses  preprocessing
  time and  space.
\end{thm}

Range trees satisfy the constraints of the comparison tree model of
computation, which is considerably weaker than the linear decision tree
model. Dujmovi\'c \etal\ \cite{dhm09} give a distribution-sensitive 2-d
orthogonal range counting data structure that works in the comparison
tree model.  However, their technique can only answer \emph{2-sided
queries}, i.e., queries of the form .

Filter trees can be made to work in the comparison tree model
and handle full (4-sided) 2-d orthogonal range counting queries.
The key modification required is the use of -d trees in
\thmref{prob-partition-tree} rather than Matou\v{s}ek's partition
trees. (This method, in 2 dimensions, is essentially how Dujmovi\'c \etal\
obtain their results.)

In the comparison tree model, an Interference Oracle query is a
-dimensional box, rather than a simplex. In the special case of 2-d
orthogonal range counting, Interference Oracle queries can be reduced to
a constant number of rectangular range counting queries among the input
set .  Therefore, Interference Oracle queries can, in this case,
be answered in  time after  preprocessing using
range trees.

\begin{thm}\thmlabel{last-app}
  There exists a distribution-sensitive data structure \emph{in the
  comparison tree model} for the 2-d orthogonal range counting problem
  that uses  preprocessing time and space.
\end{thm}

\section{Summary and Conclusions}
\seclabel{conclusions}

We have presented a data structure --- the odds-on tree --- that can
be added on to any data structure that answers queries drawn from some
distribution  over .  If the underlying data structure has query
time , then the combined data structure will have optimal
expected query time in the linear decision tree model.  A variant of
the odds-on tree based on -d trees provides a similar result in the
comparison tree model.  \secref{applications} contains a smattering of
applications of the odds-on tree.  Many more are possible.

Note that \corref{odds-on-algebraic} applies to all of the problems
in Theorems~\ref{thm:first-app}--\ref{thm:last-app} to yield, for
any constant , data structures that are distribution-sensitive
in the degree  algebraic decision tree model.  However, when
applying \corref{odds-on-algebraic}, the Interference Oracle becomes
considerably more complicated, so that the fast preprocessing times in
Theorems~\ref{thm:a}, \ref{thm:b}, \ref{thm:c}, and \ref{thm:d} increase
to .
However, the real power of \corref{odds-on-algebraic} is its applications
to problems that cannot be solved by finite linear decision trees.
Examples of such problems include fixed-radius circular ray shooting in
polygons \cite{cceo04}, point-location in 2-dimensional power diagrams
\cite{a87}, point-location in planar subdivisions whose edges are defined
by algebraic curves (such as arrangements of circles), and many others.

We believe that the odds-on tree may actually be practical in some
settings.  The comparison-tree version of the odds-on tree is based on
-d trees, which are simple and widely used in practice. At worst,
a comparison-based odds-on tree will perform  extra
comparisons before falling back to the backup data structure.

In low dimensions, simpler alternatives to Matou\v{s}ek's Partition
Theorem (\thmref{point-partition}) are available and may be more
practical.  For example, in 2-d one can,  time, find two lines
that partition any  point set into four point sets each of size at
most  and such that no line intersects more than the 3 of
the resulting sets \cite{m85}. This result is strong enough that it can
be used in place of \thmref{point-partition} to prove all our results
(for 2-d problems) and yields an odds-on tree that only requires 2
point-line comparisons at each node.

Because the odds-on tree is so small (of size ) it
may be useful to speed up searching in environments where memory is
constrained. For example, it can be applied to the succinct point
location data structures of Bose \etal\ \cite{bchmm09} to obtain a
distribution-sensitive and succinct data structure for point location.
In external-memory settings, an odds-on tree may also be useful as a
filter that is sufficiently small to fit into internal memory while the
backup structure lives in (larger but slower) external memory.




\bibliographystyle{plain}
\bibliography{odds-on}
\end{document}
