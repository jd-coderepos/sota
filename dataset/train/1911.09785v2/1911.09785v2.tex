
\documentclass{article} \usepackage{iclr2020_conference,times}



\usepackage{amsmath,amsfonts,bm}

\newcommand{\figleft}{{\em (Left)}}
\newcommand{\figcenter}{{\em (Center)}}
\newcommand{\figright}{{\em (Right)}}
\newcommand{\figtop}{{\em (Top)}}
\newcommand{\figbottom}{{\em (Bottom)}}
\newcommand{\captiona}{{\em (a)}}
\newcommand{\captionb}{{\em (b)}}
\newcommand{\captionc}{{\em (c)}}
\newcommand{\captiond}{{\em (d)}}

\newcommand{\newterm}[1]{{\bf #1}}


\def\figref#1{figure~\ref{#1}}
\def\Figref#1{Figure~\ref{#1}}
\def\twofigref#1#2{figures \ref{#1} and \ref{#2}}
\def\quadfigref#1#2#3#4{figures \ref{#1}, \ref{#2}, \ref{#3} and \ref{#4}}
\def\secref#1{section~\ref{#1}}
\def\Secref#1{Section~\ref{#1}}
\def\twosecrefs#1#2{sections \ref{#1} and \ref{#2}}
\def\secrefs#1#2#3{sections \ref{#1}, \ref{#2} and \ref{#3}}
\def\eqref#1{equation~\ref{#1}}
\def\Eqref#1{Equation~\ref{#1}}
\def\plaineqref#1{\ref{#1}}
\def\chapref#1{chapter~\ref{#1}}
\def\Chapref#1{Chapter~\ref{#1}}
\def\rangechapref#1#2{chapters\ref{#1}--\ref{#2}}
\def\algref#1{algorithm~\ref{#1}}
\def\Algref#1{Algorithm~\ref{#1}}
\def\twoalgref#1#2{algorithms \ref{#1} and \ref{#2}}
\def\Twoalgref#1#2{Algorithms \ref{#1} and \ref{#2}}
\def\partref#1{part~\ref{#1}}
\def\Partref#1{Part~\ref{#1}}
\def\twopartref#1#2{parts \ref{#1} and \ref{#2}}

\def\ceil#1{\lceil #1 \rceil}
\def\floor#1{\lfloor #1 \rfloor}
\def\1{\bm{1}}
\newcommand{\train}{\mathcal{D}}
\newcommand{\valid}{\mathcal{D_{\mathrm{valid}}}}
\newcommand{\test}{\mathcal{D_{\mathrm{test}}}}

\def\eps{{\epsilon}}


\def\reta{{\textnormal{}}}
\def\ra{{\textnormal{a}}}
\def\rb{{\textnormal{b}}}
\def\rc{{\textnormal{c}}}
\def\rd{{\textnormal{d}}}
\def\re{{\textnormal{e}}}
\def\rf{{\textnormal{f}}}
\def\rg{{\textnormal{g}}}
\def\rh{{\textnormal{h}}}
\def\ri{{\textnormal{i}}}
\def\rj{{\textnormal{j}}}
\def\rk{{\textnormal{k}}}
\def\rl{{\textnormal{l}}}
\def\rn{{\textnormal{n}}}
\def\ro{{\textnormal{o}}}
\def\rp{{\textnormal{p}}}
\def\rq{{\textnormal{q}}}
\def\rr{{\textnormal{r}}}
\def\rs{{\textnormal{s}}}
\def\rt{{\textnormal{t}}}
\def\ru{{\textnormal{u}}}
\def\rv{{\textnormal{v}}}
\def\rw{{\textnormal{w}}}
\def\rx{{\textnormal{x}}}
\def\ry{{\textnormal{y}}}
\def\rz{{\textnormal{z}}}

\def\rvepsilon{{\mathbf{\epsilon}}}
\def\rvtheta{{\mathbf{\theta}}}
\def\rva{{\mathbf{a}}}
\def\rvb{{\mathbf{b}}}
\def\rvc{{\mathbf{c}}}
\def\rvd{{\mathbf{d}}}
\def\rve{{\mathbf{e}}}
\def\rvf{{\mathbf{f}}}
\def\rvg{{\mathbf{g}}}
\def\rvh{{\mathbf{h}}}
\def\rvu{{\mathbf{i}}}
\def\rvj{{\mathbf{j}}}
\def\rvk{{\mathbf{k}}}
\def\rvl{{\mathbf{l}}}
\def\rvm{{\mathbf{m}}}
\def\rvn{{\mathbf{n}}}
\def\rvo{{\mathbf{o}}}
\def\rvp{{\mathbf{p}}}
\def\rvq{{\mathbf{q}}}
\def\rvr{{\mathbf{r}}}
\def\rvs{{\mathbf{s}}}
\def\rvt{{\mathbf{t}}}
\def\rvu{{\mathbf{u}}}
\def\rvv{{\mathbf{v}}}
\def\rvw{{\mathbf{w}}}
\def\rvx{{\mathbf{x}}}
\def\rvy{{\mathbf{y}}}
\def\rvz{{\mathbf{z}}}

\def\erva{{\textnormal{a}}}
\def\ervb{{\textnormal{b}}}
\def\ervc{{\textnormal{c}}}
\def\ervd{{\textnormal{d}}}
\def\erve{{\textnormal{e}}}
\def\ervf{{\textnormal{f}}}
\def\ervg{{\textnormal{g}}}
\def\ervh{{\textnormal{h}}}
\def\ervi{{\textnormal{i}}}
\def\ervj{{\textnormal{j}}}
\def\ervk{{\textnormal{k}}}
\def\ervl{{\textnormal{l}}}
\def\ervm{{\textnormal{m}}}
\def\ervn{{\textnormal{n}}}
\def\ervo{{\textnormal{o}}}
\def\ervp{{\textnormal{p}}}
\def\ervq{{\textnormal{q}}}
\def\ervr{{\textnormal{r}}}
\def\ervs{{\textnormal{s}}}
\def\ervt{{\textnormal{t}}}
\def\ervu{{\textnormal{u}}}
\def\ervv{{\textnormal{v}}}
\def\ervw{{\textnormal{w}}}
\def\ervx{{\textnormal{x}}}
\def\ervy{{\textnormal{y}}}
\def\ervz{{\textnormal{z}}}

\def\rmA{{\mathbf{A}}}
\def\rmB{{\mathbf{B}}}
\def\rmC{{\mathbf{C}}}
\def\rmD{{\mathbf{D}}}
\def\rmE{{\mathbf{E}}}
\def\rmF{{\mathbf{F}}}
\def\rmG{{\mathbf{G}}}
\def\rmH{{\mathbf{H}}}
\def\rmI{{\mathbf{I}}}
\def\rmJ{{\mathbf{J}}}
\def\rmK{{\mathbf{K}}}
\def\rmL{{\mathbf{L}}}
\def\rmM{{\mathbf{M}}}
\def\rmN{{\mathbf{N}}}
\def\rmO{{\mathbf{O}}}
\def\rmP{{\mathbf{P}}}
\def\rmQ{{\mathbf{Q}}}
\def\rmR{{\mathbf{R}}}
\def\rmS{{\mathbf{S}}}
\def\rmT{{\mathbf{T}}}
\def\rmU{{\mathbf{U}}}
\def\rmV{{\mathbf{V}}}
\def\rmW{{\mathbf{W}}}
\def\rmX{{\mathbf{X}}}
\def\rmY{{\mathbf{Y}}}
\def\rmZ{{\mathbf{Z}}}

\def\ermA{{\textnormal{A}}}
\def\ermB{{\textnormal{B}}}
\def\ermC{{\textnormal{C}}}
\def\ermD{{\textnormal{D}}}
\def\ermE{{\textnormal{E}}}
\def\ermF{{\textnormal{F}}}
\def\ermG{{\textnormal{G}}}
\def\ermH{{\textnormal{H}}}
\def\ermI{{\textnormal{I}}}
\def\ermJ{{\textnormal{J}}}
\def\ermK{{\textnormal{K}}}
\def\ermL{{\textnormal{L}}}
\def\ermM{{\textnormal{M}}}
\def\ermN{{\textnormal{N}}}
\def\ermO{{\textnormal{O}}}
\def\ermP{{\textnormal{P}}}
\def\ermQ{{\textnormal{Q}}}
\def\ermR{{\textnormal{R}}}
\def\ermS{{\textnormal{S}}}
\def\ermT{{\textnormal{T}}}
\def\ermU{{\textnormal{U}}}
\def\ermV{{\textnormal{V}}}
\def\ermW{{\textnormal{W}}}
\def\ermX{{\textnormal{X}}}
\def\ermY{{\textnormal{Y}}}
\def\ermZ{{\textnormal{Z}}}

\def\vzero{{\bm{0}}}
\def\vone{{\bm{1}}}
\def\vmu{{\bm{\mu}}}
\def\vtheta{{\bm{\theta}}}
\def\va{{\bm{a}}}
\def\vb{{\bm{b}}}
\def\vc{{\bm{c}}}
\def\vd{{\bm{d}}}
\def\ve{{\bm{e}}}
\def\vf{{\bm{f}}}
\def\vg{{\bm{g}}}
\def\vh{{\bm{h}}}
\def\vi{{\bm{i}}}
\def\vj{{\bm{j}}}
\def\vk{{\bm{k}}}
\def\vl{{\bm{l}}}
\def\vm{{\bm{m}}}
\def\vn{{\bm{n}}}
\def\vo{{\bm{o}}}
\def\vp{{\bm{p}}}
\def\vq{{\bm{q}}}
\def\vr{{\bm{r}}}
\def\vs{{\bm{s}}}
\def\vt{{\bm{t}}}
\def\vu{{\bm{u}}}
\def\vv{{\bm{v}}}
\def\vw{{\bm{w}}}
\def\vx{{\bm{x}}}
\def\vy{{\bm{y}}}
\def\vz{{\bm{z}}}

\def\evalpha{{\alpha}}
\def\evbeta{{\beta}}
\def\evepsilon{{\epsilon}}
\def\evlambda{{\lambda}}
\def\evomega{{\omega}}
\def\evmu{{\mu}}
\def\evpsi{{\psi}}
\def\evsigma{{\sigma}}
\def\evtheta{{\theta}}
\def\eva{{a}}
\def\evb{{b}}
\def\evc{{c}}
\def\evd{{d}}
\def\eve{{e}}
\def\evf{{f}}
\def\evg{{g}}
\def\evh{{h}}
\def\evi{{i}}
\def\evj{{j}}
\def\evk{{k}}
\def\evl{{l}}
\def\evm{{m}}
\def\evn{{n}}
\def\evo{{o}}
\def\evp{{p}}
\def\evq{{q}}
\def\evr{{r}}
\def\evs{{s}}
\def\evt{{t}}
\def\evu{{u}}
\def\evv{{v}}
\def\evw{{w}}
\def\evx{{x}}
\def\evy{{y}}
\def\evz{{z}}

\def\mA{{\bm{A}}}
\def\mB{{\bm{B}}}
\def\mC{{\bm{C}}}
\def\mD{{\bm{D}}}
\def\mE{{\bm{E}}}
\def\mF{{\bm{F}}}
\def\mG{{\bm{G}}}
\def\mH{{\bm{H}}}
\def\mI{{\bm{I}}}
\def\mJ{{\bm{J}}}
\def\mK{{\bm{K}}}
\def\mL{{\bm{L}}}
\def\mM{{\bm{M}}}
\def\mN{{\bm{N}}}
\def\mO{{\bm{O}}}
\def\mP{{\bm{P}}}
\def\mQ{{\bm{Q}}}
\def\mR{{\bm{R}}}
\def\mS{{\bm{S}}}
\def\mT{{\bm{T}}}
\def\mU{{\bm{U}}}
\def\mV{{\bm{V}}}
\def\mW{{\bm{W}}}
\def\mX{{\bm{X}}}
\def\mY{{\bm{Y}}}
\def\mZ{{\bm{Z}}}
\def\mBeta{{\bm{\beta}}}
\def\mPhi{{\bm{\Phi}}}
\def\mLambda{{\bm{\Lambda}}}
\def\mSigma{{\bm{\Sigma}}}

\DeclareMathAlphabet{\mathsfit}{\encodingdefault}{\sfdefault}{m}{sl}
\SetMathAlphabet{\mathsfit}{bold}{\encodingdefault}{\sfdefault}{bx}{n}
\newcommand{\tens}[1]{\bm{\mathsfit{#1}}}
\def\tA{{\tens{A}}}
\def\tB{{\tens{B}}}
\def\tC{{\tens{C}}}
\def\tD{{\tens{D}}}
\def\tE{{\tens{E}}}
\def\tF{{\tens{F}}}
\def\tG{{\tens{G}}}
\def\tH{{\tens{H}}}
\def\tI{{\tens{I}}}
\def\tJ{{\tens{J}}}
\def\tK{{\tens{K}}}
\def\tL{{\tens{L}}}
\def\tM{{\tens{M}}}
\def\tN{{\tens{N}}}
\def\tO{{\tens{O}}}
\def\tP{{\tens{P}}}
\def\tQ{{\tens{Q}}}
\def\tR{{\tens{R}}}
\def\tS{{\tens{S}}}
\def\tT{{\tens{T}}}
\def\tU{{\tens{U}}}
\def\tV{{\tens{V}}}
\def\tW{{\tens{W}}}
\def\tX{{\tens{X}}}
\def\tY{{\tens{Y}}}
\def\tZ{{\tens{Z}}}


\def\gA{{\mathcal{A}}}
\def\gB{{\mathcal{B}}}
\def\gC{{\mathcal{C}}}
\def\gD{{\mathcal{D}}}
\def\gE{{\mathcal{E}}}
\def\gF{{\mathcal{F}}}
\def\gG{{\mathcal{G}}}
\def\gH{{\mathcal{H}}}
\def\gI{{\mathcal{I}}}
\def\gJ{{\mathcal{J}}}
\def\gK{{\mathcal{K}}}
\def\gL{{\mathcal{L}}}
\def\gM{{\mathcal{M}}}
\def\gN{{\mathcal{N}}}
\def\gO{{\mathcal{O}}}
\def\gP{{\mathcal{P}}}
\def\gQ{{\mathcal{Q}}}
\def\gR{{\mathcal{R}}}
\def\gS{{\mathcal{S}}}
\def\gT{{\mathcal{T}}}
\def\gU{{\mathcal{U}}}
\def\gV{{\mathcal{V}}}
\def\gW{{\mathcal{W}}}
\def\gX{{\mathcal{X}}}
\def\gY{{\mathcal{Y}}}
\def\gZ{{\mathcal{Z}}}

\def\sA{{\mathbb{A}}}
\def\sB{{\mathbb{B}}}
\def\sC{{\mathbb{C}}}
\def\sD{{\mathbb{D}}}
\def\sF{{\mathbb{F}}}
\def\sG{{\mathbb{G}}}
\def\sH{{\mathbb{H}}}
\def\sI{{\mathbb{I}}}
\def\sJ{{\mathbb{J}}}
\def\sK{{\mathbb{K}}}
\def\sL{{\mathbb{L}}}
\def\sM{{\mathbb{M}}}
\def\sN{{\mathbb{N}}}
\def\sO{{\mathbb{O}}}
\def\sP{{\mathbb{P}}}
\def\sQ{{\mathbb{Q}}}
\def\sR{{\mathbb{R}}}
\def\sS{{\mathbb{S}}}
\def\sT{{\mathbb{T}}}
\def\sU{{\mathbb{U}}}
\def\sV{{\mathbb{V}}}
\def\sW{{\mathbb{W}}}
\def\sX{{\mathbb{X}}}
\def\sY{{\mathbb{Y}}}
\def\sZ{{\mathbb{Z}}}

\def\emLambda{{\Lambda}}
\def\emA{{A}}
\def\emB{{B}}
\def\emC{{C}}
\def\emD{{D}}
\def\emE{{E}}
\def\emF{{F}}
\def\emG{{G}}
\def\emH{{H}}
\def\emI{{I}}
\def\emJ{{J}}
\def\emK{{K}}
\def\emL{{L}}
\def\emM{{M}}
\def\emN{{N}}
\def\emO{{O}}
\def\emP{{P}}
\def\emQ{{Q}}
\def\emR{{R}}
\def\emS{{S}}
\def\emT{{T}}
\def\emU{{U}}
\def\emV{{V}}
\def\emW{{W}}
\def\emX{{X}}
\def\emY{{Y}}
\def\emZ{{Z}}
\def\emSigma{{\Sigma}}

\newcommand{\etens}[1]{\mathsfit{#1}}
\def\etLambda{{\etens{\Lambda}}}
\def\etA{{\etens{A}}}
\def\etB{{\etens{B}}}
\def\etC{{\etens{C}}}
\def\etD{{\etens{D}}}
\def\etE{{\etens{E}}}
\def\etF{{\etens{F}}}
\def\etG{{\etens{G}}}
\def\etH{{\etens{H}}}
\def\etI{{\etens{I}}}
\def\etJ{{\etens{J}}}
\def\etK{{\etens{K}}}
\def\etL{{\etens{L}}}
\def\etM{{\etens{M}}}
\def\etN{{\etens{N}}}
\def\etO{{\etens{O}}}
\def\etP{{\etens{P}}}
\def\etQ{{\etens{Q}}}
\def\etR{{\etens{R}}}
\def\etS{{\etens{S}}}
\def\etT{{\etens{T}}}
\def\etU{{\etens{U}}}
\def\etV{{\etens{V}}}
\def\etW{{\etens{W}}}
\def\etX{{\etens{X}}}
\def\etY{{\etens{Y}}}
\def\etZ{{\etens{Z}}}

\newcommand{\pdata}{p_{\rm{data}}}
\newcommand{\ptrain}{\hat{p}_{\rm{data}}}
\newcommand{\Ptrain}{\hat{P}_{\rm{data}}}
\newcommand{\pmodel}{p_{\rm{model}}}
\newcommand{\pratio}{p_{\rm{ratio}}}
\newcommand{\pdatalab}{p_{\rm{labeled}}}
\newcommand{\pdataunlab}{p_{\rm{unlabeled}}}
\newcommand{\Pmodel}{P_{\rm{model}}}
\newcommand{\ptildemodel}{\tilde{p}_{\rm{model}}}
\newcommand{\pencode}{p_{\rm{encoder}}}
\newcommand{\pdecode}{p_{\rm{decoder}}}
\newcommand{\precons}{p_{\rm{reconstruct}}}
\newcommand{\decay}{\eta}

\newcommand{\laplace}{\mathrm{Laplace}} 

\newcommand{\E}{\mathbb{E}}
\newcommand{\Ls}{\mathcal{L}}
\newcommand{\R}{\mathbb{R}}
\newcommand{\emp}{\tilde{p}}
\newcommand{\lr}{\alpha}
\newcommand{\reg}{\lambda}
\newcommand{\rect}{\mathrm{rectifier}}
\newcommand{\softmax}{\mathrm{softmax}}
\newcommand{\sigmoid}{\sigma}
\newcommand{\softplus}{\zeta}
\newcommand{\KL}{D_{\mathrm{KL}}}
\newcommand{\Var}{\mathrm{Var}}
\newcommand{\standarderror}{\mathrm{SE}}
\newcommand{\Cov}{\mathrm{Cov}}
\newcommand{\normlzero}{L^0}
\newcommand{\normlone}{L^1}
\newcommand{\normltwo}{L^2}
\newcommand{\normlp}{L^p}
\newcommand{\normmax}{L^\infty}

\newcommand{\parents}{Pa} 

\DeclareMathOperator*{\argmax}{arg\,max}
\DeclareMathOperator*{\argmin}{arg\,min}

\DeclareMathOperator{\sign}{sign}
\DeclareMathOperator{\Tr}{Tr}
\let\ab\allowbreak
 
\usepackage{hyperref}
\usepackage{url}
\usepackage{booktabs}
\usepackage{algorithm}
\usepackage{algorithmic}
\usepackage{physics}
\usepackage{mathtools}
\usepackage{wrapfig}
\usepackage{todonotes}
\usepackage{xfrac}
\usepackage{caption}
\usepackage{subcaption}


\renewcommand{\theHalgorithm}{\arabic{algorithm}}
\definecolor{mygray}{gray}{0.5}
\renewcommand{\algorithmiccomment}[1]{\;\;\;\textcolor{mygray}{\;\textit{#1}}}
\makeatletter
\newcommand{\algorithmicbreak}{\textbf{break}}
\newcommand{\BREAK}{\STATE \algorithmicbreak}
\makeatother

\DeclareMathOperator{\weakaugment}{WeakAugment}
\DeclareMathOperator{\strongaugment}{StrongAugment}
\DeclareMathOperator{\betadist}{Beta}
\DeclareMathOperator{\guesslabel}{GuessLabel}
\DeclareMathOperator{\onehot}{OneHot}
\DeclareMathOperator{\sharpen}{Sharpen}
\DeclareMathOperator{\normalize}{Normalize}
\DeclareMathOperator{\shuffle}{Shuffle}
\DeclareMathOperator{\concat}{Concat}
\DeclareMathOperator{\uniform}{Uniform}
\DeclareMathOperator{\mixup}{MixUp}
\DeclareMathOperator{\mixmatch}{MixMatch}
\DeclareMathOperator{\remixmatch}{ReMixMatch}
\DeclareMathOperator{\xent}{H}
\DeclareMathOperator{\ent}{\mathcal{H}}
\DeclareMathOperator{\kl}{KL}
\DeclareMathOperator{\rotate}{Rotate}
\DeclareMathOperator{\categorical}{Categorical}


\newcommand*{\myov}[1]{\overbracket[0.8pt][0pt]{#1}}

\DeclarePairedDelimiterX{\infdivx}[2]{(}{)}{#1\;\delimsize|\delimsize|\;#2}
\newcommand{\kld}[2]{\ensuremath{\kl\infdivx{#1}{#2}}\xspace}


\usepackage{cleveref}


\title{ReMixMatch: Semi-Supervised Learning with Distribution Alignment and Augmentation Anchoring}



\author{
  David Berthelot, Nicholas Carlini, Ekin D. Cubuk, Alex Kurakin, Han Zhang, Colin Raffel \\
  Google Research \\
  \texttt{\{dberth,ncarlini,cubuk,kurakin,zhanghan,craffel\}@google.com} \\
  \And
  Kihyuk Sohn \\
  Google Cloud AI \\
  \texttt{kihyuks@google.com}
}




\newcommand{\fix}{\marginpar{FIX}}
\newcommand{\new}{\marginpar{NEW}}

\newif\ifarxiv\arxivtrue
\iclrfinalcopy

\begin{document}


\maketitle
\ifarxiv
\lhead{\footnotesize{ReMixMatch: Semi-Supervised Learning with Distribution Alignment and Augmentation Anchoring}}
\fi

\begin{abstract}

We improve the recently-proposed ``MixMatch'' semi-supervised learning algorithm 
by introducing two new techniques: distribution alignment and augmentation anchoring.
\emph{Distribution alignment} encourages the marginal distribution of predictions on unlabeled data to be close to the marginal distribution of ground-truth labels.
\emph{Augmentation anchoring} feeds multiple strongly augmented versions of an input into the model and encourages each output to be close to the prediction for a weakly-augmented version of the same input.
To produce strong augmentations, we propose a variant of AutoAugment which learns the augmentation policy while the model is being trained.
Our new algorithm, dubbed ReMixMatch, is
significantly more data-efficient than prior work,
requiring between  and  less data to reach the same accuracy.
For example, on CIFAR-10 with 250 labeled examples we reach  accuracy
(compared to MixMatch's accuracy of  with  examples)
and a median accuracy of  with just \textbf{four} labels per class.
We make our code and data open-source at
\texttt{https://github.com/google-research/remixmatch}.

\end{abstract}

\section{Introduction}

Semi-supervised learning (SSL) provides a means of leveraging unlabeled data to improve a model's performance when only limited labeled data is available.
This can enable the use of large, powerful models when labeling data is expensive or inconvenient.
Research on SSL has produced a diverse collection of approaches, including consistency regularization \citep{sajjadi2016regularization,laine2016temporal} which encourages a model to produce the same prediction when the input is perturbed and entropy minimization \citep{grandvalet2005semi} which encourages the model to output high-confidence predictions. 
The recently proposed ``MixMatch'' algorithm \citep{berthelot2019mixmatch} combines these techniques in a unified loss function and achieves strong performance on a variety of image classification benchmarks.
In this paper, we propose two improvements which can be readily integrated into MixMatch's framework.

First, we introduce ``distribution alignment'', which encourages the distribution of a model's aggregated class predictions to match the marginal distribution of ground-truth class labels.
This concept was introduced as a ``fair'' objective by \cite{bridle1992unsupervised}, where a related loss term was shown to arise from the maximization of mutual information between model inputs and outputs.
After reviewing this theoretical framework, we show how distribution alignment can be straightforwardly added to MixMatch by modifying the ``guessed labels'' using a running average of model predictions.

Second, we introduce ``augmentation anchoring'', which replaces the consistency regularization component of MixMatch.
For each given unlabeled input, augmentation anchoring first generates a weakly augmented version (e.g.\ using only a flip and a crop) and then generates multiple strongly augmented versions.
The model's prediction for the weakly-augmented input is treated as the basis of the guessed label for all of the strongly augmented versions.
To generate strong augmentations, we introduce a variant of AutoAugment \citep{cubuk2018autoaugment} based on control theory which we dub ``CTAugment''.
Unlike AutoAugment, CTAugment learns an augmentation policy alongside model training, making it particularly convenient in SSL settings.

We call our improved algorithm ``ReMixMatch'' and experimentally validate it on a suite of standard SSL image benchmarks.
ReMixMatch achieves state-of-the-art accuracy across all labeled data amounts, 
for example achieving an accuracy of  with 250 labels on CIFAR-10 compared to the previous state-of-the-art of  (and compared to  for fully-supervised classification with  labels).
We also push the limited-data setting further than ever before, ultimately achieving a median of  accuracy with only 40 labels (just 4 labels per class) on CIFAR-10.
To quantify the impact of our proposed improvements, we carry out an extensive ablation study to measure the impact of our improvements to MixMatch.
Finally, we release all of our models and code to facilitate future work on semi-supervised learning.

\begin{figure}[t]
\centering
\begin{minipage}{.485\textwidth}
  \centering
  \includegraphics[width=\linewidth]{distribution_matching.pdf}
  \captionof{figure}{Distribution alignment. Guessed label distributions are adjusted according to the ratio of the empirical ground-truth class distribution divided by the average model predictions on unlabeled data.}
  \label{fig:distribution_matching}
\end{minipage}\hfill
\begin{minipage}{.485\textwidth}
  \centering
  \vspace{-1em}
  \includegraphics[width=\linewidth]{augmentation_anchoring.pdf}
  \captionof{figure}{Augmentation anchoring. We use the prediction for a weakly augmented image ({\color{green}green}, middle) as the target for predictions on strong augmentations of the same image ({\color{blue}blue}).}
  \label{fig:augmentation_anchoring}
\end{minipage}
\end{figure}

\section{Background}

The goal of a semi-supervised learning algorithm is to learn from unlabeled data in a way that improves performance on labeled data.
Typical ways of achieving this include training against ``guessed'' labels for unlabeled data or optimizing a heuristically-motivated objective that does not rely on labels.
This section reviews the semi-supervised learning methods relevant to ReMixMatch, with a particular focus on the components of the MixMatch algorithm upon which we base our work.

\paragraph{Consistency Regularization}
Many SSL methods rely on consistency regularization to enforce that the model output remains unchanged when the input is perturbed.
First proposed in \citep{bachman2014learning}, \citep{sajjadi2016regularization} and \citep{laine2016temporal},
this approach was referred to as ``Regularization With Stochastic Transformations and Perturbations'' and the ``-Model'' respectively.
While some work perturbs adversarially \citep{miyato2018virtual} or using dropout \citep{laine2016temporal,tarvainen2017weight}, the most common perturbation is to apply domain-specific data augmentation \citep{laine2016temporal,sajjadi2016regularization,berthelot2019mixmatch,xie2019unsupervised}.
The loss function used to measure consistency is typically either the mean-squared error \citep{laine2016temporal,tarvainen2017weight,sajjadi2016regularization} or cross-entropy \citep{miyato2018virtual,xie2019unsupervised} between the model's output for a perturbed and non-perturbed input.

\paragraph{Entropy Minimization}
\cite{grandvalet2005semi} argues that unlabeled data should be used to ensure that classes are well-separated.
This can be achieved by encouraging the model's output distribution to have low entropy (i.e., to make ``high-confidence'' predictions) on unlabeled data.
For example, one can explicitly add a loss term to minimize the entropy of the model's predicted class distribution on unlabeled data \citep{grandvalet2005semi,miyato2018virtual}.
Related to this idea are ``self-training'' methods \citep{mclachlan1975iterative,rosenberg2005semi} such as Pseudo-Label \citep{lee2013pseudo} that use the predicted class on an unlabeled input as a hard target for the same input, which implicitly minimizes the entropy of the prediction.

\paragraph{Standard Regularization}
Outside of the setting of SSL, it is often useful to regularize models in the over-parameterized regime.
This regularization can often be applied both when training on labeled and unlabeled data.
For example, standard ``weight decay'' \citep{hinton1993keeping} where the  norm of parameters is minimized is often used alongside SSL techniques.
Similarly, powerful MixUp regularization \citep{zhang2017mixup} which trains a model on linear interpolants of inputs and labels has recently been applied to SSL \citep{berthelot2019mixmatch,verma2019interpolation}.

\paragraph{Other Approaches}
The three aforementioned categories of SSL techniques does not cover the full literature on semi-supervised learning.
For example, there is a significant body of research on ``transductive'' or graph-based semi-supervised learning techniques which leverage the idea that unlabeled datapoints should be assigned the label of a labeled datapoint if they are sufficiently similar \citep{gammerman1998learning,joachims2003transductive,joachims1999transductive,bengio2006label,liu2018deep}.
Since our work does not involve these (or other) approaches to SSL, we will not discuss them further.
A more substantial overview of SSL methods is available in \citep{chapelle2006semi}.

\subsection{MixMatch}

MixMatch \citep{berthelot2019mixmatch} unifies several of the previously mentioned SSL techniques.
The algorithm works by generating ``guessed labels'' for each unlabeled example, and then
using fully-supervised techniques to train on the original labeled data along with
the guessed labels for the unlabeled data.
This section reviews the necessary details of MixMatch; see \citep{berthelot2019mixmatch} for a full definition.

Let  be a batch of labeled data and their corresponding one-hot labels representing one of  classes and let  be augmented versions of these labeled examples.
Similarly, let  be a batch of unlabeled examples.
Finally, let  be the predicted class distribution produced by the model for input .

MixMatch first produces  weakly augmented versions of each unlabeled datapoint  for .
Then, it generates a ``guessed label''  for each  by computing the average prediction  across the  augmented versions: .
The guessed label distribution is then sharpened by adjusting its temperature (i.e. raising all probabilities to a power of \sfrac{1}{T} and renormalizing).
Finally, pairs of examples  from the combined set of labeled examples and unlabeled examples with label guesses are fed into the MixUp \citep{zhang2017mixup} algorithm to compute examples  where
 for , and similarly for .
Given these mixed-up examples, MixMatch performs standard fully-supervised training
with minor modifications.
A standard cross-entropy loss is used for labeled data, whereas the loss for unlabeled data is computed using a mean square error (i.e.\ the Brier score \citep{brier1950verification}) and is weighted with a hyperparameter .
The terms  (number of augmentations),  (sharpening temperature),  (MixUp  parameter), and  (unlabeled loss weight) are MixMatch's hyperparameters.
For augmentation, shifting and flipping was used for the CIFAR-10, CIFAR-100, and STL-10 datasets, and shifting alone was used for SVHN.

\section{ReMixMatch}


\begin{algorithm*}[t]
        \caption{ algorithm for producing a collection of processed labeled examples and processed unlabeled examples with label guesses (cf.\ \cite{berthelot2019mixmatch} Algorithm 1.)}
   \label{alg:remixmatch}
\begin{algorithmic}[1]
   \footnotesize
   \STATE {\bfseries Input:} Batch of labeled examples and their one-hot labels , batch of unlabeled examples , sharpening temperature , number of augmentations ,  distribution parameter  for .
   \FOR{ \TO }
   \STATE  \COMMENT{\textit{Apply strong data augmentation to }} \\
   \STATE  \COMMENT{\textit{Apply strong data augmentation  times to }} \\
   \STATE  \COMMENT{\textit{Apply weak data augmentation to }} \\
   \STATE  \COMMENT{\textit{Compute prediction for weak augmentation of }} \\
   \STATE  \COMMENT{\textit{Apply distribution alignment}} \\
   \STATE  \COMMENT{\textit{Apply temperature sharpening to label guess}} \label{line:sharpen} \\
   \ENDFOR
   \STATE  \COMMENT{\textit{Augmented labeled examples and their labels}} \label{line:hat_x} \\
   \STATE  \COMMENT{\textit{First strongly augmented unlabeled example and guessed label}} \\
   \STATE  \COMMENT{\textit{All strongly augmented unlabeled examples}} \label{line:hat_u} \\
   \STATE  \COMMENT{\textit{Add weakly augmented unlabeled examples}} \label{line:tilde_u} \\
   \STATE  \COMMENT{\textit{Combine and shuffle labeled and unlabeled data}} \label{line:w} \\
   \STATE  \COMMENT{Apply \textit{ to labeled data and entries from }} \label{line:x_prime} \\
   \STATE  \COMMENT{\textit{Apply  to unlabeled data and the rest of }} \label{line:u_prime} \\
\RETURN , 
\end{algorithmic}
\end{algorithm*}

Having introduced MixMatch, we now turn to the two improvements we propose in this paper: Distribution alignment and augmentation anchoring.
For clarity, we describe how we integrate them into the base MixMatch algorithm; the full algorithm for ReMixMatch is shown in \cref{alg:remixmatch}.

\subsection{Distribution Alignment}

Our first contribution is \textit{distribution alignment}, which enforces that the aggregate of predictions on unlabeled data matches the distribution of the provided labeled data.
This general idea was first introduced over 25 years ago \citep{bridle1992unsupervised}, but to the best of our knowledge is not used in modern SSL techniques.
A schematic of distribution alignment can be seen in \cref{fig:distribution_matching}.
After reviewing and extending the theory, we describe how it can be straightforwardly included in ReMixMatch.

\subsubsection{Input-Output Mutual Information}

As previously mentioned, the primary goal of
an SSL algorithm is to incorporate unlabeled data in a way which improves a model's performance.
One way to formalize this intuition, first proposed by \cite{bridle1992unsupervised},
is to maximize the mutual information between the model's input and output for unlabeled data.
Intuitively, a good classifier's prediction should depend as much as possible on the input.
Following the analysis from \cite{bridle1992unsupervised}, we can formalize this objective as


where  refers to the entropy. See Appendix A for a proof.
To interpret this result, observe that 
the second term in \cref{eqn:firm_but_fair} is the familiar entropy minimization objective \citep{grandvalet2005semi}, which simply encourages each individual model output to have low entropy (suggesting high confidence in a class label).
The first term, however, is not widely used in modern SSL techniques.
This term (roughly speaking) encourages that on average, 
across the entire training set, the model predicts each class with equal frequency.
\cite{bridle1992unsupervised} refer to this as the model being ``fair''.


\subsubsection{Distribution Alignment in ReMixMatch}

MixMatch already includes a form of entropy minimization via the ``sharpening'' operation which makes the guessed labels (synthetic targets) for unlabeled data have lower entropy.
We are therefore interested in also incorporating a form of ``fairness'' in ReMixMatch.
However, note that the objective  on its own essentially implies that the model should predict each class with equal frequency.
This is not necessarily a useful objective if the dataset's marginal class distribution  is not uniform.
Furthermore, while it would in principle be possible to directly minimize this objective on a per-batch basis, we are instead interested in integrating it into MixMatch in a way which does not introduce an additional loss term or any sensitive hyperparameters.

To address these issues, we incorporate a form of fairness we call ``distribution alignment'' which proceeds as follows:
over the course of training, we maintain a running average of the model's predictions on unlabeled data, which we refer to as .
Given the model's prediction  on an unlabeled example , we scale  by the ratio  and then renormalize the result to form a valid probability distribution: 

where .
We then use  as the label guess for , and proceed as usual with sharpening and other processing.
In practice, we compute  as the moving average of the model's predictions on unlabeled examples over the last  batches.
We also estimate the marginal class distribution  based on the labeled examples seen during training.
Note that a better estimate for  could be used if it is known a priori; in this work we do not explore this direction further.

\subsection{Improved Consistency Regularization}

Consistency regularization underlies most SSL methods \citep{miyato2018virtual,tarvainen2017weight,berthelot2019mixmatch,xie2019unsupervised}.
For image classification tasks, consistency is typically enforced between two augmented versions of the same unlabeled image.
In order to enforce a form of consistency regularization, MixMatch generates  (in practice, ) augmentations of each unlabeled example  and averages them together to produce a ``guessed label'' for .

Recent work \citep{xie2019unsupervised} found that applying stronger forms of augmentation can significantly improve the performance of consistency regularization.
In particular, for image classification tasks it was shown that using variants of AutoAugment \citep{cubuk2018autoaugment} produced substantial gains.
Since MixMatch uses a simple flip-and-crop augmentation strategy, we were interested to see if replacing the weak augmentation in MixMatch with AutoAugment would improve performance but found that training would not converge.
To circumvent this issue, we propose a new method for consistency regularization in MixMatch called ``Augmentation Anchoring''.
The basic idea is to use the model's prediction for a weakly augmented unlabeled image as the guessed label for many strongly augmented versions of the same image.

A further logistical concern with using AutoAugment is that it uses reinforcement learning to learn a policy which requires many trials of supervised model training.
This poses issues in the SSL setting where we often have limited labeled data.
To address this, we propose a variant of AutoAugment called ``CTAugment'' which adapts itself online using ideas from control theory without requiring any form of reinforcement learning-based training.
We describe Augmentation Anchoring and CTAugment in the following two subsections.

\subsubsection{Augmentation Anchoring}

We hypothesize the reason MixMatch with AutoAugment is unstable is that MixMatch averages the prediction across  augmentations.
Stronger augmentation can result in disparate predictions, so their average may not be a meaningful target.
Instead, given an unlabeled input we first generate an ``anchor'' by applying weak augmentation to it.
Then, we generate  strongly-augmented versions of the same unlabeled input using CTAugment (described below).
We use the guessed label (after applying distribution alignment and sharpening) as the target for all of the  strongly-augmented versions of the image.
This process is visualized in \cref{fig:augmentation_anchoring}.

While experimenting with Augmentation Anchoring, we found it enabled us to replace MixMatch's unlabeled-data mean squared error loss with a standard cross-entropy loss.
This maintained stability while also simplifying the implementation.
While MixMatch achieved its best performance at only , we found that augmentation anchoring benefited from a larger value of .
We compare different values of  in \cref{sec:experiments} to measure the gain achieved from additional augmentations.

\subsubsection{Control Theory Augment} 
\label{sec:ctaugment}
AutoAugment \citep{cubuk2018autoaugment} is a method for learning a data augmentation policy which results in high validation set accuracy.
An augmentation policy consists a sequence of transformation-parameter magnitude tuples to apply to each image.
Critically, the AutoAugment policy is learned with supervision: 
the magnitudes and sequence of transformations are determined
via training many models on a proxy task which e.g.\ involves the use of  labels on
CIFAR-10 and  labels on SVHN \citep{cubuk2018autoaugment}.
This makes applying AutoAugment methodologically problematic for low-label SSL.
To remedy this necessity for training a policy on labeled data,
RandAugment \citep{cubuk2019randaugment} uniformly randomly samples transformations,
but requires tuning the hyper-parameters for the random sampling on the validation set,
which again is methodologically difficult when only very few (e.g., 40 or 250)
labeled examples are available.

Thus, in this work, we develop CTAugment, an alternative approach to designing high-performance augmentation strategies.
Like RandAugment, CTAugment also uniformly randomly samples transformations to apply but dynamically infers magnitudes for each transformation during the training process.
Since CTAugment does not need to be optimized on a supervised proxy task and has no sensitive hyperparameters, we can directly include it in our semi-supervised models to experiment with more aggressive data augmentation in semi-supervised learning.   
Intuitively, for each augmentation parameter, CTAugment learns the likelihood that it will produce an image which is classified as the correct label.
Using these likelihoods, CTAugment then only samples augmentations that fall within the network tolerance.
This process is related to what is called density-matching in Fast AutoAugment \citep{lim2019fast}, where policies are optimized so that the density of augmented validation images match the density of images from the training set. 

First, CTAugment divides each parameter for each transformation into bins of distortion magnitude as is done in AutoAugment (see Appendix C for a list of the bin ranges).
Let  be the vector of bin weights for some distortion parameter for some transformation.
At the beginning of training, all magnitude bins are initialized to have a weight set to .
These weights are used to determine which magnitude bin to apply to a given image.

At each training step, for each image two transformations are sampled uniformly at random.
To augment images for training, for each parameter of these transformations we produce a modified set of bin weights  where  if  and  otherwise, and sample magnitude bins from .
To update the weights of the sampled transformations, we first sample a magnitude bin  for each transformation parameter uniformly at random.
The resulting transformations are applied to a labeled example  with label  to obtain an augmented version .
Then, we measure the extent to which the model's prediction matches the label as .
The weight for each sampled magnitude bin is updated as  where  is a fixed exponential decay hyperparameter.


\subsection{Putting it all together}

ReMixMatch's algorithm for processing a batch of labeled and unlabeled examples is shown in \cref{alg:remixmatch}.
The main purpose of this algorithm is to produce the collections  and , consisting of augmented labeled and unlabeled examples with  applied.
The labels and label guesses in  and  are fed into standard cross-entropy loss terms against the model's predictions.
\Cref{alg:remixmatch} also outputs , which consists of a single heavily-augmented version of each unlabeled image and its label guesses \emph{without MixUp applied}.
 is used in two additional loss terms which provide a mild boost in performance in addition to improved stability:

\paragraph{Pre-mixup unlabeled loss} We feed the guessed labels and predictions for example in  as-is into a separate cross-entropy loss term.

\paragraph{Rotation loss} Recent result have shown that applying ideas from self-supervised learning to SSL can produce strong performance \citep{gidaris2018unsupervised,zhai2019s}.
We integrate this idea by rotating each image  as  where we sample the rotation angle  uniformly from  and then ask the model to predict the rotation amount as a four-class classification problem.


In total, the ReMixMatch loss is



\paragraph{Hyperparameters} ReMixMatch introduce two new hyperparameters: 
the weight on the rotation loss  and
the weight on the un-augmented example .
In practice both are fixed 
.
ReMixMatch also shares many hyperparameters from MixMatch:
the weight for the unlabeled loss ,
the sharpening temperature ,
the MixUp Beta parameter,
and the number of augmentations .
All experiments (unless otherwise stated) use , Beta , and .
We found using a larger number of augmentations monotonically
increases accuracy, and so set  for all experiments (as running
with  augmentations increases computation by a factor of ).

We train our models using Adam
\citep{kingma2014adam} with a fixed learning rate of 0.002 and weight decay \citep{zhang2018three} with a
fixed value of .
We take the final model as an exponential moving average over the trained model weights
with a decay of .




\section{Experiments}
\label{sec:experiments}

We now test the efficacy of ReMixMatch on a set of standard semi-supervised learning
benchmarks. 
Unless otherwise noted, all of the experiments performed in this section
use the same codebase and model architecture (a Wide ResNet-28-2 \citep{zagoruyko2016wide} with 1.5 million parameters, as used in \citep{oliver2018realistic}).

\subsection{Realistic SSL setting}

We follow the Realistic Semi-Supervised Learning \citep{oliver2018realistic} recommendations for
performing SSL evaluations.
In particular, as mentioned above, this means we use the same model and training
algorithm in the same codebase for all experiments.
We compare against VAT \citep{miyato2018virtual} and MeanTeacher \citep{tarvainen2017weight}, copying the re-implementations
over from the MixMatch codebase \citep{berthelot2019mixmatch}.


\paragraph{Fully supervised baseline}
To begin, we train a fully-supervised baseline to measure the highest
accuracy we could hope to obtain with our training pipeline.
The experiments we perform use the same model
and training algorithm, so these baselines are valid for all discussed SSL techniques.
On CIFAR-10, we obtain an fully-supervised error rate of  using weak flip + crop augmentation, which drops to  using AutoAugment and  using CTAugment.
Similarly, on SVHN we obtain  error using weak (flip) augmentation and  and  using AutoAugment and CTAugment respectively.
While AutoAugment performs slightly better on CIFAR-10 and slightly worse on SVHN compared to CTAugment, it is not our intent to design a \emph{better} augmentation
strategy; just one that can be used \emph{without a pre-training or tuning of hyper-parameters}.


\paragraph{CIFAR-10}
Our results on CIFAR-10 are shown in \cref{tab:realistic_ssl}, left.
ReMixMatch sets the new state-of-the-art for all numbers of
labeled examples.
Most importantly,
ReMixMatch is  more data efficient than MixMatch (e.g., at  labeled
examples ReMixMatch has identical accuracy compared to MixMatch at ).

\paragraph{SVHN} 
Results for SVHN are shown in \cref{tab:realistic_ssl}, right.
ReMixMatch reaches state-of-the-art at  labeled examples,
and within the margin of error for state-of-the-art otherwise.

\begin{table}[h]
    \centering
    \footnotesize
    \begin{tabular}{lrrrrrr}
    \toprule
        & \multicolumn{3}{c}{CIFAR-10} & \multicolumn{3}{c}{SVHN} \\
        \cmidrule(l{3pt}r{3pt}){1-1} \cmidrule(l{3pt}r{3pt}){2-4}  \cmidrule(l{3pt}r{3pt}){5-7}
        Method & 250 labels & 1000 labels & 4000 labels & 250 labels & 1000 labels & 4000 labels \\
        \cmidrule(l{3pt}r{3pt}){1-1} \cmidrule(l{3pt}r{3pt}){2-4}  \cmidrule(l{3pt}r{3pt}){5-7}
        VAT &  36.032.82 & 18.640.40 & 11.050.31 &  8.411.01 & 5.980.21 & 4.200.15 \\
        Mean Teacher  & 47.324.71 & 17.324.00 & 10.360.25 &  6.452.43 & 3.750.10 & 3.390.11 \\
        MixMatch & 11.080.87 & 7.750.32 & 6.240.06 & 3.780.26 & 3.270.31 & 2.890.06 \\
        ReMixMatch & 6.270.34 & 5.730.16 & 5.140.04 &  3.100.50 & 2.830.30 & 2.420.09 \\
        \cmidrule(l{3pt}r{3pt}){1-1} \cmidrule(l{3pt}r{3pt}){2-4}  \cmidrule(l{3pt}r{3pt}){5-7}
        UDA, reported* & 8.760.90 & 5.870.13 & 5.290.25 & 2.760.17 & 2.550.09 & 2.470.15 \\
        \bottomrule
    \end{tabular}
    \caption{Results on CIFAR-10 and SVHN.
    * For UDA, due to adaptation difficulties, we report the results from \cite{xie2019unsupervised} which are not comparable to our results due to a different network implementation, training procedure, etc.
    For VAT, Mean Teacher, and MixMatch, we report results using our reimplementation, which makes them directly comparable to ReMixMatch's scores.
    }
    \label{tab:realistic_ssl}
\end{table}

\subsection{STL-10}

The STL-10 dataset consists of  labeled  color images
drawn from 10 classes and  unlabeled images drawn from a similar---but not identical---data distribution.
The labeled set is partitioned into ten pre-defined folds of  images
each. For efficiency, we only run our analysis on five of these ten folds.
We do not perform evaluation here under the Realistic SSL \citep{oliver2018realistic} setting when
comparing to non-MixMatch results.
Our results are, however, directly comparable to the MixMatch results.
Using the same WRN-37-2 network (23.8 million parameters), we reduce the error rate by a factor of two compared to MixMatch.

\begin{table}[h]
    \centering
    \footnotesize
    \begin{minipage}{.37\linewidth}
    \begin{tabular}{lr}
    \toprule
      Method & Error Rate \\
      \midrule
SWWAE &  \\CC-GAN  &  \\MixMatch &  \\ \midrule
      ReMixMatch (K=1) &  \\ReMixMatch (K=4) &  \\\bottomrule
    \end{tabular}
    \caption{STL-10 error rate using -label splits. SWWAE and CC-GAN results are from \citep{zhao2015stacked} and \citep{denton2016semi}.} \label{tab:stl10}
    \end{minipage}\hfill \begin{minipage}{.6\linewidth}
    \centering
    \begin{tabular}{lrlr}
    \toprule
        Ablation & Error Rate & Ablation & Error Rate \\
        \midrule
        ReMixMatch &  & No rotation loss &  \\
        With K=1 &  & No pre-mixup loss &  \\
        With K=2 &  & No dist. alignment &  \\
        With K=4 &  & L2 unlabeled loss &  \\
        With K=16 &  & No strong aug. &  \\
        MixMatch &  & No weak aug. &  \\
        \bottomrule
    \end{tabular}
    \caption{Ablation study. Error rates are reported on a single 250-label split from CIFAR-10.}
    \label{tab:ablation}
    \end{minipage}
\end{table}


\subsection{Towards few-shot learning}

We find that ReMixMatch is able to work in extremely low-label
settings. By only changing  from  to  we
can train CIFAR-10 with just \textbf{four} labels 
per class and SVHN with only  labels total.
On CIFAR-10 we obtain a median-of-five error rate of ;
on SVHN we reach  error and
on SVHN with the ``extra'' dataset we reach  error.
Full results are given in Appendix B.

\subsection{Ablation Study}

Because we have made several changes to the existing MixMatch algorithm,
here we perform an ablation study and remove one component of ReMixMatch
at a time to understand from which changes produce the largest accuracy gains.
Our ablation results are summarized in Table~\ref{tab:ablation}.
We find that removing the pre-mixup unlabeled loss, removing distribution alignment, and lowering  all hurt performance by a small amount.
Given that distribution alignment improves performance, we were interested to see whether it also had the intended effect of making marginal distribution of model predictions match the ground-truth marginal class distribution.
We measure this directly in \cref{sec:dm_kl}.
Removing the rotation loss reduces accuracy at  labels by only  percentage points, but we find that in the 40-label setting rotation loss is necessary to prevent collapse.
Changing the cross-entropy loss on unlabeled data to an L2 loss as used in MixMatch hurts performance dramatically, as does removing either of the augmentation components.
This validates using augmentation anchoring in place of the consistency regularization mechanism of MixMatch.

\section{Conclusion}

Progress on semi-supervised learning over the past year has upended many of the
long-held beliefs about classification, namely, that vast quantities of
labeled data is necessary.
By introducing augmentation anchoring and distribution alignment to MixMatch, we continue this trend:
ReMixMatch reduces the quantity of labeled data needed by a large factor compared to prior work  
(e.g., beating MixMatch at 4000 labeled
examples with only 250 on CIFAR-10, and closely approaching MixMatch at 5000 labeled examples
with only 1000 on STL-10).
In future work, we are interested in pushing the limited data regime further to close the gap between few-shot learning and SSL.
We also note that in many real-life scenarios, a dataset begins as unlabeled and is incrementally labeled until satisfactory performance is achieved.
Our strong empirical results suggest that it will be possible to achieve gains in this ``active learning'' setting by using ideas from ReMixMatch.
Finally, in this paper we present results on widely-studied image benchmarks for ease of comparison.
However, the true power of data-efficient learning will come from applying these techniques to real-world problems where obtaining labeling data is expensive or impractical.


\bibliography{iclr2020_conference}
\bibliographystyle{iclr2020_conference}

\appendix

\newpage
\section{Proof of Equation \ref{eqn:firm_but_fair}}
The proof here follows closely \cite{bridle1992unsupervised}. 
We begin with the definition


\section{Full 40 label results}
We now report the full results for running ReMixMatch with
just 40 labeled examples. We sort the table by error rate
over five different splits (i.e., 40-label subsets) of the
training data.
High variance is to be expected when choosing so few labeled examples at random.

\begin{table}[h!]
\centering
\begin{tabular}{lrrrrr}
\toprule
Dataset & \multicolumn{5}{c}{Split (ordered by error rate)} \\
 & 1 & 2 & 3 & 4 & 5 \\ 
\midrule
CIFAR-10 & 10.88 & 12.65 & 15.08 & 16.78 & 19.49 \\
SVHN & 3.43 & 3.46 & 3.48 & 4.06 & 12.24 \\
SVHN+extra & 2.59 & 2.71 & 2.81 & 3.50 & 15.14 \\
\bottomrule
\end{tabular}
\caption{Sorted error rate of ReMixMatch with 40 labeled examples.}
\end{table}

\newpage
\section{Transformations included in CTAugment}
\label{sec:ctaugment_bins}
\begin{table}[h!]
\begin{tabular}{lp{7cm}lp{2cm}}
    \toprule
Transformation             & Description    & Parameter &         Range \\
\midrule
Autocontrast &Maximizes the image contrast by setting the darkest (lightest) pixel to black (white), and then blends with the original image with blending ratio .&           &      [0, 1]                          \\
Blur         &&           &                                 \\
Brightness   &Adjusts the brightness of the image.  returns a black image,  returns the original image.&&[0, 1]\\
Color        &Adjusts the color balance of the image like in a TV.  returns a black \& white image,  returns the original image.&&[0, 1]                \\
Contrast     &Controls the contrast of the image. A  returns a gray image,  returns the original image.& &[0, 1] \\
Cutout       &Sets a random square patch of side-length (image width) pixels to gray.&&[0, 0.5] \\
Equalize     &Equalizes the image histogram, and then blends with the original image with blending ratio .&&[0, 1]\\
Invert       &Inverts the pixels of the image, and then blends with the original image with blending ratio .&&[0, 1]\\
Identity     &Returns the original image. &           &                                  \\
Posterize    &Reduces each pixel to  bits. &&[1, 8] \\
Rescale      &Takes a center crop that is of side-length (image width), and rescales to the original image size using method .&&[0.5, 1.0] \\           &&&see caption\\
Rotate       &Rotates the image by  degrees.&     & [-45, 45]      \\
Sharpness    &Adjusts the sharpness of the image, where  returns a blurred image, and  returns the original image.&&[0, 1]\\
Shear\_x     &Shears the image along the horizontal axis with rate .&         & [-0.3, 0.3]     \\
Shear\_y     &Shears the image along the vertical axis with rate .&          & [-0.3, 0.3]     \\
Smooth       &Adjusts the smoothness of the image, where  returns a maximally smooth image, and  returns the original image.&&[0, 1]\\
Solarize     &Inverts all pixels above a threshold value of .        &           & [0, 1]    \\
Translate\_x &Translates the image horizontally by (image width) pixels.  &    &[-0.3, 0.3]\\
Translate\_y &Translates the image vertically by (image width) pixels.  &    &[-0.3, 0.3]\\
\bottomrule
\end{tabular}
\caption{The ranges for all of the listed parameters are discretized into 17 equal bins. The only exception is the  parameter of the Rescale transformation, which takes on one of the following six options: anti-alias, bicubic, bilinear, box, hamming, and nearest.}   
\end{table}

\section{Measuring the effect of distribution alignment}
\label{sec:dm_kl}

Recall that the goal of distribution alignment is to encourage the marginal distribution of the model's predictions  to match the true marginal class distribution .
To measure whether distribution alignment indeed has this effect, we monitored the KL divergence between  and  over the course of training.
We show the KL divergence for a training run on CIFAR-10 with 250 labels with and without distribution alignment in \cref{fig:distribution_alignment_kl}.
Indeed, the KL divergence between  and  is significantly smaller throughout training.

\begin{figure}
    \centering
    \includegraphics[width=0.6\textwidth]{distribution_matching_kl.pdf}
    \caption{KL divergence between the marginal distribution of model predictions vs.\ the true marginal distribution of class labels over the course of training with and without distribution alignment.
    This figure corresponds to a training run on CIFAR-10 with 250 labels.
    }
    \label{fig:distribution_alignment_kl}
\end{figure}


\section{CTAugment parameters effects}
In this section we compare the effects of varying the CTAugment hyper-parameters on CIFAR10 with 250 labels, using the standard ReMixMatch settings.
The exponential weight decay  does not effect the results significantly while depth and threshold have significant effects.
The default settings are highlighted in the table. 
They appear to perform well and have been shown to be robust across many datasets in our previous experiments.

\begin{table}[h!]
\centering
\begin{tabular}{rrrr}
\toprule
Depth & Threshold &  & Error rate \\
\midrule
1 & 0.80 & 0.99 & 23.90 \\
2 & 0.80 & 0.99 & \textbf{6.25} \\
3 & 0.80 & 0.99 & 6.36 \\
\midrule
2 & 0.50 & 0.99 & 10.51 \\
2 & 0.80 & 0.99 & \textbf{6.25} \\
2 & 0.90 & 0.99 & 10.80 \\
2 & 0.95 & 0.99 & 18.47 \\
\midrule
2 & 0.80 & 0.9 & 6.15 \\
2 & 0.80 & 0.99 & \textbf{6.25} \\
2 & 0.80 & 0.999 & 6.02 \\
\bottomrule
\end{tabular}
\caption{Effects of hyper-parameters for CTAugment, the bold results are the default settings used for all experiments.}
\end{table}

\end{document}