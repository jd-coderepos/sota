\section{Experiments and Results}
In this section, we first describe our experiment setup in Sec. \ref{Dataset_decp} \& Sec. \ref{section:Archiecture and Implementation}). We conduct a systematic analysis of the behavior of video-SSL models in vanilla FL settings in Sec. \ref{sec:vanilla}, followed by a discussion for the results of our proposed FedVSSL in Sec. \ref{sec:propose}.

\subsection{Datasets}
\label{Dataset_decp}
For the pretraining stages of all video-SSL approaches, we utilize kinetics-400 (K400) dataset \cite{kay2017kinetics} with k training samples distributed among  action classes. For downstream task, we utilize the UCF-101 \cite{soomro2012ucf101} (UCF) dataset containing  video samples for 101 action classes, and HMDB-51 \cite{Kuehne11} (HMDB) dataset with k video samples distributed among 51 action classes.

\noindent\textbf{Kinectics-400 Non-IID.} Each video sample in K400 comes from a different source, which conforms to the definition of non-IID based on video source-level. To make it more realistic, we generate the non-IID version of K400 based on actual class-labels \cite{mcmahan2017communication}. 
We randomly partition the dataset into 100 shards to mimic the setting of having 100 disjoint clients participating in FL. Each client contains  classes resulting in each client having  samples on average. Note that there is no overlap of samples between different clients. 


\subsection{Architecture and Implementation}
\label{section:Archiecture and Implementation}
\textbf{Video-SSL Approaches.} In this work, we consider three SOTA video-SSL algorithms, all of which propose to solve different pretext tasks for video representation learning. More specifically, VCOP~\cite{xu2019self} learns to determine the permutation order of shuffled clips, Speed~\cite{benaim2020speednet,yao2020video,cho2021self} learns to predict the playback speed of videos, and CtP~\cite{wang2021unsupervised} predicts the positions and sizes of a synthetic image patch in a sequence of video frames. 
For all video-SSL approaches, we use R3D-18 \cite{tran2018closer} architecture as the backbone ). The architecture choices of prediction heads for different pretext tasks and downstream tasks follow the settings in the original papers. It should be noted that our federated framework is agnostic to different architectures and video-SSL approaches. We develop the FL version of the video-SSL approaches considered in this work on top of Flower \cite{beutel2020flower} federated learning platform by incorporating various video-SSL algorithms developed in MMCV framework \cite{mmcv,wang2021unsupervised}.     
Unless otherwise specified, we keep the settings of the video-SSL approaches as provided by \cite{wang2021unsupervised} during the pretraining tasks and downstream tasks. 


\noindent \textbf{FL Pretraining.} We perform the FL pretraining of the video-SSL pretext-task  using Algo. \ref{al1}. The local pretraining on each client lasts for  epochs per FL round , where we set  in our experiments. 
We set the total number of rounds R to  to ensure that each client acquires sufficient participation during FL pretraining.
The selection of the number of  and  is based on our empirical observations. Each round, we randomly select  clients from the pool of 100 clients to participate in training and each client trains its local model using SGD optimizer without momentum. We set a constant learning rate of  for CtP and Speed and  for VCOP. Weight decay is set to  and training batch-size is set to 4. On the server side, in addition to our proposed method FedVSSL, we consider three existing aggregation strategies including FedAvg, Loss and FedU.
 
\noindent \textbf{Downstream Tasks.} For the fine-tuning stage of action recognition, we follow the configuration in CtP framework \cite{wang2021unsupervised}. The  is fine-tuned using the SGD optimizer with an initial learning rate of , momentum of , and weight decay of . The learning rate is decayed by a factor of  after  and  epochs, respectively. The batch-size is set , and the fine-tuning stage lasts for 150 epochs. For linear probe, we keep the same settings as for the fine-tuning of the whole network, except that we train only  layer of  for  epochs. The learning rate is decayed by the factor of  after  and  epochs. For the video clip retrieval task, we follow the approach described in Sec. \ref{sec:method_sys}.

\setlength{\tabcolsep}{2pt}
\begin{table}[t]
    \caption{\small Action recognition accuracy (Top-1\%) and video clip retrieval accuracy (Top-1\%, Top5\%) on UCF and HMDB for three video-SSL methods. F-T represents fine-tune and L-P stands for linear probe.  represents the difference between centralized and corresponding FL performance.``" and ``" show \% improvement and degradation respectively.  means the results are reproduced using the implementation in \cite{wang2021unsupervised}}
    \label{Tab-action_recog_comp}
    \centering
    \scalebox{0.85}{
    \begin{tabular}{l cccc cccc}
    \toprule
     & \multicolumn{4}{c}{\textbf{Action Recognition}} & \multicolumn{4}{c}{\textbf{Video Clip Retrieval}}\\
   \cmidrule(r){2-5} \cmidrule(r){6-9}
      & \multicolumn{2}{c}{UCF} & \multicolumn{2}{c}{HMDB} & \multicolumn{2}{c}{UCF} &  \multicolumn{2}{c}{HMDB}\\
      \cmidrule(r){2-3} \cmidrule(r){4-5} \cmidrule(r){6-7} \cmidrule(r){8-9}
     \textbf{SSL Method} & F-T & L-P & F-T & L-P & R@1 & R@5 & R@1 & R@5\\ 
     \cmidrule(r){1-9}
    VCOP* & 71.29 & 24.93 & 38.56 & 13.53 &  15.52 & 28.26 & 8.11 & 22.22  \\
     VCOP(Fed)& 69.26 &  20.00 & 33.27 & 12.22 &  13.72 & 24.85 & 6.41 & 19.94  \\
     & (-2.03) & (-4.93) &(-5.29) &(-1.31) &(-1.8) & (-3.41) & (-1.7) & (-2.28) \\
    \cmidrule(r){1-9}
    Speed*  & 81.15 & 29.32 & 47.58 & 14.90  & 16.84 & 36.58  & 6.93 & 21.05 \\
    Speed(Fed)  & 73.16 & 35.63& 38.43 & 21.57 & 21.97 & 41.61 & 10.98 & 28.30 \\
     & (-7.99) &  (+6.31) & (-9.05) & (+6.67) & (+4.05) & (+3.94) & (+3.92) & (+7.25) \\
    \cmidrule(r){1-9}
    CtP*  & \textbf{86.20} & \textbf{48.14} & \textbf{57.00} & \textbf{30.65} & 29.0 & 47.30 & 11.80 & 30.10  \\
    CtP(Fed) & 81.95 & 46.13& 49.15 & 28.63 & \textbf{29.29} & \textbf{48.90} & \textbf{13.66} & \textbf{32.42} \\
     & (-4.25) & (-2.01) & (-7.85) & (-2.02) & (+0.29) & (+1.6) & (+1.86) & (+2.32) \\
    \bottomrule
   \end{tabular}
   }
\end{table}


\subsection{Video-SSL in Vanilla FL Settings}
\label{sec:vanilla}
Here we investigate the performance of video-SSL in vanilla FL settings against the key factors listed in Sec.\ref{sec:method_sys}. 

\noindent \textbf{Centralized vs. Federated Video-SSL.} In this experiment, we draw a first investigation for the performance of video-SSL approaches using FedAvg in centralized and vanilla FL settings with Non-IID video data. We report this comparison in terms of three downstream tasks, i.e, fine-tuning, linear probe, video clip retrieval, on UCF and HMDB datasets (Table \ref{Tab-action_recog_comp}).
First, CtP obtains the best performance for all tasks in both centralized and FL settings.
Second, when the trained network is fine-tuned for the action recognition task, the centralized video-SSL approaches perform better compared to their corresponding FL counterparts. However, the degradation in the performance is not drastic. We conjecture that it is caused by the smoother and flatter manifold in the models in FL settings, which would be more challenging to fine-tune.
Third, the linear-probe results for action recognition show mixed results due to the fact that only the classification head participates in the training.
Finally, the video clip retrieval results are more competitive with the FL version of Speed and CtP, which achieve better performance than their centralized counterparts.

Given the fact that the video-SSL benefits from the large-scale datasets and the performance degradation of the FL version of the video-SSL is acceptable (even in the Non-IID case with FedAvg), it makes the FL a natural choice for video-SSL approaches. 

\begin{table}[t]
    \caption{\small Action recognition and video clip retrieval accuracies (\%) on UCF and HMDB for the federated CtP models pretrained with one local epoch per round. C represents the number of clients, and Cpc stands for the number of classes per client} 
    \label{Tab-ablation_action}
    \centering
    \scalebox{0.85}{
    \begin{tabular}{lcccc cccc}
        \toprule
&  & & \multicolumn{2}{c}{\textbf{Fine-tuning}} & \multicolumn{4}{c}{\textbf{Retrieval}}  \\
        \cmidrule(r){4-5} \cmidrule(r){6-9}
        & & & UCF & HMDB & \multicolumn{2}{c}{UCF} & \multicolumn{2}{c}{HMDB}\\
        \cmidrule(r){4-4} \cmidrule(r){5-5} \cmidrule(r){6-7} \cmidrule(r){8-9}
       \textbf{Method} & \textbf{C/Cpc} & \textbf{Data}  & Top-1 & Top-1 & R@1 & R@5 & R@1 & R@5 \\
        \cmidrule(r){1-9}
        \multirow{4}{4em}{CtP(Fed.)} & 100/- & IID & 81.92 & 48.49 & 29.42 & 47.90 & 13.80 & 34.56\\ 
& 100/8 & Non-IID & 81.95 & 49.15 & 29.29 & 48.90 &  13.66 & 32.42\\
& 100/4 & Non-IID & 81.15 & 47.78 & 29.18 & 48.37 & 14.70 & 32.94 \\
\hline
        CtP(Cent.) & - & IID & 86.2 & 57.00 & 29.00 & 47.30 & 11.80 & 30.10 \\
        \bottomrule
    \end{tabular}
    }
\end{table}

\noindent \textbf{Performance with IID vs. Non-IID Data.} Conventional FL methods are designed to solve a supervised/semi-supervised learning task within an IID/Non-IID data distribution based on the actual class-labels. 
To understand the impact of data distribution on federated video-SSL training, we simulate IID and Non-IID settings based on class-labels and compare the performance of downstream task in Table \ref{Tab-ablation_action}. 
The Non-IID versions of K-400 are generated with two variations of the distribution of the samples among 100 clients, with 4 and 8 classes per client respectively.
We report the fine-tuning and video clip retrieval accuracy on UCF and HMDB, by pretraining CtP video-SSL approach on all settings.

One can see from Table \ref{Tab-ablation_action} that pretraining the CtP video-SSL approach using standard FedAvg with IID and different degrees of Non-IID levels achieve comparatively similar performance on the fine-tuning and video clip retrieval task.
This could be explained by the generation process of IID/Non-IID data based the actual class-labels. The video-SSL methods learn representations by generating pseudo labels based on the pretext task it solves, which is independent of actual class-labels. Hence, the IID/Non-IID data distribution has a slight impact to the SSL model training.
In addition, we find that there exists a degradation in the fine-tuning performance of federated CtP video-SSL compared to its centralized counterpart. Interestingly, the FL version of CtP video-SSL approach gives better video clip retrieval performance when compared to its centralized counterpart with both IID and different degrees of Non-IID levels.

\noindent \textbf{Performance of Aggregation Strategies.} The aggregation method often plays an important role towards superior performance of models trained in FL environments. 
In this experiment, we investigate the impact of FL aggregation strategies on the pretraining by evaluating the final performance of video-SSL approaches in Non-IID FL settings. In Table \ref{Tab-action_finetune_adam}, we show the performance of CtP video-SSL approach on UCF and HMDB against a range of aggregation strategies that include FedAvg \cite{mcmahan2017communication}, Loss \cite{gao2021end}, and FedU \cite{zhuang2021collaborative}. 
It can be observed that FedAvg performs better on HMDB and obtains similar performance with Loss method on UCF. Additionally, except for retrieval accuracy on HMDB, FedU outperforms others on both video clip retrieval and fine-tuning mainly due to its dynamic aggregation mechanism. 

\setlength{\tabcolsep}{1.7pt}
\begin{table}[t]
\begin{center}
    \caption{\small Video clip retrieval accuracies (\%) and fine-tuning accuracies (\%) on UCF and HMDB for CtP video-SSL approach using various aggregation strategies. The SSL pretraining is performed on K400 (Non-IID).
    Cent represents the centralized training for  epochs which equals to  rounds in our FL setting } 
    \label{Tab-action_finetune_adam}
    \scalebox{0.85}{
    \begin{tabular}{l cccc cc}
    \toprule
      & \multicolumn{4}{c}{\textbf{Retrieval}} & \multicolumn{2}{c}{\textbf{Fine-tuning}} \\
     \cmidrule(r){2-5} \cmidrule(r){6-7}
      & \multicolumn{2}{c}{UCF} & \multicolumn{2}{c}{HMDB} & UCF & HMDB \\
   \cmidrule(r){2-3} \cmidrule(r){4-5} \cmidrule(r){6-6} \cmidrule(r){7-7} 
    \textbf{Method} &  R@1 & R@5 & R@1 & R@5 & Top-1 & Top-1 \\
     \cmidrule(r){1-7}
Centralized & 29.00 & 47.3 & 11.80 & 30.1 & 86.20 & 57.00 \\
      Centralized & 27.65 & 47.67 & 12.81 & 31.05 & 83.64 & 53.73 \\
       \cmidrule(r){1-7}
FedAvg (Baseline) & 32.62 & 50.41 & \textbf{16.54} & 35.29 & 79.91 & 52.88 \\
      Loss-based &  32.54 & 50.01 & 14.44 &  34.97 & 79.43 & 50.63  \\
      FedU &   \textbf{34.07} & \textbf{52.29} & 14.90 & \textbf{36.67} & \textbf{80.17} & \textbf{53.73} \\
     \bottomrule
    \end{tabular}
    }
\end{center}
\end{table}


\noindent \textbf{Loss Surface and Model Stability of Video-SSL in FL.}
To understand why the federated video-SSL models gain higher retrieval accuracy than centralized models, we further analyze the loss landscape around the pretrained model both in centralized and FL settings. To compute this, we utilize the filter normalization method as proposed in \cite{li2018visualizing}. The results are shown in Fig. \ref{fig:cent_loss_surf} for CtP video-SSL approach. We find that the loss landscape of model pretrained with FedAvg is flatter than the model pretrianed with the centralized video-SSL. 
The width of the optima is critically related to generalization, which enables the model to converge in a point centered in this region \cite{izmailov2018averaging,keskar2016large,hochreiter1997flat}. This often leads to slightly worse training loss but substantially better test accuracy.


We then explore whether such wider optima could increase model stability against small perturbations. To achieve this, we perturb the weights of the backbone pretrained with centralized and federated video-SSL approach. The perturbations are sampled from a uniform normal distribution with zero mean and unit variance, i.e., . We start with the perturbation level of  and incrementally increase the level of perturbation by a factor of , i.e., (). 
The results are shown in Fig. \ref{fig:perturb_fed_vs_cent} for the top-1\% video clip retrieval accuracy for the centralized video-SSL approach and its corresponding FL counterparts, on UCF and HMDB datasets. 
One can see from that as the level of perturbation is increased from 0 to 0.1 the top-1\% accuracy drops significantly for both centralized CtP video-SSL and its FL counterparts. However, as the level for perturbation is further increased we find that the FL versions of the video-SSL approach show good stability compared to its centralized counterpart on both datasets. Overall, the federated training boosts the generalization and stability of video-SSL models. 

\begin{figure}[t]
    \centering
    \begin{subfigure}{0.3\textwidth}
    \centering
    \includegraphics[width=\linewidth]{figures/loss_landscape/ctp_centralized_pretext_visualize_3dsurface.png}
\end{subfigure}\begin{subfigure}{0.3\textwidth}
    \centering
    \includegraphics[width=\linewidth]{figures/loss_landscape/ctp_5c1e540r_federated_visualize_3dsurface.png}
\end{subfigure}

    \caption{\small Loss landscape of the final  pretrained in a centralized(left) and FL with FedAvg(right) settings}
\label{fig:cent_loss_surf}
\end{figure}

\begin{figure}[pt]
    \centering
    
     \begin{subfigure}{0.5\textwidth}
    \centering
    \includegraphics[width=\linewidth]{figures/LINEAR_PERTURB_FEDVSSL.png}\\
\end{subfigure}\begin{subfigure}{0.5\textwidth}
    \centering
    \includegraphics[width=\linewidth]{figures/LINEAR_PERTURB_HMDB_FEDVSSL.png}
\end{subfigure}
    \caption{\small Top1\% action retrieval accuracy on UCF and HMDB by adding perturbation to all the weights of the pretrained  network. The perturbation is sampled from a normal distribution  and multiplied by a factor }
    \label{fig:perturb_fed_vs_cent}
\end{figure}

\noindent \textbf{Training  Efficiency and Communication Cost.} In this experiment, we analyze the computational efficiency of pretraining CtP approach in both FL and centralized settings. We find that our FL pretraining of CtP for  rounds, with  clients and  client sampling rate (in ideal scenarios), is equivalent to  epochs () of centralized pretraining. This results in  of GPU time saving compared to the centralized pretraining of the CtP that lasts for  epochs. Additionally, compared with the performance of centralized pretraining of CtP for  epochs, our federated CtP model achieves significant boost in video clip retrieval performance while providing competitive performance on fine-tuning as shown in Table \ref{Tab-action_finetune_adam}. 
We further show the number of communication rounds required by federated video-SSL models to achieve the centralized target video clip retrieval accuracy. 
One can see from Fig. \ref{fig:comm_vs_no_rounds} that the FL model trained with FedAvg requires less than  rounds to reach the centralized target accuracy on UCF and HMDB datasets. Indeed, our proposed FedVSSL shows even better better performance and convergence behaviour.


\begin{figure}[pt]
    \centering
\begin{subfigure}{0.5\textwidth}
    \centering
    \includegraphics[width=0.9\linewidth]{figures/comm_vs_acc_ucf_wo_moment_stabilityBK.png}\\
\end{subfigure}\begin{subfigure}{0.5\textwidth}
    \centering
    \includegraphics[width=0.9\linewidth]{figures/comm_vs_acc_hmdb_wo_moment_stabilityBK.png}
\end{subfigure}
    \caption{\small Top  retrieval accuracy () w.r.t communication rounds for our proposed FL methods on UCF(left) and HMDB (right).  Our proposed methods require less than 200 rounds to reach the centralized target accuracy on both datasets}
    \label{fig:comm_vs_no_rounds}
\end{figure}




\subsection{Results on FedVSSL}
\label{sec:propose}

In this section, we investigate the performance of our proposed FVSSL method, conduct ablation studies by varying  and  in Eq. \ref{eq:SWA} and Eq. \ref{eq:weighted_comb}, and report the results on UCF and HMDB in Table \ref{Tab-proposed}. One can see that the performance of all proposed methods are competitive, which demonstrates that the learned representations are qualified for the downstream applications.


\begin{figure}[h]
    \centering
    \includegraphics[width=0.7\linewidth]{figures/weight_diff_wo_moment_std.png}
    \caption{\small Standard deviations of the  difference between the global model weights and the locally trained model weights at each round of FL video-SSL pretraining with FedAvg. Both backbone  and prediction head  are aggregated on the server}
    \label{fig:std_divergence}
\end{figure}

\begin{table}[h]
\begin{center}
    \caption{\small Video clip retrieval accuracies (\%) and fine-tuning accuracies (\%) on UCF101 and HMDB51 for CtP video-SSL approach using our proposed FedVSSL methods. The SSL pretraining is performed on K400 (Non-IID)} 
    \label{Tab-proposed}
    \scalebox{0.85}{
    \begin{tabular}{l cccc cc cc}
    \toprule
      & \multicolumn{4}{c}{\textbf{Retrieval}} & \multicolumn{2}{c}{\textbf{Fine-tuning}} & \multicolumn{2}{c}{\textbf{Linear-probe}} \\
      \cmidrule(r){2-5} \cmidrule(r){6-7} \cmidrule(r){8-9}
      & \multicolumn{2}{c}{UCF} & \multicolumn{2}{c}{HMDB} & UCF & HMDB & UCF & HMDB \\
    \cmidrule(r){2-3} \cmidrule(r){4-5} \cmidrule(r){6-6} \cmidrule(r){7-7} \cmidrule(r){8-8} \cmidrule(r){9-9}
    \textbf{Method} &  R@1 & R@5 & R@1 & R@5 & Top-1 & Top-1 & Top-1 & Top-1 \\
     \cmidrule(r){1-9}
      Centralized & 29.00 & 47.3 & 11.80 & 30.1 & 86.20 & 57.00 & 48.14 & 30.65 \\
     \cmidrule(r){1-9}
     FedAvg (Baseline) & 32.62 & 50.41 & 16.54 & 35.29 & 79.91 & 52.88 & 45.31 & 31.44 \\
     FedVSSL() & 34.34 & 51.71 & 15.82 & 36.01 & 79.91 & 52.94 & 47.95 & 31.12 \\
     FedVSSL()& 34.23 & 52.21 & 16.73& \textbf{38.30} & 79.14 & 51.11 & 47.90 & 29.48 \\
     FedVSSL() &  35.61 & 52.18 & \textbf{16.93} & 37.78 & 79.43 & 51.90 & 47.66 & 30.00 \\
     FedVSSL()& \textbf{35.66} & 52.34 & 16.41 & 36.93 & 78.99 & 51.18 & 48.93 & 31.44 \\
     FedVSSL()&  35.50 & \textbf{54.27} & 16.27& 37.25 & \textbf{80.62} & \textbf{53.14} & \textbf{50.36} & \textbf{32.68} \\
     FedVSSL()&  35.34 & 52.34 & \textbf{16.93}& 37.39 & 79.41 & 51.50 & 50.30 & 32.42 \\
     \bottomrule
    \end{tabular}
    }
\end{center}
\end{table}

First, all models trained with FedVSSL provide superior retrieval performance.
Concretely, (FedVSSL with ) we improve the video clip retrieval performance over FedAvg baseline by  (top) and  (top) on UCF, and  (top) on HMDB. We obtained  and  improvement (top1\%) in the category of fine-tuning  on UCF and HMDB, respectively compared to FedAvg baseline. In the category of Linear-probe, we obtained  and  improvement (top1\%) on UCF and HMDB, respectively compared to the FedAvg baseline.  
Second, the component of SWA ()in FedVSSL has a distinct benefit on the improvement of retrieval performance. 
Third, the top-1\% retrieval accuracy of FedVSSL() outperforms the FedAvg baseline by  on UCF dataset, which highlights the benefits of only updating backbone. 


One can see from Fig. \ref{fig:std_divergence} that the standard deviation of the  distance for the backbone model parameter is more consistent throughout the FL pretraining compared to that of prediction model parameters. This indicates that the backbone weights cause less divergence in FL pretraining of video-SSL which may provide significant efficiency and performance boost in the FL scenarios with stringent communication budget. 

    



