\documentclass[final]{dmtcs-episciences}

\usepackage[utf8]{inputenc}
\usepackage{subfigure}
\usepackage[round]{natbib}

\usepackage{amssymb}
\usepackage{amsmath}
\usepackage{latexsym}
\usepackage{verbatim}
\usepackage{amsfonts}
\usepackage{latexsym}
\usepackage{xcolor}
\usepackage{url}
\usepackage{algorithm}
\usepackage{algorithmic}


\newcommand{\per}{{per}}
\newcommand{\lper}{{lper}}
\newcommand{\minper}{{\bf minper}}
\newcommand{\nat}{{\mathbb{N}}}
\newcommand{\ident}{\bf{1}}
\newcommand{\bigo}{{\mathcal O}}
\def\ur{\uparrow}
\def\xor{{\bf\ xor\ }}
\newcommand{\ra}{\rightarrow}
\renewcommand{\alph}{\mbox{alph}}
\renewcommand{\lg}{\log}
\newcommand{\eps}{\epsilon}
\newcommand{\LCP}{{\mathit{LCP}}}
\newcommand{\LCSuf}{{\mathit{LCS}}}
\newcommand{\LPF}{{\mathit{LPrF}}}
\newcommand{\LPdF}{{\mathit{LPF}}}
\newcommand{\LP}{{\mathit{LPal}}_\alpha}
\newcommand{\LR}{{\mathit{LRep}}_\alpha}
\newcommand{\lmp}{{\mathit{LPnF}}}

\newtheorem{remark}{Remark}
\newtheorem{lemma}{Lemma}
\newtheorem{problem}{Problem}
\newtheorem{theorem}{Theorem}

\author{Marius Dumitran\affiliationmark{1} \and Pawe\l{} Gawrychowski\affiliationmark{2} \and Florin Manea\affiliationmark{3}}
\title[Longest Gapped Repeats and Palindromes]{Longest Gapped Repeats and Palindromes
\thanks{This is an extension of the conference papers of \cite{fct}, presented at the 20th International Symposium on
Fundamentals of Computation Theory, FCT 2015, and of \cite{mfcs}, presented at the 40th International Symposium on
Mathematical Foundations of Computer Science, MFCS 2015.}}
\affiliation{
  Faculty of Mathematics and Computer Science, University of Bucharest \\
  Institute of Computer Science, University of Wroc\l{}aw\\
  Department of Computer Science, Kiel University}
\keywords{combinatorial pattern matching, gapped repeats, gapped palindromes}
\received{2015-11-24}
\revised{2016-10-12, 2017-9-25}
\accepted{2017-10-3}

\begin{document}
\publicationdetails{19}{2017}{4}{4}{1337}
\maketitle
\begin{abstract}
A gapped repeat (respectively, palindrome) occurring in a word  is a factor  (respectively, ) of . In such a repeat (palindrome)  is called the arm of the repeat (respectively, palindrome), while  is called the gap. 
We show how to compute efficiently, for every position  of the word , the longest gapped repeat and palindrome occurring at that position, provided that the length of the gap is subject to various types of restrictions. That is, that for each position  we compute the longest prefix  of  such that  (respectively, ) is a suffix of  (defining thus a gapped repeat  -- respectively, palindrome ), and the length of  is subject to the aforementioned restrictions.
\end{abstract}

\section{Introduction}
Gapped repeats and palindromes have been investigated for a long time (see, e.g., \cite{Gu97,Brodal,KK_SPIRE,KK09,KolpakovPPK14,power_of_SA,Cro2011} and the references therein), with motivation coming especially from the analysis of DNA and RNA structures, where tandem repeats or hairpin structures play important roles in revealing structural and functional information of the analysed genetic sequence (see \cite{Gu97,Brodal,KK09} and the references therein). 

A gapped repeat (respectively, palindrome) occurring in a word  is a factor  (respectively, ) of . The middle part  of such a structure is called gap, while the two factors  (respectively, the factors  and ) are called left and right arms. Generally, the previous works were interested in finding all the gapped repeats and palindromes, under certain numerical restrictions on the length of the gap or on the relation between the length of the arm of the repeat or palindrome and the length of the gap.

A classical problem for palindromes asks to find the longest palindromic factor of a word (see, \cite{Manacher}). This is our first inspiration point in proposing an alternative point of view in the study of gapped repeats and palindromes. As a second inspiration point for our work, we refer to the longest previous factor table (LPF) associated to a word. This data structure was introduced and considered in the context of efficiently computing Lempel-Ziv-like factorisations of words (see \cite{IlieLPF,power_of_SA}). Such a table provides for each position  of the word the longest factor occurring both at position  and once again on a position . Several variants of this table were also considered by \cite{power_of_SA}: the longest previous reverse factor (), where we look for the longest factor occurring at position  and whose mirror image occurs in the prefix of  of length , or the longest previous non-overlapping factor, where we look for the longest factor occurring both at position  and somewhere inside the prefix of length  of . Such tables may be seen as providing a comprehensive image of the long repeats and symmetries occurring in the analysed word. 

According to the above, in our work we approach the construction of longest previous gapped repeat or palindrome tables: for each position  of the word we want to compute the longest factor occurring both at position  and once again on a position  (or, respectively, whose mirror image occurs in the prefix of length  of ) such that there is a gap (subject to various restrictions) between  and the previous occurrence of the respective factor (mirrored factor). Similar to the original setting, this should give us a good image of the long gapped repeats and symmetries of a~word.

A simple way to restrict the gap is to lower bound it by a constant; i.e., we look for factors  (or ) with  for some . The techniques of~\cite{power_of_SA} can be easily adapted to compute for each position  the longest prefix  of  such that there exists a suffix  (respectively, ) of , forming thus a factor  (respectively, ) with . Here we consider three other different types of restricted gaps.

We first consider the case when the length of the gap is between a lower bound  and an upper bound , where  and  are given as input (so, may depend on the input word). This extends naturally the case of lower bounded~gaps. 
\begin{problem}\label{LPFgG}
Given  of length  and two integers  and , such that , construct the arrays  and  defined for :
\begin{itemize} 
\item[a.]  there exists  such that  is a suffix of  and  is prefix of , with .
\item[b.] there exists  such that  is a suffix of  and  is prefix of , with .
\end{itemize}
\end{problem}
We are able to solve Problem \ref{LPFgG}(a) in linear time . Problem \ref{LPFgG}(b)  is solved here in  time. Intuitively, in the case of gapped palindromes, when trying to compute the longest prefix  of  such that  is a suffix of  with , we just have to compute the longest common prefix between  and the words  with . The increased difficulty in solving the problem for repeats (reflected in the increased complexity of our algorithm) seems to come from the fact that when trying to compute the longest prefix  of  such that  is a suffix of  with , it is hard to see where the  factor may start, so we have to somehow try more variants for the length of . \cite{Brodal} give an algorithm that finds all maximal repeats (i.e., repeats whose arms cannot be extended) with gap between a lower and an upper bound, running in  time, where  is the number of such repeats. It is worth noting that there are words (e.g., , from \cite{Brodal}) that may have  maximal repeats  with . Hence, for  and , for instance, our algorithm is faster than an approach that would first use the algorithms of \cite{Brodal} to get all maximal repeats, and then process them somehow to solve Problem \ref{LPFgG}(b). 

The data structures we construct allow us to trivially find in linear time the longest gapped palindrome having the length of the gap between  and , and in  time the longest gapped repeat with the length of the gap between the bounds  and .  

In the second case, the gaps of the repeats and palindromes we investigate are only lower bounded; however, the bound on the gap allowed at each position is defined by a function depending on the~position.
\begin{problem}\label{LPFg(i)}
Given  of length  and the values  of , construct the arrays  and  defined for :
\begin{itemize}
\item[a.]  there exists  such that  is a suffix of  and  is prefix of , with .
\item[b.]  there exists  such that  is a suffix of  and  is prefix of , with .
\end{itemize}
\end{problem}
The setting of this problem can be seen as follows. An expert preprocesses the input word (in a way specific to the framework in which one needs this problem solved), and detects the length of the gap occurring at each position (so, computes  for all ). These values and the word are then given to us, to compute the arrays defined in our problems. We solve both problems in linear time. Consequently, we can find in linear time the longest gapped palindrome or repeat whose gap fulfils the length restriction defined by the position where this palindrome or repeat occurs (as above).

Finally, following \cite{KK09,KolpakovPPK14}, we analyse gapped repeats  or palindromes  where the length of the gap  is upper bounded by the length of the arm  multiplied by some factor. More precisely, \cite{KolpakovPPK14} investigate {\em -gapped repeats}: words  with . Similarly, \cite{KK09} analyse {\em -gapped palindromes}, i.e., words  with .  For , these structures are called long armed repeats (or pairs) and palindromes, respectively; for , they are squares and palindromes of even length, respectively. Intuitively, one is interested in repeats or palindromes whose arms are roughly close one to the other; therefore, the study of -gapped repeats and palindromes was rather focused on the cases with small . Here, we address the general case, of searching in a word  -gapped repeats or palindromes for .

\begin{problem}\label{LLAP}
Given   of length  and a number , construct the arrays  and , defined for :
\begin{itemize}
\item[a.] there exists  such that  is a suffix of  is a prefix of , and .
\item[b.] there exists  such that  is a suffix of  is a prefix of , and and .
\end{itemize}
\end{problem}

The problem of constructing the set  of all factors of a word of length  which are maximal -gapped repeats of palindromes (i.e., the arms cannot be extended simultaneously with one symbol to the right or to the left to get a longer similar structure) was thoroughly considered, and finally settled by \cite{CroKolKu2015,STACS2016} (see also the references therein). In both these papers, it is shown that the number of -gapped repeats or palindromes a word of length  may contain is . Using as starting point the algorithm presented in \cite{fct}, that finds the longest -gapped repeat or palindrome (without constructing the set of all such structures), \cite{STACS2016} give an algorithm finding all maximal -gapped repeats and -gapped palindromes in optimal time .  Here, we first present the algorithm of \cite{fct} for the identification of the longest -gapped repeat or palindrome contained in a word, and briefly explain how it was extended to output all maximal -gapped repeats and palindromes in a word. Then we use the algorithm of \cite{STACS2016} and a linear time algorithm finding the longest square/palindrome centred at each position of a word to solve Problem~\ref{LLAP} in linear time. 

Our algorithms are generally based on efficient data-structures. On one hand, we use efficient word-processing data structures like suffix arrays, longest common prefix structures, or dictionaries of basic factors. On the other hand, we heavily use specific data-structures for maintaining efficiently collections of disjoint sets, under union and find ope\-rations. Alongside these data-structures, we make use of a series of remarks of combinatorial nature, providing insight in the repetitive structure of the words. 

\section{Preliminaries}
The computational model we use to design and analyze our algorithms is the standard unit-cost RAM with logarithmic word size, which is generally used in the analysis of algorithms. In this model, the memory word size is logarithmic in the size of the input. 

Let  be a finite alphabet;  denotes the set of all finite words over . In the upcoming algorithmic problems, we assume that the words we process are sequences of integers (i.e., over integer alphabets). In general, if the input word has length  then we assume its letters are in , so each letter fits in a single memory-word. This is a common assumption in stringology (see, e.g., the discussion by \cite{KaSaBu06}).

The \emph{length} of a word  is denoted by . The \emph{empty word} is denoted by . 
A word  is a \emph{factor} of  if , for some ; we say that  is a \emph{prefix} of , if , and a \emph{suffix} of , if 
We denote by  the symbol occurring at position  in  and by  the factor of  starting at position  and ending at position  consisting of the catenation of the symbols  where ; we define  if . The powers of a word  are defined recursively by  and   for . 
If  cannot be expressed as a nontrivial power (i.e.,  is not a repetition) of another word, then  is \emph{primitive}. 
A \emph{period} of a word  over  is a positive integer  such that  for all  and  with . Let  be the smallest~period~of~. A word  with  is called periodic; a periodic  (with ) is a run if it cannot be extended to the left or right to get a word with the same period , i.e.,  or ,
and,  or . \cite{KK99} showed that the number of runs of a word is linear and their list (with a run  represented as the triple ) can be computed in linear time.
The exponent of a run  occurring in  is defined as ; the sum of the exponents of all runs in a word of length  is  (see \cite{KK99}). 

For a word , , over  we build in  time the suffix array as well as data structures allowing us to retrieve in constant time the length of the longest common prefix of any two suffixes  and 
of , denoted  (the subscript  is omitted when there is no danger of confusion). Such structures are called  data structures in the following. For details, see, e.g., \cite{KaSaBu06,Gu97}, and the references therein. In the solutions of the problems dealing with gapped palindromes inside a word  (Problems \ref{LPFgG}(a), \ref{LPFg(i)}(a), and \ref{LLAP}(a)) we construct the suffix array and  data structures for 
the word , where  is a new symbol lexicographically smaller than all the symbols of ; this takes  time. To check whether  occurs at position  in  (respectively,  occurs at position  in ) we check whether  and  (respectively, ). To keep the notation free of subscripts, when we measure the longest common prefix of a word  and word  we write , and this is in fact an -query on ; when we measure the longest common prefix of a word  and word  we write , and this is in fact an -query on .

The suffix array of  allows us to construct in linear time a list  of the suffixes  of  and of the mirror images  of the prefixes of  (which correspond to the suffixes of length less than  of ), ordered lexicographically. Generally, we denote by  the position of  in the ordered list  of these factors, and by  the position of  in . 

The dictionary of basic factors (introduced by~\cite{DBF}) of a word  (DBF for short) is a data structure that labels the factors  (called basic factors), for  and , such that every two identical factors of  get the same label and we can retrieve~the~label of any basic factor in  time. The DBF of a word of length  is constructed in  time. 

Note that a basic factor  occurs either at most twice in any factor  or the occurrences of  in  form a run of period  (so the corresponding positions where  occurs in  form an arithmetic progression of ratio , see~\cite{KociumakaSPIRE2012}). Hence, the occurrences of   in  can be presented in a compact manner: either at most two positions, or the starting position of the progression and its ratio. For , the occurrences of the basic factor  in  can be also presented in a compact manner: the positions (at most ) where  occurs isolated (not inside a run) and/or at most  maximal runs that contain the overlapping occurrences of , each run having period .

\begin{figure}\begin{center}
\includegraphics[width=\linewidth]{basic_factors.pdf}
\end{center}
\vspace*{-2.5cm}
\caption{Occurrences of the basic factors  in . The overlapping occurrences are part of runs, and they can be returned as the pair formed of the first occurrence of  from each run and the period of . The representation of the occurrences of  in  will return  elements:  runs and one separate occurrence.}
\end{figure}

\begin{remark}\label{rem_DBF}
Using the DBF of a word  of length , given a number  we can produce in  time a data structure answering the following type of queries in  time: ``Given  and  return the compact representation of the occurrences of the basic factor  inside the basic factor ''. Similarly, given  and a constant  (e.g., ), we can produce in  time a data structure answering the following type of queries in  time: ``Given  and  return the compact representation of the occurrences of the basic factor  in  ''. 

Indeed, once we construct the dictionary of basic factors of , we reorganise it such that for each distinct basic factor we have an array with all the positions where it occurs, ordered increasingly. Now, we traverse each such array, keeping track of the current occurrence  and a window containing its occurrences from the range between  and  (and a compact representation of these occurrences); when we move in our traversal of this array to the next occurrence of the current basic factors, we also slide the window in the array, and, looking at the content of the previous window and keeping track of the occurrences that were taken out and those that were added to its content, we can easily obtain in constant time a representation of the occurrences of the considered basic factors inside the new window. 
\end{remark}

The previous remark is extended by the following lemma in a more general setting:  is no longer a constant, and in a query we look, this time, for the occurrences of a basic factor  in factors , where there is no relation between  and . 
\begin{lemma}\label{find_occ_range}
Given a word  of length  and a number , we can preprocess  in time  such that given any basic factor  and any factor , with , we can compute in  time a compact representation of all the occurrences of  in .
\end{lemma}
\begin{proof}
We construct the dictionary of basic factors of a word of length  in  time and reorganise it such that for each basic factor we have an array with all its occurrences, ordered by their starting positions. For each such array we construct data structures that allow predecessor/successor search in  time with linear time preprocessing w.r.t. its length (see, e.g., \cite{Boas75}). When we have to return the occurrences of  in , we search in the basic factors-array corresponding to  the successor of  and, respectively, the predecessor of  and then return a compact representation of the occurrences of  between these two values. This representation can be obtained in  time. We just have to detect those occurrences that form a run; this can be done with a constant number of  queries. Indeed, for two consecutive occurrences, we compute the length of their overlap, which gives us a period of . Then we look in  to see how long can the run with this period be extended to the right, which gives us the number of occurrences of   in that run. As their starting positions form an arithmetic progression, we can represent them compactly. So, we return the representation of the occurrences of  from this run, and then move directly to the first occurrence of  appearing after this run and still in the desired range; as there are at most  runs and separate occurrences of the given basic factor in the desired range, the conclusion follows.
\end{proof}

In the following we make use of a result by \cite{Gawrychowski11}, where it is shown that one can also construct data structures that allow the fast identification of the suffixes of a word that start with a given basic factor.
\begin{lemma}(\cite{Gawrychowski11})\label{find_node}
A word  of length  can be processed in  time such that given any basic factor , with , we can retrieve in  time the range of the suffix array of  of suffixes starting with . Equivalently, we can find the node of the suffix tree of  closest to the root, such that the label of the path from the root to that node has the prefix .
\end{lemma}
We can now show the following lemma. 
\begin{lemma}\label{find_occ_small}
Given a word , , we can process  in time  time such that given any basic factor , with  and , we can find in  time  bit-sets, each storing  bits, characterising all the occurrences of  in .
\end{lemma}
\begin{proof}
We first show how the proof works for . 

We first build the suffix tree for  in  time (see~\cite{Farach97}). We further process this suffix tree such that we can find in constant time, for each factor , the node of the suffix tree which is closest to the root with the property that the label of path from the root to it starts with . According to Lemma \ref{find_node}, this can be done in linear time. 

Now, we augment the suffix tree in such a manner that for each node we store an additional bit-set, indicating the positions of  where the word labelling the path from the root to the respective node occurs. Each of these bit-sets, of size , can be stored in constant space; indeed, each  block of bits from the bit-set can be seen in fact as a number between  and  so we only need to store a constant number of numbers smaller than ; in our model, each such number fits in a memory word. Computing the bit-sets can be done in a bottom up manner in linear time: for a node, we need to make the union of the bit-sets of its children, and this can be done by doing a bitwise {\bf or} operation between all the bit-sets corresponding to the children. So, now, checking the bit-set associated to the lowest node of the suffix tree such that the label of the path from the root to that node starts with  we can immediately output a representation of this factor's occurrences in .

This concludes the proof for . 

For , we just have to repeat the algorithm in the previous proof for the words , for , which allows us to find all the occurrences of the basic factors of  in . The time is clearly . 

\end{proof}


Note that each of the bit-sets produced in the above lemma can be stored in a constant number of memory words in our model of computation. Essentially, this lemma states that we can obtain in  time a representation of size  of all the occurrences of  in . 

\begin{remark}\label{find_occ_small_range}
By Lemma \ref{find_node}, given a word , ,  and a basic factor , with  and , we can produce  bit-sets, each containing exactly  bits, characterising all the occurrences of  in . Let us also assume that we have access to all values  with  (which can be ensured by a  preprocessing). Now, using the bit-sets encoding the occurrences of  in  and given a factor  of ,  for some , we can obtain in  time the occurrences of  in : the positions (at most ) where  occurs outside a run and/or at most  runs containing the occurrences of . Indeed, the main idea is to select by bitwise operations on the bit-sets encoding the factors of  that overlap  the positions where  occurs (so the positions with an ). For each two consecutive such occurrences of  we detect whether they are part of a run in  (by -queries on ) and then skip over all the occurrences of  from that run (and the corresponding parts of the bit-sets) before looking again for the -bits in the bit-sets.
 \end{remark}

Some of our solutions rely on an efficient solution for the \emph{disjoint set union-find} problem. This problem asks to maintain a family consisting initially of  disjoint singleton sets from the universe  (shorter for ) so that given any element we can locate its current set and return the minimal (and/or the maximal) element of this set (operation called {\em find-query}) and we can merge two disjoint sets into one (operation called {\em union}). In our framework, we know from the beginning the pairs of elements whose corresponding sets can be joined. Under this assumption, a data-structure fulfilling the above requirements can be constructed in  time such that performing a sequence of  find and union operations takes  time in the computation model we use (see \cite{Gabow83}). As a particular case, this data structure solves with  preprocessing time and  amortised time per operation the \emph{interval union-find} problem, which asks to maintain a partition of the universe  into a number of  disjoint intervals, so that given an element of  we can locate its current interval, and we can merge two adjacent intervals of the partition. 

\begin{remark}\label{weighted_tree}As a first consequence of the algorithms of \cite{Gabow83}, we recall a folklore result, stating that we can process in  time a weighted tree with  nodes and all weights in  so that we can compute off-line, also in linear time, the answer to  weighted level ancestor queries on the nodes of this tree (where such a query asked for the first node on a path from a given node to the root such that the sum of the weights of the edges between the given and the returned node is greater than a given weight). 
\end{remark}

In the solutions of both tasks of Problem \ref{LPFgG}, we use the following variant of the interval union-find problem.
\begin{remark}\label{rem_Union_Find} 
Let . We are given integers  and for each~ a partition  of  in  intervals, a sequence of  find-queries and a sequence of  union-operations to be performed alternatively on  (that is, we perform one find query then the one union operation, and so on, in the order specified in the sequences of union and find-queries). We can maintain the structure and obtain the answers to all find-queries in  total time. 

To see why this holds, assume that we are given the sequence  of  find-queries and the sequence  of  union-operations to be performed alternatively on this partition. As defined above, first we perform the first find query in which we search for the interval containing , then the first union between the interval ending on  and the one starting on , then the second find query on the updated partition, in which we search the interval containing , and so on. In the following we show how to obtain the answers to all find-queries in  time. 

As a first step, we sort in time  all the ends of the intervals in  and the elements of  for all  at once, using radix-sort. Then we separate them (now sorted) according to the partition they correspond to: so, we have for each  an ordered list of the ends of the intervals of  and the elements of . Now we basically have all the data needed to be able to run the the algorithms of~\cite{Gabow83} in  time for each partition (e.g., the time used in our setting by the sub-routines defined and used by \cite{Gabow83} is exactly just the one the required to apply the results of that paper, for each of the partitions). In conclusion, the total time needed to process one partition and to perform all the find queries and union operations on it is . This adds up to a total time of . 
\end{remark}

We further give another lemma related to the union-find data structure.
\begin{lemma}\label{stabbing}
Let . We are given  intervals  included in~. Also, for each  we are given a positive integer , the weight of the interval . We can compute in  time the values  (or, alternatively, ) for all .  
\end{lemma}
\begin{proof}
Let us assume that  where  and , for all . We first show how the array  is computed.  

We sort the intervals  with respect to their starting positions , for . Then, we produce for each  from  to  the list of the intervals  that have  (again, sorted by their starting positions). Using radix-sort we can achieve this in time . Further, we set up a disjoint set union-find data structure for the universe . Initially, the sets in our structure are the singletons ; the only unions that we can a make while maintaining this structure are between the set containing  and the set containing , for all . Therefore, we can think that our structure only contains intervals ; initially, we have in our union-find data structures, for all , the sets . Now, we process the intervals that have weight , for each  from  to  in decreasing order; that is, the intervals are considered in decreasing order of their weight. So, assume that we process the input intervals of weight . Assume that at this moment,  is partitioned in some intervals (some of them just singletons); initially, as mentioned above, we only have singletons . Let  be an input interval of weight . Let now  (in the following,  will take different values between  and ). We locate the interval   (of the union-find structure we maintain) where  is located; if this is a singleton and  was not already set, then we set . Further, unless  is , we merge the interval containing  to that containing  and set ; if  we just set .  In both cases, we repeat the procedure while . We process in this manner all the intervals  with , in the order given by their starting positions, then continue and process the intervals with weight , and so~on.

The algorithm computes  correctly. Indeed, we set  when we process an interval  of weight  that contains , and no other interval of greater weight contained . To see the complexity of the algorithm we need to count the number of union and find operations we make. First, we count the number of union operations. For this, it is enough to note that for each element  we might make at most  unions: one that unites the singleton interval  to the interval of , which has the form  for some , and another one that unites the interval of  to the one of . So, this means that we make at most  union operations. For the find operations, we just have to note that when an interval  is processed the total number of finds is , where  is the union of the intervals that were processed before . This shows that the total number of find operations is . 

By the results of \cite{Gabow83}, as we know the structure of the unions we can make forms a tree, our algorithm runs in  time. 

The computation of  is similar. The only difference is that we consider the intervals in increasing order of their weight.
\end{proof}


We conclude this section with a lemma that will be used in the solutions of Problem \ref{LLAP}. It shows how to compute in linear time the length of the longest square centred at each position of a given word. 
\begin{lemma}\label{centred_squares}
Given a word  of length  we can compute in  time the values  is both a suffix of  and a prefix of .
\end{lemma}
\begin{proof}
Note that each square  occurring in a word  is part of a maximal run , where  is primitive and  is a prefix of , and , where  is a cyclic shift of  (i.e.,  is a factor of  of length ) and . 

So, if we consider a maximal run  and some , we can easily detect the possible centre positions of the squares having the form  contained in this run, with  a cyclic shift of . These positions occur consecutively in the word : the first is the  position of the run, and the last is the one where the suffix of length  of the run starts. So they form an interval  and we associate to this interval the weight  (i.e., the length of an arm of the square). In this way, we define  intervals (as their number is upper bounded by the sum of the exponents of the maximal runs of ), all contained in , and each interval having a weight between  and . By Lemma \ref{stabbing}, we can process these intervals so that we can determine for each  the interval of maximum weight containing , or, in other words, the maximum length  of a square centred on . This procedure runs in  time. 
 \end{proof}

It is worth noting that using the same strategy as in the proof of Lemma~\ref{centred_squares}, one can detect the minimum length of a square centred at each position of a word (also called the local period at that position) in linear time. Indeed, in this case we note that the square of minimum length centred at some position of the input word must be primitively rooted. Then, we repeat the same strategy as in the proof of Lemma \ref{centred_squares}, but only construct the intervals  for the case when  (i.e., the intervals ) for all runs , with the corresponding weights. Then we use Lemma \ref{stabbing} for these intervals to determine the interval of minimum weight that contains each position of the word.
This leads to an alternative solution to the problem of computing the local periods of a word, solved by~\cite{MFCS_Lecroq}. Compared to the solution of \cite{MFCS_Lecroq}, ours uses a relatively involved data structures machinery (disjoint sets union-find structures, as well as an algorithm finding all runs in a word), but is much shorter and seems conceptually simpler as it does not require a very long and detailed combinatorial analysis of the properties of the input word. 

The same strategy allows solving the problem of computing in linear time, for integer alphabets, the length of the shortest (or longest) square ending (or starting) at each position of a given word; this improves the results by  \cite{kosarajuCPM,XuCPM}, where such a result was only shown for constant size alphabets. Let us briefly discuss the case of finding the shortest square ending at each position of the word; such squares are, clearly,  primitively rooted. So, just like in the case of searching squares centred at some position, we can determine for each run an interval of positions where a square having exactly the same period as the run may end. The period of each run becomes the weight of the interval associated to that run. Then we use again Lemma \ref{stabbing}  for these intervals to determine the interval of minimum weight that contains each position of the word. Thus, we determine for each position the shortest square ending on it. In the case when we want the longest square ending at each position, just like in the case of centred squares, we define for each run several intervals. Fortunately, this does not increase asymptotically the complexity.

In the following we apply the machinery developed in this section to identify the longest gapped repeats and palindromes occurring in a word.


\section{Lower and upper bounded gap}
In this section we present the solutions of Problems \ref{LPFgG}(a) and \ref{LPFgG}(b). With these problems solved, we can immediately retrieve the longest gapped repeat and palindrome contained in the input word of these problems, such that the length gap is between a given lower bound and a given upper bound.

\begin{theorem}\label{thLPrFgG}
Problem \ref{LPFgG}(a) can be solved in linear time.
\end{theorem}
\begin{proof}
Let ; for simplicity, assume that  is divisible by . Further, for , 
let  be the longest factor which is a prefix of  such that  is a suffix of some  with ; then,  is the rightmost position  such that  and  is a suffix of . Knowing  means knowing : we just have to return . 

We split the set  into  ranges of consecutive numbers: , , and so on. Note that for all  in some range  from those defined above, there are at most three consecutive ranges where some  such that  may be found: the range containing , the range containing , and the one in between these two (i.e., the range containing ). Moreover, for some fixed , we know that we have to look for  in the interval , of length ; when we search  we look at the interval . So, basically, when trying to find  for all , we move a window of length  over the three ranges named above, and try to find for every content of the window (so for every ) its one element that fits the description of . The difference between the content of the window in two consecutive steps is not major: we just removed an element and introduced a new one. Also, note that at each moment the window intersects exactly two of the aforementioned three ranges. We try to use these remarks, and maintain the contents of the window such that the update can be done efficiently, and the values of  (and, implicitly, ) can be, for each , retrieved very fast. Intuitively, grouping the 's on ranges of consecutive numbers allows us to find the possible places of the corresponding 's for all  in  time.

\begin{figure}[H]
\begin{center}
\includegraphics[width=\linewidth]{intervals.pdf}
\end{center}
\vspace{-1cm}
\caption{Proof of Theorem \ref{thLPrFgG}: Construction of the ranges  for some range , and of the sliding window  for some }
\end{figure}

We now go into more details. As we described in the preliminaries, let  be the lexicographically ordered list of the the suffixes  of  and of the mirror images  of the prefixes of  (which correspond to the suffixes of ). For the list  we compute the arrays  and . 
We use the suffix array for  to produce for each of the ranges  computed above the set of suffixes of  that start in the respective range (sorted lexicographically, in the order they appear in the suffix array) and the set of prefixes of  ending in , ordered lexicographically with respect to their mirror image. 

We consider now one of the ranges of indexes  from the above, and show how we can compute the values , for all . For some  we look for the maximum  such that there exists a position  with , and . As already explained, for the 's of  there are three consecutive ranges where the 's corresponding to the 's of  may be found; we denote them . 

Now, for an  we have that  (for which ) belongs to , where  is an interval starting with  and extending until the end of the range that contains  (which is one of the ranges ) and  is an interval ending with , which starts at the beginning of the range that contains  (which is the range that comes next after the one containing ). Referencing back to the intuitive explanation we gave at the beginning of this proof,  is the window we use to locate the value of  for an .  

To compute  for some , take  such that  for all . Similarly, take  such that for all  we have . Once  and  computed, we set  if ; we set , otherwise. So, in order to compute, for some , the value , that determines ,  we first compute  and .

We compute for all the indices , considered in increasing order, the values . 
We consider for each  the interval  and note that , and, if  is not a singleton (i.e., ) then . 
If  is a singleton, than  is, in fact, one of the precomputed range , namely the one which starts on position  (so, ). 
 
These relations suggest the following approach. We start with  and consider the set of words  with ; this set can be easily obtained in  time by finding first the range  in which  is contained (which takes  time, as  for ), and then selecting from  of the set of prefixes  of , ending in  with  (ordered lexicographically with respect to their mirror image). The ranks corresponding to these prefixes in the ordered list  (i.e., the set of numbers ) define a partition of the universe  in at most  disjoint intervals. So, we can maintain an interval union-find data structures like in Remark \ref{rem_Union_Find}, where the ranks are seen as limits of the intervals in this structure. We assume that the intervals in our data structure are of the form , with  and  equal to some  and , respectively. The first interval in the structure is of the form , while the last is of the form . We now find the interval to which  belongs; say that this is . This means that the words  and  are the two words of  which are closest to  lexicographically ( is lexicographically smaller,  is greater). Clearly,  if  and , otherwise (in case of a tie, we take  to be the greater of  and ). So, to compute  we query once the union-find data structure to find  and , and the corresponding  and , and then run two more  queries. 

When moving on to compute , we just have to update our structure and then run the same procedure. Now,  is no longer a valid candidate for , and it is removed from . So we just delete it from the interval union-find data structure, and merge the interval ending right before  and the one starting with . This means one union operation in our interval union-find structure. Then we proceed to compute  as in the case of .

The process continues until  is a singleton, so  equals its single element.

Now,  is the last element of one of the ranges  or ; assume this range is . So far, we performed alternatively at most  find queries and  union operations on the union-find structure. Now,  instead of updating this structure, we consider a new interval partition of  induced by the ranks of the~ prefixes ending in . When computing the values  for  we need to consider a new partition of  at most once: at the border between  and .

It is not hard to see from the comments made in the above presentation that our algorithm computes  correctly. In summary, in order to compute , we considered the elements  from left to right, keeping track of the left part  of the window  while it moved from left to right through the ranges  and . Now, to compute the values  for , we proceed in a symmetric manner: we consider the values  in decreasing order, moving the window from right to left, and keep track of its right part . 

As already explained, by knowing the values  and  for all  and for all , we immediately get  (and, consequently ) for all . 

We now evaluate the running time of our approach. We can compute, in  time, from the very beginning of our algorithm the partitions of  we need to process (basically, for each  we find ,  and  in constant time, and we get the three initial partitions we have to process in  time), and we also know the union-operations and find-queries that we will need to perform for each such partition (as we know the order in which the prefixes are taken out of the window, so the order in which the intervals are merged). In total we have  partitions, each having initially  intervals, and on each we perform  find-queries and -union operations. So, by Remark \ref{rem_Union_Find}, we can preprocess this data (once, at the beginning of the algorithm) in  time, to be sure that the time needed to obtain the correct answers to all the find queries is . So, the total time needed to compute the values  for all  and for all  is . Similarly, the total time needed to compute the values  for all  is . Then, for each  we get  and  in  time.

Therefore, Problem \ref{LPFgG}(a) can be solved in linear time.
\end{proof}

Before giving the formal solution for Problem \ref{LPFgG}(b), we give a short intuitive description of how this algorithm is different from the previous one. In this case, when trying to construct the repeat  with the longest arm occurring at a certain position, we need to somehow restrict the range where its left arm may occur. To this end, we restrict the length of the arm, and, consequently, search for  with , for each . Such a factor always start with  and may only occur in the factor . If , using the dictionary of basic factors data structures (from~\cite{DBF}) and the results by \cite{KociumakaSPIRE2012}, we get a constant size representation of the occurrences of  in that range (which are a constant number of times longer than the searched factor), and then we detect which one of these occurrences produces the repeat  with the longest arm. If , we use roughly the same strategy to find the repeat  with the longest arm and  starting in a range of radius  centred around  or in a range of length  ending on  (again, these ranges are just a constant number of times longer than the searched factor). To detect a repeat starting between  and  we use the strategy from the solution of Problem \ref{LPFgG}(a); in that case, we just have to return the longest common prefix of  and the words  with . Overall, this approach can be implemented to work in  time.
\begin{theorem}\label{sol_LPFgG}
Problem \ref{LPFgG}(b) can be solved in  time.
\end{theorem}
\begin{proof}
For , let  denote the value  such that  and . 
In other words, to define , let  be the longest factor which is both a prefix of  and a suffix of some  with ; then,  is the rightmost position  such that  and  is a suffix of . Clearly, knowing  means knowing . 

Intuitively, computing  is harder in this case than it was in the case of the solution of Problem \ref{LPFgG}(a). Now we have no real information where  might be, we just know the range of  where the longest factor that occurs both at  and at  ends. So, to determine  we try different variants for the length of this factor, and see which one leads to the right answer. 

Let  and ; assume w.l.o.g. that  is divisible by . 

As already noted, the solution used in the case of gapped palindromes in the proof of Theorem \ref{thLPrFgG} does not work anymore in this case: we do not know for a given  a range in which  is found. So, we try to restrict the places where  can occur. We split our discussion in two cases.

In the first case, we try to find, for each  and each , the factor  with the longest , such that the second  occurs at position  in ,  and . Clearly,  should start with the basic factor , and the left arm  in the factor  we look for should have its prefix of length  (so, a factor equal to the basic factor ) contained in the factor , whose length is \centerline{} So, by Remark \ref{rem_DBF}, using the dictionary of basic factors we can 
retrieve a compact representation of the occurrences of  in : these consist in a constant number of isolated occurrences and a constant number of runs. For each of the isolated occurrences  we compute  and this gives us a possible candidate for ; we measure the gap between the two occurrences of  (the one at  and the one at ) and if it is between smaller than , we store this  as a possible solution to our problem (we might have to cut a suffix of  so that the gap is also longer than ). Further, each of the runs has the form , where  is the period of  and  is a prefix of  (which varies from run to run); such a run cannot be extended to the right: either the period breaks, or it would go out of the factor . Using a  query we find the longest factor  with period , occurring at position . For a run , the longest candidate for the first  of the factor  we look for starts with  where  and  is the shortest of  and ; if , then this factor is extended with the longest factor that occurs both after the current run and after  and does not overlaps the minimal gap (i.e., end at least  symbols before ). This gives us 
a candidate for the factor  we look for (provided that the gap between the two candidates for  we found is not too large). In the end, we just take the longest of the candidates we identified (in case of ties, we take the one that starts on the rightmost position), and this gives the factor  with the longest , such that the second  occurs at position  in ,  and . 

\begin{figure}\begin{center}
\includegraphics[width=\linewidth]{Intervals_long.pdf}
\end{center}
\vspace{-0.5cm}
\caption{Proof of Theorem \ref{sol_LPFgG}: Occurrences of  inside : one separate occurrence, and a run containing three occurrences. The separate occurrence can be prolonged to produce a gapped palindrome , which is not, however, long enough as it does not reach the range between  and . The rightmost occurrence in the run produces the gapped repeat , which fulfils the conditions imposed on the gap.}
\end{figure}


Iterating this process for all  and  as above, we obtain for each  the factor  with the longest , such that the second  occurs at position  in ,  and .
By Remark \ref{rem_DBF}, the time spent in this computation for some  and  is constant, so the overall time used in the above computation is . Clearly, if for some  we found such a factor , then this gives us both  and ; if not, we continue as follows.

In the second case, we try to identify  for each  the factor  with the longest , such that the second  factor occurs at position  in ,  and . Again, we consider each  separately and split the discussion in three cases.

Firstly, for each , we find the factor  with the longest , such that the second  occurs at position  in , , , and the first  has its prefix of length  in the factor , whose length is . This can be done similarly to the above (report all the occurrences of  in that range, and try to extend them to get ); for all  and all  takes  time. 

Secondly, for each , we find the factor  with the longest , such that the second  occurs at position  in , , , and the first  has its prefix of length  in the factor , whose length is . Again, this can be done like above, and for all  and all  takes  time. 

The third and more complicated subcase is when the first  starts in the factor , of length . Let ; obviously, . Note that, in this case, every factor of length at most  starting in  ends before , so it is a valid candidate for the  we look for.
In this case we can follow the algorithm from the proof of Theorem \ref{thLPrFgG}. We split the set  into ranges of consecutive numbers: , , and so on. For some , considering all  there are three consecutive ranges from the ones defined above, where the first  of the factor  we look for may occur. The first (leftmost, with respect to its starting position) such range is the one containing , and let us denote it ; the last one (rightmost) is the one that contains , and we denote it by . Clearly, between the ranges containing  and , respectively, there is exactly one complete range, call it . 

Moreover, for a precise  the possible starting positions of the left arm  of the repeat  of the type we are searching for (i.e., with the gap between  and ), with the second  starting on , form a contiguous range  where  is an interval starting with  and extending until the end of the range  that contains , and  is an interval ending with , contained in  (when ). Like before,  can be seen as the content of a window that slides through  while searching for . We denote by  the position of  such that  is maximum among all such positions; we denote by  the position of  such that  is maximum among all such positions. Then we just have to check where, at  or , occurs a longer factor that also occurs at . We just explain how to compute . 

We start with  and consider the set of words  with ; this set can be easily obtained in  time by finding first the range  in which  is contained and then selecting from  of the set of words  of  starting in  with  (ordered lexicographically). The ranks corresponding to these suffixes in the suffix array of  (i.e., the set of numbers ) define a partition of the universe  in at most  disjoint intervals. So, we can maintain an interval union-find data structures like in Remark \ref{rem_Union_Find}, where the ranks are seen as limits of the intervals in this structure. We assume that the intervals in our data structure are of the form , with  and  integers that are equal to some  and . The first interval in the structure is of the form , while the last is of the form . Recall that we want to compute . To this end, we just have to find the interval to which  belongs; say that this is . This means that the words  and  are the two words of the set  which are closest to  lexicographically ( is lexicographically smaller, while  is lexicographically greater). Clearly,  if  and , otherwise (in case of a tie, we take  if , and  otherwise). So, to compute  we have to query once the union-find data structure to find  and , and the corresponding  and , and then compute the answer to two  queries. 

When moving on to compute , we just have to update our structure. In this case,  is no longer a valid candidate for , as it should be removed from . So we just delete it from the interval union-find data structure, and merge the interval ending right before  and the one starting with . This means one union operation in our interval union-find structure. Then we proceed to compute  just in the same manner as in the case of .

The process continues in this way until we try to compute  for  being a singleton. This means that  is the last element of one of the ranges , , or ; let us assume that this range is  from the ranges defined above. Clearly, this time  is the single element of . Until now, we performed alternatively at most  find operations and  union operations on the union-find data structure. Further, instead of updating the union-find data structure, we consider a new interval partition of  induced by the ranks of the  suffixes starting in . Note that when computing the values  for  we need to consider a new partition of  once: at the border between  and .

Now, by the same arguments as in the proof for gapped palindromes, the process takes  in total for all intervals  (so, when we iterate ), for each . In this way we find the factor  with the longest , such that the second  occurs at position  in , , , and the first  starts in . Iterating for all , we complete the computation of  and  for all ; the needed time is  in this case.

Considering the three cases above leads to finding for each  the factor  with the longest , such that the second  factor occurs at position  in ,  and . The complexity of this analysis is . After concluding this, we get the value  for each . Therefore, the entire process of computing  and  for all  takes  time.
\end{proof}

We conclude this section with the following consequence of Theorems~\ref{thLPrFgG} and~\ref{sol_LPFgG}.

\begin{theorem}
Given  of length  and two integers  and , such that , we can find in linear time the gapped palindrome  occurring in that word with the longest arm  and .\\
Given  of length  and two integers  and , such that , we can find in  time the gapped repeat  occurring in that word with the longest arm  and .
\end{theorem}
\begin{proof}
It is immediate that, after solving Problem \ref{LPFgG} for the word , we just have to check which is the longest gapped palindrome (respectively, repeat) stored in the array  (respectively, ). 
 \end{proof}

\section{Lower bounded gap}
To solve Problem \ref{LPFg(i)}(a) we need to find, for some position  of , the factor  with  that occurs closest to  in the lexicographically ordered list  of all the suffixes  of  and of the mirror images  of its prefixes. In the following we show how to do this for all  in  time, by reducing it to answering  find queries in an extended interval union-find data~structure.
\begin{theorem}\label{LPFg(i)_sol}
Problem \ref{LPFg(i)}(a) can be solved in linear time.
\end{theorem}
\begin{proof}
In a preprocessing step of our algorithm, we produce the suffix array of  and the lexicographically ordered list  of the suffixes of  of  and of the mirror images  of the prefixes of  (which correspond to the suffixes of ). For the list  we compute the arrays  and . 

We first want to find, for each , the prefix , such that ,  occurs before  in  (i.e., ), and the length of the common prefix of  and  is greater or equal to the length of the common prefix of  and  for  such that ; for the prefix  as above, the length of the common prefix of  and  is denoted by , while  denotes . If  has no common prefix with any factor  with  and , then   and  is not defined; as a convention, we set  to 

Afterwards, we compute for each  the prefix , such that ,  occurs after  in  (i.e., ), and the length of the common prefix of  and  is greater or equal to the length of the common prefix of  and  for  such that ; for the prefix  as above, the length of the common prefix of  and  is denoted by , while  denotes . Clearly, . If  has no common prefix with any factor  with  and , then   and  is set to 

For simplicity, we just present an algorithm computing  and . The computation of  is performed in a similar way.

The main idea behind the computation of , for some , is that if  and  are such that  and  then definitely . Indeed, , and, moreover, . So, if  then also , and it follows that , so  cannot be . This suggests that we could try to construct for each  an ordered list  of all the integers  such that  and moreover, if  and  are in  and  then also . 

Now we describe how to implement this. Let us now consider  and  which occur on consecutive positions of the suffix array of , such that . The list  can be obtained from  as follows. We consider one by one, in the order they appear in , the integers  such that , and for each of them update a temporary list , which initially is equal to . When a certain  is considered, we delete from the right end of the list  (where  is ordered increasingly from left to right) all the values ; then we insert  in . When there are no more indices  that we need to consider, we set  to be equal to . It is clear that the list  is computed correctly. 

Now, for each  we need to compute the greatest  such that . As  is ordered increasingly, we could obtain  by performing a predecessor search on  (that is, binary searching the greatest  of the list, which is smaller than ), immediately after we computed it, and save the answer in . However, this would be inefficient. Before proceeding, we note that if we compute the lists  for the integers  in the order they appear in the suffix array of , then it is clear that the time needed to compute all these lists is linear. Indeed, each  is introduced exactly once in the temporary list, and then deleted exactly once from it. Doing the above mentioned binary searches would add up to a total of . We can do better than that.

Now we have reduced the original problem to a data-structures problem. We have to maintain an increasingly ordered (from left to right) list  of numbers (at most , in the range , each two different), subject to the following update and query operations. This list can be updated by the following procedure: we are given a number , we delete from the right end of  all the numbers greater than , then we append  to . By this update, the list remains increasingly ordered.  The following queries can be asked: for a given , which is the rightmost number of , smaller than ? 
We want to maintain this list while  updates are executed, and  queries are asked at different moments of time. 
Ideally, the total time we can spend in processing the list during all the updates should be , and, after all the updates are processed, we should be able to provide in  time the correct answer for all the queries (i.e., if a certain query was asked after  update operations were performed on the list, we should return the answer to the query with respect to the state of the list after those  update operations were completed).

Next we describe our solution to this problem.

We use a dynamic tree data-structure to maintain the different stages of . Initially, the tree contains only one path: the root  and the leaf . When an update is processed, in which a number  is added to the list, we go up the rightmost path of the tree (from leaf to root) until we find a node with a value smaller than . Then  becomes the rightmost child of that node (i.e.,  is a leaf). Basically, the rightmost path of a tree after  updates contains the elements of  after those  updates, preceded by . When a query is asked we associate that query with the leaf corresponding to the rightmost leaf of the tree at that moment. In this way, we will be able to identify, after all updates were processed, the contents of the list at the moments of time the queries were, respectively, asked: we just have to traverse the path from the node of the tree associated to that query (this node was a leaf when the query is asked, but after all the updates were processed might have become an internal node) to the root.

The tree can be clearly constructed in linear time: each node is inserted once on the rightmost tree, and it disappears from this rightmost tree (and will not be reinserted there) when a smaller value is inserted in the tree.

In this new setting, the queries can be interpreted as weighted level ancestor queries on the nodes of the constructed tree (where the weight of an edge is the difference between the two nodes bounding it). Considering that the size of the tree is 
, all weights are also , there are  queries, and these queries are to be answered off-line, it follows (see Remark~\ref{weighted_tree}) that we can return the answers to all these queries in  time. 

This completes the linear solution to our problem. 
\end{proof}

To solve Problem \ref{LPFg(i)}(b) we use the following lemma.
\begin{lemma}\label{overlapping_LPF}
Given a word , let  for all . The array  can be computed in linear time.
\end{lemma}
\begin{proof}
We first produce the suffix array of . We denote by  the position of  in the suffix array of . 

We first want to find, for each , the suffix , such that  is minimum with  and  for all  such that .
For the suffix  as above, let . If no such  exists, we set . 

Similarly, we compute, for each , the suffix , such that  is minimum with  and  for all  such that .
For the suffix  as above, let . Again, if no such  exists, we set .  

For simplicity, we just present an algorithm computing . The computation of  is performed in a similar way. Then,  if  or  and ; similarly,  if  or  and .

The main idea behind the computation of , for some , is that if  and  are such that  and  then definitely . Indeed, , and, moreover, , so  is a better candidate than  for . This suggests that we should construct for each  an ordered list  of all the integers  such that  and moreover, if  and  are in  and  then also . If  is on top of , then  is just the minimum  of  such that .

Let us now consider  and  which occur on consecutive positions of the suffix array of , such that . Assume that we already computed . The list  can be obtained from  by deleting from the right end of the list  (where  is ordered increasingly from left to right) all the values . Also, to compute  more efficiently, we also delete all the values of  that are greater than . Indeed, for some  we have that  and , so  is a better candidate for  than . Afterwards, we insert  in the updated list , to obtain a list  from which  can be computed. Clearly, this entire process takes linear time, and leads to a correct computation of . 

Afterwards, we compute  similarly, and get  in linear time.
\end{proof}


Another lemma shows how the computation of the array  can be connected to that of the array . For an easier presentation, let  denote the leftmost starting position of the longest factor  that occurs both at position~ and at a position  such that ; if there is no such factor , then . In other words, the length of the factor  occurring at position  gives us . In fact, . 

Now, let  and , for ; also, we define \\
\centerline{.} 

The following lemma shows the important fact that  can be obtained just by looking at the values of . More precisely,  equals , where  is obtained by looking at the values  and taking the one such that the factor starting on it and ending on  has a maximal common prefix with . Afterwards, Theorem \ref{LPFg(i)_sol_rep} shows that this check can be done in linear time for all , thus solving optimally Problem \ref{LPFg(i)}. 

\begin{lemma}\label{iterated_L}
For a word  of length  and all  such that , we have that . 
\end{lemma}
\begin{proof}
Let us assume, for the sake of a contradiction, that . This means that  and  for all . We further consider two simple cases.

In the first case, there is  such that ; take  to be the greatest number less than  that belongs to . Then, it is clear that the longest factor that occurs both at  and at  ends before . Otherwise, we would have , so we would have , a contradiction. So, it follows immediately, that . Now, if  (that is , where  is applied  times on ), then there exists  such that  and  and . Clearly, this means that  occurs in the suffix array of  closer to the suffix  than the suffix , but farther than the suffix . So, , which is a contradiction to the definition of . In conclusion, we cannot have that there is  such that .

Now, assume that there is no  such that . As , this leads immediately to a contradiction. Since , we have that the suffix starting at position  has at least the prefix of length one common with all the factors starting at positions from . Therefore, at least one element from  should be less or equal to . 
This concludes our proof.
\end{proof}

\begin{theorem}\label{LPFg(i)_sol_rep}
Problem \ref{LPFg(i)}(b) can be solved in linear time.
\end{theorem}
\begin{proof}
The main idea in this proof is that, to compute , it is enough to check the elements  with , and choose from them the one for which  is maximum; this maximum will be the value we look for. In the following, we show how we can obtain these values efficiently.

First, if  for some , we define the value , where . Basically, for each position , the longest factor  starting at  and ending on  which also occurs at position  is longer than any factor starting on position  and ending on  which also occurs at position . Now we note that if  is the greatest element of this set such that , then . Clearly,  can be computed in constant time for each .

To be able to retrieve efficiently for some  the greatest element of this set such that  we proceed as follows.

First we define a disjoint-set union-find data structure on the universe , where the unions can be only performed between the set containing  and that containing , for all . Initially, each number between  and  is a singleton set in this structure. Moreover, our structure fulfils the conditions that the efficient union-find data structure of \cite{Gabow83} should fulfil: the unions we make form a tree. 

Further, we sort in linear time the numbers , for all ; we also sort in linear time the numbers  for all . We now traverse the numbers from  to , in decreasing order. When we reach position  we check whether  equals  for some ; if yes, we unite the set containing  with the set containing  for all  such that . Then, if  for some , we just have to return the minimum of the set containing ; this value gives exactly 
the greatest element  such that . So, as described above, we can obtain from it the value of .  The computation of this array follows from the previous remarks.

\begin{figure}
\begin{center}
\includegraphics[width=\linewidth]{LPFgi.pdf}
\end{center}
\caption{Proof of Theorem \ref{LPFg(i)_sol_rep}: We measure the length of the common prefix between each factor starting on  and ending on  and  the suffix . The starting position of the factor that produces the longest such common prefix is . Also, this longest common prefix defines the arm  of the gapped repeat .}
\end{figure}


To evaluate the complexity of our approach, note that we do  union operations and  find queries on the union-find data structure. By the results of \cite{Gabow83}, the time needed to construct the union-find data structure and perform these operations on it is also . From every find query we get in constant time the value of a element . So the solution of Problem \ref{LPFg(i)} is linear. 
\end{proof}

Just like in the previous section, the following consequence of the previous two theorems is immediate.

\begin{theorem}
Given  of length  and the values  of , we can find in linear time the gapped palindrome (or repeat)  (respectively, ) occurring in , with the longest arm , such that if its right arm starts on position  then . 
\end{theorem}

\section{-gapped Repeats and Palindromes}

Recall that an -gapped palindrome (respectively, repeat)  is called maximal if the arms cannot be extended to the right or to the left: neither  nor  (respectively, neither  nor ) are -gapped palindromes (respectively, repeats).
\cite{fct} defined algorithms that find the longest -gapped palindromes and repeats in  time; these algorithms do not compute the set of all -gapped palindromes or repeats, but just the ones with the longest arms. We present them below.

We first consider the case of -gapped repeats.
\begin{theorem}\label{algorithm_rep_case_aperiodic}
Given a word  of length  and an integer , the longest -gapped repeat  contained in  can be found in  time. 
\end{theorem}
\begin{proof}
Informally, our approach works as follows (see also Figure \ref{aper}). For each , we try to find the longest -gapped repeat , with , and . In each such repeat, the right arm  must contain a factor (called -block) , of length , starting on a position of the form . So, we try each such factor , fixing in this way a range of the input word where  could appear. Now,  must also contain a copy of . However, it is not mandatory that this copy of  occurs nicely aligned to its original occurrence; that is, the copy of  does not necessarily occur on a position of the form . But, it is not hard to see that  has a factor  of length~, starting in its first  positions and whose corresponding occurrence in  starts on a position of the form . Further, we can use the fact that  is -gapped and apply Lemma \ref{find_occ_range} to a suitable encoding of the input word to locate in constant time for each  starting in the first  positions of  all possible occurrences of  on a position of the form , occurring not more than  positions to the left of . Intuitively, each occurrence of  found in this way fixes a range where  might occur in , such that  is -gapped. So, around each such occurrence of  (supposedly, in the range corresponding to ) and around the  from the original occurrence of  we try to effectively construct the arms  and , respectively, and see if we really get an -gapped repeat. In the end, we just return the longest repeat we obtained, going through all the possible choices for  and the corresponding 's. We describe in the following an  time implementation of this approach.

\begin{figure}
\begin{center}
\includegraphics[width=\linewidth]{reps_aperiodic.pdf}
\end{center}
\caption{
Proof of Theorem \ref{algorithm_rep_case_aperiodic}: Segment of , split into blocks of length . In this segment,  is a -block of length . For each factor , of length , occurring in the first  symbols of  (not necessarily a sequence of blocks), we find the occurrences of  that correspond to sequences of  blocks, and start at most  symbols (or, alternatively,  blocks) to the left of the considered . These  factors may appear as runs or as separate occurrences. Some of them can be extended to form an -gapped repeat  such that the respective occurrence of  has the same offset in  as the initial  in .}
\label{aper}
\end{figure} 

The first step of the algorithm is to construct a word , of length , whose symbols, called {\em blocks}, encode  consecutive symbols of  grouped together. Basically, now we have two versions of the word : the original one, and the one where it is split in blocks. Clearly, the blocks can be encoded into numbers between~ and  in linear time. Indeed, we produce the suffix array of , and group together the suffixes that share a common prefix of length . Then, we label (injectively) the groups obtained in this way with numbers between  and . Finally, a block is encoded as the label of the suffix that starts with that block. Consequently, we can construct in  time the suffix arrays and -data structures for both  and . We can also build in  time the data structures of Lemma \ref{find_occ_range} for the word . 

Now, we try to find the longest -gapped repeat  of , with , and , for each  if  or , otherwise. Let us consider now one such . We split again the word , this time in factors of length , called {\em -blocks}. For simplicity, assume that each split is exact. 

Clearly, if an -gapped repeat  like above exists, then  contains at least one of the -blocks. Consider such a -block  and assume it is the leftmost -block of . On the other hand,  contains at least  consecutive blocks from , so there should be a factor  of  corresponding to  of these  blocks which is also a factor of , and starts on one of the first  positions of . Now, for each -block  and each , with  and starting in its prefix of length , we check whether there are occurrences of  in  ending before~ that correspond to exactly  consecutive blocks of  (one of them should be the occurrence of  in~); note that the occurrence of  in  may not necessarily correspond to a group of  consecutive blocks, but the one from  should. As  is -gapped and , then the occurrence of  from  starts at most  symbols before  (as , and  occurs with an offset of at most  symbols in ). So, the block-encoding of the occurrence of the factor  from the left arm  should occur in a factor of  blocks of , to the left of the blocks corresponding to~.

For the current  and an  as above, we check whether there exists a factor  of  whose blocks correspond to , by binary searching the suffix array of  (using -queries on  to compare the factors of  symbols of  and the blocks of , at each step of the search). If not, we try another possible . If yes, using Lemma \ref{find_occ_range} for , we retrieve (in  time) a representation of the occurrences of  in the range of  blocks of~ occurring before the blocks of ; this range corresponds to a range of length ~of~. 

If  is aperiodic then there are only  such occurrences. Each factor of  corresponding to one of these occurrences might be the occurrence of  from , so we try to extend both the factor corresponding to the respective occurrence of  from  and the factor  from  in a similar way to the left and right to see whether we obtain the longest -gapped repeat. If  is periodic (so,  is periodic as well), we know that the representation of its occurrences consists of  separate occurrences and  runs in which  occurs (see Preliminaries). The separate occurrences are treated as above. Each run  of  where  occurs is treated differently, depending on whether its corresponding run  from  (made of the blocks corresponding to~) supposedly starts inside , ends inside , or both starts and ends inside . We can check each of these three cases separately, each time trying to establish a correspondence between  and the run containing the occurrence of  from , which should also start, end, or both start or end inside , respectively. Then we define  and  as the longest equal factors containing these matching runs on matching positions. Hence, for each separate occurrence of  or run of such occurrences, we may find an -gapped repeat in ; we just store the longest. This whole process takes  time.

If , we run this algorithm for all  and find the longest -gapped repeat , with , in  time. 

If , we run this algorithm for all  and find the longest -gapped repeat , with , in  time.  If our algorithm did not find such a repeat, we should look for -gapped repeats with shorter arm. Now,  is upper bounded by , so , for . Such an -gapped repeat  is, thus, contained in (at least) one factor of length  of , starting on a position of the form  for .  So, we take the factors  of , for , and apply for each such factor, separately, the same strategy as above. As an important detail, before running the algorithm presented above, we first encode the symbols of , which were numbers between  and , to numbers between  and ; again, this is done by looking at the suffix array of , and it allows us to apply recursively the algorithm described before. The total time needed to do that is . Hence, we found the longest -gapped repeats , with . If our search was still fruitless, we need to search -gapped repeats with  (a rough estimation, based on the fact that ). 

So, in both cases,  or , it is enough to find the longest -gapped repeats with . The right arm  of such a repeat is contained in a factor  of , while  surely occurs in a factor  (or, if , then in a factor ); in total, there are  such  factors. As before, we can process them in linear time in order to re-encode each of them as a word over the alphabet consisting of numbers which are in . In each of these factors, we look for -gapped repeats  with , where  (the case  is trivial), and  occurs in the suffix of length  of this factor. Moreover,  contains a factor  of the form . Using Lemma \ref{find_occ_small} and Remark \ref{find_occ_small_range}, 
for each such possible  occurring in the suffix of length  of , we assume it is the one contained in  and we produce in  time a representation of the  occurrences of  in the factor of length  preceding . One of these should be the occurrence of  from . Similarly to the previous cases, we check in  time which is the longest -gapped repeat obtained by pairing one of these occurrences to , and extending them similarly to the left and right. The time needed for this is  per each of the  factors  defined above. 
This adds up to an overall complexity of , again.

This was the last case we needed to consider. In conclusion, we can find the longest -gapped repeat  in  time.
\end{proof}

Further we discuss the case of -gapped palindromes.

\begin{theorem}\label{algorithm_case_aperiodic}
Given a word  of length , the longest -gapped palindrome  contained in  can be determined in  time. 
\end{theorem}
\begin{proof} 
Our approach is similar to the case of repeats, presented in the previous theorem. For each , we try to find the longest -gapped palindrome , with . In each such -gapped palindrome, the right arm  must contain a factor , of length , starting on a position of the form . So, we try each such factor , fixing in this way a range of the input word where  could appear. Now,  must contain a factor ; however, it is not mandatory that this factor  occurs at a position of the form . But, just like before, it is not hard to see that  has a factor , of length~, that starts in its first  positions and whose corresponding occurrence  from  should start on a position of the form . 
Further, we can use the fact that  is -gapped and apply Lemma \ref{find_occ_range} to an encoding of the input word to locate in constant time for each  starting in the first  positions of  all possible occurrences of  on a position of the form , occurring not more than  positions to the left of . Intuitively, each occurrence of  found in this way fixes a range where  might occur in , such that  is -gapped. So, around each such occurrence of  (supposedly, in the range corresponding to ) and around the  from  we try to effectively construct the arms  and , respectively, and see if we get the longest -gapped palindrome. This approach can be implemented in  time, just like in the case of -gapped repeats.

The first step of the algorithm is to construct a word , of length , whose symbols, called {\em blocks}, encode  consecutive symbols of  grouped together. Now we have two versions of the word : the original one, and the one made of blocks. As before, the blocks can be encoded as numbers between  and  in linear time. We construct in  time the suffix arrays and -data structures for both  and , and we build in  time the data structures of Lemma \ref{find_occ_range} for the word .

Considering the original word , we find the -gapped palindrome  with , for each . To this end, we split again the word , this time in factors of length , called {\em -blocks}. For simplicity, assume that each split we do is exact; to achieve this, we may have to pad the word with a new symbol in a suitable manner. 

If an -gapped palindrome  of the kind we search for exists, then  contains at least one of the -blocks. Consider such a -block  and assume it is the leftmost -block of . On the other hand,  contains at least  consecutive blocks from , so there should be a factor  of  with  corresponding to  of these  blocks such that  is a factor of  that starts on one of its first  positions. Now, for each -block  and each  starting it its prefix of length , with , we check whether there are occurrences of  ending before~ (one of them should be the occurrence of  in ) that correspond to exactly  consecutive blocks of . Note that the occurrence of  in  may not necessarily correspond to a group of  consecutive blocks, but the one of  from  do. As  is -gapped and , then the occurrence of  from  starts at most  symbols before . So, the block-encoding of  should occur in a factor of   blocks of , to the left of the blocks corresponding to~.


\begin{figure}\begin{center}
\includegraphics[width=\linewidth]{pals_aperiodic.pdf}
\end{center}
\caption{
Proof of Theorem \ref{algorithm_case_aperiodic}: Segment of , split into blocks of length . In this segment,  is a -block of length . For each factor , of length , occurring in the first  symbols of  (not necessarily a sequence of blocks), we find the occurrences of  that correspond to sequences of  blocks, and start at most  symbols (or, alternatively,  blocks) to the left of the considered . These  factors may appear as runs or as separate occurrences. Some of them can be extended to form an -gapped palindrome  such that the respective occurrence of  is the mirror image of the initial  in .}
\end{figure}

For the considered  and some  as above, by binary searching the suffix array of  (using -queries on the word  to compare the factors of  symbols of  and the blocks of , at each step of the search), we check whether there exists a factor  of  whose blocks correspond to . If not, we try another possible . If yes, we continue. Using Lemma \ref{find_occ_range} for , we obtain a representation of the occurrences of  in the range of  blocks of , occurring before the blocks that correspond to ; note that this range corresponds to a range of length  of . 

If  is aperiodic then there are  such occurrences. Each factor corresponding to these occurrences might be the occurrence of  from , so we try to extend it and the  from  in a similar way to see whether we obtain the longest -gapped palindrome. 

If  is periodic (so,  is periodic as well), the representation of its occurrences consists of  separate occurrences and  runs in which  occurs. The separate occurrences are treated as above. Each run  of  where  occurs is treated differently, depending on whether its corresponding run  from  (made of the blocks corresponding to ) supposedly starts inside , ends inside , or both starts and ends inside . We can check all these three cases separately, each time trying to establish a correspondence between  and the run containing the occurrence of  from , which should also end, start, or both start or end inside , respectively. Then we define  and  as the longest mirrored words containing these matching runs on mirrored positions. In this way, for each separate occurrence of  or run of such occurrences, we found a -gapped palindrome in ; we just store the longest. This whole process takes  time for each run.

If , we run this algorithm for all  and find the longest -gapped palindrome , with , in  time. 

If , we run this algorithm for all  and find the longest -gapped palindrome , with , in  time. If our algorithm did not find such a palindrome, we should look for -gapped palindrome with shorter arm. The length of this arm, , is now upper bounded by , so , for . Such an -gapped palindrome  is, thus, contained in (at least) one factor of length  of , starting on a position of the form  for .  So, we take the factors  of , for , and apply for each such factor, separately, the same strategy as above. As noted in the previous proof, these words can be re-encoded in linear time as words over an alphabet of size . The total time needed to do that is . Hence, we found the longest -gapped palindromes , with . If our search was still fruitless, we search -gapped palindromes with  (a rough estimation, based on the fact that ). 

Now in both cases (when  or ) it is enough to find the -gapped palindromes with . The right arm  of such a repeat is contained in a factor  of , while  surely occurs in a factor  (or, if , then in a factor ). In total, there are  such  factors, and after a linear time preprocessing we can ensure that they are all over integer alphabets with respect to their length. In each of them, we look for -gapped palindromes  with , where  (the case  is trivial), and  occurs in the suffix of length  of this factor. Moreover,  contains a factor  of the form . Using Lemma \ref{find_occ_small} and Remark \ref{find_occ_small_range}, 
for each such possible  occurring in the suffix of length  of , we assume it is the one contained in  and we produce in  time a representation of the  occurrences of  in the factor of length  preceding . One of these should be the occurrence of  from . Similarly to the previous cases, we check in  time which is the longest -gapped palindrome obtained by pairing one of these occurrences to , and extending them similarly to the left and right. The time needed for this is  per each of the  factors  defined above. 
This adds up to an overall complexity of , again.

This was the last case we needed to consider. In conclusion, we can find the longest -gapped palindrome  in  time.
\end{proof}

The algorithms presented in the previous two proofs were non-trivially extended by \cite{STACS2016} to algorithms that construct the sets of all maximal -gapped repeats and maximal -gapped palindromes (which have a non-empty gap) in  time. Essentially, instead of looking for the longest -gapped repeat (or palindrome) that contains a certain basic factor (as we did in this proof), we look for all the maximal -gapped repeats (respectively, palindromes) that contain the respective basic factor. Using a series of deep combinatorial observations on the structure of these maximal gapped repeats or palindromes, one can output all of them in  time per repeat or palindrome. Using the crucial fact that the number of both -gapped repeats with non-empty gap as well as -gapped palindromes with non-empty gap is  (in fact, the main result of \cite{STACS2016}), we get that they can all be identified and output in  time.

Accordingly, we further show that given the set  of all factors of a word which are maximal -gapped palindromes (respectively, repeats) we can compute the array  (respectively, ) for that word in  time. As a consequence, for constant , these problems can be solved in linear time. 

Note that, in this case, our strategy is fundamentally different from the ones we used in the cases of Problems \ref{LPFgG} and \ref{LPFg(i)}. There we were able to construct the desired data structures without constructing first the set of all maximal gapped palindromes and maximal gapped repeats whose gap fulfilled the required restrictions. Here we first find all maximal -gapped repeats and -gapped palindromes using the algorithms of \cite{STACS2016}, and then compute directly the desired data structures. 

\begin{theorem}\label{proof_LLAP}
Problem \ref{LLAP}(a) can be solved in  time.
\end{theorem}
\begin{proof}
We assume that we are given an input word , for which the set  of all maximal -gapped palindromes is computed, using the algorithm of~\cite{STACS2016}. 

Let us consider a maximal -gapped palindrome , with . For simplicity, let us denote by , the length of the gap; here,  and  will be called the {\em outer ends} of this palindrome, while  and  are the {\em inner ends}. 

It is not hard to see that from a maximal -gapped palindrome one can get a family of -gapped palindromes whose arms cannot be extended by appending letters simultaneously to their outer ends. We now show how this family of -gapped palindromes can be computed. Intuitively, we extend simultaneously the gap in both directions, decreasing in this way the length of the arms of the palindrome, until the gap becomes long enough to violate the -gapped restriction. The longest possible such extension of the gap can be easily computed. 

Indeed, let . It is not hard to check that for  we have that , with , is an -gapped palindrome whose left arm cannot be extended by appending letters to their outer ends. For  we have that , with , is still a gapped palindrome, but it is not -gapped anymore.  So, for a maximal -gapped palindrome , we associate the interval , and associate to it a weight . Intuitively, we know that at each position  there exists a factor , ending at position , such that  is a suffix of  for some . 

On the other hand, if  is the longest factor starting at some position  such that  is a suffix of , then the factor  is, in fact, a maximal -gapped palindrome (i.e.,  is a prefix of  and  is a suffix of ). In other words,  and  could be extended simultaneously inside the gap, but not at the outer ends.

\begin{figure}
\begin{center}
\includegraphics[width=\linewidth]{long_armed_pals.pdf}
\end{center}
\vspace{-0.5cm}
\caption{Proof of Theorem \ref{proof_LLAP}:  is a maximal -gapped palindrome (here ) with  and . We define . This allows us to define the interval , where the right arm of an -gapped palindrome obtained from  may start. Further,  is an example of such an -gapped palindrome;  is a gapped palindrome obtained from , which is not -gapped: it's right arm does not start in .
The interval  has weight .}
\end{figure}
 
Consequently, to compute  for some  we have to find the -gapped palindromes  for which the interval  contains . Then, we identify which of these intervals has the greatest weight. Say, for instance, that the interval m which contains , is the one that weight maximal weight  from all the intervals containing . Then . Indeed, from all the factors  starting at position , such that  is a suffix of  for some , there is one that ends at position , while all the other end before  (otherwise, the intervals associated, respectively, to the maximal -gapped palindromes containing each of these factors  would have a greater weight). So, the palindrome ending at position  is the longest of them all.

This allows us to design the following algorithm for the computation of . We first use the algorithm of \cite{KK09} to compute the set  of all maximal -gapped palindromes of . For each maximal -gapped palindrome , we associate the interval , where   and , and associate to it the weight . We process these  intervals, with weights and bounds in , in  time as in Lemma \ref{stabbing}, to compute for each  the maximal weight  of an interval containing . Then we set . 

The correctness of the above algorithm follows from the remarks at the beginning of this proof. Its complexity is clearly . 
\end{proof}

The solution of Problem \ref{LLAP}(b) is very similar. 
\begin{theorem}\label{sol_LLAR}
Problem \ref{LLAP}(b) can be solved in  time.
\end{theorem}
\begin{proof}
We first use the algorithm of \cite{STACS2016} to compute the set  of all maximal -gapped repeats with non-empty gap of . For each maximal -gapped repeat , we associate the interval , where  and , and associate to it the weight . We process these  intervals, with weights and bounds in , in  time as in Lemma \ref{stabbing}, to compute for each  the maximal weight  of an interval containing . Now, we use Lemma \ref{centred_squares} to compute the values  for each . We set .

The complexity of this algorithm is , as  (see \cite{STACS2016}).

The correctness of the algorithm follows from the following remark. For a maximal -gapped repeat  let , where . Then the factors  are -gapped repeats for all , whose right arm cannot be extended anymore to the right. Moreover,  the factors  are gapped repeats which are not -gapped for all . The rest of the arguments showing the soundness of our algorithm are similar to those of Theorem \ref{proof_LLAP}.
\end{proof}

\section{Future Work}

In this paper we proposed a series of algorithms that construct data structures giving detailed information on the longest gapped repeats  and palindromes occurring in a given word. There are several directions in which the work presented here can be continued.

Firstly, it seems interesting to us whether Problem \ref{LPFgG}(b) (the construction of the array ) can be solved faster. An intermediate problem could be to check whether we can find in linear time the longest gapped repeats with the length of the gap between a given lower bound and a given upper bound. 

Secondly, although the algorithms we propose in Theorems~\ref{algorithm_rep_case_aperiodic} and~\ref{algorithm_case_aperiodic} do not rely on computing and going through all the maximal -gapped repeats and palindromes when looking for the longest such structure, they have asymptotically the same complexity as the (optimal) algorithms finding all such structures. Thus, it seems natural and interesting to design algorithms finding the longest -gapped repeat or palindrome of a word that run faster than the algorithms we proposed here (and, in particular, than the algorithms finding all these structures). Also, it is interesting whether we can construct the data structures defined in Problem~\ref{LLAP} without producing first the list of all -gapped repeats and palindromes. 

Lastly, following the problems studied by \cite{GMMNT13,GMN14}, one could be interested in finding the longest gapped pseudo-repeats. More precisely, for a literal bijective anti-/morphism , we want to find the longest word (or words)  such that a given word  contains a factor  with  subject to different length-restrictions (e.g., between a lower and an upper bound, or shorter than  multiplied by a factor, like in the case of -gapped repeats and palindromes, etc.). Such repeats and palindromes are sometimes used to formalise repeats and palindromes occurring in DNA sequences. In this setting one works with the alphabet . When we are interested in direct repeats we may take  work as a morphism and model the Watson-Crick complementarity:  and ;  when we are interested in inverted repeats in the genetic sequence we may take  work as an antimorphism, still defined by the Watson-Crick complementarity. It is not hard to see that our algorithms can also be adapted in a straightforward manner to work in the context of such gapped pseudo-repeats.


\acknowledgements
The authors thank the anonymous referees of this paper, as well as those of the conference papers which we extend here, for their valuable remarks, suggestions, and comments, that improved the quality of this manuscript. The work of Florin Manea was supported by the DFG grant 596676.


\nocite{*}
\bibliographystyle{abbrvnat}
\bibliography{f_periodic_old}
\label{sec:biblio}

\end{document}
