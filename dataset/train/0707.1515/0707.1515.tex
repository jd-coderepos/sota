\documentclass[12pt]{article}
\author{Gun Srijuntongsiri\thanks{Sirindhorn International Institute of Technology, 131 Moo 5, Tiwanont Road,
Bangkadi, Muang, Pathumthani, 12000, Thailand. Email:
gun@siit.tu.ac.th.},
Stephen A. Vavasis\thanks{MC 6054, University of Waterloo, 200
University Avenue W., Waterloo, ON N2L 3G1, Canada. Email:
vavasis@math.uwaterloo.ca.}}
\title{Properties of polynomial bases used in a line-surface intersection algorithm\thanks{Supported in part by NSF DMS 0434338 and NSF CCF 0085969.}}
\date{\today}

\tolerance=9999


\bibliographystyle{plain}

\usepackage{amsmath, amsthm, amssymb,graphicx,subfig}

\begin{document}
\maketitle
\newcommand{\cond}[1]{\mathop{\rm{cond}}(#1)}
\newcommand{\norm}[1]{\left\|#1\right\|}
\newcommand{\normtwo}[1]{\left\|#1\right\|_2}
\newcommand{\abs}[1]{\left|#1\right|} \newcommand{\norma}[1]{\left\|#1\right\|}   \newcommand{\inv}[1]{#1^{-1}}
\newcommand{\nchoosek}[2]{\left(\begin{array}{c} #1\\ #2 \end{array} \right)}

\newtheorem{thm}{Theorem}[section]
\newtheorem{cor}[thm]{Corollary}
\newtheorem{lemma}[thm]{Lemma}
\newtheorem{prop}{Proposition}[thm]

\theoremstyle{remark}
\newtheorem{rem}[thm]{Remark}

\begin{abstract}
In \cite{srijuntongsiri_lsi}, Srijuntongsiri and Vavasis propose
the \emph{Kantorovich-Test Subdivision algorithm}, or KTS, which is
an algorithm for finding all zeros of a polynomial system in a bounded region
of the plane.  This algorithm can be used to find the intersections between a
line and a surface.  The main features of KTS are that it can operate on
polynomials represented in any basis that satisfies certain
conditions and that its efficiency has an upper bound
that depends only on the conditioning of the problem and the choice of
the basis representing the polynomial system.

This article explores in detail the dependence of the efficiency of the KTS algorithm on the choice of basis.
Three bases are considered: the power, the Bernstein, and the Chebyshev bases.
These three bases satisfy the basis properties required by KTS.
Theoretically, Chebyshev case has the smallest upper bound on its running time.
The computational results, however, do not show that Chebyshev case performs
better than the other two.
\end{abstract}

\section{The line-surface intersection problem and the required basis properties}
\label{section_basis_prop}

Let , \ldots,  denote a basis for the set of
univariate polynomials of degree at most .  For example,
the power basis is defined by .  The line-surface
intersection problem can be reduced to the problem
of finding all zeros of

where   denote the coefficients \cite{srijuntongsiri_lsi}.

For this article, let the
notation  refer specifically to infinity
norm.  Other norms are explicitly notated so.
The \emph{Kantorovich-Test Subdivision algorithm} (KTS
in short), proposed by Srijuntongsiri and Vavasis \cite{srijuntongsiri_lsi},
can be used to solve (\ref{maineq}).
KTS works with any polynomial basis 
provided that the following properties hold:
\begin{enumerate}
\item There is a natural interval  that is the domain for the polynomial.
In the case of Bernstein polynomials, this is , and in the case of power and
Chebyshev polynomials, this is .

\item It is possible to compute a bounding polytope  of , where  and  for any , that satisfies the following
properties: \label{bounding_prop}
\begin{enumerate}
\item Determining whether  can be done efficiently
(ideally in  operations).

\item The polytope  is affinely invariant. In other words,
the bounding polytope of 
 is  for any nonsingular matrix
 and any vector .

\item For any ,

where  is a function of  and .
\label{prop_theta}

\item If , then the endpoints of  can be computed efficiently (ideally in  time).
\label{prop_endpoint}
\end{enumerate}

\item It is possible to reparametrize with  the surface
, where  and .
In other words, it is possible (and efficient) to compute the polynomial
 represented in the same basis such that .

\item Constant polynomials are easy to represent. \label{constant_poly_easy}

\item Derivatives of polynomials are easy to determine in the same basis. (preferably in  operations).
\label{prop_deriv}
\end{enumerate}
We are generally interested in the case where .  In this case, we call  a bounding polygon.  Recall that 
is a bounding polygon of  if and only if  implies .

\section{The Kantorovich-Test Subdivision algorithm}

The description of KTS, as well as the definitions of
the quantities mentioned in the description, are given below.
More details can be found in \cite{srijuntongsiri_lsi}.

For a given zero  of polynomial ,
let  and 
be quantities satisfying the conditions that, first,  is the smallest Lipschitz constant
for , i.e.,

and, second,

Define

where  is as in (\ref{thetadef}).
Define  to be
the smallest nonnegative constant  satisfying

where

Denote  as the maximum of
 and all 

Finally, define the condition number of  to be


We define the \emph{Kantorovich test} on a region  as the application of Kantorovich's Theorem on
the point  using  as the
domain (refer to \cite{deuflhard, kantorovich} for the statement of
Kantorovich's Theorem).  The region  passes the Kantorovich
test if  and .

The other test KTS uses is the exclusion test. For a
given region , let  be the polynomial in the basis
 that reparametrizes with  the
surface defined by  over .  The region  passes the
\emph{exclusion test} if the bounding polygon of  excludes the origin.

Having defined the above prerequisites, the description of KTS
can now be given.

\begin{flushleft}
\textbf{Algorithm KTS}:
\end{flushleft}
\begin{itemize}
\item Let  be a queue with  as its only entry. Set .
\item Repeat until 
\begin{enumerate}
\item Let  be the patch at the front of .  Remove  from .
\item If  for all ,
\begin{itemize}
\item Perform the exclusion test on 
\item If  fails the exclusion test,
\begin{enumerate}
\item Perform the Kantorovich test on 
\item If  passes the Kantorovich test,
\begin{enumerate}
\item Perform Newton's method starting from  to find a zero .
\item If  for any  (i.e.,  has not been found previously),
\begin{itemize}
\item Compute  and its associated  by binary search.
\item Set .
\end{itemize}
\end{enumerate}
\item Subdivide  along both  and -axes into four equal subregions. Add these subregions
to the end of .
\end{enumerate}
\end{itemize}
\end{enumerate}
\end{itemize}

The following theorem shows that the efficiency of KTS has an upper bound
that depends only on the conditioning of the problem and the choice of
the basis.
\begin{thm}
\label{thm3} Let  be a polynomial system in basis
 in two dimensions with generic coefficients
whose zeros are sought.  Let  be a patch under
consideration during the course of the KTS algorithm. The
algorithm does not need to subdivide  if

\begin{proof} See \cite{srijuntongsiri_lsi}.
\end{proof}
\end{thm}
\begin{flushleft}
\textbf{Remark:} Both terms in the bound on the right-hand side of (\ref{thm3ass}) are
increasing as a function of .
Therefore, our theorem predicts that the KTS algorithm will be more efficient
for  as small as possible (close to 1).
\end{flushleft}

\section{Properties of the power, Bernstein, and Chebyshev bases}

As mentioned above, the basis used to represent the polynomial
system must satisfy the properties listed in Section
\ref{section_basis_prop} for KTS to work efficiently. Three bases,
the power, Bernstein, and Chebyshev bases are examined in detail.
The power basis for polynomials of degree  is 
. The Bernstein basis is  .
The Chebyshev basis is   ,
where  is the Chebyshev polynomial of the first kind
generated by the recurrence relation

Another way to define the Chebyshev polynomials of the first kind
is through the identity

This second definition shows, in particular, that all zeros of 
lies in .  It also shows that  for any .

The rest of this article shows that the power, Bernstein, and Chebyshev
bases all satisfy these basis properties.  The values 's of
the three bases and their corresponding bounding polygons are also
derived as these values dictate the efficiency
of KTS operating on such bases.  The upper bound of the efficiency of KTS
is lowest when it operates on the basis with the smallest .

\subsection{Bounding polygons}

\label{section_bounding_polygon} The choices of 
and  and the definitions of bounding polygons of the surface
, where  is represented
by one of the three bases, that satisfy the required properties
are as follows: For Bernstein
basis, the convex hull of the coefficients (control points), call
it , satisfies the requirements for  and .  The
convex hull  can be described as

For power and Chebyshev bases, the bounding polygon

satisfies the requirements for  and .  Note that
 is a bounding polygon of  in the Chebyshev case since 
for any  and any .
Determining whether  is done by solving a small linear programming problem.
To determine if ,
the convex hull is constructed by conventional method and is tested if
it contains the origin.

The affine and translational invariance of  and 
for their respective bases can be verified as follows:  Let

For the Bernstein basis,
by using the property that , it is seen that
 for all 's.  Therefore, the bounding polygon of
 is


For the power and the Chebyshev bases, note that 
for both bases.  Hence,  and  for
.  The bounding polygon of  for this case is



\subsection{The size of the bounding polygons compared to the size of the bounded surface}

Item \ref{prop_theta} of the basis properties in effect ensures that the bounding polygons
are not unboundedly larger than the actual surface itself lest the bounding polygons
lose their usefulness.  The value  also can be used as a measure of the
tightness of the bounding polygon.  Recall from Theorem \ref{thm3} that the
efficiency of KTS depends on .

Since the bounding polygons  and  are defined by the coefficients of ,
our approach to derive  is to first derive , a function of  and , satisfying

for any coefficient  of .
But the following lemma shows that one needs only derive
the equivalent of  for univariate polynomial to derive  itself.

\begin{lemma}
\label{uni_theta_to_bi}
Assume there exists a function  such that

for any  , and any univariate polynomial .
Then

for any   , and any
bivariate polynomial .
\begin{proof}




Let  be an arbitrary bivariate polynomial.  For any , define .  Applying (\ref{asuni}) to  yields

for any .  Let .  Define .  Applying (\ref{asuni}) to  yields

for any .  Consequently, by combining (\ref{e1}) and (\ref{e2}), \\ .
\end{proof}
\end{lemma}

We proceed to derive  of the three bases, starting with the Bernstein basis.
The following lemma regarding the product
of two polynomials in Bernstein basis is needed to find 
for Bernstein case.

\begin{lemma}
\label{productbez} Let

and

Then

where

\begin{proof}
Straightforward arithmetic shows that

Taking absolute value on both sides and bounding  (resp.
) with  (resp. ) gives

Recall the combinatorial identity

Hence, the lemma follows.
\end{proof}
\end{lemma}

With the above lemma, we are ready to derive  of the Bernstein basis.

\begin{thm}
\label{bibound} Let  be a polynomial system

where . The norm of the coefficients
can be bounded by

where

\end{thm}

\begin{flushleft}
\textbf{Remark.} An inequality in the other
direction, namely, that

is a well-known consequence of the convex hull property of
Bernstein polynomials \cite{farin}.
\end{flushleft}

\begin{proof}
By definition of infinity norm, it suffices to prove the lemma for
the case .  Therefore, it is assumed that
 for the rest of this proof.

Let  . Define a matrix  having element

Define the vectors  and

Observe that

We claim that  is invertible. In particular, we show that the
linear system  has solution for any arbitrary . Due to the definition of , solving
the system  is equivalent to finding the coefficients
of the polynomial

with the property that , ,
\ldots, .  The polynomial  satisfying such
property is the Lagrange interpolant

Transforming (\ref{lagint}) to the Bernstein basis
yields the solution .

Knowing that  is invertible, we multiply both sides of
(\ref{abf}) by ,

and hence, for any ,

Comparing (\ref{ceq}) to (\ref{beforec}), it is seen that the
final step is to show that .

Observe that the th column of  is , where
 denotes the th column of the identity matrix. Let
 be a polynomial in the Bernstein basis and let  be its coefficients. With
similar reasoning as the above,

But (\ref{bbb}) implies that the th column of ,
, are the coefficients of  such that, for
,

The following Lagrange interpolant 
satisfies (\ref{gcon}):

Note that each term of the product in (\ref{lastg}) is a polynomial in
Bernstein basis with coefficients   and .
Applying Lemma \ref{productbez} to (\ref{lastg}) shows
that

Since (\ref{bp}) holds for any column  of ,
the lemma follows.
\end{proof}

Next is the derivation of  of the Chebyshev basis.  The following
identity is useful for this derivation:

for , where   are the  zeros of .

\begin{thm}
\label{chebbound} Let  be a polynomial system

where . The norm of the coefficients
can be bounded by

\end{thm}
\begin{proof}
By definition of infinity norm, it suffices to prove the lemma for
the case .  Therefore, it is assumed that
 for the rest of this proof.

Let   be the  zeros of ,
which lie in . Define a matrix  having element

Define the vectors  and

Observe that

By (\ref{relation_zeros_cheb}),

which implies that  is invertible and

The equation (\ref{aat}) implies

Finally, from (\ref{abf_cheb}) and (\ref{normAi}),

\end{proof}

Last is the power basis.  Our approach to derive  of power basis
is to derive the relationship between the coefficients of
a polynomial in power basis and the coefficients of the same
polynomial but written in Chebyshev basis.  By using this relationship
and Theorem \ref{chebbound},  of the power basis can be computed.

\begin{lemma}
\label{power_cheb_relation}
Let  be a univariate polynomial such that

In other words,  are the coefficients of  when written in the power
basis and  are the coefficients of  when written in the Chebyshev basis.
Then

for any .
\begin{proof}
Let  be the -by- matrix such that

where  and .  Note that

Recall the recurrence relation .
It follows from this recurrence that

That is, when  is written in the power basis, the resulting
coefficients (of power basis) is less than or equal to .  The
inequality (\ref{d1}) can be verified by induction on the recurrence
relation.  Since the entries in the th column of  is
bounded by , we have, from geometric sum,

The lemma follows from .
\end{proof}
\end{lemma}
\begin{thm}
\label{powerbound} Let  be a polynomial system

where . The norm of the coefficients
can be bounded by

\end{thm}
\begin{proof}
Follow directly from Theorem \ref{chebbound} and Lemma \ref{power_cheb_relation}.
\end{proof}

Having  for each of the three bases, the values of  for
the three bases can now be derived.

\begin{cor}
Let

where  .
Let  be the convex hull of . Then, for any ,

\end{cor}
\begin{proof}
By the convex hull property of Bernstein polynomials, 
for any .
The corollary then follows from Theorem \ref{bibound} and Lemma \ref{uni_theta_to_bi}.
\end{proof}

\begin{cor}
Let

where  .
Let

Then, for any ,

\end{cor}
\begin{proof}
For any ,

The corollary then follows from Theorem \ref{powerbound} and Lemma \ref{uni_theta_to_bi}.
\end{proof}

\begin{cor}
Let

where  .
Let

Then, for any ,

\end{cor}
\begin{proof}
For any ,

The corollary then follows from Theorem \ref{chebbound} and Lemma \ref{uni_theta_to_bi}.
\end{proof}

\section{Relationship between the bounding polygon of the power basis and that of Chebyshev basis}
\label{section_cheb_better_than_power} Let  denote the
bounding polygon  computed from the power basis
representation of a polynomial and  denote  computed
from the Chebyshev basis representation of it. The results from
previous section show that the value  of  is
smaller than  of . This only implies that the worst
case of  is better than the worst case of .
Comparing the values of 's of the two does not indicate
that  is always a better choice than  for every
polynomial.  The following results show, however, that  is,
in fact, always a better choice than . Specifically, this
section shows that for any given polynomial, its bounding polygon
 is a subset of its bounding polygon .

The following two lemmas show that when representing monomials
 in Chebyshev basis, each coefficient is nonnegative, and the
sum of all coefficients are exactly 1.  These results are useful
in relating  to .

\begin{lemma}
\label{lem_nonnegu} Let 's (; ) be the numbers satisfying .  Then

for any  and any .
\begin{proof}
We prove the lemma by induction on .  The base cases  and
 are trivial.  For the inductive step, for any ,

By (\ref{cheb_recurrence}) and noting that ,

Hence,

But since  for any  by the induction
hypothesis, (\ref{ukplus1def}) shows that  for
any .
\end{proof}
\end{lemma}

\begin{lemma}
\label{lem_sumeq1}
Let 's (; ) be the numbers satisfying . Then

for any  and any .
\begin{proof}
We prove the lemma by induction on .  The base cases  and
 are trivial.  For the inductive step, the same reasoning as
in the proof of Lemma \ref{lem_nonnegu} shows that  is
as in (\ref{ukplus1def}) for any .  Therefore,

by the induction hypothesis.
\end{proof}
\end{lemma}

\begin{thm}
Let  be a bivariate
polynomial. Its bounding polygon  is a subset of its
bounding polygon .
\begin{proof}
Let , where  (; ) are the
coefficients of  when written in the power basis and  (; ) are the
coefficients of  when written in the Chebyshev basis. Let
's (; ) be the numbers
satisfying .  Hence,

Therefore, .  This means that  can be written as

But since ,

By Lemma \ref{lem_nonnegu} and Lemma \ref{lem_sumeq1}, it is seen
that .  In addition, using the fact that , for any  and any , together
with Lemma \ref{lem_nonnegu} and Lemma \ref{lem_sumeq1}, it is
seen that \\ \\
.  Therefore, .
\end{proof}
\end{thm}


\subsection{Reparametrization}
The last nontrivial basis property that warrants detailed discussion
is the issue of efficient reparametrization.
Reparametrizing polynomials
in power basis is straightforward from the \emph{binomial} theorem.
Polynomials in other bases, on
the other hand, may not be as simple to reparametrize.  The
details of the process for polynomials in Bernstein and Chebyshev
bases are covered in this section.

\subsubsection{Reparametrization of polynomials in Bernstein
basis}  There is more than one algorithm to compute the
reparametrization with  of a bivariate polynomial in
Bernstein basis. We describe one method here. Our method makes use
of a program that, given 's, , , , , ,
, , and , computes 's satisfying

Such conversion can be done in  by
generalizing Horner's rule. We leave the details of the conversion
to the reader. Let  denote . To compute the coefficients
 of , the -reparametrized surface
of , first substitute  and  into , yielding

Substituting  and 
into (\ref{l2}) yields

where (\ref{l4}) is obtained from (\ref{l3}) by
the conversion program mentioned above. Substituting  and  back
into (\ref{l4}) to see that

Therefore,  are the
control points of  where .

\subsubsection{Reparametrization of polynomials in Chebyshev
basis}  Let , ,  and  be scalar constants.  The
reparametrization with  of a bivariate polynomial in
Chebyshev basis can be computed if the values of 's
 satisfying

and the values of 's  satisfying

are known.  Note that

which is adequate to find the reparametrization.  The values of
, , , and  are determined by the -domain of the
surface to be reparametrized.

To compute 's, observe that for , by
(\ref{cheb_recurrence}),

and

The equalities (\ref{c1}), (\ref{c2}), and (\ref{c3}) yield a
recurrence relation of 's that can be used to
compute their values.  The values of 's can be computed
similarly.

\section{Computational results}

Three versions of KTS algorithms are implemented in Matlab; one
operating on the polynomials in power basis, one on Bernstein
basis, and one on Chebyshev basis.  They are tested against a
number of problem instances with varying condition numbers.  Most
of the test problems are created by using the normally distributed
random numbers as the coefficients 's of  in Chebyshev
basis.  For some of the test problems especially those with high
condition number, some coefficients are manually entered.  The
resulting Chebyshev polynomial system is then transformed to the
equivalent system in the power and the Bernstein bases. Hence the
three versions of KTS solve the same polynomial system and the
efficiency of the three are compared. The degrees of the test
polynomials are between biquadratic and biquartic.

For the experiment, we use the algorithm by J\'{o}nsson and
Vavasis \cite{jonsson} to compute the complex zeros required to
estimate the condition number. Table \ref{table_ba} compares the
efficiency of the three versions of KTS for the test problems
with differing condition numbers. The total number of subpatches
examined by KTS during the entire computation and the width of
the smallest patch among those examined are reported. The results
do not show any one version to be particularly more efficient than
the others although the Chebyshev basis has better theoretical
bound than the other two.
\begin{table}
\caption{Comparison of the efficiency of KTS algorithm
operating on the power, the Bernstein, and the Chebyshev bases.
The number of patches examined during the course of the algorithm
and the width of the smallest patch examined are shown for each
version of KTS. \label{table_ba} }
\begin{center}
\begin{tabular}{|r|r|r|r|r|r|r|}
\hline
 & \multicolumn{2}{c}{Power basis} \vline& \multicolumn{2}{c}{Bernstein basis}\vline & \multicolumn{2}{c}{Chebyshev basis}\vline\\
\cline{2-7}
 & Num. of & Smallest & Num. of & Smallest & Num. of & Smallest\\
& \multicolumn{1}{c}{patches}\vline &
\multicolumn{1}{c}{width}\vline &
\multicolumn{1}{c}{patches}\vline &
\multicolumn{1}{c}{width}\vline
& \multicolumn{1}{c}{patches}\vline & \multicolumn{1}{c}{width}\vline\\
\hline \hline
 & 29 & .125 & 17 & .0625 & 21 & .125 \\
 & 13 & .125 & 17 & .0625 & 13 & .125 \\
 & 49 & .0625 & 21 & .0625 & 45 & .0625 \\
 & 97 & .0313 & 65 & .0313 & 85 & .0313 \\
 & 89 & .0313 & 81 & .0313 & 89 & .0313 \\
\hline
\end{tabular}
\end{center}
\end{table}

Since the types of test polynomials may affect the relative
efficiency of the three versions of KTS, another experiment is
performed on degree  univariate polynomials generated by
different methods.  Since Section
\ref{section_cheb_better_than_power} shows that the Chebyshev
basis always gives tighter bounding polygons than the power basis,
this experiment only compares between the Chebyshev and Bernstein
bases.  Table \ref{table_bb} and Table \ref{table_bc} show the
results of this experiment.  The polynomials are generated as
follows. The ``rand" polynomials are generated by interpolating
points whose x-coordinates are evenly spaced between  and ,
inclusive, and whose y-coordinates are normally distributed random
numbers. The ``sin" ones are interpolations of  at
evenly spaced points between  and , inclusive, where 
and  are normally distributed random numbers.  The ``sin-L"
ones are the same as the ``sin" ones except that least-squares
interpolation is used instead. The ``sinw" (resp. ``sinw-L") ones
are generated in the same way as the ``sin" (resp. ``sin-L") ones
but with the function . Table \ref{table_bb} compares
the number of test polynomials of each type where one basis yields
tighter bounding intervals than the other.  Table \ref{table_bc}
shows the number of test polynomials of each type that bounding
intervals of each basis have at least one endpoint exactly at the
boundary of the ranges of the polynomials. The results show that
the Chebyshev basis is decidedly better for ``rand" polynomials,
is about the same for ``sin" ones, but is worse for the rests of
the polynomials than the Bernstein basis.
\begin{table}
\caption{The numbers of test polynomials out of  that
bounding intervals associated with the Bernstein basis is tighter
than the those associated with the Chebyshev basis, and \emph{vice
versa}. \label{table_bb} } \begin{center}
\begin{tabular}{|r|r|r|}
\hline Poly. type & Num. that Bernstein is tighter & Num. that Chebyshev is tighter\\
\hline \hline
rand & 1 & 999 \\
sin & 963 & 37 \\
sin-L & 960 & 40 \\
sinw & 436 & 564 \\
sinw-L & 998 & 2 \\
\hline
\end{tabular}
\end{center}
\end{table}

\begin{table}
\caption{The numbers of test polynomials out of  that
bounding intervals associated with the Bernstein basis and those
associated with the Chebyshev basis having at least one endpoint
exactly at the boundary of the ranges of the polynomials.
\label{table_bc} }
\begin{center}
\begin{tabular}{|r|r|r|}
\hline Poly. type & Num. Bernstein with & Num. Chebyshev with \\
& \multicolumn{1}{c}{ exact endpoint}\vline & \multicolumn{1}{c}{ exact endpoint}\vline  \\
 \hline \hline
rand & 2 & 13 \\
sin & 965 & 0 \\
sin-L & 972 & 0\\
sinw & 330 & 0 \\
sinw-L & 999 & 658 \\
\hline
\end{tabular}
\end{center}
\end{table}

\section{Conclusion}

Three common bases, the power, the Bernstein, and the Chebyshev
bases, are shown to satisfy the required properties for KTS to
perform efficiently. In particular, the values of  for the
three bases are derived. These values are used to calculate the
time complexity of KTS when that basis is used to represent the
polynomial system.  The Chebyshev basis has the smallest 
among the three, which shows that using KTS with the Chebyshev
basis has the smallest worst-case time complexity.  The
computational results, however, show no significant differences
between the performances of the three versions of KTS operating
on the three bases. It appears that, in average case, choosing any
of the three bases do not greatly affect the efficiency of KTS.
The experiment on univariate polynomials show that the Bernstein
basis is more suitable for certain types of polynomials while the
Chebyshev basis is better suited for other types.

\bibliography{basis}


\end{document}
