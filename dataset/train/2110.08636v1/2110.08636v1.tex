\section{Results} \label{sec:resutls}
In this section, we present the results of our DPC model on several well-established datasets and compare the model's performance to recent state-of-the-art techniques for shape matching. Additionally, we evaluate the run time of the different methods and discuss ablation experiments that validate the design choices in our method.



\begin{figure*}[tb!]
\begin{center}
\begin{tabular}{c c c c c c}
\multicolumn{6}{c}{\includegraphics[width=0.96\linewidth]{figures/comparison_shrec/comparison_shrec.pdf}} \\
\whitetext{a}Reference target & \whitetext{}3D-CODED~\cite{groueix20183dcoded} & \whitetext{aa}Elementary~\cite{deprelle2019learning} & \whitetext{a}CorrNet3D~\cite{zeng2020corrnet3d} & \whitetext{aaa}DPC (ours) & \whitetext{aa}Ground-truth \\
\end{tabular}
\end{center}
\caption{\textbf{Visual comparison for human shapes for a SHREC'19 test pair.} The training was done on the SURREAL dataset. Previous methods suffer from correspondence errors, such as matching the knee to the hand or mixing between the limbs (marked with arrows and zoomed-in). In contrast, our method produces an accurate result, which is close to the ground truth correspondence map (color-coded).}
\label{fig:comp_shrec}
\end{figure*}

%
 \begin{figure}[tb!]
\begin{center}
\includegraphics[width=\columnwidth]{figures/surreal_on_shrec/surreal_on_shrec.pdf}
\caption{{\bfseries Correspondence accuracy for human point clouds.} The methods were trained on the SURREAL dataset and evaluated on the official SHREC'19 test pairs. The number of training shapes (in thousands) is stated in the squared brackets. Our method achieves a substantial performance gain compared to the alternatives while being trained on much less training data.}
\vspace{-5pt}
\label{fig:surreal_on_shrec}
\end{center}
\end{figure}
 
\subsection{Experimental Setup} \label{subsec:experimental_setup}
\noindent \textbf{Datasets} \quad To demonstrate the flexibility of our method, we evaluate it on both human and non-human datasets. For human figures, we use the SURREAL training dataset of 3D-CODED~\cite{groueix20183dcoded}, consisting of 230000 training shapes. This is a synthetic dataset generated from the parametric human model SMPL~\cite{loper2015smpl}. During training, we select shapes from the dataset at random and use them as training pairs. For testing, we follow the evaluation protocol of previous works~\cite{groueix20183dcoded, deprelle2019learning, zeng2020corrnet3d} and use the challenging SHREC'19~\cite{melzi2019matching} dataset. This dataset contains 44 real human scans, paired into 430 annotated test examples.





For non-human shapes, SMAL~\cite{zuffi20173dmenagerie} and TOSCA~\cite{bronstein2008numerical} datasets are adopted for training and evaluation, respectively. SMAL is a parametric model for animals: cat, dog, cow, horse, and hippo. We use the model to create 2000 examples in various poses for each animal type and obtain a train set of 10000 shapes in total. For training, we randomly select shape pairs from within the same animal category. The TOSCA collection includes 80 objects of animals and humans. Different from SMAL, it is not a model-based dataset and also includes animal species other than those in SMAL. We consider the 41 animal figures from TOSCA and pair shapes from the same category to form a test set of 286 examples.

\begin{table}[tb!]
\small
\centering
\begin{tabular}{@{ } l c c c c c @{}}
\toprule
       & & \multicolumn{2}{c}{\textbf{SURREAL/}} & \multicolumn{2}{c}{\textbf{SHREC/}} \\
       & & \multicolumn{2}{c}{\textbf{SHREC}}    & \multicolumn{2}{c}{\textbf{SHREC}}  \\
       \cmidrule(lr){3-4} \cmidrule(lr){5-6}
Method & Input  & \textit{acc}  & \textit{err}  & \textit{acc}  & \textit{err} \whitetext{a}\: \\
\midrule
\graytxt{SURFMNet~\cite{roufosse2019unsupervised}} & \graytxt{LBO} & \graytxt{4.3\%} & \graytxt{0.3} & \graytxt{5.9\%} &  \graytxt{0.2} \\
\graytxt{GeoFMNet~\cite{donati2020deep}} & \graytxt{LBO} & \graytxt{8.2\%} & \graytxt{0.2} & \graytxt{*} & \graytxt{*} \\
\midrule
Diff-FMaps~\cite{marin2020correspondence} & Point & 4.0\% & 7.1 & * & *        \\
3D-CODED~\cite{groueix20183dcoded}        & Point & 2.1\% & 8.1 & * & *        \\
Elementary~\cite{deprelle2019learning}    & Point & 2.3\% & 7.6 & * & *        \\
CorrNet3D~\cite{zeng2020corrnet3d}        & Point & 6.0\% & 6.9 & 0.4\% & 33.8 \\
DPC (ours) & Point & \textbf{17.7\%} & \textbf{6.1} & \textbf{15.3\%} & \textbf{5.6} \\
\bottomrule
\end{tabular}
\vspace{0.1cm}
\caption{\textbf{Accuracy and error.} We evaluate the accuracy at 1\% tolerance (\textit{acc}, in percentage) and the average correspondence error (\textit{err}, in centimeters) for two train/test settings of human datasets. Higher accuracy and lower error reflect a better result. Spectral methods on meshes are grayed out to emphasize the difference in their operation requirements compared to ours. We achieve better results than the other point-based methods.}
\label{tbl:surreal_and_shrec}
\end{table}





%
 






The number of points in the shapes substantially varies from one dataset to another. Thus, to have a shared baseline, we randomly sample  points from each shape to create point clouds for training and evaluation, as done in CorrNet3D work~\cite{zeng2020corrnet3d}. In the supplementary, we also report results for higher point cloud resolutions.

\medskip

\noindent \textbf{Evaluation metrics} \quad A common evaluation metric for shape correspondence is the average geodesic error~\cite{litany2017deep, donati2020deep}, which requires knowing the point adjacency matrix. However, as we are in the realm of point clouds, we assume that this information is unavailable and adopt a Euclidean-based measure instead~\cite{zeng2020corrnet3d}. For a pair of source and target shapes , the correspondence error is defined as:


\noindent where  is the ground truth corresponding point to \footnote{Ground truth data is only used during testing DPC, not during its training.}. Additionally, we measure the correspondence accuracy, defined as:


\noindent where  is the indicator function,  is the maximal Euclidean distance between points in , and  is an error tolerance. We note that these evaluation metrics are analogous to the ones used for mesh-represented shapes, with the geodesic distance replaced by the Euclidean distance.

\medskip

\noindent \textbf{Implementation details} \quad We implement our method in PyTorch~\cite{paszke2017automatic} and adapt the open-source DGCNN~\cite{wang2019dynamic} implementation for our feature extractor module. For the cross and self-construction operations and the mapping loss, we use a neighborhood size of . , , and  in Equation~\ref{eq:total_loss} are set to , , and , respectively. Additional implementation details are given in the supplementary material. 

\medskip

\noindent \textbf{Baseline methods} \quad We contrast our method with the recent state-of-the-art point-based matching techniques Diff-FMaps~\cite{marin2020correspondence}, 3D-CODED~\cite{groueix20183dcoded}, and Elementary Structures work~\cite{deprelle2019learning}. These methods require ground-truth matching supervision. Additionally, we compare with the most recent CorrNet3D work~\cite{zeng2020corrnet3d} that learns point cloud correspondence in an unsupervised manner. For the completeness of the discussion, we also include in our evaluation the unsupervised SURFMNet~\cite{roufosse2019unsupervised} and the supervised GeoFMNet~\cite{donati2020deep} methods for meshes. For all the examined baselines, training and evaluation are done using their publicly available official source code.













\begin{table}[tb!]
\small
\centering
\begin{tabular}{@{ } l c c c @{ }}
\toprule
Method & Pre-process & Inference & Total \\
\midrule
\graytxt{SURFMNet~\cite{roufosse2019unsupervised}} & \graytxt{1593} & \graytxt{163} & \graytxt{1756} \\
\graytxt{GeoFMNet~\cite{donati2020deep}}           & \graytxt{1997} & \graytxt{215} & \graytxt{2212} \\
\midrule
Diff-FMaps~\cite{marin2020correspondence}     & 0 & 121.7  & 121.7 \\
3D-CODED~\cite{groueix20183dcoded}            & 0 & 32.1  & 32.1 \\
Elementary~\cite{deprelle2019learning}        & 0 & 35.3  & 35.3 \\
CorrNet3D~\cite{zeng2020corrnet3d}            & 0 & 175.4 & 175.4 \\
DPC (ours)                                    & 0 & \textbf{26.3} & \textbf{26.3} \\
\bottomrule
\end{tabular}
\vspace{0.1cm}
\caption{\textbf{Processing time comparison.} We report the time requirements (in milliseconds) for different methods for the correspondence computation. Our method has the best time performance, which is about  faster compared to the spectral methods~\cite{roufosse2019unsupervised, donati2020deep}.}
\label{tbl:time_analysis}
\end{table}
 
\subsection{Evaluation on Human Datasets} \label{subsec:human_results}
\noindent \textbf{Cross-dataset generalization} \quad Figure~\ref{fig:surreal_on_shrec} presents the correspondence accuracy (Equation~\ref{eq:corr_acc}) for point-based methods trained on SURREAL and evaluated on the SHREC'19 test set. For a fair comparison, we report the results without any post-processing and include methods that operate on point sets and do not require the additional connectivity information, nor the intense eigendecomposition pre-processing step, as the spectral approaches demand. As seen in the figure, our method outperforms the competing approaches by a large margin. For example, at a 5\% error tolerance, it achieves 50\% accuracy, an improvement of 23\% over CorrNet3D~\cite{zeng2020corrnet3d}. Visual examples in Figure~\ref{fig:comp_shrec} demonstrate the improved accuracy of our method compared to the previous ones.







Diff-FMaps~\cite{marin2020correspondence} has learned basis functions from the synthetic SURREAL data, which are less suitable for aligning the different SHREC'19 shapes. The other compared methods employ a learned reconstruction module as a proxy for point matches. This module requires a large amount of training data and limits the generalization capability to the unseen test dataset. In contrast, we take a spatial approach and exclude the point regression of the decoder. Instead, we replace it with our structured construction modules and concentrate on point feature learning for the correspondence task. It enables our method to be trained on only a small fraction (1\%) of 2000 SURREAL shapes, while the other methods utilize all the available 230000 instances.





\medskip

\noindent \textbf{Training on a small dataset} \quad To further demonstrate the ability of our method to learn discriminative point representations from a small amount of data, we train it on random shape pairs from the 44 human instances in SHREC'19. These pairs do not have matching annotations and are suitable only for unsupervised techniques. Table~\ref{tbl:surreal_and_shrec} reports the correspondence accuracy at 1\% tolerance, which represents a near-perfect hit, and the average correspondence error (Equation~\ref{eq:corr_err}) for training either on SURREAL or SHREC shapes and testing on the official 430 SHREC'19 pairs.





The spectral methods SURFMNet~\cite{roufosse2019unsupervised} and GeoFMNet~\cite{donati2020deep} show an outstanding result for the correspondence error. However, they are less accurate at 1\% tolerance. We believe that this is due to the projection of the vertex feature maps on the highly smooth spectral functions, which reduces the overall error but compromises the near-perfect accuracy. We also show in sub-section~\ref{subsec:time_analysis} that the spectral methods are approximately  slower compared to DPC in terms of total inference run-time, making them impractical for real-time usage. Among point-based approaches, we achieve the best results on both the accuracy and error measures. Notably, our method reaches a comparable performance when trained either on SURREAL or SHREC, where the latter contained only 44 shapes, two orders of magnitude less than the former (which includes 2000 shapes).



\begin{figure*}[tb!]
\begin{center}
\begin{tabular}{c c c c c c}


\includegraphics[width=0.14\linewidth]{figures/comparison_tosca/dpc/t_280_corr_fwd.png} & \includegraphics[width=0.14\linewidth]{figures/comparison_tosca/3dcoded/s_280_corr_fwd.png} & \includegraphics[width=0.14\linewidth]{figures/comparison_tosca/elementary/s_280_corr_fwd.png} & \includegraphics[width=0.14\linewidth]{figures/comparison_tosca/corrnet3d/s_280_corr_fwd.png} & \includegraphics[width=0.14\linewidth]{figures/comparison_tosca/dpc/s_280_corr_fwd.png} & \includegraphics[width=0.14\linewidth]{figures/comparison_tosca/dpc/s_280_gt_fwd.png} \\ 



Reference target & 3D-CODED~\cite{groueix20183dcoded} & Elementary~\cite{deprelle2019learning} & CorrNet3D~\cite{zeng2020corrnet3d} & DPC (ours) & Ground-truth \\
\end{tabular}
\caption{\textbf{Visual comparison for animal shapes from the TOSCA test set.} The training was done on the synthetic SMAL dataset. 3D-CODED and Elementary Structures produce a patchy result. CorrNet3D's output is noisy and contains outlier matches. In contrast, our method produces a smooth and accurate alignment between the animal point clouds (color-coded).}
\vspace{-15pt}
\label{fig:comp_tosca}
\end{center}
\end{figure*}
 \begin{figure}[tb!]
\begin{center}
\includegraphics[width=\columnwidth]{figures/smal_on_tosca/smal_on_tosca.pdf}
\caption{{\bfseries Correspondence accuracy for non-humans.} The compared works were trained on the SMAL dataset and tested on animal shapes from the TOSCA benchmark. Our DPC model outperforms the other methods by a large margin across all the error tolerance range.}
\vspace{-15pt}
\label{fig:smal_on_tosca}
\end{center}
\end{figure}

%
 
\subsection{Time Analysis} \label{subsec:time_analysis}
We evaluate the average processing time of different methods for computing the correspondence between a pair of shapes from the SHREC'19 test set. The measurements were done on an NVIDIA RTX 2080Ti GPU. Table~\ref{tbl:time_analysis} summarizes the results. The spectral methods~\cite{roufosse2019unsupervised, donati2020deep} require the time-consuming LBO-based spectral decomposition of each shape, which results in a long overall time duration. In contrast, DPC operates directly on raw input point clouds without any pre-processing and runs faster than the other spectral and point-based alternatives. Its inference time is only 26.3 milliseconds, providing a real-time processing rate of 38 point cloud pairs per second. To sum up, our method offers a sweet spot of strong generalization capabilities, along with real-time performance.

\subsection{Evaluation on Non-human Shapes} \label{subsec:non_human_results}
We demonstrate the flexibility of our method by applying it to the dense alignment of animal point sets. Similar to the evaluation for human figures, we examine its and the other methods' generalization power by training on the model-based SMAL dataset and testing on the diverse animal objects from the TOSCA set. Figure~\ref{fig:comp_tosca} shows visualizations and Figure~\ref{fig:smal_on_tosca} depicts the correspondence accuracy results.



Both 3D-CODED~\cite{groueix20183dcoded} and Elementary Structures~\cite{deprelle2019learning} rely on the deformation of a template shape to the source and target point clouds for deducing the correspondence map between them. In the SMAL dataset, this template takes the form of a standing cat. However, the TOSCA set includes substantially different poses and shapes, such as a howling wolf. Thus, these methods struggle to generalize to this test case.



CorrNet3D~\cite{zeng2020corrnet3d}, on the other hand, does not depend on a template shape and improves over 3D-CODED and Elementary Structures. Still, it includes a decoder module that is fitted to the characteristics of the SMAL data and compromises CorrNet3D generalization capability to TOSCA's animal objects. Our method neither uses a template nor a decoder component. Instead, it learns robust local point descriptors, which enables it to operate on shapes out of the training distribution. As visualized in Figure~\ref{fig:comp_tosca} and quantified in Figure~\ref{fig:smal_on_tosca}, our DPC consistently surpasses the performance of the alternatives for point cloud matching.

Lastly, we refer the reader to the supplementary for an evaluation on SMAL and TOSCA, where we present our accuracy at 1\% tolerance and the average correspondence error for these datasets as well. Since SURFMNet~\cite{roufosse2019unsupervised} and GeoFMNet~\cite{donati2020deep} are LBO-based architectures, they fail to be applied to the SMAL and TOSCA sets since these methods are numerically unstable under non-watertight or topology-intersected meshes, as present in the datasets.



\subsection{Ablation Study} \label{subsec:ablation_study}
In the supplementary, we present a thorough ablation study verifying the design choices in our DPC model. From the ablation study, we recognize that the local neighborhood for cross-construction contributes the most to the method's performance. While considering all target points for mapping a source point is a common approach in previous works~\cite{wang2019deep, zeng2020corrnet3d, eisenberger2021neuromorph}, we find it less effective, as it reduces our correspondence accuracy by 15.5\%. Instead, for each source point, we consider a local latent neighborhood in the target shape. It focuses the model on exploring only relevant candidates for matching and eases the learning process. Additionally, the ablation study highlights the importance of our self-construction module, which regularizes the learned point representation and is crucial for an accurate correspondence result. Without it, the performance drops by 14.3\%. For further details, please see the supplementary.



%
