\documentclass[10pt,journal,letterpaper]{IEEEtran}


\pdfoutput=1 

\usepackage{graphicx}
\usepackage{verbatim}
\usepackage{url}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage[latin1]{inputenc}
\usepackage{delarray}
\usepackage{subfigure}
\usepackage{setspace}
\usepackage{paralist}
\usepackage{enumerate}

\usepackage{hyperref}
\IEEEoverridecommandlockouts

\newtheorem{definition}{Definition}[section]
\newtheorem{lemma}{Lemma}[section]
\newtheorem{proposition}{Proposition}[section]
\newtheorem{conjecture}{Conjecture}[section]
\newtheorem{theorem}{Theorem}[section]
\newtheorem{observation}{Observation}
\newtheorem{example}{Example}[section]
\newtheorem{cexample}{Counter-example}[section]
\newtheorem{remarks}{Remarks}[section]
\newtheorem{corollary}{Corollary}[section]

\newcommand{\remove}[1]{}



\begin{document}
\title{Optimal Forwarding in Delay Tolerant Networks with Multiple Destinations}
\author{Chandramani~Singh,~\IEEEmembership{Student Member,~IEEE,}
Eitan~Altman,~\IEEEmembership{Fellow,~IEEE,}
Anurag~Kumar,~\IEEEmembership{Fellow,~IEEE,}\\
and~Rajesh~Sundaresan,~\IEEEmembership{Senior Member,~IEEE}
\thanks{This is an extended version of a paper that appeared in WiOpt~2011.}
\thanks{This work was supported by
the Indo-French Centre for the Promotion of Advanced
Research~(IFCPAR) Project 4000-IT-1, by DAWN~(an Associates
program of INRIA, France), and by the Department of Science 
and Technology, Government of India.}
\thanks{Chandramani~Singh, Anurag~Kumar and Rajesh~Sundaresan are with the Department of Electrical Communication Engineering
Indian Institute of Science Bangalore, India~(email: \{chandra,~anurag,~rajeshs\}@ece.iisc.ernet.in). Eitan~Altman is with INRIA, Sophia-Antipolis, France~(email: Eitan.Altman@sophia.inria.fr). }
}

\maketitle

\begin{abstract}

We study the trade-off between delivery delay and energy consumption
in a delay tolerant network in which a message~(or a file) has to be delivered to each of several
destinations by epidemic relaying. In addition to the destinations, there are
several other nodes in the network that can assist in relaying the message.
We first assume that, at every instant,
all the nodes know the number of relays carrying the
packet and the number of destinations that have received the packet. We formulate the problem
as a controlled continuous time Markov chain and derive the optimal closed loop control~(i.e., forwarding policy).
However, in practice, the intermittent connectivity in the network implies that the nodes may not have the required perfect knowledge
of the system state.
To address this issue, we obtain an ODE~(i.e., a deterministic fluid) approximation for the
optimally controlled Markov chain.
This fluid approximation also yields an asymptotically optimal open loop policy.
Finally, we evaluate the performance of the deterministic policy over finite networks.
Numerical results show that this policy performs close to the optimal closed loop policy.
\end{abstract}

\section{Introduction}

{\it Delay tolerant networks}~(DTNs)~\cite{comnet-dtn.fall03dtn-architecture}
 are sparse wireless ad hoc networks with highly mobile nodes.
In these networks, the link between any two nodes is up when these are
within each other's transmission range, and is down otherwise. In
particular, at any given time, it is unlikely that there is a complete route between a source and its
destination.


We consider a DTN in which a short message~(also referred to as a
{\it packet}) needs to be delivered to multiple~(say )
destinations. There are also  potential relays that do not
themselves ``want'' the message but can assist in relaying it to the
nodes that do. At time ,  of the relays have copies of the
packet. All nodes are assumed to be mobile. In such a network, a
common technique to improve packet delivery delay is {\it epidemic}
relaying~\cite{comnet-dtn.vahdat-becker00epidemic-routing}. We
consider a controlled relaying scheme that works as follows.
Whenever a node~(relay or destination) carrying the packet meets a
relay that does not have a copy of the packet, then the former has
the option of either copying or not copying. When a node that has
the packet meets a destination that does not, the packet can be
delivered.


We want to minimize the delay until a significant fraction (say ) of the destinations receive the packet;
we refer to this duration as {\it delivery delay}.
Evidently, delivery delay can be reduced if the number of carriers of
the packet is increased by copying it to relays. Such copying can not be
done indiscriminately, however, as every act of copying between two
nodes incurs a transmission cost. Thus, we focus
on the problem of the control of packet forwarding.

\noindent
{\bf Related work:} Analysis and control of DTNs with a single-source
and a single-destination has been widely studied. Groenevelt et
al.~\cite{comnet-dtn.groenevelt-etal05message-delay-mobile-networks}
modeled epidemic relaying and two-hop relaying using Markov chains.
They derived the average delay and the number of copies generated until
the time of delivery. Zhang et
al.~\cite{comnet-dtn.zhang-etal07epidemic-routing} developed a unified
framework based on ordinary differential equations~(ODEs) to study epidemic
routing and its variants.

Neglia and Zhang~\cite{ctrltheory-dtn.neglia-zhang06optimal-delay-power-tradeoff}
were the first to study the optimal control of relaying in
DTNs with a single destination and multiple relays. They
assumed that all the nodes have perfect knowledge of the number of nodes carrying the packet.
Their optimal closed loop control is a threshold policy - when a relay that does not have a copy
of the packet is met, the packet
is copied if and only if the number of relays carrying the packet is below a threshold.
Due to the assumption of complete knowledge, the reported performance is a lower bound for the cost in a real
system.

Altman et al.~\cite{stochctrl-dtn.altmanetal10monotone-forwarding-policies} addressed
the optimal relaying problem for a class of {\it monotone relay strategies} which
includes epidemic relaying and two-hop relaying. In particular,
they derived {\it static} and {\it dynamic} relaying policies.
Altman et al.~\cite{ctrltheory-dtn.altman-etal09decentralized-stochastic-control}
considered optimal discrete-time two-hop relaying. They also employed stochastic
approximation to facilitate online estimation of network parameters.
In another paper, Altman et al.~\cite{ctrltheory-dtn.altman-etal10optimal-activation-transmission-control} considered
a scenario where active nodes in the network continuously spend energy
while {\it beaconing}. Their paper studied the joint problem of node activation
and transmission power control. These works~(\cite{stochctrl-dtn.altmanetal10monotone-forwarding-policies,ctrltheory-dtn.altman-etal09decentralized-stochastic-control,ctrltheory-dtn.altman-etal10optimal-activation-transmission-control})
heuristically obtain fluid approximations for DTNs and study open
loop controls. Li et al.~\cite{stochctrl-dtn.lietal10optimal-opportunistic-forwarding}
considered several families
of open loop controls and obtain optimal controls within each family.


Deterministic fluid models expressed as ordinary differential equations have been used to approximate
large Markovian systems. Kurtz~\cite{stochproc.kurtz70limits-markov-processes} obtained sufficient
conditions for the convergence of Markov chains to such fluid limits. Darling~\cite{stochproc.darling02fluid-limits} and subsequently, Darling and Norris~\cite{stochproc.darling-norris08differential-equation-approximations} generalized Kurtz's results. Darling~\cite{stochproc.darling02fluid-limits} considers the scenario when the  Markovian system satisfies the conditions in~\cite{stochproc.kurtz70limits-markov-processes} only over a subset. He shows that the scaled processes converge to a fluid limit until they exit from this subset. Darling and Norris~\cite{stochproc.darling-norris08differential-equation-approximations} generalize the conditions for convergence, e.g., uniform convergence of the mean drifts of Markov chains and Lipschitz continuity of the limiting drift function, prescribed in~\cite{stochproc.kurtz70limits-markov-processes}.  Gast and Gaujal~\cite{stochctrl.gast-gaujal10mean-field-nonsmooth} address the scenario where the limiting drift functions are not Lipschitz continuous. They prove that under mild conditions, the stochastic system converges to the solution of a differential inclusion. Gast et al.~\cite{stochctrl.gast-etal10mean-field-MDPs} study an optimization problem on a large Markovian system. They show that solving the limiting deterministic problem yields an asymptotically optimal policy for the original problem.

\noindent
{\bf Our Contributions:} We formulate the problem as a controlled
continuous time Markov
chain~(CTMC)~\cite{stochctrl.bertsekas07dpoc-vol2}, and obtain the
optimal policy~(Section~\ref{forwarding-policy}). The optimal policy
relies on complete knowledge of the network state at every node,
but availability of  such information is constrained by the same connectivity
problem that limits packet delivery. In the incomplete information
setting, the decisions of the nodes would have to depend upon their beliefs
about the network state. The nodes would need to update their
beliefs continuously with time, and also after each meeting with
another node. Such belief updates would involve maintaining a complex
information structure and are often impractical for nodes with limited memory and
computation capability. Moreover, designing closed loop controls based on beliefs is a difficult
task~\cite{stochctrl-dtn.singhetal10dtn-twohop}, even more so in our
context with multiple decision makers and all of them equipped with
distinct partial information.

In view of the above difficulties, we adopt the following approach.
We show that when the number of
nodes is large, the optimally controlled network evolution is well
approximated by a deterministic dynamical system~(Section~\ref{asym-opt-forward}).
The existing differential equation approximation results for
Markovian systems~\cite{stochproc.kurtz70limits-markov-processes,stochproc.darling02fluid-limits}
do not directly apply, as, in the optimally controlled Markov chain that arises in our problem,
the mean drift rates are discontinuous and do not converge uniformly.
We extend the results to our problem setting in our Theorem~\ref{assym-optimality} in Section~\ref{asym-opt-forward}.
Note that the differential inclusion based approach of Gast and Gaujal~\cite{stochctrl.gast-gaujal10mean-field-nonsmooth}
is not directly applicable in our case, as it needs uniform
convergence of the mean drift rates.
The limiting deterministic dynamics then suggests a deterministic control
that is asymptotically optimal for the finite network problem, i.e.,
the cost incurred by the deterministic control approaches
the optimal cost as the network size grows.
We briefly consider the analogous control of two-hop forwarding~\cite{comnet-wireless.grossglauser-tse02mobility-adhoc-networks} 
in Section~\ref{sec:two-hop}.
Our numerical results
illustrate that the deterministic policy performs close to the
complete information optimal closed loop policy for a wide range of
parameter values~(Section~\ref{num-results}).

In a nutshell, the ODE approach is quite common in the modeling of such problems.
Its validity in situations without control is established by Kurtz~\cite{stochproc.kurtz70limits-markov-processes}, 
Darling and Norris~\cite{stochproc.darling-norris08differential-equation-approximations}, etc.
We aim in this paper at rigorously showing the validity of this limit under control in a few DTN problems.

\remove{
They study general Markov decision processes~(MDPs)~\cite{stochctrl.bertsekas07dpoc-vol2}.
However, They do not solve the finite problems, but consider the fluid limits
of MDPs, and analyze optimal control over the deterministic liming problems. Then show that, the so obtained deterministic
control is asymptotically optimal for the finite problem, i.e, the
the cost incurred by the deterministic control approaches the optimal cost as the system size grows.
On the other hand we explicitly characterize the optimal policy for the
finite~(complete information) problem. Then we prove convergence of the optimally
controlled Markov chain to a fluid limit.
Our notion of asymptotic optimality is identical to the one
proposed in~\cite{stochctrl.gast-etal10mean-field-MDPs}.
}

\remove{
 We formulate the controlled forwarding
problem as a POMDP~(Section~\ref{forwarding-problem}), and derive
monotonicity results for the value
function~(Theorem~\ref{theorem-value-function}) and the optimal
policy~(Theorem~\ref{theorem-optimal-policy}). Next we study an
approximate control problem that explicitly gives a suboptimal
policy for the original
problem~(Theorem~\ref{theorem-suboptimal-policy}). Numerical results
show that the suboptimal control performs close to optimal control
with complete information, and outperforms the open loop control. We
omit all proofs for brevity.
}

\remove{
Observe that our approach is different from that of Gast et al.~\cite{stochctrl.gast-etal10mean-field-MDPs}.
They study general Markov decision processes~(MDPs)~\cite{stochctrl.bertsekas07dpoc-vol2}.
However, They do not solve the finite problems, but consider the fluid limits
of MDPs, and analyze optimal control over the deterministic liming problems. Then show that, the so obtained deterministic
control is asymptotically optimal for the finite problem, i.e, the
the cost incurred by the deterministic control approaches the optimal cost as the system size grows.
On the other hand we explicitly characterize the optimal policy for the
finite~(complete information) problem. Then we prove convergence of the optimally
controlled Markov chain to a fluid limit. The limiting deterministic
dynamics then suggests a deterministic control~(for the finite
network) that is asymptotically optimal.
}

\section{The System Model}
\label{sec:sys-model}
We consider a set of  mobile nodes. These include 
destinations and  relays. At , a packet is generated and
immediately copied to  relays~(e.g., via a broadcast from an infrastructure
network). Alternatively, these  nodes can be thought of
as source nodes.

\subsubsection{Mobility model}
We model the point process of the {\it meeting instants} between pairs of nodes as independent Poisson point processes, each with rate . Groenevelt et al.~\cite{comnet-dtn.groenevelt-etal05message-delay-mobile-networks} validate this model for a number of common mobility models~(random walker, random direction, random waypoint). In particular, they establish its accuracy under the assumptions of small communication range and sufficiently high speed of nodes.

\subsubsection{Communication model}
Two nodes may communicate only when they come within transmission
range of each other, i.e., at {\it meeting instants}.
The transmissions are assumed to be instantaneous. We assume that
that each transmission of the packet incurs unit energy expenditure
at the transmitter.

\subsubsection{Relaying model}
We assume that a controlled epidemic relay protocol is employed.

Throughout, we use the terminology relating to the spread of
infectious diseases. A node with a copy of the packet is said to be
{\it infected}. A node is said to be {\it susceptible} until it receives a copy
of the packet from another infected node. Thus at ,  
nodes are infected while  are susceptible.

\subsection{The Forwarding Problem}
\label{sec:forward-problem} The packet has to be disseminated to all
the  destinations. However, the goal is to minimize the duration
until a fraction ~() of the
destinations receive the packet.

\remove{
 The goal is to deliver the packet to a fraction
~() of the  destinations within a short
duration. Thanks to the intermittent connectivity, nodes only have
beliefs about the number of infected destinations. Let
 be a time such that with high probability the
fraction of infected nodes at  is close to .
More precisely, if  is the number of infected destinations at
time , then for any ,

We want to shorten . }

At each meeting epoch with a susceptible relay, an infected
node~(relay or destination) has to decide whether to copy the
packet to the susceptible relay or not. Copying the packet incurs
unit cost, but promotes early delivery of the packet to the
destinations.
We wish to find the trade-off between these costs by minimizing

where  is the time until which at least  destinations receive the packet,
 is the total energy consumed
in copying, and  is the parameter that relates
energy consumption cost to delay cost. Varying  helps studying
the trade-off between the delay and the energy costs.

\remove{
\begin{remarks}
In the presence of complete information, every node knows when
the desired fraction of destinations receive the packet.
Thus no copying is done to the remaining susceptible destinations. In the case
of partial information copying to the susceptible destinations is stopped
at . This ensures that the fraction of infected destinations is
close to .
\end{remarks}
}
\section{Optimal Epidemic Forwarding}
\label{forwarding-policy}
We derive the optimal forwarding policy under the assumption that, at any instant of time,
all the nodes have full information about the number of relays carrying the
packet and the number of destinations that have received the packet.
This assumption will be relaxed in the next section.

\subsection{The MDP Formulation}
\label{sec:mdp-formulation}
Let  denote the meeting epochs of the infected
nodes~(relays or destinations) with the susceptible nodes. Let  and define  for .

Let  and  be the numbers of infected destinations and
relays, respectively, at time . In particular,  and
, and the forwarding process stops at time  if . We use  and  to mean  and  which are the numbers
of infected destinations and relays, respectively,  just before the meeting epoch .
Let  describe the type of the susceptible node
that an infected node meets at ;  where  and  stand for destination and relay,
respectively. The state of the system at a meeting epoch  is
given by the tuple

Since the forwarding process stops at time  if , the
state space is .\footnote{We use notation  and  for
 and .}

Let   be the action of the infected node at
meeting epoch .
The control space is
, where  is for {\it copy} and  is for {\it do not copy}.
The embedding convention described
above is shown in Figure~\ref{embedding}.
\begin{figure}[t]{
\centering
\includegraphics[height=1.6in]{embedding-md1.pdf}
\caption{\label{embedding}Evolution of the controlled Markov chain
. Note that  is embedded at , i.e., just before the meeting epoch.}}
\end{figure}

We treat the tuple  as the random
disturbance at epoch . Note that for , the time
between successive decision epochs, , is independent and
exponentially distributed with parameter
. Furthermore, with ``w.p.'' standing for ``with probability'', we have

\subsubsection{Transition structure}
From the description of the system model, the state at time  is given by   if , and  if . Recall that  is a component in the
random disturbance. Thus the next state is  a function of the
current state, the current action and the current disturbance as
required for an MDP .

\subsubsection{Cost Structure}
For a state-action pair 
the expected single stage cost is given by

where the expectation is taken with respect to the random
disturbance . It can be observed that

where

 is the mean time
until the next decision epoch. The quantity  is expended whenever , i.e., the action is to copy.


\subsubsection{Policies} A policy  is a sequence of mappings ,
where . The cost of an admissible policy  for
an initial state  is

Let   be the set of all admissible policies. Then the optimal cost function is defined as


A policy  is called stationary if  are identical, say , for all .
For brevity we refer to such a policy as the stationary policy .
A stationary policy  is optimal if  for all states .


\subsubsection{Total Cost}
We now translate the optimal cost-to-go from the first meeting instant into optimal total cost.
Recall that at the first decision instant , the state
 is  or  depending on whether the susceptible node that is met is a relay
or a destination.
The objective function~\eqref{eqn-objective} can then be restated as

where the subscript  shows dependence on the underlying policy. In the right hand side, the first term  is the average delay until the first decision instant which has to be borne under any policy.


\subsection{Optimal Policy}
\label{sec:opt-policy} Since the cost function  is
nonnegative, Proposition~1.1 in~\cite[Chapter~3]{stochctrl.bertsekas07dpoc-vol2}
implies that the optimal cost function will satisfy the following
Bellman equation. For ,

Here  denotes the next state which depends on  and the random disturbance
in accordance with the
transition structure described above. The expectation is taken with
respect to  the random disturbance. Furthermore, since the action
space is finite, there exists a stationary optimal policy 
such that, for all ,  attains minimum in the above
Bellman equation
~(see~\cite[Chapter~3]{stochctrl.bertsekas07dpoc-vol2}). In the
following we characterize this stationary optimal policy.

First, observe that it is always optimal to copy to a destination, that is, the optimal policy satisfies  for all . Moreover, once a fraction  of the destinations have obtained the packet, no further delay cost is incurred, and so further copying to relays does not help:  for all .

\remove{
\begin{lemma}
\label{lemma:copy-destinations}
The optimal policy satisfies  for all .
\end{lemma}
\begin{IEEEproof}
Consider a policy  such that  for
some . In the following, we derive
another policy  that yields less expected cost than . Thus
 can not be an optimal policy.
In other words, the optimal policy satisfies  for all .

Let us assume that the network is operating under policy .
We define the following attributes associated with any realization
 of the network.\footnote{A realization consists of meeting epochs
of each of the node pairs.}\\
\begin{inparaenum}[\textbullet]
\item : epoch when the network encounters state ;  if
the network does not encounter state . \\
\item : index of the susceptible destination met at .\\
\item : epoch when an infected node meets  and copies the packet.
Clearly, . Moreover,  if 
is never copied under policy .\\
\end{inparaenum}
Now, we propose another policy  that executes the same sequence of
actions as , but copies the packet to  at ,
does not copy at , and moreover, stops copying once  destinations get
the packet. Evidently,  and  spend equal transmission
energies as under both the polices equal number of relays and destinations are copied.
However,    yields strictly less delivery delay if either 
or  is the last destination~(i.e., th destination) to be copied
under policy . In any other case,  and  yield equal delivery delays.
Thus, the aggregate cost of   is less than or equal to that of .
Notice that all the above cases can occur with positive probabilities.
We obtain the claim by averaging the costs over all the realizations.
\end{IEEEproof}
}

Next, focus on a reduced state space .
 \remove{ We cast the problem as a {\it stopping
problem}~\cite[Section~3.4]{stochctrl.bertsekas07dpoc-vol2}. Towards
this, we define an special  action which implies that no
copying is done to the susceptible relay met at present or those to
be met in the future. Alternatively,  is equivalent to a sequence
of actions .
Clearly, if we choose
action  at a state , the stopping cost, ,
is the expected time to go until the desired fraction of
destinations are infected. It can be easily verified that, for all
,

The one-step stopping set is defined as

where, as before,  and  denote the random disturbance and
the next state, respectively.
}
Consider the following {\it one step look
ahead policy}~\cite[Section~3.4]{stochctrl.bertsekas07dpoc-vol2}. At
a meeting with a susceptible relay, say when the state is , compare
the following two action sequences.
\begin{enumerate}
\item : {\it stop}, i.e., do not copy to this relay or to any susceptible relays met in the future,
\item : copy to this relay and then {\it stop}.
\end{enumerate}
The costs to go corresponding to the action sequences
 and  are, respectively,

The {\it stopping set}  is defined to be

where

for all .
The one step look ahead policy is to copy to relay
when , and to stop copying otherwise.\footnote{We use the standard convention that a sum over an
empty index set is . Thus  if . Consequently, for the states , one step-look ahead
policy prescribes {\it stop}. This is consistent with our earlier discussion.}


One step look ahead policies have been shown to be optimal for
stopping problems under certain
conditions~(see~\cite[Section~4.4]{stochctrl.bertsekas05dpoc-vol1}
and~\cite[Section~3.4]{stochctrl.bertsekas07dpoc-vol2}).
Let us reemphasize that our problem is not a stopping problem because an action  now
is not equivalent to {\it stop} as the resulting state
is not a {\it terminal state};  a susceptible relay that is met in
the future may be copied even if the one met now is not.
However, we exploit the cost structure to prove that when an infected node meets a susceptible relay,
it can restrict attention to two actions: ~(i.e., copy now) and \emph{stop}~(i.e., do not
copy now and never copy again).
Subsequently, we also show that the above one step look ahead policy~(see~\eqref{eqn:stopping-set}) is optimal.
\begin{theorem}
\label{heu-optimality} The optimal policy  satisfies

\end{theorem}
\begin{IEEEproof}
Though the optimal policy is a simple stopping policy, the proof of its optimality is far from obvious. 
See Appendix~\ref{proof-heu-optimality}.
\end{IEEEproof}

\remove{
\begin{remarks}
\label{remark:Phi} Observe that  is decreasing in  for
a given  and also decreasing in  for a given . Thus the
optimal policy has the following properties.\\
\begin{inparaenum}[1)]
\item If , then  for all .\\
\item If , then  for all .
\end{inparaenum}

Thus the optimal solution can be given a ``stopping''
interpretation. More precisely, if the packet is not copied at a
meeting with a susceptible relay, it is not copied to relays in
future meetings. A priori however, we did not know if such a
``stopping'' was optimal.
\end{remarks}
}
\remove{
\begin{remarks}
Also observe that
 
 Hence

 Since phi is decreasing in m, we conclude that
\begin{enumerate}
\item  is convex in , and thus so is 
\item They are both submodular
\end{enumerate}
\end{remarks}
}

We illustrate the optimal policy using an example. Let  and . The
``'' in Figure~\ref{fig:heu-policy} are the
states where the optimal action~(at meeting with a relay) is to
copy. For example, if only  destinations have the packet, then
relays are copied to if and only if there are  or less infected
relays. If  destinations already have the packet and there are
 infected relays, then no further copying to relays is done.
\begin{figure}[t]{
\centering
\includegraphics[height=2.5in]{heu-policy.pdf}
\caption{An illustration of the optimal policy. The symbols 'X' mark
the states in which the optimal action~(at meeting with a relay) is
to copy}
 \label{fig:heu-policy}}
\end{figure}

\section{Asymptotically Optimal Epidemic Forwarding}
\label{asym-opt-forward}

In states , the optimal
action, which is governed by the function , requires
perfect knowledge of the network state~.
This may not be available to the decision maker due to intermittent
connectivity.
In this section, we derive an asymptotically optimal policy that
does not require knowledge of network's state but depends only on
the time elapsed since the generation of the packet. Such a policy
is implementable if the packet is time-stamped when generated and
the nodes' clocks are synchronized.


\subsection{Asymptotic Deterministic Dynamics}
\label{asym-det-dynamics}
 Our analysis closely follows
Darling~\cite{stochproc.darling02fluid-limits}. It is
straightforward to show that the equations that follow are the conditional expected
drift rates of the optimally controlled CTMC. For , using the optimal policy in Theorem~\ref{heu-optimality}, we get

\frac{{\rm d}\mathbb{E}(m(t)|(m(t),n(t)))}{{\rm d}t} = &~\lambda (m(t) + n(t))(M-m(t)), \label{eqn:drift-1}\\
\frac{{\rm d}\mathbb{E}(n(t)|(m(t),n(t)))}{{\rm d}t} = &~\lambda (m(t) + n(t))(N-n(t)) \nonumber\\
& \ \ \ \ \ \ \ \ \ \ \ \ \ 1_{\{\Phi(m(t),n(t)) > 0\}}. \label{eqn:drift-2}


Recalling that , the total number of nodes, we study large  asymptotics. Towards
this, we consider a sequence of problems indexed by .
The parameters of the th problem are denoted using the superscript .
Normalized versions of these parameters, and normalized versions of the system state
are denoted as follows:

\remove{

}
\begin{remarks}
The pairwise meeting rate and the copying cost must both scale down as  increases.
Otherwise, the delivery delay will be negligible and the total transmission cost will be
enormous for any policy, and no meaningful analysis is possible.
\end{remarks}

For each , we define scaled two-dimensional integer lattice

. Also, for , using the notation in~\eqref{eqn:scalings}, the
drift rates in~\eqref{eqn:drift-1}-\eqref{eqn:drift-2}  can be rewritten as follows.
\remove{
\footnote{More precisely,
 lies on a scaled two-dimensional integer lattice
of the from  for some .}
}

&\frac{{\rm d}\mathbb{E}(x^K(t)|(x^K(t),y^K(t)))}{{\rm d}t} \nonumber \\
& \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ = f^K_1(x^K(t),y^K(t)) \nonumber \\
& \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \  := \Lambda(x^K(t)+ y^K(t))(X-x^K(t)), \label{eqn:f-K_1} \\
&\frac{{\rm d}\mathbb{E}(y^K(t)|(x^K(t),y^K(t)))}{{\rm d}t} \nonumber \\
& \ = f^K_2(x^K(t),y^K(t)) &  \nonumber \\
&:= \Lambda (x^K(t) + y^K(t))(Y-y^K(t))1_{\{\phi^K(x^K(t),y^K(t)) > 0\}}, \label{eqn:f-K_2}

where, for ,

We also define  as functions
satisfying the following ODEs: , and for ,

\frac{{\rm d}x(t)}{{\rm d}t} = &~f_1(x(t),y(t)) := \Lambda (x(t) + y(t))(X-x(t)),\label{eqn:f-1} \\
\frac{{\rm d}y(t)}{{\rm d}t} = &~f_2(x(t),y(t)) := \Lambda (x(t) + y(t))(Y-y(t)) \nonumber\\
                               & \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ 1_{\{\phi(x(t),y(t)) > 0\}}\label{eqn:f-2}

where\footnote{We use the convention that an integral assumes the value 
if its lower limit exceeds the upper limit. So,  if .}

Finally, we redefine the delivery delay ~(see~\eqref{eqn-objective}) to be

 Note that  is a stopping time for the random
process , whereas  is a deterministic time instant. Since  is bounded away from
zero,  with probability . Similarly, on account of  being bounded away from
zero, .

Kurtz~\cite{stochproc.kurtz70limits-markov-processes} and Darling~\cite{stochproc.darling02fluid-limits}
studied convergence of CTMCs to the solutions of ODEs. The following are the hypotheses for
the version of the limit theorem that appears in Darling~\cite{stochproc.darling02fluid-limits}.
\begin{enumerate}[(i)]
\item ;
\item In the scaled process , the jump rates are  and drifts are ;
\item  converges to  uniformly  in ;
\item  is Lipschitz continuous.
\end{enumerate}
Observe that, in our case, only the first two hypotheses are satisfied.
In particular,  does not converge uniformly to ,
and  is not Lipschitz over . Hence, the convergence results do not directly apply in
our context. Thankfully, there is some regularity we can exploit which
we now summarize as easily checkable facts.
\begin{enumerate}[(a)]
\item  converges uniformly to ;
\item the drift rates  and  are bounded from below and above;
\item  is Lipschitz and  is locally Lipschitz; and
\item for all small enough , and all  on the graph of ``'', the direction in which the ODE
progresses, , is not tangent to the graph.
\end{enumerate}
We then prove the following result which is identical to
~\cite[Theorem~2.8]{stochproc.darling02fluid-limits}.
\begin{theorem}
\label{assym-optimality}
Assume that  and . Then, for every ,

\end{theorem}
\begin{IEEEproof}
See Appendix~\ref{proof-assym-optimality}.
\end{IEEEproof}
\remove{
Moreover, we also obtain the following result.
\begin{theorem}
\label{thm:asym-stop-time}
For every ,

\end{theorem}
\begin{IEEEproof}
\end{IEEEproof}
}
We illustrate Theorem~\ref{assym-optimality} using an example. Let 
and . In Figure~\ref{fig:kurtz}, we plot  and
sample trajectories of  for 
and . We indicate the states at which the optimal policy stops copying to
relays, i.e.,  goes below ~(see Theorem~\ref{heu-optimality})
and the states at which the fraction of infected destinations crosses .
We also show the corresponding states in the fluid model.
The plots show that for large , the fluid model captures the random dynamics
of the network very well.
\begin{figure}[t]
\centering
\subfigure{\includegraphics[width=2.6in]{kurtz-scaledx.pdf}}
\subfigure{\includegraphics[width=2.6in]{kurtz-scaledy.pdf}}
\caption{Simulation results: The top and bottom sub-plots
respectively show the fractions of infected destinations and relays
as a function of time.  are obtained from a
simulation of the controlled CTMC, and  from the ODEs.
The marker 'X' indicates the states at which copying to relays is
stopped whereas 'O' indicates the states at which a fraction 
of destinations have the packet.} \label{fig:kurtz}
\end{figure}

\subsection{Asymptotically Optimal Policy}
Observe that  is decreasing in  and , both of which are nondecreasing with . Consequently
 decreases with . We define

The limiting deterministic dynamics suggests the following policy
 for the original forwarding problem.\footnote{Observe that the policy  does not require
knowledge of  and . The infected node readily knows the type
of the susceptible node~( or ) at the decision epoch.}



We show that the policy  is asymptotically optimal in the sense that
 its expected cost approaches the expected cost of the optimal
policy  as the network grows.
Let us restate~\eqref{eqn:cost} as

We have used superscript  to show the dependence of cost on the
network size. We then establish the following asymptotically optimality result.
\begin{theorem}
\label{theorem:asym-optimal}

\remove{

}
\end{theorem}
\begin{IEEEproof}
See Appendix~\ref{proof-asym-optimal}.
\end{IEEEproof}
\begin{remarks}
\label{remark:cost-comparision}
Observe that we do not compare the limiting value of the optimal costs with the 
optimal cost on the~(limiting) deterministic system. In general, these two may differ.\footnote{In our case these two indeed match. See Appendix~\ref{hamiltonian} for a proof.} 
However, the deterministic policy  can be applied on the finite -node system. 
The content of the above theorem is that given any , cost of the policy  
is within  of the optimal cost {\em on the -node system} for all sufficiently large .
\end{remarks}

\subsubsection*{Distributed Implementation}
The asymptotically optimal policy can be implemented
in a distributed fashion. Assume that all the nodes are time
synchronized.\footnote{In practice, due to variations in the clock
frequency, the clocks at different nodes will drift from each other.
But the time differences are negligible compared to the delays
caused by intermittent connectivity in the network. Moreover, when
an infected node meets a susceptible node, clock synchronization can
be performed before the packet is copied.} Suppose that the packet
is generated at the source at time ~(we assumed  for
the purpose of analysis). Given the system parameters
 and , the source first extracts
 and  as
in~\eqref{eqn:scalings}. Then, it calculates
~(see~\eqref{eqn:stop-relays}), and stores   as a header in the packet. \remove{
\begin{enumerate}
\item the time at which copying to relays is stopped - this is set to .
\item the time at which copying to destinations is stopped - this is set to .
\end{enumerate}}

The packet is immediately copied to  relays, perhaps by means of a
broadcast from an infrastructure "base station". When an infected
node meets a susceptible relay, it compares  with
the current time. The susceptible relay is not copied to if the
current time exceeds . However, all the infected
nodes continue to carry the packet, and to copy to susceptible
destinations as and when they meet.

\begin{remarks}
Consider a scenario, where the interest is in copying packet to only
a  fraction  of the destinations. Observe that for
every ,

Thus, in large networks, copying to destinations can also be stopped at
time ~(see~\eqref{eqn:stop-dstns}) while ensuring that
with large probability the fraction of infected destinations is
close to . Consequently, all the relays can delete the
packet and free their memory at .
This helps when packets are large and relay~(cache) memory is limited.
\end{remarks}

\remove{
\section{Optimal Epidemic Forwarding: Single Destination Problem}
\label{sec:single-dest}
Let us consider the optimal forwarding problem studied in~\cite{ctrltheory-dtn.neglia-zhang06optimal-delay-power-tradeoff}.
Now, the network consists of  mobile nodes;  relays and  destination.
As in Section~\ref{sec:sys-model},  relays have copies of the packet at ,
and we consider the same mobility, communication, relaying models and terminology as in Section~\ref{sec:sys-model}.

We aim at delivering the packet to the destination within a short duration.
The packet may also be forwarded to one or more of the remaining  relays to facilitate
quicker delivery. The destination receives the packet when it meets any of the
infected relays.
At each meeting epoch with a susceptible relay, an infected
relay  has to decide whether to copy the
packet to the susceptible relay or not. Again, the
objective is to minimize

where
 is the time at which the destination receives the packet,
 is the total energy consumption due to transmissions
of copies of the packet to relays, and  is the parameter that relates
energy consumption to delay.

We first assume that all the relays, at any instant,  have information  about the
number of relays carrying the packet, and also whether the destination has received the
packet or not. Subsequently, we relax this assumption, and propose an open loop control.

Let  denote the meeting epochs of the infected relays with
susceptible relays; . Let  be the number of infected relays at
time ; . We use  to mean . The forwarding to relays is stopped at time 
if either  or an infected relay meets the destination.
The state of the system at a meeting epoch  is , and the state
space is . The transition and cost structures and policies can be defined as in  Section~\ref{sec:sys-model}.
Neglia and Zhang~\cite{ctrltheory-dtn.neglia-zhang06optimal-delay-power-tradeoff}
show that the optimal policy  satisfies

where


In order to obtain an asymptotically optimal policy we write the conditional expected drift rate for the CTMC .
For ,

We normalize the system variables as in~\eqref{eqn:scalings}. Define

For , the drift rate can be rewritten as

where

As in Section~\ref{asym-opt-forward}, we define  as a function satisfying  and

where

Finally, we define

It can be easily seen that

Observe that when copying cost is high or the number of sources is high enough, no relay is copied. On the other hand,
if the copying cost is very small, the copying to the relays could be continued for ever.

A similar analysis as in Section~~\ref{asym-opt-forward} shows that the following is the asymptotically
optimal policy. We omit the proof for brevity.
\begin{theorem}
\label{theorem:asym-optimal-sd}
The asymptotically optimal open-loop policy is

\end{theorem}
\begin{remarks}
If an infected relay meets the destination, it copies (if the destination has not
received already) and then deletes the packet. All the relays carry the packet
until they know that destination has received the packet. However, no relays are
infected after  .
\end{remarks}
}

\section{Optimal Two-Hop Forwarding}
\label{sec:two-hop}
Instead of epidemic relaying one can consider two-hop
relaying~\cite{comnet-wireless.grossglauser-tse02mobility-adhoc-networks}.
Here, the  source nodes can copy the packet
to any of the  relays or  destinations.
The infected destinations can also copy the packet to
any of the susceptible relays or destinations.
However, the relays are allowed to transmit the packet only
to the destinations. Here also a similar optimization problem as in
Section~\ref{sec:forward-problem} arises.


Now, the decision epochs  are the meeting epochs of the infected nodes~(sources, relays or destinations)
with the susceptible destinations and the meeting epochs of the sources or infected destinations with the susceptible relays.
We can formulate an MDP with state

at instant  where  and   are as defined in
Section~\ref{sec:mdp-formulation}. The state space is . The control space is
, where  is for {\it copy} and  is for {\it do not copy}.
We also get a transition structure identical  to that in Section~\ref{sec:mdp-formulation}.

For a state action pair 
the expected single stage cost is given by

where \\


 is the mean time until the next decision epoch.
As before, the quantity  accounts for the
transmission energy.

Let  be a stationary optimal policy. As in
Section~\ref{sec:opt-policy}, the optimal policy satisfies
 for all , and
 for all . Thus, we focus on a reduced state space . As before, we look for the one step
look ahead policy which turns out to be the same as that for
epidemic relaying. Finally, Theorem~\ref{heu-optimality} holds for
two-hop relaying as well~(see the proof in
Appendix~\ref{proof-heu-optimality}).

Next, we turn to the asymptotically optimal control for two-hop relaying.
The following are the conditional expected
drift rates. For ,

We employ the same scaling and notations as in~\eqref{eqn:scalings}. The drift rates
in terms of  are

Now,  are defined as functions satisfying  and for
,

The analysis in Section~\ref{asym-opt-forward} applies to two-hop relaying
as well. In particular, Theorems~\ref{assym-optimality} and~\ref{theorem:asym-optimal} hold.
However, for the identical system parameters~( and )
and initial state~(), the value of the time-threshold  will be larger on account of the
slower rates of infection of relays and destinations.


We illustrate the comparison between epidemic and two-hop relaying using an example.
Let 
and . In Figure~\ref{fig:epi-twohop-trajectory}, we plot the
graph of  ``'', and also the ' versus ' trajectories corresponding to
 epidemic and two-hop relayings. In Figure~\ref{fig:epi-twohop-evolution},
we plot the trajectories of  corresponding to
 epidemic and two-hop relayings. As anticipated, the value of the time-threshold  is larger
for two-hop relaying than epidemic relaying. Moreover, the number of transmissions is less while the deliverly delay is more 
under the controlled two-hop relaying. 

\begin{figure}[t]
\centering
\includegraphics[width=2.6in]{trajectory.pdf}
\caption{An illustration of the  epidemic and two hop trajectories.
 The plots also show the graph of  `'.}
\label{fig:epi-twohop-trajectory}
\end{figure}

\begin{figure}[t]
\centering
\subfigure{\includegraphics[width=2.6in]{kurtz-scaledx-epi-th.pdf}}
\subfigure{\includegraphics[width=2.6in]{kurtz-scaledy-epi-th.pdf}}
\caption{The top and bottom sub-plots respectively show the fractions of infected
destinations and relays as a function of time. The marker 'X' indicates the states at
which copying to relays is stopped, and 'O' indicates the states at
which  fraction of destinations have been copied.}
\label{fig:epi-twohop-evolution}
\end{figure}

\remove{
\subsection{Single Destination Problem}
\label{sec:two-hop-single-destn}
Now, we consider the optimal forwarding problem studied in~\cite{stochctrl-dtn.singhetal10dtn-twohop}.
As in Section~\ref{sec:single-dest}, the network consists of  mobile nodes;  relays and  destination.
 relays have copies of a packet at . We consider the same mobility and communication
models as in Section~\ref{sec:sys-model} and relaying model as in Section~\ref{sec:two-hop-multi-destn}.
Also, we address the the optimization problem identical to the one studied in Section~\ref{sec:single-dest}.

As before, consider first the case when all the source nodes, at any instant,  have information  about the
number of nodes carrying the packet, and also whether the destination has received the
packet or not. The decision epoch  are the meeting epochs of the source nodes with
susceptible relays. The problem can be formulated as an MDP similar to the one in Section~\ref{sec:single-dest}.
The transition and cost structures and policies can be defined as in  Section~\ref{sec:sys-model}.
The optimal policy turns out to be the same as given
by~\eqref{eqn:opt-policy-sd}~(see~\cite{stochctrl-dtn.singhetal10dtn-twohop} for a discussion).

Following the programme as before, we now obtain an asymptotically optimal open loop policy.
To do this,  we write the conditional expected drift rate for the CTMC .
For ,

We employ the same scaling and notations as in~\eqref{eqn:scalings-sd}. The drift rate
in terms of  is

As in Section~\ref{asym-opt-forward}, we define  as a function satisfying  and

The time threshold   turns out to be

The asymptotically
optimal policy is given by Theorem~\ref{theorem:asym-optimal-sd} with  defined as above.

Comparing~\eqref{eqn:stop-relays-sd} and~\eqref{eqn:stop-relays-th-sd}, it
can be observed the  is larger for two-hop relaying than
epidemic relaying.
}

\section{Numerical Results}
\label{num-results}
We now show some numerical results to demonstrate the good performance of the deterministic control
in epidemic forwarding in a DTN with multiple destinations.
Let  and .
We vary  from  to  and use  and .
In Figure~\ref{fig:numerical}, we plot the total number of copies to relays and the delivery delays corresponding
to both the optimal and the  asymptotically optimal deterministic policies.
Evidently, the deterministic policy
performs close to the optimal policy on both the fronts.
We observe that, for a fixed , both the mean delivery delay and the
 mean number of copies to relays decrease as  increases.
We also observe that, for a fixed , the mean delivery delay decreases
as the network size grows.
Finally, for smaller values of , the mean number of copies to relays
increases  with the network size, and for larger values of , the opposite happens.
\begin{figure}[t]
\centering
\subfigure{\includegraphics[width=2.8in]{number-copies.pdf}}
\subfigure{\includegraphics[width=2.8in]{delivery-delay.pdf}}
\caption{The top and bottom sub-plots, respectively, show the total
number of copies to relays and the delivery delays corresponding to
both the optimal and the deterministic policies.}
\label{fig:numerical}
\end{figure}

\section{Conclusion}
We studied the epidemic forwarding in DTNs, formulated the problem as a controlled continuous time Markov chain, and
obtained the optimal policy~(Theorem~\ref{heu-optimality}). We then developed an ordinary differential equation
approximation for the optimally controlled Markov chain, under a natural scaling, as the population of nodes
increases to ~(Theorem~\ref{assym-optimality}). This o.d.e. approximation yielded a forwarding policy that does not require
global state information (and, hence, is implementable), and is asymptotically optimal~(Theorem~\ref{theorem:asym-optimal}).


The optimal forwarding problem can also be addressed following the
result of Gast et al.~\cite{stochctrl.gast-etal10mean-field-MDPs}.
They study a general discrete time Markov decision process~(MDP)~\cite{stochctrl.bertsekas07dpoc-vol2}.
However, they do not solve the finite problem citing the difficulties
associated with obtaining the asymptotics of the optimally controlled
process~(see~\cite[Section~3.3]{stochctrl.gast-etal10mean-field-MDPs}).
Instead, they consider the fluid limit
of the MDP, and analyze optimal control over the deterministic limiting problem.
They then show that the optimal reward of the MDP converges to the optimal reward of its
mean field approximation, given by the solution to a Hamilton-Jacobi-Bellman~(HJB)
equation~\cite[Section~3.2]{stochctrl.bertsekas05dpoc-vol1}.
On the other hand, our approach is more direct.
We have a continuous time controlled Markov chain at our disposal
We explicitly characterize the optimal policy for the finite~(complete information) problem,
and prove convergence of the optimally controlled Markov chain to a fluid limit.
An asymptotically optimal deterministic control is then suggested by the limiting deterministic dynamics,
and does not require solving HJB equations. Our notion of asymptotic optimality is also stronger in the
sense that we apply both the optimal policy and the deterministic policy to the finite problem, and show that
the corresponding costs converge.

There are several directions in which this work can be extended.
In the same DTN framework, there could be a deadline on the delivery time of the packet~(or message);
the goal of the optimal control could be to maximize the fraction of destinations that receive
the packet before the deadline subject to an energy constraint. Our work in this paper
assumes that network parameters such as  etc., are known;
it will be important to address the adaptive control problem when these parameters are unknown.

\appendices
\section{Proof of Theorem~\ref{heu-optimality}}
\label{proof-heu-optimality}

We first prove that for the optimal policy it is sufficient to consider two
actions ~(i.e., copy now) and {\it stop}~(i.e., do not copy now and never copy again).
More precisely, under the optimal policy, if a susceptible relay
that is met is not copied, then no susceptible relay is copied in the future as well.
Let us fix a . Let   be the maximum 
such that .\footnote{Note that, for a given ,   could be 0,
in that case we do not copy to any more relays.}
We show that  for all ; see Figure~\ref{fig:heu-policy}
for an illustration of this fact.
The proof is via induction.
\remove{
Let us assume that  for all . The following results completes the induction step.
}

\begin{proposition}
If  for all , then .
\end{proposition}
\begin{IEEEproof}
Define

Both the action sequences that give rise to the two cost terms in
the definition of , do not copy to the
susceptible relay that was just met. Let  be the number of infected
destinations at the next decision epoch when a susceptible relay is
met;  can be . All interim decision epochs must be
meetings with susceptible destinations, and both policies copy at
these meetings. Hence, both policies incur the same cost until this
epoch, and differ by  in the costs to go~(from this epoch onwards).
Averaging the difference over , and noting that  for , we get\footnote{We use the
standard convention that a product over an empty index set is ,
which happens when .}

Since , it follows that , and so
\vspace{1pt}

which implies upon rearrangement


Next, we establish the following lemma.
\begin{lemma}
\label{lma:lemma2}

\end{lemma}
\begin{IEEEproof}
Note that both the action sequences that lead to the two cost terms in
the definition of  copy at state .
Subsequently, both incur equal costs until a decision epoch when
an infected node meets a susceptible relay. Also, at any such state
, the costs to go differ by .
Hence,

where

Thus it suffices to show that

which is same as~\eqref{eqn:psi-nm} with  replaced by .
\end{IEEEproof}

Next, observe that for all ,

Moreover, from the induction hypothesis, the optimal policy copies at states
 for all . Hence, for ,

Finally,  for all  as the optimal policy does not copy
in these states.
Hence, from~\eqref{eqn:theta_0},

where the first~(strict) inequality holds because  is strictly decreasing~(see~\eqref{eqn:Phi})
and  is decreasing~(see Lemma~\ref{lma:lemma2}) in  for fixed
. The second inequality follows because the summation term is a probability which is less than .
Now suppose that .
Then

which contradicts~\eqref{eqn:bound-2}. Thus, we conclude that

This further implies that  (see~\eqref{eqn:psi-jn}),
and so that .
\end{IEEEproof}

We now return to the proof of Theorem~\ref{heu-optimality}.
We show that the one-step look ahead policy is optimal for the resulting
stopping problem. To see this, observe that  is decreasing in  for
a given  and also decreasing in  for a given . Thus,
if , i.e, ~(see~\eqref{eqn:stopping-set}), and the
susceptible relay that is met is copied, the next state  also belongs to the
stopping set . In  other words,   is also an
absorbing set~\cite[Section~3.4]{stochctrl.bertsekas07dpoc-vol2}).
Consequently, the one-step look ahead policy is an optimal policy.


\section{Proof of Theorem~\ref{assym-optimality}}
\label{proof-assym-optimality}
We start with a preliminary result and a few definitions.
\begin{proposition}
\label{prop-uni-conv} Let  and . Let 
and  be as given in~\eqref{eqn:phi-K} and~\eqref{eqn:phi},
respectively. Then, the functions  converge to
 uniformly, i.e., for every , there exists a
 such that

for all .
\end{proposition}
\begin{IEEEproof}
For a , define  as follows.

Clearly, the family  is positive and uniformly upper
bounded. Indeed,

Further,

from which it can be seen that

where  is a suitably defined constant. So the family
 is uniformly Lipschitz. Now, for ,

where the first and the last inequalities follow from the
definitions of  and  respectively. On the other
hand,

Hence

Combining~\eqref{inq-left} and~\eqref{inq-right},

Now fix a . Setting , and summing over
, we get

The obtained upper bound on the right-hand side is independent of
, and vanishes as . Thus, for every , there exists a
 such that

for all .
\end{IEEEproof}

In the following, to facilitate a parsimonious description, we use
the notation ,  and
. Let us define, for
a ,

and a stopping time

the time when  exits the limiting set .
Observe that

 and  defined in~\eqref{eqn:f-K_1} is positive and is also bounded away from zero.
 These imply that  with probability .
Similarly, . The following assertion is a
corollary of Proposition~\ref{prop-uni-conv}.
\begin{corollary}
\label{cor:apprx-bdry} Let  be as in
Proposition~\ref{prop-uni-conv}. For ,

\end{corollary}

We define the uncontrolled dynamics~(i.e., the one in which the
susceptible relays are always copied) as a Markov process
,  for which
. Let ,
 be the corresponding limiting deterministic dynamics.
Formally, , and for ,

The quantities on the right-hand side of the above equations are at
most , and so

Also observe that the processes  and 
satisfy the hypotheses of Darling~\cite{stochproc.darling02fluid-limits}~(see Section~\ref{asym-det-dynamics}),
and thus convergence of  to  follows.


We also define a Markov process ,  for which
 and

In other words,  is the process in which relays are
not copied from  onwards. Similarly, we define
,  as
the solution of the corresponding differential equations. In other
words, , and for ,

 We define

Since

the lower bound implies that there is a strictly positive increase
in  after time . Since  decreases
with increasing  at a rate bounded away from
~(see~\ref{eqn:rate-phi}),  must exit 
within a short additional duration. Thus, we have that

for a suitably chosen .


To aid the reader, we summarize
the variables used in Table~\ref{variables-description}.
We also illustrate sample trajectories of a controlled CTMC and the corresponding
ODE via an example~(Figure~\ref{fig:boundries}). We choose 
and . We plot the graphs of '' and ''
for . We also show the trajectories `` vs '', `` vs '',  `` vs ''
and the epochs ,  and .


\begin{table}[t]
\renewcommand{\arraystretch}{1.3}
\caption{Variables and their description}
\label{variables-description}
\centering
\begin{tabular}{l|l}
\hline
\bfseries variables & \bfseries description \\
\hline
  & controlled dynamics with discontinuity at  \\
  & 's fluid limit with discontinuity at  \\
  & instant when  exits  \\
  & instant when  exits  \\
  & uncontrolled dynamics with no discontinuity \\
  & 's fluid limit with no discontinuity \\
  & identical to  until  at which
 copying to \\
        & relays is stopped \\
  & 's fluid limit with discontinuity at  \\
  & instant when  exits  \\
  & instant when  exits  \\
\hline
\end{tabular}
\end{table}


\begin{figure}[b]
\centering
\includegraphics[width=3.6  in]{boundary-variables.pdf}
\caption{An illustration of the trajectories of the controlled CTMC and the corresponding ODE, and the associated variables.}
\label{fig:boundries}
\end{figure}

We prove the assertion in Theorem~\ref{assym-optimality} in three
steps:
\begin{inparaenum}[(a)]
\item over ,
\item over  and
\item over .
\end{inparaenum}
However, we also need the following lemmas in our proof..
\begin{lemma}
\label{epsi-tau} For every , there exists a
 such that for all , ,

\end{lemma}
\begin{IEEEproof}
Observe that

Hence, for all , ,

where the last equality follows
from~\cite[Theorem~2.8]{stochproc.darling02fluid-limits}. Setting
, for all
, 

\end{IEEEproof}

\begin{lemma}
\label{epsi-delta} Suppose  is a fixed time and  is a random
time that satisfies  for every . Then, for every ,

\end{lemma}
\begin{IEEEproof}
Fix a . Then,

where the last inequality holds because  is a monotone
increasing function. Setting ~(see
Lemma~\ref{epsi-tau}),

where the last inequality follows from Lemma~\ref{epsi-tau}.
\end{IEEEproof}

Following is the proof of Theorem~\ref{assym-optimality}.

\noindent
\begin{inparaenum}[(a)]
\item First, we prove the convergence of  to  over
. Fix a .
Then Corollary~\ref{cor:apprx-bdry} implies that
 converges to  in the region . Following~\cite[Theorem~2.8]{stochproc.darling02fluid-limits} we
have, for all ,

& \mathbb{P}\left(\sup_{0 \leq t \leq \tau_{\nu}} \Vert z^K(t
\wedge \tau^K_{\nu}) - z(t) \Vert > \epsilon \right) =
O(K^{-1}) \label{eqn:darling-a1}\\
&\mbox{and } \mathbb{P}(|\tau^K_{\nu} - \tau_{\nu}| > \delta) =
O(K^{-1}) \label{eqn:darling-a2} .

Since, for all ,

we obtain

If the left side is larger than , at least one of the two
terms on the right side is larger than , and so by the
union bound, we get

where the first term in the last inequality follows
from~\eqref{eqn:darling-a1}. Also, from
corollary~\ref{cor:apprx-bdry}, for ,
, i.e., the process  follows
uncontrolled dynamics until . Thus, for ,  and

sample path wise. The inequality is an equality if ;  both sides equal  in this case. Otherwise, it is
an inequality because the possible change in dynamics of 
after  makes it increase (in both its components) at a
slower pace than the uncontrolled . Thus

where the last inequality follows from~\eqref{eqn:darling-a2} and
Lemma~\ref{epsi-delta}. Using this in~\eqref{eqn:bound-1} we get


\item Now we prove the convergence of  to  over
.
Observe that, for ,

Hence,

where the equality follows because the  and  are
nondecreasing. The last inequality holds because  and .
Moreover,

where the equality follows from the result of part~(a). We
now redefine the Markov process  for , to be the
uncontrolled dynamics with initial condition . Again, it can be easily observed that

 Thus

Set , and apply Lemma~\ref{epsi-tau} to get


\remove{

Observe that

Thus,

The last equality can be easily seen to be true. Similarly, it can be shown that


aaaaaaaaaaaa


Following~\cite[Theorem~2.8]{stochproc.darling02fluid-limits} we have that, for every ,

Now we show that, for every ,

However,

Thus, it suffices to prove that

These follow once we recognize that


ssssssssssss

}
\item Finally, we prove the convergence of  to  over
. Reconsider the process
 and the associated function
. Recall that, for any ,  and
 exit  at 
and  respectively. Clearly,
; say
. Also,
using~\cite[Theorem~2.8]{stochproc.darling02fluid-limits},

Furthermore, we have that  sample path wise. The  inequality holds
because  may continue to increase (in both its components)
at a higher pace than  even after . Thus

implying that the probability that   has changed its
dynamics by  approaches  as  approaches
. In these realizations, the dynamics of  and 
match for . We restrict ourselves to
only these realizations. We also have from part~(b) that, for every
,

Once more using~\cite[Theorem~2.8]{stochproc.darling02fluid-limits}, for any 


\end{inparaenum}

\section{Proof of Theorem~\ref{theorem:asym-optimal}}
\label{proof-asym-optimal}
For the optimal policy , the total expected cost

since  by definition~(see~\eqref{eqn:tau-K});
we use the subscript  to show dependence of the probability law on the underlying policy.
Under the deterministic policy , copying to relays is stopped at the deterministic
time instant , implying . Thus, the total expected cost

Also observe that for  under , the corresponding fluid limits are
the same deterministic dynamics  defined in
Section~\ref{asym-det-dynamics}~(i.e., solutions of~\eqref{eqn:f-1}-\eqref{eqn:f-2}).
 and  satisfy the hypotheses assumed in Darling~\cite{stochproc.darling02fluid-limits} over the intervals
 and . Thus~\cite[Theorem~2.8]{stochproc.darling02fluid-limits}
applies, and we conclude~\footnote{Applying~\cite[Theorem~2.8]{stochproc.darling02fluid-limits} over  yields

which is a necessary condition to apply~\cite[Theorem~2.8]{stochproc.darling02fluid-limits} over .}


\remove{
Furthermore, it can be easily shown that under both the controls  and ,
the delivery delays  have second moments which are bounded uniformly over all , i.e.,\footnote{The proof entails
binding ~(under the control  or ) by the delivery delays under the policy that never
copies to relays, and showing that the latter have second moments which are bounded uniformly over all .}

}
Furthermore, it can be easily shown that under both the controls  and ,
the delivery delays  have second moments that are bounded uniformly over all . To see this,
consider a policy  that never copies to relays. Clearly,

for each . Then is suffices to show that

Note that

where  is the time duration for which ;  are independent,
and   is exponentially distributed with mean
 under policy  .
Thus

Similarly,

as . These results together imply~\eqref{eqn:delay-u0}.

Following~\cite[Remark~9.5.1]{stochproc.measure-and-probability}, under both  and ,
 are uniformly integrable. Since, , under both  and , converge to 
in probability and hence in distribution,~\cite[Theorem~9.5.1]{stochproc.measure-and-probability} yields


Next, it is easy to show that under the control ,  converges
to  in probability. To see this, observe that

From Theorem~\ref{assym-optimality},  and  converge to  and  respectively, in probability.
The latter result, along with the arguments similar to those in the proof of Lemma~\ref{epsi-delta}, implies
that

for every . Using these facts in~\eqref{ineq:conv-y}, we conclude that

for every . Since  is bounded, and hence uniformly integrable,~\cite[Theorem~9.5.1]{stochproc.measure-and-probability}
implies that

Similarly, under the control  also,  is bounded, and hence is uniformly integrable. It
also converges to   in probability. Once more using~\cite[Theorem~9.5.1]{stochproc.measure-and-probability}, we get

Combining~\eqref{eqn:conv-y_ast} and~\eqref{eqn:conv-y_infty}

Finally, combining~\eqref{eqn:delay-tau} and~\eqref{eqn:copy-cost}, we get that



\remove{


Recall the definition of  in~\eqref{eqn:tau-K}. Also, define

Then, for the optimal policy ,

where as for the deterministic policy ,

For any , it is already shown that

and it can be easily shown that

Since under both the controls,  and , the random variable   has finite mean
and second moment, we conclude that

Next, let us consider the uncontrolled dynamics of the number of infected relays.
Following Lemma~\ref{epsi-delta}, for every ,

Since, the random variables  and  are bounded,
we get

Observe that   and
. Thus

Finally, combining~\eqref{eqn:delay-tau} and~\eqref{eqn:copy-cost}, we get that

}

\section{The Hamiltonian Formulation and The Solution}
\label{hamiltonian}

In this section we consider the limiting deterministic~(fluid) system  
and study its optimal control.
The limiting controlled system is: , , and for ,

\frac{{\rm d}x(t)}{{\rm d}t} &= \Lambda (x(t) + y(t))(X-x(t)), \label{controlled-drift-1}\\
\frac{{\rm d}y(t)}{{\rm d}t} &=  \Lambda (x(t) + y(t))(Y-y(t))u(t) \label{controlled-drift-2}\

where  is the control at time . Our objective is to minimize

where  is the terminal time when ; dependence of  on the underlying control is understood, and
is not shown explicitly. 
\begin{theorem}
The optimal policy for the deterministic system~\eqref{controlled-drift-1}-\eqref{controlled-drift-2} with cost~\eqref{objective} 
is 

with  as in~\eqref{eqn:stop-relays}.
Furthermore, the optimal cost is  with   as in~\eqref{eqn:stop-dstns}.
\end{theorem}
\begin{IEEEproof}
Following~\cite[Section~3.3.1]{stochctrl.bertsekas05dpoc-vol1}, we define the Hamiltonian for the system

where  are the cojoint functions
associated with  and  respectively.
Let , be an optimal control trajectory.
Let  be the corresponding terminal time, and let 
be the  corresponding state trajectory.
\paragraph{Adjoint equations}
By~\cite[Section~3.3.1, Proposition~3.1]{stochctrl.bertsekas05dpoc-vol1},
the functions  are
solutions of the following adjoint equations:

\paragraph{Boundary condition} 
Observe that the terminal cost is .
Thus, by~\cite[Section~3.3.1, Proposition~3.1]{stochctrl.bertsekas05dpoc-vol1},

\paragraph{Minimum principle} Moreover, the optimal control  satisfies

for all . From~\eqref{eqn:hamiltonian}, it is
immediate that the optimal policy is a bang-bang policy.

In particular, our observation~\eqref{adjoint-bdary-cond1} implies that
. 
\paragraph{Free terminal time condition}
Since the terminal time is free, we also
have from~\cite[Section~3.4.3]{stochctrl.bertsekas05dpoc-vol1} that

for all . In particular, equality at  implies~(see~\eqref{eqn:hamiltonian})

Since , we must have

 We will find this observation useful later.

Our characterization of the optimal control consists of two steps.
First we show that the optimal control trajectory is of threshold
type, i.e.,

This is done in the next subsection. In the subsequent subsection,
we obtain the threshold .

\subsection{Optimal control is of threshold type}
We show that  is negative for  and
strictly positive for  for some
. It then follows from~\eqref{hamiltonian-min} that
 is as in~\eqref{threshold-policy}. Recall  in~\eqref{adjoint1}. We consider two scenarios.
\subsubsection{Case~1}
\label{form-part1} Let . Since  and  both are non-decreasing in
, we have
 
Moreover, from~\eqref{hamiltonian-min},

with equality at . Thus, from~\eqref{adjoint1},

for all   at which . But, using the observation
~(see~\eqref{adjoint-bdary-cond2}), it immediately follows that

and so,  for all . Now, from~\eqref{adjoint2}, 

for all   at which .  Again, using the observation
~(see~\eqref{adjoint-bdary-cond1}), it follows that
either  for all , 
or there exists a  such that , and 


\subsubsection{Case 2}
\label{form-part2}
 Let .
Observe that  is decreasing in .
Thus, tracing back from , there exists a  such
that ; we set  if
 for all .
Clearly,  for all .

We claim that   for all . 
Suppose not, i.e., there exists a  such that
. Then, from~\eqref{adjoint1},

and so,  increases with  in this interval. But this
contradicts the assertion in~\eqref{adjoint-bdary-cond2} that
. Hence the claim holds.

Now, , and .
An argument similar to that in {\it Case~1} yields that 

and so,  for all ; 
recall that it is readily seen that   for all .  
Consequently, as in {\it Case~1},
either  for all , 
or there exists a  such that , and 


\remove{
 for all . Our assertion
for conclusion implies that~(see~\eqref{adjoint2})

and so,  is increasing in . Since
, either there exists a  such that  and

or  for all . In the former case,


for all  , further implying that  for all
. In the latter case, . We also have  and .
But this is similar to {\it Case~1}, whence we conclude that either
 for all , or there exists a  such that

}

To summarize, in both the cases there exits a  such that


\subsection{Optimum Threshold}
We now characterize the optimal threshold . Consider a threshold policy

Let the corresponding state trajectory be
, and let the terminal
time be . Let  and
 be the values at the threshold
time . Clearly,

The associated cost is

and\footnote{We can restrict to only those  such that .}

For any  and ,

and so

Its substitution in~\eqref{eqn:cost-threshold} yields

Using Leibniz rule of differentiation, we get

where the last equality uses~\eqref{eqn:gredient-barx}. Defining

we get

Note that , ,
, , 
and so  is also strictly increasing in  with slope bounded away from .
Thus, the optimal threshold is given by

which is identical to  in~\eqref{eqn:stop-relays}.
\end{IEEEproof}
\begin{remarks}
Combined with Theorem~\ref{theorem:asym-optimal}, we now have that the limit of the optimal cost~(of the finite problem) equals the
optimal cost of the limiting system. This does not hold in general~(see Remark~\ref{remark:cost-comparision}).
\end{remarks}

\bibliographystyle{IEEEtran}
\bibliography{IEEEabrv,ctrl-theory,stoch-proc,stoch-ctrl,comm-net}

\end{document}
