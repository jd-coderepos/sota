\documentclass[a4paper]{sig-alternate}
\usepackage[plainpages=false,pdfpagelabels,colorlinks=true,citecolor=blue,hypertexnames=false]{hyperref}
\usepackage{amssymb}
\usepackage{bbm}
\usepackage[utf8]{inputenc}
\usepackage{algo}

\def\<#1>{\langle#1\rangle}
\let\set\mathbbm
\def\vec#1{\mathbf{#1}}
\def\spread{\operatorname{Spread}}
\def\disp{\operatorname{Disp}}
\def\res{\operatorname{res}}
\def\lcm{\operatorname{lcm}}

\def\K{\set K}

\overfullrule=5mm

\newtheorem{theorem}{Theorem}
\newtheorem{proposition}{Proposition}
\newtheorem{corollary}{Corollary}
\newtheorem{lemma}{Lemma}
\newtheorem{definition}{Definition}
\newtheorem{example}{Example}
\newtheorem{rem}{Remark}
\newtheorem{algorithm}{Algorithm}

\newcommand{\todo}[1]{{\fbox{\bfseries TO DO:} {\sffamily #1}}}

\begin{document}

\title{A Refined Denominator Bounding Algorithm for Multivariate Linear Difference Equations}

\numberofauthors{2}
\author{
 \alignauthor Manuel Kauers\titlenote{Supported by the Austrian FWF grant Y464-N18 and 
     the EU grant PITN-GA-2010-264564.}\\smallskipamount]
      \email{mkauers@risc.jku.at}
 \alignauthor Carsten Schneider\titlenote{Supported by the Austrian FWF grant P20347-N18
     and the EU grant PITN-GA-2010-264564.}\\smallskipamount]
      \email{cschneid@risc.jku.at}
}

\maketitle

\begin{abstract}
  We continue to investigate which polynomials can possibly occur as factors in the
  denominators of rational solutions of a given partial linear difference equation.
  In an earlier article we had introduced the distinction between periodic and
  aperiodic factors in the denominator, and we gave an algorithm for predicting
  the aperiodic ones. Now we extend this technique towards the periodic case
  and present a refined algorithm which also finds most of the periodic factors.
\end{abstract}

\kern-\medskipamount

\category{I.1.2}{Computing Methodologies}{Symbolic and Algebraic Manipulation}[Algorithms]

\kern-\medskipamount

\terms{Algorithms}

\kern-\medskipamount

\keywords{Difference Equations, Rational Solutions}

\section{Introduction}

The usual approach for finding rational solutions of linear difference equations
with polynomial coefficients is as follows. First one constructs a nonzero polynomial~ such
that for any solution  of the given equation we must have .
Such a polynomial~ is called a denominator bound for the equation.  Next, the
denominator bound is used to transform the given equation into a new equation
with the property that a polynomial~ solves the new equation if and only if
the rational function  solves the original equation.  Thus the
knowledge of a denominator bound reduces rational solving to polynomial solving.

The first algorithm for finding a denominator bound~ was given by Abramov in
1971~\cite{abramov71,Abramov:89b,abramov91}. During the past fourty years, other
algorithms were found~\cite{paule95,hoeij98,bostan06,chen08b} and the technique
was generalized to matrix equations~\cite{abramov98a,barkatou99} as well as to
equation over function fields~\cite{Petkov:92,bronstein00,schneider04c}. Last
year~\cite{kauers10b} we made a first step towards a denominator bounding
algorithm for equations in several variables (PLDEs). We found that some factors
of the denominator are easier to predict than others. We called a polynomial
periodic if it has a nontrivial gcd with one of its shifts, and aperiodic
otherwise. For example, the polynomial  is periodic because shifting it
twice in~ and three times in~ leaves it fixed.  We say that it is periodic
in direction . An example for an aperiodic polynomial is . The
main result of last year's paper was an algorithm for determining aperiodic
denominator bounds for PLDEs, i.e., we can find  such that whenever
 solves the given equation and  is aperiodic, then .

The present paper is a continuation of this work. We now turn to periodic
factors and study under which circumstances a slightly adapted version of last
year's algorithm can also predict periodic factors of the denominator. We
propose an algorithm which finds the periodic factors for almost all
directions. Every equation has however some directions which our algorithm does
not cover. But if, for instance, we have a system of two equations and apply our
algorithm to each of them, then the two bounds can under favorable circumstances
(which can be detected algorithmically) combined to a denominator bound which
provably contains all the factors that can possibly occur in the denominator of
any solution of the system. This was not possible before. So while until now we
were just able to compute in all situations some factors, we can now also find
in some situations all factors.

Despite this progress, we must confess that our results are still of a somewhat
academic nature because denominator bounds in which some factors are missing are
not really enough for solving equations. And even when a full denominator bound
is known, it still remains to find the polynomial solutions of a PLDE, and
nobody knows how to do this---the corresponding problem for differential
equations is undecidable. But in practice, we can heuristically choose a degree
bound for finding polynomial solutions, and knowing parts of the possible
denominators is certainly better than knowing nothing, and the more factors we
know, the better. Apart from this, we find it interesting to see how far the
classical univariate techniques carry in the multivariate setting, and we would
be curious to see new ideas leading towards algorithms which also find the
factors that we still miss.

\section{Preparations}

Let  be a field of characteristic zero. We consider polynomials and rational functions
in the  variables  with coefficients in~. For each variable~,
let  denote the shift operator mapping  to  and leaving all other variables
fixed, so that

for every rational function~. Whenever it seems appropriate, we will use multiindex
notation, writing for instance  instead of  or 
for .

We consider equations of the form

where  is finite and nonempty,  and 
() are given, and  is an unknown rational function.
Our goal is to determine the polynomials  which may possibly occur in the denominator
of a solution~, or at least to find many factors of~.

We recall the following definitions and results from our previous paper~\cite{kauers10b}.

\begin{definition} Let .
\begin{enumerate}
\item The set  is called
  the \emph{spread} of  and~.
  For short, we write .
\item The number  is called
  the \emph{dispersion} of  and  with respect to . (We set
   if  is empty and  if  is unbounded.)
\item The polynomial  is called \emph{aperiodic} if  is finite, and \emph{aperiodic}
  otherwise.
\item The polynomial~ is called an \emph{aperiodic denominator bound} for equation~\eqref{eq:main}
  if  and every solution~ can be written as  for some 
  where  is periodic and .
\item A point  is called a \emph{corner point} of 
  if there exists a vector  such that  for all
  . Such a vector  is then called an \emph{inner vector,}
  and the affine hyperplane  is called a
  \emph{border plane} for~.

  \medskip
  \centerline{\epsfig{file=cornerpoint.eps}}

\end{enumerate}
\end{definition}

\begin{theorem}\label{thm:1} Let .
\begin{enumerate}
\item If  is irreducible, then  is a submodule of~ and
   is aperiodic if and only if .
\item\label{thm:1.2} If  and  are irreducible, then there exists  such that
   is a submodule of~.
\item There is an algorithm for computing .
\item There is an algorithm for computing an aperiodic denominator bound for~\eqref{eq:main}
  given the support  and the coefficients  ().
\end{enumerate}
\end{theorem}

\section{Denominator Bounds modulo a Prescribed Module}

Our goal in this section is to determine the factors whose spread is contained
in some prescribed set~. Under suitable assumptions
about~ such factors must pop up in the coefficients of the equation (cf.\
Lemma~\ref{lem:2} below) and under stronger assumptions we can also give a bound
on the dispersion between them (cf.\ Theorem~\ref{thm:disp} below). Using these
two results we obtain a denominator bound relative to~ (cf.\
Theorem~\ref{thm:db} and Algorithm~\ref{algo:1}) below. In the next section, we
then propose an algorithm which combines the denominator bounds with respect to
several sets~. It turns out that by considering only finitely many sets~ 
one can obtain a denominator bound with respect to infinitely many sets~.

\begin{definition}
  Let  with .
  A polynomial  is called a denominator bound of \eqref{eq:main}
  with respect to~ if for every solution 
  of \eqref{eq:main} and every irreducible factor  of~ with
   we have .
\end{definition}

Typically, ~will be a submodule of  or a union of such modules.
The definition reduces to the notion of aperiodic denominator bound
when . In the other extreme, when  then  is
a ``complete'' denominator bound: it contains all the factors, periodic or not,
that can possibly occur in the denominator of a solution~ of~\eqref{eq:main}.
In general, ~predicts all aperiodic factors in the denominator of a solution
as well as the periodic factors whose spread is contained in~.

Denominator bounds with respect to different submodules can be combined as follows.

\begin{lemma}\label{lemma:lcm}
  Let  be submodules of~, and let
   be denominator bounds of \eqref{eq:main} with respect to
  , respectively. Then
   is a denominator bound with respect to
  .
\end{lemma}

\begin{proof}
  Let  be an irreducible factor of the denominator of some solution
  of~\eqref{eq:main} and suppose that . It suffices
  to show that then  for some~, because then it follows that
  , as desired.

  We show that if  contains some vector , then
  , hence .
  Applying the argument repeatedly proves that  for some~.

  Let . Since  is a submodule of , we have  for all .  By assumption , so each such  must belong to at
  least one module~ (). It cannot belong to~ though,
  because together with  this would imply , which
  is not the case. Therefore: For every  there exists
   such that .

  Since  is infinite and  is finite, there must be some index
   for which there are two different
   with  and
  . Since  is also a submodule of~, it follows that , and finally , as claimed.
\end{proof}

The next result says that factors of denominators tend to leave traces in the
coefficients of corner points of~.

\begin{lemma}\label{lem:2}
  Let  be a submodule of  and let  with 
  be an irreducible factor of the denominator of some solution~ of~\eqref{eq:main}.
  Let  be a corner point of  with an inner vector 
  orthogonal to  (meaning  for all ).
  Then there exists  such that .
\end{lemma}

\begin{proof}
  If  is another irreducible factor of the denominator of~ and
   is nonempty, then we have  for some .
  This follows from Theorem~\ref{thm:1}.\ref{thm:1.2} and the assumption .
  For the full denominator~ of~, we can thus find 
  with  where each element
  from  is necessary.
  Let  be such a choice, and let  be such that
   is minimal.

  We have
  
  as an identity in . Therefore, every factor in the denominator of 
  must either be canceled by  or it also occurs as a factor in at least
  one of the  ().
  The factor  appears in the denominator of~.
  If it also appeared in the denominator of  for some ,
  then this would imply  for some .
  But then , which is in contradiction to
  
  because  is orthogonal to  by assumption.
  Hence  cannot appear as a denominator on the right hand side,
  and hence it must be canceled on the left hand side.
  This forces , so the claim is proven for
  . \qed
\end{proof}

The lemma tells us for which choices of  something nontrivial may happen.
Let us illustrate this with an example.

\begin{example}\label{ex:1}
  The equation
  
  has the solution . Its denominator is periodic, .
  Lemma~\ref{lem:2} predicts the appearance of  (or at least some shifted version of it)
  in the coefficient of~, because for the choice , the point
   admits the choice  in accordance with the requirements imposed
  by the lemma. Note that no shift equivalent copy of  occurs in the coefficients of 
  or , which does not contradict the lemma, because the points  and  lie on
  a line parallel to~. This has the consequence that for these points, there does not exist
  a vector  with the required property.

  Conversely, the factor  cannot possibly appear in the denominator of a solution,
  because for  we can take  and
  , and according to the lemma, some shifted version of 
  would have to appear in the coefficient of .

  More generally, for any nontrivial submodule  of  other than~, Lemma~\ref{lem:2}
  excludes the possibility of periodic factors whose spread is contained in~, because such
  factors would have to leave a trace in at least one of the coefficients of the equation.

  \medskip
  \centerline{\epsfig{file=example1.eps}}

\end{example}

In the previous example, we could thus determine all the interesting modules  by just looking
at the spreads of the the factors of the coefficients of the equation. The following example
indicates that this is not always sufficient.

\begin{example}\label{ex:2}
  The equation
  
  also has the solution . Its denominator  does not appear in
  any of the coefficients of the equation. This is because for its spread 
  there are no suitable  and  matching the conditions of the
  lemma because the points  as well as the points  lie
  on a line parallel to~.
\end{example}

In summary, in order for  to be the spread of a factor that can appear in the denominator
of a solution of~\eqref{eq:main}, ~must be contained in the spread of some coefficient
of the equation (as in Ex.~\ref{ex:1}) or it must be parallel to one of the faces in the
convex hull of the support~ (as in Ex.~\ref{ex:2}).
For every equation, we can thus determine some finitely many submodules of  of
codimension one such that each possibly occuring spread  is contained in at least one
of them.

\subsection{A Normalizing Change of Variables}\label{sec:normal}

Let  be a decomposition of~ into submodules.
Our goal is to obtain denominator bounds with respect to~ by applying the
algorithm from last year~\cite{kauers10b} to .
It turns out that this can be done provided
that  is sufficiently nondegenerate. In order to formulate the precise
conditions on~ without too much notational overhead, it seems convenient
to make a change of coordinates.

Let invertible matrices 
act on  via

We obviously have  and
 for all .
It can be checked that we also have

for every  with  and
every  and every .
It follows that  is a solution of \eqref{eq:main}
if and only if  is a solution of the transformed equation

or equivalently of

where , 
(), and .

Now take  with  such that the first  rows of 
form a basis of  and the last  rows of  form
a basis of~. Then the transformation just described maps
the basis vectors of  to the first  unit vectors and the basis
vectors of  to the last  unit vectors. In other words, we can
assume without loss of generality that  itself is generated by the
first  unit vectors and  by the last  unit vectors in~.
We will make this assumption from now on, unless otherwise stated.
Note that this convention implies for an irreducible polynomial 
that  is equivalent to  being free of the variables
 and aperiodic as element of .

By applying, if necessary, a suitable power of  on both sides of the
equation we can further assume without loss of generality that
, and we set
.
\subsection{Bounding the Dispersion}

With this transformation w.r.t.\ the submodule  of  and under the assumption that the extreme points~\eqref{Equ:ABSet} of  have certain properties, Theorem~\ref{thm:disp} explains how one can bound the dispersion along the -coordinate of all factors  with  that occur in the denominator of a solution of~\eqref{eq:main}. This result is a refinement of Lemma~2 from~\cite{kauers10b}.

\begin{lemma}\label{Lemma:UniqueTComponents}
Let  with  and . Then

\end{lemma}
\begin{proof}
Take  with . As , it follows , and thus the first  components of  agree.
\end{proof}

\begin{theorem}\label{thm:disp}
  Let
  
  Suppose that no two elements of  agree in the first  coordinates,
  and that the same is true for~. Let  be those polynomials which contain all irreducible factors  of  with . Let
  
  Then for any solution  of  and any irreducible
  factors  of  with  we have .
\end{theorem}
\begin{proof}
As  is not empty, ~are nonempty. W.l.o.g.\ we may assume that the minimal element of  w.r.t.\ lexicographic order is the zero vector.\\
Suppose that there are irreducible factors  of  with ,  and  such that ; take such  such that  is maximal.
Consider all the factors  and  occurring in  where the first entry in  and  is . Note that by Lemma~\ref{Lemma:UniqueTComponents} there are only finitely many choices of the first  components, so we can choose two such factors from  where the first  components of  are minimal and the first  components of  are maximal w.r.t.\ lexicographic order; these factors are denoted by  respectively.\\
 First suppose that  divides one of the polynomials  with .
In this case we choose the polynomial  with  such that  is maximal w.r.t.\ lexicographic order (uniqueness is guaranteed by the assumption that no two elements from  agree in the first  components). We can write~\eqref{eq:main} in the form

Now observe that the factor  does not occur in the denominator of any  with :
\begin{enumerate}
\item Suppose that there is  such that  occurs in , i.e.,  is a factor of . Since the first component of  is  () and the first component of  is smaller than  (), the first component of  is positive. Moreover, since the distance between the factors  and  of  is  in the first component, the factors  and  of  have distance larger than  in the first component; a contradiction that the distance  is maximally chosen. Consequently, if  is a factor
    in the denominator of  with , it follows that .
\item Suppose that there is  with  such that  is a factor of . Then  is a factor of . Since the first component of the vectors in  is , but the first  components in total cannot be the same for two different vectors of , it follows that the first entry in  is zero and at least one of the others is non-zero; in particular, by the maximality assumption on  the first non-zero entry is positive. Hence we find  such that  is a factor of  and such that  is larger than  w.r.t.\ lexicographic ordering; a contradiction to the choice of the vector .
\end{enumerate}
Since , the common denominator of the rational function
 does not contain the factor  .  Now suppose that  is a factor of . Since ,
its first component is . But then, since  and  have distance  in the first coordinate, also the factors  and  have distance . Thus
 which implies that ; a contradiction. Overall, the common denominator on the right hand side of~\eqref{Equ:RewritePLDE} cannot contain the factor  which implies that the denominator of  is not divisible by . Thus the denominator of , in particular  is not divisible by ; a contradiction.\\
 Conversely, suppose that  does not divide any of the polynomials  with . Now let  such that  is minimal w.r.t.\ lexicographic ordering (again it is uniquely determined by the assumptions on ), and write~\eqref{eq:main} in the form~\eqref{Equ:RewritePLDE}; by our assumption stated in the beginning,  is just the zero vector . By analogous arguments as above (the roles of  and  are exchanged) it follows that  does not occur in the denominator of any  with . Hence as above, the common denominator of
 does not contain the factor  . Moreover, since  does not divide any  from , the factor  does not occur in . In total, the factor  is not part of the denominator on the right hand side of~\eqref{Equ:RewritePLDE}, but it is a factor of the denominator on the left hand side; a
contradiction.
\end{proof}

If the required properties on the sets~\eqref{Equ:ABSet} in Theorem~\ref{thm:disp} are violated, our bounding strategy does not work, as can be seen by the following example.

\begin{example}
Fix  and take
. The problem from Example~\ref{ex:1} is normalized
by the change of variables  and  (i.e., a basis transformation \tiny\normalsize with determinant  is chosen) and one obtains  and . This gives the new equation
  
with the new structure set 
which now has the solution  where the denominator consists of the factor  with . As observed already in Example~\ref{ex:1} one can predict the factor  (up to a shift in ) by exploiting Lemma~\ref{lem:2}. However, one cannot apply Theorem~\ref{thm:disp}. For  we get the sets  and  where in  the two vectors are the same in the first component but differ in the second component.
\end{example}

\subsection{Denominator Bounding Theorem}

The denominator bounding theorem says that if we rewrite the equation \eqref{eq:main} into
a new equation whose support contains some point  which is sufficiently far away from
all the other points in the support, then we can read off a denominator bound from this
new equation. We will need the following fact, which appears literally as Theorem~3 in~\cite{kauers10b}
(with  renamed to  here in order to avoid a name clash with the meaning of 
in the present paper).

\begin{lemma}\label{lemma:1}
  Let  be a corner point of  with border plane  and inner vector~.
  Then for every  there exist finite sets
  
  and polynomials  such that for any solution 
  of \eqref{eq:main} we have
  
\end{lemma}

The sets  and  and the polynomials  can be computed for a
given , , , and~ by Algorithm~2 from~\cite{kauers10b}. The next theorem provides
a denominator bound with respect to~. It is an adaption of Theorem~4 from~\cite{kauers10b}
to the present situation. We continue to assume the normalization ,
.

\begin{theorem}\label{thm:db}
  Let  be such that for any solution 
  of~\eqref{eq:main} and any irreducible factors  of  with 
  we have .
  Let  be a corner point of  for which there is an inner vector 
  with  as well as an inner vector  orthogonal to~.
  For these choices of , , and~, let , , ,~ be as in
  Lemma~\ref{lemma:1}.
  Let  be the polynomial consisting of all the factors of 
  whose spread is contained in~.
  Then
  
  is a denominator bound of~\eqref{eq:main} with respect to~.
\end{theorem}

\begin{proof}
  Let  be a solution of~\eqref{eq:main} and let  be an irreducible
  factor of  with multiplicity  and .
  We have to show .
  Lemma~\ref{lem:2} applied to  and  implies that there is some 
  with  and .
  By the choice of~ we have .

  Lemma~\ref{lemma:1} implies the representation
  
  Because of , every  differs from  in the first coordinate
  by more than~. This implies that  and hence that  cannot appear in the denominator of
   for any . But it does appear in the denominator of~,
  so it must appear as well in the denominator of the right hand side.
  The only remaining possibility is thus
  ,
  and hence
  
  Because of , it follows that .
\end{proof}

The following figure illustrates the situation. The vector  is orthogonal to 
but not necessarily to~, while the vector  is orthogonal to  but not
necessarily to~.
Relation~\eqref{eq:reduced} separates  from the points in  which are all below
the plane . The points in  are all between  and .

\medskip
\centerline{\epsfig{file=separated.eps}}

\medskip

\subsection{A Denominator Bounding Algorithm}

We now combine Theorems~\ref{thm:disp} and~\ref{thm:db} to an algorithm
for computing a denominator bound with respect to an arbitrary given~
in situations where these theorems are applicable.

\begin{definition} Let  be corner points of~
  and  some submodule of~.
  \begin{enumerate}
  \item The point  is called \emph{useless} for  if there is an edge 
    in the convex hull of  with .
  \item The pair  is called \emph{opposite} if there is a vector 
    such that  and
     for all .
    Such a  is called a \emph{witness vector} for the pair .
  \item The pair  is called \emph{useful} for  if it is opposite and neither
     nor  is useless for~.
  \end{enumerate}
\end{definition}

The definition of a useful pair is made in such a way that when a change of variables as
described in Section~\ref{sec:normal} is applied which maps a witness vector of the pair
to the first axis, then the sets  and  from Theorem~\ref{lem:2} are such that
,  (because of the oppositeness), no two elements of 
agree in the first  coordinates (because  is not useless), and the
same is true for~ (because  is not useless).

Whether a pair  is useful or not can be found out by making an
ansatz for the coefficients of a witness vector and solving the system of linear
inequalities from the definition. The pair is useful if and only if this system is
solvable, and in this case, any solution gives rise to a witness vector.

If for a given submodule  we have found a useful pair, then we can compute a denominator
bound with respect to  by the following algorithm.

\begin{algorithm}\label{algo:1}
\emph{Input:} An equation of the form \eqref{eq:main}, a submodule  of~,
   a useful pair  of~ for~.
\emph{Output:} A denominator bound for \eqref{eq:main} with respect to~.

\begin{algo}\text{Set .}
  \text{Choose  such that  is a witness}\label{alg:1:2}
  ^^I^^I^^I\text{vector for  and  where}
  ^^I^^I^^I\text{ is the module generated by these vectors.}
  \text{Perform a change of variables as described in}
  ^^I^^I^^I\text{Section~\ref{sec:normal} such that  becomes the th unit}
  ^^I^^I^^I\text{vector in ,  becomes .}
  \text{Determine  as in Theorem~\ref{lem:2}.}\label{a:1:11}
  \text{Compute  as defined in Theorem~\ref{lem:2}.}
  \text{Choose an inner vector  for .}
  \text{Compute  as defined in Lemma~\ref{lemma:1}.}
  \text{Compute  as defined in Theorem~\ref{thm:db}.}
  \text{Apply the inverse change of variables to~, getting .}
  \text{Return .}\end{algo}
\end{algorithm}

The following variations can be applied for further improvements:

\begin{enumerate}
\item If the dimension of  is larger than 1, there might be different choices
  of witness vectors. Choosing different versions in line~\ref{alg:1:2} might
  lead to different denominator bounds of , say, . Then taking
   leads to a sharper denominator bound
  for~\eqref{eq:main} w.r.t.\ .

\item Choosing different inner vectors in line~10 might lead to different sets 
to write~\eqref{eq:reduced} and hence gives rise to different denominator bounds in~\eqref{Equ:DenBoundPlance}. Taking the gcd of these denominator bounds produces a refined version.
\end{enumerate}

We remark that the coefficients  with  are often available in factorized form. Then also the denominator bounds are obtained in factorized form, and the gcd-computations reduce to comparisons of these factors and bookkeeping of their multiplicities.


\section{A Combined Denominator Bound}

As mentioned earlier, when setting , one is able to derive an aperiodic
denominator bound for equation~\eqref{eq:main}. In this particular case, for
each corner point  there is an other corner point  such that
 is useful for . Hence applying Algorithm~\ref{algo:1} for
any useful pair leads to an aperiodic denominator bound. In particular, running
through all corner points and taking the gcd for all these candidates leads to a
rather sharp aperiodic denominator bound for equation~\eqref{eq:main} which
coincides with the output given in our previous investigation~\cite{kauers10b}.

In the other extreme, when setting , a denominator bound
for~\eqref{eq:main} w.r.t.\  would lead to a complete denominator bound for
equation~\eqref{eq:main}. However, in this case, we will fail to find 
a useful pair , and our Algorithm~\ref{algo:1} is not
applicable.

Our goal is to find a simultaneous denominator bound with respect to all 
to which Algorithm~\ref{algo:1} is applicable, i.e., for all  from the set

In general, this is an infinite set. But we can make use of the observations
made after Example~\ref{ex:2}. Using Lemma~\ref{lem:2}, it turns out that instead 
of looping through all these infinitely many modules~, it is sufficient to
consider those  which appear as spread of some factor in the coefficient of
.

This argument even works for all  in the larger set

but since the  do not satisfy the conditions of Theorem~\ref{thm:disp},
we can only obtain partial information about their denominator bounds. 

We propose the following algorithm. 



\begin{algorithm}\label{algo:2}
\emph{Input:} An equation of the form \eqref{eq:main}.
\emph{Output:} A finite set of irreducible polynomials , and
  a nonzero  such that for every solution  of~\eqref{eq:main} and every irreducible factor  of  with multiplicity  exactly one of the following holds:\\
  1.  and ,\\
  2.  and ,\\
  3. .

\begin{algo}d:=1
  P:=\{\}
  C:=\{\vec p\in S: \vec p\text{ is a corner point of }\}
  |forall| \vec q\in C |do|
  ^^I |forall| u\mid a_{\vec q}\text{ irreducible} |do|\label{alg:2:5}
  ^^I^^I W := \spread(u)
  ^^I^^I |if| W\in U |then|
  ^^I^^I^^I \text{Compute a denominator bound  w.r.t.\ }\label{alg:2:9}
  ^^I^^I^^I^^I^^I^^I \text{using an arbitrary useful pair for .}
  ^^I^^I^^I d := \lcm(d,d_0)\label{alg:2:11}
  ^^I^^I |else\ if| W\in O |then|
  ^^I^^I^^I P := P \cup\{u\}\label{alg:2:12}
  |return| (P,d)\end{algo}
\end{algorithm}

\begin{theorem}\label{thm:combined}
  The polynomial  computed by Algorithm~\ref{algo:2}
  is a denominator bound with respect to any finite union of modules in~.
\end{theorem}
\begin{proof}
  Let  be in~ and  be a useful pair with respect to~.
  Let  be a solution of~\eqref{eq:main} and  be an irreducible factor
  of  with multiplicity~ and .
  We have to show that .

  Since  is not useless, Lemma~\ref{lem:2} implies that there is some
   with . This factor is going
  to be investigated in some iteration of the loop starting in line~\ref{alg:2:5}.
  The polynomial  computed in this iteration is a denominator bound with
  respect to  and hence a forteriori a 
  denominator bound with respect to~. 
  It follows that .

  This proves the theorem when  itself is in~. If  is only a finite union
  of elements of~, the theorem follows from here by Lemma~\ref{lemma:lcm}.
\end{proof}

For , we can still apply Lemma~\ref{lem:2} but
Theorem~\ref{thm:disp} is no longer applicable. This prevents us from computing
precise denominator bounds with respect to these~. However, using the set
 returned by the algorithm we can at least say that 
for every denominator  of a solution  of~\eqref{eq:main} there
exist  and a finite set  such that

is a multiple of every divisor of  whose spread is contained in some finite
union of modules in~. Appropriate choices  and  can be found for instance by making an
ansatz. Note also that the set~ is usually smaller than the set of all
periodic factors that occur in the coefficients 
of~\eqref{eq:main}. This phenomenon was demonstrated already in the second part
of Example~\ref{ex:2}.



Summarizing, some part of the denominator is out of reach, namely all those parts of the denominator w.r.t.\ the modules from

some part of the denominator can be given up to possible shifts and multiplicities, and a big part of our denominator bound can be given explicitly by~.

The following improvements can be utilized.

\begin{enumerate}
\item As preprocessing step, one should compute an aperiodic denominator bound for the equation~\eqref{eq:main} as described above. What remains is to recover the periodic factors. As a consequence, one can neglect all irreducible factors  which are aperiodic and one can apply Theorem~\ref{thm:db} where all aperiodic factors are removed from the polynomials .

\item Choosing different useful pairs for a module  in line~9 might lead to different choices of denominator bounds, and taking their gcd gives rise to sharper denominator bounds of~\eqref{eq:main} w.r.t.\ .
\end{enumerate}


\section{Discussion}

Typically the set  will contain all the submodules of . Only when
the convex hull of  happens to have two parallel edges on opposite sides, as
is the case in Example~\ref{ex:2}, then modules  parallel to this edge do not
belong to~.  The set  will never contain all the submodules of~. Precisely those modules  which are parallel to an edge of the convex
hull of~ do not belong to~. Since the convex hull of  contains only
finitely many edges, ~will in some sense still contain almost all the
submodules of~.

Depending on the origin of the equation, it may be that there is some freedom in
the structure set~. For example, by multivariate guessing~\cite{kauers09a} or
by creative telescoping~\cite{zeilberger91,chyzak00,schneider04c} one can
systematically search for equations with a prescribed structure set. In such
situations, one can try to search for an equation with a structure set for which
 and~ cover as many spaces as possible.

If two equations with different structure sets are available, it may be possible
to combine the two denominator bounds obtained by Algorithm~\ref{algo:2} to a
denominator bound with respect to the full space .

\begin{example}
  Consider the following system of equations:
  
  Algorithm~\ref{algo:2} applied to the first equation returns
  
  as a denominator bound with respect to any  except  and
  . Applied to the second equation, it returns
  
  as a denominator bound with respect to any  except  and
  . The least common multiple of the two outputs is a
  simultaneous denominator bound with respect to any~.

  Indeed, the system has the solution
  
\end{example}

There is no hope for an algorithm which computes for any given single equation a
denominator bound with respect to the full space~. This is because
there are quations whose solution space contains rational functions with no
finite common denominator. For instance, for every univariate polynomial~, we
have that  is a solution of the equation

It would be interesting to characterize under which circumstances this happens,
and to have an algorithm which finds a denominator bound with respect to 
in all other cases. 

\bibliographystyle{plain}
\bibliography{all}

\end{document}
