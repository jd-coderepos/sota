\documentclass[10pt,twocolumn,letterpaper]{article}
\usepackage{conf}

\usepackage{times}
\usepackage{epsfig, graphicx}
\usepackage{color}
\usepackage{xcolor}
\usepackage{amsmath,amssymb}
\usepackage[ruled, vlined, linesnumbered]{algorithm2e}
\usepackage{multirow}
\usepackage{array}
\usepackage{slashbox}
\usepackage{subfigure}
\usepackage{units}
\pdfoutput=1
\graphicspath{{./figures/}}
\DeclareGraphicsExtensions{.pdf,.jpeg,.png,.jpg}


\newcommand\todo[1]{\textcolor{red}{#1}}



\usepackage[pagebackref=true,breaklinks=true,letterpaper=true,colorlinks,bookmarks=false]{hyperref}

\newcommand{\stavros}[1]{{\textcolor{red}{[\emph{stavros}: #1]}}}

\usepackage{xspace}
\def\sota{state-of-the-art}
\def\groundtruth{ground truth}
\def\CUB{CUB-200-2011}
\def\kmeans{\emph{k}-means}
\def\cpp{C\texttt{++}}
\def\matlab{MATLAB}
\def\matconvnet{MatConvNet}

\newcommand{\ks}[1]{\textcolor{blue}{\bf [KS: #1]}}
\newcommand{\st}[1]{\textcolor{red}{\bf [ST: #1]}}
\newcommand{\xb}[1]{\textcolor{green}{\bf [XB: #1]}}
\newcommand{\yx}[1]{\textcolor{purple}{\bf [YX: #1]}}
\newcommand{\sd}[1]{\textcolor{orange}{\bf [SD: #1]}}

\newcommand{\refchap}[1]{Chapter~\ref{#1}}
\newcommand{\refsec}[1]{Section~\ref{#1}}
\newcommand{\reffig}[1]{Figure~\ref{#1}}
\newcommand{\refeq}[1]{Equation~\eqref{#1}}
\newcommand{\refalg}[1]{Algorithm~\ref{#1}}
\newcommand{\reftab}[1]{Table~\ref{#1}}
\newcommand{\refapp}[1]{Appendix~\ref{#1}}

\newcommand{\pd}[2]{\frac{\partial #1}{\partial #2}}
\newcommand{\mat}[1]{\mathbf{#1}}
\renewcommand{\vec}[1]{\mathbf{#1}}
\newcommand{\set}[1]{\mathcal{#1}}
\newcommand{\inprod}[1]{{\left< \, #1 \, \right>}}
\newcommand{\R}{\mathbb{R}}
\def\abs{\operatorname{abs}}
\DeclareMathOperator*{\argmin}{arg\,min}
\DeclareMathOperator*{\argmax}{arg\,max}
\newcommand{\p}[1]{\vec{p}_{#1}} 	 \newcommand{\f}[1]{\vec{f}_{#1}} 	 \newcommand{\g}[1]{\vec{g}_{#1}} 	 \newcommand{\norm}[1]{\left \lVert #1 \right \rVert} \newcommand{\scales}{\set{R}}


\conffinalcopy 

\def\confPaperID{} \def\httilde{\mbox{\tt\raisebox{-.5ex}{\symbol{126}}}}

\ifconffinal\pagestyle{empty}\fi
\begin{document}

\title{DeepFlux for Skeletons in the Wild}

\author{
Yukang Wang \quad Yongchao Xu \quad Stavros Tsogkas \quad Xiang Bai \quad Sven Dickinson \quad Kaleem Siddiqi
\
F(p) =
\left\{
\begin{matrix} \
\overrightarrow{p N_p}/\left\vert\overrightarrow{p N_p}\right\vert, & p\in R_c  \\ \\
(0,0), & p \in R_s \cup R_b,
\end{matrix}
\right.
\label{eq:sklrep}

L \; = \; \sum_{p \in \Omega}{w(p) * \left\|F(p), \hat{F}(p)\right\|_2},
\label{eq:loss}

w(p) =
\left\{
\begin{matrix} \
\frac{|R_b|}{|R_c|+|R_b|+|R_s|}, & p \in R_c \cup R_s \\ \\
\frac{|R_c|+|R_s|}{|R_c|+|R_b|+|R_s|}, & p \in R_b,
\end{matrix}
\right.
\label{eq:weight}

where ,  and  denote the number of context, background, and skeleton pixels, respectively.

\subsection{From flux to skeleton points} \label{sec:postprocessing}
We propose a simple post-processing procedure to recover an object skeleton from the predicted context flux.
As described in~\refeq{eq:sklrep}, pixels around the skeleton are labeled with unit two-dimensional vectors while the others are set to .
Thus, thresholding the magnitude of the vector field reveals the context pixels while
computing the flux direction reveals the location of context pixels relative to the skeleton. We refer the reader to~\reffig{fig:pipeline} for a visualization of the post-processing steps, listed in Algorithm~\ref{algo:skeletonrecovery}.

Let  and  be the magnitude and direction of the predicted context flux , respectively.
For a given pixel ,  is binned into one of 8 directions, pointing to one of the 8 neighbors, denoted by .
Having computed these two quantities, extracting the skeleton is straightforward:
pixels close to the real object skeleton should have a high inward flux, due to a singularity in the vector field , as analyzed in \cite{dimitrov2003}.
Finally, we apply a morphological dilation with a disk structuring element of radius , followed by a morphological erosion with a disk of radius , to group pixels together and produce the object skeleton.

\begin{algorithm}[t]
\caption{Algorithm for skeleton recovery from learned context flux . : magnitude; : direction; : neighbor of  at direction .}
\label{algo:skeletonrecovery}
\DontPrintSemicolon

\KwIn{Predicted context flux , threshold }
\KwOut{Binary skeleton map }
\SetKwBlock{Begin}{function}{end function}
\Begin()
{
    // initialization \\
     \\
    // find ending points near skeleton \\
    \ForEach{}
    {
    	\If{ \textbf{and} }
        {
        	
        }
    }
    // apply morphological closing \\
     \;
    \Return{} \;
}
\end{algorithm}

\section{Experiments} \label{sec:experiments}
We conduct experiments on five well-known, challenging datasets, including three for skeleton detection (SK-LARGE~\cite{shen2017lmsds}, SK506~\cite{shen2016fsds}, WH-SYMMAX~\cite{shen2016misl}) and two for local symmetry detection (SYM-PASCAL~\cite{ke2017srn}, SYMMAX300~\cite{tsogkas2012mil}).
We distinguish between the two tasks by associating skeletons with a foreground object, and local symmetry detection with any symmetric structure, be it a foreground object or background clutter.

\begin{table*}
\begin{center}
\begin{tabular}{|l|c|c|c|c|c|}
\hline
Methods      & SK-LARGE  & SK506  & WH-SYMMAX  &  SYM-PASCAL & SYMMAX300    \\ \hline\hline
MIL~\cite{tsogkas2012mil}  & 0.353   & 0.392  & 0.365 & 0.174 & 0.362     \\ \hline
HED~\cite{xie2015hed}  & 0.497   & 0.541  & 0.732 & 0.369 & 0.427    \\ \hline
RCF~\cite{liu2017rcf}  & 0.626   & 0.613  & 0.751 & 0.392 & -    \\ \hline
FSDS*~\cite{shen2016fsds}  & 0.633   & 0.623  & 0.769 & 0.418 & 0.467    \\ \hline
LMSDS*~\cite{shen2017lmsds} & 0.649 & 0.621 & 0.779 & - & -
\\ \hline
SRN~\cite{ke2017srn} & 0.678   & 0.632  & 0.780 & 0.443 & 0.446    \\ \hline
LSN~\cite{liu2018lsn} & 0.668   & 0.633  & 0.797 & 0.425 & 0.480    \\ \hline
Hi-Fi*~\cite{zhao2018hifi} & 0.724   & 0.681  & 0.805 & 0.454 & -    \\ \hline
DeepFlux (Ours) & \bf{0.732}  & \bf{0.695}  & \bf{0.840}  & \bf{0.502} & \bf{0.491} \\ \hline
\end{tabular}
\end{center}
\caption{F-measure comparison. * indicates scale supervision was also used. Results for competing methods are from the respective papers.}
\label{tab:quantitativeresults}
\end{table*}

\subsection{Dataset and evaluation protocol}\label{sec:datasets}
\noindent\textbf{SK-LARGE}~\cite{shen2017lmsds} is a benchmark dataset for object skeleton detection, built on the MS COCO dataset~\cite{chen2015mscoco}.
It contains 1491 images, 746 for training and 745 for testing.


\medskip

\noindent\textbf{SK506}~\cite{shen2016fsds} (aka SK-SMALL), is an earlier version of SK-LARGE containing 300 train images and 206 test images.

\medskip

\noindent\textbf{WH-SYMMAX}~\cite{shen2016misl} contains 328 cropped images from the Weizmann Horse dataset~\cite{borenstein2002horse}, with skeleton annotations.
It is split into 228 train images and 100 test images.

\medskip

\noindent\textbf{SYM-PASCAL}~\cite{ke2017srn} is derived from the PASCAL-VOC-2011 segmentation dataset~\cite{everingham2010pascalvoc} and targets object symmetry detection in the wild.
It consists of 648 train images and 787 test images.


\medskip

\noindent\textbf{SYMMAX300}~\cite{tsogkas2012mil} is built on the Berkeley Segmentation Dataset (BSDS300)~\cite{martin2001bsds}, which contains 200 train images and 100 test images.
Both foreground and background symmetries are considered.


\medskip

\noindent\textbf{Evaluation protocol}
We use precision-recall (PR) curves and the F-measure metric to evaluate skeleton detection performance in our experiments.
For methods that output a skeleton probability map, a standard non-maximal suppression (NMS) algorithm~\cite{dollar2015nms} is first applied and the thinned skeleton map is obtained.
This map is then thresholded into a binary map and matched with the groundtruth skeleton map, allowing small localization errors.
Since DeepFlux does not directly output skeleton probabilities, we use the inverse magnitude of predicted context flux on the recovered skeleton as a surrogate for a ``skeleton confidence''.
Thresholding at different values gives rise to a PR curve and the optimal threshold is selected as the one producing the highest F-measure according to the formula .
F-measure is commonly reported as a single scalar performance index.

\subsection{Implementation details} \label{sec:implementation}
Our implementation involves the following hyperparameters (values in parentheses denote the default values used in our experiments):
the width of the skeleton context neighborhood ;
the threshold used to recover skeleton points from the predicted flux field, ;
the sizes of the structuring elements involved in the morphological operations for skeleton recovery,  and .

For training, we adopt standard data augmentation strategies~\cite{shen2016fsds,shen2017lmsds,zhao2018hifi}.
We resize training images to 3 different scales (0.8, 1, 1.2) and then rotate them to 4 angles (, , , ).
Finally, we flip them with respect to different axes (up-down, left-right, no flip).
The proposed network is initialized with the VGG16 model pretrained on ImageNet~\cite{imagenet} and optimized using ADAM~\cite{kinga2015adam}.
The learning rate is set to  for the first 100k iterations, then reduced to  for the remaining 40k iterations.

We use the Caffe~\cite{jia2014caffe} platform to train DeepFlux. All experiments are carried out on a workstation with an Intel Xeon 16-core CPU (3.5GHz), 64GB RAM, and a single Titan Xp GPU.
Training on SK-LARGE using a batch size of 1 takes about 2 hours.





\subsection{Results} \label{sec:results}
PR-curves for all methods are shown in~\reffig{fig:prcurve}.
DeepFlux performance excels particularly in the high-precision regime, where it clearly surpasses competing methods.
This is indicative of the contribution of local context to more robust and accurate localization of skeleton points.

\reftab{tab:quantitativeresults} lists the optimal F-measure score for all methods.
DeepFlux consistently outperforms all other approaches using the VGG16 backbone~\cite{vgg16network}.
Specifically, it improves over the recent Hi-Fi~\cite{zhao2018hifi} by , , and  on SK-LARGE, SK506, and WH-SYMMAX, respectively, despite the fact that Hi-Fi uses stronger supervision during training (skeleton position \emph{and} scale).
DeepFlux also outperforms LSN~\cite{liu2018lsn}, another recent method, by , , and  on SK-LARGE, SK506, and WH-SYMMAX, respectively.

Similar results are observed for the symmetry detection task.
DeepFlux significantly outperforms \sota\ methods on the SYM-PASCAL dataset, recording an improvement of  and  compared to Hi-Fi~\cite{zhao2018hifi} and LSN~\cite{liu2018lsn}, respectively.
On SYMMAX300, DeepFlux also improves over LSN by .
Some qualitative results are shown in~\reffig{fig:qualitativeresults}, including failure cases.

\begin{figure} \centering
\subfigure[SK-LARGE]
{
\label{fig:prsklarge}
\includegraphics[width=0.46\columnwidth]{figures/sklarge_crop.pdf}
}
\subfigure[SK506]
{
\label{fig:prsk506}
\includegraphics[width=0.46\columnwidth]{figures/sk506_crop.pdf}
}
\subfigure[WH-SYMMAX]
{
\label{fig:prsymmax}
\includegraphics[width=0.46\columnwidth]{figures/symmax_crop.pdf}
}
\subfigure[SYM-PASCAL]
{
\label{fig:prsympascal}
\includegraphics[width=0.46\columnwidth]{figures/sympascal_crop.pdf}
}
\caption{PR curves on four datasets. DeepFlux offers high precision, especially in the high-recall regime.}
\label{fig:prcurve}
\end{figure}

\subsection{Runtime analysis} \label{sec:runtime}
We decompose runtime analysis into two stages: network inference and post-processing.
Inference on the GPU using VGG16 takes on average \unit[14]{ms} for a  image and the post-processing stage requires on average \unit[5]{ms} on the CPU.
As shown in~\reftab{tab:runtime}, DeepFlux is as fast as competing methods while achieving superior performance.

\begin{figure*}
\centering
\includegraphics[width=1.0\linewidth]{figures/qualitative_results_crop.pdf}
\vskip 0.2cm
\caption{Qualitative results on SK-LARGE, WH-SYMMAX, and SYM-PASCAL (a-c), SK506 (d), SYMMAX300 (e), and two failure cases (f). Red: GT; Green: detected skeleton; Yellow: detected skeleton and GT overlap.
DeepFlux fails to detect the skeleton on the bird body due the severe blurring. In the second failure example DeepFlux detects a symmetry axis not annotated in the ground truth.
}
\label{fig:qualitativeresults}
\end{figure*}



\begin{table}
\begin{center}
\begin{tabular}{|l|c|c|}
\hline
Method & F-measure & Runtime (in \emph{sec}) \\
\hline\hline
HED~\cite{xie2015hed} & 0.497 & 0.014 \\
\hline
FSDS~\cite{shen2016fsds} & 0.633 & 0.017 \\
\hline
LMSDS~\cite{shen2017lmsds} & 0.649 & 0.017 \\
\hline
LSN~\cite{liu2018lsn} & 0.668 & 0.021 \\
\hline
SRN~\cite{ke2017srn} & 0.678 & 0.016 \\
\hline
Hi-Fi~\cite{zhao2018hifi} & 0.724 & 0.030 \\
\hline
DeepFlux (ours) & 0.732 & 0.019 \\
\hline
\end{tabular}
\end{center}
\caption{Runtime and performance on SK-LARGE. For DeeFlux we list the total inference (GPU) + post-processing (CPU) time. }
\label{tab:runtime}
\end{table}

\subsection{Ablation study} \label{sec:ablation}
We study the contribution of the two main modules (ASPP module and flux representation)  to skeleton detection on SK-LARGE and SYM-PASCAL. We first remove the ASPP module and study the effect of the proposed context flux representation compared to a baseline model with the same architecture, but trained for binary classification.
As shown in~\reftab{tab:ablation}, employing a flux representation results in a   improvement on SK-LARGE and  on SYM-PASCAL.
We then conduct experiments without using context flux, and study the effect of the increased receptive field offered by the ASPP module.
The ASPP module alone leads to a  improvement on SK-LARGE and  on SYM-PASCAL.
This demonstrates that the gains from ASPP and context flux are orthogonal; indeed, combining both improves the baseline model by  on SK-LARGE and and   on SYM-PASCAL.

We also study the effect of the size of the neighborhood within which context flux is defined.
We conduct experiments with different radii, ranging from  to , on the SK-LARGE and SYM-PASCAL datasets.
Best results are obtained for , and using smaller or larger values seems to slightly decrease performance.
Our understanding is that a narrower context neighborhood provides less contextual information to predict the final skeleton map.
On the other hand, using a wider neighborhood may increase the chance for mistakes in flux prediction around areas of severe discontinuities, such as the areas around boundaries of thin objects that are fully contained in the context neighborhood.
The good news, however, is that DeepFlux is not sensitive to the value of .

Finally, one may argue that simply using a dilated skeleton ground truth is sufficient to make a baseline model more robust in accurately localizing skeleton points.
To examine if this is the case, we retrained our baseline model using binary cross-entropy on the same dilated ground truth we used for DeepFlux.
Without context flux, performance drops to  (\textcolor{red}{}) on SK-LARGE and to  (\textcolor{red}{}) on SYM-PASCAL, validating the importance of our proposed representation for accurate localization.


\begin{table}
\begin{center}
\begin{tabular}{|c|c|c|c|}
\hline
Dataset & Context flux & ASPP & F-measure \\
\hline\hline
\multirow{4}{*}{SK-LARGE} & & &0.696 \\
& & \checkmark & 0.712 \\
& \checkmark & & 0.716 \\
& \checkmark & \checkmark & \textbf{0.732} \\
\hline\hline
\multirow{4}{*}{SYM-PASCAL} & & &0.409 \\
& & \checkmark & 0.426\\
& \checkmark & & 0.458\\
& \checkmark & \checkmark & \textbf{0.502} \\
\hline
\end{tabular}
\end{center}
\caption{The effect of the context flux representation and the ASPP module on performance.}
\label{tab:ablation}
\end{table}

\begin{table}
\begin{center}
\begin{tabular}{|c|c|c|c|c|c|}
\hline
Dataset &  &  &  &  &  \\
\hline \hline
\small{SK-LARGE} & 0.721 & 0.727 & \textbf{0.732} & 0.726 & 0.724\\
\hline
\small{SYM-PASCAL} & 0.481 & 0.498 & \textbf{0.502} & 0.500 & 0.501 \\
\hline
\end{tabular}
\end{center}
\caption{Influence of the context size  on the F-measure.}
\label{tab:diffks}
\end{table}

\section{Conclusion} \label{sec:conclusion}
We have proposed DeepFlux, a novel approach for accurate detection of object skeletons in the wild.
Departing from the usual view of learning-based skeleton detection as a binary classification problem, we have recast it as the regression problem of predicting a 2D vector field of ``context flux''.
We have developed a simple convolutional neural network to compute such a flux, followed by a simple post-processing scheme that can accurately recover object skeletons in 
Our approach steers clear of many limitations related to poor localization, commonly shared by previous methods, and particularly shines in handling ligature points, and skeletons at large scales.

Experimental results on five popular and challenging benchmarks demonstrate that DeepFlux systematically improves the state-of-the-art, both quantitatively and qualitatively.
Furthermore, DeepFlux goes beyond object skeleton detection, and achieves \sota\ results in detecting generic symmetry in the wild.
In the future, we would like to explore replacing the post-processing step used to recover the skeleton with an appropriate NN module, making the entire pipeline trainable in an end-to-end  fashion.


{\small
\bibliographystyle{ieee}
\bibliography{ref}
}

\end{document}
