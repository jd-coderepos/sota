\documentclass[11pt]{article}
\usepackage{fullpage}

\usepackage{graphics}
\usepackage[dvips]{epsfig}

\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{amsfonts}
\usepackage{graphicx}

\usepackage[small,compact]{titlesec}
\usepackage{times}



\newtheorem{theorem}{Theorem}[section]
\newtheorem{lemma}{Lemma}[section]
\newtheorem{corollary}{Corollary}[section]
\newtheorem{claim}{Claim}[section]
\newtheorem{proposition}{Proposition}[section]
\newtheorem{definition}{Definition}[section]
\newtheorem{fact}{Fact}[section]
\newtheorem{example}{Example}[section]

\newcommand{\finclaim}{\hfill }
\newcommand{\qed}{\hfill  \bigbreak}
\newenvironment{proof}{\noindent {\bf Proof.}}{\qed}
\newcommand{\noproof}{\hfill }
\newcommand{\reals}{I\!\!R}
\newcommand{\np}{\mbox{{\sc NP}}}
\newcommand{\sing}{\mbox{{\sc Sing}}}
\newcommand{\con}{\mbox{{\sc Con}}}
\newcommand{\hop}{\mbox{{\sc Hops}}}
\newcommand{\atm}{\mbox{{\sc ATM}}}
\newcommand{\hopn}{\hop_{\cN}}
\newcommand{\atmn}{\atm_{\cN}}
\newcommand{\cC}{{\cal C}}
\newcommand{\cN}{{\cal N}}
\newcommand{\cP}{{\cal P}}
\newcommand{\cD}{{\cal D}}
\newcommand{\cH}{{\cal H}}
\newcommand{\cS}{{\cal S}}
\newcommand{\D}{\Delta}
\newcommand{\cA}{{\cal A}}
\newcommand{\cR}{{\cal R}}
\newcommand{\cV}{{\cal V}}
\newcommand{\cM}{{\cal M}}


\newcommand{\A}{{\cal{R}}}
\newcommand{\E}{{\cal{E}}}
\newcommand{\Si}{\Sigma}

\newcommand{\succeed}{{\sc success}}
\newcommand{\explore}{{\sc explore}}
\newcommand{\fail}{{\sc failure}}
\newcommand{\ceil}[1]{\lceil #1 \rceil}
\newcommand{\lcm}{\mbox{lcm}}
\newcommand{\dist}{\mbox{dist}}
\newcommand{\caL}{{\cal{L}}}

\newcommand{\remove}[1]{}

\newcommand{\qq}{\hfill  \smallbreak}

\newcommand{\cO}{{\cal O}}
\newcommand{\cZ}{{\mathbb Z}}
\newcommand{\bt}{{\bar t}}
\newcommand{\GC}{{\sc Graph\-Cover}}
\newcommand{\CW}{{\sc Cover\-Walk}}

\newcommand{\F}{\vspace*{\smallskipamount}}
\newcommand{\FF}{\vspace*{\medskipamount}}
\newcommand{\FFF}{\vspace*{\bigskipamount}}
\newcommand{\B}{\vspace*{-\smallskipamount}}
\newcommand{\BB}{\vspace*{-\medskipamount}}
\newcommand{\BBB}{\vspace*{-\bigskipamount}}
\newcommand{\BBBB}{\vspace*{-2.5\bigskipamount}}
\newcommand{\T}{\hspace*{1em}}
\newcommand{\TT}{\hspace*{2em}}
\newcommand{\TTT}{\hspace*{4em}}
\newcommand{\TTTT}{\hspace*{6em}}
\newcommand{\TTTTT}{\hspace*{10em}}


\newcommand{\caA}{{\cal{A}}}
\newcommand{\BW}{\mbox{\sc bw}}
\newcommand{\CBW}{\mbox{\sc cbw}}
\newcommand{\reco}{\mbox{\tt recognize}}
\newcommand{\recobis}{\mbox{\tt recognize-bis}}
\newcommand{\prem}{\mbox{\tt prime}}
\renewcommand{\wedge}{\,|\,}



\begin{document}

\baselineskip  0.18in \parskip     0.0in \parindent   0.3in 

\title{{\bf Anonymous Meeting in Networks\thanks{
A preliminary version of this paper appeared in the Proc. 24th Annual ACM-SIAM Symposium on Discrete Algorithms (SODA 2013). 
A part of this research was done during the Dieudonn\'e's stay at the Research Chair in Distributed Computing of
the Universit\'{e} du Qu\'{e}bec en Outaouais as a postdoctoral fellow. Supported in part by NSERC discovery grant 
and by the Research Chair in Distributed Computing of
the Universit\'{e} du Qu\'{e}bec en Outaouais.}}}

\author{
Yoann Dieudonn\'{e}\thanks{MIS, Universit\'{e} de Picardie  Jules  Verne Amiens,  France and D\'{e}partement d'informatique, Universit\'{e} du Qu\'{e}bec en Outaouais,
Gatineau, Qu\'{e}bec J8X 3X7,
Canada. E-mail:  yoann.dieudonne@u-picardie.fr. 
}
\and
Andrzej Pelc\thanks{D\'{e}partement d'informatique, Universit\'{e} du Qu\'{e}bec en Outaouais,
Gatineau, Qu\'{e}bec J8X 3X7,
Canada. E-mail: pelc@uqo.ca.}
}

\date{ }
\maketitle

\begin{abstract}
A team consisting of an unknown number of mobile agents, starting from different nodes of an unknown network,
possibly at different times, have to meet at the same node.
Agents are anonymous (identical), execute the same deterministic algorithm and move in synchronous rounds along links of the network. An initial
configuration of agents is called {\em gatherable} if there exists a deterministic algorithm (even dedicated to this particular configuration) that achieves meeting of all
agents in one node. Which configurations are gatherable and how to gather all of them deterministically by the same algorithm?

We give a complete solution of this gathering problem in arbitrary networks. We characterize all gatherable configurations and give two {\em universal} deterministic 
gathering algorithms, i.e., algorithms that gather all gatherable configurations. The first algorithm works under the assumption that a common upper bound 
on the size of the network is known to all agents. In this case our algorithm guarantees {\em gathering with detection}, i.e., the existence of a round 
for any gatherable configuration, such that  all agents are at the
same node and all declare that gathering is accomplished. If no upper bound on the size of the network is known, we show that a universal algorithm for gathering
with detection does not exist. Hence, for this harder scenario, we construct a second universal gathering algorithm, which guarantees that, for any gatherable
configuration, all agents eventually get to one node and stop, although they cannot tell if gathering is over. The time of the first algorithm is polynomial in the
upper bound  on the size of the network, and the time of the second algorithm is polynomial in the (unknown) size itself.

Our results have an important consequence for the leader election
problem for anonymous agents in arbitrary graphs.
Leader election is a fundamental symmetry breaking problem in distributed
computing. Its goal is to assign, in some common round, value 1 (leader) to one of the entities and value 0 (non-leader)
to all others.  For anonymous agents in graphs, leader election turns out to be equivalent to
gathering with detection. Hence, as a by-product, we obtain a complete solution of 
the leader election
problem for anonymous agents in arbitrary graphs.



\vspace{2ex}

\noindent {\bf Keywords:} gathering, deterministic algorithm, anonymous mobile agent. 
\end{abstract}

\vfill



\vfill

\thispagestyle{empty}
\setcounter{page}{0}
\pagebreak


\section{Introduction}


\noindent
{\bf The background.}
A team of at least two mobile agents, starting from different nodes of a network, possibly at different times, have to meet at the same node.
This basic task,  known  as {\em gathering} or {\em rendezvous}, has been thoroughly studied in the literature.
This task has even applications in everyday life, e.g., when agents are people that have to meet in a city whose streets form a network.
In computer science,
mobile agents usually represent software agents in computer networks, or mobile robots, if the network is a labyrinth.
The reason to meet may be to exchange data previously collected by the agents,
or to coordinate some future task, such as network maintenance or finding a map of the network.

\noindent
{\bf The model and the problem.}
The network is modeled as an undirected connected graph, referred to hereafter as a graph. 
We seek gathering algorithms that do not
rely on the knowledge of node labels, and can work in anonymous graphs as well  (cf. \cite{alpern02b}). 
The importance of designing such algorithms
is motivated by the fact that, even when nodes are equipped with distinct labels, agents may be unable to perceive them
because of limited sensory capabilities, 
or nodes may refuse to reveal their labels, e.g., due to security or privacy reasons.
Note that if nodes had distinct labels, then agents might explore the graph and meet in the smallest node, hence gathering would reduce to exploration.
On the other hand, we assume that
edges incident to a node  have distinct labels in 
, where  is the degree of . Thus every undirected
edge  has two labels, which are called its {\em port numbers} at 
and at . Port numbering is {\em local}, i.e., there is no relation between
port numbers at  and at . Note that in the absence of port numbers, edges incident to a node
would be undistinguishable for agents and thus gathering would be often impossible, 
as the adversary could prevent an agent from taking some edge incident to the current node.

There are at least two agents that start from different nodes of the graph  and  traverse its edges in synchronous rounds.
They cannot mark visited nodes or traversed edges in any way.
The adversary wakes up some of the agents at possibly different times. A dormant agent, not woken up by the adversary,  is woken up by the first agent that visits
its starting node, if such an agent exists. Agents are anonymous (identical) and they execute the same deterministic algorithm. (Algorithms assuming anonymity of agents may be also used if agents refuse to reveal their identities.)
Every agent starts executing the algorithm in the round of its wake-up.
Agents do not  know the topology of the graph or the size of the team. We consider two scenarios: one when agents know
an upper bound on the size of the graph and another when no bound is known. 
In every round an agent may perform some local computations and move to an adjacent node by a chosen port, or stay at the current node.
When an agent enters a node, it learns its degree and the port of entry. When several agents are at the same node in the same round,
they  can exchange all information they currently have. However, agents that cross each other
on an edge, traversing it simultaneously in different directions, do not notice this fact. Also, agents cannot observe any part of the network except the currently visited node.
We assume that the memory of the agents is unlimited: they can be viewed as 
Turing machines.

An initial configuration of agents, i.e., their placement at some nodes of the graph, is called {\em gatherable} if there exists a deterministic algorithm 
(even only dedicated to this particular configuration) that achieves meeting of all
agents in one node, regardless of the times at which some of the agents are woken up by the adversary. In this paper we study the following gathering problem:
\begin{quote}
Which initial configurations are gatherable and how to gather all of them deterministically by the same algorithm?
\end{quote}
In other words, we want to decide which initial configurations are possible to gather, even by an algorithm specifically designed for this particular
configuration, and we want to find a {\em universal} gathering algorithm that gathers all such configurations. We are interested only in {\em terminating}
algorithms, in which every agent eventually stops forever.



\noindent
{\bf Our results.}
We give a complete solution of the gathering problem in arbitrary networks. We characterize all gatherable configurations and give two {\em universal} deterministic 
gathering algorithms, i.e., algorithms that gather all gatherable configurations. The first algorithm works under the assumption that a common upper bound 
on the size of the network is known to all agents. In this case our algorithm guarantees {\em gathering with detection}, i.e., the existence of a round 
for any gatherable configuration, such that  all agents are at the
same node and all declare that gathering is accomplished. If no upper bound on the size of the network is known, we show that a universal algorithm for gathering
with detection does not exist. Hence, for this harder scenario, we construct a second universal gathering algorithm, which guarantees that, for any gatherable
configuration, all agents eventually get to one node and stop, although they cannot tell if gathering is over. The time of the first algorithm is polynomial in the
upper bound  on the size of the network, and the time of the second algorithm is polynomial in the (unknown) size itself.

While gathering two anonymous agents is a relatively easy task (cf. \cite{CKP}),
our problem of gathering an unknown team of anonymous agents  
presents the following major difficulty. The asymmetry of the initial configuration
because of which gathering is feasible, may be caused not only by non-similar locations
of the agents in the graph, but by their different situation {\em with respect to other agents}.
Hence a new algorithmic idea is needed in order to gather: agents
that were initially identical, must make decisions based on the memories
of other agents met to date, in order to distinguish their future behavior. 
In the beginning the memory of each agent is a blank slate and
in the execution of the algorithm it records what the agent has seen in 
previous steps of the navigation and what it heard from other agents during meetings.
Even a slight asymmetry occurring  in a remote part of the graph
must eventually influence the behavior of initially distant agents.
Notice that agents in different initial situations may be unaware of this difference in early meetings, as the difference
may be revealed only later on, after meeting other agents. Hence, for example,  an agent may mistakenly "think" that two different agents
that it met in different stages of the algorithm execution, are the same agent. 
Confusions due to this possibility are a significant
challenge absent both in gathering two (even anonymous) agents and in gathering many labeled agents. 

Our results have an important consequence for the leader election
problem for anonymous agents in arbitrary graphs.
Leader election \cite{Ly} is a fundamental symmetry breaking problem in distributed
computing. Its goal is to assign, in some common round, value 1 (leader) to one of the entities and value 0 (non-leader)
to all others.  For anonymous agents in graphs, leader election turns out to be equivalent to
gathering with detection (see Section 5). Hence, 
as a by-product, we obtain a complete solution of 
the leader election
problem for anonymous agents in arbitrary graphs.












\noindent
{\bf Related work.}
Gathering was mostly studied for two mobile agents and in this case it is usually called rendezvous.
An extensive survey of  randomized rendezvous in various scenarios  can be found in
\cite{alpern02b}, cf. also  \cite{alpern95a,alpern02a,anderson90,israeli}. 
Deterministic rendezvous in networks was surveyed in \cite{Pe}.
Several authors
considered the geometric scenario (rendezvous in an interval of the real line, see, e.g.,  \cite{baston01,gal99},
or in the plane, see, e.g., \cite{anderson98a,anderson98b}).
Gathering more than two agents was studied, e.g., 
in \cite{israeli,lim96}. In~\cite{YY} the authors considered 
rendezvous of many agents with unique labels, and gathering many labeled agents in the presence of Byzantine agents was studied in \cite{DPP}. 
The problem was also studied in the context of multiple robot systems, cf.
\cite{CP05,fpsw}, and fault tolerant gathering of robots in the plane was studied, e.g., in \cite{AP06,CP08}. 

For the deterministic setting a lot of effort was dedicated to the study of the feasibility of rendezvous, and to the time required to achieve this task, when feasible. For instance, deterministic rendezvous with agents equipped with tokens used to mark nodes was considered, e.g., in~\cite{KKSS}. Deterministic rendezvous of two agents that cannot mark nodes but have unique labels was discussed in \cite{DFKP,KM,TSZ14}.
These papers were concerned with the time of rendezvous in arbitrary
graphs. In \cite{DFKP} the authors showed a rendezvous algorithm polynomial in the size of the graph, in the length of the shorter
label and in the delay between the starting time of the agents. In \cite{KM,TSZ14} rendezvous time is polynomial in the first two of these parameters and independent of the delay.


Memory required by two anonymous agents to achieve deterministic rendezvous was studied in \cite{FP,FP2} for trees and in  \cite{CKP} for general graphs.
Memory needed for randomized rendezvous in the ring was discussed, e.g., in~\cite{KKPM11}. 

Apart from the synchronous model used, e.g., in \cite{CKP,DFKP,TSZ14,YY} and in this paper, several authors investigated asynchronous rendezvous in the plane \cite{CFPS,fpsw} and in network environments
\cite{BCGIL,CLP,DGKKP,DPV,GP}.
In the latter scenario the agent chooses the edge which it decides to traverse but the adversary controls the speed of the agent. Under this assumption rendezvous
in a node cannot be guaranteed even in very simple graphs and hence the rendezvous requirement is relaxed to permit the agents to meet inside an edge.
In particular, in \cite{GP} the authors studied asynchronous rendezvous of two anonymous agents. 

Gathering many anonymous agents in a ring  \cite{DDN,KKN,KMP} and in a tree \cite{FIPS} was studied in a different model, where agents 
execute Look-Compute-Move cycles in an asynchronous way and can see positions of other agents during the Look operation. While agents have the advantage
of periodically seeing other agents, they do not have any memory of past events, unlike in our model.

Tree exploration by many agents starting at the same node was studied in \cite{FGKP}.
Some of the techniques of this paper have been later used in our paper \cite{DP} in the context of anonymous graph exploration by many agents.

The leader election problem was introduced in \cite{LL} and has been mostly studied in the scenario
where all nodes have distinct labels and the leader is found among them \cite{FL,HS,P}. 
In \cite{HKMMJ}, the leader election problem was
approached in a model based on mobile agents for networks with labeled nodes.
Many authors \cite{An,AtSn,BV,YK2,YK3} studied leader election
in anonymous networks. In particular, \cite{YK3} characterized message-passing networks in which
leader election among nodes can be achieved when nodes are anonymous.
Memory needed for leader election in unlabeled networks was studied in \cite{FuPe}. 




\section{Preliminaries}\label{prelim}

Throughout the paper, 
the number of nodes of a graph is called its size.
In this section we recall four procedures known from the literature, that will be used as building blocks in our algorithms. 
The aim of the first two procedures is graph exploration, i.e., visiting all nodes of the graph by a single agent (cf., e.g., \cite{CDK,Re}). 

{The first of these procedures assumes an upper bound  on the size of the graph. It is based on universal exploration sequences (UXS) and is a corollary of the result of Reingold \cite{Re}. It allows the agent to traverse all nodes of any graph of size at most , starting from any node of this graph, using  edge traversals, where  is some polynomial. After entering a node of degree  by some port ,
the agent can compute the port  by which it has to exit; more precisely , where  is the corresponding term of the UXS of length . 

The second procedure makes no assumptions on the size but 
it is performed by an agent using a fixed token placed at the starting node of the agent.}
(It is well known that a terminating exploration even of all anonymous rings of unknown size by a single agent without a token is impossible.)
In our applications the roles of the token and of the exploring agent will be played by agents or by groups of agents.

The first procedure works in time polynomial in the known upper bound  on the size of the graph and the second in time polynomial in the size of the graph. At the end of each procedure all nodes of the graph are visited.
Moreover, at the end of the second procedure the agent is with the token and has a complete map of the graph with all port numbers marked.
We call the first procedure  and the second procedure , for {\em exploration with a stationary token}.
{We denote by  the maximum time of execution of the procedure  
in a graph of size at most .} 







Before describing the third procedure we define the
following notion from \cite{YK3}. Let  be a graph and  a node of .  
The {\em view} from  is the infinite rooted tree  with labeled ports, defined as follows.
Nodes of this tree are all (not necessarily simple) finite paths in  starting at  and represented as the corresponding sequences of port numbers.
The root of the tree is the empty path, and children of path  of length  are all paths of length , whose prefix is .
A child  of node , such that  (with juxtaposition standing for concatenation) is connected with node  by an edge
that has port  at node  and port  at node .

The {\em truncated view}  at depth  is the rooted subtree of   induced by all nodes at distance  at most  from the root.


The third procedure, described in \cite{CKP},  permits a single anonymous agent starting at node  of an -node graph, to find a  positive integer ,
called the signature of the agent, such that 
 if and only if . This procedure, called  works for any graph  of known upper bound  on its size and 
its running time is polynomial in . After the completion of , {graph  has been completely explored (i.e., all the nodes of  have been visited at least once) and} the agent is back at its starting node.
We denote by  the maximum time of execution of the procedure  in a graph of size at most .


Finally, the fourth procedure is for gathering two agents in a graph of unknown size. It is due to Ta-Shma and Zwick \cite{TSZ14} and relies on the
fact that agents have distinct labels. (Using it as a building block in our scenario of anonymous agents is one of the difficulties that we need to overcome.)
Each agent knows its own label (which is a parameter of the algorithm) but not the label of the other agent.
We will call this procedure , where  is the label of the executing agent. In  \cite{TSZ14}, the authors give a polynomial 
in two variables, increasing in each of the variables,
such that, if there are agents with distinct labels  and  operating in a graph of size , appearing at their starting positions in possibly
different times, then they will meet after at most  rounds since the appearance of the later agent, where  is the smaller label.
Also, if an agent with label   performs  for  rounds and the other agent is inert during this time, the meeting is guaranteed.

We will also use a notion similar to that of the view but reflecting the positions of agents in an initial configuration.
Consider a graph  and an initial configuration of agents in this graph. Let  be a node occupied by an agent. The {\em enhanced view} from  is the couple 
 , where  is a binary valued function defined on the set of nodes of , such that  if there is an agent at the unique node  in 
 that is reached from  by path , and  otherwise. (Recall that nodes of  are paths in , represented as sequences of port numbers.)
 Thus the enhanced view of an agent additionally marks in its view the positions of other agents in the initial configuration.
 
 An important notion used throughout the paper is the {\em memory} of an agent. 
 Intuitively, the memory of an agent in a given round is the total information the agent collected since its wake-up,
 both by navigating in the graph and by exchanging information with other agents met until this round. This is formalized as follows. The memory of an agent  at
 the end of some round which is  the -th round since its wake-up, is the sequence , where  is the information of the agent at its start
 and  is the information acquired in round . The terms  are defined as follows. Suppose that in round  the agent  met agents  at node  of degree . Suppose that agent  entered node  in round  leaving an adjacent node  by port  and entering  by port . 
 Suppose that agent  entered node  in round  leaving an adjacent node  by port  and entering  by port . If some agent did not move in
 round  then the respective ports are replaced by . The term  for agent , called its -th {\em memory box} is defined as the sequence
 , where  is the memory of the agent  at the end of round . This definition is recursive with respect to 
  global time (unknown to agents), starting at the wake-up of the earliest agent by the adversary. Note that if an agent is woken up by the adversary 
  at a node of degree  and no other agents are at this node at this time then {} for this agent (at its wake-up the agent sees only the degree of its
  starting position). If an agent is woken up by some other agents, it also learns their memories to date. Note also that, since the memory of the agent is the total  
  information it acquired to date, any deterministic algorithm used by agents to navigate (including any deterministic gathering algorithm) may be viewed as a function
  from the set of all memories into  the set of integers greater or equal to  telling the agent to take a given port  
  (or stay idle, in which case the output is ), if it has a given memory. It should be noted that memories of agents may often be (at least) exponential in the size of the graph in which they navigate.
  
  If two agents meet, they must necessarily have different memories. Indeed, if they had identical memories, then they would be woken up in the same round
  and they would traverse identical paths to the meeting node. This contradicts the assumption that agents start at different nodes.

 {We will end this section by introducing the order  on the set  of all possible memories, and the notion of  that will be used throughout the paper. Let  be any linear order on the set of all memory boxes (one such simple order is to code all possible memory boxes as binary sequences in some canonical way and use lexicographic order on binary sequences). Let  be a lexicographic order on the set  based on the order . Now the linear order  on the set  is defined as follows:  if (1) the number of memory boxes of  is strictly smaller than that of  or (2)  and  have the same number of memory boxes and . When  (resp. ), we say memory  is {\em larger} (resp. {\em smaller}) than . The order  has the property that if the memory of agent  is smaller than the memory of agent  in some round then it will remain smaller in all subsequent rounds. Let  be an agent with a memory  in round  (with ): the memory of agent  in round  for  is denoted  and is equal to  if , and to the empty word otherwise.}




\section{Known upper bound on the size of the graph}

In this section we assume that a common upper bound  on the size of the graph is known to all agents at the beginning.
The aim of this section is to characterize gatherable configurations and give a {\em universal} gathering algorithm that gathers {\em with detection} all gatherable configurations. The time of such an algorithm is the number of rounds between the wake-up of the first agent and the round when
all agents declare that gathering is accomplished.
Consider the following condition on an initial configuration in an arbitrary graph.
\begin{itemize}
\item
[{\bf G:}] There exist agents with different views, and each agent has a unique enhanced view.
\end{itemize}

We will prove the following result.

\begin{theorem}\label{eq}
An initial configuration is gatherable if and only if it satisfies the condition {\bf G}. If a common upper bound  on the size of the graph is known to all agents then
there exists an algorithm for gathering with detection all gatherable configurations. This algorithm works in time polynomial in .
\end{theorem}

In order to appreciate the full strength of Theorem \ref{eq} notice that it can be rephrased as follows.  If  an initial configuration does not satisfy
condition {\bf G} then there is no algorithm (even no algorithm dedicated to this specific configuration, knowing it entirely) that permits to gather this configuration, even gather it without detection: simply no algorithm can bring all agents simultaneously to one node. On the other hand, assuming that all agents know a common 
upper bound on the size of the graph, there is a {\em universal} algorithm that gathers {\em with detection} all initial configurations
satisfying condition {\bf G}. Our algorithm works in time polynomial in any commonly known upper bound  on the size of the graph. Hence,  if this upper bound is
polynomial in the size of the graph, the algorithm is polynomial in the size as well. 
In the next section we will show how the positive part of the result changes when no upper bound on the size of the graph is known. 

It is also important to stress the global nature of the second part of condition {\bf G}. While the first part concerns views of individual agents, which depend only on
the position of the agent in the graph, the second part concerns {\em enhanced} views, which depend, for each agent, on the positions of {\em all} agents in the graph.
In our algorithms, the actions of each agent eventually depend on its enhanced view, and hence require learning the initial positions of other agents with respect to the initial position of the given agent.
(Since not only agents but also nodes are anonymous, no ``absolute'' positions can ever be learned).
 This can be done
only by meeting other agents and learning these positions, sometimes indirectly, with agent  acting as intermediary in conveying the initial position of agent  
to agent . In short, the execution of a gathering algorithm for an agent depends on the actions of other agents. This is in sharp contrast to rendezvous of two anonymous agents, cf., e.g., \cite{CKP}, where actions of each agent depend only on its  view, whose sufficient part (a truncated view) can be constructed
individually by each agent without any help from the outside. This is also in sharp contrast with gathering or other tasks performed by two or more {\em labeled} agents, when actions of each agent depend on its label known by the agent in advance, and simple decisions based on comparison of labels are made after meetings
of subsets of agents when the task involves more than two agents,  cf., e.g., \cite{DPV}. 

The rest of the section is devoted to the proof of Theorem \ref{eq}.
We start with the following lemma.

\begin{lemma}\label{not}
If an initial configuration does not satisfy condition {\bf G}, then it is not gatherable.
\end{lemma}

\begin{proof}
Suppose that an initial configuration  does not satisfy condition {\bf G} and that agents execute the same deterministic algorithm.
First suppose that the configuration  does not satisfy the first part of condition  {\bf G}, i.e., that the views of all agents are identical.
Suppose that the adversary wakes up all agents in the same round. We show that no pair of agents can meet. Suppose, for contradiction, that 
agents  and  are the first to meet and that this occurs in round  from the common start. Since the initial views of the agents are identical
and they execute the same deterministic algorithm, the sequences of port numbers encountered by both agents are identical and hence they both
enter the node at which they first meet by the same port. This is a contradiction.

Now suppose that the configuration  does not satisfy the second part of condition  {\bf G}, i.e., that there exists an agent whose enhanced view is not unique. 
Consider distinct agents
 and  that have identical enhanced views. Let  be any agent and suppose that   is a sequence of port numbers that leads
from agent  to agent  in the enhanced view of agent . (Notice that there may be many such sequences, corresponding to different paths 
leading from  to .) Then there exists an agent  such that  is a sequence of port numbers that leads
from agent  to agent  in the enhanced view of agent . Agent  has the same enhanced view as agent . 
Since agents  and  were different, agents  and  are different as well. Hence for every agent there exists another agent whose enhanced view
is identical. Call such agents {\em homologs}.

Suppose again that the adversary wakes up all agents in the same round. We will show that, although now some meetings of agents are possible, homologs will
never meet. Suppose that agents  and  are homologs. Since  and  have the same enhanced view at the beginning, it follows by induction
on the round number that their memory will be identical in every round. Indeed, whenever  meets an agent  in some round, its homolog  meets
a homolog  of  in the same round and hence the memories of  and  evolve identically. In particular, since all agents execute the same
deterministic algorithm, agents  and  follow identical sequences of port numbers on their paths. As before, if they met for the first time at some node, they
would have to enter this node by the same port. This is a contradiction.
 \end{proof}
 
 The other (much more difficult) direction of the equivalence from Theorem \ref{eq} will be shown by constructing an algorithm which, 
 executed by agents starting from any initial
 configuration satisfying condition {\bf G}, accomplishes gathering with detection of all agents. (Our algorithm uses the knowledge of an upper bound  of the size
 of the graph: this is enough to prove the other direction of the equivalence, as for any specific configuration satisfying condition {\bf G} even a gathering
 algorithm dedicated to this specific configuration is enough to show that the configuration is gatherable, and such a dedicated algorithm knows the exact size
 of the graph. Of course, our algorithm accomplishes much more: knowing just an upper bound on the size of the graph it gathers {\em all} configurations satisfying condition {\bf G} and does this {\em with detection}.) We first give a high-level idea of the algorithm, then describe
 it in detail and prove its correctness. From now on we assume that the initial configuration satisfies condition {\bf G}.
 
 \vspace*{0.3cm}
 \noindent
 {\bf Idea of the algorithm.}
 At high level the algorithm works in two stages. The aim of the first stage for any agent is to meet another agent, in order to perform later an exploration 
 in which one of the agents will play the role of the token and the other the role of the explorer (roles will be decided comparing memories of the agents).
 To this end the agent starts an exploration of the graph using the known upper bound  on its size. The aim of this exploration is to wake up all, possibly still dormant
 agents. Afterwards,  in order to meet, 
 agents use the procedure  mentioned in Section 2. 
 However, this procedure requires a label  for each agent and our agents are anonymous. One way to differentiate agents
 and give them labels is to find their views: a view (truncated to ) from the initial position could serve as a label because the first part of condition {\bf G} guarantees
 that there are at least two distinct views. However, it is {\em a priori} not at all clear how to find the view of an agent (truncated to ) in time polynomial in .
 (Recall that the size of the view truncated to  is exponential in .) Hence we use
 procedure  mentioned in Section 2, which is polynomial in  and can still assign labels to agents {after exploring the graph}, producing at least two different labels. 
 Then, performing procedure  for a sufficiently long time guarantees a meeting for every agent.
 
 In the second stage each explorer explores the graph using procedure  and then backtracks to its token
 left at the starting node of the exploration. After the backtrack, memories of the token and of the explorer are updated to check for anomalies caused by other agents
 meeting in the meantime either the token or the explorer. Note that, due to the fact that some agents may have identical memories at this stage of the algorithm, 
 an explorer may sometimes falsely consider another token as its own, due to their identical memories. By contrast, an end of each
 backtrack is a time when an explorer can be sure that it is on its token and the token can be sure that its explorer is with it.  
 
 Explorers repeat these explorations with backtrack again and again, with the aim of creating meetings with other agents and detecting anomalies.
 As a consequence of these anomalies some agents merge with others, mergers being decided on the basis of the memories of the agents.
Each explorer eventually either merges with some token or performs an exploration without anomalies. In the latter case it waits a prescribed amount of time with its token: if
no new agent comes during the waiting time, the end of the gathering is declared, otherwise another exploration is launched. It will be proved that eventually, due to the second part of condition {\bf G}, all agents merge with the same
token  and then, after the last exploration made by the explorer  of  and after undisturbed waiting time, the end of the gathering is correctly declared.
 
  
 We now give a detailed description of the algorithm.
 
 \vspace*{0.3cm}
 
 \noindent
 {\bf Algorithm Gathering-with-Detection} with parameter  (upper bound on the size of the graph)
 
  \vspace*{0.2cm}
 
 During the execution of the algorithm an agent can be in one of the following six states: {\tt setup},  {\tt cruiser}, {\tt shadow}, {\tt explorer},  {\tt token}, {\tt searcher},
 depending on its memory.
 For every agent  in state  {\tt shadow} there is exactly one agent  in some state different from  {\tt shadow}, called the {\em guide} of . We will also
 say that  is a shadow of .
 Below we describe the actions of an agent  in each of the states and the transitions between the states. At wake-up agent  enters the state  {\tt setup}.
 
  \vspace*{0.2cm}
 
  \noindent
 {\bf State} {\tt setup}.
 
{Agent  performs  visiting all nodes (and waking up all still dormant agents) and finding the signature of its initial position , called the {\em label} of agent .}
 Agent   transits to state  {\tt cruiser}.
 
  \vspace*{0.2cm}
 
  \noindent
 {\bf State} {\tt cruiser}.
 
 Agent  performs , where  is its label, until meeting an agent in state  {\tt cruiser} or {\tt token} at a node . 
 {When such a meeting occurs, we consider  cases.}

  \noindent
 Case 1.
 Agent   meets an agent  in state {\tt token}.\\
{We consider  subcases}

{Subcase 1.1.}
{Agent  is not with its explorer at the time of the meeting. Then agent  transits to state {\tt shadow} of .}

{Subcase 1.2.}
 {Agent  is with its explorer  at the time of the meeting. Then agent  transits to state {\tt shadow} of .}
 
 
  \noindent
 Case 2.
 Agent  does not meet an agent  in state {\tt token}.\\ 
 Then there is at least one other agent in state {\tt cruiser} at node  {(because, as mentionned above, the considered meeting involves an agent in state {\tt cruiser} or {\tt token})}. {We consider  subcases.}
 
 Subcase 2.1.
 Agent   has the largest memory among all agents in state  {\tt cruiser} at node .\\
 Then agent   transits to state {\tt explorer}.
 
 Subcase 2.2.
 Agent   does not have the largest memory among all agents in state  {\tt cruiser} at node .\\
 If there is exactly one agent  in state {\tt cruiser}  with memory larger than  at node , then  transits to state {\tt token}.
 Otherwise, it becomes {\tt shadow} of the agent in state  {\tt cruiser} at node  with largest memory.
 
  \vspace*{0.2cm}
 
 \noindent
 {\bf State}  {\tt shadow}.
 
 Agent  has exactly one guide and is at  the same node as the guide in every round. In every round it makes the same move as the guide.
 If the guide  transits itself to state  {\tt shadow} and gets agent  as its guide, then agent  changes its guide to  as well. 
 Agent  declares that gathering is over if the unique agent in state {\tt explorer} collocated with it makes this declaration.  
 
 Before describing the actions in the three remaining states, we define the notion of {\em seniority} of an agent in state {\tt token} (respectively {\tt explorer}).
The seniority in a given round is the number of rounds from the time when the agent became {\tt token} (respectively {\tt explorer}).

 \vspace*{0.2cm}
 
  \noindent
 {\bf State} {\tt explorer}
 
 When agent  transits to state {\tt explorer}, there is another agent  that transits to state  {\tt token} in the same round at the same node .
 Agent  is called the token of . Agent  has a variable - that it initializes to the memory of  in this round. 
 Denote by  the procedure   followed by a complete backtrack  in which the agent traverses all edges traversed
in   in the reverse order and the reverse direction. The variable - is updated in the beginning of each execution of .
 An execution of   is called {\em clean} if 
the following condition is satisfied: in each round  during this execution, in which  met an agent  {that is not in state {\tt shadow}}, the memory of  is equal to that of ,
and in each round during this execution, in which the token  was met by an agent , the memory of  was equal to that of . Notice that 
after the execution of  , agent  is together with its token  and thus they can verify if the execution was clean, by inspecting their memories.
The execution time of  is at most .



 
 
 After transiting to state {\tt explorer}, agent  waits for { rounds}, where  is the largest possible label (it is 
 polynomial in ). 
 Then it executes the following protocol:
\newpage
 
  \vspace*{0.2cm}
  \noindent
 {\bf while}  has not declared that gathering is over {\bf do}
 
 \noindent
  \hspace*{0.5cm}{\bf do}\\
   \noindent
 \hspace*{1cm}\\
  \noindent
  \hspace*{1cm}/*now agent  is with its token.*/
 
 \vspace*{0.2cm}
  \noindent
  \hspace*{1cm}{\bf if} {in round } agent  met an agent  in state {\tt token} of higher\\
   \noindent
  \hspace*{1cm}seniority than that of  or of equal seniority but such
  that \\ 
   \noindent
   \hspace*{1cm} where  is the memory of agent  and\\
    \noindent 
    \hspace*{1cm} is the last round {before }
    when agent  updated its variable \\
    \noindent 
    \hspace*{1cm}- {\bf then}  transits to state {\tt searcher}
    
    \vspace*{0.2cm}
     \noindent
     \hspace*{1cm}{\bf if}  was visited in round  by an agent  in state {\tt explorer} of higher\\ 
      \noindent 
    \hspace*{1cm}seniority than that of 
     or of equal seniority but such that\\
      \noindent 
      \hspace*{1cm}{} where  is the memory of agent ,  is the last \\
       \noindent 
      \hspace*{1cm}{
round before  when agent  updated its variable - and }\\ 
\noindent 
      \hspace*{1cm}{is the variable - of agent  in round } {\bf then}  transits to \\
\noindent 
      \hspace*{1cm}state {\tt searcher}
    
     \vspace*{0.2cm}
     \noindent
       \hspace*{0.5cm}{\bf until} the execution of  is clean\\

     \noindent
       \hspace*{0.5cm}{agent  waits  rounds: this waiting period is interrupted} \\
       \hspace*{0.5cm}{if  is visited by another agent;} 
       
        \vspace*{0.2cm}
        \noindent
       \hspace*{0.5cm}{{\bf if} the waiting period of  rounds has expired\\}
       \hspace*{0.5cm}{without any interruption {\bf then}  declares that gathering is over.\\}
\vspace*{0.2cm}
 {{\bf endwhile}}     
 


 
 
 
 
  \vspace*{0.2cm}
 
  \noindent
{\bf State} {\tt token}
 
  When agent  transits to state {\tt token}, there is another agent  that transits to state  {\tt explorer} in the same round at the same node .
 Agent  is called the explorer of . 
Agent  remains  idle at a node  and does not change its state, except when its explorer  transits to state {\tt searcher}. In this case it transits
 to state {\tt shadow} and  becomes its guide. 
    Agent  declares that gathering is over if the unique agent in state {\tt explorer} collocated with it makes this declaration.
    
     \vspace*{0.2cm}
 
  \noindent
  {\bf State} {\tt searcher}
    
{Agent  performs an entire execution of  until its termination, regardless of any meetings it could make during this execution. Then the agent starts another execution of  which is stopped as soon as agent  meets an agent  in state {\tt token}.}
{If at the time of the meeting agent  is not with its explorer  then agent  transits to state {\tt shadow} of  ( becomes its guide). Otherwise, agent  transits to state {\tt shadow} of  ( becomes its guide).}

\vspace*{0.5cm}
The proof of the correctness of the algorithm is split into the following lemmas.

\begin{lemma}\label{term}
In Algorithm Gathering-with-Detection every agent eventually stops after time polynomial in  and declares that gathering is over.
\end{lemma}

\begin{proof}
At its wake-up an agent  enters state  {\tt setup} and remains in it for at most { rounds} (the time to complete an exploration and find
its label ) and then transits to state {\tt cruiser}. We will prove that
in state {\tt cruiser} agent  can spend at most  { rounds}.
We will use the following claim.

\vspace*{0.3cm}
\noindent
{\bf Claim 1.} Let  be the first round{, if any,} in which an agent transits to state {\tt token}. Then there exists an agent  that remains in state {\tt token}
and is idle from round  on.

{To prove the claim, let  be the set of agents that transited to state {\tt token} in round .  In every round , {each} agent from  with the current largest memory
remains in state {\tt token} and stays idle. Indeed, the reasons why such an agent, call it , could leave the state token in round  all lead to a contradiction. There are four such reasons.}

\begin{itemize}
\item{ {Case~1.} The token  was visited by an agent in state {\tt explorer} of higher seniority. We get a contradiction with the fact that the agents belonging to  have the highest seniority.}

\item{ {Case~2.} The explorer of the token  met an agent  in state {\tt token} of higher seniority. Since the explorer of  has the same seniority as , by transitivity the seniority of agent  is higher than that of agent  which is a contradiction with the definition of .}

\item{ {Case~3.} In round  the token  was visited by an agent  in state {\tt explorer} of equal seniority but such that  where  is the memory of agent ,  is the last round before  when agent  updated its variable - and  is the variable - of agent  in round . This case is impossible. Indeed, by definition, agent  has one of the highest memories among the agents from  in round . Hence, according to the definition of order  given in Section~\ref{prelim}, agent  had one of the highest memories among the agents from  in all rounds between  and . Moreover, since  and  have the same seniority, this implies that the token of  belongs to . Hence, in round  the memory of agent  is greater than or equal to the memory of the token of , which is a contradiction with .}


\item{ {Case~4.} In round  the explorer of the token  met an agent  in state {\tt token} of equal seniority but such that  where  is the memory of agent ,  is the last round before  when the explorer of  updated its variable -, and  is the variable - of the explorer of  in round . Similarly as before, we can get a contradiction with the fact that .}

\end{itemize}

Since an agent with the largest memory {in } in a given round must have had the largest memory among the agents in  in all previous rounds, the claim follows. \finclaim

In order to prove our upper bound on the time spent by  in state {\tt cruiser}, observe that
after at most { rounds} since  transits to state {\tt cruiser}, all other agents have quit state {\tt setup}. 
Consider the additional  rounds during which agent  performs . Let round  be the end of the first half
of this segment  of   rounds. Some meeting must have occurred on or before round , due to the properties of .
If agent  was involved in one of those meetings, it left state {\tt cruiser} by round . Otherwise, it must have met some other agent
in state either {\tt cruiser} or {\tt token} during the second half of the segment . Indeed, if it does not meet another agent in state {\tt cruiser},
it must meet another agent in state {\tt token}, which transited to this state by round . (Claim 1 guarantees the existence of such an 
agent after round .) This proves our upper bound on the time spent by  in state {\tt cruiser}.

From state {\tt cruiser} agent  can transit to one of the three states: {\tt shadow}, {\tt explorer} or {\tt token}. {To deal with the state {\tt shadow}, we need the following claim.}

\vspace*{0.3cm}
\noindent
{{\bf Claim 2.} If agent  becomes the {\tt shadow} of an agent  in some round , then agent  cannot itself switch to state {\tt shadow} in the same round.}


{To prove the claim, there are  cases to consider.}

\begin{itemize}
\item{ {Case~1.} Agent  transits from state {\tt token} to state {\tt shadow} in round . According to the algorithm, agent  is an 
{\tt explorer} transiting to state {\tt searcher} in round .}

\item{{Case~2.} Agent  transits from state {\tt searcher} to state {\tt shadow} in round . According to the algorithm,  is }
\begin{itemize}
\item{ either an agent in state {\tt token} that is not with its explorer in round , in which case agent  remains in state {\tt token} in round }
\item{ or an agent in state {\tt explorer}. However an agent in state {\tt explorer} cannot switch directly to state {\tt shadow}. Hence  cannot transit to
state {\tt shadow} in round . }
\end{itemize}
\item{ {Case~3.} Agent  transits from state {\tt cruiser} to state {\tt shadow} in round . According to the algorithm,  is either in one of the situations described in Case~2, in which case  does not switch to state {\tt shadow} in round , or  is an agent in state {\tt cruiser} that transits to state {\tt explorer}.} 
\end{itemize}

{In all cases,  does not switch to state {\tt shadow} in round , which proves the claim.} \finclaim

{In view of Claim~2 and of the fact that} the termination  conditions for an agent in state 
 {\tt shadow} are the same as of its guide, we may eliminate the case of state  {\tt shadow} from our analysis. 

{Consider an agent  in state {\tt explorer}}. After 
  waiting time of  {   rounds}, where  is the largest possible label (it is polynomial in ),
 agent  knows that all other agents have already transited from the state {\tt cruiser}
 (they used at most {} rounds in state {\tt setup} and at most   rounds in state  {\tt cruiser}, as their labels are at most  and 
 at least one token is already present in the graph).


{In what follows, we show that, after at most a polynomial time , agent  either leaves state {\tt explorer} or declares that gathering is over.}  
 


 {In order to prove this, we first compute an upper bound on the number of non-clean explorations  that can be performed by agent  as an explorer. An exploration could be non-clean due to several reasons,
 according to the description of the algorithm.}
 \begin{itemize}
 \item
{{In round } agent  met an agent  in state {\tt token} of higher seniority than that of , or of equal seniority but such
  that , {where  is the last round before round  when the variable - of  was updated}. According to the algorithm, agent  transits to state {\tt searcher} as soon as it terminates its exploration  after round . Hence such a meeting can make at most  non-clean exploration.}
 \item
{In round  the token  of  was visited  by an agent  in state {\tt explorer} of higher seniority than that of ,
     or of equal seniority but such that {}, where  is the variable - of agent  and  is the last round before round  when the variable - of  was updated. According to the algorithm, agent  transits to state {\tt searcher} as soon as it terminates its exploration  after round . Hence such a meeting can make at most  non-clean exploration.}
  \item
  Either agent  or its token  met an agent in state {\tt searcher}. Since the lifespan of a searcher is at most the time of two consecutive executions of 
  , it can overlap at most three consecutive executions of this procedure. Hence one searcher can make non-clean at most 6 explorations 
  (3 by meeting  and 3 by meeting ). Since there are at most  searchers, this gives at most  non-clean explorations. 
   \item
 {In round } agent  met an agent   in state {\tt token} of lower seniority than that of , or of equal seniority but such that {, where  is the last round before  when the variable - of  was updated}. After this meeting,
   the remaining time when agent  remains in state {\tt token} is at most the duration of one execution of  (after at most this time the explorer of  becomes searcher and hence  transits to state {\tt shadow}). This time can overlap at most two consecutive executions of  ,
   hence such meetings can make at most  non-clean explorations.  
    \item
    {In round } the token  of  met an agent   in state {\tt explorer} of lower seniority than that of , or of equal seniority but such that  {(where  is the last round before round  when the variable - of  was updated)}.
     A similar analysis as in the previous case shows that such meetings can make at most  non-clean explorations. 
     \item
     Agent  met an agent  in state {\tt explorer}. The memories of the two agents at this time are different. After this meeting,
   the remaining time when agent  remains in state {\tt explorer} is at most the duration of two consecutive executions of  because after the 
   return of  on its token, the tokens of  and  have different memories and hence after another exploration,  must become a searcher.
   Indeed, since by assumption  remains in state {\tt explorer} till the end of the algorithm, we must have , where  is the variable - of  at the time , where  is the first round after the meeting of  and , in which agent  updated its variable -. 
  This gives at most  non-clean explorations. 
   \item
    met an agent   in state {\tt token} in round , that looked like its token  at this time, but that turned out not to be the token  after the backtrack
    of  on . More precisely,  in round  (where  is the last round {before round } when the variable - of  was updated)
    but . After round  agent  remains in state {\tt token} for at most the duration of two executions of .
    This gives at most  non-clean explorations.
    \item
   {In round  the token  was visited by an agent  of equal seniority in state {\tt explorer} such that , where  is the last round before  when the variable - of  was updated and this agent turned out not to be  after 
    the backtrack of  on . Similarly as before, this gives at most  non-clean explorations.}
     \end{itemize}
     
         
      Hence there can be at most {} non-clean executions of  for agent  
     (notice that, e.g., an agent can make non-clean one exploration in the state 
     {\tt explorer} and then in the state {\tt searcher}, hence for simplicity we add all the above upper bounds). A similar analysis shows that during at most {}
     waiting periods of a duration  agent  can be met by a new agent. Recall that before performing the first  execution of  agent  has been waiting for { rounds}.
     {Hence if agent  has not left state {\tt explorer} after at most  rounds since it transited to state {\tt explorer}, there
     has been a clean execution of  followed by a waiting period without any new agent coming during the period of  rounds, and thus agent  declares that gathering is over by the end of this period. Otherwise, agent  transits to state {\tt searcher} before spending  rounds in state 
  {\tt explorer}, in which case it uses at most  rounds for one execution of  and after
 additional at most   rounds it finds an idle agent  in state {\tt token} (claim 1 guarantees the existence of such an agent): it then becomes 
 the shadow of either  or of the explorer of .}

  
    
  It remains to consider an agent  in state {\tt token}. 
  From this state, either at some point the agent transits to state {\tt shadow} or it remains in state {\tt token} till the end of the algorithm. 
  In this latter case, its explorer declares that gathering is over after at most { rounds} since it transited to state 
   {\tt explorer}. However, as soon as an explorer declares that gathering is over, its token does the same. So, agent  declares that gathering is over after at most  
 { rounds} since it transited to state {\tt token} (recall that, according to the algorithm, agent  and its explorer have reached their current state at the same time).
   
   Hence every agent eventually terminates.
   We conclude by observing that the execution time of the entire algorithm is upper bounded by the sum of the following upper bounds:
   \begin{itemize}
   \item
   the time between the wake up of the first agent and the time of the wake up of an agent  that will be in state {\tt explorer} when declaring that gathering is over; this time is upper bounded by {}.
   \item
   the time that such an agent  spends in state {\tt setup} and {\tt cruiser}
   \item
   the time that such an agent  spends in state {\tt explorer}
   \end{itemize}
   
   We have shown above that each of these upper bounds is {}, where  is polynomial in . Since the values of
 ,  and  are all polynomial in , this proves that the running time of  Algorithm Gathering-with-Detection is polynomial in .    
\end{proof}

In the sequel we will use the following notion, which is a generalization of the enhanced view of a node. Consider a configuration of agents in any round.
Color nodes  and  with the same color if and only if they are occupied by agents  and , respectively, where  and 
have the same memory in this round. A {\em colored} view from node  is the view from  in which nodes are colored according to the above rule. 

In view of Lemma \ref{term}, all agents eventually declare that gathering is over. Hence the final configuration must consist of agents in states  {\tt explorer} , 
{\tt token} and {\tt shadow}, all situated in nodes , such that in each node  there is exactly one agent  in state {\tt explorer}, exactly one
agent  in state {\tt token}  and possibly some agents in state  {\tt shadow}. Call such a final configuration a {\em clone} configuration if there are at least two
distinct nodes ,  which have identical colored views. We will first show that the final configuration cannot be a clone configuration
and then that it must consist of all agents
gathered in a unique node and hence our algorithm is correct. 
 

 
 \begin{lemma}\label{clone}
 The final configuration cannot be a clone configuration.
\end{lemma}

\begin{proof}
Suppose for contradiction that the final configuration in round  contains distinct nodes which have identical colored views.
Let  be one of the agents woken up earliest by the adversary. There exists an agent  (also woken up earliest by the adversary) which has an
identical memory as  and an identical colored view.
Notice that if two agents have the same memory at time  they must have had the same memory at time . Since colors in a colored view
are decided by memories of agents, this implies (by a backward induction on the round number) that the colored views of  and  are the same in each round 
after their wake-up, and in particular {\em in} the round of their wake-up. In this round no agent has moved yet and hence each agent is in a different node. Hence colored
views in this round correspond to enhanced views. Thus we can conclude that the enhanced views from the initial positions of agents  and  were identical,
which contradicts the assumption that in the initial configuration every agent has a unique enhanced view.
\end{proof}
 

  \begin{lemma}\label{one}
   In the final configuration all agents must be at the same node.
   \end{lemma}

\begin{proof}
It follows from the formulation of the algorithm that at least one agent transits to state {\tt token}. By Claim 1 in the proof of Lemma \ref{term}, 
there exists an agent that remains in the state {\tt token} till the end of the algorithm. By Lemma \ref{term}, this agent declares that gathering is over.
Let  be the first (or one of the first) agents in state {\tt token} that declares that gathering is over. Let  be its explorer. Let  be the round in which
agent  starts its last exploration . Let  be the round in which backtrack begins during this execution. Let  be the round in which
this backtrack (and hence the execution of ) is finished, and let  be the round in which  declares that gathering is over.

\vspace*{0.3cm}
\noindent
{\bf Claim 1.} In round  all agents in state {\tt token} have the same memory.

In order to prove the claim we first show that all agents in state {\tt token} in round  have the same seniority. Observe that there cannot be any agent
in state {\tt token} of higher seniority than : {at least one of such agents} would be seen by  during its last clean exploration  between rounds 
and  contradicting its cleanliness. Also there cannot be any agent  in state {\tt token} of lower seniority than . Indeed, let  be the explorer of .
Either  becomes a {\tt searcher} between  and  and thus it meets the token  before time  which contradicts the
declaration of  and  at time  or it remains an {\tt explorer}, in which case  remains a {\tt token} between  and  and thus  is visited
by  during its last clean exploration,  contradicting its cleanliness. This shows that all agents in state {\tt token} in round  have the same seniority.
Hence their explorers start and finish  at the same time. Consequently no token existing in round  can transit to state {\tt shadow}
before round . Agent  must have seen all these tokens during its last exploration. It follows that the memory of each such token in round  must
be equal to the memory of  at this time: otherwise, agent  would detect such a discrepancy during its last exploration, which would contradict the 
cleanliness of this exploration. This proves Claim 1.\finclaim

Claim 1 implies that in time  all agents in state {\tt explorer} have the same memory. Indeed, since at time  agent  is together with , each explorer
must be with its token, since tokens have the same memory.

 \vspace*{0.3cm}
  \noindent
{\bf Claim 2.} In round  there are no agents in state {\tt searcher}.

Suppose for contradiction that there is a searcher  in round . Recall that  performs two explorations: one entire exploration  
and another partial exploration   until meeting a token or an explorer.

  \noindent
{\em Case 1.}  finished its first exploration  by round .\\
Hence its second exploration ends by round . It could not end by round  because  would not be a searcher in this round anymore.
If it ended between  and , it must have met a token . By Claim 1, all explorers have the same seniority and hence at time  the 
explorer  of  backtracked to . This exploration is not clean for . Either  becomes a {\tt searcher} at time  and thus meets  and 
before time , contradicting their declaration at time , or  starts another   and it meets itself  and 
before time , contradicting their declaration at time . This shows that the second exploration of  cannot end between  and ,
hence Case 1 is impossible.

  \noindent
{\em Case 2.}  finished its first exploration  between  and .\\
Hence it must visit some token  during its second exploration (and before starting the backtrack) by round . As before, this contradicts 
the declaration of  and  at time .

  \noindent
{\em Case 3.}  finished its first exploration  between   and .\\
Hence the entire backtrack during this first exploration took place between rounds   and . During this backtrack,  visited some token.
As before, this contradicts 
the declaration of  and  at time .

  \noindent
{\em Case 4.}  finished its first exploration  after round .\\
This is impossible, as it would not be in state {\tt searcher} in round .

This concludes the proof of Claim 2.\finclaim

\vspace*{0.3cm}
\noindent
{\bf Claim 3.} Let  be the set of agents in state {\tt explorer} in round . 
In round  every agent from  can reconstruct its colored view in round  .

To prove the claim first note that since agent  starts its last exploration in round  and all agents from  have the same memory in round ,
they all start an exploration  in this round. In round  every agent from  has visited all nodes of the graph and starts its backtrack.
In round  there are no agents in state {\tt setup} or {\tt cruiser}, in view of the waiting time when  transited to state {\tt explorer}, and there are no agents
in state {\tt searcher} by Claim 2. Hence the visit of all nodes between rounds  and  permits to see all agents that were tokens at time .
Since at this time every explorer were with its token, this
permits to reconstruct the memories and the positions of all agents in round . This is enough to reconstruct the colored views of all agents in round  , which proves the claim.\finclaim

To conclude the proof of the lemma it is enough to show that in round  only one node is occupied by agents, since this will be the final configuration.
Suppose that nodes  are occupied in this round. Let  be the explorer at  and  the explorer at . Note that the colored views of  and 
in round 
must be different, for otherwise the configuration in round  would be a clone configuration, and consequently the final configuration would also be clone,
contradicting Lemma \ref{clone}. Since, by Claim 3, in round  each of the agents  and  has reconstructed its colored view in round  , their memories in round  are different. Between rounds   and , during its backtrack, agent  has visited again all tokens, 
in particular the token of . Hence , after backtracking
to its token in round ,  realizes that another explorer has visited its token, which contradicts the cleanliness of the last exploration of .
This contradiction shows that in round  only one node is occupied and hence the same is true in the final configuration. This concludes the proof of the lemma.
\end{proof}

Now the proof of Theorem \ref{eq} follows directly from Lemmas  \ref{not}, \ref{term},  and \ref{one}. 
 

 
 
 
 
 
 
 
 
 

 


\section{Unknown upper bound on the size of the graph}

In this section we show that, if no upper bound on the size of the graph is known, then there is no universal algorithm for gathering
{\em with detection} all gatherable configurations. Nevertheless, we still show in this case a universal algorithm that gathers all gatherable configurations:
all agents from any gatherable configuration eventually stop forever at the same node (although no agent is ever sure
that gathering is over). The time of such an algorithm is the number of rounds between the wake-up of the first agent and the last round in which some agent moves.
Our algorithm is polynomial in the (unknown) size of the graph.


We first prove the following negative result.

\begin{theorem}\label{no}
There is no universal algorithm for gathering with detection all gatherable configurations in all graphs. 
\end{theorem}

\begin{proof}
Consider the following initial configurations. In configuration  the graph is a 4-cycle with clockwise oriented ports 0,1 at each node, and with additional
nodes of degree 1 attached to two non-consecutive nodes. There are two agents starting at a node of degree 2 and at its clockwise neighbor, cf. Fig. 
 \ref{fig:gatherable} (a).
In configuration , for , the graph is constructed as follows. Take a cycle of size   with clockwise oriented ports 0,1 at each node. 
Call clockwise consecutive nodes of the cycle  (names are used only to explain the construction) 
and attach two nodes of degree 1 to  and one node of degree 1 to every other node with even index. Initial positions of agents are at nodes , where 
 or , for some ,  cf. Fig. \ref{fig:gatherable} (b).

\begin{figure}[h!]
        \begin{center}
        \includegraphics[width=0.8\textwidth]{gatherable.pdf}
        \caption{Configurations  and  in the proof of
Theorem \ref{no}. Black nodes are occupied by agents}
        \label{fig:gatherable}
        \end{center}
\end{figure}

Each of the configurations  and , for , is gatherable. Indeed, in each of these configurations there exist agents with different views
(agents starting at nodes of degree 2 and of degree 3) and each agent has a unique enhanced view (this is obvious for configuration  and follows 
from the existence of a unique node of degree 4 for configurations ). Hence each of these configurations satisfies condition {\bf G} and consequently,
by Theorem \ref{eq}, there is an algorithm for gathering with detection each specific configuration, as such a dedicated algorithm knows 
the configuration and hence may use the knowledge of the size
of the graph.

It remains to show that there is no {\em universal} algorithm that gathers with detection all configurations  and . Suppose, for contradiction, that  is such 
an algorithm. Suppose that the adversary wakes up all agents simultaneously and let  be the time after which agents in configuration  stop at the same node
and declare that gathering is over. Consider the configuration  and two consecutive agents antipodal to the unique node of degree 4, i.e.,   starting from nodes
 and . Call  the agent starting at a node of degree 2 in configuration  and call  the agent starting at its clockwise neighbor (of degree 3)
in this configuration. Call  the agent starting at node  and call  the agent starting at node  in configuration .
(Again names are used only to explain the construction.) 

In the first  rounds of the executions of algorithm  starting from configurations  and  the memories of the agents  and  and
of the agents  and  are 
the same. This easily follows by induction on the round number. Hence after  rounds agents  and  starting from configuration   stop and (falsely)
declare that gathering is over. This contradicts universality of algorithm .
\end{proof}

Our final result is a universal algorithm gathering all gatherable configurations, working without any additional knowledge. It accomplishes correct gathering
and always terminates but (as opposed to Algorithm Gathering-with-Detection which used an upper bound on the size of the graph), this algorithm does not
have the feature of detecting that gathering is over. We first present a high-level idea of the algorithm, then describe it in detail and prove its correctness.
Recall that we assume that the initial configuration satisfies condition {\bf G} (otherwise gathering, even without detection,  is impossible by Lemma \ref{not}).

 \vspace*{0.2cm}

\noindent
{\bf Idea of the algorithm.}

Since in our present scenario no upper bound on the size of the graph is known, already guaranteeing any meeting between agents must be done 
differently than in Algorithm Gathering-with-Detection. After wake-up each agent proceeds in phases {}, where in phase  it ``supposes'' that the graph
has size at most .  In each phase an appropriate label based on procedure  is computed and procedure  is performed sufficiently long to guarantee
a meeting at most at the end of phase {}, where  is the real size of the graph. If no meeting occurs in some phase for a sufficiently long time, the agent starts the next phase.

Another important difference occurs after the meeting, when one of the agents becomes an explorer and the other its token.  Unlike in the case of known upper bound
on the size of the graph, 
there is no way for any explorer to be sure at any point of the execution that it has already visited the entire graph. Clearly procedure  cannot give this guarantee, as  is unknown, and procedure  of exploration with a stationary token, which does not require the knowledge of an upper bound, cannot give this guarantee either, as an explorer cannot be always sure that it visits its own token, because memories of several agents playing the role of the token can be 
identical at various stages of the execution, and hence these ``tokens'' may be undistinguishable for the explorer. 

Nevertheless, our algorithm succeeds in accomplishing the task by using a mechanism which is analogous to the ``butterfly effect''.
Even a slight asymmetry in a remote part of the graph is eventually communicated to all agents and
guarantees that at some point some explorer will visit the entire graph (although in some graphs no explorer can ever be sure of it at any point of an execution) and then all agents will eventually gather at the token of one of these explorers. Making all agents decide on the same token uses property {\bf G}
and is one of the main technical difficulties of the algorithm.

 \vspace*{0.2cm}
 
  \noindent
{\bf Algorithm Gathering-without-Detection}

 Similarly as in Algorithm Gathering-with-Detection,  an agent can be in one of the following five states: {\tt traveler}, {\tt shadow}, {\tt explorer},  {\tt token}, {\tt searcher}.
 State {\tt traveler} partly combines the roles of previous states {\tt setup} and {\tt cruiser}. 
 For every agent  in state  {\tt shadow} the notion of guide is defined as before. 
 Below we describe the actions of an agent  in each of the states and the transitions between the states. At wake-up agent  enters the state  {\tt traveler}.
 
  \vspace*{0.2cm}
 
  \noindent
  {\bf State} {\tt traveler}.
  
  {In this state agent  works in phases  {}. In phase  the agent supposes that the graph has size at most .
 {Agent  performs  in order to visit all nodes (and wake up all still dormant agents), if the assumption is correct, and find the current signature of its initial position , called the {\em label}  of agent .}
 Let  be the maximum possible label of an agent in phase . (Note that  is polynomial in ).
 Then  agent  performs  for  rounds, where {}, for { (i.e., ), and . In the formula for ,  is defined as {} and is an upper bound on the duration of phase . Note that by induction on  we can prove that . Hence  is upper-bounded by\\  which is a polynomial in .}}



 {If no agent has been met during phase , agent  starts phase .} As soon as another agent is met in some phase , agent 
 interrupts this phase and transits either to state
 {\tt shadow} or {\tt token} or {\tt explorer}. Suppose that the first meeting of agent  occurs in round  at node .
 
 \noindent
 Case 1. There are some agents  in round  at node  which are either in state  {\tt searcher}, or {\tt explorer} or  {\tt token} .\\
 Let  be the set of these agents.
 
{ Subcase 1.1.
 There are some agents in  that are either in state {\tt explorer} or {\tt token}. Let  be the set of all those agents in .
 Agent  transits to state {\tt shadow} and its guide is the agent having the largest memory in set .}
 
{Subcase 1.2.
 There is no agent in  that is either in state {\tt explorer} or {\tt token}. Agent  transits to state {\tt shadow} and its guide is the agent in state {\tt searcher} having the largest memory in set .}

 
 \noindent
 Case 2. There are only agents in state {\tt traveler} in round  at node .
 
 Subcase 2.1.
 Agent   has the largest memory among all agents in round  at node .\\
 Then agent   transits to state {\tt explorer}.
 
 Subcase 2.2.
 Agent   does not have the largest memory among all agents in round  at node .\\
 If there is exactly one agent   with memory larger than , then agent  transits to state {\tt token}.
 Otherwise, it transits to state {\tt shadow} of the agent  with largest memory.
 
 (Note that cases 1 and 2 cover all possibilities because 
 an agent in state {\tt shadow} always accompanies its guide and this guide cannot be an agent in state {\tt traveler}.)
 
 \vspace*{0.2cm}
  \noindent
 {\bf State} {\tt shadow}.
 
 Agent  has exactly one guide and is at  the same node as the guide in every round. In every round it makes the same move as the guide.
 If the guide  transits itself to state  {\tt shadow} and gets agent  as its guide, then agent  changes its guide to  as well.  

In the description of the actions in the three remaining states, we will use the notion of seniority defined for  Algorithm Gathering-with-Detection.

 
 
    \vspace*{0.2cm}
 
  \noindent
    {\bf State} {\tt explorer}.
    
    When agent  transits to state {\tt explorer}, there is another agent  that transits to state  {\tt token} in the same round at the same node .
 Agent  is called the token of . Agent  has a variable - that it initializes to the memory of  in this round. 
 
 We first define the notion of a {\em consistent meeting} for agent .
 Let  be the last round when agent  updated its variable -. 
 A consistent meeting for  is a meeting in round  with an agent  in state  {\tt token}
 of the same seniority as ,  such that  is the current memory of  and  . Intuitively, a consistent meeting is a meeting of
 an agent that  can plausibly consider to be its token . Note that, according to this definition, a meeting in the round when the variable - is updated,
 is not a consistent meeting.
 
 We now briefly describe the procedure  based on \cite{CDK} that will be subsequently adapted to our needs {and which allows an agent to construct a BFS tree of the network provided that it cannot confuse its token with another one.}
The agent constructs a BFS tree rooted at its starting node 
marked by the stationary token. In this tree it marks port numbers at all nodes. 
During the BFS traversal, some nodes are added to the BFS tree. {In the beginning, the agent adds the root  and then it makes the {\em process} of . The process of a node  consists in checking all the neighbors of  in order to determine whether 
some of them have to be added to the tree or not. When an agent starts the process of a node , it goes to the neighbor reachable via port  and then checks the neighbor.}

{When a neighbor  of  gets checked, the agent  
verifies if  is equal to some node
previously added to the tree. To do this, for each node  belonging to the current BFS tree, the agent travels from  using the reversal  of the shortest path  from  to  in the BFS tree (the path  is
a sequence of port numbers). If at the end of this backtrack it meets the token, then : in this case  is not added to the tree as a neighbor of  and is called -{\em rejected}. If not, then . Whether node  is rejected or not, the agent then comes back to  using the path . If  is different from all the nodes of the BFS tree, then it is added to the tree.}

{Once node  is added to the tree or rejected, the agent makes an edge traversal in order to be located at  and then goes to a non-checked neighbor of , if any. The order, in which the neighbors of  are checked, follows the increasing order of the port numbers of .} 

{When all the neighbors of  are checked, the agent proceeds as follows. Let  be the set of the shortest paths in the BFS tree leading from the root  to a node  having non-checked neighbors. If  is empty then procedure  is completed. Otherwise, the agent goes to the root , using the shortest path from  to  in the BFS tree, and then goes to a node  having non-checked neighbors, using the lexicographically smallest path from . From there, the agent starts the process of .}

{Note that given a graph  of size at most , every execution of  in  lasts at most  rounds. Indeed,  processing every node  takes at most  rounds (because each node  has at most  neighbors, checking a neighbor of  takes at most  rounds, and before (resp. after) each checking of a neighbor  of , the agent makes an edge traversal from  to  (resp.  to )). Considering the fact that there are at most  nodes to process in  and the fact that moving from a node that has been processed to the next node to process costs at most  rounds, we get the upper bound of  rounds. Hereafter we define  as being equal to .}

{The procedure  is a simulation of  with the following two changes. The first change concerns the beginning of the execution of  when the agent is with its token: it updates its variable - w.r.t to the current memory of its token. The second change concerns meetings with the token. Consider a verification if a node  , which is getting checked, is equal to some previously constructed node . This verification consists in traveling from  using the reverse path ,  where  is the path from the root  to  in the BFS tree and checking the presence of the token. If 
 at the end of the simulation of path  in  agent  makes a consistent meeting, then it acts as if it saw the token in ; otherwise it acts as if it did not see
 the token in .}

{To introduce the next proposition, we first need to define the notion of a {\em truncated spanning tree}. We say that a tree  is a truncated spanning tree of a graph  if  can be obtained from a spanning tree of  by removing one or more of its subtrees.}

{
\begin{proposition}
\label{prop1}
Given a graph  of size {of at most } (unknown to the agents), the following two properties hold: (1) every execution of  in  lasts at most  rounds and (2) every execution of  produces a spanning tree of  or a truncated spanning tree of .
\end{proposition}}

\begin{proof}
{If the agent never confuses its token with another one, the proposition follows directly. So in this proof, we focus only on the situations where there are possible confusions among tokens. When such confusions may occur? }

{The execution of procedure  consists of alternating periods of two different types. The first one corresponds to periods when the agent processes a node and the second one corresponds to those when the agent moves to the next node to process it. During the periods of the second type, an agent does not use any token to move: it follows the same path regardless of whether it meets some token or not on its path. Hence, an agent can confuse its token with another one only in periods of the first type. During such periods, an agent may indeed be "mislead" by a token which is not its own token, when verifying whether a node has to be rejected or not, by wrongly rejecting a node. This leads to the construction of a spanning tree which is truncated, which proves the second property of the proposition.}

{Concerning the first property, note that, as for procedure , every execution of  in  lasts at most . Indeed,  processing every node  also takes at most  rounds (as each node  has at most  neighbors, checking a neighbor of  takes at most  rounds, and before (resp. after) each checking of a neighbor  of , the agent makes an edge traversal from  to  (resp.  to )). Besides, still for the same reasons as for procedure , there are at most  nodes to process in  and moving from a node that has been processed to the next node to process costs at most  rounds. Hence, we also obtain the upper bound of  rounds. Since , the first property of the proposition follows.}
\end{proof}
 
{The procedure  is a simulation of  with the following change.}
 Suppose that the execution of {} produced the route  of the agent. In procedure , upon completing
 procedure , the agent traverses the reverse route  and then again  and . Hence in procedure 
 the agent traverses the concatenation of routes . These parts of the trajectory will be called, respectively, the
 first, second, third and fourth segment of .
 The variable - is updated at the beginning of the first and third segment of . Note that in these rounds agent  is certain to be with its token. {The (possibly truncated) spanning tree resulting from the simulation  is the (possibly truncated) spanning tree resulting from the execution of the first segment.}

{In view of the description of procedure  and Proposition~\ref{prop1}, we have the following proposition.}

{
\begin{proposition}
\label{prop2}
Given a graph  of size  (unknown to the agents), the following two properties hold: (1) every execution of  in  lasts at most  rounds and (2) every execution of  produces a spanning tree of  or a truncated spanning tree of .
\end{proposition}}
   


Similarly as for ,  an execution of   is called {\em clean} if 
the following condition is satisfied: in each round  during this execution, in which  met an agent  {that is not in state {\tt shadow}}, the memory of  is equal to that of ,
and in each round during this execution, in which the token  was met by an agent , the memory of  was equal to that of . Notice that 
after the execution of  , agent  is together with its token  and thus they can verify if the execution was clean, by inspecting their memories.


 After transiting to state {\tt explorer}, agent  executes the following protocol:
 
\noindent
 {\bf repeat forever}\\ 
 /*Before the first turn of the loop agent  has just entered state {\tt explorer} and is with its token.
 After each turn of the loop, agent  is with its token, waiting  after a clean exploration.*/ 
 
  \vspace*{0.2cm} 
  \noindent
  \hspace*{0.5cm} {\bf if}  has just transited to state {\tt explorer} {\bf or}  has just been visited by another agent {\bf then}\\
   \noindent
  \hspace*{1cm}{\bf do}\\
   \noindent
 \hspace*{1.5cm}
 
  \vspace*{0.2cm}
  \noindent
  \hspace*{1.5cm}{\bf if} {in round } agent  met an agent  in state {\tt token} of higher\\ 
   \noindent
  \hspace*{1.5cm}seniority than that of  or of equal seniority but 
   such that\\
   \noindent
   \hspace*{1.5cm} where  is the memory of agent \\
    \noindent
    \hspace*{1.5cm}and  is the last
   round before round  when agent  updated its \\
    \noindent
    \hspace*{1.5cm}variable - {\bf then}  transits to state {\tt searcher}
    
     \vspace*{0.2cm}
     \noindent
     \hspace*{1.5cm}{\bf if} {in round  agent}  met another agent  in state {\tt explorer}, such\\ 
      \noindent
    \hspace*{1.5cm}{that either the seniority of  is higher
     than that of , or these}\\ 
      \noindent
      \hspace*{1.5cm}{seniorities are equal but ,}\\ 
       \noindent
      \hspace*{1.5cm}{where  (resp. ) is the value of the variable - of }\\ 
      \noindent
      \hspace*{1.5cm}{(resp. ) at the time of the meeting and  (resp. ) is the}\\
 \noindent
      \hspace*{1.5cm}{last round before  when agent  (resp. )}\\
 \noindent
      \hspace*{1.5cm}{updated its variable -
       {\bf then}  transits to state {\tt searcher}}
    
     \vspace*{0.2cm}
     \noindent
     \hspace*{1.5cm}{\bf if}  was visited in round  by an agent  in state {\tt explorer} of\\ 
     \noindent
      \hspace*{1.5cm}higher seniority than that of 
     or of equal seniority but such that\\ 
     \noindent
      \hspace*{1.5cm}{, where  is the memory of agent ,
        is}\\
      \noindent
      \hspace*{1.5cm}{the variable - of agent  in round , and  is the last}\\
      \noindent
      \hspace*{1.5cm}{round before  when the variable  was updated}\\
    \noindent
      \hspace*{1.5cm}{\bf then}  transits to state {\tt searcher}\\


     \noindent
     \hspace*{1cm}{\bf until} the execution of  is clean
     
            
 \vspace*{0.2cm}
        \noindent
     {\bf State}  {\tt token}.
     
      When agent  transits to state {\tt token}, there is another agent  that transits to state  {\tt explorer} in the same round at the same node .
 Agent  is called the explorer of . 
Agent  remains  idle at a node  and does not change its state, except when its explorer  transits to state {\tt searcher}. In this case it transits
 to state {\tt shadow} and  becomes its guide. 
  
  \vspace*{0.2cm}
        \noindent
    {\bf State} {\tt searcher}
    
After transiting to state {\tt searcher} agent  performs the sequence of explorations  for {}, until it meets an agent in state
{\tt token} or {\tt explorer} in round . Let  be the set of these agents met by  in round . Agent  transits to state {\tt shadow} and its guide is the 
agent from  with largest memory.   

The analysis of the algorithm is split into the following lemmas.

\begin{lemma}\label{term2}
In Algorithm Gathering-without-Detection every agent eventually stops after time polynomial in the size of the graph.
\end{lemma}

\begin{proof}
Let  be the size of the graph (unknown to the agents). Let {}. Let  be any agent. 
We may assume that at some point  is woken up (otherwise it would be idle all the time).
{We will first show that  must meet some other agent at the end of phase  at the latest. To this end, we need to prove the following claim.}

\noindent
{{\bf Claim 1.} Let  be the first round, if any, in which an agent transits to state {\tt token}. Then there exists an agent  that remains in state {\tt token} and is idle from round  on. }

{To prove the claim, let  be the set of agents that transited to state {\tt token} in round . In every round , the agent from  with the current largest memory remains in state {\tt token} and stays idle. Indeed, the reasons why such an agent, call it , could leave the state {\tt token} in round  all lead to a contradiction. There are six such reasons: four of them are identical to those given in Claim~1 of the proof of Lemma~\ref{term}. Hence to show the validity of the claim, we only need to deal with the two remaining reasons which are the following ones.}
\begin{itemize}

\item{ The explorer of token , denoted , met an agent  in state explorer of higher seniority. Since agent  has the same seniority as agent , by transitivity the seniority of agent  (and of its token) is higher than that of agent , which is a contradiction with the definition of .}

\item{ In round  the explorer of token , denoted , met an agent  in state explorer of equal seniority but such that , where  (resp. ) is the value of the variable - of  (resp. ) at the time of the meeting and  (resp. ) is the last round before  when agent  (resp. ) updated its variable -. This case is impossible. Indeed, by definition, agent  is among the agents having the highest memory among the agents from  in round . Hence, according to the definition of order  given in Section~\ref{prelim}, agent  was among the agents having the highest memory among the agents from  in all rounds between  and . Moreover, since  and  have the same seniority, this implies that the token of  belongs to . Hence, in round  the memory of agent  is greater than or equal to the memory of the token of , which is a contradiction with .}

\end{itemize}

{Since an agent with the largest memory in  in a given round must have had the largest memory among the agents in  in all previous rounds, the claim follows.} \finclaim

Now we are ready to prove the following claim.

\vspace*{0.3cm}
\noindent
{{\bf Claim 2.} Agent  must meet some other agent at the end of phase  at the latest.}

{Assume by contradiction that agent  does not meet any agent by the end of phase . So, there exists at least one agent executing the first { phases} in state {\tt traveler}.
Let  be the first agent to finish the execution of phase . According to the algorithm, phase  is made up of two parts.
The first one consists in performing  and finding the current signature  of the initial position of the executing agent. The signature  plays the role of the agent's label in the second part of phase  which consists in performing  for { rounds, where  is an upper bound on the sum of durations of phases  to , and  is the maximum possible label of an agent in phase }. Observe that at the end of the execution by agent , at some round , of the first part of phase , all the agents in the graph are necessarily woken up due to the properties of procedure  (as ). Hence, we consider two cases.}
\begin{itemize}
\item{No agent meets another agent by round {}. In that case, we know that from round {} on, all the agents execute the second part of phase  and for each of them there remain at least  rounds before the end of the second part of phase . Since the agents cannot all determine the same signature in phase , there are at least two agents having two distinct labels and thus two agents meet by round {} due to the properties of procedure . So, at least one agent transits to state {\tt token} by round . However, the last period of  rounds when agent  executes the second part of phase  starts after round . So, in view of the properties of procedure  and of Claim~1, we know that agent  meets an agent in state  by the end of phase  if it does not meet an agent in another state before. We get a contradiction with the assumption made at the beginning of this proof.}

\item{At least two agents meet by round {}. In that case, we know that an agent transits to state {\tt token} by this round. Using similar arguments as before, we can prove that agent  meets an agent in state  by the end of phase  if it does not meet an agent in another state before. Again we get a contradiction with the assumption made at the beginning of this proof.}
\end{itemize}

{So, we get a contradiction in all cases. Hence, agent  must meet some other agent at the end of phase  at the latest, which proves the claim.} \finclaim

{According to Claim~2, we know that after time at most {\\ } agent  transits from state 
{\tt traveler} either to state {\tt shadow} or {\tt token} or {\tt explorer}.} {To deal with the state {\tt shadow}, we need the following claim.}

\vspace*{0.3cm}
\noindent
{{\bf Claim 3.} If agent  becomes the {\tt shadow} of an agent  at some round , then agent  cannot itself switch to state {\tt shadow} in the same round.}

{To prove the claim, there are  cases to consider.}

\begin{itemize}
\item{ {Case~1.} Agent  transits from state {\tt token} to state {\tt shadow} in round . According to the algorithm, agent  is an 
{\tt explorer} transiting to state {\tt searcher} in round .}

\item{ {Case~2.} Agent  transits from state {\tt searcher} to state {\tt shadow} in round . According to the algorithm,  is }
\begin{itemize}
\item{ either an agent in state {\tt explorer}. However, an agent in state {\tt explorer} cannot switch directly to state {\tt shadow}. Hence  cannot transit to
state {\tt shadow} in round . }
\item{ or an agent in state {\tt token}. Let  be the set of agents in state {\tt explorer} or {\tt token} that are at the same node as  in round . According to the algorithm, agent  is the agent having the highest memory in . This implies that agent  is not with its {\tt explorer} in round  because an agent in state {\tt explorer} has a higher memory than its {\tt token} (refer to the way they are created from state {\tt traveler}). However, an agent in state {\tt token} may transit to state {\tt shadow} only if it is with its {\tt explorer}. Hence agent  remains in state {\tt token} in round .}
\end{itemize}
\item{ {Case~3.} Agent  transits from state {\tt traveler} to state {\tt shadow} in round . Let  be the set of the other agents that are at the same node  as agent  in round . We have  subcases to consider.}
\begin{itemize}

\item{  There are only agents in state {\tt traveler} in .\\ According to the algorithm, agent  is a {\tt traveler} transiting to state {\tt explorer}.}

\item{  There is no agent in state {\tt explorer} or {\tt token} in  but at least one agent in state {\tt searcher}.\\ According to the algorithm, agent  is an agent in state {\tt searcher} that does not transit to state {\tt shadow} in round  (because an agent in state {\tt searcher} can transit to state {\tt shadow} only if it is with an agent in state {\tt explorer} or {\tt token}).}

\item{  There is at least one agent in state {\tt explorer} or {\tt token} in .\\ According to the algorithm, agent  is an agent in state {\tt explorer} or {\tt token} that cannot switch to state {\tt shadow} in round  for similar reasons as in Case~2. }

\end{itemize}
 
\end{itemize}

{In all cases,  does not switch to state {\tt shadow} in round , which proves the claim.} \finclaim

{In view of Claim~3 and of the fact that} the termination  conditions for an agent in state 
 {\tt shadow} are the same as of its guide, we may exclude the state {\tt shadow} from our analysis.



Consider an agent in state {\tt explorer}. Either at some point it transits to state {\tt searcher}, in which case, after executing this transition,  it uses at most  rounds to perform procedures 
 for , by which time it must have met some token or explorer {(because at least one token is idle all the time starting from the first round when an agent transits to state token, according to Claim~1)} and hence must have transited to state {\tt shadow},
 or it remains in state {\tt explorer} till the end of the algorithm.
 
{ We will first show that the total number of rounds in which the agent moves as an explorer is polynomial in . This is not enough to show that, after polynomial time,  transits to state {\tt searcher} or remains idle forever (as an explorer), since we still need to bound the duration of each period of idleness
 between any consecutive periods of moving. This will be addressed later.}
 
{Two events can trigger further moves of agent  while it is in state {\tt explorer}}: a meeting causing a non-clean exploration
  or a visit of  by some agent, when  stays with its token after a clean exploration. 
 
 We first treat the first of these two types of events and bound the total time of explorations caused by them.
 An exploration {made by agent } could be non-clean due to several reasons,
 according to the description of the algorithm.
 \begin{itemize}
 \item
{{In round } agent  met an agent  in state {\tt token} of higher seniority than that of , or of equal seniority but such
  that , {where  is the last round before round  when the variable - of  was updated.} According to the algorithm, agent  transits to state {\tt searcher} as soon as it terminates its exploration  after round . Hence such a meeting can cause at most  exploration  of  to be non-clean.}
\item
  {{In round  the token  of  was visited by an agent  in state {\tt explorer} of higher seniority than that of ,
     or of equal seniority but such that , where  is the variable - of agent , and  is the last round before round  when the variable - of  was updated. According to the algorithm, agent  transits to state {\tt searcher} as soon as it terminates its exploration  after round . Hence such a meeting can cause at most  exploration  of  to be non-clean.}}

     \item
     Either agent  or its token  met an agent  in state {\tt traveler}. Since  transits immediately to state {\tt shadow}, all agents in state {\tt traveler}
    {can cause at most  explorations  of agent  to be non-clean.}
       \item
     Either agent  or its token  met an agent  in state {\tt searcher}. Since  transits immediately to state {\tt shadow}, all agents in state {\tt searcher}
   {can cause at most  explorations  of agent  to be non-clean.}
   \item
  { met an agent   in state {\tt token} of lower seniority than that of , or of equal seniority but such that , where  is the last round before this meeting when agent  updated its variable . After this meeting,
   the remaining time when agent  remains in state {\tt token} is less than the longest duration of one execution of  (after less than this time the explorer of  becomes searcher and hence  transits to state {\tt shadow}). Thus, as an agent in state {\tt token}, agent  can cause at most  explorations  of  to be non-clean.
Hence all such meetings can cause at most  explorations  of  to be non-clean.} 
   
   
     \item
     {In round } the token  of  met an agent   in state {\tt explorer} of lower seniority than that of , or of equal seniority but such that , {(where  is the last round before  when the variable - of  was updated)}.
     A similar analysis as in the previous case shows that such meetings {can cause at most  explorations  of  to be non-clean.}  
     \item
    {In round  agent  met an agent  in state {\tt explorer} of lower seniority than that of , or of equal seniority but such that , where  (resp. ) is the value of the variable - of  (resp. ) at the time of the meeting and  (resp. ) is the last round before  when agent  (resp. ) updated its variable. After the meeting agent  ``loses'', i.e., it will transit to state {\tt searcher} after backtracking
     to its token. Hence agent  remains in state {\tt explorer} for less than  rounds after the meeting. Similarly as before, such meetings can cause at most   explorations  of  to be non-clean.}

\item
    {In round  agent  met an agent  in state {\tt explorer} of equal seniority and such that , where  (resp. ) is the value of the variable - of  (resp. ) at the time of the meeting and  (resp. ) is the last round before  when agent  (resp. ) updated its variable -. Let  (resp. ) be the first round since  when agent  (resp. ) updates its variable -. From round  on, this kind of meeting with agent  cannot occur anymore. Indeed, in view of the fact that the memories of  and  are necessarily different in round  and the fact that once agent  finishes the execution of  involving this meeting, its variable - will be updated, we know that   from round  on. Since the difference between  and  is less than the longest duration of one execution of , similarly as before, such meetings can cause at most   explorations  of  to be non-clean.}

\item
   {In round  agent  met an agent  in state {\tt explorer} of higher seniority than that of  or of equal seniority but such that , where  (resp. ) is the value of the variable - of  (resp. ) at the time of the meeting and  (resp. ) is the last round before  when agent  (resp. ) updated its variable. According to the algorithm, agent  transits to state {\tt searcher} as soon as it terminates its exploration  after round . Hence such a meeting can cause at most  exploration  of  to be non-clean.}    
     
   \item
     met an agent   in state {\tt token} in round , that looked like its token  at this time, but that turned out not to be the token  after the backtrack
    of  on . More precisely,  in round  (where  is the last round before  when the variable - of  was updated)
    but . After round  agent  may look like token  of  for {less than}   rounds because after {less than} this time
     backtracks to its token  and, from this time on, it can see the difference between  and .
    Similarly as before such meetings can cause at most {  explorations  of  to be non-clean.} 
    
    \item
    In round  the token  was visited by an agent  of equal seniority in state {\tt explorer} such that , where  is the last round before  when the variable - of  was updated, and this agent turned out not to be  after 
    the backtrack of  on . Similarly as before, such meetings can cause at most { explorations  of  to be non-clean.} 
     \end{itemize}
 {Hence the first of the two types of events (meeting causing a non-clean exploration) can cause at most {} explorations  of  to be non-clean. (As before we add up all upper bounds for simplicity). Considering the fact that each non-clean exploration  is directly followed by at most one clean exploration , this kind of meeting can cause at most {} rounds of motion of .}
 {The second type of events (a visit of  by some agent, when  stays with its token after a clean exploration)
     can cause at most  rounds of motion of . Indeed, according to the algorithm, a visit of  by some agent  when  stays idle with its token 
can be of the following kinds.}

\begin{itemize}
\item {Agents  and  are visited by an agent  in state {\tt traveler}. Since, at this visit, agent  transits immediately to state {\tt shadow}, such visits can trigger at most  exploration  of agent .} 

\item {Agents  and  are visited by an agent  in state {\tt searcher}. Since, at this visit, agent  transits immediately to state {\tt shadow}, such  visits can trigger at most  exploration  of agent .}

\item {In round , agents  and  are visited by an agent  in state {\tt explorer} of lower seniority than that of , or of equal seniority but such that , where  is the memory of agent  in round ,  is the variable - of agent  in round , and  is the last round before  when the variable  was updated. After the visit agent  ``loses'', i.e., it will transit to state {\tt searcher} after backtracking
     to its token. Hence agent  remains in state {\tt explorer} for less than  rounds after the visit and thus, such visits can trigger at most  explorations  of .}

\item {In round  agents  and  are visited by an agent  in state {\tt explorer} of equal seniority to that of  and such that , where  is the memory of agent  in round ,  is the variable - of agent  in round , and  is the last round before  when the variable  was updated. Let  be the first round after  when agent  updates its variable -. From round  on, this kind of visit by agent  cannot occur anymore. Indeed, in view of the fact that the memories of  and  are necessarily different in round  and the fact that once agent  finishes the execution of , its variable - will be updated, we know that  from round  on. Since the difference between  and  is less than the longest duration of one execution of , similarly as before, such visits can trigger at most   explorations  of .}

\item  {In round , agents  and  are visited by an agent  in state {\tt explorer} of higher seniority than that of  or of equal seniority to that of  and such that , where  is the memory of agent  in round ,  is the variable - of agent  in round , and  is the last round before  when the variable  was updated. According to the algorithm, agent  transits to state {\tt searcher} as soon as it terminates its exploration  after round . Hence such visits can trigger at most  exploration  of A.}
\end{itemize}



{Hence adding the first exploration that must be made by  (which is not trigerred by any meeting), we get an upper bound of { rounds} during which agent  moves in state {\tt explorer}.}
      
      It remains to consider an agent in state {\tt token}. It may either transit to state {\tt shadow} or remain in state {\tt token} forever.
      In the latter case it is idle all the time. 
      
      Since {{},  and  are all polynomial in }, the above
      analysis shows that there exists a polynomial , such that, for each agent  executing Algorithm Gathering-without-Detection in any graph of size , the 
      number of rounds during which this agent moves is at most . In order to finish the proof, we need to bound the number of rounds during which an
      agent  can be idle before moving again. To do this we will use the following claim.
      
      \vspace*{0.3cm}
      \noindent
      {{\bf Claim 4.}} If in round  of the execution of Algorithm Gathering-without-Detection no agent moves, then no agent moves in any later round of this execution.
      
      To prove the claim notice that if no agent moves in round , then in this round no agent is in state {\tt traveler} or {\tt searcher}.
      Moreover each agent in state  {\tt explorer} must be idle and stay with its token in this round (all other nodes must be in state {\tt shadow}).
      In order for some agent to move in round , some explorer would have to visit some other token in round , contradicting the definition of .
      Hence all agents are idle in round . By induction, all agents are idle from round  on. This proves the claim.\finclaim
      


      Since for each agent executing Algorithm Gathering-without-Detection in a graph of size , the number of rounds in which it moves is at most 
      and there are at most  agents, {Claim~4} implies that after time at most   since the wake up of the first agent, all agents must stop forever.
    \end{proof} 
    
    By Lemma \ref{term2} there exists a round after which, according to Algorithm Gathering-without-Detection,  no agent moves.
    Call the resulting configuration {\em final}. The following lemma implies  that  Algorithm Gathering-without-Detection is correct.
    
    \begin{lemma}\label{cor}
    In every final configuration exactly one node is occupied by agents. 
    \end{lemma}
    
    \begin{proof}
    A final configuration must consist of agents in states  {\tt explorer} , 
{\tt token} and {\tt shadow}, all situated in nodes , such that in each node  there is exactly one agent  in state {\tt explorer}, exactly one
agent  in state {\tt token}  and possibly some agents in state  {\tt shadow}. As before we call such a final configuration a {\em clone} 
configuration if there are at least two
distinct nodes ,  which have identical colored views. The same argument as in the proof of Lemma \ref{clone} shows that
a final configuration cannot be a clone configuration. 

It is enough to prove that . Suppose for contradiction that . We will consider two cases. In the first case the memories of all explorers  are
identical and in the second case they are not. In both cases we will derive a contradiction.

 \vspace*{0.2cm}
        \noindent
Case 1. All explorers  in the final configuration have identical memory.

In this case all these explorers performed the last exploration  simultaneously, {in view of the fact that the algorithm that they execute is deterministic}.

We start with the following claim.

 \vspace*{0.2cm}
        \noindent
{\bf Claim 1.} {If a node has been rejected by the explorer  in the construction of its {(truncated) spanning} tree during its last exploration , then
this node, let us call it , must have been either added previously by  to its {(truncated) spanning} tree, or added  by another explorer 
in the construction of its {(truncated) spanning} tree during its last exploration .} 

The node  was rejected by  for the following reason.   
traveled from  using the reversal  of the path , where  is a path (coded as a sequence of ports) from  to some node
 already in the {(truncated) spanning} tree of , and at the end of this path ,  met a token with memory , such that ,
where  is the last round when  updated its variable -.

There are two possible cases. If the token met by  is its own token (residing at ), then  is equal to some node  already added previously
to the {(truncated) spanning} tree of .  If, on the other hand, the token
met by  is the token of some other explorer , then we will show that  is added by  to its {(truncated) spanning tree}. 
Indeed, since  has added a node 
to its {(truncated) spanning} tree, such that the path from  to  is , the explorer  must have added a node  to its {(truncated) spanning} tree, such that the path from  to  is 
as well, because both  and  have identical memories. However, this node  must be equal to , since the path from  to  is .
This proves the claim.\finclaim

The contradiction in Case 1 will be obtained in the following way. Using {(truncated) spanning} trees produced by explorers  during their last exploration 
(recall that these trees are isomorphic, since memories of the explorers are identical), we will construct the colored view for each explorer.
Using the fact that memories of the explorers are identical, these colored views will be identical. This will imply that the final configuration is a clone
configuration, which is impossible. 

The construction proceeds as follows (we will show it for explorer ). Let  be the {(truncated) spanning} tree produced by .
Each tree  has its root  colored black and all other nodes colored white. We will gradually
attach various trees to  in order to obtain the colored view from . 
First attach to every node of  its neighbors that have been rejected by  during the construction of . Explorer  has visited these
nodes, hence the respective port numbers can be faithfully added. Consider any such rejected node .  By Claim 1, there are two possibilities.
If node  was previously added by  to  as some node , then we proceed as follows. Let  be the tree  but rooted at  instead of .
We attach tree  at , identifying its root  with .
If node  was added  by another explorer  in the construction of its {(truncated) spanning} tree , we proceed as follows. 
As mentioned in the proof of Claim 1, the explorer  must have added a node  to its {(truncated) spanning} tree, such that the path from  to  is .
Let  be the tree  but rooted at  instead of . We attach tree  at , identifying its root  with .

After processing all nodes rejected by  and adding the appropriate trees, we attach all rejected neighbors of nodes in the newly obtained increased
tree. These nodes could have been rejected either by  itself or by another explorer  whose (re-rooted) tree  has been attached.
For each newly attached node rejected by , the construction continues as before, replacing the role of  by .

{The above construction proceeds infinitely, producing an infinite rooted tree (rooted at a node corresponding to ). We make one final addition in order to obtain the view  from  (cf. Claim~2) : each node  of the tree is assigned a label corresponding to the shortest path from the root to . The resulting infinite tree is denoted by }.

\vspace*{0.3cm}
\noindent
{{\bf Claim 2.}  corresponds to view }

{We prove the claim by induction. First of all, note that  truncated at depth  from its root corresponds to the truncated view .
Assume as induction hypothesis that the tree  truncated at depth  from its root, call it , corresponds to the truncated view . We will show that  corresponds to the truncated view .}

{According to the process described above, whenever a node , corresponding to a node  in the network , is added to  under construction, exactly one child  is eventually added to  for each neighbor  of  in . More precisely, node  is connected to node  by an edge having port  at node  and port  at node  iff node  and its child  are connected between them by an edge having port  at node  and port  at node . In addition, if the label of  is path  then the label of  is path .}

{Hence, if in tree  we identify a node with its label, we have the following two properties: (1) for every path  of length  (according to the induction hypothesis,  is located at distance  from the root of  and corresponds to a path from  in ), its children correspond to all paths from  of length  whose prefix is  in  and (2) for every path  of length , every child  of path , such that , is connected to  in  by an edge that has port  at node  and port  at node .}

{Moreover, since  is , the above two properties also hold if  is replaced by any value ranging from  to . Hence  is , which proves the claim.} \finclaim

To produce the colored view, notice that there are only two colors in this colored view: white corresponding to empty nodes in the final configuration and
black corresponding to nodes ,...,  (all these nodes get identical colors: since memories of explorers are the same, memories of their tokens
are also the same and memories of corresponding nodes in state {\tt shadow} are also identical).  It remains to indicate how the colors are distributed
in the constructed view. This is done as follows. When a tree  is attached, exactly one of its nodes (namely the node corresponding to ) is black.
Exactly these nodes become black in the obtained colored view. 

This construction of colored views is done for all explorers . Consider two explorers  and .
Since these explorers have the same memory, the trees  attached at a given stage of the construction of the views of  and   are
isomorphic. They are also attached in the same places of the view. Hence by induction of the level of the view it follows that both colored views are identical.
This implies that the final configuration is a clone configuration which gives a contradiction in Case 1.

 \vspace*{0.2cm}
        \noindent
Case 2.  There are at least two explorers  and  with different memories in the final configuration.

Consider the equivalence relation on the set of explorers , such that two explorers are equivalent if their memories
in the final configuration are identical.
Let , where , be the equivalence classes of this relation. Suppose w.l.o.g. that  is a class of explorers with smallest
seniority. We will use the following claim.

\vspace*{0.3cm}
\noindent
{{\bf Claim 3.}}
During the last exploration  of explorers in , at least one of the following statements holds:
\begin{itemize}
\item
an explorer from  has visited a token of an explorer not belonging to ;
\item
a token of an explorer from  has been visited by an explorer not belonging to .
\end{itemize}

In order to prove the claim consider two cases. If every node of the graph has been visited by some explorer from , we will show that the
first statement holds. Indeed, since explorers from  have the smallest seniority, during their last execution of   all tokens{, which are in the final configuration,} are already at 
their respective nodes {(because otherwise there would be at least one token and its explorer in the final configuration that were created after the creation of the tokens from , which would be a contradiction with the fact that explorers from , and hence also their tokens, have the smallest seniority in the final configuration)}. Hence some explorers from  must visit the tokens of explorers outside of . Hence we can restrict attention
to the second case, when some nodes of the graph have not been visited by any explorer from . Notice that if there were no other classes than
, this could not occur. Indeed, we would be then in Case 1 (in which all explorers have identical memory). Thus Claim 1 would hold, which implies
that all nodes must be visited by some explorer, in view of the graph connectivity. 

Hence the fact that some node is not visited by explorers from  must be due to a meeting of some other agent
(which is neither an explorer from   nor a token of such an explorer) during their last exploration .
What kind of a meeting can it be? It cannot be a meeting with an agent in state {\tt traveler} or {\tt searcher} because this would contradict that the last exploration
was clean. For the same reason it cannot be a meeting of an explorer from  with another explorer. This leaves only the two types of meetings specified in the claim, which finishes the proof of the claim.\finclaim

Let  be a couple of an explorer outside of   and of its token, such that either an explorer from  visited  or a token of an explorer
from  has been visited by  during the last exploration of explorers in the class . Such a couple exists by {Claim 3}. The seniority of  and  must be the same as that of explorers from  ,
for otherwise their last exploration would not be clean. For the same reason, when explorers from  started their last exploration, the explorer  must
have started an exploration as well (possibly not its final exploration):  otherwise the exploration of explorers from  would not be clean. Moreover we show that
 when explorers from  finished their last exploration, explorer  must have finished an exploration as well. To prove this, consider two cases, corresponding
 to two possibilities in {Claim 3}.  Suppose that an explorer  from  has visited  and that its exploration did not finish simultaneously with the exploration
 of . Consider the consecutive segments  of the last exploration  of . (Recall that these segments were specified in the definition of .) Since  has visited  during , it must have visited it during each segment . At the end of , explorer  knows how long
  will take. At the end of  its token learns it as well. When  visits  again in segment , there are two possibilities. 
 Either  does not
 know when the exploration of  finishes, or it does know that it finishes at a different time than the exploration of . In both cases the explorer  that
 updated its variable - at the end of  can see that , where  is the memory of  and  is the end of . 
This makes the last exploration of  non clean, which is a contradiction. This proves that   and  finish their exploration simultaneously, if 
has visited . The other case, when  has visited the token of  is similar. Hence we conclude that explorations of  and of  started
and finished simultaneously.

Let  be the round in which the last exploration of  (and hence of all explorers in ) finished. The exploration of  that finished in round 
cannot be its final exploration because then it would have the same memory as  in the final configuration and thus it would be in the class   
contrary to the choice of . Hence  must move after round . It follows that there exists a class  (w.l.o.g. let it be ) such that explorers 
from this class started their last exploration after round . Note that during this last exploration, explorers from  could not visit all nodes of the graph, for otherwise they would meet explorers from  after round , inducing them to move after this round, contradicting the fact that explorers from 
do not move after round .

The fact that some node is not visited by explorers from  must be due to a meeting of some other agent
(which is neither an explorer from   nor a token of such an explorer) during their last exploration .
Otherwise, for explorers in  the situation would be identical as if their equivalence class were the only one, and hence, as in Case 1, 
they would visit all nodes. Moreover, the fact that some node is not visited by explorers from  must be due to a meeting of some explorer outside of 
or of its token (if not, explorers from  would move after round , which is a contradiction). 
An argument similar to that used in the proof of {Claim 3} shows that there exists a couple , such that  is an explorer outside of  ,
 is its token, and 
either an explorer from  visited  or a token of an explorer
from  has been visited by  during the last exploration of explorers in the class .
Let  be the round in which the last exploration of explorers from  is finished.
Similarly as before, the explorer  terminates some exploration in round  but continues to move afterwards.

Repeating the same argument  times we conclude that there exists a round 
after which all explorers from  never move again, but the last exploration of explorers from 
  starts on or after . During this last exploration there must be a node not visited by any explorer from , 
 otherwise some explorers from  would move after .
 This is due to a meeting. It cannot be a meeting with an agent in state {\tt traveler} or {\tt searcher} because this would contradict that the last exploration
was clean. For the same reason it cannot be a meeting of an explorer from  with another explorer. Hence two possibilities remain.
Either an explorer from  visits a token of an explorer from  or a token of an explorer from  is visited
by an explorer from . The first situation is impossible because it would contradict the cleanliness of the last exploration
of explorers from  and the second situation is impossible because explorers from  do not move after .
Hence in Case 2 we obtain a contradiction as well, which completes the proof.
    \end{proof}
    
    Lemmas \ref{term2} and \ref{cor} imply the following result.


\begin{theorem}
Algorithm Gathering-without-Detection performs a correct gathering of all gatherable configurations and terminates in time polynomial in the size of the graph.
\end{theorem}

\section{Consequences for leader election}

Leader election \cite{Ly} is a fundamental symmetry breaking problem in distributed
computing. Its goal is to assign, in some common round, value 1 (leader) to one of the entities and value 0 (non-leader)
to all others. The assignment should happen once for each identity, in a unique common round, and cannot be changed afterwards. 
In the context of anonymous agents in graphs, leader election can be formulated
as follows:
\begin{itemize}
\item
There exists a common unique round in which one of the agents assigns itself value 1 (i.e., it declares itself a leader) and each 
other agent assigns itself value 0 (i.e., it declares itself non-leader).
\end{itemize}

The following proposition says that the problems of leader election and of gathering with detection are equivalent in the following strong sense.
Consider any  initial configuration of agents in a graph. If gathering with detection can be accomplished for this configuration in some round , then
leader election can be accomplished for this configuration in some round , and conversely, if leader election can be accomplished for this configuration 
in some round , then gathering with detection  can be accomplished for this configuration in some round .
 


\begin{proposition}\label{eqbis}
Leader election is equivalent to gathering with detection.
\end{proposition}

\begin{proof}
Suppose that gathering with detection is accomplished and let  be the round when all agents
are together and declare that gathering is over. As mentioned in the Preliminaries, all agents must have different
memories, since they are at the same node, and, being together, they can compare these memories. 
Since,  in view of detection, the round  is known to all agents,
in round  the agent with 
the largest memory assigns itself value 1 and all other agents assign themselves value 0.

Conversely, suppose that leader election is accomplished and let  be the round in which one 
of the agents assigns itself value 1 and all other agents assign themselves value 0. Starting from round 
the agent with value 1 stops forever and plays the role of the token, all other agents playing the role of explorers.
First, every explorer finds the token by executing procedure  for  rounds in phases 
, until it finds the token in round  (this round may be different for every explorer). 
Then every explorer executes procedure  (using the token) and finds the map of the graph and hence its size .
Then it waits with the token until round . By this round
all explorers must have found the token and executed procedure , i.e., they are all together with the token.
In round  all agents declare that gathering is over. 
\end{proof}

Proposition \ref{eqbis} implies that the class of initial configurations for which leader election is at all possible (even only using an algorithm dedicated
to this specific configuration) is equal to the class of gatherable configurations, i.e., to the class of configurations
satisfying property {\bf G}. Similarly as for gathering, we will say that a leader election algorithm is {\em universal} if it performs leader election for all
such configurations. It follows that a small modification of Algorithm Gathering-with-Detection is a universal leader election algorithm,
provided that an upper bound on the size of the graph is known to the agents. The modification is 
the following: use Algorithm Gathering-with-Detection to gather all agents in some round , and, in round , elect as leader the agent that has the largest 
memory in the round of the gathering declaration (this agent assigns itself value 1 and all other agents assign themselves value 0). Let LE be the name of this modified algorithm.





The following corollary summarizes the above discussion and gives a complete solution of the leader election
problem for anonymous agents in arbitrary graphs.
 



\begin{corollary}
For a given initial configuration, leader election is possible if and only if this
configuration satisfies condition {\bf G}. 
If an upper bound on the size of the graph is known, then Algorithm LE accomplishes leader election for
all these configurations.
There is no universal algorithm accomplishing leader election for all configurations satisfying condition {\bf G} in all graphs.
\end{corollary}







 



  
  
  
     








\begin{thebibliography}{10}

\bibitem{AP06}
Noa Agmon and David Peleg.
\newblock Fault-tolerant gathering algorithms for autonomous mobile robots.
\newblock {\em {SIAM} Journal on Computing}, 36(1):56--82, 2006.

\bibitem{alpern95a}
Steve Alpern.
\newblock The rendezvous search problem.
\newblock {\em SIAM Journal on Control and Optimization}, 33(3):673--683, 1995.

\bibitem{alpern02a}
Steve Alpern.
\newblock Rendezvous search on labelled networks.
\newblock {\em Naval Research Logistics}, 49:256--274, 2002.

\bibitem{alpern02b}
Steve Alpern and Shmuel Gal.
\newblock {\em Theory of Search Games and Rendezvous}.
\newblock Kluwer Academic Publisher, 2003.

\bibitem{anderson90}
Eddie Anderson and Richard Weber.
\newblock The rendezvous problem on discrete locations.
\newblock {\em Journal of Applied Probability}, 28(4):839--851, 1990.

\bibitem{anderson98a}
Edward Anderson and S{\'{a}}ndor Fekete.
\newblock Asymmetric rendezvous on the plane.
\newblock In {\em 14th Annual Symposium on Computational Geometry, June 7-10, 1998, Minneapolis, Minnesota, USA. Proceedings}, pages 365--373, 1998.

\bibitem{anderson98b}
Edward Anderson and S{\'{a}}ndor Fekete.
\newblock Two dimensional rendezvous search.
\newblock {\em Operations Research}, 49(1):107--118, 2001.

\bibitem{An}
Dana Angluin.
\newblock Local and global properties in networks of processors (extended
  abstract).
\newblock In {\em 12th Annual {ACM} Symposium on Theory of
  Computing, April 28-30, 1980, Los Angeles, California, {USA}. Proceedings}, pages 82--93,
  1980.


\bibitem{AtSn}
Hagit Attiya and Marc Snir.
\newblock Better computing on the anonymous ring.
\newblock {\em Journal of Algorithms}, 12(2):204--238, 1991.


\bibitem{BCGIL}
Evangelos Bampas, Jurek Czyzowicz, Leszek Gasieniec, David Ilcinkas, and Arnaud
  Labourel.
\newblock Almost optimal asynchronous rendezvous in infinite multidimensional
  grids.
\newblock In {\em Distributed Computing, 24th International Symposium, {DISC}
  2010, Cambridge, MA, USA, September 13-15, 2010. Proceedings}, pages
  297--311, 2010.

\bibitem{baston01}
Vic Baston and Shmuel Gal.
\newblock Rendezvous search when marks are left at the starting points.
\newblock {\em Naval Research Logistics}, 48(8):722--731, 2001.

\bibitem{BV}
Paolo Boldi and Sebastiano Vigna.
\newblock Computing anonymously with arbitrary knowledge.
\newblock In {\em Proceedings of the Eighteenth Annual {ACM} Symposium on
  Principles of Distributed Computing, PODC, '99Atlanta, Georgia, USA, May 3-6,
  1999}, pages 181--188, 1999.


\bibitem{CDK}
J{\'{e}}r{\'{e}}mie Chalopin, Shantanu Das, and Adrian Kosowski.
\newblock Constructing a map of an anonymous graph: Applications of universal
  sequences.
\newblock In {\em Principles of Distributed Systems - 14th International
  Conference, {OPODIS} 2010, Tozeur, Tunisia, December 14-17, 2010.
  Proceedings}, pages 119--134, 2010.
  


\bibitem{CFPS}
Mark Cieliebak, Paola Flocchini, Giuseppe Prencipe, and Nicola Santoro.
\newblock Distributed computing by mobile robots: Gathering.
\newblock {\em {SIAM} Journal on Computing}, 41(4):829--879, 2012.

\bibitem{CP05}
Reuven Cohen and David Peleg.
\newblock Convergence properties of the gravitational algorithm in asynchronous
  robot systems.
\newblock {\em {SIAM} Journal on Computing}, 34(6):1516--1528, 2005.

\bibitem{CP08}
Reuven Cohen and David Peleg.
\newblock Convergence of autonomous mobile robots with inaccurate sensors and
  movements.
\newblock {\em {SIAM} Journal on Computing}, 38(1):276--302, 2008.

\bibitem{CKP}
Jurek Czyzowicz, Adrian Kosowski, and Andrzej Pelc.
\newblock How to meet when you forget: log-space rendezvous in arbitrary
  graphs.
\newblock {\em Distributed Computing}, 25(2):165--178, 2012.

\bibitem{CLP}
Jurek Czyzowicz, Andrzej Pelc, and Arnaud Labourel.
\newblock How to meet asynchronously (almost) everywhere.
\newblock {\em {ACM} Transactions on Algorithms}, 8(4):37, 2012.

\bibitem{DDN}
Gianlorenzo D'Angelo, Gabriele~Di Stefano, and Alfredo Navarra.
\newblock Gathering on rings under the look-compute-move model.
\newblock {\em Distributed Computing}, 27(4):255--285, 2014.

\bibitem{DGKKP}
Gianluca~De Marco, Luisa Gargano, Evangelos Kranakis, Danny Krizanc, Andrzej
  Pelc, and Ugo Vaccaro.
\newblock Asynchronous deterministic rendezvous in graphs.
\newblock {\em Theoretical Computer Science}, 355(3):315--326, 2006.


\bibitem{DFKP}
Anders Dessmark, Pierre Fraigniaud, Dariusz~R. Kowalski, and Andrzej Pelc.
\newblock Deterministic rendezvous in graphs.
\newblock {\em Algorithmica}, 46(1):69--96, 2006.

\bibitem{DP}
Yoann Dieudonn{\'{e}} and Andrzej Pelc.
\newblock Deterministic network exploration by anonymous silent agents with
  local traffic reports.
\newblock In {\em Automata, Languages, and Programming - 39th International
  Colloquium, {ICALP} 2012, Warwick, UK, July 9-13, 2012, Proceedings, Part
  {II}}, pages 500--512, 2012.

\bibitem{DPP}
Yoann Dieudonn{\'{e}}, Andrzej Pelc, and David Peleg.
\newblock Gathering despite mischief.
\newblock {\em {ACM} Transactions on Algorithms}, 11(1):1, 2014.

\bibitem{DPV}
Yoann Dieudonn{\'{e}}, Andrzej Pelc, and Vincent Villain.
\newblock How to meet asynchronously at polynomial cost.
\newblock In {\em {ACM} Symposium on Principles of Distributed Computing,
  {PODC} 2013, Montreal, QC, Canada, July 22-24, 2013}, pages 92--99, 2013.

\bibitem{FIPS}
Paola Flocchini, David Ilcinkas, Andrzej Pelc, and Nicola Santoro.
\newblock Remembering without memory: Tree exploration by asynchronous
  oblivious robots.
\newblock {\em Theoretical Computer Sci.ence}, 411(14-15):1583--1598, 2010.

\bibitem{fpsw}
Paola Flocchini, Giuseppe Prencipe, Nicola Santoro, and Peter Widmayer.
\newblock Gathering of asynchronous robots with limited visibility.
\newblock {\em Theoretical Computer Science}, 337(1-3):147--168, 2005.

\bibitem{FGKP}
Pierre Fraigniaud, Leszek Gasieniec, Dariusz~R. Kowalski, and Andrzej Pelc.
\newblock Collective tree exploration.
\newblock {\em Networks}, 48(3):166--177, 2006.

\bibitem{FP}
Pierre Fraigniaud and Andrzej Pelc.
\newblock Deterministic rendezvous in trees with little memory.
\newblock In {\em Distributed Computing, 22nd International Symposium, {DISC}
  2008, Arcachon, France, September 22-24, 2008. Proceedings}, pages 242--256,
  2008.

\bibitem{FP2}
Pierre Fraigniaud and Andrzej Pelc.
\newblock Delays induce an exponential memory gap for rendezvous in trees.
\newblock {\em {ACM} Transactions on Algorithms}, 9(2):17, 2013.

\bibitem{FL}
Greg~N. Frederickson and Nancy~A. Lynch.
\newblock Electing a leader in a synchronous ring.
\newblock {\em Journal of the {ACM}}, 34(1):98--115, 1987.


\bibitem{FuPe}
Emanuele~G. Fusco and Andrzej Pelc.
\newblock How much memory is needed for leader election.
\newblock {\em Distributed Computing}, 24(2):65--78, 2011.


\bibitem{gal99}
Shmuel Gal.
\newblock Rendezvous search on the line.
\newblock {\em Operations Research}, 47(6):974--976, 1999.

\bibitem{GP}
Samuel Guilbault and Andrzej Pelc.
\newblock Asynchronous rendezvous of anonymous agents in arbitrary graphs.
\newblock In {\em Principles of Distributed Systems - 15th International
  Conference, {OPODIS} 2011, Toulouse, France, December 13-16, 2011.
  Proceedings}, pages 421--434, 2011.

\bibitem{HKMMJ}
Med~Amine Haddar, Ahmed~Hadj Kacem, Yves M{\'{e}}tivier, Mohamed Mosbah, and
  Mohamed Jmaiel.
\newblock Electing a leader in the local computation model using mobile agents.
\newblock In {\em  6th {ACS/IEEE} International Conference on Computer
  Systems and Applications, {AICCSA} 2008, Doha, Qatar, March 31 - April 4,
  2008, Proceedings}, pages 473--480, 2008.


\bibitem{HS}
Daniel~S. Hirschberg and J.~B. Sinclair.
\newblock Decentralized extrema-finding in circular configurations of
  processors.
\newblock {\em Communications of the {ACM}}, 23(11):627--628, 1980.



\bibitem{israeli}
Amos Israeli and Marc Jalfon.
\newblock Token management schemes and random walks yield self-stabilizing
  mutual exclusion.
\newblock In {\em 9th Annual {ACM} Symposium on Principles
  of Distributed Computing, Quebec City, Quebec, Canada, August 22-24, 1990, Proceedings}, pages 119--131, 1990.

  
\bibitem{KKN}
Ralf Klasing, Adrian Kosowski, and Alfredo Navarra.
\newblock Taking advantage of symmetries: Gathering of many asynchronous
  oblivious robots on a ring.
\newblock {\em Theoretical Computer Science}, 411(34-36):3235--3246, 2010.

\bibitem{KMP}
Ralf Klasing, Euripides Markou, and Andrzej Pelc.
\newblock Gathering asynchronous oblivious mobile robots in a ring.
\newblock {\em Theoretical Computer Science}, 390(1):27--39, 2008.
 
  
\bibitem{KM}
Dariusz~R. Kowalski and Adam Malinowski.
\newblock How to meet in anonymous network.
\newblock {\em Theoretical Computer Science}, 399(1-2):141--156, 2008.

\bibitem{KKPM11}
Evangelos Kranakis, Danny Krizanc, and Pat Morin.
\newblock Randomized rendezvous with limited memory.
\newblock {\em {ACM} Transactions on Algorithms}, 7(3):34, 2011.

\bibitem{KKSS}
Evangelos Kranakis, Nicola Santoro, Cindy Sawchuk, and Danny Krizanc.
\newblock Mobile agent rendezvous in a ring.
\newblock In {\em 23rd International Conference on Distributed Computing
  Systems {(ICDCS} 2003), 19-22 May 2003, Providence, RI, {USA}. Proceedings}, pages
  592--599, 2003.
  
\bibitem{LL}
G{\'{e}}rard~Le Lann.
\newblock Distributed systems - towards a formal approach.
\newblock In {\em  IFIP Congress 77, Toronto, Canada, August 8-12, 1977. North-Holland, Proceedings}, pages 155--160, 1977.



\bibitem{lim96}
Wei~Shi Lim and Steve Alpern.
\newblock Minimax rendezvous on the line.
\newblock {\em SIAM Journal on Control and Optimization}, 34(5):1650--1665,
  1996.

\bibitem{Ly}
Nancy~Ann Lynch.
\newblock {\em Distributed Algorithms}.
\newblock Morgan Kaufmann, 1996.


\bibitem{Pe}
Andrzej Pelc.
\newblock Deterministic rendezvous in networks: {A} comprehensive survey.
\newblock {\em Networks}, 59(3):331--347, 2012.

\bibitem{P}
Gary~L. Peterson.
\newblock An O(n log n) unidirectional algorithm for the circular extrema
  problem.
\newblock {\em {ACM} Transactions on Programming  Languages and Systems}, 4(4):758--762, 1982.



\bibitem{Re}
Omer Reingold.
\newblock Undirected connectivity in log-space.
\newblock {\em Journal of the {ACM}}, 55(4), 2008.

\bibitem{TSZ14}
Amnon Ta{-}Shma and Uri Zwick.
\newblock Deterministic rendezvous, treasure hunts, and strongly universal
  exploration sequences.
\newblock {\em {ACM} Transactions on Algorithms}, 10(3):12, 2014.

\bibitem{YK2}
Masafumi Yamashita and Tiko Kameda.
\newblock Electing a leader when processor identity numbers are not distinct
  (extended abstract).
\newblock In {\em Distributed Algorithms, 3rd International Workshop, Nice,
  France, September 26-28, 1989, Proceedings}, pages 303--314, 1989.


\bibitem{YK3}
Masafumi Yamashita and Tsunehiko Kameda.
\newblock Computing on anonymous networks: Part i-characterizing the solvable
  cases.
\newblock {\em {IEEE} Transactions on Parallel and Distributed Systems},
  7(1):69--89, 1996.

\bibitem{YY}
Xiangdong Yu and Moti Yung.
\newblock Agent rendezvous: A dynamic symmetry-breaking problem.
\newblock In {\em Automata, Languages, and Programming - 23rd International
  Colloquium, ICALP 1996, Paderborn, Germany, July 8-12, 1996, Proceedings}, pages 610--621, 1996.
\end{thebibliography}

\end{document}
