\documentclass{eptcs}


\providecommand{\event}{WRS 2011} \providecommand{\volume}{??}
\providecommand{\anno}{20??}
\providecommand{\firstpage}{1}
\providecommand{\eid}{??}

\usepackage[utf8x]{inputenc}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsthm}
\usepackage{microtype}

\DeclareSymbolFont{symbols}{OMS}{ptm}{m}{n}

\usepackage[bf]{caption}


\usepackage{tikz}
\usetikzlibrary{arrows,decorations.pathmorphing,backgrounds,positioning,fit,shapes,shapes.gates.logic.US}


\hypersetup{
pdfborder = 0 0 0.5,
  pdfdisplaydoctitle,
pdftitle={Productivity of Non-Orthogonal Term Rewrite Systems},
  pdfauthor={Matthias Raffelsieper},
}


\clubpenalty = 10000
\widowpenalty = 10000


\begin{document}
\renewcommand{\email}[1]{\href{mailto:#1}{\footnotesize\tt #1}}

\title{Productivity of Non-Orthogonal Term Rewrite Systems}
\author{Matthias Raffelsieper
\institute{
Department of Computer Science, TU Eindhoven\\
P.O.\ Box 513, 5600~MB Eindhoven, The Netherlands\\
eMail: \email{M.Raffelsieper@tue.nl}
}
}
\def\titlerunning{Productivity of Non-Orthogonal Term Rewrite Systems}
\def\authorrunning{Matthias Raffelsieper}


\newcommand{\Nats}{\mathbb{N}}
\newcommand{\rt}{\mathrm{root}}
\newcommand{\T}{\mathcal{T}}
\newcommand{\V}{\mathcal{V}}
\newcommand{\C}{\mathcal{C}}
\newcommand{\R}{\mathcal{R}}
\newcommand{\NF}{\mathrm{NF}}
\newcommand{\gnd}{\mathrm{gnd}}
\newcommand{\Spec}{\mathcal{S}}
\newcommand{\ar}{\mathsf{ar}}
\newcommand{\supt}{\trianglerighteq}
\newcommand{\subt}{\trianglelefteq}
\newcommand{\fsym}[1]{\mathsf{#1}}
\newcommand{\zero}{\fsym{0}}
\newcommand{\one}{\fsym{1}}
\newcommand{\Pos}{\mathrm{Pos}}
\newcommand{\PosRedS}{\mathrm{Pos}^{\mathrm{red}_s}}
\newcommand{\blocked}[1][\mu]{\mathrm{blocked}_{#1}}
\newcommand{\parto}{\mathrel{\smash{\overset{\shortparallel}{\rightarrow}}}}
\newcommand{\muto}{\mathrel{\smash{\overset{\mu}{\rightarrow}}}}
\newcommand{\SNinf}{\mathsf{SN}^{\infty}}


\def\clap#1{\hbox to 0pt{\hss#1\hss}}
\def\mathllap{\mathpalette\mathllapinternal}
\def\mathrlap{\mathpalette\mathrlapinternal}
\def\mathclap{\mathpalette\mathclapinternal}
\def\mathllapinternal#1#2{\llap{}}
\def\mathrlapinternal#1#2{\rlap{}}
\def\mathclapinternal#1#2{\clap{}}


\theoremstyle{plain}
\newtheorem{theorem}{Theorem}
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{proposition}[theorem]{Proposition}

\theoremstyle{definition}
\newtheorem{definition}[theorem]{Definition}
\newtheorem{example}[theorem]{Example}



\maketitle

\begin{abstract}
Productivity is the property that finite prefixes of an infinite constructor
term can be computed using a given term rewrite system. Hitherto, productivity
has only been considered for orthogonal systems, where non-determinism is not
allowed. This paper presents techniques to also prove productivity of
non-orthogonal term rewrite systems.
For such systems, it is desired that one does not have to guess the reduction
steps to perform, instead any outermost-fair reduction should compute
an infinite constructor term in the limit.
As a main result, it is shown that for possibly non-orthogonal term rewrite
systems this kind of productivity can be concluded from context-sensitive
termination.
This result can be applied to prove stabilization of digital circuits, as
will be illustrated by means of an example.
\end{abstract}


\section{Introduction}
\label{sec:Introduction}

Productivity is the property that a given set of computation rules computes a
desired infinite object. This has been studied mostly in the setting of
\emph{streams}, the simplest infinite objects. However, as already observed
in~\cite{ZR10}, productivity is also of interest for other infinite structures,
for example infinite trees, or mixtures of finite and infinite structures.
A prominent example of the latter are lists in the programming language
\textsf{Haskell}~\cite{Haskell98}, which can be finite (by ending with a
sentinel ``\texttt{[]}'') or which can go on forever.

Existing approaches for automatically checking productivity,
e.g.,~\cite{End10,EGH08,ZR10},
are restricted to \emph{orthogonal} systems. The main reason for this
restriction is that it disallows non-determinism. A complete computer program
(i.e., a program and all possible input sequences, neglecting sources of true
randomness) always behaves deterministically, as the steps of computation are
precisely determined.
However, often a complete program is not available, too large to be studied, or
its inputs are provided by the user or they are not specified completely.
In this case, non-determinism can be used to abstract from certain parts by
describing a number of possible behaviors. In such a setting, the restriction to
orthogonal systems, which is even far stronger than only disallowing
non-determinism, should be removed.
An example of such a setting are hardware components, describing streams of
output values which are depending on the streams of input values. To analyze
such components in isolation, all possible input streams have to be considered.

This paper presents an extension of the techniques in~\cite{ZR10} to analyze
productivity of specifications that may contain non-determinism.
As in that work, the main technique to prove productivity is by analyzing
termination of a corresponding context-sensitive term rewrite system~\cite{L98}.
Here however, overlapping rules are allowed and the data TRS is only required to
be terminating, but it need not be confluent nor left-linear.
This technique can be used to prove stabilization of hardware circuits,
which have external inputs whose exact sequence of values is unknown.
Thus, stabilization should be proven for all possible input sequences, which are
therefore abstracted to be random Boolean streams, i.e., arbitrary streams
containing the data values~ and~.

\paragraph{Structure of the Paper.} In Section~\ref{sec:Specifications} we
introduce \emph{proper specifications}, which are the forms of rewrite systems
studied in this paper. After that, in Section~\ref{sec:Productivity}, the
different notions of productivity are discussed. For non-orthogonal
specifications as studied in this paper, there exist both \emph{weak} and
\emph{strong} productivity. We will motivate that strong productivity is the
notion that we are interested in, as it does guarantee a constructor term to
be reached by any outermost-fair reduction.
The theoretical basis is laid in Section~\ref{sec:Criteria},
proving our desired result that termination of a corresponding context-sensitive
TRS implies strong productivity of a proper specification.
Section~\ref{sec:ApplHW} then applies this theory to an example hardware
circuit, checking that for a given circuit the output values always stabilize,
regardless of the sequence of input values.
Finally, Section~\ref{sec:Conclusions} concludes the paper.

\section{Specifications}
\label{sec:Specifications}

A \emph{specification} gives the symbols and rules that shall be used to
compute an intended infinite object. This section gives a brief introduction to
term rewriting, mainly aimed at fixing notation. For an in-depth description of
term rewriting, see for example~\cite{BN98, Terese03}.
All symbols are assumed to have one of two possible \emph{sorts}.
The first sort~ is for \emph{data}. Terms of this sort represent the
elements in an infinite structure, but which are not infinite terms by
themselves. An example for data are the Booleans  and
 (which are also written~ and~),
or the natural numbers represented in Peano form by the two constructors 
and . The set of all terms of sort~ is denoted
, where  is a set of function symbols all having
types of the form  and where  is a set of \emph{variables}
all having sort~.
The second sort is the sort~ for \emph{structure}. Terms of this sort are to
represent the intended structure containing the data and therefore are allowed
to be infinite. The set of all well-typed structure terms is denoted
, where
 is disjoint from  and contains function symbols having
types of the form  and where
 for a set  of variables all having sort~, which
is disjoint from .
We define the set of all well-typed terms as
 and denote
the set of all \emph{ground terms}, i.e., terms not containing any variables,
by .
A term  of sort 
is either a variable, i.e., ,
or 
with  of type 
(where  if ),
,
and .
In the latter case, i.e., when , we
define the \emph{root} of the term~ as .

A \emph{Term Rewrite System (TRS)} over a signature  is a collection of
rules  such that  and every
variable contained in~ is also contained in~. As usual, we write
 instead of .
A term  \emph{rewrites} to a term 
with the rule , denoted 
at \emph{position} , if a substitution~
exists such that  and .
A position is as usual a sequence of natural numbers that identifies a number of
argument positions taken to reach a certain subterm. The notation 
represents the term  in which the subterm at position~, that is denoted
by , has been replaced by the term . This is the term~ in
which all variables have been replaced according to the substitution ,
which is a map from variables to terms.
It is allowed to only indicate the term rewrite system  instead of
the specific rule  or to leave out the subscripts in case they
are irrelevant or clear from the context.
The set of all \emph{normal forms} of a TRS  over a
signature  is denoted  and is defined as .
The set of \emph{ground normal forms}  additionally requires
that all contained terms are ground terms, i.e.,
.


We still have to impose some restrictions on specifications to make our
approach work. These restrictions are given below in the definition of
\emph{proper} specifications, which are similar to those of~\cite{ZR10}.

\begin{definition}
\label{def:Spec}
A \emph{proper specification} is a tuple
,
where  is the signature of data symbols, each of type 
(then the data arity of such a symbol  is defined to be ),
 is the signature of structure symbols~,
which have types of the shape 
(and data arity , structure arity ),
 is a set of \emph{constructors},
 is a terminating TRS over the signature , and
 is a TRS over the signature ,
containing rules 
that satisfy the following properties:
\begin{itemize}
\item
 with , ,

\item
 is a well-sorted linear term,

\item
 is a well-sorted term of sort~, and

\item
for all  and for all  such that  is not
a variable and , it holds that
 for all 
(i.e., no structure symbol is below a constructor).
\end{itemize}

Furthermore,  is required to be \emph{exhaustive}, meaning that for every
 with , , ground normal
forms , and terms
 such that for every
,
 with
 for  and
, there exists at least one rule  such that
 matches the term .

A proper specification  is called \emph{orthogonal}, if 
is orthogonal, otherwise it is called \emph{non-orthogonal}.
\end{definition}

The above definition coincides with the definition of proper specifications
given in~\cite{ZR10} for orthogonal proper specifications.\footnote{To see this, one should observe that a defined symbol cannot occur on a non-root
position of a left-hand side. This holds since otherwise the innermost such
symbol would have variables and constructors as structure arguments and data
arguments that do not unify with any of the data rules (due to orthogonality),
which therefore are normal forms and can be instantiated to ground normal forms.
Thus, exhaustiveness would require a left-hand side to match this term when
instantiating all structure variables with some terms having a constructor root,
which would give a contradiction to non-overlappingness.}
We will illustrate the restrictions in the above definition later in
Section~\ref{sec:Criteria}.
In the following, all examples except for Example~\ref{ex:CexpLeftLin}
will be using the domain of Boolean streams,
where  and  with
 and .
In these examples, only a data TRS~ and a structure TRS~ are given
from which the remaining symbols in~ and~ and their arities
can be derived.
If the data TRS~ is not provided it is assumed to be empty.


\section{Productivity}
\label{sec:Productivity}

For orthogonal proper specifications, productivity is the property that
every ground term  of sort~ can, in the limit, be rewritten to a possibly
infinite term consisting only of constructors. This is equivalent to stating
that for every prefix depth , the term  can be rewritten to
another term  having only constructor symbols on positions of depth  or
less.

\begin{definition}
\label{def:OrthoProd}
An orthogonal proper specification  is
\emph{productive},
iff for every ground term  of sort~ and every ,
there is a reduction  such that every
symbol of sort~ in  on depth less or equal to~ is a constructor.
\end{definition}

Productivity of an orthogonal proper specification is equivalent to the
following property, as was shown in~\cite{ZR10}.

\begin{proposition}
\label{prop:OrthoProd}
An orthogonal proper specification  is 
\emph{productive},
iff for every ground term  of sort~ there is a reduction
 such that .
\end{proposition}


It was already observed in~\cite{EGH09,End10} that productivity of orthogonal
specifications is equivalent to the existence of an \emph{outermost-fair}
reduction computing a constructor prefix for any given depth. Below, we give a
general definition of outermost-fair reductions, as they will
also be used in the non-orthogonal setting.

\pagebreak[2]
\begin{definition}
\label{def:OutFair}
~
\begin{itemize}
\item
A \emph{redex} is a subterm  of a term  at position 
such that a rule  and a substitution  exist with
.
The redex  is said to be \emph{matched} by the rule .

\item
A redex is called \emph{outermost} iff it is not a strict subterm of another
redex.

\item
A redex  is said to \emph{survive} a reduction step
 if , or if  and
 for some substitution 
(i.e., the same rule can still be applied at ).


\item
A rewrite sequence (reduction) is called \emph{outermost-fair}, iff there is no
outermost redex that survives as an outermost redex infinitely long.

\item
A rewrite sequence (reduction) is called \emph{maximal}, iff it is infinite or
ends in a \emph{normal form} (a term that cannot be rewritten further).
\end{itemize}
\end{definition}


For non-orthogonal proper specifications, requiring just the existence of a
reduction to a normal form (or to a constructor prefix of arbitrary depth)
does not guarantee the computation to reach it, due to the possible
non-deterministic choices. This can be observed for the term 
in the following example.

\begin{example}
\label{ex:NonOrthoMaybeRnd}
Consider a proper specification with the TRS  consisting of the following
rules:


This specification is not orthogonal, since the rules for  as well
as those for  overlap.
We do not want to call this specification productive, since it admits the
infinite outermost-fair reduction 
that never produces any constructors. However, there exists an infinite
reduction producing infinitely many constructors starting in the term
, namely
.
When only considering the rules for  then we want to call
the resulting specification productive, since no matter what rule of
 we choose, an element of the stream is created.
\end{example}

Requiring just the existence of a constructor normal form is called
\emph{weak productivity} in~\cite{EGH09,End10}. We already stated above that
this is not the notion of productivity we are interested in. The one we are
interested in is \emph{strong productivity}, which is also defined
in~\cite{EGH09,End10}, since it requires all reductions that make progress on
outermost positions to reach constructor normal forms.

\begin{definition}
\label{def:StrongProd}
A proper specification  is called \emph{strongly productive} iff for
every ground term  of sort~ all maximal outermost-fair rewrite sequences
starting in  end in (i.e., have as limit for infinite sequences)
a constructor normal form.
\end{definition}

It was observed in~\cite{EGH09,End10} that weak and strong productivity coincide
for orthogonal (proper) specifications.
However, for non-orthogonal (proper) specifications this is not the case
anymore.
The rules for  in Example~\ref{ex:NonOrthoMaybeRnd} are not
strongly productive, since they allow the infinite outermost-fair reduction
. However, these rules are weakly
productive, since any ground term can be rewritten to an infinite stream
containing only ~elements after some finite prefix.
For example, the ground term  can be rewritten to the
infinite stream .

An example of a non-orthogonal proper specification that is both strongly and
weakly productive are the rules for  in
Example~\ref{ex:NonOrthoMaybeRnd}, which always produce an infinite stream.
In this case, the restriction to outermost-fair reductions is not needed.
However, if we add the rule  and replace the
rule  by the rule
, then
the infinite reduction
 exists. This
reduction is not outermost-fair since the outermost redex 
survives infinitely often.
When restricting to outermost-fair reductions, then indeed an infinite stream of
Boolean values is obtained for every such reduction, so this is a strongly
productive proper specification, too.
Note that strong productivity implies weak productivity, so the example is also
weakly productive.



\section{Criteria for Strong Productivity}
\label{sec:Criteria}

For orthogonal proper specifications, it is sufficient to just consider
reductions that create a constructor at the top, as stated in
Proposition~\ref{prop:OrthoProd}. We will show next that this is also the case
for non-orthogonal proper specifications. However, in contrast to~\cite{ZR10},
here we have to consider all maximal outermost-fair reductions, instead of just
requiring the existence of such a reduction.

\begin{proposition}
\label{prop:NonOrthoProd}
A proper specification  is
\emph{strongly productive} iff for every maximal outermost-fair reduction

with  being of sort~ there exists  such that
.
\end{proposition}

\begin{proof}
The ``only if''-direction is trivial. For the ``if''-direction, we show
inductively that for every depth  and every maximal outermost-fair
reduction  there exists an index
 such that for all positions  of sort~ with
, .

For , the index  can be set to , thus here the claim trivially
holds.
Otherwise, we get that an index  exists such that
. Let  with
.
Because  is a constructor, we know that  for all .
Define  for  (i.e.,
the positions in the maximal outermost-fair reduction that are occurring in
structure argument~).
Then, for  and  the
reduction  is also a
maximal outermost-fair reduction, otherwise an infinitely long surviving
outermost redex would also be an infinitely long surviving outermost redex of
the reduction~. By the induction hypothesis for  we get
that indices  for  exist such that
 for all positions  with
. Since all these reductions were taken from the original reduction,
we define ,
where  denotes the number of reductions performed in the
data arguments of the constructor~ such that  for the
last~.
This shows that the initial reduction~ has the form
,
where  for every . Since there are only
constructors in  for depths , these constructors are
still present in . This proves the proposition, since  and
thus for all positions  of sort~ with  we have
.
\end{proof}


This characterization of strong productivity will be used in the remainder of
the paper. Note that it is similar to the requirements for infinitary strong
normalization  observed in~\cite{Z08}, where it is found that for
left-linear and finite term rewrite systems,  holds if and only if every
infinite reduction only contains a finite number of root steps. Thus, it could
seem possible to define strong productivity of proper specifications by
requiring that every reduction starting in a finite ground term is infinitary
strongly normalizing, i.e.,  holds for the relation
.
However, this is not the case, as the following example shows.

\begin{example}
\label{ex:CexpSNinf}
Consider the proper specification containing the following TRS :


This TRS has the property , intuitively because either the
symbol~ remains at the root position and can never be rewritten again
(in case the first rule is applied), or the constructor~ is created at the
root. Formally, this can for example be proven by the technique presented
in~\cite{Z08}: Let ,
where  is the signature of
the specification.
Then we choose the finite weakly monotone  algebra
, where , ,
,
, , ,
, , and  for
 and~ and~ are the natural comparison operators on
the numbers .
It is easy to check that this algebra is indeed weakly monotone (i.e., that
~is well-founded, , and
for every , the operation  is monotone with respect
to~). Additionally, the requirements of the combination
of~\cite[Theorem~5 and Theorem~6]{Z08} are satisfied, i.e.,  is
finite, ~is transitive,  implies  or ,
 for all , and
 and 
for all  and all substitutions , where
.
This proves  of , which especially entails  of the
relation .

However, the above proper specification is not strongly productive, since the
infinite outermost-fair reduction
,
continued by repeatedly reducing the symbol ,
never produces any constructors.
\end{example}

The above example shows that even though we require exhaustiveness of proper
specifications, this exhaustiveness only refers to constructor terms, i.e., the
objects we are interested in, and not to arbitrary terms. A similar observation,
namely that top termination is not equivalent to productivity, was already made
in~\cite{ZR09}.

A first technique to prove strong productivity of proper specifications is given
next. It is a simple syntactic check that determines whether every right-hand
side of sort~ starts with a constructor. For orthogonal proper
specifications, this was already observed in~\cite{ZR10}. It has to be proven
again since here we consider strong productivity, which requires all possible
outermost-fair reductions to reach a constructor normal form, instead of weak
productivity as in~\cite{ZR10}, for which only a single reduction to a
constructor normal form needs to be constructed.

\begin{theorem}
\label{thm:SyntacticCheck}
Let  be a proper specification.
If for all rules  we have , then  is
strongly productive.
\end{theorem}

\begin{proof}
Let  be a maximal outermost-fair
reduction and let .
If  we are done, so we assume  and
perform structural induction on  to prove that  for some
.

From the induction hypothesis we get that for every  and every
maximal outermost-fair reduction  there
exists an index  such that .

Assume that for all , .
As in the proof of Proposition~\ref{prop:NonOrthoProd}, we therefore again
obtain maximal outermost-fair reductions , thus we get indices
 such that , as explained above. This
makes our reduction  have the shape
 for some ,
where  (since the reduction  is
maximal outermost-fair and  is terminating) and
, thus also . Because  is
exhaustive, we get that  contains a redex at the root position~,
which of course is outermost. This gives rise to a contradiction to  being
outermost fair, as this outermost redex survives infinitely often, because
 for all . Therefore,  for some
 and the reduction has the shape , where the last step is with respect to some rule
.
By the assumption on the shape of the rules in , we have ,
hence also , which proves productivity according to
Proposition~\ref{prop:NonOrthoProd}.
\end{proof}

This technique is sufficient to prove strong productivity of the proper
specification consisting of the two rules for  in
Example~\ref{ex:NonOrthoMaybeRnd}, since both have right-hand sides with the
constructor~ at the root. However, it is easy to create examples which are
strongly productive, but do not satisfy the syntactic requirements of
Theorem~\ref{thm:SyntacticCheck}.

\begin{example}
\label{ex:NonSyntax}
Consider the proper specification with the following TRS :


The constant  produces non-deterministically a stream that
starts with one, two, or three zeroes followed by an infinite stream of ones.
Function~ takes a binary stream as argument and filters out all
occurrences of zeroes. Thus, productivity of this example proves that only a
finite number of zeroes can be produced. This however cannot be proven with the
technique of Theorem~\ref{thm:SyntacticCheck}, since the right-hand side of the
rule  does not start with the
constructor~.
\end{example}


Another technique presented in~\cite{ZR10} to show productivity of orthogonal
proper specifications is based on context-sensitive termination~\cite{L98}.
The idea is to disallow rewriting in structure arguments of constructors, thus
context-sensitive termination implies that for every ground term of sort~,
a term starting with a constructor can be reached (due to the exhaustiveness
requirement). As was observed by Endrullis and Hendriks recently in~\cite{EH11},
this set of blocked positions can be enlarged, making the approach even
stronger.

Below,
the technique for proving productivity by showing termination of a corresponding
context-sensitive TRS is extended
to also be applicable in the case of our more general proper specifications.
This version already includes an adaption of the improvement mentioned above.

\begin{definition}
\label{def:Mu}
Let  be a proper specification.
The replacement map 
is defined as follows:
\footnote{
Note that in~\cite{EH11}, Endrullis and Hendriks consider orthogonal TRSs and
also block arguments of symbols in  which only contain variables.
This however is problematic when allowing data rules that are not left-linear.
Example:

Here, the term  can
only be -rewritten to the term  (which then in turn has
to be rewritten to )
if defining , since the subterm
 can never be rewritten to . However, the
example is not strongly productive, as reducing in this way gives rise to an
infinite outermost-fair reduction
.
Blocking arguments of data symbols can only be done when  is
left-linear.
}
\begin{itemize}
\item
, if 

\item
 is a variable
        for all 
        and all non-variable subterms  of  with ,\footnote{
        The requirement of  not being a variable ensures that
         is defined.
    }
    otherwise
\end{itemize}
\end{definition}

In the remainder, we leave out the subscript  if the specification is
clear from the context. The replacement map  is used to define
the set of \emph{allowed} positions of a non-variable term  as

and the set of \emph{blocked} positions of  as
.
Context-sensitive rewriting~\cite{L98} then
is the restriction of the rewrite relation to those redexes on positions
from . Formally, we have  iff
 and  and we say a TRS  is
\emph{-terminating} iff no infinite -chain exists.

The replacement map  is \emph{canonical}~\cite{L02} for the
left-linear TRS , guaranteeing through the second condition of the above
Definition~\ref{def:Mu} that non-variable positions of left-hand
sides are allowed.
In that definition, the replacement map  is extended to the
possibly non-left-linear TRS  by allowing all arguments of
symbols from~.


Our main result of this paper is that also for possibly non-orthogonal proper
specifications, -termination implies productivity.

\begin{theorem}
\label{thm:CStermination}
A proper specification  is
strongly productive, if  is -terminating.
\end{theorem}

Before proving the above theorem, we will show first that it subsumes
Theorem~\ref{thm:SyntacticCheck}. Intuitively, this holds because structure
arguments of constructors are blocked, and if every right-hand side of 
starts with a constructor then the number of allowed redexes of sort~ in a
term steadily decreases.

\begin{proposition}
\label{prop:CSimpliesSyn}
Let  be a proper specification.
If for all rules  we have , then
 is -terminating.
\end{proposition}

\begin{proof}
Let  be well-typed.
If  has sort~, then all subterms must also be of sort~, as symbols from
 only have arguments of that sort. Hence, rewriting can only be done
with rules from , which is assumed to be terminating.

Otherwise, let  be of sort~ and assume that~ starts an infinite
-reduction
.
We define
 is a redex of sort~
for any term .
It will be proven that in every step 
of the infinite reduction,

and that for steps with , we even have
.
To this end, case analysis of the rule  is performed.
If , then  and
 for some substitution .
Because ,

since all symbols in  have arguments of sort~.
Thus, .
In the second case, . Let
 and
 for some substitution .
Then, 
for any variable  of sort~.
For  we observe that

for any variable  of sort~.
Here, it holds that
,
therefore .
Furthermore, ,
since  by assumption, hence
 and because symbols from
 only have arguments of sort~.
Thus, .

Combining these observations, we therefore only have finitely many reductions
with rules from  in the infinite reduction. Thus, an infinite tail of
steps with rules from  exists. This however contradicts the assumption
that  is terminating, hence no infinite -reduction can exist which
proves -termination of .
\end{proof}

Hence, we could restrict ourselves to analyzing context-sensitive termination
only. However, the syntactic check of Theorem~\ref{thm:SyntacticCheck} can be
done very fast and should therefore be the first method to try.

In order to prove Theorem~\ref{thm:CStermination} we will show that a maximal
outermost-fair reduction that never reaches a constructor entails an infinite
-reduction.
For this purpose we need the following lemma,
which shows that in every ground term not starting with a constructor there
exists a redex that is not blocked by the replacement map~.

\begin{lemma}
\label{lem:ExistRedex}
Let  be a proper specification.
For all ground terms  of sort  with  there exists a
position  such that .
\end{lemma}

\begin{proof}
Let . We perform structural induction
on .
If  for some  with , then
 and  since arguments of data symbols are
never blocked.
Thus, we assume in the remainder that
 for all  with .
If  for all , , then
 by the exhaustiveness requirement (and because all arguments
,  with  are being matched by pairwise different
variables, due to left-linearity).
Otherwise, there exists ,  such that
. By the induction hypothesis we get that 
for some . Therefore, we also have
 and .
\end{proof}


A second lemma that is required for the proof of Theorem~\ref{thm:CStermination}
states that a specialized version of the
Parallel Moves Lemma~\cite[Lemma~6.4.4]{BN98}
holds for our restricted format of term rewrite systems.
It allows us to swap the order of reductions blocked by~ with reductions
not blocked by~.
To formulate the lemma, we need the notion of a parallel reduction step
, which is defined for a set
 such that for every pair
 we have 
and a term
 as
 for rules
 and substitutions ,
.

\begin{lemma}
\label{lem:SpecialPML}
Let  be a proper specification.
For all ground terms  and positions ,
 with ,
a term  and a set  exist such that
.
\end{lemma}

\begin{proof}
Let .
Then  for some rules
 and
substitutions .
W.l.o.g., let  be such that
 for all 
and  for all .
Since  and , it must
hold that  for all .
Therefore, the term  must have the shape
.

If , then it must hold that , since arguments of data
symbols are never blocked. Hence, the lemma trivially holds in this case, as all
reductions are on independent positions.

Otherwise, .
Because the positions  for  are blocked, it must be the case
that they are either below a variable in all rules containing a certain
symbol~ (hence, they are also below a variable in~), or they are
below a structure argument of a constructor . By requirement of
specifications, if a constructor is present on a left-hand side of a rule, all
its structure arguments must be variables. Thus, we conclude that all positions
, and thereby all terms , are below some variable of
 in . Additionally, the left-hand side  is required to be
linear, therefore there exist pairwise different variables ,
contexts , and a substitution  being like 
except that  for  such that:


We conclude that , as all reduction steps in
 are either below or independent of . Thus:


In the second reduction step, the positions of the terms 
in  constitute the set .
\end{proof}

We are now able to prove our main theorem, showing that context-sensitive
termination implies productivity of the considered proper specification.


\begin{proof}[Proof of Theorem~\ref{thm:CStermination}]
Assume  is not strongly productive.
Then, a maximal outermost-fair reduction sequence
 exists where for all
, .

This reduction sequence is infinite, since otherwise it would end in a term
 for some  with . Then however, according
to Lemma~\ref{lem:ExistRedex}, the term  would contain a redex, giving a
contradiction to the sequence being maximal.

The sequence might however perform reductions that are below a variable argument
of a constructor or below a variable in all left-hand sides of a defined symbol.
These reduction steps are not allowed when considering context-sensitive
rewriting with respect to~. Such reductions however can be reordered.
First, we observe that there is always a redex which is not blocked, due to 
Lemma~\ref{lem:ExistRedex}, thus there is also an outermost such one. Because
the reduction is outermost-fair, and because reductions below a variable cannot
change the matching of a rule, as shown in Lemma~\ref{lem:SpecialPML}, such
redexes must be contracted an infinite number of times in the infinite reduction
sequence . Thus, we can reorder the reduction steps in :
If there is a (parallel) reduction below a variable before performing a step
that is allowed by~, then we swap these two steps using
Lemma~\ref{lem:SpecialPML}. Repeating this, we get an infinite reduction
sequence  consisting of steps which are not blocked by~. Thus, this
is an infinite -reduction sequence, showing that  is not
-terminating, which proves the theorem.
\end{proof}

The technique of Theorem~\ref{thm:CStermination}, i.e., proving
-termination of the corresponding context-sensitive TRS, is able to prove
strong productivity of Example~\ref{ex:NonSyntax}. By Definition~\ref{def:Mu},
the corresponding replacement map~ is defined as
 and
, i.e., rewriting is allowed on all
positions except those that are inside a second argument of the
constructor~.
Context-sensitive termination of the TRS together with the above replacement
map~ can for example be shown by the tool AProVE~\cite{AProVE06}.
Thus, productivity of that example has been shown according to
Theorem~\ref{thm:CStermination}.
Also, strong productivity of the proper specification consisting of the rules
,
, and 
can be proven using Theorem~\ref{thm:CStermination} and the tool
AProVE~\cite{AProVE06}, where

and 
according to Definition~\ref{def:Mu}.
Note that for this example, one could also have used ,
i.e., here the removal of argument positions in the second item of
Definition~\ref{def:Mu} is irrelevant.

This is not the case in the next example, showing that this improvement,
which was inspired by~\cite{EH11} and blocks more argument positions,
allows to prove productivity of specifications where this would otherwise not be
possible.

\begin{example}
\label{ex:BlockingMoreArgs}
Consider the following proper specification, given by the TRS~:


When defining  and
 by the first case of Definition~\ref{def:Mu}, and
defining  (i.e., not removing any argument
positions, as was done in the orthogonal case in~\cite{ZR10}),
then an infinite -reduction exists:


\noindent
This reduction can be continued in the above style by reducing the underlined
redex further, which will always create the term~ on an allowed
position of the form . However, such positions are not required for any
of the -rules to be applicable; for both rules it holds that all
subterms of left-hand sides that start with the symbol~,
which are the terms , , and
,
have a variable as second argument. Thus, according to Definition~\ref{def:Mu},
the replacement map~ can be defined to be like , except that
.
With this improved replacement map, -termination of the above TRS can for
example be proven by the tool AProVE~\cite{AProVE06},
which implies productivity by Theorem~\ref{thm:CStermination}.
\end{example}

Checking productivity in this way, i.e., by checking context-sensitive
termination, can only prove productivity but not disprove it. This is
illustrated in the next example.

\begin{example}
\label{ex:IncompleteCSterm}
Consider the proper specification with the following rules in :


Starting in the term , we observe that an infinite -reduction
starting with  exists,
which can be continued by reducing the underlined redex repeatedly, since
.
Thus, the example is not -terminating. However, the specification is
productive, as can be shown by case analysis based on the root symbol of
some arbitrary ground term . In case , then nothing has to be
done, according to Proposition~\ref{prop:NonOrthoProd}.
Otherwise, if , then any maximal outermost-fair reduction
must start with , thus we can reduce our
analysis to the final case, where . In this last case,
. Due to the rules for the symbol , we have to
perform a further case analysis based on the root symbol of .
If , i.e.,  for some terms  and ,
then this constructor cannot be reduced further.
Also,  is a redex, due to the second rule.
Hence, in any maximal outermost-fair reduction sequence this redex must
eventually be reduced using the second rule, which results in a term with the
constructor~ at the root.
For  we again must reduce
.
Finally, in case , we have two possibilities. The first
one occurs when the term  is eventually reduced at the root. Since
, this has to happen with either of the -rules,
creating a constructor~ which, as we already observed, must eventually result
in the term  also being reduced to a term with the constructor~ at the
root. Otherwise, in the second possible scenario, the term  is never reduced
at the root. Then however, an outermost redex of the shape
 exists in all terms that  can be rewritten to in
this way, thus it has to be reduced eventually with the third rule. This again
creates a term with constructor~ at the root. Combining all these
observations, we see that in every maximal outermost-fair reduction there exists
a term with the constructor~ as root symbol, which proves productivity due to
Proposition~\ref{prop:NonOrthoProd}.
\end{example}


In the remainder of this section we want to illustrate the requirements
of proper specifications in Definition~\ref{def:Spec}, namely that the TRS
 should be left-linear and that structure arguments of constructors in
left-hand sides must not be structure symbols, i.e., they must be variables.
We begin with an example specification that is not left-linear and not
productive, but -terminating.

\begin{example}
\label{ex:CexpLeftLin}
We consider the non-proper specification
 with ,
,
and the following rules in  which also imply the arities of the symbols:


The example specification is not productive, as it admits the infinite
outermost-fair reduction sequence
.
However, the TRS is -terminating, as shown by the tool
AProVE~\cite{AProVE06}, where  and
. This is the case
because rewriting below the constructor~ is not allowed, thus the
second step of the above reduction sequence is blocked.
The reason why Theorem~\ref{thm:CStermination} fails is the
reordering of reductions, since in this example a reduction of the form

(here: )
does not imply that 
(in the example, ),
i.e., Lemma~\ref{lem:SpecialPML} does not hold.
\end{example}


The next example illustrates why non-variable structure arguments of
constructors are not allowed in left-hand sides.

\begin{example}
\label{ex:CexpConsNonVarArg}
Let  contain the following rules:


Here, we have non-productivity of the corresponding non-proper specification due
to the infinite outermost-fair reduction sequence
,
however the second step is not allowed when performing context-sensitive
rewriting, since .
Using the tool AProVE~\cite{AProVE06}, context-sensitive termination of the
above TRS together with the replacement map~ can be shown.


We can however unfold this example (cf.~\cite{EH11,Z09}),
which makes the resulting specification
proper, by introducing a fresh symbol  and replacing the two
rules for  with the following three rules:


Then, in the corresponding context-sensitive TRS, we have
, , and
.
This context-sensitive TRS is not -terminating, since it admits the
infinite reduction
.
\end{example}

It should be noted that the restriction for left-hand sides to only contain
variables in constructor arguments was already made in~\cite{ZR10}. This is the
case because matching constructors nested within constructors would otherwise
invalidate the approach of disallowing rewriting inside structure arguments of
constructors.



\section{Application to Hardware Circuits}
\label{sec:ApplHW}

Proving productivity can be used to verify stabilization of hardware circuits.
In such a circuit, the inputs can be seen as an infinite stream of zeroes and
ones, which in general can occur in any arbitrary sequence. Furthermore, a
circuit contains a number of internal signals, which also carry different
Boolean values over time.

To store a value over time, feedback loops are used. In such a loop, a value
that is computed from some logic function is also used as an input to that
function. Thus, it is desired that such values stabilize, instead of oscillating
infinitely.

To check this, productivity analysis can be used. We will illustrate this by
means of an example, that will be considered throughout the rest of this
section.

\begin{figure}
\begin{center}
\begin{tikzpicture}[
]
\node[trapezium, draw,
    trapezium left angle=70, trapezium right angle=70,
    rotate=-90,
    inner sep=.5cm
    ]
            (muxi) at (-2,0) {};
\node[circle,draw,right=-.4pt
    ]
        (minvi) at (muxi.top side) {};

\node[signal,draw,anchor=east]
        (d) at (muxi.south west) {\texttt{D}};
\node[signal,draw,anchor=east]
        (si) at (muxi.south east) {\texttt{SI}};
\node[signal,draw]
        (se) at (-3,-1.5) {\texttt{SE}};
\node[signal,draw]
        (ck) at (-3,-2.5) {\texttt{CK}};

\node[shape=not gate US,draw,
    logic gate inverted radius=.15cm
    ]
        (ckn) at (-1.5,-2.5) {};

\node[shape=not gate US,draw,
    logic gate inverted radius=.15cm
    ]
        (cknn) at (1,-2.5) {};

\draw[] (se.east) -| (muxi.east);
\draw[] (ck.east) -- (ckn.input);

\draw[] (ckn.output) -- (cknn.input);

\node[trapezium, draw, 
    trapezium left angle=70, trapezium right angle=70,
    rotate=-90,
    inner sep=.5cm
    ]
            (mux1) at (0,0) {};
\node[circle,draw,right=-.4pt
    ]
        (minv1) at (mux1.top side) {};

\node[shape=not gate US,draw,rotate=180,
    logic gate inverted radius=.15cm
    ]
        (inv1) at (0.25,2) {};


\draw[] (minvi.east) -- (-1,0) |- (mux1.south east)
        node[below,pos=0.5] {\texttt{next}};
\draw[] (ckn.output) -| (mux1.east);

\draw[] (minv1.east) -- (1,0) |- (inv1.input);
\draw[] (inv1.output) -- (-1,2) |- (mux1.south west);


\node[trapezium, draw, 
    trapezium left angle=70, trapezium right angle=70,
    rotate=-90,
    inner sep=.5cm
    ]
            (mux2) at (2.5,0) {};
\node[circle,draw,right=-.4pt
    ]
        (minv2) at (mux2.top side) {};

\node[shape=not gate US,draw,rotate=180,
    logic gate inverted radius=.15cm
    ]
        (inv2) at (2.75,2) {};

\draw[] (minv1.east) -- (1.5,0) |- (mux2.south east)
        node[below,pos=0.5] {\texttt{n1}};
\draw[] (cknn.output) -| (mux2.east);

\draw[] (minv2.east) -- (3.5,0) |- (inv2.input)
        node[right,pos=0.25] {\texttt{n2}};
\draw[] (inv2.output) -- (1.5,2) |- (mux2.south west);


\node[shape=not gate US,draw,
    logic gate inverted radius=.15cm
    ]
        (invq) at (4,0) {};

\node[shape=not gate US,draw,
    logic gate inverted radius=.15cm
    ]
        (invqn) at (5.5,2) {};

\draw[] (minv2.east) -- (invq.input);
\draw[] (invq.output) -- (5,0) |- (invqn.input);


\node[signal,draw] (q) at (7,0) {\texttt{Q}};
\node[signal,draw] (qn) at (7,2) {\texttt{QN}};

\draw[] (invq.output) -- (q.west);
\draw[] (invqn.output) -- (qn.west);


\end{tikzpicture}
\end{center}
\caption{Example hardware circuit}
\label{fig:Circuit}
\end{figure}

Consider the circuit shown in Figure~\ref{fig:Circuit},
which was constructed from the transistor netlist of the cell \texttt{SDFF\_X1}
in the Nangate Open Cell Library~\cite{OpenCellLibrary08_10_SP1}
and which implements a scanable D~flip-flop.
This circuit first selects, based on the value of the input
\texttt{SE} (scan enable), either the negation of the data input \texttt{D}
(in case \texttt{SE}=0)
or the negation of the scan data input \texttt{SI} (in case \texttt{SE}=1).
This value, called \texttt{next} in Figure~\ref{fig:Circuit}, is then fed into
another multiplexer (mux), for which a feedback loop exists.
This mux is controlled by the negation of the clock input \texttt{CK}. If the
clock is~0 then the negated value of \texttt{next} is forwarded to the output
\texttt{n1}, otherwise the stored value of \texttt{n1} is kept.
Similarly, \texttt{n2} implements such a latch structure, however this time the
latch forwards the negation of the \texttt{n1} input in case \texttt{CK} is 1,
and it keeps its value when \texttt{CK} is 0.
The outputs \texttt{Q} and \texttt{QN} are computed from this stored value
\texttt{n2}.

Note that a lot of the negations are only contained to refresh the signals,
otherwise a high voltage value might decay and not be detected properly anymore.

From the example circuit, we create a proper specification, where the data
symbols consist of the two Boolean values~ and~ and the symbol
 used for negating:


The structures we are interested in are infinite streams containing Boolean
values, thus the set of constructors is . The structure
TRS  is shown in Figure~\ref{fig:HWrules}.

\begin{figure}[t]
\centering

\caption{Structure TRS  for the circuit shown in Figure~\ref{fig:Circuit}}
\label{fig:HWrules}
\end{figure}

It should be remarked that in the shown rules, some simplifications regarding
the clock input \texttt{CK} have been made. The inverters for the clock have
been removed, and the two muxes that output the signals \texttt{n1} and
\texttt{n2} are provided with decoupled clock values.

The defined function symbols , , ,
, and  reflect the wires and output signals with the
corresponding name in Figure~\ref{fig:Circuit}.
The constant~ is added to abstract the values of the inputs. It
provides a random stream of Boolean values, thus it is able to represent any
sequence of input values provided to the circuit.
The rules of the symbol  implement the mux selecting either the
next data input value  in case the next scan enable input value~ is~,
or the next scan input value  in case~ is~.

The output of  is also computed by a mux, however, here the previous
output value has to be considered due to the feedback loop. We break the cycle
by introducing a new parameter~ that stores the previously output
value.
Then, the next value of the stream at  is computed
from the next value of the clock~, the input stream
 coming from the previously described
multiplexer, and from the previous output value~.
If the clock~ is~, then the latch simply outputs the negated value of
 and continues on the remaining streams, setting the
parameter~ to this value to remember it.
Otherwise, if~ is~, then the feedback loop is active and has to be
evaluated until it stabilizes. This is done by the function .
It has as arguments the remaining input stream of the clock, the remaining input
stream of the scan multiplexer, and the previous output value and the newly
computed output value. If both of these values are the same, then the value of
the wire  has stabilized and hence can be output. The tail of the
output stream is computed by again calling the function  with the
remaining streams for the clock and the scan multiplexer.
Otherwise, the new output value (the last argument of ) differs from
the old output value (the penultimate argument of ). In that case,
the new output value becomes the old output value and the new output is
recomputed. This is repeated until eventually the output value stabilizes, or it
will oscillate and never produce a stable output.

Similar to the function~, the function~ computes stable
values for the corresponding wire in Figure~\ref{fig:Circuit}. Again, the
parameter~ is added to store a previously output value, and the
auxiliary function~ is used to compute a stable value for the
feedback loop. The only difference to the function~ is that the cases
of the clock are inverted, due to the additional inverter in
Figure~\ref{fig:Circuit} that feeds the select input of the multiplexer that
computes~.
Finally, the functions~ and~ implement the two inverters
that feed the corresponding output signals in Figure~\ref{fig:Circuit}.

The above specification is productive, since the TRS  can be
proven context-sensitive terminating, for example by the tool
AProVE~\cite{AProVE06}.
Hence, according to Theorem~\ref{thm:CStermination}, the specification is
productive, meaning that every ground term of sort~ rewrites to a constructor
term. This especially holds for the ground terms

and
,
where

and the variables  and  are instantiated with all
possible combinations of~ and~. Thus, the circuit produces an
infinite stream of stable output values, regardless of its initial state and
input streams, and does not oscillate infinitely long. This illustrates that
productivity analysis can be used to prove stabilization of digital circuits
with arbitrary input sequences, when encoding them as non-orthogonal
proper specifications.


\section{Conclusions and Future Work}
\label{sec:Conclusions}

We have presented a generalization of the productivity checking techniques
in~\cite{ZR10} (including the improvements of~\cite{EH11})
to non-orthogonal specifications, which are able to represent non-deterministic
systems. These naturally arise for example when abstracting away certain details
of an implementation, such as the concrete sequence of input values. This was
used to verify stabilization of hardware descriptions whose environment is left
unspecified, as was demonstrated in Section~\ref{sec:ApplHW}.

Our setting still imposes certain restrictions on the specifications that can be
treated. The most severe restriction is the requirement of left-linear rules in
the structure TRS .
Dropping this requirement however would make Theorem~\ref{thm:CStermination}
unsound.
Similarly, also the requirement that structure arguments of constructors must be
variables cannot be dropped without losing soundness of
Theorem~\ref{thm:CStermination}. This requirement however is not that severe in
practice, since many specifications can be unfolded by introducing fresh
symbols, as was presented in~\cite{EH11,Z09}.

In the future, it would be interesting to investigate whether transformations of
non-orthogonal proper specifications, similar to those in~\cite{ZR10}, can be
defined. It is clear that rewriting of right-hand sides for example is not
productivity-preserving for non-orthogonal specifications, since it only
considers one possible reduction.
However, it would be interesting to investigate whether for example narrowing of
right-hand sides is productivity preserving, as it considers all possible
reductions.

\noindent
\paragraph*{Acknowledgment.} The author would like to thank the anonymous
reviewers for their valuable comments and suggestions that helped to improve
the paper.

\bibliographystyle{eptcs}
\bibliography{ref}

\end{document}
