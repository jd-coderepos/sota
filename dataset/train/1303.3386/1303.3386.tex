\documentclass[12pt]{article}


\usepackage{fullpage}
\usepackage{amsmath,amsfonts,amssymb}
\usepackage{amsthm}
\usepackage{pdfpages}
\usepackage{float}



\newtheorem{theorem}{Theorem}[section]
\newtheorem{corollary}[theorem]{Corollary}
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{claim}[theorem]{Claim}
\newtheorem{fact}[theorem]{Fact}
\newtheorem{proposition}[theorem]{Proposition}
\newtheorem{conjecture}{Conjecture}
\newtheorem{property}{Property}
\newtheorem{observation}[theorem]{Observation}




\newenvironment{proofof}[1]{ {\sc Proof of #1.}\/}{\qedsymbol}
\newenvironment{proofsketch}{ {\sc Proof sketch.}\/}{\qedsymbol}
\renewcommand{\qedsymbol}{\ensuremath{\blacksquare}}



\newcommand{\comment}[1]{}
\newcommand{\remove}[1]{}
\newcommand{\suppress}[1]{}


\newcommand{\NN}{{\mathbb{N}}}
\newcommand{\RR}{{\mathbb{R}}}
\newcommand{\QQ}{{\mathbb{Q}}}
\newcommand{\ZZ}{{\mathbb{Z}}}
\newcommand{\FF}{{\mathbb{F}}}
\newcommand{\EE}{{\mathbb{E}}}
\newcommand{\SSS}{{\mathbb{S}}}

\newcommand{\opt}{{\hbox{\sc opt}}}
\newcommand{\alg}{{\hbox{\sc alg}}}
\newcommand{\LP}{{\hbox{\sc lp}}}
\newcommand{\IP}{{\hbox{\sc ip}}}
\newcommand{\DP}{{\hbox{\sc dp}}}
\newcommand{\ALG}{{\hbox{\sc tlc}}}
\newcommand{\first}{{\hbox{first}}}
\newcommand{\last}{{\hbox{last}}}

\DeclareMathOperator{\out}{out}
\DeclareMathOperator{\argmax}{argmax}
\DeclareMathOperator{\argmin}{argmin}



\newcommand{\eps}{\epsilon}
\newcommand{\phsu}{^{\phantom{a}}}
\newcommand{\bone}{{\hbox{\boldmath }}}
\newcommand{\inner}[1]{\left\langle #1 \right\rangle}
\newcommand{\bool}{\{-1,1\}}
\newcommand{\bn}{{\cal B}_n}
\newcommand{\obn}{\overline{{\cal B}_n}}



\begin{document}



\title{An Optimal Randomized Online Algorithm for Reordering Buffer Management}



\author{
Noa Avigdor-Elgrabli\thanks{Computer Science Department,
Technion---Israel Institute of Technology, Haifa 32000, Israel.
Email: {\tt noaelg@cs.technion.ac.il}}
\and
Yuval Rabani\thanks{The Rachel and Selim Benin School of 
Computer Science and Engineering, The Hebrew University of Jerusalem,
Jerusalem 91904, Israel. Email: {\tt yrabani@cs.huji.ac.il}. Research
supported by Israel Science Foundation grant number 856-11 and
by the Israeli Center of Excellence on Algorithms.}
}

\date{\today}

\setcounter{footnote}{3}
\maketitle

\begin{abstract}
We give an -competitive randomized online
algorithm for reordering buffer management, where  is the
buffer size. Our bound matches the lower bound of
Adamaszek et al. (STOC 2011). Our algorithm has two stages
which are executed online in parallel. The first stage computes
deterministically a feasible fractional solution to an LP relaxation 
for reordering buffer management. The second stage ``rounds" 
using randomness the fractional solution. The first stage 
is based on the online primal-dual schema, combined with a 
dual fitting argument. As multiplicative weights steps and dual
fitting steps are interleaved and in some sense conflicting, 
combining them is challenging. We also note that we apply
the primal-dual schema to a relaxation with mixed packing
and covering constraints. We pay the  competitive 
factor for the gap between the computed LP solution and the
optimal LP solution. The second stage
gives an online algorithm that converts the LP solution to
an integral solution, while increasing the cost by an  
factor. This stage generalizes recent results that gave a
similar approximation factor for rounding the LP solution, 
albeit using an offline rounding algorithm.
\end{abstract}



\section{Introduction}

In the reordering buffer management problem (RBM) an input
sequence of colored items arrives online, and has to be rescheduled 
in a permuted output sequence of the same items, with the help 
of a buffer that can hold  items. The items enter the buffer 
in their order of arrival. When the buffer is full, one color present
in the buffer must be chosen, and the items of this color in the
buffer, followed by any new items of the same color encountered 
along the way, are scheduled in the output sequence one item
per time slot, making room for new input items to enter the
buffer. The choice of color is made before future input items 
are revealed. Choosing a color
and evicting items is repeated until we reach the end of the 
input sequence and we empty the buffer. The objective is to 
minimize the total number of color changes between consecutive 
items in the output schedule. This seemingly simple model, 
introduced in~\cite{RSW02}, formalizes a wide scope of resource 
management problems in production engineering, logistics, 
computer systems, network optimization, and information retrieval 
(see, e.g.,~\cite{RSW02,BB02,KRSW04,GSV04}). Moreover, 
beyond its simplicity, elegance, and applicability, the problem
turns out to be challenging, and it captures some new and 
fundamental issues in online computing. We note that the
offline version of RBM is NP-hard~\cite{AKM10,CMSS10}, and
there is a polynomial time -approximation algorithm~\cite{AR13}.

This paper resolves the randomized competitive ratio of RBM.
We design a randomized online RBM algorithm and prove that
its competitive ratio is . This matches the
recent lower bound of  of Adamaszek
et al.~\cite{ACER11}.
All previous online algorithms for RBM are deterministic. A
sequence of papers~\cite{RSW02,EW05,AR10,ACER11}
culminated in an 
-competitive algorithm~\cite{ACER11},
nearly matching the deterministic lower bound in the same
paper. Thus, our work is the first to demonstrate an
exponential gap between the deterministic and the randomized 
competitive ratio of RBM.

In essence, our algorithm is an implementation of the primal-dual 
schema, and more specifically of the multiplicate weights update
method (see~\cite{BN09} for a survey of its use in online computing,
and~\cite{AHK12} for a general survey of the method). 
We compute online a feasible solution 
to an LP relaxation
for RBM. This part is done deterministically, and it uses the same
relaxation as in our past paper~\cite{AR10}. As we compute the LP 
solution, we feed it to an online rounding algorithm, which generates 
an integral solution on-the-fly. This part uses randomness, and is
motivated by our recent paper~\cite{AR13} that gives a (deterministic)
constant factor polynomial time approximation algorithm for RBM.

One of the interesting aspects of our result is that we apply the 
multiplicative weights update method to a bipartite perfect matching-style 
linear program. Essentially all prior online results 
using this method (e.g.~\cite{AAABN09,BBN12,BBMN11,ACER12}) 
were derived through relaxations that are packing 
or covering linear programs, or small variations thereof (such as 
having additional box constraints). Another interesting aspect of 
our result is that, for reasons explained below, we cannot apply this 
method in its pure form. We must combine it with a dual fitting argument 
that is similar in spirit to that in~\cite{AR10}. Combining the two
conflicting approaches into a hybrid primal-dual algorithm and
proof is the main technical challenge of our work.

What's unique about RBM and what separates it from other reputed
online problems is the following. Usually, when an online algorithm 
makes an irrevocable decision, this may change the state of the system
in a way that changes the cost of future decisions, but it only sets
the current output. In contrast, when an RBM algorithm makes a
decision to evict a color block from the buffer, this may decide the 
output for many steps ahead, as only one item can be evicted in one
step. What's even worse, as items that are already in the buffer when
the decision is made are evicted, new items of this color that arrive
along the way can be appended to the evicted sequence, so the algorithm
is perhaps deciding now how to handle future input it hasn't yet seen.
Moreover, the size of the color block being evicted could have a dramatic
influence on the length of the sequence being evicted, and hence on
future cost: if two algorithms differ by just one item between their buffer 
contents at some point in time, and they both decide to evict a color in 
which they differ, the algorithm with one less item might evict a much 
shorter sequence than the algorithm with one more item.

Very recently, Adamaszek et al.~\cite{ACER12} proposed a 
problem they call {\em buffer scheduling for block devices},
which is a variant of RBM that differs from it in one crucial
aspect. In block devices, while evicting a color from the buffer, 
new arriving items of that color cannot be appended to the 
output sequence without incurring additional cost. For example,
if the entire input sequence consists of a single color, an RBM 
solution pays , while a block device solution pays 
approximately . Thus, their problem eliminates 
the issue of making decisions regarding unknown future items, 
but it still has to cope with the problem of making decisions 
regarding future output steps. 
They give an -competitive
randomized online algorithm for buffer scheduling for
block devices that implements the multiplicative weights
update method (see~\cite{BN09}), using a covering LP formulation.

Their result, which motivated our work and
influenced part of it, overcomes the issue of deciding on
future output steps by employing a resource augmentation 
argument, adapted from~\cite{ERW09}. In~\cite{EW05,ERW09} 
it is proved (for RBM, but the same proof applies to block
devices) that if we replace a buffer of size  by a buffer of 
size , then the optimal value of a solution cannot 
increase by more than an  factor. If it were possible 
to reduce this factor to  for some constant factor decrease
in the buffer size, we could derive our results with ease using 
a fairly simple implementation of multiplicative weights. 
Unfortunately, the  factor is tight~\cite{Abo08}.
What is used in~\cite{ACER12} is a straightforward generalization 
of the proof in~\cite{ERW09}, which shows (for block devices,
but it is easy to generalize the proof also for RBM) that replacing 
a size  buffer by a size  buffer, for 
, increases the
optimal cost by a constant factor. 

Intuitively, resource augmentation
equips the online algorithm with some lookahead of  items,
and this lookahead allows the algorithm to decide on up to  
steps into the future. Technically, this helps implement the online
primal-dual schema in the two crucial parts of the argument.
Firstly, the gap enables an initialization of the primal variables
(triggered by the corresponding dual constraint becoming tight)
to roughly  instead of , and this reduces
the competitive ratio that one can hope for from  to 
.
Setting the multiplicative weights update method to prove this claim
is the main contribution of~\cite{ACER12} to extending the method
to handle RBM-style problems.
Secondly, lookahead helps bound the rate of
growth of the primal cost. In order to relate it to the rate of growth
of the dual cost, we'd like to remove items (fractionally) from the
buffer at a rate that is roughly the fractional volume that we've
already removed from items that are still present with some
weight in the buffer. This is easy if we only take into account
the removed volume that already disappeared from the buffer.
However, past decisions and current decisions extend into the
future, and there is some volume that has been scheduled to be
removed, but its removal hasn't yet happened. In particular,
some items can no longer ``participate in the game" despite
being still in the buffer, because they've already been scheduled
to be removed entirely from the buffer (this reduces the growth
rate of the dual cost). At least in the
case of block devices, if there are never more than 
items of a single color in the buffer, then this scheduled but
not removed volume never exceeds , and this bounds
the growth of the primal cost adequately. However, even in the
case of block devices, the buffer may contain very large color
blocks. In~\cite{ACER12} they overcome this problem by generating
an infeasible primal solution. Thanks to the fact that in the
block devices setting the future schedule does not include any
future items, they are still able to round the infeasible solution
to get a feasible integral solution.

This approach does not work in the case of RBM. It can be made
to work if the buffer never contains a color block larger than
, as in this case a feasible primal solution can be
generated.
On the other hand, if {\em every} color block in the buffer
always has (at decision points) at least  items, then
(a simple version of)
the deterministic dual fitting algorithm of~\cite{AR10} (and
probably also earlier algorithms) guarantees a competitive
ratio of . Thus, the main challenge and
the main technical contribution of this paper, is to combine
the two methods to give an  competitive
ratio without restrictions on the instance. As at any given
time the buffer can be in a ``mixed" state with both small
and large color blocks, combining these methods is non-trivial.
A covering formulation similar to the one used in~\cite{ACER12}
cannot be used, to the best of our knowledge, so we are
required to deal with a non-covering formulation that is
harder to incorporate into the primal-dual schema. Adding 
to the challenge is the fact that the dual fitting argument
inherently generates an integral solution, whereas the 
primal-dual schema inherently
generates a fractional solution. Thus, we have to decide if
a color block will turn out to be small or large before we know
how many items of this color we can accumulate in the buffer.
If we start removing it fractionally using the primal-dual schema, 
we cannot regret this decision later and switch to dual fitting.
Rounding also poses its own challenge, mainly due to the
above-mentioned feature of RBM, whereby premature eviction
of a color may cost us a great deal later. (This is something
that does not happen in the block devices problem.)

The rest of the paper is organized as follows. After
introducing some notation, definitions, and an
overview in Section~\ref{sec: preliminaries}, we present
our online primal-dual algorithm in Section~\ref{sec: online lp} 
and analyze it in Section~\ref{sec: frac analysis}. Finally,
we present the online rounding algorithm and analyze
it in Section~\ref{sec: online rounding}. The explicit 
constants in the rest of the paper are somewhat
arbitrary. We made no attempt to optimize them.




\section{Preliminaries}\label{sec: preliminaries}

Let  be a sequence of colored items. We denote
the color of an item  by . Abusing notation, we
denote the color of a sequence  of items of the same
color by . We denote
by  the cost of an optimal (offline) RBM 
schedule of  using a buffer of size . The
following lemma is adapted from~\cite{ERW09,ACER12}.
For completeness, we include a proof in the appendix.
\begin{lemma}\label{lm: resource augmentation}
For every input sequence  and for every ,
.
\end{lemma}
In our algorithm and analysis we use this lemma with
, which increases the optimal
cost by a constant factor.

Consider a sequence  of items of a single color  in 
 that includes all the items of this color between
the first and last item of . If there is an RBM solution
that outputs  starting at time , we call the pair 
a {\em batch}. Thus, an RBM solution consists of scheduling
or packing batches in the interval of output time slots
, where every output slot is used by at most
one batch, and every input item is scheduled or covered
by at least one batch. In other words, an RBM solution
is a bipartite matching of input items to output slots. The
matching must observe the order of input on each color
separately, and an item cannot be matched to an output
slot that precedes its arrival. The cost is the number of batches, where
a batch is a maximal output interval that got matched to
a set of items of the same color. This discussion leads us
to a natural linear programming relaxation for RBM. We
can think of the output slots as a channel of width 
spanning the output interval .
We pack batches fractionally in this channel, without
violating the width constraint, but covering all input items 
at least once. This relaxation is essentially identical to the
one used in~\cite{AR10,AR13}. We denote it simply by
. Formally,  is

Here,  is the weight of the batch  in the packing.
Constraints~\eqref{eq: input constraints} require that every item
is eventually removed from the buffer (in batches of total weight
). Constraints~\eqref{eq: output constraints} restrict the output
to remove a total weight of at most  in each time slot.
The dual linear program, which we denote by  is


Our algorithm computes online an  feasible solution
 and a  feasible solution . The algorithm
feeds , as it is being produced, to an online ``rounding"
procedure that produces an  feasible integer solution
, which is the output of our online algorithm. Our
main result, which the rest of the paper builds towards, is
\begin{theorem}
There is an -competitive randomized online
algorithm for RBM.
\end{theorem}

\begin{proof}
Theorem~\ref{thm: main} establishes that the value of 
is at most  times the value of , which
is a lower bound on , and hence at most
 (by Lemma~\ref{lm: resource augmentation}). 
Lemma~\ref{lm: rounding main} establishes that
the value of  is at most  times the value
of , and this concludes the proof of the theorem.
\end{proof}



\section{The Online LP Solution}\label{sec: online lp}

In this section we give an online algorithm that constructs
a primal feasible solution  to  and a dual feasible
solution  to . In Section~\ref{sec: frac analysis}
we prove the following theorem.
\begin{theorem}\label{thm: main}

\end{theorem}

We construct simultaneously a feasible primal solution
, an infeasible dual solution ,
and an auxiliary dual penalty . The construction
of  uses a non-trivial implementation of 
the multiplicative weights update method, and  is
generated by a dual fitting argument.
A feasible dual solution  can be derived by scaling
down  by a factor of .
The algorithm maintains throughout its execution for
every color  an index  which is the earliest item
of color  whose primal constraint~\eqref{eq: input constraints}
is violated, i.e., .

Notice that if a color  is not present in the buffer (for
instance,  has not been encountered yet), the algorithm
may not know . However, if the buffer has no item of
color , then the algorithm does not use , so this
does not cause a problem. The algorithm further maintains
the  earliest output slot  whose primal
constraint~\eqref{eq: output constraints} is not tight, i.e.,
.
Initially,  is set to .

The dual solution  is generated as
follows. Initially, all dual variables are set to . The
solution is parametrized by , which is raised at
a uniform rate. We occasionally refer to  as
{\em time}, but this should not be confused with the
discrete input and output time steps. Further notice
that even though for convenience we describe the
algorithm as a continuous process, it can be discretized
easily, and it can be implemented 
efficiently (regardless, competitive analysis is not concerned
with computational efficiency). 
The algorithm raises all the variables
 with  and all the variables
 for  at the same rate .
(This raises also future -s and -s; when 
we reach them, we will initialize their value to what's determined
by this process.)
Notice that we raise the -s corresponding to
violated primal constraints~\eqref{eq: input constraints},
and the -s corresponding to primal
constraints~\eqref{eq: output constraints} that are not tight.
Raising dual variables causes  to change, thus removing items
fractionally or integrally from the algorithm's buffer. This eventually
increments the -s and , thus changing the set of dual variables that
are raised. It also affects . The process ends when 
passes past time . At this point, we simply evict the remaining
buffer contents, using the output slots up to time .
(Notice that this last step does not cost more than the total
number of colors plus one; the total number of colors is a lower 
bound on the optimal cost.)

We now explain how raising  affects
. At any given time, let  denote the set of
items encountered so far, whose primal constraints are
violated, and let  denote the set of items of color
 in . In other words,  includes all the color
 items that appear in the input sequence starting from
 and before the current slot .
Notice that for every item in , at least a
fraction of that item is still in the algorithm's buffer.
There may be additional items in the algorithm's buffer.
These are items that are already scheduled to be removed
entirely from the buffer, but  hasn't yet passed
the point where they disappear from the buffer. The items
in  are endowed with one of three states: {\em fractional},
{\em integral}, or {\em frozen}. If any item in  is integral,
then they all are. Otherwise, the first ones are fractional and the 
remaining ones (if any) are frozen. We
will refer to a set of items in  of the same color and the same
state as a {\em block}. Thus,  consists of either one or two
blocks: an {\em active} block  that is either fractional
or integral, and a frozen block  that might be empty
(and must be empty if  is integral). With a slight abuse
of terminology, we sometimes also refer to all of  as a block.
These sets (, , , ) are all functions 
of  (and so are , , , , , , 
and other variables defined below).

Consider a dual constraint indexed  and put . Let

denote the current {\em dual cost} of the batch . Notice that we 
know this value at any time , even if the batch is matched to 
output slots we haven't yet reached.
\begin{fact}
Consider a batch  of color . If
 then there must be an item
 that is matched by  to an output
slot before the current time .
\end{fact}

\begin{proof}
If all the items in  are matched by  at time 
or later, then for all , we have that ,
so  increases, and therefore  cannot 
increase.
\end{proof}

The algorithm produces a primal solution  by scheduling
batches of items, i.e., by raising , for some batches
, where . If we schedule a batch  of 
color , then 
begins with the items in  (at the time  when
 is scheduled) and  could extend beyond
. We append a new item  of color  to  if
and when the following becomes true: 's state is the same as 
the state of the previous 
items in  (when they were added to ), and we did not
pass beyond the end of the current schedule of . 
In particular, when an item extends  it 
is in . Specifically, we do not append 
to , even though it is in our buffer by the time we reach
the end of the current schedule of , if 
at that time.
To summarize, scheduling a batch of color  at time 
involves packing in the output stream, starting with output slot 
, 
the sequence of items in  (with a weight
that cannot be greater than the remaining unscheduled weight of the 
first item in ), and later possibly extending this sequence 
with new items on-the-fly.

The regular execution of the algorithm is to schedule
continuously batches for every color  for which 
is fractional. The rate  at which we raise  is
governed by pseudo-dual cost variables 
and pseudo-primal variables , defined for all
batches . We maintain the equation

We set

Notice we schedule batches simultaneously for all colors with
fractional items in the buffer.

In order to complete the description of the algorithm's regular
execution, we need to explain how  changes.
Initially,  is set to , and at certain events
(see below) we reset  to . During an interval 
 with no reset,  does not
decrease. In order to explain the increase in ,
consider the increase in  when  changes by
an infinitesimal amount . Let , and let
. If  or
if all the items in  are matched by  at time 
or later, then  does not increase, and 
does not change. Otherwise,  increases by 
times the number of items in  that are matched by
 before time . In this case,  increases
by  times the number of items in  that
are matched by  before time . We will later see that
in this case .
We say that a batch  of color  that is scheduled during this 
increase is {\em relevant to} (the dual cost of the batch) .
Intuitively, if  is relevant to , then when  increases,
 increases by at most the same amount. Notice that
if a batch  that is relevant to  is scheduled without
interruption (i.e., it never reaches an item that is frozen at the
time slot it needs to be scheduled), then  includes the last
item of .

Occasionally during regular execusion, we reset  
to . We call this a {\em regular reset} (to distinguish it from
other resets that happen when regular execusion is interrupted).
This happens in the following situation. Let the current time 
be . Let  be the first item that {\em interrupts}
(is not appended to) a scheduled batch  ()
that is relevant to , because  when
it needs to be appended. If at time  the number of
items in  that arrived before  just dropped below
, we reset  to . Notice 
that we do this only for the first such item , so for
any batch , we do a regular reset at most once.
We denote the time of the regular reset by . 
If  never experiences a regular reset, we put 
.
Also notice that if  is reset to , 
automatically  is reset to .


Regular execution is interrupted in a few cases as follows. Upon
interruption, we keep executing the valid cases until none of them
hold, in which case regular execution is resumed.

{\em Case 1:}\/ A primal constraint~\eqref{eq: input constraints}
becomes satisfied, i.e., for some , 
reaches . In this case we increment . Notice that this also
changes .

{\em Case 2:}\/ A primal constraint~\eqref{eq: output constraints}
becomes tight, i.e.,  reaches .
In this case, we increment . Each new item that enters the
buffer initializes its state as follows. If there are integral
items of the same color, it enters the buffer as integral.
Otherwise, it enters the buffer as frozen (however, the
frozen state may change immediately due to the application
of one of the following cases).

{\em Case 3:}\/ If  for
some color , we schedule all the remaining
volume of . (This may involve scheduling
several distinct batches, and it also increments .) Then,
we change the state of all the items in  to integral.
(In particular this moves all of them to .)
Finally, we reset  (and hence ) 
to  for all batches  of color .

{\em Case 4:}\/ If  is fractional and
, we change the
state of all the items in  to fractional
(in particular, they move to ).

{\em Case 5:}\/ There is an integral block ,
and  reaches  for a color 
batch . (Notice that taking into account the reset
in Case~3 above, we can assume that  is a subset of 
.)
We {\em suspend} all fractional scheduled batches
that haven't yet ended. We set
 for every .
We schedule, starting at the current , an integral
( weight-) batch with all the items in  followed
by any items that can be appended to that block while it
is being evicted from the buffer. We reschedule
the unfinished portion of the suspended batches following
this integral batch. Finally, we reset  
(and hence ) to  for all batches  of 
color . Notice that following this case, both
 and  are incremented by at least .

{\em Case 6:}\/ Since the last application of this case, we've
moved past the end of regular execution fractionally scheduled 
batches of color  with total weight at least 
(suspended batches are not considered to have ended).
We apply the same procedure as in Case~5 to the block
, except that we don't raise . To
distinguish batches scheduled by this case from integral
batches scheduled by Case~5, we will refer to the ones
we schedule here as {\em weight- fractional batches}.



\section{Analyzing the LP Algorithm}\label{sec: frac analysis}

We first observe that by the definition of the algorithm
(Case~ and Case~) it constructs a feasible fractional
solution.
\begin{observation}\label{obs: x feasible}
The primal solution  is a feasible solution of .
\end{observation}

We now bound the total volume of items in the buffer that 
the algorithm schedules at any given time while in regular
execution.

\begin{claim}\label{cl: B_c bound}
If  is fractional, then 
and .
\end{claim}

\begin{proof}
By Case~3, if  is fractional, then 
. By Case~4, we keep
new items of color  in , unless
. If 
drops below , we move the
items in  to , adding at
most  new items, so
 always
(while fractional).
Combining this bound with the bound on
, we get that 
.
\end{proof}

\begin{corollary}\label{cor: volume beyond t-1}
At any time , the volume of items in  
that is scheduled beyond time  is less than 
.
\end{corollary}

\begin{proof}
There is a total weight of less than  of scheduled batches 
that extend to time  and beyond (otherwise, 
Case~2 would have happened). Each of these batches is fractional,
so by Claim~\ref{cl: B_c bound} it has less than  
items that are in . Therefore, the total volume
that is scheduled of items in  is less than
.
\end{proof}

\begin{claim}\label{cl: scheduled volume}
Consider the (partial) solution  at a time of regular 
execution of  the algorithm.
The total volume that the algorithm already scheduled
of items that are currently in  is bounded by

\end {claim}

\begin{proof}
Let  denote the current time, and let  denote
the current output time slot. By Corollary~\ref{cor: volume beyond t-1},
the total volume of items in  that is scheduled beyond time 
is less than . The total volume that is  
scheduled before time  is exactly . By the definition
of , exactly  items are scheduled to be removed completely 
from the buffer. Therefore, the volume that is scheduled from items in 
is bounded as follows:


\end{proof}

\begin{claim}\label{cl: x-hat bounded}
For every batch , it holds that 
always.
\end{claim}

\begin{proof}
Let . Notice that  can increase beyond  only
while  is fractional.
Consider an interval  
of uninterrupted regular execution
where  increases by  and the output time slot is .
Let  be a scheduled batch relevant to . Notice that
 is at least the total increase in  during 
the interval  where  was set. We prove 
the claim by bounding the total increase in  for all 
relevant .

First notice that the total increase for all  that extend all 
the way to the last item in  must be at most . This is because after 
an increase of  the last item of  is no longer in , and 
 cannot increase further. (A batch that is suspended
and later rescheduled is considered here as a single batch.)
The only reason that we 
do not extend  to the last item of  is if some item along the 
way is frozen at the time it needs to be appended to .
If when 
we reach the end of 's schedule, we've accumulated a cost of 
at least  of interrupted schedules since the last time
a weight- fractional batch of color  was scheduled, then we schedule a 
weight- fractional batch beginning with . Notice that 
the items of  are scheduled past where they
are matched by , so all the remaining items of  will be 
evicted from the buffer completely, and  will not 
increase further. 

So consider the first interrupted such  (so the first color  
item following  is ). At the time 
when the interruption occurs, all the items in  are 
not appended to
any scheduled batch. Let  denote the time when the items
that were in  are schduled to be removed
entirely from the buffer (i.e., they are removed from ). Every
scheduled batch that removes these items must schedule them after
time slot , so unless such a batch is interrupted, it includes 
the last item of .

Suppose that between time  and time  no other scheduled
batch of color  is interrupted. If  is past the end of the first
scheduled batch that removes , then this batch is not
interrupted and thus it includes the last item of . Therefore,
none of the scheduled batches that remove  are 
interrupted before they include the last item of . Otherwise,
at time  there
must be a total weight of  of scheduled batches of this color,
because each item in  is scheduled with total weight
 in batches that begin past , and none of these batches 
are interrupted until  (by our above assumption). In
this case, at time  all of  is scheduled to
be removed completely from the buffer. Also, it must be that
, because if  was non-empty
just before , it is moved to  due to Case~4 of
the algorithm (as  drops to ). Therefore, while all
these batches are still being scheduled, any new item of color 
is appended to all of them and is thus removed from the buffer, so
none of them are interrupted at least until the first one ends. As the
first such batch that ends must include the last item of , they
all must include the last item of .

If there is an interruption between time  and time ,
repeat this argument for the new interrupted batch  and
interrupting . Notice that any such interruption must
have the property that  must schedule the previous  
past , and therefore past where it is matched by .
If we accumulate  of
interrupted  at some point, then we schedule a 
weight- fractional batch, and by the argument above
 does not increase further. Notice that in this
case the last such  so .
Otherwise, the weight
of interrupted  is less than  and the weight
of uninterrupted  is at most , so
. (Notice that along the way we
might have reset , but this can only decrease its
value, and we analyzed aggregate increase .)
\end{proof}


\subsection{Dual feasibility}

The main technical difficulty is to show that the dual solution that the
algorithm computes is a feasible solution.
In order to prove this, we need to show that
the constraints~\eqref{eq: dual constraints} are satisfied, namely that
for every batch ,

We consider several cases in the following claims. These cases will be
combined in the pursuing proof of Lemma~\ref{lm: (y,z) feasible}.
Consider a batch . The items in  are partitioned by the
algorithm's execution into segments. A segment is a maximal
substring of items with the same state when removed from the
buffer. Thus, there are alternating fractional and integral segments.
An integral segment consists of a block of items that were removed
together in a single application of Case~5 of the algorithm. In
between two integral segments (or an integral segment and an
endpoint of , or two endpoints of ) there is a fractional
segment.

We first deal with batches that do not contain an integral
segment.
\begin{claim}\label{cl: fractional batch}
For every batch  for which all of  is one fractional segment,

\end {claim}

\begin{proof}
Denote . Notice that  increases only when 
and  (this is a necessary but not sufficient condition). We bound
the total increase in , ignoring possible decreases along the
way. Therefore, we may assume that  is a maximal set without an
integral segment, because extending it backwards and forwards can only
make the sum of increases larger. To see this, notice that if , then
extending  backwards adds items whose  value possibly
increases, whereas its corresponding  value remains fixed.
Extending  forwards adds items whose  value definitely
increases (because ), and its corresponding  value
possibly also increases.

Notice that there is at most one value  of  
where 
(and therefore ) is reset to  while , 
because  does not contain
an integral segment. Recall that  is the first
item in  that is in  when we need to append it to a relevant 
scheduled batch. Then  is the smallest value of  for which
.

Notice that whenever 
increases by , then  increases by at least
. This is because the increase in 
is incurred by all the items that increase , excluding those that
are currently frozen. However,  and
if  matches any item of  before the current time , then it
matches all the items of  before time  as well. (As 
is fractional and  is maximal, .)

Notice that

By Claim~\ref{cl: x-hat bounded},  always.
Therefore,  always. Because
 is reset at most once, we get that 
.
\end{proof}

The proof of the following property is useful
in the rest of the analysis.
Consider a batch  of color .  
Let  be its integral segments
(by the order of the matching).
Let  be the time that the first item of  is matched by ,
and let  be the time slot where  was scheduled by the algorithm.
Denote by   the difference between these times.
We also denote by  the number of items from 
that are in the algorithm's buffer when the algorithm decides to
remove  (starting at time slot ).

\begin{claim}\label{cl: delta_p}
For every batch  with  integral segments, and
for every , we have that .
\end{claim}

\begin{proof}
Notice that for every , . 
Otherwise the time slot where the algorithm starts removing the items 
in  is after where they are matched by the batch .
Thus, the algorithm removes all the remaining items of . 
This mean that there would be no more integral segments after . 

We now show that given , we have that
. 
At time  when we reach past the end of 's
eviction, there are no items of this color in . Therefore, all the items 
of the following fractional segment (denoted by ), 
and all the integral items that were in  at the time
that segment  was sheduled (starting at time slot ), 
enter the buffer during the input interval . 
Therefore,
.
Combined with the fact that,
, we get that

This complets the proof as

\end{proof}

\begin{claim}\label{cl: batch before alg}
Every batch  such that the first item  is in 
at time  contains a constant number of segments.
\end{claim}

\begin{proof}
Let  be the number of integral segments in .
 We start by showing that  .
We assume that the first segment of  is a fractional segment.
Otherwise, as  the first item  is in  at time ,
all of  is a single integral segment. 
Let  be the first fractional segment. We also assume that 
 as otherwise   is triviall, 
because  and . 
As there can be at most  fractional
items at time , at least  items
are added to  after time . Furthermore, there are at least 
 items from  that arrive before time
slot . These items arrive after the items of  and therefore
after time slot .
Therefore, .
Thus, in this case .

We now use Claim~\ref{cl: delta_p} and get that 

The upper and lower bounds on  imply that .
\end{proof}

\begin{claim}\label{cl: batch after alg}
For every batch  such that for every item  it holds
that  at the time it is scheduled by ,

\end{claim}

\begin{proof}
Let  be a batch of color  with  integral segments 
that satisfies the conditions of the claim. For  define 
to be the output time slot where  is scheduled by . For every item , let
 be the contribution of 
to the pseudo-dual cost of . 
Note that the sum of all contributions over  is exactly the left hand 
side of the claimed equation.
Let  be the fractional segment between 
 and . We assume w.l.o.g that  starts and ends with
an integral segment, as every fractional item has a negative contribution,
as we prove below.
Let  be the time slot in which  is removed from .
Notice that for an item , .
For every integral segment , let  be the time that the
first items of  are ``defrosted" (i.e. they are moved from 
to ).

We start with the following observations:\\
() For every , .\\
() For every ,
.\\
Observation () follows as .
Observation () follows from  Case~5. When the integral block 
 is scheduled at time slot , the pseudo-dual cost 
 of some batch  with  reaches .
Notice that the pseudo-dual cost 
is reset to  when  is ``defrosted" at time slot
, and between  and  there are never more
than  items of color  in . Therefore,
the rate at which  is raised in this
interval is at most .
Therefore,  increases by at least  in between 
 and .

Let  be the maximum index for which  
(the lateset integral segment that was sheduled up to time ).
Let . (This is the
maximum between  and the time slot where the algorithm 
removes the last item of .)  Notice that ,
because if , the algorithm removes during the interval 
part of the integral block , and therefore the corresponding 
-s do not increase beyond their set value when the removal 
began at time slot . 
We have that

The second equality follows from observation (). The inequality is
explained as follows. From observation  we have that
.
Therefore, if , then ,
so we can ignore these terms for fractional segments. Furthermore,
for any  in a fractional segment, .

We upper-bound the above right-hand side as follows.\\
{\em First part:}\/ Here we bound

Notice that we bound the contribution of all the items before 
segment  assuming that they are all matched by the batch 
to time slot . (In the next part we use the negative contribution that
each of these items  accumulates between time slot  and time
slot .)
Consider , . For every 
, we have that   and .
Also notice that .
Therefore, using observation () we have that
.
Moreover, for every such segment 
there are  items  each with a positive contribution
 to~\eqref{eq: first part},
and at least  items with a negative 
contribution 

to~\eqref{eq: first part}.
The last integral segment  cobntributes at most 
to~\eqref{eq: first part}. Therefore,

Let  be the indices of the segments
that have a positive contribution to the right-hand side of~\eqref{eq: first part upper bound}.
For every , 
.
Because for every  it must be that , 
we conclude that . Each segment  contributes
to the right-hand side of~\eqref{eq: first part upper bound} at most .
Therefore,


{\em Second part:}\/ In this part we bound

We start by noticing that for every 
there are exactly  items that are matched by the
batch  in the interval  (by the fact that 
we know that ). These items precede
in the input any item in , and therefore they are
scheduled by the algorithm (completely) before time slot .
In particular, for any such item  we have .
Observation  implies that each such item accumulates
in the interval  a negative contribution to~\eqref{eq: second part}
of at least . Notice that the same items might
accumulate a negative contribution from several such intervals
for consecutive -s. Further notice that if , then
.
Using Claim~\ref{cl: delta_p} to bound , we get that

where the extra term  accounts for the contributions of  and .
We therefore get that only integral segments  such that
 can have 
a positive contibution. As ,
there are at most  such segments, and each
segment adds at most  to right hand side of the above
inequallity.
\end{proof}

We are now ready to prove the main lemma.
\begin{lemma}\label{lm: (y,z) feasible}
The dual solution  is a feasible solution of .
\end{lemma}

\begin{proof}
Consider a dual constraint indexed . 
We partion the pseudo-dual cost 

of 
into two parts. Let  be the first item for which  at the
time it is matched by . Partition  into two 
sub-batches ,  
such that  contains 
all the items in  smaller than ,  contains 
the rest of 's items, and .
From Claim~\ref{cl: batch after alg} the pseudo-dual cost of 
 is . Any integral segment 
of  contributes 
exactly  to . Only 
the last integral segment can have a positive contribution 
to , as any integral block with positive 
contribution to a batch  evicts all the remaining 
items of . Any fractional segment contributes at most 
 to , by 
Claim~\ref{cl: fractional batch}. Therefore, as the total
number of segments in  is bounded by an
absolute constant
(Claim~\ref{cl: batch before alg}), the total pseudo-dual 
cost of  is also .
We therefore conclude that the dual solution ,
derived by scaling down  
by an appropriate factor of , is feasible.
\end{proof}


\subsection{Bounding the primal cost}

Here we bound the cost of the primal solution using the
cost of the dual solution.
\begin{lemma}\label{lm: primal cost}
At the end, 

\end{lemma}

\begin{proof}
We partition the primal cost of the algorithm into three parts,
according to the reason for incurring the cost.

{\em Part 1 (regular execution):}\/
Consider an increase  in  during regular
execution, and let  be the current output time slot.
By the definition of the algorithm, the dual variables that 
are raised at time  
are , , and
. Therefore,

Let ,  be the (partial) primal and pseudo-primal 
solutions at time .
For every color  for which  is
fractional, let  be the batch of color 
that maximizes  (i.e., at time
 the rate of increase of  dictates the
rate at which color  is removed from the buffer).
Notice that during regular execusion, if  increases
then  must be fractional. 
Thus, by definition,

We bound the first term as follows:

The last inequality follows from the fact that the volume in the buffer
of items in  is at least  (an immediate
consequence of Corollary~\ref{cor: volume beyond t-1}).
Because the volume in the buffer of items in  
is at least 
also . So,


We now bound the second term
.
We show that for every color ,

The difficulty in proving this is the following. Any increase in
 lower bounds the increase in , if
the batch  is relevant to  at that time. In this
case, it is possible to extend the scheduled batch  to
include all the items in . However, the batch
might terminate before removing all those items because it
reaches an item that is in  at the time it needs to
be scheduled. The regular reset of  takes
care of this problem, as we show below.

In order to show Inequality~\eqref{eq: second term}, we consider 
three cases, according to the current value of . The first case 
is when  (i.e., before 
experiences a regular reset). Notice that every batch  that 
is relevant to  and is scheduled starting at some time
, removes more than half of the items in ,
because at the current  less than half of  arrived 
after the first item  that causes any interruption 
in a relevant scheduled batch. In this case,


The second case is when ,
where  is the time at which 
is scheduled to be removed completely from the buffer.
Notice that  is reset at , 
so , where the sum is taken
over relevant  that are scheduled after time .
Consider such . 
If  is never interrupted (something that
might happen if  at the time we reach
the end of ), then clearly .
Otherwise, let  denote any point in the time
interval where  was scheduled (the sets don't change during that
interval). Less than half the items in  arrived 
before , so this remains true also for . 
As , we have that .
Set  to be the minimum time in  when
. If no such time exists, set
. Clearly, .
Let  (i.e., the input items starting
with ). Now, ,
so 

Clearly,  schedules all of . 
Notice that 
 and
.
Combining everything together,


The last case is when . In this
case, consider all the scheduled batches that include .
Their total weight is , and they've all been scheduled
before the current . Because  interrupted a
relevant batch, all these batches must be relevant. A weight
of less than  of these batches is interrupted
before time , otherwise we would have executed
Case~6, removing all the remaining items of . This 
contradicts the definition of  as the batch that 
currently, at time , controls the rate at which color
 is evicted from the buffer. Thus, a weight of at least 
of the scheduled batches that include  schedules at time 
 all the items in . On the other 
hand, by Claim~\ref{cl: x-hat bounded}, 
. Therefore,

Therefore, regardless of the value of the current time ,

where the last inequality follows from Claim~\ref{cl: scheduled volume}.
Thus, summing the bounds on the two terms,

which implies trivially that the total primal cost due to 
regular execution of the algorithm is at most  times 
the dual cost.

{\em Part 2 (Case 3 and Case 5 execution):}\/
Each time an integral block is evicted (Case~5),
 is raised by .
Preceding each such eviction there is a specific Case~3 execution, 
 when the block became integral. 
These Case~3 and Case~5 executions incur together
a primal cost of at most . (Case~3 evicts a color from
the buffer at a cost of at most . Case~5 schedules an
intergal block, and may suspend fractional batches of
toal weight . So the cost of Case~5 is at most .)
Therefore, the total primal increment due
to Case~3 and Case~5 is at most .

{\em Part 3 (Case 6 execution):}\/ Case~6 costs at most  (just like
Case~5). Each time we execute Case~6 on color , we've moved past
the end of regular execution fractional scheduled batches of color  with
total weight at least . After the end of this eviction,
 does not contain any color  items, therefore the next Case~6
execution is due to distinct fractional scheduled batches.
Therefore the primal increase as a result of Case~6 is at most
 times the primal increase due to regular executions.
By the above analysis of regular execution, this incurs a cost of 
at most  times the dual cost.
\end{proof}




\section{Online Rounding}\label{sec: online rounding}

In this section we give a randomized online algorithm that
rounds the fractional solution  to an integral solution
for the reordering buffer management problem.
The rounding algorithm presented here is inspired
by our deterministic offline rounding algorithm in~\cite{AR13}.
Here we use randomness to replace the knowledge of future
input that is needed in~\cite{AR13}. 
At each
step  where our rounding algorithm needs to choose a
color to evict, it uses only the input up to time  and the 
fractional solution  that we computed up to time . 
Thus, our randomized online algorithm for reordering buffer 
management repeats two alternating steps: () Extend the 
fractional solution deterministically up to the current time. 
() Evict from the buffer using randomness some items 
chosen based on the current partial fractional solution. This 
increments the current time to the next vacant output slot.



\subsection{The rounding algorithm}

The algorithm works in phases. The first phase begins at
time . In the beginning of a phase, the algorithm
chooses one or more color blocks to evict, based on the 
fractional
solution  that was computed up to the output time
slot  where the phase begins. Then, the algorithm 
evicts the chosen
blocks, and a new phase begins. Notice that
in order to execute the next phase, we need to extend
the fractional solution  to the new time slot that we 
have reached, taking into account the new input items 
that have entered the buffer during the last phase.

In choosing the colors to evict in a phase, we consider
four cases. Let  be a sufficiently small constant, 
and let  be the starting output time slot of the current 
phase. More precisely, the fractional solution computed so
far fully uses the time slots up to at least , whereas the 
integral solution computed so far extends up to time slot 
.

{\em Case 1:}\/ The buffer contains an item from which 
the fractional solution removed so far a weight of at least 
. We evict the color block of this item.

{\em Case 2:}\/ The total weight of the items that the
fractional solution schedules in the time slot  
and are also in our buffer is at least 
. We choose one such item at random with 
probability proportional to the weight it is removed at
time , and we evict its block.

{\em Case 3:}\/ A weight of more than  of
the items that the fractional solution schedules at time
 belong to a single color  that we just evicted
from our buffer (i.e., the integral solution evicts at time 
slot  an item of color ). 
In this case we first choose color
blocks to evict according to the following procedure, 
and then we evict all these blocks in arbitrary order.

We now describe the procedure for choosing color
blocks to evict in Case~3. Besides choosing color
blocks, the procedure also ``locks" some volume
fractionally scheduled before time . Any volume
that is fractionally scheduled starts unlocked. Locked
volume is assigned to a specific evicted block, and
when the weight in the fractional buffer of an item 
in this block drops below , the volume
assigned to this block becomes unlocked again.
 
We partition the colors into classes according to the
number of items in the buffer of each color at time .
A color  is in class  iff the
number of items in the buffer of color  is in .
Next, we partition the classes into subclasses as follows.
For every color  let  denote the average over the 
color  items in the buffer of the unlocked volume
that the fractional solution scheduled for this item
before time . Let  denote the sum of 
over all colors  in class . To construct a subclass, 
we collect
blocks until their total  weight exceeds .
In a class, we construct disjoint subclasses using this
process while the remaining weight is at least .
Notice that because  for every color ,
the total weight of a subclass is in .
Also notice that in each class we might have colors with
total  weight of less than  that are not
assigned to subclasses. We ignore those colors. If 
 then no block of class  is chosen.
In each subclass, we choose at random one color block 
to evict. The probability of choosing a color  is 
proportional to . The chosen block locks all
the unlocked volume in the subclass. Finally, we also 
choose the largest color block in our buffer (This block 
takes care of the excess weight that we ignored in the 
above choice.)

{\em Case 4:}\/ If all else fails (i.e., for all previous
cases, the conditions for executing the case do not
hold), we choose the largest
and second largest color blocks, and also apply the
Case~3 procedure that chooses more colors. If after 
evicting the largest or second largest color block one 
of the other cases applies, 
we terminate the phase without evicting the remaining
chosen blocks. (If we don't get to evict the Case~3
procedure choices, we annul the locks generated by 
the choice.) We stress that we choose all the blocks to 
evict in this case according to the situation at time ,
but some of the chosen blocks might end up not being
evicted.




\subsection{Performance guarantees}

We show that the cost of the integral solution generated
by the rounding algorithm is within a factor of  of
the cost of the fractional solution generated by the
primal-dual algorithm. The main idea of the proof is the
following. Evicting a color block increases the cost of the
integral solution by , and we would like to change this
cost against an increase by some (small) constant of the
cost of the fractional solution. The blocks evicted due to 
the procedure in Case~3, excluding the eviction of the largest 
block, are handled separately (see Claim~\ref{cl: case 3 procedure}).
All the remaining evictions amount to a constant number of
blocks evicted per phase. We show that for an expected
constant fraction of the phases, we can find batches that
were scheduled by the fractional solution with the following
properties: () These batches do not stretch beyond the time
slot reached by the integral solution in the corresponding phase.
() Their total weight is at least . () They were
not selected more than once in previous phases (excluding the 
charging of the Case~3 procedure). This, together with the
Case~3 charging scheme, implies the following guarantee.
\begin{lemma}\label{lm: rounding main}
The expected cost of the solution generated by the
rounding algorithm is ,
where  is the primal solution generated by the
primal-dual algorithm.
\end{lemma}

\begin{proof}
We consider the four cases that define a phase that
begins at time . In the first two cases our 
charging scheme is easy to achieve. In Case~1, 
an item  that is evicted in this phase is scheduled 
in the fractional solution before time  in batches 
of total weight at least . Because each such 
batch matches  to an output slot before , all 
of these batches end before the end of the current 
eviction of . So we charge this phase to the cost
of  of those batches.

In Case~2, consider the fractionally scheduled
batches with an item scheduled at time . Let  
be the earliest time when the subset of these batches 
that have ended by time  has total weight of at 
least . Thus, the weight of the subset of these 
batches that reaches time  is at least . 
Consider the subset of batches that schedule at 
time  an item that is in our buffer at that time. 
This subset has total weight . Therefore, 
the total weight of batches that schedule at time  
an item in our buffer and also reach time  is at least 
. The probability that the algorithm 
chooses to evict a color block of one of these batches
is at least .
If this event happens, the current phase ends past , and
we charge the phase to the weight of at least  
of batches that use  but end at or before .
If our choice is unsuccessful, we don't charge the phase. 
This happens with probability at most .

If we execute neither Case~1 nor Case~2, then for
every item in our buffer, the weight of this item that the 
fractional solution scheduled before time  
is less than . Also, a weight of more than 
 scheduled by the fractional solution at time 
 is of items no longer in our buffer. Notice that these items
must have appeared in the input prior to their removal, so 
we've already placed them in the buffer and evicted them in 
the past.

By the definition of , it's still true that in the fractional 
solution the total weight of batches whose schedule contains
the interval  is at least .
Let  denote the total volume of the content difference 
between our buffer and the fractional buffer (i.e., of the items 
in our buffer the fractional buffer lacks a total volume of ,
and symmetrically of the contents of the fractional buffer, a
total volume of  belongs to items we no longer hold). 
Let  denote the earliest time where at least a weight 
of  of the fractionally scheduled batches that reach 
 schedule an item that arrived at time  or later (i.e., 
items we haven't seen yet).

Assume for now that Case~3 does not hold. If our buffer at 
time  contains one or two colors that together have more
than  items, then the eviction of the two colors chosen 
in the first step of Case~4 makes us reach . Notice that we
reach  just by removing the items of these colors that are
already in our buffer at . However, as we evict each
color, additional items of this color that enter the buffer might 
be appended. If we reach ,
we can charge this phase as in Case~2. If we haven't reached 
, then Case~2 now applies for the following reason: our 
buffer at time  contains more than  items that are 
evicted. We advance beyond  by at least the number of items
that arrived after time  that we remove. Thus, if we haven't 
reached , there is still a weight of at least  of 
fractionally scheduled batches stretching to  with the current
item in our buffer. Therefore, the next phase will be charged with
probability at least  (because it executes either Case~1
or Case~2). We do not charge this phase.

So let's assume that there are no such colors. Let 
be a sufficiently large constant. Suppose that
. By our assumptions, between
 and  there is a total volume 
 that the fractional solution
schedules of items that arrived before time . This is
because at most  of the volume 
belongs to items arriving past  in fractionally scheduled
batches that reach , and another at most 
belongs to batches that don't reach 
(regardless of when their items arrived). Of this volume, more 
than  must still be in 
our buffer at time . Consider the fractionally scheduled
batches of total weight 
at least  whose schedule contains the interval
 (which includes ). At least
 of this weight belongs to batches that 
begin with no more than  items no longer in 
our buffer at time . Otherwise, the total volume of items
that are no longer in our buffer but are still in the fractional
buffer is 
,
a contradiction to our assumptions.

Consider these
batches of total weight at least . In the
interval , they contain only items
that are either in our buffer at time  or arrive past .
But only less than  of this weight belongs to batches
that contain, up to time , any item that arrives past 
(as their schedule all reach ). So there's a weight of at least
 of these batches that in the interval
 contain only items that are in our
buffer at time . Notice that for every color that appears
in these batches, our buffer in the beginning of the phase
contains at least  items of this
color. Assuming that  is sufficiently
large, . 
If there two different colors, then our buffer at 
time  contains one or two colors that together have more
than  items, a contradiction to our assumptions.
Thus, all these batches belong to the same color . The number
of items of color  in our buffer is at least 
. 

Recall that by our assumptions so far, we execute in the
current phase Case~4.
If there is a color in our buffer with more items than , 
then after evicting the largest color one of the following
two possibilities happens. If we've reached  then we
charge this phase as in Case~2. Otherwise, more than half 
the weight that the fractional solution now removes is on
items of color  that we currently have in the buffer. 
Therefore, we will next execute either Case~1 or Case~2.
We do not charge this phase,
and the next phase is charged with probability at least 
.

If we choose to evict  (because it has the maximum
number of items in the buffer) and we don't reach , 
we end up with no items of color  in the buffer, and a
weight of  is now
being removed by the fractional solution from items of
color . In particular, this means that Case~3 holds, so
in the next phase we definitely will not execute Case~4 again.
(This scenario is precisely the reason for defining Case~3.)
We do not charge this phase. If in the next phase we execute 
Case~1 or Case~2, then the next phase is charged with 
probability at least . Otherwise, in the next
phase we execute Case~3, and as we show below, a Case~3 
phase is either charged or followed by a Case~1 or Case~2 
phase, which is charged with probability at least .

We now analyze the remaining Case~3. Recall that Case~3 is
invoked if the fractional solution removes at time slot 
a weight of at least  of items of a color that we've
just evicted. Define , where  is 
defined as follows. Consider the color  batches that pass
through . (Recall that we've just evicted color .)
Each of these batches begins (at time slot ) with one
or more items that we already evicted from our buffer. Define
 to be the median number of such items in a batch, where
each batch has probability proportional to its fractional weight.
Notice that at time  at least a weight of  
of the scheduled batches remove an item that arrived 
at time  or later. If 
is sufficiently small (so that ), 
a weight of at least  of those batches
reaches . Thus, if we've reached  without
removing any items that arrived from  onwards,
Case~2 applies.
Moreover, in the interval ,
at least  of the scheduled weight is on
items that we've already evicted from our buffer
before time . This volume is held in the fractional 
buffer at time . So .
Thus, if either Case~3 holds or the assumptions under 
which we've analyzed Case~4 do not hold, we are left 
with the following situation. There is a time  such
that , and if we reach
 using only items currently in our buffer, then
Case~2 holds. 
By Claim~\ref{cl: case 3 procedure} below, the Case~3 
procedure chooses colors with 
more than  items that are in our buffer at time 
. Any item that arrives after time  that we evict
pushes us one step further beyond . Therefore,
after evicting all the Case~3 items, either we reach 
or we can apply Case~2. All but one of the color blocks 
evicted by the Case~3 procedure are charged via 
Claim~\ref{cl: case 3 procedure}.
If we reach , the phase is charged as in Case~2.
Otherwise, the phase is not charged, but the next phase
executes either Case~1 or Case~2 and will be charged
with probability at least . 

Concluding the analysis, in expectation at least  
of the phases are charged. The worst case is when repeatedly
we have a Case~4 phase followed by a Case~3 phase followed
by a Case~2 phase which is charged with probability . 
\end{proof}

\begin{claim}\label{cl: case 3 procedure}
For every  there exists  
such that applying the Case~3 procedure starting at time 
chooses color blocks totalling more  items in our buffer 
at time . Excluding one block, we can charge the eviction
of each block with probability at least  to constant
fractional cost incurred before we complete its eviction. The
same fractional cost is never charged more than once in all
Case~3 procedure invocations.
\end{claim}

\begin{proof}
We relate the charge for chosen colors to the locking of volume that 
the fractional solution removes prior to time  of items that we 
hold at time . Notice that the total such volume (locked and
unlocked) is precisely . Notice that in every -subclass, 
one execution of the Case~3 procedure locks a volume of at most
. While this volume is locked, all the items of
the evicted color block that locked it are kept in the fractional
buffer with weight . Let  denote the 
portion of  that is unlocked. 
We start by showing that  is close to . More 
specifically, we show that 
.
To show this, we consider  as the volume in the fractional
buffer and not in our buffer, and  as the unlocked volume 
in our buffer and not in the fractional buffer.

Notice that each of our evictions of a color block
 that is scheduled before  contributes to  the total 
weight in the fractional buffer of 's items at time . The
sum of these contributions is exactly . If our buffer at time
 does not contain any items with volume that was locked for 
the eviction of , then  contributes the same amount to 
and . Suppose our buffer does contain items
with volume locked by the eviction of . The fractional solution holds 
at time  all such items with weight more than , 
otherwise we would have applied Case~1. Moreover, since this volume
is still locked, then all the items of  must be held at time  by 
the fractional solution with weight at least  (otherwise, the
volume assigned to  would become unlocked).
So, if we 
write the contribution of  to  as , we get 
that . The volume that is locked
because of  contributes at most  to 
, because  is at least half the maximum size of
a block in 's subclass. Therefore,
.

Going back to the main argument, let  be
the colors in some -subclass, sorted by non-decreasing 
order of the time one of their current items first drops to weight 
at most  in the fractional solution. Let  denote
the color we choose from this subclass. Notice that the contribution 
to  of this subclass is at most ,
whereas we evict at least  items from our
time  buffer. The total  volume unaccounted
for is less than ,
where  is the maximum participating value of  
(this includes classes from which we did not take any color
block). To handle this portion of  that is unaccounted
for, recall that we always also evict the largest color block,
whose size is at least . Notice that we might
be counting this block twice, once as it might have been chosen
in an -subclass, and once as the largest block.
Summarizing the argument, we have that the number of items 
we evict from our time  buffer is at least 

for an appropriate choice of . (The initial 
factor is for the double-counting of the largest block.)

Finally, we deal with charging the cost of evicting the colors
we choose. Consider the colors  in an
-subclass as defined above. Let  denote the median
color in this subclass where colors are weighted by their
contribution to . The probability that we choose
a color with index  or larger is at least . If
this happens, we charge the fractional cost of at least
 that generated 
the volume of colors 
 that we are now locking. Otherwise, we
don't charge the eviction of a block from this subclass.
Notice that
by the time the block with index  or larger releases the
lock, the blocks for colors  or smaller have been evicted
from our buffer (because of Case~1). Therefore, this cost is 
never charged again in a Case~3 procedure. Also notice that
in expectation half of the Case~3 evictions are charged.
\end{proof}






\bibliographystyle{abbrv}
\begin{thebibliography}{10}


\bibitem{Abo08}
A.~Aboud.
\newblock Correlation clustering with penalties and approximating the
  reordering buffer management problem.
\newblock Master's thesis, Computer Science Department, The {Technion} -
  {Israel} Institute of Technology, January 2008.

\bibitem{ACER11}
A.~Adamaszek, A.~Czumaj, M.~Englert, and H.~R\"acke.
\newblock Almost tight bounds for reordering buffer management.
\newblock In {\em Proc. of the 43rd Ann. ACM Symp. on Theory of Computing},
  pages 607--616, June 2011.

\bibitem{ACER12}
A.~Adamaszek, A.~Czumaj, M.~Englert, and H.~R\"acke.
\newblock Optimal online buffer scheduling for block devices.
\newblock In {\em Proc. of the 44th Ann. ACM Symp. on Theory of Computing},
 pages 589--598, June 2012.



\bibitem{AAABN09}
N.~Alon, B.~Awerbuch, Y.~Azar, N.~Buchbinder, and J.~Naor.
\newblock The online set cover problem.
\newblock {\em SIAM J. Comput.}, 39(2):361--370, 2009.

\bibitem{AHK12}
S.~Arora, E.~Hazan, and S.~Kale.
\newblock The multiplicative weights update method: a meta-algorithm and applications.
\newblock {\em Theory of Computing}, 8(1):121--164, 2012.

\bibitem{AKM10}
Y.~Asahiro, K.~Kawahara, and E.~Miyano.
\newblock NP-hardness of the sorting buffer problem on the uniform metric.
\newblock Unpublished, 2010.

\bibitem{AR10}
N.~Avigdor-Elgrabli and Y.~Rabani.
\newblock An improved competitive algorithm for reordering buffer management.
\newblock In {\em Proc. of the 21st Ann. ACM-SIAM Symp. on Discrete Algorithms},
  pages 13--21, January 2010.

\bibitem{AR13}
N.~Avigdor-Elgrabli and Y.~Rabani.
\newblock A constant factor approximation algorithm for reordering buffer management.
\newblock To appear in {\em Proc. of the 24th Ann. ACM-SIAM Symp. on Discrete Algorithms}.



\bibitem{BBMN11}
N.~Bansal, N.~Buchbinder, A.~Madry, and J.~Naor.
\newblock A polylogarithmic-competitive algorithm for the -server problem.
\newblock In {\em Proc. of the 52nd Ann. IEEE Symp. on Foundations of Computer Science},
pages 267--276, October 2011.

\bibitem{BBN12}
N.~Bansal, N.~Buchbinder, and J.~Naor.
\newblock A primal-dual randomized algorithm for weighted paging.
\newblock {\em J. ACM}, 59(4) (Article 19), 2012.

\bibitem{BB02}
D.~Blandford and G.~Blelloch.
\newblock Index compression through document reordering.
\newblock In {\em Data Compression Conference}, pages 342--351, 2002.

\bibitem{BN09}
N.~Buchbinder and J.~Naor. 
\newblock The design of competitive online algorithms via a primal-dual 
approach. 
\newblock {\em Found. Trends Theor. Comput. Sci.},  3(2--3):93--263, February 2009.

\bibitem{CMSS10}
H.-L. Chan, N. Megow, R. van Stee, and R. Sitters.
\newblock A note on sorting buffers offline.
\newblock {\em Theor. Comput. Sci.}, 423:11--18, 2012.



\bibitem{ERW09}
M.~Englert, H. R{\"o}glin, and M.~Westermann.
\newblock Evaluation of online strategies for reordering buffers.
\newblock {\em ACM Journal of Experimental Algorithmics}, 14 (Article 3), 2009.

\bibitem{EW05}
M.~Englert and M.~Westermann.
\newblock Reordering buffer management for non-uniform cost models.
\newblock In {\em Proc. of the 32nd Ann. Int'l Colloq. on
  Algorithms, Langauages, and Programming}, pages 627--638, 2005.



\bibitem{GSV04}
K.~Gutenschwager, S.~Spiekermann, and S.~Vos.
\newblock A sequential ordering problem in automotive paint shops.
\newblock {\em Int'l J. of Production Research, 42(9):1865--1878},
  2004.



\bibitem{KRSW04}
J.~Krokowski, H.~R{\"a}cke, C.~Sohler, and M.~Westermann.
\newblock Reducing state changes with a pipeline buffer.
\newblock In {\em Proc. of the 9th Int'l Workshop on Vision, Modeling and Visualization},
  page 217, 2004.



\bibitem{RSW02}
H.~R\"{a}cke, C.~Sohler, and M.~Westermann.
\newblock Online scheduling for sorting buffers.
\newblock In {\em Proc. of the 10th Ann. European Symp. on Algorithms},
  pages 820--832, 2002.



\end{thebibliography}

\newpage
\appendix
\begin{proofof}{Lemma \ref{lm: resource augmentation}}
Given an an input sequance , let  be an optimal solution to the reordering buffer problem
that uses a buffer of size .
We define an algorithm, , that uses a buffer of size  and the optimal solution . 
In particular,  is offline. (We abuse notation and denote by 
 and  also the cost of these respective solutions.)
Observe that we may assume that after each time  finishes evicting
a color, this color will not appear in the input sequence again.
(After each eviction, we can rename all the following occurences 
with a new color  without incurring any additional cost.)
We can therefore denote by color  the 'th color that 
evicts.
Consider a time  during the execution of .
Denote by  the minimum color in 's buffer.
For any color , denote by  the number of items
of color  in 's buffer. For any color , 
define the potential  of color  by .
Finally, we define for each color  a counter  initialized
to . Intuitively, this counter counts the number of items 
larger than  that were evicted so far.
Notice that , , , and  are all a functions of 
. 
The algorithm  works as follows.\\
For any time .
\begin{enumerate}
\item If the eviction of color  will evict 
the last item of this color in , evict color . 
\item Otherwise, let  be the color with the maximum potential
in 's buffer. Evict exactly the  items of this color
currently in the buffer (without appending any aditional 
arriving items of the same color).\\
If after the eviction we cannot execute Step~1, we update 
 for every , by increasing  by .
\end{enumerate}

We start by proving a bound on .
\begin{claim}
For any color , at any time during the execution of the algorithm, 
.
\end{claim}
\begin{proof}
Notice that it is sufficient to bound  in any point in time,
as this is the maximum counter among the colors that their 
 can still increase.
Assume for contradiction that at a given time  the counter 
 became larger than  (right after removing a color by Step~2). 
Consider this time . Let  be the number of items  evicted from 
items of a color smaller than  (this equals to the number of items with
 a color smaller than ). Let  be the 
number of items  evicted from color .
At time ,  started evicting color ,
therefore at time , if the buffer evicted at
most  items from color , evicting this color will reach 
the last item of .
On the other hand, 
because  is at least the number of items from colors larger than
 that were evicted so far,
it holds that 

This is in contradiction to Step~2, as the counter is increased only if 
we cannot apply Step~1.
\end{proof}

Next we show a lower bound on the potential.
\begin{claim}
Consider a time  right before executing Step~2.
The maximal potential is .
\end{claim}
\begin{proof}
Denote .
Assume for contradiction that for any color  we have that 
. Therefore, , and , 
for every color  in the buffer.
Because there are exactly  items in the buffer, 

Thus, the claim follows.
\end{proof}

We are now ready to prove our lemma.
Notice that the number of times  executes Step~1
is at most . Furthermore, notice that 
in every execution of Step~2 , except for  executions,   is increased 
by at least .
Because , there could be at most 
 executions.
Therefore, 

and the lemma then follows.
\end{proofof}

\end{document}
