\documentclass{llncs}

\usepackage{latexsym}
\usepackage{graphicx,ulem,algorithm2e,algorithmic}
\usepackage {todonotes}
\usepackage{amsmath}


\newtheorem{defn}{Definition}

\newcommand{\ra}{\rightarrow}
\newcommand{\ora}{\stackrel{\bullet}{\rightarrow}}

\newcommand{\Lra}{\Longrightarrow}
\newcommand{\lra}{\longrightarrow}
\def\l#1{{{[_{}}_{}}_{#1}}
\def\r#1{{{\ ]_{}}_{}}_{#1}}
\newenvironment{keywords}{
       \list{}{\advance\topsep by0.35cm\relax\small
       \leftmargin=1cm
       \labelwidth=0.35cm
       \listparindent=0.35cm
       \itemindent\listparindent
       \rightmargin\leftmargin}\item[\hskip\labelsep
                                     \bfseries Keywords:]}
     {\endlist}
\usepackage{verbatim}


	\title{PROJECTION Algorithm for Motif Finding on GPUs}
	\author{Jhoirene B. Clemente, Francis George C. Cabarle, \and Henry N. Adorna}
	\institute{Algorithms \& Complexity Lab\\
Department of Computer Science\\
University of the Philippines Diliman\\
sDiliman 1101 Quezon City, Philippines\\
E-mail: \tt{\{jbclemente, fccabarle, hnadorna\}@up.edu.ph } }

\begin{document}	
\maketitle

\begin{abstract}
Motif finding is one of the NP-complete problems in Computational Biology. Existing nondeterministic algorithms for motif finding do not guarantee the global optimality of results and are sensitive to initial parameters. To address this problem, the PROJECTION algorithm provides a good initial estimate that can be  further refined using local optimization algorithms such as EM, MEME or Gibbs. For large enough input (600-1000  per sequence) or for challenging motif finding problems, the PROJECTION algorithm may run  in an inordinate amount of time. In this paper we present a parallel implementation of the PROJECTION algorithm in  Graphics Processing Units (GPUs) using CUDA. We also list down several major issues we have encountered including  performing  space optimizations because of the GPU's space limitations.
\end{abstract}
\begin{keywords}
motif finding, parallel computing , GPU, CUDA
\end{keywords}
		
\section{Introduction}\label{intro}


Motif finding problem (MFP) is the detection of overrepresented pattern  in sequences, and has become  a central problem in Computational Biology. Motifs can be transcription binding sites in DNA. These transcription sites regulate the expression of genes that are involved in similar cellular functions. Aside from identifying co-expressed genes,  motif finding can provide powerful hypotheses about links in the genetic regulatory networks \cite{manson}. Additionally, discovery of such patterns will help in the development of treatments and the identification of disease susceptibility \cite{shashidhara}.

Finding motifs is considered to be computationally hard, since it is considered to be an \textit{NP-complete} problem \cite{pevznerBook}. Existing algorithms are classified into two main categories: deterministic and nondeterministic\cite{yu}. Deterministic algorithms include the naive algorithm\cite{pevznerBook}, \textit{Statistical Enumerative Methods}, and \textit{Suffix Trees} \cite{pevznerBook}. Nondeterministic algorithms include \textit{Gibbs Sampling}\cite{yu}, \textit{Expectation Maximization}\cite{lawrenceEM} and \textit{Random Projection}\cite{tompa}. Deterministic algorithms assure the optimality of results,  however they are time consuming and are less effective for longer motifs. Nondeterministic algorithms are usually preferred for large input data,  since they do not require high computational complexity and are also effective for longer motifs. Nondeterministic algorithms do not guarantee the optimality of result since they are also sensitive to initial configurations. Aside from these two main categories, several algorithms use both techniques to compromise the advantages and disadvantages of using one of the two categories described. These hybrid algorithms include the works of \cite{shashidhara}, and Hybrid Gibbs sampling by \cite{hybridGibbs}.

With the flood of information and the volume of data we have nowadays, parallel algorithms and their implementation remain as important computational challenges in order to further boost performance and to keep up with the huge amount of data. Aside from traditional CPU-based grids and clusters the computational sciences, including biology, are using massively parallel hardware such as Graphics Processing Units (GPUs). GPUs are highly scalable (run thousands of cores easily), cheaper (by cost acquisition and maintenance) and provide performance increase and ease of use. Numerous Bioinformatics algorithms have been implemented using GPUs: BLAST, Smith-Waterman, Multiple Sequence Alignment, and Sequencing. Specifically, for motif finding there is Parallel Gibbs Sampling, CUDA-MEME\cite{liu}, and mCUDA-MEME\cite{liu}.  Brief discussions of these algorithms are presented in Section \ref{mfp_algorithms}.

\section{Motif Finding Problem}\label{motifFindingProblem}
\noindent  \textit{Regulatory motifs} in DNA are short sequences of patterns that occur in several locations of the genome as transcription binding sites or as a response to certain conditions. An example is the regulatory motif  in  fruit flies. Whenever flies are infected by pathogens (e.g. viruses, bacteria), they have an \textit{immunity gene} that is switched on to produce a certain protein used as an immune response. The gene responsible for the protein transcription will occur frequently at random positions on its genome. Finding motifs is not restricted to DNA, since it was first used in proteins for discovering transcription factors. Computationally, we can represent the genome and the patterns as strings, and the problem will be translated into finding a pattern of a given length that occurs frequently in the set of all strings. We first define notations before formally defining MFP.

\begin{itemize}

\item \textit{Sequences} denotes the list of  strings, where each  has length . 

\item The alphabet  is defined to be  for DNA with cardinality  and  for protein with cardinality . 

\item The length of  a motif may be a range denoted by an ordered pair (,) or a constant , where , , and  are positive integers usually in the range .

\item An -mer is a string of length  defined over some . 

\item The notation  is an -mer from , starting with the th position of the sequence.

\item The starting position vector , contains the list of starting positions of each -mer for each sequence, .

\item An \textit{alignment matrix}  with dimension equal to  is derived from a vector of starting positions , each row  corresponds to an -mer .

\item A \textit{profile matrix}  with dimension equal to  is derived from the frequency of each letter in each column of the \textit{alignment matrix}.
\end{itemize}

{ represents the four nucleotide bases of the DNA: , , , and  }respectively. { are amino acid bases of proteins. Figure \ref{Sequences} gives an illustration of an instance of \textit{Sequences} while Figure \ref{alignment-profile} shows the corresponding  and .

\begin{figure}[h]
\centering
\begin{tiny}
\begin{tabular}{l c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c}
 & C& G& G& G& G& C& T& A& T& G& G& A& A& C& T& G& G& G& T& C& G& T& C& A& C& A& T& T& C& C& C& C& T& T& T& C& G& A& T& A\\
 & T& T& T& G& A& G& G& G& T& G& C& C& C& A& A& T& A& A& A& T& G& C& C& A& C& T& C& C& A& A& A& G& C& G& G& A& C& A& A& A\\
 & G& G& A& T& G& C& A& A& C& T& G& A& T& G& C& C& G& T& T& T& G& A& C& G& A& C& C& T& A& A& A& T& C& A& A& C& G& G& C& C\\
 & A& A& G& G& A& T& G& C& A& A& C& T& C& C& A& G& G& A& G& C& G& C& C& T& T& T& G& C& T& G& G& T& T& C& T& A& C& C& T& G\\
 & A& A& T& T& T& T& C& T& A& A& A& A& A& G& A& T& T& A& T& A& A& T& G& T& C& G& G& T& C& C& A& T& G& C& A& A& C& T& T& C\\
 & C& T& G& C& T& G& T& A& C& A& A& C& T& G& A& G& A& T& C& A& T& G& C& T& G& C& A& T& G& C& A& A& C& T& T& T& C& A& A& C\\
 & T& A& C& A& T& G& A& T& C& T& T& T& T& G& A& T& G& C& A& A& C& G& T& G& G& A& T& G& A& G& G& G& A& A& T& G& A& T& G& C\\
\end{tabular}
\end{tiny}

\caption{ , with  for }
\label{Sequences}
\end{figure}



\begin{figure}[h]
\begin{center}
\begin{small}

\begin{tabular}{l l l c c c c c c c c}
					&: 	&	A&T&G&G&A&A&C&T\\
					&:	&	A&T&G&C&C&A&C&T\\
					&:	&	A&T&G&C&A&A&C&T\\
\textbf{Alignment}	&	: &	A&T&G&C&A&A&C&T\\
					&	: &	A&T&G&C&A&A&C&T\\
					&: &	A&T&G&C&A&A&C&T\\
					&	: &	A&T&G&C&A&A&C&G\\
					\hline \\
					& \textbf{A}	: &	\textbf{7}&0&0&0&\textbf{6}&\textbf{7}&0&0 \\
					& \textbf{T}	: &	0&\textbf{7}&0&0&0&0&0&\textbf{6}\\
\textbf{Profile}	& \textbf{C}	: &	0&0&0&\textbf{6}&1&0&\textbf{7}&0\\
					& \textbf{G}	: &	0&0&\textbf{7}&1&0&0&0&1\\
					\hline \\
\textit{Consensus String}		&& \textbf{A} & \textbf{T} & \textbf{G} & \textbf{C}& \textbf{A} & \textbf{A}& \textbf{C}&\textbf{T} \\
					
\end{tabular}
\end{small}
\caption{the alignment   corresponding to the set of strings  and the  profile matrix  with , and }
\label{alignment-profile}
\end{center}
\end{figure}

From the  we define , where , be the maximum number at th column of the profile matrix (elements of   written in boldface) e.g.  = 7, and  = 6 .  We define a \textit{consensus string} to be an -mer, where each of its element is the nucleotide base corresponding to . For instance, the consensus string in Figure \ref{alignment-profile} is `ATGCAACT', and there can exist an instance where  will correspond to more than one letter so we choose one arbitrarily from the choices. Thus the consensus string for a given  is not unique. We define the \textit{Score(s,DNA)}, to be equal to  The \textit{Score} in the above example is . We use the \textit{Score} to evaluate the strength of a given alignment. Below is the formal definition of the MFP on DNAs.


\begin{definition} \label{mfpDefinition} \textbf{Motif finding Problem(MFP)} \\
\noindent INPUT: A  matrix of DNA, and , the length of the pattern to find\\
OUTPUT: An array = () maximizing \textit{Score(s,DNA)}
\end{definition}

MFP maximizes the \textit{Score(s,DNA)} function over all possible starting positions. The maximum value for \textit{Score} is  which corresponds to the best possible alignment, where each row for each column has the same element. However, having a consensus score equal to  corresponds to the worst possible alignment, where each column has an equal distribution of nucleotide bases. The algorithm for the naive MFP is given in Algorithm \ref{naivemfp}. 

\begin{algorithm}\label{naivemfp}
\KwIn{, }
\KwOut{}
~\\
\begin{verbatim}    
    Procedure NAIVEMFP:
        bestScore <- 0
        For each s in (1,1,..1) to (n-l+1, n-l+1,...n-l+1)
        	if Score(s,DNA) > bestScore
    	       bestScore <- Score(s,DNA)
    	       bestMotif <- Consensus(s)
        return bestMotif
    end Procedure NAIVEMFP	
	
\end{verbatim}	
\caption{Algorithm for naive MFP solver.}
\end{algorithm}

Note that in Algorithm \ref{naivemfp} we need to exhaust all possible starting positions and compute the \textit{Score} to be able to determine  with the best possible alignment. The total number of starting positions to test is , which is exponential in . The computation of \textit{Score(s,DNA)} will take . Therefore, the running time complexity of the naive MFP algorithm is .
To reduce the running time complexity of motif finding, \cite{pevznerBook} uses the concept of median string to exhaust the possible motifs. With the inclusion of this idea, the running time complexity of finding motif  is reduced to .

For these algorithms, the assumption is that, each sequence contains exactly one occurrence of the motif. This assumption follows the basic search model called \textit{OOPS} (One Occurrence per Sequence). Other models are \textit{ZOOPS} and \textit{TCM}.\textit{ ZOOPS} (Zero or One Occurrence per Sequence) is the generalized model for \textit{OOPS}, where we assume that for each sequence the occurrence of the motif is at most one i.e. we allow a sequence without any occurrence of the motif. \textit{TCM} (Two component mixture) model assumes that each sequence may contain zero or more occurrence of the motif. 

In some cases, occurrences of motif in sequences may vary due to mutations or genome rearrangements, and  motif finding algorithms become even more challenging. Because of this reason, \cite{pevznerBook} defined a specific variant of MFP in which we expect  mutations from each occurrences of the motif. This variant is called motif finding, and is similar to our previous definition except for the fact that each occurrence(s) of motif  in sequence , , the edit distance of  in each of those occurrence(s) is . 


Experiments from \cite{tompa} showed that their \textit{PROJECTION} algorithm performs better than existing algorithms in solving this specific variant. In addition to this, most of the challenging problem instances like (14-4), (16,5), and (18,6)  were successfully computed. Details for the PROJECTION algorithm will be discussed in Section \ref{projection}.

\section{Algorithms for Motif Finding}\label{mfp_algorithms}
Algorithms for motif finding can be classified into two main categories: deterministic (\textit{word-based enumerative methods}) and nondeterministic (\textit{probabilistic sequence models}). The \textit{word-based models}  rely on exhaustive enumeration, counting and comparing nucleotide frequencies. These algorithms include the naive implementation in Algorithm \ref{naivemfp}, branch and bound techniques, and suffix trees. Meanwhile, the \textit{probabilistic sequence models} rely on model parameters that are estimated using Likelihood computation and Bayesian inference. This category includes algorithms such as Gibbs Sampling\cite{yu}, Expectation Maximization\cite{liu} and Random Projection\cite{tompa}.

Word-based methods guarantee global optimality of result, and are appropriate for short motifs. However, for longer motifs and weakly constrained positions, word-based methods may become problematic due to their high computational complexity. The probabilistic sequence models require few search parameters, and are more effective for longer and general motifs. These algorithms are  dependent on probability matrices, and are called  Position Specific Scoring Matrix(PSSM),  model, and frequency matrix in Gibbs Sampling, Expectation Maximization and Random Projection respectively. The probabilistic sequence models however do not guarantee the global optimality of the results, but these models do run significantly faster than the previous models by giving good enough solutions. 


\section{GPU computing}

In 2007 NVIDIA, a well-known graphics processor manufacturer, introduced the \textit{Compute Unified Device Architecture (CUDA)} as an update of their G80 line of GPUs \cite{cudabook}.CUDA provides numerous advances in massively parallel computations: (a) allowing programmers to declare only the resources they need (threads/ computatonal units and memory space used). Though additional conversion is needed for the input data, CUDA can significantly reduce the running time of methods related to string comparison, among other methods (b) hardware improvements such as abstracted performance scaling from a GPU with fewer cores to another with more cores (c) introduction of memory and computational unit hierarchy, (d) latency hiding etc. \cite{cudaguide,cudabook}. All of these help boost parallel computations in GPUs compared to CPU-based clusters or grids which require enormous amounts of money to setup and maintain. Comparable CPU cluster performance can be achieved by buying graphics cards from computer resellers at about 65535 \times 65535)(512 \times 512 \times 64)vnh_k(v)kvh_k(v)v(l,d)tlndksm(l-k)[0,l]xth_k(x).k(h_k(x))|\Sigma|^kksm(l,d)MM_iS_id(M,M_i)=dkMM_il-dkk(l-d-1)st\cdot(n-l+1)/4^kst\cdot(n-l+1) << 4^ks = (3,4)mmqsmm\hat{t}\hat{p}(l,d,k)skB_{\hat{t},\hat{p}(l,d,k)}(s)ExpectationExpectationSequences1,\ 2,\ 3,\ 5,6s4k7l\{S_{1,8}, S_{2,19}, S_{3,3} ,S_{4,5}, S_{5,31}, S_{6,27}S_{7,15})\theta^0\theta(t\ \times\ (l+1)) \theta\sigma_ij1 \leq j \leq l\sigma_ij=0\sigma_i\Sigma = \{\sigma_1, \sigma_2, \ldots\}S_{1,8}S_{2,19}S_{3,3}S_{4,5}S_{5,31}S_{6,27}S_{7,15}\theta^{0}\theta^0Expectation = 8.58 SSequencesExpectationn(600-1000)kx = t \cdot (n-l+1)lSequenceslkO(l \cdot x)O(l \cdot x)O(x)O(|\Sigma|^k)O(x)O(r \cdot x)rkO(x)O(l \cdot x)lxO(|\Sigma|^k)lkO(l \cdot x)O(l \cdot x)O(x^2)O(x)kkO(x)O(r \cdot x)rO(x^2)O(x)ltlndksm(l-k)[0,l]xth_k(x)k(h_k(x))|\Sigma|^k(l-k)0lk(l-d-1)(l-k)kk(l-k)ltlSequenceslxh_k(x)lSequenceskh_k(1,2,3,4, 7)k|\Sigma|10\{0, .. ,|\Sigma|\}\Sigma\{(A:0), (C:1), (T:2), (G:3)\}07kk4^kO(4^k)O(t \cdot t \cdot (n -l +1) )kkkkpid(k-mer) = \{pid^{'}_0, ..., ,pid^{'}_c\}kpid=kpid^{'}_0=\ldots =kpid^{'}_cc\geq skkkpidkbkbmx=  t \cdot (n - l +1) lkO(t \cdot n)lO(l \cdot x)kO(k \cdot x)O(x)O( r \cdot x)rkkr(t\cdot s)kstkkkt4^kyx(l,d)l l > 174^k(r \cdot x)t=20n=6004^klkO(l)O(l \cdot x)O(k)k10O(k)O(x)kkO(x)O(r \cdot x)rkO(x)O(x)O(x)O(x)$. Compared to PROJECTION1, our implementation achieved no speedup but we significantly reduced the space complexity. Compared to PROJECTION2, our implementation uses the same amount of space with linear speedup. In other words, CUDA-PROJECTION captures the best side of both sequential implementations. 

\section*{Acknowledgments}
Jhoirene Clemente and Francis George Cabarle are supported by the {DOST-ERDT program}. Henry Adorna is funded by the {DOST-ERDT research grant} and the Alexan professorial chair of the {UP Diliman Department of Computer Science}.



\bibliographystyle{ieee}
\begin{thebibliography}{99}
\bibitem{bailey} Bailey T L., ``Discovering Motifs i DNA and Protein Sequences: The Approximate Common Substring Problem", 1995, Ph.D. Dissertation, University of California San Diego
\bibitem{tompa}Buhler J., and Tompa M., ``Finding Motifs Using Random Projections", 2001, RECOMB '01 Proceedings of the fifth annual international conference on Computational biology
\bibitem{chen}Chen C., Schmidt B., Liu W., and Muller-Wittig W., ``GPU-MEME: Using Graphics
Hardware to Accelerate Motif Finding in DNA Sequences.", 2008, LNCS 5265, 448-459.
\bibitem{dempster} Dempster A P., Laird N M., and Rubin D B., ``Maximum Likelihood from Incomplete Data via the EM Algorithm", 1977, Journal of the Royal Statistical Society, Series B
\bibitem{gpgpu} M. Harris, ``Mapping computational concepts to GPUs'', {\it ACM SIGGRAPH 2005 Courses}, NY, USA, 2005.
\bibitem{hertz} Hertz G Z., and Stormo G. D.,``Identifying DNA and Protein Patterns with Statistically Significant Alignments of Multiple Sequences", 1999, Bioinformatics, 15:563-577
\bibitem{pevznerBook} Jones N.,and Pevzner P.,``An Introduction to Bioinformatics Algorithms", 2004, Massachusetts Institute of Technology Press 
\bibitem{cudabook} D. Kirk, W. Hwu, {\it Programming Massively Parallel Processors: A Hands On Approach}, 1st ed. MA, USA: Morgan Kaufmann, 2010.
\bibitem{manson} McGuire A., and Church G., ``Discovery of DNA Regulatory Motifs", Harvard University Medical School
\bibitem{lawrenceEM} Lawrence C., Reilly A., ``An Expectation Maximization Algorithm for the Identification and Characterization of Common sites in Unaligned Biopolymer Sequences.", 1990, Proteins 7 (1), 41-51
\bibitem{lawrenceGibbs} Lawrence C., Altschul S., Boguski M., Liu J., Neuwald A.,and Wootton J., ``Detecting subtle sequence signals: A Gibbs sampling strategy fr multiple alignment", 1993, Science 262, 208-214 
\bibitem{liu} Liu Y., Schmidt B., Liu W.,and Maskell D. , ``CUDA-MEME: Accelerating Motif Discovery in Biological Sequences Using CUDA-enabled Graphics Processing Units",2009, Pattern Recognition Letters 31, 2170-2177
\bibitem{parkMiller} Park S., and Miller K.W.,``Random Number Generator: Good ones are Hard to Find", 1988, COMM, ACM 31, 1192-1201
\bibitem{shashidhara} Shashidhara H S., Joseph P. ,and Srinivasa K G., ``Improving Motif Refinement using Hybrid Expectation Maximization and Random Projection", ISB 2010, Feb 15-17, Calicut India
\bibitem{hybridGibbs} Shida K., ``Hybrid Gibbs-Sampling Algorithm for Challenging Motif Discovery: GibbsDST", 2006, Genome Informatics 17(2): 3-13
\bibitem{yu} Yu L., and Xu Y., ``Parallel Gibbs Sampling Algorithm for Motif Finding on GPU", 2009, IEEE International Symposium on Parallel and Distributed Processing with Applications
\bibitem{cudaguide} NVIDIA corporation,{\it ``NVIDIA CUDA C programming guide''}, version 3.2, CA, USA: NVIDIA, 2011.
\end{thebibliography}
\end{document}