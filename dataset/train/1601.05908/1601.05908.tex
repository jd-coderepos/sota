



\documentclass[preprint,3p,times,twocolumn,authoryear]{elsarticle}




\usepackage{graphics}


\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{multirow}
\usepackage{subfigure}






\usepackage[lined, linesnumbered, ruled]{algorithm2e}





\biboptions{comma,round}


\journal{Journal of Network and Computer applications}

\begin{document}

\begin{frontmatter}





\title{Agile-SD: A Linux-based TCP Congestion Control Algorithm for Supporting High-speed and Short-distance Networks}




\author[lable1]{Mohamed A. Alrshah}
\author[lable1]{Mohamed Othman}
\author[lable2]{Borhanuddin Ali}
\author[lable1]{Zurina Mohd Hanapi}
\address[lable1]{Department of Communication Technology and Network, Universiti Putra Malaysia, 43400 UPM, Serdang, Selangor D.E., Malaysia}
\address[lable2]{Department of Computer and Communication Systems Engineering, Universiti Putra Malaysia, 43400 UPM, Serdang, Selangor D.E, Malaysia.}

\begin{abstract}
Recently, high-speed and short-distance networks are widely deployed and their necessity is rapidly increasing everyday. This type of networks is used in several network applications; such as Local Area Networks (LAN) and Data Center Networks (DCN). In LANs and DCNs, high-speed and short-distance networks are commonly deployed to connect between computing and storage elements in order to provide rapid services. Indeed, the overall performance of such networks is significantly influenced by the Congestion Control Algorithm (CCA) which suffers from the problem of bandwidth under-utilization, especially if the applied buffer regime is very small. In this paper, a novel loss-based CCA tailored for high-speed and Short-Distance (SD) networks, namely Agile-SD, has been proposed. The main contribution of the proposed CCA is to implement the mechanism of agility factor. Further, intensive simulation experiments have been carried out to evaluate the performance of Agile-SD compared to Compound and Cubic which are the default CCAs of the most commonly used operating systems. The results of the simulation experiments show that the proposed CCA outperforms the compared CCAs in terms of average throughput, loss ratio and fairness, especially when a small buffer is applied. Moreover, Agile-SD shows lower sensitivity to the buffer size change and packet error rate variation which increases its efficiency.

\end{abstract}

\begin{keyword}
Agile\sep
CCA\sep
TCP\sep
Linux\sep
High-speed\sep
Short-distance\sep
Bandwidth Utilization\sep
Fairness\sep
Small Buffer.
\end{keyword}

\end{frontmatter}

\footnotetext[1]{Corresponding authors: 
\\E-mail addresses: mohamed.asnd@gmail.com (Mohamed Alrshah),\\mothman@upm.edu.my (Mohamed Othman).}

\footnotetext[2]{The author is also an associate researcher at the Computational \mbox{Science} and Mathematical Physics Lab, Institute of Mathematical \mbox{Science}, Universiti Putra Malaysia.}





\section{Introduction}
\label{Intro}
In the last decades, the necessity of high-speed and short-distance networks is rapidly increasing everyday due to their wide deployment. Several network applications, such as Local Area Networks (LAN) and Data Center Networks (DCN), are implementing this type of networks \citep{Buyya2008, Armbrust2010}. These LANs and DCNs serve a very wide range of network-based applications; such as web hosting, searching engines, social media, multimedia broadcasting and storage drives. In the environment of LANs, as shown in Figure \ref{fig:lantopology}, and DCNs, as shown in Figure \ref{fig:dctopology} \citep{Alfares2010, Wu2012, Yoo2012, prakash2012}, high-speed and short-distance networks are commonly deployed to connect computing and storage elements to each other in order to provide rapid services.These networks have certain characteristics which are widely different from other types of networks; for instance, link delay is very small which can be a few milliseconds or even hundreds of microseconds and the Bandwidth-Delay-Product (BDP) of the link is very small compared to its equivalent in high-speed and long-distance networks \citep{Tahiliani2012, Vasudevan2009}.

These attributes could negatively affect the performance of the Transmission Control Protocol (TCP) by making it either more aggressive or more conservative based on the applied approach. In fact, the Congestion Control Algorithm (CCA) is one of the main parts of TCP. It significantly affects the overall performance of such networks, because it is still suffering from the problem of bandwidth under-utilization, especially if the applied buffer regime is very small. This under-utilization of bandwidth is caused by the variation of the aforementioned characteristics of the networks which results either a slow growth of  or an over-injection of data into the network \citep{Afanasyev2010, Scharf2011, Callegari2012b, Callegari2014, Lar2013, acharya2012, alrshah2014}.

In order to solve the problem of bandwidth under-utilization over high-speed and Short-Distance (SD) networks, a new loss-based CCA, namely Agile-SD, has been proposed. The main contribution of the proposed CCA is to implement the mechanism of agility factor. Further, intensive simulation experiments have been carried out to evaluate the performance of Agile-SD compared to Compound (the default CCA of MS Windows since Windows Vista) and Cubic (the default CCA of Linux since Kernel 2.6.16) which are the default CCAs of the most commonly used operating systems \citep{Afanasyev2010, alrshah2014}.

The rest of this paper is organized as follows: the related work is presented in Section \ref{RW} while Section \ref{Agile-SD} presents the proposed algorithm \textquotedblleft Agile-SD\textquotedblright. Section \ref{PE} explains the used approach of performance evaluation which is contains the experiments' setup, network topology, performance metrics, results and discussion. Finally, Section \ref{Conc} presents the conclusion and the future work.

\section{Related Work}
\label{RW}

In order to solve the problem of bandwidth under-utilization, Cubic \citep{Ha2008}, Scalable TCP \citep{Kelly2003}, HS-TCP \citep{Floyd2003}, BIC \citep{xu2004}, HCC \citep{xu2011}, H-TCP \citep{Leith2004}, TCP Africa \citep{King2005}, TCP Compound \citep{Tan2006}, Fusion \citep{Kaneko2007}, TCP illinois \citep{Liu2008} and YeAH \citep{Baiocchi2007} have been developed and implemented in the real operating systems. All of these TCP variants are still unable to fully utilize the available bandwidths of high-speed networks, especially if the used buffer size is less than the BDP of the link \citep{Afanasyev2010, Scharf2011, Callegari2012b, Callegari2014, Lar2013, acharya2012, alrshah2014}. 

Further, some researchers tried to solve the aforementioned problem by proposing a set of CCAs or TCP variants; such as DCTCP \citep{Alizadeh2010}, ICTCP \citep{Haitao2013}, IA-TCP \citep{Jaehyun2012} and DTCP \citep{Vamanan2012} which designed for data center networks. All of these TCP variants are still suffering from some critical problems, such as the problem of TCP outcast which has not been solved yet \citep{Tahiliani2012}.

Furthermore, some researchers tried to improve the performance of TCP by using parallel approaches; such as AppTCP \citep{Wang2013}, GridFTP \citep{allcock2005}, pTCP \citep{hsieh2002}, BBCP \citep{hanushevsky2001}, PSockets \citep{sivakumar2000}, MulTCP \citep{crowcroft1998}, DPSS \citep{Tierney1994} and Parallel-TCP \citep{alrshah2009, alrshah2013}. Most of parallel schemes have achieved high bandwidth utilization, but unfortunately they have another issues which limited their deployments. One of these issues is that all of the parallel schemes have a very high aggressiveness level compared to the existing single-based TCP variants. This aggressive behavior negatively affects the fairness \citep{Fu2005, fu2007}.

\begin{figure} [t]
\centering
\includegraphics[width=1\linewidth]{lantopology.pdf}
\caption{A Network Topology for LAN.}
\label{fig:lantopology}
\end{figure}

\begin{figure}[t]
\centering
\includegraphics[width=1\linewidth]{dctopology.pdf}
\caption{Multi-rooted Hierarchical Topology of Data Centers.}
\label{fig:dctopology}
\end{figure}

However, the widely deployed CCAs; such as Compound and Cubic which have been set as the default CCAs in MS Windows and Linux operating systems, respectively; are playing the important role in the real networks. Thus, Compound and Cubic should be used as a benchmark, to confirm the performance of any newly proposed CCA or TCP variant. For this reason, these two CCAs are going to be briefly explained in the next subsections.

\subsection{Compound TCP (C-TCP)}
The widely deployed TCP variant namely C-TCP \citep{Tan2006} is the default CCA of MS Windows since Windows Vista. C-TCP combines HS-TCP \citep{Floyd2003} and NewReno \citep{floyd1999} to be used as fast and slow modes, respectively. C-TCP is a loss-delay-based approach relies on multi-modes switching to increase the bandwidth utilization over high-speed networks. Generally, it improves the performance of TCP to some extent but it introduces another problem which is the RTT mis-estimation. This problem has been inherited from Vegas \citep{brak1995} and it can negatively affect the overall performance of the protocol \citep{Afanasyev2010, alrshah2014}.

\subsection{CUBIC TCP (Cubic)}
Cubic \citep{Ha2008} is the default CCA of Linux operating systems since its implementation in Kernel 2.6.16. Cubic enhances the bandwidth utilization over high-speed networks by increasing the  in the congestion avoidance phase by a  function of the elapsed time since last loss. In addition, Cubic forces its  not to be less than the pre-calculated  of NewReno. Despite of all, Cubic is still suffering from the under-utilization of high-speed bandwidth specifically when the used buffer size is small \citep{Afanasyev2010, alrshah2014, Ha2008}.

\subsection{The Latest Issues}
Recent studies have revealed that all of the current TCP variants have different levels of inability on fully utilizing the bandwidths over the new generation of high-speed networks, especially if a \emph{near-zero} buffer is applied. Thus, it becomes very necessary to design a new CCA to increase the bandwidth utilization over such networks \citep{Afanasyev2010, alrshah2014}.




\section{Agile-SD: The Proposed Algorithm}
\label{Agile-SD}

Algorithm \ref{algo01} explains the Agile-SD mechanism which is geared to work on high-speed and short-distance networks to enhance the overall performance and bandwidth utilization while preserving the fairness. Moreover, Figure \ref{fig:TCP} shows the flow control diagram of Agile-SD and the following subsections explain the proposed algorithm in more details.

\SetKwProg{Function}{Function}{ }{end}
\SetKwProg{Event}{Event}{ do}{end}
\begin{algorithm}[t!]
\caption{Agile-SD Congestion Avoidance.}\label{algo01}

\textbf{Initialization:}\\
\hspace{0.5cm}\\
	\hspace{0.5cm}\\
	\hspace{0.5cm}

\Event{On ACK Receiption}
{
	calculate  as in Equation (\ref{eq3})\\
	
	calculate  as in Equation (\ref{eq2})\\

	calculate  as in Equation (\ref{eq1})\\

	


	\\
}

\Event{On Loss Detection of 3-duplicated ACKs}
{
	\\
	
	\uIf {}
	{	
		 \label{L13}\\
	}
	\Else
	{
		 \label{L17}\\
	}
	
	\\
	\\
}
\end{algorithm} \DecMargin{1em}


\begin{figure}[h!]
\centering
\includegraphics[width=0.7\linewidth]{TCP.pdf}
\caption{The flow control diagram of Agile-SD.}
\label{fig:TCP}
\end{figure}

\subsection{The Agility Factor Mechanism}
As known, \citet{RFC6928} increases the initial value of TCP  to 10 packets, but Agile-SD initializes its  by 2 packets in order to focus on the impact of CA on bandwidth utilization. However, in the future implementations the initial  should be set to 10 to gain better bandwidth utilization.

Clearly, Agile-SD increases its  in the stage of congestion avoidance by fraction similarly as the existing CCAs. But, Agile-SD increases its  by  to show a convex curve unlike the standard TCP which increases its  linearly by . The main contribution of Agile-SD is the unique  growth function which relies on the agility factor mechanism which symbolized by , as shown in Equation \eqref{eq1}.
\begin{figure}[t]
\centering
\includegraphics[width=\linewidth]{epoch.pdf}
\caption{The  evolution of Agile-SD and the standard TCP.}
\label{fig:epoch}
\end{figure}

where,  exemplifies the amount of decrease in the  which caused by the loss event. In other words,  represents the released amount from the bandwidth after loss.  is calculated as the distance between the maximum recorded limit of the bandwidth () and the  as in Equation \eqref{eq2}.


While,  is calculated as the difference between the maximum recorded limit of the bandwidth () and the current , as in Equation \eqref{eq3}.


Simply,  is used to mitigate the impact of loss degradation on the overall performance of TCP. Specifically,  shortens the time of epoch which is needed by CCA to move its  from  to  or to the maximum allowed , as shown in Figure \ref{fig:epoch}. In order to increase the bandwidth utilization,  speeds up the growth of  when the current  is far away from the last . While, it conservatively slows down the growth of  when the current  nearing to the last .

More specifically, to ensure that the performance of Agile-SD is not less than the standard TCP,  must be always set to 1 while  must be always set to a value . However, if  is set to 1, Agile-SD will behave exactly similar to NewReno. But, if it was set to a value , such as 2, 3 or 4, it would clearly improve the overall performance. 

\begin{figure} [t]
\centering
\includegraphics[width=0.9\linewidth]{factor.pdf}
\caption{The concept of agility factor mechanism .}
\label{fig:factor}
\end{figure}

\begin{figure} [t]
\centering
\includegraphics[width=0.9\linewidth]{fraction.pdf}
\caption{Relation between  and the bandwidth utilization.}
\label{fig:fraction}
\end{figure}


After loss detection by receiving three duplicate ACKs, Agile-SD initiates its agility factor by , then reduces it every cycle towards . Nevertheless, it restarts by  again if another three duplicate ACKs are received as shown in Figure \ref{fig:factor}. Consequently, it is very clear that  is directly proportional to , and  is reversely proportional to the current size of , as shown in Figure \ref{fig:fraction}. In other words, the aggressiveness of the proposed algorithm increases whenever the difference between  and  increases, as in Equation \eqref{eq4}. 



Contrarily, it decreases its aggressiveness whenever the utilization is around to touch the maximum available bandwidth, as in Equation \eqref{eq5}. 


In general, Agile-SD reduces the cycle time which by its role reduces the epoch time to overcome the problem of slow evolution of  provided by the standard TCP, as shown early in Figure \ref{fig:epoch}. On one hand, this behavior guarantees the performance of Agile-SD not to be lower than the standard TCP. Thus, it increases the bandwidth utilization by improving the ability of Agile-SD to expose the condition of the underlying network as shown in Figure \ref{fig:fraction}. On the other hand, it reduces the sensitivity of Agile-SD to the loss rate.

\subsection{The Decrement of cwnd}

The standard TCP applies the \textit{Multiplicative} \textit{Decrease} mechanism which halves the  after any loss detection, by receiving three duplicate ACKs, regardless of which stage the loss is detected in. Unlikely, Agile-SD decreases its  after any loss detection by two ways based on the stage which the loss is coming from. First, if the loss is detected in the slow start stage, Agile-SD reduces its  to  of the latest  as shown at Line \ref{L13} in Algorithm \ref{algo01}. Second, if the loss is detected in the congestion avoidance stage, Agile-SD reduces its  to  of the latest   as shown at Line \ref{L17} in Algorithm \ref{algo01}. Moreover, Agile-SD sets the  to , after any degradation, in order to avoid slipping into an undesirable slow start.

Since, the loss which happens in the slow start stage is more severe than which happens in the congestion avoidance stage. Therefore, the value of  should be always less than . In other words, the reduction which follows a slow start loss should be greater than the reduction which follows a congestion avoidance loss. Also,  and  must be reversely proportional to their relative  but the relation among them is still under investigation to be revealed in the future work. Thus, whenever the values of  and  is increased, the value of  should be adaptively decreased and vice versa. For instance, if  and  are set to 0.9 and 0.95, respectively, where these values are compatible with . Then, if  and  are reduced to 0.85 and 0.9, respectively, the value of  should be increased to a value, such as 4 or 5, and so on.

\subsection{Agile-SD Overall Behavior}

Similar to standard TCP, Agile-SD starts by slow start to show an exponential increase until the detection of first loss; by receiving three duplicate ACKs. This reduces its  to  and triggers the congestion avoidance function. In this stage, Agile-SD increases its  by  to show a convex curve. But, if the  becomes closer to the bandwidth limit which is set as , it starts a linear increase until detecting another packet loss. If the event of packet loss is detected, Agile-SD reduces its  to  then repeats the same stages which follows the slow start stage. However, if timeout is detected at any stage, Agile-SD resets its  to the initial value, as shown in Figure \ref{fig:TCP}.

For more understanding, assume that there is a TCP link with  and a constant  equal to 20 ms, and the congestion avoidance stage is just started after the loss directly. Thus, the number of  needed by any CCA to reach  is 4 cycles which is equal to . Consequently, the epoch time needed by the standard TCP, which is , is the number of needed  times , so it will be equal to 80 ms. 

Instead, Agile-SD increases its  independently from the . Thus, every  consumes a time of  to send a number of  packets during that cycle, then it increases its  by 1. Consequently, the epoch time needed by Agile-SD will be equal to what shown in Equation \eqref{eq6}.

where  is the number of needed cycles. 

Suppose  and  are set to 1 and 4, respectively. So,  will take the value of [4, 3, 2, 1] sequentially, which will result in an epoch time equal to 41.66 ms. Thus, the epoch time of Agile-SD will be shrunk by around 48\% from the epoch time of the standard TCP on the same network link. This behavior helps Agile-SD to increase its  more quickly than the other compared CCAs and consequently improves the bandwidth utilization. In other words, the faster  growth is the higher bandwidth utilization and vice versa. 

\section{Performance Evaluation of Agile-SD}
\label{PE}
The goal of this work is, to develop a new CCA, namely Agile-SD, which has the ability of increasing the bandwidth utilization over high-speed and short-distance networks while maintaining fairness. \mbox{Agile-SD} CCA has been implemented as a pluggable Linux CCA module which can be plugged into any Linux Kernel. As well as, this module has the ability to be plugged into NS-2 network simulator, as a Linux TCP, in order to evaluate its performance compared to some of the widely deployed CCAs.

\subsection{The Experiments Setup}
In this work, intensive simulation experiments have been conducted using the well-known network simulator NS-2 version 2.35, to evaluate the proposed CCA by comparing its performance with C-TCP and \mbox{Cubic}. The conducted experiments have been divided into three main scenarios: single-flow, sequentially established/terminated multiple-flows, and synchronously established/terminated multiple-flows. Table \ref{params} shows the setting of the experiments' parameters as used in this work.
\begin{table}[h!]
	\caption{Experiment Parameters.}
	\begin{center}
	\begin{tabular}{p{0.15cm}p{2.24cm}p{4.16cm}} \hline
	No.& Parameter			&	Value									\\ \hline
	1. & CCAs				&	Agile-SD, Cubic, C-TCP					\\ 2. & Link capacity		&	1 Gbps for all							\\ 3. & Link delay			&	1ms (node to router)						\\ & 					&	4ms (router to router)					\\ 4. & BDP				&	750KB (As in \citep{RFC1072})			\\ 5. & PER				&   				\\6. & Buffer size		&	from 5 to 500 packets					\\ 7. & Packet size		&	1000 bytes								\\ 8. & Queuing Algo	 	&	Drop-Tail								\\ 9. & Traffic type		&	FTP										\\ 10. & SACK, FACK		&	Disabled								\\ 11. & Simulation time	&	100 seconds								\\ \hline
	\end{tabular}
	\label{params}
	\end{center}
\end{table}

In the first scenario of single-flow, there is only one pair of sender and receiver, as shown in Figure \ref{fig:topology-ideal}, which presents an ideal case with no congestion to show the ability of the evaluated CCAs on achieving full bandwidth utilization. As for the second and third scenarios of multiple flows, there are  pairs of sender and receiver, as shown in Figure \ref{fig:topology}, which have been used to simulate the network congestion and to show its impact on the performance measurements of the evaluated CCAs. In the second scenario, the flows are sequentially established and terminated as shown in Figure \ref{fig:multi-flows-sequence}(a). While in the third scenario, the flows are synchronously established and terminated as shown in Figure \ref{fig:multi-flows-sequence}(b).

In all of these experiments, a standard single dumbbell topology has been used, as shown in figures \ref{fig:topology-ideal} and \ref{fig:topology}, where  is the competing senders (, , , ..., ) which send data simultaneously to  receivers (, , , ..., ) through the shared single bottleneck. All source and destination nodes are connected to the bottleneck routers over LAN with  speed and  propagation delay. While the bottleneck link is  speed with a propagation delay of  \citep{Wang2013}. These experiments have been repeated for each CCA separately with variable buffer size and variable packet error rate (PER). The buffer size varies from  to  packets while the PERs which have been used are ,  and  PER. 

\begin{figure} [t!]
\centering
\includegraphics[width=\linewidth]{topologyideal.pdf}
\caption{Non-congested Network topology.}
\label{fig:topology-ideal}
\end{figure}

\begin{figure} [t!]
\centering
\includegraphics[width=\linewidth]{topology.pdf}
\caption{Network topology with standard dumbbell bottleneck.}
\label{fig:topology}
\end{figure}

\begin{figure} [t!]
	\centering
	\begin{center}
		\subfigure[Sequentially established/terminated flows scenario.] 
		{
			\includegraphics[width=0.9\linewidth]{multiflowssequence1.pdf}
			\label{fig:multi-flows-sequence1}
		}
		\subfigure[Synchronously established/terminated flows scenario.] 
		{
			\includegraphics[width=0.9\linewidth]{multiflowssequence2.pdf}
			\label{fig:multi-flows-sequence2}
		}
	\end{center}
	\caption{The sequence of establishments and terminations of the multiple flows scenarios.}
	\label{fig:multi-flows-sequence}
\end{figure}

Moreover, the performance metrics evaluated in this paper are the average throughput, loss ratio, inter-fairness, intra-fairness and RTT-fairness. Average throughput and loss ratio are evaluated to reflect the ability of the TCP variant on utilizing the bandwidth. While, measuring inter-fairness, intra-fairness and RTT-fairness is to show the quality of sharing the link between the competing TCP flows based on Jain's fairness index (JFI) \citep{jain1984}, as shown in Equation \eqref{fair}.



Substantially, these experiments show the impact of bottleneck congestion, buffer size and PER on the performance of the examined CCAs and also show the performance changes when a smaller buffer size is applied. Moreover, the simulation time used in all experiments has been set to 100 seconds which is enough for TCP to show its steady state.

\subsection{Results and Discussion}

This subsection presents an analytical discussion of the behavior exhibited by the proposed CCA and the compared CCAs. As well as, it presents the results of the performance evaluation and shows the measurements of the average throughput, loss ratio, inter-fairness, intra-fairness and RTT-fairness.

\subsubsection{The  evolution}
Fundamentally, the target of CCAs is: to maximize the throughput while minimizing the loss ratio and maintaining the fairness. Figure \ref{fig:CWND} shows the  evolution of the studied CCAs based on the buffer size change. Due to the mechanism of agility factor, Agile-SD expectedly shows the faster  growth followed by Cubic and C-TCP. This fast or slow evolution of  is the core of any CCA which would directly affect the other performance metrics, such as throughput, loss ratio and it may affect the fairness as well.

In Figure \ref{fig:CWND:1}, it is very clear that Agile-SD reaches the maximum , which is about 1500 packets, in around 17 second then starts oscillating to show very short epochs, while, Cubic reaches the maximum  in about 60 seconds then starts oscillating to draw very long epochs. As for C-TCP, it fails to reach the maximum  and touches only the edge of 110 packets then exhibits very short epochs. Indeed, the larger the , the higher the throughput and vice versa.

Interestingly, when the buffer size increases, the behavior of the studied CCAs relatively improves. The figures from \ref{fig:CWND:3} to \ref{fig:CWND:7} show that Agile-SD and Cubic reduce their time of reaching the maximum  whenever the buffer size increases. Besides, Agile-SD keeps showing short epochs while Cubic remains drawing long epochs. Unlikely, C-TCP heightens its  towards the maximum limit whenever the buffer size increases. In fact, the wider oscillating and/or the longer epochs is the lower bandwidth utilization and vice versa. Thus, the higher bandwidth utilization among the studied CCAs would be provided by Agile-SD followed by Cubic then C-TCP.

\begin{figure*} [t!]
	\centering
	\begin{center}
		\subfigure [Buffer Size = 5 Packets.]	{
			\includegraphics[scale=0.39]{agile1.pdf}		
			\includegraphics[scale=0.39]{compound1.pdf}
			\includegraphics[scale=0.39]{cubic1.pdf}
			\label{fig:CWND:1}
		}	
\subfigure [Buffer Size = 25 Packets.]	{
			\includegraphics[scale=0.39]{agile3.pdf}		
			\includegraphics[scale=0.39]{compound3.pdf}
			\includegraphics[scale=0.39]{cubic3.pdf}
			\label{fig:CWND:3}
		}	
\subfigure [Buffer Size = 100 Packets.]	{
			\includegraphics[scale=0.39]{agile5.pdf}		
			\includegraphics[scale=0.39]{compound5.pdf}
			\includegraphics[scale=0.39]{cubic5.pdf}
			\label{fig:CWND:5}
		}
\subfigure [Buffer Size = 250 Packets.]	{
			\includegraphics[scale=0.39]{agile6.pdf}		
			\includegraphics[scale=0.39]{compound6.pdf}
			\includegraphics[scale=0.39]{cubic6.pdf}
			\label{fig:CWND:6}
		}	
		\subfigure [Buffer Size = 500 Packets.]	{
			\includegraphics[scale=0.39]{agile7.pdf}		
			\includegraphics[scale=0.39]{compound7.pdf}
			\includegraphics[scale=0.39]{cubic7.pdf}
			\label{fig:CWND:7}
		}
	\end{center}
	\caption{TCP Congestion Window Evolution.}
	\label{fig:CWND}
\end{figure*}

\subsubsection{The average throughput}
In the first scenario, as shown in Figure \ref{fig:single-0per-throughput}, Agile-SD has overcome the other CCAs in terms of average throughput due to its fast growth of  resulted by the mechanism of agility factor. Moreover, Agile-SD presents lower sensitivity to PER than the others, whereas, Cubic and C-TCP are highly affected by PER and they present a poor performance when the PER is increased. However, in the cases of  PER as shown in figures \ref{fig:single-2per-throughput} and \ref{fig:single-3per-throughput}, C-TCP presents better performance than Cubic in most cases. In general, Agile-SD achieves better throughput than the others in most cases even in the lossy environments. Clearly, it improves the bandwidth utilization up to 55\% in some cases of this scenario.

For the second scenario, the figures \ref{fig:seq-0per-throughput}, \ref{fig:seq-2per-throughput} and \ref{fig:seq-3per-throughput} show that Agile-SD has overcome the other CCAs, in term of average throughput, at most cases even when the buffer size is small and the PER is high. Furthermore, it improves the bandwidth utilization from 10\% to 40\% in the cases of 5 packets buffer size. While in the third scenario, Agile-SD has outperformed the other CCAs in all cases especially when a \emph{near-zero} buffer is applied as shown in figures \ref{fig:sync-0per-throughput}, \ref{fig:sync-2per-throughput} and \ref{fig:sync-3per-throughput}. Moreover, Agile-SD significantly improves the bandwidth utilization even when the PER is high. Thus, it provides up to 40\% of improvement in some cases.

\begin{figure*}[t!]
	\begin{center}
		\subfigure[The First Scenario:  PER.] 
		{
			\includegraphics[scale=0.39]{single0perthroughput.pdf}
			\label{fig:single-0per-throughput}
		}
\subfigure[The First Scenario:  PER.]
		{
			\includegraphics[scale=0.39]{single2perthroughput.pdf}
			\label{fig:single-2per-throughput}
		}
		\subfigure[The First Scenario:  PER.]
		{
			\includegraphics[scale=0.39]{single3perthroughput.pdf}
			\label{fig:single-3per-throughput}
		}
\subfigure[The Second Scenario:  PER.] 
		{
			\includegraphics[scale=0.39]{seq0perthroughput.pdf}
			\label{fig:seq-0per-throughput}
		}
\subfigure[The Second Scenario:  PER.]
		{
			\includegraphics[scale=0.39]{seq2perthroughput.pdf}
			\label{fig:seq-2per-throughput}
		}
		\subfigure[The Second Scenario:  PER.]
		{
			\includegraphics[scale=0.39]{seq3perthroughput.pdf}
			\label{fig:seq-3per-throughput}
		}
\subfigure[The Third Scenario:  PER.] 
		{
			\includegraphics[scale=0.39]{sync0perthroughput.pdf}
			\label{fig:sync-0per-throughput}
		}
\subfigure[The Third Scenario:  PER.]
		{
			\includegraphics[scale=0.39]{sync2perthroughput.pdf}
			\label{fig:sync-2per-throughput}
		}
		\subfigure[The Third Scenario:  PER.]
		{
			\includegraphics[scale=0.39]{sync3perthroughput.pdf}
			\label{fig:sync-3per-throughput}
		}
	\end{center}
	\caption{The Average Throughput vs. Buffer Size.}
	\label{fig:throughput}
\end{figure*}

\subsubsection{The loss ratio}
As regarding to all scenarios, the studied CCAs have presented a loss ratio lower than 0.5\% which is considered as a negligible loss ratio. Thus, Figure \ref{fig:single3perloss} has been selected here as a sample of the loss ratio results of all scenarios to save the space of this paper and because the rest of the figures have no much difference.







\subsubsection{The fairness}
As for intra-fairness and RTT-fairness, all the studied CCAs are interchangeably close to each other. However, in some cases Agile-SD seems more fair, especially when the applied buffer size is small. Since the difference among the graphs of the results is very trivial, the figures \ref{fig:seq0perintra} and \ref{fig:sync0perrtt} have been chosen as samples of intra-fairness and RTT-fairness, respectively.

Moreover, a separated experiment has been carried out to evaluate the inter-fairness among the studied CCAs and the standard NewReno, using the same topology as shown in Figure \ref{fig:topology}, where the result is shown in Figure \ref{fig:interfairness}. For inter-fairness to NewReno, Agile-SD and C-TCP achieve around 0.76 while Cubic achieves about 0.79 inter-fairness index. As for the inter-fairness to Cubic, Agile-SD scores the highest index which is almost 0.99 and C-TCP scores around 0.96 while NewReno achieves only 0.79 inter-fairness index. As for the inter-fairness to C-TCP, Cubic scores the highest index which is around 0.96 while Agile-SD and NewReno achieve about 0.76 inter-fairness index.

\section{Conclusion}
\label{Conc}

In this paper, a new CCA, namely Agile-SD, has been proposed and evaluated. The main contribution of the proposed CCA is to implement the mechanism of agility factor. The need of the proposed CCA has been arisen by the inability of the existing high-speed CCAs in achieving a full bandwidth utilization over high-speed networks, especially when a small buffer regime is applied. Further, a new CCA module has been implemented and plugged into the Linux kernel version 3.19.0. As well as, this module has been plugged into the Network Simulator NS-2 version 2.35, as a Linux TCP, in order to evaluate it by comparing its performance to the other CCAs. 

Subsequently, intensive simulation experiments have been conducted to evaluate the proposed CCA by comparing its performance to C-TCP and Cubic, which are the current default TCP algorithms of MS Windows and Linux, respectively. The results show that the proposed algorithm achieves higher bandwidth utilization than the existing CCAs while maintaining fairness. Due to the use of agility factor, Agile-SD shows lower sensitivity to the changes of buffer size and PER.

Importantly, Agile-SD presents higher performance than the compared CCAs and it provides a significant improvement which is: up to 55\% in the case of single flow, up to 40\% in the case of sequentially established/terminated multi-flows and up to 40\% in the case of synchronously established/terminated multi-flows.

More importantly, the second scenario presents the real case of network, in which all TCP flows are not established or terminated synchronously. In this scenario, Agile-SD has achieved up to 95\% bandwidth utilization while the others did not exceed it in the case of large buffer. As for the case of small buffer, Agile-SD achieves around 92\% bandwidth utilization while the other TCP variants achieve from 32\% to 85\% bandwidth utilization.

Eventually, Agile-SD is a sender-side TCP module which does not change anything at receiver-side. It uses the standard slow start and provides a new congestion avoidance algorithm featured by the mechanism of agility factor. Currently, we have already implemented Agile-SD into the latest Linux kernel 3.19.0 and a real dumbbell topology has been built using Dummynet over PC-BSD version 10 to evaluate the proposed CCA based on real test-bed in the nearest future. Also, there is a strong intention to evaluate Agile-SD with SACK and/or FACK features to show their impacts on the throughput. As well as, Agile-SD should have the ability to consider the delayed acknowledgments which needs some modification at the receiver-side.

\section*{Acknowledgments}
This work has been partially supported by the Malaysian Ministry of Education under the Fundamental Research Grant FRGS/02/01/12/1143/FR for financial support.\\

\begin{figure}[h!]
\centering
\includegraphics[width=1\linewidth]{single3perloss.pdf}
\caption{1st Scenario ( PER): Loss Ratio vs. Buffer Size.}
\label{fig:single3perloss}
\end{figure}

\begin{figure}[h!]
\centering
\includegraphics[width=\linewidth]{seq0perintra.pdf}
\caption{2nd Scenario ( PER): Intra-Fairness vs. Buffer Size.}
\label{fig:seq0perintra}
\end{figure}

\begin{figure}[h!]
\centering
\includegraphics[width=\linewidth]{sync0perrtt.pdf}
\caption{3rd Scenario ( PER): RTT-Fairness vs. Buffer Size.}
\label{fig:sync0perrtt}
\end{figure}

\begin{figure}[h!]
\centering
\includegraphics[angle=-90,width=0.9\linewidth]{interfairness.pdf}
\caption{The inter-fairness among the studied CCAs.}
\label{fig:interfairness}
\end{figure}














\begin{thebibliography}{46}
\expandafter\ifx\csname natexlab\endcsname\relax\def\natexlab#1{#1}\fi
\expandafter\ifx\csname url\endcsname\relax
  \def\url#1{\texttt{#1}}\fi
\expandafter\ifx\csname urlprefix\endcsname\relax\def\urlprefix{URL }\fi

\bibitem[{Acharya(2012)}]{acharya2012}
Acharya, S., 2012. Study and analysis of tcp/ip congestion control techniques:
  A review. Illinois Journalism Education Association, .

\bibitem[{Afanasyev et~al.(2010)Afanasyev, Tilley, Reiher, and
  Kleinrock}]{Afanasyev2010}
Afanasyev, A., Tilley, N., Reiher, P., Kleinrock, L., 2010. {Host-to-Host
  Congestion Control for TCP}. IEEE Communications Surveys and Tutorials
  12~(3), 304--342.

\bibitem[{Al-Fares et~al.(2010)Al-Fares, Radhakrishnan, Raghavan, Huang, and
  Vahdat}]{Alfares2010}
Al-Fares, M., Radhakrishnan, S., Raghavan, B., Huang, N., Vahdat, A., 2010.
  Hedera: Dynamic flow scheduling for data center networks. In: NSDI. Vol.~10.
  pp. 19--19.

\bibitem[{Alizadeh et~al.(2010)Alizadeh, Greenberg, Maltz, Padhye, Patel,
  Prabhakar, Sengupta, and Sridharan}]{Alizadeh2010}
Alizadeh, M., Greenberg, A., Maltz, D.~A., Padhye, J., Patel, P., Prabhakar,
  B., Sengupta, S., Sridharan, M., 2010. Data center tcp (dctcp). In:
  Proceedings of the ACM SIGCOMM 2010 Conference. SIGCOMM '10. ACM, New York,
  NY, USA, pp. 63--74.

\bibitem[{Allcock et~al.(2005)Allcock, Bresnahan, Kettimuthu, Link, Dumitrescu,
  Raicu, and Foster}]{allcock2005}
Allcock, W., Bresnahan, J., Kettimuthu, R., Link, M., Dumitrescu, C., Raicu,
  I., Foster, I., 2005. The globus striped gridftp framework and server. In:
  Proceedings of the 2005 ACM/IEEE conference on Supercomputing. Vol.~1. IEEE
  Computer Society, pp. 1--11.

\bibitem[{Armbrust et~al.(2010)Armbrust, Fox, Griffith, Joseph, Katz,
  Konwinski, Lee, Patterson, Rabkin, Stoica, and Zaharia}]{Armbrust2010}
Armbrust, M., Fox, A., Griffith, R., Joseph, A.~D., Katz, R., Konwinski, A.,
  Lee, G., Patterson, D., Rabkin, A., Stoica, I., Zaharia, M., Apr. 2010. View
  of cloud computing. Comm. ACM 53~(4), 50--58.

\bibitem[{Baiocchi et~al.(2007)Baiocchi, Castellani, and
  Vacirca}]{Baiocchi2007}
Baiocchi, A., Castellani, A.~P., Vacirca, F., 2007. {YeAH-TCP:Yet Another
  Highspeed TCP}. In: Proc. PFLDnet. Roma, Italy, pp. 37--42.

\bibitem[{Brakmo and Peterson(1995)}]{brak1995}
Brakmo, L.~S., Peterson, L.~L., 1995. Tcp vegas: End to end congestion
  avoidance on a global internet. Selected Areas in Communications, IEEE
  Journal on 13~(8), 1465--1480.

\bibitem[{Buyya et~al.(2008)Buyya, Yeo, and Venugopal}]{Buyya2008}
Buyya, R., Yeo, C.~S., Venugopal, S., Sept 2008. Market-oriented cloud
  computing: Vision, hype, and reality for delivering it services as computing
  utilities. In: 10th IEEE International Conference on High Performance
  Computing and Communications, 2008. pp. 5--13.

\bibitem[{Callegari et~al.(2012)Callegari, Giordano, Pagano, and
  Pepe}]{Callegari2012b}
Callegari, C., Giordano, S., Pagano, M., Pepe, T., 2012. {Behavior analysis of
  TCP Linux variants}. Computer Networks 56~(1), 462--476.

\bibitem[{Callegari et~al.(2014)Callegari, Giordano, Pagano, and
  Pepe}]{Callegari2014}
Callegari, C., Giordano, S., Pagano, M., Pepe, T., 2014. A survey of congestion
  control mechanisms in linux tcp. In: Distributed Computer and Communication
  Networks. Vol. 279 of Communications in Computer and Information Science.
  Springer, pp. 28--42.

\bibitem[{Chu et~al.(2013)Chu, Cheng, Dukkipati, and Mathis}]{RFC6928}
Chu, J., Cheng, Y., Dukkipati, N., Mathis, M., April 2013. Increasing tcp's
  initial window. RFC 6928, IETF Network Working Group, .

\bibitem[{Crowcroft and Oechslin(1998)}]{crowcroft1998}
Crowcroft, J., Oechslin, P., 1998. Differentiated end-to-end internet services
  using a weighted proportional fair sharing tcp. ACM SIGCOMM Computer
  Communication Review 28~(3), 53--69.

\bibitem[{{D. Leith}(2004)}]{Leith2004}
{D. Leith}, R.~S., 2004. H-tcp: Tcp for high-speed and long distance networks.
  In: Proceedings of PFLDnet. pp. 95--101.

\bibitem[{Floyd(2003)}]{Floyd2003}
Floyd, S., April 2003. {HighSpeed TCP for Large Congestion Windows}. RFC 3649,
  IETF Network Working Group, .

\bibitem[{Floyd and Henderson(1999)}]{floyd1999}
Floyd, S., Henderson, T., April 1999. The newreno modification to tcpâ€™s fast
  recovery algorithm. RFC 2582, IETF Network Group, .

\bibitem[{Fu and Indulska(2005)}]{Fu2005}
Fu, Q., Indulska, J., 2005. Features of parallel tcp with emphasis on
  congestion avoidance in heterogeneous networks. In: Wysocki, T., Dadej, A.,
  Wysocki, B. (Eds.), Advanced Wired and Wireless Networks. Vol.~26 of
  Multimedia Systems and Applications Series. Springer US, pp. 207--230.

\bibitem[{Fu et~al.(2007)Fu, Indulska, Perreau, and Zhang}]{fu2007}
Fu, Q., Indulska, J., Perreau, S., Zhang, L., 2007. Exploring tcp
  parallelisation for performance improvement in heterogeneous networks.
  Computer Communications 30~(17), 3321--3334.

\bibitem[{Ha and Rhee(2008)}]{Ha2008}
Ha, S., Rhee, I., 2008. {CUBIC: A New TCP-Friendly High-Speed TCP Variant}.
  SIGOPS Operating Systems Review 42~(5), 64--74.

\bibitem[{Hanushevsky et~al.(2001)Hanushevsky, Trunov, and
  Cottrell}]{hanushevsky2001}
Hanushevsky, A., Trunov, A., Cottrell, L., 2001. Peer-to-peer computing for
  secure high performance data copying. In: In Proc. of the 2001 Int. Conf. on
  Computing in High Energy and Nuclear Physics (CHEP 2001), Beijng. Vol. 2001.
  Citeseer.

\bibitem[{Hsieh and Sivakumar(2002)}]{hsieh2002}
Hsieh, H.-Y., Sivakumar, R., 2002. ptcp: An end-to-end transport layer protocol
  for striped connections. In: 10th IEEE International Conference on Network
  Protocols Proceedings. Vol. 2002. IEEE, pp. 24--33.

\bibitem[{Hwang et~al.(2012)Hwang, Yoo, and Choi}]{Jaehyun2012}
Hwang, J., Yoo, J., Choi, N., June 2012. Ia-tcp:a rate based incast-avoidance
  algorithm for tcp in data center networks. In: IEEE International Conference
  on Communications (ICC). pp. 1292--1296.

\bibitem[{Jacobson and Braden(1988)}]{RFC1072}
Jacobson, V., Braden, R., October 1988. Tcp extensions for long-delay paths.
  RFC 1072, IETF Network Working Group, .

\bibitem[{Jain et~al.(1984)Jain, Chiu, and Hawe}]{jain1984}
Jain, R., Chiu, D.-M., Hawe, W.~R., 1984. A quantitative measure of fairness
  and discrimination for resource allocation in shared computer system. Eastern
  Research Laboratory, Digital Equipment Corporation.

\bibitem[{Kaneko et~al.(2007)Kaneko, Fujikawa, Su, and Katto}]{Kaneko2007}
Kaneko, K., Fujikawa, T., Su, Z., Katto, J., 2007. {TCP-Fusion : A Hybrid
  Congestion Control Algorithm for High-speed Networks}. In: Proc. PFLDnet,
  ISI, Marina Del Rey, California. pp. 31--36.

\bibitem[{Kelly(2003)}]{Kelly2003}
Kelly, T., 2003. {Scalable TCP : Improving Performance in Highspeed Wide Area
  Networks}. ACM SIGCOMM Computer Communications Review 33~(2), 83--91.

\bibitem[{King et~al.(2005)King, Baraniuk, and Riedi}]{King2005}
King, R., Baraniuk, R., Riedi, R., 2005. {TCP-Africa: An adaptive and fair
  rapid increase rule for scalable TCP}. In: INFOCOM 2005. 24th Annual Joint
  Conference of the IEEE Computer and Communications Societies. Proceedings
  IEEE. pp. 1--11.

\bibitem[{Lar and Liao(2013)}]{Lar2013}
Lar, S.-u., Liao, X., 2013. An initiative for a classified bibliography on
  tcp/ip congestion control. Journal of Network and Computer Applications
  36~(1), 126--133.

\bibitem[{Liu et~al.(2008)Liu, Ba{\c{s}}ar, and Srikant}]{Liu2008}
Liu, S., Ba{\c{s}}ar, T., Srikant, R., 2008. Tcp-illinois: A loss-and
  delay-based congestion control algorithm for high-speed networks. Performance
  Evaluation 65~(6), 417--440.

\bibitem[{{Mohamed A. Alrshah} and {Mohamed Othman}(2009)}]{alrshah2009}
{Mohamed A. Alrshah}, {Mohamed Othman}, Nov 2009. Test-bed based comparison of
  single and parallel tcp and the impact of parallelism on throughput and
  fairness in heterogenous networks. In: ICCTD '09. International Conference on
  Computer Technology and Development, 2009. Vol.~1. pp. 332--335.

\bibitem[{{Mohamed A. Alrshah} et~al.(2014){Mohamed A. Alrshah}, {Mohamed
  Othman}, {Borhanuddin Ali}, and {Zurina Mohd Hanapi}}]{alrshah2014}
{Mohamed A. Alrshah}, {Mohamed Othman}, {Borhanuddin Ali}, {Zurina Mohd
  Hanapi}, 2014. Comparative study of high-speed linux tcp variants over
  high-{BDP} networks. Journal of Network and Computer Applications 43, 66--75.

\bibitem[{{Mohamed A. Alrshah and Mohamed Othman}(2013)}]{alrshah2013}
{Mohamed A. Alrshah and Mohamed Othman}, Nov 2013. Performance evaluation of
  parallel {TCP}, and its impact on bandwidth utilization and fairness in
  {High-BDP} networks based on test-bed. In: 2013 IEEE Malaysia International
  Conference on Communications (MICC). pp. 23--28.

\bibitem[{Prakash et~al.(2012)Prakash, Dixit, Hu, and Kompella}]{prakash2012}
Prakash, P., Dixit, A., Hu, Y.~C., Kompella, R., 2012. The tcp outcast problem:
  Exposing unfairness in data center networks. In: Proceedings of the 9th
  USENIX conference on Networked Systems Design and Implementation, San Jose,
  CA. p.~.

\bibitem[{Scharf(2011)}]{Scharf2011}
Scharf, M., 2011. {Comparison of end-to-end and network-supported fast startup
  congestion control schemes}. Computer Networks 55~(8), 1921--1940.

\bibitem[{Sivakumar et~al.(2000)Sivakumar, Bailey, and
  Grossman}]{sivakumar2000}
Sivakumar, H., Bailey, S., Grossman, R.~L., 2000. Psockets: The case for
  application-level network striping for data intensive applications using high
  speed wide area networks. In: Proceedings of the 2000 ACM/IEEE conference on
  Supercomputing. Vol. 2000. IEEE Computer Society, pp. 1--7.

\bibitem[{Tahiliani et~al.(2012)Tahiliani, Tahiliani, and
  Sekaran}]{Tahiliani2012}
Tahiliani, R., Tahiliani, M., Sekaran, K., Dec 2012. Tcp variants for data
  center networks: A comparative study. In: International Symposium on Cloud
  and Services Computing (ISCOS). pp. 57--62.

\bibitem[{Tan and Song(2006)}]{Tan2006}
Tan, K., Song, J., 2006. Compound tcp: A scalable and tcp-friendly congestion
  control for high-speed networks. In: in 4th International workshop on
  Protocols for Fast Long-Distance Networks (PFLDNet), 2006. pp. 80--83.

\bibitem[{Tierney et~al.(1994)Tierney, Lee, Chen, Herzog, Hoo, Jin, and
  Johnston}]{Tierney1994}
Tierney, B., Lee, J., Chen, L.~T., Herzog, H., Hoo, G., Jin, G., Johnston,
  W.~E., 1994. Distributed parallel data storage systems: a scalable approach
  to high speed image servers. In: Proceedings of the second ACM international
  conference on Multimedia. Vol. 1994 of MULTIMEDIA '94. ACM, pp. 399--405.

\bibitem[{Vamanan et~al.(2012)Vamanan, Hasan, and Vijaykumar}]{Vamanan2012}
Vamanan, B., Hasan, J., Vijaykumar, T., 2012. Deadline-aware datacenter tcp
  (d2tcp). In: Proceedings of the ACM SIGCOMM 2012 Conference on Applications,
  Technologies, Architectures, and Protocols for Computer Communication.
  SIGCOMM '12. ACM, New York, NY, USA, pp. 115--126.

\bibitem[{Vasudevan et~al.(2009)Vasudevan, Phanishayee, Shah, Krevat, Andersen,
  Ganger, Gibson, and Mueller}]{Vasudevan2009}
Vasudevan, V., Phanishayee, A., Shah, H., Krevat, E., Andersen, D.~G., Ganger,
  G.~R., Gibson, G.~A., Mueller, B., Aug. 2009. Safe and effective fine-grained
  tcp retransmissions for datacenter communication. SIGCOMM Comput. Commun.
  Rev. 39~(4), 303--314.

\bibitem[{Wang et~al.(2014)Wang, Wu, Dou, Ren, and Li}]{Wang2013}
Wang, G., Wu, Y., Dou, K., Ren, Y., Li, J., 2014. Apptcp: The design and
  evaluation of application-based tcp for e-vlbi in fast long distance
  networks. Future Generation Computer Systems 39, 67--74.

\bibitem[{Wu et~al.(2013)Wu, Feng, Guo, and Zhang}]{Haitao2013}
Wu, H., Feng, Z., Guo, C., Zhang, Y., April 2013. Ictcp: Incast congestion
  control for tcp in data-center networks. Networking, IEEE/ACM Transactions on
  21~(2), 345--358.

\bibitem[{Wu and Yang(2012)}]{Wu2012}
Wu, X., Yang, X., June 2012. Dard: Distributed adaptive routing for datacenter
  networks. In: 2012 IEEE 32nd International Conference on Distributed
  Computing Systems (ICDCS). pp. 32--41.

\bibitem[{Xu et~al.(2004)Xu, Harfoush, and Rhee}]{xu2004}
Xu, L., Harfoush, K., Rhee, I., 2004. Binary increase congestion control (bic)
  for fast long-distance networks. In: INFOCOM 2004. Twenty-third Annual Joint
  Conference of the IEEE Computer and Communications Societies. Vol.~4. pp.
  2514--2524.

\bibitem[{Xu et~al.(2011)Xu, Zhou, Pham, Ji, Yang, and Liu}]{xu2011}
Xu, W., Zhou, Z., Pham, D., Ji, C., Yang, M., Liu, Q., 2011. Hybrid congestion
  control for high-speed networks. Journal of Network and Computer Applications
  34~(4), 1416--1428.

\bibitem[{Yoo et~al.(2012)Yoo, Yin, and Wen}]{Yoo2012}
Yoo, S. J.~B., Yin, Y., Wen, K., April 2012. Intra and inter datacenter
  networking: The role of optical packet switching and flexible bandwidth
  optical networking. In: Optical Network Design and Modeling, 2012 16th
  International Conference on. pp. 1--6.

\end{thebibliography}
















\end{document}
