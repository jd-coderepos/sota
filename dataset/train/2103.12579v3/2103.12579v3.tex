\section{Experiment}
We evaluate our method on the following long-tailed datasets: CIFAR-LT-10, CIFAR-LT-100, ImageNet-LT, iNaturalist 2017 and iNaturalist 2018. In addition, we report the average result of 3 random experiments. For those experiments conducted in the same settings, we directly quote their results from original papers. Code is available at \url{https://github.com/BIT-DA/MetaSAug}.

\subsection{Datasets}
\textbf{Long-Tailed CIFAR} is the long-tailed version of CIFAR dataset. The original CIFAR-10 (CIFAR-100) dataset consists of 50000 images drawn from 10 (100) classes with even data distribution. In other words, CIFAR-10 (CIFAR-100) has 5000 (500) images per class. Following \cite{cui2019class}, we discard some training samples to construct imbalanced datasets. We build 5 training sets by varying imbalance factor , where the  denotes the image amount ratio between largest and smallest classes. If let  denotes the sample amount of -th class, we can define . As for test sets, we use the original balanced test sets. Following \cite{jamal2020rethinking}, we randomly select ten samples per class from training set to construct validation set .

\textbf{ImageNet-LT}: ImageNet \cite{imagenet2014} is a classic visual recognition dataset, which contains 1,281,167 training images and 50,000 validation images. Liu et al. \cite{liu2019large} build the long-tailed version of ImageNet, termed as ImageNet-LT. After discarding some training examples, ImageNet-LT remains 115,846 training examples in 1,000 classes. The imbalance factor is 1280/5. We adopt the original validation to test methods. In addition, Liu et al. \cite{liu2019large} also construct a small balanced validation set with 20 images per class. Hence, we adopt ten images per class from it to construct our validation set  as \cite{jamal2020rethinking}.

\textbf{iNaturalist 2017 and iNaturalist 2018}. The iNaturalist datasets are large-scale datasets with images collected from real-world, which have an extremely imbalanced class distribution. The iNatualist 2017 \cite{inaturalist2017} includes 579,184 training images in 5,089 classes with an imbalance factor of 3919/9, while the iNaturalist 2018 \cite{inaturalist} is composed of 435,713 images from 8,142 classes with an imbalance factor of 1000/2. We adopt the original validation set to test our method. To construct the validation set , we select five and two images from the training sets of iNaturalist 2017 and iNaturalist 2018, respectively, following \cite{jamal2020rethinking}.


\subsection{Visual Recognition on CIFAR-LT}
We conduct comparison experiments on the long-tailed datasets CIFAR-LT-10 and CIFAR-LT-100. Following \cite{jamal2020rethinking, cui2019class}, we adopt the ResNet-32 \cite{resnet} as the backbone network in our experiments. 

\textbf{Implementation details}.
For the baselines LDAM and LDAM-DRW, we reproduce them with the source code released by authors \cite{cao2019learning}. We train the ResNet-32 \cite{resnet} with standard stochastic gradient decent (SGD) with momentum  and weight decay of  for all experiments. And We train the models on a single GPU for 200 epochs. In addition, we decay the learning rate by 0.01 at the 160 and 180 epochs as \cite{jamal2020rethinking}. For our method, we adopt the initial learning rate 0.1. And we set the batch size as 100 for our experiments. The hyperparameter  is selected from .

\textbf{Comparison methods}. We compare our method with the following methods:
\begin{itemize}
	\item \textbf{Cross-entropy training} is the baseline method in long-tailed visual recognition, which trains ResNet-32 using vanilla cross-entropy loss function.
	\item \textbf{Class weighting methods}. This type of method assigns weights to training examples in class level, which includes class-balanced loss \cite{cui2019class}, meta-class-weight \cite{jamal2020rethinking} and LDAM-DRW \cite{cao2019learning}. Class-balanced loss proposes effective number to measure the sample size of each class and the class-wise weights. Class-balanced focal loss and class-balanced cross-entropy loss refer to applying class-balanced loss on focal loss and cross-entropy loss, respectively. LDAM-DRW allocates label-aware margins to the examples based on the label distribution, and adopts deferred re-weighting strategy for better performance on tail classes.
	\item \textbf{Instance weighting methods} assign weights to samples according to the instance characteristic \cite{L2RW,MetaWeightNet,lin2017focal}. For example, focal loss \cite{lin2017focal} determine the weights for samples based on the sample difficulty. Though focal loss is not specially designed for long-tailed classification, it can penalize the samples of minority classes if the classifier overlooks the minority classes during training.  

	\item \textbf{Meta-learning methods}. In fact, these methods adopt meta-learning to learn better class level or instance level weights \cite{jamal2020rethinking,MetaWeightNet,L2RW}. For saving space, we only introduce them here. Meta-class-weight \cite{jamal2020rethinking} exploits meta-learning to model the condition distribution difference between training and testing data, leading to better class level weights. While L2RW \cite{L2RW} and meta-weight-net \cite{MetaWeightNet} adopt meta-learning to model the instance-wise weights. L2RW directly optimizes the weight variables, while meta-weight-net additionally constructs a multilayer perceptron network to model the weighting function. Note that both L2RW and meta-weight-net can handle the learning with imbalanced label distribution and noisy labels.
	\item \textbf{Two-stage methods}. We also compared with methods that adopt two-stage learning \cite{jamal2020rethinking,cao2019learning,cui2018large}. BBN \cite{BBN} unifies the representation and classifier learning stages to form a cumulative learning strategy.
\end{itemize} 


\begin{table*}
	\centering
	\caption { Test top-1 errors (\%) of ResNet-32 on CIFAR-LT-10 under different imbalance settings. * indicates results reported in original paper.  indicates results reported in \cite{jamal2020rethinking}.}
	\vspace{2pt}{\begin{tabular}{l|c|c|c|c|c}
			\hline
			Imbalance factor & 200 & 100 & 50 & 20 & 10\\ \hline
			Cross-entropy training & 34.13 & 29.86  & 25.06  &  17.56 & 13.82 \\ \hline
			Class-balanced cross-entropy loss \cite{cui2019class} & 31.23 & 27.32  & 21.87 & 15.44 & 13.10  \\ \hline
			Class-balanced fine-tuning \cite{cui2018large} & 33.76 & 28.66 & 22.56 & 16.78 & 16.83  \\ \hline
			BBN \cite{BBN} & - & 20.18 & 17.82 & - & 11.68 \\ \hline
			Mixup \cite{mixup} (results from \cite{BBN}) & - & 26.94 & 22.18 & - & 12.90 \\ \hline
			L2RW \cite{L2RW} & 33.75 & 27.77 & 23.55 & 18.65 & 17.88 \\ \hline
			Meta-weight net \cite{MetaWeightNet} & 32.80 & 26.43 & 20.90 & 15.55 & 12.45  \\ \hline
			Meta-class-weight with cross-entropy loss \cite{jamal2020rethinking} & 29.34 & 23.59 & 19.49 & 13.54 & 11.15 \\\hline
			\textbf{MetaSAug with cross-entropy loss} & \textbf{23.11} & \textbf{19.46} & \textbf{15.97} & \textbf{12.36} & \textbf{10.56} \\ \hline\hline 
			Focal loss \cite{lin2017focal} & 34.71 & 29.62 & 23.29 & 17.24 & 13.34  \\ \hline
			Class-balanced focal loss \cite{cui2019class} & 31.85 & 25.43 & 20.78 & 16.22 & 12.52 \\ \hline
			Meta-class-weight with focal loss \cite{jamal2020rethinking} & 25.57 & 21.10 & 17.12 & 13.90 & 11.63 \\ \hline
			\textbf{MetaSAug with focal loss} & \textbf{22.73} & \textbf{19.36} & \textbf{15.96} & \textbf{12.84} & \textbf{10.74} \\ \hline\hline 
			LDAM loss\cite{cao2019learning} & 33.25 & 26.45 & 21.17 & 16.11 & 12.68  \\ \hline
			LDAM-DRW \cite{cao2019learning} & 25.26 & 21.88 & 18.73 & 15.10 & 11.63  \\ \hline
			Meta-class-weight with LDAM loss  \cite{jamal2020rethinking} & 22.77 & 20.00 & 17.77 & 15.63 & 12.60 \\ \hline
			
			\textbf{MetaSAug with LDAM loss}  & \textbf{22.65} & \textbf{19.34} & \textbf{15.66} & \textbf{11.90} & \textbf{10.32} \\ \hline
		\end{tabular}
	}\label{tab:CIFAR-10}
	
\end{table*}


\begin{table*}
	\centering
	\caption {Test top-1 errors (\%) of ResNet-32 on CIFAR-LT-100 under different imbalance settings. * indicates results reported in original paper.  indicates results reported in \cite{jamal2020rethinking}.}
	{\begin{tabular}{l|c|c|c|c|c}
			\hline
			Imbalance factor & 200 & 100 & 50 & 20 & 10 \\ \hline
			
			Cross-entropy training & 65.30 & 61.54 & 55.98 & 48.94 & 44.27 \\ \hline
			Class-balanced cross-entropy loss \cite{cui2019class} & 64.44 & 61.23 & 55.21 & 48.06 & 42.43 \\ \hline
			Class-balanced fine-tuning \cite{cui2018large} & 61.34 & 58.50 & 53.78 & 47.70 & 42.43 \\ \hline
			BBN \cite{BBN} & - & 57.44 & 52.98 & - & 40.88 \\ \hline
			Mixup \cite{mixup} (results from \cite{BBN}) & - & 60.46 & 55.01 & - & 41.98 \\ \hline
			L2RW \cite{L2RW} & 67.00 & 61.10 & 56.83 & 49.25 & 47.88 \\ \hline
			Meta-weight net \cite{MetaWeightNet} & 63.38 & 58.39 & 54.34 & 46.96 & 41.09 \\ \hline
			Meta-class-weight with cross-entropy loss \cite{jamal2020rethinking} & 60.69 & 56.65 & 51.47 & 44.38 & 40.42 \\ \hline
			\textbf{MetaSAug with cross-entropy loss} & \textbf{60.06} & \textbf{53.13} & \textbf{48.10} & \textbf{42.15} & \textbf{38.27} \\ \hline\hline 
		
			Focal loss \cite{lin2017focal} & 64.38 & 61.59 & 55.68 & 48.05 & 44.22  \\ \hline
		
			Class-balanced focal loss \cite{cui2019class} & 63.77 & 60.40 & 54.79 & 47.41 & 42.01  \\ \hline
			Meta-class-weight with focal loss \cite{jamal2020rethinking}& 60.66 & 55.30 & 49.92 & 44.27 & 40.41 \\ \hline
			\textbf{MetaSAug with focal loss} & \textbf{59.78} & \textbf{54.11} & \textbf{48.38} & \textbf{42.41} & \textbf{38.94} \\ \hline\hline 
		
			LDAM loss \cite{cao2019learning}  & 63.47 & 59.40  & 53.84 & 48.41 & 42.71  \\ \hline
			LDAM-DRW \cite{cao2019learning} & 61.55 & 57.11 & 52.03 & 47.01 & 41.22 \\ \hline
			Meta-class-weight with LDAM loss \cite{jamal2020rethinking} & 60.47 & 55.92 & 50.84 & 47.62 & 42.00 \\ \hline
			\textbf{MetaSAug with LDAM loss} & \textbf{56.91} & \textbf{51.99} & \textbf{47.73} & \textbf{42.47} & \textbf{38.72} \\ \hline
		\end{tabular}
	}
	\label{tab:CIFAR-100}
\end{table*}

\textbf{Results}. 
\label{comparision_results}
The experimental results of long-tailed CIFAR-10 with different imbalance factors are shown in Table \ref{tab:CIFAR-10}, which are organized into three groups according to the adopted basic losses (i.e., cross-entropy, focal, and LDAM). 

From the results, we can observe that re-weighting strategies are effective for the long-tailed problems, since several re-weighting methods (e.g., meta-class-weight) outperform the cross-entropy training by a large margin. We evaluate our method with the three basic losses. The results reveal that our method can consistently improve the performance of the basic losses significantly. Particularly, MetaSAug notably surpasses mixup that conducts augmentation on the inputs, manifesting that facilitating semantic augmentation is more effective in long-tailed scenarios. In addition, our method performs better than the re-weighting methods. This demonstrates that our augmentation strategy indeed can ameliorate the performance of classifiers. When the dataset is less imbalanced (implying imbalance factor=10), our method can still stably achieve performance gains, revealing that MetaSAug won't 
damage the performance of classifier under the relatively balanced setting.

Table \ref{tab:CIFAR-100} presents the classification error of dataset long-tailed CIFAR-100, from which we can still observe that our methods achieve the best results in each group. Particularly, ``MetaSAug with LDAM loss" exceeds the best competing method ``Meta-class-weight with LDAM loss" by 3.56\%.


\begin{figure*}[htbp]\centering
	\setlength{\abovecaptionskip}{0.cm}
	\setlength{\belowcaptionskip}{0.cm}
	\centering
	\includegraphics[width=1.0\textwidth]{Figures/Fig_visualization_4.pdf}
	\caption{Visualization of the augmented examples for the four rarest classes: frog, horse, ship and truck (frequent  rare). We adopt WGAN-GP \cite{WGAN-GP} generator to search the images corresponding to the augmented features. ``Original'' refers to the original training samples. ``Restored'' and ``Augmented" present the original and augmented images generated by the generator, respectively. Our method is able to semantically alter the semantic of training images, e.g., changing color of objects, backgrounds, shapes of objects, etc.}
	\label{fig:visualization}
	
\end{figure*}


\begin{figure*}[htbp]\centering
	\setlength{\abovecaptionskip}{0.cm}
	\setlength{\belowcaptionskip}{0.cm}
	\centering
	\includegraphics[width=1.0\textwidth]{Figures/Fig_confusion_matrix.pdf}
	\caption{Illustration of confusion matrices of the vanilla cross-entropy training, meta-class-weight \cite{jamal2020rethinking}, and our method on dataset CIFAR-LT-10. The imbalance factor is 200. Classes are ranked by the frequency, i.e., frequent (left)  rare (right).}
	\label{Fig_confusion_matrix}
\end{figure*}



\subsection{Visual Recognition on ImageNet-LT} \vspace{-1mm}
We use ResNet-50 \cite{resnet} as the backbone network in the experiments on ImageNet-LT. And we train ResNet-50 with batch size 64. We decay the learning rate by 0.1 at 60 epoch and 80 epoch. In addition, for training efficiency, we only finetune the last full-connected layer while fixing the representations in the meta-learning stage. We reproduce the comparison methods based on the code released by authors.

\textbf{Results}. The experimental results are shown in Table \ref{tab:ImageNet-LT}. Class-balanced cross-entropy performs better than cross-entropy training and LDAM-DRW surpasses LDAM by a large margin. These results imply that re-weighting strategy is also effective for the dataset with a large number of classes. Hence, MetaSAug also adopts this strategy to better fulfill the semantic augmentation procedure. In addition, compared with the best competing method meta-class-weight, MetaSAug can still yield better results, demonstrating that MetaSAug is able to perform data augmentation useful for the classification learning of classifiers.


\begin{table}
	\centering
	\caption {Test top-1 error rate (\%) on ImageNet-LT of different models. (CE=Cross-entropy)}
	{\begin{tabular}{l|c}
			\hline
			Method & Top-1 error \\ \hline
			CE training & 61.12 \\ \hline
			Class-balanced CE \cite{cui2019class}  & 59.15 \\ \hline
			OLTR \cite{liu2019large} & 59.64 \\ \hline
			LDAM \cite{cao2019learning} & 58.14 \\ \hline
			LDAM-DRW \cite{cao2019learning} & 54.26 \\ \hline
			Meta-class-weight with CE loss \cite{jamal2020rethinking} & 55.08 \\ \hline
			\textbf{MetaSAug with CE loss} & \textbf{52.61} \\ \hline
		\end{tabular}
	}\label{tab:ImageNet-LT}
	
\end{table}

\subsection{Visual Recognition on iNaturalist Datasets}
For fair comparisons, we adopt ResNet-50 \cite{resnet} as the backbone network for iNaturalist 2017 and 2018. Following \cite{jamal2020rethinking}, we pre-train the backbone network on ImageNet for iNaturalist 2017. As for iNaturalist 2018, the network is pre-trained on ImageNet and iNaturalist 2017. We use stochastic gradient descent (SGD) with momentum to train models. The batch size is set as 64 and the initial learning rate is 0.01. In the meta-learning stage of our method, we decay the learning rate to 0.0001 and only finetune the last fully-connected layer for training efficiency.

\textbf{Results}. Table \ref{tab:iNat} presents the experimental results on the naturally-skewed datasets iNaturalist 2017 and iNaturalist 2018. MetaSAug and meta-class-weight both exploit the CE loss as basic loss. Compared with the improvement brought by class-balanced CE \cite{cui2019class} to CE Loss, MetaSAug further enhances the performance of CE loss, implying that performing effective data augmentation is also of importance for long-tailed classification. In addition, MetaSAug yields the best results among these competitive methods on iNat 2018 and is on par with the state-of-art method BBN \cite{BBN} on iNat 2017. These results demonstrate that our method indeed can facilitate data augmentation useful for classification in the deep feature space.

\begin{table}
	\centering
	\caption {Test top-1 error rate (\%) on iNaturalist (iNat) 2017 and 2018 of different models. results is quoted from original papers.  indicates results reported in \cite{jamal2020rethinking}. (CE=Cross-entropy)}
	{\begin{tabular}{l|c|c}
			\hline
			Method & iNat 2017 & iNat 2018 \\ \hline
			CE & 43.21 & 34.24 \\ \hline
			Class-balanced CE \cite{cui2019class} & 42.02 & 33.57 \\ \hline
			Class-balanced focal \cite{cui2019class} & 41.92 & 38.88 \\ \hline
			cRT \cite{kang2019decoupling} & - & 32.40 \\ \hline
			BBN \cite{BBN} & \textbf{36.61} & 33.71 \\ \hline
			LDAM \cite{cao2019learning}  & - & 35.42 \\ \hline
			LDAM \cite{cao2019learning} & 39.15 & 34.13 \\ \hline
			LDAM-DRW \cite{cao2019learning} & - & 32.00  \\ \hline
			LDAM-DRW \cite{cao2019learning} & 37.84 & 32.12 \\ \hline
			Meta-class-weight \cite{jamal2020rethinking} & 40.62 & 32.45 \\ \hline
			\textbf{MetaSAug} & 36.72 & \textbf{31.25}\\ \hline
		\end{tabular}
	}\label{tab:iNat}
\end{table}



\subsection{Analysis}
\label{ablation study}
\textbf{Ablation study}. To verify each component of MetaSAug, we conduct ablation study (see Table \ref{tab:ablation}). Removing re-weighting or meta-learning causes performance drop. This manifests 1) re-weighting is effective to construct a proper meta-learning objective, and 2) our meta-learning method can indeed learn covariance useful for classification. Importantly, the latter is non-trivial since MetaSAug achieves the notable accuracy gains as shown in Table \ref{tab:ablation}. While this cannot be reached by meta-weighting methods with fixed ISDA (e.g., L2RW; Meta-weight net, MWN; Meta-class-weight, MCW). Furthermore, we observe that ISDA can boost former long-tailed methods to some extent, but the improvement is limited. This also validate the importance of our meta-learning algorithm.


\textbf{Adaptivity to deeper backbone networks}. For a reasonable comparison with baselines, we adopt the commonly used ResNet-32 and ResNet-50 to evaluate our method on CIFAR-LT and ImageNet-LT/iNaturalist datasets, respectively. However, MetaSAug can be easily adapted to other networks, and, as indicated in \cite{ISDA}, deeper models may even benefit our method more due to their stronger ability to model complex semantic relationships. In Table \ref{tab:deeper_backbones}, we show the results of MetaSAug, MCW \cite{jamal2020rethinking} and LDAM-DRW \cite{cao2019learning} with different backbone networks. One can observe that MetaSAug consistently outperforms other methods.

\textbf{Confusion matrices}. To find out whether our method ameliorates the performance on minority classes, we plot the confusion matrices of cross-entropy (CE) training, meta-class-weight \cite{jamal2020rethinking}, and our method on CIFAR-LT-10 with imbalance factor 200. From Fig.\ref{Fig_confusion_matrix}, we can observe that CE training can almost perfectly classify the samples in majority classes, but suffers severe performance degeneration on the minority classes. Due to the proposed two-component weighting, meta-classes-weight performs much better than CE training on the minority classes. Since MetaSAug inclines to augment the minority classes, it can further enhance the performance on rare classes and reduce the confusion between similar classes (implying automobile \& truck, and airplane \& ship).


\textbf{Visualization Results}. To intuitively reveal that our method can indeed alter the semantics of training examples and generate diverse meaningful augmented samples, we carry out the visualization experiment (the detailed visualization algorithm is presented in \cite{ISDA}). The visualization results are shown in Fig. \ref{fig:visualization}, from which we can observe that MetaSAug is capable of semantically altering the semantics of training examples while preserving the label identity. Particularly, MetaSAug can still generate meaningful augmented samples for the rarest class ``truck".


\begin{table}
	\centering
	\caption {Ablation study of MetaSAug using cross-entropy loss on dataset CIFAR-LT-10. The results are top-1 errors (\%).}
	{\begin{tabular}{l|c|c|c}
			\hline
			Imbalance factor  & 100 & 50 & 20 \\ \hline
			MetaSAug w/o re-weighting & 25.96 & 20.63 & 15.15 \\ \hline
			MetaSAug w/o meta-learning & 21.68 & 17.43 & 13.08 \\ \hline
			MetaSAug & \textbf{19.46} & \textbf{15.97} & \textbf{12.36} \\ \hline  \hline
			ISDA, L2RW \cite{L2RW} & 25.16 & 20.78 & 16.53  \\ \hline
			ISDA, MWN \cite{MetaWeightNet} & 24.69 & 20.42 & 14.71 \\ \hline
			ISDA, MCW \cite{jamal2020rethinking} & 20.78 & 17.12 & 12.93 \\ \hline
		\end{tabular}
	}\label{tab:ablation}
\end{table}



\begin{table}[htbp]
	\centering
	\small
	
	\caption {\small Test top-1 errors (\%) on ImageNet-LT of methods with different backbone networks.}
	
	{\begin{tabular}{l|c|c|c}
			\hline
			Network & MCW \cite{jamal2020rethinking} & LDAM-DRW \cite{cao2019learning} &  MetaSAug \\ \hline
			ResNet-50 & 55.08 & 54.26 & \textbf{52.61}  \\ \hline
			ResNet-101 & 53.76 & 53.55  & \textbf{50.95}  \\ \hline
			ResNet-152 & 53.18 &  52.86 & \textbf{49.97}  \\ \hline
		\end{tabular}
		
	}\vspace{-3mm}
	\label{tab:deeper_backbones} 
\end{table}




