\documentclass[journal]{IEEEtran}
\ifCLASSINFOpdf
   \usepackage[pdftex]{graphicx}
   \graphicspath{{../pdf/}{../jpeg/}}
   \DeclareGraphicsExtensions{.pdf,.jpeg,.png}
\else
   \usepackage[dvips]{graphicx}
   \graphicspath{{../eps/}}
   \DeclareGraphicsExtensions{.eps}
\fi
\usepackage{booktabs}
\usepackage{subfigure}
\usepackage[cmex10]{amsmath}
\usepackage{color}
\usepackage{algorithmic}
\usepackage{algorithm}
\usepackage{multirow}
\usepackage[misc]{ifsym}
\usepackage{amsfonts}
\usepackage{url}
\usepackage{array}
\usepackage{footmisc}
\renewcommand{\algorithmicrequire}{\textbf{Input:}} \renewcommand{\algorithmicensure}{\textbf{Output:}} \newcommand{\etal}{\emph{et al.\ }}
\newcommand{\tabincell}[2]{\begin{tabular}{@{}#1@{}}#2\end{tabular}}
\newcommand{\minitab}[2][l]{\begin{tabular}{#1}#2\end{tabular}}
\newcolumntype{C}[1]{>{\centering}p{#1}}
\newcolumntype{L}[1]{>{\raggedleft}p{#1}}
\newcolumntype{R}[1]{>{\raggedright}p{#1}}
\newcolumntype{I}{!{\vrule width 3pt}}
\newlength\savedwidth
\newcommand\whline{\noalign{\global\savedwidth\arrayrulewidth
                            \global\arrayrulewidth 2pt}\hline
                   \noalign{\global\arrayrulewidth\savedwidth}}
\newlength\savewidth
\newcommand\shline{\noalign{\global\savewidth\arrayrulewidth
                            \global\arrayrulewidth 1.0pt}\hline
                   \noalign{\global\arrayrulewidth\savewidth}}


\hyphenation{op-tical net-works semi-conduc-tor}


\begin{document}
\title{DehazeNet: An End-to-End System for Single Image Haze Removal}

\author{Bolun~Cai,
        Xiangmin~Xu,~\IEEEmembership{Member,~IEEE,}
        Kui~Jia,~\IEEEmembership{Member,~IEEE,}
        Chunmei~Qing,~\IEEEmembership{Member,~IEEE,}
        and~Dacheng~Tao,~\IEEEmembership{Fellow,~IEEE}\thanks{B. Cai, X. Xu (\Letter) and C. Qing are with
 School of Electronic and Information Engineering,
 South China University of Technology,
 Wushan RD., Tianhe District, Guangzhou, P.R.China.
 E-mail: \{caibolun@gmail.com, xmxu@scut.edu.cn, qchm@scut.edu.cn\}.}
 \thanks{K. Jia is with the Department of Electrical and Computer Engineering,
Faculty of Science and Technology, University of Macau, Macau 999078, China.
E-mail: \{kuijia@gmail.com\}.}
\thanks{D. Tao is with Centre for Quantum Computation \& Intelligent Systems,
 Faculty of Engineering \& Information Technology, University of Technology Sydney,
 235 Jones Street, Ultimo, NSW 2007, Australia.
 E-mail: \{dacheng.tao@uts.edu.au\}.}}



\markboth{}
{Shell \MakeLowercase{\textit{et al.}}: Bare Demo of IEEEtran.cls for Journals}
\maketitle

\begin{abstract}
Single image haze removal is a challenging ill-posed problem. Existing methods use various constraints/priors to get plausible dehazing solutions. The key to achieve haze removal is to estimate a medium transmission map for an input hazy image. In this paper, we propose a trainable end-to-end system called DehazeNet, for medium transmission estimation. DehazeNet takes a hazy image as input, and outputs its medium transmission map that is subsequently used to recover a haze-free image via atmospheric scattering model. DehazeNet adopts Convolutional Neural Networks (CNN) based deep architecture, whose layers are specially designed to embody the established assumptions/priors in image dehazing. Specifically, layers of Maxout units are used for feature extraction, which can generate almost all haze-relevant features. We also propose a novel nonlinear activation function in DehazeNet, called Bilateral Rectified Linear Unit (BReLU), which is able to improve the quality of recovered haze-free image.  We establish connections between components of the proposed DehazeNet and those used in existing methods. Experiments on benchmark images show that DehazeNet achieves superior performance over existing methods, yet keeps efficient and easy to use.
\end{abstract}

\begin{IEEEkeywords}
Dehaze, image restoration, deep CNN, BReLU.
\end{IEEEkeywords}

\IEEEpeerreviewmaketitle

\section{Introduction}\label{sec:Introduction}

\IEEEPARstart{H}{aze} is a traditional atmospheric phenomenon where dust, smoke and other dry particles obscure the clarity of the atmosphere. Haze causes issues in the area of terrestrial photography, where the light penetration of dense atmosphere may be necessary to image distant subjects. This results in the visual effect of a loss of contrast in the subject, due to the effect of light scattering through the haze particles. For these reasons, haze removal is desired in both consumer photography and computer vision applications.

Haze removal is a challenging problem because the haze transmission depends on the unknown depth which varies at different positions. Various techniques of image enhancement have been applied to the problem of removing haze from a single image, including histogram-based \cite{histogram}, contrast-based \cite{contrast} and saturation-based \cite{saturation}. In addition, methods using multiple images or depth information have also been proposed. For example, polarization based methods \cite{polarization} remove the haze effect through multiple images taken with different degrees of polarization. In \cite{multiimage1}, multi-constraint based methods are applied to multiple images capturing the same scene under different weather conditions. Depth-based methods \cite{depth2} require some depth information from user inputs or known 3D models. In practice, depth information or multiple hazy images are not always available.

Single image haze removal has made significant progresses recently, due to the use of better assumptions and priors. Specifically, under the assumption that the local contrast of the haze-free image is much higher than that of hazy image, a local contrast maximizing method \cite{maxcontrast} based on Markov Random Field (MRF) is proposed for haze removal. Although contrast maximizing approach is able to achieve impressive results, it tends to produce over-saturated images. In \cite{ica}, Independent Component Analysis (ICA) based on minimal input is proposed to remove the haze from color images, but the approach is time-consuming and cannot be used to deal with dense-haze images. Inspired by dark-object subtraction technique, Dark Channel Prior (DCP) \cite{dcp} is discovered based on empirical statistics of experiments on haze-free images, which shows at least one color channel has some pixels with very low intensities in most of non-haze patches. With dark channel prior, the thickness of haze is estimated and removed by the atmospheric scattering model. However, DCP loses dehazing quality in the sky images and is computationally intensive. Some improved algorithms are proposed to overcome these limitations. To improve dehazing quality, Kratz and Nishino \etal \cite{bayesian} model the image with a factorial MRF to estimate the scene radiance more accurately; Meng \etal \cite{bccr} propose an effective regularization dehazing method to restore the haze-free image by exploring the inherent boundary constraint. To improve computational efficiency, standard median filtering \cite{median}, median of median filter \cite{medianmedian}, guided joint bilateral filtering \cite{jointbilateral} and guided image filter \cite{guided} are used to replace the time-consuming soft matting \cite{softmatting}. In recent years, haze-relevant priors are investigated in machine learning framework. Tang \etal \cite{rf} combine four types of haze-relevant features with Random Forests to estimate the transmission. Zhu \etal \cite{cap} create a linear model for estimating the scene depth of the hazy image under color attenuation prior and learns the parameters of the model with a supervised method. Despite the remarkable progress, these state-of-the-art methods are limited by the very same haze-relevant priors or heuristic cues - they are often less effective for some images.

Haze removal from a single image is a difficult vision task. In contrast, the human brain can quickly identify the hazy area from the natural scenery without any additional information. One might be tempted to propose biologically inspired models for image dehazing, by following the success of bio-inspired CNNs for high-level vision tasks such as image classification \cite{imagenet}, face recognition \cite{facednn} and object detection \cite{objectdetection}. In fact, there have been a few (convolutional) neural network based deep learning methods that are recently proposed for low-level vision tasks of image restoration/reconstruction \cite{deconvolution,srcnn,dirtrain}. However, these methods cannot be directly applied to single image haze removal.

Note that apart from estimation of a global atmospheric light magnitude, the key to achieve haze removal is to recover an accurate medium transmission map. To this end, we propose DehazeNet, a trainable CNN based end-to-end system for medium transmission estimation. DehazeNet takes a hazy image as input, and outputs its medium transmission map that is subsequently used to recover the haze-free image by a simple pixel-wise operation. Design of DehazeNet borrows ideas from established assumptions/principles in image dehazing, while parameters of all its layers can be automatically learned from training hazy images. Experiments on benchmark images show that DehazeNet gives superior performance over existing methods, yet keeps efficient and easy to use. Our main contributions are summarized as follows.

\begin{enumerate}
\item DehazeNet is an end-to-end system. It directly learns and estimates the mapping relations between hazy image patches and their medium transmissions. This is achieved by special design of its deep architecture to embody established image dehazing principles.
\item We propose a novel nonlinear activation function in DehazeNet, called Bilateral Rectified Linear Unit\footnote{During the preparation of this manuscript (in December, 2015), we find that a nonlinear activation function called adjustable bounded rectifier is proposed in \cite{abr} (arXived in November, 2015), which is almost identical to BReLU. Adjustable bounded rectifier is motivated to achieve the objective of image recognition. In contrast, BReLU is proposed here to improve image restoration accuracy. It is interesting that we come to the same activation function from completely different initial objectives. This may also suggest the general usefulness of the proposed BReLU.} (BReLU). BReLU extends Rectified Linear Unit (ReLU) and demonstrates its significance in obtaining accurate image restoration. Technically, BReLU uses the bilateral restraint to reduce search space and improve convergence.
\item We establish connections between components of DehazeNet and those assumptions/priors used in existing dehazing methods, and explain that DehazeNet improves over these methods by automatically learning all these components from end to end.
\end{enumerate}

The remainder of this paper is organized as follows. In Section \ref{sec:related}, we review the atmospheric scattering model and haze-relevant features, which provides background knowledge to understand the design of DehazeNet. In Section \ref{sec:dehazecnn}, we present details of the proposed DehazeNet, and discuss how it relates to existing methods. Experiments are presented in Section \ref{sec:experiments}, before conclusion is drawn in Section \ref{sec:conclusion}.

\section{Related Works}\label{sec:related}
Many image dehazing methods have been proposed in the literature. In this section, we briefly review some important ones, paying attention to those proposing the atmospheric scattering model, which is the basic underlying model of image dehazing, and  those proposing useful assumptions for computing haze-relevant features.

\subsection{Atmospheric Scattering Model}\label{sec:asm}
To describe the formation of a hazy image, the atmospheric scattering model is first proposed by McCartney \cite{atmosphere}, which is further developed by Narasimhan and Nayar \cite{badweather,narasimhan}. The atmospheric scattering model can be formally written as

where  is the observed hazy image,  is the real scene to be recovered,  is the medium transmission,  is the global atmospheric light, and  indexes pixels in the observed hazy image . Fig. \ref{fig:atm} gives an illustration. There are three unknowns in equation \eqref{I}, and the real scene  can be recovered after  and  are estimated.


\begin{figure*}
    \begin{minipage}{0.5\linewidth}
    \flushleft
    \subfigure[The process of imaging in hazy weather. The transmission attenuation  caused by the reduction in reflected energy, leads to low brightness intensity. The airlight  formed by the scattering of the environmental illumination, enhances the brightness and reduces the saturation.]{ \label{fig:subfig:round} \includegraphics[width=0.95\linewidth]{Images/model.jpg}}
    \end{minipage}
    \begin{minipage}{0.5\linewidth}
    \flushright
    \subfigure[Atmospheric scattering model. The observed hazy image  is generated by the real scene , the medium transmission   and the global atmospheric light .]{ \label{fig:subfig:maxout} \includegraphics[width=0.95\linewidth]{Images/atm.jpg}}
    \end{minipage}
    \caption{Imaging in hazy weather and atmospheric scattering model}
    \label{fig:atm}
\end{figure*}

The medium transmission map  describes the light portion that is not scattered and reaches the camera.  is defined as

where  is the distance from the scene point to the camera, and  is the scattering coefficient of the atmosphere. Equation \eqref{t} suggests that when  goes to infinity,  approaches zero. Together with equation \eqref{I} we have

In practical imaging of a distance view,  cannot be infinity, but rather be a long distance that gives a very low transmission . Instead of relying on equation \eqref{alpha} to get the global atmospheric light , it is more stably estimated based on the following rule


The discussion above suggests that \emph{to recover a clean scene (i.e., to achieve haze removal), it is the key to estimate an accurate medium transmission map.}

\subsection{Haze-relevant features}\label{sec:features}
Image dehazing is an inherently ill-posed problem. Based on empirical observations, existing methods propose various assumptions or prior knowledge that are utilized to compute intermediate haze-relevant features. Final haze removal can be achieved based on these haze-relevant features.
\subsubsection{Dark Channel}
The dark channel prior is based on the wide observation on outdoor haze-free images. In most of the haze-free patches, at least one color channel has some pixels whose intensity values are very low and even close to zero. The dark channel \cite{dcp} is defined as the minimum of all pixel colors in a local patch:

where  is a RGB color channel of  and  is a local patch centered at  with the size of . The dark channel feature has a high correlation to the amount of haze in the image, and is used to estimate the medium transmission  directly.

\subsubsection{Maximum Contrast}
According to the atmospheric scattering, the contrast of the image is reduced by the haze transmission as  . Based on this observation, the local contrast \cite{maxcontrast} as the variance of pixel intensities in a  local patch  with respect to the center pixel, and the local maximum of local contrast values in a  region  is defined as:

where  is the cardinality of the local neighborhood. The correlation between the contrast feature and the medium transmission  is visually obvious, so the visibility of the image is enhanced by maximizing the local contrast showed as \eqref{C}.

\subsubsection{Color Attenuation}
 The saturation  of the patch decreases sharply while the color of the scene fades under the influence of the haze, and the brightness value  increases at the same time producing a high value for the difference. According to the above color attenuation prior \cite{cap}, the difference between the brightness and the saturation is utilized to estimate the concentration of the haze:

where  and  can be expressed in the HSV color space as  and . The color attenuation feature is proportional to the scene depth , and is used for transmission estimation easily.

\subsubsection{Hue Disparity}
Hue disparity between the original image  and its semi-inverse image,  with , has been used to detect the haze. For haze-free images, pixel values in the three channels of their semi-inverse images will not all flip, resulting in large hue changes between  and . In \cite{semiinverse}, the hue disparity feature is defined:

where the superscript "" denotes the hue channel of the image in HSV color space. According to \eqref{H}, the medium transmission  is in inverse propagation to .

\section{The Proposed DehazeNet}\label{sec:dehazecnn}

The atmospheric scattering model in Section \ref{sec:asm} suggests that estimation of the medium transmission map is the most important step to recover a haze-free image. To this end, we propose DehazeNet, a trainable end-to-end system that explicitly learns the mapping relations between raw hazy images and their associated medium transmission maps. In this section, we present layer designs of DehazeNet, and discuss how these designs are related to ideas in existing image dehazing methods.  The final pixel-wise operation to get a recovered haze-free image from the estimated medium transmission map will be presented in Section \ref{sec:experiments}.

\subsection{Layer Designs of DehazeNet}
The proposed DehazeNet consists of cascaded convolutional and pooling layers, with appropriate nonlinear activation functions employed after some of these layers. Fig. \ref{fig:hazenet} shows the architecture of DehazeNet. Layers and nonlinear activations of DehazeNet are designed to implement four sequential operations for medium transmission estimation, namely, feature extraction, multi-scale mapping, local extremum, and nonlinear regression. We detail these designs as follows.
\begin{figure*}[!t]
\centering
\includegraphics[width=0.95\linewidth]{Images/hazenet.jpg}
\caption{The architecture of DehazeNet. DehazeNet conceptually consists of four sequential operations (feature extraction, multi-scale mapping, local extremum and non-linear regression), which is constructed by 3 convolution layers, a max-pooling, a Maxout unit and a BReLU activation function.}
\label{fig:hazenet}
\end{figure*}

\subsubsection{Feature Extraction}
To address the ill-posed nature of image dehazing problem, existing methods propose  various assumptions and based on these assumptions, they are able to extract haze-relevant features (e.g., dark channel, hue disparity, and color attenuation) densely over the image domain. Note that densely extracting these haze-relevant features is equivalent to convolving an input hazy image with appropriate filters, followed by nonlinear mappings. Inspired by extremum processing in color channels of those haze-relevant features, an unusual activation function called Maxout unit \cite{maxout} is selected as the non-linear mapping for dimension reduction. Maxout unit is a simple feed-forward nonlinear activation function used in multi-layer perceptron or CNNs. When used in CNNs, it generates a new feature map by taking a pixel-wise maximization operation over  affine feature maps. Based on Maxout unit, we design the first layer of DehazeNet as follows

where  and  represent the filters and biases respectively, and  denotes the convolution operation. Here, there are  output feature maps in the first layer.  is one of the total  convolution filters, where 3 is the number of channels in the input image , and  is the spatial size of a filter (detailed in Table \ref{tab:architectures}). Maxout unit maps each of -dimensional vectors into an -dimensional one, and extracts the haze-relevant features by automatic learning rather than heuristic ways in existing methods.

\subsubsection{Multi-scale Mapping}
In \cite{rf}, multi-scale features have been proven effective for haze removal, which densely compute features of an input image at multiple spatial scales. Multi-scale feature extraction is also effective to achieve scale invariance. For example, the inception architecture in GoogLeNet \cite{googlenet} uses parallel convolutions with varying filter sizes, and better addresses the issue of aligning objects in input images, resulting in state-of-the-art performance in ILSVRC14 \cite{ilsvrc}. Motivated by these successes of multi-scale feature extraction,  we choose to use parallel convolutional operations in the second layer of DehazeNet, where size of any convolution filter is among {,  and }, and we use the same number of filters for these three scales. Formally, the output of the second layer is written as

where  and  contain  pairs of parameters that is break up into 3 groups.  is the output dimension of the second layer, and  indexes the output feature maps.  takes the integer upwardly and  denotes the remainder operation.

\subsubsection{Local Extremum}
To achieve spatial invariance, the cortical complex cells in the visual cortex receive responses from the simple cells for linear feature integration. Ilan \etal \cite{maxpool} proposed that spatial integration properties of complex cells can be described by a series of pooling operations. According to the classical architecture of CNNs \cite{lenet}, the neighborhood maximum is considered under each pixel to overcome local sensitivity. In addition, the local extremum is in accordance with the assumption that the medium transmission is locally constant, and it is commonly to overcome the noise of transmission estimation. Therefore, we use a local extremum operation in the third layer of DehazeNet.

where  is an  neighborhood centered at , and the output dimension of the third layer . In contrast to max-pooling in CNNs, which usually reduce resolutions of feature maps, the local extremum operation here is densely applied to every feature map pixel, and is able to preserve resolution for use of image restoration.

\subsubsection{Non-linear Regression}
Standard choices of nonlinear activation functions in deep networks include Sigmoid \cite{function} and Rectified Linear Unit (ReLU). The former one is easier to suffer from vanishing gradient, which may lead to slow convergence or poor local optima in networks training. To overcome the problem of vanishing gradient, ReLU is proposed \cite{relu} which offers sparse representations. However, ReLU is designed for classification problems and not perfectly suitable for the regression problems such as image restoration. In particular, ReLU inhibits values only when they are less than zero. It might lead to response overflow especially in the last layer, because for image restoration, the output values of the last layer are supposed to be both lower and upper bounded in a small range.  To this end, we propose a Bilateral Rectified Linear Unit (BReLU) activation function, shown in Fig. \ref{fig:drelu}, to overcome this limitation. Inspired by Sigmoid and ReLU, BReLU as a novel linear unit keeps bilateral restraint and local linearity. Based on the proposed BReLU, the feature map of the fourth layer is defined as
\begin{figure}[!t]
\centering
\subfigure[ReLU]{ \label{fig:drelu:relu} \includegraphics[width=0.4\linewidth]{Images/relu.jpg}}
    \subfigure[BReLU]{ \label{fig:drelu:drelu} \includegraphics[width=0.42\linewidth]{Images/drelu.jpg}}
\caption{Rectified Linear Unit (ReLU) and Bilateral Rectified Linear Unit (BReLU)}
\label{fig:drelu}
\end{figure}

Here  contains a filter with the size of ,  contains a bias, and  is the marginal value of BReLU ( and  in this paper). According to \eqref{F4}, the gradient of this activation function can be shown as


The above four layers are cascaded together to form a CNN based trainable end-to-end system, where filters and biases associated with convolutional layers are network parameters to be learned. We note that designs of these layers can be connected with expertise in existing image dehazing methods, which we specify in the subsequent section.

\subsection{Connections with Traditional Dehazing Methods}\label{sec:relationship}

The first layer feature  in DehazeNet is designed for haze-relevant feature extraction. Take dark channel feature \cite{dcp} as an example. If the weight  is an opposite filter (sparse matrices with the value of -1 at the center of one channel, as in Fig. \ref{fig:subfig:opposite}) and  is a unit bias, then the maximum output of the feature map is equivalent to the minimum of color channels, which is similar to dark channel \cite{dcp} (see Equation \eqref{D}). In the same way, when the weight is a round filter as Fig. \ref{fig:subfig:round},  is similar to the maximum contrast \cite{maxcontrast} (see Equation \eqref{C}); when  includes all-pass filters and opposite filters,  is similar to the maximum and minimum feature maps, which are atomic operations of the color space transformation from RGB to HSV, then the color attenuation \cite{cap} (see Equation \eqref{A}) and hue disparity \cite{semiinverse} (see Equation \eqref{H}) features are extracted. In conclusion, upon success of filter learning shown in Fig. \ref{fig:subfig:kernel}, almost all haze-relevant features can be potentially extracted from the first layer of DehazeNet. On the other hand, Maxout activation functions can be considered as piece-wise linear approximations to arbitrary convex functions. In this paper, we choose the maximum across four feature maps () to approximate an arbitrary convex function, as shown in Fig. \ref{fig:subfig:maxout}.
\begin{figure}
    \centering
    \subfigure[Opposite filter]{ \label{fig:subfig:opposite} \includegraphics[width=0.22\linewidth]{Images/opposite.jpg}}
    \subfigure[All-pass filter]{ \label{fig:subfig:allpass} \includegraphics[width=0.22\linewidth]{Images/allpass.jpg}}
    \subfigure[Round filter]{ \label{fig:subfig:round} \includegraphics[width=0.22\linewidth]{Images/round.jpg}}
    \subfigure[Maxout]{ \label{fig:subfig:maxout} \includegraphics[width=0.22\linewidth]{Images/maxout.jpg}}

    \subfigure[The actual kernels learned from DehazeNet]{
    \label{fig:subfig:kernel}
    \begin{minipage}[b]{1.0\linewidth}
    \centering
    \includegraphics[width=0.1\linewidth]{Images/kernel/kenel_2.png}
    \includegraphics[width=0.1\linewidth]{Images/kernel/kenel_13.png}
    \includegraphics[width=0.1\linewidth]{Images/kernel/kenel_16.png}
    \includegraphics[width=0.1\linewidth]{Images/kernel/kenel_1.png}
    \includegraphics[width=0.1\linewidth]{Images/kernel/kenel_15.png}
    \includegraphics[width=0.1\linewidth]{Images/kernel/kenel_14.png}
    \includegraphics[width=0.1\linewidth]{Images/kernel/kenel_7.png}
    \includegraphics[width=0.1\linewidth]{Images/kernel/kenel_8.png}
    \\label{loss}
L\left( \Theta  \right) = \frac{1}{N}\sum\limits_{i = 1}^N {{{\left\| {\mathcal{F}\left( {I_i^P;\Theta } \right) - {t_i}} \right\|}^2}}
\label{J}
J\left( x \right) = \frac{{I\left( x \right) - \alpha \left( {1 - t\left( x \right)} \right)}}{{t\left( x \right)}}
-)}} &\textbf{4-(163)} & \textbf{1.090} & \textbf{1.190} &\hspace{0.5em}\textbf{8,240}\\
  &8-() & 0.972 & 1.138 &27,104\\
  &16-() & 0.902 & 1.112 &96,704\\
  \hline
  \hline
  \multirow{4}{*}{\tabincell{c}{ Size\f_1f_2f_3f_4F_2F_27\times7F_3F_4F_4F_3F_3F_4t\in \left(0,1\right)\times10^{-2}d\left(x\right)\beta=1\alpha =1\beta=1\alpha=1\beta\beta\in\{0.75,1.0,1.25,1.5\}\beta=0.75\beta=1F_1(\beta=)(\alpha=)(s=)(\sigma=)\alpha\alpha=1[1.0, 1.0, 0.9]sF_2\sigma\in\{10,15,20,25\}F_1F_3F_1F_4\alpha$ cannot be regarded as a global constant, which will be learned together with medium transmission in a unified network. Moreover, we think atmospheric scattering model can also be learned in a deeper neural network, in which an end-to-end mapping between haze and haze-free images can be optimized directly without the medium transmission estimation.
We leave this problem for future research.



\ifCLASSOPTIONcaptionsoff
  \newpage
\fi

\bibliographystyle{IEEEtran}
\bibliography{refs}








\end{document}
