[{'LEADERBOARD': {'Task': 'Question Answering', 'Dataset': 'PIQA', 'Metric': 'Accuracy', 'Score': '81.07'}}, {'LEADERBOARD': {'Task': 'Question Answering', 'Dataset': 'PIQA', 'Metric': 'Accuracy', 'Score': '80.63'}}, {'LEADERBOARD': {'Task': 'Question Answering', 'Dataset': 'PIQA', 'Metric': 'Accuracy', 'Score': '79.54'}}, {'LEADERBOARD': {'Task': 'Question Answering', 'Dataset': 'PIQA', 'Metric': 'Accuracy', 'Score': '54.73'}}, {'LEADERBOARD': {'Task': 'Question Answering', 'Dataset': 'Story Cloze', 'Metric': 'Accuracy', 'Score': '79.82'}}, {'LEADERBOARD': {'Task': 'Question Answering', 'Dataset': 'Story Cloze', 'Metric': 'Accuracy', 'Score': '78.87'}}, {'LEADERBOARD': {'Task': 'Question Answering', 'Dataset': 'Story Cloze', 'Metric': 'Accuracy', 'Score': '77.02'}}, {'LEADERBOARD': {'Task': 'Question Answering', 'Dataset': 'Story Cloze', 'Metric': 'Accuracy', 'Score': '76.19'}}, {'LEADERBOARD': {'Task': 'Question Answering', 'Dataset': 'Story Cloze', 'Metric': 'Accuracy', 'Score': '47.10'}}, {'LEADERBOARD': {'Task': 'Common Sense Reasoning', 'Dataset': 'ARC (Challenge)', 'Metric': 'Accuracy', 'Score': '43.94'}}, {'LEADERBOARD': {'Task': 'Common Sense Reasoning', 'Dataset': 'ARC (Challenge)', 'Metric': 'Accuracy', 'Score': '41.3'}}, {'LEADERBOARD': {'Task': 'Common Sense Reasoning', 'Dataset': 'ARC (Challenge)', 'Metric': 'Accuracy', 'Score': '39.85'}}, {'LEADERBOARD': {'Task': 'Common Sense Reasoning', 'Dataset': 'ARC (Challenge)', 'Metric': 'Accuracy', 'Score': '38.99'}}, {'LEADERBOARD': {'Task': 'Common Sense Reasoning', 'Dataset': 'ARC (Challenge)', 'Metric': 'Accuracy', 'Score': '25.6'}}, {'LEADERBOARD': {'Task': 'Common Sense Reasoning', 'Dataset': 'ARC (Easy)', 'Metric': 'Accuracy', 'Score': '71.04'}}, {'LEADERBOARD': {'Task': 'Common Sense Reasoning', 'Dataset': 'ARC (Easy)', 'Metric': 'Accuracy', 'Score': '69.65'}}, {'LEADERBOARD': {'Task': 'Common Sense Reasoning', 'Dataset': 'ARC (Easy)', 'Metric': 'Accuracy', 'Score': '68.35'}}, {'LEADERBOARD': {'Task': 'Common Sense Reasoning', 'Dataset': 'ARC (Easy)', 'Metric': 'Accuracy', 'Score': '67.08'}}, {'LEADERBOARD': {'Task': 'Common Sense Reasoning', 'Dataset': 'ARC (Easy)', 'Metric': 'Accuracy', 'Score': '28.03'}}, {'LEADERBOARD': {'Task': 'Language Modelling', 'Dataset': 'LAMBADA', 'Metric': 'Accuracy', 'Score': '79.47'}}, {'LEADERBOARD': {'Task': 'Language Modelling', 'Dataset': 'LAMBADA', 'Metric': 'Accuracy', 'Score': '78.77'}}, {'LEADERBOARD': {'Task': 'Language Modelling', 'Dataset': 'LAMBADA', 'Metric': 'Accuracy', 'Score': '76.51'}}, {'LEADERBOARD': {'Task': 'Language Modelling', 'Dataset': 'LAMBADA', 'Metric': 'Accuracy', 'Score': '75.59'}}, {'LEADERBOARD': {'Task': 'Language Modelling', 'Dataset': 'LAMBADA', 'Metric': 'Accuracy', 'Score': '0.02'}}, {'LEADERBOARD': {'Task': 'Language Modelling', 'Dataset': 'WikiText-2', 'Metric': 'Test perplexity', 'Score': '8.21'}}, {'LEADERBOARD': {'Task': 'Language Modelling', 'Dataset': 'WikiText-2', 'Metric': 'Test perplexity', 'Score': '8.34'}}, {'LEADERBOARD': {'Task': 'Language Modelling', 'Dataset': 'WikiText-2', 'Metric': 'Test perplexity', 'Score': '8.45'}}, {'LEADERBOARD': {'Task': 'Language Modelling', 'Dataset': 'WikiText-2', 'Metric': 'Test perplexity', 'Score': '8.73'}}, {'LEADERBOARD': {'Task': 'Language Modelling', 'Dataset': 'WikiText-2', 'Metric': 'Test perplexity', 'Score': '234.77'}}]
