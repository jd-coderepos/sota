
\documentclass{article}


\PassOptionsToPackage{square,numbers, sort}{natbib}

\usepackage[preprint]{neurips_2022}











\usepackage[utf8]{inputenc} \usepackage[T1]{fontenc}    \usepackage{hyperref}       \usepackage{url}            \usepackage{booktabs}       \usepackage{amsfonts}       \usepackage{nicefrac}       \usepackage{microtype}      \usepackage{xcolor}         \usepackage{graphicx}
\usepackage{amsmath}
\usepackage{subcaption}

\newcommand{\xb}{\mathbf{x}}
\newcommand{\yb}{\mathbf{y}}
\newcommand{\zb}{\mathbf{z}}
\newcommand{\bb}{\mathbf{b}}
\newcommand{\gb}{\mathbf{g}}
\newcommand{\pb}{\mathbf{p}}
\newcommand{\Mb}{\mathbf{M}}
\newcommand{\Ib}{\mathbf{I}}


\title{Rethinking the compositionality of point clouds through regularization in the hyperbolic space}


\author{Antonio Montanaro\thanks{Code of the project: \url{https://github.com/diegovalsesia/HyCoRe} } \\
  Politecnico di Torino, Italy\\
  \texttt{antonio.montanaro@polito.it} \\
\And
  Diego Valsesia\\
  Politecnico di Torino, Italy\\
  \texttt{diego.valsesia@polito.it} \\
  \AND
  Enrico Magli\\
  Politecnico di Torino, Italy\\
  \texttt{enrico.magli@polito.it} \\
}

\usepackage{graphicx,wrapfig,lipsum}

\begin{document}


\maketitle


\begin{abstract}
Point clouds of 3D objects exhibit an inherent compositional nature where simple parts can be assembled into progressively more complex shapes to form whole objects. Explicitly capturing such part-whole hierarchy is a long-sought objective in order to build effective models, but its tree-like nature has made the task elusive. In this paper, we propose to embed the features of a point cloud classifier into the hyperbolic space and explicitly regularize the space to account for the part-whole hierarchy. The hyperbolic space is the only space that can successfully embed the tree-like nature of the hierarchy. This leads to substantial improvements in the performance of state-of-art supervised models for point cloud classification.
\end{abstract}


\section{Introduction}

Is the whole more than the sum of its parts? While philosophers have been debating such deep question since the time of Aristotle, we can certainly say that understanding and capturing the relationship between parts as constituents of whole complex structures is of paramount importance in building models of reality. In this paper, we turn our attention to the compositional nature of 3D objects, represented as point clouds, where simple parts can be assembled to form progressively more complex shapes. Indeed, the complex geometry of an object can be better understood by unraveling the implicit hierarchy of its parts. Such hierarchy can be intuitively captured by a tree where nodes close to the root represent basic universal shapes, which become progressively more complex as we approach the whole-object leaves. Transforming an object into another requires swapping parts by traversing the tree up to a common ancestor part. It is thus clear that a model extracting features, that claim to capture the nature of 3D objects, needs to incorporate such hierarchy.

In the last years, point cloud processing methods have tried to devise methods to extract complex geometric information from points and neighborhoods. Architectures like graph neural networks \cite{shi2020point} compose the features extracted by local receptive fields, with sophisticated geometric priors \cite{chen2021equivariant} exploiting locality and self-similarity, while a different school of thought argues that simple architectures, such as PointMLP \cite{ma2022rethinking} and SimpleView \cite{goyal2021revisiting}, with limited geometric priors are nevertherless very effective. It thus raises a question whether prior knowledge about the data is being exploited effectively.

In this sense, works such as PointGLR \cite{rao2020global}, Info3D \cite{sanghi2020info3d} and DCGLR \cite{fu2022distillation} recognized the need to reason about local and global interactions in the feature extraction process. In particular, their claim is that maximizing the mutual information between parts and whole objects leads to understanding of local and global relations. Although these methods present compelling results for unsupervised feature extraction, they still fall short of providing significant improvements when finetuned with supervision.

In our work, we argue that those methods do not fulfill their promise of capturing the part-whole relationship because they are unable to represent the tree-like nature of the compositional hierarchy. Indeed, their fundamental weakness lies in the use of spaces that are either flat (Euclidean) or with positive curvature (spherical). However, it is known that only spaces with negative curvature (hyperbolic) are able to embed tree structures with low distortion \cite{sarkar2011low}. This is due to the fact that the volume of the Euclidean space grows only as a power of its radius rather than exponentially, limiting the representation capacity of tree-like data with an exponential number of leaves. This unique characteristic has inspired many researchers to represent hierarchical relations in many domains, from natural language processing \cite{nickel2017poincare},\cite{ganea2018hyperbolic} to computer vision \cite{weng2021unsupervised} ,\cite{hsu2021capturing}. However, the use of such principles for point clouds and 3D data is still unexplored.

The main contributions of this paper lie in the following aspects:
\begin{itemize}
    \item we propose a novel regularizer to supervised training of point cloud classification models that promotes the part-whole hierarchy of compositionality in the hyperbolic space;
    \item this regularizer can be applied to any state-of-art architecture with a simple modification of its head to perform classification with hyperbolic layers in the regularized space, coupled with Riemannian optimization \cite{becigneul2018riemannian};
    \item we observe a significant improvement in the performance of a number of popular architectures, including state-of-the-art techniques, surpassing the currently known best results on two different datasets;
    \item we are the first to experimentally observe the desired part-whole hierarchy, by noticing that the geodesics in hyperbolic space between whole objects pass though common part ancestors.
\end{itemize}


\section{Related work}
\label{sec:related}

\textbf{Point Cloud Analysis} Point cloud data are sets of multiple points and, in recent years, several deep neural networks have been studied to process them. Early works adapted models for images through 2D projections \cite{you2018pvnet}, \cite{li2020end}. Later, PointNet \cite{qi2017pointnet} established new models working directly on the raw set of 3D coordinates by exploiting shared architectures invariant to points permutation. Originally, PointNet independently processed individual points through a shared MLP. To improve performance, PointNet++ \cite{qi2017pointnet++} exploited spatial correlation by using a hierarchical feature learning paradigm.
Other methods \cite{liu2019relation}, \cite{wu2019pointconv}, \cite{li2018pointcnn}, treat point clouds as a graph and exploit operators defined over irregular sets to capture relations among points and their neighbors at different resolutions. This is the case of DGCNN \cite{wang2019dynamic}, where the EdgeConv graph convolution operation aggregates features supported on neighborhoods as defined by a nearest neighbor graph dynamically computed in the feature space.
Recently, PointMLP \cite{ma2022rethinking} revisits PointNet++ to include the concept of residual connections. Through this simple model, the authors show that sophisticated geometric models are not essential to obtain state-of-the-art performance. 

\textbf{Part Compositionality} Successfully capturing the semantics of 3D objects represented as point clouds requires to learn interactions between local and global information, and, in particular, the compositional nature of 3D objects as constructed from local parts. Indeed, some works have focused on capturing global-local reasoning in point cloud processing. One of the first and most representative works is PointGLR \cite{rao2020global}. In this work, the authors map local features at different levels within the network to a common hypersphere where the global features embedding is made close to such local embeddings. This is the first approach towards modeling the similarities of parts (local features) and whole objects (global features). The use of a hypersphere as embedding space for similarity promotion traces its roots in metric learning works for face recognition \cite{deng2019arcface}. In addition to the global-local embedding, PointGLR added two other pretext tasks, namely normal estimation and self-reconstruction, to further promote learning of highly discriminative features. Our work significantly differs from PointGLR in multiple ways: i) a positive curvature manifold such as the hypersphere is unable to accurately embed hierarchies (tree-like structures), hence our adoption of the hyperbolic space; ii) we actively promote a continuous embedding of part-whole hierarchies by penalizing the hyperbolic norm of parts proportionally to their number of points (a proxy for part complexity); iii) we move the classification head of the model to the hyperbolic space to exploit our regularized geometry. A further limitation of PointGLR is the implicit assumption of a model generating progressive hierarchies (e.g. via expanding receptive fields) in the intermediate layers. In contrast, our work can be readily adopted by any state-of-the-art model with just a replacement of the final layers.
Other works revisit the global-local relations using maximization of mutual information between different views \cite{sanghi2020info3d}, clustering and contrastive learning \cite{mei2022unsupervised}, distillation with constrast \cite{fu2022distillation}, self-similarity and contrastive learning with hard negative samples \cite{du2021self}.
Although most of these works include the contrastive strategy, they differ in the way they contrast the positive and negative samples and in the details of the self-supervision procedures, e.g., contrastive loss and point cloud augmentations. We also notice that most these works focus on unsupervised learning, and, while they show that the features learned in this manner are highly discriminative, they are also mostly unable to improve upon state-of-the-art supervised methods when finetuned with full supervision. 
These approaches differ from the one followed in this paper, where we focus on regularization of a fully supervised method, and we show improvements upon the supervised baselines that do not adopt our regularizer.


\textbf{Hyperbolic Learning} The intuition that the hyperbolic space is crucial to embed hierarchical structures comes from the work of Sarkar \cite{sarkar2011low} who proved that trees can be embedded in the hyperbolic space with arbitrarily low distortion. This inspired several works which investigated how various frameworks of representation learning can be reformulated in non-Euclidean manifolds. In particular, \cite{nickel2017poincare} \cite{becigneul2018riemannian} and \cite{ganea2018hyperbolic} were some of the first works to explore hyperbolic representation learning by introducing Riemannian adaptive optimization, Poincarè embeddings and hyperbolic neural networks for natural language processing. The new mathematical formalism introduced by Ganea et al. \cite{ganea2018hyperbolic} was decisive to demonstrate the effectiveness of hyperbolic variants of neural network layers compared to the Euclidean counterparts. 
Generalizations to other data, such as images \cite{khrulkov2020hyperbolic} and graphs \cite{ying2018graph} with the corresponding hyperbolic variants of the main operations like graph convolution \cite{ying2018graph} and gyroplane convolution \cite{hsu2021capturing} have also been studied.
In the context of unsupervised learning, new objectives in the hyperbolic space force the models to include the implicit hierarchical structure of the data leading to a better clustering in the embedding space \cite{hsu2021capturing}, \cite{weng2021unsupervised}.
To the best of our knowledge, no work has yet focused on hyperbolic representations for point clouds. Indeed, 3D objects present an intrinsic hierarchy where whole objects are made by parts of different size. While the smallest parts may be shared across different object classes, the larger the parts the more class-specific they become. This consistently fits with the structure of a tree where simple fundamental parts are shared ancestors of complex objects and hence we show how the hyperbolic space can fruitfully capture this data prior. 



\section{Method} 

\begin{figure}
  \centering
    \includegraphics[width=0.95\textwidth]{figures/architecture.pdf}
  \caption{HyCoRe overview. A point cloud classification model is regularized by promoting the feature space to include compositional information. Hierarchy regularizer: simple parts should be mapped closer to the center of the Poincarè disk (common ancestors of whole objects). Contrastive regularizer: parts of the same class should be embedded closer than parts of other classes. }
  \label{fig:arch}
\end{figure}



In this section we present our proposed method, named HyCoRe (Hyperbolic Compositional Regularizer). An overview is presented in Fig. \ref{fig:arch}. At a high level, HyCoRe enhances any state-of-the-art neural network model for point cloud classification by 1) replacing its last layers with layers performing transformations in the hyperbolic space (see Sec. \ref{sec:hyperbolic_nn}), and 2) regularizing the classification loss to induce a desirable configuration of the hyperbolic feature space where embeddings of parts both follow a hierarchy and cluster according to class labels. 


\subsection{Compositional Hierarchy in 3D Point Clouds}

The objective of HyCoRe is to regularize the feature space produced by a neural network so that it captures the compositional structure of the 3D point cloud at different levels. In particular, we notice that there exists a hierarchy where small parts (e.g., simple structures like disks, squares, triangles) composed of few points are universal ancestors to more complex shapes included in many different objects. As these structures are composed into more complex parts with more points, they progressively become more specific to an object or class. This hierarchy can be mathematically represented by a tree, as depicted in Fig.\ref{fig:tree} where a simple cylinder can be the ancestor of both pieces of a chair or a table. While the leaves in the tree are whole objects, thus belonging to a specific class, their ancestors are progressively more universal the higher up in the hierarchy they sit.

At this point, it is important noting that the graph distance between leaves is determined by the shortest path passing through the first common ancestor for objects in the same or similar classes, while objects from significantly dissimilar classes have the shortest path passing through the root of the hierarchy. In order to ensure that we can embed this tree structure in a feature space, we need a space that preserves the geometrical properties of trees and especially the graph distance. In particular, the embedding space must be able to accommodate the exponential volume growth of a tree along its radius. A classic result by Sarkar \cite{sarkar2011low} showed that flat Euclidean space does not provide this, leading to high errors when embedding trees, even in high dimensions. On the contrary, the hyperbolic space, a Riemannian manifold with negative curvature, does support exponentially increasing volumes and can embed trees with arbitrarily low distortion. Indeed, the geodesic (shortest path) between two points in this space does pass through points closer to the origin, mimicking the behavior of distance defined over a tree.

In particular, we will focus on the Poincarè ball model of hyperbolic space. Since hyperbolic space is a non-Euclidean manifold, it cannot benefit from conventional vector representations and linear algebra. As a consequence, classical neural networks cannot operate in such a space. However, we will use extensions \cite{ganea2018hyperbolic} of classic layers defined through the concept of gyrovector spaces. 


\subsection{Hyperbolic Space and Neural Networks}\label{sec:hyperbolic_nn}
The hyperbolic space is a Riemannian manifold with constant negative curvature. The curvature determines the metric of a space by the following formula:
    


where  is the metric tensor of a generic Riemannian manifold,  is the conformal factor that depends on the curvature  and on the point  on which is calculated, and  is the metric tensor of the Euclidean space , i.e., the identity tensor . Note how the metric depends on the coordinates (through ) for , and how  yields , i.e., the Euclidean space is a flat Riemannian manifold with zero curvature. Spaces with  are spherical, and with  hyperbolic.

The Poincarè Ball in  dimensions  is a hyperbolic space with , and it is isometric to other models such as the Lorentz model. The distance and norm are defined as:



Since the Poincarè Ball is a Riemannian manifold, for each point  we can define a logarithmic map  :  that maps points from the Poincarè Ball to the corresponding tangent space , and an exponential map  :  that does the opposite. These operations \cite{ganea2018hyperbolic} are fundamental to move from one space to the other and viceversa.

The formalism to generalize tensor operations in the hyperbolic space is called the gyrovector space, where addition, scalar multiplication, vector-matrix multiplication and other operations are redefined as M\"{o}bius operations and work in Riemannian manifolds with curvature . These become the basic blocks of the hyperbolic neural networks. In particular, we will use the hyperbolic feed forward (FF) layer (also known as M\"{o}bius layer).
Considering the Euclidean case, for a FF layer, we need a matrix  to linearly project the input  to the feature space , and, additionally, a translation made by a bias addition, i.e.,  with  and, finally, a pointwise non-linearity .

Matrix multiplication, bias and pointwise non-linearity are replaced by M\"{o}bius operations in the gyrovector space and become:

where  and  are the same matrix and vector defined above,  is the magnitude of the curvature. Note that when  we recover the Euclidean feed-forward layer. An interesting property of the M\"{o}bius layer is that it is highly nonlinear; indeed the bias addition in hyperbolic space becomes a nonlinear mapping since geodesics are curved paths in non-flat manifolds.


\subsection{Hyperbolic Compositional Regularization}

\begin{figure}
  \centering
    \includegraphics[width=0.38\textwidth]{figures/hier_tree.pdf}
    \qquad
    \includegraphics[width=0.43\textwidth]{figures/hier_emb_b.pdf}
  \caption{3D objects possess inherent hierarchies due to their nature as compositions of small parts. The hyperbolic space can embed trees and hierarchical structures with lower distortions than the Euclidean space. The number of points in the embedded part point cloud is highlighted in figure. Embeddings shown are experimental results projected to 2D Poincarè disk with hyperbolic UMAP.}
  \label{fig:tree}
\end{figure}


Armed with the formalism introduced in the previous section, we are ready to formulate our HyCoRe framework, anticipated in Fig. \ref{fig:arch}.
Consider a point cloud  as a set of 3D points  with  elements. We use any state-of-the-art point cloud processing network as a feature extraction backbone  to encode  in the corresponding feature space. At this point we apply an exponential map  to map the Euclidean feature vector into the hyperbolic space and then a M\"{o}bius layer   to project the hyperbolic vector in an -dimensional Poincarè ball. This is the hyperbolic embedding of the whole point cloud , i.e., . We repeat the same procedure for a sub-part of , which we call  with a number of points , to create the part embedding  in the same feature space as before.

We now want to regularize the feature space to induce the previously mentioned properties, namely the part-whole hierarchy and clustering according to the class labels. This is performed by defining the following triplet regularizers:


where  and  are the hyperbolic representation of the whole and a part from the same point cloud, while  is the embedding of a part of a different point cloud from a different class. 

\begin{wrapfigure}{r}{0.5\textwidth}
   \centering
   \includegraphics[width=0.46\textwidth]{figures/geodesic.pdf}
   \caption{Geodesic path.}
   \label{fig:geodesic}
\end{wrapfigure}

The  regularizer in Eq. \eqref{eq:reg_hier} induces the compositional part-whole hierarchy by promoting part embeddings to lie closer to the center of the Poincarè ball and whole embeddings to be closer to the edge. In particular, we use a variable margin  that depends on the number of points  of the part . This means that shapes composed by few points (hence simple universal shapes) will be far from the whole object representation and with lower hyperbolic norm (near the centre). On the other hand, embeddings of larger parts will be progressively closer to the edge of the Poincarè ball, depending on the part size. Since geodesics between two points pass closer to the ball center (Fig. \ref{fig:geodesic}), this structure we impose to the space allows to visit common part ancestors while traversing a geodesic between two whole objects. This regularization thus mimics a continuous version of a part-whole tree embedded in the Poincarè ball.

The  regularizer in Eq. \eqref{eq:reg_contr} promotes correct clustering of objects and parts in the hyperbolic space. In particular, parts and whole of the same point cloud are promoted to be close while a part from a different class is mapped far apart with respect to the other whole.
It ensures that the parts of a point cloud of a different class are far in terms of geodesic distance.  is a margin hyperparameter to control the degree of separation between positive and negative samples. 


The two regularizations are included in the final loss in this way:

where  is the conventional classification loss (e.g., cross-entropy) evaluated on the whole objects. The classification head is a hyperbolic M\"{o}bius layer followed by softmax. In principle, one could argue that  could already promote correct clustering according to class labels, rendering  redundant. However, several works \cite{ganea2018hyperbolic} have noticed that the M\"{o}bius-softmax hyperbolic head is weaker than its Euclidean counterpart. We thus found it more effective to evaluate  on the whole objects only, and use  as a metric penalty that explicitly considers geodesic distances to ensure correct clustering of both parts and whole objects.

At each iteration of training with HyCoRe we sample shapes with a random  varying within a predefined range. A part is defined as the  nearest neighbors of a random point. In future work, it would be interesting to explore alternative definitions for parts, e.g., using part labels if available but, at the moment, we only address definition via spatial neighbors to avoid extra labeling requirements.


\section{Experimental results}

\subsection{Experimental setting}


We study the performance of our regularizer HyCoRe on the synthetic dataset ModelNet40 \cite{wu20153d} (12,331 objects with 1024 points, 40 classes) and on the real dataset ScanObjectNN \cite{uy2019revisiting} (15,000 objects with 1024 points, 15 classes). 
We apply our method over multiple classification architectures, namely the widely popular DGCNN and PointNet++ baselines, as well as the recent state-of-the-art PointMLP model. We substitute the standard classifier with its hyperbolic version (M\"{o}bius+softmax), as shown in Fig. \ref{fig:arch}. We use  features to be comparable to the official implementations in the Euclidean space, then we test the model over different embedding dimensions in the ablation study.
Moreover, we set ,  and . For the number of points of each part , we select a random number between 200 and 600, and for the whole object a random number between 800 and 1024 to ensure better flexibility of the learned to model to part sizes. 
We train the models using Riemannian SGD optimization. Our implementation is on Pytorch and we use \textit{geoopt} \cite{geoopt2020kochurov} for the hyperbolic operations. Models are trained on an Nvidia A6000 GPU.


\subsection{Main Results}


\begin{table}
  \caption{Classification results on ModelNet40. *: re-implemented. **: re-implemented but did not exactly reproduce the reference result.}
\setlength\tabcolsep{2pt} 
  \label{class-mn40}
  \centering
  \begin{tabular}{lccc}
    \toprule
Method     & AA()     & OA() & Training \\
    \midrule
    *PointNet++\cite{qi2017pointnet++}    & -  &  90.5 & supervised   \\
    *DGCNN\cite{wang2019dynamic}    & 90.2  &  92.9  & supervised  \\
    Point Transformer \cite{zhao2021point} & 90.6 & 93.7 & supervised \\
    PA-DGC \cite{xu2021paconv}            & - & 93.6 & supervised \\
    CurveNet \cite{xiang2021walk}          & - & 93.8 & supervised \\
    **PointMLP\cite{ma2022rethinking} & 91.2  &   93.4   & supervised \\
    **PointMLP (voting) & 91.4  &   93.7   & supervised \\
    \midrule
    DGCNN+Self-Recon. \cite{sauder2019self}    & - & 92.4 & finetuned \\
    DGCNN+STRL \cite{huang2021spatio}             & - & 93.1 & finetuned \\
    DGCNN+DCGLR \cite{fu2022distillation}             & - & 93.2 & finetuned \\
    *PointNet++ +PointGLR \cite{rao2020global}   & -  &  90.6 & finetuned   \\

    \midrule
    \textbf{PointNet++ +HyCoRe}    & -  &  91.1  & regularized  \\
    \textbf{DGCNN +HyCoRe}    & 91.0  &  93.7 & regularized    \\
    \textbf{PointMLP +HyCoRe} & \textbf{91.7}  &   \textbf{94.3}  & regularized \\
    \textbf{PointMLP +HyCoRe (voting)} & \textbf{91.9}  &   \textbf{94.5} & regularized   \\
    \bottomrule
  \end{tabular}
\end{table}


\begin{table}
\begin{minipage}{.5\linewidth}
  \caption{Classification results on ScanObjectNN.}
  \setlength\tabcolsep{3pt} 
  \label{class-sonn}
  \centering
  \begin{tabular}{lll}
    \toprule
Method     & AA()     & OA()  \\
    \midrule
    DGCNN\cite{wang2019dynamic}       &77.8 & 80.3 \\
    SimpleView\cite{goyal2021revisiting}  & - & 80.8 \\
    PRANet\cite{cheng2021net}     &79.1& 82.1 \\
    MVTN\cite{hamdi2021mvtn}       & - & 82.8 \\
    PointMLP\cite{ma2022rethinking}     & 84.4 & 86.1 \\
    **PointNeXt\cite{qian2022pointnext} & 86.4 & 88.0 \\ 
    \midrule
    \textbf{DGCNN+HyCoRe}    & 80.2  &   82.1    \\
    \textbf{PointMLP+HyCoRe} & \textbf{85.9}  &   \textbf{87.2}   \\
    \textbf{PointNeXt+HyCoRe} & \textbf{87.0}  &   \textbf{88.3}   \\
    \bottomrule
  \end{tabular}
\end{minipage}
\begin{minipage}{.5\linewidth}
\caption{Effectiveness of hyperbolic space.}
  \setlength\tabcolsep{2pt} 
  \label{class-emdim}
  \centering
  \begin{tabular}{llllll}
    \toprule
    \multicolumn{6}{c}{Average Accuracy ()}                   \\
    \cmidrule(r){1-6}
    Dim     & 16     & 64 & 256 & 512 & 1024\\
    \midrule
    DGCNN           &  76.6 & 77.5 & 77.8 &  76.6 & 76.3   \\
    DGCNN+EuCoRe       & 78.2 & 78.9 & 79.0 &  78.8  &  79.0      \\
    Hype-DGCNN      & 76.8 & 75.9 & 76.5 &  76.0 & 77.5        \\
    \textbf{DGCNN+HyCoRe}  &  79.1  & 80.0 & \textbf{80.2} & \textbf{80.2}  & 79.7   \\
    \bottomrule
  \end{tabular}
  \end{minipage}
\end{table}

Table \ref{class-mn40} shows the results for ModelNet40 classification. In the first part we report
well-known and state-of-the-art supervised models. We retrained PointNet++, DGCNN and the state-of-the-art PointMLP as baselines, noting some documented difficulty \cite{github_pointmlp} with exactly reproducing the official results. In addition, the second part of the table reports the performance of methods \cite{sauder2019self}, \cite{huang2021spatio}, \cite{fu2022distillation} proposing self-supervised pretraining techniques, after supervised finetuning. Concerning PointGLR \cite{rao2020global}, the most similar method to HyCoRe, we ensure a fair comparison by using only the L2G embedding loss and not the pretext tasks of normal estimation and reconstruction.  

Finally, the last part of the table presents the results with HyCoRe applied to the selected baselines. We can see that the proposed method achieves substantial gains not only compared to the randomly initialized models, but also compared to the finetuned models. When applied to the PointMLP, HyCoRe exceed the state-of-the-art performance on ModelNet40. Moreover, it is interesting to notice that the embedding framework of PointGLR is not particularly effective without the pretext tasks. This is due to the unsuitability of the spherical space to embed hierarchical information, as explained in Sec. \ref{sec:related}, and it is indeed not far from results we obtain with our method in Euclidean space.

Table \ref{class-sonn} reports the classification results on the ScanObjectNN dataset. Also in this case, HyCoRe significantly improves the baseline DGCNN leading it to be comparable with the state-of-the-art methods such as SimpleView \cite{goyal2021revisiting}, PRANet \cite{cheng2021net} and MVTN \cite{hamdi2021mvtn}. 
In addition, PointMLP that holds the state of the art for this dataset, is further improved by our method and reaches an impressive overall accuracy of 87.2 , substantially outperforming all the previous approaches. Although the authors in \cite{ma2022rethinking} claim that classification performance has reached a saturation point, we show that including novel regularizers in the training process can still lead to significant gains. This demonstrates that the proposed method leverages novel ideas, complementary to what is exploited by existing architectures, and it is thus able to boost the performance even of state-of-the-art methods. It is also remarkable that an older, yet still popular, architecture like DGCNN is able to outperform complex and sophisticated models such as the Point Transformer, when regularized by HyCoRe.


\begin{figure}
  \centering
    \includegraphics[width=0.9\textwidth]{figures/poincare_ball.png}
\caption{Embeddings produced by the hyperbolic encoder, projected to 2 dimensions with hyperbolic UMAP. Each color represents a class; small points correspond to parts; large points correspond to whole objects. Parts are closer to the center, sitting higher in the hierarchy (whole objects at the border may share a common part ancestor reachable via the geodesic connecting the objects).}
  \label{fig:feat-emb}
\end{figure}

\begin{table}
\centering
\begin{minipage}{.49\linewidth}
  \caption{Classification results when one of\\the two regularizations is omitted.}
\label{class-reg}
  \centering
  \begin{tabular}{lll}
    \toprule
& AA()     & OA() \\
    \midrule
    DGCNN      & 77.8 & 80.3         \\
    DGCNN+      & 77.9 & 80.5         \\
    DGCNN+  &  79.2  & 81.6     \\
    \textbf{DGCNN+HyCoRe}  &  \textbf{80.2}  & \textbf{82.1}     \\
    \bottomrule
  \end{tabular}
\end{minipage}
\begin{minipage}{.49\linewidth}
\caption{Performance vs. curvature of the Poincarè Ball}
  \label{class-curv}
  \centering
  \setlength\tabcolsep{4pt} 
  \begin{tabular}{lllll}
    \toprule
    \multicolumn{5}{c}{Average Accuracy ()}                   \\
    \cmidrule(r){1-5}
    Curvature     & 1     & 0.5 & 0.1 & 0.01 \\
    \midrule
    Hype-DGCNN      & 76.5 & 76.9 & 76.6 &  76.9         \\
    \textbf{DGCNN+HyCoRe}  &  \textbf{80.2}  & 79.4 & 78.7 & 78.5    \\
    \bottomrule
  \end{tabular}
\end{minipage}
\end{table}


In addition, to further prove that enforcing the hierarchy between parts is useful to build better clusters, we show in Fig. \ref{fig:feat-emb} a 2D visualization with UMAP of the hyperbolic representations for the ModelNet40 data. Colors denote classes, big points whole objects and small points parts. Besides the clear clustering according to class labels, it is fascinating to notice the emergence of the part-whole hierarchy with part objects closer to the center of the disk. Importantly, some parts bridge multiple classes, such as the ones in the bottom right zoom, i.e., they are found along a geodesic connecting two class clusters, serving as common ancestors. This can happen due to the fact that some simple parts having roughly the same shape appear with multiple class labels during training, and the net effect of  is to position them midway across the classes.   

The tree-likeness of the hyperbolic space can be also be seen in the visualization in Fig. \ref{fig:tree} (right). There we embed shapes with gradually large number of points up to the whole object made by 1024 points. We can notice that the parts are moved towards the disk edge as more points are added. Furthermore, a quantitative analysis of the part-whole hierarchy is shown in Table \ref{norm-table}. Here we calculated the hyperbolic norms of compositions of labeled parts. We can see that, as the parts are assembled with other parts, their hyperbolic norms grow, up to the whole object that is pushed close to the ball edge.

\begin{table}
  \caption{Hyperbolic Norms of labeled parts from the whole object up to the single parts.}
\label{norm-table}
  \centering
  \begin{tabular}{cccccccc}
    \toprule
Table & Plane+uprights & Legs+uprights & Plane & Legs & Uprights \\
    \midrule
           5.32 & 4.56 & 2.08 & 4.07 & 2.05 & 1.99     \\
    \midrule
          Aircraft & Wings+tail+engines & Wings+tail  & Wings & Fuselage &  Tail \\

          4.98 & 4.56  & 4.45  & 4.22 & 3.37 & 2.94  \\
    \bottomrule
  \end{tabular}
\end{table}




\subsection{Ablation study}

In the following we show an ablation study focusing on the DGCNN backbone and the ScanObjectNN dataset. The dataset selection is motivated by the fact that it is a real dataset, able to provide more stable and representative results compared to ModelNet40.

We first compare HyCoRe with its Euclidean version (EuCoRe) to investigate the effectiveness of the hyperbolic space. The basic principles and losses are the same, but in EuCoRe distances and network layers are defined in the Euclidean space. Table \ref{class-emdim} shows the results. With Hype-DGCNN we indicate the hyperbolic version of DGCNN, as represented in Fig. \ref{fig:arch}, but without any regularization, serving as a baseline to assess the individual effect of the regularizer. We also test the models over a different number of embedding dimensions. We can see that EuCoRe only provides a modest improvement, underlining the importance of the hyperbolic space. We also notice that the hyperbolic baseline struggles to be on par with its Euclidean counterpart, as observed by many recent works \cite{khrulkov2020hyperbolic}, \cite{ganea2018hyperbolic}. However, when regularized with HyCoRe, we can observe significant gains, even in low dimensions.
This also leaves an open research question, about whether better hyperbolic baselines could be built so that HyCoRe starts from a less disadvantaged point. 



In Table \ref{class-reg} we ablate HyCoRe by removing one of the two regularizers. We can see that the combination of the two provides the overall best gain.  

In order to study the effect of different space curvatures , Table \ref{class-curv} evaluates HyCoRe from the standard curvature  down to . We remark that some works \cite{khrulkov2020hyperbolic},\cite{ermolov2022hyperbolic}, report significant improvements when  is very low (e.g., 0.001), but this is counter-intuitive since the hyperbolic space then resembles an almost flat manifold. On the contrary, we do see improved results at higher curvatures.

Since HyCoRe constrains the network to learn the relations between parts and whole object, we claim that, at the end of the training process, the model should be better able to classify coarser objects. 
In Figs. \ref{fig:oapoints} and \ref{fig:oapointsparts} we show the test accuracy of DGCNN on ModelNet40, when presented with a uniformly subsampled point cloud and with a small randomly chosen and spatially-contiguous part, respectively. Indeed, we can notice that HyCoRe provides a gain up to  percentage points for very sparse point clouds, and is also able to successfully detect the object from smaller parts. For a fair comparison, we also report the baseline DGCNN with training augmented by random crops of parts. Even though the augmentation is useful to improve accuracy, HyCoRe is more effective demonstrating the importance of compositional reasoning.


\begin{figure}
\centering
\begin{subfigure}{0.47\textwidth}
\centering
    \includegraphics[width=0.95\textwidth]{figures/AA_npoi_dgcnn_aug_crop.pdf}
    \caption{Subsampled input. HyCoRe is more robust when the point cloud has coarser sampling.}
    \label{fig:oapoints}
\end{subfigure}
\quad
\begin{subfigure}{0.47\textwidth}
    \includegraphics[width=0.95\textwidth]{figures/AA_parts_dgcnn_aug_crop.pdf}
    \caption{Parts with different size. HyCoRe better detects objects from only a small part.}
    \label{fig:oapointsparts}
\end{subfigure}
\caption{Test inference of DGCNN on ModelNet40.}
\end{figure}





\section{Conclusions}

Although deep learning in the hyperbolic space is in its infancy, in this paper we showed how it can successfully capture the hierarchical nature of 3D point clouds, boosting the performance of state-of-the-art models for classification. Reasoning about the relations between objects and the parts that compose them leads not only to better results but also more robust and explainable models. In the future, it would be interesting to explore different ways of defining parts, not based on spatial nearest neighbors but rather on more semantic constructions. One important extension is to adapt HyCoRe to segmentation. Since segmentation aims to classify single points and the corresponding parts, contrary to classification, the parts embeddings should be placed on the boundary of the Poincarè Ball, where there is more space to correctly cluster them, and the whole objects (made by composition of parts) near the origin. We could exploit the label of the parts to this end or investigate unsupervised settings where the part hierarchy emerges naturally.



\begin{thebibliography}{10}
\providecommand{\url}[1]{#1}
\csname url@samestyle\endcsname
\providecommand{\newblock}{\relax}
\providecommand{\bibinfo}[2]{#2}
\providecommand{\BIBentrySTDinterwordspacing}{\spaceskip=0pt\relax}
\providecommand{\BIBentryALTinterwordstretchfactor}{4}
\providecommand{\BIBentryALTinterwordspacing}{\spaceskip=\fontdimen2\font plus
\BIBentryALTinterwordstretchfactor\fontdimen3\font minus
  \fontdimen4\font\relax}
\providecommand{\BIBforeignlanguage}[2]{{\expandafter\ifx\csname l@#1\endcsname\relax
\typeout{** WARNING: IEEEtran.bst: No hyphenation pattern has been}\typeout{** loaded for the language `#1'. Using the pattern for}\typeout{** the default language instead.}\else
\language=\csname l@#1\endcsname
\fi
#2}}
\providecommand{\BIBdecl}{\relax}
\BIBdecl

\bibitem{shi2020point}
W.~Shi and R.~Rajkumar, ``Point-gnn: Graph neural network for 3d object
  detection in a point cloud,'' in \emph{Proceedings of the IEEE/CVF conference
  on computer vision and pattern recognition}, 2020, pp. 1711--1719.

\bibitem{chen2021equivariant}
H.~Chen, S.~Liu, W.~Chen, H.~Li, and R.~Hill, ``Equivariant point network for
  3d point cloud analysis,'' in \emph{Proceedings of the IEEE/CVF Conference on
  Computer Vision and Pattern Recognition}, 2021, pp. 14\,514--14\,523.

\bibitem{ma2022rethinking}
X.~Ma, C.~Qin, H.~You, H.~Ran, and Y.~Fu, ``Rethinking network design and local
  geometry in point cloud: A simple residual mlp framework,'' \emph{arXiv
  preprint arXiv:2202.07123}, 2022.

\bibitem{goyal2021revisiting}
A.~Goyal, H.~Law, B.~Liu, A.~Newell, and J.~Deng, ``{Revisiting point cloud
  shape classification with a simple and effective baseline},'' in
  \emph{International Conference on Machine Learning}.\hskip 1em plus 0.5em
  minus 0.4em\relax PMLR, 2021, pp. 3809--3820.

\bibitem{rao2020global}
Y.~Rao, J.~Lu, and J.~Zhou, ``Global-local bidirectional reasoning for
  unsupervised representation learning of 3d point clouds,'' in
  \emph{Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern
  Recognition}, 2020, pp. 5376--5385.

\bibitem{sanghi2020info3d}
A.~Sanghi, ``Info3d: Representation learning on 3d objects using mutual
  information maximization and contrastive learning,'' in \emph{European
  Conference on Computer Vision}.\hskip 1em plus 0.5em minus 0.4em\relax
  Springer, 2020, pp. 626--642.

\bibitem{fu2022distillation}
K.~Fu, P.~Gao, R.~Zhang, H.~Li, Y.~Qiao, and M.~Wang, ``Distillation with
  contrast is all you need for self-supervised point cloud representation
  learning,'' \emph{arXiv preprint arXiv:2202.04241}, 2022.

\bibitem{sarkar2011low}
R.~Sarkar, ``Low distortion delaunay embedding of trees in hyperbolic plane,''
  in \emph{International Symposium on Graph Drawing}.\hskip 1em plus 0.5em
  minus 0.4em\relax Springer, 2011, pp. 355--366.

\bibitem{nickel2017poincare}
M.~Nickel and D.~Kiela, ``Poincar{\'e} embeddings for learning hierarchical
  representations,'' \emph{Advances in neural information processing systems},
  vol.~30, 2017.

\bibitem{ganea2018hyperbolic}
O.~Ganea, G.~B{\'e}cigneul, and T.~Hofmann, ``Hyperbolic neural networks,''
  \emph{Advances in neural information processing systems}, vol.~31, 2018.

\bibitem{weng2021unsupervised}
Z.~Weng, M.~G. Ogut, S.~Limonchik, and S.~Yeung, ``Unsupervised discovery of
  the long-tail in instance segmentation using hierarchical self-supervision,''
  in \emph{Proceedings of the IEEE/CVF Conference on Computer Vision and
  Pattern Recognition}, 2021, pp. 2603--2612.

\bibitem{hsu2021capturing}
J.~Hsu, J.~Gu, G.~Wu, W.~Chiu, and S.~Yeung, ``{Capturing implicit hierarchical
  structure in 3D biomedical images with self-supervised hyperbolic
  representations},'' \emph{Advances in Neural Information Processing Systems},
  vol.~34, 2021.

\bibitem{becigneul2018riemannian}
\BIBentryALTinterwordspacing
G.~Becigneul and O.-E. Ganea, ``{Riemannian Adaptive Optimization Methods},''
  in \emph{International Conference on Learning Representations}, 2019.
  [Online]. Available: \url{https://openreview.net/forum?id=r1eiqi09K7}
\BIBentrySTDinterwordspacing

\bibitem{you2018pvnet}
H.~You, Y.~Feng, R.~Ji, and Y.~Gao, ``{PVNet: A joint convolutional network of
  point cloud and multi-view for 3D shape recognition},'' in \emph{Proceedings
  of the 26th ACM international conference on Multimedia}, 2018, pp.
  1310--1318.

\bibitem{li2020end}
L.~Li, S.~Zhu, H.~Fu, P.~Tan, and C.-L. Tai, ``End-to-end learning local
  multi-view descriptors for 3d point clouds,'' in \emph{Proceedings of the
  IEEE/CVF Conference on Computer Vision and Pattern Recognition}, 2020, pp.
  1919--1928.

\bibitem{qi2017pointnet}
C.~R. Qi, H.~Su, K.~Mo, and L.~J. Guibas, ``Pointnet: Deep learning on point
  sets for 3d classification and segmentation,'' in \emph{Proceedings of the
  IEEE conference on computer vision and pattern recognition}, 2017, pp.
  652--660.

\bibitem{qi2017pointnet++}
C.~R. Qi, L.~Yi, H.~Su, and L.~J. Guibas, ``Pointnet++: Deep hierarchical
  feature learning on point sets in a metric space,'' \emph{Advances in neural
  information processing systems}, vol.~30, 2017.

\bibitem{liu2019relation}
Y.~Liu, B.~Fan, S.~Xiang, and C.~Pan, ``Relation-shape convolutional neural
  network for point cloud analysis,'' in \emph{Proceedings of the IEEE/CVF
  Conference on Computer Vision and Pattern Recognition}, 2019, pp. 8895--8904.

\bibitem{wu2019pointconv}
W.~Wu, Z.~Qi, and L.~Fuxin, ``Pointconv: Deep convolutional networks on 3d
  point clouds,'' in \emph{Proceedings of the IEEE/CVF Conference on Computer
  Vision and Pattern Recognition}, 2019, pp. 9621--9630.

\bibitem{li2018pointcnn}
Y.~Li, R.~Bu, M.~Sun, W.~Wu, X.~Di, and B.~Chen, ``{PointCNN: Convolution on
  X-transformed points},'' \emph{Advances in neural information processing
  systems}, vol.~31, 2018.

\bibitem{wang2019dynamic}
Y.~Wang, Y.~Sun, Z.~Liu, S.~E. Sarma, M.~M. Bronstein, and J.~M. Solomon,
  ``Dynamic graph cnn for learning on point clouds,'' \emph{ACM Transactions on
  Graphics (TOG)}, vol.~38, no.~5, p. 146, 2019.

\bibitem{deng2019arcface}
J.~Deng, J.~Guo, N.~Xue, and S.~Zafeiriou, ``Arcface: Additive angular margin
  loss for deep face recognition,'' in \emph{Proceedings of the IEEE/CVF
  conference on computer vision and pattern recognition}, 2019, pp. 4690--4699.

\bibitem{mei2022unsupervised}
G.~Mei, L.~Yu, Q.~Wu, and J.~Zhang, ``Unsupervised learning on 3d point clouds
  by clustering and contrasting,'' \emph{arXiv preprint arXiv:2202.02543},
  2022.

\bibitem{du2021self}
B.~Du, X.~Gao, W.~Hu, and X.~Li, ``Self-contrastive learning with hard negative
  sampling for self-supervised point cloud learning,'' in \emph{Proceedings of
  the 29th ACM International Conference on Multimedia}, 2021, pp. 3133--3142.

\bibitem{khrulkov2020hyperbolic}
V.~Khrulkov, L.~Mirvakhabova, E.~Ustinova, I.~Oseledets, and V.~Lempitsky,
  ``Hyperbolic image embeddings,'' in \emph{Proceedings of the IEEE/CVF
  Conference on Computer Vision and Pattern Recognition}, 2020, pp. 6418--6428.

\bibitem{ying2018graph}
R.~Ying, R.~He, K.~Chen, P.~Eksombatchai, W.~L. Hamilton, and J.~Leskovec,
  ``Graph convolutional neural networks for web-scale recommender systems,'' in
  \emph{Proceedings of the 24th ACM SIGKDD international conference on
  knowledge discovery \& data mining}, 2018, pp. 974--983.

\bibitem{wu20153d}
Z.~Wu, S.~Song, A.~Khosla, F.~Yu, L.~Zhang, X.~Tang, and J.~Xiao, ``3d
  shapenets: A deep representation for volumetric shapes,'' in
  \emph{Proceedings of the IEEE conference on computer vision and pattern
  recognition}, 2015, pp. 1912--1920.

\bibitem{uy2019revisiting}
M.~A. Uy, Q.-H. Pham, B.-S. Hua, T.~Nguyen, and S.-K. Yeung, ``Revisiting point
  cloud classification: A new benchmark dataset and classification model on
  real-world data,'' in \emph{Proceedings of the IEEE/CVF international
  conference on computer vision}, 2019, pp. 1588--1597.

\bibitem{geoopt2020kochurov}
M.~Kochurov, R.~Karimov, and S.~Kozlukov, ``Geoopt: Riemannian optimization in
  pytorch,'' 2020.

\bibitem{zhao2021point}
H.~Zhao, L.~Jiang, J.~Jia, P.~H. Torr, and V.~Koltun, ``{Point transformer},''
  in \emph{Proceedings of the IEEE/CVF International Conference on Computer
  Vision}, 2021, pp. 16\,259--16\,268.

\bibitem{xu2021paconv}
M.~Xu, R.~Ding, H.~Zhao, and X.~Qi, ``{Paconv: Position adaptive convolution
  with dynamic kernel assembling on point clouds},'' in \emph{Proceedings of
  the IEEE/CVF Conference on Computer Vision and Pattern Recognition}, 2021,
  pp. 3173--3182.

\bibitem{xiang2021walk}
T.~Xiang, C.~Zhang, Y.~Song, J.~Yu, and W.~Cai, ``{Walk in the cloud: Learning
  curves for point clouds shape analysis},'' in \emph{Proceedings of the
  IEEE/CVF International Conference on Computer Vision}, 2021, pp. 915--924.

\bibitem{sauder2019self}
J.~Sauder and B.~Sievers, ``{Self-supervised deep learning on point clouds by
  reconstructing space},'' \emph{Advances in Neural Information Processing
  Systems}, vol.~32, 2019.

\bibitem{huang2021spatio}
S.~Huang, Y.~Xie, S.-C. Zhu, and Y.~Zhu, ``Spatio-temporal self-supervised
  representation learning for 3d point clouds,'' in \emph{Proceedings of the
  IEEE/CVF International Conference on Computer Vision}, 2021, pp. 6535--6545.

\bibitem{cheng2021net}
S.~Cheng, X.~Chen, X.~He, Z.~Liu, and X.~Bai, ``{Pra-net: Point relation-aware
  network for 3d point cloud analysis},'' \emph{IEEE Transactions on Image
  Processing}, vol.~30, pp. 4436--4448, 2021.

\bibitem{hamdi2021mvtn}
A.~Hamdi, S.~Giancola, and B.~Ghanem, ``{Mvtn: Multi-view transformation
  network for 3d shape recognition},'' in \emph{Proceedings of the IEEE/CVF
  International Conference on Computer Vision}, 2021, pp. 1--11.

\bibitem{qian2022pointnext}
G.~Qian, Y.~Li, H.~Peng, J.~Mai, H.~A. A.~K. Hammoud, M.~Elhoseiny, and
  B.~Ghanem, ``Pointnext: Revisiting pointnet++ with improved training and
  scaling strategies,'' \emph{arXiv preprint arXiv:2206.04670}, 2022.

\bibitem{github_pointmlp}
``{Reproducing PointMLP on ModelNet40},''
  \url{https://github.com/ma-xu/pointMLP-pytorch/issues/1}, accessed:
  2022-05-16.

\bibitem{ermolov2022hyperbolic}
A.~Ermolov, L.~Mirvakhabova, V.~Khrulkov, N.~Sebe, and I.~Oseledets,
  ``{Hyperbolic Vision Transformers: Combining Improvements in Metric
  Learning},'' \emph{arXiv preprint arXiv:2203.10833}, 2022.

\end{thebibliography}



\end{document}