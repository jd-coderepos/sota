

\documentclass[11pt,a4paper]{article}
\usepackage[hyperref]{acl2021}
\usepackage{times}
\usepackage{latexsym}
\renewcommand{\UrlFont}{\ttfamily\small}

\usepackage{microtype}
\usepackage{graphicx}
\usepackage{amsmath}
\usepackage{algorithm}
\usepackage{algorithmic}
\usepackage{booktabs}
\usepackage{natbib}
\renewcommand{\algorithmicrequire}{\textbf{Learning Phase:}} 
\renewcommand{\algorithmicensure}{\textbf{Prediction Phase:}} 


\aclfinalcopy \def\aclpaperid{375} 



\newcommand\BibTeX{B\textsc{ib}\TeX}

\title{Relation Classification with Entity Type Restriction}

\author{Shengfei Lyu, \quad Huanhuan Chen\thanks{\, Corresponding author.} \\
  School of Computer Science and Technology \\
  University of Science and Technology of China, Hefei, China  \\
  \texttt{saintfe@mail.ustc.edu.cn, hchen@ustc.edu.cn} }

\date{}

\begin{document}
\maketitle

\begin{abstract}
Relation classification aims to predict a relation between two entities in a sentence. 
The existing methods regard all relations as the candidate relations for the two entities. 
These methods  neglect the restrictions on candidate relations by entity types, 
which leads to some inappropriate relations 
being candidate relations. 
In this paper, we propose a novel paradigm,  RElation Classification with ENtity Type restriction (RECENT), 
which exploits entity types to restrict candidate relations. 
Specially, the mutual restrictions of relations and entity types are formalized and 
introduced into relation classification. Besides, the proposed paradigm, RECENT, 
is model-agnostic. 
Based on two representative models GCN and SpanBERT respectively, 
 and  
 are trained in RECENT\footnote{Our code is available at \url{https://github.com//Saintfe/RECENT}.}.
Experimental results on a standard dataset indicate that 
RECENT improves the performance of GCN and SpanBERT by 6.9 and 4.4 F1 points, respectively. 
Especially,  achieves a new state-of-the-art on TACRED.

\end{abstract}


\section{Introduction}


Relation classification, a supervised version of relation extraction, aims to predict a relation between two entities in a sentence. 
Relation classification is an important step to construct knowledge bases from a large number of unstructured texts \cite{trisedya-etal-2019-neural}, 
which benefits many natural language processing applications, 
such as natural language generation \cite{kang-hashimoto-2020-improved} and question answering \cite{zhao-2020-conditiion}.

Recently, the majority of methods make use of various neural network architectures to learn a fixed-size representation for a sentence and its entities  
with various language features, such as part of speech (POS), entity types, and dependency trees. 
Dependency trees that are parsed from sentences are exploited by GCN \cite{kipf-2017-gcn} to  model sentences \cite{zhang-etal-2018-graph, guo-etal-2019-attention}. 
As a sequence of words, a sentence is modeled by LSTM \cite{hochreiter1997long} and its entity positions are involved with the attention mechanism \cite{zhang-etal-2017-position}.
More recently, pretrained language models \cite{devlin-etal-2019-bert,baldini-soares-etal-2019-matching,joshi-etal-2020-spanbert} 
achieve good performance in relation classification since they are pretrained on massive corpora.


\begin{figure}[t]
	\centering
	\includegraphics[width=1\columnwidth]{relation_domain}
	\caption{A relation restricts entities  with appropriate types. 
		In the figure,   is \textit{who-is-born-when}. 
		Different colored ellipses represent entities with different types.
	}
	\label{fig:relation_domain}
\end{figure}

\begin{figure}[t]
	\centering
	\includegraphics[width=1\columnwidth]{entity_domain}
	\caption{Entity type restriction for relation classification. 
		According to entity type restriction, the number of candidate relations reduces from 5 (left) to 2 (right).}
	\label{fig:entity_type_restriction}
\end{figure}

\begin{figure*}[t]
	\centering
	\includegraphics[width=2\columnwidth]{rcret}
	\caption{Relation classification with entity type restriction. 
The left part  does not consider the restriction of entity types on relations and 
		only feeds entity types as features into a general classifier. 
		The right part explicitly utilizes entity types to restrict candidate relations and 
		learns a specific classifier for each pair of entity types.
	}
	\label{fig:rcret}
\end{figure*}

To recap, these methods utilize an encoder architecture \cite{Badrinarayanan-etal-2017-segnet} to obtain a representation for a sentence. 
In other words, they only focus on the modeling of sentences and treat relations as 
labels\footnote{Specifically, these meaningful relations are treated as meaningless numbers, such as 0, 1, 2. } to be classified.
However, in this process, these methods inevitably lose the semantics of relations.  
Take the mutual restrictions between a relation and entity types as an example.
In Figure \ref{fig:relation_domain}, the relation \textit{who-is-born-when} 
restricts its first entity to be a person and the second one to be a time.
Conversely, entity types  can also restrict candidate relations in relation classification.
As illustrated in Figure \ref{fig:entity_type_restriction}, 
some inappropriate relations can be discarded from candidate relations by entity type restriction. 
However, the current methods neglect the restriction of entity types on relations 
so that some inappropriate relations are regarded as candidate relations, 
which further hurts their performance. 




To solve the above problem, a novel paradigm, RElation Classification with ENtity Type restriction (RECENT), 
is proposed to exploit entity types to restrict candidate relations.
As the basis of the paradigm, the mutual restrictions of relations and entity types are formalized. 
With the entity type restriction, some inappropriate relations are discarded from the candidate relations of a specific pair of entity types, as illustrated in Figure  \ref{fig:entity_type_restriction}. 
A specific classifier with a specific set of candidate relations is individually learned for each pair of entity types (Figure \ref{fig:rcret}).
Therefore, the proposed paradigm, RECENT, can eliminate the interference from inappropriate candidate relations. 

The contributions are summarized as follows:
\begin{itemize}
	\setlength{\itemsep}{0pt}
\item The  mutual restrictions of relations and entity types are formalized.
	\item A novel paradigm, RECENT, is proposed to exploit entity types to restrict candidate relations in relation classification.
	\item A new state-of-the-art  is achieved on TACRED.
\end{itemize}








\section{Proposed Paradigm}
Before introducing the proposed paradigm RECENT, 
the mutual restrictions between a relation and a pair of entities are formalized as the basis of RECENT.

\subsection{Relation Function}
When a binary relation is considered as a function, 
this relation has two entities as its two arguments.  
Formally, this relation is formalized as , 
where  denotes the \textbf{\underline{r}}elation and ,  denote the first (\textbf{\underline{s}}ubject) entity and the second (\textbf{\underline{o}}bject) entity, respectively. 
The range of this relation contains two discrete values \{0, 1\}:



In a broad sense, the domain of this relation can be any pair of entities. 
However, when a pair of entities with inappropriate types is fed into a specific relation, 
the relation can directly return 0, no need to consider the compositional semantics of the relation and the pair of entities.
For example, a specific relation \textit{who-is-born-when} expects the first argument to be a person and the second one to be a time.
Therefore, (\textit{apple}, \textit{Steven Jobs}) is a pair of inappropriate entities for this relation so that 
\textit{who-is-born-when(apple, Steven Jobs)} returns 0 without considering the compositional semantics, 
since \textit{apple} may refer to either a kind of fruit or a company (not a person) and  \textit{Steven Jobs} may refer to a famous person (not a time). 

Only when a relation receives a pair of appropriate entities whose types match it, 
the combination of the relation and the entities might make sense (i.e., the function defined in Eq. \ref{eq:relation} may return 1).
In this case, it is meaningful to further verify the correctness of the  compositional semantics.
From this perspective, in a narrow sense,  the domain (denoted by ) of a relation () is defined as follows:

where   and  denote the \textbf{\underline{t}}ypes of the subject entity () and the object entity (), respectively.
  and  are the appropriate types of  on the subject entity () and the object entity (), respectively.

 
\subsection{Entity Type Restriction}
In the previous subsection, the narrow domain of a relation restricts entities whose types need to match the relation.
Conversely, given a pair of entities whose types are known, the candidate relations of the entities are also restricted, 
since the match between relations and entity types is mutual.

Formally, given a pair of entities  (, ) and their types (, ), 
its candidate relations (denoted by ) are restricted into a limited set:

where  denotes all possible relations. 
When the types (, ) of a pair of entities (, ) are explicitly utilized to restrict its candidate relations, 
the candidate relations reduce from all possible relations   into a rather smaller set .

\subsection{Relation Classification}

Unlike traditional methods that classify a sentence and its entities on all candidate relations  (the left part of Figure \ref{fig:rcret}),  
the proposed paradigm, RECENT learns a specific classifier with smaller and more precise candidate relations for each pair of entity types (the right part of Figure \ref{fig:rcret}), 
based on entity type restriction in the previous subsection.


The procedure of RECENT is summarized in Algorithm \ref{alg:recent}.
In the learning phase, all sentences are first grouped by types of their entities (line 1). 
For each group (marked as ) with a specific pair of entity types (,), 
the candidate relations   for the group  are obtained by aggregating the relations in the group  (line 3).
Then, a specific classifier (marked by ) that maps sentences and their entities in  to , is learned for the group  (line 4).
In the prediction phase, given a new sample (, , , , ), a group (marked as ) is matched by the entity types (, ) (line 6).
Then, the classifier  learned on the group  is utilized to predict a relation according to the input (, , ) (line 7).


From the 4th line of Algorithm \ref{alg:recent}, the proposed paradigm RECENT is model-agnostic, 
which means that 
RECENT is theoretically compatible with many relation classification models.


\begin{algorithm}[htb]
	\caption{ RECENT}
	\label{alg:recent}
	\begin{algorithmic}[1] \REQUIRE ~~\\ {\bf Input:}   
		where the subscript  indicates the th sample,  is \textbf{\underline{se}}ntence,  is \textbf{\underline{s}}ubject entity, 
		 is \textbf{\underline{o}}bject entity,  is \textbf{\underline{t}}ype of \textbf{\underline{s}}ubject entity,  is  \textbf{\underline{t}}ype of \textbf{\underline{o}}bject entity,  is \textbf{\underline{r}}elation. \\
		{\bf Output:} Multiple classifiers.
		\STATE Group sentences by entity types. 
		\FOR{each \textbf{\underline{g}}roup  (enity types (, )  )}
\STATE aggregate relations in the group as  candidate relations  defined in Eq. \ref{eq:etr}.
		\STATE learn a classifier (marked as ) on the group  that maps  to . \ENDFOR		
		\ENSURE ~~\\ {\bf Input:}  A new sample ,
					each specific classifier for each pair of entity types.	 \\
		{\bf Output:} A relation.
		\STATE match the sample to a group (marked as ) according to the entity types (, ).
		\STATE Use the classifier () learned on the group to map (, , ) to a relation. 
		\RETURN the relation. 
	\end{algorithmic}
\end{algorithm}

\section{Experiments}
\subsection{Dataset} 
The proposed paradigm RECENT is evaluated on TACRED\footnote{\url{https://catalog.ldc.upenn.edu/LDC2018T24}} \cite{zhang-etal-2017-position}. 
TACRED contains 41 semantic relations and a special \textit{no\_relation} over 106,264 sentences. 
The subject entities in TACRED are classified  into two types: \textit{PERSON} and \textit{ORGANIZATION} 
while the object entities are categorized into 16 fine-grained types, such as \textit{LOCATION } and \textit{TIME}.
Namely, entity types are known.
By convention, the micro-averaged F1 score (abbreviated as F1) is reported on TACRED.

\subsection{Experimental Setup}


Since \textit{no\_relation}  is a candidate relation of  each pair of entity types in TACRED, 
a binary classifier is first learned to distinguish between 41 semantic relations and \textit{no\_relation}.
In this way, each pair of entity types reduces one candidate relation (i.e. \textit{no\_relation}) in RECENT.
If the binary classifier predicts \textit{no\_relation} for a pair of entities, then the final relation for them is \textit{no\_relation}.
Otherwise, their specific semantic relation is further predicted in  RECENT.  


\paragraph{Base Models} The proposed paradigm RECENT is model-agnostic. 
Two representative models 
that are GCN \cite{zhang-etal-2018-graph} and SpanBERT \cite{joshi-etal-2020-spanbert} 
are selected as base models (line 4 in Algorithm \ref{alg:recent}). 
For a fair comparison with a base model, 
all classifiers (including the binary classifier) in RECENT are trained by the base model. 
The corresponding models in the paper are denoted as  and 	
.

\paragraph{Hyperparameters}
For , the path-centric pruning  is set to 1 as GCN \cite{zhang-etal-2018-graph}.
The learning rates for all classifiers in  are set to 0.3. 
For , the learning rates for all classifiers are chosen from \{5e-6, 1e-5, 2e-5, 3e-5, 5e-5\} as SpanBERT.

\paragraph{Compared Models} Extensive  models in relation classification are regarded as comparison models. 
They include PA-LSTM \cite{zhang-etal-2017-position}, 
C-GCN  \cite{zhang-etal-2018-graph},
AGGCN  \cite{guo-etal-2019-attention}, 	
C-AGGCN \cite{guo-etal-2019-attention},
MTB  \cite{baldini-soares-etal-2019-matching},
KnowBert   \cite{peters-etal-2019-knowledge}, 
SpanBERT-ALT \cite{lyu-etal-2020-auxiliary},
KEPLER  \cite{wang-etal-2020-kepler}, 
K-Adapter  \cite{wang-etal-2020-k-adapter}, 
and
LUKE  \cite{yamada-etal-2020-luke}. 
To save space, please refer to the original papers of these models for details.



\begin{table}[t]
	\hspace*{-0.2cm} 
	\centering
	\resizebox{8cm}{!}{
		\begin{tabular}{lccc}		
			\toprule
			{Model} & {P} & {R} & {F1}  \\ 
			\midrule
PA-LSTM  \cite{zhang-etal-2017-position}  & 65.7 & 64.5 & 65.1 \\	
			C-GCN  \cite{zhang-etal-2018-graph}  & 69.9 & 63.3 & 66.4\\
			AGGCN  \cite{guo-etal-2019-attention} & 69.9 & 60.9 & 65.1\\
			C-AGGCN  \cite{guo-etal-2019-attention} & 71.8 & {66.4} & 69.0 \\
			\midrule
			GCN  \cite{zhang-etal-2018-graph} & 69.8 & 59.0 & 64.0 \\
			 (ours) & 88.3 & 59.3 & {70.9} \\
			\midrule
			\midrule
			SpanBERT-ALT  \cite{lyu-etal-2020-auxiliary} & 69.0 & 73.0 & 70.9 \\
			MTB   \cite{baldini-soares-etal-2019-matching} & - & - & 71.5 \\			
			KnowBert  \cite{peters-etal-2019-knowledge} & 71.6 & 71.4 & 71.5 \\		
			KEPLER * \cite{wang-etal-2020-kepler} & 71.5 & 72.5 & 72.0 \\			
			K-Adapter * \cite{wang-etal-2020-k-adapter} & 70.14 & 74.04 & 72.04 \\					
			LUKE   \cite{yamada-etal-2020-luke} & 70.4 & \textbf{75.1} & 72.7 \\
			
			\midrule
			SpanBERT  \cite{joshi-etal-2020-spanbert} & 70.8 & {70.9} & 70.8 \\
			 (ours) & \textbf{90.9} & 64.2 & \textbf{75.2} \\
			\bottomrule
		\end{tabular}
	}
	\caption{\label{tab:result-rencet} Results on the TACRED dataset. 
		P and R indicate precision and recall, respectively.
		Bold marks the highest values among models.
		 marks results reported in the original papers.
		* marks results from preprint papers.
		}
\end{table}

\subsection{Experimental Results}

The experimental results are presented in Table \ref{tab:result-rencet}. 
 achieves a significant performance increase on the F1 score above its base model GCN. 
The absolute increase reaches  6.9 from 64.0 to 70.9. 
The main contribution for the F1 increase is the improved precision  that greatly increases from 69.8 to 88.3.
The great increase in precision, which might result from the restriction on candidate relations by entity types in RECENT, indicates the effectiveness of the proposed paradigm RECENT. 
Besides,  suppresses the compared models that do not include pretrained language models. 

Similarly,  overtakes its base model SpanBERT by absolute 4.4 points on F1.
The great soar (absolute 20.1 points) on precision contributes the superior F1 of . 
Unfortunately, 
the decline in recall limits the further improvement of F1.  
This might be due to sample imbalance  of candidate relations, 
which will be further studied in future work. 
On the whole (i.e. F1),  outperforms all the compared models. 
Especially,  exceeds the state-of-the-art LUKE 
model\footnote{LUKE achieves the state-of-the-art (72.7) on the published papers. 
	\citet{cohen-etal-2020-relation} report a new state-of-the-art (74.8) in the preprint way. 
	Anyway,  achieves a new state-of-the-art (75.2). 
} 
by 2.5 F1 points 
and achieves a new state-of-the-art.

\subsection{Error Analysis of GCN}

\begin{table}[t]
	\centering

		\begin{tabular}{lccc|cc}		
			\toprule
			{Model} & {P} & {R} & {F1} & {FP} & {FP(ET)}   \\ 
			\midrule
			GCN  & 68.4 & 60.2 & 64.1 & 1,323 & 144  \\
			\bottomrule
		\end{tabular}
	\caption{\label{tab:result-gcn} Results of our trained GCN on the TACRED dataset. 
		P and R indicate precision and recall, respectively. 
		FP indicates the number of  false positives 
		and FP(ET) indicates the number of false positives that break the entity type restriction. 
	}
\end{table}

This subsection analyzes the influence of a baseline model (i.e. GCN) that neglects the restriction of entity types on relations. 
We retrain a GCN model and the model achieves 68.4 precision, 60.2 recall, and 64.1 F1 (Table \ref{tab:result-gcn}), 
which are similar to the results in its reported paper \cite{zhang-etal-2018-graph}. 
Observing the prediction results of the model, we find that 1) 1,323 examples are false positives in the test set of TACRED, 
2) 144 (about 11\%) false positives among them break the entity type restriction. 
Namely, GCN can make about 89\% of false positives meet the entity type restriction, by implicitly using entity types. 
However, about 11\% of false positives still break the restriction. 
The false positives broken down by relations are counted in Appendix \ref{apx:stat-fp}.
In details, false positives  broken down by relations are weakly negatively correlated with the amount of training data of relations, where the correlation coefficient is -0.39. 
This infers that fewer training examples of relations may lead to more false positives of relations.


\section{Conclusion}

In the paper, a novel paradigm, RECENT, is proposed by entity type restriction.
RECENT reduces  candidate relations for each pair of entity types by 
the mutual restrictions between relations and entity types.
RECENT is model-agnostic. 
 and  
that are based on two representative models GCN and SpanBERT respectively,
outperform their counterparts on the standard dataset TACRED, 
which empirically indicates the effectiveness of the proposed paradigm RECENT.
Especially,  achieves a new state-of-the-art on TACRED.







\bibliographystyle{acl_natbib}
\bibliography{acl2021}

\appendix 
\section{The Statistics of False Positives}
\label{apx:stat-fp} 

\begin{table}[t]
	\centering
	\begin{tabular}{lc}
		\toprule
		{Relation} & {False Positives}   \\ 
		\midrule
		org:alternate\_names                  & 53 \\
		org:city\_of\_headquarters            & 30 \\
		org:country\_of\_headquarters         & 70 \\
		org:dissolved                         & 2  \\
		org:founded                           & 9  \\
		org:founded\_by                       & 46 \\
		org:member\_of                        & 18 \\
		org:members                           & 31 \\
		org:number\_of\_employees/members     & 9  \\
		org:parents                           & 62 \\
		org:political/religious\_affiliation  & 4  \\
		org:shareholders                      & 10 \\
		org:stateorprovince\_of\_headquarters & 16 \\
		org:subsidiaries                      & 37 \\
		org:top\_members/employees            & 61 \\
		org:website                           & 1  \\
		per:age                               & 13 \\
		per:alternate\_names                  & 11 \\
		per:cause\_of\_death                  & 37 \\
		per:charges                           & 35 \\
		per:children                          & 31 \\
		per:cities\_of\_residence             & 90 \\
		per:city\_of\_birth                   & 3  \\
		per:city\_of\_death                   & 19 \\
		per:countries\_of\_residence          & 93 \\
		per:country\_of\_birth                & 5  \\
		per:country\_of\_death                & 9  \\
		per:date\_of\_birth                   & 3  \\
		per:date\_of\_death                   & 36 \\
		per:employee\_of                      & 98 \\
		per:origin                            & 46 \\
		per:other\_family                     & 60 \\
		per:parents                           & 49 \\
		per:religion                          & 16 \\
		per:schools\_attended                 & 13 \\
		per:siblings                          & 25 \\
		per:spouse                            & 24 \\
		per:stateorprovince\_of\_birth        & 4  \\
		per:stateorprovince\_of\_death        & 10 \\
		per:stateorprovinces\_of\_residence   & 40 \\
		per:title                             & 94 \\
		\bottomrule
	\end{tabular}
	\caption{\label{tab:stat-fp-tacred} False positives broken down by relations of our trained GCN on the TACRED dataset. }
\end{table}
Table \ref{tab:stat-fp-tacred} presents  false positives broken down by relations of our trained GCN on the TACRED dataset. 
In details, false positives  broken down by relations are weakly negatively correlated with the amount of training data of relations, where the correlation coefficient is -0.39. 

\end{document}
