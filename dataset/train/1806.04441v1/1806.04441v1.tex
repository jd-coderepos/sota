



\documentclass[11pt]{article}
\usepackage{coling2018}
\usepackage{times}
\usepackage{url}
\usepackage{latexsym}
\usepackage{bbm}
\usepackage{amssymb}
\usepackage{graphicx}
\usepackage{subfigure}
\usepackage{amsmath}
\usepackage{color}
\usepackage{xcolor}
\usepackage{bm}
\usepackage[]{caption2} 
\usepackage{CJKutf8}
\newcommand{\tabincell}[2]{\begin{tabular}{@{}#1@{}}#2\end{tabular}}
\newcommand{\info}[1]{\textcolor{blue}{[#1]}}
\newcommand{\warn}[1]{\textcolor{red}{[#1]}}
\newcommand{\yjsay}[1]{\textcolor{orange}{[#1 -- YJ]}}




\slname{Chinese}

\title{Sequence-to-Sequence Learning for Task-oriented Dialogue with Dialogue State Representation}
\sltitle{\begin{CJK}{UTF8}{gbsn} 面向任务型对话中基于对话状态表示的序列到序列学习   \end{CJK}}

\author{Haoyang Wen, Yijia Liu, Wanxiang Che*, Libo Qin, Ting Liu\\
	Research Center for Social Computing and Information Retrieval, \\
	Harbin Institute of Technology, China \\
	{\tt \{hywen, yjliu, car, lbqin, tliu\}@ir.hit.edu.cn} \\\
}
\date{}

\begin{document}
\maketitle
\begin{abstract}
	Classic pipeline models for task-oriented dialogue system require explicit modeling the dialogue states and
hand-crafted action spaces to query a domain-specific knowledge base.
Conversely, sequence-to-sequence models learn to map dialogue history to the response in current turn
without explicit knowledge base querying. In this work, we
propose a novel framework that leverages the advantages of classic pipeline and
sequence-to-sequence models. Our framework models a dialogue state as a fixed-size distributed
representation and use this representation to query a knowledge base via an attention mechanism.
Experiment on Stanford Multi-turn Multi-domain
Task-oriented Dialogue Dataset shows that our framework significantly outperforms other
sequence-to-sequence based baseline models on both automatic and human evaluation.
\end{abstract}
\makesltitle
\begin{slabstract}
	\begin{CJK}{UTF8}{gbsn}
		面向任务型对话中，传统流水线模型要求对对话状态进行显式建模。这需要人工定义对领域相关的知识库进行检索的动作空间。相反地，序列到序列模型可以直接学习从对话历史到当前轮回复的一个映射，但其没有显式地进行知识库的检索。在本文中，我们提出了一个结合传统流水线与序列到序列二者优点的模型。我们的模型将对话历史建模为一组固定大小的分布式表示。基于这组表示，我们利用注意力机制对知识库进行检索。在斯坦福多轮多领域对话数据集上的实验证明，我们的模型在自动评价与人工评价上优于其他基于序列到序列的模型。
	\end{CJK}
\end{slabstract}
\blfootnote{
	\hspace{-0.65cm}  This work is licenced under a Creative Commons 
	Attribution 4.0 International Licence.
	Licence details:
	\url{http://creativecommons.org/licenses/by/4.0/}
}
\blfootnote{
	\hspace{-0.65cm}
	* Email corresponding.
}
\section{Introduction}
\begin{figure}[!tp]
	\centering
	\normalsize
	\label{fig1}
	\begin{tabular}{|l|l|l|l|l|}
		\hline\textbf{Address} & \textbf{Distance} & \textbf{POI type} & \textbf{POI} & \textbf{Traffic info} \\\hline
		638 Amherst St&3 miles&grocery store&Sigona Farmers Market&car collision nearby\\
		269 Alger Dr&1 miles&coffee or tea place&Cafe Venetia&car collision nearby\\
		5672 barringer street & 5 miles & certain address & 5672 barringer street & no traffic \\
		200 Alester Ave&2 miles&gas station&Valero&road block nearby\\
		899 Ames Ct&5 miles&hospital&Stanford Childrens Health&moderate traffic\\
		481 Amaranta Ave&1 miles&parking garage&Palo Alto Garage R&moderate traffic\\
		145 Amherst St&1 miles&coffee or tea place&Teavana&road block nearby\\
		409 Bollard St&5 miles&grocery store&Willows Market&no traffic\\\hline
	\end{tabular}
	\\
	\begin{tabular}{ll}
		\textbf{Driver:} & Address to the gas station.\\
		\textbf{Car:} & Valero is located at 200 Alester Ave.\\
		\textbf{Driver:} & OK , please give me directions via a route that avoids all heavy traffic.\\
		\textbf{Car:} & Since there is a road block nearby, I found another route for you and I sent it on your screen.\\
		\textbf{Driver:} & Awesome thank you.\\	
	\end{tabular}
	\caption{An example of a task-oriented dialogue that incorporates a knowledge base. The knowledge 
		base will be changed based on different dialogue environment setting. Agents need to generate 
		response based on current knowledge base.}
\end{figure}


	Task-oriented dialogue system attracts more and more attention with the success of commercial
systems such as Siri, Cortana and Echo. It helps users complete specific tasks with natural language. Figure \ref{fig1} shows a typical example of a task-oriented
dialogue, where an agent provides with location information for a user. The requirements for the
agents to accomplish users' demands usually involve querying the knowledge base (KB), like
acquiring address from location information KB in Figure \ref{fig1}.

Typical machine learning approaches model the problem as a partially observable Markov Decision 
Process (POMDP) \cite{williams-young:2007:CSL,young:2013:IEEE}, where a pipeline system is 
introduced. The pipeline system consists of four components: natural language understanding (NLU, Tur and De Mori, 2011)
\nocite{tur-demori:2011}, dialogue state tracking \cite{williams:2013:SIGDial,williams:2012:NAACL}, dialogue 
policy learning \cite{young:2010:CSL} and natural language generation \cite{wen:2015:ACL}. Taking the utterance in Figure \ref{fig1} for example,
NLU maps the utterance ``\texttt{Address to the gas station}'' into semantic slot ``\texttt{POI type}''.
Dialogue state tracker keeps the probability of ``\texttt{gas station}'' close to 1
against other values of slot ``\texttt{POI type}''.
Given a semantic frame as a dialogue state, which is the combination of distributions of these slots,
dialogue policy learning generates the next pre-defined system action, which usually involves querying the knowledge base.
The action is then converted to its natural language
expression using natural language generation. Both natural language understanding and dialogue state 
tracking require a large amount of domain specific annotation for training, which is expensive to 
obtain. Besides, the design of actions and the explicit forms of semantic frames require a lot 
of knowledge from human experts, which are domain-specific as well.

Neural generative models, typically Seq2Seq models, have achieved success on machine 
translation \cite{sutskever:2014:NIPS,bahdanau-cho-bengio:2014:arxiv,luong-pham-manning:2015:EMNLP}. This success spurs the 
interests to apply Seq2Seq models into dialogue systems. Seq2Seq models
map dialogue history directly into the response in current turn,
while requires a minimum amount of hand-crafting.
However, conventional Seq2Seq doesn't model the exterior data retrieval explicitly,
which makes it hard for Seq2Seq to generate information stored in KB like meeting time and address,
but this kind of retrieval is easy to achieve for classic pipeline.
To tackle with the problem, \newcite{eric-manning:2017:EACL} use an additional copy mechanism to retrieve entities that occurs in  both KB and dialogue history. 
\newcite{eric:2017:SIGDial} further introduced retrieval from key-value KB where the model uses key representations to retrieve the corresponding values.
However, not all KBs are presented in key-value forms. 
Besides, an important component of classic pipeline, dialogue state tracker,
is not properly modeled, making it difficult to precisely retrieve from KB.

In this paper, we propose a novel framework that takes the advantages from both classic pipeline 
models and Seq2Seq models. We introduce dialogue states into 
Seq2Seq learning, but in a implicit way. Distributions in classic state tracking are modeled as a group of representation vectors computed by an attention-based network \cite{britz-guan-luong:2017:EMNLP},
which can be considered as a dialogue state representation that aggregates information for each slot. And training this representation doesn't require annotation of dialogue state tracking.
Our model queries the KB entries in an 
attention-based method as well, so that the querying is differentiable, without domain-specific pre-defined action spaces. Meanwhile we compute the representation for KB using entry-level attention and aggregate the representation with dialogue state representation to form a memory matrix of dialogue history and KB information.
While decoding, we perform an attention over memory and an attention over input, incorporating copying mechanism \cite{gu:2016:ACL} that allows model to copy words from KBs to enhance the capability of retrieving accurate entities.

We evaluate the proposed framework on Stanford Multi-turn, Multi-domain Dialogue Dataset 
\cite{eric:2017:SIGDial}, to test the effectiveness of our framework and flexibility to apply to different 
domains. We compare our model with other Seq2Seq models and discovered that our 
model has outperformed other models on both automatic evaluation and human evaluation.

\section{Proposed Framework}
In this section, we describe a framework for task-oriented dialogue system. 
Our framework first encodes previous dialogue history, and computes dialogue state representation. 
Then our framework queries the table by attention and computes a matrix to represent information from previous history and KB. 
At last, the responses are generated using copying mechanism. 
The general architecture is demonstrated in Figure \ref{fig22}. 
\begin{figure}[!tp]
\label{fig22}
 \includegraphics[width=\linewidth, trim={0 1cm 0 1.5cm}, clip]{fig2.pdf}
 \caption{Proposed framework.}
\end{figure}
\subsection{Encoder}
Given a dialogue consisting of utterances from a user and an agent, our encoder encodes the whole dialogue history. We represent the dialogue history
as a sequence of utterances. We encode the previous dialogue history as one single sequence 
consisting of each word in previous dialogue history and use  to denote the whole dialogue history word by word, where  is the length of this sequence. Words are 
mapped to word embeddings and a long short-term memory network (LSTM) aggregates hidden representation 
over the sentence, denoted as  (,  is the dimensionality of a hidden state).

\subsection{Dialogue State Representation}
The dialogue state tracking component of a dialogue system interprets the previous dialogue history to 
a belief state \cite{williams:2013:SIGDial}, which consists of a group of probability distributions over 
values for each slot. The dialogue state tracking is the core component of pipeline model. It helps with retrieving values from KB and generating accurate entities. To introduce dialogue state into Seq2Seq learning, in this framework, we model representation of belief state, motivated by 
\newcite{britz-guan-luong:2017:EMNLP}. We do not compute the explicit probability distribution for each 
slot. Instead, a group of distributed representations is computed. 
In this paper, we assume each turn of the dialogue is associated with  slots and its dialouge state representation
is a matrix  whose columns represent corresponding distribution.
We further assume that  equals to the number of columns in our KB.
Each state representation  is calculated 
by an attention over the whole representation of history:

where we assign each hidden state  different kinds of scores and perform a weighted average. The 
scores are computed by the following equations:

 is a 
parameter matrix in .

\subsection{Soft KB Attention}
\paragraph{Table Encoder.}
In our framework, we compile the process of querying  a KB entry into an attention network. The first step is to encode the tables.
Each KB cell is represented as the concatenation of the column name embedding  and the cell value embedding .
This representation is further fed into a  non-linearity and the final representation can be formalized as .
The representation of the KB entry  is denote as , consisting all its cell representations.


\paragraph{Entry and KB Representation.}
\label{KB}
Conventionally, task-oriented dialogue systems interact with KB via carefully hand-crafted API calls, which are usually domain-specific and break the differentiability \cite{wen:2017:EACL}. To make it differentiable, our framework applies a soft-attention over the KB entries and the attention value can be interpreted as the possibility that an entry will be used for decoding. 
	We use the similarity between  and  to represent attention score for the  entry. 
	The similarity is computed by the following equation:


where we sum the dot product between vectors in  and  respectively. 

This similarity distribution is then converted into a probability distribution naturally using a softmax function. This probability distribution indicates the possibility to use entry  in the further response generation given previous dialogue history  :


The information matrix from KB that is used for future generation can be computed as a weighted summation:

where  is denoted as the information matrix,  is the number of entries in this KB.

Since the dimensionalities of all parameters are not related to the size of knowledge base. it allows changing the KB on-the-fly. Besides, there is no need to define specific operations, which is required for using API calls to extract information. Since we model the entries directly, it is appropriate to extract information from non-entity-centric knowledge bases as well.

Finally, we combine these two kinds of information by concatenating corresponding vectors and feeding them into a linear layer with an activation function. Formally, we denote  as the concatenation of  and . The two matrices are concatenated by concatenated corresponding vectors respectively. The process can be formulated as:
 . The matrix  can be considered as a fix-sized memory representation over dialogue history and knowledge base.

\subsection{Decoder}
In this section, we will discuss the decoder that takes all previously calculated information to generate sentences. The vanilla Seq2Seq decoder generates a sequence of words recurrently based on the last hidden state of a encoder. We denote  as the hidden states of the decoder and  as the output sentence. We will consider two kinds of information, that are information of dialogue history and information from KB. The model aggregates information via attention over KB representation and history representation.
\paragraph{Input Attention.}
The conventional attention mechanism is introduced to extend the decoder, where each hidden state in the encoder is assigned a score based on the current hidden state  at time step , and then the context vector is computed by the weight summation \cite{luong-pham-manning:2015:EMNLP}. This process can be described by the following equations:


\paragraph{Memory Attention.}
Besides the context vector through input attention, we also use another context vector from the attention over the fix-size memory matrix  and it's computed as:

In practice, we use an additional context vector from encoder to calculate the dialogue state representation, which is different from the one that is used for the start of decoding.

The two kinds of context vectors and the current hidden state are used for decoding. 
We introduce a variant of copying mechanism \cite{gu:2016:ACL} in order to retrieve entities from KB directly. We first compute a probability distribution over output vocabulary  and slot types , given previous dialogue history  and previous generated words , which can be described as:

The probability of generating a slot type represents the sum of probability of generating a slot value for this slot from KB. Since we have calculated the probability of using an entry in section \ref{KB}, the probability of generating a word can be described as:

where  is the cell that is in slot (i.e. column) .
Note that the summation of probability over  is exactly 1 after the model copies entities from KB.


\subsection{Training}
Conventionally, we use negative log likelihood (NLL) for training to train a Seq2Seq model. 
Since there is no supervision for soft KB attention, and it is easy to get over-fitting when we only use NLL,  we apply policy gradient to improve the performance of soft KB attention as well. We consider the KB and fix-size memory representation from input as the environment in a reinforcement learning setting. There is only one action, which is defined as choosing a single entry from KB to help with generating response. Heuristically, the more entities in an entry appear in dialogue context, the higher possibility that this entry is used for generating response. Therefore, we consider the number of entities from an entry  that appear in previous dialogue history or current gold response as reward , and apply REINFORCE with baseline \cite{williams:1992:RL}:
,
where  is a hyperparameter denoting the baseline reward. The joint loss is the combination of the NLL and loss from reinforcement learning, which is:

where  is a hyperpramater balancing the two factors. In practice, we first use  only to train the soft KB attention and its encoder, without training for response generation, which will accelerate the convergence of Seq2Seq learning. We apply data augmentation to the original dataset as well, where we add delexicalised form responses into training data in order to force our model to generate slot types first and then retrieve entity from KB using copying mechanism. The delexicalised responses are generated by simple matching and replacing.

\section{Experiment}
In this section, we first introduce the details of experiment setting. Then we provide results and analyses of automatic evaluation and human evaluation in order to compare with other baseline models. Besides, we present ablation test to evaluate and analyze the function of different components in our framework. Finally, we provide visualization of dialogue state representation and case study.
\begin{table}
	\label{table1}
	\begin{tabular}{l|p{6.5cm}|p{6.5cm}}
		&\multicolumn{1}{c|}{\textbf{Weather}}&\multicolumn{1}{c}{\textbf{Navigation}}\\\hline
		\textbf{Slot Types}& location, date, highest temperature, lowest temperature and weather attribute&POI name, traffic info, POI type, address, distance\\
	\end{tabular}
	\caption{Slot types for different domains.}
\end{table}
\subsection{Experiment Setting}
We choose two KB-rich domains from Stanford Multi-turn Multi-domain Task-oriented Dialogue Dataset  \newcite{eric:2017:SIGDial}, which are weather information retrieval and point-of-interest (POI) navigation (navigation). We first change the form of KB in weather information retrieval domain (weather). \newcite{eric:2017:SIGDial} integrates the highest temperature, lowest temperature and weather information into a single weekday column due to their incapability of utilizing non-entity-centric KB. In this paper, we separate these information into three different column, and the slots of these two domains are provided in Table \ref{table1}.

Our framework is trained separately in these two domains, using the same train/validation/test split sets as \newcite{eric:2017:SIGDial}. We do not map the entities in dialogue into its canonical form as what \newcite{eric:2017:SIGDial} have done, since our framework extract entities directly from KB. And we evaluate our framework on exact entities as well.

Our framework is trained using the Adam optimizer \cite{kingma-ba:2014:ICLR}. The learning rate is ,  for balancing two loss functions is . We applied dropout \cite{srivastava:2014:JMLR} to the input and the output of LSTM, with a dropout rate at . We add the weight decay on the model. The coefficient of weight decay is . The embedding size and all hidden size are 200. The number of epochs for training soft KB attention is 30 for both navigation and weather. Baseline  is 1.5 for both navigation and weather.
\subsubsection{Baseline Models}
We compare our model with two additional baselines beyond the Seq2Seq with attention, which includes:
\begin{itemize}
\item \textbf{Copy-augmented Sequence-to-Sequence Network.} This model is adapted from \cite{eric-manning:2017:EACL}. It utilizes entities that appear in both previous dialogue history and KB. A hard copy mechanism for these entities is applied in this model.
\item \textbf{Key-value Retrieval Network.} This model is adapted from \newcite{eric:2017:SIGDial}. It utilizes key-value forms to represent KBs. Key representations are used for an attention-based value retrieval. In weather information retrieval domain, although we have changed the KB into an non-entity-centric form, we still designate ``\texttt{location}'' slot as subject slot and we allow a key representation to retrieval multiple values. We convert inputs into canonical forms, while the outputs remain the same in order to compare with our model.
\end{itemize}

\subsection{Automatic Evaluation}
In this section, we provide two different automatic evaluations to compare with other baseline models. The results and analyses are provide in the following sections.

\subsubsection{Evaluation Metrics}

Entity F1 and BLEU score are used to evaluate our model.
	The entity F1 scores in both micro-average and macro-average manners are used to measure the difference between entities in the system and gold responses. Besides, we use BLEU to evaluate the quality of responses. \newcite{sharma:2017:arxiv} showed that BLEU has a comparatively strong correlation with human evaluation on task-oriented dialogue dataset. The BLEU score is computed from results with highest micro F1. To evaluate macro F1, we delete instances that neither gold nor generated response contains an entity.

\subsubsection{Results and Analyses}
Experiment results are illustrated in Table \ref{table2}. 
The results show that our model outperforms other models in most of automatic evaluation metrics. 
In the navigation domain, compared to KV Net, we achieve 5.0 improvement on BLEU score, 37.1 improvement on Macro F1 and 27.4 improvement on Micro F1. 
Compared to Copy Net, we achieve 5.0 improvement on BLEU score, 41.2 improvement Macro F1 and 27.4 improvement on Micro F1. 
The results in navigation show our model's capability to generate more natural and accurate response than the Seq2Seq baseline models. 
In the weather domain, our model generates more accurate responses than our baseline models as well. 
The BLEU score is a little bit lower than Copy Net and Seq2Seq with attention. This is because the forms of responses are relatively limited in weather domain.
Besides, the entities in inputs are highly probable to be mentioned in responses, such as ``\texttt{location}''. These two reasons indicate that the simpler models can capture this pattern more smoothly.
The results that Seq2Seq with Attention performs better than Copy Net and KV Net also confirm this.

We also find that the KV Net's results are lower than that reported by \newcite{eric:2017:SIGDial}.
	We address this to the differences in the preprocessing, model training and evaluation metrics. 
	In spite of the difference of evaluation metrics that we evaluate on exact entities rather than their canonical forms, the Micro F1 score of our model still outperforms what \newcite{eric:2017:SIGDial} reported, which is 41.3 in navigation domain and which is evaluated on canonical forms.
	Our changes of the weather domain into non-entity-centric also influence its performance.
	This differences in results also indicate the robustness of our model when facing non-entity-centric KBs.
\begin{table}
	\centering
	\begin{tabular}{l|ccc|ccc}
		&\multicolumn{3}{c|}{\textbf{Navigation}}&\multicolumn{3}{c}{\textbf{Weather}}\\
		\textbf{Model}&\textbf{BLEU}&\textbf{Macro F1}&\textbf{Micro F1}&\textbf{BLEU}&\textbf{Macro F1}&\textbf{Micro F1}\\\hline
		Seq2Seq with Attention&8.3&15.6&17.5&\textbf{19.6}&56.0&53.5\\
		Copy Net &8.7&20.8&23.7&17.5&52.4&53.1\\
		KV Net &8.7&24.9&29.5&12.4&37.7&39.4\\
		our model&\textbf{13.7}&\textbf{62.0}&\textbf{56.9}&14.9&\textbf{58.5}&\textbf{56.3}\\
	\end{tabular}
	\caption{Automatic evaluation on test data. Best results are shown in bold. Generally, our framework outperforms other models in most automatic evaluation metrics. }
	\label{table2}
\end{table}
\begin{table}[!tp]
	\centering
	\begin{tabular}{l|ccc}
		\textbf{Model}&\textbf{BLEU}&\textbf{Macro F1}&\textbf{Micro F1}\\\hline
		our model&\textbf{13.7}&\textbf{62.0}&\textbf{56.9}\\
-copying&9.6&35.2&41.3\\
		-RL&9.3&38.2&46.0\\
	\end{tabular}
	\caption{Ablation experiment on navigation domain. 
		-copy refers to a framework without copying. -RL refers to a framework without RL loss.}
	\label{table3}
\end{table}
\subsubsection{Ablation}

In this section, we perform several ablation experiments to evaluate different components in our framework on the navigation domain. Results are shown in Table \ref{table3}. The results demonstrate effectiveness of components of our model to the final performance. 

Copying mechanism enables our framework to retrieve entities directly from KBs. Without copying mechanism, such retrieval is infeasible and our framework cannot produce values in KBs. The results show that it introduces more variability to the generation process if we do not use copying mechanism.

The reinforcement learning loss helps our framework to use correct KB entries so that improve the performance of generation. Without this reinforcement learning loss, the item selection process is only supervised by log likelihood loss. We address the drop in performance to that our model overfits to the training data.

\begin{table}[!tp]
	\centering
		\begin{tabular}{l|ccc}
	\textbf{Model}&\textbf{Correct}&\textbf{Fluent}&\textbf{Humanlike}\\\hline
	Copy Net &3.52&4.47&4.17\\
	KV Net&3.61&4.50&4.20\\
	our model&\textbf{4.21}&\textbf{4.65}&\textbf{4.38}\\\hline
	agreement&41.0&55.0&43.0
\end{tabular}
\caption{Human evaluation of responses based on random selected previous dialogue history in test dataset. The agreement scores indicate the percentage of responses to which all three human experts give exactly the same scores.}
\label{table4}
\end{table}

\subsection{Human Evaluation}
In this section, we provide human evaluation on our framework and other baseline models. We randomly generated 200 responses. These response are based on distinct dialogue history in navigation test data. We hire three different human experts to evaluate the quality of responses. Three dimensions are involved, which are correctness, fluency, and humanlikeness. Three human experts judged each dimension on a scale from 1 to 5. And each judgment indicates a relative score compared to standard response from test data. The results are illustrated in Table \ref{table4}. The results show that our framework outperforms other baseline models on all metrics. The most significant improvement is from correctness, indicating that our model generates more accurate information that the users want to know.

\begin{table}

\end{table}
\subsection{Visualization and Case Study}
We provide a visualization example to demonstrate the effectiveness of dialogue state representation. 
The visualization illustrates attention scores over the sentence for each slot. The blue-level of a cell indicates the attention score it represents.
From this visualization, we can discover that our dialogue state representation matches slots with correct entities in sentence. 
For example, ``\texttt{pizza\_restaurant}'' matches ``\texttt{poi}'' and 
``\texttt{poi\_type}'' correctly, ``\texttt{4\_miles}'' matches ``\texttt{address}'' correctly. The visualization indicates the capability of our framework to track accurate information and integrate them into a fix-size matrix representation.

Finally, we provide a case study that consists of two conversations which are generated between our framework and a human and between Seq2Seq with Attention with human respectively. In this case, we find that our framework is able to generate correct information such as address and point-of-interest. Conversely, Seq2Seq with Attention is generated in a more random way. The comparison between these two dialogues illustrates the capability of our model to retrieve accurate entities and while in the same time generate natural response.

\begin{figure}[!tp]
\centering
\includegraphics[scale=0.8, trim={0cm 1.3cm 0cm 0cm}, clip]{m_figure3.pdf}
\caption{Visualization of dialogue state representation.}
\end{figure}
\begin{figure}[!t]
	\centering
	\normalsize
	\label{fig4}
	\begin{tabular}{|l|l|l|l|l|}
		\hline\textbf{Address} & \textbf{Distance} & \textbf{POI type} & \textbf{POI} & \textbf{Traffic info} \\\hline
		783 Arcadia Pl&5 miles&gas station&Chevron&moderate traffic\\
		383 University Ave&5 miles&shopping center&Town and Country&no traffic\\
		864 Almanor Ln & 5 miles &friends house& jacks house & no traffic \\
		5671 barringer street&6 miles&home&home&heavy traffic\\
		657 Ames Ave&4 miles&rest stop&The Clement Hotel&no traffic\\
		638 Amherst St&1 miles&grocery store&Sigona Farmers Market&heavy traffic\\
		830 Almanor Ln&6 miles&chinese restaurant&tai pan&no traffic\\\hline
	\end{tabular}
	\\
	
	\begin{minipage}{0.49 \textwidth}
		\raggedright
		
		\begin{tabular}{lp{5.7cm}}
			\multicolumn{2}{c}{\textbf{our model}}\\
			\textbf{Driver:} & what gas stations are here ?\\
			\textbf{Car:} & there is a chevron 5 miles away .\\
			\textbf{Driver:} & that 's good ! please show me the address and pick the quickest route to get there !\\
			\textbf{Car:} & the address is 783 arcadia pl , i sent on your screen the best route to reach there .\\
			\textbf{Driver:} & thank you !\\
			\textbf{Car:} & you 're welcome ! \\
		\end{tabular}
	\end{minipage}
	\begin{minipage}{0.49\textwidth}
		\raggedleft
		\begin{tabular}{lp{5.7cm}}
			\multicolumn{2}{c}{\textbf{Seq2Seq with Attention}}\\
			\textbf{Driver:} & what gas stations are here ?\\
			\textbf{Car:} & there is a chevron 4 miles away .\\
			\textbf{Driver:} & that 's good ! please show me the address and pick the quickest route to get there !\\
			\textbf{Car:} & the address to safeway is 452 arcadia pl .\\
			\textbf{Driver:} & thank you !\\
			\textbf{Car:} & you 're welcome ! \\
			&\\
		\end{tabular}
	\end{minipage}
	\caption{Case study. The dialogue in the left is generated from our framework, and that in the right is generated from Seq2Seq with Attention baseline.}
\end{figure}
\section{Related Work}
The recent successes on neural networks spread across many natural language processing tasks, which also stimulate research on task-oriented dialogue system. 
The powerful distributed representation ability of neural networks makes task-oriented dialogue system end-to-end possible. 
Recently, \newcite{wen:2017:EACL} built a system that connects classic pipeline modules by a policy network training with a user simulator. \newcite{wen:2017:ICML} further introduced latent intention into end-to-end learning.
However, their modules like belief tracker still needs to be trained separately before end-to-end training. 
In contrast to their work, our framework trained the state tracker jointly with the end-to-end dialogue training. \newcite{liu:2017:interspeech} built a turn-level LSTM to model the dialogue state and generate probability distribution for each slot.
 \newcite{bordes-weston:2017:ICLR} built a system by applying memory network to store the previous dialogue history. But the responses are retrieved from templates, which is significantly different from our neural generative responses. Another type of work tried to build an end-to-end system as a task completion dialogue system \cite{li:2016:arxiv,li:2017:IJCNLP,peng:2017:EMNLP}. These modeled are trained through an end-to-end fashion via reinforcement learning algorithm using the reward from user simulators. However, their dialogue responses are not generated from the dialogue history directly but from a set of pre-defined action and explicit semantic frames.
 
Our soft KB attention can be considered as a process to retrieve entries, which has been explored in many QA and dialogue work.
One line of this research includes creating well-defined API calls to query the KB \cite{williams-asadi-zweig:2017:ACL,wen:2017:ICML}.
And another line of research tried to directly retrieve entities from knowledge base.
 \newcite{yin:2016b:IJCAI} has built a system to encode all table cells and assign a score vector to each row. Our framework resembles the second line of research, but can generate multiple entities to form natural language responses. 
\newcite{he:2017:ACL} has built two symmetric dialogue agents with private knowledge, and has applied knowledge graph reasoning into Seq2Seq learning, which is distantly related with our framework.
 In the sense of the KB forms, \newcite{yin:2016a:IJCAI} retrieved entities based on (\textit{subject, relation, object}) triples. 
 While \newcite{dhingra:2017:ACL} applied a soft-KB lookup on an entity-centric knowledge base to compute the probability of that the user knows the values of slots, and has tried to model the posterior distributions over all slots. 
 However, our framework doesn't require entity-centric knowledge base.


\section{Conclusion}
In this paper, we proposed a framework that leverages dialogue state representation, which is tracked by an attention-based methods. Our framework performed an entry-level soft lookup over the knowledge base, and applied copying mechanism to retrieve entities from knowledge base while decoding. This framework was trained in an end-to-end fashion with only the dialogue history, and get rid of other annotation. Experiments showed that our model outperformed other Seq2Seq models on both automatic and human evaluation. The visualization and case study demonstrated the effectiveness of dialogue state representation and entity retrieval.

\section{Acknowledgments}
We thank the anonymous reviewers for their helpful comments and suggestions.
This work was supported by the National Key Basic Research
Program of China via grant 2014CB340503 and the
National Natural Science Foundation of China (NSFC) via
grant 61632011 and 61772153.
\begin{thebibliography}{}
	
	\bibitem[\protect\citename{Bahdanau \bgroup et al.\egroup
	}2014]{bahdanau-cho-bengio:2014:arxiv}
	Dzmitry Bahdanau, Kyunghyun Cho, and Yoshua Bengio.
	\newblock 2014.
	\newblock Neural machine translation by jointly learning to align and
	translate.
	\newblock {\em arXiv preprint arXiv:1409.0473}.
	
	\bibitem[\protect\citename{Bordes and Weston}2017]{bordes-weston:2017:ICLR}
	Antoine Bordes and Jason Weston.
	\newblock 2017.
	\newblock Learning end-to-end goal-oriented dialog.
	\newblock In {\em Proceedings of International Conference on Learning
		Representations}.
	
	\bibitem[\protect\citename{Britz \bgroup et al.\egroup
	}2017]{britz-guan-luong:2017:EMNLP}
	Denny Britz, Melody Guan, and Minh-Thang Luong.
	\newblock 2017.
	\newblock Efficient attention using a fixed-size memory representation.
	\newblock In {\em Proceedings of the 2017 Conference on Empirical Methods in
		Natural Language Processing}, pages 392--400.
	
	\bibitem[\protect\citename{Dhingra \bgroup et al.\egroup
	}2017]{dhingra:2017:ACL}
	Bhuwan Dhingra, Lihong Li, Xiujun Li, Jianfeng Gao, Yun-Nung Chen, Faisal
	Ahmed, and Li~Deng.
	\newblock 2017.
	\newblock Towards end-to-end reinforcement learning of dialogue agents for
	information access.
	\newblock In {\em Proceedings of the 55th Annual Meeting of the Association for
		Computational Linguistics (Volume 1: Long Papers)}, volume~1, pages 484--495.
	
	\bibitem[\protect\citename{Eric and Manning}2017]{eric-manning:2017:EACL}
	Mihail Eric and Christopher Manning.
	\newblock 2017.
	\newblock A copy-augmented sequence-to-sequence architecture gives good
	performance on task-oriented dialogue.
	\newblock In {\em Proceedings of the 15th Conference of the European Chapter of
		the Association for Computational Linguistics: (Volume 2, Short Papers)},
	volume~2, pages 468--473.
	
	\bibitem[\protect\citename{Eric \bgroup et al.\egroup }2017]{eric:2017:SIGDial}
	Mihail Eric, Lakshmi Krishnan, Francois Charette, and Christopher~D Manning.
	\newblock 2017.
	\newblock Key-value retrieval networks for task-oriented dialogue.
	\newblock In {\em Proceedings of the 18th Annual SIGDial Meeting on Discourse
		and Dialogue}, pages 37--49.
	
	\bibitem[\protect\citename{Gu \bgroup et al.\egroup }2016]{gu:2016:ACL}
	Jiatao Gu, Zhengdong Lu, Hang Li, and Victor~OK Li.
	\newblock 2016.
	\newblock Incorporating copying mechanism in sequence-to-sequence learning.
	\newblock In {\em Proceedings of the 54th Annual Meeting of the Association for
		Computational Linguistics (Volume 1: Long Papers)}, volume~1, pages
	1631--1640.
	
	\bibitem[\protect\citename{He \bgroup et al.\egroup }2017]{he:2017:ACL}
	He~He, Anusha Balakrishnan, Mihail Eric, and Percy Liang.
	\newblock 2017.
	\newblock Learning symmetric collaborative dialogue agents with dynamic
	knowledge graph embeddings.
	\newblock In {\em Proceedings of the 55th Annual Meeting of the Association for
		Computational Linguistics (Volume 1: Long Papers)}, volume~1, pages
	1766--1776.
	
	\bibitem[\protect\citename{Kingma and Ba}2014]{kingma-ba:2014:ICLR}
	Diederik~P Kingma and Jimmy Ba.
	\newblock 2014.
	\newblock Adam: A method for stochastic optimization.
	\newblock {\em arXiv preprint arXiv:1412.6980}.
	
	\bibitem[\protect\citename{Li \bgroup et al.\egroup }2016]{li:2016:arxiv}
	Xiujun Li, Zachary~C Lipton, Bhuwan Dhingra, Lihong Li, Jianfeng Gao, and
	Yun-Nung Chen.
	\newblock 2016.
	\newblock A user simulator for task-completion dialogues.
	\newblock {\em arXiv preprint arXiv:1612.05688}.
	
	\bibitem[\protect\citename{Li \bgroup et al.\egroup }2017]{li:2017:IJCNLP}
	Xiujun Li, Yun-Nung Chen, Lihong Li, Jianfeng Gao, and Asli Celikyilmaz.
	\newblock 2017.
	\newblock End-to-end task-completion neural dialogue systems.
	\newblock In {\em Proceedings of the Eighth International Joint Conference on
		Natural Language Processing (Volume 1: Long Papers)}, volume~1, pages
	733--743.
	
	\bibitem[\protect\citename{Liu and Lane}2017]{liu:2017:interspeech}
	Bing Liu and Ian Lane.
	\newblock 2017.
	\newblock An end-to-end trainable neural network model with belief tracking for
	task-oriented dialog.
	\newblock In {\em Interspeech 2017}.
	
	\bibitem[\protect\citename{Luong \bgroup et al.\egroup
	}2015]{luong-pham-manning:2015:EMNLP}
	Thang Luong, Hieu Pham, and Christopher~D. Manning.
	\newblock 2015.
	\newblock Effective approaches to attention-based neural machine translation.
	\newblock In {\em Proceedings of the 2015 Conference on Empirical Methods in
		Natural Language Processing}, pages 1412--1421, Lisbon, Portugal, September.
	Association for Computational Linguistics.
	
	\bibitem[\protect\citename{Peng \bgroup et al.\egroup }2017]{peng:2017:EMNLP}
	Baolin Peng, Xiujun Li, Lihong Li, Jianfeng Gao, Asli Celikyilmaz, Sungjin Lee,
	and Kam-Fai Wong.
	\newblock 2017.
	\newblock Composite task-completion dialogue policy learning via hierarchical
	deep reinforcement learning.
	\newblock In {\em Proceedings of the 2017 Conference on Empirical Methods in
		Natural Language Processing}, pages 2231--2240.
	
	\bibitem[\protect\citename{Sharma \bgroup et al.\egroup
	}2017]{sharma:2017:arxiv}
	Shikhar Sharma, Layla~El Asri, Hannes Schulz, and Jeremie Zumer.
	\newblock 2017.
	\newblock Relevance of unsupervised metrics in task-oriented dialogue for
	evaluating natural language generation.
	\newblock {\em arXiv preprint arXiv:1706.09799}.
	
	\bibitem[\protect\citename{Srivastava \bgroup et al.\egroup
	}2014]{srivastava:2014:JMLR}
	Nitish Srivastava, Geoffrey Hinton, Alex Krizhevsky, Ilya Sutskever, and Ruslan
	Salakhutdinov.
	\newblock 2014.
	\newblock Dropout: A simple way to prevent neural networks from overfitting.
	\newblock {\em The Journal of Machine Learning Research}, 15(1):1929--1958.
	
	\bibitem[\protect\citename{Sutskever \bgroup et al.\egroup
	}2014]{sutskever:2014:NIPS}
	Ilya Sutskever, Oriol Vinyals, and Quoc~V Le.
	\newblock 2014.
	\newblock Sequence to sequence learning with neural networks.
	\newblock In {\em Advances in neural information processing systems}, pages
	3104--3112.
	
	\bibitem[\protect\citename{Tur and De~Mori}2011]{tur-demori:2011}
	Gokhan Tur and Renato De~Mori.
	\newblock 2011.
	\newblock {\em Spoken language understanding: Systems for extracting semantic
		information from speech}.
	\newblock John Wiley \& Sons.
	
	\bibitem[\protect\citename{Wen \bgroup et al.\egroup }2015]{wen:2015:ACL}
	Tsung-Hsien Wen, Milica Ga{\v{s}}ic, Dongho Kim, Nikola Mrk{\v{s}}ic, Pei-Hao
	Su, David Vandyke, and Steve Young.
	\newblock 2015.
	\newblock Stochastic language generation in dialogue using recurrent neural
	networks with convolutional sentence reranking.
	\newblock In {\em 16th Annual Meeting of the Special Interest Group on
		Discourse and Dialogue}, page 275.
	
	\bibitem[\protect\citename{Wen \bgroup et al.\egroup }2017a]{wen:2017:ICML}
	Tsung-Hsien Wen, Yishu Miao, Phil Blunsom, and Steve Young.
	\newblock 2017a.
	\newblock Latent intention dialogue models.
	\newblock In {\em International Conference on Machine Learning}, pages
	3732--3741.
	
	\bibitem[\protect\citename{Wen \bgroup et al.\egroup }2017b]{wen:2017:EACL}
	Tsung-Hsien Wen, David Vandyke, Nikola Mrk\v{s}i\'{c}, Milica Gasic, Lina~M.
	Rojas~Barahona, Pei-Hao Su, Stefan Ultes, and Steve Young.
	\newblock 2017b.
	\newblock A network-based end-to-end trainable task-oriented dialogue system.
	\newblock In {\em EACL}, pages 438--449, Valencia, Spain, April. Association
	for Computational Linguistics.
	
	\bibitem[\protect\citename{Williams and Young}2007]{williams-young:2007:CSL}
	Jason~D Williams and Steve Young.
	\newblock 2007.
	\newblock Partially observable markov decision processes for spoken dialog
	systems.
	\newblock {\em Computer Speech \& Language}, 21(2):393--422.
	
	\bibitem[\protect\citename{Williams \bgroup et al.\egroup
	}2013]{williams:2013:SIGDial}
	Jason~D Williams, Antoine Raux, Deepak Ramachandran, and Alan Black.
	\newblock 2013.
	\newblock The dialog state tracking challenge.
	\newblock In {\em Proceedings of the 14th Annual SIGDial Meeting on Discourse
		and Dialogue}, pages 404--413.
	
	\bibitem[\protect\citename{Williams \bgroup et al.\egroup
	}2017]{williams-asadi-zweig:2017:ACL}
	Jason~D Williams, Kavosh Asadi, and Geoffrey Zweig.
	\newblock 2017.
	\newblock Hybrid code networks: practical and efficient end-to-end dialog
	control with supervised and reinforcement learning.
	\newblock In {\em Proceedings of the 55th Annual Meeting of the Association for
		Computational Linguistics (Volume 1: Long Papers)}, volume~1, pages 665--677.
	
	\bibitem[\protect\citename{Williams}1992]{williams:1992:RL}
	Ronald~J Williams.
	\newblock 1992.
	\newblock Simple statistical gradient-following algorithms for connectionist
	reinforcement learning.
	\newblock In {\em Reinforcement Learning}, pages 5--32. Springer.
	
	\bibitem[\protect\citename{Williams}2012]{williams:2012:NAACL}
	Jason~D Williams.
	\newblock 2012.
	\newblock A belief tracking challenge task for spoken dialog systems.
	\newblock In {\em NAACL-HLT Workshop on future directions and needs in the
		spoken dialog community: tools and data}, pages 23--24. Association for
	Computational Linguistics.
	
	\bibitem[\protect\citename{Yin \bgroup et al.\egroup }2016a]{yin:2016a:IJCAI}
	Jun Yin, Xin Jiang, Zhengdong Lu, Lifeng Shang, Hang Li, and Xiaoming Li.
	\newblock 2016a.
	\newblock Neural generative question answering.
	\newblock In {\em Proceedings of the Twenty-Fifth International Joint
		Conference on Artificial Intelligence (IJCAI-16)}, pages 2972--2978. AAAI
	Press.
	
	\bibitem[\protect\citename{Yin \bgroup et al.\egroup }2016b]{yin:2016b:IJCAI}
	Pengcheng Yin, Zhengdong Lu, Hang Li, and Ben Kao.
	\newblock 2016b.
	\newblock Neural enquirer: learning to query tables in natural language.
	\newblock In {\em Proceedings of the Twenty-Fifth International Joint
		Conference on Artificial Intelligence (IJCAI-16)}. AAAI Press.
	
	\bibitem[\protect\citename{Young \bgroup et al.\egroup }2010]{young:2010:CSL}
	Steve Young, Milica Ga{\v{s}}i{\'c}, Simon Keizer, Fran{\c{c}}ois Mairesse,
	Jost Schatzmann, Blaise Thomson, and Kai Yu.
	\newblock 2010.
	\newblock The hidden information state model: A practical framework for
	pomdp-based spoken dialogue management.
	\newblock {\em Computer Speech \& Language}, 24(2):150--174.
	
	\bibitem[\protect\citename{Young \bgroup et al.\egroup }2013]{young:2013:IEEE}
	Steve Young, Milica Ga{\v{s}}i{\'c}, Blaise Thomson, and Jason~D Williams.
	\newblock 2013.
	\newblock Pomdp-based statistical spoken dialog systems: A review.
	\newblock {\em Proceedings of the IEEE}, 101(5):1160--1179.
	
\end{thebibliography}




\end{document}
