
\begin{figure*}[!p]
    \centering
    \setlength\tabcolsep{2.12345pt}
    \resizebox*{0.99\linewidth}{0.974\textheight}{\begin{tabular}{cccccc}
    \toprule[0.2em]
        Original Image & MaX-DeepLab-L & Axial-DeepLab~\cite{wang2020axial} & DetectoRS~\cite{qiao2020detectors} & DETR~\cite{carion2020end} & Ground Truth \\
        \midrule[0.07em]
         & Mask Transformer & Box-Free & Box-Based & Box Transformer & \\
         & 51.1\% PQ & 43.4\% PQ & 48.6\% PQ & 45.1\% PQ & \\
        \midrule[0.07em] \addlinespace[0.5em]
        \includegraphics[width=0.155\textwidth,height=0.2\textwidth]{figures_appendix/12748.jpg} &
        \includegraphics[width=0.155\textwidth,height=0.2\textwidth]{figures_appendix/12748_max.png} &
        \includegraphics[width=0.155\textwidth,height=0.2\textwidth]{figures_appendix/12748_axial.png} &
        \includegraphics[width=0.155\textwidth,height=0.2\textwidth]{figures_appendix/12748_detectors.png} &
        \includegraphics[width=0.155\textwidth,height=0.2\textwidth]{figures_appendix/12748_detr.png} &
        \includegraphics[width=0.155\textwidth,height=0.2\textwidth]{figures_appendix/12748_gt.png} \\
        \multicolumn{6}{p{0.98\textwidth}}{\small MaX-DeepLab segments the baby with its occluded leg correctly. DetectoRS and DETR merge the two people into one instance, probably because the two people have similar bounding boxes. In addition, DETR introduces artifacts around the head of the horse.} \\
        \midrule[0.07em] \addlinespace[0.5em]
        \includegraphics[width=0.155\textwidth]{figures_appendix/127517.jpg} &
        \includegraphics[width=0.155\textwidth]{figures_appendix/127517_max.png} &
        \includegraphics[width=0.155\textwidth]{figures_appendix/127517_axial.png} &
        \includegraphics[width=0.155\textwidth]{figures_appendix/127517_detectors.png} &
        \includegraphics[width=0.155\textwidth]{figures_appendix/127517_detr.png} &
        \includegraphics[width=0.155\textwidth]{figures_appendix/127517_gt.png} \\
        \includegraphics[width=0.155\textwidth]{figures_appendix/124975.jpg} &
        \includegraphics[width=0.155\textwidth]{figures_appendix/124975_max.png} &
        \includegraphics[width=0.155\textwidth]{figures_appendix/124975_axial.png} &
        \includegraphics[width=0.155\textwidth]{figures_appendix/124975_detectors.png} &
        \includegraphics[width=0.155\textwidth]{figures_appendix/124975_detr.png} &
        \includegraphics[width=0.155\textwidth]{figures_appendix/124975_gt.png} \\
        \includegraphics[width=0.155\textwidth]{figures_appendix/533493.jpg} &
        \includegraphics[width=0.155\textwidth]{figures_appendix/533493_max.png} &
        \includegraphics[width=0.155\textwidth]{figures_appendix/533493_axial.png} &
        \includegraphics[width=0.155\textwidth]{figures_appendix/533493_detectors.png} &
        \includegraphics[width=0.155\textwidth]{figures_appendix/533493_detr.png} &
        \includegraphics[width=0.155\textwidth]{figures_appendix/533493_gt.png} \\
        \multicolumn{6}{p{0.98\textwidth}}{\small MaX-DeepLab correctly segments all the boards, the zebras, and the people. All other methods fail in these challenging cases of similar bounding boxes and nearby object centers.} \\
        \midrule[0.07em] \addlinespace[0.5em]
        \includegraphics[width=0.155\textwidth]{figures_appendix/109055.jpg} &
        \includegraphics[width=0.155\textwidth]{figures_appendix/109055_max.png} &
        \includegraphics[width=0.155\textwidth]{figures_appendix/109055_axial.png} &
        \includegraphics[width=0.155\textwidth]{figures_appendix/109055_detectors.png} &
        \includegraphics[width=0.155\textwidth]{figures_appendix/109055_detr.png} &
        \includegraphics[width=0.155\textwidth]{figures_appendix/109055_gt.png} \\
        \multicolumn{6}{p{0.98\textwidth}}{\small MaX-DeepLab generates a high quality mask for the cat, arguably better than the ground truth. Axial-DeepLab predicts cat pixels on the right of the image, as the center of the cat is close to the center of the bike. And DETR misses the cat and introduces artifacts.} \\
        \midrule[0.07em] \addlinespace[0.5em]
        \includegraphics[width=0.155\textwidth]{figures_appendix/561958.jpg} &
        \includegraphics[width=0.155\textwidth]{figures_appendix/561958_max.png} &
        \includegraphics[width=0.155\textwidth]{figures_appendix/561958_axial.png} &
        \includegraphics[width=0.155\textwidth]{figures_appendix/561958_detectors.png} &
        \includegraphics[width=0.155\textwidth]{figures_appendix/561958_detr.png} &
        \includegraphics[width=0.155\textwidth]{figures_appendix/561958_gt.png} \\
        \includegraphics[width=0.155\textwidth]{figures_appendix/376322.jpg} &
        \includegraphics[width=0.155\textwidth]{figures_appendix/376322_max.png} &
        \includegraphics[width=0.155\textwidth]{figures_appendix/376322_axial.png} &
        \includegraphics[width=0.155\textwidth]{figures_appendix/376322_detectors.png} &
        \includegraphics[width=0.155\textwidth]{figures_appendix/376322_detr.png} &
        \includegraphics[width=0.155\textwidth]{figures_appendix/376322_gt.png} \\
        \multicolumn{6}{p{0.98\textwidth}}{\small MaX-DeepLab also performs well in the presence of many small instances.} \\
        \bottomrule[0.1em]
    \end{tabular}}
    \vspace{7pt}
    \caption{Comparing  MaX-DeepLab with other representative methods on the COCO {\it val} set. (Colors modified for better visualization).}
    \label{fig:comparison}
\end{figure*}

\begin{figure*}[p]
    \centering
    \setlength\tabcolsep{2.12345pt}
    \resizebox*{0.99\linewidth}{!}{\begin{tabular}{cccccc}
    \toprule[0.2em]
        Original Image & MaX-DeepLab-L & Axial-DeepLab~\cite{wang2020axial} & DetectoRS~\cite{qiao2020detectors} & DETR~\cite{carion2020end} & Ground Truth \\
        \midrule[0.07em]
         & Mask Transformer & Box-Free & Box-Based & Box Transformer & \\
         & 51.1\% PQ & 43.4\% PQ & 48.6\% PQ & 45.1\% PQ & \\
        \midrule[0.07em] \addlinespace[0.5em]
        \includegraphics[width=0.155\textwidth]{figures_appendix/24021.jpg} &
        \includegraphics[width=0.155\textwidth]{figures_appendix/24021_max.png} &
        \includegraphics[width=0.155\textwidth]{figures_appendix/24021_axial.png} &
        \includegraphics[width=0.155\textwidth]{figures_appendix/24021_detectors.png} &
        \includegraphics[width=0.155\textwidth]{figures_appendix/24021_detr.png} &
        \includegraphics[width=0.155\textwidth]{figures_appendix/24021_gt.png} \\
        \multicolumn{6}{p{0.98\textwidth}}{\small Similar to DETR~\cite{carion2020end}, MaX-DeepLab fails typically when there are too many masks to segment in an image. This example contains more than 200 masks that should be predicted, mostly people and ties.} \\
        \midrule[0.07em] \addlinespace[0.5em]
        \includegraphics[width=0.155\textwidth]{figures_appendix/186345.jpg} &
        \includegraphics[width=0.155\textwidth]{figures_appendix/186345_max.png} &
        \includegraphics[width=0.155\textwidth]{figures_appendix/186345_axial.png} &
        \includegraphics[width=0.155\textwidth]{figures_appendix/186345_detectors.png} &
        \includegraphics[width=0.155\textwidth]{figures_appendix/186345_detr.png} &
        \includegraphics[width=0.155\textwidth]{figures_appendix/186345_gt.png} \\
        \multicolumn{6}{p{0.98\textwidth}}{\small In this failure case, MaX-DeepLab mistakes the birds for kites in the sky, probably because the birds are too small.} \\
        \bottomrule[0.1em]
    \end{tabular}}
    \vspace{7pt}
    \caption{Failure cases of MaX-DeepLab on the COCO {\it val} set.}
    \label{fig:failures}
\end{figure*}

\begin{savenotes}
\begin{table*}[t]
    \setlength{\tabcolsep}{1.0em}
        \begin{center}
        \begin{tabular}{l|c|c|c|c|c}
            \toprule[0.2em]
            Method & Backbone & Input Size & Runtime (ms) & PQ [val] & PQ [test] \\
            \toprule[0.2em]
            \multicolumn{6}{c}{Fast Regime}\\
            \midrule
            Panoptic-DeepLab~\cite{cheng2019panoptic} & X-71~\cite{chollet2016xception} & 641641 & 74 & 38.9 & 38.8 \\
            MaX-DeepLab-S & MaX-S & 641641 & 67 & 46.4 & 46.7 \\
            \midrule
            \multicolumn{6}{c}{Slow Regime}\\
            \midrule
            DETR~\cite{carion2020end} & RN-101 & 1333800 & 128\footnote{https://github.com/facebookresearch/detr} & 45.1 & 46.0 \\
            Panoptic-DeepLab~\cite{cheng2019panoptic} & X-71~\cite{chollet2016xception} & 10251025 & 132 & 39.7 & 39.6 \\
            MaX-DeepLab-S & MaX-S & 10251025 & 131 & 48.4 & 49.0 \\
            \bottomrule[0.1em]
        \end{tabular}
        \end{center}
        \vspace{\abovetabcapmargin}
        \caption{End-to-end runtime. {\bf PQ [val]:} PQ (\%) on COCO val set. {\bf PQ [test]:} PQ (\%) on COCO test-dev set.
        }
        \label{tab:runtime}
        \vspace{\belowtabcapmargin}
    \end{table*}
    \end{savenotes}

\begin{figure*}[t]
    \centering
    \includegraphics[width=0.59\linewidth]{figures_appendix/histogram.pdf}
    \caption{The joint distribution for our  mask slots and 133 classes with 80 `thing' classes on the left and 53 `stuff' classes on the right. We observe that a few mask slots predict a lot of the masks. Some mask slots are used less frequently, probably only when there are a lot of objects in one image. Some other slots do not fire at all. In addition, we see automatic functional segregation between `thing' mask slots and `stuff' mask slots, with a few exceptions that can predict both thing and stuff masks.
    }
    \label{fig:distribution}
\end{figure*}

\begin{figure*}[t]
    \centering
    \setlength\tabcolsep{1.0pt}
    \begin{tabular}{ccccccccc}
    \midrule
    & \small Mask Slot 71 & \small Mask Slot 106 & \small Mask Slot 125 & \small Mask Slot 69 & \small Mask Slot 116 & \small Mask Slot 4 & \small Mask Slot 27 & \small Mask Slot 103\\
    \begin{tabular}{c}
    Most \\ Firings \\ (sorted)
    \end{tabular} &
    \raisebox{-.5\height}{\includegraphics[width=0.11\linewidth]{figures_appendix/many1.png}} &
    \raisebox{-.5\height}{\includegraphics[width=0.11\linewidth]{figures_appendix/many2.png}} &
    \raisebox{-.5\height}{\includegraphics[width=0.11\linewidth]{figures_appendix/many3.png}} &
    \raisebox{-.5\height}{\includegraphics[width=0.11\linewidth]{figures_appendix/many4.png}} &
    \raisebox{-.5\height}{\includegraphics[width=0.11\linewidth]{figures_appendix/many5.png}} &
    \raisebox{-.5\height}{\includegraphics[width=0.11\linewidth]{figures_appendix/many6.png}} &
    \raisebox{-.5\height}{\includegraphics[width=0.11\linewidth]{figures_appendix/many7.png}} &
    \raisebox{-.5\height}{\includegraphics[width=0.11\linewidth]{figures_appendix/many8.png}} \\
    \midrule
    & \small Mask Slot 84 & \small Mask Slot 67 & \small Mask Slot 23 & \small Mask Slot 101 & \small Mask Slot 127 & \small Mask Slot 28 & \small Mask Slot 105 & \small Mask Slot 122 \\
    \begin{tabular}{c}
    Medium \\ Firings \\ (sorted)
    \end{tabular} &
    \raisebox{-.5\height}{\includegraphics[width=0.11\linewidth]{figures_appendix/medium1.png}} &
    \raisebox{-.5\height}{\includegraphics[width=0.11\linewidth]{figures_appendix/medium2.png}} &
    \raisebox{-.5\height}{\includegraphics[width=0.11\linewidth]{figures_appendix/medium3.png}} &
    \raisebox{-.5\height}{\includegraphics[width=0.11\linewidth]{figures_appendix/medium4.png}} &
    \raisebox{-.5\height}{\includegraphics[width=0.11\linewidth]{figures_appendix/medium5.png}} &
    \raisebox{-.5\height}{\includegraphics[width=0.11\linewidth]{figures_appendix/medium6.png}} &
    \raisebox{-.5\height}{\includegraphics[width=0.11\linewidth]{figures_appendix/medium7.png}} &
    \raisebox{-.5\height}{\includegraphics[width=0.11\linewidth]{figures_appendix/medium8.png}} \\
    \midrule
    & \small Mask Slot 25 & \small Mask Slot 66 & \small Mask Slot 98 & \small Mask Slot 110 & \small Mask Slot 63 & \small Mask Slot 95 & \small Mask Slot 40 & \small Mask Slot 79 \\
    \begin{tabular}{c}
    Few \\ Firings \\ (sorted)
    \end{tabular} &
    \raisebox{-.5\height}{\includegraphics[width=0.11\linewidth]{figures_appendix/few1.png}} &
    \raisebox{-.5\height}{\includegraphics[width=0.11\linewidth]{figures_appendix/few2.png}} &
    \raisebox{-.5\height}{\includegraphics[width=0.11\linewidth]{figures_appendix/few3.png}} &
    \raisebox{-.5\height}{\includegraphics[width=0.11\linewidth]{figures_appendix/few4.png}} &
    \raisebox{-.5\height}{\includegraphics[width=0.11\linewidth]{figures_appendix/few5.png}} &
    \raisebox{-.5\height}{\includegraphics[width=0.11\linewidth]{figures_appendix/few6.png}} &
    \raisebox{-.5\height}{\includegraphics[width=0.11\linewidth]{figures_appendix/few7.png}} &
    \raisebox{-.5\height}{\includegraphics[width=0.11\linewidth]{figures_appendix/few8.png}} \\
    \midrule
    \end{tabular}
    \vspace{3pt}
    \caption{The average masks that each mask slot predicts, normalized by image shape. Mask slots are categorized by their total number of firings and sorted from most firings to few firings. We observe spatial clustered patterns, meaning that the mask slots specialize on certain regions of an input image. For example, the most firing mask slot 71, focusing on the center of an image, predicts almost all 80 `thing' classes but ignores `stuff' classes (\figref{fig:distribution}). The top three categories are tennis rackets, cats, and dogs. The second firing mask slot 106 segments 14 classes of masks on the bottom of an image, such as road, floor, or dining-tables. The third firing mask slot 125 concentrates 99.9\% on walls or trees that are usually on the top of an image. The fourth firing mask slot 69 focuses entirely on the person class and predicts 2663 people in the 5000 validation images.
    }
    \label{fig:pixel}
\end{figure*}

\subsection{Panoptic Segmentation Results}
Similar to the case study in \figref{fig:teaser}, we provide more panoptic segmentation results of our MaX-DeepLab-L and compare them to the state-of-the-art {\it box-free} method, Axial-DeepLab~\cite{wang2020axial}, the state-of-the-art {\it box-based} method, DetectoRS~\cite{qiao2020detectors}, and the first Detection Transformer, DETR~\cite{carion2020end} in \figref{fig:comparison} and \figref{fig:failures}. MaX-DeepLab demonstrates robustness to the challenging cases of similar object bounding boxes and nearby objects with close centers, while other methods make systematic mistakes because of their individual surrogate sub-task design. MaX-DeepLab also shows exceptional mask quality, and performs well in the cases of many small objects. Similar to DETR~\cite{carion2020end}, MaX-DeepLab fails typically when there are too many object masks.

\subsection{Runtime}
In \tabref{tab:runtime}, we report the end-to-end runtime (i.e., inference time from an input image to final panoptic segmentation) of MaX-DeepLab on a V100 GPU. All results are obtained by (1) a single-scale input without flipping, and (2) built-in TensorFlow library without extra inference optimization.
In the fast regime, MaX-DeepLab-S takes 67 ms with a typical 641641 input. This runtime includes 5 ms of postprocessing and 15 ms of batch normalization that can be easily optimized. This fast MaX-DeepLab-S does not only outperform DETR-R101~\cite{carion2020end}, but is also around 2x faster.
In the slow regime, the standard MaX-DeepLab-S takes 131 ms with a 10251025 input, similar to Panoptic-DeepLab-X71~\cite{cheng2019panoptic}. This runtime is also similar to our run of the official DETR-R101 which takes 128 ms on a V100, including 63 ms for box detection and 65 ms for the heavy mask decoding.

\subsection{Mask Output Slot Analysis}
In this subsection, we analyze the statistics of all  mask prediction slots using MaX-DeepLab-L. In \figref{fig:distribution}, we visualize the joint distribution of mask slot firings and the classes they predict. We observe that the mask slots have imbalanced numbers of predictions and they specialize on `thing' classes and `stuff' classes. Similar to this Mask-Class joint distribution, we visualize the Mask-Pixel joint distribution by extracting an average mask for each mask slot, as shown in \figref{fig:pixel}. Specifically, we resize all COCO~\cite{lin2014microsoft} validation set panoptic segmentation results to a unit square and take an average of masks that are predicted by each mask slot. We split all mask slots into three categories according to their total firings and visualize mask slots in each category. We observe that besides the class-level specialization, our mask slots also specialize on certain regions of an input image. This observation is similar to DETR~\cite{carion2020end}, but we do not see the pattern that almost all slots have a mode of predicting large image-wide masks.

\subsection{Mask Head Visualization}
In \figref{fig:vis3channels}, we visualize how the mask head works by training a MaX-DeepLab with only  decoder feature channels (for visualization purpose only). Although this extreme setting degrades the performance from 45.7\% PQ to 37.8\% PQ, it enables us to directly visualize the decoder features as RGB colors. Here in \figref{fig:maskhead} we show more examples using this model, together with the corresponding panoptic sementation results. We see a similar clustering effect of instance colors, which enables our simple mask extraction with just a matrix multiplication (a.k.a. dynamic convolution~\cite{tian2020conditional,wang2020solov2,jia2016dynamic,yang2019condconv}).

\begin{figure*}[t]
    \centering
    \setlength\tabcolsep{2.0pt}
    \begin{tabular}{ccc|ccc}
    \includegraphics[width=0.155\linewidth, height=0.11\linewidth]{figures_appendix/000013_image.png} &
    \includegraphics[width=0.155\linewidth, height=0.11\linewidth]{figures_appendix/000013_rgb.png} &
    \includegraphics[width=0.155\linewidth, height=0.11\linewidth]{figures_appendix/000013_result.png}
    \phantom{.} & \phantom{.}
    \includegraphics[width=0.155\linewidth, height=0.11\linewidth]{figures_appendix/000049_image.png} &
    \includegraphics[width=0.155\linewidth, height=0.11\linewidth]{figures_appendix/000049_rgb.png} & \includegraphics[width=0.155\linewidth, height=0.11\linewidth]{figures_appendix/000049_result.png} \\
    \includegraphics[width=0.155\linewidth, height=0.11\linewidth]{figures_appendix/000084_image.png} &
    \includegraphics[width=0.155\linewidth, height=0.11\linewidth]{figures_appendix/000084_rgb.png} & \includegraphics[width=0.155\linewidth, height=0.11\linewidth]{figures_appendix/000084_result.png}
    \phantom{.} & \phantom{.}
    \includegraphics[width=0.155\linewidth, height=0.11\linewidth]{figures_appendix/000026_image.png} &
    \includegraphics[width=0.155\linewidth, height=0.11\linewidth]{figures_appendix/000026_rgb.png} &
    \includegraphics[width=0.155\linewidth, height=0.11\linewidth]{figures_appendix/000026_result.png} \\
    \small Original Image & \small Decoder Feature  & \small Panoptic Seg. \phantom{.} & \small \phantom{.} Original Image & \small Decoder Feature  & \small Panoptic Seg. \\
    \end{tabular}
    \vspace{3pt}
    \caption{More visualizations of the decoder feature  with . Similar to \figref{fig:vis3channels}, we observe a clustering effect of instance colors, \ie, pixels of the same instance have similar colors (features) while pixels of different instances have distinct colors. Note that in this extreme case of  (that achieves 37.8\% PQ), there are not enough colors for all masks, which causes missing objects or artifacts at object boundaries, but these artifacts do not present in our normal setting of  (that achieves 45.7\%~PQ).}
    \label{fig:maskhead}
\end{figure*}


\subsection{Transformer Attention Visualization}
We also visualize the {\it M2P} attention that connects the transformer to the CNN. Specifically, given an input image from COCO validation set, we first select four output masks of interest from the MaX-DeepLab-L panoptic prediction. Then, we probe the attention weights between the four masks and all the pixels, in the last dual-path transformer block. Finally, we colorize the four attention maps with four colors and visualize them in one figure. This process is repeated for two images and all eight attention heads as shown in \figref{fig:attention}. We omit our results for the first transformer block since it is mostly flat. This is expected because the memory feature in the first transformer block is unaware of the pixel-path input image at all. Unlike DETR~\cite{carion2020end} which focuses on object extreme points for detecting bounding boxes, our MaX-DeepLab attends to individual object (or stuff) masks. This mask-attending property makes MaX-DeepLab relatively robust to nearby objects with similar bounding boxes or close mass centers.

\begin{figure*}[!p]
    \centering
    \setlength\tabcolsep{1.12345pt}
    \begin{tabular}{ccccc}
    \midrule
    Original Image & Head 1 & Head 2 & Head 3 & Head 4 \\
    \includegraphics[width=0.19\textwidth]{figures_appendix/486104.jpg} \phantom{.}&\phantom{.} \includegraphics[width=0.19\textwidth]{figures_appendix/486104_head0.png} & \includegraphics[width=0.19\textwidth]{figures_appendix/486104_head1.png} & \includegraphics[width=0.19\textwidth]{figures_appendix/486104_head2.png} & \includegraphics[width=0.19\textwidth]{figures_appendix/486104_head3.png} \\
    Panoptic Segmentation \phantom{.} & Head 5 & Head 6 & Head 7 & Head 8 \\
    \includegraphics[width=0.19\textwidth]{figures_appendix/486104.png} \phantom{.}&\phantom{.} \includegraphics[width=0.19\textwidth]{figures_appendix/486104_head4.png} & \includegraphics[width=0.19\textwidth]{figures_appendix/486104_head5.png} & \includegraphics[width=0.19\textwidth]{figures_appendix/486104_head6.png} & \includegraphics[width=0.19\textwidth]{figures_appendix/486104_head7.png} \\
    \multicolumn{5}{p{0.96\textwidth}}{\small Attention maps for three people (\blue{left}, \green{middle}, \yellow{right}) on a \red{playing field}.} \\
    \midrule
    Original Image & Head 1 & Head 2 & Head 3 & Head 4 \\
    \includegraphics[width=0.19\textwidth]{figures_appendix/439525.jpg} \phantom{.}&\phantom{.} \includegraphics[width=0.19\textwidth]{figures_appendix/439525_head0.png} & \includegraphics[width=0.19\textwidth]{figures_appendix/439525_head1.png} & \includegraphics[width=0.19\textwidth]{figures_appendix/439525_head2.png} & \includegraphics[width=0.19\textwidth]{figures_appendix/439525_head3.png} \\
    Panoptic Segmentation \phantom{.} & Head 5 & Head 6 & Head 7 & Head 8 \\
    \includegraphics[width=0.19\textwidth]{figures_appendix/439525.png} \phantom{.}&\phantom{.} \includegraphics[width=0.19\textwidth]{figures_appendix/439525_head4.png} & \includegraphics[width=0.19\textwidth]{figures_appendix/439525_head5.png} & \includegraphics[width=0.19\textwidth]{figures_appendix/439525_head6.png} & \includegraphics[width=0.19\textwidth]{figures_appendix/439525_head7.png} \\
    \multicolumn{5}{p{0.96\textwidth}}{\small Attention maps for two people (\green{woman}, \yellow{man}) cutting a \red{cake} on a \blue{table}.} \\
    \midrule
    \end{tabular}
    \vspace{3pt}
    \caption{Visualizing the transformer {\it M2P} attention maps for selected predicted masks. We observe that head 2, together with head 5, 7, and 8, mainly attends to the output mask regions. Head 1, 3, and 4 gather more context from broader regions, such as semantically-similar instances (scene 1 head 1) or mask boundaries (scene 2 head 4). In addition, we see that head 6 does not pay much attention to the pixel-path, except for some minor firings on the playing field and on the table. Instead, it focuses more on {\it M2M} self-attention which shares the same  with {\it M2P} attention (\equref{eq:memory}).}
    \label{fig:attention}
\end{figure*}


\subsection{More Technical Details}
\label{sec:appendix_details}
In \figref{fig:axial_block}, \figref{fig:building_blocks}, and \figref{fig:archs}, we include more details of our MaX-DeepLab architectures. As marked in the figure, we pretrain our model on ImageNet~\cite{krizhevsky2012imagenet}. The pretraining model uses only {\it P2P} attention (could be a convolutional residual block or an axial-attention block), without the other three types of attention, the feed-forward network (FFN), or the memory. We directly pretrain with an average pooling followed by a linear layer. This pretrained model is used as a backbone for panoptic segmentation, and it uses the backbone learning rate multiplier we mentioned in \secref{sec:exp}. After pretraining the CNN path, we apply (with random initialization) our proposed memory path, including the memory, the three types of attention, the FFNs, the decoding layers, and the output heads for panoptic segmentation. In addition, we employ multi-head attention with 8 heads for all attention operations. In MaX-DeepLab-L, we use shortcuts in the stacked decoder. Specifically, each decoding stage (resolution) is connected to the nearest two previous decoding stage outputs of the same resolution.

\begin{figure*}[!t]
    \centering
    \includegraphics[width=0.9\textwidth]{figures_appendix/axial_block.pdf}
    \caption{An example Axial-Block from Axial-DeepLab~\cite{wang2020axial}. This axial-attention bottleneck block consists of two axial-attention layers operating along height- and width-axis sequentially.}
    \label{fig:axial_block}
\end{figure*}

\begin{figure*}[t]
    \centering
    \setlength{\tabcolsep}{0.0em}
    \subfigure[Inception Stem~\cite{szegedy2016rethinking, szegedy2017inception}]{
        \includegraphics[width=0.17\linewidth]{figures_appendix/inception_stem.pdf}
        \label{fig:inception_stem}}
    \subfigure[Bottleneck block]{
        \includegraphics[width=0.17\linewidth]{figures_appendix/bottleneck.pdf}
        \label{fig:bottleneck}}
    \subfigure[Wide-Basic block]{
        \includegraphics[width=0.17\linewidth]{figures_appendix/basic_block.pdf}
        \label{fig:basic_block}}
    \subfigure[Wide-Bottle block]{
        \includegraphics[width=0.17\linewidth]{figures_appendix/wide_bottle.pdf}
        \label{fig:wide_bottle}} 
    \caption{Building blocks for our MaX-DeepLab architectures.}
    \label{fig:building_blocks}
\end{figure*}
    
\begin{figure*}[t]
    \centering
    \setlength{\tabcolsep}{0.0em}
    \subfigure[Dual-Path Transformer Block]{
        \includegraphics[width=0.23\linewidth]{figures_appendix/MaX_T.pdf}
        \label{fig:max_t}}
    \subfigure[MaX-DeepLab-Ablation]{
        \includegraphics[width=0.23\linewidth]{figures_appendix/MaX_A.pdf}
        \label{fig:max_a}}
    \subfigure[MaX-DeepLab-S]{
        \includegraphics[width=0.23\linewidth]{figures_appendix/MaX_S.pdf}
        \label{fig:max_s}}
    \subfigure[MaX-DeepLab-L]{
        \includegraphics[width=0.23\linewidth]{figures_appendix/MaX_L.pdf}
        \label{fig:max_l}}
    \caption{More detailed MaX-DeepLab architectures. {\bf Pretrain} labels where we use a classification head to pretrain our models on ImageNet~\cite{krizhevsky2012imagenet}. \subref{fig:max_t} A dual-path transformer block with  intermediate bottleneck channels. \subref{fig:max_a} The baseline architecture for our ablation studies in \secref{sec:ablation}. \subref{fig:max_s} MaX-DeepLab-S that matches the number of parameters and M-Adds of DETR-R101-Panoptic~\cite{carion2020end}. {\bf Axial-Block} (\figref{fig:axial_block}) is an axial-attention bottleneck block borrowed from Axial-DeepLab-L~\cite{wang2020axial}. \subref{fig:max_l} MaX-DeepLab-L that achieves the state-of-the-art performance on COCO~\cite{lin2014microsoft}. {\bf Wide-Axial} is a wide version of Axial-Block with doubled intermediate bottleneck channels, similar to the one used in Axial-DeepLab-XL~\cite{wang2020axial}. (The residual connections are dropped for neatness).
    }
    \label{fig:archs}
\end{figure*}
