





\documentclass[final,3p,times,twocolumn]{elsarticle}


\usepackage{amsthm}
\usepackage{amsopn}
\usepackage{amsmath}
\usepackage{url}
\usepackage{paralist}

\theoremstyle{plain}
\newtheorem{theorem}{Theorem}

\theoremstyle{definition}
\newtheorem{definition}{Definition}

\newcommand{\state}{s}
\newcommand{\states}{S}
\newcommand{\alphabet}{\Sigma}
\newcommand{\allprobs}{\mathcal{P}}
\newcommand{\initstate}{\state^{i}}

\newcommand{\reachset}{\mathcal{S}}
\newcommand{\errthres}{\epsilon}
\newcommand{\sys}{\mathcal{A}}
\newcommand{\prob}[3]{p_{{#1},{#2}}(#3)}
\newcommand{\computed}{v}
\newcommand{\smbol}{\alpha}
\newcommand{\smbolp}{\beta}
\newcommand{\plength}{n}
\newcommand{\statesi}{i}
\newcommand{\fpath}{\pi}
\newcommand{\ipath}{\rho}
\newcommand{\extension}[1]{{#1}^{\uparrow}}
\newcommand{\fword}{w}
\DeclareMathOperator{\lastWord}{last}
\newcommand{\last}[1]{\lastWord({#1})}
\newcommand{\infimum}{I}
\newcommand{\phit}{\mathcal{H}}
\newcommand{\pnhit}{\lnot\mathcal{H}}
\newcommand{\measset}{\mathcal{Z}}
\DeclareMathOperator{\lenWord}{len}
\newcommand{\len}[1]{\lenWord({#1})}
\newcommand{\iword}{\psi}
\DeclareMathOperator{\prWord}{Pr}
\newcommand{\lb}{l}
\newcommand{\ub}{u}
\newcommand{\iter}{r}
\newcommand{\recallEquation}[1]{Eq.~\ref{#1}}
\newcommand{\recallTable}[1]{Table~\ref{#1}}
\newcommand{\finmc}{\mathcal{M}}
\newcommand{\wprefix}[2]{\text{}}
\newcommand{\limword}{\vec{\iword}}
\newcommand{\recallInequation}[1]{Inequation~\ref{#1}}
\newcommand{\recallExternalThm}[1]{Thm.~{#1}}
\newcommand{\recallExternalDef}[1]{Def.~{#1}}
\newcommand{\st}{\mid}
\newcommand{\recallDefinition}[1]{Def.~\ref{#1}}
\newcommand{\bigiter}{R}
\newcommand{\iwordeps}{\iword^{\epsilon/2}}
\newcommand{\recallFigure}[1]{Fig.~\ref{#1}}
\newcommand{\wlogenCaps}{W.l.o.g.}
\newcommand{\qsep}{:}
\newcommand{\belief}[3]{b^{#1}_{#2}({#3})}
\newcommand{\beliefns}[2]{b^{#1}_{#2}}
\DeclareMathOperator{\supp}{supp}
\newcommand{\card}[1]{|{#1}|}
\newcommand{\sequ}{\sigma}
\DeclareMathOperator{\orderWord}{order}
\newcommand{\order}[1]{\orderWord(#1)}
\newcommand{\lsw}{LSW}
\newcommand{\lsws}{LSWs}
\DeclareMathOperator{\allwords}{Words}
\DeclareMathOperator{\lswWord}{LSW}
\newcommand{\alllsw}[1]{\lswWord({#1})}
\DeclareMathOperator{\statesWord}{States}
\newcommand{\stec}[1]{\statesWord({#1})}
\newcommand{\explanation}[1]{\mbox{#1}}
\newcommand{\pr}{\prWord\,\!}
 

\usepackage{amssymb}











\journal{Information Processing Letters}

\begin{document}

\begin{frontmatter}



\title{An algorithmic approximation of the infimum reachability
			probability for Probabilistic Finite Automata}\author{Sergio Giro\corref{cor1}}\address{FaMAF -- Universidad Nacional de C\'ordoba -- Argentina\\
			FCEIA -- Universidad Nacional de Rosario}


\cortext[cor1]{Urquiza 1949 16/F.
							Rosario, (2000) Rosario, Argentina}











\begin{abstract}
Given a Probabilistic Finite Automata (PFA), a set of states ,
and an error threshold , our algorithm approximates the
infimum probability (quantifying over all infinite words) that the automata
reaches . Our result contrasts with the known result that the
approximation problem is undecidable if we consider the supremum instead of the
infimum. Since we study the probability of reaching a set of states, instead of
the probability of ending in an accepting state, our work is more related to
model checking than to formal languages.
\end{abstract}

\begin{keyword}
probabilistic finite automata \sep reachability \sep automatic verification
\end{keyword}

\end{frontmatter}



\section{Introduction}
\label{}

Suppose you want to analyse a system  whose number of states is finite.
This system reacts to inputs from the environment in
a probabilistic fashion: if  is in state  and receives
 from the environment, the probability that  transitions
to state  is . Moreover, assume that the environment
cannot observe the state of  in order to choose the particular input
. The analysis you want to perform on this system is to calculate a
tight lower bound of the probability that the system achieves a certain goal,
no matter what the inputs are. For instance, inputs can model notifications
of the (un)availability of resources, and you might want to check that your
system sends a message with probability at least , no matter what the
available resources are.

The problem in the paragraph above can be modelled using Probabilistic Finite
Automata (PFA)~\cite{DBLP:journals/iandc/Rabin63,DBLP:journals/ai/MadaniHC03}.
The assumption that inputs do not depend on the internal state of the
state of the input is central to assert that a PFA model adequately
reflects the behaviour of the system. In case the environment can observe
the state of  to choose the particular input , the problem
can be modelled using Markov Decision Processes (MDP)~\cite{BOOK:Puterman}.


The usual semantics for PFA rely on the concept of \emph{acceptance},
by considering the set of finite words ending in an acceptance state
with probability greater than a given cut-point . In contrast,
we focus on the concept of \emph{reachability}, and we are interested
on the probability with which each infinite word reaches some of the states
in a given set . In the realm of MDPs, both the supremum and
the infimum probability can be calculated in polynomial
time~\cite{DBLP:conf/fsttcs/BiancoA95}. In contrast, in the PFA setting
the supremum problem is undecidable~\cite{DBLP:journals/ai/MadaniHC03} for
both finite and infinite words~\footnote{Here, we consider only infinite words,
as the infimum probability over finite words is either , if the initial
state of the system is in , or , if it is not.}.
In fact, the supremum probability that  reaches a state in
 cannot be even approximated algorithmically. This undecidability
result was the key to prove undecidability results for MDPs under partial
information~\cite{DBLP:conf/formats/GiroD07} as well as undecidability
for Probabilistic B\"uchi Automata~\cite{DBLP:conf/fossacs/BaierBG08}.

We present an algorithm to approximate the infimum probability that a PFA
 reaches a set of states . Moreover, the computed value
 is a lower bound of the infimum and, by performing a
sufficient number of iterations, we can ensure that it is as close to the
infimum as desired. Using the value , we can answer our motivating
problem by stating that ``the probability that the goal is achieved is at
least , no matter what the inputs are''. The fact that the value
 is close to the infimum implies that the bound we provide is tight.

\section{Algorithm}

For our algorithm, we use the following definitions: a Probabilistic Finite
Automata (PFA) is a quintuple
, where
 is a finite set of states,  is a set of symbols,
 is a set of probability distributions on , comprising
one probability distribution  for each
pair  in . The state 
is called the \emph{initial state} of , and  is a set of
\emph{hitting states}. We assume .

A finite path in  is a sequence

where  and 
for all . Note that paths always start with the initial state
. We write  for  and 
for . In an analogous way to finite paths, infinite paths
are infinite sequences alternating symbols and states. The set of all infinite
paths having the finite path  as prefix is denoted by
.

Given a word  over , let  denote the -th
symbol in . For every infinite word  over ,
for every finite path , the probability
 is defined as 
if ; if , we have
; if
, then
.
In the same way as for Markov chains and MDPs (namely, by resorting to the
Carath\'eodory extension theorem), the previous definition for sets of the form
 can be extended in such a way that, for all infinite
words , the value  is defined for all
measurable sets  of infinite paths.

Let  be the set of all infinite paths  such that
some of the states in  is in . The amount we want to
approximate is . Note that
 can be written as 

where  is the set of all finite paths  such that 
is the only state of  in .

In order to approximate , our algorithm iterates producing two
values in each iteration . One of the values is a lower bound 
and the other one is an upper bound . These bounds comply with:

To approximate  with error at most , the algorithm stops
when  (this is guaranteed to occur as
both  and  converge to the
same limit), and then returns . Note that  is also a
value with error less than  but, in order to give a safe lower bound
on the probability that a hitting state is reached, we use the pessimistic
value .

In the next subsections, we show how to calculate upper and lower bounds
complying with the desired properties.

\subsection{Lower bounds}

Let  where
 is the set of paths such that  is the only state
of  in  and . By making the
same observation as for~\recallEquation{eq:def-phit}, we deduce that
 is the set of all infinite paths reaching 
after at most  symbols. We often profit from the inclusion


We take .
Next, we show that this number can be calculated by brute force. 

Since only the first  symbols are relevant, we need to consider each of
the finite words  having exactly  symbols. The truncation
operator , that returns the prefix of 
having length , will thus be quite useful in this subsection.
In addition, we use the notation  to mean
, where  is any infinite word such
that .

For each  with , we construct a finite Markov
chain . The procedure resembles the standard unfolding of a
probabilistic automaton (or an MDP) for a particular
adversary~\cite{thesis:segala}, and so we merely outline it. The states of
 are pairs  with  in 
and . To describe  briefly, let's say that
the path

in  maps to the path
 in .
For all , the probability of transitioning
from  to  is 
(note that these probabilities depend on ). For simplicity, the states
 are stuttering. The initial state of  is
. The previous definitions for  imply that the
probabilities of the paths in  having length at most  coincide
with the probabilities of the corresponding paths in :

As a consequence, the probability that  reaches  in
at most  steps equals the probability that  reaches a state in
. The latter probability can be
calculated using standard techniques, as it poses a simple reachability
problem for finite Markov chains.

We have just showed that  is computable. We still need to prove
that it complies with the properties we need so that our main algorithm works.
In order to prove \recallInequation{ineq:lb-increase}, we use the fact
that ,
where  is the set of all words of length . Let  be

and  be . The required inequality
 follows since
,
where the last inequality holds since
.


Next, we prove \recallInequation{ineq:lb-islower}. Let
 be a sequence of
infinite words such that

and the sequence 
is non-increasing (such a sequence exists by definition of infimum). Let
 be a word of length  that appears infinitely often in the
sequence  (this word
exists as the sequence is infinite, and there are finitely many words of
length ).

We prove \recallInequation{ineq:lb-islower} by proving
. Suppose, towards a
contradiction, that . Then,
by definition of  there exists  in  such that
.
Since  appears infinitely often in
, there exists
 such that . Since
the values  are non-increasing, we reach the following
contradiction:
.


It remains to prove \recallEquation{eq:lb-tends-inf}. In
other to prove this equality, let
 be the sequence

(the set  has been defined above). Note that
 
Given , we construct an infinite \emph{limit} word\footnote{We use the word
\emph{limit} as it resembles the \emph{limit schedulers}
in~\cite{DBLP:journals/entcs/GiroD09}.}  having the property that,
for every , the prefix  appears infinitely often in
the sequence .
We take the first symbol  to be any symbol that appears
infinitely often in .
In order to obtain the second symbol , we consider
the subsequence  of  containing all words in  whose
first symbol is . Then,  is any symbol
that appears infinitely often as the second symbol in 
. In general, we can
describe the process to obtain  and 
in an inductive fashion,  by stating that  is any symbol that
appears infinitely often in  and
 is an (infinite) subsequence of  complying with
. The existence of the subsequence  
ensures that  appears infinitely often in
, as desired.

As an auxiliary result, we prove .
Suppose, towards a contradiction, that .
Then, there exists  such that
.
As\footnote{This equality is standard for reachability properties, and can
be deduced from
.}

there exists  such that

for all .
By definition of , there exists  such that
. Then,
 (where the last inequality holds by
definition of ) thus
contradicting~\recallInequation{ineq:limword-gt-other-word}.

Now we are ready to prove .
Since  for all , we have
. Suppose, towards a
contradiction, that . Then, by
 and~\recallEquation{eq:reach-by-limit},
there exists  such that

By definition of , there exists  such that
.
Then, by~\recallEquation{eq:alt-def-lb}, we have
, which
contradicts~\recallInequation{ineq:limit-lt-inf}.

\subsection{Upper bounds}

For our upper bounds, we use \emph{lasso-shaped} words (\lsw). A \lsw\ is an
infinite word of the form
, in which the last 
in which the sequence of symbols  is looped
infinitely many times. The name \emph{lasso-shaped} is borrowed from the
counterexamples for LTL properties of B\"uchi automata, this name being used,
for instance, in~\cite{DBLP:conf/tacas/SchuppanB05}. Such counterexamples also
consist of a finite stem and a sequence that is looped infinitely many times.

In this paper, we restrict to \lsws\ with  (recall
that  is the set of states of the PFA), and we say that  is the
 of , denoted by . Note that, because of
our restriction on the length of the loop, the amount of \lsws\ with order at
most  is finite.

We denote by  the set of all \lsw\ with order at most .
The set of all infinite words is denoted by .

For upper bounds, we take
.
Inequalities~\ref{ineq:ub-decrease} and~\ref{ineq:ub-isupper} follow from
.

The computability of  follows in a similar way to that of
: the amount of \lsws\ having order at most  is finite, and we
can explore the probabilities for each of these words. Similarly as for the
lower bounds, the probability for a word  is calculated
by constructing a finite Markov chain. We just outline the construction. The
set of the states of the Markov chain is
\newcommand{\isstem}{\mathsf{S}}
\newcommand{\isloop}{\mathsf{L}}

(where  and ).
The initial state is . In the state 
(, resp.), the probability distribution for the next state is
determined by the -th symbol in the stem (in the loop, resp.) In symbols, the
probability of transitioning from  to
 is  whenever
. From  to
, the probability is
. The probabilities for the loop are
defined in a similar way: the only difference is that in a state
 in the end of the loop, we have that
 is the probability of transitioning to
 (that is, we return to the beginning of the loop). Note that
all the paths with positive probability are of the form

Is is easy to see that the probability
 is the probability of reaching a state
 such that , and so the minimum probability for all
words of order at most  can be obtained by constructing a Markov chain for
each of such words.

It remains to prove \recallEquation{eq:ub-tends-inf}.
If , then  for all , and so the equation
is trivial. From now on, we concentrate on the case . In order to
prove that the limit is the infimum, it suffices to show that, for all
, there exists  such that

We can indeed restrict to  such that

(Having proved the result for such values, the result also holds for the values
 such that , by taking  such
that   and hence
.)

We prove~\recallInequation{ineq:desired-lim} by showing that there exists
 with
 such that ,
By taking  to be the order of , we obtain
\recallInequation{ineq:desired-lim}, that is, the value 
is -close to .

Let  be an infinite word such that
 (such a word exists by
definition of infimum). Using this word, we construct the word 
with the desired properties. For this construction, we focus on
the probability of \emph{not} reaching  (that is, the probability of
all infinite paths such that none of the states is in ).
By definition of , we know that  does not reach
 with probability greater than ; in
symbols:

where  is the complement of , that is, the set of all infinite
paths  such that  for all .

Using , we define  in such a way that

and so . The proof proceeds by
finding numbers  and  such that the first  symbols of 
are the same as in . We name these symbols
.
After these symbols, the word  repeats
 indefinitely. This word is illustrated
in~\recallFigure{fig:counter-example-pfa}. The intuition behind the proof is
that there exists a set  of states such that, after exactly  steps,
there is sufficiently high probability to be in , without hitting
 (in the figure, states in  are represented with crosses).
Moreover, if  (, respectively) is the set of all states that
can be reached after symbol  (, resp.) occurs in some
state in  (, resp.), then  for
all .
\begin{figure}
\centering
\begin{picture}(0,0)\includegraphics{counter-example-pfa.pstex}\end{picture}\setlength{\unitlength}{2901sp}\begingroup\makeatletter\ifx\SetFigFont\undefined \gdef\SetFigFont#1#2#3#4#5{\reset@font\fontsize{#1}{#2pt}\fontfamily{#3}\fontseries{#4}\fontshape{#5}\selectfont}\fi\endgroup \begin{picture}(3676,3799)(-1592,-4630)
\put(901,-4561){\makebox(0,0)[lb]{\smash{{\SetFigFont{8}{9.6}{\rmdefault}{\mddefault}{\updefault}{}}}}}
\put(451,-4111){\makebox(0,0)[b]{\smash{{\SetFigFont{8}{9.6}{\rmdefault}{\mddefault}{\updefault}{}}}}}
\put(451,-2761){\makebox(0,0)[b]{\smash{{\SetFigFont{8}{9.6}{\rmdefault}{\mddefault}{\updefault}{}}}}}
\put(-1349,-2356){\makebox(0,0)[rb]{\smash{{\SetFigFont{8}{9.6}{\rmdefault}{\mddefault}{\updefault}{}}}}}
\put(-1577,-1927){\makebox(0,0)[rb]{\smash{{\SetFigFont{8}{9.6}{\rmdefault}{\mddefault}{\updefault}{}}}}}
\put(-1577,-1028){\makebox(0,0)[rb]{\smash{{\SetFigFont{8}{9.6}{\rmdefault}{\mddefault}{\updefault}{}}}}}
\put(-1349,-2137){\makebox(0,0)[rb]{\smash{{\SetFigFont{8}{9.6}{\rmdefault}{\mddefault}{\updefault}{}}}}}
\put(-1349,-1321){\makebox(0,0)[rb]{\smash{{\SetFigFont{8}{9.6}{\rmdefault}{\mddefault}{\updefault}{}}}}}
\end{picture} \caption{\label{fig:counter-example-pfa}Avoiding
										 with high probability}
\end{figure}
We find ,  and show that  complies with
\recallInequation{ineq:iword-star-avoids-reach}.

In order to obtain the required , , we profit from the fact that a PFA
according to our definition can be seen as a particular case of an MDP. For the
sake of completeness, we show how our definition for PFA matches the definition
of MDP in~\cite{thesis:deAlfaro}. If the MDP underlying a PFA  is obvious
to the reader, then the rest of this paragraph can be safely skipped.
In~\cite{thesis:deAlfaro}, (\recallExternalDef{3.1}), an MDP 
is defined by a set of states , a set of actions  enabled at each
state , and probabilities  of stepping from  to  using ,
for each . When mapping a PFA  to an MDP , the set of
states  of  is the same set of states as in ; for each  the
set  of actions enabled is the set ; the probabilities
 in~\cite{thesis:deAlfaro} are simply .

Using the MDP underlying , we can resort to the \emph{end-component
theorem} (\cite[\recallExternalThm{3.2}]{thesis:deAlfaro}). In terms of PFA,
the definition of an end component is as follows.
\begin{definition}
\label{def:end-component}
An end component is a set  such that for
every states  in (a pair in)  there
exists a path

such that  and
 for all
. We write  for the set of states of .
When no confusion arises, we simply write  instead of
.
\end{definition}
Let  be the set of infinite paths
 such that there exists  such that
the set  is an end component. The
end-component theorem states that  has probability  for all
words. The paths in  are said to \emph{end} in an end component.
Then, the set of paths that do not end in an end component (that is, the paths
for which no such  exists) has probability  for all words and, roughly
speaking, can thus be disregarded in probability calculations.

From now on, we are interested on the set  comprising all paths
ending in an end component. Now we show a partition for . For all
finite paths , end components , let  be the set of all
infinite paths  such that
 for all . Next, we prove that the set
 is equal to

where  is the set of all pairs  such that
 is either the trivial path , and ; or

and  and 
in . In words, the last state/symbol pair is not in , but the last state
is. Clearly, the inclusion  holds as the
paths in  end in  for all , . In order to prove the
inclusion , we prove that any path
 is also in . Since
, there exists  as
in~\recallDefinition{def:end-component}. Let's consider the minimum such .
The existence of  ensures that  has a prefix  after which
all the pairs state/symbol are in . Moreover, since we are considering the
minimum , either  is the trivial path , and 
is in ; or the last state/symbol pair before  is not in .
In summary, the fact that  is minimum ensures that there exists
 such that . It remains to
prove disjointness, that is, 
imply . Suppose that there exists
. The set of all state/symbol pairs
that appear infinitely often in  are all the pairs in 
(as ), and the same goes for , thus yielding
. It remains to prove . We have that  and
 are both a prefix of . Moreover, since we consider only
finite paths in which the last state/symbol pair is not in , we have that
 is the smallest prefix such that after  all the state/symbol
pairs are in , and the same holds for . Then, both  and
 have the same length, and so .

As a consequence of the partition we found, and the end-component theorem, for
all words  we have
.
If a paths ends in an end component  and does not hit , then no
prefix hits , and  has no states in . Hence, for all
words  we have

The outer sum ranges over all finite paths such that no state is in 
(which we denote as ), and the inner sum
ranges over all end components  such that the last state/action pair in
 is not in , the last state is in , and no state of  is in
 (denoted by ). In particular, for the
word  in~\recallInequation{ineq:iwordeps-gt-epsilon}, we have
.
Then, there exists a finite set
 such that
.
Let . For the sake of brevity,
let  be the set of all pairs  such that
, and , and
, and , and
. Then,


Note that we can restrict to the pairs  such that
, as the pairs with probability 
do not affect the sum.
In addition, by \recallInequation{ineq:restrict-epsilon}, we have
, and so in the sum in
\recallInequation{ineq:prob-bounded-non-reaching} there is at least one
positive summand .

\begin{figure}
\centering
\begin{picture}(0,0)\includegraphics{exiting-end-component.pstex}\end{picture}\setlength{\unitlength}{2901sp}\begingroup\makeatletter\ifx\SetFigFont\undefined \gdef\SetFigFont#1#2#3#4#5{\reset@font\fontsize{#1}{#2pt}\fontfamily{#3}\fontseries{#4}\fontshape{#5}\selectfont}\fi\endgroup \begin{picture}(3685,1400)(1191,-5911)
\put(4861,-4820){\makebox(0,0)[lb]{\smash{{\SetFigFont{8}{9.6}{\rmdefault}{\mddefault}{\updefault}{}}}}}
\put(1877,-4685){\makebox(0,0)[b]{\smash{{\SetFigFont{8}{9.6}{\rmdefault}{\mddefault}{\updefault}{}}}}}
\put(3061,-4685){\makebox(0,0)[b]{\smash{{\SetFigFont{8}{9.6}{\rmdefault}{\mddefault}{\updefault}{}}}}}
\put(3061,-5416){\makebox(0,0)[b]{\smash{{\SetFigFont{8}{9.6}{\rmdefault}{\mddefault}{\updefault}{}}}}}
\put(3286,-5056){\makebox(0,0)[b]{\smash{{\SetFigFont{8}{9.6}{\rmdefault}{\mddefault}{\updefault}{}}}}}
\end{picture} \caption{\label{fig:exiting-end-component} is
					in , but  is not}

\end{figure}
The desired ,  are now obtained from  and . Note that,
although we restricted to the summands complying with
, it is still possible that 
exits  after  with positive probability (as the same symbol might
be inside  for a reachable state , but outside  for a state
 that is reachable after the same number of steps as , see
\recallFigure{fig:exiting-end-component}). We
show that, by considering arbitrarily large paths, the probability that  is
exited becomes arbitrarily small.

Let  be the probability that, after  steps,
the state is reached is . We generalize this notation to sets of states.
Formally:
.
We call the distribution  a \emph{belief state},
following the nomenclature for POMDPs~\cite{DBLP:journals/ai/KaelblingLC98}.
Since the set of states is finite, there exist two indices  such that

(where  denotes the support of the distribution). Moreover, given any
two numbers , , such that , we have
 and
 for some
, . Since the amount of sequences of the form
 with  is
finite (where each  is a set of states), at least one of such finite
sequences appears infinitely many times in the infinite sequence
. Suppose this
finite sequence is .

We show that we can take
.
In addition, we take  to be a number (defined below) greater than , in
which an occurrence of  starts.

Given a component  in a pair in  (defined before
\recallInequation{ineq:prob-bounded-non-reaching}), let

In other words,  comprises the states in  from
which, when executing , we can only reach states
in . Let  be .

Consider the infinite sequence
 of indices where  starts. We show that
 for all
. (As the number of states is finite, this implies
.)
Suppose, towards a contradiction, that for some , ,
we have  for all . By definition of
, there exists , , and  such that
. Then, the
probability of staying in  after the -th repetition of  is
less than or equal to , for all . This implies that the
probability of staying in  indefinitely is , thus contradicting the fact
that .

As a result, for all pairs  in , there exists
 such that

Define

and 
.
We have
.
Then,

for all infinite words .

We have

as, under , all paths of length  ending in a state in
 do not reach states outside  (because of our definition of 
and the symbols ). In fact, if , the
scenario in \recallFigure{fig:exiting-end-component} is possible under
, but not possible under . Roughly speaking, after 
steps the word  does not escape , thus yielding higher
(or equal) probability for  than any word  such that
 and, in particular, than
. Then,

In conclusion, the word

(where  are first
 symbols in ) complies with
\recallInequation{ineq:iword-star-avoids-reach}. Since
, we obtain
. By
\recallInequation{ineq:ub-decrease}, this inequality implies

for all , thus ensuring \recallEquation{eq:ub-tends-inf}.

\section{Discussion}

Our algorithm is nonprimitive recursive, and we have still nothing to say
about the complexity of the problem.

However, the fact that there exists an algorithm to approximate the value is
quite surprising considering similar problems for PFA, as shown in
\recallTable{tab:decidability}. The table indicates, for the problems of
reachability and acceptance, whether there exists an
algorithm to approximate and/or to compute extremal values.
\begin{table}
\centering
\footnotesize
\begin{tabular}{|c|c|c|}
\hline
Approximate/Compute &  Infimum & Supremum \cite{DBLP:journals/ai/MadaniHC03} \\
\hline
Reachability 		&		& 
									\\
\hline
Acceptance	\cite{DBLP:journals/mst/BlondelC03} & 
												&    \\
\hline
\end{tabular}
\caption{\label{tab:decidability}Existence of algorithms for PFA}
\end{table}
Note that the only  in the table corresponds to the result in this
paper. The table also indicates two pending questions: whether there exists
an algorithm to effectively compute the infimum for reachability, and whether
the infimum for acceptance can be approximated.

The undecidability for the supremum probability has been used to prove that
quantitative model checking under partial
information~\cite{DBLP:conf/formats/GiroD07,DBLP:conf/sbmf/Giro09} is
undecidable for properties involving the supremum. The setting of these papers
is more general, as several entities might have different information about the
state of the system (in contrast, the problem we address in this paper concerns
only an environment that has no information about the state of the system).
However, we expect that the proof we presented sheds some light on whether this
more general problem is computable or not, in case we consider the infimum
instead of the supremum.

\bibliographystyle{elsarticle-num}
\bibliography{probability.bib}

\end{document}
