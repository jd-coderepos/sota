\documentclass{article}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{hyperref}

\title{Invisible pushdown languages}

\author{Eryk~Kopczy\'nski}




\begin{document}

\maketitle

\newcounter{mycount}[section]
\renewcommand{\themycount}{\thesection.\arabic{mycount}}

\newtheorem{theorem}[mycount]{Theorem}
\newtheorem{lemma}[mycount]{Lemma}
\newtheorem{definition}[mycount]{Definition}
\newtheorem{problem}[mycount]{Problem}


\newenvironment{proof}[1][]{\medskip{\bf Proof #1 }}{}
\def\qed{\hfill\par\medskip}

\def\mod{{\rm{\ mod\ }}}
\def\ra{\rightarrow}
\def\la{\leftarrow}
\def\trans{\delta}
\def\rh{|}
\def\ut{\tau}
\def\emt{\emptyset}
\def\Port{{\rm{port}}}
\def\Aut{\mathcal A}
\def\Lang{\mathcal L}
\def\restrict{{\rm{Restrict}}}

\def\dom{{\rm{dom}}}
\def\bia{\{0,1\}}
\def\i{\hskip 2em}
\def\EOT{{\rm EOT}}
\def\pat{p}

\def\calC{{\mathcal C}}
\def\bbN{{\mathbb N}}
\def\PaV{V^P}
\def\PaE{E^P}
\def\SpV{{V^\tau}}
\def\SpE{{E^\tau}}
\def\SpR{{v^\tau}}

\def\bbN{{\mathbb N}}
\def\bbR{{\mathbb R}}
\def\bbP{{\mathbb P}}
\def\bbZ{{\mathbb Z}}
\def\bbC{{\mathbb C}}
\def\oa{\diamondsuit}
\def\ca{\overbar{\diamondsuit}}
\def\leaf{\spadesuit}

\newcommand{\overbar}[1]{\mkern 1.5mu\overline{\mkern-1.5mu#1\mkern-1.5mu}\mkern 1.5mu}

\begin{abstract}
Context free languages allow one to express data with hierarchical structure,
at the cost of losing some of the useful properties of languages recognized by 
finite automata on words. However, it is possible
to restore some of these properties by making the structure of the tree visible, 
such as is done by visibly pushdown languages, or finite automata on trees.
In this paper, we show that the structure given by such approaches remains
invisible when it is read by a finite automaton (on word).
In particular, we show
that separability with a regular language
is undecidable for visibly pushdown languages, just as it is undecidable for
general context free languages.
\end{abstract}

\section{Introduction}

Finite automata are a well known formalism for describing the simplest formal languages.
Regular languages -- ones which are recognized by finite automata -- have very nice
closure properties, such as decidability of most problems such as universality or
disjointness, equivalence of deterministic finite automata (DFA) and non-deterministic
finite automata (NFA), and closure under complement.

However, most programming and natural languages have to describe a hierarchical (tree)
structure, and finite automata on words are no longer appropriate.
To capture such a hierarchical structure,
Noam Chomsky proposed the classic notion of \emph{context free languages}.
Context free languages are recognized
by context free grammars (CFGs), or equivalently by pushdown automata (PDA).

However, context free languages do not have as good properties as regular ones --
for example, universality and disjointness are no longer decidable, deterministic
PDA are less powerful than non-deterministic ones, and they are not closed under
complement. These properties fail since, although
words from a context free language have an underlying tree structure, it is hard
to tell what this structure is just by looking at the word -- two completely different
derivation trees can yield a very similar output, consider for example the English
sentences \emph{Time flies like an arrow} and \emph{fruit flies like a banana}, 
or \emph{The complex houses married and single soldiers and their families} -- after
reading the four first words of the latter sentence, one could think that 
\emph{the complex houses} is the subject and \emph{married} is the verb, while in fact,
\emph{the complex} is the subject and \emph{houses} is the verb. This is also a big
problem in practical computer science, since such a possibility of incorrect parsing leads to many errors
-- one famous example is the SQL injection attack, which is based on fabricating
SQL queries which will be parsed incorrectly, allowing unauthorized access to a database.

There are two popular approaches to solve this. One of them is to use the 
\emph{finite automata on trees} (TFAs) \cite{tata}, which work on trees directly. Another one is to
use \emph{visibly pushdown automata} (VPDAs), also known as languages of \emph{nested
words} \cite{visibly}, where every symbol in our alphabet has a fixed type
with respect to the stack -- it either always pushes a new symbols, or always pops a
symbol, or it never pushes or pops symbols -- this property allows the tree structure to be easily
read. When we safely flatten a language on trees into a language of words -- XML is the
common and effective way to do that -- these two approaches are seen to be equivalent
(in some sense), and most properties of regular languages of words are retained --
non-deterministic and deterministic VPDAs and finite automata on trees are equivalent,
and universality and intersection problems are decidable. Hence,
representing our data as trees, instead of forcing a linear word structure,
definitely solves many problems -- both theoretical and practical -- efficiently.

In this paper, we show that not all problems are solved by these approaches. In
particular, we show that, informally,
although (flattened) TFAs and VPDAs are successful at making
the structure visible to powerful computation models such as
Turing machines, the structure still remains invisible to the simple
ones, such as finite automata on words. We use our technique to show that the following
problem is undecidable, just as in the usual ``invisible'' context free case
\cite{hunt, szymanski}:
given two VPDAs (or, equivalently, flattened TFAs) accepting languages  and 
such that  and  are disjoint, is there a regular language  such that
 accepts all words from , but no words from ?

A similar property
is also obtained for separating by other classes of languages, as long as the
corresponding problem for CFGs is undecidable, and the separating class has basic
closure properties and a pumping property -- the precise conditions are listed in the
sequel.
In \cite{hunt} it is shown that the separability problem of
context free languages is undecidable for any class which includes all
{\it definite} languages. On the other hand, 
it has been shown recently that the problem of separability of CFLs by
\emph{piecewise testable languages} is decidable \cite{wojtekczerwinski}.

Our method solves the following open problem, 
which has appeared on Rajeev Alur's website in early 2013 \cite{alur2013}:

\begin{quote}
A Challenging Open Problem

Consider the following decision problem: given two regular languages  and  of nested
words, does there exist a regular language  of words over the tagged alphabet such that
Intersection(,) equals ? [...]\end{quote}

We say that  is a \emph{regular restriction} of 
iff the above holds.
Since disjoint languages  and  are separable iff  is a regular
restriction of , and separability is undecidable,
restriction-regularity is undecidable too.

Rajeev Alur's question is inspired by \cite{streaming-pods}, where
it is shown that, for a fully recursive DTD, it is decidable whether
there is a regular language  such that, for any valid XML document ,
it is decidable whether  is valid with respect to . This is a special case
of our result -- we take fully recursive DTDs instead of arbitrary finite automata
on trees, and we want to separate  from its complement. It is stated as an open
problem in \cite{streaming-pods} whether the problem is still decidable for arbitrary
finite automata on trees.

On the other hand, in \cite{regvis} it is shown that it is decidable whether,
for a given visibly push-down language , there exists a language  such that
, where  is the language of all well matched words.

{\bf Acknowledgements.} Thanks to Charles Paperman for introducing me to
the separability problem for VPDAs, and for helping me with the references.

\section{Preliminaries}

We remind the basic notions of automata theory;  see \cite{hu79}.

For an alphabet ,  denotes the set of words over , and
 denotes the empty word.

A \emph{deterministic finite automaton} (DFA) is a tuple ),
where  is the alphabet of ,  is the set fo states,  is the
initial state,  is the final state, and 
is the transition function. We extend  to 
in the following way: , .

A \emph{context free grammar} (CFG) is a tuple , where  is the
set of non-terminal symbols,  is the set of terminal symbols,  is a set
of \emph{productions} of form  where  is a non-terminal symbol
and and each  is either a terminal or non-terminal symbol, and  is
the start symbol. The language accepted by , , is the set of
words which can be obtained from the start symbol  by replacing non-terminal symbols
with words, according to the productions.

A \emph{binary flattened tree grammar} (BFG) over  is a context free grammar, whose
set of terminal symbols is , and every production is 
of form ,  or , where 
 are non-terminals, and  is a terminal.
A BFG corresponds to the XML encoding of a 
regular language of trees ( and  correspond to the opening 
\verb:<a>: and closing \verb:</a>: tag, respectively), and languages recognized by
flattened tree grammars are visibly pushdown languages. These two facts are routine
to check -- we omit this to avoid having
to state the definitions of VPDAs and TFAs; we have decided to use flattened tree
grammars in this paper since they are easier to define than both of these formalisms.

\begin{definition}
We say that two languages  and  are \emph{separable} if there is a 
regular language  such that for each , ,
but for each , .
\end{definition}

\begin{problem}[CFG-SEPARABILITY] \label{cflsep} {\ }

{\bf INPUT} Two context tree grammars  and  such that  and 
are disjoint

{\bf OUTPUT} Are  and  separable?
\end{problem}

The CFL separation problem is known to be undecidable \cite{hunt, szymanski}. For
convenience, we include the idea of the proof here. Encode configurations of a 
Turing machine  as words, and say that  iff a machine
in configuration  reaches the configuration  in next step. It can be
easily shown 
that (for simple encodings)
the languages  and 
are context free, and thus the languages  and  below are also context free.
They are separable iff  terminates from the initial configuration .


\begin{problem}[BFG-SEPARABILITY] \label{flattensep} {\ }

{\bf INPUT} Two BFGs  and  such that  and  are disjoint

{\bf OUTPUT} Are  and  separable?
\end{problem}

Our main result is the following:

\begin{theorem} \label{tflattensep}
The problem {\bf BFG-SEPARABILITY} is undecidable.
\end{theorem}

\section{Proof}

We will reduce {\bf CFG-SEPARABILITY} to {\bf BFG-SEPARABILITY}. To do this,
we will take two CFGs  and , and create two BFGs  and 
such that  and  are separable iff  and  are.

Without loss of generality, we can assume that grammars  do not accept the
empty word, or any word of length 1. We can also assume that these grammars
are in the \emph{Chomsky normal form}, that is, each production is of form
 or , where ,  and  are non-terminals,
and  is a terminal. It is well known that any context free grammar is effectively
equivalent to a grammar in Chomsky normal form \cite{hu79}.

Given a context free grammar 
in Chomsky normal form, we will construct a 
binary flattened
tree grammar , in the following way:

\begin{itemize}
\item For each , we have a non-terminal . We also
have one special non-terminal . The starting symbol of  is .

\item For each production  in , we have the corresponding production in :


\item For each production  in , we have the corresponding
bracketed production in :


\item For each , we also have the following productions for :


\item Where the productions for  are as follows:


\end{itemize}

Consider , the homomorphism which simply
removes the structural symbols  and . By applying
 to all the production rules for , we obtain a grammar  which
accepts exactly . It is straightforward to check that  is
in fact equivalent to  -- the only difference is that  is inserted in some
places, but all words generated by  reduce to the empty word after applying .
Therefore,  equals , which makes the following straightforward:

\begin{lemma}\label{easydir}
If  and  are separable, then so are  and .
\end{lemma}

\begin{proof}
 is a regular language
which separates  and  -- in other words, the automaton separating
these two languages works exactly as the one separating  and 
(it just ignores all the closing and structural symbols). \qed
\end{proof}

The rest of this section will prove the other direction:

\begin{theorem}\label{harddir}
If  and  are separable, then so are  and .
\end{theorem}

Assume that  and  are separable. Therefore, there is a finite automaton
 such that  accepts all words from , but no words from . We say
that two words  are {\it syntactically equivalent} with respect to 
iff for any words , we have  iff .
Syntactic equivalence is a congruence with respect to concatenation.

\begin{lemma}\label{semigroup}
There is a number  such that for any ,
 is syntactically equivalent to  with respect to .
\end{lemma}

\begin{proof}
The set  of all the equivalence classes
is a semigroup with concatenation as the operation. This semigroup is called the
\emph{syntactic semigroup} of A, and it is finite -- if for 
two words  and  we have  for each ,
then they are syntactically equivalent.
For any finite semigroup , there is a number  such that 
for any , we have  -- since 
yields an ultimately cyclic sequence with period at most , 
 will work. \qed
\end{proof}


We say that  is a \emph{padding} iff
there exist  such that,
for any ,
 is the word .

\begin{lemma}\label{translemma}
For a padding , 
the languages  and  are separable, iff  and  are.
\end{lemma}

\begin{proof}
The forward direction is straightforward, and proven just as Lemma \ref{easydir}
-- the automaton simply ignores all the symbols from  (in fact,
the stronger version of this lemma where  is also true).

For the backward direction, we take the DFA .
We can assume that there are no transitions to the initial state  in  --
otherwise, we create a copy of  and make it the new initial state.

We construct a new DFA  in the following way: take
, and  for .
For  we take the set of states  such that . 
The
automaton  working on  simulates the automaton  working
on , hence it accepts  iff  accepts . \qed
\end{proof}

\begin{lemma}\label{pumplemma}
There is a padding  with the following property:
for each , there is a word 
which is equivalent to  with respect to .
\end{lemma}

This proves Theorem \ref{harddir} and thus Theorem \ref{tflattensep}. Indeed,
we will show that  and  are separated by  -- then, after
applying Lemma \ref{translemma}, we get our claim.

Consider ; we have to show that  accepts  iff .
From Lemma \ref{pumplemma} we know that there is some  which
is equivalent to  with respect to . Therefore, 
we know that  iff
, and since ,  iff . \qed

\begin{proof}[of Lemma \ref{pumplemma}]

\def\ob{\heartsuit}
\def\cb{{\overbar{\heartsuit}}}
Let , . Thus, for any 
non-terminal , by applying one of productions (
\ref{gp_leftempty}, \ref{gp_rightempty} or \ref{gp_fork}) and then 
(\ref{gp_leaf}), we have  and 
. Also, let .

By applying the above many times to terminals  and , we get
 and , where:



Now, whenever we have a production  in , we can do the following in :


This can be written as , where:



We claim that the padding  given by the words , ,  defined above
satisfies our claim.

Indeed, take . Consider the derivation tree of  in ;
repeat this derivation in , replacing each production  with
 according to
the chain of productions (\ref{goodjob}) above, and each production  with 
(\ref{gp_terminal}).
In the end, for , we obtain the word , which
contains the symbols  separated with , possibly accompanied
by 's on the right side and 's on the left side, and with at least one
 before  and at least one  after . In other words,



where all ,  are integers, and .
Remembering that  is a left factor of  and thus , and similarly ,
it can be checked that the following equivalences hold:

\begin{itemize}
\item  is equivalent to :


\item  is equivalent to :


\item  is equivalent to :


\item  is equivalent to :

\end{itemize}

These rules allow us to reduce all  and  to zeros (except  and ,
which can be reduced to 1). Hence, the word  is equivalent to . \qed
\end{proof}

\section{Why binary trees?}

Our proof uses {\it binary} flattened tree grammars -- that is,
productions of form  are allowed only for 
or .

If we allowed such rules for any , a somewhat easier proof would work.
The general structure is the same, but
it is not required to have 's in the Chomsky normal form, 
and the grammar  allows inserting empty brackets with productions 
 before and after every symbol:
, and 
can be obtained by pumping each pair of   times, and then
using the rule  to make sure that  appears
 times between each two consecutive terminals.

While such a proof 
was sufficient to solve the problem for visibly pushdown languages, and for
XML encoding of trees, it left us with a craving for more, for the following
reasons.

First, if we consider languages of terms, it is natural to consider
different symbols for nodes with different arities (numbers of children) --
while the simpler proof above heavily uses the fact that the XML encoding cannot
tell whether  comes from the structurally significant rule ,
or it is a fake inserted by the  or  rules.
Since the arities here are respectively  1 and 2, this fails if
the automaton sees them.

Moreover, if we consider the process of flattening a tree as the result of an
automaton which traverses the tree recursively and react to what it is seeing on its path,
it is natural to assume that such an automaton sees the arity, and moreover, 
between returning from the -th child of  and progressing to the -th child,
the automaton should see that  of  children are progressed. This corresponds
to flattening rules of form .

Restricting ourselves to the binary case allows us to solve the problem in full
generality -- while the encoding in the definition of BFG does not explicitely 
say whether  comes from 
the ``empty leaf'' rule  or from one of the binary branching rules,
a finite automaton can easily tell which one is the case by looking at the neighborhood.
Also, while we do not write the infix structural symbols  explicitely,
the automaton can tell that it is at such a branching point iff the last symbol was ,
and the next one is .

In the binary case, a computer program was used to find the 
appropriate words  which work in Lemma \ref{pumplemma}.

\section{Conclusion}
We can also consider the separation problem for other classes of languages --
that is, is it decidable whether languages accepted by two BFGs are separable
by a language of class ? From the proof above, this problem is undecidable
for class , as long as the following conditions are satisfied:

\begin{itemize}
\item The respective problem for CFGs is undecidable.
\item The class  has the following pumping property: for any ,
there exists some  such that for any words , , ,
 iff . (This is Lemma 
\ref{semigroup}, and it is used in the proof of Lemma \ref{pumplemma}.)
\item If  is a homomorphism which ignores a subset of symbols, 
and , then . (Used in the proofs of Lemma 
\ref{easydir} and \ref{translemma}.)
\item If 
for some , and , then . (Used in the proof of \ref{translemma}.)
\end{itemize}

Hence, the separability problem is also undecidable for other classes of languages,
such as the class of languages recognizable by first-order logic.

\bibliographystyle{plain}
\bibliography{visibly}

\end{document}
