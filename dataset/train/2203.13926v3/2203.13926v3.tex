\begin{table*}[h!]
\small
\centering
\resizebox{0.8\textwidth}{!}{
\begin{tabular}{ll|cccccccc}
\toprule
& \textbf{Model} & \textbf{BLEU1} & \textbf{BLEU2} & \textbf{METEOR} & \textbf{ROUGE} & \textbf{CIDEr} & \textbf{Sem-Sim} \\
\midrule

\rotatetabularnormal{8}{almond}{(1.1.1)}{Cause}& 
\code{T5} & 0.2874  & 	 0.1493  &  	 0.1630  & 	 0.2626  & 	0.4560  & 	 0.6278  \\
  &  \code{BART} &  0.2542  & 	 0.1396  & 	 0.1527  & 	 0.2586  & 	 0.4241  & 	 	 0.6224 \\
 &  \code{COMET} & 0.2762 &	0.1518 &	0.1580 &	0.2652 &	0.4486 &	0.6253 \\
 & \code{GLUCOSE-T5} & \bf 0.2935 &	\bf 0.1563 &	\bf 0.1634 &	\bf 0.2707 &	\bf 0.4915 &	\bf 0.6305 \\
 &\code{T5}   &  0.0137 &	0.0042 & 0.0200 &	0.0266	& 0.0237 &	0.3735 \\
  &  \code{BART}   & 0.0793 &	0.0053 &	0.0347 &	0.0872 &	0.0153 &	0.3181  \\
 &  \code{COMET}   & 0.0562 &	0.0216 &	0.0474 &	0.0902 &	0.0862 &	0.4402\\
 & \code{GLUCOSE-T5}   & 0.0654 &	0.0287 &	0.0560 &	0.0827 &	0.1332 &	0.4442 \\
 \midrule

\rotatetabularnormal{8}{ghostwhite}{(1.1.2)}{SE}& 
\code{T5} &  \textbf{0.3083}  & 	 \textbf{0.1619}  & 	 \textbf{0.1662}  & 	 0.2760  & 	0.4119  & 		 0.6276 \\
  &  \code{BART} &  0.2926  & 	 0.1484  & 	 0.1608  & 	 0.2670  & 	 0.3681    & 	 0.6166 \\
 &  \code{COMET} & 0.3053 &	0.1565 & 0.1588 &	0.2730 &	0.3850 &	0.6211 \\
 & \code{GLUCOSE-T5} & 0.3000 &	0.1611 &	0.1628 &	\textbf{0.2778} &	\textbf{0.4430} &	\textbf{0.6297} \\
 &\code{T5}   &  0.0133 &	0.0045 &	0.0191 &	0.0264 &	0.0241 &	0.3865 \\
  &  \code{BART}   & 0.0823 &	0.0061 & 0.0345 &	0.0926 &	0.0140 &	0.3243  \\
 &  \code{COMET}   & 0.0567 &	0.0217 &	0.0472 &	0.0937 &	0.0884 &	0.4523 \\
 & \code{GLUCOSE-T5}   & 0.0003 &	0.0001 &	0.0070 &	0.0024 &	0.0032 &	0.3073\\
 
 \midrule

\rotatetabularnormal{8}{ghostwhite}{(1.1.3)}{SE Clipped}&
 \code{T5} &  0.2889  & 	 0.1448  & 	 \textbf{0.1549}  & 	 0.2618  & 	 0.3099  & 	\textbf{0.6123} \\
  &  \code{BART} &  0.2651  & 	 0.1272  & 	 0.1384  & 	 0.2409  & 	 0.2765  &  	 0.5814 \\
 &  \code{COMET} & \textbf{0.3023}  &	\textbf{0.1509}   &	0.1536  &	\textbf{0.2667}  &	0.3090  &	0.6083 \\
 & \code{GLUCOSE-T5}  & 0.2870  &	0.1461  &	0.1523  &	0.2645  &	\textbf{0.3238}  &	0.6094\\
 &\code{T5}   & 0.0559  &	0.0199  &	0.0439  &	0.0564  &	0.0762  &	0.4549  \\
  &  \code{BART}   & 0.0931  &	0.0067  &	0.0367  &	0.0869  &	0.0198  &	0.3541  \\
 &  \code{COMET}   & 0.0577  &	0.0215  &	0.0479  &	0.0953  &	0.0911  &	0.4583 \\
 & \code{GLUCOSE-T5}    & 0.0003  &	0.0001  &	0.0066  &	0.0025  &	0.0034  &	0.3063\\
 
 
\midrule

\rotatetabularnormal{8}{Green2}{(1.2.1)}{Prerequisite}& 
 \code{T5} & 0.1826  & 	 0.1002  & 	 0.1282  & 	0.2176  & 	 0.3357  &  	\textbf{ 0.5902} \\
  &  \code{BART} & 0.1817  & 	 0.1020  & 	 0.1260  & 	 0.2118  & 	\textbf{0.3401}  & 	 0.5804 \\
 &  \code{COMET} & \textbf{0.2115} &	\textbf{0.1145} &	0.1296 &	0.2168 &	0.3064 &	0.5815 \\
 & \code{GLUCOSE-T5} & 0.1812 &	0.1001 &	\textbf{0.1299} &	\textbf{0.2197} &	0.3144 &	0.5896 \\
 &\code{T5}   &  0.0177 &	0.0043 &	0.0222 &	0.0279 &	0.0225 &	0.3541 \\
  &  \code{BART}   & 0.0779 &	0.0065 &	0.0334 &	0.0827 &	0.0166 &	0.2913  \\
 &  \code{COMET}   & 0.0517 & 	0.0186 &	0.0447 &	0.0782 &	0.0768 &	0.4281\\
 & \code{GLUCOSE-T5}    &0.0259 &	0.0108 &	0.0394 &	0.0625 &	0.0889 &	0.4392\\

\midrule

\rotatetabularnormal{8}{Blue2}{(1.2.2)}{Motivation}&
  \code{T5} & 0.3462  & 	 0.2503  & 	 0.1998  & 	 0.3781  & 	 0.7109  & 		 0.6973 \\
  &  \code{BART} &  0.3497  & 	 0.2482  & 	 0.1961  & 	 0.3709  & 	 0.6434  &	 0.6914  \\
 &  \code{COMET} & 0.3428 &	0.2381 &	0.1935 &	0.3649 &	0.6286 &	0.6962 \\
 & \code{GLUCOSE-T5} & \textbf{0.3546} &	\textbf{0.2582} &	\textbf{0.2037} &	\textbf{0.3840} &	\textbf{0.7499} &	\textbf{0.7048} \\
 &\code{T5}   &  0.0134 &	0.0033 & 0.0183 &	0.0257 &	0.0181 &	0.4038 \\
  &  \code{BART}   & 0.1072 &	0.0082 &	0.0416 &	0.1212 &	0.0164 &	0.3497  \\
 &  \code{COMET}   & 0.0582 &	0.0215 &	0.0475 &	0.0882 &	0.0782 &	0.4516 \\
 & \code{GLUCOSE-T5}    & 0.0504 &	0.0174 &	0.0434 &	0.0632 &	0.0696 &	0.4053\\
 
 \midrule

\rotatetabularnormal{8}{Gray3}{(1.2.3)}{Reaction} &
  \code{T5} &  \textbf{0.3410}  & 	 \textbf{0.2397}  &  	 \textbf{0.1939}  & 	 \textbf{0.3720}  & 	 0.5177  & 	 \textbf{0.6665}  \\
  &  \code{BART} &  0.3320  & 	 0.2297  & 	 0.1869  & 	 0.3531  & 	 0.4575  &  	 0.6575  \\
 &  \code{COMET} & 0.3338 &	0.2273 &	0.1815 &	0.3406 &	0.2662 &	0.6520\\
 & \code{GLUCOSE-T5} & 0.3283 &	0.2318 &	0.1903 &	0.3716 &	\textbf{0.5364} &	0.6653\\
 &\code{T5}   &  0.0116 &	0.0037 &	0.0201 &	0.0239 &	0.0167 &	0.3899 \\
  &  \code{BART}   & 0.1815 &	0.0418 &	0.0913 &	0.1531 &	0.0194 &	0.5353  \\
 &  \code{COMET}   & 0.0590 &	0.0204 &	0.0454 &	0.0966 &	0.0653 &	0.4299\\
 & \code{GLUCOSE-T5}    & 0.0534 &	0.0213 &	0.0459 &	0.0759 &	0.0719 &	0.4125\\
 
\cmidrule{1-8}
\rotatetabularnormal{8}{brilliantlavender}{Average}{Score}&
 \code{T5} & 0.2924 & 0.1744 & \textbf{0.1677} & 0.2947 & 0.4570 & 0.6369 \\
 & \code{BART} & 0.2792 & 0.1658 & 0.1602 &  0.2837 & 0.4183  & 0.6249 \\
 & \code{COMET} & \textbf{0.2953} & 0.1732 & 0.1625 &  0.2879 & 0.3906  &   0.6307 \\
 & \code{GLUCOSE-T5} & 0.2908 & \textbf{0.1756} & 0.1671 & \textbf{0.2980} & \textbf{0.4765} & \textbf{0.6382} \\
 & \code{T5} & 0.0209 & 0.0066 & 0.0239 & 0.0312 & 0.0302 & 0.3938 \\
  & \code{BART} & 0.1036 & 0.0124 & 0.0454 &  0.1040 & 0.0169 & 0.3621 \\
  & \code{COMET} & 0.0575 & 0.0185 & 0.0445 &  0.0917 & 0.0641 & 0.4303 \\
 & \code{GLUCOSE-T5} & 0.0310 & 0.0130 & 0.0322 & 0.0491 & 0.0601 & 0.3886 \\


\bottomrule
\end{tabular}
}
\caption{Results for Task 1. \code{T5}, \code{BART}, \code{COMET} and \code{GLUCOSE-T5} are not fine-tuned on \dataset{}. \colorbox{ghostwhite}{SE} denotes Subsequent Event.}
\label{tab:results-sup}
\end{table*}

 \begin{table*}[t]
\centering
\resizebox{\linewidth}{!}{
\begin{tabular}{l|cccccc}
\toprule
\textbf{Model} & \textbf{BLEU1} & \textbf{BLEU2} & \textbf{METEOR} & \textbf{ROUGE} & \textbf{CIDEr} & \textbf{Sem-Sim} \\
\midrule
\colorbox{almond}{\textbf{(1.1.4) Chained Cause}} & & \\
\quad \quad \code{T5} & 0.2781  & 	 0.1566   & 	0.1675  & 	 0.2757  & 	 0.5303  & 	 0.6518 \\
  \quad \quad  \code{BART} &  0.1960  &	0.1104  &	0.1382  &	0.2242  &	0.4231  &	0.6074 \\
\quad \quad \code{COMET} &  \textbf{0.2893}  &	\textbf{0.1633}  &	0.1674  &	0.2742  &	0.5247  &	0.6488 \\
\quad \quad \code{GLUCOSE-T5}  & 0.2820  &	0.1600  &	\bf 0.1697  &	\bf 0.2796  &	\bf 0.5633  &	\bf 0.6557\\
\cmidrule{2-7}
\colorbox{almond}{\textbf{(1.1.1)* Cause}} & & \\
\quad \quad \code{T5} & 0.2884  & 	 0.1503   & 	 0.1635  & 	 0.2634  &  0.4591  & 0.6284  \\
  \quad \quad  \code{BART} &  0.2548  &	0.1400   &	0.1530  &	0.2590  &	0.4279  &	0.6225 \\
\quad \quad \code{COMET} &  0.2769  &	0.1522  &	0.1584  &	0.2654  &	0.4510  &	0.6257 \\
\quad \quad \code{GLUCOSE-T5}  & \bf 0.2938  &	\bf 0.1564  &	\bf 0.1636  &	\bf 0.2709  &	\bf 0.4915  &	\bf 0.6310\\
\midrule
\colorbox{ghostwhite}{\textbf{(1.1.5) Chained SE}} & & \\
\quad \quad \code{T5} & \textbf{0.3322}  & 	 \textbf{0.1813}   & 	 \textbf{0.1784}  & 	 0.2940  & 	 0.5136  & 	 0.6469 \\
  \quad \quad  \code{BART} &  0.3131  &	0.1649   &	0.1672  &	0.2795  &	0.4106  &	0.6314 \\
\quad \quad \code{COMET} &  0.3057  &	0.1626  &	0.1673  &	0.2742  &	0.4515  &	0.6321 \\
\quad \quad \code{GLUCOSE-T5}  & 0.3258  &	0.1789  &	0.1776  &	\bf 0.2943  &	\bf 0.5218  &	\bf 0.6516\\
\cmidrule{2-7}
\colorbox{ghostwhite}{\textbf{(1.1.2)* SE}} & & \\
\quad \quad \code{T5} & \bf 0.3088  & 	 \bf 0.1622  & 	 0.0841   & 	 0.2764  & 	 0.4167  & 0.6279  \\
  \quad \quad  \code{BART} & 0.2919  &	0.1490  & 0.1617  &	0.2667  &	0.3719  &	0.6165  \\
\quad \quad \code{COMET} &  0.3036  &	0.1557  &	0.1580  &	0.2727  &	0.3790&	0.6187 \\
\quad \quad \code{GLUCOSE-T5}  & 0.2998  &	0.1612  &	\bf 0.1628  &	\bf 0.2778  &	\bf 0.4471  &	\bf 0.6294\\
\bottomrule
\end{tabular}
}
\caption{Results for chained cause effect generation. (1.1.1)* and (1.1.2)* indicates results from Task 1.1.1, and 1.1.2 (as in \cref{tab:results-sup}), but only for target instances which have both cause and effect annotated, ensuring a fair comparison with (1.2). \colorbox{ghostwhite}{SE} denotes Subsequent Event.}
\label{tab:cqa-sup}
\end{table*} 
\begin{table}[h!]
\centering
\resizebox{\linewidth}{!}{
\begin{tabular}{l|ccc}
\toprule
\textbf{Model}  & \textbf{Creativity} & \textbf{Contextuality}  & \textbf{Fluency} \\
\midrule
Gold & 4.7 & 4.8 & 5.0 \\
\midrule
\code{T5} & 3.8 & 4.1 & \bf 4.9 \\
\code{BART} & 3.6 & \bf 4.3 & \bf 4.9 \\
\code{COMET} & 3.8 & 4.1 & 4.8 \\
\code{GLUCOSE-T5} & \bf 3.9 & \bf 4.3 & \bf 4.9 \\
\code{T5}  & 2.4 & 2.1 & 1.9 \\
\code{BART}  & 2.6 & 2.5 & 1.8 \\
\code{COMET}  & 2.2 & 2.3 & 2.5 \\
\code{GLUCOSE-T5}  & 1.9 & 2.1 & 2.9 \\
\bottomrule
\end{tabular}}
\caption{Results of the human evaluation for the \dataset{} task. \code{T5}, \code{BART}, \code{COMET}, and \code{GLUCOSE-T5} represent non fine-tuned versions.}
\label{tab:human-eval-sup}
\end{table}

\begin{table*}[ht!]
  \centering
  \begin{subtable}{\textwidth}
  \centering
  \resizebox{\textwidth}{!}{
    \begin{tabular}{p{16cm}}
    \toprule
    \textbf{A \pmb {()}}: Hi, Jenny. Is it true you're moving to London?
    \textbf{B \pmb {()}}: Yes, it is.
    \textbf{A \pmb {()}}: What made you decide to do that?
    \textbf{B \pmb {()}}: Work, mainly. I'm sure I'll be able to find a job there.
    \textbf{A \pmb {()}}: You're probably right. But where are you going to live?
    \textbf{B \pmb {()}}: I hope I'll find a flat to share with somebody. That way it will be cheaper.
    \textbf{A \pmb {()}}: Yes, that's a good idea. Are you taking your dog with you?
    \textbf{B \pmb {()}}:  No, I don't think so. My parents have offered to take care of him, and I don't think he'd be happy in the city.
    \textbf{A \pmb {()}}: You're probably right. But aren't you afraid of moving to such a big place, especially after living in a small village?
    \textbf{B \pmb {()}}: Not really. I think I'll enjoy myself. There's so much to do there; I expect I won't miss the countryside much and I can always come back and visit. 
    \textbf{A \pmb {()}}: Well, I just hope you'll invite me to stay when you get settled.
    \textbf{B \pmb {()}}:  Of course I will.
    \\
    \end{tabular}
    }
\end{subtable}
\bigskip
\begin{subtable}{\textwidth}
\centering
\resizebox{\textwidth}{!}{
  \begin{tabular}{p{16cm}}
      \toprule
      \textbf{Target -} \pmb{}; \textbf{Inference:} \colorbox{almond}{\bf Cause}; \textbf{Answers:} \colorbox{gold}{\textbf{Gold}} - Being an expensive city, it is quite difficult to find an affordable place to live in London. \colorbox{Blue4}{\textbf{T5}} - The listener asked Jenny where she was going to live. \colorbox{brilliantlavender}{\textbf{COMET}} - The speaker is looking for a flat to live in London. \colorbox{aqua}{\textbf{GLUCOSE-T5}-} Jenny has decided to move to London for her job. \\
      
      \midrule
      \textbf{Target -} \pmb{}; \textbf{Inference:} \colorbox{almond}{\bf Cause}; \textbf{Answers:} \colorbox{gold}{\textbf{Gold}}  - Jenny realizes that a city like London will provide a great quality of life for her. \colorbox{Blue4}{\textbf{T5}} - The listener asked Jenny if she was afraid of moving to London after living in a small village. \colorbox{brilliantlavender}{\textbf{COMET}} - The speaker is moving to London for a job.
      \colorbox{aqua}{\textbf{GLUCOSE-T5}-} The listener asked Jenny if she was afraid of moving to such a big place. \\
      
      \midrule
      \textbf{Target -} \pmb{}; \textbf{Inference:} \colorbox{ghostwhite}{\bf Subsequent Event}; \textbf{Answers:} \colorbox{gold}{\textbf{Gold}} - The listener suggests Jenny to find potential flats or flatmates online. \colorbox{Blue4}{\textbf{T5}} - The speaker will find a flat to share with a friend. \colorbox{brilliantlavender}{\textbf{COMET}} - The speaker informed the listener that she will share the flat with someone else. \colorbox{aqua}{\textbf{GLUCOSE-T5}-} Jenny will find a flat to share with her friend. \\
      
      \midrule
      \textbf{Target -} \pmb{}; \textbf{Inference:} \colorbox{ghostwhite}{\bf Subsequent Event}; \textbf{Answers:} \colorbox{gold}{\textbf{Gold}} - Jenny inquired a social club in London and ask for their membership to utilize her free time. \colorbox{Blue4}{\textbf{T5}} - The speaker told the listener that he would love to visit London. \colorbox{brilliantlavender}{\textbf{COMET}} - The speaker informed the listener that he will miss the countryside very much. \colorbox{aqua}{\textbf{GLUCOSE-T5}-} The speaker informed the listener that he would love to come back to London. \\
      
      \midrule
      \textbf{Target -} \pmb{}; \textbf{Inference:} \colorbox{Green2}{\bf Prerequisite}; \textbf{Answers:} \colorbox{gold}{\textbf{Gold}} - Jenny has completed her studies. \colorbox{Blue4}{\textbf{T5}} - The speaker has a job in London. \colorbox{brilliantlavender}{\textbf{COMET}} - Jenny has applied for a job in London. \colorbox{aqua}{\textbf{GLUCOSE-T5}-} The speaker has a job in London. \\
      \midrule
      \textbf{Target -} \pmb{}; \textbf{Inference:} \colorbox{Green2}{\bf Prerequisite}; \textbf{Answers:} \colorbox{gold}{\textbf{Gold}} - Jenny and the listener are good friends. \colorbox{Blue4}{\textbf{T5}} - Jenny has invited her friend to stay with her in London. \colorbox{brilliantlavender}{\textbf{COMET}} - Jenny has a place to stay in London. \colorbox{aqua}{\textbf{GLUCOSE-T5}-}The listener invited Jenny to stay in London. \\
      
      \midrule
      \textbf{Target -} \pmb{}; \textbf{Inference:} \colorbox{Blue2}{\bf Motivation}; \textbf{Answers:} \colorbox{gold}{\textbf{Gold}} - Jenny is optimistic about having someone as her flatmate to save on rent. \colorbox{Blue4}{\textbf{T5}} - Jenny is hopeful of finding a flat to share with someone. \colorbox{brilliantlavender}{\textbf{COMET}} -  Jenny is optimistic about having someone as her flatmate. \colorbox{aqua}{\textbf{GLUCOSE-T5}-} Jenny is hopeful that she will find a flat to share with somebody. \\
      
      \midrule
      \textbf{Target -} \pmb{}; \textbf{Inference:} \colorbox{Gray3}{\bf Reaction}; \textbf{Answers:} \colorbox{gold}{\textbf{Gold}} - The listener is happy for Jenny and looks forward to being invited to London by Jenny. \colorbox{Blue4}{\textbf{T5}} - The listener is happy for Jenny. \colorbox{brilliantlavender}{\textbf{COMET}} - The listener is happy to know that the speaker is moving to London. \colorbox{aqua}{\textbf{GLUCOSE-T5}-} The listener is excited to meet Jenny in London. \\
      \bottomrule
  \end{tabular}
  }
\end{subtable}
\caption{Inferences extracted from a sample dialogue.}
\label{tab:examples-sup}
\end{table*} \begin{table*}[t]
\small
\centering
\resizebox{0.96\linewidth}{!}{
\begin{tabular}{l|c|c|cccccc}
\toprule
\bf Model & \bf \begin{tabular}[c]{@{}c@{}}Trained\\ On\end{tabular} & \bf \begin{tabular}[c]{@{}c@{}}Evaluated\\ On\end{tabular}  & \bf Cause & \bf SE & \bf Prereq. & \bf Motiv. & \bf Emo. Reac. & \bf Avg. \\
\midrule
\code{RoBERTa} & Single & Single & 83.34 & 83.17 & 79.48 & 86.33 & 84.26 & 83.28  \\
\code{ELECTRA} & Single & Single &  \bf 87.09  & \bf 86.09 &  \bf 85.15 & \bf 90.31 & \bf 86.11 & \bf 86.82 \\
\midrule
\code{T5} & Single & Single & 95.19 & \bf 95.29 & 94.93 & \bf 96.52 & 96.99 & 95.54 \\
\code{Unified QA} & Single  & Single  & \bf 95.85 & 94.99 & \bf 95.55  & 96.35 & \bf 97.22 & \bf 95.70\\
\midrule
\code{T5} & Multiple & Multiple & 20.04  & 20.45 & 15.94 & 25.26 & 26.72 & 20.62 \\
\code{Unified QA} & Multiple  & Multiple  & \bf 25.68 & \bf 21.64 & \bf 21.51 & \bf 30.93 & \bf 31.03 & \bf 24.33 \\
\midrule
\code{T5} & Single \& Multiple & Single \& Multiple &  \bf 78.18 & 74.72 & \bf 75.50 & \bf 82.51 & \bf 84.59 & \bf 77.68 \\
\code{Unified QA} & Single \& Multiple  & Single \& Multiple  & 78.12 & \bf 74.79 & 75.36 & 81.58 & 84.08 & 77.51\\
\midrule
\code{T5} & Single \& Multiple & Single &  \bf 93.20 & \bf 91.28 & \bf 91.27 & \bf 95.19 & \bf 95.14 & \bf 92.71 \\
\code{Unified QA} & Single \& Multiple  & Single  & 93.12 & 91.16 & 91.00 & 94.28 & 94.79 & 92.45 \\
\midrule
\code{T5} & Single \& Multiple & Multiple & \bf 3.50 & 2.77 & 3.59 & \bf 3.61 & \bf 6.03 & 3.38 \\
\code{Unified QA} & Single \& Multiple  & Multiple  & \bf \bf 3.50 & \bf 3.69 & \bf 3.98 & 2.58 & 4.31 & \bf 3.60 \\
\bottomrule
\end{tabular}
}
\caption{Results of the \dataset{} task. SE denotes subsequent event. Single  Instances with single answer. Multiple  Instances with multiple answers.}
\label{tab:appendix-alt}
\end{table*}


\begin{table*}[t]
\small
\centering
\resizebox{0.96\textwidth}{!}{
\begin{tabular}{l|c|c|cccccc}
\toprule
\bf Model & \bf \begin{tabular}[c]{@{}c@{}}Trained\\ On\end{tabular} & \bf \begin{tabular}[c]{@{}c@{}}Evaluated\\ On\end{tabular}  & \bf Cause & \bf SE & \bf Prereq. & \bf Motiv. & \bf Emo. Reac. & \bf Avg. \\
\midrule
\code{RoBERTa} & Single & Single & - & 78.31 & - & 80.94 & - & 79.02  \\
\code{ELECTRA} & Single & Single & - & \bf 82.02 & - & \bf 87.41 & - & \bf 83.46 \\
\midrule
\code{T5} & Single & Single & - & 94.23 & - & 95.61 & - & 94.60 \\
\code{Unified QA} & Single  & Single  &  - & \bf 94.38 &  - &  \bf 96.19 & - & \bf 94.87 \\
\midrule
\code{T5} & Multiple & Multiple & - & 16.49 & - & 24.23 & - & 18.07 \\
\code{Unified QA} & Multiple  & Multiple  & - & \bf 19.79 & - & \bf 24.74 & - & \bf 20.80\\
\midrule
\code{T5} & Single \& Multiple & Single \& Multiple & - & \bf 74.99 & - & 80.73 & -  & \bf 76.46 \\
\code{Unified QA} & Single \& Multiple  & Single \& Multiple  & - & 74.67 & - & \bf 80.80 & - & 76.24 \\
\midrule
\code{T5} & Single \& Multiple & Single & - & \bf 91.95 & - & 93.29 & -  & \bf 92.31 \\
\code{Unified QA} & Single \& Multiple  & Single  & - & 91.43 & - & \bf 93.37 & - & 91.95 \\
\midrule
\code{T5} & Single \& Multiple & Multiple & - & 1.32 & - & \bf 2.58 & -  & 1.58 \\
\code{Unified QA} & Single \& Multiple  & Multiple  & - & \bf 1.85 & - & \bf 2.58 & - & \bf 2.00 \\
\bottomrule
\end{tabular}
}
\caption{Results of the \dataset{} task under the zero-shot setting. SE denotes subsequent event. Instance corresponding to cause, prerequisite, and emotional reaction are used for training. Instance corresponding to subsequent event and motivation are used for evaluation. Single  Instances with single answer. Multiple  Instances with multiple answers.}
\label{tab:appendix-alt2}
\end{table*} 
\begin{figure}[t]
    \centering
        \includegraphics[width=\linewidth]{fig/MCQ-cider2-new2.pdf}
        \caption{A data sample of \dataset{} for the \dataset{} task. Here, commonsense is required to infer the following events -- booking a table at night implies the intention of having dinner.}
        \label{fig:mcq2}
\end{figure}

\begin{figure}[!ht]
\begin{subfigure}[t]{\linewidth}
    \centering
        \includegraphics[width=\linewidth]{fig/MCQ-cider2-new15.pdf}
        \caption{}
        \label{fig:mcq15}
\end{subfigure}
\begin{subfigure}[t]{\linewidth}
    \centering
        \includegraphics[width=\linewidth]{fig/MCQ-cider2-new16.pdf}
        \caption{}
        \label{fig:mcq16}
\end{subfigure}
\caption{Instances of \texttt{temporal commonsense} in \dataset{}.}
\label{fig:temporal-csk-sup}
\end{figure}

\begin{figure}[t]
    \centering
        \includegraphics[width=\linewidth]{fig/MCQ-cider2-new3.pdf}
        \caption{A data sample of \dataset{} where physical commonsense inference is prevalent.}
        \label{fig:mcq3}
\end{figure}

\begin{figure*}[ht]
    \centering
    
\begin{subfigure}[t]{.49\textwidth}
        \includegraphics[width=\linewidth]{fig/MCQ-cider2-new5.pdf}
        \caption{}
        \label{fig:mcq5}
\end{subfigure}~
\begin{subfigure}[t]{.49\textwidth}
        \includegraphics[width=\linewidth]{fig/MCQ-cider2-new6.pdf}
        \caption{}
        \label{fig:mcq6}
\end{subfigure}

\begin{subfigure}[t]{.49\textwidth}
        \includegraphics[width=\linewidth]{fig/MCQ-cider2-new8.pdf}
        \caption{}
        \label{fig:mcq8}
\end{subfigure}~
\begin{subfigure}[t]{.49\textwidth}
        \includegraphics[width=\linewidth]{fig/MCQ-cider2-new9.pdf}
        \caption{}
        \label{fig:mcq9}
\end{subfigure}
\caption{Instances of \texttt{general commonsense} in \dataset{}.}
\label{fig:general_csk_sup}
\end{figure*}

\begin{figure}[ht]
        \includegraphics[width=\linewidth]{fig/MCQ-cider2-new10.pdf}
        \caption{An instance where \code{RoBERTa} fails to capture the contextual commonsense cue.}
        \label{fig:mcq10}
\end{figure}
\begin{figure}[t]
\begin{subfigure}[t]{\linewidth}
    \centering
        \includegraphics[width=\linewidth]{fig/MCQ-cider2-new4.pdf}
        \caption{}
        \label{fig:mcq4}
\end{subfigure}

\begin{subfigure}[t]{\linewidth}
    \centering
        \includegraphics[width=\linewidth]{fig/MCQ-cider2-new7.pdf}
        \caption{}
        \label{fig:mcq7}
\end{subfigure}
\caption{Instances of \texttt{social commonsense} in \dataset{}.}
\label{fig:social_csk_sup}
\end{figure}

\begin{figure}[ht]
\begin{subfigure}[t]{\linewidth}
    \centering
        \includegraphics[width=\linewidth]{fig/MCQ-cider2-new13.pdf}
        \caption{}
        \label{fig:mcq13}
\end{subfigure}
\begin{subfigure}[t]{\linewidth}
    \centering
        \includegraphics[width=\linewidth]{fig/MCQ-cider2-new14.pdf}
        \caption{}
        \label{fig:mcq14}
\end{subfigure}
\caption{Multiple-answer predictions by \code{T5} for the \dataset{} task.}
\end{figure}

\begin{figure}[ht]
\begin{subfigure}[t]{\linewidth}
    \centering
        \includegraphics[width=\linewidth]{fig/MCQ-cider2-new11.pdf}
        \label{fig:mcq11}
\end{subfigure}
\begin{subfigure}[t]{\linewidth}
    \centering
        \includegraphics[width=\linewidth]{fig/MCQ-cider2-new12.pdf}
        \label{fig:mcq12}
\end{subfigure}
\caption{Examples of some incorrect predictions by \code{RoBERTa} for the \dataset{} task.}
\label{fig:mcq11-12}
\end{figure}

\section{Additional Details on \dataset{}}
The total compensation for the complete annotation process of \dataset{} including all the manual labeling (\cref{sec:dataset}), and verification stages in AF (\cref{sec:altsc}) was USD . The annotators were hired through a data annotation company. The total compensation was derived based on the country of residence of the annotators, as deemed by the company.

Being a dialogue-centric dataset, \dataset{} encompasses various aspects of human to human conversations such as temporal commonsense awareness in \cref{fig:mcq2}, \cref{fig:temporal-csk-sup}, physical commonsense in \cref{fig:mcq3}, general commonsense in \cref{fig:general_csk_sup}, and social commonsense in \cref{fig:social_csk_sup}.  In \cref{fig:mcq15}, commonsense is required to infer that a familiar face may look different to us if we meet that person after a long time. There could be other potential reasons why a person might look different to his/her friends such as facial surgery, sickness, makeup, etc. However, in this particular dialogue context, the most appropriate speculative cause of the target is meeting the person after a long time. Similarly in \cref{fig:mcq16}, the person hurries to the boarding gate as only 20 minutes is left before the flight takes off. Leveraging commonsense inference, we can infer that going to a place in a very short period requires us to rush.  In \cref{fig:mcq3}, \texttt{physical commonsense knowledge} is required to infer --- touching a hot element can burn our fingers and pans or microwaves are used for cooking.

\section{\dataset{} Task: Extended Results}
\label{sec:appendix-ex}
We report BLEU1 scores~\cite{papineni2002bleu} in addition to the automatic evaluation metrics described in \Cref{sec:results}. We also report results for generative tasks with the \code{BART-large} ~\cite{lewis2019bart}, and \code{COMET}~\cite{Hwang2021COMETATOMIC2O} model. \code{COMET} is a commonsense generation model from free text input. It is a pre-trained \code{BART-large} model fine-tuned on the ATOMIC dataset~\cite{Hwang2021COMETATOMIC2O}. In our work, we have used all the models in two distinct ways -- i) with fine-tuning and ii) without fine-tuning on \dataset{}. The results are shown in \cref{tab:results-sup}, and \cref{tab:cqa-sup}. Surprisingly, despite being pre-trained on a large commonsense inference dataset, the fine-tuned \code{COMET} model fails to outperform both fine-tuned \code{T5} and \code{BART} in most of the experiments. This could be due to catastrophic forgetting triggered by disparate inputs, which are at odds with ATOMIC. Further research is needed to draw any conclusion.

The results of human evaluation of the models are illustrated in \cref{tab:human-eval-sup}. It can be seen that all the models perform almost similarly on \dataset{} and stand far from reaching human-level performance.

\paragraph{Fine-tuned vs non Fine-tuned Evaluations.}
All the models perform very poorly when they are not fine-tuned on \dataset{}.
The non fine-tuned models generate gibberish sentences across all five inference categories. The automatic and human evaluation results of these models are also reported in \cref{tab:results-sup} and \cref{tab:human-eval-sup}, respectively. 
The results confirm that fine-tuning is necessary for dialogue-level commonsense inference thus reaffirming the importance of our curated dataset \dataset{}. The non fine-tuned \code{COMET} produces very short outputs (1--3 words, akin to ATOMIC annotations) that are not readily comparable with \dataset{}, resulting in poor evaluation scores.

Finally, we provide some additional examples to depict the inference generation quality of the models in \cref{tab:examples-sup}.

\section{\dataset{}: Extended Results, Quantitative and Qualitative Analysis}
\label{sec:appendix-alt}
For answer selection with generative models in \dataset{}, we train \code{T5} and \code{Unified QA} models under three distinct settings: 1) \textbf{Setting 1:} train models only on instances with a single-answer, 2) \textbf{Setting 2:} train models only on instances with multiple-answers, 3) \textbf{Setting 3:} train models on the entire dataset comprising both single and multiple-answers. 

The performances of both the generative models \code{T5} and \code{Unified QA} on instances with multiple answers are very poor (see \cref{tab:appendix-alt}, \cref{tab:appendix-alt2} and \cref{fig:mcq13}, \cref{fig:mcq14}). Further, we can also see instances where the predicted answers by these models contradict (see \cref{fig:mcq14}). While \code{T5} surpasses \code{Unified QA} for Setting 3, \code{Unified QA} shines over \code{T5} for the other two settings. 

\paragraph{Performance of \code{ELECTRA} vs \code{RoBERTa}.}
We also extend upon the results reported earlier for \code{ELECTRA} and \code{RoBERTa} in \Cref{sec:results-mcq} for the single answer selection (Task 2.1) in \dataset{}. The performance of \code{ELECTRA} is notably better than \code{RoBERTa} on this task. We reckon this could be due to the fact that we train our adversarial filtering (AF) method using \texttt{RoBERTa}. As such the efficacy of AF to prevent exposing stylistic artifacts to the discriminators is lesser for ELECTRA compared to RoBERTa. In other words, \code{ELECTRA} is more efficient than \code{RoBERTa} for the \dataset{} task due to its ability to better discriminate machine-generated negative answers from human-annotated true answers by leveraging stylistic artifacts as observed in \citet{zellers2018swag}.

Despite performing decently on the single answer selection task for \dataset{}, \code{RoBERTa} does make mistakes in understanding some very interesting commonsense-based inferences such as the ones illustrated in \cref{fig:mcq11-12}. In these two examples, commonsense inference is required to detect the bluff by Tim Smith. Among other kinds of errors, we find \code{RoBERTa} failing to capture contextual commonsense cues such as in \cref{fig:mcq10} --- if a person wanting to buy new batteries is informed about the availability of batteries at photocopy stores, that person will search for photocopy stores instead of ad stores. 

\paragraph{Zero-shot Setting.} We also set up a zero-shot setting for Task 2.1 -- Single Answer Selection and Task 2.2 -- All Answers Selection. Under this setting, we only keep instances pertaining to cause, prerequisite, and emotional reaction in the train, validation data while instances with subsequent event, and motivation are kept in the test data. All the models underperform in the zero-shot setting, as can be seen in \cref{tab:appendix-alt2}. Like the all and single answer(s) prediction, \code{T5} and \code{Unified QA} perform similarly. On the other hand, \code{ELECTRA}'s zero-shot performance surpasses that of \code{RoBERTa}. Notably, performance of \code{T5} and \code{Unified QA} only drop around 1\% in this setting, as compared to 3\% drop observed for \code{RoBERTa} and \code{ELECTRA}. Hence, it is fair to conclude that for the \dataset{} task, \code{T5} and \code{Unified QA} are more robust to zero-shot scenarios than \code{RoBERTa} and \code{ELECTRA}. In the case of zero-shot single answer prediction, the best model is \code{Unified QA} which outperforms \code{RoBERTa} and \code{ELECTRA} by 11\% and 15\% respectively. 

\paragraph{Performance on Single- vs Multi-answer Instances.} It is evident from \cref{tab:appendix-alt,tab:appendix-alt2}, that in both regular and zero-shot settings, all the models exclusively trained on single- and multi-answer instances perform better on single- and multi-answer test instances, respectively, as compared to models trained on both types of instances. This is likely a side-effect of the data imbalance between the single- and multi-answer instances (86/14\%) in the training set which causes the scarce multi-answer instances to have confounding effect on the training process, degrading the performance on both types of test instances.

\paragraph{Performance of \dataset{} vs \dataset{}.}
We present the qualitative analysis for generative (\dataset{}) and discriminative (\dataset{}) experiments in \cref{fig:mcq5}, \cref{fig:mcq6}, \cref{fig:mcq8}, \cref{fig:mcq9}, \cref{fig:mcq10}, \cref{fig:mcq4}, and \cref{fig:mcq7}. Except for \cref{fig:mcq10}, \code{RoBERTa} provides the accurate answer on all instances. Contrary to this, the performance of \code{T5} is far from being sublime on those samples for the \dataset{} task. This depicts that the commonsense-based generative task \dataset{} poses more challenge than the commonsense-based discriminative task \dataset{}. We surmise this could happen due to two potential reasons --- 
\begin{enumerate}
    \item Machine-generated negative answers may carry stylistic biases~\cite{zellers2018swag}, thus making the task of discriminators easier.
    \item We collate the negative answers by generating counterfactual and contradictory sentences from the annotated true inferences. As a result, the generated negative answers are lexically very similar to the annotated sentences resulting in less diversity in the dataset. 
\end{enumerate}

\begin{table}[h!]
\centering
\small
\resizebox{0.9\linewidth}{!}{
\begin{tabular}{l|r}
\toprule
\textbf{Dataset}  & \textbf{RoBERTa-Large} \\
\midrule
Swag & 89.92 \\
HellaSwag &  85.20 \\
-NLI & 83.91 \\
Cosmos QA & 82.25 \\
Physical IQA & 79.40 \\
Social IQA & 77.12 \\
\midrule
\dataset{} & 83.28 \\
\bottomrule
\end{tabular}
}
\caption{Results of baseline models in other CSK datasets. Note: This result on \dataset{} using \code{RoBERTa-large} is obtained for only instances with single answer. }
\label{tab:other-csk-sup}
\end{table} 
\section{\dataset{} vs Other Commonsense Datasets}
The key differences that set \dataset{} apart from the rest of the commonsense datasets are following:

\begin{itemize}
    \item To the best of our knowledge, \dataset{} is the only publicly available dialogue-centric commonsense inference dataset.
    \item The speculative nature of the questions posed to the annotators enforces employment of rich commonsense knowledge in the inferences, thereby, making \dataset{} commonsense-rich and, thus, difficult inferences for models without relevant commonsense knowledge.
    \item While the performance of the strong baseline models on \dataset{} for \dataset{} task are comparable (see \cref{tab:other-csk-sup}) with the performance on other available commonsense-based question-answering datasets, unlike the others, around 14\% of the instances in \dataset{} contain multiple correct inferences/answers. These are more challenging to the baselines, as can be seen in \cref{tab:appendix-alt}.
    \item Dialogue-centric commonsense inference/answer generation task, i.e., \dataset{} is novel and hard to solve. Strong baselines, such as, T5, BART, and their checkpoints pre-trained on large external commonsense datasets, such as, ATOMIC and GLUCOSE, perform poorly at this task.
\end{itemize}

\section{Hyperparameter Details}
All models for the \dataset{} generative tasks were trained with the Adafactor optimizer~\cite{shazeer2018adafactor} with a learning rate of 5e-6. The models  \dataset{} alternative selection were trained with the AdamW~\cite{loshchilov2018decoupled} optimizer with a learning rate of 1e-5. We used a batch size of 4 for all our experiments.

\section{Computational Resources}
The T5 Large and \code{GLUCOSE-T5} Large have 770M parameters each. The \code{RoBERTa-Large} and \code{ELECTRA-Large} have 355M and 335M parameters, respectively. We also use a \code{BART-Large} and \code{COMET-Large} models for more extensive experiments (\Cref{sec:appendix-ex}). Both the models have 406M parameters. We use a single RTX 8000 GPU for our experiments. All models were trained for 5 epochs. Training and inference for the generative tasks i.e., \dataset{} require between 1.5-6 hours in this GPU. Training and inference for the alternative selection task i.e., \dataset{} require a total of 15 hours. Training and inference times are 40\% less for zero-shot setting experiments. 