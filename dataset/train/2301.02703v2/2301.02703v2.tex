\documentclass{article}


\usepackage{PRIMEarxiv}

\usepackage[utf8]{inputenc} \usepackage[T1]{fontenc}    \usepackage{hyperref}       \usepackage{url}            \usepackage{booktabs}       \usepackage{amsfonts}       \usepackage{nicefrac}       \usepackage{microtype}      \usepackage{lipsum}
\usepackage{fancyhdr}       \usepackage{graphicx}       \graphicspath{{media/}}     

\pagestyle{fancy}
\thispagestyle{empty}
\rhead{ \textit{ }} 

\fancyhead[LO]{Residual upsampling network for real-time polyp segmentation}




  
\title{RUPNet: Residual upsampling network for real-time polyp segmentation
\thanks{\textit{\underline{Citation}}: 
\textbf{Authors. Title. Pages.... DOI:000000/11111.}} 
}

\author{
 Nikhil Kumar Tomar\\
 Machine and Hybrid Intelligence Lab,\\ Department of Radiology,\\ Northwestern University, \\Chicago \\
  USA\\
  \texttt{\{nikhilroxtomar\}@gmail.com} \\
\And
  Ulas Bagci \\
  Machine and Hybrid Intelligence Lab,\\ Department of Radiology,\\ Northwestern University, \\Chicago \\
  USA\\
  \texttt{\{ulas.bagci\}@northwestern.edu} \\
     \And
Debesh Jha \\
  Machine and Hybrid Intelligence Lab,\\ Department of Radiology,\\ Northwestern University, \\Chicago \\
  USA\\
  \texttt{\{debesh.jha\}@northwestern.edu} \\
}


\begin{document}
\maketitle


\begin{abstract}
Colorectal cancer is among the most prevalent cause of cancer-related mortality worldwide. Detection and removal of polyps at an early stage can help reduce mortality and even help in spreading over adjacent organs. Early polyp detection could save the lives of millions of patients over the world as well as reduce the clinical burden. However, the detection polyp rate varies significantly among endoscopists. There is numerous deep learning-based method proposed, however, most of the studies improve accuracy. Here, we propose a novel architecture,  Residual Upsampling Network (RUPNet) for colon polyp segmentation that can process in real-time and show high recall and precision. The proposed architecture, RUPNet, is an encoder-decoder network that consists of three encoders, three decoder blocks, and some additional upsampling blocks at the end of the network. With an image size of , the proposed method achieves an excellent real-time operation speed of 152.60 frames per second with an average dice coefficient of 0.7658,  mean intersection of union of 0.6553, sensitivity of 0.8049, precision of 0.7995, and accuracy of 0.9361. The results suggest that RUPNet can give real-time feedback while retaining high accuracy indicating a good benchmark for early polyp detection.
\end{abstract}


\keywords{Deep learning \and Convolutional neural network \and Medical image segmentation \and Colon polyps\\ \and Colorectal cancer  \and Computer aided diagnosis \and Polyp segmentation \and Residual network}


\section{Introduction}
Colonoscopy is considered the gold standard and is recommended screening tool for colon cancer diagnosis and follow-up. Early detection and removal of adenomas is crucial in colonoscopy for removing incidence and mortality. A 1\% increase in adenoma detection rate showed associated with a 3\% decrease in interval colorectal cancer incidence~\cite{urban2018deep}. Still, the adenoma miss rate is around 6-27\%~\cite{ahn2012miss}. Therefore, an endoscopist is expected to perform a high-quality colonoscopy examination. The essential quality indicators for colonoscopy are adenoma detection rate (ADR) and withdrawal time (WT)~\cite{rex2002quality,kaminski2010quality}. Once the adenomas are detected during examination there are chances that the endoscopists become less motivated in finding the subsequent adenomas~\cite{lai2009boston,imperiale2016new,amano2018number}.

There are various reasons for high polyp miss-rate such as size, shape, quality of bowel preparation, and faster colonoscope withdrawal time~\cite{ahn2012miss}. Sometimes during a routine examination, the polyp is not recognized and sometimes despite being recognized they are missed. The polyp detection rate can be improved by detecting the unrecognized polyps that are on the visual field~\cite{mahmud2015computer}. Therefore, an algorithm-based second observer might help to improve the polyp detection rate during live colonoscopy examination. Additionally, a real-time computer-aided diagnosis system could highlight the suspicious polyps that could be clinically relevant for selecting optimal treatment, ideal colonoscopic resection and reducing overall cost~\cite{rex2017colorectal}. 

Deep learning based algorithms can highlight the presence of precancerous tissue in the colon and have the potential to improve the diagnostic performance of endoscopists.  In clinical practice, precise polyp segmentation provides important information in the early detection of colorectal cancer. Despite of success of deep learning algorithms for automatic polyp segmentation, it is still an unsolved problem. This is because even the most successful method fails when tested across new datasets obtained from the other centers mostly because of different imaging protocols, different cohorts populations and various scanners. The challenges which make polyp segmentation complicated are the variable nature of polyps in their size, shapes, subtle appearances (for example, sessile serrated lesions) and high recurrence rate etc. The human factors such as bowel preparation and skill of the particular endoscopist can also affect examination procedure~\cite{jha2022machine}.


Tomar et al.~\cite{tomar2022fanet} proposed a feedback attention network (FANet) for improved biomedical image segmentation, where they showed the state-of-the-art performance on seven publicly available benchmark datasets. FANet unifies the mask of the previous epoch with the current training epoch and rectifies the prediction iteratively during test time for improved performance. Recently, Biffi et al.~\cite{biffi2022novel} proposed an intelligent medical device for real-time optical characterization of colonoscopy polyps which can be also integrated easily into clinics. Besides that, there are several recent works on colonoscopy targeting polyps attributes such as size and count~\cite{tomar2022tganet}, flat, sessile or diminutive polyps~\cite{jha2021comprehensive}, out-of-distribution polyp detection through cross dataset test~\cite{srivastava2022gmsrf,jha2021comprehensive}, and synthetic data generation for improving the performance of the network~\cite{fagereng2022polypconnect}. As the study of colonoscopy cancer is becoming mature more emphasis is being given towards exploring the possibilities of new technological advancement such as diagnostic classification, risk stratification, and outcome examination~\cite{diao2022computer}. 

The main contribution are as follow:
\begin{enumerate}
\item We propose RUPNet, a novel lightweight encoder decoder based architecture for real-time polyp segmentation. Our algorithm is based on residual block and the architecture is designed in a way that requires low computational power for training.  

\item We evaluate RUPNet with the popular benchmarks and showed improvement over those architectures. Most interestingly, our method obtained a real-time speed of 152.60 which is important for the clinical integration. 
\end{enumerate}

\vspace{5 mm}

The rest of the paper is organized as follows. In Section~\ref{sec:method}, we present the method. In Section~\ref{sec:experimental_setup}, we present the experimental setup. Then, in Section~\ref{sec:results}, we present results and Discussion. Finally, we conclude our work in Section~\ref{sec:conclusion}. 


\vspace{3mm}
\section{Method}
\vspace{3mm}
\label{sec:method}
Figure~\ref{fig:rupnet} shows the block diagram of the proposed RUPNet architecture. RUPNet is an encoder-decoder network that consists of three encoder blocks, three decoder blocks, and a few additional upsampling blocks at the end of the network. The input image is passed to the first encoder block consisting of the residual block, followed by  max-pooling. The residual block~\cite{he2016deep} helps propagate information over layers that allows to build a deeper neural network for solving the degradation problems in each encoder block. It helps to improve the channel inter-dependencies and reduces the overall computational cost. The max-pooling is an operation for computing the maximum value for patches of feature maps which is used for creating downsampled feature maps. The output of the last encoder block passes through a residual block, which acts as the bridge between the encoder network and the decoder network. The output of the bridge acts as the input for the decoder network. 


\begin{figure}[!t]
    \centering
    \includegraphics[width = 0.6\textwidth]{Figure/RUPNet.png}
    \caption{Overall architecture of the RUPNet.}
    \label{fig:rupnet}
\end{figure}
The decoder begins with a bilinear upsampling with a factor of two. After that, it is followed by a residual block. The feature map increases in height and width with every decoder block until it reaches the last decoder. Here, we take the skip connections, followed by a bilinear upsampling to ensure that all the skip connections have the same resolution. The skip connection in the network allows the passing of lower-level semantic information to the latter layer, which helps preserve the information for better information flow. Next, we concatenate the upsampled feature maps with the output of the last decoder block. Finally, we have a  convolution with the Sigmoid activation function to get the final mask.

 \begin{figure}[!t]
    \centering
    \includegraphics[width = 0.9\textwidth]{Figure/Kvasir-seg.png}
    \caption{The figure shows examples of Kvasir-SEG~\cite{jha2020kvasir} used for training the RUPNet algorithm.}
    \label{fig:kvasir}
\end{figure}

\section{Experimental setup}
\label{sec:experimental_setup}


We have selected the Kvasir-SEG~\cite{jha2020kvasir} dataset consisting of 1,000 polyp images and their corresponding ground truth for training the proposed model. Figure~\ref{fig:kvasir} shows the example images from the Kvasir-SEG dataset. We use 880 images and masks for training our model and the rest 120 images for testing. We have performed extensive data augmentation, such as flipping, rotation, random brightness, etc., to increase the number of training samples. Our experiments are run on an NVIDIA RTX 3090 GPU system. We have used the Adam optimizer having a learning rate of 1e  and a batch size of 8. We have used a combination of binary cross-entropy and dice loss as a loss function. For the evaluation, we use standard medical image segmentation based metrics such as mean intersection over union (mIoU), dice coefficient (mDSC), recall or sensitivity, precision, accuracy, F2-score and processing speed. 
\begin{table*}[t!]
   \def\arraystretch{1.6}
    \setlength\tabcolsep{6pt}
    \par\bigskip
\centering
\caption{Quantitative results on the Kvasir-SEG~\cite{jha2020kvasir} test dataset.}
 \begin{tabular} {l|c|c|c|c|c|c}
\toprule
\textbf{Method} & \textbf{mDSC}  &\textbf{mIoU}  &\textbf{Recall}& \textbf{Precision} &\textbf{Accuracy} &\textbf{FPS}\\ 
\hline

U-Net~\cite{ronneberger2015u}  &0.5969  & 0.4713 &0.6171 & 0.6722 &0.8936 & 22.02 \\

ResUNet~\cite{zhang2018road}&0.6902 &0.5721 &0.7248 &0.7454 &0.9169 &14.82\\

ResU-Net++~\cite{jha2019resunet++}&0.7143 &0.6126 &0.7419 &0.7836 &0.9172 &7.01\\

RUPNet (Ours) &\textbf{0.7658} &\textbf{0.6553} &\textbf{0.8049} &\textbf{0.7995} &\textbf{0.9361} &\textbf{152.60}\\

\bottomrule
\end{tabular}
\label{tab:results}
\end{table*}


\begin{figure}[!t]
\centering
\includegraphics[width=0.6\linewidth]{Figure/results.png} 
\caption{The figure shows the example of qualitative results of RUPNet prediction. From the example, it can be observed that RUPNet can accurately segment medium and smaller-sized polyps. However, it also shows over-segmentation when exposed to light lighting conditions.}
\label{fig:qualitative}
\end{figure}



\section{Result and Discussion}
\label{sec:results}
\subsection{Comparison with State-of-the-Art: } 
Table~\ref{tab:results} shows the result of the RUPNet. The proposed architecture obtain an F1-score of 0.7658, mIoU of 0.6553,  recall of 0.8049, precision of 0.7995, and F2-score 0.9361. With the image resolution of , the proposed method achieves a real-time operation speed of 152.60 frames per second (FPS). The main reason behind higher speed is its architectural design, which has only a few trainable parameters, making the network lightweight for real-time processing. The most competitive benchmarking method of RUPNet was ResUNet++ with a dice coefficient of 0.7143. However, it has only a speed of 7.0193 FPS. Therefore, our method is 21.74 times faster than one of the widely used benchmark in the field of automated polyp segmentation.


Figure~\ref{fig:qualitative} shows the qualitative results of RUPNet. The qualitative result shows that RUPNet can correctly segment smaller and medium-sized polyps that are commonly missed due to their size. The visual results also show that RUPNet shows over-segmentation for the lighting conditions, as evidenced last two examples from Figure~\ref{fig:qualitative}. Thus, both the qualitative and quantitative results exhibit an acceptable overall performance. 

\subsection{Limitations and open challenges}
Our study has some limitations. We classify images into polyp and non-polyp regions. However, we do not cover if the polyp is adenoma or non-adenoma and does not look into diagnostic classes such as hyperplastic or sessile polyps. For the algorithm to be integrated into the clinical workflow,  the proposed algorithm should perform well on out-of-the-distribution datasets that are collected from different medical centres. Additionally, the algorithm should perform well in conditions such as camouflage and noise and should possess real-time processing speed. Although, we achieve real-time speed our algorithm is trained and tested on the same distribution datasets. We have not experimented on multi-center datasets, and our algorithm shows that there are still some challenges when there is camouflage which is caused by the false positive. This is also observed through the qualitative analysis. Moreover, we have not performed statistical tests for any experiments, which is also a way of interpreting the best model. 



\section{Conclusion}
In this work, we proposed the RUPNet architecture that utilizes a simple residual block to accurately segment polyps with high processing speed. The experimental results on the colon polyp dataset showed that RUPNet can accurately give real-time feedback with high accuracy, and it might help endoscopists in early polyp detection in clinics. In the future, we plan to extend RUPNet by adding transformer blocks in the encoder and evaluate with the multi-centre out-of-distribution dataset to study the robustness of our algorithm. Additionally, we will also research on distinguishing colon polyps based on their attributes, such as the number of polyps counts (for example, one or many) and their size (for example, , between , and  than 10 mm) and compare it with the recent state-of-the-art polyp segmentation benchmark. 

\section*{Acknowledgments}
This project is supported by the NIH funding: R01-CA246704 and R01-CA240639.

\bibliographystyle{unsrt}  
\bibliography{references}  


\end{document}
