





In the earlier sections we focussed on the number of gaps in the schedule. For
certain applications,  the \emph{size} of the gaps is also of interest. 
In this section we will study the problem where the objective is to
minimize the maximum gap in the schedule. Such schedules
tend to spread the jobs more uniformly over the time range and
produce many gaps, which may be useful in applications
discussed in Section~\ref{sec: maximizing the number of gaps}, where a good
schedule should leave some gaps between high-priority jobs, to allow other
jobs to access the processor. This could also be useful in temperature
control of the processor (see the discussion at the end of Section~\ref{sec: final comments}).

The general setting is as before. We have an instance $\calJ$ consisting
of $n$ unit jobs, where job $j$ has release time $r_j$ and deadline $d_j\ge r_j$. 
As explained in Section~\ref{sec: preliminaries}, we can assume that $\calJ$ is feasible.
The objective is to compute a schedule of all jobs that minimizes the maximum gap size.

Interestingly, this problem is structurally different from these in the previous 
sections, because now, intuitively, a good schedule should
spread the jobs more-or-less evenly in time. For example, if we have $n-2$ jobs released 
at $0$, all with deadline $D \gg n$, plus two more tight jobs $1$ and $n$ in time slots $0$ and $D$, respectively,
then we should schedule the non-tight jobs $j = 2,3,...,n-1$
at time slots $\approx (j-1) \frac{D}{n-1}$. In contrast, the algorithms in
Sections~\ref{sec: maximizing throughput with budget for gaps} and~\ref{sec: min gaps with throughput requirement}
attempted to group the jobs into a small number of blocks. 
Similar to the objective in Section~\ref{sec: maximizing the number of gaps}, a schedule
that minimizes the maximum gap size will typically create many gaps, but,
as can be seen in Figure~\ref{fig: example max gaps}, these two objective functions
will in general produce different schedules.



\begin{figure}[ht]
\begin{center}
\includegraphics[width=5in]{FIGURES/06_example_max_gaps.pdf}
\caption{An instance with two schedules. Red/dark shaded slots represent tight jobs.
The range of job $3$ is represented by a horizontal segment. The schedule on the left maximizes the
number of gaps. The schedule on the right minimizes the maximum gap. Both
schedules are unique optimal solutions for their respective objective functions.}
\label{fig: example max gaps}
\end{center}
\end{figure}



In this section we give an $O(n^2\log n)$-time algorithm for computing schedules
that minimize the maximum gap. We first give an algorithm for the
continuous model, and then extend it to the discrete model.



\subsection{The Continuous Case}

The continuous analogue of our scheduling problem can be formulated as follows. The input consists of $n$ intervals
$I_1,I_2,...,I_n$. As before, $I_j = [r_j,d_j]$ for each $j$.
The objective is to compute a hitting set $H$ for these intervals that
minimizes the maximum gap between its consecutive points. Another way to think about this problem is as computing a
\emph{representative} $h_j\in H\cap I_j$ for each interval $I_j$. Except for degenerate
situations (two equal intervals of length $0$), we can assume that
all representatives are different, although we will not be using this
property in our algorithm, and we treat $H$ as a multiset.

We order the intervals so that $d_1\le d_2 \le ... \le d_n$. (In this continuous version
we cannot assume all $d_j$'s are different without losing generality.) Further, we only need to
be concerned with sets $H$ that contain $d_1$, because if $H$ contains any points
before $d_1$ then we can replace them all by $d_1$ without increasing the maximum gap in $H$. 
Also, if $\max_i r_i\le d_1$ then there is a singleton hitting set, $H = \braced{d_1}$,
whose maximum gap is equal to $0$. Thus we can also assume
that $\max_i r_i > d_1$, so that we need at least two points in $H$.

Consider first the decision version: \emph{``Given $\lambda > 0$, is there a
hitting set $H$ for $I_1,I_2,...,I_n$ in which all gaps are at most $\lambda$?''}
If $\lambda$ has this property, we will call it \emph{viable}.
We first give a greedy algorithm for this decision version and
then later we show how to use it to obtain an efficient algorithm for the minimization version.



\medskip
\myparagraph{Algorithm~$\AlgViable(\lambda)$.}
We initialize $\circh_1 = d_1$ and $U = \braced{2,3,...,n}$. $U$ represents the set containing  the
indices of intervals that do not have yet representatives selected.
We move from left to right, at each step assigning a representative to one
interval in $U$, placing this representative as far to the right as possible, and we remove this interval from $U$. 

Specifically, at the beginning of a step $j\ge 2$ the current set of representatives is
$\circh_1,\circh_2,...,\circh_{j-1}$, listed in non-decreasing order. In this step we proceed as follows. 
Let $z = \circh_{j-1} + \lambda$. If all $j\in U$ satisfy $r_j > z$, declare failure and return $\FALSE$.
Otherwise, choose $j\in U$ with $r_j \le z$ that minimizes $d_j$ and remove $j$ from $U$.
We now have two cases. If $d_j \le z$, let $\circh_j = d_j$, and otherwise
(that is, when $r_j \le z < d_j$) let $\circh_j = z$. Then increment $j$ and continue.
If the process completes with $U = \emptyset$ (and thus also $j=n$),
return $\TRUE$ and the computed solution $\circH = \smallbraced{\circh_1,\circh_2,...,\circh_n}$.



\medskip

To show correctness of Algorithm~$\AlgViable(\lambda)$,
let $H = \braced{ h_1, h_2, ..., h_n}$ be some solution in increasing order and
with all gaps at most $\lambda$. We show that this solution can be converted into the one computed by our algorithm.
For $j=1$, as we explained earlier, we can assume that $h_1 = d_1$, so  $h_1 = \circh_1$.
Consider the first step when Algorithm~$\AlgViable(\lambda)$ chooses some $\circh_j\neq h_j$.  (If there is no such step, we are done.)
By the choice of $\circh_j$ in the algorithm, we have that $h_j < \circh_j$.  
(Otherwise, either the gap between $h_{j-1}$ and $h_j$ would exceed $\lambda$ or $H$ would not hit $I_j$.)
We can then replace $h_j$ by $\circh_j$ in $H$, without increasing the gap
size to above $\lambda$. This way, we increase the number of steps of
Algorithm~$\AlgViable(\lambda)$ that produce the same representatives as those in $H$.
So repeating this process sufficiently many times eventually converts $H$ into the set $\circH$.

\smallskip

We claim that Algorithm~$\AlgViable(\lambda)$ can be implemented in time $O(n\log n)$. Instead of
$U$, the algorithm maintains a set $U'\subseteq U$ that, when a step $j\ge 2$ starts, consists of indices $i$ for which
$r_i \le \circh_{j-1} + \lambda$ and $I_i$ does not yet have a representative. 
Store $U'$ in a  priority queue with priority values equal to the deadlines.
Then choosing the new interval $I_j$ in the algorithm and removing $j$ from $U'$ takes time $O(\log n)$.
When $j$ is incremented (after adding $\circh_j$ to the solution), the indices of new intervals are inserted
into $U'$ in order of release times (which can be sorted in the pre-processing stage), with each insertion taking time $O(\log n)$.

\medskip

Now, the idea is to use Algorithm~$\AlgViable(\lambda)$ as an oracle in binary search on $\lambda$'s. 
For this to work, we need to be able to efficiently identify a small set of candidate values for the optimal $\lambda$. Let 
\begin{equation*}
	\Lambda \;=\; \braced{ \frac{r_i - d_j}{k} \suchthat k\in \braced{1,2,..., n-1} , i,j\in\braced{1,2,...,n} , r_i > d_j}.
\end{equation*}
Observe that $|\Lambda| = O(n^3)$ and, by our assumption that $\max_i r_i > d_1$, also $\Lambda \neq \emptyset$.

We claim that $\Lambda$ contains the optimal gap length $\starlambda$. The argument is this. 
Consider some hitting set $\starH = \braced{\starh_1,\starh_2,...,\starh_n}$ whose maximum gap is $\starlambda$, 
sorted in non-decreasing order. Choose some maximal (w.r.t. inclusion)
consecutive sub-sequence $\starh_a < \starh_{a+1} < ... < \starh_b$ 
with all gaps equal to $\starlambda$, and suppose that $\starh_a$ is not a deadline. 
Then we can move $\starh_a$ by a little bit to the right without creating a gap
longer than $\starlambda$. Similarly, if $\starh_b$ is not a release time then
we can apply a similar procedure to $\starh_b$ and shift it to the left.
Each such operation reduces the number of gaps of length $\starlambda$. Since $\starlambda$ is optimal,
eventually we must get stuck, meaning that we will find a sub-sequence like the one above with the first
and last indices $a$ and $b$ that satisfy $\starh_a  = d_j$ and $\starh_b  = r_i$, for some $i$ and $j$.
Then we will have $\starlambda = \frac{r_i - d_j}{b-a} \in \Lambda$.

The idea above immediately yields an $O(n^3\log n)$-time algorithm. This algorithm
first computes the set $\Lambda$, sorts it, and then finds the optimal $\lambda$
through binary search in $\Lambda$. Note that the running time is dominated by sorting $\Lambda$. 

\smallskip

We now show that this running time can be improved to $O(n^2\log n)$,
by conducting a more careful search in $\Lambda$ that avoids constructing $\Lambda$ explicitly. 
The basic idea is to use a smaller set $\Delta$ that consists of all values $r_i - d_j$ where $r_i > d_j$.
This set $\Delta$ implicitly represents $\Lambda$, in the sense that it consists of
all numerator values of the fractions in $\Lambda$. More precisely,
each value in $\Lambda$ can be expressed as $x/k$, for some $x\in \Delta$ and $1\le k \le n-1$. 
One can visualize $\Lambda$ by representing such values $x/k$ as points in 2D, 
with the two coordinates representing the values of $x$ and $k$, and point $(x,k)$ representing
$x/k$ (see Figure~\ref{fig: idea behind algorithm minmaxgap}). 
Roughly, the algorithm then finds two consecutive values $v,w$ in $\Delta$ such that
$w/(n-1)$ is viable but $v/(n-1)$ is not. It then finds an index $\kappa$ such that
$v/\kappa$ is viable but $v/(\kappa+1)$ is not. Then the optimum
value of $\lambda$ must be between $v/\kappa$ and $v/(\kappa+1)$. We then
show that there are only $O(n^2)$ such values in $\Lambda$, so by doing a binary
search among these values we can find the optimum $\lambda$ in time $O(n^2\log n)$. 
A detailed algorithm with complete analysis follows.

\begin{figure}[ht]
\centering
\includegraphics[width=3in]{FIGURES/06_algorithm_min_maxgap.pdf} 
\caption{An illustration of the the idea behind Algorithm~$\AlgMinMaxGap$.
Viable fractions in $\Lambda$ are represented by the shaded region.
}
\label{fig: idea behind algorithm minmaxgap}
\end{figure}




\medskip

\myparagraph{Algorithm~$\AlgMinMaxGap$.} 
The algorithm is described below in Pseudocode~\ref{alg:minmaxgap}. In this pseudo-code,
to avoid multi-level nesting, we assume that the algorithm terminates if
the \textbf{return} statement is reached. 



\begin{algorithm}
  \setstretch{1.2}
  \caption{Algorithm~$\AlgMinMaxGap$}
  \label{alg:minmaxgap}
  \begin{algorithmic}[1]
	\State {\myIf} {$\max_i r_i\le d_1$} {\myThen} {\myReturn} $0$
	\State $\Delta \assign \braced{ r_i - d_j \suchthat r_i > d_j, i,j \in \braced{1,2,...,n}}$
	\State sort $\Delta$ in non-decreasing order
	\State {\myIf} {$\AlgViable(\frac{\min(\Delta)}{n-1})$} {\myThen} {\myReturn} $\frac{\min(\Delta)}{n-1}$
	\State $v \assign \max\braced{ x \in \Delta \suchthat \AlgViable(\frac{x}{n-1}) = \FALSE}$
	\State $w\assign \min \braced{ x \in \Delta \suchthat x > v }$
	\State {\myIf} {$\AlgViable(v) = \FALSE$} {\myThen} {\myReturn} $\frac{w}{n-1}$
	\State $\kappa \assign \max\braced{k \in \braced{1,2,...,n-1} \suchthat \AlgViable(\frac{v}{k}) = \TRUE}$
	\State $\Lambda'\assign \braced{ \frac{x}{ \ceiling{ \kappa x/v } }
						\suchthat x\in \Delta \;\textrm{and}\; \frac{v}{\kappa + 1} < \frac{x}{ \ceiling{ \kappa x}/v } \leq \frac{v}{\kappa}
						}\cup\braced{\frac{w}{n-1}}$		
	\State sort $\Lambda'$ in non-decreasing order
	\State \textbf{return} $\min \braced{ \lambda \in \Lambda' \suchthat \AlgViable(\lambda) = \TRUE}$
  \end{algorithmic}
\end{algorithm} 

\bigskip

We now explain the steps in the algorithm and justify correctness and the running time.
First, if $\max_i r_i\le d_1$ then there is a hitting set with all representatives on one point, 
and we return $0$ as the optimum value (Line~1).

Otherwise we have $\max_i r_i > d_1$, that is any hitting set needs at least two points and 
the optimal gap is strictly positive. 
We then compute all positive values $r_i - d_j$, store them in a set $\Delta$ and sort them (Lines~2-3).
This will take time $O(n^2\log n)$.

If $\frac{\min(\Delta)}{n-1}$ is viable (which we check in Line~4), 
then this is the optimal value, since no hitting set can have all
gaps smaller than $\frac{\min(\Delta)}{n-1} = \min(\Lambda)$. 
We can thus now assume that $\frac{\min(\Delta)}{n-1}$ is not viable.

Next, we compute the largest $v\in \Delta$ for which $\frac{v}{n-1}$ is not viable. By the
previous paragraph, such $v$ exists. 
To this end, we can do binary search in the set $\braced{\frac{x}{n-1} \suchthat x \in \Delta}$,
at each step making calls to $\AlgViable()$ to
determine whether the current split value is viable or not.
The binary search will take time $O(n^2\log n)$. 
We also let $w$ to be the next value in $\Delta$ after $v$. (If there is no such value, let $w = \infty$.)

At this point we check whether $v$ is viable. If it is not, it means that for all $x\in\Delta$ with
$x\le v$, all fractions $x/k$, for $k= 1,2,...,n-1$, are not viable as well. 
Then the smallest viable value in $\Lambda$ must be $\frac{w}{n-1}$, so we output $\frac{w}{n-1}$ in Line~7. 
(Note that in this case $w$ must exist, because if $v$ were the largest value in $\Delta$
then $v$ would be viable.)

If $v$ is viable, we compute the largest $\kappa$ for which $v/\kappa$ is viable (Line~8). By the choice of $v$ we have
$\kappa < n-1$. We now also know that the optimal value for $\lambda$ has the form $\frac{x}{k} \in \Lambda$
where $x\in\Delta$, $x\le v$, and
\begin{equation}
	 \frac{v}{\kappa+1} \;<\; \frac{x}{k} \;\le\; \frac{v}{\kappa}. 
	 \label{eqn: min max gap range of x}
\end{equation}
So we only need to search for $\lambda$ among such values.

Next, we define a small set $\Lambda'$ that contains all candidate values from the previous paragraph.
To this end, we claim that for any $x\in \Delta$, if $x\le v$ then there is at most one integer
$k_x\in\braced{1,...,n-1}$ for which condition~(\ref{eqn: min max gap range of x}) holds. 
This follows from simple calculation, as~(\ref{eqn: min max gap range of x}) implies that
\begin{equation*}
			\frac{x}{v}\cdot \kappa \;\le\; k < \frac{x}{v}\cdot \kappa + \frac{x}{v} \;\le\; \frac{x}{v}\cdot \kappa + 1.
\end{equation*}
Thus the only candidate for $k_x$ is $k_x = \ceiling{\frac{x}{v}\cdot \kappa}$.

The above argument gives us that the only candidates for the optimal gap size we need to consider
are all values  $x/k_x$, for $x\in \Delta$ and $x \le v$, plus the value $\frac{w}{n-1}$ that we identified before
as another candidate.
In Lines~9-10 we let $\Lambda'$ be the set of these candidates and we sort them in non-decreasing order.
Finally, we find the smallest viable value in $\Lambda'$. 
As $|\Lambda'| = O(n^2)$, this can be done in time $O(n^2\log n)$ with binary search that calls $\AlgViable()$ for each split value.




\subsection{The Discrete Case}

We now show that Algorithm~$\AlgMinMaxGap$ from the previous section can be adapted
to the discrete case, namely to scheduling unit jobs.

Let $\calJ$ be an instance of unit job scheduling with release times and deadlines.   
As explained in Section~\ref{sec: preliminaries},  we can now assume 
without loss of generality (and in contrast to the continuous case) that
all deadlines are different and sorted in increasing order, $d_1 < d_2 < ... < d_n$.

We treat $\calJ$ as a collection of intervals $I_j = [r_j,d_j]$, $j=1,2,...,n$, and
run Algorithm~$\AlgMinMaxGap$. This will produce a set of
(real-valued) representatives $H = \braced{h_1,h_2,...,h_n}$ for the intervals in $\calJ$. 
(Here $h_j$ denotes the representative of interval $I_j$, so the elements in $H$ may not be in increasing order.)
Let $\lambda$ be the maximum gap between these representatives. Since $\lambda$
is an optimal gap for the continuous variant, $\barlambda = \ceiling{\lambda}-1$
is a lower bound on the optimal gap length for the discrete variant.
(We need to subtract $1$ to account for unit length of jobs.)
It is thus enough to construct a schedule with all gaps of length at most $\barlambda$.

Recall that Algorithm~$\AlgViable(\lambda)$ either assigns jobs to their deadlines
or it spaces consecutive jobs at intervals of $\lambda$ between some deadline and some release time.
As explained before, without loss of generality we can assume that job $1$ is scheduled at $d_1$, and
Algorithm~$\AlgViable(\lambda)$ will in fact produce $h_1 = d_1$. 
If all other $h_i$'s are also deadlines, we are done. Otherwise, the rough idea is
to tentatively assign each job $j$ to $h_j$ (which may not be integral), and then, going from left to right,
gradually shift each job to the first available slot after $h_j$. This does not quite
work, because when several intervals have their representatives in the same slot, this
could force some jobs past their deadlines. So the correct process needs to be more
subtle and allow for some job reordering, as described below.



\medskip
\myparagraph{Procedure~${\AlgAdjust}(\lambda)$.}
We describe how to convert $H$ into a schedule $S$ of $\calJ$. Start by initializing $S_1 = d_1$ and $P=\emptyset$. 
(Set $P$ represents pending jobs that are ``delayed'', namely those
whose representatives' values in $H$ are before or at the current slot.)
Then consider slots $t = d_1+1, d_1 +2 , ...$, one by one. For each such $t$, first add to $P$ all jobs $j$ with $\ceiling{h_j} = t$. 
If $P\neq\emptyset$, choose $j$ to be the job in $P$ with minimum $d_j$, let $S_j = t$, and remove $j$ from $P$.
Then increment $t$ to $t+1$ and continue.
\smallskip



We claim that $S = (S_1,S_2,...,S_n)$ is a feasible schedule. By the way we add
jobs to $P$, if $j\in P$ when we consider slot $t$ then $r_j\le h_j \le t$. Since also
$h_j \le d_j$, each job will be added to $P$ not later than when processing slot $t=d_j$.
Also, the assumption about different deadlines implies (by simple induction) that when we consider a slot $t$ then all jobs in $P$
have deadlines at least $t$; in particular this gives us that no job will miss its deadline. 
Thus $S_j \in [r_j,d_j]$ for all $j\in\calJ$.

Next, we show that the maximum gap size in $S$ is equal to $\barlambda$. Obviously (see above), it
cannot be smaller. To show that it is not larger, consider a tentative assignment $Q = \braced{Q_1,Q_2,...,Q_n}$ of jobs to
slots defined by $Q_j = \ceiling{h_j}$, for all $j\in\calJ$. (This is not a feasible schedule
because it may assign different jobs to the same slot.) We first show that the
maximum gap in this assignment is at most $\barlambda$. Consider two jobs $j$ and $j'$ that are consecutive in $Q$;
that is, $Q_j < Q_{j'}$ and there is no job $\ell$ with $Q_j < Q_\ell < Q_{j'}$.
We can assume that $h_j = \max\braced{ h_\ell \suchthat Q_\ell = Q_j}$ and
$h_{j'} = \min\braced{ h_\ell \suchthat Q_\ell = Q_{j'}}$. Then $j$ and $j'$ are also consecutive in $H$ and
the length of the gap between them is $h_{j'} - h_j \le \lambda$. We then have
\begin{equation*}
Q_{j'} \;=\; \ceiling{h_{j'}} \le \ceiling{ h_j + \lambda} 
		\;\le\; \ceiling{h_j} + \ceiling{\lambda} 
		\;\le\; Q_j + 1 + \barlambda.
\end{equation*}
Thus all gaps in $Q$ are at most $\barlambda$. But all slots of $Q$ are also used by $S$
because, in Procedure~${\AlgAdjust}(\lambda)$, when we consider slot $t\in Q$ set $P$ is not empty.
This implies that the gaps in $S$ are bounded from above by $\barlambda$. We can thus conclude that $S$ is optimal.  

The way we described Procedure~${\AlgAdjust}(\lambda)$, its running time would not be bounded by a function of $n$.
This is easy to fix by skipping all the slots $t$ for which the current set $P$ is empty. Specifically,
we do this: Suppose that when we process a slot $t$ we have $P\neq\emptyset$. If $|P|\ge 2$ then $P$ remains non-empty
after scheduling a job in slot $t$, so in this case we increment $t$ by $1$. Otherwise, we increment it to the
first value $\ceiling{h_j}$ after $t$. This way we will only examine $n$ slots.
With routine data structures, this approach will give us running time $O(n\log n)$.

The discussion above focussed only on computing the optimum gap size. Given this value
and using Algorithm~$\AlgViable()$, one can also compute an actual optimum schedule. Summarizing, we obtain the following theorem.



\begin{theorem}\label{thm: min max gap}
For any instance $\calJ$, Algorithm~$\AlgMinMaxGap$ (adapted for the discrete case, as explained above)
in time $O(n^2\log n)$ computes a schedule of $\calJ$ whose maximum gap value is minimized. 
\end{theorem}




