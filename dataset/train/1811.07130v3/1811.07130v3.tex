\begin{table*}[t]
    \begin{center}
    \resizebox{0.8\linewidth}{!}{
    \begin{tabular}{c|c|c|c|c|c|c|c|c}
     \hline
     & \multicolumn{2}{c|}{CUHK03-Label} & \multicolumn{2}{|c|}{CUHK03-Detect} & \multicolumn{2}{|c|}{DukeMTMC-reID} & \multicolumn{2}{|c}{Market1501} \\
     Method & Rank-1 & mAP & Rank-1 & mAP & Rank-1 & mAP & Rank-1 & mAP \\
     \hline
     IDE~\cite{zheng2016person} & 22.2 & 21.0 & 21.3 & 19.7 & 67.7 & 47.1 & 72.5 & 46.0 \\
     PAN~\cite{zheng2018pedestrian} & 36.9 & 35.0 & 36.3 & 34.0 &71.6 & 51.5 & 82.8 & 63.4 \\
     SVDNet~\cite{sun2017svdnet} & - & - & 41.5 & 37.3 & 76.7 & 56.8 & 82.3 & 62.1 \\
     DPFL~\cite{chen2018person} & 43.0 & 40.5 & 40.7 & 37.0 & 79.2 & 60.0 & 88.9 & 73.1 \\
     HA-CNN~\cite{li2018harmonious} & 44.4 & 41.0 & 41.7 & 38.6 & 80.5 & 63.8 & 91.2 & 75.7 \\
     SVDNet+Era~\cite{zhong2017random} & 49.4 & 45.0 & 48.7 & 37.2 & 79.3 & 62.4 & 87.1 & 71.3 \\
     TriNet+Era~\cite{zhong2017random} & 58.1 & 53.8 & 55.5 & 50.7 & 73.0 & 56.6 & 83.9 & 68.7 \\
     DaRe~\cite{wang2018resource} & 66.1 & 61.6 & 63.3 & 59.0 & 80.2 & 64.5 & 89.0 & 76.0 \\
     GP-reid~\cite{almazan2018re} & - & - & - & - & 85.2 & 72.8 & 92.2 & 81.2 \\
     PCB~\cite{sun2017beyond} & - & - & 61.3& 54.2  & 81.9 & 65.3 & 92.4 & 77.3\\
     PCB + RPP~\cite{sun2017beyond} & - & - & 62.8 & 56.7 & 83.3 & 69.2 & 93.8 & 81.6\\
     MGN~\cite{wang2018mgn} & 68.0 & 67.4 & 66.8 & 66.0 & 88.7 & {\bf 78.4} & {\bf 95.7} & {\bf 86.9} \\
     \hline
Baseline & 52.6 & 49.9 & 51.1 & 47.9 & 81.0 & 62.8	& 91.6 & 77.1\\
     Baseline+Triplet & 67.4 & 61.5 & 63.6 & 60.0& 83.8 & 68.5 & 93.1 & 80.6\\
     \hline
     BDB & 73.6 & 71.7 & 72.8 & 69.3 & 86.8 & 72.1 & 94.2 & 84.3\\
     BDB+Cut & {\bf 79.4} & {\bf 76.7} & {\bf 76.4} & {\bf 73.5} & {\bf 89.0} & 76.0 & 95.3 & 86.7\\
     \hline
    \end{tabular}
    }
    \end{center}
    \vspace{-5mm}
    \caption{The comparison with the existing person re-ID methods. `Era' means Random Erasing~\cite{zhong2017random}. `Cut' means Cutout~\cite{devries2017improved}.}
    \label{tab:compare_person}
    \vspace{-4mm}
\end{table*}

\section{Experiments}
We verify our BDB Network on the benchmark person re-ID datasets.
The BDB Network with different metric learning loss functions is also tested on the standard image retrieval datasets. 

\subsection{Person re-ID Experiments}
\subsubsection{Datasets and Settings}
We test three generally used person re-ID datasets including Market-1501~\cite{zheng2015scalable}, DukeMTMC-reID~\cite{Ristani2016Performance,zheng2017unlabeled}, and CUHK03~\cite{Li2014DeepReID} datasets. 
We also follow the same strategy used in recent works~\cite{hermans2017defense, sun2017beyond, wang2018mgn} to generate training, query, and gallery data.
Notice that the original CUHK03 dataset is divided into 20 random training/testing splits for cross validation which is commonly used in hand-craft feature based methods. 
The new partition method adopted in our experiments further splits the training and gallery images, and selects challenging query images for evaluation. 
Therefore, CUHK03 dataset becomes the most challenging dataset among the three.

During training, the input images are re-sized to  and then augmented by random horizontal flip and normalization.
In Batch DropBlock layer, we set the erased height ratio  to 0.3 and erased width ratio  to 1.0. The same setting is used in all the person re-ID datasets. The testing images are re-sized to  and only augmented with normalization.

For each query image, we rank all the gallery images in decreasing order of their Euclidean distances to the query images and compute the Cumulative Matching Characteristic (CMC) curve. 
We use Rank-1 accuracy and mean average precision (mAP) as the evaluation metrics. 
Results with the same identity and the same camera ID as the the query image are not counted. 
It is worth noting that all the experiments are conducted in a single-query setting without re-ranking\cite{bai2017reid,zhong2017re} for simplicity.
\vspace{-3mm}
\subsubsection{Training}\vspace{-1mm}
Our network is trained using 4 GTX1080 GPUs with a batch size of 128. 
Each identity contains 4 instance images in a batch, so there are 32 identities per batch. 
The backbone ResNet-50 is initialized from the ImageNet~\cite{deng2009imagenet} pre-trained model. 
We use the batch hard soft margin triplet loss~\cite{hermans2017defense} to avoid margin parameters.
We use the Adam optimizer~\cite{kingma2014adame} with the base learning rate initialized to 1e-3 with a linear warm-up~\cite{goyal2017accurate} in first 50 epochs, then decayed to 1e-4 after 200 epochs, and further decayed to 1e-5 after 300 epochs. The whole training procedure has 400 epochs and takes approximately 1.5 hours. 
\vspace{-3mm}
\subsubsection{Comparison with State-of-the-Art}\vspace{-1mm}
The statistical comparison between our BDB Network and the state-of-the-art methods on CUHK03, DukeMTMC-reID and Market-1501 datasets is shown in Table~\ref{tab:compare_person}. It shows that our method achieves state-of-the-art performance on both CUHK03 and DukeMTMC-reID datasets. Remarkably, our method achieves the largest improvement over previous methods on CUHK03-Detect dataset, which is the most challenging dataset. For Market1501 datasets, our model achieves comparative performance to MGN~\cite{wang2018mgn}. However, it is worth to point out that MGN benefits from a much lager and more complex network which generates 8 feature vectors with 8 branches supervised by 11 loss functions. 
The model size (i.e., number of parameters) of MGN is three times of BDB Network.

\begin{figure}[t]
\begin{center}
\includegraphics[width=0.8\linewidth]{Figures/cuhk_results.jpg}
\end{center}\vspace{-3mm}
\caption{The top-4 ranking list for the query images on CUHK03-Label dataset from the proposed BDB Network. 
The correct results are highlighted by green borders and the incorrect results by red borders.}
\label{fig:cuhk_results}
\vspace{3mm}
\end{figure}

Some sample query results are illustrated in Figure~\ref{fig:cuhk_results}. We can see that, given a back view person image, BDB Network can even retrieve the front view and side view images of the same person.
\vspace{-3mm}
\subsubsection{Ablation Studies}
We perform extensive experiments on Market-1501 and CUHK03 datasets to analyze the effectiveness of each component and the impact of hyper parameters in our method.

\begin{table}[]
    \begin{center}
    \resizebox{0.8\linewidth}{!}{
    \begin{tabular}{c|c|c}
        \hline
         Method & Rank-1 & mAP  \\
         \hline
         Global Branch (Baseline) & 93.1 & 80.6 \\
         Feature Dropping Branch & 93.6 & 83.3 \\
         Both Branches (BDB)    & 94.2  & 84.3 \\
         \hline
         Feature Dropping Branch + Cut & 88.0 & 75.7\\
         BDB + Cut & 95.3 & 86.7\\
         \hline
    \end{tabular}
    }
    \end{center}
    \vspace{-4mm}
    \caption{The effect of global branch and feature dropping branch on Market-1501 dataset. `Cut' means Cutout~\cite{devries2017improved} augmentation.}
    \label{tab:global_branch}
    \vspace{1mm}
\end{table}



\paragraph{Benefit of Global Branch and Feature Dropping Branch.}\vspace{-4mm}
Without the global branch, the BDB Network still performs better than the baseline as illustrated in Table~\ref{tab:global_branch}. Adding the global branch could further improve the performance. The motivation behind the two-branch structure in the BDB Network is that it learns both the most salient appearance clues and fine-grained discriminative features. This suggests that the two branches reinforce each other and are both important to the final performance.

\begin{figure}[t]
    \centering
    \includegraphics[width=1\linewidth]{Figures/dropouts.jpg}
    \vspace{-3mm}
    \caption{The comparison with Dropout methods on two feature maps within the same batch.}\label{fig:dropout}
    \vspace{3mm}
\end{figure}


\begin{table*}[!htb]
\begin{minipage}[t]{.25\linewidth}
\resizebox{\linewidth}{!}{\begin{tabular}{c|c|c}
\hline
Method & Rank-1 & mAP  \\
\hline
SpatialDropout\cite{tompson2015efficient} & 60.5 & 56.8 \\
Dropout~\cite{srivastava2014dropout} & 65.3 & 62.2 \\
Batch Dropout & 65.8 & 62.9 \\
DropBlock~\cite{ghiasi2018dropblock} & 70.6 & 67.7 \\
\hline
Batch DropBlock & 72.8 & 69.3 \\
\hline
\end{tabular}
}
\vspace{0mm}
\caption{The Comparison with other Dropout methods on the CUHK03-Detect dataset.}
\label{table:variants}
\end{minipage}\hfill \begin{minipage}[t]{.38\linewidth}
\resizebox{\linewidth}{!}{\begin{tabular}{c|c|c|c|c}
\hline
& \multicolumn{2}{c|}{CUHK03-Detect} & \multicolumn{2}{|c}{Market1501} \\
Method & Rank-1 & mAP & Rank-1 & mAP \\
     \hline
     Baseline & 51.1 & 47.9 & 91.6 & 77.1\\ 
     Baseline + Triplet & 63.6 & 60.0 & 93.1 & 80.6\\
     Baseline + Dropping & 60.9 & 57.2 & 93.8 & 80.5\\
     \hline
     Baseline + Triplet + &\multirow{2}{*}{72.8} &\multirow{2}{*}{69.3} &\multirow{2}{*}{94.2} &\multirow{2}{*}{84.3}\\
     Dropping (BDB Network) & & & &\\
     \hline
\end{tabular}
}
\caption{Ablation studies of the effective components of BDB network on CUHK03-Detect and Market1501 datasets. `Dropping' means the feature dropping branch.}
\label{table:triplet_loss}
\end{minipage}\hfill \begin{minipage}[t]{.33\linewidth}
\resizebox{\linewidth}{!}{\begin{tabular}{c|c|c|c|c}
\hline
& \multicolumn{2}{c|}{CUHK03-Detect} & \multicolumn{2}{|c}{Market1501} \\
Method & Rank-1 & mAP & Rank-1 & mAP \\
\hline
Baseline & 63.6 & 60.0 & 93.1 & 80.6 \\
Baseline + RE & 70.6 & 65.9 & 93.3 & 81.5\\
Baseline + Cut & 67.7 & 64.2 & 93.5 & 82.0 \\
Baseline + RE + Cut & 70.7 & 65.9 &  93.1 & 82.0 \\
\hline\hline
BDB & 72.8 & 69.3 & 94.2 & 84.3\\
BDB + RE & 75.9 & 72.6 & 94.4 & 85.0 \\
BDB + Cut & {\bf 76.4} & {\bf 73.5} & {\bf 95.3} & {\bf 86.7}\\
\hline
\end{tabular}
}
\vspace{-3mm}
\caption{The comparison with data augmentation methods. `RE' means Random Erasing~\cite{zhong2017random}. `Cut' means Cutout~\cite{devries2017improved}.}
\label{table:augmentation}
\end{minipage} 
\vspace{-3mm}
\end{table*}

\paragraph{Comparison with Dropout and DropBlock.}\vspace{-4mm} Dropout~\cite{srivastava2014dropout} drops values of input tensor randomly and is a widely used regularization technique to prevent overfitting. 
We replace the Batch DropBlock layer with various Dropout methods and compare their performance in Table~\ref{table:variants}. 
SpatialDropout~\cite{tompson2015efficient} randomly zeroes whole channels of the input tensor. The channels to zero-out are randomized on every forward call. 
Here, Batch Dropout means we select random spatial positions and drops all input features in these locations. The difference between Batch DropBlock and Batch Dropout is that Batch DropBlock zeroes a large contiguous area while Batch Dropout zeroes some isolated features. 
DropBlock~\cite{ghiasi2018dropblock} means for a batch of input tensor, every tensor randomly drops a contiguous region. 
The difference between Batch DropBlock and DropBlock is that Batch DropBlock drops the same region for every input tensor within a batch while DropBlock crops out different regions. These Dropout methods are visualized in Figure~\ref{fig:dropout}.
As shown in Table~\ref{table:variants}, Batch DropBlock is more effective than these various Dropout strategies in the person re-ID tasks.

\paragraph{Global Average Pooling (GAP) vs Global Max Pooling (GMP) in Feature Dropping Branch.}\vspace{-4mm}
As shown in Figure~\ref{fig:cuhk_ratio} (b), the Rank-1 accuracy of the feature dropping branch with GMP is consistently superior to that with GAP.
We therefore demonstrate the importance of Max Pooling \textcolor{myRed}{for} a robust convergence and increased performance on the feature dropping branch.

\paragraph{Benefit of Triplet Loss}\vspace{-4mm}
The BDB Network is trained using both triplet loss and softmax loss. The triplet loss is a vital part of BDB Network since the Batch DropBlock layer has effect only when considering relationship between images. In table~\ref{table:triplet_loss}, `Baseline + Dropping' is the BDB Network without triplet loss. We can see that the triplet loss significantly improves the performance.

\begin{figure}
\includegraphics[width=1.0\linewidth]{Figures/raio_avg.jpg}
\vspace{-6mm}
\caption{(a) The effects of erased height ratio on mAP and CMC scores. The erased width ratio is fixed to 1.0. (b) The comparison of  global average pooling and global max pooling on the feature dropping branch under different height ratio settings. The statistics are analyzed on the CUHK03-Detect dataset.}
\label{fig:cuhk_ratio}
\vspace{2mm}
\end{figure}

\paragraph{Impact of Batch DropBlock Layer Hyper-parameters.}\vspace{-4mm}
Figure~\ref{fig:cuhk_ratio} (a) studies the impact of erased height ratio on the performance of the BDB Network.  
Here, the erased width ratio is fixed to 1.0 in all the person Re-ID experiments.
We can see that the best performance is achieved when height erased ratio is 0.3, which is the setting for BDB Network in person re-ID experiments.



\paragraph{Relationship with Data Augmentation methods.}\vspace{-4mm}
A natural question about BDB Network is could BDB Network still benefit from image erasing data augmentation methods such as Cutout~\cite{devries2017improved} and Random Erasing~\cite{zhong2017random} since they perform similar operations? The answer is yes. Because the BDB Network contains a global branch which sees the complete feature map and it can benefit from Cutout or Random Erasing. To verify it, we apply image erasing augmentation on BDB Network with or without the global branch in Table~\ref{tab:global_branch}. We can see Cutout performs bad without the global branch. Table~\ref{table:augmentation} shows BDB Network performs well with data augmentation methods. As can be seen, `BDB + Cut' or `BDB + RE' are significantly better than `Baseline + Cut', `Baseline + RE', or `BDB'.