\documentclass
[
    a4paper,
    DIV=11,
    abstracton
]
{scrartcl}

\usepackage
{
    graphicx,
    amssymb,
    amsmath,
    amsthm,
    algorithm,
    algpseudocode,
    stmaryrd, multirow,
    pbox,
    dsfont, authblk,
    xcolor,
    enumitem
}

\usepackage[pdffitwindow=false,
            plainpages=false,
            pdfpagelabels=true,
            pdfpagemode=UseOutlines,
            pdfpagelayout=SinglePage,
            bookmarks=false,
            colorlinks=true,
            hyperfootnotes=false,
            linkcolor=blue,
            urlcolor=blue!30!black,
            citecolor=green!50!black]{hyperref}

\usepackage[bf]{caption}
\captionsetup{format=plain}

\DeclareMathAlphabet{\mathpzc}{OT1}{pzc}{m}{it}

\newcommand{\subfiguretitle}[1]{{\scriptsize{#1}} \
    (\mc{v}_i, \mc{v}_j) \in \mc{E}_A \iff (\mc{v}_{\pi(i)}, \mc{v}_{\pi(j)}) \in \mc{E}_B,

    B = P^T A P,

    p_{ij} =
    \begin{cases}
        1, & \text{if } \pi(i) = j, \\
        0, & \text{otherwise}.
    \end{cases}
 \label{eq:GIP}
    \min_{P \in \mathcal{P}_n} \norm{ B - P^T A P }_F,

    \norm{B - P^T A P}_F^2 = \norm{B}_F^2 - 2 \tr\left(B^T P^T A P \right) + \norm{A}_F^2,
 \label{eq:RGIP}
    \min_{P \in \mathcal{O}_n} \norm{ B - P^T A P }_F,

    P^* = V_A S V_B^T,

    c = \min_{P \in \mathcal{O}_n} \norm{ B - P^T A P }_F
      = \norm{ B - P^{*T} A P^* }_F
      = \norm{ \Lambda_B - \Lambda_A }_F.

    \begin{split}
        v_A^{(6)} &= [0.380, 0.092, 0.157, 0.655, 0.477, 0.407]^T, \\
        v_B^{(6)} &= [0.222, 0.068, 0.352, 0.575, 0.353, 0.606]^T.
    \end{split}

    c_{ij} = \sum_{k=1}^m \big\lvert v_i^{(k)} - w_j^{(k)} \big\rvert,
 \label{eq:LAP}
    c = \min_{P \in \mathcal{P}_n} \tr \left( P^T C \right)

    \tr \left( P^T C \right) = \sum_{i,j=1}^n p_{ij} c_{ij} = \sum_{i=1}^n c_{i, \pi(i)} = 0.

    \norm{B - P^T A P}_F = \norm{V_B \Lambda_B V_B^T - P^T V_A \Lambda_A V_A^T P}_F = \norm{ \Lambda_B - \Lambda_A}_F = 0. \qedhere

    \pi =
    \begin{bmatrix}
        1 & 2 & 3 & 4 & 5 & 6 & 7 & 8 & 9 & 10 & 11 & 12 \\
        4 & 5 & 6 & 1 & 2 & 3 & 9 & 8 & 7 & 12 & 11 & 10
    \end{bmatrix}

    \pi_1 =
    \begin{bmatrix}
        1 & 2 & 3 & 4 & 5 & 6 & 7 & 8 \\
        4 & 3 & 2 & 1 & 6 & 5 & 7 & 8
    \end{bmatrix}, \quad
    \pi_2 =
    \begin{bmatrix}
        1 & 2 & 3 & 4 & 5 & 6 & 7 & 8 \\
        2 & 1 & 4 & 3 & 6 & 5 & 7 & 8
    \end{bmatrix}.
1ex]
    
    \begin{minipage}[t]{0.45\textwidth}
        \centering
        \subfiguretitle{c)}
        \includegraphics[width=0.75\textwidth]{pics/House_1}
    \end{minipage}
    \begin{minipage}[t]{0.45\textwidth}
        \centering
        \subfiguretitle{d)}
        \includegraphics[width=0.75\textwidth]{pics/House_2}
    \end{minipage} \1ex]
    
    \begin{minipage}[t]{0.45\textwidth}
        \centering
        \subfiguretitle{g)}
        \includegraphics[width=0.7\textwidth]{pics/Frucht_C}
    \end{minipage}
    \begin{minipage}[t]{0.45\textwidth}
        \centering
        \subfiguretitle{h)}
        \includegraphics[width=0.68\textwidth]{pics/House_C}
    \end{minipage}
    \caption{a--b)~Original and permuted Frucht graph.
             c--d)~Original and permuted house graph.
             e--f)~Original and permuted adjacency matrix of the Facebook graph.
             g\protect\nobreakdash--h)~Cost matrix for Frucht graph and house graph. White entries represent possible assignments with cost .}
    \label{fig:Simple graphs}
\end{figure}

\end{example}

The examples show that even with incomplete information it is possible to compute valid solutions of the graph isomorphism problem. If the solution is not unique, constructing the cost matrix reduces the search space significantly since only zero-cost entries need to be taken into account. Furthermore, the examples illustrate the difficulties arising from ambiguous eigenvectors.

\section{Graphs with repeated eigenvalues}
\label{sec:Graphs with repeated eigenvalues}

If the graphs possess repeated eigenvalues, finding isomorphisms is much harder. The eigenvectors belonging to repeated eigenvalues are unique only up to basis rotations and we cannot construct a linear assignment problem by comparing corresponding eigenvectors anymore. As mentioned above, repeated eigenvalues typically correspond to graph symmetries. It can be shown that strongly regular graphs, for instance, possess at most three distinct eigenvalues~\cite{Lov07}.

\begin{definition} \label{def:Eigenvector partitioning}
Given a graph  with adjacency matrix . Let  be the eigenvalues of the graph  with multiplicities , i.e., . We then partition  into , with .
\end{definition}

That is,  is either the eigenvector belonging to the eigenvalue  or the matrix whose columns form an orthogonal basis of the eigenspace.

\begin{example} \label{ex:Symmetric graphs}
We will use the following guiding examples to illustrate the proposed isomorphism testing approach for graphs with repeated eigenvalues:
\begin{enumerate}[leftmargin=0em,itemindent=1.7em,labelsep=0.3em,label=\roman*)] \setlength{\itemsep}{0mm}
\item The eigenvalues of the cycle graph shown in Figure~\ref{fig:Cycle graph}a are  with multiplicities . The automorphism group of the cycle graph is  and thus .

\item The eigenvalues of the strongly regular Paley graph shown in Figure~\ref{fig:Paley}a are  with multiplicities . Here, . Thus, the graph possesses  automorphisms. \exampleSymbol
\end{enumerate}
\end{example}

\subsection{Eigenpolytopes}

For the graphs in the previous example, it is not possible to apply Algorithm~\ref{alg:GI friendly graphs} directly. If we compare only eigenvectors belonging to distinct eigenvalues, this leads to . That is, any permutation matrix would be a feasible solution of the linear assignment problem. Therefore, we need to exploit additional information encoded in matrices representing orthogonal projections onto the eigenspace of repeated eigenvalues.

\begin{definition}
Let  be a repeated eigenvalue of graph . For a vertex , define  to be the -th row of . The convex hull of all vectors , , is called the \emph{eigenpolytope} of the graph belonging to the eigenvalue .
\end{definition}

The row vectors  clearly depend on the orthogonal basis chosen for the eigenspace, but the scalar product is independent of the choice of basis~\cite{God98}. The matrix

i.e., , represents the orthogonal projection onto the column space of  and is an invariant of the eigenspace that does not depend on the orthogonal basis chosen for , see also~\cite{CG97}. Thus, , which in itself can again be interpreted as a graph isomorphism problem. For a detailed description of the relation between a graph and the geometry of its eigenpolytopes, we refer to~\cite{God98, CG97}. We now exploit properties of the matrices  to identify isomorphisms. In what follows, we will show that by comparing eigenvectors and eigenpolytopes, it is possible to compute isomorphisms of strongly regular graphs such as the Paley graph.

\subsection{A spectral assignment approach for graphs with symmetries}

As described above, repeated eigenvalues complicate graph isomorphism testing. Our heuristic approach is based on finding local perturbations of the adjacency matrices  and  that break symmetries without changing the isomorphism. Let us illustrate the basic idea with a simple example.

\begin{example} \label{ex:Cycle graph motivation}
Let us consider the cycle graphs shown in Figure~\ref{fig:Cycle graph}a. In order to find an assignment for vertices of  to vertices of , we perturb the adjacency matrices  and . If we add a self-loop to vertex  of  and  of , the two graphs remain isomorphic\footnote{Note that due to the cyclic symmetry, we could assign vertex  to any other vertex of .}. Thus, we assign vertex  to vertex  of . The updated graphs are shown in Figure~\ref{fig:Cycle graph}b, the red vertices denote self-loops with weight . Now, we try to assign vertex  of  to a vertex of . Since we have broken the cyclic symmetry, there are now only two possible assignments (due to the remaining reflection symmetry). Vertex  of  could be either assigned to vertex  or  of . Adding self-loops with weight  to vertex  of  and vertex  of  -- shown in Figure~\ref{fig:Cycle graph}c --, the resulting graph is friendly and thus asymmetric. The permutation matrix  could be computed using Algorithm~\ref{alg:GI friendly graphs}. Alternatively, the procedure described above can be repeated until a valid assignment for all vertices is found. The resulting graphs are shown in Figure~\ref{fig:Cycle graph}d. \exampleSymbol
\end{example}

Let us formalize the above procedure. We start with the original adjacency matrices  and  and construct cost matrices , ,  as follows. For simple eigenvectors, we use the cost matrix from Definition~\ref{def:Cost matrix}, i.e., . For repeated eigenvalues, we compute the projection matrices  and  and check for each row  of  whether it can be written as a permutation of row  of  by comparing the sorted vectors\footnote{Assume that  and  are simple eigenvectors and contain the same entries, then comparing  and  leads to the same nonzero pattern as comparing the eigenvectors entry-wise.}.

\begin{definition}
Let  and  be the -th and -th row of the matrices  and , respectively, and let  be a function that sorts the entries of a vector. For repeated eigenvalues, we define , with .
\end{definition}

Note that this is only a heuristic approach and might lead to wrong assignments. However, utilizing properties of the eigenpolytopes improves the efficiency of the algorithm significantly and backtracking is required only in exceptional cases. For two graphs  and , the cost matrix is then defined as

The entries  represent the costs of assigning  of  to  of . To determine possible assignments, we again compute  and solve the resulting linear assignment problem


For the unperturbed cycle graph and Paley graph, the resulting cost matrices are zero, which implies that any vertex of  can initially be assigned to any vertex of . However, these assignment cannot be chosen independently. Thus, we assign vertices iteratively using local perturbations of the graphs as described in Example~\ref{ex:Cycle graph motivation}. After perturbing the graphs, symmetries are destroyed and the number of nonzero entries decreases until only one feasible solution remains. In order to perturb the adjacency matrices  and  and hence the eigenvalues and eigenvectors, we use single-entry matrices representing self-loops with different weights .

\begin{definition}
Define  to be the diagonal matrix with

\end{definition}

The proposed method for graphs with repeated eigenvalues is described in Algorithm~\ref{alg:GI symmetric graphs}. The algorithm can be stopped if the solution of the LAP is unique. The number of iterations required to obtain a unique solution depends on the order in which the vertices are perturbed. In the description of the algorithm, we have not included backtracking techniques. Backtracking is needed if a previously found assignment does not result in a correct permutation. We then delete the previous assignment and try to find a different assignment for the current vertex. Backtracking is required only for certain graph types as illustrated in Section~\ref{sec:Benchmark problems}.

\begin{algorithm}[htb]
    \caption{Graph isomorphism testing for graphs with repeated eigenvalues.}
    \label{alg:GI symmetric graphs}
    \vspace*{-0.5\baselineskip}
    \begin{enumerate} \setlength{\itemsep}{0mm}
        \item Compute  and .
        \item If  and , set .
        \item Define , , and .
        \item Find  so that .
        \item Set , . If , set  and go to step 3.
    \end{enumerate}
    \vspace*{-0.5\baselineskip}
\end{algorithm}

\begin{example}
Let us consider again the graphs from Example~\ref{ex:Symmetric graphs}:
\begin{enumerate}[leftmargin=0em,itemindent=1.7em,labelsep=0.3em,label=\roman*)] \setlength{\itemsep}{0mm}
\item For the cycle graph, the cost matrices  that result in successful assignments are shown in Figure~\ref{fig:Cycle graph}a--d. Without perturbing the adjacency matrices, each vertex of  can be assigned to each vertex of  and the cost matrix  is zero. After one perturbation, all eigenvalues are distinct, but due to the remaining reflection symmetry the solution is not unique and there are still two ambiguous eigenvectors (see Example~\ref{ex:GI distint eigenvalues}). After two iterations, the solution is unique and the resulting permutation is given by


\begin{figure}[htb]
    \centering
    \begin{minipage}[c]{0.23\textwidth}
        \centering
        \subfiguretitle{a)}
        \includegraphics[width=0.9\textwidth]{pics/Cycle_10}
    \end{minipage}
    \begin{minipage}[c]{0.23\textwidth}
        \centering
        \subfiguretitle{b)}
        \includegraphics[width=0.9\textwidth]{pics/Cycle_11}
    \end{minipage}
    \begin{minipage}[c]{0.23\textwidth}
        \centering
        \subfiguretitle{c)}
        \includegraphics[width=0.9\textwidth]{pics/Cycle_12}
    \end{minipage}
    \begin{minipage}[c]{0.03\textwidth}
        \vspace*{3ex} ...
    \end{minipage}
    \begin{minipage}[c]{0.23\textwidth}
        \centering
        \subfiguretitle{d)}
        \includegraphics[width=0.9\textwidth]{pics/Cycle_16}
    \end{minipage} \1.5ex]
    
    \begin{minipage}[c]{0.23\textwidth}
        \centering
        \includegraphics[width=0.8\textwidth]{pics/Cycle_C0}
    \end{minipage}
    \begin{minipage}[c]{0.23\textwidth}
        \centering
        \includegraphics[width=0.8\textwidth]{pics/Cycle_C1}
    \end{minipage}
    \begin{minipage}[c]{0.23\textwidth}
        \centering
        \includegraphics[width=0.8\textwidth]{pics/Cycle_C2}
    \end{minipage}
    \begin{minipage}[c]{0.03\textwidth}
        ...
    \end{minipage}
    \begin{minipage}[c]{0.23\textwidth}
        \centering
        \includegraphics[width=0.8\textwidth]{pics/Cycle_C6}
    \end{minipage}   
    \caption{Graph isomorphism testing procedure for the cycle graph. The various colors represent self-loops with different weights. The bottom row shows the structure of the corresponding cost matrices . White entries represent possible assignments with cost . After two perturbations of the graphs, the solution of the LAP is unique.}
    \label{fig:Cycle graph}
\end{figure}

\item For the Paley graph, the cost matrices after 1, 2, 3, and 4 successful assignments are shown in Figure~\ref{fig:Paley}b--e. After the fourth perturbation, the solution is unique and


\begin{figure}[htb]
    \centering
    \begin{minipage}[r]{0.24\textwidth}
        \centering
        \subfiguretitle{b)}
        \includegraphics[width=\textwidth]{pics/Paley_C1}
        \subfiguretitle{c)}
        \includegraphics[width=\textwidth]{pics/Paley_C2}
    \end{minipage}
    \begin{minipage}[c]{0.5\textwidth}
        \centering
        \subfiguretitle{a)}
        \includegraphics[width=\textwidth]{pics/Paley}
    \end{minipage}
    \begin{minipage}[c]{0.24\textwidth}
        \centering
        \subfiguretitle{d)}
        \includegraphics[width=\textwidth]{pics/Paley_C3}
        \subfiguretitle{e)}
        \includegraphics[width=\textwidth]{pics/Paley_C4}
    \end{minipage}
    \caption{a) Strongly regular Paley graph. b--e) Structure of the cost matrices  after 1, 2, 3, and 4 successful assignments. White entries represent assignments with . After four perturbations, the solution is unique.}
    \label{fig:Paley}
\end{figure}
\end{enumerate}

\end{example}

These examples demonstrate that the proposed method successfully computes isomorphisms of graphs with repeated eigenvalues.

\section{Benchmark problems}
\label{sec:Benchmark problems}

In this section, we will present numerical results for benchmark problems downloaded from~\cite{Val11} and~\cite{LAC11a}. For our computations, we used \emph{Matlab} and an error tolerance . That is, two eigenvalues of a matrix are defined to be identical if the difference is less than . Furthermore, an assignment is accepted if the cost  of the solution of the LAP is less than . For all graphs downloaded from~\cite{Val11}, the algorithm returned correct results without backtracking. Results for larger benchmark problems used by \emph{conauto} are presented in Table~\ref{tab:BenchmarkResults}. For each benchmark problem, we run the proposed algorithm 100 times using different randomly generated permutations of the original graph. Here, \emph{n} is the number of vertices, \emph{noBT} the number of runs where no backtracking was required, and \emph{BT} the number of runs where backtracking was required to find an isomorphism. The column \emph{steps} describes the average number of backtracking steps needed to find an isomorphism and the last column lists the average runtime in seconds. The efficiency of the algorithm could be easily improved by using C or C\texttt{++}. The results show that the algorithm returns correct results for most of the benchmark problems without backtracking. Only the Steiner triple system graph (1) and the union of strongly regular graphs (16) require backtracking for almost all test cases.

\begin{table}[htb]
    \newcommand{\muco}[1]{\multicolumn{1}{|c|}{#1}}
    \centering
    \caption{Test results for various benchmark graphs.}
    \scriptsize
    \begin{tabular}{|l|r|l|r|r|r|r|r|}
        \hline
        \muco{Type} & \muco{\#} & \muco{Name} &  & \muco{noBT} & \muco{BT} & \muco{steps (avg)} & \muco{time [s]} \\
        \hline
        \hline
\multirow{1}{*}{Steiner triple system graphs}                           &  1 & sts-19\_57         & 57 &   5 &  95 & 37.91 & 11.051 \\ \hline \multirow{3}{*}{\pbox{5cm}{Latin square graphs \\ (prime order)}}       &  2 & latin-3\_9         &  9 & 100 &   0 &  0.00 &  0.004 \\ &  3 & latin-5\_25        & 25 & 100 &   0 &  0.00 &  0.017 \\
                                                                                &  4 & latin-7\_49        & 49 &  98 &   2 &  1.00 &  0.141 \\ \hline
        \multirow{3}{*}{\pbox{5cm}{Latin square graphs \\ (prime power order)}} &  5 & latin-2\_4         &  4 & 100 &   0 &  0.00 &  0.001 \\ &  6 & latin-4\_16        & 16 & 100 &   0 &  0.00 &  0.008 \\
                                                                                &  7 & latin-6\_36        & 36 &  74 &  26 &  2.31 &  0.086 \\ \hline
        Paley graphs                                                            &  8 & paley-prime\_13    & 13 &  89 &  11 &  1.09 &  0.006 \\ (prime order)                                                           &  9 & paley-prime\_29    & 29 & 100 &   0 &  0.00 &  0.031 \\ \hline
        Paley graphs                                                            & 10 & paley-power\_9     &  9 & 100 &   0 &  0.00 &  0.002 \\ (prime power order)                                                     & 11 & paley-power\_25    & 25 & 100 &   0 &  0.00 &  0.020 \\ \hline                     
        \multirow{2}{*}{Lattice graphs}                                         & 12 & lattice(4)\_16     & 16 & 100 &   0 &  0.00 &  0.010 \\ & 13 & lattice(6)\_36     & 36 & 100 &   0 &  0.00 &  0.067 \\ \hline
        \multirow{2}{*}{Triangular graphs}                                      & 14 & triangular(7)\_21  & 21 & 100 &   0 &  0.00 &  0.013 \\ & 15 & triangular(10)\_45 & 45 & 100 &   0 &  0.00 &  0.097 \\ \hline
Unions of strongly regular graphs                                       & 16 & usr(1)\_29-1       & 29 &  11 &  89 & 13.49 &  0.392 \\ \hline Clique-conected cubic                                                   & 17 & chh\_cc(1-1)\_22-1 & 22 & 100 &   0 &  0.00 &  0.006 \\ hypo-Hamiltonian graphs                                                 & 18 & chh\_cc(2-1)\_44-1 & 44 & 100 &   0 &  0.00 &  0.097 \\ \hline
        Non-disjoint unions of                                                  & 19 & tnn(1)\_26-1       & 26 & 100 &   0 &  0.00 &  0.066 \\ undirected tripartite graphs                                            & 20 & tnn(2)\_52-1       & 52 & 100 &   0 &  0.00 &  0.700 \\ \hline
\multirow{2}{*}{Random graphs}                                          & 21 & iso\_r01N\_s20     & 20 & 100 &   0 &  0.00 &  0.002 \\ & 22 & iso\_r01N\_s40     & 40 & 100 &   0 &  0.00 &  0.010 \\
        \hline
    \end{tabular}
    \label{tab:BenchmarkResults}
\end{table}

In order to analyze the scalability of the spectral assignment approach, we compare it with the state-of-the-art graph automorphism and isomorphism tool \emph{nauty}~\cite{MK81, MKP14}. For each benchmark graph, we run \emph{nauty} 100 times using different randomly generated permutations. Additionally, each GI instance is solved 10000 times to obtain more accurate runtimes. The results are shown in Figure~\ref{fig:Runtimes}. We expect similar results for other tools such as \emph{conauto}~\cite{LAC11b} or \emph{bliss}~\cite{JK07} (for a comparison of these algorithms, see~\cite{MKP14}). While the absolute runtimes of \emph{nauty}, which is implemented in C, are much lower than the runtimes of our proof-of-concept Matlab implementation, the complexity of the spectral assignment grows only slightly faster. Furthermore, the comparison shows that in particular the random graphs (21) and (22) seem to be comparably easy to solve, while the union of strongly regular graphs (16) and the Steiner triple system graph (1) seem particularly hard to solve for both nauty and spectral approaches. This is also reflected in the number of backtracking steps. The spectral assignment approach for graphs with repeated eigenvalues could be optimized by a more sophisticated assignment strategy and by combining it with other heuristics. Instead of assigning nodes depending on the node numbers as described in Algorithm~\ref{alg:GI symmetric graphs}, it might be more efficient to exploit properties of the graph to decide which node should be assigned next. This is expected to reduce the number of backtracking steps and will be the focus of our future work.

\begin{figure}[htb]
    \centering
    \includegraphics[width=0.95\textwidth]{pics/Runtimes}
    \caption{Comparison of the runtimes of the spectral assignment approach and \emph{nauty}. Note that two different axes are used.}
    \label{fig:Runtimes}
\end{figure}

\section{Conclusion}
\label{sec:Conclusion}

In this work, we have presented eigendecomposition-based methods for solving the graph isomorphism problem. The algorithms were demonstrated with the aid of several guiding examples and benchmark problems. For friendly graphs, we have proven that the problem can be cast as a linear assignment problem. The approach was then generalized to unambiguous graphs. The examples show that the assignment problem formulation results in correct solutions even for ambiguous graphs. The primary issue related to the influence of ambiguous eigenvectors is the number of automorphisms and feasible solutions of the LAP. For graphs with repeated eigenvalues, our approach relies on the repeated perturbation of the adjacency matrices and solution of linear assignment problems. By exploiting properties of eigenpolytopes, it is possible to check whether two highly symmetric graphs are isomorphic. We believe that the proposed approach can be used to efficiently find isomorphisms, to detect and break symmetries, and to gain insight into the structure of highly regular graphs. Other properties of the eigenpolytopes may be exploited to minimize the number of erroneous assignments which then require backtracking. An important open question is the classification of graphs that require backtracking in the spectral approach and ones that do not. The isomorphisms for graphs that do not require backtracking can consequently be computed in polynomial time. We conjecture that graphs that requires backtracking have additional structure that makes the computations particularly challenging.

In practical applications, the graphs might be contaminated by noise \cite{ABK15}. Instead of finding a perfect matching with zero assignment cost, the goal then is to find a permutation which minimizes a given cost function. This is also called the \emph{inexact} graph isomorphism problem. Future work includes investigating whether our approach can also be used for the inexact problem formulation. Since the eigenvalues of a graph depend continuously on the entries of the adjacency matrix, a slightly perturbed graph will have a similar spectrum. Thus, instead of determining whether two graphs are isomorphic, the assignment approach can potentially be generalized so that the best matching of two graphs is computed, i.e., a permutation that minimizes the Frobenius norm distance between them. We believe that the Frobenius norm will serve as a good cost function for the inexact isomorphism problem. If the noise, however, is large, the spectrum of the graph might change in such a way that it becomes impossible to compare corresponding eigenvalues and eigenvectors.

\section*{Acknowledgements}

We would like to thank the reviewers for their helpful comments and suggestions.

\bibliographystyle{unsrt}
\bibliography{GI}

\end{document}
