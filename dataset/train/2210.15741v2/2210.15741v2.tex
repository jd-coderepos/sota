\documentclass[10pt,twocolumn,oneside,letterpaper]{article} 

\usepackage{avss}
\usepackage{times}
\usepackage{epsfig}
\usepackage{graphicx}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{booktabs}
\usepackage{multicol}
\newcommand{\pl}[1]{\textcolor[rgb]{0,0.5,1}{#1}}
\newcommand{\red}[1]{\textcolor[rgb]{1,0,0}{#1}}
\usepackage{algorithm,algpseudocode}
\usepackage{comment}
\usepackage{adjustbox}
\usepackage{multirow}
\usepackage{float}
\usepackage{pifont}
\usepackage{xcolor}
\usepackage{fancyhdr,lipsum}



\usepackage[pagebackref=true,breaklinks=true,letterpaper=true,colorlinks,bookmarks=false]{hyperref}


\avssfinalcopy 

\def\avssPaperID{77} \def\httilde{\mbox{\tt\raisebox{-.5ex}{\symbol{126}}}}

\ifavssfinal\pagestyle{empty}\fi
\begin{document}




\title{Spatio-temporal predictive tasks for abnormal event detection in videos}

\author{{ {Yassine Naji, Aleksandr Setkov, Angélique Loesch, Michèle Gouiffès, Romaric Audigier}}\\
{\normalsize Université Paris-Saclay, CEA, List, 91120, Palaiseau, France} \\  
{\tt\small firstname.lastname@cea.fr}
\\
{\normalsize  Université Paris-Saclay, CNRS, LISN, 91400, Orsay, France}
\\
{\tt\small firstname.lastname@universite-paris-saclay.fr}
}




\maketitle
\thispagestyle{empty}

\newcommand{\blue}[1]{\textcolor{black}{#1}}
\newcommand{\green}[1]{\textcolor{black}{#1}}


\begin{abstract}
  Abnormal event detection in videos is a challenging problem, partly due to the multiplicity of abnormal patterns and the lack of their corresponding annotations. In this paper, we propose new constrained pretext tasks to learn object level normality patterns. Our approach consists in learning a mapping between down-scaled visual queries and their corresponding normal appearance and motion characteristics at the original resolution. The proposed tasks are more challenging than reconstruction and future frame prediction tasks which are widely used in the literature, since our model learns to jointly predict spatial and temporal features rather than reconstructing them. We believe that more constrained pretext tasks induce a better learning of normality patterns. Experiments on several benchmark datasets demonstrate the effectiveness of our approach to localize and track anomalies as it outperforms or reaches the current state-of-the-art on spatio-temporal evaluation metrics.
\end{abstract}

 
\let\thefootnote\relax\footnote{978-1-6654-6382-9/22/\\bullet\bullettt-1  \rightarrow tt \rightarrow t+1t - 1tt + 1A_{t-1} , A_{t}, A_{t+1}M_{t-1 \rightarrow t} , M_{t \rightarrow t+1} tA_t\mathcal{E}\mathcal{D} \hat{A}_{t-1},\hat{A}_{t+1}\hat{M}_{t-1 \rightarrow t} , \hat{M}_{t \rightarrow t+1} tt-1  \rightarrow tt \rightarrow t+1t - 1tt + 1tF_{t - 1}F_{t}F_{t + 1}t-1, t+1F_tF_tF_{t+1}\mathcal{E}\mathcal{D}^{t-1}\mathcal{D}^{t-1 \rightarrow t}\mathcal{D}^{t\rightarrow t+1}, \mathcal{D}^{t+1} \mathcal{D}^{t-1}\mathcal{D}^{t+1}\mathcal{D}^{t-1 \rightarrow t}\mathcal{D}^{t \rightarrow t+1}\hat{A}_{t-1}\hat{A}_{t+1}\hat{M}_{t-1\rightarrow t}\hat{M}_{t \rightarrow t+1}O^{t-1}\mathcal{D}^{t-1}\hat{M}_{t-1 \rightarrow t}\mathcal{D}^{t-1\rightarrow t}M_{t-1 \rightarrow t}\mathcal{L}_{past}\mathcal{L}ij\mathcal{L}_{past}\mathcal{D}^{t-1}\hat{A}_{t-1}{A}_{t-1}\hat{M}_{t-1 \rightarrow t}\mathcal{D}^{t-1\rightarrow t}M_{t-1 \rightarrow t}\mathcal{L}_{future}tt+1O_t\ell_{1}\mu\SigmaLn = 4L\Delta_tN_tF_tF_t\delta t = 1\mathcal{E}10^{-3}tt-1t+1\frac{1}{2}\frac{1}{4}1S\frac{1}{2}\frac{1}{4}\frac{1}{2}$ gives slightly better performances. One possible explanation is that it offers a good compromise in terms of predictability. In fact, too much down-scaling makes the prediction hard even for normal samples, while without down-scaling it is easier for the model to recover anomalies.} Indeed, we observe a global drop in performances which is particularly high for RBDC (4.9p.p) when no down-scaling is performed. This results show that constraining further the prediction task by down-scaling the input is useful.  



\section{Conclusions}

In this work, we introduced a new way of approaching the VAD problem, by imposing constrained pretext tasks to learn appearance and motion normality patterns. The experiments conducted on benchmark datasets show the effectiveness of our methodology. In future work, we will explore more pretext tasks in order to further improve VAD performances and address new types of anomalies. 

{\small
\bibliographystyle{ieee}
\bibliography{egbib}
}





\end{document}
