We prove, in a constructive way, that the type inference problem for
\ETAS{} is decidable. Namely a type inference algorithm is
designed such that, for every lambda term  it produces
a \emph{principal typing} from which all and only its typings can be
obtained by a suitable substitution. The substitution is a partial
function, defined if it satisfies a set of linear constraints.  If
there is not a substitution defined on its principal typing, then 
is not typable.  We will also prove that the computational complexity
of the type inference procedure is of the same order as the type
inference for simple type assignment system.

The design of the algorithm is based on the following Generation Lemma.
\begin{lem}[Generation Lemma] 
Let .
 \begin{enumerate}[\em i)]
\item Let  If  is linear, then either  or . 
Otherwise, .
\item Let . Then  is of the shape .
\begin{enumerate}[]
\item Let . If  is linear then , else
 
\item Let . Then  and
, where 
.   
\end{enumerate}
\item Let . Then  is of the shape ,
 and  
, for some .
\begin{enumerate}[\em(a)]
\item If , then ,  and .
\item If , then , where
.      
\end{enumerate}
 \end{enumerate}
 \end{lem}  
\noindent The principal typing is described through the notion of a
 \emph{type scheme}, which is an extension of that one used in~\cite{Coppola03tlca} in
 the context of  and \NEAL.  Roughly speaking, a type scheme
 describes a class of types, i.e.  it can be transformed into a type
 through a suitable notion of a substitution.

\begin{defi}\hfill
\begin{enumerate}[i)]
\item\emph{Linear schemes} and \emph{schemes} are
  respectively defined by the grammars

where  belongs to a countable set of scheme variables and the \emph{exponential}   
is defined by the grammar

  where  ranges over a countable set of \emph{literals}.
 Linear schemes are
  ranged over by , schemes are ranged over by , exponentials are ranged over by  and literals are ranged over by .
  
 Note that the grammar does not generate nesting exponentials, i.e.,  is not a correct scheme, while
  is correct. 
\item A \emph{modality set} is a set of linear constraints in the
form either  or  or , where  and  are exponentials. Modality sets are ranged over by C.
\item A \emph{type scheme} is denoted by , where  is a scheme 
and  is
a modality set. Type schemes will be ranged over by . Let  
denote the set of type schemes.
  \item  denotes the simple type skeleton underlying the 
 type scheme , and it is defined as follows:
  
\item A \emph{scheme substitution}  is a partial function from type schemes
  to types, replacing scheme variables by types and literals by
  natural numbers, in such a way that constraints in  are satisfied. If  is an exponential,
  let  be the result of applying the scheme substitution  on all the literals in , e.g. 
 if  coincides with , then  is . 
  is satisfied by  if, for every constraint
  () in ,  ()
Clearly the solvability of a
set of linear constraints is a decidable problem. 
The application of a substitution 
   satisfying  to a type scheme  is defined inductively as follows:
  
   If  is not satisfied by , then  is undefined.
\end{enumerate}
\end{defi}

Binary relation  is extended to denote the syntactical
identity between both types, schemes and type schemes.  Making clear what we
said before, a type scheme can be seen as a description of the set of
all types that can be obtained from it through a scheme
substitution defined on it. 
\medskip

A substitution is a total function from type schemes to type schemes mapping scheme variables 
to schemes, and generating some constraints. 
A substitution is denoted by a pair 
, where  is a function from scheme variables to schemes and  is a modality set. 
Substitutions will be ranged over by . 
The behaviour of  is defined as follows.

  Note that the last rule is necessary in order to preserve the 
  correct syntax of schemes, where the nesting of exponentials is not allowed. 

  In order to define the principal typing, we will use a unification
algorithm for type schemes, which is a variant of that defined in
\cite{Coppola03tlca}.  Let  be the relation between type schemes
such that  if .

The unification algorithm, which we will present in Table
\ref{U-unification}, in Structured Operational Semantics style, is a function  from 
to substitutions.





\begin{table*}
\begin{center}
\fbox{
\begin{minipage}{.9\textwidth}

\vspace{1mm}   

\vspace{1mm}

\vspace{1mm}   

\vspace{1mm}

\vspace{1mm}   

\vspace{1mm}   


\vspace{1mm}  
 is the substitution such that \\
.
\end{minipage}}
\end{center}
\caption{The unification algorithm }\label{U-unification}
\end{table*}

The following lemma  proves that the function  supplies a more general unifier for two type schemes,
in two steps: the substitution it generates is the most general unifier with respect to
the relation , and moreover there is a most general scheme substitution
unifying the two type schemes modulo the syntactic equivalence .

\begin{lem}\label{e-unif}\hfill
\begin{enumerate}[\em i)]
\item (correctness)  implies
  ,   
   where .
  Moreover for every scheme substitution , defined on both the type schemes,
  .
\item (completeness)  implies
   
and  there is  such that, for every type scheme , 
  , for some .
\end{enumerate}
\end{lem}

\proof\hfill
\begin{enumerate}[i)]
\item Easy, by induction on the rules defining .
\item By induction on the pair (), where  and  are respectively the number of scheme variables occurring in
both  and  and the total number of symbols of  and .\\
Let , and let ; clearly 
either  or  cannot occur as proper subterm of . 
In the first case , and
. In the second case
. Then every 
scheme substitution , solving both  and  and acting as  on all the scheme 
variables occurring in  and  but 
does the desired job.\\
Let  and .
So ,
and .
So by induction 
,

and 
where . 
Moreover there is 
such that  and
.
In case  is not empty, the number 
of scheme variables in both the type schemes is less than
in  and ; otherwise their total number of symbols is less than the one in 
 and .
In both cases we can apply the induction hypothesis and conclude the proof.\\
All the other cases follow directly from the induction hypothesis.\qed
\end{enumerate}

The principal type scheme of a term is a pair in the form
, where  is a scheme context (i.e., a set of assignments
of the shape , where no variable is repeated), and  is a
type scheme. 

In order to simplify the text of the algorithm, we will use the following conventions:
\begin{enumerate}[]
\item Let  be a scheme.  denotes  in case ,
, where  in case ; if , then
 denotes ;
\item Let  be a scheme context.  denotes the scheme context 

\end{enumerate}

The principal type scheme algorithm is defined in
Table~\ref{table-def-type-inf}.

\begin{table*}
\begin{center}
\scalebox{.9}{\framebox{\begin{minipage}{.9\textwidth}
\begin{itemize}
\item 
\item \begin{tabbing}
     \= \texttt{let} \=
     \texttt{in}\\ 
    \>\> \texttt{if} \= doesn't occur free in \\
     \>\>\\
    \>\> \texttt{else}\\
    \>\>\> \texttt{let} \= \texttt{in}\\
    \>\>\>\> \texttt{if} \=  occurs multiple times in \\
    \>\>\>\>\> \texttt{let} \= 
    \texttt{in}\\
\>\>\>\>\>\> \texttt{let} \=  \texttt{and}\\
  \>\>\>\>\>\>\>   
  \texttt{in}\\
    \>\>\>\>\>\>\> \\
    \>\>\>\> \texttt{else}\\
    \>\>\>\>\> 
  \end{tabbing}
\item \begin{tabbing}
    \= \texttt{let} \=
      \texttt{,}
      \\
 \>\>   \texttt{and let they are disjoint in}\\
 \>\> \texttt{let} \=  \texttt{and} \\
\>\>\>  \texttt{and}\\
\>\>\> 
\texttt{and}\\
\>\>\>  \texttt{and}\\
\>\>\>  \texttt{and} \\
\>\>\>\texttt{let}  \texttt{in}\\
\>\>\>
  \end{tabbing}
\end{itemize}
 are fresh variables.
\end{minipage}
}}
\caption{The type inference algorithm .} \label{table-def-type-inf}
\end{center}
\end{table*}





\begin{thm}[Type Inference]\hfill 
\begin{enumerate}[\em i)] 
\item (correctness) If  then
for every scheme substitution
 defined on all the type schemes occurring in ,  partitioning
 s.t. .
\item (completeness)  If  then
  and there exists a scheme
 substitution  defined on all the type schemes occurring in  such that 
  and .
\end{enumerate} 
\end{thm}  

\proof\hfill
\begin{enumerate}[i)] 
\item By induction on .
\begin{enumerate}[]
\item . Then .
Every scheme substitution  satisfies the empty set of constraints. 

If 
 is linear, then
take  and either  
and  
or  and . 
Otherwise choose 
, and .
\item . This case follows directly by induction.
\item . 
Then , 
, and 
,
where  is defined as in Table \ref{table-def-type-inf}.

Let  be a scheme substitution defined on all the type schemes occurring in :
note that, by the definition of the function  this implies that  is defined on both 
and . Moreover, by construction of ,  ()
implies  is defined, and ,
by Lemma \ref{e-unif}.\\
By induction 

(). Note that every type derivation for  ends with an application of the rule , followed by a sequence, 
may be be empty, of rule (). Since in rule  the two linear contexts are disjoint, we can build the partition of the contexts in
the following way:\\
,\\
,\\
 and\\
 ().\\
 By the weakening Lemma, we have that 
 (). 
Since  (by Lemma \ref{e-unif}.i), 
the proof follows by rule ().
\end{enumerate}
\item By induction on the derivation proving .

Let the last used rule be (). Then , and . By definition, 
, and the proof follows easily.

The case () is similar.

The cases  and  both follow by induction and weakening lemma.

Let us consider the case when the last used rule is . 
Then , and 
 and 
, for some ,
where  and  are disjoint.
By induction  and 
there is  defined on all type schemes in  such that ,
and .\\
Moreover 
 (). 
Since by construction  and  are disjoint, there is a well defined scheme substitution
 acting as both  and  and such that 
, for  fresh. So
if ,
, 
and  is defined on all the type schemes in
 ().
Then 
by Lemma \ref{e-unif}.ii), 
.
Since  satisfies all the constraints in  (), if 
 and  belong to  and 
respectively, then , and so, by Lemma \ref{e-unif}.ii), 
they can be unified.
So  is defined, and by 
induction it enjoys the desired properties.

Let the last used rule be . Then  and the premise of the rule is 
, where 
.
By induction  and there is a scheme substitution 
such that .
Let  be such that  is defined on all the type schemes in , and
such that , for all 
type scheme : it is easy to check that, if  is defined, i.e., it satisfies all the constraints in , than  is 
well defined too, and so it does the right job.\qed
\end{enumerate}



\noindent The complexity of the type inference algorithm  is of
the same order as the type inference algorithm for simple types. In
order to prove this, we need some notations.  If  is an
algorithm running on a datum , let us denote by  its
asymptotic complexity.  Moreover, if  is a scheme, let
 be the number of symbols in it.  Let  be
the type inference algorithm for simple types running on a term
. By abuse of notation, we assume that, for every type scheme
,  denotes a simple type: in fact the
syntax of type schemes, when erasing exponentials and constraints,
coincides with that of simple types.
\begin{thm}[Complexity]
.
\end{thm}
\proof
First of all, let us observe that the the unification algorithm  coincide with the Robinson unification, when it is applied to two type schemes
whose set of constraints is empty, so, if  denotes the Robinson's unification, 
. 
Then 
.
Remember that Robinson unification is equivalent to the principal simple type assignment.
Moreover it is easy to see that, if , then 
, when  denotes the context obtained 
from  by applying the function  to all types in it.

The proof is by induction on . If  is a constant the proof is trivial.
If , then , for a constant , since  is a scheme variable. Then the result follows by induction.
Let . Then  
if  and 
  .  is an abbreviation for the unification of the 
  two scheme contexts  and , as specified in the algorithm. 
 By induction .
 Remembering that , the result follows.\qed
 






\begin{exa}
  Let us illustrate the application of the type inference algorithm to
  the term:
 
  Let  be literals and  be scheme variables.  First we will
  build PT(\underline{2}). Starting from

  due to , we obtain:
 
  where .

  Now a fresh version of  is needed, so consider .  The rule for application allows
  us to perform certain unifications.  First we obtain
 
  where .  A second unification is
  necessary for unifying the two premises on  in the first
  component of  and , respectively:
 
  where .  By composing the two substitutions,
  we have .  So 

  where  By
  applying the rule for the abstraction, we obtain:

  and

  where .

  Due to the particular form of , we can deduce
  that the term  can be assigned, among others,
  the following types

  In particular, the scheme substitution that replaces  by , furthermore , , ,  and  by , and both
   and  by , satisfies the constraints and generates the
  typing , whose derivation is
  shown in Example \ref{exa:terms}.

  In order to build the principal type scheme of , we
  need to start from two fresh copies of  and , let

  where .

  By applying the rule for application, we obtain, for the first
  unification:

  where  By unifying the two premises on , we have
 
  where . So, composing the two substitutions:

  where .
  So, by applying the rules for abstraction, we have:

  and

  where .

  It is easy, but boring, to check that the typings for
   are the same that the ones for , by
  inspecting the modality set.  Now, in order to build
  , we need to unify the two
  type schemes:

  and 
 
  obtaining:

  where . So

  where .

  Finally, the scheme substitution that replaces  by ,
  furthermore , ,  and  by , and both  and
   by , satisfies the constraints and generates the typing
  , whose derivation is
  shown in Example \ref{exa:terms}.
\end{exa}

