\documentclass[review]{elsart}

\usepackage{units} \usepackage{graphicx}

\usepackage[monochrome]{color}
\usepackage[disable]{todonotes}

\usepackage{xy}
\xyoption{all}

\usepackage{lineno,hyperref}
\modulolinenumbers[5]




















\bibliographystyle{elsarticle-num}


\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{stackrel}

\newtheorem{definition}{Definition}[section]
\newtheorem{theorem}[definition]{Theorem}
\newtheorem{proposition}[definition]{Proposition}
\newtheorem{corollary}[definition]{Corollary}
\newtheorem{conjecture}[definition]{Conjecture}
\newtheorem{lemma}[definition]{Lemma}
\newtheorem{example}[definition]{Example} 

\newenvironment{proof}{\par
\noindent
\textsc{Proof. }
\noindent}{\hfill}

\newenvironment{proofsummary}{\par
\noindent
\textsc{Proof (Sketch). }
\noindent}{\hfill}

\usepackage{environ} \NewEnviron{killcontents}{}
\let\proofsummary\killcontents
\let\endproofsummary\endkillcontents


\newenvironment{append}{}{}





\newcommand\blfootnote[1]{\begingroup
  \renewcommand\thefootnote{}\footnote{#1}\addtocounter{footnote}{-1}\endgroup
}

\newcommand{\Nat}{{\mathbb N}}
\newcommand{\Real}{{\mathbb R}}
\newcommand{\D}{\mathbb{D}}
\renewcommand{\H}{\mathbb{H}}
\newcommand{\J}{\mathbb{J}}
\renewcommand{\P}{\mathbb{P}}
\newcommand{\Z}{\mathbb{Z}}
\newcommand{\Hip}{\overline{\mathbb{H}}_1}
\newcommand{\Jip}{\mathbb{D}_{\le1}}
\newcommand{\conv}{\mathrm{conv}}

\newcommand{\pto}{\rightharpoondown}
\newcommand{\dom}{\mathrm{dom}}

\newcommand{\EE}{\mathcal{E}}
\newcommand{\FF}{\mathcal{F}}
\newcommand{\GG}{\mathcal{G}}
\newcommand{\TT}{\mathcal{T}}
\newcommand{\exit}{\mathbf{\Phi}}
\newcommand{\init}{\mathbf{in}}
\newcommand{\sched}{\mathbf{Sched}}
\newcommand{\unity}{\delta}
\newcommand{\sem}[1]{[\![#1]\!]}

\newcommand{\seq}{\cdot}
\newcommand{\triple}[3]{\{#1\}#2\{#3\}}
\newcommand{\pc}[1]{{\oplus_{\!#1}}}
\newcommand{\convol}{\star}
\newcommand{\bks}{*}

\newcommand{\refby}{\sqsubseteq}
\newcommand{\refbyh}{\sqsubseteq_{\mathbb{H}}}
\newcommand{\simref}{\refby_{\mathrm{sim}}}

\newcommand{\thread}{\mathtt{thd}}

\newcommand{\Eqn}[1]{Eqn.~(\ref{#1})}
\newcommand{\Prop}[1]{Prop.~\ref{#1}}
\newcommand{\Thm}[1]{Thm.~\ref{#1}}
\newcommand{\Defs}[1]{Def. #1}
\newcommand{\Sec}[1]{Sec. \ref{#1}}
\newcommand{\Fig}[1]{Fig.~\ref{#1}}




\newcommand{\Ax}{\color{red}}
\newcommand{\Gx}{\color{blue}}
\newcommand{\Tx}{\color{orange}}
\newcommand{\Xx}{\color{gray}}


\let\OLDthebibliography\thebibliography
\renewcommand\thebibliography[1]{
  \OLDthebibliography{#1}
  \setlength{\parskip}{0pt}
  \setlength{\itemsep}{0pt plus 0.3ex}
}


\begin{document}

\begin{frontmatter}
\title{Probabilistic Rely-guarantee Calculus}


\author[mq]{Annabelle McIver}
\ead{annabelle.mciver@mq.edu.au}
\author[mq]{Tahiry Rabehaja}
\ead{tahiry.rabehaja@mq.edu.au}
\author[sh]{Georg Struth}
\blfootnote{This research was supported by an iMQRES from Macquarie University, the ARC Discovery Grant DP1092464 and the EPSRC Grant EP/J003727/1.}
\ead{g.struth@sheffield.ac.uk}
\address[mq]{Department of Computing, Macquarie University, Australia}
\address[sh]{Department of Computer Science, University of Sheffield, United Kingdom}


\begin{abstract} Jones' rely-guarantee calculus for shared variable concurrency is extended to include probabilistic behaviours. We use an algebraic approach that is based on a combination of probabilistic Kleene algebra with concurrent Kleene algebra.  \todo[disable]{adapts with concurrent KA sounds odd. Why not write: We use an algebraic approach that is based on a combination of probabilistic Kleene algebra with concurrent Kleene algebra?} Soundness of the algebra is shown relative to a general probabilistic event structure semantics. The main contribution of this paper is a collection of rely-guarantee rules built on top of that semantics. In particular, we show how to obtain bounds on probabilities of correctness by deriving quantitative extensions of rely-guarantee rules. 
\todo[inline]{I don't fully understand the previous sentence: probability bounds should come from the probabilistic part of the semantics, not from the concurrent one... {\Tx Does that make more sense?}} 
The use of these rules is illustrated by a detailed verification of a simple probabilistic concurrent program: a faulty Eratosthenes sieve.  \end{abstract}

\begin{keyword}probabilistic programs, concurrency, rely-guarantee, program verification, program semantics, Kleene algebra, event structures.
\end{keyword}


\end{frontmatter}



\section{Introduction}
The rigorous study of concurrent systems remains a difficult task due to the intricate interactions {\Gx and interferences} between their components. A formal framework for concurrent systems ultimately depends on the kind of concurrency considered. Jones' rely-guarantee calculus provides a mathematical foundation for {\Gx proving} the correctness of programs with shared variables concurrency{\Gx in compositional fashion}~\cite{Jon81}. This paper extends Jones' calculus to the quantitative correctness of probabilistic concurrent programs.

Probabilistic programs have become popular due to their ability to express quantitative rather than limited qualitative properties. Probabilities are particularly important for protocols that rely on the unpredictability of probabilistic choices.
\todo[disable]{protocols requiring security?} 
The sequential probabilistic semantics, originating with Kozen~\cite{Koz81} and Jones~\cite{Jon92}, have been extended with nondeterminism~\cite{He97,Mci04}, to yield methods for quantitative reasoning based on partial orders. \todo[inline]{What does using partial orders mean? {\Tx Rewritten}} 

{\Gx
We aim to obtain similar methods for reasoning in compositional ways about probabilistic programs with shared variable concurrency. In algebraic approaches, compositionality arises quite naturally through congruence or monotonicity properties of algebraic operations such as sequential and concurrent composition or probabilistic choice.

It is well known that compositional reasoning is nontrivial both for concurrent and for sequential probabilistic systems.  In the concurrent case, the obvious source of non-compositionality is communication or interaction between components.  In the rely-guarantee approach, interference conditions are imposed between individual components and their environment in order to achieve compositionality. Rely conditions account for the global effect of the environment's interference with a component; guarantee conditions express the effect of a particular component on the environment.  Compositionality is then obtained by considering rely conditions within components and guarantee conditions within the environment.
}

In the presence of probabilistic behaviours, a problem of congruence (and hence non-compositionality) arises when considering the natural extension of trace-based semantics to probabilistic automata~\cite{Seg94}, where a standard work-around is to define a partial order based on simulations.
\todo[inline]{I would prefer to see a conceptual explanation instead of a mathematical one, as in the r-g case.}


In this paper, we define a similar construct to achieve compositionality. However, simulation-based equivalences are usually too discriminating for program verification. Therefore, we also use a weaker semantics that is essentially based on sequential behaviours. Such a technique has been motivated elsewhere~\cite{Arm14}, where the sequential order is usually not a congruence. Therefore, the simulation-based order is used for properties requiring composition while the second order provides a tool that captures the sequential behaviours of the system.


Concurrent Kleene algebra~\cite{Hoa11,Arm14} provides an algebraic account of Jones' rely-guarantee framework. Algebras provide an abstract view of a program by focusing more on control flows rather than data flows. All the rely-guarantee rules described in~\cite{Hoa11,Arm14} were derived by equational reasoning from a finite set of algebraic axioms. Often, the verification of these axioms on an intended semantics is easier than proving the inference rules directly in that semantics. Moreover, every structure satisfying these laws will automatically incorporate a direct interpretation of the rely-guarantee rules, as well as additional rules that can be used for program refinement. Therefore, we also adopt an algebraic approach to the quantitative extension of rely-guarantee, that is, we establish some basic algebraic properties of a concrete event structure model and derive the rely-guarantee rules by algebraic reasoning.

In summary, the main contribution of this paper is the development of a mathematical foundation for \textit{probabilistic rely-guarantee calculi}. The inference rules are expressed algebraically, and we illustrate their use on an example based on the Sieve of Eratosthenes which incorporates a probability of failure. We also outline two rules that provide probabilistic lower bounds for the correctness of the concurrent execution of multiple components. 

A short summary of the algebraic approach to rely-guarantee calculus and the extension to probabilistic programs are found respectively in Section~\ref{sec:standard-rg} and~\ref{sec:prgc}-\ref{sec:prg-rules}. Section~\ref{sec:sequential-programs} and~\ref{sec:es} are devoted to the construction of a denotational model for probabilistic concurrent programs.
Section~\ref{sec:application} closes this paper with a detailed verification of the faulty Eratosthenes sieve. 





\section{Non-probabilistic rely-guarantee calculus}\label{sec:standard-rg}
The rely-guarantee approach, originally put forward by Jones~\cite{Jon81}, is a compositional method for developing and verifying large concurrent systems. An algebraic formulation of the approach has been proposed recently in the context of concurrent Kleene algebras~\cite{Hoa11}.  In a nutshell, a bi-Kleene algebra is an algebraic structure  such that  is a Kleene algebra and  is a commutative Kleene algebra. The axioms of Kleene algebra and related structures are in Appendix~\ref{A:ka} 
.

\todo[inline]{I think such an appendix should be added to summarise the algebraic laws used in this paper.}

Intuitively, the set  models the actions a system can take; the operation  corresponds to the nondeterministic choice between actions,  to their sequential composition and  to their parallel or concurrent composition. The constant , the unit of addition, models the abortive action, , the unit of sequential and concurrent composition, the ineffective action . The operation  is a sequential finite iteration of actions; the corresponding parallel finite iteration operation  is not considered further in this article. Two standard models of bi-Kleene algebras are languages, with  interpreted as language union,  as language product,  as shuffle product,  as the empty language,  as the empty word language and  as the Kleene star, and pomset languages under operations similarly to those in Section~\ref{S:seqred} below (cf. ~\cite{BloomEsik}).

Language-style models with interleaving or shuffle also form the standard semantics of rely-guarantee calculi. In that context, traces are typically of the form , where the  and  denote states of a system, pairs  correspond to internal transitions of a component, and fragments  to transitions caused by interferences of the environment. Behaviours of a concurrent system are associated with sets of such traces.

With semantics for concurrency in mind, a generalised encoding of the validity of Hoare triples becomes useful:  

where .  It has been proposed originally by Tarlecki~\cite{Tar85} for sequential programs with a relational semantics. In contrast to Hoare's standard approach, where  and  are assertions and  a program, all three elements are now allowed to be programs. In the context of traces,  holds if all traces that are initially in  and then in  are also in . This comprises situations where program  models traces ending in a set of states  (a precondition) and  models traces ending in a set of states  (a postcondition). The Hoare triple then holds if all traces establishing precondition  can be extended by program  to traces establishing postcondition , whenever  terminates, as in the standard interpretation. We freely write  in such cases. It turns out that all the inference rules of Hoare logic except the assignment rule can be derived in the setting of Kleene algebra~\cite{Hoa11}.

For concurrency applications, the algebraic encoding of Hoare triples has been expanded to Jones quintuples , also written , with respect to rely conditions  and guarantee conditions ~\cite{Hoa11}. The basic intuition is as follows. A rely condition  is understood as a special program that constrains the behaviour of a component  by executing it in parallel as . This is consistent with the above trace interpretation where parallel composition is interpreted as shuffle and gaps in traces correspond to interferences by the environment. Typical properties of relies are  (where  is ) and . Moreover, relies distribute over nondeterministic choices as well as sequential and concurrent compositions: ,  and , hence they apply to all subcomponents of a given component~\cite{Arm14}. A guarantee  of a given component  is only constrained by the fact that it should include all behaviours of , that is, .

\todo[inline]{\Tx I wonder if using the word constrain both for the guarantee (previous sentence) and the rely (next sentence) wouldn't introduce confusion.}

Consequently, a Jones quintuple is valid if the component  constrained by the rely satisfies the Hoare triple---the relationship between precondition and postcondition---and the guarantee includes all behaviours of ~\cite{Hoa11}: 
The rules of Hoare logic without the assignment axiom are still derivable from the axioms of bi-Kleene algebra, when Hoare triples are replaced by Jones quintuples~\cite{Hoa11}. To derive the standard rely-guarantee concurrency rule, one can expand bi-Kleene algebra by a meet operation  and assume that  forms a distributive lattice~\cite{Arm14}. Then

This inference rule demonstrates how the rely-guarantee specifications of components can be composed into a rely-guarantee specification of a larger system. If  and  satisfy the premises, then  satisfies both postconditions  and  when run in an environment satisfying both relies  and . Moreover,  guarantees either of  or .

Deriving these inference rules from the algebraic axioms mentioned makes them sound with respect to all models of these axioms, including trace-based semantics with parallel composition interpreted as interleaving, and true-concurrency semantics such as pomset languages and the event structures considered in this article. Without the algebraic layer, Dingel~\cite{Din02} and Coleman and Jones~\cite{Col07} have already proved the soundness of rely-guarantee rules with respect to trace-based semantics, more precisely \emph{Aczel traces}~\cite{Roe97}.  This paper follows previous algebraic developments, but for probabilistic programs.

In Section~\ref{sec:prgc}, we provide a suitable extension of the rely-guarantee formalism, in particular Rule~(\ref{rule:rg-standard}), to probabilistic concurrent programs. The soundness of such a formalism is shown relative to a semantic space that allows sequential probabilistic programs to include concurrent behaviours.

\section{Sequential probabilistic programs}\label{sec:sequential-programs}
We start by giving a brief summary of the denotation of sequential probabilistic programs using the powerdomain construction of McIver and Morgan~\cite{Mci04}. All probabilistic programs are considered to have a finite state space denoted by . A distribution over the set  is a function  such that . The set of distributions over  is denoted by . Since  is a finite set, we identify a distribution with the associated measure. For every  and , we write . An example of distribution is the point distribution , centred at the state , such that

A (nondeterministic) probabilistic program  modelled as a map of type  such that  is a non-empty, topologically closed and convex subset of  for every state . The set  is a topological sub-space of the finite product  (endowed with the usual product topology), and the topological closure is considered with respect to the induced topology on \footnote{These healthiness conditions are set out and fully explained in the work of McIver and Morgan~\cite{Mci04}.}. We denote by  the set of probabilistic programs that terminate almost certainly. Notice that the set  contains only distributions instead of the subdistributions considered by McIver and Morgan~\cite{Mci04}. Therefore, we only model nondeterministic programs that are terminating with probability .

Programs in  are ordered by pointwise inclusion, i.e.  if for every , . A program  is deterministic if, for every ,  (i.e. a singleton) for some distribution . The set of deterministic programs is denoted by  (as in Jones' spaces~\cite{Jon92}). If  is a deterministic program such that , then we usually just write . A particularly useful example of a probabilistic deterministic program is the ineffectual program , which we denote by . Thus .



Let . The probabilistic combination of two probabilistic programs  and  is defined as~(\cite[\Defs{5.4.5}]{Mci04}) 

where  for every state . Thus, the program  (resp. ) is executed  with probability  (resp. ).

Nondeterminism is obtained as the set of all probabilistic choices (\cite[\Defs{5.4.6}]{Mci04} ), that is, 

The sequential composition of  by  is defined as (\cite[\Defs{5.4.7}]{Mci04}):

where 

for every state . 





For , the binary Kleene star  is the least fixed point of the function  in . It has been shown in~\cite{Mci04} that the function  is continuous ---it preserves directed suprema. Notice that a topological closure is sometimes needed to ensure that we obtain an element of . Hence, the Kleene star  is the program such that
,
where  is the topological closure of the set  and the constant  is defined, as usual, such that ,  and  for every .








We introduce tests, which are used for conditional constructs, following the idea adopted in various algebras of programs. We define a test to be a map  such that . Indeed, an ``if statement" is modelled algebraically as  where  if the test underlying  holds at state  and it is  otherwise. The sub-expression  still evaluates to  if  is empty, but care should be taken to avoid expressions such as  (if  is a deterministic refinement of , then  may have no meaning if ). A test that is always false can be identified with .

We denote by  the set of tests together with the set of probabilistic programs. The refinement order  is extended to  in a straightforward manner. For every test , we have ; hence, we refer to tests as \emph{subidentities}. Every elements of  are called programs, unless otherwise specified.





\section{An event structures model for probabilistic concurrent programs}\label{sec:es}

The set  of probabilistic programs provides a full semantics for program constructs such as (probabilistic) assignments, probabilistic choices, conditionals and while loops that terminate almost surely. Unfortunately, it is impossible to define the concurrent composition of two sequential programs as an operation on  because the result would always be a sequential program. Thus we are forced to look for a more general framework in order to formally model concurrency. Fortunately, there are several suitable mathematical models that allows the formal verification of programs with concurrent behaviours. A powerful example that accounts for true concurrency are Winskel's \emph{event structures}~\cite{Win80,Win86}. In this section, we outline a denotational semantics for probabilistic concurrent programs based on Langerak's bundle event structures~\cite{Lan92}, which have been extended successfully to quantitative features~\cite{Kat93,Kat96,Var03}. This construction is necessary to ensure the soundness of the extended rely-guarantee formalism.

{\Tx
A bundle event structure comprises events ranging over some set  of \emph{events} as its fundamental objects. Intuitively, an event is an occurrence of an action at a certain moment in time. Thus an action can be repeated, but each of its occurrences is associated with a unique event. Events are (partially) ordered by a causality relation which we denote by : if an event  causally depends on either  or  (i.e. ) then either  or  must have happened before  can happen or is \emph{enabled}. The relationship between  and  is called \emph{conflict}, written , because both events cannot occur simultaneously.
}

In general, the conflict relation  is a binary relation on . Given two subsets , the predicate  holds iff for every  such that , we have . 

\begin{definition}\label{def:ipbes}
A quintuple  is a \emph{bundle event structure with internal probability} (i.e. an ipBES) if 
\begin{itemize}
\item  is an irreflexive symmetric binary relation on , called \emph{conflict relation}. 
\item  is a \emph{bundle relation}, i.e. if  for some  and , then . 
\item , i.e. it labels events with (atomic) probabilistic programs.
\item  such that  holds  for every .
\end{itemize}
 
The finite state space  of the programs used as labels is fixed.
\end{definition} 

The intuition behind this definition is that events are occurrences of atomic program fragments, i.e. they can happen without interferences from an environment. Hence, we need to distinguish all atomic program fragments when translating a program into a bundle event structure. Atomic programs can be achieved by creating a construct that forces atomicity. Examples of such a technique include ``atomic brackets"~\cite{Jon12}. In this paper, we always state which actions are atomic rather than using such a device.

Given an ipBES , a \emph{finite trace} of  is a sequence of events  such that for all different ,  and if  then there exists an  such that  and ~\cite{Lan92,Kat96,Rab13}. In other words, a trace is safe (an event may occur only when it is enabled) and is conflict free. The set of all finite traces of  is denoted by . The set of maximal traces of  (w.r.t the prefix ordering) is denoted . We simply write  (resp. ) instead of  (resp. ) when no confusion may arise.

The aim of this section is to elaborate two relationships between the sets of traces of given event structures. The first comparison is based on a sequential reduction using schedulers; the second one is simulation. We will show that the sequential comparison is strictly weaker than the simulation relation.

\subsection{Schedulers on ipBES}\label{sec:scheduler}

{\Tx
As in the case of automata, we define schedulers on ipBES in order to obtain a sequential equivalence on bundle event structures with internal probability. Intuitively, a scheduler reduces an ipBES to a element of . While the technicalities of the schedulers we define in this paper is tailored towards a rely-guarantee reasoning, there might be relationships with previous works~\cite{Geo10,Geo12} where schedulers (and associated testing theories) are restricted in order achieve a broader class observationally equivalent processes. 
}

A \emph{subdistribution} is a map  such that .  The set of subdistributions over  is denoted by .  

\begin{definition}\label{def:ipscheduler}
A \emph{scheduler}  on an ipBES  is a map 
 
such that for all :
\begin{enumerate}
\item ,\label{pr:sched-dom}
\item there exists a function  such that, for every ,  for some .
\label{pr:sched-choice}
\item for every , we have ,\label{pr:sched-prob}
\item for every , if , then   and  (the subdistribution that evaluates to  everywhere).\label{pr:sched-consistent}
\end{enumerate}
The set of all schedulers on  is denoted by .
\end{definition}

Property~\ref{pr:sched-dom} says that we may schedule an event provided it does not depend on unscheduled events.

Property~\ref{pr:sched-choice} states that, given a trace , the scheduler will resolve the nondeterminism between events enabled after  byusing the weight function . This may include immediate conflicts or interleavings of concurrent events. Moreover, the scheduler has access to the current program state when resolving that nondeterminism. This means that  is the probability that the event  is scheduled, knowing that the program state is . If the event  is successfully scheduled, then the scheduler performs a last choice of distribution, say  from , to generate the next state of the program.

Property~\ref{pr:sched-prob} ensures that when the state  is known, then the choice between the events, enabled after the trace , is indeed probabilistic.  

Property~\ref{pr:sched-consistent} says that a scheduler is forced to choose events whose labels do not evaluate to the empty set at the current state of the program. This is particularly important when the program contains conditionals and the label of an event is a test. A scheduler is forced to choose the branch whose test holds. If two tests hold at state , then a branch is chosen probabilistically using the weight function . 

The motivation behind Property~\ref{pr:sched-consistent} is to ensure that, for every trace  such that , and every state , we have

hence that sum is indeed a distribution. To ensure that a scheduler satisfying that condition can be constructed, we restrict ourselves to \textit{feasible} event structures. Given an element , we write .

\begin{definition}
An ipBES  is \emph{feasible} if for every trace , we have .
\end{definition}

A consequence of this assumption is that an ``if clause" always needs to have a corresponding ``else clause".

\begin{example}
Let us consider the program . In this program,  is  atomic deterministic (such as an assignment to a variable) and the associated event structure has three events:

where  (see \Sec{S:seqred} for an inductive construction of ipBES from primitive blocks). This event structure is feasible and a scheduler  on  is characterised by a weight function  resolving the choice .  In fact, for every fixed state , we have  and  and .
\end{example}


\subsection{Generating sequential probabilistic programs from ipBES and schedulers}

Similar to the case of probabilistic automata~\cite{Seg94}, our scheduler resolves branching as encoded in the conflict relation of an event structure. In addition, a scheduler also ``flattens" concurrency into interleaving by choosing an enabled event according to the associated weight function. The flattening of concurrent behaviours is sound because actions labelling events are assumed atomic and we are using schedulers to generate sequential behaviours from an ipBES. True concurrency is accounted for in \Sec{s1511}.

Let  and  be an initial state. We inductively construct a sequence of functions  that map a trace in  to a subdistribution on  according to  and . Intuitively, if , then  is the sequential composition of the -first probabilistic actions labelling events in  applied to the initial state . This yields a subdistribution because  is weighted with respect to the scheduler . The sequence of partial functions  is the \emph{computation sequence} of  with respect to   from initial state .

Formally, for each , we have , where  is the set of traces of length  and 

\begin{enumerate}
\item ,where  is the initial state,
\item if  then 

and   otherwise.\label{pr:induction-computation-function}
\end{enumerate}

To emphasises that this computation function refers to a specific initial state  we sometimes write  instead of .

The \textit{complete run} of  with respect to  is the limit  of that sequence, i.e. , which exists because  defines a sequence of partial functions such that  is the restriction of  to . Since we consider finite traces only, we have . The \textit{sequential behaviour} of  with respect to  from the initial state  is defined by the sum 

\begin{proposition}\label{pro:scheduler-well-defined}
For every bundle event structure , scheduler  and initial state ,  is a subdistribution. 
\end{proposition}

\begin{proofsummary}
The proof is by induction on the sequence of computation functions. We can show by induction on  that 

and deduce that, at the limit, .
\end{proofsummary}

\begin{proof}
Let  be the complete run of  with respect to a given scheduler . We show by induction on  that

For the base case , we have , where  is the initial state. Assume the induction hypothesis . We have
 
() Follows from  and the fact that the second union is disjoint.

() The square-bracketed term equals  because of Properties~\ref{pr:sched-choice} and~\ref{pr:sched-prob} of the scheduler .


Therefore, each partial computation  can be seen as a probability distribution  supported on . Hence, the limit is a subdistribution  on . It does not necessarily add up to  because elements of  are finite maximal traces only and non-termination will decrease that quantity (we assume that the empty sum is . This occurs when there are no maximal traces).
\end{proof}

Given a state ,  is the probability that the concurrent probabilistic program denoted by  terminates in state  when conflicts (resp. concurrent events) are resolved (resp. interleaved) according to the scheduler . Since we consider terminating programs only, we denote by  the set of schedulers of  such that, for every initial state ,  is a distribution. A scheduler in   generates a sequential behaviour that terminates almost surely. This leads to our definition of a bracket  that transform each feasible ipBES to an element of : 
where  (resp. ) is the convex (resp. topological) closure of the set of distributions  in . 

\begin{definition}\label{def:semantics-sequential}
Let  be two feasible event structures. We say that  (sequentially) refines , denoted by , if  holds in .
\end{definition}

The relation  is a preorder on ipBES. Whilst this order is not a congruence, it is used to specify the desired sequential properties of a feasible event structure  with . We will show that feasibility and non-emptiness of  are preserved by the regular operations of the next section (Props \ref{pro:homomorphism} and \ref{pro:*-homomorphism}).

\subsection{Regular operations on ipBES}\label{S:seqred}

This section provides interpretations of the operations  and constants  on event structures with disjoint sets of events. These definitions allow the inductive translation of program texts into event structure objects.

\begin{itemize}
\item[-] The algebraic constant  is interpreted as .
\item[-] The algebraic constant  is interpreted as .
\item[-] Each atomic action  is associated with . This event structure is again denoted by .
\item[-] The nondeterministic choice between the event structures  and  is constructed as 

where  and  is the symmetric closure of a relation on . The square-bracketed set ensures that every final event in  is in conflict with every final event in . This ensures that, if , then .

\item[-] The sequential composition of  by  is 

\item[-] The concurrent composition of  and  is
 
\item[-] The binary Kleene star of  and  is the supremum of the sequence 
of bundle event structures with respect to the -complete sub-BES order~\cite{Rab13b}.
\end{itemize}

\todo[inline]{\Tx The reviewer advised that this example should show the inductive construction in practice.}

\begin{example}
Let us consider the sequential programs . A concurrent program that is skipping or running  in parallel with itself is algebraically denoted by . The construction of the associated event structure starts from the innermost operation , assuming that each occurrence of the atomic action  is associated with an event from . Thus 

We can now construct the nondeterministic choice between  and  as
\begin{footnotesize}

\end{footnotesize}
In this example, we have  and  but  and  are concurrent.
\end{example}

For every bundle event structure , , , and in particular, . The constant  was only introduced to have a bottom element on the set of bundle event structures with internal probabilities. It ensures that we can compute the Kleene star inductively from the least element. Moreover,  will disappear in mixed expressions because of these properties.

We now show that the operations  and  are preserved by the map . The case of the binary Kleene star  is proven in \Prop{pro:*-homomorphism}.

\begin{proposition}\label{pro:homomorphism}
For  non-zero, feasible and terminating event structures, we have  and .
\end{proposition}



\begin{proof}
For the case of nondeterminism , let  be the initial state and . Let us firstly assume that  for some . By definition of the sum , the set of events  and  are disjoints, so we can define two schedulers  and  as follows. Let  and , we define

 
where ,  is the weight function associated to  at the trace  and  is the initial state. The real number  is just a normalisation constant required by Property~\ref{pr:sched-prob} in the definition of schedulers.~\footnote{If , then .} The scheduler  is similarly defined. It follows directly from these definition of  and  that  where  because of Property~\ref{pr:sched-prob}. Hence,  i.e. . Since  is convex and topologically closed, we deduce that . 

For the converse inclusion , notice that  holds for every subset . If we write  and , then 

But it is clear that  (a scheduler that does not choose  is possible because  is feasible) and . Therefore,  because the last set is convex and topologically closed.


The sequential composition is proven using a similar reasoning. Let  be two bundle event structures satisfying the hypothesis, and  for some initial state . 

The proof of  goes as follows. Firstly, let us assume that there is a scheduler  on  such that . Since schedulers are inductively constructed, there exists  and  such that 

Let us denote by  and  (resp. \varphi_{n,t}t the computation sequences associated to the respective schedulers  and  (resp. ) from the initial state  (resp. ). It follows directly that  for every . If  and  then, for every state ,

Similarly, we have


By simple induction on the length of , we deduce that

where  is the complete run obtained from the sequence . 
It follows by definition of the sequential composition on  (\Eqn{eq:6-sequential-H}) that

for every state . Secondly, since  is upclosed and topologically closed, we deduce that . 

Conversely, if , then either  or  is in the closure of the set of these distributions. Either way, the closure properties of  implies that . 
\end{proof}


\subsection{Simulation for ipBES}\label{s1511}

The partial order defined in Definition~\ref{def:semantics-sequential} compares the sequential behaviours of two systems. However, it suffers from a congruence problem, i.e. there exist programs  and  such that  but . A known technique for achieving congruence is to construct an order based on simulations, which is the subject of this section. We use a similar technique in this subsection.

We say that a trace  is \emph{weakly maximal} if it is maximal or there exist some events  such that  and  for every . 

\begin{definition}\label{def:t-simulation}
A function  is called a \emph{t-simulation} if the following conditions hold:
\begin{itemize}
\item[-] if  and  is a finite set for every ,
\item[-] if  then either:
\begin{itemize}
\item  and  holds in ,
\item or there exists an event  of  such that  and .
\end{itemize} 
\item[-] if  is maximal in  then , for some  (with ), and  is weakly maximal in ~\footnote{If  is maximal then  is necessarily maximal.}.
\end{itemize}
We say that  is simulated by , written , if there exists a simulation from  to . The equivalence generated by this preorder is denoted .
\end{definition}



The notion of t-simulation has been designed to simulate event structures correctly in the presence of tests. For instance, given a test , the simulation  fails because a t-simulation is a total function and it does not allow the removal of ``internal" events labelled with subidentities during a refinement step. The finiteness condition on  ensures that we do not refine a terminating specification with a diverging implementation. Without that constraint, we would be able to write the refinement 
However, this should not hold because the left hand sides is a non-terminating program and cannot refine the terminating assignment .

A t-simulation is used to compare bundle event structures without looking in details at the labels of events. It can be seen as a refinement order on the higher level structure of a concurrent program.  Once a sequential behaviour has to be checked, we use the previously defined functional equivalence on event structures with internal probabilities.

\begin{example}\label{ex:t-sim}
Consider a program variable  of type Boolean (with value  or ). A t-simulation from  to ~\footnote{ is an atomic nondeterministic-assignment, it cannot be interfered with.} is given by the dotted arrow in the following diagram:

This t-simulation refines two nondeterministic choices, one at the program structure level and the other at the atomic level.
\end{example}

\begin{proposition}
The t-simulation relation  is a preorder.
\end{proposition}

\begin{proof}
Reflexivity follows from the identity function and transitivity is obtained by composing t-simulations which will generate a new t-simulation. Notice that care should be taken with respect to the third property of a t-simulation. If ,  are t-simulations,  and , then  for some  of  such that . If , then it is possible that . However, since  is weakly maximal,  is also weakly maximal and we can find an event  such that  is weakly maximal and . We then map  to  in the t-simulation from  to .
\end{proof}

\begin{proposition}\label{pro:necessary-axioms}
If  are ipBES, then

\end{proposition}

\begin{proofsummary}
The constructions  and  result in the same event structure and similarly for associativity. 

For the implication~(\ref{eq:congruence}), let  be a t-simulation. We construct a t-simulation  inductively. We set . Let  and  such that  is a trace of . We write  for the restriction of  to the events occurring in . The inductive definition of  is:

Since the set of events of  and  are disjoint, the cases in the above definition of  are disjoint. That is,  is indeed a function and it satisfies the second property of a t-simulation. The last property is clear because if  is maximal in , then either  is maximal in  and  is maximal in , or  is maximal in  and  is maximal in . In both cases,  for some  and  is weakly maximal in .

Similarly, the other cases are shown by constructing t-simulations.
\end{proofsummary}

\begin{proof}
The constructions  and  result in the same event structure and similarly for the associativity. 



The Unfold \Eqn{eq:unfold} is clear because the left and right hand side event structures are exactly the same up to renaming of events.

Implication~(\ref{eq:+-monotony}) follows by considering the function . It is indeed a function because the sets of events  and  (resp. ) are disjoint. The property of a t-simulation follows directly because the set of traces  is the disjoint union  (similarly for ).

For case of sequential composition~(\ref{eq:monotony}), let  be a t-simulation from  to . It is clear that the function , such that  is a t-simulation.

For the Implication~(\ref{eq:congruence}), let  be a t-simulation. Let us construct a t-simulation  inductively. We set . Let  and  such that  is a trace of . We write  the restriction of  to the events occurring in . The inductive definition of  is:

Since the set of events of  and  are disjoint, the cases in the above definition of  are disjoint. That is,  is indeed a function and it satisfies the second property of a t-simulation. The last property is clear because if  is maximal in , then either  is maximal in  and  is maximal in , or  is maximal in  and  is maximal in . In both cases,  for some  and  is weakly maximal in .
\end{proof}

We now state the main result of this section, which is the backbone of our probabilistic rely-guarantee calculus. 


\begin{theorem}\label{thm:trace-imply-distribution}
Let  and  be feasible and terminating ipBES. Then  implies .
\end{theorem}

\begin{proofsummary}
The proof amounts to showing that, given an initial state  and a scheduler  of , there exists a scheduler  of  that generates exactly the same distribution as  from the state . The scheduler  is  constructed  inductively from the t-simulation from  to . 
\end{proofsummary}


\begin{proof}
Let  be a t-simulation from  to ,  be the initial state,  and  is the complete run of  on  from . We have to generate a scheduler  such that the measures  and   are equal i.e. they produce the same value for every state .

For every , we define  to be the set of minimal traces in , that is,

We now construct the scheduler . Let . We consider two cases:
\begin{itemize}
\item If  then we set , except for some particular maximal traces that are handled in  below. 
\item Otherwise, given a state , we define a normalisation factor 

and we set~\footnote{Notice if  for some  then  for every . In other words, none of these  will be scheduled at all. Hence,  need not be scheduled either.}

where  is the weight function such that , and  (if  is empty then ). The distribution  is chosen by  from , when scheduling .
\end{itemize}

Firstly, we show that  is indeed a scheduler on . The Property(\ref{pr:sched-dom}) of Definition~\ref{def:ipscheduler} is clear. Let us show the other properties. Let  and
let  be the weight function such that 

Indeed,  is in ~\footnote{The case  can be adapted easily because the numerator in the definition of  is also . For instance, we can assume that .} because  is convex and for each  and .
Hence  and  satisfies the Property (\ref{pr:sched-choice}) of \Defs{\ref{def:ipscheduler}}. As for Property (\ref{pr:sched-prob}), let  and let us compute the quantity 

for a fixed . Let us write .

From the second to the third expression, the two rightmost sums were merged into a single one because  ( is a function). It follows from Property~(\ref{pr:sched-prob}), applied on the weight  of , that
	
and hence  (c.f. Figure~\ref{fig:6-concrete-sched} for a concrete example). The last Property (\ref{pr:sched-consistent}) of \Defs{\ref{def:ipscheduler}} is clear because if , then the coefficient of  is  because . Hence, the product is also .

\begin{figure}

We have  because  and  (\Defs{\ref{def:ipscheduler}} Property (\ref{pr:sched-prob})).
\caption{An example showing that .}\label{fig:6-concrete-sched}
\end{figure}

Secondly, let  be the complete run of  with respect to . We now show by induction on  that 

where the empty sum evaluates to the identically zero distribution. The base case is clear because  where  is the initial state. Let us assume the above identity for  and let  such that  and . By definition of , if , we have:
\begin{footnotesize}

\end{footnotesize}
By continuing the above reasoning for all  (induction), , we obtain 

Hence, 

 We finally compute the sum . Notice firstly that  may not schedule some traces of . In particular, the third property in the definition of simulation implies that a maximal element of  may be mapped to a weakly maximal element of . Hence, we need to extend the scheduler  so that it is non-zero for exactly one maximal element from that weakly maximal trace. More precisely, if  is weakly maximal for some maximal trace , then there exists a sequence  such that  and . We extend  such that . This implies that . The other case is that  is maximal and belongs to the image of . In both cases, we have 

where  if  is in the image of , or  if there is such a  as above, otherwise, . Thus,  contains maximal traces only (if it is not empty). Since,  is a total function, the set  is a partition of  and we have 

i.e. we obtain .
\end{proof}

\begin{example}
Reconsider the t-simulation of Example~\ref{ex:t-sim}. By definition, the unique scheduler  on  satisfies:
\begin{itemize}
\item[-]  where

\item[-] , for .
\end{itemize}
The corresponding scheduler  on , constructed (as per the proof of \Thm{thm:trace-imply-distribution}) from  using the illustrated t-simulation, satisfies:
\begin{itemize}
\item[-]  and ,
\item[-]  and .
\end{itemize}
Since  is sequentially equivalent to , we can see that the scheduler  on  forces the final value of  to be  by resolving  and  as they were resolved in the program .
\end{example}

We now show that the binary Kleene star is preserved by the semantics map.

\begin{proposition}\label{pro:*-homomorphism}
For every non-zero, feasible and terminating event structure  and , we have .
\end{proposition}
\begin{proofsummary}
  Note that  is the least fixed point of the function  in \footnote{Notice that the least fixed point is in  but not . The reason is that  and  are elements of  because of feasibility and termination.}, and  satisfies  by construction of the sequences of bundle event structures defining . Therefore, \Thm{thm:trace-imply-distribution} and \Prop{pro:homomorphism} imply that .

The converse refinement  holds because every scheduler of  is the ``limit" of a sequence of schedulers used in the construction of .
\end{proofsummary}

\begin{proof}
For the binary Kleene product, since  is the least fixed point of  in \footnote{Notice that the least fixed point is in  but not . The reason is that  and  are elements of  because of feasibility and termination.}, and  satisfies 

by construction of the sequences of bundle event structures defining . Therefore, \Thm{thm:trace-imply-distribution} and \Prop{pro:homomorphism} imply that . 

Conversely, let  for some initial state . As in the case of \Prop{pro:homomorphism}, we assume that  is computed from a scheduler  on . We construct a sequence of schedulers  that ``converges" to  as follows. We set  to be any element of ,  if  is a trace of  or , otherwise, we set  where  (notice that  is applied to a different copy of  but this is not important as event names can be abstracted.). Inductively, we define 
  

Again,  is applied to the  copy of . Indeed, we have 
 
by construction. On the one hand, the sequence of distributions  forms a subset of . On the other hand, let  and let us denote 
	
If we denote by  the complete run of  on , then we have

The set  shrinks, when  increases, because every finite trace of  belongs to some set . Therefore, the last sum above is decreasing to . Hence, since  is a finite set, the sequence  converges (pointwise) to  in . Since  is topologically closed, we deduce that . Therefore, .
\end{proof}

\begin{proposition}\label{pro:get-rid-of-par}
Let  be two atomic programs and let  be two bundle event structures with internal probability, then 

where .
\end{proposition}

\begin{proofsummary}
  These inequations are again verified by explicitly constructing a t-simulation from the left-hand side to the right-hand side of the inequality. The following reasoning illustrates such a construction for \Eqn{eq:star-trans}.

  Denote by  and  (resp. ) the events that are labelled by  in the event structure associated to  (resp. ). We construct an operation  such that, given a trace  of  that does not contain any of the s, we define  to be the unique trace corresponding to  in  (i.e. with the same number of events labelled by ). A t-simulation from  to  is obtained by considering a function  such that  \end{proofsummary}

\begin{proof}
Let us denote by  and  (resp. ) the events that are labelled by  in the event structure associated to  (resp. ). Given a trace  of  that does not contain any of the s, we denote by  unique trace corresponding to  in  (i.e. with the same number of events labelled by ). 

A t-simulation from  to  is obtained by considering a function  such that 


The t-simulation~(\ref{eq:par-atom}) is constructed as follows. Let us abstract the event names, i.e.  would be a trace where each  is the label of a unique event. Every trace of  is a prefix of  or , for some . Every prefix of either trace corresponds to a unique trace of . For instance, the maximal trace  is associated to the weakly maximal trace  of . Figure~\ref{fig:messy-simulation} shows an explicit construction of the t-simulation.
\begin{figure}
\begin{small}

\end{small}
The ``obvious" arrows, such as an arrow from  to , have been left out to keep the picture clear.
\caption{The t-simulation from  to .}\label{fig:messy-simulation}
\end{figure}

The Simulation~(\ref{eq:par-nondet} )is similar. Every trace of  is a prefix of  or  or  or , where , , ,  and . Again, prefixes of the first two traces correspond to a unique trace of . The maximal trace  is again mapped to the weakly maximal trace . Similarly for the fourth case. This indeed results in a t-simulation.

The Simulation~(\ref{eq:par-seq}) is constructed as follows. Every trace of  is a prefix of  or  for some trace  and . We continue as in the previous case.
\end{proof}

\Prop{pro:get-rid-of-par} is used mainly to interleave the right operand  systematically with the internal structure of , while preserving the simulation order. More precisely, these equations are applied to generate algebraic proofs for the reduction of one expression into another, where the occurrence of  is pushed deeper into the sub-expressions (and possibly removed).


\section{Probabilistic rely-guarantee conditions}\label{sec:prgc}

Our first task towards the extension of the rely-guarantee method to probabilistic systems is to provide a suitable definition of a rely condition that contains sufficient quantitative information about the environment and the components of a system. 

From a relational point of view, as in Jones' thesis~\cite{Jon81}, a guarantee condition expresses a constraint between a state and its successor by running the relation as a nondeterministic program. Therefore, it is important to know whether some action is executed atomically or whether it is split into smaller components. 
For instance, when run in the same environment, a probabilistic choice between  and  produced from an \texttt{if\dots then\dots else} clause may behave differently from an atomic probabilistic assignment that assigns  and  to  with the exact same probability.



Without probability, a common example of a guarantee condition for a given program is the reflexive transitive closure with respect to  of the union of all atomic actions in that program~\cite{Hoa09a} which completely captures all possible ``effects" of the program. Such a closure property plays a crucial role in the algebraic proof of Rule~\ref{rule:rg-standard} is achieved through \Prop{pro:get-rid-of-par}. This construction was introduced by Jones~\cite{Jon81} and later refined by others~\cite{Din02,Jon12,Hoa09a}.

Non-probabilistic rely-guarantee conditions usually take the form  for some binary relation , defined on the state space of the studied program. The transitive closure of  with respect to the relational composition  is usually a desirable property. To obtain a probabilistic guarantee condition from a relation , we construct a probabilistic program   such that 

Equivalently,  is the convex closure of . The following proposition then follows from that construction.
\begin{proposition}\label{pro:transitive-convex-closure}
If a relation  is transitive, then the convex closure  of  satisfies .
\end{proposition}

\begin{proofsummary}
It follows immediately from the transitivity of  and the definition of .
\end{proofsummary}

\begin{proof}
Let  be a transitive relation,  its associated probabilistic program,  a state and  . We need to show that . By definition of the sequential composition  (\Eqn{eq:6-sequential-H}), there exists  and a deterministic program  such that . Let  such that , we are going to show that . We have:

The second equality follows from  for every . Similarly, the last equality follows from  for . The last expression reduces to , by transitivity of , which is an empty sum because . Therefore,  for every , that is .
\end{proof}

The convex closure of a relation , given in \Prop{pro:transitive-convex-closure}, sometimes provides a very general rely condition that is too weak to be useful in the probabilistic case. In practice, a probabilistic assignment is considered atomic and the correctness of many protocols is based on that crucial assumption. Hence the random choice and the writing of the chosen value into a program variable  is assumed to happen instantaneously and no other program can modify  during and in-between these two operations. Thus, probabilistic rely and guarantee conditions need to capture the probabilistic information in such an assignment.

\begin{example} Let  be a (integer) program variable with values bounded by  and . Let us write  for the program that assigns a random integer between two integers  and  to the variable . A probabilistic guarantee condition for that assignment is obtained from the probabilistic program  that satisfies, for every integer ,
  
The condition  specifies the convex set of all probabilistic deterministic programs whose atomic actions establish a state in  with probability at least . In particular,  is an overspecification of   where the rhs occurrence of  is evaluated to the initial value of . Since  is transitive, it can prove useful to deduce quantitative properties of .  \end{example}

In practice, constructing a useful transitive probabilistic rely-guarantee condition is difficult, but the standard technique is still valid: the strongest guarantee condition of a given program is the nondeterministic choice of all atomic actions found in that program.
\begin{definition}\label{def:rely}
A \emph{probabilistic rely} or \emph{guarantee condition}  is a probabilistic concurrent program such that .
\end{definition} 

In particular, the concurrent program  is a rely condition because 

holds in the event structure model (\Prop{pro:get-rid-of-par} \Eqn{eq:star-trans}). This illustrates the idea that a rely condition specifies an environment that can stutter or execute a sequence of actions that are bounded by . 

\section{Probabilistic rely-guarantee calculus}\label{sec:prg-rules}

In this section, we develop the rely-guarantee rules governing programs involving probability and concurrency. An example is given by Rule~\ref{rule:rg-standard}, which allows us check the safety properties of the subsystems and infer the correctness of the whole system in a compositional fashion. We provide a probabilistic version of that rule.

In the previous sections, we have developed the mathematical foundations needed for our interpretation of Hoare triples and \emph{guarantee} relations, namely, the sequential refinement  and simulation-based order . Following~\cite{Hoa09a}, we only adapt the orders in the algebraic interpretation of rely-guarantee quintuples (\Eqn{eq:rgspec}). That is, validity of probabilistic rely-guarantee quintuples is captured by

where  and  are probabilistic concurrent programs and  and  are rely-guarantee conditions. The first part is seen as a probabilistic instance of the contraction of~\cite{Arm14} which specifies the functional behaviour of  under a precondition . The second part uses the simulation order which is compositional and  very sensitive to the structural properties of the program.

The conditions  and  specify how the component  interacts with its environment. As we have discussed in the previous section, rely and guarantee conditions are obtained by taking  for some atomic probabilistic program . Therefore,  implies that all actions carried by events in  are either stuttering or satisfying the specification . This corresponds to the standard approach of Jones~\cite{Jon12,Jon81}.

The following rules are probabilistic extensions of the related rely-guarantee rules developed in~\cite{Hoa11,Jon12}. These rules are  sound with respect to the event structure semantics of Section~\ref{sec:es}.

\noindent{\textbf{Atomic action: }}
The rely-guarantee rule for an atomic statement  is provided by the equation

where  is the rely condition. This equation shows that a (background) program satisfying the rely condition  will not interfere with the low level operations involved in the atomic execution of . The programs will be interleaved.

\noindent{\textbf{Conditional statement:}}
The rely-guarantee rule for conditional statement is provided by the equation

This equation shows how a rely condition  distributes through branching structures. The tests  and  are assumed to be atomic and their disjunction is always \emph{true} (this is necessary for feasibility). This assumption may be too strong in general because  may involve the reading of some large data that is too expensive to be performed atomically. However, we may assume that such a reading is done before the guard  is checked and the non-atomic evaluation of the variables involved in  may be assigned to some auxiliary variable that is then checked atomically by .

\noindent{\textbf{Prefixing: }}
the sequential rely-guarantee rule for a probabilistic program expressed using prefixing. We have  

It generalises Rule~\ref{rule:atomic} and tells us that a rely condition  distributes through the prefixing operation. In other words, the program  and   should tolerate the same rely condition in order to prove any meaningful property of . This results from of our interpretation of  where no synchronisation is assumed. 

\noindent{\textbf{Concurrent execution:}}
in Rule~\ref{rule:rg-standard}, the concurrent composition  requires an environment that satisfies  to establish the postcondition . However, such an intersection is not readily accessible at the structural level of event structures. Therefore, the most general probabilistic extension of Rule~\ref{rule:rg-standard} which applies to our algebraic setting is:

where  is a rely condition such that  and .
The proof of this rule is exactly the same as in~\cite{Hoa11,Rab13}. In fact, we have , , , therefore \Eqn{eq:par-assoc} and Equational Implication~(\ref{eq:congruence}) imply 

and we obtain  by \Eqn{eq:monotony}. It follows from \Thm{thm:trace-imply-distribution} that . 

The conclusion does not contain any occurrence of , but by symmetry, it is also valid if  is substituted for . The combined rely condition  is constructed such that it is below  and . Indeed, if  have a greatest lower bound with respect to , then  can be taken as that bound, so that the strengthening of the rely is as week as possible. 

The above rule can be specialised by considering rely-guarantee conditions of the form , where  is an atomic probabilistic program. The following rule is expressed in exactly as in the standard case~\cite{Hoa11}. This is possible because probabilities are internal.

\begin{proposition}\label{pro:rule1}
The following rule is valid in BES:

where  and  is the nondeterministic choice on .
\end{proposition}

\begin{proof}
This follows from substituting  and  by respectively  and  in Rule~\ref{rule:rg-general}. Moreover  holds because  (\Eqn{eq:rely-closure}).
\end{proof}

Recall that the nondeterministic choice of  is obtained by the pointwise union followed by the necessary closure properties for the elements of . The intersection  is obtained by pointwise intersection.

\noindent{\textbf{Iteration:}}
a while program is modelled by using the binary Kleene star. The idea is to unfold the loop as far as necessary. The conditional and prefix (sequential) cases can then be applied on the unfolded structure to distribute the rely condition. That is, we write 

If  is sequential, then  can be ``interleaved" within the internal structure of  by applying the prefixing and conditional statement rules.

The sequential correctness is achieved by the usual generation of probability distributions, obtained from terminating sequential behaviours, on the ``totally" unfolded event structure (assuming that  is sequential). The sequential behaviours are usually obtained by interleaving the rely condition  through the internal structure of the unfolded loop. A bounded loop, such as a for loop, should be modelled using a sequence of sequential compositions or prefixing.

\section{Application: a faulty Eratosthenes sieve}\label{sec:application}

In this section, we show how to use the previously established rely-guarantee rules to verify a probabilistic property of a faulty Eratosthenes sieve, which is a quantitative variant Jones' example~\cite{Jon81}.

Let  be a natural number and . For each integer  such that , we consider a program  that sequentially removes all (strict) multiples of  from the shared set variable  with a fixed probability . More precisely, each thread  is implemented as the following program: 

where  is the integer division of  by . Each  can be seen as a faulty action that removes the product  from the current value of  with probability . The state space of each atomic deterministic program  is . In ,  is defined by . 
The whole system is specified by the concurrent execution 

where, in the sequel,  is computed without decimals.

Let    be the set of prime numbers in . Our goal is to compute a ``good" lower bound probability that the final state is , after executing the threads  concurrently, from the initial state .

We denote by  and 

a specification of a probabilistic program that removes  from the state  with at least probability  and does not add anything to it. We define ,  and  to be the probabilistic program such that  is the convex closure of . 

First, we show that every thread  guarantees . Second, we show that  establishes  when run in an environment satisfying , i.e. , using the atomic and prefix rules~\ref{rule:atomic} and~\ref{rule:prefix}. Finally, we  apply the concurrency rule~\ref{rule:rg-atom-rely} to deduce that the system  establishes all postconditions , when run in an environment satisfying .

\noindent{\textbf{Establising  and }}
 
On the one hand, it is clear that , for every , and thus  follows from the unfold~(\ref{eq:unfold}). On the other hand, let us show that . Multiple applications of the prefix-case give 

Since the right multiplication , by any program , is the lower adjoint in a Galois connection~\cite{Mci04}, the fixed point fusion theorem~\cite{Bac02} implies  

where the equality is in . Thus, 

follows from the fact that  is weaker than  (\Thm{thm:trace-imply-distribution}). The right hand side explicitly  states the interleaving of the rely condition  in-between the atomic executions in  as in~\cite{Jon12}. 

Moreover, since  is the probabilistic version of a transitive binary relation, \Prop{pro:transitive-convex-closure} implies that . Since  is a probabilistic Kleene algebra~\cite{Mci05}, the right induction law of pKA implies . This reduction of  to  illustrates the practical importance of transitive rely conditions. Therefore, 
where the left hand side is a sequential program (thus \Prop{pro:homomorphism} enables us to use the definition of sequential composition of ) directly
. Since , it remains to show that .

First we show that  and 
 . Let  and . By definition of the sequential composition in , there exists a probabilistic deterministic program  and a distribution  such that 
,
for every . Therefore, 


where the second equality follows from , for every . We deduce , i.e. , by observing

because  for every  such that  and  for every . Consequently, .
Similarly, we can show that  and thus . 

\noindent{\textbf{Establising the property of }}

Applying the rule~\ref{rule:rg-atom-rely}  times, we obtain, for every  such that ,

\noindent{\textbf{Inferring a lower bound for the probability of correctness}}

Unfortunately, Rule~\ref{rule:rg-atom-rely} does not give any explicit quantitative bound in term of probability for correctness. It does provide quantitative correctness, but all the probabilities are buried in the .

To obtain an explicit lower bound for the probability of removing all composite numbers, we first study the case of two threads that run concurrently. We know from Rule~\ref{rule:rg-atom-rely} that  and . Therefore, for every , we have  and  because there are  (resp. ) multiples of  (resp. ) in  (resp. ). Therefore,  and 

In the construction of the lower bound in \Eqn{e1601}, we have only used the modularity of measures and, therefore, it can be transformed into a more general rely-guarantee rule with explicit probabilities (\Prop{p1605}).

Given a subset  and , we write  if for every  we have . 

\begin{proposition}\label{p1605}
For every initial state  and for all subsets ,
\begin{footnotesize}

\end{footnotesize}
\end{proposition}

\begin{proof}
Let , we need to show that  with the above definition of  and . 
 
Let us define  to be the (single event) ipBES whose event is labelled by the probabilistic program  such that  else  for . Similarly, we define . Then the premises imply  and 
. By \Prop{pro:rule1}, we have 
Therefore  and . Modularity of finite measures implies that . Hence,  since .

The simulation  is also clear from \Prop{pro:rule1}.
\end{proof}

We know from the above discussion that 

Applying \Prop{p1605} on  and  yields

Thus  applications of \Prop{p1605} give 

The lower bound  sometimes provides a bad lower-approximation for the probability that the system establishes . However, it is clear that . 

In the particular case of , we have  and we only need to consider  and  so that . The plot of  in \Fig{fig:comparison} shows that  gives a positive lower bound when , the exact probability being . 

\noindent{\textbf{Refining the lower bound}}

We can use other internal properties of the system to obtain a better lower bound. It is clear that  is an invariant for every  (for ) and that all actions  (sequentially) commute with each other. Thus, we should obtain a better lower bound by noticing that the system is ``sequentially better" than the following interleaving:  removes all (strict) multiples of ,  removes all multiples of  assuming that all multiples of  (the lowest common multiple of  and  that is strictly greater than both) have been removed by , and so on~\footnote{The probability of removing all composite numbers is  usually above that bound because  can be removed by either  or .}. Thus 

where the square-bracketed terms are the numbers of multiples remove by threads with smaller indices. For example, before  runs,  removes  multiples of ,  removes  multiples of  (not multiples of ), thus  removes the remaining  multiples of . In the particular case of , this yields
 A graphical comparison of  and the actual probability is displayed in Figure~\ref{fig:comparison} for .

\begin{figure}
\centering
\includegraphics[width=0.75\linewidth]{./proba-comparison}
\caption{Comparison of the quantities  (dotted),  (dashed) and the actual probability  (solid).}
\label{fig:comparison}
\end{figure}

\noindent{\textbf{Establising the property of }}

Finally, notice that  which means that  can establish  with a positive probability. This issue is resolved by using a stronger guarantee property such as `` never removes ". Therefore,  never removes any prime numbers i.e. any element of , that does not contain all the positive prime numbers below , occurs with probability .
 
\section{Conclusion}

We have presented an extension of the rely-guarantee calculus that accounts for probabilistic programs running in a shared variable environment. The rely-guarantee rules are expressed and derived by and large by using the algebraic properties of a bundle event structure semantics for concurrent programs. 

In our approach, the specification of a probabilistic concurrent program is expressed with a rely-guarantee quintuple. Each quintuple is defined algebraically through the use of a sequential order , which captures all possible sequential behaviours when a suitable definition of the concurrency operation  is given, and a simulation order , which specifies the level of interference between the specified component and the environment. Various probabilistic rely-guarantee rules have been established and applied on a simple example of a faulty concurrent system. We have also shown some rules that provide explicit quantitative properties, including a lower bound for the probability of correctness. In particular, a better lower-approximation can be derived if further internal properties of the systems are known.

The framework developed in this paper has its current limitations. Firstly, neither the algebra nor the event structure model support non-terminating probabilistic concurrent programs at the moment. That is, the rely-guarantee rules of this paper can only be applied in a partial correctness setting. Secondly, the concrete model is restricted to programs with finite state spaces. We will focus particularly on the first limitation in our future work.


\bibliography{./tcs-qapl}

\begin{append}
\newpage
\appendix
\section{Axioms of Kleene algebra and related structures}\label{A:ka}
\subsection{Idempotent semiring}
An \emph{idempotent semiring} is an algebraic structure  such that, for every , the following axioms hold

\subsection{Kleene algebra}
A \emph{Kleene algebra} is an algebraic structure  where  is an idempotent semiring and the Kleene star  satisfies Kozen's axioms:

The induction laws~\ref{eq:*-linduction} (resp. ~\ref{eq:*-rinduction}) implies that  is the least fixed point of  (resp. ).
\subsection{Probabilistic Kleene algebra}
A \emph{probabilistic Kleene algebra} has the same signature as Kleene algebra but weakens the distributivity law~\ref{eq:+-rdist-seq} and the induction rule~\ref{eq:*-rinduction} to:

\subsection{Concurrent Kleene algebra}
A \emph{concurrent Kleene algebra} is composed of a Kleene algebra  and a commutative Kleene algebra  (i.e.  is commutative) linked by the interchange law:

\end{append}

\end{document}