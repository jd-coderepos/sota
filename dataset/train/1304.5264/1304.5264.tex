\documentclass[11pt]{article}
\usepackage[margin=2.54cm]{geometry}
\usepackage[dvipsnames,usenames]{color}
\usepackage{amsfonts,amsmath,amssymb,amsthm,mathtools}
\usepackage{paralist}
\usepackage{algorithmic,algorithm}
\usepackage{bm}
\usepackage{xspace}
\usepackage[pagebackref,letterpaper=true,colorlinks=true,pdfpagemode=none,urlcolor=blue,linkcolor=blue,citecolor=BrickRed,pdfstartview=FitH]{hyperref}
\usepackage{xspace,prettyref}
\usepackage{color}
\let\pref=\prettyref
\newcommand{\savehyperref}[2]{\texorpdfstring{\hyperref[#1]{#2}}{#2}}
\newcommand{\comment}[1]{ {\color{BrickRed} \footnotesize[#1]}\marginpar{\footnotesize\textbf{\color{red} To Do!}}}
\newcommand{\ignore}[1]{}



\newtheorem{theorem}{Theorem}[section]
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{claim}[theorem]{Claim}
\newtheorem{proposition}[theorem]{Proposition}
\newtheorem{corollary}[theorem]{Corollary}
\newtheorem{fact}[theorem]{Fact}
\newtheorem{conjecture}[theorem]{Conjecture}
\newtheorem{question}[theorem]{Question}
\newtheorem{example}[theorem]{Example}
\newtheorem{definition}[theorem]{Definition}
\newtheorem{remark}{Remark}
\newtheorem{observation}{Observation}

\def\eqdef{~\triangleq~}
\def\eps{\varepsilon}
\def\bar{\overline}
\def\floor#1{\lfloor {#1} \rfloor}
\def\ceil#1{\lceil {#1} \rceil}
\def\script#1{\mathcal{#1}}

\newenvironment{proofof}[1]{\smallskip\noindent{\bf Proof of #1:}}{\hspace*{\fill}\par}



\def\m{[m]}
\def\n{[n]}
\def\calB{{\mathcal B}}
\def\calM{{\mathcal M}}
\def\bD{{\boldsymbol\Delta}}
\def\P{\mathcal P}
\def\Q{\mathcal Q}
\def\F{\mathcal F}
\def\w{\hat{w}}
\def\indeg{{\tt in}}
\def\outdeg{{\tt out}}
\def\z{z^{\tt int}}
\def\supp{{\tt frac}}
\def\R{{\mathbb R}}
\def\ROI{{\sf ROI}}
\def\minROI{{\sf minROI}}
\def\spend{{\sf spend}}
\def\util{{\sf util}}
\def\x{{\bf x}}
\def\Exp{{\bf Exp}}

\newcommand{\bG}{{\bf G}}
\newcommand{\bK}{{\bf K}}
\newcommand{\bS}{{\bf S}}
\newcommand{\bT}{{\bf T}}

\newcommand{\cA}{{\cal A}}
\newcommand{\cB}{{\cal B}}
\newcommand{\cC}{{\cal C}}
\newcommand{\cD}{{\cal D}}
\newcommand{\cE}{{\cal E}}
\newcommand{\cF}{{\cal F}}
\newcommand{\cG}{{\cal G}}
\newcommand{\cH}{{\cal H}}
\newcommand{\cI}{{\cal I}}
\newcommand{\cJ}{{\cal J}}
\newcommand{\cL}{{\cal L}}
\newcommand{\cM}{{\cal M}}
\newcommand{\cP}{{\cal P}}
\newcommand{\cR}{{\cal R}}
\newcommand{\cS}{{\cal S}}
\newcommand{\cT}{{\cal T}}
\newcommand{\cU}{{\cal U}}
\newcommand{\cV}{{\cal V}}

\newcommand{\NN}{\mathbb{N}}
\newcommand{\RR}{\mathbb{R}}
\newcommand{\ZZ}{\mathbb{Z}}

\newcommand{\EX}{\hbox{\bf E}}


\newcommand{\ab}{\hbox{ab}}
\newcommand{\acc}{\hbox{acc}}
\newcommand{\argmin}{\hbox{argmin}}
\newcommand{\argmax}{\hbox{argmax}}
\newcommand{\proj}{\drop^{-1}}
\newcommand{\drop}{\hbox{drop}}
\newcommand{\rej}{\hbox{rej}}
\newcommand{\rest}[2]{{#1}_{\overline{#2}}}
\newcommand{\support}{\hbox{supp}}

\newcommand{\Sec}[1]{\hyperref[sec:#1]{\S\ref*{sec:#1}}} \newcommand{\Eqn}[1]{\hyperref[eqn:#1]{(\ref*{eqn:#1})}} \newcommand{\Clm}[1]{\hyperref[clm:#1]{Claim~\ref*{clm:#1}}} \newcommand{\Fig}[1]{\hyperref[fig:#1]{Figure~\ref*{fig:#1}}} \newcommand{\Tab}[1]{\hyperref[tab:#1]{Table~\ref*{tab:#1}}} \newcommand{\Thm}[1]{\hyperref[thm:#1]{Theorem~\ref*{thm:#1}}} \newcommand{\Lem}[1]{\hyperref[lem:#1]{Lemma~\ref*{lem:#1}}} \newcommand{\Prop}[1]{\hyperref[prop:#1]{Proposition~\ref*{prop:#1}}} \newcommand{\Cor}[1]{\hyperref[cor:#1]{Corollary~\ref*{cor:#1}}} \newcommand{\Def}[1]{\hyperref[def:#1]{Definition~\ref*{def:#1}}} \newcommand{\Alg}[1]{\hyperref[alg:#1]{Algorithm~\ref*{alg:#1}}} \newcommand{\Ex}[1]{\hyperref[ex:#1]{Example~\ref*{ex:#1}}} 

\begin{document}


\author{Deeparnab Chakrabarty
  \\\\ 
  Microsoft Research India\\
  {\tt dechakr@microsoft.com} \\
\and C. Seshadhri \\\\ 
Sandia National Labs, Livermore\thanks{Sandia National Laboratories is a multi-program laboratory managed and operated by Sandia Corporation, a wholly owned subsidiary of Lockheed Martin Corporation, for the U.S. Department of Energy's National Nuclear Security Administration under contract DE-AC04-94AL85000.} \\
{\tt scomand@sandia.gov}}


\title{An optimal lower bound for monotonicity testing over hypergrids}



\date{}
\maketitle
\def\D{{\mathbf D}}
\def\R{{\mathbf R}}

\begin{abstract} For positive integers , consider the hypergrid  with the coordinate-wise product partial ordering denoted by . 
A function  is monotone if , .
A function  is -far from monotone if at least an -fraction of values must be changed to make
 monotone. Given a parameter , a \emph{monotonicity tester} must distinguish with high probability a monotone function from one that is -far.

We prove that any (adaptive, two-sided) monotonicity tester for functions  must make
 queries. Recent upper bounds show the existence of 
query monotonicity testers for hypergrids. This closes the question of monotonicity testing for hypergrids
over arbitrary ranges. The previous best lower bound for general hypergrids was a non-adaptive bound
of . 
\end{abstract}

\section{Introduction} \label{sec:intro}

Given query access to a function , the field of \emph{property testing}~\cite{RS96,GGR98} deals
with the problem of determining properties of  without reading all of it.
Monotonicity testing~\cite{GGLRS00} is a classic problem in property testing. Consider a function ,
where  is some partial order given by ``", and  is a total order. The function  is monotone
if for all  (in ), . The \emph{distance to monotonicity} of  is the minimum
fraction of values that need to be modified to make  monotone. More precisely, define the distance between functions
 as . Let  be the set of all monotone functions.
Then the distance to monotonicity of  is .

A function is called -far from monotone if the distance to monotonicity is at least .
A \emph{property tester for monotonicity} is a, possibly randomized, algorithm that takes as input a distance parameter , error parameter , 
and query access to an arbitrary . If  is monotone, then the tester must accept with probability .
If it is -far from monotone, then the tester rejects with probability . (If neither, then the tester
is allowed to do anything.) The aim is to design a property tester using as few queries as possible.
A tester is called \emph{one-sided} if it always accepts a monotone function. A tester is called \emph{non-adaptive}
if the queries made do not depend on the function values. The most general tester is an adaptive two-sided tester.

Monotonicity testing has a rich history and the hypergrid domain, , has received special attention.
The boolean hypercube () and the total order () are special instances of hypergrids.
Following a long line of work~\cite{EKK+00, GGLRS00,DGLRRS99,LR01,FLNRRS02,AC04,E04,HK04,PRR04,ACCL04,BRW05,BBM11}, 
previous work of the authors~\cite{ChSe13} shows the existence of -query
monotonicity testers. Our result is a matching adaptive lower bound that is optimal in all parameters
(for unbounded range functions).
This closes the
question of monotonicity testing for unbounded ranges on hypergrids.
This is also the first adaptive bound for monotonicity testing on general hypergrids.

\begin{theorem} \label{thm:main}
Any (adaptive, two-sided) monotonicity tester for functions  requires  queries.
\end{theorem}

\subsection{Previous work} \label{sec:prev}

The problem of monotonicity testing was introduced by Goldreich et al~\cite{GGLRS00}, with an 
tester for functions . The first tester for general hypergrids was given
by Dodis et al~\cite{DGLRRS99}. The upper bound of  for monotonicity testing was recently proven
in~\cite{ChSe13}. We refer the interested reader to the introduction of~\cite{ChSe13} for a more detailed history of previous upper bounds.

There have been numerous lower bounds for monotonicity testing. We begin by summarizing the state of the art.
The known adaptive lower bounds are  for the total order  by Fischer~\cite{E04},
and  for the boolean hypercube  by Brody~\cite{Br13}. For general hypergrids,
Blais, Raskhodnikova, and Yaroslavtsev~\cite{BlJh+12} recently proved the first result, a non-adaptive lower bound of .
\Thm{main} is the first adaptive bound for monotonicity testing on hypergrids and is optimal (for arbitrary ranges) in all parameters.


Now for the chronological documentation. The first lower bound was the non-adaptive bound of  for the total order  by Ergun et al~\cite{EKK+00}.
This was extended by Fischer~\cite{E04} to an (optimal) adaptive bound. For the hypercube domain ,
Fischer et al~\cite{FLNRRS02} proved the first non-adaptive lower bound of . (This was proven
even for the range .) This was improved to  by Br\"{i}et et al~\cite{BCG+10}.
Blais, Brody, and Matulef~\cite{BBM11} gave an ingenious reduction from communication complexity
to prove an adaptive, two-sided bound of . (Honing this reduction, Brody~\cite{Br13} improved this bound to .)
The non-adaptive lower bounds of Blais, Raskhodnikova, and Yaroslavtsev~\cite{BlJh+12} were also achieved
through communication complexity reductions.

We note that our theorem only holds when the range is , while some previous results hold for restricted
ranges. The results of~\cite{BBM11, Br13} provide lower bounds for range .
The non-adaptive bound of~\cite{BlJh+12} holds even when the range is . In that sense,
the communication complexity reductions provide stronger lower bounds than our result.

\subsection{Main ideas} \label{sec:ideas}

The starting point of this work is the result of Fischer~\cite{E04}, an adaptive lower bound for monotonicity
testing for functions . He shows that adaptive testers can be converted to comparison-based
testers, using Ramsey theory arguments. A comparison-based tester for  can be easily converted to a non-adaptive
tester, for which an  bound was previously known. We make a fairly simple observation. The main part of Fischer's proof
actually goes through for functions over \emph{any partial order}, so it suffices to prove lower bounds
for comparison-based testers. (The reduction to non-adaptive testers only holds for .)

We then prove a comparison-based lower bound of 
for the domain . 
As usual, Yao's minimax lemma allows us to prove determinstic lower bounds over some distribution of functions.
The major challenge in proving (even non-adaptive) lower bounds for monotonicity is that the tester might make decisions
based on the actual values that it sees. Great care is required to construct a distribution over functions
whose monotonicity status cannot be decided by simply looking at the values.
But a comparison-based tester has no such power, and
optimal lower bounds over all parameters can be obtained with a fairly clean distribution.

\section{The reduction to comparison based testers} \label{sec:prelim}

Consider the family of functions , where  is some partial order, and .
We will assume that  always takes distinct values, so . Since we are proving
lower bounds, this is no loss of generality.

\begin{definition} \label{def:tester}
An algorithm  is a \emph{-monotonicity tester}
if  has the following properties. For any , the algorithm  makes  (possibly randomized) queries to 
and then outputs either ``accept" or ``reject". If  is monotone, then  accepts with probability .
If  is -far from monotone, then  rejects with probability .
\end{definition}
\def\acc{{\tt acc}}
\def\rej{{\tt rej}}
\def\x{{\mathbf x}}
\def\a{{\mathbf a}}


Given a positive integer , let  denote the collection of {\em ordered}, -tupled vectors with each entry in .
We define two symbols \acc~ and \rej, and denote .
Any -tester can be completely specified by the following family of functions.
For all , , , we consider a function , with the semantic that for any ,  denotes the probability the tester queries  as the th query, given that the 
first  queries are  and  for . By querying  we imply returning accept or reject. These functions satisfy the following properties.


\Eqn{dist} ensures the decisions of the tester at step  must form a probability distribution. \Eqn{time} implies that the tester makes at most  queries.


For any positive integer , let  denote {\em unordered} sets of  of cardinality . For reasons that will soon become clear, we introduce new functions as follows. For each ,  , , and {\em each permutation} , we associate functions , with the semantic


That is,  sorts the answers in  in increasing order, permutes it according to , and passes the permuted ordered tuple to . Any adaptive tester can be specified by these functions. The important point to note is that they are finitely many such functions; their number is upper bounded by . These -functions allow us to define comparison based testers.


\begin{definition} \label{def:comp}
A monotonicity tester  is \emph{comparison-based} if for all ,, and permutations , the function  is a constant function on . 
In other words, the th decision of the tester given that the first  questions is , depends only on the {\em ordering} of the answers received, and not on the values of the answers.
\end{definition}

The following theorem is implicit in the work of Fischer~\cite{E04}.

\begin{theorem} \label{thm:fischer} Suppose there exists a -monotonicity tester
for functions . Then there exists a comparison-based -monotonicity tester
for functions .
\end{theorem}

This implies that a comparison-based lower bound suffices for proving a general lower bound on monotonicity testing.
We provide a proof of the above theorem in the next section for completeness.

\subsection{Performing the reduction} \label{sec:comp}

We basically present Fischer's argument, observing that  can be any partial order. 
A monotonicity tester is called \emph{discrete} if the corresponding functions  can
only take values in  for some finite . Note that this implies the functions  also take discrete values.

\begin{claim} \label{clm:discrete} Suppose there exists a -monotonicity tester 
for functions . Then there exists a discrete -monotonicity tester for these functions.
\end{claim}
\def\p{\hat{p}}

\begin{proof} We do a rounding on the -functions. Let .
Start with the -functions of the -tester .
For , , , let 
 be the largest value in 
at most . 
Set  so that \Eqn{dist} is maintained. 

Note that for  , if , then 

Furthermore, .


The -functions describe a new discrete tester  that makes at most  queries. We argue that  is a -tester.
Given a function  that is either monotone or -far from monotone, 
consider a sequence of queries  after which  returns a {\em correct} decision . 
Call such a sequence good, and let  denote the probability this occurs. We know that the sum of probabilities over all good query sequences is at least . Now,


Two cases arise. suppose all of the probabilities in the RHS are . Then, the probability of this good sequence arising in  is at least .
Otherwise, suppose some probability in the RHS is . Then the total probability mass on such good sequences in  is atmost .
Therefore, the probability of good sequences in  is at least .
That is,  is a  tester.
\end{proof}

\ignore{
Henceforth, we focus on discrete testers. We use the notation
 for sets of size  in .
As defined, the -functions have a domain , but it will be preferable to replace this with . 
This will
need some additional notation. Consider . Let  denote the
discrete set of possible probability values.


Note that any element of  can be mapped to an element of  and function .
More precisely, suppose the function  has the argument ,
where the 's are in sorted order. The output value is the probability of selection  as the next query
when , , . So the tester formulation
of the previous section can be converted to this form, and hence any property tester can represented
by this finite family of functions.

The notion of a comparison-based tester becomes quite clean now. The functions 
are constant functions iff the tester is comparison-based. 


\begin{claim} \label{clm:map} Consider some explicit strictly monotone function . Consider the tester 
that, given input function , actually runs  on . Then  is a  tester.
\end{claim}

\begin{proof} Since  is a strictly monotone function, the distance to monotonicity of  and 
are identical. If  is monotone or -far from monotone, the probability that  errors of 
is at most .
\end{proof}
}
\def\col{{\tt col}}


We introduce some Ramsey theory terminology. For any positive integer , a {\em finite} coloring of  is a function 
for some finite number . An infinite set  is called {\em monochromatic} w.r.t   if for all sets , . A {\em -wise} finite coloring of  is a collection of  colorings
. (Note that each coloring is over different sized tuples.) 
An infinite set  is -wise monochromatic if  is monochromatic w.r.t. all the 's.

The following is a simple variant of Ramsey's original theorem.
(We closely follow the proof of Ramsey's theorem as given in Chap V1, Theorem 4 of~\cite{Bol00}.)




\begin{theorem} \label{thm:ramsey} For any -wise  finite coloring of ,
there is an infinite -wise monochromatic set .
\end{theorem}
\begin{proof} We proceed by induction on . If , then this is trivially true; let  be
the maximum color class. Since the coloring is finite,  is infinite.
We will now iteratively construct an infinite set of  via induction.

Start with  being the minimum element in . Consider a -wise coloring of 
, where .
By the induction hypothesis, there exists an infinite -wise monochromatic
set  with respect to coloring s. 
That is, for , and any set  with , we have 
, say.
\def\C{{\mathbf C}}
Denote the collection of these colors as a vector .

 Subsequently, let  be the minimum element in , and consider the -wise coloring  of  where  for .
Again, the induction hypothesis yields an infinite -wise monochromatic set  as before, and similarly the vector . 
Continuing this procedure, 
we get an infinite sequence  of natural numbers, an infinite sequence
of vectors of  colors , and an infinite nested sequence of infinite sets .
Every  contains  and by construction, any set , , , 
has color . Since there are only finitely many colors, some vector of colors occurs infinitely often as . The corresponding
infinite sequence of elements  is -wise monochromatic.
\end{proof}



\begin{proof} (of \Thm{fischer}) 
Suppose there exists a -tester for functions . We need to show there is a comparison-based -tester for such functions.

By \Clm{discrete}, there is a discrete -tester . Equivalently, we have the functions  as described in the previous section.
We now describe a -wise finite coloring of . 
Consider .
Given a set ,  is a vector indexed by , where , , and  is a -permutation, whose entry is .
The domain is finite, so the number of dimensions is finite.
Since the tester is discrete, the number of possible colors entries is finite.  
Applying \Thm{ramsey}, we know the existence of a -wise monochromatic infinite set . We have the property that for any , and any two sets , we have . That is, the algorithm  is a comparison based tester for functions with range . 



Consider the strictly monotone map , where  is the th element of   in sorted order. Now given any function , consider the function . 
Consider an algorithm  which on input  runs  on . More precisely, whenever  queries a point , it gets answer .  Observe that if  is monotone (or -far from monotone), then so is , and therefore, the algorithm  is a -tester of . Since the range of  is ,  
 is comparison-based.
\end{proof}

\section{Lower bounds} \label{sec:dist}

\def\f{\widetilde{f}}
\def\v{{\tt val}}
We assume that  is a power of , set , and think of  as . 
For any number , we think of the binary representation as  as an -bit vector ,
where  is the least significant bit.

Consider the following canonical, one-to-one mapping .
For any , we concatenate their binary representations in order 
to get a -bit vector . Hence, we can transform a function 
into a function  by defining .


We will now describe a distribution of functions over the boolean hypercube with equal mass on monotone and -far from monotone functions. The key property is that for a function drawn from this distribution, any deterministic comparison based algorithm errs in classifying it with non-trivial probability. 
This property will be used in conjunction with the above mapping to get our final lower bound.


\subsection{The hard distribution} \label{sec:hard}

We focus on functions . (Eventually, we set .)
Given any , we let  denote the number for which  is the binary representation. Here,  denotes the least significant bit of . 

For convenience, we let  be a power of . For , we let  

Note that 's partition the hypercube, with each .
In fact, each  is a subhypercube of dimension , with the minimal element having all zeros in the  least significant bits, and the maximal element having all ones in those.

We describe a distribution  on functions. 
The support of  consists ,
and  functions indexed as  with  and , defined as follows.


The distribution  puts probability mass  on the function  and  on each of the 's. 
All these functions take distinct values on their domain.
Note that  induces a total order on .\smallskip

\noindent
\textbf{The distinguishing problem:} Given query access to a random function  from , we want a deterministic comparison-based algorithm
that declares that  or . We refer to any such algorithm as a \emph{distinguisher}. 
Naturally, we say that the distinguisher errs on  if it's declaration is wrong.
Our main lemma is the following.

\begin{lemma} \label{lem:main-hard} Any deterministic comparison-based distinguisher that makes less than  queries errs
with probability at least .
\end{lemma}

\noindent
The following proposition allows us to focus on {\em non-adaptive} comparison based testers. 


\begin{proposition}	\label{prop:comp}
Given any deterministic comparison-based distinguisher  for  that makes at most  queries, there exists a deterministic {\em non-adaptive} comparison-based distinguisher  making at most  queries whose probability of error on  is at most that of .
\end{proposition}
\def\ans{{\tt ans}}
\begin{proof}
We represent  as a comparison tree. For any path in , the total number of distinct domain points involved in comparisons is at most .
Note that  is a total order, since for any  either  or vice versa.
For any comparison in , there is an outcome inconsistent with this ordering. (An outcome ``"
where  is inconsistent with the total order.)
We construct a comparison tree 
where we simply reject whenever a comparison is inconsistent with the total order, and otherwise mimics . 
The comparison tree of  has an error probability at most that of  (since it may reject a few ), and is just a path. Hence, it
can be modeled as a non-adaptive distinguisher. We query upfront all the points involving points on this path, and make the relevant comparisons
for the output.
\end{proof}





\def\v{{\tt val}}

\noindent
Combined with \Prop{comp}, the following lemma completes the proof of \Lem{main-hard}.
\begin{lemma}\label{lem:hard}
Any deterministic, non-adaptive, comparison-based distinguisher  making fewer than  queries, errs with probability at least .
\end{lemma}
\begin{proof} 



Let  be the set of points queried by the distinguisher. Set ; these form a partition of .
We say that a pair of points  \emph{captures} the (unique) coordinate , if  is the largest
coordinate where . (By largest coordinate, we refer to the value of the index.)
For a set  of points, we say  captures coordinate  if there is a pair in  that captures .

\begin{claim}\label{clm:viol}
For any , if the algorithm distinguishes between  and , then  captures .
\end{claim}
\begin{proof} 
If the algorithm distinguishes between  and , there must exist  such that
  and . We claim that  and  capture ; this will also imply they lie in the same  since the  most significant bit of  and  are the same.



Firstly, observe that we must have  and ; otherwise,  contradicting the supposition. Now suppose  don't capture  implying there exists  which is the largest coordinate at which they differ. Since  we have  and . Therefore,
we have 
So,  capture  and lie in the same . If , then again . Therefore,  captures .
\end{proof}


\noindent
The following claim allows us to complete the proof of the lemma.
\begin{claim}\label{clm:cap} A set  captures at most  coordinates.
\end{claim}

\begin{proof} We prove by induction on . When , this is trivially true.
Otherwise, pick the largest coordinate  captured by  and let  and . 
By induction,  captures at most  coordinates, and  captures at most  coordinates.
Pairs  only capture coordinate . Therefore, the total number of captured coordinates is at most .
\end{proof}

\noindent

If , then there exist at least  values of 
such that . 
By \Clm{cap}, each such  captures at most  coordinates.
Therefore, there exist at least 
 functions 's that are indistinguishable from the monotone function  to a comparison-based procedure
that queries . 
This implies the distinguisher must err (make a mistake on either these 's or ) with probability at least .
\end{proof}

\subsection{The final bound}
\def\v{{\tt val}}

Recall, given  function , we have 
the function  by defining .
We start with the following observation.

\begin{proposition}\label{prop:dist}
The function  is monotone and
every  is -far from being monotone.
\end{proposition}

\begin{proof} Let  and  be elements in  such that .
We have , so  is monotone.
For the latter, it suffices to exhibit a matching of violated pairs of cardinality  for . This is 
given by pairs  where  and  only differ in their
th coordinate, and are both contained in . Note that these pairs are comparable in 
and are violations.
\end{proof}


\begin{theorem}\label{thm:hc}
Any -monotonicity tester for , must have .
\end{theorem}

\begin{proof} By \Thm{fischer}, it suffices to show this for comparison-based  testers.
By Yao's minimax lemma, it suffices to produce a distribution  over functions  such
that any deterministic comparison-based -monotonicity tester for  must have ,
where .

Consider the distribution  where we generate  from  and output . 
Suppose . By \Prop{dist}, the deterministic comparison based monotonicity tester acts as a determinisitic comparison-based distinguisher
for 
making fewer than  queries, contradicting \Lem{hard}.
\end{proof}

\section{Conclusion}
In this paper, we exhibit a lower bound of  queries on adaptive, two-sided monotonicity testers for functions , matching the upper bound of  queries of~\cite{ChSe13}. Our proof hinged on two things: that for monotonicity on any partial order one can focus on comparison-based testers, and a lower bound on comparison-based testers for the hypercube domain.  Some natural questions are left open. Can one focus on some restricted class of testers for the Lipschitz property, and more generally, can one prove adaptive, two-sided lower bounds for the Lipschitz property testing on the hypergrid/cube? 
Currently, a -query non-adaptive lower bound is known for the problem~\cite{BlJh+12}.
Can one prove comparison-based lower bounds for monotonicity testing on a general -vertex poset? For the latter problem, there is a -query non-adaptive tester, and a -query non-adaptive, two-sided error lower bound~\cite{FLNRRS02}.
Our methods do not yield any results for bounded ranges, but there are significant gaps in our understanding for that regime. 
For monotonicity testing of boolean functions , the best adaptive lower bound
of , while the best non-adaptive bound is ~\cite{FLNRRS02}. 

\bibliographystyle{alpha}
\bibliography{derivative-testing}

\end{document}
