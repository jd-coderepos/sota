\pdfoutput=1


\documentclass[11pt]{article}

\usepackage[]{emnlp2021}

\usepackage{times}
\usepackage{latexsym}

\usepackage[T1]{fontenc}


\usepackage[utf8]{inputenc}

\usepackage{microtype}





\usepackage{amsmath,amsfonts,bm}

\newcommand{\figleft}{{\em (Left)}}
\newcommand{\figcenter}{{\em (Center)}}
\newcommand{\figright}{{\em (Right)}}
\newcommand{\figtop}{{\em (Top)}}
\newcommand{\figbottom}{{\em (Bottom)}}
\newcommand{\captiona}{{\em (a)}}
\newcommand{\captionb}{{\em (b)}}
\newcommand{\captionc}{{\em (c)}}
\newcommand{\captiond}{{\em (d)}}

\newcommand{\newterm}[1]{{\bf #1}}


\def\figref#1{figure~\ref{#1}}
\def\Figref#1{Figure~\ref{#1}}
\def\twofigref#1#2{figures \ref{#1} and \ref{#2}}
\def\quadfigref#1#2#3#4{figures \ref{#1}, \ref{#2}, \ref{#3} and \ref{#4}}
\def\secref#1{section~\ref{#1}}
\def\Secref#1{Section~\ref{#1}}
\def\twosecrefs#1#2{sections \ref{#1} and \ref{#2}}
\def\secrefs#1#2#3{sections \ref{#1}, \ref{#2} and \ref{#3}}
\def\eqref#1{equation~\ref{#1}}
\def\Eqref#1{Equation~\ref{#1}}
\def\plaineqref#1{\ref{#1}}
\def\chapref#1{chapter~\ref{#1}}
\def\Chapref#1{Chapter~\ref{#1}}
\def\rangechapref#1#2{chapters\ref{#1}--\ref{#2}}
\def\algref#1{algorithm~\ref{#1}}
\def\Algref#1{Algorithm~\ref{#1}}
\def\twoalgref#1#2{algorithms \ref{#1} and \ref{#2}}
\def\Twoalgref#1#2{Algorithms \ref{#1} and \ref{#2}}
\def\partref#1{part~\ref{#1}}
\def\Partref#1{Part~\ref{#1}}
\def\twopartref#1#2{parts \ref{#1} and \ref{#2}}

\def\ceil#1{\lceil #1 \rceil}
\def\floor#1{\lfloor #1 \rfloor}
\def\1{\bm{1}}
\newcommand{\train}{\mathcal{D}}
\newcommand{\valid}{\mathcal{D_{\mathrm{valid}}}}
\newcommand{\test}{\mathcal{D_{\mathrm{test}}}}

\def\eps{{\epsilon}}


\def\reta{{\textnormal{}}}
\def\ra{{\textnormal{a}}}
\def\rb{{\textnormal{b}}}
\def\rc{{\textnormal{c}}}
\def\rd{{\textnormal{d}}}
\def\re{{\textnormal{e}}}
\def\rf{{\textnormal{f}}}
\def\rg{{\textnormal{g}}}
\def\rh{{\textnormal{h}}}
\def\ri{{\textnormal{i}}}
\def\rj{{\textnormal{j}}}
\def\rk{{\textnormal{k}}}
\def\rl{{\textnormal{l}}}
\def\rn{{\textnormal{n}}}
\def\ro{{\textnormal{o}}}
\def\rp{{\textnormal{p}}}
\def\rq{{\textnormal{q}}}
\def\rr{{\textnormal{r}}}
\def\rs{{\textnormal{s}}}
\def\rt{{\textnormal{t}}}
\def\ru{{\textnormal{u}}}
\def\rv{{\textnormal{v}}}
\def\rw{{\textnormal{w}}}
\def\rx{{\textnormal{x}}}
\def\ry{{\textnormal{y}}}
\def\rz{{\textnormal{z}}}

\def\rvepsilon{{\mathbf{\epsilon}}}
\def\rvtheta{{\mathbf{\theta}}}
\def\rva{{\mathbf{a}}}
\def\rvb{{\mathbf{b}}}
\def\rvc{{\mathbf{c}}}
\def\rvd{{\mathbf{d}}}
\def\rve{{\mathbf{e}}}
\def\rvf{{\mathbf{f}}}
\def\rvg{{\mathbf{g}}}
\def\rvh{{\mathbf{h}}}
\def\rvu{{\mathbf{i}}}
\def\rvj{{\mathbf{j}}}
\def\rvk{{\mathbf{k}}}
\def\rvl{{\mathbf{l}}}
\def\rvm{{\mathbf{m}}}
\def\rvn{{\mathbf{n}}}
\def\rvo{{\mathbf{o}}}
\def\rvp{{\mathbf{p}}}
\def\rvq{{\mathbf{q}}}
\def\rvr{{\mathbf{r}}}
\def\rvs{{\mathbf{s}}}
\def\rvt{{\mathbf{t}}}
\def\rvu{{\mathbf{u}}}
\def\rvv{{\mathbf{v}}}
\def\rvw{{\mathbf{w}}}
\def\rvx{{\mathbf{x}}}
\def\rvy{{\mathbf{y}}}
\def\rvz{{\mathbf{z}}}

\def\erva{{\textnormal{a}}}
\def\ervb{{\textnormal{b}}}
\def\ervc{{\textnormal{c}}}
\def\ervd{{\textnormal{d}}}
\def\erve{{\textnormal{e}}}
\def\ervf{{\textnormal{f}}}
\def\ervg{{\textnormal{g}}}
\def\ervh{{\textnormal{h}}}
\def\ervi{{\textnormal{i}}}
\def\ervj{{\textnormal{j}}}
\def\ervk{{\textnormal{k}}}
\def\ervl{{\textnormal{l}}}
\def\ervm{{\textnormal{m}}}
\def\ervn{{\textnormal{n}}}
\def\ervo{{\textnormal{o}}}
\def\ervp{{\textnormal{p}}}
\def\ervq{{\textnormal{q}}}
\def\ervr{{\textnormal{r}}}
\def\ervs{{\textnormal{s}}}
\def\ervt{{\textnormal{t}}}
\def\ervu{{\textnormal{u}}}
\def\ervv{{\textnormal{v}}}
\def\ervw{{\textnormal{w}}}
\def\ervx{{\textnormal{x}}}
\def\ervy{{\textnormal{y}}}
\def\ervz{{\textnormal{z}}}

\def\rmA{{\mathbf{A}}}
\def\rmB{{\mathbf{B}}}
\def\rmC{{\mathbf{C}}}
\def\rmD{{\mathbf{D}}}
\def\rmE{{\mathbf{E}}}
\def\rmF{{\mathbf{F}}}
\def\rmG{{\mathbf{G}}}
\def\rmH{{\mathbf{H}}}
\def\rmI{{\mathbf{I}}}
\def\rmJ{{\mathbf{J}}}
\def\rmK{{\mathbf{K}}}
\def\rmL{{\mathbf{L}}}
\def\rmM{{\mathbf{M}}}
\def\rmN{{\mathbf{N}}}
\def\rmO{{\mathbf{O}}}
\def\rmP{{\mathbf{P}}}
\def\rmQ{{\mathbf{Q}}}
\def\rmR{{\mathbf{R}}}
\def\rmS{{\mathbf{S}}}
\def\rmT{{\mathbf{T}}}
\def\rmU{{\mathbf{U}}}
\def\rmV{{\mathbf{V}}}
\def\rmW{{\mathbf{W}}}
\def\rmX{{\mathbf{X}}}
\def\rmY{{\mathbf{Y}}}
\def\rmZ{{\mathbf{Z}}}

\def\ermA{{\textnormal{A}}}
\def\ermB{{\textnormal{B}}}
\def\ermC{{\textnormal{C}}}
\def\ermD{{\textnormal{D}}}
\def\ermE{{\textnormal{E}}}
\def\ermF{{\textnormal{F}}}
\def\ermG{{\textnormal{G}}}
\def\ermH{{\textnormal{H}}}
\def\ermI{{\textnormal{I}}}
\def\ermJ{{\textnormal{J}}}
\def\ermK{{\textnormal{K}}}
\def\ermL{{\textnormal{L}}}
\def\ermM{{\textnormal{M}}}
\def\ermN{{\textnormal{N}}}
\def\ermO{{\textnormal{O}}}
\def\ermP{{\textnormal{P}}}
\def\ermQ{{\textnormal{Q}}}
\def\ermR{{\textnormal{R}}}
\def\ermS{{\textnormal{S}}}
\def\ermT{{\textnormal{T}}}
\def\ermU{{\textnormal{U}}}
\def\ermV{{\textnormal{V}}}
\def\ermW{{\textnormal{W}}}
\def\ermX{{\textnormal{X}}}
\def\ermY{{\textnormal{Y}}}
\def\ermZ{{\textnormal{Z}}}

\def\vzero{{\bm{0}}}
\def\vone{{\bm{1}}}
\def\vmu{{\bm{\mu}}}
\def\vtheta{{\bm{\theta}}}
\def\va{{\bm{a}}}
\def\vb{{\bm{b}}}
\def\vc{{\bm{c}}}
\def\vd{{\bm{d}}}
\def\ve{{\bm{e}}}
\def\vf{{\bm{f}}}
\def\vg{{\bm{g}}}
\def\vh{{\bm{h}}}
\def\vi{{\bm{i}}}
\def\vj{{\bm{j}}}
\def\vk{{\bm{k}}}
\def\vl{{\bm{l}}}
\def\vm{{\bm{m}}}
\def\vn{{\bm{n}}}
\def\vo{{\bm{o}}}
\def\vp{{\bm{p}}}
\def\vq{{\bm{q}}}
\def\vr{{\bm{r}}}
\def\vs{{\bm{s}}}
\def\vt{{\bm{t}}}
\def\vu{{\bm{u}}}
\def\vv{{\bm{v}}}
\def\vw{{\bm{w}}}
\def\vx{{\bm{x}}}
\def\vy{{\bm{y}}}
\def\vz{{\bm{z}}}

\def\evalpha{{\alpha}}
\def\evbeta{{\beta}}
\def\evepsilon{{\epsilon}}
\def\evlambda{{\lambda}}
\def\evomega{{\omega}}
\def\evmu{{\mu}}
\def\evpsi{{\psi}}
\def\evsigma{{\sigma}}
\def\evtheta{{\theta}}
\def\eva{{a}}
\def\evb{{b}}
\def\evc{{c}}
\def\evd{{d}}
\def\eve{{e}}
\def\evf{{f}}
\def\evg{{g}}
\def\evh{{h}}
\def\evi{{i}}
\def\evj{{j}}
\def\evk{{k}}
\def\evl{{l}}
\def\evm{{m}}
\def\evn{{n}}
\def\evo{{o}}
\def\evp{{p}}
\def\evq{{q}}
\def\evr{{r}}
\def\evs{{s}}
\def\evt{{t}}
\def\evu{{u}}
\def\evv{{v}}
\def\evw{{w}}
\def\evx{{x}}
\def\evy{{y}}
\def\evz{{z}}

\def\mA{{\bm{A}}}
\def\mB{{\bm{B}}}
\def\mC{{\bm{C}}}
\def\mD{{\bm{D}}}
\def\mE{{\bm{E}}}
\def\mF{{\bm{F}}}
\def\mG{{\bm{G}}}
\def\mH{{\bm{H}}}
\def\mI{{\bm{I}}}
\def\mJ{{\bm{J}}}
\def\mK{{\bm{K}}}
\def\mL{{\bm{L}}}
\def\mM{{\bm{M}}}
\def\mN{{\bm{N}}}
\def\mO{{\bm{O}}}
\def\mP{{\bm{P}}}
\def\mQ{{\bm{Q}}}
\def\mR{{\bm{R}}}
\def\mS{{\bm{S}}}
\def\mT{{\bm{T}}}
\def\mU{{\bm{U}}}
\def\mV{{\bm{V}}}
\def\mW{{\bm{W}}}
\def\mX{{\bm{X}}}
\def\mY{{\bm{Y}}}
\def\mZ{{\bm{Z}}}
\def\mBeta{{\bm{\beta}}}
\def\mPhi{{\bm{\Phi}}}
\def\mLambda{{\bm{\Lambda}}}
\def\mSigma{{\bm{\Sigma}}}

\DeclareMathAlphabet{\mathsfit}{\encodingdefault}{\sfdefault}{m}{sl}
\SetMathAlphabet{\mathsfit}{bold}{\encodingdefault}{\sfdefault}{bx}{n}
\newcommand{\tens}[1]{\bm{\mathsfit{#1}}}
\def\tA{{\tens{A}}}
\def\tB{{\tens{B}}}
\def\tC{{\tens{C}}}
\def\tD{{\tens{D}}}
\def\tE{{\tens{E}}}
\def\tF{{\tens{F}}}
\def\tG{{\tens{G}}}
\def\tH{{\tens{H}}}
\def\tI{{\tens{I}}}
\def\tJ{{\tens{J}}}
\def\tK{{\tens{K}}}
\def\tL{{\tens{L}}}
\def\tM{{\tens{M}}}
\def\tN{{\tens{N}}}
\def\tO{{\tens{O}}}
\def\tP{{\tens{P}}}
\def\tQ{{\tens{Q}}}
\def\tR{{\tens{R}}}
\def\tS{{\tens{S}}}
\def\tT{{\tens{T}}}
\def\tU{{\tens{U}}}
\def\tV{{\tens{V}}}
\def\tW{{\tens{W}}}
\def\tX{{\tens{X}}}
\def\tY{{\tens{Y}}}
\def\tZ{{\tens{Z}}}


\def\gA{{\mathcal{A}}}
\def\gB{{\mathcal{B}}}
\def\gC{{\mathcal{C}}}
\def\gD{{\mathcal{D}}}
\def\gE{{\mathcal{E}}}
\def\gF{{\mathcal{F}}}
\def\gG{{\mathcal{G}}}
\def\gH{{\mathcal{H}}}
\def\gI{{\mathcal{I}}}
\def\gJ{{\mathcal{J}}}
\def\gK{{\mathcal{K}}}
\def\gL{{\mathcal{L}}}
\def\gM{{\mathcal{M}}}
\def\gN{{\mathcal{N}}}
\def\gO{{\mathcal{O}}}
\def\gP{{\mathcal{P}}}
\def\gQ{{\mathcal{Q}}}
\def\gR{{\mathcal{R}}}
\def\gS{{\mathcal{S}}}
\def\gT{{\mathcal{T}}}
\def\gU{{\mathcal{U}}}
\def\gV{{\mathcal{V}}}
\def\gW{{\mathcal{W}}}
\def\gX{{\mathcal{X}}}
\def\gY{{\mathcal{Y}}}
\def\gZ{{\mathcal{Z}}}

\def\sA{{\mathbb{A}}}
\def\sB{{\mathbb{B}}}
\def\sC{{\mathbb{C}}}
\def\sD{{\mathbb{D}}}
\def\sF{{\mathbb{F}}}
\def\sG{{\mathbb{G}}}
\def\sH{{\mathbb{H}}}
\def\sI{{\mathbb{I}}}
\def\sJ{{\mathbb{J}}}
\def\sK{{\mathbb{K}}}
\def\sL{{\mathbb{L}}}
\def\sM{{\mathbb{M}}}
\def\sN{{\mathbb{N}}}
\def\sO{{\mathbb{O}}}
\def\sP{{\mathbb{P}}}
\def\sQ{{\mathbb{Q}}}
\def\sR{{\mathbb{R}}}
\def\sS{{\mathbb{S}}}
\def\sT{{\mathbb{T}}}
\def\sU{{\mathbb{U}}}
\def\sV{{\mathbb{V}}}
\def\sW{{\mathbb{W}}}
\def\sX{{\mathbb{X}}}
\def\sY{{\mathbb{Y}}}
\def\sZ{{\mathbb{Z}}}

\def\emLambda{{\Lambda}}
\def\emA{{A}}
\def\emB{{B}}
\def\emC{{C}}
\def\emD{{D}}
\def\emE{{E}}
\def\emF{{F}}
\def\emG{{G}}
\def\emH{{H}}
\def\emI{{I}}
\def\emJ{{J}}
\def\emK{{K}}
\def\emL{{L}}
\def\emM{{M}}
\def\emN{{N}}
\def\emO{{O}}
\def\emP{{P}}
\def\emQ{{Q}}
\def\emR{{R}}
\def\emS{{S}}
\def\emT{{T}}
\def\emU{{U}}
\def\emV{{V}}
\def\emW{{W}}
\def\emX{{X}}
\def\emY{{Y}}
\def\emZ{{Z}}
\def\emSigma{{\Sigma}}

\newcommand{\etens}[1]{\mathsfit{#1}}
\def\etLambda{{\etens{\Lambda}}}
\def\etA{{\etens{A}}}
\def\etB{{\etens{B}}}
\def\etC{{\etens{C}}}
\def\etD{{\etens{D}}}
\def\etE{{\etens{E}}}
\def\etF{{\etens{F}}}
\def\etG{{\etens{G}}}
\def\etH{{\etens{H}}}
\def\etI{{\etens{I}}}
\def\etJ{{\etens{J}}}
\def\etK{{\etens{K}}}
\def\etL{{\etens{L}}}
\def\etM{{\etens{M}}}
\def\etN{{\etens{N}}}
\def\etO{{\etens{O}}}
\def\etP{{\etens{P}}}
\def\etQ{{\etens{Q}}}
\def\etR{{\etens{R}}}
\def\etS{{\etens{S}}}
\def\etT{{\etens{T}}}
\def\etU{{\etens{U}}}
\def\etV{{\etens{V}}}
\def\etW{{\etens{W}}}
\def\etX{{\etens{X}}}
\def\etY{{\etens{Y}}}
\def\etZ{{\etens{Z}}}

\newcommand{\pdata}{p_{\rm{data}}}
\newcommand{\ptrain}{\hat{p}_{\rm{data}}}
\newcommand{\Ptrain}{\hat{P}_{\rm{data}}}
\newcommand{\pmodel}{p_{\rm{model}}}
\newcommand{\Pmodel}{P_{\rm{model}}}
\newcommand{\ptildemodel}{\tilde{p}_{\rm{model}}}
\newcommand{\pencode}{p_{\rm{encoder}}}
\newcommand{\pdecode}{p_{\rm{decoder}}}
\newcommand{\precons}{p_{\rm{reconstruct}}}

\newcommand{\laplace}{\mathrm{Laplace}} 

\newcommand{\E}{\mathbb{E}}
\newcommand{\Ls}{\mathcal{L}}
\newcommand{\R}{\mathbb{R}}
\newcommand{\emp}{\tilde{p}}
\newcommand{\lr}{\alpha}
\newcommand{\reg}{\lambda}
\newcommand{\rect}{\mathrm{rectifier}}
\newcommand{\softmax}{\mathrm{softmax}}
\newcommand{\sigmoid}{\sigma}
\newcommand{\softplus}{\zeta}
\newcommand{\KL}{D_{\mathrm{KL}}}
\newcommand{\Var}{\mathrm{Var}}
\newcommand{\standarderror}{\mathrm{SE}}
\newcommand{\Cov}{\mathrm{Cov}}
\newcommand{\normlzero}{L^0}
\newcommand{\normlone}{L^1}
\newcommand{\normltwo}{L^2}
\newcommand{\normlp}{L^p}
\newcommand{\normmax}{L^\infty}

\newcommand{\parents}{Pa} 

\DeclareMathOperator*{\argmax}{arg\,max}
\DeclareMathOperator*{\argmin}{arg\,min}

\DeclareMathOperator{\sign}{sign}
\DeclareMathOperator{\Tr}{Tr}
\let\ab\allowbreak
 \clearpage{}\usepackage{color}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{multirow, varwidth}
\usepackage{dblfloatfix}
\usepackage{verbatim}
\makeatletter
\newif\if@restonecol
\makeatother
\let\algorithm\relax
\let\endalgorithm\relax
\usepackage[ruled,vlined]{algorithm2e}
\usepackage{xr}
\usepackage[amsmath,thmmarks]{ntheorem}


\def\mathbi#1{\textbf{\em #1}}


\DeclareRobustCommand\onedot{\futurelet\@let@token\@onedot}
\def\onedot{. }
\def\eg{\emph{e.g}\onedot} \def\Eg{\emph{E.g}\onedot}
\def\ie{\emph{i.e}\onedot} \def\Ie{\emph{I.e}\onedot}
\def\cf{\emph{c.f}\onedot} \def\Cf{\emph{C.f}\onedot}
\def\etc{\emph{etc}\onedot} \def\vs{\emph{vs}\onedot}
\def\wrt{w.r.t\onedot} \def\dof{d.o.f\onedot}
\def\etal{\emph{et al}\onedot}
\clearpage{}
\usepackage{graphicx}
\usepackage{algorithmic}
\usepackage{mathtools}
\usepackage{caption}
\usepackage{booktabs}
\usepackage{multirow}
\usepackage{multirow}
\usepackage{url}
\usepackage{algorithm2e}
\usepackage{makecell}
\usepackage{lipsum}
\usepackage{soul}
\usepackage{tabularx}
\usepackage{adjustbox}
\usepackage{hyperref}

\newcolumntype{b}{X}
\newcolumntype{s}{>{\hsize=.5\hsize}X}

\usepackage{footnote}
\makesavenoteenv{tabular}
\makesavenoteenv{table}
\makesavenoteenv{minipage}
\makesavenoteenv{figure}

\newcommand\BibTeX{B\textsc{ib}\TeX}
\newcommand{\new}[1]{{\color{magenta}{\small\bf\sf [New: #1]}}}
\newcommand{\hw}[1]{{\color{teal}{\small\bf\sf [@Hyunwoo: #1]}}}
\newcommand{\hyunwoo}[1]{{\color{teal}{\small\bf\sf [@Hyunwoo: #1]}}}
\newcommand{\bc}[1]{{\color{blue}{\small\bf\sf [@Byeongchang: #1]}}}
\newcommand{\byeongchang}[1]{{\color{blue}{\small\bf\sf [@Byeongchang: #1]}}}

\definecolor{anger}{HTML}{FFC7BF}
\definecolor{joy}{HTML}{ffec99} \definecolor{excited}{HTML}{ffd8a8} \definecolor{faithful}{HTML}{ffd8a8} \definecolor{disgust}{HTML}{CFFFCC}
\definecolor{embarrassed}{HTML}{c3fae8} \definecolor{sadness}{HTML}{C0DEFF}
\definecolor{fear}{HTML}{d0bfff} \definecolor{grateful}{HTML}{bac8ff} \definecolor{surprised}{HTML}{faa2c1} \definecolor{selected}{HTML}{d3f9d8} \definecolor{guilty}{HTML}{adb5bd} \definecolor{proud}{HTML}{91a7ff} \definecolor{confident}{HTML}{e599f7} 


\newcommand{\hlc}[2][yellow]{{\colorlet{foo}{#1}\sethlcolor{foo}\hl{#2}}}

\newcommand{\joy}[1]{\hlc[joy]{#1}}
\newcommand{\angry}[1]{\hlc[anger]{#1}}
\newcommand{\excited}[1]{\hlc[excited]{#1}}
\newcommand{\fear}[1]{\hlc[fear]{#1}}
\newcommand{\sad}[1]{\hlc[sadness]{#1}}
\newcommand{\surprised}[1]{\hlc[surprised]{#1}}
\newcommand{\embarrassed}[1]{\hlc[embarrassed]{#1}}
\newcommand{\terrified}[1]{\hlc[fear]{#1}}
\newcommand{\guilty}[1]{\hlc[guilty]{#1}}
\newcommand{\faithful}[1]{\hlc[faithful]{#1}}
\newcommand{\anticipating}[1]{\hlc[joy]{#1}}
\newcommand{\proud}[1]{\hlc[proud]{#1}}
\newcommand{\confident}[1]{\hlc[confident]{#1}}
\newcommand{\sel}[1]{\hlc[selected]{#1}}


\definecolor{myred}{RGB}{255, 86, 93}
\definecolor{myblue}{RGB}{86, 125, 255}
\definecolor{urlcolor}{HTML}{E31C79} 

\title{Perspective-taking and Pragmatics for Generating \\ Empathetic Responses Focused on Emotion Causes}

\author{
    Hyunwoo Kim \qquad Byeongchang Kim \qquad Gunhee Kim \\
    Department of Computer Science and Engineering\\
    Seoul National University, Seoul, Korea \\
    {\tt \small{ \{hyunw.kim, byeongchang.kim\}@vl.snu.ac.kr gunhee@snu.ac.kr }} \\
\href{https://vl.snu.ac.kr/projects/focused-empathy}{\textcolor{urlcolor}{\small{\texttt{https://vl.snu.ac.kr/projects/focused-empathy}}}}
}

\date{}

\begin{document}
\maketitle
\begin{abstract}
    Empathy is a complex cognitive ability based on the reasoning of others' affective states.
    In order to better understand others and express stronger empathy in dialogues, we argue that two issues must be tackled at the same time:
    (i) identifying which word is the cause for the other's emotion from his or her utterance and (ii) reflecting those specific words in the response generation.
    However, previous approaches for recognizing emotion cause words in text require sub-utterance level annotations, which can be demanding.
    Taking inspiration from social cognition, we leverage a generative estimator to infer emotion cause words from utterances with no word-level label.
    Also, we introduce a novel method based on pragmatics to make dialogue models focus on targeted words in the input during generation.
    Our method is applicable to any dialogue models with no additional training on the fly.
    We show our approach improves multiple best performing dialogue agents on generating more focused empathetic responses in terms of both automatic and human evaluation.
\end{abstract}

\section{Introduction}
\label{sec:intro}

Empathy is one of the hallmarks of social cognition.
It is an intricate cognitive ability that requires high-level reasoning on other's affective states.
The intensity of expressed empathy varies depending on the depth of reasoning.
According to \citet{Sharma:2020:EMNLP}, weak empathy is accompanied by generic expressions such as ``\textit{Are you OK?}'' or ``\textit{It's just terrible, isn't it?}'',
while stronger empathy reflects the other's specific situation:
``\textit{How is your \sad{headache}, any better?}'' or ``\textit{You must be worried about the \fear{job interview}}''.
In order to respond with stronger empathy, two issues must be tackled: reasoning (i) where to focus on the interlocutor's utterance (for the reason behind the emotion) and
(ii) how to generate utterances that focus on such words.



Firstly, which words should we focus on when empathizing with others?
As empathy relates to other's emotional states, the reasons behind emotions (\textit{emotion cause}) should be identified.
Imagine you are told ``\textit{I got a \joy{gift} from a \joy{friend} last vacation!}'' with a joyful face.
The likely words that can be the causes of his/her happiness are ``\textit{gift}'' and ``\textit{friend}''.
On the other hand, ``\textit{vacation}'' has less to do with the emotion.
If you respond ``\textit{How was your vacation?}'', the interlocutor may think you are not interested; rather, it is better to say ``\textit{Wow, what was the \joy{gift}?}'' or ``\textit{Your \joy{friend} must really like you.}'' by focusing on the emotion cause words.



We humans do not rely on word-level supervision for such affective reasoning.
Instead, we put ourselves in the other's shoes and simulate what it would be like.
\textit{Perspective-taking} is this act of considering an alternative point of view for a given situation.
According to cognitive science, \textit{perspective-taking} and \textit{simulation} are key components in empathetic reasoning \citep{Davis:1983:JPSP, Batson:1991:JPSP, Ruby:2004:JCogNeuro}.
Taking inspiration from these concepts, we propose to train a generative emotion estimator for simulating the other's situation and identifying emotion cause words.

Secondly, after reasoning which words to focus on, the problem of how to generate focused responses still remains.
Safe responses that can be adopted to any situations might hurt other's feelings.
Generated utterances need to convey the impression that concerns the specific situation of the interlocutor.
Such communicative reasoning is studied in the field of computational pragmatics.
The Rational Speech Acts (RSA) framework \citep{Frank:2012:Science} formulates communication between speaker and listener as probabilistic reasoning.
It has been applied to many tasks to increase the informativeness of generated text grounded on inputs \citep{Andreas:2016:EMNLP, Fried:2018:NeurIPS, Cohn:2019:NAACL, Shen:2019:NAACL}.
That is, RSA allows the input to be more reflected in the generated output.

However, controlling the RSA framework to reflect specific parts of the input remains understudied.
We introduce a novel method for the RSA framework to make models focus on targeted words in the interlocutor's utterance during generation.

In summary, we recognize emotion cause words in dialogue utterances with no word-level labels and generate stronger empathetic responses focused on them without additional training.
Our major contributions are as follows:

(1) We identify emotion cause words in dialogue utterances by leveraging a generative estimator.
Our approach requires no additional emotion cause labels other than the emotion label on the whole sentence, and outperforms other baselines.


(2) We introduce a new method of controlling the Rational Speech Acts framework \citep{Frank:2012:Science}
to make dialogue models better focus on targeted words in the input context to generate more specific empathetic responses.

(3) For evaluation, we annotate emotion cause words in emotional situations from the validation and test set of EmpatheticDialogues dataset \citep{Rashkin:2019:ACL}.
We publicly release our \textsc{EmoCause} evaluation set for future research.

(4) Our approach improves model-based empathy scores \citep{Sharma:2020:EMNLP} of three recent dialogue agents,
MIME~\citep{Majumder:2020:EMNLP}, DodecaTransformer~\citep{Shuster:2020:ACL}, and Blender~\citep{Roller:2021:EACL} on EmpatheticDialogues.
User studies also show that our approach improves human-rated empathy scores and is more preferred in A/B tests.








\section{Related Work}
\label{sec:related_work}

\textbf{Empathetic dialogue modeling.}
Incorporating user sentiment is one of early attempts for empathetic conversation generation \citep{Siddique:2017:ACL, Shi:2018:ACL}.
\citet{Rashkin:2019:ACL} collect a large-scale English empathetic dialogue dataset named EmpatheticDialogues. The dataset is now adopted in other dialogue corpus such as DodecaDialogue \citep{Shuster:2020:ACL} and BST \citep{Smith:2020:ACL}.
As a result, pretrained large dialogue agents such as DodecaTransformer \citep{Shuster:2020:ACL} and Blender \citep{Roller:2021:EACL} now show empathizing capabilities.
Empathy-specialized dialogue models are another stream of research.
Diverse architectures have been adopted, including emotion recognition \citep{Lin:2020:AAAI}, mixture of experts \citep{Lin:2019:EMNLP}, emotion mimicry \citep{Majumder:2020:EMNLP} and persona \citep{Zhong:2020:EMNLP}.
\citet{Li:2020:COLING} use lexicon to extract emotion-related words from utterances and feed them to a GAN-based agent.

We aim to improve both pretrained large dialogue agents and empathy-specialized ones by making them focus on emotion cause words in context.





\textbf{Emotion Cause (Pair) Extraction.}
The emotion cause extraction (ECE) task predicts causes in text spans, given an emotion.
Cause spans have been collected from Chinese microblogs and news \citep{Gui:2014:NLPCC, Gui:2016:EMNLP},
English novels \citep{Gao:2017:NTCIR}, and English dialogues \citep{Poria:2020:arxiv}.
\citet{Xia:2019:ACL} propose a task of extracting pairs of both emotion and its cause spans.
Previous works tackle these tasks via supervised learning with question-answering \citep{Gui:2017:EMNLP},
joint-learning \citep{Chen:2018:EMNLP}, co-attention \citep{Li:2018:EMNLP}, and regularization \citep{Fan:2019:EMNLP}.


Compared to those tasks, we recognize emotion cause words with no word-level labels using a generative estimator.
Our method does not require word-level labels other than the emotion labels of the whole sentences.
We then generate more specific empathetic responses focused on them.


\textbf{Rational Speech Acts (RSA) framework.}
The RSA framework \citep{Frank:2012:Science} has been applied to many NLP tasks including
referencing \cite{Andreas:2016:EMNLP, Zarriess:2019:ACL}, captioning \cite{Vedantam:2017:CVPR, Cohn:2018:NAACL},
navigating \cite{Fried:2018:NeurIPS}, translation \cite{Cohn:2019:NAACL}, summarization \cite{Shen:2019:NAACL}, and dialogue \citep{Kim:2020:EMNLP}.
It can improve informativeness of generated utterances better grounded on inputs (\eg images, texts).

Compared to previous use of RSA, we propose an approach that can control the models to focus on targeted words from the given input.






\section{Identifying Emotion Cause Words \newline with Generative Emotion Estimation}
\label{sec:gee}

Our approach consists of two steps: (i)  recognizing emotion cause words from utterances with no word-level labels (\S \ref{sec:gee}), and
(ii) generating empathetic responses focused on those words (\S \ref{sec:generation}).
In this section, we first train a generative emotion estimator to identify emotion cause words.


\subsection{Why Generative Emotion Estimator?}
\label{subsec:why_gee}
We leverage a \textit{generative} model by taking inspiration from \textit{perspective-taking} (\ie \textit{simulating} oneself in other's shoes) to reason emotion causes; not requiring word-level labels.
Our idea is to estimate the emotion cause weight of each word in the utterance while satisfying the following three desiderata.


(1) Do not require word-level supervision for learning to identify emotion cause words in the utterances.
Humans do not need word-level labels to infer the probable causes associated with the other's emotion during conversation.

(2) Simulate the observed interlocutor's situation within the model.
\textit{Simulation theory} (ST) from cognitive science explains that this mental imitation helps understanding the internal mental states of others \citep{Gallese:2004:TiCS}.
Much evidence for ST is found from neuroscience including mirror neurons \citep{Rizzolatti:2004:RevNeuro}, action-perception coupling \citep{Decety:2003:Neural}, and empathetic perspective-taking \citep{Ruby:2004:JCogNeuro}.


(3) Reason other's internal emotional states in Bayesian fashion.
Studies from cognitive science argue that human reasoning of other's affective states and minds can be described via Bayesian inference \citep{Griffiths:2008:Cambridge, Ong:2015:Cognition, Saxe:2017:Curr, Ong:2019:topics}.


Interestingly, a generative emotion estimator (GEE), which models  with text sequence (\eg context)  and emotion , satisfies all the above conditions.
First, the generative estimator computes the likelihood of  by \textit{generating}  given , which can be viewed as a \textit{simulation} of .
Second, it estimates  via Bayes' rule.
Finally, the association between the emotion estimate and each word comes for free by using the likelihood of each words; without using any word-level supervision.
We use BART \citep{Lewis:2020:ACL} to implement a GEE. 



\subsection{Training to Model Emotional Situations}
\label{subsec:train_gee}

\textbf{Dataset}.
To train our GEE, we leverage the EmpatheticDialogues \citep{Rashkin:2019:ACL},
a multi-turn English dialogue dataset where the speaker talks about an emotional situation and the listener expresses empathy.
An example is shown in Table \ref{tab:ed_example}.
The emotion and the situation sentence are only visible to the speaker.
Situations are collected beforehand by asking annotators to recall related experiences for a given emotion label.
The dataset includes a rich suite of 32 emotion labels that are evenly distributed.


\textbf{Training}.
Given an emotion label , GEE is trained to generate its corresponding emotional situation , where  is a word.
As a result, our GEE learns the joint probability .
The trained GEE shows perplexity of 13.6 on the test situations of EmpatheticDialogues.




{\renewcommand{\arraystretch}{1.1}
    \begin{table}[t] \begin{center}
    \small
    \setlength{\tabcolsep}{1pt}
    \begin{tabularx}{\linewidth}{X}
        \toprule
        \textbf{Emotion}: Grateful \\
        \textbf{Situation}: \\
        I was grateful when my mother visited me for my birthday. \\
        \midrule
        \textbf{Speaker}: It was my birthday, my mom came to surprise me. \\
        \textbf{Listener}: Aw that's so nice, how did she surprise you? \\
        \textbf{Speaker}: She showed up to my house and brought me a cake. \\
        \textbf{Listener}: Cakes! yessss winning. :) \\
        \bottomrule
    \end{tabularx}
    \vspace{-7pt}
    \caption{A dialogue example in EmpatheticDialogues.} \label{tab:ed_example}
    \vspace{-10pt}
\end{center}\end{table}}

{\renewcommand{\arraystretch}{1}
    \begin{table}[t] \begin{center}
    \small
    \setlength{\tabcolsep}{4pt}
    \begin{tabular}{l}
        \toprule
        \textbf{Emotion}: \hlc[joy]{Joyful} \\
        \textbf{GEE}:\\
\textbullet~I got accepted into a masters program in neuroscience. \\
\midrule
        \textbf{Emotion}: \hlc[anger]{Angry} \\
        \textbf{GEE}:\\
\textbullet~I was so mad at my cousin. He stole my daughters stuff. \\
        \midrule
        \textbf{Emotion}: \hlc[grateful]{Grateful} \\
        \textbf{GEE}:\\
\textbullet~The night my dad got me a new car was a magical time. \\
        \bottomrule
    \end{tabular}
    \caption{Example of sampled outputs from our generative emotion estimator (GEE) using Nucleus sampling.}
    \label{tab:gee_examples}
    \vspace{-15pt}
\end{center}\end{table}}


\subsection{Recognizing Emotions}
\label{subsec:gee_emotion}

Once trained, GEE can predict  for a word sequence  (\eg utterance) using Bayes' rule: 
We compute the likelihood  by GEE's generative ability as described in \S \ref{subsec:why_gee}.
Since emotions in EmpatheticDialogues are almost evenly distributed, we set the prior  to a uniform distribution.
Finally, we find the emotion with the highest likelihood of the given sequence . 

We comparatively report the emotion classification accuracy of GEE in Appendix.




\subsection{Weakly Supervised \newline Emotion Cause Word Recognition}
\label{subsec:gee_emotionalword}

We introduce how GEE can recognize emotion cause words solely based on emotion labels without word-level annotations.
For a given word sequence  (\eg utterance),
GEE can reason the association  of each word  in the sequence  to the recognized emotion  in Bayesian fashion:

The emotion likelihood is computed as 

where  is the partial utterance up to time step .
Since computing the expectation over all possible partial utterance  is intractable, we approximate it by a single sample.
We build set  to include  and emotions with the two lowest probability of   when recognizing emotion in Eq.(\ref{eq:emotion_recognition}). 
We assume the marginal  is uniform.
We choose the top- words reasoned by GEE as emotion cause words, and focus on them during empathetic response generation.










\section{Controlling the RSA framework for Focused Empathetic Responses}
\label{sec:generation}

We introduce how to control the Bayesian Rational Speech Acts (RSA) framework \citep{Frank:2012:Science} to focus on targeted words in the context during response generation.
We first preview the basics of RSA for dialogues (\S \ref{subsec:rsa}).
We then present how to control the RSA with word-level focus (\S \ref{subsec:world}), where our major contribution lies.
Figure \ref{fig:model} is the overview of our method.


\subsection{The Rational Speech Acts Framework}
\label{subsec:rsa}

Applying the RSA framework is computing the posterior of the dialogue agent's output distribution over words each time step. Hence, it is applicable to any existing pretrained dialogue agents on the fly, with no additional training.

The RSA framework formulates communication as a reference game between speaker and listener.
Based on recursive Bayesian formulation, the speaker (\ie dialogue model) reasons about the listener's belief of what the speaker is referring to.
We follow the approach of \citet{Kim:2020:EMNLP} for adopting RSA to dialogues.
Our goal here is to update a base speaker  to a pragmatic speaker  that focuses more on the emotion cause words in dialogue context  (\ie dialogue history).

\textbf{Base Speaker }.
Let  and  denote dialogue context and the output word of the model at time step , respectively.
The base speaker  is a dialogue agent that outputs  for a dialogue context and partial utterance : .
As described, one can use any dialogue models for .

\textbf{Pragmatic Listener }.
The pragmatic listener is a posterior distribution over which dialogue context the speaker is referring to.
It is defined in terms of the base speaker  and a prior distribution  over the context in Bayesian fashion:

The \textit{shared world}  is a finite set comprising the given dialogue context  and other contexts (coined as \textit{distractors}) different from .
Our contribution lies in how to build world  to endow the dialogue agent with controllability to better focus on targeted words, which we discuss in \S \ref{subsec:world}.
We update prior  with  from time step  as follows: .
 is the rationality parameter which controls how much the base speaker's distribution is taken into account.
We note that  is simply a distribution computed in Bayesian fashion, not another separate model.



\begin{figure}[t] \begin{center}
    \vspace{-5pt}
\includegraphics[width=\linewidth]{figures/model_figure.pdf}
    \caption{Overview of our method, consisting of emotion recognition (\S \ref{subsec:gee_emotion}),
        emotion cause word recognition (\S \ref{subsec:gee_emotionalword}),
        distractor context sampling (\S \ref{subsec:world}), and pragmatic generation (\S \ref{subsec:rsa}).
        GEE denotes our generative emotion estimator.}
    \label{fig:model}
    \vspace{-10pt}
\end{center} \end{figure}


\textbf{Pragmatic Speaker }.
Integrating  with , we obtain the pragmatic speaker :

Since the pragmatic speaker  is forced to consider how its utterance is perceived by the listener (via ),
it favors words that have high likelihood of the given context  over other contexts in shared world .
Similar to Eq. \ref{eq:listener},  is the rationality parameter for .


\subsection{Endowing Word-level Control for RSA \newline to Focus on Targeted Words in Context}
\label{subsec:world}

We aim to make dialogue models focus on targeted words from the input (\ie dialogue context) during generation via shared world .
The shared world  consists of the given dialogue context  and other distractor contexts.
It is used for computing the likelihood of the given context  in Eq. \ref{eq:listener}.


Previous works of RSA in NLP manually (or randomly) select pieces of text (\eg sentences) entirely different from the given input \citep{Cohn:2019:NAACL, Shen:2019:NAACL, Kim:2020:EMNLP}.
In our context, it means distractors will be totally different contexts from  in the dataset.
For example, when given a context ``\textit{I got a gift from my friend.}'', a distractor might be ``\textit{Today, I have an exam at school.}''.
Although such type of distractors helps improve the specificity of the model's generated outputs,
it is difficult to finely control which words the models should be specific about.



Our core idea is to build distractors by replacing the emotion cause words in  with different words via sampling with GEE.
It can enhance the controllability of the RSA by making models focus on targeted words (\eg emotion cause words recognized by GEE) from the dialogue context.


For a dialogue context  where  is a word, GEE outputs top- emotion cause words regarding the recognized emotion  from context , denoted by .
Next, we concatenate the least likely  emotions from GEE with the context  removing the top- emotion cause words:
,
which is input to GEE.
We then sample different words () from GEE's output in place of  to construct a distractor .
For example, given a context  ``\textit{I was \sad{sick} from the \sad{flu}}'' and ``\textit{sick, flu}'' as the top-2 emotion cause words,
a sampled distractor  can be ``\textit{I was \joy{laughing} from the \joy{relief}}''.
We use these altered contexts  as distractors for the shared world  in the pragmatic listener  (Eq. \ref{eq:listener}).
We set  and cardinality of world  to 3 (\ie ).
We run experiments and find the best  () (see Appendix).


The only difference between the original context  and the sampled distractor  is those emotion cause words.
The pragmatic speaker  (Eq. \ref{eq:s1}) prefers to generate words that have a
higher likelihood of the given context  (including the original emotion cause words ) than the distractor context . As a result, the pragmatic agent can generate utterances more focused on those original emotion cause words.



{\renewcommand{\arraystretch}{1.1}
    \begin{table}[t] \begin{center}
\begin{adjustbox}{width=\columnwidth}
    \begin{tabular}{lcccc}
        \toprule
                                & \#Emotion      & Label     & \#Label/Utt    & \#Utt                 \\
        \midrule
        RECCON                  & 8              & Span      & 2.0             & 6.3K \\
        \textsc{EmoCause} (Ours)     & 32             & Word      & 2.3             & 4.6K \\
        \bottomrule
    \end{tabular}
    \end{adjustbox}
    \vspace{-5pt}
    \caption{
        Statistics of the \textsc{EmoCause} evaluation set compared to RECCON \citep{Poria:2020:arxiv}. Utt denotes utterance.
    }
    \vspace{-15pt}
    \label{tab:dataset_stats}
\end{center}\end{table}}

\begin{figure}[t] \begin{center}
    \includegraphics[width=\linewidth]{figures/dataset_ratio.pdf}
    \vspace{-17pt}
    \caption{Emotion ratio of RECCON and our \textsc{EmoCause} evaluation set.}
    \label{fig:label_ratio}
    \vspace{-12pt}
\end{center} \end{figure}

{\renewcommand{\arraystretch}{1}\begin{table}[t!] \begin{center}
    \small
    \setlength{\tabcolsep}{6pt}
    \begin{tabular}{cc}
        \toprule
        Emotion                               & Situation \\
        \midrule
\addlinespace[0.2cm]
        \makecell{Surprised} & \makecell[l]{Man, I did not expect to \surprised{see} a \surprised{bear} on the \\ \surprised{road} today.} \\
\addlinespace[0.1cm]
        \cmidrule(lr{0.3em}){1-2}
        \addlinespace[0.1cm]
\makecell{Afraid}  & \makecell[l]{I have to take a \fear{business} \fear{trip} next week, \\
                                            I'm not looking forward to \fear{flying}.} \\
        \cmidrule(lr{0.3em}){1-2}
        \addlinespace[0.1cm]
\makecell{Sad}  & \makecell[l]{I feel sad that I am \sad{spending} so much \sad{time} \\ this late on the \sad{internet}.} \\
        \cmidrule(lr{0.3em}){1-2}
        \addlinespace[0.1cm]
        \makecell{Joyful}  & \makecell[l]{I'm excited I get to \joy{go} to \joy{Disney} in October!} \\
        \addlinespace[0.1cm]
        \bottomrule
    \end{tabular}
    \vspace{-5pt}
    \caption{
        Examples of annotated emotion cause words.
}
    \vspace{-10pt}
    \label{tab:dataset_example}
\end{center}\end{table}}

{\renewcommand{\arraystretch}{1}\begin{table}[t!] \begin{center}
    \small
    \setlength{\tabcolsep}{4.5pt}
    \begin{tabular}{ll}
        \toprule
        {Embarrassed} & \makecell[c]{pant, fell, dropped, people, tripped, toilet} \\
        \cmidrule(lr{0.1em}){1-2}
        {Nostalgic} & \makecell[c]{old, childhood, memory, friend, back} \\
        \cmidrule(lr{0.1em}){1-2}
        {Trusting} & \makecell[c]{friend, gave, best, daughter, money, phone} \\
        \cmidrule(lr{0.1em}){1-2}
        {Anxious} & \makecell[c]{job, interview, exam, new, presentation} \\
        \cmidrule(lr{0.1em}){1-2}
{Proud} & \makecell[c]{graduated, daughter, college, son, school} \\
        \cmidrule(lr{0.1em}){1-2}
{Disappointed} & \makecell[c]{not, son, car, failed, get, job, hard, friend} \\
\bottomrule
    \end{tabular}
    \vspace{-5pt}
    \caption{
        The most frequent cause words for each emotion. Other emotions can be found in Appendix.
    }
    \vspace{-15pt}
    \label{tab:frequent_words}
\end{center}\end{table}}





\section{\textsc{EmoCause}: \newline Emotion Cause Words Evaluation Set} \label{sec:dataset}




\subsection{Collecting Annotations}

To evaluate the performance of GEE, we annotate emotion cause words\footnote{
    As existing works annotate emotion cause spans for a given emotion label, we also coin our annotations as emotion cause words.
    However, in terms of ``\textit{causality}'', we note that the \textit{true} cause of the given emotion can be annotated only by the original annotator of the emotion label.
}
in the situations of validation and test set in EmpatheticDialogues \citep{Rashkin:2019:ACL} (\S \ref{subsec:train_gee}).
Using Amazon Mechanical Turk, we ask three workers to vote which words (\eg object, action, event, concept) in the situation sentence are the cause words to the given emotion.
Since explicit emotion words in the text (\eg happy, disappointed) are not cause words of emotion, we discourage workers from selecting them.

Annotators are required to have a minimum of 1000 HITs, 95\% HIT approval rate, and be located at one of [AU, CA, GB, NZ, US].
We pay the annotators \1,3,53,5\uparrow\uparrowS_0S_1S_1S_0S_0S_1S_1S_0S_0S_1S_1S_1S_1S_0S_1S_1S_1S_1\uparrow\uparrow\uparrowS_0S_1S_0S_1S_0S_1S_1(S_0)S_1S_0S_1S_0S_1S_0S_1(S_0)S_1S_1S_1S_1S_1S_1S_0S_0\mathbf{S_0}\mathbf{S_1}\mathbf{S_1}\mathbf{S_0}\mathbf{S_1}\mathbf{S_1}\mathbf{S_0}\mathbf{S_1}\mathbf{S_1}S_0S_1S_1S_1S_0S_1S_0S_1S_0\alphaS_1S_1S_1S_1S_1S_1\alpha\beta\alpha\beta[1.0, 2.0, 3.0, 4.0][0.5, 0.6, 0.7, 0.8, 0.9, 1.0]kkk=5k=1,2,4,8k\uparrow\uparrowkk$ emotion cause words on generating empathetic responses in EmpatheticDialogues \cite{Rashkin:2019:ACL}.
        Exploration and Interpretation scores are evaluated by pretrained RoBERTa models from \citet{Sharma:2020:EMNLP}.
    }
    \vspace{-7pt}
    \label{tab:topk_results}
\end{center}\end{table}}

Experiments for emotion cause word recognition and emotion classification are run on one NVIDIA Quadro RTX 6000 GPU.
Experiments for empathetic response generation are run on two GPUs.


\section{Emotion Classification}
\label{sec:emotion_classification}

We report the classification performance of emotion classifiers used in empathetic response generation.
Table \ref{tab:emo_classification} shows the Top-1, 5 emotion classification accuracy for each model.
For reference, BERT \citep{Devlin:2019:NAACL} shows 0.55 and 0.88 for Top-1 and 5 accuracy.

{\renewcommand{\arraystretch}{1}\begin{table}[h!] \begin{center}
    \small
    \setlength{\tabcolsep}{11pt}
    \begin{tabular}{lcc}
        \toprule
        Model                               & \makecell{Top-1}  & \makecell{Top-5} \\
        \midrule
        \addlinespace[0.1cm]
        MoEL \citep{Lin:2019:EMNLP}           & 0.38               & 0.74                                 \\
        MIME \citep{Majumder:2020:EMNLP}      & 0.34               & 0.77                                 \\
        GEE (Ours)                            & 0.40               & 0.77                         \\
\bottomrule
    \end{tabular}
\caption{
        Comparison of emotion classification accuracy from different models trained on EmpatheticDialogues \cite{Rashkin:2019:ACL}.
    }
    \vspace{-10pt}
    \label{tab:emo_classification}
\end{center}\end{table}}


\section{Details of \textsc{EmoCause} Evaluation Set}
\label{sec:emotional_words_detail}

Table \ref{tab:annotation_examples_supp} shows some selected examples of emotion cause words with given emotion and situation.
Table \ref{tab:top10_frequent_words} shows Top-10 frequent cause words per emotion.
Interestingly, same words can be seen in both positive and negative emotions.
For example, we can find the word \textit{interview} on both ``Anxious'' and ``Confident''.
``Anticipating'' and ``Disappointed'' are closely related to \textit{vacation}.
This result shows that understanding the context is one of key prerequisites for emotion cause word recognition.



{\renewcommand{\arraystretch}{1.4}\begin{table}[h!] \begin{center}
    \small
\begin{tabularx}{\linewidth}{X}
        \toprule
\textbf{Emotion}: Surprised \\
        We just got a \surprised{new} \surprised{puppy} . My older dog knew to let that one out first when I get home from work . \\
        \midrule
\textbf{Emotion}: Faithful \\
        My \faithful{boyfriend} is going out with a bunch of people I do n't know tonight . But I trust him that he will be a \faithful{good} \faithful{boy} . \\
        \midrule
\textbf{Emotion}: Anticipating \\
        I am really waiting on \anticipating{getting} my \anticipating{tax} \anticipating{returns} this year I could use new carpet \\
        \midrule
\textbf{Emotion}: Trusting \\
        I trust my own \sel{intuitions} when it comes to my \sel{health} . \\
        \midrule
\textbf{Emotion}: Embarrassed \\
        i was \embarrassed{super} \embarrassed{late} for my \embarrassed{meeting} on tuesday \\
        \midrule
\textbf{Emotion}: Sad \\
        My girlfriend 's \sad{cat} is \sad{sick} with \sad{Cancer} . I do n't think she 's going to make it for much longer and I 'm really shaken up by it . \\
        \midrule
\textbf{Emotion}: Proud \\
        I put in a lot of effort and \proud{energy} and I \proud{found} a \proud{new} \proud{job} . It 's an online teaching position and I feel so good about myself . \\
        \midrule
\textbf{Emotion}: Terrified \\
        Driving down the highway during a heavy \terrified{thunderstorm} and a car \terrified{crash} happens in front of me where a car flips over . \\
        \midrule
\textbf{Emotion}: Confident \\
        I \confident{studied} \confident{all} \confident{night} for my final exam \\
        \midrule
\textbf{Emotion}: Guilty \\
        I made a really \guilty{inappropriate} \guilty{joke} about someone I work with to other coworkers and it got back to them . I feel really bad about it . \\
        \bottomrule
    \end{tabularx}
    \caption{
        Examples of our annotated emotion cause words.
        Words with background color are selected as emotion cause words by annotators.
    }
    \vspace{-10pt}
    \label{tab:annotation_examples_supp}
\end{center}\end{table}}




{\renewcommand{\arraystretch}{1}\begin{table*}[t!] \begin{center}
    \small
\begin{tabular}{lcl}
        \toprule
        \textbf{Emotion} & \textbf{\#Label/Utt} & \textbf{Top-10 frequent emotion cause words} \\
        \midrule
        Afraid        & 2.12 & alone, night, spider, house, noise, movie, dark, storm, hurricane, heard \\
        Angry         & 2.62 & car, dog, neighbor, friend, husband, brother, not, stole, hit, kid \\
        Annoyed       & 2.59 & dog, people, cat, work, loud, late, night, sister, neighbor, friend \\
        Anticipating  & 2.04 & new, waiting, vacation, coming, son, job, forward, next, friend, back \\
        Anxious       & 2.05 & interview, job, exam, presentation, big, dentist, going, test, girlfriend, back \\
        Apprehensive  & 2.11 & job, nervous, new, first, interview, driving, moving, car, day, night \\
        Ashamed       & 2.48 & stole, ate, friend, forgot, girlfriend, missed, drunk, bad, money, mistake \\
        Caring        & 2.49 & dog, sick, care, wife, friend, home, helped, puppy, girlfriend, baby \\
        Confident     & 1.95 & exam, studied, job, interview, win, test, well, prepared, good, answer \\
        Content       & 2.04 & life, good, happy, relaxing, watching, weekend, back, breakfast, family, live \\
        Devastated    & 2.42 & dog, passed, died, away, lost, friend, father, job, cancer, cat \\
        Disappointed  & 2.59 & not, son, car, failed, get, hard, job, n't, birthday, vacation \\
        Disgusted     & 2.47 & dog, poop, threw, friend, dead, food, roach, puked, eat, animal \\
        Embarrassed   & 2.73 & pant, fell, dropped, people, tripped, stuck, slipped, toilet, front, friend \\
        Excited       & 1.95 & vacation, new, friend, first, trip, car, puppy, see, won, coming \\
        Faithful      & 2.09 & loyal, girlfriend, husband, year, relationship, boyfriend, family, friend, married, good \\
        Furious       & 2.58 & car, dog, neighbor, hit, broke, without, son, room, accident, cheated \\
        Grateful      & 2.42 & friend, helped, life, job, family, good, help, husband, work, parent \\
        Guilty        & 2.64 & ate, stole, friend, forgot, money, candy, eating, cake, bar, girlfriend \\
        Hopeful       & 1.91 & job, promotion, future, new, better, get, interview, ticket, college, well \\
        Impressed     & 2.30 & friend, daughter, guy, car, new, well, man, brother, world, backflip \\
        Jealous       & 2.66 & friend, car, new, husband, girl, girlfriend, bought, got, boyfriend, won \\
        Joyful        & 2.18 & first, child, wife, friend, family, together, daughter, baby, birthday, trip \\
        Lonely        & 2.18 & friend, alone, moved, husband, family, myself, away, wife, went, left \\
        Nostalgic     & 2.59 & old, childhood, friend, memory, game, school, child, family, back, comic \\
        Prepared      & 2.00 & ready, packed, studied, exam, everything, supply, ingredient, studying, set, all \\
        Proud         & 2.40 & graduated, college, daughter, job, first, son, school, brother, won, new \\
        Sad           & 2.39 & dog, died, passed, away, cat, sick, friend, not, lost, put \\
        Sentimental   & 2.40 & old, picture, passed, photo, dog, childhood, school, away, toy, found \\
        Surprised     & 2.29 & friend, party, birthday, found, baby, car, gift, home, pregnant, won \\
        Terrified     & 2.28 & night, dog, tornado, car, bad, chased, someone, storm, fly, crash \\
        Trusting      & 2.17 & friend, best, daughter, drive, car, brother, sister, card, dog, phone \\
        \bottomrule
    \end{tabular}
    \caption{
        Number of emotion cause words per utterance and Top-10 frequent emotion cause words for each emotion.
    }
    \label{tab:top10_frequent_words}
\end{center}\end{table*}}


\end{document}
