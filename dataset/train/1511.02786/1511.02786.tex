



\documentclass[11pt]{article}

\usepackage{fullpage,wrapfig}
\usepackage{amsmath, amsthm, amssymb, algorithm,thmtools,algpseudocode,enumerate,caption}

\usepackage[usenames,dvipsnames,svgnames,table]{xcolor}
\definecolor{darkgreen}{rgb}{0.0,0,0.9}

\usepackage[colorlinks=true,pdfpagemode=UseNone,citecolor=OliveGreen,linkcolor=BrickRed,urlcolor=BrickRed,
pagebackref]{hyperref} 



\usepackage{tikz}
\usetikzlibrary{arrows,math,calc}

\renewcommand\rmdefault{cmr}
\renewcommand\sfdefault{cmss}
\renewcommand\ttdefault{cmtt}
\newcommand{\theHalgorithm}{\arabic{algorithm}}
\newcommand{\Input}{\item[{\bf Input:}]}
\newcommand{\Output}{\item[{\bf Output:}]}
\renewcommand{\Return}{\item[{\bf return}]}

\makeatletter
\newcommand{\setword}[2]{\phantomsection
  #1\def\@currentlabel{\unexpanded{#1}}\label{#2}}
\makeatother

\def\X{b}
\def\tX{\tilde{b}}
\def\mX{B}
\def\tmX{\tilde{B}}
\def\bone{{\bf 1}}
\def\bzero{{\bf 0}}
\def\bx{{\bf x}}
\def\by{{\bf y}}
\def\bz{{\bf z}}
\def\bof{{\bf f}}
\def\R{\mathbb{R}}
\def\mP{\mathbb{P}}
\def\mE{\mathbb{E}}
\def\mI{\mathbb{I}}
\def\cT{{\cal T}}
\def\cB{{\cal B}}
\def\eps{\epsilon}
\def\reff{\textup{Reff}}
\def\deg{\textup{deg}}

\renewcommand{\thepage}{\arabic{page}}
\renewcommand{\thesection}{\arabic{section}}
\renewcommand{\theequation}{\arabic{equation}}
\renewcommand{\thefigure}{\arabic{figure}}
\renewcommand{\thetable}{\arabic{table}}
\newcommand{\PP}[2]{\mP_{#1}\left[#2\right]}
\newcommand{\weight}[1]{w(#1)}
\renewcommand{\P}[1]{\mP\left[#1\right]}
\newcommand{\I}[1]{\mI\left[#1\right]}
\newcommand{\E}[1]{\mE\left[#1\right]}
\newcommand{\EE}[2]{\mE_{#1}\left[#2\right]}
\newcommand{\norm}[1]{\|#1\|}
\DeclareMathOperator{\trace}{Tr}
\DeclareMathOperator{\vol}{vol}
\DeclareMathOperator{\ham}{ham}
\DeclareMathOperator{\sspan}{span}
\DeclareMathOperator{\st}{s.t.} 
\DeclareMathOperator{\poly}{poly}
\newcommand{\algorithmautorefname}{Algorithm}
\def\h{h}
\def\hin{\h_{in}}
\def\expansion{expansion}




\newcommand{\Set}[2]{
  \{\, #1 \mid #2 \, \}
}
\newtheorem{theorem}{Theorem}[section]
\newtheorem{conjecture}{Conjecture}[section]
\newtheorem{lemma}{Lemma}[section]
\newtheorem{fact}[theorem]{Fact}
\newtheorem{proposition}[theorem]{Proposition}
\newtheorem{claim}[theorem]{Claim}
\newtheorem{corollary}[theorem]{Corollary}
\newtheorem{definition}{Definition}[section]
\newenvironment{proofof}[1]{{\em Proof of #1.}}{\hfill \qed}
\DeclareMathOperator{\polylog}{polylog}

\title{Approximation Algorithms for Finding\\ Maximum  Induced Expanders}

\author{
Shayan Oveis Gharan
\thanks{Department of Computer Science and Engineering, University of Washington.
Email: \protect\url{shayan@cs.washington.edu}}
\and
Alireza Rezaei
\thanks{Department of Computer Science and Engineering, University of Washington.
Email: \protect\url{arezaei@cs.washington.edu}}
}
\begin{document}
\maketitle

\begin{abstract}
	We initiate the study of approximating the largest induced expander in a given graph . Given a -regular graph  with  vertices, the goal is to find the set with the largest induced expansion of size at least . We design a bi-criteria approximation algorithm for this problem; if the optimum has induced spectral expansion  our algorithm returns a -(spectral) expander of size at least  (up to constants).

	Our proof introduces and employs a novel semidefinite programming relaxation for the largest induced expander problem. We expect to see further applications of our SDP relaxation in  graph partitioning problems. In particular, because of the close connection to the small set expansion problem, one may be able to obtain new insights into the unique games problem.
\end{abstract}







\section{Introduction}
In an instance of the maximum clique problem, we are given an undirected graph  and the goal is to find the largest set  of vertices of  such that the induced subgraph  is a clique. The maximum clique problem is extensively studied in the last several decades and it is shown to be one of the hardest problems to approximate in the worst case \cite{Has96}.  

Although the maximum clique problem has many applications in theory and practice,   being an actual complete graph is a property that is  unstable with respect to slight changes in . First of all, there is no natural extension of the maximum clique problem to weighted graphs. Even if  is unweighted, a large clique of  may be completely eliminated by removing only a few edges of .  For a concrete example, suppose  is a complete graph, i.e., the maximum clique of  has size ; if we delete only an  fraction of edges of  uniformly at random, the size of the maximum clique of  reduces by an exponential factor to  \cite{GM75,BE76}. 

It is a natural question to find the maximum size subgraph of  such that  is ``clique-like''. There are several directions to formalize the clique-like property of : For example, one can say  is clique-like if the local neighborhood of every vertex is similar to a clique, i.e., if the average degree of vertices in  is ; such a measure corresponds to the densest subgraph problem which is also extensively studied in the past decade \cite{Cha00,Fei02,Kho04,BCCFV10}.

In this paper, we use \emph{spectral expansion}
as a \emph{global} clique-like property. First, we define spectral expansion, and then we justify that it can be considered as a clique-like property.
Let  be a -regular graph with  vertices.
For a pair of vertices , let  be the vector that is  in ,  in  and zero everywhere else. Let . The Laplacian of ,  is defined as follows:

where we write  to denote . 
Note that if  is weighted, then we need to scale  with the weight of the edge .
It is easy to see that  is a PSD matrix, its first eigenvalue is zero, and the corresponding eigenvector is the all-ones vector.
The spectral expansion of  is defined as the second smallest eigenvalue  of , 
We say  is an -\emph{expander} if .
In this paper,  we design bicriteria approximation algorithms for approximating the largest induced  expander of . 

It is a well-known fact that (-regular)  -expander graphs are essentially sparse complete graphs.
This can be justified    by analyzing either the spectral or combinatorial properties of expander graphs. The eigenvalues of the Laplacian matrix of an -expander graph are essentially the same as the eigenvalues of a complete graph scaled by . 
Similarly, the size of any cut is (up to constants) equal to  fraction of the same cut in the complete graph. This  follows from the Cheeger's inequality.
For a set  let

be the \emph{combinatorial expansion} of , where  is the set of edges in the cut . The combinatorial \expansion~of , , is defined as follows:

 Cheeger's inequality relates (combinatorial) expansion to the spectral expansion.
\begin{theorem}[Discrete Cheeger's inequality \cite{AM85,Alon86}]
\label{thm:cheeger}
For any graph  with maximum degree , we have
	
\end{theorem}
By the above theorem, if  is an -expander, then . 
One can also prove tighter connections between the structure of cuts in an expander graph and the complete graph by  the expander mixing lemma and its generalizations (see e.g., \cite{BL04}).
In summary, unlike the density, (spectral) expansion can be considered as a global clique-like property.


\iffalse
\begin{wrapfigure}{R}{0.3\textwidth}
\begin{center}
\begin{tikzpicture}[inner sep=2pt,scale=.8,pre/.style={<-,shorten <=2pt,>=stealth,thick}, post/.style={->,shorten >=1pt,>=stealth,thick}]

\tikzmath{int \n;
  \b = 0; \d = 2; \N = 16;
  for \n in {1,...,\N}{
    \l = "black";
    \temp = ((\n > 10 && \n <15 )||(\n <8 && \n > 3)) ? 0 : 1 ;
    \tempp =((\n > 10 && \n <14 )||(\n <7 && \n > 3)) ? 0 : 1 ;  
    { \path [draw=\l] (\b:\d * \tempp) -- (\b+360/\N:\d * \tempp);
   	  \tikzmath{ if \temp == 1 then{ {\path [rotate = \b,midway] (\d,0) node (a_\n) [circle,fill = black]{}; };
   	  };
   	  if \temp == 0 then{ {\path [rotate = \b] (\d,0) node  [fill = white] (a_\n){}; };
   	  };
   	  } 
   }; 
    \b = \b + 360/\N;};
	{};  
{
\begin{scope}[rotate=0]
\path () node (A)  {};
\path () node (Text) [rotate=0]  { };
\path () node (B)  {}; 
\draw [color=blue,dashed,line width=1.4pt] (A) arc (2*360/\N : 2*360/\N-180:0.4);
\draw [color=blue,dashed,line width=1.4pt] (A) arc (2*360/\N : 7*360/\N:\d+0.4); 
\draw [color=blue,dashed,line width=1.4pt] () arc (2*360/\N : 7*360/\N:\d-0.4); 
\draw [color=blue,dashed,line width=1.4pt] (B) arc (7*360/\N : 7*360/\N+180:0.4);
\draw [color=black,dashed,line width=0.9pt] (a_4) arc (3*360/\N : 6*360/\N:\d);
\draw [color=black,dashed,line width=0.9pt] (a_11) arc (10*360/\N : 13*360/\N:\d);   
   
\end{scope}
};
}
\end{tikzpicture}
\caption{Although a path of length  in a cycle (of length ) has outside expansion , it may not represent a community because it has a very large girth.}
\label{fig:cycleexpansion}
\end{center}
\end{wrapfigure}
\fi
\paragraph{Motivations.} 
Variants of the largest induced expander problem are previously studied and employed in the design of approximation algorithms. Trevisan \cite{Tre05} showed that one can remove a small fraction of the edges of   such that any connected component of the remaining graph is an -expander. He used this fact to design an approximation algorithm for the unique games problem.
More recently, the first author together with Anari showed that if  is -edge-connected, then it has an induced -edge-connected subgraph that is an -expander.
This fact is used to design an approximation algorithm for Asymmetric TSP \cite{AO14,AO14b}. We emphasize that both of the aforementioned results do not provide any guarantee on the size of the induced expanders that they construct.


Finding induced expanders can also have practical applications in clustering and community detection problems. 
Classically, the expansion or \emph{conductance} are used as combinatorial measures for the quality of a clustering of a graph.
This parameter fails dramatically when the underlying clusters are \emph{overlapping} because the (outside) expansion of each cluster is . The failure of using sparsest cut approximation algorithms is one of the major challenges in overlapping clustering. In those scenarios, it is more natural to look for a cluster which induces an expander graph. For a concrete example, consider the set of all people living in USA in a world wide social network. Since each person typically belongs to multiple international communities, such a set has a large outside expansion. However, it is expectable that it  induces an -expander. 

In general, unlike outside expansion, if  has  spectral expansion, then it has many properties which resembles the structure of a community: 
\begin{enumerate}[i)]
\item Low degree of separation: The diameter of  is at most . 
\item Small mixing time of random walks: A simple random walk in  mixes in time  (see \cite{LPW06} for the definition of mixing time and its connection to expander graphs).
\end{enumerate}
We refrain from going into the detailed properties of expanders and we refer interested readers to \cite{HLW06}. 
Next,  we formally define our problem and its SDP relaxation, then we describe our results.


\paragraph{Problem Formulation.}
Throughout the paper we assume that  is an  undirected, unweighted, -regular graph.
We restrict our attention to unweighted graphs for the brevity of the arguments, but all of our results naturally extend to weighted graphs.
Given a parameter , we are interested in finding a subset  of size  with the largest induced spectral expansion,

The interesting regime of the problem is when , i.e., when  has a sparse complete graph as a subgraph.
Because of this, our goal is to approximate the above objective function with no (or as little as possible) loss on the size of  and . Our approximation factor may have an exponential loss in .



The above problem can be considered as a ``dual'' of the \emph{small set expansion} problem \cite{RS10}. In an instance of the small set expansion problem we are given a -regular graph, and a parameter  and we want to find the set  of size at most  with the smallest (outside) expansion, i.e., we want to approximate 

The problem is extensively studied in the last couple of years because of its close connection to the unique games problem \cite{RST10,BFKM11,OT12,KL12}. To this date, all of the  approximation algorithms of the small set expansion problem incur a loss  in the expansion of the output. The following simple fact relates the two problems
\begin{fact}
	If  has a partitioning into  sets each inducing an -expander,  then 
	
\end{fact}
Because of the above close connection to the small set expansion problem, our SDP relaxation and the rounding algorithm also incur a  loss in the expansion of the output.

\paragraph{Related Works.}
In the last decade three general families of algorithms are studied to detect communities which have large induced expansion. The first one is the class of  greedy based algorithms, the second one is the family of local random walk based algorithms, and the last one is the  spectral algorithms that employ eigenvectors of the Laplacian matrix. To the best of our knowledge, all of these algorithms  fail to capture an induced expander because the vertices of the expander may be highly connected to the outside, i.e., we may have .
The failure is because of the fact that these algorithms are specifically designed to detect sets with small (outside) expansion.

Let us elaborate on the latter fact in each of the three cases. Greedy based algorithms \cite{KVV04,Tre05,AO14} recursively partition the graph using an approximation algorithm for the sparsest cut problem; the algorithm stops once there is no sparse cut in any set of the partition. If the vertices of the hidden expander are highly connected to the outside, the algorithm may simply separate them apart and the structure of the expander will be lost in the partitioning of the graph. Nonetheless, we show that a variant of this algorithm provides an -approximation to the largest induced expander problem; we will also provide some tight examples.


Local graph clustering algorithms \cite{ST08,ACL06,AP09,OT12,ZLM13} simulate simple lazy random walks, or the associated Markov chains like the page rank \cite{ACL06} or the evolving set process \cite{MP03}, on a graph. They detect a nonexpanding set by looking at threshold sets of the probability distribution of the walk at some time .
Perhaps, the closest result to our work is the  work of Zhu, Lattanzi and Mirrokni \cite{ZLM13} who show that if for a set , ,   then it is possible to recover the set. Unfortunately, when  is large, the random walk algorithm fails to recover  because before the walk visits all vertices of , most of the probability mass has escaped the set.

The last family of algorithms use spectral methods, in particular the eigenvalues and eigenvectors of the (normalized) Laplacian matrix to detect the communities \cite{LOT12,LRTV11,OT14,DPRS14,PSZ15,Sin16}. These algorithms typically assume that there is a large gap between the  and  eigenvalue of the graph. This assumption implies that the graph can be partitioned into induced expanders which have very small outside expansion \cite{OT14}. It follows that by utilizing the first  eigenvectors of the Laplacian matrix one can recover these expander graphs. However, the existence of a large size induced expander (possibly with large outside expansion) does not  guarantee the existence of small eigenvalues, so, in our settings, the spectral methods fail to recover the hidden expander.




\subsection{Our SDP relaxation}
As alluded to in the previous section, the known local and spectral algorithms fail to find a large induced expander in a given graph. Therefore, in this work, we use semidefinite programming to write a convex relaxation of \eqref{eq:benchmarkinducedexp}. 
There are two underlying obstacles to write a SDP relaxation for our problem. Firstly, the local neighborhood of a vertex in an expander graph may be very sparse and look like just a tree. Therefore, unlike the Lov\'asz theta function \cite{Lov79},  being an expander does not enforce any constraints on the local neighborhoods. 
Secondly, having an induced expander of size say  does not imply any global constraint on the structure of . So, our SDP constraints must be ``localized''   to the induced expander that we are trying to find.




Before describing the relaxation, we need to set up a notation and write an equivalent definition of expander graphs.
For a symmetric matrix , we say  is positive semidefinite (PSD), , if for any vector ,

For two matrices , we write  if  is PSD. 

Fix a set  and let  be a complete graph induced on . 
It is a simple fact that all (except the first) eigenvalues of the Laplacian matrix of a complete graph of size  are equal to . 
Since all (except the first) eigenvalues of  are at least  we can write

Next,  we use the above simple inequality to write our SDP relaxation of \eqref{eq:benchmarkinducedexp}.
See \ref{sdp:noh} for the details of our SDP relaxation.
\begin{figure*}
\centering
\fbox{\parbox{5in}{ \vspace*{0mm}
\begin{center}{\bf \setword{SDP 1}{sdp:noh}}\end{center}\vspace{-.7cm}

}}
\end{figure*}
Note that the first constraint of the SDP, \eqref{eq:lambdaconstraint}, is not convex. To make it convex, it is enough to solve the SDP with an explicit value of , and then run a binary search to maximize .


Let us show that \ref{sdp:noh} is a relaxation of \eqref{eq:benchmarkinducedexp}, i.e., its optimum value is at least .
Let  such that  be the set maximizing \eqref{eq:benchmarkinducedexp}.

Our intended integral solution is defined as follows:
 We let  if both endpoints of  are in  and zero otherwise, and we let  if  and zero otherwise. 
Let us verify the first constraint of the SDP and the rest are easy to check. It is easy to see that 
 is the Laplacian of the induced graph . On the other hand, 
is the Laplacian of a complete graph  on  scaled by . 
Therefore, the first constraint of the SDP follows by \eqref{eq:GKSlambda2}.

We can strengthen the above relaxation (and our results) when the optimum induced expander is loosely connected to the outside. That is, suppose the optimum set  of \eqref{eq:benchmarkinducedexp} satisfies

Let  be the set of edges between the vertices of .
Then, by the above inequality,

So, we can strengthen \ref{sdp:noh} by adding a relaxation of the above inequality. See \ref{sdp:withh} for the new SDP. 
Note that, although the constraint \eqref{eq:hconstraint} is nonlinear, we can make it linear by introducing new variables  where   for all .
It is an easy exercise that for a set , the vector solution  that we constructed in the preceding paragraphs satisfy constraint \eqref{eq:hconstraint}.
\begin{figure*}
\centering
\fbox{\parbox{4in}{ \begin{center}{\bf \setword{SDP 2}{sdp:withh}}\end{center}\vspace{-.7cm}

}}
\end{figure*}


\subsection{Our Results}
\label{subsec:ourresults}
In this subsection we describe the main results of this paper. 
Before describing our main result, we design a simple greedy algorithm analogous to the work of Kannan, Vempala and Vetta \cite{KVV04} (and \cite{Tre05,AO14}) for the largest induced expander problem. 
\begin{theorem}
\label{thm:greedy}
There is a polynomial time algorithm that for any -regular graph , , returns a set  of size  and spectral expansion 

where .
\end{theorem}
The algorithm simply uses repeated applications of the spectral minimum bisection algorithm to find an induced expander. See \autoref{sec:greedy} for the proof of the above theorem. The main downside of the above result is the polynomial dependency on  which is essential to the greedy algorithm (see \autoref{prop:tightgreedy}). 
In particular, if  (and ), any connected subgraph of  of size  is a -expander.

In our main result, we use \ref{sdp:noh} to exponentially improve the polynomial dependency on  in the greedy algorithm. 
We design a bicriteria approximation algorithm for ; we show that any feasible solution of \ref{sdp:noh} can be rounded to a set of size  and spectral expansion .

\begin{restatable}{theorem}{mainthm}
\label{thm:maintheoremwithoutoutsideexpansion}
There is a polynomial time algorithm that for any -regular graph ,  and any feasible solution  of \ref{sdp:noh},
 returns a set  of size  and spectral expansion
 
\end{restatable}
In the regime where  the approximation factor of the above theorem is  (up to constants).
As a simple corollary, because of logarithmic dependency on , we can use the above algorithm to find an -expander of size  in  assuming the existence of an -expander of a similar size.

The  loss in the above theorem essentially follows because of the connection to the small set expansion problem.
To make this connection more rigorous, we complement the above theorem and we show that, assuming  is sufficiently large, 
 the integrality gap of \ref{sdp:noh} is at least .
\begin{theorem}
\label{thm:IG1}
The integrality gap of the \ref{sdp:noh} is .
\end{theorem}

Our integrality gap example is made up of a hypercube of  dimensions where every vertex is blown up to a cloud of  vertices. For every edge of the original hypercube, we add a complete bipartite graph of weight  between the vertices of the corresponding clouds.





Furthermore, we show that in certain regimes we can improve the exponential dependency on  assuming the optimum solution of the largest induced expander problem has a small (outside) expansion. \begin{restatable}{theorem}{thmmainnoexp}
\label{thm:mainwithoutsideexpansion}
	There is a polynomial time algorithm that for any -regular graph, , , and any feasible solution  of \ref{sdp:withh}, returns a set  of size at least , and spectral expansion
	
\end{restatable}
As a corollary of the above theorem, assume that  and , i.e., there is a set  of size  such that  and . Then, by the above theorem, in polynomial time we can find a set  of size  such that

























\subsection{Preliminaries}
Throughout the paper, we use bold letters to represent vectors. 
Unless otherwise specified, we let  
represent a feasible solution of \ref{sdp:noh}. Note that since feasible solutions of \ref{sdp:withh} is a subset of feasible solutions of \ref{sdp:noh}, any result for feasible solutions of \ref{sdp:noh} extends to the solutions of \ref{sdp:withh}.
Without loss of generality, we extend  to all unordered pairs , and we let   whenever .

For two disjoint subsets of vertices , we let 

be the edges connecting  to .
For a vector , we let  
. 
We use  to denote the  graph with vertex set  where the weight of the edge connecting each pair of vertices  is .
Similarly, we use  to denote the graph weighted by vector . 

For any vertex , let  

be the weight of .
Observe that if  then all edges incident to  have weight . It is easy to see that any feasible solution of the SDP remains feasible when we delete all vertices of weight zero.
Therefore, throughout the paper we assume that  for all .

We define the \emph{width} of  to be . 
The weighted expansion of a set  in  (and ) is the ratio of the sum of the weights of the edges in the cut  to the sum of the 
weights of vertices of ,


\subsection{Background on spectral graph theory}
\label{sec:spectralgraphtheory}
Perhaps the most natural property 	of the Laplacian matrix is the simple description of their quadratic form. For any vector , 

Note that if  is weighted every term in the RHS will be scaled by the weight of the edge .
One simple consequence of the above identity is that the Laplacian is always a PSD matrix. 
A simple application of the above identity is that we can write the size of a cut  as a quadratic form. For  we get,  
 

As alluded to in the introduction, the Cheeger's inequality relates the second eigenvalue of the Laplacian matrix to . The left side of \eqref{eq:cheeger} is known as the \emph{easy} direction, and the the right side is the \emph{hard} direction. The proof of the hard direction follows by a simple rounding algorithm known as the \emph{spectral partitioning algorithm} which rounds the second eigenvector of the Laplacian matrix to a set  of (size  and) expansion . 
For the sake of completeness, here we describe the algorithm:
Let  be the second eigenvector of . Sort vertices based on , and call them . Return the best threshold cut, i.e., 



One can use repeated applications of the preceding algorithm to approximate the minimum bisection of a given graph . See \autoref{alg:minbisection} for the details of the algorithm. 
\begin{lemma}
\label{lem:bisection}
 Let  be a graph with maximum degree . For every , Algorithm \ref{alg:minbisection} returns a set  such that either  and , or  and .
\end{lemma}
The proof of the above lemma simply follows from \autoref{thm:cheeger} and the fact that for any two disjoint sets , .
\begin{algorithm}
\begin{algorithmic}[1]
	\Input A graph  with maximum degree  and .
	\Output A set  s.t., either   and , or   and 
	\State Let .
	\While{ }	
		\State If  then \textbf{return} .
			 \label{line:returnexpander} 
		\State Otherwise, run the spectral partitioning on  and let  be the output.
		 	\State Say . let . 
	\EndWhile
	\Return .
\end{algorithmic}
\caption{Spectral Bisection Algorithm}
\label{alg:minbisection}
\end{algorithm}





\section{Proof Overview}\label{sec:proofoverview}
Let  be the graphs weighted by the  and  vectors respectively. In the first step of the proof, we exploit the main constraint of the SDP, i.e., \eqref{eq:lambdaconstraint}, to show that  is a -small set  weighted expander, i.e., every set  of size   satisfies .
Although the proof of this statement is simple, it crucially uses the SDP constraints.
Firstly, we use \eqref{eq:lambdaconstraint} to show that for any set ,  Then, we use constraints \eqref{eq:sumyconstraint} and \eqref{eq:maxyconstraint} to show that  is a -small set  weighted expander; this implies that  is a -small set weighted expander (see \autoref{lem:expandingsmallsets} for the details of the proof). 
This statement  enlightens  a deep connection between our SDP and the small set expansion problem which may have further applications in understanding the computational complexity of the small set expansion problem. 

In the second step, we  essentially reduce the problem to the case where  is almost a constant vector. 
The consequence is that when  is a constant vector,  the weighted expansion is the same as (unweighted) expansion up to a normalization. Therefore,  we can conclude from the previous paragraph that  is a small set expander.
More precisely, in the second step, we find a set  of small width such that . Note that any such set must satisfy . Since  has a small width, the  vector restricted to the induced graph  looks like a constant vector. 
If , then indeed  is a small set expander. 
But, if , we cannot conclude that \emph{any} small set  has a large unweighted expansion. 
Nonetheless, since  is small, a random small set has large unweighted expansion; in particular, if we partition  into many small sets say , we can conclude that 

This fact will be crucially used in the third step to find an induced expander.


To find   we run the following randomized algorithm: First we map each vertex , to the point  on the real line. Then, we randomly choose vertices in a window of length , where the probability of each window is proportional to the total weight of the vertices that it contains.  By construction, the width of any set in the distribution is at most ; we use an averaging argument to show that the expected weighted expansion of a random window is proportional to  (see \autoref{lem:nonexpandingset} for the details of the proof)

In the last step of the proof we design an algorithm to find an expander  in the set  that we found in the previous step. We use the spectral bisection algorithm to recursively partition  until we find an -expander, or  the size of every set in the partition is less than . It follows that a random set in the final partition has  unweighted expansion . Since  has width , the \emph{weighted} expansion of any subset  is within  of its unweighted expansion. 
But, by  \eqref{eq:hGxbigTi} a random set in the final partition must have a weighted expansion at least . 
Letting  proves the theorem.
\section{The Analysis of the Simple Greedy Algorithm} 
\label{sec:greedy}
In this section we prove \autoref{thm:greedy}.
First we prove the following simple lemma.

\begin{lemma}
\label{lem:graphdecomposition}
There is a 
polynomial algorithm (Algorithm \ref{alg:findingexpander}) that for every graph  with  vertices of maximum degree  and parameters , returns one of the followings. 
\begin{enumerate}[i)]
\item \label{case:largeexpander} A set  of size at least 
 and  
\item \label{case:decomposition} A
partition  of  into sets of size at most  such that  

\end{enumerate}

\end{lemma}
\begin{proof}
If   then we are done. Otherwise, we split 
 into two pieces by the spectral bisection algorithm introduced in \autoref{lem:bisection} for . Then, we recursively run the bisection algorithm  
on each new set until we find either an -expander, or all sets have size at most . The details are described in  \autoref{alg:findingexpander}. If we find an -expander (Line \ref{line:elseline} of  \autoref{alg:findingexpander}),  its size is at least , and we are done. 

\begin{algorithm}
\begin{algorithmic}[1]
	\Input A graph  with maximum degree  and parameters .
	\Output A subset of  or a partitioning of it. 
	\State Let . \While{ there is a set in  with more than   vertices}
	    \ForAll {  with }
	        \State Run \autoref{alg:minbisection} on input  and . Let  be the output.
	        \State If , return .
	        Otherwise, add  and  to  and remove . \label{line:elseline}
		    \EndFor
	\EndWhile	
		\State Return .\label{line:nonexpanding}
\end{algorithmic}
\caption{Algorithm for finding either a large expander or a sparse partition}
\label{alg:findingexpander}
\end{algorithm}
Otherwise, Let  be the partition of  at the end of the algorithm. 
In this case, by description of the  algorithm all sets in  have size at most , so all we need to do is to prove \eqref{eq:numberofedges}.
Let  be the set  at the end of iteration  of the main 
loop of the algorithm and define .    
By  description of the algorithm, we have the following two simple facts.
\begin{fact}
For any , . 
\end{fact}
The above holds since  is obtained by splitting all sets in  into two new sets by a cut of expansion at most .
\begin{fact}
The number of iterations of the main loop is at most .
\end{fact}
To see this, note that the algorithm terminates after  steps where  is the smallest number for which all the sets in  have size at most . Furthermore, in every iteration we split every set into two pieces, each of them having at most  fraction of the vertices of the initial set. 
Combining these two facts, we get \eqref{eq:numberofedges} which completes the proof. 
\end{proof}

\begin{proofof}{\autoref{thm:greedy}}
We show that if for some  the output of \autoref{alg:findingexpander} for  is Case \ref{case:decomposition}, then 
So, to find an induced expander, it is enough to run \autoref{alg:findingexpander} for an  smaller than the RHS.
Suppose that for some  the algorithm returns a partition  of 
 satisfying Case \ref{case:decomposition}. 
By definition 
of , there is a set  of size  
such that . So we have  

where in the second inequality we use Cheeger's inequality and the fact that for every ,  as  by Case \ref{case:decomposition} of the 
lemma.
Using \eqref{eq:numberofedges}, 
we get that

which proves \eqref{eq:contradictionwithnumofedges}.
\end{proofof}
\newline

In the following proposition we show that our analysis in the preceding theorem is essentially 
tight and the largest induced expansion that Algorithm \ref{alg:findingexpander} guarantees is . 
\begin{proposition}\label{prop:tightgreedy}
For any , there exists a graph  which is -regular such that the output of the algorithm of \autoref{thm:greedy} on input  and  is an  -expander. 
\end{proposition}
\begin{proof}
Let  be a complete graph with  vertices where every edge has weight . We construct  by attaching a path  of length  to each , where the weight of each edge of each path is .  Note that these paths are mutually disjoint. Since the induced subgraph  of  is an -expander, we have .


To prove the proposition, it is sufficient to show that for any ,  if we run  \autoref{alg:findingexpander} on ,  and , then
all of the subsets of  that we construct in the algorithm are -expanders. 
Let  be the set containing half of  together with the paths attached to its vertices. It is easy to see that  is the minimum bisection (and the sparsest cut) of . 
So even with an access to an oracle for the minimum bisection (or the sparsest cut) problem,
 will be divided into  and  in the first step of Algorithm \ref{alg:findingexpander}. By a similar argument, it follows that in the second iteration,  will be divided into  parts, where each of them contains a quarter of the vertices of  together with the paths attached to them. Continuing this line of reasoning, at the end of the algorithm,  is divided into  sets each with exactly  fraction of the vertices of  together with their attached paths. 
Depending on the value of , the algorithm terminates at some iteration. But, since  all of the aforementioned sets are -expanders, the best set that the algorithm  finds is an -expander.
\end{proof}

\section{The SDP Rounding Algorithms}
\label{sec:sdprounding}
In this section, we prove our main results, theorems\ref{thm:maintheoremwithoutoutsideexpansion} and \ref{thm:mainwithoutsideexpansion}. 
Our proof follows the  plan that we discussed in \autoref{sec:proofoverview}.
Throughout this section, we assume  is a -regular graph and  represents a feasible solution of \ref{sdp:noh} or \ref{sdp:withh}. 
In the first step, we show that  is a -small set weighted expander.
\begin{lemma}
\label{lem:expandingsmallsets}
For any  of size at most , we have .
\end{lemma}
\begin{proof}
First we prove  , and then by  constraint \eqref{eq:lambdaconstraint}, we conclude that .
We have 

where the first inequality uses  Constraint \eqref{eq:maxyconstraint}. 
Note that Constraint \eqref{eq:sumyconstraint} implies that . Combining it with the above inequalities and our assumption that , we get . Therefore, to 
prove the lemma, it is enough to show that . This directly follows from Constraint \eqref{eq:lambdaconstraint}. We have 

So .
\end{proof}
In the next lemma, we provide an algorithm to find a set of vertices with small weighted expansion in  and relatively small width. 
\begin{lemma}
\label{lem:nonexpandingset}
Let . For any , there is a set  such that  and . Furthermore, such a set can be found in polynomial time. 
\end{lemma}
\begin{proof}Let  be the set of vertices with -value , and let  . 
In addition, we define  and  to be  and  respectively. 



It is sufficient to prove there is a  such that 

 This proves the lemma since by definition of  

In addition, since there are at most  possible such sets, a simple linear time algorithm find the best . Consider a  probability distribution with density function , for any . To prove \eqref{eq:windowgoal}, it is enough to show  
  
Intuitively, if  and  are close, then the  probability that 
 is cut by a set , which is essentially proportional 
to , is small. On the other hand, since 
,  as  and  gets further, the 
relative contribution of , , 
decreases. 
We start by upper bounding .

where  is the normalizing 
constant of the probability distribution. The last inequality holds, 
since an edge  appears in  
only when exactly one of  the numbers  and  lies 
in the interval .
It is fairly easy to verify  . Substituting  
into above, to show \eqref{eq:expectationgoal}, it is enough to prove 
that 


To prove \eqref{eq:mainineq}, it is enough to show an analogous 
statement for  every vertex . Assume there is an ordering on the vertices of the graph such that  implies  and set . For any vertex , we show  

First, we show that by summing up \eqref{eq:singlevertexcont} over all vertices, we obtain \eqref{eq:mainineq}. Then we prove \eqref{eq:singlevertexcont}. Observe that summing up LHS of \eqref{eq:singlevertexcont} over all , gives the LHS of \eqref{eq:mainineq}. Therefore, it is sufficient to show 

We prove this by Jensen's inequality.
Since  is a concave function, by Jensen's inequality we have  \\

where the first and second equality use definitions of  and , respectively. This proves \eqref{eq:singlevertexcontribution2} which implies that by summing up \eqref{eq:singlevertexcont} over all vertices we get \eqref{eq:mainineq}. It remains to prove \eqref{eq:singlevertexcont}. By definition of , to prove  \eqref{eq:singlevertexcont}, we can show \\

By definition of , is a probability distribution on neighbors  of  where , so we can rewrite the LHS in terms of the entropy of this distribution, as follows: 

where the inequality holds since  has at most  neighbors and consequently  the entropy of the distribution defined above is at most .  
As stated before it  proves \eqref{eq:singlevertexcont} and 
finishes the proof of the lemma.
\end{proof}



\begin{lemma}
\label{lem:findingexpander}
Given , for any , there is a set  satisfying one of the following cases. 
\begin{enumerate}[i)]
\item \label{case:expander}  and .
\item \label{case:nonexpanding}  and   
where . 
\end{enumerate}
\end{lemma}

\begin{proof}
If ,  satisfies Case \ref{case:nonexpanding} and we are done. Otherwise, we set  and run  \autoref{alg:findingexpander} on input subgraph ,  and . If it returns a set , then we are in Case \ref{case:largeexpander} of  \autoref{lem:graphdecomposition} which implies we have found the desired expander. Now, assume the output of the algorithm is Case 
\ref{case:decomposition}, a partition  of  satisfying \eqref{eq:numberofedges}. Since by 
 \autoref{alg:findingexpander}, any element of  has at 
most  vertices, to prove the lemma, it suffices to 
show that there exists a set  for which \eqref{eq:nonexpandingset} holds. To show it, we consider a probability distribution on elements of  where for every ,  and prove that 
 
We can write  as follows: 

So comparing to our goal, \eqref{eq:expectedexpansion}, we only need to prove 

Note that it simply follows from \eqref{eq:numberofedges} and 

which is implied by definition of .
\end{proof} 
It is easy to see that Theorems \ref{thm:mainwithoutsideexpansion} and \ref{thm:maintheoremwithoutoutsideexpansion} follow from the above three lemmas. 

\mainthm*
\begin{proof}We combine Lemmas \ref{lem:nonexpandingset}, \ref{lem:findingexpander}, and \ref{lem:expandingsmallsets} to prove the theorem. Let  be two parameters that we will fix later. First, by  \autoref{lem:nonexpandingset}, we find a set 
 with width  such that 

where the last 
inequality holds since  for any . Then, we run the algorithm in  
\autoref{lem:findingexpander} 
on subgraph  and parameters  and . Let  be the  output. We choose  and 
 such that . 
This implies  Case 
\ref{case:expander} of  \autoref{lem:findingexpander} is satisfied; this is because Case \ref{case:nonexpanding} implies 

 which contradicts  \autoref{lem:expandingsmallsets} as . The second inequality in the above follows by \eqref{eq:hxSissmall}. Letting

we get .
Therefore, by Case \ref{case:expander} of \autoref{lem:findingexpander},  and 

as desired. In the second equation we absorbed the term  in the denominator in .
\end{proof}

Using similar ideas combined with the constraint \eqref{eq:hconstraint} of \ref{sdp:withh}, we can prove  \autoref{thm:mainwithoutsideexpansion}.

\thmmainnoexp*
\begin{proof}The structure of the proof is very similar to the proof of  
\autoref{thm:maintheoremwithoutoutsideexpansion}. Again, we use  
\autoref{lem:nonexpandingset} to find a set  with 
width , and run the algorithm in \autoref{lem:findingexpander} on  ,  and a proper value of 
. The main 
difference  is to use Constraint \eqref{eq:hconstraint} of 
the \ref{sdp:withh} to prove a stronger upper bound on the weighted expansion of , 

First, recall that by \autoref{lem:nonexpandingset}, 
where .
It follows by Constraint \eqref{eq:hconstraint} (and  ) that 

To prove \eqref{eq:betterexpansionS}, it is enough to note that  is a decreasing function of  for , and  as  by the lemma's assumption. Therefore, 

Similar to \autoref{thm:maintheoremwithoutoutsideexpansion}, if we choose  such that 

then (by an application of \autoref{lem:expandingsmallsets}) Case \ref{case:expander} of \autoref{lem:findingexpander} is satisfied.
Letting   
and using \eqref{eq:betterexpansionS}, it is easy to see that \eqref{eq:hxSbetterlambda} is satisfied. 
Therefore, by Case \ref{case:expander} of \autoref{lem:findingexpander},  and 

as desired. In the second inequality we use that  for .
\end{proof}


\section{Integrality Gap}
In this section we prove that the integrality gap of \ref{sdp:noh} is  . 
\begin{theorem}
\label{thm:IGfirst}
For any integer  and , there exists an -regular graph  such that  , but the optimal value of \ref{sdp:noh} is at least .
\end{theorem}

\begin{proof}
Let  be a -dimensional hypercube with  vertices. We let  be a  sufficiently large multiple of  and construct  as follows:   
We blow up every vertex  by a cloud of   vertices, called . For every edge , 
we place a complete  bipartite graph between  and , where 
the weight of every edge is \footnote{Here for the sake of 
simplicity, we construct a weighted graph , but one can extend the construction to unweighted graphs by replacing the weighted complete bipartite graphs with constant degree expanders.}.
By definition,  is a -regular graph. First, we show  and then we 
build a feasible solution of \ref{sdp:noh} of value .

For every , we prove , which 
by Cheeger's inequality (\autoref{thm:cheeger}) implies  and 
consequently .
 Without loss of generality, 
assume there is a  dimension cut  of  such that the union of clouds of vertices of  cut . Let . Since for each vertex , only  fraction of edges incident to  are leaving , we have 

Similarly, ; so . 

It remains to  present a feasible 
solution for \ref{sdp:noh}  of value . We  
construct  as follows: \\ 

With this solution, the only non-trivial constraint of  \ref{sdp:noh} that we should verify is the first constraint, i.e,

Note that since  for all ,  (and ).
Let  be an edge of . Since  is a complete bipartite graph, we have 



Rewriting the above inequality by extending  and  to , by inserting zero rows and columns corresponding to vertices in , we get
 
Summing up the above inequality  over all  gives 
\eqref{eq:SDPmainconstraint}.
\end{proof}



\section{Discussion}
We provide the first approximation algorithms for the largest induced expander problem. Let us conclude by providing several open problems and future directions. Firstly, we can show that the  exponential dependency on  in \autoref{thm:maintheoremwithoutoutsideexpansion} is necessary to our rounding algorithm. But, we are not aware of any tight integrality gap example. It is a fascinating question if this dependency can be improved to . Secondly, our techniques fail to find induced expanders in dense regular graphs when  is significantly larger than ; in such cases, one can construct a trivial integral SDP solution for any given graph . A resolution of this question can lead to new approximation algorithms for the hidden clique problem. Perhaps a practical downside of our algorithm is the need to solve a semidefinite program. It is interesting if one can reproduce our results using fast spectral methods. 






\bibliographystyle{alpha}
\bibliography{references}










\end{document}
