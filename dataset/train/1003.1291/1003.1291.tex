\documentclass[12pt,a4paper]{article}
\usepackage{graphicx}
\usepackage{amsmath}
\usepackage{hyperref}
\usepackage{pstricks}
\usepackage{verbatim}
\usepackage[utf8x]{inputenc}
\hypersetup{bookmarksopen=true,
  bookmarksnumbered=true,
  pdftitle = {The Grid[Way] Job Template Manager, a tool for parameter sweeping},
  pdfsubject = {Parameter sweep, Grid computing},
  pdfkeywords = {e-science, parameter sweep, grid computing, middleware, high-throughput computing},
  pdfauthor = {A. Lorca, E. Huedo, I.M. Llorente},
}
\def\unix{{\sc Unix}}
\def\linux{{\sc Linux}}
\def\solaris{{\sc Solaris}}
\def\c{{\sc C}}
\def\cpp{{\sc C}++}
\def\make{{\sc Make}}
\newcommand{\eq}[1]{Eq.~(\ref{#1})}
\newcommand{\eqs}[2]{Eqs.~(\ref{#1}\ref{#2})}
\newcommand{\fig}[1]{Fig.~\ref{#1}}
\newcommand{\tab}[1]{Table \ref{#1}}
\newcommand{\tabs}[2]{Tables \ref{#1}\ref{#2}}
\newcommand{\sect}[1]{Sect.~\ref{#1}}
\newcommand{\arxiv}[1]{\href{http://arxiv.org/abs/#1}{#1}}
\newcommand{\Tr}[1]{\: \mathrm{Tr}\!\left(#1\right)}
\newcommand{\terminal}[2]{\framebox{\begin{minipage}{\textwidth}\hspace{-0ex}{#1{\tt{\noindent #2}}}\end{minipage}}}
\newenvironment{term}{\endgraf\scriptsize\noindent\verbatim}{\endverbatim}
\title{The Grid[Way] Job Template Manager,\\ a tool for parameter sweeping}
 \author{\bigskip
{Alejandro Lorca\footnote{Corresponding author, e-Mail:\href{mailto:alejandro.lorca@fdi.ucm.es}{alejandro.lorca@fdi.ucm.es}}, Eduardo Huedo\footnote{e-Mail:\href{mailto:ehuedo@fdi.ucm.es}{ehuedo@fdi.ucm.es}}, Ignacio M. Llorente\footnote{e-Mail:\href{mailto:llorente@dacya.ucm.es}{llorente@dacya.ucm.es}}}\\* \vspace{-0.5ex}
{\small \em Facultad de Inform{\'a}tica, Universidad Complutense de Madrid,}\\*
{\small \em C/ Prof.\ Jos\'e Garc\'{\i}a Santesmases s/n, E-28040, Madrid, Spain}
}
\date{\today}
\begin{document}
\maketitle
\begin{abstract}
Parameter sweeping is a widely used algorithmic technique in computational science. It is specially suited for high-throughput computing since the jobs evaluating the parameter space are loosely coupled or independent. 

A tool that integrates the modeling of a parameter study with the control of jobs in a distributed architecture is presented. The main task is to facilitate the creation and deletion of job templates, which are the elements describing the jobs to be run. Extra functionality relies upon the GridWay Metascheduler, acting as the middleware layer for job submission and control. It supports interesting features like multi-dimensional sweeping space, wildcarding of parameters, functional evaluation of ranges, value-skipping and job template automatic indexation.

The use of this tool increases the reliability of the parameter sweep study thanks to the systematic bookkeping of job templates and respective job statuses. Furthermore, it simplifies the porting of the target application to the grid reducing the required amount of time and effort.
\end{abstract}
\section{Program summary}
\begin{itemize}
\item {\em Title of the program}: Grid[Way] Job Template Manager (version 1.0, released on February 26th, 2010).
\item {\em Catalogue identifier}:
\item {\em Program obtainable from}:\\ \url{http://dev.gridway.org/projects/gwjobtemplatemanager}.
\item {\em Computer}: any (tested on PC x86 and x86\_64).
\item {\em Operating system}: Unix, GNU/\linux{} (tested on Ubuntu 9.04, Scientific Linux 4.7, centOS 5.4), Mac OS X (tested on Snow Leopard 10.6).
\item {\em Programming language used}: perl 5.8.5 and above.
\item {\em Additional programs/libraries used}: The GridWay Metascheduler \cite{gridway}.
\item {\em Memory required to execute with typical data}: 10MB.
\item {\em No.~of processors used}: 1.
\item {\em No.~of bytes in distributed program, including test data, etc.}: 20799.
\item {\em Distribution format}: Gzipped tar file.
\item {\em High-speed storage required}: No.
\item {\em Keywords}: e-science, parameter sweep, grid computing, middleware, high-throughput computing.
\item {\em Nature of the physical problem}: To parameterize and manage an application running on a grid or cluster.
\item {\em Method of solution}: Generation of job templates as a cross product of the input parameter sets. Also management of the job template files including the job submission to the grid, control and information retrieval.
\item {\em Restriction of the complexity of the problem}: The parameter sweep is limited by disk space during generation of the job templates. The wildcarding of parameters cannot be done in decreasing order. Job submission, control and information is delegated to the GridWay Metascheduler.
\item {\em Typical running time}: From half a second in the simplest operation to a few minutes for thousands of exponential sampling parameters.
\end{itemize}
\section{Introduction}
Parameter sweeping is a very common strategy in order to solve complex scientific problems. It consists on scanning different points on a relevant parameter space region. There are many possible interests on doing such, for instance, the optimization of a functional by finding its minima over the scanned region, to parameterize an analytical function with the help of interpolated values or to understand different regimes of simulated physical models. The variety of the scientific disciplines profiting from this strategy is overwhelming; experimental high-energy physics, astrophysics and astro-particle physics, life sciences, computational chemistry,  earth sciences, computational linguistics, game theory, etc, are just prominent examples.

The evaluation of parameter space points is a simple problem within computational theory, but requires, in turn, some pre-processing of the problem according to a given search criteria, the systematic exploration of the parameter space points and a final data post-processing.

According to the application profile three different categories can be established for better understanding the scope of the tool:
\begin{itemize}
\item Parallelization. The second stage mentioned above, in which the parameter space is explored, requires the evaluation of some functional for each point. Making this stage {\em parallel} is in some cases unfeasible and the applications are run in {\em sequential} mode. Those parallelizable applications require some porting (i.e. either to cluster, grid or supercomputers) to improve the execution time, surmount memory limitations, etc.
\item Interactivity. User intervention might be automated to a certain degree depending on the application profile. If it is not required at any stage of the computation we will consider the applications as {\em non-interactive}. Otherwise, for the {\em interactive} ones, the user is obliged to take some decision during execution.
\item Recursion. On one hand, {\em single-pass} applications do not profit from the knowledge of the parameter space exploration or the results at a post-processing stage. On the other hand, if the application is aware of such feedback, an improved range of the parameter space can be chosen for optimizing results or further testing. This workflow is common in {\em master-worker} execution profiles.
\end{itemize}

With such classifications in mind, the {\em parallel, non-interactive, single-pass} applications are the target group for the Grid[Way] Job Template Manager, specially those with a large amount of independent tasks to be accomplished.

Large-scale problems well suited to high-throughput computing can be tackled in different manners, from last generation supercomputers to distributed solutions such as workstations or PCs. Indeed, grid computing has emerged during the last two decades as a new and affordable computational paradigm. The main distinguishing feature of this distributed architecture is the integration of different computing resources, typically involving high performance clusters (computing elements) and massive database storages (storage elements) hosted on universities, research centres, private companies, etc. The access to the grid is mediated through a software layer, usually referred to as the {\em middleware}, which takes care of the user's certificate checking, data transfer, host monitoring, file registering, and many other additional services.

There are other tools on the market dealing with parameter studies on the grid, like Nimrod/G \cite{Abramson:2000} or APST\cite{Casanova:2003} from AppLeS \cite{Casanova:2000}. Nimrod/G possess a ``parametric engine'' which is the agent centralizing the parameterization of the experiment, job creation, submission and control. Nimrod/G requires a static declarative language, allowing multi-dimensional analysis to set of strings and basic real ranges. Alternatively, the AppLeS Parameter Sweep Template uses a simple, XML-based\footnote{Extensible Markup Language.} interface which can be used from the command-line or called from scripts, but it is left to the user the enumeration of individual tasks. In both cases, the scheduling and other grid-related tasks are part of the projects. This is not the case of the Grid[Way] Job Template Manager, because the GridWay Metascheduler handles those operations directly.  As will be shown later, the reason for naming our tool with a bracket in the word Grid[Way] tries to make clear the relation to the grid technology, being optional the underlying use of GridWay.

GridWay itself contains a mechanism to proceed with a collection of jobs (i.e. job array)\cite{Huedo:2004}, but it is certainly limiting: only single parameter variation through ingeters, both in step and values, can be achieved. This is somewhat similar to the possibilities integrated on the gLite WMS job description language \cite{JDL}. A remarkable effort to stardardize the parameter sweeps has been carried out \cite{JSDL}, but the approach is more a formal extension of the job standard description language than a useful grammar easy to by remembered by the end user.

The structure of the paper is as follows: The \sect{algorithm} describes the method and framework used for the composition of the parameter sweep region directly from the spanning of the one-dimensional parameter sets. It also describes the syntax of the parameter file. \sect{setup} moves on to the technical steps to have the tool up and running while \sect{usage} shows the general use of the tool. Several examples have been worked out in detail in \sect{examples} with increasing dificulty. Finally we summarize the work in \sect{conclusion}.


\section{Algorithm}\label{algorithm}
The basic working environment of the program is depicted in \fig{basic}. The user specifies what is going to be performed through the command line interface and, depending on which tasks has been asked for, some input files will be required. The parameter sweep specification comes from the parameter file and job template appendices from the template file. During the processing, some calls to the GridWay Metascheduler are required for submitting, purging, killing and getting information about jobs. The main outcome of the tool are the job template files, which contain the information about the parameter sweep study and are ready for submission. The information about the job creation and deletion, as well as from the jobs coming from these job template files is available through the standard output and error. Additionally, if GridWay is used, the corresponding jobs' output will be available as extra files.
\begin{figure}[!ht]
\center
\includegraphics[scale=0.5]{basic}
\caption{Grid[Way] Job Template Manager framework. Continuous lines represent input/output while dashed lines indicates interaction with GridWay through optional instructions and information feedback.}
\label{basic}
\end{figure}

\subsection{Mathematical framework}
The starting point for carrying out a parameter study is to define which parameter points are considered for evaluation. Let denote by  a parameter point belonging to the direct product space of suitable dimensions :

being  the respective one-dimensional space of the -th argument.

A given set of points  of arbitrary size  forms the complete parameter sweep set:

but for simplification we will consider only the case where any element  comes from a Cartesian product of subsets  of some chosen elements, each subset with size . Thus,


Indexing the -tuple elements of  is trivial when following the natural ordering of each set  until it gets exhausted, then incrementing the previous set.

Note the difference in labeling convention: the elements in each set  are indexed from  to , while the composition of the -tuples correspond to . This is because we expect the user to feed the application with  command line arguments, being each job uniquely indexed:


We have not yet described which is the allowed nature of the spaces  where the subsets  are included. Let us discuss this issue altogether with the mechanism to model the study.

\subsection{Parameter file parsing}
Next, the way to declare the sets  for each argument is explained. The declaration grammar has been chosen to be fairly simple for user's convenience:
\begin{itemize}
\item The parametric study, denoted by  is declared as  valid sentences in the parameter file.
\item Each set  is declared at the valid -th sentence of the file, one per line. It contains instructions to define the structure of the set and value assignments.
\item The words of the language are KEY=VALUE pairs, separated by blank spaces.
\end{itemize}

The structure of each set is declared in the first word. The following possibilities are currently available:
\begin{enumerate}
\item {\tt LOOPTYPE=LIST}. The set consists of a list of given values. These are assigned through an arbitrary number of {\tt VALUE=} pairs. Admitted values are taken as strings.
\item {\tt LOOPTYPE=RANGE}. The set is built according to a linear range of values. The keys {\tt START} and {\tt END} define the initial and final elements of the set, while the tags {\tt STEP} or {\tt POINTS} fix either the iteration increment between each element or the total number of points of the set respectively. Admitted values can be entered in the following formats:
\subitem a) integer (i.e. {\tt -4} or {\tt 54764563}),
\subitem b) floating point up to 16 digits (i.e. {\tt 567884.2234}),
\subitem c) scientific up to  (i.e. {\tt 1.4E-12}),
\subitem d) characters (i.e. {\tt j} or {\tt z}),
\subitem e) arbitrary-size\footnote{Should the user require this feature, then the the following option through the command line interface has to be added: {\tt --config use\_bignum=1}.} (i.e. {\tt 1000000000000000000000000001}).
\item {\tt LOOPTYPE=EXPRANGE}. It is similar to {\tt RANGE} but interpolates exponentially between the initial and final elements. Therefore a {\tt STEP=1} means exponential increases by one order of magnitude. Admitted values take the same form than for {\tt RANGE}.
\end{enumerate}
\begin{table}[!ht]
\center
{\tt
\begin{tabular}{ll}
\hline
\textrm{Structure} & \textrm{Assignment} \\
\hline
LOOPTYPE=LIST & VALUE= VALUE=  VALUE=\\
LOOPTYPE=RANGE & START= END= STEP=POINTS=\\
LOOPTYPE=EXPRANGE & START= END= STEP=POINTS=\\
\hline
\end{tabular}
}
\caption{Basic syntactic grammar for the -th line of the parameter file.  is the -th value of the set ,  is a linear step increment while  defines order of magnitude factor to separate points in the {\tt EXPRANGE}.}
\label{syntax}
\end{table}
A summary of the correct sentence composition is given in \tab{syntax}, where the square brackets ([~]) enclose optional words, and the pipe symbol () refers to mutually exclusive pairs.

Additionally, there are two other keys which may be included for modifying the evaluation of the sets, specially suited to the {\tt RANGE} and {\tt EXPRANGE}:
\begin{itemize}
\item{\tt SKIP}. It permits to remove the specific point from the set.
\item{\tt FUNCTION}. Any valid perl function or concatenation of functions which accept an argument are candidates to transform the -th element in the set  according to .
\end{itemize}
\begin{table}[!ht]
\center
{\tt
\begin{tabular}{lll}
\hline
\textrm{Key=Value} & \textrm{Description}\\
\hline
SKIP=&\\
FUNCTION= &\\
 abs&{\rm absolute value function}\\
 atan2&{\rm arctangent in the range - to }\\
 cos&{\rm cosine function}\\
 exp&{\rm raise to a power}\\
  hex&{\rm convert a string to a hexadecimal number}\\
 int&{\rm get the integer portion of a number}\\
 log&{\rm retrieve the natural logarithm for a number}\\
 oct&{\rm convert a string to an octal number}\\
 rand&{\rm retrieve the next pseudo-random number}\\
 sin&{\rm return the sine of a number}\\
 sqrt&{\rm square root function}\\
 srand&{\rm seed the random number generator}\\
 chomp&{\rm remove a trailing record separator from a string}\\
 chop&{\rm remove the last character from a string}\\
 chr&{\rm get character this number represents}\\
 crypt&{\rm one-way passwd-style encryption}\\
 hex&{\rm convert a string to a hexadecimal number}\\
 lc&{\rm return lower-case version of a string}\\
 lcfirst&{\rm return a string with just the next letter in lower case}\\
 length&{\rm return the number of bytes in a string}\\
 oct&{\rm convert a string to an octal number}\\
 ord&{\rm find a character's numeric representation}\\
 reverse&{\rm flip a string or a list}\\
 uc&{\rm return upper-case version of a string}\\
 ucfirst&{\rm return a string with just the next letter in upper case}\\
\hline
\end{tabular}
}
\caption{Optional tags available for modifying the standard composition of elements in each set.}
\label{optionalsyntax}
\end{table}
A summary of possible option values for the {\tt FUNCTION} key as well as the syntax is given in \tab{optionalsyntax}.
\subsection{Wildcarding}
Once the parsing of the file is finished, the tool has obtained sufficient information to create the Cartesian product given by \eq{cartesian}. A nice feature which allows parameter substitution and job template index substitution is wildcarding. The pattern for substitution has the following syntax:
\begin{itemize}
\item {\tt \\{2\},, \r_{1}, r_{2}, \ldots, r_{n}\{i\}} is performed at lower set declarations from  to .
\item {\tt \Pm>10\{JT\_ID\}'\\
	job\_template\_prefix & ''\\
	job\_template\_suffix & '.jt'\\
	std\_output\_dir & '.'\\
	std\_error\_dir & '.'\\
	input\_file\_default\_suffix & '.in'\\
	comment\_char & '\#'\\
	keyassignment\_char & '='\\
	separation\_char & ','\\
	separation\_char\_cli & ' '\\
	separation\_char\_filename & '\_'\\
	jt\_id\_to\_arg\_separation & '\_'\\
    unix\_operators & '\&|<>;()`'\\
	gridway\_submit & 'gwsubmit'\\
	gridway\_ps & 'gwps'\\
	gridway\_kill & 'gwkill'\\
	gridway\_wait & 'gwwait'\\
	gridway\_dir\_var & ''\\
	use\_bignum & 0\\
	huge\_number\_points & 10000\\
	inode\_size\_kB & 4 \\
\hline
\end{tabular}
}
\caption{Get\_config\_keywords parameter available. Strings are enclosed by single ticks.}
\label{keyword}
\end{table}
\begin{table}
\center
{\tt
\begin{tabular}{ll}
\hline
\textrm{Parameter} & \textrm{Default Value}\\
\hline
	Template\_executable & 'EXECUTABLE'\\
	Template\_arguments & 'ARGUMENTS'\\
	Template\_stdout\_file & 'STDOUT\_FILE'\\
	Template\_stderr\_file & 'STDERR\_FILE'\\
	Template\_job\_name & 'NAME'\\
	Template\_encloser\_char & ''\\
	Template\_end\_of\_line & ''\\
\hline
\end{tabular}
}
\caption{Get\_config\_template\_keywords. Strings are enclosed by single ticks.}
\label{templatekeyword}
\end{table}
The whole set of possible parameters to be assigned are given in \tabs{keyword}{templatekeyword}


\section{Usage}\label{usage}

The tool has been designed to be used through the command line interface of the users' terminal. It suffices to invoke the main command together with a subcommand which specifies the action to be performed and arguments to set the scope of the operation. Typed at the prompt, it reads:
\begin{verbatim}
gw_job_template_manager [OPTION] SUBCOMMAND ARG(S)
\end{verbatim}
where some options for debug and configure also exists. All the elements needed for a correct use are summarized in \tab{usagetable}.

\begin{table}[!th]
\center
\begin{tabular}{ll}
\hline
Subcommand & Description\\
\hline
{\tt -c, --create} & create templates\\
{\tt -d, --delete} & delete templates\\
{\tt -s, --submit} & submit the jobs from templates\\
{\tt -p, --purge} & purge the existing jobs from templates\\
{\tt -k, --kill} & kill the existing jobs from templates\\
{\tt -i, --info} & information about status of the submitted jobs\\
{\tt -v, --version} & version number of the program\\
{\tt -l, --license} & credits and license\\
{\tt -h, --help} & print help\\
\hline
Option & Description\\
\hline
{\tt -w, --worker} & add worker file\\
{\tt -t, --template} & add template file\\
{\tt     --signal} & add signal for kill\\
{\tt     --debug} & show debugging information\\
{\tt     --config key=value}& assign a key=value pair for configuration settings\\
\hline
Syntax\\
\hline
\multicolumn{2}{l}{{\tt -c <PARAMETER\_FILE> [-w WORKER\_FILE] [-t TEMPLATE\_FILE]}}\\
\multicolumn{2}{l}{\tt -d <all|[un]submitted|[un]finished|[un]successful|FROM-TO>}\\
\multicolumn{2}{l}{\tt -s <all|[un]submitted|[un]finished|[un]successful|FROM-TO>}\\
\multicolumn{2}{l}{\tt -p <all|[un]finished|[un]successful|FROM-TO>}\\
\multicolumn{2}{l}{\tt -k <all|[un]finished|[un]successful|FROM-TO> [--signal SIG]}\\
\multicolumn{2}{l}{\tt -i <history|now|evolution>}\\
\hline
Argument & Description\\
\hline
{\tt PARAMETER\_FILE} & file with parameter description\\
{\tt WORKER\_FILE} & executable file to be run remotely\\
{\tt TEMPLATE\_FILE} & append extra variables from template file\\
{\tt all} &               all the templates are subcommanded\\
{\tt [un]submitted} &     only those which were [not] submitted\\
{\tt [un]finished} &      only those whose jobs have [not] finished\\
{\tt [un]successful} &    only those whose jobs finished [un]succesfully\\
{\tt FROM-TO} &           deletes the range [FROM,TO]\\
{\tt SIG} &               kill with signal passed to gwkill\\
{\tt history} &           full historic information about each job\\
{\tt now} &               last status update for each job\\
{\tt evolution} &         timely snapshots of job statuses\\
\hline
\end{tabular}
\caption{Different subcommands, syntax, arguments and options for the command line interface. Square brackets indicate optional features whilst angle brackets are compulsory elements.}
\label{usagetable}
\end{table}

Firstly, the user would edit a parameter file containing the instruction to generate the arguments wishing to pass as arguments to the executable. These job templates include five definitions:
\begin{itemize}
\item {\tt EXECUTABLE =} executable filename (i.e. {\tt WORKER\_FILE}),
\item {\tt ARGUMENTS =} argument list, separated by whitespaces,
\item {\tt STDOUT\_FILE =} standard output destination file,
\item {\tt STDERR\_FILE =} standard error destination file,
\item {\tt NAME =} label for naming the job.
\end{itemize}

These definitions correspond to the GridWay Job Template Language and can be extended by adding the {\tt TEMPLATE\_FILE} with extra ones or modified through the config option.

After a successful run of the program, a zero exit status is delivered. Otherwise, it indicates an error, probably associated with either internal code errors or wrong syntax. Because there is no systematic way to represent program exit codes, an indication of the encountered problem is given in \tab{error}.
\begin{table}
\center
\begin{tabular}{cp{50ex}}
\hline
{Exit status} & {Description}\\
\hline
0 & success\\
1 & wrong syntax in the command line\\
2 & system execution error\\
3 & file not found or requirement not matched\\
4 & parameter file syntax inconsistent\\
5 & error opening file\\
6 & error closing file\\
7 & no job found coming from template in the list\\
8 & internal computation error\\
9 & internal parsing error\\
\hline
\end{tabular}
\caption{Success and error code description from exit status.}
\label{error}
\end{table}

\section{Examples}\label{examples}
A simple collection of examples will illustrate the usage of the tool and some tips enhancing the possibilities of writing job templates.

\subsection{Hello world!}
Sticking to tradition, the first example must create a job template whose job is submitted and prints {``Hello world!''}. Doing this involves at least two executions of the Grid[Way] Job Template Manager. Step by step:
\begin{enumerate}
\item A file (say {\tt parameter.in}) describes which is the string argument to be printed. One valid line suffices in this case:
\begin{term}
} symbol resembling the shell prompt.} with the creation of job templates ({\tt --create}) and an executable of the system ({\tt --worker}):
\begin{term}
 ls
0_echo_Hello_world!.jt parameter.in
\end{term}
with a name indicating the job template index ({\tt 0}), the job executable ({\tt echo}) without trailing path, the sampled argument ({\tt Hello World!}) where the whitespaces have been substituted by underscores, and a suffix extension ({\tt .jt}). It contains five fields with instructions for GridWay:
\begin{term}
 gw_job_template_manager --submit all
Submitted 1 jobs from templates
\end{term}
depending on the scheduling, and resource availability, it will take more or less time for the remote job to finish. When it is done, the standard output file will be there containing the expected greeting.
\begin{term}
P_1=P_2=P_1 ls -1
0_echo_Hello_world!.jt
1_echo_Hello_mars!.jt
2_echo_Goodbye_world!.jt
3_echo_Goodbye_mars!.jt
parameter.in
\end{term} 
with equivalent content as shown in the simple ``Hello world!'' example.
\item After the submission of all the templates, it is very useful to monitor the status of the jobs. This action can be performed with the {\tt --info} subcommand
\begin{term}
 gw_job_template_manager --purge successful
Purged 4 jobs from templates
\end{term}
and also to get rid of all the job templates
\begin{term}
 cat *.out
Hello world!
Hello mars!
Goodbye world!
Goodbye mars!
\end{term}
\end{enumerate}
\subsection{Squaring and skipping}
The next example tries to compute the square of the set \{1,2,4,5\}. 
\begin{enumerate}
\item Instead of typing them by hand, a squaring executable  which receives a single argument has been prepared (named {\tt square}). The parameter file {\tt para\-meter.in} has one line:
\begin{term}
LOOPTYPE=RANGE, START=1, END=5, STEP=1, SKIP=3
\end{term}
saying it should fill the integer interval [1,5], and from them skip the value 3
\begin{term}
 ls -1
0_square_1.jt
1_square_2.jt
2_square_4.jt
3_square_5.jt
parameter.in
square
\end{term}
Note that this time, the shortcuts {\tt -c} and {\tt -w} have been use instead of {\tt --create} and {\tt --worker}.
\item Job templates do not need to be submitted all at a time. For instance, the user could perform a first operation for jobs 0 to 1 and, later on, a second operation with the rest.
\begin{term}
 gw_job_template_manager --submit unsubmitted
Submitted 2 jobs from templates
\end{term}
\item Another way to get to know what happened to each job is to use the history tag with the information command:
\begin{term}
 cat  *.out
1^2=1
2^2=4
4^2=16
5^2=25
\end{term}
\end{enumerate}
\subsection{Random Monte-Carlo}
Often, programs involving large statistical runs require a proper initiation of the random number generator. This can be done by means of a seed and is a key point for ensuring uncorrelated jobs. Here a simple way of getting different seeds in the integer interval [0,1000) is implemented for eight independent jobs.
\begin{enumerate}
\item The {\tt parameter.in} looks like:
\begin{term}
\{1000, \ldots ,1000\} gw_job_template_manager -w worker -c parameter.in
Composed 8 job templates
\end{term}
is
\begin{term}
 cat parameter.in
LOOPTYPE=LIST, VALUE=Taylor, VALUE=Exact
LOOPTYPE=EXPRANGE, START=1, END=1E3, STEP=1, SKIP=100
LOOPTYPE=LIST, VALUE={JT\_ID}} for each job.
\item The creation of templates is this time slightly different due to the retrieval of extra output files. For this to be taken into account, an extra job template input file is needed {\tt template.in}:
\begin{term}
{3}
 ls -1
0_worker_Taylor_1_0.txt.jt
1_worker_Taylor_10_1.txt.jt
2_worker_Taylor_1000_2.txt.jt
3_worker_Exact_1_3.txt.jt
4_worker_Exact_10_4.txt.jt
5_worker_Exact_1000_5.txt.jt
parameter.in
worker
template.in
 gw_job_template_manager -s all; time gw_job_template_manager -p all
Submitted 6 jobs from templates
Purged 6 jobs from templates

real    1m51.861s
user    0m0.660s
sys	    0m0.060s
\end{term}
\item In this case, the relevant results are the text files
\begin{term}
 cat parameter.in
LOOPTYPE=RANGE,\
START=123456789012345678911234567892123456789312345678941,\
  END=123456789012345678911234567892123456789312345678943,\
POINTS=3
\end{term}
\item The standard tentative will {\bf not} work\footnote{Depending on the perl version, for perl 5.10 it does not work, but earlier versions (5.8) did not yet transform automatically into scientific notation.}
\begin{term}
 ls -1
0_echo_1.23456789012346e+50.jt
1_echo_1.23456789012346e+50.jt
2_echo_1.23456789012346e+50.jt
parameter.in
\end{term}
because the transformation into scientific notation dropped out the precision we expect to work with. 
\item Instead, the user should instruct the tool to profit from the {\tt bignum} perl package
\begin{term}
 gw_job_template_manager --config use_bignum=1\
  -w /bin/echo -c parameter.in
Composed 3 job templates
 cat parameter.in
LOOPTYPE=LIST, VALUE=ps, VALUE=pwd, VALUE=ls, VALUE=whoami
{JT_ID}_env_{JT_ID}_env_ gw_job_template_manager \
-w /usr/bin/env -c parameter.in -t template.in \
--config Template_executable=Executable \
--config Template_arguments=Arguments \
--config Template_stdout_file=StdOutput \
--config Template_stderr_file=StdError \
--config Template_job_name=JobName \
--config Template_encloser_char=\" \
--config Template_end_of_line=\; \
--config job_template_suffix=.jdl
WARNING: GridWay location not set up.
This means that the usability of this tool is limited to create and delete 
job templates. Please identify your  gw_job_template_manager -s all \
--config gridway_submit=glite-wms-job-submit \
--config gridway_submit_flag=-a \
--config job_template_suffix=.jdl
WARNING: GridWay location not set up.
This means that the usability of this tool is limited to create and delete 
job templates. Please identify your  glite-wms-job-output https://gilda-rb.rediris.es:9000/IP4LKZgkpxcL9NE58AHuPQ
Connecting to the service https://gilda-rb.rediris.es:7443/glite_wms_wmproxy_server


================================================================================

			JOB GET OUTPUT OUTCOME

Output sandbox files for the job:
https://gilda-rb.rediris.es:9000/53HM4HRBCsqwHwpa01zEVw
have been successfully retrieved and stored in the directory:
/tmp/jobOutput/user_53HM4HRBCsqwHwpa01zEVw

================================================================================
 ls -1
3_env_whoami.err
3_env_whoami.out
$ cat 3_env_whoami.out
gilda075
\end{term}
\end{enumerate}

\section{Conclusion}\label{conclusion}
A tool for managing a parameter sweep study on a distributed architecture has been presented, with special emphasis on the mechanism to create job templates from a given parameter file. The syntax of the parameter file is simple though quite powerful, specially because broad scoped features (arbitrary dimensions, exponentiation, value skipping, wildcarding and functions) have been implemented.

The usage has been designed to perform an action and the anti-action, so to the creation of job templates a deletion exists. Moreover, submission of jobs is also complemented by the purge. In any case, all the operations are grouped under useful subcommands which can be accessed through the command line interface.

In order to allow enough flexibility, the user has at disposal configuration options to modify program parameters. Some examples have been worked out for illustrating how a little amount of input give rise to a plethora of possibilities, from the ``Hello world!'' trivial case up to a  parameter study controlled with the GridWay Metascheduler.

Within the aspects which could be desirable but not yet implemented, it can be mentioned the capability to handle job templates in the XML-formatted Job Standard Description Language. The problem to accept this format is the inherent hierarchy of the XML syntax, which is incompatible with appending a template file with extra information. Nevertheless, an smart merge might be implemented under certain scheme. Another kind of limitation is the use of wildcards and functions altogether, or the need of other wildcards. The inclusion of these features could be studied if they turn to handicap parameter sweep studies from the scientific community.

The tool can be viewed an extension of GridWay, which performs the resource discovering, scheduling or workloading for the jobs. Being modular, it is much easier to focus on the aspects regarding parameter sweeps and the programming protocol to interact with the middleware. It has been shown also the possibilities to interact with other submission agents, such as the gLite WMS.

Altogether, this tool provides the user a powerful mechanism to port applications to clusters, grid or cloud. Our experience on this subject indicates that the steep learning curve and lack of success are the main drawbacks for adopting the solutions of distributed computing. Offering an opportunity to save time on the generation of the parameters to be swept and to ensure consistent operations on specific blocks of jobs is clearly an step forward to enhance the overall performance of the application at the user's convenience.


\section*{Acknowledgements}
We would like to thank the gilda VO \cite{gilda} for providing a working infrastructure for tests within the EGEE project \cite{EGEE}. Also, we would like to express our gratitude to Antonio Fuentes and Virginia Martín-Rubio from RedIRIS for the kind organization of several tutorials for grid application developers, giving us the opportunity to interact with interested groups of students and researchers. They all gave us unvaluable feedback to improve the tool. 

This work was supported by the Consejería de Educación de la Comunidad de Madrid, Fondo Europeo de Desarrollo Regional (FEDER) and Fondo Social Europeo (FSE), through the MEDIANET Research Program S2009/TIC-1468, by the spanish Ministerio de Ciencia e Innovacion, through the research grant TIN2009-07146, and by the European Union through the EGEE-III grant agreement INFSO-RI-222667.
 
\section*{References}
\begin{thebibliography}{10}

\bibitem{gridway}
E.~Huedo, R.~S.~Montero, I.~M.~Llorente.\\
{\em The GridWay Framework for Adaptive Scheduling and Execution on Grids}.\\
Scalable Computing, Practice and Experience 6 (3) 2005, pp 1-8.

\bibitem{Abramson:2000}
D.~Abramson, J.~Giddy, L.~Kotler.\\
{\em High Performance Parametric Modeling with Nimrod/G: Killer Application for the Global Grid?}.\\
 International Parallel and Distributed Processing Symposium (IPDPS), Cancun, Mexico. May 2000. pp. 520-528

\bibitem{Casanova:2003}
H.~Casanova, F.~Berman.\\
{\em Parameter Sweeps on the Grid with APST}.\\
Grid Computing: Making the Global Infrastructure a Reality, 2003, pp. 773-787.


\bibitem{Casanova:2000}
F.~Berman, R.~Wolski, H.~Casanova et al.\\
{\em Adaptive Computing on the Grid Using AppLeS.}\\
IEEE Transactions on Parallel and Distributed Systems, pp. 369-382, April, 2003.

\bibitem{Huedo:2004}
E.~Huedo, R.~S.~Montero, I.~M.~Llorente.\\
{\em Experiences on Adaptive Grid Scheduling of Parameter Sweep Applications}.\\
Proceedings of the 12th Euromicro Conference on Parallel, Distributed and Network-Based Processing (Euromicro-PDP'04), 2004. pp. 28-33.

\bibitem{JDL}
GLite Job Description Language.\\
{\em Workload Management System User and Reference Guide.}\\
\url{https://edms.cern.ch/document/572489/1},\\ 
{\em Attributes Specification}.\\
\url{https://edms.cern.ch/document/555796/1JDL}

\bibitem{JSDL}
M.~Drescher, A.~Anjomshoaa, G.~Williams, D.~Meredith.\\
{\em JSDL Parameter Sweep Job Extension.}\\
\url{http://www.ogf.org/documents/GFD.149.pdf}

\bibitem{gridwayinstall}
{\em GridWay Installation Guide}.\\
\href{http://gridway.org/doku.php?id=documentation:release_5.6:ig}{\tt http://gridway.org/doku.php?id=documentation:release\_5.6:ig}


\bibitem{gilda}
Grid INFN Laboratory for Dissemination Activities.\\
\url{https://gilda.ct.infn.it/vo.html}

\bibitem{EGEE}
EGEE: Enabling Grids for E-sciencE.\\
\url{http://www.eu-egee.org}
\end{thebibliography}

\end{document}
