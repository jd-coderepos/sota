\documentclass[12pt]{article}
\usepackage{amsmath,epsfig}
\usepackage{amssymb}
\usepackage{color}
\usepackage[english]{babel}
\usepackage{graphicx}
\usepackage{times}
\usepackage{verbatim}
\usepackage{multirow}
\usepackage{algorithm}
\usepackage{algorithmic}
\usepackage{lscape}
\usepackage{psfrag}

\clearpage{}\makeatletter
\newcommand{\subjclass}[2][1991]{\let\@oldtitle\@title \gdef\@title{\@oldtitle\footnotetext{#1 \emph{Mathematics subject classification.} #2}}}
\newcommand{\keywords}[1]{\let\@@oldtitle\@title \gdef\@title{\@@oldtitle\footnotetext{\emph{Key words and phrases.} #1.}}}
\makeatother



\newtheorem{thm}{Theorem}[section]
\newtheorem{lem}[thm]{Lemma}
\newtheorem{defn}[thm]{Definition}
\newtheorem{cor}[thm]{Corollary}
\newtheorem{prop}[thm]{Proposition}
\newtheorem{rem}[thm]{Remark}
\newtheorem{ex}[thm]{Example}
\newtheorem{alg}[thm]{Algorithm}
\newtheorem{conj}[thm]{Conjecture}

\newenvironment{proof}{\noindent\textsc{Proof: }}{\hfill\par\medskip\par}

\newenvironment{aenum}{\begin{enumerate}
 \renewcommand{\theenumi}{\alph{enumi}}
 \renewcommand{\labelenumi}{(\theenumi)}}{\end{enumerate}}



\newcommand{\C}{{\mathbb C}}
\newcommand{\F}{{\mathbb F}}
\newcommand{\Q}{{\mathbb Q}}
\newcommand{\R}{{\mathbb R}}
\newcommand{\Z}{{\mathbb Z}}
\newcommand{\N}{{\mathbb N}}



\newcommand{\cA}{{\cal A}}
\newcommand{\cB}{{\cal B}}
\newcommand{\cC}{{\cal C}}
\newcommand{\cD}{{\cal D}}
\newcommand{\cE}{{\cal E}}
\newcommand{\cF}{{\cal F}}
\newcommand{\cG}{{\cal G}}
\newcommand{\cH}{{\cal H}}
\newcommand{\cI}{{\cal I}}
\newcommand{\cJ}{{\cal J}}
\newcommand{\cK}{{\cal K}}
\newcommand{\cL}{{\cal L}}
\newcommand{\cM}{{\cal M}}
\newcommand{\cN}{{\cal N}}
\newcommand{\cO}{{\cal O}}
\newcommand{\cP}{{\cal P}}
\newcommand{\cR}{{\cal R}}
\newcommand{\cS}{{\cal S}}
\newcommand{\cT}{{\cal T}}
\newcommand{\cU}{{\cal U}}
\newcommand{\cV}{{\cal V}}
\newcommand{\cW}{{\cal W}}
\newcommand{\cX}{{\cal X}}
\newcommand{\cY}{{\cal Y}}
\newcommand{\cZ}{{\cal Z}}

\newcommand{\ba}{{\bf a}} \newcommand{\bb}{{\bf b}}
\newcommand{\bc}{{\bf c}}
\newcommand{\bd}{{\bf d}}
\newcommand{\be}{{\bf e}}
\newcommand{\bi}{{\bf i}}
\newcommand{\bk}{{\bf k}}
\newcommand{\bl}{{\bf l}}
\newcommand{\br}{{\bf r}}
\newcommand{\bs}{{\bf s}}
\newcommand{\bu}{{\bf u}}
\newcommand{\bv}{{\bf v}}
\newcommand{\bw}{{\bf w}}
\newcommand{\bx}{{\bf x}}
\newcommand{\by}{{\bf y}}
\newcommand{\bz}{{\bf z}}

\newcommand{\cl}{\mbox{\rm cl\,}}
\newcommand{\diam}{\mbox{\rm diam\,}}
\newcommand{\dist}{\mbox{\rm dist\,}}
\newcommand{\id}{\mbox{\rm id\,}}
\newcommand{\image}{\mbox{\rm im\,}} \newcommand{\Inv}{\mbox{\rm Inv\,}}     \newcommand{\oh}{\mbox{\rm oh\,}}
\newcommand{\rank}{\mbox{\rm rank\,}}
\newcommand{\sgn}{\mbox{\rm sgn\,}}
\newcommand{\emb}{\mbox{\rm emb\,}}
\newcommand{\floor}{\mbox{\rm floor\,}}
\newcommand{\ceiling}{\mbox{\rm ceil\,}}  \newcommand{\card}{\mbox{\rm card\,}}
\newcommand{\dom}{\rm dom}
\def\scal#1{\langle #1 \rangle}
\newcommand{\Int}{\mbox{\rm Int\,}} 

\def\mapright#1{\stackrel{#1}{\longrightarrow}}
\def\mapleft#1{\stackrel{#1}{\longleftarrow}}
\def\mapdown#1{\Big\downarrow\rlap{\scriptstyle#1}}
\def\mapup#1{\Big\uparrow\rlap{\scriptstyle#1}}
\def\mapne#1{\nearrow\rlap{\scriptstyle#1}}
\def\mapse#1{\searrow\rlap{\scriptstyle#1}}
\def\mapsw#1{\swarrow\rlap{\scriptstyle#1}}
\def\mapnw#1{\nwarrow\rlap{\scriptstyle#1}}




\newcommand{\Ws}{W^{s}}
\newcommand{\Wu}{W^{u}}

\newcommand{\dis}{\displaystyle}
\newcommand{\rX}{\textcolor{red}{X}}
\newcommand{\dd}{ \partial _P f(Q)}
\newcommand{\f}{  }
\newcommand{\mvmap}{\to \cP}   

\newcommand{\wup}{\overline{wrap}\,}         \newcommand{\wlo}{\underline{wrap}\,}        

\newcommand{\wrap}{wrap\,} \newcommand{\swrap}{\mbox{\rm wrap}\,}         \newcommand{\swup}{\overline{{\mbox{\rm wrap}}}\,}
\newcommand{\swlo}{\underline{{\mbox{\rm wrap}}}\,}

\newcommand{\bdy}{{\partial}} \newcommand{\cbdy}{bd\,} \newcommand{\sbdy}{\mbox{\rm bd\,}} \newcommand{\cb}{\mbox{\rm \bf cb\,}} \newcommand{\sd}{\mbox{\rm sd\,}} 

\newcommand{\mcgs}{Morse connections graph }

\newcommand{\MCG}{Morse Connections Graph}
\newcommand{\MCGf}{MCG_{\fm}}
\newcommand{\fm}{f}
\newcommand{\Par}[1]{\left( #1 \right)}      \newcommand{\Brc}[1]{\left\{ #1 \right\}}    \newcommand{\Brq}[1]{\left[ #1 \right]}      \newcommand{\Abs}[1]{\left| #1 \right|}      \newcommand{\st}{ \ \mid \ }
\newcommand{\conup}[2]{#1 \nearrow #2}
\newcommand{\condown}[2]{#1 \searrow #2}
\newcommand{\mcg}{Morse connections graph}

\newcommand{\St}{\mathrm{St}\,} \newcommand{\cSt}{\mathrm{\overline{St}}\,} \newcommand{\uSt}{\mathrm{St^+}\,} \newcommand{\lSt}{\mathrm{St^{-}}\,} \newcommand{\Lk}{\mathrm{Lk}\,} \newcommand{\uLk}{\mathrm{Lk^+}\,} \newcommand{\lLk}{\mathrm{Lk^{-}}\,} 

\def\op#1{\stackrel{\circ}{#1}}



\newcommand{\aphi}{{\varphi^\urcorner}} \newcommand{\apsi}{{\psi^\urcorner}} 

\newcommand{\lphi}{{\overline{\varphi}}} \newcommand{\lpsi}{{\overline{\psi}}} 

\newcommand{\mphi}{{\tilde{\varphi}}} \newcommand{\mpsi}{{\tilde{\psi}}} 

\newcommand{\dm}{\mathrm{D}\,} \newcommand{\dmm}{\mathrm{D_m}\,} 



\newcommand{\ma}{\texttt{m}\,} \newcommand{\re}{\texttt{r}\,} 


\newcommand{\sS}{\texttt{S}} \newcommand{\sA}{\texttt{A}}
\newcommand{\sB}{\texttt{B}}
\newcommand{\sC}{\texttt{C}} \newcommand{\sD}{\texttt{D}} \newcommand{\sM}{\texttt{M}} \newcommand{\sL}{\texttt{L}}
\newcommand{\mI}{\texttt{I}\,}



\clearpage{}

\setlength{\topmargin}{-.15in}
\setlength{\textheight}{9.in}


\title{A New Matching Algorithm for Multidimensional Persistence}
\author{Madjid Allili, Tomasz Kaczynski\thanks{This work was partially supported by NSERC Canada Discovery Grant  and IMA Minnesota}, Claudia Landi\thanks{Work  performed under the auspices of INdAM-GNSAGA}, Filippo Masoni}

\subjclass[2010]{Primary 65D18; Secondary 52C45, 57Q10}

\keywords{Multidimensional persistent homology, discrete Morse theory, acyclic partial matchings, matching algorithm}

\begin{document}


\maketitle

\begin{abstract}
An algorithm is presented that constructs an acyclic partial matching on the cells of a given simplicial complex from a vector-valued function defined on the vertices and extended to each simplex by taking the least common upper bound of the values on its vertices. The resulting acyclic partial matching may be used to construct a reduced filtered complex with the same multidimensional persistent homology as the original simplicial complex filtered by the sublevel sets of the function. Numerical tests show that in practical cases the rate of reduction in the number of cells achieved by the algorithm is substantial.  This promises to be useful for the computation of multidimensional persistent homology of  simplicial complexes filtered by  sublevel sets of vector-valued functions.
\end{abstract}

\section{Introduction}\label{sec:intro}

In the past decade, Forman's discrete Morse theory \cite{For98,Forman02} appeared to be useful for computing homology of complexes \cite{Har2014} and for providing filtration--preserving reductions of complexes in the study of persistent homology. Until recently, algorithms computing discrete Morse matchings have primarily been used for one--dimensional filtrations, see e.\ g.\ \cite{KinKnuMra05,RobWooShe11,MiNa}. However, there is currently a strong interest in combining persistence information coming from multiple functions in multiscale problems,  e.g. in biological applications  \cite{xia-wei}, which motivates extensions to generalized types of persistence. A more general setting of persistence modules on quiver complexes has been recently presented in \cite{Esc2014}. A parallel attempt in the direction of extending such algorithms to multidimensional filtrations  is our paper \cite{AlKaLa17}. In that paper, an initial framework related to Morse matchings for the multidimensional setting is proposed and an algorithm given by King et al.\ in \cite{KinKnuMra05} is extended. The algorithm produces a partition of the initial complex into three sets  and a bijection  called matching. Any simplex which is not matched is added to  and declared as critical. The matching algorithm of \cite{AlKaLa17} is used for establishing a reduction of a simplicial complex to a smaller but not necessarily optimal cellular complex. First experiments with filtrations of triangular meshes show that there is a considerable amount of cells identified by the algorithm as critical but which seem to be spurious, in the sense that they appear in clusters of adjacent critical faces which do not seem to carry significant topological information.

The main goal of the current work is to improve the matching method for optimality, in the sense of reducing the number of spurious critical cells. The improvement is in two directions. First, the matching algorithm in \cite{AlKaLa17} is an extension of the one in the 2005 King et al.\ paper \cite{KinKnuMra05} which processes the lower links of vertices and is not optimal even in the one-dimensional setting. Our new matching algorithm extends the one given in 2011 by Robins et al.\ \cite{RobWooShe11} for cubical complexes, which processes lower stars rather than lower links, and improves the result of \cite{KinKnuMra05} for optimality. Next, the new matching algorithm presented here emerges from the observation that, in the multidimensional setting, it is not enough to look at lower stars of vertices: one should take into consideration the lower stars of simplices of all dimensions, as there may be vertices of a simplex which are not comparable in the partial order of the multi-filtration. The vector-valued function initially given on vertices of a complex is first extended to simplices of all dimensions by taking the least common upper bound of the values on their vertices. Then the algorithm processes the lower stars of all simplices, not only the vertices. The resulting acyclic partial matching may be used to construct a reduced filtered Lefschetz complex with the same multidimensional persistent homology as the original simplicial complex filtered by the sublevel sets of the function. This promises to be useful for the computation of multidimensional persistent homology of  simplicial complexes filtered by  sublevel sets of vector-valued functions.

The paper is organized as follows. In Section~\ref{sec:prel}, the preliminaries are introduced. We recall the definition of simplicial complex, which is the input for our matching algorithm, of partial and acyclic matching, and of multidimensional filtration. A preliminary topological sorting Algorithm~\ref{alg:sorting} is presented.

In Section~\ref{sec:alg}, the main Algorithm~\ref{alg-match} is presented. Its correctness is proved and the complexity analyzed.

Section~\ref{per-hom} starts from recalling the notion of Lefschetz complex \cite{Lef42}, also studied under the name of --complex in \cite{MrBa09}. These complexes are produced by applying the reduction method \cite{KaMrSl98,MrBa09,MiNa} to an initial simplicial complex, with the use of the matchings produced by our main Algorithm~\ref{alg-match}. Multidimensional persistent homology and the reduction method are recalled. The main feature of the reduction method is preserving persistent homology. It is presented in Corollary~\ref{cor:homology-S-iso-C}.

In Section~\ref{sec:experiments} experiments on synthetic and real 3D data are presented. These experiments show that in practical cases the rate of reduction in the number of cells achieved by the algorithm is substantial. Statistics are presented in Tables \ref{tab:sphere}, \ref{tab:torus}, \ref{tab:klein}, and \ref{tab:space}.

The improvement is observed in practice but the optimality of Morse reduction is not yet well defined in the multidimesional setting. Recall that, in the classical smooth case, the singularities of vector-valued functions on manifolds are in general not isolated; they form submanifolds of lower dimension. An appropriate extension of the Morse theory to multidimensional functions is not much investigated yet. Some related work is that of Edelsbrunner and Harer \cite{EdHa02} on Jacobi sets and of Patel \cite{Pat10} on preimages of maps between manifolds. However there are essential differences between those concepts and our sublevel sets with respect to the partial order relation.

\section{Working Assumptions}\label{sec:prel}


\subsection{Simplicial framework}\label{sec:simpl}

In this paper, we shall primarily work in the framework of finite geometric simplicial complexes  in the Euclidean space . More precisely, the main result of this paper, the Matching Algorithm~\ref{alg-match} takes as input any finite geometric simplicial complex  in the Euclidean space . On the other hand, its applications to computing multidimensional persistent homology of  are expressed in the language of Lefschetz complexes which are an algebraic abstraction of cellular complexes. The structure of Lefschetz complexes and the notion of persistent homology will be reviewed in Section~\ref{per-hom}.

Let us recall that a {\em  geometric -simplex}  is the convex hull of  affinely independent vertices ,, ,  in . The number  is its dimension. In programming,  can be identified with the list of its vertices, which is called an {\em abstract simplex}. A {\em face} of  is a simplex  whose vertices constitute a subset of . If , it is called a {\em primary face} or, for short, a {\em facet} of . In this case,  is called a {\em primary coface} or a {\em cofacet} of , and we write .

The set  is a collection of all simplices in  dimension . In particular,  is the set of vertices in . Given , we write  for the set of vertices of . The collection  is called a {\em simplicial complex} if every face of a simplex in  is also in  and the intersection of any two simplices in , if non-empty, is their common face. We denote either by  or by  the {\em carrier} of   which is the union of all its simplices. Thus  is a polyhedron in  and  its triangulation.

\subsection{Partial matching}\label{sec:match}

A {\em partial matching}  on  is a partition of  into three
sets  together with a bijective  map   such that, for each ,  is a cofacet of .

An {\em --path} is a sequence

such that, for each , , , and  is a
cofacet of  .

A partial matching  on  is called {\em acyclic} if there does not exist a closed --path, that is a path as in (\ref{eq:m-path}) such that, .

A convenient way to phrase the definition of an acyclic partial matching is via the {\em Hasse diagram} of . It is the directed graph whose vertices are elements of , edges are given by cofacet relations, and oriented from the larger element to the smaller one. Given a partial matching  on  , we change the orientation of the edge  whenever . Thus the --path in (\ref{eq:m-path}) can be displayed as

where  stands for the matching, and the symbol  for the cofacet relation. The acyclicity means that the oriented graph obtained this way, which is also called the {\em modified Hasse diagram} of , has no nontrivial cycles. A directed graph with no directed cycles is called a directed acyclic graph (DAG). Thus, a partial matching  on  is acyclic if its corresponding modified Hasse diagram is a DAG.

\medskip

It is important to emphasize that the sets of simplices   of  in general are not simplicial complexes. Nevertheless, the set  of critical simplices can be given a combinatorial structure of a Lefschetz complex discussed in Section~\ref{per-hom} and a  topology of a CW complex \cite{Mun84}.

\subsection{Multidimensional filtration}\label{sec:md-f}

The main goal of this paper is to produce a partial matching which preserves the filtration of  by sublevel sets of a vector-valued function  given on the set of vertices of . We define these notions below.

\medskip

Let now  be a  simplicial complex of cardinality , and let  denote the cardinality of .

We assume that  is a function  on the set of vertices of  which is {\em component-wise injective},
that is, whose components  are injective. Note that  this is a stronger condition than assuming that  is injective.


Given any function , we can obtain a component-wise injective function  which is arbitrarily
close to  via the following procedure.
For , let us set .
For each  with , we can assume that the  vertices in  are indexed by a integer index , with , increasing with . Thus, the
function   can be  defined by setting , with 
(the larger , the closer  to ). Finally, it is sufficient to set .

We extend  to a function  as follows:



Any function   that is an extension of a component-wise injective function  defined on
the vertices of the complex  in such a way that  satisfies equation~(\ref{max}) will be called \emph{admissible}.

\medskip

In  we consider the following partial order. Given two values  we set  if and only if
 for every  with . Moreover we write  whenever  and .


The {\em sublevel set filtration} of  induced by an admissible function  is the family  of subsets of  defined as follows:

It is clear that, for any parameter value  and any simplex , all faces of  are also in . Thus  is a simplical subcomplex of  for each . The changes of topology of  as we change the multiparameter  permit recognizing some features of the shape of   if  is appropriately chosen. For this reason, the function  is called in the literature a {\em measuring function} or, more specifically, a {\em multidimensional measuring function} \cite{BiCe*08}.

\medskip

The {\em lower star} of a simplex is the set

and the {\em reduced lower stars} is the set
.

\subsection{Indexing map}

An {\em indexing map} on the simplices of the complex , compatible with an admissible function , is a bijective map  such that, for each
 with , if  or  then .

To build an indexing map  on the simplices of the complex , we will revisit the algorithm introduced in~\cite{AlKaLa17} that uses the topological sorting of a DAG
to build an indexing for vertices of a complex that is compatible with the ordering of values of a given function defined on the vertices.
We will extend the algorithm to build an indexing for all cells of a complex that is compatible with both the ordering of values of a given admissible
function defined on the cells and the ordering of the dimensions of the cells.

We recall that a topological sorting of a directed graph is a linear ordering of its nodes such that for every directed edge
 from node  to node ,  precedes  in the ordering. This ordering is possible if and only if the graph
has no directed cycles, that is, if it is a  DAG.

A simple well known algorithm (see~\cite{Wikipedia14,Kahn62}) for this task consists
of successively finding nodes of the DAG that have no incoming edges and placing them in a list for the final sorting. Note that
at least one such node must exist in a DAG, otherwise the graph must have at least one directed cycle.
The algorithm consists of two nested loops as presented in Algorithm \ref{alg:sorting}.

\begin{algorithm}
\caption{Topological sorting}
\label{alg:sorting}
\begin{algorithmic}[1]
\STATE {\bf Input:} A DAG whose list of nodes with no incoming edges is  \texttt{I}
\STATE {\bf Output:} The list \texttt{L} containing the sorted nodes
\WHILE {there are nodes remaining in \texttt{I}}
\STATE remove a node  from \texttt{I}
\STATE add  to \texttt{L}
\FOR {each node  with an edge  from  to  }
\STATE remove edge  from the DAG
\IF { has no other incoming edges}
\STATE insert  into \texttt{I}
\ENDIF
\ENDFOR
\ENDWHILE
\end{algorithmic}
\end{algorithm}

When the graph is a DAG, there exists at least one solution for the sorting problem, which is not necessarily unique.
We can easily see that each node and each edge of the DAG is visited once by the algorithm, therefore its running time
is linear in the number of nodes plus the number of edges in the DAG.

\begin{lem}\label{lem:index}
Let  be an admissible function. There exists an injective function  such that, for each  with ,
if  or  then .
\end{lem}

\begin{proof}
The set  is partially ordered by the following relation:  if and only if either
 or  and, in the latter case,  is a face of  or  .
Indeed, it can be straightforwardly checked that this relation is reflexive, antisymmetric and transitive.
Hence  can be represented in a directed graph by its Hasse diagram that is acyclic.

The topological sorting Algorithm \ref{alg:sorting}  allows us to sort and store the simplices
in  in an array  of size , with indexes that can be chosen from 1 to . It follows that the map  that
associates to every node its index in the array  is bijective. Moreover, and due to the topological sorting,  satisfies the constraint
that for  with , if  or , then .
\end{proof}

\section{Matching Algorithm}
\label{sec:alg}

\subsection{The algorithm}

The main contribution of this paper is the Matching Algorithm~\ref{alg-match}.
It uses the following input data:

\begin{enumerate}
\item A finite simplicial complex .

\item An admissible function . Typically, it is obtained from a component-wise injective function    using  the extension formula given in equation~(\ref{max}).

\item An indexing map  compatible with . It can be precomputed using the topological sorting Algorithm \ref{alg:sorting}.
\end{enumerate}

We also use the following definitions:

\begin{enumerate}\setcounter{enumi}{3}
\item Given a simplex , we use \texttt{{unclass}\_{facets}})
to denote the set of facets of a simplex  that are
in  and have not been classified yet, that is, not inserted
in either , , or , and \texttt{{num}\_{unclass}\_{facets}}) to denote the cardinality of
\texttt{{unclass}\_{facets}}).

\item We initialize \texttt{classified}()={\bf false}
for every .

\item We use priority queues \texttt{PQzero} and \texttt{PQone}
which store candidates for pairings with zero and one unclassified
facets respectively in the order given by . We initialize both as empty sets.
\end{enumerate}

The algorithm processes cells in the increasing order of their indexes given by the indexing map  defined on . Each cell  can be set to the states
of \texttt{classified}()={\bf true} or \texttt{classified}()={\bf false} so that if it is processed as part of a lower star of another cell it is not
processed again by the algorithm. The algorithm makes use of extra routines to calculate the cells in the lower star  and the set of unclassified
faces \texttt{{unclass}\_{facets}}) of  in  for each cell  and each cell .
The goal of the processing is to build a partition of  into three lists , , and  where  is the list
of critical cells and in which each cell in  is paired in a one-to-one manner with a cell in  which defines a bijective map .
When a cell  is considered, each cell in its lower star  is processed exactly once as shown in Lemma~\ref{lem:correctness3}. The cell  is inserted into the list of critical cells  if . Otherwise,
 is paired with the cofacet  that has minimal index value . The algorithm makes additional pairings which can be
interpreted topologically as the process of
constructing  with simple homotopy expansions or the process of reducing  with simple homotopy contractions.
When no pairing is possible a  cell is classified as critical and the
process is continued from that cell. A cell  is candidate for a pairing when \texttt{{unclass}\_{facets}}) contains exactly one element  that belongs to \texttt{PQzero} as shown in Lemma~\ref{lem:correctness1}. For this purpose, the priority queues \texttt{PQzero} and \texttt{PQone} which store cells with zero and
one available unclassified faces respectively are created. As long as \texttt{PQone} is not empty, its front is popped and either inserted into \texttt{PQzero} or paired with its single available unclassified face. When \texttt{PQone} becomes empty, the front cell of \texttt{PQzero} is declared as critical and inserted in .

\begin{algorithm}[H]
\caption{Matching}
\label{alg-match}
\begin{algorithmic}[1]
\STATE {\bf Input:} A finite simplicial complex  with an admissible function 
and an indexing map  on its simplices compatible with .
\STATE {\bf Output:} Three lists  of simplices of , and a function .\\
\FOR{ to }
\STATE 
\IF{\texttt{classified}()=\FALSE}
\IF{ contains no  cells}
\STATE add  to , \texttt{classified}()=\TRUE
\ELSE
\STATE  the cofacet in  of minimal index 
\STATE add  to  and  to  and define , \texttt{classified}()=\TRUE, \texttt{classified}()=\TRUE
\STATE add all   with \texttt{{num}\_{unclass}\_{facets}} to \texttt{PQzero}
\STATE add all   with \texttt{{num}\_{unclass}\_{facets}} = 1 and   to \texttt{PQone}
\WHILE{\texttt{PQone}  or \texttt{PQzero} }
\WHILE{\texttt{PQone} }
\STATE  \texttt{PQone}.pop\_front
\IF{\texttt{{num}\_{unclass}\_{facets}}) = 0}
\STATE add  to \texttt{PQzero}
\ELSE
\STATE add  to , add  to  and define ,
\texttt{classified}()=\TRUE, \texttt{classified}()=\TRUE
\STATE remove  from \texttt{PQzero}
\STATE add all   with \texttt{{num}\_{unclass}\_{facets}}) = 1 and
either  or  to \texttt{PQone}
\ENDIF
\ENDWHILE
\IF{\texttt{PQzero} }
\STATE  \texttt{PQzero}.pop\_front
\STATE add  to , \texttt{classified}()=\TRUE
\STATE add all   with \texttt{{num}\_{unclass}\_{facets}}) = 1 and
 to \texttt{PQone}
\ENDIF
\ENDWHILE
\ENDIF
\ENDIF
\ENDFOR
\end{algorithmic}
\end{algorithm}


We illustrate the algorithm by a simple example. We use the simplicial complex  from our first paper \cite[Figure 2]{AlKaLa17} to compare the outputs of the previous matching algorithm and the new one. Figure~\ref{fig:matching2}(a) displays  and the output of \cite[Algorithm 6]{AlKaLa17}.

The coordinates of vertices are the values of the function considered in \cite{AlKaLa17}. Since that function is not component-wise injective, we denote it by  and we start from constructing a component-wise injective approximation  discussed at the beginning of Section~\ref{sec:md-f}. We have , . Let  where  can be conveniently fixed for programming. For increasing order of , the vertices are ordered as . We get the values

For increasing order of , the vertices are ordered as . We get the values

If we interpret the passage from  to  as a displacement of the coordinates of vertices, the new complex  is illustrated by Figure~\ref{fig:matching2}(b). The partial order relation is preserved when passing from  to , and the indexing of vertices in \cite[Figure 2]{AlKaLa17} may be kept for . Hence, it is easy to see that \cite[Algorithm 6]{AlKaLa17} applied to  gives the same result as that displayed in Figure~\ref{fig:matching2}(a).

In order to apply our new Algorithm~\ref{alg-match}, we need to index all  simplices of . For convenience of presentation, we label the vertices , edges , and triangles  by the index values . The result is displayed in Figure~\ref{fig:matching2}(b). The sequence of vertices  is replaced by .  Here are the main steps of the algorithm:

\begin{center}
\begin{tabular}[b]{ll}
: &   , add  to .\\
: & , .\\
: &   classified.\\
: & \parbox[t]{10cm}{, ,\\
 add  to , add  to ,\\
at line , remove  from ,\\
 at line , , , remove  from .}\\
: &  classified.\\
 : &  \parbox[t]{10cm}{ , , \\
		add  to , add  to ,\\
    at line , remove  from , \\
    at line , , , remove  from .}\\
: &  classified.\\
: & \parbox[t]{10cm}{ , , \\
		add  to , ,\\
    at line , add  to .}\\
: &   classified.
\end{tabular}
\end{center}

The output is displayed in Figure~\ref{fig:matching2}(b).

\begin{figure}[h]
\begin{center}
\begin{tabular}{ccc}
\psfrag{v0}{}
\psfrag{v1}{}
\psfrag{v2}{}
\psfrag{v3}{}
\psfrag{v4}{}
 \includegraphics[width=0.40\textwidth]{Figs/Fig2.eps}
& \ \ \ \ \  \ \ \ \ \  &
\psfrag{w1}{}
\psfrag{w2}{}
\psfrag{w4}{}
\psfrag{w12}{}
\psfrag{w8}{}
\psfrag{e3}{}
\psfrag{e5}{}
\psfrag{e6}{}
\psfrag{e9}{}
\psfrag{e10}{}
\psfrag{e13}{}
\psfrag{e14}{}
\psfrag{t7}{}
\psfrag{t11}{}
\includegraphics[width=0.45\textwidth]{Figs/prova.eps}
\\
(a) &\ \ \ \ \  & (b)
\end{tabular}
\caption{In (a), the complex and output of Algorithm 6 of \cite{AlKaLa17} are displayed. Gray-shaded triangles are those which are present in the simplicial complex. Critical simplexes are marked by red circles and the matched simplexes are marked by arrows. In  (b), the complex is modified so to satisfy the coordinate-wise injectivity assumption. Labeling of all simplices by the indexing function and the output of Algorithm~\ref{alg-match} are displayed.
}
\label{fig:matching2}
\end{center}
\end{figure}




\subsection{Correctness}

Recall that  is a function  whose  components  are injective on the vertices of ; moreover,  is  extended to  defined on cells  of any dimension by using formula (\ref{max}).  The assumption that   is component-wise injective on the vertices is not sufficient to obtain disjoint lower stars, but when two lower
stars meet, then they get classified at the same time. This is expressed by the following statements.

\begin{lem}
\label{lem:inj}
The following statements hold:
\begin{enumerate}
\item[(1)] If , then .
\item[(2)] If , then .
\item[(3)] If  then there exists  with .
\item[(4)] Assume that  and  are two  simplices  of  such that .
Then, there exists a simplex  such that  and .
\end{enumerate}
\end{lem}

\begin{proof}
 If , then  by definition of lower star. On the other hand,  since
, by definition of , . Thus .

\noindent
 If , then  and the conclusion follows from the definition of the indexing map.

\noindent
 If , then, for every , . By
the injectivity of , the two maxima must be attained at the same vertex. Therefore  and  have a common face.

\noindent
  If  there exists a simplex
, then  we get  from . By  ,
there exists a simplex  such that . It is now clear that for any
,  and  , thus
. By , .
\end{proof}

\begin{lem}\label{lem:correctness1}
Assume that  is a cell in . If  is a cofacet of  then, at any stage of the algorithm , , and it is equal to 1 if and only if  is still unclassified. In this case, the unclassified face of  is exactly .
\end{lem}

\begin{proof}
Let us assume that . For any unclassified face   of  such that , it holds that
. Indeed, , and  because . Thus, if , the assumption  is contradicted. Hence, if  for every , we have .  Otherwise, if , then , concluding the proof.
\end{proof}

\begin{lem}\label{lem:i=1-2}
Let  such that   with . Then,  is a vertex. Moreover,
\begin{enumerate}
\item if , then Algorithm~\ref{alg-match} classifies  as critical at line 7;
\item if , then either  or  where  is an edge whose vertices are the cells with indexes 1 and 2. Moreover, if , then  is classified as critical at line 7; if , then  is an edge and  is  paired with   at line 9.
\end{enumerate}
\end{lem}

\begin{proof}
If , then  needs to be a vertex. Indeed, if we assume  , then it can be written as  with . It follows that  has at least two faces of lower dimension and lower value by  which should also have lower indexes than that of .
This contradicts the fact that .


Let us now prove separately statements  and .

1. We note that \texttt{classified}()={\bf false} at line 5 because of the initialization. Moreover,  is empty. To see this, let us observe that, for any coface   of ,  it must hold that  for at least one index . Indeed,  is a vertex of  and at any other vertex of    the value of  must be greater than  because  is injective and  has minimal index. Hence  gets classified at line 7 and there is no other cell in  to classify.

2.  If , then all the vertices in  other than  should have   values lower than .
They should therefore have lower indexes too. The only possibility left is to have  where  and .
\end{proof}

\begin{lem}\label{lem:line10}
  Assume that  is unclassified when Algorithm~\ref{alg-match} reaches line 5 for , and that, for all simplexes  with , it holds that \texttt{classified}={\bf true} for all cells . Then the following statements hold true:
\begin{enumerate}
\item[(i)] All simplexes in  are  also unclassified at step 5 when ;
\item[(ii)] If Algorithm~\ref{alg-match} gets to line 9, then there exists at least one cofacet of . Moreover, the one with minimal index, say , has exactly  as unclassified facet, and it is still unclassified. Thus  and  get classified at line 10.
\item[(iii)] If  and  at line 11 of Algorithm~\ref{alg-match}, then  is a facet of .
\end{enumerate}
\end{lem}

\begin{proof}
\begin{enumerate}
\item[{\em (i)}] If  the claim is true by assumption. Let us assume that   has at least one coface .  If  is  classified  it  belongs to the lower star of another cell  different from  with . By Lemma~\ref{lem:inj}(4), also  belongs to  and, therefore,  is already classified by assumption. This gives a contradiction. Hence  is not classified.

\item[{\em (ii)}] If  had no cofaces, then  would be empty. Therefore line 9 would not be reached, contradicting the hypothesis. So  has at least one coface . By Lemma~\ref{lem:inj}(1), . Assuming  and , there exists a sequence of simplices  of dimensions  such that
    
 By definition of ,  for . Recalling that  we see that . Thus  for . In particular,  is a cofacet of  that belongs to . Every cofacet of  in  has only  as unclassified facet in  by Lemma~\ref{lem:correctness1}. Let  be the cofacet of  with minimal index. Statement {\em (i)} implies that  is still unclassified.

\item[{\em (iii)}] Let  and . If  then there are at least two sequences  and  of cells belonging to   with . These cells  and   need to be already classified at line 11 because of the assumption .  By {\em (i)}, they had not been classified when . Since we are at line 11, it has necessarily occurred when  at line 9. But the coface  of  with minimal index is unique so only one between  and   has been classified at line 9, giving a contradiction. Thus, .
\end{enumerate}
\end{proof}

\begin{lem}\label{lem:line19}
 Let  be such that when it is popped from \texttt{PQone}
at line  of Algorithm~\ref{alg-match}, \texttt{{num}\_{unclass}\_{facets}}) = 1. Then the unique cell
 belongs to \texttt{PQzero}. Therefore all cells popped out from \texttt{PQone} at line  of Algorithm~\ref{alg-match} for which \texttt{{num}\_{unclass}\_{facets}}) = 1 get paired at line 19.
\end{lem}

\begin{proof}
We reason by induction on  where . Note that for ,  is a cofacet of  with 0 unclassified faces in  after step 9 is executed. Therefore  cannot enter \texttt{PQone}. For ,  is a primary facet of  with 0 unclassified faces in  after step 9 is executed. Therefore . Assume by induction that for each natural number  from 2 up to value , when  with  is popped from \texttt{PQone} with \texttt{{num}\_{unclass}\_{facets}}) = 1, its unique unclassified face  belongs to \texttt{PQzero} and therefore  and  get paired at line 19. Let now , and  . Let us assume that  is not in \texttt{PQzero}. Then there are two cases. If  has entered \texttt{PQone}, then it has been processed before . Since  is not in \texttt{PQzero}, by the induction hypothesis, it must have been paired with some cell in \texttt{PQzero}. This is a contradiction to the statement \texttt{{num}\_{unclass}\_{facets}}) = 1. If  did not enter \texttt{PQone}, then the number of unclassified faces of  in  is greater than or equal to 1. Thus, since  is of dimension , there must exist a face  of  of dimension  in  that is not paired and not added to . This process can be carried out until we get a -cell  in  that is not classified by the algorithm. In general, we get sequences in  such that
 with  not classified by the algorithm. By Lemma~\ref{lem:correctness1} the number of unclassified faces of  is 0, implying that  has entered \texttt{PQzero}. Let us fix the sequence for which  is of minimal index and has only one unclassified face, hence it has entered \texttt{PQone} before . It exists because  has been classified and  is a simplicial complex.  We deduce that   and   have been paired, contradicting the assumption that  has not  been classified by the algorithm. Hence,  should belong to \texttt{PQzero}, which completes the proof.
\end{proof}

\begin{lem}\label{lem:correctness3}
Let . Each cell in  is processed exactly once by the algorithm
and it is paired with some other cell or classified as critical. Hence Algorithm~\ref{alg-match} classifies all cells of  and always terminates.
\end{lem}

\begin{proof} We break the conclusion into three statements:
\begin{aenum}
\item Each cell in the lower star eventually enters PQone or PQzero.
\item Each cell that has entered PQone or PQzero is eventually classified.
\item A cell that has already been classified cannot enter PQone or PQzero again.
\end{aenum}

We simultaneously prove the three statements by induction on . For  the claim is proved by Lemma~\ref{lem:i=1-2}. Let us now assume by induction that the claim is true from 2 up to . Let . If \texttt{classified()}={\bf true}, then  has already been classified as part of  for some cell  that is a face of . Thus,  and . By induction hypothesis, every cell of  is processed once by the algorithm
and it is paired with some other cell or classified as critical. If \texttt{classified()}={\bf false},  is  either declared critical at line 7 or, by Lemma~\ref{lem:line10}{\em (ii)}, paired with some other cell  in  at line 10. The cells  and  are no further processed.

Let  be a cell left in , if any. Suppose that

Then  is either added to \texttt{PQzero} or to \texttt{PQone} and it is ultimately either paired or classified as critical. More precisely, if  is added to \texttt{PQone}, then it is either moved to \texttt{PQzero} at line 17, or paired at line 19 by Lemma~\ref{lem:line19}. If  is added to \texttt{PQzero}, it is either paired at line 20 or declared critical at line 26. This also shows that, when , every cell in  enters at most once in \texttt{PQzero} and \texttt{PQone}.

It remains to show that (a) also holds for cells  with

We prove (a) by induction on the dimension  of cells in . The initial step is . But then  is a cofacet of  and, by Lemma~\ref{lem:correctness1}, (\ref{eq:dimleq1}) holds. Assume by induction that all cells of  with dimension smaller than  have entered either \texttt{PQzero} or \texttt{PQone}.

Let  be a cell of dimension  in . If (\ref{eq:dimleq1}) holds, we are done. Suppose that (\ref{eq:dimgeq2}) holds. We show that  eventually enters \texttt{PQone}. By induction, all faces of  eventually enter \texttt{PQzero} or \texttt{PQone}. We have earlier shown that those which enter \texttt{PQone} are classified or moved to \texttt{PQzero}. So all faces of  which are not classified enter \texttt{PQzero}. All such faces which have a coface in \texttt{PQone} or get a coface in \texttt{PQone} at line 21 are classified at line 19-20. We remain with the faces of  which are in \texttt{PQzero} but have no coface in \texttt{PQone}. Let  be the number of such faces. Necessarily , otherwise  is in \texttt{PQone}. At lines 25-26 one of those faces is classified as critical, so we remain with  such faces.  After passing other  times through lines 25-26,  remains with only one unclassified face and it is added to \texttt{PQone} at line 27.

So we have proved that every cell in  is processed exactly once by the algorithm while  and it is paired with some other cell of  or classified as critical.

Finally, since the number of cells in the complex  is finite and the union of 's covers the complex, the proof is complete.
\end{proof}

\begin{prop}\label{lem:partition}
  is a partition of the complex  and  is a bijective function from  to .
Moreover, if  then .
\end{prop}

\begin{proof}
By Lemma \ref{lem:correctness3},  . We show that .
This statement is trivial for vertices since they cannot belong to . Assume on the contrary that there exists a cell  with  such that
. Thus, there exist cells  such that
 and . This means that  is paired twice by processing two different lower stars  and .
By Lemma~\ref{lem:inj}(4), there exists a cell  such that the cells  and  are all processed within . Thus  is
processed twice within , which contradicts Lemma~\ref{lem:correctness3}.  If we assume that 
and contains a cell , then  has been declared critical either at line 7 or at line 26. In the first case,   was not previously assigned to 
because of line 5; on the other hand it cannot be assigned to  later because of Lemma~\ref{lem:correctness3}. In the second case,  when  is added to ,
it comes from  and  is empty. The only cells that may enter  or  later are cofaces of  (see line 27).
Therefore  cannot be added again to , and as a consequence it cannot be added to . The proof that    can be handled in
much the same way. It follows that  is a partition of .

By construction, the map  is onto. We will show that  is injective. If two cells  and  are paired with the same cell , it follows that 
must belong to the intersection of two lower stars. Therefore, again by Lemma~\ref{lem:inj}(4), there must exist a  such that  is processed twice by the algorithm within
 which is again a
contradiction to Lemma~\ref{lem:correctness3}. Thus  is bijective.

By construction,  is a face of  and they both belong to some . Thus, by Lemma~\ref{lem:inj}(1),
, and therefore if  then .

\end{proof}


\begin{thm}\label{th:acyclicity}
Algorithm~\ref{alg-match} produces a partial matching  that is acyclic.
\end{thm}

\begin{proof}
A partial matching is acyclic if and only if there are no nontrivial closed --paths as defined in (\ref{eq:m-path}). We prove this by contradiction. Assume that

is a directed loop in the modified Hasse diagram. In particular, all  in the loop have the same dimension, say,  and all  have the same dimension .
The index  of  is not the value of the indexing function  but it simply displays its position in the loop.
From Lemma~\ref{lem:inj}(1), it follows that

If any of the inequalities  is strict, then there exists a coordinate  such that
 and so , a contradiction. Hence  is constant on all the elements of the loop.
Let us set  equal to the cell such that 
The simplex  exists  by Lemma~\ref{lem:inj}(3). This implies that  and  belong to  for . Now we have two cases: either
 for some , , or  for every . In the first case, without a loss of generality, we may assume that .  Since  has the same dimension as , it is  in  if and only if , implying that the loop is trivial, a contradiction.
In the second case, note that Algorithm~\ref{alg-match} produces a pairing  only when \texttt{{num}\_{unclass}\_{facets}} = 1, and in that case the unclassified face of  is exactly . Therefore, we have that  is paired to  after that ,  also a face of , has been paired to .

Iterating this argument for , we deduce that  is paired to  after that  has been paired to . But since  is also a face of , and  is still unclassified when  is paired to , it follows that , implying that the loop is trivial, again a contradiction.

\end{proof}

\subsection{Complexity analysis}
\label{sec:complexity}

{\bf Definitions and parameters.} We use the following definitions and parameters in estimating the computational cost of Algorithm~\ref{alg-match}.
\begin{enumerate}
 \item Given a simplex , the coboundary cells of  are given by

It is immediate from the definitions that .

\item We define the coboundary mass  of  as

where  denotes cardinality. While  is trivially bounded by , the number of cells in ,
this upper bound is a gross estimate of  for many complexes of manifolds and approximating surface boundaries of objects.

\item For the simplicial complex , we assume that the boundary and coboundary cells of each simplex
are computed offline and stored in such a way that access to every cell is done in constant time.

\item Given an admissible function , the values by  of simplices  are stored in the structure
that stores the complex  in such a away that they are accessed in constant time.

\item We assume that adding cells to the lists , , and  is done in constant time.
\end{enumerate}


Algorithm~\ref{alg-match} processes every cell  of the simplicial complex  and checks whether it is classified or not.
In the latter case, the algorithm requires a function that returns the cells in the reduced lower star  which
is read directly from the structure storing the complex. In the best case,  is empty and the cell is declared critical.
Since , it follows that .
As stated earlier in proof of Lemma~\ref{lem:correctness3} every cell in  enters at most once in \texttt{PQzero} and \texttt{PQone}.
It follows that the while loops in the algorithm are executed all together in at most  steps. We may consider the operations such as finding
the number of unclassified faces of a cell to have constant time except for the priority queue operations which are logarithmic in the size of the priority queue
when implemented using heaps. Since the sizes of \texttt{PQzero} and \texttt{PQone} are clearly bounded by , it follows that  is
processed in at most  steps.
Therefore processing the whole complex incurs a worst case cost of .


\section{Persistent Homology Reduction}
\label{per-hom}

\subsection{Lefschetz complexes}

For the purpose of the Matching Algorithm~\ref{alg-match}, we only needed simplical complexes but, for its applications to computing persistent homology, one shall need a more general class of cellular complexes. A convenient combinatorial framework for a cellular complex is that of a Lefschetz complex introduced by Lefschetz in \cite{Lef42} under the name {\em complex}. The properties of Lefchetz complexes are developed further with the purpose of efficient homology computation in \cite{MrBa09} under the name -complex and we refer to this term in our first paper \cite{AlKaLa17}.

A {\em  Lefschetz complex}, equivalently, {\em -complex} is a graded set  of elements which we shall call {\em cells} with a {\em facet relation}  and {\em incidence numbers}  which are zero unless  is a facet of . The incidence numbers are defined so that they give rise to a chain boundary map , thus defining a free chain complex . It is assumed in \cite{MrBa09} that the chain coefficients are in a principal ideal domain  but in our paper we assume that  is a field. A simplicial complex  is a particular case of a Lefschetz complex. For the incidence relations, one needs to impose an orientation on simplices of  unless we compute the homology with  coefficients.

By the homology of a Lefschetz complex  we mean the homology of the chain complex , and we denote it by  or simply by .

\subsection{Multifiltration on Lefschetz complexes}\label{sec:S-m-filt}

The concept of {\em sublevel set filtration} of  induced by  introduced in Section~\ref{sec:md-f} naturally extends to Lefschetz complexes as follows.

Let  be a Lefschetz complex. A {\em multi-filtration} of  is a family  of
subsets of  with the following properties:
\begin{aenum}
\item  is nested with respect to inclusions, that is , for every ,
where  if and only if  for all ;
\item  is non-increasing on faces, that is, if  and  is a face of  then .
\end{aenum}

Persistence is based on analyzing the homological changes occurring along the filtration as  varies. This analysis is carried out by considering, for , the homomorphism

induced by the inclusion map .

The image of the map  is  known as the {\em 'th multidimensional persistent homology group} of the filtration at  and we denote it by . It contains the homology classes of order  born not later than  and still alive at .

\subsection{Reductions}\label{sec:reductions}

The definition of a partial matching given in Section~\ref{sec:match} extends in a straightforward way to any Lefschetz complex ~\cite{AlKaLa17}. The only substantial difference is that the condition ``for each ,  is a cofacet of '' needs to be replaced by the condition ``for each ,  is invertible'', unless field coefficients are assumed.

Let   be a partial matching (not necessarily acyclic) on a Lefschetz complex . Given , a new Lefschetz complex  is constructed in \cite{AlKaLa17} by setting , and ,

We say that  is obtained from  by a {\em reduction} of the pair .

It is well known \cite{KaMrSl98} that  is a well-defined chain complex and that there exists a pair of linear maps  and , explicitly defined by \cite[Formulas (3,4)]{AlKaLa17}, which are chain equivalences. As a consequence,


Let   be an acyclic partial matching  on a Lefschetz complex . Let  be obtained from  by reduction of the pair , . It is proved in \cite{AlKaLa17} that  for any .

The Algorithm~\ref{alg-match} takes a simplicial complex  as the input. Let us set

as the initial complex. If we apply a reduction to , we may get a Lefchetz complex which is no longer a simplicial complex. However, as a set of generators of a chain complex, it is the subset of the original one: it consists of simplices of  and only the incidence numbers get changed. This fact is used to prove in \cite{AlKaLa17} that one-step reductions can be iterated on new subcomplexes. We do not iterate the matching algorithm: it is applied only once to the initial simplicial complex . We iterate reductions of pairs initially matched by the algorithm. Here are the steps towards the main result on persistent homology of  proved in \cite{AlKaLa17}. All the following statements equally apply to the matching produced by the new Algorithm~\ref{alg-match}.

\begin{prop}\label{prop:reduced-matching}
Let   be an acyclic partial matching on . Given a fixed ,
define ,
, , and .
Then  is an acyclic partial matching on .
\end{prop}

Let  be a multifiltration on . Then  is the {\em induced multifiltration} on
 defined by setting, for each ,


In the sequel, we assume that  is an acyclic matching on a filtered Lefschetz complex  with the property:



Lemma~\ref{lem:partition} asserts that the matching produced by Algorithm~\ref{alg-match} on a filtered simplicial complex  has this property.

\begin{lem}\label{lem:chain-equivalence} Let  and let  be obtained from  by reduction of the pair .
Let  and  be chain equivalences defined by the formulas (3) and (4) in \cite{AlKaLa17} respectively.
Then the maps  and
 defined by restriction are chain homotopy equivalences.
Moreover, the diagram

commutes.
\end{lem}

Lemma~\ref{lem:chain-equivalence} immediately yields the following result.

\begin{thm}\label{th:reduced-filtration-iso}
For every , .
\end{thm}

We now let  and consider the matching on  produced by Algorithm~\ref{alg-match}. We order  in a sequence

and set , . Put  and

Since a partial matching defines a partition of , we have .

By definition of induced filtration, the condition (\ref{matching-filtration}) carries through to the reduced complex. Consequently, Proposition~\ref{prop:reduced-matching}, Lemma~\ref{lem:chain-equivalence} and Theorem~\ref{th:reduced-filtration-iso} extend by induction to any step of reduction. Hence, for any ,  we get a sequence of filtered Lefschetz complexes

where , together with a sequence of chain equivalences

Moreover, for any , we get the sequence of inclusions

such that the commutative diagram of Lemma~\ref{lem:chain-equivalence} can be applied to the 'th iterate. By induction, we get the final result.

\medskip

\begin{cor}\label{cor:homology-S-iso-C}
For every , .
Moreover, the diagram

commutes.
\end{cor}

Corollary~\ref{cor:homology-S-iso-C} asserts that the multidimensional persistent homology of the reduced complex is the same as of the initial complex.

An equivalent reduction procedure for linearly filtered complexes is presented in \cite{MiNa}. Its implementation and complexity analysis can be applied in our setting. It is shown there that the worst case computational complexity of the reduction procedure is bounded by the product , where  is the number of cells in ,  is the bound on the number of cofaces of any given cell, and  is the cardinality of the set . In many practical situations, meshing techniques produce regular tirangulations, where  can be assumed constant. If, moreover, the partial matching algorithm produces  significantly smaller than , the complexity as a function of  is close to linear.

Recently, new reduction techniques were designed among others by \cite{DloWag} and \cite[Section C.2]{Rat15}. We believe that our Matching Algorithm~\ref{alg-match} can also be applied together with those techniques to speed up the multidimensional persistent homology computation.


\section{Experimental Results}\label{sec:experiments}

We have successfully applied the algorithms from Section \ref{sec:alg}
to different sets of triangle meshes. In this
section we present two numeric applications - on synthetic and on real data - for which
an acyclic matching preserving multidimensional persistent homology is computed.

In each case the input data is a 2-dimensional simplicial complex   and a function  defined on the vertices of  with values in .

The first step is to slightly perturb  in order to achieve injectivity on each component as described in Section \ref{sec:prel}. The second step is to construct an index function defined on all the simplices of the complex and satisfying the properties of Lemma \ref{lem:index}. Then we build
the acyclic matching  and the partition  in the simplices of the complex using Algorithm \ref{alg-match}. In particular, the number of simplices in  out of the total number of simplices of  is relevant, because it determines the amount of reduction obtained by our algorithm to speed up the computation of multidimensional persistent homology.

\subsection{Examples on Synthetic Data}

We consider three well known 2-dimensional manifolds - the sphere, the torus, and the Klein bottle - triangulated in different ways.

In the case of spheres, we consider triangulations of five different sizes and we take
. The triangulated sphere with the least number of simplices is shown in Figure \ref{fig:sphere}, together with the acyclic matching produced by our algorithm (critical cells are in red) and the corresponding --paths.

\begin{figure}[t]
\begin{center}
\includegraphics[width=0.80\textwidth]{Figs/sfera_injective.eps}
  \caption{Left: A triangulated sphere  in  with the acyclic matching and  critical cells (in red)  associated with a perturbation of the function  given on its vertices by . Right: the corresponding -paths (in yellow).
 }
\end{center}
\label{fig:sphere}
\end{figure}




The comparison with other triangulations of the sphere is shown in Table \ref{tab:sphere}:  the first row  shows  the number of  simplexes in each considered mesh ; the middle row shows the number of critical cells  obtained by using our matching algorithm to reduce ; the bottom row shows the ratio between the second and the first lines, expressing them in percentage points.

\begin{table}[h]
\caption{Reduction performance on five different triangulations of the sphere. }
\begin{center}
\begin{tabular}{| c | c | c | c | c |c|}
\hline
 & \tt{sphere\_1}&
 \tt{sphere\_2} & \tt{sphere\_3}
 &  \tt{sphere\_4} & \tt{sphere\_5} \\
 \hline
   &
  &
  &
  &
 &
 \\
 \hline
 \end{tabular}
 \end{center}
\label{tab:sphere}
\end{table}

In the case of the torus, we again consider triangulations of different sizes and we take
. The numerical results are shown in Table \ref{tab:torus} (see also Figure \ref{fig:torus}).

\begin{table}[h]
\caption{Reduction performance on different triangulations of the torus.}
\begin{center}
\begin{tabular}{| c | c | c | c|}
\hline
 & \tt{torus\_96}&
 \tt{torus\_4608} & \tt{torus\_7200} \\
 \hline
   &
  &
 &

\\
 \hline
 \end{tabular}
 \end{center}
\label{tab:torus}
\end{table}


\begin{figure}[ht]
\begin{center}
\includegraphics[width=0.80\textwidth]{Figs/torus_7200_x-y-injective_view2.eps}
  \caption{A triangulation of the torus with 7200 simplices, with respect to a component-wise injective perturbation of the function defined of its vertices by , has 156 critical simplices: 39 critical vertices  out of 1200  (in yellow), 78 critical edges  out of 3600 (in blue),  and 39 critical faces  out of 2400 (in red).
 }
\end{center}
\label{fig:torus}
\end{figure}


Finally, similar tests in the case of an approximation of a Klein bottle immersed in  give the results displayed in Table \ref{tab:klein} and Figure \ref{fig:klein}.

\begin{table}[h]
\caption{Reduction performance on different triangulations approximating an immersion of the Klein bottle.}
\begin{center}
\begin{tabular}{| c | c | c | c| c |}
\hline
 & \tt{klein\_89}&
 \tt{klein\_187} & \tt{klein\_491} &  \tt{klein\_1881}\\
 \hline
   &
  &
 &
 &

\\
 \hline
 \end{tabular}
 \end{center}
\label{tab:klein}
\end{table}


\begin{figure}
\begin{center}
\includegraphics[width=0.7\textwidth]{Figs/klein_10_x-y-injective_view1_new.eps}
  \caption{A triangulation of an (almost) Klein bottle immersed in  with 1881 simplices, with respect to a component-wise injective perturbation of the function defined of its vertices by , has 234 critical simplices: 73 critical vertices  out of 341  (in yellow), 128 critical edges  out of 940 (in blue),  and 56 critical faces  out of 600 (in red).
 }
\end{center}
\label{fig:klein}
\end{figure}


In conclusion, our experiments on synthetic data confirm that the current simplex-based matching algorithm scales well with the size of the complex.

\subsection{Examples on Real Data}
We consider four triangle meshes (available at \cite{sf}).
For each mesh the input  2-dimensional measuring function 
takes each vertex  of coordinates  to the pair .

In Table \ref{tab:space}, the first row shows on the top line the number of vertices in each considered mesh, and in
the middle line same quantities referred to the cell complex 
obtained by using our matching algorithm to reduce . Finally, it also displays in the bottom line the ratio between
the second and the first lines, expressing them in percentage points.
The second and the third rows show similar information for the edges and the faces. Finally, the fourth row show the same
information for the total number of cells of each considered mesh . The critical simplexes are displayed in Figure \ref{fig:space}.


Our experiment confirm that the current simplex-based matching algorithms produce a fair rate of reduction for simplices of any dimension also on real data. In particular, it shows a clear improvement with respect to the analogous result presented in \cite{AlKaLa17} and obtained using a vertex-based and recursive matching algorithm.


More experiments for a modified but equivalent version our algorithm can be found in ~\cite{Iur16}.

\begin{table}
\caption{Reduction performance on some natural triangle meshes.}
\begin{tabular}{| c | c | c | c | c |}
\hline
Dataset & \tt{tie} & \tt{space\_shuttle} & \tt{x\_wing} & \tt{space\_station}\\
 \hline
&
&
 &
&
 \\
 \hline
  &
 &
  &
  &
  \\
 \hline
  &
  &
 &
  &
  \\
 \hline
   &
  &
  &
  &
 \\
 \hline
 \end{tabular}
\label{tab:space}
\end{table}

\begin{figure}
\begin{center}
\makebox[\textwidth]{\begin{tabular}{cc}
{\includegraphics[width=0.55\textwidth]{Figs/tie_critical.eps}}&
{\includegraphics[width=0.55\textwidth]{Figs/space_shuttle_critical.eps} }\\
\tt{tie} & \tt{space\_shuttle} \\
{\includegraphics[width=0.55\textwidth]{Figs/x_wing_critical.eps}}&
{\includegraphics[width=0.55\textwidth]{Figs/space_station_critical.eps}}\\
\tt{x\_wing} & \tt{space\_station}
\end{tabular}}
  \caption{The critical simplexes of four triangle meshes with respect to a component-wise injective perturbation of : critical vertices  in yellow,  critical edges  in blue,  and  critical faces  in red.
 }
\end{center}
\label{fig:space}
\end{figure}

\bibliographystyle{abbrv}
\bibliography{biblio}

\medskip



\noindent Department of Computer Science\\
Bishop's University\\
Lennoxville (Qu\'ebec),  Canada J1M 1Z7\\
mallili@ubishops.ca
\\~\\
D\'epartement de math\'ematiques\\
Universit\'e de Sherbrooke,\\
Sherbrooke (Qu\'ebec), Canada J1K 2R1\\
t.kaczynski@usherbrooke.ca
\\~\\
\noindent Dipartimento di Scienze e Metodi dell'Ingegneria\\
Universit\`a di Modena e Reggio Emilia\\
Reggio Emilia, Italy
\\
claudia.landi@unimore.it


\end{document}
