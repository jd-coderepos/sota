\documentclass[conference]{IEEEtran}
\IEEEoverridecommandlockouts
\usepackage{cite}
\usepackage{amsmath,amssymb,amsfonts}
\usepackage{algorithmic}
\usepackage{xwatermark}
\usepackage{graphicx}
\usepackage{textcomp}
\usepackage{lipsum}
\usepackage{xcolor}
\def\BibTeX{{\rm B\kern-.05em{\sc i\kern-.025em b}\kern-.08em
    T\kern-.1667em\lower.7ex\hbox{E}\kern-.125emX}}
\begin{document}
\IEEEoverridecommandlockouts
\IEEEpubid{\makebox[\columnwidth]{978-1-6654-8939-3/22/\$ space. The dot product is taken between the attention vector and the extracted embedding. It is passed to the output layer to obtain the final outputs.\\
However, the proposed model architecture is finished here but it can also be combined with other models easily using the average means method that we have described above.

\section{Results}
This section includes the details of experimental setup and the results of our proposed approach. Moreover, it also adds the comparison of the proposed approach with the state of the art approaches.
\begin{figure*}
    \centering
    \includegraphics[width=19cm,height=20cm,keepaspectratio]{Network_Time.drawio.png}
    \caption{Time taken by each part of the network.}
    \label{fig:time}
\end{figure*}
\subsection{Experimental Setup}
In order to perform the experiments, a pipeline is created as following:
\begin{itemize}
    \item An executable (.exe) file is transferred as an input to the framework.
    \item A reverse engineering process is used to convert the .exe file to an assembly (.asm) file.
    \item The opcodes are extracted from .asm file without disturbing their sequence of opcodes.
    \item At the end, the opcodes are given as an input to the proposed classifier which will construct embeddings and later on use them for classification.
\end{itemize}
In this research, we have used tesla T4 GPU with 16GB RAM to train the model. 
\subsection{Comparative results with other classifiers}
For validation of the classifier, our primary metric is log-loss on 5-fold validation data and log-loss on Kaggle’s testing data.\\
For the 5 fold validation, the model was trained on 50 epochs on each fold. For all the folds, the loss was between 0.065 and 0.045 (can be seen in Fig \ref{fig9}) which is very similar to the existing methods while being the efficient one.

\begin{figure*}
\centerline{\includegraphics[width=20cm,height=18cm,keepaspectratio]{logloss.png}}
\caption{Logloss on 5-fold validation.}
\label{fig9}
\end{figure*}
Other than logloss, we also computed some other metrics such as ROC-AUC score, accuracy and f1 score and compared them with existing methods as shown in \ref{tab1}.

\begin{table}[htbp]
\caption{Comparison of SEA with state-of-the-art models}
\begin{center}
\begin{tabular}{|c|c|c|c|}
\hline
\textbf{Models}&\multicolumn{3}{|c|}{\textbf{Metrics}} \\
\cline{2-4} 
& \textbf{\textit{Accuracy}}& \textbf{\textit{F1 Score}}& \textbf{\textit{Logloss(Kaggle)}} \\

\hline
\textbf{SEA} &0.9912 &\underline{0.9908} &0.0431  \\
(Proposed Method) &  &  & \\
\hline
\hline
Hierarchical CNN \cite{b5}&0.9913 &0.9830 &0.0419  \\
\hline
\hline
CNN with &0.9828 &0.9830 &0.0750  \\
Structural Entropy \cite{b6}& & & \\ 
\hline
\hline
HYDRA \cite{b3}&0.9975 &\textbf{0.9951} &-  \\
\hline
\hline
Orthrus \cite{b4}&0.9924 &0.9872 &-  \\
\hline
\hline
Bytes Files Classifier \cite{b7}&0.9861 &0.9719 &0.3677  \\
\hline
\end{tabular}
\label{tab1}
\end{center}
\end{table}

Figure \ref{fig10} shows the confusion matrix based upon 5-folds cross validation. It shows that, our model is successful in capturing the patterns of minority classes as well. Even though only a few examples of minority classes were given, still our classifier successfully identified the majority of them. It indicates that our proposed method can give proper attention to hidden patterns among different classes.

\begin{figure}[htbp]
\centerline{\includegraphics[width=8cm,height=8cm,keepaspectratio]{cm.png}}
\caption{Confusion Matrix based on 5-folds}
\label{fig10}
\end{figure}

\subsection{Time efficiency}
Another metric for our evaluation was the time efficiency of our classifier which makes it the fastest classifier among other methods.We have divided our model’s time into different parts which helps us to understand the time consumption of each component.
\subsubsection{Training Time}
Embedding Training
\begin{itemize}
    \item 100 epochs took 16 minutes 46 secs with 1223 samples on Tesla GPU Neural Network Training
    \item 250 Epochs in 25 minutes on Tesla GPU
    \item 250/25 = 10 Epochs per minute
\end{itemize}
\subsubsection{Time efficiency in real time}
It took our model 686 seconds to process 11K massive data in 5 folds and each of the fold took 137.2 seconds. It means that \textbf{Each sample took 0.0124 seconds.}\\
\begin{itemize}
    \item 0.05 Seconds in embedding extraction
    \item 0.005 seconds in machine learning helping models
    \item 0.001 seconds in neural network part
\end{itemize}
The time taken in real time scenarios that is for test data on each part of the network is shown in Fig \ref{fig:time}.

\begin{table*}[htbp]
\caption{Comparison of trainable parameters of different methods with efficient proposed method.}
\begin{center}
\begin{tabular}{|c|c|}
\hline
\textbf{Models}&{\textbf{Trainable Parameters}} \\

\hline
\textbf{SEA} &\textbf{812,030}  \\
\hline
\hline
Hierarchical CNN \cite{b5}&20,863,302   \\
\hline
\hline
CNN with Structural Entropy \cite{b6} &900,148 \\ 
\hline
\hline
HYDRA \cite{b3}&2,666,617  \\
\hline
\hline
Orthrus \cite{b4}&973,989  \\
\hline
\hline

\end{tabular}
\label{tab2}
\end{center}
\end{table*}

In table \ref{tab2}, we compared trainable parameters of our proposed method with other methods. The reported numbers show that our proposed method has less number of trainable parameters. It makes SEA a suitable choice to be used in light weight smart applications. Although, in terms of logloss, hierarchical CNN was slightly better than our method and in terms of f1-score, HYDRA was slightly better. However, if we compare the number of parameters we can see a huge difference, we were able to almost equal them with very less number of parameters. Moreover, in terms of f1-score and logloss our method has outperformed most of them. Hence, the proposed method is a perfect balance between performance and efficiency.

\section{Conclusion and Future Work}
In this work, we proposed a light weight malware detection technique, called as SEA, for the detection of malicious software in smart applications. By formulating the problem of detection of malicious executable as a highly imbalanced multi-class classification, we developed an attention based model to improve the results on the minority classes as well.
Furthermore, after benchmarking the developed model against state-of-the-art models, we found that our proposed model is comparatively better not only in terms of accuracy and log loss but the number of parameters and time consumption as well. The other factors such as energy consumption, implementation on hardware devices such as Raspberry Pi or ESP32 and delay in the network are the part of future work. 

\section*{Acknowledgment}
This work has been fully supported by Higher Education Commission (HEC) of Pakistan under the Grant No. NRPU-5946

\begin{thebibliography}{00}
\bibitem{b1} Greff, K., Srivastava, R.K., Koutník, J., Steunebrink, B.R. and Schmidhuber, J., 2016. LSTM: A search space odyssey. IEEE transactions on neural networks and learning systems, 28(10), pp.2222-2232.
\bibitem{b2} Dey, R. and Salem, F.M., 2017, August. Gate-variants of gated recurrent unit (GRU) neural networks. In 2017 IEEE 60th international midwest symposium on circuits and systems (MWSCAS) (pp. 1597-1600). IEEE.
\bibitem{b3} Daniel Gibert, Carles Mateu, Jordi Planes, HYDRA: A multimodal deep learning framework for malware classification, Computers \& Security, Volume 95, 2020, 101873, ISSN 0167-4048, https://doi.org/10.1016/j.cose.2020.101873.
\bibitem{b4} D. Gibert, C. Mateu and J. Planes, "Orthrus: A Bimodal Learning Architecture for Malware Classification," 2020 International Joint Conference on Neural Networks (IJCNN), 2020, pp. 1-8, doi: 10.1109/IJCNN48605.2020.9206671.
\bibitem{b5} D. Gibert, C. Mateu and J. Planes, "A Hierarchical Convolutional Neural Network for Malware Classification," 2019 International Joint Conference on Neural Networks (IJCNN), 2019, pp. 1-8, doi: 10.1109/IJCNN.2019.8852469.
\bibitem{b6} Gibert, D., Mateu, C., Planes, J. and Vicens, R., 2018, April. Classification of malware by using structural entropy on convolutional neural networks. In Proceedings of the AAAI Conference on Artificial Intelligence (Vol. 32, No. 1).
\bibitem{b7} Gibert, D., Mateu, C., Planes, J. (2018). An End-to-End Deep Learning Architecture for Classification of Malware’s Binary Content. In: Kůrková, V., Manolopoulos, Y., Hammer, B., Iliadis, L., Maglogiannis, I. (eds) Artificial Neural Networks and Machine Learning – ICANN 2018. ICANN 2018. Lecture Notes in Computer Science(), vol 11141. Springer, Cham.
\bibitem{b8} Van der Maaten, L. and Hinton, G., 2008. Visualizing data using t-SNE. Journal of machine learning research, 9(11).
\bibitem{b9} Daffertshofer, A., Lamoth, C.J., Meijer, O.G. and Beek, P.J., 2004. PCA in studying coordination and variability: a tutorial. Clinical biomechanics, 19(4), pp.415-428.
\bibitem{b10} Benesty, J., Chen, J., Huang, Y. and Cohen, I., 2009. Pearson correlation coefficient. In Noise reduction in speech processing (pp. 1-4). Springer, Berlin, Heidelberg.
\bibitem{b11} Ling, C.X. and Li, C., 1998, August. Data mining for direct marketing: Problems and solutions. In Kdd
(Vol. 98, pp. 73-79).
\bibitem{b12} Japkowicz, N., 2000, June. The class imbalance problem: Significance and strategies. In Proc. of the
Int’l Conf. on Artificial Intelligence (Vol. 56, pp. 111-117).
\bibitem{b13} Alrubayyi, H., Goteng, G., Jaber, M. and Kelly, J., 2021. Challenges of Malware Detection in the IoT
and a Review of Artificial Immune System Approaches. Journal of Sensor and Actuator Networks, 10(4),
p.61
\bibitem{b14} Swain, P.H. and Hauska, H., 1977. The decision tree classifier: Design and potential. IEEE Transactions on Geoscience Electronics, 15(3), pp.142-147.
\bibitem{b15} Vishwanathan, S.V.M. and Murty, M.N., 2002, May. SSVM: a simple SVM algorithm. In Proceedings of the 2002 International Joint Conference on Neural Networks. IJCNN'02 (Cat. No. 02CH37290) (Vol. 3, pp. 2393-2398). IEEE.
\bibitem{b16} Hopfield, J.J., 1988. Artificial neural networks. IEEE Circuits and Devices Magazine, 4(5), pp.3-10.
\bibitem{b17} Ronen, R., Radu, M., Feuerstein, C., Yom-Tov, E. and Ahmadi, M., 2018. Microsoft malware classification challenge. arXiv preprint arXiv:1802.10135.
\bibitem{b18} Alrubayyi, H., Goteng, G., Jaber, M. and Kelly, J., 2021. Challenges of Malware Detection in the IoT and a Review of Artificial Immune System Approaches. Journal of Sensor and Actuator Networks, 10(4), p.61
\bibitem{b19} Nikolopoulos, S.D. and Polenakis, I., 2017. A graph-based model for malware detection and classification using system-call groups. Journal of Computer Virology and Hacking Techniques, 13(1), pp.29-46.
\bibitem{b20} Zhang, Y., Huang, Q., Ma, X., Yang, Z., and Jiang, J., 2016, August. Using multi-features and ensemble learning method for imbalanced malware classification. In 2016 IEEE Trustcom/BigDataSE/ISPA (pp. 965-973). IEEE.
\bibitem{b21} Yue, S., 2017. Imbalanced malware images classification: a CNN based approach. arXiv preprint arXiv:1708.08042.
\bibitem{b22} K. Alzarooni ., 2012, ‘‘Malware variant detection,’’ Ph.D. dissertation, Dept.Comput. Sci., Univ. College London, London, U.K
\bibitem{b23} Saxe, J. and Berlin, K., 2015, October. Deep neural network-based malware detection using two-dimensional binary program features. In 2015 10th international conference on malicious and
unwanted software (MALWARE) (pp. 11-20). IEEE.
\bibitem{b24} Ronen, R., Radu, M., Feuerstein, C., Yom-Tov, E. and Ahmadi, M., 2018. Microsoft malware classification challenge. arXiv preprint arXiv:1802.10135.
\bibitem{b25} Iwamoto, K. and Wasaki, K., 2012, November. Malware classification based on extracted api sequences using static analysis. In Proceedings of the Asian Internet Engineeering Conference (pp. 31-38).
\bibitem{b26} Carlin, D., O’Kane, P. and Sezer, S., 2017. Dynamic analysis of malware using run-time opcodes. In Data analytics and decision support for cybersecurity (pp. 99-125). Springer, Cham.
\bibitem{b27} Liu, L., Wang, B.S., Yu, B. and Zhong, Q.X., 2017. Automatic malware classification and new malware detection using machine learning. Frontiers of Information Technology \& Electronic Engineering, 18(9), pp.1336-1347.
\bibitem{b28} Venugopal, D. and Hu, G., 2008. Efficient signature based malware detection on mobile devices. Mobile Information Systems, 4(1), pp.33-49.
\bibitem{b29} OWASP https://owasp.org/
\bibitem{b30} Tommasini, Martino, Martin Rosso, Emmanuele Zambon, Luca Allodi, and Jerry den Hartog. "Characterizing Building Automation System Attacks and Attackers." In 2022 IEEE European Symposium on Security and Privacy Workshops (EuroS\&PW), pp. 139-149. IEEE, 2022.
\bibitem{b31} Popli, Navneet Kaur, and Anup Girdhar. "Behavioural analysis of recent ransomwares and prediction of future attacks by polymorphic and metamorphic ransomware." In Computational Intelligence: Theories, Applications and Future Directions-Volume II, pp. 65-80. Springer, Singapore, 2019.
\end{thebibliography}


\end{document}
