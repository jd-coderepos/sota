
\begin{figure}[t]
	\centering
	\includegraphics[height=1.8mm]{./figure/distribution_key.pdf}
    \subfigure[\label{fig:dist:a}1-shot]{\hspace{1mm}\includegraphics[width=0.4
    \columnwidth]{./figure/figure_dist_1shot.pdf}\hspace{1mm}} 
    \subfigure[\label{fig:dist:b}5-shot]{\hspace{1mm}\includegraphics[width=0.4\columnwidth]{./figure/figure_dist_5shot.pdf}\hspace{1mm}}
\caption{Weight distributions of base and novel classifiers where dotted lines represent means, using \textit{tiered-ImageNet} with ResNet-18.}
	\label{fig:shifting}
	\vspace{-2mm}
\end{figure}

\section{Analysis and Methodology on Zero-Base GFSL} \label{sec:anaylsis}

This section first investigates why the basic framework of GFSL cannot perform well in zero-base GFSL, and then presents an effective weight normalization method that enables a simple transfer learning scheme to achieve even a better performance than existing GFSL methods assuming the existence of base data.

\subsection{Hardness of Zero-Base GFSL}
As presented in Figure \ref{fig:imagenet}, a model trained by the basic framework of GFSL, that is, fine-tuning only the joint classifier  with , turns out to be extremely inaccurate for base classes yet pretty accurate for novel classes despite freezing the feature extractor. Thus, the fine-tuned classifier gets highly biased toward novel classes due to the absence of base samples. 

More specifically, when freezing the feature extractor , the feature space itself is fixed and so are the feature vectors  of all the samples . Consequently, it is 
decision boundaries in the space that are changed by fine-tuning the classifier and therefore matter to a biased prediction. Without a balanced dataset, it is challenging to properly learn hidden relationships between base and novel classes, leading to \textit{enlarged} (i.e., biased) decision boundaries of novel classes as depicted in Figure \ref{fig:decision}. In zero-base GFSL, it is our mission to find the best balance between decision boundaries of base and novel classes without retraining any base samples so that we can ideally make the best joint prediction. As decision boundaries between base and novel classes are formed where , they are mainly affected by how the weight values of  and  are distributed. In the following subsection, we therefore conduct a systematic analysis on the weight distributions of  and .

\subsection{Analysis on Weight Distributions of Classifiers} 

We investigate the underlying distributions of weights of base and novel classifiers particularly in terms of their mean  and variance . More specifically, given a classifier , where  represents the weight vector corresponding to class , we first define the vectors of class-wise means and standard deviations of weight values as follows:

where  and . Also, we use , , , and  to denote the vectors corresponding to the weights of base and novel classifiers (i.e.,  and ). 

In order to examine how the weight values of the novel classifier are different from those of the base classifier, we compute the average of class-wise means and standard deviations as  and compare  and  with  and . As observed in Figure \ref{fig:shifting}, we discover the following two undesirable facts, both of which should be tackled to obtain a balanced joint classifier.






\smalltitle{L2-norms proportional to standard deviations}
We first discover that the variance of  is greater than that of , i.e., , as shown in Figure \ref{fig:shifting}. This is somewhat intuitive in that the base classifier is trained on a large number of samples in  that can increase the diversity, whereas the novel classifier cannot have such a large diversity due to the lack of training samples in . What is \eat{maybe change}not quite obvious is that these standard deviations are indeed proportional to the L2-norms of weights in neural networks as the following proposition.
\begin{proposition} \label{thm:std}
Consider a parameter  of  weights in a neural network with the assumption that  is randomly initialized by a Gaussian distribution with zero mean and trained by a uniformly distributed dataset. Then, it holds that .
\end{proposition}
\begin{proof}
Given , we have: 
\end{proof}
By Proposition \ref{thm:std},  is implied from the observation of . Somewhat surprisingly, this contradicts to the highly biased results toward novel classes in Figure \ref{fig:imagenet} in the sense that many existing works \cite{HouPLWL19,KangXRYGFK20,ZhaoXGZX20} report that larger weight norms of a class tend to produce larger logits leading to more biased predictions toward the corresponding class. Thus, if we follow the existing strategy of equalizing the weight norms \cite{HouPLWL19,KangXRYGFK20,ZhaoXGZX20} by increasing the smaller ones yet decreasing the larger ones, the novel-biased classifier in zero-base GFSL would get even more biased toward novel classes, to be confirmed in our experiments.

Then, how could the classifier be highly biased toward novel classes even though the weight norms of novel classes are less than those of base classes? The true answer to this question lies in the average weight of each classifier rather than its weight norm.

\smalltitle{Mean shifting phenomenon}
In terms of means of weight distributions, we observe the fact that the average weight of the novel classifier is positively shifted (i.e., ) while that of the base classifier keeps almost zero (i.e., ). We call this situation \textit{mean shifting phenomenon} commonly observed in all the graphs of Figure \ref{fig:shifting}. 

Positively shifted  indicates that each weight of  on the average has a more positive value. Recalling that decision boundaries are constructed at , more positive weights of  would increase , and therefore enlarge the decision boundaries of novel classes. This implies that mean shifting phenomenon is a more critical reason behind the novel-biased model in zero-base GFSL. As mentioned above, however, the existing works \cite{HouPLWL19,KangXRYGFK20,ZhaoXGZX20} only focus on equalizing the weight norms, which turn out to be proportional to the standard deviations of weights, between base and novel classes, and hence their normalization method alone fails to achieve a satisfactory performance.


\begin{figure}[t!]
	\centering
    \includegraphics[width=0.98\columnwidth]{./figure/figure_prob.pdf}
    \caption{An illustrative example for the positively shifted mean of weights for novel classes, where a cat image gets probabilities  from  but its probabilities becomes  in .}
    \label{fig:prob}\end{figure}



\smalltitle{What makes mean shifted}
Let us now analyze why mean shifting phenomenon occurs to the novel classifier in zero-base GFSL. To this end, we first consider how we update the weights of each classifier by gradient descent as , where the gradient is:

Since  is always non-negative due to the ReLU function and  is also a non-negative probability value, the gradient is positive only if  (i.e., for the probability of the class label of ) and negative for all the other class probabilities. In training a balanced dataset of all the classes uniformly distributed, the total positive gradient for each class eventually gets similar to the absolute value of its total negative gradient, which is why . Thus, if we train  only to  ,  would also be close to zero. 

However, when fine-tuning the joint classifier  with only , the total positive gradient of  increases whereas the absolute value of its total negative gradient decreases because all the output probabilities of  together become smaller in training  than they used to be in training only . To illustrate, consider an example of Figure \ref{fig:prob}, where output probabilities of  are larger than those of  for a given training image of \textit{`cat'}. Thus, even if  outputs  for the cat image, the joint classifier  would output something like  for 6 base classes followed by 2 novel classes. Consequently, the positive gradient caused by the novel class \textit{`cat'} is increased from  to , but the absolute value of the negative gradient for the second novel class \textit{`bird'} is decreased from  to . Furthermore,  can receive negative gradients only from the instances of the other novel classes due to the absence of base instances. This makes  to be more positively shifted. 

As for , only negative gradients will arrive during the entire fine-tuning process, but its total amount would not be that much because the well-trained  is not likely to be overconfident to irrelevant novel classes particularly when  gets used to identifying their corresponding novel classes. This is why  still keeps to be zero after fine-tuning.





































\subsection{Solution: Mean-Variance Classifier Normalization} \label{sec:solution}

\begin{figure*}[t!]
   \centering 
    \includegraphics[width=1.7\columnwidth]{./figure/figure_concept.pdf}
   \caption{Overview of Mean-Variance Classifier Normalization. In the pre-training stage, we train the entire model on all base classes. In the fine-tuning stage, we normalize the novel classifier by online mean centering in the process of training and adjust the trained weights of the base and novel classifiers by re-scaling them using the standard deviation ratio.}
   \label{fig:framework}
\end{figure*}

To fulfill both the zero-mean and a balanced variance of base and novel classifiers, we propose a simple yet effective normalization method, called \textit{Mean-Variance Classifier Normalization} (\textit{MVCN}). MVCN takes two essential steps, namely \textit{online mean centering} and \textit{offline variance balancing}. We perform online mean centering during fine-tuning the joint classifier, and then proceed to balance variances of weights as a post processing step once the classifier is well trained. The entire process is outlined in Figure \ref{fig:framework}.


\smalltitle{Online mean centering} First, we keep normalizing the weights of the novel classifier to have zero-mean in the process of training by:

When fine-tuning the joint classifier, online mean centering is performed only on the novel classifier. This directly reduces the positive weights of the novel classifier and keeps the zero-mean while learning the features of novel classes. Note that we do not give any constraints to the variance of weights during fine-tuning, but rather allow each classifier to learn as many required features as possible.








\smalltitle{Offline variance balancing} 
Once the fine-tuning stage is done, we adjust the weights of base classifier according to the ratio of standard deviations as follows:

where  is the average of class-wise standard deviations for all novel classes. We re-scale each weight of the base classifier by multiplying the ratio of the standard deviation of the novel classifier to that of the base classifier (i.e., ), and thereby the weight variance of the base classifier gets similar to that of the novel classifier. Note that we do not directly normalize  by their , which makes the zero-mean and unit-variance , because the standard deviation of weights is much smaller than 1.









\smalltitle{Post linear optimization without base data}
Finally, we introduce class-wise learnable parameters  and  for , which are intended for further optimizing decision boundaries of novel classes. With freezing ,  and  are similarly trained by Eq. (\ref{eq:finetuning}) and used at inference time as . Through these additional parameters, we can further improve the performance of novel classes particularly in an extreme case of 1-shot learning. Note that this optimization process is performed still without using any base samples.































 
 
























 































%
