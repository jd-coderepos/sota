\documentclass{article}

      \usepackage[nonatbib,final]{neurips_2020}

\newcommand{\EXP}[1]{\exp\left({#1}\right)}
\usepackage[utf8]{inputenc} \usepackage[T1]{fontenc}    \usepackage{hyperref}       \usepackage{url}            \usepackage{booktabs}       \usepackage{amsfonts}       \usepackage{nicefrac}       \usepackage{microtype}      




\usepackage{amsmath,amsfonts,bm}

\newcommand{\figleft}{{\em (Left)}}
\newcommand{\figcenter}{{\em (Center)}}
\newcommand{\figright}{{\em (Right)}}
\newcommand{\figtop}{{\em (Top)}}
\newcommand{\figbottom}{{\em (Bottom)}}
\newcommand{\captiona}{{\em (a)}}
\newcommand{\captionb}{{\em (b)}}
\newcommand{\captionc}{{\em (c)}}
\newcommand{\captiond}{{\em (d)}}

\newcommand{\newterm}[1]{{\bf #1}}


\def\figref#1{figure~\ref{#1}}
\def\Figref#1{Figure~\ref{#1}}
\def\twofigref#1#2{figures \ref{#1} and \ref{#2}}
\def\quadfigref#1#2#3#4{figures \ref{#1}, \ref{#2}, \ref{#3} and \ref{#4}}
\def\secref#1{section~\ref{#1}}
\def\Secref#1{Section~\ref{#1}}
\def\twosecrefs#1#2{sections \ref{#1} and \ref{#2}}
\def\secrefs#1#2#3{sections \ref{#1}, \ref{#2} and \ref{#3}}
\def\eqref#1{equation~\ref{#1}}
\def\Eqref#1{Equation~\ref{#1}}
\def\plaineqref#1{\ref{#1}}
\def\chapref#1{chapter~\ref{#1}}
\def\Chapref#1{Chapter~\ref{#1}}
\def\rangechapref#1#2{chapters\ref{#1}--\ref{#2}}
\def\algref#1{algorithm~\ref{#1}}
\def\Algref#1{Algorithm~\ref{#1}}
\def\twoalgref#1#2{algorithms \ref{#1} and \ref{#2}}
\def\Twoalgref#1#2{Algorithms \ref{#1} and \ref{#2}}
\def\partref#1{part~\ref{#1}}
\def\Partref#1{Part~\ref{#1}}
\def\twopartref#1#2{parts \ref{#1} and \ref{#2}}

\def\ceil#1{\lceil #1 \rceil}
\def\floor#1{\lfloor #1 \rfloor}
\def\1{\bm{1}}
\newcommand{\train}{\mathcal{D}}
\newcommand{\valid}{\mathcal{D_{\mathrm{valid}}}}
\newcommand{\test}{\mathcal{D_{\mathrm{test}}}}

\def\eps{{\epsilon}}


\def\reta{{\textnormal{}}}
\def\ra{{\textnormal{a}}}
\def\rb{{\textnormal{b}}}
\def\rc{{\textnormal{c}}}
\def\rd{{\textnormal{d}}}
\def\re{{\textnormal{e}}}
\def\rf{{\textnormal{f}}}
\def\rg{{\textnormal{g}}}
\def\rh{{\textnormal{h}}}
\def\ri{{\textnormal{i}}}
\def\rj{{\textnormal{j}}}
\def\rk{{\textnormal{k}}}
\def\rl{{\textnormal{l}}}
\def\rn{{\textnormal{n}}}
\def\ro{{\textnormal{o}}}
\def\rp{{\textnormal{p}}}
\def\rq{{\textnormal{q}}}
\def\rr{{\textnormal{r}}}
\def\rs{{\textnormal{s}}}
\def\rt{{\textnormal{t}}}
\def\ru{{\textnormal{u}}}
\def\rv{{\textnormal{v}}}
\def\rw{{\textnormal{w}}}
\def\rx{{\textnormal{x}}}
\def\ry{{\textnormal{y}}}
\def\rz{{\textnormal{z}}}

\def\rvepsilon{{\mathbf{\epsilon}}}
\def\rvtheta{{\mathbf{\theta}}}
\def\rva{{\mathbf{a}}}
\def\rvb{{\mathbf{b}}}
\def\rvc{{\mathbf{c}}}
\def\rvd{{\mathbf{d}}}
\def\rve{{\mathbf{e}}}
\def\rvf{{\mathbf{f}}}
\def\rvg{{\mathbf{g}}}
\def\rvh{{\mathbf{h}}}
\def\rvu{{\mathbf{i}}}
\def\rvj{{\mathbf{j}}}
\def\rvk{{\mathbf{k}}}
\def\rvl{{\mathbf{l}}}
\def\rvm{{\mathbf{m}}}
\def\rvn{{\mathbf{n}}}
\def\rvo{{\mathbf{o}}}
\def\rvp{{\mathbf{p}}}
\def\rvq{{\mathbf{q}}}
\def\rvr{{\mathbf{r}}}
\def\rvs{{\mathbf{s}}}
\def\rvt{{\mathbf{t}}}
\def\rvu{{\mathbf{u}}}
\def\rvv{{\mathbf{v}}}
\def\rvw{{\mathbf{w}}}
\def\rvx{{\mathbf{x}}}
\def\rvy{{\mathbf{y}}}
\def\rvz{{\mathbf{z}}}

\def\erva{{\textnormal{a}}}
\def\ervb{{\textnormal{b}}}
\def\ervc{{\textnormal{c}}}
\def\ervd{{\textnormal{d}}}
\def\erve{{\textnormal{e}}}
\def\ervf{{\textnormal{f}}}
\def\ervg{{\textnormal{g}}}
\def\ervh{{\textnormal{h}}}
\def\ervi{{\textnormal{i}}}
\def\ervj{{\textnormal{j}}}
\def\ervk{{\textnormal{k}}}
\def\ervl{{\textnormal{l}}}
\def\ervm{{\textnormal{m}}}
\def\ervn{{\textnormal{n}}}
\def\ervo{{\textnormal{o}}}
\def\ervp{{\textnormal{p}}}
\def\ervq{{\textnormal{q}}}
\def\ervr{{\textnormal{r}}}
\def\ervs{{\textnormal{s}}}
\def\ervt{{\textnormal{t}}}
\def\ervu{{\textnormal{u}}}
\def\ervv{{\textnormal{v}}}
\def\ervw{{\textnormal{w}}}
\def\ervx{{\textnormal{x}}}
\def\ervy{{\textnormal{y}}}
\def\ervz{{\textnormal{z}}}

\def\rmA{{\mathbf{A}}}
\def\rmB{{\mathbf{B}}}
\def\rmC{{\mathbf{C}}}
\def\rmD{{\mathbf{D}}}
\def\rmE{{\mathbf{E}}}
\def\rmF{{\mathbf{F}}}
\def\rmG{{\mathbf{G}}}
\def\rmH{{\mathbf{H}}}
\def\rmI{{\mathbf{I}}}
\def\rmJ{{\mathbf{J}}}
\def\rmK{{\mathbf{K}}}
\def\rmL{{\mathbf{L}}}
\def\rmM{{\mathbf{M}}}
\def\rmN{{\mathbf{N}}}
\def\rmO{{\mathbf{O}}}
\def\rmP{{\mathbf{P}}}
\def\rmQ{{\mathbf{Q}}}
\def\rmR{{\mathbf{R}}}
\def\rmS{{\mathbf{S}}}
\def\rmT{{\mathbf{T}}}
\def\rmU{{\mathbf{U}}}
\def\rmV{{\mathbf{V}}}
\def\rmW{{\mathbf{W}}}
\def\rmX{{\mathbf{X}}}
\def\rmY{{\mathbf{Y}}}
\def\rmZ{{\mathbf{Z}}}

\def\ermA{{\textnormal{A}}}
\def\ermB{{\textnormal{B}}}
\def\ermC{{\textnormal{C}}}
\def\ermD{{\textnormal{D}}}
\def\ermE{{\textnormal{E}}}
\def\ermF{{\textnormal{F}}}
\def\ermG{{\textnormal{G}}}
\def\ermH{{\textnormal{H}}}
\def\ermI{{\textnormal{I}}}
\def\ermJ{{\textnormal{J}}}
\def\ermK{{\textnormal{K}}}
\def\ermL{{\textnormal{L}}}
\def\ermM{{\textnormal{M}}}
\def\ermN{{\textnormal{N}}}
\def\ermO{{\textnormal{O}}}
\def\ermP{{\textnormal{P}}}
\def\ermQ{{\textnormal{Q}}}
\def\ermR{{\textnormal{R}}}
\def\ermS{{\textnormal{S}}}
\def\ermT{{\textnormal{T}}}
\def\ermU{{\textnormal{U}}}
\def\ermV{{\textnormal{V}}}
\def\ermW{{\textnormal{W}}}
\def\ermX{{\textnormal{X}}}
\def\ermY{{\textnormal{Y}}}
\def\ermZ{{\textnormal{Z}}}

\def\vzero{{\bm{0}}}
\def\vone{{\bm{1}}}
\def\vmu{{\bm{\mu}}}
\def\vtheta{{\bm{\theta}}}
\def\va{{\bm{a}}}
\def\vb{{\bm{b}}}
\def\vc{{\bm{c}}}
\def\vd{{\bm{d}}}
\def\ve{{\bm{e}}}
\def\vf{{\bm{f}}}
\def\vg{{\bm{g}}}
\def\vh{{\bm{h}}}
\def\vi{{\bm{i}}}
\def\vj{{\bm{j}}}
\def\vk{{\bm{k}}}
\def\vl{{\bm{l}}}
\def\vm{{\bm{m}}}
\def\vn{{\bm{n}}}
\def\vo{{\bm{o}}}
\def\vp{{\bm{p}}}
\def\vq{{\bm{q}}}
\def\vr{{\bm{r}}}
\def\vs{{\bm{s}}}
\def\vt{{\bm{t}}}
\def\vu{{\bm{u}}}
\def\vv{{\bm{v}}}
\def\vw{{\bm{w}}}
\def\vx{{\bm{x}}}
\def\vy{{\bm{y}}}
\def\vz{{\bm{z}}}

\def\evalpha{{\alpha}}
\def\evbeta{{\beta}}
\def\evepsilon{{\epsilon}}
\def\evlambda{{\lambda}}
\def\evomega{{\omega}}
\def\evmu{{\mu}}
\def\evpsi{{\psi}}
\def\evsigma{{\sigma}}
\def\evtheta{{\theta}}
\def\eva{{a}}
\def\evb{{b}}
\def\evc{{c}}
\def\evd{{d}}
\def\eve{{e}}
\def\evf{{f}}
\def\evg{{g}}
\def\evh{{h}}
\def\evi{{i}}
\def\evj{{j}}
\def\evk{{k}}
\def\evl{{l}}
\def\evm{{m}}
\def\evn{{n}}
\def\evo{{o}}
\def\evp{{p}}
\def\evq{{q}}
\def\evr{{r}}
\def\evs{{s}}
\def\evt{{t}}
\def\evu{{u}}
\def\evv{{v}}
\def\evw{{w}}
\def\evx{{x}}
\def\evy{{y}}
\def\evz{{z}}

\def\mA{{\bm{A}}}
\def\mB{{\bm{B}}}
\def\mC{{\bm{C}}}
\def\mD{{\bm{D}}}
\def\mE{{\bm{E}}}
\def\mF{{\bm{F}}}
\def\mG{{\bm{G}}}
\def\mH{{\bm{H}}}
\def\mI{{\bm{I}}}
\def\mJ{{\bm{J}}}
\def\mK{{\bm{K}}}
\def\mL{{\bm{L}}}
\def\mM{{\bm{M}}}
\def\mN{{\bm{N}}}
\def\mO{{\bm{O}}}
\def\mP{{\bm{P}}}
\def\mQ{{\bm{Q}}}
\def\mR{{\bm{R}}}
\def\mS{{\bm{S}}}
\def\mT{{\bm{T}}}
\def\mU{{\bm{U}}}
\def\mV{{\bm{V}}}
\def\mW{{\bm{W}}}
\def\mX{{\bm{X}}}
\def\mY{{\bm{Y}}}
\def\mZ{{\bm{Z}}}
\def\mBeta{{\bm{\beta}}}
\def\mPhi{{\bm{\Phi}}}
\def\mLambda{{\bm{\Lambda}}}
\def\mSigma{{\bm{\Sigma}}}

\DeclareMathAlphabet{\mathsfit}{\encodingdefault}{\sfdefault}{m}{sl}
\SetMathAlphabet{\mathsfit}{bold}{\encodingdefault}{\sfdefault}{bx}{n}
\newcommand{\tens}[1]{\bm{\mathsfit{#1}}}
\def\tA{{\tens{A}}}
\def\tB{{\tens{B}}}
\def\tC{{\tens{C}}}
\def\tD{{\tens{D}}}
\def\tE{{\tens{E}}}
\def\tF{{\tens{F}}}
\def\tG{{\tens{G}}}
\def\tH{{\tens{H}}}
\def\tI{{\tens{I}}}
\def\tJ{{\tens{J}}}
\def\tK{{\tens{K}}}
\def\tL{{\tens{L}}}
\def\tM{{\tens{M}}}
\def\tN{{\tens{N}}}
\def\tO{{\tens{O}}}
\def\tP{{\tens{P}}}
\def\tQ{{\tens{Q}}}
\def\tR{{\tens{R}}}
\def\tS{{\tens{S}}}
\def\tT{{\tens{T}}}
\def\tU{{\tens{U}}}
\def\tV{{\tens{V}}}
\def\tW{{\tens{W}}}
\def\tX{{\tens{X}}}
\def\tY{{\tens{Y}}}
\def\tZ{{\tens{Z}}}


\def\gA{{\mathcal{A}}}
\def\gB{{\mathcal{B}}}
\def\gC{{\mathcal{C}}}
\def\gD{{\mathcal{D}}}
\def\gE{{\mathcal{E}}}
\def\gF{{\mathcal{F}}}
\def\gG{{\mathcal{G}}}
\def\gH{{\mathcal{H}}}
\def\gI{{\mathcal{I}}}
\def\gJ{{\mathcal{J}}}
\def\gK{{\mathcal{K}}}
\def\gL{{\mathcal{L}}}
\def\gM{{\mathcal{M}}}
\def\gN{{\mathcal{N}}}
\def\gO{{\mathcal{O}}}
\def\gP{{\mathcal{P}}}
\def\gQ{{\mathcal{Q}}}
\def\gR{{\mathcal{R}}}
\def\gS{{\mathcal{S}}}
\def\gT{{\mathcal{T}}}
\def\gU{{\mathcal{U}}}
\def\gV{{\mathcal{V}}}
\def\gW{{\mathcal{W}}}
\def\gX{{\mathcal{X}}}
\def\gY{{\mathcal{Y}}}
\def\gZ{{\mathcal{Z}}}

\def\sA{{\mathbb{A}}}
\def\sB{{\mathbb{B}}}
\def\sC{{\mathbb{C}}}
\def\sD{{\mathbb{D}}}
\def\sF{{\mathbb{F}}}
\def\sG{{\mathbb{G}}}
\def\sH{{\mathbb{H}}}
\def\sI{{\mathbb{I}}}
\def\sJ{{\mathbb{J}}}
\def\sK{{\mathbb{K}}}
\def\sL{{\mathbb{L}}}
\def\sM{{\mathbb{M}}}
\def\sN{{\mathbb{N}}}
\def\sO{{\mathbb{O}}}
\def\sP{{\mathbb{P}}}
\def\sQ{{\mathbb{Q}}}
\def\sR{{\mathbb{R}}}
\def\sS{{\mathbb{S}}}
\def\sT{{\mathbb{T}}}
\def\sU{{\mathbb{U}}}
\def\sV{{\mathbb{V}}}
\def\sW{{\mathbb{W}}}
\def\sX{{\mathbb{X}}}
\def\sY{{\mathbb{Y}}}
\def\sZ{{\mathbb{Z}}}

\def\emLambda{{\Lambda}}
\def\emA{{A}}
\def\emB{{B}}
\def\emC{{C}}
\def\emD{{D}}
\def\emE{{E}}
\def\emF{{F}}
\def\emG{{G}}
\def\emH{{H}}
\def\emI{{I}}
\def\emJ{{J}}
\def\emK{{K}}
\def\emL{{L}}
\def\emM{{M}}
\def\emN{{N}}
\def\emO{{O}}
\def\emP{{P}}
\def\emQ{{Q}}
\def\emR{{R}}
\def\emS{{S}}
\def\emT{{T}}
\def\emU{{U}}
\def\emV{{V}}
\def\emW{{W}}
\def\emX{{X}}
\def\emY{{Y}}
\def\emZ{{Z}}
\def\emSigma{{\Sigma}}

\newcommand{\etens}[1]{\mathsfit{#1}}
\def\etLambda{{\etens{\Lambda}}}
\def\etA{{\etens{A}}}
\def\etB{{\etens{B}}}
\def\etC{{\etens{C}}}
\def\etD{{\etens{D}}}
\def\etE{{\etens{E}}}
\def\etF{{\etens{F}}}
\def\etG{{\etens{G}}}
\def\etH{{\etens{H}}}
\def\etI{{\etens{I}}}
\def\etJ{{\etens{J}}}
\def\etK{{\etens{K}}}
\def\etL{{\etens{L}}}
\def\etM{{\etens{M}}}
\def\etN{{\etens{N}}}
\def\etO{{\etens{O}}}
\def\etP{{\etens{P}}}
\def\etQ{{\etens{Q}}}
\def\etR{{\etens{R}}}
\def\etS{{\etens{S}}}
\def\etT{{\etens{T}}}
\def\etU{{\etens{U}}}
\def\etV{{\etens{V}}}
\def\etW{{\etens{W}}}
\def\etX{{\etens{X}}}
\def\etY{{\etens{Y}}}
\def\etZ{{\etens{Z}}}

\newcommand{\pdata}{p_{\rm{data}}}
\newcommand{\ptrain}{\hat{p}_{\rm{data}}}
\newcommand{\Ptrain}{\hat{P}_{\rm{data}}}
\newcommand{\pmodel}{p_{\rm{model}}}
\newcommand{\Pmodel}{P_{\rm{model}}}
\newcommand{\ptildemodel}{\tilde{p}_{\rm{model}}}
\newcommand{\pencode}{p_{\rm{encoder}}}
\newcommand{\pdecode}{p_{\rm{decoder}}}
\newcommand{\precons}{p_{\rm{reconstruct}}}

\newcommand{\laplace}{\mathrm{Laplace}} 

\newcommand{\E}{\mathbb{E}}
\newcommand{\Ls}{\mathcal{L}}
\newcommand{\R}{\mathbb{R}}
\newcommand{\emp}{\tilde{p}}
\newcommand{\lr}{\alpha}
\newcommand{\reg}{\lambda}
\newcommand{\rect}{\mathrm{rectifier}}
\newcommand{\softmax}{\mathrm{softmax}}
\newcommand{\sigmoid}{\sigma}
\newcommand{\softplus}{\zeta}
\newcommand{\KL}{D_{\mathrm{KL}}}
\newcommand{\Var}{\mathrm{Var}}
\newcommand{\standarderror}{\mathrm{SE}}
\newcommand{\Cov}{\mathrm{Cov}}
\newcommand{\normlzero}{L^0}
\newcommand{\normlone}{L^1}
\newcommand{\normltwo}{L^2}
\newcommand{\normlp}{L^p}
\newcommand{\normmax}{L^\infty}

\newcommand{\parents}{Pa} 

\DeclareMathOperator*{\argmax}{arg\,max}
\DeclareMathOperator*{\argmin}{arg\,min}

\DeclareMathOperator{\sign}{sign}
\DeclareMathOperator{\Tr}{Tr}
\let\ab\allowbreak
 
\usepackage{hyperref}
\usepackage{url}




\newcommand\bertbase{BERT\xspace}
\newcommand\bertlarge{BERT\xspace}
\newcommand\bertft{BERT\xspace}

\newcommand{\mb}[1]{\boldsymbol{\mathbf{#1}}}
\usepackage{xcolor}

\newcommand{\qizhe}[1]{\textbf{\textcolor{red}{Qizhe: #1}}}
\newcommand{\zihang}[1]{\textbf{\textcolor{blue}{Zihang: #1}}}
\newcommand{\ed}[1]{\textbf{\textcolor{yellow}{Ed: #1}}}
\newcommand{\tl}[1]{\textcolor{brown}{#1}}
\newcommand{\qvl}[1]{\textbf{\textcolor{orange}{Quoc: #1}}}

\newcommand{\delete}[1]{{\textcolor{gray}{#1}}}
\newcommand{\add}[1]{{\textcolor{blue}{#1}}}


\newcommand{\divg}[3][]{\mathcal{D}_{#1}\left({#2} \;\middle\|\; {#3} \right)}
\newcommand{\ce}[2][]{\mathrm{CE}\left({#1} \;\middle\|\; {#2} \right)}


\newcommand{\cmark}{\ding{51}}\newcommand{\xmark}{\ding{55}}

\usepackage{url}

\usepackage{graphicx}
\usepackage{caption}
\usepackage{booktabs}
\usepackage{enumitem}
\usepackage{xspace}
\usepackage{multirow}
\usepackage{algorithm}
\usepackage{algorithmic}

\usepackage{amssymb}\usepackage{pifont}\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{amsthm}
\usepackage{hyperref}
\newtheorem{theorem}{Theorem}
\newtheorem{corollary}{Corollary}
\newtheorem{innercustomthm}{Theorem}
\newenvironment{customthm}[1]
  {\renewcommand\theinnercustomthm{#1}\innercustomthm}
  {\endinnercustomthm}




\usepackage{subcaption}


\def\name{UDA\xspace}
\def\smallImagenet{ImageNet-10\%\xspace}
\def\jft{JFT~\cite{hinton2015distilling, chollet2017xception}\xspace}



\title{Unsupervised Data Augmentation\\ for Consistency Training}

\author{Qizhe Xie, Zihang Dai, Eduard Hovy, Minh-Thang Luong, Quoc V. Le\\
 Google Research, Brain Team,  Carnegie Mellon University \\
  \texttt{\{qizhex, dzihang, hovy\}@cs.cmu.edu, \{thangluong, qvl\}@google.com} \\
}



\begin{document}

\maketitle


\begin{abstract}
Semi-supervised learning lately has shown much promise in improving deep learning models when labeled data is scarce. Common among recent approaches is the use of consistency training on a large amount of unlabeled data to constrain model predictions to be invariant to input noise. In this work, we present a new perspective on how to effectively noise unlabeled examples and argue that the quality of noising, specifically those produced by advanced data augmentation methods, plays a crucial role in semi-supervised learning. By substituting simple noising operations with advanced data augmentation methods such as RandAugment and back-translation, our method brings substantial improvements across six language and three vision tasks under the same consistency training framework. On the IMDb text classification dataset, with only 20 labeled examples, our method achieves an error rate of 4.20, outperforming the state-of-the-art model trained on 25,000 labeled examples. On a standard semi-supervised learning benchmark, CIFAR-10, our method outperforms all previous approaches and achieves an error rate of 5.43 with only 250 examples. Our method also combines well with transfer learning, e.g., when finetuning from BERT, and yields improvements in high-data regime, such as ImageNet, whether when there is only 10\% labeled data or when a full labeled set with 1.3M extra unlabeled examples is used.\footnote{Code is available at \url{https://github.com/google-research/uda}.}
\end{abstract}



 \vspace{-0.5em}
\section{Introduction}
\vspace{-0.5em}
\label{sec:intro}


A fundamental weakness of deep learning is that it typically requires a lot of labeled data to work well. 
Semi-supervised learning (SSL) ~\cite{chapelle2009semi} is one of the most promising paradigms of leveraging unlabeled data to address this weakness. The recent works in SSL are diverse but those that are based on consistency training~\cite{bachman2014learning,rasmus2015semi,laine2016temporal,tarvainen2017mean} have  shown to work well on many benchmarks. 



In a nutshell, consistency training methods simply regularize model predictions to be invariant to small noise applied to either input examples~\cite{miyato2018virtual, sajjadi2016regularization, clark2018semi} or hidden states~\cite{bachman2014learning, laine2016temporal}. 
This framework makes sense intuitively because a good model should be robust to any small change in an input example or hidden states.
Under this framework, different methods in this category differ mostly in how and where the noise injection is applied.  Typical noise injection methods are additive Gaussian noise, dropout noise or adversarial noise. 


In this work, we investigate the role of noise injection in consistency training 
and observe that advanced data augmentation methods, specifically those work best in supervised learning \cite{simard1998transformation,krizhevsky2012imagenet,cubuk2018autoaugment,yu2018qanet}, also perform well in semi-supervised learning.
There is indeed a strong correlation between the performance of data augmentation operations in supervised learning and their performance in consistency training. We, hence, propose to substitute the traditional noise injection methods with high quality data augmentation methods in order to improve consistency training.
To emphasize the use of better data augmentation in consistency training, we name our method Unsupervised Data Augmentation or UDA.


We evaluate \name on a wide variety of language and vision tasks. 
On six text classification tasks, our method achieves significant improvements over state-of-the-art models. Notably, on IMDb, \name with 20 labeled examples outperforms the state-of-the-art model trained on 1250x more labeled data. On standard semi-supervised learning benchmarks CIFAR-10 and SVHN, 
UDA outperforms all existing semi-supervised learning methods by significant margins and achieves an error rate of 5.43 and 2.72 with 250 labeled examples respectively. Finally, we also find \name to be beneficial when there is a large amount of supervised data. 
For instance, on ImageNet, \name leads to improvements of top-1 accuracy from  to  with  of the labeled set and from  to  when we use the full labeled set and an external dataset with M unlabeled examples.

Our key contributions and findings can be summarized as follows:
\begin{itemize}[leftmargin=*,itemsep=0em,topsep=0em]
    \item First, we show that state-of-the-art data augmentations found in supervised learning can also serve as a superior source of noise under the consistency enforcing semi-supervised framework. {\it See results in Table~\ref{tab:cifar10_sup_vs_unsup} and Table~\ref{tab:yelp_5_sup_vs_unsup}.}
    \item Second, we show that UDA can match and even outperform purely supervised learning that uses orders of magnitude more labeled data. {\it See results in Table~\ref{tab:text_results} and Figure~\ref{fig:cifar_svhn_vary_sup}.}
    
    {\it State-of-the-art results for both vision and language tasks are reported in Table~\ref{tab:published_results} and \ref{tab:text_results}. The effectiveness of UDA across different training data sizes are highlighted in Figure~\ref{fig:cifar_svhn_vary_sup} and \ref{fig:text_vary_sup}.}
    \item Third, we show that UDA combines well with transfer learning, e.g., when fine-tuning from BERT ({\it see Table~\ref{tab:text_results}}), and is effective at high-data regime, e.g. on ImageNet ({\it see Table~\ref{tab:imagenet}}).
    \item Lastly, we also provide a theoretical analysis of how \name improves the classification performance and the corresponding role of the state-of-the-art augmentation in Section \ref{sec:theory}.
\end{itemize}
 \vspace{-0.5em}
\section{Unsupervised Data Augmentation (UDA)}
\label{sec:method}
\vspace{-0.5em}
In this section, we first formulate our task and then present the key method and insights behind \name.
Throughout this paper, we focus on classification problems and will use  to denote the input and  to denote its ground-truth prediction target. We are interested in learning a model  to predict  based on the input , where  denotes the model parameters.
Finally, we will use  and  to denote the distributions of labeled and unlabeled examples respectively and use  to denote the perfect classifier that we hope to learn. 

\vspace{-0.5em}
\subsection{Background: Supervised Data Augmentation}
\label{sec:sda}
\vspace{-0.5em}

Data augmentation aims at creating novel and realistic-looking training data by applying a transformation to an example, without changing its label.
Formally, let  be the augmentation transformation from which one can draw augmented examples  based on an original example .
For an augmentation transformation to be valid, it is required that any example  drawn from the distribution shares the same ground-truth label as .
Given a valid augmentation transformation, we can simply minimize the negative log-likelihood on augmented examples. 

Supervised data augmentation can be equivalently seen as constructing an augmented labeled set from the original supervised set and then training the model on the augmented set. Therefore, the augmented set needs to provide additional inductive biases to be more effective. How to design the augmentation transformation has, thus, become critical. 

In recent years, there have been significant advancements on the design of data augmentations for NLP~\cite{yu2018qanet}, vision~\cite{krizhevsky2012imagenet,cubuk2018autoaugment} and speech~\cite{hannun2014deep,park2019specaugment} in supervised settings.
Despite the promising results, data augmentation is mostly regarded as the ``cherry on the cake'' which provides a steady but limited performance boost because these augmentations has so far only been applied to a set of labeled examples which is usually of a small size. 
Motivated by this limitation, via the consistency training framework, we extend the advancement in supervised data augmentation to semi-supervised learning where abundant unlabeled data is available. 

\vspace{-0.3em}
\subsection{Unsupervised Data Augmentation}
\label{sec:uda}
\vspace{-0.3em}

As discussed in the introduction, a recent line of work in semi-supervised learning has been utilizing unlabeled examples to enforce smoothness of the model.
The general form of these works can be summarized as follows:
\begin{itemize}[leftmargin=*,itemsep=0em,topsep=0em]
\item Given an input , compute the output distribution  given  and a noised version  by injecting a small noise . 
The noise can be applied to  or hidden states.
\item Minimize a divergence metric between the two distributions .
\end{itemize}
This procedure enforces the model to be insensitive to the noise  and hence smoother with respect to changes in the input (or hidden) space. 
From another perspective, minimizing the consistency loss gradually propagates label information from labeled examples to unlabeled ones.

In this work, we are interested in a particular setting where the noise is injected to the input , i.e., , as considered by prior works~\cite{sajjadi2016regularization, laine2016temporal, miyato2018virtual}.
But different from existing work, we focus on the unattended question of how the form or ``quality'' of the noising operation  can influence the performance of this consistency training framework.
Specifically, to enforce consistency, prior methods generally employ simple noise injection methods such as adding Gaussian noise, simple input augmentations to noise unlabeled examples. 
In contrast, we hypothesize that stronger data augmentations in supervised learning can also lead to superior performance when used to noise unlabeled examples in the semi-supervised consistency training framework, since it has been shown that more advanced data augmentations that are more diverse and natural can lead to significant performance gain in the supervised setting.

Following this idea, we propose to use a rich set of state-of-the-art data augmentations verified in various supervised settings to inject noise and optimize the same consistency training objective on unlabeled examples. When jointly trained with labeled examples, we utilize a weighting factor  to balance the supervised cross entropy and the unsupervised consistency training loss, which is illustrated in Figure \ref{fig:illustration}. Formally, the full objective can be written as follows:

where CE denotes cross entropy,  is a data augmentation transformation and  is a \textit{fixed} copy of the current parameters  indicating that the gradient is not propagated through , as suggested by VAT~\cite{miyato2018virtual}. 
We set  to  for most of our experiments. In practice, in each iteration, we compute the supervised loss on a mini-batch of labeled examples and compute the consistency loss on a mini-batch of unlabeled data. The two losses are then summed for the final loss. We use a larger batch size for the consistency loss. 

In the vision domain, simple augmentations including cropping and flipping are applied to labeled examples. To minimize the discrepancy between supervised training and prediction on unlabeled examples, we apply the same simple augmentations to unlabeled examples for computing .

\begin{figure}
\vspace{-3em}
    \centering
    \includegraphics[width=0.85\textwidth]{fig/uda.pdf}
    \caption{Training objective for \name, where M is a model that predicts a distribution of  given .}
    \label{fig:illustration}
\vspace{-1em}
\end{figure}


\textbf{Discussion.}
Before detailing the augmentation operations used in this work, we first provide some intuitions on how more advanced data augmentations can provide extra advantages over simple ones used in earlier works from three aspects: 
\begin{itemize}[leftmargin=*,itemsep=0em,topsep=0em]
\item \textbf{Valid noise}: Advanced data augmentation methods that achieve great performance in supervised learning usually generate realistic augmented examples that share the same ground-truth labels with the original example.
Thus, it is safe to encourage the consistency between predictions on the original unlabeled example and the augmented unlabeled examples.

\item \textbf{Diverse noise}: Advanced data augmentation can generate a diverse set of examples since it can make large modifications to the input example without changing its label, while simple Gaussian noise only make local changes. Encouraging consistency on a diverse set of augmented examples can significantly improve the sample efficiency. 

\item \textbf{Targeted inductive biases}: Different tasks require different inductive biases. Data augmentation operations that work well in supervised training essentially provides the missing inductive biases.
\end{itemize}

\vspace{-0.3em}
\subsection{Augmentation Strategies for Different Tasks} 
\vspace{-0.3em}
\label{sec:data_aug_for_task}
We now detail the augmentation methods, tailored for different tasks, that we use in this work.


\textbf{RandAugment for Image Classification.}
We use a data augmentation method called RandAugment~\cite{cubuk2019RandAugment}, which is inspired by AutoAugment~\cite{cubuk2018autoaugment}. AutoAugment uses a search method to combine all image processing transformations in the Python Image Library (PIL) to find a good augmentation strategy.
In RandAugment, we do not use search, but instead uniformly sample from the same set of augmentation transformations in PIL. In other words, RandAugment is simpler and requires no labeled data as there is no need to search for optimal policies.



\textbf{Back-translation for Text Classification.} 
When used as an augmentation method, back-translation~\cite{sennrich2015improving, edunov2018understanding} refers to the procedure of translating an existing example  in language  into another language  and then translating it back into  to obtain an augmented example .
As observed by \cite{yu2018qanet}, back-translation can generate diverse paraphrases while preserving the semantics of the original sentences, leading to significant performance improvements in question answering. 
In our case, we use back-translation to paraphrase the training data of our text classification tasks.\footnote{We also note that while translation uses a labeled dataset, the translation task itself is quite distinctive from a text classification task and does not make use of any text classification label. In addition, back-translation is a general data augmentation method that can be applied to many tasks with the same model checkpoints.}

We find that the diversity of the paraphrases is important. Hence, we employ random sampling with a tunable temperature instead of beam search for the generation. As shown in Figure \ref{fig:augmentation}, the paraphrases generated by back-translation sentence are diverse and have similar semantic meanings.
More specifically, we use WMT'14 English-French translation models (in both directions) to perform back-translation on each sentence.
To facilitate future research, we have open-sourced our back-translation system together with the translation checkpoints.



\begin{figure}[h]
\vspace{-0.7em}
    \centering
    \includegraphics[width=0.85\textwidth]{fig/augmentation.pdf}
    \caption{Augmented examples using back-translation and RandAugment. }
    \label{fig:augmentation}
\vspace{-0.7em}

\end{figure}

\textbf{Word replacing with TF-IDF for Text Classification.} While back-translation is good at maintaining the global semantics of a sentence, there is little control over which words will be retained. This requirement is important for topic classification tasks, such as DBPedia, in which some keywords are more informative than other words in determining the topic. We, therefore, propose an augmentation method that replaces uninformative words with low TF-IDF scores while keeping those with high TF-IDF values. We refer readers to Appendix \ref{sec:apdx_augmentations} for a detailed description.


\vspace{-0.3em}
\subsection{Additional Training Techniques}
\label{sec:apdx_training_technique}
\vspace{-0.3em}

In this section, we present additional techniques targeting at some commonly encountered problems.


\textbf{Confidence-based masking.} We find it to be helpful to mask out examples that the current model is not confident about. Specifically, in each minibatch, the consistency loss term is computed only on examples whose highest probability among classification categories is greater than a threshold . We set the threshold  to a high value. Specifically,  is set to 0.8 for CIFAR-10 and SVHN and 0.5 for ImageNet. 

\textbf{Sharpening Predictions.}
\label{sec:sharpending_predictions}
Since regularizing the predictions to have low entropy has been shown to be beneficial~\cite{grandvalet2005semi,miyato2018virtual}, we sharpen predictions when computing the target distribution on unlabeled examples by using a low Softmax temperature . 
When combined with confidence-based masking, the loss on unlabeled examples  on a minibatch  is computed as:


where  is the indicator function,  is the logit of label  for example . We set  to 0.4 for CIFAR-10, SVHN and ImageNet.


\textbf{Domain-relevance Data Filtering.} 
\label{sec:domain_relevance}
Ideally, we would like to make use of out-of-domain unlabeled data since it is usually much easier to collect, but the class distributions of out-of-domain data are mismatched with those of in-domain data, which can result in performance loss if directly used~\cite{oliver2018realistic}.
To obtain data relevant to the domain for the task at hand, we adopt a common technique for detecting out-of-domain data. 
We use our baseline model trained on the in-domain data to infer the labels of data in a large out-of-domain dataset and pick out examples that the model is most confident about. 
Specifically, for each category, we sort all examples based on the classified probabilities of being in that category and select the examples with the highest probabilities.


\vspace{-0.5em}
\section{Theoretical Analysis}
\vspace{-0.5em}
\label{sec:theory}
In this section, we theoretically analyze why \name can improve the performance of a model and the required number of labeled examples to achieve a certain error rate.
Following previous sections, we will use  to denote the perfect classifier that we hope to learn, use  to denote the marginal distribution of the unlabeled data and use  to denote the augmentation distribution.

To make the analysis tractable, we make the following simplistic assumptions about the data augmentation transformation: 
\begin{itemize}[leftmargin=*,itemsep=0em,topsep=0em]
    \item \textbf{In-domain} augmentation: data examples generated by data augmentation have non-zero probability under , i.e.,  for .
    \item \textbf{Label-preserving} augmentation: data augmentation preserves the label of the original example, i.e.,  for .
    \item \textbf{Reversible} augmentation: the data augmentation operation can be reversed, i.e., if  then  .
\end{itemize}

As the first step, we hope to provide an intuitive sketch of our formal analysis.
Let us define a graph  where each node corresponds to a data sample  and an edge  exists in the graph \textit{if and only if} . 
Due to the label-preserving assumption, it is easy to see that examples with different labels must reside on different components (disconnected sub-graphs) of the graph .
Hence, for an -category classification problems, the graph has   components (sub-graphs) when all examples within each category can be traversed by the augmentation operation.
Otherwise, the graph will have more than  components.

Given this construction, notice that for each component  of the graph, as long as there is a single labeled example in the component, i.e. , one can propagate the label of the node to the rest of the nodes in  by traversing   via the augmentation operation .
More importantly, if one only performs \textit{supervised data augmentation}, one can only propagate the label information to the directly connected neighbors of the labeled node.
In contrast, performing \textit{unsupervised data augmentation} ensures the traversal of the entire sub-graph .
This provides the first high-level intuition how \name could  help.


Taking one step further, in order to find a perfect classifier via such label propagation, it requires that there exists at least one labeled example in each component.
In other words, the number of components lower bounds the minimum amount of labeled examples needed to learn a perfect classifier.
Importantly, number of components is actually decided by the quality of the augmentation operation: an ideal augmentation should be able to reach all other examples of the same category given a starting instance.
This well matches our discussion of the benefits of state-of-the-art data augmentation methods in generating more diverse examples.
Effectively, the augmentation diversity leads to more neighbors for each node, and hence reduces the number of components in a graph. 

Since supervised data augmentation only propagates the label information to the directly connected neighbors of the labeled nodes.
Advanced data augmentation that has a high accuracy must lead to a graph where each node has more neighbors. Effectively, such a graph has more edges and better connectivity. Hence, it is also more likely that this graph will have a smaller number of components. 
To further illustrate this intuition, in Figure \ref{fig:alg_compare}, we provide a comparison between different algorithms.

\begin{figure}[ht]
\begin{subfigure}{.19\textwidth}
  \centering
  \includegraphics[width=0.8\linewidth]{fig/graph/sup}  
  \caption{Supervised learning. \
    Pr(\mathcal{A})= \sum_{i} P_i(1 - P_i)^m.

    m = O(k/\epsilon) \implies Pr(\mathcal{A}) = O(\epsilon).

    Pr(\mathcal{A})= \sum_{i} P_i(1 - P_i)^m.

    m = O(k/\epsilon) \implies Pr(\mathcal{A}) = O(\epsilon).
Pr(\mathcal{A})= \sum_{i} Pr(\mathcal{A}\mathrm{\ and\ }x' \in C_i)= \sum_{i} P_i(1 - P_i)^m
 \min_{P}& -\sum_{c_i} P_i(1 - P_i)^m   \\
 \mathrm{s.t.} & \sum_{c_i} P_i=1
\mathcal{L}=\sum_{i} P_i(1 - P_i)^m - \lambda (\sum_{i} P_i -1)\lambda=(1-mP_i) (1-P_i)^{m-1}P_i=\frac{1}{k}Pr(\mathcal{A})\leq (1-\frac{1}{k})^m=\exp(m\log(1-\frac{1}{k}))\leq \exp(-\frac{m}{k})Pr(\mathcal{A})=O(\epsilon)

\end{proof}





\section{Extended Related Work}
\label{sec:apdx_related_work}
\textbf{Semi-supervised Learning.} Due to the long history of semi-supervised learning (SSL), we refer readers to~\cite{chapelle2009semi} for a general review.
More recently, many efforts have been made to renovate classic ideas into deep neural instantiations.
For example, graph-based label propagation~\cite{zhu2003semi} has been extended to neural methods via graph embeddings~\cite{weston2012deep,yang2016revisiting} and later graph convolutions~\cite{kipf2016semi}.
Similarly, with the variational auto-encoding framework and reinforce algorithm, classic graphical models based SSL methods with target variable being latent can also take advantage of deep architectures~\cite{kingma2014semi,maaloe2016auxiliary,yang2017semi}.
Besides the direct extensions, it was found that training neural classifiers to classify out-of-domain examples into an additional class~\cite{salimans2016improved} works very well in practice.
Later, Dai et al.~\cite{dai2017good} shows that this can be seen as an instantiation of low-density separation. 

Apart from enforcing consistency on the noised input examples and the hidden representations, another line of research enforces consistency under different model parameters, which is complementary to our method. For example, Mean Teacher~\cite{tarvainen2017mean} maintains a teacher model with parameters being the ensemble of a student model's parameters and enforces the consistency between the predictions of the two models. Recently, fast-SWA~\cite{athiwaratkun2018there} improves Mean Teacher by encouraging the model to explore a diverse set of plausible parameters. In addition to parameter-level consistency, SNTG~\cite{luo2018smooth} also enforces input-level consistency by constructing a similarity graph between unlabeled examples.

\textbf{Data Augmentation.} Also related to our work is the field of data augmentation research.
Besides the conventional approaches and two data augmentation methods mentioned in Section \ref{sec:sda}, a recent approach MixUp~\cite{zhang2017mixup} goes beyond data augmentation from a single data point and performs interpolation of data pairs to achieve augmentation. Recently,  it has been shown that data augmentation can be regarded as a kind of explicit regularization methods similar to Dropout~\cite{hernandez2018data}. 

\textbf{Diverse Back Translation.} Diverse paraphrases generated by back-translation has been a key component in the significant performance improvements in our text classification experiments. We use random sampling instead of beam search for decoding similar to \cite{edunov2018understanding}. There are also recent works on generating diverse translations~\cite{he2018sequence, shen2019mixture, kool2019stochastic} that might lead to further improvements when used as data augmentations.


\textbf{Unsupervised Representation Learning.} Apart from semi-supervised learning, unsupervised representation learning offers another way to utilize unsupervised data. 
Collobert and Weston \cite{collobert2008unified} demonstrated that word embeddings learned by language modeling can improve the performance significantly on semantic role labeling.
Later, the pre-training of word embeddings was simplified and substantially scaled in Word2Vec~\cite{mikolov2013distributed} and Glove~\cite{pennington2014glove}.
More recently,  pre-training using language modeling and denoising auto-encoding has been shown to lead to significant improvements on many tasks in the language domain~\cite{dai2015semi,peters2018deep, radford2018improving,howard2018universal,devlin2018bert}. There is also a growing interest in self-supervised learning for vision~\cite{zhai2019s, henaff2019data, trinh2019selfie}.  

\textbf{Consistency Training in Other Domains.} Similar ideas of consistency training has also been applied in other domains. For example, recently, enforcing adversarial consistency on unsupervised data has also been shown to be helpful in adversarial robustness~\cite{stanforth2019labels,  zhai2019adversarially, najafi2019robustness, carmon2019unlabeled}.
Enforcing consistency w.r.t data augmentation has also been shown to work well for representation learning~\cite{hu2017learning, ye2019unsupervised}. Invariant representation learning ~\cite{liang2018learning,Salazar2018Invariant} applies the consistency loss not only to the predicted distributions but also to representations and has been shown significant improvements on speech recognition. 



\section{Experiment Details}
\label{sec:exp_details}
\subsection{Text Classifications}
\textbf{Datasets.} In our semi-supervised setting, we randomly sampled labeled examples from the full supervised set\footnote{\url{http://bit.ly/2kRWoof}, \  \url{https://ai.stanford.edu/~amaas/data/sentiment/}} and use the same number of examples for each category. For unlabeled data, we use the whole training set for DBPedia, the concatenation of the training set and the unlabeled set for IMDb and  external data for Yelp-2, Yelp-5, Amazon-2 and Amazon-5 \cite{mcauley2015image}\footnote{\url{https://www.kaggle.com/yelp-dataset/yelp-dataset}, \url{http://jmcauley.ucsd.edu/data/amazon/}}. Note that for Yelp and Amazon based datasets, the label distribution of the unlabeled set might not match with that of labeled datasets since there are different number of examples in different categories. Nevertheless, we find it works well to use all the unlabeled data.


 
\textbf{Preprocessing.} 
We find the sequence length to be an important factor in achieving good performance. For all text classification datasets, we truncate the input to 512 subwords since BERT is pretrained with a maximum sequence length of 512.  Further, when the length of an example is greater than 512, we keep the last 512 subwords instead of the first 512 subwords as keeping the latter part of the sentence lead to better performances on IMDb. 


\textbf{Fine-tuning BERT on in-domain unsupervised data.} We fine-tune the BERT model on in-domain unsupervised data using the code released by BERT. We try learning rate of 2e-5, 5e-5 and 1e-4, batch size of 32, 64 and 128 and number of training steps of 30k, 100k and 300k. We pick the fine-tuned models by the BERT loss on a held-out set instead of the performance on a downstream task. 

\textbf{Random initialized Transformer.} For the experiments with randomly initialized Transformer, we adopt hyperparameters for BERT base except that we only use 6 hidden layers and 8 attention heads. We also increase the dropout rate on the attention and the hidden states to 0.2, When we train UDA with randomly initialized architectures, we train UDA for 500k or 1M steps on Amazon-5 and Yelp-5 where we have abundant unlabeled data.

\textbf{BERT hyperparameters.} Following the common BERT fine-tuning procedure, we keep a dropout rate of 0.1, and try learning rate of 1e-5, 2e-5 and 5e-5 and batch size of 32 and 128. We also tune the number of steps ranging from 30 to 100k for various data sizes.

\textbf{UDA hyperparameters.} We set the weight on the unsupervised objective  to 1 in all of our experiments. We use a batch size of 32 for the supervised objective since 32 is the smallest batch size on v3-32 Cloud TPU Pod. We use a batch size of 224 for the unsupervised objective when the Transformer is initialized with BERT so that the model can be trained on more unlabeled data. We find that generating one augmented example for each unlabeled example is enough for \bertft. 


All experiments in this part are performed on a v3-32 Cloud TPU Pod. 


\subsection{Semi-supervised learning benchmarks CIFAR-10 and SVHN}   
\textbf{Hyperparameters for Wide-ResNet-28-2.} 
We train our model for 500K steps. We apply Exponential Moving Average to the parameters with a decay rate of 0.9999. We use a batch size of 64 for labeled data and a batch size of 448 for unlabeled data. The softmax temperature  is set to 0.4. The confidence threshold  is set to 0.8. We use a cosine learning rate decay schedule:  where  is the current step and  is the total number of steps. We use a SGD optimizer with nesterov momentum with the momentum hyperparameter set to 0.9. 
In order to reduce training time, we generate augmented examples before training and dump them to disk. For CIFAR-10, we generate 100 augmented examples for each unlabeled example. Note that generating augmented examples in an online fashion is always better or as good as using dumped augmented examples since the model can see different augmented examples in different epochs, leading to more diverse samples. We report the average performance and the standard deviation for 10 runs.
Experiments in this part are performed on a Tesla V100 GPU. 


\textbf{Hyperparameters for Shake-Shake and PyramidNet.} For the experiments with Shake-Shake, we train UDA for 300k steps and use a batch size of 128 for the supervised objective and use a batch size of 512 for the unsuperivsed objective. For the experiments with PyramidNet+ShakeDrop, we train UDA for 700k steps and use a batch size of 64 for the supervised objective and a batch size of 128 for the unsupervised objective. For both models, we use a learning rate of 0.03 and use a cosine learning decay with one annealing cycle following AutoAugment. Experiments in this part are performed on a v3-32 Cloud TPU v3 Pod. 

\subsection{ImageNet} 

\textbf{10\% Labeled Set Setting.} Unless otherwise stated, we follow the standard hyperparameters used in an open-source implementation of ResNet.\footnote{https://github.com/tensorflow/tpu/tree/master/models/official/resnet} 
For the 10\% labeled set setting, we use a batch size of 512 for the supervised objective and a batch size of 15,360 for the unsupervised objective. We use a base learning rate of 0.3 that is decayed by 10 for four times and set the weight on the unsupervised objective  to 20. We mask out unlabeled examples whose highest probabilities across categories are less than 0.5 and set the Softmax temperature to 0.4. The model is trained for 40k steps. Experiments in this part are performed on a v3-64 Cloud TPU v3 Pod. 

\textbf{Full Labeled Set Setting.} For experiments on the full ImageNet, we use a batch size of 8,192 for the supervised objective and a batch size of 16,384 for the unsupervised objective. The weight on the unsupervised objective  is set to 1. 
We use entropy minimization to sharpen the prediction.
We use a base learning rate of 1.6 and decay it by 10 for four times. Experiments in this part are performed on a v3-128 Cloud TPU v3 Pod.











\newpage



%
 


\end{document}
