\newif\ifSODA
\SODAfalse

\ifSODA
\documentclass[twoside,leqno,twocolumn]{article}  
\usepackage{ltexpprt} \else
\documentclass[11pt]{article}  
\usepackage{fullpage,amsthm}
\fi

\usepackage
{
        amssymb,
        amsmath,
        tikz,
        pgfplots,
}

\usepackage{graphicx}




\ifSODA
\makeatletter\def\@endproof{\hfill\vbox{\hrule height.2pt\hbox{\vrule width.2pt height5pt \kern5pt \vrule width.2pt} \hrule height.2pt}\outerparskip 0pt\endtrivlist}
\def\paragraph{\@startsection  
 {paragraph}{4}{\parindent}{5pt}{-5pt}{\normalsize\bf}}
\makeatother
\newcommand {\texorpdfstring} [2] {{#1}}
\else
\pdfoptionpdfminorversion=5
\usepackage[unicode,colorlinks=true,citecolor=black,filecolor=black,linkcolor=black,urlcolor=black,pdfpagelabels,plainpages=false]{hyperref}
\usepackage{bookmark}
\fi

\def\compactify{\itemsep=0pt \topsep=0pt \partopsep=0pt \parsep=0pt}

\def\clap#1{\hbox to 0pt{\hss#1\hss}}
\def\mathllap{\mathpalette\mathllapinternal}
\def\mathrlap{\mathpalette\mathrlapinternal}
\def\mathclap{\mathpalette\mathclapinternal}
\def\mathllapinternal#1#2{\llap{}}
\def\mathrlapinternal#1#2{\rlap{}}
\def\mathclapinternal#1#2{\clap{}}

\newcommand{\OO}{\mathcal{O}}



\newcommand {\compactMath}[1]{}


\DeclareMathOperator {\diam}  {diam}
\DeclareMathOperator {\reverse}  {reverse}
\DeclareMathOperator {\rank}  {rank}
\DeclareMathOperator {\vol}  {vol}
\DeclareMathOperator {\dem}  {dem}
\DeclareMathOperator {\spn}  {span}
\DeclareMathOperator {\sgn}  {sgn}
\DeclareMathOperator {\conv} {conv}
\DeclareMathOperator {\Var}  {Var}
\DeclareMathOperator {\cov}  {cov}


\newcommand {\nc}  {\frac{1}{\sqrt{2\pi}}}
\newcommand {\ncc} [2]  {\frac{#1}{\sqrt{2\pi} #2}}
\newcommand {\roundup}   [1] {{\lceil {#1} \rceil}}
\newcommand {\rounddown} [1] {{\lfloor {#1} \rfloor}}

\newcommand {\set}   [1] {\left\{ #1 \right\}}
\newcommand {\brc}   [1] {\left(#1\right)}

\newcommand {\Exp}       {\mathbb{E}}
\newcommand {\Prob}  [1] {\Pr \brc{#1 }}
\newcommand {\Probb} [2] {\Pr_{#1} \brc{#2 }}
\newcommand {\E}     [1] {\Exp\left[#1\right]}
\newcommand {\EE}    [2] {\Exp_{#1}\left[#2\right]}
\newcommand {\Varr}  [1] {\Var \left[#1\right]}
\newcommand {\iprod} [2] {\langle #1, #2 \rangle}
\newcommand {\Iprod} [2] {\left\langle #1, #2 \right\rangle}
\newcommand {\tprod} [2] {{#1 \otimes #2}}
\newcommand{\given}{\mid}




\newcommand {\bbN}    {\mathbb{N}}
\newcommand {\bbZ}    {\mathbb{Z}}
\newcommand {\bbB}    {\mathbb{B}}
\newcommand {\bbR}    {\mathbb{R}}
\newcommand {\bbC}    {\mathbb{C}}
\newcommand {\calD}   {{\cal{D}}}
\newcommand {\calW}   {{\cal{W}}}
\newcommand {\calE}   {{\cal{E}}}
\newcommand {\calS}   {{\cal{S}}}
\newcommand {\calH}   {{\cal{H}}}
\newcommand {\calN}   {{\cal{N}}}
\newcommand {\calP}   {{\cal{P}}}
\newcommand {\calF}   {{\cal{F}}}
\newcommand {\calZ}   {{\cal{Z}}}
\newcommand {\calU}   {{\cal{U}}}

\newcommand {\calA}   {{\cal{A}}}
\newcommand {\calB}   {{\cal{B}}}
\newcommand {\calL}   {{\cal{L}}}

\newcommand {\NP}   {{\cal{NP}}}



\newcommand{\OpenFrame}{\rule{0pt}{12pt} \hrule height 0.8pt \rule{0pt}{1pt} \hrule height 0.4pt \rule{0pt}{6pt}}
\newcommand{\CloseFrame}{\rule{0pt}{1pt}\hrule height 0.4pt \rule{0pt}{1pt} \hrule height 0.8pt \rule{0pt}{12pt}}





\newcommand {\TODO}[1] {\footnote{TODO: #1}}


\newcommand {\normu}   {\tilde{u}}
\newcommand {\normv}   {\tilde{v}}


\newcommand {\Ui}      {{u_i}}

\newcommand {\ONE}      {\text{\textbf{1}}}
\newcommand {\VOne}     {v_\text{\textbf{1}}}
\newcommand {\VPerp}    {v_\text{\textbf{}}}
\newcommand {\tensor}   {\otimes}
\newcommand {\ptensor}  {\mathbin{\hat\otimes}}
\newcommand {\indicator} {{\text{\small{\textbf{1}}}}}

\DeclareMathOperator {\Ball}{Ball}
\DeclareMathOperator {\srcost}{sr-cost}
\DeclareMathOperator {\sdpcost}{sdp-cost}
\DeclareMathOperator {\SDP}{SDP}
\DeclareMathOperator {\cost}{cost}
\DeclareMathOperator {\cut}{cut}
\DeclareMathOperator {\width}{width}
\DeclareMathOperator {\optcost}{opt-cost}
\DeclareMathOperator {\plantedcost}{planted-cost}





\ifSODA\else
\newtheorem{theorem}{Theorem}[section]
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{proposition}[theorem]{Proposition}
\newtheorem{corollary}[theorem]{Corollary}
\newtheorem{Definition}[theorem]{Definition}
\newtheorem{observation}[theorem]{Observation}
\newtheorem{fact}[theorem]{Fact}
\newtheorem{property}{Property}
\newtheorem{notation}{Notation}[section]
\newtheorem{example}{Example}[section]
\newtheorem{algorithm}{Algorithm}
\newtheorem{conjecture}{Conjecture}
\newtheorem{question}[conjecture]{Question}

\newtheorem*{question*}{Question}
\newtheorem*{definition*}{Definition}
\newtheorem*{itheorem}{Informal Theorem}
\fi

\newtheorem{claim}{Claim}[section]
\newtheorem{remark}{Remark}[section]


\newcommand{\textproblem}[1]{{#1}} \newcommand{\fas}{\textproblem{FAS}\xspace}
\newcommand{\flipedge}{Random Edge Flipping\xspace}
\newcommand{\backedge}{Random Backward Edge\xspace}
\newcommand{\eps}{\varepsilon}


\newcommand{\maxcut}{\textsc{Max Cut}~}
\newcommand{\N}{N}




\title{Bilu--Linial Stable Instances of Max Cut and Minimum Multiway Cut}
\author{Konstantin Makarychev\\Microsoft Research
\and Yury Makarychev\thanks{Supported by NSF CAREER award CCF-1150062 and NSF grant IIS-1302662. 
Work done in part while visiting Microsoft Research.}\\TTIC
\and Aravindan Vijayaraghavan\thanks{Supported by the Simons Postdoctoral Fellowship. Work done in part while visiting Microsoft Research.}\\CMU}
\date{}
\begin{document}
\maketitle
\begin{abstract}
We investigate the notion of stability proposed by Bilu and Linial. We obtain an \textit{exact} polynomial-time  algorithm for
-stable Max Cut instances with  for some absolute constant . 
Our algorithm is robust: it never returns an incorrect answer;
if the instance is -stable, it finds the maximum cut, otherwise, it either finds the maximum cut or certifies that the instance is not -stable. We prove that there is no \textit{robust} polynomial-time algorithm for -stable instances of Max Cut
when , where  is the best approximation factor for Sparsest Cut with non-uniform demands. That suggests that solving -stable instances with  might be difficult or even impossible.

Our algorithm is based on semidefinite programming. We show that the standard SDP relaxation for Max Cut 
(with  triangle inequalities) is integral if 
, where  is the least distortion with which every  point metric space of negative type embeds into . On the negative side, we show that the SDP relaxation is not integral when .
Moreover, there is no tractable convex relaxation for -stable instances of Max Cut
when . 

Our results significantly improve previously known results. The best previously known algorithm for -stable instances of Max Cut 
required that  (for some )  [Bilu, Daniely, Linial, and Saks]. No hardness results were known for the problem.

Additionally, we present an exact robust polynomial-time algorithm for -stable instances of Minimum Multiway Cut.

We also study a relaxed notion of \textit{weak stability} and present algorithms for weakly stable instances of Max Cut and Minimum Multiway Cut.
\end{abstract}

\ifSODA\else
\setcounter{page}{0}
\thispagestyle{empty} \pagebreak
\fi


\section{Introduction} \label{sec:intro}
Empirical evidence suggests that many discrete optimization problems like clustering and partitioning
are much easier in practice than in the worst case. Even though these problems are usually provably 
hard in the worst case, we can still try to design algorithms that 
work well on instances that we encounter in practice. To do so, we need a good mathematical model 
for such instances. 

There are several approaches to modeling real-life instances. Perhaps, a more classical approach dating back
to early 1980's is to assume that real-life instances come from a random or ``semi-random'' distribution~\cite{BS,FKra,FK,KMM,MMV1,MMV2}. To learn more about this approach,
we refer the interested reader to our previous work~\cite{MMV1} on semi-random instances of graph partitioning and references therein.
An alternative approach, which we study here, is to identify certain structural properties that
``interesting'' instances (or ``practically interesting instances''~\cite{BDLS}) must satisfy, and then assume that instances arising in practice 
satisfy them. One such
property was proposed by Bilu and Linial~\cite{BL}.

Bilu and Linial~\cite{BL} introduced a notion of {\em stability of instances} for discrete optimization problems. They argue that interesting instances have stable solutions: the optimal solution does not change upon small perturbations. For example, a clustering instance that is meaningful should have a solution that stands out. This solution should remain optimal even if the edge weights are slightly inaccurate or noisy.
As Balcan, Blum and Gupta~\cite{BBG} argue, the real goal of solving a clustering problem is often to obtain the correct ``target''
clustering, and so the objective function serves only as a proxy. In this case, if the edge weights, which may be rough estimates of how similar or dissimilar the endpoints are, are imprecise, then the solution is meaningful only when the instance is stable. 
Here is a formal definition of -stability~\cite{BL}.

\begin{Definition}[-Stability~\cite{BL}]
Consider an instance of a graph optimization problem on  vertices, defined by the matrix of non-negative edge weights . We say that the instance is -stable if there is an optimal solution which remains optimal, even when any subset of the edge weights are increased by a factor of at most . 
\end{Definition} 

We note that prior to work of Bilu and Linial~\cite{BL}, Balcan, Blum and Gupta~\cite{BBG} introduced and studied a somewhat 
similar but different notion of \textit{approximation--stability} for clustering problems like -means and -median;
later Awasthi, Blum and Sheffet~\cite{Awasthietal}, Balcan and Liang~\cite{BalcanL}, and Reyzin~\cite{Rey} studied a related notion of \textit{perturbation resilience} for these center--based clustering problems.
 


We study stable instances of Max Cut and Minimum Multiway Cut, and propose a general technique for solving 
stable instances of graph partitioning problems (see Section~\ref{sec:Discussion}). However, to be more specific,
we focus  our exposition on Max Cut --- the problem that was previously studied by Bilu and Linial~\cite{BL} and Bilu, Daniely, Linial, and Saks~\cite{BDLS}.
In Max Cut, we are given a weighted graph  on  vertices with an adjacency matrix . Our goal is to find a cut  in the graph with the maximum weight of edges crossing it

Max Cut is one of the classic NP-hard problems~\cite{GJ}. It is NP-hard to approximate within a factor of  \cite{Hastad,TSSW}.
Goemans and Williamson~\cite{GW} gave a semidefinite programming based algorithm that achieves a  approximation ratio for Max Cut. Khot, Kindler, Mossel and O'Donnell~\cite{KKMO} showed that this is the best possible approximation ratio in the worst-case, assuming the Unique Games Conjecture \cite{Khot}.

In the work that introduced -stability, Bilu and Linial~\cite{BL} designed an algorithm for -stable instances of Max Cut with  (for some absolute constant ). The aim of 
the algorithm is to find the exact optimal solution. This solution is unique (because of stability) and corresponds to the ``true'' partitioning we want to find. Finding just a good approximation for -stable instances of Max Cut is easy, 
since -stable instances of Max Cut are almost bipartite, and for almost bipartite graphs, the algorithm of Goemans and Williamson~\cite{GW} 
returns a solution in which almost all edges are cut (see~\cite{BL} for more details). Bilu, Daniely, Linial, and Saks~\cite{BDLS} gave an algorithm for -stable Max Cut instances with  (for some absolute constant ). Both papers also gave better algorithms for
stable instances that satisfy some extra conditions (see~\cite{BL} and~\cite{BDLS}). 
 
\paragraph{Our Results.} In this work, we give an algorithm that solves -stable instances of Max Cut with  (for some absolute constant ). We also study the classic partitioning problem of finding the Minimum Multiway Cut (see Section~\ref{sec:muliway} for the definition) and give an algorithm for -stable instances of it, with . 
Our result for Max Cut is an
exponential improvement over previous results. Our algorithms are {\em robust} (in the notion of 
Raghavan and Spinrad~\cite{RS}):
\begin{enumerate}
\item If the instance is -stable, the algorithm finds the unique optimal solution.
\item If the instance is not -stable, the algorithm either finds an optimal solution, or a (polynomial-time verifiable) certificate that proves that the instance is not -stable. 
\end{enumerate}   
In other words, our algorithm is always correct: when we claim to output the maximum cut (minimum multiway cut), 
we can guarantee its optimality; else we identify that the given graph is not sufficiently stable. This is a very desirable property for algorithms we want to use in practice,
since we may only assume that real-life or important instances are stable (or satisfy other properties), but we cannot be 
completely certain that they indeed are. When we use robust algorithms, we cannot get a suboptimal solution even if our assumptions are not quite correct.
Note that previous algorithms for stable instances of Max Cut~\cite{BL,BDLS}, and Clustering~\cite{BBG,BalcanL,Awasthietal} are not robust. That is, if the instance is not -stable, the previous algorithms can output a suboptimal solution without notifying us that the 
solution is suboptimal.

Our algorithms use that our SDP and LP relaxations for Max Cut and Minimum Multiway Cut, respectively, are integral
when  is sufficiently large. 
For Max Cut, we prove that the standard SDP relaxation with triangle inequalities is integral for -stable instances.
We remark that we are unaware of other natural settings when the semidefinite program becomes integral and the corresponding linear program does not! 

We also present algorithms that work for the same values of  with a more relaxed notion of stability 
which we call {\em weak stability}.
The optimal solution of every perturbed instance of a weakly stable instance, is close to the optimal solution
of the original instance, but may not be exactly the same (see Section~\ref{sec:weakstability} for details). We believe that -weak stability may be a more realistic assumption than -stability in practice. Bilu and Linial~\cite{BL} mentioned weakly stable instances in the introduction to their paper (without formally defining them), and proposed to study them in the future.
Our algorithms for -weakly stable instances are not robust.


Our result for weakly stable instances of Max Cut uses an approximation algorithm for Sparsest Cut with non-uniform demands
as a black box. In particular, the result implies that if there is an -approximation algorithm for Sparsest Cut (which finds approximately not only the value but also a solution to Sparsest Cut) 
then there is an exact algorithm for -stable instances of Max Cut. (For simplicity of exposition,
 is fixed in our proof; in general,  can be sub-constant, the running time
is proportional to .)

Finally, we present a general approach to solving stable instances of graph partitioning problems.

\paragraph{Negative Results.} We supplement our algorithmic results, by showing that any robust algorithm for Max Cut that works for better values of  would result in a similar improvement in the worst-case approximation for non-uniform Sparsest Cut. Moreover, we also show that the SDP is not integral if  (where  is the least distortion with which every -point  space can be embedded into ). While our algorithmic results give algorithms for sufficiently stable instances, our reduction from non-uniform Sparsest Cut suggests that it may be hard to obtain robust algorithms for Max Cut that work for -stable instances. 
Finally, we describe a very strong negative result for the Max -Cut problem when .
We show that for every function  there is no exact polynomial-time algorithm for -stable instances of the problem
unless .

We note that our positive results for Max Cut also apply to the problem of clustering points into two clusters (or, equivalently, to Max Cut
with positive and negative weights). Our negative result for Max -Cut, on the other hand, shows that there is no exact algorithm for
the problem of clustering points into  clusters when  unless  (see Appendix~\ref{sec:corrclust} for details). 

\subsection{Overview of Techniques}

The main technical component of our work is showing that the standard SDP relaxation with triangle inequalities
is {\em integral} for -stable instances of Max Cut, when , where
 is the least distortion with which every -point  space can be embedded into .
Hence, when the instance is -stable (for sufficiently large ), we can read off the optimal solution from the SDP; otherwise, the non-integrality of the SDP certifies that the instance is not -stable. This gives a {\em robust} algorithm for instances with .

Loosely speaking, we prove that if the SDP solution is not integral, then the integral optimal solution can be improved,
possibly after changing the weights of some \ifSODA\linebreak \newpage\noindent\fi edges.
Given the SDP solution  (a vector  for each vertex ) and the optimal integral solution ,
we define a new configuration of vectors : we keep  if ; and replace 
with  if . If  is the integral solution corresponding to ,
then all vectors  are equal. Otherwise, if the SDP is not integral, \textit{not all vectors  are equal}. Then we embed 
these vectors into , and obtain a distribution
of cuts . It turns, out that if the distortion of the embedding was 1, then we would be able to 
improve the quality of the optimal solution by picking a random cut  and moving vertices in  to  and vertices in  to 
(see Figure~\ref{fig:cuts}). Of course, the distortion may be much larger than 1. Then, we show how to compensate
for this distortion using the -stability.
We can first change the weights of some edges by a factor at most , and only then 
move the vertices to improve the quality of the solution. Hence, we get a contradiction if .

Our algorithm for weakly stable instances starts with an approximate solution and then iteratively improves the quality of the solution 
using the algorithm for non-uniform Sparsest Cut by Arora, Lee, and Naor~\cite{ALN} as a subroutine.

\subsection{Outline}
In Section~\ref{sec:prelims}, we introduce the formal definitions of stability and some preliminaries including the semidefinite program (SDP) we use in our algorithm. Then, in Section~\ref{sec:robustalgo}, we describe our robust algorithm for -stable instances of Max Cut. 
In Section~\ref{sec:negative}, we present evidence suggesting that obtaining algorithms for better values of  may not be easy. We first give a reduction from non-uniform Sparsest Cut (in Section~\ref{sec:hardness}), which shows that any robust algorithm with better guarantees would lead to a similar improvement for non-uniform Sparsest Cut. Then we show in Section~\ref{sec:intgap} that the SDP is not integral for smaller values of . 
In Section~\ref{sec:muliway}, we present our algorithm for -stable instances of Minimum Multiway Cut.
In Section~\ref{sec:weakstability}, we introduce a more general notion of weak stability and obtain similar guarantees in
this setting. 


We describe our results for Max -Cut and Correlation Clustering
in Sections~\ref{sec:max-k-cut} and Appendix~\ref{sec:corrclust}, respectively.
Finally, we outline a general approach for solving stable instances of graph partitioning problems in Section~\ref{sec:Discussion}. 
 

\section{Preliminaries}\label{sec:prelims}
We start with formally defining the notion of Bilu--Linial stability for Max Cut instances. Following~\cite{BL}, we give two equivalent
definitions (see Proposition 2.1 in~\cite{BL}).

\ifSODA
\pagebreak
\fi

\begin{Definition}[Bilu and Linial~\cite{BL}]\label{def:stability1}
\ifSODA \ \w(u,v) \leq w'(u,v) \leq \gamma \cdot w(u,v).w(E(S, \bar S)\setminus E(T, \bar T)) > \gamma\cdot w(E(T, \bar T )\setminus E(S, \bar S)).
\text{maximize }& \frac{1}{4} \sum_{(u,v)\in E} w_{uv} \|\bar u - \bar v\|^2\\
\text{subject to:}& \ifSODA\text{ for every } u,v,w\in V\fi\\
& \|\bar u\|^2 = 1 \ifSODA\else\quad \text{for every } u\in V,\fi\\
&\|\bar u-\bar v\|^2 + \|\bar v-\bar w\|^2 \geq \|\bar u-\bar w\|^2 \ifSODA\else\quad
  \text{for every } u,v,w\in V,\fi\\
&\|\bar u-\bar v\|^2 + \|\bar v+\bar w\|^2 \geq \|\bar u+\bar w\|^2 \ifSODA\else\quad
  \text{for every } u,v,w\in V,\fi\\
&\|\bar u+\bar v\|^2 + \|\bar v+\bar w\|^2 \geq \|\bar u-\bar w\|^2 \ifSODA\else\quad
  \text{for every } u,v,w\in V\fi.
\|\varphi\|_{Lip} = \sup_{\substack{x, y \in X \\ x\neq y}} \frac{d_Y(\varphi(x),\varphi(y))}{d_X(x,y)}.d(u,v) + d(v,w) \geq d(u,w) \quad\text{for every } u,v,w \in X.
\sigma \cdot{} & \Prob{(x,y) \text{ is separated by } (A,\bar A)} \leq 
\|x-y\|^2 \leq \\
&\sigma \cdot D_{\ell_2^2\to \ell_1}(n) \cdot \Prob{(x,y) \text{ is separated by } (A,\bar A)}.
\sigma \cdot \Prob{(x,y) \text{ is separated by } (A,\bar A)} \leq \|x-y\|^2 \leq \sigma \cdot D_{\ell_2^2\to \ell_1}(n) \cdot \Prob{(x,y) \text{ is separated by } (A,\bar A)}.\phi(A) = \frac{\mathrm{cap}(E_c(A,\bar A))}{\mathrm{dem}(E_d(A,\bar A))},
\label{ineq:sdp-is-relaxation}
\frac{1}{4} \sum_{(u,v)\in E} w_{uv} \|\bar u - \bar v\|^2 \geq w(E(S,\bar S)).
\hat u=
\begin{cases}
\bar u, &\text{if } u\in S,\\
-\bar u, &\text{if } u\notin S.
\end{cases}
\|\bar u - \bar v\|^2 = 2 - 2 \langle \bar u , \bar v\rangle = 2 + 2 \langle \hat u , \hat v \rangle = 4 - \|\hat u - \hat v\|^2;
\frac{1}{4} & \sum_{(u,v)\in E} w_{uv} \|\bar u - \bar v\|^2 = 
\frac{1}{4} \sum_{(u,v)\in E(S,\bar S)} w_{uv} \|\bar u - \bar v\|^2 \\
&\qquad{}+ \frac{1}{4} \sum_{(u,v)\in E\setminus E(S,\bar S)} w_{uv} \|\bar u - \bar v\|^2\\
&= \frac{1}{4} \sum_{(u,v)\in E(S,\bar S)} w_{uv} (4 - \|\hat u - \hat v\|^2) \\
&\qquad{}+ \frac{1}{4} \sum_{(u,v)\in E\setminus E(S,\bar S)} w_{uv} \|\hat u - \hat v\|^2\\
&= w(E(S,\bar S)) + \frac{1}{4}  \sum_{(u,v)\in E \setminus E(S,\bar S)} w_{uv} \|\hat u - \hat v\|^2\\
&\qquad   {}- \frac{1}{4}  \sum_{(u,v)\in E(S,\bar S)} w_{uv} \|\hat u - \hat v\|^2.

\frac{1}{4} \sum_{(u,v)\in E} w_{uv} \|\bar u - \bar v\|^2 &= 
\frac{1}{4} \sum_{(u,v)\in E(S,\bar S)} w_{uv} \|\bar u - \bar v\|^2 + \frac{1}{4} \sum_{(u,v)\in E\setminus E(S,\bar S)} w_{uv} \|\bar u - \bar v\|^2\\
&= \frac{1}{4} \sum_{(u,v)\in E(S,\bar S)} w_{uv} (4 - \|\hat u - \hat v\|^2) + \frac{1}{4} \sum_{(u,v)\in E\setminus E(S,\bar S)} w_{uv} \|\hat u - \hat v\|^2\\
&= w(E(S,\bar S)) + \frac{1}{4}  \sum_{(u,v)\in E \setminus E(S,\bar S)} w_{uv} \|\hat u - \hat v\|^2
   - \frac{1}{4}  \sum_{(u,v)\in E(S,\bar S)} w_{uv} \|\hat u - \hat v\|^2.

\sum_{(u,v)\in E(S,\bar S)} w_{uv} \|\hat u - \hat v\|^2
\leq
\sum_{(u,v)\in E \setminus E(S,\bar S)} w_{uv} \|\hat u - \hat v\|^2
.
\sigma & \Prob{\text{pair }(\hat u,\hat v) \text{ is separated by } (A,\bar A)} \leq \|\hat u -\hat v\|^2 \\
&\leq
\sigma  D_{\ell_2^2\to \ell_1}(n)  \Prob{\text{pair }(\hat u,\hat v) \text{ is separated by } (A,\bar A)}.

\sigma \cdot \Prob{\text{pair }(\hat u,\hat v) \text{ is separated by } (A,\bar A)} \leq \|\hat u -\hat v\|^2 \\
\leq
\sigma \cdot D_{\ell_2^2\to \ell_1}(n) \cdot \Prob{\text{pair }(\hat u,\hat v) \text{ is separated by } (A,\bar A)}.

&\sum_{(u,v)\in E(S,\bar S)} w_{uv} \sigma \Prob{(u, v) \in E(A',\bar A')} \\
&{}\leq
\sum_{(u,v)\in E(S,\bar S)} w_{uv} \|\hat u - \hat v\|^2
\leq
\sum_{(u,v)\in E\setminus E(S,\bar S)} w_{uv} \|\hat u - \hat v\|^2 \\
&{}\leq \sum_{(u,v)\in E\setminus E(S,\bar S)} w_{uv} \sigma D_{\ell_2^2\to \ell_1}(n) \Prob{(u, v) \in (A',\bar A')}.

\sum_{(u,v)\in E(S,\bar S)} w_{uv} & \sigma \Prob{(u, v) \in E(A',\bar A')} 
\leq
\sum_{(u,v)\in E(S,\bar S)} w_{uv} \|\hat u - \hat v\|^2\\
&\leq
\sum_{(u,v)\in E\setminus E(S,\bar S)} w_{uv} \|\hat u - \hat v\|^2 \\
&\leq \sum_{(u,v)\in E\setminus E(S,\bar S)} w_{uv} \sigma D_{\ell_2^2\to \ell_1}(n) \Prob{(u, v) \in (A',\bar A')}.

\E{w(E(S,\bar S) \cap E(A',\bar A'))} \\ \leq D_{\ell_2^2\to \ell_1}(n) \cdot \E{w((E\setminus E(S,\bar S)) \cap E(A',\bar A'))}.
\E{w(E(S,\bar S) \cap E(A',\bar A'))} \leq D_{\ell_2^2\to \ell_1}(n) \cdot \E{w((E\setminus E(S,\bar S)) \cap E(A',\bar A'))}.
w&(E(S,\bar S) \cap E(A'',\bar A'')) \\
&\leq D_{\ell_2^2\to \ell_1}(n) \cdot w((E\setminus E(S,\bar S)) \cap E(A'',\bar A''))\\
&\leq \gamma \cdot w((E\setminus E(S,\bar S)) \cap E(A'',\bar A'')).

w(E(S,\bar S) \cap E(A'',\bar A'')) &\leq D_{\ell_2^2\to \ell_1}(n) \cdot w((E\setminus E(S,\bar S)) \cap E(A'',\bar A''))\\
&\leq \gamma \cdot w((E\setminus E(S,\bar S)) \cap E(A'',\bar A'')).

E(S,\bar S)  & {}\cap E(A'',\bar A'') \\
&= E(S\cap A'', \bar S \cap \bar A'') \cup E(S\cap \bar A'', \bar S \cap A'')\\
&=E(S\cap T, \bar S \cap T) \cup E(S\cap \bar T, \bar S \cap \bar T)\\
&= E(S, \bar S) \setminus E(T, \bar T),\\
\intertext{and}
\mathrlap{(E\setminus E(S,\bar S)) \cap E(A'',\bar A'')} \phantom{E(S,\bar S)} &\\
&= E(S\cap A'', S\cap \bar A'') \cup E(\bar S\cap A'', \bar S\cap \bar A'')\\
&= E(T\cap A'', \bar T\cap A'') \cup E(T\cap \bar A'', \bar T\cap \bar A'') \\
&= E(T, \bar T) \cap E(S, \bar S).

E(S,\bar S) \cap E(A'',\bar A'')&= E(S\cap A'', \bar S \cap \bar A'') \cup E(S\cap \bar A'', \bar S \cap A'')\\
&=E(S\cap T, \bar S \cap T) \cup E(S\cap \bar T, \bar S \cap \bar T)=
E(S, \bar S) \setminus E(T, \bar T),\\
\intertext{and}
(E\setminus E(S,\bar S)) \cap E(A'',\bar A'') &= E(S\cap A'', S\cap \bar A'') \cup E(\bar S\cap A'', \bar S\cap \bar A'')\\
&= E(T\cap A'', \bar T\cap A'') \cup E(T\cap \bar A'', \bar T\cap \bar A'')\\
& = E(T, \bar T) \cap E(S, \bar S).
w(E(S,\bar S) \setminus E(T,\bar T)) \leq \gamma\cdot w(E(T,\bar T) \setminus E(S,\bar S)),w(E'\setminus E^*) > \gamma\cdot w(E^*\setminus E'),
\text{minimize } & \mathrlap{\frac{1}{2} \sum_{(u,v)\in E} w(u,v) \, \|\bar u - \bar v\|_1}\qquad \label{eq:CKR-relaxation}\\
\text{subject to: }&\notag\\
&\bar s_i = e_i &&\text{for every } i,\notag\\
&\bar u \in \Delta &&\text{for every } u\in V.\notag

\text{minimize } & \frac{1}{2} \sum_{(u,v)\in E} w(u,v) \, \|\bar u - \bar v\|_1 \label{eq:CKR-relaxation}\\
\text{subject to: }&\notag\\
&\bar s_i = e_i &&\text{for every } i,\notag\\
&\bar u \in \Delta &&\text{for every } u\in V.\notag

\Pr((u, v) \text{ is cut}) \leq 2d(u,v)\Pr((u,v)  \text{ is not cut}) \geq \frac{1 - d(u,v)}{2}.
\Pr((u, v) \text{ is cut}) \leq 2d(u,v) \quad\text{ and }\quad
\Pr((u,v)  \text{ is not cut}) \geq \frac{1 - d(u,v)}{2}.

\frac{1}{k}\sum_{i=1}^k \max(\bar u_i,\bar v_i) &= \frac{1}{k}\sum_{i=1}^k \left(\frac{\bar u_i +\bar v_i}{2} 
+ \frac{|\bar u_i -\bar v_i|}{2}\right) \\
&= \frac{1}{k}\left(1 
+ \frac{\|\bar u -\bar v\|_1}{2}\right) \\
&= \frac{1 
+ d(u,v)}{k}.
\frac{1}{k}\sum_{i=1}^k \max(\bar u_i,\bar v_i) = \frac{1}{k}\sum_{i=1}^k \left(\frac{\bar u_i +\bar v_i}{2} 
+ \frac{|\bar u_i -\bar v_i|}{2}\right) = \frac{1}{k}\left(1 
+ \frac{\|\bar u -\bar v\|_1}{2}\right) = \frac{1 
+ d(u,v)}{k}.\frac{1}{k}\sum_{i=1}^k |\bar u_i-\bar v_i| = \frac{\|\bar u - \bar v\|_1 }{k}= \frac{2d(u,v)}{k}.
\mathsf{LP}_{+} &= \sum_{(u,v)\in E^*} w(u,v) (1 - d(u,v)),\\
\mathsf{LP}_{-} &= \sum_{(u,v)\in E\setminus E^*} w(u,v) \, d(u,v).

\E{w(E^*\setminus E')} &= \sum_{(u,v) \in E^*} w(u,v) \Pr((u,v) \text{ is not cut}) \\
&
\geq 
\sum_{(u,v) \in E^*} w(u,v) (1-d(u,v))/2 \\&
= \mathsf{LP}_{+}/2,\\
\intertext{and}
\E{w(E'\setminus E^*)} &= \sum_{(u,v) \in E\setminus E^*} w(u,v) \, \Pr((u, v) \text{ is cut}) \\
&\leq 
2\sum_{(u,v) \in E^*} w(u,v) d(u,v) \\
&= 2\,\mathsf{LP}_{-}.

\E{w(E^*\setminus E')} &= \sum_{(u,v) \in E^*} w(u,v) \Pr((u,v) \text{ is not cut}) \\
&
\geq 
\sum_{(u,v) \in E^*} w(u,v) (1-d(u,v))/2 = \mathsf{LP}_{+}/2,\\
\E{w(E'\setminus E^*)} &= \sum_{(u,v) \in E\setminus E^*} w(u,v) \, \Pr((u, v) \text{ is cut}) \leq 
2\sum_{(u,v) \in E^*} w(u,v) d(u,v) = 2\,\mathsf{LP}_{-}.

\mathsf{LP}_{+} - \mathsf{LP}_{-} &= w(E^*) - \sum_{(u,v) \in E} w(u,v) \, d(u,v) \\
&= w(E^*) - \frac{1}{2}\sum_{(u,v) \in E} w(u,v) \, \|\bar u-\bar v\|_1 
\geq 0
\mathsf{LP}_{+} - \mathsf{LP}_{-} = w(E^*) - \sum_{(u,v) \in E} w(u,v) \, d(u,v) = w(E^*) - \frac{1}{2}\sum_{(u,v) \in E} w(u,v) \, \|\bar u-\bar v\|_1 \geq 0
E &= \set{(u_1,v_2): (u,v) \in E_c} \\ &\qquad{} \cup  \set{(u_1,v_1), (u_2,v_2): (u,v) \in E_d} \\&\qquad{}\cup \set{(u_1,u_2): u\in V_0}.
E = \set{(u_1,v_2): (u,v) \in E_c} \cup \set{(u_1,v_1), (u_2,v_2): (u,v) \in E_d} \cup \set{(u_1,u_2): u\in V_0}.\gamma \cdot w(\set{(u_1,v_2): (u,v) \in E_c} \cup \set{(u_1,v_1), (u_2,v_2): (u,v) \in E_d}).w(E(S,\bar S)\setminus E(T,\bar T)) > \gamma \cdot w(E(T,\bar T)\setminus E(S,\bar S)).
A &= \set{u\in V_0: u_1\in T} = \set{u\in V_0: u_2\in \bar T} ;\\
\bar A &= \set{u\in V_0: u_1\in \bar T} = \set{u\in V_0: u_2\in T}.

\mathrlap{w(E(S,\bar S)\setminus E(T,\bar T)) }\qquad & \\
&=w(E(S\cap T, \bar S\cap T)) + w(E(S\cap \bar T, \bar S\cap \bar T))\\
&= 2\, \mathrm{cap}(E_c(A,\bar A)) > \gamma \cdot 2\, \mathrm{dem}(E_d(A,\bar A))\\
&= w(E(S\cap T, S\cap \bar T)) + w(E(\bar S\cap T, \bar S\cap \bar T))\\
& = w(E(T,\bar T)\setminus E(S,\bar S)),

w(E(S,\bar S)\setminus E(T,\bar T)) &= w(E(S\cap T, \bar S\cap T)) + w(E(S\cap \bar T, \bar S\cap \bar T))\\
&= 2\, \mathrm{cap}(E_c(A,\bar A)) > \gamma \cdot 2\, \mathrm{dem}(E_d(A,\bar A))\\
&= w(E(S\cap T, S\cap \bar T)) + w(E(\bar S\cap T, \bar S\cap \bar T)) = w(E(T,\bar T)\setminus E(S,\bar S)),
\phi^* = \min_{(A,\bar A)} \phi(A) < \phi_0 \text{ or } \phi^* > \gamma(2n) \phi_0.
\mathrlap{w(E(S,\bar S)) - w(E(T,\bar T))}\quad &
 \\
&= w(E(S\cap T, \bar S\cap T)) + w(E(S\cap \bar T, \bar S\cap \bar T)) \\
&\quad - 
(w(E(S\cap T, S\cap \bar T)) + w(E(\bar S\cap T, \bar S\cap \bar T)))\\
&=2\, \mathrm{cap}(E_c(A,\bar A)) -  2\, \mathrm{dem}(E_d(A,\bar A)) < 0.

w(E(S,\bar S)) - w(E(T,\bar T)) &= w(E(S\cap T, \bar S\cap T)) + w(E(S\cap \bar T, \bar S\cap \bar T)) \\
&\quad - 
(w(E(S\cap T, S\cap \bar T)) + w(E(\bar S\cap T, \bar S\cap \bar T)))\\
&=2\, \mathrm{cap}(E_c(A,\bar A)) -  2\, \mathrm{dem}(E_d(A,\bar A)) < 0.

\phi(A) &{}= \frac{\mathrm{cap}(E_c(A,\bar A))}{\mathrm{dem}(E_d(A,\bar A))} \\
&{}\geq D \cdot \frac{\sum_{(u,v)\in E_c} \mathrm{cap}_{uv}\cdot\|\bar u - \bar v\|^2}{\sum_{(u,v)\in E_d} \mathrm{dem}_{uv}\cdot\|\bar u - \bar v\|^2}

\phi(A) = \frac{\mathrm{cap}(E_c(A,\bar A))}{\mathrm{dem}(E_d(A,\bar A))} \geq D \cdot
\frac{\sum_{(u,v)\in E_c} \mathrm{cap}_{uv}\cdot\|\bar u - \bar v\|^2}{\sum_{(u,v)\in E_d} \mathrm{dem}_{uv}\cdot\|\bar u - \bar v\|^2}
\quad\text{for every cut} (A, \bar A).

\mathrm{cap}(E_c(A,\bar A)) &> (D_{\ell_2^2\to \ell_1} - \varepsilon) \cdot \mathrm{dem}(E_d(A,\bar A)) 
\ifSODA\else\qquad\text{for every cut } (A, \bar A)\fi \label{ineq:combinatorial}\\
\sum_{(u,v)\in E_c} \mathrm{cap}_{uv}\cdot \|\bar u - \bar v\|^2 &< \sum_{(u,v)\in E_d} \mathrm{dem}_{uv}\cdot \|\bar u - \bar v\|^2 
\label{ineq:vector}.

SDP &\equiv \frac{1}{4} \sum_{(x,y) \in E} w(x,y) \|\bar x- \bar y\|^2 = n W_{\infty} \\
       &\ {} + \frac{1}{4} \sum_{(u,v) \in E_d} \mathrm{dem}_{uv} \cdot(\|\bar u_1- \bar v_1\|^2 + \|\bar u_2- \bar v_2\|^2) \\
       &\ {}+ \frac{1}{4} \sum_{(u,v) \in E_c} \mathrm{cap}_{uv} \cdot (\|\bar u_1- \bar v_2\|^2 + \|\bar u_2- \bar v_1\|^2)\\
       &= n W_{\infty} + \frac{1}{2} \sum_{(u,v) \in E_d} \mathrm{dem}_{uv} \cdot \|\bar u - \bar v\|^2  \\
       &\ + \frac{1}{2} \sum_{(u,v) \in E_c} \mathrm{cap}_{uv} \|\bar u + \bar v\|^2.

SDP &\equiv \frac{1}{4} \sum_{(x,y) \in E} w(x,y) \|\bar x- \bar y\|^2 \\
       &= n W_{\infty} + \frac{1}{4} \sum_{(u,v) \in E_d} \mathrm{dem}_{uv} \cdot(\|\bar u_1- \bar v_1\|^2 + \|\bar u_2- \bar v_2\|^2) \\
       &\phantom{{}= n W_{\infty}} {}+ \frac{1}{4} \sum_{(u,v) \in E_c} \mathrm{cap}_{uv} \cdot (\|\bar u_1- \bar v_2\|^2 + \|\bar u_2- \bar v_1\|^2)\\
       &= n W_{\infty} + \frac{1}{2} \sum_{(u,v) \in E_d} \mathrm{dem}_{uv} \cdot \|\bar u - \bar v\|^2  + \frac{1}{2} \sum_{(u,v) \in E_c} \mathrm{cap}_{uv} \|\bar u + \bar v\|^2.
SDP = (n W_{\infty} + 2 \mathrm{cap} (E_c)) +  \frac{1}{2}\sum_{(u,v) \in E_d} \mathrm{dem}_{uv} \cdot \|\bar u - \bar v\|^2 -  \frac{1}{2}\sum_{(u,v) \in E_c} \mathrm{dem}_{uv} \|\bar u - \bar v\|^2.SDP = w(S, \bar S) +  \frac{1}{2}\sum_{(u,v) \in E_d} \mathrm{dem}_{uv} \cdot \|\bar u - \bar v\|^2 -  \frac{1}{2}\sum_{(u,v) \in E_c} \mathrm{dem}_{uv} \|\bar u - \bar v\|^2 > w(S,\bar S).w'(E(S,\bar S)) \geq w'(E(T,\bar T)).w(E(S, \bar S)\setminus E(T, \bar T)) > \gamma\cdot w(E(T, \bar T )\setminus E(S, \bar S)).w(E(S, \bar S)\setminus E(T, \bar T)) > \gamma\cdot w(E(T, \bar T )\setminus E(S, \bar S)).
E_c &= E(T,\bar T) , & \mathrm{cap}_{uv} &= w(u,v)\\
E_d &= \set{(u,v) \in E\setminus E(T,\bar T):  w(u,v) \geq 2\omega} , & \mathrm{dem}_{uv} &= w(u,v).

\mathrm{dem}&(E_d \cap E(A^*,\bar A^*)) \geq w((E\setminus E(T,\bar T)) \cap E(A^*,\bar A^*)) \\
&\quad{}- m \cdot 2\omega \geq w((E\setminus E(T,\bar T))/2  \\
&> \gamma \cdot  w(E(T,\bar T) \cap E(A^*,\bar A^*))/2 = (\gamma/2) \cdot \mathrm{cap}(E_c).

\mathrm{dem}(E_d \cap E(A^*,\bar A^*)) &\geq w((E\setminus E(T,\bar T)) \cap E(A^*,\bar A^*)) - m \cdot 2\omega \geq w((E\setminus E(T,\bar T))/2  \\
&> \gamma \cdot  w(E(T,\bar T) \cap E(A^*,\bar A^*))/2 = (\gamma/2) \cdot \mathrm{cap}(E_c).

w&(T',\bar T') - w(T,\bar T) \\
&= w(E(T',\bar T')\setminus E(T,\bar T)) - w(E(T,\bar T)\setminus E(T',\bar T')) \\
&\geq \mathrm{dem}(E_d \cap E(A,\bar A)) - w(E_c \cap E(A,\bar A)) \\
&\geq  \mathrm{dem}(E_d \cap E(A,\bar A))/2 \geq
\omega.

w(T',\bar T') - w(T,\bar T) &= w(E(T',\bar T')\setminus E(T,\bar T)) - w(E(T,\bar T)\setminus E(T',\bar T')) \\
&\geq \mathrm{dem}(E_d \cap E(A,\bar A)) - w(E_c \cap E(A,\bar A)) \geq  \mathrm{dem}(E_d \cap E(A,\bar A))/2 \geq
\omega.
0.5em] \noindent \textit{Proof of Theorem~\ref{thm:weakly-stable}.}\w(E(S,\bar S)) - w(E(T,\bar T)) \leq w(E(S,\bar S)\setminus E(T,\bar T)) \leq  |E(S,\bar S)\setminus E(T,\bar T)| 
\cdot (4m \omega^*) \leq 4m^2 \omega.w(E(T_k,\bar T_k)) \geq w(E(T_0,\bar T_0)) +k\omega \geq w(E(S,\bar S)) -  4m^2\omega + k\omega.w'(E') > w'(E^*),w(E'\setminus E^*) > \gamma\cdot w(E^*\setminus E'),
w'(u,v) = 
\begin{cases}
w(u,v), & \text{if} (u,v) \in E^{\circ},\\
4\,w(u,v), & \text{otherwise}.
\end{cases}

\mathsf{LP}_{+} &= \sum_{(u,v)\in E^{\circ}} w'(u,v) (1 - d(u,v)) \\&= \sum_{(u,v)\in E^{\circ}} w(u,v) (1 - d(u,v)),\\
\intertext{and}
\mathsf{LP}_{-} &= \sum_{(u,v)\in E\setminus E^{\circ}} w'(u,v) \, d(u,v) \\&= 4\sum_{(u,v)\in E\setminus E^{\circ}} w(u,v) \, d(u,v).

\mathsf{LP}_{+} &= \sum_{(u,v)\in E^{\circ}} w'(u,v) (1 - d(u,v)) = \sum_{(u,v)\in E^{\circ}} w(u,v) (1 - d(u,v)),\\
\mathsf{LP}_{-} &= \sum_{(u,v)\in E\setminus E^{\circ}} w'(u,v) \, d(u,v) = 4\sum_{(u,v)\in E\setminus E^{\circ}} w(u,v) \, d(u,v).

\E{w(E^{\circ}\setminus E')} &= \sum_{(u,v) \in E^{\circ}} w(u,v) \Pr((u,v) \text{ is not cut}) \\
&
\geq 
\sum_{(u,v) \in E^{\circ}} w(u,v) (1-d(u,v))/2 \\
&= \mathsf{LP}_{+}/2,\\
\intertext{and}
\E{w(E'\setminus E^{\circ})} &= \sum_{(u,v) \in E\setminus E^*} w(u,v) \, \Pr((u, v) \text{ is cut}) \\
&\leq 
2\sum_{(u,v) \in E^{\circ}} w(u,v) d(u,v) = \mathsf{LP}_{-}/2.

\E{w(E^{\circ}\setminus E')} &= \sum_{(u,v) \in E^{\circ}} w(u,v) \Pr((u,v) \text{ is not cut}) \geq 
\sum_{(u,v) \in E^{\circ}} w(u,v) (1-d(u,v))/2 = \mathsf{LP}_{+}/2,\\
\E{w(E'\setminus E^{\circ})} &= \sum_{(u,v) \in E\setminus E^*} w(u,v) \, \Pr((u, v) \text{ is cut}) \leq 
2\sum_{(u,v) \in E^{\circ}} w(u,v) d(u,v) = \mathsf{LP}_{-}/2.

\E{w(E^{\circ})- w(E')} &=  \E{w(E^{\circ}\setminus E')} - \E{w(E'\setminus E^{\circ})}\\
&= \frac{\mathsf{LP}_{+}- \mathsf{LP}_{-}}{2}.
\E{w(E^{\circ})- w(E')} =  \E{w(E^{\circ}\setminus E')} - \E{w(E'\setminus E^{\circ})}= \frac{\mathsf{LP}_{+}- \mathsf{LP}_{-}}{2}.
\mathsf{LP}_{+} &{}- \mathsf{LP}_{-} = w'(E^{\circ}) - \sum_{(u,v) \in E} w'(u,v) \, d(u,v) \\
&\geq w'(E^{\circ}) - w'(E^*)  = w'(E^{\circ} \setminus E^*) - w'(E^* \setminus E^{\circ}),
\mathsf{LP}_{+} - \mathsf{LP}_{-} = w'(E^{\circ}) - \sum_{(u,v) \in E} w'(u,v) \, d(u,v) \geq w'(E^{\circ}) - w'(E^*) 
= w'(E^{\circ} \setminus E^*) - w'(E^* \setminus E^{\circ}),
\mathsf{LP}_{+} - \mathsf{LP}_{-} &= w'(E^{\circ} \setminus E^*) - w'(E^* \setminus E^{\circ})\\
& = w(E^{\circ} \setminus E^*) - 4 w(E^* \setminus E^{\circ}) > 0.
\mathsf{LP}_{+} - \mathsf{LP}_{-} = w'(E^{\circ} \setminus E^*) - w'(E^* \setminus E^{\circ})
 = w(E^{\circ} \setminus E^*) - 4 w(E^* \setminus E^{\circ}) > 0.
0.25em]
\else
\begin{proof}[Proof of Theorem~\ref{thm:weakly-stable-multiway-prime}]
\fi
We start with an arbitrary feasible multiway cut  and iteratively 
improve it using the algorithm from Lemma~\ref{lem:improve-multiway}. Once the algorithm returns
that the current cut  lies in , we output it.
Since the cost of the multiway cut decreases by at least  in each iteration, and
the initial cost of  is polynomial in , the algorithm terminates after
polynomially many steps.
\ifSODA

{\hfill\vbox{\hrule height.2pt\hbox{\vrule width.2pt height5pt \kern5pt \vrule width.2pt} \hrule height.2pt}}
\else
\end{proof}
\fi

\section{Discussion}\label{sec:Discussion}
In this paper, we presented algorithms for stable instances of Max Cut and Minimum Multiway Cut.
In conclusion, we briefly discuss what properties of these problems we used. 
We provide a sufficient condition under which there is an algorithm for stable instances
of a graph partitioning problem.

Consider a graph partitioning problem. Our goal is to partition a graph into several pieces, subject to certain constraints,
so as to minimize or maximize the weight of cut edges. Consider a metric relaxation for this problem. The relaxation
defines a metric  on the set of vertices. A combinatorial solution to the problem corresponds to a 
multicut metric : the distance between vertices in one piece is , the distance between vertices in different
pieces is . For Max Cut and Multiway Cut, 
we proved that \textit{the metric relaxation is integral when the instance is sufficiently stable};
this, in turn, implied the existence of polynomial-time robust algorithms for stable instances of these problems.
We summarize the properties that we used in the proof in the following meta-theorem.
\begin{theorem}[Meta-theorem]
Consider a graph partitioning problem and a metric relaxation for it. Suppose that there is a rounding scheme 
that given a graph  and a metric  returns a feasible partition such that
for some  and :
\begin{tabbing}
\ifSODA
\=\  \=\quad \ \=\ \=\ \=\ \=\kill
\else
\quad\=\quad\=\quad\quad\=\quad\=\quad\=\quad\=\kill
\fi
\>\textnormal{\textbf{For a cut minimization problem,}} \\
\>\> \> , \\
\>\> \> .\
\frac{\mathrm{cap}(E_c(A,\bar A))}{\mathrm{dem}(E_d(A,\bar A))} \geq D_{\ell_2^2\to \ell_1}\cdot
\frac{\sum_{(u,v)\in E_c} \mathrm{cap}_{uv}\cdot\|\bar u - \bar v\|^2}{\sum_{(u,v)\in E_d} \mathrm{dem}_{uv}\cdot\|\bar u - \bar v\|^2}.
\frac{D_{\ell_2^2\to \ell_1}-\varepsilon}{D_{\ell_2^2\to \ell_1}} <
\frac{\sum_{(u,v)\in E_c} \mathrm{cap}_{uv}\cdot \|\bar u - \bar v\|^2}{\sum_{(u,v)\in E_d} \mathrm{dem}_{uv}\cdot \|\bar u - \bar v\|^2} < 1.\tilde u = \frac{\sqrt{3}\,\bar z}{2}  + \frac{\bar u' - \bar c}{2R}.\|\tilde u - \tilde v\|^2 = \left\|\frac{\bar u' - \bar v'}{2R}\right\|^2 = \frac{\|\bar u - \bar v'\|^2 + 2\delta^2}{4R^2}.\frac{\sum_{(u,v)\in E_c} \mathrm{cap}_{uv}\cdot \|\tilde u - \tilde v\|^2}{\sum_{(u,v)\in E_d} \mathrm{dem}_{uv}\cdot \|\tilde u - \tilde v\|^2}=
\frac{\sum_{(u,v)\in E_c} \mathrm{cap}_{uv}\cdot\|\bar u - \bar v\|^2}{\sum_{(u,v)\in E_d} \mathrm{dem}_{uv}\cdot\|\bar u - \bar v\|^2} + O(\delta^2).

\frac{\sum_{(u,v)\in E_c} \mathrm{cap}_{uv}\cdot \|\tilde u - \tilde v\|^2}{\sum_{(u,v)\in E_d} \mathrm{dem}_{uv}\cdot \|\tilde u - \tilde v\|^2} < 1.

\|\tilde u - \tilde v\|^2 &{} + \|\tilde v - \tilde w\|^2 = 
\frac{\|\bar u - \bar v\|^2 + \|\bar v - \bar w\|^2 + 4\delta^2}{4R^2}\\
&\geq
\frac{\|\bar u - \bar w\|^2 + 4\delta^2}{4R^2} > \|\tilde u - \tilde w\|^2,\\
\|\tilde u - \tilde v\|^2 &{}+ \|\tilde v + \tilde w\|^2 =
\|\tilde u - \tilde v\|^2 +  (4 - \|\tilde v - \tilde w\|^2) \\
& > 
(\|\tilde u - \tilde w\|^2 + \|\tilde w - \tilde v\|^2) + (4 - \|\tilde v - \tilde w\|^2)\\
&= \|\tilde u + \tilde w\|^2,\\
\|\tilde u + \tilde v\|^2 &{}+ \|\tilde v + \tilde w\|^2 = 4 - \|\tilde u - \tilde v\|^2 + 4 - \|\tilde v - \tilde w\|^2\\
&\geq 8 - 2 > \|\tilde u - \tilde w\|^2.

\|\tilde u - \tilde v\|^2 + \|\tilde v - \tilde w\|^2 &= \frac{\|\bar u - \bar v\|^2 + \|\bar v - \bar w\|^2 + 4\delta^2}{4R^2}
\geq
\frac{\|\bar u - \bar w\|^2 + 4\delta^2}{4R^2} > \|\tilde u - \tilde w\|^2,\\
\|\tilde u - \tilde v\|^2 + \|\tilde v + \tilde w\|^2 &=
\|\tilde u - \tilde v\|^2 +  (4 - \|\tilde v - \tilde w\|^2) \\
&> 
(\|\tilde u - \tilde w\|^2 + \|\tilde w - \tilde v\|^2) + (4 - \|\tilde v - \tilde w\|^2)= \|\tilde u + \tilde w\|^2,\\
\|\tilde u + \tilde v\|^2 + \|\tilde v + \tilde w\|^2 &= 4 - \|\tilde u - \tilde v\|^2 + 4 - \|\tilde v - \tilde w\|^2
\geq 8 - 2 > \|\tilde u - \tilde w\|^2.

\mathsf{Agree}_G({\cal C}) &= \sum_{\substack{(u,v)\in E^+\\ {\cal C}(u) = {\cal C}(u)}} w_{(u,v)} + \sum_{\substack{(u,v)\in E^-\\ {\cal C}(u) \neq {\cal C}(u)}} w_{(u,v)}\\
\mathsf{DisAgree}_G({\cal C}) &= \sum_{\substack{(u,v)\in E^+\\ {\cal C}(u) \neq {\cal C}(u)}} w_{(u,v)} + \sum_{\substack{(u,v)\in E^-\\ {\cal C}(u) = {\cal C}(u)}} w_{(u,v)}.

V' &= \set{u:u\in V} \cup \set{u':u\in V}, \\
E' & = \set{(u,v): (u,v) \in E^-} \cup \set{(u',u): u\in V} \cup \set{(u',v), (u,v'): (u,v) \in E^+},\\
w'(u,v) &= w(u,v), \quad w'(u,v') = w(u,v) /2, \quad w(u,u') = W_{\infty},

S' &= \set{u: u\in S} \cup \set{u': u\in \bar S} \\
\bar S' &= \set{u: u\in \bar S} \cup \set{u': u\in S}.

w(E(S,\bar S)\setminus E(T,\bar T)) = w'(E(S,\bar S)\setminus E(T,\bar T)) \\ > w'(E(T,\bar T)\setminus E(S,\bar S)) = \gamma w(E(T,\bar T)\setminus E(S,\bar S)).

w(E(S,\bar S)\setminus E(T,\bar T)) = w'(E(S,\bar S)\setminus E(T,\bar T)) > w'(E(T,\bar T)\setminus E(S,\bar S)) = \gamma w(E(T,\bar T)\setminus E(S,\bar S)).

w'(E(S,\bar S)\setminus E(T,\bar T)) \geq w(E(S,\bar S)\setminus E(T,\bar T)) \\ > \gamma w(E(T,\bar T)\setminus E(S,\bar S))
\geq w'(E(T,\bar T)\setminus E(S,\bar S)),

w'(E(S,\bar S)\setminus E(T,\bar T)) \geq w(E(S,\bar S)\setminus E(T,\bar T)) > \gamma w(E(T,\bar T)\setminus E(S,\bar S))
\geq w'(E(T,\bar T)\setminus E(S,\bar S)),
\gamma w(E^*\setminus E') = w'(E^*\setminus E') < w'(E'\setminus E^*) = w(E'\setminus E^*).w'(E^*\setminus E') \leq \gamma w(E^*\setminus E') < w(E'\setminus E^*) \leq w'(E'\setminus E^*).
as required.
\end{proof}

\end{document} 