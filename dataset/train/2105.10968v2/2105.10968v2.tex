

\documentclass[letterpaper, 10 pt, conference]{ieeeconf}  

\IEEEoverridecommandlockouts                              \overrideIEEEmargins


\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{amssymb}
\usepackage{amsmath}
\usepackage[ruled]{algorithm2e}
\usepackage{amsfonts}
\usepackage{dsfont}
\usepackage{graphicx}   
\usepackage{url}   
\usepackage[backend=biber]{biblatex}
\usepackage{caption}
\usepackage{subcaption} 
\usepackage{stfloats}

\addbibresource{references.bib}


\usepackage{xcolor,colortbl}

\newcommand{\mc}[2]{\multicolumn{#1}{c}{#2}}
\definecolor{Gray}{gray}{0.85}
\definecolor{LightCyan}{rgb}{0.88,1,1}

\newcolumntype{a}{>{\columncolor{Gray}}c}
\newcolumntype{b}{>{\columncolor{white}}c}




\title{\LARGE \bf
HOME: Heatmap Output for future Motion Estimation
}



\author{Thomas Gilles, Stefano Sabatini, Dzmitry Tsishkou, Bogdan Stanciulescu, Fabien Moutarde

\thanks{IoV team, Paris Research Center, Huawei Technologies France}\thanks{MINES ParisTech, PSL University, Center for robotics}\thanks{Contact: thomas.gilles@mines-paristech.fr}}


\begin{document}



\maketitle
\thispagestyle{empty}
\pagestyle{empty}


\begin{abstract}

In this paper, we propose HOME, a framework tackling the motion forecasting problem with an image output representing the probability distribution of the agent's future location. This method allows for a simple architecture with classic convolution networks coupled with attention mechanism for agent interactions, and outputs an unconstrained 2D top-view representation of the agent's possible future. Based on this output, we design two methods to sample a finite set of agent's future locations. These methods allow us to control the optimization trade-off between miss rate and final displacement error for multiple modalities without having to retrain any part of the model. We apply our method to the Argoverse Motion Forecasting Benchmark and achieve 1 place on the online leaderboard.


\end{abstract}




\section{INTRODUCTION}

Forecasting the future motion of surrounding actors is an essential part of the autonomous driving pipeline, necessary for safe planning and useful for simulation of realistic behaviors. In order to capture the complexity of a driving scenario, the prediction model needs to take into account the local map, the past trajectory of the predicted agent and the interactions with other actors. Its output needs to be multimodal to cover the different choices a driver could make, between going straight or turning, slowing down or overtaking. Each modality proposed should represent a possible trajectory that an agent could take in the immediate future.

The challenge in motion prediction resides not in having the absolute closest trajectory to the ground truth, but rather in avoiding big failures where a possibility has not been considered, and the future is totally missed by all modalities. An accident will rarely happen because most predictions are offset by half a meter, but rather because of one single case where a lack of coverage led to a miss of more than a few meters.

A classic way to obtain  modalities is to design a model that outputs a fixed number of  future trajectories \cite{cui2019multimodal, mercat2020multi, messaoud2020multi, liang2020learning}, as a regression problem. This approach has however significant drawbacks, as training predictions all together leads to mode collapse. The common solution to this problem is to only train the closest prediction to the ground truth, but this diminishes the training data allocated to each predicted modality as only one is learning at each sample. 

Later methods adapt the model to the multi-modal problem by conditioning the prediction to specific inputs such as lanes \cite{khandelwal2020if} or targets \cite{zhao2020tnt}. Finally, recent methods use the topological lane graph itself to generate trajectory for each node \cite{zeng2021lanercnn}. However each of these model constrains its prediction space to a restricted representation, that may be limited to represent the actual diversity of possible futures. For example, if the predicted modalities are constrained to the High Definition map graph, it becomes very hard to predict agent breaking traffic rules or slowing down to park at the side of the road.

\begin{figure}[t]
\centerline{\includegraphics[width=0.9\columnwidth]{images/approach_cut3_new.PNG}}
\caption{Summary of our approach. The yellow/red heatmap is our predicted probability distribution and the blue points are the sampled final point predictions. }
\label{fig:approach}
\end{figure}

\begin{figure*}[t]
\centerline{\includegraphics[width=2\columnwidth]{images/pipeline_new.png}}
\caption{HOME pipeline. a) Context map, target agent (blue) and neighbor (green) trajectories are given as input to the network. b) Heatmap output of the network. c) Sampled final points. d) Trajectories are built for each final point}
\label{fig:pipeline}
\end{figure*}

In this paper, following the same principle as recent state of the art method, which is that a future trajectory can be almost fully defined by its final point \cite{zhao2020tnt, zeng2021lanercnn}, we reformulate the prediction problem in three steps. We first represent the possible futures distribution by a 2D probability heatmap that gives an unconstrained approximation of the probability of the agent position. This heatmap is represented as a squared image and it naturally accommodates for multimodal predictions where each pixel represent a possible future position of the target agent. It also enables to fully describe the future uncertainty in a probability distribution, without having to choose its modes or means. In a second step, we sample from the heatmap a finite number of possible future locations with the possibility to choose which metric we want to optimize without retraining the model. Finally, we build the full trajectories based on the past history and conditioned on the sampled final points.


Our contributions are summarized as follow:
\begin{itemize}
    \item We present a simple model architecture made of a convolutional neural network (CNN), a recurrent neural network (RNN) and an Attention module, with a heatmap output allowing for easy and efficient training.
    \item We design two  sampling algorithms from this heatmap output, optimizing MR or minFDE respectively.
    \item We highlight a trade-off between both metrics, and show that our sampling algorithm allows us to control this trade-off with a simple parameter.
\end{itemize}




\section{RELATED WORK}

Deep learning has brought great progress to the motion forecasting results \cite{mozaffari2020deep}. A classic CNN architecture can be applied to a rasterized map to predict 2D coordinates \cite{cui2019multimodal}.


In order to model interactions better between driving agents, attention has been introduced in multiple methods. The approach of \cite{mercat2020multi} encodes separately agents and centerlines with 1D CNN and LSTM and then applies multi-head attention from actors to other actors and lines. MHA-JAM \cite{messaoud2020multi} concatenates agent features to a CNN-encoded map at their specific coordinates, and then applies attention on this joint representation. The work of \cite{luo2020probabilistic} also uses attention between agents for interactions, and parallely applies an attention head on encoded lane to obtain lane probabilities and generate a modality for each given lane. mmTransformer \cite{liu2021multimodal} applies a general Transformer \cite{vaswani2017polosukhin} architecture to fuse history, map and interactions.

Another family of methods use a pool of anchor trajectories, predefined \cite{chai2020multipath} or model-based \cite{phan2020covernet,song2021learning}, and rank them with a learned model. This allows to avoid any mode collapse and assert realistic trajectories, but removes the ability to tune the trajectories accurately to the current situation.

Multimodality can also be obtained using generative approaches   that model the actual future probability distribution \cite{lee2017desire, mangalam2020not, tang2019multiple, rhinehart2018r2p2, rhinehart2019precog}. However, generative models require multiple independent sampling at inference time without any optimization of coverage or average distance.

More recently, methods have started to leverage the graph obtained from HD-map  in order to better represent lane connectivity. VectorNet \cite{gao2020vectornet} encodes both map features and agent trajectories as polylines then merge them with a global interaction graph. LaneGCN \cite{liang2020learning} treats actor past and the lane graph separately, and then fuse them with a series of attention layers between lane and actors. 


Other methods then use the graph to structure their multimodal outputs. TNT \cite{zhao2020tnt} builds from the VectorNet backbone and combines it with multiple target proposals sampled from the lanes in order to diversify the prediction points. GoalNet \cite{zhang2020map} also identifies possible goals and applied a prediction head for each on a localized raster in order to base the modalities on reachable lanes. WIMP \cite{khandelwal2020if} matches possible polylines to the past trajectory and uses them as conditional input to their model. LaneRCNN \cite{zeng2021lanercnn} adds actor features from the start to sampled nodes on the lanes, and then predicts a future point for each node along a probability. 

Grid-based outputs have already been used in pedestrian behavior prediction such as \cite{liang2020garden, deo2020trajectory, mangalam2020goals, jain2020discrete, ridel2020scene}. Their model architecture, training and sampling strategies however differ greatly from ours. The work of \cite{sadat2020perceive} produces a future grid occupancy output prediction for each vehicle class in order to plan from it, but it is not instance-based and doesn't allow for individual vehicle prediction.

\begin{figure*}[t]
\centerline{\includegraphics[width=2\columnwidth]{images/NN_architecture_new.pdf}}
\caption{Example of input and output data for our model with brief description of architecture}
\label{fig:in_out_archi}
\end{figure*}


\section{METHOD}



We describe our general pipeline in Fig. \ref{fig:pipeline}. Our method takes as input a rasterized image of the agent environment, and outputs a probability distribution heatmap representing where the agent could be at a fixed time horizon T in the future. A finite set of possible locations are then extracted from the heatmap to ensure appropriate coverage. Future locations are sampled to minimize either rate of misses or final displacement errors. Finally for each sampled future location, a trajectory representing the motion of agent from the initial state to the future location is computed.

The aim of motion estimation is to predict the future positions of the target agent  for T timesteps . The model is given the past H timesteps  for the target agent  and the  neighbor agents .
Supplementary context informations are available in the shape of a graph High Definition Map (HD map). We will focus in this paper on the prediction of the final points , and then regress the whole trajectory conditioned on the end point.

\subsection{Encoding history and local context information}



\subsubsection{Map and past trajectory encoding}

The local context is available as a High Definition Map centered on the target agent.
We rasterize the HD-Map in 5 semantic channels: drivable area, lane boundaries and directed center-lines with their headings encoded using HSV on 3 channels. We also add the target agent trajectory as a moving rectangle on 20 history channels and the other agents history on 20 more channels. The final input is a (224, 224, 45) image with a 0.5 x 0.5 m² resolution per pixel. This image is processed by a classic CNN model alternating convolutional layers and max-pooling for downscaling to obtain a (14, 14, 512) encoding  as illustrated in the top-left part of Fig. \ref{fig:in_out_archi}.

The scalar history of the agents is also taken as input to the model as a list of 2D coordinates. Missing timesteps are padded with zeros and a binary mask indicating if padding was applied is concatenated to the trajectory, as well as the timestamps for each step, so to obtain a  input for each agent. Each agent  trajectory goes through a 1D convolutional layer followed by a UGRU\cite{ugru} recurrent layer. The weights are shared for all agents except the target agent.



\subsubsection{Inter-agent attention for interaction}

Similar to \cite{mercat2020multi, messaoud2020multi, luo2020probabilistic}, we use attention \cite{vaswani2017polosukhin} to model agent interaction. A query vector is generated for the target agent, while key and value vectors are created for the other actors. The normalized dot product of query and keys creates an attention map from the target agent to the other agent, then used to pool their value features into a context vector. The context vector is then added to the target vehicle feature vector through a residual connection followed by LayerNormalization \cite{ba2016layer}. The obtained trajectory encoding  is then repeated to match the context encoding  dimensions. The final encoding  is the result of the concatenation of both encodings  and .

\subsubsection{Increased output size for longer range}
Due to high speed, some cars may go through a greater range in the time horizon  that is covered by the input range of 56m. However, simply increasing input size would greatly add to the computational burden while not necessarily bringing useful information. We therefore want to increase the output size while retaining the spatial correspondences through the layers. In order to do so, we apply Tranpose Convolutions with stride 1 and kernel size 3. Since 1 input pixel is connected to a grid of 3x3 output pixels, the edge pixels generate a new border of pixels around them, increasing the encoding size by 1 in each direction. We apply 2 of these layers, resulting in a (18, 18, 512) augmented encoding so that once upscaled the decoded image output will be of size (288, 288), corresponding to a 72m range.


\subsection{Heatmap output}

The final part of the model is a convolutional decoder alternating transpose convolutions for upscaling and classic convolutions, topped with a sigmoid activation. We output an image  with similar resolution as the raster input (0.5 x 0.5 m² / pixel). The output target is an image  with a Gaussian centered around the ground truth position. This image is trained with a pixel-wise focal loss inspired from \cite{zhou2019objects}, averaged over the total  pixels  of the heatmap:



where the non-null pixels around the Gaussian center serve as penalty-reducing coefficients, and the square factor of error allows the gradient to focus on poorly-predicted pixels. We use a standard deviation of 4 pixels for the Gaussian.




\subsection{Modality sampling}

Our aim is here to sample the probability heatmap in order to optimize the performance metric of our choice. In most datasets such as Argoverse \cite{chang2019argoverse} and NuScenes \cite{caesar2020nuscenes}, two main metrics are used for the final predicted point: MissRate (MR) and Final Displacement Error (FDE). MissRate corresponds to the percentage of prediction being farther than a certain threshhold to the ground truth, and FDE is simply the mean of  distance between the prediction and the ground truth.
When the output is multimodal, with  predictions, minimum Final Displacement Error minFDE and Miss Rate over the  predictions MR are used.


\subsubsection{Optimizing Miss Rate}

We design a sampling method in order to optimize the Miss Rate between the predicted modalities and the ground truth. A case is defined as missed if the ground truth is further than 2m from the prediction. For a given area , the probability of the ground truth  being in this area is equal to the integral of the probability distribution  under this ground truth. 






Therefore, for  predictions, given a 2D probability distribution, the sampling minimizing the expected MR is the one maximizing the integral of the future probability distribution under the area defined as 2m radius circles around the  predictions:




\begin{figure}[t]
    \center
    \begin{subfigure}[b]{0.23\textwidth}
        \includegraphics[width=\textwidth]{images/mr_sampling_h.png}
        \caption{MR sampling}
        \label{fig:mr_samplimg}
    \end{subfigure}
    \begin{subfigure}[b]{0.23\textwidth}
        \includegraphics[width=\textwidth]{images/fde_sampling_h.png}
        \caption{FDE sampling}
        \label{fig:fde_sampling}
    \end{subfigure}
    \caption{Illustration of sampling methods}
    \label{fig:sampling}
\end{figure}

We therefore process in a greedy way as described in Algo. \ref{mr_algo}, and iteratively select the location with the highest integrated probability value in its 2m circle. Once we obtain such a point, we set to zero the heatmap values under the defined circle and move on to selecting the next point with the same method. 

\begin{algorithm}
\DontPrintSemicolon 
\SetKwInOut{Input}{input}
\Input{Probability map p(x) \\

 number of predictions \\

 threshhold for Miss Rate
}
\For{k = 1..K } {
    Find  maximizing  \\
    Set  for all  such that  \\
}
\caption{ MR Sampling Algorithm\label{IR}}
\label{mr_algo}
\end{algorithm}

The result is illustrated in Fig. \ref{fig:mr_samplimg}. We see that each sampled point can be surrounded by a circle of radius 2m that barely overlaps with other circles. Each point is sampled almost equidistant to the others, as setting the probability under previous points to zero sets a very strict limit to the minimum distance between points.

For implementation, we process the covered area for each point using a convolution layer with kernel weights fixed so to approximate a 2m circle. In practice, we don't actually use a radius of 2 meters, but a 1.8 meters one as we found out it to yield better performance. We also upscale the heatmap to 0.25 x 0.25 m per pixel with bilinear interpolation to have a more refined prediction location.



\subsubsection{Optimizing Final Displacement Error}

We inspire ourselves from KMeans to optimize minFDE.
The image output can be represented as a discrete probability distribution  where  represents the pixel centers and  the associated probability value. Optimizing the Final Displacement Error over  predictions means finding  centroids  that minimize the following quantity:



To do so we design our sampling algorithm for FDE optimization detailed in Algo. \ref{fde_algo}.

\begin{algorithm}
\DontPrintSemicolon 
\SetKwInOut{Input}{input}
\Input{Set of points  with probability weight \\

 number of iterations to run the algorithm\\

Initialization of  centroids 
}
\For{l = 1..L } {
    Compute  the matrix of distance of point  to each centroid  \\
    Compute  the distance of point  to the closest centroid  \\
    \For{k = 1..K } {
        Compute new centroid coordinates :
        
        with 

    }
}
\caption{ FDE Sampling Algorithm\label{IR}}
\label{fde_algo}
\end{algorithm}

We replace the classic weighted average  for each centroid  by  where  is the distance between point  and centroid  to be more robust to outliers and take into account the optimisation of  norm instead of its square.



In essence, we update each prediction as a weighted average of its local neighborhood in a radius of 3m. The coefficient , with  the distance between point  and its closest centroid allows for flexible partition boundaries compared to KMeans (where we would use  instead): when  is in the partition of prediction , its value is 1, while when it's outside it decreases, so as to be 0 when at the exact position of another prediction , where it could never be improved by a displacement of .

We initialize the centroids with the results of the Miss Rate optimization algorithm and use the number of iterations  as a parameter to tune the trade-off between Miss Rate and FDE: when  is zero, Miss Rate is optimized while when  increases MR is sacrificed to get better FDE. The output of the algorithm is illustrated in Fig. \ref{fig:fde_sampling}, where is it can be observed that centroids are brought closer together, sacrificing total coverage but getting closer to areas with high probabilities to reduce the expected distance. Results of this trade-off are illustrated further in Sec. \ref{sec:traj_trade}, where we show in Fig. \ref{fig:trade} that every iteration of Algo. \ref{fde_algo} diminishes minFDE and increases MR.


\begin{table*}[bp]
\caption{Results on Argoverse Motion Forecasting Leaderboard \cite{leaderboard} (test set)}
    \begin{center}
    \begin{tabular}{l|c c c|c c c c a}
      \hline
       & \multicolumn{3}{c|}{K=1}  & \multicolumn{5}{c}{K=6}  \\
      & minADE & minFDE& MR&minADE & minFDE&p-minADE & p-minFDE& MR \\
      \hline
      WIMP \cite{khandelwal2020if} & 1.82 & 4.03 & 62.9 &  0.90 & 1.42& 2.69 & 3.21 & 16.7\\
      LaneGCN \cite{liang2020learning} & 1.71 & 3.78 & 59.1 &  0.87 & 1.36 & 2.66 & 3.16 & 16.3\\
      Alibaba-ADLab  & 1.97 & 4.35 & 63.4 &  0.92 & 1.48 & 2.64 & 3.23 & 15.9\\
      TPCN \cite{ye2021tpcn} & \textbf{1.64} & \textbf{3.64} & 58.6 &  \textbf{0.85} & \textbf{1.35} & 2.61 & 3.11 & 15.9\\
      HIKVISION-ADLab-HZ & 1.94 & 3.90 & 58.2 &  1.21 & 1.83 & 3.00 & 3.62& 13.8\\
      TNT \cite{zhao2020tnt} & 1.78 & 3.91 & 59.7 &  0.94 & 1.54 & 2.73 & 3.33& 13.3\\
      Jean \cite{mercat2020multi} & 1.74 & 4.24 & 68.6 &  1.00 & 1.42 & 2.79 & 3.21 & 13.1\\
      TMP \cite{liu2021multimodal} & 1.70 & 3.78 & 58.4 & 0.87 & 1.37 & 2.66 & 3.16 & 13.0\\
      LaneRCNN \cite{zeng2021lanercnn} & 1.69 & 3.69 & \textbf{56.9} &  0.90 & 1.45 & 2.70 & 3.24 & 12.3\\
      SenseTime\_AP  & 1.70 & 3.76 & 58.3 &  0.87 & 1.36 & 2.66 & 3.16 & 12.0\\
      poly (3) & 1.70 & 3.82 & 58.8 &  0.87 & 1.47 & 2.67 & 3.28 & 12.0\\
      PRIME (2) \cite{song2021learning}& 1.91 & 3.82 & 58.7 &  1.22 & 1.56 & 2.71 & 3.04 & 11.5\\
      \hline
      Ours-HOME (FDE L=4) & 1.72 & 3.73 & 58.4 &  0.92 & 1.36 & 2.64 & 3.08 & 11.3\\
      Ours-HOME (MR) (1) & 1.73 & 3.73 & 58.4 &  0.94 & 1.45 & \textbf{2.52} & \textbf{3.03}& \textbf{10.2}\\
      

      \hline
    \end{tabular}
    \end{center}
    \label{tab:argo_test}
\end{table*}

\subsection{Full trajectory generation}

We use a separate model to generate full trajectories connecting the initial agent position to all sampled locations. This model applies a fully-connected layer to encode the target agent history into a vector of 32 features, which is then concatenated with the  coordinates of the target future location. Another fully-connected layer is then applied to obtain a 64 feature vector, which is then transformed through a last fully-connected layer to a set of locations representing the intermediate position of the agent in the time frame . The probability of a trajectory is the integral of the probability heatmap under the circle of radius 2m around the end point of the trajectory.




\section{EXPERIMENTS}

\subsection{Experimental settings}

\subsubsection{Dataset} We use the Argoverse Motion Forecasting Dataset \cite{chang2019argoverse}. It is a car trajectory prediction benchmark with 205942 training samples, 39472 validation samples and 78143 test samples. Each sample contains the position of all agents in the scene in the past 2s as well as the local map, and the labels are the 3s future positions of one target agent in the scene. 

\subsubsection{Metrics}

We report the previously defined metrics MR and minFDE for k=1,6, completed by the minimum Average Displacement Error minADE which is the average  error over all successive trajectory points. We also report the metrics p-minFDE and p-minADE for the test set, where  is added to the metric,  being the probability assigned to the best (closest to ground-truth) predicted trajectory. These later metrics allow to measure the quality of the probability distribution assigned to the predictions.

\subsubsection{Implementation details} We train all models for 16 epochs with batch size 32, using Adam optimizer initialized with a learning rate of 0.001. Each sample frame is centered on the target agent and aligned with its heading. We divide learning rate by half at epochs 3, 6, 9 and 13. We augment the training data by dropping each raster channel with a probability of 0.1 and rotating the frame by a uniform random angle in  in 50\% of the samples. All convolution layers are CoordConv \cite{liu2018intriguing} with a kernel of size 3x3 (3 for 1D Convs) and are followed by BatchNormalization and ReLU activation.

\subsection{Comparison with State-of-the-art}

We show in Tab. \ref{tab:argo_test} our results compared to other methods on the Argoverse motion forecasting test set. The benchmark is ranked by MR, where we rank first and significantly improve on previous results, demonstrating that having the heatmap output enables the best coverage with respect to the prior art. We also outperform other methods on both p-minFDE and p-minADE, demonstrating superior modelling of the probability distribution between predictions. Another interesting observation is that methods performing very well on minFDE such as LaneGCN \cite{liang2020learning} and TPCN \cite{ye2021tpcn} have a worse MR as drawback. PRIME \cite{song2021learning} has the closest MR to ours but a much higher minFDE in comparison. We show the results of both our sampling optimized for MR and minFDE with the same trained model. Our FDE sampling with  sacrifices 1.1 points of MR for 9 cm of minFDE, which gets us second best on minFDE while still being good enough for 1 position on the leaderboard.


\begin{table}[t]
\centering
\caption{Ablation study on output representation \Argoverse validation set)}
    \begin{center}
    \begin{tabular}{l|c c|c c}
      \hline
       Bottleneck  & \multicolumn{2}{c|}{K=1}  & \multicolumn{2}{c}{K=6}  \\
      & minFDE& MR& minFDE& MR \\
      \hline
      Pixel ranking with NMS & 3.07 & 51.0  & 1.21 & 10.7\\
      KMeans  & 3.06 & 51.6 &  1.23 & 9.3\\
      Ours (MR)   & 3.02 & 50.7 & 1.28 & \textbf{6.8}\\
      Ours (FDE L=6)   & \textbf{3.01} & \textbf{50.5} & \textbf{1.16} & 7.4\\

      \hline
    \end{tabular}
    \end{center}
    \label{tab:ablation_sampling}
\end{table}



We highlight our sampling results in Tab \ref{tab:ablation_sampling} and compare them to other possible sampling strategies: we try ranking pixels by probability and select them in decreasing order while removing overlapping pixels that are closer than a 1.8m radius following a classic Non-Maximum Suppression method. We also try KMeans as is used in \cite{mangalam2020goals}.






\begin{figure*}[b]
\centerline{\includegraphics[width=2\columnwidth]{images/qualitative_cases_new_compressed.png}}
\caption{Qualitative examples. The yellow/red heatmap is our predicted probability distribution and the blue points are the sampled final point predictions. The ground truth trajectory is shown in green.}
\label{fig:qualitative}
\end{figure*}


\subsection{Qualitative results}

We show supplementary qualitative results in Fig. \ref{fig:qualitative}. We highlight examples of straight line, overtaking, curve road, going outside the map and intersections. Our model heatmap output makes use and usually follows the prior from the context map, but it is also able to divert from it based on interactions, realistic observations and hints of divergence from history.

\section{CONCLUSION}

We have presented HOME, a novel representation for multimodal trajectory prediction. It is based on predicting the future final point position on a 2D top-view grid, decoding then this final point into a full trajectory. This heatmap output represents the complete future probability distribution and its uncertainties, from which we design two prediction sampling methods. Sampling directly from the heatmap distribution enables a more optimized coverage, achieving state-of-the-art performance on the Argoverse Motion Forecasting benchmark.














\section*{ACKNOWLEDGMENT}

We would like to thank Thomas Wang and Camille Truong-Allié for useful comments on the paper, as well as Arthur Moreau and Joseph Gesnouin for insightful discussions.









\printbibliography



\end{document}
