\documentclass[prodmode,acmtompecs]{acmsmall} 



\usepackage{rotating}
\usepackage{graphicx}
\usepackage[cmex10]{amsmath}	\usepackage{amssymb}	\usepackage{multirow}

\newtheorem{assumption}{\textbf{Assumption}}
\DeclareMathOperator*{\argmin}{arg\,min} \DeclareMathOperator*{\argmax}{arg\,max} \DeclareMathOperator*{\expectation}{\mathrm{E}} 

\newcommand{\reqvec}{\mathbf{q}}
\newcommand{\reqscalar}{q}
\newcommand{\ribvec}{\boldsymbol{\alpha}}
\newcommand{\ribscalar}{\alpha}

\newcommand{\priorityImplication}{monotonicity in individual expected payoff}
\newcommand{\modelSatisfyPriorityImplication}{a system satisfies monotonicity in payoffs}

\newcommand{\concaveHull}{R}
\newcommand{\feasibilityRegion}{F}
\newcommand{\fullUserSet}{N}
\newcommand{\taskScheduler}{\mathcal{X}}

\newcommand{\succS}[1]{\succ_{#1}}
\newcommand{\succeqS}[1]{\succeq_{#1}}
\newcommand{\precS}[1]{\prec_{#1}}
\newcommand{\preceqS}[1]{\preceq_{#1}}

\newcommand{\myComments}[1]{}	

\newif\ifinfocom
\infocomfalse

\newif\iftompecs
\tompecstrue

\newif\iftompecsonly
\tompecsonlyfalse

\newif\iftompecsextended
\tompecsextendedtrue

\newif\ifdissertation
\dissertationfalse

\newif\ifhuawei
\huaweifalse

\newcommand{\infocomStart}{\ifinfocom \myComments{Infocom: }}
\newcommand{\tompecsStart}{\iftompecs \myComments{TOMPECS version: }}
\newcommand{\tompecsonlyStart}{\iftompecsonly \myComments{TOMPECS only version: }}
\newcommand{\tompecsextendedStart}{\iftompecsextended  \myComments{TOMPECS extended version: }}
\newcommand{\dissertationStart}{\ifdissertation  \myComments{Dissertation version: }}
\newcommand{\huaweiStart}{\ifhuawei  \myComments{Huawei version: }}

\newcommand{\commentEnd}{\myComments{End}}

\newcommand{\add}[1]{#1}



\begin{document}

\markboth{Y. Du and G. de Veciana}{Scheduling for Cloud-Based Computing Systems to Support Soft Real-Time Applications}

\title{Scheduling for Cloud-Based Computing Systems to Support Soft Real-Time Applications}
\author{YUHUAN DU and GUSTAVO DE VECIANA
\affil{The  University of Texas at Austin}
}

\begin{abstract}
Cloud-based computing infrastructure provides an efficient means to support real-time processing workloads, e.g., virtualized base station processing, and collaborative video conferencing. This paper addresses resource allocation for a computing system with multiple resources supporting heterogeneous soft real-time applications subject to Quality of Service (QoS) constraints on failures to meet processing deadlines. We develop a general outer bound on the feasible QoS region for non-clairvoyant resource allocation policies, and an inner bound for a natural class of policies based on dynamically prioritizing applications' tasks by favoring those with the largest (QoS) deficits. This provides an avenue to study the efficiency of two natural resource allocation policies: (1) priority-based greedy task scheduling for applications with variable workloads, and (2) priority-based task selection and optimal scheduling for applications with deterministic workloads. The near-optimality of these simple policies emerges when task processing deadlines are relatively large and/or when the number of compute resources is large. Analysis and simulations show substantial resource savings for such policies over reservation-based designs.
\end{abstract}

\keywords{Soft real-time applications, cloud-computing, non-clairvoyant resource allocation, feasibility region, largest deficit first, greedy task scheduling, task selection and optimal scheduling, efficiency ratio}

\begin{bottomstuff}
\add{
This research was supported by Huawei Technologies Co. Ltd.}

\add{A conference version of this paper has been accepted to INFOCOM 2016. 
}
\end{bottomstuff}

\maketitle


\section{Introduction}
\label{sec_introduction}
The shift towards delivering compute platforms/services via cloud-based infrastructure is well on its way. 
An increasing number of the applications/services migrating to the cloud involve 
real-time computation with processing deadlines and where failure to meet the deadlines degrades user's Quality of Service (QoS). Such infrastructure allows one to reap 
the significant benefits of cloud computing, e.g., reduced cost of sharing computing, hoteling and cooling resources, 
along with increased reliability and energy efficiency. In this paper, we focus on Soft Real-Time (SRT) applications 
which can tolerate occasional violations of processing deadlines but still need to meet 
QoS or Service Level Agreements (SLA). 

\infocomStart
An example of such a platform is the Cloud-based Radio Access Network (CRAN) \cite{CMW, BLS14A, DuD14A} being considered for next generation cellular deployments. Instead of co-locating dedicated compute resources next to base station antennas, they virtualize compute resources for baseband processing. To do so, the received uplink signals associated with wireless subframes are sampled and sent from antennas to the cloud for timely decoding and processing such that
downlink signals requiring timely channel measurements, acknowledgements, etc., 
can be sent back to antennas for transmission. This process must happen within 
several milliseconds as determined by the cellular system standards. 
In this setting shared compute resources may occasionally fail to complete subframe processing on time, 
but this must happen infrequently, i.e., QoS/SLA requirements must be met. 
In fact, different tasks may have different QoS/SLA requirements. For example, failures in subframe baseband processing should be very infrequent whereas failures for tasks associated with channel measurement/estimation might be acceptable once every few subframes \cite{PCO}. 
Other SRT applications including collaborative video conferencing, multimedia processing, real-time control, augmented reality platforms, have similar characteristics. 
\commentEnd\fi

\tompecsStart
An example of such a platform is the Cloud-based Radio Access Network (CRAN) \cite{CMW,BLS14A,DuD14A} being considered for next generation cellular deployments. Instead of co-locating dedicated compute resources next to base station antennas, they virtualize compute resources for baseband processing. To do so, the received uplink signals associated with wireless subframes are sampled and sent from antennas to the cloud for timely decoding and processing such that
downlink signals requiring timely channel measurements, acknowledgements, etc., 
can be sent back to antennas for transmission. This process must happen within 
several milliseconds as determined by the cellular system standards. 
In this setting shared compute resources may occasionally fail to complete subframe processing on time, 
but this must happen infrequently, i.e., QoS/SLA requirements must be met. 
In fact, different tasks may have different QoS/SLA requirements. For example, failures in subframe baseband processing should be very infrequent whereas failures for tasks associated with channel measurement/estimation might be acceptable once every few subframes \cite{PCO}. 
Other SRT applications including multi-party collaborative video conferencing, multimedia processing, real-time control systems, augmented reality platforms, etc., have similar characteristics. 
\commentEnd\fi


\dissertationStart
Another example of an SRT service would be services associated with distributed multi-party collaborative video conferencing or educational applications. 
In this setting multiple participants at varied locations send their video and content 
to a processing center where it is combined, tailored, transcoded and sent back to distributed attendees 
in possibly distributed locations with different resolutions or points of view, etc.
In interactive settings, one must ensure small end-to-end delays and thus 
tight processing delays.  
Still in many cases, it is acceptable that some video frames not be delivered
on time without substantially impacting user perceived quality of experience. 
\commentEnd\fi

\dissertationStart
Google glass and other augmented reality platforms share similar characteristics to the above examples. 
In such applications, a stream of local observations including video/sound could be sent to computing centers for processing, e.g., 
face and activity recognition, and results returned for display. To ensure ``fluidity'' the turnaround for such 
processing must be quite tight yet such applications may tolerate occasional failures in 
meeting processing deadlines if they are handled properly. 
\commentEnd
\fi

The computing infrastructure, e.g. \cite{VPK15A}, to support such applications may involve a large number of heterogeneous servers, e.g., 
various generations of processors, which themselves have multiple cores, special purpose hardware, shared memories/caches, etc. 
In other words, a complex collection of resources must be orchestrated to efficiently  
meet applications' SRT requirements. In this paper we focus on a single computing system, e.g., managed server/center, 
shared by a set of users, corresponding to SRT applications, that periodically generate workloads. The traditional management approach is to allocate dedicated resources to users to meet their QoS requirements. However, given the typical uncertainty in users' workloads and ``interference'' across shared resources, doing so typically involves over-provisioning. 

Computing systems today are engineered so as to permit prioritization 
of one user over another, e.g., production vs. non-production tasks, which in turn translates to priority in accessing
shared compute resources and/or memory. 
In this paper we consider resource allocation policies which can {\em dynamically} prioritize users in each period. 
Such dynamic prioritization of users would typically
reduce the required resources vs. static allocations, and is further flexible to changes in users' workload characteristics or QoS requirements.



Given a set of users and a computing system, here are some key questions of interest:
\begin{longitem}
\item What QoS requirements are feasible? 
\item Can we design simple efficient resource allocation policies meeting users' QoS requirements and characterize the performance of these policies? 
\item Compared with dedicated resource allocation, what kinds of reductions in resource requirements can one expect from enabling dynamic resource sharing? 
\end{longitem}

In the sequel we will address these basic questions and more, but we first turn to related work. 

{\bf \em Related Work. }
\label{subsection_related_work}
There is a substantial body of work on scheduling real-time tasks. 
Starting with \cite{LiL73}, the community has established theoretical frameworks to study the scheduling of real-time applications where tasks are subject to hard deadlines, see e.g., \cite{Liu00b,DaB11,CFH04,Leu89}. The results typically assume worst case execution times/workloads and are too conservative for SRT applications.  

Different models have been introduced for the QoS needs of Soft Real-Time (SRT) applications. 
The work in \cite{HaR95,BeB97,Ram99} proposes the notion of -firm deadlines requiring at least  out of any  consecutive tasks complete by their deadlines. 
But many services do not need such tight requirements and \add{the analytical results typically require deterministic workloads}. 
The authors in \cite{LLN87,HoK13b} consider imprecise computation models where each task consists of a mandatory part, which needs to complete by the deadline, and an optional part which improves the computational results. This is a reasonable model for tasks like artificial intelligence computation since additional optional iterations improve the results. However, many real-time tasks do not contain optional part and some of these tasks can miss the deadlines up to some degree. 
The work in \cite{LiA09} aims to guarantee bounded maximum deadline tardiness for all users. 
However, these frameworks and QoS models are not suitable for applications like CRAN and video conferencing where it is useless to process a task after its deadline and it is better to simply drop the task if it misses the deadline. 

This paper focuses on an SRT QoS model where a bound on the fraction of tasks completed on time is the QoS requirement. 
Such a model was first introduced in \cite{AtB98} where the authors propose a static allocation approach to meet such a QoS requirements. We shall use this as an evaluation benchmark. 
More recently, the authors in \cite{HoK13b,HoK12} adopt this QoS model to study a wireless access point supporting users that periodically generate packets which need to be transmitted within that period, and propose simple ``optimal'' scheduling policies. However, their results are limited to the setting where only one user can transmit at a time and where packet transmissions can be viewed as tasks with geometrically distributed workloads. 


In this paper we consider prioritization policies that use the idea underlying longest-queue-first policies, whose performance has been studied in \cite{DiW06,JLS07,KWJ13} but in different settings. Moreover, the scheduling problem we consider is more than just one of ordering users according to a policy such as largest-deficit-first. We also need to design the task scheduler to allocate resources to tasks across a computing system's cores. 

Work on stochastic scheduling, e.g., \cite{BCS74,LLK93,Pin12b,AGG10,BDW86,AlS03} considers how to schedule a set of tasks with random workloads on multiple cores and aims to find a single schedule to minimize some objective function. Most of this type of work does not consider task completion deadlines and focuses on minimizing the expected completion time of the last task or the average expected completion time of all tasks. Moreover, such work typically assumes exponential workloads in order to get analytical results.  

Additional related work include those studying the mixing of real-time and non real-time traffic, see e.g., \cite{ShS01,JaS11,PaD07}, 
and those studying user/job management, see e.g., 
\cite{AAB00,MTH11,DeK14}. 

\dissertationStart
There is a substantial body of work on the study of scheduling users/services with streams of real-time tasks. 
Starting with \cite{LiL73A} the community has established solid frameworks for hard real-time services where all tasks need to be completed by deadlines and any violation is considered as a system failure \cite{Liu00b} \cite{DaB11A}. The results typically assume worst case execution times/workloads which can be much larger than the average case and cause inefficient utilization of the computing systems. However, for many soft real-time applications such as in the CRAN or video conferencing context, it is acceptable to miss the deadlines up to a limited failure rate as long as some QoS requirements are guaranteed. Moreover, these services typically have uncertainties in the workloads. 

In the literature, there are different models for the QoS requirement of soft real-time services. The work in \cite{HaR95A}, \cite{BeB97A} proposes the notion of -firm deadlines which requires that for each user at least  out of any  consecutive tasks must be completed by their deadlines. But many services do not need such tight requirements. The authors in \cite{LLN87A}, \cite{HoK13bA} consider imprecise computation model where each task consists of a mandatory part which needs to be completed by the deadline and an optional part which improves the computational results but can always be dropped if the compute resource is limited. This is a reasonable model for tasks like artificial intelligence computation since additional optional iterations improve the results. However, many real-time tasks do not contain optional part that can always be dropped and the tasks can miss the deadlines up to some degree. The work in \cite{LiA09A} aims to guarantee bounded deadline tardiness for all users. The tardiness of a task is defined as the delay from the task deadline to the actual task completion time, and the tardiness for a user is the maximum tardiness of any of its tasks. But in some services like video conferencing and CRAN, it is useless to process a task after its deadline and it is better to simply drop it if the task misses the deadline. 

In this paper we focus on a soft real-time service model where users periodically generate tasks of random workloads and propose time-averaged number of tasks completed on time per period as QoS requirements. Such a QoS requirement model is first introduced in \cite{AtB98A} and recently adopted by \cite{HoK13bA} \cite{HoK12A} to study packet transmission in a wireless context. The authors in \cite{AtB98A} propose to meet the QoS requirements by allocating each user a fixed amount of time in each period where the amount of time is computed based on the workload distributions and the QoS requirements. But such an approach is not efficient when the workloads have large uncertainties. In this paper we use this as a benchmark to evaluate the performance of our approaches. 

The authors in \cite{HoK13bA} \cite{HoK12A} consider a wireless access point supporting users which periodically generate packets (tasks) that need to be transmitted within that period over independent heterogeneous unreliable wireless channels. 
The access point schedules only one user at each discrete time unit and the scheduled user transmits the packet successfully with some probability. 
For this setting, the authors propose simple scheduling policies which are shown to be ``optimal''. However, their results are restricted to the simplified setting. 
Since only one user can transmit at a time, the access point can be viewed as a simple single core. Considering packet transmissions as tasks then the transmission time corresponds to the tasks' workloads and is geometrically distributed, which has the memoryless property. In this paper we propose a general framework involving multiple cores and where users may generate generally distributed workloads, and we characterize the performance of some simple approaches. We will see that the model and results in these prior work is a special case of our work. 

Some additional work including \cite{ShS01A} \cite{JaS11A} studies mixing real-time and non real-time traffic, but considers restricted wireless models. The authors in \cite{DaB11A} \cite{SAA04} provide a more comprehensive review for real-time scheduling. 

In our proposed approach we use the idea of longest-queue-first policy whose performance is studied in \cite{DiW06} \cite{KWJ13A} but in different context. The work in \cite{DiW06} proposes sufficient conditions for the optimality of longest-queue-first policy in a generalized switch model which is different from our soft real-time framework in terms of task completion deadlines and random execution process in each period depending on the schedule and the workloads. 
The authors in \cite{KWJ13A} study the performance of a largest-deficit-first policy in a wireless setting where a set of links with QoS requirements may interfere with each other and at each time the system picks a set of links that do not interfere. But the mutually excluded interference model and assumption of constant service rate may not fit beyond wireless context. Moreover, the scheduling problem we will consider is more than just one of ordering users according to some policies like largest-deficit-first. We also need to design the task scheduler to coordinate the scheduling of tasks across cores. 

The problem of stochastic scheduling \cite{Pin12b} considers to schedule a set of tasks with random workloads on multiple cores and aims to find a single schedule to minimize some objective function. Most of these work focuses on minimizing the expected completion time of the last task or the average expected completion time of all tasks. And these work typically assume exponential workloads to get clean results. In our framework, in each period we also have to schedule tasks with random workloads across cores, but we need to finish tasks before deadlines and moreover we look at the long-term time-averaged effect of changing schedules from period to period rather than the effect of a single schedule. Also we look at more general workloads. 
\commentEnd
\fi

{\bf \em Our Contributions. }
In this paper, we consider a computing system consisting of multiple resources and study the scheduling of SRT users' random workloads subject to QoS constraints on timely task completions. To our knowledge, we are the first to give a theoretical 
characterization of the feasibility region for this general SRT framework and to consider performance and near-optimality of simple efficient scheduling policies. 
The contributions of this paper are threefold. 

First, we propose a general framework for SRT user scheduling on multiple resources, albeit we assume the workloads are New Better than Used in Expectation (NBUE) type. 
\dissertationStart
The authors believe it is a novel contribution to look at NBUE random workloads that characterize many workload distributions of interest and lead to nice results. 
\commentEnd\fi
In this framework, we develop an outer bound for the set of feasible QoS requirements for all possible non-clairvoyant resource allocation policies. 

Second, we study resource allocation policies which prioritize users based on Largest ``Deficit'' First (LDF) in each period and schedule tasks accordingly. We develop a general inner bound for the feasibility region for this class of policies. 
This enables us to study the efficiency of two policies: (1) LDF-based greedy task scheduling for users with variable workloads, and (2) LDF-based task selection and optimal scheduling for users with deterministic workloads. 
These simple policies are near-optimal when the deadlines are relatively large, and/or the number of resources is large. 


Finally, we evaluate the performance of the proposed policies in terms of the required number of resources to fulfill a given set of users' QoS requirements. 
We exhibit substantial savings versus a traditional reservation-based approach in various system settings. 
We also discuss generalizations of our results when the resources have different processing speeds. 

{\bf \em Paper Organization. }
The paper is organized as follows: Section 2 introduces our system model and Section 3 describes a reservation-based approach and a general outer bound for the feasibility region. Section 4 discusses two prioritization-based policies and studies their efficiency ratios. Simulation results are exhibited in Section 5. Section 6 discusses generalizations and Section 7 concludes the paper. Some of the proofs are provided in the Appendix.


\section{System Model}
\label{sec_system_model}
We first introduce our user, system and QoS models. 

\subsection{Soft Real-Time (SRT) User Model}
We consider a computing system shared by a set of users . 
The system operates over discrete periods . We denote by  the length of a period.
In each period each of the  users generates exactly one task. 
These tasks are available for processing at the beginning of the period, and need to complete by the end of the period. 
Tasks not completed on time are dropped, i.e., cannot be processed in subsequent periods. 
Here we assume a task is the unit of scheduling, i.e., a task cannot be processed in parallel. 

\dissertationStart
We consider a system wherein  users indexed from  to  share a centralized computing system. Let  be the user set. 
The system operates in discrete time, over periods . We denote by  the length of a period. 
The users generate streams of tasks periodically. Specifically in each period, each of the  users generates exactly one task. 
These tasks are available for processing, i.e., released, at the beginning of the period, and need to complete by the end of the period. 
Tasks not completed on time are dropped, i.e., cannot be processed in subsequent periods. 
Figure~\ref{figure_task_generation} exhibits the above task generation process. 
Here we assume a task is the unit of scheduling, i.e., a task cannot be processed in parallel on multiple compute resources. 
In the sequel we will discuss generalizations where a task contains dependent sub-tasks. 
\commentEnd\fi

\dissertationStart
\begin{figure}[htp]
  \centering
  \includegraphics[width=0.4\textwidth]{Figures/task_generation.pdf}
  \caption{An example illustrating the task generation model. It shows the start and end points of periods. Each down and up arrow represents the release time and deadline of a task, respectively. }
  \label{figure_task_generation}
\end{figure}
\commentEnd\fi

The workload of a task will refer to its resource requirement or service time. If a task's workload is large it may not be possible to complete on time. 
A task's workload is modeled by a random variable whose distribution captures variability in its resource requirement and/or uncertainty in the computing system, e.g., caused by memory contention across the cores. 
We assume task workloads for a given user are independent and identically distributed 
\tompecsStart
(i.i.d.)
\commentEnd\fi
across periods and workloads from different users are independent, possibly with different distributions. Let  be a random variable denoting the workload of a task from user  and let . 
Next we introduce a further assumption on task workloads which seems reasonable for SRT users and will enable theoretical analysis. 

\begin{definition}
\infocomStart
A non-negative random variable  is said to satisfy {\bf New Better than Used in Expectation (NBUE)} if for all , 
\commentEnd\fi
\tompecsStart
A non-negative random variable  is said to satisfy {\bf New Better than Used in Expectation (NBUE)} if for all , 
\commentEnd\fi

\end{definition}
\dissertationStart
The exponential and geometric distributions are special NBUE distributions since they result in equality in the above for all  and for all integers , respectively. 
\commentEnd\fi
\dissertationStart
The notion of NBUE, see, e.g., \cite{MuS02b}\cite{ShS07b}, captures workload/lifetime distributions where the expected residual workload/lifetime of a task/device of age  is no more than that of a new task/device. 
By \cite{ShS07b} the set of NBUE distributions is closed under convolution. Formally one can show the following results:
\begin{proposition}
\label{prop_NBUE_closure}
The NBUE property satisfies the following, 
\begin{itemize}
\item If two independent random variables  are NBUE, then  is NBUE. 
\item If a random variable  is NBUE, then for all real numbers ,  is NBUE. 
\end{itemize}
\end{proposition}
\myComments{end}
\fi
In this paper we shall assume all task workloads are NBUE. 

The NBUE property characterizes many workload distributions of interest. \cite{MuS02b} provides a discussion of NBUE distributions which include, but are not limited to, exponential, gamma with shape parameter  and deterministic distributions. 
A common class of distributions that are not NBUE is the heavy-tailed one. However since tasks need to complete within a period\footnote{In fact, we only require (\ref{align_NBUE}) to be true for . }, we are not likely to encounter tasks with such tails in the settings under consideration.  

\dissertationStart
The NBUE property characterizes many workload distributions of interest. By \cite{MuS02b} NBUE distributions include but are not limited to exponential distribution, gamma distribution with  and deterministic distribution (constant). 
Moreover, many distributions which are not NBUE can be closely approximated by NBUE distributions. For example, the normal distribution can be approximated by gamma distribution with large . 
A common class of distributions that are not NBUE is the heavy-tailed one. However since in this setting tasks must complete within , we only require (\ref{align_NBUE}) for  and thus are not likely to care about such tails in practice.  
\commentEnd\fi

We shall assume that each user  has a QoS requirement given by a minimal long-term average number of tasks completed on time per period, denoted by  where . 
We let  and 
assume 's are rational\footnote{All the results in this paper can be generalized to 's with irrational values. For simplicity in the proof we do not consider that level of generality. }.

Let us consider some examples. An SRT user might correspond to the processing associated with a set of co-located cellular antennas in the CRAN context or an end user in video conferencing. 
Accordingly, the period  would correspond to a wireless subframe or the length of a group of video frames, respectively. 
\dissertationStart
In CRAN each antenna generates a task associated with each subframe. Depending on the traffic and wireless channels, the tasks may take different CPU time and resources to process. 
\commentEnd\fi
For SRT users, it is generally useless to process a task after its deadline. For example, in video conferencing it is not desirable to display an out-of-date frame. This is why in this model tasks not completed on time are dropped. 
\infocomStart
In the extended version of this paper \cite{EXT}, 
\commentEnd\fi
\tompecsStart
In Section \ref{section_possible_generalizations}, 
\commentEnd\fi
we discuss possible generalizations where users may generate tasks with different periods and where a task may further consists of sub-tasks. 

\subsection{Computing Infrastructure}
A computing system can be very complex consisting of diverse, heterogeneous resources. 
In this paper, for simplicity of explanation we start with a computing system comprising of  identical resources (cores)\textemdash a simple but relevant model. 
In Section 
\infocomStart
\ref{section_generalizations} 
\commentEnd\fi
\tompecsStart
\ref{section_possible_generalizations}
\commentEnd\fi
we discuss generalizations where cores have different processing speeds. 

Given  identical cores, a task processed on any core requires the same processing time and each core can process only one task at a time. 
\dissertationStart
In this context, the workload of a task refers to the required core time to fully complete the task. 
\commentEnd\fi
In each period, the computing system dynamically schedules tasks according to a given strategy. Given the resource limit and the randomness of workloads, some tasks complete on time and some may fail. 

Unless otherwise specified we allow task preemption/migration, i.e., interrupting a task being processed and resuming later on the same/different core. We shall ignore the overheads of these operations. But in practice these operations involve context switching, and therefore, policies with minimal preemption and migration are desirable. 

A resource allocation policy is said to be {\em non-clairvoyant} if it does not make use of information regarding future events, such as tasks' workload realizations, which are not generally known until the tasks complete. However, a non-clairvoyant resource allocation policy may still have knowledge of a user's task workload distribution, which can be obtained from the history events or repeated experiments. We shall only consider non-clairvoyant resource allocation policies. 

In our model a ``core'' represents the minimum unit of compute resource such as physical computing core, specialized hardware, or hyper-thread as appropriate. The computing system could be a cloud-based cluster of machines or a centralized server with a collection of processors/cores. There are many possible non-clairvoyant resource allocation policies which may involve exploiting knowledge of workload distributions, exploiting history events, preempting tasks at appropriate times, dynamically prioritizing tasks, etc. 

\subsection{SRT QoS Feasibility}
Given a requirement vector , a computing system and a non-clairvoyant resource allocation policy, how do we verify if  is feasible?  
To keep track of the deficit among users' QoS requirements and actually completed tasks, for each user  and period , we define\footnote{We truncate the deficit at  via  simply for the convenience of defining feasibility. Removing the truncation does not change the results in the paper. }

where  and  is an indicator random variable which takes value  if user 's task completes in period . 
\infocomStart
The deficit vector  is a summary of the history of events up to period . 
\commentEnd\fi
\tompecsStart
We let  denote the deficit vector.  is a summary of the history of events up to period . 
\commentEnd\fi

We shall say that the long-term QoS requirement  for user  is met if and only if  is ``stable''. 
Formally, in this paper we consider non-clairvoyant resource allocation policies under which the process  is a Markov chain\footnote{
\infocomStart
All the results in this paper can be generalized to a broader range of non-clairvoyant policies and 's with irrational values, see \cite{EXT}. 
\commentEnd\fi
\tompecsStart
All the results in this paper can be generalized to a broader range of non-clairvoyant resource allocation policies under which some variation of  is a Markov chain. For example, if a resource allocation policy depends on the deficit vectors in the past two periods, then  is a Markov chain. For simplicity of explanation, we assume  is a Markov chain.
\commentEnd\fi
}. 
We assume the initial state , the QoS requirements  and the policy make  an irreducible Markov chain. 

\begin{definition}
\label{defn_feasibility_pr}
We say the QoS requirement vector  is {\bf feasible} if there exists a non-clairvoyant resource allocation policy  under which the Markov chain  is positive recurrent, i.e., this policy fulfills . 
We denote by  the feasibility region of policy , i.e., the set of QoS requirement vectors fulfilled by policy . The union of  over all allowable policies gives the {\bf system feasibility region} . 
\end{definition}

We shall refer to this model as SRT-Multiple Identical Cores (SRT-MIC) with NBUE workloads and the aim is to devise non-clairvoyant resource allocation policies that fulfill .

\dissertationStart
Note that different users may require different QoS . For example, in the CRAN context, soft real-time tasks include subframe baseband processing which requires  close to , and channel measurements, which only need to be updated every few subframes and require low , probably . 
\commentEnd\fi

In summary, the SRT-MIC model with NBUE workloads is an abstract system model which captures a family of systems supporting SRT users with random workloads. 
To summarize, the SRT-MIC model with NBUE workloads is parameterized by the number of cores , number of users , period length , QoS requirements , and the NBUE workload distributions. 


\section{Reservation-Based Static Sharing and Outer Bound for the System Feasibility Region}
\dissertationStart
In the next few sections we will analyze and compare several resource allocation policies for the SRT-MIC systems with the aim of motivating good policies for more complicated practical systems.
\commentEnd\fi 
\add{Clearly simple policies like Earliest Deadline First (EDF) do not apply in our setting. Indeed in our problem statement all users generate tasks
which have the same deadline at the start of the scheduling interval. In fact in the sequel (see Section 6) we will see that even if users generate tasks with
different deadlines EDF performs poorly because it does not take the soft QoS requirements  into account.}

In this section we introduce a reservation-based policy and a general outer bound for the system feasibility region  which applies to any non-clairvoyant resource allocation policy. These serve as benchmarks which enable us to evaluate the performance of the policies proposed in the sequel. 



\subsection{Reservation-Based Static Sharing Policies}
\label{subsection_reservation_based_design}
A straightforward and commonly adopted approach to meet users' QoS requirements  is to allocate dedicated resources, i.e., core time, to each user. For user , with task workload  and the requirement , we let  represent the minimum core time reservation needed to ensure the requirement is met. Specifically,  is given by

and thus, when  is close to ,  will approach the worst-case workload for user . 

{\em Reservation-based static sharing} policies allocate core time  to each user  in each period and the tasks from users are only processed in the corresponding allocated time. Figure~{\ref{fig_reservation_based_design}} exhibits an example with 2 cores. Note that in this example User 3's task first executes on Core 2 and later continues on Core 1. Therefore, a reservation-based static sharing policy, although seemingly simple, can be aggressive in requiring task preemption/migration and knowledge of workload distributions to compute  for all users. 

\begin{figure}[htp]
  \centering
  \includegraphics[width=0.45\textwidth]{Figures/reservation_based_design.pdf}
  \caption{An example of the reservation-based approach. }
  \label{fig_reservation_based_design}
\end{figure}

Note that since a task cannot be processed in parallel, if  exceeds the period length , the requirement for user  cannot be met. In this paper, we assume the task workloads and requirements  are such that  is bounded by . 

For a system with  identical cores, the feasibility region  of reservation-based static sharing is given by

where  means  for all . 
Clearly  comes from the fact that each user generates only one task in each period. 

This approach was perhaps first proposed in \cite{AtB98A} and is also loosely used in reservation based schemes adopted in modern cloud infrastructure, see e.g., \cite{VPK15A}. 
Cores are not used efficiently under such a policy. When the realization of a task workload is smaller than the allocated time, the remaining time is wasted and cannot be used to process other real-time tasks. 
Typically , e.g. \cite{VPK15A}, the resources are then used to support best effort traffic. 

\subsection{Outer Bound for the System Feasibility Region }
\label{subsection_outer_bound_for_F}
Ideally we aim to devise a policy that can fulfill all feasible QoS requirement vectors. More formally, a non-clairvoyant resource allocation policy  is said to be {\em feasibility optimal} if its feasibility region  is such that , where  and  is the interior and closure of , and thus is for practical purposes equivalent to the system feasibility region . 

\dissertationStart
Ideally we wish to devise a policy that can fulfill all feasible QoS requirement vectors. More formally, a non-clairvoyant resource allocation policy  is said to be {\em feasibility optimal} if its feasibility region  is such that , where  and  is the interior and closure of . In other words, a policy  is feasibility optimal if  is different from the feasibility region  by at most a boundary, and therefore, is equivalent to  for practical purposes. 
\commentEnd\fi

\dissertationStart
Intuitively, a feasibility optimal non-clairvoyant design will orchestrate task scheduling across the  cores. For example, the system might choose to process tasks with the maximum conditional probability of success to maximize the expected number of task completions in some periods while guaranteeing fairness and thus the required  of users in other periods. 
\commentEnd\fi

Given the heterogeneity and randomness of tasks' workloads and the large number of possible non-clairvoyant resource allocation policies, a feasibility optimal policy is unknown except for very specific resource and workload models, see e.g., \cite{HoK12A}. To solve this and to provide a benchmark to evaluate other resource allocation policies, we develop a simple outer bound  for the system feasibility region . 
Formally, we have the following theorem. 
\begin{theorem}
\label{thm_optimal_benchmark}
For the SRT-MIC  model with NBUE workloads, the system feasibility region  is such that 

\end{theorem}

Intuitively, if  tasks of user  are completed each period, the expected time spent on user  is roughly given by . To make  feasible, the total time spent on all users  cannot exceed the total available core time given by . 
This informal argument is perhaps deceptive. 
Note that in fact the expected time to complete the  tasks for user  in each period might be smaller than  since completed tasks might tend to have smaller workloads. This seems to imply that  could be smaller than  for some feasible . This is where the NBUE assumption on workloads is critical to the result. 
\infocomStart
See Appendix \ref{appendix_pf_R_OB} for a detailed proof. 

This simple outer bound applies to any non-clairvoyant resource allocation policy in any specific SRT-MIC system with NBUE workload distributions. 
Note however the result does not necessarily hold for non-NBUE workloads. See the extended version of this paper \cite{EXT} for an illustrative example. 
\commentEnd\fi

\tompecsStart
Note this simple outer bound applies only to non-clairvoyant resource allocation policies for a specific SRT-MIC system with NBUE workload distributions. 
A formal proof of the theorem is given below. 

\begin{proof}
Given a feasible QoS requirement vector , the goal is to show . 

Suppose  is fulfilled by a non-clairvoyant resource allocation policy , by definition  is positive recurrent and therefore, there exists a stationary distribution. 
We consider a typical period where the deficit vector  follows the stationary distribution and introduce further notation associated with period . To simplify notation, we will suppress the period index in this proof. 

For each user , we define  to be the indicator random variable that the task from user  completes in a typical period. By the Ergodic Theorem,  also represents the time-averaged number of task completions per period for user . If we view  as a queue, the average arrival  should not exceed the average departure . For each user subset , we define  to be a random variable denoting the total core time spent on users in  in a typical period. Clearly,  cannot exceed the total available core time . To show , it suffices to show that . To that end we first develop an equation connecting  and , and then use the NBUE assumption to show the inequality. 

We say a task is {\em unfinished} if it starts processing but does not complete in a given period. Let  be the indicator random variable that user 's task is unfinished in a typical period. Now if  it indicates that user 's task starts processing in the period though it may not have completed. 
For each user , we further define . Intuitively,  represents the ``residual workloads for user 's unfinished tasks''. 
Note that these random variables and their means depend on the policy . 

For each user subset , the total time spent on users in  can be written as

and by taking expectations, we get


Clearly , which indicates that user 's task starts processing, is independent of . Indeed this follows from the requirement that the resource allocation policy be non-clairvoyant, and the independence among users' task workloads. In a typical period under policy , the event that user 's task starts may depend on the workloads of others' tasks, but not on . 

Note that although  is independent of , in general  which indicates user 's task completes may depend on , i.e., . To better understand this, consider an extreme example. If , clearly the user 's task cannot complete implying that . Thus, . 
Similarly, we can argue  is not independent of . 

Still given the independence of  and , we have that


So (\ref{align_internal_exp}) becomes

This equation holds for all non-clairvoyant resource allocation policies and for all subsets of users . 


Now let . To show , by (\ref{align_subset_time_equation}) it suffices to show  for all users . We will show this is true under the NBUE workload assumption in the discrete-time scenario and it is straightforward to generalize the proof to the continuous-time scenario. 

Suppose each period contains  discrete time units. 
For all  and for , we let  denote the indicator random variable that user 's task is unfinished and is processed for  time units in a typical period. Clearly,  and . By the law of total probability, the expected residual workload  for user  can be written as

where . 
This is because under the non-clairvoyant design the event  tells nothing about  except that . 

By the NBUE workload assumption we know that  for  and therefore, we get the following inequality,

Note that the equality holds if all users' task workloads follow geometric distributions (or exponential distributions in continuous-time scenario), possibly with different parameters. 

To summarize, by (\ref{align_subset_time_equation}) and (\ref{align_ret_smaller_than_mean}) we know that given a feasible requirement vector , for all user subsets ,

which by letting  implies

and thus, 

\end{proof}

A key part of this argument is the inequality (\ref{align_required_workload_smaller_than_spent_time}), stating that for a feasible  the ``effective'' workload  for any user subset  should not exceed the total time spent on users in , which is bounded by . 
This holds under the NBUE workload assumption but may not be true if users have non-NBUE task workloads. For example, suppose all users generate tasks with non-NBUE workloads as follows, 

Clearly, the mean workload is . 
Let us consider such a policy. In each period, the system processes each task for exactly  time unit and stops if the task does not complete because given its workload distribution we know this task will require  more time units to complete. Suppose  and  is such that  and therefore, the system can process each task for  time unit per period. Under such a policy we know  for all user  and the total time spent per period is . Therefore, 

which is not consistent with (\ref{align_required_workload_smaller_than_spent_time}) and Theorem \ref{thm_optimal_benchmark}. 
Non-NBUE workloads are beyond the scope of this paper. Yet for real-time computing workloads we expect NBUE to be a good assumption. 
\commentEnd\fi


\section{Largest Deficit First (LDF) Based Policies}
Our aim is to devise a non-clairvoyant resource allocation policy that is easy to implement and whose feasibility region is near optimal. 
In this section we consider a specific class of policies, called {\em prioritization-based resource allocation} policies, which decompose resource allocation into two sub-problems, see Figure~{\ref{fig_prioritization_based_framework}}: 
\begin{enumerate}
\item \underline{User prioritization}: in each period the system dynamically prioritizes users based on the history of events. 
\item \underline{Task scheduler}: the system schedules users' tasks on cores based on their priorities. 
\end{enumerate}
There are still many options for each sub-problem. 
For example, task scheduling might be done greedily by simply scheduling the task with the highest priority, or using the priorities to first select a subset of tasks and then process that task subset via optimal scheduling policies. 

\begin{figure}[htp]
  \centering
  \includegraphics[width=0.55\textwidth]{Figures/framework_prioritization_based_design_infocom.pdf}
  \caption{The framework for prioritization-based resource allocation policies. }
  \label{fig_prioritization_based_framework}
\end{figure}

In this paper we shall prioritize users based on the Largest Deficit First (LDF) policy which is defined as follows. 

We let  denote a {\em priority decision} where  is the index of the user with  highest priority and  denote the set of all possible priority decisions.
\dissertationStart
and let  be the number of possible decisions. We shall assume no restrictions on the set of allowable priority decisions, so 
\commentEnd\fi

\begin{definition}
\label{defn_w_LDF}
The {\bf Largest Deficit First (LDF)} policy is such that, given the users' deficit vector , the priority decision  for period  is such that

with ties broken arbitrarily (possibly randomly). In other words, it sorts the deficits and assigns priorities accordingly. 
\end{definition}

The LDF user prioritization can be combined with different approaches of task scheduling. In the sequel we will explore such combinations and characterize their performance. 

\subsection{Inner Bound for Feasibility Region of LDF+}
\label{subsection_LDF}
Given a task scheduling policy , we let LDF+ refer to the resource allocation policy that combines LDF user prioritization and task scheduler .
In this subsection, we provide an inner bound for its feasibility region .   

We first introduce some further notation. 
Given a task scheduler, in each period, the task completions depend on the selected priority decision. We let  denote the expected number of tasks completed in a period for user  under priority decision  and let . Note that different task schedulers will correspond to different sets of vectors . 
We denote by  a positive vector  with  for all . For all user subsets , we let  be the number of users in  and we let  denote the set of all priority decisions that assign the highest  priorities to users in . 
The following theorem gives an inner bound on \taskScheduler. 
\begin{theorem}
\label{thm_R_IB}
Given a task scheduler  and thus the  dependent expected completion vectors , an inner bound for the feasibility region of the \tompecsStart resource allocation \commentEnd\fi policy LDF+ is given by
\taskScheduler 
where 

\end{theorem}

Intuitively,  is in  and is feasible under the LDF+ policy if there is a weight vector  such that for any subset of users , if the users in  are given the highest priorities, the weighted sum of the requirements  does not exceed the least weighted sum of the ``service rate'' . Again, different task schedulers  will have different vectors  and thus different inner bounds . 
\infocomStart
For a detailed proof, see the extended version of this paper \cite{EXT}. 
\commentEnd\fi
\tompecsStart
A proof is provided in Appendix \ref{pf_theorem_R_IB}. 
Note that Theorem \ref{thm_R_IB} applies beyond the SRT-MIC model when the LDF policy is used but in a general setting where  represent the expected payoffs under priority decision  and users require long-term time-averaged payoff  per period. The LDF policy can also be generalized to a class of weighted LDF policies. This general result is further developed in \cite{DuD16E}. 
\commentEnd\fi

Next we explore specific task schedulers and use Theorem \ref{thm_R_IB} to study their performance. 

\dissertationStart
Note that Theorem \ref{thm_R_IB} applies beyond the SRT-MIC model when the LDF policy is used but in a general setting where  represent the expected payoffs under priority decision  and users require long-term time-averaged payoff  per period. The LDF policy can also be generalized to a class of weighted LDF policies. This general result is further developed in [?]. 
\commentEnd\fi

\subsection{Performance Analysis of LDF+Greedy Scheduling}
Given an LDF-based user priority decision in each period, a natural way to allocate resources is to greedily process tasks from highest to lowest priority. Specifically, to start by putting the  tasks with the highest priority on the  cores and, once one of these tasks completes, continue by processing the task with priority  on the available core, etc.  

We let {\em LDF+Greedy} refer to the resource allocation policy that combines LDF and such a greedy task scheduler. Note this is easy to implement and does not require any a-priori knowledge of the tasks' workloads. Also this policy does not use task preemption or migration. 

Next we characterize the performance of LDF+Greedy. To that end, we introduce a metric called the efficiency ratio, see e.g., \cite{JLS07A}. The {\em efficiency ratio} of a non-clairvoyant resource allocation policy  is defined as 

Clearly  characterizes the performance gap between a policy  and the best possible way of orchestrating the scheduling of multiple tasks across multiple cores. Also  equals to  if and only if policy  is feasibility optimal. 

\begin{theorem}
\label{thm_LDF_greedy_eff_ratio}
For the SRT-MIC model with NBUE workloads, the efficiency ratio of LDF+Greedy exceeds  where

\end{theorem}

The intuition underlying this result is as follows. 
We say a task is {\em unfinished} if it starts processing but does not complete in a period.
The time spent on an unfinished task goes to waste since it does not contribute to a task completion. 
For LDF+Greedy, in one period, at most 1 task is unfinished per core and thus the wasted time on each core is expected to be less than . Given the period is of length , the gap between LDF+Greedy and optimality is bounded by . 
Note that again this argument is deceptively simplified since unfinished tasks might tend to have larger workloads. 
Also as for Theorem \ref{thm_optimal_benchmark}, this result does not necessarily hold for non-NBUE workloads. 
\infocomStart
A sketch of the proof of this result using Theorem \ref{thm_R_IB} is included in Appendix \ref{appendix_pf_gamma_LDF_Greedy} and detailed proof is provided in the extended version of this paper \cite{EXT}. 
\commentEnd\fi
\tompecsStart
The formal proof is given below. 
\commentEnd\fi

\dissertationStart
We first provide an intuitive way to understand this theorem. 
We say a task is {\em unfinished} if it starts processing but does not complete in a period.
If a task is unfinished the time spent on the task goes to waste since it does not contribute to a task completion. 
For LDF+Greedy, in one period, since at most 1 task is unfinished per core, the wasted time on each core is expected to be less than . Given the period length , the gap between LDF+Greedy and optimality is bounded by . 
Note that again this argument is deceptive since unfinished tasks might tend to have larger workloads. 
As for Theorem \ref{thm_optimal_benchmark}, this result does not necessarily hold for non-NBUE workloads. 
\commentEnd\fi

\tompecsStart
\begin{proof}
Given a requirement vector  fulfilled by resource allocation policy , by (\ref{align_required_workload_smaller_than_spent_time}) we know for all subsets of users , 

where  represents the time-averaged core time spent on users in  per period under policy . 

During each period, the total time  spent on users in  is bounded by the total task workload  of users in  and the total available core time . 
We define  and therefore, for all user subsets , we have that


Thus, for a vector  satisfying (\ref{align_proof_LDF_greedy_necessary_condition}) the aim to show  which is equivalent to showing . By Theorem \ref{thm_R_IB}, it suffices to show that .
In LDF+Greedy, the expected vector  described in Section \ref{subsection_LDF} represents the expected numbers of timely completions under greedy task scheduler under priority decision .  
Therefore,  follows if one can find a vector  such that for all , 

We will show  satisfies the above condition. By (\ref{align_proof_LDF_greedy_necessary_condition}) it suffices to show for all ,

which is equivalent to showing for any given user subset  and priority decision  that


First we rewrite  by similar approach used to obtain (\ref{align_subset_time_equation}). 
As in the proof of Theorem \ref{thm_optimal_benchmark}, for each subset of users  and each user , 
we let ,  and  denote the time spent on users in , the indicator random variable that user 's task is unfinished and the residual workload of user 's unfinished tasks in a period under the greedy task scheduler with priority decision , respectively. 


By (\ref{align_subset_time_equation}), for the given  and , we have that


Now (\ref{align_gamma_exp_T_S_leq}) follows by showing that

and 

respectively. 

To demonstrate (\ref{align_exp_U_S_plus_E}), it suffices to show for each workload realization, 

where  are realizations of , respectively. 

If , clearly . Otherwise, . Since  assigns the highest priorities to users in , by greedy task scheduler  implies that at the end of the period no task from users in  is waiting to be scheduled, i.e., all tasks from users in  start processing and therefore, , where  represents the realization of workload . Therefore, (\ref{align_exp_U_S_plus_E}) is verified. 

Now it remains to show (\ref{align_wasted_smaller_than_fraction_of_total}). 
Clearly we have that

Thus, to demonstrate (\ref{align_wasted_smaller_than_fraction_of_total}) it suffices to show that



We define  to be the number of unfinished tasks in a period from users in  under greedy task scheduler under priority decision . Since there are at most  unfinished tasks, we have . 

Under greedy task scheduling, for  we claim  implies  for . This is true because  means there are  unfinished tasks on  different cores, implying these  cores are busy processing tasks from users in  throughout the period.
Therefore,  and thus . 


By this claim, we can get that



This proves 
(\ref{align_num_unfinished_tasks_leq}) 
which in turn shows (\ref{align_gamma_exp_T_S_leq}) and therefore,


\end{proof}
\commentEnd\fi

Theorem \ref{thm_LDF_greedy_eff_ratio} provides a lower bound on the efficiency ratio of LDF+Greedy, denoted by . The bound is tight in the sense that for any , there exists an SRT-MIC  system with NBUE workloads such that . 
\infocomStart
Such a system is also detailed in \cite{EXT}. 
\commentEnd\fi
\tompecsStart
Such a system is detailed in Appendix \ref{appendix_example_showing_theorem_LDF_Greedy_eff_ratio_is_tight}. 
\commentEnd\fi

\dissertationStart
Intuitively,  represents the worst case ratio of wasted resources (core time)  under LDF+Greedy to the total available resources . 
\commentEnd\fi

It follows that if , then  is close to , i.e., LDF+Greedy is close to optimal. This is true when the task workloads are small relative to the core processing speed. 

However, when  is comparable to , the efficiency ratio lower bound  is small, 
although in some scenarios LDF+Greedy may still be efficient. For example, LDF+Greedy is feasibility optimal if the task workloads of all users follow the same exponential (or geometric) distribution, 
or prior work in \cite{HoK12}. 
This is due to the memoryless property of the exponential (or geometric) distribution. 
We omit the proof here. 
Still in some scenarios where we know more about the task workloads it is interesting to explore other simple policies that perform better than LDF+Greedy, especially when  is comparable to the maximum mean workload. That motivates the discussion in the next subsection. 

\subsection{Performance Analysis of LDF+TS/LLREF Scheduling under Deterministic Workloads}
\label{subsection_LDF_TS_LLREF}
In this subsection, we consider systems where users generate tasks with deterministic, but possibly different, workloads, i.e.,  for all . 
For soft real-time users that can tolerate missing some deadlines, even if they generate tasks with deterministic workloads, one can still intentionally drop a fraction of tasks in each period while guaranteeing the users' long-term QoS requirements. 
Selecting a subset of tasks to be processed in each period is like a bin backing problem. And to fulfill the long-term soft QoS requirements, one need to dynamically change or rotate the selected task subset. 


Note deterministic workloads satisfy the NBUE property. Also note that for deterministic workloads, non-clairvoyant policies have knowledge of workload realizations. 
We shall once again prioritize users using LDF prioritization. 
Intuitively, the greedy task scheduler wastes time on multiple cores if multiple tasks are unfinished at the end of a period, so we will devise a task scheduler that orchestrates across cores so as to ``reduce'' wasted core time to finish more tasks. 

For deterministic workloads, one can assess how many tasks one can complete prior to initiating processing. 
Indeed, it is intuitive, and established in \cite{CRJ06}, that one can complete all tasks in a user subset  in a period by some optimal scheduling if and only if . We consider one such optimal algorithm: Largest Local Remaining Execution time First (LLREF) \cite{CRJ06}. Let us briefly describe how LLREF\footnote{LLREF is defined to be applicable in more general settings where users might generate tasks with different period. We will discuss this in Section \ref{section_possible_generalizations}. } would work in the SRT-MIC model and then introduce a task scheduler that combines the idea of task selection and LLREF scheduling. 

To that end we introduce some terminology used in \cite{CRJ06}. Consider a period starting at time  and ending at time  , at any time , the {\em Local Remaining Execution time (LRE)} of user  is defined as the remaining time needed to complete its task. The LRE decrements as the task is processed. 
Further, the {\em laxity} of user  is defined as the remaining time before the deadline of user 's task, i.e., , minus the current LRE of user . Thus, if some user has zero laxity at some time, one needs to start processing the task immediately to complete it by its deadline. 

\begin{definition}
\label{defn_LLREF}
For the SRT-MIC model with deterministic workloads, the {\bf Largest Local Remaining Execution time First (LLREF)} policy is such that, given a selected user subset  for the period, it does the following: 
\begin{enumerate}
\item At the beginning of the period,  tasks associated with users in  are chosen to be processed according to largest LRE first.
\item When a running task completes, or a non-running task reaches a state where it has zero laxity, again the  tasks in  with largest 
\infocomStart
LRE
\commentEnd\fi
\tompecsStart
local remaining execution time
\commentEnd\fi
are selected to be processed. 
\end{enumerate}
\end{definition}
Note that the LLREF policy uses task preemption and possibly migration. A review of variants of LLREF aimed at reducing task preemptions is provided in \cite{DaB11A}. 

\dissertationStart
Now we propose the following task scheduler. The framework is exhibited in Figure~{\ref{fig_LDF_TS_LLREF_framework}}. 
\commentEnd\fi

\begin{definition}
\label{defn_TS_LLREF}
The {\bf Task Selection/LLREF (TS/LLREF)} task scheduler is such that, given the user priority decision  for a period, it does the following: 
\begin{enumerate}
\item Task selection: it greedily selects users based on  until the sum workload exceeds . More formally, it selects

Let  represent the selected user subset. 
\dissertationStart
subset\footnote{One trivial way to extend the task selection step is to continue checking users greedily according to  and adding users to  while guaranteeing . But that does not improve the results in the sequel and therefore, we do not discuss this extension. }. 
\commentEnd\fi
\item LLREF for : the system uses LLREF scheduling for tasks in  in this period. 
\end{enumerate}
\end{definition}
By \cite{CRJ06A}, it follows that all tasks from  will complete. 

\dissertationStart
\begin{figure}[htp]
  \centering
  \includegraphics[width=0.55\textwidth]{Figures/framework_LDF_TS_LLREF.pdf}
  \caption{The framework for LDF+TS/LLREF design. }
  \label{fig_LDF_TS_LLREF_framework}
\end{figure}
\commentEnd\fi

Paralleling Theorem \ref{thm_LDF_greedy_eff_ratio}, we have the following result for the LDF+TS/LLREF resource allocation, i.e., the combination of LDF user prioritization and TS/LLREF task scheduling. 
\dissertationStart
The framework of LDF+TS/LLREF is exhibited in Figure{~\ref{fig_LDF_TS_LLREF_framework}}. 
\commentEnd\fi

\begin{theorem}
\label{thm_LDF_TS_LLREF_eff_ratio}
For the SRT-MIC model with deterministic workloads, the efficiency ratio of LDF+TS/LLREF exceeds  where

\end{theorem}

Intuitively, under TS/LLREF, the task selection rule guarantees that in any given period the wasted time  is less than . Given the total available core time , the gap between LDF+TS/LLREF and optimality is again bounded by the fraction of wasted time, i.e.,  . A formal proof of this result is similar to that of Theorem \ref{thm_LDF_greedy_eff_ratio} and is provided 
\infocomStart
in the extended version of this paper \cite{EXT}. 
\commentEnd\fi
\tompecsStart
in Appendix \ref{appendix_pf_thm_LDF_TS_LLREF_eff_ratio}. 
\commentEnd\fi

The efficiency ratio lower bound  in this theorem is better than  obtained in Theorem \ref{thm_LDF_greedy_eff_ratio}, specifically the dependence on  is much stronger. For a system with a large number of cores ,  is close to , i.e., LDF+TS/LLREF is close to feasibility optimal even if  is comparable to . 

\dissertationStart
Under the more general NBUE (but not deterministic) workload assumption, if we somehow know the workload realizations at the beginning of each period, 
we can still adopt the LDF+TS/LLREF policy where the task selection is based on workload realizations. By similar proof as that for Theorem \ref{thm_LDF_TS_LLREF_eff_ratio} we can get the following corollary:
\begin{corollary}
For the SRT-MIC model with random NBUE workloads, if a QoS requirement vector  can be fulfilled by some non-clairvoyant design, then under LDF+TS/LLREF which is clairvoyant , where

\end{corollary}

In this corollary we are only comparing with non-clairvoyant designs, but note that in this scenario the LDF+TS/LLREF is a clairvoyant design because it requires knowledge of workload realizations, which can be hard in practice. 
\commentEnd\fi

Although LDF+TS/LLREF is designed for deterministic workloads, we envisage it will work well for workloads with small variability by using the expected workload, or some more sophisticated workload estimation . Specifically, TS makes selections based on  and LLREF computes local remaining execution time and laxity by assuming . 
Note that this heuristic LDF+TS/LLREF is still non-clairvoyant. This will be explored in the simulation section. 

\dissertationStart
This heuristic LDF+TS/LLREF is still non-clairvoyant but picking appropriate  is key to the performance. 
On one hand big  reduces the number of tasks selected per period and on the other hand small  may cause user 's task fail to complete. 
In the simulation section, we will show such a policy performs well for NBUE workloads that are not deterministic but have small variability. 
\commentEnd\fi

\subsection{Resource Requirements}

So far we have analytically characterized the efficiency ratios of two LDF-based resource allocation policies. Another metric of interest is the resource requirements in terms of the number of cores  needed to fulfill a set of users' QoS requirements. To that end in this subsection we shall explore the required  given , , the random workload distributions and the requirement vector . A policy that requires a smaller  is better in that it saves compute resources and/or energy. 

\subsubsection{Resource Requirements for Reservation-Based Static Sharing}
~

Based on the definition of  in \ref{subsection_reservation_based_design}, the required number of cores to fulfill the users' QoS requirements  under reservation-based static sharing is given by

where  is the ceiling of . 

\subsubsection{Lower Bound on Resource Requirements}
~

For any non-clairvoyant resource allocation policy , we let  denote the required number of cores to fulfill users' QoS requirements under policy . 
By Theorem \ref{thm_optimal_benchmark}, we know  must satisfy 

, giving the following lower bound on the required number of cores: 


\dissertationStart
If we ignore the ceilings, 

gives us a {\em upper bound} for the possible resource savings compared with reservation-based static sharing, i.e., the percentage of cores we can save by devising the best possible non-clairvoyant resource allocation policies. Clearly, this depends on the workload distributions and the requirement vector . We will see in the simulation section that the proposed approaches can achieve this upper bound in some scenarios. 
\commentEnd\fi

\subsubsection{Resource Requirements Estimate for LDF+Greedy}
~

\dissertationStart
After giving a the lower bound  for the required number of cores for all non-clairvoyant designs, we want to explore the required  for the LDF+Greedy policy. 
\commentEnd\fi
Ideally one would like a tight upper bound for the required resources  for LDF+Greedy. 
By Theorem \ref{thm_LDF_greedy_eff_ratio} we know that LDF+Greedy may expect to waste up to  time on each core in a period because of unfinished tasks. 
\dissertationStart
Therefore, the ``effective'' time for each core in one period is at least . 
\commentEnd\fi
Thus, to complete an ``effective'' workload , we propose an estimate for  as follows,

If , this estimate is close to the lower bound . 


\infocomStart
One can analytically show that indeed  when  and  are large, see the extended version of this paper \cite{EXT}. 
\commentEnd\fi
We can analytically show that indeed  when  and  are large, 
\tompecsonlyStart
see the extended version of this paper \cite{EXT}. 
\commentEnd\fi
\tompecsextendedStart
see the proposition as follows. 
\commentEnd\fi
We observe that the inequality holds true in the various simulation settings considered next. 

\tompecsextendedStart
\begin{proposition}
\label{proposition_m_est_for_large_system}
For a SRT-MIC  system model with homogeneous users where all users have i.i.d. NBUE task workloads with mean  and the same QoS requirement , if the period length satisfies , then for any NBUE workload distribution and for any  satisfying , there exists , such that for all , 

is a sufficient number of cores to meet the QoS requirement for  users. 
\end{proposition}

By letting  approach , the  in this proposition approaches . This is due to the law of large numbers and we omit the proof.  
\commentEnd\fi

\section{Simulations}
In this section we address through simulation some of the questions that are still open: 
\begin{enumerate}
\item What are possible resource savings of adopting LDF+Greedy versus reservation-based static sharing? 
		Are they close to optimal when  is large? 
		How do they depend on the QoS requirements ? 
\item Our theorems on the lower bounds on efficiency ratios imply that LDF+TS/LLREF is better than LDF+Greedy for small  and deterministic workloads. Is it true that LDF+TS/LLREF is more efficient? 
\item For workloads with small variability, can one use LDF+TS/LLREF and get gains over LDF+Greedy?  
\end{enumerate}

Our simulation setup is as follows. We start with an initial deficit vector . In each period, we independently generate a task workload realization for each user and simulate the specified policy to evaluate if tasks complete. All simulations are run for  periods. A QoS requirement vector  is feasible if for all users  the fraction of task completions over the  periods exceeds . 

\subsection{Near-Optimality of LDF+Greedy for Large }
\dissertationStart
LDF+Greedy is simple to implement in practice since it does not require knowledge of workload distribution or the task preemption and migration. 
\commentEnd\fi
To evaluate the resource savings of LDF+Greedy for large period length , we consider an SRT-MIC system model with  and , serving homogeneous users that have the same QoS requirement  and generate tasks with Gamma workloads, i.e., a sum of  independent exponential random variables with parameter . 
The probability density function is shown in the top panel in Figure~{\ref{fig_gamma_dist_and_m_savings_large_period}}. We choose this NBUE workload distribution as a representative one. 

In the bottom panel in Figure~{\ref{fig_gamma_dist_and_m_savings_large_period}}, 
we show the simulated resource savings of LDF+Greedy versus the reservation-based static sharing, i.e., , and the computed upper bound on resource savings  as the QoS requirement  increases from  to . 
The lines are not smooth because we take ceilings when computing  and . 

It can be seen that the savings under LDF+Greedy is close to the upper bound in this setting. 
The ``U'' shape of the exhibited results depends on the workload distribution. 
Intuitively, in this homogeneous-user scenario, if we ignore the ceilings in (\ref{align_m_RB}) (\ref{align_m_LB}), the upper bound on savings becomes,

where  is the common mean workload and  is the common required static allocation. 
For high ,  is like a worst-case workload and this is an improvement from worst case to average which is as high as - for Gamma distribution. 
For medium ,  is around  while  is roughly , giving a  resource savings. For low ,  is much smaller compared to  and the savings can be up to -. 
\dissertationStart
Intuitively, in this setting the percentage of resource savings (\ref{align_m_savings}) simplifies to

where  is the common mean task workload and  represents the common required static allocation for each user. 

For SRT applications that require high , under reservation-based static sharing policies we need to allocate each user  which is like worst-case workload while an optimal resource allocation policy only requires  which is even less than  for each user. This is an improvement from worst case to average and is as big as - for Gamma distribution. 
For some applications whose QoS requirements are similar to , e.g., the channel measurement tasks in the CRAN context,  is roughly  while an optimal resource allocation policy only need around , giving a  resource savings. 
For low , the savings can be up to -. 
\commentEnd\fi



\begin{figure}[htp]
  \centering
  \includegraphics[width=0.65\textwidth]{Figures/gamma_dist_and_m_savings_large_period.pdf}
\caption{Top: the probability density functions for Gamma and Gamma. Bottom: the resource savings for large period.}
  \label{fig_gamma_dist_and_m_savings_large_period}
\end{figure}


\subsection{LDF+Greedy vs. LDF+TS/LLREF for Deterministic Workloads and Small } 
\dissertationStart
When period  is comparable to mean workloads, we shall explore other resource allocation policies. 

For the SRT-MIC system model where users have the same  and generate tasks with the same deterministic workloads, by (\ref{align_m_savings_simplified}) we know  equals to  and thus we get


This implies that the resource savings monotonically decrease as  increases, which is different from the ``U'' shape of the lines in Figure~{\ref{fig_gamma_dist_and_m_savings_large_period}}. By Theorem \ref{thm_LDF_TS_LLREF_eff_ratio} the LDF+TS/LLREF policy provides a good option to achieve these savings. 
\commentEnd\fi

To compare LDF+Greedy and LDF+TS/LLREF for short periods  and deterministic workloads, we consider a system where  and  and where users are homogeneous and generate tasks with deterministic workloads . 
In the top panel in Figure~{\ref{fig_m_savings_deterministic_and_low_variability}}, we exhibit the upper bound of resource savings and the resource savings under LDF+Greedy and LDF+TS/LLREF as the requirement  changes from  to . 

As can be seen, LDF+TS/LLREF can achieve the upper bound on savings while LDF+Greedy does not perform as well. 
For high , the savings for LDF+Greedy is even negative implying that LDF+Greedy is worse than the reservation-based approach. 
This is because we chose  and  such that LDF+Greedy wastes a significant amount of time on unfinished tasks. 
Observe that the savings are monotonically decreasing in , which is different from the ``U'' shape exhibited in Figure~{\ref{fig_gamma_dist_and_m_savings_large_period}}. Intuitively, this is because for deterministic workloads, by (\ref{align_m_savings_simplified}) we know  equals to  and thus we get


\begin{figure}[htp]
  \centering
  \includegraphics[width=0.6\textwidth]{Figures/m_savings_deterministic_and_low_variability.pdf}
  \caption{Top: the resource savings under deterministic workloads. Bottom: the resource savings under random workloads with small variability. }
  \label{fig_m_savings_deterministic_and_low_variability}
\end{figure}

\subsection{LDF+TS/LLREF for Workloads with Small Variability}
\label{subsubsection_heuristic_TS_LLREF_small_var}
For workloads with small variability, we envisage that the heuristic LDF+TS/LLREF described in Section \ref{subsection_LDF_TS_LLREF} is a good non-clairvoyant policy. 
\dissertationStart
For non-deterministic workloads, the LDF+TS/LLREF policy requires knowledge of workload realizations and so is not non-clairvoyant. 
However, we envisage that the heuristic estimation based LDF+TS/LLREF described in \ref{subsection_LDF_TS_LLREF} can be a good non-clairvoyant generalization, especially for random NBUE workloads with small variability. 
\commentEnd\fi
Consider a SRT-MIC system with homogeneous users where  and  and where the task workload distributions are Gamma exhibited on the top panel in Figure~{\ref{fig_gamma_dist_and_m_savings_large_period}}. 
Note that the distribution Gamma has the same mean  but a small variance. In this setting, we shall estimate the workload to be  and use our proposed heuristic LDF+TS/LLREF in Section \ref{subsection_LDF_TS_LLREF}. 
We conduct the same analysis for resource savings and exhibit the results in the bottom panel in Figure~{\ref{fig_m_savings_deterministic_and_low_variability}}. 

As can be seen, the heuristic LDF+TS/LLREF indeed performs better than LDF+Greedy. However, the performance of the heuristic LDF+TS/LLREF degrades for high . This is due to the fact that some selected tasks fail to complete since their workloads are larger than . 
\dissertationStart
and that becomes a more critical problem as  becomes bigger. 
\commentEnd\fi
One approach to solve this is to increase  as  becomes bigger. 
\dissertationStart
and we observe it can improve the resource savings for the heuristic LDF+TS/LLREF in large  regime. 
\commentEnd\fi



Although we only considered homogeneous users, the above observations were found to be robust for heterogeneous users. 

\dissertationStart
\subsection{Impact of Workload Heterogeneity}
In general users sharing a computing system may have heterogeneous workloads and requirements. We shall explore the impact of workload heterogeneity on our proposed designs. We consider a system similar to the one above in \ref{subsubsection_heuristic_TS_LLREF_small_var} but with heterogeneous workloads. For simplicity, we denote by HOM the system in \ref{subsubsection_heuristic_TS_LLREF_small_var} and by HET the heterogeneous system introduced below. 

In the HET system, some users in the HOM system are replaced by users with smaller task workloads. 
Specifically, the HET system has  users with workload distribution being Gamma and  users with workload distribution being Gamma. Suppose the period is  and all users have the same QoS requirement . By (\ref{align_m_RB}) and (\ref{align_m_LB}) it is easy to verify that with the same QoS requirement  the HOM and HET systems have the same  and  and therefore, the same upper bound resource savings. 
Similarly as for the HOM system, in Figure~{\ref{fig_m_savings_heterogeneous_low_variability}} we plot the upper bound resource savings and the savings for the LDF+Greedy design and the estimation based LDF+TS/LLREF design with  for each user  in the HET system. 

We can see that the savings for the LDF+Greedy design is better in HET system implying that workload heterogeneity improves the performance of LDF+Greedy. Intuitively we know that under LDF+Greedy each core wastes time on at most  unfinished task per period. By replacing big tasks with small ones, the expected wasted time decreases and thus, the performance is improved. 
The heterogeneous workloads have little impact on the performance of the heuristic LDF+TS/LLREF design. 

\begin{figure}[htp]
  \centering
  \includegraphics[width=0.45\textwidth]{Figures/m_savings_heterogeneous_low_variability.pdf}
  \caption{The resource savings under heterogeneous random workloads with small variabilities. }
  \label{fig_m_savings_heterogeneous_low_variability}
\end{figure}
\commentEnd\fi


\infocomStart
\section{Generalizations to Cores with Different Processing Speeds}
\label{section_generalizations}
In this section we summarize generalizations of our results to systems consisting of cores with different processing speeds. 
Let  denote the set of cores. Suppose all cores are of the same type and each core  has processing speed , i.e., cores are ``uniform'', see the taxonomy in, e.g., \cite{DaB11A}. 
A task with workload  processed on core  has a processing time .
Let  be the average processing speed. 
In the model we have considered,  for all . 

In this setting, the outer bound  in Theorem \ref{thm_optimal_benchmark} becomes


For LDF+Greedy, given that cores have different processing speeds, one may want to migrate tasks to faster cores if possible. Therefore, 
depending on whether task preemption/migration is allowed, there are two types of LDF+Greedy. In Type , the task scheduler greedily and preemptively schedules tasks with the highest priority on the fastest cores. In this setting,  in Theorem \ref{thm_LDF_greedy_eff_ratio} becomes

In Type , the task scheduler greedily places tasks on available cores by priority but does not allow preemption/migration. Here  becomes


We can also generalize LDF+TS/LLREF and Theorem \ref{thm_LDF_TS_LLREF_eff_ratio} with additional natural assumptions. See the extended version of this paper \cite{EXT} for more details and other generalizations.
\commentEnd\fi


\tompecsStart
\section{Possible Generalizations}
\label{section_possible_generalizations}
\begin{table}
\footnotesize
    \tbl{Results for different generalizations. \label{tab_generalizations}}{
    \centering
    \begin{tabular}{| c || c | c | c | c | c |}
    \hline
    \multirow{3}{*}{Model} & \multirow{3}{*}{Reservation-Based } & \multirow{3}{*}{Outer Bound } & \multicolumn{2}{|c|}{ (NBUE workloads)} & {}	\\
    \cline{4-5}
     & & & \multirow{2}{*}{preemptive} & {non-} & {(deterministic}	\\
     & & & & {preemptive} & {workloads)}	\\
    \hline\hline
    {} 
    & {} 
    & {} 
    & \multicolumn{2}{|c|}{} 
    & {}	\\
    \hline
    {}
    & \multirow{5}{*}{} 
    & \multirow{5}{*}{}
    & \multirow{5}{*}{}
    & \multirow{5}{*}{}
    & \multirow{5}{*}{}\\
    {Different} & & & & &	\\
    {speeds} & & & & &	\\
    {} & & & & &	\\
     & & & & &	\\
    \hline
	{}
    & \multirow{5}{*}{} 
    & \multirow{5}{*}{}
    & \multicolumn{2}{|c|}{\multirow{5}{*}{N/A}}
& \multirow{5}{*}{}\\
    {Different} & & & \multicolumn{2}{|c|}{} &	\\
    {periods} & & & \multicolumn{2}{|c|}{} &	\\
    {} & & & \multicolumn{2}{|c|}{} &	\\
     & & & \multicolumn{2}{|c|}{} &	\\
    \hline
	{} 
    & \multirow{5}{*}{} 
    & \multirow{5}{*}{} 
    & \multicolumn{2}{|c|}{\multirow{5}{*}{}} 
    & \multirow{5}{*}{}	\\
    {Chains of} & & & \multicolumn{2}{|c|}{} &	\\
    {subtasks} & & & \multicolumn{2}{|c|}{} &	\\
    {} & & & \multicolumn{2}{|c|}{} &	\\
     & & & \multicolumn{2}{|c|}{} &	\\
    \hline
    \end{tabular}
    }
\end{table}

In this section we discuss the following generalizations of the SRT-MIC NBUE-workload model and associated results: 
\begin{enumerate}
\item Cores with different processing speeds. 
\item Users generating tasks at different periods. 
\item Tasks which further consist of sub-tasks that need to be processed in order. 
\end{enumerate}
We discuss these three generalizations in the following three subsections, respectively. 

For ease of reference, Table \ref{tab_generalizations} provides a summary of various generalizations\textemdash the necessary notation is introduced in the sequel.  

\subsection{Cores with Different Processing Speeds}
We first consider generalizations where the cores may have different processing speeds. 
Let  denote the set of cores. Suppose all cores are of the same type and each core  has processing speed , 
i.e., cores are ``uniform'', see the taxonomy in, e.g., \cite{DaB11}. 
In other words, if a task runs on a core with speed  for  time units, then  units of work are performed. 
In this context, the workload of a task refers to the required units of \emph{work} to fully complete the task. 
Therefore, a task with workload  processed on core  has a processing time .
Let  be the average processing speed. 
Clearly, in the SRT-MIC model we have previously considered,  for each . 

We assume  since otherwise one only needs the  fastest cores. 
Next we discuss generalizations of our results. 

\subsubsection{Reservation-Based Static Sharing Policies}

In reservation-based static sharing, given the computed  for all users , the question is whether it is feasible to find a static allocation guaranteeing that  units of work can be performed for each user  in each period. 

\newcommand{\sumFnName}{a}

To answer this question, we first introduce some notation. 
Given a set  of non-negative numbers and a positive integer  which satisfies , we let  be the sum of the largest  numbers in . 
We let . 
Given a QoS requirement vector , for , we let  be the sum of the  largest core time reservations. 
By \cite{FGB01,FuM09}, we know that a static allocation is feasible if and only if the following conditions hold: 

Intuitively, (\ref{align_B_n_leq_S_m}) implies that the sum of required reservations does not exceed the total units of work that can be performed in a period. 
And (\ref{align_B_k_leq_S_k}) implies that the  largest reservation requirements can be satisfied by the  fastest cores. 

Such a static allocation can be obtained according to prior work, see e.g., \cite{FGB01,FuM09}. 
Therefore, the feasibility region of reservation-based static sharing  is given by

This is consistent with our analysis when  for all , see Eq (\ref{align_F_RB_MIC}). 

\subsubsection{Outer Bound  for the System Feasibility Region}

For a system with different core processing speeds, the outer bound  in Theorem \ref{thm_optimal_benchmark} needs to be modified to

i.e., the ``effective'' workload  cannot exceed the maximum units of work  that can be performed in a period. 

A proof of this result requires a slight modification of that of Theorem \ref{thm_optimal_benchmark}: we replace  by ; we redefine  to be the total units of work performed for users in  in a typical period; and we redefine  to be the indicator random variable that user 's task is unfinished and  units of work are performed for user 's task in a typical period. 

\subsubsection{LDF+Greedy Scheduling}

For LDF+Greedy, if all cores have the same speed, there is no benefit of moving a running task from one core to another. 
However, if cores have different speeds, one may want to migrate tasks to faster cores if they become available. 
Therefore, depending on whether task preemption/migration is allowed, there are two types of greedy task schedulers: 
preemptive and non-preemptive greedy task scheduler. 

{\bf \em Preemptive Greedy Task Scheduler: }
In the preemptive case, the task scheduler greedily and preemptively schedules tasks with the highest priority on the fastest cores. Specifically, at all times the task scheduler guarantees that the available\footnote{A task is available if it is not completed yet. } task with the highest priority is placed on the fastest core, the available task with the second highest priority is on the second fastest core, etc. 
In this setting, similarly to Theorem \ref{thm_LDF_greedy_eff_ratio} we get the following corollary. 

\begin{corollary}
\label{corollary_gamma1_diff_speed_pre}
For the generalization of SRT-MIC model to cores with different processing speeds, the efficiency ratio of the preemptive LDF+Greedy exceeds  where

\end{corollary}

Note that in the denominator we have an average processing speed , which equals to  in the SRT-MIC model we considered previously. 
Intuitively, this is because under the preemptive greedy task scheduler the unfinished tasks are always on the fastest cores. And the average processing speed of the  fastest cores is at least  for . 
\tompecsonlyStart
We omit the proof to save space. For a detailed proof, see the extended version of this paper \cite{EXT}. 
\commentEnd\fi
\tompecsextendedStart
Refer to Appendix \ref{appendix_pf_gamma1_diff_speed_pre} for the proof. 
\commentEnd\fi

{\bf \em Non-Preemptive Greedy Task Scheduler: }
The non-preemptive greedy task scheduler starts by putting the task with the highest priority on the fastest core, the task with the second highest priority on the second fastest core, etc. Once one of these tasks completes, it continues by processing the task with priority  on the available core, etc. In this setting, we get the following corollary. 

\begin{corollary}
\label{corollary_gamma1_diff_speed_nonpre}
For the generalization of SRT-MIC model with different processing speeds, the efficiency ratio of the non-preemptive LDF+Greedy exceeds  where

\end{corollary}
\tompecsonlyStart
\noindent See the extended version of this paper \cite{EXT} for the proof. 
\commentEnd\fi
\tompecsextendedStart
\noindent See Appendix \ref{appendix_pf_gamma1_diff_speed_nonpre} for the proof. 
\commentEnd\fi

Note that  under the preemptive LDF+Greedy is larger than that under the non-preemptive LDF+Greedy. This captures the benefit of task preemption/migration although these operations involve overheads in practice. 

\subsubsection{LDF+TS/LLREF Scheduling}
For deterministic workloads, we shall generalize our proposed LDF+TS/LLREF scheduling. We first introduce a further assumption. 

\begin{assumption}
\label{assumption_largest_workload_compatible}
We suppose the  users' deterministic workloads are such that for all , 

where  represents the sum of the  largest workloads. 
\end{assumption}

Intuitively, this guarantees that for all , the  tasks with largest workloads can complete on the  fastest processors in a period. 

Under Assumption \ref{assumption_largest_workload_compatible}, and by \cite{FGB01,FuM09}, we can complete all tasks in a user subset  in a period by some optimal scheduling if and only if . Such optimal scheduling algorithms include U-LLREF \cite{FuM09}, a variant of LLREF for cores with different speeds, and Proportionate Fair (Pfair) \cite{BCP96}. 

Similar to the TS/LLREF task scheduler in Definition \ref{defn_TS_LLREF}, we propose TS/U-LLREF or TS/Pfair where the task selection rule (\ref{align_j_d}) naturally becomes 

and the selected subset of users are scheduled via U-LLREF or Pfair algorithms. 

Under Assumption \ref{assumption_largest_workload_compatible}, and similarly to Theorem \ref{thm_LDF_TS_LLREF_eff_ratio}, we can show that the efficiency ratio of LDF+TS/U-LLREF or LDF+TS/Pfair exceeds  where

The proof of this result follows that of Theorem \ref{thm_LDF_TS_LLREF_eff_ratio} by simply replacing  with . 


\subsection{Users Generating Tasks at Different Periods}
In this subsection, we consider possible generalizations of the SRT-MIC NBUE-workload model where users generate tasks at different periods, and discuss results that cannot be generalized and/or associated difficulties. 

Specifically, suppose starting from time  each user  generates a task at the beginning of each period of length . We assume there exists a minimum common multiple  of  for all . We shall refer to  as a {\em super period}. 


Again, each user requires the long-term time-averaged number of tasks completed on time per period . To be consistent with the SRT-MIC  model, we define the feasibility in terms of the positive recurrence of a Markov chain. Given , we keep track of the deficits of users across super periods. For each user  and super period , we shall define deficit updates as follows,

where  is a random variable representing the number of tasks completed on time for user  in super period . Let . We only consider non-clairvoyant resource allocation policies such that the process  is a Markov chain. A QoS requirement vector  is feasible if the Markov chain  is positive recurrent under some non-clairvoyant resource allocation policy. 

\subsubsection{Reservation-Based Static Sharing Policies}

We first generalize the performance characterization of reservation-based static sharing policies. Similarly to the setting in {\ref{subsection_reservation_based_design}}, we can compute the required core time reservation per period  for all users . Now  represents the required core utilization for user  if we want to allocate  core time to user  per period. Clearly, if  we cannot meet the core time reservations  for all users. Indeed, by prior work, see e.g., \cite{CRJ06,DaB11}, we can characterize the feasibility region  of reservation-based static sharing policies as follows, 

Note that this is consistent with our analysis when all users have the same period, see Eq (\ref{align_F_RB_MIC}). 

Given that  and  for all , since users have different periods, the remaining problem is how to allocate  to each user  in each period. 
One solution is to use the LLREF scheduling policy. 
\tompecsonlyStart
\add{We omit the details to save space. Refer to the extended version of this paper \cite{EXT} for detailed discussion. }
\commentEnd\fi
\tompecsextendedStart
Refer to Appendix \ref{appendix_LLREF_for_RB} for more details. 
\commentEnd\fi

\subsubsection{Outer Bound  for the System Feasibility Region}

When users generate tasks with different periods, the outer bound  for the system feasibility region can be generalized as follows, 


Intuitively,  represents the sum of core utilizations to fulfill QoS requirement , which cannot exceed the maximum degree of parallelism . The proof is similar to that of Theorem \ref{thm_optimal_benchmark}\textemdash refer to 
\tompecsonlyStart
the extended version of this paper \cite{EXT} for details. 
\commentEnd\fi
\tompecsextendedStart
Appendix \ref{appendix_pf_R_OB_diff_periods} for details. 
\commentEnd\fi

\subsubsection{LDF-Based Policies Over Super Periods}

A heuristic way to generalize our proposed LDF-based resource allocation policies to different-period scenarios is to adopt the LDF policy to pick a priority decision for each super period.  
Specifically, at the beginning of super period , the system orders the deficit vector  and assigns priorities from largest to smallest. 
These priorities are interpreted by the task scheduler to schedule tasks in this super period. 

{\bf \em LDF+Greedy:}
When users generate tasks with different periods, the greedy task scheduler can be preemptive or non-preemptive depending on whether preemption/migration is allowed. In the preemptive version, at all times the task scheduler processes the  available tasks with the highest priority on the  cores. In the non-preemptive version, the task scheduler starts with  tasks with the highest priority. When a running task completes or reaches its deadline\footnote{This implies that another task from the same user is released. That new task is also considered to be a non-running task. }, the available non-running task with the highest priority is selected to be processed on the available core. 

Unfortunately, for this generalized LDF+Greedy policy we cannot get a similar performance characterization as Theorem \ref{thm_LDF_greedy_eff_ratio}. Intuitively, this is because the greedy task scheduler can potentially waste a lot of time on unfinished tasks in different-period scenarios. For example, under the preemptive greedy task scheduler, we may start processing a task right before its deadline and fail to complete it, or we may process a task only for a short time before we have to switch to process another task with higher priority leaving the original task unfinished. These scenarios degrade the performance of the LDF+Greedy policy. 

{\bf \em LDF+TS/LLREF under Deterministic Workloads: }
If the users generate tasks with different periods but with deterministic workloads, we can generalize the LDF+TS/LLREF policy and also Theorem \ref{thm_LDF_TS_LLREF_eff_ratio}. 
Naturally we assume  for all . Otherwise, the tasks from user  cannot complete on time. 

Under LDF+TS/LLREF, in each super period, a priority decision  is selected according to the LDF policy. Similarly to (\ref{align_j_d}), the system selects the user subset  where  is computed as follows, 

We shall consider the case where the system adopts the LLREF policy to process and complete all tasks from  in this super period. 

To characterize the efficiency ratio, we proved the following corollary which is similar to Theorem \ref{thm_LDF_TS_LLREF_eff_ratio}. 
\begin{corollary}
\label{corollary_LDF_TS_LLREF_eff_ratio_generalized}
For the SRT-MIC  system model with different periods and deterministic workloads, the efficiency ratio of LDF+TS/LLREF that operates over super periods exceeds , where

\end{corollary}

Intuitively, under the task selection rule (\ref{align_j_d_generalized}), for the selected user subset  we know that  is less than , and therefore, the performance gap is bounded by . The formal proof is straightforward generalization of the proof of Theorem \ref{thm_LDF_TS_LLREF_eff_ratio} and we shall omit it. 

Again, this result is consistent with our analysis when all users have the same period, see Theorem \ref{thm_LDF_TS_LLREF_eff_ratio}. 

\subsubsection{Fine-Grained LDF-Based System Designs}
A problem for the LDF-based resource allocation policies over super periods is that the task completions of users vary a lot from super period to super period. For example, a user with high priority in one super period may complete a large number of tasks in this super period and then be assigned a low priority in the next super period, completing only a small number of tasks. Such bursty completions would likely be undesirable for users especially when the super period  is large. 

To mitigate this problem, we could consider a fine-grained LDF policy to change the priority decisions more frequently. We divide the timeline into intervals associated with times where tasks become available for processing and deadlines. At the beginning of each interval, we compute the deficit between the QoS requirement and the actual number of completed tasks up to that time for each user , sort the deficits from largest to smallest and assign priorities accordingly. 

Given the priority decision in each interval, we can adopt a greedy task scheduler. 
If task preemption/migration is allowed, naturally we start by putting the  tasks with highest priority on the  cores, and once one of these tasks completes, we continue by putting the task with priority  on the available core, etc. 
If preemption/migration is not allowed, at the beginning of this interval, we continue processing the tasks running at the end of the previous interval, and once one of these tasks completes or reaches the deadline, we put the non-running task with the highest priority on the available core, etc. 


It would be of interest to characterize the performance of such resource allocation policies and to generalize LDF+TS/LLREF in future work. 

\subsection{Tasks Consisting of Sub-Tasks}
We continue our discussion of possible generalizations of our SRT-MIC NBUE-workload model to the case where each task consists of several sub-tasks that need to be processed in order and all of which need to be completed by the end of the corresponding period. We assume all sub-tasks can be processed on all cores. 

Specifically, suppose in each period each user  generates a task consisting of  sub-tasks, which have to be processed in order and cannot be processed in parallel. But sub-tasks of different tasks can be processed simultaneously. A task in a period is said to be completed on time if and only if all its sub-tasks complete by the end of the period. Each user  requires time-averaged task completions per period . 
For a given user, we assume the sub-task workloads with the same sub-task index are i.i.d. across periods and the sub-task workloads with different indices are independent. 
For each user  and each sub-task index , we denote by  the workload of the  sub-task from user  and let  be the mean sub-task workload. Clearly  and . 
We further assume each sub-task has an NBUE workload distribution. By \cite{ShS07b} we know user 's task workload  also has an NBUE distribution. 

This generalized task model captures tasks that are completed in phases. For example, in the CRAN context each antenna generates a task associated with each subframe. A task may further consist of sub-tasks like encoding/decoding, modulation/demodulation, FFT/IFFT.

Suppose the system can observe the sub-task completions, these observations enable a broader range of non-clairvoyant resource allocation policies, which could potentially achieve better performance, i.e., a larger system feasibility region . For example, now we can consider a resource allocation policy that stops processing a task if its first sub-task takes too long. 

Clearly our original SRT-MIC  system model is a special case of this generalized model where  for all users . 
It turns out that our proposed approaches and performance characterization still hold under this generalized task model although some of the proofs need modification. Next we shall discuss this in more detail. 

\subsubsection{Reservation-Based Static Sharing Designs}

Given the sub-task workload distributions and the assumption of workload independence, we can get the workload distribution of  and thus  for all users . Therefore, the discussion of reservation-based static sharing policies in Section \ref{subsection_reservation_based_design} still holds. 

\subsubsection{Outer Bound for the System Feasibility Region F}

The definition of the outer bound region  and Theorem \ref{thm_optimal_benchmark} still holds, but the proof for Theorem \ref{thm_optimal_benchmark} requires some modification. 
\tompecsonlyStart
See the extended version of this paper \cite{EXT} for the details. 
\commentEnd\fi
\tompecsextendedStart
See Appendix \ref{appendix_pf_R_OB_subtask_model} for the details. 
\commentEnd\fi

\subsubsection{LDF-Based System Designs}

We can still use our proposed LDF-based resource allocation policies, i.e., LDF+Greedy and LDF+TS/LLREF, to process tasks consisting of sub-tasks. When applying these approaches, we consider each task as a whole task and do not use the sub-task information. This is reasonable because partially completing some sub-tasks does not help to meet the QoS requirements . Our performance characterization results Theorem \ref{thm_LDF_greedy_eff_ratio}, Theorem \ref{thm_LDF_TS_LLREF_eff_ratio}, etc., still hold. 

As a summary, tasks consisting of sequences of sub-tasks with independent NBUE workloads do not change the results in this paper. 

In this section we have introduced three possible generalizations in parallel. Given these results, the combinations of multiple generalizations, e.g., scenarios where the processors have different processing speeds and users generate tasks with different periods, are straightforward and we omit the discussion here. 
\commentEnd\fi


\section{Conclusion}
We have considered a computing system with multiple resources supporting soft real-time applications and established analytically and through simulation that simple resource allocation policies like LDF+Greedy are near-optimal and achieve substantial resource savings, except when the real-time constraints are tight, i.e., the period length is similar to the service time for a user's task. 
In this case, LDF+Greedy may not work well and it is worth exploring other policies. 
For workloads with small variability, we have proposed the LDF+TS/LLREF policy which indeed outperforms LDF+Greedy. 
For future work, a more detailed exploration of systems consisting of possibly different types of resources is of interest. 



\huaweiStart
\section*{Acknowledgment}
This research was supported by Huawei Technologies Co. Ltd. 
The authors would like to thank Alan Gatherer, Zheng Lu, Haishan Zhu and Mattan Erez for their comments and feedbacks on this work. 
\commentEnd\fi

\bibliography{diss_myown}{}
\bibliographystyle{ACM-Reference-Format-Journals}


\dissertationStart
\section{User Management Across SRT-MIC  Systems}
\myComments{Improve this based on prof's feedbacks. }
As we have argued, a SRT-MIC  system could be a cluster of machines or a centralized server with a large number of cores. A large-scale cloud-based infrastructure in practice generally consists of several such SRT-MIC  systems and it requires a centralized user\footnote{A user can be viewed as a stream of periodic tasks. }/stream management system to add new users to existing SRT-MIC  systems, or to move users across SRT-MIC  systems if one system is overloaded, etc. In this section, we consider a cloud-based infrastructure that consists of several SRT-MIC systems and explore how to allocate a new user to one of these systems. 

\subsection{System Model for Stream Management}
We consider a cloud-based infrastructure consisting of several SRT-MIC systems, each of which serves a set of users with NBUE workloads according to some optimized resource allocation policies, such as the LDF+Greedy policy we proposed. The users are generating tasks as we discussed in Section \ref{sec_system_model}. 
Suppose all users generate tasks with the same period . Let  be the set of all SRT-MIC systems. Each SRT-MIC system  has  identical cores. For simplicity, we assume different SRT-MIC systems have identical cores, but possible with different numbers of cores. The user set for system  is denoted by  and  is the number of users. The QoS requirement vector for system  is denoted by  where  represents the required number of tasks completed on time for user . 

We can evaluate the performance of these SRT-MIC systems based on measurements of the history events. For example, for each SRT-MIC system  we can measure the achieved time-averaged\footnote{In practice we can measure the average over a reasonable time window. } task completion vector  where  represents the achieved time-averaged number of tasks completed on time per period for user . The SRT-MIC system  is called feasible if  for all users . Here we assume all SRT-MIC systems are feasible since otherwise we would remove users from this overloaded system. 
For each user  we can also measure the time-averaged time spent on that user per period, denoted by . 

Suppose there is a new user  periodically sending over tasks to this cloud-based infrastructure with QoS requirement  and mean workload . Our objective is to allocate this new user to a SRT-MIC system aiming to meet the QoS requirement for this new user without violating the requirements of the existing users in that system. We want to ensure the QoS requirements are met while at the same time using these SRT-MIC systems efficiently. 

Based on our discussion in this paper, we have seen that it is very hard to accurately predict the impact of adding a new user to a SRT-MIC system. 
Moreover, in practice it could be challenging to get fine-grained information about workload distributions or even mean workloads since the users may not know the processing speed of the cores, the uncertainties of the SRT-MIC systems, etc. 
In this section we propose a heuristic user allocation policy that is only based on measurements of the SRT-MIC systems with the aim of motivating similar policies for more complicated cloud-based infrastructures dealing with soft real-time services. 

\subsection{Measurement-Based User Allocation Policy}
We are motivated by the inequality (\ref{align_required_workload_smaller_than_spent_time}) in the characterization of outer bound feasibility region . By letting  in (\ref{align_required_workload_smaller_than_spent_time}) we know for each SRT-MIC system  and each user , we have

and the equality holds if user  generates tasks with exponential workloads in the continuous-time scenario (or geometric workloads in the discrete-time scenario). 
Therefore, the required average time spent on user  to meet QoS requirement  can be estimated by . Next we introduce our user allocation policy. 

Our policy consists of two parts: {\em feasibility checking}, to find SRT-MIC systems that can admit this new user, and {\em scoring}, to select one out of these candidate SRT-MIC systems. Similar two-part approach is adopted in Google Borg system \cite{VPK15A} to allocate tasks, not necessarily soft real-time tasks, to machines. 

In feasibility checking, we aim to find a set of SRT-MIC systems that have enough ``space'' to admit the new user . For each SRT-MIC system , we define the remaining space  as follows, 

Intuitively,  represents the required time we need to spent on users in  to meet the QoS requirement  and  represents the remaining time system  can spend on additional users. Everything we need to compute  is trivial to get, such as , , , or can be measured from system , i.e.,  and . 

We mark the system  as a candidate system if 

where  is a non-negative safety guard. We use  to represent the set of candidate systems, i.e. 

We introduce this safety guard  because there is a gap between  and  in (\ref{align_p_i_mu_i_leq_t_i}). In the sequel we will discuss how to adapt the value of  based on the ``accuracy'' of our user allocation policy. 

In scoring, we compute a score for each candidate system  according to some scoring function  and pick the SRT-MIC system with the largest score. We may use different scoring functions for different purposes. For example, to fill each SRT-MIC system as tight as possible, or for ``best-fit'' purpose, we can let  which is equivalent to picking the system  with smallest remaining space . That enables us to consolidate the SRT-MIC systems so that we can shut down some SRT-MIC systems to save energy or to use those resources for other purposes. But under this scoring function, we will get penalized for even small errors in the estimations of , , etc. 

Alternatively, to be conservative we can let  which is equivalent to picking the system  with the largest remaining space . That would result in the users' workloads being balanced across SRT-MIC systems. A potential problem for using this scoring function is that the available ``space'' are separated across SRT-MIC systems and we may not be able to find a candidate system for a new user with large . Some other complicated scoring functions may take into account the mixing of users with high QoS requirements and low QoS requirements. In practice we can design an appropriate scoring function based on the practical context. 

Once we allocate the new user  to a SRT-MIC system  according to the policy above, we check the correctness of this allocation by observing the achieved task completion vector over a reasonable time window and comparing it with the QoS requirements. If the system  is no longer feasible after adding user , we remove user  from  and re-allocate the user according to the policy above. But this time we no longer mark the system  as a candidate system for user . 

We want to adapt the value of safety guard  based on the correctness of our user allocation decisions. Suppose  starts with  and we allocate user  to system  according to the policy above. If the user allocation decision turns out to be incorrect, that implies the value of  is too small and we double the value of . Otherwise, the user allocation decision is correct and we want to decrease the value of  to be more aggressive. But note that  only plays a role when  is close to . If , the correctness of this decision is straightforward and does not provide much insight on whether  is a good value. Therefore, in such scenario we keep  unchanged. But if  is close to , by which we mean , and the decision is correct, then we decrease the value of  by a small constant  while guaranteeing  is non-negative. In this way we dynamically adapt the value of  based on the correctness of user allocation decisions. 

\commentEnd\fi











\section{Appendix}

\subsection{Proof of Theorem \ref{thm_R_IB}}
\label{pf_theorem_R_IB}
We first introduce some additional notation. Given two vectors  and , we denote by  the entrywise product. 

Given , we need only show  can be fulfilled by the LDF+ policy. 

By definition of interior there exists an  such that . 
By definition of , there exists a vector  such that for all , 


Consider the following candidate Lyapunov function: 


Note that the process  is now driven by LDF, and let  be the vector of indicator variables for users' task completions under LDF. 
At period , we have that


For simplicity, let  denote the priority decision selected by LDF at period . We have

By reordering users according to priorities, we get


By the LDF policy we know . By (\ref{align_q_prime_condition}) we have  for . Therefore, 



Suppose  is an upper bound for all ,  and possible , by (\ref{align_LDF_drift})

for  satisfying . 

It is not hard to show\footnote{This is true because given our assumption that requirement  are rational valued, the state space of process  is in a lattice \cite{CoS13b}.} there are finite states  satisfying . Therefore, by Foster's Theorem  is positive recurrent and  is fulfilled by the LDF policy. 

\subsection{Lower Bound in Theorem \ref{thm_LDF_greedy_eff_ratio} is Tight}
\label{appendix_example_showing_theorem_LDF_Greedy_eff_ratio_is_tight}
Given , consider a SRT-MIC system model that has  identical cores serving  users generating tasks with deterministic workload  in each period of length . Suppose all users have the same QoS requirement . 

In this setting, since , by using LDF+Greedy one can complete  tasks per period. However, by using LDF+TS/LLREF policy we can complete  tasks per period, which is a lower bound on the number of completed tasks per period under a feasibility optimal policy. 

Given that all users have the same QoS requirement, the efficiency ratio of LDF+Greedy equals to ratio of the number of tasks completed per period under LDF+Greedy to that under a feasibility optimal policy, and thus


Since , we know . Further since , we get that


Thus, in this setting, we have that


\subsection{Proof of Theorem \ref{thm_LDF_TS_LLREF_eff_ratio}}
\label{appendix_pf_thm_LDF_TS_LLREF_eff_ratio}
Suppose we are given a QoS requirement vector . Under deterministic workloads, to fulfill  the average core processing time  per period should not exceed . Therefore, a feasible requirement vector  implies 

and clearly . 

The goal is to show . Recall that in this setting the vector  represents the expected numbers of task completions per period for TS/LLREF task scheduling under priority decision . Given deterministic workloads and any decision , under LDF+TS/LLREF,  equals to  if user 's task is selected and thus completes, and equals to  otherwise. By Theorem \ref{thm_R_IB} it suffices to show  and by letting , it suffices to show for any given user subset  and priority decision , 


We show this in the following two cases. 

If , the task selection rule (\ref{align_j_d}) will assure that all users in  are selected and thus,  for all . Since  and , we have 
. 

Otherwise,  and then not all users in  are selected. 
The task selection rule (\ref{align_j_d}) will ensure 
 and therefore, 


This proves (\ref{align_sum_mu_p_geq_gamma_2}) and therefore, 


\tompecsextendedStart
\subsection{Proof of Corollary \ref{corollary_gamma1_diff_speed_pre}}
\label{appendix_pf_gamma1_diff_speed_pre}
The proof is similar to that of Theorem \ref{thm_LDF_greedy_eff_ratio}. 
To avoid duplication here we only discuss the differences in the associated arguments. 
First,  should be replaced by . 
Second, instead of showing (\ref{align_wasted_smaller_than_fraction_of_total}), one needs to show

for which it suffices to show that


We still define . Under preemptive greedy task scheduling, if  for , then there are  unfinished tasks on the  fastest cores, implying that the  fastest cores are busy processing tasks from users in  throughout the period. 
Therefore,  and thus . Clearly by the definition of  we know 

Therefore, . 

Thus it follows that


This proves (\ref{align_num_unfinished_tasks_leq_different_speed}) and concludes the proof. 
\commentEnd\fi

\tompecsextendedStart
\subsection{Proof of Corollary \ref{corollary_gamma1_diff_speed_nonpre}}
\label{appendix_pf_gamma1_diff_speed_nonpre}
The proof is similar as that of Corollary \ref{corollary_gamma1_diff_speed_pre}. But this time, instead of showing (\ref{align_wasted_smaller_than_fraction_of_total_different_speed}), we shall show

for which it suffices to show that


This is true because, if  for , then there are  unfinished tasks, implying that there are  cores busy processing tasks from users in  throughout the period. 
Thus, . 

Thus it follows that

which proves (\ref{align_num_unfinished_tasks_leq_different_speed_nonpreemptive}). 
\commentEnd\fi

\tompecsextendedStart
\subsection{Proof of  when users generate tasks with different periods}
\label{appendix_pf_R_OB_diff_periods}
The proof of this generalization is similar to that of Theorem \ref{thm_optimal_benchmark}. The main differences lie in the definitions of the random variables , ,  and . 
In this setting, for each user  we define  to be the random variable that represents the number of tasks completed on time over a typical super period . 
For a feasible , by the Ergodic Theorem, we know  for all . 
We further define  to be the number of user 's unfinished tasks over a typical super period and define  to be the total residual workloads of user 's unfinished tasks over a typical super period. For each subset of users , we define  to be a random variable denoting the total core time spent on users in  in a typical super period. We can still get equation (\ref{align_subset_time_equation}) and by  we can get that 


Therefore, 

\commentEnd\fi

\tompecsextendedStart
\subsection{Proof of  under generalized sub-task model}
\label{appendix_pf_R_OB_subtask_model}
In systems where each task consists of a sequence of sub-tasks, the definition of the outer bound region  and Theorem \ref{thm_optimal_benchmark} still holds, but the proof for Theorem \ref{thm_optimal_benchmark} requires some modification, specifically (\ref{align_E_i_total_probability}) in the proof no longer holds. 

Recall that in the proof of Theorem \ref{thm_optimal_benchmark} we want to show  for all users , where  is the mean residual workload of user 's unfinished tasks and  is the mean number of user 's unfinished tasks. Our approach is to define  to be the indicator random variable that user 's task is unfinished and is processed for  time units in a typical period. 
By total probability we have that 

Under the original SRT-MIC  system model where , by NBUE property  and that enables us to show . 

However, under this generalized task model,  may no longer equal to . This is because in some resource allocation policies, the event  could give more information than . For example, suppose user  generates tasks with two sub-tasks, i.e., . Consider a policy that always finishes user 's sub-task  and then stops. Suppose the period length  is large enough to complete user 's sub-task . In this scenario we know for all ,  which may not equal to . 

Next we shall show  is still true under the generalized task model for a user  with . The proof can be easily extended to general . We define  to be the indicator random variable that sub-task  from user  completes in a typical period. By total probability we have that


Given that , the residual workload  is only the remaining workload of sub-task  and by the NBUE property of sub-task , we know

Similarly, if , then  is the sum of the remaining workload of sub-task , and the whole workload of sub-task  which is independent of the event . Therefore, by the NBUE property of sub-task , we have that


Now by (\ref{eqnarray_exp_E_i_given_A_i_c}) we get that


Therefore, 


The other part of the proof of Theorem \ref{thm_optimal_benchmark} remains unchanged, and thus, our discussion of  still holds. 
\commentEnd\fi

\tompecsextendedStart
\subsection{Achieving  via LLREF scheduling}
\label{appendix_LLREF_for_RB}
Given that  and  for all , since users have different periods, the challenge is how to allocate  to each user  in each period. 
We convert this to the following equivalent hard real-time scheduling problem. Consider a system where each user  periodically generates tasks with period  and deterministic task workload . The tasks are available for processing at the beginning of periods and need to be completed by the end of the corresponding periods. The objective is to schedule these tasks on  identical cores to guarantee that all tasks complete on time without exception. One solution is to use the LLREF scheduling policy which always gives a feasible schedule if it is possible. In Section \ref{subsection_LDF_TS_LLREF} we have introduced LLREF policy when users have the same periods. Next we introduce how to apply LLREF to solve this hard real-time scheduling problem where users generate tasks with different periods. 

LLREF divides the timeline into intervals by task releases/deadlines. In each interval of length , the {\em local workload} of each user  is defined as . Therefore, to complete all tasks on time it suffices to complete the local workloads of all users in each interval. To achieve that, in each interval we adopt the LLREF policy introduced in Definition \ref{defn_LLREF} to process local workloads for all users. This LLREF policy solves the hard real-time scheduling problem. 

By adopting this policy we can get a static time allocation such that each user  gets core time reservation  in each period, which further guarantees that each user  meets the QoS requirement . 
\commentEnd\fi



\end{document}
