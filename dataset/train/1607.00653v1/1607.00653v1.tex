

The objective in Eq.~\ref{eq:finalObjFn} is independent of any downstream task and the flexibility in exploration offered by \nodevec lends the learned feature representations to a wide variety of network analysis settings discussed below.

\subsection{Case Study: Les Mis\'{e}rables network}

In Section~\ref{sec:bfsdfs} we observed that BFS and DFS strategies represent extreme ends on the spectrum of embedding nodes based on the principles of homophily (\ie, network communities) and structural equivalence (\ie, structural roles of nodes). We now aim to empirically demonstrate this fact and show that \nodevec in fact can discover embeddings that obey both principles.

We use a network where nodes correspond to characters in the novel Les Mis\'{e}rables~\cite{knuth-1993} and edges connect coappearing characters. The network has 77 nodes and 254 edges. We set  and run \nodevec to learn feature representation for every node in the network. The feature representations are clustered using -means. We then visualize the original network in two dimensions with nodes now assigned colors based on their clusters.



Figure~\ref{fig:equi}(top) shows the example when we set . Notice how regions of the network (\ie, network communities) are colored using the same color. In this setting \nodevec discovers clusters/communities of characters that frequently interact with each other in the major sub-plots of the novel. Since the edges between characters are based on coappearances, we can conclude this characterization closely relates with homophily. 

In order to discover which nodes have the same structural roles we use the same network but set , use \nodevec to get node features and then cluster the nodes based on the obtained features. Here \nodevec obtains a complementary assignment of node to clusters such that the colors correspond to structural equivalence as illustrated in Figure~\ref{fig:equi}(bottom). For instance, \nodevec embeds blue-colored nodes close together. These nodes represent characters that act as bridges between different sub-plots of the novel. Similarly, the yellow nodes mostly represent characters that are at the periphery and have limited interactions. 
One could assign alternate semantic interpretations to these clusters of nodes, but the key takeaway is that \nodevec is not tied to a particular notion of equivalence. As we show through our experiments, these equivalence notions are commonly exhibited in most real-world networks and have a significant impact on the performance of the learned representations for prediction tasks.


\begin{figure}[t]
	\centering
	\includegraphics[width=0.4\textwidth]{FIG/homo}
	\vspace{-0.2cm}
	\includegraphics[width=0.4\textwidth]{FIG/struceq}
	\caption{Complementary visualizations of Les Mis\'{e}rables coappearance network generated by \nodevec with label colors reflecting homophily (top) and structural equivalence (bottom).}\label{fig:equi}
	\vspace{-0.4cm}
\end{figure}


\subsection{Experimental setup}

Our experiments evaluate the feature representations obtained through \nodevec on standard supervised learning tasks: multi-label classification for nodes and link prediction for edges. For both tasks, we evaluate the performance of \nodevec against the following feature learning algorithms:

\begin{itemize}[noitemsep,nolistsep]
	\item Spectral clustering~\cite{spectral}: This is a matrix factorization approach in which we take the top  eigenvectors of the normalized Laplacian matrix of graph  as the feature vector representations for nodes.
	\item DeepWalk 
~\cite{deepwalk}: This approach learns -dimensional feature representations by simulating uniform random walks. The sampling strategy in DeepWalk can be seen as a special case of \nodevec with  and .
	\item LINE 
~\cite{line}: This approach learns -dimensional feature representations in two separate phases. In the first phase, it learns  dimensions by BFS-style simulations over immediate neighbors of nodes. In the second phase, it learns the next  dimensions by sampling nodes strictly at a 2-hop distance from the source nodes. 
\end{itemize}

We exclude other matrix factorization approaches which have already been shown to be inferior to DeepWalk~\cite{deepwalk}. We also exclude a recent approach, GraRep~\cite{grarep}, that generalizes LINE to incorporate information from network neighborhoods beyond 2-hops, but is unable to efficiently scale to large networks. 


In contrast to the setup used in prior work for evaluating sampling-based feature learning algorithms, we generate an equal number of samples for each method and then evaluate the quality of the obtained features on the prediction task. In doing so, we discount for performance gain observed purely because of the implementation language (C/C++/Python) since it is secondary to the algorithm.
Thus, in the sampling phase, the parameters for DeepWalk, LINE and \nodevec are set such that they generate equal number of samples at runtime. As an example, if  is the overall sampling budget, then the \nodevec parameters satisfy . In the optimization phase, all these benchmarks optimize using SGD with two key differences that we correct for. First, DeepWalk uses hierarchical sampling to approximate the softmax probabilities with an objective similar to the one use by \nodevec. However, hierarchical softmax is inefficient when compared with negative sampling~\cite{word2vec2}. Hence, keeping everything else the same, we switch to negative sampling in DeepWalk which is also the de facto approximation in \nodevec and LINE. Second, both \nodevec and DeepWalk have a parameter for the number of context neighborhood nodes to optimize for and the greater the number, the more rounds of optimization are required. This parameter is set to unity for LINE, but since LINE completes a single epoch quicker than other approaches, we let it run for  epochs.

The parameter settings used for \nodevec are in line with typical values used for DeepWalk and LINE. Specifically, we set , , , , and the optimization is run for a single epoch. We repeat our experiments for  random seed initializations, and our results are statistically significant with a p-value of less than 0.01.The best in-out and return hyperparameters were learned using 10-fold cross-validation on 10\% labeled data with a grid search over . 


\subsection{Multi-label classification}







\begin{table}[t]
	\centering
	
	\begin{tabular}{l|c|c|c}
	\multicolumn{1}{c}{\textbf{Algorithm}} & \multicolumn{3}{c}{\textbf{Dataset}}      \\ 
										   & BlogCatalog     & PPI             & Wikipedia   \\ \hline
	Spectral Clustering					   & 0.0405			 & 0.0681	 	   & 0.0395		\\
	DeepWalk                               & 0.2110		     & 0.1768          & 0.1274 \\
	LINE                                   & 0.0784          & 0.1447          & 0.1164    \\
	\nodevec 			                   & \textbf{0.2581} & \textbf{0.1791} & \textbf{0.1552}     \\ \hline
	\nodevec settings (p,q)		  		   & 0.25, 0.25  	 & 4, 1	       		& 4, 0.5		\\
	{\bf Gain of \nodevec [\%]}         	& {\bf 22.3}	 & {\bf 1.3}       & {\bf 21.8 }
	\end{tabular}
	\vspace{-0.2cm}
	\caption{Macro-F scores for multilabel classification on BlogCatalog, PPI (Homo sapiens) and Wikipedia word cooccurrence networks with 50\% of the nodes labeled for
	training.}
\label{tab:mlc_macro}
\vspace{-0.4cm}
\end{table}

\begin{figure*}[t]
\centering
	\includegraphics[width=\textwidth]{FIG/mlc}
	\vspace{-0.3cm}
	\caption{Performance evaluation of different benchmarks on varying the amount of labeled data used for training. The  axis denotes the fraction of labeled data, whereas the  axis in the top and bottom rows denote the Micro-F and Macro-F scores respectively. DeepWalk and \nodevec give comparable performance on PPI. In all other networks, across all fractions of labeled data \nodevec performs best.}\label{fig:mlc}
\vspace{-0.4cm}
\end{figure*}

In the multi-label classification setting, every node is assigned one or more labels from a finite set . During the training phase, we observe a certain fraction of nodes and all their labels. The task is to predict the labels for the remaining nodes. This is a challenging task especially if  is large. 
We utilize the following datasets:
\begin{itemize}[noitemsep,nolistsep]
	\item BlogCatalog~\cite{asu}: This is a network of social relationships of the bloggers listed on the BlogCatalog website. The labels represent blogger interests inferred through the meta-data provided by the bloggers. The network has 10,312 nodes, 333,983 edges, and 39 different labels.

	\item Protein-Protein Interactions (PPI)~\cite{biogrid}: We use a subgraph of the PPI network for Homo Sapiens. The subgraph corresponds to the graph induced by nodes for which we could obtain labels from the hallmark gene sets~\cite{msigdb} and represent biological states. 
	The network has 3,890 nodes, 76,584 edges, and 50 different labels.

	\item Wikipedia ~\cite{wiki-pos}: This is a cooccurrence network of words appearing in the first million bytes of the Wikipedia dump. The labels represent the Part-of-Speech (POS) tags inferred using the Stanford POS-Tagger~\cite{postagger}. The network has 4,777 nodes, 184,812 edges, and 40 different labels.
\end{itemize}

All these networks exhibit a fair mix of homophilic and structural equivalences. For example, we expect the social network of bloggers to exhibit strong homophily-based relationships; however, there might also be some ``familiar strangers'', \ie, bloggers that do not interact but share interests and hence are structurally equivalent nodes.
The biological states of proteins in a protein-protein interaction network also exhibit both types of equivalences. For example, they exhibit structural equivalence when proteins perform functions complementary to those of neighboring proteins, and at other times, they organize based on homophily in assisting neighboring proteins in performing similar functions. The word cooccurence network is fairly dense, since edges exist between words cooccuring in a 2-length window in the Wikipedia corpus. Hence, words having the same POS tags are not hard to find, lending a high degree of homophily. At the same time, we expect some structural equivalence in the POS tags due to syntactic grammar patterns such as nouns following determiners, punctuations succeeding nouns etc.

\xhdr{Experimental results} 
The node feature representations are input to a one-vs-rest logistic regression classifier with L2 regularization. The train and test data is split equally over 10 random instances. We use the Macro-F scores for comparing performance in Table~\ref{tab:mlc_macro} and the relative performance gain is over the closest benchmark. The trends are similar for Micro-F and accuracy and are not shown. 

From the results, it is evident we can see how the added flexibility in exploring neighborhoods allows \nodevec to outperform the other benchmark algorithms. In BlogCatalog, we can discover the right mix of homophily and structural equivalence by setting parameters  and  to low values, giving us 22.3\% gain over DeepWalk and 229.2\% gain over LINE in Macro-F scores. LINE showed worse performance than expected, which can be explained by its inability to reuse samples, a feat that can be easily done using the random walk methods. Even in our other two networks, where we have a mix of equivalences present, the semi-supervised nature of \nodevec can help us infer the appropriate degree of exploration necessary for feature learning. In the case of PPI network, the best exploration strategy (, ) turns out to be virtually indistinguishable from DeepWalk's uniform (, ) exploration giving us only a slight edge over DeepWalk by avoiding redudancy in already visited nodes through a high  value, but a convincing 23.8\% gain over LINE in Macro-F scores. However, in general, the uniform random walks can be much worse than the exploration strategy learned by \nodevec. As we can see in the Wikipedia word cooccurrence network, uniform walks cannot guide the search procedure towards the best samples and hence, we achieve a gain of 21.8\% over DeepWalk and 33.2\% over LINE.

For a more fine-grained analysis, we also compare performance while varying the train-test split from 10\% to 90\%, while learning parameters  and  on 10\% of the data as before. For brevity, we summarize the results for the Micro-F and Macro-F scores graphically in Figure~\ref{fig:mlc}. Here we make similar observations. All methods significantly outperform Spectral clustering, DeepWalk outperforms LINE, \nodevec consistently outperforms LINE and achieves large improvement over DeepWalk across domains. For example, we achieve the biggest improvement over DeepWalk of 26.7\% on BlogCatalog at 70\% labeled data. In the worst case, the search phase has little bearing on learned representations in which case \nodevec is equivalent to DeepWalk. Similarly, the improvements are even more striking when compared to LINE, where in addition to drastic gain (over 200\%) on BlogCatalog, we observe high magnitude improvements upto 41.1\% on other datasets such as PPI while training on just 10\% labeled data.




\begin{figure*}[t]
\centering
\begin{subfigure}[b]{0.70\textwidth}
\includegraphics[width=\textwidth]{FIG/params}
\caption{}\label{fig:mlc_params}
\end{subfigure} 
~
\begin{subfigure}[b]{0.28\textwidth}
\includegraphics[width=\textwidth]{FIG/perturbations_BC}
\caption{}\label{fig:mlc_perturb}
\end{subfigure}
\vspace{-0.2cm}
\caption{(a). Parameter sensitivity (b). Perturbation analysis for multilabel classification on the BlogCatalog network.}
\vspace{-0.4cm}
\end{figure*}

\subsection{Parameter sensitivity} 

The \nodevec algorithm involves a number of parameters and in Figure~\ref{fig:mlc_params}, we examine how the different choices of parameters affect the performance of \nodevec on the BlogCatalog dataset using a 50-50 split between labeled and unlabeled data. Except for the parameter being tested, all other parameters assume default values. The default values for  and  are set to unity.

We measure the Macro-F score as a function of parameters  and . The performance of \nodevec improves as the in-out parameter  and the return parameter  decrease. This increase in performance can be based on the homophilic and structural equivalences we expect to see in BlogCatalog. While a low  encourages outward exploration, it is balanced by a low  which ensures that the walk does not go too far from the start node.

We also examine how the number of features  and the node's neighborhood parameters (number of walks , walk length , and neighborhood size ) affect the performance. We observe that performance tends to saturate once the dimensions of the representations reaches around 100.
Similarly, we observe that increasing the number and length of walks per source improves performance, which is not surprising since we have a greater overall sampling budget  to learn representations. Both these parameters have a relatively high impact on the performance of the method. Interestingly, the context size,  also improves performance at the cost of increased optimization time. However, the performance differences are not that large in this case.

 
\subsection{Perturbation Analysis}
For many real-world networks, we do not have access to accurate information about the network structure. We performed a perturbation study where we analyzed the performance of \nodevec for two imperfect information scenarios related to the edge structure in the BlogCatalog network. In the first scenario, we measure performace as a function of the fraction of missing edges (relative to the full network). The missing edges are chosen randomly, subject to the constraint that the number of connected components in the network remains fixed. As we can see in Figure~\ref{fig:mlc_perturb}(top), the decrease in Macro-F score as the fraction of missing edges increases is roughly linear with a small slope. Robustness to missing edges in the network is especially important in cases where the graphs are evolving over time (\eg, citation networks), or where network construction is expensive (\eg, biological networks). 

In the second perturbation setting, we have noisy edges between randomly selected pairs of nodes in the network. As shown in Figure~\ref{fig:mlc_perturb}(bottom), the performance of \nodevec declines slightly faster initially when compared with the setting of missing edges, however, the rate of decrease in Macro-F score gradually slows down over time. Again, the robustness of \nodevec to false edges is useful in several situations such as sensor networks where the measurements used for constructing the network are noisy.

 

\subsection{Scalability}
\begin{figure}[t]
\centering
\includegraphics[width=\columnwidth]{FIG/scale}
\vspace{-0.5cm}
\caption{Scalability of \nodevec on Erdos-Renyi graphs with an average degree of 10.}\label{fig:scale}
\vspace{-0.6cm}
\end{figure}

To test for scalability, we learn node representations using \nodevec with default parameter values for Erdos-Renyi graphs with increasing sizes from 100 to 1,000,000 nodes and constant average degree of 10. In Figure~\ref{fig:scale}, we empirically observe that \nodevec scales linearly with increase in number of nodes generating representations for one million nodes in less than four hours. The sampling procedure comprises of preprocessing for computing transition probabilities for our walk (negligibly small) and simulation of random walks. The optimization phase is made efficient using negative sampling~\cite{word2vec2} and asynchronous SGD~\cite{recht-nips2011}. 

Many ideas from prior work serve as useful pointers in making the sampling procedure computationally efficient. We showed how random walks, also used in DeepWalk~\cite{deepwalk}, allow the sampled nodes to be reused as neighborhoods for different source nodes appearing in the walk. Alias sampling allows our walks to generalize to weighted networks, with little preprocessing~\cite{line}. Though we are free to set the search parameters based on the underlying task and domain at no additional cost, learning the best settings of our search parameters adds an overhead. However, as our experiments confirm, this overhead is minimal since \nodevec is semi-supervised and hence, can learn these parameters efficiently with very little labeled data. 



\subsection{Link prediction}
In link prediction, we are given a network with a certain fraction of edges removed, and we would like to predict these missing edges. We generate the labeled dataset of edges as follows: To obtain positive examples, we remove 50\% of edges chosen randomly from the network while ensuring that the residual network obtained after the edge removals is connected, and to generate negative examples, we randomly sample an equal number of node pairs from the network which have no edge connecting them. 

Since none of feature learning algorithms have been previously used for link prediction, we additionally evaluate \nodevec against some popular heuristic scores that achieve good performance in link prediction. The scores we consider are defined in terms of the neighborhood sets of the nodes constituting the pair (see Table~\ref{tab:lp_scores}). We test our benchmarks on the following datasets:

\begin{itemize}[noitemsep,nolistsep]
	\item Facebook~\cite{snapnets}: In the Facebook network, nodes represent users, and edges represent a friendship relation between any two users. The network has 4,039 nodes and 88,234 edges.
	\item Protein-Protein Interactions (PPI)~\cite{biogrid}: In the PPI network for Homo Sapiens, nodes represent proteins, and an edge indicates a biological interaction between a pair of proteins. The network has 19,706 nodes and 390,633 edges.
	\item arXiv ASTRO-PH~\cite{snapnets}: This is a collaboration network generated from papers submitted to the e-print arXiv where nodes represent scientists, and an edge is present between two scientists if they have collaborated in a paper. The network has 18,722 nodes and 198,110 edges.
\end{itemize}

\xhdr{Experimental results} We summarize our results for link prediction in Table~\ref{tab:lp_random}. The best  and  parameter settings for each \nodevec entry are omitted for ease of presentation. A general observation we can draw from the results is that the learned feature representations for node pairs significantly outperform the heuristic benchmark scores with \nodevec achieving the best AUC improvement on 12.6\% on the arXiv dataset over the best performing baseline (Adamic-Adar~\cite{adamicadar}). 

\begin{table}
\centering
\begin{tabular}{l|c}
\textbf{Score} & \textbf{Definition} \\ \hline
Common Neighbors &  \\
Jaccard's Coefficient &  \\
Adamic-Adar Score &  \\
Preferential Attachment & 
\end{tabular}
\vspace{-0.2cm}
\caption{Link prediction heuristic scores for node pair  with immediate neighbor sets  and  respectively.}
\label{tab:lp_scores}
\vspace{-0.4cm}
\end{table}

Amongst the feature learning algorithms, \nodevec outperforms both DeepWalk and LINE in all networks with gain up to 3.8\% and 6.5\% respectively in the AUC scores for the best possible choices of the binary operator for each algorithm. When we look at operators individually (Table~\ref{tab:edgeop}), \nodevec outperforms DeepWalk and LINE barring a couple of cases involving the Weighted-L1 and Weighted-L2 operators in which LINE performs better. Overall, the Hadamard operator when used with \nodevec is highly stable and gives the best performance on average across all networks. 

\begin{table}[h]
\centering
	\begin{tabular}{c|l|l|l|l}
	\multicolumn{1}{c}{\textbf{Op}} & \multicolumn{1}{c}{\textbf{Algorithm}} & \multicolumn{3}{c}{\textbf{Dataset}}      \\ 
	         			    & & Facebook     & PPI    & arXiv      \\ \hline
	& Common Neighbors        & 0.8100 & 0.7142 & 0.8153 \\
	& Jaccard's Coefficient   & 0.8880 & 0.7018 & 0.8067 \\
	& Adamic-Adar             & 0.8289 & 0.7126 & 0.8315 \\
	& Pref. Attachment 		  & 0.7137 & 0.6670 & 0.6996 \\ \hline
	& Spectral Clustering     & 0.5960 & 0.6588 & 0.5812 \\
	(a) & DeepWalk            & 0.7238 & 0.6923 & 0.7066 \\ & LINE 			  		  & 0.7029 & 0.6330 & 0.6516 \\
	& \nodevec 		  		  & 0.7266 & 0.7543 & 0.7221 \\ \hline 
	& Spectral Clustering     & 0.6192 & 0.4920 & 0.5740 \\
	(b) & DeepWalk            & \textbf{0.9680} & 0.7441 & 0.9340 \\ & LINE 			  		  & 0.9490 & 0.7249 & 0.8902  \\
	& \nodevec 		  		  & \textbf{0.9680} & \textbf{0.7719} & \textbf{0.9366}\\ \hline 
	& Spectral Clustering     & 0.7200 & 0.6356 & 0.7099\\
	(c) & DeepWalk            & 0.9574 & 0.6026 & 0.8282 \\ & LINE 			  		  & 0.9483 & 0.7024 & 0.8809 \\
	& \nodevec 	      		  & 0.9602 & 0.6292 & 0.8468 \\ \hline 
	& Spectral Clustering     & 0.7107 & 0.6026 & 0.6765 \\
	(d) & DeepWalk            & 0.9584 & 0.6118 & 0.8305 \\ & LINE 			  		  & 0.9460 & 0.7106 & 0.8862 \\
	& \nodevec          	  & 0.9606 & 0.6236 & 0.8477  \\ 
	\end{tabular}
	\vspace{-0.2cm}
	\caption{Area Under Curve (AUC) scores for link prediction. Comparison with popular baselines and embedding based methods bootstapped using binary operators: (a) Average, (b) Hadamard, (c) Weighted-L1, and (d) Weighted-L2
	(See Table~\ref{tab:edgeop} for definitions).
	}\label{tab:lp_random}
	\vspace{-0.4cm}
\end{table}



