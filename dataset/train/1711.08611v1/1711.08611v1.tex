\documentclass{sig-alternate-05-2015}
\usepackage{multirow}
\usepackage[british]{babel}

\begin{document}


\CopyrightYear{2016}
\setcopyright{acmcopyright}
\conferenceinfo{CIKM'16 ,}{October 24-28, 2016, Indianapolis, IN, USA}
\isbn{978-1-4503-4073-1/16/10}\acmPrice{\^{\dagger}^{\dagger}^{\ddagger}^{\ddagger}^{\dagger}^{\ddagger}\{\}T_1T_2\PhiF\PhiF\PhiF\PhiF\PhiF\PhiF\PhiF\PhiFq\!\!=\!\!\{w^{(q)}_1,\dots,w^{(q)}_M\}d=\{w^{(d)}_1,\dots,w^{(d)}_N\}w^{(q)}_i, i=1,\dots,Mw^{(d)}_j, j=1,\dots,Ns\otimesh\boldsymbol{z}_i^{(l)}, l=0,\dots,Lig_i, i=1,\dots,M\boldsymbol{W}^{(l)}l\boldsymbol{b}^{(l)}l[-1,1]0.5\{[-1,-0.5), [-0.5,-0), [0,0.5),[0.5,1), [1,1]\}(car, rent, truck, bump, injunction, runway)(1, 0.2, 0.7, 0.3, -0.1, 0.1)[0, 1, 3, 1, 1]KKK\boldsymbol{w}_g\boldsymbol{x}^{(q)}_i, i=1,\dots,Mi\boldsymbol{x}^{(q)}_ii\boldsymbol{w}_g\boldsymbol{x}^{(q)}_ii\boldsymbol{w}_g(q,d^+,d^-)d^+d^-qs(q,d)(q,d)\Theta2060^{th}60^{th}_T_D_T_D_T_D^{3}_T_D_{IND}_{COS}_{DOT}_{CH\times IDF}300101010^{-4}100.14.1pvalue \le 0.05_D^-^-^-^-^-^-_D^-^-^-^-^-^-^-^-^-^-^-^-^-^-^-^-^-^-_{IND}^-^-^-^-^-^-_{COS}^-^-^-^-^-^-_{DOT}^-^-^-^-^-^-_{CH\times TV}_{NH\times TV}^-^-^-^-^-^-_{LCH\times TV}^+^+^+^+_{CH\times IDF}^+_{NH\times IDF}^-^-^-^-^-^-_{LCH\times IDF}^+^+^+^+^+^+^+_T^-^-^-^-^-^-_D^-^-^-^-^-^-_T^-^-^-^-^-^-_D^-^-^-^-^-^-^-^-^-^-^-^-^-^-^-^-^-^-_{IND}^-^-^-^-^-^-_{COS}^-^-^-^-^-^-_{DOT}^-^-^-^-^-^-_{CH\times TV}_{NH\times TV}^-^-^-^-^-^-_{LCH\times TV}^+^+^+_{CH\times IDF}^+^+_{NH\times IDF}^-^-^-^-^-^-_{LCH\times IDF}^+^+^+^+^+^+364683\times 330511554551,0002020\alpha=0.052,0001,000_T_T_T_T_{COS}_{IND}_{COS}_{DOT}_{IND}_{COS}_{DOT}_{COS}_{DOT}_{DOT}_{DOT}300155_{LCH\times IDF}11.9\%14.7\%12\%_{LCH\times IDF}_{LCH\times IDF}_{LCH\times UNI}K30K_{DYN\times IDF}_{KMAX\times IDF}_{LCH\times UNI}_{LCH\times UNI}_{LCH\times IDF}6.8\%3.5\%_{DYN\times IDF}_{LCH\times IDF}_{KMAX\times IDF}_{KMAX\times IDF}_{LCH\times IDF}_{KMAX\times IDF}K50100300500300_{tree}_{tree}$ defines interactions in the product space of dependency trees. A deep neural network is then leveraged for making a matching decision on the two short texts, on the basis of these local interactions. In \cite{wan2016match}, Wan et al.~introduced Match-SRNN to model the recursive matching structure in the local interactions so that long-distance dependency between the interactions can be captured. The proposed model was evaluated on two tasks, including community based question answering and paper citation \mbox{matching}.

Most of these deep matching models are designed for the semantic matching problem, which is significantly different from the relevance matching problem in ad-hoc retrieval. In this work, we introduce a model specifically designed for the relevance matching problem.

\section{Conclusions}
In this paper, we point out that there are significant differences between semantic matching for many NLP tasks and relevance matching for the ad-hoc retrieval task. Many existing deep matching models designed for the semantic matching problem thus may not fit the ad-hoc retrieval task. Based on this analysis, we propose a novel deep relevance matching model for ad-hoc retrieval, by explicitly addressing the three factors in relevance matching. The proposed model contains three major components, i.e., matching histogram mapping, a feed forward matching network, and a term gating network. Experimental results on two representative benchmark datasets show that our model can significantly outperform traditional retrieval models as well as state-of-the-art deep matching models.

For future work, we would like to leverage larger training data, e.g. click-through logs, to train deeper DRMM so that we can further explore the potential of the proposed model on ad-hoc retrieval. We may also include phrase embeddings so that phrases can be treated as a whole rather than separate terms. In this way, we expect the local interactions can better reflect the meaning by using the proper semantic units in language, leading to better retrieval performance.


\section{Acknowledgments}
This work was supported in part by the Center for Intelligent Information Retrieval, in part by the 973 Program of China under Grant No. 2014CB340401 and 2013CB329606, in part by the National Natural Science Foundation of China under Grant No. 61232010, 61472401, 61425016, and 61203298, and in part by the Youth Innovation Promotion Association CAS under Grant No. 20144310 and 2016102.


\bibliographystyle{abbrv}
\begin{thebibliography}{10}

\bibitem{burges2005learning}
C.~Burges, T.~Shaked, E.~Renshaw, A.~Lazier, M.~Deeds, N.~Hamilton, and
  G.~Hullender.
\newblock Learning to rank using gradient descent.
\newblock In {\em ICML}, pages 89--96. ACM, 2005.

\bibitem{callan1995trec}
J.~P. Callan, W.~B. Croft, and J.~Broglio.
\newblock Trec and tipster experiments with inquery.
\newblock {\em IPM}, 31(3):327--343, 1995.

\bibitem{cormack2011efficient}
G.~V. Cormack, M.~D. Smucker, and C.~L. Clarke.
\newblock Efficient and effective spam filtering and re-ranking for large web
  datasets.
\newblock {\em Information retrieval}, 14(5):441--465, 2011.

\bibitem{duchi2011adaptive}
J.~Duchi, E.~Hazan, and Y.~Singer.
\newblock Adaptive subgradient methods for online learning and stochastic
  optimization.
\newblock {\em JMLR}, 12:2121--2159, 2011.

\bibitem{fang2004formal}
H.~Fang, T.~Tao, and C.~Zhai.
\newblock A formal study of information retrieval heuristics.
\newblock In {\em SIGIR}, pages 49--56. ACM, 2004.

\bibitem{fang2011diagnostic}
H.~Fang, T.~Tao, and C.~Zhai.
\newblock Diagnostic evaluation of information retrieval models.
\newblock {\em TOIS}, 29(2):7, 2011.

\bibitem{fang2006semantic}
H.~Fang and C.~Zhai.
\newblock Semantic term matching in axiomatic approaches to information
  retrieval.
\newblock In {\em SIGIR}, pages 115--122. ACM, 2006.

\bibitem{gao2015modeling}
J.~Gao, P.~Pantel, M.~Gamon, X.~He, L.~Deng, and Y.~Shen.
\newblock Modeling interestingness with deep neural networks.
\newblock EMNLP, October 2014.

\bibitem{giles2001overfitting}
R.~C. S. L.~L. Giles.
\newblock Overfitting in neural nets: Backpropagation, conjugate gradient, and
  early stopping.
\newblock In {\em NIPS}, volume~13, page 402. MIT Press, 2001.

\bibitem{hinton2012deep}
G.~Hinton, L.~Deng, D.~Yu, G.~E. Dahl, A.-r. Mohamed, N.~Jaitly, A.~Senior,
  V.~Vanhoucke, P.~Nguyen, T.~N. Sainath, et~al.
\newblock Deep neural networks for acoustic modeling in speech recognition: The
  shared views of four research groups.
\newblock {\em Signal Processing Magazine}, 29(6):82--97, 2012.

\bibitem{hu2014convolutional}
B.~Hu, Z.~Lu, H.~Li, and Q.~Chen.
\newblock Convolutional neural network architectures for matching natural
  language sentences.
\newblock In {\em NIPS}, pages 2042--2050, 2014.

\bibitem{huang2013learning}
P.-S. Huang, X.~He, J.~Gao, L.~Deng, A.~Acero, and L.~Heck.
\newblock Learning deep structured semantic models for web search using
  clickthrough data.
\newblock In {\em CIKM}, pages 2333--2338. ACM, 2013.

\bibitem{kalchbrenner2014convolutional}
N.~Kalchbrenner, E.~Grefenstette, and P.~Blunsom.
\newblock A convolutional neural network for modelling sentences.
\newblock {\em arXiv preprint arXiv:1404.2188}, 2014.

\bibitem{kenter2015short}
T.~Kenter and M.~de~Rijke.
\newblock Short text similarity with word embeddings.
\newblock In {\em CIKM}, pages 1411--1420. ACM, 2015.

\bibitem{krovetz1993viewing}
R.~Krovetz.
\newblock Viewing morphology as an inference process.
\newblock In {\em SIGIR}, pages 191--202. ACM, 1993.

\bibitem{lecun1995convolutional}
Y.~LeCun and Y.~Bengio.
\newblock Convolutional networks for images, speech, and time series.
\newblock {\em The handbook of brain theory and neural networks},
  3361(10):1995, 1995.

\bibitem{lu2013deep}
Z.~Lu and H.~Li.
\newblock A deep architecture for matching short texts.
\newblock In {\em NIPS}, pages 1367--1375, 2013.

\bibitem{mikolov2013distributed}
T.~Mikolov, I.~Sutskever, K.~Chen, G.~S. Corrado, and J.~Dean.
\newblock Distributed representations of words and phrases and their
  compositionality.
\newblock In {\em NIPS}, pages 3111--3119, 2013.

\bibitem{pang2016text}
L.~Pang, Y.~Lan, J.~Guo, J.~Xu, S.~Wan, and X.~Cheng.
\newblock Text matching as image recognition.
\newblock 2016.

\bibitem{pennington2014glove}
J.~Pennington, R.~Socher, and C.~D. Manning.
\newblock Glove: Global vectors for word representation.
\newblock In {\em EMNLP}, pages 1532--1543, 2014.

\bibitem{qiu2015convolutional}
X.~Qiu and X.~Huang.
\newblock Convolutional neural tensor network architecture for community-based
  question answering.
\newblock In {\em IJCAI}, pages 1305--1311, 2015.

\bibitem{robertson1994some}
S.~E. Robertson and S.~Walker.
\newblock Some simple effective approximations to the 2-poisson model for
  probabilistic weighted retrieval.
\newblock In {\em SIGIR}, pages 232--241. ACM, 1994.

\bibitem{shen2014learning}
Y.~Shen, X.~He, J.~Gao, L.~Deng, and G.~Mesnil.
\newblock Learning semantic representations using convolutional neural networks
  for web search.
\newblock In {\em WWW}, pages 373--374, 2014.

\bibitem{smucker2007comparison}
M.~D. Smucker, J.~Allan, and B.~Carterette.
\newblock A comparison of statistical significance tests for information
  retrieval evaluation.
\newblock In {\em CIKM}, pages 623--632. ACM, 2007.

\bibitem{socher2011dynamic}
R.~Socher, E.~H. Huang, J.~Pennin, C.~D. Manning, and A.~Y. Ng.
\newblock Dynamic pooling and unfolding recursive autoencoders for paraphrase
  detection.
\newblock In {\em NIPS}, pages 801--809, 2011.

\bibitem{wan2015deep}
S.~Wan, Y.~Lan, J.~Guo, J.~Xu, L.~Pang, and X.~Cheng.
\newblock A deep architecture for semantic matching with multiple positional
  sentence representations.
\newblock {\em arXiv preprint arXiv:1511.08277}, 2015.

\bibitem{wan2016match}
S.~Wan, Y.~Lan, J.~Xu, J.~Guo, L.~Pang, and X.~Cheng.
\newblock Match-srnn: Modeling the recursive matching structure with spatial
  rnn.
\newblock In {\em IJCAI}, 2016.

\bibitem{wang2015syntax}
M.~Wang, Z.~Lu, H.~Li, and Q.~Liu.
\newblock Syntax-based deep matching of short texts.
\newblock {\em arXiv preprint arXiv:1503.02427}, 2015.

\bibitem{williams1986learning}
D.~R. G. H.~R. Williams and G.~Hinton.
\newblock Learning representations by back-propagating errors.
\newblock {\em Nature}, 323:533--536, 1986.

\bibitem{yin2015multigrancnn}
W.~Yin and H.~Sch{\"u}tze.
\newblock Multigrancnn: An architecture for general matching of text chunks on
  multiple levels of granularity.
\newblock In {\em ACL}, pages 63--73, 2015.

\bibitem{zhai2001study}
C.~Zhai and J.~Lafferty.
\newblock A study of smoothing methods for language models applied to ad hoc
  information retrieval.
\newblock In {\em SIGIR}, pages 334--342. ACM, 2001.

\bibitem{zheng2015learning}
G.~Zheng and J.~Callan.
\newblock Learning to reweight terms with distributed representations.
\newblock In {\em SIGIR}, pages 575--584. ACM, 2015.

\end{thebibliography}

\end{document}
