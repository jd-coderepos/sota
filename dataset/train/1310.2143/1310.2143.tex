\documentclass{llncs}
\usepackage{microtype}
\pdfoutput=1

\usepackage{amsmath}
\usepackage{amssymb}

\usepackage{graphicx}
\usepackage{epstopdf}

\usepackage{pgf}
\usepackage{tikz}
\usetikzlibrary{automata,calc}
\usepackage{color}
\definecolor{bluestate}{RGB}{135,206,250}

\usepackage{algorithm}
\usepackage{algorithmicx}
\usepackage{algpseudocode}

\usepackage{booktabs} \usepackage{wrapfig}  

\def\A{\mathcal{A}}
\def\sc{\mathbf{T}}
\def\ns{\star}
\def\prod{\mathbf{A}}
\def\t{\mathbf{t}}
\def\s{\mathbf{s}}
\def\U{\mathcal{U}}
\newcommand{\inp}[1]{{}^\bullet\!{#1}}
\newcommand{\out}[1]{{#1}^\bullet}
\def\N{\mathcal{N}}
\def\C{\mathcal{C}}
\def\S{\mathcal{S}}
\def\co{co}
\def\tco{coc}
\def\conf{\mathrel{\#}}
\def\P{\mathcal{P}}
\def\eqrel{\equiv}
\def\embset{\mathcal{A}^\prod}
\def\strat{\prec}
\def\scause{\ll}
\newcommand{\st}[1]{\mathbf{St}(#1)}
\newcommand{\past}[1]{[#1]}
\newcommand{\ma}[1]{M(#1)}
\def\ocseq{w}
\newcommand{\concset}[1]{conc_i^\strat(#1)}
\newcommand{\finalconcset}[1]{conc_i(#1)}
\newcommand{\Tr}[1]{{\it Tr}(#1)}
\newcommand{\Coni}[2]{{\it Ico}_{#1}(#2)}
\renewcommand{\S}{{\cal S}}
\def\R{\mathbb{R}_+}
\def\trace{tr}
\def\stateseq{S}
\def\blocks{\vdash_{\!\N}}
\def\rblocks{\mathord{\blocks}}
\def\ind#1{\mathit{ind}(#1)}
\def\parb#1{\mathit{par}(#1)}
\def\worklist{\mathit{worklist}}

\def\by#1{\mathop{{\hbox{\setbox0=\hbox{}{}}}}}



\title{Computation of summaries using net unfoldings}
\author{Javier Esparza\inst{1}, Lo\"ig Jezequel\inst{2}, and Stefan Schwoon\inst{3}}
\institute{Institut f\"ur Informatik, Technische Universit\"at M\"unchen, Germany
\and
ENS Cachan Bretagne, Rennes, France
\and
LSV, ENS Cachan \& CNRS, INRIA Saclay, France}


\begin{document}

\maketitle

\begin{abstract}
We study the following {\em summarization problem}: given a parallel
composition  of labelled transition systems
communicating with the environment through a distinguished component , 
efficiently compute a {\em summary }  such that  and  are trace-equivalent for every environment . While  
can be computed using elementary automata theory, the resulting algorithm suffers from
the state-explosion problem. We present a new, simple but subtle algorithm based on net unfoldings, 
a partial-order semantics, give some experimental results using an implementation on top of \textsc{Mole}, and show that our algorithm can handle {\em divergences} and compute {\em weighted summaries} with minor modifications.


\end{abstract}

\section{Introduction}

We address a fundamental problem in automatic compositional verification. Consider a 
parallel composition  of processes,
modelled as labelled transition systems, which is itself part of a larger system  for some environment .
Assume that  is the interface of  with the environment, i.e., 
 communicates with the outer world only through actions 
of . The task consists in computing a new interface 
 with the same set
of actions as  such that  and  
have the same behaviour. In other words, the environment  cannot distinguish between 
 and . Since
 usually has a much smaller state space than  (making
 easier to analyse) we call it a {\em summary}.

We study the problem in a CSP-like setting \cite{Hoare85}:
parallel composition is by rendez-vous, and the behaviour of a transition
system is given by its trace semantics. 

It is easy to compute  using elementary automata theory:
we first compute the transition system of , whose states  
are tuples , where  is a state of . Then we
hide all actions except those of the interface, i.e., we 
replace them by -transitions (-transitions in CSP terminology). 
We can then eliminate all -transitions using standard algorithms, and, if
desired, compute the minimal summary by applying e.g. Hopcroft's algorithm.
The problem of this approach is the state-space explosion: the number of states of 
 can grow exponentially in the number of sequential components. While this
is unavoidable in the worst case (deciding whether  has an empty set of traces 
is a PSPACE-complete problem, and the minimal summary  may be exponentially larger than 
 in the worst case, see e.g. \cite{HarelKV97}) the combinatorial explosion happens 
already in trivial cases: if the components  do not communicate at all, 
we can obviously take , but the algorithm we have just 
described will need 
exponential time and space.

We present a technique to palliate this problem based on 
net unfoldings (see e.g. \cite{Esparza08}). Net unfoldings are a partial-order semantics for 
concurrent systems, closely related to event structures~\cite{Winskel11}, that provides very 
compact representations of the state space for systems with a high degree of concurrency. 
Intuitively, an unfolding is the extension to parallel compositions
of the notion of unfolding a transition system into a tree. The unfolding
is usually infinite. We show how to algorithmically construct a finite 
prefix of it from which the summary can be easily extracted. The algorithm 
can be easily implemented re-using many 
components of existing unfolders like \textsc{Punf}~\cite{Punf}
and \textsc{Mole}~\cite{Mole}.
However, its correctness proof is surprisingly subtle. This proof is 
the main contribution of the paper. 
However, we also evaluate the algorithm on some classical benchmarks \cite{Cor96}.
We then show that -- with minor modifications -- the algorithm can be extended so that the summary obtained contains information about the possible divergences, that is whether or not after a given finite trace of the interface  it is possible that  evolves silently forever (i.e. without using any action of ).
And finally, we show how to extend the algorithm to deal with weighted systems:  then also gives for each of its finite traces the minimum cost in  to execute this trace.

{\bf Related work.} The summarization problem has been extensively studied in an 
interleaving setting (see e.g. \cite{GrafS90,Valmari96,zaraket2005scalable}), in which one 
first constructs the transition system of  and then reduces it. 
We study it in a partial-order setting.

Net unfoldings, and in general partial-order semantics, have been used to solve many analysis problems: deadlock \cite{Mcmillan95,Khomenko00}, 
reachability and model-checking questions \cite{Esparza96,Couvreur00,Khomenko03b,Esparza08,Baldan12}, diagnosis 
\cite{Fabre05}, and other specific applications \cite{Khomenko06,Hickmott07}. To the best of our knowledge 
we are the first to explicitly study the summarization problem. 

Our problem can be solved with the help of Zielonka's algorithm \cite{Zielonka87,Mukund94,Genest10}, which yields 
an asynchronous automaton trace-equivalent to . The projection of this automaton onto the alphabet of  
yields a summary . However, Zielonka's algorithm is notoriously complicated and, contrary to our algorithm, 
requires to store much additional information for each event \cite{Mukund94}. 
In \cite{Fabre09},  the complete tuple  is computed -- possibly in a weighted context -- with an iterative message-passing algorithm that 
transfers information between components until a fixed point is reached. However, termination
is only guaranteed when the communication graph is acyclic.

This paper extends~\cite{Esparza13} with proofs and implementation details.

\section{Preliminaries}

\subsection{Transition systems}

A \emph{labelled transition system} (LTS) is a tuple  where  
is a set of \emph{actions},  is a set of \emph{states}, 
 is a set of \emph{transitions}, 
is a {\em labelling function}, and  is an \emph{initial state}. 
An -transition
is a transition labelled by . 
We use this definition -- excluding the possibility to have two transitions with different labels between the same pair of states -- for simplicity. 
However, the results presented in this paper would still hold if this possibility was not excluded.
A sequence of transitions  is an \emph{execution} of  if there
is a sequence  of states such that  
for every . We write  (or  when  is finite with  as last transition). An execution 
is a \emph{history} if . 
A sequence  
of actions is a \emph{computation} if there is an execution 
such that ; if , 
then we also write . 
It is a \emph{trace} if{}f there exists such  which is an history.
We call  a \emph{realization} of .
Abusing language, given an execution , we denote by  the 
computation  (even if it is not necessarily a trace).
The set of traces 
of  is denoted by .
Figure~\ref{fig:transitionsystems} shows (on its left) three transition systems. 

\begin{figure}[htbp]
\centering
\includegraphics[scale=0.7]{tsys_prefix.pdf}
\caption{Three labeled transition systems (left) and a branching process (right)}\label{fig:transitionsystems}\label{fig:petrinet}\label{fig:unfolding}
\end{figure}


Let  be LTSs where . 
The {\em parallel composition}   is the LTS 
defined as follows. The set of actions
is . The states, called \emph{global states}, are the tuples  
 such that  for every . 
The \emph{initial global state} is . The transitions, called {\em global transitions},
are the tuples  such that there is an action  satisfying 
 for every : if , then  is an -transition of ,
otherwise ; the label of  is the action . 
If  we say that  \emph{participates} in . 
It is easy to see that  is a trace of  if{}f for every  the projection of  on , denoted by , is a trace of .


\subsection{Petri nets}

A \emph{labelled net} is a tuple  where  is a set of {\em actions},  and  are 
disjoint sets of \emph{places} and \emph{transitions} (jointly called \emph{nodes}),  is a set
of {\em arcs}, and  is a {\em labelling
function}. For  we denote by  and  the sets of \emph{inputs} and \emph{outputs} of , respectively. A set  of places is called a \emph{marking}.  
A \emph{labelled Petri net} is a tuple  where  is a labelled net and  is the \emph{initial marking}.
A marking  \emph{enables} a transition  if .
In this case  can \emph{occur} or \emph{fire}, leading to the new marking .
An \emph{occurrence sequence} is a (finite or infinite) sequence of transitions that can occur from  in the 
order specified by the sequence. A \emph{trace} is the sequence of labels of an occurrence 
sequence. The set of traces of  is denoted by .

\subsection{Branching processes}

The finite \emph{branching processes} of 
are labelled Petri nets whose places are labelled with states of , and 
whose transitions are labelled with global transitions of . Following tradition, 
we call the places and transitions of these nets {\em conditions} and {\em events}, respectively.
 (Since global transitions are labelled with 
actions, each event is also implicitly labelled with an action.)
We say that a marking  of these nets {\em enables} a global transition 
 of  if for every state  some condition of  is labelled by . 
The set of {\em finite branching processes} of  is defined inductively as follows:
\begin{enumerate}
\item A labelled Petri net with conditions  labelled by , 
no events, and  
with initial marking ,
is a branching process of .
\item Let  be a branching process of  such that some reachable marking of  enables some  
global transition . Let  be the subset of conditions of the marking labelled by . 
If  has no event labelled by  with  as input set, then the Petri net
obtained by adding to : a new event , labelled by ; a new condition for every state  of 
, labelled by ; new arcs leading from each condition of  to , and from  to each 
of the new conditions, is also a branching process of . 
\end{enumerate}
Figure~\ref{fig:unfolding} shows on the right a branching process 
of the parallel composition of the LTSs on the left. Events are labelled with their corresponding actions.

The set of all branching processes of a net, finite and infinite, is defined by
closing the finite branching processes under countable unions (after a suitable renaming of conditions and events) \cite{Esparza08}.
In particular, the union of 
all finite branching processes yields the {\em unfolding} of the net, which 
intuitively corresponds to the result of exhaustively adding all extensions in the definition above. 

A {\em trace} of a branching process  is the sequence of action labels of an occurrence sequence of events of . In Figure~\ref{fig:unfolding},
firing the events on the top half of the process yields any of the traces 
, , , or .
The sets of traces of 
and of its unfolding coincide.

Let  be nodes of a branching process. We say that  is 
a \emph{causal predecessor} of , denoted by , if there is a non-empty path 
of arcs from  to ; further,
 denotes that either  or . If  or , then  and 
 are \emph{causally related}.
We say that  and  are \emph{in conflict}, denoted by , if there is a 
condition  (different from  and ) from which one can reach both  and , 
exiting  by different arcs.
Finally,  and  are \emph{concurrent} if they are neither causally related nor 
in conflict.

A set of events  is a \emph{configuration} if it is \emph{causally closed} (that is, 
if  and  then ) and \emph{conflict-free} (that is, for every 
,  and  are not in conflict). 
The \emph{past} of an event , denoted by , is the set of events  such 
that  (so it is a configuration). For any event ,  we denote by  the unique marking reached by 
any occurrence sequence that fires exactly the events of . 
Notice that, for each component  of ,  contains exactly one condition 
labelled by a state of . We denote this condition by .
We write  and call it the 
\emph{global state reached by }.


\section{The Summary Problem}

Let  be a parallel composition with a distinguished
component , called the {\em interface}. An {\em environment} of  is any LTS
 (possibly a parallel composition) that only communicates with  through the interface,
i.e, . We wish to
compute a {\em summary} , i.e., an LTS with the same actions as  such that 
 for every 
environment , where  denotes the projection of the traces of  onto 
. It is well known (and follows easily from the definitions) that this holds if{}f 
 \cite{Hoare85}. We therefore address the following problem:

\begin{definition}[Summary problem]
Given LTSs  with interface ,
compute an LTS  satisfying , 
where . 
\end{definition}

The problem can be solved by computing the LTS , but the size of  
can be exponential in . So we investigate an unfolding approach. 

The {\em interface projection}  of a branching process  of  onto 
 is the following labelled subnet of :
(1) the conditions of  are the conditions of  with labels in ;
(2) the events of  are the events of   where  participates;
(3)  is an arc of  if{}f it is an arc of  and  are nodes of .
Obviously, every event of  has exactly one
input and one output condition, and  can therefore be seen as an LTS; thus, we sometimes
speak of the LTS . The interface projection  for the branching process of 
Figure \ref{fig:unfolding} is the subnet given by the black conditions and their input and output 
events, and its LTS representation is shown in the left of Figure \ref{fig:projection}. 


\begin{figure}[htbp]
\centering
\includegraphics[scale=0.55]{proj_fold.pdf}
\caption{Projection of the branching process of Figure~\ref{fig:unfolding} on 
 (left) and a folding (right)}\label{fig:projection}
\end{figure}

The projection  of the full unfolding of  onto  clearly 
satisfies ; however,  can be
infinite. In the rest of the paper we show how to compute a 
{\em finite} branching process  and an equivalence relation  between the 
conditions of  such that the result of {\em folding}  into a finite 
LTS by merging the conditions of each equivalence class yields the desired . 
The {\em folding} of  
is the LTS whose states are
the equivalence classes of , and every transition  of  yields a 
transition  of the folding.
Figure~\ref{fig:projection} shows on the right
the result of folding the LTS on the left 
when the only equivalence class with more than one member is formed by the two rightmost states labelled by .

We construct  by starting with the branching processes without events and
iteratively add one event at a time.
Some events are marked as {\em cut-offs} \cite{Esparza08}. An event  added to  becomes 
a cut-off if  already contains an , called the {\em companion} of , satisfying 
a certain, yet to be specified \emph{cut-off criterion}. Events with cut-offs
in their past cannot be added. The algorithm 
terminates when no more events can be added. 
The equivalence relation  is determined by the {\em interface cut-offs}: the cut-offs labelled with interface actions. 
If an interface cut-off  has companion , then we set . 
Algorithm~\ref{algo:unfolding} is pseudocode for the unfolding, where
 denotes the 
{\em possible extensions}: the events which can be added to  without
events from the set  of cut-offs in their past.

\begin{algorithm}[htbp]
\begin{algorithmic}
\State let  be the unique branching process of  without events and let 
\State {\bf While}  {\bf do}
\State\hspace*{0.4cm} choose  in  and extend  with 
\State\hspace*{0.4cm} {\bf If}  is a cut-off event {\bf then} let 
\State {\bf For every}  with companion  {\bf do} merge  and 
\end{algorithmic}
\caption{Unfolding procedure for a product .}
\label{algo:unfolding}
\end{algorithm}

Notice that the algorithm is nondeterministic: the order
in which events are added is not fixed (though it necessarily respects causal relations).
We wish to find a definition of cut-offs such that the LTS 
delivered by the algorithm
is a correct solution to the summary problem. 
Several papers have addressed the problem of defining cut-offs such that the
branching process delivered by the algorithm contains all global states of 
the system (see \cite{Esparza08} and the references therein). 
We first remark that these approaches do not ``unfold enough''.


\paragraph{\bf Standard cut-off condition does not work.}

Usually, an event  is declared a cut-off if the 
branching process already contains an event  with the 
same global state. If events are added according to an {\em adequate order} \cite{Esparza08}, then the prefix generated by the algorithm is guaranteed to contain occurrence sequences leading to all reachable markings.

We show that with this definition of cut-off even we do not always compute
a correct summary. We do so by showing an example in which {\em independently of the order in which Algorithm~\ref{algo:unfolding} adds events} the summary is always wrong. Consider the parallel composition of Figure~\ref{fig:transitionsystemsapp} with  as interface.

\begin{figure}[htbp]
\centering
\includegraphics[scale=0.7]{tsys_prefix_appendix.pdf}
\caption{Three labeled transition systems (left) and a branching process (right)}\label{fig:transitionsystemsapp}
\end{figure}
  
Independently of the order in which events are added, the branching process  computed  
by Algorithm \ref{algo:unfolding} is the one shown on the right of Figure~\ref{fig:transitionsystemsapp}. The only cut-off event is , with companion event , for which we 
have  .  The interface projection  is the transition system in Figure~\ref{fig:projectionapp}. 

\begin{figure}[htbp]
\centering
\includegraphics[scale=0.55]{proj_fold_appendix.pdf}
\caption{Projection of the branching process of Figure~\ref{fig:transitionsystemsapp} on 
}\label{fig:projectionapp}
\end{figure}

Since  does not contain any cut-off, its folding is again
, and since ,  is
not a summary.

\section{Two Attempts}

The solution turns out to be remarkably subtle, and so we approach it in a series of steps.

\subsection{First attempt} 

In the following we shall call events in which  participates
{\em -events} for short; analogously, we call {\em -conditions} the 
conditions labelled by states of .

The simplest idea is to declare an -event  a cut-off if the 
branching process already contains another -event  with . Intuitively, the behaviours of the interface after the configurations  and  is identical, and so we only explore the future of .

\begin{quote}
{\bf Cut-off definition 1.} An event  is a cut-off event 
if it is an -event and  contains an -event  such that
 . 
\end{quote}

It is not difficult to show that this definition is correct for 
{\em non-divergent} systems.

\begin{definition}
A parallel composition  with interface  is 
{\em divergent} if some infinite trace of  contains only finitely many occurrences of actions of . 
\end{definition}

\begin{theorem}
\label{th:interfacefair}
Let  be non-divergent. The instance of Algorithm~\ref{algo:unfolding} with cut-off definition 1 terminates with a finite branching process , and the folding  of  is a summary of .
\end{theorem}

\begin{proof}
Let  be the branching process constructed by Algorithm~\ref{algo:unfolding}.
Assume  is infinite (i.e., the algorithm does not terminate). 
Then  contains an infinite chain  of causally related events~\cite{Khomenko03}. 
Since  is non-divergent, the infinite configuration  contains infinitely
many -events. Since the interface  participates in all of them, they are all causally related, 
and so  contains an infinite chain  of causally related -events. Since
 has only finitely many global states, the chain contains two -events  such that
. So  is a cut-off, in contradiction with the fact that  belongs to . 
So  is finite, and so Algorithm~\ref{algo:unfolding} terminates.

\vspace{0.2cm}
It remains to prove . We prove both inclusions separately,
but we first need some preliminaries. We extend the mapping  to conditions
by defining , where  is the unique input event of condition . Since the states of  
are equivalence classes of conditions of  and, by definition, if  
then , we can extend  further to equivalence classes by defining
. 

. Let  be a trace of . Then  in ,
where  is the initial state of .
By the definition of folding, there exist  (finite sequences of actions) and pairs  of conditions of  such that
(1) ; (2) ; (3)  in  for every ; 
and (4)  for every . 

By (3) and the definition of projection, we have
 in  for some  such that : indeed, if  and  are the input events of  and , then  is reachable from  by means of any computation  corresponding to executing the events of , and any
such  satisfies . Moreover, by (4) we have . So we get 

\noindent By (1) and (2) we have  in , and so
 with .

.  Let  be a finite or infinite trace of .
We prove that there exists a trace  of  such that .
For that we prove that for every history  of  there exists a history  of  
such that . 

A finite history  is {\em short} if the unique sequence of events of the unfolding
 such that  for every  satisfies the
following conditions:  for every , and  is an -event.
(The name is due to the fact that, loosely speaking,  is a shortest history in which  occurs.)  

We say that a finite or infinite history  is {\em succinct} if there are  such that 
,  for every , and  is short for every .
We call  the {\em -decomposition} of .
It is easy to see that for every history  of  there exists a succinct history  of  with the same 
projection onto  (let  be the occurrence sequence such that , denote by  its -events in the order they appear in , then simply take for  any history with -decomposition  such that, for any ,  is an history corresponding to ).
So it suffices to prove the result for 
succinct histories. 

We prove by induction the following stronger result.
For every succinct history of  with -decomposition  there exist  such that for every :
\begin{enumerate}
\item[(a)]  is an history of  such that .
\item[(b)] There exists a configuration  of  that contains no cut-offs and such that
 is the state reached by .
\end{enumerate}

\noindent{\bf Base case.}
If , then  is the empty history of , take .

\noindent{\bf Inductive step.}
Let  be the prefix of  with -decomposition  (it is a succinct history of ).
Then  is succinct with -decomposition . 
By induction hypothesis  and some configuration 
satisfy the conditions above. 

Let , where ,  be the only sequence of events 
whose labelling is  and can occur in the order of the sequence from the marking  
(this sequence always exists by the properties of ). 
Two cases are possible.
\begin{enumerate}
\item  contains no cut-off.
In this case  is a sequence of events from  (because  contains no cut-offs). 
Thus, there exists an execution  of  from the state  
to the state  such that .
So we can take .
It remains to choose the configuration . We take  as ,
which contains no cut-offs because  contains no cut-offs by hypothesis.
\item  contains some cut-off.
Since  is succinct,  is the only -event of , and the only
maximal event of  w.r.t. the causal relation. Since
only -events can be cut-offs,  is a cut-off, and the only cut-off among the events of
. So  is a sequence of events from  whose last event is a cut-off.
Further, by the maximality of , the marking reached by  is .
By the definition of folding,  has an execution  from the state 
 to the state  such that 
. As above, this allows to take .

It remains to choose the configuration . We cannot take 
, because then  would contain cut-offs. 
So we proceed differently. We choose , where  is the companion of . 
Since  is not a cut-off,  contains no cut-offs. Moreover, since the marking 
reached by  is , we have that  is the state reached by 
.
\end{enumerate}
\end{proof}

The system of Figure~\ref{fig:transitionsystems} is non-divergent. 
Algorithm \ref{algo:unfolding} computes the branching process 
on the right of Figure~\ref{fig:transitionsystems}. The only cut-off is
event  with companion . The folding is shown in Figure~\ref{fig:projection} (right) and is a correct summary.
However, cut-off definition 1 {\em never} works if  is divergent
because the unfolding procedure does not terminate. Indeed, if the system 
has divergent traces then we can easily construct an infinite firing sequence of the unfolding such that none of the finitely many -events 
in the sequence is a cut-off. Since no other events can be cut-offs, Algorithm~\ref{algo:unfolding} adds all events of the sequence. This occurs for 
instance for the system of Figure~\ref{fig:needconc} with interface , where the occurrence sequence of the unfolding for the trace  contains no cut-off.


\subsection{Second attempt} 
To ensure termination for divergent systems, we extend the definition of cut-off. For this, we define for each event  its {\em -predecessor}. Intuitively, the -predecessor of an event  is the last condition that  ``knows'' has been
reached by the interface. 

\begin{definition}
The 
{\em -predecessor} of an event , denoted by , is the condition .
\end{definition}

Assume now that two events , neither of them interface event, satisfy 
and . Then any occurrence sequence  that executes 
the events of the set  leads from a marking to itself and 
contains no interface events. So  can be repeated infinitely often,
leading to an infinite trace with only finitely many interface actions. It is therefore
plausible to mark  as cut-off event, in order to avoid this infinite repetition.

\begin{quote}
{\bf Cut-off definition 2.} An event  is a cut-off if 
\begin{enumerate}
\item[(1)]  is an -event, and  contains an -event  with , or
\item[(2)]  is not an -event, and some event  satisfies  and .
\end{enumerate}
\end{quote}

We give 
an example showing that this natural definition does not work: the algorithm always terminates
but can yield a wrong result. Consider the parallel composition at the left of
Figure \ref{fig:concneeded}, with interface . Clearly
. For any strategy the algorithm generates the branching 
process  at the top right of the figure (without the dashed part).  has two cut-off events: the interface event ,
which is of type (1), and event , a non-interface event, of type (2). Event  has  as companion,
with . Event  has  as companion, with ;
moreover,  and . The folding of  
is shown at the bottom right of the figure.
It is clearly not trace-equivalent to  because it ``misses'' the trace 
. The dashed event at the bottom right, which would correct this,
is not added by the algorithm because it is a successor of . 

\begin{figure}[htbp]
\centering
\includegraphics[scale=0.55]{concurrency2b.pdf}
\caption{Cut-off definition 2 produces an incorrect result on }\label{fig:needconc}
\label{fig:concneeded}
\end{figure}


\section{The Solution}

Intuitively, the reason for the failure of our second attempt
on the example of Figure \ref{fig:concneeded} is that  can only execute  if  and  
execute  first. However, when the algorithm observes that the markings before and after 
the execution of  are identical, it declares  a cut-off event, and so it cannot ``use'' it to construct event .
So, on the one hand,  should not be a cut-off event. But, on the other hand, {\em some} event of the trace 
 must be declared cut-off, otherwise the algorithm does not terminate. 

The way out of this dilemma is to introduce {\em cut-off candidates}.
If an event is declared a cut-off candidate, the algorithm does not add any of its 
successors, just as with regular cut-offs. However, cut-off candidates may stop being candidates if the addition of a new event {\em frees} them. 
(So, an event is a cut-off candidate {\em with respect to the current branching process}.) A generic unfolding procedure using these ideas is given in Algorithm~\ref{algo:unfolding2}, where 
 denotes the possible extensions of  that do not have any 
event of  or  in their past.
Assuming suitable definitions of cut-off candidates and freeing, the algorithm
would, in our example, declare event  a cut-off candidate, momentarily stop adding any of its successors, but later free event  when event  is discovered.

\begin{algorithm}[htbp]
\begin{algorithmic}
\State let  be the unique branching process of  without events; let  and 
\State {\bf While}  {\bf do}
\State\hspace*{0.4cm} choose  in  according to the search strategy
\State\hspace*{0.4cm} {\bf If}  is a cut-off event {\bf then} let 
\State\hspace*{0.4cm} {\bf Elseif}  is a cut-off candidate of  {\bf then} let 
\State\hspace*{0.4cm} {\bf Else for every}  {\bf do}
\State\hspace*{0.8cm} {\bf If}  frees  {\bf then} 
\State\hspace*{0.4cm} extend  with 
\State {\bf For every}  with companion  {\bf do} merge  and 
\end{algorithmic}
\caption{Unfolding procedure for a product .}
\label{algo:unfolding2}
\end{algorithm}

The main contribution of our paper is the definition of a correct notion of cut-off candidate for the projection problem. 
We shall declare event  a  cut-off candidate if  is not an interface event,
and  contains a companion  such that , , and, additionally, no interface event  of  is concurrent with  without being concurrent with .
As long as this condition holds, the successors of  are put ``on hold''. In the example of Figure \ref{fig:concneeded}, if the algorithm first adds events , , , and , then event  becomes a cut-off candidate with  as companion. However, the addition of the interface event  frees event , because  is concurrent with  and not with .

However, we are not completely done yet. 
The parallel composition at the left of Figure~\ref{fig:strong} gives an example in which 
even with this notion of cut-off candidate the result is still wrong.
 is the interface.
One branching process is represented at the top right of the figure. 
Event 3 (concurrent with 1) is a cut-off candidate with 2 (concurrent with 1, 4, and 5) as companion.
This prevents the lower dashed part of the net to be added.
Event 6 is cut-off with 1 as companion.
This prevents the upper dashed part of the net to be added.
The refolding obtained then (bottom right) does not contain the word .

\begin{figure}[htbp]
\centering
\includegraphics[scale=0.55]{strong2.pdf}
\caption{An example illustrating the use of strong causality}\label{fig:strong}
\end{figure}

If we wish a correct algorithm for all strategies, we need a final touch: replace the condition  by , where  is the {\em strong causal relation}:
\begin{definition}
Event  is a {\em strong cause} of event , denoted by ,
if  and  for every . 
\end{definition}

Using this definition, event 3 is no longer a cut-off candidate in the branching process of Figure~\ref{fig:strong} as it is not in strong causal relation with its companion 2 (because the -labelled condition just after 2 belongs to  and is not causally related with the -labelled condition just after  which belongs to ).

The two following lemma give properties of the strong causal relation that will be useful to prove our main result (Theorem~\ref{thm:correctnessacceptable}).

\begin{lemma}
\label{lem:causal}
Every infinite chain  of events of a branching process
contains a strong causal subchain . 
\end{lemma}
\begin{proof}
Let . Say that a component  of  participates
in an event  if it participates in the transition labelling . We partition the (indices of the)
components into the set  of indices  such that  participates in finitely many 
events of , and . We say that the LTS  has 
{\em stabilized} at event  in the chain if  does not participate in any event . 
Let  be any event of  such that all LTSs of  
have stabilized before . We claim that there exists  in  such that
. Since clearly all LTSs of  have also stabilized before ,
A repeated application of the claim produces the desired subsequence. The claim itself
is proved in two steps:
\begin{itemize}
\item[(1)] There exists  in  such that 
for every , (which implies  for every ).\\
The existence of  follows from (1) the fact that all events of  are causally related, and (2) the definition of , which implies for any  the existence of an infinite subchain  such that  for every .
\item[(2)] There exists  in  such that  for every .\\
Observe that if  for some  and some , then  for all  (as ).
Suppose that  does not exist.
Then there exists  such that  for every .
As , there exists, by definition, an infinite subchain  of  such that  for every .
So for any of these  there exists a -event  such that 
 and  is concurrent with .
Let  be an event on a path from  to  and such that 
 and  for some  (the existence of such an event is ensured by the fact that ).
As  we get  and thus  for every .
Hence, by the observation above, the set  is strictly greater than the set .
Since  is finite, this contradicts the existence of  such that 
 for every  in . So the event  exists.
\end{itemize}
It follows immediately from (1) and (2) that  (because for any , ), and all LTSs of  have stabilized before , and so the claim is proved.
\end{proof}

\begin{lemma}
\label{lem:conc}
If  and  is concurrent with both  and , then 
.
\end{lemma}

\begin{proof}
Assume . 

Then  and . Since  and  are concurrent,
we have . So , and so
there is a nonempty path ,
where  denotes . Since  and  are concurrent, there is 
a first condition  in the path such that  and  are concurrent, and we have
. Since , we have . Since
, we have  for every . In
particular, since there is at least one condition  such that ,
we have , and so . But then, since  belongs to the path 
from  to , we have , contradicting that 
 and  are concurrent.
\end{proof}

We are now in a position to provide adequate definitions
for Algorithm~\ref{algo:unfolding2}.

\begin{definition}[Cut-off and cut-off candidate] 
\label{def:ccos}
Let  denote the set of 
non cut-off interface events of  that are concurrent with . An event   
\begin{itemize}
\item is a cut-off if it is an -event, and  contains an -event  
such that .
\item is a cut-off candidate of  if it is not an -event, and  contains  such that
, , and . 
\item frees a cut-off candidate  of  if  is not a cut-off candidate of the branching process
obtained by adding  to . 
\end{itemize}
\end{definition}


\begin{theorem}
\label{thm:correctnessacceptable}
Let  with interface . The instance of Algorithm~\ref{algo:unfolding2} given by Definition \ref{def:ccos} terminates and returns a branching process  such that the folding 
of  is a summary of .
\end{theorem}

\begin{proof}
We first prove termination. Assume the algorithm does not terminate, i.e., it constructs an
infinite branching process .
Then there exists an infinite chain  of causally related events in ~\cite{Khomenko03}.
First remark that  cannot contain an infinite number of -events:
if there is infinitely many -event in  one of them must be a cut-off (this is due to the finite number of global states in ) as all the -events of  are causally related there is a contradiction.
Hence,  contains an infinite chain  of causally related events such that for any two events  and  of  one has .
From that, the finite number of possible global states in  ensures that there exists an infinite subchain  of  such that for any two events  and  of  one has . 
The finite number of possible global states in  also ensures that in  there exists only a finite set of non-cut-off -events.
So, there exists an infinite subchain  of  such that for any two events  and  of  one has .
Finally, by Lemma~\ref{lem:causal} there exists two events  and  of  such that .
Then,  is a cut-off candidate of , which is in contradiction with the infiniteness of  and so with the existence of .
The termination of Algorithm~\ref{algo:unfolding2} is thus proved.

\vspace{0.2cm}
Now we prove . As in the proof of Theorem 
\ref{th:interfacefair}, we extend the mapping  to conditions, and to equivalence classes of
conditions of . 

. The proof of this part is identical to
that of Theorem \ref{th:interfacefair}: since the folding  is completely determined by the cut-offs
that are -events, and the definition of these cut-offs in Definition 2 and Definition 5
coincide, the same argument applies. 

. The proof has the same structure 
as the proof of Theorem \ref{th:interfacefair}, but with a number of important changes. 

Let  be a (finite or infinite) trace of .
We prove that there exists a trace  of  such that .
For that we prove that for every history  of  there exists a history  of  
such that .

As in Theorem \ref{th:interfacefair}, we use the notion of a succinct histories. However, we need
to strengthen it even more. Let  be a (finite or infinite) sequence of
global states of , and let  be the (possibly empty) set of 
succinct histories  with -decomposition
 such that . 
We say that a history  with -decomposition 
is {\em strongly succinct} if for every history  with -decomposition
 we have  for every .
If  is succinct, , and 
, then  is also succinct. Therefore,
if  is nonempty then it contains at least one strongly succinct history.

As in Theorem \ref{th:interfacefair}, we prove by induction a result implying the one we need.
For every (finite or infinite) strongly succinct history of  with -decomposition 
there exists  such that for every :
\begin{enumerate}
\item[(a)]  is a history of  such that .
\item[(b)] There exists a configuration  of  that contains no cut-offs and such that
 is the state reached by . 
\item[(c)] If , then there exists an -event  such that . 
\end{enumerate}
\noindent (The first two claims are as Theorem \ref{th:interfacefair}, while the third one is new.)

\noindent{\bf Base case.}
If , then  is the empty history of  and .

\noindent{\bf Inductive step.}
The initial part of the inductive step is identical to that of Theorem \ref{th:interfacefair}. 
Let  be the prefix of  with -decomposition  (it is a strongly succinct history).
Then  is strongly succinct with -decomposition . 
By induction hypothesis , some configuration ,
and, if , some event  satisfy the conditions above. 

Let , where ,  be the only sequence of events 
whose labelling is  and can occur in the order of the sequence from the marking  
(this sequence always exists by the properties of ). 
Two cases are possible:

\vspace{0.1cm}
\noindent 1.  contains no cut-off.\\
The proof of this case is as in Theorem \ref{th:interfacefair}. Part (c) follows because in Theorem \ref{th:interfacefair}
we choose  as , which, since  for every , implies .

\vspace{0.1cm}
\noindent 2.  contains some cut-off event.\\
In Theorem \ref{th:interfacefair} we used the following argument: since  is the only -event of
, and cut-offs must be -events,  is a cut-off. This argument is no longer valid,
because in Definition \ref{def:ccos} non--events can also be cut-offs. So we prove 
that  is a cut-off in a different way.

Let  be a cut-off of , and let  be its companion. 
We prove that, due to the minimality of  in the definition of strong succinctness,
we have .

Assume . Since  is the unique -event of ,
 is not an -event. So, by Definition \ref{def:ccos}, it is an event that became a cut-off candidate
and was never freed. 


We consider first the case in which  is the empty configuration (i.e. ).
In this case, consider a permutation  of  in which  contains the events of ,  contains the events of , and  contains the rest of the events.
Since ,  is also a history of .
Since  this contradicts the minimality of .

If  is nonempty, then the -event  in part (c) of the induction hypothesis exists.
We consider the events  and . Since  is an -event but  is not,
we have . Since there is an occurrence sequence that contains
both  and , the events are not in conflict. Moreover, since in this occurrence sequence
 occurs after , we have that  is not a causal predecessor of  either.
So there are two remaining cases, for which we also have to show that they lead to a contradiction: 

\vspace{0.1cm}
\noindent (b1) . Let  be the companion of . By the definition of cut-off
candidate, we have . Since  is an -event and , we have 
, and so . Consider the permutation  of
 in which  contains the events of ,
 contains the events of , and  the rest
of the events. Since ,  is also a history of . Since
, this contradicts the minimality of .

\vspace{0.1cm}
\noindent (b2)  and  are concurrent. We handle this case by means 
of a sequence of claims. 
\begin{itemize}
\item[(i)]  Let  be the companion of . The events  and  are concurrent. \\
Follows from the fact that  is an -event
and  by the definition of cut-off candidate.
\item[(ii)] .\\
Follows from Lemma \ref{lem:conc}, assigning .
\item[(iii)]  is not minimal, contradicting the hypothesis.\\
By (ii), the sets  and  are disjoint.
So every event of  belongs to .
Consider the permutation  of
 in which  contains the events that do not belong to ,
 contains the events of , and  the rest. 
Since ,  is also a history of , and since
 the sequence  is not minimal.
\end{itemize}

Since all cases have been excluded, and so we have , i.e., the -event 
 is the unique cut-off of . Now we can reason as in Theorem \ref{th:interfacefair}. We have that
 is a sequence of events from  whose last event is a cut-off, and 
the marking reached by  is .
By the definition of folding,  has an execution  from the state 
 to the state  such that 
. This allows to take . 
We choose , 
where  is the companion of  and then, obviously . 
Since  is not a cut-off,  contains no cut-offs. Moreover, since the marking 
reached by  is , we have that  is the state reached by 
.
\end{proof}

\section{Implementation and Experiments}

\label{sec:exp}

As an illustration of the previous results, we report in this section on an implementation of 
Algorithm~\ref{algo:unfolding2}. All programs and data
used are publicly available.\footnote{\url{http://www.lsv.ens-cachan.fr/~schwoon/tools/mole/summaries.tar.gz}}

\subsection{Implementation}

We implemented Algorithm~\ref{algo:unfolding2} by modifying the
unfolding tool \textsc{Mole}~\cite{Mole}. The input of our tool is
the Petri net representation of a product  in which every place
is annotated with the component it belongs to. Most of the infrastructure
of \textsc{Mole} could be re-used, in particular the existing implementation
contains efficient algorithms and data structures \cite{Esparza96}
for detecting new events
of the unfolding (the so-called possible extensions), computing the marking
 of an event, etc.

The main work therefore consisted in determining cut-off candidates and
the ``freeing'' condition of Definition~\ref{def:ccos}.
For this, we introduce a \emph{blocking} relation between events: we write
 if , , , and
, in other words  is a cut-off
candidate because of ; let .
Notice that .
Therefore, an over-approximation of this set can be computed when
 is discovered as a possible extension, by checking all its causal
predecessors. When  is expanded,  can only decrease
because adding an event may lead to a violation of the condition
.

The blocking relation requires two principal, interacting additions
to the unfolding algorithm:
\begin{itemize}
\item[(i)] a traversal of  collecting information about
  the `cut' ;
\item[(ii)] computing the concurrency relation between events.
\end{itemize}

For (i), we modify the way \textsc{Mole} determines :
it performs a linear traversal of , marking all conditions
consumed and produced by the events of , thus obtaining .
We extend this linear traversal with Algorithm~\ref{alg:walk}, which computes
, allowing to directly determine the conditions

and . Moreover, every condition  becomes annotated with
a set .
This, together with  and , allows
to efficiently determine whether  holds. Notice that if the
number of components in  is ``small'', the operations on 
can be implemented with bitsets. Thus, the additional overhead of
Algorithm~\ref{alg:walk} with respect to the previous algorithm can be
kept small.

\begin{algorithm}[htbp]
\begin{algorithmic}
\State let  be the current branching process and  its latest extension
\State set  and 
\State for all conditions , let  unmarked and 
\While{}
\State remove a -maximal element  from 
\State add all unmarked conditions  to  and set 
\State ;
\State mark all conditions  and set 
\EndWhile
\State add all unmarked initial conditions  to  and set 
\end{algorithmic}
\caption{Traversal of  for efficiently determining ,
where  denotes the component to which condition  belongs.}
\label{alg:walk}
\end{algorithm}

Concerning (ii), we are interested in determining the sets 
for all events . We make use of the facts that:
\begin{itemize}
\item \textsc{Mole} already determines, for every condition , a set
  of other conditions  that are concurrent with . When
  the  is extended with event , it computes the set
   and sets
   for every .
\item Two events  of  are concurrent iff their inputs 
  and  are disjoint and pairwise concurrent. Thus, when  is
  added, this relation can be checked by marking the events in  and
  checking whether  includes . Thus,  can be
  obtained with small overhead w.r.t.\ the existing implementation.
\item At the same time, we can easily determine whether the addition
  of an event  should lead to the removal of some event  from
  ; if this causes  to become empty,
   is freed.
\end{itemize}

\subsection{Experimental results}


We tested our implementation on well-known benchmarks
used widely in the unfolding literature,
see for example~\cite{Cor96,Esparza96,Khomenko03}.
The input is the set of components ,
which are converted into an equivalent Petri net. 
All reported times are on a machine with a 2.8 MHz Intel CPU and
4~GB of memory running Linux.
For each example, we
also report the number of events
(including cut-offs) in the prefix (Events),
the number of states
in the resulting summary  (), the size of a minimal deterministic
automaton for a summary (Min), and
the number of reachable
markings (Markings, taken from \cite{RoemerPhd} where
available, and computed combinatorially for \textsc{DpSyn}).


The experiments are summarized in Table~\ref{tab:expfull}. We used
the following families of examples~\cite{Cor96}:
the \textsc{CyclicC} and \textsc{CyclicS} families are a model of
Milner's cyclic scheduler with  consumers and  schedulers; in
one case we compute the folding for a consumer, in the other for a scheduler.
The \textsc{Dac} family represents a divide-and-conquer computation.
\textsc{Ring} is a mutual-exclusion protocol on a token-ring. The tasks
are not entirely symmetric, we report the results for the first.
Finally, \textsc{Dp}, \textsc{Dpsyn}, and \textsc{Dpd} are variants of
Dining Philosophers. In \textsc{Dp},
philosophers take and release forks one by one, whereas in \textsc{Dpsyn}
they take and release both at once. In \textsc{Dpd}, 
deadlocks are prevented by passing a dictionary.

\begin{table}[ht]
\begin{center}
\setlength\tabcolsep{5pt}
\begin{tabular}{lrrrrr}
\midrule
Test case & Time/s & Events &  & Min. & Markings \\
\toprule
\textsc{CyclicC}(6)  &  0.04  &   426 & 5 & 2 &    639 \\
\textsc{CyclicC}(9)  &  0.17  &  3347 & 5 & 2 &   7423 \\
\textsc{CyclicC}(12) &  4.04  & 26652 & 5 & 2 &  74264 \\
\midrule
\textsc{CyclicS}(6)  & 0.05 &   303 & 11 & 5 &    639 \\
\textsc{CyclicS}(9)  & 0.12 &  2328 & 11 & 5 &   7423 \\
\textsc{CyclicS}(12) & 2.38 & 18464 & 11 & 5 &  74264 \\
\midrule
\textsc{Dac}(9)  & 0.02 &  86 & 4 & 4 &   1790 \\
\textsc{Dac}(12) & 0.03 & 134 & 4 & 4 &  14334 \\
\textsc{Dac}(15) & 0.03 & 191 & 4 & 4 & 114686 \\
\midrule
\textsc{Dp}(6)  & 0.06 &    935 & 20 & 4 &   729 \\
\textsc{Dp}(8)  & 0.22 &   5121 & 28 & 4 &  6555 \\
\textsc{Dp}(10) & 2.23 &  31031 & 36 & 4 & 48897 \\
\midrule
\textsc{Dpd}(4) &  0.10 &   2373 & 114 & 6 &    601 \\
\textsc{Dpd}(5) &  0.71 &  23789 & 332 & 6 &   3489 \\
\textsc{Dpd}(6) & 17.68 & 245013 & 903 & 6 &  19861 \\
\midrule
\textsc{Dpsyn}(10) & 0.02 &  176 & 2 & 2 &     123 \\
\textsc{Dpsyn}(20) & 0.07 &  701 & 2 & 2 &   15127 \\
\textsc{Dpsyn}(30) & 0.26 & 1576 & 2 & 2 & 1860498 \\
\midrule
\textsc{Ring}(5) & 0.07 &   511 &  53 & 10 &   1290 \\
\textsc{Ring}(7) & 0.12 &  3139 & 101 & 10 &  17000 \\
\textsc{Ring}(9) & 0.93 & 16799 & 165 & 10 & 211528 \\
\end{tabular}
\caption{More experimental results}
\label{tab:expfull}
\end{center}
\end{table}

In all cases except one (\textsc{Dpd}) our algorithm needs clearly 
fewer events than there are reachable markings;
in some families (\textsc{Dac},
\textsc{Dpsyn}, \textsc{Ring}) there are far fewer events.
A comparison of \textsc{Dp} and \textsc{Dpsyn} is instructive. In \textsc{Dp},
neighbours can concurrently pick and drop forks. Intuitively, this leads
to fewer cases in which the condition 
for cut-off candidates is satisfied. On the other hand, in \textsc{Dpsyn} both forks are
picked and dropped synchronously, and so no event in  is concurrent to any
event in the neighbouring components, making the unfolding procedure much
more efficient. 


\section{Extensions: Divergences and  Weights}

We conclude the paper by showing that our algorithm can be extended to handle more complex semantics than traces.
Indeed, the divergences of the system can be captured by the summaries, as well as the minimal weights of the finite traces from  when  are weighted systems.

\subsection{Divergences}
We first extend our algorithm so that the summary
also contains information about {\em divergences}.
Intuitively, a divergence is a finite trace of the interface after which
the system can ``remain silent'' forever.

\begin{definition}
Let  be LTSs with interface . A 
{\em divergence} of  is a finite trace
 such that  for some
infinite trace .
A {\em divergence-summary} is a pair , where  is a summary 
and  is a subset of the states of  such that 
is a divergence of  if{}f some realization of  in  
leads to a state of . 
\end{definition}

We define the set of divergent conditions of the output of Algorithm~\ref{algo:unfolding2}, and show that it is a correct choice for the set .

\begin{definition}
Let  be the output of Algorithm~\ref{algo:unfolding2}. A condition  of  is {\em divergent}
if after termination of the algorithm there is  with 
companion  such that  is concurrent to both  and . We denote
the set of divergent conditions by .
\end{definition}

\begin{theorem}
\label{thm:divergences}
A finite trace  is a divergence of  
if{}f there is a divergent condition  of  such that some realization
of  leads to . Therefore,  is a divergence-summary.
\end{theorem}

\begin{proof}

Assume that  is a divergence of .
By the definition of a divergence, there exists  such that  and  is infinite.
So there exists a strongly succinct history  of  such that . Denote by  the last i-event of .
The proof of Theorem~\ref{thm:correctnessacceptable} guarantees the existance
of an i-event  in  which is not a cut-off and satisfies the following two properties: , and there exists a realisation of  leading to , where .
As  is infinite, the unfolding  of  contains an infinite occurrence sequence starting at  and containing no i-event. Since 
, another infinite sequence with the same labelling and without -events can occur from  in . By construction of , and since  is not a cut-off, a non-empty prefix of this second occurrence sequence appears in , and contains at least one cut-off candidate .
So  appears in some occurrence sequence without i-events starting at .
It follows that  is either (1) concurrent with , or 
(2) a successor of  such that . 
Moreover, since  is not an i-event, it is concurrent with .
It remains to show that the companion  of  is also concurrent with .
If (1) holds, i.e., if  is concurrent with , then  is concurrent with  (and so with ) as well, because, by the definition of a cut-off candidate, we have .
If (2) holds, i.e., if , then we have  for the same reason as in the case (b1) in the proof of Theorem~\ref{thm:correctnessacceptable}), and so  and  are concurrent.


Consider a divergent condition  of .
By the definition of a divergent condition there exist a cut-off candidate  with companion  such that neither  nor  are i-events, 
and both  and  are concurrent with .
Let  be the i-event such that .
As  is concurrent with , it is either concurrent with , or a successor of  such that . We consider these two cases separately.

(1)  is a successor of  such that .  Then  is a successor of  for the same reason as in case (b1) of Theorem~\ref{thm:correctnessacceptable}. So we have .
Let  be any occurrence sequence starting from  and containing exactly the events in  (so  contains no i-events).
Let  be any occurrence sequence starting at  and containing exactly the events in  (so  contains no i-events either).
As , there exists an occurrence sequence  
in  starting at  and such that ; moreover the last event  of  satisfies .
So we can iteratively construct occurrence sequences  for every , each of them starting at , satisfying , 
and ending with an event  satisfying .
So the infinite occurrence sequence  can occur in  from .

(2)  is concurrent with .  Then  is also concurrent with , because the definition of a cut-off candidate requires . By Lemma~\ref{lem:conc} we have . Let  be any occurrence sequence starting from  and containing exactly the events in  (so  contains no i-events).

Given two arbitrary concurrent events , let  be the unique marking reached by any occurrence sequence that fires exactly the events of . Let  be any occurrence sequence starting from  and containing exactly the events in  (so  contains no i-events).
As  and , there exists  an occurrence sequence  in  starting at  and such that ; moreover the last event  of  satisfies . So for every  we can iteratively
construct sequences  starting from  such that  and ending with an event  satisfying . It follows that the infinite occurrence sequence  can occur in  from .

So in both cases  has an infinite execution  starting at  and such that  is empty.
Moreover, if some realization of  leads to , the proof of Theorem~\ref{thm:correctnessacceptable} guarantees the existence of a history  of  reaching state  and satisfying .
Taking  concludes the proof.
\end{proof}

\subsection{Weights}
We now consider weighted systems, e.g parallel compositions of weighted LTS.
Formally, a weighted LTS  consists of an LTS  and a weight function  associating a weight to each transition.
A \emph{weighted trace} of  is a pair  where  is a finite trace of  and  is the minimal weight among the paths realizing , i.e:

We denote by  the set of all the weighted traces of .
The parallel composition  of the LTS  is such that  and the weight of a global transition  is: 


Similarly a \emph{weighted labelled Petri net} is a tuple  where  is a labelled Petri net and  associates weights to transitions.
A weighted trace in  is a pair  with  a finite trace of  and  the minimal weight of an occurrence sequence corresponding to , where the weight of an occurrence sequence is the sum of the weights of its transitions.
By  we denote the set of all the weighted traces of .

The branching processes of  are defined as weighted labelled Petri nets like in the non-weighted case, where
each event is implicitly labelled by an action (as before) and a cost.
Given a finite set of weighted traces  we define its restriction to alphabet  as 

As in the non-weighted case we are interested in solving the following summary problem:
\begin{definition}[Weighted summary problem]
Given , weighted LTSs with interface , compute a weighted LTS  satisfying , where .
\end{definition}

This section aims at showing that the approach to the summary problem proposed in the non-weighted case still works in the weighted one.
In other words,  can be obtained by computing a finite branching process  of  (using Definition~\ref{def:ccos} of cut-off and cut-off candidates and Algorithm~\ref{algo:unfolding2}) and then taking the interface projection  of  on  and folding it.
The notion of interface projection needs to be slightly modified to take weights into account.
The conditions, events, and arcs of  are defined exactly as above, and the weight of an event  of  is  if the predecessor  of  in  exists and  else, where  is the weight function of  and , where  is the past of  in the weighted branching process .

\begin{theorem}
\label{thm:costs}
Let  with interface .
The instance of Algorithm~\ref{algo:unfolding2} given by Definition~\ref{def:ccos} terminates and returns a weighted branching process  such that the folding  of  is a weighted summary of . 
\end{theorem}

\begin{proof}
The termination is granted by Theorem~\ref{thm:correctnessacceptable} as well as the fact that the weighted trace  belongs to  if and only if, for some , the weighted trace  belongs to .
It remains to show that for any  such that  and  one has .
In the following we denote by  the costs functions of  and , and by  the cost function of .
Similarly we denote by  the labelling function of  and by  the labelling function of .

.
This part of the proof is very close to the proof of the first inclusion of Theorem~\ref{th:interfacefair}.
Let  be a finite weighted trace of . 
Then  in  with ,
where  is the initial state of , and  is some state of .
By the definition of folding, there exist  occurrence sequences of  and  pairs of conditions of  such that
(1) ; (2)  and ; (3)  in  for every ; 
(4)  for every ;
and (5) .

By (3) and the definition of projection, we have
 in  for some execution  such that  and : indeed, if  and  are the input events of  and , then  is reachable from  by means of any execution  corresponding to executing the events of , and any
such  satisfies  and . Moreover, by (4) we have . So we get 

\noindent By (1) and (2) we have  in , so
 with , and by (5) and the definition of a weighted trace .

.
This part of the proof is almost exactly the same as the proof of the second inclusion of Theorem~\ref{thm:correctnessacceptable} (considering finite traces only).
We describe here the few differences between these two proofs.
The main one is the definition of strongly succinct histories: instead of requiring  we require , or  and .
Then, as we are interested in weights, claim (a) of the induction hypothesis has the supplementary requirement that .
The base case is then the same, just remarking that the cost of the empty history is  in both  and . 
For the inductive step two things have to be done: (1) ensuring that when  contains a cut-off it is necessarily  and (2) ensuring the new part of claim (a) about weights.
For (1) just remark that in all cases  is such that  and  so the same arguments as previously can be used with the new definition of a strongly succinct history.
For (2) notice that when  is a cut-off i-event, in the unfolding of  the events that can occur from  and from  do not only have the same labelling: they in fact correspond to the exact same transitions of  and so they also have the same weights.

Reusing this proof we have shown that the weighted trace  of  is such that there exists a history  of  such that  and .
So, by the definition of a weighted trace it comes directly that .
\end{proof}


\section{Conclusions}

We have presented the first unfolding-based solution to the 
summarization problem for trace semantics. The final algorithm is 
simple, but its correctness proof is surprisingly subtle. 
We have shown that it can be extended (with minor modifications) to handle divergences and weighted systems.

The algorithm can also be extended to other semantics,
including information about failures or completed traces;
this material is not contained in the paper because, while laborious,
it does not require any new conceptual ideas. 

We conjecture that the condition  in the definition 
of cut-off candidate 
can be replaced by , if at the same time the algorithm is 
required to add events 
in a suitable order. Similar ideas have proved successful in the past 
(see e.g. \cite{Esparza96,Khomenko03}).


\bibliographystyle{plain}
\bibliography{bibliotech}


\end{document}
