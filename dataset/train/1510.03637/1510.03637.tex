

In this section we introduce our model and approach through a working example. 



We want to develop a system which allows the interaction between  a Client
$\role C$ and a Server $\role S$ for verified file transfer. The server is
composed by a download process $\role D$, an access manager  $\role A$ and a
logger $\role L$. The behaviour of the system can be informally described as
follows.

The client $\role C$ asks for a file transfer to $\role A$ by sending its
credentials and the identifier of the file (e.g., a URL). The access manager
$\role A$ then check whether the credentials and the  identifier are valid. If
not, $\role A$ transmit the outcome of the validation to $\role D$ and then
notifies the failure  to $\role C$. In its turn,  $\role S$ forward the error
received from $\role A$ to the logger $\role L$.
If the validation of the request is valid, $\role A$ sends a message to $\role
S$ containing the resource identifier of the requested file and then sends a
message to $\role C$  to acknowledge the success of the request. Hence  and
$\role D$ asks to $\role L$ to $log$ the request and start the actual transfer
by repeating, recursively, the transfer of  a packet of bytes of the requested
file to $\role C$ until the End of File is reached and  the checksum is sent to
$\role C$. In its turn $\role C$ uses a process  $\role F$ of the operative
system in order to access the file system and save the file: $\role C$ asks to
$\role F$ to $create$ a new file and then, through a recursive procedure, it
sends the packets to be appended to the file until the transfer is terminated.
At this point  the checksum is sent and finally  $\role F$, depending on the
outcome of the checksum,  notify  $\role C$ whether it $saved$ or $discarded$
the file.


It is worth noting that in this simple example two kind of interactions or, in
other terms, two protocols are involved on the client side: one for
communicating with the server in order to download the file, and another one
for saving it through the functionalities of the file system. As we will see,
our approach allows a smooth integration of this kind of different behaviours
within the same (choreographic) process.


Our first step in the development of the system introduced above is the
definition, in Figure XXX, of a suitable (applied) choreography which describes
globally the system in terms of two  (parallel) processes $C_c$ and $C_s$
representing  the client $\role C$  and the server $\role S$, respectively.
Note that is not a purely abstract description of a protocol, as one could
obtain with such formalisms as global types, but is a first, high level,
program.

Before going into the details of the code let us observe that, in general, key elements of choreographies are \emph{processes}.
and \emph{sessions} . A process represents an entity that executes a sequence of instructions, 
while a session implements the communications among the processes taking part in it (NON MI PIACE MOLTO 
QUESTA DEF DI SESSIONE).  Processes ca be dynamically created and they can create new sessions 
(SEMPRE O SOLO QUI?). 
Important in choreographies are also roles, which are used to indicate specific classes of behaviours in specific contexts: for example, the client $\role C$, the access manager $\role A$ etc. in our example are roles.  

A first distinguishing feature of our approach is the presence of specific of
deployment information which is given in terms of locations: these are used to
identify the places where deployment of processes take place or, in other
terms, where services are located. In a sense locations in our model are
similar to public channels which, in other choreographic approaches, are used
to model the creation of a new session, even though a location can support only
the behaviour of one single role. More precisely ... QUI DIRE LA RELAZIONE
PRECISA FRA SESSIONE E LOCATION. It is worth noting that the presence of
locations, rather than channels names, makes easier the link of our applied
choreographic language with real implementations. DIRE QUALCHE COSA SU
CORRELAZIONE AT THIS STAGE ??





CAMBIARE NEL CODICE RUOLO S IN RUOLO D

Below we comment the behaviour of a choreography that implements the
interaction described above. In order to explain the benefits of our approach,
we first describe one of the key element of our model: the \emph {environment}
($\env$). $\env$ is a global structure that contains the state of the processes
in a choreography. Given a choreography $C$, we call the couple $\env,C$ a
\emph {running choreography}. The reason we introduced $\env$ is that we need
it to model message passing based on data (rather than names). At runtime
$\env$ keeps track of the evolution of a choreography.

Figs.\ref{fig:preview_example_client} and~\ref{fig:preview_example_server} with
respectively the code of choreographies $C_c$ and $C_s$. In the code, the
behaviours of our components are represented by the roles appearing in the
choreographies with the same notation indicated above ($\role C$ for the
Client, etc.).

Let us run some salient parts of the parallel composition of $C_c$ and $C_s$
along with environment $\env$, written $\env,C_c \pp C_s$.

The interaction between the first two statements (Line 1) of $C_c$ and $C_s$
spawns a new session named $k_d$. At Line 1 of $C_c$ process $\pid c$, playing
role $\role C$, requests to create a new session with some new processes at
locations $l_{\role A}$, $l_{\role S}$, and $l_{\role L}$. Line 1 of $C_s$
matches the request with the newly created processes $\pid a$ (playing $\role
A$, running at location $l_{\role A}$), $\pid s$ (playing $\role S$, running at
$l_{\role S}$), and $\pid l$ (playing $\role L$, running at $l_{\role L}$).

Let $\wtil{l.\prc qB} = l_{\role A}.\prc aA,l_{\role S}.\prc sS,l_{\role
L}.\prc lL$, and $C_c'$ and $C_s'$ continuation of respectively $C_c$ and $C_s$
after Line 1. $E,C$ reduces to
$$
\hspace{-.5em}\begin{array}{l}
\env,
\req{k_d}{\prc cC}{\wtil{l.\prc qB}}; C_c' 
	\pp
	\acc{k_d}{\wtil{l.\prc qB}}; C_s'		
\to
\\
\env \seff (\ \start{k_d}{\pid c[\role C]}{\wtil{l.\prc qB}}\ ), C_c' \pp C_s'
\end{array}	
$$
The writing $\env \seff ( \start{k_d}{\pid c[\role C]}{\wtil{l.\prc qB}} )$
means that $\env$ records the effect of the start. As a result, the new state
of $\env$ is ready to handle message passing in session $k_d$.

\textbf{Message passing.}


\textbf{METTERE UN RIFERIMENTO AL TIPO!!!}

Line 2 of $C_c$ and $C_s$ respectively represent send and receive (partial)
operations. At Line 2 of $C_c$, $\com{k_d}{\prc cC.\m{mkReq()}}{\role A.get}$,
means that through session $k_d$, $\pid c$ (playing role $\role C$), sends the
result of the evaluation of function $\m{mkReq()}$ on operation $get$ to the
external process that plays role $\role A$. Note that $C_c$ does not specify
the name of the process playing $\role A$. The name has to be defined by the
complementary partial choreography that implements the process playing
$\role A$ ($C_s$). Below we report the reduction steps of the communication
($C_c'$ and $C_s'$ continuations of resp. $C_c$ and $C_s$ after Line 2).
{\scriptsize
$$
\hspace{-.5em}\begin{array}{l}
	\env,\ \com{k_d}{\prc cC.\m{mkReq()}}{\role A.get};C_c' \pp
			 \com{k_d}{\role C}{\prc aA.get(\jpath{req})};C_s'
	\to
	\\
	\env\ \seff \com{k_d}{\prc cC.\m{mkReq()}}{\role A.get},\ C_c' \pp
			 \com{k_d}{\role C}{\prc aA.get(\jpath{req})};C_s'
	\to
	\\
	\env' \seff \com{k_d}{\role C}{\prc aA.get(\jpath{req})},\ C_c' \pp C_s'
\end{array}
$$
}
First $\pid c$ sends the message to the process playing $\role A$. The effect
of $\env' = \env\ \seff \com{k_d}{\prc cC.\m{mkReq()}}{\role A.get}$ is that
$\env'$ stored a new message in the queue pointed by $\jpath {kd.C.A.c}$ of
process $\pid a$. The content of the message is the evaluation of $\m{mkReq
()}$ on the state of $\pid c$. We remark that the effect does not need to
carry the identity of $\pid a$ in $C$. $\env$ can guess it from the
correlation data used by $\pid c$. The intention behind this choice is that
it will ease the process of compilation, as it exploits the same technique
used to route messages in the target language of compilation.

Then process $\pid a$ reads the message from $\role C$ for operation $get$,
in the queue pointed by $\jpath {kd.C.A}$. The effect of $\env' \seff
\com{k_d}{\role C}{\prc aA.get(\jpath{req})}$ removes the message from the
queue and assigns its content to variable $\jpath{req}$ in the state of $\pid
a$.

\textbf{Asynchrony.}
One of the benefits of including the environment in our model is that it
makes message passing inherently asynchronous. Indeed, in the example above
the two instructions at Line 2 of $C_c$ and $C_s$ are asynchronous. E.g.,
$\pid c$ may have already delivered the message and passed to the next
instruction, whilst $\pid a$ still had to reach Line 2 and read the message.
This holds also for complete operations in our semantics. They first reduce
to a send and then execute a reception.

This means that, even if a choreography defines a certain order in which its
processes shall receive (read) their messages, this order can change at
runtime. This is actually what happens in real-world distributed system.
Messages (data) are consumed according to the state of computation of each
process. Our model naturally matches this feature.

The execution of Lines 4-5 of $C_s$ show this concept (we omit
effects on $\env$ for brevity, $C_s'$ continuation of $C_s$ after Line 5):
{\footnotesize
$$
\hspace{-.5em}\begin{array}{l}
 \env, \com{k_d}{\prc aA.\jpath{req.rsc}}{\prc sS.ok(\jpath{rsc})};
\com{k_d}{\prc aA}{\role C.ok};C_s'\pp C_c
\to
\\ \env', \com{k_d}{\role A}{\prc sS.ok(\jpath{rsc})};
\com{k_d}{\prc aA}{\role C.ok};C_s'\pp C_c
\swapC
\\ \env', \com{k_d}{\prc aA}{\role C.ok};\com{k_d}{\role A}{\prc
sS.ok(\jpath{rsc})};C_s'\pp C_c
\to
\\ \env'', \com{k_d}{\role A}{\prc sS.ok(\jpath{rsc})};C_s'\pp C_c
\end{array}
$$
}
After $\pid a$ sent its message to $\pid s$, it is possible
that $\pid s$ is not ready to read it (e.g., due to scheduling). In our
model, we allow two operations to swap if they have no process in common.
Operations $\com{k_d}{\role A}{\prc sS.ok}$ and $\com{k_d}{\prc aA}{\role
C.ok}$ regard resp. $\pid s$ and $\pid a$ and can swap. We indicate swapping
with $\swapC$. After the swap, $\pid a$ delivers its message to $\role C$.

Another example of asynchrony are Lines 9-10 of $C_s$. $\pid s$ can send all
the sequence of packets of the file to $\pid c$, whilst $\pid c$ might have
read none of them yet. The queue between them works as a buffer.

Remarkably, although allowing for asynchrony, our type system guarantees to
preserve the order of interactions, i.e., the order two processes
send and receive messages to and from each other.

\textbf{Parallelism.}
Our model also automatically achieves the maximum degree of parallelism among
different processes.

Lines 4-6 of $C_s$ show an example of that. 
The instructions at Lines 5-6 concern a disjoint set of processes (resp. $\pid
a$, $\pid s$, and $\pid l$). According to our model the two instructions can
swap, thus their order of execution is non-deterministic. A possible reduction
is (effect on $\env$ omitted for brevity, $C_s'$ continuation of $C_s$ after
Line 6):
{\scriptsize
$$
\hspace{-.5em}\begin{array}{ll}
\hspace{-.5em}\begin{array}{l}
	\env, \begin{array}{l}
		\com{k_d}{\prc aA.\jpath{req.rsc}}{\prc sS.ok(\jpath{rsc})};
	  \com{k_d}{\prc aA}{\role C.ok};
	  \\
		\com{k_d}{\prc sS.\m{logok}(\jpath{rsc})}{\prc lL.log(\jpath{log})};
		C_s' \pp C_c	
	\end{array}
\end{array}
\to
\\[7pt]
\hspace{-.5em}\begin{array}{l}
	\env', \begin{array}{l}
		\com{k_d}{\role A}{\prc sS.ok(\jpath{rsc})};
	  \com{k_d}{\prc aA}{\role C.ok};
	  \\
		\com{k_d}{\prc sS.\m{logok}(\jpath{rsc})}{\prc lL.log(\jpath{log})};
		C_s' \pp C_c	
	\end{array}
\end{array}
\to
\\[7pt]
\env'',
	  \com{k_d}{\prc aA}{\role C.ok};
		\com{k_d}{\prc sS.\m{logok}(\jpath{rsc})}{\prc lL.log(\jpath{log})};
		C_s' \pp C_c	
\swapC
\\[3pt]
\env'',
		\com{k_d}{\prc sS.\m{logok}(\jpath{rsc})}{\prc lL.log(\jpath{log})};
	  \com{k_d}{\prc aA}{\role C.ok};
		C_s' \pp C_c	
\to
\\[3pt]
\env''',
		\com{k_d}{\role S}{\prc lL.log(\jpath{log})};
	  \com{k_d}{\prc aA}{\role C.ok};
		C_s' \pp C_c	
\swapC
\\[3pt]
\env''',
	  \com{k_d}{\prc aA}{\role C.ok};
		\com{k_d}{\role S}{\prc lL.log(\jpath{log})};
		C_s' \pp C_c	
\to \ldots
\end{array}
$$
}

After $\pid a$ sent its message, let us suppose that $\pid s$ reads it. Then,
since no process is shared between the instructions at Lines 5 and 6, it is
possible to swap them. Then $\pid s$ sends its message to $\pid l$, the two
Lines can swap again, and proceed with e.g., $\pid a$ delivering its message.
Indeed, there are other possible execution scenarios, all permitted by our
model.

\textbf{Endpoint Projection.}
In order to execute a choreography, we need to compile (translate) it to a
set of running processes that, run in parallel, enact the behaviour it
describes. Our procedure of compilation consists in two steps. The first
\emph{projects} the original choreography into a parallel composition of
partial single-process choreographies. The goal of this step is to have a set
of partial choreographies whose parallel composition behaves exactly as the
original one. Partial single-process choreographies will later ease the process
of compilation to a running language. Figs.~\ref{fig:preview_example_epp_A},
~\ref{fig:preview_example_epp_S}, and~\ref{fig:preview_example_epp_L}
respectively show the projection of the choreography in the example above ($C$)
on processes $\pid a$ ($\epp {C}{\pid a}$), $\pid s$ ($\epp{C}{\pid s}$), and
$\pid l$($\epp{C}{\pid l}$)\footnote{Processes $\pid a$, $\pid s$, and $\pid l$
all belong to $C_s$, therefore $\epp{C}{\pid a} =
\epp{C_s}{\pid a}$, $\epp{C_s}{\pid s} = \epp{C}{\pid s}$, and $\epp{C_s} {\pid
l} = \epp{C}{\pid l}$.}.

The EPP of $C$, $\epp{C}{} = \epp{C}{\pid c} \pp \epp{C}{\pid f} \pp \epp{C}
{\pid a} \pp \epp{C}{\pid s} \pp \epp{C}{\pid l}$, behaves exactly as $C$. This
results from the definition of the semantics of our model in which all complete
operations break into partials.

Below we highlight some salient parts of the projection and show that $C$ and
$\epp{C}{}$ behave accordingly.

Let $\wtil{l.\prc qB} = l_{\role A}.\prc aA,l_{\role S}.\prc sS,l_{\role
L}.\prc lL$, $\pid p \in \{\pid a, \pid s, \pid l\}$ and $\epp{C}{\pid p}'$
continuation of $\epp {C} {\pid p}$ after Line 1. The effect of the execution
of Line 1 of $\epp {C} {}$ is
{\footnotesize
$$
\hspace{-5pt}\begin{array}{l}
\env,\begin{array}{l}
\req{k_d}{\prc cC}{\wtil{l.\prc qB}}; \epp{C}{\pid c}' \pp \acc{k_d}{l_{\role A}.\prc aA}; \epp{C}{\pid a}' \pp \\
\acc{k_d}{l_{\role S}.\prc sS}; \epp{C}{\pid s}' \pp \acc{k_d}{l_{\role L}.\prc lL}; \epp{C}{\pid l}'		
\end{array}
\to
\\[10pt]
\env \seff \start{k_d}{\pid c[\role C]}{\wtil{l.\prc qB}},\ 
\epp{C}{\pid c}' \pp \epp{C}{\pid a}' \pp \epp{C}{\pid s}' \pp 
\epp{C}{\pid l}'		
\end{array} 
$$
}
Which is the same effect of the execution of Line 1 of $C$.

Complete communications project as partial sends and receives
between the two processes taking part in it. E.g., at Line 6 of $C_s$, $\pid s$
sends a message to $\pid l$ on operation $log$. The EPP of Line 6 of $C_s$
projects to the send at Line 4 of $\epp{C_s}{\pid s}$ and the reception at Line
2 of $\epp{C_s}{\pid l}$. As we already commented, the effect, at runtime, of
Line 6 of $C_s$ is that first $\pid s$ delivers its message to $\pid l$ and,
later on, $\pid l$ reads it. Line 4 of $\epp{C_s}{\pid s}$ and Line 2 of
$\epp{C_s}{\pid l}$ enact the same behaviour: first Line 4 executes
 and after the deliver Line 2 can execute.

The EPP preserves conditionals on the process evaluating it. For all the
other processes involved in the body of the conditional, the EPP projects a
branched reception. E.g., at Line 3 of $C_s$, process $\pid a$ evaluates a
condition that either branches in the behaviour at Lines 4-15 or Lines 17-19.
The condition evaluated at Line 3 of $C_s$ by process $\pid a$ is projected
verbatim at Line 3 of $\epp{C_s}{\pid a}$. The EPP of $\pid s$ projects a
branched communication on either operation $ok$ (Line 3) or $ko$ (Line 6 of
$\epp {C_s} {\pid s}$). The EPP of $\pid l$ projects only one branch (Line 2
of $\epp{C_s}{\pid l}$) as $\pid l$ receives on operation $log$ in either cases.

\textbf{Compilation.}
Once projected, we can compile the EPP of each process in the choreography to
a process of an executable language. To prove our translation sound we chose,
as target language of the compilation, an extended version of the Correlation
Calculus~\cite{MC11} (CC), the theoretical model behind the Jolie
language~\cite{jolie:website}.

Key elements of CC are \emph{services} and \emph{processes}. A service acts
as a deployment container. Each service is associated with a location,
contains a set of processes running in parallel, and can spawn new processes
at runtime on request. The form of a service is $S =\jsrv {B, P} {l}$, where
$B$ is the behaviour of spawnable processes, $P$ the parallel composition of
the running processes, and $l$ the deployment location. A process, with form
$\jprc{B}{t}{M}$, is associated with a behaviour $B$, a state $t$, and a set
of queues $M$.

CC handles communication via message passing. Messages are routed to
processes by means of correlation (matching) between a set of values
contained in the message and the values that identify a queue (just like
queues are identified by values in our choreographic model). In~\cite{MC11}
queues are static and assigned when a new process is created. To support the
runtime creation of new session, we present in this paper an extension of CC
that enables processes to create new queues at runtime.

In this way, we can translate the interactions on a session (in the original
choreography) into a set of message exchanges routed on the carried data. When
in the choreography a running process requests the creation of a new session,
we encode the request as the creation of a new set of data for correlation and
the relative queues pointed by that data. The result of our approach is that
the global knowledge on the state of the choreography, kept by the environment
$\env$, is distributed among the processes that result form the compilation of
the choreography.

\textbf{DIRE PERCHE' SERVE $\Gamma$ ALL'ENCODING} 

We write the encoding of a running choreography $\env,C$ as $\genenc{\env,C}{}$.
Informally, $\genenc{\env,C}{}$ compiles to a parallel composition services, one
for
each location in $C$. For each service $S = \jsrv{B,P}l$:
\emph{i}) let $\pid p$ be the process that offers to accept ($\textbf {acc}$)
a new session on $l$ in $C$, $$S = \jsrv{\genenc{\epp{C}{\pid p}},P}l$$. E.g.,
Figure~\ref{fig:preview_example_encoding_A} shows the encoding of the service
at $l_{\role A}$ and it exposes $\genenc{\epp{C_{s}}{\pid a}}$
to spawn new processes. A similar service is the one at $l_{\role L}$ in
Figure~\ref{fig:preview_example_encoding_L}.
\emph{ii}) for all running processes $\pid p_1, \ldots, \pid p_n$ located at
$l$ in $C$, $$S = \jsrv{B, \genenc{\epp{C}{\pid p_1}} \pp \ldots \pp
\genenc{\epp{C}{\pid p_n}}}{l}$$, i.e., it contains the parallel composition of
the compilation of the projection of $C$ on each process. E.g., let process
$\pid c$ in $C$ be located at $l_{\role C}$, the encoding of $C$ for $S$
located at $l_{\role C}$ is $S = \jsrv{B,P}{l_{\role C}}$ where $P =
\jprc{\genenc{\epp{C_{c}}{\pid c}}} {\env(\pid a).\estate}{\env(\pid
a).\equeues}$, i.e., $P$ is the encoding of the projection $\epp{C}{\pid c}$.
Note that the state and set of queues of $P$ are exactly the ones defined by
the environment $\env$ for $\pid a$.
Figure~\ref{fig:preview_example_encoding_C} shows an excerpt of the compilation
of the service at $l_{\role C}$.


Below we comment some salient parts of the compilation and show how $\genenc{C}
{}$ implements the runtime behaviour of $C$.

$\env' = \env \seff \start {k_d} {\pid c [\role C]} {\wtil {l.\prc qB}}$ is
the effect of starting a new session and it modifies $\env$ in such a way
that all involved processes in the start have the proper values set for
process-to-process communication (correlation) on $k_d$ along with the
corresponding queues. In $\genenc{C}{}$ we need to ensure the same behaviour in
a distributed setting. To do this, we compile the start of a new session to a
centralised synchronisation procedure. As a convention, we put in charge the
process running the $\textbf{req}$ for a new session of setting the values
and to work as the synchronisation point.

Figure~\ref{fig:preview_example_encoding_C} shows an excerpt of the compilation
of $\textbf{req}$: \emph{i}) Lines 1-2 set the location of the involved
processes. This data will be used later in send operations to address the
service of the receiver. \emph{ii}) Lines 3-5 assign fresh values ($\new$) to
the variables for correlation, following the convention
$\jpath{Session.Sender.Receiver}$. \emph{iii}) Lines 6-11 spawn the new
processes, one for each role (except the one played by the requester) in the
choreography. Lines 6-8 show the instructions for the process playing role
$\role A$. Line 6 sets the queue of the requester to receive messages from
$\role A$. Line 7 requests to the service at $l_{\role A}$ to spawn a new
process. Line 8 waits to receive a message on operation $sync$ from the new
process playing role $\role A$, i.e., on its queue pointed by
$\jpath{kd.A.C}$. \emph{iv}) Finally, Lines 12-14 notify all (new) processes
to start running the session.

The compilation of $\textbf{acc}$ is the complementary to
$\textbf{req}$. Let us look at the compilation of Line 1 of $\epp{C_s}{\pid
a}$ (Figure~\ref{fig:preview_example_epp_A}) shown at Lines 1-6 of
Figure~\ref{fig:preview_example_encoding_A}. At Line 1 $\oneway{!}{\jpath{kd}}$
accepts the request to spawn a new process. Then (Lines 2-4) the process sets
its queues to receive, on session $k_d$, from resp. $\role C$, $\role S$, and
$\role L$. Finally, it notifies the starter (at $\jpath{kd.C.l}$) it is
ready to begin the session (Line 5) and waits to be notified on operation
$start$ (Line 6).

Apart from the start procedure, the code of a compiled process and its EPP
are very similar. Indeed, the main difference between the EPP and the
compilation is that, whilst in the choreography communications happen through
a session, in the compiled code we make explicit reference to the
data-structures used to address services and communicate on queues. E.g., let
us compare Figs.~\ref{fig:preview_example_epp_A}
and~\ref{fig:preview_example_encoding_A}, below respectively addressed as the
EPP and compilation of $\pid a$. Lines 3-9 of the EPP translate, one-by-one,
to Lines 7-14 of the compilation. We briefly comment a reception and a send
operation. The reception at Line 2 of the EPP compiles to Line 7 of
Figure~\ref{fig:preview_example_encoding_A}. $\oneway{get}{\jpath{req}}
\qfrom{\jpath{kd.C.A}}$ reads a message for operation $get$
from the queue pointed by $\jpath{kd.C.A}$ and assigns its content to
variable $\jpath{req}$. The send operation at Line 4 of the EPP translates to
$\notify{ok}{\jpath{kd.S.l}}{\jpath{req.rsc}} \qto{\jpath{kd.A.S}}$ (Line 9
of the compilation) which sends the content of $\jpath{req.rsc}$ to the
process located at $\jpath{kd.S.l}$ that correlates with $\jpath{kd.A.S}$.



