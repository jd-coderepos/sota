

In this section we introduce our model and approach through a working example. 



We want to develop a system which allows the interaction between  a Client
 and a Server  for verified file transfer. The server is
composed by a download process , an access manager   and a
logger . The behaviour of the system can be informally described as
follows.

The client  asks for a file transfer to  by sending its
credentials and the identifier of the file (e.g., a URL). The access manager
 then check whether the credentials and the  identifier are valid. If
not,  transmit the outcome of the validation to  and then
notifies the failure  to . In its turn,   forward the error
received from  to the logger .
If the validation of the request is valid,  sends a message to  containing the resource identifier of the requested file and then sends a
message to   to acknowledge the success of the request. Hence  and
 asks to  to  the request and start the actual transfer
by repeating, recursively, the transfer of  a packet of bytes of the requested
file to  until the End of File is reached and  the checksum is sent to
. In its turn  uses a process   of the operative
system in order to access the file system and save the file:  asks to
 to  a new file and then, through a recursive procedure, it
sends the packets to be appended to the file until the transfer is terminated.
At this point  the checksum is sent and finally  , depending on the
outcome of the checksum,  notify   whether it  or 
the file.


It is worth noting that in this simple example two kind of interactions or, in
other terms, two protocols are involved on the client side: one for
communicating with the server in order to download the file, and another one
for saving it through the functionalities of the file system. As we will see,
our approach allows a smooth integration of this kind of different behaviours
within the same (choreographic) process.


Our first step in the development of the system introduced above is the
definition, in Figure XXX, of a suitable (applied) choreography which describes
globally the system in terms of two  (parallel) processes  and 
representing  the client   and the server , respectively.
Note that is not a purely abstract description of a protocol, as one could
obtain with such formalisms as global types, but is a first, high level,
program.

Before going into the details of the code let us observe that, in general, key elements of choreographies are \emph{processes}.
and \emph{sessions} . A process represents an entity that executes a sequence of instructions, 
while a session implements the communications among the processes taking part in it (NON MI PIACE MOLTO 
QUESTA DEF DI SESSIONE).  Processes ca be dynamically created and they can create new sessions 
(SEMPRE O SOLO QUI?). 
Important in choreographies are also roles, which are used to indicate specific classes of behaviours in specific contexts: for example, the client , the access manager  etc. in our example are roles.  

A first distinguishing feature of our approach is the presence of specific of
deployment information which is given in terms of locations: these are used to
identify the places where deployment of processes take place or, in other
terms, where services are located. In a sense locations in our model are
similar to public channels which, in other choreographic approaches, are used
to model the creation of a new session, even though a location can support only
the behaviour of one single role. More precisely ... QUI DIRE LA RELAZIONE
PRECISA FRA SESSIONE E LOCATION. It is worth noting that the presence of
locations, rather than channels names, makes easier the link of our applied
choreographic language with real implementations. DIRE QUALCHE COSA SU
CORRELAZIONE AT THIS STAGE ??





CAMBIARE NEL CODICE RUOLO S IN RUOLO D

Below we comment the behaviour of a choreography that implements the
interaction described above. In order to explain the benefits of our approach,
we first describe one of the key element of our model: the \emph {environment}
().  is a global structure that contains the state of the processes
in a choreography. Given a choreography , we call the couple  a
\emph {running choreography}. The reason we introduced  is that we need
it to model message passing based on data (rather than names). At runtime
 keeps track of the evolution of a choreography.

Figs.\ref{fig:preview_example_client} and~\ref{fig:preview_example_server} with
respectively the code of choreographies  and . In the code, the
behaviours of our components are represented by the roles appearing in the
choreographies with the same notation indicated above ( for the
Client, etc.).

Let us run some salient parts of the parallel composition of  and 
along with environment , written .

The interaction between the first two statements (Line 1) of  and 
spawns a new session named . At Line 1 of  process , playing
role , requests to create a new session with some new processes at
locations , , and . Line 1 of 
matches the request with the newly created processes  (playing , running at location ),  (playing , running at
), and  (playing , running at ).

Let , and  and  continuation of respectively  and 
after Line 1.  reduces to

The writing 
means that  records the effect of the start. As a result, the new state
of  is ready to handle message passing in session .

\textbf{Message passing.}


\textbf{METTERE UN RIFERIMENTO AL TIPO!!!}

Line 2 of  and  respectively represent send and receive (partial)
operations. At Line 2 of , ,
means that through session ,  (playing role ), sends the
result of the evaluation of function  on operation  to the
external process that plays role . Note that  does not specify
the name of the process playing . The name has to be defined by the
complementary partial choreography that implements the process playing
 (). Below we report the reduction steps of the communication
( and  continuations of resp.  and  after Line 2).
{\scriptsize

}
First  sends the message to the process playing . The effect
of  is that
 stored a new message in the queue pointed by  of
process . The content of the message is the evaluation of  on the state of . We remark that the effect does not need to
carry the identity of  in .  can guess it from the
correlation data used by . The intention behind this choice is that
it will ease the process of compilation, as it exploits the same technique
used to route messages in the target language of compilation.

Then process  reads the message from  for operation ,
in the queue pointed by . The effect of  removes the message from the
queue and assigns its content to variable  in the state of .

\textbf{Asynchrony.}
One of the benefits of including the environment in our model is that it
makes message passing inherently asynchronous. Indeed, in the example above
the two instructions at Line 2 of  and  are asynchronous. E.g.,
 may have already delivered the message and passed to the next
instruction, whilst  still had to reach Line 2 and read the message.
This holds also for complete operations in our semantics. They first reduce
to a send and then execute a reception.

This means that, even if a choreography defines a certain order in which its
processes shall receive (read) their messages, this order can change at
runtime. This is actually what happens in real-world distributed system.
Messages (data) are consumed according to the state of computation of each
process. Our model naturally matches this feature.

The execution of Lines 4-5 of  show this concept (we omit
effects on  for brevity,  continuation of  after Line 5):
{\footnotesize

}
After  sent its message to , it is possible
that  is not ready to read it (e.g., due to scheduling). In our
model, we allow two operations to swap if they have no process in common.
Operations  and  regard resp.  and  and can swap. We indicate swapping
with . After the swap,  delivers its message to .

Another example of asynchrony are Lines 9-10 of .  can send all
the sequence of packets of the file to , whilst  might have
read none of them yet. The queue between them works as a buffer.

Remarkably, although allowing for asynchrony, our type system guarantees to
preserve the order of interactions, i.e., the order two processes
send and receive messages to and from each other.

\textbf{Parallelism.}
Our model also automatically achieves the maximum degree of parallelism among
different processes.

Lines 4-6 of  show an example of that. 
The instructions at Lines 5-6 concern a disjoint set of processes (resp. , , and ). According to our model the two instructions can
swap, thus their order of execution is non-deterministic. A possible reduction
is (effect on  omitted for brevity,  continuation of  after
Line 6):
{\scriptsize
7pt]
\hspace{-.5em}\begin{array}{l}
	\env', \begin{array}{l}
		\com{k_d}{\role A}{\prc sS.ok(\jpath{rsc})};
	  \com{k_d}{\prc aA}{\role C.ok};
	  \\
		\com{k_d}{\prc sS.\m{logok}(\jpath{rsc})}{\prc lL.log(\jpath{log})};
		C_s' \pp C_c	
	\end{array}
\end{array}
\to
\3pt]
\env'',
		\com{k_d}{\prc sS.\m{logok}(\jpath{rsc})}{\prc lL.log(\jpath{log})};
	  \com{k_d}{\prc aA}{\role C.ok};
		C_s' \pp C_c	
\to
\3pt]
\env''',
	  \com{k_d}{\prc aA}{\role C.ok};
		\com{k_d}{\role S}{\prc lL.log(\jpath{log})};
		C_s' \pp C_c	
\to \ldots
\end{array}

\hspace{-5pt}\begin{array}{l}
\env,\begin{array}{l}
\req{k_d}{\prc cC}{\wtil{l.\prc qB}}; \epp{C}{\pid c}' \pp \acc{k_d}{l_{\role A}.\prc aA}; \epp{C}{\pid a}' \pp \\
\acc{k_d}{l_{\role S}.\prc sS}; \epp{C}{\pid s}' \pp \acc{k_d}{l_{\role L}.\prc lL}; \epp{C}{\pid l}'		
\end{array}
\to
\
}
Which is the same effect of the execution of Line 1 of .

Complete communications project as partial sends and receives
between the two processes taking part in it. E.g., at Line 6 of , 
sends a message to  on operation . The EPP of Line 6 of 
projects to the send at Line 4 of  and the reception at Line
2 of . As we already commented, the effect, at runtime, of
Line 6 of  is that first  delivers its message to  and,
later on,  reads it. Line 4 of  and Line 2 of
 enact the same behaviour: first Line 4 executes
 and after the deliver Line 2 can execute.

The EPP preserves conditionals on the process evaluating it. For all the
other processes involved in the body of the conditional, the EPP projects a
branched reception. E.g., at Line 3 of , process  evaluates a
condition that either branches in the behaviour at Lines 4-15 or Lines 17-19.
The condition evaluated at Line 3 of  by process  is projected
verbatim at Line 3 of . The EPP of  projects a
branched communication on either operation  (Line 3) or  (Line 6 of
). The EPP of  projects only one branch (Line 2
of ) as  receives on operation  in either cases.

\textbf{Compilation.}
Once projected, we can compile the EPP of each process in the choreography to
a process of an executable language. To prove our translation sound we chose,
as target language of the compilation, an extended version of the Correlation
Calculus~\cite{MC11} (CC), the theoretical model behind the Jolie
language~\cite{jolie:website}.

Key elements of CC are \emph{services} and \emph{processes}. A service acts
as a deployment container. Each service is associated with a location,
contains a set of processes running in parallel, and can spawn new processes
at runtime on request. The form of a service is , where
 is the behaviour of spawnable processes,  the parallel composition of
the running processes, and  the deployment location. A process, with form
, is associated with a behaviour , a state , and a set
of queues .

CC handles communication via message passing. Messages are routed to
processes by means of correlation (matching) between a set of values
contained in the message and the values that identify a queue (just like
queues are identified by values in our choreographic model). In~\cite{MC11}
queues are static and assigned when a new process is created. To support the
runtime creation of new session, we present in this paper an extension of CC
that enables processes to create new queues at runtime.

In this way, we can translate the interactions on a session (in the original
choreography) into a set of message exchanges routed on the carried data. When
in the choreography a running process requests the creation of a new session,
we encode the request as the creation of a new set of data for correlation and
the relative queues pointed by that data. The result of our approach is that
the global knowledge on the state of the choreography, kept by the environment
, is distributed among the processes that result form the compilation of
the choreography.

\textbf{DIRE PERCHE' SERVE  ALL'ENCODING} 

We write the encoding of a running choreography  as .
Informally,  compiles to a parallel composition services, one
for
each location in . For each service :
\emph{i}) let  be the process that offers to accept ()
a new session on  in , . E.g.,
Figure~\ref{fig:preview_example_encoding_A} shows the encoding of the service
at  and it exposes 
to spawn new processes. A similar service is the one at  in
Figure~\ref{fig:preview_example_encoding_L}.
\emph{ii}) for all running processes  located at
 in , , i.e., it contains the parallel composition of
the compilation of the projection of  on each process. E.g., let process
 in  be located at , the encoding of  for 
located at  is  where , i.e.,  is the encoding of the projection .
Note that the state and set of queues of  are exactly the ones defined by
the environment  for .
Figure~\ref{fig:preview_example_encoding_C} shows an excerpt of the compilation
of the service at .


Below we comment some salient parts of the compilation and show how  implements the runtime behaviour of .

 is
the effect of starting a new session and it modifies  in such a way
that all involved processes in the start have the proper values set for
process-to-process communication (correlation) on  along with the
corresponding queues. In  we need to ensure the same behaviour in
a distributed setting. To do this, we compile the start of a new session to a
centralised synchronisation procedure. As a convention, we put in charge the
process running the  for a new session of setting the values
and to work as the synchronisation point.

Figure~\ref{fig:preview_example_encoding_C} shows an excerpt of the compilation
of : \emph{i}) Lines 1-2 set the location of the involved
processes. This data will be used later in send operations to address the
service of the receiver. \emph{ii}) Lines 3-5 assign fresh values () to
the variables for correlation, following the convention
. \emph{iii}) Lines 6-11 spawn the new
processes, one for each role (except the one played by the requester) in the
choreography. Lines 6-8 show the instructions for the process playing role
. Line 6 sets the queue of the requester to receive messages from
. Line 7 requests to the service at  to spawn a new
process. Line 8 waits to receive a message on operation  from the new
process playing role , i.e., on its queue pointed by
. \emph{iv}) Finally, Lines 12-14 notify all (new) processes
to start running the session.

The compilation of  is the complementary to
. Let us look at the compilation of Line 1 of  (Figure~\ref{fig:preview_example_epp_A}) shown at Lines 1-6 of
Figure~\ref{fig:preview_example_encoding_A}. At Line 1 
accepts the request to spawn a new process. Then (Lines 2-4) the process sets
its queues to receive, on session , from resp. , , and
. Finally, it notifies the starter (at ) it is
ready to begin the session (Line 5) and waits to be notified on operation
 (Line 6).

Apart from the start procedure, the code of a compiled process and its EPP
are very similar. Indeed, the main difference between the EPP and the
compilation is that, whilst in the choreography communications happen through
a session, in the compiled code we make explicit reference to the
data-structures used to address services and communicate on queues. E.g., let
us compare Figs.~\ref{fig:preview_example_epp_A}
and~\ref{fig:preview_example_encoding_A}, below respectively addressed as the
EPP and compilation of . Lines 3-9 of the EPP translate, one-by-one,
to Lines 7-14 of the compilation. We briefly comment a reception and a send
operation. The reception at Line 2 of the EPP compiles to Line 7 of
Figure~\ref{fig:preview_example_encoding_A}.  reads a message for operation 
from the queue pointed by  and assigns its content to
variable . The send operation at Line 4 of the EPP translates to
 (Line 9
of the compilation) which sends the content of  to the
process located at  that correlates with .



