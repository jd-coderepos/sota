\newif\ifprocs
\procsfalse


\ifprocs
\documentclass[twoside,leqno,twocolumn]{article}  
\usepackage{ltexpprt} 
\usepackage{balance}
\else
\documentclass[11pt,fleqn]{article}
\usepackage{fullpage}
\usepackage{amsthm}
\fi

\usepackage{amsmath,amssymb}
\usepackage[boxed]{algorithm}
\usepackage[noend]{algorithmic}
\usepackage{bbm}
\usepackage{graphicx}
\usepackage{subfigure}
\usepackage{xspace}
\usepackage{color}


\usepackage{ifpdf}
\ifpdf    \usepackage{hyperref}
\else    \usepackage[hypertex]{hyperref}
\fi


\renewcommand{\algorithmicrequire}{\textbf{Input:}}
\renewcommand{\algorithmicensure}{\textbf{Output:}}
\renewcommand{\algorithmiccomment}[1]{// {\em #1}}

\ifprocs
\newtheorem{definition}[Definition]{Definition}
\newtheorem{assumption}[Definition]{Assumption}
\newtheorem{notation}[Definition]{Notation}
\newtheorem{claim}[lemma]{Claim}
\newtheorem{remark}[Remark]{Remark}
\else
\newtheorem{theorem}{Theorem}[section]
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{fact}[theorem]{Fact}
\newtheorem{corollary}[theorem]{Corollary}
\newtheorem{definition}[theorem]{Definition}
\newtheorem{proposition}[theorem]{Proposition}
\newtheorem{observation}[theorem]{Observation}
\newtheorem{claim}[theorem]{Claim}
\newtheorem{assumption}[theorem]{Assumption}
\newtheorem{remark}[theorem]{Remark}
\newtheorem{notation}[theorem]{Notation}
\fi

\ifprocs
\newcommand{\proofof}[1]{of #1}
\else
\newcommand{\proofof}[1]{Proof of #1}
\renewcommand{\qedhere}{}
\fi

\newcommand {\ignore} [1] {}
\def \opt   {\mathsf{opt}}                             \def \iter {10 \log_b \calD}

\newcommand{\rnote}[1]{\textcolor{red}{\textsf{#1 --Robi}\marginpar{\tiny\bf RK}}}

\DeclareMathOperator{\supp}{supp}
\DeclareMathOperator{\diam}{diam}
\DeclareMathOperator*{\EX}{{\mathbb E}}
\DeclareMathOperator{\polylog}{polylog}
\newcommand{\R}{{\mathbb R}}
\newcommand{\etal}{{\em et al.\ }\xspace}
\newcommand{\minn}[1]{\min\{{#1}\}}
\newcommand{\maxx}[1]{\max\{{#1}\}}
\providecommand{\ceil}[1]{\lceil #1 \rceil}
\providecommand{\abs}[1]{\lvert#1\rvert}
\providecommand{\card}[1]{\lvert#1\rvert}
\providecommand{\norm}[1]{\lVert#1\rVert}
\providecommand{\aset}[1]{\{#1\}}
\providecommand{\eqdef}{:=}

\def\compactify{\itemsep=0pt \topsep=0pt \partopsep=0pt \parsep=0pt}

\newcommand{\calP}{{\mathcal P}}
\newcommand{\calD}{{\mathcal D}}
\newcommand{\far}{{\text{far}}}
\newcommand{\near}{{\text{near}}}
\newcommand{\fin}{{\text{fin}}}
\newcommand{\longSub}{{\text{long}}}
\DeclareMathOperator{\texp}{Texp}



\title{Cutting corners cheaply, or how to remove Steiner points\thanks{A preliminary version appeared in Proceedings of the 25th Annual ACM-SIAM
Symposium on Discrete Algorithms, 2014}}
\author{Lior Kamma\thanks{This work was supported in part by the Israel Science Foundation (grant 
\#897/13), the US-Israel BSF (grant \#2010418), and by the Citi Foundation.
Part of this work was done while visiting Microsoft Research New England.
Email: \texttt{\{lior.kamma,robert.krauthgamer\}@weizmann.ac.il}
}
\\ The Weizmann Institute
\and Robert Krauthgamer\footnotemark[\value{footnote}]
\\ The Weizmann Institute
\and Huy L. Nguyn\thanks{This work was supported in part by NSF CCF 0832797, and a Gordon Wu Fellowship.
Part of this work was done while interning at Microsoft Research New England.
Email: \texttt{hlnguyen@princeton.edu}
}
\\ Princeton University
}

\ifprocs
\date{}
\fi


\begin{document}

\maketitle

\begin{abstract}
\ifprocs
  \small \fi
Our main result is that the Steiner Point Removal (SPR) problem
can always be solved with polylogarithmic distortion,
which answers in the affirmative 
a question posed by Chan, Xia, Konjevod, and Richa (2006).
Specifically, we prove that for every edge-weighted graph 
and a subset of terminals , 
there is a graph  that is isomorphic to a minor of ,
such that for every two terminals ,
the shortest-path distances between them in  and in  satisfy
.
Our existence proof actually gives a randomized polynomial-time algorithm.

\ifprocs
  \small \fi
Our proof features a new variant of metric decomposition.
It is well-known that every finite metric space  admits 
a -separating decomposition for , 
which means that for every  there is a randomized 
partitioning of  into clusters of diameter at most ,
satisfying the following separation property:
for every , the probability they lie in different clusters 
of the partition is at most . 
We introduce an additional requirement in the form of a tail bound:
for every shortest-path  of length , 
the number of clusters of the partition that meet the path , denoted ,
satisfies  for all .
\end{abstract}


\section{Introduction}

\emph{Graph compression} describes the transformation of a given graph  
into a small graph  that preserves certain features (quantities) of ,
such as distances or cut values.
Notable examples for this genre include graph spanners, distance oracles,
cut sparsifiers, and spectral sparsifiers, 
see e.g.\ \cite{PS89,TZ05,BK96,BSS08} and references therein.
The algorithmic utility of such graph transformations is clear  -- 
once the ``compressed'' graph  is computed as a preprocessing step,
further processing can be performed on  instead of on ,
using less resources like runtime and memory, 
or achieving better accuracy (when the solution is approximate). 
See more in Section \ref{sec:related}.


Within this context, we study \emph{vertex-sparsification},
where  has a designated subset of vertices ,
and the goal is to reduce the number of vertices in the graph
while maintaining certain properties of .
A prime example for this genre is vertex-sparsifiers
that preserve terminal versions of (multicommodity) cut and flow problems, 
a successful direction that was initiated by Moitra \cite{Moitra09} 
and extended in several followups \cite{LM10,CLLM10,MM10,EGKRTT10,Chuzhoy12}.
Our focus here is different, on preserving distances, 
a direction that was seeded by Gupta \cite{Gupta01} more than a decade ago.

Throughout the paper, all graphs are undirected and all edge weights are positive.

\paragraph{Steiner Point Removal (SPR).}
Let  be an edge-weighted graphand let  be a designated set of  terminals.
Here and throughout,  denotes the shortest-path metric 
between vertices of  according to the weights .
The \emph{Steiner Point Removal} problem asks to construct on the terminals
a new graph  such that
(i)  
distances between the terminals are \emph{distorted} at most 
by factor , formally

and (ii) the graph  is (isomorphic to) a minor of .
This formulation of the SPR problem was proposed by
Chan, Xia, Konjevod, and Richa \cite[Section 5]{CXKR06}
who posed the problem of bounding the distortion 
(existentially and/or using an efficient algorithm).
Our main result is to answer their open question.

Requirement (ii) above expresses structural similarity between  and ; 
for instance, if  is planar then so is .
The SPR formulation above actually came about as a generalization 
to a result of Gupta \cite{Gupta01}, which
asserts that if  is a tree, there exists a tree , which preserves terminal distances with distortion .
Later Chan \etal \cite{CXKR06} observed that this same  
is actually a minor of the original tree ,
and proved the factor of  to be tight.
The upper bound for trees was later extended by Basu and Gupta \cite{BG08},
who achieve distortion  for the larger class of outerplanar graphs.



\paragraph{How to construct minors.}

We now describe a general methodology that is natural for the SPR problem.
The first step constructs a minor  with vertex set , 
but without any edge weights,
and is prescribed by Definition \ref{defn:tcm}.
The second step determines edge weights  
such that  dominates  on the terminals ,
and is given in Definition \ref{defn:sr}.
These steps are illustrated in Figure \ref{fig:defs}.
Our definitions are actually more general (anticipating the technical sections),
and consider  whose vertex set is sandwiched between  and .
\begin{definition}
A \emph{partial partition} of a set  is a collection  
of pairwise disjoint subsets of , referred to as {\em clusters}.
\end{definition}

\begin{figure}[ht]
  \begin{center}
    \label{fig:defs}
    \includegraphics[scale=0.45]{defs}
    \caption{The graph , a -cycle with unit edge weights, 
is depicted on the left with  terminals and disjoint subsets . 
Its terminal-centered minor  and the standard-restriction 
edge weights are shown on the right.}
  \end{center}
\hrule
\end{figure}

\begin{definition}[Terminal-Centered Minor] \label{defn:tcm}
Let  be a graph with  terminals ,
and let  be a partial partition of , 
such that each induced subgraph  is connected and contains .
The graph  obtained by contracting each  
into a single vertex that is identified with , 
is called the {\em terminal-centered minor} of  induced by .
\end{definition}

By identifying the ``contracted super-node''  with , 
we may think of the vertex-set  as containing 
and (possibly) some vertices from ,
which implies .
A terminal-centered minor  of  
can also be described by a mapping , 
such that  
and  is connected in  for all .
Indeed, simply let  for all , 
and thus . 

\begin{definition}[Standard Restriction] \label{defn:sr}
Let  be an edge-weighted graph with terminal set ,
and let  be a terminal-centered minor of .
(Recall we view .)
The {\em standard restriction} of  to  is the edge weight 
given by the respective distances in , formally

\end{definition}

This edge weight  is optimal in the sense that 
 dominates  (where it is defined, i.e., on ),
and the weight of each edge  is minimal
under this domination condition.

\subsection{Main Result} \label{sec:results}

Our main result below gives an efficient algorithm 
that achieves  distortion for the SPR problem.
Its proof spans Sections \ref{sec:TCM} and \ref{sec:proofDiscard},
though the former contains the heart of the matter.

\begin{theorem} \label{thm:main}
Let  be an edge-weighted graph with  terminals .
Then there exists a terminal-centered minor  of  that attains distance distortion , i.e., 

Moreover,  is the standard restriction of ,
and  is computable in randomized polynomial time.
\end{theorem}

This theorem answers a question of Chan \etal \cite{CXKR06}. The only distortion lower bound known for general graphs 
is a factor of  (which actually holds for trees) \cite{CXKR06},
and thus it remains a challenging open question whether 
 distortion can be achieved in general graphs.

Our proof of Theorem \ref{thm:main} begins similarly to the proof of Englert \etal \cite{EGKRTT10}, 
by iterating over the ``distance scales'' , 
going from the smallest distance  among all terminals ,
towards the largest such distance.
Each iteration  first employs a ``stochastic decomposition'',
which is basically a randomized procedure that finds 
clusters of  whose diameter is at most .
Then, some clusters are contracted to a nearby terminal,
which must be ``adjacent'' to the cluster;
this way, the current graph is a minor of the previous iteration's graph, 
and thus also of the initial .
After iteration  is executed, 
we roughly expect ``neighborhoods'' of radius proportional to  
around the terminals to be contracted.
As  increases, these neighborhoods get larger
until eventually all the vertices are contracted into terminals,
at which point the edge weights are set according to the standard restriction.
To eventually get a minor, 
it is imperative that every contracted region is connected.
To guarantee this, we perform the iteration  decomposition in the graph 
resulting from previous iterations' contractions (rather than the initial ),
which introduces further dependencies between the iterations.

The main challenge is to control the distortion,
and this is where we crucially deviate from \cite{EGKRTT10}
(and differ from all previous work).
In their randomized construction of a minor , 
for every two terminals  it is shown that  contains
a -path of \emph{expected length} at most .
Consequently, they design a \emph{distribution}  over minors ,
such that the stretch  between any 
has expectation at most . Note, however, that it is possible that no  achieves a low stretch 
simultaneously for all .
In contrast, in our randomized construction of ,
the stretch between  is polylogarithmic
\emph{with high probability}, say at least .
Applying a simple union bound over the  terminal pairs,
we can then obtain a single graph  achieving a polylogarithmic distortion.
Technically, these bounds follow by fixing in  
a shortest-path  between two terminals ,
and then tracking the execution of the randomized algorithm
to analyze how the path  evolves into a -path  in .
In \cite{EGKRTT10}, the length of  is analyzed in expectation,
which by linearity of expectation, 
follows from analyzing the case where  consists of a single edge;
In contrast, we provide for  a high-probability bound,
which inevitably must consider (anti)correlations along the path.

The next section features a new tool that we developed in our quest 
for high-probability bounds, and which may be of independent interest.
For the sake of clarity, we provide below  
a vanilla version that excludes technical complications 
such as terminals, strong diameter, and consistency between scales.
The proof of Theorem \ref{thm:main} actually does require these complications, 
and thus cannot use the generic form described below.


\subsection{A Key Technique: Metric Decomposition with Concentration} \label{sec:techniques}

\paragraph{Metric decomposition.}

Let  be a metric space, and let  be a partition of .
Every  is called a {\em cluster},
and for every , we use  to denote the unique cluster 
 such that .
In general, a stochastic decomposition of the metric  
is a distribution  over partitions of ,
although we usually impose additional requirements.
The following definition is perhaps the most basic version,
often called a separating decomposition or a Lipschitz decomposition.

\begin{definition}\label{def:beta}
A metric space  is called {\em -decomposable} 
if for every , there is a probability distribution  over 
partitions of , satisfying the following requirements:
\begin{enumerate} \compactify
\renewcommand{\theenumi}{\emph{(\alph{enumi})}}
\item \label{it:DiameterBound}
Diameter bound: for all  and all , 
  \ . 
\item \label{it:SeparatingProb}
Separation probability: for all ,
  \ .
\end{enumerate}
\end{definition}
We note that the diameter bound holds with respect to distances in ;
in the case of a shortest-path metric in a graph, 
this is known as a {\em weak-diameter} bound.

Bartal \cite{Bartal96} proved that every -point metric is 
-decomposable, and that this bound is tight. 
We remark that by now there is a rich literature on metric decompositions,
and different variants of this notion may involve terminals,
or (in a graphical context) connectivity requirements inside each cluster,
see e.g.\ \cite{LS93,Bartal96, CKR01, FRT04, Bartal04, LN05, GNR10, EGKRTT10, MN07, AGMW10, KR11}.


\paragraph{Degree of separation.}
Let  be a {\em shortest path},
i.e., a sequence of points in  such that

We denote its length by ,
and say that  {\em meets} a cluster  
if . 
Given a partition  of , 
define the \emph{degree of separation}  as
the number of different clusters in the partition  that meet . 
Formally,


Throughout, we omit the partition  when it is clear from the context.
When we consider a random partition , 
the corresponding  is actually a random variable.
If this distribution  satisfies 
requirement \ref{it:SeparatingProb} of Definition \ref{def:beta}, then 

But what about the concentration of ?
More precisely, can every finite metric be decomposed, such that 
every shortest path  admits a tail bound on its degree of separation ?

\paragraph{A tail bound.}
We answer this last question in the affirmative using the following theorem.
We prove it, or actually a stronger version that does involve terminals,
in Section \ref{sec:main2}.


\begin{theorem}\label{thm:main2}
For every -point metric space  and every  
there is a probability distribution  over partitions of 
that satisfies, for ,
requirements \ref{it:DiameterBound}-\ref{it:SeparatingProb} 
of Definition \ref{def:beta}, and furthermore
\begin{enumerate} \compactify
\renewcommand{\theenumi}{\emph{(\alph{enumi})}}
\addtocounter{enumi}{2}
\item \label{it:DegreeSeparation}
Degree of separation: For every shortest path  of length , 

\end{enumerate}
\end{theorem}
The tail bound \eqref{eq:SimpleTail} can be compared to a naive estimate 
that holds for every -decomposition :
using \eqref{eq:ExpectedCount} we have ,
and then by Markov's inequality .

We remark that for general metric spaces, it is known that  is tight \cite{Bartal96}. However, for requirements \ref{it:DiameterBound}-\ref{it:SeparatingProb} of Definition \ref{def:beta} several decompositions are known to have better values of  
for special families of metric spaces 
(e.g., metrics induced by planar graphs \cite{KPR93}). 
We leave it open whether for these families
the bounds of Theorem~\ref{thm:main2} can be improved, say to .


\subsection{Related Work} \label{sec:related}

\paragraph{Applications.}
Vertex-sparsification, and the ``graph compression'' approach in general, 
is obviously beneficial when  can be computed from  very efficiently, 
say in linear time, 
and then  may be computed on the fly rather than in advance.
But compression may be valuable also in scenarios
that require the storage of many graphs, like archiving and backups,
or rely on low-throughput communication, like distributed or remote processing.
For instance, the succinct nature of  may be indispensable for computations
performed frequently, say on a smartphone,
with preprocessing done in advance on a powerful machine.

We do not have new theoretical applications that leverage our SPR result,
although we anticipate these will be found later. 
Either way, we believe this line of work will prove technically productive,
and may influence, e.g., work on metric embeddings 
and on approximate min-cut/max-flow theorems.

\paragraph{Probabilistic SPR.}
Here, the objective is not to find a single graph ,
but rather a distribution  over graphs ,
such that every graph  is isomorphic to a minor of 
and its distances  dominate  (on ),
and such that the distortion inequalities hold in expectation, that is,

This problem, first posed by Chan \etal in \cite{CXKR06}, was answered by Englert \etal in \cite{EGKRTT10}
with .

\paragraph{Distance Preserving Minors.} 
This problem is a relaxation of SPR in which the minor  may contain a few non-terminals,
while preserving terminal distances exactly.
Formally, the objective is to find a small graph  such that
(i)  is isomorphic to a minor of ;
(ii) ; and
(iii) for every ,\ .
This problem was originally defined by Krauthgamer, Nguyn and Zondiner \cite{KNZ14},
who showed an upper bound  for general graphs,
and a lower bound of  that holds even for planar graphs. 


\section{Metric Decomposition with Concentration} \label{sec:main2}

In this section we prove a slightly stronger result than that of Theorem~\ref{thm:main2},
stated as Theorem \ref{thm:main3} below. 
Let  be a metric space, and let  
be a designated set of terminals.
Recall that a partial partition  of  
is a collection of pairwise disjoint subsets of . 
For a shortest path  in ,
define  using Eqn.~\eqref{eq:dosdef},
which is similar to before, except that now  is a partial partition.
We first extend Definition~\ref{def:beta}.

\begin{definition}
We say that  is {\em -terminal-decomposable with concentration} if for every  there is a probability distribution  over partial partitions of , satisfying the following properties.
\begin{itemize} \compactify
	\item {\em Diameter Bound:} For all  and all ,\ .
	\item {\em Separation Probability:} For every , 
	\item {\em Terminal Cover:} For all , we have \mbox{}.
	\item {\em Degree of Separation:} For every shortest path  and every , 
          

\end{itemize}
\end{definition}

\begin{theorem} \label{thm:main3}
Every finite metric space with  terminals 
is -terminal-decomposable with concentration.
\end{theorem}

Define the {\em truncated exponential} with parameters , 
denoted ,
to be distribution given by the probability density function 

for all . 

We are now ready to prove Theorem \ref{thm:main3}. For simplicity of notation, we prove the result with cluster diameter at most  instead of .
Fix a desired ,
and set for the rest of the proof  
and . 
For  and , we use the standard notation of a closed ball
. 
We define the distribution  via the following procedure that samples 
a partial partition  of .
\begin{algorithm}[H]
\begin{algorithmic}[1]
\FOR{}
\STATE choose  independently at random, and let .
\STATE set .
\ENDFOR
\RETURN .
\end{algorithmic}
\end{algorithm}
The diameter bound and terminal partition properties hold by construction. The proof of the separation event property is identical to the one in \cite[Section 3]{Bartal96}.
The following two lemmas prove the degree of separation property, 
which will conclude the proof of Theorem~\ref{thm:main3}. 
Fix a shortest path  in ,
and let us assume that  is a positive integer;
a general  can be reduced to this case up to a loss
in the unspecified constant.

\begin{lemma} \label{l:shortShortest}
If , then .
\end{lemma}
\begin{proof}
Split the  terminals into 
 
and .
Define random variables 
 
and .
Then  and 

For every , 

and therefore .
Since  is the sum of independent indicators, 
by the Chernoff bound,  
for all .
For smaller , observe that , 
and thus for every  we have .

Next, consider the balls among  
that have non-empty intersection with . Let  denote the number of such balls, 
and let  denote their indices.
In other words, we condition henceforth on an event  
that determines whether  occurs or not for each . The indices of coordinates of  that are equal to  are exactly .
For , let  be the indicator variable for the event that the
ball  does \emph{not} contain . Note that since  are independent, then so are . Then

Having conditioned on ,
the event  implies that  and moreover,  for all ,
and since  are independent, 

for an appropriate constant . 
The last inequality holds for all such events  
(with the same constant ),
and thus also without any such conditioning.

Altogether, we conclude that

\end{proof}

\begin{lemma} \label{l:longShortest}
If , then .
\end{lemma}
\begin{proof}
Treating  as a continuous path, 
subdivide it into  segments,
say segments of equal length that are (except for the last one)\
half open and half closed.
The induced subpaths  of  
are disjoint (as subsets of ) and have length at most  each,
though some of subpaths may contain only one or even zero points of .
Writing , we can
apply a union bound and then Lemma~\ref{l:shortShortest} on each , 
to obtain

Furthermore, for every , 
let , 
and since  is a shortest path, 
.
Observe that  (with certainty) 
for all ,
hence

\end{proof}

By substituting  and , it is easy to verify that Lemmas \ref{l:shortShortest} and \ref{l:longShortest}
complete the proof of Theorem \ref{thm:main3}.


\section{Terminal-Centered Minors: Main Construction} \label{sec:TCM}

This section proves Theorem \ref{thm:main} when 

satisfies the following assumption 
(the extension to the general case is proved in Section~\ref{sec:proofDiscard}).
\begin{assumption} \label{a:polyLogDelta}
.
\end{assumption}
By scaling all edge weights, we may further assume that 
.

\begin{notation}
Let .
For , denote . 
In addition, denote  
and  for any . 
\end{notation}

We now present a randomized algorithm that, 
given a graph  and terminals ,
constructs a terminal-centered minor  as stated in Theorem~\ref{thm:main}.
The algorithm maintains a partial partition  of , 
starting with  for all . 
The sets grow monotonically during the execution of the algorithm. 
We may also think of the algorithm as if it maintains a mapping 
, 
starting with  for all  and gradually assigning a value in  
to additional vertices, which correspond to the set . 
Thus, we will also refer to the vertices in  as {\em assigned}, 
and to vertices in  as {\em unassigned}.
The heart of the algorithm is two nested loops (lines \ref{al:outer}-\ref{al:endOuter}). During every iteration of the outer loop, the inner loop performs  iterations, one for every terminal . 
Every inner-loop iteration picks a random radius (from an exponential distribution) 
and ``grows''  to that radius (but without overlapping any other set) thus removing nodes from  and assigning them to . 
Every outer-loop iteration increases the expectation of the radius distribution.
Eventually, all nodes are assigned, 
i.e.\  is a partition of .
Note that the algorithm does not actually contract the clusters at the end of each iteration of the outer loop. 
However, subsequent iterations grow each  
only in the subgraph of  induced by the respective ,
which is effectively the same as contracting clusters to their respective terminals at the end of each outer-loop iteration.

Every cluster in the partial partition maintained by the algorithm needs to induce a connected subgraph of , 
and thus we cannot directly use the result of Section~\ref{sec:main2}, 
but rather apply more subtle arguments which use the same idea. 
In particular, the algorithm has to grow the clusters so that they do not overlap. We therefore require the following definition.
\begin{definition}
For , let  denote the subgraph of  induced by , with induced edge lengths (i.e. ).
For a subgraph  of  with induced edge lengths, a vertex  and , denote , where  is the shortest path metric in  induced by .
\end{definition}

\begin{algorithm}[H]
\caption{Partitioning }
\label{alg:part}
\begin{algorithmic}[1]
\REQUIRE 
\ENSURE A partition  of .
\STATE set 
\STATE for every  set , .
\STATE set . \COMMENT{ is the iteration number of the outer loop.}
\WHILE{} \label{al:outer} 
\STATE .
\FORALL{} \label{al:inner}
\ifprocs
\STATE choose independently\! at\!  random\! .
\else
\STATE choose independently at  random .
\fi
\STATE .
\STATE . 
  \COMMENT{This is the same as .}
\ENDFOR
\ENDWHILE \label{al:endOuter}
\RETURN .
\end{algorithmic}
\end{algorithm}

\begin{claim}
The following properties hold throughout the execution of the algorithm.
\begin{enumerate} \compactify
	\item For all ,  is connected in , and .
	\item For every , if , then .
	\item For every outer loop iteration  and every , 
if  denotes the set  at the beginning of the -th iteration (of the outer loop), and  denotes the set  at the end of that iteration, 
then .
\end{enumerate}
\end{claim}

In what follows, we analyze the stretch in distance between a fixed pair of terminals. We show that with probability at least , the distance between these terminals in  is at most  times their distance in . By a union bound over all  pairs of terminals, we deduce Theorem~\ref{thm:main}.
Let , and let  be a shortest -path in . Due to the triangle inequality, we may focus on pairs which satisfy , where  is the node set of . We denote .

\subsection{High-Level Analysis}
Following an execution of the algorithm, we maintain a (dynamic) path  between  and . In a sense, in every step of the algorithm,  simulates an -path in the terminal-centered minor induced by . At the beginning of the execution, set  to be simply . During the course of the execution update  to satisfy two invariants. At every step of the algorithm, the weight of  is an upper bound on the distance between  and  in the terminal centered minor induced by  (in that step). In addition, if  is a subpath of , whose inner vertices are all unassigned, then  is a subpath of . Throughout the analysis, we think of  as directed from  to , thus inducing a linear ordering of the vertices in . 

\begin{definition}
A subpath of  will be called {\em active} if it is a maximal subpath whose inner vertices are unassigned.
\end{definition}

Note that a single edge whose endpoints are both assigned will not be considered active.

We now describe how  is updated during the execution of the algorithm. Consider line \ref{al:endOuter} of the algorithm for the -th iteration of the outer loop, and some . We say that the ball  {\em punctures} an active subpath  of , if there is an inner node of  that belongs to the ball.
If  does not puncture any active subpath of , we do not change . Otherwise, denote by  the first and last unassigned nodes (possibly not in the same active subpath) in  respectively. Then we do the following.

We replace the entire subpath of  between  and  with a concatenation of a shortest -path and a shortest -path that lie in ; this is possible, since  is connected, and .
This addition to  will be called a {\em detour} from  to  through . The process is illustrated in figures~\ref{f:det-a}-\ref{f:det-b}. Beginning with , the figure describes the update after the first four balls. Note that the detour might not be a simple path.
It is also worth noting that here  and  may belong to different active subpaths of . For example, in figure~\ref{f:det-c}, the new ball punctures two active subpaths, and therefore in figure~\ref{f:det-d}, the detour goes from a node in one active subpath to a node in another active subpath. Note that in this case, we remove from  portions which are not active.

It is worth noting that this update process implies that at any given time, there is at most one detour that goes through . If, for some iteration  of the outer loop, and for some , we added a detour from  to  through  in iteration , we keep only one detour through , from the first node between  and to the last between . For example, in figure~\ref{f:det-e}, the ball centered in  punctures an active subpath. Only one detour is kept in figure~\ref{f:det-f}.
\ifprocs 
\begin{figure*}[ht]
  \begin{center}
    \subfigure[We begin with ]{\label{f:det-a}\includegraphics[scale=0.25]{det1}}
    \ 
    \subfigure[Every inner-loop iteration grows a terminal-centered ball. Here balls around  are grown with detours added. Since  is a shortest path, the detours for  and  are, in fact, subpaths of .]{\label{f:det-b}\includegraphics[scale=0.25]{det2}}
    \ 
    \subfigure[Endpoints of a detour can belong to different active subpaths. Here a ball around  is grown.]{\label{f:det-c}\includegraphics[scale=0.25]{det25}}
    \
    \subfigure[Update detour for .]{\label{f:det-d}\includegraphics[scale=0.25]{det3}}
    \ 
    \subfigure[The ball around  is further grown.]{\label{f:det-e}\includegraphics[scale=0.25]{det4}}
    \ 
    \subfigure[Update detour for .]{\label{f:det-f}\includegraphics[scale=0.25]{det5}}
  \end{center}
  \caption{Updating }
  \label{f:det}
\end{figure*}
\else
\begin{figure}[t]
  \begin{center}
    \subfigure[We begin with ]{\label{f:det-a}\includegraphics[scale=0.25]{det1}}
    \quad 
    \subfigure[Every inner-loop iteration grows a terminal-centered ball. Here balls around  are grown with detours added. Since  is a shortest path, the detours for  and  are, in fact, subpaths of .]{\label{f:det-b}\includegraphics[scale=0.25]{det2}}
    \quad
    \subfigure[Endpoints of a detour can belong to different active subpaths. Here a ball around  is grown.]{\label{f:det-c}\includegraphics[scale=0.25]{det25}}
    \quad
    \subfigure[Update detour for .]{\label{f:det-d}\includegraphics[scale=0.25]{det3}}
    \quad
    \subfigure[The ball around  is further grown.]{\label{f:det-e}\includegraphics[scale=0.25]{det4}}
    \quad
    \subfigure[Update detour for .]{\label{f:det-f}\includegraphics[scale=0.25]{det5}}
  \caption{Updating }
  \label{f:det}
  \end{center}
\hrule
\end{figure}
\fi

The total weight of all detours during the execution will be called the {\em additional weight} to  (ignoring portions of  that are deleted from ).
Denote the set of active subpaths of  at the beginning of the -th iteration of the outer loop by .

Let  be the partition returned by the algorithm, let  the terminal-centered minor induced by that partition, and let  be the standard restriction of  to . 
Denote by  the path obtained at the end of the execution.
\begin{claim} 
At every step of the algorithm the following holds:
\begin{enumerate}
	\item The weight of  is an upper bound on the distance between  and  in the terminal centered minor induced by . Moreover, once  (namely,  has no active subpaths), the weight of  is an upper bound on the distance between  and  in the terminal centered minor induced by  (actually, from this point on, ).
	\item If  is a subpath of , whose inner points are all in , then  is a subpath of .
	\item If  are two different active subpaths of , they are internally disjoint.
	\item  for all .
\end{enumerate}
\end{claim}

\begin{proof}
Follows easily by induction on .
\end{proof} 
\begin{corollary} \label{cor:costMinor}
.
\end{corollary}

Let . During the execution of the inner loop,  is either removed from  entirely, or some subpaths of  remain active (perhaps  remains active entirely). Therefore, for every , either  is a non-trivial subpath of  (by non-trivial we mean ), or  and  are internally disjoint. Therefore there is a laminar structure on . 

We describe this structure using a tree , whose node set is . The root of  is , and for every  and every , the children of , if any, are all pairs , where  is a subpath of .
Whenever we update  we log the weight of the detour by charging it to one of the nodes of  as follows. Consider a detour from  to  in the -th iteration of the outer loop for some . Before adding this detour,  and  are unassigned nodes in . Because  is unassigned,  is an inner vertex of some active subpath. In either case, there is exactly one active subpath containing . The weight of the detour is charged to the unique active subpath  such that . For every  and , let  be the total weight charged to . If the node is never charged, the weight of the node is set to . Therefore, 

Eqn.~\eqref{eq:treeBound} together with Corollary~\ref{cor:costMinor} imply that if we show that with high probability, the total weight charged to the tree is at most , we can deduce Theorem~\ref{thm:main}.
For the rest of this section, we therefore prove the following lemma.
\begin{lemma} \label{l:totalWeight}
With probability at least , the total weight charged to the tree is at most .
\end{lemma}

Consider an iteration  and an active subpath . 
Informally, since the distortion is measured relatively to , 
if the expected radius  is small compared to , 
then with high probability a detour will not add ``much'' to the distortion,
and thus we are more concerned with the opposite case 
where  is small relative to the current expected radius.

Formally, let . An active subpath  will be called {\em short} if . Otherwise,  will be called {\em long}. Notice that  is long, and for , every  is short.

\begin{definition}
Let  and let  be a short subpath. Denote by  the subtree of  rooted in . 
Denote the parent of  in  
by  for .
If  is long,  will be called a {\em short subtree} of .
\end{definition}

Once an active subpath becomes short (during the course of the iterations), 
we want all its vertices to be assigned quickly, and by a few detours. 
For this reason, the height and weight of short subtrees will play an important role in the analysis of the height and weight of .

To bound the total weight of the tree , we analyze separately 
the weights charged to long active subpaths at each level, 
and the weights of short subtrees rooted at each level.
More formally, for every , denote by  the total weight charged to nodes of the form , where  is a long active subpath. Denote by  the total weight charged to short subtrees rooted at the level  of . 
For , every  is short and thus  belongs to some short subtree rooted at level at most . Therefore,

Similarly to the proof of Theorem~\ref{thm:main3}, we will first analyze the behavior of short subpaths of active paths, and then use it to bound . 
To bound the weight of long active paths, we will divide them into short segments, similarly to the proof of Lemma~\ref{l:longShortest}, and then sum everything up to bound .


\subsubsection{The Effect of a Single Ball on a Short Segment}
Let  and let  be a subpath of  such that all the inner nodes of  are unassigned in the beginning of the -th iteration of the outer loop, and . Note that  is not necessarily maximal with that property, and therefore is not necessarily an active subpath. However,  is a subpath of some (unique) active subpath .
We first consider the effect of a single ball over , in some iteration . 

Fix some , and some .
Let  denote the number of active subpaths  such that  at the beginning of the -th iteration of the inner loop (during the -th iteration of the outer loop). Note that every such subpath  is necessarily a subpath of , due to the laminar structure of active subpaths. Since every such active subpath will add at least one detour before it is completely assigned, we want to show that  is rapidly decreasing.
Let  denote the number of active subpaths  such that  at the end of the -th iteration. Denote by  the ball considered in this iteration, namely .
\begin{proposition} \label{p:maxBirth}
With certainty, .
\end{proposition} 

\begin{proof}
Let  be all active subpaths of  which intersect  and are active in the beginning of the -th iteration ordered by their location on . For  denote by  the first and last unassigned nodes in , respectively. If  does not puncture any of these subpaths, then  (Note that subpaths of  can still be removed if  punctures active subpaths of  not contained in ). So assume  punctures .
Assume first that  is the only subpath of  which is active and is punctured by . Then there are three options:
If both , then  is replaced and removed entirely from  when adding the detour, and .
If  and , let  be the last node in  then the  segment of  is replaced, and the segment  remains active. Therefore . The argument is similar, if  and .
Otherwise, some of the inner portion of  is replaced by a non-active path, and both end segments of  remain active, therefore .
Next, assume the ball punctures several active subpaths of , and maybe more subpaths of . Denote by  the first and last subpaths of  punctured by . Denote by  the first node in , and  the last node in . When updating , the entire subpath of  between  and  is removed. 
Thus .
\end{proof}


We now want to show that if some unassigned vertex  gets assigned due to a ball , i.e.,  punctures some active subpath intersecting , then  is likely to decrease. 
Recalling that unassigned nodes in  must be in , 
this goal is stated formally as 
 
However, this statement is not sufficient for our needs, as it does not imply 
that with high probability a short active subpath is assigned quickly. 
Indeed, let  be a short active subpath and suppose no ball punctures any subpath of  for many iterations following ; 
then the detour that will eventually be added to replace a subpath of 
might be too long relative to  (as expected radii increase exponentially). Therefore, when arguing that with reasonable probability  decreases,
we shall condition on a more refined event, 
which generalizes the notion of a ball puncturing an active subpath.
Loosely speaking, we consider events in which the ball  includes 
a vertex  (i.e.,  is already assigned),
and assume there is an unassigned , such that  is an edge in  (since  is a shortest path, this edge  must be part of ),
which means there is an active subpath intersecting  adjacent to 
(in particular,  is one of its endpoints). 
By the memoryless property of the exponential distribution, conditioned on , with reasonable probability  covers that subpath. 
The formal definition follows.

\begin{definition}
Let  be a subpath of . We say that a ball  {\em reaches}  if there is  such that either  is unassigned, 
or  has an unassigned neighbor which is in .
\end{definition}

Consider again the case where  is active. Then both its endpoints are assigned. Note that the endpoints of  cannot both be assigned to the same terminal (otherwise  would have been removed entirely). 
By the definition of the balls in the algorithm,  and therefore  may reach  and not puncture it if and only if  has exactly one endpoint in . Note that all active subpaths are reached at least twice in every iteration of the outer loop (by the clusters which contain their endpoints). Therefore in every iteration of the outer loop at least two balls reach  with certainty, even though it could be the case that no ball punctures . 
\begin{proposition} \label{p:cond}
BI
\end{proposition} 

\begin{proof}
Assume that  reaches . Then there exists a node  such that either  is unassigned, or  has an unassigned neighbor .
Let .
Assume first that  is unassigned. Let  be the active subpath such that .
Following the analysis of the previous proof, if , then  punctures exactly one active subpath (namely ) that intersects  and does not cover the part of  contained in , or  punctures exactly two  such active subpaths and covers neither of them. In either case,  punctures  and does not cover the part of  contained in . Since , the length of  is at most . We conclude that , and .
If  has an unassigned neighbor , we get the same conclusion, since this again means . By the memoryless property,
\ifprocs

\else

\fi
\end{proof}

\subsubsection{The Effect of a Sequence of Balls on a Short Segment}
Consider now the first  balls that reach , starting from the beginning of iteration  of the outer loop, and perhaps during several iterations of that loop. For every , let  be the indicator random variable for the event that the -th ball reaching  decreased the number of active subpaths intersecting . In these notations, Proposition~\ref{p:cond} stated that

Let  and let . Simple induction on  implies the following claim.
\begin{claim}
.
\end{claim}
\begin{lemma} \label{l:puncBalls}
With probability at least , after  balls have reached , there are no active subpaths intersecting .
\end{lemma} 
\begin{proof}
Assume .
Since whenever , the number of active subpaths increases by at most , and whenever , the number of active subpaths decreases by at least , if , then there are no active subpaths intersecting . Therefore by the Chernoff bound,

\end{proof}

\subsection{The Behavior of Short Subtrees} \label{subsec:short}
As stated before, the most crucial part of the proof is to bound the weight and height of short subtrees of .
Let , and let  be a short subpath such that  is a short subtree of .
Clearly,  is short for every node  of . 
In order to bound the height of  we combine the fact that not too many balls may reach , with the fact that at least two balls reach  during each iteration of the outer loop. 
\begin{claim}
With probability at least , the height of  is at most .
\end{claim}
\begin{proof}
In the notations of Lemma~\ref{l:puncBalls}, consider some .
If  has an active subpath at the end of the -th iteration of the outer loop, then at least two times during the -th iteration an active subpath of  is reached by a ball. 
After  iterations of the outer loop, if  has an active subpath, then .
By similar arguments to Lemma~\ref{l:puncBalls}, 

\end{proof}
We denote by  the event that for every , and every , if  is a short subtree then after at most  balls reach an active subpath of ,  has no more active subpaths and in addition, the height of  is at most .
\begin{lemma} \label{l:shortReach}
.
\end{lemma}
\begin{proof}
Fix some , and . Assume that  is a short subtree. By definition,  has no short ancestor.
For ,  itself is short, since , and thus all tree nodes in level  (and lower) are short.  Therefore, . Since there are at most  nodes in every level of the tree, the number of short subtrees of  is at most . By the previous lemma, and a union bound over all short subtrees, the result follows.
\end{proof}

Since every node in level  of the tree belongs to some short subtree, we get the following corollary.
\begin{corollary} \label{c:height}
With probability at least , the height of  is at most .
\end{corollary}

We denote by  the event that for all  and , the radius of the -th ball of the -th iteration of the outer loop is at most .
\ifprocs
From assumption~\ref{a:polyLogDelta} we deduce the following.
\else
\fi
We wish to prove that  holds with high probability. We will need the following lemma, which gives a concentration bound on the sum of independent exponential random variables.
\begin{lemma}\label{l:conc}
Let  be independent random variables
such that each  for ,
and denote .
Then  
has expectation  
and satisfies

\end{lemma}
\begin{proof}
We proceed by applying Markov's inequality to the moment generating function
(similarly to proving Chernoff bounds).
Let  and consider .
Then the moment generating function of  is known and can be written as
.
Now set  and use Markov's inequality to get

\end{proof}

\begin{lemma} \label{l:radii}
.
\end{lemma}
\begin{proof}
Fix  and . 
In the notations of Algorithm~\ref{alg:part}, let  be the radius of the th ball in the th iteration of the outer loop. Then  is the sum of independent exponential random variables.
. Applying Lemma~\ref{l:conc} we get that 

By assumption~\ref{a:polyLogDelta}, .
Thus by a union bound over all values of  and  in question, 

\end{proof}

Summing everything up, we can now bound with high probability the weights of all short subtrees of . 
\begin{claim} \label{c:shortWeight}
Conditioned on the events  and , for every  and , if  is a short subtree of , then the total weight charged to nodes of  is at most  with certainty.
\end{claim}
\begin{proof}
Conditioned on , at most  detours are charged to nodes of every short subtree and for , there are no more active subpaths of . Conditioned on , the most expensive detour is of weight at most , we get that the total weight charged to nodes of the subtree is , since . \end{proof}
\subsection{Bounding The Weight Of }
We are now ready to bound the total weight charged to the tree. 
Recall that for every  we denoted by  the total weight charged to nodes of the form , where  is a long active subpath, and by  the total weight charged to short subtrees rooted in the -th level of . 
Since ,  is long. Therefore, . We can therefore rearrange Eqn.~\eqref{eq:treeWeight} to get the following.


Let .
Let  be a long active subpath. That is, .
Thinking of  as a continuous path, divide  into  segments of length . Some segments may contain no nodes.
Let  be a segment of , and assume  contains nodes (otherwise, no cost is charged to  on account of detours from ). Following Lemma~\ref{l:puncBalls}, we get the following.
\begin{lemma}
With probability at least , no more than  balls reach .
\end{lemma}
Denote by  the event that for every , and for every long active subpath , in the division of  to segments of length , every such subsegment is reached by at most  balls.
\begin{lemma}
.
\end{lemma}
\begin{proof}
Since for every , every  is short, the number of relevant iterations (of the outer loop) is at most .
For every  and every long path , the number of segments of  is at most 
.
Therefore the number of relevant segments for all  and for all long  is at most 
Applying a union bound over all relevant segments the result follows.
\end{proof}
Since  and , we get the following corollary.
\begin{corollary}

\end{corollary}
It follows that it is enough for us to prove that conditioned on ,  and , with probability  the total weight charged to the tree is at most .
\begin{lemma} \label{l:long}
Conditioned on  and , . In addition, if , 
then  with probability .
\end{lemma}
\begin{proof}
To see the first bound, observe that by the update process of , at most  detours are added to  during the -th iteration. Conditioned on , each one of them is of weight at most .
To see the second bound, let  be a long active subpath.
The additional weight resulting from detours from vertices of  is at most the number of segments of  of length , times the additional weight to each segment. Therefore, the additional weight is at most 

Since all paths in  are internally disjoint subpaths of , we get:

\end{proof}

\begin{lemma}\label{l:short}
Conditioned on events ,  and , .  In addition, if , then .
\end{lemma}
\begin{proof}
Conditioned on  and , we proved in Claim~\ref{c:shortWeight} that the total weight charged to a short subtree rooted in level  is at most  with certainty. Since there are at most  such subtrees, the first bound follows.
To get the second bound, note that by the definition of a short subtree, for every short subtree  rooted at level , the parent of the root of  consists of a long active subpath  of level . Conditioned on , every segment of  is intersected by at most  balls. Therefore,  can have at most  children, and in particular, children consisting of short active subpaths. The cost of a short subtree rooted in the  level of  is at most . Thus the total cost of all short subtrees rooted in children of  is bounded by 

Summing over all (internally disjoint) long subpaths of level , the result follows.
\end{proof}
We now turn to prove Lemma~\ref{l:totalWeight}.
\begin{proof}[\proofof{Lemma~\ref{l:totalWeight}}]
Since , it is enough to show that conditioned on {\bf E1}, {\bf E2} and {\bf E3}, the total weight charged to the tree is at most  with certainty.
Recall that . Following Lemmas~\ref{l:long} and \ref{l:short} we get that
\ifprocs

\else

\fi
In addition,
\ifprocs

\else

\fi
\end{proof}


\section{Terminal-Centered Minors: Extension to General Case}\label{sec:proofDiscard}

In this section we complete the proof of Theorem~\ref{thm:main} by reducing it to the special case where Assumption~\ref{a:polyLogDelta} holds (which we proved in Section~\ref{sec:TCM}).
We first outline the reduction, which is implemented using a recursive algorithm,
as follows. 
The algorithm initially rescales edge weights of the graph so that minimal terminal distance is . If  then we apply Algorithm~\ref{alg:part} and we are done. Otherwise, we construct a set of at most  low-diameter balls which are mutually far apart, and whose union contains all terminals. Then, for each of the balls, we apply Algorithm~\ref{alg:part} on the graph induced by that ball. 
Each ball is then contracted into a ``super-terminal". We apply the algorithm recursively on the resulting graph  with the set of super-terminals as the terminal set. Going back from the recursion, we ``stitch" together the output of Algorithm~\ref{alg:part} on the balls in the original graph with the output of the recursive call on , to construct a partition of  as required.
The detailed algorithm and proof of correctness  
\ifprocs
appear in the full version \cite{KKN13}.
\else
are described in Section~\ref{sec:general-alg}. Before that, we need a few definitions.

Assume that the edge weights are already so that the minimum inter-terminal distance is 1. Denote by  the set of all distances between terminals, rounded down to the nearest powers of . Note that . Consider the case . There must exist  such that .
Define . 
\begin{claim} \label{c:equivR}
 is an equivalence relation.
\end{claim}
\begin{proof}
Reflexivity and symmetry of  follow directly from the definition of a metric. To see that  is transitive, let , and assume . Therefore  and . By the triangle inequality, . Since , , and therefore .
\end{proof}
For every equivalence class , we pick an arbitrary , and define .
\begin{claim}\label{c:sepBalls}
 is a partial partition of . Moreover, for every , ,  is connected and of diameter at most .
\end{claim}
\begin{proof}
Let . Let  be such that . For every , by the definition of , , and thus . Therefore . By the definition of a ball,  is connected and of diameter at most .
To see that  is a partial partition of , take  such that , and let  be such that . Since , , and since 
, , thus .
\end{proof}


\subsection{Detailed Algorithm}\label{sec:general-alg}

\begin{algorithm}[t]
\caption{Partitioning  - The General Case}
\label{alg:gen}
\begin{algorithmic}[1]
\REQUIRE 
\ENSURE A partition  of .
\STATE rescale the edge weights so that the minimal terminal distance is .
\IF {}
\STATE run Algorithm~\ref{alg:part}, and return its output.
\ELSE
\STATE define  and  as above.
\FORALL{}
\STATE run Algorithm~\ref{alg:part} independently on .
\STATE contract  to a single ``super-terminal'', maintaining edge weights of all remaining edges. \label{al:super}
\ENDFOR
\STATE denote the resulting graph . \STATE run Algorithm~\ref{alg:gen} recursively on  with the set of super-terminals.
\FORALL {super-terminals }
\STATE let  be the terminals contracted to  in line~\ref{al:super} in an arbitrary order.
\FORALL {vertices  assigned to  in the recursive call}
\STATE assign  to its nearest terminal among . \\
Break ties by the ordering of . \COMMENT{Making sure we construct a minor.}
\ENDFOR
\ENDFOR
\ENDIF
\RETURN the resulting partition of .
\end{algorithmic}
\end{algorithm}

Our algorithm for the general case of Theorem~\ref{thm:main} is given 
as Algorithm~\ref{alg:gen} (which makes calls to Algorithm~\ref{alg:part}).
It is clear that this algorithm returns a partition of . 
In addition, since every level of recursion decreases the number of terminals in the graph, the depth of the recursion is at most . During each level of the recursion, Algorithm~\ref{alg:part} is invoked at most  times. Therefore, Algorithm~\ref{alg:part} is invoked at most  times, each time on a set of at most  terminals. Note that the result of Lemma~\ref{l:totalWeight} still applies if  is only an upper bound on the number of terminals, and not the exact number of terminals. Therefore, we get that there exists , such that all  times that the algorithm is invoked, it achieves a weight stretch factor of at most , with probability at least . Applying a union bound, we get that with high probability, the stretch bound is obtained in all invocations of the algorithm. It remains to show that this suffices to achieve the desired stretch factor in . 
\begin{lemma} \label{l:discard}
With probability at least , on a graph with  terminals, 
Algorithm \ref{alg:gen} obtains a stretch factor of at most .
\end{lemma}

\begin{proof}
It is enough to show that conditioned on the event that every invocation of Algorithm~\ref{alg:part} achieves a stretch factor of at most , the generalized algorithm achieves the desired stretch factor.
We prove this by induction on . For the case , rescaling the weights assures that , and therefore Algorithm~\ref{alg:part} is applied on . The result follows from the proof of Section~\ref{sec:TCM}. Assuming correctness for every , we prove correctness for . 
Let . If , then  and  are in the same set in , and by the conditioning, the stretch factor of the distance between  and  is at most . This does not change in steps  of the algorithm.
Otherwise, Let  be the terminals (or super-terminals) associated with  and  in  respectively.
Denote  and . Denote by  the terminal-centered minor induced by the partition returned by the recursive call, and by  the terminal-centered minor induced by the partition returned in the final step of the algorithm. 
Denote . and .
Let  be a super terminal on a shortest path  between  and  in .
Let  be the path obtained from  in  in the following manner. In the place of every super-terminal  in , originating in some node set , we add a path between the corresponding terminals in  (based on the terminal-centered minor constructed for  in step ). The edges of  are also replaced with corresponding edges in .

Recall that in , the weight of every edge is the distance between its endpoints in  (by the definition of a terminal-centered minor). In  the weight of every edge is the distance between its endpoints in . Therefore the weight 
 contained at most  edges. In  the weight of each such edge increases by at most . In addition, every expansion of a super-terminal adds at most  to the path. Therefore, .
By the induction hypothesis  
Since , we get that 
\ifprocs
 is at most

\else

\fi
This completes the proof of Lemma~\ref{l:discard}
(and in fact also of Theorem~\ref{thm:main}).
\end{proof}
\fi

\paragraph{Acknowledgments.}
We thank the anonymous reviewers for useful comments, 
and particularly for suggesting to improve the proof of Lemma~\ref{l:radii}
using a tail bound for sum of exponential random variables, 
which saves a factor of  in our main result, Theorem~\ref{thm:main}.


\bibliographystyle{alphaurlinit}
\bibliography{robi}
\end{document}