\documentclass[10pt,twocolumn]{article}
\usepackage[hidelinks,bookmarks=false]{hyperref}
\usepackage[T1]{fontenc}
\usepackage{amsthm}
\usepackage{framed}
\usepackage{fullpage}
\usepackage{breakurl}
\usepackage[hang,flushmargin]{footmisc}
\usepackage{cite}
\usepackage{color}
\usepackage{paralist}
\usepackage{amssymb,amsmath}
\usepackage{epsfig}
\usepackage{url}
\usepackage{xspace}
\usepackage{subfig}
\usepackage[notcomma,notperiod,notquote,notcolon,notexcl,notquery,notscolon]{hanging}
\usepackage{mathptmx}

\DeclareMathAlphabet{\mathcal}{OMS}{cmsy}{m}{n}








\setlength{\belowcaptionskip}{-8pt}

\long\def\abbr#1#2{#2}     

\newtheorem{defn}{Definition}


\newcommand\blfootnote[1]{\begingroup
  \renewcommand\thefootnote{}\footnote{#1}\addtocounter{footnote}{-1}\endgroup
}

\def\widowpage{\pagebreak}

\newcommand{\CRH}{\textsf{CRH}}
\newcommand{\D}{\mathcal{D}}
\newcommand{\E}{\textrm{E}}
\newcommand{\Z}{\mathbb{Z}}
\newcommand{\F}{\mathbb{F}}
\newcommand{\Seed}{\mathbb{S}}
\newcommand{\G}{\mathbb{G}}
\newcommand{\HH}{\mathcal{H}}
\newcommand{\rgets}{\mathrel{\mathpalette\rgetscmd\relax}}
\newcommand{\rgetscmd}{\ooalign{\cr
        \hidewidth\raisebox{1.2\height}{\scalebox{0.5}{\ \rm R}}\hidewidth\cr}}
\newcommand{\Adv}{\mathcal{A}}
\newcommand{\hbet}{\hat{\beta}}
\newcommand{\hsA}{\hat{\sigma}_A}
\newcommand{\hsB}{\hat{\sigma}_B}
\newcommand{\lbits}{\{0,1\}^\lambda}
\newcommand{\mA}{{\bf m}_A}
\newcommand{\hmA}{\hat{{\bf m}}_A}
\newcommand{\hcA}{\hat{c}_A}
\newcommand{\hcB}{\hat{c}_B}
\newcommand{\mB}{{\bf m}_B}
\newcommand{\hmB}{\hat{{\bf m}}_B}
\newcommand{\hvA}{\hat{{\bf v}}_A}
\newcommand{\vA}{{\bf v}_A}
\newcommand{\hvB}{\hat{{\bf v}}_B}
\newcommand{\vB}{{\bf v}_B}
\newcommand{\hbeta}{\hat{beta}}
\newcommand{\MM}{\mathcal{M}}
\newcommand{\state}{\textsf{state}}
\newcommand{\Gen}{\ensuremath{\mathsf{Gen}}\xspace}
\newcommand{\Eval}{\ensuremath{\mathsf{Eval}}\xspace}
\newcommand{\nicepara}[1]{\medskip\noindent\textbf{#1.}}

\newcommand{\name}{Riposte\xspace}
\newcommand{\Name}{Riposte\xspace}

\title{\Large \bf \Name: An Anonymous Messaging System\\Handling Millions of Users}
\author{Henry Corrigan-Gibbs, Dan Boneh, and David Mazi\`eres\\
Stanford University}
\date{\today}
\begin{document}

\maketitle

\begin{abstract}
This paper presents \name, a new system for anonymous
broadcast messaging.
\Name is the first such system, to our knowledge, that
simultaneously protects against traffic-analysis attacks,
prevents anonymous denial-of-service by malicious clients,
and scales to million-user anonymity sets.
To achieve these properties, \name makes novel use
of techniques used in systems for private information retrieval and
secure multi-party computation. 
For latency-tolerant workloads with many more readers than writers 
(e.g.~Twitter, Wikileaks), we demonstrate that
a three-server \name cluster can build an anonymity set of 2,895,216 users
in 32 hours.
\end{abstract}

\blfootnote{{\color{blue} \textbf{Note:}} 
This is the extended and corrected
version of a paper by the same name that appeared at the
{\em IEEE Symposium on Security and Privacy}
in May 2015. This version corrects an error in the 
 protocol of Section~\ref{sec:disrupt:smc}
that could allow a malicious database server to de-anonymize
a client using an active attack.
We thank Elette Boyle and Yuval Ishai for pointing out this
error and for helpful discussions on how to correct it.
Since the complexity of the updated protocol is almost identical
to the original one, and since the first author's 
dissertation~\cite{thesis} describes and evaluates
a DPF-checking protocol that improves upon the one
presented here, the evaluation section (Section~\ref{sec:eval}) 
of this paper reflects the DPF-checking protocol from
the original version of this work.
}

 
\section{Introduction}

In a world of ubiquitous network 
surveillance~\cite{bennhold2014britain,gellman2013nsa,
gellman2014nsa,goel2014government,nakashima2014court}, 
prospective whistleblowers face a daunting task.
Consider, for example, a government employee who wants to anonymously 
leak evidence of waste, fraud, or incompetence to the public.
The whistleblower could email an investigative reporter directly, but {\em post hoc} 
analysis of email server logs could easily reveal the tipster's identity.
The whistleblower could contact a reporter via 
Tor~\cite{dingledine2004tor} or another
low-latency anonymizing proxy~\cite{freedman2002tarzan,leblond2013towards,mittal2009shadowwalker,reiter1998crowds}, 
but this would leave the leaker vulnerable to traffic-analysis attacks~\cite{bauer2007low,murdoch2005low,murdoch2007sampled}.
The whistleblower could instead use an anonymous messaging system that protects
against traffic analysis attacks~\cite{chaum1988dining,goel2003herbivore,wolinsky2012dissent}, 
but these systems typically only support
relatively small anonymity sets (tens of thousands of users, at most).
Protecting whistleblowers in the digital age requires 
anonymous messaging systems that provide strong security guarantees,
but that also scale to very large network sizes.

In this paper, we present a new system that attempts to make
traffic-analysis-resistant anonymous broadcast 
messaging practical at Internet scale.
Our system, called \name, allows a large number of clients 
to anonymously post messages to a
shared ``bulletin board,'' maintained by a small set of 
minimally trusted servers. 
(As few as three non-colluding servers are sufficient).
Whistleblowers could use \name as a platform for anonymously publishing Tweet-
or email-length messages and could combine it with standard
public-key encryption to build point-to-point private messaging channels.

While there is an extensive literature on anonymity 
systems~\cite{danezis2008survey,edman2009anonymity},
\name offers a combination of 
security and scalability properties unachievable with
current designs.
To the best of our knowledge, \name is the only anonymous
messaging system that simultaneously:
\begin{compactenum}
\item protects against traffic analysis attacks,
\item prevents malicious clients from anonymously executing 
      denial-of-service attacks, and 
\item scales to anonymity set sizes of 
      {\em millions} of users,
      for certain latency-tolerant applications.
\end{compactenum}
We achieve these three properties in \name 
by adapting three different techniques from the 
cryptography and privacy literature.
First, we defeat traffic-analysis attacks 
and protect against malicious servers by 
using a protocol, inspired by client/server 
DC-nets~\cite{chaum1988dining,wolinsky2012dissent},
in which every participating client sends a fixed-length
secret-shared message to the system's servers in every time epoch.
Second, we achieve efficient disruption resistance
by using a secure multi-party protocol 
to quickly detect and exclude malformed 
client requests~\cite{fagin1996comparing,goldreich1987play,yao1982protocols}.
Third, we achieve scalability
by leveraging a specific technique developed in the context of private information retrieval (PIR) to 
minimize the number of bits each client must upload to
each server in every time epoch.  The tool we use is called
a {\em distributed point function}~\cite{chor1997computationally,gilboa2014distributed}.
The novel synthesis of these techniques leads to a
system that is efficient (in terms of bandwidth and 
computation) and practical, even for large anonymity sets.

Our particular use 
of private information retrieval (PIR) protocols is unusual:
PIR systems~\cite{chor1998private}  allow a client to efficiently read a row from a database,
maintained collectively at a set of servers, without
revealing to the servers which row it is reading.
\Name achieves scalable anonymous messaging by running
a private information retrieval protocol {\em in reverse}:
with reverse PIR, a \name client can efficiently {\em write} into a database
maintained at the set of servers without revealing to 
the servers which row it has written~\cite{ostrovsky1997private}.

As we discuss later on, a large \name deployment 
could form the basis for an anonymous Twitter service.
Users would ``tweet'' by using \name to anonymously 
write into a database containing all clients' tweets for
a particular time period.
In addition, by having read-only users submit ``empty''
writes to the system, the effective anonymity set can
be much larger than the number of writers, with little impact
on system performance. 


\medskip

Messaging in \name proceeds in regular {\em time epochs}
(e.g., each time epoch could be one hour long).
To post a message, the client generates 
a {\em write request}, cryptographically splits it into many
shares, and sends one share to each of the \name servers.
A coalition of servers smaller than a certain threshold cannot
learn anything about the client's message or write location given
its subset of the shares.

The \name servers collect write requests until the end of the time epoch,
at which time they publish the aggregation of the write requests they received
during the epoch.
From this information, anyone can recover the set of posts uploaded during
the epoch, but the system reveals no information about who posted which message.  
The identity of the entire set of clients who
posted during the interval is known, but no one can link a client to a post.
(Thus, each time epoch must be long enough to ensure that a large
number of honest clients are able to participate in each epoch.)

\begin{figure*}
  \centering
  \subfloat[A client submits one share of its write 
      request to each of the two database servers.
      If the database has length , each share has
      length .]{\includegraphics[height=0.14\textwidth]{figs/arch-0.eps}}
  \quad
  \subfloat[The database servers generate blinded ``audit request'' messages derived
      from their shares of the write request.]{\includegraphics[height=0.14\textwidth]{figs/arch-1.eps}}
  \quad
  \subfloat[The audit server uses the audit request messages to validate the 
      client's request and returns an
      ``OK'' or ``Invalid'' bit to the database servers.]{\includegraphics[height=0.14\textwidth]{figs/arch-2.eps}}
  \quad
  \subfloat[The servers apply the write request to their local database state.
    The XOR of the servers' states contains the clients message at the given row.]{\includegraphics[height=0.14\textwidth]{figs/arch-3.eps}}

    \caption{The process of handling a single client write request. 
        The servers run this process once per client in each time epoch.}
    \label{fig:arch}
\end{figure*}

In this paper, we describe two \name variants, which
offer slightly different security properties.
The first variant scales to very large network
sizes (millions of clients) but
requires three servers such that no two of these servers collude.
The second variant is more computationally expensive, 
but provides security
even when all but one of the  servers are malicious.
Both variants maintain their security properties
when network links are actively adversarial, when 
all but two of the clients are actively malicious, and
when the servers are actively malicious 
(subject to the non-collusion requirement above).

The three-server variant uses a computationally inexpensive
multi-party protocol to detect and exclude malformed client
requests. (Figure~\ref{fig:arch} depicts this
protocol at a high-level.)
The -server variant uses client-produced
zero-knowledge proofs to guarantee the well-formedness of 
client requests.

Unlike Tor~\cite{dingledine2004tor} and
other low-latency anonymity systems~\cite{goel2003herbivore,
  hsiao2012lap,
  leblond2013towards,
  reiter1998crowds},
\name protects against active traffic analysis attacks
by a global network adversary.
Prior systems have offered traffic-analysis-resistance 
only at the cost of scalability:
\begin{compactitem}
\item
Mix-net-based systems~\cite{chaum1981untraceable} require
large zero-knowledge proofs of correctness to provide privacy in
the face of active attacks by malicious servers~\cite{adida2007shuffle,bayer2012efficient,furukawa2004efficient,groth2010verifiable,neff2001verifiable}.
\item
DC-nets-based systems require clients to transfer data {\em linear} in the size
of the anonymity set~\cite{chaum1988dining,wolinsky2012dissent}
and rely on expensive zero-knowledge proofs
to protect against malicious clients~\cite{corrigangibbs2013proactively,golle2004dining}.
\end{compactitem}
We discuss these systems and other prior work in Section~\ref{sec:rel}.

\nicepara{Experiments}
To demonstrate the practicality of \name for 
anonymous broadcast messaging 
(i.e., anonymous whistleblowing or microblogging), we
implemented and evaluated the complete three-server variant of the system.
When the servers maintain a database table large enough to fit
65,536 160-byte Tweets, the system can process 32.8 client write
requests per second.
In Section~\ref{sec:eval:million}, we discuss how to use a table of this
size as the basis for very large anonymity 
sets in read-heavy applications.
When using a larger 377 MB database table (over 2.3 million 160-byte Tweets),
a \name cluster can process 1.4 client write requests per second.

Writing into a 377 MB table requires
each client to upload less than 1 MB of data to the servers.
In contrast, a two-server DC-net-based system would 
require each client to upload more than 750 MB of data.
More generally, to process a \name client request for a table of size ,
clients and servers perform only  bytes of data transfer.

The servers' AES-NI encryption throughput limits the 
rate at which \name can process client requests at large table sizes.
Thus, the system's capacity to handle client write request scales
with the number of available CPU cores.
A large \name deployment could shard the database table across
 machines to achieve a near--fold speedup.

We tested the system with anonymity set sizes of up to
2,895,216 clients, with a read-heavy latency-tolerant
microblogging workload.
To our knowledge, this is the largest anonymity set 
{\em ever constructed} in a system defending against 
traffic analysis attacks.
Prior DC-net-based systems scaled to 5,120 clients~\cite{wolinsky2012dissent}
and prior verifiable-shuffle-based systems 
scaled to 100,000 clients~\cite{bayer2012efficient}.
In contrast, \name scales to millions of clients for
certain applications.


\nicepara{Contributions}
This paper contributes:
\begin{compactitem}
  \item two new bandwidth-efficient and traffic-analysis-resistant 
        anonymous messaging protocols, 
        obtained by running private information retrieval 
        protocols ``in reverse'' (Sections~\ref{sec:arch} and~\ref{sec:dpf}),
  \item a fast method for excluding
        malformed client requests 
        (Section~\ref{sec:disrupt}), 
  \item a method to recover from transmission 
        collisions in DC-net-style anonymity systems, 
  \item experimental evaluation of these protocols with anonymity 
        set sizes of up to 2,895,216 users (Section~\ref{sec:eval}).
\end{compactitem}

\medskip
In Section~\ref{sec:goal}, we introduce our goals,
threat model, and security definitions.
Section~\ref{sec:arch} presents the high-level system
architecture. 
Section~\ref{sec:dpf} and Section~\ref{sec:disrupt}
detail our techniques for achieving bandwidth efficiency 
and disruption resistance in \name.
We evaluate the performance of the system in Section~\ref{sec:eval},
survey related work in Section~\ref{sec:rel}, and conclude
in Section~\ref{sec:concl}.

 \section{Goals and Problem Statement}
\label{sec:goal}

In this section, we summarize the high-level goals of the \name system and
present our threat model and security definitions.

\subsection{System Goals}

\Name implements an anonymous bulletin board using a
primitive we call a \textit{write-private database scheme}.
\Name enables clients to write into a shared
database, collectively maintained at a small set of servers,
without revealing to the servers the location or contents of the write.
Conceptually, the database table 
is just a long fixed-length bitstring divided into fixed-length rows. 

To write into the database, a client generates a {\em write request}. 
The write request encodes the message to be written
and the row index at which the client wants to write.
(A single client write request modifies a single 
database row at a time.)
Using cryptographic techniques, the client splits its write request
into a number of shares and the client sends 
one share to each of the servers.
By construction of the shares, no coalition of servers
smaller than a particular pre-specified threshold 
can learn the contents of a single client's write request.
While the cluster of servers must remain online for the duration 
of a protocol run, a client need only stay online for long enough to 
upload its write request to the servers.
As soon as the servers receive a write request, they
can apply it to to their local state. 

The \name cluster divides time into a series of epochs.
During each time epoch, servers collect many write requests from clients.
When the servers agree that the epoch has ended, they
combine their shares of the database to reveal the clients' plaintext messages.
A particular client's anonymity set consists of all of the honest clients
who submitted write requests to the servers during the time epoch.  
Thus, if 50,000 distinct honest clients submitted write requests
during a particular time epoch, each honest client is perfectly anonymous
amongst this set of 50,000 clients.

The epoch could be measured in time (e.g., 4 hours), in
a number of write requests (e.g., accumulate 10,000 write
requests before ending the epoch), or by
some more complicated condition
(e.g., wait for a write request signed from each of these
150 users identified by a pre-defined list of public keys).
The definition of what constitutes an epoch is crucial for security,
since a client's anonymity set is only as large as the number of
honest clients who submit write requests in the 
same epoch~\cite{serjantov2003trickle}.

When using \name as a platform for anonymous microblogging, the rows
would be long enough to fit a Tweet (140 bytes) and the number of rows would be
some multiple of the number of anticipated users.
To anonymously Tweet, a client would use the write-private database scheme to 
write its message into a random row of the database.
After many clients have written to the database, the servers can
reveal the clients' plaintext Tweets.
The write-privacy of the database scheme prevents eavesdroppers, malicious clients, 
and coalitions of malicious servers (smaller than a particular threshold) from
learning which client posted which message.

\subsection{Threat Model}
\label{sec:goal:threat}

Clients in our system are {\em completely untrusted}: they
may submit maliciously formed write requests to the system
and may collude with servers or with arbitrarily many other
clients to try to break the security properties of the system.

Servers in our system are trusted for availability. 
The failure---whether malicious or benign---of any one server 
renders the database state unrecoverable but {\em does not}
compromise the anonymity of the clients.
To protect against benign failures, server maintainers could
implement a single ``logical'' \name server with a cluster
of many physical servers running a
standard state-machine-replication 
protocol~\cite{liskov2012viewstamped,ongaro2014search}.

For each of the cryptographic instantiations of \name, there is a
threshold parameter  that defines the number of malicious servers
that the system can tolerate while still maintaining its security
properties.  We make no assumptions about the behavior of malicious
servers---they can misbehave 
by publishing their secret keys, 
by colluding with coalitions of up
to  malicious servers and arbitrarily many clients, 
or by mounting any other sort of attack against the system.

The threshold  depends on the particular 
cryptographic primitives in use.
For our most secure scheme, {\em all but one} of the servers can
collude without compromising client privacy ().
For our most efficient scheme, {\em no two} servers can collude ().

\subsection{Security Goals}

The \name system implements a {\em write-private} and {\em disruption-resistant} 
database scheme. We describe the correctness and security properties for such 
a scheme here.

\begin{defn}[Correctness]
The scheme is {\em correct} if,
when all servers execute the protocol
faithfully, the plaintext state of the database revealed
at the end of a protocol run
is equal to the result of applying
each valid client write requests to an empty database
(i.e., a database of all zeros).
\end{defn}

Since we rely on all servers for availability,
correctness need only hold when all servers 
run the protocol correctly.

\medskip

To be useful as an anonymous bulletin board, the database
scheme must be {\em write-private} and {\em disruption resistant}.
We define these security properties here.

\nicepara{-Write Privacy}
Intuitively, the system provides -{\em write-privacy} if an 
adversary's advantage at guessing which honest
client wrote into a particular row of the database
is negligibly better than random guessing, even 
when the adversary controls all but two clients
and up to  out of  servers 
(where  is a parameter of the scheme).
We define this property in terms of a {\em privacy game},
given in full in Appendix~\ref{app:game}.

\begin{defn}[-Write Privacy]
We say that the protocol provides -{\em write privacy} if the adversary's advantage
in the security game of Appendix~\ref{app:game}
is negligible in the (implicit) security parameter.
\end{defn}

\Name provides a very robust sort of privacy:
the adversary can select the messages that the honest clients will send and
can send maliciously formed messages that depend on the honest clients' messages.
Even then, the adversary still cannot guess which client uploaded which message.



\nicepara{Disruption resistance}
The system is {\em disruption resistant}
if an adversary who controls  clients
can write into at most  database rows during
a single time epoch.
A system that lacks disruption resistance might
be susceptible to denial-of-service attacks:
a malicious client could corrupt every row in the database
with a single write request.
Even worse, the write privacy of the system might prevent
the servers from learning which client was the disruptor.
Preventing such attacks is a major focus of prior
anonymous messaging schemes~\cite{chaum1988dining,goel2003herbivore,golle2004dining,waidner1989dining,wolinsky2012dissent}.
Under our threat model, we trust all servers for
availability of the system (though not for privacy).
Thus, our definition of disruption resistance concerns
itself only with clients attempting to disrupt the
system---we {\em do not} try to prevent servers
from corrupting the database state.
 

We formally define {\em disruption resistance} using
the following game, played between a challenger
and an adversary.
In this game, the challenger plays the role of
all of the servers and the adversary plays the 
role of all clients.
\begin{enumerate}
  \item The adversary sends  write requests
    to the challenger
    (where  is less than or equal to the number of 
    rows in the database).
  \item The challenger runs the protocol for
    a single time epoch, playing the role of the servers.
    The challenger then combines the servers' database
    shares to reveal the plaintext output.
\end{enumerate}

The adversary wins the game if the plaintext
output contains more than  non-zero rows. 

\begin{defn}[Disruption Resistance]
We say that the protocol is {\em disruption resistant}
if the probability that the adversary wins the game
above is negligible in the (implicit) security parameter.
\end{defn}

\subsection{Intersection Attacks}

\Name makes it infeasible for an adversary to determine
which client posted which message {\em within} a particular time epoch.
If an adversary can observe traffic patterns {\em across} many
epochs, as the set of online clients changes, the adversary can
make statistical inferences about which client is sending 
which stream of 
messages~\cite{danezis2004statistical,kedogan2003limits,mathewson2005practical}.
These ``intersection'' or ``statistical disclosure'' attacks
affect many anonymity systems and defending against them is an important,
albeit orthogonal, problem~\cite{mathewson2005practical,wolinsky2013hang}.
Even so, intersection attacks typically become more difficult to
mount as the size of the anonymity set increases, so \name's support for
very large anonymity sets makes it less vulnerable to these attacks than 
are many prior systems. 


 \section{System Architecture}
\label{sec:arch}

As described in the prior section,
a \name deployment consists of a small number
of servers, who maintain the database state, 
and a large number of clients.
To write into the database, a client
splits its write request using secret sharing
techniques and sends a single share to each of
the servers.
Each server updates its database state using
the client's share.
After collecting write requests from many
clients, the servers
combine their shares to reveal the plaintexts
represented by the write requests.
The security requirement is that 
no coalition of  servers can learn which client
wrote into which row of the database.

\subsection{A First-Attempt Construction:\\Toy Protocol}
\label{sec:arch:straw}

As a starting point, we sketch a simple ``straw man''
construction that demonstrates the techniques
behind our scheme.
This first-attempt protocol shares some design features
with anonymous communication schemes based on 
client/server DC-nets~\cite{chaum1988dining,wolinsky2012dissent}.

In the simple scheme, we have two servers,  and ,
and each server stores an -bit bitstring, initialized to all zeros.
We assume for now that the servers {\em do not collude}---i.e.,
that one of the two servers is honest.
The bitstrings represent shares of the database state
and each ``row'' of the database is a single bit.

Consider a client who wants to write a ``1'' into 
row  of the database.
To do so, the client generates a random -bit bitstring .
The client sends  to server  and  to server ,
where  is an -bit vector of zeros with a one at index~
and  denotes bitwise XOR.
Upon receiving the write request from the client, each server XORs
the received string into its share of the database.

After processing  write requests, the database state at
server  will be:

and the database at server  will be:

At the end of the time epoch, the servers can reveal the plaintext
database by combining their local states ~and~.

The construction generalizes to fields larger than .
For example, each ``row'' of the database could be a -bit bitstring
instead of a single bit.
To prevent impersonation, network-tampering, and replay attacks, we 
use authenticated and encrypted channels with per-message nonces
bound to the time epoch identifier. 

\medskip

This protocol satisfies the write-privacy property
as long as the two servers do not collude (assuming that the clients
and servers deploy the replay attack defenses mentioned above).
Indeed, server  can information theoretically simulate its view 
of a run of the protocol given only  as input.
A similar argument shows that the protocol is write-private with
respect to server  as well.

This first-attempt protocol has two major limitations.
The first limitation is that it is not bandwidth-efficient.
If millions of clients want to use the system in each time epoch, then 
the database must be at least millions of bits in length.
To flip a {\em single bit} in the database then, each client
must send {\em millions of bits} to each database,
in the form of a write request.

The second limitation is that it is not disruption resistant:
a malicious client can corrupt
the entire database with a single malformed request.
To do so, the malicious client picks random -bit bitstrings
 and , sends  to server , and sends  
(instead of ) to server .
Thus, a single malicious client can efficiently
and anonymously deny service to all honest clients.

Improving bandwidth efficiency and adding
disruption resistance are the two core contributions
of this work, and we return to them in Sections~\ref{sec:dpf}
and~\ref{sec:disrupt}.


\subsection{Collisions} \label{sec:collisions}
Putting aside the issues of bandwidth efficiency and
disruption resistance for the moment, we now discuss
the issue of {\em colliding writes} to the shared database.
If clients write into random locations in the database,
there is some chance that one client's write request
will overwrite a previous client's message.
If client A writes message  into location ,
client B might later write message  into the
same location .
In this case, row  will contain , 
and the contents of row  will be unrecoverable.

To address this issue,
we set the size of the database table to 
be large enough to accommodate the expected number 
of write requests for a given ``success rate.''
For example, the servers can choose a table size
that is large enough to accommodate  write requests
such that  of write requests
will not be involved in a collision (in expectation).
Under these parameters,  of the write
requests will fail and those clients will have to
resubmit their write requests in a future time epoch.

We can determine the appropriate table size by solving
a simple ``balls and bins'' problem.
If we throw  balls independently and uniformly at
random into  bins, how many bins contain exactly one ball?
Here, the  balls represent the write requests
and the  bins represent the rows of the database.

Let  be the probability that ball 
falls into bin~. For all  and , .
Let  be the event that {\em exactly} one ball falls
into bin~.  Then

Expanding using the binomial theorem and ignoring low order terms
we obtain 

where the approximation ignores terms of order  and .
Then  is the expected number of bins
with exactly one ball which is the expected number of messages 
successfully received.  
Dividing this quantity by  gives the expected success rate so that:

So, if we want an expected success rate of  then we need
.  For example, with  writers,
we would use a table of size . 



\nicepara{Handling collisions}  We can shrink the table
size  by coding the writes so that we can recover from collisions.
We show how to handle two-way collisions. 
That is, when at most two
clients write to the same location in the database.  Let us assume
that the messages being written to the database are elements in some
field  of odd characteristic (say  where ).
We replace the XOR operation used in the basic scheme
by addition in .   

To recover from a two-way collision we will need to double the size of
each cell in the database, but the overall number of cells  will
shrink by more than a factor of two.

When a client  wants to write the message
 to location~ in the database the client will
actually write the pair  into that location.  
Clearly if no
collision occurs at location  then recovering  at the end
of the epoch is trivial: simply drop the second coordinate (it is easy
to test that no collision occurred because the second coordinate is a
square of the first).  Now, suppose a collision occurs with some
client  who also added her own message  to
the same location~ (and no other client writes to location
).  Then at the end of the epoch the published values are

From these values it is quite easy to recover both  and 
by observing that

from which we obtain  by taking a square root modulo  (it does not
matter which of the two square roots we use---they both lead to the
same result).  Since  is also given it is now easy to
recover both  and .

Now that we can recover from two-way collisions we can shrink the
number of cells  in the table.  Let  be the event that 
exactly two balls fell into bin~.  Then the expected number
of received messages is

where .
As before, dividing the expected number of received messages (\ref{eq:exp}) 
by , expanding using the binomial theorem, and ignoring low order terms
gives the expected success rate as:

So, if we want an expected success rate of  
we need a table with  cells.  
This is a far smaller table than before, when we could not handle 
collisions.  In that case we needed  which results
in much bigger tables, despite each cell being half as big.
Shrinking the table reduces the storage
and computational burden on the servers.

\medskip
This two-way collision handling technique generalizes to handle
-way collisions for .
To handle -way collisions, we increase the size of each cell by a
factor of  and have each client  write  to its chosen cell.  A -collision gives 
equations in  variables that can be efficiently solved to recover
all  messages, as long as the characteristic of  is greater
than ~\cite{bos1989detection,chien1966application}.
Using  further reduces the table size as the
desired success rate approaches one.

The collision handling method described in this section will also
improve performance of our full system, which we describe in the next section.


\nicepara{Adversarial collisions} The analysis above assumes that
clients behave honestly.  Adversarial clients, however,
need not write into random rows of the database---i.e.,
all  balls might not be thrown independently and uniformly at
random.  A coalition of clients might, for example, try to increase the
probability of collisions by writing into the database using some
malicious strategy.

By symmetry of writes we can assume that all  adversarial
clients write to the database before the honest clients do.  
Now a message from an honest client is properly received at the end of an
epoch if it avoids all the cells filled by the malicious
clients.  We can therefore carry out the honest client analysis above
assuming the database contain  cells instead of  cells.
In other words, given a bound  on the number of malicious
clients we can calculate the required table size .  In practice, if
too many collisions are detected at the end of an epoch the servers can
adaptively double the size of the table so that the next epoch has
fewer collisions. 


 


\subsection{Forward Security}
\label{sec:arch:forward}

Even the first-attempt scheme
sketched in Section~\ref{sec:arch:straw} provides
{\em forward security} in the event that all
of the servers' secret keys are compromised~\cite{canetti2003forward}.
To be precise: an adversary could compromise the
state and secret keys of {\em all servers} after the servers
have processed  write requests from honest clients, 
but {\em before} the time epoch has ended.
Even in this case, 
the adversary will be unable to determine which of the
 clients submitted which of the  plaintext
messages with a non-negligible advantage over random guessing.
(We assume here that clients and servers
communicate using encrypted channels which themselves
have forward secrecy~\cite{rfc7296}.)

This forward security property means that clients need not
trust that  servers stay honest forever---just that they
are honest at the moment when the client submits its upload request.
Being able to weaken the trust assumption about the servers
in this way might be valuable in hostile environments, in which
an adversary could compromise a server at any time without warning.

Mix-nets do not have this property, since servers must accumulate
a set of onion-encrypted messages before shuffling and
decrypting them~\cite{chaum1981untraceable}. 
If an adversary always controls the first mix server
and if it can compromise the rest of the mix servers after
accumulating a set of ciphertexts,
the adversary can de-anonymize all of the system's users.
DC-net-based systems that use ``blame'' protocols to 
retroactively discover disruptors have a similar 
weakness~\cite{corrigangibbs2010dissent,wolinsky2012dissent}.

The full \name protocol
maintains this forward security property.

 \section{Improving Bandwidth Efficiency with Distributed Point Functions}
\label{sec:dpf}

This section describes how application of private
information retrieval techniques can improve the bandwidth
efficiency of the first-attempt protocol.

\nicepara{Notation}
The symbol  denotes an arbitrary finite field,
 is the ring of integers modulo .
We use  to represent a vector 
that is zero everywhere except at index ,
where it has value ``.''
Thus, for , the vector  is the 
vector whose value is zero everywhere except at index , where it
has value .
For a finite set , the notation  indicates
that the value of  is sampled independently and uniformly at random
from .
The element  is the value of
a vector  at index .
We index vectors starting at zero.


\subsection{Definitions}
The bandwidth inefficiency of the protocol sketched above comes from the
fact that the client must send an -bit vector
to each server to flip a single bit in the logical database.
To reduce this  bandwidth overhead, we apply techniques inspired
by private information retrieval 
protocols~\cite{chor1997computationally,chor1998private,gilboa2014distributed}.

The problem of private information retrieval (PIR) is essentially the converse
of the problem we are interested in here.
In PIR, the client must {\em read} 
a bit from a replicated database without revealing to 
the servers the index being read.
In our setting, the client must {\em write}
a bit into a replicated database without revealing to the servers the
index being written.
Ostrovsky and Shoup first made this
connection in the context of a ``private information storage'' protocol~\cite{ostrovsky1997private}.

PIR schemes allow the client to split its query to the servers 
into shares such that  
(1) a subset of the shares does not leak information about the index of interest, and
(2) the length of the query shares is much less than the length of the database.
The core building block of many PIR schemes, which we adopt
for our purposes, is a {\em distributed point function}.
Although Gilboa and Ishai~\cite{gilboa2014distributed}
defined distributed point functions 
as a primitive only recently, many prior PIR schemes make implicit
use the primitive~\cite{chor1997computationally,chor1998private}.
Our definition of a distributed point function
follows that of Gilboa and Ishai, except
that we generalize the definition to allow 
for more than two servers.

First, we define a (non-distributed) point function.

\begin{defn}[Point Function]
Fix a positive integer  and a finite field .
For all  and , the {\em point function} 
is the function such that  and  for
all .
\end{defn}

That is, the point function  has the value  when evaluated at any 
input not equal to  and it has the value  when evaluated at .
For example, if  and , the point function 
 takes on the values  when evaluated
on the values  (note that we index vectors from zero).

An -distributed point function provides a way to 
distribute a point function  amongst  servers such that
no coalition of at most  servers learns anything about  or 
given their  shares of the function.

\begin{defn}[Distributed Point Function (DPF)]
Fix a positive integer  and a finite field .
An {\em -distributed point function} consists of a pair
of possibly randomized algorithms that implement the following functionalities:
\begin{compactitem}

\item
  .
Given an integer  and value , 
output a list of  keys.

\item
.
Given a key  generated using , and 
an index , return a value .
\end{compactitem}
\end{defn}

We define correctness and privacy for 
a distributed point function as follows:
\begin{compactitem}

\item
{\bf Correctness.}
For a collection of  keys generated using ,
the sum of the outputs of these keys (generated using )
must equal the point function .
More formally, for all  and :

where the probability is taken over the randomness of the  algorithm.

\item
{\bf Privacy.}
Let  be any subset of  
such that .
Then for any  and ,
let  denote the distribution of
keys  induced by 
.
We say that an -DPF maintains privacy if
there exists a p.p.t. algorithm  such that
the following distributions are computationally
indistinguishable:

That is, any subset of at most
 keys leaks no information about  or .
(We can also strengthen this definition to require statistical
or perfect indistinguishability.)
\end{compactitem}

\medskip

\nicepara{Toy Construction}
To make this definition concrete,
we first construct a trivial information-theoretically secure 
\mbox{}-distributed point function with length- keys.
As above, we fix a length  and a finite field .

\begin{compactitem}
\item
.
Generate random vectors .
Set .

\item
.
Interpret  as a vector in .
Return the value of the vector  at index .

\end{compactitem}
The correctness property of this
construction follows immediately.
Privacy is maintained because the distribution of
any collection of  keys is independent of  and~.

This toy construction uses length- keys to distribute
a point function with domain .
Later in this section we describe 
DPF constructions which use much shorter keys.

\subsection{Applying Distributed Point Functions for Bandwidth Efficiency}

We can now use DPFs to improve the efficiency of the
write-private database scheme introduced in Section~\ref{sec:arch:straw}.
We show that the existence of an -DPF with keys of length 
 (along with standard cryptographic assumptions) implies
the existence of write-private database scheme using  servers
that maintains anonymity in the presence of  malicious servers,
such that write requests have length .
Any DPF construction with short keys thus immediately implies 
a bandwidth-efficient write-private database scheme.

The construction is a generalization of the one presented
in Section~\ref{sec:arch:straw}.
We now assume that there are  servers such that no more than 
of them collude.
Each of the  servers maintains a vector in  as their
database state, for some fixed 
finite field  and integer .
Each ``row'' in the database is now an element of  and the database
has  rows.

When the client wants to write a message  into location
 in the database, the client 
uses an -distributed point function to generate a set of
 DPF keys:

The client then sends one of the keys to each of the servers.
Each server  can then expand
the key into a vector 
by computing  for .
The server then adds this vector  into its database state,
using addition in .
At the end of the time epoch, all servers combine their database
states to reveal the set of client-submitted messages.


\nicepara{Correctness}
The correctness of this construction follows directly
from the correctness of the DPF.
For each of the  write requests submitted by the clients, 
denote the -th key in the -th request as ,
denote the write location as , and the message
being written as .
When the servers combine their databases at the end of the
epoch, the contents of the final database at row  will be:

In words: as desired, 
the combined database contains the sum of  point
functions---one for each of the write requests.

\nicepara{Anonymity}
The anonymity of this construction 
follows directly from the privacy property of the DPF.
Given the plaintext database state  (as defined above),
any coalition of  servers can simulate its view of the protocol.
By definition of DPF privacy, there exists
a simulator , which simulates the
distribution of any subset of  DPF keys generated
using .
The coalition of servers can use this simulator to simulate each
of the  write requests it sees during a run of the protocol.
Thus, the servers can simulate their view of a
protocol run and cannot win the anonymity game
with non-negligible advantage. 

\nicepara{Efficiency}
A client in this scheme sends  bits to each
server (where  is a DPF key), so the 
bandwidth efficiency of 
the scheme depends on the efficiency of the DPF.
As we will show later in this section,  can be
much smaller than the length of the database.

\subsection{A Two-Server Scheme Tolerating One Malicious Server}
\label{sec:dpf:twoserver}

\begin{figure*}
\centering
\includegraphics[width=\textwidth]{figs/dpf2.eps}
\caption{Left: We represent the 
output of  as an  matrix of field
elements.
Left-center: Construction of the  vector used
in the DPF keys.
Right: using the , , and  vectors,
 expands each of the two keys into an 
 matrix of field elements.
These two matrices sum to zero everywhere except 
at , where they sum to .
}
\label{fig:dpf}
\end{figure*}


Having established that DPFs with short keys lead to 
bandwidth-efficient write-private database schemes,
we now present one such DPF construction. 
This construction is a simplification of
computational PIR scheme of Chor and 
Gilboa~\cite{chor1997computationally}.

This is a -DPF with keys of length 
operating on a domain of size .
This DPF yields a two-server write-private database scheme 
tolerating one malicious server such that writing into a database
of size  requires sending  
bits to each server.
Gilboa and Ishai~\cite{gilboa2014distributed} construct
a -DPF with even shorter keys (),
but the construction presented here is efficient enough for the database sizes
we use in practice.
Although the DPF construction works over any field, we
describe it here using the binary field  
(the field of -bit bitstrings) to simplify the exposition.

When  is run on every
integer , 
its output is a vector of  field elements.
The DPF key construction conceptually works by representing this
a vector of  field elements
as an  matrix, such that .
The trick that makes the construction work is that the size of the keys
needs only to grow with the size of the {\em sides} of this matrix
rather than its {\em area}.
The DPF keys that  outputs give an efficient
way to construct two matrices  and  that differ only 
at one cell 
(Figure~\ref{fig:dpf}).


Fix a binary finite field , 
a DPF domain size , and integers  and  such that .
(Later in this section, we describe how to 
choose  and  to minimize the key size.)
The construction requires a pseudo-random generator (PRG)
 that stretches seeds from some space  
into length- vectors of elements of ~\cite{haastad1999pseudorandom}.
So the signature of the PRG is .
In practice, an implementation might use AES-128 
in counter mode as the pseudo-random generator~\cite{nist2001aes}.

The algorithms comprising the DPF are:
\begin{compactitem}
\item
.
Compute integers  and  
such that .
Sample a random bit-vector ,
a random vector of PRG seeds ,
and a single random PRG seed .

Given  and , we define 
 and  as: 

That is, the vectors  and 
(similarly  and ) 
differ only at index .

Let  be the vector in  of all zeros except
that it has value  at index .
Define .

The output DPF keys are:


\item
.
Interpret  as a tuple .
To evaluate the PRF at index , 
first write  as an  tuple such that
, , and .
Use the PRG  to stretch the -th seed
of  into a length- vector: 
.
Return .

\end{compactitem}

Figure~\ref{fig:dpf} graphically depicts
how  stretches the 
keys into a table of  field elements.

\nicepara{Correctness}
We prove correctness of the scheme in Appendix~\ref{app:correct}.

\nicepara{Privacy}
The privacy property requires that there exists
an efficient simulator that, on input ``'' or ``,''
outputs samples from a distribution that is computationally
indistinguishable from the distribution of DPF keys
 or .

The simulator  simulates each component of the
DPF key as follows:
It samples 
,
, and
. 
The simulator returns .

We must now argue that the simulator's output distribution
is computationally indistinguishable from that induced by the
distribution of a single output of \Gen.
Since the  and  vectors outputted by 
\Gen are random, the simulation is perfect.
The  vector outputted by \Gen is computationally indistinguishable
from random, since it is padded with the output of the PRG seeded with 
a seed unknown to the holder of the key.
An efficient algorithm
to distinguish the simulated  vector from 
random can then also distinguish the PRG output from random.

\nicepara{Key Size}
A key for this DPF scheme consists of:
a vector in ,
a vector in , and
a vector in .
Let  be the number of bits required to represent
an element of  and let  be the number of
bits required to represent an element of .
The total length of a key is then:

For fixed spaces  and , we can find the optimal
choices of  and  to minimize the key length.
To do so, we solve:

and conclude that the optimal values of  and  are:

The key size is then .

When using a database table of 
one million rows in length (),
a row length of 1 KB per row (), 
and a PRG seed size of 128 bits (using AES-128, for example)
the keys will be roughly 263 KB in length.
For these parameters, 
the keys for the na\"ive construction
(Section~\ref{sec:arch:straw})
would be 1 GB in length.
Application of efficient DPFs thus yields
a 4,000 bandwidth savings in this case.

\nicepara{Computational Efficiency}
A second benefit of this scheme is that
both the \Gen and  routines are 
computationally efficient, since they just require performing
finite field additions (i.e., XOR for binary fields)
and PRG operations (i.e., computations of the AES function).
The construction requires no public-key primitives. 

\subsection{An -Server Scheme Tolerating  Malicious Servers}
\label{sec:dpf:manyserver}

The -DPF scheme described above 
achieved a key size of  bits using only 
symmetric-key primitives.
The limitation of that construction is that it only
maintains privacy when a single key is compromised.
In the context of a write-private database scheme, this
means that the construction 
can only maintain anonymity in the presence
of a {\em single} malicious server.
It would be much better to have a write-private database 
scheme with  servers that maintains anonymity in the
presence of  malicious servers.
To achieve this stronger security notion, we need a
bandwidth-efficient
-distributed point function.

In this section, we construct an -DPF
where each key has size .
We do so at the cost of requiring more expensive 
public-key cryptographic operations, 
instead of the symmetric-key operations used
in the prior DPF.
While the -DPF construction above
directly follows the work of Chor and Gilboa~\cite{chor1997computationally},
this -DPF construction is novel, as far as we know.
In recent work, Boyle et al.~present a -DPF construction using only symmetric-key 
operations, but this construction exhibits a key size {\em exponential} in 
the number of servers ~\cite{boyle2015function}.

\medskip

This construction uses
a \textit{seed-homomorphic pseudorandom 
generator}~\cite{banerjee2014new,boneh2013key,naor1999distributed},
to split the key for the pseudo-random generator  across
a collection of  DPF keys.

\begin{defn}[Seed-Homomorphic PRG]
A {\em seed-homomorphic} PRG is a pseudo-random generator
 mapping seeds in a group
 to outputs in a group  
with the additional property that for any :

\end{defn}

It is possible to construct a simple seed-homomorphic PRG from the decision
Diffie-Hellman (DDH) assumption~\cite{boneh2013key,naor1999distributed}.
The public parameters for the scheme are 
list of  generators chosen at random from an order- 
group , in which the DDH problem is hard~\cite{boneh1998decision}.
For example, if  is an elliptic curve group~\cite{miller1986use},
then the public parameters will be  points .
The seed space is  and the generator
outputs vectors in .
On input , the generator outputs
.
The generator is seed-homomorphic because,
for any , and for
all : 
. 

\medskip

As in the prior DPF construction, we fix
a DPF domain size , and
integers  and  such that .
The construction requires a seed-homomorphic PRG
, for some group 
of prime order~.

For consistency with the prior DPF construction,
we will write the group operation in  
using additive notation.
Thus, the group operation applied component-wise
to vectors  results in
the vector .
Since  has order ,  for all .

The algorithms comprising the -DPF are:
\begin{compactitem}
\item
.
Compute integers  and  
such that .
Sample random integer-valued vectors ,
random vectors of PRG seeds ,
and a single random PRG seed .

Select  such that 

and select
 such that 
.
Define .

The DPF key for server  is
.

\item
.
Interpret  as a tuple .
To evaluate the PRF at index , 
first write  as an  tuple such that
, , and .
Use the PRG  to stretch the -th seed
of  into a length- vector: 
.
Return .

\end{compactitem}

We omit correctness and privacy proofs, since they follow exactly the same
structure as those used to prove security of our prior DPF construction.
The only difference is that correctness here
relies on the fact that  is a seed-homomorphic PRG, rather than a
conventional PRG.
As in the DPF construction
of Section~\ref{sec:dpf:twoserver},
the keys here are of length
. 


\nicepara{Computational Efficiency}
The main computational cost of this DPF construction
comes from the use of the seed-homomorphic PRG .
\textit{Unlike} a conventional PRG, which can be implemented
using AES or another fast block cipher in counter mode,
known constructions of seed-homomorphic PRGs require
algebraic groups~\cite{naor1999distributed} 
or lattice-based cryptography~\cite{banerjee2014new,boneh2013key}.

When instantiating the -DPF with 
the DDH-based PRG construction in elliptic curve groups,
each call to the DPF  routine 
requires an expensive 
elliptic curve scalar multiplication.
Since elliptic curve operations are, per byte,
orders of magnitude slower than AES operations,
this -DPF will be orders
of magnitude slower than the -DPF.
Security against an arbitrary number of malicious servers
comes at the cost of computational efficiency, at least
for these DPF constructions.

\medskip

With DPFs, we can now construct
a bandwidth-efficient write-private database scheme
that tolerates one malicious server (first construction)
or  out of  malicious servers (second construction).


 \section{Preventing Disruptors}
\label{sec:disrupt}

The first-attempt construction of
our write-private database scheme (Section~\ref{sec:arch:straw})
had two limitations: 
(1) client write requests were very large 
and (2) malicious clients could corrupt the database state
by sending malformed write requests.
We addressed the first of these two challenges
in Section~\ref{sec:dpf}.
In this section, we address the second challenge.

A client write request in our protocol just consists
of a collection of  DPF keys.
The client sends one key to each of the  servers.
The servers must collectively decide whether the collection
of  keys is a valid output of the DPF  routine,
without revealing any information about the keys themselves.

One way to view the servers' task here is as a secure
multi-party computation~\cite{goldreich1987play,yao1982protocols}.
Each server 's private input is its DPF key .
The output of the protocol is a single bit, which determines if the  keys  are a
well-formed collection of DPF keys.

Since we already rely on servers for availability
(Section~\ref{sec:goal:threat}), we {\em need not} protect
against servers maliciously trying to manipulate the 
output of the multi-party protocol.
Such manipulation could only result in corrupting the database 
(if a malicious server accepts a write request that it should
have rejected)
or denying service to an honest client
(if a malicious server rejects a write request that it should
have accepted).
Since both attacks are tantamount to denial of service,
we need not consider them.

We {\em do} care, in contrast, about protecting 
client privacy against malicious servers.
A malicious server participating in the protocol
should not gain any additional information about
the private inputs of other parties, no matter how
it deviates from the protocol specification.

We construct two protocols for checking the validity
of client write requests.
The first protocol is computationally inexpensive, but 
requires introducing a third non-colluding party to 
the two-server scheme. 
The second protocol requires relatively expensive zero-knowledge proofs~\cite{feige1988zero,goldreich1991proofs,goldwasser1989knowledge,rackoff1992non},
but it maintains security when all but one
of  servers is malicious.
Both of these protocols must satisfy the 
standard notions of soundness, completeness, and
zero-knowledge~\cite{camenisch1998group}.

Since the publication of this paper, Boyle et al.~have designed a very
efficient protocol for checking the well-formedness of DPF
keys~\cite{boyle2016function}.
Their checking protocol provides security against semi-honest (i.e., honest but curious) servers
and requires only a \textit{constant} amount of server-to-server communication.
If it is possible to extend their checking protocol to provide security against fully malicious
servers, their new scheme could serve as a more efficient alternative to the protocols described herein.

\subsection{Three-Server Protocol}
\label{sec:disrupt:smc}

Our first protocol for detecting malformed write requests
works with the -DPF scheme presented in 
Section~\ref{sec:dpf:twoserver}.
The protocol uses only hashing and finite field additions, 
so it is computationally inexpensive.
The downside is that it requires introducing a third
{\em audit} server, which must not collude with either
of the other two servers.
This simple protocol draws inspiration from classical secure
multi-party computation protocols~\cite{fagin1996comparing,
goldreich1987play, yao1982protocols}.

As a warm-up to the full checking protocol, 
we develop a three-server protocol called

that we use as a subroutine 
to implement the full write-request validation protocol.
The  protocol takes place between 
the client and three servers: 
database server , database server , and an audit server.

Let  be a security parameter (e.g., ).  
The protocol uses a hash function 
, which we model as a random
oracle~\cite{bellare1993random}.

At the start of the protocol, database server  holds 
a vector , and database server  holds a vector
.
The audit server takes no private input.
The client holds both  and .

The three servers execute a protocol that allows them to confirm
that the vectors  and  are equal everywhere except at exactly one index, and
such that any one malicious server learns nothing about 
the index at which these vectors differ,
as long as the vectors indeed differ at a single index.

More formally, the servers want to execute this 
check in such a way that the following properties hold:
\begin{compactitem}
\item[--] \textbf{Completeness.} If all parties are honest, and
     and  are well formed, then the database servers 
    almost always accept the vectors as well formed.
\item[--] \textbf{Soundness.} If  and  do not differ
    at a single index, and all three servers are honest, then the
    servers will reject the vectors almost always.
\item[--] \textbf{Zero knowledge.} If  and  are well formed
    and the client is honest, then any one actively malicious server
    can simulate its view of the protocol execution. Furthermore,
    the simulator does not take as input the index at which  and 
    differ nor the value of the vectors at that index.
\end{compactitem}

We denote an instance of the three-server
protocol as ,
where the arguments denote the private values that 
the two database servers take as input.
The protocol proceeds as follows:
\begin{enumerate}
  \item The client sends a PRG seed  to both database servers.

  \item Servers  and  use a PRG seeded with the seed 
        to sample  pseudorandom values . 
        The servers also use the seed  to agree upon
        a pseudorandom ``shift'' value .
        
  \item Server  computes the values 
        for every index  and 
        sends to the auditor
         
        The vector  is a blinded version of server 's input vector .
        Using a secret random value  shared with server 
        (constructed using a coin-flipping protocol~\cite{blum1983coin}, for example),
        server  computes a check value
         and sends  to the auditor.

  \item Server  repeats Step~2 with .

  \item \label{step:clientsend}
        Since the client knows , , and , it can 
        compute  and  on its own.
        The client computes digests 
         and ,
        and sends these digests to the audit server.

  \item The audit server returns ``1'' to servers  and 
        if and only if:
        \begin{itemize}
          \item the vectors it receives from the two
                servers are equal at every index except one, 
          \item the values  and  are equal, and
          \item the vectors  and  satisfy
                 and ,
                where  and  are the client-provided digests. 
        \end{itemize}
        The auditor returns ``0'' otherwise.
        
\end{enumerate}



We include proofs of soundness, correctness, and zero-knowledge
for this construction in Appendix~\ref{app:almostequal}.

\medskip

The keys for the -DPF construction 
have the form 

In a correctly formed pair of keys, the 
and  vectors differ at a single index ,
and the  vector is equal to 
.

To determine whether a pair of keys is correct,
server  constructs a test vector 
such that 
for .
(where  denotes concatenation).
Server  constructs a test vector 
in the same way and the two servers, along with
the client and 
the auditor, run the protocol .
If the output of this protocol is ``1,'' then the servers
conclude that their  and  vectors
differ at a single index, though the protocol
does not reveal to the servers which index this is.
Otherwise, the servers reject the write request.

Next, the servers must verify that the  vector
is well-formed.
To do so, the servers compute another pair of test vectors:

The client and servers run 
and accept the write request as valid if it returns ``1.''

We prove security of this construction in 
\abbr{the full version of this paper}{Appendix~\ref{app:smc-proof}}.

An important implementation note is that if ---that is, if the
client writes the string of all zeros into the database---then 
the  vectors will not differ at any index and this information
is leaked to the auditor.
The protocol only provides security if the vectors differ at {\em exactly one}
index.
To avoid this information leakage, client requests 
must be defined such that  in every write request.
To achieve this, clients could define some special non-zero value
to indicate ``zero'' or could use a padding scheme to ensure
that zero values occur with negligible probability.

As a practical matter, the audit server needs to be able to match up the
portions of write requests coming from server  with those coming from server
. \Name achieves this as follows: 
When the client sends its upload request to server , the client includes a
cryptographic hash of the request it sent to server  (and vice versa). 
Both servers can use these hashes to derive a common nonce for the request. 
When the servers send audit requests to the audit server, they include the nonce
for the write request in question. 
The audit server can use the 
nonce to match every audit request from server  with the corresponding request
from server . 

\medskip

This three-party protocol is very efficient---it only 
requires  applications of a hash function and
 communication from the servers to the auditor.
The auditor only performs a simple string comparison, so it 
needs minimal computational and storage capabilities.


\subsection{Zero Knowledge Techniques}
\label{sec:disrupt:zkp}

Our second technique for detecting disruptors makes use
of non-interactive zero-knowledge proofs~\cite{camenisch1997proof,goldwasser1989knowledge,rackoff1992non}.

We apply zero-knowledge techniques to allow clients to prove the
well-formedness of their write requests.
This technique works in combination with the 
-DPF presented in Section~\ref{sec:dpf:manyserver}
and maintains client write-privacy 
when {\em all but one} of  servers is dishonest.

The keys for the -DPF scheme are tuples 
 such that:


To prove that its write request was correctly formed,
we have the client perform zero-knowledge proofs over
collections of Pedersen commitments~\cite{pedersen1992non}.
The public parameters for the Pedersen commitment scheme
consist of a group  of prime order  and two generators
 and  of  such that no one knows the discrete logarithm
.
A Pedersen commitment to a message  with randomness
 is 
(writing the group operation additively).
Pedersen commitments are {\em homomorphic}, in that given commitments
to  and , it is possible to compute a commitment to :


Here, we assume that the -DPF is instantiated with the
DDH-based PRG introduced in Section~\ref{sec:dpf:manyserver} and that
the group  used for the Pedersen commitments is the same order- group 
used in the PRG construction.

To execute the proof, the client first generates
Pedersen commitments to elements of each of the  DPF keys.
Then each server  can verify that the client computed the commitment
to the -th DPF key elements correctly.
The servers use the homomorphic property of Pedersen commitments 
to generate commitments to the \textit{sum} of the elements of the DPF keys.
Finally, the client proves in zero knowledge that these sums have the 
correct values.

The protocols proceed as follows:

\begin{enumerate}
  \item The client generates vectors of Pedersen commitments 
    and  committing to each element of  and .
    The client sends the  and  vectors to {\em every server}.
  \item To server , the client sends the opening of the commitments
     and .
    Each server  verifies that  and  are valid
    commitments to the  and  vectors in the DPF key.
    If this check fails at some server , server 
    notifies the other servers and all servers reject the write request.
  \item \label{item:check-commit}
    Using the homomorphic property of the commitments, each server can compute
    vectors of commitments  and 
    to the vectors  and .
  \item \label{item:check-proof}
    Using a non-interactive zero-knowledge proof, the client proves to 
    the servers that  and 
    are commitments to zero everywhere except at a single (secret) index ,
    and that  is a commitment to one.\footnote{
Technically, this is a zero-knowledge proof of knowledge
which proves that the client {\em knows} an opening of
the commitments to the stated values.
}
    This proof uses standard witness hiding techniques
    for discrete-logarithm-based zero knowledge 
    proofs~\cite{camenisch1997proof,cramer1994proofs}.
    If the proof is valid, the servers continue to check the  vector.
\end{enumerate}

This first protocol convinces each server that the  and  components
of the DPF keys are well formed.
Next, the servers check the  component:

\begin{enumerate}
  \item For each server , the client sums up the seed values  it
        sent to server : .
        The client then generates the output of  and blinds it: 
        
  \item The client sends the  values to all servers and the client
        sends the opening of  to each server .
  \item Each server verifies that the openings are correct, and all servers
        reject the write request if this check fails at any server.
  \item Using the homomorphic property of Pedersen commitments, every server
        can compute a vector of commitments 
        .
        If  is well formed, then the  vector
        contain commitments to zero at every index except one (at which it 
        will contain a commitment to the client's message ).
  \item \label{item:check-zkp}
        The client uses a non-interactive zero-knowledge proof to convince
        the servers that the vector of commitments
         contains commitments to zero at all indexes 
        except one.
        If the proof is valid, the servers accept the write request.
\end{enumerate}

We prove in \abbr{the full version of this paper}{Appendix~\ref{app:zkp-proof}}
that this protocol satisfies the
standard notions of soundness, completeness, and
zero-knowledge~\cite{camenisch1998group}.

 \section{Experimental Evaluation}
\label{sec:eval}

\begin{framed}
\noindent
{\color{blue} \textbf{Note:}}
As described on the title page, this is the extended and corrected
version of a paper by the same name that appeared at the
{\em IEEE Symposium on Security and Privacy}
in May 2015. This version corrects an error in the 
 protocol of Section~\ref{sec:disrupt:smc}
that could allow a malicious database server to de-anonymize
a client using an active attack.

We thank Elette Boyle and Yuval Ishai for pointing out this
error and for helpful discussions on how to correct it.
Since the complexity of the updated protocol is almost identical
to the original one, and since the first author's 
dissertation~\cite[Section 5]{thesis} describes and evaluates
a DPF-checking protocol that subsumes the one
presented here, this evaluation section 
reflects the DPF-checking protocol from
the original version of this work.

The only important qualitative difference between the original
protocol and the one presented here is that the corrected protocol
models the hash function as a random oracle, and thus requires
using a strong hash function, such as SHA-256.
In contrast, the original protocol required a less expensive 
universal hash function, such as Poly1305.

When using Riposte with table size ,
we expect that the cost of the  AES operations required 
for DPF key expansion to dominate the  hashing
operations needed for auditing.
Even so, we want to highlight this difference in case it
is relevant to those building on our work.
\end{framed}

To demonstrate that \name is a practical platform
for traffic-analysis-resistant anonymous messaging,
we implemented two variants of the system. 
The first variant uses the two-server distributed
point function (Section~\ref{sec:dpf:twoserver})
and uses the three-party protocol 
(Section~\ref{sec:disrupt:smc})
to prevent malicious clients from corrupting the database.
This variant is relatively fast, since it relies
primarily on symmetric-key primitives, but requires
that no two of the three servers collude.
Our results for the first variant {\em include the cost}
of identifying and excluding malicious clients.

The second variant uses the -server distributed
point function (Section~\ref{sec:dpf:manyserver}).
This variant protects against  colluding servers,
but relies on expensive public-key operations.
We have not implemented the zero-knowledge proofs
necessary to prevent disruptors for the -server
protocol (Section~\ref{sec:disrupt:zkp}), so the
performance numbers represent only an upper bound on the
system throughput.

We wrote the prototype in the Go programming language
and have published the source code online at
\url{https://bitbucket.org/henrycg/riposte/}.
We used the DeterLab network 
testbed for our experiments~\cite{mirkovic2012teaching}.
All of the experiments used commodity servers running Ubuntu 14.04
with four-core AES-NI-enabled Intel E3-1260L CPUs 
and 16 GB of RAM.

Our experimental network topology used between
two and ten servers (depending on the protocol variant in use)
and eight client nodes.
In each of these experiments, the eight client machines
used many threads of execution to submit
write requests to the servers as quickly as possible.
In all experiments, the server nodes
connected to a common switch via 100 Mbps links,
the clients nodes connected to a common switch via 1 Gbps links,
and the client and server switches connected via a 1 Gbps link.
The round-trip network latency between each pair of nodes was 20~ms.
We chose this network topology to limit
the bandwidth between the servers to that of a fast WAN, but
to leave client bandwidth unlimited so that the small number
of client machines could saturate the servers with
write requests.

Error bars in the charts indicate the standard
deviation of the throughput measurements.

\subsection{Three-Server Protocol}

A three-server \name cluster consists of
two database servers and one audit server.
The system maintains its security properties as long
as {\em no two} of these three servers collude.
We have fully implemented the three-server protocol,
including the audit protocol (Section~\ref{sec:disrupt:smc}),
so the throughput numbers listed here {\em include} 
the cost of detecting and rejecting malicious write requests.

The prototype used AES-128 in counter mode as the pseudo-random
generator, Poly1305 as the keyed hash function 
used in the audit protocol~\cite{bernstein2005poly},
and TLS for link encryption.

Figure~\ref{fig:tablesize} shows how many client write requests
our \name cluster can service per second as the number of 160-byte
rows in the database table grows.
For a database table of 64 rows, the system handles 
751.5 write requests per second.
At a table size of 65,536 rows, the system handles 32.8 requests
per second.
At a table size of 1,048,576 rows, the system handles 2.86 requests
per second.

We chose the row length of 160 bytes because it was the smallest
multiple of 32 bytes large enough to to contain a 140-byte Tweet.
Throughput of the system depends only the total
size of the table (number of rows  row length), so larger
row lengths might be preferable for other applications.
For example, an anonymous email system using \name with 
4096-byte rows could handle 2.86 requests per second at a table
size of 40,960 rows.

\begin{figure}
\centering
\includegraphics[width=0.5\textwidth]{figs/tablesize.eps}
\caption{As the database table size grows, the throughput of
  our system approaches the maximum possible given the 
  AES throughput of our servers.}
\label{fig:tablesize}
\end{figure}

An upper bound on the performance of the system is the speed 
of the pseudo-random generator used to stretch out the
DPF keys to the length of the database table.
The dashed line in Figure~\ref{fig:tablesize} indicates this upper
bound (605 MB/s), as determined using an AES benchmark written in Go.
That line indicates the maximum possible throughput we could hope
to achieve without aggressive optimization (e.g., writing portions of
the code in assembly) or more powerful machines.
Migrating the performance-critical
portions of our implementation from Go to C (using OpenSSL)
might increase the throughput by a factor of as much as
, since  reports AES throughput of 3.9 GB/s,
compared with the 605 MB/s we obtain with Go's crypto library.
At very small table sizes, the speed at which the server can set up
TLS connections with the clients limits the overall throughput
to roughly 900 requests per second.

\begin{figure}
\centering
\includegraphics[width=0.5\textwidth]{figs/tablewidth.eps}
\caption{Use of bandwidth-efficient DPFs gives 
 a  speed-up over the na\"ive constructions,
 in which a client's request is as large as the database.}
\label{fig:tablewidth}
\end{figure}

Figure~\ref{fig:tablewidth} demonstrates how the request throughput
varies as the width of the table changes, while the number
of bytes in the table is held constant at 10 MB.
This figure demonstrates the performance advantage of using
a bandwidth-efficient  DPF (Section~\ref{sec:dpf})
over the na\"ive DPF (Section~\ref{sec:arch:straw}).
Using a DPF with optimal table size yields a throughput of 38.4 requests
per second.
The extreme left and right ends of the figure indicate the performance
yielded by the na\"ive construction, in which making a write request
involves sending a -dimension vector to each server.
At the far right extreme of the table, performance drops to 
0.05 requests per second, so DPFs yield a 768 speed-up.

Figure~\ref{fig:bandwidth} indicates the total number of
bytes transferred by one of the database servers and
by the audit server while processing a single client write
request.
The dashed line at the top of the chart indicates the number
of bytes a client would need to send for a single write request
 if we did not use bandwidth-efficient DPFs
(i.e., the dashed line indicates the size of the database table).
As the figure demonstrates,
the total data transfer in a \name cluster
scales {\em sub-linearly} with the database size. 
When the database table is 2.5 GB in size, the database server
transfers only a total of 1.23 MB to process a write request.


\begin{figure}
\centering
\includegraphics[width=0.5\textwidth]{figs/bandwidth.eps}
\caption{The total client and server data 
  transfer scales sub-linearly
  with the size of the database.}
\label{fig:bandwidth}
\end{figure}


\subsection{-Server Protocol}

In some deployment scenarios, 
having strong protection against
server compromise may be more important
than performance or scalability.
In these cases, the -server \name protocol 
provides the same basic functionality as the three-server
protocol described above, except that it maintains
privacy even if  out of  servers collude or
deviate arbitrarily from the protocol specification.
We implemented the basic -server protocol but have not
yet implemented the zero-knowledge proofs necessary
to prevent malicious clients from corrupting the
database state (Section~\ref{sec:disrupt:zkp}).
These performance figures thus represent an {\em upper bound}
on the -server protocol's performance.
Adding the zero-knowledge proofs 
would require an additional 
elliptic curve operations per server in an -row database.
The computational cost of the proofs would almost certainly be dwarfed by the 
elliptic curve operations required to update the state of the database table.

The experiments use the DDH-based seed-homomorphic 
pseudo-random generator described
in Section~\ref{sec:dpf:manyserver} and they use the 
NIST P-256 elliptic curve as the underlying algebraic group.
The table row size is fixed at 160 bytes. 

Figure~\ref{fig:ddh-tablesize} demonstrates the performance
of an eight-server \name cluster as the table size increases.
At a table size of 1,024 rows, the cluster can process
one request every 3.44 seconds.
The limiting factor is the rate at which the servers can evaluate
the DDH-based pseudo-random generator (PRG),
since computing each 32-byte block of PRG output requires 
a costly elliptic curve scalar multiplication.
The dashed line in the figure indicates the maximum throughput
obtainable using Go's implementation of P-256 on our servers,
which in turn dictates the maximum cluster throughput.
Processing a single request with a table size of one million
rows would take nearly one hour with this construction, compared
to 0.3 seconds in the AES-based three-server protocol.

\begin{figure}
\centering
\includegraphics[width=0.5\textwidth]{figs/ddh-tablesize.eps}
\caption{Throughput of an eight-server \name cluster using the 
  -distributed point function.}
\label{fig:ddh-tablesize}
\end{figure}

Figure~\ref{fig:ddh-servers} shows how the throughput of the
\name cluster changes as the number of servers varies.
Since the workload is heavily CPU-bound, the throughput
only decreases slightly as the number of servers increases
from two to ten.

\begin{figure}
\centering
\includegraphics[width=0.5\textwidth]{figs/ddh-servers.eps}
\caption{Throughput of \name clusters using two
    different database table sizes as the number 
    of servers varies.}
\label{fig:ddh-servers}
\end{figure}


\subsection{Discussion: Whistleblowing and\\ Microblogging with Million-User\\ Anonymity Sets}
\label{sec:eval:million}

Whistleblowers, political activists,
or others discussing sensitive or controversial
issues might benefit from an anonymous microblogging service.
A whistleblower, for example, might want to anonymously blog
about an instance of bureaucratic corruption in her organization.
The utility of such a system depends on the size of the anonymity set
it would provide:
if a whistleblower is only anonymous amongst a group of ten people,
it would be easy for the whistleblower's employer to retaliate against
{\em everyone} in the anonymity set. 
Mounting this ``punish-them-all'' attack does not require breaking 
the anonymity system itself, since the anonymity set is public.
As the anonymity set size grows, however, the
feasibility of the ``punish-them-all'' attack quickly tends to zero.
At an anonymity set size of 1,000,000 clients, mounting an 
``punish-them-all'' attack would be prohibitively expensive
in most situations.

\Name can handle such large anonymity sets as long as
(1) clients are willing to tolerate hours of messaging latency, and 
(2) only a small fraction of clients writes into the database in each time epoch.
Both of these requirements are satisfied in the whistleblowing
scenario.
First, whistleblowers might not care if the system delays their posts by
a few hours.
Second, the vast majority of users of a microblogging service
(especially in the whistleblowing context) are 
more likely to {\em read} posts than write them.
To get very large anonymity sets, maintainers of an anonymous
microblogging service could take advantage of the large set of
``read-only'' users to provide anonymity for the relatively 
small number of ``read-write'' users.

The client application for such a microblogging service would 
enable read-write users to generate and submit
\name write requests to a \name cluster running the microblogging service.
However, the client application would 
also allow read-only users to submit an ``empty''
write request to the \name cluster that would always write a random
message into the first row of the \name database.
From the perspective of the servers, a read-only client would be 
indistinguishable from a read-write client.
By leveraging read-only users in this way, 
we can increase the size of the anonymity set without
needing to increase the size of the database table.

To demonstrate that \name can support very large anonymity set
sizes---albeit with high latency---we configured a cluster
of \name servers with a 65,536-row database table and left it running for 32 hours.
In that period, the system processed a total of 2,895,216 
write requests at an average rate of 25.19 requests per second.
(To our knowledge, this is the largest
anonymity set {\em ever constructed} in a system that
offers protection against traffic analysis attacks.)
Using the techniques in Section~\ref{sec:collisions},
a table of this size could handle 0.3\% of users writing at
a collision rate of under 5\%.
Thus, to get an anonymity set of roughly 1,000,000 users
with a three-server \name cluster and
a database table of size , the time epoch must 
be at least 11 hours long.

As of 2013, Twitter reported an average throughput of
5,700 140-byte Tweets per second~\cite{krikorian2013new}.
That is equivalent roughly 5,000 of our 160-byte messages per second.
At a table size of one million messages, our \name cluster's 
end-to-end throughput is 2.86 write requests per second (Figure~\ref{fig:tablesize}).
To handle the same volume of Tweets as Twitter does with
anonymity set sizes on the order of hundreds of thousands of clients, 
we would need to increase the computing power of our cluster by ``only''
a factor of 1,750.\footnote{
We assume here that scaling the number of machines
by a factor of  increases our throughput by a factor of .
This assumption is reasonable given our workload, since 
the processing of write requests is an embarrassingly parallel task.
}
Since we are using only three servers now, we would need
roughly 5,250 servers (split into three non-colluding data centers)
to handle the same volume of traffic as Twitter. 
Furthermore, since the audit server is just doing string comparisons,
the system would likely need many fewer audit servers than database servers,
so the total number of servers required might be closer to .

 \section{Related Work}
\label{sec:rel}

Anonymity systems fall into one of two general categories: systems that provide
low-latency communication and those that protect against traffic analysis
attacks by a global network adversary.

Aqua~\cite{leblond2013towards}, 
Crowds~\cite{reiter1998crowds}, 
LAP~\cite{hsiao2012lap}, 
ShadowWalker~\cite{mittal2009shadowwalker},
Tarzan~\cite{freedman2002tarzan}, and
Tor~\cite{dingledine2004tor} 
belong to the first category of systems: 
they provide an anonymous proxy for 
real-time Web browsing, but they
do not protect against an adversary 
who controls the network, many of
the clients, and some of the nodes
on a victim's path through the network.
Even providing a formal 
definition of anonymity for low-latency systems
is challenging~\cite{johnson2009design} and such
definitions typically do not capture the need to 
protect against timing attacks.

Even so, it would be possible to combine 
Tor (or another low-latency anonymizing proxy) and \name
to build a ``best of both'' anonymity system: clients would submit
their write requests to the \name servers via the Tor network.
In this configuration, even if {\em all} of the \name servers
colluded, they could not learn which user wrote which message
without also breaking the anonymity of the Tor network.

David Chaum's ``cascade'' mix networks were one of the
first systems devised with the specific goal of defending
against traffic-analysis attacks~\cite{chaum1981untraceable}.
Since then, there have been a number of mix-net-style systems proposed, 
many of which explicitly weaken 
their protections against a near omni-present adversary~\cite{syverson2013why}
to improve prospects for practical usability 
(i.e., for email traffic)~\cite{danezis2003mixminion}.
In contrast, \Name attempts to provide very strong anonymity guarantees
at the price of usability for interactive applications.


E-voting systems (also called ``verifiable shuffles'')
achieve the sort of privacy properties that \name 
offers, and some systems even provide stronger 
voting-specific guarantees 
(receipt-freeness, proportionality, etc.),
though most e-voting systems cannot provide
the forward security property that \name offers (Section~\ref{sec:arch:forward})~\cite{adida2008helios,clarkson2007civitas,neff2001verifiable,groth2007verifiable,furukawa2004efficient,groth2010verifiable,rabin2014efficient}.

In a typical e-voting system, voters submit their encrypted ballots
to a few trustees, who collectively shuffle and decrypt them.
While it is possible to repurpose e-voting systems for anonymous messaging,
they typically require expensive zero-knowledge proofs 
or are inefficient when message sizes are large.
Mix-nets that do not use zero-knowledge proofs of correctness
typically do not provide privacy in the face of active attacks 
by a subset of the mix servers. 

For example, the verifiable shuffle protocol of 
Bayer and Groth~\cite{bayer2012efficient}
is one of the most efficient in the literature.
Their shuffle implementation, when used with 
an anonymity set of size , requires  group 
exponentiations per server and data
transfer .
In addition, messages must be small enough to be encoded
in single group elements (a few hundred bytes at most).
In contrast, our protocol requires  AES operations and
data transfer , where  is the size of the
database table.
When messages are short and when the writer/reader ratio
is high, the Bayer-Groth mix may be faster than our system.
In contrast, when messages are long and when the writer/reader
ratio is low (i.e., ), our system is faster.

Chaum's Dining Cryptographers network
(DC-net) is an information-theoretically secure
anonymous broadcast channel~\cite{chaum1988dining}.
A DC-net provides the same strong anonymity properties
as \name does, but it requires every user of a DC-net
to participate in every run of the protocol.
As the number of users grows, this quickly becomes impractical.

The Dissent~\cite{wolinsky2012dissent} system
introduced the idea of using partially trusted servers to 
make DC-nets practical in distributed networks. 
Dissent requires weaker trust assumptions than our three-server
protocol does but it requires clients to send  bits
to each server per time epoch (compared with our ).
Also, excluding {\em a single} disruptor in a 1,000-client
deployment takes over an hour.
In contrast, \name can excludes disruptors as fast as it processes write
requests (tens to hundreds per second, depending on the database size).
Recent work~\cite{corrigangibbs2013proactively} uses
zero-knowledge techniques to speed up disruption resistance
in Dissent (building on ideas of Golle and Juels~\cite{golle2004dining}).
Unfortunately, these techniques limit the system's end to end-throughput
end-to-end throughput to 30 KB/s, compared with \name's 450+ MB/s.

Herbivore scales DC-nets by dividing users into many small anonymity
sets~\cite{goel2003herbivore}.
\Name creates a single large anonymity set, and thus enables
every client to be anonymous amongst the {\em entire set} of honest clients.




Our DPF constructions make extensive use
of prior work on private information
retrieval (PIR)~\cite{chor1998private,chor1997computationally,gasarch2004survey,gilboa2014distributed}.
Recent work demonstrates that it is possible to make
theoretical PIR fast enough for practical 
use~\cite{devet2014best,goldberg2007improving,demmler2014raid}.
Function secret sharing~\cite{boyle2015function} generalizes DPFs
to allow sharing of more sophisticated functions (rather than just
point functions).
This more powerful primitive may prove useful for PIR and anonymous
messaging applications in the future.

Gertner et al.\cite{gertner1998protecting} consider {\em symmetric}
PIR protocols, in which the servers prevent dishonest clients
from learning about more than a single row of the database per query.
The problem that Gertner et al.\ consider is, in a way, the dual 
of the problem we address in Section~\ref{sec:disrupt}, though
their techniques do not appear to apply directly in our setting.

Ostrovsky and Shoup first proposed
using PIR protocol as the basis for writing
into a database shared across a set of servers~\cite{ostrovsky1997private}.
However, Ostrovsky and Shoup
considered only the case of a single honest client, 
who uses the untrusted database servers for private storage. 
Since {\em many mutually distrustful clients} use a
single \name cluster, our protocol must also handle malicious clients.

Pynchon Gate~\cite{sassaman2005pynchon} builds a 
private point-to-point messaging system from mix-nets and PIR.
Clients anonymously upload messages to email servers using a traditional mix-net
and download messages from the email servers using a PIR protocol.
\Name could replace the mix-nets used in the Pynchon Gate system: clients
could anonymously write their messages into the database using \name
and could privately read incoming messages using PIR.

 \section{Conclusion and Open Questions}
\label{sec:concl}

We have presented \name, a new system for anonymous messaging.
To the best of our knowledge, \name is the first system
that simultaneously 
(1) thwarts traffic analysis attacks,
(2) prevents malicious clients from anonymously disrupting the system, and
(3) enables million-client anonymity set sizes.
We achieve these goals through novel application of private information
retrieval and secure multiparty computation techniques.
We have demonstrated \name's practicality by implementing it and
evaluating it with anonymity sets of over two million nodes.
This work leaves open a number of questions for future work, including:
\begin{compactitem}
\item Does there exist an -DPF construction for 
      that uses only symmetric-key operations?
\item Are there efficient techniques 
      (i.e., using no public-key primitives) for achieving
      disruption resistance without the need for a
      non-colluding audit server?
\item Are there DPF constructions that enable processing
      write requests in amortized time , for a 
      length- database?
\end{compactitem}
With the design and implementation of \name,
we have demonstrated that cryptographic techniques can 
make traffic-analysis-resistant anonymous microblogging
and whistleblowing more practical at Internet scale.


\subsection*{Acknowledgements}
We thank Elette Boyle and Yuval Ishai for pointing out an error in 
the  protocol of Section~\ref{sec:disrupt:smc},
and for helpful discussions on how to repair it.
We thank Paul Grubbs for the suggestion to add a note on this bug
to the evaluation section of the paper.
We would like to thank Joe Zimmerman and David
Wu for helpful discussions about distributed point functions.
We would like to thank Stephen Schwab and the staff of
DeterLab for giving us access to their excellent network testbed. 
This work was supported by NSF, an IARPA project provided via DoI/NBC,
a grant from ONR, an NDSEG fellowship, 
and by a Google faculty scholarship. Opinions,
findings and conclusions or recommendations expressed in this material
are those of the author(s) and do not necessarily reflect the views of
DARPA or IARPA.



 


\frenchspacing
\bibliographystyle{plain}
\bibliography{refs}
\nonfrenchspacing

\appendix
\section{Definition of Write Privacy}
\label{app:game}

An -{\em write-private database scheme}
consists of the following three (possibly randomized) algorithms: 

\medskip

\begin{hangparas}{0.25in}{1}
  .
  Clients use the  functionality to generate the
  write request queries sent to the  servers. 
  The  function takes as input a message  (from some 
  finite message space) and an integer  and produces a set of 
  write requests---one per server.
  
  .
  Servers use the  functionality to process incoming
  write requests.
  The  function takes as input a server's internal state
  , a write request , and outputs the updated state of the server .

  .
  At the end of the time epoch, servers use the  functionality
  to recover the contents of the database.
  The  function takes as input the set of states from
  each of the  servers and produces the plaintext database contents .
\end{hangparas}

\medskip

We define the write-privacy property using the following
security game, played between the adversary (who statically
corrupts up to  servers and all but two clients) and a challenger.
\begin{enumerate}
  \item In the first step, the adversary performs the following actions: 
        \begin{itemize}
            \item The adversary selects 
              a subset 
              of the servers, such that .
              The set  represents the
              set of adversarial servers. 
              Let the set 
              represent the set of honest servers.

            \item The adversary selects a set of clients ,
                  such that , representing the set of honest clients.
                  The adversary selects
                  one message-location pair per honest client:
                

        \end{itemize}
        The adversary sends  and  to the challenger.

  \item In the second step, the challenger responds to the adversary:
        \begin{itemize}
        \item 
        For each , the challenger generates 
        a write request: 
        
        The set of shares of the th write request revealed to the
        malicious servers is .

        In the next steps of the game, the challenger will randomly reorder the honest
        clients' write requests. 
        The challenger should learn nothing about which client wrote what,
        despite all the information at its disposal.

        \item
        The challenger then samples a random permutation  over
        .
        The challenger sends the following set of write requests to the adversary,
        permuted according to~:
        
        \end{itemize}

  \item For each client  in , 
        the adversary computes a write
        request  (possibly according 
        to some malicious strategy) and sends the set of these
        write requests to the challenger.
  
  \item \begin{itemize}
        \item For each server , the
        challenger computes the server's final state
         by running the 
        functionality on each of the  client write requests in order.
        Let  be the set of 
        states of the honest servers.

        \item 
        The challenger samples a bit . 
        If , the challenger send  to the adversary.
        Otherwise, the challenger samples a fresh permutation
         on  and sets  to the adversary.

        \end{itemize}
  \item The adversary makes a guess  for the value of .
\end{enumerate}

The adversary wins the game if .
We define the adversary's advantage as
.
The scheme maintains -write privacy if no efficient adversary
wins the game with non-negligible advantage (in the implicit security parameter). 


 \section{Correctness Proof for -DPF}
\label{app:correct}

This appendix proves correctness of the distributed
point construction of Section~\ref{sec:dpf:twoserver}.
For the scheme to be correct,
it must be that, for
, for all :

Let  be the tuple in  representing
location  and let  be the tuple representing .
Let:

We use a case analysis to show that the left-hand side of the 
equation above equals  for all :
\begin{itemize}
\item[{\bf Case I}:] . 
  When , 
  the seeds  and 
  are equal, so .
  Similarly .
  The output  will be
  ,
  The output  will be identical to .
  Since the field is a binary field, adding
  a value to itself results in the zero element,
  so the sum  will be zero as desired.

\item[{\bf Case II}:]  and .
  When , the seeds  and 
  are {\em not} equal, so .
  Similarly .
  When , 
  .
  Assume  (an analogous argument applies when 
  ), then:
  
  The sum  will then be:
  

\item[{\bf Case III}:]  and .
  This is the same as Case II, except that  when
  , so the sum , as desired.

\end{itemize}

 

\section{Proof Sketches for the\\{\sf AlmostEqual} Protocol}
\label{app:almostequal}

This appendix proves security of the  protocol 
of Section~\ref{sec:disrupt:smc}.

\nicepara{Completeness}
We must show that 
if the vectors  and  differ
in exactly one position, the audit server will output ``1''
with overwhelming probability.

The audit server checks three things:
(1) that  and  differ at a single index, 
(2) that the check values  and  are equal, and
(3) that the digests  and  match the digests
of the vectors the database servers sent to the audit server.
The second and third tests will always pass if all parties are honest.

The first test fails with some small probability:
since the audit server only outputs ``1'' if {\em exactly}
one element of the test vectors is equal, if there
is a collision in the hash function, the
protocol may return an incorrect result.
The probability of this event is negligible
in the security parameter .

\nicepara{Soundness}
To demonstrate soundness, it is sufficient to show that it is infeasible
for a cheating client to produce values

such that  and  do {\em not} differ at exactly one index, and
yet the three honest servers accept these vectors as almost equal.

Let  and  
be the values that the honest database servers send 
to the audit server.

First, note that for the cheating client to succeed, it must be that
 or .
So the choice of  and  are fixed by the client's choice
of the other values.

Next, observe that if a cheating client submits values  to
the servers, then  with probability .
This holds because we require soundness to hold only when all three
servers are honest, so both database servers will generate
 and  using a common blinding value .
So any successfully cheating client must submit a request with
.

To cause the servers to accept, the client must then find values 
 and  such that,
 and, for all but one , 
.
If  everywhere, then the probability of this event is zero:
the vectors  and  will always be the same and the servers will
always reject.

Consider instead that  and  differ at two or more indices
and yet the servers accept the vectors.
In this case,  and  differ at least at indices
 and  and yet  and  differ at only one index.
In this case, at some , we have that

If the client can find 
such vectors  and , then the client can find a collision
in .
Any adversary that violates the soundness property of
the protocol with non-negligible probability can then 
find collisions in  with non-negligible probability,
which is infeasible.

\nicepara{Zero Knowledge}
To show the zero-knowledge property we must show
that 
(1) each database server can simulate its view
of the protocol run and 
(2) the audit server can simulate
its view as well.
Each simulator takes as input all public parameters of
the system plus each server's private input.
Each simulator must produce faithful simulations whenever
the other parties are honest.

\medskip

Showing that the audit server can simulate its view
of the protocol run is straightforward: the audit
server receives values  and 
from the database servers and honest client.

Whenever the vectors differ at exactly one position the audit
server can simulate its view of the protocol.
To do so, the simulator picks length-
vectors  and  of random elements in 
the range of the hash function 
subject to the constraint
that the vectors are equal everywhere except 
at a random index .
The simulator outputs the two vectors as
the vectors received from servers  and .
The simulator computes the digests 
and .
The simulator sets .

The simulation of  and  is perfect, since 
these values are independently random values, as long as
all of the values  generated from
the seed  are distinct.
Since the servers sample each  from , the
probability of a collision is negligible.
The digests  and  are constructed exactly as in the 
real protocol run.
The values  and  that the auditor sees
in the real protocol are equal values masked by a
random -bit string.
The simulation of  and  is then perfect.

\medskip

We now must show that each database server can simulate
its view as well.
Since the role of the two database servers is symmetric, we need only
produce a simulator for server .

In the real protocol run, the database server interacts
with the honest client and honest audit server as follows:
\begin{enumerate}
  \item The honest client sends  to the database server.
  \item The database server produces a (possibly malformed) test vector
     and check value , and sends these values to the audit server.
  \item The audit server returns a bit  to the database server.
\end{enumerate}

We must produce a simulator  that simulates the first
and third flows of this protocol.
The simulator takes all of the public parameters of the system as implicit
input.
The simulator also takes the vector  and the shared random value
 as input.
The simulation proceeds as follows:
\begin{itemize}
  \item . 
        Simulator  produces a random PRG seed
        . 
        The simulator computes  using  and , 
        as in the real protocol.
        The simulator computes 
        and .
        The simulator outputs  as the output of the first flow, and outputs
        the state as:
        .
      \item .
        The simulator computes  and outputs
         if 
        
        The simulator outputs
         otherwise.
\end{itemize}

We now must argue that the simulation is accurate.
The simulation of  is perfect, since
this is just a random -bit value in the real protocol.

The distribution of  is 
statistically close to the distribution in the real protocol.
Whenever , in the real protocol, the audit
server will return , as in the simulation.
Whenever , in the real protocol, the audit
server will return , as in the simulation.
So the only time when the simulation and real protocol diverge
is when  but .
The probability (over the randomness of server  and 
the random oracle) that  outputs such a vector 
after making a polynomial number of random-oracle queries
is negligible in the security parameter.
Thus, the simulation is near perfect.

 \abbr{}{
\section{Security Proof Sketches for the\\Three-Server Protocol}
\label{app:smc-proof}

This appendix contains the security proofs for
the three-server protocol for detecting malicious
client requests (Section~\ref{sec:disrupt:smc}).

\nicepara{Completeness}
If the pair of keys is well-formed then 
the  and  vectors
(also the  and  vectors)
are equal at every index  and they 
differ at index .
Even in the negligibly unlikely event that the random seed
chosen at  is equal to the random seed 
chosen at , the test vectors  and 
will still differ because .
Thus, a correct pair of  and  vectors will pass the first 
 check.

The second  check is more subtle.
If the  vector is well formed then, 
letting  be the index where
the  vectors differ, we have:

If  is well-formed, 
then two test vectors  and 
differ only at index .


\nicepara{Soundness}
To show soundness, we must bound the probability that the audit
server will output ``1'' when the servers take a malformed pair 
of DPF keys as input.
If the  and  vectors are not equal everywhere
except at one index, the soundness of the  protocol
implies that the audit server will return ``0'' with overwhelming
probability when invoked the first time.

Now, given that the  vectors differ at one index, we
can demonstrate that if the  vectors pass the second
 check, then  is also well formed.
Let  be the index at which the  vectors differ.
Write the values of the  vectors at index 
as  and .
Then, by construction:

The first term of these two expressions are equal (because the
 vectors are equal almost everywhere).
Thus, to violate the soundness property, an adversary must construct
a tuple  such that the vectors
 and  differ at exactly one
index {\em and} such that .
This is a contradiction, however, since if 
 and  differ at exactly one index,
then: 

for some  and , by definition of .

\nicepara{Zero Knowledge}
The audit server can simulate its view of a successful
run of the protocol (one in which the input keys are
well-formed) by invoking the  simulator twice.
 \section{Security Proof Sketches for the\\Zero-Knowledge Protocol}
\label{app:zkp-proof}

\nicepara{Completeness}
Completeness for the first half of the protocol,
which checks the form of the  and  vectors,
follows directly from the construction of those vectors.

The one slightly subtle step comes in Step~\ref{item:check-zkp}
of the second half of the protocol. 
For the protocol to be complete, it must be that
 is zero at every index except one.
This is true because:


\nicepara{Soundness}
The soundness of the non-interactive zero-knowledge proof 
in the first half of the protocol guarantees that
the  vectors sum to  and that
the  vectors sum to  for
some values  and .

We must now argue that the probability that all servers
accept an invalid write request in the second half of the 
protocol is negligible.
The soundness property of the underlying
zero-knowledge proof used in Step~\ref{item:check-zkp}
implies that the vector  contains
commitments to zero at all indices except one.
A client who violates the soundness property produces
a vector  and seed value  such
that 
for some values  and , and that
.
This is a contradiction, however, since 
, by the first
half of the protocol, and so:

Finally, we conclude that .

\nicepara{Zero Knowledge}
The servers can simulate every message they receive during
a run of the protocol.
In particular, they see only Pedersen commitments, which
are statistically hiding, and non-interactive zero-knowledge
proofs, which are simulatable in the random-oracle 
model~\cite{bellare1993random}.

 }


\end{document}
