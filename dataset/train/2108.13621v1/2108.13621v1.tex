\documentclass[preprint,twocolumn,5p,12pt]{article}

\usepackage{amssymb}
\usepackage{subcaption}
\usepackage{graphicx}
\usepackage{caption}
\usepackage{xspace}
\usepackage{multirow}
\usepackage{rotating}
\captionsetup{font=footnotesize}
 \usepackage{url}
\usepackage{gensymb}
\usepackage [ table ]{ xcolor }
\usepackage[top=2cm, bottom=2cm, left=1.5cm, right=1.5cm]{geometry}
\usepackage{setspace}
\usepackage{morefloats}

\usepackage{commath}


\usepackage[affil-it]{authblk}
\usepackage[colorlinks=true,citecolor=blue, urlcolor=blue, linkcolor=blue]{hyperref}


\usepackage{setspace} 



\title{Spike time displacement based error backpropagation in convolutional spiking neural networks}\author{Maryam Mirsadeghi}
\author{Majid Shalchian\footnote{Corresponding Author \\Email addresses: \href{mailto://m.mirsadeghi@aut.ac.ir}{m.mirsadeghi@aut.ac.ir} (MM), \\ \href{mailto:// shalchian@aut.ac.ir}{ shalchian@aut.ac.ir} (MM), \\
\href{mailto:// s\_kheradpisheh@sbu.ac.ir}{ s\_kheradpisheh@sbu.ac.ir} (SRK), \\
\href{mailto:/timothee.masquelier@cnrs.fr}{timothee.masquelier@cnrs.fr} (TM)} }
\author{Saeed Reza Kheradpisheh}
\author{\\Timoth\'ee Masquelier}
\affil{\footnotesize  Department of Electrical Engineering, Amirkabir University of Technology, Tehran, Iran}
\affil{\footnotesize  Department of Computer and data Sciences, Shahid Beheshti University, Tehran, Iran}
\affil{\footnotesize   CerCo UMR 5549, CNRS Universit\'e Toulouse 3, France}

\date{}


\usepackage[absolute]{textpos}
\setlength{\TPHorizModule}{1cm}
\setlength{\TPVertModule}{1cm}

\begin{document}
\maketitle


\begin{abstract}
We recently proposed the STiDi-BP algorithm, which avoids backward recursive gradient computation, for training multi-layer spiking neural networks (SNNs) with single-spike-based temporal coding. The algorithm employs a linear approximation to compute the derivative of the spike latency with respect to the membrane potential and it uses spiking neurons with piecewise linear postsynaptic potential to reduce the computational cost and the complexity of neural processing.
In this paper, we extend the STiDi-BP algorithm to employ it in deeper and convolutional architectures. The evaluation results on the image classification task based on two popular benchmarks, MNIST and Fashion-MNIST datasets with the accuracies of respectively  and , confirm that this algorithm has been applicable in deep SNNs.
Another issue we consider is the reduction of memory storage and computational cost.
To do so, we consider a convolutional SNN (CSNN) with two sets of weights: real-valued weights that are updated in the backward pass and their signs, binary weights, that are employed in the feedforward process.
We evaluate the binary CSNN on two datasets of MNIST and Fashion-MNIST, and obtain acceptable performance with a negligible accuracy drop with respect to real-valued weights (about  and  drops, respectively).
\end{abstract}





\section{Introduction}
Spiking neural networks (SNNs) are recently attracting more and more attention due to their temporal nature and their event-driven processing paradigm which make them suitable for energy-efficient neuromorphic implementation.
However, due to the use of non-differentiable activation function and the temporal dynamics of SNNs, it is still a big challenge to train SNNs directly. Therefore, they have not yet reached the state-of-the-art accuracy compared to the artificial neural networks (ANNs), especially, in deep architectures with single-spike-based temporal coding. 


In temporal coding scheme, information is carried by the timing or the order of individual spikes~\cite{K1,K2,K3}. In the extreme case of single-spike-based temporal coding, neurons are allowed to fire at most once, which can radically reduce the computational and energy demand of SNNs.
So far, different solutions have been proposed to adapt the backpropagation (BP) algorithm to directly train SNNs with single-spike-based temporal coding.


Since the neuronal activity in single-spike coding is defined by the neurons firing time, two approaches are used to adapt BP to single-spike-based SNNs. The first approach is to compute or approximate the derivative of the firing time of each neuron with respect to its membrane potential~\cite{R7, R10, R18}. The second approach is to directly compute the firing time of each postsynaptic neuron based on the firing times of its presynaptic neurons~\cite{R8, R9, S1}.


Bohte, et al.~\cite{R7} introduced a temporal version of BP called SpikeProp which minimizes the temporal error of the network to train single-spike multilayer SNNs. They used exponentially SRM neuron models and employed a piecewise linear approximation to compute the derivative of the thresholding activation function at the firing time.
Kheradpisheh, et al.~\cite{R10} proposed temporal version of BP for a multi-layer SNN  with IF neurons and instantaneous synapses. To do so, they approximated the derivative of the neurons firing latency with respect to the  membrane potential by . By using  Rectified Linear Postsynaptic Potential (ReL-PSP) spiking neuron model, Zhang et al.~\cite{R18} could avoid such approximation and precisely compute this derivative. Mostafa~\cite{R8} defined the firing time of each neuron directly based on its presynaptic spike times. He used IF neurons with exponentially
decaying synaptic current.  Comsa, et al.~\cite{R9} employed a similar approach for SRM neuron models with alpha synaptic function. 
Zhou et al.~\cite{S1} developed \cite{R8} for implementing deep convolutional spiking neural networks (CSNNs) and achieved the state-of-the-art performance.

All aforementioned models but Zhang et al~\cite{R18} and Zhou et al.~\cite{S1}, have been used fully-connected networks with one or two hidden layers and they have not ever been applied to a deeper structure. In Zhang et al.~\cite{R18}, authors developed a deep convolutional spiking neural network consisted of two convolutional and two hidden layers~\cite{R18}. They used ReL-PSP based spiking neuron model and trained the network by employing temporal BP with recursive backward gradient. 
Zhou et al.~\cite{S1} extended \cite{R8} to implement deep architectures of SNN based on the VGG16 model~\cite{S2,S3} for CIFAR10 and the GoogleNet model~\cite{S4} for ImageNet.
To the best of our knowledge, These are the only implementation of a CSNN  with single-spike-based temporal coding. Other CSNNs are either a converted version of traditional CNNs~\cite{R4, R5, R6, R46} or they use rate coding or multi-spike per neuron schemes to directly apply BP on the network~\cite{R11,R12,R13}.


Recently, we proposed an error backpropagation algorithm based on the spike time displacements, called STiDi-BP, for multi-layer fully-connected SNNs with single-spike-based temporal coding~\cite{R3}. Similar to~\cite{R18, R7, R10}, we used a linear approximation to compute the derivative of neurons' firing time with respect to their membrane potential. However, in STiDi-BP, instead of recursively backpropagating the errors, we computed the desired firing time of neurons in each layer, and hence, we could locally compute the error just by comparing the actual and desired firing times. 

In this paper, we extend the STiDi-BP learning approach to be applicable in deeper and convolutional architectures. The evaluation results on two image classification tasks of MNIST and Fashion-MNIST datasets, with respectively  and  recognition accuracy, confirm the capabilities of the proposed algorithm in deep CSNNs.

Implementing SNNs with real-valued weights on neuromorphic devices requires a large amount of memory space and imposes a high load of floating-point computation. Binarizing the synaptic weights can help to reduce the memory footprint and the computational cost.
A few recent studies had tried to convert supervised binary artificial neural networks (BANNs) into equivalent binary SNNs (BSNNs)~\cite{R14,R15,R16,R19}. For the first time, Kheradpisheh et al. have introduced a direct supervised learning algorithm to train a two-layer fully connected SNN with binary synaptic weights\cite{R17}. But they didn't apply it to deeper SNNs or CSNNs. There is no other study to the best of our knowledge aimed at directly training deep supervised SNNs and CSNNs with binary weights. 
Here, we employ STiDi-BP to directly train a deep CSNN with binary synaptic weights which are the sign of real-valued weights. In the backward pass, we update the real-valued weights and the feedforward processing is performed by the binary weights.
We have evaluated the proposed network on MNIST and Fashion-MNIST datasets with categorization accuracies of  and , respectively, that has a negligible drop compared to real-valued-based CSNN.


\section{Forward pass}

Here, the proposed convolutional spiking neural network is comprised of a temporal coding input layer, a stack of interlaying convolutional and pooling layers for feature exraction, and a cascade of fully connected layers for the final classification. 
A temporal coding is used to convert the input image into a sparse spike train (i.e. one spike per pixel). After feeding the input codded image to the network, the convolutional operations are applied. 
In a convolutional layer, several filters are used to extract visual features from the previous layer which are presented in different feature maps. 
After each convolutional layer, a pooling layer is used to remove the redundancy and reduce the size of the feature maps.
A pooling layer does a nonlinear max pooling operation over a set of neighboring neurons to select a neuron with the highest activity (i.e., earliest spike).
After the last pooling layer, the fully connected layers are implemented to process the extracted features and do the final classification.

\subsection{Neuron Model}
We use a simple piecewise linear postsynaptinc potential
(PL-PSP) based spiking neuron model which has a very low computational cost compared to exponential PSP models~\cite{R3}. The membrane potential  of neuron 
at time  is the weighted summation of the PL-PSPs of its afferent neurons:

where,  is the synaptic weight connecting the presynaptic neuron  to the neuron  and  is the spike time of neuron .  is the kernel of the PL-PSP function that is illustrated in Figure~\ref{FIG1} and is described by the following equation:


here,  and  are time constants of the PL-PSP function and .
\begin{figure}
\centering
\includegraphics[width=0.5\textwidth]{FIG1.pdf} \caption{The piecewise linear postsynaptic potential caused by the presynaptic spike time .}
\label{FIG1}
\end{figure}

\subsection{Temporal coding}
Contrary to the costly rate-coding scheme in which the input image is encoded in the spike rates of the input neurons (i.e., the higher the pixel value, the higher the firing rate), we use the more efficient temporal coding scheme\cite{R3}, where the information is carried by the timing of individual spikes in a sparse manner. Each input neuron fires at most once such that neurons corresponding to pixels with higher intensities emit earlier spikes.
After feeding input spikes to the network, each neuron in the subsequent layer updates its membrane potential by integrating the voltage sum of all the presynaptic spikes and fires a spike right after crossing the threshold. Each neuron fires only once where its firing time determines the saliency of the extracted feature (such as the input layer), hence, the whole network obeys the sparse temporal coding.

\subsection{Convolutional layers}
There are several feature maps in a convolutional layer, each of which corresponds to a convolutional filter.
Neurons in a specific map share the same set of synaptic weights, and therefore, detect the same feature at different locations. 
Within a map , each convolutional neuron at location (,) receives spikes from neurons inside a certain window within all the feature maps of the previous layer. 
Therefore, each visual feature in a convolutional layer is obtained by combining several simpler features extracted in the previous layer.
The neuron computes its membrane potential  by applying the corresponding filter  on the received spike times according to the extended Eq.~\ref{eq1} and Eq.~\ref{eq2}.
Whenever  crosses the threshold , the convolutional neuron emits a spike, and regarding the single-spike-based coding, it will remain silent until the end of the simulation.

\subsection{Pooling layers}

In the rate-coding scheme, it is not possible to detect the neuron with maximum firing rate until the last simulation time point. 
While, in the proposed model, due to the use of temporal coding, we can simply perform the max pooling operation by propagating the first spike appearing in the input window of each pooling neuron.
To do so, in pooling layers, we use IF neurons with the threshold and the input synaptic weights of one. 
Each pooling neuron performs the maximum operation over a window in the corresponding feature map of the previous layer.
The first input spike from the neighboring afferent neurons activates the pooling neuron and makes it to fire a spike immediately. Each pooling neuron is permitted to fire at most once during the simulation time. 
Note that there is no learning for the pooling neurons.


\subsection{Fully connected layers}

The last stage of the proposed model which performs the final classification based on the extracted visual features of the convolutional part, is composed of cascading fully connected layers with PL-PSP based neurons.

Each neuron  in layer  integrates the weighted spikes according to Eq.~\ref{eq1} and Eq.~\ref{eq2} and emits a spike when its post-synaptic voltage  crosses the threshold. The neuron is allowed to fire at most once and the spike latency carries the information.
The same process has recurred in the following hidden layers and output layers.

In the output layer, the number of neurons is equal to the number of classes and each neuron is assigned to a different category. The output neuron that fires earlier than others is called the winner and it determines the class of the input image.

\section{Backward pass}

Here we apply the proposed learning algorithm to a deep convolutional spiking neural network to show that it is suitable and practical for deep structure of SNNs.

The error loss function of each layer is described independently by computing the time differences between the actual and the desired firing times. The desired firing times in the middle layers are calculated by displacing the presynaptic spike times such that the error is minimized.
Then, the GD is performed locally to update the synaptic weights without any backward recursive GD computation and to overcome the non-differentiality of SNNs, a linear approximation method described in \cite{R3} is employed.




\subsection{Fully connected layers}
The learning rule in the fully connected layers is the same as~\cite{R3}.
Here, we briefly introduce the proposed learning algorithm for the reader's convenience. More complete description of STiDi-BP is given in\cite{R3}.

The loss function of each layer  is calculated independently by the following equation:

where,  is the temporal error function for the postsynaptic neuron  obtained by substracting the desired and the actual firing times ( and , respectively) of the neuron  in the  layer:


In order to minimize the squared error loss function , the synaptic weights of layer  should be modified by using GD algorithm. 
To update each synaptic weight , we compute the gradient of loss function with respect to . Hence

where,  is the learning rate parameter and  is the weight connection between neuron  in layer  to the neuron .
 in Eq.~\ref{eq5} can be expanded to

where,  is the membrane potential of neuron  and  is the spike time of neuron . Neuron  has contribution to the membrane potential computation only if it fires before .
By using Eq.~\ref{eq3} and Eq.~\ref{eq4} we can express the first term as:

And, the third term is computed by considering Eq.~\ref{eq1} and Eq.~\ref{eq2}:


The second term, the derivative of the postsynaptic spike time with respect to its membrane potential, is calculated according to the following equation.
The details of computation are given in \cite{R3}.


By substituting Eq.~\ref{eq7}, Eq.~\ref{eq8} and Eq.~\ref{eq9} in Eq.~\ref{eq6}, the final equation for modifing the synaptic weights and minimizing the squared error loss function  is described by:


After computing the error loss function for each layer, we use Eq.~\ref{eq5} to update the synaptic weights of that layer and minimize the local error. Hence, we don't have backward recursive gradient computation. 
How to calculate target firing times is an important issue that will be discussed in the next section.

\subsubsection{Calculation of target firing times}
The target firing time is computed using different formula for the neurons of middle layer and output layer~\cite{R3}. 

In the output layer, we use a relative encoding method in which the correct output neuron should be encouraged to fire earlier than others. 
To do that, should take into account the input image category lablel. 
by assuming that the input image belongs to the  class, the  output neuron should fire at time , and others set to fire at later time .
Here  and  are the maximum and the minimum output firing times and  is a constant parameter used to provide resolution distance for the winner neuron.

There is a different situation for the middle layers. 
To compute the desired firing time of each neuron  in the  middle layer, we define the time displacement amount of the neuron spike time  to reduce the postsynaptic error . 
To do that, we compute the derivative of the postsynaptic error with respect to :

Here,  is the learning rate and  iterates over neurons in layer .
By expanding the Eq.~\ref{eq17} we have

The first and the second terms of Eq.~\ref{eq18} are calculated  the same as Eq.~\ref{eq7} and Eq.~\ref{eq8}, respectively and, the third term is expressed by considering Eq.~\ref{eq1} and Eq.~\ref{eq2}


Finally, the time displacement amount of presynaptic neuron  is described by
substituting  Eq.~\ref{eq7}, Eq.~\ref{eq8} and Eq.~\ref{eq19} in the RHS of Eq.~\ref{eq18}

The postsynaptic error  is reduced if the presynaptic neuron  fires a spike at time  instead of time . Hence,  should be considered as the target firing time of the neuron .

\subsection{Convolutional layers}

For each specific map  of a convolutional layer , the error loss function is calculated independently, by integrating the mean squares of the difference between the actual and the desired firing times:

where, d iterates over all the neurons of map . 
Then, the GD algorithm is locally employed to modify the synaptic weights of the corresponding filter  as follows:


Each synaptic weight of filter  () corresponds to the presynaptic neuron located at () with the spike firing latency of .
Therefore,  is updated as 


By expanding Eq.~\ref{eq32}, we have

The first, second and third terms of Eq.~\ref{eq33} are calculated by extending Eq.~\ref{eq7}, Eq.~\ref{eq8} and Eq.~\ref{eq9}, respectivly:





where,  is the spike firing latency of neuron  in map  of convolutional layer .

\section{Binarization}
Here we apply some modification to STiDi-BP learning rule to directly train the CSNN with binary synaptic weights .

The only change in the forward path is the use of binary weights  instead of real-valued weights, where . Hence, the membrane potential of the postsynaptic neuron  of layer   in Eq.~\ref{eq1} is rewriten as

 iterates over all presynaptic neurons and  is a shared scaling factor among all neurons of layer . Each layer has its own scaling factor which should be updated in addition to the synaptic weights in the learning phase. The scaling factor is used to make sure that neurons cross the threshold.

In the backward pass, we have two sets of weights, real-valued weights and binary weights.
For each layer , we update the real-valued weights by using Eq.~\ref{eq5} and Eq.~\ref{eq21} explained in section 3.2 and, update the scaling factor  as

here  is the learning rate parameter and  is calculated by using the following equation:


The first and second terms of Eq.~\ref{eq24} are calculated according to Eq.~\ref{eq7}  and Eq.~\ref{eq8}. For computing the third term we use Eq.~\ref{eq22}:




\section{Experiments and results}

In this section we evaluate the proposed STiDi-BP training algorithm on deep structure of spiking neural network for two image classification tasks: MNIST dataset and Fashion-MNIST dataset. We develop a single-spike-based temporal convolutional SNN with piecewise linear SRM neurons and consumes two different modes: real-valued weights and binary weights. In the following, each network (CSNN and binary CSNN) is examined separately.

\subsection{ Real-valued weights}
\subsubsection{MNIST dataset}
The MNIST dataset~\cite{mnist} is the most popular benchmark for spiking neural networks. It comprises of   grayscale training images and   grayscale testing images.
To evaluate the proposed learning algorithm on the MNIST dataset, we develop an Real-valued weights-base CSNN (R-CSNN) with the structure of , which consists of one convolutional layer, one pooling layer and one hidden layer followed by an output layer.
The convolutional layer is comprised of  neural maps with  convolution- window. The pooling-window of the pooling layer is of size  with the stride of . The hidden and the output layers are respectively consist of  and  neurons.
Here the maximum simulation time is  and other parameters of each layer are listed separately in Table~\ref{tab1}
 
\begin{table} 
\begin{center}
\caption{Model parameters for MNIST dataset in R-CSNN.}\label{tab1}
\resizebox{0.5\textwidth}{!}{\begin{tabular}{llllllc}  
\scriptsize
layer &  &   &  &  & initial weights \\ 
\hline
Convolutional & 80  & 0.001 & 1 & 5 & [0, 2] \\
Hidden &  &  0.01 & 1 & 50 & [0, 0.25] \\
Output &  &  0.001 & 1 & 10 & [0, 0.5] 
\end{tabular}}
\end{center}
\end{table}

In Table~\ref{tab2}, we compare the STiDi-BP with some recent reported results which used supervised learning algorithms. 
As shown, \cite{R11,R13} used CSNN structure and achieved the highest performance, while, they are based on rate coding which has great deal of computation.
In the area of single-spike-timing-based supervised learning algorithms 
\cite{R18,S1}, and this work are the only implementation of CSNN and other implementations \cite{R8,R9,R10,R3} are fully connected networks.
In \cite{R3}, we introduced STiDi-BP algorithm and achieved the accuracy of  with the network structure of . 
While, other fully connected SNNs\cite{R8,R9,R10,R18} employed the traditional temporal BP which requires backward recursive gradient computation.
Zhang et al. in \cite{R18} employed rectified linear PSP based spiking neuron models and developed two SNNs. They reached the accuracy of  for a fully connected network and  for CSNN with the structure of . 
Zhou et al.~\cite{S1} use IF neuron models with exponential decaying function and defined a direct relation between neuron’s pre and postsynaptic firing times same as \cite{R8}. They acheived  accuracy for CSNN with the structure of . 
Here we apply STiDi-BP to an R-CSNN architecture and acheive the state-of-the-art accuracy with the lower number of convolutional and hidden layers.

\begin{table*}  
\begin{center}
\caption{The classification accuracies of recent supervised SNNs with direct training on the MNIST dataset with some details such as input coding scheme and the network structure are provided in the table. The convolution layer and pooling layer are represented by C and P, respectively and layers are separated by -.} \label{tab2}
\begin{tabular}{llllc}  
\scriptsize
Model & structure & Coding &  Accuracy(). \\
\hline
Mostafa (2017)~\cite{R8}& 784-800-10 & Temporal & 97.2 \\
Comsa et al. (2019)~\cite{R9}& 784-340-10 & Temporal & 97.9 \\
Kheradpisheh et al. (2020)~\cite{R10}& 784-400-10 & Temporal & 97.4 \\
Mirsadeghi et al. (2020)~\cite{R3}& 784-350-10 & Temporal & 97.4 \\
Zhang et al.(2020)~\cite{R18}& 784-800-10 & Temporal & 98.5 \\
W.Zhange et al. (2020)~\cite{R11}& 15C5-P2-40C5-P2-300-10 & rate & 99.5 \\
Fang et al.(2020)~\cite{R13}& 128C3-P2-128C3-P2-2048-100-10  & rate & 99.6 \\
Zhang et al.(2020)~\cite{R18}& 16C5-P2-32C5-P2-800-128-10 & Temporal & 99.4 \\
Zhou et al.(2020)~\cite{S1}& 32C5-P2-16C5-P2-10 & Temporal & 99.3 \\
STiDi-BP in R-CSNN (This paper)& 40C5-P2-1000-10 & Temporal & 99.2 
\end{tabular}
\end{center}
\end{table*}

The mean firing time of each output neuron over the images of different categories and the mean required spikes of all layers are depicted in Figure~\ref{FIG3} and Figure~\ref{FIG4}, respectively.

\begin{figure}[ht]
\centering
\includegraphics[width=0.5\textwidth]{FIG3.pdf}  \caption{The mean firing time of each output neuron (rows)
over the images of different digit categories (columns) in R-CSNN.} \label{FIG3}
\end{figure}

\begin{figure}[ht]
\centering
\includegraphics[width=0.5\textwidth]{FIG4.pdf}  \caption{The mean required number of spikes in the input, convolutional, hidden, and total layers in R-CSNN.} \label{FIG4}
\end{figure}
According to Figure~\ref{FIG3}, Each output neuron tends to fire earlier for images of its corresponding category which confirms that to recognize each input digit, it is not necessary to give all its input spikes to the network. 
Here digit  has the maximum mean firing time because it covers the pixels that are common among most other digits. Therefore, the network needs much longer time to detect it.
On the other hand, Figure~\ref{FIG4} shows that the network is able to detect the class corresponding to the input image by firing a limited number of neurons in each layer which helps to make very rapid decisions about the input categories.
For example, the network needs only  spikes in total to correctly recognize digit , which has the maximum mean firing time of .
And, the maximum number of mean required spikes is related to the digit , which is only  spikes.

These two properties (that are illustrated in Figure~\ref{FIG3} and Figure~\ref{FIG4}), are the most important reasons for low cost and high computational speed in single-spike-based temporal SNNs.

This  is shown more clearly in Figure~\ref{FIG5}, where, the membrane potential of output neuron for a sample  test image and the accumulated input spikes until the , , , , and  time steps are depicted.
As soon as the membrane potential of an output neuron reaches the threshold, the network assigns the corresponding class to the input image and can stop the computations. 
Here, the membrane potential of  output neuron overtakes others and reaches the threshold at time step . 
As seen, there is no need to propagate all input spikes to determine the category of the input image. By propagating a limited number of input spikes up to the  time step, the membrane potential of the correct output neuron crosses the threshold and the network can classify the input image.

\begin{figure}
\centering
\includegraphics[width=0.5\textwidth]{FIG5.pdf}  
\caption{The trajectory of the membrane potential of all output neurons for sample   test image. The incoming input spikes up to the time step  contribute to the digit classification and the remaining spikes are ignored.} \label{FIG5}
\end{figure}



\subsubsection{Fashion-MNIST dataset}

Fashion-MNIST is a dataset of Zalando's article images~\cite{fashion} which has the same image size and structure of training and testing splits as MNIST, but it is more challenging classification problem.

Here we develop an R-CSNN with the structure of .
The maximum simulation time is  and other parameters of each layer are listed separately in Table~\ref{tab3}.

\begin{table}
\begin{center}
\caption{Model parameters for Fashion-MNIST dataset in R-CSNN.} \label{tab3}
\resizebox{0.5\textwidth}{!}{\begin{tabular}{lllllc}
\scriptsize
 layer &  &   &  &  & initial weights \\
\hline
convolutional& 80  & 0.0001 & 1 & 5 & [0, 2] \\
convolutional& 80  & 0.001 & 1 & 10 & [0, 1] \\
&  &  0.1 & 1 & 100 & [0, 1] \\
&  &  0.01 & 1 & 50 & [0, 1] \\
\end{tabular}}
\end{center}
\end{table}

The classification accuracies and characteristics of different approaches on Fashion-MNIST dataset are shown in Table~\ref{tab4}.

\begin{table*}
\begin{center}
\caption{The classification accuracies of recent supervised SNNs with direct training on the fashion-MNIST dataset with input coding scheme and the network structure are provided in the table. The convolution layer and pooling layer are represented by C and P, respectively and layers are separated by -.} \label{tab4}
\begin{tabular}{llllc}
\scriptsize
Model & structure & Coding &  Accuracy(). \\
\hline
Kheradpisheh et al. (2020)~\cite{R10}& 784-1000-10 & Temporal & 88.0 \\
Zhang et al.(2020)~\cite{R18}& 784-1000-10 & Temporal & 88.1 \\
W.Zhange et al. (2020)~\cite{R11}& 32C5-P2-64C5-P2-1024-10 & rate & 92.8 \\
Fang et al.(2020)~\cite{R13}& 128C3-P2-128C3-P2-2048-100-10   & rate & 93.8 \\
Zhang et al.(2020)~\cite{R18}& 16C5-P2-32C5-P2-800-128-10 & Temporal & 90.1 \\
STiDi-BP in R-CSNN (This paper)& 20C5-P2-40C5-P2-1000-10 & Temporal & \textbf{92.8}
\end{tabular}
\end{center}
\end{table*}

\cite{R11, R13} that achieve the highest performance with the convolutional structure, are based on rate coding scheme with the great deal of computation.
Among the temporal coding-based SNN approaches, \cite{R18} and this work are the only implementation of CSNN in which, the proposed learning algorithm outperforms and reaches the accuracy of  which is not much different from rate coding schemes.

The mean firing times of the output neurons for each categories of Fashion-MNIST are illustrated in Figure~\ref{FIG66}.
\begin{figure}
\centering
\includegraphics[width=0.5\textwidth]{FIG66.pdf} 
\caption{The mean firing times of the output neurons over the Fashion-MNIST categories in R-CSNN.} \label{FIG66}
\end{figure}
The correct output neuron tends to fire earlier than the others for its corresponding category, yet the difference between the mean firing times of the correct and some other output neurons is small. This is due to the similarities between images of different categories in Fashion-MNIST compared to MNIST.

These similarities are more clearly shown in Figure~\ref{FIG6}, where, the confusion matrix of the proposed learning algorithm on Fashion-MNIST is depicted.
According to Figure~\ref{FIG6}, the network confuses T\_shirt, shirt, dress, coat and pullover due to their similar images. And, the same goes for ankle boots, sandals, and sneakers that have close mean firing times together. 
For example, the output neuron corresponding to the `Ankle boot' sample has the mean firing time of , while, it fires respectively at  for `sneaker' and `sandal' samples, which are very close to .
\begin{figure}[ht]
\centering
\includegraphics[width=0.5\textwidth]{FIG6.pdf} 
\caption{The confusion matrix of R-CSNN on Fashion-MNIST.} \label{FIG6}
\end{figure}

In Table~\ref{tab5}, we show the mean firing time of correct output neurons and the mean required number of spikes in all layers. 
Again, it is not necessary to give all the input spikes of an image to the network and by firing a limited number of neurons in each layer, the network can recognize the image category.

\begin{table*}
\begin{center}
\caption{The mean firing time (MFT) of the correct output neuron and the mean required number (MRN) of spikes in all the layers for each category of Fashion-MNIST in R-CSNN.} \label{tab5}
\begin{tabular}{lllllllllllc}
\scriptsize
Category & T\_shirt & Trouser &  Pulloiver & Dress & Coat & Sandal & Shirt & Sneaker & Bag & Ankle boot \\
\hline
MFT & 73 & 68 & 75 & 72 & 74 & 70 & 77 & 64 & 72 & 66 \\
MRN & 2836 & 2096 & 3227 & 2386 & 3169 & 1886 & 3020 & 1771 & 3015 & 2592
\end{tabular}
\end{center}
\end{table*}

\subsection{Binary weights}  
\subsubsection{MNIST dataset}
Here we apply STiDi-BP to directly train a CSNN with binary synaptic weights (B-CSNN)  and evaluate it on the MNIST dataset. 
The network has the same structure and parameters as R-CSNN in section , except that the scaling factor (SCF) of each layer as another trainable parameter has been added to it. 
The parameter settings are provided in Table~\ref{tab6}.
In the convolutional layer, the value of the parameter  is shared between all the weights.

\begin{table}
\begin{center}
\small
\caption{Model parameters for MNIST dataset in B-CSNN.}  \label{tab6}
\resizebox{0.5\textwidth}{!}{\begin{tabular}{lllc }
 layer &  & initial SCF \\
\hline
convolutional & 0.0001 & [0, 2] \\
Hidden &  0.001 & [0, 3] \\
Output & 0.0001 & [0, 2] 
\end{tabular}}
\end{center}
\end{table}


The mean required number of spikes in each layer is depicted in Figure~\ref{FIG7}. 

\begin{figure}
\centering
\includegraphics[width=0.5\textwidth]{FIG7.pdf}
\caption{The mean required number of spikes in the input, convolutional, hidden, and total layers in B-CSNN.} \label{FIG7}
\end{figure}

By comparing Figure~\ref{FIG7} with Figure~\ref{FIG4},
we see that the mean required number of spikes in the input and convolutional layers are almost equal to the R-CSNN and the difference is in the hidden layer, where, B-CSNN needs more number of spikes than R-CSNN.
In fact, due to the use of binary weights, the B-CSNN should wait for more time steps in the hidden layer to detect the corresponding category of an input image. Therefore more spikes are generated in the hidden layer. 
For example, the network needs about  spikes in total layers to correctly recognize digit , while, there was  spikes in R-CSNN.

In Table~\ref{tab7}, we show the classification accuracy of STiDi-BP on two networks of R-CSNN and B-CSNN and compare with BS4NN\cite{R17}. As mentioned before, BS4NN is the only network aimed at directly training multi-layer temporal SNNs with binary weights.
Because of employing convolutional structure, B-CSNN outperforms the BS4NN. And, compared to R-CSNN, the performance of B-CSNN only dropped by  which is due to the use of binary weights.

\begin{table}
\begin{center}

\caption{The classification accuracies of recent binary SNNs with direct training on the MNIST dataset.} \label{tab7}
\resizebox{0.5\textwidth}{!}{\begin{tabular}{lllc}
\scriptsize
 Model & structure &  Accuracy() \\
\hline
BS4NN\cite{R17} & 784-600-10 & 97.0 \\
R-CSNN &  40C5-P2-1000-10 & 99.2 \\
B-CSNN & 40C5-P2-1000-10 & 98.6 
\end{tabular}}
\end{center}
\end{table}


\subsubsection{Fashion-MNIST dataset}

Here we evaluate B-CSNN on the Fashion-MNIST dataset. The network has the structure of  with the initial scaling factors in range . The value of  is  for the convolutional layers and  for the hidden and the output layers. In the convolutional layers, the value of  is different for each convolutional filter and is trained independently of the others.
Other parameters are the same as Table~\ref{tab3}.

We illustrate the classification accuracy of the proposed learning algorithm on B-CSNN and R-CSNN in Table~\ref{tab8} and compare them with the BS4NN.

\begin{table}
\begin{center}
\caption{The classification accuracies of recent binary SNNs with direct training on the Fashion-MNIST dataset.} \label{tab8}
\resizebox{0.5\textwidth}{!}{\begin{tabular}{lllc }
\scriptsize
 Model & structure &  Accuracy() \\
\hline
BS4NN\cite{R17} & 784-1000-10 & 87.3 \\
R-CSNN & 20C5-P2-40C5-P2-1000-10 & 92.8 \\
B-CSNN & 20C5-P2-40C5-P2-1000-10 & 92.0 
\end{tabular}}
\end{center}
\end{table}

As seen, B-CSNN outperforms the BS4NN, due to the use of convolutional structure. And, there is only  dropped compared to R-CSNN. 
Therefore, the proposed algorithm is able to directly train a SNN with binary weights without any significant drop in the performance of the network.

The mean firing time of correct output neurons along with the mean required number of spikes of all layers are depicted in Table~\ref{tab9}.
As seen, the mean required number (MRN) of spikes of all layers in the B-CSNN is more than R-CSNN for each category. This can be due to the use of binary weights which makes B-CSNN to wait for more time steps to detect the corresponding category of an input image.

\begin{table*}
\begin{center}
\caption{The mean firing time (MFT) of the correct output neuron and the mean required number (MRN) of spikes in all the layers for each category of Fashion-MNIST in B-CSNN.}  \label{tab9}
\begin{tabular}{lllllllllllc}
\scriptsize
Category & T\_shirt & Trouser &  Pullover & Dress & Coat & Sandal & Shirt & Sneaker & Bag & Ankle boot \\
\hline
MFT & 74 & 70 & 74 & 73 & 72 & 71 & 75 & 68 & 71 & 67 \\
MRN & 3013 & 2255 & 3418 & 2541 & 3351 & 2023 & 3204 & 1824 & 3201 & 2742 
\end{tabular}
\end{center}
\end{table*}

\section{Discussion}
In this paper, we used a convolutional SNN, as the deep structure of SNN, with two modes of real-valued and binary weights. Then, we employed the proposed supervised learning algorithm, STiDi-BP, to directly train both networks. 
In the learning phase, we applied gradient descent (GD) to each layer independently to discard the backward recursive gradient computation. 
Therefore, the desired firing times at the middle layers should be defined by using presynaptic spike time displacement, while, the desired output spike times were defined by using the relative timing of output neurons.

The most important advantage of our proposed approach is the use of temporal single-spike coding. In such methods, calculations in the backward direction are only performed at the actual firing times and it is not required to backpropagate the error in all the time steps which decreases the computational cost and the required storage space.
The space complexity in each layer during the backward pass is . While, in the rate coding schemes, the space complexity in each layer in the backward pass is , where  is the number of time steps, due to backpropagating the error in all the time steps.
Also, contrary to the rate-based CSNNs, the max-pooling operation can be simply done by propagating the first spike emerging inside the receptive window of each pooling neuron. 

Many of the existing supervised learning algorithms are based on rate or multi-spike coding~\cite{B6,B7,B9,B10,B11,B12,B13} which require expensive computation.
There are few works that focus on the single-spike-based temporal coding~\cite{R3,R7,R8,R9,R10,R17,R18,S1}.
Among the existing single-spike-based temporal approaches, Zhang et al.~\cite{R18} and Zhou et al.~\cite{S1} are the only implementation of a convolutional SNN architecture with single-spike-timing-based supervised learning algorithms and others are based on fully connected networks.

With the exception of \cite{R18,S1}, the other CSNNs have been presented in two forms:
1- the converted version of traditional CNNs~\cite{R4,R5,R6,R46} and,
2- CSNNs that use rate coding or multi-spike-based coding schemes to be directly trained by BP~\cite{R11,R12,R13}.
These approaches are computationally expensive due to the use of rate coding scheme and are based on backward recursive gradient computation.

Experimental results confirmed that the proposed approach can be applied to a CSNN and it achieves acceptable results compared to \cite{R18}.
The CSNN trained by this algorithm reaches  accuracy on MNIST dataset and accuracy of  on Fashion-MNIST as the more challenging dataset.

Adapting the proposed learning rule to CSNN, removes backward recursive gradient computation, and reduces the complexity of neural processing and computational cost.

Binarizing the synaptic weights is another important improvement which helps optimization in hardware implementations of deep SNNs~\cite{A13, A43}.
Current Binary SNNs are the converted version of pre-trained BANNs~\cite{R14,R15,R16,R19}.
They train a BANN by using traditional BP and then, convert it into the equivalent BSNN with rate-based neural coding. 
Here, we developed a CSNN with binary weights, which are the sign of real-valued weights, and employed the proposed learning rule to directly train it. 
The forward pass is done with the binary weights and, in the backward pass, we updated the real-valued weights.
The proposed BCSNN uses single-bit of memories for implementing binary synapses and employs only one full-precision scaling factor in each layer or each convolutional filter. Therefore, the network size can be reduced by  compared to a network with -bit floating-point synaptic weights~\cite{R18}.
Also, due to the use of single-bit synapses, the multiplier blocks that impose high load of floating-point computation to the network can be replaced by one unit increment and decrement blocks~\cite{R18}.
The evaluation results shows that the BCSNN has a negligible performance drop compared to the CSNN, respectively  and  accuracy drop on MNIST and Fashion-MNIST datasets. While it has more advantages than the CSNN in terms of hardware implementation.
To the best of our knowledge, this is the first implementation that aim to directly train a deep structure of single-spike-based temporal SNNs with binary synaptic weights.
However, one of the most important challenges we face is to make the network deeper to solve more complex problems such as CIFAR10 or ImageNet classification which can be our future topic.




\begin{singlespace}


\begin{thebibliography}{10}

\bibitem{K1}
SR.~Kheradpisheh, M.~Ganjtabesh and T.~Masquelier, Bio-inspired unsupervised learning of visual features leads to robust invariant object recognition, {\em Neurocomputing} {\bf 205}  (2016)
  382--392.

\bibitem{K2}
M.~Mozafari, SR.~Kheradpisheh, T.~Masquelier, A.~Nowzari-Dalini and M.~Ganjtabesh, First-Spike-Based Visual Categorization Using Reward-Modulated STDP, {\em IEEE Transactions on Neural Networks and Learning Systems} {\bf 29}  (2018) 
  6178-6190.

\bibitem{K3}
 T.~Masquelier and SR.~Kheradpisheh, Optimal Localist and Distributed Coding of Spatiotemporal Spike Patterns Through STDP and Coincidence Detection, {\em Frontiers in Computational Neuroscience}  {\bf 12} (2018) 74.

\bibitem{R7}
S.~Bohte, J.~Kok and H.~Poutre, Error-backpropagation in temporally encoded networks of spiking neurons, {\em Neurocomputing} {\bf 48}  (2002)
  17--37.

\bibitem{R8}
H.~Mostafa, Supervised learning based on temporal coding in spiking neural networks, {\em IEEE Transactions on Neural Networks and Learning Systems} {\bf 29}  (2017) 
  3227-3235.

\bibitem{R9}
IM.~Comşa, K.~Potempa, L.~Versari, T.~Fischbacher, A.~Gesmundo, J.~Alakuijala , Temporal Coding in Spiking Neural Networks with Alpha Synaptic Function, {\em IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)}  (2021)  1 - 14.

\bibitem{S1}
SH.~Zhou, X.~Li, Y.~Chen, ST.~Chandrasekaran and A.~Sanyal, Temporal-Coded Deep Spiking Neural Network with Easy Training and Robust Performance, {\em arXiv preprint arXiv:1909.10837v3}   (2020).

\bibitem{S2}
Sh.~Liu and W.~Deng, Very deep convolutional neural network based image classification using small training sample size, {\em 2015 3rd IAPR Asian Conference on Pattern Recognition (ACPR)}   (2015). 
  730-734

\bibitem{S3}
K.~Simonyan and A.~Zisserman, Very Deep Convolutional Networks for Large-Scale Image Recognition, {\em arXiv preprint arXiv:1409.1556}  (2015)  607--617.

\bibitem{S4}
C.~Szegedy, W.~Liu, Y.~Jia, P.~Sermanet, S.~Reed, D.~Anguelov, D.~Erhan, V.~Vanhoucke and A.~Rabinovich , Going deeper with convolutions  {\em Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. } (2015)  1-9

\bibitem{R10}
SR.~Kheradpisheh and T.~Masquelier, Temporal backpropagation for spiking neural networks with one spike per neuron, {\em International Journal of Neural Systems} {\bf 30}  (2020) 2050027.

\bibitem{R18}
M.~Zhang, J.~Wang, B.~Amornpaisannon, Z.~Zhang, V.~Miriyala, A.~Belatreche, H.~Qu, J.~Wu, Y.~Chua, E.~Carlson and H.~Li, Rectified Linear Postsynaptic Potential Function for Backpropagation in Deep Spiking Neural Networks, {\em arXiv preprint arXiv:2003.11837}  (2020).

\bibitem{R4}
S.~Kundu, G.~Datta, M.~Pedram, and P.A.~Beerel, Towards Energy-Efficient Deep Spiking Neural Networks by Limiting Spiking Activity via Attention-Guided Compression, {\em Proceedings of the IEEE/CVF Winter Conference on Applications of Computer Vision (WACV)}   (2021)  3953-3962.

\bibitem{R5}
N.~Muramatsu and H.~Yu, Combining Spiking Neural Network and Artificial Neural Network for Enhanced Image Classification, {\em arXiv preprint arXiv:2102.10592}, (2021).

\bibitem{R6}
A.~Sengupta, Y.~Ye, R.~Wang, C.~Liu and K.~Roy, Going Deeper in Spiking Neural Networks: VGG and Residual Architectures, {\em Frontiers in Neuroscience}{\bf 13}   (2019) 95.

\bibitem{R46}
B.~Rueckauer and SH.~Liui,  Conversion of analog to spiking neural networks using sparse temporal coding, {\em 2018 IEEE International Symposium on Circuits and Systems (ISCAS)},  (2018), pp. 1-5.

\bibitem{R11}
W.~Zhang and P.~Li, Temporal Spike Sequence Learning via Backpropagation for Deep Spiking Neural Networks, {\em arXiv preprint arXiv:2002.10085}, 2020.

\bibitem{R12}
C.~Lee, SS.~Sarwar, P.~Panda, G.~Srinivasan, and K.~Roy, Enabling Spike-Based Backpropagation for Training Deep Neural Network Architectures, {\em Frontiers in Neuroscience}{\bf 14}   (2020)   p. 119.

\bibitem{R13}
W.~Fang, Zh.~Yu, Y.~Chen, T.~Masquelier, T.~Huang and Y.~Tian,
 Incorporating Learnable Membrane Time Constant to Enhance Learning of Spiking Neural Networks, {\em arXiv preprint arXiv:2007.05785}  (2020).

\bibitem{R3}
M.~Mirsadeghi, M.~Shalchian, SR.~Kheradpisheh and T.~Masquelier,
  STiDi-BP: Spike time displacement based error backpropagation in multilayer spiking neural networks,
  {\em Neurocomputing} {\bf 427}   (2021)
  131--140.

\bibitem{R14}
S.~Esser, R.~Appuswamy, P.~Merolla, J.~Arthur and D.~Modha, Backpropagation for Energy-Efficient Neuromorphic Computing, {\em Curran Associates, Inc.} {\bf 28}  (2015).

\bibitem{R15}
S.~Esser, P.~Merolla, J.~Arthur, A.~Cassidy, R.~Appuswamy, A.~Andreopoulos, D.~Berg, J.~McKinstry, T.~Melano, D.~Barch, C.~di Nolfo, P.~Datta, A.~Amir, B.~Taba, M.~Flickner and D.~Modha, Convolutional networks for fast, energy-efficient neuromorphic computing, {\em Proceedings of the National Academy of Sciences of the United States of America}{\bf 113}(41)   (2016)  11441-11446.

\bibitem{R16}
B.~Rueckauer, IA.~Lungu, Y.~Hu, M.~Pfeiffer and SC.~Liu, Conversion of Continuous-Valued Deep Networks to Efficient Event-Driven Networks for Image Classification, {\em Frontiers in Neuroscience} {\bf 11} (2017)  p. 682.

\bibitem{R19}
Y.~Wang and Y.~Xu and R. ~Yan and H.~Tang, Deep Spiking Neural Networks with Binary Weights for Object Recognition, {\em
  IEEE Transactions on Cognitive and Developmental Systems}  (2020)  1-1.

\bibitem{R17}
SR.~Kheradpisheh, M.~Mirsadeghi, T.~Masquelier, BS4NN: Binarized Spiking Neural Networks with Temporal Coding and Learning, {\em arXiv preprint arXiv:2007.04039}  (2020).

\bibitem{mnist}
Y.~Lecun, L.~Bottou, Y.~Bengio and P.~Haffner, Gradient-based learning applied to document recognition,
  {\em Proceedings of the IEEE} {\bf 86}(11)   (1998)  2278-2324.

\bibitem{fashion}
Han Xiao and Kashif Rasul and Roland Vollgraf, Fashion-MNIST: a Novel Image Dataset for Benchmarking Machine Learning Algorithms, {\em arXiv preprint arXiv:1708.07747} (2017).

\bibitem{B6}
E.~Neftci, C.~Augustine, S.~Paul nd G.~Detorakis, Georgios, Event-driven random back-propagation: Enabling neuromorphic deep learning machines, {\em Frontiers in Neuroscience} {\bf 11}  (2017)  p. 324.

\bibitem{B7}
J.~Lee, T.~Delbruck, and M.~Pfeiffer, Training deep spiking neural networks using backpropagation, {\em Frontiers in Neuroscience} {\bf 10}  (2016) p. 508.

\bibitem{B9}
S.~Bohte, Error-backpropagation in networks of fractionally predictive spiking neurons, {\em International Conference on Artificial Neural Networks}  (2011)  60--68.

\bibitem{B10}
Y.~Wu, L.~Deng, G.~Li, J.~Zhu and L.~Shi, Spatio-temporal backpropagation for training high-performance spiking neural networks, {\em Frontiers in Neuroscience} {\bf 12}  (2018).

\bibitem{B11}
F.~Zenke and S.~Ganguli, Superspike: Supervised learning in multilayer spiking neural networks, {\em Neural Computation} {\bf 30}(6)   (2018) pp. 1514--1541.

\bibitem{B12}
SB.~Shrestha and G.~Orchard,
 SLAYER: Spike layer error reassignment in time, {\em
Advances in Neural Information Processing Systems}   (2018) pp. 1412--1421.

\bibitem{B13}
D.~Huh, and TJ.~Sejnowski, Gradient descent for spiking neural networks, {\em Advances in Neural Information Processing Systems}
    (2018)  pp.1433--1443.

\bibitem{A13}
J.~Laydevant, M.~Ernoult, D.~Querlioz and J.~Grollier, Training Dynamical Binary Neural Networks with Equilibrium Propagation, {\em arXiv preprint arXiv:2103.08953}, (2021).

\bibitem{A43}
J.~Cho, Y.~Jung, S.~Lee and Y.~Jung, Reconfigurable Binary Neural Network Accelerator with Adaptive Parallelism Scheme, {\em Electronics} {\bf 10}(3)  (2021).


\end{thebibliography}




\end{singlespace}
\end{document} 
