\documentclass{sig-alternate}
\usepackage{amssymb}
\usepackage{graphicx}
\usepackage{hyperref}
\hypersetup{colorlinks=false}

\usepackage{algorithm}
\usepackage{algorithmic}
\renewcommand{\algorithmicrequire}{\textbf{Input}:}
\renewcommand{\algorithmicensure}{\textbf{Output}:}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{amssymb}

\newtheorem{theorem}{Theorem}[section]
\newtheorem{lem}[theorem]{Lemma}
\newtheorem{prop}[theorem]{Proposition}
\newtheorem{thm}[theorem]{Theorem}
\newtheorem{cor}[theorem]{Corollary}
\newdef{rem}{Remark}
\newdef{exmp}{Example}
\newtheorem{defn}[theorem]{Definition}
\numberwithin{theorem}{section} \numberwithin{equation}{section}

\begin{document}

\title{ Simultaneous Integer Relation Detection and\\
Its an Application}

\numberofauthors{1}
\author{
\alignauthor Chen Jing-wei ,\ Feng
Yong\titlenote{Corresponding author.},\ Qin
Xiao-lin\
and \ \ Zhang Jing-zhong\\
       \affaddr{\ }\\
       \affaddr{{ Laboratory of Computer Reasoning and
        Trustworthy Computation,}}\\
       \affaddr{{University of Electronic Science and Technology of China, Chengdu 610054, China}}\\
       \affaddr{{Laboratory for Automated Reasoning and
       Programming, Chengdu Institute of} }\\
       \affaddr{{Computer Applications, Chinese Academy of Sciences, Chengdu 610041, China}}\\
      \email{
         {{\small \texttt{velen.chan@163.com\ \ \ \ yongfeng,qinxl@casit.ac.cn\ \ \ \
         zjz101@yahoo.com.cn}}}}
} \maketitle

\begin{abstract}
Let . A
simultaneous integer relation (SIR) for  is a vector  such that
 for . In this
paper, we propose an algorithm SIRD to detect an SIR for real
vectors, which constructs an SIR within  arithmetic operations, where  is the least
Euclidean norm of SIRs for . One
can easily generalize SIRD to complex number field. Experimental
results show that SIRD is practical and better than another
detecting algorithm in the literature. In its application, we
present a new algorithm for finding the minimal polynomial of an
arbitrary complex algebraic number from its an approximation, which
is not based on LLL. We also provide a sufficient condition on the
precision of the approximate value, which depends only on the height
and the degree of  the
algebraic number.\end{abstract}



\section{Introduction}
\label{sec:introduction}

Let
  be vectors in ,
and denote  by . A
\emph{simultaneous integer relation} (SIR) for  is a vector  such that , i.e.  for . For short, we also call   an SIR for . When , we say that  is an integer relation for
.
The problem of detecting integer relations for a rational or real vector is quite old.
Historical surveys can be found in \cite{Ber1971, FF1979,
Bre1982, HJL1989, FBA1999}. Among these integer relation detecting
algorithms, the HJLS algorithm \cite{HHL1986, HJL1989} and the PSLQ
algorithm \cite{FB1992, FBA1999} have been used frequently.

In the present paper, using  the technique to construct the
hyperplane matrix in HJLS and a generalized method of the matrix
reduction from PSLQ we propose an algorithm SIRD, which can be
used to detect an SIR for  real vectors. The cost of our algorithm is at most  exact arithmetic operations for detecting an SIR for
, where  represents the least Euclidean norm of SIRs
for . Furthermore, our detecting algorithm SIRD  either always
finds an SIR for  if one exists or proves that there are no SIRs
for  of norm less than a given size. Experimental results show
that SIRD is practical.

In application, we successfully apply  SIRD to find the minimal
polynomial of an algebraic number  with
degree and height at most  and  respectively from its an
approximation  satisfying , and propose the
corresponding algorithm MPF, where  the
minimal polynomial of an algebraic number  is the unique
primitive polynomial  of least degree such
that .
In fact, for  from  to  we run  SIRD with
,
 as its input and then an exact SIR for
 has been detected. We provide  a sufficient controlling on  and prove that
such an  is sufficient to enable an exact SIR for
 and  to be also an SIR for
 and ,
where  depends only on  and , as in
(\ref{eq:error-controlling}). It implies the correctness of MPF and
is better than already existing results in \cite{Jus1989,QFC2009}.
\subsection{Related Works}
In \cite{HHL1986, HJL1989}, J. Hastad, B. Just, J. C. Lagarias, and
C. P. Schnorr not only presented the HJLS algorithm and the first
rigorous proof of a `polynomial time' bound for a relation finding
algorithm but also proposed a simultaneous relations algorithm (see
 \cite[section 5]{HJL1989}), whereas HJLS
 is numerically unstable. The unstable examples can be
found in \cite{FB1992, FBA1999}. In their draft \cite{RS1997}, C. R{\"o}ssner and C. P.
Schnorr studied the case of  by using a modified HJLS
algorithm. But for the moment, \cite{RS1997} is still in a
preliminary state with some open problems. The PSLQ algorithm,
together with related lattice reduction schemes such as LLL
\cite{LLL1982}, was named one of ten ``algorithms of the twentieth
century'' by the publication \emph{Computing in Science and
Engineering} (see \cite{DS2000, BBC2007}), and is now extensively
used in Experimental Mathematics, with applications such as
identification of multiple zeta constants,
a new formula for , finding algebraic relations and so on (see \cite{BB2001, BBC2007, BB2009}). Moreover,
PSLQ is numerically stable and can be easily generalized to complex
number field and Hamiltonian quaternion number field (see
\cite{FBA1999}), but
 it is not suitable to
detect an SIR for several real vectors.\\

The SIRD algorithm in this paper is to detect an SIR for  real
vectors and can be applied to detect an integer relation in
 for a
 complex vector or a Hamilton quaternion number vector. A significant
body of experimental data shows that SIRD is practical and better
than the HJLS simultaneous relations algorithm.



In fact, the MPF algorithm in this paper is a  positive answer to
the following interesting question: Suppose we are given an
approximation to an algebraic number , and two bounds on the
degree and  the size of the coefficients of its minimal polynomial
respectively. Is it possible to infer the minimal polynomial? The
question was raised, independently, by Manuel Blum  in theoretical
cryptography (see \cite{KLL1984,KLL1988}) and the last author of
this paper  in automated reasoning (see \cite{YZH1996}). The first
complete answer to this question, KLL algorithm, was presented by R.
Kannan, A.K. Lenstra and L. Lov{\'a}sz in \cite{KLL1984, KLL1988} by
using the celebrated lattice reduction algorithm LLL \cite{LLL1982}.
In the computer algebra system \emph{Maple}, the built-in function
\texttt{PolynomialTools:-MinimalPolynomial()} is a function to find
a polynomial of degree  (or less) with small integer coefficients
which has the given approximation  of an algebraic number as one
of its roots and is based on  KLL algorithm. The correctness of the
polynomial returned by the built-in function
depends on the accuracy of the approximation (see \emph{Maple}'s Help). From another aspect, the minimal
polynomial of an algebraic number  with exact degree  can
be found by detecting an integer relation for the vector . Besides
HJLS, B. Just also presented an algorithm to detect integer relations for
a given vector consists of algebraic numbers in \cite{Jus1989}. We
can apply Just's algorithm or  HJLS  to the vector  for
finding the minimal polynomial of .
However, both Just's algorithm and HJLS are not numerically stable, as mentioned previously. All these
algorithms are based on LLL. Two authors of this paper presented a
method to reconstruct a rational number from its an approximation by
using continued fraction in \cite{ZF2007}. It may be viewed as an
answer to a special case of  the question.
Based on PSLQ, one can find algebraic relations, such as \cite{BC1999, BL2000, BHM2002, BBK2006}, whereas these
articles did not involve the minimal polynomial finding. The authors
of this paper also presented an algorithm in \cite{QFC2009} for
finding the minimal polynomial of a real algebraic number from its
an approximation. However, these PSLQ based algorithms can not deal
with complex algebraic numbers since PSLQ only outputs  a relation
in Gaussian integer ring
 for a complex vector. 


Fortunately, our simultaneous integer relation detection algorithm
SIRD in present paper can be used to overcome these pitfalls.
Applying SIRD to one or two real vectors, we present another
affirmative answer, the MPF algorithm, to the question above. We
show that MPF is a more efficient minimal polynomial finding
algorithm comparing with the algorithms in \cite{Jus1989,QFC2009}
and provide a sufficient condition on the error controlling, from
which we can claim that the
polynomial returned by MPF is the exact minimal polynomial of the algebraic number that we
only know an approximate value and two bounds on its degree and
height. Although a  similar even better complexity can be obtained
by KLL, MPF has its own meaning since it is a new method without using LLL reduction.

\textbf{{Road-map.}} In section \ref{sec:The Simultaneous Integer
Relation Detecting Algorithm} and \ref{sec:The SIRD algorithm} we
first give some preliminaries, and then present the SIRD algorithm
and analyze it. We report on some experimental results about the
performance of SIRD in section \ref{sec:Performance results}, apply
SIRD to find the minimal polynomial of an algebraic number from its
an approximation and propose the MPF algorithm in section
\ref{sec:finding-minimal-polynomial}, in which we also analyze  MPF
and present the result of error controlling. We conclude this paper
with section \ref{sec:conclude}.

\textbf{{Notations.}} Throughout this paper, ,
, and  are the sets of integers,  real
numbers, and complex numbers respectively. The real and imaginary
parts of  will be denoted Re and Im
respectively. For , . All vectors in
this paper are column vectors, and will be denoted in bold.  If
, then ~~represents
its Euclidean norm, i.e. , where~ is the inner product of two vectors.
We denote  identity matrix by . Given a matrix , we denote its transpose by , its trace by
tr, its determinant by , and its Frobenius norm by
 , i.e. . We say that a matrix  is lower trapezoidal if
 for .  is the group of
 unimodular matrix with entries in . The
height of a vector is defined by the maximum of all the absolute
values of its entries. For a polynomial , we denote by  its degree with respect to ,
 its one norm,
  its Euclidean length, and
height its height.


\section{Preliminaries}
\label{sec:The Simultaneous Integer Relation Detecting Algorithm}

In what follows we always suppose that  are linearly independent vectors in ,
where . Obviously, we
have . We denote by  the matrix , and suppose that 
satisfies
 unless otherwise specified. For  not satisfying (\ref{eq:suppose-on-x}),
exchanging some rows of  produces , where  is an
appropriate matrix in . And then we detect an SIR
for . If  is an SIR for , then 
is an SIR for .
\subsection{Hyperplane Matrix}\label{subsec:Hyperplane-matrix}

\begin{defn}[Hyperplane Matrix]\label{def:Hyperplane-matrix}
Let~. A hyperplane matrix  with respect to  is any matrix 
 such that  and the columns of  
.
\end{defn}

Now we introduce a method to construct a hyperplane matrix for  .

Let ~form a standard basis of
~, i.e. the -th entry of  is 
and others are . By performing the process of standard
Gram-Schmidt orthogonalization to  in turn we have
where


\begin{lem}\label{lem:hyperplane-matrix-construction}
Let , ,  and
 be as above. Then


1. there exist  elements in  denoted by  such that
 .


2. .
\end{lem}

\begin{proof}
Part  easily follows from the process of standard Gram-Schmidt
orthogonalization. We next prove  when  (\ref{eq:suppose-on-x}) holds.
Set

Taking each side as a column vector and observing the last 
components of two sides, we have . And since
 are linearly independent,
we have . Thus the  vectors
 are linearly independent. This implies that
.
\end{proof}





\begin{defn}[]
\label{def:H_X} For  satisfying
(\ref{eq:suppose-on-x}), define  to be the  matrix .
\end{defn}

\begin{lem}\label{lem:property-of-Hx}
Let  and  be as above. Then


1. .


2. .


3.  is an
orthogonal matrix.

4. \textbf{0}, i.e.  is a hyperplane matrix of
.





5.  is a lower trapezoidal matrix and every diagonal element
of  is nonzero.
\end{lem}

\begin{proof}
Since every two columns of  are orthogonal, part  follows.
And  part  follows from part . Let . Obviously,
 is an orthogonal
matrix. From part 3 and standard Gram-Schmidt orthogonalization we
have  and  respectively, where
 is an appropriate  invertible matrix. Thus  and hence that part 4 follows. We now
prove part 5. Denote the -th element of  by
. The diagonal elements of  are  for
. Before normalizing  we have , and at the same time,  Thus all the diagonal elements of  are nonzero. Now we only
need to show that  is lower trapezoidal. From standard
Gram-Schmidt orthogonalization, we can check that  holds for . This
completes the proof.
\end{proof}

So far, we have had a method to produce a hyperplane matrix 
for . The basic idea is from HJLS
(see \cite{HHL1986, HJL1989}). The same strategy was also used in
PSLQ, however, in which partial sum was adopted instead of
Gram-Schmidt orthogonalization.

\begin{lem}\label{lem:property-of-Px}
For  define . Then


1. .


2. .


3. .


4. .


5.  for any .
Particularly,  for any SIR
 for .
\end{lem}

\begin{proof}
The proof of the first part is easy. Let~. From Lemma \ref{lem:property-of-Hx}
we have
 . Thus part 
follows. Part  and part  follow from

and  tr tr
tr respectively. Since , we have  for . And the process of standard Gram-Schmidt
orthogonalization implies . Thus
we have  from part 2.
\end{proof}

From Lemma \ref{lem:property-of-Hx} and Lemma
\ref{lem:property-of-Px} we can easily generalize the Theorem  in
\cite{FBA1999} to the case of .

\begin{thm}\label{thm:lower-bound-of-simultaneous-relations}
Let  and  be as above. Suppose
that for any matrix  there exists an
orthogonal matrix  such that
 is lower trapezoidal and all of the diagonal
elements of  satisfy . Then for any SIR
 of  we have

\end{thm}

As this theorem easily follows from the proof of Theorem 1 of \cite{FBA1999} with
little modifications, the detail has been  omitted here.

 The lower
bound given in (\ref{eq:lower-bound-of-simultaneous-relation}) when
 is consistent with a similar lower bound in \cite{FF1979,
FF1982}. Moreover, if a method to reduce the norm of  by
multiplication by some unimodular  on the
left has been developed, then it will produce an increasing lower
bound on , where  is the least Euclidean
norm of SIRs for . In fact this theorem suggests a strategy to
detect an SIR for .



\subsection{Matrix Reduction}\label{subsec:Matrix-Reudce}
We now study how to reduce the hyperplane matrix . First we recall (modified) Hermite reduction in \cite{FBA1999}.



\begin{algorithm}[H]
\caption{(Modified Hermite Reduction).}
\begin{algorithmic}[1]
\REQUIRE a lower trapezoidal matrix  with .

\ENSURE a reducing matrix  of .

\STATE {}

\STATE {\textbf{for}  from  to  \textbf{do}}

\STATE {\ \ \ \ \textbf{for}  from  by  to 
\textbf{do}}

\STATE {\ \ \ \ \ \ \ \ , where
 for a real\\\ \ \ \ \ \ \
\ number .}

\STATE {\ \ \ \ \ \ \ \ \textbf{for}  from  to 
\textbf{do}}

\STATE {\ \ \ \ \ \ \ \ \ \ \ \ }



\RETURN the  matrix .

\end{algorithmic}\label{algo:modified-Herimite-reduction}
\end{algorithm}

If Algorithm \ref{algo:modified-Herimite-reduction} output  for
an  matrix ,  we say that  is the modified
Hermite reduction of  and that  is the reducing matrix of .
This reduction develops the left multiplying modified Hermite
reducing matrix .


Hermite reduction is also presented in \cite{FBA1999}, and is
equivalent to modified Hermite reduction  for a lower triangular
matrix  with  (see \cite[Lemma 3]{FBA1999}). Both
the two equivalent reductions have the following properties:


1. The reducing matrix .


2. For all , the (modified) Hermite reduced matrix  satisfies .


In order that the reduced and reducing matrices of  satisfy the two properties above, we
need the following generalized Hermite reduction. 

\begin{algorithm}[H]
\caption{(Generalized Hermite Reduction).}
\begin{algorithmic}[1]
\REQUIRE a lower trapezoidal matrix  with .

\ENSURE a reducing matrix  of .

\STATE {}

\STATE {\textbf{for}  from  to 
\textbf{do}}\label{algostep:ghr-hermite-reduction-start}



\STATE {\ \ \ \ \textbf{if}  \textbf{then} \\\ \ \ \ \textbf{else} }



\STATE {\ \ \ \ \textbf{for}  from  by  to 
\textbf{do}}

\STATE {\ \ \ \ \ \ \ \ }

\STATE {\ \ \ \ \ \ \ \ \textbf{for}  from  to 
\textbf{do}}

\STATE {\ \ \ \ \ \ \ \ \ \ \ \ }















\STATE {\textbf{for} every two integers  satisfying ,  and 
\textbf{do}}\label{algostep:generalized-2-hermite-reduction-start}

\STATE {\ \ \ \ exchange the -th row and the -th row of
.} \label{algostep:generalized-2-hermite-reduction-end}

\RETURN the  matrix .

\end{algorithmic}\label{algo:generalized-Herimite-reduction}
\end{algorithm}




If Algorithm \ref{algo:generalized-Herimite-reduction} output 
for an  matrix , we call  the generalized
Hermite reduction of  and  the reducing matrix of .
Obviously, generalized Hermite reduction is equivalent to modified
Hermite reduction when . In addition, we can easily check that
generalized Hermite reduction remains the two properties mentioned
above.



\begin{rem}\label{rem:generalized-Hermite-reduction}
 There are two main differences between
(modified) Hermite reduction and  generalized Hermite reduction.
Firstly, the last  rows of  will also be reduced by the
first  rows of  in generalized Hermite reduction, while
(modified) Hermite reduction can not do so. Secondly, generalized
Hermite reduction exchanges the -th row and the -th row of
 if ,  and 
(from Step \ref{algostep:generalized-2-hermite-reduction-start} to
Step \ref{algostep:generalized-2-hermite-reduction-end}). This
implies that if  after  generalized Hermite
reduction then . This
property plays an important role in the proof of Lemma
\ref{lem:Hn,n-2=0}.
\end{rem}

\section{The SIRD Algorithm}\label{sec:The SIRD algorithm}
\subsection{The Description of SIRD}
\label{subsec:The algorithm description} Using the hyperplane matrix
constructing method and generalize Hermite reduction in the previous
section we can get a simultaneous integer relation detecting
algorithm SIRD.

\begin{algorithm}[t!]
\caption{(The SIRD Algorithm).}
\begin{algorithmic}[1]
\REQUIRE  satisfying (\ref{eq:suppose-on-x})


\ENSURE either output an SIR for  or give a lower bound on
.

\STATE {\em Initiation.} Compute the hyperplane matrix , set
, .

\STATE {\em Reduction.} Call Algorithm
\ref{algo:generalized-Herimite-reduction} to reduce 
producing the reducing matrix . Set .

\LOOP

\STATE\label{algostep:exchange} {\em Exchange.} Let .
Choose an integer  such that  for , where . Define the permutation matrix  to be the identity
matrix with the  and ~rows exchanged. Update .


\STATE\label{algostep:corner} {\em Corner.} Let
 Let . If
,
 then let the submatrix of  consisting of the -th and
-th rows of columns  and  be
.
Update .


\STATE\label{algostep:reduction} {\em Reduction.} Call Algorithm
\ref{algo:generalized-Herimite-reduction} to reduce 
producing . Update .

\STATE Compute .
Then there  exists no SIR whose Euclidean norm is less than .
\label{algostep:bound-of-possible-relations}

\STATE{\textbf{if}  for some , or
 \textbf{then}}

\STATE {\ \ \ \ \textbf{return} the corresponding SIR for .}



\ENDLOOP
\end{algorithmic}\label{algo:Simultaneous-relation}
\end{algorithm}

\subsection{Analysis of SIRD}
Let  be the result after   iterations of SIRD.

Why do we set the parameter  at Step
\ref{algostep:exchange}?  Suppose the  chosen in Step
\ref{algostep:exchange} is not . In this case we let  be as in (\ref{eq:alph-beta-lambda-delta}).
Then

is the submatrix of  consisting of the  and  rows
of columns  and , where .   After Step
\ref{algostep:exchange} has been performed  may not be
zero, which makes that  is not lower trapezoidal.  After Step \ref{algostep:corner} the result is

Since  is chosen such that  is as large
as possible, and  we have , hence . From the property of generalized Hermite
reduction we have that , which then gives

Thus  is reduced as long as , i.e. . As was pointed
out by Borwein (see \cite {Bor2002}), although this
increases , this is not a significant problem. At each
step we force the larger diagonal elements of  toward
, where their size can be reduced by at least a factor
of  when .

As a matter of fact, the parameter  can be freely chosen in
the open interval .



\begin{lem}\label{lem:Hn,n-2=0}
If  for some  and no smaller
, then  and an SIR for  must appear as a column of
the matrix .
\end{lem}
\begin{proof}
By the hypothesis on  we know that all diagonal elements of  are not zero. Now, suppose the  chosen in Step
\ref{algostep:exchange} is not . Since generalized Hermite
reduction does not introduce any new zeros on the diagonal, and from
the analysis of Step \ref{algostep:exchange} and Step
\ref{algostep:corner} above, we have that no diagonal element of
 is zero. This contradicts the hypothesis on  and our
assumption that  was false. Thus we have 
after the -th iteration has been completed.

Next we show that there must be an SIR for  appeared as a column
of the matrix . We have  from Lemma
\ref{lem:property-of-Hx} and hence that  , where  is an
appropriate orthogonal  matrix. Let
, where
. Then
 
We know  and 
from . From Remark
\ref{rem:generalized-Hermite-reduction} and  we have 
which implies the last equality. Since ,
it follows that . Thus the -th column of  is an SIR for .
\end{proof}

From Theorem \ref{thm:lower-bound-of-simultaneous-relations} and
Lemma \ref{lem:Hn,n-2=0}, the correctness of SIRD has been proved.
Moreover, we have

\begin{thm}\label{thm:upper-bound-for-SIRs}
Let  be the least Euclidean norm of any SIR for . Let
  be an SIR detected by SIRD. Then
 for all
.
\end{thm}
\begin{proof}
Assume  with  and 
at the -th iteration of SIRD. Then from Theorem
\ref{thm:lower-bound-of-simultaneous-relations} and the exchange
rule of SIRD we have
 At this time,  holds from
the same strategy in the proof of Lemma 10 in \cite{FBA1999}.
\end{proof}
\begin{defn}[the  function]\label{def:Pi-function}
For the -th iteration in SIRD, define

\end{defn}

The routine of analyzing the number of iterations in \cite{FBA1999}
can be carried over here with redefining the  function as
above. So we state the following lemma directly without proof.

\begin{lem}\label{lem:Pi-function}
For  we have


1. , where  is the least norm of
SIRs for .


2. .
\end{lem}





From this lemma, it follows that the  function is increasing
with respect to  and has an upper bound for a fixed
. Thus we have

\begin{thm}\label{thm:the-number-of-iterations}
If  has SIRs, then the number of
iterations such that SIRD finds an SIR for  will be no more than

\end{thm}

\begin{proof}
From Definition \ref{def:Pi-function} we can infer .
And by Lemma \ref{lem:Pi-function} we know that  Solving 
from this inequality gives the conclusion, as was to be shown.
\end{proof}


\begin{cor}\label{thm:time-complexity-of-simultaneous-relation}
If  has SIRs, then there exists a
 such that SIRD will find an SIR for  in polynomial time
.
\end{cor}

\begin{proof}
Let . Then SIRD will construct an SIR for   in no
more than

iterations. SIRD takes  exact arithmetic
operations per iteration, and hence that
 exact arithmetic
operations is enough to produce an SIR for . Since , the
proof is complete.
\end{proof}

\begin{rem}\label{rem:simultaneous-relation-algorithm}
From this corollary, we can claim that our detecting algorithm
always return an SIR for  if one exists. Additionally, SIRD will
produce lower bound on the Euclidean norm of any possible SIRs for
 (Theorem \ref{thm:lower-bound-of-simultaneous-relations}). Thus
SIRD can be used to prove that there are no SIRs for  of norm
less than a given size.
\end{rem}

\begin{rem}
PSLQ may be viewed as a particular case of SIRD when .
Similarly with PSLQ, SIRD can be easily generalized to complex field
with  such that the  outputs are in Gaussian
integer ring and all conclusions mentioned above hold with
corresponding modifications.
\end{rem}
\begin{rem}
Moreover, SIRD can also be applied to detect an integer relation in
 for a given complex vector. For example, suppose
 in  with
vector components  where . Then SIRD can give an SIR  for
, and hence that
 is an integer relation for ,
but PSLQ only can give a Gaussian integer relation in
. This is one of
the biggest differences between SIRD and PSLQ. Furthermore, the matrix reducing method in SIRD is generalized Hermite reduction,
which avoids LLL-type reduction. This is  a difference not only
between SIRD and HJLS, but also between SIRD and PSLQ because that
(modified) Hermite reduction is not suitable to detect SIRs any more. And just the generalized Hermite reduction guarantees
the correctness of SIRD.
\end{rem}





\section{Performance Results}\label{sec:Performance results}
In theory, the costs of SIRD and the HJLS simultaneous relations
algorithm (see \cite[section 5]{HJL1989}) are the same as in
Corollary \ref{thm:time-complexity-of-simultaneous-relation} in the
worst case, whereas in practice  SIRD usually needs fewer
iterations. For  and , HJLS outputs  after 5 iterations while
SIRD outputs  after only 2 iterations.

\begin{table}[H]\centering
\begin{tabular}{||c|c|c|c|c|c|c|c|}
  \hline
No.&    &  &  &  & 
 \\\hline\hline
  1&4&15&12&\ \ 0.047&0.\ \ \  \\
 2&4&13&9&\ \ 0.171&\ \ 0.016\\
 3&4&21&19&\ \ 0.062&\ \ 0.015\\
 4&5&25&20&\ \ 0.110&\ \ 0.016\\
 5&5&27&43&\ \ 0.125&\ \ 0.016\\
 6& 5 &   21 & 14 & \ \ 0.110 & \ \ 0.032 \\\hline
7& 30 &  51 & 21 & \ \ 1.703 & \ \ 0.422 \\
  8&54 & 34 & 9 & \ \ 5.625 & \ \ 1.265 \\
   9&79  & 34 & 40 & \ 14.157 & \ \ 4.422 \\
  10&97 &  37 & 5 & \ 23.860 & \ \ 5.375 \\
  11&128 &  45 & 6 & \ 49.657 & \ 11.141 \\
  12&149 &   29 & 14 & \ 76.797 & \ 18.063 \\
   13&173 & 26 & 2 & 114.140 & \ 25.000 \\
  14&192 &  29 & 2 & 153.078 & \ 33.641 \\
  15&278& 28 & 8 & 440.781 & 102.860  \\
   16&290 & 35 & 6 & 500.562 & 118.578  \\
   17&293 & 23 & 7 & 512.796 & 123.265  \\
   18&305 & 22 & 4 & 581.844 & 137.672  \\
   19&316 & 19 & 3 & 649.032 & 147.796  \\
  20&325 & 18 & 2 & 716.094 & 159.813  \\
  \hline
\end{tabular}\caption{Comparison of performance results for HJLS and SIRD }\label{tab:performance-of-SIRD}
\end{table}

 Both the SIRD algorithm and the HJLS simultaneous relations
algorithm when , i.e. detecting an SIR for two vectors, were
implemented in \emph{Maple} 13 by the first author.  The tests were
run on AMD Athlon 7750 processor (2.70 GHz) with
2GB main memory.

The purpose of the trials in Table \ref{tab:performance-of-SIRD} is
to compare the performances of HJLS and SIRD.   in Table
\ref{tab:performance-of-SIRD} gives the dimension of the relation
vector.  and  are the numbers of iterations
of HJLS and SIRD respectively. The columns headed  and
 give the CPU run time respectively of the two algorithms
in seconds. 

The 20 trials in Table \ref{tab:performance-of-SIRD} were
constructed by \emph{Maple}'s pseudo random number generator. The
first  trials are for low dimension, and  others for higher
dimension. The results show that SIRD appears to be more effective
than HJLS. In  out of  trials, the number of iterations of
SIRD is less than that of HJLS. It is still true that SIRD usually
needs fewer iterations than  HJLS for more tests. This leads that
the running time of SIRD is much less than HJLS.  With 
increasing, the difference between the efficiency of SIRD and HJLS
is increasingly notable. On average, the SIRD running time is about
 of the running time of HJLS. All these results are obtained
under the condition that .

The \emph{Maple} implementation and more tests are available from
{\tiny
\url{http://cid-5dbb16a211c63a9b.skydrive.live.com/self.aspx/.Public/sird.rar}.
}

\section{An Application}
\label{sec:finding-minimal-polynomial} Any SIR detecting algorithm
intervenes in many fields of application, such as Diophantine
approximating, numerical constants relations finding, etc. In this
section, we discuss how to find the minimal polynomial of a complex
algebraic number from its an approximation by using SIRD.
\subsection{The MPF Algorithm}
We say that a complex number  is an algebraic number if
 is a root of a non-zero polynomial in one variable with
integer coefficients. The minimal polynomial of  is the
unique primitive polynomial  of least degree
such that . The degree and  height of  are
the degree and  height of its minimal polynomial 
respectively.

In this section, let  be an
algebraic number with degree at most , height at most , where . Suppose we are given an approximation
 to   such that
 Is it
possible to infer the minimal polynomial from the approximation?
Computer algebra system \emph{Maple} has an LLL-based procedure,
\texttt{PolynomialTools:-MinimalPolynomial()}, for finding the
minimal polynomial of an algebraic number from its an approximation,
whose
basic idea is from \cite{Sch1984, KLL1984, KLL1988}. Applying SIRD, we shall give another affirmative answer, the
following MPF algorithm, to the question above.

\begin{algorithm}[H]
\caption{(The MPF Algorithm).}
\begin{algorithmic}[1]
\REQUIRE an approximation  to  satisfying
(\ref{eq:epsilon}), a degree bound , and a height bound ,
 satisfying (\ref{eq:error-controlling})



\ENSURE the minimal polynomial of .

\WHILE{  }\label{algostep: circulating}

\STATE { }



\STATE { Call SIRD with  producing an integer relation
 for
\\the primitive part of 
}\label{algostep:call-SIRD}













\STATE {\textbf{if} height \textbf{then}}\label{algostep:if height(p)>H}

\STATE { \ \ \ \ ; \textbf{goto} Step \ref{algostep:
circulating}}

\STATE { \textbf{else}  \textbf{return} }













\ENDWHILE
\end{algorithmic}\label{algo:minimal-polynomial}
\end{algorithm}

\begin{rem}
At Step \ref{algostep:call-SIRD} of MPF,  is an SIR
for  and  when
 .
\end{rem}





















\subsection{Error Controlling}
\label{subsec:Finding the Minimal Polynomial Using Float-point
Arithmetic}






 The main idea of our minimal
polynomial finding (MPF) algorithm to determine the minimal
polynomial of an algebraic number from its an approximation is as
follows: We try the value of   in order. With 
fixed, we call SIRD for detecting an exact integer relation
 for . Then
 satisfies ,
however, from which we can not decide whether  is 
or not. Hence the most important problem is how to choose an
appropriate  in (\ref{eq:epsilon}) such that
 implies .
Before describing it
in detail, we consider the following example.

\begin{exmp}\label{exmp:x^2-4x+7}
Let . We know that the minimal polynomial of
 in  is . Let  be the approximation to  with four significant
digits. Hence , . Feeding SIRD ,  as its
input vectors gives an SIR for ,  after
 iterations. The corresponding matrices  are

It is obvious that the first column of the latter one
is an SIR for  and , and corresponds to
the coefficients of the minimal polynomial of . However, if
we take only  significant digits for the same data, after 
iterations SIRD outputs , which is an SIR for
 and , but does not correspond
to the coefficients of the minimal polynomial of . For this
reason, we have to appropriately control the error such that the
output of MPF is correct.
\end{exmp}








\begin{lem}\label{lem:approximation-of-f}
Let  be a polynomial in  of degree . If
, then
.
\end{lem}

\begin{defn}[Mahler measure]
For any polynomial  of
degree  with the complex roots  we
define the Mahler measure  by

The Mahler measure of an algebraic number  is defined to be
the measure of its minimal polynomial.
\end{defn}

\begin{lem}(see \cite[Lemma 3]{MW1978})\label{lem:Mignotte}
Let  be algebraic numbers of exact
degree of  respectively. Define
. Let  have degree at most  in
 (). If , then

where  is the Mahler measure of .
\end{lem}



This lemma gives a lower bound on  if  for an
arbitrary multivariate polynomial . If we apply it to  in
, then we have
\begin{cor}\label{cor:g(alpha)not equal to 0}
Let  be an algebraic number with exact degree  and
. Suppose both
 and  are . If
, then

where  is the height of 's minimal
polynomial.
\end{cor}

\begin{proof}
For  with degree , we
have Landau's inequality:  (e.g. see \cite[p.
154]{GG1999}), , and .
This corollary  easily follows from Lemma \ref{lem:Mignotte} and the
three facts above.
\end{proof}

Next we investigate how to choose  to enable MPF to
correctly return the minimal polynomial of  from
. We denote the exact degree of  by . For , Step \ref{algostep:call-SIRD} in MPF gives
a polynomial  with degree  such that
.
From Corollary \ref{cor:g(alpha)not equal to
0} we know that if , then

where . 



\begin{thm}
Let ,  and  be as above, and  a polynomial in  with degree  and
height . Then there exist some  such that
 implies .
\end{thm}

\begin{proof}


Set . From Lemma \ref{lem:approximation-of-f} we
have . Thus if ,
then  . From (\ref{eq:p_i(alpha)<>0}) it follows that
.
\end{proof}

If we substitute  for , we have

\begin{cor}\label{cor:epsilon-control}
Let  and   be as above and
 Then for  from  to , an integer relation for
 with height  is also for .
\end{cor}


\subsection{Correctness and Cost of MPF}


Assume that the degree of  is  and that 
satisfies (\ref{eq:error-controlling}). When , there
exists no relation for , which, combined
with Corollary \ref{cor:epsilon-control}, means that  must
satisfy the condition in Step \ref{algostep:if height(p)>H} of MPF
and then go into next iteration. When , we know that
the coefficients of the minimal polynomial of  form an
integer relation for , whose height
, hence Euclidean norm . This implies
that  has also an
integer relation with Euclidean norm . From
Theorem \ref{thm:upper-bound-for-SIRs} we know that the height of
the relation SIRD detected will . Thus the
relation detected by SIRD when  will never satisfy the
condition in Step \ref{algostep:if height(p)>H}  and corresponds an
integral multiple of the minimal polynomial of . Hence the
correctness of MPF follows.

From  (\ref{eq:error-controlling}) we have . Thus we can give
another answer to  Blum's and Zhang's question without using LLL
lattice reduction algorithm.

\begin{thm}\label{thm:complexity-of-finding-algorithm-fpa}
Let  be an algebraic number and let  and  be upper
bounds of the degree and height of  respectively. Suppose we
are given an approximation  to  such that
. Then
the minimal polynomial of  can be determined in  arithmetic operations on floating-point
numbers having  bit-complexity.
\end{thm}


\begin{table}[H]
\begin{tabular}{||c|c|c|}
  \hline
& Digits & Complexity \\\hline
  KLL\cite{KLL1988} &  &  \\\hline
  Just\cite{Jus1989} &  & 
\\\hline
  QFCZ\cite{QFC2009} &  & ------ \\\hline
  MPF &  &  \\
  \hline
\end{tabular}\caption{Comparison of different minimal polynomial finding
algorithms}\label{tab:comparison of MPFs}
\end{table}

Table \ref{tab:comparison of MPFs} gives a comparison of the digits
and complexity of 4 different minimal polynomial finding algorithms
in the worst case. Since the algorithm in \cite{QFC2009} can only find the minimal
polynomial of a real algebraic number, we don't compare the
complexity with it. It seems that a lower complexity can be achieved
by using some new type LLL algorithms, such as L \cite{NS2005}
and H-LLL \cite{MSV2009}, but when we apply these new algorithms to
find the minimal polynomial we have to choose  as in a
similar formula with (\ref{eq:error-controlling}). Thus multiple
precision arithmetic is inevitable.










\vspace{2 mm}

\emph{Example \ref{exmp:x^2-4x+7} (con.).} For , its minimal polynomial . Set  and . Computing the error tolerance as in equation
(\ref{eq:error-controlling}) gives .
Corollary \ref{cor:epsilon-control} implies that
 correct decimal digits are
sufficient to guarantee the output is correct. This example also
illustrates that  in (\ref{eq:error-controlling}) is only
a sufficient condition on error controlling, but not a necessary
one.







\section{Conclusion}\label{sec:conclude}

The number of iterations and the cost of SIRD algorithm are related
to the parameter . For  and
, if we choose  then
SIRD outputs  after 12 iterations, however,
if we choose , SIRD outputs   after
only 6 iterations. In future work we expect to find the best choice
for . Additionally, how to choose the digits such that SIRD
under floating-point arithmetic finds an exact SIR is also in our
interests.
Finally, we see that the MPF algorithm can be used to factor  in
 like this: Solve an approximation root with accuracy
satisfying  equation (\ref{eq:error-controlling}), and  call MPF for
finding its minimal polynomial which corresponds an irreducible
factor of , and then repeat the two steps until  has been
factored completely.
It is symbolic-numeric  and different from traditional algorithms
based on Hensel lifting.\vspace{1 mm}


\textbf{Acknowledgements.} This research was partially supported by
the Knowledge Innovation Program of CAS (KJCX\\2-YW-S02) and the NSFC (10771205).

\begin{thebibliography}{10}

\bibitem{BBK2006}
{\sc Bailey, D., Borwein, J., Kapoor, V., and Weisstein, E.}  {Ten
problems in experimental mathematics}. {\em American Mathematical
Monthly 113}, 6 (2006), 481--509.

\bibitem{BB2009}
{\sc Bailey, D.~H., and Borwein, J.}
  PSLQ: An algorithm to discover integer relations.
  {\em LBNL Paper LBNL-2144E}, (2009). available from  \url{http://escholarship.org/uc/item/95p4255b}.

\bibitem{BBC2007}
{\sc Bailey, D.~H., Borwein, J.~M., Calkin, N.~J., Girgensohn, R.,
Luke, D.~R., and Moll, V.~H.}
  {\em Experimental Mathematics in Action}.
  AK Peters, 2007.

\bibitem{BB2001}
{\sc Bailey, D.~H., and Broadhurst, D.~J.} Parallel integer relation
detection: techniques and applications. {\em Math. Comput. 70}, 236
(2001), 1719 --1736.

\bibitem{Ber1971}
{\sc Bernstein, L.}
  The Jacobi-Perron algorithm, its theory and application.
  {\em Lecture Notes in Mathematics 207}. Springer, 1971.

\bibitem{BC1999}
{\sc Borwein, J., and Corless, R.}
  {Emerging tools for experimental mathematics}.
  {\em American Mathematical Monthly 106}, 10 (1999), 889--909.

\bibitem{BL2000}
{\sc Borwein, J.~M., and Lisonek, P.}
  Applications of integer relation algorithms.
  {\em Discrete Mathematics (Special issue for FPSAC 1997) 217\/}
  (2000), 65--82.

\bibitem{Bor2002}
{\sc Borwein, P.}
  {\em Computational Excursions in Analysis and Number Theory}.
  Springer, New York, 2002.

\bibitem{BHM2002}
{\sc Borwein, P., Hare, K.~G., and Meichsner, A.}
  Reverse symbolic computations, the {\tt identify} function.
  In {\em Proceedings from the Maple Summer Workshop\/} (Maple
  Software, Waterloo, 2002).

\bibitem{Bre1982}
{\sc Brentjes, A.~J.}
  Multi-dimensional continued fraction algorithms.
  {\em Mathematisch Centrum Computational Methods in Number Theory, Pt.
  2 p 287-319(see N 84-17999 08-67)\/} (1982).



\bibitem{DS2000}
{\sc Dongarra, J. and Sullivan, F.}
 Guest editors' introduction: the top 10 algorithms.
  {\em Comput. Sci. Eng. 2}, 1 (2000), 22--23.

\bibitem{FB1992}
{\sc Ferguson, H. R.~P., and Bailey, D.~H.}
  Polynomial time, numerically stable integer relation algorithm.
  Tech. Rep. RNR-91-032, NAS Applied Research Branch, NASA Ames
  Research Center, Mar. 1992.

\bibitem{FBA1999}
{\sc Ferguson, H. R.~P., Bailey, D.~H., and Arno, S.}
  Analysis of PSLQ, an integer relation finding algorithm.
  {\em Math. Comput. 68}, 225 (1999), 351--369.

\bibitem{FF1979}
{\sc Ferguson, H. R.~P., and Forcade, R.~W.}
  Generalization of the Euclidean algorithm for real numbers to all
  dimensions higher than two.
  {\em Bull. Amer. Math. Soc. 1}, 6 (1979),
  912--914.

\bibitem{FF1982}
{\sc Ferguson, H. R.~P., and Forcade, R.~W.}
  Multidimensional Euclidean algorithms.
  {\em (Crelle's) Journal f{\"u}r die reine und angewandte Mathematik
  334\/} (1982), 171--181.

\bibitem{HHL1986}
{\sc Hastad, J., Helfrich, B., Lagarias, J.~C., and Schnorr, C.~P.}
  Polynomial time algorithms for finding integer relations among real
  numbers.
  In {\em STACS '86}. 1986, pp.~105--118.

\bibitem{HJL1989}
{\sc Hastad, J., Just, B., Lagarias, J.~C., and Schnorr, C.~P.}
  Polynomial time algorithms for finding integer relations among real
  numbers.
  {\em SIAM Journal on Computing 18}, 5 (1989), 859--881.

\bibitem{Jus1989}
{\sc Just, B.}
  Integer relations among algebraic numbers.
  In {\em Mathematical Foundations of Computer Science 1989}. 1989,
  pp.~314--320.

\bibitem{KLL1984}
{\sc Kannan, R., Lenstra, A.~K., and Lov\'{a}sz, L.}
  Polynomial factorization and nonrandomness of bits of algebraic and
  some transcendental numbers.
  In {\em STOC '84\/} (1984), pp.~191--200.

\bibitem{KLL1988}
{\sc Kannan, R., Lenstra, A.~K., and Lov{\'a}sz, L.}
  Polynomial factorization and nonrandomness of bits of algebraic and
  some transcendental numbers.
  {\em Math. Comput. 50}, 181 (1988), 235--250.

\bibitem{LLL1982}
{\sc Lenstra, A.~K., Lenstra, H.~W., and Lov{\'a}sz, L.}
  Factoring polynomials with rational coefficients.
  {\em Math. Ann. 261}, 4 (1982), 515--534.

\bibitem{MW1978}
{\sc Mignotte, M., and Waldschmidt, M.}
  Linear forms in two logarithms and Schneider's method.
  {\em Math. Ann. 231\/} (1978), 241--267.

\bibitem{MSV2009}
{\sc Morel, I., Stehl{\'e}, D., and Villard, G.}
  H-LLL: using Householder inside LLL.
  In {\em ISSAC '09\/} (2009), pp.~271--278.

\bibitem{NS2005}
{\sc Ngu{\~{\^e}}n, P.~Q., and Stehl{\'e}, D.}
  Floating-point LLL revisited.
  In {\em EUROCRYPT 2005\/} (2005), pp.~215--233.

\bibitem{QFC2009}
{\sc Qin, X.-l., Feng, Y., Chen, J.-w., and Zhang, J.-z.}
  Finding exact minimal polynomial by approximations.
  In {\em SNC'09\/} (2009), pp.~125--131.

\bibitem{RS1997}
{\sc R{\"o}ssner, C., and Schnorr, C.~P.}
  Diophantine approximation of a plane. (1997).
  available from \url{http://citeseer.ist.psu.edu/193822.html}.

\bibitem{Sch1984}
{\sc Sch{\"o}nhage, A.}
  Factorization of univariate integer polynomials by Diophantine
  approximation and an improved basis reduction algorithm.
  In {\em LNCS}, vol.~172. 1984, pp.~436--447.



\bibitem{GG1999}
{\sc von~zur Gathen, J., and Gerhard, J.}
  {\em Modern Computer Algebra}.
  Cambridge University Press, London, 1999.

\bibitem{YZH1996}
{\sc Yang, L., Zhang, J.-z., and Hou, X.-r.}
  {\em Nonlinear Algebraic Equation System and Automated Theorem
  Proving}.
  Shanghai Scientific and Technological Education Publishing House,
  1996 (in Chinese).
\bibitem{ZF2007}
{\sc Zhang, J.-z., and Feng, Y.}
  Obtaining exact value by approximate computations.
  {\em Science in China Series A: Mathematics 50}, 9 (2007),
  1361--1368.

\end{thebibliography}

\balance
\end{document}
