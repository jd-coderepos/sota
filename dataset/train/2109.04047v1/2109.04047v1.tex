

{Our method for utilizing the co-occurrence information of HOI labels consists of three key components:} 
(1) establishing action co-occurrence priors (\Sref{sec.prior}), (2) hierarchical learning including anchor action selection (\Sref{sec.anchor}) and devising the hierarchical architecture (\Sref{sec.architecture}), followed by an extension of the architecture via self-attention (\Sref{sec.attention}), and 
(3) {ACP projection for knowledge distillation} (\Sref{sec.knowledge_distillation}), followed by an extension of the loss function via a language prior (\Sref{sec.language}).







\subsection{Action Co-occurrence Priors}
\label{sec.prior}











{Here, we formalize the action co-occurrence priors.} 
The priors for the actions are modeled by a co-occurrence matrix  where an entry  in  represents the conditional probability that action  occurs when action  is happening: 

where  
(117 for the HICO-Det~\cite{chao2018learning} dataset) 
denotes the total number of action classes and  are indices of two actions. 
By definition, the diagonal entries are one.
 is constructed from the target HOI detection dataset by counting the {image-level} statistics of its training labels.
Examples of co-occurrence matrices constructed for a single object are visualized in \Fref{fig:co-occurrence}.




Meanwhile, we also consider the complementary event of action  (\ie~where the -th action does not occur) and denote it as , such that .
The complementary action co-occurrence matrix  can thus be defined by entries  in  that represent the conditional probability that an action  occurs when another action  does not occur: 

In this matrix, the diagonal entries are zero.



It can be seen from \Fref{fig:co-occurrence} that different types of relationships can exist between actions. 
They can be divided into three forms.
The first is the \textbf{prerequisite} relationship, where the given action is highly likely to co-occur with the conditional action. 
For example, the HOI `sit on-bicycle' is a prerequisite of the HOI `ride-bicycle'. 
In this case, 
 is close to .
Next is \textbf{exclusion}, where the given action is highly unlikely to co-occur with the conditional action. An example is that the HOI `wash-bicycle' and HOI `ride-bicycle' are unlikely to happen together. 
As a result,  is close to .
Finally, we have \textbf{overlapping}, where the given action and conditional action may possibly co-occur, for example HOI `hold-bicycle' and HOI `inspect-bicycle', such that  is in between  and .
We introduce two 
ways to exploit the co-occurrence matrix by regarding exclusion (action space partitioning) and prerequisite actions (knowledge distillation). 
Detailed descriptions of the proposed methods are presented in the following sections.





The strong relationships that may exist between action labels can provide strong priors on the presence or absence of an HOI in an image. 
{In contrast to previous works where models may implicitly learn label co-occurrence via relational architectures~\cite{baradel2018object,zhang2019co}, we explicitly exploit these relationships between action labels as priors, to effectively train our model especially for rare HOIs.}













\subsection{Anchor Action Selection via Non-Exclusive Suppression}
\label{sec.anchor}
{{From a co-occurrence matrix for an object, one can see that some actions are close in semantics or commonly co-occur while others are not. }}
Intuitively, 
visually similar actions (\eg~`ride-horse' and `hop on-horse')
tend to be harder to distinguish from each other, but these actions should not occur at the same time.
{If the positive labels for these actions are rare, then they become even more difficult to distinguish.}
Such cases require fine-grained recognition~\cite{fu2017look} and demand more dedicated classifiers.
This motivates us to learn HOI classes in a coarse-to-fine manner. 
In particular, as a pre-processing step, we first collect a set of mutually exclusive action {classes}, called \emph{anchor actions}, which tend to be distinguishable from one another. 
The anchor actions are used to partition the entire action {label} space into fine-grained sub-spaces. The other action {classes} are attributed to one or more sub-spaces and recognized in the context of a specific anchor action.
{In summary, unlike previous HOI detection works which predict action probabilities independently of one another, we divide the whole action label set into two sets, one for anchor actions and one for regular actions, which are modeled in different ways as explained in detail in \Sref{sec.architecture}}.








Before 
training, in selecting anchor actions, we seek a set of action {classes} that are exclusive of one another. To this end, we define the exclusiveness of an action {class} as counting the number of actions that never occur if action  is happening: 

 will have a high value if few other actions can occur when  does.
Based on exclusiveness values, the anchor action {label} set  is generated through \emph{\textbf{non-exclusive suppression (NES)}} as described in \Aref{alg:correlation}. It iteratively finds the most exclusive action {class} as an anchor action and removes remaining action {classes} that are not exclusive to the selected anchor actions. 
The anchors in the list are action {classes} that never occur together in the training labels. For example, if an action such as `toast' is on the anchor list, then actions like `stand' and `sit' cannot be on the list because they may co-occur with `toast', while actions such as `hunt' or `hop on' can potentially be on the list.
While there may exist other ways the anchor action selection could be done, we empirically found this approach to be simple, effective in terms of detection accuracy, and computationally efficient (less than 0.01 second).


\begin{algorithm}[ht]
\KwIn{
\;
}
\KwOut{

} 
\Begin
{
    \;
  \While{ is not empty}
{
    \# Find the most exclusive action\;
    \;
  \;
\For{}{
            \# Remove the actions correlated (not exclusive) to \;
            \If{}
            {
                
            }
    }
  }
}
\caption{
{Non-Exclusive Suppression (NES) algorithm for mutually exclusive anchor action selection.
}
}
\label{alg:correlation}
\end{algorithm}


The anchor action {label} set acts as a finite partition of the action {label} space (a set of pairwise disjoint events whose union is the entire action {label} space). To form a complete action {label} space, we add an \emph{\textbf{`other'}} anchor action, denoted as , for when an action {class} does not belong to . 
Finally, we have  anchor actions including  and the `other' action {class} . 







There are several benefits to having this anchor action {label} set.
First, only one anchor action can happen at one time between a given human and object. Thus, we can use the relative (one-hot) probability representation with \emph{softmax} activation instead of a sigmoid, where softmax features were shown to compare well against distance metric learning-based features~\cite{horiguchi2019significance}.
Second, anchor actions tend to be easier to distinguish from one another since they generally have prominent differences in an image.
Third, it decomposes the action {label} space into several sub-spaces, which facilitates a coarse-to-fine solution. Each sub-task will have a much smaller solution space, which can improve learning.
Finally, each sub-task will use a standalone sub-network which focuses on image features specific to the sub-task, which is an effective strategy for fine-grained recognition~\cite{fu2017look}.







After selecting anchor actions, the entire action {label} set  is divided into the anchor action {label} set  and the remaining set of `regular' action {classes} , so that .
Each of the regular action {classes} is then associated with one or more anchor actions to form  action groups , one for each anchor action. 
A regular action {class}  will be assigned to the group associated with anchor action  () if action  is able to co-occur with the anchor action ,

Note that the anchor actions themselves are not included in the action groups and a regular action  can be assigned to multiple action groups since it may co-occur with multiple anchor actions.









  

\begin{figure*}[t]
\centering
\includegraphics[width=1\linewidth,keepaspectratio]{Figures/architecture_extended.pdf}
    \vspace{-2mm}
    \caption{Illustration of our overall network architecture.
	Our work differs from the baseline \cite{gupta2019no} by the addition of a hierarchical \emph{action prediction module}.
	For our hierarchical architecture, anchor action probabilities are directly generated by a \emph{softmax} sub-network. Regular action probabilities are generated by a matrix multiplication of the anchor probability and the output from a few \emph{sigmoid} based conditional sub-networks.}
	\vspace{-2mm}
    \label{fig:model_merged}
\end{figure*}


\subsection{Hierarchical Architecture}
\label{sec.architecture}
We implement our hierarchical approach upon several existing HOI detection architectures~\cite{gao2020drg,gupta2019no,liao2020ppdm}.
In this section, we introduce our main baseline architecture, built on the `No-Frills' (NFs) baseline presented in~\cite{gupta2019no} on account of its simplicity, effectiveness, and code availability~\cite{nofrillsgit}.
Here, we give a brief review of the NFs architecture. 

\noindent\textbf{Baseline Network}
NFs follows the common scheme of CNN feature extraction followed by multi-information fusion. The feature extraction uses an off-the-shelf Faster R-CNN~\cite{ren2015faster} object detector with ResNet152~\cite{he2016deep} backbone network to detect human and object bounding boxes. From the final fully connected (FC) layer of the detector, the features  are extracted, where  and  denote human and object appearance, respectively. These CNN features, together with the human pose (), object category () and bounding boxes ( including both object and human bounding boxes) compose the multiple information as . As illustrated in \Fref{fig:model_merged}, they are fed to our target model via corresponding network streams: human appearance (), object appearance(), bounding box and object category (), and human pose and object category (). Each individual type of information is first fed through a separate network of two FC layers to generate a fixed dimension (number of actions ) feature. Then, all the features are added together and sent through a \emph{sigmoid} activation to obtain the probability prediction for the action :

where  represents the probability prediction for action class .
The multi-information fusion procedure  is expressed as 
 
 where 
 denotes concatenation. The baselines built on other models~\cite{gao2020drg,liao2020ppdm} are constructed in a similar manner.


To eliminate training-inference mismatch, NFs directly optimizes the HOI class probabilities instead of separating the detection and interaction losses as done in~\cite{gao2018ican,gkioxari2018detecting}. The final HOI prediction is a joint probability distribution over  number of HOI classes (600 for HICO-Det dataset)  {computed from the probabilities , , and  for human, object, and action, respectively:}

Specifically, for an HOI class ,

where  and  are the probability of a candidate box pair being a human  and object , provided by the object detector~\cite{ren2015faster}. Finally, the binary cross-entropy loss  is directly computed from the HOI prediction.
This ‘No-Frills’ baseline network is referred to as \emph{\textbf{Baseline}}.



\noindent\textbf{Modified Baseline Network} 
{For a stronger baseline comparison,}
we make two {simple} but very effective modifications on the baseline network.
(1) Replace the one-hot representation with the Glove word2vec~\cite{pennington2014glove} representation for the object category ( ).
(2) Instead of directly adding up the multiple information, we average them and forward this through another \emph{action prediction module}
to obtain the final action probability prediction. As a naive implementation of the \emph{\textbf{Modified  Baseline}}, we simply use a sub-network  of a few FC layers as the \emph{action prediction module}.
Then \Eref{eq:base_action_pred}-\ref{eq:base_action_pred_simple} are modified to

 
 In this case, . 

Our hierarchical architecture further modifies the \emph{action prediction module} by explicitly exploiting ACP information as described in the next paragraph.












\noindent\textbf{Proposed Hierarchical Architecture}
Now we introduce the \emph{action prediction module} for our hierarchical architecture (illustrated in \Fref{fig:model_merged}) that better exploits the inherent co-occurrence among actions. While the baseline network predicts all the action probabilities directly from  with a single feed-forward sub-network , we instead use  sub-networks where one () is first applied to predict the anchor action set and then one of the  other sub-networks () which corresponds to the predicted anchor action is used to estimate the specific action within the action group. Because of the mutually exclusive property of anchor actions, we use the \emph{softmax} activation for anchor action predictions, while employing the \emph{sigmoid} activation for regular action prediction conditioned on the action group:




where  is directly used as the final probability predictions for the anchor actions:
We let  represent the learned conditional probability that action  occurs when action  is happening, namely, 

Since the anchor action set is a finite partition of the entire action {label} space, the probability of a regular action  is predicted according to the law of total probability:

where .
Thus, 
instead of \Eref{eq:modified},
we obtain the final action probability predictions for our hierarchical architecture  as 

We use the same method as in \Eref{eq:base_hoi_pred} and a cross-entropy loss  to compute the final HOI probability prediction .

To demonstrate the effectiveness of the hierarchical learning, we introduce two other baselines,  \emph{\textbf{MultiTask}} and \emph{\textbf{TwoStream}}, that lie between the \emph{\textbf{Modified Baseline}} and our hierarchical learning. \emph{\textbf{MultiTask}} only uses the anchor action classification as an additional multi-task element to the \emph{\textbf{Modified Baseline}}. \emph{\textbf{TwoStream}} separately predicts the anchor and the regular actions
but without using the hierarchical modeling between anchor and regular actions. 







\subsection{Self-Attention Module Extension}
\label{sec.attention}
In order to enhance the capability for holistic relational understanding across objects or humans, we additionally leverage a self-attention module that applies the non-local layer~\cite{wang2018non} to each human-object pair. In particular, let  denote a stack of  merged human-object features from our  ().
Then, we compute the relational association matrix by:

where { denotes ReLU and}  are learnable {weights} that map the human-object features  to their own roles, (\eg~key and query) and 
the softmax operation is applied row-wise.
Then, the relational feature matrix is computed by:

where  and  are again learnable {weights}.
The matrix  encodes aggregated features across all the objects according to the degree of relational association given in . This relational feature matrix is combined with the original feature  by , so that  is enhanced by holistic relational information.








\subsection{{ACP Projection for Knowledge Distillation}}
\label{sec.knowledge_distillation}

Knowledge distillation~\cite{hinton2015distilling} was originally proposed to transfer knowledge from a large network to a smaller one. 
Recently, knowledge distillation has been utilized for various purposes such as lifelong learning~\cite{li2016learning}, multi-task learning~\cite{kim2018disjoint} or modality transfer~\cite{cho2021dealing,hoffman2016learning}.
Hu~\etal~\cite{hu2016harnessing} extended this concept to distill prior knowledge in the form of logic rules into a deep neural network. Specifically, they propose a teacher-student framework to project the network prediction (student) to a rule-regularized subspace (teacher), where the process is termed distillation. 
The network is then updated to balance between emulating the teacher's output and predicting the true labels.


Our work fits this setting as
the ACPs can act as a prior to distill. 
We first introduce \emph{ACP Projection} to map the action distribution to the ACP constraints. Then, we use the teacher-student framework~\cite{hu2016harnessing} to distill knowledge from ACPs.

\noindent\textbf{ACP Projection} In ACP Projection, an arbitrary action distribution 

is projected into the ACP-constrained probability space:

where  is the projected action prediction. The projected probability for the -th action  is generated using the law of total probability:



In matrix form, the ACP projection is expressed as




In practice, we use the object-based action co-occurrence matrices  and  which only count actions related to a specific object . \Fref{fig:co-occurrence} shows examples of  with respect to object classes.
Also, we give different weights  and  {as hyper-parameters} to the action co-occurrence matrix  and its complementary matrix , with the weights subject to .
The projection function is then modified to

This is done because we empirically found the co-occurrence relationships in  to generally be much stronger than the complementary actions in . 


\noindent\textbf{Teacher-Student Framework} Now we can distill knowledge from the ACPs using ACP Projection in both the training and inference phases. There are three ways ACP Projection can be used:
(1) Directly project the action prediction  into the ACP-constrained probability space at the testing phase to obtain the final action output (denoted as \emph{\textbf{PostProcess}}). 
(2) Project the action prediction  in the training phase and use the projected action as an additional learning target~\cite{hu2016harnessing,yu2017visual}.
(3) Project the ground truth label , , and \footnote{The triplet ground truth labels , , and  are straightforward to determine from the HOI ground truth label .} to the ACP space in the training phase and use the projected action  as an additional learning target.
The second and third items are incorporated into the teacher-student framework as terms in a new objective function {(denoted as \emph{\textbf{Distillation}})}:

where


 are balancing weights among the ground truth HOI term and the teacher objectives.
The object type can be easily determined from the object probability predictions  or the ground truth label .
With the new objective function, rare classes receive different supervisions, so confusion between them can be alleviated.






\subsection{Word Embedding Loss Extension}
\label{sec.language}
As an extension to enhance performance, we add another loss term, namely a word embedding regression loss.
Given a word2vec representation for the object category , we regress our model to the same object representation in the output by computing the regressed word embedding . 
Similar to Peyre~\etal~\cite{peyre2019detecting}, we design the word embedding regularization loss as the sigmoid loss function:

where  is the number of objects (80 for HICO-Det datasets) and  is the class for the object.
Multi-task learning with the object prediction works as prior knowledge for action prediction, which leads to performance improvements.
Therefore, the total loss function can be described as a weighted sum of the knowledge distillation loss and the embedding loss:
where  is the additional balancing weight between \Eref{eqn:distill_loss} and \Eref{eqn:emb_loss}.
Note that, as we have an object word2vec vector as input, this word embedding regression loss can be seen as an auto-encoding loss which is commonly used as a regularizer.



















