\documentclass{llncs}
\usepackage{fullpage}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{mathtools}
\usepackage{xspace}
\usepackage{tikz}
\usepackage{fixme}
\usepackage{paralist,mdwlist}
\usepackage{manfnt,mparhack}
\usepackage{caption}
\usepackage{subcaption}
\usepackage{multirow}
\usepackage{wrapfig}
\usepackage{todonotes}

\usepackage[colorlinks=true, citecolor=blue,linkcolor=red,urlcolor=black]{hyperref}

\let\doendproof\endproof
\renewcommand\endproof{~\hfill\qed\doendproof}

\newcommand{\playerOne}{\ensuremath{\mathcal{P}_{1}} }\newcommand{\abs}[1]{\ensuremath{\vert #1\vert} }
\newcommand{\mn}[1]{\marginpar{ #1}}
\newcommand{\states}{\ensuremath{S} }
\newcommand{\state}{\ensuremath{s} }
\newcommand{\statesOne}{\ensuremath{S_{1}} }
\newcommand{\succStates}[1]{\ensuremath{{\sf Succ}(#1)} }
\newcommand{\succStatesFull}{\ensuremath{\succStates{\state} = \{ \state' \in \states \mid (\state, \state') \in \edges\}} }
\newcommand{\supp}{\ensuremath{{\sf Supp}} }
\newcommand{\initState}{\ensuremath{s_{{\sf init}}} }
\newcommand{\edges}{\ensuremath{E} }
\newcommand{\edge}{\ensuremath{e} }
\newcommand{\weight}{\ensuremath{w} }
\newcommand{\mpTrans}{\ensuremath{\Delta} }
\newcommand{\markovProcess}{\ensuremath{{M} }}
\newcommand{\statesProb}{\ensuremath{S_{\mpTrans}} }
\newcommand{\markovProcessFull}{\ensuremath{{P = (\statesOne, \statesProb, \edges, \mpTrans, \weight)} }}
\newcommand{\dist}{\ensuremath{p} }
\newcommand{\dists}{\ensuremath{\mathcal{D}} }
\newcommand{\integ}{\ensuremath{\mathbb{Z}} }
\newcommand{\strat}{\ensuremath{\sigma} }
\newcommand*{\pr}{\mathbb{P}}
\newcommand*{\mpsup}{\ensuremath{\overline{\mathsf{MP}}}}
\newcommand*{\mpinf}{\ensuremath{\underline{\mathsf{MP}}}}
\newcommand*{\expect}{\mathbb{E}}
\newcommand{\calE}{\ensuremath{\mathcal{E}}}
\newcommand{\Inf}{\textrm{\sf Inf}}
\newcommand{\truncatedTarget}{\ensuremath{T} }
\newcommand{\truncatedSum}[1]{\ensuremath{{\sf TS}^{#1}} }
\newcommand{\discSum}[1]{\ensuremath{{\sf DS}^{#1}} }
\newcommand{\discount}{\ensuremath{\lambda} }
\newcommand{\dimension}{\ensuremath{d} }
\newcommand{\queries}{\ensuremath{q} }
\newcommand{\nat}{\ensuremath{\mathbb{N}} }
\newcommand{\rat}{\ensuremath{\mathbb{Q}} }
\newcommand{\twoCM}{\ensuremath{\mathcal{M}} }
\newcommand{\strats}{\ensuremath{\Sigma} }
\newcommand{\round}{\ensuremath{{\sf Round}_{\gamma}} }
\newcommand{\roundedDiscSum}[1]{\ensuremath{{\sf RDS}^{#1}} }
\usetikzlibrary{shapes,arrows}
\newcommand{\query}{\ensuremath{\mathcal{Q}} }

\newcommand\NPTIME{\textrm{\sf NP}} 
\newcommand\Val{\textrm{\sf Val}}
\newcommand\calD{\ensuremath{\mathcal{D}}}
\newcommand\calH{\ensuremath{\mathcal{H}}}
\newcommand\calI{\ensuremath{\mathcal{I}}}
\newcommand\calT{\ensuremath{\mathcal{T}}}
\newcommand\calA{\ensuremath{\mathcal{A}}}
\newcommand\calC{\ensuremath{\mathcal{C}}}
\newcommand\calB{\ensuremath{\mathcal{B}}}
\newcommand\calM{\ensuremath{\mathcal{M}}}
\newcommand\mecs{\ensuremath{\textrm{\sf MEC}}}
\newcommand\Safe{\ensuremath{\textrm{\sf Safe}}}
\newcommand\PTIME{\textrm{\sf P}}
\newcommand\PSPACE{\textrm{\sf PSPACE}}
\newcommand\EXPTIME{\textrm{\sf EXPTIME}}
\newcommand\restr[2]{\ensuremath{\left.#1\right|_{#2}}}
\newcommand\bis{\ensuremath{\textrm{\sf bis}}}
\newcommand\laststate{\textrm{\sf last}}
\usetikzlibrary{automata,calc}
\usetikzlibrary{arrows}

\title{Percentile Queries in Multi-Dimensional Markov Decision Processes\thanks{M.~Randour is an F.R.S.-FNRS Postdoctoral Researcher, J.-F.~Raskin is supported by ERC Starting Grant (279499: inVEST). Work partly supported by European project CASSTING (FP7-ICT-601148).}}
\author{Mickael Randour\inst{1} \and Jean-Fran\c{}cois Raskin\inst{1} \and Ocan Sankur\inst{2}}

\institute{
D\'epartement d'Informatique, Universit\'e libre de Bruxelles (ULB), Belgium
\and CNRS, Irisa, Rennes, France
}

\begin{document}
\maketitle

\begin{abstract}
Markov decision processes (MDPs) with multi-dimensional weights are useful to analyze systems with multiple objectives that may be conflicting and 
require the analysis of trade-offs. We study the complexity of percentile queries in such MDPs and give algorithms to synthesize strategies that enforce such constraints. 
Given a multi-dimensional weighted MDP and a quantitative payoff function~, thresholds  (one per dimension), and probability thresholds , 
we show how to compute a single strategy to enforce that for all dimensions , the probability of outcomes  satisfying  is at least . 
We consider classical quantitative payoffs from the literature (sup, inf, lim sup, lim inf, mean-payoff, truncated sum, discounted sum).  
Our work extends to the quantitative case  the multi-objective model checking problem studied by Etessami et al.~\cite{EKVY-lmcs08} in unweighted MDPs.
\end{abstract}

\section{Introduction}

{\em Markov decision processes} (MDPs) are central mathematical models for reasoning about (optimal) strategies in {\em uncertain environments}. For example, if rewards (given as numerical values) are assigned to actions in an MDP, we can search for a strategy (policy) that resolves the nondeterminism in a way that the {\em expected mean reward} of the actions taken by the strategy over time is maximized. See for example~\cite{Puterman-wiley94} for a solution to this problem. If we are risk-averse, we may want to search instead for strategies that ensure that the mean reward over time is larger than a given value with a high probability, i.e., a probability that exceeds a given threshold. See for example~\cite{FKR-ieee95} for a solution.

Recent works are exploring several natural extensions of those problems.
First, there is a series of works that investigate MDPs with multi-dimensional
weights~\cite{CMH-stacs06,BBCFK-lmcs14} rather than single-dimensional as it is
traditionally the case. Multi-dimensional MDPs are useful to analyze systems
with {\em multiple objectives} that are potentially conflicting and make
necessary the analysis of trade-offs. For instance, we may want to build a
control strategy that both ensures some good quality of service and minimizes the energy consumption. Second, there are works
that aim at synthesizing strategies enforcing {\em richer properties}. For
example, we may want to construct a strategy that both ensures some minimal
threshold with certainty (or probability one) and a good expectation~\cite{DBLP:conf/stacs/BruyereFRR14}. An illustrative survey of such extensions can be found in~\cite{DBLP:conf/vmcai/RandourRS15}.
 
Our paper participates in this general effort by providing algorithms and complexity results on the synthesis of strategies that enforce {\em multiple percentile constraints}.  A \textit{multi-percentile query} and the associated synthesis problem is as follows: given a multi-dimensionally weighted MDP  and an initial state , synthesize a strategy  such that it satisfies the conjunction of  constraints:

where each  refers to a dimension of the weight vectors, each  is a value threshold, and  is a probability threshold, and  is a payoff function. Each constraint  expresses that the strategy ensures probability at least  to obtain payoff at least  in dimension .

We consider seven payoff functions: sup, inf, limsup, liminf, mean-payoff, truncated sum and discounted sum. This wide range covers most classical functions: our exhaustive study provides a \textit{complete picture} for the new multi-percentile framework and we focus on establishing meta-theorems and connections whenever possible. Some of our results are obtained by reduction to the previous work of~\cite{EKVY-lmcs08}, but for mean-payoff, truncated sum and discounted sum, that are {\em non-regular payoffs}, we need to develop original techniques.

Let us consider some examples. In an MDP that models a stochastic shortest path problem, we may want to obtain a strategy that ensures that the probability to reach the target within  time units exceeds 50 percent: this is a single-constraint percentile query. With a {\em multi-constraint percentile query}, we can impose richer properties on strategies,
for instance, enforcing that the duration is less than  in at least 50 percent of the cases, and less than  in 95 percent of the cases, with . 
We may also consider percentile queries in multi-dimensional systems. If in the model, we add information about fuel consumption, we may also enforce that we arrive within  time units in 95 percent of the cases, and that in half of the cases the fuel consumption is below some threshold .

\paragraph{\bf Contributions.} We study percentile problems for a range of classical payoff functions: we establish algorithms and prove complexity and memory bounds.
Our algorithms can handle multi-constraint multi-dimensional queries, but
we also study interesting subclasses, namely, multi-constraint single-dimensional queries, single-constraint queries, and other classes depending on the payoff functions.
We present an overview of our results in Table~\ref{table}.
For all payoff functions but the discounted sum, they only require \textit{polynomial time in the size of the model} when the query size is fixed. 
In most applications, the query size is typically small while the model
can be very large. So our algorithms have clear potential to be useful in practice.


\def\arraystretch{1.2}
\begin{table}[t]
  \footnotesize
  \centering
  \begin{tabular}{|c||c|c|c|}
    \cline{2-4} \multicolumn{1}{c||}{} & \multirow{2}{*}{~Single-constraint~} & Single-dim. & ~Multi-dim.~ \\
    \multicolumn{1}{c||}{} & & ~Multi-constraint~ & ~Multi-constraint~\\
    \hline
    \hline
    Reachability & \PTIME~\cite{Puterman-wiley94} & P()E()~\cite{EKVY-lmcs08}, \PSPACE-h & --- \\
    \hline
    \multirow{2}{*}{~~} & \multirow{2}{*}{\PTIME~\cite{CH-ilc09}} & \multirow{2}{*}{\PTIME} & ~P()E()~ \\
    & & & \PSPACE-h.\\
    \hline
    ~ & ~\PTIME~\cite{Puterman-wiley94}~ & \PTIME & \PTIME\\
    \hline
    ~ & ~\PTIME~\cite{Puterman-wiley94}~ & ~P()E()~ & ~P()E()~\\
    \hline
    \multirow{2}{*}{~SP~} &  ~P()P()~\cite{HaaseK14}~ & ~P()P() (one target)~ & ~P()E()~\\
    & ~\PSPACE-h.~\cite{HaaseK14}~ & ~\PSPACE-h.~\cite{HaaseK14}~ & ~\PSPACE-h.~\cite{HaaseK14}~\\
    \hline
    \multirow{2}{*}{~-gap DS} & ~P()~ & ~P()E()~ & ~P()E()~\\
    & \NPTIME-h. & \NPTIME-h. & \PSPACE-h.\\
    \hline
  \end{tabular}
  \vspace{2mm}
  \caption{Some results for percentile queries. Here ,  (resp. ) stands for sup. (resp. inf.) mean-payoff, SP for shortest path, and DS for discounted sum. Parameters  and  resp. represent model size and query size; P(), E() and P() resp. denote polynomial, exponential and pseudo-polynomial time in parameter . All results without reference are new.}
  \vspace{-6mm}
  \label{table}
\end{table}

We give a non-exhaustive list of contributions and highlight some links with related problems. 
\begin{itemize}
\item[A)] We show the \PSPACE-hardness of the multiple reachability problem with exponential dependency on the query size (Theorem~\ref{thm:asreach}), and
the \PSPACE-completeness of the almost-sure case, refining the results of~\cite{EKVY-lmcs08}. We also prove that in the case of \emph{nested} target sets, the problem admits polynomial-time solution (Theorem~\ref{thm:monotonic-reach}), and we use it to solve some of the multi-constraint percentile problems.
\item[B)] For payoff functions , ,  and , we establish a polynomial-time algorithm for the single-dimension case (Theorem~\ref{thm:quant_reg_single_dim}), and an algorithm that is only exponential in the size of the query for the general case (Theorem~\ref{thm:quant_reg_multi_dim}).
We prove the \PSPACE-hardness of the problem for  (Theorem~\ref{thm:quant_reg_multi_dim_pspace}), and give a polynomial time algorithm for  
(Theorem~\ref{lemma:limsup}).
\item[C)] In the mean-payoff case, we distinguish  defined by the limsup of the average weights, and~ by their liminf. For the former, we give a polynomial-time algorithm for the general case (Theorem~\ref{thm:mpsup}). For the latter, our algorithm is polynomial in the model size and exponential in the query size (Theorem~\ref{thm:mpinf}).
\item[D)] The truncated sum function computes the \emph{sum} of weights until a target is reached. It models \emph{shortest path} problems. We prove the multi-dimensional percentile problem to be undecidable when both negative and positive weights are allowed (Theorem~\ref{thm:truncated_undec}). Therefore, we concentrate on the case of non-negative weights, and establish an algorithm that is polynomial in the model size and exponential in the query size (Theorem~\ref{thm:sp_overview}). We derive from~\cite{HaaseK14} that even the single-constraint percentile problem is \PSPACE-hard.
\item[E)] The discounted sum case turns out to be difficult, and linked to a long-standing open problem, not known to be decidable (Lemma~\ref{lem:ds_precise}). Nevertheless, we give algorithms for an approximation of the problem, called -gap percentile problem. Our algorithm guarantees correct answers up to an arbitrarily small zone of uncertainty (Theorem~\ref{thm:ds_overview}). We also prove that this -gap problem is \PSPACE-hard in general, and already \NPTIME-hard for single-constraint queries (Lemma~\ref{lem:ds_pspace_hard} and Lemma~\ref{lem:ds_np_hard}). According to a very recent paper by Haase and Kiefer~\cite{HaasePP}, our reduction even proves \textsf{PP}-hardness of single-contraint queries, which suggests that the problem does not belong to  at all otherwise the polynomial hierarchy would collapse.
\end{itemize}

We systematically study the memory requirement of strategies. We build our
algorithms using different techniques. Here are a few of them. For  and
 payoff functions, we reduce percentile queries to multiple reachability
queries, and rely on the algorithm of \cite{EKVY-lmcs08}: those are the
easiest cases. For ,  and , we additionally need to
resort to maximal end-component decomposition of MDPs. For the following cases,
there is no simple reduction to existing problems and we need non-trivial
techniques to establish algorithms.
For , we use linear programming techniques to characterize winning strategies, borrowing ideas from~\cite{EKVY-lmcs08,BBCFK-lmcs14}. For shortest path and discounted sum, we consider unfoldings of the MDP, with particular care to bound their sizes, and for the latter, to analyze the cumulative error due to necessary roundings.

\paragraph{{\bf Related work.}}
There are several works in the literature that study multi-dimensional MDPs: for discounted sum, see~\cite{CMH-stacs06}, and for mean-payoff, see~\cite{BBCFK-lmcs14,FKR-ieee95}.
In the latter papers, 
the following threshold problem is studied in multi-dimensional MDPs: given a threshold vector~ and a probability threshold , does there exist a strategy  such that , where  denotes the mean-payoff vector.
The work~\cite{FKR-ieee95} solves this problem for the single dimensional case, and the multi-dimensional for the \emph{non-degenerate} case (w.r.t.~the solutions of a linear program). 
A general algorithm was later given in \cite{BBCFK-lmcs14}.
This problem asks for a bound on the \emph{joint probability} of the thresholds, that is, the probability of satisfying \emph{all} constraints simultaneously. In contrast,
in our problem we bound the \emph{marginal probabilities} separately, which may allow for more modeling flexibility.
The problem of maximizing the \emph{expectation vector} was also solved in~\cite{BBCFK-lmcs14}. Recently, and independently from our work, the problem of bounding the marginal probabilities was considered in~\cite{CKK-lics15} for .
The given algorithm consists in a single linear program
(while we use a two-step procedure), has the same ingredients as ours, and has the same complexity. In addition, the algorithm of~\cite{CKK-lics15} also allows one to add
a constraint on the expectation vector.

Multiple reachability objectives in MDPs were considered in~\cite{EKVY-lmcs08}: given an MDP and multiple targets~, thresholds , decide if there exists a strategy that forces each  with a probability larger than . This work is the closest to our work and we show here that their problem is inter-reducible with our problem for the sup measure. In~\cite{EKVY-lmcs08} the complexity results are given only for the size of the model and not for the size of the query: we refine those results here and answer questions that were left open in that paper.

Several works consider percentile queries but only for \textit{one} dimension and {\em one} constraint (while we consider multiple constraints and possibly multiple dimensions) and particular payoff functions. Single-constraint queries for  and  were studied in~\cite{CH-ilc09}. 
The threshold probability problem for truncated sum was studied in MDPs with either all non-negative or all non-positive weights in~\cite{Ohtsubo-amc2004,SO-jcta13}. \textit{Quantile queries} in the single-constraint case were studied for
the shortest path with non-negative weights 
in~\cite{DBLP:conf/fossacs/UmmelsB13}, and for
energy-utility objectives in~\cite{BDDKK-fm14}. They have been recently extended to \textit{cost problems}~\cite{HaaseK14}, in a direction orthogonal to ours. For fixed finite horizon, \cite{XM-ijcai11} considers the problem of ensuring a single-contraint percentile query for the discounted sum, and that of maximizing the expected value subject to a single percentile constraint. Still for the discounted case, there is a series of works studying \textit{threshold problems}~\cite{White1993634,WL99} and \textit{value-at-risk problems}~\cite{DBLP:conf/fsttcs/BrazdilCFNS13}. All can be related to single-constraint percentiles queries.

This paper extends previous work presented in a conference~\cite{RRS-cav15}: it gives a full presentation of the technical details, along with additional results.
 
\section{Preliminaries}

\smallskip\noindent\textbf{Markov decision processes.} A finite \textit{Markov decision process} (MDP) is a tuple  where
 is the finite set of \emph{states}, ~is the finite set of \emph{actions} and 
is a partial function called the \emph{probabilistic transition function}, where~ denotes the set of rational probability distributions over~.
The set of actions that are available in a state  is denoted by . 
We use  as a shorthand for .
An \emph{absorbing state}  is such that for all , . We assume w.l.o.g.~that MDPs are \textit{deadlock-free}: for all ,  (if not the case, we simply replace the deadlock by an absorbing state with a unique action). An MDP where for all ,  is a fully-stochastic process called a \textit{Markov chain}.

A \textit{weighted} MDP is a tuple , where  is a \emph{-dimension weight function}~.
For any , we denote  
the projection of~ to the~-th dimension, i.e., the function mapping each action  to the -th element of vector .
A \emph{run} of~ is an infinite sequence  of
states and actions such that  for all~.
Finite prefixes of runs are called \emph{histories}.

Fix an MDP .
An \emph{end-component} (EC) of  is
an MDP  with ,  for all~,
and~ for all~
(here  denotes the support),  and such that  is \textit{strongly connected}, i.e., there is a run between any pair of states in .
The union of two ECs with non-empty intersection is
an EC; one can thus define \emph{maximal} ECs.
We let  denote the set of maximal ECs of~, computable in
polynomial time~\cite{DeAlfaro-phd97}.

\smallskip\noindent\textbf{Strategies.} A~\emph{strategy}~ is a function  such that
for all~ ending in~, we have~. The set of all strategies is . A strategy is \textit{pure} if all histories are mapped to \textit{Dirac distributions}. A strategy~ can be encoded by a 
\emph{Moore machine},  
where~ is a finite or infinite set of memory elements,~ the \emph{initial
distribution on~}, 
 the \emph{memory update
function} , 
and  the \emph{next action
function} where  for any~ and~.
We say that~ is \emph{finite-memory} if~, and \emph{-memory} if~;
it is memoryless if~, thus only depends on the last state of the history. 
We see such strategies as functions  for . 
A strategy is \emph{infinite-memory} if~ is infinite.
For a class of problems, we say that strategies use linear (resp. polynomial, exponential) memory 
if there exist strategies for which  is linear (resp. polynomial, exponential) in the size of~. The entity choosing the strategy is often called the \textit{controller}.

An MDP~, a strategy~ encoded by , and a state~ determine a
Markov chain  defined on the state space  as follows.
The initial distribution is such that for any~,
state  has probability , and~ for other states. For any pair of states
 and~, the probability of the transition  is
equal to 
if , and to~ otherwise.
A~\emph{run} of~ is an infinite sequence of the form
, where each
 is a transition with nonzero probability
in~, and~. 
When considering the probabilities of events in , we
will often consider sets of runs of~. Thus, given , we denote by  the probability of the runs 
of~ whose projection\footnote{The projection of a run
 in  to  is simply the run  in .} to~ is in~, i.e., the probability of event  when  is executed with initial state~ and strategy . Note that every event has a uniquely defined probability \cite{vardi_FOCS85} (Carath\'eodory's extension theorem induces a unique probability measure on the Borel -algebra over ).


\smallskip\noindent\textbf{Almost-sure reachability of ECs.} Let~ denote the random variable representing the disjoint union of states and actions that occur
infinitely often in the run~. By an abuse of notation,
we see  as a sub-MDP~ if it contains
exactly the states and actions of~. 
It was shown that for any MDP~, state~, strategy~,
~\cite{DeAlfaro-phd97}.



\smallskip\noindent\textbf{Multiple reachability.} Given a subset~ of states,
let  be the \emph{reachability objective w.r.t.~}, defined as 
the set of runs visiting a state of~ at least once.
The \emph{multiple reachability} problem consists, given MDP~, state~, target sets
, and probabilities~, 
in deciding whether there exists a strategy~
such that

The \emph{almost-sure multiple reachability} problem restricts to .

\label{sec:percentilesProblem}
\smallskip\noindent\textbf{Percentile problems.} 
We consider \textit{payoff functions} among , , ,
, mean-payoff, truncated sum (shortest path) and discounted sum. For
any run~, dimension~, and weight
function ,
\vspace{-1mm}
\begin{itemize*}
\item
  ,
  ,
\item
  ,
  ,
\item 
  ,   ,
\item
  , with  a rational discount factor,
\item 
 with  the first visit of a state in . If  is never reached, then we assign .
\end{itemize*}
\vspace{-1mm}

For any payoff function~,  defines the runs~ that satisfy .
A~\emph{percentile constraint} is of the form~, where~ is to be synthesized given threshold value~ and probability~. We study \emph{multi-constraint percentile queries} requiring to simultaneously satisfy~ constraints each referring to a possibly different dimension.
Formally, given a -dimensional weighted MDP~, initial state , payoff function~,
dimensions , value thresholds  and probability thresholds , the \emph{multi-constraint percentile problem} asks if there exists a strategy~ such that query

	holds. We can actually solve queries
, .
We present our results for conjunctions of constraints only since
the latter is equivalent to verifying the disjuncts independently:
in other terms, to
.

We distinguish \textit{single-dimensional percentile problems} () from
\textit{multi-dimensional} ones ().
We assume w.l.o.g.~that  otherwise one can simply neglect unused dimensions.
For some cases, we will consider the \emph{-relaxation} of the problem,
which consists in ensuring each value~ with probability~.


\smallskip\noindent\textbf{Complexity.} We assume binary encoding of constants,
and define the \emph{model size} , a polynomial in  and the size of the \textit{encoding} of weights and probabilities (e.g.,  with  the largest absolute weight), as the size of the representation of~; and the \emph{query size} , a polynomial in the number of constraints  and the encoding of thresholds, that of the query.
The \emph{problem size} refers to the sum of the two.

\smallskip\noindent\textbf{Memory and randomness.} 
Throughout the paper, we will study the memory requirements for strategies w.r.t.~different classes of percentile queries.
Here, we show, by a simple example, that randomness is always needed for all payoff functions.

\begin{lemma}
Randomized strategies are necessary for multi-dimensional percentile queries for any payoff function.
\end{lemma}

\begin{proof}
Let  be a 2-dim.~deterministic MDP with ,  and the transition function defined as , ,  and . Essentially there are only two possible runs in this MDP:  and . Assume that the weight and the payoff functions are chosen such that  and : they are incomparable. Consider the query  It is easy to see that  can only be satisfied by a strategy that chooses between  and  with equal probability, hence no pure strategy satisfies the query. 
Note that here  can be chosen anything among ,  with appropriate ,
and  with target sets~ and~ respectively for each query. For , and~, we may switch the weight vectors to obtain the same result.
\end{proof}

\section{Multiple Reachability and Contraction of MECs}
\label{section:reachsafe}

\smallskip\noindent\textbf{Multiple reachability.} The multiple reachability  problem
was studied \cite{EKVY-lmcs08} where an algorithm based on a linear program (LP) of size polynomial in the model and exponential in the query was given.
As a particular case, it was proved that restricting the target sets to absorbing states yields a polynomial-size LP. We will use this LP later in Fig.~\ref{fig:mpinf-lp} in Section~\ref{section:mp}.


\begin{theorem}[\cite{EKVY-lmcs08}]
  \label{thm:absorbing-reachsafe}
  Memoryless strategies suffice for multiple reachability with absorbing target states, and
  can be decided and computed in polynomial time.
  With arbitrary targets, exponential-memory strategies (in query size) can be computed in time polynomial in the model and exponential in the query.
\end{theorem}


In this section, we improve over this result by showing that the case of almost-sure multiple reachability is \PSPACE-complete,
with a recursive algorithm and a reduction from QBF satisfiability.
This also shows the \PSPACE-hardness of the general problem. Moreover, we show that exponential memory is required for strategies,
following a construction of \cite{DBLP:journals/acta/ChatterjeeRR14}.

\begin{theorem}
  \label{thm:asreach}
  The almost-sure multiple reachability problem is \PSPACE-complete,
  and strategies need exponential memory in the query size.
\end{theorem}

We first show the \PSPACE-completeness of the almost-sure multiple reachability problem.

\begin{lemma}
  The almost-sure multiple reachability problem is \PSPACE-complete.
\end{lemma}

\begin{proof}
  We start by showing \PSPACE-membership. Let~ be an MDP,~ a state, and  target sets. We write
  . Note first that we know how to solve the problem in polynomial time for~.
  Let~ be the MDP obtained by~ by making all states in~ absorbing. The procedure works as follows. For each state~,
  let us define ; we clearly have .
  We recursively verify whether there is a strategy almost-surely satisfying the multiple reachability objective .
  Let~ denote all states of~ for which the recursive call returned positively. We now check in polynomial time whether
  the set~ can be reached almost-surely from~.
  Note that the recursive call depth is linear, so the whole procedure uses polynomial space.

  We now prove the equivalence between~ and~. Assume that there is a strategy~ almost-surely reaching~ in~.
  This strategy can be followed in~ until some state~ of~ is reached, which happens almost-surely. But we know, by the recursive callof our procedure, that from any such state~ there exists a strategy almost-surely satisfying the rest of the reachability objectives.
  Thus, by extending~ in each state~ by these strategies, we construct a solution to the multiple reachability problem in~. Notice that the constructed strategy uses linear memory since it is ``memoryless'' between each switch.

  Conversely, assume that there is a strategy~ satisfying the multiple reachability query in~ from~.
  Towards a contradiction, assume that some state  is reached with positive probability in~ under~, 
  thus also in~ under the same strategy. We know by the recursive call of our procedure that the remaining targets cannot be satisfied 
  almost-surely by any strategy from state~ in~. It follows that strategy  fails to satisfy all targets almost-surely 
  from~, a contradiction.
  
  
  
  To show \PSPACE-hardness, we reduce the truth value of a quantified Boolean formula (QBF) to our problem. An instance of QBF is a quantified Boolean formula over 
  

   
   \noindent
    where each clause  is the disjunction of 3 literals taken in . 
    From , we construct an (acyclic) MDP as shown in Fig.~\ref{fig:qbf}. For each variable , there are three states called ,  and  in the MDP. In a state  that corresponds to an {\em existentially quantified} variable, there are two actions that are available:  and . The action  visits (deterministically) the state  while the action  visits the state , and then in the two cases, the run proceeds to the state for the next variable.  Intuitively, choosing  in  corresponds to the choice of truth value {\sf true} for , and  to truth value {\sf false}. In a state  that corresponds to an {\em universally quantified} variable, there is only the action  available and the successor is chosen uniformly at random between  and . The targets are defined as follows: for each clause , the target set  must be visited with probability one. Clearly, given the value assigned to a variable , we visit exactly the set of target sets  that correspond to the clauses that are made true by the valuation of . It should be clear now that the histories in the MDP are in bijection with the valuation of the Booelan variables in  and that the set of valuations that satisfies  correspond exactly to the histories that visits all the sets ,  with probability one.  
    
    

\begin{figure}[t]
  \centering  
  \scalebox{1.2}{\begin{tikzpicture}
    \tikzstyle{every state}=[node distance=1cm,minimum size=10pt, inner sep=1pt];
    \node[state] at (0,0) (x1){};
    \node[state,below right of=x1] (t1) {};
    \node[state,above right of=x1] (f1) {};
    \node[state,below right of=f1] (x2) {};
    \node[state,right of=x2, fill=black,minimum size=3pt] (x2b) {};
    \node[state,below right of=x2b] (t2) {};
    \node[state,above right of=x2b] (f2) {};
    \node[state,below right  of=f2] (x3) {};
    \node[right of=x3] (etc) {};
    \node[state,right of=etc] (xn) {};
    \node[state,below right of=xn] (tn) {};
    \node[state,above right of=xn] (fn) {};
    \path[-latex']
    (x1) edge node[below left] {} (t1) 
    (x1) edge node[above left] {} (f1)
    (t1) edge (x2)
    (f1) edge (x2)
    (x2) edge node[above] {} (x2b)
    (x2b) edge node[below left] {} (t2)
    (x2b) edge node[above left] {} (f2)
    (t2) edge (x3)
    (f2) edge (x3)
    (xn) edge node[below left] {} (tn)
    (xn) edge  node[above left] {} (fn)
    (fn) edge[loop right] (fn)
    (tn) edge[loop right] (tn);
  \end{tikzpicture}}
  \caption{Reduction for the QBF formula
    .
  The objectives are 
for all .}
  \label{fig:qbf}
\end{figure}

   
  Now, we claim that there is a strategy to reach each set , , with probability one if and only if the formula  is true. Indeed, if  is true, we know that there exists for each existentially quantified variable  a choice function  which assign a truth value to  given the truth values chosen for the variables that appears before  in the quantification block. These choice functions naturally translate into a (deterministic memryfull) strategy that mimics the choices of truth values by choosing between  and  accordingly. We get that if the formula is true (all closed are made true) then the associated strategy visits all the target sets with probability one.   
  
  For the other direction, we first note that it is not useful for the scheduler to play a randomised strategy. As the graph of the MDP is acyclic (except for the two states  and  that have a self loop), all the target sets are visited with probability one if and only if all the outcomes of the strategy visits all the target sets. So, if the scheduler plays randomly say in state  then all the resulting outcomes for action  and all the resulting outcomes for action  must visit all the target sets, so both choices need to be good and so there is no need for randomisation and the scheduler can safely choose one of the two arbitrarily. So, pure strategies are sufficient and but we have seen that pure strategies corresponds exactly to the choice functions in the QBF problem. So is clear that from a winning strategy for the scheduler, we can construct a choice function that makes the formula true.
  \end{proof}


We establish an exponential lower bound on the memory requirements based on a family of MDPs depicted in Fig.~\ref{fig:multiReach_exp_mem} and inspired from \cite[Lemma 8]{DBLP:journals/acta/ChatterjeeRR14}.

\begin{lemma}
  \label{lem:multiReach_expMemoryLB}
  Exponential-memory in the query size is necessary for almost-sure multiple reachability.
\end{lemma}
\begin{proof}
Consider the unweighted MDP  depicted in Fig.~\ref{fig:multiReach_exp_mem}. The MDP is composed of  gadgets where a state between  and  is stochastically chosen (they are equiprobable), followed by  gadgets where the controller can decide to visit either  or . We define an almost-sure multiple reachability problem for target sets 

Hence, this problem requires  constraints to be defined. We claim that a strategy satisfying this problem cannot be expressed by a Moore machine containing less than  memory states.



\begin{figure}[htb]
  \centering   
  \scalebox{0.9}{\begin{tikzpicture}[->,>=stealth',shorten >=1pt,auto,node
    distance=2.5cm,bend angle=45,scale=0.4, inner sep=0pt, font=\small]
    \tikzstyle{p1}=[draw,circle,text centered,minimum size=8mm]
    \tikzstyle{p2}=[fill,circle,text centered,minimum size=1.5mm]
    \node[p1]  (0)  at (0, 0) {};
    \node[p2]  (0b)  at (2.4, 0) {};
    \node[p1]  (1) at (4, 2) {};
    \node[p1]  (2) at (4, -2)  {};
    \node[p1]  (3) at (8, 0)  {};
    \node[p2]  (3b)  at (10.4, 0) {};
    \node[p1]  (4)  at (12, 2) {};
    \node[p1]  (5)  at (12, -2) {};
    \node[p1]  (6)  at (16, 0) {};
    \node[p1]  (7) at (20, 2) {};
    \node[p1]  (8) at (20, -2)  {};
    \node[p1]  (9) at (24, 0)  {};
    \node[p1]  (10)  at (28, 2) {};
    \node[p1]  (11)  at (28, -2) {};
    \coordinate[shift={(-5mm,0mm)}] (init) at (0.west);
    \path     
    (0) edge (0b)
    (0b) edge[shorten <=1pt] (1)
    (0b) edge[shorten <=1pt] (2)
    (3) edge (3b)
    (3b) edge[shorten <=1pt] (4)
    (3b) edge[shorten <=1pt] (5)
    (10) edge [loop right, out=40, in=320,looseness=3, distance=4cm] (10)
    (11) edge [loop right, out=40, in=320,looseness=3, distance=4cm] (11)
    (init) edge (0);
	\draw[dotted,->,>=latex] (1) to (3);
	\draw[dotted,->,>=latex] (2) to (3);
	\draw[->,>=latex] (4) to (6);
	\draw[->,>=latex] (5) to (6);
	\draw[->,>=latex] (6) to (7);
	\draw[->,>=latex] (6) to (8);
	\draw[dotted,->,>=latex] (7) to (9);
	\draw[dotted,->,>=latex] (8) to (9);
	\draw[->,>=latex] (9) to (10);
	\draw[->,>=latex] (9) to (11);
\end{tikzpicture}}
      \vspace{-10mm}
      \caption{Family of multiple reachability problems requiring exponential memory.}
\label{fig:multiReach_exp_mem}
  \end{figure}

Indeed, it is clear that to ensure almost-sure reachability of all sets , the controller has to chose in state  the exact opposite action of the one stochastically chosen in . Remembering the  choices made in states  requires  bits of encoding. Hence, a satisfying strategy requires a Moore machine with  memory states to encode those choices.

It is easy to see that if the controller uses a - possibly randomized - strategy  with less than  memory states, then there exists  such that , i.e., the controller chooses to go to  (resp. ) with identical probability against both stochastic choices in~. Assume that the controller chooses to go toward  with probability  and toward  with probability : this implies that the probability that the target set  (resp. ) is never visited is equal to  (resp. ). Clearly, it is impossible to have both those probabilities equal to zero simultaneously, which proves that such a strategy cannot satisfy the almost-sure multiple reachability problem defined above, and concludes our proof.
\end{proof}

Despite the above lower bounds, it turns out that the polynomial time algorithm for the case of absorbing targets can be extended:
we identify a subclass of the multiple reachability problem that admits a polynomial-time solution.
In the \emph{nested multiple reachability} problem, the target sets are nested, i.e., 
.
The memory requirement for strategies is reduced as well to linear memory.

\begin{theorem}
  \label{thm:monotonic-reach}
  The nested multiple reachability problem can be solved in polynomial time.
  Strategies have memory linear in the query size, which is optimal.
\end{theorem}

 Intuitively, we use  copies of the original MDP, one for each target set, plus one last copy. The idea is then to travel between those copies in a way that reflects the nesting of target sets whenever a target state is visited. The crux to obtain a polynomial-time algorithm is then to reduce the problem to a multiple reachability problem \textit{with absorbing states} over the MDP composed of the  copies, and to benefit from the reduced complexity of this case.
 
\begin{proof}
  Assume an MDP~,  and the target sets  are given.
  We make~ copies of the MDP~, namely, . We start  at state~.
  We redirect some of the edges as follows.
  For any~, state~, action~, and , if  for some , then we direct this edge to state~ in 
  where  is the smallest index with .
  Hence, along any run, we are in copy~ if, and only if we have already satisfied all targets .
  Now, we add a fresh absorbing state~ to each copy. From all states of~ a fresh action~ leads to~.
  Let us call this new MDP~. Note that the size of~ is .

  For each~, we define .
  We claim that the multiple reachability problem query  for~
  is equivalent to~ for~. But the latter query has absorbing target states, thus the problem can be solved in polynomial time
  by~\cite{EKVY-lmcs08}.
  
  Consider a strategy~ for~ achieving the objectives .
  We can assume w.l.o.g. that~ is finite-memory by~\cite{EKVY-lmcs08}.
  Let~ denote the set of states of~.
  We define strategy~ for~ as follows. Let us define a mapping~ from the histories of~ to those of~, where a state of any copy
  is projected to the original state in~. The mapping is actually a bijection from histories of~ that do not use the action~
  to histories of~.
  Now, for all histories~ of~ that end in copy~,
  if~, we set . Otherwise, we let~.

  We prove that for all~, .
  Let~ denote the copy in which~ ends in~.
  For all histories~ of~ from which the probability of satisfying  is nonzero,
  we have  by definition.
  Define ,
  that is, the histories that visit~ for the first time at their last state.
  Clearly .
  But the probability of reaching   is always nonzero along these histories, so 
  we also have ,
  and we get .
  In other words, ,
  that is, the target sets  are reached in~ with at least the same probabilities as in~.
  We now need to show that from any history ending in copy~, some state~ with~
  is reached almost-surely in~ under~. It will follow that
  .
  To see this, notice that strategy~ is finite-memory, and so is~. 
  So there exists  such that for any state~, and memory element~
  if the probability of satisfying  is nonzero from~ and~, 
  then it is at least~. Note that the probability of never satisfying
   while staying in such states is~.
  So, whenever the run reaches copy~, almost-surely,
  either some copy~ with~ is reached, or we reach a history~ such that , in which case we end in~.
  The inequality follows.


  Conversely, consider any strategy  for~ achieving the reachability objectives .
  We assume  to be memoryless by~\cite{EKVY-lmcs08}.
  We define~ whenever the action~ prescribes is different than~, and otherwise
   switches to an arbitrary memoryless strategy. Since all histories of~ that end in~ satisfy the objectives
  , strategy~ achieves the objectives .
  The memory of  is  since  is memoryless in~ which is made of~ copies of~.

  We now show that linear memory is necessary.
  Consider an MDP~ with states~. State~ has~ actions~.
  For each~, action~ leads from~ to~ with probability~,
  and with probability~ leads to absorbing state~. From all states~ with ,  is reachable by a deterministic action,
  but from~ one can only reach .
  The MDP is depicted in Fig.~\ref{fig:nested} ( is not shown).

\vspace{-4mm}
\begin{figure}[h]
\begin{center}
\scalebox{0.9}{
  \begin{tikzpicture}
    \tikzstyle{every state}=[node distance=1.5cm,minimum size=20pt, inner sep=1pt];
    \node[state] at (0,0) (s){};
    \node[state,minimum size=1pt, fill=black] at (-2.5, 1) (sn) {};
    \node[state, minimum size=1pt, fill=black] at (0.4,1) (sn1) {};
    \node[state, minimum size=1pt, fill=black] at (2.5, 1) (s1) {};    
    \node[state] at (-3, 2) (tn) {};
    \node[state] at (0, 2) (tn1) {};
    \node[right of=tn1] (etc) {};
    \node[state] at (3, 2) (t1) {};
    \path[-latex']
    (s) edge[bend left] node[left]{} (sn)
    (sn) edge node[left]{\tiny } (tn)
    (sn) edge node[below]{\tiny } ()
    (s) edge node[right]{} (sn1)
    (sn1) edge node[left]{\tiny } (tn1)
    (sn1) edge node[below]{\tiny } ()
    (s) edge[bend right]  node[right]{} (s1)
    (s1) edge node[left]{\tiny } (t1)
    (s1) edge node[left]{\tiny } ()
    (tn) edge[gray,bend left=-10]  (s)
    (tn1) edge[gray,bend right=60]  (s)
    (t1) edge[gray]  ();
  \end{tikzpicture}}
  \caption{Linear memory is required for the nested multiple reachability problem.}
  \label{fig:nested}
\end{center}
\vspace{-6mm}
\end{figure}

We consider the nested multiple reachability targets 
with  for each~, and consider threshold probabilities
 defined by
, and 
for .

Let us first describe a strategy that satisfies these constraints.
Define a strategy that deterministically
chooses, at each visit to state~, the following actions: . A simple calculation
shows that the constraints are satisfied: the probability of satisfying  is at least  by the first action,
that of  is  by the sequence  of actions, and so on.
We argue that this is the only strategy that satisfies these reachability queries showing that  memory is necessary.

Consider any strategy~ satisfying the multiple reachability queries. We show that  must deterministically choose~ in the first step.
In fact, assume that some action~ with  is chosen with probability~. The probability of moving to  under any such action is at least
. Thus the probability of going to  in the first step (without seeing any ) is at least
, which is a contradiction.
Now, assume that  deterministically chooses  in the first~ steps. The probability of reaching  in the first  steps is thus ,
while the probability of being in~ (and not in~) after  steps is .
Assume that  does not deterministically choose .
Target~ is reached by histories that eventually choose some action . Let~ denote the set of histories
stopping at the first action from this set, i.e.,
.
Note that at these histories, either we satisfy  or we end in , so the probability of satisfying  under~ can be written as
, where  is the probability of~ of choosing the actions of  from the current history,
and  is the probability of the resulting run.
We have, for all~,  since 
 contains  actions outside  and  after each such action 
we must come back to~.
For all  with , we must have  since otherwise we would get .
Furthermore, if  chooses an action some action~ with  in the first step, the probability of going to 
is . It follows that  for the unique history that chooses action .
\end{proof}


\smallskip\noindent\textbf{Contraction of MECs.} In order to solve percentile queries, we sometimes reduce our problems to multiple reachability by first contracting MECs of given MDPs,
which is a known technique~\cite{DeAlfaro-phd97}. We define a transformation of MDP~ to represent the events  for~
as fresh states. Intuitively, all states of a MEC will now lead to an absorbing state that will abstract the behavior of the MEC.

Consider~ with~. We define MDP~ from~ as follows. For each~, we add state~ and action~ from each state~ to~.
All states~ are absorbing, and . 
The probabilities of events  in~ are captured by the reachability of states  in~, as follows. We use the classical temporal logic symbols  and  to represent the \textit{eventually} and \textit{always} operators respectively.

\begin{lemma}
  \label{lemma:mec-contract}
	Let~ be an MDP and . For any strategy~ for , there exists a strategy~ for~ such that
  for all , . 
  Conversely, for any strategy~ for~ such that , there exists~
  such that for all
  , . 
\end{lemma}

\begin{proof}
  Consider any strategy~ in~ with .
  We define strategy~ for~ by imitating~ except that whenever it chooses action~ from some state~, we switch 
  to a memoryless strategy that surely stays inside~. The desired equality follows. The other direction was proved in \cite[Lemma 4.6]{BBCFK-lmcs14}.
\end{proof}

Under some hypotheses, solving multi-constraint percentile problems on ECs
yield the result for all MDPs, by  the transformation of Lemma~\ref{lemma:mec-contract}.
We prove a general theorem and then derive particular results as corollaries.

\begin{theorem}
  \label{thm:general}
  Consider all prefix-independent payoffs~ such that for all strongly connected MDPs~, 
  and all , 
there exists a strategy~ such that
  
  If the value  is computable in polynomial time for strongly connected MDPs, then the multi-constraint percentile problem for~ is decidable in polynomial time.
  Moreover, if strategies achieving  for strongly connected MDPs use  memory,
  then the overall strategy use  memory.
\end{theorem}


The hypotheses are crucial. Essentially, we require payoff functions that are prefix-independent and for which strategies can be combined easily inside MECs (in the sense that if two constraints can be satisfied independently, they can be satisfied simultaneously). Prefix-independence also implies that we can forget about what happens before a MEC is reached. Hence, by using the MEC contraction, we can reduce the percentile problem to multiple reachability for absorbing target states.

\begin{proof}
  Consider an MDP~, an initial state~, and an instance of the multi-constraint percentile problem  for payoff function~.
  
  Let~ denote the MECs of~.
  Consider the MDP~ of Lemma~\ref{lemma:mec-contract}.
  For each~, let~ denote the component-wise optimal value vector achievable inside~ and~ a witness strategy,
  which can be computed by hypothesis in polynomial time. Note that because  is prefix-independent and each~ strongly connected,
  it follows by~\cite{Chatterjee-tcs07} that .
  In fact, for strongly connected MDPs, if a prefix-independent measure can be satisfied with nonzero probability, then there exists a state from which 
  the threshold can be satisfied with probability~.
  Moreover, because the MDP is strongly connected, such a state is reachable almost-surely from any other state.

  Now, for each~, we define~,
  where states  were defined in Lemma~\ref{lemma:mec-contract}.
  We solve the multiple reachability with absorbing targets~ in~, 
  with probabilities~, by Theorem~\ref{thm:absorbing-reachsafe}.
  All computations are in polynomial time. We now establish the connection with the multi-constraint percentile problem.

  Assume there is a strategy~ in~ witnessing the multiple reachability problem. 
  Recall that the strategy~ for~ of Lemma~\ref{lemma:mec-contract} derived from~ consists in following~ until an action~ is taken, upon which 
  one switches to an arbitrary strategy inside the current MEC. Let us define strategy~ in this manner,
  by switching to the optimal strategy~, where~ is the current MEC. It follows that, for each~, the probability of switching to~ for~ such that
   is at least~. But such~ satisfy  almost-surely in~. Because~ is prefix-independent,
  we get .
  Strategy~ thus just needs one additional bit compared to~ to remember whether it has switched to a strategy inside a MEC.

  Conversely, consider any strategy~ satisfying the multi-constraint percentile problem for~. Let~ be the strategy 
  for~ given by Lemma~\ref{lemma:mec-contract}.
  We have,
  
Furthermore, we  implies that
 as observed above. It follows that,
.
We obtain 

which concludes the proof.
\end{proof}

\section{Inf, Sup, LimInf, LimSup Payoff Functions}
\label{section:quant-reg}
\label{subsection:single-simple}

\smallskip\noindent\textbf{Single-dimensional queries.} We give polynomial-time algorithms for the \emph{single}-dimensional multi-cons\-traint percentile problems.
For  and  we reduce the problem to nested multiple reachability, while  and  are solved by applying Theorem~\ref{thm:general}. 

\begin{theorem}
\label{thm:quant_reg_single_dim}
  The single-dimensional multi-constraint percentile problems can be solved in polynomial time in the problem size
  for , , , and  functions. Computed strategies use memory linear in the query size for~ and ,
  and constant memory for  and~.
\end{theorem}
\begin{proof}
  Let us fix MDP~, and a starting state~. We start with . The result will be derived by Theorem~\ref{thm:monotonic-reach}.
  Consider an instance  of the problem, where we assume w.l.o.g. that .
  To simplify the argument, let us assume that weights are assigned to states rather than edges;
  one can always transform the given MDP (in polynomial time) to ensure this.
  We define  as the set of states whose weights are at least~. The problem
  of ensuring that  by some strategy~ 
  is then equivalent to the nested reachability problem with targets~.
  The problem can thus be solved in polynomial time by Theorem~\ref{thm:monotonic-reach}.
  The resulting strategies use linear memory by this theorem.

  For , consider an instance  of the problem with~.
  We make  copies of~, each named~. For any state~ of~, we refer as~ to the corresponding copy in~.
  The starting state is~.
  In each~, any edge from~ to~ 
  of weight~ is redirected to~, where~ is the least index such that~.
  Intuitively, if the run is in~, this means that the current history~ violates all constraints  for all~.  
  For each , let  denote the set of states of  from which  can be surely satisfied.
  These sets can be computed in polynomial time.
  Now, we add an absorbing state  for each copy , and a fresh action  deterministically leads to~ from all states .
  Note that~ has size . Define .
  Now the multiple reachability instance  on~ (with absorbing target states) is equivalent to 
  the multi-constraint percentile problem for inf. In fact, from any strategy~ satisfying the reachability probabilities in~, one can clearly construct
  a strategy for  by following~ until some state~ is reached, and then switching to a strategy that is surely safe for the objective .
  Conversely, given a strategy  for~ satisfying the multi-constraint percentile query, we define strategy~ for~ by following~, and as soon as
  some state~ is reached, going to~. We argue that for each , the probability of reaching  is at least~
  in~ under~.
  In fact, otherwise, with probability more than , the play always stays outside this set. Because  is a safety property, this means that 
  the property is violated with probability more than , which is a contradiction.
  The resulting strategy uses linear memory since  is made of~ copies of~.

  
  For liminf and limsup, consider an instance  of the problem, where we assume~.
  We are going to use Theorem~\ref{thm:general}.

  The problem is easy to solve for an end-component~: for each~, one removes all edges with weight smaller than~, and checks 
  if there is an end-component~ included in~. Consider the largest~ with this property. We know that from any state of~,
   can be reached almost-surely, and one can stay inside~ surely. Then by such a strategy, all constraints
   for  are satisfied almost-surely, 
  while other constraints are violated almost-surely by any strategy that stays inside~.
  Optimal strategies inside strongly connected MDPs are thus memoryless.
  We satisfy the hypotheses of Theorem~\ref{thm:general},
  which yields a polynomial-time algorithm.

  The limsup case is solved similarly: In each end-component~, if~ denotes the largest~ such that some edge of~ has weight~, then all constraints  
  for~ can be satisfied almost-surely, and no other constraint is satisfied by any strategy.
  
  The memory usage follows from Theorem~\ref{thm:general}.
\end{proof}



\smallskip\noindent\textbf{Multi-dimensional queries.}
\label{subsection:multi-simple}
We show that all multi-dimensional cases can be solved in time polynomial in the model size and exponential in the query size by a reduction to multiple LTL objectives studied in~\cite{EKVY-lmcs08}. 
Our algorithm actually solves a more general class of queries, where the payoff function can be different for each query.

\begin{theorem}
\label{thm:quant_reg_multi_dim}
  The multi-dimensional percentile problems for , ,  and  can be solved in time polynomial in the model size and exponential in the query size,
  yielding strategies with memory exponential in the query.
\end{theorem}

Given an MDP~, for all~ and value~, we denote~ the set of actions of~ whose rewards are at least~.  We fix an MDP~. 
 For any constraint , we define an LTL formula denoted~ as follows. For , , for , , for , , and for , .
The percentile problem is then reduced to queries of the form , 
for which an algorithm was given in~\cite{EKVY-lmcs08} that takes time polynomial in  and doubly exponential in~. We improve this complexity since our formulae have bounded sizes.

\begin{lemma}
  For all constraints , and probabilities~,
  there exists a strategy~ such that 
  if, and only if, there exists a strategy~ such that 
  This can be decided in time polynomial in the model and exponential in the query, and computed strategies use exponential memory in the query.  
\end{lemma}
\begin{proof}
  The correspondence between LTL formulae and weighted objectives are clear by construction.
  The complexity follows from \cite{EKVY-lmcs08}. In fact, 
  if~ denotes the subset construction applied to B\"uchi automata recognizing~, 
  then the multiple objective LTL problem can be solved in time polynomial in the size of
  the product of~ with . But for each formula, a B\"uchi automaton of size~ can be constructed; it follows that the algorithm of~\cite{EKVY-lmcs08} has complexity polynomial in~ and exponential in~. 
  The computed strategy is memoryless on the product of~ and~, thus the corresponding strategy for~ has memory  which is a single exponential in~.
\end{proof}

The exponential dependency on the query size cannot be avoided in general unless , as shown in the following theorem.


\begin{theorem}
\label{thm:quant_reg_multi_dim_pspace}
  The multi-dimensional percentile problem is \PSPACE-hard for .
\end{theorem}
\begin{proof}
  Multiple reachability with arbitrary target sets can be encoded as the multi-dimensional multi-constraint percentile problem for  with weights from , as we show now.
  Given MDP~ and targets~, we define~ by duplicating states as follows.
  For each state~, we create a new state~. All actions leaving~ now leave from~,
  and a single action~ deterministically leads from~ to~.
  It is clear that there is a bijection between the strategies of~ and those of~ and that they induce the same reachability probabilities for any subset of states of~.
  We define a -dimensional weight function on~ that takes values in . At any state~, 
   if, and only if~. All other actions have value~.
  In other terms, the weight function assigns~ to dimension~ if the target set~ is seen. Since the payoff function is , along any history
  the dimensions that have the value~ are exactly the target sets that have been satisfied.
  For any probabilities~, ,
  if, and only if .
  \PSPACE-hardness follows from Theorem~\ref{thm:asreach}.
\end{proof}

Nevertheless, the complexity can be improved for  functions, for which we give a polynomial-time algorithm by an application of Theorem~\ref{thm:general}.

\begin{theorem}
  \label{lemma:limsup}
  The multi-dimensional percentile problem for  is solvable in polynomial time.
  Computed strategies use constant-memory.
\end{theorem}

\begin{proof}
  The problem is easy to solve if~ is strongly connected.
  In fact, if for some~,  contains no action whose weight at dimension~ is at least~, 
  then no strategy satisfies~ with positive probability. Conversely, let~ such that for each~,
   contains an edge~ with~. Then, there is a strategy~ satisfying
  . In fact, because~ is strongly connected
  each state and action can be eventually reached almost-surely from any state. 
  In particular, the strategy which assigns uniform probabilities to all available actions visits all states infinitely often almost-surely.
  
  Thus, we satisfy the hypotheses of Theorem~\ref{thm:general}, and a polynomial-time algorithm follows.
\end{proof}

\noindent
The exact query complexity of the  and  cases are left open. 

\section{Mean-payoff}
\label{section:mp}
We consider the multi-constraint percentile problem both for~ and~.
We will see that strategies require infinite memory in both cases, in which case
it is known that the two payoff functions differ.
The \emph{single-constraint} percentile problem was first solved in~\cite{FKR-ieee95}.
The case of multiple dimensions was mentioned as a challenging problem but left open.
We solve this problem thus generalizing the previous work. 

\subsection{The Single-Dimensional Case}

We start with a polynomial-time algorithm for the single-dimensional case
obtained via Theorem~\ref{thm:general}, thus extending the results of~\cite{FKR-ieee95} to multi-constraint percentile queries.

\begin{theorem}
  The single dimensional multi-constraint percentile problems for payoffs~ and~ are equivalent and solvable in polynomial time.
  Computed strategies use constant memory.
\end{theorem}

\begin{proof}
  Let~ be the MECs of a given MDP~.
  If we define ,
  then for each~, there exists a strategy~, computable in polynomial time, with the property
  ~\cite{Puterman-wiley94}. In other terms, optimal strategies exist for single dimensional mean-payoff,
  and the optimal value can be achieved almost-surely inside strongly connected MDPs.
  In contrast,  no value greater than the optimal value can be achieved with positive probability. 
  The polynomial-time algorithm then follows from Theorem~\ref{thm:general}.

  The equivalence between~ and~ follows from the fact that they are equivalent inside MECs since
  memoryless strategies exist, and that the strategy of Theorem~\ref{thm:general} almost-surely eventually switches to 
  an optimal strategy for a MEC.
\end{proof}

\subsection{Percentiles on Multi-Dimensional }

Let  be the \emph{expectation} of~ under strategy~,
and , computable in polynomial time~\cite{Puterman-wiley94}.
We solve the problem inside ECs, then apply Theorem~\ref{thm:general}.
It is known that for strongly connected MDPs, for each~, some strategy~ satisfies ,
and that for all strategies~,  for all .
By switching between these optimal strategies for each dimension, with growing
intervals, we prove that
for strongly connected MDPs, a single strategy can simultaneously optimize  on \emph{all} dimensions.

We first recall the following result on the convergence speed of optimal memoryless strategies
in MDPs.

\begin{lemma}[\cite{Tracol09}]
  \label{lemma:boundk}
  Let~ be any single-dimensional weighted MDP, ,
  and  an optimal memoryless strategy with .
  For all~ and~, there exists  such that  for all ,
  
\end{lemma}

We now show that strongly connected multi-dimensional MDPs, a single strategy can simultaneously optimize , on \textit{all} dimensions.

\begin{lemma}
  For any strongly connected MDP~,  there is an infinite-memory strategy~ such that , .
\end{lemma}

\begin{proof}
  Let us write , and let~ be a memoryless 
  optimal strategy for this dimension.
  We define a strategy that switches between these strategies~ with growing time intervals. 
  We fix , and define the sequence .
  Let . For~, if~ the bound given by Lemma~\ref{lemma:boundk}
  for~ and~, we choose~ such that .
  Strategy~ is defined by running~ during~ steps where .
  Let us define .
  
  We now prove that~ achieves the optimal value at each dimension with probability~.
  Let~ denote the random variable of the -th action of an execution for a given MDP, initial state, and strategy.
  Fix any dimension . For any~ such that ,
  between steps  and~, strategy~ is memoryless, and by Lemma~\ref{lemma:boundk},
  we have
  
  Observe that , and .
  So, with probability~, we get
  
  This means that for any~, there exists~ such that for all~ with , we have
  
  so  for all~.
  It follows that  for all dimensions~.
\end{proof}

Thanks to the above lemma, we fulfill the hypotheses of Theorem~\ref{thm:general}, and we obtain the following theorem.

\begin{theorem}
\label{thm:mpsup}
  The multi-dimensional percentile problem for~
  is solvable in polynomial time. Strategies use infinite-memory, which is necessary.
\end{theorem}


To see that infinite-memory strategies are necessary for , consider the MDP of Fig.~\ref{fig:mpsup-memory} where thresholds  can be achieved almost-surely by the above theorem, but not by any finite-memory strategy. The proof is identical to the case of maximizing the expectation in~\cite[Lemma 7]{CDHR-fsttcs10} where it is proved for the case of deterministic MDPs (i.e., automata).

\begin{figure}[ht]
  \centering
  \scalebox{1.2}{
  \begin{tikzpicture}
    \tikzstyle{every state}=[node distance=2cm,minimum size=15pt, inner sep=1pt];
    \node[state] at (0,0) (s){};
    \node[state, right of=s] (t) {};
    \path[-latex'] 
    (s) edge[bend left] (t)
    (t) edge[bend left] (s)
    (s) edge[loop left, looseness = 2, distance = 6mm] node{} (s)
    (t) edge[loop right, looseness = 2, distance = 6mm] node{} (t);
  \end{tikzpicture}}
  \caption{Infinite-memory strategies are necessary for .}
  \label{fig:mpsup-memory}
\end{figure}

\subsection{Percentiles on Multi-Dimensional }
\label{section:multidim-mpinf}

In contrast with the  case, our algorithm for  is more involved, and requires new techniques.
In fact, the case of end-components is already non-trivial for , since there is no single strategy 
that satisfies all percentile constraints in general, and one cannot hope to apply Theorem~\ref{thm:general} as we did in previous sections.
We rather need to consider the set of strategies~ satisfying \emph{maximal} subsets of percentile constraints; these are called \emph{maximal strategies}.
We then prove that any strategy satisfying all percentile queries can be written as a \emph{linear combination} of maximal strategies, that is,
there exists a strategy which chooses and executes each~ following a probability distribution.

For general MDPs, 
we first consider each MEC separately and write down the linear combination with unknown coefficients.
We know that any strategy in a MDP eventually stays forever in a MEC. Thus, we adapt the linear program
of~\cite{EKVY-lmcs08} that encodes the reachability probabilities with multiple targets, which are the MECs here.
We combine these reachability probabilities with the unknown linear combination coefficients, and obtain a linear program 
(Figure~\ref{fig:mpinf-lp}), which we prove to be equivalent to our problem.

\smallskip\noindent\textbf{Single EC.}
Fix a strongly connected -dimensional MDP~ and 
pairs of thresholds . We denote each event by~.
In \cite{BBCFK-lmcs14}, the problem of maximizing the \emph{joint} probability of the events~ was solved in polynomial time.
In particular, we have the following for strongly connected MDPs.
\begin{lemma}[{\cite{BBCFK-lmcs14}}]
  \label{lemma:joint-bounds}
	If~ is strongly connected, then there exists~ such that  if, and only if
    there exists~ such that~.
    Moreover, this can be decided in polynomial time, and for positive instances, for any~,
    a memoryless strategy~ can be computed in polynonomial time in ,  and~, such that
    
\end{lemma}

We give an overview of our algorithm.
Using Lemma~\ref{lemma:joint-bounds}, we define strategy  achieving 
for any maximal subset~ for which such a strategy exists.
Then, to build a strategy for the multi-constraint problem, we look for a linear combination of these~: given , we choose each~ following a probability distribution to be computed, and we run~.

We now formalize this idea. Let~ be the set of maximal~ (for set inclusion) such that some 
satisfies . 
Note that for all , and~,
. Assuming otherwise would contradict the maximality of~, by Lemma~\ref{lemma:joint-bounds}.
We consider the events 
for maximal~.

We are looking for a non-negative family 
 whose sum equals~ and such that , .
This will ensure that if each~ is chosen with probability~ (among the set ); with probability at least~,
some strategy satisfying~ with probability~ is chosen. So each~ is satisfied with probability at least~.
This can be written in the matrix notation as

where~ is a  matrix with~ if~, and~ otherwise.

\begin{lemma}
  For any strongly connected MDP~,
  and an instance  of the multi-constraint percentile problem for~,
  \eqref{eqn:mpinf-scc-lp} has a solution if, and only if there exists a strategy~ satisfying
  the multi-constraint percentile problem.
\end{lemma}

\begin{proof}
  Assume~\eqref{eqn:mpinf-scc-lp} and consider the strategy , which means that
  at the beginning of the run, we choose each set~ with probability~, and run
  . Clearly, the probability of satisfying  is at least the probability of running
  a strategy  such that~, which is .
  The result follows.

  Conversely, let~ denote a strategy satisfying  for all~.
  Let us consider all events~ including non-maximal~.
  The events~ are disjoint and we have .
  It follows that 
  since  by definition.
  In order to derive a probability distribution on \emph{maximal} subsets only, 
  we define a partition of~ by assigning each non-maximal~ to a maximal~
  with~. Formally,
  we consider sets~ with~, 
   such that for all~, , and  defines a partition of~.
  For any~, we set
  .
  This yields a solution of~\eqref{eqn:mpinf-scc-lp}.
\end{proof}

Now \eqref{eqn:mpinf-scc-lp} has size , and each subset~ can be checked in time polynomial in the model size.
The computation of , the set of maximal subsets, can be carried out in a top-down fashion;
one might thus avoid enumerating all subsets in practice.
We get the following result.

\begin{lemma}
  For strongly connected MDPs, the multi-dimensional percentile problem for   can be solved in time polynomial 
  in~ and exponential in~. Strategies require infinite-memory in general.
  On positive instances, -memory randomized strategies can be computed for the~-relaxation of the problem
  in time polynomial in~.
\end{lemma}

\begin{proof}
  The first statement is clear from the two previous lemmas, since 
  \eqref{eqn:mpinf-scc-lp} can be solved in time polynomial in~ and exponential in~.
  For the -relaxation problem, notice that
  once we compute the set~ and solve \eqref{eqn:mpinf-scc-lp}, for any set~, we compute in polynomial time a randomized strategy  ensuring . This can be done 
  as in~\cite{BBCFK-lmcs14}. Then the strategy choosing randomly each  with probability   ensures all bounds up to  (i.e., ).

  The need for infinite memory was proved in~\cite[Section 5]{BBCFK-lmcs14} for the problem of
  ensuring thresholds  for thresholds  and probability~.
  It was proved that on the MDP of Fig.~\ref{fig:mpsup-memory},  and~ can be ensured by an infinite-memory strategy and that
  finite-memory strategies can only achieve these thresholds with probability~.
  Now, if the multi-constraint percentile query  
  has a solution by a strategy~, then we must have  (this simply follows from the fact that
  ). Therefore~ must use infinite-memory.  
\end{proof}

\smallskip\noindent\textbf{General MDPs.} Given MDP~, let us consider~ given by Lemma~\ref{lemma:mec-contract}.
We start by analyzing each maximal EC~ of~ as above, and compute the sets  of maximal subsets.
We define a variable  for each~, and also  for each state~ and action~. Recall that
 for states~ that are inside a MEC, and~ otherwise.
Let  be the set of states of~ that belong to a MEC.
We consider the linear program (L) of Fig.~\ref{fig:mpinf-lp}.

\vspace{-5mm}
\begin{figure}[th]
	\small
  
\vspace{-2mm}
  \caption{Linear program~(L) for the multi-constraint percentiles for~.}
  \label{fig:mpinf-lp}
\end{figure}
\vspace{-3mm}

We prove the following main lemma in this section.

\begin{lemma}
  \label{lemma:mpinf-lp}
  The LP~(L) has a solution if, and only if the multi-constraint percentiles problem for  has a solution. Moreover, the equation has size polynomial in~ and exponential in~.
  From any solution of~(L) randomized finite memory strategies can be computed for the -relaxation problem.
\end{lemma}


  The linear program follows the ideas of~\cite{EKVY-lmcs08,BBCFK-lmcs14}. 
  Note that the first two lines of~(L) corresponds to the multiple reachability LP of~\cite{EKVY-lmcs08} for absorbing target states.
The equations encode strategies that work in two phases.
  Variables~ correspond to
  the expected number of visits of state-action~ in the first phase. Variable~ describes the probability 
  of switching to the second phase at state~.
  The second phase consists in surely staying in the current MEC, so we require 
  (and we will have  if  does not belong to a MEC).
  In the second phase, we immediately switch to some
	strategy~ where  denotes the current MEC. Thus, variable~ corresponds to the probability
  with which we enter the second phase in~ and switch to strategy~ (see~\eqref{eqn:thirdline}).
  Intuitively, given a solution  computed for one EC by \eqref{eqn:mpinf-scc-lp}, we have the correspondence
  .
  The interpretation of~\eqref{eqn:fifthline} is that each event~ is satisfied with probability at least~.

The two following lemmas prove Lemma~\ref{lemma:mpinf-lp}. 

\begin{lemma}
  If (L) has a solution then there exists a strategy for the multi-constraint percentile problem.
  Moreover, from any solution of (L) one can derive in time polynomial in~, , and exponential in~, a -memory randomized strategy
  solving the -relaxation of the multi-constraint percentile problem.
\end{lemma}

  
\begin{proof}
  Let~ be a solution of (L).
  By \cite[Theorem 3.2]{EKVY-lmcs08}, there exists a memoryless strategy~ for~ such that
   for each MEC~,
  and  by the second line.  
  In this strategy,  is the probability of going to~ from~.

  For each MEC~, we define the strategy~ for~ which, from the states of~,
  executes each strategy
   for~ with probability ,
  if the denominators are positive, and with an arbitrary distribution otherwise.
  We combine these in a strategy~ for~
  which starts by simulating~ until~ chooses takes the action~, at which point
   switches to~.

  By construction the probability of~ of switching to~ is
  , for any~ and~.
  Moreover, thanks to the fact that , we know that  will eventually switch to some~ almost-surely. 
  Because for all~ and~ such that~, the probability of~ of satisfying~ inside~ is~ (see above), 
  we get that the probability of satisfying~ under~ is equal to the probability of switching to some~.
  But thanks to the last line of the program, this quantity is at least~.
  Hence,~ satisfies the multi-constraint percentile problem.

  We obtain a strategy for the relaxed problem as follows. Each strategy~ may be infinite-memory a priori
  but for any~, we can compute by Lemma~\ref{lemma:joint-bounds}, memoryless randomized strategies~ ensuring~
  with probability~. Now, since~ is also memoryless, the combined strategy only needs  memory elements (to store the phase, and which~ it has chosen once in a MEC).
  The result follows.
\end{proof}

\begin{lemma}
  If strategy~ solves the multi-constraint percentile problem for~, then (L) has a solution.
\end{lemma}
\begin{proof}
  Let~ denote the MECs,
  and define~ for each~.
  Clearly, we have .
  Let~ denote the strategy on~ of Lemma~\ref{lemma:mec-contract} given for~.
  For any action~, let~ denote the expected number of times action~ is taken at~ under~
  in~ starting at~. 
  Now, \cite[Lemma 3.3]{EKVY-lmcs08} ensures that these variables have finite values and satisfy the 
  first two lines of (L).

  We define strategy~ for~ which follows~ until action~ is taken, at which point
  it switches to each strategy  with probability 	(these include non-maximal sets~).
  We have that 
  
  By definition of~, the first term in the sum equals
  .
  The second term in the sum is equal to . 
  It follows that .

  Now, to obtain a solution of (L), it remains to get rid of the strategies~ for non-maximal subsets~ for each MEC.
  We thus modify once more~ to obtain~ as follows. Whenever~ switches to some strategy~,
  where~ is not maximal, we rather switch to some  for some -arbitrarily chosen- maximal~.
  It is clear that  and
   for all~.
  
  Now, for each~ and~, we define .
  It is easy to verify that  and , so \eqref{eqn:thirdline} and~\eqref{eqn:fourthline} are satisfied.
  We have 
  for all . Moreover, .
  This is at least equal to~ as we saw above, which is at least~ by assumption; hence \eqref{eqn:fifthline} is also satisfied.
\end{proof}

Our results for the multi-dimensional problems with  are summed up in the next theorem.

\begin{theorem}
\label{thm:mpinf}
  The multi-dimensional percentile problem for  can be solved in 
  time polynomial in the model, and exponential in the query.
  Infinite-memory strategies are necessary, but exponential-memory (in the query) suffices
  for the -relaxation and can be computed with the same complexity.
\end{theorem}

\section{Shortest Path}
\label{sec:sp}
We study shortest path problems in MDPs, which generalize the classical graph problem. In MDPs, the problem consists in finding a strategy ensuring that a target set is reached with bounded truncated sum with high probability.
This problem has been studied in the context of games and MDPs (e.g.,~\cite{bertsekas_MOR1991,DBLP:conf/concur/Alfaro99,DBLP:conf/stacs/BruyereFRR14}).
We consider percentile queries of the form  (inner inequality  is more natural but  could be used by negating all weights). Observe that each constraint  may relate to a different target set .

\subsection{MDPs with Arbitrary Weights}

We prove that without further restriction, the multi-dimen\-sion\-al percentile problem is undecidable, even for a fixed number of dimensions. Our proof is inspired by the approach of Chatterjee et al.~for the undecidability of two-player multi-dimensional total-payoff games~\cite{DBLP:journals/iandc/Chatterjee0RR15} but requires additional techniques to adapt to the stochastic case. 

\begin{theorem}
\label{thm:truncated_undec}
The multi-dimensional percentile problem is undecidable for the truncated sum payoff function, for MDPs with both negative and positive weights and four dimensions, even with a unique target set.
\end{theorem}


\begin{proof}
We reduce the halting problem for two-counter machines (2CMs) to a multi-dimensional percentile problem for the truncated sum payoff function over an MDP with weights in , with a unique target set.

Counters of a 2CM take values  along an execution, and can be incremented or decremented (if positive). A counter can be tested for equality to zero, and the machine can branch accordingly.
The halting problem for 2CMs is well-known to be undecidable~\cite{minsky1961}.

Consider a 2CM . From this 2CM, we construct an MDP  and a target set of states , with an initial state  such that there exists a strategy  satisfying the four-dimensional percentile query

if and only if the machine does not halt.

Intuitively, this MDP is built such that strategies that do not faithfully simulate the 2CM~ cannot satisfy the percentile query. To ensure that this is the case, we will implement checks through probabilistic transitions that will produce bad runs with positive probability against unfaithful strategies.

The MDP  is built as follows. The states of  are copies of the control states of  (plus some special states discussed in the following). Actions in the MDP represent transitions between these control states. The weight function maps actions to -dimensional vectors of the form , that is, two dimensions for the first counter  and two for the second counter . Each increment of counter  (resp. ) in  is implemented in  as an action of weight  (resp. ). For decrements, we have weights respectively  and  for  and . Therefore, the current value of counters  along an execution of the 2CM  is represented in the MDP as the current sum of weights, . Hence, along a faithful execution, the 1st and 3rd dimensions are always non-negative, while the 2nd and 4th are always non-positive. The two dimensions per counter are used to enforce faithful simulation of non-negativeness of counters and zero test.

\begin{figure}[tb]
        \centering
        \begin{subfigure}[b]{0.26\textwidth}
        \centering
               \scalebox{1.1}{\begin{tikzpicture}[->,>=stealth',shorten >=1pt,auto,node
    distance=2.5cm,bend angle=45, scale=0.6, inner sep=0pt,font=\scriptsize]
    \tikzstyle{p1}=[draw,circle,text centered,minimum size=5mm,text width=4mm]
    \tikzstyle{p2}=[fill,circle,text centered,minimum size=1.5mm]
    \node[p1]  (1) at (0, 0)  {};
    \node[p2]  (3)  at (0, -2.5) {};
    \node[p1,dashed]  (2)  at (1.6, -4) {};
    \node[draw,rectangle,dashed,inner sep=2pt] (4) at (-1.6, -4) {escape gadget};
    \path
    (3) edge[shorten <=1pt](2)
    (3) edge[shorten <=1pt] (4)
    (1) edge node[left] {} (3);
      \end{tikzpicture}}
                \caption{Increment .}
        \end{subfigure} \begin{subfigure}[b]{0.7\textwidth}
        \centering
               \scalebox{1.1}{\begin{tikzpicture}[->,>=stealth',shorten >=1pt,auto,node
    distance=2.5cm,bend angle=45, scale=0.6, inner sep=0pt,font=\scriptsize]
    \tikzstyle{p1}=[draw,circle,text centered,minimum size=5mm,text width=4mm]
    \tikzstyle{p2}=[fill,circle,text centered,minimum size=1.5mm]
    \node[p1]  (1) at (0, 0)  {};
    \node[p2]  (2)  at (4, 0) {};
    \node[p1,dashed]  (3) at (8, 2)  {};
    \node[p1]  (4) at (8, -2)  {};
    \node[p1,double]  (5) at (12, -2)  {};
    \node[draw,rectangle,dashed,inner sep=2pt] (6) at (3, -2) {escape gadget};
\path
    (1) edge node[above] {} (2)
    (2) edge[shorten <=1pt](3)
    (2) edge[shorten <=1pt] (4)
    (2) edge (6)
    (4) edge (5)
    (4) edge [loop above, out=130, in=50,looseness=3, distance=2cm] node [above] {} (4)
    (5) edge [loop above, out=130, in=50,looseness=3, distance=2cm] node [above] {} (5);
      \end{tikzpicture}}
                \caption{Decrement .}\label{fig:sp_undec_gadgets_dec}
        \end{subfigure}
        
\vspace{4mm}       

\begin{subfigure}[b]{0.26\textwidth}
        \centering
               \scalebox{1.1}{\begin{tikzpicture}[->,>=stealth',shorten >=1pt,auto,node
    distance=2.5cm,bend angle=45, scale=0.6, inner sep=0pt,font=\scriptsize]
    \tikzstyle{p1}=[draw,circle,text centered,minimum size=5mm,text width=4mm]
    \tikzstyle{p2}=[draw,rectangle,text centered,minimum size=5mm,text width=4mm]
    \node[p1]  (1)  at (0, 0) {};
    \path
    (0, 2) edge (1)
    (1) edge [loop below, out=230, in=310,looseness=3, distance=2cm] node [below] {} (1);
      \end{tikzpicture}}
                \caption{Halting.}
        \end{subfigure} \begin{subfigure}[b]{0.7\textwidth}
        \centering
               \scalebox{1.1}{\begin{tikzpicture}[->,>=stealth',shorten >=1pt,auto,node
    distance=2.5cm,bend angle=45, scale=0.6, inner sep=0pt,font=\scriptsize]
    \tikzstyle{p1}=[draw,circle,text centered,minimum size=5mm,text width=4mm]
    \tikzstyle{p2}=[fill,circle,text centered,minimum size=1.5mm]
    \node[p1]  (1) at (0, 0)  {};
    \node[p2]  (2)  at (4, 0) {};
    \node[p1,dashed]  (3) at (8, 2)  {};
    \node[p1]  (4) at (8, -2)  {};
    \node[p1,double]  (5) at (12, -2)  {};
    \node[draw,rectangle,dashed,inner sep=2pt] (6) at (3, -2) {escape gadget};
    \path
    (1) edge (2)
    (2) edge[shorten <=1pt](3)
    (2) edge[shorten <=1pt] (4)
    (4) edge (5)
    (2) edge (6)
    (4) edge [loop above, out=130, in=50,looseness=3, distance=2cm] node [above] {} (4)
    (5) edge [loop above, out=130, in=50,looseness=3, distance=2cm] node [above] {} (5);
      \end{tikzpicture}}
                \caption{Checking that  is equal to zero.}\label{fig:sp_undec_gadgets_zero}
        \end{subfigure}
\vspace{4mm}       

\begin{subfigure}[b]{1\textwidth}
        \centering
             \scalebox{1.1}{\begin{tikzpicture}[->,>=stealth',shorten >=1pt,auto,node
    distance=2.5cm,bend angle=45, scale=0.6, inner sep=0pt,font=\scriptsize]
    \tikzstyle{p1}=[draw,circle,text centered,minimum size=5mm,text width=4mm]
    \tikzstyle{p2}=[draw,rectangle,text centered,minimum size=5mm,text width=4mm]
    \node[p1]  (1) at (0, 0)  {};
    \node[p1,double]  (2)  at (4, 0) {};
    \path
    (-2, 0) edge (1)
    (1) edge node[above] {} (2)
    (1) edge [loop above, out=130, in=50,looseness=3, distance=2cm] node [above] {} (1)
    (2) edge [loop above, out=130, in=50,looseness=3, distance=2cm] node [above] {} (2);
      \end{tikzpicture}}
                \caption{Escape gadget reachable by every action of the MDP.}
        \end{subfigure}
        \caption{Gadgets encoding 2CM halting problem in a multi-dimensional percentile problem for truncated sum payoff function.}\label{fig:sp_undec_gadgets}    
\end{figure}


We now discuss how this MDP  ensures faithful simulation of the 2CM~ by the controller through the use of the gadgets represented in Fig.~\ref{fig:sp_undec_gadgets}. Small filled circles represent equiprobable stochastic transitions, double circles depict states of the target set .
\begin{itemize}
\item An \textit{escape gadget} has a positive probability to be reached whenever an instruction of the 2CM is simulated. When in this gadget, the controller can decrease the sum on all dimensions below zero by cycling long enough before deciding to reach the target, hence making the run acceptable for the considered percentile query.

\item \textit{Increment and decrement} of counter values are easily simulated using the first four dimensions.

\item \textit{Values of counters may never go below zero}. To ensure this, we make every decrement action probabilistic with three equiprobable outcomes. Consider the decrement of  as depicted in Fig.~\ref{fig:sp_undec_gadgets_dec}. Either the simulation continues (dashed control state), or it branches to the escape gadget, or it branches to the bottom right part of the decrement gadget. In that case, the controller can cycle long enough in the first state to ensure a negative sum of weights in all dimensions except for the second one, before reaching the target (runs \textit{have to} reach the target or their truncated sum will be ). If the controller is not faithful and a negative value is reached on counter  when decrementing, this branching will induce a run which is losing because the second dimension will be strictly positive (recall it has value ). Notice that the controller can never cheat, otherwise this branching will happen with strictly positive probability (i.e., after a finite prefix). On the contrary, if the controller never cheats, this branching is harmless and induces acceptable runs w.r.t. the percentile query. The gadget is similar for decrements of  using the fourth dimension.

\item \textit{Zero tests are correctly executed}. In the same spirit, we allow a probabilistic branching after the controller claims a counter is equal to zero. Consider Fig.~\ref{fig:sp_undec_gadgets_zero} for counter . If a zero test is passed while , the sum on the first dimension will stay strictly positive and the run will not be acceptable. On the contrary, if the controller is faithful, this branching is again harmless as it is possible to make all sums negative except for the first dimension for which it would already be equal to zero. We use a similar gadget for  based on the third dimension. We also need to ensure that the controller cannot cheat by claiming that a counter is strictly positive while it is not. To achieve this, we follow each claim that  is strictly positive by a decrement on  (using our gadget) followed by an increment (idem). Thus, if  is equal to zero while the controller claims the opposite, the decrement gadget will yield non-acceptable runs, as seen before. On the other hand, if the controller is faithful, visiting those two gadgets is safe (and does not modify the counters for the rest of the simulation).

\item \textit{Halting}. The end of a 2CM execution is modeled in the MDP by an halting state. This state does not belong to the target set : any run corresponding to an halting execution will have its truncated sum equal to  on all dimensions, which makes it bad for the percentile query.

\end{itemize}

Now, we have argued that if the simulation is not faithful, bad runs will be produced with strictly positive probability, and the percentile query will not be satisfied. Furthermore, if the machine halts, then with a strictly positive probability, the halting state will be reached (because the machine halts after a \textit{finite} number of operations), which also results in bad runs. Hence if the percentile query is satisfied by a strategy , then this strategy describes a faithful infinite execution of .

It remains to show that if the 2CM does not halt, the percentile query is satisfiable. Clearly, the halting state will never be reached, and gadgets cannot produce bad runs as the simulation is faithful. However, runs that never reach any target state (i.e., runs that never branch away from the simulation) are still bad runs as they yield an infinite truncated sum. Nonetheless, observe that each action taken in the MDP yields a strictly positive probability to branch to the escape gadget or to branch inside decrement and zero-test gadgets. Hence, if the 2CM does not halt, such actions are taken infinitely often and with probability one, the simulation eventually branches toward the target states (with a good truncated sum as argued before). We conclude that the strategy that simulates a never-halting machine does yield good runs with probability one.

Consequently, we have that the studied multi-dimensional percentile problem is equivalent to the 2CM halting problem, and thus, undecidable.
\end{proof}

\subsection{MDPs with Non-Negative Weights}

In the light of this result, we will restrict our setting to non-negative weights, a setting closer to the original interpretation of the shortest path problem (we could equivalently consider non-positive weights with inequality  inside percentile constraints). We first discuss recent related work.

\smallskip\noindent\textbf{Comparison with quantiles and cost problems.} In~\cite{DBLP:conf/fossacs/UmmelsB13}, Ummels and Baier study \textit{quantile queries} over non-negatively weighted MDPs. They are equivalent to minimizing  in a single-constraint percentile query  such that there still exists a satisfying strategy, for some fixed . Very recently, Haase and Kiefer extended quantile queries by introducing \textit{cost problems}~\cite{HaaseK14}. They can be seen as single-constraint percentile queries where inequality  is replaced by an arbitrary Boolean combination of inequalities~. Hence, it can be written as .
Cost problems are studied on single-dimensional MDPs and all the inequalities relate to the same target , in contrast to our setting which allows both for multiple dimensions and multiple target sets. The single probability threshold bounds the probability of the whole event~.
	
Both settings are incomparable. 
Cost problems consist in a unique query that checks that with probability , paths satisfy the Boolean combination . In percentile queries, we have several constraints and we check that \textit{each} inequality is satisfied with the corresponding probability : paths do not need to satisfy \textit{all} inequalities at the same time. In full generality, for a fixed probability threshold , it is easier to satisfy a unique constraint over a disjunction of inequalities than to satisfy a disjunction of constraints over single inequalities: in the second case,  percent of the paths must satisfy the \textit{same} unique inequality, not in the first one. Similarly, it is harder to satisfy a unique constraint over a conjunction of inequalities than to satisfy a conjunction of constraints over single inequalities: in the first case,  percent of the paths must satisfy \textit{all} inequalities, not in the second one.

Still, our queries share common subclasses with cost problems: atomic formulae~ exactly correspond to our single-constraint queries. Moreover, cost problems for such formulae are inter-reducible with quantile queries~\cite[Proposition 2]{HaaseK14}. Cost problems with atomic formulae are \PSPACE-hard, so this also holds for \textit{single-constraint} percentile queries. The best known algorithm in this case is in \EXPTIME. In the following, we establish an algorithm that still only requires exponential time while allowing for \textit{multi-constraint multi-dimensional multi-target} percentile queries.

\smallskip\noindent\textbf{Overview.} 
Our main contributions for the shortest path are summarized in Theorem~\ref{thm:sp_overview}. In the following, we detail each of them and discuss some subclasses of queries with interesting complexities.

\begin{theorem}
\label{thm:sp_overview}
The percentile problem for the shortest path with non-negative weights can be solved in time polynomial in the model size
and exponential in the query size (exponential in the number of constraints and pseudo-polynomial in the largest threshold). 
The problem is \PSPACE-hard even for single-constraint queries. Exponential-memory strategies are sufficient and in general necessary.
\end{theorem}

\smallskip\noindent\textbf{Algorithm.} The sketch of our algorithm is as follows. Consider a -dimensional MDP  and a -query percentile problem, with potentially different targets for each query. 
Let  be the maximum of the thresholds . Because weights are non-negative, extending a finite history never decreases the sum of its weights.
Thus, any history ending with a sum exceeding  in all dimensions is surely losing under any strategy.

Based on this, we build an MDP  by unfolding  and integrating the sum for each dimension in states of . We ensure its finiteness thanks to the above observation and we reduce its overall size to a \textit{single}-exponential by defining a suitable equivalence relation between states of : we only care about the current sum in each dimension, and we can forget about the actual path that led to it. Precisely, 
the states of~ are in . 
Now, for each constraint, we compute a set of target states in  that exactly captures all runs satisfying the inequality of the constraint. Thus, we are left with a multiple reachability problem on~: we look for a strategy~ that ensures that each of these sets  is reached with probability . This query can be answered in time polynomial in  but exponential in the number of sets , i.e., in  (Theorem~\ref{thm:absorbing-reachsafe}). 

We prove the correctness of our algorithm in the next lemma.

\begin{lemma}
\label{lem:sp_alg}
The percentile problem for the shortest path can be solved in time polynomial in the size of the MDP and the thresholds values, and exponential in the number of dimensions of the weight function and the number of constraints of the problem.
\end{lemma}


\begin{proof}
Let  be the considered MDP,  with  its -dimensional non-negative weight function,  the initial state. We consider a -constraint query: we are looking for a strategy  such that

for the given thresholds ,  and target sets . The algorithm is as follows.

Let  be the maximum of the thresholds , . Observe that given any prefix of a run, extending it can never decrease the sum of weights (as all weights are non-negative) and that any run for which the truncated sum exceeds~ in all dimensions is not interesting for the controller.

Based on those observations, we unfold the MDP~, creating a tree-like structure in the nodes of which we integrate the current sum of weights. That is, nodes are labeled by elements of . We stop a branch as soon as the sum reaches  in all dimensions (we do not care about what happens after the sum hits this value as it is now a bad outcome for all the percentile constraints). Now, this unfolding is not exactly a tree because we allow actions of weight zero in the original MDPs. Hence we may have to introduce cycles in the unfolding: whenever a branch visits a node with a label identical to one of its ancestors, we stop this branch and introduce a cycle to the corresponding ancestor. Those two cutting criteria guarantee an unfolding which is finite and of maximum height . That is because every cycle (in the original MDP) that does not result in a cycle in the unfolding has to increase at least one dimension, by at least one, and has at most length .

Now consider the overall size of this unfolding. Recall that we want to build an unfolding which is at most exponential. If no special care is taken, the size of the unfolding could be as high as , where  denotes the branching degree of , defined as

In particular, the overall size could be exponential in , that is, doubly-exponential in its encoding. To avoid that, we reduce the size of the unfolding by merging equivalent nodes.

What are equivalent nodes? First, we declare two nodes to be equivalent if they relate to the same state and describe identical sums on all dimensions. Second, observe that for any node of the unfolding, the sum on any dimension can theoretically grow up to , with  the largest weight appearing on any action of . That is, it can grow larger than  as we stop only when \textit{all} dimensions are larger than this bound. Nonetheless, w.r.t.~satisfaction of the percentile query, we do not need to recall exactly what is the value reached after exceeding  as in any case, such a sum in a given dimension is not acceptable for any related constraint. Hence, we can also merge nodes by replacing any label larger than  by label .

By merging nodes equivalent according to this definition, we ensure that the overall size of the unfolding is at most . Indeed, the possible values for sums on any dimension in the unfolding run from  to . Observe that this overall size  is, as desired, polynomial in the number of states~ and in the largest threshold , and exponential in the number of dimensions .

Interestingly, this merging process can be executed on the fly while building the unfolding hence does not hinder the total execution time of the algorithm (i.e., one does not have to fully build the doubly-exponential unfolding to construct the single-exponential merged one).

Now notice that this unfolding is itself an MDP, denoted~. For each constraint , we can compute the set  of nodes that are labeled by a state in the corresponding target set  and have a label less than or equal to  on the corresponding sum dimension . Hence, such a set  actually captures all branches satisfying the inequality of constraint~ (a branch is captured if it possesses a node of ). Observe that we only consider dimensions related to constraint  when computing the set~ (e.g., it is not a problem to exceed  in other dimensions). This computation takes time  in the worst case.

Now we are left with a multiple reachability problem on : we have to decide the existence of a strategy~ satisfying the query

If such a strategy  exists in , it is easy to see that the equivalent strategy~ in the original MDP  satisfies the shortest path percentile query~. Indeed, the probability of reaching set  in  following strategy  is exactly the probability of satisfying constraint  in  following the equivalent strategy . On the contrary, if no strategy satisfies the multiple reachability query~, it implies that the original percentile query~ cannot be satisfied either.

Solving this multiple reachability query~ can be done in polynomial time in the size of the unfolding MDP  but exponential in the number of sets , i.e., in the number of constraints (Theorem~\ref{thm:absorbing-reachsafe}). Hence, the overall time required by the algorithm is polynomial in  and in the maximum threshold , and exponential in the number of dimensions~ and in the number of constraints .
\end{proof}


It is worthwhile to mention that the exponential dependency on the number of constraints can be lifted when they all consider the same target set.

\begin{remark}
\textit{Percentile problems with unique target are solvable in time polynomial in the number of constraints but still exponential in the number of dimensions.}
\end{remark}

\begin{proof}
Consider the unfolding algorithm described in the proof of Lemma~\ref{lem:sp_alg}. Assume that all constraints of the percentile query relate to the same target set . In that case, all branches can be stopped as soon as they reach a state of . Thus, when computing the sets  for the multiple reachability problem on the unfolding , all nodes that belong to these sets are actually leaves of the unfolding. Hence they are absorbing states of . From Theorem~\ref{thm:absorbing-reachsafe}, it follows that the multiple reachability problem can be solved in polynomial time, which eliminates the exponential dependency on the number of constraints for solving the shortest path percentile problem with a single target set.
\end{proof}


For single-dimensional queries with a unique target set (but still potentially multi-constraint), our algorithm remains pseudo-polynomial as it requires polynomial time in the thresholds values (i.e., exponential in their encoding).
\begin{corollary}
\label{cor:sp_alg}
The single-dimensional percentile problem with a unique target set can be solved in pseudo-polynomial time.
\end{corollary}


\noindent\textbf{Lower bound.}
By equivalence with cost problems for atomic cost formulae, it follows
from~\cite[Theorem 7]{HaaseK14} that no truly-polynomial-time algorithm
exists for the single-constraint percentile problem unless \PTIME~=~\PSPACE.

\begin{lemma}
The single-constraint percentile problem for the shortest path is \PSPACE-hard.
\end{lemma}

\smallskip\noindent\textbf{Memory.} 
We now formally prove the need for (and sufficiency of) exponential memory in shortest path percentile queries.

\begin{lemma}
\label{lem:spmemory}
Exponential-memory strategies are both sufficient and, in general, necessary to satisfy percentile queries for the shortest path.
\end{lemma}

\begin{proof}
First, the algorithm given in Lemma~\ref{lem:sp_alg} solves the percentile problem by answering a multiple reachability problem over an unfolded MDP of exponential size. As stated in Theorem~\ref{thm:absorbing-reachsafe}, memory of size polynomial in the MDP (here, the unfolded one) and exponential in the number of constraints (which is untouched by our algorithm) is sufficient to satisfy such queries. Hence, it follows that exponential-memory strategies suffice for shortest path percentile queries.

Second, let us show that multiple reachability problems over an MDP  can be reduced to shortest path percentile problems over the very same MDP, enriched with a trivial weight function. Consider an unweighted MDP  and a multiple reachability query for sets  and thresholds , with . Let  be a single-dimensional weighted version of the MDP~, where all actions are assigned weight zero. Then we trivially have that a strategy~ satisfies the multiple reachability query on  if and only if it satisfies the percentile query  on . Indeed, runs that are bad for this percentile query are exactly the ones that are assigned truncated sum  because they do not reach the considered target sets. This concludes the reduction.

Finally, we know by Lemma~\ref{lem:multiReach_expMemoryLB} that exponential memory is needed in general for multiple reachability queries. This lower bound thus straightforwardly carries over to shortest path percentile queries.
\end{proof} 
\section{Discounted Sum}
\label{sec:ds}

The \textit{discounted sum} accumulates weights using a discount factor to model that short-term rewards or costs are more important than long-term ones. It is well-studied in automata~\cite{DBLP:journals/corr/BokerH14} and MDPs~\cite{Puterman-wiley94,CMH-stacs06,DBLP:conf/lpar/ChatterjeeFW13}. We consider queries of the form , for discount factors  and the usual thresholds. That is, we study multi-dimensional MDPs and possibly distinct discount factors for each constraint.
	
Unfortunately, our setting encompasses a much simpler question which is still not known to be decidable. We discuss this question and its reduction to our problem in Sect.~\ref{subsec:precise}. We also argue that solving this problem would require an important breakthrough. Then, in Sect.~\ref{subsec:approx}, we establish a conservative algorithm that, in some sense, can approximate the answer to the percentile problem.
	
\subsection{Precise Discounted Sum is Hard}
\label{subsec:precise}

Consider the \textit{precise discounted sum problem}: given a rational , and a rational discount factor , does there exist an infinite binary sequence  such that ? In~\cite{bokerTDS}, this problem is related to several long-standing open questions, such as decidability of the \textit{universality problem for discounted-sum automata}~\cite{DBLP:journals/corr/BokerH14}. A slight generalization to paths in graphs is also mentioned by Chatterjee et al.~as a key open problem in~\cite{DBLP:conf/lpar/ChatterjeeFW13}.

\begin{lemma}
\label{lem:ds_precise}
The precise discounted sum problem can be reduced to an almost-sure percentile problem over a two-dimensional MDP with only one state.
\end{lemma}

\begin{proof}
Assume we have a precise discounted sum problem with discount factor  and target value . Let  be an MDP with only one state  and two actions,  and  (that both cycle on  with probability one, obviously). Consider the two-dimensional weight function  such that  and . The role of action  (resp. ) is to represent the choice of  (resp. ) in the binary sequence.

We define the percentile problem asking for the existence of a strategy  such that

By definition of the weight function, the second term of the conjunction is equivalent to . Hence, if a satisfying strategy  exists, it does satisfy . We claim that the answer to the precise discounted sum problem is \textsf{Yes} if and only if the answer to the percentile problem is \textsf{Yes}.

First, assume a satisfying strategy  exists. In general, our percentile problems do not require strategies to be pure. However, even if  is randomized, we can extract a run  induced by this strategy and such that  (such a run exists otherwise the strategy would not satisfy the percentile query). This run can be seen as a sequence of actions , which we translate in a corresponding sequence  satisfying the precise discounted sum problem.

Conversely, assume there exists a sequence  satisfying the precise discounted sum problem. Then this sequence defines a (possibly infinite-memory) pure strategy  that ensures a discounted sum equal to , and thus the percentile query is satisfied.
\end{proof}

This suggests that answering percentile problems for the discounted sum would require an important breakthrough.

\subsection{Approximation Algorithm}
\label{subsec:approx}

\smallskip\noindent\textbf{Approaching an answer.} As shown in Sect.~\ref{subsec:precise}, an exact algorithm is currently out of reach. Fortunately, we are still able to establish an algorithm that can ``approximate'' a solution. Since we consider decision problems, the notion of approximation should not be understood \textit{sensu stricto}. We will formalize the output of the algorithm in the following but we first give an intuitive sketch.

\smallskip\noindent\textbf{The -gap problem.} Our algorithm takes as input a percentile query and an arbitrarily small \textit{precision factor}  and has three possible outputs: \textsf{Yes}, \textsf{No} and \textsf{Unknown}. If it answers \textsf{Yes}, then a satisfying strategy exists and can be synthesized. If it answers \textsf{No}, then no such strategy exists. Finally, the algorithm may output \textsf{Unknown} for a specified ``zone'' close to the threshold values involved in the problem and of width which depends on .
It is possible to incrementally reduce the uncertainty zone, but it cannot be eliminated as the case~ would answer the precise discounted sum problem, which is not known to be decidable.

We actually solve an \emph{-gap problem}, a particular case of \emph{promise problems}~\cite{DBLP:conf/birthday/Goldreich06a},
where the set of inputs is partitioned in three subsets: yes-inputs, no-inputs and the rest of them. The promise problem then asks to answer \textsf{Yes} for all yes-inputs and \textsf{No} for all no-inputs, while the answer may be arbitrary for the remaining inputs. 
In our setting, the set of inputs for which no guarantee is given can be taken arbitrarily small, parametrized by value : this is an -gap problem. This notion is later formalized in Theorem~\ref{thm:ds_gap}.

\smallskip\noindent\textbf{Related work: single-constraint case.} There are papers considering models related to \textit{single-constraint} percentile queries. Consider a single-dimensional MDP and a single-constraint query, with thresholds  and . The \textit{threshold problem} fixes  and maximizes ~\cite{White1993634,WL99}. The \textit{value-at-risk problem} fixes~ and maximizes ~\cite{DBLP:conf/fsttcs/BrazdilCFNS13}. This is similar to \textit{quantiles} in the shortest path setting~\cite{DBLP:conf/fossacs/UmmelsB13}.

Paper~\cite{DBLP:conf/fsttcs/BrazdilCFNS13} is the first to provide an exponential-time algorithm to approximate the optimal value  under a fixed  in the general setting. The authors also rely on approximation. While we do not consider optimization, we do extend the setting to \textit{multi-constraint}, \textit{multi-dimensional}, \textit{multi-discount} problems, and we are able to remain in the same complexity class, namely \EXPTIME.

\smallskip\noindent\textbf{Overview.} Our main contributions for the discounted sum are summarized in Theorem~\ref{thm:ds_overview}. In the following, we provide a thorough discussion for each of them, and prove several intermediate results of interest.
 
\begin{theorem}
\label{thm:ds_overview}
The -gap percentile problem for the discounted sum can be solved in time pseudo-polynomial in the model size and the precision factor, and exponential in the query size: polynomial in the number of states, the weights, the discount factors and the precision factor, and exponential in the number of constraints. It is \PSPACE-hard for two-dimensional MDPs and already \NPTIME-hard for single-constraint queries. Exponential-memory strategies are both sufficient and in general necessary to satisfy -gap percentile queries.
\end{theorem}

\smallskip\noindent\textbf{Cornerstones of the algorithm.} Our approach is similar to the shortest path: we want to build an unfolding capturing the needed information w.r.t.~the discounted sums, and then reduce the percentile problem to a multiple reachability problem over this unfolding. However, several challenges have to be overcome.

First, we need a \textit{finite} unfolding. This was easy in the shortest path due to non-decreasing sums and corresponding upper bounds. Here, it is not the case as we put no restriction on weights. 
Nonetheless, thanks to the discount factor, weights contribute less and less to the sum along a run. In particular, cutting all runs after a pseudo-polynomial length changes the overall sum by at most~.

Second, we reduce the overall size of the unfolding.
For the shortest path we took advantage of integer labels to define equivalence. Here, the space of values taken by the discounted sums is too large for a straightforward equivalence.
To reduce it, we introduce a \textit{rounding} scheme of the numbers involved. This idea is inspired by~\cite{DBLP:conf/fsttcs/BrazdilCFNS13}. We bound the error due to cumulated roundings by .

So, we control the amount of information lost to guarantee exact answers except inside an arbitrarily small -zone.
Given a -constraint query  for thresholds , ,
dimensions  and discounts , we define the
\textit{-shifted query} , for , as the exact same
problem for thresholds , , dimensions~ and discounts
. Our algorithm satisfies the following theorem, which formalizes
the -gap percentile problem mentioned in
Theorem~\ref{thm:ds_overview}. .
\begin{theorem}
\label{thm:ds_gap}
There is an algorithm that, given an MDP, a percentile query  for the discounted sum and a precision factor , solves the following -gap problem in exponential time. It answers
\begin{itemize}
\item \textsf{Yes} if there is a strategy satisfying the -shifted percentile query ;

\item \textsf{No} if there is no strategy satisfying the -shifted percentile query ;

\item and arbitrarily otherwise.
\end{itemize}
\end{theorem}


We first state a more precise result and proceed with the technical discussion of the algorithm in the following paragraphs.

\begin{theorem}
\label{thm:disc_algo}
There is an algorithm satisfying the following properties.
\begin{enumerate}
\item It takes as input an MDP, a percentile query  for the discounted sum and a precision factor .
\item If it outputs \textsf{Yes}, then there exists a strategy satisfying the percentile query .
\item If it outputs \textsf{No}, then there exists no such strategy.
\item If it outputs \textsf{Unknown}, then there exists a strategy satisfying at least the -shifted percentile query  and there exists no strategy satisfying the -shifted percentile query .
\item It runs in time polynomial in the size of the MDP, the weights, the discount factors and the precision factor, and exponential in the number of constraints.
\end{enumerate}
\end{theorem}

It suffices to prove Theorem~\ref{thm:disc_algo} for Theorem~\ref{thm:ds_gap} to follow as an immediate corollary for the -gap formulation of the problem.

\smallskip\noindent\textbf{Technical discussion.} Let  be a -dimensional MDP. We consider the -constraint percentile query , where for , we have that , ,  and . Let  be an arbitrarily small precision factor. We assume w.l.o.g.~that , i.e., we always use rational precision factors.
	
We now describe the algorithm and establish intermediate results related to the construction operated by the algorithm. We conclude by proving that all properties stated in Theorem~\ref{thm:disc_algo} are satisfied.

Our first step is building an unfolding of , in the classical way. We denote it by . Each node of  is labeled by the corresponding state of  and the discounted sum \textit{related to each query}, computed over the descending path from the root to the node. Observe that we have  numerical dimensions in  and not  as in the shortest path. This will prove useful because we may have different discount factors for each constraint, hence the same dimension may induce different discounted sums depending on the considered constraint. This building scheme induces an infinite tree  with nodes labeled by elements of .

In order to obtain a finite tree, we compute a bound  on the height such that we do not lose too much information by cutting all branches at level  (assuming the root node is at level ). Let  denote the cut of  at level .

\begin{lemma}
\label{lem:ds_height}
There exists a pseudo-polynomial height  such that for any infinite branch of , its discounted sum on any dimension and w.r.t.~any of the discount factors is at most  far from the discounted sum of its prefix branch in .
\end{lemma}

\begin{proof}
Consider any branch of , for some . We denote the corresponding prefix of a run by . Its discounted sum w.r.t.~discount factor  and dimension  is . This branch could be extended in  to any infinite branch that represents a prolonging run  of which  is a prefix. We have that  and we want to pick  such that

for any prolonging run . That is, we want

Let  be the largest discount factor (i.e., the one for which the discounting effect if the slowest) and let  be the largest absolute weight appearing in the MDP . We obtain that

It thus suffices to take  large enough to have that . We assume that  otherwise the discounted sum is always zero and the percentile problem is trivial. We also recall that . Hence the inequality becomes . Applying the binary logarithm, we get the following inequality:

Since , we have that  and we finally obtain that

Observe that this expression is always positive as ,  and . In the following, let us assume we take the ceiling of this expression as the value~. What is the size of  w.r.t.~the input of the algorithm? Since we are taking the binary logarithm of all involved values, it may seem that  only needs to be polynomial in the encoding of the values. However, when , we have that . Therefore,  can be polynomial in the value of , that is, exponential in its encoding.
\end{proof}

We now have a finite tree , of pseudo-polynomial height, and such that all discounted sums labeled in its leaves are at most  far from the one of any prolonging run. In other words, once such a leaf has been reached, the controller may use any arbitrary strategy and its discounted sum will not vary by more than . This implies that we only care about devising a strategy for the  first steps, as we will use later.

Consider the overall size of the tree . As discussed for the shortest path, this size can be as high as , where  denotes the branching degree of , defined as . Thus, the overall size could be pseudo-exponential. Again, we want to reduce this tree  to a compressed tree of truly-exponential size by merging equivalent nodes.

However, in this case it does not suffice to look for nodes with the exact same labels. Indeed, the range of possible labels is in general pseudo-exponential. Observe that the set of labels of any tree  is a finite subset of  (this characterization can be narrowed but it suffices for our needs). We introduce a value  and maps the set of possible labels to  by rounding the values appearing in  to multiples of  (we assume w.l.o.g.~that  is such a multiple). To that end, we define the function  that rounds any rational  to the closest multiple of , i.e., the closest value in the new set of labels. The idea of rounding numbers to reduce the complexity is inspired by~\cite{DBLP:conf/fsttcs/BrazdilCFNS13}, but the technique differs.

Assume we apply this label mapping on , for some fixed . Then, we define  as the MDP obtained by merging nodes having identical labels after the mapping. This is the unfolded MDP we are looking for \textit{if  is chosen adequately}, and it can be built on the fly by rounding each node (and potentially merging) at the moment it is created. Intuitively,  should not be too large to be able to keep the resulting rounding error low, but it should be large enough to induce a range of labels which is at most of exponential size. The following lemma states the existence of such a value .

\begin{lemma}
\label{lem:ds_rounding}
There exists a value  such that
\begin{enumerate}
\item  is at most exponential;
\item for all branch  in , for all , , we have that

where  denotes the rounded discounted sum of the corresponding branch  in  (i.e., the label of the corresponding leaf in ).
\end{enumerate}
\end{lemma} 

\begin{proof}
We choose  and prove the two assumptions. Observe that we assume  otherwise  contains only the root node with all discounted sums equal to zero and no rounding is needed.

First, consider \textit{assumption 1}. The size of the set is .
Hence it suffices to prove that  is at most exponential. Since both  and  are at most exponential (in the encoding of values), this boils down to proving that  is at most exponential, which is the case.

Second, let us prove \textit{assumption 2}. Recall that our rounding scheme maps each value to the closest multiple of~ whenever the label of a node is computed. It is important to understand that this rounding is executed on the fly, and not after building the tree  fully (otherwise we would require pseudo-exponential time). Consequently, when a discounted sum for a node of level  is computed, we have to take into account that the label of its father of level  has already been rounded: the rounding errors add up along a branch.

We claim that the total error over a branch of height  is bounded by the expression . That is, for all height- branch  of , for all , ,

We prove it by induction. Let  in the following.

The base case is . We ask whether

This is clearly true by definition of , which maps any rational to the closest multiple of .

Now assume our claim is true up to level . We prove it is still satisfied for level . Let us rewrite  as follows:

Using the equality  for  and , along with the fact that  is already rounded by construction, we rewrite this as:

By the subadditivity of , we bound this expression by

Finally, using the induction hypothesis for the first term and the definition of  for the second one, we can bound this sum by

which proves our initial claim.

Now, by our choice of , this implies that the total rounding error over any branch is at most , which proves the correctness of \textit{assumption 2}.
\end{proof}

Let us sum up the situation: given an MDP, a percentile query and a precision factor , we are able to construct an unfolded MDP  of at most exponential size such that all leaves have labels in , where each of the  numerical dimensions approximate the discounted sum of corresponding infinite branches within an error bounded by  ( due to truncating the branches and  due to the rounding of values).

The last step of our algorithm is as follows. Consider the  following target sets of nodes in .
\begin{itemize}
\item ,  is the set of leaves for which the label on numerical dimension  is greater than or equal to . Essentially, we have that , where  denotes a corresponding descending branch.
\item ,  is the set of leaves for which the label on numerical dimension  is greater than or equal to . Essentially, we have that , where  denotes a corresponding descending branch.
\end{itemize}
Observe that  for all query . Our algorithm proceeds as follows.
\begin{itemize}
\item[\textit{A)}] We execute the multiple reachability problem checking the existence of a strategy  such that

with  the root node of the unfolded MDP. If the answer is \textsf{Yes}, then we answer \textsf{Yes} to the percentile problem. Otherwise, we proceed to the next step.
\item[\textit{B)}]  We execute the multiple reachability problem checking the existence of a strategy  such that 

with  the root node of the unfolded MDP. If the answer is \textsf{Yes}, then we answer \textsf{Unknown} to the percentile problem. Otherwise, we answer \textsf{No}.
\end{itemize}

The intuition is threefold. First, if a leaf of  is reached, then whatever the strategy that is played afterwards, any prolonging run will have a discounted sum at least equal to  w.r.t.~the corresponding discount factor  and dimension . Hence, all prolonging runs are acceptable for constraint . Second, if a leaf of  is reached, then some prolonging runs may satisfy the constraint while other do not: we need to compute the unfolding for a smaller precision factor  in order to obtain useful information from nodes that are currently in . Third, if a leaf does not belong to , then any prolonging run is guaranteed to falsify constraint  as adding error  does not suffice to make the discounted sum at least equal to . We are finally able to prove Theorem~\ref{thm:disc_algo}.

\begin{proof}[Proof of Theorem~\ref{thm:disc_algo}] We consider each of \textit{properties 2-5} separately.

\textit{Property 2}. Our algorithm answers \textsf{Yes} if and only if there exists a strategy  satisfying the multiple reachability query . We define the strategy  on the original MDP  that plays as follows: it chooses the  first actions according to  and then plays an arbitrary memoryless strategy. By Lemma~\ref{lem:ds_height}, Lemma~\ref{lem:ds_rounding}, and by definition of , this strategy guarantees that for all , a discounted sum (w.r.t.~ and ) at least equal to  is achieved with probability at least equal to . Hence this finite-memory strategy  satisfies the discounted sum percentile query on the original MDP .
	
\textit{Property 3}. Our algorithm answers \textsf{No} if and only if there exists no strategy  satisfying the multiple reachability query . By contradiction, assume the multiple reachability query cannot be satisfied, yet there exists a strategy  in the original MDP  that satisfies the percentile query for the discounted sum. That is, for all  and associated , this strategy achieves discounted sum at least~ with probability at least . By Lemma~\ref{lem:ds_height} and Lemma~\ref{lem:ds_rounding}, we know that such a strategy reaches with probability at least~ leaves in  that are labeled with a value at least equal to  in numerical dimension . That is,  reaches each set  with probability at least , which contradicts the hypothesis and proves the property.

\textit{Property 4}. Applying the same argument as for \textit{property 1}, if there exists a strategy  for the multiple reachability query , then this strategy can be translated into a strategy  over  that ensures the percentile query where all value thresholds  are replaced by their shifted version . Indeed, observe that the threshold gap between sets  and  is exactly . Conversely, we apply the argument of \textit{property~2} to deduce that if there exists no strategy for the multiple reachability query  (which is the case otherwise the answer of the algorithm would have been \textsf{Yes}), then there is no strategy for the percentile query shifted by . 

\textit{Property 5}. It remains to study the complexity of our algorithm. Recall that the unfolded MDP  can be constructed in time

while  is polynomial in ,  and  and  is polynomial in both  and . Moreover, multiple reachability queries executed by the algorithm only require polynomial time in  as all target states are absorbing (they are leaves in the unfolding). Overall, this shows that our algorithm requires time that is polynomial in , ,  and , and exponential in . This proves the property and finally concludes our proof of correctness for the algorithm.
\end{proof}



\smallskip\noindent\textbf{Lower bounds.} The -gap percentile problem is \PSPACE-hard by reduction from subset-sum games~\cite{DBLP:journals/tcs/Travers06}. Those are two-player games defined by a finite list of pairs of natural numbers , , , , and a target . Players take turns choosing between  and . After  rounds, if the sum of the chosen numbers equals , then player~1 wins, otherwise player~2 wins. Deciding if player~1 has a winning strategy in a subset-sum game is \PSPACE-complete~\cite{DBLP:journals/tcs/Travers06}. 



\begin{lemma}
\label{lem:ds_pspace_hard}
The -gap problem defined in Theorem~\ref{thm:ds_gap} is \PSPACE-hard, already for two-dimensional MDPs and fixed values of discount and precision factors.
\end{lemma}

Two tricks are important. First, counterbalancing the discount effect via adequate weights. Second, simulating an equality constraint. This cannot be achieved directly because it requires to handle . Still, by choosing weights carefully we restrict possible discounted sums to integer values only. Then we choose the thresholds and  such that no run can take a value within the uncertainty zone. This circumvents the limitation due to uncertainty.

\begin{proof}
Consider a subset-sum game defined by pairs , , , and target . Assume that we have an algorithm, called \textsf{Algo}, that solves the -gap problem of Theorem~\ref{thm:ds_gap}. We claim that this algorithm can also decide if player~1 has a winning strategy in the subset-sum game, through a polynomial-time reduction of the subset-sum game to a discounted sum percentile problem.

\begin{figure}[tb]
        \centering
               \scalebox{1}{\begin{tikzpicture}[->,>=stealth',shorten >=1pt,auto,node
    distance=2.5cm,bend angle=45, scale=0.52, inner sep=0pt,font=\scriptsize]
    \tikzstyle{p1}=[draw,circle,text centered,minimum size=5mm,text width=4mm]
    \tikzstyle{p2}=[fill,circle,text centered,minimum size=1.5mm]
    \tikzstyle{empty}=[]
    \node[p1]  (1) at (0, 0)  {};
    \node[p2]  (2)  at (4, 2) {};
    \node[p2]  (3)  at (4, -2) {};
    \node[p1]  (4)  at (8, 2) {};
    \node[p1]  (5)  at (8, -2) {};
    \node[p1]  (6)  at (12, 0) {};
    \node[empty]  (7)  at (16, 2) {};
    \node[empty]  (8)  at (16, -2) {};
    \node[empty]  (10)  at (18, 2) {};
    \node[empty]  (11)  at (18, -2) {};
    \node[p1]  (9) at (22, 0)  {};
    \path
    (-1.4,0) edge (1)
     (1) edge node[above,sloped,yshift=1mm] {} (2)
     (1) edge node[below,sloped,yshift=-1mm] {} (3)
    (2) edge[shorten <=1pt] (4)
    (2) edge[shorten <=1pt] (5)
    (3) edge[shorten <=1pt] (4)
    (3) edge[shorten <=1pt] (5)
    (4) edge node[above,sloped,yshift=1mm] {} (6)
    (5) edge node[below,sloped,yshift=-1mm] {} (6)
     (6) edge[dashed] node[above,sloped,yshift=1mm] {} (7)
     (6) edge[dashed] node[below,sloped,yshift=-1mm] {} (8)
    (10) edge[dashed] (9)
    (11) edge[dashed] (9)
    (10) edge[dashed] node[above,sloped,yshift=1mm] {} (9)
    (11) edge[dashed] node[below,sloped,yshift=-1mm] {} (9)
(9) edge [loop right, out=50, in=310,looseness=3, distance=2cm] node [above,xshift=-2.5mm,yshift=4.5mm] {} (9)
;
    \draw[loosely dotted,thick,-] (16.4,0) -- (17.6,0);
      \end{tikzpicture}}
        \caption{Encoding of subset-sum game into 2-dimensional percentile problem for the discounted sum.}\label{fig:ds_subset}
\end{figure}

We construct a 2-dimensional MDP . Our construction is illustrated in Fig.~\ref{fig:ds_subset}. Filled circles represent equiprobable stochastic transitions. Controllable states simulate choices of player~1 in the game: the controller can choose between  and  when  is odd. Conversely, stochastic transitions simulate choices of player~2: when  is even,  and  are chosen with the same probability . Each action corresponding to choosing  (resp. ) has a 2-dimensional weight  (resp. ). The discount factor can be fixed arbitrarily, say  for the sake of concreteness. Note that those weights only require an encoding which is polynomial in the size of the input. We add a self-loop with weight  on the terminal state.

Observe that any run in this MDP has a discounted sum which is exactly equal to the sum of the chosen elements , , thanks to the countereffect of  in the weights definition. Hence we also have that all runs have integer discounted sums. 

Our goal is to find a 2-dimensional percentile query that can express the winning condition of the subset-sum game, taking into account that algorithm \textsf{Algo} can only solve the -gap problem. 

Intuitively, we would like to express that the discounted sum must be exactly equal to , in all possible runs. First observe that given the structure of the MDP, the terminal state and its zero loop is guaranteed to be reached in  steps. Therefore, any strategy ensuring the required property almost-surely (i.e., with probability one) also ensures it surely (i.e., over all possible runs). Ideally, we would like to execute the -constraint percentile problem asking for the existence of a strategy that satisfies query

Let us call it \textit{Problem A}. Any strategy satisfying  would be a winning strategy for player-1, and conversely. Still, this would only be useful if we could take , which we cannot.

Instead, consider \textit{Problem B}, asking for the existence of a strategy satisfying

Furthermore, let us choose the precision factor . Recall we assume that \textsf{Algo} solves the -gap problem. Consider the execution of \textsf{Algo} over query . By definition of the -gap problem (Theorem~\ref{thm:ds_gap}), we have that:
\begin{itemize}
\item[(1)] if there exists a strategy  satisfying

then the answer of \textsf{Algo} is \textsf{Yes};
\item[(2)] if there exists no strategy  satisfying

then the answer of \textsf{Algo} is \textsf{No};
\item[(3)] otherwise the answer can be either \textsf{Yes} or \textsf{No}.
\end{itemize}
Now let us review the possible answers of \textsf{Algo}.

Assume the answer is \textsf{Yes}. By (2), we have that there exists a strategy  that satisfies  otherwise the answer would have been \textsf{No}. Since all runs have integer discounted sums, this necessarily implies that  also satisfies . Indeed, we have that  and . Hence player-1 has a winning strategy in the subset-sum game.

Assume the answer is \textsf{No}. By (1), we have that there exists no strategy  that satisfies  otherwise the answer would have been \textsf{Yes}. Obviously, there exists no more strategy satisfying  since it is harder to satisfy (its thresholds are higher). Hence player-1 has no winning strategy in the subset-sum game.

Finally, we see that the answer of \textsf{Algo} is \textsf{Yes} if and only if the answer to \textit{Problem A} is also \textsf{Yes}. Since algorithm \textsf{Algo} can decide \textit{Problem A}, we also have that it can decide if player-1 has a winning strategy in the subset-sum game, which concludes our proof.
\end{proof}

For single-constraint -gap problems, we prove \NPTIME-hardness, even for Markov chains. Our proof is by reduction from the -th largest subset problem~\cite{garey_FNY1979}, inspired by~\cite[Theorem 11]{DBLP:conf/stacs/BruyereFRR14}. A recent paper by Haase and Kiefer~\cite{HaasePP} shows that this -th largest subset problem is actually \textsf{PP}-complete. This suggests that the single-constraint problem does not belong to  at all, otherwise the polynomial hierarchy would collapse to  by Toda's theorem~\cite{toda1991pp}.


\begin{lemma}
\label{lem:ds_np_hard}
The -gap problem defined in Theorem~\ref{thm:ds_gap} is \NPTIME-hard for single-constraint queries. This holds even for Markov chains, i.e., MDPs with only one available action in every state.
\end{lemma}

\begin{proof}
The -th largest subset problem is as follows. Given a finite set  (hence ), a size function  assigning non-negative integer values to elements of , and two naturals , decide if there exist  distinct subsets , , such that  for all  subsets. The \NPTIME-hardness of this problem was proved in~\cite{johnson_JACM1978}.

We assume w.l.o.g.~that  otherwise the answer to the problem is trivially \textsf{No} since we cannot find a sufficient number of \textit{distinct} subsets.

\begin{figure}[htb]
  \centering   
 \scalebox{1}{\begin{tikzpicture}[->,>=stealth',shorten >=1pt,auto,node
    distance=2.5cm,bend angle=45, scale=0.52, inner sep=0pt,font=\scriptsize]
    \tikzstyle{p1}=[draw,circle,text centered,minimum size=5mm,text width=6mm]
    \tikzstyle{p2}=[fill,circle,text centered,minimum size=1.5mm]
    \tikzstyle{empty}=[]
    \node[p1]  (1) at (0, 0)  {};
    \node[p2]  (1b)  at (2, 0) {};
    \node[p1]  (2)  at (4, 2) {};
    \node[p1]  (3)  at (4, -2) {};
    \node[p2]  (2b)  at (7, 2) {};
    \node[p2]  (3b)  at (7, -2) {};
    \node[p1]  (4)  at (10, 2) {};
    \node[p1]  (5)  at (10, -2) {};
    \node[p2]  (4b)  at (13, 2) {};
    \node[p2]  (5b)  at (13, -2) {};
    \node[empty]  (6)  at (16, 2) {};
    \node[empty]  (7)  at (16, -2) {};
    \node[p1]  (8)  at (19, 2) {};
    \node[p1]  (9)  at (19, -2) {};
    \node[p1]  (10)  at (23, 0) {};
    \path
    (-1.4,0) edge (1)
    (1) edge node[above,yshift=1mm] {} (1b)
    (1b) edge[shorten <=1pt] (2)
	(1b) edge[shorten <=1pt] (3)
    (9) edge node[below,sloped,yshift=-1mm] {} (10)
    (8) edge node[above,sloped,yshift=2mm] {} (10)
    (4) edge node[above,yshift=1mm,xshift=0.8mm] {} (4b)
    (5) edge node[below,yshift=-1mm] {} (5b)
    (2) edge node[above,yshift=1mm,xshift=0.8mm] {} (2b)
    (3) edge node[below,yshift=-1mm] {} (3b)
    (2b) edge[shorten <=1pt] (4)
    (2b) edge[shorten <=1pt] (5)
    (3b) edge[shorten <=1pt] (4)
    (3b) edge[shorten <=1pt] (5)
    (4b) edge[shorten <=1pt] (6)
    (4b) edge[shorten <=1pt] (7)
    (5b) edge[shorten <=1pt] (6)
    (5b) edge[shorten <=1pt] (7)
    (10) edge [loop right, out=50, in=310,looseness=3, distance=2cm] node [above,xshift=-2.5mm,yshift=4.5mm] {} (10)
    ;
    \draw[loosely dotted,thick,-] (16.4,2) -- (17.6,2);
    \draw[loosely dotted,thick,-] (16.4,-2) -- (17.6,-2);
      \end{tikzpicture}}
      \caption{Reduction from -th largest subset problem to -gap problem for a single-constraint discounted sum percentile problem over a Markov chain.}
\label{fig:ds_np_hard}
  \end{figure}
  
Given an instance of the -th largest subset problem, we build a Markov chain as depicted in Fig.~\ref{fig:ds_np_hard}. Observe that this is indeed a Markov \textit{chain} as there is a unique action available in all states. As usual, the filled circles represent equiprobable transitions. In the first step, element  is either selected (upper transition) or not selected (lower one), with equal probability. This is repeated for every element up to reaching the terminal state with a zero loop. Hence, there is a bijection between runs in this Markov chain and subsets of~. Moreover, all subsets are equiprobable: they have probability  to be selected.

The discount factor can be chosen arbitrarily. For the sake of concreteness, assume it is . Now, observe that the weight function is defined such that the discounted sum over a run representing a subset  is exactly equal to . To achieve this, we again use the trick of multiplying values  by  (the shift is due to the first transition). By definition of our weight function, it is clear that all runs take integer values. Also, the size of the Markov chain is polynomial in the size of the original problem.

Consider the single-constraint percentile query asking if

with  the initial state of the Markov chain. Note that we drop the existential quantification on strategies since there exists a unique - and trivial - strategy in a Markov chain. Recall that we only have access to an algorithm, say \textsf{Algo}, that solves the -gap problem, not the exact one. Consider  and let us review the possible answers given by the execution of \textsf{Algo} on this query.

Assume \textsf{Algo} answers \textsf{Yes}. By definition of the -gap problem (Theorem~\ref{thm:ds_gap}), we have that

The implication follows from the fact that all runs take integer values and by equality  since . This implies that there are at least  distinct runs representing subsets  for which . Hence the answer to the -th largest subset problem is also \textsf{Yes}.

Now assume \textsf{Algo} answers \textsf{No}. By definition of the -gap problem, we have that

using the fact that the second inequality is harder to satisfy. This implies that there are strictly less than  distinct runs representing subsets  for which . Hence the answer to the -th largest subset problem is also \textsf{No}.

In summary, we have that \textsf{Algo} answers \textsf{Yes} if and only if the answer to the -th largest subset problem is also \textsf{Yes}. This concludes our proof.
\end{proof}

\smallskip\noindent\textbf{Memory.} For the precise discounted sum and
generalizations, infinite memory is
needed~\cite{DBLP:conf/lpar/ChatterjeeFW13}. For -gap problems,
the exponential upper bound follows from the algorithm while the lower bound is
shown via a family of problems that emulate the ones used for multiple
reachability (Theorem~\ref{thm:asreach}). 

\begin{lemma}
\label{lem:ds_memory}
Exponential-memory strategies are both sufficient and, in general, necessary to satisfy -gap percentile problems for the discounted sum.
\end{lemma}

\begin{proof}
First, the algorithm of Theorem~\ref{thm:disc_algo} solves the -gap percentile problem by answering a multiple reachability problem over an unfolded MDP of exponential size. As stated in Theorem~\ref{thm:absorbing-reachsafe}, memory of size polynomial in the MDP (here, the unfolded one) and exponential in the number of contraints (which is untouched by our algorithm) is sufficient to satisfy such queries. Moreover, once the first  steps have been played according to such a strategy, any arbitrary strategy may be used, in particular a memoryless one suffices. Hence, it follows that exponential-memory strategies suffice for the discounted sum -gap percentile problem.

Second, for the lower bound we use a family of MDPs based on the one defined to prove the exponential memory requirements of multiple reachability problems (Lemma~\ref{lem:multiReach_expMemoryLB}). Consider the unweighted MDP depicted in Fig.~\ref{fig:multiReach_exp_mem}. Recall it is composed of  stochastic gadgets followed by  controllable gadgets. We transform this MDP into a -dimensional MDP  as follows. First, we remove the self-loops on states  and  and replace them by actions going to a terminal state~ with probability one: this is for technical convenience. Second, we associate actions to -dimensional weight vectors:
\begin{itemize}
\item the action leaving  has weight  in all  dimensions,
\item actions leaving a state  have weight  in dimension  and weight zero in all other dimensions,
\item actions leaving a state  have weight  in dimension  and weight zero in all other dimensions,
\item actions leaving a state  have weight  in dimension  and weight zero in all other dimensions,
\item actions leaving a state  have weight  in dimension  and weight zero in all other dimensions,
\item all remaining actions have weight zero in all dimensions.
\end{itemize}

As usual, the discount factor can be taken equal to . While this may seem technical, the goal is simple: emulating the multiple reachability problem used in Lemma~\ref{lem:multiReach_expMemoryLB}. Each dimension  will get a  by the first action. Then, a dimension  (resp. ) will get a  when  or  (resp. when  or ) is visited. All other actions have no impact on the discounted sum over dimension . Therefore, one can easily check if a run  has visited a set  (resp. ): it suffices to check if the discounted sum on dimension  (resp. ) is at least zero.

Now consider the percentile query

and in particular, its -gap version, with . Applying the same reasoning as for proofs of Lemma~\ref{lem:ds_pspace_hard} and Lemma~\ref{lem:ds_np_hard}, we can prove that the answer to this -gap problem is \textsf{Yes} if and only if all target sets
 
are reached almost-surely. By Lemma~\ref{lem:multiReach_expMemoryLB}, we know that this requires a strategy encoded as a Moore machine with no less than  memory states. This shows the exponential lower bound for the -gap problem and concludes our proof.
\end{proof}
 
\section{Conclusion}

Through this paper, we studied the strategy synthesis problem for \textit{multi-percentile queries} on multi-dimen\-sion\-al MDPs: we considered a wide range of payoff functions from the literature (sup, inf, limsup, liminf, mean-payoff, truncated sum, discounted sum), and established a complete picture of the multi-percentile framework, including algorithms, lower bounds on complexity, and memory requirements. Our results are summed up in Table~\ref{table}.

It is especially interesting to observe that for all payoff functions but the discounted sum, our algorithms require \textit{polynomial time in the size of the model} when the query size is fixed. This is of utmost practical interest as in most applications, the query size (i.e., specification) is typically small while the model (i.e., the system) can be very large. Hence, our algorithms have clear potential to be useful in practice. As future work, we aim to assess their practical efficiency through implementation in tool suites and case studies.

\bibliographystyle{plain}
\bibliography{biblio}


\end{document}
