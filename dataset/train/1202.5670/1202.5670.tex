\pdfoutput=1

\documentclass[runningheads]{llncs}
\usepackage{amssymb}
\usepackage{amsmath}
\usepackage{graphicx}
\usepackage{verbatim}
\usepackage{color}
\usepackage{ae}
\usepackage[ruled]{algorithm}
\usepackage{algorithmicx}
\usepackage{algpseudocode}
\usepackage[breaklinks,bookmarks=false]{hyperref}
\DeclareMathOperator{\bord}{border}
\DeclareMathOperator{\period}{period}
\DeclareMathOperator{\prefix}{prefix}
\DeclareMathOperator{\suffix}{suffix}
\DeclareMathOperator{\nr}{nr}
\DeclareMathOperator{\rank}{rank}
\DeclareMathOperator{\post}{post}
\DeclareMathOperator{\pre}{pre}
\DeclareMathOperator{\prefixer}{prefixer}
\DeclareMathOperator{\detector}{detector}
\DeclareMathOperator{\LCP}{LCP}
\DeclareMathOperator{\child}{child}
\DeclareMathOperator{\prev}{prev}
\DeclareMathOperator{\next}{next}
\DeclareMathOperator{\failure}{failure}
\DeclareMathOperator{\RMQ}{RMQ}
\DeclareMathOperator{\heaviest}{heaviest}
\DeclareMathOperator{\ancestors}{path}
\DeclareMathOperator{\weight}{weight}
\DeclareMathOperator{\size}{size}
\DeclareMathOperator{\head}{head}
\DeclareMathOperator{\depth}{depth}


\newcommand{\twodots}{\mathinner{\ldotp\ldotp}}
\newcommand{\id}[1]{\ensuremath{\mathit{#1}}}
\newcommand{\proc}[1]{\textnormal{\scshape#1}}

\begin{document}

\title{(Really) Tight bounds for dispatching binary methods}
\titlerunning{Dispatching binary methods}

\author{Pawe\l{} Gawrychowski\thanks{Supported by MNiSW grant number N~N206 492638, 2010--2012 and START scholarship from FNP.}}
\institute{
     Institute of Computer Science, University of Wroc{\l}aw, Poland\\
     Max-Planck-Institute f\"{u}r Informatik, Saarbr\"ucken, Germany\\
	\email{gawry@cs.uni.wroc.pl}
	}

\maketitle
\begin{abstract}
We consider binary dispatching problem originating from object oriented programming. We want to preprocess a hierarchy of classes and collection of methods so that given a function call in the run-time we are able to retrieve the most specialized implementation which can be invoked with the actual types of the arguments. This problem has been thoroughly studied for the case of mono dispatching~\cite{Muthukrishnan,FerraginaDynamic}, where the methods take just one argument, resulting in (expected)  query time after just linear preprocessing. For the binary dispatching, where the methods take exactly two arguments, logarithmic query time is possible~\cite{Ferragina}, even if the structure is allowed to take linear space~\cite{Alstrup}. Unfortunately, constructing such structure requires as much as (expected)  time~\cite{Alstrup,Poon}.

Using a different idea we are able to construct in (deterministic) linear time and space a structure allowing dispatching binary methods in the same logarithmic time. Then we show how to improve the query time to just , which is easily seen to be optimal as a consequence of some already known lower bounds if we want to keep the size of the resulting structure close to linear.

\textbf{Key-words}: method dispatching, persistent data structures, rectangle geometry
\end{abstract}

\section{Introduction}

The motivation for the method dispatching comes from object-oriented programming languages, where we have a hierarchy of classes with uniquely defined parents. We also have a collection of  functions accepting a constant number of arguments, where each argument must have a specified class as an ancestor in the hierarchy. Then given a function call, we should (efficiently) determine the most specific implementation based on the actual types of the arguments. This problem was first considered in the mono dispatching version, where each method takes just one argument. It is known that in such case the input can be preprocessed in linear time and space so that each query can be answered in  time~\cite{Muthukrishnan}, and that we can update the structure in  time while retaining the same bounds on the query time~\cite{Ferragina}.

The more general multi-method version of the problem was considered by Ferragina \emph{et al.}~\cite{Ferragina}, whose methods imply that for the special case of the binary dispatching (where all function are binary) we can achieve  query time after a  preprocessing or  query after a  preprocessing. Then Eppstein and Muthukrishnan~\cite{Eppstein} improved the former by showing that, for example,  query time is possible after a  preprocessing. Finally Alstrup \emph{et al.}~\cite{Alstrup} decreased the preprocessing space to  while retaining logarithmic query time. Unfortunately, their preprocessing time was not linear but (expected) . Another structure with the same bounds was given by Poon and Kwok~\cite{Poon}. 

In this paper we first give in Section~\ref{section:algorithm} a simpler yet more effective solution with (deterministic) linear time and space preprocessing and the same logarithmic query time. Our solution uses a slightly different approach than the previous methods, and because of this difference we are then able to decrease the query time in Section~\ref{section:algorithm2} to just  while retaining the linear time and space preprocessing. This complexity is easily seen to be optimal for structures of size  as a consequence of some already known lower bounds, which we briefly review in Section~\ref{section:lower bound}.

While even the first logarithmic query time solution needs the word RAM model, the same is true for the previously known linear space solutions, hence it should not be seen as a drawback.

\begin{figure}[t]
\centering
\includegraphics{bridges}
\caption{Unique lowest bridge for  and  and an ambiguous situation.}
\label{figure:bridges}
\end{figure}

\section{Preliminaries}

We work with the following formulation of the problem: we are given a tree  on  vertices and a collection of  \emph{bridges}, which are simply pairs of vertices . We say that a bridge  is lower than  if  is a descendant of  and  is a descendant of . We want to preprocess the input so that given two vertices  and  we can detect the lowest bridge  such that  is a descendant of  and  is a descendant of , see Figure~\ref{figure:bridges}. If there is no such unique lowest bridge, we need to signal ambiguity. We aim to develop a  time preprocessing which allows  time queries.

We work in the standard RAM model of computation with logarithmic word size. The following result is known in such model.

\begin{lemma}[atomic heaps~\cite{FredmanWillard}]\label{lemma:atomic}
It is possible to maintain a collection of sets  so that inserting, removing and finding successor in each of those sets work in constant time (amortized for insert and remove, worst case for find) as long as  for all , assuming  time and space preprocessing, where  is any (but fixed) constant.
\end{lemma} 

\section{New algorithm}
\label{section:algorithm}

First observe that the above problem reduces in a natural way (by computing the pre- and post-order numbers) to retrieving the smallest rectangle containing a given point on a  grid (or detecting there is no such unique smallest rectangle). From now on we will work with this simple geometric formulation. Note that the  and  projections of any two rectangles are either disjoint or contained in each other (we call such collection of rectangles {\it valid}) and we can normalize the coordinates so that .

We sweep the grid from left to right while maintaining a structure describing currently intersected rectangles. The structure is simply a full binary tree on  leaves corresponding to different  coordinates. To process an interval  with
, we locate the lowest common ancestor  of the leaves corresponding to  and  and call it {\it responsible} for . Each inner vertex stores a stack containing all intervals it is currently responsible for. To insert a new interval we push it onto its responsible vertex stack. To remove an interval, locate the responsible vertex and observe that (because the collection is valid) the interval we want to remove is its top element, and we can simply pop it.

\begin{figure}[t]
\centering
\includegraphics[scale=0.9]{responsible}
\caption{Rectangles on the same stack and their version tree.}
\label{figure:responsible}
\end{figure}

Fix an inner vertex and consider all  rectangles it was responsible for, see Figure~\ref{figure:responsible}. Note that the intersection of
all their  projections is nonempty, and hence any two of those projections are contained in each other. By a simple linear time transformation we can assume that all their start and end points are different, and their sorted list is  (of course we cannot assume that sorting a single list can be performed in linear time, but note that we can sort lists of all inner vertices at once, and because their elements are small integers we can apply counting sort). We define the \emph{version tree} as follows: the parent of a rectangle  is the rectangle  such that  and  is the smallest possible. Because any two  projections are either disjoint or contained in each other, and all  are different, this is a valid definition. We
may assume that the result is indeed a tree (not a forest) by adding one artificial rectangle. Each vertex of this tree is labeled with an integer denoting the height  of the corresponding rectangle. Consider the sorted list of all different  coordinates. For each pair of consecutive
integers  on this list we would like to find the vertex of the version tree such that its ancestors are exactly the elements of the stack at time  (we call it the \emph{tail} at time ). This can be precomputed in a straightforward way during the sweep. 

Consider a query concerning a point . First we locate the leaf  corresponding to . Any rectangle containing  belongs to the
stack of one of its ancestors at time . More specifically, it must be an ancestor of the tail at time  of one of those  stacks. Hence
we should start with locating all those  tails efficiently.

\begin{lemma}\label{lemma:cascading}
Given a time  we can retrieve its tail at every ancestor of the leaf corresponding to  in total  time after a linear time and space preprocessing.
\end{lemma}

\begin{proof}
A straightforward application of the fractional cascading technique of Chazelle~\cite{Chazelle}. Recall that this technique allows linear time and
space preprocessing of a constant-degree graph with (sorted) lists of elements associated to the vertices so that given a path we can perform binary search for the same value in all lists corresponding to its vertices in time , where  is the total size of all lists and  is the length of the path. In our case  and the claimed running time follows.
\qed
\end{proof}

Each version tree will be carefully preprocessed as to implement two operations. Let  be the set of all ancestor weights of a given vertex . The first operation is very simple: given  we would like to find the vertex corresponding to . This can be trivially preprocessed in linear time and space. The second operation is more involved: given  and  we would like to find the vertex corresponding to the successor of  in . Before we show how to implement it efficiently, we formulate two auxiliary lemmas.

\begin{figure}
\centering
\includegraphics[scale=0.9]{slices}
\caption{Reducing the original query to queries in smaller structures.}
\label{figure:slices}
\end{figure}

\begin{lemma}\label{lemma:small grid}
A collection of sets of points  on a  grid such that  for all  can be preprocessed in  time so that given  and  we can retrieve the point corresponding to  in constant time.
\end{lemma}

\begin{proof}
The idea is to recursively build a collection of smaller structures allowing performing the same operation but on subsets of the original set of point. 

Assume we have a set of  points . By Lemma~\ref{lemma:atomic} we can sort the points according to their  coordinates in  time. Then we split the original set into blocks of size roughly  by choosing  evenly spaced elements  in this sorted sequence and call the -th block . We build a smaller structure for each . Additionally, let  be the smallest  coordinate in the -th block and create a new set of  points of the form  which we call \emph{representatives}. We build a smaller structure for this new set. If  is very small, say , we switch to a different method: we can first normalize the coordinates of the points so that they are at most  and encode the whole set in a single machine word going row-by-row.

Observe that the total size of all structures built for a single  is just . Furthermore, they allow us to answer a single query in constant time as follows. First locate the block  belongs to and query the corresponding smaller structure. If this smaller structure contains a point  with  and , we are done. Otherwise we use the smaller structure built for the representatives to locate the lowermost block containing such point and query its corresponding smaller structure, see Figure~\ref{figure:slices}. If the size of  is small and we have the whole set encoded in a single machine word, we can answer a query by first masking out all bits corresponding to points with too big  or too small  coordinates and then finding the lowest bit set to . The total running time is constant because we will inspect just a constant number of structures for a single query.
\qed
\end{proof}

The next lemma will be used to preprocess each version tree. The main tool in its proof is the heavy path decomposition, which is defined as follows: each vertex chooses an edge leading to a child with the largest size. Removing all non-chosen edges leaves us with a collection of paths. We define the \emph{path tree} by creating one vertex for each such path, and choosing the parent of a path  by looking up the parent of its highest vertex in the original tree and retrieving the corresponding path. It is easy to see that the depth of a path tree is just . We say that a path  is above a vertex  if the path  belongs to is a descendant of  in the path tree. 



\begin{lemma}\label{lemma:version preprocessing}
A node weighted weighted tree on  vertices with the weights from  can be preprocessed in linear time and space so that given  and  we can find the vertex corresponding to the successor of  in  in  time.
\end{lemma}

\begin{proof}
Consider a single path. By preprocessing all paths at once we can construct a sorted list of all weights  on this path. We split each list by choosing  evenly spaced weights  and call the corresponding vertices \emph{important}. The -th group contains vertices  for . We choose the highest vertex from each such group and calling it the {\it representative}. Note that the total number of both important vertices and representatives is at most .  For each group we construct the corresponding small set:

and apply the preprocessing described in Lemma~\ref{lemma:small grid}.

We would like to implement the following operations efficiently:
\begin{enumerate}
\item given  and , for each path above  find the successor of  among the weights of its important vertices,
\item given  and , for each path above  find the successor of  among the weights of all representatives which are ancestors of .
\end{enumerate}
First lets see how such information allows us quick retrieval of the successor of  in . Assuming that we know the successor of  among all weights of the important vertices on , we query the structure constructed for the corresponding group. If it contains at least one vertex above , we are clearly done. Otherwise we know that the successor belongs to a higher group than . Assuming that we know the successor of  among the weights of all representatives which are above , we query the structure constructed for his group.

We use almost the same to implement both operations. Lets start with the former. For each path  we build a binary search tree containing all important vertices located on all paths corresponding to the ancestors of  (including  itself) in the path tree. The vertices are sorted according to their weight. By using any persistent balanced search trees we can build the structures in total linear time and space. Furthermore, the total number of new nodes created as a result of all inserts will be just . For the sake of concreteness, assume that we use trees in which the original elements are stored only in the leaves. To facilitate efficient query processing, at each vertex  we store an additional \emph{helper structure} mapping a path depth to the smallest weight stored at the subtree of  and originating from an important vertex with such path depth. This structure consists of an array of size  and one word with the -th bit set if and only if the -th entry in the array is defined. The helper structures are of just  size, hence we can afford to build one for each new node in total linear time and space. Now given a query concerning a vertex , we locate its path and the corresponding binary search tree. Then we find the successor of  in this tree with a single  time transversal. We claim that the helper structures stored at all right brothers of the visited vertices give us enough information to locate the successors of  among the chosen weights of all paths above . This is fairly obvious if we consider a single such path. The tricky part is to extract the information from all of them in  time. We go through the vertices in a bottom-up order. In the very beginning we do not have the successor on any path. We iteratively consider the right brother of the next visited vertex: its helper structure gives us the successor on every path for which the corresponding entry is defined and which is yet unknown. By storing the currently unknown set in a single word, we can compute this intersection in constant time, and then extract the successors in constant time per path.

To implement the latter, we use almost the same method. The only exception is that now we build a binary search tree for each representative instead of each path.
\qed
\end{proof}

Now we are ready to prove the main lemma in this section.

\begin{lemma}\label{lemma:smallest}
A set of  rectangles on a  grid can be preprocessed in linear time and space so that given a point  we can find the rectangle  containing  with the smallest height  in  time.
\end{lemma}

\begin{proof}
First apply Lemma~\ref{lemma:cascading} to locate the tail at time  in every ancestor of the leaf corresponding to . Then select  to be the lowest of those ancestors such that the maximum on the corresponding tail-to-root path is sufficiently big to contain  in the corresponding interval. There are just  ancestors and extracting each maximum requires constant time. Now we claim that the smallest height rectangle can be found by looking at the version tree of  only.  Assume otherwise, i.e., there is  such that  is an ancestor of  and the smallest rectangle belongs to the version tree of . But then the  interval at  properly contains the the  interval at , and hence the interval of the rectangle at  is smaller.

To finish the proof, we apply Lemma~\ref{lemma:version preprocessing} to each version tree. Then given the tail at  we first compute the smallest possible height of a rectangle stored in this tree which guarantees containing  inside. This can be performed in  time if we store all  intervals sorted according to their lengths. Then we compute the successor of this smallest possible height on the tail-to-root path. It corresponds to the smallest height rectangle.
\qed
\end{proof}

\begin{theorem}
Bridge color problem can be solved in  time after a linear time and space preprocessing.
\end{theorem}

\begin{proof}
First we transform the input so that no two bridges share an endpoint. This can be ensured by increasing the number of vertices to at most  by repeating the following procedure: given a group of bridges ,  ,,  with the same endpoint , sort them so that  for all . Then replace  by a path  and create  bridges  for .  We interpret the resulting set of bridges as a collection of rectangles on a  grid.

By Lemma~\ref{lemma:smallest} we can find the rectangle  containing  with the smallest height  in  time. By swapping all  and  coordinates, we can also find the rectangle with the smallest width . Note that because no two bridges share an endpoint, those two rectangles are uniquely defined. If they are different, we signal ambiguity. Otherwise this rectangle is the unique lowest bridge. 
\qed
\end{proof}

\section{Decreasing the query time}
\label{section:algorithm2}

In order to reduce the query time we will carefully modify the algorithm from Section~\ref{section:algorithm}. We use a combination of standard tricks (increasing the degree of the tree to ) and a few extension of the observations from the previous section. The high level idea stays the same: we sweep the plane from left to right maintaining a structure describing currently intersected rectangles.  The structure is a full tree of degree  for a sufficiently small  (to be fixed later) on  leaves corresponding to different  coordinates . Each vertex stores three structures:

\begin{enumerate}
\item left stack storing prefixes of the corresponding segment,
\item right stack storing suffixes of the corresponding segment,
\item block stack storing fragments consisting of a number of whole segments corresponding to a contiguous range of its children.
\end{enumerate}

To process an interval  we locate the lowest common ancestor  of the leaves corresponding to  and  and split the interval into three parts: a suffix of a segment corresponding to some child of , a number of full segments corresponding to  (which we call the middle part) and finally a prefix of a segment corresponding to some child , where  are the children of .
All stacks will be implemented using technique similar to the one from Lemma~\ref{lemma:version preprocessing}, with the block stack requiring one additional detail. Nevertheless, it also uses the idea of storing a list of all different  coordinates where a new item appears or disappears. For each pair of consecutive  we store a pointer to the corresponding version of the structure, and apply fractional cascading to quickly locate the most up-to-date version given a query . Now we need a slightly stronger version, though.

\begin{lemma}\label{lemma:fast cascading}
Given a time  we can retrieve the pointers to all current structures at all ancestors of the leaf corresponding to  in total  time after a linear time and space preprocessing.
\end{lemma}

\begin{proof}
We apply the {\bf fast} fractional cascading of Shi and  J{\'a}J{\'a}~\cite{Jaja}. It allows a linear time and space preprocessing of a -degree (where ) tree with (sorted) lists of elements associated to the vertices so that given a path of length  we can find the successors of a given value in all lists corresponding to its vertices in time . As we are working with a full -ary tree,  and the claimed running time follows.
\qed
\end{proof}

The implementation of a block stack consists of two parts. For each  we store a stack of intervals which the middle part corresponds to . Note that if we store a pointer for each , the space usage might be too large. Fortunately, only a linear number of those pointers will be non-null during the whole execution, hence for each vertex we can store a dictionary mapping  to a pointer. The dictionary can be implemented efficiently using Lemma~\ref{lemma:atomic}. The second part of the implementation is a single word encoding information which stacks are currently nonempty. Observe that the stack of intervals stored for each  is indeed a stack: we either push a new interval or pop the one which is on the top. Hence its implementation will be the same as in the case of left and right stacks. The only difference is that given  we need to quickly find  such that the corresponding stack is nonempty,  and  is smallest. This can be easily done in constant time using the single word encoding all nonempty stacks. To finish the implementation we need to show how to implement all stacks. As in the previous section, we will store their version trees, and a stack is actually a pointer to the current vertex in such tree. Each version tree will be preprocessed using a stronger version of Lemma~\ref{lemma:version preprocessing}. For that we first need to extend Lemma~\ref{lemma:small grid}.

\begin{lemma}\label{lemma:fast small grid}
A collection of  sets of points  on a  grid such that  for all  can be preprocessed in  time so that given  and  we can retrieve the point corresponding to  in constant time.
\end{lemma}

\begin{proof}
We extend the method used in the proof of Lemma~\ref{lemma:small grid}. We partition  into ,  and  blocks of size roughly  by choosing  evenly spaced elements in the sequence of points sorted according to the first, second, and third coordinate, respectively. For each such block we build a smaller structure. Additionally, we create a new set of {\it representatives} by taking all original points and replacing their coordinates with the number of the corresponding , , and  block. Note that the size of this new set is at most . We build a smaller structure for this set of representatives. If , we normalize the coordinates and encode the whole set in a single machine word instead.

To answer a query concerning  we first use the smaller structures built for , , and  blocks. This gives us the answer if its coordinates are close to ,  or . Otherwise we use the smaller structure built for the representatives, which gives us the  coordinate of the answer. Having this coordinate, we use the smaller structure built for the corresponding  block. Overall, the running time is constant, and the total size of all structures is , as the depth of the recursion is constant.
\qed
\end{proof}

\begin{figure}
\centering
\includegraphics[scale=0.5]{thin}
\caption{Decomposition of a tree into thin fragments.}
\label{figure:thin fragments}
\end{figure}

To extend Lemma~\ref{lemma:version preprocessing}, we need a relaxation of the heavy path decomposition, which we call a {\it thin fragments decomposition}.  First we choose all edges connecting vertices whose subtrees are of size at least . After removing this top fragment
of the tree we get a collection of smaller trees. For each of them we do the same, namely we choose all edges connecting vertices whose subtrees are of size which is a logarithmic fraction of the whole size of the current tree, remove the resulting top fragments, and repeat the whole procedure until we get single vertices. Each removed fragment is a tree on at most  leaves (but possibly many more inner vertices, hence the name), see Figure~\ref{figure:thin fragments}. We define the {\it fragment tree} with vertices corresponding to fragments and edges defined in the natural way, namely we make one vertex a child of another if the root of the former fragment is a child of a vertex belonging to the latter fragment. It is easy to see that its depth is at most . {\it Fragment depth} is the depth of the corresponding vertex in the fragment tree.

\begin{lemma}\label{lemma:fast version preprocessing}
A node weighted weighted tree on  vertices with the weights from  can be preprocessed in linear time and space so that given  and  we can find the vertex corresponding to the successor of  in  in  time.
\end{lemma}

\begin{proof}
For each fragment containing of  vertices we construct a sorted list of all weights. We choose  evenly spaced weights out of them and call the corresponding vertices {\it important} (notice  instead of ). For each such important vertex  we construct a small set of all pairs

and apply the preprocessing described in Lemma~\ref{lemma:fast small grid}. Additionally, from each group we select vertices which are minimal in the relation of being an ancestor and call them the {\it representatives}. Note that a single group cannot have more than  such representatives, therefore the total number of representatives is just .

We will show how to preprocess the tree so that given  and , for each fragment above  we can locate the successor of  among the weights of all important vertices and the weights of all representatives which are above .  We use exactly the same method as in Lemma~\ref{lemma:version preprocessing}, namely for each fragment  we build a binary search tree containing all important vertices on all fragments corresponding to ancestors of  in the fragment tree (including ), with a smaller structure stored at each vertex. Similarly, for each representative we build a binary search tree containing all representatives above. Now the size of the helper structure is just , though,  hence we can find the successor for each fragment in  time after just linear preprocessing. Given the successor, we use the helper structure storing the whole group of the corresponding vertex to retrieve the answer in constant time per fragment above .
\qed
\end{proof}

This gives us all the ingredients necessary to speed up the method from the previous section.

\begin{theorem}
Bridge color problem can be solved in  time after a linear time and space preprocessing.
\end{theorem}

\section{Lower bound}
\label{section:lower bound}

It turns out that  query time is optimal if we want to keep the size of the structure close to linear. This follows from the results of~\cite{Patrascu}, where a lower bound for the following 2D stabbing problem is shown: preprocess a given collection of  2D rectilinear rectangles so that we can quickly retrieve (any) rectangle containing a given point. It turns out that if we want to keep the size of the structure , the best possible query time is , even if we allow randomization. Furthermore, the lower bound is shown through a reduction from the reachability oracle problem, and hence the  and  projections of any two rectangles in the collection are either disjoint or contained in each other. A closer inspection of the proof shows that the queries can be assumed to be chosen so that there is at most one rectangle containing the point. It follows that we can encode the instance as a binary method dispatching problem, and the claimed lower bound follows.

\section{Conclusions}

We presented a time-and-space optimal solution for the binary method dispatching problem. Two questions remain:

\begin{enumerate}
\item is it possible to make the structure dynamic?
\item can we achieve linear preprocessing and logarithmic query in the pointer machine model? Note that the construction of Alstrup et al.~\cite{Alstrup} makes a heavy use of word RAM specific structures, such as the van Emde Boas trees.
\end{enumerate}

\bibliographystyle{abbrv}
\bibliography{biblio}

\end{document}
