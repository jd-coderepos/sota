\documentclass{elsarticle}

\usepackage[linesnumbered,noend,vlined, scleft,nofillcomment,ruled]{algorithm2e}

\usepackage{amsthm,graphicx}
\usepackage{lineno,hyperref}
\usepackage{xspace}
\usepackage{xcolor}
\modulolinenumbers[5]
\usepackage{multirow}
\usepackage{color}

\newtheorem{theorem}{Theorem}
\newtheorem{lemma}{Lemma}
\newtheorem{corollary}[theorem]{Corollary}
\newtheorem{fact}[theorem]{Fact}
\newtheorem{definition}{Definition}

\newcommand{\Oh}[1]
  {\ensuremath{\mathcal{O}\!\left( {#1} \right)}}

\newcommand {\changed}[1]{#1}

\newcommand{\DAC}{\ensuremath{\mathrm{DAC}}}
\newcommand{\kt}{-tree\xspace}
\newcommand{\ktree}{\kt}
\newcommand{\koct}{-tree\xspace}
\newcommand{\koctdac}{-tree\xspace}
\newcommand{\ktplain}{-tree\xspace}
\newcommand{\ktdac}{-tree\xspace}
\newcommand{\dblp}{\textsf{dblp}\xspace}
\newcommand{\enwiki}{\textsf{enwiki}\xspace}
\newcommand{\indo}{\textsf{indochina}\xspace}
\newcommand{\uk}{\textsf{uk}\xspace}
\newcommand{\giss}{\textsf{GIS-sparse}\xspace}
\newcommand{\gism}{\textsf{GIS-med}\xspace}
\newcommand{\gisd}{\textsf{GIS-dense}\xspace}
\newcommand{\rdfs}{\textsf{RDF-sparse}\xspace}
\newcommand{\rdfm}{\textsf{RDF-med}\xspace}
\newcommand{\rdfd}{\textsf{RDF-dense}\xspace}
\newcommand{\mdta}{\textsf{mdt500}\xspace}
\newcommand{\mdtb}{\textsf{mdt700}\xspace}
\newcommand{\mdtc}{\textsf{mdtmed}\xspace}
\newcommand{\LCP}{\ensuremath{\mathrm{LCP}}}

\newcommand{\hpqt}{\textsf{hpqt}\xspace}
\newcommand{\hpqtp}{\textsf{hpqt}\xspace}
\newcommand{\hpqtR}{\textsf{hpqt}\xspace}
\newcommand{\hpqtpdac}{\textsf{hpqt}\xspace}
\newcommand{\hpqtRdac}{\textsf{hpqt}\xspace}

\newcommand{\pdt}{PDT\xspace}
\newcommand{\pdth}{PDT-hollow\xspace}
\newcommand{\pdtrp}{PDT-RP\xspace}

\newcommand{\warn}[1]{{\large \color{red}#1}\\}
\newcommand{\no}[1]{}

\newenvironment{unchanged}{\color{gray}}{}
  
\newenvironment{example}{\paragraph{Example}}{\qed \medskip }
 



\journal{TBD}

\bibliographystyle{elsarticle-num}


\begin{document}

\begin{frontmatter}



\title{Faster Compressed Quadtrees}

\author{Guillermo de Bernardo, Travis Gagie, 
Susana Ladra,\\ Gonzalo Navarro and Diego Seco\\
\ \\
  Universidade da Coru√±a, CITIC, Database Lab, Spain\\
  Faculty of Computer Science, Dalhousie University, Canada\\
  IMFD --- Millennium Institute for Foundational Research on Data, Chile\\
  Department of Computer Science, University of Chile, Chile\\
  Department of Computer Science, University of Concepci\'on, Chile}
\date{}
\tnotetext[acks]{An early partial version of this paper appeared in {\em Proc. of the Data Compression Conference 2015}.}



\begin{abstract}
Real-world point sets tend to be clustered, so using a machine word for each point is wasteful. In this paper we first show how a compact representation of quadtrees using  bits per node can break this bound on clustered point sets, while offering efficient range searches. We then describe a new compact quadtree representation based on heavy path decompositions, which supports queries faster than previous compact structures. We present experimental evidence showing that our structure is competitive in practice.
\end{abstract}

\begin{keyword}
compact data structures, quadtrees, heavy-path decomposition, range queries, clustered points.
\end{keyword}

\end{frontmatter}

\section{Introduction}
\label{sec:introduction}

Storing and querying two-dimensional points sets is fundamental in computational geometry, geographic information systems, graphics, and many other fields.  Most researchers have aimed at designing data structures whose size, measured in machine words, is linear in the number of points.  That is, data structures are considered small if they store a set of  points on a  grid in  words of  bits each.  Using  bits is within a constant factor of optimality when the points are distributed uniformly at random over the grid, but we can often do better on real-world point sets because they tend to be clustered and, therefore, compressible.

Quadtrees~\cite{Mor66,Sam06} store the point's coordinates in implicit form, along a root-to-leaf path per point. Quadtrees may have  nodes when the points are clustered, because closer points tend to share a longer part of their path. Still, classic quadtrees are implemented with pointers, which take  bits per node, and since they use one node per point at the very least, they require  bits overall; the same happens if we store the explicit coordinates instead of the paths \cite{Gar82}.  

Recently, various authors \cite{BLN14,VM14,BCBNP20} proposed quadtree representations based on succinct trees, which avoid pointers. These structures store the coordinates implicitly using the paths, and those paths use  bits per quadtree node. Therefore, they are able to use  bits of space, while offering the same asymptotic query times as traditional structures when supporting edge-by-edge navigation. Venkat and Mount \cite{VM14} noted, however, that
\begin{quotation}
``A method for compressing paths or moving over multiple edges at once using a succinct structure may speed up the many algorithms that rely on traversal of the quadtree.''
\end{quotation}
Some previous data structures, such as skip-quadtrees~\cite{EGS08} and path-decomposed tries~\cite{GO14}, are evidence that quadtree variants can indeed use  bits per node while moving over multiple edges at once. The authors of skip-quadtrees only aimed at a space bound of  bits and did not give an implementation, while the authors of path-decomposed tries gave a mainly experimental analyses.

This paper contains two main contributions:
\begin{enumerate}
    \item We give a space analysis of quadtree data structures as a function of the amount of clustering of the point set, showing that compressed quadtrees can use  bits of space on clustered points. We also show that quadtree queries speed up on clustered points.
    \item We present the first compressed quadtree data structure that, within that space, uses heavy-path decomposition in order to provide one-step navigation over multiple edges, thereby speeding up queries.
\end{enumerate}

After describing the compressed quadtree data structure in Section~\ref{sec:related},
contribution 1 is provided in Section~\ref{sec:space}, and contribution 2 in Sections~\ref{sec:structure} (which describes the new structure) and Section~\ref{sec:membership} (which gives the new query algorithms).  In Section~\ref{sec:practice} we describe some practical improvements and in Section~\ref{sec:experiments} we show experimentally that our structure is competitive, and in particular that it outperforms current alternatives when retrieving isolated points. We conclude in
Section~\ref{sec:conclusions}.


\section{Basic Concepts}
\label{sec:related}

\subsection{Model of computation}

Like most of the work on compressed data structures, we assume the RAM model of computation, where the machine word holds  bits and can perform all the usual arithmetic and bitwise operations operations on words in constant time. Note  because .

\subsection{Bitvectors}

A bitvector is an array  of bits. We are interested, apart from accessing any bit , in implementing two operations:  counts the number of times bit  appears in , whereas  is the position of the th occurrence of bit  in . All these operations can be computed in constant time using only  extra bits on top of  \cite{Cla96,Mun96}.

\subsection{Quadtrees} \label{sec:quadtrees}

There are many kinds of quadtrees. Our definition corresponds to the so-called 
MX-Quadtree \cite{WF90,Sam06}.

\begin{definition}
Let  be a set of  points on a discrete grid . If  is 0, 
then the quadtree for the grid is a leaf storing 0. If , then the 
quadtree is a leaf storing 1 if the cell contains a point and 0 if not.
Otherwise, the quadtree is a tree whose root stores a 1 
and has four children, which are the quadtrees of the grid's four quadrants.
We say that a node {\em covers} the area of its subgrid and that it is an 
{\em ancestor} of the points in that subgrid.
\end{definition}

\begin{example}
Figure~\ref{fig:tree} shows an example, taken from Brisaboa et al.~\cite{BCBNP20}.  Notice the order of the quadrants is top-left, top-right, bottom-left, bottom-right, instead of the counterclockwise order customary in mathematics.  This is called the Morton or Z-ordering and it is useful because, assuming  is a power of 2 and the origin is at the top right --- without loss of generality, since we can manipulate the coordinate system to make it so --- the obvious binary encoding of a root-to-leaf path is the interleaving of the binary representations of the corresponding point's - and -coordinates.

\begin{figure}
\begin{center}
\includegraphics[width=\textwidth]{k2tree.pdf}
\caption{A set of points, indicated by 1s, on a  grid (left); the quadtree for those points (right).  The heavy lines in the quadtree indicate the path to the leaf corresponding to the shaded point on the grid.}
\label{fig:tree}
\end{center}
\end{figure}

For example, if we imagine the edges descending from each internal node in Figure~\ref{fig:tree} are labelled  from left to right, then the thick edges are labelled ; the obvious binary encoding for this path is .  The coordinates for the shaded point, which corresponds to the leaf at the end of this path, are , so interleaving the binary representations 1001 and {\it 0110} of its - and -coordinates also gives . \changed{We can interleave a point's coordinates in  time using, for example, pre-computed tables}.
\end{example}

We now summarize a few simple facts on quadtrees.

\begin{fact}
\label{fact:basics}
A quadtree for the set of points  on a grid  has height at most  and  nodes. A node at depth  covers a square area of size . A leaf storing a 1 is at depth  and hence covers
a single cell; there is exactly one such leaf per point in .
\end{fact}

A quadtree can efficiently find the points lying on a region of the grid.

\begin{definition}
A {\em query}  aims to retrieve the points of 
that lie within . The result is denoted . When  is a 
rectangle, the query is called a {\em range query}, and the special
case  is called a {\em membership test}
for the point .  
\end{definition}

Given a query region , the quadtree computes  by starting at the root and visiting all the nodes whose subgrids overlap , reporting the coordinates of every leaf storing 1. In a range query we can determine in constant time whether a node's area overlaps . This reduces the problem of computing the cost of solving a query to that of computing the size of a quadtree.

\begin{fact}
\label{fact:size}
Let  be the output of a range query. Then the cost of enumerating  by traversing all the nodes overlapping  in a quadtree for  is proportional to the number of nodes in a quadtree for .
\end{fact}

The Quadtree Complexity Theorem \cite{Kli71,HS79,Sam06} establishes that the number of maximal-area quadtree nodes inside a rectangle  of size , plus their ancestors, is . We traverse all those nodes to 
solve the query , plus the paths towards every point inside
. If we pessimistically add  nodes to account for each such path, 
we obtain the following result.

\begin{theorem}
The time complexity for solving the range query , 
where  is a rectangle of size , on a quadtree for  over 
a  grid, is .
\end{theorem}

If the points in  are clustered, however, then intuitively the root-to-leaf paths in the quadtree will share many nodes and we will use less space and time. The query time can be refined to  \cite[p.~361]{Nav16}, which shows that the time per reported point decreases on smaller or denser query ranges.
We further exploit this idea to provide more refined space and time bounds on clustered points in the Section~\ref{sec:space}.

\medskip

Quadtrees can be generalized to  dimensions, in which case each node 
has  children. On a universe , the quadtree still has height 
. The Quadtree Complexity Theorem formula generalizes
to  for a hypercube  of side , and consequently
the search time complexity for the query  becomes
.

\subsection{Compressed quadtrees}
\label{sec:comprquad}

Brisaboa, Ladra and Navarro~\cite{BLN14} proposed a compressed quadtree representation called -tree (a quadtree corresponds to using ). It represents a quadtree using exactly  bit per node, by collecting the s and s of the tree in levelwise order (omitting the root). 
They show that, by adding  and  support to this concatenation of bits, the quadtree can be navigated towards children and parent in constant time: if we identify the node  with the position  so that the  bits describing its children are in  (so the root is ), then the identifier of the th child of  is , and that of the parent of  is .

\begin{example}
The quadtree on the right of Figure~\ref{fig:tree} is represented as a bitvector  concatenating the bits  (the first level), followed by  (the second level), and so on. To traverse the path in bold, we start at the
root node, , and take the third child () with 
. Indeed, the child is the 4th node in a
levelwise traversal of the quadtree. Its second child () is
. Again, the child is the 10th node in the
levelwise traversal. The parent of node  is .
\end{example}




There are several other variants of this representation \cite{VM14,BCBNP20}, as well as various techniques to further reduce space.
A major improvement in compression \cite{BLN14} can be obtained in practice by exploiting small-scale regularities that arise in many real-world datasets. To do this, they consider small submatrices of a predefined size (for instance,  or ), and only represent the tree up to those submatrices, effectively trimming the lower levels of the tree. The different submatrices that arise are then sorted by frequency and stored explicitly in a matrix vocabulary, and a sequence of matrix identifiers is used as a last level of the tree. Directly-Addressable Codes~\cite{BLN13} (DACs) are used to store and access the sequence.
The -tree representation can be naturally extended to  dimensions, hence becoming a 
-tree.





\section{Tighter Bounds on Quadtrees of Clustered Point Sets}
\label{sec:space}

We first bound the size of a quadtree when the points can be distributed in  clusters of the same level; then we generalize the result to hierarchical clustering.

\begin{theorem}
\label{thm:space}
Let  be a set of points on the discrete grid .
Let  be a partition of
 into  clusters, so that each
 contains  points lying on a square region of
side  (the square regions are not necessarily disjoint).
Then the quadtree of  has  nodes.
\end{theorem}

\begin{proof}
Let  be any  square on the grid and
 be the points of  that lie within . 
Let  be the set of ancestors of the points in , and
 be the ancestors of the corners of  (those corners may or may not 
be in ). Since the quadtree of  has maximum height 
and  has 4 corners, it holds 


By Fact~\ref{fact:basics},
any ancestor  of a point in  that has depth at most 
covers all the points in a square of size at least .  
Therefore, the square must contain at least one corner of , and thus .  It follows that

so .
Since each cluster  has  points that lie within a square of
size , the result follows.
\end{proof}



\begin{theorem} 
\label{thm:hier}
Let  be a set of points on the discrete grid , and
 be a tree with root . Every node  stores a set 
 of  points,
which is the union of the points stored at its children.
The sets  of all the nodes  
at the same depth form a partition of  into clusters. The points 
 of every node  lie on a square region of side 
; those regions need not be disjoint.
Then the quadtree of  has  nodes, where  is the parent of  in  and  is the set of leaf nodes in .
\end{theorem}

\begin{proof}
Applying Theorem~\ref{thm:space} on the non-hierarchical clustering induced by the  leaves of , we obtain the upper bound
. We now refine the first term of the bound, which comes from adding up the ancestors of the  corners of each of the regions in . Instead of adding up their ancestors up to the root, let us count those ancestors in a finer-grained mode. Consider the  corners of a square of size  containing the points in . Their  ancestors of depth over  are charged to the node . The higher ancestors, however, cover a square of size at least  by Fact~\ref{fact:basics}, and therefore are also ancestors of some of the  corners of the area of the parent of , . We then do not need to account for those higher ancestors of the corners of the area of . The result follows.
\end{proof}

For example, consider a hierarchical clustering where each cluster lying on a square region of side  distributes its points evenly into  sub-clusters lying on squares of side , for  levels of clustering. By Theorem~\ref{thm:hier}, the quadtree has  nodes, and its compressed representation uses  bits, which can be .


Due to Fact~\ref{fact:size}, these result also bound the cost of a query on the quadtree of a set of clustered points, because we traverse precisely the quadtree nodes that lead to the output points.

All those results easily generalize to  dimensions, by enclosing each cluster in a hypercube with  corners.

\begin{corollary} 
Let  be a set of points on the discrete grid  and 
 be a tree defined as in Theorem~\ref{thm:hier}, except that
now the points  of every node  lie on a 
hypercube of side ; those hypercubes need not be disjoint.
Then the quadtree of  has 
 nodes.
\end{corollary}

We can combine these results with the improvements that favor dense clusters \cite{Nav16}, though the formulas are messier:  becomes .


\section{A Compressed Quadtree Representation based on Heavy Paths}
\label{sec:structure}



We describe a new compressed quadtree representation for two-dimensional points which, like the -tree, uses  bits per node and supports the basic navigation towards parent and children in  time. In the next section we show that this representation can support queries faster than the -tree and, in general, than the standard quadtree representations. We will also generalize our representation to higher dimensions.

\subsection{Data structure}

To store a quadtree, we first replace each internal node by a binary tree of height 2 and remove any node that has no descendant storing a 1. Let  be the resulting binary tree. The number of nodes in  is  (when every quadtree node has only one child with with a 1) to  (when all quadtree nodes children have 1s) of those in the quadtree. In addition to simplifying our construction, this modification makes quadtrees more practical in higher dimensions~\cite{BDNR14}, which we will also consider at the end of this section.

We then perform a heavy-path decomposition~\cite{ST83} of , as follows.

\begin{definition}
A heavy-path decomposition of  is a recursive decomposition of  into paths called {\em heavy paths}. The first heavy path goes from the root to a leaf, so that if the path contains a node  then it also contains the child of  with the most leaf descendants (breaking ties arbitrarily). Once the first heavy path is defined, its nodes are cut off the tree , leaving a forest of former subtrees of . We then recursively decompose every remaining subtree into heavy paths.
\end{definition}

A well-known property of this decomposition is that every root-to-leaf path in  consists of  initial segments of heavy paths. 
In the sequel we call heavy paths simply paths.

\begin{example}
Figure~\ref{fig:decomposition} shows the heavy-path decomposition of the binary tree for our example of Figure~\ref{fig:tree}. 
\end{example}

\begin{figure}
\begin{center}
\includegraphics[width=0.9\textwidth]{conf/decomposition.pdf}
\caption{The heavy-path decomposition of the binary tree for the example from Figure~\ref{fig:tree}.  Nodes storing 1s are black; nodes storing 0s are shown hollow, and discarded; thick edges belong to heavy paths.  The numbers below the black leaves indicate our path ordering.}
\label{fig:decomposition}
\end{center}
\end{figure}

We encode each  path  as a binary string whose 0s and 1s indicate which of 's nodes are left children and which are right children, respectively (considering the root as a left child), in increasing order of their depths. Note that all the  paths end at the same depth, and thus their length plus the depth of their topmost node is the same for all.  

We then sort the set of all those path encodings in decreasing order of their length. Ties between two paths  and  of the same length are broken as follows: if the topmost nodes of  and  are  and , respectively, the paths are ordered in the same way of the paths containing the parents of  and . Notice that  and  cannot have the same parent, since they have the same height and the tree is binary. The numbers below the leaves in Figure~\ref{fig:decomposition} indicate how we order the paths in our example.  

Our first structure is a bitvector  that concatenates the encodings of all the  paths, once sorted as described. This bitvector has exactly  bits, one representing each node of . We say that the bit  corresponds to the node  if  indicates whether  is a left child or a right child.

For each depth  (considering the root to have depth 0 and leaves to have depth , we store a bitvector  with 1s indicating which nodes at that depth in  have two children. These bitvectors have as many bits as there are internal nodes in .  Figure~\ref{fig:HandL} shows them for our running example.

\begin{figure}[t]
{\small


\vspace*{-3mm}
}
\caption{The bitvectors  and  and the arrays  and  for the tree of Figure~\ref{fig:decomposition}. Dashes and spaces are shown only to indicate how the bits in  and  correspond.}
\label{fig:HandL}
\end{figure}

Our final structures are much smaller: an array  of  entries stores in  the position in  where the first  path of length  (measured in number of nodes) is encoded (or null if there are no  paths of that length). Similarly, an array  stores in  the number of paths longer than . We give support to perform predecessor queries on  and :  gives the minimum length  for which . Because we sorted the  paths by decreasing length in ,  is the length of the  path  belongs to. Similarly,  tells the length  of the th path in .

\begin{definition}
Our compressed quadtree representation for  points on a  grid 
has the following components, whose precise contents are defined above:
\begin{itemize}
\item A bitvector  of  bits concatenating all heavy paths.
\item Bitvectors , for , with less than  bits in total.
\item Arrays  and , of  integers overall.
\end{itemize}
\end{definition}

\begin{theorem}
Our compressed quadtree representation on a set of points in  uses  bits per quadtree node, plus  bits.
\end{theorem}
\begin{proof}
Bitvector  and all the s take  bits per node in  and, therefore,  bits per node of the original quadtree. The arrays  and , with predecessor data structures, require just  further bits.
\end{proof}

\subsection{Navigation}
\label{sec:nav}

In this section we show how the basic parent/child navigation can be supported on our data structures.

\subsubsection{Moving to the parent}
Suppose  corresponds to node  in . As explained, we obtain the length  of the path containing  with . Further, the path of  is the th (in our ordering) of length  and  is the th top-down node in its path, where  and . Because the top node in the path of  is at depth , the depth of  is .

If ,  is not the topmost node in its path, and then its parent  corresponds to . If , instead,  belongs to another path. Since  is at depth , it is mentioned in . Further, the nodes at depth  with a child starting a path are exactly those that have two children (the other child continues the path of its parent). Finally, because we order the paths according to the order of their parent node, it turns out that, since  starts the th path at depth , its parent  is the th node at depth  having two children. The position of  in  is then found with . 

Because the paths are deployed on  by increasing starting depth (or decreasing length), all the paths having a node at depth  precede those that do not. Further, since the nodes in  appear in the same order of , we have that the node at  is the node at depth  in the th path of . The length of that path is found with , and it is the  path of length , for . The position  of  in  is then computed as : the paths of length  start at , then we have the preceding  paths of length , and in our path we want the node with absolute depth , which we convert to an offset (i.e., relative depth) by subtracting the depth of the first node in the path, .



\begin{example}
Let  be the top node in the ninth path in our ordering (see the first node in the path labeled  in Figure \ref{fig:decomposition}). It corresponds to the underlined position . Its parent  is the second node in the fourth path, at . To find  from , we first compute , the length of the path  belongs to. We also compute  and , so  is the first node in its path, which is the 3rd of length . The depth of  is . Since ,  lies in another path. It is of depth , and thus mentioned at position . To find its position in , we compute , the length of its path, as well as , so that the path of  is the first of length . We then compute its position .
\end{example}

\subsubsection{Moving to a child}
We compute , , , and  for  as before.
If the depth  of  is , then  is a leaf; otherwise it has left and/or right children. Further, one of the children of  is at : the left child if  and the right if .

To determine if  has another child, and where, we must locate  in . We compute , the rank of 's path in , thus  is the th node of depth . Therefore,  has another child iff .

This child is the top node of another path, which starts at depth  and thus is of length . Since there are  nodes of depth  from where new paths start, the child of  is at , where
.



\begin{example}
Reversing our previous example, we have for  the values , , , , and .  Since 's depth is ,  is not a leaf. One of its children is at ; since , this is the left child of . To find if there is a right one, we compute , so the path of  is the 4th in  and  is the 4th node of depth . Since ,  has a right child. This child starts a path at depth , of length , and it is the 3rd of those because . We then find the right child at , where , where indeed we find .
\end{example}



\begin{theorem}
Our compressed quadtree representation on a set of 2-dimensional points can move to the parent of a node or to any desired child in  time.
\end{theorem}
\begin{proof}
Moving to the parent or to a child in the quadtree requires a constant number of steps on , each of which is dominated by the time of the predecessor operations on  and . Since these arrays have a logarithmic number of elements, predecessors can be computed in constant time \cite{FW94}. 
\end{proof}

More practically, we note that, on a downward traversal from the root, we always know the length  of the current path, and therefore we can perform the operations without the need of predecessor queries. In Section~\ref{sec:membership} we show how heavy paths speed up the specific operations to query quadtrees.

\subsection{Higher dimensions}

In dimension , each quadtree node has  children, and the quadtree is still of height . Therefore our binary tree  introduces  levels per quadtree edge, reaching height . Simulating a quadtree move towards the parent or children takes  steps in . Each such step may require predecessor queries on the arrays  and , which now contain  elements. Those predecessor queries can be carried out in time  \cite{PT06}.

The addition of new nodes in  may increase their number by a factor of  with respect to the number of nodes in the original quadtree (if a quadtree node has  children,  adds  new nodes between the parent and the children). If we consider the number of s in the original quadtree, then  has at most  nodes per  (i.e., a path of length  towards the -child of every quadtree node), and thus  nodes per represented point.

\begin{corollary}
Our compressed quadtree representation on a set of points in  uses  bits per quadtree node (or, alternatively,  bits per point), plus  bits. It can move to the parent of a node or to any desired child in time .
\end{corollary}

These space and time factors are similar to what can be obtained on previous compressed quadtree representations \cite{BLN14,Nav16} on high dimensions. Although they can move to parents and children in constant time, their space may grow up to  bits per node, that is, exponentially with the dimension, because each node has  children and most of them are s. This can be alleviated with a bitvector representation for  that exploits sparsity \cite{OS07}, which recovers the  bits per 1 in the quadtree. In exchange, operation  takes time , so moving to a child takes time , while moving to the
parent still takes  time.

Although both solutions seem then comparable in terms of space and basic operations, we show next how to leverage the heavy-path representation to support root-to-leaf traversals in time  instead of . This is particularly relevant for membership queries. 


\section{Membership and Range Queries}
\label{sec:membership}

Suppose we want to determine whether the point  is in the set. The first step is to obtain the Morton code  of the point, by interlacing the bits that describe the integers  and . We can do this in time , for any constant , with a table using  space. This table does not depend on the data points: for any two chunks of  bits, the table returns their interlacing. We can then find the Morton code of  by pieces of  bits, via  accesses to the table with the consecutive pieces of  bits of  and .

We now enter the binary tree  from the root, using the successive bits of  to
decide whether to go left or right. That is, each bit of  corresponds to an edge to follow.
Instead of processing  bit by bit and descending in  edge by edge, however, we descend path by path. 

We first determine the prefix of the first path (the one starting at the root) that we must follow. For this sake, we compute , where , , and  is the length of the longest common prefix between bitstrings  and  (we start from  because the first bit of the first path, , is spurious, whereas  refers to the first edge). Note that the length of the first path, , is , with  edges.

If , then  matches the whole path starting at , and then we know that the point is stored in the quadtree. If not, then  shares its first  edges with the path starting at , matching up to node , but not  (e.g., if  and  then  matches only the root node). We must then determine if  has two children and, if so, move to the other child. This is done as described in Section~\ref{sec:nav}.
If  has only one child, then  is not in the set. Otherwise, letting  be the other child of , we know that  starts a path of length , with  edges. We then update , , .

This process is repeated until we find  or determine it is not in the set of points. Since we switch to another descendant heavy path at each step in our process, we perform  steps \cite{ST83}. Algorithm~\ref{alg:member} gives
the pseudocode.

\begin{algorithm}[t]
\caption{{\bf Membership}(, )}
\label{alg:member}

 Morton code of ; \\
; \\
; \\
; \\
; \\
\While{true}
   { ; \\
     \lIf{} {\Return yes}
     ; \\
     \lIf{} {\Return no}
     ; \\
     ; \\
     ; \\
     ;
   }
\end{algorithm}

Note that we always know the length  of the path we are navigating, and therefore moving to a child requires only  time. Just the  functionality on the bitvectors, without using  nor predecessor queries, is needed. We can also compute  in  time if  and  are  (we apply  on , but it suffices to consider only the first  bits of that suffix). With , the  highest bits become  and the th becomes . We then use a constant-time technique to find the highest  in  \cite{Knu09}. We can also compute  using tables of size , as before.



\begin{example}
To perform a membership query for  in our quadtree of Figure~\ref{fig:tree} (the shaded cell), we first interlace the bitstrings to obtain the path label, , and then use it to traverse the path-decomposed tree  of Figure~\ref{fig:decomposition}. We first try to match  with the longest path, of length , from  (see Figure~\ref{fig:HandL}). The common prefix is of length , so we cannot go past the root by that path. We then see that the root has another child, which is , starting a path of length  (our algorithm computes , , , , and , continuing because ). Since , we can advance up to , where  wants to go right () but the path goes left (). We then find that  has another child, , which starts a path of length  (our algorithm computes , , , , and , continuing because ). We finally compute , so we have arrived at a leaf () and report that the point exists.
\end{example}

In the worst case, we must traverse  paths along this process. This contrasts with the  time needed with the classical representation, showing that our structure should be faster on sparse points sets. Further, we need fewer path switches in the way to isolated points. The next theorem shows that the membership time indeed improves on those points.

\begin{theorem}
\label{thm:membership}
With the help of a constant table using  space (for any constant 
), our compressed quadtree representation supports a membership 
query for  in  time. Further, the time is , where  is the number of points in  within distance  of .
\end{theorem}

\begin{proof}
The  bound follows from the heavy path decomposition. Further,
any ancestor  of  of depth at least  in  covers a subgrid of size at most , whose points that are then at distance at most  from . Thus,  covers at most  points of .  It follows that the path from  to the deepest ancestor  of  consists of  initial segments of heavy paths.  To see why, consider that if we ascend from  to , every time we move from the topmost node in one heavy path to its parent in another heavy path, the number of leaf descendants in the subtree below us at least doubles.  Since the path from the root to  has length , the path from the root to  consists of  initial segments of heavy paths.
\end{proof}

The following corollary, which combines Theorems~\ref{thm:hier} and~\ref{thm:membership}, suggests that our structure should be particularly suited to applications in which points are highly clustered (e.g., towns) but queries are chosen uniformly or according to a different distribution (e.g., seismic activity). 

\begin{corollary} 
\label{cor:hier-query}
Let  be a set of points on the discrete grid  and
 be a tree defined as in Theorem~\ref{thm:hier}.
Let  be the set of nodes at level  in . Then a membership query for  takes  time, where  is the minimum distance between a point in  and .
\end{corollary}
\begin{proof}
Let . Let us define
, so 
and . By Theorem~\ref{thm:membership}, the cost
of the membership query is then . This 
bound holds for every level , so the time is .
\end{proof}



\subsection{Range queries}

In order to output all the points in  given a query region , we first traverse via heavy paths towards the lowest ancestor of  in the quadtree. For this sake, we compute  and define  and  as the first  bits of  and , respectively. We then interlace  into a bitstring  of length , and traverse towards  in the quadtree as described in the main part of this section. The node  we arrive at is the ancestor of all the points in . We now traverse edge by edge towards all the descendants of  using the method described in Section~\ref{sec:nav}, in constant time per edge traversed, avoiding to enter into nodes whose area does not intersect , and reporting all the leaves found.

The node  can be very high in the tree, even for small regions, and thus this method is no faster in the worst case than the classical one. We expect, however, it to be faster in many cases when the query region is small. We inherit the
refined bounds for classic quadtrees \cite[p.~361]{Nav16}.

\begin{corollary}
Our compressed quadtree representation outputs , for a rectangle  of size , in time .
\end{corollary}

\subsection{Higher dimensions}

In dimension , the description of the point sought, , has  bits, and it might not fit in a computer word of size . We can still use the precomputed table of size  described at the beginning of this section to obtain the bitstring  (of length ) in time , as follows. Build a binary tree where the root represents all the  coordinates, . Its left child represents the odd positions of the parent,  and the right child the even positions, . This division, taking odd and even positions, continues until the leaves represent only one dimension  and store the bitstrings . Now, bottom up, every internal node merges the bitstrings of its two descendants by chunks of  bits,  until the root obtains . It is easy to see that the tree has  levels and that the total work per level is .

Once we obtain , the membership query proceeds as for two dimensions. The only difference is that a single  query may take time , because the prefix may coincide in  bits. However, the sum of all those  values along the search is also , because we advance in  by  positions each time. Therefore, the time to descend to the leaf  or to determine it does not exist is . Note that we do not require predecessor queries to determine membership.

\begin{corollary}
With the help of a constant table using  space (for any constant ), our compressed quadtree representation supports a membership query for  in  time.
\end{corollary}

Our finer results can be similarly extended to  dimensions; we leave them
as exercises to the reader.

\section{Practical Optimizations and Implementation Variants}
\label{sec:practice}

For the creation of the path labels, we use a precomputed table of 256 entries to compute the interleaving byte-wise, together with some arithmetics to build the final path. For the 3-dimensional case we have also used an implementation based on magic numbers. In practice, the computation of the initial path has negligible effect on the total query times.

The query algorithms described in previous sections always use a top-to-bottom traversal of the conceptual tree , which leads to a number of practical optimizations.  A first practical choice, already mentioned, is the adjustment of the traversal algorithms to keep track of the current depth, thereby avoiding the need for predecessor structures in  and . In this section we describe other practical variants that can reduce the space usage of our structure.

A first significant space improvement can be obtained by removing information in  that can be deduced during top-down traversals. Bitvector  stores, for each path, a bitstring representing its nodes, marking whether each is a left or a right child. During top-down traversal, we always start at the beginning of the first path, and whenever we switch to a new path we always start at its beginning. Note that when switching paths, the first bit of the new path can be inferred, since it is the opposite of the next bit in the current path. Indeed, in the membership query of Section~\ref{sec:membership} we always skip that first bit, , and compare  with . Therefore, we can remove the first bit of each path in  and still perform top-down traversals on the tree. Since all the paths are shortened in the same way, the navigational properties remain the same and only minor changes are required. Overall, we save one bit per path, or which is the same, per point in .

Another improvement in space can be obtained by noting that there are only  s across all the bitvectors , at the starting node of each path. In contrast, their total length can be up to  (i.e., one path in  per point), getting closer to that maximum on sparse datasets. We can then use for the bitvectors  a compressed bitvector representation \cite{RRR} that supports constant-time access and  queries but uses less space when the bitvector has many more s than s. With that representation, the whole set of bitvectors  fits within  bits. In practice this representation is slower, though.

Finally, we can also apply to our structure the matrix-vocabulary compression applied on the last levels of the quadtree \cite{BLN14}, described at the end of  Section~\ref{sec:comprquad}. We can trim  a few levels above the last one, and use DACs to replace the removed levels by a matrix vocabulary and a DAC-encoded sequence of matrix identifiers. All the query algorithms remain the same, though they stop at a smaller depth . Once this depth is reached, we find the corresponding submatrix, and perform single-cell access or range queries over the submatrix in the same ways as the classical compressed quadtree \cite{BLN14}.

\section{Experimental Evaluation}
\label{sec:experiments}

\subsection{Experimental framework}

We tested the performance of our solution on real datasets from different domains. We consider grids extracted from geographic information systems (GIS), social networks (SN), Web graphs (WEB) and RDF datasets (RDF). 

\begin{itemize}
\item The datasets \dblp and \enwiki are network data corresponding to the social network datasets dblp-2011 and enwiki-2013, provided by the Laboratory for Web Algorithmics\footnote{{http://law.di.unimi.it}}~\cite{BoVWFI,BRSLLP}.
\item Collections \indo and \uk are obtained from Web graph crawls, from the indochina-2004 and uk-2002 datasets provided by the Laboratory for Web Algorithmics.
\item We build three datasets storing geographic information by processing the Geonames dataset, which stores over 9 million locations, discretizing them on a grid. We build three different datasets (\giss, \gism, \gisd) by varying the resolution of the grid.
\item We build three datasets storing RDF-based grids, by parsing the DBPedia dataset\footnote{http://wiki.dbpedia.org/Downloads351}. RDF stores triples (S,P,O) that represent labeled edges in a graph, where the predicate P represents the label. We partition the dataset by predicate, so each individual element can be regarded as a binary grid, and select three different datasets, \rdfs, \rdfm, and \rdfd, with significantly different number of points in the grid.
\end{itemize}

These datasets aim at testing the performance of our technique on a wide variety of real-world applications. The selection of GIS-based and RDF-based datasets also aims at providing insights on its relative performance depending on the sparsity of the data, which is a key element for our structure. Table~\ref{tab:datasets} describes the main characteristics of the studied datasets, including the grid size (all grids are square, of size ) and the number  of points in the grid.


\begin{table}
\centering

\begin{tabular}{ l | l | r r }
 File  & Type & Grid size () & Points () \\
 \hline
\dblp       & SN  &     986,324 &   6,707,236 \\
\enwiki     & SN  &   4,206,785 & 101,355,853 \\
\hline
\indo  & WEB &   7,414,866 & 194,109,311 \\
\uk         & WEB &  18,520,486 & 298,113,762 \\
\hline
\giss   & GIS &  67,108,864 &   9,335,371 \\
\gism      & GIS &   4,194,304 &   9,328,003 \\
\gisd    & GIS &     524,288 &   9,188,290 \\
\hline
\rdfs  & RDF &  66,973,084 &     138,303 \\
\rdfm   & RDF &  66,973,084 &   7,936,138 \\
\rdfd   & RDF &  66,973,084 &  98,714,022 \\
\hline
\end{tabular}
\caption{Description of the datasets used in our experiments}
\label{tab:datasets}
\end{table}

We compare our representation with the \kt \cite{BLN14}, the best known compressed quadtree representation, which has been shown to achieve very good compression on most of those domains, especially on Web graphs and RDF data. We use two different implementations of the \kt: \ktplain is a direct implementation of the structure, with all the bitmaps stored in plain form, and using  in all levels of the tree; \ktdac is an enhanced version that applies a number of improvements over the basic approach: it uses  in the first 6 levels of decomposition and  in the remaining levels; also, DACs are used to replace the last 3 levels of the tree by submatrices of size .

We also compare our representation with path-decomposed tries (\pdt) \cite{GO14}. We use two of the configurations proposed by the authors that provide a reasonable space-time tradeoff: the centroid hollow monotone-hash technique (\pdth) and the centroid compressed trie, where labels are compressed using RePair (\pdtrp). Note that \pdt is designed to represent string dictionaries, and only supports membership queries. In order to transform the point grids into collections of strings suitable for \pdt, we use the Morton code for each individual point in the collection and build the \pdt representation of the collection of Morton codes. Membership queries are directly translated into \pdt operations, but queries involving rows/columns or ranges are not specifically supported and are therefore transformed into a number of membership queries.

We test four different implementations of our proposal, \hpqt, considering two main variables. First, bitvectors  can be stored in plain form (\hpqtp) or compressed with the so-called RRR technique \cite{RRR} (\hpqtR). Second, we may use our basic implementation, with all  paths stored completely, or use the DAC-based compression of the submatrices in the lower levels. This compression leads to two further variants, \hpqtpdac and \hpqtRdac.

We implemented the \hpqt variants in C++, using LibCDS 2 \footnote{https://github.com/fclaude/libcds2} to provide the bitvector implementations used. Both \kt implementations are provided by the authors and implemented in C. PDT is implemented in C++, and obtained from the original author's repository\footnote{https://github.com/ot/path\_decomposed\_tries}. All implementations were compiled using GCC with full optimization enabled. Experiments were executed on a machine with Intel Xeon E5-2470@2.3GHz (8 cores) CPU, and 64GB of RAM. The operating system was Debian 9.8 (kernel 4.9.0-8-amd64).

\subsection{Space usage}

\begin{table}
\footnotesize
\centering
\begin{tabular}{ l | r r r | r r r  | r r}
 & & & & \multicolumn{3}{|c|}{} & \multicolumn{2}{c}{\pdt} \\
Dataset & \hpqtp & \hpqtR & \ktplain & \hpqtp & \hpqtR & \kt & hollow & RP \\
\hline
\dblp	& 11.62	& 9.23	& 10.76	& 10.08	& \textbf{8.88}	& 9.84 & \underline{9.00} & 25.43\\
\enwiki	& 17.56	& 13.49	& 16.96	& 15.01	& \underline{13.37}	& 14.66 & \textbf{9.11} & 31.07\\
\hline
\indo	& 3.29	& 2.92	& 2.57	& 1.28	& \underline{1.27}	& \textbf{1.22} & 7.51 & 16.10 \\
\uk	    & 4.04	& 3.73	& 3.30	& 2.08	& \textbf{2.02}	& \underline{2.04} & 7.99 & 17.04\\
\hline
\giss	& 44.19	& 29.66	& 44.01	& 38.32	& \underline{28.48}	& 38.02 & \textbf{8.23} & 51.15\\
\gism	& 30.61	& 21.28	& 30.10	& 25.42	& \underline{20.72}	& 24.83 & \textbf{8.22} & 40.64\\
\gisd	& 17.37	& \underline{13.05}	& 16.55	& 13.85	& 13.21	& 13.17 &\textbf{ 8.14} & 29.81 \\
\hline
\rdfs	& 45.01	& 30.35	& 45.69	& 39.81	& \underline{29.63}	& 46.98 & \textbf{11.06} & 57.36 \\
\rdfm	& 11.19	& 9.02	& 9.80	& 7.36	& \underline{7.09}	& \textbf{6.93} & 9.28 & 24.30 \\
\rdfd	& 31.94	& 22.22	& 31.61	& 27.28	& \underline{21.54}	& 26.93 & \textbf{9.31} & 43.42 \\
\hline
\end{tabular}
\caption{Space required by all implementations (in bits per point). We put in bold the best and underline the second best space for each dataset.}
\label{tab:space}
\end{table}

In this section we compare the compression performance of \hpqt with \kt variants. Table~\ref{tab:space} displays the compression obtained, in bits per point, in all the test datasets. Let us first focus on the comparison between \hpqt variants and the \kt. The results show that \hpqtR variants achieve better compression than the \kt in almost all the datasets. The \kt only obtains the best compression results in \indo and \rdfm, two datasets where the differences between representations are not very high in general. Plain versions, \hpqtp, are still slightly larger than the equivalent \kt, both with basic representations and with DAC. 

Let us compare the compression obtained by \pdt variants, displayed in the last two columns of Table~\ref{tab:space}. The space usage of \pdt follows patterns completely different from the other alternatives: \pdth is very consistent, using 8--10 bits per point in all the datasets, whereas \pdtrp requires much more space, ranging from 16 to 57 bits per point depending on the dataset. The consistency of \pdth makes it much more efficient than \hpqt to represent datasets with no clear regularities in the points, such as clustering. For instance, in the \giss dataset, \pdth is 3--5 times smaller than the \hpqt variants, and in \rdfs it is roughly 3--4 times smaller. However, in the Web graph datasets, \pdth is far from the compression offered by \hpqt or \kt variants, becoming 2--4 times larger than our proposal. Note that the space partitioning of \hpqt and \kt is expected to work well on sparse grids with clustered points, whereas \pdt does not explicitly consider any of this. 
 
 
Overall, the results show that \hpqt outperforms \kt in space in almost all cases, achieving good compression especially on Web graphs. Alternatives like \pdth, which do not exploit point regularities, outperform both \hpqt and \kt in space on datasets where the points are distributed more randomly, for example on GIS. We recall, however, that \pdt is not designed for representing point grids, as it does not support range queries. The next sections complement this analysis by testing the query performance of all these representations.

\subsection{Membership queries}

We now test the performance of our technique for membership queries, which check whether a given point exists in the grid or not. We test separately for empty and filled cells, and perform a third test on isolated filled cells. For each dataset and query type, we build a collection of 100,000 query points. For empty and filled cells we select these points at random, whereas for isolated cells we select the 100,000 points that are farthest away from their closest neighbor. We run each full query set 100 times in each dataset and measure the average.

Figure~\ref{fig:timesempty} displays the result of membership queries for empty cells on all the datasets. The datasets are grouped by family, and we describe the tendency of each method in the datasets of the same family using lines. One first general conclusion is that the  variants are smaller and faster than those representing all the nodes in bitvectors. In general, the best variants by far are always \hpqtpdac and \ktdac, the latter being always slightly smaller and almost always faster, by a smaller or a larger margin, with the exception of the dense GIS datasets. All \kt and \hpqt variants improve in general on sparser or more clustered point sets,  because isolated empty cells tend to be higher in the quadtree, but the \kt exploits this effect better because its search cost is directly proportional to the depth of the leaf sought. Our compressed variants, \hpqtR, are significantly slower than the plain ones, \hpqtp, and provide relevant space-time tradeoffs only on the sparser GIS and RDF datasets, where points distribute uniformly and then the  bitvectors tend to have about  bits per . In many cases \pdth offers very attractive space, though it is also significantly slower. The variant \pdtrp is never competitive.



\begin{figure}[t]
\begin{center}
\includegraphics[angle=-90,width=0.48\textwidth]{figures/with-pdt/cells/empty-SN.pdf}
\includegraphics[angle=-90,width=0.48\textwidth]{figures/with-pdt/cells/empty-WEB.pdf}
\includegraphics[angle=-90,width=0.48\textwidth]{figures/with-pdt/cells/empty-GIS.pdf}
\includegraphics[angle=-90,width=0.48\textwidth]{figures/with-pdt/cells/empty-RDF.pdf}
\end{center}
\caption{Query times of membership queries for empty cells. Times are in s/query. Datasets are grouped by family, and lines join the points on different datasets of the same family: SN includes, from left to right, \dblp--\enwiki; WEB includes \indo--\uk; GIS includes \gisd--\gism--\giss; RDF includes \rdfm--\rdfd--\rdfs.}
\label{fig:timesempty}
\end{figure}

\begin{figure}[t]
\begin{center}
\includegraphics[angle=-90,width=0.48\textwidth]{figures/with-pdt/cells/filled-SN.pdf}
\includegraphics[angle=-90,width=0.48\textwidth]{figures/with-pdt/cells/filled-WEB.pdf}
\includegraphics[angle=-90,width=0.48\textwidth]{figures/with-pdt/cells/filled-GIS.pdf}
\includegraphics[angle=-90,width=0.48\textwidth]{figures/with-pdt/cells/filled-RDF.pdf}
\end{center}
\caption{Query times of membership queries for filled cells. Times are in s/query.}
\label{fig:timesfilled}
\end{figure}

Figure~\ref{fig:timesfilled} displays the result for filled cells, following the same grouping of datasets used in Figure~\ref{fig:timesempty}. For these queries, \hpqtp and \hpqtpdac become clearly faster than the \kt variants, while using similar space. In the sparser GIS and RDF datasets, even the slow compressed variants, \hpqtR and \hpqtRdac, outperform the \kt both in space and time. On the other hand, \pdth and \pdtrp are also much more competitive, especially on the GIS and RDF datasets, where \pdth is still the smallest by far (except on \rdfm) but now its speed is much more competitive. In turn, \pdtrp is by far the fastest in many cases, though it is considerably larger in general. Note that the query times of \pdt do not change significantly with respect to Figure~\ref{fig:timesempty}, whereas accessing filled cells is much more expensive for \hpqt and especially for \kt, because filled leaves are always in the deepest level. 

\begin{figure}[t]
\begin{center}
\includegraphics[angle=-90,width=0.48\textwidth]{figures/with-pdt/cells/isolated-SN.pdf}
\includegraphics[angle=-90,width=0.48\textwidth]{figures/with-pdt/cells/isolated-WEB.pdf}
\includegraphics[angle=-90,width=0.48\textwidth]{figures/with-pdt/cells/isolated-GIS.pdf}
\includegraphics[angle=-90,width=0.48\textwidth]{figures/with-pdt/cells/isolated-RDF.pdf}
\end{center}
\caption{Query times of membership queries for isolated filled cells. Times are in s/query.}
\label{fig:timesisolated}
\end{figure}

Finally, Figure~\ref{fig:timesisolated} displays the query times for isolated filled cells, where our structure excels, becoming 2--3 times faster than for random filled cells. Now even the bitvector-compressed \hpqt variants are faster than the \kt. As in the previous cases, \pdth provides a competitive space-time tradeoff in some datasets, especially on the sparser RDFs, and \pdtrp is sometimes the fastest (though also the largest), but the margin is much narrower than before. 

\subsection{Range queries}

We now consider range queries, which ask for all the points in a defined window of the grid. 
For these experiments, we selected fixed square window sizes (4, 16, 64, 256, 1024), and for each window size and dataset we built sets of 1,000 random window queries.



\begin{figure}[t]
 \centering
     \includegraphics[angle=-90,width=0.49\textwidth]{figures/with-pdt/range/dblp}
    \includegraphics[angle=-90,width=0.49\textwidth]{figures/with-pdt/range/enwiki}
    \includegraphics[angle=-90,width=0.49\textwidth]{figures/with-pdt/range/indochina}
    \includegraphics[angle=-90,width=0.49\textwidth]{figures/with-pdt/range/uk}
    \caption{Query times for window queries, with varying window size, for SN (top) and WEB (bottom) datasets. Results are in s/query. Log-scale is used in both axis.}
  \label{fig:rangeSW}
\end{figure}

Figure~\ref{fig:rangeSW} displays the query times obtained on the social networks and Web graphs, with varying window size. In this type of queries, \hpqtp, \hpqtpdac, and \ktdac are always the fastest. On small windows, \hpqt is more efficient to reach the deepest node that contains the window, whereas on larger windows \ktdac takes over, generally by a small margin. Note that the bitvector-compressed variant \hpqtRdac is always competitive in time as well. Finally, note that \pdth and \pdtrp are orders of magnitude slower even on the smallest windows, because they do not support range queries and we must resort to individual searches of all the possible points in the query window. 



\begin{figure}[t!]
 \centering
    \includegraphics[angle=-90,width=0.49\textwidth]{figures/with-pdt/range/geo-sparse}
    \includegraphics[angle=-90,width=0.49\textwidth]{figures/with-pdt/range/rdf-sparse}
    \includegraphics[angle=-90,width=0.49\textwidth]{figures/with-pdt/range/geo-med}
    \includegraphics[angle=-90,width=0.49\textwidth]{figures/with-pdt/range/rdf-med}
    \includegraphics[angle=-90,width=0.49\textwidth]{figures/with-pdt/range/geo-dense}
    \includegraphics[angle=-90,width=0.49\textwidth]{figures/with-pdt/range/rdf-dense}
  \caption{Query times for window queries, with varying window size, for GIS (left) and RDF (right) datasets. Results are in s/query. Log-scale is used in both axis.}
  \label{fig:rangeGR}
\end{figure}

Figure~\ref{fig:rangeGR} displays the results on the GIS and RDF datasets, which are more difficult to compress. On those, \hpqtp and \hpqtpdac are the fastest in almost every case. The sparser datasets, displayed at the top, yield as expected the greatest difference in performance, with \hpqtp being 2--4 times faster than \ktdac. On the other hand, \hpqtR and \hpqtRdac are slower than \kt, but get very close. The \pdt variants are again much slower in all range queries.

We can conclude that the \hpqt is generally faster than the \kt at range queries, particularly for smaller windows. The \pdt structure is not competitive for these queries.



\no{
\begin{figure}[t!]
 \centering
     \includegraphics[angle=-90,width=0.40\textwidth]{figures/rows/rows-dblp}
    \includegraphics[angle=-90,width=0.4\textwidth]{figures/rows/rows-indochina}
    \includegraphics[angle=-90,width=0.4\textwidth]{figures/rows/rows-enwiki}
    \includegraphics[angle=-90,width=0.4\textwidth]{figures/rows/rows-uk}
    \includegraphics[angle=-90,width=0.4\textwidth]{figures/rows/rows-geo-sparse}
    \includegraphics[angle=-90,width=0.4\textwidth]{figures/rows/rows-rdf-sparse}
    \includegraphics[angle=-90,width=0.4\textwidth]{figures/rows/rows-geo-med}
    \includegraphics[angle=-90,width=0.4\textwidth]{figures/rows/rows-rdf-med}
    \includegraphics[angle=-90,width=0.4\textwidth]{figures/rows/rows-geo-dense}
    \includegraphics[angle=-90,width=0.4\textwidth]{figures/rows/rows-rdf-dense}
  \caption{Query times for row queries.}
  \label{fig:rows}
\end{figure}
}

Other kinds of queries, such as row/column queries (requesting all points in a row/column of the grid), are frequent when representing graphs. On those queries the \ktree is slightly faster in general, since the efficiency of the \hpqt to locate the submatrix enclosing the query window does not produce any advantage. 


\subsection{Higher dimensions}

Finally, we test the applicability of our proposal to higher dimensions. We compare \hpqt with an implementation of the \koct, the extension of the \kt to 3 dimensions. We used a set of datasets, \mdta, \mdtb, and \mdtc, which had previously been evaluated for the \koct~\cite{BCBNP20}. Those 3-dimensional grids are obtained from elevation rasters, by considering the value stored in the raster of values as the third dimension. Table~\ref{tab:spaceraster} shows their main characteristics. 

\begin{table}[t]
\centering
\begin{tabular}{ l | r r r | r r r}
Dataset & Grid size () & Points \\
\hline
\mdta   &    &  23,051,888  \\
\mdtb   &    &  15,662,092 \\
\mdtc   &    &  84,028,401  \\
\hline
\end{tabular}
\caption{Raster datasets used.}
\label{tab:spaceraster}
\end{table}

We will focus only on the variants including DAC compression (\hpqtpdac, \hpqtRdac, and \koctdac, the \koct with matrix vocabulary), because the \koctdac is the only available implementation of the \koct.

\begin{figure}[t]
 \centering
    \includegraphics[angle=-90,width=0.49\textwidth]{figures/raster/cells-mdt500}
    \includegraphics[angle=-90,width=0.49\textwidth]{figures/raster/cells-mdt700}
     \includegraphics[angle=-90,width=0.49\textwidth]{figures/raster/cells-mdtmed}
  \caption{Space and times of membership queries for filled cells. Times are in s/query.}
  \label{fig:rastermember}
\end{figure}

We first study compression and query performance for membership queries. For each dataset, we perform a membership query for each of the points it contains, and measure the average query time. Figure~\ref{fig:rastermember} displays the results obtained for all the datasets. The results are similar in all cases: \hpqtpdac and \hpqtRdac are slightly larger than \koctdac, but this difference is very small (less than 5\% for \hpqtpdac, and around 1\% for \hpqtRdac). On the other hand, both of our solutions are significantly faster than \koctdac: \hpqtpdac is about 2.5 times faster, and the compressed variant \hpqtRdac is still 25\% faster than \koctdac in all the datasets.

We now analyze the performance on range queries. For each dataset, we run sets of 100,000 random window queries, for different window sizes with the same side in all dimensions:  to . 

\begin{figure}[t]
 \centering
    \includegraphics[angle=-90,width=0.49\textwidth]{figures/raster/range-mdt500}
    \includegraphics[angle=-90,width=0.49\textwidth]{figures/raster/range-mdt700}
    \includegraphics[angle=-90,width=0.49\textwidth]{figures/raster/range-mdt700}
  \caption{Times of raster queries for varying window sizes. Times are in s/query. Log-scale is used in both axis.}
  \label{fig:rasterwindow}
\end{figure}

Figure~\ref{fig:rasterwindow} displays the query times on all the datasets, for varying window sizes. As on 2-dimensional data, \hpqt variants are faster for small query windows, and all the times become close on larger windows. In particular, \hpqtpdac is significantly faster than \koctdac in all cases for the smallest window sizes. The compressed variant, \hpqtRdac, is the slowest, but still close to \koctdac in all cases. 

Overall, we observe in general that the performance gap between \hpqt and \kt widens on three dimensions compared to the two-dimensional case, which is in line with our theoretical expectations.

\section{Conclusions}
\label{sec:conclusions}

We have introduced a fast space-efficient representation of quadtrees based on heavy-path decompositions, answering in the affirmative to the conjecture of Venkat and Mount~\cite{VM14}. Our structure represents a quadtree on  points in a grid of size  using  bits per quadtree node, and answers membership queries in  time. Other compressed quadtree representations \cite{BLN14,VM14}, instead, require  time, which can be significantly higher on sparse grids. We also prove that the space and time of our structure benefits from sparse and clustered point sets, which are common in various applications. Some, but not all, of those benefits extend to other quadtree representations as well.

We implemented our structure, demonstrating that it is also practical and competitive. The space requirements of our new representation are similar to other space-efficient representations of quadtrees, such as the -trees \cite{BLN14}, but our structure is typically faster at retrieving existing points, especially isolated ones. Our structure is also generally faster to handle range queries, and on higher dimensions. Previous structures, instead, are faster when querying large empty areas of the grid.

One future work direction is to explore how the heavy path decomposition can be used to speed up other more sophisticated queries, like approximate-range and nearest-neighbor searches, by exploiting its ability to efficiently arrive at a desired submatrix.

Another interesting future work challenge is to make our structure dynamic, enabling point insertions and deletions, as done for the \kt and variants \cite{VM14,BCPdBN17,AdBGN19}. Every point insertion requires, in principle, marking that a new node has now two children (i.e., flipping a bit in some bitvector ) and adding a new path to the representation, somewhere inside bitvector . Removing a point reverses this process. This can be supported in time  if we use dynamic bitvectors \cite{NS12}, which is also the blowup factor induced on the other operations. Other approaches, which do not affect query times, might be possible \cite{CFRdBLN20}.

\section*{Acknowledgements}

Partially funded by the European Union‚Äôs Horizon 2020 research and innovation programme under the Marie Sk{\l}odowska-Curie grant agreement No 690941. GdB and SL funded by  MCIN/AEI/10.13039/501100011033 [grants PID2020-114635RB-I00 (EXTRACompact), PID2019-105221RB-C41 (MAGIST)], by MCIN/AEI/ 10.13039/501100011033, ``NextGenerationEU/PRTR'' [grants PDC2021-120917-C21 (SIGTRANS), PDC2021-121239-C31 (FLATCITY-POC)], by GAIN/Xunta de Galicia [grant ED431C 2017/53 (GRC)], and also supported by the Centro de Investigaci√≥n de Galicia ``CITIC'', funded by Xunta de Galicia, FEDER Galicia 2014-2020 80\%, SXU 20\% [grant ED431G 2019/01 (CSI)].  TG funded by NSERC Discovery Grant RGPIN-07185-2020.  GN and DS funded by ANID -- Millennium Science Initiative Program -- Code ICN17\_002, Chile. GN funded by Fondecyt Grant 1-200038, Chile.


\begin{thebibliography}{10}
\expandafter\ifx\csname url\endcsname\relax
  \def\url#1{\texttt{#1}}\fi
\expandafter\ifx\csname urlprefix\endcsname\relax\def\urlprefix{URL }\fi
\expandafter\ifx\csname href\endcsname\relax
  \def\href#1#2{#2} \def\path#1{#1}\fi

\bibitem{Mor66}
G.~M. Morton, A computer oriented geodetic data base; and a new technique in
  file sequencing, Tech. rep., IBM Ltd. (1966).

\bibitem{Sam06}
H.~Samet, Foundations of Multidimensional and Metric Data Structures, Morgan
  Kaufmann, 2006.

\bibitem{Gar82}
I.~Gargantini, An effective way to represent quadtrees, Communications of the
  ACM 25 (1982) 905--910.

\bibitem{BLN14}
N.~Brisaboa, S.~Ladra, G.~Navarro, Compact representation of web graphs with
  extended functionality, Information Systems 39~(1) (2014) 152--174.

\bibitem{VM14}
P.~Venkat, D.~M. Mount, A succinct, dynamic data structure for proximity
  queries on point sets, in: Proc. 26th Canadian Conference on Computational
  Geometry (CCCG), 2014, p. article 32.

\bibitem{BCBNP20}
N.~R. Brisaboa, A.~Cerdeira-Pena, G.~de~Bernardo, G.~Navarro, O.~Pedreira,
  Extending general compact querieable representations to {GIS} applications,
  Information Sciences (2020) 196--216.

\bibitem{EGS08}
D.~Eppstein, M.~T. Goodrich, J.~Z. Sun, Skip quadtrees: Dynamic data structures
  for multidimensional point sets, International Journal of Computational
  Geometry and Applications 18~(1/2) (2008) 131--160.

\bibitem{GO14}
R.~Grossi, G.~Ottaviano, Fast compressed tries through path decompositions, ACM
  Journal of Experimental Algorithmics 19~(1).

\bibitem{Cla96}
D.~R. Clark, Compact {PAT} trees, Ph.D. thesis, University of Waterloo, Canada
  (1996).

\bibitem{Mun96}
J.~I. Munro, Tables, in: Proc. 16th Conference on Foundations of Software
  Technology and Theoretical Computer Science (FSTTCS), 1996, pp. 37--42.

\bibitem{WF90}
D.~S. Wise, J.~Franco, Costs of quadtree representation of nondense matrices,
  Journal of Parallel and Distributed Computing 9~(3) (1990) 282--296.

\bibitem{Kli71}
A.~Klinger, Patterns and search statistics, in: Optimizing Methods in
  Statistics, Academic Press, 1971, pp. 303--337.

\bibitem{HS79}
G.~M. Hunter, K.~Steiglitz, Operations on images using quad trees, IEEE
  Transactions on Pattern Analysis and Machine Intelligence 1~(2) (1979)
  145--153.

\bibitem{Nav16}
G.~Navarro, Compact Data Structures -- A practical approach, Cambridge
  University Press, 2016.

\bibitem{BLN13}
N.~Brisaboa, S.~Ladra, G.~Navarro, {DACs}: Bringing direct access to
  variable-length codes, Information Processing and Management 49~(1) (2013)
  392--404.

\bibitem{BDNR14}
N.~Bereczky, A.~Duch, K.~N{\'{e}}meth, S.~Roura, Quad-{K}-d trees, in: Proc.
  11th Latin American Symposium on Theoretical Informatics (LATIN), 2014, pp.
  743--754.

\bibitem{ST83}
D.~D. Sleator, R.~E. Tarjan, A data structure for dynamic trees, Journal of
  Computer and System Sciences 26~(3) (1983) 362--391.

\bibitem{FW94}
M.~L. Fredman, D.~E. Willard, Trans-dichotomous algorithms for minimum spanning
  trees and shortest paths, {Journal of Computer and System Sciences} 48~(3)
  (1994) 533--551.

\bibitem{PT06}
M.~P{\u{a}}tra\c{s}cu, M.~Thorup, Time-space trade-offs for predecessor search,
  in: Proc. 38th Annual ACM Symposium on Theory of Computing (STOC), 2006, pp.
  232--240.

\bibitem{OS07}
D.~Okanohara, K.~Sadakane, Practical entropy-compressed rank/select dictionary,
  in: Proc. 9th Workshop on Algorithm Engineering and Experiments (ALENEX),
  2007, pp. 60--70.

\bibitem{Knu09}
D.~E. Knuth, The Art of Computer Programming, volume 4: Fascicle 1: Bitwise
  Tricks \& Techniques; Binary Decision Diagrams, Addison-Wesley Professional,
  2009.

\bibitem{RRR}
R.~Raman, V.~Raman, S.~Rao, Succinct indexable dictionaries with applications
  to encoding \emph{k}-ary trees, prefix sums and multisets, {ACM} Transactions
  on Algorithms 3~(4) (2007) 43.

\bibitem{BoVWFI}
P.~Boldi, S.~Vigna, The {W}eb{G}raph framework {I}: {C}ompression techniques,
  in: Proc. 13th International World Wide Web Conference (WWW), 2004, pp.
  595--601.

\bibitem{BRSLLP}
P.~Boldi, M.~Rosa, M.~Santini, S.~Vigna, Layered label propagation: A
  multiresolution coordinate-free ordering for compressing social networks, in:
  Proc. 20th International Conference on World Wide Web (WWW), 2011, pp.
  587--596.

\bibitem{BCPdBN17}
N.~Brisaboa, A.~Cerdeira-Pena, G.~de~Bernardo, G.~Navarro, Compressed
  representation of dynamic binary relations with applications, Information
  Systems 69 (2017) 106--123.

\bibitem{AdBGN19}
D.~Arroyuelo, G.~de~Bernardo, T.~Gagie, G.~Navarro, Faster dynamic compressed
  -ary relations, in: Proc. 26th International Symposium on String
  Processing and Information Retrieval (SPIRE), 2019, pp. 419--433.

\bibitem{NS12}
G.~Navarro, K.~Sadakane, Fully-functional static and dynamic succinct trees,
  ACM Transactions on Algorithms 10~(3) (2014) article 16.

\bibitem{CFRdBLN20}
M.~Coimbra, A.~Francisco, L.~Russo, G.~de~Bernardo, S.~Ladra, G.~Navarro, On
  dynamic succinct graph representations, in: Proc. 30th Data Compression
  Conference (DCC), 2020, pp. 213--222.

\end{thebibliography}

\end{document}
