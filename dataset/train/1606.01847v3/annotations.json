[{'LEADERBOARD': {'Task': 'Visual Question Answering (VQA)', 'Dataset': 'COCO Visual Question Answering (VQA) real images 1.0 multiple choice', 'Metric': 'Percentage correct', 'Score': '70.1'}}, {'LEADERBOARD': {'Task': 'Visual Question Answering (VQA)', 'Dataset': 'VQA v2 test-dev', 'Metric': 'Accuracy', 'Score': '64.7'}}, {'LEADERBOARD': {'Task': 'Visual Question Answering (VQA)', 'Dataset': 'VQA v1 test-dev', 'Metric': 'Accuracy', 'Score': '64.2'}}, {'LEADERBOARD': {'Task': 'Visual Question Answering (VQA)', 'Dataset': 'COCO Visual Question Answering (VQA) real images 1.0 open ended', 'Metric': 'Percentage correct', 'Score': '66.5'}}, {'LEADERBOARD': {'Task': 'Visual Question Answering (VQA)', 'Dataset': 'Visual7W', 'Metric': 'Percentage correct', 'Score': '62.2'}}, {'LEADERBOARD': {'Task': 'Phrase Grounding', 'Dataset': 'ReferIt', 'Metric': 'Accuracy', 'Score': '28.91'}}, {'LEADERBOARD': {'Task': 'Phrase Grounding', 'Dataset': 'Flickr30k Entities Test', 'Metric': 'Accuracy', 'Score': '48.69'}}]
