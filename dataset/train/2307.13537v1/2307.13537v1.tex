\documentclass[10pt,twocolumn,letterpaper]{article}

\usepackage{iccv}
\usepackage{times}
\usepackage{epsfig}
\usepackage{graphicx}
\usepackage{amsmath}
\usepackage{amssymb}

\usepackage{booktabs}
\usepackage{multirow}
\usepackage{multicol}
\usepackage{colortbl}

\def\eg{\emph{e.g.}}
\def\ie{\emph{i.e.}}
\def\etc{\emph{etc}}
\def\vs{\emph{vs}}
\def\ourmethod{SgMg}
\usepackage[pagebackref=true,breaklinks=true,letterpaper=true,colorlinks,bookmarks=false]{hyperref}

\iccvfinalcopy 

\def\iccvPaperID{8733} \def\httilde{\mbox{\tt\raisebox{-.5ex}{\symbol{126}}}}

\ificcvfinal\pagestyle{empty}\fi

\begin{document}

\title{Spectrum-guided Multi-granularity Referring Video Object Segmentation}


\author{Bo Miao,~
Mohammed Bennamoun,~
Yongsheng Gao,~
Ajmal Mian
\
{\rm SA}(\mathcal{F},K) = \mathcal{F} + \Theta_{IFFT}({\rm Conv}(\sigma(K,\mathcal{F}) \odot \Theta_{FFT}(\mathcal{F})))
\label{equ:sa}

{\rm SCF}(\mathcal{F}_{w},\mathcal{F}_{v}) = {\rm SA}({\rm SA}(\mathcal{F}_{v})\otimes {\rm Att}({\rm SA}(\mathcal{F}_{v}), \mathcal{F}_{w}))
\label{equ:SCF}

{\rm CPK}(Q,\mathcal{F}_{vl}) = \Theta({\rm FC}({\rm Att}(Q, \mathcal{F}_{vl})))
\label{equ:cpk}

{\rm SF}(\mathcal{F}_{w},\mathcal{F}_{v})= \sum_{i=1}^{N} {\rm Att}(\mathcal{F}_{w}^{i},\mathcal{F}_{v})
\label{equ:mvlf1}

{\rm MIF}(\mathcal{F}_{w},\mathcal{F}_{v}) =  {\rm SA}({\rm SA}(\mathcal{F}_{v}) \otimes {\rm SF}(\mathcal{F}_{w},{\rm SA}(\mathcal{F}_{v})))
\label{equ:mvlf}
 \mathcal{J}  \mathcal{F}  \mathcal{J}  \mathcal{F}  \mathcal{J}  \mathcal{F}  \mathcal{J}  \mathcal{F} 
\mathcal{L}_{train} = \lambda_{\mathcal{M}_{P}}\mathcal{L}_{\mathcal{M}_{P}} +
\lambda_{\mathcal{M}_{O}}\mathcal{L}_{\mathcal{M}_{O}} +
\lambda_{\mathcal{B}}\mathcal{L}_{\mathcal{B}} +  \lambda_{\mathcal{S}}\mathcal{L}_{\mathcal{S}} 
\label{equ:losstrain}
 \mathcal{J}  \mathcal{F}  \mathcal{J}  \mathcal{F}  \mathcal{J}  \mathcal{F}  \mathcal{J}  \mathcal{F}  \mathcal{J}  \mathcal{F}  \mathcal{J}  \mathcal{F}  \mathcal{J}  \mathcal{F}  \mathcal{J}  \mathcal{F}  \mathcal{J}  \mathcal{F}  \mathcal{J}  \mathcal{F}  \mathcal{J}  \mathcal{F}  \mathcal{J}  \mathcal{F} 
\mathcal{L}_{match} = \lambda_{\mathcal{M}_{P}}\mathcal{L}_{\mathcal{M}_{P}} + \lambda_{\mathcal{B}}\mathcal{L}_{\mathcal{B}} +  \lambda_{\mathcal{S}}\mathcal{L}_{\mathcal{S}} 
\label{equ:lossmatch}
 \mathcal{J}  \mathcal{F}  & Para. Num. (M) \\
\midrule
SCF w/ Spatial Conv & 57.6  & 4.7 \\
SCF w/ Linear & 57.9  & 2.4 \\
SCF (Ours) & \textbf{58.9} & \textbf{2.4} \\
\bottomrule
\end{tabular}
\vspace{1mm}
\caption{Ablation of SCF with different operations.} 
\label{tab:fps}
\end{table}


\section{Additional t-SNE Visualizations}
To further demonstrate the presence of feature drift, we present additional t-SNE~\cite{tsne} visualizations in Fig.~\ref{fig:drift}. Specifically, we add the feature decoding process into the model, where the token embeddings of encoded features  are decoded using the decoder in~\cite{ReferFormer} to obtain  for all frames in each video. 
By visualizing these embeddings with t-SNE, we observe that the token embeddings of  and  are separated into two distinct clusters. 
This indicates that the decoding process results in feature drift.
However, the segmentation kernels struggle to perceive this drift during forward propagation since the kernels are predicted before the feature decoding.

\begin{figure}[h]
\centering
\includegraphics[width=0.9\columnwidth]{figs/drift.pdf}
\caption{t-SNE~\cite{tsne} visualization of the feature embeddings in different videos before (red cluster) and after (blue cluster) decoding.}
\label{fig:drift}
\end{figure}






\section{Additional Qualitative Results}

In Fig.~\ref{fig:SuppQualitative}, we present additional qualitative results that include occlusion, similar appearance, fast motion, and small objects.

\begin{figure}[h!]
\centering
\includegraphics[width=1\columnwidth]{figs/SuppQuantitative.pdf}
\caption{Additional qualitative results of \ourmethod{}.}
\label{fig:SuppQualitative}
\end{figure}



\end{document}