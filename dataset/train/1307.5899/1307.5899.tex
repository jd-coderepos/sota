\documentclass[10pt,conference,letterpaper]{IEEEtran}

\usepackage{mdwmath}
\usepackage{mdwtab}
\usepackage{eqparbox}
\usepackage{subfig}
\captionsetup[subfigure]{font=footnotesize,captionskip=2pt,nearskip=0pt}
\captionsetup[figure]{font=footnotesize}
\captionsetup[table]{font=footnotesize}
\captionsetup[lstlisting]{font=footnotesize}
\usepackage{bm}
\usepackage{fixltx2e}
\usepackage{url}
\usepackage{array}
\usepackage{algorithmic}
\usepackage[cmex10]{amsmath}
\usepackage{amsthm}
\usepackage{cite}
\usepackage[pdftex]{graphicx}
\usepackage{xspace}
\usepackage{color}
\definecolor{comment}{rgb}{0,0.75,0}
\definecolor{keyword}{rgb}{0,0,0.75}
\usepackage{listings}
\lstset{language=C++,basicstyle={\ttfamily\tiny},keywordstyle={\color{keyword}},commentstyle={\color{comment}},captionpos=b}
\usepackage{hyperref}
\usepackage{multirow}

\graphicspath{{figs/}}
\DeclareGraphicsExtensions{.pdf}

\newcommand{\todo}[1]{}
\newcommand{\oldtodo}[1]{{\bf \small \note{#1}}}
\newtheorem{definition}{Definition}
\newtheorem{theorem}{Theorem}
\newtheorem{theorem*}{Theorem}

\setlength{\marginparwidth}{0.5in}
\setlength{\marginparsep}{0.05in}
\newcommand{\notetext}[1]{\raggedright\tiny\sffamily\bfseries{#1}}
\newcommand{\sidenote}[1]{\ifinner \smash{\raggedright \hspace*{\textwidth}\hspace*{\marginparsep}\parbox[t]{\marginparwidth}{\notetext{#1}}}\
\label{eq:prob-cmiss}
  \acmr[\csize][\len] =
  \begin{cases}
        \frac{\len}{\csize} & \text{if } \\
        1 & \text{otherwise}
  \end{cases}

  \prob[d,h] = \frac{\nodeset[h-d]}{\nodeset[h]} = \frac{2^{h-d}-1}{2^h-1},
  \label{eq:edgewts}

  \PB(\csize) = \frac{1}{W} \sum_{ij \in E} \weight[ij] \acmr[\csize][{\len[ij]}]

  \label{eq:weightedsum}
  \acmr[\csize][\len] = \frac{\len}{\csize} \qquad (\len \leq \csize)

  \PB(\csize) = \frac{1}{W \csize} \sum_{ij \in E} \weight[ij] \len[ij]
              = \frac{\pwmean[1]}{\csize}
  \qquad (\len \leq \csize)
  \label{eqn:WLA}
1ex]\includegraphics[width=\columnwidth]{veb-tran-vs-bs}\hfill \includegraphics[width=\columnwidth]{veb-wcdf}\caption{
  Two locality measures for several layouts of a tree of height .
  Left: Block transitions \PB as a function block size (lower is better).
  Right: Cumulative distribution of edge weights as a function of edge length (higher is better).
}
\label{fig:bt-in-pre}
\end{figure*}

\subsection{In-order \HLs}

Consider the in-order \vEBl, denoted as \ivl, and obtained by
arranging all bottom subtrees in-order, and in the same relative order as that of their parent leaves . 
\comment{
wherein the top subtree lies in the middle of all the bottom subtrees.
following ordering of the subtrees, ordered consecutively in memory as .
When , we refer to this version as the in-order \vEBl, and 
which we denote as \ivl.
}
\comment{Observe that the bottom subtrees are not in boldface, since they are not going to be arranged in pre-order. We call the bottom subtrees  the left bottom subtrees, and others the right bottom subtrees}
In our nomenclature, \ivl is  (see \autoref{tbl:notation}).
\comment{After the top subtree has been completely ordered, consider the leftmost  parent leaves in , and choose their children to be the left bottom subtrees. Once we choose the left and the right bottom subtrees, similar to \pvl, we arrange the bottom subtrees in \ivl in the same order as the order of their parent leaves . (Later, in \autoref{sec:ivlpp}, we will see why this is the correct choice.) 
}
\autoref{fig:tree-vebi} illustrates \ivl for a tree of height . Observe that at each branch of the recursion, the top subtree is arranged in-order. For instance, the \nodes on the top three levels are ordered in the middle of the layout, from positions  to . 
To compare \ivl with the pre-order \vEBl that arranges all subtrees pre-order (\pvl), we consider the percentage of block transitions \PB.
\comment{
So far, we have considered two versions of the \vEBl, either all subtrees arranged in-order (\ivl), or all subtrees arranged pre-order (\pvl). 
}

\autoref{fig:bt-in-pre} plots \PB for \pvl and \ivl as a function of block size for a tree of height 20. We see that \ivl dominates \pvl for every block size. Interestingly, even at very large block sizes, \ivl is much better than \pvl, indicating that it reduces the weighted average edge length.  We have observed the same dominance for trees of other heights.
In fact, for large block sizes, \ivl compares well with \minwep, which we introduce later as the optimal cache-oblivious \RL for binary search trees. 
Looking at the weighted cumulative distribution, which measures the total weight of all edges up to a certain length, we see the same dominance. 
Again, we observe that \ivl is indistinguishable from \minwep for large edge lengths.

\note{Point out that similar results were observed for different block sizes and tree heights. Stated.}
\autoref{fig:veb} plots \PB for \ivl and \pvl as a function of tree height for a block size of , , and  \nodes. With -byte \nodes, a block size of  \nodes mimics a cache line size of 64 bytes. We see that \ivl dominates \pvl for all tree heights, but is dominated by \minwep. 
In our experiments, we observed similar results for other block sizes. 
\autoref{fig:veb} also illustrates the L1 and L2 cache miss rates for \ivl and \pvl. We observe the same dominance, and also that \minwep performs better than \ivl. Interestingly, \minwep results in even fewer L1 cache misses than the number of L2 cache misses for \pvl, suggesting that \minwep is a significantly better cache-oblivious layout than \pvl, the suggested layout in the literature. 

\note{Point out linearity of \pwmean[0] for \minwep? Not sure how to work this in.}
The true measure of any of these layouts is the average time taken to find any \node in the search tree (see \autoref{sec:setup} for more details on the experimental setup).
\comment{To measure this, we repeat the following experiment  million times for each layout: Choose a \node at random, and measure the time taken to search for it.
}
To ensure that the wall clock search time is not affected by the time taken to compute the position of a \node in the layout, we store two child ``pointers'' with each \node. For this reason, we also refer to the search time as explicit, or pointer-based, search time. Illustrated in \autoref{fig:veb}, we see the same behavior as before. \ivl is significantly better than \pvl, but is marginally worse than \minwep. On average, \minwep is about  better than \ivl and almost  better than \pvl. The sudden uptick at  is due to NUMA misses. Our experiments were run on a machine with two memory banks of ~GB each, and we need ~GB of RAM to store a tree of height , generating a lot of traffic across the NUMA memory banks.  The plots in \autoref{fig:veb} therefore indicate that the percentage of block transitions (\PB) correlates very well with cache-miss ratios, and is therefore a good indicator of the quality of a layout. In \autoref{sec:wep}, we mathematically derive a new locality measure, the \WEP \pwmean[0], which is independent of the block size \csize and correlates even better with these measures and performance metrics. In \autoref{fig:veb}, we see that \ivl has much lower \pwmean[0] values than \pvl, but not as low as \minwep.

\begin{figure*}[tp]
\centering \includegraphics[height=9pt]{veb-legend}\2ex]\includegraphics[width=\columnwidth]{veb-transitions}\hfill \includegraphics[width=\columnwidth]{veb-acmr}\\\caption{
  Clockwise from top left:
  weighted edge length product \pwmean[0];
  wall clock search time;
  L1 and L2 cache miss rate;
  and block transitions for blocks of  \nodes
  as a function of tree height for several hierarchical layouts.
}\label{fig:veb}\end{figure*}

\comment{
Before we prove this for certain tree heights, we need to define the notion of a {\it level of detail}, as in \cite{Bender05}. Each level of detail is a partition of the tree into disjoint subtrees. In the finest level of detail, , each \node forms its own subtree. In the coarsest level of detail, \CEIL{\log_2 h}, the entire tree forms the unique subtree.
\note{Only if  is a power of two? Not really, works for any .}
Level of detail  is derived by starting with the entire tree, recursively partitioning it, exiting a branch of the recursion upon reaching a subtree of height less than or equal to .
The key property of any \HL is that, at any level of detail, each subtree is stored in a contiguous block of memory. 
Observe that when the height of the tree is a power of , and all subtrees are partitioned exactly in the middle (), then all subtrees at level of detail  are exactly of height . 
\note{Above LOD  was defined to be a tree of height 1.  Do you mean height ?. Yes, fixed.}
For every level of detail , consider all the edges that connect the disjoint subtrees. Let this set be . This set is the same for any \HL with cut height . For a particular layout, let the \emph{tree distance} (measured in terms of number of disjoint subtrees spanned) of edge  be .  In other words, we treat each contiguous subtree of height  as a single \node in a coarser tree of height .

The weighted cumulative distribution in \autoref{fig:veb}, suggests that \ivl strongly dominates \pvl. 
To substantiate this, we state the following result. 
We delegate this and all subsequent proofs to 
the Appendix.
\begin{theorem}
\label{thm:in-pre-edgelen}
Consider a tree of height , where  is a power of , and a level of detail . For any edge , the tree distance  (measured as described above) for \ivl is no larger than the tree distance for \pvl.
\end{theorem}

\subsection{Properties of the in-order \vEBl}
\label{sec:ivlpp}

Given that \ivl is strictly better than \pvl, we study \ivl in detail, and ask whether \ivl can be improved even further.

We prove our results within the context of \HLs, which is essentially a framework of hierarchical 
decomposition into disjoint contiguous subtrees. 
One way to prove that one layout is better than another is to show that all tree distances decrease or remain the same for a given level of detail. First, we prove the choice of which bottom subtrees to place on either side of the top subtree  in an \ivl layout. 
}

\comment{
Consider two leaves  and  of the top subtree. Let  and  be bottom subtrees whose parents are
 and , respectively.  We will use  to mean
;  implies
; and  implies
.  Without loss of generality,
assume .

Consider the case in which two bottom subtrees  and  appear
on either sides of the top subtree  containing  and .
\begin{theorem}
Let  and  be leaves in the top subtree  with 
child subtrees  and , respectively.  If , then for
any ordering with  there exists an ordering 
with smaller tree distances.
\label{thm:subtree-in-order}
\end{theorem}


\begin{theorem}
Given any in-order subtree in a \HL and an internal ordering of the leaves of its top subtree , the sum of the tree distances for all edges at a particular level of detail is reduced by arranging all the children of the left half of the parent leaves as the left bottom subtrees, and the rest as the right bottom subtrees.
\label{thm:subtree-in-order}
\end{theorem}
}

\comment{
As a corollary of \autoref{thm:subtree-in-order}, we see that the optimal division of the bottom subtrees into the left and right bottom subtrees is completely determined by the order of the leaves  of the top subtree.
 has an odd number of leaves only when , \ie when  is a single \node. In this case, the two bottom subtrees are ordered on either side of . 
We have not yet determined what the optimal ordering of the bottom subtrees is for each of these sets (left and right) -- we have prescribed it to be in the order of the leaves. In \autoref{sec:alternate}, we return to this issue, and present an ordering that improves \ivl.
\sidenote{Try to get next section to start at top of page.}
\clearpage
}



\section{A Cache-Oblivious Locality Measure}
\label{sec:wep}

\todo{
Mathematical justification for edge-product. Simplify the general writeup to trees.
Define metric, justify metric. 
Review literature on other ``linear ordering metrics''. 

Memory transfer bounds: 
Do they depend on layout?
Do they depend on cut height?

Questions: Should all BSTs be inorder? Further we go from TST, inorder seems better. 
Restricting to in/pre.
Before we study further, try to understand the edge product measure.
}

We have seen how the percentage of block transitions provides a
quality measure for a layout given a particular cache block size \csize.
We now remove this dependence on block size and derive a simple
measure of locality for graph orderings in a
cache-oblivious sense, \ie with no knowledge of cache and line size.
Continuing the discussion in
\autoref{sec:blocktrans},
we here generalize the measure presented in~\cite{Yoon06} to
weighted graphs.



\C{
As
in~\cite{Yoon05,Yoon06,Tchiboukdjian10}, we model data elements as
vertices  in a graph , with an undirected edge
indicating a nonzero likelihood that its two vertices be accessed in
succession, or more generally a desire to store those two vertices close
together in memory.  We call such a graph an \emph{affinity graph}.

The affinity between  and  may be expressed in terms of a
weight .  Let  denote the
matrix of affinities, such that  if 
and  otherwise. 
 We model data accesses as a Markov
chain random walk on  with transition matrix ,
where  is the diagonal matrix with .
If  is strongly connected,\footnote{Because each component of a
graph may be laid out independently, we assume that  is strongly
connected.}
then it is well-known that the probability 
of being in state  and transitioning to state  equals
, where .
In other words, the probability of accessing two data elements in
succession is proportional to the weight of the edge connecting them.

Consider a cache consisting of a single block that can hold \csize
data elements and is backed by a larger memory consisting of several
such blocks.  (In practice caches tend to hold more than one block,
but that would unnecessarily complicate our derivation.)
Let  and  be data elements stored at  and
 in blocks  and , respectively, and separated by
 on linear storage.  Without loss of
generality, assume .  Suppose  is accessed
first, bringing  into the cache.  We wish to estimate the
probability of a cache miss when  is accessed.  Clearly, if
, then a cache miss is inevitable, since then
.  When , the likelihood of a cache miss
depends on the position of  within , \ie where the upper
boundary of  lies with respect to .
In absence of further information, we will assume that the position
of  within  is distributed uniformly.\footnote{Even in
practice, modern operating systems allocate memory blocks with
nearly arbitrary alignment.}
Hence, there are  out of  possible alignments
that partition  and  into separate blocks, and the
probability of a cache miss occurring when  is accessed is

}

The observation underlying our cache-oblivious measure is that most block-based caches 
employed in current computer architectures are hierarchical and
nested, with a roughly geometric progression in
size.
\C{
\footnote{For instance, the memory hierarchy for the computer
used in this paper consists of
 L1 cache,
 L2 cache,
 L3 cache, 
 of RAM, and
 of disk.}
}
That is, we may write  for some base  (usually )
and positive integer . 
We then estimate the total
number of cache misses for all  for a particular edge length \len as

We note that when \len is an exact power of ,  simplifies
to ; otherwise  increases
monotonically with .  Our primary goal is not to estimate the
exact number of cache misses incurred, but rather to assign a relative ``cost''
as a function of edge length \len.  We may thus ignore the value of  (since
it affects only the slope of ) and the constant term independent of
, and arrive at the approximation

Intuitively,  measures the number of blocks smaller than \len[ij] that cannot hold both  and , and thus captures the expected number of block transitions and cache misses
associated with \len[ij] in a memory hierarchy.
\comment{
The quality of this approximation is quite good,
as evidenced by
\autoref{fig:acmr-vs-log}.

\begin{figure}[tp]
\centering \subfloat[]{\includegraphics[width=0.48\linewidth]{figs/acmr}\label{fig:acmr-vs-len}}\hfill \subfloat[]{\includegraphics[width=0.48\linewidth]{figs/acmr-vs-log}\label{fig:acmr-vs-log}}\caption{
  (a)~The cache miss ratio \acmr[\csize] as a function of edge length is linear
  up to the cache block size \csize.
  (b)~The \emph{average cache miss ratio} () is a measure of the expected
  number of cache misses across a memory hierarchy.  This plot shows that
  the \acmr associated with accessing two data elements is strongly
  correlated with the logarithm of the distance \len between the elements.
}
\label{fig:acmr-vs-lenlog}
\end{figure}
}

Finally, if we consider all edges  of an affinity graph, then

gives the \emph{average cache miss ratio},
where  denotes the \emph{weighted edge product} functional

for a weighted graph.  
In other words, .  As a result, low values of
\pwmean[0] imply good cache utilization across the whole memory hierarchy.  As we shall see, this
expected behavior is observed also in practice, with layouts optimized
for \pwmean[0] having excellent locality properties.
(In the unweighted case,  and . We denote the unweighted version of \pwmean[0] by \pmean[0].)
\comment{
As discussed in \autoref{sec:blocktrans}, the weights \weight[ij] are
given 
by the likelihood of visiting in succession \nodes  and  at
levels  and , respectively,
\ie 
by the likelihood of
searching for  or one of its descendants.
}
We call the \RL that minimizes \pwmean[0] for
geometrically decreasing weights (as described in \autoref{sec:blocktrans})
the \minwep
(short for minimum weighted edge product) layout of the tree.
\comment{
This name derives from the fact that when , the
optimal layout minimizes the (unweighted) product of edge lengths.
}


\note{Point out why  is the right thing---a reduction at short
lengths matters more than the same at long lengths, as long edges are already
out of cache. Done.}
 
\subsection{Other edge-based locality measures}

It is important to mention two other locality measures that
have been considered in the literature: the average edge
length, \pmean[1], and the maximum edge length, \pmean[\infty].
The small example in \autoref{fig:tree-layouts} 
includes the layouts \minla~\cite{Chung:MinLA} in
\autoref{fig:tree-minla}, which minimizes \pmean[1], and
\minbw~\cite{Heckmann:MinBW} in \autoref{fig:tree-minbw}, which
minimizes \pmean[\infty].  
Similar to \pwmean[0], which measures the weighted edge
length product, we may define the average weighted edge length \pwmean[1].
This figure also presents 
these four statistics
(\pwmean[0], \pwmean[1], \pmean[1], \pmean[\infty]) for 
all layouts discussed in this paper. 
From the discussion in \autoref{sec:blocktrans}, we observe that the
probability of a block transition for very large block sizes is given
by \pwmean[1], \ie, a weighted version of \pmean[1]. 

Based on an empirical study, we conjecture that among all \RLs \pwmean[1] is minimized by \minwla, the layout that
cuts at height , arranges the outermost top subtree in-order, and
arranges every subsequent subtree pre-order.
In our nomenclature, \minwla is  (see \autoref{tbl:notation}).
Restricting ourselves to \RLs with cut height , \minwla provably minimizes \pwmean[1].
We delegate all proofs to the 
Appendix.
\begin{theorem}
\label{thm:minwla}
The \minwla layout minimizes \pwmean[1] among all \RLs with cut height .
\end{theorem}

Our experiments on block transitions
(\autoref{fig:min-transitions}), observed cache misses, and timings
indicate that these other layouts have significantly
worse locality than \minwep, lending support to our claim that
the weighted edge product (represented by \pwmean[0]) is the correct
measure to consider. 

In this paper, we present a succession of \HLs that reduce \pwmean[0],
and we see that these also tend to reduce \pwmean[1], \pmean[1], and
\pmean[\infty], suggesting that these might be good layouts in other
settings that benefit from better locality. 
\note{In fact, \cite{Safro11} minimizes \pwmean[0]. Added sentences.}
In \cite{Safro11}, the authors show that minimizing \pwmean[0]
results in compression-friendly layouts.
We note that minimizing \pwmean[0] is likely to result in high locality layouts 
for all graphs, and not just trees. 
For algorithms designed to minimize
\note{Have we defined \pmean[0]? Defined earlier.}
\pmean[0], \pwmean[0], \pmean[1], and \pmean[\infty], respectively, on general graphs,
see~\cite{Yoon06}, \cite{Safro11}, \cite{Safro09}, and \cite{Cuthill:minbw}.

\begin{figure}[tp]
\centering \includegraphics[width=\columnwidth]{min-transitions}\caption{
  Block transitions for  for the layouts
  that minimize
  \pmean[\infty] (\textsc{BW}),
  \pmean[1] (\textsc{LA}),
  \pwmean[1] (\textsc{WLA}),
  \pwmean[0] (\textsc{WEP}).
}\label{fig:min-transitions}\end{figure}

 
\section{Minimizing the Weighted Edge Product}
\label{sec:minwep}

\todo{

Experical claims:
First should be pre-order.
Second may be neighter, for lowest cost. Choose In for all the rest.

Present our grammar, that generalizes vEB layouts.

Experiments: block transitions, WEP cost.
Improvement in MinWEP.
Improvement in Block transitions.

Other interesting properties - Mean Edge distance.

Implementation issues: Implicit/explicit calculations.

Is this optimal? No. Neither in/pre may be the best. But we restrict to them. 
}

We have shown that layouts wth lower \WEP \pwmean[0] result in fewer block transitions (measured by \PB). So far, we have presented \ivl, with lower \pwmean[0] values than \pvl. 
\comment{
In the example presented in \autoref{fig:tree-layouts}, we see that \pwmean[0] for \ivl () is smaller than that of \pvl (). 
}
\comment{A natural question to ask is: Is \ivl the best possible layout? }
\autoref{sec:alternate} shows that \pwmean[0] can be further reduced by \emph{alternating layouts}. 
\comment{In the rest of this paper, we introduce new \HLs that result in even lower \WEP.}
Ultimately, the goal is to find the \HL that minimizes \pwmean[0] -- the \minwep layout. 

\subsection{Ordering the subtrees: Alternating \HLs}
\label{sec:alternate}

\note{Should this not go in the section on minimizing \WEP?. Yes, moved there.}

In the discussion so far, we have not yet determined the optimal relative ordering of the bottom subtrees -- we have prescribed it to be in the order of the top subtree leaves. A simple way to reduce \pwmean[0] is to reduce the product of edge lengths among all edges that have 
the same weight, without modifying the lengths of all other edges.
\note{But alternating does change the sum of lengths, only the product. So what do we mean by reducing edge lengths? Fixed.}
If we consider the \HL at a particular branch of the recursion, all the edges between the top subtree and the bottom subtrees have the same weight.
By considering such equal-weight edges, the next result proves that a layout that orders the bottom subtrees in the reverse order of the parent leaves reduces \pwmean[0]. In such a layout,
the order of the \nodes appears to alternate between left-to-right and right-to-left. As a result, we refer to \HLs that arrange the bottom subtrees in the reverse order of the parent leaves as \textit{alternating} \HLs.
\comment{
Observe that one must cut and order the top subtree completely before ordering the bottom subtrees at each branch of the recursion. 
}
\comment{
As a consequence, \autoref{thm:in-pre-edgelen} proves that \ivl has a lower weighted edge product than \pvl, which manifests itself in lower \PB and better cache-oblivious layouts. 
}

\begin{theorem}
For any subtree in a particular branch of the recursion, suppose we fix the internal ordering of the leaves of the top subtree  and the arrangement of all the bottom subtrees in subsequent branches of the recursion. Then, the product of all the edge lengths between the top subtree and the bottom subtrees is minimized by ordering the bottom subtrees in reverse order of that of the parent leaves .
\label{thm:subtree-pre-order}
\end{theorem}

As a corollary of \autoref{thm:subtree-pre-order}, we see that when the cut height , the optimal relative ordering of bottom subtrees is one that positions both the bottom subtrees of a particular parent leaf in  adjacent to each other.
\note{This is not true when  and the root is in-order. Yes, fixed.}
This suggests that the initial orderings (\pvl and \ivl) got the adjacency of the bottom subtrees right -- they only had the order wrong.

By recursive application of \autoref{thm:subtree-pre-order}, we order the bottom subtrees in the reverse ordering of the parent leaves  at each level of recursion, converting any \HL to its alternating version, thus reducing \pwmean[0].
\comment{
When we do this, the leaves of the tree appear to be alternating in order -- left-to-right at one level and right-to-left at the next -- explaining why we call such layouts alternating. Observe that this technique can be applied to any \HL, and the alternating version of any \HL reduces the \WEP. We denote the alternating version of any \HL by appending the letter \textsc{a}. In particular, we can define the alternating version of \ivl as the layout that arranges the bottom subtrees at each branch of the recursion in the reverse order of the parent leaves  ---
}
We denote the alternating version of \ivl by \ivla, and define \pvla similarly. In our nomenclature, these two layouts are  and , respectively (see \autoref{tbl:notation}).

\autoref{fig:tree-vebia} illustrates \ivla for a tree of height . 
Observe that the bottom subtrees are arranged in reverse order of their parent leaves.
In the outermost branch of the recursion, the rightmost two leaves in the top subtree are arranged at positions  and , and the corresponding child subtrees are rooted at positions , , , and . 
That is, the child subtrees are arranged in reverse order of the parent leaves ( and  connected to ), compared to 
\ivl (see \autoref{fig:tree-vebi}, where  and  are connected to ).
We see that by alternating, the sum of edge lengths between top and bottom subtrees remains the same, but we have increased their variance, thus reducing their product and consequently \pwmean[0].
A similar argument holds for alternating pre-order trees (see \autoref{fig:tree-veboa} and \autoref{fig:tree-vebo}).

\comment{
\autoref{fig:tree-veboa} illustrates \pvla for a tree of height .
Observe that the bottom subtrees are arranged in reverse order of their parent leaves.
In the outermost branch of the recursion, the four leaves in the top subtree are arranged at positions , , , and , and the corresponding child subtrees are rooted at positions . Compare this with \pvl (see \autoref{fig:tree-vebo}) where these child subtrees are arranged in the same order as the parent leaves.
As in the previous comparison, we notice that the \pwmean[1], which measures the weighted sum of edge lengths, has not changed. However, the \WEP has been reduced. 
\note{The number of unit-length edges *does* increase in \pvla. Added.}
}

It is important to mention that \textit{alternating} a particular layout has no effect on \pwmean[1]. However, since the variance of the edge lengths is increased, alternating a layout will increase \pmean[\infty], and may increase the number of unit-length edges. Since \pwmean[0] is a function of the product of the edge lengths, the \WEP is reduced. As an example, we can see the effect of alternating a layout on \pwmean[0], \pwmean[1], and \pmean[\infty]
by comparing \ivla (\autoref{fig:tree-vebia}) and \ivl (\autoref{fig:tree-vebi}). 
\note{See what? Fixed.}
 
\autoref{fig:veb} shows that \pvla has smaller \pwmean[0] values than \pvl, but this improvement is not as drastic as the improvement from \pvl to \ivl. A natural question to ask is: Does an ordering that reduces \pwmean[0] result in better cache-oblivious layouts? And if so, do we get a greater improvement from \pvl to \ivl, as predicted by the \pwmean[0] values? We first look to block transition percentages (\PB) to show that alternating layouts are better.
\autoref{fig:bt-in-pre} plots \PB for \pvla and \ivla as a function of block size for a tree of height 20. We see that \ivla is virtually indistinguishable from \ivl, whereas \pvla dominates \pvl for small block sizes. 
\autoref{fig:veb} also plots \PB for \pvla and \ivla as a function of tree height for a variety of block sizes. 
\comment{for these block sizes, }
Again, 
we see that \ivla is virtually indistinguishable from \ivl, but \pvla dominates \pvl for all tree heights. And we see the same pattern with cache miss rate. \autoref{fig:veb} also plots the explicit search time for \ivla and \pvla. Comparing with \ivl and \pvl, we see the exact same pattern. \ivl and \ivla are indistinguishable from each other, with approximately  worse explicit search times than \minwep. On the other hand, \pvla is about  better than \pvl. 

From these experiments, we see that the improvement from \pvl to \pvla is far less than the improvement from \pvl to \ivl. This suggests that while an alternating version always improves the layout
(we restrict our attention to alternating layouts for the rest of this paper), it is far more important to switch from pre-order to in-order. One should consider this the main take-home message of this paper: All data structures that use a pre-order \HL should, at the very least, switch to an in-order version of the same \HL. Later, in \autoref{sec:cut-hts}, we will see that this result may depend on the cut height, but not for the cut heights  that have been used in practice. 

\subsection{Constructing hybrid layouts: The \halfwep layout} 

\comment{A more critical question remains: What should be the position of}
We now analyze the impact of varying the position of the top subtree  relative to all the bottom subtrees.
\RLs restrict us to the two extremes represented by \pvla and \ivla, wherein  is positioned either at one end or in the middle of all the bottom subtrees. However, \ivla and \pvla arrange \textbf{all} bottom subtrees identically, 
either in-order or pre-order, respectively. 
\note{We need to make it clear that pre-order means both pre- and post-order depending on context. Added text in the definition pf \HLs.}
We can consider many more permutations by ordering some of the bottom subtrees in-order and others pre-order. As before, 
the locality measure \pwmean[0] guides us in these decisions. Clearly, \ivla results in smaller \pwmean[0] than \pvla. 
Can a hybrid layout (by modifying \ivla, possibly) reduce \pwmean[0] even further? 

To construct a hybrid layout, we must take into account the trade-offs involved. First, observe that any bottom subtree is arranged in a contiguous block in memory, and has only one edge connecting it to the rest of the tree -- the edge from its root to a leaf in the top subtree. Therefore, rearranging any bottom subtree potentially results in two changes to its contribution to \pwmean[0]: the length of the edge connecting its root to its parent, and the lengths of the edges in the subtree itself. Discounting the connection to the top subtree, a bottom subtree ordered as in \pvla has a larger \WEP than when it is ordered as in \ivla. However, the root of a pre-order bottom subtree is closer to its parent than the root of an in-order bottom subtree, and the weight of this edge is larger than the weight of any edge within the bottom subtree. So there are potential benefits to modifying \ivla by arranging some of the bottom subtrees pre-order. This nevertheless raises the question: Which bottom subtrees should we modify, if any? Also, observe that the in-order bottom subtrees are identical, and differ only in their distance to their parent leaf in the top subtree, and similarly for the pre-order trees.
As we move further away from the top subtree, the proportional reduction in the length \len of the edge connecting the subtrees decreases (\ie the slope of  approaches zero), whereas the degradation in the \pwmean[0] value of the bottom subtree remains the same. As a result,
the marginal benefit of converting an in-order bottom subtree into a pre-order bottom subtree decreases. Therefore, if arranging any bottom subtree in-order results in lower \pwmean[0] than arranging it pre-order, then this must also be true for all bottom subtrees further away from the top subtree.

\note{Do we need to discuss dynamic trees (insertions/deletions) or incomplete trees? I don't think we need to, since we refer to Bender's papers that present dynamic search trees. And it is not the scope of this paper anyway.}
To find the best layout, we undertook a detailed empirical study that evaluated all \RLs for trees up to height .
We considered all possible cut heights  (we quickly determined that larger  were not beneficial). We calculated \pwmean[0] for every
layout 
for each tree height. We noticed that the optimal ordering always
arranged the bottom subtrees closest to the top subtree pre-order, arranged all other bottom subtrees in-order, and used an in-order arrangement for the outermost branch of the recursion. In comparison, \ivla arranges all bottom subtrees in-order, and \pvla arranges all of them pre-order. We give the version of this layout with cut height  the special name \halfwep. In our nomenclature, \halfwep is  (see \autoref{tbl:notation}).

\autoref{fig:cut} shows that \halfwep and \minwep have almost indistinguishable values of \pwmean[0] and performance in explicit search times, further validating \pwmean[0] as the appropriate locality measure for deriving cache-oblivious layouts. 

\autoref{fig:tree-halfwep} illustrates \halfwep for a tree of height . Observe that the bottom subtrees closest to the top subtree are arranged pre-order. 
\comment{are the closest to the top subtree }
At the outermost branch of the recursion, the subtrees rooted at positions  and  
are arranged pre-order in \halfwep. These are arranged in-order in \ivla (see \autoref{fig:tree-vebia}). From the thickness of the edges, one can see that \halfwep reduces some edge lengths for every branch of the recursion by replacing some in-order bottom subtrees by pre-order bottom subtrees. This does increase some distances within the bottom subtree (the next recursive branch), but deeper down the tree, where they contribute less to the \WEP. This is confirmed by the \pwmean[0] values for \halfwep () and \ivla ().

\note{Need to talk about \halfwep and \minwep almost identical. Done.}

\comment{
We believe that if we restrict ourselves to \HLs with cut height ,
then \halfwep minimizes \pwmean[0]. This is a conjecture, based on some theoretical results and empirical observations. Empirically, based on experiments on trees up to a height of , we observed that this is true.
}
\note{We did? No. Changed sentence accordingly.}
Our empirical analysis is also backed by theory, when restricted to certain cut heights. In \autoref{thm:order}, we show that when the cuts are made at the top of the tree () at all branches of the recursion, this \halfwep-like layout provably minimizes \pwmean[0]. 
\comment{
In this layout, a pre-order subtree is ordered as
, and an in-order subtree is ordered as .}
We refer to this layout as the \minep layout, because it also minimizes the edge product \pmean[0] for unweighted trees.
In our nomenclature, \minep is  (see \autoref{tbl:notation}).

\begin{theorem}
\label{thm:order}
The \minep layout minimizes \pwmean[0] among all \RLs with cut height .
\end{theorem}
 
\begin{figure*}[tp]
\centering \includegraphics[height=7.5pt]{cut-legend}\2ex]\includegraphics[width=\columnwidth]{cut-scan}\hfill \includegraphics[width=\columnwidth]{cut-implicit}\\\caption{
  Clockwise from top left:
  weighted edge length product \pwmean[0];
  pointer-based search time;
  pointer-less search time;
  and pointer-less search time excluding all memory accesses
  as a function of tree height for several layouts.
}\label{fig:cut}\end{figure*}

It can also be shown that for all \HLs where the closest bottom subtree is arranged pre-order, cutting a subtree that is arranged in-order at  results in the same layout as cutting it at . This is because cutting an in-order subtree of height  at height  results in two pre-order subtrees of height , the roots of which are adjacent to the top subtree, so long as the closest bottom subtree in either case is arranged pre-order. 
\comment{
This is equivalent to cutting the top subtree at height , 
}
This explains why, for trees of small height, such as the example with  considered in \autoref{fig:tree-layouts}, \minep is identical to \minwep (see \autoref{fig:tree-minwep}).

\subsection{Optimizing the cut height: The \minwep layout}
\label{sec:cut-hts}

In the discussion so far, we have ignored the effect of the cut height by restricting ourselves to the case where . Before we find the optimal cut height, we describe other layouts that turn out to be part of the \HL framework, albeit with extreme cut height values.

Consider cut height . Analogous to how \halfwep is a hybrid of \ivla and \pvla, one can think of \minep as a hybrid of two other simple layouts: the common \inorder and \preorder depth-first layouts. All three are \HLs that cut every subtree at height , but differ in how the bottom subtrees are arranged. \inorder arranges all subtrees in-order, and \preorder arranges all subtrees pre-order. In our nomenclature, \inorder is  and \preorder is  (see \autoref{tbl:notation}).
Observe that when the cut height , there is only one leaf \node in  at every branch of the recursion, and therefore the notion of alternating layouts is not relevant. Furthermore, there are only  bottom subtrees at each branch of the recursion, and therefore in-order and pre-order are the only two options for positioning the top subtree. 
\comment{Due to this restriction, }
As a result, all \HLs that are described using cut height  at all branches of the recursion are in fact \RLs. This is not true for other cut heights.

\autoref{fig:tree-inorder} illustrates \inorder for a tree of height . Observe that \inorder arranges the two bottom subtrees at the outermost recursion in-order, resulting in their roots being placed at positions  and . These roots are arranged pre-order at positions  and  in \minep (see \autoref{fig:tree-minep}). On the other hand, \preorder (see \autoref{fig:tree-preorder}) arranges all subtrees pre-order. The roots of the same bottom subtrees are arranged pre-order at positions  and . 
Observe that \inorder and \preorder have (nearly exactly) the same number of short edge lengths (counting the number of thick lines), but these are at the bottom of the tree for in-order, where the weights are much smaller. This results in much larger \pwmean[0] values for \inorder (), when compared to \preorder ().

At the other end of the spectrum in terms of cut height is , where each subtree is cut one level above the bottom. 
It turns out that the \HL with  that arranges all subtrees pre-order (similar to \pvl with cut height ) is the simple and commonly used breadth-first order. For this reason, we denote the breadth-first layout as \prebreadth. \autoref{fig:tree-breadth} illustrates the \prebreadth layout for a tree of height . Observe that the \nodes are arranged by level. Furthermore, one can now also consider in-order and/or alternating variants on the breadth-first ordering. We denote the in-order variant by \inbreadth. Observe that when , the bottom subtrees are single \nodes, and therefore the notion of their arrangement into pre- or in-order is not relevant. In our nomenclature, 
\inbreadth is  and \prebreadth is  (see \autoref{tbl:notation}).

\todo{
What about cut heights? Emperical graph comparing with optimal.

ApproxWEP: in/pre have different cut heights. Why do we use these? Motivation - symmetric, and empirical.
Other Observations: For MINWEP, special cases cut heights.

}

\comment{
To find the best cut height, we undertook a detailed empirical study that computed \pwmean[0] for all \HLs restricted to in-order and pre-order arrangements of the top subtree at each branch of the recursion. Two factors were allowed to vary. We allowed every subtree to be aranged in-, pre-, or post-order, and we considered all possible cut heights  (we quickly determined that larger  were not beneficial). We calculated \pwmean[0] for each potential layout to find \minwep for each tree height. 
}
In our detailed empirical analysis, which suggested that \pwmean[0] is minimized by layouts that fit the characterization  in our nomenclature, we noticed that the optimal cut height (denoted by \opt) was different from \halfwep for pre-order subtrees: .
\comment{
\begin{itemize}
\item
For every case, the \minwep layout arranged the bottom subtrees just as in \halfwep --- Those closest to the top subtree were arranged pre-order, and all others in-order.
\item
}
For in-order subtrees, it is the same as before, \ie, .
\comment{The optimal cut height, denoted by \opt, is different from \halfwep for pre-order subtrees}
Furthermore, there is one exception to the above rule, with , and correspondingly
.


\comment{
\begin{table}
\newcommand{\m}[1]{}
\centering
\begin{tabular}{|r|c|c|c|c|}
\hline
\multicolumn{1}{|c|}{\multirow{2}*{}} &
\multicolumn{2}{c|}{} &
\multicolumn{2}{c|}{} \\
\cline{2-5}
& 
\multicolumn{1}{c|}{in} &
\multicolumn{1}{c|}{pre} &
\multicolumn{1}{c|}{in} &
\multicolumn{1}{c|}{pre} \\
\hline
 2 &    &  &   &   \\
 3 &    &  &   &   \\
 4 &    &  &   &   \\
 5 &    & \m{1|4} &   &   \\
 6 & \m{2|4} &  &   &   \\
 7 &    &  &   &   \\
 8 &    &  &   &   \\
 9 &    &  &   &   \\
10 &    &  &   &   \\
11 &    &  &   &   \\
12 &    &  &   &\m{6|6} \\
13 &    &  &\m{7|6} &   \\
14 &    &  &   &   \\
15 &    &  &   &   \\
16 &    &  &   &\m{8|8} \\
\hline
\end{tabular}
\caption{
  Optimal partitions  of a tree of height  using
  geometric and exact weights for in- and pre-/post-order
  positioning of the top subtree.   denotes the height of the
  top subtree.  Exceptions to the simple partitioning rules
  ( for in-order;
  
  for pre- and post-order) are highlighted.
}
\label{tbl:partitions}
\end{table}
}
\note{Is this \minwep? Yes.}

Based on these experiments, we define \minwep as the \halfwep-like layout with the cut heights presented above, including the exception. In our nomenclature, \minwep is  (see \autoref{tbl:notation}). \autoref{fig:tree-minwep} illustrates \minwep for a tree of height . 
In the outermost branch of the recursion, the top two levels of the tree are arranged together in positions  to , indicating a cut of . This compares with a cut of height  for \halfwep (see \autoref{fig:tree-halfwep}). Also, we see that the pre-order subtree of height  rooted at position  in \minwep is cut at a height .
\comment{
We also denote the layout that does not include the exception as \approxwep. Thus \approxwep is a layout that arranges the bottom subtrees closest to the top subtree pre-order and cuts them at height . It arranges all other subtrees in-order and cuts them at height , just like \halfwep does. 
}

The pre-order cut height exception at  can also be interpreted as part of the piece-wise function 
 if , and  otherwise. Furthermore, interpreting the in-order cut height for subtrees of height  as  instead of , which is an equally valid interpretation, the cut height for an in-order subtree can be calculated directly from the cut height for an pre-order subtree as follows:  if , and  otherwise. 

Analyzing \HLs where the closest bottom subtree is arranged pre-order and the cut heights are chosen such that , we see that cutting all in-order subtrees at height  instead results in the same layout. This is because this in-order cut results in two pre-order bottom subtrees of height , each of which will subsequently be cut at the same height as they would have been if they had been part of an in-order subtree of height . Since the closest bottom subtree is pre-order in either case, the layouts are identical. As a result, we can set . As we shall see later, this is important since it simplifies the index computation for \nodes in pointer-less trees. 
Note that this optimization cannot be applied to \halfwep.
\comment{, since its pre-order and in-order cut heights are identical.}

\comment{
For small tree heights upto , \approxwep is identical to \halfwep, and is not separately illustrated in \autoref{fig:tree-layouts}. For larger trees, \approxwep differs from \halfwep and \minwep slightly, and tends to perform similar to both.We have already seen from \autoref{fig:bt-in-pre} and \autoref{fig:veb} that in all the metrics considered, \halfwep and \approxwep already perform more or less identically. For this reason, we do not include \approxwep in our figures, even though it is different from \minwep.
}

\subsection{The cost of cache-misses: Explicit pointer-based searches}

We observed earlier that \halfwep and \minwep are virtually indistinguishable in terms of explicit search time. This is because they are exactly the same ordering schemes, but with very slightly different cut heights. Larger differences in cut heights can make a significant difference. Consider the values of \pwmean[0] in \autoref{fig:cut} for many of the layouts presented so far. Recall that \bender and \pvl differ from each other only in the choice of the cut height . For \bender, the cut height , which is identical to \pvl () only for subtree heights that are a power of two. As expected, we see identical values of \pwmean[0] for \bender and \pvl for trees of height , , , and . However, for all other tree heights, \bender gives higher values for \pwmean[0]; sometimes  worse. This manifests itself in similarly worse pointer-based search times compared to \pvl. This suggests that for a particular ordering scheme, the optimal cut height is closer to halfway down the tree.
\comment{
for all ordering schemes (combination of in- and pre-order subtrees in the same column in \autoref{tbl:notation}).
}

Cut heights  and  illustrate this further. \minep, which is identical to \minwep except in its choice of the cut height (), results in significantly different trees (especially for larger tree heights), and we observe a steep divergence in \pwmean[0] as the tree height increases. 
As expected, \minep's performance (measured using pointer-based search times) also degrades significantly for large tree heights. 
At the other end of the spectrum, consider \prebreadth and \inbreadth, which are identical to \pvl and \ivl respectively, except in the choice of cut height. A cut height of  results in significantly different layouts, especially for large tree heights. Even for the small example in \autoref{fig:tree-layouts}, we see that \prebreadth is quite different from \pvl. In \autoref{fig:cut}, we see that the pointer-based search time is significantly worse for breadth-first layouts, when compared to \pvl and \ivl. 

From the \pwmean[0] values in \autoref{fig:cut}, we also observe that in-order is not always better than pre-order. For a cut height of , \preorder results in much smaller \pwmean[0] values than \inorder. The example in \autoref{fig:tree-layouts} suggests why: All the short edges in \inorder are near the bottom of the tree, where the contribution to \pwmean[0] is minimal. \comment{
As expected, \inorder results in much higher pointer-based search times than \preorder. 
}
However, this behavior changes as we increase the cut height, and at some point, in-order layouts are better than pre-order layouts. 
When the cut is approximately near halfway down the tree, in-order layouts such as \ivl result in much smaller \pwmean[0] values than pre-order layouts such as \pvl. As we increase the cut height all the way to , we observe that the in-order version of the breadth-first layout \inbreadth continues to be better than the pre-order version \prebreadth.

\begin{table*}[t]
\centering
\begin{tabular}{c|c||c|c|c|c}
&
{\multirow{2}{*}{Cut height }} &
{Pre-order layouts} &
\multicolumn{2}{c|}{Hybrid layouts} &
{In-order layouts} \\
\cline{3-6}
& &  &  &  & \\
\hline\hline
 Depth-first &  & \preorder () & \minwla () & \minep () & \inorder ()\\
\hline
 Other & & \bender () & & \minwep ()&\\
\hline
\comment{
 Optimal & & & & \approxwep (), \minwep ()&\\
\hline
}
 \multirow{2}{*}{\vEB} &
 \multirow{2}{*}{} 
 & \pvl () & & & \ivl ()\\
\cline{3-6}
 & & \pvla () & & \halfwep () & \ivla ()\\
\hline
 Breadth-first &  & \prebreadth () & & & \inbreadth ()\\
\end{tabular}
\caption{
Nomenclature for \HLs.  The table summarizes the layouts discussed in the text, organized by cut height (rows) and subtree ordering (columns). The cut height function  for \minwep is described in \autoref{sec:cut-hts}. The 
wild-card  indicates that a particular parameter is not relevant.
}
\label{tbl:notation}
\end{table*}

\subsection{The computational cost of layouts: Pointer-less searches}

Based on explicit pointer-based search times, we have shown that \minwep is a cache-oblivious layout with almost  improvement in performance when compared to the best in the literature, represented by \pvl. However, \minwep is a more complex layout than \pvl.
\comment{
and to ensure that the performance numbers are not affected by the time taken to compute the position of a \node in the layout, we have presented explicit pointer-based times so far. 
}
The natural question therefore is: If we considered implicit, pointer-less search times, would \minwep still compare favorably with \pvl? In \cite{Brodal:COSearch-vEBLayout}, the authors showed that for small tree heights, even layouts that have poor cache-performance such as \inorder and \prebreadth perform better than \pvl in implicit search, simply because it is trivial to compute the position of a \node in such layouts.

To understand the trade-offs involved, we first measured the time taken to compute the index of child nodes in a pointer-less search by excluding all memory accesses.\footnote{We achieved this by storing the keys  in the tree, allowing them to be easily inferred without lookup via their in-order index.}
\autoref{lst:code} lists the code that takes the \prebreadth index for a \node and computes its corresponding \minwep index.  This code needs to be executed for every transition in the search tree.  Here the depth (level)  of the node is maintained together with  along the search path from the root.
Observe that one of the two functions in this code segment (\texttt{partition}) calculates the cut height for any pre-order subtree. 

In \autoref{fig:cut}, we see that the index computation time is almost constant for simple layouts (\inorder, \preorder, \inbreadth, and \prebreadth). The slow increase merely stems from the longer search paths as the height of the tree is increased. Furthermore, \minwep's index computation time is usually  times that of the simple layouts. Comparing \minwep with the \vEBls (\ivl, \pvl, \bender, \halfwep) is more interesting. 
Not surprisingly, \halfwep performs worse than \ivl on this metric (around  worse), since it is a more complex layout. Observe that \pvl performs better than \ivl, and by almost . It turns out that the index can be computed more quickly within a pre-order subtree, since one does not need to keep track of left and right, and also because some other optimizations unique to pre-order layouts can be performed. This observation is key, since it allows us to compute the index for \minwep in  less time than \halfwep, which is very similar at first glance. This is because we can set , as shown in \autoref{sec:cut-hts}, reducing the computational burden significantly by converting any in-order computation to a pre-order computation. As a result of this optimization, mean index computation times for \minwep are also about  less than those of \ivl. Finally, observe that index computations take almost  more time in \bender compared to \pvl, because of the additional time spent computing \bender's complex cut heights.

\autoref{fig:cut} also presents our results on implicit, pointer-less search times. One can think of these as a combination of the index computation times (which do not include memory accesses) and explicit search times (which include memory accesses, but avoid index computations using pointers). We see that for the more complex layouts, the implicit search times correlate very well with the index computation times. This is because of the relatively fast memory access times; if we added disk or even flash to the memory hierarchy, we would expect the relative order among the implicit times to be similar to the explicit times. 
The only perceptible difference in our experiments is that the pre-order layouts (\pvl and \bender) perform slightly worse, since they perform almost  worse on the explicit search times. 
Among the simpler layouts, the implicit search times diverge significantly from the index computation times due to their poor memory access times. For tress of height , \inorder already performs worse than \pvl, and we expect all of the simpler layouts to perform worse than \minwep as the height of the tree increases beyond .

\subsection{Experimental Setup}
\label{sec:setup}

Our experiments were run on a single core of a
dual-socket 6-core 2.80~GHz Intel Xeon X5660 (Westmere-EP) processor with
96~GB of 3x DDR3-1333 RAM split over two 48~GB NUMA memory banks,
12~MB 16-way per-socket shared L3 cache,
256~KB 8-way L2 cache,
and 32~KB 8-way L1 data cache.
All three caches use 64-byte cache lines.
To reduce noise in the timing measurements, we computed the median time
of 15 runs.  Each run searches for (up to) 10 million randomly selected nodes.
We counted the number of L1 and L2 cache misses incurred in memory accesses
to the binary tree (stored as a linear array) using \texttt{valgrind-3.5.0}.
We also repeated our experiments on different architectures,
from powerful workstations to laptops, and observed similar results.

\todo{
Only search time exeriments here. since everything else has already been demonstrated?

No need to compare with DFS,etc, at this point. just i/p-VEB, and minWEP?

Cache Miss experiments.
Search time experiments. (Discuss trade-offs in calculation, compare with vEB.) 
}

\section{Conclusions}

In this paper, we present \minwep, a new layout for cache-oblivious search trees that outperforms layouts used in the literature by almost . Using a general framework of \HLs, we showed that \minwep minimizes a new locality measure (\pwmean[0], which represents the \WEP) that correlates very well with cache-misses in a multi-level cache hierarchy. 
All widely used cache-oblivious versions of search trees rely on \vEBls, which are shown to be a special case of \HLs. Therefore, we suggest that the performance of all these data structures can be easily improved by switching to a layout that is derived from \minwep.

While enumerating all possible orderings for small trees, we noticed that the optimal \pwmean[0] value is sometimes obtained by layouts that do not place the top subtree at one end or in the middle of the bottom subtrees. This implies that \RLs do not necessarily optimize \pwmean[0]. One direction of future study is to generalize the notion of \RLs to include such \HLs, and to construct unrestricted layouts that optimize \pwmean[0]. We would also like to prove that, at least among all \RLs, \minep and \minwep minimize \pmean[0] and \pwmean[0], respectively, since we believe this is true based on our extensive empirical study.
\note{These seem like contradictory statements.  If \minwep is a \HL and we think it minimizes \pwmean[0], then we could not have noticed a better one. Agreed, changed the text.}

\todo{
Finding optimal layout for WEP.
Extending memory transfer bounds.
Extensions to streaming etc can just use our vEB layout.
}

\bibliographystyle{IEEEtran}
\bibliography{paper,minwep}



\lstinputlisting[float,caption={Breadth-first to \minwep index translation.},label=lst:code]{code.cpp}



\newcommand{\stats}[4]{\ensuremath{\pwmean[0] = #1, \pwmean[1] = #2, \pmean[1] = #3, \pmean[\infty] = #4}}


\begin{figure*}[tp]
\vspace*{-2ex}\subfloat[{\minwep = \minep: \stats{1.818}{4.063}{2.581}{23}}]{\includegraphics[width=0.5\linewidth]{tree-minwep}\label{fig:tree-minwep}\label{fig:tree-minep}}\subfloat[{\halfwep: \stats{1.823}{3.938}{3.097}{26}}]{\includegraphics[width=0.5\linewidth]{tree-halfwep}\label{fig:tree-halfwep}}\-2ex]\subfloat[{\ivl: \stats{2.227}{4.300}{3.161}{25}}]{\includegraphics[width=0.5\linewidth]{tree-vebi}\label{fig:tree-vebi}}\subfloat[{\pvl: \stats{2.824}{7.100}{5.145}{50}}]{\includegraphics[width=0.5\linewidth]{tree-vebo}\label{fig:tree-vebo}}\-2ex]\subfloat[{\inbreadth: \stats{3.096}{4.700}{8.258}{16}}]{\includegraphics[width=0.5\linewidth]{tree-inbreadth}\label{fig:tree-inbreadth}}\subfloat[{\prebreadth: \stats{5.824}{9.300}{16.500}{32}}]{\includegraphics[width=0.5\linewidth]{tree-breadth}\label{fig:tree-breadth}}\-2ex]\subfloat[{\minla: \stats{2.753}{4.175}{2.323}{12}}]{\includegraphics[width=0.5\linewidth]{tree-minla}\label{fig:tree-minla}}\subfloat[{\minbw: \stats{3.629}{4.350}{4.581}{7}}]{\includegraphics[width=0.5\linewidth]{tree-minbw}\label{fig:tree-minbw}}\caption{
  Layouts and locality functionals
  \pwmean[0] (weighted edge product),
  \pwmean[1] (weighted edge sum),
  \pmean[1] (mean edge length),
  and \pmean[\infty] (maximum edge length)
  of a tree with  levels.
  For , \minep and \minwep coincide.
  Edges  are drawn with thickness inversely proportional to length \len[ij].
  Cuts are shown as dashed lines that span the width of subtrees with 3 or more levels.
  Colored vertices are roots of in- (blue) or pre-order (red) subtrees with 2 or more levels.
}
\label{fig:tree-layouts}\end{figure*}
 
\clearpage

\clearpage

\appendix

\section{Proofs}
\label{sec:proofs}

\begin{theorem*}The \minwla layout minimizes \pwmean[1] among all \RLs with cut height .
\end{theorem*}
\begin{IEEEproof}
\comment{
We introduce the following notation ot prove that, for binary tree , the \minwla layout minimizes \pmean[1] among all \RLs with cut height . 
For trees of height  cut at height , let ,  be  times average weighted edge length \pwmean[1] when the top subtree is arranged in-order and pre-order, respectively.
}
Recall that the weight of an edge between level  and level  is .
Observe that when , the top subtree  is a single \node , and there are only two bottom subtrees, which we denote as  and . 
\note{We use subscripts  and  elsewhere. Changed here.}
\comment{
We make no assumptions on the arrangement of the bottom subtrees -- this is what \autoref{thm:order} proves. 
}
Essentially, we have to prove the following for all \RLs with cut height . 
\begin{enumerate}
\item
\label{item:allpre}
\pwmean[1] is always minimized by arranging both bottom subtrees  and  pre-order.
\item
\label{item:onlytopin}
For any subtree, the optimal in-order arrangement has lower \pwmean[1] than the optimal pre-order arrangement. 
\end{enumerate}
Consider the optimal pre-order arrangement for a subtree of height . Without loss of generality, let  be the bottom subtree closest to  in a pre-order arrangement.
We can obtain an in-order arrangement of lower cost by moving the second bottom subtree  to the other side of the top subtree , since this moves the root of  closer to  without changing the costs of either bottom subtree. Clearly, the optimal in-order arrangement must have lower cost than this in-order arrangement, which proves \autoref{item:onlytopin}. 

Now, consider the optimal in-order arrangement of a bottom subtree, which has height . Let this be subtree , since the analysis is valid for both bottom subtrees.
By moving one of the bottom subtrees of height  to the other side of 's root, we convert it to a pre-order arrangement, bringing 's root closer to  by . At the same time, if we flip
the order of the \nodes of the bottom subtree we just moved, we 
have increased the length of the edge connecting its root to 's root by the same . However, since this edge is one level further down the tree, it has a lower weight, and therefore the overall cost has decreased. (Observe that no other edge lengths have changed.) As a result, we can obtain a pre-order arrangement for  that is of lower cost than the optimal in-order arrangement for . This implies that the optimal pre-order arrangement for  has a lower \pwmean[1] value than the optimal in-order arrangement for , proving \autoref{item:allpre}.

It is not too difficult to extend this proof for all weight distributions where the weights do not increase from one level to the next. As a result, among all \RLs with cut height , 
\minwla optimizes the unweighted measure \pmean[1], and also optimizes \pwmean[1] for the exact weight distribution described in \autoref{eq:edgewts}.
\todo{Finish proof to fix Case 3. Done.}
\end{IEEEproof}

\comment{
\begin{theorem*} 
Proof of \autoref{thm:subtree-in-order}.
\end{theorem*}
\begin{IEEEproof}
Consider an ordering for which  and .
Let  and let  and  be the lengths
of the edges connecting  with  and  with .  Now
swap the positions of  and  so that , and
order the \nodes in  by the corresponding reverse ordering
of \nodes in , and vice versa.  It is easy to see that this
modification of the layout shortens both  and 
by  without changing the lengths of all other
edges in the tree. Thus this ordering with  reduces all
edge lengths, and will result in an ordering with smaller \PB.
\end{IEEEproof}
}

\begin{theorem*}For any subtree in a particular branch of the recursion, suppose we fix the internal ordering of the leaves of the top subtree  and the arrangement of all the bottom subtrees in subsequent branches of the recursion. Then, the product of all the edge lengths between the top subtree and the bottom subtrees is minimized by ordering the bottom subtrees in reverse order of that of the parent leaves .
\end{theorem*}
\begin{IEEEproof}
Let \pos represent the layout of the top subtree .
Consider two leaves  and  of the top subtree . Let  and  be bottom subtrees whose parents are
 and , respectively.  We use  to mean
;  implies
; and  implies
.  

Without loss of generality, assume .
Consider the case in which the two bottom subtrees  and  appear
to the same side of the top subtree  containing  and . Without loss of 
generality, assume that  and  are to the right of , \ie
 and . 
We show that if , then there exist operations that
will place  before  such that the product of the edge lengths is lowered.  Because
the edges  and  have the same weight, it is
easy to see that the value of this weight does not affect the proof,
and hence we assume that this weight is one. 

Suppose . 
\comment{and consider some arbitrary ordering of the \nodes within
these subtrees.  
}
In \pos, let the distance
between  and  be , between  and the first \node of
 be , and between the first \nodes of  and  be .
Furthermore, let  and  denote the distances from the first
\node of  and  to their roots, such that the lengths of the
edges between  and  and their subtrees are 
and , respectively.
(See the top example in \autoref{fig:subtree-ordering}).  

\begin{figure}[tp]
\centering
\includegraphics[width=\columnwidth]{subtree-ordering-top}\{2}
\label{inorder}
C_P^{h-1} & \leq C_I^{h-1} + (h-2)\\
\label{preorder}
C_I^{h-1} + \log(2^{h-1}+2^{h-2}-1) & \leq C_P^{h-1} + (h-1){2}
\label{e:inorder}
C_P^{h-2} & \leq C_I^{h-2} + (h-3) \\
\label{e:preorder}
C_I^{h-2} + \log(2^{h-2}+2^{h-3}-1) & \leq C_P^{h-2} + (h-2)
\label{p:inorder}
C_I^{h-1} = C_P^{h-2}\\
\label{p:preorder}
C_P^{h-1} = \frac{1}{2} (C_P^{h-2} + C_I^{h-2} + \log(2^{h-2}+2^{h-3}-1))


Adding  to both sides of \eqref{e:preorder}, and multiplying by , we have
. 
Substituting in  from \eqref{p:inorder} and~\eqref{p:preorder}, we get
, which implies \eqref{inorder}.

We define . It is easy to see that for all , we have . Therefore, , and from \eqref{e:inorder}, we have .
Adding  to both sides, and multiplying by , we have 
. 
Substituting in  from \eqref{p:inorder} and~\eqref{p:preorder}, we get 
, which implies 
, which in turn implies 
\eqref{preorder}.

It is not too difficult to extend this proof for all weight distributions where the weights do not increase from one level to the next. As a result, 
among all \RLs with cut height , \minep optimizes the unweighted measure \pmean[0], and also optimizes \pwmean[0] for the exact weight distribution described in \autoref{eq:edgewts}.
\todo{Finish proof to fix Case 3. Done.}
\end{IEEEproof}
 
\end{document}
