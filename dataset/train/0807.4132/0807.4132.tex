The growing importance and pervasiveness of computer systems 
has required the introduction of new, richer, and more expressive 
temporal models, fostering their evolution from the basic ``historical'' 
models of the previous section. This evolution has inevitably 
modified the boundaries between the traditional ways of modeling 
time, often making them fuzzy. In particular, this happened with 
heterogeneous systems, which require the combination of different abstractions 
within the same model.

This section shows how the aforementioned models have been refined 
and adapted in order to meet more specific and advanced specification 
needs. These are particularly prominent in some classes of systems, 
such as hybrid, critical, and real-time systems \cite{HM96}. As we 
discussed above in Section \ref{sec:introduction}, these categories are independent 
but with large areas of overlap.


\begin{table}[!ht]
\centering
\begin{scriptsize}
\begin{tabular}{|p{5cm}|c|c|}
\hline 
\textbf{Keywords} & \textbf{Dimension} & \textbf{Section} \\
\hline 
discrete, dense, continuous, granularity & \emph{Discrete vs.~Dense} & \ref{sec:discrete} \\
\hline 
qualitative, quantitative, metric(s) & \emph{Ordering vs.~Metric} & \ref{sec:ordering} \\
\hline 
linear, branching, (non)deterministic & \emph{Linear vs.~Branching} & \ref{sec:linear} \\
\hline 
implicit(ly), explicit(ly) & \emph{Implicit vs.~Explicit} & \ref{sec:implicit} \\
\hline 
(non)-Zeno, fairness, deadlock(ed) & \emph{Time Advancement} & \ref{sec:timeadvancement} \\
\hline 
composing, composition, concurrency, synchrony, synchronous(ly), asynchronous(ly) & \emph{Concurrency and Composition} & \ref{sec:concurrency} \\
\hline 
analysis, tool(set), verification, decision procedure & \emph{Analysis and Verification} & \ref{sec:analysis} \\
\hline 
\end{tabular}
\end{scriptsize}
\caption{Keyword references to the ``Dimensions'' of Section \ref{sec:dimensions}.}
\label{tab:keywords}
\end{table}


As in the historical overview of Section \ref{sec:historical}, the
main features of the models presented in this section are discussed
along the dimensions introduced in Section \ref{sec:dimensions}. Such
dimensions, however, have different relevance for different
formalisms; in some cases a dimension may even be unrelated with some
formalism. For this reason we avoid a presentation in the style of a
systematic ``tabular'' cross-reference ; rather,
to help the reader match the features of a formalism with the
coordinates of Section \ref{sec:dimensions}, we highlight the portions
of the text where a certain dimension is specifically discussed by
graphically emphasizing (in small caps) some related
keywords. The correspondence between keywords and dimensions is shown
in Table \ref{tab:keywords}. Also, for the sake of conciseness, we do
not repeat features of a \emph{derived} formalism that are inherited
unaffected from the ``parent'' notation.



\subsubsection*{The Computer- and System-Centric Views}
As a preliminary remark we further generalize the need of adopting 
and combining different views of the same system and of its heterogeneous 
components. Going further --- and, in some sense, back --- in the path 
described in Section \ref{sec:historical}, which moved from the micro to the macro 
view of hardware, and then to the software view, we now distinguish 
between a \emph{computer-centric} and \emph{a system-centric} view. 
As the terms themselves suggest, in a computer-centric view attention 
is focused on the computing device and its behavior, which may 
involve interaction with its environment through I/O operations; 
in a system-centric view, instead, attention is on a whole collection 
of heterogeneous components, and computing devices --- hardware 
and software --- are just a subset thereof. Most often, in such 
systems the dynamics of the components range over widely different 
time scales and time granularities (in particular continuous 
and discrete components are integrated).

In a \emph{computer-centric} view we consider systems where 
time is inherently discrete, and which can be described with 
a (finite-)state model. Moreover, we usually adopt a strictly 
synchronous model of concurrency, where the global synchrony 
of the system is given by the global clock ticking. Nondeterminism 
is also often adopted to model concurrent computations at an 
abstract level.

Another typical feature of this view is the focus on the ease 
of --- possibly automated --- analysis to validate some properties; 
in general, it is possible and preferred to restrict and abstract 
away from many details of the time behavior in favor of a decidable 
formal description, amenable to automated verification.

An example of computer-centric view is the design and analysis 
of a field bus for process control: the attention is focused 
on discrete signals coming from several sensors and on their 
proper synchronization; the environment that generates the signals 
is ``hidden'' by the interface provided by the sensors.

Conversely, in the \emph{system-centric} view, the aim is to model, 
design, and analyze the whole system; this includes the process 
to be controlled, the sensors and actuators, the network connecting 
the various elements, the computing devices, etc.

In the \emph{system-centric} view, according to what kind of application 
domain we consider, time is sometimes continuous, and sometimes 
discrete. The concurrency model is often asynchronous, and the 
evolution of components is usually deterministic. For instance, 
a controlled chemical process would be described in terms of 
continuous time and asynchronous deterministic processes; on 
the other hand a logistic process --- such as the description 
of a complex storage system --- would be probably better described 
in terms of discrete time. Finally, the system-centric view puts 
particular emphasis on input/output variables, modular divisions 
among components, and the resulting ``information flow'', similarly 
to some aspects of dynamical systems. Thus, the traditional division 
between hardware and software is blurred, in favor of the more 
systemic aspects.

In practice, no model is usually taken to be totally computer-centric 
or system-centric; more often, some aspects of both views are 
united within the same model, tailored for some specific needs. 


\paragraph{}
The remainder of this section presents some broad classes of 
formal languages, in order to discuss what kind of temporal models 
they introduce, and what kind of systems they are suitable to 
describe.

We first analyze a selected sample of operational formalisms.  Then,
we discuss descriptive formalisms based on logic, and devote
particular attention to some important ones. Finally, we present
another kind of descriptive notations, the algebraic formalisms, that
are mostly timed versions of successful untimed formal languages and
methods.

To discuss some features of the formalisms surveyed we will 
adopt a simple running example based on a resource allocator. 
Let us warn the reader, however, that the various formalizations 
proposed for the running example do not aim at being different 
specifications of the same system; on the contrary, the semantics 
may change from case to case, according to which features of 
the formalism we aim at showing in that particular instance.



\subsection{Operational Formalisms} \label{sec:operational}
We consider three broad classes of operational formalisms: synchronous 
state machines, Petri nets as the most significant exponent of 
asynchronous machines, and heterogeneous models.


\subsubsection{Synchronous Abstract Machines} \label{sec:synchronous}
In Section \ref{sec:historical} we presented some classes of (finite-)state 
machines that have a synchronous behavior. As we noticed there, 
those models are mainly derived from the synchronous ``macro'' 
view of hardware digital components, and they are suitable to 
describe ``traditional'' \emph{sequential} computations.

The natural evolution of those models, in the direction of increasing
complexity and sophistication, considers \emph{concurrent} and
\emph{reactive} systems. These are, respectively, systems where
different components operate in parallel, and open systems whose
ongoing interaction with the environment is the main focus, rather
than a static input/output relation. The models presented in this
section especially tackle these new modeling needs.


\paragraph{Infinite-Word Finite-State Automata.}
Perhaps the simplest extension of automata-based formalisms to 
deal with reactive computations consists in describing a semantics 
of these machines over infinite (in particular, denumerable) 
sequences of input/output symbols. This gives rise to finite-state 
models that are usually called ``automata on infinite words'' (or -words).
The various flavors of these automata differ in how they define 
acceptance conditions (that is, how they distinguish between 
the ``good'' and ``bad'' interactions with the environment) and 
what kind of semantic models they adopt.

Normally these models are defined in a nondeterministic version, 
whose transition relation 
(where  is the input alphabet, and  is the state space) associates
input symbol, current state and next state. 
Thus, for the same pair  of input symbol and current state,
more than one next state  may be in relation with it, that is, the automaton can ``choose'' 
any of the next states in the set .
Nondeterminism and infinite words require the definition of different, 
more complex acceptance conditions than in the deterministic, 
finite word case. For instance, the B\"uchi acceptance condition 
is defined through a set of final states, some of which must 
be visited infinitely often in at least one of the nondeterministically-chosen 
runs \cite{Var96}. Other acceptance conditions are defined, for instance, 
in Rabin automata, Streett automata, parity automata, Muller 
automata, tree automata, etc. \cite{Tho90}.

As an example of use of infinite-word automata, let us model 
a simple resource manager. Before presenting the example, however, 
we warn the reader that we are not interested in making the resource 
manager as realistic as possible; rather, as our aim is to show 
through small-sized models the most relevant features of the 
formalisms presented, for the sake of brevity we introduce simplifications 
that a real-world manager would most probably avoid.

The behavior of the resource manager is the following: Users 
can issue a request for a resource either with high priority 
() or with low priority (). Whenever the resource 
is free and a high-priority request is raised, the resource is 
immediately granted and it becomes occupied. If it is free and 
a low-priority request is received, the resource is granted after 
two time units. Finally, if a high-priority request is received 
while the resource is granted, it will be served as soon as the 
resource is released, while a low-priority request will be served 
two instants after the resource is released. Further requests 
received while the resource is occupied are ignored.

The above behavior can be modeled by the automaton of Figure \ref{fig:allocator}, 
where the various requests and grant actions define the input 
alphabet (and  defines a ``waiting'' transition); note 
that the automaton is actually deterministic. We assume that 
all states are accepting states.
\begin{figure}[htb!]
	 \centering
	 \includegraphics{allocator}
	 \caption{A resource manager modeled by an infinite-word finite-state automaton.}
	 \label{fig:allocator}
\end{figure}

Let us analyze the infinite-word finite-state automaton models 
with respect to our coordinates. First of all, these models can 
be considered as mainly ``computer-centric'', focusing on simplicity 
and abstractness. In particular, from the point of view of the 
computer scientist, they are particularly appealing, as they 
allow one to reason about time in a highly simplified way.

There is no explicit notion of quantitative time. As usual, however, 
a simple \kw{metric} is implicitly defined by associating a time unit 
with the execution of a single transition; thus time is inherently \kw{discrete}. 
For example, in Figure \ref{fig:allocator}, we measure \kw{implicitly} the two time units after 
which a low priority request is granted, by forcing the path 
from the request  to  to pass through two intermediate 
states via two ``wait'' transitions .

The simplicity of the time model makes it amenable to automated 
\kw{verification}. Various techniques have been developed to analyze 
and verify automata, the most successful of whom is probably \emph{model checking} \cite{CGP00}.
(See also Section \ref{sec:duallanguage}).

The \kw{nondeterministic} versions of these automata are particularly 
effective for characterizing multiple computation paths. In defining 
its formal semantics one may exploit a \kw{branching} time model. 
There are, however, relevant examples of nondeterministic automata 
that adopt a \kw{linear} time model, B\"uchi automata being the most 
noticeable instance thereof. In fact, modeling using linear time 
is usually considered more intuitive for the user; for instance, 
considering the resource manager described above, the linear 
runs of the automaton naturally represent the possible sequences 
of events that take place in the manager. This intuitiveness 
was often considered to be traded off with amenability to automatic 
verification, since the first model checking procedures were 
more efficient with branching logic \cite{CGP00}. Later progresses 
have shown, however, that this trade off is often fictitious, 
and linear time models may be endowed with efficient verification 
procedures \cite{Var01}.

When \kw{composing} multiple automata in a global system we must face 
the problem of \kw{concurrency}. The two most common concurrency models 
used with finite automata are \emph{synchronous} concurrency and \emph{interleaving} 
concurrency. 

\begin{itemize}
\item In \emph{synchronous concurrency}, concurrent transitions of different 
composed automata occur simultaneously, that is the automata 
evolve with the same ``global'' time. This approach is probably 
the simpler one, since it presents a global, unique vision of 
time, and is more akin to the ``synchronous nature'' of finite-state 
automata. Synchronous concurrency is pursued in several languages 
that constitute extensions and specializations of the basic infinite-word 
finite-state automaton, such as Esterel \cite{BG92} and Statecharts (see below).

\item In \emph{interleaving concurrency}, concurrent transitions 
are ordered arbitrarily. Then any two global orderings of the 
transitions that differ only for the ordering of concurrent transitions 
are considered equivalent. Interleaving semantics may be regarded 
as a way to introduce a weak notion of concurrency in a strictly 
synchronous system. The fact that interleaving introduces partially 
ordered transitions weakens however the intuitive notion of time 
as a total order. Also, the natural correspondence between the 
execution of a single transition and the elapsing of a time unit 
is lost and \emph{ad hoc} rules are required to restate a time metric 
based on the transition execution sequence.

Another problem introduced by adopting an interleaving semantic 
model lies in the \kw{fairness} requirement, which prescribes that 
every concurrent request eventually gets satisfied. Usually, 
fairness is enforced explicitly \emph{a priori} in the 
composition semantic. 
\end{itemize}

The main strength of the infinite-word finite-state automata 
models, i.e., their simplicity, constitutes also their main limitation. 
When describing physical systems, adopting a strictly synchronous 
and discrete view of time might be an obstacle to a ``natural'' 
modeling of continuous processes, since discretization may be 
too strong of an abstraction. In particular, some properties 
may not hold after discretization, such as periodicity if the 
duration of the period is some irrational constant, incommensurable 
with the duration of the step assumed in the discretization. 

Moreover, it is very inconvenient to represent heterogeneous systems
with this formalism when different components run at highly different
speeds and the time \kw{granularity} problem arises. In more technical
terms, for this type of models it is rather difficult to achieve
\emph{compositionality} \cite{AFH96,AH92}.


\paragraph{Statecharts.}
Statecharts are an automata-based formalism, invented by \linebreak
David~Harel~\cite{Har87}. They are a quite popular tool in the
software engineering community, and a version thereof is part of the
UML standard \cite{UML05,UML04}.

In a nutshell, Statecharts are an enrichment of classical finite-state 
automata that introduces some mechanisms for hierarchical abstraction 
and parallel composition (including synchronization and communication 
mechanisms). They may be regarded as an attempt to overcome some 
of the limitations of the bare finite-state automaton model, 
while retaining its advantages in terms of simplicity and ease 
of graphical representation. They assume a synchronous view of 
communication between parallel processes.

Let us use the resource manager running example to illustrate 
some of Statecharts' features; to this purpose we introduce some 
modifications to the initial definition. First, after any request has 
been granted, the resource must be released within 100 time units. 
To model such \kw{metric} temporal constraints we associate a \emph{timeout} 
to some states, namely those represented with a short squiggle 
on the boundary (such as  or  in Figure \ref{fig:statechart}).

\begin{figure}[htb!]
	 \centering
	 \includegraphics[scale=1.15]{statechart}
	 \caption{A resource manager modeled through a Statechart.}
	 \label{fig:statechart}
\end{figure}

Thus, for instance, the transition that exits state  must be
taken within 100 time units after  has been entered: if no
 event has been generated within 100 time units, the timeout
event  is ``spontaneously-generated'' exactly after 100 time
units.\footnote{Note that there are in fact two transitions from state
   to state , one that is labeled , and one
  that is labeled ; they are represented in Figure
  \ref{fig:statechart} with a single arc instead of two separate ones
  for the sake of readability. The transition labeled 
  indicates that when the timeout expires (the  event), a 
  event is triggered, which is then sensed by the other parts of the
  Statechart, hence producing other state changes (for example from
   to ).}  Conversely the lower bound of 0 in the same
state indicates that the same transition cannot be taken
immediately. We use the same mechanism to model the maximum amount of
time a low-priority request may have to wait for the resource to
become available; in this case, with respect to the previous example,
we allow the low-priority request to be granted immediately,
nondeterministically. Notice that modeling time constraints using
timeouts (and exit events) implies an \kw{implicit} modeling of a
global system time, with respect to which timeouts are computed, just
like in finite-state automata.  In fact, timeouts can be regarded as
an enrichment of the discrete finite state automaton model with a
\kw{continuous} feature.

The example of Figure \ref{fig:statechart} exploits Statecharts'
so-called ``AND (parallel) composition'' to represent three logically
separable components of the system, divided by dashed lines. The
semantics of AND composition is obtained as the Cartesian product
construction,\footnote{In fact, the semantics of the AND composition
  of submachines in Statecharts differs slightly from the classic
  notion of Cartesian product of finite-state machines; however, in
  this article we will not delve any further in such details, and
  instead refer the interested reader to \cite{Har87} for a deeper
  discussion of this issue.} and it is usually called
\kw{synchronous composition};\footnote{We warn the reader that the
  terminology often varies greatly among different areas; for instance
  \cite{CL99} names the Cartesian product composition ``completely
  asynchronous''.} however, Statecharts' graphical representation
avoids the need to display all the states of the product construction,
ameliorating the readability of a complex specification. In particular
in our example, we choose to allow one pending high-priority request
to be ``enqueued'' while the resource is occupied; thus the leftmost
component is a finite-state automaton modeling whether the resource is
free, serving a high-priority request with no other pending requests
(state ), or with one pending request (state ), or
serving a low-priority request (state ).

Since in Statecharts all transition events --- both input and output 
--- are ``broadcast'' over the whole system, labeling different 
transitions with the same name enforces synchronization between 
them. For instance, whenever the automaton is in the global state , 
a release event  triggers the global state to become , 
and then cascading immediately to , 
because of the output event  triggered by the transition 
from  to . Note that we are implicitly assuming, 
in the example above, that  and  are ``internal events'',
i.e., they do not occur spontaneously in the environment 
but can only be generated internally for synchronization.

\kw{Nondeterminism} can arise in three basic features of Statecharts 
models. First, we have the ``usual'' nondeterminism of two mutually 
exclusive transitions with the same input label (such as in Figure \ref{fig:statecharts-nondet}(a)). 
Second, states with timeout are exited nondeterministically \emph{within} 
the prescribed bounds (Figure \ref{fig:statecharts-nondet}(b)). Third, Statechart modules 
may be composed with ``XOR composition'', that represents a nondeterministic 
choice between different modules (Figure \ref{fig:statecharts-nondet}(c)). 

\begin{figure}[htb!]
	 \centering
	 \includegraphics{statecharts-nondet}
	 \caption{Nondeterminism in Statecharts.}
	 \label{fig:statecharts-nondet}
\end{figure}

The popularity of Statecharts has produced an array of different 
\kw{analysis tools}, mostly automated. For instance \cite{HLNPPSST90,BDW00,GTBF03}.

While overcoming some of the limitations of the basic finite-state 
automata models, Statecharts' rich syntax often hides subtle semantic 
problems that instead should be better exposed to avoid inconsistencies 
and faults in specifications. In fact, over the years several 
researches have tried to define formally the most crucial aspects 
of the temporal semantics of Statecharts. The fact itself that 
different problems were unveiled only incrementally by different 
contributors is an indication of the difficulty of finding a 
comprehensive, intuitive, non-ambiguous semantics to an apparently 
simple and plain language. We discuss here just a few examples, 
referring the interested reader to \cite{HPSS87,PS91,vdB94,HN96} 
for more details.

The apparently safe ``perfect \kw{synchrony}'' assumption --- the assumption 
that all transition events occur simultaneously --- and the global 
``broadcast'' availability of all events --- which are therefore 
non local --- generate some subtle difficulties in obtaining a 
consistent semantics. Consider for instance the example of Figure \ref{fig:statechart}, 
and assume the system is in the global state . 
If a high-priority request takes place, and thus a  event 
is generated, the system shifts to the state  in zero time.
Simultaneously, the taken transition triggers the events  and .
If we allow a zero-time residence in states, the former event moves the system
to , representing the low-priority request being forced to release 
the resource. Still simultaneously, the latter  event 
triggers the transition from  to  in the middle sub-automaton.
This is in conformity with our intuitive requirements; however the same  generated event also triggers 
the first sub-automaton to the state , which is instead 
against the intuition that suggests that the event is only a 
message sent to the other parts of the automaton.

If we refine the analysis, we discover that the picture is even 
more complicated. The middle automaton is in fact in the state , 
while the time has not advanced; thus we still have the  
event available, which should immediately switch the middle automaton 
back to the state . Besides being intuitively not 
acceptable, this is also in conflict with the lower bound on 
the residence time in . Moreover, in general we may end 
up having multiple XOR states occupied at the same time. Finally, 
it is not difficult to conceive scenarios in which the simultaneous 
occurrence of some transitions causes an infinite sequence of 
states to be traversed, thus causing a \kw{Zeno} behavior.

How to properly disentangle such scenarios is not obvious. A 
partial solution would be, for instance, to avoid instantaneous 
transitions altogether, attaching a non-zero time to transitions 
and forcing an ordering between them or, symmetrically, to disallow 
a zero-time residence in states. This (partially) asynchronous 
approach is pursued for instance in Timed Statecharts \cite{KP92}, 
or in other works \cite{Per93}. Alternatively, other solutions disallow 
loops of zero-time transitions, but accept a finite number of 
them (for instance, by ``consuming'' each event spent by a transition \cite{HN96});
the Esterel language, which is a ``relative'' of Statecharts', follows this approach. 


\paragraph{Timed and Hybrid Automata.}
As we discussed above, the strictly discrete and synchronous view of
finite-state automata may be unsuitable to model adequately and
compositionally processes that evolve over a dense domain.
Statecharts try to overcome these problems by adding some continuous
features, namely timeout states. Timed and hybrid automata push this
idea further, constituting models, still based on finite-state
automata, that can manage continuous variables. Let us first discuss
timed automata.

\emph{Timed automata} enrich the basic finite-state automata with 
real-valued \emph{clock} variables. Although the name ``timed automata'' 
could be used generically to denote automata formalisms where 
a description of time has been added (e.g., \cite{LV96,AH96,Arc00}), 
here we specifically refer to the model first proposed by Alur 
and Dill \cite{AD94}, and to its subsequent enrichments and variations. 
We refer the reader to Alur and Dill's original paper \cite{AD94} and to \cite{BY04} 
for a formal, detailed presentation.

In timed automata, the total state is composed of two parts: 
a finite component (corresponding to the state of a finite automaton, 
which is often called \emph{location}), and a continuous one represented 
by a finite number of positive real values assigned to variables 
called \emph{clocks}. The resulting system has therefore an \emph{infinite} 
state space, since the clock components take value in the infinite 
set . The evolution of the system is made of alternating phases 
of instantaneous synchronous discrete ``jumps'' and continuous 
clock increases. More precisely, whenever a timed automaton sits 
in some discrete state, each clock variable  increases as 
time elapses, that is it evolves according to the dynamic equation , 
thus effectively measuring time. External input events cause 
the discrete state to switch; during the transition some clock 
variables may be reset to zero instantaneously. Moreover, both 
discrete states and transitions may have attached some constraints 
on clocks; each constraint must be satisfied while sitting in 
the discrete state, and when taking the transition, respectively.\footnote{The original Alur and Dill's formalization \cite{AD94} permitted constraints only on transitions; however, adding constraints to locations as well is a standard extension that does not impact on the salient features of the model (expressiveness, in particular) \cite{BY04}.}

To illustrate this notation, let us model the resource manager 
example through a timed automaton. We modify the system behavior 
of the Statechart example, by disallowing high-priority requests 
to preempt low-priority ones; moreover, let us assume that one 
low-priority request can be ``enqueued'' waiting for the resource 
to become free. The resulting timed automaton --- using a single 
clock  --- is pictured in Figure \ref{fig:timed_automaton}.
\begin{figure}[htb!]
	 \centering
	 \includegraphics{timed_automaton}
	 \caption{A resource manager modeled through a timed automaton.}
	 \label{fig:timed_automaton}
\end{figure}

The semantics of a timed automaton is usually formally defined 
by means of a timed transition system. The ``natural'' semantics 
is the \emph{timed} semantics, which exactly defines the possible 
runs of one automaton over sequences of input symbols. More precisely, 
each symbol in the input sequence is paired with a \emph{timestamp} 
that indicates the absolute time at which the symbol is received. 
Then, a run is defined by a sequence of total states (each one 
a pair  of 
the automaton, which evolve according to the timestamped input 
symbols, in such a way that, for every pair of consecutive states

in the run the constraints on the locations and the transition 
are met. For instance, the automaton of Figure \ref{fig:timed_automaton} may go through 
the following run:

In the run above state location  is entered at time 4.7 
and, since the corresponding transition resets clock , the 
new state becomes ; then, at time 
53.9 (when clock  has reached value 49.2), location 
is exited and  is entered (this time, the clock  
is not reset), which satisfies the constraint 
of location , and so on.

Timed semantics introduces a \kw{metric} treatment of time through 
timestamps. Notice that, in some sense, the use of timestamps 
introduces ``two different notions of time'': the inherently \kw{discrete} 
one, given by the position  in the run/input sequence, which 
defines a total ordering on events, and the \kw{continuous} and metric 
one, recorded by the timestamps and controlled through the clocks. 
This approach, though simple in principle, somewhat sacrifices 
naturalness, since a complete time modeling is no more represented 
as a unique flow but is two-fold.

Other, different semantics of timed automata have been introduced 
and analyzed in the literature. Subtle differences often arise 
depending on which semantics is adopted; for instance, interval-based 
semantics interprets timed automata over piecewise-constant functions 
of time, and the change of location is triggered by discontinuities 
in the input \cite{AFH96,ACM02,Asa04}.

Let us consider a few more features of time modeling for timed 
automata. 
\begin{itemize}
\item While timed automata are in general \kw{nondeterministic}, their 
semantics is usually defined through \kw{linear} time models, such 
as the one outlined above based on run sequences. Moreover, deterministic 
timed automata are strictly less expressive than nondeterministic 
ones, but also more amenable to automated verification, so they 
may be preferred in some practical cases.

\item \emph{Absolute time is} \kw{implicitly} assumed in the model 
and becomes apparent in the timestamps associated with the input 
symbols. The \emph{relative time} measured by clocks, however, is \kw{explicitly} 
measured and set.

\item Timed automata may exhibit \kw{Zeno} \emph{behaviors}, when distances 
between times at which transitions in a sequence are taken become 
increasingly smaller, accumulating to zero. For instance, in 
the example of Figure \ref{fig:timed_automaton}, the two transitions  and  
may be taken at times , so that the absolute time would accumulate at . Usually, these Zeno behaviors are ruled out \emph{a priori} 
in defining the semantics of timed automata, by requiring that 
timestamped sequences are acceptable only when the timestamp 
values are unbounded.

Moreover, in Alur and Dill's formulation \cite{AD94} timed words have \emph{strictly monotonic} timestamps,
which implies that some time (however small) must elapse between two consecutive transitions; other semantics 
have relaxed this requirement by allowing weakly monotonic timestamps  \cite{BY04}, thus permitting sequences of zero-time transitions. 
\end{itemize}

\emph{Hybrid automata} \cite{ACHH93,NOSY93,Hen96} are a generalization 
of timed automata where the dense-valued variables --- called 
``clocks'' in timed automata --- are permitted to evolve through 
more complicated timed behaviors. Namely, in hybrid automata 
one associates to each \emph{discrete state} a set of possible \emph{activities}, 
which are smooth functions (i.e., functions that are continuous 
together with all of their derivatives) from time to the dense 
domain of the \emph{variables}, and a set of \emph{invariants}, which 
are sets of allowed values for the variables. Activities specify 
possible variables' behaviors, thus generalizing the simple dynamics 
of clock variables in timed automata. More explicitly, whenever 
a hybrid automaton sits in some discrete location, its variables 
evolve over time according to one activity, \emph{nondeterministically} 
chosen among those associated with that state. However, the evolution 
can continue only as long as the variables keep their values 
within the invariant set of the state. Then, upon reading input 
symbols, the automaton instantaneously switches its discrete 
state, possibly resetting some variables according to the additional 
constraints attached to the taken transitions, similarly to timed 
automata.

Although in this general definition the evolution of the dense-valued 
variables can be represented by any function such that all its derivatives are continuous, in practice 
more constrained (and simply definable) subsets are usually considered. 
A common choice is to define the activities by giving a set of 
bounds on the first-order derivative, with respect to time, of 
the variables. For a variable , the constraint 
is an example of a class of such activities (see Figure \ref{fig:hybrid_behavior} for a visual
representation).
\begin{figure}[htb!]
	 \centering
	 \includegraphics{hybrid_behavior}
	 \caption{Some behaviors compatible with the constraint .}
	 \label{fig:hybrid_behavior}
\end{figure}

In both timed and hybrid automata, one typically defines a \kw{composition}
semantics where concurrent automata evolve in parallel, but synchronize 
on transitions in response to input symbols, similarly to traditional 
automata and Statecharts.

The development of timed and hybrid automata was also motivated 
by the desire to extend and generalize the powerful and
successful techniques of automatic \kw{verification} (and model checking 
in particular) based on the combination of infinite-word finite-state 
automata and temporal logic (see Section \ref{sec:duallanguage}), to the metric 
treatment of time. However, the presence of real-valued variables 
renders the verification problem much more difficult and, often, 
undecidable. Thus, with respect to the general model, restrictions 
are introduced that make the models more tractable and amenable 
to verification --- usually at the price of sacrificing some expressiveness.

In a nutshell, the verification problem is generally tackled 
by producing a \emph{finite abstraction} of a timed/hybrid automaton, 
where all the relevant behaviors of the modeled system are captured 
by an equivalent, but finite, model, which is therefore exhaustively 
analyzable by model checking techniques. Such procedures usually 
assume that all the numeric constraints on clocks and variables 
are expressed by \emph{rational} numbers; this permits the partitioning
of the space of all possible behaviors of the variables into a finite 
set of \emph{regions} that describe equivalent behaviors, preserving 
verification properties such as reachability and emptiness. 
For a precise description of these techniques see e.g., \cite{AM04,ACHHHNOSY95,HNSY94,HKPV98}.

These analysis techniques have been implemented in some interesting 
tools, such as UPPAAL \cite{LPY97}, Kronos \cite{Yov97}, Cospan \cite{AK95}, IF \cite{BGOOS04}, and HyTech \cite{HHW97}.


\paragraph{Timed Transition Models.}
Ostroff's \emph{Timed Transition Models} (TTM) \linebreak \cite{Ost90} are another 
formalism that is based on enriching automata with time variables; 
they are a real-time \kw{metric} extension of Manna and Pnueli's fair transition 
systems \cite{MP92}.

In TTMs, time is modeled \kw{explicitly} by means of a clock variable .
 takes values in a \kw{discrete} time domain, and is updated explicitly 
and \kw{synchronously} by the occurrence of a special \emph{tick} transition. The clock 
variable, as any variable in TTMs, is global and thus shared 
by all transitions. All transitions other than \emph{tick} do not 
change time but only update the other components of the state; 
therefore it is possible to have several different states associated 
with the same time instant. Transitions are usually annotated 
with lower and upper bounds ; this prescribes that 
the transition is taken at least , and no more than 
clock ticks (i.e., time units), after the transition has become 
enabled.

In practice, it is assumed that every TTM system includes a \emph{global clock}
subsystem, such as that pictured in Figure \ref{fig:tick}. Notice that 
this subsystem allows the special \emph{tick} transition to occur 
at any time, making time advance one step. The \emph{tick} transition 
is \emph{a priori} assumed to be fairly scheduled, that is it must 
occur infinitely often to prevent \kw{Zeno} behaviors where time stops. 
\begin{figure}[htb!]
	 \centering
	 \includegraphics{tick}
	 \caption{A Timed Transition Model for the clock.}
	 \label{fig:tick}
\end{figure}

We give a few more details of TTMs in Section \ref{sec:duallanguage} (where a TTM 
resource manager specification is also given) when discussing 
dual language approaches.


\subsubsection{Asynchronous Abstract Machines: Petri nets} \label{sec:petrinets}
This section introduces Petri nets as one of the most popular 
examples of asynchronous abstract machines.

Petri nets owe their name to their inventor, Carl Adam Petri \cite{Pet63}.
Since their introduction they became rather popular 
both in the academic and, to some extent, in the industrial world, 
as a fairly intuitive graphical tool to model concurrent systems. 
For instance, they inspired transition diagrams adopted in the 
UML standard \cite{UML05,UML04,EPLF03}. There are a few slightly 
different definitions of such nets and of their semantics. Among 
them one of the most widely adopted is the following, which we 
present informally; the reader is referred to the literature \cite{Pet81,Rei85}
for a comprehensive treatment.

A \emph{Petri net} consists of a set of places, and a set of transitions. 
Places store tokens and pass them to transitions. A transition 
is \emph{enabled} whenever all of the incoming places hold at least 
one token. Whenever a transition is enabled a \emph{firing} can 
occur; this happens nondeterministically. As a consequence of 
a firing, the enabling tokens are removed from the incoming places 
and moved to the outgoing places the transition is connected 
to. Thus, for any possible combination of nondeterministic choices, 
we have a \emph{firing sequence}.

Let us consider again the example of the resource manager, using 
a Petri net model. We introduce the following modifications with 
respect to the previous examples. First, since we are now considering 
untimed Petri nets, we do not introduce any metric time constraint. 
Second, we disallow low-priority requests while the resource 
is occupied, or high-priority requests while there is a pending 
low-priority request. Conversely, we introduce a mechanism to 
``count'' the number of consecutive high-priority requests that 
occur while the resource is occupied. Then, we make sure that 
all of them are served (consecutively) before the resource becomes 
free again. This behavior is modeled by the Petri net in Figure \ref{fig:petri_net_untimed}, 
where the places are denoted by the circles , , , , 
and , and the thick lines denote transitions. Notice that 
we allow an unbounded number of tokens in each place (actually, 
the only place where the tokens can accumulate is , 
where each token represents a pending high-priority request). 
Finally, we have also chosen to introduce an \emph{inhibiting arc}, 
from place  to transition , denoted by a small circle 
in place of an arrowhead: this means that the corresponding transition 
is enabled if and only if place  stores no tokens. This 
is a non-standard feature of Petri nets which is often added 
in the literature to increase the model's expressive power.
\begin{figure}[htb!]
	 \centering
	 \includegraphics{petri_net_untimed}
	 \caption{A resource manager modeled through a Petri net.}
	 \label{fig:petri_net_untimed}
\end{figure}

According to our taxonomy, Petri nets, as defined above, can 
be classified as follows: 

\begin{itemize}
\item There is no explicit notion of time. However a time model can 
be \kw{implicitly} associated with the semantics of the net.

\item There are at least two major approaches to formalizing 
the semantics of Petri nets. 
  \begin{itemize}
  \item The simpler one is based on \emph{interleaving semantics}. According 
	 to this semantics the behaviors of a net are just its firing 
	 sequences. Interleaving semantics, however, introduces a total 
	 ordering in the events modeled by the firing of net transitions 
	 which fails to capture the asynchronous nature of the model. 
	 For instance, in the net of Figure \ref{fig:petri_net_untimed} the two sequences
	  and
	 
	 both belong to the set of possible net's behaviors; however, 
	 they both imply an order between the firing of transitions  and , 
	 whereas the graphical structure of the net emphasizes that the 
	 two events can occur asynchronously (or simultaneously).

  \item For this reason, a \emph{true concurrency} (i.e., fully \kw{asynchronous}) 
	 approach is often preferred to describe the semantics of Petri 
	 nets. In a true concurrency approach it is natural to see the 
	 time model as a \emph{partial order}, instead of a total order of 
	 the events modeled by transition firings. Intuitively, in a true 
	 concurrency modeling the two sequences above can be ``collapsed'' into
	 ,
	 where the pair  denotes the fact that the included items can 
	 be ``shuffled'' in any order.
  \end{itemize}

\item Petri nets are a \kw{nondeterministic} operational model. For instance, 
still in the net of Figure \ref{fig:petri_net_untimed}, whenever place  holds 
some tokens, both transitions  and  are enabled, but they are 
in \emph{conflict}, so that only one of them can actually fire. 
Such a nondeterminism could be formalized by exploiting a \kw{branching}\emph{-time} model.

\item In traditional Petri nets the time model has no \kw{metrics}, so that 
it should be seen only as a (possibly partial) order.\footnote{Unless one adopts the convention of associating one time unit to the firing of a single transition, as it is often assumed in other --- synchronous --- operational models such as finite state automata. Such an assumption, however, would contrast sharply with the asynchronous original nature of the model.}

\item We also remark that Petri nets are usually ``less compositional'' 
than other operational formalisms, and synchronous automata in 
particular. While notions of \kw{composition} of Petri nets have been 
introduced in the literature, they are often less natural and 
more complicated than, for instance, Statecharts' synchronous 
composition; this is partly due to the asynchronous ``nature'' 
of the nets. 
\end{itemize}

To model hard real-time systems a metric time model is necessary in
most cases. To overcome this difficulty, many extensions have been
proposed in the literature to introduce a metric time model. Here we
report on Merlin and Farber's approach \cite{MF76}, which has been
probably the first one of such extensions and is one of the most
intuitive and popular ones.  For a thorough and comprehensive survey
of the many time extensions to Petri nets we refer to
\cite{CM99,Cer93}.

A Timed Petri net according to the Merlin and Farber's approach is
simply a net where a minimum and a maximum firing time are attached to
each transition (both firing times can be 0, and the maximum time can
be ). Figure \ref{fig:petri_net} shows how the net of Figure
\ref{fig:petri_net_untimed} can be augmented in such a way. The time
bounds that have been introduced refine the specification of the
resource manager by prescribing that each use of the resource must
take no longer than 100 contiguous (i.e., since the last request
occurred) time units, and that a low priority request is served within
2 time units.
\begin{figure}[htb!]
	 \centering
	 \includegraphics{petri_net}
	 \caption{A resource manager modeled through a timed Petri net.}
	 \label{fig:petri_net}
\end{figure}

The fairly natural intuition behind this notation is that, since the
time when a transition is enabled (i.e., all its input places have
been filled with at least one token), the transition can fire ---
nondeterministically --- at any time that is included in the specified
interval, unless it is disabled by the firing of a conflicting
transition. For instance, place  becomes occupied after a low
priority request is issued, thus enabling transition . The
latter can fire at any time between 0 and 2 time instants after it has
become enabled, thus expressing the fact that the request is served
\emph{within} 2 time units.

Despite its intuitive attractiveness, several intricacies are 
hidden in the previous informal definition, as has been pointed 
out in the literature when attempting to formalize their semantics \cite{FMM94,GMMP91}. 
Here we focus only on the main ones.

\begin{itemize}
\item Suppose that the whole time interval elapsed since the time when 
a transition became enabled: is at this point the transition \emph{forced} 
to fire or not? In the negative case it will never fire in the 
future and the tokens in their input places will be wasted (at 
least for \emph{that} firing). There are arguments in favor of both 
choices; normally --- including the example of Figure \ref{fig:petri_net} --- the 
former one is assumed (it is often called \emph{strong time semantics} 
(STS)) but there are also cases where the latter one (which is 
called \emph{weak time semantics} (WTS) and is considered as more 
consistent with traditional Petri nets semantics, where a transition 
is never forced to fire) is preferred.\footnote{In this regard, notice that the timed automata of Section \ref{sec:synchronous} could be considered to have a \emph{weak time semantics}. In fact, transitions in timed automata \emph{are not forced} to be taken when the upper limit of some constraint is met; rather, all that is prescribed by their semantics is that \emph{when} (if) a transition is taken by a timed automaton, its corresponding constraint (and those of the source and target locations) \emph{must} be met.}

\item If the minimum time associated with a transition is 0, then the
  transition can fire immediately once enabled and we have a case of
  zero-time transition (more precisely we call this circumstance
  \emph{zero-time firing} of the transition). As we pointed out in
  other cases, zero-time firing can be a useful abstraction whenever
  the duration of the event modeled by the firing of the transition
  can be neglected with respect to other activities of the whole
  process.\footnote{Normally the firing of a transition is considered
    as instantaneous. This assumption does not affect generality since
    an activity with a non-null duration can be easily modeled as a
    pair of transitions with a place between them: the first
    transition models the beginning of the activity and the second one
    models its end.}  On the other hand zero-time firing can produce
  some intricate situations since two subsequent transitions (e.g.,
   and  in Figure \ref{fig:petri_net}) could fire
  simultaneously. This can produce some \kw{Zeno} behaviors if the net
  contains loops of transitions with 0 minimum time. For this reason
  ``zero-time loops'' are often forbidden in the construction of timed
  Petri nets.
\end{itemize}

Once the above semantic ambiguities have been clarified, the behavior 
of timed Petri nets can be formalized through two main approaches. 

\begin{itemize}
\item A time stamp can be attached to each token when it is produced 
by the firing of some transition in an output place. For instance, 
with reference to Figure \ref{fig:petri_net}, we might have the sequence of
transitions 
(that is,  fires at time 2 producing a token with 
time stamp 2 in ; this is consumed at time 3 by the firing 
of  which also produces one token in  and 
one in , both timestamped 3, etc.). In this way time is 
\kw{explicitly} modeled in a \kw{metric} way --- whether \kw{discrete} or \kw{continuous} 
--- as a further variable describing system's state and evolution 
(more precisely, as \emph{many} further variables, one for each 
produced token).

As remarked in Section \ref{sec:synchronous}, this approach actually introduces 
two different time models in the formalism: the time implicitly 
subsumed by the firing sequence and the time modeled by the time 
stamps attached to tokens. Of course some restrictions should 
be applied to guarantee consistency between the two orderings: 
for instance, the same succession of firings described above could induce the timed 
sequence ,
that should however be excluded from the possible behaviors. 

\item The net could be described as a dynamical system as in the traditional 
approach described in Section \ref{sec:dynamicalsys}. The system's state would be 
the net marking whose evolution should be formalized as a function 
of time. To pursue this approach, however, a few technical difficulties 
must be overcome:
  \begin{itemize}
  \item First, tokens cannot be formalized as entities with no identity, 
	 as it happens with traditional untimed Petri nets. Here too, 
	 some kind of time stamp may be necessary. Consider, for instance, 
	 the net fragment of Figure \ref{fig:petri_state}, and suppose that one token is 
	 produced into place  at time 3 by transition  and another 
	 token is produced by  at time 4; then, according to the normal 
	 interpretation of such Petri nets (but different semantic formalizations 
	 could also be given, depending on the phenomenon that one wants 
	 to model) the output transition  should fire once at time 6=3+3 
	 and a second time at time 7=4+3. Thus, a state description that 
	 simply asserts that at time 4 there are two tokens in  would 
	 not be sufficient to fully describe the future evolution of the 
	 net.
\begin{figure}[htb!]
	 \centering
	 \includegraphics{petri_state}
	 \caption{An example Petri net fragment.}
	 \label{fig:petri_state}
\end{figure}

  \item If zero-time firings are admitted, strictly speaking, system's 
	 state cannot be formalized as a function of the independent variable 
	 ``time'': consider, for example, the case in which, in the net 
	 of Figure \ref{fig:petri_net}, at time  both transitions  and  fire
	 (which can happen, since  admits zero-time firing); in this case, it 
	 would happen that at time  both a state (marking) where 
	 place  is marked and a state where place  is marked 
	 --- and  is not marked anymore --- would hold.

	 In \cite{FMM94} this problem has been solved by forbidding ``zero-time 
	 loops'' and by stating the convention that in case of a ``race'' 
	 of zero-time firings (which is always finite) only the places 
	 at the ``end of the race'' are considered as marked, whereas tokens 
	 flow instantaneously through other places without marking them. 

	 In \cite{GMM99} a more general approach is proposed, where zero-time 
	 firings are considered as an abstraction of a non-null but \emph{infinitesimal} 
	 firing time. By this way it has been shown that mathematical 
	 formalization and analysis of the net behavior become simpler 
	 and --- perhaps --- more elegant.
    \end{itemize}
\end{itemize}

Timed Petri nets have also been the object of a formalization through 
the dual language approach (see Section \ref{sec:duallanguage}).

As for other formalisms of comparable expressive power, Petri nets
suffer intrinsic limitations in the techniques for (semi-)automatic
\kw{analysis} and \kw{verification}. In fact, let us consider the reachability
problem, i.e., the problem of stating whether a given marking can be
reached by another given marking. This is the main analysis problem
for Petri nets since most other properties can be reduced to some
formulation of this basic problem \cite{Pet81}. For normal, untimed
Petri nets with no inhibitor arcs the reachability problem has been
shown intractable though decidable; if Petri nets are augmented with
some metric time model and/or inhibitor arcs, then they reach the
expressive power of Turing machines and all problems of practical
interest become undecidable.\footnote{Of course, interesting
  particular cases are always possible, e.g., the case of bounded
  nets, where the net is such that during its behavior the number of
  tokens in every place never exceeds a given bound.} Even building
interpreters for Petri nets to analyze their properties through
simulation faces problems of combinatorial explosion due to the
intrinsic nondeterminism of the model.

Nevertheless interesting tools for the analysis of both untimed and
timed Petri nets are available. Among them we mention \cite{BD91},
which provides an algorithm for the reachability problem of timed
Petri nets assuming the set of rational numbers as the time
domain. This work has pioneered further developments. For a
comprehensive survey of tools based on Petri nets see \cite{TGI}.



\paragraph{}
Before closing this section let us also mention the Abstract State
Machines (ASM) formalism \cite{BS03}, whose generality subsumes most
types of operational formalisms, whether synchronous or
asynchronous. However, ASM have not received, to the best of our
knowledge, much attention in the realm of real-time computing until
recently, when the Timed Abstract Machine notation \cite{OL07} and
its tools \cite{OL07b} have been developed.






\subsection{Descriptive Formalisms} \label{sec:descriptive} Let us now
consider \emph{descriptive} (or \emph{declarative}) formalisms.  In
descriptive formalisms a system is formalized by declaring the
fundamental properties of its behavior. Most often, this is done by
means of a language based on mathematical logic; more seldom algebraic
formalisms (e.g., process algebras) are exploited. As we saw in
Section \ref{sec:metamodel}, descriptive notations can be used alone
or in combination with operational ones, in a dual language
approach. In the former case, both the requirements and the system
specification are expressed within the same formalism; therefore
verification consists of proving that the axioms (often expressed in
some logic language) that constitute the system specification imply
the formulas that describe the requirements. In the latter case, the
verification is usually based on some \emph{ad hoc} techniques, whose
features may vary significantly depending on the adopted combination
of descriptive and operational notations. We treat dual-language
approaches in Section \ref{sec:duallanguage}.

When considering the description of the timed behavior of a system 
through a logic formalism, it is natural to refer to \emph{temporal 
logics}. A distinction should be made here. Strictly speaking, 
temporal logics are a particular family of modal logics \cite{Kri63,RU71} 
possessing specific operators --- called \emph{modalities} --- apt 
to express temporal relationships about time-dependent propositions. 
The modalities usually make the treating of time-related information 
quite intuitive as they avoid the \kw{explicit} reference to absolute 
time values and mirror the way the human mind intuitively reasons 
about time; indeed, temporal logics were initially introduced 
by philosophers \cite{Kam68}. It was Pnueli who first observed \cite{Pnu77} 
that they could be effectively used to reason about temporal 
properties of programs, as well. Some temporal logics are discussed 
in the following Section \ref{sec:temporallogics}.

In the computer science communities, however, the term ``temporal 
logic'' has been used in a broader sense, encompassing all logic-based 
formalisms that possess some mechanism to express temporal properties 
and to reason about time, even when they introduce some \kw{explicit} 
reference to a dedicated variable representing the current value 
of time or some sort of clock and hence adopt a style of description 
that is different in nature from the original temporal logic 
derived from modal logic. Many of these languages have been used 
quite successfully for modeling time-related features: some of 
them are described in Section \ref{sec:logicswtime} below.

We emphasize that there is a wide variety of different styles 
and flavors when it comes to temporal logics. As usual, we do 
not aim to be exhaustive in the presentation of temporal logics 
(we refer the reader to other papers specifically on temporal 
logics, e.g., \cite{Eme90,AH93,AH92,Ost92,Hen98,BMN00,FPR}), but 
to highlight some significant approaches to the problem of modeling 
time in logic.

Finally, a different approach to descriptive modeling of systems, 
based on the calculational aspects of specifications, is the 
algebraic one. We discuss algebraic formalisms in Section \ref{sec:algebraic}.


\subsubsection{Temporal Logics} \label{sec:temporallogics} In this
section we deal with temporal logics with essentially \kw{implicit} time,
and we focus our discussion on a few key issues, namely the
distinction between linear-time and branching-time logics, the
adoption of a discrete or non-discrete time model, the use of a metric
on time to provide means to express temporal properties in a
quantitatively precise way, the choice of using solely temporal
operators that refer to the future versus introducing also past-tense
operators, and the assumption of time points or time intervals as the
fundamental time entities. In our discussion we will go from simple to
richer notations and occasionally combine the treatment of some of the
above mentioned issues.  Finally, some \kw{verification} issues about
temporal logics will be discussed while presenting dual language
approaches in Section \ref{sec:duallanguage}.


\paragraph{Linear-Time Temporal Logic.}
As a first, simplest example of temporal logic, let us consider 
propositional Linear-Time Temporal Logic (LTL) with discrete 
time. In LTL, formulas are composed from the atomic propositions 
with the usual Boolean connectives and the temporal connectives  
(\emph{next}, also denoted with the symbol ),  (\emph{eventually 
in the future}, also ),  (\emph{globally} --- i.e., \emph{always} 
--- \emph{in the future}, also ), and  (\emph{until}). These 
have a rather natural and intuitive interpretation, as the formulas 
of LTL are interpreted over \kw{linear} sequences of states: the formula  
means that proposition  holds at the state that immediately 
follows the one where the formula is interpreted,  
means that  will hold at some state following the current 
one,  that  will hold at all future states,  
means that there is some successive state such that proposition  
will hold then, and that  holds in all the states between 
the current and that one.

Notice that the presence of the ``next'' operator  implies 
that the logic refers to a \kw{discrete} temporal domain: by definition, 
there would be no ``next state'' if the interpretation structure 
domain were not discrete. On the other hand, depriving LTL of 
the next operator would ``weaken'' the logic to a pure ordering 
without any metrics (see below).

To illustrate LTL's main features, let us consider again the 
resource manager introduced in the previous sections: the following 
formula specifies that, if a low priority request is issued at 
a time when the resource is free, then it will be granted at 
the second successive state in the sequence. 


LTL is well-suited to specify qualitative time relations, for 
instance ordering among events: the following formula describes 
a possible assumption about incoming resource requests, i.e., 
that no two consecutive high priority requests may occur without 
a release of the resource between them (literally, the formula 
reads as: if a high priority request is issued then the resource must be eventually released and no other 
similar request can take place until the release occurs). 


Though LTL is not expressly equipped with a \kw{metric} on time, one might
use the next operator  for this purpose: for instance,  (i.e., ) would mean that proposition 
holds 3 time units in the future. The use of  to denote the
time instant at  time units in the future is only possible,
however, under the condition that there is a one-to-one correspondence
between the states of the sequence over which the formulas are
interpreted and the time points of the temporal domain. Designers of
time-critical systems should be aware that this is not necessarily the
case: there are linear discrete-time temporal logics where two
consecutive states may well refer to the same time instant whereas the
first following state associated with the successive time instant is
far away in the state sequence \cite{Lam94,MP92,Ost89}. We already
encountered this critical issue in the context of finite state
automata and the \kw{fairness} problem (see Section \ref{sec:synchronous})
and timed Petri nets when zero-time transitions are allowed (see
Section \ref{sec:petrinets}) and will encounter it again in the dual
language approach (Section \ref{sec:duallanguage}).


\paragraph{Metric Temporal Logics.}
Several variations or extensions of \kw{linear} time temporal logic have
been defined to endow it with a metric on time, and hence make it
suitable to describe strict real-time systems. Among them, we mention
Metric Temporal Logic (MTL) \cite{Koy90} and TRIO \cite{GMM90,MMG92}.
They are commonly interpreted both over \kw{discrete} and over \kw{dense} (and
\kw{continuous}) time domains.

MTL extends LTL by adding to its operators a \kw{quantitative} time
parameter, possibly qualified with a relational symbol to imply an
upper bound for a value that typically represents a distance between
time instants or the length of some time interval.  For instance the
following simple MTL formula specifies bounded response time: there is
a time distance  such that an event  is always followed by an
event  with a delay of at most  time units (notice that MTL is
a first-order logic).


The following formula asserts that  eventually takes place, and then periodically occurs with period .


TRIO introduces a quantitative notion of time by adopting a single 
basic modal operator, called \emph{Dist}. The simplest formula 
means that proposition  holds at a time instant exactly 
time units from the current one; notice that this formula may 
refer to the future, if , or to the past, if , 
or even to the present time if . All the operators of 
LTL, their quantitative-time counterparts and also other operators 
not found in traditional temporal logic are defined in TRIO by 
means of first-order quantification over the time parameter of 
the basic operator \emph{Dist}. We include in Table \ref{tab:trio-operators} a list of some 
of the most significant ones (and especially those used in the following).

\begin{table}[tbh]
\begin{center}
  \begin{scriptsize}
\begin{tabular}{|c|c|p{4.8cm}|}
    \hline
    \textsc{Operator}        &  \textsc{Definition}  &   \textsc{Description}\\
    \hline
                 &     &    holds  time units in the future \\
                 &    &    held  time units in the past \\

                     &         &    holds always \\

                &   &   holds for  time units in the future \\
               &   &   held for  time units in the past \\

              &   &   holds within  time units in the future \\

               &    &   holds until  holds \\ 

                 &   &    holds for some non-empty interval in the future \\

                &   &    held for some non-empty interval in the past \\
    \hline
  \end{tabular}
  \end{scriptsize}
\end{center}
\caption{TRIO derived temporal operators.}
\label{tab:trio-operators}
\end{table}

Referring again to the example of the resource manager, the following 
TRIO formula asserts that any low priority resource request is 
satisfied within 100 time units 

while the next one states that any two high priority requests 
must be at least 50 time units apart. 


We note incidentally that both in MTL and in TRIO the interpretation 
structure associates one single state with every time instant 
and no \kw{explicit} state component needs to be devoted to the representation 
of the current value of ``time'': quantitative timing properties 
can be specified using the modal operators embedded in the language. 
Other approaches to the quantitative specification of timing 
properties in real-time systems are based on the use of the operators 
of (plain) LTL in combination with assertions that refer to the 
value of some \emph{ad hoc} introduced clock predicates or explicit 
time variable \cite{Ost89}. For instance the following formula of 
Real Time Temporal Logic (RTTL, a logic that will be discussed 
in Section \ref{sec:duallanguage}) states the same property expressed by 
MTL Formula (\ref{eq:MTL}) above specifying bounded response time (in 
the formula the variable  represents the current value of 
the time state component). 




\paragraph{Dealing with different time granularities}
Once suitable constructs are available to denote in a quantitatively
precise way the time distance among events and the length of time
intervals, then the problem may arise of describing systems that
include several components that evolve, possibly in a partially
independent fashion, on different time scales. This is dealt in the
temporal logic TRIO described above by adopting syntactic and semantic
mechanisms that enable dealing with different levels of \kw{time granularity} \cite{CCM+91}.
 Syntactically, temporal expressions can be
labeled in such a way that they may be interpreted in different time
domains: for instance,  denotes 30 days whereas  denotes 3
hours. They key issue is the possibility given to the user to specify
a semantic mapping between time domains of different granularity;
hence, the truth of a predicate at a given time value at higher
(coarser) level of granularity is defined in terms of the
interpretation in an interval at the lower (finer) level associated
with the value at the higher level. For instance, Figure
\ref{fig:granularity} specifies that, say, working during the month of
November means working from the 2 through the 6, from the 9
through the 13, etc.

\begin{figure}[htb!]
	 \centering
	 \includegraphics{month_granularity}
	 \caption{Interpretation of an upper-level predicate in the lower-level domain. Solid lines denote the intervals in the lower domain where the predicate holds.}
	 \label{fig:granularity}
\end{figure}


As with derived TRIO temporal operators, suitable predefined mappings
help the user specify a few standard situations. For instance given
two temporal domains  and , such that
 is coarser than ,  means that predicate  is
true in any  if and only if it is true in just
one instant of the interval of  corresponding to
. Similarly,  means that  is true in any  if and only if
it is true in the whole corresponding interval of .

By this way the following TRIO formula

which formalizes the sentence ``every month, if an employee works,
then she gets her salary'' introduced in Section \ref{sec:discrete} is
given a precise semantics by introducing the mapping of Figure
\ref{fig:granularity} for predicate , and by stating
that .

In some applicative domains having administrative, business, or
financial implications, the change of time granularity is often paired
with a reference to a global time calendar that evolves in a
\emph{synchronous way}. For instance, time units such as days, weeks,
months and years change in a synchronized way at certain predefined
time instants (e.g., midnight or new year) that are conventionally
established in a global fashion.

On the contrary, when a process evolves in a way such that its
composing events are related directly with one another but are
unrelated with any global time scale, time distances can be expressed
in a time scale with no intended reference to a global time scale: in
such cases we say that time granularity is managed in an
\emph{asynchronous way}. Quite often the distinction of the two
intended meanings is implicit in natural language sentences and
depends on some conventional knowledge that is shared among the
parties involved in the described process; thus, in the formalization
stage, it needs to be made explicit.

Consider for instance the following description of a procedure for
carrying out written exams: ``Once the teacher has completed the
explanation of the exercise, the students must solve it within exactly
three hours. Then, the teacher will collect their solutions and will
publish and register the grades after three days''. Clearly, the
former part of the sentence must be interpreted in the asynchronous
way (students have to complete their job within 180 minutes starting
from the minute when the explanation ended). The latter part, however,
is normally intended according to the synchronous interpretation:
results will be published before midnight of the third ``calendar
day'' following the one when the exam was held.

This notion of synchronous vs. asynchronous refinement of predicates
can be made explicit by adding an indication ( for
synchronous,  for asynchronous) denoting the intended mode
of granularity refinement for the predicates included in the
subformula. Hence the above description of the written examination
procedure could be formalized by the following formula, where
 stands for ``hours'', and  for ``days'':



To the best of our knowledge only few other languages in the
literature approach the granularity problem in a formal way
\cite{BB06,Rom90}. Among these \cite{Rom90} addresses the problem both
for space and time in formal models of geographic data processing
requirements.




\paragraph{Dense Time Domains and the Non-Zenoness Property.}
The adoption of a dense, possibly continuous time domain allows 
one to model asynchronous systems where the occurrence of distinct, 
independent events may be at time instants that are arbitrarily 
close. As a consequence, \kw{Zeno} behaviors, where for instance an 
unbounded number of events takes place in a bounded time interval, 
become possible and must be ruled out by means of suitable axioms 
or through the adoption of \emph{ad hoc} underlying semantic assumptions. 
The axiomatic description of non-Zenoness is immediate for a 
first order, metric temporal logic like MTL or TRIO, when it is applied 
to simple entities like predicates or variables ranging over 
finite domains. It can be more complicated when non-Zenoness 
must be specified in the most general case of variables that 
are real-valued functions of time \cite{GM01}.

Informally, a predicate is non-Zeno if it has finite variability,
i.e., its truth value changes a finite number of times over any finite
interval. Correspondingly, a general predicate  can be
constrained to be non-Zeno by requiring that there always exists a
time interval before or after every time instant, where  is
constantly true or it is constantly false. This constraint can be
expressed by the following TRIO formula (see \cite{HR04,LWW07} for
formulations in other similar logics):


The additional notion of non-Zeno \emph{interval-based} predicate 
is introduced to model a property or state that holds continuously 
over time intervals of length strictly greater than zero. Suppose, 
for instance, that the ``occupied state'' for the resource in 
the resource manager example is modeled in the specification 
through a predicate ; to impose that  be an interval-based 
(non-Zeno) predicate, one can introduce, in addition to Formula (\ref{eq:nonZeno-pred}),
the following TRIO axiom (which eliminates the possibility 
of  being true in isolated time instants). 


A complementary category of non-Zeno predicates corresponds to 
properties that hold at \emph{isolated time points}, and therefore 
can naturally model instantaneous events. If, in the resource 
manager specification, predicate  represents the issue 
of a high priority request, it can be constrained to be a point-based 
predicate by introducing the following formula in addition to 
Axiom (\ref{eq:nonZeno-pred}). 


Finally, non-Zenoness for a time dependent variable  (representing
for instance the current temperature in a thermostat application)
ranging over an uncountable domain  essentially coincides with 
being piecewise analytic,\footnote{A function is analytic at a given
  point if it possesses derivatives of all orders and agrees with its
  Taylor series about that point \cite{WeiA,Kno96}. It is piecewise
  analytic if it is analytic over finitely many contiguous (open)
  intervals.} as a function of time. Analyticity is a quite strong
``smoothness'' requirement on functions which guarantees that the
function intersects any constant line only finitely many times over
any finite interval. Hence, any formula of the kind ,
where  is a constant value in , is guaranteed to be
non-Zeno according to the previous definitions for
predicates. Formally, non-Zenoness for  can be constrained by the
following TRIO formula (where  are functions
that are analytic at 0).
 

In \cite{GM06} it is shown that the adoption of a small set of predefined 
categories of specification items like the point- and interval-based 
predicates outlined above can make the modeling of real-time 
hybrid systems quite systematic and amenable to automated verification.


\paragraph{Future and Past Operators.}
While the Linear Temporal Logic LTL, as originally proposed by 
Pnueli \cite{Pnu77} to study the correctness of programs, has only 
future operators, one may consider additional modalities for the 
past tense, e.g.,  (for \emph{previous}) as the operator corresponding 
in the past to the next operator , or  (for \emph{once}) 
as opposed to ,  (for \emph{since}) as the past version 
of the \emph{until} operator , etc. The question then arises, 
whether the past operators are at all necessary (i.e., if they 
actually increase the expressiveness of the logic) or useful 
in practice (i.e., if there are significant classes of properties 
that can be described in a more concise and transparent way by 
using also past operators than by using future operators only).

Concerning the question of expressiveness, it is well known from 
\cite{GPSS80} that LTL with past operators does not add expressive 
power to future-only LTL. Moreover, the separation theorem by 
Gabbay \cite{Gab87} allows for the elimination of past operators, 
producing an LTL formula to be evaluated in the initial instant 
only: therefore, LTL with past operators is said to be \emph{initially equivalent}
to future-only LTL \cite{Eme90}.\footnote{As it is customary in the literature, we consider one-sided infinite time discrete domains (i.e., ). The bi-infinite case (i.e., ) is much less studied \cite{PP04}.}

On the other hand, it is widely recognized that the extension 
of LTL with past operators \cite{Kam68} allows one to write specifications 
that are easier, shorter, and more intuitive \cite{LPZ85}. A customary 
example, taken from \cite{Sch02}, is the specification: \emph{Every alarm is due to a fault},
which, using the \emph{globally} operator  and the \emph{previously} operator \emph{O}
(\emph{once}), may be very simply written as: 

whereas the following is one of the simplest LTL versions of 
the same specification, using the \emph{until} operator. 


In \cite{LMS02}, it has been shown that the elimination of past operators 
may yield an exponential growth of the length of the derived 
formula.

These expressiveness results change significantly when we consider 
logics interpreted over dense time domains. In general, past 
operators add expressive power when the time domain is dense, 
even if we consider mono-infinite time lines such as . For instance, 
\cite{BCM05} shows that, over the reals, propositional MTL with past 
operators is strictly more expressive than its future-only version. 
The question of the expressiveness of past operators over dense 
time domains was first addressed, and shown to differ from the 
discrete case, in \cite{AH92b,AH93}.


\paragraph{Branching-Time Temporal Logic.}
As discussed in Section \ref{sec:linear}, in \kw{branching}\emph{-time temporal logic} 
every time instant may split into several future ones and therefore 
formulas are interpreted over \emph{trees} of states; such trees 
represent all possible computations of the modeled system. The 
branching in the interpretation structure naturally represents 
the \kw{nondeterministic} nature of the model, which may derive from 
some intrinsic feature of the device under construction or from 
some feature of the stimuli coming from the environment with 
which the device interacts. When interpreting a branching temporal 
logic formula at some current time, the properties asserted for 
the future may be evaluated with reference to \emph{all} future 
computations (i.e., branches of the state tree) starting from 
the current time or only to \emph{some} of them. Therefore, branching 
time temporal logic possesses modal operators that allow one 
to quantify universally or existentially over computations starting 
from the current time.

The Computation Tree Logic (CTL) \cite{EH86} has operators that are 
similar to LTL, except that every temporal connective must be 
preceded by a \emph{path quantifier}: either  (which stands 
for \emph{there exists a computation}, sometimes also denoted with 
the quantification symbol ) or  (\emph{for all computations}, 
also ). With reference to the usual resource manager 
example, the formula below asserts that in every execution 
a low priority request (predicate ) will be eventually followed 
by the resource being occupied (predicate ) in some of 
the evolutions following the request:

while the following formula asserts that there exists a computation 
of the resource manager where all low priority requests are certainly 
(i.e., in every possible successive evolution) eventually followed by the 
resource being occupied: 


These examples, though very simple, show that in branching time
temporal logics temporal and path quantifiers may interact in quite a
subtle way.

Not surprisingly, branching temporal logic has been extended 
in a \kw{metric} version (TCTL, timed CTL) by adding to its operators 
quantitative time parameters, much in the same way MTL extends 
Linear Temporal Logic \cite{ACD93,HNSY94}. 

We refer the reader to \cite{Var01} for a deep analysis of the mutual 
pros and cons of linear time versus branching time logics.


\paragraph{Interval-Based Temporal Logics.}
All temporal logics we have considered so far adopt time \emph{points} 
as the fundamental entities: every state is associated with a 
time instant and formulas are interpreted with reference to some 
time instant. By contrast, the so-called \emph{interval temporal 
logics} assume time \emph{intervals}, rather than time instants, 
as the original temporal entity, while time points, if not completely 
ignored, are considered as derived entities. 

In principle, from a purely conceptual viewpoint, choosing intervals 
rather than points as the elementary time notion may be considered 
as a matter of subjective preference, once it is acknowledged 
that an interval may be considered as a set of points, while, 
on the other hand, a point could be viewed as a special case 
of interval having null length \cite{Koy92}. In formal logic, however, 
apparently limited variations in the set of operators may make 
a surprisingly significant difference in terms of expressiveness 
and complexity or decidability of the problems related with analysis 
and verification. Over the years, interval temporal logics have 
been a quite rich research field, producing a mass of formal 
notations with related analysis and verification procedures and 
tools.

A few relevant ones are: the Interval-based Temporal Logic of 
Schwartz et al.~\cite{SMV83}, the Interval Temporal Logic of Moszkowski \cite{Mos83,Mos86},
the Duration Calculus of Chachoen et al.~\cite{CHR91}, the Metric Interval Temporal Logic (MITL)
of Alur et al.~\cite{AFH96}. 

Among them, Duration Calculus (DC) refers to a \kw{continuous linear} sequence of
time instants as the basic interpretation structure. The significant
portions of the system state are modeled by means of suitable
functions from time (i.e., from the nonnegative reals) to Boolean
values, and operators measuring accumulated durations of states are
used to provide a \kw{metric} over time. For instance, in our resource
manager example, the property that the resource is never occupied for
more than 100 time units without interruption (except possibly for
isolated instants) would be expressed with the DC formula:

where  is a shorthand for , which formalizes the 
fact that the predicate  stays true continually (except for isolated points) over an interval of length .

Another basic operator of Duration Calculus (and of several other 
interval logics as well) is the \emph{chop} operator ; (sometimes denoted as ).
Its purpose it to join two formulas predicating 
about two different intervals into one predicating about two 
adjacent intervals. For example, if we wanted to formalize 
the property that any client occupies the resource for at least 
5 time units, we could use the chop operator as follows:

where the symbol  in the right-hand side of the implication 
now refers to the length of the overall interval, obtained by 
composition through the \emph{chop} operator.

Duration Calculus also embeds an underlying semantic assumption 
of finite variability for state functions that essentially corresponds 
to the previously discussed non-\kw{Zeno} requirement: each (Boolean-valued) 
interpretation must have only finitely many discontinuity points 
in any finite interval.


\subsubsection{Explicit-Time Logics} \label{sec:logicswtime}
Another category of descriptive formalisms adopts a ``timestamp'' 
\kw{explicit} view of time. This is typically done by introducing an \emph{ad hoc}
feature (e.g., a variable that represents the current time, 
or a time-valued function providing a timestamp associated with 
every event occurrence). In this section we focus on the distinguishing 
features of Lamport's Temporal Logic of Actions (TLA) \cite{Lam94}, 
and Alur and Henzinger's Timed Propositional Temporal Logic (TPTL) \cite{AH94}.
Other relevant examples of explicit-time logics are the Real Time Logic (RTL) of Mok et al.~\cite{JM86}
and Ostroff's Real-Time Temporal Logic (ESM/RTTL) \cite{Ost89} (which will be presented in 
the context of the dual language approach in Section \ref{sec:duallanguage}).


\paragraph{Temporal Logic of Actions.}
TLA formulas are interpreted over \kw{linear}, \kw{discrete} state sequences, 
and include variables, first order quantification, predicates 
and the usual modal operators  and  to refer to some 
or all future states. While basic TLA does not have a \kw{quantitative} 
treating of time, in \cite{AL94} Abadi and Lamport show how to introduce 
a distinguished state variable  with a \kw{continuous} domain, representing 
the current time, so that the specification of temporal properties 
consists of formulas predicating explicitly on the values of  
in different states, thus describing its expected behavior with 
respect to the events taking place.

With reference to the resource manager example, to formally describe 
the behavior in case of a low-priority request an action  
would be introduced, describing the untimed behavior of this 
request. An \emph{action} is a predicate about two states, whose 
values are denoted by unprimed and primed variables, for the current and 
next state, respectively. Therefore, the untimed behavior of 
an accepted low-priority request would simply be to change the 
value of the state of the resource (indicated by a variable )
from free to occupied, as in the following definition.

Then, the timed behavior associated with this action would be 
specified by setting an upper bound on the time taken by the 
action, specifying that the action must happen within 2 time 
units whenever it is continuously enabled. Following the scheme 
in \cite{AL94}, a \emph{timer} would be defined by means of two formulas 
(which we do not report here for the sake of brevity: the interested 
reader can find them in \cite{AL94}). The first one defines predicate ,
which holds in all states whose timestamp (represented by the 
state variable ) is less than or equal the absolute time .
The second formula defines predicate ,
where  is an action,  is a delay,  is 
the set of all variables, and  is a state variable representing 
a timer. Then,  holds if 
and only if either action  is not currently enabled and 
 is , or  is enabled and  is  
(and it will stay so until either  occurs, or  is disabled, 
see \cite[Sec.~3]{AL94} for further details).

Finally, the timed behavior of low-priority requests would be 
defined by the following action , where  is a state variable representing 
the maximum time within which action  must occur.
  
More precisely, the formula above states that after action  is enabled,
it must occur before time surpasses value .

It is interesting to discuss how TLA solves the problem of \kw{Zeno} 
behaviors. Zeno behaviors are possible because TLA formulas involving 
time are simply satisfied by behaviors where the variable , 
being a regular state variable, does not change value. There 
are at least two mechanisms to ensure non-Zenoness. The first, 
simpler one introduces explicitly in the specification the requirement 
that time always advances, by the following formula . 
  
  An alternative \emph{a posteriori} approach, which we do not discuss
  in detail, is based on a set of theorems provided in \cite{AL94} to
  infer the non-Zenoness of specifications written in a certain
  canonical form, after verifying some semantic constraints regarding
  the actions included in the specification.

It is worth noticing that also in TLA, like in other temporal 
logics discussed above, two consecutive states may refer to the 
same time instant, so that the logic departs from the notion 
of time inherited from classical physics and from traditional 
dynamical system theory. In every timed TLA specification, it 
is thus customary to explicitly introduce a formula that states 
the separation of time-advancing steps from ordinary program 
steps (see \cite{AL94} for further details). This 
approach is somewhat similar in spirit to that adopted in TTM/RTTL. which is presented in Section \ref{sec:duallanguage}.


\paragraph{Timed Propositional Temporal Logic.}
The TPTL logic by Alur and Henzinger represents a quite interesting 
example of how a careful choice of the operators provided by 
a temporal logic can make a great difference in terms of expressiveness, 
decidability, and complexity of the verification procedures. 
TPTL may be roughly described as a ``half-order'' logic, in that 
it is obtained from propositional \kw{linear} time logic by adding 
variables that refer to time, and allowing for a \emph{freeze quantification} 
operator: for a variable , the freeze quantifier (denoted 
as ) bounds the variable  to the time when the sub-formula in 
the scope of the quantification is evaluated. One can think of 
it as the analogue, for logic languages, of clock resets in timed 
automata (see Section \ref{sec:synchronous}). The freeze quantifier is combined 
with the usual modal operators  and : if 
is a formula in which variable  occurs free, then formula 
asserts that there is some future instant, with some absolute 
time , such that  will hold in that instant; 
similarly,  asserts that 
will hold in any future instant,  being the absolute time 
of that instant.

The familiar property of the resource manager, that any low priority 
resource request is satisfied within 100 time units would be 
expressed in TPTL as follows. 


In \cite{AH94} the authors show that the logic is decidable over \kw{discrete} 
time, and define a doubly exponential \kw{decision procedure} for 
it; in \cite{AH92} they prove that adding ordinary first order quantification 
on variables representing the current time, or adding past operators 
to TPTL, would make the decision procedure of the resulting logic 
non-elementary. Therefore they argue that TPTL constitutes the 
``best'' combination of expressiveness and complexity for a temporal 
logic with \kw{metric} on time.



\subsubsection{Algebraic Formalisms} \label{sec:algebraic}
Algebraic formalisms are descriptive formal languages that focus 
on the \emph{axiomatic} and \emph{calculational} aspects of a specification. 
In other words, they are based on axioms that define how one 
can symbolically derive consequences of basic definitions \cite{Bae04,Bae03}. 
From a software engineering viewpoint, this means that the emphasis 
is on \emph{refinement} of specifications (which is formalized through 
some kind of algebraic \emph{morphism}).

In algebraic formalisms devoted to the description of concurrent 
activities, the basic behavior of a system is usually called \emph{process}. 
Hence, algebraic formalisms are often named with the term \emph{process 
algebras}. A process is completely described by a set of (abstract) 
events occurring in a certain order. Therefore, a process is 
also called a \emph{discrete event system}.

In order to describe concurrent and reactive systems, algebraic 
formalisms usually provide a notion of \emph{parallel composition} 
among different, concurrently executing, processes. Then, the 
semantics of the global system is fully defined by applications 
of the transformation axioms of the algebra on the various processes. 
Such a semantics --- given axiomatically as a set of transformations 
--- is usually called \emph{operational semantics}, not to be confused 
with operational formalisms (see Section \ref{sec:operational}).


\paragraph{Untimed Process Algebras.}
Historically, the first process algebraic approaches date back 
to the early work by Beki{\v c} \cite{Bek71} and to Milner's comprehensive 
work on the Calculus of Communicating Systems (CCS) formalism \cite{Mil80,Mil89}.
Basically, they aimed at extending the axiomatic 
semantics for sequential programs to concurrent processes. In 
this section, we focus on Communicating Sequential Processes 
(CSP), another popular process algebra, introduced by Hoare \cite{Hoa78,Hoa85} 
and subsequently developed into several formalisms. As usual, 
we refer the reader to \cite{BPS01} for a more detailed and comprehensive 
presentation of process algebras, and to the historical surveys \cite{Bae04,Bae03}.

\emph{Communicating Sequential Processes} are a process algebra 
based on the notion of \emph{communication} between processes. The 
basic process is defined by the sequences of events it can generate 
or accept; to this end the  operator is used, which denotes a 
sequence of two events that occur in order. Definitions are typically 
recursive, and infinite behaviors can consequently arise
However, a pre-defined process \textsl{SKIP} always terminates as soon as it
is executed. In the following examples we denote primitive events 
by lowercase letters, and processes by uppercase letters.

Processes can be unbounded in number, and parametric with respect 
to numeric parameters, which renders the formalism very expressive. 
We exploit this fact in formalizing the usual resource manager 
example (whose complete CSP specification is shown in Table \ref{tab:untimedCSP}) 
by allowing an unbounded number of pending high-priority requests, 
similarly to what we did with Petri nets in Section \ref{sec:petrinets}.

In CSP two \emph{choice} operators are available. One is \emph{external} 
choice, denoted by the box operator ; this is basically a 
choice where the process that is actually executed is determined 
by the first (prefix) event that is available in the environment. 
In the resource manager example, external choice is used to model 
the fact that a \textsl{FREE} process can stay idle for one transition 
(behaving as process ), or accept a high-priority request or 
a low-priority one (behaving as processes  and , respectively). 
On the other hand, \emph{internal} choice, denoted by the  operator, 
models a nondeterministic choice where the process chooses between 
one of two or more possible behaviors, independently of externally 
generated events. In the resource manager example, the system's 
process  internally chooses whether to skip once or twice 
before granting the resource to a low-priority request. A special 
event, denoted by , is used to give a semantics to internal 
choices: the  event is considered invisible outside 
the process in which it occurs, and it leads to one of the possible 
internal choices.

Concurrently executing processes are modeled through the parallel
composition operator .\footnote{  denotes the parallel composition of processes
   and  such that  only
  engages in events in ,  only engages in events in
  , and they both synchronize on events in .} In our
example, we represent the occupied resource by a parallel composition
of an  process and a counter  counting
the number of pending high-priority requests. The former process turns
back to behaving as a \textsl{FREE} process as soon as there are no
more pending requests.  The latter, instead, reacts to release and
high-priority request events. In particular, it signals the number of
remaining enqueued processes by issuing the parametric event
 (which is received by an  process,
as defined by the incoming event  of
).

\begin{table}[tbh]
\begin{center}
  
\end{center}
\caption{The resource manager modeled through CSP.}
\label{tab:untimedCSP}
\end{table}

Let us now discuss the characteristics of the process algebraic 
models in general --- and CSP in particular --- with respect to 
the time modeling issues presented in Section \ref{sec:dimensions}. 

\begin{itemize}
\item Basic process algebras usually have no \kw{quantitative} notion of 
time, defining simply an \emph{ordering} among different events. 
In particular, time is typically \kw{discrete} \cite{Bae04}. Variants 
of this basic model have been proposed to introduce metric and/or 
dense time; we discuss them in the remainder of this section.

\item The presence of the silent transition  is a way of modeling 
\kw{nondeterministic} behaviors; in particular, the nondeterministic internal 
choice operator  is based on the  event.

\item Even if process algebras include nondeterministic behaviors, 
their semantics is usually defined on \kw{linear} time models. 
There are two basic approaches to formalize the semantics of 
a process algebra: the \emph{operational} one has been briefly discussed 
above; for the \emph{denotational} one we refer the interested reader 
to \cite{Sch00}.

\item The parallel \kw{composition} operation is a fundamental primitive 
of process algebras. The semantics which is consequently adopted 
for concurrency is either based on \emph{interleaving} or it is \emph{truly asynchronous}.
Whenever interleaving concurrency is chosen, it 
is possible to represent a process by a set of classes of equivalent 
linear \emph{traces} (see the timed automata subsection of Section \ref{sec:synchronous}). 
Therefore, the semantics of the parallel composition operator 
can be expressed solely in terms of the other operators of the 
algebra; the rule that details how to do this is called \emph{expansion theorem} \cite{Bae04}.
On the contrary, whenever a truly asynchronous 
concurrency model is chosen no expansion theorem holds, and the 
semantics of the parallel composition operator is not reducible 
to that of the other operators.



\item Processes described by algebraic formalisms may include \kw{deadlocked} \emph{behaviors}
where the state does not advance as some process is blocked. 
Let us consider, for instance, the following process , 
which internally chooses whether to execute  or :

Process  may \emph{refuse} an  event offered by 
the environment, if it internally (i.e., independently of the 
environment) chooses to execute . In such a 
case,  would deadlock. It is therefore the designer's 
task to prove \emph{a posteriori} that a given CSP specification 
is deadlock-free.
\end{itemize}

Among other popular process algebras, let us just mention the 
Algebra of Communicating Processes (ACP) \cite{BW90} and other approaches 
based on the integration of data description into process formalization, 
the most widespread approach being probably that of LOTOS \cite{vEVD89,Bri89}.


\paragraph{Timed Process Algebras.}
Quantitative time modeling is typically introduced in process 
algebras according to the following general schema, presented 
and discussed by Nicollin and Sifakis in \cite{NS91}. First of all, 
each process is augmented with an \emph{ad hoc} variable that \kw{explicitly} 
represents time and can be \kw{continuous}. Time is global and all cooperating processes 
are synchronized on it. 

Then, each process's evolution consists of a sequence of two-phase 
steps. During the first phase, an arbitrarily long --- but \emph{finite} 
--- sequence of events occurs, while time does not change; basically, 
this evolution phase can be fully described by ordinary process 
algebraic means. During the second phase, instead, the time variable 
is incremented while all the other state variables stay unchanged, 
thus representing time progressing; all processes also \kw{synchronously} 
update their time variables by the same amount, which can possibly 
be infinite (divergent behavior).

Time in such a timestamp model is usually called \emph{abstract} 
to denote the fact that it does not correspond to concrete or 
physical time. Notice that several of the synchronous operational 
formalisms, e.g., those presented in Section \ref{sec:synchronous}, can also 
be described on the basis of such a time model. For instance, 
in synchronous abstract machines \emph{\`{a} la} Esterel \cite{BG92} the 
time-elapsing phase corresponds implicitly to one (discrete) 
time unit.

Assuming the general time model above, the syntax of process 
algebras is augmented with constructs allowing one to \kw{explicitly} 
refer to \kw{quantitative} time in the description of a system. This 
has been first pursued for CSP in \cite{RR88}, and has been subsequently 
extended to most other process algebras. We refer the reader 
to \cite{BM02,NS91,Bae03} --- among others --- for more references, 
while briefly focusing on Timed CSP (TCSP) in the following example.

\begin{example}[Timed CSP]
The CSP language has been modified \cite{DS95,Sch00} by extending a minimal set of operators to allow 
the user to refer to metric time. In our resource manager 
example (whose complete Timed CSP specification is shown in Table \ref{tab:timedCSP}), 
we only consider two metric constructs: the special process \textsl{WAIT}
and the so-called timed timeout .

The former is a quantitative version of the untimed \textsl{SKIP}: 
is a process which just delays for  time units. We use this 
to model explicitly the acceptance of a low-priority request, 
which waits for two time units before occupying the resource 
(note that we modified the behavior with respect to the untimed 
case, by removing the nondeterminism in the waiting time).

The timed timeout  a modification of the untimed timeout
 (not presented in the previous CSP example). The semantics of a
formula  is that of a process that
behaves as  if any of 's initial events occurs
within  time units; otherwise, it behaves as  after 
time units. In the resource manager example, we exploit this semantics
to prescribe that the resource cannot be occupied continuously for
longer than 100 time units: if no release () or high-priority
request () events occur within 100 time units, the process
 is timed out and the process  is
forcefully executed.
\begin{table}[tbh]
\begin{center}

\end{center}
\caption{The resource manager modeled through Timed CSP.}
\label{tab:timedCSP}
\end{table}
\end{example}

Finally, it is worth discussing how TCSP deals with the problem 
of \kw{Zeno} behaviors. The original solution of TCSP (see \cite{DS95}) 
was to rule out Zeno processes \emph{a priori} by requiring that 
any two consecutive actions be separated by a fixed delay of 
time units, thus prohibiting simultaneity altogether. This solution 
has the advantage of being simple and of totally ruling out problems 
of Zenoness; on the other hand, it forcefully introduces a discretization 
in behavior description, and it yields complications and lack of uniformity 
in the algebra axioms. Therefore, subsequent TCSP models have 
abandoned this strong assumption by allowing for simultaneous 
events and arbitrarily short delays. Consequently, the non-Zenoness 
of any given TCSP specification must be checked explicitly \emph{a posteriori}.

Several \kw{analysis} and \kw{verification} techniques have been developed 
for, and adapted to, process algebraic formalisms. For instance, 
let us just mention the FDR2 refinement checker \cite{Ros97}, designed 
for CSP, and the LTSA toolset \cite{MK99} for the analysis of dual-language 
models combining process-algebraic descriptions with labeled 
transition systems.



\subsection{Dual Language Approaches} \label{sec:duallanguage}
The dual language approach, as stated in the introduction 
of Section \ref{sec:descriptive}, combines an operational formalism, useful for 
describing the system behavior in terms of states and transitions, 
with a descriptive notation suitable for specifying its properties. 
It provides a methodological support to the designer, in that 
it constitutes a unified framework for requirement specification, 
design, and verification. Although a dual language approach often 
provides methods and tools for \kw{verification} (e.g., for model 
checking), we point out that effectiveness or efficiency of verification 
procedures are not necessarily a direct consequence of the presence 
of two, heterogeneous notations (an operational and a descriptive 
one), but can derive from other factors, as the case of SPIN, 
discussed below, shows. In recent years a great number of frameworks 
to specify, design and verify critical, embedded, real-time systems 
have been proposed, which may be considered as applications of 
the dual language approach. As usual we limit ourselves to mention 
the most significant features of a few representative cases.


\subsubsection*{The TTM/RTTL Framework}
The work of Ostroff \cite{Ost89} is among the first ones addressing 
the problem of formal specification, design, and verification 
of real-time systems by pursuing a dual language approach. It 
proposes a framework based on Extended State Machines and Real-Time 
Temporal Logic (ESM/RTTL). In later works, ESM have been extended 
to Timed Transition Models (TTM) \cite{Ost90,Ost99}.

The operational part of the framework (TTM) associates transitions 
with lower and upper bounds, referred to the value of a global, 
\kw{discrete} time clock variable. We briefly discussed the time model 
introduced by this formalism in Section \ref{sec:synchronous}.

Here, let us illustrate TTM through the usual resource manager
example. Figure \ref{fig:ttm} represents a system similar to the Timed
Petri net example of Section \ref{sec:petrinets}: the number of
low-priority requests is not counted, while that of high-priority ones
is. Each transition is annotated with lower and upper bounds, a
\emph{guard}, and a variable update rule. For instance, the transition
 can be taken whenever the guard  evaluates to true;
notice that we exploit an integer-valued state variable to count the
number of pending high-priority requests. The effect of  is to
update the  variable by incrementing it. Finally, when 
becomes enabled, it \emph{must} be taken within a maximum of 100 clock
ticks, \emph{unless} the state is left (and possibly re-entered) by
taking another (non tick) enabled transition (such as , which
is always enabled, since it has no guard).
\begin{figure}[htb!]
	 \centering
	 \includegraphics{ttm}
	 \caption{A resource manager modeled through a Timed Transition Model.}
	 \label{fig:ttm}
\end{figure}

The descriptive part of the TTM/RTTL framework (RTTL) is based 
on Manna and Pnueli's temporal logic: it assumes \kw{linear} time 
and it adopts the usual operators of future-only propositional 
LTL. Real-time (i.e., \kw{quantitative}) temporal properties are expressed 
by means of (in)equalities on simple arithmetic expressions involving 
the clock variable, as discussed in Section \ref{sec:temporallogics}. For instance, 
the familiar requirement that a low priority request is followed, 
within 100 time units, by the resource being occupied would be expressed 
as follows.


RTTL formulas are interpreted over TTM \emph{trajectories}, i.e., sequences of states
corresponding to TTM computations: \cite{Ost89} provides both a proof system and \kw{verification} procedures based 
on reachability analysis techniques.

The TTM/RTTL framework is also supported by the StateTime \kw{toolset} \cite{Ost97},
which in turn relies on the STeP tool \cite{BBCFMSU00}.


\subsubsection*{Model Checking Environments}
The SPIN model checking environment \cite{Hol03} is based, for the 
operational part, on B\"uchi automata, which are edited by the 
designer using a high-level notation called ProMeLa. The syntax 
of ProMeLa closely resembles that of the C programming language 
(and therefore is --- perhaps deceptively --- amenable to C programmers) 
and, in addition to the traditional constructs for sequential 
programming, provides features like parallel processes, communication 
channels, nondeterministic conditional instructions. The descriptive 
notation is plain future-only LTL, with the known limitations 
concerning the possibility to express complex properties and 
quantitative time constraints already pointed out in Section \ref{sec:temporallogics}. 
Model checking in SPIN is performed by translating the LTL formula 
expressing the required property into a B\"uchi automaton and 
then checking that the languages of the two automata (that obtained 
from the ProMeLa program and the one coming from the LTL formula) 
are disjoint. It is therefore apparent that the distinction between 
the operational and the descriptive parts is maintained only 
in the user interface for methodological purposes, and it blurs 
during verification.

UPPAAL \cite{LPY97} is another prominent framework supporting model-checking 
in a dual language approach. The operational part consists of 
a network of timed automata combined by the CCS parallel composition 
operator, and it provides both synchronous communication and 
asynchronous communication. The descriptive notation uses CTL 
in a restricted form, allowing only formulas of the kind ,
, , , and ,
where  and  are ``local'' formulas, i.e., Boolean expressions 
over state predicates and integer variables, and clock constraints.


\subsubsection*{Other Dual Language Approaches}
Among the numerous other dual language frameworks \cite{JM94} we mention \linebreak \cite{FMM94},
which combines timed Petri nets and the TRIO temporal logic: it provides a systematic
procedure for translating any timed Petri net into a set of TRIO axioms that characterize its 
behavior, thus making it possible to derive required properties 
of the Petri net within the TRIO proof system.

\cite{FM02} introduces a real-time extension of the Object Constraint 
Language (OCL, \cite{WK99}), which is a logic language that allows 
users to state (and verify through model checking) properties of transitions 
of UML state diagrams (which, as mentioned in Section \ref{sec:synchronous}, 
are a variation of Harel's Statecharts), especially temporal ones.

