\subsection{Algorithms}

In this section, we study the following VM allocation algorithms:

\begin{itemize}
\item
PABFD, a power-aware and modified best-fit decreasing heuristic \cite{Beloglazov2011}\cite{Beloglazov2012}.
The PABFD sorts the  list of $VM_{i}$ (i=1, 2,..., n) by
their total requested CPU utilization, and 
assigns new VM to any host that has a minimum increase in power consumption.

\item
VBP-Norm-LX, a family of vector packing heuristics that
is presented as Norm-based Greedy with degree X={1, 2} \cite{Panigrahy2011}.
Weights of these Norm-based Greedy heuristics use FFDAvgSum which are exp(x), which is the value of the exponential function at the point x, where x is 
average of sum of demand resources (e.g. CPU, memory, storage, network bandwidth, etc.).
VBP-Norm-LX assigns new VM to any host that has minimum of these norm values.


\item
EPOBF-ST and EPOBF-FT, presented in \cite{Quang-Hung2014}. The EPOBF-ST and EPOBF-FT algorithms sorts the list of $VM_{i}$ (i=1, 2,..., n) by their starting time ($ts_{i}$) and respectively by their finished time ($ts_{i}+dur_{i}$). Both EPOBF-ST and EPOBF-FT choose a host that has maximum of performance-per-watt to assign a new VM. The performance-per-watt is ratio of total of maximum capacity MIPS and maximum host's power consumption.

\item
MinDFT-ST and MinDFT-FT, presented in \cite{HungFDSE2014}. The MinDFT-ST and MinDFT-FT algorithms sorts the list of $VM_{i}$ (i=1, 2,..., n) by their starting time ($ts_{i}$) and respectively by their finished time ($ts_{i}+dur_{i}$). Both MinDFT-ST and MinDFT-FT allocate each VM (in a given set of VMs) to a host that has a minimum increase in total completion times of hosts.

\item
EMinRET, our proposed algorithm discussed in Section \ref{sec:schedalgo}. We evaluate the EMinRET with some its configurations:
 The EMinRET-1 sorts the list of VMs by VM's earliest starting time first and host's allocated VMs by its starting time.
 The EMinRET-2 sorts the list of VMs by VM's earliest starting time first and host's allocated VMs by its finishing times.
 The VM's finishing time, which is sum of its starting time and its duration time, is calculated by ($ts_{i}+dur_{i}$).
 The EMinRET-3 sorts the list of VMs by VM's earliest finishing time first and host's allocated VMs by its starting time.
 The EMinRET-4 sorts the list of VMs by VM's earliest finishing time first and host's allocated VMs by its finishing time.
 The EMinRET-5 sorts the list of VMs by VM's longest duration time first and host's allocated VMs by its starting time.
 The EMinRET-6 sorts the list of VMs by VM's longest duration time first and host's allocated VMs by its finishing time.
 The EMinRET-7 sorts the list of VMs by VM's latest finishing time first and host's allocated VMs by its starting time.
 The EMinRET-8 sorts the list of VMs by VM's latest finishing time first and host's allocated VMs by its finishing time.


\end{itemize}

\subsection{Methodology}

\begin{table}[htp]
\caption{Four VM type in simulations}
\label{tab:vmtype}
\centering

\begin{tabular}{|l|c|c|c|c|c|}
\hline
Type                    & \multicolumn{1}{l|}{Cores} & \multicolumn{1}{l|}{MIPS} & \multicolumn{1}{l|}{Mem. (MB)} & \multicolumn{1}{l|}{Net. (Mb/s)} & \multicolumn{1}{l|}{Storage (GB)} \\ \hline
VM1                     & 2                              & 2500                     & 871                             & 100                             & 5                             \\
VM2	 					& 1                              & 2000                     & 3840                            & 100                             & 5                             \\
VM3                     & 1                              & 1000                     & 1536                            & 100                             & 5                             \\
VM4                     & 1                              & 500                       & 613                             & 100                             & 5                             \\ \hline
\end{tabular}
\end{table}
 
\begin{table*}[htp]
\caption{Host power consumption model with CPU utilization of an typical server with 4 cores, 8192 MBytes of RAM, 10Gb/s of network bandwidth, 1TBytes of storage.}
\label{tab:HostPower}
\centering
\begin{tabular}{|l|r|r|r|r|r|r|r|r|r|r|r|}
\hline
CPU Utilization (\%) & 0\%  & 10\% & 20\% & 30\% & 40\% & 50\% & 60\% & 70\% & 80\% & 90\%  & 100\% \\ \hline
Host power (Watts)   &  93.7 &  97.0 & 101.0 & 105.0 & 110.0 & 116.0 & 121.0 & 125.0 & 129.0 & 133.0 & 135.0 \\ \hline
\end{tabular}

\end{table*}
 
\begin{table}[!h]
\centering
\caption{Result of simulations using the first 300 jobs of the HPC2N Seth log-trace \cite{HPC2NWorkload}}
\label{table:simresult-hpc2n}
\resizebox{0.5\textwidth}{!}{
\begin{tabular}{|l|c|c|c|c|}
\hline
Algorithm & \multicolumn{1}{l|}{\#Hosts} & \multicolumn{1}{l|}{\#VMs} & \multicolumn{1}{l|}{Energy (KWh)} & \multicolumn{1}{l|}{Saving (\%)} \\ \hline
(1) PABFD \cite{Beloglazov2011} (baseline)  & 10000 & 5687 & 3325.72 & 0\% \\ \hline
(2) VBP Norm L1 \cite{Panigrahy2011} & 10000 & 5687 & 3328.81 & 0\% \\ \hline
(3) VBP Norm L2 \cite{Panigrahy2011} & 10000 & 5687 & 3328.81 & 0\% \\ \hline
(4) EPOBF-ST \cite{Quang-Hung2014} & 10000 & 5687 & 2763.78 & 17\% \\ \hline
(6) EPOBF-FT \cite{Quang-Hung2014} & 10000 & 5687 & 2786.90 & 16\% \\ \hline
(7) MinDFT-ST \cite{HungFDSE2014} & 10000 & 5687 & 2651.58 & 20\% \\ \hline
(8) MinDFT-FT \cite{HungFDSE2014} & 10000 & 5687 & 2786.90 & 16\% \\ \hline
(9) EMinRET-1 & 10000 & 5687 & 2491.70 & 25\% \\ \hline
(10) EMinRET-2 & 10000 & 5687 & 2490.81 & 25\% \\ \hline
(11) EMinRET-3 & 10000 & 5687 & 2457.73 & 26\% \\ \hline
(12) EMinRET-4 & 10000 & 5687 & 2457.73 & 26\% \\ \hline
(13) EMinRET-5 & 10000 & 5687 & 1957.67 & 41\% \\ \hline
(14) EMinRET-6 & 10000 & 5687 & 1957.99 & 41\%  \\ \hline
(15) EMinRET-7 & 10000 & 5687 & 1817.62 & 45\%  \\ \hline
(16) EMinRET-8 & 10000 & 5687 & 1817.62 & 45\%  \\ \hline
\end{tabular}
}
\end{table}





\begin{table}[!h]
\centering
\caption{Result of simulations using the first 50 jobs of SDSC BLUE log-trace \cite{SDSCBLUEWorkload}.}
\label{table:simresult-sdscblue}
\resizebox{0.5\textwidth}{!}{ 
\begin{tabular}{|l|c|c|c|c|}
\hline
Algorithm & \multicolumn{1}{l|}{\#Hosts} & \multicolumn{1}{l|}{\#VMs} & \multicolumn{1}{l|}{Energy (KWh)} & \multicolumn{1}{l|}{Saving (\%)} \\ \hline
(1) PABFD  \cite{Beloglazov2011} (baseline)  & 5000 & 8368 & 729.51 & 0\% \\ \hline
(2) VBP Norm-L1 \cite{Panigrahy2011} & 5000 & 8368 & 784.04 & -7\% \\ \hline
(3) VBP Norm-L2 \cite{Panigrahy2011} & 5000 & 8368 & 784.04 & -7\% \\ \hline
(4) EPOBF-ST \cite{Quang-Hung2014} & 5000 & 8368 & 576.59 & 21\% \\ \hline
(5) EPOBF-FT \cite{Quang-Hung2014} & 5000 & 8368 & 649.23 & 11\% \\ \hline
(6) MinDFT-ST \cite{HungFDSE2014} & 5000 & 8368 & 563.27 & 23\% \\ \hline
(7) MinDFT-FT \cite{HungFDSE2014} & 5000 & 8368 & 649.23 & 11\% \\ \hline
(8) EMinRET-1 & 5000 & 8368 & 447.84 & 39\% \\ \hline
(9) EMinRET-2 & 5000 & 8368 & 447.84 & 39\% \\ \hline
(10) EMinRET-3 & 5000 & 8368 & 447.84 & 39\% \\ \hline
(11) EMinRET-4 & 5000 & 8368 & 447.84 & 39\% \\ \hline
(12) EMinRET-5 & 5000 & 8368 & 447.84 & 39\% \\ \hline
(13) EMinRET-6 & 5000 & 8368 & 447.84 & 39\% \\ \hline
(14) EMinRET-7 & 5000 & 8368 & 447.84 & 39\% \\ \hline
(15) EMinRET-8 & 5000 & 8368 & 447.84 & 39\% \\ \hline
\end{tabular}
}
\end{table} 
\begin{figure}[!ht]
    \centering
	\includegraphics[width=0.45\textwidth,height=4.4cm]{vmtime-hpc2n-300jobs.eps}
    \caption[VM's starting and finishing time of VMs]{Starting time (blue line) and finishing time (dotted red line) of VMs in simulations with HPC2N Seth log-trace \cite{HPC2NWorkload}.}
    \label{fig:vmtime}
\end{figure}



\begin{figure}[!ht]
\centering
\includegraphics[width=0.45\textwidth,height=4.4cm]{scaledenergy-chart-hpc2n-300jobs.eps}
\caption{Normalized energy. Result of simulations with HPC2N Seth log-trace.}
    \label{fig:scaledenergyresult-hpc2n}
\end{figure}

\begin{figure}[!ht]
    \centering
    \includegraphics[width=0.45\textwidth, height=4.4cm]{chart-vmtime-sdsc-blue.eps}
    \caption[Starting time of VMs]{Starting time (blue line) and finishing time (dotted red line) of VMs in simulations with SDSC Blue Horizon log-trace \cite{SDSCBLUEWorkload}. Both starting time* and finishing time* in the chart which has their values from the simulated starting and finishing time subtracts 390,000 seconds.}
    \label{fig:vmtime-sdscblue}
\end{figure}





\begin{figure}[!ht]
\centering
\includegraphics[width=0.45\textwidth,height=4.4cm]{chart-scaledenergy-sdsc-blue.eps}
\caption{Normalized energy. Result of simulations with SDSC Blue Horizon log-trace.}
    \label{fig:chart-scaledenergy-sdsc-blue}
\end{figure}

We evaluate these algorithms by simulation using the CloudSim \cite{Cloudsim} to create a simulated
 cloud data center system that has identical physical machines, heterogeneous VMs,
 and with thousands of CloudSim's cloudlets \cite{Cloudsim} (we assume that each
HPC job's task is modeled as a cloudlet that is run on a single VM). 
The information of VMs (and also cloudlets) in these simulated workloads 
is extracted from two real log-traces ( SDSC Blue Horizon log-trace \cite{SDSCBLUEWorkload}) and 
HPC2N Seth log-trace \cite{HPC2NWorkload}) 
in Feitelson's Parallel Workloads Archive (PWA) \cite{PWA} to 
model HPC jobs. When converting from the 
log-trace, each cloudlet's length is a product of the system's 
processing time and CPU rating (we set the CPU rating is equal to included VM's MIPS).
 We convert job's submission time, job's start time (if the start time is missing, then the start time is equal to sum of job's submission time and job's waiting time), 
 job's request run-time, 
 and job's number of processors 
in job data from the log-trace in the PWA
 to VM's submission time, starting time and duration time, 
 and number of VMs (each VM is created in round-robin in the four types of VMs in Table \ref{tab:vmtype} on the number of VMs). 
 Four types of VMs as presented in the Table \ref{tab:vmtype} is similar to categories in Amazon EC2's 
 VM instances: high-CPU VM, high-memory VM, small VM, and micro VM. 
 Figure \ref{fig:vmtime} shows chart of starting times and finishing times
 of the VMs in a simulation (the simulations have the same starting times and duration times of VMs).
 All physical machines are identical and each physical machine has x4 CPU cores (2660 MIPS per core),
 8192 MB of physical memory, 10 Gb/s of network bandwidth, 1 TBytes of storage.
 Power model of each physical machine is shown in Table \ref{tab:HostPower},
 which is from a typical Hewlett-Packard Company ProLiant ML110 G5 in SPECpower\_ssj2008 benchmark \cite{HPProliantG5PowerModel}.
In the simulations, we use weights as following:
(i) weight of increasing time of mapping a VM to a host: \{0.001, 0.01, 1, 100, 3600\};
(ii) weights of computing resources such as number of MIPS per CPU core, physical memory (RAM), network bandwidth, and storage respectively: 940, 24414, 1, 0.0001 respectively. 
We will discuss how to choose these values for weights of resources in another paper. 
We simulate on combination of these weights. 
The total energy consumption of each EMinRET-[1-8] is the average of five times simulation with various weights of increasing time (e.g. 0.001, 0.01, 1, 100, or 3600).


We choose PABFD \cite{Beloglazov2011} as the baseline algorithm 
because the PABFD is a famous power-aware best-fit decreasing
in the energy-aware scheduling research community.
We also compare our proposed VM 
allocation algorithms with two vector bin-packing algorithms (VBP-Norm-L1/L2) to show 
the importance of with/without considering VM's starting time and finish time 
in reducing the total energy consumption of VM placement problem.




\subsection{Results and Discussions}
\label{sec:resultsanddiscussions}

The Table \ref{table:simresult-hpc2n} shows simulation results of scheduling algorithms solving scheduling problems 
 with 5,687 VMs and 10,000 physical machines (hosts),
 in which VM's data is converted from the HPC2N Seth log-trace \cite{HPC2NWorkload}.
 The Table \ref{table:simresult-sdscblue} shows simulation results of scheduling algorithms solving scheduling problems 
  with 8,368 VMs and 5,000 physical machines (hosts),
  in which VM's data is converted from the SDSC BLUE log-trace \cite{SDSCBLUEWorkload}.
Both Figure \ref{fig:scaledenergyresult-hpc2n} and Figure \ref{fig:chart-scaledenergy-sdsc-blue} show a bar chart comparing energy consumption of VM allocation algorithms that scale with the PABFD.
None of the algorithms use VM migration techniques,
and all of them  satisfy the Quality of Service
(e.g. the scheduling algorithm provisions maximum of user VM's requested resources).
We use total energy consumption as the performance metric for
evaluating these VM allocation algorithms.
The energy saving shown in both Table \ref{table:simresult-hpc2n} and Table \ref{table:simresult-sdscblue} are the reduction of
total energy consumption of the corresponding algorithm
compared with the baseline PABFD  \cite{Beloglazov2011} algorithm.

Table \ref{table:simresult-hpc2n} shows that, compared with PABFD \cite{Beloglazov2011},
 our EMinRET with 8 configurations
 can reduce the total energy consumption by average 34.25\%, and
 average 34.25\% respectively compared with
 norm-based vector bin-packing algorithms
 (VBP-Norm-L1/L2) in simulations with the first 300 jobs of the HPC2N Seth log-trace. 
 Table \ref{table:simresult-sdscblue} shows that, compared with PABFD \cite{Beloglazov2011} 
 or norm-based vector bin-packing algorithms (e.g. VBP-Norm-L2) \cite{Panigrahy2011},
 our EMinRET-[1-8]
 reduces the total energy consumption by average 39\%
 in simulations with the first 50 jobs in the SDSC BLUE log-trace.



The PABFD generates a schedule that uses higher energy consumption than
the MinRET-ST and EMinRET-FT because of the following main reasons.
First, our hypothesis in this paper is that each VM consumes the same amount of energy 
in any physical server ($e_{i}$) and all physical servers
are identical. In consequence, the PABFD will choose a random
physical server to map a new VM. The PABFD sorts the list of VMs by decreasing requested computing power (e.g. MIPS), 
 therefore the PABFD allocates VMs that has the most requested computing power firstly. 
 In Table \ref{tab:vmtype}, a VM1-typed VM has highest requested computing power in the list, next is VM2-typed VMs, etc..
Instead, our proposed EMinRET-[1-8] algorithms assign a new VM to a physical 
server in such a way that has minimum increase of completion times and use fully all resources in physical machines.

These EMinRET-[1-8] algorithms perform
better than our previous algorithms such as MinDFT-ST/FT and EPOBF-ST/FT in the simulations. 
Compared to EPOBF-ST and EPOBF-FT, the EMinRET-[1-8] have less
total energy consumption than by average 14.2\% and respectively average 14.9\%.
The EMinRET-[1-8] have also less
total energy consumption than the MinDFT-ST and MinDFT-FT from average 10.6\% and respectively 14.9\%.
In the simulations, swapping between a new VM and its overlapped VM that is allocated to a host 
 reduce total completion time on the host. 
 For input as in Table \ref{table:example1}, the VM2 is remove from the first host, 
 the VM6 will allocated to the first host.








