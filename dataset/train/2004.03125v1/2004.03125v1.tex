\documentclass[11pt,a4paper]{article}
\usepackage{authblk}

\usepackage[hyperref]{acl2020}
\usepackage{times}
\usepackage{latexsym}
\renewcommand{\UrlFont}{\ttfamily\small}

\usepackage{microtype}

\aclfinalcopy 



\usepackage{graphicx}
\usepackage{amssymb}
\usepackage{mathtools}
\usepackage{multirow}
\newcommand\BibTeX{B\textsc{ib}\TeX}



\title{RYANSQL: Recursively Applying Sketch-based Slot Fillings\\for Complex Text-to-SQL in Cross-Domain Databases}

\author[1,2]{ DongHyun Choi}
\author[1]{ Myeong Cheol Shin}
\author[1]{ EungGyun Kim}
\author[2]{ Dong Ryeol Shin}

\affil[1]{ Kakao Enterprise, Pangyo, South Korea}
\affil[ ]{\textit {\{heuristic.c,index.sh.jason.ng\}@kakaoenterprise.com}}
\affil[2]{Sungkyunkwan University, Suwon, South Korea}
\affil[ ]{\textit {drshin@skku.edu}}

\date{}

\begin{document}
\maketitle
\begin{abstract}
Text-to-SQL is the problem of converting  a user question into an SQL query, when the question and database are given. In this paper, we present a neural network approach called RYANSQL (Recursively Yielding Annotation Network for SQL) to solve complex Text-to-SQL tasks for cross-domain databases. Statement Position Code (SPC) is defined to transform a nested SQL query into a set of non-nested \texttt{SELECT} statements; a sketch-based slot filling approach is proposed to synthesize each \texttt{SELECT} statement for its corresponding SPC. Additionally, two input manipulation methods are presented to improve generation performance further. RYANSQL achieved 58.2\% accuracy on the challenging Spider benchmark, which is a 3.2\%p improvement over previous state-of-the-art approaches. At the time of writing, RYANSQL achieves the first position on the Spider leaderboard.
 
 \end{abstract}

\section{Introduction}
Text-to-SQL is the task of generating SQL queries when database and natural language user questions are given. Recently proposed neural net architectures achieved more than 80\% exact matching accuracy on the well-known Text-to-SQL benchmarks such as ATIS, GeoQuery and WikiSQL \citep{sqlnet, typesql, incsql, dong:18, sqlova, xsql}. However, those benchmarks have shortcomings of either assuming the same database across the training and test dataset(ATIS, GeoQuery) or assuming the database of a single table and restricting the complexity of SQL query to have a unitary \texttt{SELECT} statement with a single \texttt{SELECT} and \texttt{WHERE} clause (WikiSQL). 

Different from those benchmarks, the Spider benchmark proposed by \citet{Yu:18} contains complex SQL queries with cross-domain databases. Cross-domain means that the databases for the training dataset and test dataset are different; the system should predict with an unseen database as its input during testing. Also, different from another cross-domain benchmark WikiSQL, the SQL queries in Spider benchmark contain nested queries with multiple \texttt{JOIN}ed tables, and clauses like \texttt{ORDERBY}, \texttt{GROUPBY}, and \texttt{HAVING}. \citet{Yu:18} showed that the state-of-the-art systems for the previous benchmarks do not perform well on the Spider dataset.

In this paper, we propose a novel network architecture called RYANSQL (Recursively Yielding Annotation Network for SQL) to handle such complex, cross-domain Text-to-SQL problem. The proposed approach generates nested queries by recursively yielding its component \texttt{SELECT} statements. A sketch-based slot filling approach is proposed to predict each \texttt{SELECT} statement. In addition, two simple but effective input manipulation methods are proposed to improve the overall system performance. The proposed system improves the previous state-of-the-art system by 3.2\%p in terms of the test set exact matching accuracy, using BERT \citep{Devlin:19}. Our contributions are summarized as follows.

\begin{itemize}
\item{We propose a detailed sketch for the complex \texttt{SELECT} statements, along with a network architecture to fill the slots. }
\item{Statement Position Code (SPC) is introduced to recursively predict nested queries with sketch-based slot filling algorithm.}
\item{We suggest two simple input manipulation methods to improve performance further. Those methods are easy to apply, and they improve the overall system performance significantly.}
\end{itemize}

\section{Related Works}
\label{sec:related}
Most recent works on Text-to-SQL task used encoder-decoder model. Those works could be classified into three main categories, based on their decoder outputs. Direct Sequence-to-Sequence approaches \citep{dong:16,zhong:17} generate SQL query tokens as their decoder outputs; due to the risk of generating grammatically incorrect SQL queries, the Direct Sequence-to-Sequence approaches are rarely used in recent works. 

Grammar-based approaches generate a sequence of grammar rules and apply the generated rules sequentially to get the resultant SQL query. \citet{incsql} defines a structural representation of an SQL query and a set of parse actions to handle the WikiSQL dataset. \citet{irnet} defines SemQL queries, which is an abstraction of SQL query in tree form, along with a set of grammar rules to synthesize SemQL queries; Synthesizing SQL query from a SemQL tree structure is straightforward. \citet{gnn} focused on the DB constraints selection problem during the grammar decoding process; they applied global reasoning between question words and database columns/tables.

Sketch-based slot-filling approaches, firstly proposed by \citet{sqlnet} to handle the WikiSQL dataset, define a sketch with slots for SQL queries, and the decoder classifies values for those slots. Sketch-based approaches \citet{sqlova} and \citet{xsql} achieved state-of-the-art performances on the WikiSQL dataset, with the aid of BERT \citep{Devlin:19}. However, sketch-based approach on more complex Spider benchmark \citep{rcsql} showed relatively low performance compared to the grammar-based approaches. There are two major reasons: (1) It is hard to define a sketch for Spider queries since the allowed syntax of the Spider SQL queries is far more complicated than that of the WikiSQL queries. (2) Since the sketch-based approaches fill values for the predefined slots, the approaches have difficulties in predicting the nested queries.

In this paper, a sketch-based slot filling approach is proposed to solve the complex Text-to-SQL problem. A detailed sketch for complex \texttt{SELECT} statements is newly proposed, along with Statement Position Code (SPC) to effectively predict for the nested queries.

\section{Task Definition}
\label{sec:task}
The Text-to-SQL task considered in this paper is defined as follows: Given a question with  tokens  and a DB schema with  tables and  foreign key relations , find , the SQL translation of . Each table  consists of a table name with  words , and a set of columns . Each column  consists of a column name , and a marker to check if the column is a primary key.  

For an SQL query  we define a non-nested form of , . In the definition,  is the -th SPC, and  is its corresponding \texttt{SELECT} statement. Table \ref{tbl:ex} shows an example of natural language query , SQL translation  and its non-nested form .

\begin{table}
\centering
\begin{tabular}{|c|c|l|} \hline
\multirow{2}{*}{\textbf{Q}} &\multicolumn{2}{l|}{ Find the name of airports which do not  } \\
&\multicolumn{2}{l|}{have any flight in and out.}\\ \hline
\multirow{5}{*}{\textbf{S}} &\multicolumn{2}{l|}{ \texttt{SELECT} AirportName \texttt{FROM} Airports } \\
&\multicolumn{2}{l|}{ \texttt{WHERE} AirportCode \texttt{NOT} \texttt{IN} } \\
&\multicolumn{2}{l|}{ (\texttt{SELECT} SourceAirport \texttt{FROM} Flights }\\
&\multicolumn{2}{l|}{ \texttt{UNION} } \\
&\multicolumn{2}{l|}{ \texttt{SELECT} DestAirport \texttt{FROM} Flights) }\\ \hline
\multirow{8}{*}{\textbf{N(S)}}&&[ \texttt{NONE} ] \\  \cline{2-3}
&\multirow{3}{*}{}& \texttt{SELECT} AirportName \\
 & & \texttt{FROM} Airports\\ 
  & & \texttt{WHERE} AirportCode \texttt{NOT} \texttt{IN}  \\ \cline{2-3}
&& [ \texttt{WHERE} ] \\ \cline{2-3}
&\multirow{2}{*}{}&\texttt{SELECT} SourceAirport \\ 
& & \texttt{FROM} Flights \texttt{UNION} \\ \cline{2-3}
&&[ \texttt{WHERE}, \texttt{UNION} ] \\ \cline{2-3}
&&\texttt{SELECT} DestAirport \texttt{FROM} Flights \\ \hline
\end{tabular}
\caption{Example of a user question , SQL translation , and its non-nested form .}
\label{tbl:ex}
\end{table}

\begin{figure*}
\centering
\includegraphics[width=\textwidth]{fig_encode}
\caption{Network architecture of the proposed input encoder. \raisebox{-0.5ex}{\includegraphics[height=3.3mm]{mark_1}} represents vector concatenation, \raisebox{-0.5ex}{\includegraphics[height=3.3mm]{mark_2}} represents max-pooling and \raisebox{-0.5ex}{\includegraphics[height=3.3mm]{mark_3}} represents self-attention.}
\label{fig:encode}
\end{figure*}

Each SPC  could be considered as a sequence of  position code elements, . The possible set of position code elements is \texttt{NONE}, \texttt{UNION}, \texttt{INTERSECT}, \texttt{EXCEPT}, \texttt{WHERE}, \texttt{HAVING}, \texttt{PARALLEL}. \texttt{NONE} represents the outermost statement, while \texttt{PARALLEL} means the parallel elements inside a single clause like the second element of the \texttt{WHERE} clause. Other position code elements represent corresponding SQL clauses.

Since it is straightforward to construct  from , the goal of the proposed system is to construct  for the given  and . To achieve the goal, the proposed system first sets the initial SPC , and predicts its corresponding \texttt{SELECT} statement and nested SPCs. The system recursively finds out the corresponding \texttt{SELECT} statements for remaining SPCs, until every SPC has its corresponding \texttt{SELECT} statement. 

\section{Generating a \texttt{SELECT} Statement}
\label{sec:genselect}

In this section, the method to create the \texttt{SELECT} statement for the given question , database , and SPC  is described. Section \ref{subsec:encoder} describes the input encoder; the sketch-based slot-filling decoder is described in section \ref{subsec:decoder}.

\subsection{Input Encoder}
\label{subsec:encoder}

Figure \ref{fig:encode} shows the overall network architecture. The input encoder consists of five layers: Embedding layer, Embedding Encoder layer, Question-Column Alignment layer, Table Encoder layer, and Question-Table Alignment layer. 

\paragraph{Embedding.} To get the embedding vector for a word  in question, table names or column names, its word embedding and character embedding are concatenated. The word embedding is initialized with -dimensional pre-trained GloVe \citep{pennington14} word vectors, and is fixed during training. For character embedding, each character is represented as a trainable vector of dimension , and we take maximum value of each dimension of component characters to get the fixed-length vector. The two vectors are then concatenated to get the embedding vector .  One layer highway network \citep{highway} is applied on top of this representation. For SPC , each code element   is represented as a trainable vector of dimension . 

\paragraph{Embedding Encoder.} One dimensional convolution layer with kernel size 3 is applied on SPC element embedding vectors . Max-pooling is applied on the output to get the SPC vector .  is then concatenated to each question and column word embedding vector. 

CNN with Dense Connection proposed in \citet{Yoon18} is applied to encode each word of question and columns to capture local information. Parameters are shared across the question and columns. For each column, a max-pooling layer is followed; outputs are concatenated with their table name representations and projected to dimension . Layer outputs are encoded question words , and hidden column vectors .

\paragraph{Question-Column Alignment.} In this layer, the column vectors are modeled with contextual information of the question by attending question tokens with their corresponding columns. Scaled dot-product attention \citep{transformer} is used to align question tokens with column vectors:



Where each -th row of  is an attended question vector of the -th column.

The heuristic fusion function , proposed in \citet{mnemonic}, is applied to merge  with :


Where  and  are trainable variables,  denotes the sigmoid function,   denotes element-wise multiplication and  is fused column matrix. A transformer layer \citep{transformer} is applied on top of  to capture contextual column information. Layer outputs are the encoded column vectors .

\paragraph{Table Encoder.} Column vectors belonging to each table are integrated to get the encoded table vector. For a matrix , self-attention function  is defined as follows:



Where ,  are trainable parameters. Then, for table  with columns , the hidden table vector  is calculated as follows:



Layer outputs are the hidden table vectors .

\paragraph{Question-Table Alignment.} In this layer, the same network architecture as the Question-Column alignment layer is used to model the table vectors with contextual information of the question. Layer outputs are the encoded table vectors .

\paragraph{Output.} Final outputs of the input encoder are: (1) Encoded question words , (2) Encoded columns , (3) Encoded tables , and (4) Encoded SPC . Additionally, (5) Encoded question  and (6) Encoded DB schema  are calculated for later use.

\subsubsection{BERT-based Input Encoder}
Inspired by the work of \citet{sqlova} and \citet{irnet}, BERT \citep{Devlin:19} is considered as another version of input encoder. The input to BERT is constructed by concatenating question words, SPC elements and column words as follows: \texttt{[CLS]}, , \texttt{[SEP]}, , \texttt{[SEP]}, , \texttt{[SEP]}, ..., , \texttt{[SEP]}. 

Hidden states of the last layer are retrieved to form  and ; for , the state of each column's last word is taken to represent encoded column vector. Each table vector  is calculated as a self-attended vector of its containing columns; , , and  are calculated as the same.

\subsection{Sketch-based Slot-Filling Decoder} 
\label{subsec:decoder}

\begin{table*}[hbt]
\centering
\begin{tabular}{|l|l|} \hline
\textbf{CLAUSE}&\textbf{SKETCH} \\ \hline
\texttt{FROM}& TBL})^+DIST} ( \texttt{\DIST} \texttt{\_1COL} \texttt{\DIST} \texttt{\_2COL} ) )   \\ \hline
\texttt{ORDERBY}&  ( ( \texttt{\_1AGG} \texttt{\_1ARI} \texttt{\_2AGG} \texttt{\_2ORD} )  \\ \hline
\texttt{GROUPBY} & ( \texttt{\^*NUM} \\ \hline
\texttt{WHERE} &  ( \texttt{\DIST} \texttt{\_1COL} \texttt{\DIST} \texttt{\_2COL} ) \\
\texttt{HAVING} & ~~\texttt{\COND} \texttt{\_1|SEL}  ) \\ \hline
\texttt{INTERSECT} \ & \\
\texttt{UNION} \ & \texttt{\TBL} and \texttt{\AGG} is one of \{\textbf{none}, \textbf{max}, \textbf{min}, \textbf{count}, \textbf{sum}, \textbf{avg}\}, \texttt{\COND} is one of the conditional operators \{\textbf{between}, \textbf{=}, \textbf{\textgreater}, \textbf{\textless}, \textbf{\textgreater=}, \textbf{\textless=}, \textbf{!=}, \textbf{in}, \textbf{like}, \textbf{is}, \textbf{exists}\}. \texttt{\NOT} are boolean variables representing the existence of keywords \texttt{DISTINCT} and \texttt{NOT}, respectively. \texttt{\CONJ} is one of conjunctions \{\texttt{AND}, \texttt{OR}\}. \texttt{\SEL} represents the slot for another \texttt{SELECT} statement.  }
\label{tbl:sketch}
\end{table*}

Table \ref{tbl:sketch} shows the proposed sketch for a \texttt{SELECT} statement. The sketch-based slot-filling decoder predicts values for slots of the proposed sketch.  

\paragraph{Classifying Base Structure.}  By the term \textit{base structure} of a \texttt{SELECT} statement, we refer to the existence of its component clauses and the number of conditions for each clause. We first combine the encoded vectors ,  and  to get the statement encoding vector , as follows:



Where  is a trainable parameter, and function  is the concatenation function for heuristic matching method proposed in \citet{heuristicmatching}.

Eleven values ,  and  are classified by applying two fully-connected layers on . Binary values  represent the existence of \texttt{GROUPBY}, \texttt{ORDERBY}, \texttt{LIMIT}, \texttt{WHERE} and \texttt{HAVING}, respectively. Note that \texttt{FROM} and \texttt{SELECT} clauses must exist to form a valid \texttt{SELECT} statement.  represent the number of conditions in \texttt{GROUPBY}, \texttt{ORDERBY}, \texttt{SELECT}, \texttt{WHERE} and \texttt{HAVING} clause, respectively. The maximal number of conditions , , , , and  are defined for  \texttt{GROUPBY}, \texttt{ORDERBY}, \texttt{SELECT}, \texttt{WHERE} and \texttt{HAVING} clauses, to solve the problem as -way classification problem. The values of maximal condition numbers are chosen to cover all the training cases.

Finally,  represents the existence of one of \texttt{INTERSECT}, \texttt{UNION} or \texttt{EXCEPT}, or \texttt{NONE} if no such clause exists. If the value of  is one of \texttt{INTERSECT}, \texttt{UNION} or \texttt{EXCEPT}, the corresponding SPC is created, and the \texttt{SELECT} statement for that SPC is generated recursively.

\paragraph{\texttt{FROM} clause.} A list of \texttt{\iP_\textbf{fromtbl}(i | Q,D,P)iW_1W_2s=[s_1, ..., s_t] \in \mathbb{R}^t\sigmaQDPn_tP_\textbf{fromtbl}(i)N_t=6P_\textbf{\#tbl}(n_t)n_tfull_2sN_sQW_1, W_2 \in \mathbb{R}^{d \times d}W_3 \in \mathbb{R}^{N_s \times d }V_\textbf{sel}^Q \in \mathbb{R}^{N_s \times d}N_sv^PV^QmN_sP_\textbf{sel\_col1} \in \mathbb{R}^{N_s \times m}COL} of each condition, is calculated as follows:



Where  and  are trainable parameters. The notation  is used to represent the -th row of matrix .

The attended question vectors are then updated with selected column information to get the updated question vector  :



Where  is a trainable variable, and  is defined in equation \ref{eq:hc}. The probabilities for \texttt{\_1AGG}, \texttt{\AGG} are calculated by applying a fully connected layer on .

Equation \ref{eq:col1} is reused to calculate , with  replaced by ; then  is retrieved in the same way as equation \ref{eq:updatedq}, and the probabilities of \texttt{\_2AGG} are calculated in the same way as \texttt{\_1AGG}. Finally, the \texttt{\v^SN_sn_sQORD} slot; this could be done by applying a fully connected layer on , which is the correspondence of .


\paragraph{\texttt{GROUPBY} clause.} The same network structure  as a \texttt{SELECT} clause is applied. For the \texttt{GROUPBY} case, retrieving only the values of  is enough to fill the necessary slots.

\paragraph{\texttt{LIMIT} clause.} Questions do not contain the \texttt{\QNUM} value to 1; otherwise, it tries to find the specific token for \texttt{\QP_{\textbf{limit\_top1}}v^SP^Q_{\textbf{limit\_num}}[i]iNUM} slot value, is calculated as:



, ,  are trainable parameters.

\paragraph{\texttt{WHERE} clause.} The same network structure as a \texttt{SELECT} clause is applied to get the attended question vectors , and probabilities for \texttt{\_1COL}, \texttt{\_1DIST}, \texttt{\_1AGG} and \texttt{\U^Q_\textbf{wh\_col1}CONJ}, \texttt{\COND}.

 A fully-connected layer is applied on  and  to determine if the condition value for each column is another nested \texttt{SELECT} statement or not. If the value is determined as a nested \texttt{SELECT} statement, the corresponding SPC is generated, and the \texttt{SELECT} statement for the SPC is predicted recursively. If not, the pointer network is used to get the start and end position of the value span from question tokens. 


\paragraph{\texttt{HAVING} clause.} The same network structure as a \texttt{WHERE} clause is applied.


\section{Two Input Manipulation Methods}
\label{sec:data}

\begin{table}
\centering
\begin{tabular}{|l|} \hline
\textbf{Q:} What are the papers of Liwen Xiong in 2015? \\
\textbf{SQL:} \\
\texttt{SELECT DISTINCT} t3.paperid \\
~~\texttt{FROM} writes \texttt{AS} t2 \\
~~~~\texttt{JOIN} author \texttt{AS} t1 \texttt{ON} t2.authorid  =  t1.authorid \\
~~~~\texttt{JOIN} paper \texttt{AS} t3 \texttt{ON} t2.paperid  =  t3.paperid  \\
~~\texttt{WHERE} t1.authorname  =  "Liwen Xiong"  \\
~~~~\texttt{AND} t3.year  =  2015; \\ \hline
\end{tabular}
\caption{SQL statement with link table. Table \textbf{writes} is not explicitly mentioned in , but it is used in the \texttt{JOIN} statement to link between tables \textbf{author} and \textbf{paper}.}
\label{tbl:linktbl}
\end{table}

In this section, we introduce two input manipulation methods to improve the performance of our proposed system further.

\subsection{\texttt{JOIN} Table Filtering}
In a \texttt{FROM} clause, some tables may be used only to make ``link" between other tables; Table \ref{tbl:linktbl} shows such an example. Those ``link" tables are necessary to create the proper \texttt{SELECT} statement, but they work as noise for Question-Table alignment since they do not have the corresponding tokens in . Thus, we discard those tables from \texttt{FROM} clauses during training; while inferencing, the link tables are easily recovered using foreign key relations.
 

\subsection{Supplemented Column Names}

\begin{table}
\centering
\begin{tabular}{|l|l|l|}\hline
\textbf{Table}&\textbf{Column}&\textbf{SCN} \\ \hline
\multirow{2}{*}{tv channel} & id & tv channel id \\ \cline{2-3}
& series name & tv channel series name \\ \hline
tv series & id & tv series id \\ \hline
cartoon & id & cartoon id \\ \hline
\end{tabular}
\caption{Examples of supplemented column names. \textbf{SCN} represents Supplemented Column Name.}
\label{tbl:scn}
\end{table}

We supplement the column names with its table names to distinguish between columns with the same name but belonging to different tables and representing different entities. Table names are concatenated in front of their belonging column names to form SCNs, but if the stemmed form of a table name is wholly included in a stemmed form of the column name, the table name is not concatenated.  Table \ref{tbl:scn} shows SCN examples; the three columns with the same name \textit{id} are distinguished using their SCNs.

 \section{Experiment}

\subsection{Experiment Setup}
\paragraph{Dataset.} Spider dataset \citep{Yu:18} is used to evaluate our proposed system. We use the same data split as \citet{Yu:18}; 206 databases are split into 146 train, 20 dev, and 40 test. All questions for the same database are in the same split; there are 8659 questions for train, 1034 for dev, and 2147 for test. The test set of Spider is not publicly available, so for testing our models are submitted to the data owner. For evaluation, we used exact matching accuracy, with the same definition as defined in \citet{Yu:18}.
\paragraph{Implementation.}
The proposed system is implemented with Tensorflow \citep{tensorflow2015-whitepaper}. Layernorm \citep{layernorm} and dropout \citep{dropout} are applied between layers, with a dropout rate of 0.1. Exponential decay with decay rate 0.8 is applied for every 3 epochs. On each epoch, the trained classifier is evaluated against the validation dataset, and the training stops when the exact match score for the validation dataset is not improved for 20 consequent training epochs. Minibatch size is set to 16; learning rate is set to . Loss is defined as the sum of all classification losses from the slot-filling decoder.

For BERT-based input encoding, we downloaded the publicly available pre-trained model of BERT, \texttt{BERT-Large, Uncased (Whole Word Masking)}, and fine-tuned the model during training. The learning rate is set to , and minibatch size is set to 4.

\subsection{Experimental Results}

Table \ref{tbl:eval} shows the comparisons of our system with several state-of-the-art systems; Evaluation scores for dev and test datasets are retrieved from the Spider leaderboard\footnote{https://yale-lily.github.io/spider}. The performance of the proposed system is compared with grammar-based systems GrammarSQL \citep{grammarsql}, Global-GNN \citep{gnn} and IRNet \citep{irnet}. Also, we compared the system performance with RCSQL \citep{rcsql}, which so far showed the best performance on the Spider dataset using a sketch-based slot-filling approach.

\begin{table}
\centering
\begin{tabular}{|l|c|c|} \hline
\textbf{System}&\textbf{Dev}&\textbf{Test} \\ \hline
RCSQL & 28.5\% & 24.3\% \\
GrammarSQL & 34.8\% & 33.8\% \\
IRNet&53.2\%&46.7\% \\ 
Global-GNN&52.7\%&47.4\% \\
IRNet v2(BERT)&63.9\%&55.0\% \\ \hline
\textbf{Ours}&& \\
\textbf{RYANSQL}&43.4\%&- \\
\textbf{RYANSQL(BERT)}&\textbf{66.6\%}&\textbf{58.2\%} \\ \hline
\end{tabular}
\caption{Comparison results with other state-of-the-art systems}
\label{tbl:eval}
\end{table}



As can be observed from the table, the proposed system RYANSQL improves the previous slot filling based system RCSQL by a large margin of 15\%p on the development dataset. With the use of BERT, our system outperforms the current state-of-the-art by 3.2\%p on the hidden test dataset, in terms of exact matching accuracy.

Ablation studies are conducted to further figure out the effect of SPC and the two input manipulation methods.  Since the test dataset is not publicly available, we use the development dataset to run the tests. The results are presented in Table \ref{tbl:abl}. In addition, the ablation study results of \textbf{RYANSQL(BERT)} for each hardness level is presented in Table \ref{tbl:diff}. The definitions of hardness levels are the same as the definitions in \citet{Yu:18}. In the tables, \textbf{Proposed} means our proposed system, while \textbf{-SPC} means the one without Statement Position Code, \textbf{-JTF} means the one without \texttt{JOIN} Table Filtering, and \textbf{-SCN} means the one without Supplemented Column Names. 

\begin{table}
\centering
\begin{tabular}{|l|c|c|} \hline
\multirow{2}{*}{\textbf{Approach}}&\multirow{2}{*}{\textbf{RYANSQL}}&\textbf{RYANSQL} \\
& & \textbf{(BERT)} \\ \hline
\textbf{Proposed} & 43.4\% & 66.6\% \\
- \textbf{SPC} &  38.1\% & 57.3\% \\
- \textbf{JTF} & 41.4\% & 63.9\% \\
- \textbf{SCN} & 37.7\% & 56.1\% \\ \hline
\end{tabular}
\caption{Ablation study results of \textbf{RYANSQL} and \textbf{RYANSQL(BERT)}.}
\label{tbl:abl}
\end{table}

\begin{table}
\centering
\begin{tabular}{|l|c|c|c|c|} \hline
\multirow{2}{*}{\textbf{Approach}} & \multirow{2}{*}{\textbf{Easy}} & \textbf{Med-} & \multirow{2}{*}{\textbf{Hard}} & \textbf{Extra} \\
&&\textbf{ium}&&\textbf{Hard} \\ \hline
\textbf{Proposed}&86.0\%&70.5\%&54.6\%&40.6\% \\ 
\textbf{-SPC}&85.6\%&66.6\%&27.0\%&22.4\% \\ 
\textbf{-JTF}&86.8\%&66.1\%&46.6\%&42.4\% \\ 
\textbf{-SCN}&76.4\%&58.2\%&46.6\%&30.6\% \\ \hline
\end{tabular}
\caption{Ablation study results of \textbf{RYANSQL(BERT)} for each hardness level.}
\label{tbl:diff}
\end{table}


As can be observed from the tables, the use of SPC significantly improves the system performance, especially for \textbf{Hard} and \textbf{Extra Hard} queries. The result suggests that by introducing the SPC the proposed system could effectively handle the nested queries. The \textbf{JTF} feature showed some improvements over \textbf{Medium} and \textbf{Hard} queries, meaning that the \textbf{JTF} feature is effective for handling the statements with multiple tables and clauses.

Finally, the \textbf{SCN} feature showed the most significant performance improvement among the three proposed features. When the \textbf{SCN} feature is used, the system performances of all hardness levels are improved significantly. The evaluation result suggests that our proposed input encoder network architectures do not integrate the table names efficiently during the encoding process. But the evaluation result also shows that the proposed system could successfully integrate the table names into encoding vectors by simply applying the proposed \textbf{SCN} feature, instead of modifying the network architectures.

\subsection{Error Analysis}
We analyzed 345 failed examples of the \textbf{RYANSQL(BERT)} system on the development set. 195 of those examples are analyzed to figure out the main reasons for failure.

The most common cause of failure is column selection failure; 68 out of 195 cases (34.9\%) suffered from the error. In many of those cases, the correct column name is not mentioned in a question; for example, for the question ``What is the airport name for airport `AKO'?", the decoder chooses column \texttt{AirportName} instead of \texttt{AirportCode} as its \texttt{WHERE} clause condition column. As mentioned in \citet{cellvalue}, cell value examples for each column will be helpful to solve this problem.

The second frequent error is table number classification error; 49 out of 195 cases (25.2\%) belong to the category. The decoder occasionally chooses too many tables for the \texttt{FROM} clause, resulting unnecessary table \texttt{JOIN}s. Similarly, 22 out of 195 cases (11.3\%) were due to condition number classification error. Those errors could be resolved by observing and updating the extracted slot values as a whole; our future work will focus on this problem.

The remaining 150 errors were either hard to be classified into one category, and some of them were due to different representations of the same meaning, for example: ``\texttt{SELECT} max(age) \texttt{FROM} Dogs" vs. ``\texttt{SELECT} age \texttt{FROM} Dogs \texttt{ORDER BY} age \texttt{DESC} \texttt{LIMIT} 1".

\section{Conclusion}
In this paper, we proposed a sketch-based slot filling algorithm for complex, cross-domain Text-to-SQL problem. A detailed sketch for complex \texttt{SELECT} statement prediction is proposed, along with the Statement Position Code to handle nested queries. Also, two input manipulation methods are proposed to enhance the overall system performance further. Our proposed system achieved the state-of-the-art performance on the challenging Spider benchmark dataset.

The error analysis suggests that we should update slot values based on other slots' prediction results. Our future work will focus on this slot value updating problem.


\bibliography{acl2020_sql2txt}
\bibliographystyle{acl_natbib}


\end{document}
