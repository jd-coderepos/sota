\documentclass[12pt]{article}

\usepackage{bbm}
\usepackage{ifpdf}
\usepackage{amsmath}
\usepackage{amsthm}
\usepackage{url}
\usepackage{amsfonts}
\usepackage{alltt, amssymb}
\usepackage{hyperref}
\usepackage{mathrsfs,stmaryrd}
\usepackage{graphicx}
\usepackage{color}
\usepackage{fullpage}

\def\C {\ensuremath{\mathbb{C}}}
\def\CC {\ensuremath{\mathsf{C}}}
\def\EE {\ensuremath{\mathsf{E}}}
\def\Q {\ensuremath{\mathbb{Q}}}
\def\N {\ensuremath{\mathbb{N}}}
\def\R {\ensuremath{\mathbb{R}}}
\def\r {\ensuremath{\mathbf{r}}}
\def\Z {\ensuremath{\mathbb{Z}}}
\def\F {\ensuremath{\mathbb{F}}}
\def\H {\ensuremath{\mathbb{H}}}
\def\K {\ensuremath{\mathbb{K}}}
\def\Kbar {\ensuremath{\overline{\mathbb{K}}}}
\def\A {\ensuremath{\mathbb{A}}}
\def\M {\ensuremath{\mathsf{M}}}
\def\bd {\ensuremath{\mathbf{d}}}
\def\Pp {\ensuremath{\mathbf{P}}}
\def\Ll {\ensuremath{\mathbf{L}}}
\def\Qq {\ensuremath{\mathbf{Q}}}
\def\P {\ensuremath{\mathbf{P}}}
\def\Tt {\ensuremath{\mathbf{T}}}
\def\Ss {\ensuremath{\mathbf{S}}}
\def\Uu {\ensuremath{\mathbf{U}}}
\def\Vv {\ensuremath{\mathbf{V}}}
\def\Ww {\ensuremath{\mathbf{W}}}
\def\Mm {\ensuremath{\mathbf{M}}}
\def\Nn {\ensuremath{\mathbf{N}}}
\def\bmu{\mbox{\boldmath}}
\def\bnu{\mbox{\boldmath}}

\def\mmod{\ensuremath{\mathsf{Mod}}}
\def\id{\ensuremath{\mathsf{Id}}}
\def\rev{\ensuremath{\mathsf{Rev}}}
\def\mul{\ensuremath{\mathsf{Mul}}}
\def\multrunc{\ensuremath{\mathsf{MulTr}}}
\def\mulmod{\ensuremath{\mathsf{MulMod}}}
\def\DFT{\ensuremath{\mathsf{DFT}}}
\def\IDFT{\ensuremath{\mathsf{IDFT}}}
\def\diag{\ensuremath{\mathsf{Diag}}}
\def\trunc{\ensuremath{\mathsf{Tr}}}
\def\inj{\ensuremath{\mathsf{Inj}}}
\def\trans{\ensuremath{\mathsf{Trans}}}
\def\op{\ensuremath{\mathsf{Op}}}

\def\x {\ensuremath{\mathbf{x}}}
\def\y {\ensuremath{\mathbf{y}}}
\def\v {\ensuremath{\mathbf{v}}}
\def\X {\ensuremath{\mathbf{X}}}
\def\V {\ensuremath{\mathbf{V}}}

\def\Ur {\ensuremath{\mathscr U}}
\def\Wr {\ensuremath{\mathscr W}}
\def\Vr {\ensuremath{\mathscr V}}
\def\Mr {\ensuremath{\mathscr M}}
\def\Dr {\ensuremath{\mathscr D}}
\def\Dec {\ensuremath{\mathsf{Dec}}}

\def\Ot {O\tilde{~}}
\def\eps {\varepsilon}

\newtheorem{Def}{Definition} 
\newtheorem{Theo}{Theorem}
\newtheorem{Prop}{Proposition} 
\newtheorem{Lemma}{Lemma}

\title{On the complexity of computing with zero-dimensional triangular sets}

\author{
  \begin{tabular}{cc}
    Adrien Poteaux & \'Eric Schost \\ 
    \texttt{adrien.poteaux@lip6.fr} & \texttt{eschost@uwo.ca}\\
  \end{tabular}\\
  : {\scriptsize Computer Science Department, 
    The University of Western Ontario, London, ON, Canada}\\
  : {\scriptsize UPMC, Univ Paris 06, INRIA, Paris-Rocquencourt center, SALSA Project, LIP6/CNRS UMR 7606 France}
}

\begin{document}

\maketitle

\begin{abstract}
  We study the complexity of some fundamental operations for
  triangular sets in dimension zero. Using Las-Vegas algorithms, we
  prove that one can perform such operations as change of order,
  equiprojectable decomposition, or quasi-inverse computation with a
    cost that is essentially that of {\em modular composition}. Over
    an abstract field, this leads to a subquadratic cost (with respect
    to the degree of the underlying algebraic set). Over a finite
    field, in a boolean RAM model, we obtain a quasi-linear running
    time using Kedlaya and Umans' algorithm for modular composition.

  Conversely, we also show how to reduce the problem of modular
  composition to change of order for triangular sets, so that all
  these problems are essentially equivalent.

  Our algorithms are implemented in Maple; we present some
  experimental results.
\end{abstract}








\section{Introduction}\label{sec:intro}

Triangular sets (in dimension zero, in this paper) are families of
polynomials with a simple triangular structure, which turns out to be
well adapted to solve many problems for systems of polynomial
equations. As a result, there is now a vast literature dedicated to
algorithms with triangular sets, their generalization to {\em regular
  chains}, and applications: without being exhaustive, we refer the
reader
to~\cite{Kalkbrener93,AuLaMo99,MorenoMaza00,Hubert03,Schost03,Schost03b}.

However, from the algorithmic point of view, many questions
remain. Despite a growing amount of work~\cite{LiMoSc09,
  LiMoPa09,BoChHoSc09}, the complexity of many basic operations with
triangular sets (such as set-theoretic operations on their zero-sets,
change of variable order, or arithmetic operations modulo a triangular
set) remains imperfectly understood.

The aim of this paper is to answer some of these questions, by
describing fast algorithms for several operations with triangular
sets, extending our previous results from~\cite{PoSc10}. In
particular, we will focus on the relationship between these problems
and some classical operations on univariate and bivariate polynomials,
called {\em modular composition} and {\em power projection}. To
describe these issues with more details, we need a few definitions.



\subsection{Basic definitions}\label{ssec:equiproj}

\paragraph{Triangular sets.} Let  be our base field, and let
 be indeterminates over ; we order them as .  A (monic) triangular set , for
this variable order, is a family of polynomials in  with the
following triangular structure

and such that for all~,  is monic in  and reduced modulo
, in the sense that  for ; in particular,  is a zero-dimensional
Gr\"obner basis for the lexicographic order induced by . In all that follows, we will impose the condition that  is a
perfect field; often, we will also require that 
is a radical ideal.

We write ;  will be called the
{\em multidegree} of . Define further . Then,  is the natural
complexity measure associated to computations modulo , as it represents the dimension of the residue class ring
 over~. This integer will be called the {\em degree} of
.

In all our algorithms, elements of  are represented on the
monomial basis i. Dually, all -linear forms  are represented by their values on the basis .

\paragraph{Equiprojectable sets.} Not every zero-dimensional radical ideal  in
 admits a triangular set of generators: this is the case only
when the zero-set  possesses a
geometric property called {\em equiprojectability}~\cite{AuVa00}. For
the moment, we will simply give an idea of the definition; proper
definitions are in Section~\ref{ssec:equi}.

Roughly speaking,  is equiprojectable if all fibers of the
projection  have the same cardinality, and similarly
for the further projections to .  For
instance, of the following pictures, the left-hand one describes an
equiprojectable set, whereas the right-hand one does not (since the
rightmost fiber has a larger cardinality than the others).

\begin{center}
\begin{picture}(0,0)\includegraphics{fig0a_pspdftex}\end{picture}\setlength{\unitlength}{2763sp}\begingroup\makeatletter\ifx\SetFigFont\undefined \gdef\SetFigFont#1#2#3#4#5{\reset@font\fontsize{#1}{#2pt}\fontfamily{#3}\fontseries{#4}\fontshape{#5}\selectfont}\fi\endgroup \begin{picture}(2427,2328)(589,-1630)
\put(3001,-1561){\makebox(0,0)[lb]{\smash{{\SetFigFont{8}{9.6}{\rmdefault}{\mddefault}{\updefault}{\color[rgb]{0,0,0}}}}}}
\put(901,539){\makebox(0,0)[lb]{\smash{{\SetFigFont{8}{9.6}{\rmdefault}{\mddefault}{\updefault}{\color[rgb]{0,0,0}}}}}}
\end{picture} \hspace{1cm} 
\begin{picture}(0,0)\includegraphics{fig0_pspdftex}\end{picture}\setlength{\unitlength}{2763sp}\begingroup\makeatletter\ifx\SetFigFont\undefined \gdef\SetFigFont#1#2#3#4#5{\reset@font\fontsize{#1}{#2pt}\fontfamily{#3}\fontseries{#4}\fontshape{#5}\selectfont}\fi\endgroup \begin{picture}(2427,2328)(589,-1630)
\put(3001,-1561){\makebox(0,0)[lb]{\smash{{\SetFigFont{8}{9.6}{\rmdefault}{\mddefault}{\updefault}{\color[rgb]{0,0,0}}}}}}
\put(901,539){\makebox(0,0)[lb]{\smash{{\SetFigFont{8}{9.6}{\rmdefault}{\mddefault}{\updefault}{\color[rgb]{0,0,0}}}}}}
\end{picture} \end{center}

The relationship with triangular representations is described
in~\cite{AuVa00}:  is equiprojectable if and only if its defining
ideal  is generated by a triangular set (for this equivalence, it
is required that the base field be perfect).

\paragraph{Equiprojectable decomposition.} Any finite set can be
decomposed, in general not uniquely, into a finite union of pairwise
disjoint equiprojectable sets. At the level of ideals, this amounts to
write a zero-dimensional radical ideal  as , with all
 being triangular sets and all ideals  being pairwise coprime. Of course, starting from  in
, we want all  to have coefficients in  as
well.

To solve the non-uniqueness issue, the decomposition of  into an
intersection of {\em maximal} ideals may appear as a good candidate;
however, it suffers from significant drawbacks. For instance,
computing it requires us to factor polynomials over , or
extensions of it: even if we strengthen our model by requiring that
 and its finite extensions support this operation, it is usually
prohibitively costly.

There exists another canonical way to find such a decomposition,
called the {\em equiprojectable
  decomposition}~\cite{DaMoScWuXi05}. For instance, among its useful
properties is the fact that it behaves well under specialization: if
 is the fraction field of a ring  such as
 or  and  is a maximal ideal
of , the equiprojectable decomposition of 
coincides with the equiprojectable decomposition of , reduced
modulo , for ``most'' maximal ideals~. We
refer to~\cite{DaMoScWuXi05} for more precise statements; here, we
simply point out that this property makes it for instance possible to
apply modular methods, such as Hensel lifting
techniques~\cite{Schost03,Schost03b}, to recover the equiprojectable
decomposition of  starting from that of ;
the decomposition of  into maximal ideals does not have this useful
specialization property.

While the definition of the equiprojectable decomposition is
technical, the idea is simple. We will proceed geometrically: to
obtain the equiprojectable decomposition of a finite set , we first split it using the cardinality of the fibers
of the projection . Then we apply the same
process to all the components we obtained, using the projection to
, and so on (again, we refer the reader to
Section~\ref{ssec:equi} for precise definitions).  The following
picture (from~\cite{DaMoScWuXi05}) shows the equiprojectable
decomposition of the non-equiprojectable set  of the former example.

\begin{center}
\begin{picture}(0,0)\includegraphics{fig1_pspdftex}\end{picture}\setlength{\unitlength}{2763sp}\begingroup\makeatletter\ifx\SetFigFont\undefined \gdef\SetFigFont#1#2#3#4#5{\reset@font\fontsize{#1}{#2pt}\fontfamily{#3}\fontseries{#4}\fontshape{#5}\selectfont}\fi\endgroup \begin{picture}(2427,2328)(589,-1630)
\put(3001,-1561){\makebox(0,0)[lb]{\smash{{\SetFigFont{8}{9.6}{\rmdefault}{\mddefault}{\updefault}{\color[rgb]{0,0,0}}}}}}
\put(901,539){\makebox(0,0)[lb]{\smash{{\SetFigFont{8}{9.6}{\rmdefault}{\mddefault}{\updefault}{\color[rgb]{0,0,0}}}}}}
\end{picture} \end{center}



Each component of the equiprojectable decomposition is an
equiprojectable set. As a result, this construction allows us to
represent an arbitrary finite set , defined over , by means of
a canonical family of triangular sets with coefficients in , that
depends only on the order  we have chosen on the variables. The
collection of these triangular sets will thus be denoted by
.



\subsection{Our contribution}

Our purpose is to give algorithms for various operations involving a
triangular set, or a family thereof. We will make these questions more
precise below; for the moment, one should have in mind problems such
as modular arithmetic, computation of the equiprojectable
decomposition, or change of order on the variables.

\paragraph{Two central problems.}
The following two problems, called modular composition and power
projection, will be at the heart of our algorithms.  Given a
triangular set  in , the general forms of
these questions are the following.
\begin{itemize}
\item {\em modular composition:} given  in ,
  with  for all , and  in
  , compute 
\item {\em power projection:} given a linear form ,
   in  and bounds , compute
  , for all .
\end{itemize}
In both cases, we will write  and
, so that the size of the problem is
characterized by  and . We will call
 the {\em parameters} for these questions, and
 the {\em size}. When  and
 are fixed, the two problems become linear in
respectively  and ; as it turns out, they are dual problems,
as was observed by Shoup for ~\cite{Shoup94}.

The only cases we will need actually have parameters  in
.  Besides, we will always suppose that , so that all costs can be measured in terms of
 only. However, even in this simple situation, these
questions have resisted many attempts.

As of now, no quasi-linear time algorithm is known in an algebraic
complexity model (say using an algebraic RAM, counting field
operations at unit cost). Among the best results known to us is that
both operations can be done in time ,
where  is such that matrices over  of size  can be
multiplied in time ; we assume , otherwise
logarithmic terms may appear. Using the exponent 
from~\cite{CoWi90}, this gives the subquadratic estimate
.

For , this claim follows from respectively Brent and
Kung's modular composition algorithm~\cite{BrKu78} and Shoup's power
projection algorithm~\cite{Shoup94}, which is actually the transpose
of Brent and Kung's. For power projection, extensions to parameters
 are in~\cite{Shoup99,Kaltofen00,BoFlSaSc06}, and the
case  is partially dealt with in~\cite{PaSc06}. For
completeness, in Section~\ref{ssec:basics}, we will give
straightforward extensions of the Brent-Kung and Shoup algorithms to
all cases , establishing the bound
 claimed above.

We will thus write  to denote a function such that over
any field, one can do both modular composition and power projection in
 base field operations, under the assumptions that
the parameters  are in  and .  We take  super-linear, in the sense that we require
that  holds for all
. Then, the former discussion shows that we can take .

Some further restrictions are imposed on the function . As is now
customary, we let  be such that over any ring,
polynomials of degree less than  can be multiplied in  base
ring operations; we make the standard superlinearity assumptions
of~\cite[Chapter~8]{GaGe03}. Using Cantor and Kaltofen's
algorithm~\cite{CaKa91}, we can take  in . Then, to simplify several estimates, we also make the
reasonable assumption that  is in ; this is
the case for  quasi-linear and .

\paragraph{The Kedlaya-Umans algorithm and its applications.}
In a boolean model (using a boolean RAM, with logarithmic cost for
data access), and for , it turns out that one can do much
better than in the algebraic model for modular composition and power
projection.

The best known result comes from Kedlaya and Umans'
work~\cite{KeUm10}: for , they show how to solve both problems in
 bit operations, for all
. Their algorithm uses modular techniques
(transferring the problem over  to a problem over , and vice
versa), and the idea does not seem to extend easily to an arbitrary
base field. In~\cite{PoSc10}, we described an extension of this result
to any parameters , with a running time of
 bit operations for any
; the  notation indicates the omission of
polylogarithmic factors of the form .

In this paper, we will be interested in both models, algebraic and
boolean. Now, for a given algorithm, the cost analysis in the boolean
model differs from the analysis in the algebraic model (where we only
count base field operations) by a few aspects. A minor issue is that
we should count the cost of fetching data (which grows like ,
to access the contents at address ). Another difference is that in
the boolean model, we need to take into account the boolean cost of
operations in : disregarding the cost of fetching data, any
arithmetic operations in  can be done in 
bit operations, say  for some fixed .

As a result, in what follows, in all rigor, we should prove most
statements twice, once in the algebraic complexity model and once in
the boolean one. To avoid making the paper excessively heavy, we will
indeed state our main results twice, but {\em all intermediate results
  and proofs will be given for the algebraic model}. There would
actually be no major difference in the boolean model, only some extra
bookkeeping, on the basis of the remarks in the previous paragraph.

Similarly to the algebraic case,  will thus denote a
function such that one can do both modular composition and power
projection over  using  bit
operations, assuming that the parameters  are in
 and that . As before, we require
that  holds for all . As in the algebraic case,
we will also assume that the cost of polynomial multiplication and
related operations can be absorbed into : explicitly,
we require that for any function , the function
 is in , where 
is the constant introduced above. The results of~\cite{PoSc10} imply
that we can take  in
 for any .

\paragraph{Main results.}
The questions we will consider are the following set-theoretic
operations. In all the following items, {\em all triangular sets are
  supposed to generate zero-dimensional radical ideals}.
\begin{itemize}
\item [] Given triangular sets
   and  in
  , for a variable order , and given a target
  variable order , compute the equiprojectable decomposition
   We let
   be the sum of the degrees of
   and .
\item [] Given a triangular set  in
  , for a variable order , as well as  in
   and a target variable order , compute the
  equiprojectable decompositions
   for every  in , compute also the
  inverse of  in . (Note that even if  is only defined
  modulo , the two sets above are actually
  defined unambiguously.)  In this case, we let  be the
  degree of .
\end{itemize}
These questions are general enough to allow us to solve a variety of
classical problems for triangular sets. When the initial and target
orders are the same, and when , the first question amounts to
compute the equiprojectable decomposition of a family of triangular
sets, which is a key subroutine in the algorithms
of~\cite{DaMoScWuXi05}. When the initial and target orders are
different, taking only a single triangular set  as input, the
first question allows us to perform a change of order on , and to
output a canonical family of triangular sets for the target order.
Taking the same order for input and output, the second operation
allows us to compute the {\em quasi-inverse} of a polynomial 
modulo , which amounts to split  into its
components where  vanishes, resp. is invertible.  This is an
important subroutine for triangular decomposition
algorithms~\cite{LiMoPa09}.

With that being said, our first main results are the following:
\begin{Theo}
  \label{theo:CtoE}
  In an algebraic RAM complexity model, the following holds over any
  field  of characteristic :
  \begin{itemize}
  \item if  or  is greater than , one can answer
    question  using an expected
     base field
    operations;
  \item if  or  is greater than , one can answer
    question  using an expected
     base field operations.
  \end{itemize}
  In a boolean RAM complexity model, the following holds over any
  finite field  of characteristic :
  \begin{itemize}
  \item if  is greater than , one can answer question
     using an expected  bit operations;
  \item if  is greater than , one can answer question
     using an expected  bit operations.
  \end{itemize}
\end{Theo}
Using the estimates of the previous paragraphs, the former costs are
 and , and the latter are
 and , for any .  Since
the input sizes are roughly proportional to 
(resp. ) field elements, this means that with respect to
 (resp. ), we obtain a subquadratic running time
in the algebraic model, and a quasi-linear running time in the boolean
model.

Before discussing further questions, we briefly comment on the
assumption on the characteristic of . We do need 
(resp. ) to be invertible in ; otherwise, the
algorithm will not work. The stronger requirement that
 (resp. ) are units allows us
to find random elements in  that are ``lucky'' with large
probability; if this assumption does not hold, the algorithm may still
succeed, but we lose the control on the expected running time.


The basic idea of our algorithms is from~\cite{PoSc10}: we reduce
everything to computations with univariate polynomials, since most
operations above will be easy to deal with in the univariate case. To
this end, we perform a change of representation between our input and
a univariate representation, by using repeatedly modular composition
and power projection.

This raises the question of whether better algorithms may be possible,
bypassing modular composition and power projection.  The following
theorem essentially proves that this is not the case, and that
computing the equiprojectable decomposition is essentially equivalent
to modular composition or power projection, at least for the choice of
parameter .

In what follows, let  be such that one can solve
problem  above in  base field operations
(in an algebraic model), for triangular sets in  variables. Then,
our second main result is the following.

\begin{Theo}
  \label{theo:EtoC}
  Let  be a triangular set in  variables, with ,
  that generates a radical ideal. Then, we can compute modular
  compositions and power projections modulo  with
  parameters  and size  in time
  .
\end{Theo}
\noindent In other words, if we are able to compute four-variate
equiprojectable decompositions efficiently, we can compute modular
compositions and power projections efficiently for some small values
of the parameters (which cover in particular the most useful case
, that is, computing , for univariate polynomials
). Note that an entirely similar result holds for the boolean
model as well.

\paragraph{Organization of the paper.} 
Section~\ref{sec:notation} introduces most basic algorithms used in
the paper: a reminder on modular composition and power projection for
triangular sets in one or two variables, and conversions between
univariate and triangular representations. Section~\ref{sec:CtoE}
gives an algorithm to compute the so-called -decomposition of a
zero-dimensional algebraic set , that is, a decomposition according
to the cardinalities of the fibers of a mapping . We use this in Section~\ref{ssec:equi} to prove
Theorem~\ref{theo:CtoE}; in that section, we also present experimental
results obtained with a Maple implementation. Finally,
Section~\ref{sec:EtoC} proves Theorem~\ref{theo:EtoC}.


\paragraph{Previous work.}
Let us first review previous work for the questions we consider in the
algebraic complexity model.

For a triangular set , some previous algorithms have costs of the
form  for multiplication in
~\cite{LiMoSc09} or  for computing
quasi-inverses in ~\cite{DaMoScXi06}, for  a large
constant. For multiplication, some particular cases with a better
cost are discussed in~\cite{BoChHoSc09}. An algorithm for
regularization, a similar question to quasi-inverse, is given
in~\cite{LiMoPa09,LiMoPa10}; under a non-degeneracy assumption, its
cost grows like , up
to polylogarithmic factors. In particular, all these algorithms
involve an extra factor of the form .

For change of order, previous work includes~\cite{BoLeMo01} (which
covers more general questions, e.g. in positive dimension), for which
we are not aware of a complexity analysis. A close reference to our
work is~\cite{PaSc06}: the results in that paper are restricted to the
bivariate case, but use similar techniques; our algorithms are
actually a generalization of those in~\cite{PaSc06}. 

It is worth discussing in some detail a natural approach to change of
order, based on resultant computations. In the simplest case of
bivariate systems, changing the order in a triangular set
 can be done by first computing the resultant
, so as to eliminate  --- this would of
course be only the first step of the algorithm, since we would also
have to deal with . Still, already this first step may be costly,
since the best algorithm we are aware of takes time
, which can be as large as
. An extension to triangular sets in more
variables could be done along the lines of~\cite{LiMoPa09,LiMoPa10};
roughly speaking, it may induce costs similar to the one seen above
for regularization.

For the problem of computing the equiprojectable decomposition (or
more generally, for our question ), we are not aware of
previous complexity results.

In the boolean model, relying on the results by Kedlaya and Umans
mentioned above, we showed in~\cite{PoSc10} that it is possible to
answer some of our questions in  bit operations, for any fixed
 (note that exponential terms of the form  have
disappeared).  Those results addressed multiplication in  and
some restricted forms of inversion and change of order, but did not
consider any issues related to equiprojectable decomposition.



\section{Notations and known results}\label{sec:notation}

In this section, we first recall a few results from the literature,
and describe algorithms for bivariate modular composition and power
projection (thereby proving the claim made in the introduction
regarding the cost of these operations in an algebraic model). In a
second subsection, we discuss the representation of zero-dimensional
algebraic sets by means of {\em univariate representations}, and give
some basic algorithms for this data structure.



\subsection{Basic algorithms}\label{ssec:basics}

In this subsection, we let  denote either  or
 and we consider a triangular set  in ; we write
as usual  and we let  be the zero-set
of , in either  or . We will describe a few
useful algorithms for computing in ; most of them actually
extend to , but the costs would then involve an
extra factor of the form~, for some constant .

In all this subsection, we will assume that the characteristic of 
is equal to  or greater than~.

\paragraph{Multiplication and transposed multiplication.}
Using univariate multiplication, we can do the following in
 operations in :
\begin{itemize}
\item {\em modular multiplication:} given , compute 
\item {\em transposed multiplication:} given a linear form  and , compute the linear form  defined by .
\end{itemize}
See for instance~\cite{GaSh92} and~\cite{PaSc06} for a proof.

\paragraph{Modular composition.} 
In this paragraph, we discuss modular composition with parameters
, with : given , with 
and , and given  in , this amounts to
compute . For , that is, with 
univariate and , the best-known algorithm is
due to Brent and Kung~\cite{BrKu78}. We present here a straightforward
generalization, under the simplifying assumption that . Note that solving this problem for  actually also
solves it for , by taking .


We let  and
 be positive integers such that
 and  (to be specified below), and we decompose 
into ``rectangular slices'' of the form

with each  in  and satisfying
 and
. Then, we have

with ,  and , all
equalities being modulo . This gives the
following algorithm:
\begin{enumerate}
\item Compute all powers , for , ,
  , as well as . This costs a total of
   multiplications in  (one per
  monomial).
\item We deduce all  by linear algebra: given
  ,  is obtained by doing the matrix-vector product , where  is the matrix of size  that contains the coefficients of
  all  (in columns) and
   is the column-vector of coefficients of ;
  to do it for all , we end up doing one matrix product of
  size .
\item We eventually get  by
  using Horner's scheme twice: first, to compute
  
  this is done with  multiplications modulo . Then to compute
  
  The total is  multiplications modulo
  .
\end{enumerate}
In total, we do at most  multiplications modulo  and a
matrix product of size .  We take  and , and we write .
Then, we end up with  multiplications modulo
 and a matrix product of size .  Since by
assumption , the cost is
, which
is .

\paragraph{Power projection.} 
Next, we present an algorithm to solve the power projection problem
for parameters , with . Recall that power projection takes
as input a linear form ,  and  in ,
some bounds , and outputs the sequence
.

For parameters , the algorithm is due to
Shoup~\cite{Shoup99} and an extension to  is due to
Kaltofen~\cite{Kaltofen00}; these algorithms are dual to Brent-Kung's
algorithm. As for modular composition, we present a straightforward
generalization to , with the assumption . The algorithm is obtained by simply transposing steps 2
and 3 of the modular composition algorithm (step 1 is kept as a
preprocessing phase), so the cost estimate is therefore the same.

Let  be as
above, and let again  and . For  and , let

where the ``dot'' denotes transposed multiplication. It follows that
for  and , we have
 Thus, we compute all , for , ,  and , as this gives us the values we need.
\begin{enumerate}
\item First, we compute all powers , with  and . This costs 
  multiplications modulo .  We need as well
   and , for two extra multiplications.
\item Then, we compute the linear forms  incrementally
  by  and
  ; each of them
  takes one transposed multiplication.
\item We finally compute all  by computing the matrix product ,
  where  is the same  matrix as in the modular composition case, and
   is the  matrix giving the coefficients of the
  .
\end{enumerate}



In total, we do  (transposed) multiplications modulo  and a matrix product of size . Let . With  and , we end up with 
(transposed) multiplications modulo  and a matrix
product of size . Since , the cost is
, which
is .

Together with the former algorithm for modular composition, this shows
indeed that we can take  in , as claimed
in the introduction.

\paragraph{Trace and characteristic polynomial.}
For , we let  and  be
respectively the trace and characteristic polynomial of the
multiplication-by- endomorphism of . We discuss briefly how
to compute these objects.

The trace  is actually a -linear form. Using
fast multiplication, it is possible to determine its values on the
monomial basis  of  using 
operations~\cite{PaSc06}.

Since  is a reduced algebra, by~\cite[Prop.~4.2.7]{CoLiSh98}
(sometimes called Stickelberger's Theorem), we have

We can compute  using power projection (this is well-known,
see e.g.~\cite{Rouillier99} for a presentation of this algorithm in a
more general context). We start by computing the values of the trace
 on the monomial basis . By power projection, we can then
compute the traces , for , which
are the power sums of . By our assumption on the
characteristic of , we can then use Newton iteration (for the
exponential of a power series) to deduce the characteristic polynomial
 of  in time ,
see~\cite{BrKu78,Schonhage82}. By our assumption that , we deduce that the power projection is the dominant part
of this algorithm, so the total cost is .

\paragraph{Inverse modular composition.}
A second use of trace formulas is an inverse modular
composition. Given  and  in , we want to compute a
polynomial , if it exists, such that  in
. In~\cite{PoSc10}, following ideas
from~\cite{Shoup94,Rouillier99}, we recall an algorithm that computes
a polynomial  in time , such that if  can
indeed be written as a polynomial in , then ; note that the
analysis uses the assumption that  is in ,
and our assumption on the characteristic of . Verifying whether
 can be done for another modular composition, so the total
time is 



\subsection{Univariate representations}\label{ssec:uni}

We next turn to questions related to the representation of
zero-dimensional algebraic sets. We have already introduced triangular
representations; in this subsection, we will discuss {\em univariate
  representations}, which rely on the introduction of a linear
combination of all variables, and for which most of our questions are
easy to solve.

In all that follows, the {\em degree}  of a zero-dimensional
algebraic set  simply denotes its cardinality.

\paragraph{Definition.}
Let  be a zero-dimensional algebraic set of degree
, defined over , and let  be its defining ideal.

A {\em univariate representation}  of  consists of
a polynomial , a sequence of polynomials
, with  for all
, as well as a linear form  with
coefficients in , such that

is an isomorphism: this allows one to transfer most algebraic
operations to the ring , where arithmetic is
easy. In particular, the definition implies that  is squarefree,
and that it is the characteristic polynomial of  in .
Thus, we have

and  for all  in  and .

This kind of representation is familiar: up to a few differences, it
is used for instance in
\cite{GiMo89,AlBeRoWo96,Rouillier99,GiHeMoPa95,GiLeSa01}.

We will call a linear form  a {\em
  separating element} for  if for all distinct  in ,
. One easily sees that  is separating if and
only if  admits a univariate representation of the form
, if and only if the characteristic polynomial  of
 in  is squarefree. This characterization implies the
following well-known lemma.
\begin{Lemma}\label{lemma:prob}
  If the characteristic of  is at least , and if
   are chosen uniformly at random in , the probability that  be a separating element for  is at least
  . The same remains true if  is set to  and
   are chosen uniformly at random in .
\end{Lemma}
\begin{proof}
  The above characterization implies that  is separating if and
  only if  does not cancel the polynomial
   of degree  defined by
   The
  Zippel-Schwartz lemma implies that there are at most 
  roots of  in , and the first statement
  follows. To get the second one, observe that  is
  homogeneous, so we can set  without loss of generality; the
  second statement follows.
\end{proof}

\paragraph{Useful algorithms.} We conclude this section with a few
algorithms for univariate representations. Most of what is here is
standard, or at least folklore, although the complexity statements
themselves may be new (e.g., one finds in~\cite{GiLeSa01} an
equivalent of Lemma~\ref{lemma:change} below, but with a quadratic
running time).

\begin{Lemma}\label{lemma:change}
  Given a univariate representation  of an algebraic
  set  defined over , and a linear form
   with coefficients in , one
  can decide whether  is a separating element for , and if so
  compute the corresponding univariate representation
  , in time , with
  , provided that the characteristic of  is equal
  to  or greater than .
\end{Lemma}
\begin{proof}
  Let  be as in Equation~\eqref{eq:psi}. We first compute
  ; this takes only
   operations.

  Next, we compute the characteristic polynomial  of  in
  ; as mentioned before,  is a separating
  element for  if and only if  is squarefree. We have seen that
  computing  takes time ; testing squarefreeness
  takes time , which is by assumption
  .

  When  is separating, we can use the algorithm for inverse
  modular composition, to find polynomials  such that
   holds for all ; then, we have found
  . In view of the results recalled in
  Subsection~\ref{ssec:basics} on inverse modular composition, the
  total time is .
\end{proof}

\begin{Lemma}\label{lemma:merge}
  Given univariate representations  and
   of two algebraic sets  and  defined over , one can compute univariate
  representations of either  or  in expected time , with , provided that the
  characteristic of  is equal to  or greater than .
\end{Lemma}
\begin{proof}
  The following process is repeated until success. We pick a random
  linear form  with
  coefficients in , and apply the
  algorithm of Lemma~\ref{lemma:change} to  and
  .  The cost of this step is . In
  case of success, we let  and
   be the resulting univariate representations
  of  and ; if either subroutine fails, we pick another
  .

  At this stage,  is separating for both  and .  Now,
  we compute the polynomial , as well as  and
  . We also compute
   for all . Using fast GCD and fast
  Euclidean division, this can be done in time
  , which is negligible
  compared to the cost of the first step.

  These polynomials will allow us to determine whether  is a
  separating element for . This is the case if and only if
  for any common root  of  and , the equalities
   hold for all , that is, if
   holds for all . Doing this test takes time
  ; if not all equalities hold, we pick another .
  Note that if  is separating for , it is
  separating for .

  Assuming  is a separating element for , we obtain
  a univariate representation for  by computing , where  is obtained by applying
  the Chinese Remainder Theorem to  and moduli
  , for all . Computing these polynomials takes time
  , which is again
  . Similarly, we obtain a univariate representation
  for  as .

  By Lemma~\ref{lemma:prob}, we expect to test  choices of
   (precisely, at most 2) before finding a suitable one.  As
  a consequence, the expected running time is .
\end{proof}

To conclude this section, we mention the following result about
conversions between univariate and triangular representations.

As a preliminary, remember that if  is a univariate
representation of an algebraic set , there exists an isomorphism
. If furthermore
the defining ideal of  admits a triangular set of generators 
for some variable order , we also have . As a result, there exists  change-of-basis isomorphisms
 which will be useful in the sequel.

\begin{Lemma}\label{lemma:conv}
  Let  be an algebraic set of degree ,
  defined over , and let  be its
  defining ideal; suppose that the characteristic of  is equal to
   or greater than . Let finally  be an order on the
  variables  and suppose that  is generated by a
  triangular set  for the variable order . Then the following
  holds:
  \begin{itemize}
  \item Given a univariate representation  of ,
    one can compute the triangular set  in expected time
    . Given  in , one
    can then compute  in time
    .

  \item Given , one can compute a univariate representation
     of  in expected time .
    Given  in , one can then compute  in time .
  \end{itemize}
\end{Lemma}
\begin{proof}
  We will merely describe the main ideas, so as to highlight the roles
  of modular composition and power projection. Details are given in
  \cite[Section~5.3 and~6.3]{PoSc10}, together with worked-out
  examples (the complexity analysis there is given in the boolean
  model, but carries over to the algebraic model without
  difficulty). In both directions, we proceed one variable at a time.
  \begin{itemize}
  \item In the first direction, we change (if needed) the linear form
    , so as to ensure that the coefficient of  in  is
    equal to~; this is done in expected time  by
    means of Lemmas~\ref{lemma:prob} and~\ref{lemma:change}. This mild
    condition is needed to apply the algorithm of~\cite{PoSc10}; we
    still write the input .

    Then, we let 
    be a random combination of , with coefficients
    in , whose coefficient in  is
    . We can then replace the single polynomial  by
    a bivariate triangular set
    
    where  is the squarefree part of the characteristic
    polynomial of 
    modulo . As we go, we also compute expressions of
     as polynomials in , to allow the process to 
    continue. In the second step, we introduce a triangular set
    
    in three variables , and so on until we
    obtain~.

    Using formulas from~\cite{PaSc06,PoSc10}, going from  to
     is done by means of power projections with
    parameters  and  and size , as
    well as inverse modular compositions, all computed modulo ; the total time is . The change of
    basis  is done by means of a modular
    composition with parameters  and size , computed modulo ; it takes time .

    The further steps are done in the same manner. For instance, going
    from  to 
    requires first to compute , similarly to
    what we did in the first step. Then, we obtain  by
    applying the change of basis  to all coefficients
    of .

    There are  such steps before we reach ; each takes an
    expected , so the total time is an expected
    .

    Staring from  in , we obtain its image
    in  by computing its representations in , and so on. Each conversion is done as
    above by means of modular compositions with parameters  and
    takes time ; the total number of operations is thus
    .

  \item To compute a univariate representation starting from a
    triangular set , we follow the same process
    backward. Starting from ,
    we first work with , and find a univariate
    representation for these two polynomials; this gives us the
    triangular set in  variables
    . We continue until we reach
    a single polynomial , which we will simply write .

    The polynomial  is the characteristic polynomial of a
    random combination of  with coefficients in
    , computed modulo ; all other polynomials  are
    obtained by applying the change-of-basis .

    This first step requires a power projection with parameters
    , as well as modular compositions with parameters ,
    and the cost is an expected . Since there are 
    such steps, the total cost is then an expected
    . The change-of-basis  is obtained similarly by means of modular compositions,
    and takes time .
  \end{itemize}
\end{proof}



\section{The -decomposition}\label{sec:CtoE}

In this section, we define the notions of {\em -equiprojectable}
sets and {\em -decomposition} of a zero-dimensional algebraic
set , where  is a mapping . We then give an algorithm to compute the
-decomposition of , by reducing again this problem to
(mainly) modular composition and power projection.

In what follows, we suppose that  is a zero-dimensional algebraic
subset of  of cardinality , defined over , and we
let  be its defining ideal. We
make the assumption that the characteristic of  is equal to  or
greater than .

We start with the definition of some counting functions. Let  be
a mapping , given by polynomials with coefficients
in . For  in , we let  be the cardinality of
the set : this is the number of
points  in  such that . Then, we say that
 is {\em -equiprojectable} if there exists a positive integer
 such that for all  in , .

In general, we should not expect  to be -equiprojectable.
Then, we define

this is the set of all  with  points in their
-fiber. Since  is finite,  takes only
finitely many values on , say .  As a
consequence, the sets

form a partition of ; by construction, all these sets are
-equiprojectable. We will write
 and we will call this
decomposition the {\em -decomposition} of .  Although it may
not be clear from our definition, all  are in fact defined
over .

\begin{Lemma}\label{lemma:def}
  With notation as in~\eqref{eq:Vri},  are
  defined over .
\end{Lemma}
\begin{proof}
  We are going to prove that for any ,
   is defined over
  .  Since , and since
  the set-theoretic difference of two zero-dimensional algebraic sets
  defined over  is still defined over , this will be
  sufficient to establish our claim.

  Fix , and let  be the -fold product ; obviously,  is defined
  over . Let  be the coordinates on
  , where each  has length , and let
   where
   is defined by . Again,  is
  defined over , and  is in  if and
  only if all  are in  and pairwise distinct. Finally, we
  define
  
  then,  is the projection of  on the first
  factor , so it is indeed defined over , as claimed.
\end{proof}

Before discussing an algorithm that computes , we prove
a simple lemma that will be used in the next section.
\begin{Lemma}\label{lemma:comp}
  Consider two mappings  and , such that , for some mapping , and suppose that  is
  -equiprojectable. Then any  in  is both
  -equiprojectable and -equiprojectable.
\end{Lemma}
\begin{proof} Let  be the common cardinality of the fibers of the
  restriction of  to . Let further  be in ,
  and let  be in . We will show that ,
  thereby establishing that  is -equiprojectable ( is
  -equiprojectable by construction).
  
  Remember that  is the cardinality of the fiber
  . We claim that we actually
  have , with . Since by
  assumption , proving  is sufficient to prove that
  .

  Of course,  is a subset of . Conversely, let  be in .
  Then,  and our assumption on  and 
  implies that . This implies that  is in
  , as claimed.
\end{proof}

We now explain how to compute .  For simplicity, we will
assume that , and that  is a simple linear map (the
algorithm would not be substantially different in general, but a few
extra terms could appear in the cost analysis).
\begin{Prop}\label{prop:dec}
  Consider an algebraic set  defined over  and
  of degree , and a univariate representation
   of , and let
  . Suppose that the following
  conditions are satisfied:
  \begin{itemize}
  \item the characteristic of  is equal to  or greater than
    ,
  \item  is a linear map , of the form
    .
  \end{itemize}
  Then we can compute univariate representations  of  in expected time
  .
\end{Prop}
The rest of this section is devoted to prove this proposition. In what
follows, we write  and, for all ,
. We also write , with all
 in . Since for all  in  we have
, we deduce that
 for  in .

\paragraph{Step 1.}
Choose a random linear form  with
coefficients in , compute , and compute the characteristic polynomial
 of  in . Computing  takes
time  and computing its characteristic polynomial takes
time , see Subsection~\ref{ssec:basics}.

The linear form  must be a separating element for . To verify
if this is the case, we check whether  can be written
as polynomials in  modulo . This is done using the algorithm for
inverse modular composition, and takes time , which
is . Due to our assumption on the characteristic of
, we need to test an expected  choices of  before
finding a separating element, see Lemma~\ref{lemma:prob}.

Remark that for  in , .

\paragraph{Step 2.} Compute the squarefree decomposition of
; this takes times ,
see~\cite[Chapter~14]{GaGe03}.  Using the previous notation, we claim
this decomposition has the form

Indeed, by Stickelberger's Theorem, we have the factorization
2mm]
  &=& \prod_{\x \in V} (X-\nu(\phi(\x))).
\end{array}

\begin{array}{rcl}
  \chi_N&=& \prod_{\y \in W} (X-\nu(\y))^{r(\y)} \
since by construction the projections  are pairwise
disjoint. As  is separating for , the linear factors
 are pairwise distinct, which proves our claim.

For future use, note that , since
 has degree .

\paragraph{Step 3.} For , compute .  We
will prove at the end of the section that this can be done in time
. That proof will be somewhat lengthy; for
the moment, we will only prove that for , we have

Both sides are squarefree (since they divide ), so to prove our
claim it is enough to prove that the roots of  are exactly the
values  for  in . As a preliminary remark,
recall that for all  in , we have .
\begin{itemize}
\item For  in ,  is in
   so  is a root of . By the remark
  above, this shows that  is a root of . But of
  course  is also a root of , so  is a root of
  .
\item Conversely, consider a root  of . Since any root of
   is a root of ,  is of the form  for some
   in . But by assumption  is also a root of
  , which means that  is a root of .  In
  particular,  is a root of no other , because
  these polynomials are pairwise coprime. This implies that 
  belongs to no other , so it must belong to ; thus,
   is in .
\end{itemize}
Note also that we have , all  being pairwise coprime.

\paragraph{Step 4.} For  and , compute . This can be done in time  using fast multiple
reduction~\cite[Chapter~10]{GaGe03}, which is .
Writing , Eq.~\eqref{eq:pk} shows that
for ,  is a univariate representation of
, so we are done.

\paragraph{Analysis of Step 3.} Summing all the costs mentioned above
gives the cost estimate claimed in Proposition~\ref{prop:dec}.  All
that is missing is to prove that, as announced, the cost of computing
the polynomials  of Step~3 is .

Recall that for all , . We cannot compute
the polynomials , or even , as there are too
many of them: one easily sees that  could be as large as
; each polynomial  requires to store
 field elements, so computing all of them would take time at
least .

Therefore, we compute the  directly, using divide-and-conquer
techniques. Given polynomials , we will write
 so that the polynomials we want to compute are
. 

Assuming we know , Definition~\eqref{eq:gamma2} shows that
we can compute  by computing first , then taking its GCD with . Since by assumption 
is , we can thus obtain  in time 
by modular composition and fast GCD, with ;
we will call this the {\em plain algorithm}. In particular, we could
compute any  in time . However, as we mentioned
above, computing all  directly in this manner incurs a cost of
the form , which is too much for our purposes.

The key equality we will use is the following: for any polynomials
, we have

Indeed, using Definition~\eqref{eq:gamma1}, the left-hand side
reads

whereas the right-hand side is

equality~\eqref{eq:gamma} follows from the fact that
 holds for all polynomials
.

We are now ready to explain how to complete Step~3.  To simplify our
presentation, we will assume that  is a power of two, of the form
; when this is not the case, we can complete  by
dummy polynomials , so as to replace  by the next power of
two, without affecting the asymptotic running time.

\bigskip\noindent{\em Step 3.1.~} We compute the {\em subproduct tree}
(see details below) associated to
. From~\cite[Chapter~10]{GaGe03}, this can be done in
time , since we have seen that . Using our assumption on  and ,
this is in .

At the top level of the subproduct tree, the root is labelled by
; its two children are labelled by  and  with , and so
on. For , the polynomials the th level are written
, with , so that . At the leaves, for , we have .

In what follows, we are going to compute all polynomials
, for  and , in a
top-down manner. At the leaves, for , we will obtain the
polynomials  we are looking for.

\bigskip\noindent{\em Step 3.2.~} We compute
 using the plain algorithm, in
time , as well as  in
time , by fast Euclidean division. The latter cost is
negligible.

\bigskip\noindent{\em Step 3.3.~} For  and
, assuming we know  and , we compute
 followed by
 Our claim is twofold:
first, we will prove that  for all
; second, we will establish that the total running time is
. Note that this is enough to finish the
proof of Proposition~\ref{prop:dec}, since we have seen that for
, we have .

The proof that ) is done by induction
on . By definition, this is true for ; for ,
this follows from Equation~\eqref{eq:gamma}, first taking
,  and , then ,
 and .  Since  and
 divide , we can also prove by
induction that  holds for all .

It remains to do the cost analysis. Since  is known, we can indeed compute  and
 from  and 
by the plain algorithm in time , where we write
 The computation of
 and  can be done in time
, which is negligible by assumption.
Hence, the total cost is, up to a constant factor,
 This admits the
obvious upper bound

Using the super-linearity of , we obtain the upper bound
 To conclude the
cost analysis, we will prove the inequalities

These inequalities imply a cost upper bound of the form
, up to a constant factor. The claim
on the total cost follows, since  is in .
\begin{itemize}
\item The first inequality 
  is a straightforward consequence of the equality , which itself follows from
  the definition of the subproduct tree, and the fact that .
\item To obtain the second inequality , we start by proving that for fixed
  , and for ,  and  are
  coprime. Indeed, we have seen that
   where  has the form
  . Here, 
  is a set of indices which we will not need to make explicit;
  however, for further use, we note that for ,
   and  are disjoint. The factorization
  of  implies that
  
  Recall now that the polynomials  are
  pairwise coprime; as a result, the former equality gives
   Since for fixed  the sets
   are pairwise disjoint, and since the polynomials
   are pairwise coprime, we deduce that for fixed , the
  polynomials  themselves are pairwise coprime, as
  claimed.

  Since by construction all  divide , the product
   must divide  as well, and the
  inequality  follows.
\end{itemize}



\section{Proof of Theorem~\ref{theo:CtoE}}\label{ssec:equi}

In this section, we prove Theorem~\ref{theo:CtoE}.  We start by
defining equiprojectable sets and the equiprojectable
decomposition. The algorithms underlying Theorem~\ref{theo:CtoE} are
then straightforward applications of the results of the previous
section.



\subsection{The equiprojectable decomposition}

Let  be a zero-dimensional algebraic set defined
over . We suppose that we are given an order  on the variables;
up to renaming them, we can suppose that the order is simply . For , we define the projection

Then, we say that  is equiprojectable if it is
-equiprojectable for ; in other words,  is
equiprojectable if all fibers of  on  have a common
cardinality , all fibers of  on  have a common
cardinality , etc.

In general, we should not expect  to be equiprojectable. There are
potentially many ways to decompose  into equiprojectable sets; the
equiprojectable decomposition will be a canonical partition of 
into pairwise disjoint equiprojectable sets, that will all be defined
over .

We will actually define a sequence , for ,
which will all be partitions of , refining one another. At index
, we write . Then, for , assuming that we
have defined

we obtain  by computing the -decomposition of
every element in :
 
which we rewrite as 
An easy
decreasing induction proves that for  and ,
every  is -equiprojectable for :
\begin{itemize}
\item For ,  is simply , which is
  -equiprojectable (since  is the identity).
\item For , assuming that the claim holds for , we
  prove it for . To do so, it is enough to take
   in  and prove that every  in
   is -equiprojectable, for
  .

  Obviously,  is -equiprojectable. Besides, since by the
  induction assumption  is -equiprojectable for
  , Lemma~\ref{lemma:comp} implies that  is also
  -equiprojectable for .
\end{itemize}
Taking ,  is the {\em equiprojectable decomposition}
of ; we will actually denote it by . Dropping the
subscript , we will write
 This is thus a decomposition of 
into pairwise disjoint equiprojectable sets .

Aubry and Valibouze proved in~\cite{AuVa00} that an algebraic set is
equiprojectable if and only if its defining ideal is generated by a
triangular set. Besides, by Lemma~\ref{lemma:def}, each  is
defined over ; thus, its defining ideal is generated by a
triangular set  in . As said in the introduction,
we will write  to denote the collection of the triangular
sets . In ideal-theoretic terms, the
ideals  are thus pairwise coprime, and their
intersection is the defining ideal  of , so that .



\medskip

The following proposition gives a cost estimate on the computation of
the equiprojectable decomposition, using a univariate representation
as input.
\begin{Prop}\label{lemma:equi}
  Let  be a zero-dimensional algebraic set defined
  over , of degree . If the characteristic of  is
  equal to  or greater than , given a univariate
  representation  of , we can compute
   in expected time
   Besides, the following change of
  bases can be done in time :
  \begin{itemize}
  \item given  in , compute its images
     in ;
  \item given  in , compute their preimage  in .
  \end{itemize}
\end{Prop}
\begin{proof}
  Let us write as before .  The
  algorithm to compute  proceeds in two steps: first, we
  compute univariate representations of all ; secondly, we
  convert them into triangular sets. As we go, we also explain how to
  perform the change of basis from  to , and back.

  \paragraph{Step 1.} Recall the definition of the sequence
  : we have  and starting from
    
    we set
     The
    first step of the algorithm follows the same loop, and computes
    univariate representations of all . We set
    , and for , we let
     be the univariate representations
    obtained by applying the algorithm of Proposition~\ref{prop:dec}
    to  and . If
     denotes the degree of , applying the
    algorithm of Proposition~\ref{prop:dec} to  and
     takes an expected time
    
    Using the super-linearity of , and the fact that
     the time
    spent at index  is seen to be an expected
     Summing over all , the total
    time is an expected
    

    Let  be the characteristic polynomial of , and let
     be those of
    . Since the separating elements of
     and  are the same, we have
    . The change of basis  is done by multiple reduction, and the inverse
    conversion is done using the Chinese Remainder Theorem. Using the
    results of~\cite[Chapter~10]{GaGe03}, both conversions take time
    , which is .

    \paragraph{Step 2.} Starting from ,
    we now compute the corresponding triangular sets
    . This is done by applying
    Lemma~\ref{lemma:conv}, which shows that we can compute each
    triangular set  in expected time ,
    where  is the degree of . Summing over all  and
    using the super-linearity of the function  gives a total
    expected time of .

    Using the notation of Subsection~\ref{ssec:uni}, the conversion
     and its inverse are done by applying
    
    By Lemma~\ref{lemma:conv}, and using the super-linearity of
    , each conversion takes time .
  \end{proof}



  \subsection{Solving question }\label{ssec:P1}

  We can now show how to solve question  stated in the
  introduction.  Given triangular sets 
  and  for an order , and a target order
  , we want to compute  with
 We let  be the sum of the degrees of
 and  and we
make the assumption that the characteristic of  is equal to  or
greater than .

Our strategy is to reduce to univariate representations, perform the
set theoretic operations on univariate polynomials, and finally
compute the equiprojectable decomposition for the new order.

\paragraph{Step 1.} We compute univariate representations
 and  of respectively
 and
. By Lemma~\ref{lemma:conv}, this can
be done in expected time
 where  is the degree of
 and  is the degree of .  Using the
super-linearity of , this is seen to be an expected .

\paragraph{Step 2.} We compute univariate representations  of
 and  of
. The following
divide-and-conquer process takes an expected time
 to achieve this task.

We apply repeatedly the union algorithm of Lemma~\ref{lemma:merge} to
, respectively . To compute
say , we let , and we compute
recursively univariate representations of
 then, these two
univariate representations are merged by means of
Lemma~\ref{lemma:merge}. The running time analysis is the same as in
the proof of Proposition~\ref{prop:dec}: the divide-and-conquer
structure of the algorithm induces the loss of a logarithmic factor,
as is the case for other algorithms with the same
structure~\cite[Chapter~10]{GaGe03}.

\paragraph{Step 3.} By another application of Lemma~\ref{lemma:merge}
to  and , this time for computing a set-theoretic
difference, we finally obtain a univariate representation  of
. This takes an expected time .

\paragraph{Step 4.} Starting from , we compute  using
the algorithm of Proposition~\ref{lemma:equi}.  This takes an expected
time 

\medskip

The total cost of this algorithm is an expected , as claimed in Theorem~\ref{theo:CtoE}.



\subsection{Solving question }\label{ssec:P2}

Next, we show how to solve question  stated in the
introduction. Given a triangular set  in , for
a variable order , as well as  in  and a target variable
order , we are to compute the equiprojectable decompositions

as well as the inverse of  modulo each  in . We let  be the degrees of  and we make the
assumption that the characteristic of  is equal to  or greater
than~.

Our strategy is similar to the one of the previous subsection: we
convert to a univariate representation, operate with univariate
polynomials, and convert back to triangular representations.

\paragraph{Step 1.} We compute a univariate representation
 of  and . By
Lemma~\ref{lemma:conv}, this can be done in expected time .

\paragraph{Step 2.} We compute  and ,
as well as the inverse  of  modulo  (this
inverse exists, since  is squarefree). This takes time
, which is .

The roots of  describe the points of  where  vanishes;
the roots of  describe those where  is nonzero.

\paragraph{Step 3.} Writing , we compute  and  for all , and we define
 and
. This takes time
, which is negligible compared to the cost of Step~1.

Note that  is a univariate representation of ,
and that  is a univariate representation of .

\paragraph{Step 4.} Starting from  and  we compute
the equiprojectable decompositions  and
 using the algorithm of
Proposition~\ref{lemma:equi}.  This takes an expected time
 Besides, using the second part of
Proposition~\ref{lemma:equi}, we can compute the image of  in
each , for  in . This image is
the inverse of  in .

\medskip

As for question , the total cost of this algorithm is an
expected , as claimed in
Theorem~\ref{theo:CtoE}.



\subsection{Experimental results}

This section reports on experimental results obtained with a Maple
implementation of the algorithms of Subsection~\ref{ssec:P1}
and~\ref{ssec:P2}.

Our implementation supports inputs with coefficients in finite fields
of the form ,  prime. This is the most natural choice, since
over base fields such as  or rational function fields, the cost of
arithmetic operations in the base field cannot be assumed to be
constant. For inputs defined over e.g. , the natural approach
would be to use modular methods, using for instance lifting techniques
(for which the equiprojectable decomposition is particularly well
suited, as we pointed out in the introduction).

Over base fields such as , we have two choices for modular
composition and power projection: algorithms following Brent and
Kung's idea, as described in Section~\ref{ssec:basics}, or the
extension of the Kedlaya-Umans algorithm given in~\cite{PoSc10}.
Unfortunately, even though the latter is asymptotically better, the
large constants hidden in the  notation make it inferior for the
range of degrees we consider. Thus, our implementation relies on the
Brent-Kung approach.

Other than modular composition and power projection, our algorithms
use only univariate and bivariate polynomial arithmetic. As a result,
they were implemented using the {\tt modp1} functions, which provide
fast implementations of arithmetic operations in , for  a
word-size prime.

The following timings are obtained using Maple 15 on an 2.8 GHz AMD
Athlon II X2 240e processor. The base field is , with
. All timings are in seconds, and all computations were
interrupted whenever they used 2Gb of RAM or more.

Our first experiments concern the particular case of question ,
where the input and the target order are the same, and . In other
words, we take as input some triangular sets
 for an order , and we compute the
equiprojectable decomposition of
 for the same order.
In Table~\ref{table1}, we shows comparisons with the function {\tt
  Equi\-projectableDe\-com\-position} of the {\tt RegularChains}
library~\cite{LeMoXi05}, which has similar specifications
(we are not aware of other implementations of such an algorithm).

In each sub-table, the number  of variables is fixed; we show
timings for the equiprojectable decompositions of sets of points of
cardinality ; the column  gives an upper bound on all 
that appear as main degrees in the triangular sets in the output.  In
almost all cases, our implementation does better than the built-in
function; the fact that we are relying on the {\tt modp1} functions is
certainly a key factor for this.

\begin{table}
  \caption{Timings for equiprojectable decomposition}\label{table1}
  \begin{center}
  \begin{tabular}{cc}
  \begin{tabular}{c|c|c||c|c}
     &  &  & us & Maple \\ \hline
    3& 2& 4&  0.03 & 0.03 \\
    3& 3& 10& {0.07}& 0.12\\
    3& 4& 20& {0.12} & 0.52 \\
    3& 5& 35& {0.22} &1.6 \\
    3& 6& 56& {0.44} & 4.2
  \end{tabular}
&
  \begin{tabular}{c|c|c||c|c}
     &  &  & us & Maple \\ \hline
4& 2& 5 & 0.06 & {0.05} \\
4& 3& 15 & {0.2} & 0.4\\
4& 4& 35 & {0.3} & 2.1\\
4& 5& 70 & {0.8} & 8.4\\
4& 6& 126 & {1.9} & 40
  \end{tabular} 
\\
\\
  \begin{tabular}{c|c|c||c|c}
     &  &  & us & Maple \\ \hline
5& 2& 6 & 0.09 & {0.08}\\
5& 3& 21 & {0.37} & 0.96\\
5& 4& 56 & {0.81} & 6.5\\
5& 5& 126& {2.4} & 45 \\
5& 6& 252& {9.5} & 512
  \end{tabular}
&
  \begin{tabular}{c|c|c||c|c}
     &  &  & us & Maple \\ \hline
6& 2& 7 & 0.15 & {0.13} \\
6& 3& 28& {0.5} & 2.1\\
6& 4& 84& {1.8} &19\\
6& 5& 210& {8.2} & 300\\
6& 6& 462& {49} & 5885
  \end{tabular} 
  \end{tabular}
  \end{center}
\end{table}

Our second experiments address inverse computation modulo a triangular
set, which is a particular case of question : the input and
the target order are the same, and (by construction of our examples),
no splitting occurred. In other words, we take as input a triangular
set  and , invertible in ; we output the
inverse of  in .

In Table~\ref{table2}, we give examples for various situations: 
 denotes the number of variables and  is such that 
the input triangular set has multidegree , of length ;
thus, its degree  is . 

We show comparisons with the function {\tt Inverse} of the {\tt
  RegularChains} library. This function may induce splittings; if we
wanted the same output as in our implementation, we would also have to
perform a recombination after the call to {\tt Inverse} (we did not
include this step in the timings). As in the previous example, our
code usually does better.

We also include timings obtained by using the C {\tt modpn}
library~\cite{LiMoRaSc09}, which can be called from a Maple
session. Obviously, we expect this compiled library to be much faster
than our interpreted code; however, timings are sometimes within a
factor of 10 or less, which we see as a sign that our implementation
performs well. Note that {\tt modpn} relies on FFT techniques, as a
result, only those finite fields  with suitable roots of unity
are supported (the field  in our examples is one of them).

\begin{table}
  \caption{Timings for inversion in }\label{table2}
  \begin{center}
  \begin{tabular}{cc}
  \begin{tabular}{c|c|c||c|c|c}
     &  &  & us & {\tt Inverse} & {\tt modpn} \\ \hline
3& 2& 8 & 0.04 & 0.3 & 0.01\\
3& 3& 27 & 0.06 & 1.4 & 0.01\\
3& 4& 64 & 0.14 & 5.2 & 0.02\\
3& 5& 125& 0.24& 6.1 & 0.05\\
3& 6& 216& 0.75& 21 & 0.06
  \end{tabular}
&
  \begin{tabular}{c|c|c||c|c|c}
     &  &  & us & {\tt Inverse} & {\tt modpn} \\ \hline
4& 2& 16& 0.07& 1.1& 0.01\\
4& 3& 81& 0.2 & 4.8 &0.06\\
4& 4& 256& 1& 600 & 0.1\\
4& 5& 625& 5.3& 10536& 0.8\\
4& 6& 1296& 23&  Gb& 1.2
  \end{tabular} 
\\
\\
  \begin{tabular}{c|c|c||c|c|c}
     &  &  & us & {\tt Inverse} & {\tt modpn} \\ \hline
5& 2& 32  & 0.14 & 210 & 0.03\\
5& 3& 243  &1 & 1576 & 0.42\\
5& 4& 1024 &1.5&  Gb &1.2\\
5& 5& 3125 &151 &   Gb & 24\\
5& 6& 7776 &1007 &   Gb & 37
  \end{tabular}
&
  \begin{tabular}{c|c|c||c|c|c}
     &  &  & us & {\tt Inverse} & {\tt modpn} \\ \hline
6& 2& 64 & 0.3 &  Gb & 0.1\\
6& 3& 729 & 8.8 &  Gb & 4.6\\
6& 4& 4096 & 273 &  Gb & 18\\
6& 5& 15625 & 5099 &  Gb &661\\
6& 6& 46656 & 67339 &  Gb& 1135
  \end{tabular} 
  \end{tabular}
  \end{center}
\end{table}






\section{The converse reduction}\label{sec:EtoC}

This section is mostly independent from the other ones. In the
previous sections, we used modular composition and power projection as
our basic subroutines, and reduced other questions to these two
operations. In this section, we will do the opposite, by reducing
modular composition and power projection to equiprojectable
decomposition.



As mentioned in the introduction, modular composition and power
projection are dual problems. An algorithmic theorem called the {\em
  transposition principle} shows that an algorithm for the former can
be transformed into an algorithm for the latter, and
conversely~\cite{BuClSh97,BoLeSc03}: this result could in principle
allow us to deal only with e.g. modular composition. However, it
applies only in a restricted computational model (using {\em linear
  programs}), which is not suited to questions such as decompositions
of triangular sets (which are inherently non-linear). As a result, we
give explicit reductions for both modular composition and power
projection.

In the introduction, we defined  as a function such
that one can solve problem  (computing the equiprojectable
decomposition of a family of triangular sets in  variables, with
sum of degrees ) using  base field operations.

Recall then the statement of Theorem~\ref{theo:EtoC}: we take
 or , and we let  be a triangular set
in  variables that generates a radical ideal. Then, we can compute
modular compositions and power projections modulo  with parameters  and size  in time .

The two subsections address respectively modular composition and power
projection. In both cases, we can assume that , since any
triangular set in one variable (that is, any polynomial )
can be seen as a triangular set in two variables, by adding a dummy
polynomial . Note that the proofs would generalize
to computations in more than two variables, and would involve terms of
the form .



\subsection{Modular composition}



Following the previous discussion let thus  be a
triangular set in ,  in , and  in ,
of degree . We show here how to compute
, using change of order as our main subroutine.

Consider the triangular set (for the order )

let  be its zero-set, and let us compute , where  is the order . We obtain a family of
triangular sets  of the form

Let now  be the ideal generated by the polynomials (which do not
form a triangular set, since the first polynomial is not reduced)

After reduction, we see that  is generated by the triangular set
(for the order )

where  is the polynomial we want to compute. On the other hand, the
construction of the triangular sets  shows that  is the
intersection of the ideals
generated by the triangular sets  (for the order ) given by

with . The algorithm is then the following:
\begin{itemize}
\item First, we compute all triangular sets . Since 
  generates a radical ideal, this can be done in  base field operations (obviously,  holds for all , as can be seen by using
   dummy polynomials to obtain a triangular set in 
  variables).
\item Next, we compute all triangular sets . This requires
  us to compute all . Since , and since
  the sum of the degrees of the  is at most  as well,
  all  can be computed in time
   using fast multiple
  reduction~\cite[Chapter~10]{GaGe03}.
\item Finally, we compute , and thus , by computing the
  equiprojectable decomposition of , for the order . Again, this takes
  time .
\end{itemize}
The total time is at most
, which fits
into the claimed bound.



\subsection{Power projection}

We will now prove the second part of Theorem~\ref{theo:EtoC}, dealing
with power projection. Let thus  be a triangular set in
 that generates a radical ideal, let  be in ,
and let  be a -linear form. Given an integer , we show here how to compute the values ,
for . We start with a folklore lemma involving univariate
computations only.

\paragraph{Univariate computations.}
Let  be a ring,  a monic polynomial of degree  in ,
and  the free -module , with the
(classes of)  as a basis. In this context, the {\em
  trace}  is still well-defined, with  being
the trace of the multiplication map by  in~.  For  and
 an -linear form , the -linear form  is defined as before, by .

\begin{Lemma}\label{lemma:trdeg}
  Suppose that the derivative  of  is
  invertible in , with inverse . Given , and given an
  -linear form , we can compute  in  such
  that , using  operations in .
\end{Lemma}
\begin{proof}
  Let us define another useful -linear form, the {\em residue}
  , by  for  and
  . Given  as above, it is known that there
  exists  such that . Indeed, a straightforward
  computation shows that the values , for
  , are the coefficients of , where for any polynomial  and
  any , we write . This
  implies that given , we can find the requested  by means of
  a power series multiplication modulo , which can be done in
   operations in .
  
  Furthermore, the {\em Euler formula}~\cite[Proposition
    2.4]{Demazure87} shows that , so that . With  and  as above,
  this implies that we have , with . Computing  thus takes another  operations in ,
  proving the lemma.
\end{proof}


\paragraph{Bivariate computations.} We will now apply the results 
of the former paragraph in a bivariate context. The notation is the
one introduced at the beginning of this subsection; furthermore, we
let  be the trace linear form. We also write
 and , so that .

\begin{Lemma}\label{lemma:trdeg2}
  Given a -linear form , one can compute an
  element  such that  in time
  .
\end{Lemma}
\begin{proof}
  Let us define , so that we have
  . Let further  and  be the trace forms; thus, 
  is -linear,  is -linear, and we have .

  First, we are going to factor  as , where  is a suitable
  -linear form. Computing  amounts to compute
  , for ; the condition
  defining  is equivalent to , for 
  and . This can be rewritten as , by -linearity
  of~. For a fixed , let  be the -linear
  form  defined by .
  Then, the previous condition says that .

  Computing the linear forms  is free (since their values
  on the canonical basis of  are simply values of );
  then, finding  is done by first inverting 
  modulo , and applying Lemma~\ref{lemma:trdeg} for the extension
  . The total time to computing all  is
  thus .

  Now that we have written , we will apply
  Lemma~\ref{lemma:trdeg} to , for the extension .
  This requires us to invert  in ; a
  quasi-linear time algorithm is given in~\cite{AcCoMa03}, with a cost
  . Once this is done,
  Lemma~\ref{lemma:trdeg} gives us an element  such that
   in time .

  To summarize, we have written  and , so that  holds for all . Since , this implies that 
  .
\end{proof}


\paragraph{Transposed multiple reduction.} Our next ingredient 
is an algorithm for the following operation. Consider some pairwise
coprime monic polynomials  in , 
and let .

We have already mentioned the multiple reduction map ; writing , this operation can be
done in time . In this paragraph, we will discuss the
dual map. On input linear forms , this dual map computes the linear form  defined by
 where all  and
 are given by means of their values on the monomials bases of
the respective  and . In other words, it computes the values
 for .
In~\cite{BoLeSaScWi04}, an algorithm called  is given
that solves this problem in time . Computing the
above values up to index , for some , can then be done in time
, see for instance~\cite{BoLeSc03}.

\paragraph{Conclusion.} Let us return to the proof of Theorem~\ref{theo:EtoC}.
On input ,  and , we will
show how to compute the values , for .
Using the algorithm of Lemma~\ref{lemma:trdeg2}, we can compute  such the values we want are of the form , for
.

Let us introduce the triangular set (for the order )

and let its equiprojectable decomposition for the order  be given by triangular sets

For , let  be the trace modulo
. Since  and  are isomorphic
-algebras, the traces in  and  coincide.  Since
 is the intersection of the pairwise coprime
ideals , it follows (for instance from
Stickelberger's Theorem) that for any index , we have
 For , let  be the linear form 
defined by . Then, one sees that , so that we have

Using
this remark, we can now give the whole algorithm and its running time.
\begin{itemize}
\item First, we compute  such that . By Lemma~\ref{lemma:trdeg2}, this can be done in time
  .
\item Next, we compute the triangular sets ,
  .  This takes time .



\item The following step consists of computing the linear forms
   (by means of their values on the canonical bases of the
  residue class rings ). We have seen in
  Subsection~\ref{ssec:basics} that we can compute each of those in
  time , so the total time is
   by the super-linearity of .
\item Knowing the linear forms , we can deduce  by
  first computing all  (for a total time of
   again), from which the values of  on the
  basis of  can be read off.
\item Finally, we obtain , for
  , using Eq.~\eqref{eq:tAG} and the
  algorithm for transposed multiple reduction; this takes time
  
\end{itemize}
Taking a quasi-linear , and summing all previous costs, the claim
in Theorem~\ref{theo:EtoC} follows.

\section*{Acknowledgments}

Adrien Poteaux is supported by the EXACTA grant of the National
Science Foundation of China (NSFC 60911130369) and the French National
Research Agency (ANR-09-BLAN-0371-01). \'Eric Schost is supported by
NSERC and the Canada Research Chair program. We wish to thank Marc
Moreno Maza and Yuzhen Xie for interesting discussions during the
preparation of this article.


\bibliographystyle{plain} \bibliography{equiproj}
\end{document}
