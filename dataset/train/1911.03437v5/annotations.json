[{'LEADERBOARD': {'Task': 'Natural Language Inference', 'Dataset': 'AX', 'Metric': 'Accuracy', 'Score': '53.1'}}, {'LEADERBOARD': {'Task': 'Natural Language Inference', 'Dataset': 'QNLI', 'Metric': 'Accuracy', 'Score': '99.2%'}}, {'LEADERBOARD': {'Task': 'Natural Language Inference', 'Dataset': 'SciTail', 'Metric': 'Dev Accuracy', 'Score': '96.1'}}, {'LEADERBOARD': {'Task': 'Natural Language Inference', 'Dataset': 'SciTail', 'Metric': 'Dev Accuracy', 'Score': '91.3'}}, {'LEADERBOARD': {'Task': 'Natural Language Inference', 'Dataset': 'SciTail', 'Metric': 'Dev Accuracy', 'Score': '88.6'}}, {'LEADERBOARD': {'Task': 'Natural Language Inference', 'Dataset': 'SciTail', 'Metric': 'Dev Accuracy', 'Score': '82.3'}}, {'LEADERBOARD': {'Task': 'Natural Language Inference', 'Dataset': 'SciTail', 'Metric': '% Dev Accuracy', 'Score': '96.6'}}, {'LEADERBOARD': {'Task': 'Natural Language Inference', 'Dataset': 'SciTail', 'Metric': '% Test Accuracy', 'Score': '95.2'}}, {'LEADERBOARD': {'Task': 'Natural Language Inference', 'Dataset': 'MNLI + SNLI + ANLI + FEVER', 'Metric': '% Dev Accuracy', 'Score': '57.1'}}, {'LEADERBOARD': {'Task': 'Natural Language Inference', 'Dataset': 'MNLI + SNLI + ANLI + FEVER', 'Metric': '% Test Accuracy', 'Score': '57.1'}}, {'LEADERBOARD': {'Task': 'Natural Language Inference', 'Dataset': 'WNLI', 'Metric': 'Accuracy', 'Score': '93.2%'}}, {'LEADERBOARD': {'Task': 'Natural Language Inference', 'Dataset': 'RTE', 'Metric': 'Accuracy', 'Score': '92.5%'}}, {'LEADERBOARD': {'Task': 'Natural Language Inference', 'Dataset': 'RTE', 'Metric': 'Accuracy', 'Score': '92.0%'}}, {'LEADERBOARD': {'Task': 'Natural Language Inference', 'Dataset': 'RTE', 'Metric': 'Accuracy', 'Score': '71.2%'}}, {'LEADERBOARD': {'Task': 'Natural Language Inference', 'Dataset': 'MultiNLI', 'Metric': 'Matched', 'Score': '92.0'}}, {'LEADERBOARD': {'Task': 'Natural Language Inference', 'Dataset': 'MultiNLI', 'Metric': 'Mismatched', 'Score': '91.7'}}, {'LEADERBOARD': {'Task': 'Natural Language Inference', 'Dataset': 'MultiNLI', 'Metric': 'Accuracy', 'Score': '85.7'}}, {'LEADERBOARD': {'Task': 'Natural Language Inference', 'Dataset': 'MultiNLI', 'Metric': 'Accuracy', 'Score': '85.6'}}, {'LEADERBOARD': {'Task': 'Natural Language Inference', 'Dataset': 'MultiNLI', 'Metric': 'Dev Matched', 'Score': '91.1'}}, {'LEADERBOARD': {'Task': 'Natural Language Inference', 'Dataset': 'MultiNLI', 'Metric': 'Dev Mismatched', 'Score': '91.3'}}, {'LEADERBOARD': {'Task': 'Natural Language Inference', 'Dataset': 'MultiNLI', 'Metric': 'Dev Matched', 'Score': '85.6'}}, {'LEADERBOARD': {'Task': 'Natural Language Inference', 'Dataset': 'MultiNLI', 'Metric': 'Dev Mismatched', 'Score': '86.0'}}, {'LEADERBOARD': {'Task': 'Natural Language Inference', 'Dataset': 'SNLI', 'Metric': '% Test Accuracy', 'Score': '91.7'}}, {'LEADERBOARD': {'Task': 'Natural Language Inference', 'Dataset': 'SNLI', 'Metric': '% Dev Accuracy', 'Score': '92.6'}}, {'LEADERBOARD': {'Task': 'Natural Language Inference', 'Dataset': 'SNLI', 'Metric': 'Dev Accuracy', 'Score': '91.6'}}, {'LEADERBOARD': {'Task': 'Natural Language Inference', 'Dataset': 'SNLI', 'Metric': 'Dev Accuracy', 'Score': '88.7'}}, {'LEADERBOARD': {'Task': 'Natural Language Inference', 'Dataset': 'SNLI', 'Metric': 'Dev Accuracy', 'Score': '86'}}, {'LEADERBOARD': {'Task': 'Natural Language Inference', 'Dataset': 'SNLI', 'Metric': 'Dev Accuracy', 'Score': '82.7'}}, {'LEADERBOARD': {'Task': 'Semantic Textual Similarity', 'Dataset': 'MRPC', 'Metric': 'Accuracy', 'Score': '93.7%'}}, {'LEADERBOARD': {'Task': 'Semantic Textual Similarity', 'Dataset': 'MRPC', 'Metric': 'F1', 'Score': '91.7'}}, {'LEADERBOARD': {'Task': 'Semantic Textual Similarity', 'Dataset': 'MRPC', 'Metric': 'Accuracy', 'Score': '91.3%'}}, {'LEADERBOARD': {'Task': 'Semantic Textual Similarity', 'Dataset': 'MRPC', 'Metric': 'Dev F1', 'Score': '92.1'}}, {'LEADERBOARD': {'Task': 'Semantic Textual Similarity', 'Dataset': 'MRPC', 'Metric': 'Dev Accuracy', 'Score': '89.2'}}, {'LEADERBOARD': {'Task': 'Semantic Textual Similarity', 'Dataset': 'MRPC', 'Metric': 'Dev F1', 'Score': '91.3'}}, {'LEADERBOARD': {'Task': 'Semantic Textual Similarity', 'Dataset': 'MRPC', 'Metric': 'Dev Accuracy', 'Score': '87.7'}}, {'LEADERBOARD': {'Task': 'Semantic Textual Similarity', 'Dataset': 'STS Benchmark', 'Metric': 'Pearson Correlation', 'Score': '0.929'}}, {'LEADERBOARD': {'Task': 'Semantic Textual Similarity', 'Dataset': 'STS Benchmark', 'Metric': 'Spearman Correlation', 'Score': '0.925'}}, {'LEADERBOARD': {'Task': 'Semantic Textual Similarity', 'Dataset': 'STS Benchmark', 'Metric': 'Dev Spearman Correlation', 'Score': '92.6'}}, {'LEADERBOARD': {'Task': 'Semantic Textual Similarity', 'Dataset': 'STS Benchmark', 'Metric': 'Dev Pearson Correlation', 'Score': '92.8'}}, {'LEADERBOARD': {'Task': 'Semantic Textual Similarity', 'Dataset': 'STS Benchmark', 'Metric': 'Dev Spearman Correlation', 'Score': '89.4'}}, {'LEADERBOARD': {'Task': 'Semantic Textual Similarity', 'Dataset': 'STS Benchmark', 'Metric': 'Dev Pearson Correlation', 'Score': '90.0'}}, {'LEADERBOARD': {'Task': 'Sentiment Analysis', 'Dataset': 'SST-2 Binary classification', 'Metric': 'Accuracy', 'Score': '97.5'}}, {'LEADERBOARD': {'Task': 'Sentiment Analysis', 'Dataset': 'SST-2 Binary classification', 'Metric': 'Accuracy', 'Score': '93.6'}}, {'LEADERBOARD': {'Task': 'Sentiment Analysis', 'Dataset': 'SST-2 Binary classification', 'Metric': 'Accuracy', 'Score': '93'}}, {'LEADERBOARD': {'Task': 'Sentiment Analysis', 'Dataset': 'SST-2 Binary classification', 'Metric': 'Dev Accuracy', 'Score': '96.9'}}, {'LEADERBOARD': {'Task': 'Sentiment Analysis', 'Dataset': 'SST-2 Binary classification', 'Metric': 'Dev Accuracy', 'Score': '96.1'}}, {'LEADERBOARD': {'Task': 'Sentiment Analysis', 'Dataset': 'SST-2 Binary classification', 'Metric': 'Dev Accuracy', 'Score': '93.0'}}]
