\subsection{Results from Order Statistics}
\label{sec:central_order_stats}
\begin{thm}[Central Value Theorem (Theorem 10.3 in \cite{david_order_2003})]
\label{thm:central_order_stats}
Given $X_1, X_2, \allowbreak \ldots, \allowbreak X_n \beiid F_X$, if $0 < p < 1$ and $0 < f(x_p) < \infty$, where $x_p = F_X^{-1}(p)$, then
for $k = np + \SmallO{\sqrt{n}}$, the $k^{th}$ order statistic is asymptotically normal,
\begin{equation*}
    \OSn{k}
    \convergeinprob
    \PGaussian{x_p}{\frac{p(1-p)}{n f^2(x_p)}}
\end{equation*}
where $f(\cdot)$ is the \pdfunc\ corresponds to $F_X$ and $\convergeinprob$ denotes convergence in probability as $n \rightarrow \infty$.
\end{thm}
{Extreme value theory} (EVT) is an asymptotic theory of extremes, \ie, minima and maxima. It shows that if a distribution belongs to one of three families of distributions \Cref{thm:domain_of_attractions}), then its maxima can be well characterized asymptotically as given by \Cref{thm:ev_thm}, which is also referred to as the
Fisher-Tippett-Gnedenko Theorem (Theorem 1.1.3 in~\cite{haan_extreme_2006}).
\begin{thm}[Domains of attraction]
    \label{thm:domain_of_attractions}
    A distribution function $F_X$ has one of the following domains of attraction if it satisfies the conditions of the extreme value
    distribution $G(x)$ if and only if
    \begin{enumerate}
        \item $F_X \in \DAG$ if and only if there exists $\eta(x) > 0$ such that
            \begin{equation*}
                \lim_{x \rightarrow \CDUpper{F}^-} \frac{\brF(x + t \eta(x))}{\brF(x)} = e^{-t};
            \end{equation*}
        \item $F_X \in \DAF$ if and only if $\CDUpper{F} = \infty$ and
            \begin{equation*}
                \lim_{\ntoinf[x]} \frac{\brF(tx)}{\brF(x)} = t^{-\xi}, \quad t > 0;
            \end{equation*}
        \item $F_X \in \DAW$ if and only if $\CDUpper{F} < \infty$ and
            \begin{equation*}
                \lim_{x \rightarrow 0^+} \frac{\brF(\CDUpper{F} - tx)}{\brF(\CDUpper{F} - x)} = t^{\xi}, \quad t > 0;
            \end{equation*}
    \end{enumerate}
    where $\CDUpper{x} = \sup \{ x : F_X(x) < 1 \}$, the upper end point of the distribution $F_X$.
\end{thm}

Intuitively, 
$F \in \DAG$ corresponds to the case that $\brF$ has an exponentially decaying tail, 
$F \in \DAF$ corresponds to the case that $\brF$ has heavy tail (such as 
polynomially decaying), 
and 
$F \in \DAW$ corresponds to the case that $\brF$ has a short tail with finite
upper bound.

\begin{thm}[Extreme Value Theorem]
    \label{thm:ev_thm}
    Given $X_1$, $\ldots, X_n \allowbreak \beiid F$, if there exist sequences of constants
    $a_n>0 $ and $b_n\in \reals$ such that
    \begin{align}
        \label{eqn:ev_dist}
        \Prob{(\OSn{n}-b_n)/a_n \leq x} \rightarrow G(x)
    \end{align}
    as $n \rightarrow \infty$ and $G(\cdot)$ is a non-degenerate distribution. 
The extreme value distribution $G(x)$ and the values of  $a_n$ and $b_n$ depend on the domain of attraction (and
hence the tail behavior) of $F_X$ given by \Cref{thm:domain_of_attractions}.
\begin{enumerate}
    \item For $F_X \in \DAG$,
        \begin{align}
            a_n &= \eta\left( F^{-1}(1-1/n) \right), \label{eqn:a_n_gumbel}\\
            b_n &= F^{-1}(1-1/n) \label{eqn:b_n_gumbel}\\
            G(x)& = \GumbelDist(x) = \exp\left\{-\exp\left(-x\right)\right\} \label{eqn:gumbel_law}
        \end{align}
        where $\GumbelDist(x)$ is called the {Gumbel distribution}.
    \item For $F_X \in \DAF$,
        \begin{align}
            a_n &= F^{-1}(1-1/n), \label{eqn:a_n_frechet} \\
            b_n &= 0, \label{eqn:b_n_frechet} \\
            G(x)  &= \FrechetDist(x) =\begin{cases} 
                0 & x \leq 0 \\ 
                \exp\left\{-x^{-\xi}\right\} & x > 0
            \end{cases}. \label{eqn:frechet_law}
        \end{align}
        where $\FrechetDist(x)$  is called the {\Frechet\ distribution}.
    \item For $F_X \in \DAW$,
        \begin{align}
            a_n &= \CDUpper{F} - F^{-1}(1-1/n),\\
            b_n &= \CDUpper{F}, \\
            G(x) &= \RWeibullDist(x) =\begin{cases} 
                \exp\left\{-\left( - x \right)^\xi\right\} & x<0, \\ 
                1 & x\geq 0.
            \end{cases}  \label{eqn:weibull_law}
        \end{align}
        where $\RWeibullDist(x)$ is called the {reversed-Weibull distribution}.
\end{enumerate}
\end{thm}
Based on \Cref{thm:ev_thm}, we can derive the expected value of extreme values, as shown in
\Cref{lem:E_evt_dists}.
\begin{lem}[Expected Extreme Values]
    \label{lem:E_evt_dists}
    \begin{align*}
        \E{\GumbelDist} &= \EMConstantSymbol,
        \\
        \E{\FrechetDist} &= \begin{cases}
            \Gamma\left( 1 - 1/\xi \right)
            & \xi > 1 \\
            +\infty & \mathrm{otherwise},
        \end{cases} \\
        \E{\RWeibullDist} &= -\Gamma\left( 1 + 1/\xi \right),
    \end{align*}
    where $\EMConstantSymbol$ is the \EulerConstant\ and 
    $\Gamma(\cdot)$ is the Gamma function, \ie,
    \begin{equation*}
        \Gamma(t) \defeq \int_0^{\infty} x^{t-1} e^{-x} \, dx
        .
    \end{equation*}
\end{lem}

We can also characterize the limit distribution of the sample extreme $\OSn{1}$
analogously via \Cref{thm:ev_thm} by 
\begin{equation*}
    X_{1:n} = \min\Set{X_1, \ldots, X_n} = - \max\Set{-X_1, \ldots, -X_n}.
\end{equation*}
It is worth noting that the distribution function for $-X$ may be in a different
domain of attraction from that of $X$.



\subsection{Proofs of Single Fork Analysis}
\label{sec:proof_single_fork_general}




\begin{proof}[of \Cref{thm:single_fork_gen}]
The expected latency $\E{T}$ can be divided into two parts: before and after replication. \begin{align}
\E{T} &= \E{\Ta} + \E{\Tb}, \nonumber \\
&= \E{X_{(1-p)n:n} } + \E{ \max_{j=1, 2, \dots, pn} Y_j}, \nonumber \\
&= F_X^{-1}(1-p) + \E{Y_{pn:pn}}. \label{eqn:latency_1}
\end{align}
The time before forking $\Ta$ is the time until $(1-p)n$ of the $n$ tasks launched at time $0$ finish. Thus, its expected value $\E{\Ta}$ is the expectation of the $(1-p)n ^{th}$ order statistic $X_{(1-p)n:n}$ of $n$ i.i.d.\ random variables with distribution $F_X$. By the Central Value Theorem stated as \Cref{thm:central_order_stats}, for $n \rightarrow \infty$, this term converges to inverse CDF value $F_X^{-1}(1-p)$.

At this forking point, the scheduler introduces replicas of the $pn$ straggling tasks. The distribution $F_Y$ of the residual execution time (minimum over the $r+1$ replicas). First consider $\SingleForkKillText$ where the original copy is killed. The residual execution
time distribution $F_Y$ (after time $T^{(1)}$ when the replicas are added) of each task is the minimum of $r+1$ i.i.d.\ random variables with distribution $F_X$. Hence,
\begin{align}
\Pr(Y>y) &= \Pr( \min (X_1, X_2, \dots X_{r+1} ) > y ) ,\\
\fccdf[Y]{y} &= \fccdf[X]{y}^{r+1} \quad \text{ for } \SingleForkKillText.
\end{align}
For $\SingleForkKeepText$, there is $1$ original replica and $r$ new replicas of each of the straggling tasks. Thus, the tail distribution $\fccdf[Y]{y} = 1- F_Y(y)$ is given by
\begin{align}
\Pr(Y>y) &= \Pr( X_1 > y + T^{(1)} \vert X_1 > T^{(1)}) \cdot \Pr( \min (X_2,\dots X_{r+1} ) > y ), \\
\fccdf[Y]{y} &= \frac{\fccdf[X]{y +T^{(1)} }}{ \fccdf[X]{T^{(1)}}} \fccdf[X]{y}^{r}.
\end{align}
As the number of tasks $n \rightarrow \infty$ by \Cref{thm:central_order_stats} we have $T^{(1)} \rightarrow F_X^{-1}(1-p)$. Hence,
\begin{align}
\fccdf[Y]{y} &= \frac{\fccdf[X]{y +F_X^{-1}(1-p) }}{p} \fccdf[X]{y}^{r} \quad \text{ for } \SingleForkKeepText.
\end{align}
The second term $\E{\Tb}$ in \eqref{eqn:latency_1} is the expected value of the maximum of $pn$ i.i.d.\ random variables with distribution $F_Y$.

Recall from \Cref{defn:cost} that the expected cost $\E{C}$ is the sum of the running times of all machines, normalized by the number of tasks $n$. We can analyze $\E{C}$ by dividing it into sum of machine runtimes before and after forking.
\begin{align}
    \E{\Cost} &= \E{\Ca} + \E{\Cb} \label{eqn:cost_1} , \\
\E{\Ca} &= \frac{1}{n} \sum_{i=1}^{(1-p) n} \E{\OSn{i}} + \frac{n p}{n} \E{ \Ta} \label{eqn:cost_2},\\
   &= \frac{1}{n} \sum_{i=1}^{(1-p) n} F_X^{-1} \left(\frac{i}{n} \right) + p F_X^{-1}(1-p) \label{eqn:cost_3},\\
   &= \int_{0}^{1-p} F_X^{-1}(h) dh + p F_X^{-1}(1-p) \label{eqn:cost_4}.
\end{align}

\begin{align}
 \E{\Cb} 
  &= \frac{1}{n}  \sum_{j=1}^{pn} (r+1) \E{Y_j} \label{eqn:cost_5},\\
  &= (r+1)  p \cdot \E{Y} . \label{eqn:cost_6}
\end{align}
The cost before forking $\E{\Ca}$ consists of the cost for the $(1-p)n$ tasks that finish first, plus the cost
for the $pn$ straggling tasks. The first term in \eqref{eqn:cost_2} is the sum of the expected values of the
smallest $(1-p)n$ execution times. Using \Cref{thm:central_order_stats}, we can show that the $i^{th}$ term in
the summation converges to $F_X^{-1}(i/n)$ as $n \rightarrow \infty$. Expressing the sum as an integral over $h
= i/n$ we get the first term in \eqref{eqn:cost_4}. The second term in \eqref{eqn:cost_2}, is the normalized
running time of the $pn$ straggling tasks before forking. Substituting $\E{\Ta}$ from \eqref{eqn:latency_1} and
simplifying, we get \eqref{eqn:cost_4}. 

The cost after forking, $\E{\Cb}$ is the normalized sum of the runtimes of the $r+1$ replicas of each of the
$pn$ straggling tasks. The residual execution time of the $j^{th}$ straggling task is $Y_j \sim F_Y$. Since the
scheduler kills all replicas as soon as one replica finishes, the expected runtime for the $j^{th}$ straggling
task is $(r+1) \E{Y_j}$. Thus, the cost in \eqref{eqn:cost_5} is the sum of $(r+1) \E{Y_j}$ over the $pn$ tasks,
normalized by $n$. Since $Y_j$ are i.i.d, we can reduce this to \eqref{eqn:cost_6}.
\end{proof}


\begin{proof}[of \Cref{lem:relaunch_vs_not}]
When we keep the original copy, the residual execution time of a straggling task is \begin{align}
\Ykeep &= \min\Set{X_{1:r}, (X | X > T^{(1)})}, \\
\Pr(\Ykeep > x) &= \Pr(X>x)^r \frac{\Pr(X > x + F_X^{-1}(1-p))}{p} \label{eqn:Y_keep_tail}
\end{align}
where $\CondProb{X > x + T^{(1)}}{X > T^{(1)}}$ is the additional time needed for the original copy to finish after forking time $T^{(1)}$. As $n \rightarrow \infty$, $T^{(1)} \rightarrow F_X^{-1}(1-p)$. Thus, the tail distribution of $\Ykeep$ is given by \eqref{eqn:Y_keep_tail}. 

When we kill the original copy, $r+1$ new copies of the straggling task are launched at the forking point. Thus the residual execution time is
\begin{align}
\Ykill &= \min\Set{X_{1:r}, X}, \\
\Pr(\Ykill > x) &= \Pr(X>x)^{r+1}.
\end{align}
Killing the original task is better than keeping it if $\Ykeep$ stochastically dominates $\Ykill$, that is $\Pr(\Ykeep > x) \geq \Pr(\Ykill > x)$ for all $x$. This gives the condition \eqref{eqn:kill_or_keep}. Conversely, keeping the original task is better when the reverse condition holds.
\end{proof}

\begin{proof}[of \Cref{thm:single_fork_sexp}]
\begin{align}
\E{T} &= F_X^{-1}(1-p) + \E{ Y_{pn:pn}} \nonumber ,\\
&= \Delta - \frac{1}{\mu} \ln p + \tilde{a}_{pn} \E{ \GumbelDist} + \tilde{b}_{pn},\\
&= \Delta - \frac{1}{\mu} \ln p + \tilde{a}_{pn} \EMConstantSymbol + \tilde{b}_{pn}.
\end{align}
\begin{align}
\E{\Cost} &= \int_{0}^{1-p} F_X^{-1}(h) dh + p F_X^{-1}(1-p)  + (r+1) p \cdot \E{Y}, \\
&= \int_{0}^{1-p}\left ( \Delta - \frac{1}{\mu} \ln(1-h) \right) dh + p \left(\Delta - \frac{1}{\mu} \ln p \right) \nonumber,\\
& \quad \quad \quad \quad  \quad \quad+  (r+1)p \cdot \E{Y} ,\\
&= \Delta + \frac{1}{\mu} \left( p \ln p + (1-p) \right)  + p \Delta - \frac{p}{\mu} \ln p \nonumber ,\\
&\quad \quad \quad \quad  \quad \quad+ (r+1)p \cdot \E{Y} ,\\
&= \Delta (1 + p) + \frac{1-p}{\mu} + (r+1)p \cdot \E{Y} .
\end{align}
To find $\E{Y}$, $\tilde{a}_{pn}$ and  $\tlb_{pn}$ we consider the cases of relaunching ($l=0$) and no relaunching ($l=1$) separately. 

~\\
\textbf{Case 1: Killing the original task ($\SingleForkKillText$)}
\begin{align}
Y &= \min \Set{ X_1, X_2, \cdots X_{r+1} } \\
&\sim \PSExp{\Delta}{(r+1)\mu} \\
\E{Y} &= \Delta + \frac{1}{(r+1)\mu}
\end{align}
Based on \Cref{thm:domain_of_attractions}, for $ \eta(y) = 1/((r+1)\mu)$ we have
\begin{align}
    \lim_{y \rightarrow \CDUpper{F_Y}} \frac{\fccdf[Y]{y + u \eta(y)}}{\fccdf[Y]{y}}
    &= e^{-u}.
\end{align}
By \Cref{thm:ev_thm} and \Cref{thm:domain_of_attractions}, the maximum of shifted exponential belongs to the Gumbel family with
\begin{align*}
    \tla_{pn} &= \frac{1}{\mu(1+r) },
    \\
    \tlb_{pn} &= \finvccdf[Y]{1/n} = \Delta + \frac{\ln (pn) }{\mu(r+1)}.
\end{align*}

~\\
\textbf{Case 2: Keeping the original task ($\SingleForkKeepText$)}
\label{sec:shifted_exp_no_relaunching}

In the case of no relaunching,
\[Y = \min\Set{\PExp{\mu}, \Delta + \PExp{r\mu}}.\]
Note that the first term does not include $\Delta$ because for large $n$ the original task would have run for at least $\Delta$ seconds. Thus the tail distribution of $Y$ is given by
\begin{align}
    \label{eqn:shifted_exp_Y}
    \fccdf[Y]{y} &= \begin{cases}
        e^{-\mu y} & 0 < y < \Delta, \\
        e^{\mu r \Delta} e^{-\mu(r+1)y} & y \geq \Delta.
    \end{cases}
\end{align}

The expected value $\E{Y}$ is the integration of $\fccdf[Y]{y}$ over its support.
\begin{align*}
\E{Y} &= \int_{0}^{\Delta} e^{-\mu y} dy + \int_{\Delta}^{\infty} e^{\mu r \Delta} e^{-\mu(r+1)y}, \\
&= \frac{1- e^{-\mu \Delta}}{\mu} + \frac{e^{-\mu \Delta}}{ \mu (r+1)} .
\end{align*}

By \Cref{thm:ev_thm} and \Cref{thm:domain_of_attractions} similar to the relaunching case we have
\begin{align*}
    \tla_{pn} &= 1/\left[ \mu(1+r) \right], \\
    \tlb_{pn} &= \finvccdf[Y]{1/n} = \frac{r}{r+1} \Delta + \frac{\ln (pn) }{\mu(r+1)}.
\end{align*}
\end{proof}



Before showing the detailed proof of \Cref{thm:single_fork_pareto}], 
we state in \Cref{lem:DA_FY} how the domain of attraction of $F_Y$ relates to that of $F_X$. 

\begin{lem}[Domain of attraction for $F_Y$]
    \label{lem:DA_FY}
    Given a single fork policy $\SingleFork{p,r; n}$ with $0 < p < 1$, 
    \begin{enumerate}
        \item if $F_X \in \DAG$, then $F_Y \in \DAG$;
        \item if $F_X \in \DAF$, then $F_Y \in \DAF[(r+1)\xi]$;
        \item if $F_X \in \DAW$, then $F_Y \in \DAW[(r+1)\xi]$ for $\SingleForkKill{p,r}$ and $F_Y \in \DAW[\xi]$ for $\SingleForkKeep{p,r}$.
    \end{enumerate}
\end{lem}
The proof follows directly from \Cref{eqn:Y_defn} and \Cref{thm:domain_of_attractions}, and hence is omitted here. 


\begin{proof}[of \Cref{thm:single_fork_pareto}]
From \Cref{thm:single_fork_gen} we have
\begin{align}
\E{T} &= F_X^{-1}(1-p) + \E{ Y_{pn:pn}} \nonumber ,\\
&= x_m p^{-1/\alpha}  + \tilde{a}_{pn} \E{ \Phi_{(r+1)\alpha}} \label{eqn:latency_pareto_1} ,\\
&= x_m p^{-1/\alpha}  + \tilde{a}_{pn}  \Gamma \left( 1- 1\frac{1}{(r+1)\alpha} \right) \label{eqn:latency_pareto_2}. \\
\E{C} &=  \int_{0}^{1-p} F_X^{-1}(h) dh + p F_X^{-1}(1-p)  + (r+1) p \cdot \E{Y} ,\label{eqn:cost_pareto_1} \\
&= x_m \int_{0}^{1-p} (1-h)^{-1/\alpha} dh + p x_m p^{-1/\alpha}  + (r+1) p \cdot \E{Y} ,\nonumber \\
&= x_m \frac{\alpha}{\alpha-1} [1 - p^{1-1/\alpha} ] + x_m p^{1-1/\alpha}  + (r+1) p \cdot \E{Y} ,\nonumber \\
&= x_m \frac{\alpha}{\alpha-1} - x_m \frac{p^{1- 1/\alpha}}{\alpha-1} + (r+1) p \cdot \E{Y} .\label{eqn:cost_pareto_4}
\end{align}
To obtain \eqref{eqn:latency_pareto_1} we first observe that since $F_X$ is Pareto, by
\Cref{thm:domain_of_attractions} it falls into the \Frechet{} domain of attraction, i.e.\ $F_X \in
\DAF[\alpha]$. Then using \Cref{lem:DA_FY} we can show that $F_Y \in \DAF[(r+1)\alpha]$. Subsequently, using
\Cref{thm:ev_thm} and \Cref{lem:E_evt_dists} we get \eqref{eqn:latency_pareto_2}. To derive the expected cost
\eqref{eqn:cost_pareto_4} we substitute $F^{-1}_X(h) = x_m (1-h)^{-1/\alpha}$ in the first and second terms in
\eqref{eqn:cost_pareto_1} and simplify the expression.
To find $\tilde{a}_{pn}$ and $\E{Y}$ in \eqref{eqn:latency_pareto_2} and \eqref{eqn:cost_pareto_4} respectively we
consider the cases of killing the original task ($\SingleForkKillText$) and keeping the original task
($\SingleForkKeepText$) separately. 

~\\
\textbf{Case 1: Killing the original task($\SingleForkKillText$)} \\
For a single-fork policy that kills the original task, the scheduler waits for $(1-p)n$ tasks to finish and then relaunches each of the $pn$ straggler tasks on a new machine. 
\begin{align}
Y &= \min( X_1, X_2, \dots X_{r+1} ) ,\nonumber \\
Y &\sim \PPareto{(r+1)\alpha}{x_m} . \label{eqn:Y_pareto_relaunch}
\end{align}
From \eqref{eqn:a_n_frechet} in \Cref{thm:ev_thm} we can evaluate $\tilde{a}_{pn}$ as follows
\begin{align*}
\tilde{a}_{pn} &= F_Y^{-1}\left(1- \frac{1}{pn} \right) = x_m (pn)^{1/\alpha} .
\end{align*}
And $\E{Y}$ of \eqref{eqn:Y_pareto_relaunch} can be evaluated as
\begin{align}
\E{Y} &= \frac{ (r+1) \alpha }{ (r+1) \alpha - 1} x_m .
\end{align}

~\\
\textbf{Case 2: Keeping the original task ($\SingleForkKeepText$)} \\
For a single-fork policy that keeps the original task, the scheduler keeps the original copy, and adds $r$
additional replicas for each straggling task. Thus the residual execution time can be expressed as
\begin{align}
Y &= \min( \PPareto{\alpha}{F_X^{-1}(1-p)} - F_X^{-1}(1-p),  \PPareto{r\alpha}{x_m} )  \\
\bar{F}_Y(y) &= \frac{1}{p} \left( \frac{x_m}{y} \right)^{\alpha r} \left( \frac{x_m}{y + x_m p^{-1/\alpha}} \right)^{\alpha} .\label{eqn:Y_pareto_no_relaunch}
\end{align}
From \eqref{eqn:a_n_frechet} in \Cref{thm:ev_thm}, $\tilde{a}_{pn} = \bar{F}_Y^{-1}\left(\frac{1}{pn} \right)$. The expected value of $Y$ can be found by numerically integrating $\bar{F}_Y(y)$ in \eqref{eqn:Y_pareto_no_relaunch} over its support. 
\end{proof}

\begin{proof}[of \Cref{coro:scaling}]
For the case of killing the original task, it follows directly from \eqref{eqn:pareto_ET} and
\eqref{eqn:pareto_relaunching_a}. For the case of keeping the original task, note that $\tla_{pn}$ grows with $n$. When $n$ is large enough, from\eqref{eqn:Y_pareto_no_relaunch} and the fact that $\tilde{a}_{pn} = \bar{F}_Y^{-1}\left(\frac{1}{pn} \right)$, we have
\begin{align}
\tla_{pn} ^{r+1}
\leq
n^{1/\alpha} x_m^{r+1} 
&\leq 2 \tla_{pn} ^{r+1},
\end{align}
and then the result holds again following \eqref{eqn:pareto_ET}.
\end{proof}







