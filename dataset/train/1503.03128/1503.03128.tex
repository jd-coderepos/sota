\subsection{Results from Order Statistics}
\label{sec:central_order_stats}
\begin{thm}[Central Value Theorem (Theorem 10.3 in \cite{david_order_2003})]
\label{thm:central_order_stats}
Given , if  and , where , then
for , the  order statistic is asymptotically normal,

where  is the \pdfunc\ corresponds to  and  denotes convergence in probability as .
\end{thm}
{Extreme value theory} (EVT) is an asymptotic theory of extremes, \ie, minima and maxima. It shows that if a distribution belongs to one of three families of distributions \Cref{thm:domain_of_attractions}), then its maxima can be well characterized asymptotically as given by \Cref{thm:ev_thm}, which is also referred to as the
Fisher-Tippett-Gnedenko Theorem (Theorem 1.1.3 in~\cite{haan_extreme_2006}).
\begin{thm}[Domains of attraction]
    \label{thm:domain_of_attractions}
    A distribution function  has one of the following domains of attraction if it satisfies the conditions of the extreme value
    distribution  if and only if
    \begin{enumerate}
        \item  if and only if there exists  such that
            
        \item  if and only if  and
            
        \item  if and only if  and
            
    \end{enumerate}
    where , the upper end point of the distribution .
\end{thm}

Intuitively, 
 corresponds to the case that  has an exponentially decaying tail, 
 corresponds to the case that  has heavy tail (such as 
polynomially decaying), 
and 
 corresponds to the case that  has a short tail with finite
upper bound.

\begin{thm}[Extreme Value Theorem]
    \label{thm:ev_thm}
    Given , , if there exist sequences of constants
     and  such that
    
    as  and  is a non-degenerate distribution. 
The extreme value distribution  and the values of   and  depend on the domain of attraction (and
hence the tail behavior) of  given by \Cref{thm:domain_of_attractions}.
\begin{enumerate}
    \item For ,
        
        where  is called the {Gumbel distribution}.
    \item For ,
        
        where   is called the {\Frechet\ distribution}.
    \item For ,
        
        where  is called the {reversed-Weibull distribution}.
\end{enumerate}
\end{thm}
Based on \Cref{thm:ev_thm}, we can derive the expected value of extreme values, as shown in
\Cref{lem:E_evt_dists}.
\begin{lem}[Expected Extreme Values]
    \label{lem:E_evt_dists}
    
    where  is the \EulerConstant\ and 
     is the Gamma function, \ie,
    
\end{lem}

We can also characterize the limit distribution of the sample extreme 
analogously via \Cref{thm:ev_thm} by 

It is worth noting that the distribution function for  may be in a different
domain of attraction from that of .



\subsection{Proofs of Single Fork Analysis}
\label{sec:proof_single_fork_general}




\begin{proof}[of \Cref{thm:single_fork_gen}]
The expected latency  can be divided into two parts: before and after replication. 
The time before forking  is the time until  of the  tasks launched at time  finish. Thus, its expected value  is the expectation of the  order statistic  of  i.i.d.\ random variables with distribution . By the Central Value Theorem stated as \Cref{thm:central_order_stats}, for , this term converges to inverse CDF value .

At this forking point, the scheduler introduces replicas of the  straggling tasks. The distribution  of the residual execution time (minimum over the  replicas). First consider  where the original copy is killed. The residual execution
time distribution  (after time  when the replicas are added) of each task is the minimum of  i.i.d.\ random variables with distribution . Hence,

For , there is  original replica and  new replicas of each of the straggling tasks. Thus, the tail distribution  is given by

As the number of tasks  by \Cref{thm:central_order_stats} we have . Hence,

The second term  in \eqref{eqn:latency_1} is the expected value of the maximum of  i.i.d.\ random variables with distribution .

Recall from \Cref{defn:cost} that the expected cost  is the sum of the running times of all machines, normalized by the number of tasks . We can analyze  by dividing it into sum of machine runtimes before and after forking.



The cost before forking  consists of the cost for the  tasks that finish first, plus the cost
for the  straggling tasks. The first term in \eqref{eqn:cost_2} is the sum of the expected values of the
smallest  execution times. Using \Cref{thm:central_order_stats}, we can show that the  term in
the summation converges to  as . Expressing the sum as an integral over  we get the first term in \eqref{eqn:cost_4}. The second term in \eqref{eqn:cost_2}, is the normalized
running time of the  straggling tasks before forking. Substituting  from \eqref{eqn:latency_1} and
simplifying, we get \eqref{eqn:cost_4}. 

The cost after forking,  is the normalized sum of the runtimes of the  replicas of each of the
 straggling tasks. The residual execution time of the  straggling task is . Since the
scheduler kills all replicas as soon as one replica finishes, the expected runtime for the  straggling
task is . Thus, the cost in \eqref{eqn:cost_5} is the sum of  over the  tasks,
normalized by . Since  are i.i.d, we can reduce this to \eqref{eqn:cost_6}.
\end{proof}


\begin{proof}[of \Cref{lem:relaunch_vs_not}]
When we keep the original copy, the residual execution time of a straggling task is 
where  is the additional time needed for the original copy to finish after forking time . As , . Thus, the tail distribution of  is given by \eqref{eqn:Y_keep_tail}. 

When we kill the original copy,  new copies of the straggling task are launched at the forking point. Thus the residual execution time is

Killing the original task is better than keeping it if  stochastically dominates , that is  for all . This gives the condition \eqref{eqn:kill_or_keep}. Conversely, keeping the original task is better when the reverse condition holds.
\end{proof}

\begin{proof}[of \Cref{thm:single_fork_sexp}]


To find ,  and   we consider the cases of relaunching () and no relaunching () separately. 

~\\
\textbf{Case 1: Killing the original task ()}

Based on \Cref{thm:domain_of_attractions}, for  we have

By \Cref{thm:ev_thm} and \Cref{thm:domain_of_attractions}, the maximum of shifted exponential belongs to the Gumbel family with


~\\
\textbf{Case 2: Keeping the original task ()}
\label{sec:shifted_exp_no_relaunching}

In the case of no relaunching,

Note that the first term does not include  because for large  the original task would have run for at least  seconds. Thus the tail distribution of  is given by


The expected value  is the integration of  over its support.


By \Cref{thm:ev_thm} and \Cref{thm:domain_of_attractions} similar to the relaunching case we have

\end{proof}



Before showing the detailed proof of \Cref{thm:single_fork_pareto}], 
we state in \Cref{lem:DA_FY} how the domain of attraction of  relates to that of . 

\begin{lem}[Domain of attraction for ]
    \label{lem:DA_FY}
    Given a single fork policy  with , 
    \begin{enumerate}
        \item if , then ;
        \item if , then ;
        \item if , then  for  and  for .
    \end{enumerate}
\end{lem}
The proof follows directly from \Cref{eqn:Y_defn} and \Cref{thm:domain_of_attractions}, and hence is omitted here. 


\begin{proof}[of \Cref{thm:single_fork_pareto}]
From \Cref{thm:single_fork_gen} we have

To obtain \eqref{eqn:latency_pareto_1} we first observe that since  is Pareto, by
\Cref{thm:domain_of_attractions} it falls into the \Frechet{} domain of attraction, i.e.\ . Then using \Cref{lem:DA_FY} we can show that . Subsequently, using
\Cref{thm:ev_thm} and \Cref{lem:E_evt_dists} we get \eqref{eqn:latency_pareto_2}. To derive the expected cost
\eqref{eqn:cost_pareto_4} we substitute  in the first and second terms in
\eqref{eqn:cost_pareto_1} and simplify the expression.
To find  and  in \eqref{eqn:latency_pareto_2} and \eqref{eqn:cost_pareto_4} respectively we
consider the cases of killing the original task () and keeping the original task
() separately. 

~\\
\textbf{Case 1: Killing the original task()} \\
For a single-fork policy that kills the original task, the scheduler waits for  tasks to finish and then relaunches each of the  straggler tasks on a new machine. 

From \eqref{eqn:a_n_frechet} in \Cref{thm:ev_thm} we can evaluate  as follows

And  of \eqref{eqn:Y_pareto_relaunch} can be evaluated as


~\\
\textbf{Case 2: Keeping the original task ()} \\
For a single-fork policy that keeps the original task, the scheduler keeps the original copy, and adds 
additional replicas for each straggling task. Thus the residual execution time can be expressed as

From \eqref{eqn:a_n_frechet} in \Cref{thm:ev_thm}, . The expected value of  can be found by numerically integrating  in \eqref{eqn:Y_pareto_no_relaunch} over its support. 
\end{proof}

\begin{proof}[of \Cref{coro:scaling}]
For the case of killing the original task, it follows directly from \eqref{eqn:pareto_ET} and
\eqref{eqn:pareto_relaunching_a}. For the case of keeping the original task, note that  grows with . When  is large enough, from\eqref{eqn:Y_pareto_no_relaunch} and the fact that , we have

and then the result holds again following \eqref{eqn:pareto_ET}.
\end{proof}







