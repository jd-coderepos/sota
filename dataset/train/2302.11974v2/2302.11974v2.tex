\documentclass[sigconf,screen,anonymous=false]{acmart}
\settopmatter{printacmref=false} \renewcommand\footnotetextcopyrightpermission[1]{} \pagestyle{plain} 

\usepackage{booktabs}
\usepackage{url}
\usepackage{multirow}
\usepackage[shortlabels]{enumitem}
\usepackage{graphicx,subfigure}





\captionsetup{skip=2pt}
\setlength{\intextsep}{3pt plus 3pt}
\let\temp\rmdefault
\let\rmdefault\temp



\newcommand{\LightCTS}{\mbox{LightCTS}}
\newcommand{\where}[1]{{\textcolor{blue}{#1}}}

\newcommand{\Lai}[1]{{\textcolor{purple}{#1}}}

\copyrightyear{2023}
\acmYear{2023} 
\setcopyright{acmcopyright}
\acmConference[SIGMOD '23]{Proceedings of the 2023
International Conference on Management of Data}{June 18--23, 2023}{Seattle, WA, USA}

\acmPrice{15.00}
\acmDOI{nnnnn/nnnnnn.nnnnn}


\begin{document}

\pagestyle{plain}
\pagenumbering{arabic}	


\title{Summary of Revisions}
\maketitle

We would like to thank the three reviewers and the meta-reviewer for their insightful and constructive comments that provide us with opportunities to improve our work. We have revised the paper carefully, and we believe that we have addressed all the comments. The major changes are summarized in this report and highlighted with colours and tags (e.g., R1.O1) in the revised paper. 

\noindent
\textbf{M1}
\label{M1}
We have included the \emph{latency} and \emph{peak memory usage} as two additional metrics throughout the empirical study (cf.\ \where{Tables 5-7 and 9-10 and Figures 5 and 6}).
Referring to descriptions in \where{Sections~5.1.2 and 5.1.4}, these metrics were measured on a computation-resource-constrained device (CPU @380 MHz), as requested by R1.O1.



\noindent
\textbf{M2}
\label{M2}
We have discussed the tuning of the group number, specifically in \where{Section~4.2.2} where we first present the group techniques for L-TCN.
Stated briefly, the group number is naturally within a small number of candidates as controlled by the specified embedding size.
Then, one can iterate through the small candidate set and choose the maximal group number (corresponding to the highest lightness) that can still achieve the state-of-the-art accuracy.
For readers' reference, we also mention a training method from NAS [48] to speed-up the hyperparameter tuning procedure.
Moreover, we have evaluated the impact of a varying group number in L-TCN in \where{Section~5.3.2}.
Finally, we have discussed the group number tuning as future work in \where{Section~7} as we believe it is a critical procedure for further studying.





\noindent
\textbf{M3} 
\label{M3}
We applied the knowledge distillation (KD) technique from the suggested literature to the most accurate completing model, \AutoCTS{}, creating new baselines named \AutoCTSKDF{} and \AutoCTSKDP{}.
Respectively, they are compressed small models having nearly the same FLOPs and parameter numbers as \LightCTS{}.
However, the experimental results in \where{Tables 5-7} showed that a straightforward application of the KD technique on CTS forecasting models leads to inferior results compared to \LightCTS{} and even other baselines (cf.\ the result explanation in \where{Section~5.1.5}).
Nevertheless, this motivates further investigation and has been discussed as future work in \where{Section~7}.





\noindent
\textbf{M4}
\label{M4}
LightCTS address the challenge of implementing highly accurate CTS forecasting models in scenarios where computational resources are constrained. Existing models such as GWNet and AutoCTS have demonstrated high accuracy in CTS forecasting, but these complex models are computationally intensive and energy-consuming, making them infeasible for use in devices with constrained resources. On the other hand, naive forecasting models lack the accuracy required for many practical applications. To address this challenge, we propose a lightweight and highly accurate CTS forecasting framework, LightCTS. In 
\where{Section 5.5}, we conduct a series of resource constraint experiments on the PEMS08 dataset. Our results show that when the upper bound of peak memory usage is under 3Mb, the most accurate model AutoCTS fails to be implemented. Additionally, models such as GWNet and AGCRN, which have the lowest latency and peak memory usage, respectively, also generate highly erroneous forecasting results under the same constraint (See \where{Table 10}). However, our proposed LightCTS model is able to produce satisfactory results under these resource constraints.

Examples of existing models that enable highly accurate CTS forecasting include GWNet, AutoCTS, and so on. However, they are too large and consume too much energy to implement in some practical scenarios where they should be implemented in devices with limited resources, while naive forecasting models cannot guarantee accuracy. The long-term operation of CTS forecasting models, which may result in much more errors or energy consumption, makes the lightweight and highly accurate CTS forecasting model even more significant. 

Specifically, we conduct a series of resource constraint experiments in \where{Section 5.5}. On PEMS08 dataset, when the upper bound of peak memory usage is under 3Mb, the most accurate model AutoCTS fails to be implemented. Besides, AGCRN, which requires the least memory, and GWNet, which has the lowest latency, generate highly erroneous forecasting results when the upper bound of peak memory usage is under 3Mb (see \where{Table 10}). However, our proposed LightCTS is still able to produce satisfactory results. Such lightweight and accurate models are desirable for many practical applications. For instance, wind turbines are often deployed in harsh and remote locations. This poses challenges for regular maintenance and repairs as it requires considerable manpower. Predictive maintenance, on the other hand, utilizes accurate and instant forecasts of the operating status of wind turbines to identify potential failures in advance and provide timely maintenance. In smart grid systems, smart meters are often resource-constrained and should consume the least amount of energy possible, making lightweight forecasting models essential for smart meter analyses such as anomaly detection and working status monitoring.

In conclusion, we propose LightCTS that is able to address the challenge of implementing highly accurate CTS forecasting models in scenarios where computational resources are limited. 




\noindent
\textbf{M5} Following the suggestion, we conduct the experiments, which test LightCTS under different memory constraints (3Mb, 2.5Mb, and 2Mb). We also apply the same constraints to three representative state-of-the-art models: AutoCTS, which is the most accurate; GWNet, which has the lowest latency; AGCRN, which has the lowest peak memory usage. Specifically, in order to maintain a fair comparison among these models, adjustments to the embedding size $\mathtt{D}$ of each model are made to accommodate the memory constraints while maintaining the structure and components unaltered. We add \where{Section 5.5} to analyze the details of these experiments. As shown in \where{Table 10}, the experimental results show that, AutoCTS is not applicable to be implemented under such tight memory constraints, it fails to work when the memory constraint is below 3Mb. The results also indicate that the accuracy of AGCRN and GWNet declines significantly as memory constraints tightened. However, our proposed model, LightCTS, is able to maintain a relatively high level of accuracy under these constraints. This suggests that LightCTS may be a more applicable and effective choice for use on edge devices, where memory constraints are often a limiting factor.


\noindent
\textbf{M6} Following the suggestion, we flesh out an example of predictive maintenance of wind turbines in \where{Section 1}.






\noindent
\textbf{R1.O1}\label{R1O1}
Please refer to \hyperref[M1]{M1}.

\noindent
\textbf{R1.O2} Please refer to \hyperref[M2]{M2}.

\noindent
\textbf{R1.O3}
We improve the description of L-TCN and highlight its benefit over last-shot compression.

\noindent
\textbf{R2.O1 and R2.O4.(1)} Please refer to \textbf{M3}.

\noindent
\textbf{R2.O3 and R2.O4.(2)} Please refer to \textbf{M5}.

\noindent
\textbf{R3.O1} Please refer to \textbf{M6}.

\noindent
\textbf{R3.O2} Following the suggestion, we perform the experiments on a resource-constrained X86 end device with a CPU at 380Mhz, and we report the latency and the peak memory usage in \where{Table 9}, which gives LightCTS more justification for being deployed in a server that is operating under such constraints. Please also refer to \textbf{M5} for more details.

\clearpage
\balance
\end{document}
