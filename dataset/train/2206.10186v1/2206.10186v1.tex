\section{Experiments}
\label{experiments}

\noindent\textbf{Dataset}.
We perform our tests on the MS COCO 2017 dataset \cite{lin2014microsoft}.
The training dataset consists of more than 117,000 images and 80 different classes of objects, where 10\% of the labeled images are used.

\noindent\textbf{Evaluation Metrics}.
All the tests are done on COCO minival 2017 validation dataset, which contains 5000 images.
We report mean Average Precision (mAP) and  and  with 0.5 and 0.75 minimum IoU thresholds, and ,  and  for small, medium and large objects, respectively.

\noindent\textbf{Implementation details.}
All the values are obtained running the training with the same hardware and hyper-parameters.
When available, the original code released by the authors is used.
Our code is developed on top of the Unbiased Teacher \cite{liu2021unbiased} source code.
We perform the training on a single machine with 6 Tesla P100 GPUs with 12GB of memory.
The train lasts 180,000 iterations with a batch size of 2 images per GPU for the supervised part and 2 images for the unsupervised part, with  set to 4.
We use the Stochastic Gradient Descent (SGD) optimization algorithm with a learning rate of 0.0075, a weight decay of 0.0001, and a momentum of 0.9.
The learning rate decays at iteration 179990 and 179995.
We use the Faster R-CNN with FPN \cite{lin2017feature} and the ResNet 50 \cite{he2016deep} backbone for the teacher and student models, initialized by pre-trained on ImageNet, and the same augmentation of Unbiased Teacher \cite{liu2021unbiased}.

\begin{figure*}[bt]
	\centering
	\begin{subfigure}{0.43\linewidth}
\includegraphics[width=0.9\linewidth]{images/ablation_weight_regr.jpg}
		\caption{Unsup regression loss weights.}
		\label{fig:ablation_weight_regr_losses}
	\end{subfigure}
	\begin{subfigure}{0.43\linewidth}
\includegraphics[width=0.9\linewidth]{images/ablation_cls_regr.jpg}
		\caption{Classification vs Regression.}
		\label{fig:bbox-iou-cls-regr-loss}
	\end{subfigure}
	\begin{subfigure}{0.43\linewidth}
\includegraphics[width=0.9\linewidth]{images/ablation_with_without_filtering_bbox.jpg}
		\caption{Filtering with bbox IoU score.}
		\label{fig:ablation_with_without_filtering_bbox}
	\end{subfigure}
	\begin{subfigure}{0.43\linewidth}
\includegraphics[width=0.9\linewidth]{images/ablation_inf_threshold_count.jpg}
		\caption{Count filtered pseudo-bboxes.}
		\label{fig:bbox-iou-inf-threshold-count}
	\end{subfigure}
	\caption{Ablation studies:
		(\ref{fig:ablation_weight_regr_losses}) weights for unsupervised regression loss on RPN and RoI.
		(\ref{fig:bbox-iou-cls-regr-loss}) classification vs regression loss on bbox IoU branch.
(\ref{fig:ablation_with_without_filtering_bbox}) filtering bbox on inference with bbox IoU classification score.
		(\ref{fig:bbox-iou-inf-threshold-count}) count bboxes filtered by inference threshold  during training.
	}
	\label{fig:ablations}
\end{figure*}


\begin{table*}[bt]
	\footnotesize
	\setlength{\tabcolsep}{1.2pt}
	\begin{center}
		\begin{tabular}{!c|^c|^c|^c|^c|^c|^c|^c|}
			\# &  &  &  &   &  &  &  \\
			\hline\hline
0                     & 0.5  & 31.775 & 51.450 & 34.190 & 16.952 & 34.384 & 41.549 \\
\rowstyle{\bfseries}1 & 1.0  & 31.947 & 51.530 & 34.270 & 16.949 & 34.900 & 41.306 \\
2                     & 2.0  & 31.754 & 51.078 & 34.143 & 16.691 & 35.008 & 41.670 \\
3                     & 4.0  & 30.445 & 49.387 & 32.727 & 15.044 & 33.200 & 40.209 \\
		\end{tabular}
	\end{center}
	\caption{Performance varying the weight loss  on unsupervised regression losses.}
	\label{tab:ablation_training_regression_unsup}
\end{table*}

\begin{table*}[bt]
	\footnotesize
	\setlength{\tabcolsep}{1.2pt}
	\begin{center}
		\begin{tabular}{c|l|c|c|c|c|c|c|}
			\# & Method &  &  &   &  &  &  \\
			\hline\hline
1 & UT                   & 31.027 & 50.757 & 33.056 & 17.014 & 33.684 & 40.322 \\
2 & Ours (with filter)    & 31.604 & 51.181 & 33.962 & 16.816 & 34.283 & 40.809 \\
3 & Ours (w/out filter)   & 31.509 & 51.118 & 33.564 & 16.848 & 34.684 & 40.582 \\
\end{tabular}
	\end{center}
	\caption{Performance comparison with original Unbiased Teacher (UT) model: (2) Training with BBox IoU branch with and (3) w/out pseudo-labels filtering.}
	\label{tab:ablation_with_without_filtering_bbox}
\end{table*}

\begin{table*}[bt]
	\footnotesize
	\setlength{\tabcolsep}{1.2pt}
	\begin{center}
		\begin{tabular}{!c|^l|^c|^c|^c|^c|^c|^c|}
			\# &  &  &  &   &  &  &  \\
			\hline\hline
1 					  & 0.5    & 31.199 & 51.009 & 33.047 & 16.187 & 34.000 & 40.180 \\
2 					  & 0.6    & 31.128 & 50.785 & 33.268 & 17.102 & 33.805 & 39.932 \\
3                     & 0.7    & 31.461 & 51.319 & 33.637 & 16.714 & 34.217 & 40.100 \\
\rowstyle{\bfseries}4 & 0.75   & 31.604 & 51.181 & 33.962 & 16.816 & 34.283 & 40.809 \\
5 					  & 0.8    & 31.336 & 50.601 & 33.707 & 16.327 & 34.180 & 40.476 \\
6 					  & 0.9    & 27.125 & 43.515 & 28.800 & 12.815 & 29.486 & 36.034 \\
		\end{tabular}
	\end{center}
	\caption{Performance using BBox IoU classification branch with inference threshold  fixed to 0.5 and varying training threshold .}
	\label{tab:ablation_training_threshold}
\end{table*}

\begin{table*}[bt]
	\footnotesize
	\setlength{\tabcolsep}{1.2pt}
	\begin{center}
		\begin{tabular}{!c|^c|^c|^c|^c|^c|^c|^c|}
			\# &  &  &  &   &  &  &  \\
			\hline\hline
0 					  & 0.3   & 31.404 & 51.205 & 33.792 & 16.273 & 34.542 & 40.851 \\
\rowstyle{\bfseries}1             & 0.4   & 31.630 & 51.185 & 34.044 & 17.387 & 34.494 & 40.784 \\
2 					  & 0.5   & 31.604 & 51.181 & 33.962 & 16.816 & 34.283 & 40.809 \\
3					  & 0.6   & 31.158 & 50.227 & 33.418 & 16.203 & 33.687 & 40.323 \\
4 					  & 0.7   & 30.649 & 49.216 & 33.138 & 16.532 & 33.409 & 39.542 \\
\end{tabular}
	\end{center}
	\caption{Performance using BBox IoU classification branch with training threshold  fixed to 0.75 and varying inference threshold .}
	\label{tab:ablation_evaluation_threshold}
\end{table*}



\begin{table*}[bt]
	\footnotesize
	\setlength{\tabcolsep}{1.2pt}
	\begin{center}
		\begin{tabular}{!c|^c|^c|^c|^c|^c|^c|^c|^c|^c|^c|}
			\# &  &  & scores & deltas  &  &  &   &  &  &  \\
			\hline\hline
1         &            &            &            &            & 31.027 & 50.757 & 33.056 & 17.014 & 33.684 & 40.322 \\
2         & \checkmark &            &            &            & 31.947 & 51.530 & 34.270 & 16.949 & 34.900 & 41.306 \\
3         & \checkmark & \checkmark &            &            & 31.754 & 51.189 & 34.032 & 16.850 & 34.657 & 41.320 \\
\rowstyle{\bfseries}4 & \checkmark & \checkmark & \checkmark &            & 32.166 & 51.772 & 34.765 & 16.647 & 34.999 & 41.870 \\
5         & \checkmark & \checkmark & \checkmark & \checkmark & 31.923 & 51.464 & 34.070 & 16.202 & 35.197 & 41.368 \\
6         &            & \checkmark & \checkmark & \checkmark & 31.630 & 51.185 & 34.044 & 17.387 & 34.494 & 40.784 \\
\end{tabular}
	\end{center}
	\caption{Study on unsupervised regression losses and IoU classification loss.}
	\label{tab:net_full}
\end{table*}

\subsection{Ablation study}
\label{ablation-study}

\noindent\textbf{Unsupervised regression loss}.
In this experiment, we empirically show that we can also use regression losses on RPN and RoI head for the unsupervised part.
We test different weights for the constant  in the loss formula (see eq. \ref{eq:all_losses}).
In Figure \ref{fig:ablation_weight_regr_losses} and Table \ref{tab:ablation_training_regression_unsup}, we can see that greatly amplifying the contribution can be deleterious, becoming counterproductive in the case of  equal to 4.\\

\noindent\textbf{Bounding box IoU branch loss type}.
Our proposal involves a new IoU classification task, trained with a binary cross-entropy function.
In this experiment, we test how performance changes in case our new branch learns a regression task instead of a classification, using a \textit{smooth L1} loss.
In this case, the ground-truth is represented by the real IoU value between the bbox and the ground-truth.
In Figure \ref{fig:bbox-iou-cls-regr-loss}, we can see that classification branch is a bit more stable and reaches a slightly higher performance.\\

\noindent\textbf{With and without filtering bboxes}.
The bbox IoU branch learns to recognize high quality bounding boxes and, as the default behavior, also to pre-filter Teacher's pseudo-bboxes depending on our new threshold score.
In Figure \ref{fig:ablation_with_without_filtering_bbox} and in Table \ref{tab:ablation_with_without_filtering_bbox} (rows \#2 and \#3), we see that our new branch contributes to the increase of the general performance (+0.48\% mAP).
Then, another small improvement is given by the filtering phase, increasing the performance by +0.1\% mAP.\\

\noindent\textbf{Bounding box training threshold }.
In this experiment, we test the bbox IoU classification branch, setting inference threshold  to 0.5 and varying the training threshold .
From Table \ref{tab:ablation_training_threshold}, it is clear that the choice of a correct threshold greatly influences the performance. On the one hand, if the threshold is too low, it does not help the network to learn more descriptive feature maps. On the other hand, if it is too high, the risk to wrongly filter out the bounding boxes will increase.
As we can see in Fig. \ref{fig:bbox-iou-inf-threshold-count}, with the increase of IoU threshold , the number of teacher pseudo-bboxes filtered during the training increases exponentially.
This is likely due to an imbalance in training, where the higher the threshold, the fewer high-quality examples are available.
The best value is in the middle between the threshold  (0.5) and the IoU maximum value 1.0.

\noindent\textbf{Bounding box inference filter threshold }.
In this experiment, we test our bbox IoU branch, setting the training threshold  to 0.75 (best value previously found) and varying the inference threshold .
In Table \ref{tab:ablation_evaluation_threshold}, we see that the best value for this threshold is in the middle as expected because the branch is trained to reply 1 if the bbox is good enough and 0 otherwise.\\



\noindent\textbf{IL-net: Improving Localization net}.
Finally, we test the full architecture IL-net, composed of the unsupervised regression losses and the new IoU classification branch.
Since, using both of them, the contribution of the new branch is absorbed by the loss of unsupervised regression (see rows 2 and 5 in Table \ref{tab:net_full}), we performed an ablation study reducing the values in input to the new branch (see eq. \ref{eq:iou_branch}).
This analysis has allowed us to highlight that by removing the contribution of the deltas, we can increase the general performance.
This behavior could be explained by the fact that the deltas are optimized from both losses ( and ), causing the conflict as a result.



