\subsection{Proof of Proposition~\ref{prop:term-upper-critical}} \label{app:term-upper-critical}

In this subsection we prove Proposition~\ref{prop:term-upper-critical}.
Given a finite set~, we regard the elements of  as vectors.
Given two vectors , we define a scalar product by setting .
Further, elements of~ are regarded as matrices, with the usual matrix-vector multiplication.

It will be convenient for the proof to measure the termination time of pBPA starting in an arbitrary initial configuration~,
 not just with a single initial symbol .
To this end we generalize , , etc.\ to , , etc.\ in the straightforward way.

It will also be convenient to allow ``pBPA'' that have transition rules with more than two stack symbols on the right-hand side.
We call them {\em relaxed pBPA}.
All concepts associated to a pBPA, e.g., the induced Markov chain, termination time, etc., are defined analogously for relaxed pBPA.

A relaxed pBPA is called {\em strongly connected}, if the DAG of the dependence relation on its stack alphabet consists of a single SCC.

For any , define  as the Parikh image of~,
 i.e., the vector of  such that  is the number of occurrences of  in .
Given a relaxed pBPA~, let  be the matrix with
 
We drop the subscript of~ if  is clear from the context.
Intuitively,  is the expected number of -symbols pushed on the stack when executing a rule with  on the left hand side.
For instance, if  and , then .
Note that  is nonnegative.
The matrix~ plays a crucial role in the analysis of pPDA and related models (see e.g.~\cite{EY:RMC-SG-equations-JACM})
 and in the theory of branching processes~\cite{Harris:book}.
We have the following lemma:
\begin{lemma} \label{lem:cone-vector}
 Let  be an almost surely terminating, strongly connected pBPA.
 Then there is a positive vector  such that
  , where  is meant componentwise.
 All such vectors~ satisfy ,
  where  denotes the least rule probability in~,
  and  and  denote the least and the greatest component of~, respectively.
\end{lemma}
\begin{proof}
  Let .
  Since  is strongly connected, there is a sequence  with  such that  depends directly on~
   for all .
  A straightforward induction on~ shows that ; i.e.,  is {\em irreducible}.
  The assumption that  is almost surely terminating implies that
   the spectral radius of~ is less than or equal to one, see, e.g., Section 8.1 of~\cite{EY:RMC-SG-equations-JACM}.
Perron-Frobenius theory (see, e.g., \cite{book:BermanP}) then implies that there is a positive vector  such that
   ;
   e.g., one can take for~ the dominant eigenvector of~.

  Let .
  It remains to show that .
  The proof is essentially given in~\cite{EKL10:SICOMP}, we repeat it for convenience.
  W.l.o.g.\ let .
  We write  for .
  W.l.o.g.\ let  and .
  Since  is strongly connected, there is a sequence  with 
   such that  depends on~ for all .
  We have
   
  By the pigeonhole principle there is  with  such that
   
  We have , which implies  and so .
  On the other hand, since  depends on~, we clearly have .
  Combining those inequalities with~\eqref{eq:cone-vector-pigeonhole} yields .
\qed
\end{proof}

Given a relaxed pBPA~ and vector ,
 we say that  is {\em -progressive}, if  has, for all ,
 a rule  such that .
The following lemma states that, intuitively, any pBPA can be transformed into a -progressive relaxed pBPA
 that is at least as fast but no more than  times faster.
\begin{lemma} \label{lem:progressive}
 Let  be an almost surely terminating pBPA with stack alphabet~.
 Let  denote the least rule probability in~, and let  with .
 Then one can construct a -progressive, almost surely terminating relaxed pBPA~
  with stack alphabet~ such that for all  and for all 
 
 where  and  are the probability measures associated with  and , respectively.
 Furthermore, the least rule probability in~ is at least , and .
 Finally, if , then .
\end{lemma}
\begin{proof}
\newcommand{\Con}{\mathit{Con}}
A sequence of transitions  is called {\em derivation sequence from  to },
 if for all  the symbol  occurs in .
The {\em word induced} by a derivation sequence 
 is obtained by taking , replacing an occurrence of~ by~,
 then replacing an occurrence of~ by~, etc., and finally replacing an occurrence of~ by~.

Given a pBPA~ and a derivation sequence
 
 with  for all ,
we define the {\em contraction}  of~, a set of -transitions with possibly more than two symbols on the right hand side.
The contraction  will include a rule , where  is the word induced by~.
We define~ inductively over the length~ of~.
If , then .
If , let  and define
 
 i.e.,  is the set of -transitions in~ with  replaced by .
W.l.o.g.\ assume .
Then we define
 
The following properties are easy to show by induction on~:
\begin{itemize}
 \item[(a)]
   contains , where  is the word induced by~.
 \item[(b)]
  The rule probabilities are at least .
 \item[(c)]
  Let  be the relaxed pBPA obtained from~ by replacing  with .
  Then each path in  corresponds in a straightforward way to a path in~,
   namely to the path obtained by ``re-expanding'' the contractions.
  The corresponding path in~ has the same probability
   and is not shorter but at most  times longer than the one in~.
 \item[(d)]
  Let  be as in~(c).
  Then .
  Let us prove that explicitly.
  The induction hypothesis  is trivial.
  For the induction step, using the definition for~ in~\eqref{eq:delta-2} and
   ,
   we know by the induction hypothesis that .
  This implies
   
   Since  and  may differ only in the -row, we have .
 \item[(e)]
  Let  be as in (c) and~(d).
  If , then .
  This follows as in~(d), with the inequality signs replaced by equality.
\end{itemize}

Associate to each symbol  a shortest derivation sequence
 
  from  to~.
Since  is almost surely terminating, the length of~ is at most~ for all .
Let ,
 and let  denote the word induced by ,
 and let  denote the word induced by the derivation sequence .
We have ,
 so we can choose  such that .
Choose  such that  induces~.
(Of course, if  has length zero, take .)
Note that .

The relaxed pBPA~ from the statement of the lemma is obtained by replacing, for all ,
 the first rule of~ with .
The properties (a)--(e) from above imply:
\begin{itemize}
 \item[(a)]
  The relaxed pBPA  is -progressive.
 \item[(b)]
  The rule probabilities are at least .
 \item[(c)]
  For each finite path  in~ from some  to~ there is a
   finite path  in~ from  to~ such that  and .
  Hence,  holds for all ,
   which implies .
 \item[(d)]
  We have .
 \item[(e)]
  If , then .
\end{itemize}
This completes the proof of the lemma.
\qed
\end{proof}

\begin{proposition} \label{prop:critical-u-progressive}
 Let  be an almost surely terminating relaxed pBPA with stack alphabet~.
 Let  be such that  and  and  is -progressive.
 Let  denote the least rule probability in~.
 Let .
 Then for each  there is  such that
   
\end{proposition}
\begin{proof}
For each  we define a function  by setting
 
The following lemma states important properties of~.
\begin{lemma} \label{lem:g-properties}
  The following holds for all :
  \begin{itemize}
    \item[(a)]
     For all  we have .
    \item[(b)]
     For all  we have .
    \item[(c)]
     For all  we have . In particular, .
  \end{itemize}
\end{lemma}
\begin{proof}[Proof of the lemma]\mbox{}
 \begin{itemize}
  \item[(a)]
   Clearly, .
   The inequality  follows from (b).
  \item[(b)]
   We have:
   
   The inequality  follows from~(c).
  \item[(c)]
   We have
   
   Since  is -progressive, there is a rule  with .
   Hence, for  we have .
 \end{itemize}
This proves the lemma.
\qed
\end{proof}

Let in the following .
Given a run  and , we write  for the symbol  for which .
Define
 

\begin{lemma} \label{lem:exponential-martingale}
 is a martingale.
\end{lemma}
\begin{proof}[Proof of the lemma]
Let us fix a path  of length  and let  be an arbitrary run of .
First assume that .
Then we have:

If , then for every  we have .
Hence,  is a martingale.
\qed
\end{proof}

Since  and since  by Lemma~\ref{lem:g-properties}(a),
 we have , so the martingale is bounded.
Since, furthermore,  (we write only  in the following) is finite with probability~,
 it follows using Doob's Optional-Stopping Theorem (see Theorem~10.10~(ii) of~\cite{book:Williams})
 that .
Hence we have for each :

Rearranging the inequality, we obtain

For the following we set .
We want to give an upper bound for the right hand side of~\eqref{eq:before-hopital}.
To this end we will show:
 
Combining \eqref{eq:before-hopital} with \eqref{eq:quotient}, we obtain
 
which implies the proposition.

To prove~\eqref{eq:quotient}, we compute limits for the nominator and the denominator separately.
For the nominator, we use l'Hopital's rule to obtain:
 
For the denominator of~\eqref{eq:quotient} we consider first the following limit:
 
This proves~\eqref{eq:quotient}
 and thus completes the proof of Proposition~\ref{prop:critical-u-progressive}.
\qed
\end{proof}

The following lemma serves as induction base for the proof of Proposition~\ref{prop:term-upper-critical}.
\begin{lemma} \label{lem:critical-strongly-connected}
  Let  be an almost surely terminating pBPA with stack alphabet~.
  Assume that all SCCs of~ are bottom SCCs.
  Let  denote the least rule probability in~.
  Let .
Then for each  there is  such that
   
\end{lemma}
\begin{proof}
Decompose  into its SCCs, say ,
 and let the pBPA~ be obtained by restricting~ to the -symbols.
For each , Lemma~\ref{lem:cone-vector} gives a vector .
W.l.o.g.\ we can assume for each~ that the largest component of~ is equal to~,
 because  can be multiplied with any positive scalar without changing the properties guaranteed by Lemma~\ref{lem:cone-vector}.
If the vectors~ are assembled (in the obvious way) to the vector ,
 the assertions of Lemma~\ref{lem:cone-vector} carry over;
 i.e., we have  and  and .
Let  be the -progressive relaxed pBPA from Lemma~\ref{lem:progressive},
 and denote by~ and  its associated probability measure and least rule probability, respectively.
Then we have:

\qed
\end{proof}

\newcommand{\GammaH}{\Gamma_{\it high}}
\newcommand{\GammaL}{\Gamma_{\it low}}
\newcommand{\DeltaH}{\Delta_{\it high}}
\newcommand{\DeltaL}{\Delta_{\it low}}
Now we are ready to prove Proposition~\ref{prop:term-upper-critical}, which is restated here.
\begin{qproposition}{\ref{prop:term-upper-critical}}
 \stmtproptermuppercritical
\end{qproposition}
\begin{proof}
 Let  be the  from Lemma~\ref{lem:critical-strongly-connected}.
 We show by induction on~:
 
 Note that \eqref{eq:ct-induction} implies the proposition.
 The case  (induction base) is implied by Lemma~\ref{lem:critical-strongly-connected}.
 Let .
 Partition  into  such that 
  contains the variables of the SCCs of depth~ in the DAG of SCCs,
  and  contains the other variables (in ``higher'' SCCs).
 If , then we can restrict~ to the variables that are in the same SCC as~,
  and Lemma~\ref{lem:critical-strongly-connected} implies~\eqref{eq:ct-induction}.
 So we can assume .

 Assume for a moment that  holds for a run~;
  i.e., we have:
 
 It follows that one of the following events is true for~:
 \begin{itemize}
  \item[(a)]
   At least  steps in~ have a -symbol on top of the stack.
   More formally,
    
  \item[(b)]
   Event~(a) is not true, but at least  steps in~ have a -symbol on top of the stack.
   More formally,
    
 \end{itemize}
 In order to give bounds on the probabilities of events (a) and~(b),
  it is convenient to ``reshuffle'' the execution order of runs in the following way:
 Whenever a rule  is executed, we do not replace the -symbol on top of the stack by~,
  but instead we push only the -symbols in~ on top of the stack, whereas the -symbols in~
  are added to the {\em bottom} of the stack.
 Since  is a pBPA and thus does not have control states,
  the reshuffling of the execution order does not influence the distribution of the termination time.
 The advantage of this execution order is that each run can be decomposed into two phases:
 \begin{itemize}
  \item[(1)]
   In the first phase, the symbol on the top of the stack is always a -symbol.
   When rules are executed, -symbols may be produced, which are added to the bottom of the stack.
  \item[(2)]
   In the second phase, the stack consists of -symbols exclusively.
   Notice that by definition of , no new -symbols can be produced.
 \end{itemize}
 In terms of those phases, the above events (a) and~(b) can be reformulated as follows:
 \begin{itemize}
  \item[(a)]
   The first phase of~ consists of at least  steps.
   The probability of this event is equal to
    
   where  is the pBPA obtained from~ by deleting all -symbols
   from the right hand sides of the rules and deleting all rules with -symbols on the left hand side,
   and  is its associated probability measure.
  \item[(b)]
   The first phase of~ consists of fewer than  steps
    (which implies that at most  -symbols are produced during the first phase),
    and the second phase consists of at least  steps.
   Therefore, the probability of the event~(b) is at most
    
    where  is the pBPA~ restricted to the -symbols,
     and  is its associated probability measure.
   Notice that  for large enough~.
   Furthermore, by the definition of~, the SCCs of~ are all bottom SCCs.
   Hence, by Lemma~\ref{lem:critical-strongly-connected}, the above maximum is at most~.
 \end{itemize}
 Summing up, we have for almost all :
 
 This completes the induction proof.
\qed
\end{proof}
