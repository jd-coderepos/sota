\documentclass[a4paper,12pt,onecolumn]{article}



\usepackage{amsthm}






















\addtolength{\textheight}{2cm}
\addtolength{\hoffset}{-1cm}
\addtolength{\textwidth}{2cm} 



\usepackage{graphics} 

\usepackage{epsfig} 

\usepackage{mathptmx} 

\usepackage{times} 

\usepackage{amsmath} 

\usepackage{amssymb}  

\usepackage{amsthm}

\usepackage{color}

\usepackage{algorithm}

\usepackage{algorithmic}

\usepackage{enumerate}

\usepackage{caption}

\newtheorem{thm}{Theorem}
\newtheorem{prop}{Proposition}
\newtheorem{cor}{Corollary}
\newtheorem{lem}{Lemma}
\newtheorem{defn}{Definition}
\newtheorem{rem}{Remark}
\newtheorem{ex}{Example}


\newcommand{\RR}{{\mathbb{R}}}
\newcommand{\NN}{{\mathbb N}}
\newcommand{\SSS}{{\mathbb  S}}
\newcommand{\CC}{{\mathbb C}}
\newcommand{\abs}[1]{\lvert#1\rvert}
\newcommand{\norm}[1]{\lVert#1\rVert}
\newcommand{\ds}{\displaystyle}
\newcommand{\Rset}{{\mathbb{R}}}

\newcommand{\scal}[1]{\left\langle#1\right\rangle}




\newcommand{\XX}{{\mathcal X }}
\newcommand{\YY}{{\mathcal Y }}
\newcommand{\EE}{{\mathcal E }}
\newcommand{\HH}{{\mathbb H }}
\newcommand{\BB}{{\mathcal  B}}
\newcommand{\DD}{{\mathcal  D}}
\newcommand{\UU}{{\mathcal  U}}
\newcommand{\LL}{{\mathcal  L}}
\newcommand{\GG}{{\mathcal  G}}
\newcommand{\MM}{{\mathcal  M}}

\newcommand{\uu}{{\mathbf u }}
\newcommand{\xx}{{\mathbf x }}
\newcommand{\TT}{{\mathbf T }}
\newcommand{\G}{{\mathbf g }}
\newcommand{\ol}[1]{\overline{#1}}
\newcommand{\dv}[2]{{\frac{\partial #1}{\partial #2}}}
\newcommand{\dvv}[2]{{\frac{\partial^2 #1}{\partial {#2}^2}}}
\newcommand{\drvd}[2]{{\displaystyle\frac{\mbox{\rm d}#1}{\mbox{\rm d}#2}}}
\newcommand{\drvp}[2]{{\displaystyle\frac{\partial #1}{\partial #2}}}
\newcommand{\dotex}{{\frac{d}{dt}}}

\newcommand{\ket}[1]{\left|#1\right>}
\newcommand{\bra}[1]{\left<#1\right|}
\newcommand{\bket}[1]{\left<#1\right>}

\newcommand{\vw}{\textbf{}}
\newcommand{\vW}{\Omega}
\newcommand{\vv}{{\vec{ v} }}
\newcommand{\vV}{{\mathbf V }}
\newcommand{\va}{{\mathbf a}}
\newcommand{\vA}{{\mathbf A}}
\newcommand{\vG}{{\mathbf A}_{grav}}
\newcommand{\vg}{{\mathbf a_{grav}}}
\newcommand{\vb}{{\mathbf b}}
\newcommand{\vB}{{\mathbf B}}

\newcommand{\Rg}{{\mathbb R^{\text{dim } \mathfrak g}}}







\begin{document}


\title{The Invariant Extended Kalman filter as a stable observer}
\author{Axel Barrau, Silv\` ere Bonnabel
\thanks{A. Barrau and S. Bonnabel are with MINES
ParisTech, PSL Research University, Centre for
robotics, 60 Bd St Michel 75006 Paris, France.{\tt\small [axel.barrau,silvere.bonnabel]@mines-paristech.fr}} }
\date{}

\maketitle

\thispagestyle{empty}

\pagestyle{empty}

\begin{abstract}
 We analyze the convergence aspects of the invariant extended Kalman filter (IEKF), when the latter is used as a deterministic non-linear observer on Lie groups, for continuous-time systems with discrete observations. One of the main features of invariant observers for left-invariant systems on Lie groups is that the estimation error is autonomous. In this paper we first generalize this result by characterizing the (much broader) class of systems  for which this property holds. Then, we leverage the result to prove for those systems the local stability of the IEKF around \emph{any} trajectory, under the standard conditions of the linear case. One mobile robotics example and one inertial navigation example illustrate the interest of the approach. Simulations evidence the fact that the EKF is capable of diverging in some challenging situations, where the IEKF with identical tuning keeps converging. 
\end{abstract}















\section{Introduction}



The design of non-linear observers is always a challenge, as except for a few classes of systems  (e.g.,  \cite{Gauthier-Kupka-book01}), no general method exists. Of course, the grail of non-linear observer design is to achieve global convergence  to zero of the state estimation error, but this is a very ambitious property to pursue. As a first step, a general method is to use standard linearization techniques, such as the extended Kalman filter (EKF) that makes use of Kalman equations to stabilize the linearized estimation error, and then attempt to derive local convergence properties around \emph{any} trajectory. This is yet a rare property to obtain in a non-linear setting (see, e.g., \cite{aghannan-rouchon-ieee03}), due to the fact that the linearized estimation error equation is time varying, and contrarily to the linear case it generally depends on the unknown true state we seek to estimate.  The EKF,  the most popular observer in the engineering world, provides an ``off the shelf" candidate observer, potentially able to deal with the time-varying nature of the linearized error equation, due to its adaptive gain tuning through a Riccati equation.  However, the EKF does not possess any optimality guarantee, and its efficiency is aleatory. Indeed, its main flaw lies in its very nature: the Kalman gain is computed assuming the estimation error is sufficiently small to be propagated analytically through a first-order linearization of the dynamics about the \emph{estimated} trajectory. When the estimate is actually far from the true state variable, the linearization is not valid, and results in an unadapted gain that may amplify the error. In turn, such positive feedback loop may lead to divergence of the filter. This is the reason why most of the papers dealing with the stability of the EKF (see \cite{boutayeb,song-grizzle-95,reif,bonnabel2012contraction}) rely on the highly non-trivial assumption that the eigenvalues of the Kalman covariance matrix  computed about the \emph{estimated} trajectory are lower and upper bounded by strictly positive scalars.  To the authors' knowledge, only a few papers deal with the stability of the EKF without invoking this assumption \cite{krener2003convergence}. It is then replaced by second-order properties whose verification can prove difficult in practical situations. This lack of guarantee is also due to the fact the filter \emph{can} diverge indeed in a number of applications. Note that,  beyond the general theory, there are not even that many engineering examples where the EKF is proved to be (locally) stable. 

The present paper builds upon the theory of symmetry preserving observers  \cite{bonnabel2008symmetry,bonnabel2009non} and notably the theory of invariant Kalman filtering \cite{bonnabel2007left,bonnabel2009invariant,martin2010generalized,barrau2013intrinsic}  in a purely \emph{deterministic} context. As such, it is a contribution to the theory of non-linear observer design on Lie groups that has lately attracted considerable interest, notably for attitude estimation,  see, e.g.,  \cite{mahony2005complementary,Vasconcelos,barczyk2013invariant,
hua2010attitude,lageman2010gradient,grip2015globally,izadi2014rigid}. The detailed contributions and organization of the paper are as follows.  





 
In Section \ref{sect::deterministic}, we recall the main contribution of \cite{bonnabel2008symmetry,bonnabel2009non} is to evidence the fact that for left-invariant systems on Lie groups, non-linear observers may be designed in such a way that the left-invariant estimation error obeys an autonomous equation, a key property for observer design on Lie groups. We show here this property of the error equation can actually be obtained for a \emph{much} broader class of systems, and we characterize this class. Very surprisingly, it turns out that, up to a suitable non-linear change of variables, the error evolution (in the absence of measurements) obeys a \emph{linear} differential equation.

 
In Section    \ref{sect::IEKF}, we focus on the invariant extended Kalman filter (IEKF) \cite{bonnabel2007left} when applied to the broad class of systems of Section \ref{sect::deterministic}. We consider continuous-time models with discrete observations, which best suits navigation systems where high rate  sensors governing the dynamics are to be combined with low rate sensors \cite{farrell2008aided}. We  change a little the IEKF equations to cast them into a matrix Lie group framework, more handy to use than   the usual abstract Lie group formulation of \cite{bonnabel2007left}. We then prove, that under the standard convergence conditions of the linear case \cite{deyst}, applied to   the linearized model around the \emph{true} state, the IEKF is an asymptotic observer around \emph{any} trajectory of the system, a rare to obtain property. This way, we produce a generic observer with guaranteed local convergence properties under natural assumptions, for a broad class of systems on Lie groups, whereas this property has so far only been reserved to specific examples on Lie groups.   This also allows putting on firm theoretical ground the good behavior of the IEKF in practice, as already noticed in a few papers, see e.g.,  \cite{barczyk2013invariant,barrau2013intrinsic,barczyk2015invariant}. 



In Section \ref{sect::examples:A} we consider a mobile robotics example, where a unicycle robot (or simplified car) tries to estimate its position and orientation from GPS position (only) measurements, or alternatively landmarks range and bearing measurements. On this example of engineering interest, the IEKF is proved to converge around \emph{any}  trajectory using the results of the paper, which is a contribution in itself. Simulations indicate the IEKF is always superior to the EKF and may even outperform the latter in challenging situations.  

In Section \ref{sect::examples:B} we consider the highly relevant problem of an unmanned aerial vehicle (UAV) navigating with accelerometers and gyrometers, and range and bearing measurements of known landmarks. Although the system is not invariant in the sense of \cite{bonnabel2008symmetry,bonnabel2009non}, it is proved to fit into our framework so that the  autonomous error equation property of \cite{bonnabel2009non}  holds, a fact never  noticed before to our best knowledge (except in our preliminary conference paper \cite{barrau-bonnabel-cdc14}). The IEKF is shown to converge around \emph{any} trajectory using the results of the paper, which is a contribution in itself. Moreover, it is shown to outperform the EKF which even  diverges when, as in high precision navigation, the user has way more trust in the inertial sensors  than in the landmark measurements. 




The  main contributions can be summarized as follows:
\begin{itemize}
\item The class of systems, for which the key result of \cite{bonnabel2009non} about the (state) error equation autonomy holds, is completely characterized, and actually shown to be much broader than left-invariant systems. 
\item The autonomy of the error equation is proved to come with a very intriguing property: a well-chosen non-linear function of the non-linear error is proved to obey a linear differential equation.
\item In turn, this property allows proving that, for the introduced class of systems, the IEKF used in a deterministic context possesses powerful local convergence guarantees that the standard EKF lacks. 
 \item Two examples of navigation illustrate the applicability of the results, and simulations indicate indeed the IEKF is always superior to the EKF, and may turn out to literally outperform the latter when confronted with some challenging situations - the EKF being even capable to diverge. 
\end{itemize}


 















\section{A special class of multiplicative systems}
\label{sect::deterministic}

\subsection{An introductory example}\label{introd:ex}

Consider a linear (deterministic) system . Consider two trajectories of this system, say, a reference trajectory   and another one . The  discrepancy between both trajectories  satisfies the linear equation .  This is a key property for the design of linear convergent observers, as during the propagation step, the evolution of the error between the true state and the estimate does \emph{not} depend on the true state's trajectory. 




Consider now the following non-linear standard  model of the two-dimensional non-holonomic car. Its state is defined by three parameters : heading  and position . The velocity  is given by an odometer, the angular velocity  is measured by a differential odometer or a gyrometer. The equations read (see, e.g., \cite{de1998feedback}):

Now consider a reference trajectory  and a second trajectory  with different initial conditions but same inputs. The exact propagation of the ``error" , ,  satisfies:

where we let . We see the time derivative of   is not a function of  only: it also involves  and  individually. Moreover, the equation is non-linear. These features, characteristic of non-linear systems, make the design of observers way more complicated in the non-linear case. Now, let us introduce the following non-linear error, where  denotes the planar rotation matrix of angle   (see definition of  below):

which is equal to 0 indeed if and only if both trajectories coincide. We are about to prove by elementary means a surprising property that will be generalized by Theorem \ref{dechire:thm}.
\begin{prop}Contrarily to the linear error obeying  \eqref{ouaich}, the alternative non-linear error \eqref{xi:ccar} obeys the following  \emph{linear} and autonomous equation although the system, and the error, are totally non-linear:

\end{prop}
\begin{proof}
We will use the notations   . Since we have   as in the linear case above, only the two last terms of  change over time. Moreover,  commutes with ,  and  and . Thus we have:

In the second to last equality we used the relation . Equation \eqref{eq::linear_2D} is proved.
\end{proof}
 The present section provides a novel geometrical framework - encompassing this example - to characterize systems on Lie groups for which such a property holds. In turn, such a property will simplify the convergence analysis of non-linear observers, namely the IEKF,  due to the implied similarities with the linear case. 






\subsection{Systems on Lie groups with state trajectory independent error propagation property}

Let  be a matrix Lie group whose Lie algebra is denoted  and has dimension . We consider a class of dynamical systems:

where the state  lives in the Lie group  and  is an input variable. Consider two distinct trajectories  and  of \eqref{eq:IEKF_model}.  Define the left-invariant and right-invariant errors   and  between the two trajectories as:


The  terminology stems from the invariance of e.g.,  \eqref{leftinv} to (left) multiplications  for . 
\begin{defn}
The left-invariant and right-invariant errors are said to have a  state-trajectory independent propagation if they satisfy a differential equation of the form .
\end{defn}

Note that, in general the time derivative of  is a complicated function depending on  and both  and  in a way that does not boil down to a function of , see for instance eq \eqref{ouaich} above. The following result allows characterizing the class of systems of the form \eqref{eq:IEKF_model} for which the property holds. 

\begin{thm}
\label{thm::CNS}
 The three following conditions are equivalent for the dynamics \eqref{eq:IEKF_model}:
\begin{enumerate}[i]
\item The left-invariant error \eqref{leftinv} is state trajectory independent
\item The right-invariant error \eqref{rightinv} is state trajectory independent
\item For all  and  we have (in the tangent space at ):

\end{enumerate}
where  denotes the identity matrix. Moreover, if one of these conditions is satisfied we have 

\end{thm}

\begin{proof}
Assume we have  for a certain function  and any  , where  and  are solutions of \eqref{eq:IEKF_model}. We have:

This has to hold for any  and . In the particular case where  we obtain:

Reinjecting \eqref{g_f_22} in \eqref{g_f_11} we obtain:

The converse is trivial and the proof is analogous for right-invariant errors.
\end{proof}

\begin{rem}
The particular cases of left-invariant and right-invariant dynamics, or the combination of both as follows, verify \eqref{eq::main_relation}. Let . We have indeed:

\end{rem}

\begin{rem}
In the particular case where  is a vector space with  standard addition as the group composition law,  the condition \eqref{eq::main_relation} boils down to  and we recover the affine functions. We thus see the class of system introduced here  appears as a generalization of the linear case. 
\end{rem}




In the next section we show that the dynamics of the form \eqref{eq:IEKF_model} with additional property  \eqref{eq::main_relation} have striking properties  generalizing those of linear systems. 





\subsection{Log-linear property of the error propagation}
In the sequel, we will systematically consider systems of the form \eqref{eq:IEKF_model} with the additional property  \eqref{eq::main_relation}, i.e.  systems on Lie groups defined by






For such systems, Theorem \ref{thm::CNS} proves that the left (resp. right) invariant error  is a solution to the equation   where  is given by   \eqref{g_f_1} (resp. \eqref{g_f_2}).  We have the following novel and striking property. 





\begin{thm}\label{dechire:thm}[Log-linear property of the error]
Consider the left or right invariant error  as defined by \eqref{leftinv} or \eqref{rightinv} between two arbitrarily far  trajectories of \eqref{eq::mult_linear}, the superscript   denoting indifferently  or . Let  and  be defined as in Appendix \ref{sect::tuto_Lie_groups}. Let  be such that initially . Let  be  defined by . If  is defined for  by the \emph{linear} differential equation in  

\emph{then}, we have for the true non-linear error , the correspondence \emph{at all times} and for arbitrarily large errors 

 \end{thm}The latter result, whose proof has been moved to the Appendix, shows that a wide range of nonlinear problems (see examples below) can lead to linear error equations provided the error variable is correctly chosen.  We also see the results displayed in the previous introductory example of Section \ref{introd:ex} are mere applications of the latter theorem, as the non-holonomic car example turns out to perfectly fit into our framework (see Section \ref{sect::examples:A}) and   in eq \eqref{xi:ccar} actually  merely is the Lie logarithm of the left-invariant error.   
 This will be extensively used in Section \ref{sect::IEKF}, and in the examples to prove stability properties of IEKFs.













\section{Invariant Extended Kalman Filtering}
\label{sect::IEKF}


In this section we first recap the equations of the Invariant EKF (IEKF), a variant of the EKF devoted to Lie groups space states, that has been introduced in continuous time in \cite{bonnabel2007left,bonnabel2009invariant}. We derive the equations in continuous time with discrete observations here, which has already been done in a restricted setting in \cite{barrau2013intrinsic}, and we propose a novel matrix (Lie group) framework to simplify the design. We then show that for the class of systems introduced in Section \ref{sect::deterministic}, under observability conditions, and painless conditions on the covariance matrices considered here as design parameters, the IEKF is a (deterministic) non-linear observer with local convergence properties around \emph{any} trajectory, a feature extremely rare to obtain in the field of non-linear observers, due to the dependency of the estimation error to the true unknown trajectory. The notions necessary to follow Section \ref{sect::IEKF} are given in Appendix \ref{sect::tuto_Lie_groups}. 

\subsection{Full system and IEKF general structure}


We consider in this section an equation on a matrix Lie group  of the form:

with  for all . This system will be associated to two different kinds of observations.

\subsubsection{Left-invariant observations}
The first family of outputs we are interested in write:

where  are known vectors.  The Left-Invariant Extended Kalman Filter (LIEKF) is defined in this setting through the following propagation  and update steps:
where the function  is to be defined in the sequel using error linearizations. 
A left-invariant error between true state  and estimated state  can be associated to this filter:

During the Propagation step,   and  are two trajectories of the system \eqref{eq::IEKF_modelle}. Thus, the error \eqref{tule} is independent from the true state trajectory from Theorem \ref{thm::CNS} and eq. \eqref{g_f_1} ! We have thus
Consider now the following linear differential equation in : 

where  is defined by . Theorem \ref{dechire:thm} implies the unexpected result:
\begin{prop}\label{mrpror}If  is defined as a solution to the  \emph{linear} system \eqref{line:eqrev} and   is defined as the solution to the \emph{nonlinear} error system \eqref{er_r:eqrev}, then if at time   we have  then the equality  is verified at all times , even for arbitrarily large initial errors.\end{prop}






Besides, at the update step, the evolution of the invariant error variable \eqref{tule} merely writes:

We see that the nice geometrical structure of the LIEKF allows the updated error   to be here again only a function of the error just before update , i.e. to be independent from the true state . 



\subsubsection{Right-invariant observations}
The second family of observations we are interested in have the form:

with the same notations as in the previous section.
The Right-Invariant EKF (RIEKF) is defined here as:

A right-invariant error can be associated to this filter:

Once again,  Theorem \ref{thm::CNS} proves the evolution of the error does not depend on the state of the system. The analog of Proposition \ref{mrpror} is thus easily derived for the error \eqref{skypi} and we skip it due to space limitations.

  
At the update step, the evolution of the invariant error variable reads:

so that the error update does not depend on the true state either. 


\subsection{IEKF gain tuning}\label{ouida}


In the standard theory of Kalman filtering, EKFs are designed for ``noisy" systems associated with the deterministic considered system. In a deterministic context, the covariance matrices  and  of the noises are left free to tune by the user, and are design parameters for the EKF used as  a non-linear observer. Yet, in the spirit of \cite{song-grizzle-95}, it is nevertheless convenient to  associate a ``noisy'' system with the considered deterministic system consisting of dynamics \eqref{eq::IEKF_modelle} with outputs \eqref{claude:eq} or \eqref{claudio:eq}. The obtained error equations can be linearized, and the standard Kalman equations applied to make this error decrease. This way, the matrices  and   can be \emph{interpreted} as covariance matrices. And in many engineering applications, the characteristics of the noises of the sensors are approximately known, so that the engineer can use the corresponding covariance matrices as a useful guide to tune (or design) the  non-linear observer, that is here the IEKF. This provides him with (at least) a first sensible tuning  of the parameter matrices, which is consistent with the trust he has in each sensor. Moreover,  in the same spirit, the IEKF viewed as a non-linear observer remedies a common weakness shared by numerous non-linear observers on Lie groups, as it conveys an information about its own accuracy through the computed covariance matrix . Although it comes with no rigorous interpretation in a deterministic context, the information conveyed by  may prove useful in applications. 


Note that,  in mobile robotics and navigation, the sensors are attached to the earth-fixed frame (e.g., a GPS) or to the body frame (e.g., a gyrometer). To \emph{interpret} them as covariance matrices in the IEKF framework (see below) those matrices  and  may have to undergo a change of frame yielding trajectory dependent tuning matrices  and , such as in the application examples in the sequel. This does not weaken the results, but however comes at the price of making the stability analysis a little more complicated. 



\subsubsection{Associated ``noisy" system}
To tune the IEKF \eqref{IEKF_propagation}-\eqref{LIEKF_update} or  \eqref{RIEKF_propp}-\eqref{RIEKF_update}, we associate to the system \eqref{eq::IEKF_modelle} the following
``noisy" system:

 where
  is a continuous white noise belonging to  whose covariance matrix is denoted by  (for a proper discussion on multiplicative noise for systems defined on Lie groups, see e.g. \cite{barrau2013intrinsic}). 



In the same way, we associate to the family of left-invariant observations \eqref{claude:eq} the following family of ``noisy" outputs:

where the ,  are noises with known characteristics.  To the family of right-invariant observations \eqref{claudio:eq} we associate the following family of ``noisy" outputs






\subsubsection{Linearized ``noisy" estimation error equation}
As in a conventional EKF, we assume the error to be small (here close to  as it is equal to  if ) so that the error system can be linearized to compute the gains . By definition, the Lie algebra  represents the infinitesimal variations around  of an element of . Thus the natural way to define a vector error variable  in  is (see Appendix \ref{sect::tuto_Lie_groups}):











During the Propagation step, that is for , elementary computations based on the results of Theorem \ref{thm::CNS} show that for the noisy model \eqref{eq::IEKF_model} we have

Defining  by  in the first case and  (i.e. ) in the second case, and using the superscript  to denote indifferently  or  we end up with the linearized error equation in : 

where  is defined by   and where we have neglected terms of order  as well as terms of order . The latter approximation, as well as the fact that  can be considered as white noise, are approximations that would require a proper justification in a stochastic setting. However,   they are part of the standard EKF methodology, see e.g.,  \cite{lefferts1982kalman} and justifying them is not the object of the present paper. Besides,   the emphasis is put here on   deterministic properties of the observer. 


Regarding the output,  we consider for instance the case of left-invariant observations, and define 
 through the exponential mapping \eqref{expmap}, i.e. . Moreover, for  let  denote  . 
The error update  \eqref{update:evolution:left:eq}, when the LIEKF update \eqref{LIEKF_update} is fed with the ``noisy" measurements  \eqref{claude:noise} becomes

To linearize it we proceed as follows. For  we have

using a simple Taylor expansion of the matrix exponential map. Expanding similarly equation \eqref{update:evolution:left:eq:noise} yields 
with  terms of order . 
Neglecting them  we finally get the following linearized error equation in 

where ,  and   are defined by

Now, let  reflect the trusted covariance of the modified process noise , and  the trusted covariance of the modified measurement noise .  
Note that, equations \eqref{line:eq} and \eqref{uppdate:eq} mimick those of a Kalman filter designed for the following auxiliary linear  system with discrete measurements: , . The standard Kalman theory thus suggests to compute  through the Riccati equation 


\subsection{Summary of IEFK equations}
In a deterministic context, the IEKF equations can be compactly recapped as follows

where the LIEKF (resp. RIEKF) is to be used in the case of left (resp. right) invariant outputs. The gain  is obtained in each case through the following Riccati equation


As concerns the LIEKF,  is defined by , and  is defined by .  
The design matrix parameters  are freely assigned by the user. When sensor noise characteristics are known, they can provide the user with a first sensible tuning of those matrices by considering the associated ``noisy" system \eqref{eq::IEKF_model}-\eqref{claude:noise} of Section \ref{ouida}. In this case, the matrices can be \emph{interpreted} in the following way:     denotes the covariance  of the modified process noise  and  the covariance matrix of the noise ,  and  being defined as:
  , .

As concerns the RIEKF implementation,  is defined by , and  by . The design matrix parameters  are freely assigned by the user. Considering the associated ``noisy" system \eqref{eq::IEKF_model}-\eqref{claudio:noise} of Section \ref{ouida} they can be interpreted as follows.  denotes the covariance of the modified process noise    and  the covariance matrix of the noise ,  and  being defined as:
  , .

\subsection{Stability properties}
The aim of the present section is to study the stability properties of the IEKF as a \emph{deterministic} observer for the system \eqref{eq::IEKF_modelle}-\eqref{claude:eq}, or alternatively \eqref{eq::IEKF_modelle}-\eqref{claudio:eq}.  We are about to prove the IEKF has  \emph{guaranteed} (local) stability properties, that  rely on the error equation properties   the  EKF does \emph{not} possess. The stability of an observer is defined as its ability to recover from a perturbation or an erroneous initialization:
\begin{defn}\label{deff}
Let  denote a continuous flow on a space  endowed with a distance . A flow  is an asymptotically stable observer of  about the trajectory   if there exists  such that:

\end{defn}
Theorem \ref{thm::localCV} below is the main result of the paper . It is a consequence of Theorem \ref{dechire:thm} of Section \ref{sect::deterministic}.  
J. J. Deyst and C. F. Price have shown in \cite{deyst} the following theorem, stating sufficient conditions for the Kalman filter to be a stable observer for \emph{linear} (time-varying) deterministic systems.

\begin{thm}[Deyst and Price, 1968]
\label{thm::Deyst_Price}Consider the  linear system ,  with  and let  denote the square matrix defined by .
If there exist  such that: 
\begin{enumerate}[i]
\item  \label{cond::Psi}
\item  where  \label{cond::Q}
\item  \label{cond::R}
\item  \label{cond::reachable}
\item  \label{cond::observable}
\end{enumerate}
Then the linear Kalman filter tuned with covariance matrices  and  is an asymptotically stable observer for the Euclidean distance. More precisely there exist  such that  for all  and  has  exponential decay.
\end{thm}

The main theorem of the present paper is the extension of this linear result to the non-linear case when the Invariant Extended Kalman Filter is used for systems of Section \ref{sect::deterministic}.
\begin{thm}
\label{thm::localCV}
Consider the system \eqref{eq::IEKF_modelle}-\eqref{claude:eq} (respectively  \eqref{eq::IEKF_modelle}-\eqref{claudio:eq}). Suppose the stability conditions of the linear Kalman filter given in Theorem \ref{thm::Deyst_Price} are verified  about the \emph{true} system's trajectory  (i.e. are verified for the linear system obtained by linearizing the system \eqref{eq::IEKF_modelle} with left (resp. right) invariant output about ). Then the Left (resp. Right) Invariant Extended Kalman Filter  estimate  defined at eq. \eqref{LIEKF:::eq} is an asymptotically stable observer of  in the sense of Definition \ref{deff}. Moreover, the convergence radius  is valid over the whole trajectory (i.e. is independent of the initialization time ).
\end{thm}
\begin{proof}
The full proof is technical and has been moved to Appendix \ref{proof::localCV}.  The rationale is to compare the evolution of the logarithmic error  defined as , with its linearization. For the general EKF, the control of second and higher order terms in the error equation is difficult because: 1- they depend on the inputs  2- they depend on the linearization point  3- the estimation error impacts the gain matrices. 
For the IEKF, the main difficulties vanish as during the propagation step the IEKF is built for the  logarithmic error  whose evolution  is in fact \emph{exact}  (no higher order terms) due to  Theorem \ref{dechire:thm}. At the update step, due to the specific form of the IEKF update, second order terms can be \emph{uniformly}  bounded over . And finally, due to the error equation of the IEKF, the Riccati equation depends on the estimate \emph{only} through the  matrices  and  which affect stability in a minor way, as shown by  Theorem \ref{thm::Deyst_Price}.



\end{proof}


The result displayed in Theorem \ref{thm::localCV} is in sharp contrast with the usual results available, that make the \emph{highly non-trivial  assumption} that the linearized system around the \emph{estimated} trajectory is well-behaved \cite{boutayeb,song-grizzle-95,reif,bonnabel2012contraction}. But this fact is almost impossible to predict as when the estimate is (even slightly) away  from the true state, the Kalman gain becomes erroneous, which can in turn amplify the discrepancy between estimate and true state so that there is \emph{no} reason the assumption should keep holding. On the other hand, when considering an actual system undergoing a realistic physical motion (see the examples below), if sufficiently many sensors are available, one can generally assert \emph{in advance} the linearized system around the \emph{true} trajectory  possesses all the desired properties. The following consequence  proves useful in practice.
\begin{thm}
\label{thm::bounded}
Assume the system linearized around the \emph{true} trajectory has the following properties : the propagation matrix  is constant, there exist matrices  such that  and  with  and  upper- and lower-bounded, with  detectable and reachable. Then the conditions of Theorem \ref{thm::localCV} are satisfied and the IEKF is asymptotically stable.
\end{thm}





\section{Simplified car example}\label{sect::examples:A}
The computations require only  basic knowledge about matrix Lie groups as recalled in Appendix \ref{sect::tuto_Lie_groups}.


\subsection{Considered model}



Consider a (non-holonomic) car evolving on the 2D plane. Its heading is denoted by an angle  and its position by a vector . They follow the classical equations (see, e.g., \cite{de1998feedback}):

where  is the velocity measured by an odometer and  (a function of) the steering angle. Two kinds of observations are considered:

where  is a planar rotation of angle . Equation
\eqref{car_GPS:nonoise} represents a  position measurement (GPS for instance) whereas \eqref{car_feature:nonoise} represents a range-and-bearing observation of a sequence of known features located at  for .

\subsection{IEKF gain tuning}
\label{sect::gain_tuning_car}

To derive and tune the IEKF equations, we follow the methodology of Section \ref{ouida} which amounts to 1- associate a ``noisy "system to the original considered system, just because it allows obtaining a sensible  tuning of the design matrices from an engineering viewpoint, 2- transform it into a system defined on a matrix Lie group to make it fit into our framework, 3- linearize the ``noisy" equations, and 4- use the Kalman equations to tune the observer gain. 

\subsubsection{Associated ``noisy" system}
Taking into account the possible noise in the measurements we get

with  the differential odometry error,  the longitudinal odometry error and  the transversal shift. By letting noise enter the measurement equations we get the following two kinds of measurements:


\subsubsection{Matrix form}
This system can be embedded in the matrix Lie group  (see Appendix \ref{sect::tuto_SE2}) using the   matrices:


 The equation \eqref{mec:eq} governing the ``noisy" system evolution writes:

and the observations \eqref{car_GPS} and \eqref{car_feature}  respectively have the equivalent form:




The reader can verify relation \eqref{eq::main_relation} letting .



\subsubsection{IEKF equations for the left-invariant output \eqref{car_GPS:nonoise}}
\label{ex::car_GPS}
The LIEKF  equations \eqref{LIEKF:::eq} for the associated ``noisy" system \eqref{eq::car_matrix}, \eqref{eq::car_matrix_GPS} write:

As the bottom element of  is always zero we can conveniently use a reduced-dimension gain matrix  defined by  with . To compute the gains, we write the left-invariant error  
whose evolution is:

To linearize this equation we introduce the linearized error  defined replacing  with . Introducing the first-order approximations , ,  and  in \eqref{expl::car} and removing the second-order terms in ,  and  we obtain:
  The gains  are thus finally computed using the Riccati equation \eqref{eq::Riccati_Left} with:
 







\subsubsection{IEKF equations for the right-invariant output \eqref{car_feature}}\label{etouais}


The RIEKF equations \eqref{LIEKF:::eq} for the associated ``noisy" system \eqref{eq::car_matrix}, \eqref{eq::car_matrix_feature} write:

As the bottom element of  is always zero we can conveniently use a reduced-dimension gain matrix  defined by  with . To compute the gains  we derive the evolution of the right-invariant error variable 
 between the estimate and the state of the associated ``noisy" system:

To linearize this equation we introduce the linearized error  defined as . Introducing , ,  and  in \eqref{eq::erro_car_feature} and removing the second-order terms in ,  and  we obtain:

 The gains are thus computed using the Riccati equation \eqref{eq::Riccati_Left} with  and  defined as:

 



 \subsection{Stability properties of the IEKF viewed as a non-linear observer for the simplified car}
 
 \subsubsection{Stability of the IEKF for the left-invariant output \eqref{car_GPS:nonoise}}

\begin{prop}
\label{prop::car}
If  there exists  such that the displacement satisfies  and the input velocity satisfies   then the LIEKF derived at Section \ref{etouais} is an asymptotically stable observer in the sense of Definition \ref{deff} about \emph{any} trajectory.
\end{prop}

The proof is a verification of the hypotheses of Theorem \ref{thm::localCV} and  has been moved to Appendix \ref{proof::car}.  
Note that it seems very difficult to improve on the assumptions: if the car is at the same place each time its position is measured, the heading  becomes unobservable, and in practice an arbitrary high velocity is unfeasible. 
 \subsubsection{Stability of the IEKF for the right-invariant output \eqref{car_feature:nonoise}}




\begin{prop}
If at least two distinct points are observed then the IEKF is an asymptotically stable observer in the sense of Definition \ref{deff} about \emph{any} bounded trajectory.
\end{prop}

\begin{proof}
According to Theorem \ref{thm::bounded} it is sufficient to show that in this case the observation matrix  is full-rank, i.e. of rank 3. This is obvious as the position and the heading are easily computed from the observation of two vectors at known locations.
\end{proof}

\subsection{Simulations}

The IEKF described in Section \ref{sect::gain_tuning_car} has been implemented and compared to a classical EKF for the experimental setting described by Figure \ref{fig::Simu_2D}. The car drives along a 10-meter diameter circle  for 40 seconds with high rate odometer measurements (100 Hz) and low rate GPS measurements (1 Hz). 

The equations of the IEKF can be found above. The conventional  EKF  is based on the linear error  yielding the linearized matrices   and 
 Both filters are tuned with the same design parameters (which can be interpreted as odometer and GPS noise covariances)  and  i.e. moderate angular velocity uncertainty and highly precise linear velocity. 
The simulation is performed for two initial values of the heading error: 1 and 45 while the initial position is always assumed known. The covariance matrix  is consistent with the initial error (it encodes a standard deviation of the heading of 1 and 45 respectively).

The results are displayed on Figure \ref{fig::Simu_2D}. We see that for small initial errors both filters behave similarly for a long time, but for larger errors they soon behave differently, and we see  the IEKF, whose design has been adapted to the specific structure of the system, completely outperforms the EKF.



\begin{figure*}[!h]
  \centering
\begin{minipage}[b][]{0.49\linewidth}\noindent
\includegraphics[width=\linewidth]{Traj_2D_close}
\end{minipage}
\begin{minipage}[b][]{0.49\linewidth}\noindent
\includegraphics[width=\linewidth]{Traj_2D}
\end{minipage}
\begin{minipage}[b][]{0.49\linewidth}
\includegraphics[width=\linewidth]{Angle_2D_close}
\end{minipage}
\begin{minipage}[b][]{0.49\linewidth}
\includegraphics[width=\linewidth]{Angle_2D}
\end{minipage}
\begin{minipage}[b][]{0.49\linewidth}\noindent
\includegraphics[width=\linewidth]{Position_2D_close}
\end{minipage}
\begin{minipage}[b][]{0.49\linewidth}\noindent
\includegraphics[width=\linewidth]{Position_2D}
\end{minipage}
  \caption{The heading and position of the car are estimated through EKF and IEKF with high rate odometry and low rate GPS measurements. Top plots illustrate the experimental setting and display the estimated trajectories, middle plots display the heading errors and bottom plots the position errors. As the starting point is assumed known in this simulation, the initial values of the latter are zero. But it increases afterwards due to initial heading error.
\textbf{Left column:} small initial angle error (1). We see EKF and IEKF behave similarly (at least for a long time) as propagation steps are identical. \textbf{Right column:} large initial angle error (45). The behaviors rapidly become different, and the EKF is  outperformed. Due to its righteous use of the system's non-linearities, the IEKF keeps ensuring rapid estimation error decrease.
}
\label{fig::Simu_2D}
\end{figure*}





\section{Navigation on flat earth}\label{sect::examples:B}

In this example we estimate the orientation, velocity, and position of a rigid body in space from inertial sensors and relative observations of points having known locations (the setting of \cite{Vasconcelos} but with the state including the position). To our knowledge, this is the first time the invariant observer on Lie groups based approach  is applied to this full navigation problem with landmarks, except for our preliminary conference paper \cite{barrau-bonnabel-cdc14}. Indeed, this example does not fit into the usual framework leading to autonomous errors (unless we discard the position estimate as in   \cite{Vasconcelos}) but thanks to Theorem \ref{thm::CNS} we see it still leads to an autonomous error equation. This allows the IEKF observer to possess provable convergence properties. Note  the problem at hand is different from the navigation problems using magnetometers, and velocity and position measurements of the GPS  \cite{hua2010attitude,grip2015globally}. 

Of course, the EKF, to be more precise its appropriate variant the multiplicative (M)EKF \cite{lefferts1982kalman}, is the state of the (industrial) art for this navigation example, due to its good  performances, and easy tuning based on sensors' noise covariances. But to our best knowledge it is nowhere proved to possess stability properties as a non-linear observer, and  simulations below even indicate  it may diverge in some situations whereas the IEKF converges. The computations require basic formulas recalled in Appendix \ref{sect::tuto_Lie_groups}. 

\subsection{Considered  model}



We consider here the  more complicated model of a vehicle evolving in the 3D space and characterized by its attitude , velocity  and position . The vehicle is endowed with accelerometers and gyroscopes whose measures are denoted respectively by  and angular velocity . The   dynamics read:

where  denotes the  skew-symmetric matrix associated with the cross product with , that is, for any  we have . 
Observations of the relative position of known features (using for instance a depth camera) are considered:
 where  denote the (assumed known) position of the features in the earth-fixed frame.

\subsection{IEKF gain tuning}
To derive and tune the IEKF equations, we follow the methodology of Section \ref{ouida} which amounts to 1- associate a ``noisy "system to the original considered system, just because it allows obtaining a sensible  tuning of the design matrices from an engineering viewpoint, 2- transform it into a system defined on a matrix Lie group to make it fit into our framework, 3- linearize the ``noisy" equations, and 4- use the Kalman equations to tune the observer gain. 

\subsubsection{Associated ``noisy" system}

By merely introducing noise in the accelerometers' and gyrometers' measurements we obtain the well-known equations \cite{farrell2008aided}:

Letting additive noise pollute the observations (the sensor being in the body frame) we get:

where ,  are noises in .

\subsubsection{Matrix form}
As already noticed in the preliminary work \cite{barrau-bonnabel-cdc14}, the system \eqref{3D_dynamics} can be embedded in the group of double homogeneous matrices (see Appendix \ref{sect::tuto_SE23}) using the matrices ,  and function :


The equation of the dynamics becomes:

and the observations \eqref{3D_features} have the equivalent forms:

\begin{prop}
The matricial function  is neither left nor right invariant. However the reader can verify relation \eqref{eq::main_relation}  which is easy to derive.
\end{prop}






\subsubsection{IEKF equations}
\label{sect::IEKF_eq_3D}
The RIEKF \eqref{LIEKF:::eq} for the associated ``noisy" system
 \eqref{eq::3D_matrix_dynamique}, with right-invariant ``noisy" observations \eqref{eq::3D_matrix_features} reads:

As the two last entries of each matrix  are always zero, one we can conveniently use a reduced-dimension gain matrix  defined by  with .  
The right-invariant error is 
and its evolution reads:



To linearize this equation we introduce the linearized error  by replacing  with . Using the first order approximations , ,  and  in \eqref{eq::error_3D_dynamics_features}, \eqref{eq::error_3D_observation_features} and removing the second-order terms in ,  and  we obtain:


The gains   are computed using the Riccati equation \eqref{eq::Riccati_Left} and matrices  and  defined as:




\subsection{Stability properties of the IEKF viewed as a non-linear observer for the navigation example}
\begin{thm}
\label{thm::3D_features_stability}
If three non-collinear points are observed, then the  IEKF whose equations are derived in Section \ref{sect::IEKF_eq_3D} is an asymptotically stable observer for the system \eqref{3D_dynamics:nonoise}-\eqref{3D_features:nonoise}   in the sense of Definition \ref{deff} about \emph{any} bounded trajectory.
\end{thm}

\begin{proof}
According to Theorem \ref{thm::bounded} we only have to ensure the couple (A,H) is observable. Integrating the propagation on one step we obtain the discrete propagation matrix  The observation matrix is denoted . We will show that  has rank . We can keep only the raws corresponding to the observation of three non-collinear features  and denote the remaining matrix by . Matrices  and , obtained using elementary operations on the columns of , have a rank inferior or equal to the rank of :

 
The diagonal blocks ,  and  have rank  thus the full matrix has rank .
\end{proof}

\subsection{Simulations}

The IEKF described in Section \ref{sect::IEKF_eq_3D} has been implemented and compared to a state of the art multiplicative EKF \cite{lefferts1982kalman} for the experimental setting described by Figure \ref{fig::Simu_3D} (top plots). The vehicle drives a 10-meter diameter circle (green arrows) in 30 seconds and observes three features (black circles) every second while receiving high-frequency inertial measurements (100 Hz).  The equations of the IEKF have already been detailed. The error variable to be linearized for the multiplicative (M)EKF is . As  is not a vector variable,  it is linearized using the first-order expansion   \cite{lefferts1982kalman}. The linearized error variable is thus a vector . Expanding the propagation and observation steps up to the first order in  give the classical  and  matrices used in the Riccati Equation of the MEKF:
 

We use the following design parameters in two distinct simulations, with same  but two different matrices .


The initial errors are the same for both simulations:  15 degrees for attitude and  1 meter for position standard deviations. The small ``process noise'' matrix , although reasonable in the context of high-precision inertial navigation, has been deliberately chosen to challenge EKF-like methods: the corresponding gains are small so  the errors introduced during the transitory phase due to non-linearities in the initial errors can never be corrected. Note this would not be an issue if the system was linear: the estimation errors and filter gains would decrease simultaneously. The problem is that the error does not decrease as fast as predicted by the \emph{linear} Kalman theory. As shown by the plots of the left column of Figure \ref{fig::Simu_3D} (top plots) it makes the EKF even diverge! This is probably the simplest way to  make the EKF fail in a navigation problem and this is purely a problem of  non-linearity as no noise has been added  whatsoever. Still on the left column, we see the IEKF is not affected by the problem, due to its appropriate non-linear structure. In particular, the attitude and position errors go to zero in accordance with Theorem \ref{thm::3D_features_stability}.

Usually, engineers get around those convergence problems by   artificially inflating the ``process noise'' matrix  (see also \cite{reif}). This classical solution, sometimes referred to as robust tuning, is illustrated here by using    instead. The results are displayed on the right column of Fig. \ref{fig::Simu_3D}. They illustrate the fact the EKF, as an observer, can be improved  through a proper tuning, although still much slower to converge that the IEKF. But this raises issues:  and  have been chosen for a specific trajectory with no guarantee regarding robustness. Moreover, these matrices admit a physical interpretation (the accuracy of the sensors) and arbitrarily changing them by several  orders of magnitude is a renouncement to use this precious information when available. In turn,  this makes  the matrix  loose its interpretability as an indication of the observer's accuracy in response to the sensors' trusted accuracy.  For this relevant problem, we thus see the IEKF turns out to be a viable alternative to the EKF thanks to its \emph{guaranteed} properties, and to its convincing experimental behavior reflecting way better performances than the EKF, even for challenging choices of  and .





\begin{figure*}[!h]
  \centering
\begin{minipage}[b][]{0.44\linewidth}\noindent
\includegraphics[width=\linewidth]{Results_fail}
\end{minipage}
\begin{minipage}[b][]{0.44\linewidth}\noindent
\includegraphics[width=\linewidth]{Results_work}
\end{minipage}
\begin{minipage}[b][]{0.44\linewidth}
\includegraphics[width=\linewidth]{Attitude_fail}
\end{minipage}
\begin{minipage}[b][]{0.44\linewidth}
\includegraphics[width=\linewidth]{Attitude_work}
\end{minipage}
\begin{minipage}[b][]{0.44\linewidth}\noindent
\includegraphics[width=\linewidth]{Pos_fail}
\end{minipage}
\begin{minipage}[b][]{0.44\linewidth}\noindent
\includegraphics[width=\linewidth]{Pos_work}
\end{minipage}
  \caption{Aided inertial navigation based on high rate accelerometers' and gyrometers' measurements and low rate observation of known landmarks. We also displayed the orthogonal projection of the landmarks on the plane containing the trajectory (black crosses) to help imagining the 3D position of the landmarks. This shows the disposition of the landmarks is the same in both experiments. Top plots illustrate the experimental setting and display the  EKF and IEKF estimates. Middle plots display the attitude errors and bottom plots the position errors. \textbf{Left column:} the tuning of  is tight () due to highly precise inertial sensors. This creates robustness issues: the gains of the EKF decrease rapidly during the transitory phase while the attitude error is not reduced enough due to non-linearities. When the position estimate is impacted, the gains have become too small to correct the errors, leading to filter's divergence. IEKF ensures rapid decrease to 0 of the estimation error with identical tuning. \textbf{Right plot:}    is inflated (). This classical engineering trick prevents the EKF to diverge but IEKF still prevails in terms of time of convergence.}
\label{fig::Simu_3D}
\end{figure*}


\section{Conclusion}
The Invariant EKF, when used as a deterministic observer for an introduced and well characterized class of problems on Lie groups, is shown to possess theoretical stability guarantees under the simple and natural hypotheses of the linear case, a feature the EKF has never been proved to share so far. Simulations confirm the   IEKF is an appealing alternative indeed, as it is always superior to the EKF and  outperforms it in challenging situations, while remaining similar to EKF in terms of tuning, implementation, and computational load. 




\appendix


 \section{Matrix Lie groups useful formulas}
\label{sect::tuto_Lie_groups}

A matrix Lie group  is a set of square invertible matrices of size  verifying the following properties:


If  is a process taking values in  and verifying , then its derivative at  cannot take any value in the set of squared matrices . It is constrained to lie in a vector subspace  of  called the ``Lie algebra of ". As it proves useful to identify  to , a linear mapping  is used in this paper. The vector space  can be mapped to the matrix Lie group  through the classical matrix exponential . As well,  can be mapped to  through a function  defined by . For any  the operator  is defined by . For any  the operator  is defined by . These operators are very handy in practical computations. For all matrix Lie groups considered in this paper, no matrix exponentiation is actually needed as there exist closed formulas, given thereafter. We give now a short description of the matrix Lie groups appearing in the present paper.

\subsection{Group of direct planar isometries }
\label{sect::tuto_SE2}

We have here  and , where    where
 denotes the rotation of angle , and the exponential mapping is:

where


\subsection{Group of double direct spatial isometries }
\label{sect::tuto_SE23}

We have here:   An isomorphism between  and  is given by . The exponential mapping is given by the formula:

where  .


















\section{Further explanation and proof of the log-linear property}


The definition of  through   is very convenient in practice as shown in Sections \ref{sect::examples:A} and \ref{sect::examples:B}, but it requires a quick theoretical explanation  as follows. 
On an abstract Lie group, vector  belongs to  (tangent space at ) whereas the image of  is . But as  it is true that the first order terms of   belong to . Indeed as  we have  for some function  with . Thus .

The proof of Theorem \ref{dechire:thm} is based upon the following lemmas.
\begin{lem}Consider the system \eqref{eq::mult_linear} and let  denote a particular solution. Consider the condition

We have the following properties:
\begin{itemize}
\item The function   verifies \eqref{eq::mult_homogeneous} and all the solutions of \eqref{eq::mult_linear} have the form , where  verifies .
\item The function   verifies  \eqref{eq::mult_homogeneous} and all the solutions of \eqref{eq::mult_linear} have the form , where  verifies .
\end{itemize}
\end{lem}
The verification of these two properties is trivial. The functions  governing the errors propagation turn out to possess an intriguing property. 
\begin{lem}
\label{prop::product}
Let  be the flow (that is the solution at time  associated to a given initial condition) associated to the system , where  verifies \eqref{eq::mult_homogeneous}. Then:

\end{lem}
\begin{proof}
We simply have to see that  is solution of the system :

\end{proof}
An immediate recursion gives then:


\begin{lem}
\label{prop::power}
We have furthermore

\end{lem}
Lemmas \ref{prop::product} and \ref{prop::power} indicate the behavior of the flow infinitely close to  dictates its behavior arbitrarily far from it, as the flow commutes with exponentiation. The use of the exponential thus allows deriving an infinitesimal version of the Lemma \ref{prop::power}, which is an equivalent formulation of Theorem \ref{dechire:thm}.



\begin{thm}
\label{thm::exp}
Let  be the flow associated to the system  satisfying \eqref{eq::mult_homogeneous}.
We have:
\color{black}

where  is the solution of the matrix equation  \color{black}.
\end{thm}
 \begin{proof}
Thanks to Lemma \ref{prop::power} we have, for any , , where  and  is a quadratic term, which ensures in turn .  
Letting  we get . Differentiating both sides of the latter equality we obtain . A first-order expansion in  using matrix  gives: , then  for any  and finally .
\color{black}
\end{proof}


\section{Proof of theorem \ref{thm::localCV}}
\label{proof::localCV}




\subsection{Proof rationale}
We define the rest , here for the left-invariant filter only, as follows:     ~~= . We then introduce the flow  of the linear part  of the equations governing  (that is, ) and decompose the solution  as:

All we have to verify is that the appearance of the second-order terms  at each update is compensated by the exponential decay of  (Theorem \ref{thm::Deyst_Price}).
\subsection{Review of existing linear results}

Consider a linear time-varying Kalman filter and let  denote the flow of the error variable . It is proved in \cite{deyst} that if the parameters of the Riccati equation verify conditions \eqref{cond::Psi} - \eqref{cond::observable} then there exist  and  such that . This pivotal property allows proving the solution of the \emph{linear} error equation  verifies for :

where  only depends on . Of course, the proof given in \cite{deyst} holds if the inequalities are only verified on an interval . We will also use the  direct consequence:


\subsection{Preliminary lemmas}
The proof of Theorem \ref{thm::localCV} is displayed in the next subsection. It relies on the final Lemma \ref{lem::Lyapounov}, which is proved step by step in this section through lemmas \ref{lem::Riccati}, \ref{lem::first_order} and \ref{lem::second_order}. The time  interval between two successive observations will be denoted .  will denote the Kalman covariance about the true state trajectory.

\begin{lem}
\label{lem::Riccati} \emph{[modified constants for closeby trajectories]}
If the conditions \eqref{cond::Psi} to \eqref{cond::observable} are satisfied about the \emph{true} trajectory, then for any  there exists a radius  such that the bound  ensures the conditions \eqref{cond::Psi} to \eqref{cond::observable} are also verified on  about the \emph{estimated} trajectory, with the modified constants .  Moreover, if  then  holds on .
\end{lem}

\begin{proof}
We consider the LIEKF, the proof works the same way for the RIEKF. Matrices  and  depend on the estimate , this is why this lemma is needed. So we replace them by their values:  if the noise term has the form ,  if the noise term has the form , and . All these situations are covered if we assume there exist four (possibly time-dependent) matrices , ,  and  such that  and . These notations will be used in the sequel but they hold only for this proof: they are not related to matrices  and  defined in the simulations sections. The Riccati equation computed about the true trajectory reads:

The Riccati equation computed on the estimated trajectory is obtained replacing  with .
Recalling the error  and the properties of the , the idea of the proof is simply to rewrite the Riccati equation computed about  as a perturbation of the Riccati equation computed about :


Controlling the perturbation is easy: matrix-valued functions  and  are continuous and equal to  for , thus there exists a real
 depending only on   such that  ensures  and . It ensures consequently  and  and a mere look at the definitions of the constants of Theorem \ref{thm::Deyst_Price} yields the modified constants.

The inequality  follows from the matrix inequalities above on the covariance matrices, by writing the Riccati equation verified by  and  and using simple matrix inequalities. 

\end{proof}

\begin{lem}\emph{[first-order control of growth]}
Under the same conditions as in Lemma \ref{lem::Riccati} (including ) and  bounded by the same  for  (i.e. over  time steps, where  is defined as in Theorem \ref{thm::Deyst_Price}), there exists a continuous function  depending \emph{only} on  ensuring  for any  and .
\label{lem::first_order}
\end{lem}
\begin{proof}
Using Lemma \ref{lem::Riccati} and then Theorem \ref{thm::Deyst_Price} we know there exist two constants  and  such that . The non-linear rest  introduced in \eqref{eq::decomposition} is defined by . The Baker-Campbell-Hausdorff (BCH) formula gives  but  is uniformly bounded over time by  as an operator. Thus  is \emph{uniformly} dominated over time by a second order: there exists a continuous function  (depending only on  and on the \emph{true} trajectory) such that  and  for any  such that .

Now we can control the evolution of the error using . The propagation step is linear, thus we have the classical result . It ensures  as long as there is no update on . At each update step we have   using the triangular inequality. Thus: ~~. Reiterating over successive propagations and updates  over ,  we see   is uniformly bounded by a  function  that is first order in .

\end{proof}



\begin{lem}\emph{[second-order control of the Lyapunov function]}
Under the same conditions as in Lemma \ref{lem::Riccati} (including )  and for  bounded by the same  for  ( time steps, see Theorem \ref{thm::Deyst_Price} for the definition of ), there exists a continuous function  depending \emph{only} on  ensuring  for any  with . We also have  for .
\label{lem::second_order}
\end{lem}
\begin{proof}
The result stems from the decomposition \eqref{eq::decomposition} as:

As we have , we obtain the result squaring the inequality and using   to control the crossed terms.
\end{proof}


\begin{lem}\emph{[final second order growth control]}
Under the same conditions as in Lemma \ref{lem::Riccati} (including )  and for  bounded by the same  for , there exist two functions  and  and a constant  ensuring the relation:

where  is the last update before  ( i.e. ),  is the number of successive sequences of  updates in  (i.e. ) and . If  the last term can be removed.
\label{lem::Lyapounov}
\end{lem}

\begin{proof}
For  we choose the same function as in Lemma \ref{lem::second_order}. There is nothing more to prove for . Let . We have . The first and third terms are upper bounded using Lemma \ref{lem::second_order}. The second term is controlled as follows:

And we conclude using (see \cite{deyst}): 

for a  depending only on the modified constants of Lemma \ref{lem::Riccati}. The last inequality is obtained using  and an obvious recursion over  time steps. We finally set .
\end{proof}

\begin{rem}
The control we have obtained on  is verified if  is \emph{already} in a ball of radius  over the whole interval . We now prove the result holds assuming \emph{only} that  is sufficiently small.
\end{rem}

\subsection{Proof of theorem \ref{thm::localCV}}
Applying Lemma \ref{lem::Lyapounov} with  gives for  and  on  :

There exist  and  such that for , we have  and  (as  and ) which gives:

Thus, for :

which finally ensures
Reducing  if necessary to have , we have obtained  for  for sufficiently small  (as Lemma \ref{lem::Lyapounov} applies).   Letting  for sufficiently small  we end up with a contradiction if we suppose , which proves . All the previous results thus hold \emph{only} for sufficiently small . 


Moreover, \eqref{eq::control_last formula} shows that  is bounded and has positive terms thus  goes to zero. Note also that  as a byproduct.





\section{Proof of proposition \ref{prop::car}}
\label{proof::car}
Only conditions \eqref{cond::Psi} and \eqref{cond::observable} are non-trivial. Let  denote the flow of the dynamics. We have  as the eigenvalues of  are . Thus,  and finally  as .  Thus  and \eqref{cond::Psi} is verified. The difficult part of \eqref{cond::observable} is the lower bound. Denoting  by  we will show:

That is to say that we want a lower bound on the quadratic form: 

We decompose  as . To simplify the writing we introduce the norms  and the associated scalar product . There exists  such that . For any  we have 

 and for  we have:

As  there exists  such that:

and the result is true for .









\bibliographystyle{plain}
\bibliography{rhn}

\end{document}
