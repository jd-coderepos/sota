Unsupervised Machine Translation#WMT2016 Romanian-English#BLEU#39.5
Unsupervised Machine Translation#WMT2014 English-French#BLEU#32.6
Unsupervised Machine Translation#WMT2016 German-English#BLEU#40.6
Unsupervised Machine Translation#WMT2014 French-English#BLEU#39.2
Unsupervised Machine Translation#WMT2016 English-German#BLEU#29.7
Unsupervised Machine Translation#WMT2016 English-Romanian#BLEU#21
Multi-Task Learning#Hendrycks Test#Accuracy (%)#43.9
Question Answering#PIQA#Accuracy#82.8
Question Answering#DROP Test#F1#36.5
Question Answering#BoolQ#Accuracy#76.4
Question Answering#Natural Questions#Accuracy#29.9
Question Answering#CoQA#Overall#85
Question Answering#COPA#Accuracy#92
Question Answering#MultiRC#F1a#75.4
Question Answering#TriviaQA#Accuracy#71.2
Question Answering#QuAC#F1#44.3
Question Answering#Story Cloze Test#Accuracy#87.7
Question Answering#RACE#RACE-h#46.8
Question Answering#RACE#RACE-m#58.1
Question Answering#OpenBookQA#Accuracy#65.4
Question Answering#WebQuestions#Accuracy#41.5
Common Sense Reasoning#ARC (Challenge)#Accuracy#51.5
Common Sense Reasoning#ARC (Easy)#Accuracy#70.1
Word Sense Disambiguation#Words in Context#Accuracy#49.4
Natural Language Inference#RTE#Accuracy#69%
Natural Language Inference#ANLI test#A1#36.8
Natural Language Inference#ANLI test#A2#34
Natural Language Inference#ANLI test#A3#40.2
Natural Language Inference#CommitmentBank#Accuracy#75.6
Natural Language Inference#CommitmentBank#F1#52
Language Modelling#LAMBADA#Accuracy#86.4
Language Modelling#LAMBADA#Perplexity#1.92
Language Modelling#The Pile#Bits per byte#0.7177
Language Modelling#Penn Treebank (Word Level)#Params#175000M
Language Modelling#Penn Treebank (Word Level)#Test perplexity#20.5
Coreference Resolution#Winograd Schema Challenge#Accuracy#80.1
Coreference Resolution#WSC#Accuracy#80.1
