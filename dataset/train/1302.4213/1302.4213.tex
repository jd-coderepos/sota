\documentclass[a4paper,11pt]{article}

\usepackage{lmodern}  

\usepackage[english]{babel}
\usepackage[T1]{fontenc}
\usepackage[latin1]{inputenc}

\usepackage[margin=1in]{geometry}


\pdfpagewidth=\paperwidth
\pdfpageheight=\paperheight

\newcommand{\reell}{\mathbb{R}}
\newcommand{\natur}{\mathbb{N}}
\newcommand{\menge}[1]{\left\{#1\right\}}
\newcommand{\mengest}[2]{\left\{#1|#2\right\}}
\newcommand{\nor}[1]{\left\|#1\right\|}
\newcommand{\betr}[1]{\left|#1\right|}
\newcommand{\partiell}[2]{\frac{\partial #1}{\partial #2}}
\newcommand{\klammer}[1]{\left(#1\right)}
\newcommand{\skalar}[2]{\left\langle #1,#2\right\rangle}





\usepackage{amsmath}
\usepackage{amsthm}
\usepackage{amsfonts}
\usepackage[numbers]{natbib}
\usepackage{amssymb}
\usepackage{cancel}
\usepackage{graphicx}
\usepackage{url}
\newtheorem{thm}{Theorem}
\newtheorem{lem}[thm]{Lemma}
\newtheorem{cor}[thm]{Corollary}
\newtheorem{algo}{Algorithm}

\DeclareMathOperator{\pos}{pos}
\DeclareMathOperator{\listi}{list}
\DeclareMathOperator{\size}{size}
\DeclareMathOperator{\migration}{migration}
\usepackage[lined,algonl,ruled,noend]{algorithm2e}



\title{A Robust AFPTAS for Online Bin Packing with Polynomial Migration}
\author{Klaus Jansen\\
Department of Computer Science\\
Christian-Albrechts-University to Kiel\\\url{ kj@informatik.uni-kiel.de}
 \and 
Kim-Manuel Klein\\
Department of Computer Science\\
Christian-Albrechts-University to Kiel\\
\url{ kmk@informatik.uni-kiel.de}}

\date{}

\begin{document}

\maketitle

\begin{abstract}
In this paper we develop general LP and ILP techniques to find an approximate solution with improved objective
value close to an existing solution.
The task of improving an approximate solution is closely related to a classical theorem of 
Cook et al. \cite{cook1986sensitivity} in the
sensitivity analysis for LPs and ILPs. This result is often applied in designing robust algorithms for online
problems.
We apply our new techniques to the online bin packing problem, where it is allowed to reassign a certain
number of items, measured by the migration factor. The migration factor is defined by
the total size of reassigned items divided by the size of the arriving item.
We obtain a robust asymptotic fully polynomial time approximation scheme (AFPTAS) for the online bin packing
problem with migration 
factor bounded by a polynomial in .
This answers an open question stated by Epstein and Levin \cite{epstein2006robust} in the affirmative.
As a byproduct we prove an approximate variant of the sensitivity
theorem by Cook at el. \cite{cook1986sensitivity} for linear programs.
\end{abstract}


\section{Introduction}
The idea behind robust algorithms is to find solutions of an optimization problem 
that are not only good for a single instance, but also if the instance changes in 
certain ways. Instances change for example due to uncertainty or when new data
arrive. With changing parameters and data, we have the effort to keep as much 
parts of the existing solution as possible, since modifying a solution is often
connected with costs or may even be impossible in practice.
Achieving robustness especially for linear programming (LP) and integer linear programming (ILP)
is thus a big concern and a very interesting research area. Looking at worst case scenarios, how
much do we have to modify a solution if the LP/ILP is changing? There is a result of Cook et al. \cite{cook1986sensitivity}
giving an upper bound for ILPs when changing the right hand side of the ILP.
Many algorithms in the theory of robustness are based on this theorem.

As a concrete application we consider the classical online bin packing problem, 
where items arrive over time and our
objective is to assign these items into as few bins as
possible. The notion of robustness allows to repack a certain number of
already packed items when a new item arrives. 
On the one hand we want to guarantee that we use
only a certain number of additional bins away from the minimum solution
and on the other hand, when a new item arrives, we want to repack as few items as possible.
In the case of offline bin packing 
it is known that unless  there is no polynomial time approximation 
algorithm for offline bin packing that produces
a solution better than , where  is the minimum number
of bins needed. For this reason, the most common way to deal with the inapproximability problem is the 
introduction of the asymptotic approximation ratio. 
The \emph{asymptotic approximation ratio} for an algorithm  is defined to be .
This leads to the notion of \emph{asymptotic polynomial time approximation schemes (APTAS)}. 
Given an instance of size  and a 
parameter , an APTAS has a running time of  and 
asymptotic approximation
ratio , where  is an arbitrary function.
An APTAS is called an \emph{asymptotic fully polynomial time approximation scheme (AFPTAS)} if its
running time is polynomial in  and .
The first APTAS for offline bin packing was developed by Fernandez de la Vega \& Lueker \cite{de1981bin},
and Karmakar \& Karp improved this result by giving an AFPTAS \cite{karmarkar1982} (see survey on 
bin packing \cite{coffman1996}).

Since the introduction by Ullman of the classical online bin packing problem \cite{ullman1971}, there has been 
plenty of research 
(see survey \cite {csirik1998}). The best known algorithm has an asymptotic competitive
ratio of  \cite{seiden2002} compared to the optimum in the offline case, 
while the best known lower bound is  \cite{balogh2010}.
Due to the relatively high lower bound of the classical online bin packing problem, there has been effort
to extend the model with the purpose to obtain an improved competitive ratio.
Gambosi et al. \cite{gambosi2000} presented a model where they allow repacking of items. 
They presented an algorithm 
which achieves ratio  by moving at most 7 items to a different bin each time
a new item arrives.
The idea of a dynamic packing was developed pretty early by Coffman, Garey and Johnson \cite{coffman1983}.
They developed and analyzed an algorithm for the dynamic bin packing model when arrival and departure of items
are known in advance.
Ivkovic and Lloyd \cite{ivkovic1998} presented an algorithm for dynamic bin packing having ratio .
In their model items and their arrival and departure are not known in advance.
The algorithm requires  shifting moves, where a shifting move consists of moving a 
large item or a bundle of small items from one bin to another. 
In another work Ivkovic and Lloyd \cite{ivkovic1997} gave an algorithm which achieves approximation
ratio  by using amortized  shifting moves.
Concerning reassignment of jobs in scheduling, Albers and Hellwig \cite{albers2012} 
presented an algorithm for online scheduling with minimizing the makespan on  machines. 
The algorithm has a competitive ratio
of , where  and for  the competitive ratio  converges 
to . The reassignment of jobs is bounded by . 
They also proved that it is not possible to obtain an algorithm with better competitive ratio than 
without reassigning  jobs.

The model we follow is the notion of robustness. Introduced by Sanders et al. \cite{sanders2009} it allows 
repacking of arbitrary items while the number of items that are being repacked is limited. To give a measure 
on how many items are allowed to
be repacked Sanders et al. \cite{sanders2009} defined the \emph{migration factor}.
It is defined by the complete size of all moved items divided by the size of the arriving one.
An (A)PTAS is called \emph{robust} if its migration factor is of the size , where  is
an arbitrary function that only depends on .
Since the promising introduction of robustness, several robust algorithms have been developed.
Sanders et al. \cite{sanders2009} found a robust PTAS for the online scheduling problem  
on identical machines, where the goal is to minimize the makespan. The robust PTAS has
constant but exponential migration factor .
In case of bin packing
Epstein and Levin \cite{epstein2006robust} developed a robust APTAS for the classical bin packing problem
with migration factor  and running time
double exponential in .
In addition they proved that there is no optimal online algorithm with a constant migration factor.
Furthermore, Epstein and Levin \cite{epsteinu} showed that the robust APTAS for bin packing can 
be generalized to packing d-dimensional cubes into a minimum number of unit cubes.
Recently Epstein and Levin \cite{epstein2011} also designed a robust 
algorithm for preemptive online
scheduling of jobs on identical machines, where the corresponding offline problem is polynomial solvable.
They presented an algorithm with migration factor
 that computes an optimal solution whenever a new item arrives.
Skutella and Verschae \cite{skutella2010} studied the problem of maximizing the minimum load given 
 jobs and  machines. They proved that there is no robust PTAS for this machine covering problem.
On the positive side, they gave a robust PTAS for the machine covering problem in the case that
migrations can be reserved for a later timestep. The algorithm has an amortized migration factor of
.
\subsection{Our Results:}
An online algorithm is called \emph{fully robust} if its migration factor is bounded by
, where  is a polynomial in .
The purpose of this paper is to give methods to develop fully robust
algorithms. In Section 2 we develop a theorem for a given linear program (LP)
.
Given an approximate solution  
with value  (where  is the minimum objective value of the LP)
and a parameter , we prove the existence of an improved solution 
with value  and distance .
In addition, for a given fractional solution  and corresponding integral solution , the existence
of an improved integral solution  with  is shown
(where  is the number of rows of ). Since both results are constructive, we propose also algorithms
to compute such improved solutions.
Previous robust online algorithms require an optimum solution of the corresponding ILP and use a sensitivity theorem
by Cook et al. \cite{cook1986sensitivity}.
This results in an exponential migration factor in 
(\cite{epstein2006robust, epsteinu, skutella2010, sanders2009}).
In contrast to this we consider approximate solutions of the corresponding LP relaxations and are able
to use the techniques above to improve the fractional and integral solutions.
Furthermore we also prove an approximate version of a sensitivity theorem for LPs with modified right
hand side  and .
During the online algorithm the number of non-zero variables increases from step to step and would result
in a large additive term. To avoid this we present algorithms in Section 3 to control the number
of non-zero variables of the LP and ILP solutions. We can bound the number of non-zero variables and the
additive term by .
In Section 4 we present the fully robust AFPTAS for the robust bin packing problem. We use a modified
version of the clever rounding techniques of Epstein and Levin \cite{epstein2006robust}.
This rounding technique is used to round the incoming items dynamically and control the number of item sizes.
One difficulty is that we use approximate solutions of the LP.
During the online algorithm items are rounded to different values and are shifted across different 
rounding groups. We show how to embed the rounded instance into another rounded instance that fulfills
several invariants.
By combining the dynanic rounding and the algorithm to get improved solutions of the LP and ILP, we are able
to obtain a fully robust AFPTAS for the online bin packing problem.
The algorithm has a migration factor of 
 (or  if the size of the arriving item is ) and 
running time polynomial in  and , where  is the number of arrived items. 
This resolves an open question of Epstein and Levin \cite{epstein2006robust}. We believe that our techniques
can be used for other online problems like 2D strip packing, scheduling moldable tasks, resource constrained
scheduling and multi-commodity flow problems to obtain online algorithms with low migration factors.
\section{Robustness of approximate LPs}
We consider a matrix , a vector  and a cost vector
.
The goal in a \emph{linear program} (LP) is to find a  with  such that the
\emph{objective value}  is minimal.
We say  is an optimal solution if  
and we define . In general we suppose that the objective function of a solution
is positive and hence .
We say  is an approximate solution with approximation ratio  for some 
 if . For the most part of the paper we will assume that
 and therefore .
The following theorem is central. Given an approximate solution , we want to improve its
approximation by some constant. But to achieve robustness we have to maintain most
parts of . We show that by changing  by size of , 
we can improve the approximation by a constant .
\begin{thm}
  \label{thm1}
  Consider the LP  and an approximate solution  with  for some .  For every positive  there 
  exists a solution  with objective value of at most  and distance .
  If  then .
\end{thm}
\begin{proof}
   We prove feasibility of the following \ref{form:lp1}. 
  
  The assumption  implies 
   and hence .
  Suppose that \ref{form:lp1} is feasible and has a solution . Due to constraints 3 and 4 the distance between 
  and  can be bounded. Components  with  may be smaller compared to  by
  , while components  with
   may be larger than  by .
  In the worst case,  and  have no common non-zero entries 
  and hence, .
	If  then  and . Therefore  .
  It remains to prove feasibility of \ref{form:lp1}.
  We construct a solution  by 
  .
	We prove that each constraint of \ref{form:lp1}	is satisfied for . Note that  since
	.
	Constraint 3 is fulfilled since  and
	constraint 4 is fulfilled since .
  Feasibility for  follows from 
  .
  The objective value of  is bounded by
  .
\end{proof}
From here on and for the rest of the paper we suppose that .\\
{\bf Remark 1:\\}
Suppose  has approximation ratio  for some .
By Theorem \ref{thm1} the following LP is feasible if .

Setting  for some  yields feasibility for the following
LP assuming .

Here, we use . The condition that  is equivalent to the condition that
 since  and . \qed

{\bf Remark 2:\\}
In many cases, we do not know the exact approximation ratio  but the 
approximation
guarantee  for some .
Assuming  we can use feasibility of \ref{form:lpr} to prove the existence of
a solution  with  and .
The distance  follows again easily from constraints 3 and 4 of \ref{form:lpr}.
We derive the aimed objective value  from the last constraint of \ref{form:lpr}:
.
This proves, that it suffices to know an upper bound for the approximation to obtain an improved solution .\qed


Of course, one major application of Theorem \ref{thm1} is to improve the approximation. 
But we can also apply Theorem \ref{thm1} to obtain a variant of the theorem of
Cook et al. \cite{cook1986sensitivity} for the sensitivity analysis of
an LP. Consider the following problem: Let  be a solution of .  Find a solution  for  with changed right hand side such that
 is small. A theorem of Cook
et al. \cite{cook1986sensitivity} states that there exists a 
satisfying the LP and , where  is the largest subdeterminant of
. This result is not satisfying if  and  are too big,
especially if they are exponential in . By letting loose of optimal solutions we obtain
a corollary that is much more appropriate to derive fully robust algorithms.
In contrary to the theorem of Cook et al. \cite{cook1986sensitivity} the amount of change in the solution does not depend on the determinant 
nor on the dimensions
of  but on the approximation ratio of the solution.

\begin{cor}
 Consider the linear program  defined by  and an approximate solution  with  () and . There exists a solution
   of  defined by  with  such that the distance 
  where  and  is a vector having components .
\end{cor}
\begin{proof}
	Suppose there is only one index  where . Consider the 2 cases:\\
	{\bf Case 1:}  We increase  by , where  is the index with the maximum entry in row .
	This way we make sure that the so modified  covers the larger  since now .
	Since we simply increase  to cover the larger  we may worsen the approximation by an additive term of
	at most .\\
	{\bf Case 2:} . In this case we do not modify component  of , but since a smaller  has to
	be covered the optimal value of a solution may decrease. 
	Let  be the optimal value of  and let  be the optimal value of .
	The inequality  leads to a contradiction since
	we can increase an optimal solution  of  to cover the lager  like 
	we did in case 1. Modifying 
	 this way would lead to a smaller optimal solution.
	Therefore the optimal solution of  can not decline by more than .
	Using  as an approximate solution for  yields therefore .
	
	Iterating over all components  and changing the solution according to the cases would result 
	in an approximate solution of at most
	.
	Using Remark 2 with 
	guarantees the existence of a solution  for  having value  and 
	.
	Modifying  according to the cases yields therefore a solution  with . For the distance between  and  we get .
\end{proof}
Note that if  is an integral matrix without zero rows, each component  is at least .

\section{Algorithmic Use}
Let  be an approximate solution of the LP with . 
In Theorem \ref{thm1}, we have proven the existence of a solution  near  with 
.
We are looking now for algorithmic ways to calculate this improved solution .
We present two algorithms that basically rely on solving an LP.
According to \ref{form:lpr} 
we split  into a fixed part  and a variable part .
The variable part is defined according to \ref{form:lpr} by  and the fixed part by . By assigning the variable part in a better way, Theorem
\ref{thm1} and Remark 2 state under the assumption that  that 
we can improve the objective value by . 
We denote with  the part which has to be reassigned. The
algorithm works as follows:
\begin{algo} \label{alg1}
\ 
  \begin{enumerate}
\item Set , 
  and 
\item Solve the LP 
\item Generate a new solution 
  \end{enumerate}
\end{algo}
If  is a basic feasible solution, compared to , our new solution  has up to  additional
non-zero components.
\begin{thm}
	Given solution  with  and .
	Algorithm \ref{alg1} returns a feasible solution  with  and the 
	distance between  and  is .
\end{thm}
\begin{proof}
Solution  is feasible because .
For the approximation we use Remark 2, which guarantees the existence of a solution 
with objective value 
 by leaving the part  of the solution  unchanged.
The unchanged part  is defined by using the lower bounds of \ref{form:lpr}, 
. Placing
 optimally leads therefore to the aimed approximation. Since the  and  are bounded by
 the worst possible distance between  and  is .
\end{proof}
In Algorithm \ref{alg1} we use an optimal LP solver as a subroutine. In many cases, like for example bin packing,
the corresponding LP relaxation is hard to solve and
the running time
for computing an optimal solution is very high. For the following algorithm it is sufficient to compute the LP
approximately, which in general can be performed more efficiently. We assume that 
because the double amount has to be reassigned to achieve the same improvement in the approximation as in Algorithm \ref{alg1}.
\begin{algo}\label{alg2}
\ 
\begin{enumerate}
\item Set , 
  and 
\item Solve 
  approximately with ratio 
\item If  set 
else .
\end{enumerate}
\end{algo}
\begin{thm} \label{thm2}
	Let  be a solution with  and .
  Then Algorithm \ref{alg2} returns a feasible solution  with approximation guarantee  
  and .
\end{thm}
\begin{proof}
	The property that  follows by Theorem 3 and the fact,
	that  has the double size  compared to  defined in Algorithm \ref{alg1}. 
	Furthermore we have to show that at the end of the algorithm .
	Suppose  for some . Using the assumption 
	 implies that
	.
	Consider the case that . In this case  has the aimed approximation since 
	 using
	.
	Thus in the following we assume .
	Suppose we solve the LP in step 2 optimally. In this case, Algorithm \ref{alg2} is identical to Algorithm \ref{alg1} using improvement
	of . By feasibility of \ref{form:lpr} we know there exists a solution 
	with 
	.
	This implies, that an optimal solution  of the LP 
	 is of size . Solving the LP approximately with ratio , 
	solution  has an additional term . The value of 
	 is therefore bounded by
	.
	Finally this results in the approximation for  as follows.

The last inequality holds because  since  and .
	By the last step of the algorithm we know that  and thus
	.
\end{proof}
In some cases we may not want to get a guaranteed approximation, but a guarantee that our solution  is getting
smaller by some . This works if the approximation ratio of  is worse than . 
The following corollary states, that if we use Algorithm \ref{alg2} on a solution  with 
 for some  the objective function of our new solution 
 decreases by at least .
\begin{cor}\label{cor5}
	Let  for some  and 
	. Then Algorithm \ref{alg2} returns a solution
	 with  and 
	.
\end{cor}
\begin{proof}
	Suppose like in the proof of Theorem 4 that we solve the LP in step 2 optimally. In this case, Algorithm \ref{alg2} is 
	identical to Algorithm \ref{alg1} using improvement
	of  and therefore by feasibility of \ref{form:lpr} we know that it returns a solution 
	with 
	.
	An optimal solution  of the LP
	 is therefore of size . Since we actually solve the LP approximately with ratio , 
	solution  has an additional term of  and the value is therefore 
	bounded by
	 according to the proof of Theorem 5.
	By construction of  we get . Since  we know that
        and that . Hence .
\end{proof}
\subsection{Integer Programming}
\label{sec:integer}
In this section we discuss how we can apply results from the previous sections to integer programming.
Consider a fractional solution  of the LP and a corresponding integral solution . 
By rounding each component  up to the next integer value, it is easy to get a feasible
integer solution  with an additional additive term , where  is the number of 
non-zero components.
We can apply any of the previous algorithms to  to get an improved solution .
But our actual goal is to find a corresponding integer solution 
with improved objective value  such that the 
distance between  and  is small.
In the following we present two algorithms that compute a suitable  with improved objective value and small
distance between  and .
Note that the straight forward approach to simply round up each component  leads to a distance between
 and  that depends on  and hence (depending on the LP) is too high.
Designing the algorithms, there seems to be some trade off between the number of non-zero components and the
distance between the integer solutions  and . The first algorithms tries to minimize the distance 
between  and  while
the second guarantees better approximation of  and  while the distance between them increases.
The existence of an algorithm combining both good properties, low distance and good approximation guarantee of 
 and , is an interesting question.

In Algorithm \ref{alg3} we focus on how much components of  need to be reduced to achieve the improved approximation guarantee.
This defines the migration factor in robust bin packing. The actual worst case distance between  and  is 
larger and however can only
be bounded by . Like in the previous algorithms, we assume that 
.
We require  to be a solution with
approximation guarantee  and
we require  to be an integer solution with
approximation guarantee . For every  we suppose that
.
For a vector , let  be the set of all integral vectors 
 such that .
Given LP solution  and integer solution  with the described properties above. 
The algorithm performs in the following
way.
  \begin{algo}\label{alg3}
\ 
  \begin{enumerate}
  	\item If possible choose vector  with  and return  and .
  	 Otherwise choose  such that  is maximal.\\
  Set .
  \item Set , 
  and 
  \item Compute an optimal solution  of the LP 
	\item Set  
	\item For each  set 
	\item If possible choose  such that  otherwise
  choose  such that  is maximal.
  \item Return .
  \end{enumerate}
  \end{algo}
\begin{thm}\label{thm6}
	 Let  be a solution of the LP with  and . Let  be an integral
	 solution of the LP with   where  for each 
	 .
	Then Algorithm \ref{alg3} returns an integral solution
	 with  such that
	.
\end{thm}
\begin{proof}
	{\bf Feasibility:} Feasibility for  and approximation  
	follows from Theorem 3. Step 2,3 and 4 are identical to Algorithm \ref{alg1}.
	Feasibility for the integer solution  follows from the fact, that for every component  we have 
	 and hence .\\
  {\bf Size of reduction of :} The only steps where components of  are changed are in step 1, 5 and 6. 
  In step 1 we change 
	 to obtain , in step 5 we change  to obtain  and in step 6
	we change  to obtain . Summing up the change in each step leads therefore to
	the maximum possible size of reduction of  compared to .
	In step 1 there are  components of  which are being reduced. In step 5
	no components of  are being reduced and in step 6 there are  
	components of  which are being reduced to obtain . Hence there are at most 
	components of  which are being reduced to obtain .\\
  {\bf Approximation:} It remains to prove, that  has approximation ratio .\\
  Case 1, :
  In this case, the algorithm returns in step 1 solution  with 
  and the algorithm terminates.
  Otherwise, if  we have for every component , that  and . Note that steps 2-4 are equivalent to Algorithm \ref{alg1}.\\
  Case 2, :
  In this case  for , since 
  is chosen maximally. Using  and  for
   we have .\\
  Case 3, :
  Let  be the number of components with . Next we compare the vector  with .
  Using  and the definition of  in step 5 we obtain 
  .
  The fact that  for  and  and the fact there are at most  components with  yield that
  . As a result we can bound 
  . 
  Since  and ,
  our integer solution  has the aimed approximation guarantee of .
\end{proof}
The running time of the above algorithm depends on the number of non-zero components and the time to compute 
an optimal solution of an LP. The algorithms computes an integral solution  with 
 for given fractional and integral solution.
In many cases, like bin packing, the dimension  is very large and provides thus a large additive
term in the approximation. The following algorithm describes how this large additive term can be avoided.
On the other hand the difference between  and  increases to .
Let  be an approximate solution of the LP  with
 and . 
Furthermore let  be an approximate integer solution of the LP with 
and 
and  for .
In addition we suppose that both  and  have exactly 
non-zero components. 
Our goal is now to compute a fractional solution  and and integer solution  having improved approximation properties
and still  non-zero components.
For a vector , let  be the set of all integral vectors 
 such that .
Furthermore we denote with  the indices of the non-zero components  such that
 are sorted in non-decreasing order.
\begin{algo}\label{alg4}
\ 
  \begin{enumerate}
  \item Choose  maximally such that the sum of smallest  components  is 
  
	\item Set  and 
	\item Set ,  and compute an 
	optimal solution  of the LP  
  \item Set 
  \item For each  set 
	\item If possible choose  such that  otherwise
  choose  such that  is maximal.
  \item Return 
  \end{enumerate}
\end{algo}
\begin{thm}
	Let  be a solution of the LP with  and 
	. Let  be an integral
	 solution of the LP with   and .
	 Solutions  and  have both exactly  non-zero components and for each component we have 
	 .
	Then Algorithm \ref{alg4} returns a fractional solution  with 
	 and an integral solution
	 with . Both  and  have the same 
	number of non-zero components with  and the number of non-zero components is bounded by
	 .
	The distance between  and  is bounded by .
\end{thm}
\begin{proof}
	{\bf Feasibility}: Feasibility and approximation for the fractional solution  follow easily from correctness 
	of Algorithm \ref{alg1} and the fact that removing additional components  and reassigning them
	optimally does not worsen
	the approximation. Each integral component  is by definition (step 5) greater or equal than . 
	By choice of  step 6 and 7 retain this property for  and imply thus feasibility for .
	
	{\bf Distance between  and :}
	The only steps where components of  are changed are step 2, 5 and 7. In step 2 we change 
	 to obtain , in step 5 we change  to obtain  and in step 7
	we change  to obtain . Summing up the change in each step leads therefore to
	the maximum possible distance between  and . In step 2 of the algorithm  components
	of  are set to zero to obtain , which by the definition of  results in a change of at most .
	We define  by  
	 with .
	In step 5, the only components  being changed are the ones where  is larger than . 
	So the change in step 5 is bounded by  by
	knowing that  since  if  for a 
	or . Furthermore we can bound 
	 since 
	is a basic feasible solution and 
	can be bounded by  (i.e. we get  for the size of components 
	 plus 
	 for the
	remaining ones). Therefore we have .
 	In step 7, .
	In sum this makes a total change of at most .

	{\bf Number of components}: 
	The property that  and  have the same number of non-zero components together with the property that 
	 implies that  whenever .
	This property holds also for  and  since a component  is set to zero if and only if
	. Notice that .
	Suppose by contradiction that there is a component  with  and , then 
	and by definition
	of  we obtain . In this case we have , which gives a contradiction
	to .
	Using the property that  and  have the same number of non-zero components, it is sufficient to prove
	that the number of non-zero components of  is limited by .
	Our new solution  is composed of  and . Solution  has  non-zero
	components, since in step 2 we set  components of  to zero. Being a basic feasible solution,
	 has at most  non-zero components and hence  has at most  non-zero components.
	If , then  has  non-zero components.
	So let : The total number of non-zero components after step 4 is . We now prove that
	this number is bounded by . 
	Parameter  is chosen to be maximal, therefore . 
	Hence, the average size of
	components  is greater than . Since the components are sorted in non-decreasing order, 
	every component 
	with  has size .
	Summing over all non-zero components of  yields the following inequality:
	.
	Using that  yields
	.
	Dividing both sides by  gives . This shows
	that the number of non-zero components of  and  is at most .

	{\bf Approximation:} Case1: \\
	The following inequalities  and
	 together yield the aimed approximation
	.\\
	Case2: \\
	Since  is chosen maximally,  for every components . Since 
		and  has at most  non-zero
	components  is bounded by .
\end{proof}
Instead of using an optimal LP solution in Algorithm \ref{alg3} and \ref{alg4}, we can solve the LP approximately 
with a ratio of . The following algorithm is basically a combination of Algorithm \ref{alg2} and Algorithm \ref{alg4}.
We could also combine Algorithm \ref{alg2} and Algorithm \ref{alg3} to obtain similar results.
We make the following assumption for the fractional solution  and the corresponding integer solution :
Let  be an approximate solution of the LP  with
 and .
Let  be an approximate integer solution of the LP with  for some value 
 and with . 
Suppose that both  and  have only 
non-zero components. 
For every component  we suppose that .
Furthermore we are given indices , such that the non-zero components  are
sorted in non-decreasing order i.e. .
\newpage
\begin{algo}\label{alg5}
\ 
  \begin{enumerate}
   \item Set ,  and 
   
	\item Compute an approximate solution  of the LP 
	with ratio 
	\item If  then set , 
	 and goto step 9
  \item Choose the largest  such that the sum of smallest components  is 
  
	\item For all  set  
	and 
	\item Set  where  is a vector consisting of components 
	. Reduce the number of non-zero components to at most .
  \item 
  \item For all non-zero components  set 
	\item If possible choose  such that  otherwise
  choose  such that  is maximal.
  \item Return 
  \end{enumerate}
\end{algo}
Step 6 of the algorithm can be performed using a standard technique presented for example in \cite{beling1998}. 
Arbitrary many components of 
 can be reduced to  without making the approximation guarantee worse.
We formulate the following theorem and corollary such that we can directly use it in the next section.
\begin{thm}\label{thm8}
	Let  be a solution of the LP with  and . Let  be an integral
	 solution of the LP with  for some value 
	 and with .
	 Solutions  and  have the same number of non-zero components and for each component we have 
	 . The number of non-zero components of  and  is  with .
	Then Algorithm \ref{alg5} returns a fractional solution  with 
	 and an integral solution
	 where one of the two properties hold:
	  or . 
	 Both,  and  have at most 
	non-zero components and the distance between  and  is bounded by .
\end{thm}
\begin{proof}
	Note that the first 3 steps are equivalent to Algorithm \ref{alg2}. In steps 4-6 
	the number of non-zero components  are reduced. As we apply
	a method that does not increase the objective value we obtain by
	Theorem 4 that . 
	Steps 4-9 are similar to Algorithm \ref{alg4}. The main
	difference is that components  are not assigned by the LP but are added to the 
	LP solution	afterwards in step 7.\\
	{\bf Distance between  and :} As in Theorem 7, the steps where components of  are changed are steps 
	5,8 and 10. By definition of  the change of  in step 5 is bounded by .
	As shown, the change in step 8 is bounded by  and 
	, where.
	The change in step 10 is bounded by . Therefore the total change
	between  and  is bounded by .\\
	{\bf Number of components:} According to Theorem 7, the number of nonzero components of  is equal to 
	the number of non-zero components of  which equals  (the number of non-zero components of
	 is bounded by ). We distinguish between the
	two cases where  and . In the case where  the number of components
	of  is smaller than  and hence bounded by . Consider the case where .
	By definition of  we know that .
	Using the argument in the proof of Theorem 7, we obtain the following inequality:
	
	Using that  yields
	.
	As  we obtain that 
	.\\
	{\bf Approximation:} According to Theorem 7 we distinguish between the two cases where 
	 and . In the second case where
	 we know that  is bounded by  plus the number
	of non-zero components of  since  is chosen maximally. Hence .
	In the case where , we know . As  we get .
	Note that we can also make the general claim for  that . 
\end{proof}
The following corollary is an analog to Corollary \ref{cor5} which states what Algorithm \ref{alg5} is doing if the approximation
ratio of  is worse than . We will need this corollary in the next section as we have no true control
about the approximation ratio of . During the bin packing algorithm new columns might appear in the LP, 
which might change
the optimal solution and therefore the approximation ratio of a solution .
\begin{cor}\label{cor9}
	Let  for some  
	 and 
	and let  for some
	 and . 
	Solutions  and  have the same number of non-zero components and for each component we have 
	 . The number of non-zero components of  and  is  with . 
	 Then Algorithm \ref{alg5} returns a fractional solution
	 with  and an integral solution  
	where one of the two properties holds:
	  or . 
	Both  and  have at most 
	non-zero components and the distance between  and  is bounded by .
\end{cor}
\begin{proof}
Note that steps 1-3 are basically identical to Algorithm \ref{alg2}. Hence Algorithm \ref{alg5} returns by Corollary 6 a fractional
solution  with . The distance between the integral solutions  
and  are independent of the approximation ratio of . Hence the distance between  and  is
according to Theorem \ref{thm8} bounded by . The number of non-zero components of
 and 
is by the proof of Theorem \ref{thm8} bounded by the number  of non-zero components of  or by 
.
The approximation guarantee for , that  follows if 
. If  then .
We can also make the general claim for  that .
\end{proof}

\section{AFPTAS for robust bin packing}
\label{sec:bin-packing}
The goal of this section is to give a fully robust AFPTAS for the bin packing
problem using the methods developed in the previous section. For that purpose we show at first the common way how one
can formulate a rounded instance of bin packing as an ILP. In Section 4.2 we present abstract properties
of a rounding that need to be fulfilled to obtain a suitable rounding and in Section 4.3 we present the used
dynamic rounding algorithm. The crucial part however is the analysis of the dynamic rounding in combination with ILP
techniques. Since the ILP and its optimal value are in constant change due to the dynamic rounding, it is difficult to 
to give a bound for the approximation. Based on the abstract properties we therefore develop techniques how
to view and analyze the problem as a whole. 

The \emph{online bin packing problem} is defined as follows:
Let  be an instance with  items at time step 
and let  be a mapping that defines the sizes of the items.
Our objective is to find a function , such that  for all
 and minimal  (i.e.  describes a packing of the items into a minimum number
of bins). We allow to move
few items when creating a new solution  for instance . 
Sanders et al. \cite{sanders2009} and also Epstein and Levin \cite{epstein2006robust}
defined the \emph{migration factor} to give a measure for the amount of repacking. 
The migration factor is defined as the total size of all items that are
moved between the solutions divided by the size of the arriving item.
Formally the migration factor of two packings  and  is defined by 
.
\subsection{LP-Formulation}
Let  be an instance of bin packing with  different item sizes . Suppose
that for each item  there is a size  with .
A configuration  is a multiset of sizes 
with , where 
denotes how often size  appears in configuration . We denote by  the set of all configurations. Let .
We consider the following LP relaxation of the bin packing problem:

Component  states the number of items  in  with  for .
This LP-formulation was first described by Eisemann
\cite{eisemann1957trim}. Suppose that each size  is larger or equal to
 for some . Since the number of different item sizes is ,
the number of feasible packings for a bin is bounded by .
Obviously an optimal integral solution of the LP gives a solution to our bin packing problem. We denote
by  the value of an optimal solution. An optimal fractional solution is a lower bound 
for the optimal value. We denote the optimal fractional solution by .





\subsection{Rounding}
We use a rounding technique based on the offline APTAS by Fernandez de La Vega \&
Lueker \cite{de1981bin}. As we plan to modify the rounding through the dynamic rounding algorithm we give a 
more abstract approach on how we can
round the items to obtain an approximate packing.
At first we divide the set of items into \emph{small} ones and
\emph{large} ones. An item  is called \emph{small} if , otherwise it is called \emph{large}. Instance  is partitioned accordingly
into the large items  and the small items .
We treat small items and large items differently. Small items can be packed using a greedy algorithm
and large items need to be rounded using a rounding function.
We define a \emph{rounding function} as a function  which maps each large item 
to a \emph{group} . By  we denote the set of items being mapped to the same 
group , i.e.
. By  we denote an item  with 
.
Given an instance  and a rounding function , we define the rounded instance  by rounding the size of 
every large item  for  up to the size  of the largest item in its group. 
Items in  are
excluded from instance . We write  for the rounded size of item  in .
Depending on constants  and , we define the following properties for a rounding function .
\begin{itemize}
\item[(A)]  for a constant 
\item[(B)]  for all 
\item[(C)]  for a constant  with 
\item[(D)]  
\end{itemize}
Any rounding function fulfilling property (A) has at most  different item sizes and hence 
instance
 can now be solved approximately using the LP relaxation. The resulting LP relaxation has  
rows
and can be solved approximately with accuracy  using the max-min resource sharing \cite{grigoriadis2001approximate}
in polynomial time.
Based on the fractional solution we obtain an integral solution  of the LP with 
for some additive term .
We say a packing  \emph{corresponds} to a rounding  and solution  if items 
in  are packed by  according to the integral solution  of the LP. The LP is defined by
instance . Items in  are each packed in separate bins.
\begin{lem}\label{lem10}
  Given instance  with items greater than  and a rounding function  fulfilling properties
  (A) to (D), then  and .
  Let  be an integral solution of the LP for instance  with  
  for some value , let  be a packing of  which corresponds to  and  and let  
  . Then
  
\end{lem}
\begin{proof}
	Let . Let  be the set of items in rounding group , which corresponds
	to their rounded sizes and let  be the set of items in , which corresponds to their actual
	size. Instance  contains every item from  to , 
	while items from  are excluded.
	By property (D) we know, that items in  are larger or equal than items in .
	By property (C) we find for every item in  an unique item in  with larger or equal size, 
	since the largest item
	in  to which all items are being rounded up is smaller than any item in .
	Using property (B) for each item in  we find a unique larger item in .
	Therefore we have for every item in the rounded instance  an item with larger size in instance  and hence
	
   Since the packing  corresponds to a solution ,  gives a solution with 
    bins and since 
   we obtain that . Further, we can bound .
   Since every item in  is of size at least  there is a lower bound for the optimum:
   .
   Resolving this inequality, we get  and hence 
	. Since
    and  are constant we know  which implies together with
   the inequality .
\end{proof}
How can we handle the small items? Actually, small items do not make problems at all. We can pack them via 
FirstFit \cite{coffman1984approximation}
on top of the existing large items and still obtain a good solution. FirstFit is a greedy algorithm which simply places
the current item into the first bin having enough space. FirstFit opens a new bin of the item does not fit into any
used bin.
\begin{lem}\label{lem11} \cite{de1981bin}
	Let  be an instance with small and large items and given a packing  of the large items with
	 for some .
  Packing the small items via FirstFit on top of packing  gives a new packing of instance  which uses
  
  bins.
\end{lem}
Given instance , we define  by  if 
 is even and otherwise . By definition  is
always even.
For every instance  we find a rounding function 
with rounding groups  which fulfills properties (A)-(D) such that 
and .
\begin{algo}\label{alg6}
\   
\begin{enumerate}
\item Partition the large items according to the rounding function  in groups 
\item Round up the size of each large item  to  to obtain instance 
\item Compute a fractional solution  of the LP defined by  approximately with ratio 
\item Round up each component of the fractional solution to obtain an integral solution  for the LP for instance 
\item Pack items in  according to the integral solution 
\item Open a bin for each item  with 
\item Pack the small items in  via FirstFit
\end{enumerate}
\end{algo}
A solution  of  with ratio  having  non-zero components can be computed using
max-min resource sharing \cite{grigoriadis2001approximate}.
According to Lemma \ref{lem10} and 11, the algorithm described above produces a solution with approximation
 with .
\subsection{Online Bin Packing}
Let us consider the case where items arrive online. As new items arrive we are allowed to repack several items but
we intend to keep the migration factor as small as possible.
We present operations that modify the current rounding  and packing  to give a solution for
the new instance. The given operations worsen the approximation but by applying the results from the previous section
we can maintain an approximation ratio that depends on .
The presented rounding technique is similar to the one used in \cite{epstein2006robust}. 
In our algorithm we use approximate solutions of ILPs in contrast to the APTAS of Epstein \& Levin which solve
the ILPs optimally. Handling with approximate ILPs results in a different analysis of the algorithm because
many helpful properties of optimal solution are getting lost.

Note that in an online scenario of bin packing  where large and small items arrive online, small items do not
need to be considered. We use the same techniques as in \cite{epstein2006robust} to pack small items. As a small item 
arrives we place it via FirstFit \cite{coffman1984approximation}. 
In this case FirstFit 
increases the number of bins being used by at most  (\cite{de1981bin}) and the migration factor is zero as we 
repack no item.
Whenever a new large item arrives several small items might also need to be replaced. Every small item in a bin
that is repacked by the algorithm, is replaced via FirstFit. Packing small items with this strategy 
does not increase the number of bins that need to
be repacked as a large item arrives. Later on the migration factor will solely be determined by the number of bins
that are being repacked. More precisely, we will prove that the number of bins, that need to be repacked is bounded
by .
Therefore we assume without loss of generality that every arriving item is large, i.e. has a size  
(see also \cite{epstein2006robust}).
Our rounding  will be constructed by three different \emph{operations},
called the \emph{insertion, creation} and \emph{union} operation. The
insertion operation is performed whenever a large item arrives. This
operation is followed by a creation or an union operation depending on the phase the algorithm is in. 
Let  be the existing instance as defined above, let  be the corresponding rounding function, let  
be a fractional solution of the LP generated for the rounded instance  and let  be the current packing
of items in . We define two subgroups of  denoted by  and  in the creation phase, 
which are also
being modified by the operations.
Let  be the new instance. We use the following operations that modify
the current rounding , the packing  and the fractional and integral LP solution  and .
We denote with , ,  and  the new rounding, packing and fractional/integral LP solutions for instance 
\subsubsection*{Insertion Step}
Find the largest  with . 
Set  and .
For every  we define  and .
Set  and .
\begin{figure}
\includegraphics[width=\textwidth]{insertion.pdf}
\caption{Insert operation}
\end{figure}
\subsubsection*{Modified Insertion Step}
During the creation phase, the algorithm uses the modified insertion operation.
Find the largest  ( and  included) with . 
Set  and .
For every  we define  and .
For every  we define  and .
Set  and .

\subsubsection*{Creation Phase}
The creation phase consists of  creation steps, where . At the end of each creation phase we intend
to have new rounding groups  and  created from the subgroups of  named  and .
At the beginning of the creation phase we always have  and  and  are empty.
In the first step we change the rounding group
for all items  with  to . 
Furthermore we say the  largest items of  belong to  and the  smallest items belong to .
In each of the  creation steps we change the rounding function for the largest items  
and . Set 
and . Since items  and  are moved from  to  
and  they have to be covered by
the LP. Therefore we increase the value of the LP solution by ,  and 
, , where  are defined such that 
 and . For  set 
and .
\begin{figure}
\includegraphics[width=\textwidth]{creation.pdf}
\caption{Create operation}
\end{figure}
\subsubsection*{Union Phase}
The union phase consists of  union steps, where . At the end of each union phase we have made
out of  roundings groups  rounding groups with size doubled.
For the first union step we determine the largest index  with . If there is no such index then
set . In each step now set  and  and for the other items 
we define . Modify the packing for  and  by  and
place  into a new bin. Modifying the packing this way implies that we have to change one configuration
of the fractional and integral LP solution  and  and add one configurations for the additional bin. 
Let  be the
configuration used by . Configuration  is replaced by a configuration  where an item
of size  is exchanged by an item of size . Furthermore we add another 
configuration  with an item of size .
\begin{figure}
\includegraphics[width=\textwidth]{union.pdf}
\caption{Union operation}
\end{figure}

Note that each repacking that we perform in the operations is valid because we always replace items by smaller ones.
New packings  are created in a way that they correspond to new integer solution . We have to prove that
this solutions  is feasible. Note also, that in a creation operation and in a union operation two additional
non-zero components of size  might be created.
\begin{lem}\label{lem12}
	Applying any operation above on a rounding  and ILP solution  with corresponding packing  defines
	a new rounding  and a new integral solution . Solution  is a feasible solution of the LP
	for instance .
\end{lem}
\begin{proof}
	We have to analyze how the LP for instance  changes in comparison to the LP for instance .
	\\{\bf Insertion Operation:} The right hand side of the LP derived from  does not change at all since
	the right hand side is determined by the cardinalities . 
	For some  let  be the the rounding group where the new item is inserted.
	By construction of the insertion operation for each rounding group  with , there is
	one item that is inserted into group  and one item that is shifted out.
	Let  be the second largest item of rounding group .
	Since the largest item  in group  is shifted to the next group,
	the size  of item  in a group  is defined by .
	Therefore each item in  is rounded to the previous smaller value since ).
	Hence configurations of the LP solution for  can be transformed into feasible configurations for 
	i.e. .\\
	{\bf Creation Operation:}
	Note that the rounding groups , for  remain identical; i.e. .
	The groups  and  get both a new item, but of smaller size. Therefore the sizes  of all items
	 are not modified by a creation operation. We have  for items in groups 
	. Therefore the matrix  remains the same. Only the right hand side 
	of the LP from instance  is modified (i.e. ).
	As two new configurations are being added to  and  they cover exactly the enhanced right hand side
	and are therefore a feasible solution of the LP from instance .\\
	{\bf Union Operation:}
	In the union operation we basically change only 4 rounding groups. Suppose we merge rounding group  with
	 and rounding group  with . While the size of  and 
	 is incremented the size of  and 
	is reduced. Similar to the creation operation, this leads to a change in the right
	hand side of the LP. Two components of the right hand side, which correspond to 
	and  are reduced by  and two other components, which correspond to the 
	 and  are increased by .
	Furthermore the sizes of items in  and  are equal or smaller than the sizes of
	items in  and  since 
	for all items  and  for all items .
	 
	and  are shifted to the next rounding groups. 
	Consider a feasible configuration  of the LP for instance . Then the modified configuration 
	(with replaced item sizes) is also feasible in the LP for instance . The new solutions  and  use
	the modified configurations and cover the right hand side of the LP.
\end{proof}
The operations are used as described in Algorithm \ref{alg7} below. We apply the algorithm on a rounding function
 and instance . We suppose that 
for some  and hence .
An improve() statement stands for a call of Algorithm \ref{alg5} 
with improvement , fractional solution  and integral solution . The variable part  
is defined by . 
After an improve call the packing is changed according to the new integral solution.
Since during a creation operation and a union operation two additional non-zero components of size  might appear,
we change the parameter  of Algorithm \ref{alg5} slightly to . Parameter  is defined maximally such that
the sum of the smallest components  are 
. The two additional non-zero components belong to
components  and are therefore reduced in step 6 along with the others.
\begin{algo}\label{alg7}
\\
 \begin{algorithm}[H]
    \For{i := 1 to K}{
	get new item\;
	improve();
       insert\;}
	\For{i := 1 to m/2}{
		\tcc{Creation Phase}
		\For{j := 1 to K}{
			get new item\;
			improve()\;
       		 modified insert\;
			create\;
		}
		\tcc{Union Phase}
		\For{j := 1 to K}{
			get new item\;
			improve()\;
       		insert\;
			union\;
		}
	}
  \end{algorithm}
\end{algo}
In the following we present how the algorithm changes the rounding groups for . The table presents the state of each
rounding
groups after each phase.
\begin{table}\centering
\begin{tabular}{c|c|c|c|c|c|c|c|c|c}
phases &  &  &  &  &  &  &  &  & \\
\hline
start &  &  &  &  &  &  &  &  &  \\
insertion &  &  &  &  &  &  &  &  &  \\
creation &  &  &  &  &  &  &  &  & \\
union &  &  &  &  &  &  &  &  &  \\
creation &  &  &  &  &  &  &  &  &  \\
union &  &  &  &  &  &  &  &  &  \\
creation &  &  &  &  &  &  &  &  &  \\
union &  &  &  &  &  &  &  &  &  \\
\end{tabular}
\end{table}
One can see that after the execution of Algorithm \ref{alg7} each rounding group has exactly  items. We prove the
general case for arbitrary : Every rounding has exactly  items after the execution of Algorithm \ref{alg7}.
\begin{lem}\label{lem13}
	Let  be the rounding function at the beginning of the algorithm. Suppose that every 
	rounding group		has exactly  items.
	Then after the execution of the algorithm above the computed rounding function  after  insertions
	has  rounding groups  with  for . 
\end{lem}
\begin{proof}
	The algorithm starts with a rounding function that contains exactly  items. After the first  insertion steps
	rounding function  is of the form:
	 since  items are shifted to   while the cardinalities 
	of the other rounding groups remain the same.
	During the next  arrivals, the algorithm is in the creation phase. We perform a creation operation after
	each insertion. For each item shifted to , two items are shifted to the new created groups  and .
	At the end of the first creation
	phase, the rounding function  satisfies .
	In the following union phase, the rounding groups ,  and , 
	are merged together. For each union operation, one item is shifted from  to 
	and another from  to . Since there are  insert operations in the union phase,
	rounding group . 
	After the next creation and union phase, the number of rounding groups is also .
	On the other hand we have two additional groups .
	After  creation and union phases the rounding
	function  is by induction of the form . 
	This can be proved by induction on . For  we get .
	Therefore, after one additional creation and union phase, we obtain  groups  for
	.
\end{proof}
Using Algorithm \ref{alg7} with a starting rounding function  that has  rounding groups and the property that 

produces according to the lemma a rounding function  that has also  rounding groups of equal size,
but with cardinality doubled.
Therefore we can use Algorithm \ref{alg7} repetitively to always get suitable rounding functions.
The following algorithm is our final online AFPTAS for the classical bin packing problem. Let  be the sum
of all item sizes of items .
\begin{algo}\label{alg8}
\
\begin{itemize}
\item While  and  does not divide  get the new item  and
use the offline AFPTAS \ref{alg6} with an LP of approximation ratio .
\item Afterwards use Algorithm \ref{alg7} repetitively to obtain a packing for each instance
\end{itemize}
\
\end{algo}
By using the offline AFPTAS for small instances we can make sure that Algorithm \ref{alg7} is started with
a suitable rounding function. Since Algorithm \ref{alg7} always produces a rounding function fulfilling properties (A) to (D)
and  divides the current number of items , every rounding group  has the same
number of item sizes as the algorithm leaves the while-loop in the first step.

In the following we give a bound for the rounding functions  that we produce in every step of
the algorithm. 
It remains to prove that the approximation during the execution of Algorithm \ref{alg7} can be bounded.
Therefore we define a relation between rounding functions.
Let  and  be two rounding functions, with  having  rounding groups for 
some .
We can \emph{embed}  into  in symbols , if  and for 
every item  we 
have . A relation  always implies that 
.
\begin{lem}\label{lem14}
  For each , we can embed  into a function
  , which fulfills properties (A) to (D). Rounding function  has parameter
   for property (A) and  for property (C).
\end{lem}
\begin{proof}
	Since we basically shift largest items to the following rounding group we designed operations 
	insertion, creation and union in a way that property (D) is never being
	violated by any  for . As shown in the proof of Lemma \ref{lem12} the number of rounding groups remains
	constant between  at the end of a union phase and  during the creation and union phase.
	Suppose the algorithm above has started with a number of items  and rounding groups 
	,which are being modified	by the algorithm.
	We define the rounding function  in which  can be embeded in the following way: 
	Function  has rounding groups  with 
	 and .
	Since every rounding group of  except  has the same number of items, the rounding function
	 fulfills property (B). Rounding function  fulfills property (C) because  and . This implies constant .
	We prove property (A) by giving an upper and a lower bound for  that are both
	in . Recall that .
	On the one hand we get .
	On the other hand . Since 
	weg get .
	It remains to prove that we can embed  in  i.e. . 
	Since  never exceeds  items and  we get .
	According to the proof of Lemma \ref{lem12} and the construction of the creation operation,  is during 
	the creation phase
	of the following form:  for some  and . Rounding function 
	has in every rounding group  for  exactly  items.
	Since property (D) 
	holds for both rounding function  and , the rounding groups  contain
	the same items as the last  rounding groups of .
	Items in these groups are therefore rounded identically.
	For some  let  be the rounding group which contains the same items as .
	Since rounding groups  each contain exactly  items, the rounding groups 
	 contain the items of exactly two rounding groups. Therefore the items
	in  are rounded to a smaller size compared to using
	. Items that belong to  and 
	are contained in  and by definition do not need to be considered. Hence, any rounding function 
	which is in an creation phase can be embedded into an .
	By construction of the union operation and the proof of Lemma \ref{lem12},  is during the union phase
	of the form  for some  and 
	. As shown in the union phase, items in  are rounded equally
	in . As the sum of  and  is  and the sum of  and 
	is  the items of  and  and the items in  and  
	belong in  to the same rounding group and are hence rounded equally or to a smaller size compared to using
	.
	Items in  are each of size  and are rounded equally or to a smaller size 
	than using  since the same argument as in the creation phase holds.
\end{proof}
Define  by .
As  fulfills property (A) to (D), we obtain by Lemma \ref{lem10} and  the following 
two equations for every :
\begin{enumerate}
\item 
\item 
\end{enumerate}
Note that since  we have . Recall that
 implies that 
 and that 
 (rounding up a basic feasible solution).
Let us discuss how the methods from the previous section apply to the presented online algorithm.
The procedure improve is implemented by using Algorithm \ref{alg5} in order 
to get an improved solution for instance . 
Algorithm \ref{alg5} is applied using  as the approximation parameter. 
In the following lemma we prove that
applying Algorithm \ref{alg5} to improve a solution for  impacts the overall approximation 

in the same way. We define .
\begin{thm}\label{thm15}
	Given a rounding function  and an LP defined for . Let  be a fractional solution of the LP with
	 and  
	and  for some 
	. Let  be	an integral solution of the LP with  and
	corresponding packing  such that .
	Suppose  and  have the same number  of non-zero components and for all components  we have
	.
	Then using 
	Algorithm \ref{alg5} on  and  returns new solutions  with  and integral solution  with corresponding packing  such that
	
	Further, both solutions  and  have the same number  of non-zero components and for each component we have
	.
\end{thm}
\begin{proof}
	As shown in the following, Algorithm \ref{alg5} maintains the property that  and  have
	the same number of non-zero components and that  since we can use Theorem \ref{thm8} and Corollary \ref{cor9}.
	By condition we have . Since
	 we obtain for the integral solution  that
	.
	Hence by definition of  we get . This is one requirement to use Theorem \ref{thm8} 
	or Corollary \ref{cor9}.
	We look at the cases separately where on the one hand  and on the other hand 
	. 
	
	Case 1, :
	At first we give an upper bound for : We get  using
	that . This implies
	that .
	Algorithm \ref{alg5} returns by Theorem \ref{thm8} a solution  with  and an integral solution  with 
	 or .
	For the term  we get  .
	Using that  can be embedded in  we get . 
	Therefore .
	In the case where  we can bound the number of bins of the new packing  
	by	.
	In the case that  we obtain
	.
	
	Case 2, : 
	By condition we have . Since
	 we obtain for the solution  that
	.
	Hence by definition of  this implies  and therefore ,
	which fulfills the requirements of Corollary \ref{cor9}.
	Using Algorithm \ref{alg5} on solutions  with  and  with 
	
	we obtain by Corollary \ref{cor9} a fractional solution  with
	 and an integral solution  with either
	 or .
	So for the new packing  we can guarantee, that
	
	if . If , we can guarantee
	that .
	Furthermore we know by Corollary \ref{cor9} that  and  have at most  
	non-zero components.
\end{proof}
Set . Then .
We get the central theorem:
\begin{thm}\label{thm16}
  Algorithm \ref{alg8} is a fully robust AFPTAS for the bin packing problem.
\end{thm}
\begin{proof}
	While instances are small Algorithm \ref{alg8} uses the offline AFPTAS (see Algorithm \ref{alg6}). Using Algorithm \ref{alg6}, we get a packing
	 for instance  that uses at most
	 bins, where 
	. 
	Since the instance is small
	the migration factor is bounded although we might repack every single item. Let  be the first index where
	the algorithm leaves the while-loop. By condition we are in the while loop
	while  and  does not divide . Hence . The migration factor for instances  with 
	 is therefore bounded by  since every arriving item
	has size at least . The approximation guarantee for small instances is bounded by 
	.
	In the following we consider large instances  with .
	
	{\bf Full robustness:} The migration factor for some consecutive packings  and  is bounded by
	the migration of the improve-call plus the migration of an insertion and an union operation. 
	The operations create requires no shifting of items at all.
	As proven in the previous section, an improve-call changes at most  components of a solution .
	Since the arriving item is large with size , changing a complete configuration 
	requires migration of at most .
	Combined this results in a migration factor for the improve-call  
	if we use Algorithm \ref{alg5}.
	By construction of the insertion operation it shifts in worst case one item per 
	rounding group. Having  rounding groups this gives a migration factor of at most 
	.
	Therefore the complete migration is bounded by .
	
	{\bf Running time:} The running time is dominated by the max-min resource sharing (see Algorithm \ref{alg5}) and 
	the number of non-zero components. The number of non-zero components is bounded by 
	and is therefore polynomial in  and . As the running time for the max-min resource sharing
	is also polynomial in  (see \cite{grigoriadis2001approximate}), 
	the running time is clearly polynomial in  and .
	
	{\bf Approximation:} We prove by induction that four properties hold for any packing 
	and corresponding LP solutions. Given fractional solutions
	 and integral solution  of the LP defined by instance . 
	Properties (2)-(4) are
	necessary to apply Theorem \ref{thm16} and property (1) provides the wished approximation ratio for the bin packing problem.
	\begin{enumerate}
		\item packing  uses at most  bins
		\item 
		\item for every configuration  we have 
		\item  and  have the same number of non-zero components and that number is bounded by 
		
	\end{enumerate}
	To apply Theorem \ref{thm15} we furthermore need a guaranteed minimal size for  and .
	According to Theorem \ref{thm15} integral solution  needs  and 
	 as we set at most .
	By condition of the while-loop we know that any instance . 
	Since  we get
	. 
	By  we
	finally get that . Since  we obtain by the same argument
	that  and since  we get that .
	
	In the case that  we have by the offline algorithm that the number of non-zero components  since . The number of used bins is bounded
	by 
	(note ) and property (2) is fulfilled for the same reason. Furthermore in the 
	offline algorithm every component  is rounded up to obtain the integral component . 
	Therefore all properties (1)-(4) are fulfilled for  and the induction basis holds.
	Now let  be a packing for  for instance  with solutions  and  of the LP defined by 
	. Suppose
	by induction that property (1)-(4) hold. We have to prove that these properties also hold for  and the
	corresponding solutions of the LP defined by . Packing  is created by using an
	improve call for  and  followed by an insertion operation and optional, an union or a creation operation.
	\\{\bf improve:} Let  be the resulting fractional solution of Algorithm \ref{alg5}, let  be the resulting integral solution
	of Algorithm \ref{alg5} and let  be the corresponding packing. Properties (1)-(4) are fulfilled 
	for ,  and  by induction hypothesis. Hence we can use Theorem \ref{thm15}. 
	By Theorem \ref{thm15} properties (1)-(4) are then still fulfilled for ,  and  and moreover we get
	 and 
	 for  or .
	\\{\bf operations:} First we take a look at how the operations modify ,  and .
	By construction of the insertion operation, the LP solutions  and  are not modified while 
	increases by . By construction of the creation operation  and  are increased by 
	and  decreases by . By construction of the union operation,  and  
	are increased by  and  remains constant.
	Property (1): Let  be the fractional solution and  be the integral solution after using operations 
	on  and . Packing  equals . According to the operations
	an insertion operation yields .
	An insertion operation followed by an union operation yields  and an insertion operation followed by a creation operation
	yields . Algorithm \ref{alg7} is designed that in 
	the union phase  since there is an improve call with 
	 and otherwise
	 since there is an improve call with .
	Therefore we have in any case that  uses at most  bins.
	The proof that property (2) holds is symmetric since  increases in the same way as  
	and  for  or .
	For property (3) note that in the operations a configuration  of the fractional solution is increased by  
	if and only
	if a configuration  is increased by . Therefore the property that for all configurations  
	retains from  and . By Theorem \ref{thm15} the number of non-zero components of  and  is bounded 
	by . 
	By construction of the creation operation and union operation  and 
	might have two additional non-zero components. But since these are being reduced by Algorithm \ref{alg5} (note that 
	we increased the number of components being reduced in step 6 by ), the LP solutions  and  
	have at most  non-zero components which proves property (4).
	\end{proof}
\subsection{Running Time}
Storing items that are in the same rounding group in a heap structure, we can perform each operation 
(insertion, creation and union) in time . 
Furthermore Algorithm \ref{alg5} needs to look through all non-zero components. The number of non-zero components is bounded
by .
Main part of the complexity lies in finding an approximate LP solution.
Let  be the time to solve a system of  linear equations. The running time of
max-min resource sharing is then in our case 
(see \cite{jansen2004approximation}).
Therefore the running time of the Algorithm is .
\section{Conclusion}
Based on approximate solutions, we developed an analogon to a theorem of Cook et al. \cite{cook1986sensitivity}. 
Our improvement
helps to develop online algorithms with a migration factor that is bounded by a polynomial
in , while algorithms based on Cook's theorem usually have exponential migration factors. 
We therefore applied our techniques to the famous online bin packing problem.
This led to the creation of the first fully robust AFPTAS for an NP-hard online optimization problem.
The migration factor of our algorithm is of size , which is a notable 
reduction compared to previous robust algorithms.
When a new item arrives at time  the algorithm needs
running time of , where  is the time to solve a system 
of  linear equations.
Any improvement to the max-min resource sharing algorithm based on the special structure of bin packing would 
immediately speed up our online algorithm. We believe that there is room to reduce
the running time and the migration factor. Note for example that we give only a very rough bound for the
migration factor as the algorithm repacks  bins. Repacking these bins in a more
carefully way might lead to a smaller migration factor.
An open question is the existence of an 
AFPTAS with a constant migration factor that is 
independent of .
We mention in closing that the LP/ILP-techniques presented are very general and hence can possibly be used
to obtain
fully robust algorithms for several other online optimization problems as well (i.e. multi-commodity flow, 
strip packing, scheduling with malleable/moldable task or scheduling with resource constraints).

\bibliographystyle{plain}
\bibliography{library}









\end{document}
