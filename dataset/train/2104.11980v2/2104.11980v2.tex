\subsection{Multi-agent trajectory modelling}

Our problem description closely follows \citet{alcorn2021baller2vec}, whom we quote here:

\begin{quote}
Let  be a set indexing  agents and  be the  agents involved in a particular sequence.
[Let]  [be] an unordered set of  coordinate pairs such that  are the coordinates for agent  at time step .
The ordered sequence of sets of coordinates , together with , thus defines the trajectories for the  agents over  time steps.
\end{quote}

In multi-agent trajectory modeling, the goal is to model a joint probability of the form:



\noindent
i.e., the joint probability of the  agents' trajectories  at time step  given the agents' location histories .
We note here that the common practice of \textit{simultaneously} predicting the trajectories for all of the agents at a specific time step is not required by theory.
Using the chain rule of probability, the joint probability of the agents' trajectories can be factorized as, e.g.:



where we omit the conditional historical trajectories for brevity.
As a result, it is perfectly acceptable to generate trajectories agent-wise, using the previously generated trajectories as additional conditioning information when generating the trajectories for later agents (see Figure \ref{fig:legal_dep}).

\begin{figure}[ht]
\centering
\subfigure{\includegraphics[width=\columnwidth]{legal}}
\caption{
At inference time, a model is not \textit{required} to \textit{simultaneously} generate the trajectories for all of the agents at a specific time step.
An alternative strategy is to allow the model to generate the agents' trajectories one at a time, and let the model use the previously generated trajectories to inform the trajectories it generates for the remaining agents.
}
\label{fig:legal_dep}
\end{figure}

\subsection{\btv{} is a (conditional) generative model.}\label{sec:baller2vec_generative}

\btv{} is a recently described \textit{multi-entity} Transformer that can model sequences of \textit{sets} (the underlying data structure for multi-agent spatiotemporal systems), as opposed to sequences of individual inputs (like words in a sentence).
When used to model the game of basketball, the input at each time step for \btv{} is a set of feature vectors where each feature vector contains information about the identity and location of a player on the court.
\btv{} maps each input feature vector to an output feature vector, which is then used to ``classify'' the binned trajectory for that specific player at that specific time step.

Here, we provide a probabilistic interpretation of \btv{}, which establishes the theoretical grounds for using the chain rule to generate trajectories agent-wise at each time step in \btvpp{}.
Without loss of generality, we only consider one-dimensional trajectories for a single agent here.
To briefly summarize, the outputs of the softmax function over the  binned trajectories in \btv{} can be interpreted as mixture proportions for a mixture of uniform distributions with predetermined bounds that partition the Euclidean trajectory space.
Further, because , \btv{} is in fact a conditional generative model that assigns a probability to a sequence of trajectories given the initial position of the agent, i.e., .
Using the chain rule, we decompose the joint probability of the trajectories as:



\noindent
to reflect their temporal structure (we omit the conditional initial position term for brevity).
Therefore, new trajectories can be generated from \btv{} with the following procedure (see Figure \ref{fig:graphical_model}):

\begin{enumerate}
    \item First, sample one of the  different mixture components using the mixture proportions output from the classifier  (i.e., \btv{}) conditioned on the agent's current position, i.e.,  where .
    \item Next, sample a trajectory from the uniform distribution associated with the sampled component, i.e., .
    \item Finally, add the sampled trajectory to the agent's input position to generate the agent's position at the start of the next time step, i.e., .
\end{enumerate}

\begin{wrapfigure}{r}{0.5\linewidth}
\vskip -0.2in
\includegraphics[width=\linewidth]{graphical_model_tight}
\caption{
\btv{} can be viewed as a conditional generative model that assigns a probability to a sequence of trajectories given the initial positions of the agents.
Here, we show a graphical model depiction of a \btv{} model that generates a sequence of one-dimensional trajectories for a single agent.
Given the initial position of the agent (the circle containing ), one of  different uniform distributions (the square containing ) is sampled using the mixture proportions () output by \btv{} ().
The agent's trajectory (the diamond containing ) is then sampled from the selected uniform distribution, which has bounds .
At the start of the next time step, the agent's position is .
Maximizing the likelihood of \btv{} as a classifier over the binned trajectories is thus equivalent to maximizing its likelihood when assuming the trajectories are generated from a mixture of uniform distributions that partition the Euclidean trajectory space (see Section \ref{sec:baller2vec_generative} for details).
}
\label{fig:graphical_model}
\end{wrapfigure}
Let  be an interval on the real line such that any trajectory  or  has zero density (i.e., such trajectories are humanly impossible).
Let  be a set of  intervals that partition the interval  into  bins, i.e.,  and .
Recall that the probability density function (PDF) for a uniform distribution with bounds  is:



\noindent
Letting , the PDF for a mixture of uniforms with these bounds is thus:



\noindent
where  is the density assigned to  by the mixture,  is the mixture proportion for the mixture component indexed by  (i.e.,  and ), and  is the density assigned to  by the uniform distribution with bounds .
Because the bounds of the uniform distributions partition , Equation \eqref{eq:mix_uniforms} reduces to:



\noindent
where  (because the other uniform distributions will assign a density of zero to ).
The likelihood for data  (with ) is then:



\noindent
where  is the mixture proportion assigned to the component with   and  is the associated density.
Taking the negative logarithm of the likelihood gives:



\noindent
Because the bounds are fixed, the second summation is a constant, and Equation \eqref{eq:mixture_nll} becomes:



\noindent
where .
Therefore, minimizing the loss of \btv{} as a classifier of binned trajectories is equivalent to minimizing the loss of the model when assuming the trajectories are generated from a mixture of uniform distributions as specified in Equation \eqref{eq:mix_uniforms}.