[{'LEADERBOARD': {'Task': '3D Question Answering (3D-QA)', 'Dataset': 'ScanQA Test w/ objects', 'Metric': 'Exact Match', 'Score': '23.2'}}, {'LEADERBOARD': {'Task': '3D Question Answering (3D-QA)', 'Dataset': 'ScanQA Test w/ objects', 'Metric': 'BLEU-1', 'Score': '32.6'}}, {'LEADERBOARD': {'Task': '3D Question Answering (3D-QA)', 'Dataset': 'ScanQA Test w/ objects', 'Metric': 'BLEU-4', 'Score': '8.4'}}, {'LEADERBOARD': {'Task': '3D Question Answering (3D-QA)', 'Dataset': 'ScanQA Test w/ objects', 'Metric': 'ROUGE', 'Score': '34.8'}}, {'LEADERBOARD': {'Task': '3D Question Answering (3D-QA)', 'Dataset': 'ScanQA Test w/ objects', 'Metric': 'METEOR', 'Score': '13.5'}}, {'LEADERBOARD': {'Task': '3D Question Answering (3D-QA)', 'Dataset': 'ScanQA Test w/ objects', 'Metric': 'CIDEr', 'Score': '65.6'}}, {'LEADERBOARD': {'Task': '3D Question Answering (3D-QA)', 'Dataset': 'ScanQA Test w/ objects', 'Metric': 'Exact Match', 'Score': '19.1'}}, {'LEADERBOARD': {'Task': '3D Question Answering (3D-QA)', 'Dataset': 'ScanQA Test w/ objects', 'Metric': 'BLEU-1', 'Score': '38.3'}}, {'LEADERBOARD': {'Task': '3D Question Answering (3D-QA)', 'Dataset': 'ScanQA Test w/ objects', 'Metric': 'BLEU-4', 'Score': '11.6'}}, {'LEADERBOARD': {'Task': '3D Question Answering (3D-QA)', 'Dataset': 'ScanQA Test w/ objects', 'Metric': 'ROUGE', 'Score': '35.3'}}, {'LEADERBOARD': {'Task': '3D Question Answering (3D-QA)', 'Dataset': 'ScanQA Test w/ objects', 'Metric': 'METEOR', 'Score': '14.9'}}, {'LEADERBOARD': {'Task': '3D Question Answering (3D-QA)', 'Dataset': 'ScanQA Test w/ objects', 'Metric': 'CIDEr', 'Score': '69.6'}}, {'LEADERBOARD': {'Task': '3D Question Answering (3D-QA)', 'Dataset': 'ScanQA Test w/ objects', 'Metric': 'BLEU-1', 'Score': '37.3'}}, {'LEADERBOARD': {'Task': '3D Question Answering (3D-QA)', 'Dataset': 'ScanQA Test w/ objects', 'Metric': 'BLEU-4', 'Score': '10.7'}}, {'LEADERBOARD': {'Task': '3D Question Answering (3D-QA)', 'Dataset': 'ScanQA Test w/ objects', 'Metric': 'ROUGE', 'Score': '34.5'}}, {'LEADERBOARD': {'Task': '3D Question Answering (3D-QA)', 'Dataset': 'ScanQA Test w/ objects', 'Metric': 'METEOR', 'Score': '14.3'}}, {'LEADERBOARD': {'Task': '3D Question Answering (3D-QA)', 'Dataset': 'ScanQA Test w/ objects', 'Metric': 'CIDEr', 'Score': '67.1'}}]
