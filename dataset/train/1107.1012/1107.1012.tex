\documentclass[11pt]{article}
\usepackage{latexsym}
\usepackage{tabularx,booktabs,multirow,delarray,array}
\usepackage{graphicx,amssymb,amsmath,amssymb,mathrsfs}


\aboverulesep=0pt
\belowrulesep=0pt

\oddsidemargin=0.0in
\evensidemargin=0.0in
\headheight=0.0in
\topmargin=-0.40in \textheight=9.0in \textwidth=6.5in   

\newenvironment{proof}{\noindent {\textbf{Proof:}}\rm}{\hfill 
\rm}

\def\calA{\mathcal{A}}

\newtheorem{Theo}{Theorem}
\newtheorem{Lem}{Lemma}
\newtheorem{Coro}{Corollary}
\newtheorem{Def}{Definition}
\newtheorem{Obs}{Observation}
\newcounter{fignumb}

\begin{document}

\baselineskip=14.0pt

\title{
\vspace*{-0.55in}
Optimal Point Movement for Covering Circular Regions
}



\author{
Danny Z. Chen\thanks{Dept.~of Computer Science and Engineering,
University of Notre Dame, Notre Dame, IN 46556, USA; { \{dchen,
hwang6\}@nd.edu.} These authors' work was supported in part by NSF
under Grant CCF-0916606. } \hspace*{0.1in} Xuehou Tan\thanks{Tokai
University, 4-1-1 Kitakaname, Hiratsuka 259-1292, Japan; {
tan@wing.ncc.u-tokai.ac.jp}.} \hspace*{0.1in} Haitao
Wang\footnotemark[1]  \thanks{Corresponding author.} \hspace*{0.1in}
Gangshan Wu\thanks{State Key Lab.~for Novel Software Technology,
Nanjing University, Nanjing 210093, China; {
gswu@graphics.nju.edu.cn}.}}

\date{ }
\maketitle

\pagestyle{plain}
\pagenumbering{arabic}
\setcounter{page}{1}


\vspace*{-0.3in}
\begin{abstract}
Given  points in a circular region  in the plane, we study the problems of
moving the  points to its boundary to form a regular -gon such that
the maximum (min-max) or the sum (min-sum) of the Euclidean
distances traveled by the points is minimized. The problems have
applications, e.g., in mobile sensor barrier coverage of wireless
sensor networks.
The min-max problem further has two versions: the decision version and optimization
version. For the min-max problem, we present an  time
algorithm for the decision version and an  time algorithm for
the optimization version. The
previously best algorithms for the two problem versions take  time
and  time, respectively. For the min-sum problem,
we show that a special case with all points initially lying on the
boundary of the circular region can be solved in  time,
improving a previous  time solution. For the general
min-sum problem, we present a -approximation  time
algorithm, improving the previous -approximation  time algorithm.
A by-product of our techniques is an algorithm for dynamically
maintaining the maximum matching of a circular convex bipartite
graph; our algorithm can handle each vertex insertion or deletion on
the graph in  time. This result is interesting in its
own right.
\end{abstract}


\section{Introduction}

Given  points in a circular region  in the plane, we study the problems of
moving the  points to its boundary to form a regular -gon such that
the maximum (min-max) or the sum (min-sum) of the Euclidean
distances traveled by the points is minimized. The problems have
applications, e.g., in mobile sensor barrier coverage of wireless
sensor networks. The problems have
been studied before. In this paper we present new algorithms that significantly
improve the previous solutions for the problems.

\subsection{Problem Definitions}

Let  denote the Euclidean length of the line segment with two
endpoints  and  in the plane. Let  be a circular region in
the plane. Given a set of  points  in
 (i.e., in its interior or on its boundary), we wish to move all sensors to
 points  on the boundary of  that
form a regular -gon. The {\em min-max} problem aims to minimize
the maximum Euclidean distance traveled by all points, i.e.,
. The {\em min-sum}
problem aims to minimize the sum of the Euclidean distances traveled
by all points, i.e., .

Further, given a value , the {\em decision version} of
the min-max problem is to determine whether it is possible to move all points in
 to the boundary of  to form a regular -gon such that the distance
traveled by each point is no more than . Indeed,
let  be the maximum distance traveled by the points in
an optimal solution for the min-max problem. Then, the answer to the
feasibility problem is ``yes" if and only if . For discrimination, we refer to the original min-max
problem as the {\em optimization version} of the min-max problem.

For the min-sum problem, if the points in  are given initially all lying on the
boundary of , then this case is referred to as the {\em boundary
case} of the min-sum problem.

\subsection{Applications in Wireless Sensor Networks}

A Wireless Sensor Network (WSN) is composed of a large number of
sensors which monitor some surrounding environmental phenomenon.
Usually, the sensors are densely deployed either inside the target phenomenon or
are very close to it \cite{ref:AkyildizWi02}. Each sensor
is equipped with a sensing device
with limited battery-supplied energy.
The sensors process data obtained and forward the data to a base station.
A typical type of WSN applications
is concerned with security and safety systems, such as detecting intruders
(or movement thereof) around infrastructure facilities and regions. Particularly,
it is often used to monitor a protected area so as to detect intruders
as they penetrate the area or as they cross the area border. For example, research
efforts have been under way to extend the scalability of wireless sensor networks
to the monitoring of international borders \cite{ref:Hu08,ref:KumarBa07}.

The study of {\it barrier coverage} using mobile sensors was originated
in \cite{ref:ChenDe07,ref:KumarBa07} and later in \cite{ref:BhattacharyaOp09}.
Different from the traditional concept of {\it full coverage},
it seeks to cover the deployment region by guaranteeing that there is no
path through the region that can be traversed undetectedly by an intruder,
i.e., all possible crossing paths through the region
are covered by the sensors \cite{ref:BhattacharyaOp09,ref:ChenDe07,ref:KumarBa07}.
Hence, an interesting problem is
to reposition the sensors quickly so as to repair the existing security hole and
thereby detect intruders \cite{ref:BhattacharyaOp09}. Since barrier coverage
requires fewer sensors for detecting intruders, it gives a good
approximation of full area coverage. The planar region on which the sensors move
is sometimes represented by a circle.
Since sensors have limited battery-supplied energy, we wish
to minimize their movement. Thus, if each sensor is
represented as a point, the problem is exactly our optimal point
movement min-max (the optimization version) or min-sum problem.
Further, if each sensor has energy  and we want to determine
whether this level of energy is sufficient to form a barrier coverage,
then the problem becomes the decision version of the min-max problem.





\subsection{Previous Work and Our Results}

For the min-max problem, Bhattacharya {\em et al.}~\cite{ref:BhattacharyaOp09}
proposed an  time algorithm
for the decision version and an  time algorithm
for the optimization version, where the decision algorithm is
based on some observations and brute force and the optimization
algorithm is based on parametric search approach
\cite{ref:ColeSl87,ref:MegiddoAp83}.
Recently, it was claimed in \cite{ref:TanNe10} that these two
problem versions were solvable in  time and
 time, respectively. However, it seems that the
announced algorithms in \cite{ref:TanNe10} contain errors (which
might be fixed, say, by using the methods given in this paper).
In this paper, we solve the decision version in  time and the
optimization version in  time, which significantly
improve the previous results. The improvements of our algorithms are
based on new observations and interesting techniques.


A by-product of our techniques that is interesting in its own right
is an algorithm for dynamically maintaining the maximum matchings of
{\em circular convex bipartite graphs}. Our
algorithm handles each (online) vertex insertion or deletion on
an -vertex circular convex bipartite graph in  time.
This matches the performance of the best known
dynamic matching algorithm for {\em convex bipartite graphs}
\cite{ref:BrodalDy07}. Note that convex bipartite graphs are a subclass of
circular convex bipartite graphs \cite{ref:LiangCi95}.  To our best knowledge,
no dynamic matching algorithm for circular convex bipartite graphs was known before.
Since dynamically maintaining the maximum
matching of a graph is a basic problem, our result
may find other applications.



For the min-sum problem, an  time approximation algorithm with approximation
ratio  was given in \cite{ref:BhattacharyaOp09}. A PTAS approximation
algorithm, which has a substantially larger polynomial time bound,
was also given in \cite{ref:BhattacharyaOp09}. In this paper,
we present an  time approximation algorithm with approximation
ratio , which improves the -approximation result in
\cite{ref:BhattacharyaOp09}. However, whether the general min-sum problem is
NP-hard is still left open.

For the boundary case of the min-sum problem, an  time
(exact) algorithm was given in \cite{ref:TanNe10}. We show that the
time bound of that algorithm can be reduced to .

The rest of this paper is organized as follows. Our algorithm for the
decision version of the min-max problem is given in Section
\ref{sec:decision}, and our algorithm for the optimization version
is presented in Section \ref{sec:optimization}. The min-sum problem
is discussed in Section \ref{sec:minsum}.

To distinguish from a normal point in the plane, in the following
paper we refer to each
point  as a sensor.

\section{The Decision Version of the Min-max Problem}
\label{sec:decision}

For simplicity, we assume the radius of the circle  is . Denote by
 the boundary of . Let  be the
maximum distance traveled by the sensors in  in an optimal solution for
the min-max problem, i.e., . Since the sensors are all in , .
In this section, we consider the decision version of the min-max
problem on : Given a value , determine whether . We present an  time algorithm for this problem.

\subsection{An Algorithm Overview}

We first discuss some concepts. A
{\it bipartite} graph  with  and  is
{\it convex} on the vertex set  if there is a linear ordering
on , say, , such that if any two
edges  and  with ,
, and , then  for all . In other words, for any vertex , the subset of
vertices in  connected to  forms an interval on the linear
ordering of . For any , suppose the subset of vertices
in  connected to  is ; then we denote
 and . Although  may have 
edges, it can be represented implicitly by specifying  and
 for each .  A {\em vertex insertion} on  is
to insert a vertex  into  with an edge interval
 and implicitly connect  to every  with . Similarly, a {\em vertex
deletion} on  is to delete a vertex  from  as well as all its
adjacent edges.

A bipartite graph  is {\it circular convex} on
the vertex set  if there is a circular ordering on  such
that for each vertex , the subset of vertices in 
connected to  forms a circular-arc interval on that ordering. Precisely,
suppose such a {\em clockwise} circular ordering of  is .
For any two edges  and  with
, , and , either
 for all , or  for all  and  for all . For
each , suppose the vertices of  connected to  are
from  to  clockwise on the ordering, then  and
 are defined to be  and , respectively.
Vertex insertions and deletions on  are defined similarly.




A maximum matching in a convex bipartite graph can be found in
 time \cite{ref:GabowA85,ref:LipskiEf81,ref:SteinerA96}. The
same time bound holds for a circular convex bipartite graph
\cite{ref:LiangCi95}. Brotal {\em et al.}~\cite{ref:BrodalDy07} designed
a data structure for dynamically maintaining the maximum matchings of
a convex bipartite graph that can support each vertex insertion or
deletion in  amortized time. For circular convex
bipartite graphs, however, to our best knowledge, we are not aware of
any previous work on dynamically maintaining their maximum matchings.

The main idea of our algorithm for the decision version of the
min-max problem is as follows. First, we model the problem as
finding the maximum matchings in a sequence of  circular convex
bipartite graphs, which is further modeled as dynamically
maintaining the maximum matching of a circular convex bipartite
graph under a sequence of  vertex insertion and deletion operations.
Second, we develop an approach for solving the latter problem.
Specifically, we show that the maximum matching of a circular convex
bipartite graph of  vertices can be dynamically maintained in  time
(in the worst case) for each vertex insertion or deletion. Note that
this result is of independent interest.



In the following, we first present the problem modeling and then
give our algorithm for dynamically maintaining the maximum matching of
a circular convex bipartite graph.

\subsection{The Problem Modeling}
\label{subsec-model}

Recall that in the decision version of the min-max problem,
our goal is to determine whether . Let  be an arbitrary regular -gon with its vertices
 ordered clockwise on . We first
consider the following sub-problem: Determine whether we can move all sensors to
the vertices of  such that the maximum distance traveled by the
sensors is at most . Let  be the bipartite graph
between the sensors  and the vertices of ,
such that a sensor  is connected to a vertex  in  if and only
if .  The next lemma is immediate.
\begin{Lem}\label{lem:cir-conv}
The bipartite graph  is circular convex.
\end{Lem}
\begin{proof}
This simply follows from the fact that the boundary of any circle of radius 
can intersect  at most twice.
\end{proof}

To solve the above sub-problem, it suffices to compute a maximum matching 
in the circular convex bipartite graph  (by using the algorithm
in \cite{ref:LiangCi95}). If  is a
perfect matching, then the answer to the sub-problem is ``yes";
otherwise, the answer is ``no". Thus, the sub-problem can be solved in
 time (note that the graph  can be constructed implicitly
in  time, after  time preprocessing).
If the answer to the sub-problem is ``yes", then we say
that  is {\em feasible} with respect to the value .

If  is feasible, then clearly .
If  is not feasible, however,  does not necessarily hold,
because  may not be positioned ``right" (i.e.,  may not be the regular
-gon in an optimal solution of
the optimization version of the min-max problem). To further
decide whether , our strategy is to rotate
 clockwise on  by an arc distance at most .
Since the perimeter of  is , the arc distance
between any two neighboring vertices of  is . A simple
yet critical observation is that  if and only
if during the rotation of , there is a moment (called a {\em
feasible moment}) at which 
becomes feasible with respect to . Thus, our task is to determine whether a feasible moment exists
during the rotation of .

Consider the graph . For each sensor , denote by
 the subset of vertices of  connected to
 in , where the indices of the vertices of  are
taken as module by . We assume that  does not contain all
vertices of  (otherwise, it is trivial). Since the arc distance
from  to  is , during the (clockwise) rotation
of , there must be a moment after which  becomes connected to
, and we say that  is {\em added} to ; similarly,
there must be a moment after which  becomes disconnected to ,
and we say that  is {\em removed} from .
Note that these are the moments when the edges of  (and thus the graph )
are changed due to the rotation of .  Also, note that during the rotation, all
vertices in  remain connected to  and
all vertices in  remain
disconnected to . Hence throughout this rotation,
there are totally  additions and  removals on the graph .
If we sort all these additions and removals based on the time
moments when they occur, then we obtain a sequence of  circular
convex bipartite graphs, and determining whether there exists a
feasible moment is equivalent to determining whether there is a graph
in this sequence that has a perfect matching. With the  time maximum matching
algorithm for circular convex bipartite graphs of  vertices in
\cite{ref:LiangCi95}, a straightforward solution for determining whether there
is a feasible moment would take  time.

To obtain a faster algorithm, we further model the problem as follows.
Consider the addition of  to . This can be done
by first deleting the vertex of  corresponding to  and
then inserting a new vertex corresponding to  with its edges connecting
to the vertices in .
The removal of  from  can be handled similarly. Thus,
each addition or removal on  can be transformed to one vertex
deletion and one vertex insertion on . If we sort all vertex
updates (i.e., insertions and deletions) by the time moments when
they occur, then the problem of determining whether there is a feasible moment is
transformed to determining whether there exists a perfect matching
in a sequence of vertex updates on the graph . In other words, we need to
dynamically maintain the maximum matching in a circular convex
bipartite graph to support a sequence of  vertex insertions and
 vertex deletions.  This problem is handled in the next
subsection.

\subsection{Dynamic Maximum Matching in a Circular Convex Bipartite Graph}

In this subsection, we consider the problem of dynamically maintaining the
maximum matching in a circular convex bipartite graph to support vertex
insertions and deletions. We treat all vertex updates in an online fashion.

Let  with  and  be a circular convex
bipartite graph on the vertex set , i.e., the vertices of 
connected to each vertex in  form a circular-arc interval on the
sequence of the vertex indices of . Suppose
 is ordered clockwise. Recall that a
vertex insertion on  is to insert a vertex  into  with an edge interval
 such that  is (implicitly) connected to all
vertices of  from  clockwise to .
A vertex deletion is to delete a
vertex  from  and all its adjacent edges (implicitly).  Our
task is to design an algorithm for maintaining the maximum matching of
 to support such update operations (i.e., vertex insertions and
deletions) efficiently. Below, we present an algorithm with an  time per
update operation.


Our approach can be viewed as a combination of the data structure in
\cite{ref:BrodalDy07} for dynamically maintaining the maximum
matching in a convex bipartite graph and the linear time algorithm
in \cite{ref:LiangCi95} for computing a maximum matching in a
circular convex bipartite graph. We refer to them as the BGHK data
structure \cite{ref:BrodalDy07} and the LB algorithm
\cite{ref:LiangCi95}, respectively. We first briefly describe
the BGHK data structure and the LB algorithm.

The BGHK data structure \cite{ref:BrodalDy07} is a binary tree ,
and each node of  maintains a balanced binary tree. This data structure
can be constructed in  time and can
support each vertex insertion or deletion in  amortized time.
Consider a vertex insertion, i.e., inserting a vertex  into . Let
 (resp., ) be the maximum matching in the graph before
(resp., after) the insertion. Let  denote the number of matched
pairs in .  After the data structure is updated (in 
amortized time), the value  can be reported in  time
and  can be reported in  time. We can also determine in
 time whether  is matched in . Further, if another
vertex  was matched in  but is not matched in ,
then it is easy to see that  must be matched in . When this
case occurs, we say that  {\em replaces}  and  is called
the {\em replacement}, and the data structure is able to report the
replacement in  time. Note that as shown in
\cite{ref:BrodalDy07}, although an update on the graph can cause
dramatic changes on the maximum matching, the sets of the
matched vertices in  (and ) can change by at most one
vertex. Thus, there is at most one such replacement .  Similarly,
consider deleting a vertex  from . After the data structure
is updated, the value  can be reported in  time and 
can be reported in  time. We can also find out whether  was
matched in  in  time. If a vertex  was not
matched in  but is matched in ,
then it is easy to see that  must be matched in . When this
case occurs, we say  is the {\em
supplement}, which can be determined in  time.


The LB algorithm \cite{ref:LiangCi95} finds a maximum matching in
a circular convex bipartite graph  by reducing the
problem to two sub-problems of computing the maximum matchings in two
convex bipartite graphs  and . Some details are summarized
below. For any vertex , if , then
 is called a {\em non-boundary} vertex. Otherwise,  is a {\em
boundary} vertex; the edges connecting  to
 in  are called {\em lower
edges}, and the other edges connecting  are {\em upper edges}.
Based on the graph , a convex bipartite graph
 is defined as follows. Both its vertex sets are
the same as those in . For each vertex  in ,
; if  is a non-boundary vertex,
then , and otherwise  (note
that this value of  is used only for comparison in the algorithm
although there are not so many vertices in ). The LB
algorithm has two main steps. The first step is to compute a
maximum matching in , which can be done in  time
\cite{ref:GabowA85,ref:LipskiEf81,ref:SteinerA96}. Let  be
the maximum matching of . Next, another convex
bipartite graph  is defined based on  and , as
follows. Both its vertex sets are the same as those in . For each
non-boundary vertex  in ,  and
. For each boundary vertex  in ,
there are two cases: If  is matched in , then
 and ; otherwise,
 and . The second step of the LB
algorithm is to compute a maximum matching in  (in 
time), denoted by . It was shown in \cite{ref:LiangCi95}
that  is also a maximum matching of the original graph .




We now discuss our algorithm for dynamically maintaining a
maximum matching in the circular convex bipartite graph . As
preprocessing, we first run the LB algorithm on , after which
both the convex bipartite graphs  and  of  are
available. We then build two BGHK data structures for  and
, denoted by  and , respectively, for
maintaining their maximum matchings. This completes the preprocessing,
which takes  time. In the following, we discuss how to perform
vertex insertions and deletions.

Consider a vertex insertion, i.e., inserting a vertex  into  with the edge
interval , . To perform this insertion, intuitively, we need to
update the two BGHK data structures  and  in a way that mimics some
behavior of the LB algorithm. Specifically, we first insert  into the graph
 by updating . Based on the results on 
(e.g., whether there is a replacement) and the behavior of the LB algorithm,
we modify  by updating  accordingly.
In this way, the maximum matching maintained by
 is the maximum matching of  after the insertion.
The details are given below.

Let  and  be the two graphs
that would be produced by running the LB algorithm on  with the new vertex 
(and its adjacent edges). Let , and  be the maximum
matchings of , and , respectively.
Depending on whether  is a boundary
vertex, there are two main cases.

\begin{itemize}
\item
If  is a non-boundary vertex (i.e., ), then
 can be obtained by inserting  into . Hence we insert  into
. Depending on whether there is a replacement, there are two
cases.

\begin{itemize}
\item
If no replacement, then  can be obtained by inserting 
into . Thus, we simply insert  into  and we
are done.

\item
Otherwise, let  be the replacement. So  was matched in
 but is not matched in .
Depending on whether  is a boundary vertex, there are two
subcases.

\begin{itemize}
\item
If  is a non-boundary vertex, then again,  can be obtained
by inserting  into . We thus insert  into  and we
are done.


\item
If  is a boundary vertex, then
since  was matched in , according to the LB algorithm,
 with the edge interval  is in .
After the insertion of  into ,  is not matched in .
Thus, according to the LB algorithm,  can be obtained by
deleting  (with the edge interval ) from , inserting
 with the edge interval  into , and finally inserting  into .

In summary, for this subcase, we delete  (with the edge interval
) from  and insert
 with the edge interval  into .
Finally, we insert  into , and we are done.
\end{itemize}
\end{itemize}

\item
If  is a boundary vertex (i.e., ),
then according to the LB algorithm,  can be obtained by
inserting  with the edge interval  into .
Thus we insert  with the edge interval  into .
Depending on whether there is a replacement, there are two
cases.

\begin{itemize}
\item
If no replacement, then depending on whether  is matched in ,
there are two subcases.

\begin{itemize}
\item
If  is matched, then according to the LB algorithm,  can be
obtained by inserting  with the edge interval  into . Thus,
we insert  with the edge interval  into , and we are
done.

\item
If  is not matched, then according to the LB algorithm,  can be
obtained by inserting  with the edge interval  into .
We thus insert  with the edge interval  into , and we are done.

\end{itemize}

\item
Otherwise, there is a replacement . So 
was matched in  but is not matched in , and  is
matched in . Depending on whether  is a boundary vertex, there are two
subcases.

\begin{itemize}
\item
If  is a non-boundary vertex, then since  is
matched in ,  can be
obtained by inserting  with the edge interval  into .
We thus insert  with the edge interval  into .


\item
If  is a boundary vertex, then according to the LB algorithm,
 is the graph obtained by deleting  (with the edge interval
) from , inserting  with the edge interval  into
, and finally inserting  with the edge interval  into .

Thus, we delete  (with the edge interval ) from , and insert
 with the edge interval  into .
Finally, we insert  with the edge interval  into .
\end{itemize}

\end{itemize}
\end{itemize}

This completes the description of our procedure for handling a vertex insertion.

Next, consider a vertex deletion, i.e., deleting a vertex  from  of
. Our procedure for this operation proceeds in a manner symmetric to the insertion
procedure, and we briefly discuss it below. Define the two graphs  and  similarly as above.

\begin{itemize}
\item If  is a non-boundary vertex, then we delete  from
. If no supplement, then we delete  from  and we
are done. Otherwise, let  be the supplement. So  was not
matched in  but is matched in .
Depending on whether  is a boundary vertex, there are two cases.

\begin{itemize}
\item If  is a non-boundary vertex, then we delete  from
 and we are done.

\item If  is a boundary vertex, then we delete  with the edge interval
 from  and insert  with the edge interval
 into
. Finally, delete  from , and we are done.

\end{itemize}

\item If  is a boundary vertex, then we delete  (with the edge interval
) from . Depending on whether there is
a supplement, there are two cases.

\begin{itemize}
\item
If no supplement, then depending on whether  was matched in
, there are two subcases. If  was matched, then we
delete  (with the edge interval ) from ;
otherwise, we delete  (with the edge interval ) from .


\item Otherwise, let  be the supplement.
So  was not matched in  but is matched in , and
 was matched in .
Since  was matched in , according to the LB algorithm,
 contains  with the edge interval .
If  is a non-boundary vertex, then we delete  (with the edge interval
) from  and we are done.
Otherwise, since  was not matched in , according to the LB
algorithm,  contains  with the edge interval ;
since  is matched in , according to the LB
algorithm,  should contain  with the edge interval
. Therefore,
we delete  (with the edge interval ) from ,
insert  with the edge interval  into , and finally
delete  (with the edge interval ) from .
\end{itemize}
\end{itemize}

This completes the description of our vertex deletion procedure.

As shown in Subsection \ref{subsec-model}, the decision version of the min-max problem
can be transformed to the problem of dynamically maintaining the maximum matching
in a circular convex bipartite graph subject to a sequence of vertex insertions and deletions.
Hence, the correctness of our algorithm for the decision version hinges on the correctness
of our dynamic maximum matching algorithm for circular convex bipartite graphs.
Yet, the correctness of our (online) dynamic maximum matching algorithm for circular
convex bipartite graphs can be seen quite easily. This is because our procedures
for performing vertex insertions and deletions are both based on the fact that
they simply mimic the behavior of the LB algorithm (while
implementing their processing by the means of the BGHK data structures).

For the running time of our algorithm, each update operation involves
at most two vertex insertions and two vertex deletions on  and
, each of which takes  amortized time
\cite{ref:BrodalDy07}; thus, it takes  amortized time in total.
Actually, the BGHK data structure in \cite{ref:BrodalDy07} supports
vertex insertions and deletions not only on  but also on .
Inserting vertices on  may make the tree unbalanced, and that is why its
running time is amortized. However, if vertices are inserted only on
, then the tree will never become unbalanced and thus each update takes 
time in the worst case. In our
problem formulation, the vertex updates indeed are only on .
Denote by  the maximum matching in . We then have the following result.


\begin{Theo}\label{theo:10}
A data structure on a circular convex bipartite graph
 can be built in  time for
maintaining its maximum matching  so that each online
vertex insertion or deletion on  can be done in  time in the
worst case. After each update operation,  can be reported in
 time and  can be reported in  time.
\end{Theo}

Since the decision version of the min-max problem
has been reduced to dynamically maintaining the maximum matching
in a circular convex bipartite graph
under a sequence of  vertex insertions and  vertex decisions,
we solve the dynamic maximum problem as follows.  After each update
operation, we check whether , and if this is true, then we report
 and halt the algorithm. If all  updates have
been processed but it is always , then we report
.  Based on Theorem \ref{theo:10}, we have the result below.

\begin{Theo}\label{theo:20}
Given a value , we can determine whether
 in  time for the decision version
of the min-max problem.
\end{Theo}

\section{The Optimization Version of the Min-max Problem}
\label{sec:optimization}

In this section, we consider the optimization version of the min-max
problem, and present an  time algorithm for it.
The main task is to compute the value .

Let  be the center of . For simplicity of discussion, we assume that no sensor
lies at .
Denote by  and  the two points on  which are closest
and farthest to each sensor , respectively.
Clearly,  and  are the two intersection
points of  with the line passing through  and the center 
of  (see Figure 1(a)). The lemma below has been proved in
\cite{ref:TanNe10}, and for self-containment of this paper, we include that proof in
Appendix \ref{app:lemmaproofs}.

\begin{figure}[t]
\begin{center}
\includegraphics[height=1.3in,clip]{Barrier1.eps}
\caption{(a) The points  and  on  for ;
(b) .}
\end{center}
\vspace*{-0.2in}
\end{figure}


\begin{Lem}\label{lem:10}\cite{ref:TanNe10}
Suppose an optimal solution for the min-max optimization problem is achieved
with  for some . Then either  is the point , or there is
another sensor  () such that  also holds. In the latter case, any slight rotation of the
regular -gon that achieves  in either direction
causes the value of  to increase (i.e., it makes one of the two
distances  and  increase and the other one decrease).
\end{Lem}

The points on  satisfying the conditions specified in
Lemma \ref{lem:10}
may be considered as those defining candidate values for ,
i.e., they can be considered as some vertices of possible regular
-gons on  in an optimal solution. The points 
of all sensors  () can be easily determined.
Define , which can be computed in
 time. But, the challenging task is to handle all the pairs
 () such that the distance from  to a
vertex of a regular -gon is equal to the distance from  to
another vertex of that -gon and a slight rotation of the -gon
in either direction monotonically increases one of these two
distances but decreases the other. We refer to such distances as the
{\it critical equal distances}. Denote by  the set of all critical equal
distances. Let . By Lemma \ref{lem:10}, . Thus, if  is somehow available, then  can be
determined by using our algorithm in Theorem \ref{theo:20} in a binary search process. Since
 is readily available, the key is to deal with 
efficiently. An easy observation is .
We can use the algorithm in Theorem \ref{theo:20} to check whether
, after which we know
whether . Below, we assume
 (otherwise, we are
done). Thus, we only need to focus on finding  from the set .




It has been shown in \cite{ref:TanNe10} that .
Of course, our goal is to avoid an  time solution.
To do so, first we determine a subset  of  such that
 but with .
Furthermore, we do not compute  explicitly. Specifically, our
idea is as follows. We show that the elements of  are the
-coordinates of a subset of intersection points among a set  of 
functional curves in the plane such that each curve is -monotone and any two
such curves intersect in at most one point at which the two curves cross
each other. (Such a set of curves is sometimes referred to as
{\em pseudolines} in the literature.) Let  be the arrangement
of  and  be the number of vertices of . Without
computing  explicitly, we will generalize the techniques in
\cite{ref:ColeAn89} to compute the -th highest vertex of
 for any integer  with  in
 time. Consequently, with Theorem \ref{theo:20}, the
value  can be computed in  time. The
details are given below.







Let  be an arbitrary regular -gon with its vertices ,
, ,  clockwise on . Suppose the
distances of all the pairs between a sensor and a vertex of  are  in sorted order. Let .
Clearly,  (the case of  is
trivial). Hence, there exists an integer  with  such
that . One can find  and 
by first computing all these  distances explicitly and then utilizing
our algorithm in Theorem \ref{theo:20} in a binary search process.
But that would take 
time. In the following lemma, we give a faster procedure without
having to compute these  distances explicitly.

\begin{Lem}\label{lem:new20}
The two distances  and 
can be obtained in  time.
\end{Lem}
\begin{proof}
We apply a technique, called {\em binary search in sorted arrays}
\cite{ref:ChenRe11},
as follows. Given  arrays , , each containing
 elements in sorted order, the task is to find a certain element . Further, assume that there is a ``black-box"
decision procedure  available, such that given any value ,
 reports  or  in  time. An
algorithm is given in \cite{ref:ChenRe11} to find the sought element
 in  in 
time. We use this technique to find  and , as follows.

Consider a sensor . Let  be the set of distances
between  and all vertices of . In  time, we can
implicitly partition  into two sorted arrays in the
following way. By binary search, we can determine an index  such
that  lies on the arc of  from  to 
clockwise (the indices are taken as module by ). Recall that
 is the point on  closest to . If a vertex of
 is on , then define  to be the index of that vertex.
Similarly, we can determine an index  such that  (i.e., the
farthest point on  to ) lies on the arc from 
to  clockwise. If a vertex of  is on , then define
 to be the index of that vertex. Both  and  can be
determined in  time, after which we implicitly
partition  into two sorted arrays: One array consists of all
distances from  to , and the other
consists of all distances from  to
 (again, all indices are taken as
module by ). Note that both these arrays are sorted increasingly and
each element in them can be obtained in  time by using its index in
the corresponding array.

Thus, we obtain  sorted arrays (represented implicitly) for all  sensors in
 time, and each array has no more than  elements.
Therefore, by using the technique of binary search in sorted arrays, with
our algorithm in Theorem \ref{theo:20} as the black-box decision
procedure, both  and  can be found in 
time. The lemma thus follows.
\end{proof}

By applying Lemma \ref{lem:new20}, we have .
Below, for simplicity of discussion, we assume .
Thus . Since
,
we redefine .
We still have .
Let  be the set of all
critical equal distances in the range . Then . We
show below that  and  can be found in
 time without computing  explicitly.



Suppose we rotate the regular -gon  on
 clockwise by an arc distance  (this is the arc
distance between any two adjacent vertices of ). Let
 denote the distance function from a sensor  to a
vertex  of  with the time parameter  during
the rotation. Clearly, the function  increases or
decreases monotonically, unless the interval of  in
which  moves contains the point  or ; if that interval
contains  or , then we can further divide the interval
into two sub-intervals at  or , such that
 is monotone in each sub-interval.
The functions , for all 's of , can thus be
put into two sets  and  such that all functions
in  monotonically increase and all functions in 
monotonically decrease. Let . Then . Denote by
 the sorted sequence of the
initial values of the functions in . Also, let 
and  (recall that the radius of  is ).  It is
easy to see that the range  obtained in Lemma \ref{lem:new20}
is contained in  for some .
The same discussion can be made for the distance functions in the
set  as well.


Since we rotate  by only an arc distance , during the
rotation of , each sensor  can have at most two distance
functions (i.e., one decreasing and one increasing) whose values may
vary in the range . We can easily identify these at
most  distance functions for the  sensors in 
time. Denote by  the set of all such distance functions.
Clearly, all critical equal distances in the range  can be
generated by the functions in  during the rotation of . Because every
such distance function either increases or decreases monotonically
during the rotation of , each pair of one increasing function and
one decreasing function can generate at most one critical equal distance
during the rotation. (Note that by Lemma \ref{lem:10}, a
critical equal distance cannot be generated by two increasing functions or
two decreasing functions.) Since , the total number of
critical equal distances in  is bounded by , i.e.,
. For convenience of discussion, since we are
concerned only with the critical equal distances in , for each
function in , we restrict it to the range  only.

Let the time  be the -coordinate and the function values be
the -coordinates of the plane. Then each function in  defines a curve
segment that lies in the strip of the plane between the two horizontal lines
 and . We refer to a function in
 and its curve segment interchangeably, i.e.,  is
also a set of curve segments. Clearly, a critical equal distance generated by an
increasing function and a decreasing function is the -coordinate of
the intersection point of the two corresponding curve segments.
Note that every function in 
has a simple mathematical description. Below, we simply assume that
each function in  is of  complexity. Thus, many
operations on them can each be performed in  time, e.g., computing the
intersection of a decreasing function and an increasing function.

The set  can be computed explicitly in  time, after
which  can be easily found by binary search. Below, we develop a faster
solution without computing  explicitly, by utilizing
the property that each element of  is the -coordinate of the
intersection point of a decreasing function and an increasing function in
 and generalizing the techniques in \cite{ref:ColeAn89}.

A slope selection algorithm for a set of points in the plane was given in
\cite{ref:ColeAn89}. We will extend this approach to solve our problem.
The following lemma is needed.

\begin{Lem}\label{lem:30}
For any two increasing (resp., decreasing) functions in , if the
curve segments defined by them are not identical to each other, then the two curve
segments intersect in at most one point and they cross each other at
their intersection point (if any).
\end{Lem}
\begin{proof}
We only prove the decreasing case. The increasing case can be proved
similarly. Let  and  be two
decreasing curves in , where  (resp.,
) is the distance function between the sensor 
(resp., ) and the vertex  (resp., ) of the regular -gon
, and the two curve segments defined by  and
 are not the same. Since each sensor has at most one
decreasing function in , we have .
We assume that during the (clockwise) rotation of ,  at the
moment  and  is the first such moment. Below, we prove
that  cannot happen again for any 
in the rotation. There are two cases:  and
.

For any two points  and , let  denote the line passing
through the two points and  denote the line segment with
endpoints  and  whose length is .
Recall that  is the center of the circle . Let  and
 be the positions of  and  at the moment ,
respectively.


\begin{itemize}
\item
. Clearly, .
Let  be the perpendicular bisector of the line
segment . At the moment , since
,  is at one of the two intersection points of
 and . Further, since  is a decreasing
function,  must be on the right side of the line  if
we walk from  to  (see Fig.~\ref{fig:case10}(a)). Similarly, 
must be on the right side of the line  (going  to ). Let  be the
other intersection point of  and . It is easy to see that
 is on the left side of either the line  or the line
. Note that .
Thus,  and . During the rotation of ,
since both  and  are always larger than
,  cannot pass any of  and , and thus 
cannot arrive to the position  during the rotation. Hence,
 cannot happen again after .

Further, recall that  is the first moment from the beginning of
the rotation with . Without loss of
generality, we assume  for any time  (as
the example shown in Fig.~\ref{fig:case10}(a)). It is easy to see
that  for any time , which implies that
the two functions cross each other at their intersection point.

\begin{figure}[t]
\begin{minipage}[t]{\linewidth}
\begin{center}
\includegraphics[totalheight=1.5in]{case10.eps}
\caption{\footnotesize Illustrating the proof
of Lemma \ref{lem:30}: (a) ; (b) .} \label{fig:case10}
\end{center}
\end{minipage}
\vspace*{-0.10in}
\end{figure}

\item
. At the moment , we have .
Assume to the contrary that at some moment , we also have
. Suppose at the moment ,  is at
the position  and  is at the position  (see
Fig.~\ref{fig:case10}(b)). Then . Since 
and  are rotated simultaneously, the arc distance from  to
 is equal to the arc distance from  to , and thus
. Consider the two triangles 
and  (shown with red solid segments
in Fig.~\ref{fig:case10}(b)).
Since , , and
,  is congruent to
. Thus, the two angles . Further, it is easy to see
. Consequently, we have .

But, if , then we can show that the
two functions  and  define exactly the
same curve segment. The proof is nothing but the inverse of the
above argument. Specifically, consider any time moment 
before the end of the rotation. Suppose at the moment ,  is
at the position  and  is at the position . Since
 and , we have . Further,
since  and ,  is congruent to . Thus,
, i.e.,  at any time .
Similarly, we can also show that at any time moment ,
. Hence,  and
 define exactly the same curve segment. But this
contradicts with the fact that the curve segments defined by these two
functions are not the same. This implies that
 cannot happen again at any moment .

Further, without loss of generality, we assume
 for any time  (as
the example shown in Fig.~\ref{fig:case10}(b)). We then show that
 for any time , which means that
the two functions cross each other at their intersection point. We
briefly discuss this.  Again, suppose at the moment ,  is
at the position  and  is at the position . First,
since  for any time , it must be
 (this can be proved by similar techniques as above and
we omit the details). Consider the two triangles  and
 (at the moment ). Since
, , and , we have
, which further implies . Consider the triangles  and . Due to ,
, and ,
it must be . In
other words,  at any time .
\end{itemize}

The lemma thus follows.
\end{proof}

We further extend every curve segment in  into an -monotone
curve, as follows. For each increasing (resp., decreasing) curve
segment, we extend it by attaching two half-lines with slope 
(resp., ) at the two endpoints of that curve segment,
respectively, such that the resulting new curve is still monotonically increasing
(resp., decreasing). Denote the resulting new curve set by . Obviously, an
increasing curve and a decreasing curve in  intersect once and
they cross each other at their intersection point. For any two different increasing (resp.,
decreasing) curves in , by Lemma \ref{lem:30} and the way we
extend the corresponding curve segments, they can intersect in at
most one point and cross each other at their intersection point
(if any). In other words,  can be viewed as a set of pseudolines.
Let  be the arrangement of . Observe that the
elements in  are the -coordinates of a subset of the
vertices of . Since ,  is the
-coordinate of a vertex of . Denote by  the
number of vertices in . Of course, we do not want to compute
the vertices of  explicitly.  By generalizing some techniques in
\cite{ref:ColeAn89}, we have the following lemma.

\begin{Lem}\label{lem:new50}
The value  can be computed in  time. Given an
integer  with , the -th
highest vertex of  can be found in  time.
\end{Lem}
\begin{proof}
First of all, because every function in  is of  complexity,
we can determine in  time whether a curve segment in 
intersects a given horizontal line, and if ``yes", then compute the
intersection. Thus, for every curve in , we can also compute its
intersection with any horizontal line in  time. Let
.

Recall that the curve segments in  are all in the horizontal strip between
 and . Thus, all vertices of  above the
horizontal line  are intersections of the newly attached half-lines.
We can easily determine the highest vertex of  in
 time, e.g., by using the approach in \cite{ref:ColeAn89}. Let
 be a horizontal line higher than the highest vertex. Denote by
 the sequence of the curves of  sorted in
increasing order of the -coordinates of their intersections with
. Similarly, we can determine the lowest vertex of  in
 time. Let  be
the sequence of the curves of  sorted in increasing order of the
-coordinates of their intersections with a horizontal line below
the lowest vertex of . Since the curves in  can be
viewed as a set of pseudolines, as in \cite{ref:ColeAn89}, the
number of inversions in the permutation , which can be computed
in  time, is equal to . In summary, we can
compute  in  time.

To compute the -th highest vertex of , we choose to
generalize the  time algorithm in \cite{ref:ColeAn89}.
Let  be a set of  lines in the plane and  be the arrangement of .
An  time algorithm was given in \cite{ref:ColeAn89} for
computing the -th highest vertex of  ()
in  time based on parametric search \cite{ref:ColeSl87,ref:MegiddoAp83}. The main
property used in the algorithm \cite{ref:ColeAn89} is the following one. Denote by
 the sequence of lines in  sorted in
increasing order of their intersections with a horizontal line above
the highest vertex of . Given any horizontal line , let
 be the sequence of lines
of  sorted in increasing order of their intersections with .
Then, the number of vertices of  above  is equal to the
number of inversions in the permutation .

In our problem, since
any two curves in  can intersect each other in at most one point and they
cross each other at their intersection point, the above property still holds for
. Thus, the  time algorithm in
\cite{ref:ColeAn89} is applicable to our problem. Therefore, we can
find the -th highest vertex of  in  time, and
the lemma follows.
\end{proof}

A remark: An optimal  time algorithm was also given in
\cite{ref:ColeAn89} (and in \cite{ref:KatzOp93}) for finding the
-th highest vertex of . However, these algorithms are overly
complicated. Although we think that the  time approach in \cite{ref:ColeAn89} may
be made work for our problem, it does not
benefit our overall solution for the optimization version of the
min-sum problem because its total time is dominated by
other parts of the algorithm. Hence, the much simpler 
time solution (for finding the -th highest vertex of )
suffices for our purpose.


Recall that  is the -coordinate of a vertex of
. Our algorithm for computing  then works as follows.
First, compute . Next, find the -th
highest vertex of , and denote its -coordinate by
. Determine whether  by the
algorithm in Theorem \ref{theo:20}, after which one half of the
vertices of  can be pruned away. We apply the above
procedure recursively on the remaining vertices of , until
 is found. Since there are  recursive calls to this procedure,
each of which takes , the
total time for computing  is .



\begin{Theo}
The min-max optimization problem is solvable in  time.
\end{Theo}


\section{The Min-sum Problem}
\label{sec:minsum}

In this section, we present our new algorithms for the min-sum problem. We show that the
boundary case of this problem is solvable in  time, which improves the
 time result in \cite{ref:TanNe10}. We also give an  time
approximation algorithm with approximation ratio ,
which improves the -approximation  time
algorithm in \cite{ref:BhattacharyaOp09}.

For the boundary case, the  time algorithm in
\cite{ref:TanNe10} uses the  time Hungarian algorithm
to compute a minimum weight perfect matching in a complete bipartite graph.
However, the graph for this case is very special in the sense that all its
vertices lie on the boundary of a circle. By using the result in \cite{ref:BussLi98},
we can actually find a minimum weight perfect matching in such a graph
in  time. Therefore, if we follow the algorithmic scheme in
\cite{ref:TanNe10} but replace the Hungarian algorithm by the algorithm in
\cite{ref:BussLi98}, the boundary case can be solved in
 time. For completeness, more details on the proof of the
following theorem are given in Appendix \ref{app:Theorem40}.

\begin{Theo}\label{theo:40}
The boundary case of the min-sum problem can be solved in 
time.
\end{Theo}

Next, we discuss our approximation algorithm for the general min-sum
problem.

Let  be the sensors in . Our approximation
algorithm works as follows. (1) For each sensor ,
, compute the point  on  that is
closest to . (2) By using the algorithm in Theorem \ref{theo:40},
solve the following min-sum boundary case problem: Viewing the 
points  as {\em pseudo-sensors} (which all
lie on ), find  points on  as the goal
positions for the pseudo-sensors such that the sum of the distances
traveled by all  pseudo-sensors is minimized. Let  be the goal
position for each  () in the optimal
solution thus obtained. We then let  be the goal position for each sensor
, , for our original min-sum problem. This completes the
description of our approximation algorithm.

Clearly, with Theorem \ref{theo:40}, the time complexity of the
above approximation algorithm is . The lemma below shows that the
approximation ratio of this algorithm is .

\begin{Lem}\label{lem:40}
The approximation ratio of our approximation algorithm is .
\end{Lem}
\begin{proof}
Let . Let
 be the goal positions
of all sensors (i.e.,  is the goal position for each sensor
, ) in an optimal solution for the
min-sum problem. Let .
Our task is to prove .

First,   , and  holds for each . Then,

The lemma thus follows.
\end{proof}

Hence, we conclude with the following result.

\begin{Theo}
There exists an  time approximation algorithm for the
min-sum problem with approximation ratio 3.
\end{Theo}



\footnotesize
\baselineskip=11.0pt
\bibliographystyle{plain}
\bibliography{reference}

\newpage
\normalsize
\appendix
\section*{Appendix}

\section{The Proof of Lemma \ref{lem:10}}
\label{app:lemmaproofs}

\noindent
{\bf Lemma \ref{lem:10}\ }\cite{ref:TanNe10}
{\em
Suppose an optimal solution for the min-max optimization problem is achieved
with  for some . Then either  is the point , or there is
another sensor  () such that  also holds. In the latter case, any slight rotation of the
regular -gon that achieves  in either direction
causes the value of  to increase (i.e., it makes one of the two
distances  and  increase and the other one decrease).
}
\vspace{0.15in}

\begin{proof}
First assume that in an optimal solution,
the sensor  is the only one satisfying ,
but  is not the point . Thus  holds (see Figure 1(a)).
Then, we rotate the regular -gon that achieves  by moving
the vertex  towards , with a very small distance . Clearly,
the distance function between  and  decreases monotonically during
this rotation of that -gon. Denote by , , , 
the new positions of the sensors after the rotation stops. Since  is
arbitrarily small and  is the only sensor satisfying ,
we have  for all ;
moreover,  holds. But, this contradicts with
the assumption that
 gives an optimal solution to the min-max optimization problem.

Suppose now there exists another sensor  such that the optimal value
 () also holds (see Figure 1(b)).
A slight rotation of the regular -gon that achieves 
in either direction cannot make 
and  both occur, where  and 
are the new positions of  and  after the rotation stops
(otherwise, it would contradict with the assumption that  gives an optimal solution).
Hence, the rotation of the regular -gon that achieves 
increases one of the two distances
 and , while decreasing the other.
The proof is thus complete.
\end{proof}

\section{The Proof of Theorem \ref{theo:40}}
\label{app:Theorem40}

Recall that in the boundary case of the min-sum problem, all sensors
are on the boundary  of . Let , , , 
denote the initial positions of the  sensors on , and
, , ,  denote their goal positions on
 that form a regular -gon. Denote by  the
sum of the distances traveled by all  sensors in an optimal solution
of the min-sum problem, i.e., . The following lemma has been proved in
\cite{ref:TanNe10}.

\begin{Lem}\cite{ref:TanNe10}
\label{lem-not-move}
There exists an optimal solution for the boundary case of the
min-sum problem with the following property: There exists a sensor  which
does not move, i.e., .
\end{Lem}

Based on Lemma \ref{lem-not-move}, the boundary case can be solved as
follows. For each sensor , , let  be
the regular -gon on  such that  is one of its
vertices. Denote by  the complete bipartite graph between the
set of all sensors and the set of all vertices of  such
that the weight of an edge connecting a sensor and a vertex of
 is defined as their Euclidean distance. We compute a
minimum weight perfect matching  in , for each , and the one that gives the minimum weight defines an
optimal solution for our original problem. Here, the weight of a
perfect matching is the sum of all edge weights of the matching.

The running time of the above algorithm is dominated by the step of
computing the minimum weight perfect matchings in the graphs .
The algorithm in \cite{ref:TanNe10} uses the  time
Hungarian algorithm for computing such matchings in the graphs .

Let  be a complete bipartite graph with two vertex sets of
cardinalities  and , respectively, such that all its vertices
lie on the boundary of a circle and each edge weight is the
Euclidean distance between two such vertices (the edges are
represented implicitly). A maximum cardinality matching of  consists of
 edges. An algorithm was given in
\cite{ref:BussLi98} for computing a
minimum weight maximum cardinality matching in  in  time (i.e., the total sum
of edge weights in the output maximum cardinality matching is as small as possible).

Since in our algorithm, all vertices of every complete bipartite
graph  lie on , the linear time algorithm in
\cite{ref:BussLi98} can be applied to compute a minimum weight
maximum cardinality matching of  in  time, for
. (Note that a maximum
cardinality matching in the graph  is a perfect matching, and vice versa.)
Consequently, the total running time of our algorithm is .
Theorem \ref{theo:40} thus follows.
\end{document}
