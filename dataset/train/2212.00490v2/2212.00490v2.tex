
\documentclass{article} \usepackage{iclr2023_conference,times}



\usepackage{amsmath,amsfonts,bm}

\newcommand{\figleft}{{\em (Left)}}
\newcommand{\figcenter}{{\em (Center)}}
\newcommand{\figright}{{\em (Right)}}
\newcommand{\figtop}{{\em (Top)}}
\newcommand{\figbottom}{{\em (Bottom)}}
\newcommand{\captiona}{{\em (a)}}
\newcommand{\captionb}{{\em (b)}}
\newcommand{\captionc}{{\em (c)}}
\newcommand{\captiond}{{\em (d)}}

\newcommand{\newterm}[1]{{\bf #1}}


\def\figref#1{figure~\ref{#1}}
\def\Figref#1{Figure~\ref{#1}}
\def\twofigref#1#2{figures \ref{#1} and \ref{#2}}
\def\quadfigref#1#2#3#4{figures \ref{#1}, \ref{#2}, \ref{#3} and \ref{#4}}
\def\secref#1{section~\ref{#1}}
\def\Secref#1{Section~\ref{#1}}
\def\twosecrefs#1#2{sections \ref{#1} and \ref{#2}}
\def\secrefs#1#2#3{sections \ref{#1}, \ref{#2} and \ref{#3}}
\def\eqref#1{equation~\ref{#1}}
\def\Eqref#1{Equation~\ref{#1}}
\def\plaineqref#1{\ref{#1}}
\def\chapref#1{chapter~\ref{#1}}
\def\Chapref#1{Chapter~\ref{#1}}
\def\rangechapref#1#2{chapters\ref{#1}--\ref{#2}}
\def\algref#1{algorithm~\ref{#1}}
\def\Algref#1{Algorithm~\ref{#1}}
\def\twoalgref#1#2{algorithms \ref{#1} and \ref{#2}}
\def\Twoalgref#1#2{Algorithms \ref{#1} and \ref{#2}}
\def\partref#1{part~\ref{#1}}
\def\Partref#1{Part~\ref{#1}}
\def\twopartref#1#2{parts \ref{#1} and \ref{#2}}

\def\ceil#1{\lceil #1 \rceil}
\def\floor#1{\lfloor #1 \rfloor}
\def\1{\bm{1}}
\newcommand{\train}{\mathcal{D}}
\newcommand{\valid}{\mathcal{D_{\mathrm{valid}}}}
\newcommand{\test}{\mathcal{D_{\mathrm{test}}}}

\def\eps{{\epsilon}}


\def\reta{{\textnormal{}}}
\def\ra{{\textnormal{a}}}
\def\rb{{\textnormal{b}}}
\def\rc{{\textnormal{c}}}
\def\rd{{\textnormal{d}}}
\def\re{{\textnormal{e}}}
\def\rf{{\textnormal{f}}}
\def\rg{{\textnormal{g}}}
\def\rh{{\textnormal{h}}}
\def\ri{{\textnormal{i}}}
\def\rj{{\textnormal{j}}}
\def\rk{{\textnormal{k}}}
\def\rl{{\textnormal{l}}}
\def\rn{{\textnormal{n}}}
\def\ro{{\textnormal{o}}}
\def\rp{{\textnormal{p}}}
\def\rq{{\textnormal{q}}}
\def\rr{{\textnormal{r}}}
\def\rs{{\textnormal{s}}}
\def\rt{{\textnormal{t}}}
\def\ru{{\textnormal{u}}}
\def\rv{{\textnormal{v}}}
\def\rw{{\textnormal{w}}}
\def\rx{{\textnormal{x}}}
\def\ry{{\textnormal{y}}}
\def\rz{{\textnormal{z}}}

\def\rvepsilon{{\mathbf{\epsilon}}}
\def\rvtheta{{\mathbf{\theta}}}
\def\rva{{\mathbf{a}}}
\def\rvb{{\mathbf{b}}}
\def\rvc{{\mathbf{c}}}
\def\rvd{{\mathbf{d}}}
\def\rve{{\mathbf{e}}}
\def\rvf{{\mathbf{f}}}
\def\rvg{{\mathbf{g}}}
\def\rvh{{\mathbf{h}}}
\def\rvu{{\mathbf{i}}}
\def\rvj{{\mathbf{j}}}
\def\rvk{{\mathbf{k}}}
\def\rvl{{\mathbf{l}}}
\def\rvm{{\mathbf{m}}}
\def\rvn{{\mathbf{n}}}
\def\rvo{{\mathbf{o}}}
\def\rvp{{\mathbf{p}}}
\def\rvq{{\mathbf{q}}}
\def\rvr{{\mathbf{r}}}
\def\rvs{{\mathbf{s}}}
\def\rvt{{\mathbf{t}}}
\def\rvu{{\mathbf{u}}}
\def\rvv{{\mathbf{v}}}
\def\rvw{{\mathbf{w}}}
\def\rvx{{\mathbf{x}}}
\def\rvy{{\mathbf{y}}}
\def\rvz{{\mathbf{z}}}

\def\erva{{\textnormal{a}}}
\def\ervb{{\textnormal{b}}}
\def\ervc{{\textnormal{c}}}
\def\ervd{{\textnormal{d}}}
\def\erve{{\textnormal{e}}}
\def\ervf{{\textnormal{f}}}
\def\ervg{{\textnormal{g}}}
\def\ervh{{\textnormal{h}}}
\def\ervi{{\textnormal{i}}}
\def\ervj{{\textnormal{j}}}
\def\ervk{{\textnormal{k}}}
\def\ervl{{\textnormal{l}}}
\def\ervm{{\textnormal{m}}}
\def\ervn{{\textnormal{n}}}
\def\ervo{{\textnormal{o}}}
\def\ervp{{\textnormal{p}}}
\def\ervq{{\textnormal{q}}}
\def\ervr{{\textnormal{r}}}
\def\ervs{{\textnormal{s}}}
\def\ervt{{\textnormal{t}}}
\def\ervu{{\textnormal{u}}}
\def\ervv{{\textnormal{v}}}
\def\ervw{{\textnormal{w}}}
\def\ervx{{\textnormal{x}}}
\def\ervy{{\textnormal{y}}}
\def\ervz{{\textnormal{z}}}

\def\rmA{{\mathbf{A}}}
\def\rmB{{\mathbf{B}}}
\def\rmC{{\mathbf{C}}}
\def\rmD{{\mathbf{D}}}
\def\rmE{{\mathbf{E}}}
\def\rmF{{\mathbf{F}}}
\def\rmG{{\mathbf{G}}}
\def\rmH{{\mathbf{H}}}
\def\rmI{{\mathbf{I}}}
\def\rmJ{{\mathbf{J}}}
\def\rmK{{\mathbf{K}}}
\def\rmL{{\mathbf{L}}}
\def\rmM{{\mathbf{M}}}
\def\rmN{{\mathbf{N}}}
\def\rmO{{\mathbf{O}}}
\def\rmP{{\mathbf{P}}}
\def\rmQ{{\mathbf{Q}}}
\def\rmR{{\mathbf{R}}}
\def\rmS{{\mathbf{S}}}
\def\rmT{{\mathbf{T}}}
\def\rmU{{\mathbf{U}}}
\def\rmV{{\mathbf{V}}}
\def\rmW{{\mathbf{W}}}
\def\rmX{{\mathbf{X}}}
\def\rmY{{\mathbf{Y}}}
\def\rmZ{{\mathbf{Z}}}

\def\ermA{{\textnormal{A}}}
\def\ermB{{\textnormal{B}}}
\def\ermC{{\textnormal{C}}}
\def\ermD{{\textnormal{D}}}
\def\ermE{{\textnormal{E}}}
\def\ermF{{\textnormal{F}}}
\def\ermG{{\textnormal{G}}}
\def\ermH{{\textnormal{H}}}
\def\ermI{{\textnormal{I}}}
\def\ermJ{{\textnormal{J}}}
\def\ermK{{\textnormal{K}}}
\def\ermL{{\textnormal{L}}}
\def\ermM{{\textnormal{M}}}
\def\ermN{{\textnormal{N}}}
\def\ermO{{\textnormal{O}}}
\def\ermP{{\textnormal{P}}}
\def\ermQ{{\textnormal{Q}}}
\def\ermR{{\textnormal{R}}}
\def\ermS{{\textnormal{S}}}
\def\ermT{{\textnormal{T}}}
\def\ermU{{\textnormal{U}}}
\def\ermV{{\textnormal{V}}}
\def\ermW{{\textnormal{W}}}
\def\ermX{{\textnormal{X}}}
\def\ermY{{\textnormal{Y}}}
\def\ermZ{{\textnormal{Z}}}

\def\vzero{{\bm{0}}}
\def\vone{{\bm{1}}}
\def\vmu{{\bm{\mu}}}
\def\vtheta{{\bm{\theta}}}
\def\va{{\bm{a}}}
\def\vb{{\bm{b}}}
\def\vc{{\bm{c}}}
\def\vd{{\bm{d}}}
\def\ve{{\bm{e}}}
\def\vf{{\bm{f}}}
\def\vg{{\bm{g}}}
\def\vh{{\bm{h}}}
\def\vi{{\bm{i}}}
\def\vj{{\bm{j}}}
\def\vk{{\bm{k}}}
\def\vl{{\bm{l}}}
\def\vm{{\bm{m}}}
\def\vn{{\bm{n}}}
\def\vo{{\bm{o}}}
\def\vp{{\bm{p}}}
\def\vq{{\bm{q}}}
\def\vr{{\bm{r}}}
\def\vs{{\bm{s}}}
\def\vt{{\bm{t}}}
\def\vu{{\bm{u}}}
\def\vv{{\bm{v}}}
\def\vw{{\bm{w}}}
\def\vx{{\bm{x}}}
\def\vy{{\bm{y}}}
\def\vz{{\bm{z}}}

\def\evalpha{{\alpha}}
\def\evbeta{{\beta}}
\def\evepsilon{{\epsilon}}
\def\evlambda{{\lambda}}
\def\evomega{{\omega}}
\def\evmu{{\mu}}
\def\evpsi{{\psi}}
\def\evsigma{{\sigma}}
\def\evtheta{{\theta}}
\def\eva{{a}}
\def\evb{{b}}
\def\evc{{c}}
\def\evd{{d}}
\def\eve{{e}}
\def\evf{{f}}
\def\evg{{g}}
\def\evh{{h}}
\def\evi{{i}}
\def\evj{{j}}
\def\evk{{k}}
\def\evl{{l}}
\def\evm{{m}}
\def\evn{{n}}
\def\evo{{o}}
\def\evp{{p}}
\def\evq{{q}}
\def\evr{{r}}
\def\evs{{s}}
\def\evt{{t}}
\def\evu{{u}}
\def\evv{{v}}
\def\evw{{w}}
\def\evx{{x}}
\def\evy{{y}}
\def\evz{{z}}

\def\mA{{\bm{A}}}
\def\mB{{\bm{B}}}
\def\mC{{\bm{C}}}
\def\mD{{\bm{D}}}
\def\mE{{\bm{E}}}
\def\mF{{\bm{F}}}
\def\mG{{\bm{G}}}
\def\mH{{\bm{H}}}
\def\mI{{\bm{I}}}
\def\mJ{{\bm{J}}}
\def\mK{{\bm{K}}}
\def\mL{{\bm{L}}}
\def\mM{{\bm{M}}}
\def\mN{{\bm{N}}}
\def\mO{{\bm{O}}}
\def\mP{{\bm{P}}}
\def\mQ{{\bm{Q}}}
\def\mR{{\bm{R}}}
\def\mS{{\bm{S}}}
\def\mT{{\bm{T}}}
\def\mU{{\bm{U}}}
\def\mV{{\bm{V}}}
\def\mW{{\bm{W}}}
\def\mX{{\bm{X}}}
\def\mY{{\bm{Y}}}
\def\mZ{{\bm{Z}}}
\def\mBeta{{\bm{\beta}}}
\def\mPhi{{\bm{\Phi}}}
\def\mLambda{{\bm{\Lambda}}}
\def\mSigma{{\bm{\Sigma}}}

\DeclareMathAlphabet{\mathsfit}{\encodingdefault}{\sfdefault}{m}{sl}
\SetMathAlphabet{\mathsfit}{bold}{\encodingdefault}{\sfdefault}{bx}{n}
\newcommand{\tens}[1]{\bm{\mathsfit{#1}}}
\def\tA{{\tens{A}}}
\def\tB{{\tens{B}}}
\def\tC{{\tens{C}}}
\def\tD{{\tens{D}}}
\def\tE{{\tens{E}}}
\def\tF{{\tens{F}}}
\def\tG{{\tens{G}}}
\def\tH{{\tens{H}}}
\def\tI{{\tens{I}}}
\def\tJ{{\tens{J}}}
\def\tK{{\tens{K}}}
\def\tL{{\tens{L}}}
\def\tM{{\tens{M}}}
\def\tN{{\tens{N}}}
\def\tO{{\tens{O}}}
\def\tP{{\tens{P}}}
\def\tQ{{\tens{Q}}}
\def\tR{{\tens{R}}}
\def\tS{{\tens{S}}}
\def\tT{{\tens{T}}}
\def\tU{{\tens{U}}}
\def\tV{{\tens{V}}}
\def\tW{{\tens{W}}}
\def\tX{{\tens{X}}}
\def\tY{{\tens{Y}}}
\def\tZ{{\tens{Z}}}


\def\gA{{\mathcal{A}}}
\def\gB{{\mathcal{B}}}
\def\gC{{\mathcal{C}}}
\def\gD{{\mathcal{D}}}
\def\gE{{\mathcal{E}}}
\def\gF{{\mathcal{F}}}
\def\gG{{\mathcal{G}}}
\def\gH{{\mathcal{H}}}
\def\gI{{\mathcal{I}}}
\def\gJ{{\mathcal{J}}}
\def\gK{{\mathcal{K}}}
\def\gL{{\mathcal{L}}}
\def\gM{{\mathcal{M}}}
\def\gN{{\mathcal{N}}}
\def\gO{{\mathcal{O}}}
\def\gP{{\mathcal{P}}}
\def\gQ{{\mathcal{Q}}}
\def\gR{{\mathcal{R}}}
\def\gS{{\mathcal{S}}}
\def\gT{{\mathcal{T}}}
\def\gU{{\mathcal{U}}}
\def\gV{{\mathcal{V}}}
\def\gW{{\mathcal{W}}}
\def\gX{{\mathcal{X}}}
\def\gY{{\mathcal{Y}}}
\def\gZ{{\mathcal{Z}}}

\def\sA{{\mathbb{A}}}
\def\sB{{\mathbb{B}}}
\def\sC{{\mathbb{C}}}
\def\sD{{\mathbb{D}}}
\def\sF{{\mathbb{F}}}
\def\sG{{\mathbb{G}}}
\def\sH{{\mathbb{H}}}
\def\sI{{\mathbb{I}}}
\def\sJ{{\mathbb{J}}}
\def\sK{{\mathbb{K}}}
\def\sL{{\mathbb{L}}}
\def\sM{{\mathbb{M}}}
\def\sN{{\mathbb{N}}}
\def\sO{{\mathbb{O}}}
\def\sP{{\mathbb{P}}}
\def\sQ{{\mathbb{Q}}}
\def\sR{{\mathbb{R}}}
\def\sS{{\mathbb{S}}}
\def\sT{{\mathbb{T}}}
\def\sU{{\mathbb{U}}}
\def\sV{{\mathbb{V}}}
\def\sW{{\mathbb{W}}}
\def\sX{{\mathbb{X}}}
\def\sY{{\mathbb{Y}}}
\def\sZ{{\mathbb{Z}}}

\def\emLambda{{\Lambda}}
\def\emA{{A}}
\def\emB{{B}}
\def\emC{{C}}
\def\emD{{D}}
\def\emE{{E}}
\def\emF{{F}}
\def\emG{{G}}
\def\emH{{H}}
\def\emI{{I}}
\def\emJ{{J}}
\def\emK{{K}}
\def\emL{{L}}
\def\emM{{M}}
\def\emN{{N}}
\def\emO{{O}}
\def\emP{{P}}
\def\emQ{{Q}}
\def\emR{{R}}
\def\emS{{S}}
\def\emT{{T}}
\def\emU{{U}}
\def\emV{{V}}
\def\emW{{W}}
\def\emX{{X}}
\def\emY{{Y}}
\def\emZ{{Z}}
\def\emSigma{{\Sigma}}

\newcommand{\etens}[1]{\mathsfit{#1}}
\def\etLambda{{\etens{\Lambda}}}
\def\etA{{\etens{A}}}
\def\etB{{\etens{B}}}
\def\etC{{\etens{C}}}
\def\etD{{\etens{D}}}
\def\etE{{\etens{E}}}
\def\etF{{\etens{F}}}
\def\etG{{\etens{G}}}
\def\etH{{\etens{H}}}
\def\etI{{\etens{I}}}
\def\etJ{{\etens{J}}}
\def\etK{{\etens{K}}}
\def\etL{{\etens{L}}}
\def\etM{{\etens{M}}}
\def\etN{{\etens{N}}}
\def\etO{{\etens{O}}}
\def\etP{{\etens{P}}}
\def\etQ{{\etens{Q}}}
\def\etR{{\etens{R}}}
\def\etS{{\etens{S}}}
\def\etT{{\etens{T}}}
\def\etU{{\etens{U}}}
\def\etV{{\etens{V}}}
\def\etW{{\etens{W}}}
\def\etX{{\etens{X}}}
\def\etY{{\etens{Y}}}
\def\etZ{{\etens{Z}}}

\newcommand{\pdata}{p_{\rm{data}}}
\newcommand{\ptrain}{\hat{p}_{\rm{data}}}
\newcommand{\Ptrain}{\hat{P}_{\rm{data}}}
\newcommand{\pmodel}{p_{\rm{model}}}
\newcommand{\Pmodel}{P_{\rm{model}}}
\newcommand{\ptildemodel}{\tilde{p}_{\rm{model}}}
\newcommand{\pencode}{p_{\rm{encoder}}}
\newcommand{\pdecode}{p_{\rm{decoder}}}
\newcommand{\precons}{p_{\rm{reconstruct}}}

\newcommand{\laplace}{\mathrm{Laplace}} 

\newcommand{\E}{\mathbb{E}}
\newcommand{\Ls}{\mathcal{L}}
\newcommand{\R}{\mathbb{R}}
\newcommand{\emp}{\tilde{p}}
\newcommand{\lr}{\alpha}
\newcommand{\reg}{\lambda}
\newcommand{\rect}{\mathrm{rectifier}}
\newcommand{\softmax}{\mathrm{softmax}}
\newcommand{\sigmoid}{\sigma}
\newcommand{\softplus}{\zeta}
\newcommand{\KL}{D_{\mathrm{KL}}}
\newcommand{\Var}{\mathrm{Var}}
\newcommand{\standarderror}{\mathrm{SE}}
\newcommand{\Cov}{\mathrm{Cov}}
\newcommand{\normlzero}{L^0}
\newcommand{\normlone}{L^1}
\newcommand{\normltwo}{L^2}
\newcommand{\normlp}{L^p}
\newcommand{\normmax}{L^\infty}

\newcommand{\parents}{Pa} 

\DeclareMathOperator*{\argmax}{arg\,max}
\DeclareMathOperator*{\argmin}{arg\,min}

\DeclareMathOperator{\sign}{sign}
\DeclareMathOperator{\Tr}{Tr}
\let\ab\allowbreak
 
\usepackage{hyperref}
\usepackage{url}

\usepackage{listings}
\usepackage{xcolor}
\usepackage{graphicx}
\usepackage{algorithm}
\usepackage{multirow}
\usepackage[noend]{algpseudocode}
\usepackage{algorithmicx}
\usepackage{float}

\title{Zero-Shot Image Restoration Using\\ Denoising Diffusion Null-Space Model}



\author{Yinhuai~Wang\textsuperscript{\rm 1},
Jiwen~Yu\textsuperscript{\rm 1},
Jian~Zhang\textsuperscript{\rm 1,2}\\
\textsuperscript{\rm 1}Peking University Shenzhen Graduate School, \textsuperscript{\rm 2}Peng Cheng Laboratory\\
\texttt{\{yinhuai; yujiwen\}@stu.pku.edu.cn, zhangjian.sz@pku.edu.cn} \\
}



\newcommand{\fix}{\marginpar{FIX}}
\newcommand{\new}{\marginpar{NEW}}

\iclrfinalcopy \begin{document}


\maketitle

\begin{abstract}
Most existing Image Restoration (IR) models are task-specific, which can not be generalized to different degradation operators. In this work, we propose the Denoising Diffusion Null-Space Model (DDNM), a novel zero-shot framework for arbitrary linear IR problems, including but not limited to image super-resolution, colorization, inpainting, compressed sensing, and deblurring. DDNM only needs a pre-trained off-the-shelf diffusion model as the generative prior, without any extra training or network modifications. By refining only the null-space contents during the reverse diffusion process, we can yield diverse results satisfying both data consistency and realness. We further propose an enhanced and robust version, dubbed DDNM, to support noisy restoration and improve restoration quality for hard tasks. Our experiments on several IR tasks reveal that DDNM outperforms other state-of-the-art zero-shot IR methods. We also demonstrate that DDNM can solve complex real-world applications, \textit{e.g.}, old photo restoration. 
\end{abstract}

\vspace{-0.1cm}
\section{Introduction}

\begin{figure*}[hb]
  \centering
  \vspace{-0.1cm}
  \includegraphics[width=1\linewidth]{im/fig1.pdf}
  \vspace{-0.7cm}
  \caption{\textbf{We use DDNM to solve various image restoration tasks in a zero-shot way}.  Here we show some of the results that best characterize our method, where  is the input degraded image and  represents the restoration result. Part (a) shows the results of DDNM on image super-resolution (SR) from scale 2 to extreme scale 256. Note that DDNM assures strict data consistency. Part (b) shows multiple results of DDNM on inpainting and colorization. Part (c) shows the results of DDNM on SR with synthetic noise and colorization with real-world noise. Part (d) shows the results of DDNM on old photo restoration. All the results here are yielded in a \textbf{zero-shot} way.}
   \vspace{-0.2cm}
\label{fig:front} 
\end{figure*}

\def\thefootnote{*}\footnotetext{Authors contributed equally to this work. Code
is available at \textcolor{blue}{https://github.com/wyhuai/DDNM}}
\vspace{-0.2cm}

Image Restoration (IR) is a long-standing problem due to its extensive application value and its ill-posed nature \citep{richardson1972bayesian,andrews1977digital}. IR aims at yielding a high-quality image  from a degraded observation , where  stands for the original image and  represents a non-linear noise.  is a known linear operator, which may be a bicubic downsampler in image super-resolution, a sampling matrix in compressed sensing, or even a composite type. Traditional IR methods are typically model-based, whose solution can be usually formulated as:

The first data-fidelity term  optimizes the result toward data consistency while the second image-prior term  regularizes the result with formulaic prior knowledge on natural image distribution, e.g., sparsity and Tikhonov regularization. Though the hand-designed prior knowledge may prevent some artifacts, they often fail to bring realistic details. 

The prevailing of deep neural networks (DNN) brings new patterns of solving IR tasks \citep{srcnn}, which typically train an end-to-end DNN  by optimizing network parameters  following 

where  pairs of degraded image  and ground truth image  are needed to learn the mapping from  to  directly. Although end-to-end learning-based IR methods avoid explicitly modeling the degradation  and the prior term in Eq.~\ref{eq:traditional} and are fast during inference, they usually lack interpretation. Some efforts have been made in exploring interpretable DNN structures \citep{zhang2018ista,zhang2020dunsr}, however, they still yield poor performance when facing domain shift since Eq.~\ref{eq:dnn} essentially encourage learning the mapping from  to . For the same reason, the end-to-end learning-based IR methods usually need to train a dedicated DNN for each specific task, lacking generalizability and flexibility in solving diverse IR tasks. The evolution of generative models \citep{gan, kingma2014auto,vqvae,stylegan,stylegan2,stylegan3} further pushes the end-to-end learning-based IR methods toward unprecedented performance in yielding realistic results \citep{gpen,gfpgan,glean,panini}. At the same time, some methods \citep{menon2020pulse,pan2021exploiting} start to leverage the latent space of pretrained generative models to solve IR problems in a zero-shot way. Typically, they optimize the following objective: 

where  is the pretrained generative model,  is the latent code,  is the corresponding generative result and  constrains  to its original distribution space, e.g., a Gaussian distribution. However, this type of method often struggles to balance realness and data consistency.


The Range-Null space decomposition \citep{schwab2019deep,wang2022gan} offers a new perspective on the relationship between realness and data consistency: the data consistency is only related to the range-space contents, which can be analytically calculated. Hence the data term can be strictly guaranteed, and the key problem is to find proper null-space contents that make the result satisfying realness. We notice that the emerging diffusion models \citep{ho2020denoising,dhariwal2021diffusion} are ideal tools to yield ideal null-space contents because they support explicit control over the generation process.  

In this paper, we propose a novel zero-shot solution for various IR tasks, which we call the Denoising Diffusion Null-Space Model (DDNM). By refining only the null-space contents during the reverse diffusion sampling, our solution only requires an off-the-shelf diffusion model to yield realistic and data-consistent results, without any extra training or optimization nor needing any modifications to network structures. Extensive experiments show that DDNM outperforms state-of-the-art zero-shot IR methods in diverse IR tasks, including super-resolution, colorization, compressed sensing, inpainting, and deblurring. We further propose an enhanced version, DDNM, which significantly elevates the generative quality and supports solving noisy IR tasks. Our methods are free from domain shifts in degradation modes and thus can flexibly solve complex IR tasks with real-world degradation, such as old photo restoration. Our approaches reveal a promising new path toward solving IR tasks in zero-shots, as the data consistency is analytically guaranteed, and the realness is determined by the pretrained diffusion models used, which are rapidly evolving. Fig.~\ref{fig:front} provides some typical applications that fully show the superiority and generality of the proposed methods.

\textbf{Contributions.} (1) \textbf{In theory}, we reveal that a pretrained diffusion model can be a zero-shot solver for linear IR problems by refining only the null-space during the reverse diffusion process. Correspondingly, we propose a unified theoretical framework for arbitrary linear IR problems. We further extend our method to support solving noisy IR tasks and propose a \textit{time-travel} trick to improve the restoration quality significantly; (2) \textbf{In practice}, our solution is the first that can decently solve diverse linear IR tasks with arbitrary noise levels, in a zero-shot manner. Furthermore, our solution can handle composite degradation and is robust to noise types, whereby we can tackle challenging real-world applications. Our proposed DDNMs achieve state-of-the-art zero-shot IR results. 



\section{Background}
\label{gen_inst}

\subsection{Review the Diffusion Models}
We follow the diffusion model defined in denoising diffusion probabilistic models (DDPM)~\citep{ho2020denoising}. DDPM defines a -step forward process and a -step reverse process. The forward process slowly adds random noise to data, while the reverse process constructs desired data samples from the noise. The forward process yields the present state  from the previous state :

where  is the noised image at time-step ,  is the predefined scale factor, and  represents the Gaussian distribution. Using reparameterization trick, it becomes

The reverse process aims at yielding the previous state  from  using the posterior distribution , which can be derived from the Bayes theorem using Eq.~\ref{eq:ddpm forward 1} and Eq.~\ref{eq:ddpm forward 2}:

with the closed forms of mean  and variance .  represents the noise in  and is the only uncertain variable during the reverse process. DDPM uses a neural network  to predict the noise  for each time-step , i.e., , where  denotes the estimation of  at time-step . To train  , DDPM randomly picks a clean image  from the dataset and samples a noise , then picks a random time-step  and updates the network parameters  in  with the following gradient descent step \citep{ho2020denoising}:

By iteratively sampling  from ,  DDPM can yield clean images  from random noises , where  represents the image distribution in the training dataset.


\subsection{Range-Null Space Decomposition}
\label{RND}
For ease of derivation, we represent linear operators in matrix form and images in vector form. Note that our derivations hold for all linear operators. Given a linear operator , its pseudo-inverse  satisfies . There are many ways to solve the pseudo-inverse , e.g., the Singular Value Decomposition (SVD) is often used to solve  in matrix form, and the Fourier transform is often used to solve the convolutional form of . 

 and  have some interesting properties.  can be seen as the operator that projects samples  to the range-space of  because . In contrast,  can be seen as the operator that projects samples  to the null-space of  because .

Interestingly, any sample  can be decomposed into two parts: one part is in the range-space of  and the other is in the null-space of , i.e.,

This decomposition has profound significance for linear IR problems, which we will get to later.


\section{Method}
\subsection{Denoising Diffusion Null-Space Model}
\paragraph{Null-Space Is All We Need.} We start with noise-free Image Restoration (IR) as below:

where , , and  denote the ground-truth (GT) image, the linear degradation operator, and the degraded image, respectively. Given an input , IR problems essentially aim to yield an image  that conforms to the following two constraints:

where  denotes the distribution of the GT images.

For the \textit{Consistency} constraint, we can resort to range-null space decomposition. As discussed in Sec.~\ref{RND}, the GT image  can be decomposed as a range-space part  and a null-space part . Interestingly, we can find that the range-space part  becomes exactly  after being operated by , while the null-space part  becomes exactly  after being operated by , i.e., .

More interestingly, for a degraded image , we can directly construct a general solution  that satisfies the \textit{Consistency} constraint , that is . Whatever  is, it does not affect the \textit{Consistency} at all. But  determines whether . Then our goal is to find a proper  that makes . We resort to diffusion models to generate the null-space  
which is in harmony with the range-space .

\paragraph{Refine Null-Space Iteratively.} We know the reverse diffusion process iteratively samples  from  to yield clean images  from random noises . However, this process is completely random, and the intermediate state  is noisy. To yield clean intermediate states for range-null space decomposition, we reparameterize the mean  and variance  of distribution  as: 

where  is unknown, but we can reverse Eq.~\ref{eq:ddpm forward 2} to estimate a  from  and the predicted noise . We denote the estimated  at time-step  as , which can be formulated as:

Note that this formulation is equivalent to the original DDPM. We do this because it provides a ``clean" image  (rather than noisy image ). To finally yield a  satisfying , we fix the range-space as  and leave the null-space unchanged, yielding a rectified estimation  as: 

Hence we use  as the estimation of  in Eq.~\ref{eq:mu}, thereby allowing only the null space to participate in the reverse diffusion process. Then we yield  by sampling from :

Roughly speaking,  is a noised version of  and the added noise erases the disharmony between the range-space contents  and the null-space contents . Therefore, iteratively applying Eq.~\ref{eq:x0t}, Eq.~\ref{eq:ndm core}, and Eq.~\ref{eq:ndm_xt-1} yields a final result . Note that all the rectified estimation  conforms to \textit{Consistency} due to the fact that
 
Considering  is equal to , so the final result  also satisfies \textit{Consistency}. We call the proposed method the Denoising Diffusion Null-Space Model (DDNM) because it utilizes the denoising diffusion model to fill up the null-space information.

Algo.~\ref{alg:ndm} and Fig.~\ref{fig:ddcm}(a) show the whole reverse diffusion process of DDNM. For ease of understanding, we visualize the intermediate results of DDNM in Appendix \ref{ddnm visualization}. By using a denoising network  pre-trained for general generative purposes, DDNM can solve IR tasks with arbitrary forms of linear degradation operator . It does not need task-specific training or optimization and forms a zero-shot solution for diverse IR tasks. 

It is worth noting that our method is compatible with most of the recent advances in diffusion models, e.g., DDNM can be deployed to score-based models \citep{song2019generative,song2020score} or combined with DDIM \citep{song2021denoising} to accelerate the sampling speed.


\begin{figure}
\begin{minipage}{.39\textwidth}
    \vspace{-0.5cm}
    \begin{algorithm}[H]
    \scriptsize
    \caption{Sampling of DDNM}
    \label{alg:ndm}
    \begin{algorithmic}[1]
        \State 
        \For{}
            \item[]
            \item[]
            \item[]
            \State 
            \State 
            \State 
        \EndFor
        \State \textbf{return} 
    \end{algorithmic}
    \end{algorithm}
\end{minipage}
\begin{minipage}{.59\textwidth}
    \vspace{-0.5cm}
        \begin{algorithm}[H]
        \scriptsize
        \caption{Sampling of DDNM\textcolor{blue}{}}
        \label{alg:ndm+}
        \begin{algorithmic}[1] \State 
            \For{}
                    \State 
                    \State 
                    \For{}
\State 
                        \State 
                        \State
                \EndFor
            \EndFor
        \State \textbf{return} 
        \end{algorithmic}
        \end{algorithm}
\end{minipage}
\vspace{-0.5em}
\end{figure}


\begin{figure*}[t]
  \centering
  \includegraphics[width=1\linewidth]{im/fig2.pdf}
  \vspace{-0.5cm}
  \caption{Illustration of (a) DDNM and (b) the time-travel trick.}
  \vspace{-0.5cm}
\label{fig:ddcm} 
\end{figure*}

\subsection{Examples of Constructing  and }
\label{cp:construct A}
Typical IR tasks usually have simple forms of  and , 
some of which are easy to construct by hand without resorting to complex Fourier transform or SVD. Here we introduce three practical examples. Inpainting is the simplest case, where  is the mask operator. Due to the unique property that , we can use  itself as . For colorization,  can be a pixel-wise operator  that converts each RGB channel pixel  into a grayscale value . It is easy to construct a pseudo-inverse  that satisfies . The same idea can be used for SR with scale , where we can set  as the average-pooling operator  that averages each patch into a single value. Similarly, we can construct its pseudo-inverse as . We provide pytorch-like codes in Appendix \ref{pseudo code}. 

Considering  as a compound operation that consists of many sub-operations, i.e., , we may still yield its pseudo-inverse . This provides a flexible solution for solving complex IR tasks, such as old photo restoration. Specifically, we can decompose the degradation of old photos as three parts, i.e., , where  is the grayscale operator,  is the average-pooling operator with scale 4, and  is the mask operator defined by the damaged areas on the photo. Hence the pseudo-inverse is . Our experiments show that these hand-designed operators work very well (Fig.~\ref{fig:front}(a,b,d)).



\subsection{Enhanced Version: DDNM}
\label{cp:DDNM+}
DDNM can solve noise-free IR tasks well but fails to handle noisy IR tasks and yields poor \textit{Realness} in the face of some particular forms of . To overcome these two limits, as described by \textbf{Algo.}~\ref{alg:ndm+}, we propose an enhanced version, dubbed DDNM, by making the following two major extensions to DDNM to enable it to handle noisy situations and improve its restoration quality. 

\paragraph{Scaling Range-Space Correction to Support Noisy Image Restoration} We consider noisy IR problems in the form of , where  represents the additive Gaussian noise and  represents the clean measurement. Applying DDNM directly yields 

where  is the extra noise introduced into  and will be further introduced into .  is the correction for the range-space contents, which is the key to \textit{Consistency}. To solve noisy image restoration, we propose to modify DDNM (on Eq.~\ref{eq:ndm core} and Eq.~\ref{eq:ndm_xt-1}) as: 


 is utilized to scale the range-space correction  and   is used to scale the added noise  in . The choice of  and  follows two principles: (\romannumeral1)  and  need to assure the total noise variance in  conforms to the definition in  (Eq.~\ref{eq:ddpm forward 2}) so the total noise can be predicted by  and gets removed; (\romannumeral2)  should be as close as possible to  to maximize the preservation of the range-space correction  so as to maximize the \textit{Consistency}. For SR and colorization defined in Sec.\ref{cp:construct A},  is copy operation. Thus  can be approximated as a Gaussian noise , then  and  can be simplified as  and . Since , principle (\romannumeral1) is equivalent to:  with  denotes . Considering principle (\romannumeral2), we set: 

In addition to the simplified version above, we also provide a more accurate version for general forms of , where we set , .  is derived from the SVD of the operator 
. The calculation of  and  are presented in Appendix ~\ref{ap:ndm+}. Note that the only hyperparameter that need manual setting is .

We can also approximate non-Gaussian noise like Poisson, speckle, and real-world noise as Gaussian noise, thereby estimating a noise level  and resorting to the same solution mentioned above.

\paragraph{Time-Travel For Better Restoration Quality} We find that DDNM yields inferior \textit{Realness} when facing particular cases like SR with large-scale average-pooling downsampler, low sampling ratio compressed sensing(CS), and inpainting with a large mask. In these cases, the range-space contents  is too local to guide the reverse diffusion process toward yielding a global harmony result.

Let us review Eq.~\ref{eq:mu}. We can see that the mean value  of the posterior distribution  relies on accurate estimation of . DDNM uses  as the estimation of  at time-step , but if the range-space contents  is too local or uneven,  may have disharmonious null-space contents. How can we salvage the disharmony? Well, we can time travel back to change the past. Say we travel back to time-step , we can yield the next state  using the ``future" estimation  , which should be more accurate than . By reparameterization, this operation is equivalent to sampling  from . Similar to \cite{lugmayr2022repaint} that use a ``back and forward" strategy for inpainting tasks, we propose a time-travel trick to improve global harmony for general IR tasks: For a chosen time-step , we sample  from . Then we travel back to time-step  and repeat normal DDNM sampling (Eq.~\ref{eq:x0t}, Eq.~\ref{eq:ndm core}, and Eq.~\ref{eq:ndm_xt-1}) until yielding .  is actually the travel length. Fig.~\ref{fig:ddcm}(b) illustrates the basic time-travel trick.

Intuitively, the time-travel trick produces a better ``past", which in turn produces a better ``future". For ease of use, we assign two extra hyperparameters:  controls the interval of using the time-travel trick;  determines the repeat times. The time-travel trick in Algo.~\ref{alg:ndm+} is with , . Fig.~\ref{fig:ndm+}(b) and the right part in Tab.~\ref{fig:ndm+} demonstrate the improvements that the time-travel trick brings. 



It is worth emphasizing that although Algo.~\ref{alg:ndm} and Algo.~\ref{alg:ndm+} are derived based on DDPM, they can also be easily extended to other diffusion frameworks, such as DDIM \citep{song2021denoising}. Obviously, DDNM becomes exactly DDNM when setting , , and .

\begin{table*}[t]
    \centering
\scriptsize
    \begin{tabular}{cccccc}
        \hline
           \multicolumn{1}{c}{\rule{0pt}{10pt}\scriptsize\textbf{ImageNet}}&\multicolumn{1}{c}{{4 SR}} &\multicolumn{1}{c}{Deblurring}&\multicolumn{1}{c}{Colorization}&\multicolumn{1}{c}{CS 25\%}&\multicolumn{1}{c}{Inpainting}\\
           \rule{0pt}{10pt}Method& PSNR↑/SSIM↑/FID↓ & PSNR↑/SSIM↑/FID↓ &  \textit{Cons}↓/FID↓ &  PSNR↑/SSIM↑/FID↓ &  PSNR↑/SSIM↑/FID↓\\
        \hline
            \rule{0pt}{10pt}{} &24.26 / 0.684 / 134.4 &18.56 / 0.6616 / 55.42
            &0.0 / 43.37 &15.65 / 0.510 / 277.4&14.52 / 0.799 / 72.71\\
            \rule{0pt}{10pt}{DGP} &23.18 / 0.798 / 64.34&{N/A}& - / 69.54& {N/A}& {N/A}\\
            \rule{0pt}{10pt}{ILVR} &27.40 / \textbf{0.870} / 43.66&{N/A}& {N/A}& {N/A}& {N/A}\\
            \rule{0pt}{10pt}{RePaint} &{N/A}&{N/A}& {N/A}& {N/A}& 31.87 / \textbf{0.968} / 12.31\\
            \rule{0pt}{10pt}{DDRM} &27.38 / 0.869 / 43.15&43.01 / 0.992 / 1.48 
            &260.4 / 36.56&19.95 / 0.704 / 97.99 &31.73 / 0.966 / 4.82\\
            \rule{0pt}{10pt}{\textbf{DDNM}(ours)} &\textbf{27.46 / 0.870/ 39.26}&\textbf{44.93 / 0.994 / 1.15}
            &\textbf{42.32 / 36.32} &\textbf{21.66 / 0.749 / 64.68} &\textbf{32.06 / 0.968 / 3.89}\\
        \hline
    \end{tabular}
    \begin{tabular}{cccccc}
        \hline
           \multicolumn{1}{c}{\rule{0pt}{10pt}\textbf{CelebA}}&\multicolumn{1}{c}{{4 SR}} &\multicolumn{1}{c}{Deblurring}&\multicolumn{1}{c}{Colorization}&\multicolumn{1}{c}{CS 25\%}&\multicolumn{1}{c}{Inpainting}\\
           \rule{0pt}{10pt}Method& PSNR↑/SSIM↑/FID↓ & PSNR↑/SSIM↑/FID↓ &  \textit{Cons}↓/FID↓ &  PSNR↑/SSIM↑/FID↓ &  PSNR↑/SSIM↑/FID↓\\
        \hline
            \rule{0pt}{10pt}{} &27.27 / 0.782 / 103.3 &18.85 / 0.741 / 54.31
            &0.0 / 68.81&15.09 / 0.583 / 377.7& 15.57 / 0.809 / 181.56\\
            \rule{0pt}{10pt}{PULSE} &22.74 / 0.623 / 40.33&{N/A}& {N/A}& {N/A}& {N/A}\\
            \rule{0pt}{10pt}{ILVR} &31.59 / \textbf{0.945} / 29.82 &{N/A}& {N/A}& {N/A}& {N/A}\\
            \rule{0pt}{10pt}{RePaint} &{N/A}&{N/A}& {N/A}& {N/A}&35.20 / 0.981 /14.19\\
            \rule{0pt}{10pt}{DDRM} &\textbf{31.63} / \textbf{0.945} / 31.04&43.07 / 0.993 / 6.24
            &455.9 / 31.26&24.86 / 0.876 / 46.77&34.79 / 0.978 /12.53\\
            \rule{0pt}{10pt}{\textbf{DDNM}(ours)} &\textbf{31.63 / 0.945 / 22.27}&\textbf{46.72 / 0.996 / 1.41}   &\textbf{26.25 / 26.44}&\textbf{27.56 / 0.909 / 28.80}&\textbf{35.64 / 0.982 /4.54}\\
        \hline
    \end{tabular}
    \caption{Quantitative results of zero-shot IR methods on \textbf{ImageNet}(\textit{top}) and \textbf{CelebA}(\textit{bottom}), including five typical IR tasks. We mark N/A for those not applicable and \textbf{bold} the best scores.}
    \label{tb:ndm}
\end{table*}

\begin{figure*}[t]
  \centering
\includegraphics[width=1\linewidth]{im/fig3.pdf}
  \vspace{-0.4cm}
  \caption{Qualitative results of zero-shot IR methods. }
  \vspace{-0.1cm}
\label{fig:ndm+ comprehensive} 
\end{figure*}


\section{Experiments}
Our experiments consist of three parts. Firstly, we evaluate the performance of DDNM on five typical IR tasks and compare it with state-of-the-art zero-shot IR methods. Secondly, we experiment DDNM on three typical IR tasks to verify its improvements against DDNM. Thirdly, we show that DDNM and DDNM perform well on challenging real-world applications.


\subsection{Evaluation on DDNM}
To evaluate the performance of DDNM, we compare DDNM with recent state-of-the-art zero-shot IR methods: DGP\citep{chen2020deep}, Pulse\citep{menon2020pulse}, ILVR\citep{choi2021ilvr}, RePaint\citep{lugmayr2022repaint} and DDRM\citep{kawar2022denoising}. We experiment on five typical noise-free IR tasks, including 4 SR with bicubic downsampler, deblurring with Gaussian blur kernel, colorization with average grayscale operator, compressed sensing (CS) using Walsh-Hadamard sampling matrix with a 0.25 compression ratio, and inpainting with text masks. For each task, we use the same degradation operator for all methods. We choose ImageNet 1K and CelebA 1K datasets with image size 256256 for validation. For ImageNet 1K, we use the 256256 denoising network as , which is pretrained on ImageNet by \cite{dhariwal2021diffusion}. For CelebA 1K, we use the 256256 denoising network pretrained on CelebA by \cite{lugmayr2022repaint}. For fair comparisons, we use the same pretrained denoising networks for ILVR, RePaint, DDRM, and DDNM. We use DDIM as the base sampling strategy with , 100 steps, without classifier guidance, for all diffusion-based methods. We choose PSNR, SSIM, and FID \citep{fid} as the main metrics. Since PSNR and SSIM can not reflect the colorization performance, we use FID and the \textit{Consistency} metric (calculated by  and denoted as \textit{Cons}) for colorization.


Tab.~\ref{tb:ndm} shows the quantitative results. For those tasks that are not supported, we mark them as ``NA". We can see that DDNM far exceeds previous GAN prior based zero-shot IR methods (DGP, PULSE). Though with the same pretrained denoising models and sampling steps, DDNM achieves significantly better performance in both \textit{Consistency} and \textit{Realness} than ILVR, RePaint, and DDRM. Appendix ~\ref{extensive exp ndm} shows more quantitative comparisons and qualitative results.  

\begin{figure*}[t]
  \centering
  \vspace{-0.5cm}
  \includegraphics[width=1\linewidth]{im/fig4.pdf}
  \vspace{-0.5cm}
  \caption{DDNM improves (a) denoising performance and (b) restoration quality.}
\label{fig:ndm+} 
\end{figure*}
\begin{table*}[t]
    \centering
    \scriptsize
    \begin{tabular}{c|ccc|ccc}
        \hline
           \multicolumn{1}{c}{\rule{0pt}{10pt}\textbf{CelebA}}&\multicolumn{1}{|c}{{16 SR =0.2}} &\multicolumn{1}{c}{C =0.2}&\multicolumn{1}{c}{CS ratio=25\% =0.2}&\multicolumn{1}{|c}{{32 SR}} &\multicolumn{1}{c}{C}&\multicolumn{1}{c}{CS ratio=10\%}\\
           \rule{0pt}{10pt}Method& PSNR↑/SSIM↑/FID↓ &  FID↓&  PSNR↑/SSIM↑/FID↓& PSNR↑/SSIM↑/FID↓ &  FID↓&  PSNR↑/SSIM↑/FID↓\\
        \hline
            \rule{0pt}{10pt}{DDNM} &13.10 / 0.2387 / 281.45& 216.74
            &17.89 / 0.4531 / 82.81&17.55 / 0.437 / 39.37&22.79&15.74/ 0.275 / 110.7
            \\   
            \rule{0pt}{10pt}{DDNM} &\textbf{19.44 / 0.712 / 58.31 }& \textbf{46.11}
            &\textbf{25.02 / 0.868 / 51.35} &\textbf{18.44 / 0.501 / 37.50}& \textbf{18.23}&\textbf{26.33 / 0.741 / 47.93}
            \\
        \hline
    \end{tabular}
    \caption{Ablation study on denoising improvements (\textit{left}) and the time-travel trick (\textit{right}). C represents the colorization task.  denotes the noise variance on .
    }
    \vspace{-0.2cm}
    \label{tb:ndm+}
\end{table*}

\vspace{-0.2cm}
\subsection{Evaluation on DDNM}
We evaluate the performance of DDNM from two aspects: the denoising performance and the robustness in restoration quality.

\textbf{Denoising Performance.} We experiment DDNM on three noisy IR tasks with , i.e., we disable the time-travel trick to only evaluate the denoising performance. Fig.~\ref{fig:ndm+}(a) and the left part in Tab.~\ref{tb:ndm+} show the denoising improvements of DDNM against DDNM. We can see that DDNM fully inherits the noise contained in , while DDNM decently removes the noise.

\textbf{Robustness in Restoration Quality.} We experiment DDNM on three tasks that DDNM may yield inferior results, they are 32 SR, colorization, and compressed sensing (CS) using orthogonalized sampling matrix with a 10\% compression ratio. For fair comparison, we set , ,  for DDNM while set  for DDNM so that the total sampling steps and computational consumptions are roughly equal. Fig.~\ref{fig:ndm+}(b) and the right part in Tab.~\ref{tb:ndm+} show the improvements of the time-travel trick. We can see that the time-travel trick significantly improves the overall performance, especially the \textit{Realness} (measured by FID).

To the best of our knowledge, DDNM is the first IR method that can robustly handle arbitrary scales of linear IR tasks. As is shown in Fig.~\ref{fig:ndm+ comprehensive}, We compare DDNM (, ) with state-of-the-art zero-shot IR methods on diverse IR tasks. We also crop images from DIV2K dataset \citep{div2k} as the testset. The results show that DDNM owns excellent robustness in dealing with diverse IR tasks, which is remarkable considering DDNM as a zero-shot method. More experiments of DDNM/DDNM can be found in Appendix \ref{ap: time and memory} and \ref{ap: compare supervised}.

\subsection{Real-World Applications}
Theoretically, we can use DDNM to solve real-world IR task as long as we can construct an approximate linear degradation  and its pseudo-inverse . Here we demonstrate two typical real-world applications using DDNM with , : (1) \textbf{Real-World Noise.} We experiment DDNM on real-world colorization with  and  defined in Sec.~\ref{cp:construct A}. We set  by observing the noise level of . The results are shown in Fig.~\ref{fig:jpeg}, Fig.~\ref{fig:rebuttal-fig1}, and Fig.~\ref{fig:front}(c). (2) \textbf{Old Photo Restoration.}  For old photos, we construct  and  as described in Sec ~\ref{cp:construct A}, where we manually draw a mask for damaged areas on the photo. The results are shown in Fig.~\ref{fig:front}(d), and Fig.~\ref{fig:old photo additional}.



\section{Related Work}
\subsection{Diffusion Models for Image Restoration}
Recent methods using diffusion models to solve image restoration can be roughly divided into two categories: supervised methods and zero-shot methods.

\textbf{Supervised Methods.} SR3 \citep{sr3} trains a conditional diffusion model for image super-resolution with synthetic image pairs as the training data. This pattern is further promoted to other IR tasks \citep{saharia2022palette}. To solve image deblurring, \cite{whang2022deblurring} uses a deterministic predictor to estimate the initial result and trains a diffusion model to predict the residual. However, these methods all need task-specific training and can not generalize to different degradation operators or different IR tasks.

\textbf{Zero-Shot Methods.} \cite{song2019generative} first propose a zero-shot image inpainting solution by guiding the reverse diffusion process with the unmasked region. They further propose using gradient guidance to solve general inverse problems in a zero-shot fashion and apply this idea to medical imaging problems \citep{song2020score,song2021solving}. ILVR \citep{choi2021ilvr} applies low-frequency guidance from a reference image to achieve reference-based image generation tasks. RePaint \citep{lugmayr2022repaint} solves the inpainting problem by guiding the diffusion process with the unmasked region. DDRM \citep{kawar2022denoising} uses SVD to decompose the degradation operators. However, SVD encounters a computational bottleneck when dealing with high-dimensional matrices. Actually, the core guidance function in ILVR \citep{choi2021ilvr}, RePaint \citep{lugmayr2022repaint} and DDRM \citep{kawar2022denoising} can be seen as special cases of the range-null space decomposition used in DDNM, detailed analysis is in Appendix ~\ref{ap:special cases}. 

\subsection{Range-Null Space Decomposition in Image Inverse Problems}
\cite{schwab2019deep} first proposes using a DNN to learn the missing null-space contents in image inverse problems and provide detailed theory analysis. \cite{chen2020deep} proposes learning the range and null space respectively. \cite{bahat2020explorable} achieves editable super-resolution via exploring the null-space contents. \cite{wang2022gan} apply range-null space decomposition to existing GAN prior based SR methods to improve their performance and convergence speed.


\section{Conclusion \& Discussion}
This paper presents a unified framework for solving linear IR tasks in a zero-shot manner. We believe that our work demonstrates a promising new path for solving general IR tasks, which may also be instructive for general inverse problems. Theoretically, our framework can be easily extended to solve inverse problems of diverse data types, e.g., video, audio, and point cloud, as long as one can collect enough data to train a corresponding diffusion model. More discussion is in Appendix \ref{cp: limitations}.


\begin{figure*}[t]
  \centering
  \vspace{-0.5cm}
  \includegraphics[width=1\linewidth]{im/maskshift.pdf}
  \vspace{-0.5cm}
  \caption{4SR using Mask-Shift trick, DDNM. Input size: 64256; output size: 2561024.}
\label{fig:maskshift} 
\end{figure*}

\section{Mask-Shift Trick}
In this section, we propose a Mask-Shift trick that enables DDNM to \textcolor{blue}{solve IR tasks with arbitrary desired output sizes}, e.g., \textcolor{blue}{4K} images.

Diffusion models usually have a strict constraint on output image size. Assume the default DDNM yields results of size 256256. We have a low-resolution image  with size 64256 and want to SR it into size 2561024. The simplest way is to divide  into 4 images with resolution 6464, then use DDNM to yield 4 SR results and concatenate them as the final result. However, this will bring significant block artifacts between each division.

Here we propose a simple but effective trick to perfectly solve this problem. Let's take the above example. First, we divide  into 8 parts [], each part is a 6432 image. In the first turn, we take [,] as the input and use DDNM to get the SR result , we further divide it as [,]. Next, we need to run 6 turns of DDNM. For the th turn, we use [,] as the input and divide the intermediate result  as [] and replace its left by

The final result is [, ..., ], as shown in Fig.~\ref{fig:maskshift}. This method assures the reconstruction is always coherent between shifts. We call it the Mask-Shift trick. For input image  with an arbitrary size, we can first zero-pad it into regular size, then divide it vertically and horizontally. Then use a similar Mask-Shift trick to ensure the vertical and horizontal coherence of the final output result.




\bibliography{iclr2023_conference}
\bibliographystyle{iclr2023_conference}

\newpage

\appendix

\section{Time \& Memory Consumption}
\label{ap: time and memory}
Our method has obvious advantages in time \& memory consumption among recent zero-shot diffusion-based restoration methods \citep{kawar2022denoising,ho2022video,chung2022improving,chung2022diffusion}. These methods are all based on basic diffusion models, the differences are how to bring the constraint  into the reverse diffusion process. We conclude our advantages as below:
\begin{itemize}
\item DDNM yields almost the same consumption as the original diffusion models.
\item DDNM does not need any optimization toward minimizing  since we directly yield the optimal solution by range-null space decomposition (Section 3.1) and precise range-space denoising (Section 3.3). We notice some recent works \citep{ho2022video,chung2022improving,chung2022diffusion} resort to such optimization, e.g., DPS \citep{chung2022diffusion} uses  to update ; however, this involves costly gradient computation. 
\item Unlike DDRM \citep{kawar2022denoising}, our DDNM does not necessarily need SVD. As is presented in Section 3.2, we construct  and  for colorization, inpainting, and super-resolution problems \textbf{by hand}, which bring negligible computation and memory consumption. In contrast, SVD-based methods suffer heavy cost on memory and computation if  has a high dimension (e.g., 128xSR, as shown below). 
\end{itemize}

Experiments in Tab.~\ref{tb:ddnm time and memory} well support these claims.

\begin{table*}[h]
\scriptsize
\centering
    \begin{tabular}{c | cccc | cc| cc}
    \hline
           \multicolumn{1}{c}{\rule{0pt}{8pt}\tiny\textbf{ImageNet}}&\multicolumn{4}{|c}{4 SR} &\multicolumn{2}{|c}{64 SR}&\multicolumn{2}{|c}{128 SR}\\
        \hline
           \rule{0pt}{8pt}Method& PSNR↑&FID↓ & Time(s/image) & Memory(MB)& Time & Memory & Time & Memory \\
        \hline
            \rule{0pt}{8pt}{DDPM*} &N/A&N/A &11.9&5758&11.9&5758&11.9&5758\\
            \rule{0pt}{8pt}{DPS} &25.51&55.92 &36.5&8112 &-&-&-&-\\
            \rule{0pt}{8pt}{DDRM} &\textbf{27.05}&38.05 &12.4&5788 &36.4&5788&83.3&6792\\
            \rule{0pt}{8pt}{\textbf{DDNM}} & 27.04&\textbf{33.81}&\textbf{11.9}& \textbf{5728}&\textbf{11.9}& \textbf{5728}&\textbf{11.9}& \textbf{5728}\\
        \hline
    \end{tabular}
    \caption{Comparisons on Time \& Memory Consumption. We use the average-pooling downsampler, 4 SR, 100 DDIM steps with =0.85 and without classifier guidance, on a single 2080Ti GPU with batch size 1. For DPS, we set =100. *The DDPM here is tested on unconditional generation.}
    \label{tb:ddnm time and memory}
\end{table*}

\section{Comparing DDNM with Supervised Methods}
\label{ap: compare supervised}
Our method is superior to existing supervised IR methods \citep{zhang2021designing,liang2021swinir} in these ways:
\begin{itemize}
\item DDNM is zero-shot for diverse tasks, but supervised methods need to train separate models for each task.
\item DDNM is robust to degradation modes, but supervised methods own poor generalized performance.
\item DDNM yields significantly better performance on certain datasets and resolutions (e.g., ImageNet at 256x256).
\end{itemize}
These claims are well supported by experiments in Tab.~\ref{tb:ddnm supervised}.

\begin{table*}[h]
\scriptsize
\centering
    \begin{tabular}{c | ccc | ccc| ccc|c}
    \hline
           \multicolumn{1}{c}{\rule{0pt}{8pt}\tiny\textbf{ImageNet}}&\multicolumn{3}{|c}{Bicubic, =0} &\multicolumn{3}{|c}{Average-pooling, =0}&\multicolumn{3}{|c}{Average-pooling, =0.2}&\multicolumn{1}{|c}{Inference time}\\
        \hline
           \rule{0pt}{8pt}Method& PSNR↑&SSIM↑&FID↓ & PSNR↑&SSIM↑&FID↓ & PSNR↑&SSIM↑&FID↓&s/image \\
        \hline
            \rule{0pt}{8pt}{SwinIR-L} &21.21&0.7410&56.77 &23.88&0.8010&54.93 &18.39&0.5387&134.18&6.1\\
            \rule{0pt}{8pt}{BSRGAN} &21.46&0.7384&68.15 &24.14&0.7948&67.70 &14.06&0.3663&195.41&\textbf{0.036}\\
            \rule{0pt}{8pt}{DDNM} & \textbf{27.46}&\textbf{0.8707}&\textbf{39.26}& \textbf{27.04}&\textbf{0.8651}&\textbf{33.81}& \textbf{22.67}&\textbf{0.7400}&\textbf{80.69}&11.9\\
        \hline
    \end{tabular}
    \caption{Comparisons between DDNM and supervised SR methods. DDNM uses 100 DDIM steps with =0.85 and without classifier guidance. We use the official SwinIR-L \citep{liang2021swinir} and BSRGAN \citep{zhang2021designing} pretrained for SR tasks.}
    \label{tb:ddnm supervised}
    \vspace{-0.5cm}
\end{table*}
\newpage

\section{Limitations}
\label{cp: limitations}
There remain many limitations that deserve further study. 
\begin{itemize}
    \item Though DDNM brings negligible extra cost on computations, it is still limited by the slow inference speed of existing diffusion models. 

    \item DDNM needs explicit forms of the degradation operator, which may be challenging to acquire for some tasks. Approximations may work well, but not optimal. 

    \item In theory, DDNM only supports linear operators. Though nonlinear operators may also have ``pseudo-inverse", they may not conform to the distributive property, e.g., , so they may not have linearly separable null-space and range-space. 

    \item DDNM inherits the randomness of diffusion models. This property benefits diversity but may yield undesirable results sometimes. 

    \item The restoration capabilities of DDNM are limited by the performance of the pretrained denoiser, which is related to the network capacity and the training dataset. For example, existing diffusion models do not outperform StyleGANs \citep{stylegan,stylegan2,stylegan3} in synthesizing FFHQ/AFHQ images at 10241024 resolution.

\end{itemize}

\section{Solving Real-World Degradation Using DDNM}
\label{cp: Details of Old Photo Restoration}
DDNM+ can well handle real-world degradation, where the degradation operator A is unknown and non-linear and even contains non-Gaussian noise. We follow these observations:
\begin{itemize}
\item In theory, DDNM is designed to solve IR tasks of diverse noise levels. As is shown in Fig.~\ref{fig:strong noise}, DDNM can well handle 4 SR even with a strong noise =0.9. 
\item For real-world degraded images, the non-linear artifacts can generally be divided into \textbf{global} (e.g., the real-world noise in Fig.~\ref{fig:front}(c)) and \textbf{local} (e.g., the scratches in Fig.~\ref{fig:front}(d)).
\item For \textbf{global} non-linear artifacts, we can set a proper  to cover them. As is shown in Fig.~\ref{fig:jpeg}, the input images  suffer JPEG-like unknown artifacts, but DDNM can still remove them decently by setting a proper .
\item For \textbf{local} non-linear artifacts, we can directly draw a mask to cover them. Hence all we need is to construct  and set a proper . We have proved  and  and their pseudo-inverse can be easily constructed by hand. (maybe a  is needed for resize when  is too blur)
\end{itemize}



\begin{figure*}[ht]
  \centering
  \includegraphics[width=1\linewidth]{im/strong_noise.pdf}
  \vspace{-0.5cm}
  \caption{DDNM can well handle 4 SR even with a strong noise =0.9.}
\label{fig:strong noise} 
\end{figure*}

\begin{figure*}[ht]
  \centering
  \includegraphics[width=1\linewidth]{im/jpeg.pdf}
  \vspace{-0.5cm}
  \caption{Solving JPEG-like artifacts using DDNM. Here we set  to exert a pure denoising.  denotes the input degraded image. When we set , the artifacts are decently removed. When we set , the results become smoother but yield relatively poor identity consistency.}
\label{fig:jpeg} 
\end{figure*}


\begin{figure*}[ht]
  \centering
  \includegraphics[width=1\linewidth]{im/rebuttal-fig1.pdf}
  \vspace{-0.5cm}
  \caption{Old photo restoration. Zoom in for the best view. By setting , the noise is removed, and the identity is well preserved. When we set higher , the results becomes much smoother but yield relatively poor identity consistency.}
\label{fig:rebuttal-fig1} 
\end{figure*}

In Fig.~\ref{fig:rebuttal-fig1} we demonstrate an example. The input image  is a black-and-white photo with unknown noise and scratches. We first manually draw a mask  to cover these scratches. Then we use a grayscale operator  to convert the image into grayscale. Definition of  and  and their pseudo-inverse can be find in Sec.~\ref{cp:construct A}. Then we take  and  for DDNM, and set a proper . From the results in Fig.~\ref{fig:rebuttal-fig1}, we can see that when setting , the noise is fully inherited by the results. By setting , the noise is removed, and the identity is well preserved. When we set higher , the results becomes much smoother but yield relatively poor identity consistency. 

The choice of  is critical to achieve the best balance between realness and consistency. But for now we can only rely on manual estimates.


\newpage


\lstset{ language=python,                basicstyle=\scriptsize,           numbers=left,                   numberstyle=\tiny\color{gray},  stepnumber=2,                   numbersep=5pt,                  backgroundcolor=\color{white},      showspaces=false,               showstringspaces=false,         showtabs=false,                 frame=single,                   rulecolor=\color{black},        tabsize=2,                      captionpos=b,                   breaklines=true,                breakatwhitespace=false,        title=\lstname,                 keywordstyle=\color{blue},          commentstyle=\color{green},       stringstyle=\color{orange},         escapeinside={\%*}{*)},            morekeywords={*,...}               }


\section{PyTorch-Like Code Implementation}
\label{pseudo code}

Here we provide a basic PyTorch-Like implementation of DDNM. Readers can quickly implement a basic DDNM on their own projects by referencing Algo.~\ref{alg:ndm+} and Sec.~\ref{cp:DDNM+} and the code below.


\begin{lstlisting}

def color2gray(x):
    coef=1/3
    x = x[:,0,:,:] * coef + x[:,1,:,:]*coef +  x[:,2,:,:]*coef
    return x.repeat(1,3,1,1)

def gray2color(x):
    x = x[:,0,:,:]
    coef=1/3
    base = coef**2 + coef**2 + coef**2
    return th.stack((x*coef/base, x*coef/base, x*coef/base), 1)      
    
def PatchUpsample(x, scale):
    n, c, h, w = x.shape
    x = torch.zeros(n,c,h,scale,w,scale) + x.view(n,c,h,1,w,1)
    return x.view(n,c,scale*h,scale*w)

# Implementation of A and its pseudo-inverse Ap    
    
if IR_mode=="colorization":
    A = color2gray
    Ap = gray2color
    
elif IR_mode=="inpainting":
    A = lambda z: z*mask
    Ap = A
      
elif IR_mode=="super resolution":
    A = torch.nn.AdaptiveAvgPool2d((256//scale,256//scale))
    Ap = lambda z: PatchUpsample(z, scale)

elif IR_mode=="old photo restoration":
    A1 = lambda z: z*mask
    A1p = A1
    
    A2 = color2gray
    A2p = gray2color
    
    A3 = torch.nn.AdaptiveAvgPool2d((256//scale,256//scale))
    A3p = lambda z: PatchUpsample(z, scale)
    
    A = lambda z: A3(A2(A1(z)))
    Ap = lambda z: A1p(A2p(A3p(z)))
    

# Core Implementation of DDNM+, simplified denoising solution
# For more accurate denoising, please refer to Appendix I and the full source code.

def ddnmp_core(x0t, y, sigma_y, sigma_t, a_t):

    #Eq 19
    if sigma_t >= a_t*sigma_y: 
        lambda_t = 1
        gamma_t = sigma_t**2 - (a_t*lambda_t*sigma_y)**2
    else:
        lambda_t = sigma_t/(a_t*sigma_y)
        gamma_t = 0
        
    #Eq 17    
    x0t= x0t + lambda_t*Ap(y - A(x0t))
    
    return x0t, gamma_t
    
\end{lstlisting}



\newpage

\section{Details of The Degradation Operators}

\paragraph{Super Resolution (SR).} For SR experiments in Tab.~\ref{tb:ndm}, we use the bicubic downsampler as the degradation operator to ensure fair comparisons. For other cases in this paper, we use the average-pooling downsampler as the degradation operator, which is easy to get the pseudo-inverse as described in Sec.~\ref{cp:construct A}. Fig.~\ref{fig:all_degradation}(a) and Fig.~\ref{fig:all_degradation}(b) show examples of the bicubic operation and the average-pooling operation.

\paragraph{Inpainting.} We use text masks, random pixel-wise masks, and hand-drawn masks for inpainting experiments. Fig.\ref{fig:all_degradation}(d) demonstrates examples of different masks.

\paragraph{Deblurring.} For deblurring experiments, We use three typical kernels to implement blurring operations, including Gaussian blur kernel, uniform blur kernel, and anisotropic blur kernel. For Gaussian blur, the kernel size is 5 and kernel width is 10; For uniform blur kernel, the kernel size is 9; For anisotropic blur kernel, the kernel size is 9 and the kernel widths of each axis are 20 and 1. Fig.\ref{fig:all_degradation}(c) demonstrates the effect of these kernels.

\paragraph{Compressed Sensing (CS).} For CS experiments, we choose two types of sampling matrices: one is based on the Walsh-Hadamard transformation, and the other is an orthogonalized random matrix applied to the original image block-wisely. For the Walsh-Hadamard sampling matrix, we choose 50\% and 25\% as the sampling ratio. For the orthogonalized sampling matrix, we choose ratios from 40\% to 5\%. Fig.\ref{fig:all_degradation}(e) and (f) demonstrate the effects of the Walsh-Hadamard sampling matrix and orthogonalized sampling matrix with different CS ratios.

\paragraph{Colorization.} For colorization, we choose the degradation matrix  for each pixel as we described in Sec.~\ref{cp:construct A}. Fig.\ref{fig:all_degradation}(g) demonstrates the example of colorization degradation.

\paragraph{Solve the Pseudo-Inverse Using SVD} Considering we have a linear operator , we need to compute its pseudo-inverse  to implement the algorithm of 
the proposed DDNM. For some simple degradation like inpainting, colorization, and SR based on average pooling, the pseudo-inverse  can be constructed manually, which has been discussed in Sec.~\ref{cp:construct A}. For general cases, we can use the singular value decomposition (SVD) of  to compute the pseudo-inverse  where  and  have the following relationship:

where  means the -th singular value of  and  means the -th diagonal element of .


\section{Visualization of The Intermediate Results}
\label{ddnm visualization}
In Fig.~\ref{fig:intermediate}, we visualize the intermediate results of DDNM on 4 SR, 16 SR, and deblurring. Specifically, we show the noisy result , the clean estimation , and the rectified clean estimation . The total diffusion step is 1000. From Fig.~\ref{fig:intermediate}(a), we can see that due to the fixed range-space contents ,  already owns meaningful contents in early stages while  and  contains limited information. But when , we can observe that  contains much more details than . These details are precisely the null-space contents. We may notice a potential speed-up trick here. For example, we can replace  with  and start DDNM directly from , which yields a 10 times faster sampling. We leave it to future work. From Fig.~\ref{fig:intermediate}(b), we can see that the reverse diffusion process gradually restores images from low-frequency contours to high-frequency details.

\newpage


\begin{figure*}[ht]
  \centering
   \vspace{-0.5cm}
  \includegraphics[width=1\linewidth]{im/each.pdf}
   \vspace{-0.5cm}
  \caption{Visualization of different degradation operators. (a) Bicubic downsampler. The scale factors from left to right are 4, 8, 16, 32; (b) Average-pooling downsampler. The scale factors from left to right are 4, 8, 16, 32; (c) Blur operators. The type of kernels from left to right are Gaussian, uniform, and anisotropic; (d) Masks; (e) Walsh-Hadamard sampling matrix. The sampling ratios from left to right are 0.5 and 0.25; (f) Block-based sampling matrix. The sampling ratios from left to right are 0.4, 0.3, 0.2, 0.1, 0.05; (g) Grayscale operator.}
\label{fig:all_degradation} 
\end{figure*}

\begin{figure*}[ht]
  \centering
   \vspace{-0.2cm}
  \includegraphics[width=1\linewidth]{im/ablation1.pdf}
   \vspace{-0.5cm}
  \caption{Visualization of the intermediate results in DDNM. Zoom-in for the best view.}
   \vspace{-0.8cm}
\label{fig:intermediate} 
\end{figure*}


\newpage


\newpage

\section{Comparing DDNM With Recent Diffusion-Based IR methods}
\label{ap:special cases}
Here we provide detailed comparison between DDNM and recent diffusion-based IR methods, including RePaint \citep{lugmayr2022repaint}, ILVR \citep{choi2021ilvr}, DDRM \citep{kawar2022denoising}, SR3 \citep{sr3} and SDE \citep{song2020score}. For easier comparison, we rewrite their algorithms based on DDPM \citep{ho2020denoising} and follow the characters used in DDNM. Algo.~\ref{alg:ddpm}, Algo.~\ref{alg:ddnm appendix version} show the reverse diffusion process of DDPM and DDNM. We mark in \textcolor{blue}{blue} those that are most distinct from DDNM.
All the IR problems discussed here can be formulated as

where , , ,  represents the degraded image, the degradation operator, the original image, and the additive noise, respectively.

\subsection{RePaint and ILVR.}
RePaint \citep{lugmayr2022repaint} solves noise-free image inpainting problems, where  and  represents the mask operation. RePaint first create a noised version of the masked image 

Then uses  to fill in the unmasked regions in :

Besides, RePaint applies an ``back and forward" strategy to refine the results. Algo.~\ref{alg:repaint} shows the algorithm of RePaint.

ILVR \citep{choi2021ilvr} focuses on reference-based image generation tasks, where  and  represents a low-pass filter defined by  ( is a bicubic upsampler and  is a bicubic downsampler). ILVR creates a noised version of the reference image  and uses the low-pass filter  to extract its low-frequency contents:

Then combines the high-frequency part of  with the low-frequency contents in :

Algo.~\ref{alg:ilvr} shows the algorithm of ILVR. 

Essentially, RePaint and ILVR share the same formulations, with different definitions of the degradation operator . DDNM differs from RePaint and ILVR mainly in two parts: 

(\romannumeral1) \textbf{Operating on Different Domains.} RePaint and ILVR all operate on the noisy  domain of diffusion models, which is inaccurate in range-space preservation during the reverse diffusion process. Instead, we directly operate on the noise-free  domain, which does not need extra process on  and is strictly derived from the theory and owns strict data consistency. 

(\romannumeral2) \textbf{As Special Cases.} Aside from the difference in operation domain, Eq.~\ref{eq:repaint xt-1} of RePaint is essentially a special case of the range-null space decomposition. Considering  as a mask operator, it satisfies , so  we can use  itself as the pseudo-inverse . Hence the range-null space decomposition becomes , which is exactly the same as Eq.~\ref{eq:repaint xt-1}. Similarly, Eq.~\ref{eq:ilvr xt-1} of ILVR can be seen as a special case of range-null space decomposition, which uses  as the approximation of . Note that the final result  of RePaint satisfies \textit{Consistency}, i.e., , while ILVR does not because the pseudo-inverse  they used is inaccurate.   

\begin{algorithm}\caption{Reverse Diffusion Process of DDPM}
\label{alg:ddpm}
\textbf{Require}: \textcolor{blue}{None}
\begin{algorithmic}[1] \State .
\For{}
\State  if , else .
\State 
\EndFor
\State \textbf{return} 
\end{algorithmic}
\end{algorithm}

\begin{algorithm}
\caption{Reverse Diffusion Process of DDNM Based On DDPM}
\label{alg:ddnm appendix version}
\textbf{Require}: The degraded image , the degradation operator  and its pseudo-inverse 
\begin{algorithmic}[1] \State .
\For{}
\State  if , else .
\State 
\State 
\State 
\EndFor
\State \textbf{return} 
\end{algorithmic}
\end{algorithm}



\begin{algorithm}\caption{Reverse Diffusion Process of RePaint}
\label{alg:repaint}
\textbf{Require}: The masked image , the mask 
\begin{algorithmic}[1] \State .
\For{}
\For{}
\State  if , else .
\State \textcolor{blue}{}
\label{alg:repaint yt}
\State 
\State 
\label{alg:repaint rnd}
\If{ and }
\State 
\label{alg:repaint loop}
\EndIf
\EndFor
\EndFor
\State \textbf{return} 
\end{algorithmic}
\end{algorithm}



\begin{algorithm}\caption{Reverse Diffusion Process of ILVR}
\label{alg:ilvr}
\textbf{Require}: The \textcolor{blue}{reference image , the low-pass filter }
\begin{algorithmic}[1] \State .
\For{}
\State  if , else .
\State 
\label{alg:ilvr xt}
\State 
\State 
\label{alg:ilvr rnd}
\EndFor
\State \textbf{return} 
\end{algorithmic}
\end{algorithm}



\newpage


\begin{algorithm}\caption{Reverse Diffusion Process of DDRM}
\label{alg:ddrm}
\textbf{Require}: The degraded image  with noise level , the operator , 
\begin{algorithmic}[1] \State .
\State \textcolor{blue}{}
\For{}
\State  if , else .
\State 
\For{}
\If{}
\label{alg:ddrm seq0}
\State 
\label{alg:ddrm null}
\ElsIf{}
\State 
\ElsIf{}
\label{alg:ddrm sneq0}
\State 
\label{alg:ddrm range}
\EndIf
\EndFor
\State 
\EndFor
\State \textbf{return} 
\end{algorithmic}
\end{algorithm}



\subsection{DDRM} The forward diffusion process defined by DDRM is

The original reverse diffusion process of DDRM is based on DDIM, which is

For noisy linear inverse problem  where , DDRM first uses SVD to decompose  as , then use  and  for derivation. Each element in  and  corresponds to a singular value in (the nonexistent singular value is defined as 0), hence it is possible to modify  element-wisely according to each singular value. Then one can yield the final result  by . Algo.~\ref{alg:ddrm} describes the whole reverse diffusion process of DDRM. 

For noise-free() situation, the final result  of DDRM is essentially yielded through a special range-null space decomposition. Specifically,  when  and , we can rewrite the formula of the -th element of  as:

To simplify the representation, we define a diagonal matrix : 

Then we can rewrite  as

and yield the result  by left multiplying :

This result is essentially a special range-null space decomposition:

Now we can clearly see that  is the range-space part while  is the null-space part. However for our DDNM,  can be any linear operator as long as it satisfies , where  is a special case. 

Due to the calculation needs of SVD, DDRM needs to convert the operator  into matrix form. However, common operations in computer vision are in the form of convolution, let alone  as a compound or high-dimension one. For example, DDRM is difficult to handle old photo restoration. Rather, our DDNM supports any linear forms of operator  and , as long as  is satisfied. It is worth mentioning that there exist diverse ways of yielding the pseudo-inverse , and SVD is just one of them. Besides, DDNM is more concise than DDRM in the formulation and performs better in noise-free IR tasks. 


\subsection{Other Diffusion-Based IR Methods}
SR3 \citep{sr3} is a task-specific super-resolution method which trains a denoiser with \textcolor{blue}{} as an additional input, i.e., . Then follow the similar reverse diffusion process in DDPM \citep{ho2020denoising} to implement image super-resolution, as is shown in Algo.~\ref{alg:sr3}. SR3 needs to modify the network structures to support extra input  and needs paired data to train the conditional denoiser , while our DDNM is free from those burdens and is fully zero-shot for diverse IR tasks. Besides, DDNM can be also applied to SR3 to improve its performance. Specifically, we insert the core process of DDNM, the range-null space decomposition process, into SR3, yielding Algo.\ref{alg:sr3+ddnm}. Results are demonstrated in Fig.\ref{fig:sr3+ddnm}. We can see that the range-null space decomposition can improve the restoration quality by ensuring data consistency.

\begin{algorithm}[h]
\caption{Reverse Diffusion Process of SR3}
\label{alg:sr3}
\textbf{Require}: The degraded image 
\begin{algorithmic}[1] \State .
\For{}
\State  if , else .
\State 
\EndFor
\State \textbf{return} 
\end{algorithmic}
\end{algorithm}



\begin{algorithm}[h]
\caption{Reverse Diffusion Process of SR3+DDNM}
\label{alg:sr3+ddnm}
\textbf{Require}: The degraded image 
\begin{algorithmic}[1] \State .
\For{}
\State  if , else .
\State 
\State 
\State 
\EndFor
\State \textbf{return} 
\end{algorithmic}
\end{algorithm}
\begin{figure*}[!h]
  \centering
\includegraphics[width=1\linewidth]{im/sr3+ddnm.pdf}
  \caption{DDNM can be applied to SR3 to improve the restoration performance. Here we experiment on 8 SR (from image size 1616 to 128128), the metrics are PSNR/\textit{Consistency}.}
\label{fig:sr3+ddnm} 
\end{figure*}
\begin{algorithm}[h]
\caption{Reverse Diffusion Process of SDE (conditional)}
\label{alg:sdec}
\textbf{Require}: The condition , the operator  and the rate 
\begin{algorithmic}[1] \State .
\For{}
\State  if , else .
\State \textcolor{blue}{}
\State 
\EndFor
\State \textbf{return} 
\end{algorithmic}
\end{algorithm}

\newpage

\cite{song2020score} propose a conditional sampling strategy in diffusion models, which we abbreviate as SDE in this paper. Specifically, SDE optimize each latent variable  toward a specific condition  and put the optimized  back to the original reverse diffusion process, as is shown in Algo.~\ref{alg:sdec}.  is the condition and  is an operator with  measures the distance between  and . 

It is worth noting that DDNM is compatible with extra sources of constraints in the form of operation 5 in Algo.~\ref{alg:sdec}. For example, our results in Fig.~\ref{fig:front} and Fig.~\ref{fig:ndm+ comprehensive} are generated using the diffusion model pretrained on ImageNet with classifier guidance.




\section{Solving noisy Image Restoration Precisely}
\label{ap:ndm+}
For noisy tasks , Sec.~\ref{cp:DDNM+} provide a simple solution where  is approximated as . However, the precise distribution of  is  where the covariance matrix is usually non-diagonal. To use similar principles in Eq.~\ref{eq:ddnm+ handdesigne}, we need to 
orthodiagonalize this matrix. Next, we conduct detailed derivations.


This solution involves the Singular Value Decomposition(SVD), which can decompose the degradation operator  and yield its pseudo-inverse :



To find out how much noise has been introduced into , we first rewrite Eq.~\ref{eq:ndm+ core} as:

where  represents the clean measurements before adding noise.  is the scaling matrix with . Then we can rewrite the additive noise  as  where . Now Eq.~\ref{eq:46} becomes

where  denotes the clean part of  (written as ).
It is clear that the noise introduced into  is . The handling of the introduced noise depends on the sampling strategy we used. We will discuss the solution for DDPM and DDIM, respectively. 

\paragraph{The Situation in DDPM.}
When using DDPM as the sampling strategy, we yield  by sampling from , i.e., 

Considering the introduced noise, we change  to ensure the entire noise level not exceed . Hence we construct a new noise . Then the Eq.~\ref{eq:origal_ddpm_sampling} becomes

 denotes the introduced noise, which can be further written as

The variance matrix of  can be simplified as , with : 

To construct , we define a new diagonal matrix :

Now we can yield  by sampling from  to ensure that . An easier implementation method is firstly sampling  from  and finally get  From Eq.~\ref{eq:gamma_ddpm}, we also observe that  guarantees the noise level of the introduced noise do not exceed the pre-defined noise level  so that we can get the formula of  in :



\paragraph{The Situation in DDIM.}
When using DDIM as the sampling strategy, the process of getting  from  becomes:

where  is the noise level of the -th time-step,  is the denoiser which estimates the additive noise from  and  control the randomness of this sampling process.
Considering the noise part is subject to a normal distribution, that is, , so that the equation can be rewritten as 

Considering the introduced noise, we change  to ensure the entire noise level not exceed . Hence we construct a new noise term :

 denotes the introduced noise, which can be further written as

The variance matrix of  can be simplified as , with : 

To construct , we define a new diagonal matrix :

Now we can construct  by sampling from  to ensure that . An easier implementation is firstly sampling  from  and finally get  From Eq.~\ref{eq:gamma_ddim}, we also observe that  guarantees the noise level of the introduced noise do not exceed the pre-defined noise level  so that we can get the formula of  in :

In the actual implementation, we have adopted the following formula for  and it can be proved that its distribution is :

where  denotes the -th element of the vector  and .

Note that the \textcolor{blue}{blue}  is not necessarily needed. By our theory in Sec.~\ref{cp:DDNM+},  should be 0 to maximize the preservation of range-space correction. But inspired by DDRM\citep{kawar2022denoising}, we find that involving  help improves the robustness, though sacrificing some range-space information.   


\newpage
\section{Additional Results}
\label{extensive exp ndm}
We present additional quantitative results in Tab.~\ref{tb:ddnm appendix big table}, with corresponding visual results of DDNM in Fig.~\ref{fig:ddnm_show_celeba} and Fig.~\ref{fig:ddnm_show_imagenet}. Additional visual results of DDNM are shown in Fig.~\ref{fig:ddnm_denoise_celeba} and Fig.~\ref{fig:ddnm_denoise_imagenet}. Additional results for real-world photo restoration are presented in Fig.~\ref{fig:old photo additional}. Note that all the additional results presented here do not use the time-travel trick.


\begin{table*}[h]
\scriptsize
    \begin{tabular}{c | cccc | cccc| cccc}
        \hline
           \multicolumn{1}{c}{\rule{0pt}{10pt}\tiny\textbf{CelebA-HQ}}&\multicolumn{4}{c}{4 bicubic SR} &\multicolumn{4}{c}{8 bicubic SR}&\multicolumn{4}{c}{16 bicubic SR}\\
        \hline
           \rule{0pt}{10pt}Method& PSNR↑&SSIM↑& \textit{Cons}↓&FID↓ &  PSNR↑&SSIM↑&  \textit{Cons}↓ &FID↓ &  PSNR↑&SSIM↑& \textit{Cons}↓&FID↓ \\
        \hline
            \rule{0pt}{10pt}{DDRM} &31.63&0.9452&33.88&31.04 & 28.11&0.9039&3.23&38.84 & 24.80&0.8612&0.36&46.67\\
            \rule{0pt}{10pt}{DDNM} &31.63&0.9450&4.80&22.27 & 28.18&0.9043&0.68&37.50 & 24.96&0.8634&0.10&45.5\\
        \hline
        \hline
           \multicolumn{1}{c}{\rule{0pt}{10pt}\tiny\textbf{ImageNet}}&\multicolumn{4}{c}{4 bicubic SR} &\multicolumn{4}{c}{8 bicubic SR}&\multicolumn{4}{c}{16 bicubic SR}\\
        \hline
           \rule{0pt}{10pt}Method& PSNR↑&SSIM↑& \textit{Cons}↓&FID↓ &  PSNR↑&SSIM↑&  \textit{Cons}↓ &FID↓ &  PSNR↑&SSIM↑& \textit{Cons}↓&FID↓ \\
        \hline
             \rule{0pt}{10pt}{DDRM} &27.38&0.8698&19.79&43.15&23.75&0.7668&2.70&83.67&20.85&0.6842&0.38&130.81\\
            \rule{0pt}{10pt}{DDNM}& 27.46&0.8707&4.92&39.26 & 23.79&0.7684&0.72&80.15 & 20.90&0.6853&0.11&128.13\\
        \hline
        \hline
            \multicolumn{1}{c}{\rule{0pt}{10pt}\tiny\textbf{CelebA-HQ}}&\multicolumn{4}{c}{inpainting (Mask 1)} &\multicolumn{4}{c}{inpainting (Mask 2)}&\multicolumn{4}{c}{inpainting (Mask 3)}\\
        \hline
           \rule{0pt}{10pt}Method& PSNR↑&SSIM↑& \textit{Cons}↓&FID↓ &  PSNR↑&SSIM↑&  \textit{Cons}↓ &FID↓ &  PSNR↑&SSIM↑& \textit{Cons}↓&FID↓ \\
        \hline
\rule{0pt}{10pt}{DDRM} &34.79&0.9783&1325.46&12.53 & 38.27&0.9879&1357.09&10.34 & 35.77&0.9767&-&21.49\\
            \rule{0pt}{10pt}{DDNM} &35.64&0.9823&0.0&4.54 & 39.38&0.9915&0.0&2.82 & 36.32&0.9797&-&12.46\\
        \hline
        \hline
           \multicolumn{1}{c}{\rule{0pt}{10pt}\tiny\textbf{ImageNet}}&\multicolumn{4}{c}{inpainting (Mask 1)} &\multicolumn{4}{c}{inpainting (Mask 2)}&\multicolumn{4}{c}{inpainting (Mask 3)}\\
        \hline
           \rule{0pt}{10pt}Method& PSNR↑&SSIM↑& \textit{Cons}↓&FID↓ &  PSNR↑&SSIM↑&  \textit{Cons}↓ &FID↓ &  PSNR↑&SSIM↑& \textit{Cons}↓&FID↓ \\
        \hline
            \rule{0pt}{10pt}{DDRM} &31.73&0.9663&876.86&4.82 & 34.60&0.9785&1036.85&3.77 & 31.34&0.9439&-&12.84\\
            \rule{0pt}{10pt}{DDNM} &32.06&0.9682&0.0&3.89 & 34.92&0.9801&0.0&3.19 & 31.62&0.9461&-&9.73\\
        \hline
        \hline
           \multicolumn{1}{c}{\rule{0pt}{10pt}\tiny\textbf{CelebA-HQ}}&\multicolumn{4}{c}{deblur (Gaussian)} &\multicolumn{4}{c}{deblur (anisotropic)}&\multicolumn{4}{c}{deblur (uniform)}\\
        \hline
           \rule{0pt}{10pt}Method& PSNR↑&SSIM↑& \textit{Cons}↓&FID↓ &  PSNR↑&SSIM↑&  \textit{Cons}↓ &FID↓ &  PSNR↑&SSIM↑& \textit{Cons}↓&FID↓ \\
        \hline
            \rule{0pt}{10pt}{DDRM} &43.07&0.9937&297.15&6.24&41.29&0.9909&312.14&7.02&40.95&0.9900&182.27&7.74\\
            \rule{0pt}{10pt}{DDNM} &46.72&0.9966&60.00&1.41 & 43.19&0.9931&66.14&2.80 & 42.85&0.9923&41.86&3.79\\
        \hline
        \hline
           \multicolumn{1}{c}{\rule{0pt}{10pt}\tiny\textbf{ImageNet}}&\multicolumn{4}{c}{deblur (Gaussian)} &\multicolumn{4}{c}{deblur (anisotropic)}&\multicolumn{4}{c}{deblur (uniform)}\\
        \hline
           \rule{0pt}{10pt}Method& PSNR↑&SSIM↑& \textit{Cons}↓&FID↓ &  PSNR↑&SSIM↑&  \textit{Cons}↓ &FID↓ &  PSNR↑&SSIM↑& \textit{Cons}↓&FID↓ \\
        \hline
            \rule{0pt}{10pt}{DDRM} &43.01&0.9921&207.90&1.48 & 40.01&0.9855&221.23&2.55 & 39.72&0.9829&134.60&3.73\\
            \rule{0pt}{10pt}{DDNM} & 44.93&0.9937&59.09&1.15 & 40.81&0.9864&63.89&2.14 & 40.70&0.9844&41.86&3.22\\
        \hline
    \end{tabular}
    \begin{tabular}{c | cccc | cccc}
    \hline
           \multicolumn{1}{c}{\rule{0pt}{10pt}\tiny\textbf{CelebA-HQ}}&\multicolumn{4}{c}{CS (ratio=0.5)} &\multicolumn{4}{c}{CS (ratio=0.25)}\\
        \hline
           \rule{0pt}{10pt}Method& PSNR↑&SSIM↑& \textit{Cons}↓&FID↓ &  PSNR↑&SSIM↑&  \textit{Cons}↓ &FID↓ \\
        \hline
            \rule{0pt}{10pt}{DDRM} &31.52&0.9520&2171.76&25.71 & 24.86&0.8765&1869.03&46.77\\
            \rule{0pt}{10pt}{DDNM} & 33.44&0.9604&1640.67&15.81 & 27.56&0.9090&1511.51&28.80\\
        \hline
        \hline
           \multicolumn{1}{c}{\rule{0pt}{10pt}\tiny\textbf{ImageNet}}&\multicolumn{4}{c}{CS (ratio=0.5)} &\multicolumn{4}{c}{CS (ratio=0.25)}\\
        \hline
           \rule{0pt}{10pt}Method& PSNR↑&SSIM↑& \textit{Cons}↓&FID↓ &  PSNR↑&SSIM↑&  \textit{Cons}↓ &FID↓ \\
        \hline
            \rule{0pt}{10pt}{DDRM} &26.94&0.8902&6293.69&25.01 & 19.95&0.7048&3444.50&97.99\\
            \rule{0pt}{10pt}{DDNM} &29.22&0.9106&5564.00&18.55 & 21.66&0.7493&3162.30&64.68\\
        \hline
    \end{tabular}
    \begin{tabular}{c | cccc }
    \hline
           \multicolumn{1}{c}{\rule{0pt}{10pt}\tiny\textbf{CelebA-HQ}}&\multicolumn{4}{c}{Colorization} \\
        \hline
           \rule{0pt}{10pt}Method& PSNR↑&SSIM↑& \textit{Cons}↓&FID↓ \\
        \hline
            \rule{0pt}{10pt}{DDRM} &26.38&0.7974&455.90&31.26\\
            \rule{0pt}{10pt}{DDNM} & 26.25&0.7947&48.87&26.44\\
        \hline
        \hline
           \multicolumn{1}{c}{\rule{0pt}{10pt}\tiny\textbf{ImageNet}}&\multicolumn{4}{c}{Colorization} \\
        \hline
           \rule{0pt}{10pt}Method& PSNR↑&SSIM↑& \textit{Cons}↓&FID↓ \\
        \hline
            \rule{0pt}{10pt}{DDRM} &23.34&0.6429&260.43&36.56\\
            \rule{0pt}{10pt}{DDNM} &23.47&0.6550&42.32&36.32\\
        \hline
    \end{tabular}
    \caption{Comprehensive quantitative comparisons between DDNM and DDRM.}
    \label{tb:ddnm appendix big table}
\end{table*}



\begin{figure*}[t]
  \centering
  \vspace{-0.2cm}
  \includegraphics[width=1\linewidth]{im/ddnm_show_celeba.pdf}
  \vspace{-0.3cm}
  \caption{Image restoration results of DDNM on CelebA.}
\label{fig:ddnm_show_celeba} 
\end{figure*}

\begin{figure*}[t]
  \centering
  \vspace{-0.2cm}
  \includegraphics[width=1\linewidth]{im/ddnm_show_imagenet.pdf}
  \vspace{-0.3cm}
  \caption{Image restoration results of DDNM on ImageNet.}
\label{fig:ddnm_show_imagenet} 
\end{figure*}


\begin{figure*}[t]
  \centering
  \vspace{-0.2cm}
  \includegraphics[width=1\linewidth]{im/ddnm_denoise_celeba.pdf}
  \vspace{-0.3cm}
  \caption{Noisy image restoration results of DDNM on CelebA. The results here do not use the time-travel trick.}
\label{fig:ddnm_denoise_celeba} 
\end{figure*}

\begin{figure*}[t]
  \centering
  \vspace{-0.2cm}
  \includegraphics[width=1\linewidth]{im/ddnm_denoise_imagenet_new.pdf}
  \vspace{-0.3cm}
  \caption{Noisy image restoration results of DDNM on ImageNet. The results here do not use the time-travel trick.}
\label{fig:ddnm_denoise_imagenet} 
\end{figure*}

\begin{figure*}[t]
  \centering
  \vspace{-0.2cm}
  \includegraphics[width=1\linewidth]{im/old_photo.pdf}
  \vspace{-0.3cm}
  \caption{Restoring real-world photos using DDNM.  represents the degraded images collected from the internet. The results here do not use the time-travel trick.}
\label{fig:old photo additional} 
\end{figure*}


\newpage


\end{document}
