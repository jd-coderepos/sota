\documentclass[11pt]{llncs}


\usepackage{epsfig}
\usepackage{graphics}
\usepackage{amsmath,setspace}

\usepackage[dvipsnames,usenames]{color}
\usepackage[colorlinks=true,urlcolor=Blue,citecolor=Green,linkcolor=BrickRed]{hyperref}
\urlstyle{same}


\newcommand{\Oh}[1]
    {\ensuremath{{O}({#1})}}
\newcommand{\occ}
    {\ensuremath{\mathrm{occ}}}
\newcommand{\rank}
    {\ensuremath{\mathrm{rank}}}


\pagestyle{plain}
\sloppy

\begin{document}

\title{Binary Jumbled Pattern Matching\\ via All-Pairs Shortest Paths}


\author{Danny Hermelin \inst{1}\thanks{Supported in part by the Marie Curie Career Integration Grant (CIG) 631163.}  \and Gad M. Landau\inst{2}\thanks{Supported in part by the National Science Foundation (NSF) grant 0904246, the Israel Science Foundation (ISF) grant 347/09,
and the United States-Israel Binational Science Foundation (BSF) grant 2008217.}  \and \\ Yuri Rabinovich\inst{2}
\and Oren Weimann\inst{2}\thanks{Supported in part by the Israel Science Foundation (ISF) grant 794/13.}}
\institute{
Ben-Gurion University, {hermelin@bgu.ac.il} \and
University of Haifa, \{landau,yuri,oren\}@cs.haifa.ac.il}

\maketitle

\begin{abstract}
In binary jumbled pattern matching we wish to preprocess a binary string  in order to answer queries  which ask for a substring of  that is of size  and  has exactly  1-bits. The problem naturally generalizes to node-labeled trees and graphs by replacing ``substring'' with ``connected subgraph''.

\hspace{15pt} In this paper, we give   time solutions for both strings and trees. This odd-looking time complexity improves the state of the art  solutions by more than any poly-logarithmic factor. It originates from the recent seminal algorithm of Williams for min-plus matrix multiplication.
We obtain the result by giving a black-box reduction from trees to strings. This is then combined with a  reduction from strings to min-plus matrix multiplications.
\end{abstract}


\section{Introduction}
\label{sec:introduction}

A string  is said to have a {\em jumbled} occurrence in string  if  can be rearranged so that it appears in . In other words, if  contains a substring of length  where each letter of the alphabet occurs the same number of times as in .
In indexing for {\em Jumbled pattern matching} we wish to preprocess a given text  so that given a query  we can determine quickly whether  has a jumbled occurrence of .



\paragraph{\bf Binary jumbled pattern matching on strings.}
Apart from a recent paper on constant alphabets~\cite{ESA13}, all the
 results on the problem are restricted to binary alphabets (where a query pattern  asks for a substring of  that is of length  and has  1s). The important property of a binary alphabet is that  appears in  iff  is between the minimum and maximum number of 1s over all substrings of length .
As observed in~\cite{CFL09}, this means that we can store only the  minimum and maximum values of every  and can then answer a query in  time. While this requires only  space, computing it naively takes  time. Beating  has become a recent challenge of the pattern matching community.

The first improvement was to . It was independently obtained by Burcsi et al.~\cite{BCFL12a}, and by Moosa and Rahman~\cite{MR10}, who reduced the problem to min-plus products of vectors. Moosa and Rahman~\cite{MR12} then further improved it to  in the RAM model by cleverly using the four-Russians technique instead of min-plus products. This remained the state of the art and  time was only known when the string compresses well under run-length encoding~\cite{BFKL12,GG12} or when we are willing to settle for approximate indexes~\cite{CLWY12}.

 \paragraph{\bf Binary jumbled pattern matching on Trees.}
On a tree  whose nodes are labeled 0 or 1, a query  asks for a connected subgraph of  that is of size  and has exactly  nodes labeled by 1. Like in strings, if  and  both appear in , then for every ,   appears in . This means that, again, we only need to store for every  the minimum  and maximum  values such that   and  appear  in .
In~\cite{OurESA13} we showed that finding these values can be done in  time, just like in strings.  In fact, the solution for trees was obtained by reducing it to multiple applications of the solution for strings~\cite{MR12} based on the four-Russians technique.

\paragraph{\bf Our results.} Given a string (resp. tree) , we refer to jumbled pattern matching as the problem of computing for every  the maximum and minimum number of 1s in a substring (resp. connected subgraph) of  of size .
We obtain the following:


\begin{theorem}\label{theorem1}
Any  algorithm for computing the min-plus product of  matrices implies an
  algorithm for jumbled pattern matching on strings and an -time algorithm for  jumbled pattern matching on trees for any choice of .
\end{theorem}

\noindent Our work was motivated by the recent breakthrough algorithm of Williams~\cite{Ryan} for computing the min-plus product of two  matrices in  time\footnote{Using the Williams algorithm on the word RAM takes  time since we know that all elements of our matrices are bounded by . The algorithm is randomized and can be made deterministic  in  time for some .}. This means that currently both  and   are  (the difference between  and   is only in the constant behind the ). Choosing , we get:

\begin{corollary}\label{cor}
Jumbled pattern matching on both strings and trees can be solved in  time.
 \end{corollary}

\noindent Finally, we note that the above bound also applies to the more general problem of computing the maximum sub-sums  of a string or a tree. Namely, given a string (resp. tree) whose characters (resp. nodes) have arbitrary weights we can compute (in the time bound of Corollary~\ref{cor}) for every  the maximum sum of weights of all substrings (resp. connected subgraphs) of size .




\section{Binary Jumbled Pattern Matching on Strings}

We begin by proving the first part of Theorem~\ref{theorem1} regarding jumbled pattern matching on strings. As discussed in the previous section, this boils down to the following problem: Given a binary text  of length , compute the minimum and maximum number of 1s in a substring of length  in , for all . Below, we focus on computing the minimum number of 1s in each substring length, as computing the maximum number of 1s can be done in an analogous manner. We show how to do this in total  time, where  is the assumed speedup factor for the naive cubic-time min-plus multiplication algorithm of matrices  and , defined as:  
That is, matrix multiplication where  plays the role of addition, and  plays the role of multiplication.
The  complexity of  such multiplication is equivalent to that of All-Pairs Shortest Paths.

We start by first partitioning the string  into consecutive substrings (blocks)  each of length . We then compute for every  the minimum number of 1s in a substring of length  that is completely inside~. This can be done naively for all  in  time, and over all 's in  time.


We next want to compute the minimum number of 1s in substrings that span more than one block. For every , let  be the   matrix where  is the minimum number of 1s in substrings that include: (1) a suffix  of  (2) the complete blocks  (3) a prefix  of , and (4) . It is not hard to see that once we have all , along with all information we computed within the blocks, solving our problem is trivial in  time.

We distinguish between two cases: The case where  (in which  and  are allowed to be empty), and the case where  (in which both  and  must be non-empty).

Assume that . Let  be the   matrix such that  is the number of 1s in the last  bits of . Similarly, we define the  matrix  such that  is the number of 1s in the first  bits of . Their min-plus product  is defined as . We set  +  where  is the number of 1s in the substring . Note that computing  is done once and is then used for every .

To compute  for , we use the same procedure and only slightly change  and . Now  is an   matrix, and  is the number of 1s in the last  bits of . The matrix  is an~  matrix such that  equals the number of 1s in the first  bits of . The matrix  is again defined as the min-plus product , and  is computed as in the previous case.

Note that computing  and  for each  can be trivially done in  time. Furthermore, it is not difficult to see that  the value  computed for each  and  is indeed the minimum number of 1s in substrings of  as required above. The matrix  can be computed easily in  time once  has been computed via the min-plus computation. Since , using the algorithm of Williams, we can compute this product in  time. Thus, in total we compute  in  time. This proves the first part of Theorem~\ref{theorem1}.

\subsection{Relation to Previous Work}
The above proof was first suggested by us in 2008~\cite{Private2008}. A similar construction was independently obtained by Bremner et al.~\cite{BCDEHILT06} (Arxiv 2012, Section 4.4) who showed that MPVMPM.  Here, MPM denotes the time it takes to compute the min-plus product of two  {\em matrices} and  MPV denotes the time it takes to compute the min-plus product of two -length {\em vectors}  
defined as: \vspace{-0.07in} 

Moosa and Rahman~\cite{MR10} showed that jumbled pattern matching on a string of length   can be done in time MPV. By Bremner et al. this means that MPM. By
Williams~\cite{Ryan} we have MPM and so .




\section{Binary Jumbled Pattern Matching on Trees}

We now prove the second part of Theorem~\ref{theorem1}. Given a tree  with~ nodes, each labeled with either 0 or 1, we wish to compute, for every  the minimum number of nodes labeled 1 in a connected subgraph of  that is of size  (the maximum is found similarly). In~\cite{OurESA13}, we presented a tree-to-strings reduction for this problem that was based on the four-Russians speedup of~\cite{MR12}. Here, we generalize this reduction to a black-box reduction, which is applied regardless of the particular speedup technique used in the string case. We outline this generalization below.

The first observation in~\cite{OurESA13} was that we can assume w.l.o.g that  is a binary tree. The second was an  simple algorithm: In a bottom-up manner, for each node  of , compute an array  of size  ( includes  and all its descendants in ). The entry  will store the minimum number of 1-nodes in a connected subgraph of size  that includes  and another  nodes in . If  has a single child , then we set , where  is the label of . If  has two children  and ,  we set . The time required to compute all arrays is asymptotically bounded by  where  (resp. ) is the size of 's left (resp. right) child's subtree.

The total space used can be made  by only keeping 's which are necessary for future computations. It can be made  {\em bits} by representing  as a binary string  where , and  for all . Since , each entry of  can be retrieved from  in  time using {\em rank} queries~\cite{Jacobson}.

\paragraph{\bf The black-box reduction.}

Now that we have an -time algorithm for  strings we would like to also obtain an -time algorithm for trees. Using the above algorithm, this can be achieved if computing  can be done in  time, since in total we would then get  time.

For a node  with children  and , we can compute  using jumbled pattern matching on the binary string , where  is obtained from  by reversing it and removing its last bit, and  is obtained from  by removing its first bit. The catch is that we are only interested in substrings that include the position of  in . If  and , then this can naively be done in  time. Alternatively, it can also be done in  time using the algorithm of the previous section\footnote{Note that the algorithm from the previous section can easily be adapted (in the same time complexity) to only consider substrings that include the position of .}. However, we desire .

To achieve this, assume w.l.o.g that . We partition  into consecutive substrings , each of length  (except perhaps the last one). We compute  by solving jumbled pattern matching on all the strings  . Using the previous section this takes total . This would be fine if  is roughly equal to . Note that for large enough , say , with the current Williams bound  indeed both  and  are .  The challenge is therefore  to deal with small  (say ).

The challenge of small  was also an obstacle in the reduction of~\cite{OurESA13}.
We use the same solution of~\cite{OurESA13} (with only a small change in parameters). Namely a \emph{micro-macro decomposition}~\cite{MicroMacro}.
A micro-macro decomposition is a partition of  into
 disjoint connected subgraphs of size at most  called {\em micro trees}. Each micro tree  has at most two nodes (called \emph{boundary} nodes) that are adjacent to nodes in other micro trees. The {\em macro tree}  is a tree of size . Each node of the macro tree corresponds to a micro tree  and the edges of the macro tree  to edges between boundary nodes.



We first compute the maximum number of 1s in all patterns that are completely inside a micro tree. Using the above simple algorithm each micro tree is handled in  time, so overall . Notice that in particular this computes  for every boundary node  with respect to its micro tree . Denote this array by .

To deal with patterns that span multiple micro trees, it was shown in~\cite{OurESA13} that the simple algorithm can be applied bottom-up on the macro tree (instead of on ). For each node  in the macro tree, and each boundary node  of , the array  is computed by combining the array  with the arrays  of every descendant boundary node  adjacent to . Recall that combining the arrays means solving jumbled pattern matching on a binary string  with  and . As before, if  this takes  time, so over all such computations take  time. If~, we simply extend  artificially until it is of length . The computation will then take  time, but there are only  boundary nodes, so overall this takes  time. Accounting also for the  time required for computing all necessary information inside the micro trees, we obtain the time complexity promised in Theorem~\ref{theorem1}.



\section{Conclusions}
We have showed that any  algorithm for computing the min-plus product of  matrices implies an -time algorithm for  jumbled pattern matching on strings, and an -time algorithm for jumbled pattern matching on trees for any choice of . With the current Williams bound on , and by choosing , we get that jumbled pattern matching on either strings or trees can be done in  time. This is because currently both  and  are .

In the future, if say an  algorithm is found (with a constant ) for All-Pairs Shortest Paths (i.e., for min-plus products), then we would get an  algorithm for jumbled pattern matching on strings but only an  algorithm for trees where .  This is obtained using the  bound of Theorem~\ref{theorem1} with . However, notice that the  factor originated from running the simple  algorithm on each one of the  micro trees. But we now have a better than  algorithm, namely an  algorithm for any choice of . Doing this recursively improves the  factor and makes  closer to . We leave this as an exercise for the optimistic future in which APSP can be done in  time.




\bibliographystyle{plain}
\bibliography{jumbled}
\end{document}
