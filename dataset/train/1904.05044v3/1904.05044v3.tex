


\begin{figure*} [!t]
\centering
\includegraphics[width = 0.95 \textwidth]{figures/figure1_3.pdf}
\caption{
Overview of our framework for generating pseudo instance segmentation labels.
} 
\vspace{-0.3cm}
\label{fig:label_synthesis}
\end{figure*}


\section{Introduction}
\label{sec:intro}
Instance segmentation is a task that jointly estimates class labels and segmentation masks of individual objects.
As in other visual recognition tasks, supervised learning of Convolutional Neural Networks (CNNs) has driven recent advances in instance segmentation~\cite{Sds,DAICVPR15,Dai16_SDS,mask_rcnn,instancecut,Semiconv,Dai2016,Liu2016}.
Due to the data-hungry nature of deep CNNs, this approach demands an enormous number of training images with groundtruth labels, which are given by hand in general. 
However, manual annotation of instance-wise segmentation masks is prohibitively time-consuming, which results in existing datasets limited in terms of both class diversity and the amount of annotated data.
It is thus not straightforward to learn instance segmentation models that can handle diverse object classes in the real world.


One way to alleviate this issue is weakly supervised learning that adopts weaker and less expensive labels than instance-wise segmentation masks as supervision.
Thanks to low annotation costs of weak labels, approaches in this category can utilize more training images of diverse objects, although they have to compensate for missing information in weak labels.
For instance segmentation, bounding boxes have been widely used as weak labels since they provide every property of objects except shape~\cite{SDI,Cutnpaste}.
However, it is still costly to obtain box labels for a variety of classes in a large number of images as they are manually annotated.


To further reduce the annotation cost, one may utilize image-level class labels for learning instance segmentation since such labels are readily available in large-scale image classification datasets, \eg, ImageNet~\cite{Russakovsky2015}.
Furthermore, although image-level class labels indicate only the existence of object classes, they can be used to derive strong cues for instance segmentation, called \emph{Class Attention Maps} (CAMs)~\cite{Cam,Oquab15,Wei_2017_CVPR,Selvaraju_2017_ICCV}.
A CAM roughly estimates areas of each class by investigating the contribution of local image regions to the classification score of the class.
However, CAMs cannot be directly utilized as supervision for instance segmentation since they have limited resolution, often highlight only partial areas of objects, and most importantly, cannot distinguish different instances of the same class.
To resolve this issue, a recent approach~\cite{PRM} incorporates CAMs with an off-the-shelf segmentation proposal technique~\cite{MCG}, which however has to be trained separately on an external dataset with additional supervision.










In this paper, we present a novel approach for learning instance segmentation using image-level class labels, which outperforms the previous state-of-the-art trained with the same level of supervision~\cite{PRM} and even some of approaches relying on stronger supervision~\cite{SDI,Sds}.
Moreover, it requires neither additional supervision nor any segmentation proposals unlike the previous approaches~\cite{Sds,PRM}.
Our method generates pseudo instance segmentation labels of training images given their image-level labels and trains a known CNN model with the pseudo labels.
For generating the pseudo labels, it utilizes CAMs, but as mentioned earlier, they can neither distinguish different instances nor find entire instance areas with accurate boundaries.

To overcome these limitations of CAMs, we introduce \emph{Inter-pixel Relation Network} (IRNet) that is used to estimate two types of additional information complementary to CAMs: a class-agnostic instance map and pairwise semantic affinities.
A class-agnostic instance map is a rough instance segmentation mask without class labels nor accurate boundaries.
On the other hand, the semantic affinity between a pair of pixels is a confidence score for class equivalence between them.
By incorporating instance-agnostic CAMs with a class-agnostic instance map, we obtain instance-wise CAMs, which are in turn enhanced by propagating their attention scores to relevant areas based on the semantic affinities between neighboring pixels.
After the enhancement, a pseudo instance segmentation label is generated by selecting the instance label with the highest attention score in the instance-wise CAMS at each pixel.
The entire procedure for label synthesis is illustrated in \Fig{label_synthesis}.

IRNet has two branches estimating an instance map and semantic affinities, respectively. 
The first branch predicts a displacement vector field where a 2D vector at each pixel indicates the centroid of the instance the pixel belongs to.
The displacement field is converted to an instance map by assigning the same instance label to pixels whose displacement vectors point at the same location.
The second branch detects boundaries between different object classes.
Pairwise semantic affinities are then computed from the detected boundaries in such a way that two pixels separated by a strong boundary are considered as a pair with a low semantic affinity.
Furthermore, we found that IRNet can be trained effectively with inter-pixel relations derived from CAMs.
Specifically, we collect pixels with high attention scores and train IRNet with the displacements and class equivalence between the collected pixels.
Thus, no supervision in addition to image-level class labels is required.


The contribution of this paper is three-fold:
\vspace{-2mm}
\begin{itemize}[leftmargin=5mm] 
\itemsep=-1mm
\item We propose a new approach to identify and localize instances with image-level supervision through class-agnostic instance maps. 
This enables instance segmentation without off-the-shelf segmentation proposals.
\item We propose a new way to learn and predict semantic affinities between pixels with image-level supervision through class boundary detection, which is more effective and efficient than previous work~\cite{affinitynet}.
\item On the PASCAL VOC 2012 dataset~\cite{Pascalvoc}, our model substantially outperforms the previous state-of-the-art trained with the same level of supervision~\cite{PRM}. 
Also, it even surpasses previous models based on stronger supervision like SDI~\cite{SDI} that uses bounding box labels and SDS~\cite{Sds}, an early model that uses full supervision. \end{itemize}

\iffalse
The rest of the paper is organized as follows.
\Sec{relatedwork} summarizes related work and \Sec{cams} reviews CAMs as an initial step of our framework.
We then describe details of IRNet in \Sec{irnet}, and our label synthesis method using IRNet in \Sec{labelsynth}.
\Sec{experiments} presents experimental results. Finally, \Sec{conclusion} concludes this paper.
\fi











\iffalse
To overcome these limitations of CAMs, we introduce \emph{Inter-pixel Relation Network} (IRNet) that estimates two types of additional information that are complementary to CAMs: a class-agnostic instance map and pairwise semantic affinities.
A class-agnostic instance map is a rough instance segmentation mask without class labels nor accurate boundaries.
On the other hand, semantic affinities provides information about potential instance boundaries.
By combining instance-agnostic CAMs, class-agnostic instance maps, and semantic affinities, we can generate an accurate pseudo instance segmentation label.
IRNet does not require any additional supervision, but it is trained with local inter-pixel relations derived from CAMs.
Specifically, to estimate an instance map, IRNet learns a displacement vector field of 2D vectors indicating the centroids of instances they belong to.
For pairwise semantic affinities, IRNet learns to predict semantic object class boundaries.

The contribution of this paper is three-fold:
\begin{itemize}[leftmargin=5mm] 
\itemsep=0mm
\item We propose a new approach based on the displacement field estimation to identify and localize instances in weakly supervised setting. This allows our model to perform instance segmentation without off-the-shelf segmentation proposals.
\item We propose a new way to learn semantic affinities between pixels with image-level supervision only, and it is more effective and memory-efficient compared to the previous approach~\cite{affinitynet}.
\item On the PASCAL VOC 2012 dataset~\cite{Pascalvoc}, our model substantially outperforms the previous state of the art trained with the same level of supervision~\cite{PRM}. 
Also, it even surpasses previous models based on stronger supervision like SDI~\cite{SDI} using bounding box labels and SDS~\cite{Sds}, one of the earliest fully supervised model.
\end{itemize}

\fi












\iffalse To overcome these limitations of CAMs, our method estimates two types of additional information that are complementary to CAMs: a class-agnostic instance map and pairwise semantic affinities.
A class-agnostic instance map is a rough instance segmentation mask without class labels nor accurate boundaries.
On the other hand, semantic affinities provides information about potential instance boundaries. 
By combining instance-agnostic CAMs with class-agnostic instance maps, our method generates instance-wise CAMs.
Then, the method propagates attention scores of each instance-wise CAM to reveal the entire area of the corresponding instance using semantic propagation based on the pairwise semantic affinities.
After semantic propagation, a pseudo instance segmentation label is generated by selecting the instance-class combination with the highest attention score for each pixel.
The entire procedure for label synthesis is illustrated in \Fig{label_synthesis}.

The remaining issue is how to estimate class-agnostic instance maps and semantic affinities between pixels. 
To this end, we design \emph{Inter-pixel Relation Network} (IRNet), which has two output branches for the two tasks respectively.
The first branch of IRNet predicts a displacement vector field where a 2D vector at each pixel indicates the centroid of the instance the pixel belongs to.
The displacement field is converted to a class-agnostic instance map by assigning the same instance label to pixels whose displacement vectors point out the same location.
The second branch predicts maps of potential boundaries of object classes.
Pairwise semantic affinities are then computed from the detected boundary maps in such a way that, given detected boundaries, two pixels separated by a strong boundary are considered as a pair with a low semantic affinity.

We train IRNet with local inter-pixel relations derived from CAMs without any additional supervision.
Specifically, we first collect pixels with high attention scores, and train IRNet with the displacements and class equivalence between the collected pixels.
Note that learning IRNet in principle demands instance-wise segmentation supervision as it predicts instance-aware information, but we found that it can be trained successfully with CAMs 
since their class label prediction is often correct within local confident areas,
hence able to provide reliable evidences for local inter-pixel relations, as also shown in~\cite{affinitynet}.
\fi











\iffalse
The issue is then how to predict instance label maps and semantic affinities between pixels. 
To this end, we design a CNN called \emph{Inter-pixel Relation Embedding Network} (IREN), which has two output branches conducting the two prediction tasks respectively.
The first branch predicts offset vectors from pixels to centroids of instances they belong to so that pixels converging to the same centroid are assigned the same instance label.
The second one detects boundaries between different classes so that two pixels separated by such boundaries are considered as a pair with a low semantic affinity.
Importantly, IREN is trained with inter-pixel relations derived from CAMs, thus demands image-level supervision only.
Specifically, we define two kinds of relations between neighboring pixels, class equivalent and location displacement, where the class labels of pixels are given by CAMs.
\fi

