\documentclass[preprint]{sigplanconf}

\pdfoutput=1

\usepackage[utf8]{inputenc}
\usepackage{amssymb,amsmath}
\usepackage{amsthm}
\usepackage{stmaryrd,colonequals,mathabx}
\usepackage{mathtools,empheq}
\usepackage[f]{esvect}
\usepackage{fancybox}
\usepackage{ifthen}
\usepackage{hhline}
\usepackage{xargs}
\usepackage{xspace}
\usepackage{calc}
\usepackage{tikz}
\usepackage{tikz-cd}
\usepackage{pgffor}
\usepackage{array}
\usepackage{etoolbox}
\usepackage[inline]{enumitem}
\usepackage{bussproofs}
\usepackage{listings}
\usepackage{wrapfig}
\usepackage{url}



\usepackage{local-macros}
\usepackage{thm}






\makeatletter
\newenvironment{CenteredBox}{\begin{Sbox}}{\end{Sbox}\centerline{\parbox{\wd\@Sbox}{\TheSbox}}}\makeatother

\newcommand\blfootnote[1]{\begingroup
  \renewcommand\thefootnote{}\footnote{#1}\addtocounter{footnote}{-1}\endgroup
}

\setenumerate{listparindent=\parindent}



\begin{document}

\special{papersize=8.5in,11in}
\setlength{\pdfpageheight}{\paperheight}
\setlength{\pdfpagewidth}{\paperwidth}

\conferenceinfo{CONF 'yy}{Month d--d, 20yy, City, ST, Country}
\copyrightyear{20yy}
\copyrightdata{978-1-nnnn-nnnn-n/yy/mm}
\copyrightdoi{nnnnnnn.nnnnnnn}





\title{Type Theory based on Dependent Inductive and Coinductive Types}

\authorinfo{Henning Basold}
           {Radboud University \\ CWI, Amsterdam}
           {h.basold@cs.ru.nl}
\authorinfo{Herman Geuvers}
           {Radboud University \\ Technical University Eindhoven}
           {herman@cs.ru.nl}

\maketitle

\begin{abstract}
  We develop a dependent type theory that is based purely on inductive
  and coinductive types, and the corresponding recursion and
  corecursion principles.
  This results in a type theory with a small set of rules, while still being
  fairly expressive.
  For example, all well-known basic types and type formers that are needed for
  using this type theory as a logic are definable: propositional
  connectives, like falsity, conjunction, disjunction, and function space,
  dependent function space, existential quantification, equality,
  natural numbers, vectors etc.
  The reduction relation on terms consists solely of a rule for recursion and a
  rule for corecursion.
  The reduction relations for well-known types arise from that.
  To further support the introduction of this new type theory, we also
  prove fundamental properties of its term calculus.
  Most importantly, we prove subject reduction and strong normalisation of
  the reduction relation, which gives computational meaning to the terms.

  The presented type theory is based on
  ideas from categorical logic that have been investigated before by
  the first author, and it extends Hagino's categorical data types to
  a dependently typed setting.
  By basing the type theory on concepts from category theory we maintain the
  duality between inductive and coinductive types, and it allows us to describe,
  for example, the function space as a coinductive type.
\end{abstract}

\category{F.4.1}{Mathematical Logic and Formal Languages}
                {Mathematical Logic}




\keywords
Dependent Types, Inductive Types, Coinductive Types, Fibrations


\section{Introduction}
\label{sec:intro}


In this paper, we develop a type theory that is based solely on dependent
inductive and coinductive types.
By this we mean that the only way to form new types is by specifying the type
of their corresponding constructors or destructors, respectively.
From such a specification, we get the corresponding recursion and corecursion
principles.
One might be tempted to think that such a theory is relatively weak as, for
example, there is no function space type.
However, as it turns out, the function space is definable as a
coinductive type.
Other type formers, like the existential quantifier, that are needed in logic,
are definable as well.
Thus, the type theory we present in this paper encompasses intuitionistic
predicate logic.

Why do we need another type theory, especially since
Martin-Löf type theory (MLTT)~\cite{MartinLof-ModelsITT} or the calculus of
inductive constructions (CoIC)~\cite{Paulin-Mohring93,Werner1994,BertotC04}
are well-studied
frameworks for intuitionistic logic?
The main reason is that the existing type theories have no explicit
dependent coinductive types.
Gim\'enez~\cite{Gimenez-RecursiveSchemes} discusses an extension of the CoIC
with coinductive types and guarded recursive schemes but proves no properties
about the conversion relation.
On the other hand, Sacchini~\cite{Sacchini-TypeBasedProductivity} extended the
CoC with streams, and proves subject reduction and strong normalisation.
However, the problem of limited support for general coinductive types remains.
Finally, we should also mention that general coinductive types are
available in implementations like Coq~\cite{Coq:manual}, which is based
on~\cite{Gimenez-RecursiveSchemes}, Agda~\cite{Agda:system} and
Nuprl~\cite{Constable:NuprlTT}.
Yet, none of these has a formal justification, and Coq's coinductive types
are even known to have problems (e.g. related to subject reduction).

One might argue that dependent coinductive types can be encoded through
inductive types, see~\cite{Ahrens:MTypes-HoTT,Basold-DepCoindFibDialg}.
However, it is not clear whether such an encoding gives rise to a good
computation principle in an intensional type theory such as MLTT or CoIC,
see~\cite{cLab:FinalChain-TT}.
This becomes an issue once we try to prove propositions about terms of
coinductive type.


Other reasons for considering a new type theory are of foundational interest.
First, taking inductive and coinductive types as core of
the type theory reduces the number of deduction rules considerably
compared to, for example, MLTT with W- and M-types.
Second, it is an interesting fact that the (dependent) function space can be
described as a coinductive type.
This is well-known in category theory but we do not know of any treatment of
this fact in type theories.
Thus the presented type theory allows us to deepen our understanding of
coinductive types.

\paragraph{Contributions}

Having discussed the raison d'être of this paper, let us briefly mention the
technical contributions.
First of all, we introduce the type theory and show how important logical
operators can be represented in it. We also discuss some other basic examples,
including one that shows the difference to existing theories with coinductive
types.
Second, we show that computations of terms, given in form of a reduction
relation, are meaningful, in the sense that the reduction relation preserves
types (subject reduction) and that all computations are terminating (strong
normalisation).
Thus, under the propositions-as-types interpretation, our type theory can
serve as formal framework for intuitionistic reasoning.



\paragraph{Related Work}
A major source of inspiration for the setup of our type theory is categorical
logic.
Especially, the use of fibrations, brought forward in~\cite{Jacobs1999-CLTT},
helped a great deal in understanding how coinductive types should be treated.
Another source of inspiration is the view of type theories as internal language
or even free model for categories, see for example~\cite{LambekScott-HOCatLog}.
This view is especially important in topos theory, where final coalgebras
have been used as foundation for predicative, constructive
set theory~\cite{Aczel:nonwfs,vdBerg-Non-wellfoundedTrees,vanDenBerg:thesis}.
These ideas were extended in~\cite{Basold-DepCoindFibDialg},
which discusses the categorical analogue of the type theory of this paper,
see also~\iSecRef{dtcc}.

Let us briefly discuss other type theories that the present work relates to.
Especially close is the copattern calculus introduced
in~\cite{Abel2013-Copatterns}, as there the coinductive types are also
specified by the types of their destructors.
However, said calculus does not have dependent types, and it is based on
systems of equations to define terms, whereas the calculus in the present paper
is based on recursion and corecursion schemes.

To ensure strong normalisation, the copatterns have been combined with size
annotations in~\cite{Abel2013}.
Due to the nature of the reduction relation in these copattern-based calculi,
strong normalisation also ensures productivity for coinductive types or,
more generally, well-definedness~\cite{BasoldHansen:Welldef-Equiv-CoInd}.
As another way to ensure productivity, guarded recursive types were proposed
and in \cite{Bizjak:GuardedDepRecTypes} guarded recursion was extended to
dependent types.
Guarded recursive types are not only applicable to strictly positive types,
which we restrict to in this paper, but also to positive and even negative
types.
However, it is not clear how one can include inductive types into such
a type theory, which are, in the authors opinion, crucial to mathematics
and computer science.
Finally, in~\cite{Sacchini-TypeBasedProductivity} another type theory
with type-based termination conditions and a type former for streams
has been introduced.
This type theory, however, lacks again dependent coinductive types.

\paragraph{Outline}

The rest of the paper is structured as follows.
In~\iSecRef{dtcc}, we briefly discuss the ideas from category theory
that motivate the definition of the type theory.
This section is strictly optional and can be safely skipped.
The type theory itself is introduced in~\iSecRef{syntax}, and
in~\iSecRef{examples} we give a host of examples and discuss the representation
of logical operators.
After that, we justify in~\iSecRef{pre-syntax} the definition of the typing
rules of~\iSecRef{syntax} by giving an untyped version of the calculus.
Moreover, this section serves as the technical basis for the strong
normalisation proof.
\secRef{meta-prop} is devoted to proving important properties of the type
theory, namely subject reduction in~\iSecRef{subject-reduction}, and
strong normalisation in~\iSecRef{sn}.
Finally, we make concluding remarks and discuss future work
in~\iSecRef{conclusion}.

 \section{Categorical Dependent Data Types}
\label{sec:dtcc}

Before we introduce the actual calculus, let us briefly describe the structure
the calculus shall capture.
This is a short recap from~\cite{Basold-DepCoindFibDialg}, to which we refer
for more details.
Note, that this section is completely optional and only serves as
motivation for those familiar with category theory.

We begin with the definition of dialgebras and associated notions,
see~\cite{Hagino-Dialg}.
\begin{definition}
  \label{def:dialgebra}
  Let  and  be categories and  be
  functors.
  An -\emph{dialgebra} is morphism  in  for
  an object  in .
  We say that a morphism  is a dialgebra \emph{homomorphism}
  from the dialgebra  to
  , if .
  This allows us to form the category  of dialgebras and their
  homomorphisms.
  Finally, a dialgebra is an \emph{initial} (resp. \emph{final})
  -dialgebra if it is an initial (resp. final) object in ,
  see~\cite{Basold-DepCoindFibDialg}.
\end{definition}

Let us discuss an example of a dialgebra in the category of sets.
\begin{example}
  Let  be given by
   and , that is,  maps a
  set  to the pair  in the product category.
  Similarly, , the diagonal functor, maps  to .
  Now, let  and  be the constant zero map
  and the successor on natural numbers, respectively.
  It is then easy to see that  is an initial
  dialgebra.
  \qedDef
\end{example}

Initial and final dialgebras will allow us to describe dependent data types
conveniently, where the dependencies are handled through the use of fibrations.
\begin{definition}
  \label{def:fibration}
  Let  be a functor, where  is called the
  \emph{total} category and  the \emph{base} category.
  A morphism  in  is said to be \emph{cartesian over}
   in , provided that
  \begin{enumerate*}[label=\roman*)]
  \item , and
  \item for all  in  and  with
     there is a unique  such that .
  \end{enumerate*}
  For  to be a \emph{fibration}, we require that
  for every  and  in , there is
  a cartesian morphism  over .
  Finally, a fibration is \emph{cloven}, if it comes with a unique choice
  for  and , in which case we denote  by  and
   by , as displayed in the diagram on the right.
\end{definition}

\begin{wrapfigure}[7]{r}{.2\textwidth}
\vspace{-1.2\baselineskip}
\hspace*{-20pt}
\begin{tikzcd}[row sep=0.1cm, column sep=0.25cm]
    C \arrow[bend left=15]{drrr}{g}
      \arrow[dashed,shorten >= -5pt]{dr}[swap]{!h}
& & \\
    & \reidx{u} B
      \arrow{rr}[swap]{\cartL{u} B}
& & B
& \TCat \arrow{dddd}{P}
    \\ \\ \\
    PC
      \arrow[bend left=15]{drrr}{P g}
      \arrow{dr}[swap]{v} & & \\
    & I
      \arrow{rr}[swap]{u} & & PB
      & \BCat
  \end{tikzcd}
\end{wrapfigure}

On cloven fibrations, we can define for each  in 
a functor, the \emph{reindexing} along , as follows.
Let us denote by  the category
having objects  with  and morphisms  with
.
We call  the \emph{fibre above }.
The assignment of  to  for a cloven fibration can then be
extended to a functor .
Moreover, one can show that  and
.
In this work, we are mostly interested in \emph{split fibrations},
which are cloven fibrations such that the above isomorphisms are
equalities, that is,  and
.

\begin{example}[See~\cite{Jacobs1999-CLTT}]
  Important examples of fibrations arise from categories with pullbacks.
  Let  be a category and  be the arrow category with
  morphisms  of  as objects and commutative squares as
  morphisms.
  We can then define a functor  by
  .
  This functor turns out to be a fibration, the \emph{codomain fibration},
  if  has pullbacks.
  If we are given a choice of pullbacks, then  is cloven.

  The split variant of this construction is given by the category of
  \emph{set-indexed families} over .
  Let  be the category that has families 
  of objects  in  indexed by a set .
  The morphisms  in
   are pairs  where  is a function and 
  is an -indexed family of morphisms in  with
  .
  It is then straightforward to show that the functor
  , given by projecting on the index set,
  is a split fibration.
  \qedDef
\end{example}

To model \emph{dependent} data types, we consider dialgebras in the fibres of a
fibration .
Before giving a general account, let us look at an important example:
the dependent function space.
\begin{example}
  Suppose that  has a final object , and let .
  Thus, there is a morphism , which gives rise
  to the \emph{weakening} functor
  .
  We can then show that for each  the dependent function space
   is the final -dialgebra, whereby  is
  the functor mapping every object to  and morphism to .
  That is to say, there is a dialgebra 
  that evaluates a function on an argument from , such that for each
  dialgebra  there is a unique
   with .
  \qedDef
\end{example}

From a categorical perspective, the dependent function space is actually a
functor  that is, moreover, right adjoint to the
weakening functor : .
To capture this, we allow data types to have parameters.
\begin{definition}
  \label{def:parameterised-dialg}
  Let , ,  be categories, and
   be a functor.
  We define a functor
  
  between functor categories by
  
  Let  be another functor.
  A \emph{parameterised} -dialgebra is an
  -dialgebra, that is, a natural transformation
   for a functor
  .
\end{definition}

\begin{example}
  The dependent function space  functor is a final, parameterised
  -dialgebra, where
  ,
   and
   is the product projection.
  This is a consequence of the fact that ,
  , and that for each  the function
  space  is a final -dialgebra.
  This allows us to prove that the evaluation  is natural in 
  and that  is final in .
  \qedDef
\end{example}

Let  be a cloven fibration,  and 
a tuple  of morphisms  in .
Then for every  there is a functor
 given by

Now we are in the position to define what it means for a category to have
strictly positive, dependent data types.
\begin{definition}
  \label{def:dt-complete}
  Given a cloven fibration  we define by mutual induction
  data type completeness, the class  of strictly
  positive signatures and the class  of strictly positive data
  types.


  We say that  is \emph{data type complete}, if for all 
  an initial - and final
  -dialgebra exists.
  We denote their carriers by   and
  , respectively.
  A pair  is a \emph{strictly positive signature}, if
   by the first rule in~\iFigRef{dtcc-rules}.
  Finally, a \emph{strictly positive data type} is a functor ,
  as given by the other rules in~\iFigRef{dtcc-rules}.

  \begin{figure*}
    \centering
    

  7pt]
    \AxiomC{}
    \AxiomC{}
    \BinaryInfC{}
    \DisplayProof
    \quad
    \AxiomC{}
    \UnaryInfC{}
    \DisplayProof
    \quad
    \AxiomC{}
    \UnaryInfC{}
    \DisplayProof
  
  \validTypeN{A}[]{i},

  \validTypeN{A}{i},

  \validTypeN{A \inst t_1 \inst \dotsb \inst t_n}[]{i}.

  \validTypeN[X : {\pType[\objCtx_2]}][\objCtx_1]{X}[\objCtx_2]{i},

  \validTypeN[X : {\pType[\objCtx_2]}][\objCtx_1]
  {X \inst t_1 \inst \dotsb \inst t_n}[]{i}.

  \validTypeN[X : {\pType[(x : B, y : B)]}][\emptyset]
  {(z).(X \inst z \inst z)}[(z:B)]{i}.

  \objCtx_1  \vdash s \inst t_1 \inst \dotsb \inst t_n: A[\vec{t}/\vec{x}],

  \indTy{X}{\objCtx}{\vec{\sigma}}{\vec{A}}
  \qquad \text{and} \qquad
  \coindTy{X}{\objCtx}{\vec{\sigma}}{\vec{A}},

  \typed[]{\inMu_k}{
    \pTerm[\left(\objCtx_k, z : A_k \tySubst{\mu}{X} \right)]{
      \left( \mu \inst t_1 \inst \dotsb \inst t_m \right)}}.

    \AxiomC{}
    \UnaryInfC{}
    \bottomAlignProof
    \DisplayProof
    \quad
    \AxiomC{}
    \AxiomC{}
    \BinaryInfC{}
    \bottomAlignProof
    \DisplayProof
    \\
    \AxiomC{}
    \UnaryInfC{}
    \bottomAlignProof
    \DisplayProof
    \quad
    \AxiomC{}
    \UnaryInfC{}
    \bottomAlignProof
    \DisplayProof
  
    \AxiomC{}
    \UnaryInfC{}
    \bottomAlignProof
    \DisplayProof
    \quad
    \AxiomC{}
    \AxiomC{}
    \BinaryInfC{}
    \bottomAlignProof
    \DisplayProof
  [box=\fbox]{gather*}
    \AxiomC{}
    \RightLabel{\TTyI}
    \UnaryInfC{}
    \DisplayProof
    \7pt]
    \AxiomC{}
    \AxiomC{}
    \RightLabel{\TyVarWeak}
    \BinaryInfC{}
    \DisplayProof
    \7pt]
    \AxiomC{}
    \AxiomC{}
    \RightLabel{\TyInst}
    \BinaryInfC{}
    \DisplayProof
    \7pt]
    \AxiomC{}
    \AxiomC{}
    \RightLabel{\FPTy}
    \BinaryInfC{}
    \DisplayProof
  
    (\pAbstr{x}{A}) \inst t \paramReduce A \subst{t}{x}.
  
    \label{eq:ty-reduction}
    \AxiomC{}
    \UnaryInfC{}
    \DisplayProof
  
    A \tBireduce B \iff A \tReduce B \text{ or } B \tReduce A.
  [box=\fbox]{gather*}
  \AxiomC{}
  \RightLabel{\rulelabel{-I}}
  \UnaryInfC{}
  \bottomAlignProof
  \DisplayProof
  \qquad
  \AxiomC{}
  \AxiomC{}
  \RightLabel{\Inst}
  \BinaryInfC{}
  \bottomAlignProof
  \DisplayProof
  \quad
  \AxiomC{}
  \AxiomC{}
  \RightLabel{\rulelabel{Conv}}
  \BinaryInfC{}
  \DisplayProof
  \7pt]
  \AxiomC{}
  \AxiomC{}
  \RightLabel{\rulelabel{Ind-I}}
  \BinaryInfC{}
  \DisplayProof
  \quad
  \AxiomC{}
  \AxiomC{}
  \RightLabel{\rulelabel{Coind-E}}
  \BinaryInfC{}
  \DisplayProof
  \7pt]
  \AxiomC{}
  \AxiomC{}
  \AxiomC{}
  \RightLabel{\rulelabel{Coind-I}}
  \TrinaryInfC{}
  \DisplayProof

  \validTypeN[!][\emptyset]{\pAbstr{\objCtx}{B}}[\objCtx]{i}.

  \tyFunc{C}(\vec{A}) =
  C \tySubst{\vec{\pAbstr{\objCtx_i}{A}}}{\vec{X}} \inst \id_{\objCtx}.

  \label{eq:typing-functor-from-type}
  \AxiomC{}
\AxiomC{}
  \BinaryInfC{}
  \DisplayProof

  \label{eq:compose-ctx-mor}
  \tau \bullet \sigma \colonequals (\tau_1[\sigma], \dotsc, \tau_n[\sigma]).

    \recPs{\objCtx_k, y_k}{g_k} \inst \, (\sigma_k \bullet \tau) \inst \,
(\inMu_k \inst \tau \inst u)
    & \contract g_k
    \subst*{\tyFunc{A_k}(\recPs{\objCtx_k, y_k}{g_k}
      \inst \id_{\objCtx} \inst x)}{y_k}
    [\tau, u] \\
\outNu_k \inst \tau \inst \,
    (\corecPs{\objCtx_k, y_k}{g_k} \inst \, (\sigma_k \bullet \tau) \inst u)
    & \contract \tyFunc{A_k}\left(
      \corecPs{\objCtx_k, y_k}{g_k} \inst \id_{\objCtx} \inst x\right)
    \subst*{g_k}{x}
    [\tau, u]

  \begin{tikzcd}[row sep=1.5em,column sep=3.5cm]
    C \inst \sigma_k
    \rar{\corecPs{\objCtx_k, y}{g_k} \inst \sigma_k \inst x}
    \dar[swap]{g_k}
    & \nu \inst \sigma_k
    \dar{\outNu_k \inst \id_{\objCtx_k} \inst y} \\
    A_k \tySubst{C}{X}
    \rar{\tyFunc{A_k}(\corecPs{\objCtx_k, y}{g} \inst \sigma_k \inst x)}
    & A_k \tySubst{\nu}{X}
  \end{tikzcd}

  \varepsilon_k \colonequals ((), \dotsc, ()).

    \AxiomC{}
    \UnaryInfC{}
    \DisplayProof
  
    \AxiomC{}
    \AxiomC{}
    \RightLabel{\rulelabel{Coind-I}}
    \BinaryInfC{}
\DisplayProof
  
    \outNu_1 \inst \unit'
    & = \outNu_1 \inst \, (\corecP{y}{y} \inst \unit) \\
    & \reduce \tyFunc{X}(\corecP{y}{y} \inst x')
    \subst{y}{x'} \subst{\unit}{y} \\
    & = (\corecP{y}{y} \inst x') \subst{y}{x'} \subst{\unit}{y} \\
    & = \corecP{y}{y} \inst \unit \\
    & = \unit'
  
    \AxiomC{}
    \UnaryInfC{}
    \DisplayProof
  
    \NatT \colonequals \indTy{X}{}{\varepsilon_2}{(\T, X)},
  
    0 = \inMu_1^{\NatT} \inst \unit : \NatT
    \quad \text{ and } \quad
    s = \inMu_2^{\NatT} : (y : \NatT) \ctxTo \NatT.
  
    \AxiomC{}
    \AxiomC{}
    \BinaryInfC{}
    \DisplayProof
  
    \AxiomC{}
    \AxiomC{}
    \BinaryInfC{}
    \DisplayProof
  
    \AxiomC{}
    \AxiomC{}
    \UnaryInfC{}
    \BinaryInfC{}
    \UnaryInfC{}
    \DisplayProof
  
    \pi_k \inst \, (t_1, t_2)
    & = \outNu_k \inst \id_\objCtx
    \inst \, (P \inst \id_{\objCtx} \inst \unit) \\
    & \reduce \tyFunc{A_k}(P \inst \id_{\objCtx} \inst x)
    \subst{t_k}{x} \substN{(\id_\objCtx, \unit)} \\
    & = x \subst{t_k}{x} \substN{(\id_\objCtx, \unit)} \\
    & = t_k,
  
    A_1 +_{\objCtx} A_2 \colonequals
    \indTy{X}{\objCtx}{(\id_\objCtx, \id_\objCtx)}{(A_1, A_2)}
    \inst \id_{\Gamma},
  
    \AxiomC{}
    \AxiomC{}
    \BinaryInfC{}
    \DisplayProof
  
    \coprodArr{t_1,t_2} \inst \, (\kappa_i \inst s)
    \reduce t_i \subst{s}{x}.
  
    \AxiomC{}
    \UnaryInfC{}
    \AxiomC{}
    \RightLabel{\rulelabel{FP-Ty}}
    \BinaryInfC{}
    \DisplayProof
  
    \AxiomC{}
    \AxiomC{}
    \RightLabel{\TermWeak}
    \BinaryInfC{}
    \RightLabel{\rulelabel{Coind-I}}
    \UnaryInfC{}
\RightLabel{\Inst}
    \UnaryInfC{}
    \DisplayProof
  
    \AxiomC{}
    \AxiomC{}
    \BinaryInfC{}
    \DisplayProof
  
    (\lambda x. g) \, a
    & = \outNu_1 \inst a \inst \, (\corecP{x, \_{}}{g} \inst \unit) \\
    & \reduce \tyFunc{B}(\corecP{x, \_{}}{g} \inst x')
    \subst{g}{x'} \substN{\unit/\_, a/x} \\
    & = x' \subst{g}{x'} \substN{\unit/\_, a/x} \\
& = g[a/x],
  
     A \to B \colonequals \Pi x:A. B \text{ if } x \not\in \fv(B).
  
    \AxiomC{}
    \UnaryInfC{}
    \doubleLine \dashedLine
    \UnaryInfC{}
    \DisplayProof
  
    \AxiomC{}
    \AxiomC{}
    \BinaryInfC{}
    \DisplayProof
  
    \cramped{E_{x,y}^\exists}(t, p) \colonequals \recP{x : A, y : B}{p} \inst t,
  
    \AxiomC{}
    \AxiomC{}
    \AxiomC{}
    \TrinaryInfC{}
    \DisplayProof
  
    \cramped{E_{x,y}^\exists} ((t, s), p) \reduce p \substL{t/x, s/y}.
    \tag*{\qedDef}
  
    \textstyle
    \validTypeN[][y : J]{\coprod_f A}[]{i}
    \quad \text{ and } \quad
    \validTypeN[][y : J]{\prod_f A}[]{i}
  
    & \VecT A \colonequals
    \indTy{X}{\objCtx}{(\sigma_1, \sigma_2)}{(\T, A \times X \inst k)} \\
    & \objCtx = n : \NatT
    \quad \text{ and } \quad \objCtx_1 = \emptyset
    \quad \text{ and } \quad \objCtx_2 = k : \NatT \\
    & \ctxMor{\sigma_1 = (0)}{\objCtx_1}{(n : \NatT)}
    \quad \text{ and } \quad
    \ctxMor{\sigma_2 = (s \inst k)}{\objCtx_2}{(n : \NatT)} \\
    & \validTypeN[X : {\pType[(n : \NatT)]}][\objCtx_1]{\T}[]{0} \\
    & \validTypeN[X : {\pType[(n : \NatT)]}][\objCtx_2]
    {A \times X \inst k}[]{0}
  
    \EN = \coindTy{X}{}{\varepsilon_1}{\oneT + X} : \univ{0}
  
    \PStr A \colonequals
    \coindTy{X}{\Gamma}{(s_\infty \, k, s_\infty \, k)}{(A, X \inst k)},
  
    \objCtx & \colonequals \emptyset \mid \objCtx, x \quad x \in \var \\
    \tyCtx & \colonequals \emptyset \mid \tyCtx, X : \pType[\objCtx] \\
    M, N & \colonequals
    \begin{aligned}[t]
    & \oneT \mid \unit
    \mid x \in \var
    \mid M \inst N
    \mid \pAbstr{x}{M}
    \mid X \in \tyVar \\
    & \mid \inMu_k
    \mid \outNu_k
    \mid \recT{\rho}{X : \pType[\objCtx]}{\vec{\sigma}}{
      \vec{M}}, \; \rho \in \{\mu, \nu\} \\
    &
    \mid \rec^{\indTy{X}{\objCtx}{\vec{\sigma}}{\vec{M}}}
    \vec{\pAbstr{\objCtx_k, y_k}{N_k}} \\
    &
    \mid \corec^{\coindTy{X}{\objCtx}{\vec{\sigma}}{\vec{M}}}
    \vec{\pAbstr{\objCtx_k, y_k}{N_k}}
    \end{aligned}
  
  \validTypeN{A}[\objCtx_2]{i}
  \qquad \text{ and } \qquad
  \preTerm[\objCtx_1, x]{t}[\objCtx_2].

    & \begin{aligned}
      & \tyFunc[\tyCtx, X_{n+1}]{C}(\vec{t}, t_{n+1})
      = \tyFunc[\tyCtx]{C}(\vec{t})
      & & \text{for } \TyVarWeak \\
      & \tyFunc[\tyCtx]{X_i}(\vec{t}) = t_i \\
      & \tyFunc[\tyCtx]{C' \inst s}(\vec{t})
      = \tyFunc[\tyCtx]{C'}(\vec{t}) \subst{s}{y},
      & & \text{for }
      \validTypeN[!][\objCtx']{C'}[(y, \objCtx)]{i} \\
      & \tyFunc[\tyCtx]{\pAbstr{y}{C'}}(\vec{t}) = \tyFunc[\tyCtx]{C'}(\vec{t}),
      & & \text{for }
      \validTypeN[!][(\objCtx',y)]{C'}[\objCtx]{i} \\
    \end{aligned} \\
    & \tyFunc[\tyCtx]{\indTy{Y}{\objCtx}{\vec{\sigma}}{\vec{D}}}(\vec{t})
      = \recPs[R_A]{\objCtxA_k, x}{g_k} \inst \id_{\objCtx} \inst x, \\
      & \quad \text{with } g_k =
      \inMu_k
\inst \id_{\objCtxA_k} \inst
      \left(\tyFunc[\tyCtx, Y]{D_k}\left(
          \vec{t}, y
\right)\right) \\
      & \quad \text{and } R_{A} =
      \indTy{Y}{\objCtx}{\vec{\sigma}}{\vec{D} \tySubst{\vec{\pAbstr{\objCtx_i}{A}}}{\vec{X}}} \\
      & \quad \text{for }
      \validTypeN[\tyCtx, Y : {\pType[\objCtx]}][\Delta_k]{D_k}[]{i} \\
    & \tyFunc[\tyCtx]{\coindTy{Y}{\objCtx}{\vec{\sigma}}{\vec{D}}}(\vec{t})
      = \corecPs[R_{B}]{\objCtxA_k, x}{g}
      \inst \id_{\objCtx} \inst x, \\
      & \quad \text{with } g_k =
      \tyFunc[\tyCtx,Y]{D_k}\left( \vec{t}, x \right)
      \subst*{(\outNu_k \inst \id_{\objCtxA_k} \inst x)}{x} \\
      & \quad \text{and } R_{B} =
      \coindTy{Y}{\objCtx}{\vec{\sigma}}{\vec{D} \tySubst{\vec{\pAbstr{\objCtx_i}{B}}}{\vec{X}}}
  
    \AxiomC{}
    \AxiomC{}
    \BinaryInfC{}
    \DisplayProof
  
  \label{eq:sem-ctx-mor}
  \begin{aligned}
    & \sem{\ctxMor{\sigma}{\objCtx_1}{\objCtx_2}} :
    \Terms^{\vars{\Gamma_1}} \to \Terms^{\vars{\Gamma_2}} \\
    & \sem{\ctxMor{\sigma}{\objCtx_1}{\objCtx_2}}(\gamma)(y)
    = \sigma(y)[\gamma].
  \end{aligned}

    \label{eq:sat-comprehension}
    \compr{(E, U)}_{x} =
    \setDef*{\rho[x \mapsto M]}{
      \rho \in E \text{ and }
      M \in U(\rho)},
  
    \label{eq:sat-typing}
    E \Vdash U = \setDef{M}{\forall \gamma \in E. \; M[\gamma] \in U(\gamma)}.
  
    \sem{\emptyset} & = \{! : \emptyset \to \Terms\} \\
    \sem{\objCtx, x : A} & =
    \compr{(\sem{\objCtx}, \sem{A})}_x \\
    & = \setDef{\rho[x \mapsto M]}{
      \rho \in \sem{\objCtx} \text{ and } M \in \sem{A}(\rho)}

    \sem{\tyCtx} = \prod_{X_i \in \vars{\tyCtx}} \tyVal{\objCtx_i},
  
\tyVal{\objCtx} =
    \setDef{U : \sem{\objCtx} \to \sat}{
      \forall \rho, \rho'. \; \rho \tReduce \rho' \Rightarrow U(\rho) = U(\rho')}
  
    \sem{\validTypeN[][]{\oneT}[]{i}}(\delta, \rho)
    & = \bigcap \setDef{X \in \sat}{\unit \in X} \\
    \sem{\validTypeN[\tyCtx, X : {\pType[\objCtx]}][\emptyset]{X}[\objCtx]{i}}
    (\delta, \rho)
    & = \delta(X)(\rho) \\
    \sem{\validTypeN[\tyCtx, X]{A}{i}}(\delta, \rho)
    & = \sem{\validTypeN{A}{i}}(\restr{\delta}{\vars{\tyCtx}}, \rho) \\
    \sem{\validTypeN[!][\objCtx_1, x : B]{A}{i}}(\delta, \rho)
    & = \sem{\validTypeN{A}{i}}(\delta, \restr{\rho}{\vars{\objCtx_1}}) \\
    \sem{\validTypeN{A \inst t}[\objCtx_2 \subst{t}{x}]{i}}(\delta, \rho)
    & = \sem{\validTypeN{A}[(x : B, \objCtx_2)]{i}}(\delta, \rho[x \mapsto t[\rho]]) \\
    \sem{\validTypeN{\pAbstr{x}{A}}[(x : B, \objCtx_2)]{i}}(\delta, \rho)
    & = \sem{\validTypeN[!][\objCtx_1, x : B]{A}{i}}(\delta, \rho) \\
    \sem{\validTypeN[!][\emptyset]{
        \indTy{X}{\objCtx}{\vec{\sigma}}{\vec{A}}}[\objCtx]{i}}(\delta, \rho)
    & = 
    \begin{aligned}[t]
      \{M \mid \;
      & \forall U \in \tyVal{\objCtx}. \; \forall \objCtxA. \;
      \forall k. \;
      \forall N_k \in
      \compr{\sem{\objCtx_k}, \sem{A_k^\objCtxA}(\delta[X \mapsto U])}_y
      \Vdash \reidx{\sem{\sigma_k \bullet \pi}}(U). \\
      & \quad
      \rec \vec{\pAbstr{\objCtx_k, y}{N_k}} \inst \rho \inst M \in U(\rho) \}
    \end{aligned} \\
    \sem{\validTypeN[!][\emptyset]{
        \coindTy{X}{\objCtx}{\vec{\sigma}}{\vec{A}}}[\objCtx]{i}}(\delta, \rho)
    & = 
      \{M \mid \;
      \exists U \in \tyVal{\objCtx}. \;
      \forall k. \;
      \forall \gamma \in \sem{\sigma_k}^{-1}(\rho). \;
      \outNu_k \inst \gamma \inst M \in \sem{A_k}(\delta[X \mapsto U], \gamma)\}
  
    \sem{A \to B}(\gamma)
    & = \setDef{M}{\forall N \in \sem{A}. \,
      \outNu_1 \inst \gamma \inst M \in \sem{B}} \\
    & = \setDef{M}{\forall N \in \sem{A}. \, M \, N \in \sem{B}},
  
    \tyFunc{C}(\vec{t})\substN{\sigma, s} \in \sem{C}(\delta_B, \sigma).
  
    \AxiomC{}
    \UnaryInfC{}
    \DisplayProof
  
    \bot_{\objCtx} \colonequals
    \indTy{X}{\objCtx}{\id_{\objCtx}}{X \inst \id_{\objCtx}} \inst \id_{\objCtx},
  
    \AxiomC{}
    \UnaryInfC{}
    \DisplayProof
  
    \AxiomC{}
\UnaryInfC{}
    \AxiomC{}
    \RightLabel{\IndE}
    \BinaryInfC{}
    \RightLabel{\Inst}
    \UnaryInfC{}
    \RightLabel{\Conv}
    \UnaryInfC{}
    \DisplayProof
  
    \Eq_A(x,y)  \colonequals
    \indTy{X}{(x : A, y : A)}{\delta}{\top} \inst x \inst y,
  
    \AxiomC{}
    \AxiomC{}
    \BinaryInfC{}
    \DisplayProof
  
    \insertBetweenHyps{\hskip .1in}
    \AxiomC{}
    \AxiomC{}
    \AxiomC{}
    \TrinaryInfC{}
    \DisplayProof
  
    \repl(p,t) \colonequals E^{\Eq}_{x,y}(p,t).
    \tag*{\qedDef}
  
    \begin{tikzcd}[column sep=2cm]
      C \rar{h} \dar{d} & \EN \dar{\outNu} \\
      (\oneT + C) + \EN \rar{\coprodArr{\id_\oneT + h, \outNu}}
      & \oneT + \EN
    \end{tikzcd}
  
    a = \coprodArr{
      \coprodArr{\kappa_1 \inst x, \kappa_2 \inst \kappa_1 \inst x},
      \kappa_2 \inst \kappa_2 \inst x
    }
  
\AxiomC{}
    \UnaryInfC{}
    \UnaryInfC{}
    \DisplayProof
  
    \typed[\objCtxA]{\corecP{y}{d'}}{\pTerm[y:C + \EN]{\EN}}
  
    \typed[\objCtxA, y : C]{h}{\EN}.
  
    \coprodArr{\kappa_1 \circ \kappa_2 \circ \kappa_2, \kappa_2}
    : \EN + \EN \to (\oneT + (\EN + \EN)) + \EN,
  
      \AxiomC{}
      \AxiomC{}
      \BinaryInfC{}
      \DisplayProof
      \
  \item Exchange
     7pt]
      \AxiomC{}
      \AxiomC{}
\BinaryInfC{}
      \DisplayProof
    
      \AxiomC{}
      \UnaryInfC{}
      \DisplayProof
      \
  \end{itemize}
\end{proposition}
\begin{proof}
  In each case, the rules are straightforwardly proved by simultaneous
  induction over types and terms.
  It should be noted that for types only the instantiation and weakening
  rules appear as cases, since the other rules have only types without
  free variables in the conclusion.
  Similarly, only terms constructed by means of the the projection, weakening
  or the instantiation rule appear as cases in the proofs.
\end{proof}

Analogously, the substitution, exchange and contraction rules for type variables
are valid in the calculus, as well.

\subsection{Subject Reduction}

\begin{proof}[Proof of \lemRef{correctness-type-action}]
  Recall that we have to prove
  
  We want to prove this by induction in the derivation of ,
  thus we need to generalise the statement to arbitrary type constructor
  contexts .
  So let
  
  be a context,
  
  a type and
   terms for .
  We show that
  
  holds by induction in the derivation of .

  The induction base has two cases.
  First, it is clear that if , then 
  and , thus the definition
  is thus well-typed.
  Second, if  for some , then we immediately have
  
  thus, by \rulelabel{Conv} and the type of , we have
   as
  required.

  In the induction step, we have five cases for .
  \begin{itemize}
  \item The type correctness for  in case  has been constructed
    by Weakening for type and term variables is immediate by
    induction and the definition of  in these cases.
  \item  and  with
    
    By induction we have then that
    ,
    thus, since
    
    we get by \iPropRef{derived-structural-rules}
    
    As we now have
    
    and ,
    we find that
    
    as expected.
  \item  with
    .
    This gives us, by induction,
    .
    Now we observe that
    
    which gives us, by \rulelabel{Conv}, that
    .
    Thus the definition
     is
    well-typed.
    \vspace*{5pt}
  \item  with
    
    For brevity, we define
    .
    Then, by induction, we have

    Now we note that
    .\footnote{
      Note that the second substitution does not contain a parameter
      abstraction, as  is closed.}
    If we define
    
    where  refers to
    
    (see the definition of ), then we can derive the following.
    
    Finally, we have
    
    which implies, by the above derivitations, that we indeed have
    
  \item .
    This case is treated analogously to that for inductive types.
  \end{itemize}
  This concludes the induction, thus \eqRef{typing-functor-from-type}
  indeed holds for all , ,  and .
\end{proof}


\section{Strong Normalisation}
\label{app:sn}

\subsection*{Pre-Types and -Terms}

\begin{definition}[Pre-Types]
  See \iFigRef{pre-types}
  \begin{figure*}
  7pt]
    \AxiomC{}
    \RightLabel{\rulelabel{PT-TyVar}}
    \UnaryInfC{}
    \DisplayProof
    \7pt]
    \AxiomC{}
    \RightLabel{\rulelabel{PT-Weak}}
    \UnaryInfC{}
    \DisplayProof
    \7pt]
    \AxiomC{}
    \RightLabel{\rulelabel{PT-Param-Abstr}}
    \UnaryInfC{}
    \DisplayProof
    \
    \caption{Pre-Types}
    \label{fig:pre-types}
  \end{figure*}
\end{definition}


\begin{definition}[Pre-Terms]
  See \iFigRef{pre-terms}.
  \begin{figure*}
  7pt]
    \AxiomC{}
    \RightLabel{\rulelabel{PO-Proj}}
    \UnaryInfC{}
    \DisplayProof
    \qquad
    \AxiomC{}
    \RightLabel{\rulelabel{PO-Weak}}
    \UnaryInfC{}
    \DisplayProof
    \7pt]
\AxiomC{}
    \AxiomC{}
    \RightLabel{\rulelabel{PO-Ind-E}}
    \BinaryInfC{}
    \DisplayProof
    \
    \caption{Pre-Terms}
    \label{fig:pre-terms}
  \end{figure*}
\end{definition}


\begin{remark}
  The intuition for \iDefRef{type-action} can be better understood in terms of
  the diagrams that correspond to, for example, the definition on initial
  dialgebras.
  Put
  
  and analogous for .
  Then  is defined
  as the morphism  in the following diagram.
  
\end{remark}

\subsection{Soundness proof for saturated sets model}

\begin{lemma}
  \label{lem:interpret-ctx-mor-composition}
  For all  and
   we have
  .
\end{lemma}
\begin{proof}
  For all  and 
  we have
  
  as required.
\end{proof}

\begin{lemma}
  \label{lem:move-inst-to-valuation}
  If ,
  
  and , then
  ,
  where  is
  given by
  
\end{lemma}
\begin{proof}
  Simply by repeatedly applying the case of the semantics of type
  instantiations.
\end{proof}

The following four lemmas
\ref{lem:interpret-subst-lemma}-\ref{lem:monotonicity-interpretation}
are easily proved by induction in the derivation of the corresponding type .
\begin{lemma}
  \label{lem:interpret-subst-lemma}
  If  and
  , then
  for all  we have
  .
\end{lemma}

\begin{lemma}
  \label{lem:interpret-move-subst}
  If  and
  , then
  for all  and  we have
  .
\end{lemma}

\begin{lemma}
  \label{lem:interpret-move-ty-subst}
  If 
  and , then
  .
\end{lemma}


\begin{lemma}
  \label{lem:monotonicity-interpretation}
  If  and
   with 
  (point-wise order), then for all 
  
\end{lemma}

\begin{lemma}
  \label{lem:constructor-closure}
  Let  where we have
  .
  If ,  and
  , then
  
\end{lemma}
\begin{proof}
  Let ,  and  be given as in the lemma, and
  put .
  We need to show for any choice of  and
  
  that
  
  is in .
  Now we define  and
  
  so that .
  Let us furthermore put
  
  By , it suffices to prove
  that .
  Note that we can rearrange the substitution in  to get
   with
  .

  We get  from
  ,
  provided that  and
  .
  The former is given from the assumption of the lemma.
  The latter we get from \iLemRef{ty-functor-sound},
  since we have assumed soundness for the components of  and
  .
  Thus we have .

  So by saturation we have  for any choice
  of  and , thus if follows that
  .
\end{proof}

\begin{lemma}
  \label{lem:coind-is-largest-fp}
  Let  where we have
  .
  If  and , such that for all
  , all ,
  all  and all
  ,
  ,
  then
  
\end{lemma}
\begin{proof}
  This follows immediately from the definition of , just instantiate
  the definition with the given .
  Then all all  are in .
\end{proof}

\begin{lemma}
  \label{lem:corec-closure}
  Let  where we have
  .
  If , ,
   and
  
  for ,
  then
  
\end{lemma}
\begin{proof}
  Similar to the proof of \iLemRef{constructor-closure} by using that
  the interpretation of -types is a largest fixed
  point~\iLemRef{coind-is-largest-fp} and that the interpretation is
  monotone~\iLemRef{monotonicity-interpretation}.
\end{proof}

\begin{lemma}
  \label{lem:interpret-resp-reduction}
  Suppose  is a type with .
  If   with
  , then
  .
  Furthermore, if , then .
\end{lemma}
\begin{proof}
  The first part follows by an easy induction, in which the only interesting
  case  is.
  Here we have
  
  since  and thus respects conversions.

  For the second part, let  be given by replacing all terms in parameter
  position in  by variables, so that  for some substitution
  .
  But then there is a  with  and ,
  and the claim follows from the first part.
\end{proof}

\begin{proof}[Proof of \lemRef{ty-functor-sound}]
  We proceed by induction in the derivation of
  .
  \begin{itemize}
  \item  by \TTyI.
    In this case we have that ,
    thus  by
    by saturation.
  \item  by \TyVarI.
    Note that
     and
    .
    thus the claim follows directly from the assumption of the lemma.
  \item 
    by \TyVarWeak.
    Immediate by induction.
  \item  by \TyWeak.
    Again immediate by induction.
  \item  with
     by \TyInst.
    First, we note that  with
     and
    .
    Let us put ,
    so that we have
    
    By the assumption of the lemma on parameters we have
    , and thus
    ,
    which gives
    .
    By induction, we have
    ,
    and
    
    follows.
  \item 
    by \PAbstr.
    Immediate by induction.
  \item 
    by \FPTy.
    We abbreviate, as before, this type just by .
    Recall the definition of :
    
    Now, put ,
    then we have by induction that
    .
    Since  we have by \iLemRef{constructor-closure}
    for all  that
    .
By assumption, we have , hence by
    choosing  in the definition of  we find
    .
  \item 
    by \FPTy.
    Analagous to the inductive case, only that we use \iLemRef{corec-closure}.
\end{itemize}
\end{proof}

\begin{proof}[Proof of \lemRef{sat-sound}]
  We proceed by induction in the type derivation for .
  Since  does not have any parameters, we only have to deal with fully
  applied terms and will thus leave out the case for instantiation in
  the induction.
  Instead, we will have cases for fully instantiated , , etc.
  So let  and proceed by the cases for .
  \begin{itemize}
  \item  by definition.
  \item For  we have .
    By definition of , we have
    .
    Thus  as required.
  \item Weakening is dealt with immediately by induction.
  \item If  is of type  by \rulelabel{Conv}, then by
    induction .
    Since by \iLemRef{interpret-resp-reduction} ,
    we have .
  \item Suppose we are given
     and
    
    with  and
    .

    Then, by induction, we have
    
    and soundness for the components of ,
    thus by \iLemRef{constructor-closure}
    



\item Suppose we have
     and
    .
    Then by induction we get from 
    that , hence if we chose
     and 
    the definition of  yields
    .
  \item Suppose
     and
    
    with 
    and .
    By induction, 
    thus there is a  such that
    .
    By \iLemRef{coind-is-largest-fp} and \iLemRef{monotonicity-interpretation}
    we then have
    .
    Since
    ,
    the claim follows.
  \item For -terms we just apply \iLemRef{corec-closure}, similar to
    the -case.
  \end{itemize}
  This concludes the induction, thus the interpretation of types is sound
  with respect to the typing judgement for terms.
\end{proof}



%
 
\end{document}
