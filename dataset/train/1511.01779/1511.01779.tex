\chapter{Transactional Memory model}
\label{ch:tm-model}
\epigraph{All models are wrong, but some models are useful.}
{\textit{George Edward Pelham Box}}
In this chapter, we formalize the TM model and discuss some important TM properties proposed in literature.
In Section~\ref{sec:c21}, we formalize the specification of TMs.
In Section~\ref{sec:tm-correctness}, we introduce the basic TM-correctness property of \emph{strict serializability}
that we consider in the thesis.
Sections~\ref{sec:tm-progress} and \ref{sec:tm-liveness} overview progress and liveness properties for TMs
respectively and identifies the relations between them.
Section~\ref{sec:inv} defines the notion of \emph{invisible reads} while
Section~\ref{sec:dap} is on \emph{disjoint-access parallelism}.
Finally, in Section~\ref{sec:complexity}, we introduce some of the complexity metrics considered in the thesis.
\section{TM interface and TM implementations}
\label{sec:c21}
In this section, we first describe the \emph{shared memory} model of computation and then introduce the TM abstraction.

\vspace{1mm}\noindent\textbf{The shared memory model.}
The thesis considers the standard \emph{asynchronous shared memory} model of computation in which
a set of $n\in \mathbb{N}$ processes (that may \emph{fail by crashing}), 
communicate by applying \emph{operations} on shared \emph{objects}~\cite{AGHK09}.
An object is an instance of an \emph{abstract data type}.
An abstract data type $\tau$ is a \emph{mealy machine} that is specified as a tuple
$(\Phi,\Gamma, Q, q_0, \delta)$ where
$\Phi$ is a set of operations,
$\Gamma$ is a set of responses, $Q$ is a set of states, $q_0\in Q$ is an
initial state and $\delta \subseteq Q\times \Phi \times Q\times \Gamma$ 
is a transition relation that determines, for each state
and each operation, the set of possible
resulting states and produced responses~\cite{AFHHT07}. 
Here, $(q,\pi,q',r) \in \delta$ implies that when
an operation $\pi \in \Phi$ is applied on an object of type $\tau$
in state $q$, the object moves to state $q'$ and returns response $r$.

An \emph{implementation} of an object type $\tau$ provides a specific data-representation of $\tau$ that is realized by
processes applying \emph{primitives} on shared \emph{base objects}, each of which is assigned an initial value. 
In order to implement an object, processes are provided with an algorithm, which is a set of deterministic
state-machines, one for each process.
In the thesis, we use the term primitive to refer to operations on base objects and reserve the term operation
for the object that is implemented from the base objects.


A primitive is a generic atomic \emph{read-modify-write} (\emph{rmw}) procedure applied to a base object~\cite{G05,Her91}.
It is characterized by a pair of functions $\langle g,h \rangle$:
given the current state of the base object, $g$ is an \emph{update function} that
computes its state after the primitive is applied, while $h$ 
is a \emph{response function} that specifies the outcome of the primitive returned to the process.
A rmw primitive is \emph{trivial} if it never changes the value of the base object to which it is applied.
Otherwise, it is \emph{nontrivial}.
An rmw primitive $\langle g,h \rangle$ is \emph{conditional} if there exists $v$, $w$ such that
$g(v,w)=v$ and there exists $v$, $w$ such that
$g(v,w)\neq v$~\cite{cond-04}.

\emph{Read} is an example of a trivial rmw primitive that takes no input arguments: when applied
to a base object with value $v$, the update function leaves the state of the base object unchanged and 
the response function returns the value $v$.
\emph{Write} is an example of a nontrivial rmw primitive that takes an input argument $v'$: when applied to a base object
with value $v$, its update function changes the value of the base object to $v'$ and its response function
returns $ok$.
\emph{Compare-and-swap} is an example of a nontrivial conditional rmw primitive: its update function receives an input argument 
$\langle \ms{old},\ms{new} \rangle$ and changes the value $v$ of the base object to which it is applied \emph{iff} $v=\ms{old}$.
\emph{Load-linked/store-conditional} is another example of a nontrivial conditional rmw primitive:
the \emph{load-linked} primitive executed by some process $p_i$ returns the value of the base object to which
it is applied and the \emph{store-conditional} primitive's update function receives an input $\ms{new}$ and 
atomically changes the value of the base object to $\ms{new}$
\emph{iff} the base object has not been updated by any other process since the load-linked event by $p_i$.
\emph{Fetch-and-add} is an example of a nontrivial rmw primitive that is not conditional: its update
function applied to base object with an integer value $v$ takes an integer $w$ as input
and changes the value of the base object to $v+w$.

\vspace{1mm}\noindent\textbf{Transactional memory (TM).}
\emph{Transactional memory}
allows a set of data items (called \emph{t-objects}) to be accessed 
via \emph{transactions}.
Every transaction $T_k$ has a unique identifier $k$. 
We make no assumptions on the \emph{size} of a t-object, \emph{i.e.}, 
the cardinality on the set $V$ of possible values a t-object can store.
A transaction $T_k$ may contain the following \emph{t-operations},
each being a matching pair of an \emph{invocation} and a \emph{response}:
$\Read_k(X)$ returns a value in $V$, denoted $\Read_k(X) \rightarrow v$, 
or a special value $A_k\notin V$ (\emph{abort});
$\Write_k(X,v)$, for a value $v \in V$,
returns \textit{ok} or $A_k$;
$\TryC_k$ returns $C_k\notin V$ (\emph{commit}) or $A_k$.
As we show in the subsequent Section~\ref{sec:tm-correctness}, we can specify
TM as an abstract data type.

Note that a TM interface may additionally provide a $\textit{start}_k$ t-operation that returns $ok$ or $A_k$, 
which is the first t-operation
transaction $T_k$ must invoke, or a $\textit{tryA}_k$ t-operation that returns $A_k$.
However, the actions performed inside the $\textit{start}_k$ may be performed as part of the first t-operation performed
by the transaction. The $\textit{tryA}_k$ t-operation allows the user application
to explicitly abort a transaction and can be useful, but since each of the individual t-read or t-write are allowed to abort,
the $\textit{tryA}_k$ t-operation provides no additional expressive power to the TM interface.
Thus, for simplicity, we do not incorporate these t-operations in our TM specification.

\vspace{1mm}\noindent\textbf{TM implementations.}
A TM \emph{implementation} provides processes with algorithms
for implementing $\Read_k$, $\Write_k$ and $\TryC_k()$
of a transaction $T_k$ by applying primitives from a set of shared base objects, each of which is 
assigned an initial value.
We assume that a process starts a new transaction
only after its previous transaction has committed or aborted.

In the rest of this section, we define the terms specifically in the context of TM implementations, but
they may be used analogously in the context of any concurrent implementation of an abstract data type.

\vspace{1mm}\noindent\textbf{Executions and configurations.}
An \emph{event} of a process $p_i$ (sometimes we say \emph{step} of $p_i$)
is an invocation or response of an operation performed by $p_i$ or a 
rmw primitive $\langle g,h \rangle$ applied by $p_i$ to a base object $b$
along with its response $r$ (we call it a \emph{rmw event} and write $(b, \langle g,h\rangle, r,i)$).


A \emph{configuration} (of an implementation) specifies the value of each base object and 
the state of each process.
The \emph{initial configuration} is the configuration in which all 
base objects have their initial values and all processes are in their initial states.

An \emph{execution fragment} is a (finite or infinite) sequence of events.
An \emph{execution} of an implementation $M$ is an execution
fragment where, starting from the initial configuration, each event is
issued according to $M$ and each response of a rmw event $(b, \langle
g,h\rangle, r,i)$ matches the state of $b$ resulting from all
preceding events.
An execution $E\cdot E'$ denotes the concatenation of $E$ and execution fragment $E'$,
and we say that $E'$ is an \emph{extension} of $E$ or $E'$ \emph{extends} $E$.

Let $E$ be an execution fragment.
For every transaction (resp., process) identifier $k$,
$E|k$ denotes the subsequence of $E$ restricted to events of
transaction $T_k$ (resp., process $p_k$).
If $E|k$ is non-empty,
we say that $T_k$ (resp., $p_k$) \emph{participates} in $E$, else we say $E$ is \emph{$T_k$-free} (resp., \emph{$p_k$-free}).
Two executions $E$ and $E'$ are \emph{indistinguishable} to a set $\mathcal{T}$ of transactions, if
for each transaction $T_k \in \mathcal{T}$, $E|k=E'|k$.
A TM \emph{history} is the subsequence of an execution consisting of the invocation and 
response events of t-operations.
Two histories $H$ and $H'$ are \emph{equivalent} if $\txns(H) = \txns(H')$
and for every transaction $T_k \in \txns(H)$, $H|k=H'|k$.

\vspace{1mm}\noindent\textbf{Data sets of transactions.}
The \emph{read set} (resp., the \emph{write set}) of a transaction $T_k$ in an execution $E$,
denoted $\Rset_E(T_k)$ (resp., $\Wset_E(T_k)$), is the set of t-objects that $T_k$ reads (resp., writes to) in $E$.
More specifically, if $E$ contains an invocation of $\Read_k(X)$ (resp., $\Write_k(X,v)$), we say
that $X\in \Rset_E(T_k)$ (resp., $\Wset_E(T_k)$) (for brevity, we sometimes omit the subscript $E$ from the notation).
The \emph{data set} of $T_k$ is $\Dset(T_k)=\Rset(T_k)\cup\Wset(T_k)$.
A transaction is called \emph{read-only} if $\Rset(T_k)\neq \emptyset \wedge \Wset(T_k)=\emptyset$; 
\emph{write-only} if $\Wset(T_k)\neq \emptyset \wedge \Rset(T_k)=\emptyset$ and
\emph{updating} if $\Wset(T_k)\neq\emptyset$.
Note that, in our TM model, the data set of a transaction is not known apriori, \emph{i.e.}, at the start of the transaction
and it is identifiable only by the set of data items the transaction has invoked a read or write on in the given execution.

\vspace{1mm}\noindent\textbf{Transaction orders.}
Let $\txns(E)$ denote the set of transactions that participate in $E$.
In an infinite history $H$, 
we assume that each $T_k\in \txns(H)$, $H|k$ is finite;
\emph{i.e.}, transactions do not issue an infinite number of t-operations.
An execution $E$ is \emph{sequential} if every invocation of
a t-operation is either the last event in the history $H$ exported by $E$ or
is immediately followed by a matching response.
We assume that executions are \emph{well-formed}, \emph{i.e.}, for all $T_k$, $E|k$ begins with the invocation of a t-operation, is
sequential and has no events after $A_k$ or $C_k$.
A transaction $T_k\in \txns(E)$ is \emph{complete in $E$} if
$E|k$ ends with a response event.
The execution $E$ is \emph{complete} if all transactions in $\txns(E)$
are complete in $E$.
A transaction $T_k\in \txns(E)$ is \emph{t-complete} if $E|k$
ends with $A_k$ or $C_k$; otherwise, $T_k$ is \emph{t-incomplete}.
$T_k$ is \emph{committed} (resp., \emph{aborted}) in $E$
if the last event of $T_k$ is $C_k$ (resp., $A_k$).
The execution $E$ is \emph{t-complete} if all transactions in
$\txns(E)$ are t-complete.

For transactions $\{T_k,T_m\} \in \txns(E)$, we say that $T_k$ \emph{precedes}
$T_m$ in the \emph{real-time order} of $E$, denoted $T_k\prec_E^{RT} T_m$,
if $T_k$ is t-complete in $E$ and
the last event of $T_k$ precedes the first event of $T_m$ in $E$.
If neither $T_k\prec_E^{RT} T_m$ nor $T_m\prec_E^{RT} T_k$,
then $T_k$ and $T_m$ are \emph{concurrent} in $E$.
An execution $E$ is \emph{t-sequential} if there are no concurrent
transactions in $E$.

\vspace{1mm}\noindent\textbf{Latest written value and legality.}
Let $H$ be a t-sequential history.
For every operation $\Read_k(X)$ in $H$,
we define the \emph{latest written value} of $X$ as follows:
if $T_k$ contains a $\Write_k(X,v)$ preceding $\Read_k(X)$,
then the latest written value of $X$ is the value of the latest such write to $X$.
Otherwise,
the latest written value of $X$ is the value
of the argument of the latest $\Write_m(X,v)$ that precedes
$\Read_k(X)$ and belongs to a committed transaction in $H$.
(This write is well-defined since $H$ starts with $T_0$ writing to
all t-objects.)

We say that $\Read_k(X)$ is \emph{legal} in a t-sequential history $H$ 
if it returns the latest written value of $X$, and $H$ is \emph{legal}
if every $\Read_k(X)$ in $H$ that does not return $A_k$ is legal in $H$.

We also assume, for simplicity, that the user application invokes a $\Read_k(X)$
at most once within a transaction $T_k$.
This assumption incurs no loss of generality,
since a repeated read can be assigned to return a previously returned
value without affecting the history's legality.

\vspace{1mm}\noindent\textbf{Contention.}
We say that a configuration $C$ after an execution $E$ is \emph{quiescent} (resp., \emph{t-quiescent})
if every transaction $T_k \in \ms{txns}(E)$ is complete (resp., t-complete) in $C$.
If a transaction $T$ is incomplete in an execution $E$, it has exactly one \emph{enabled} event, 
which is the next event the transaction will perform according to the TM implementation.
Events $e$ and $e'$ of an execution $E$  \emph{contend} on a base
object $b$ if they are both events on $b$ in $E$ and at least 
one of them is nontrivial (the event is trivial (resp., nontrivial) 
if it is the application of a trivial (resp., nontrivial) primitive).


We say that $T$ is \emph{poised to apply an event $e$ after $E$} if $e$ is the next enabled event for $T$ in $E$.
We say that transactions $T$ and $T'$ \emph{concurrently contend on $b$ in $E$} 
if they are poised to apply contending events on $b$ after $E$.

We say that an execution fragment $E$ is \emph{step contention-free for t-operation $op_k$} if the events of $E|op_k$ 
are contiguous in $E$.
We say that an execution fragment $E$ is \emph{step contention-free for $T_k$} if the events of $E|k$ are contiguous in $E$.
We say that $E$ is \emph{step contention-free} if $E$ is step contention-free for all transactions that participate in $E$.
\section{TM-correctness}
\label{sec:tm-correctness}
Correctness for TMs is specified as a safety property on TM histories~\cite{OL82,AS85,Lyn96}.
In this section, we introduce the popular TM-correctness condition \emph{strict serializability}~\cite{Pap79-serial}:
all committed transactions appear to execute sequentially in some total order respecting the real-time transaction orders.
We then explain how strict serializability is related to \emph{linearizability}~\cite{HW90}.

In the thesis, we only consider TM-correctness conditions like strict serializability and its restrictions.
We formally define strict serializability below, but other TM-correctness conditions studied in the
thesis can be found in Chapter~\ref{ch:pc1}.

First, we define how to derive a t-complete history from a t-incomplete one.
\begin{definition}[Completions]
\label{def:comp}
Let $H$ be a history.
A \emph{completion of $H$}, denoted ${\overline{H}}$,
is a history derived from $H$ as follows:
\begin{itemize}
\item[--]
First, for every transaction $T_k \in \txns(H)$
with an incomplete t-operation $op_k$ in $H$,
if $op_k=\Read_k \vee \Write_k$,
insert $A_k$ somewhere after the invocation of $op_k$;
otherwise, if $op_k=\TryC_k()$,
insert $C_k$ or $A_k$ somewhere after the last event of $T_k$.
\item[--]
After all transactions are complete,
for every transaction $T_k$ that is not t-complete,
insert $\TryC_k\cdot A_k$ after the last event of transaction $T_k$.
\end{itemize}
\end{definition}
\begin{definition}[Strict serializability]
\label{def:oser}
A finite history $H$ is \emph{serializable} if there
is a legal t-complete t-sequential history $S$,
such that
there is a completion $\overline{H}$ of $H$,
such that $S$ is equivalent to $\ms{cseq}(\overline{H})$,
where $\ms{cseq}(\overline{H})$ is the subsequence of $\overline{H}$
reduced to committed transactions in $\overline{H}$.


We refer to $S$ as a \emph{serialization} of $H$.

We say that $H$ is \emph{strictly serializable} if there exists a serialization $S$ of $H$ such that
for any two transactions $T_k,T_m \in \txns(H)$,
if $T_k \prec_H^{RT} T_m$, then $T_k$ precedes $T_m$ in $S$.
\end{definition}
In general, given a TM-correctness condition $C$, we say that a TM implementation $M$ satisfies $C$ if every
execution of $M$ satisfies $C$.

\vspace{1mm}\noindent\textbf{Strict serializability as linearizability.}
We now show we can specify TM as an abstract data type.

The sequential specification of a TM is specified as follows:
\begin{enumerate}
\item
$\Phi$ is the set of all transactions $\{T_i\}_{i\in \mathbb{N}}$
\item 
$\Gamma$ is the set of incommensurate vectors $\{[r_1,\ldots, r_i ]\};i\in \mathbb{N}$; where each 
$r_j$; $1\leq j \leq i-1$ $\in \{v \in V, A, ok\}$ and $r_i \in \{A,C\}$
\item 
The state of TM is a vector of the state of each t-object $X_m$.
The state of a t-object $X_m$ is a value $v_m\in V$ of $X_m$.
Thus, $Q \subseteq \{ [v^i_1,\ldots, v^i_m, \ldots ]\}$; where each $v^i_m \in V$
\item 
$q_0 \in Q=[ov_1,\ldots, ov_m,\ldots ]$, where each $ov_m\in V$
\item 
$\delta$ is defined as follows:
Let $T_k$ be a transaction
applied to the TM in state $q=[v_1,\ldots, v_m, \ldots]$.
\begin{itemize}
\item For every $X\in \Rset(T_k)$, the response of $\Read_k(X)$ is defined as follows:
If $T_k$ contains a $\Write_k(X,v)$ prior to $\Read_k(X)$, then the response is $v$; else the response is the current state of $X$.
\item 
For every $X\in \Wset(T_k)$, the response of $\Write_k(X,v)$ is $ok$.
\item
Transaction $T_k$ returns the response $C$ in which case the TM moves to state $q'$ defined as follows:
every $X_j\in \Wset(T_k)$ to which $T_k$ writes values $nv_j$, $q'[j]=nv_j$; else if $X_j\not\in \Wset(T_k)$, $q'[j]$ is unchanged.
Otherwise, $T_k$ returns the response $A$ in which case $q'=q$.
\end{itemize}
\end{enumerate}
In general, the correctness of an implementation of a data type is commonly captured by the criterion 
of linearizability.
In the TM context, a t-complete history $H$ is \emph{linearizable} with 
respect to the TM type if there exists
a t-sequential history $S$ equivalent to $H$ such that
(1) $S$ respects the real-time ordering of transactions in $H$ and
(2) \emph{$S$ is consistent with the sequential specification of TM}.

The following lemma, which illustrates the similarity between strict serializability
and linearizability with respect to the TM type, is now immediate.
\begin{lemma}
\label{lm:serlin}
Let $H$ be any t-complete history. Then, $H$ is strictly serializable \emph{iff} $H$ is linearizable with respect to the
TM type.
\end{lemma}
\section{TM-progress}
\label{sec:tm-progress}
One may notice that a TM implementation that forces, in every execution to abort every transaction is trivially strictly
serializable, but not very useful.
A TM-progress condition specifies the conditions under which a transaction is allowed to abort.
Technically, a TM-progress condition specified this way is a \emph{safety property} since it can be violated
in a finite execution (cf. Chapter~\ref{ch:pc1} for details on safety properties).

Ideally, a TM-progress condition must provide \emph{non-blocking} progress, in the sense that a prematurely halted
transaction cannot prevent all other transactions from committing.
Such a TM-progress condition is also said to be \emph{lock-free}
since it cannot be achieved by use of locks and mutual-exclusion.
A non-blocking TM-progress condition is considered useful in asynchronous systems with process failures
since it prevents the TM implementation from deadlocking (processes wait infinitely long without
committing their transactions).

\vspace{1mm}\noindent\textbf{Obstruction-freedom.}
Perhaps, the weakest non-blocking TM-progress condition is obstruction-freedom, which stipulates
that a transaction may be aborted only if it encounters steps of a concurrent transaction~\cite{HS11-progress}.
\begin{definition}[Obstruction-free (OF) TM-progress]
We say that a TM implementation $M$ provides \emph{obstruction-free (OF) TM-progress} if for every execution $E$ of $M$, 
if any transaction $T_k \in \ms{txns}(E)$ returns $A_k$ in $E$, then $E$ is not step contention-free for $T_k$. 
\end{definition}
We now survey the popular \emph{blocking} TM-progress properties proposed in literature. Intuitively,
unlike non-blocking TM-progress conditions that adapt to \emph{step contention}, 
a blocking TM-progress condition allows a transaction to be aborted due to \emph{overlap contention}.

\vspace{1mm}\noindent\textbf{Minimal progressiveness.}
Intuitively, the most basic TM-progress condition is one which provide only \emph{sequential} TM-progress, \emph{i.e.},
a transaction may be aborted due to a concurrent transaction.
In literature, this is referred to as \emph{minimal progressiveness}~\cite{tm-book}.
\begin{definition}[Minimal progressiveness]
We say that a TM implementation $M$ provides \emph{minimal progressive} TM-progress (or \emph{minimal progressiveness}) 
if for every execution $E$ of $M$
and every transaction $T_k\in \ms{txns}(E)$ that returns $A_k$ in $E$, there exists a transaction $T_m\in \ms{txns}(E)$
that is concurrent to $T_k$ in $E$~\cite{tm-book}.
\end{definition}
Given TM conditions $C_1$ and $C_2$, if every TM implementation that satisfies 
$C_1$ also satisfies $C_2$, 
but the converse is not true, we say that $C_2$~$\ll$~$C_1$.
\begin{observation}
Minimal progressiveness~$\ll$ Obstruction-free.
\end{observation}
\begin{proof}
Clearly, every TM implementation that satisfies obstruction-freedom also satisfies minimal progressiveness, but the converse 
is not true.
Consider any execution of a TM implementation $M$ in which a transaction $T$ run step contention-free.
If $M$ is minimally progressive, then $T$ may be aborted in such an execution since $T$ may be concurrent with another transaction.
However, if $M$ satisfies obstruction-freedom, $T$ cannot be aborted in such an execution.
\end{proof}
\vspace{1mm}\noindent\textbf{Progressiveness.}
In contrast to the ``single-lock'' minimal progressive TM-progress
condition (also referred to as \emph{sequential} TM-progress in the thesis), 
state-of-the-art TM implementations
allow a transaction to abort only if it encounters a \emph{conflict} on a 
t-object with a concurrent transaction.
\begin{definition}[Conflicts]
We say that transactions $T_i,T_j$ \emph{conflict} in an execution $E$ on a t-object $X$ if
$T_i$ and $T_j$ are concurrent in $E$ and $X\in\Dset(T_i)\cap\Dset(T_j)$,  and $X\in\Wset(T_i)\cup\Wset(T_j)$.
\end{definition}
\begin{definition}[Progressiveness]
\label{def:progdef}
A TM implementation $M$ provides \emph{progressive} TM-progress (or \emph{progressiveness}) 
if for every execution $E$ of $M$ and every transaction $T_i \in \ms{txns}(E)$ that returns $A_i$ in $E$,
there exists a transaction $T_k \in \ms{txns}(E)$ such that $T_k$ and $T_i$
conflict in $E$~\cite{tm-book}. 
\end{definition}
Note that progressiveness is incomparable to obstruction-freedom.
\begin{observation}
Progressiveness~$\not\ll$~Obstruction-free and Obstruction-free~$\not\ll$~Progressiveness.
\end{observation}
\begin{proof}
We can show that there exists an execution exported by an obstruction-free TM, but not by any
progressive TM and vice-versa.

Consider a t-read $X$ by a transaction $T$ that runs step contention-free
from a configuration that contains an incomplete write to $X$. Weak progressiveness
does not preclude $T$ from being aborted in such an execution.
Obstruction-free TMs however, must ensure that $T$ must complete its read of $X$ without blocking or aborting in such executions.
On the other hand, weak progressiveness requires two non-conflicting transactions to not be aborted even
in executions that are not step contention-free; but this is not guaranteed by obstruction-freedom.
\end{proof}
In general, progressive TMs (including the ones described in the thesis) satisfy the following stronger definition: 
for every transaction $T_i \in \ms{txns}(E)$ that returns $A_i$ in an execution $E$, 
there exists prefix $E'$ of $E$ and a transaction $T_k \in \ms{txns}(E')$ such that $T_k$ and $T_i$
conflict in $E$. However, for the lower bound results stated in the thesis, we stick to Definition~\ref{def:progdef}.

\vspace{1mm}\noindent\textbf{Strong progressiveness.}
One may observe that the definition of progressiveness does not preclude two conflicting 
transactions (over a single t-object) from each being aborted.
Thus, we study a stronger notion of progressiveness called \emph{strong progressiveness}~\cite{tm-book}.

Let $CObj_E(T_i)$ denote the set of t-objects over which transaction $T_i \in \ms{txns}(H)$ conflicts with any other 
transaction in an execution $E$,
\emph{i.e.}, $X \in CObj_E(T_i)$, \emph{iff} there exist transactions $T_i$ and $T_k$
that conflict on $X$ in $E$.
Let $ Q\subseteq \ms{txns}(E)$ and $CObj_E(Q)=\bigcup\limits_{ T_i \in Q} CObj_E(T_i)$.

Let $\ms{CTrans}(E)$ denote the set of non-empty subsets of $\ms{txns}(E)$ such that a set $Q$ is in $\ms{CTrans}(E)$ 
if no transaction in $Q$ conflicts with a transaction not in $Q$.
\begin{definition}[Strong progressiveness]
\label{def:sprog}
A TM implementation $M$ is \emph{strongly progressive} if $M$ is weakly progressive 
and for every execution $E$ of $M$ and for every set $Q \in \ms{CTrans}(E)$ such that $|CObj_{E}(Q)| \leq 1$, 
some transaction in $Q$ is not aborted in $E$~\cite{tm-book}.
\end{definition}
The above definitions imply:
\begin{corollary}
Minimal progressiveness (sequential TM-progress)~$\ll$~Progressiveness~$\ll$~Strong progressiveness.
\end{corollary}
\vspace{1mm}\noindent\textbf{Mv-permissiveness.}
Perelman \emph{et al.} introduced the notion of \emph{mv-permissiveness}, a TM-progress property
designed to prevent read-only transactions from being aborted.
\begin{definition}[Mv-permissiveness]
\label{def:sprog}
A TM implementation $M$ is \emph{mv-permissive} if for every execution $E$ of $M$ and
for every transaction $T_k\in \ms{txns}(E)$ that returns $A_k$ in $E$, we have that $\Wset(T_k)\neq \emptyset$
and there exists an updating transaction $T_m\in \ms{txns}(E)$ such that $T_k$ and $T_m$ conflict in $E$.
\end{definition}
We observe that mv-permissiveness is strictly stronger than progressiveness, but incomparable to strong progressiveness.
\begin{observation}
Progressiveness~$\ll$~Mv-permissiveness.
\end{observation}
\begin{proof}
Since mv-permissive TMs allow a transaction to be aborted only on read-write conflicts, they also
satisfy progressiveness. But the converse is not true.
Consider an execution in which a read-only transaction $T_i$ that runs concurrently with a conflicting
updating transaction $T_j$.
By the definition of progressiveness, both $T_i$ and $T_j$ may be aborted in such an execution.
However, a mv-permissive TM would not allow $T_i$ to be aborted since it is read-only.
\end{proof}
\begin{observation}
Strong progressiveness~$\not\ll$~Mv-permissiveness and Mv-permissiveness~$\not\ll$~Strong progressiveness.
\end{observation}
\begin{proof}
Consider an execution in which a read-only transaction $T_i$ that runs concurrently with an
updating transaction $T_j$ such that $T_i$ and $T_j$ conflict on at least two t-objects.
By the definition of strong progressiveness, both $T_i$ and $T_j$ may be aborted in such an execution.
However, a mv-permissive TM would not allow $T_i$ to be aborted since it is read-only.

On the other hand, consider an execution in which two updating transactions $T_i$ and $T_j$ that conflict on a single t-object.
A mv-permissive TM allows both $T_i$ and $T_j$ to be aborted, but strong progressiveness ensures that at least one of
$T_i$ or $T_j$ is not aborted in such an execution.
\end{proof}
\section{TM-liveness}
\label{sec:tm-liveness}
Observe that a TM-progress condition only specifies the conditions under which a transaction is aborted, but does not
specify the conditions under which it must commit.
For instance, the OF TM-progress condition specifies that a transaction $T$ may be aborted only in executions
that are not step contention-free for $T$, but does not guarantee that $T$ is committed in a step contention-free execution.
Thus, in addition to a progress condition, we must stipulate a \emph{liveness}~\cite{AS85,Lyn96} condition.

We now define the TM-liveness conditions considered in the thesis.
\begin{definition}[Sequential TM-liveness]
A TM implementation $M$ provides \emph{sequential TM-liveness} if for every finite execution $E$ of $M$, 
and every transaction $T_k$ that runs t-sequentially and applies the invocation of a t-operation $op_k$ immediately after $E$, 
the finite step contention-free extension for $op_k$ contains a response.
\end{definition}
\begin{definition}[Interval contention-free (ICF) TM-liveness]
A TM implementation $M$ provides \emph{interval contention-free (ICF)} TM-liveness
if for every finite execution $E$ of $M$ such that the configuration after $E$ is quiescent, 
and every transaction $T_k$ that applies the invocation of a t-operation $op_k$ immediately after $E$, 
the finite step contention-free extension for $op_k$ contains a response.
\end{definition}
\begin{definition}[Starvation-free TM-liveness]
A TM implementation $M$ provides \emph{starvation-free TM-liveness} if in every execution of $M$, each t-operation 
eventually returns a matching response, assuming that no concurrent t-operation stops indefinitely before returning.  
\end{definition}
\begin{definition}[Obstruction-free (OF) TM-liveness]
A TM implementation $M$ provides \emph{obstruction-free (OF) TM-liveness} if for every finite execution $E$ of $M$, 
and every transaction $T_k$ that applies the invocation of a t-operation $op_k$ immediately after $E$, 
the finite step contention-free extension for $op_k$ contains a matching response.
\end{definition}
\begin{definition}[Wait-free (WF) TM-liveness]
A TM implementation $M$ provides \emph{wait-free (WF) TM-liveness} if
in every execution of $M$, every t-operation returns a response in a finite number of its steps.
\end{definition}
The following observations are immediate from the definitions:
\begin{observation}
Sequential TM-liveness~$\ll$~ICF TM-liveness~$\ll$~OF TM-liveness~$\ll$~WF TM-liveness
and
Starvation-free TM-liveness~$\ll$~WF TM-liveness.
\end{observation}
Since ICF TM-liveness guarantees that a t-operation returns a response if there is no other concurrent t-operation,
we have:
\begin{observation}
ICF TM-liveness~$\ll$~Starvation-free TM-liveness.
\end{observation}
However, we observe that OF TM-liveness and starvation-free TM-liveness are incomparable.
\begin{observation}
Starvation-free TM-liveness~$\not\ll$~OF TM-liveness and OF TM-liveness~$\not\ll$~Starvation-free TM-liveness.
\end{observation}
\begin{proof}
Consider the step contention-free execution of t-operation $op_k$ concurrent with t-operation $op_m$: $op_k$
must return a matching response within a finite number of its steps, but this is not necessarily ensured by starvation-free
TM-liveness ($op_m$ may be delayed indefinitely).
On the other hand, in executions where two concurrent t-operations $op_k$ and $op_k$ encounter step contention, but
neither stalls indefinitely, both must return matching responses. But this is not guaranteed by OF TM-liveness.
\end{proof}
\section{Invisible reads}
\label{sec:inv}
In this section, we introduce the notion of \emph{invisible reads} that intuitively ensures that
a reading transaction does not cause a concurrent transaction to abort.
Since most TM worklods are believed to be read-dominated, this is considered to be an important TM property for
performance~\cite{stmbench7, Attiya09-tmread}.

\vspace{1mm}\noindent\textbf{Invisible reads.}
Informally, in a TM using invisible reads, 
a transaction cannot reveal any information about its read set to
other transactions. Thus, given an execution $E$ and some transaction
$T_k$ with a non-empty read set, transactions other than $T_k$ cannot
distinguish $E$ from an execution in which $T_k$'s read set is empty.
This prevents TMs from applying nontrivial primitives
during t-read operations and from announcing read sets of transactions during tryCommit.
Most popular TM implementations like \emph{TL2}~\cite{DSS06} and
\emph{NOrec}~\cite{norec} satisfy this property.
\begin{definition}[Invisible reads~\cite{attiyaH13}]
We say that a TM implementation $M$ uses \emph{invisible reads} if
for every execution $E$ of $M$:
\begin{itemize}
\item
for every read-only transaction $T_k \in \ms{txns}(E)$, 
no event of $E|k$ is nontrivial in $E$, 
\item
for every updating transaction $T_k \in \ms{txns}(E)$; $\Rset_E(T_k)\neq \emptyset$, 
there exists an execution $E'$ of $M$ such that
\begin{itemize}
\item
$\Rset_{E'}(T_k)=\emptyset$,
\item
$\ms{txns}(E)=\ms{txns}(E')$ and $\forall T_m \in \ms{txns}(E) \setminus \{T_k\}$: $E|m=E'|m$
\item
for any two transactions $T_i, T_j \in \ms{txns}(E)$, 
if the last event of $T_i$ precedes the first event of $T_j$ in $E$, 
then the last event of $T_i$ precedes the first event of $T_j$ in $E'$.
\end{itemize}
\end{itemize}
\end{definition}
\vspace{1mm}\noindent\textbf{Weak invisible reads.}
We introduce the notion of \emph{weak} invisible reads that prevents t-read operations
from applying nontrivial primitives only in the absence of concurrent transactions.
Specifically, weak read invisibility allows t-read operations of a transaction
$T$ to be ``visible'', \emph{i.e.}, write to base objects, only if $T$ is concurrent with
another transaction.
\begin{definition}[Weak invisible reads]
For any execution $E$ and any t-operation $\pi_k$ invoked by some transaction $T_k\in \ms{txns}(E)$,
let $E|\pi_k$ denote the subsequence of $E$ restricted to events of $\pi_k$ in $E$.

We say that a TM implementation $M$ satisfies \emph{weak invisible reads}
if for any execution $E$ of $M$ and every transaction $T_k\in \ms{txns}(E)$; $\Rset(T_k)\neq \emptyset$ that is
not concurrent with any transaction $T_m\in \ms{txns}(E)$, $E|\pi_k$ does not contain any nontrivial events, where $\pi_k$ is
any t-read operation invoked by $T_k$ in $E$.
\end{definition}
For example, the popular TM implementation \emph{DSTM}~\cite{HLM+03} satisfies weak invisible reads, but not invisible reads.
Algorithm~\ref{alg:oftm} in Chapter~\ref{ch:p3c2} 
depicts a TM implementation that is based on DSTM satisfying weak invisible reads, but not
the stronger definition of invisible reads.
\section{Disjoint-access parallelism (DAP)}
\label{sec:dap}
The notion of \emph{disjoint-access parallelism (DAP)}~\cite{israeli-disjoint}
is considered important in the TM context since it allows two transactions accessing unrelated t-objects to execute
without memory contention.
In this section, we preview the DAP definitions proposed in literature and identify the relations between them.

\vspace{1mm}\noindent\textbf{Strict data-partitioning.}
Let $E|X$ denote the subsequence of the execution $E$ derived by removing all events associated with t-object $X$.
A TM implementation $M$ is \emph{strict data-partitioned}~\cite{tm-book}, if for every t-object $X$, 
there exists a set of base objects $\ms{Base}_M(X)$ such that
\begin{itemize}
\item
for any two t-objects $X_1, X_2$; $\ms{Base}_M(X_1) \cap \ms{Base}_M(X_2)=\emptyset$,
\item 
for every execution $E$ of $M$ and every transaction $T \in \ms{txns}(E)$,
every base object accessed by $T$ in $E$ is contained in $\ms{Base}_M(X)$ for some $X\in \Dset(T)$
\item
for all executions $E$ and $E'$ of $M$, if $E|X=E|X$ for some t-object $X$, then the configurations after $E$ and
$E'$ only differ in the states of the base objects in $\ms{Base}_M(X)$.
\end{itemize}
\vspace{1mm}\noindent\textbf{Strict disjoint-access parallelism.}
A TM implementation $M$ is \emph{strictly disjoint-access parallel
  (strict DAP)} if, for
all executions $E$ of $M$, and for all transactions $T_i$ and $T_j$ that participate in $E$, 
$T_i$ and $T_j$ contend on a base object in $E$ only if 
$\Dset(T_i)\cap \Dset(T_j)\neq \emptyset$~\cite{tm-book}.
\begin{proposition}
Strict DAP $\ll$ Strict data-partitioning.
\end{proposition}
\begin{proof}
Let $M$ be any strict data-partitioned TM implementation. Then, $M$ is also strict DAP. Indeed,
since any two transactions accessing mutually disjoint data sets in a strict data-partitioned implementation
cannot access a common base object in any execution $E$ of $M$, $E$ also ensures that
any two transactions
contend on the same base object in $E$ only if   
they access a common t-object.

Consider the following execution $E$ of a strict DAP TM implementaton $M$ 
that begins with two transactions $T_1$ and $T_2$ that access disjoint data sets in $E$. 
A strict data-partitioned TM implementation
would preclude transactions $T_1$ and $T_2$ from accessing the same base object, but a strict DAP
TM implementation does not preclude this possibility.
\end{proof}
We now describe two relaxations of strict DAP. For the formal definitions, we introduce the notion of a
\emph{conflict graph} which captures the dependency relation among t-objects accessed by transactions.

\vspace{1mm}\noindent\textbf{Read-write (RW) disjoint-access parallelism.}
Informally, read-write (RW) DAP means that two transactions
can \emph{contend}  
on a common base object only if their data 
sets are connected in the \emph{conflict graph}, capturing 
write-set overlaps among all concurrent transactions.

We denote by $\tau_{E}(T_i,T_j)$, the set of transactions ($T_i$ and $T_j$ included)
that are concurrent to at least one of $T_i$ and $T_j$ in an execution $E$.

Let ${\tilde G}(T_i,T_j,E)$ be an undirected graph whose vertex set is $\bigcup\limits_{T \in \tau_{E}(T_i,T_j)} \Dset(T)$
and there is an edge
between t-objects $X$ and $Y$ \emph{iff} there exists $T \in \tau_{E}(T_i,T_j)$ such that 
$\{X,Y\} \in \Wset(T)$.
We say that $T_i$ and $T_j$ are \emph{read-write disjoint-access} in $E$
if there is no path between a t-object in $\Dset(T_i)$ and a t-object in $\Dset(T_j)$ in ${\tilde G}(T_i,T_j,E)$.
A TM implementation $M$ is \emph{read-write disjoint-access parallel (RW DAP)} if, for
all executions $E$ of $M$, 
transactions $T_i$ and $T_j$ 
contend on the same base object in $E$ only if   
$T_i$ and $T_j$ are not read-write disjoint-access in $E$ or there exists a t-object $X \in \Dset(T_i) \cap \Dset(T_j)$.
\begin{proposition}
RW DAP $\ll$ Strict DAP.
\end{proposition}
\begin{proof}
From the definitions, it is immediate that every strict DAP TM implementation satisfies RW DAP.

But the converse is not true (Algorithm~\ref{alg:oftm} describes a TM implementation that satisfies RW and weak DAP, but not strict DAP).
Consider the following execution $E$ of a weak DAP or RW DAP TM implementaton $M$ 
that begins with the t-incomplete execution of a transaction $T_0$ that 
accesses t-objects $X$ and $Y$, followed by the step contention-free executions of two transactions $T_1$ and $T_2$ 
which access $X$ and $Y$ respectively. Transactions $T_1$ and $T_2$ may contend on a base object since 
there is a path between $X$ and $Y$ in $G(T_1,T_2,E)$. However, a strict DAP TM implementation
would preclude transactions $T_1$ and $T_2$ from contending on the same base object since $\Dset(T_1) \cap \Dset(T_2)=\emptyset$
in $E$.
\end{proof}
\vspace{1mm}\noindent\textbf{Weak disjoint-access parallelism.}
Informally, weak DAP means that two transactions
can \emph{concurrently contend}  
on a common base object only if their data 
sets are connected in the \emph{conflict graph}, capturing 
data-set overlaps among all concurrent transactions.

Let $G(T_i,T_j,E)$ be an undirected graph whose vertex set is $\bigcup\limits_{T \in \tau_{E}(T_i,T_j)} \Dset(T)$
and there is an edge
between t-objects $X$ and $Y$ \emph{iff} there exists $T \in \tau_{E}(T_i,T_j)$ such that 
$\{X,Y\} \in \Dset(T)$.
We say that $T_i$ and $T_j$ are \emph{disjoint-access} in $E$
if there is no path between a t-object in $\Dset(T_i)$ and a t-object in $\Dset(T_j)$ in $G(T_i,T_j,E)$.
A TM implementation $M$ is \emph{weak disjoint-access parallel (weak DAP)} if, for
all executions $E$ of $M$,
transactions $T_i$ and $T_j$ 
concurrently contend on the same base object in $E$ only if   
$T_i$ and $T_j$ are not disjoint-access in $E$ or there exists a t-object $X \in \Dset(T_i) \cap \Dset(T_j)$~\cite{AHM09,PFK10}.

We now prove an auxiliary lemma, inspired by \cite{AHM09}, concerning weak DAP TM implementations 
that will be useful in subsequent proofs. Intuitively, the lemma states that, two transactions that are disjoint-access
and running one after the other in an execution of a weak DAP TM cannot contend on the same base object.
\begin{lemma}
\label{lm:dap}
Let $M $ be any weak DAP TM implementation.
Let $\alpha\cdot \rho_1 \cdot \rho_2$ be any execution of $M$ where
$\rho_1$ (resp., $\rho_2$) is the step contention-free
execution fragment of transaction $T_1 \not\in \ms{txns}(\alpha)$ (resp., $T_2 \not\in \ms{txns}(\alpha)$) 
and transactions $T_1$, $T_2$ are disjoint-access in $\alpha\cdot \rho_1 \cdot \rho_2$. 
Then, $T_1$ and $T_2$ do not contend on any base object in $\alpha\cdot \rho_1 \cdot \rho_2$.
\end{lemma}
\begin{proof}
Suppose, by contradiction that $T_1$ and $T_2$ contend on the same base object in $\alpha\cdot \rho_1\cdot \rho_2$.

If in $\rho_1$, $T_1$ performs a nontrivial event on a base object on which they contend, let $e_1$ be the last
event in $\rho_1$ in which $T_1$ performs such an event to some base object $b$ and $e_2$, the first event
in $\rho_2$ that accesses $b$.
Otherwise, $T_1$
only performs trivial events in $\rho_1$ to base objects on which it contends with $T_2$ in $\alpha\cdot \rho_1\cdot \rho_2$:
let $e_2$ be the first event in $\rho_2$ in which $\rho_2$ performs a nontrivial event to some base object $b$
on which they contend and $e_1$, the last event of $\rho_1$ in $T_1$ that accesses $b$.

Let $\rho_1'$ (and resp. $\rho_2'$) be the longest prefix of $\rho_1$ (and resp. $\rho_2$) that does not include
$e_1$ (and resp. $e_2$).
Since before accessing $b$, the execution is step contention-free for $T_1$, $\alpha \cdot
\rho_1'\cdot \rho_2'$ is an execution of $M$.
By construction, $T_1$ and $T_2$ are disjoint-access in $\alpha \cdot \rho_1'\cdot \rho_2'$
and $\alpha\cdot \rho_1 \cdot \rho_2'$ is indistinguishable to $T_2$ from $\alpha\cdot \rho_1' \cdot \rho_2'$.
Hence, $T_1$ and
$T_2$ are poised to apply contending events $e_1$ and $e_2$ on $b$ in the configuration after 
$\alpha\cdot \rho_1' \cdot \rho_2'$---a contradiction since $T_1$ and $T_2$ cannot concurrently contend on the same base object.   
\end{proof}
We now show that weak DAP is a weaker property than RW DAP.
\begin{proposition}
Weak DAP $\ll$ RW DAP.
\end{proposition}
\begin{proof}
Clearly, every implementation that satisfies RW DAP also satisfies weak DAP since the conflict graph
${\tilde G}(T_i,T_j,E)$ (for RW DAP) is a subgraph of ${G}(T_i,T_j,E)$ (for weak DAP).

However, the converse is not true (Algorithm~\ref{alg:oftm2} describes a TM implementation that 
satisfies weak DAP, but not RW DAP).
Consider the following execution $E$ of a weak DAP TM implementaton $M$ 
that begins with the t-incomplete execution of a transaction $T_0$ that 
reads $X$ and writes to $Y$, followed by the step contention-free executions of two transactions $T_1$ and $T_2$ 
which write to $X$ and read $Y$ respectively. Transactions $T_1$ and $T_2$ may contend on a base object since 
there is a path between $X$ and $Y$ in $G(T_1,T_2,E)$. However, a RW DAP TM implementation
would preclude transactions $T_1$ and $T_2$ from contending on the same base object: there is no edge
between t-objects $X$ and $Y$ in the corresponding conflict graph ${\tilde G}(T_1,T_2,E)$ because
$X$ and $Y$ are not contained in the write set of $T_0$.
\end{proof}
Thus, the above propositions imply:
\begin{corollary}
Weak DAP~$\ll$~ RW DAP~$\ll$~Strict DAP~$\ll$~Strict data-partitioning.
\end{corollary}
\section{TM complexity metrics}
\label{sec:complexity}
We now present an overview of some of the TM complexity metrics we consider in the thesis.

\vspace{1mm}\noindent\textbf{Step complexity.}
The step complexity metric, is the total number of events that a process performs on the shared memory,
in the worst case, in order to complete its operation on the implementation.

\vspace{1mm}\noindent\textbf{RAW/AWAR patterns.}
Attiya \emph{et al.} identified two common expensive synchronization patterns that frequently arise in
the design of concurrent algorithms: \emph{read-after-write (RAW) or atomic write-after-read (AWAR)}~\cite{AGK11-popl,McKenney10}
and showed that it is 
impossible to derive RAW/AWAR-free implementations of
a wide class of data types that include \emph{sets}, \emph{queues} and \emph{deadlock-free mutual exclusion}.

Note the shared memory model in the thesis makes the assumption that CPU \emph{events} are performed atomically:
every ``read'' of a base object returns the value of ``latest write'' to the base object. In practice however,
the CPU architecture's \emph{memory model}~\cite{AdveG96} that specifies the outcome of CPU instructions
is \emph{relaxed} without enforcing a strict order among the shared memory instructions.
Intuitively, RAW (read-after-write) or AWAR (atomic-write-after-read)
patterns~\cite{AGK11-popl} capture the amount of ``expensive
synchronization'', \emph{i.e.}, the number of costly memory barriers or conditional primitives~\cite{AdveG96} incurred by the
implementation in relaxed CPU architectures.
The metric appears to be more practically relevant than simply counting the number of steps performed by a process, 
as it accounts for expensive cache-coherence operations or instructions like compare-and-swap.
Detailed coverage on memory fences and the RAW/AWAR metric can be found in \cite{McKenney10}.
\begin{definition}[Read-after-write metric]
A \emph{RAW} (read-after-write) pattern  performed by a transaction
$T_k$ in an execution $\pi$ 
is a pair of its events $e$ and $e'$, such that: (1) $e$ is a write to a
base object $b$ by $T_k$, 
(2) $e'$ is a subsequent read of a base object $b'\neq b$ by $T_k$, and 
(3) no event on $b$ by $T_k$ takes place between $e$ and $e'$. 
\end{definition}
In the thesis, we are concerned only with \emph{non-overlapping} RAWs,
\emph{i.e.}, the read performed by one RAW precedes the write 
performed by the other RAW.
\begin{definition}[Atomic write-after-read metric]
An \emph{AWAR} (atomic-write-after-read) pattern $e$ in an execution
$\pi\cdot e$ is a nontrivial rmw event on an object $b$ which
atomically returns the value of $b$ (resulting after $\pi$) and updates $b$ with a
new value.  
\end{definition}
For example, consider the execution $\pi\cdot e$ where $e$ is the application of a \emph{compare-and-swap} rmw primitive that
returns $\true$.

\vspace{1mm}\noindent\textbf{Stall complexity.}
Intuitively, the stall metric captures the fact that the time a process might have to spend before it applies a 
primitive on a base object can be proportional to the number of processes that try to update the object concurrently.  

Let $M$ be any TM implementation.
Let $e$ be an event applied by process $p$ to a base object $b$ as it performs a transaction $T$ during an execution $E$ of $M$.
Let $E=\alpha\cdot e_1\cdots e_m \cdot e \cdot \beta$ be an execution of $M$, where $\alpha$ and $\beta$ are execution 
fragments and $e_1\cdots e_m$
is a maximal sequence of $m\geq 1$ consecutive nontrivial events by distinct distinct processes other than $p$ that access $b$.
Then, we say that $T$ incurs $m$ \emph{memory stalls in $E$ on account of $e$}.
The \emph{number of memory stalls incurred by $T$ in $E$} is the sum of memory stalls incurred by all events of $T$ in $E$~\cite{G05,AGHK09}.

In the thesis, we adopt the following definition of a \emph{k-stall execution} from \cite{AGHK09,G05}.
\begin{definition}
\label{def:stalls}
An execution $\alpha\cdot \sigma_1 \cdots \sigma_i$ is a $k$-stall execution for t-operation $op$ executed by process $p$ if
\begin{itemize}
\item 
$\alpha$ is $p$-free,
\item
there are distinct base objects $b_1,\ldots , b_i$ and disjoint sets of processes $S_1,\ldots , S_i$
whose union does not include $p$
and has cardinality $k$ such that, for $j=1,\ldots i $,
\begin{itemize}
\item
each process in $S_j$ has an enabled nontrivial event about to access base object $b_j$ after $\alpha$, and
\item
in $\sigma_j$, $p$ applies events by itself until it is the first about to apply an event to $b_j$,
then each of the processes in $S_j$ applies an event that accesses $b_j$, and finally, $p$ applies an event that accesses $b_j$,
\end{itemize}
\item
$p$ invokes exactly one t-operation $op$ in the execution fragment $\sigma_1\cdots \sigma_i$
\item
$\sigma_1\cdots \sigma_i$ contains no events of processes not in $(\{p\}\cup S_1\cup \cdots \cup S_i)$
\item
in every $(\{p\}\cup S_1\cup \cdots \cup S_i)$-free execution fragment that extends $\alpha$, 
no process applies a nontrivial event to any base object accessed in $\sigma_1 \cdots \sigma_i$.
\end{itemize}
\end{definition}
Observe that in a $k$-stall execution $E$ for t-operation $op$, the number of memory stalls incurred by $op$
in $E$ is $k$.

The following lemma will be of use in our proofs.
\begin{lemma}
\label{lm:stalls}
Let $\alpha\cdot \sigma_1 \cdots \sigma_i$ be a $k$-stall execution for t-operation $op$ executed by process $p$.
Then, $\alpha\cdot \sigma_1 \cdots \sigma_i$ is indistinguishable to $p$ from a step contention-free execution~\cite{AGHK09}.
\end{lemma}
\vspace{1mm}\noindent\textbf{Remote memory references(RMR)~\cite{rmr-mutex}.}
Modern shared memory CPU architectures employ a \emph{memory hierarchy}~\cite{hennessy-patterson}:
a hierarchy of memory devices with different capacities and costs.
Some of the memory is \emph{local} to a given process while the rest of the memory is \emph{remote}.
Accesses to memory locations (\emph{i.e.} base objects) that are \emph{remote} to a given process
are often orders of magnitude slower than a \emph{local} access of the base object.
Thus, the performance of concurrent implementations in the shared memory model may depend on the number
of \emph{remote memory references} made to base objects~\cite{anderson-90-tpds}.

In the \emph{cache-coherent (CC) shared memory}, each process maintains \emph{local}
copies of shared base objects inside its cache, whose consistency is ensured by a \emph{coherence protocol}.
Informally, we say that an access to a base object $b$ is \emph{remote} to a process $p$ and 
causes a \emph{remote memory reference (RMR)} if $p$'s cache contains a 
cached copy of the object that is out of date or \emph{invalidated}; otherwise the access is \emph{local}.

In the \emph{write-through (CC) protocol}, to read a base object $b$, process $p$ must have a cached copy of $b$ that
has not been invalidated since its previous read. Otherwise, $p$ incurs a RMR. 
To write to $b$, $p$ causes a RMR that invalidates all cached copies
of $b$ and writes to the main memory.

In the \emph{write-back (CC) protocol}, $p$ reads a base object $b$ without causing a RMR if it holds a cached copy of $b$
in shared or exclusive mode; otherwise the access of $b$ causes a RMR that (1) 
invalidates all copies of $b$ held in exclusive mode, and writing $b$ back to the main memory,
(2) creates a cached copy of $b$ in shared mode.
Process $p$ can write to $b$ without causing a RMR if it holds a copy of $b$ in exclusive mode; otherwise
$p$ causes a RMR that invalidates all cached copies of $b$ and creates a cached copy of $b$ in exclusive mode.

In the \emph{distributed shared memory (DSM)}, each base object is forever assigned to a single process and it is
\emph{remote} to the others. Any access of a remote register causes a RMR.
%
