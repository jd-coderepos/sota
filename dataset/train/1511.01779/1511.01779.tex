\chapter{Transactional Memory model}
\label{ch:tm-model}
\epigraph{All models are wrong, but some models are useful.}
{\textit{George Edward Pelham Box}}
In this chapter, we formalize the TM model and discuss some important TM properties proposed in literature.
In Section~\ref{sec:c21}, we formalize the specification of TMs.
In Section~\ref{sec:tm-correctness}, we introduce the basic TM-correctness property of \emph{strict serializability}
that we consider in the thesis.
Sections~\ref{sec:tm-progress} and \ref{sec:tm-liveness} overview progress and liveness properties for TMs
respectively and identifies the relations between them.
Section~\ref{sec:inv} defines the notion of \emph{invisible reads} while
Section~\ref{sec:dap} is on \emph{disjoint-access parallelism}.
Finally, in Section~\ref{sec:complexity}, we introduce some of the complexity metrics considered in the thesis.
\section{TM interface and TM implementations}
\label{sec:c21}
In this section, we first describe the \emph{shared memory} model of computation and then introduce the TM abstraction.

\vspace{1mm}\noindent\textbf{The shared memory model.}
The thesis considers the standard \emph{asynchronous shared memory} model of computation in which
a set of  processes (that may \emph{fail by crashing}), 
communicate by applying \emph{operations} on shared \emph{objects}~\cite{AGHK09}.
An object is an instance of an \emph{abstract data type}.
An abstract data type  is a \emph{mealy machine} that is specified as a tuple
 where
 is a set of operations,
 is a set of responses,  is a set of states,  is an
initial state and  
is a transition relation that determines, for each state
and each operation, the set of possible
resulting states and produced responses~\cite{AFHHT07}. 
Here,  implies that when
an operation  is applied on an object of type 
in state , the object moves to state  and returns response .

An \emph{implementation} of an object type  provides a specific data-representation of  that is realized by
processes applying \emph{primitives} on shared \emph{base objects}, each of which is assigned an initial value. 
In order to implement an object, processes are provided with an algorithm, which is a set of deterministic
state-machines, one for each process.
In the thesis, we use the term primitive to refer to operations on base objects and reserve the term operation
for the object that is implemented from the base objects.


A primitive is a generic atomic \emph{read-modify-write} (\emph{rmw}) procedure applied to a base object~\cite{G05,Her91}.
It is characterized by a pair of functions :
given the current state of the base object,  is an \emph{update function} that
computes its state after the primitive is applied, while  
is a \emph{response function} that specifies the outcome of the primitive returned to the process.
A rmw primitive is \emph{trivial} if it never changes the value of the base object to which it is applied.
Otherwise, it is \emph{nontrivial}.
An rmw primitive  is \emph{conditional} if there exists ,  such that
 and there exists ,  such that
~\cite{cond-04}.

\emph{Read} is an example of a trivial rmw primitive that takes no input arguments: when applied
to a base object with value , the update function leaves the state of the base object unchanged and 
the response function returns the value .
\emph{Write} is an example of a nontrivial rmw primitive that takes an input argument : when applied to a base object
with value , its update function changes the value of the base object to  and its response function
returns .
\emph{Compare-and-swap} is an example of a nontrivial conditional rmw primitive: its update function receives an input argument 
 and changes the value  of the base object to which it is applied \emph{iff} .
\emph{Load-linked/store-conditional} is another example of a nontrivial conditional rmw primitive:
the \emph{load-linked} primitive executed by some process  returns the value of the base object to which
it is applied and the \emph{store-conditional} primitive's update function receives an input  and 
atomically changes the value of the base object to 
\emph{iff} the base object has not been updated by any other process since the load-linked event by .
\emph{Fetch-and-add} is an example of a nontrivial rmw primitive that is not conditional: its update
function applied to base object with an integer value  takes an integer  as input
and changes the value of the base object to .

\vspace{1mm}\noindent\textbf{Transactional memory (TM).}
\emph{Transactional memory}
allows a set of data items (called \emph{t-objects}) to be accessed 
via \emph{transactions}.
Every transaction  has a unique identifier . 
We make no assumptions on the \emph{size} of a t-object, \emph{i.e.}, 
the cardinality on the set  of possible values a t-object can store.
A transaction  may contain the following \emph{t-operations},
each being a matching pair of an \emph{invocation} and a \emph{response}:
 returns a value in , denoted , 
or a special value  (\emph{abort});
, for a value ,
returns \textit{ok} or ;
 returns  (\emph{commit}) or .
As we show in the subsequent Section~\ref{sec:tm-correctness}, we can specify
TM as an abstract data type.

Note that a TM interface may additionally provide a  t-operation that returns  or , 
which is the first t-operation
transaction  must invoke, or a  t-operation that returns .
However, the actions performed inside the  may be performed as part of the first t-operation performed
by the transaction. The  t-operation allows the user application
to explicitly abort a transaction and can be useful, but since each of the individual t-read or t-write are allowed to abort,
the  t-operation provides no additional expressive power to the TM interface.
Thus, for simplicity, we do not incorporate these t-operations in our TM specification.

\vspace{1mm}\noindent\textbf{TM implementations.}
A TM \emph{implementation} provides processes with algorithms
for implementing ,  and 
of a transaction  by applying primitives from a set of shared base objects, each of which is 
assigned an initial value.
We assume that a process starts a new transaction
only after its previous transaction has committed or aborted.

In the rest of this section, we define the terms specifically in the context of TM implementations, but
they may be used analogously in the context of any concurrent implementation of an abstract data type.

\vspace{1mm}\noindent\textbf{Executions and configurations.}
An \emph{event} of a process  (sometimes we say \emph{step} of )
is an invocation or response of an operation performed by  or a 
rmw primitive  applied by  to a base object 
along with its response  (we call it a \emph{rmw event} and write ).


A \emph{configuration} (of an implementation) specifies the value of each base object and 
the state of each process.
The \emph{initial configuration} is the configuration in which all 
base objects have their initial values and all processes are in their initial states.

An \emph{execution fragment} is a (finite or infinite) sequence of events.
An \emph{execution} of an implementation  is an execution
fragment where, starting from the initial configuration, each event is
issued according to  and each response of a rmw event  matches the state of  resulting from all
preceding events.
An execution  denotes the concatenation of  and execution fragment ,
and we say that  is an \emph{extension} of  or  \emph{extends} .

Let  be an execution fragment.
For every transaction (resp., process) identifier ,
 denotes the subsequence of  restricted to events of
transaction  (resp., process ).
If  is non-empty,
we say that  (resp., ) \emph{participates} in , else we say  is \emph{-free} (resp., \emph{-free}).
Two executions  and  are \emph{indistinguishable} to a set  of transactions, if
for each transaction , .
A TM \emph{history} is the subsequence of an execution consisting of the invocation and 
response events of t-operations.
Two histories  and  are \emph{equivalent} if 
and for every transaction , .

\vspace{1mm}\noindent\textbf{Data sets of transactions.}
The \emph{read set} (resp., the \emph{write set}) of a transaction  in an execution ,
denoted  (resp., ), is the set of t-objects that  reads (resp., writes to) in .
More specifically, if  contains an invocation of  (resp., ), we say
that  (resp., ) (for brevity, we sometimes omit the subscript  from the notation).
The \emph{data set} of  is .
A transaction is called \emph{read-only} if ; 
\emph{write-only} if  and
\emph{updating} if .
Note that, in our TM model, the data set of a transaction is not known apriori, \emph{i.e.}, at the start of the transaction
and it is identifiable only by the set of data items the transaction has invoked a read or write on in the given execution.

\vspace{1mm}\noindent\textbf{Transaction orders.}
Let  denote the set of transactions that participate in .
In an infinite history , 
we assume that each ,  is finite;
\emph{i.e.}, transactions do not issue an infinite number of t-operations.
An execution  is \emph{sequential} if every invocation of
a t-operation is either the last event in the history  exported by  or
is immediately followed by a matching response.
We assume that executions are \emph{well-formed}, \emph{i.e.}, for all ,  begins with the invocation of a t-operation, is
sequential and has no events after  or .
A transaction  is \emph{complete in } if
 ends with a response event.
The execution  is \emph{complete} if all transactions in 
are complete in .
A transaction  is \emph{t-complete} if 
ends with  or ; otherwise,  is \emph{t-incomplete}.
 is \emph{committed} (resp., \emph{aborted}) in 
if the last event of  is  (resp., ).
The execution  is \emph{t-complete} if all transactions in
 are t-complete.

For transactions , we say that  \emph{precedes}
 in the \emph{real-time order} of , denoted ,
if  is t-complete in  and
the last event of  precedes the first event of  in .
If neither  nor ,
then  and  are \emph{concurrent} in .
An execution  is \emph{t-sequential} if there are no concurrent
transactions in .

\vspace{1mm}\noindent\textbf{Latest written value and legality.}
Let  be a t-sequential history.
For every operation  in ,
we define the \emph{latest written value} of  as follows:
if  contains a  preceding ,
then the latest written value of  is the value of the latest such write to .
Otherwise,
the latest written value of  is the value
of the argument of the latest  that precedes
 and belongs to a committed transaction in .
(This write is well-defined since  starts with  writing to
all t-objects.)

We say that  is \emph{legal} in a t-sequential history  
if it returns the latest written value of , and  is \emph{legal}
if every  in  that does not return  is legal in .

We also assume, for simplicity, that the user application invokes a 
at most once within a transaction .
This assumption incurs no loss of generality,
since a repeated read can be assigned to return a previously returned
value without affecting the history's legality.

\vspace{1mm}\noindent\textbf{Contention.}
We say that a configuration  after an execution  is \emph{quiescent} (resp., \emph{t-quiescent})
if every transaction  is complete (resp., t-complete) in .
If a transaction  is incomplete in an execution , it has exactly one \emph{enabled} event, 
which is the next event the transaction will perform according to the TM implementation.
Events  and  of an execution   \emph{contend} on a base
object  if they are both events on  in  and at least 
one of them is nontrivial (the event is trivial (resp., nontrivial) 
if it is the application of a trivial (resp., nontrivial) primitive).


We say that  is \emph{poised to apply an event  after } if  is the next enabled event for  in .
We say that transactions  and  \emph{concurrently contend on  in } 
if they are poised to apply contending events on  after .

We say that an execution fragment  is \emph{step contention-free for t-operation } if the events of  
are contiguous in .
We say that an execution fragment  is \emph{step contention-free for } if the events of  are contiguous in .
We say that  is \emph{step contention-free} if  is step contention-free for all transactions that participate in .
\section{TM-correctness}
\label{sec:tm-correctness}
Correctness for TMs is specified as a safety property on TM histories~\cite{OL82,AS85,Lyn96}.
In this section, we introduce the popular TM-correctness condition \emph{strict serializability}~\cite{Pap79-serial}:
all committed transactions appear to execute sequentially in some total order respecting the real-time transaction orders.
We then explain how strict serializability is related to \emph{linearizability}~\cite{HW90}.

In the thesis, we only consider TM-correctness conditions like strict serializability and its restrictions.
We formally define strict serializability below, but other TM-correctness conditions studied in the
thesis can be found in Chapter~\ref{ch:pc1}.

First, we define how to derive a t-complete history from a t-incomplete one.
\begin{definition}[Completions]
\label{def:comp}
Let  be a history.
A \emph{completion of }, denoted ,
is a history derived from  as follows:
\begin{itemize}
\item[--]
First, for every transaction 
with an incomplete t-operation  in ,
if ,
insert  somewhere after the invocation of ;
otherwise, if ,
insert  or  somewhere after the last event of .
\item[--]
After all transactions are complete,
for every transaction  that is not t-complete,
insert  after the last event of transaction .
\end{itemize}
\end{definition}
\begin{definition}[Strict serializability]
\label{def:oser}
A finite history  is \emph{serializable} if there
is a legal t-complete t-sequential history ,
such that
there is a completion  of ,
such that  is equivalent to ,
where  is the subsequence of 
reduced to committed transactions in .


We refer to  as a \emph{serialization} of .

We say that  is \emph{strictly serializable} if there exists a serialization  of  such that
for any two transactions ,
if , then  precedes  in .
\end{definition}
In general, given a TM-correctness condition , we say that a TM implementation  satisfies  if every
execution of  satisfies .

\vspace{1mm}\noindent\textbf{Strict serializability as linearizability.}
We now show we can specify TM as an abstract data type.

The sequential specification of a TM is specified as follows:
\begin{enumerate}
\item
 is the set of all transactions 
\item 
 is the set of incommensurate vectors ; where each 
;   and 
\item 
The state of TM is a vector of the state of each t-object .
The state of a t-object  is a value  of .
Thus, ; where each 
\item 
, where each 
\item 
 is defined as follows:
Let  be a transaction
applied to the TM in state .
\begin{itemize}
\item For every , the response of  is defined as follows:
If  contains a  prior to , then the response is ; else the response is the current state of .
\item 
For every , the response of  is .
\item
Transaction  returns the response  in which case the TM moves to state  defined as follows:
every  to which  writes values , ; else if ,  is unchanged.
Otherwise,  returns the response  in which case .
\end{itemize}
\end{enumerate}
In general, the correctness of an implementation of a data type is commonly captured by the criterion 
of linearizability.
In the TM context, a t-complete history  is \emph{linearizable} with 
respect to the TM type if there exists
a t-sequential history  equivalent to  such that
(1)  respects the real-time ordering of transactions in  and
(2) \emph{ is consistent with the sequential specification of TM}.

The following lemma, which illustrates the similarity between strict serializability
and linearizability with respect to the TM type, is now immediate.
\begin{lemma}
\label{lm:serlin}
Let  be any t-complete history. Then,  is strictly serializable \emph{iff}  is linearizable with respect to the
TM type.
\end{lemma}
\section{TM-progress}
\label{sec:tm-progress}
One may notice that a TM implementation that forces, in every execution to abort every transaction is trivially strictly
serializable, but not very useful.
A TM-progress condition specifies the conditions under which a transaction is allowed to abort.
Technically, a TM-progress condition specified this way is a \emph{safety property} since it can be violated
in a finite execution (cf. Chapter~\ref{ch:pc1} for details on safety properties).

Ideally, a TM-progress condition must provide \emph{non-blocking} progress, in the sense that a prematurely halted
transaction cannot prevent all other transactions from committing.
Such a TM-progress condition is also said to be \emph{lock-free}
since it cannot be achieved by use of locks and mutual-exclusion.
A non-blocking TM-progress condition is considered useful in asynchronous systems with process failures
since it prevents the TM implementation from deadlocking (processes wait infinitely long without
committing their transactions).

\vspace{1mm}\noindent\textbf{Obstruction-freedom.}
Perhaps, the weakest non-blocking TM-progress condition is obstruction-freedom, which stipulates
that a transaction may be aborted only if it encounters steps of a concurrent transaction~\cite{HS11-progress}.
\begin{definition}[Obstruction-free (OF) TM-progress]
We say that a TM implementation  provides \emph{obstruction-free (OF) TM-progress} if for every execution  of , 
if any transaction  returns  in , then  is not step contention-free for . 
\end{definition}
We now survey the popular \emph{blocking} TM-progress properties proposed in literature. Intuitively,
unlike non-blocking TM-progress conditions that adapt to \emph{step contention}, 
a blocking TM-progress condition allows a transaction to be aborted due to \emph{overlap contention}.

\vspace{1mm}\noindent\textbf{Minimal progressiveness.}
Intuitively, the most basic TM-progress condition is one which provide only \emph{sequential} TM-progress, \emph{i.e.},
a transaction may be aborted due to a concurrent transaction.
In literature, this is referred to as \emph{minimal progressiveness}~\cite{tm-book}.
\begin{definition}[Minimal progressiveness]
We say that a TM implementation  provides \emph{minimal progressive} TM-progress (or \emph{minimal progressiveness}) 
if for every execution  of 
and every transaction  that returns  in , there exists a transaction 
that is concurrent to  in ~\cite{tm-book}.
\end{definition}
Given TM conditions  and , if every TM implementation that satisfies 
 also satisfies , 
but the converse is not true, we say that ~~.
\begin{observation}
Minimal progressiveness~ Obstruction-free.
\end{observation}
\begin{proof}
Clearly, every TM implementation that satisfies obstruction-freedom also satisfies minimal progressiveness, but the converse 
is not true.
Consider any execution of a TM implementation  in which a transaction  run step contention-free.
If  is minimally progressive, then  may be aborted in such an execution since  may be concurrent with another transaction.
However, if  satisfies obstruction-freedom,  cannot be aborted in such an execution.
\end{proof}
\vspace{1mm}\noindent\textbf{Progressiveness.}
In contrast to the ``single-lock'' minimal progressive TM-progress
condition (also referred to as \emph{sequential} TM-progress in the thesis), 
state-of-the-art TM implementations
allow a transaction to abort only if it encounters a \emph{conflict} on a 
t-object with a concurrent transaction.
\begin{definition}[Conflicts]
We say that transactions  \emph{conflict} in an execution  on a t-object  if
 and  are concurrent in  and ,  and .
\end{definition}
\begin{definition}[Progressiveness]
\label{def:progdef}
A TM implementation  provides \emph{progressive} TM-progress (or \emph{progressiveness}) 
if for every execution  of  and every transaction  that returns  in ,
there exists a transaction  such that  and 
conflict in ~\cite{tm-book}. 
\end{definition}
Note that progressiveness is incomparable to obstruction-freedom.
\begin{observation}
Progressiveness~~Obstruction-free and Obstruction-free~~Progressiveness.
\end{observation}
\begin{proof}
We can show that there exists an execution exported by an obstruction-free TM, but not by any
progressive TM and vice-versa.

Consider a t-read  by a transaction  that runs step contention-free
from a configuration that contains an incomplete write to . Weak progressiveness
does not preclude  from being aborted in such an execution.
Obstruction-free TMs however, must ensure that  must complete its read of  without blocking or aborting in such executions.
On the other hand, weak progressiveness requires two non-conflicting transactions to not be aborted even
in executions that are not step contention-free; but this is not guaranteed by obstruction-freedom.
\end{proof}
In general, progressive TMs (including the ones described in the thesis) satisfy the following stronger definition: 
for every transaction  that returns  in an execution , 
there exists prefix  of  and a transaction  such that  and 
conflict in . However, for the lower bound results stated in the thesis, we stick to Definition~\ref{def:progdef}.

\vspace{1mm}\noindent\textbf{Strong progressiveness.}
One may observe that the definition of progressiveness does not preclude two conflicting 
transactions (over a single t-object) from each being aborted.
Thus, we study a stronger notion of progressiveness called \emph{strong progressiveness}~\cite{tm-book}.

Let  denote the set of t-objects over which transaction  conflicts with any other 
transaction in an execution ,
\emph{i.e.}, , \emph{iff} there exist transactions  and 
that conflict on  in .
Let  and .

Let  denote the set of non-empty subsets of  such that a set  is in  
if no transaction in  conflicts with a transaction not in .
\begin{definition}[Strong progressiveness]
\label{def:sprog}
A TM implementation  is \emph{strongly progressive} if  is weakly progressive 
and for every execution  of  and for every set  such that , 
some transaction in  is not aborted in ~\cite{tm-book}.
\end{definition}
The above definitions imply:
\begin{corollary}
Minimal progressiveness (sequential TM-progress)~~Progressiveness~~Strong progressiveness.
\end{corollary}
\vspace{1mm}\noindent\textbf{Mv-permissiveness.}
Perelman \emph{et al.} introduced the notion of \emph{mv-permissiveness}, a TM-progress property
designed to prevent read-only transactions from being aborted.
\begin{definition}[Mv-permissiveness]
\label{def:sprog}
A TM implementation  is \emph{mv-permissive} if for every execution  of  and
for every transaction  that returns  in , we have that 
and there exists an updating transaction  such that  and  conflict in .
\end{definition}
We observe that mv-permissiveness is strictly stronger than progressiveness, but incomparable to strong progressiveness.
\begin{observation}
Progressiveness~~Mv-permissiveness.
\end{observation}
\begin{proof}
Since mv-permissive TMs allow a transaction to be aborted only on read-write conflicts, they also
satisfy progressiveness. But the converse is not true.
Consider an execution in which a read-only transaction  that runs concurrently with a conflicting
updating transaction .
By the definition of progressiveness, both  and  may be aborted in such an execution.
However, a mv-permissive TM would not allow  to be aborted since it is read-only.
\end{proof}
\begin{observation}
Strong progressiveness~~Mv-permissiveness and Mv-permissiveness~~Strong progressiveness.
\end{observation}
\begin{proof}
Consider an execution in which a read-only transaction  that runs concurrently with an
updating transaction  such that  and  conflict on at least two t-objects.
By the definition of strong progressiveness, both  and  may be aborted in such an execution.
However, a mv-permissive TM would not allow  to be aborted since it is read-only.

On the other hand, consider an execution in which two updating transactions  and  that conflict on a single t-object.
A mv-permissive TM allows both  and  to be aborted, but strong progressiveness ensures that at least one of
 or  is not aborted in such an execution.
\end{proof}
\section{TM-liveness}
\label{sec:tm-liveness}
Observe that a TM-progress condition only specifies the conditions under which a transaction is aborted, but does not
specify the conditions under which it must commit.
For instance, the OF TM-progress condition specifies that a transaction  may be aborted only in executions
that are not step contention-free for , but does not guarantee that  is committed in a step contention-free execution.
Thus, in addition to a progress condition, we must stipulate a \emph{liveness}~\cite{AS85,Lyn96} condition.

We now define the TM-liveness conditions considered in the thesis.
\begin{definition}[Sequential TM-liveness]
A TM implementation  provides \emph{sequential TM-liveness} if for every finite execution  of , 
and every transaction  that runs t-sequentially and applies the invocation of a t-operation  immediately after , 
the finite step contention-free extension for  contains a response.
\end{definition}
\begin{definition}[Interval contention-free (ICF) TM-liveness]
A TM implementation  provides \emph{interval contention-free (ICF)} TM-liveness
if for every finite execution  of  such that the configuration after  is quiescent, 
and every transaction  that applies the invocation of a t-operation  immediately after , 
the finite step contention-free extension for  contains a response.
\end{definition}
\begin{definition}[Starvation-free TM-liveness]
A TM implementation  provides \emph{starvation-free TM-liveness} if in every execution of , each t-operation 
eventually returns a matching response, assuming that no concurrent t-operation stops indefinitely before returning.  
\end{definition}
\begin{definition}[Obstruction-free (OF) TM-liveness]
A TM implementation  provides \emph{obstruction-free (OF) TM-liveness} if for every finite execution  of , 
and every transaction  that applies the invocation of a t-operation  immediately after , 
the finite step contention-free extension for  contains a matching response.
\end{definition}
\begin{definition}[Wait-free (WF) TM-liveness]
A TM implementation  provides \emph{wait-free (WF) TM-liveness} if
in every execution of , every t-operation returns a response in a finite number of its steps.
\end{definition}
The following observations are immediate from the definitions:
\begin{observation}
Sequential TM-liveness~~ICF TM-liveness~~OF TM-liveness~~WF TM-liveness
and
Starvation-free TM-liveness~~WF TM-liveness.
\end{observation}
Since ICF TM-liveness guarantees that a t-operation returns a response if there is no other concurrent t-operation,
we have:
\begin{observation}
ICF TM-liveness~~Starvation-free TM-liveness.
\end{observation}
However, we observe that OF TM-liveness and starvation-free TM-liveness are incomparable.
\begin{observation}
Starvation-free TM-liveness~~OF TM-liveness and OF TM-liveness~~Starvation-free TM-liveness.
\end{observation}
\begin{proof}
Consider the step contention-free execution of t-operation  concurrent with t-operation : 
must return a matching response within a finite number of its steps, but this is not necessarily ensured by starvation-free
TM-liveness ( may be delayed indefinitely).
On the other hand, in executions where two concurrent t-operations  and  encounter step contention, but
neither stalls indefinitely, both must return matching responses. But this is not guaranteed by OF TM-liveness.
\end{proof}
\section{Invisible reads}
\label{sec:inv}
In this section, we introduce the notion of \emph{invisible reads} that intuitively ensures that
a reading transaction does not cause a concurrent transaction to abort.
Since most TM worklods are believed to be read-dominated, this is considered to be an important TM property for
performance~\cite{stmbench7, Attiya09-tmread}.

\vspace{1mm}\noindent\textbf{Invisible reads.}
Informally, in a TM using invisible reads, 
a transaction cannot reveal any information about its read set to
other transactions. Thus, given an execution  and some transaction
 with a non-empty read set, transactions other than  cannot
distinguish  from an execution in which 's read set is empty.
This prevents TMs from applying nontrivial primitives
during t-read operations and from announcing read sets of transactions during tryCommit.
Most popular TM implementations like \emph{TL2}~\cite{DSS06} and
\emph{NOrec}~\cite{norec} satisfy this property.
\begin{definition}[Invisible reads~\cite{attiyaH13}]
We say that a TM implementation  uses \emph{invisible reads} if
for every execution  of :
\begin{itemize}
\item
for every read-only transaction , 
no event of  is nontrivial in , 
\item
for every updating transaction ; , 
there exists an execution  of  such that
\begin{itemize}
\item
,
\item
 and : 
\item
for any two transactions , 
if the last event of  precedes the first event of  in , 
then the last event of  precedes the first event of  in .
\end{itemize}
\end{itemize}
\end{definition}
\vspace{1mm}\noindent\textbf{Weak invisible reads.}
We introduce the notion of \emph{weak} invisible reads that prevents t-read operations
from applying nontrivial primitives only in the absence of concurrent transactions.
Specifically, weak read invisibility allows t-read operations of a transaction
 to be ``visible'', \emph{i.e.}, write to base objects, only if  is concurrent with
another transaction.
\begin{definition}[Weak invisible reads]
For any execution  and any t-operation  invoked by some transaction ,
let  denote the subsequence of  restricted to events of  in .

We say that a TM implementation  satisfies \emph{weak invisible reads}
if for any execution  of  and every transaction ;  that is
not concurrent with any transaction ,  does not contain any nontrivial events, where  is
any t-read operation invoked by  in .
\end{definition}
For example, the popular TM implementation \emph{DSTM}~\cite{HLM+03} satisfies weak invisible reads, but not invisible reads.
Algorithm~\ref{alg:oftm} in Chapter~\ref{ch:p3c2} 
depicts a TM implementation that is based on DSTM satisfying weak invisible reads, but not
the stronger definition of invisible reads.
\section{Disjoint-access parallelism (DAP)}
\label{sec:dap}
The notion of \emph{disjoint-access parallelism (DAP)}~\cite{israeli-disjoint}
is considered important in the TM context since it allows two transactions accessing unrelated t-objects to execute
without memory contention.
In this section, we preview the DAP definitions proposed in literature and identify the relations between them.

\vspace{1mm}\noindent\textbf{Strict data-partitioning.}
Let  denote the subsequence of the execution  derived by removing all events associated with t-object .
A TM implementation  is \emph{strict data-partitioned}~\cite{tm-book}, if for every t-object , 
there exists a set of base objects  such that
\begin{itemize}
\item
for any two t-objects ; ,
\item 
for every execution  of  and every transaction ,
every base object accessed by  in  is contained in  for some 
\item
for all executions  and  of , if  for some t-object , then the configurations after  and
 only differ in the states of the base objects in .
\end{itemize}
\vspace{1mm}\noindent\textbf{Strict disjoint-access parallelism.}
A TM implementation  is \emph{strictly disjoint-access parallel
  (strict DAP)} if, for
all executions  of , and for all transactions  and  that participate in , 
 and  contend on a base object in  only if 
~\cite{tm-book}.
\begin{proposition}
Strict DAP  Strict data-partitioning.
\end{proposition}
\begin{proof}
Let  be any strict data-partitioned TM implementation. Then,  is also strict DAP. Indeed,
since any two transactions accessing mutually disjoint data sets in a strict data-partitioned implementation
cannot access a common base object in any execution  of ,  also ensures that
any two transactions
contend on the same base object in  only if   
they access a common t-object.

Consider the following execution  of a strict DAP TM implementaton  
that begins with two transactions  and  that access disjoint data sets in . 
A strict data-partitioned TM implementation
would preclude transactions  and  from accessing the same base object, but a strict DAP
TM implementation does not preclude this possibility.
\end{proof}
We now describe two relaxations of strict DAP. For the formal definitions, we introduce the notion of a
\emph{conflict graph} which captures the dependency relation among t-objects accessed by transactions.

\vspace{1mm}\noindent\textbf{Read-write (RW) disjoint-access parallelism.}
Informally, read-write (RW) DAP means that two transactions
can \emph{contend}  
on a common base object only if their data 
sets are connected in the \emph{conflict graph}, capturing 
write-set overlaps among all concurrent transactions.

We denote by , the set of transactions ( and  included)
that are concurrent to at least one of  and  in an execution .

Let  be an undirected graph whose vertex set is 
and there is an edge
between t-objects  and  \emph{iff} there exists  such that 
.
We say that  and  are \emph{read-write disjoint-access} in 
if there is no path between a t-object in  and a t-object in  in .
A TM implementation  is \emph{read-write disjoint-access parallel (RW DAP)} if, for
all executions  of , 
transactions  and  
contend on the same base object in  only if   
 and  are not read-write disjoint-access in  or there exists a t-object .
\begin{proposition}
RW DAP  Strict DAP.
\end{proposition}
\begin{proof}
From the definitions, it is immediate that every strict DAP TM implementation satisfies RW DAP.

But the converse is not true (Algorithm~\ref{alg:oftm} describes a TM implementation that satisfies RW and weak DAP, but not strict DAP).
Consider the following execution  of a weak DAP or RW DAP TM implementaton  
that begins with the t-incomplete execution of a transaction  that 
accesses t-objects  and , followed by the step contention-free executions of two transactions  and  
which access  and  respectively. Transactions  and  may contend on a base object since 
there is a path between  and  in . However, a strict DAP TM implementation
would preclude transactions  and  from contending on the same base object since 
in .
\end{proof}
\vspace{1mm}\noindent\textbf{Weak disjoint-access parallelism.}
Informally, weak DAP means that two transactions
can \emph{concurrently contend}  
on a common base object only if their data 
sets are connected in the \emph{conflict graph}, capturing 
data-set overlaps among all concurrent transactions.

Let  be an undirected graph whose vertex set is 
and there is an edge
between t-objects  and  \emph{iff} there exists  such that 
.
We say that  and  are \emph{disjoint-access} in 
if there is no path between a t-object in  and a t-object in  in .
A TM implementation  is \emph{weak disjoint-access parallel (weak DAP)} if, for
all executions  of ,
transactions  and  
concurrently contend on the same base object in  only if   
 and  are not disjoint-access in  or there exists a t-object ~\cite{AHM09,PFK10}.

We now prove an auxiliary lemma, inspired by \cite{AHM09}, concerning weak DAP TM implementations 
that will be useful in subsequent proofs. Intuitively, the lemma states that, two transactions that are disjoint-access
and running one after the other in an execution of a weak DAP TM cannot contend on the same base object.
\begin{lemma}
\label{lm:dap}
Let  be any weak DAP TM implementation.
Let  be any execution of  where
 (resp., ) is the step contention-free
execution fragment of transaction  (resp., ) 
and transactions ,  are disjoint-access in . 
Then,  and  do not contend on any base object in .
\end{lemma}
\begin{proof}
Suppose, by contradiction that  and  contend on the same base object in .

If in ,  performs a nontrivial event on a base object on which they contend, let  be the last
event in  in which  performs such an event to some base object  and , the first event
in  that accesses .
Otherwise, 
only performs trivial events in  to base objects on which it contends with  in :
let  be the first event in  in which  performs a nontrivial event to some base object 
on which they contend and , the last event of  in  that accesses .

Let  (and resp. ) be the longest prefix of  (and resp. ) that does not include
 (and resp. ).
Since before accessing , the execution is step contention-free for ,  is an execution of .
By construction,  and  are disjoint-access in 
and  is indistinguishable to  from .
Hence,  and
 are poised to apply contending events  and  on  in the configuration after 
---a contradiction since  and  cannot concurrently contend on the same base object.   
\end{proof}
We now show that weak DAP is a weaker property than RW DAP.
\begin{proposition}
Weak DAP  RW DAP.
\end{proposition}
\begin{proof}
Clearly, every implementation that satisfies RW DAP also satisfies weak DAP since the conflict graph
 (for RW DAP) is a subgraph of  (for weak DAP).

However, the converse is not true (Algorithm~\ref{alg:oftm2} describes a TM implementation that 
satisfies weak DAP, but not RW DAP).
Consider the following execution  of a weak DAP TM implementaton  
that begins with the t-incomplete execution of a transaction  that 
reads  and writes to , followed by the step contention-free executions of two transactions  and  
which write to  and read  respectively. Transactions  and  may contend on a base object since 
there is a path between  and  in . However, a RW DAP TM implementation
would preclude transactions  and  from contending on the same base object: there is no edge
between t-objects  and  in the corresponding conflict graph  because
 and  are not contained in the write set of .
\end{proof}
Thus, the above propositions imply:
\begin{corollary}
Weak DAP~~ RW DAP~~Strict DAP~~Strict data-partitioning.
\end{corollary}
\section{TM complexity metrics}
\label{sec:complexity}
We now present an overview of some of the TM complexity metrics we consider in the thesis.

\vspace{1mm}\noindent\textbf{Step complexity.}
The step complexity metric, is the total number of events that a process performs on the shared memory,
in the worst case, in order to complete its operation on the implementation.

\vspace{1mm}\noindent\textbf{RAW/AWAR patterns.}
Attiya \emph{et al.} identified two common expensive synchronization patterns that frequently arise in
the design of concurrent algorithms: \emph{read-after-write (RAW) or atomic write-after-read (AWAR)}~\cite{AGK11-popl,McKenney10}
and showed that it is 
impossible to derive RAW/AWAR-free implementations of
a wide class of data types that include \emph{sets}, \emph{queues} and \emph{deadlock-free mutual exclusion}.

Note the shared memory model in the thesis makes the assumption that CPU \emph{events} are performed atomically:
every ``read'' of a base object returns the value of ``latest write'' to the base object. In practice however,
the CPU architecture's \emph{memory model}~\cite{AdveG96} that specifies the outcome of CPU instructions
is \emph{relaxed} without enforcing a strict order among the shared memory instructions.
Intuitively, RAW (read-after-write) or AWAR (atomic-write-after-read)
patterns~\cite{AGK11-popl} capture the amount of ``expensive
synchronization'', \emph{i.e.}, the number of costly memory barriers or conditional primitives~\cite{AdveG96} incurred by the
implementation in relaxed CPU architectures.
The metric appears to be more practically relevant than simply counting the number of steps performed by a process, 
as it accounts for expensive cache-coherence operations or instructions like compare-and-swap.
Detailed coverage on memory fences and the RAW/AWAR metric can be found in \cite{McKenney10}.
\begin{definition}[Read-after-write metric]
A \emph{RAW} (read-after-write) pattern  performed by a transaction
 in an execution  
is a pair of its events  and , such that: (1)  is a write to a
base object  by , 
(2)  is a subsequent read of a base object  by , and 
(3) no event on  by  takes place between  and . 
\end{definition}
In the thesis, we are concerned only with \emph{non-overlapping} RAWs,
\emph{i.e.}, the read performed by one RAW precedes the write 
performed by the other RAW.
\begin{definition}[Atomic write-after-read metric]
An \emph{AWAR} (atomic-write-after-read) pattern  in an execution
 is a nontrivial rmw event on an object  which
atomically returns the value of  (resulting after ) and updates  with a
new value.  
\end{definition}
For example, consider the execution  where  is the application of a \emph{compare-and-swap} rmw primitive that
returns .

\vspace{1mm}\noindent\textbf{Stall complexity.}
Intuitively, the stall metric captures the fact that the time a process might have to spend before it applies a 
primitive on a base object can be proportional to the number of processes that try to update the object concurrently.  

Let  be any TM implementation.
Let  be an event applied by process  to a base object  as it performs a transaction  during an execution  of .
Let  be an execution of , where  and  are execution 
fragments and 
is a maximal sequence of  consecutive nontrivial events by distinct distinct processes other than  that access .
Then, we say that  incurs  \emph{memory stalls in  on account of }.
The \emph{number of memory stalls incurred by  in } is the sum of memory stalls incurred by all events of  in ~\cite{G05,AGHK09}.

In the thesis, we adopt the following definition of a \emph{k-stall execution} from \cite{AGHK09,G05}.
\begin{definition}
\label{def:stalls}
An execution  is a -stall execution for t-operation  executed by process  if
\begin{itemize}
\item 
 is -free,
\item
there are distinct base objects  and disjoint sets of processes 
whose union does not include 
and has cardinality  such that, for ,
\begin{itemize}
\item
each process in  has an enabled nontrivial event about to access base object  after , and
\item
in ,  applies events by itself until it is the first about to apply an event to ,
then each of the processes in  applies an event that accesses , and finally,  applies an event that accesses ,
\end{itemize}
\item
 invokes exactly one t-operation  in the execution fragment 
\item
 contains no events of processes not in 
\item
in every -free execution fragment that extends , 
no process applies a nontrivial event to any base object accessed in .
\end{itemize}
\end{definition}
Observe that in a -stall execution  for t-operation , the number of memory stalls incurred by 
in  is .

The following lemma will be of use in our proofs.
\begin{lemma}
\label{lm:stalls}
Let  be a -stall execution for t-operation  executed by process .
Then,  is indistinguishable to  from a step contention-free execution~\cite{AGHK09}.
\end{lemma}
\vspace{1mm}\noindent\textbf{Remote memory references(RMR)~\cite{rmr-mutex}.}
Modern shared memory CPU architectures employ a \emph{memory hierarchy}~\cite{hennessy-patterson}:
a hierarchy of memory devices with different capacities and costs.
Some of the memory is \emph{local} to a given process while the rest of the memory is \emph{remote}.
Accesses to memory locations (\emph{i.e.} base objects) that are \emph{remote} to a given process
are often orders of magnitude slower than a \emph{local} access of the base object.
Thus, the performance of concurrent implementations in the shared memory model may depend on the number
of \emph{remote memory references} made to base objects~\cite{anderson-90-tpds}.

In the \emph{cache-coherent (CC) shared memory}, each process maintains \emph{local}
copies of shared base objects inside its cache, whose consistency is ensured by a \emph{coherence protocol}.
Informally, we say that an access to a base object  is \emph{remote} to a process  and 
causes a \emph{remote memory reference (RMR)} if 's cache contains a 
cached copy of the object that is out of date or \emph{invalidated}; otherwise the access is \emph{local}.

In the \emph{write-through (CC) protocol}, to read a base object , process  must have a cached copy of  that
has not been invalidated since its previous read. Otherwise,  incurs a RMR. 
To write to ,  causes a RMR that invalidates all cached copies
of  and writes to the main memory.

In the \emph{write-back (CC) protocol},  reads a base object  without causing a RMR if it holds a cached copy of 
in shared or exclusive mode; otherwise the access of  causes a RMR that (1) 
invalidates all copies of  held in exclusive mode, and writing  back to the main memory,
(2) creates a cached copy of  in shared mode.
Process  can write to  without causing a RMR if it holds a copy of  in exclusive mode; otherwise
 causes a RMR that invalidates all cached copies of  and creates a cached copy of  in exclusive mode.

In the \emph{distributed shared memory (DSM)}, each base object is forever assigned to a single process and it is
\emph{remote} to the others. Any access of a remote register causes a RMR.
%
