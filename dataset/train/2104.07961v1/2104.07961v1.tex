\documentclass{article}
\usepackage{spconf,amsmath,graphicx}

\usepackage{url}
\usepackage{booktabs}
\usepackage{multirow}
\usepackage{amsfonts}
\usepackage[misc]{ifsym}
\usepackage{setspace}
\usepackage{bm}
\usepackage{enumitem}

\setlist{nosep, leftmargin=14pt}

\usepackage{mwe} 

\def\x{{\mathbf x}}
\def\L{{\cal L}}

\title{Advanced Deep Networks for 3D Mitochondria Instance Segmentation}
\name{Mingxing Li, Chang Chen, Xiaoyu Liu, Wei Huang, Yueyi Zhang, Zhiwei Xiong
}
\address{University of Science and Technology of China}
\begin{document}
\maketitle
\begin{abstract}
Mitochondria instance segmentation from electron microscopy (EM) images has seen notable progress since the introduction of deep learning methods. In this paper, we propose two advanced deep networks, named Res-UNet-R and Res-UNet-H, for 3D mitochondria instance segmentation from Rat and Human samples. Specifically, we design a simple yet effective anisotropic convolution block and deploy a multi-scale training strategy, which together boost the segmentation performance. Moreover, we enhance the generalizability of the trained models on the test set by adding a denoising operation as pre-processing. In the Large-scale 3D Mitochondria Instance Segmentation Challenge, our team ranks the 1st on the leaderboard at the end of the testing phase. Code is available at \url{https://github.com/Limingxing00/MitoEM2021-Challenge}




\end{abstract}
\begin{keywords}
Electron microscopy, mitochondria, instance segmentation, deep network
\end{keywords}

\section{Introduction}
\label{sec:introduction}
As an important kind of organelle, mitochondria provide energy for cells and are of great value to the research of life science. Generally, electron microscopy (EM) images that contain recognizable mitochondria  consume a huge storage, e.g., at the scale of Terabyte \cite{motta2019dense}.
Manual instance segmentation of mitochondria from such a large amount of data is  impossible, and automatic segmentation algorithms are highly desired. As pioneer works,
Lucci et al. \cite{lucchi2011supervoxel} propose a supervoxel-based method with learned  shape features to recognize mitochondria.
Seyedhosseini et al. \cite{seyedhosseini2013segmentation} use algebraic curves and a random forest classifier to segment mitochondria. 
Due to the limited generalizability, however, these traditional methods cannot be easily adapted to large-scale datasets such as MitoEM \cite{wei2020mitoem} including both rat and human samples.



Recently, some methods based on convolutional neural networks (CNNs) have emerged for mitochondrial segmentation.
For example, Oztel et al. \cite{oztel2017mitochondria} propose a deep network to first segment 2D mitochondria slices and then integrate 3D information with median filtering in the axial dimension.
Wei et al. \cite{wei2020mitoem} summarize the CNN-based methods  into two groups, top-down methods and bottom-up methods. Representative top-down methods use Mask-RCNN \cite{he2017mask} for instance segmentation. Due to the elongated and distorted shape of mitochondria, however, it is difficult to set a proper anchor size for Mask-RCNN in this task.
The bottom-up methods usually predict a binary segmentation mask \cite{ronneberger2015u}, an affinity map \cite{lee2017superhuman}, or a binary mask  with the instance boundary \cite{chen2016dcan}. Then a post-processing algorithm is used to distinguish instances. Despite of the notable progress achieved, there is still a large room for improving the performance of mitochondria instance segmentation.



\begin{figure*}[t]
	\centering
	\includegraphics[width=0.96\textwidth]{figure/framework.pdf} \caption{Network structure of Res-UNet-R. Note that the decoder of Res-UNet-H has two paths to generate the semantic mask and the instance boundary separately.}
	\label{fig:framework}
\end{figure*}

In this paper, we propose two advanced deep residual networks based on the 3D UNet backbone \cite{cciccek20163d}, named Res-UNet-R for the rat sample and Res-UNet-H for the human sample in the MitoEM dataset. Both networks generate the same form of outputs, including a semantic mask and an instance boundary. Since the human sample is more difficult (i.e., containing more noise) than the rat sample, we increase a decoder path for Res-UNet-H to predict the semantic mask and the instance boundary separately, while the decoder of Res-UNet-R has only one path. Obtaining the semantic mask and the instance boundary, we then synthesize a seed map. Finally, we adopt the connected component labeling    to obtain the mitochondria instances.

To boost the segmentation performance of our networks, we design a simple yet effective anisotropic convolution block and deploy a multi-scale training strategy. The effectiveness of these two components is validated by comprehensive experiments. Moreover, we observe that noise caused by staining precipitates is sparsely distributed in the MitoEM dataset. Especially in the human sample, the noise level is subjectively stronger than that in the rat sample. To alleviate the influence of noise on segmentation, we utilize an interpolation network \cite{niklaus2017video,huang2020learning} to restore the noisy regions coarsely marked by labor. It is demonstrated that the generalizability of the trained models can be enhanced on the test set by adding this denoising operation as pre-processing.
\vspace{-0.5cm}






\section{Method}
\label{sec:method}
\subsection{Res-UNet-R and Res-UNet-H}
We follow the bottom-up methods to extract the response map of mitochondria first. For the rat sample and the human sample, we propose two deep residual networks named Res-UNet-R and Res-UNet-H respectively. In the following description, we omit the exponential linear unit (ELU) after the convolutional layer for brevity.

\textbf{Anisotropic Convolution Block.} 
Since the MitoEM dataset has anisotropic resolution, we design an anisotropic convolution block (ACB) as shown in Fig.~\ref{fig:framework}. After a  conventional layer, we cascade two   conventional layers to further enlarge the receptive field. At the same time, we insert the skip connection in the two   conventional layers. 

\textbf{Network Structure.}
The overall structure of Res-UNet-R is shown in Fig.~\ref{fig:framework}. Inspired by 3D U-Net \cite{cciccek20163d}, we first embed the feature maps extracted from a 3D block with a  conventional layer. In each layer of the encoder, there is an ACB to extract the anisotropic information. Then we adopt a  conventional layer to downsample the feature maps in the lateral dimensions. In the decoder, we use the trilinear upsampling to restore the resolution of the feature maps and the ACB to reconstruct the detailed information. For Res-UNet-R, the decoder outputs a semantic mask and an instance boundary simultaneously. Since the human sample is of poorer imaging quality than the rat sample, we design two decoder paths for Res-UNet-H to predict the semantic mask and the instance boundary separately.



\textbf{Loss Function.} 
The binary cross entropy (BCE) is a common loss function used in biomedical image segmentation. To address the class imbalance problem, we adopt a weighted BCE (WBCE) loss as

where  and  are the predicted response map and ground-truth of the i-th block, D, H, and W denote the depth, height, and width of the block, and the weight  is defined as

Here  is the foreground voxel ratio, i.e., . 
The overall loss function  is defined as 

where  and  are the predicted response maps of the semantic mask and the instance boundary respectively.  and  are the corresponding ground-truth of  and .

\subsection{Post-processing}
Obtaining the semantic mask  and the instance boundary , we can generate the seed map  as 

where  and  are two thresholds. In our experiments, we set  and . Then we generate the seed map and adopt the connected component labeling   to obtain the final mitochondria instances.

\subsection{Denoising as Pre-processing}
As mentioned above, we find that by adding a denoising operation as pre-processing on the test set, the influence of noisy regions on segmentation can be alleviated, especially for the human sample.  To this end, we adopt the interpolation network initially proposed for video frame \cite{niklaus2017video} and also employed for EM image restoration in \cite{huang2020learning}. As shown in Fig.~\ref{fig:framework}, the interpolation network takes the two adjacent frames of the noisy frame as input and predicts two kernels. The two adjacent frames are then convolved by the two kernels respectively, the sum of which contributes to the restored frame. Fig.~\ref{fig:Denosing}  gives visual examples of frames before and after denoising, which demonstrate the effectiveness of the denoising pre-processing.





\begin{figure}[t]
	\centering
	\includegraphics[width=1.0\linewidth]{figure/denoising.pdf} \caption{Visualized results before and after denoising pre-processing on the test set of MitoEM-H.} \label{fig:Denosing}
\end{figure}

\vspace{-0.3cm}
\section{EXPERIMENTS}
\label{sec:exp}
\subsection{Dataset and Evaluation Metric}
The MitoEM dataset \cite{wei2020mitoem} consists of two (30 ) EM image volumes of resolution  , which come from a rat tissue (MitoEM-R) and a human tissue (MitoEM-H) respectively. The two volumes have been stitched and aligned. Each volume has three parts, a training set (), a validation set () and a test set ().

We adopt an efficient 3D metric, which evaluates AP-75 with the bounding boxes instead of voxel-wise calculation \cite{wei2020mitoem}. In this case, at least 0.75 intersection over union (IoU) with the ground truth for a detection is required to be a true positive (TP). According to the number of mitochondrial voxels, mitochondria are divided into small, medium and large instances, with respective thresholds of 5K and 15K.




\subsection{Implementation Details}
We adopt Pytorch (version 1.1) to implement the proposed method. Two TITAN Xp (12GB) are used for training and inference. During the training stage, we adopt the 11 data augmentation methods following \cite{wei2020mitoem}  and set the batch size as 2. The network is optimized by Adam with a fixed learning rate 0.0001. We train the network in two stages. First, we train the network in 20K iterations with the input size   to select the best model. Then we change the input size to  and fine-tune the network in 10K iterations. We call this two-stage training as multi-scale training. The validation stage needs 45 GB of memory, which is mainly due to post-processing for the seed map of size .

We train the interpolation network with  patches in the training set. The interpolation network is responsible for predicting the middle slice of the patch supervised by the mean square error (MSE) loss. We manually mark the coarse noisy regions on the test sets of both MitoEM-R and MitoEM-H  and utilize the trained interpolation network to restore the noisy regions before inference of segmentation.





\begin{table}[t]
\centering
\begin{tabular}{ccccc}
\hline
\multirow{2}{*}{Block unit} & \multicolumn{4}{c}{MitoEM-R} \\ \cline{2-5} 
                 & Small  & Med  & Large  & ALL \\ \hline
3D ECA block        & \textbf{0.398}  & 0.831 & 0.874 & 0.865 \\ 
3D SE block                & 0.388  & 0.826 & 0.891 & 0.872 \\ 
3D Res block        & 0.375  & \textbf{0.860} & 0.901 & 0.884 \\ 
3D ACB         & 0.307  & 0.853 & 0.935 & 0.913 \\
\hline
3D ACB+MT   & 0.277  & 0.850 & \textbf{0.949} & \textbf{0.917} \\
\hline
\end{tabular}
\caption{Segmentation results on MitoEM-R validation set.}
\label{tab:rat_result}
\end{table}


\begin{table}[t]
\centering
\begin{tabular}{ccccc}
\hline
\multirow{2}{*}{Method} & \multicolumn{4}{c}{MitoEM-H} \\ \cline{2-5} 
                 & Small  & Med  & Large  & ALL \\ \hline
Res-UNet-R          & 0.470  & 0.791 & 0.790 & 0.783 \\
Res-UNet-H          & 0.405  & 0.805 & \textbf{0.837} & 0.816 \\
\hline
Res-UNet-H+MT & \textbf{0.522} & \textbf{0.844}  & 0.826  & \textbf{0.828}  \\ 
\hline
\end{tabular}
\caption{Segmentation results on MitoEM-H validation set.}
\label{tab:human_result}
\end{table}



\begin{table}[!t]
\centering
\begin{tabular}{ccccc}
\hline
\multirow{2}{*}{Method} & \multicolumn{4}{c}{MitoEM-R} \\ \cline{2-5} 
                 & Small  & Med  & Large  & ALL \\ \hline
Res-UNet-R          & \textbf{0.305}   & \textbf{0.861}  & 0.848  & 0.850  \\
After denoising           & 0.151  & 0.832  & \textbf{0.854}  & \textbf{0.851}  \\
\hline
\hline
\multirow{2}{*}{Method} & \multicolumn{4}{c}{MitoEM-H} \\ \cline{2-5} 
                 & Small  & Med  & Large  & ALL \\ \hline
Res-UNet-H          & 0.522 & \textbf{0.844}  & 0.826  & 0.828  \\
After denoising          & \textbf{0.531}  & 0.834  &\textbf{ 0.827}  &  \textbf{0.829} \\
\hline
\end{tabular}
\caption{Segmentation results on test sets of MitoEM-R and MitoEM-H .}
\label{tab:denoising test}
\end{table}


\subsection{Ablation Study}
We conduct comprehensive experiments to validate the effectiveness of main components in the proposed method.

\textbf{Block Unit Selection.} We test different block units in Table \ref{tab:rat_result} on the validation set of MitoEM-R. Here 3D SE block \cite{hu2018squeeze}, 3D ECA block \cite{wang2020eca} and 3D Res block \cite{he2016deep} are modified from state-of-the-art methods for the image recognition task. In comparison with these more complex block units, our simply designed ACB alleviates overfitting and achieves the best results on the 3D mitochondria segmentation task, outperforming the second best method by 2.9\%.

\textbf{Network Structure.} As shown in Table \ref{tab:human_result}, if we train and test Res-UNet-R on MitoEM-H, the AP-75 result is 0.783. By introducing an extra decoder, Res-UNet-H improves the AP-75 result to 0.816 (3.3\% increment). It verifies that Res-UNet-H can handle more difficult sample.

\textbf{Training Strategy.} As shown in Table \ref{tab:rat_result} and \ref{tab:human_result}, the multi-scale training strategy (MT) we used is beneficial for both models, especially for Res-UNet-H (AP-75 improves 1.2\%). It proves that both models need larger receptive field to avoid over-fitting.


 \begin{figure}[!t]
	\centering
	\includegraphics[width=1.0\linewidth]{figure/seg_results.pdf}
	\caption{Visualized results from validation sets of MitoEM-R and MitoEM-H.} \label{fig:seg_results}
	\vspace{-0.3cm}
\end{figure}
\textbf{Denoising Pre-processing.} As shown in Fig.~\ref{fig:Denosing}, the noisy regions of the middle frame can be well restored by the interpolation network. We evaluate the effect of denoising pre-processing with the above trained segmentation models on the test sets of both MitoEM-R and MitoEM-H . As shown in Table \ref{tab:denoising test}, the AP-75 metric improves 0.1\% on both test sets. 

\vspace{-0.2cm}
\subsection{Challenge Results}
In the Large-scale 3D Mitochondria Instance Segmentation Challenge, our team ranks the 1st on the leaderboard at the end of the testing phase. As shown in Table \ref{tab:final_rank}, the proposed method notably outperforms other competitors on both MitoEM-R and MitoEM-H  test sets.   We also show some visualized results from the validation set of MitoEM-R and MitoEM-H in Fig.\ref{fig:seg_results}. It can be seen that the predicted results by the proposed method is very close to ground-truth.

\vspace{-0.3cm}



\begin{table}[t]
\centering
\setlength{\tabcolsep}{2mm}
\begin{tabular}{c|c|c|c}
	\hline
	Method     & MitoEM-R   & MitoEM-H   & Average        \\ \hline
	Ours       & \textbf{0.851}   & \textbf{0.829 }  &  \textbf{0.8400}  \\
	2nd    & 0.836   & 0.800   &  0.8180  \\
	3rd  & 0.833   & 0.800   &  0.8165 \\
	4th & 0.816   & 0.804   &  0.8100 \\
	\hline
\end{tabular}
\caption{MitoEM Challenge leaderboard at the end of the testing phase.}
	\vspace{-0.3cm}
\label{tab:final_rank}
\end{table}



\section{Conclusion}
\label{sec:conclusion}
In this paper, we present two advanced deep networks for 3D mitochondria instance segmentation, named Res-UNet-R for the rat sample and Res-UNet-H for the human sample.  Specifically, we exploit a simple yet effective ACB and  a multi-scale training strategy to boost the segmentation performance.  Moreover, we enhance the generalizability of the trained models on the test set by adding a denoising operation as pre-processing. In the Large-scale 3D Mitochondria Instance Segmentation Challenge, our team ranks the 1st on the leaderboard at the end of the testing phase.




\footnotesize
\bibliographystyle{IEEEbib}
\bibliography{strings,refs}

\end{document}
