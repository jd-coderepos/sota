

\documentclass[runningheads]{llncs}
\usepackage{graphicx}


\usepackage{tikz}
\usepackage{comment}\usepackage{color}
\usepackage{multirow}

\usepackage[accsupp]{axessibility}  






\begin{document}
\sloppy
\pagestyle{headings}
\mainmatter
\def\ECCVSubNumber{3985}  

\title{Self-Constrained Inference Optimization on  Structural Groups  for Human Pose Estimation} 

\begin{comment}
\titlerunning{ECCV-22 submission ID \ECCVSubNumber} 
\authorrunning{ECCV-22 submission ID \ECCVSubNumber} 
\author{Anonymous ECCV submission}
\institute{Paper ID \ECCVSubNumber}
\end{comment}


\titlerunning{SCIO on  Structural Groups  for Human Pose Estimation}
\author{Zhehan Kan\and
Shuoshuo Chen\and
Zeng Li
\and
Zhihai He\thanks{Corresponding author}}
\authorrunning{Z. Kan et al.}
\institute{Southern University of Science and Technology\\
\email{\{kanzh2021, chenss2021\}@mail.sustech.edu.cn} \\
\email{\{liz9, hezh\}@sustech.edu.cn}
}
\maketitle

\begin{abstract}
We observe that human poses exhibit strong group-wise structural correlation and spatial coupling between keypoints due to the biological constraints of different body parts. 
This group-wise structural correlation can be explored to improve the accuracy and robustness of human pose estimation. 
In this work, we develop a self-constrained  prediction-verification network to characterize and learn the structural correlation between keypoints during training. During the inference stage, the feedback information from the verification network allows us to perform further optimization of pose prediction, which significantly improves the performance of human pose estimation.
Specifically, we partition the keypoints into groups according to the biological structure of human body. Within each group, the keypoints are further partitioned into two subsets, high-confidence base keypoints and low-confidence terminal keypoints. We develop a self-constrained prediction-verification network  to perform forward and backward predictions between these keypoint subsets. 
One fundamental challenge in pose estimation, as well as in generic prediction tasks, is that there is no mechanism for us to verify if the obtained pose estimation or prediction results are accurate or not, since the ground truth is not available. 
Once successfully learned, the verification network serves as an accuracy  verification module for the forward pose prediction. During the inference stage, it can  be used to guide the local optimization of the pose estimation results of low-confidence keypoints with the self-constrained loss on high-confidence keypoints as the objective function. Our extensive experimental results on benchmark MS COCO and CrowdPose datasets demonstrate that the proposed method can significantly improve the pose estimation results. 
\keywords{Human Pose Estimation, Self-Constrained, Structural Inference, Prediction Optimization.}
\end{abstract}


\section{Introduction}
\label{sec:intro}
Human pose estimation aims to correctly detect and localize keypoints, i.e., human body joints or parts, for all persons in an input image. It is one of the fundamental computer vision tasks which plays an important role  in a variety of downstream applications, such as motion capture \cite{DBLP:conf/cvpr/ElhayekAJTPABST15,DBLP:conf/cvpr/RhodinCKSF19}, activity recognition \cite{DBLP:conf/cvpr/BagautdinovAFFS17,DBLP:conf/cvpr/WuWWGW19}, and person tracking \cite{DBLP:conf/cvpr/YangRLZW021,DBLP:conf/cvpr/WangTM20}. Recently, remarkable process has been made in human pose estimation based on deep neural network methods \cite{DBLP:conf/cvpr/CaoSWS17,Chen_2018_CVPR,DBLP:conf/cvpr/0009XLW19,He_2017_ICCV,DBLP:conf/cvpr/PapandreouZKTTB17,DBLP:conf/cvpr/SuYXGW19}. For regular scenes, deep learning-based methods have already achieved remarkably accurate estimation of body keypoints and there is little space for further performance improvement \cite{DBLP:conf/cvpr/ZhangZD0Z20,DBLP:conf/eccv/WangLGDW20,DBLP:conf/cvpr/0005ZGH20}. However,  for complex scenes with person-person occlusions, large variations of appearance, and cluttered backgrounds, pose estimation remains very challenging \cite{DBLP:conf/eccv/XiaoWW18,DBLP:conf/cvpr/0005ZGH20}. 
We  notice that, in complex scenes, the performance of pose estimation on different keypoints exhibits large variations. For example, for those visible keypoints with little interference from other persons or background, their estimation results are fairly accurate and reliable. However, for some keypoints, for example the terminal keypoints at tip locations of body parts, it is very challenging to achieve accurate pose estimation. The low accuracy of these challenging keypoints degrades the overall pose estimation performance. Therefore, the main challenge in pose estimation is how to improve the estimation accuracy of these challenging keypoints. 


\begin{figure}[t]
\centering
\setlength{\belowcaptionskip}{-0.4cm} 
\includegraphics[width=0.6\columnwidth]{fig/idea.png}
\centering
\caption{Illustration of the proposed idea of self-constrained inference optimization of structural groups for human pose estimation.}
\label{fig:idea}
\end{figure}

 As summarized in Fig. \ref{fig:idea}, this work is motivated by the following two important observations: (1) human poses, although exhibiting large variations due to the free styles and flexible movements of human, are however restricted by the biological structure of the body. The whole body consists of multiple  parts, such as the upper limbs and lower limbs. Each body part corresponds to a subgroup of keypoints. We observe that the keypoint correlation across different body parts remains low since different body parts, such as the left and right arms, can move with totally different styles and towards different directions. However, within the same body part or within the same structural group, keypoints are more spatially constrained by each other. This implies that keypoints can be potentially predictable from each other by exploring this unique structural correlation. Motivated by this observation, in this work, we propose to partition the body parts into a set of structural groups and perform group-wise structure learning and keypoint prediction refinement. 

\begin{figure}[h]
\centering
\setlength{\abovecaptionskip}{-0.1cm} 
\setlength{\belowcaptionskip}{-0.4cm} 
\includegraphics[width=0.95\columnwidth]{fig/confidence_index.png}
\centering
\caption{Keypoints at the tip locations of body parts suffer from low confidence scores obtained from the heatmap during pose estimation.}
\label{fig:confidence}
\end{figure}

(2) We have also observed that, within each group of keypoints, terminal keypoints at tip locations of the body parts, such as 
ankle and wrist keypoints, often suffer from lower estimation accuracy. This is because they have much larger freedom of motion and are more easily to be occluded by other objects. Fig. \ref{fig:confidence} shows the average prediction confidence (obtained from the heatmaps) of all keypoints with yellow dots and bars representing the locations and estimation confidence for terminal keypoints, for example, wrist or ankle keypoints.  We can see that the average estimation confidence of terminal keypoints are much lower than the rest. 

Motivated by the above two observations, we propose to partition the body keypoints into 6 structural groups according to their biological parts, and each structural group is further partitioned into two subsets: \textit{terminal keypoints} and \textit{base keypoints} (the rest keypoints). We develop a self-constrained prediction-verification network to learn the structural correlation between these two subsets within each structural group. Specifically, we learn two tightly coupled networks, the prediction network  which performs the forward prediction of terminal keypoints from base keypoints, and the verification network  which performs backward prediction of the base keypoints from terminal keypoints. 
This prediction-verification network aims to characterize the structural correlation between keypoints within each structural group. They are jointly learned using a self-constraint loss.
Once successfully learned, the verification network  is then used as a performance assessment module to optimize the prediction of low-confidence terminal keypoints based on local search and refinement within each structural group.
Our extensive experimental results on benchmark MS COCO datasets demonstrate that the proposed method is able to significantly improve the pose estimation results. 

The rest of the paper is organized as follows. Section 2 reviews related work on human pose estimation. The proposed 
self-constrained inference optimization of structural groups is presented in Section 3. Section 4 presents the experimental results, performance comparisons, and ablation studies. Section 5  concludes the paper.


\section{Related Work and Major Contributions}
\label{sec:related}
In this section, we review related works on heatmap-based pose estimation, multi-person pose estimation, pose refinement and error correction, and reciprocal learning. We then summarize the major contributions of this work.

\textbf{(1) Heatmap-based pose estimation.}
In this paper, we use heatmap-based pose estimation. 
The probability for a pixel to be the keypoint can be measured by its response in the heatmap. Recently, heatmap-based approaches have achieved the state-of-the-art performance in pose estimation \cite{DBLP:conf/eccv/XiaoWW18,Cheng_2020_CVPR,DBLP:conf/cvpr/XuT21,DBLP:conf/cvpr/0009XLW19}.  The  coordinates of keypoints are obtained by decoding the heatmaps \cite{DBLP:conf/cvpr/SuYXGW19}.  \cite{Cheng_2020_CVPR} predicted scale-aware high-resolution heatmaps using multi-resolution aggregation during inference. \cite{DBLP:conf/cvpr/XuT21} processed graph-structured features across multi-scale human skeletal representations and proposed a learning approach for multi-level feature learning and heatmap estimation.



\textbf{(2) Multi-person pose estimation.}
Multi-person pose estimation requires detecting keypoints of all persons in an image \cite{Fang_2017_ICCV}. It is very challenging due to overlapping between body parts from neighboring persons. Top-down methods and bottom-up methods have been developed in the literature to address this issue. \textbf{(a) Top-down} approaches \cite{He_2017_ICCV,DBLP:conf/eccv/SunXWLW18,DBLP:conf/cvpr/MoonCL19,DBLP:conf/cvpr/SuYXGW19} first detect all persons in the image and then estimates keypoints of each person. The performance of this method depends on the reliability of object detection which generates the bounding box for each person. When the number of persons is large, accurate detection of each person becomes very challenging, especially in highly occluded and cluttered scenes \cite{DBLP:conf/cvpr/PapandreouZKTTB17}.
\textbf{(b) Bottom-up} approaches \cite{Geng_2021_CVPR,DBLP:conf/cvpr/CaoSWS17,Luo_2021_CVPR} directly detect keypoints of all persons and then group keypoints for each person. These methods usually run faster than the top-down methods in multi-person pose estimation since they do not require person detection. \cite{Geng_2021_CVPR} activated the pixels in the keypoint regions and learned disentangled representations for each keypoint to improve the regression result. \cite{Luo_2021_CVPR} developed a scale-adaptive heatmap regression method to handle large variations of body sizes. 


\textbf{(3) Pose refinement and error correction.} A number of methods have been developed in the literature to refine the estimation of body keypoints \cite{9107502,DBLP:conf/cvpr/MoonCL19,DBLP:conf/eccv/WangLGDW20}.
\cite{8575519} proposed a pose refinement network  which takes  the image and the predicted keypoint locations as input and learns to directly predict refined keypoint locations. \cite{9107502} designed two networks where the correction network guides the refinement to correct the joint locations before generating the final pose estimation. \cite{DBLP:conf/cvpr/MoonCL19} introduced a model-agnostic pose refinement method using statistics of error distributions as prior information to generate synthetic poses for training.  \cite{DBLP:conf/eccv/WangLGDW20}  introduced a localization sub-net to extract different visual features and a graph pose refinement module to explore the relationship between points sampled from the heatmap regression network. 

\textbf{(4) Cycle consistency and reciprocal learning.}
This work is related to cycle consistency and reciprocal learning. \cite{Zhu_2017_ICCV} translated an image from the source domain into the target domain by introducing a cycle consistence constraint so that the distribution of images from translated domain is indistinguishable from the distribution of target domain. 
\cite{Sun_2020_CVPR} developed a pair of jointly-learned networks to predict human trajectory forward and backward. 
\cite{xu2020segmentation} developed a reciprocal cross-task architecture for image segmentation, which improves the learning efficiency and generation accuracy by exploiting the commonalities and differences across tasks. 
\cite{liu2021watching} developed a  Temporal Reciprocal Learning (TRL) approach to fully explore the discriminative information from the disentangled features. \cite{zhang2021accurate} designed a support-query mutual guidance architecture for few-shot object detection.

\vspace{0.2cm}
\textbf{(5) Major contributions of this work.} 
Compared to the above related work, the major contributions of this work are: (a) we propose to partition the body keypoints into structural groups and explore the structural correlation within each group to improve the pose estimation results. 
Within each structural group, we propose to partition the keypoints into high-confidence and low-confidence ones. We  develop a  prediction-verification network to characterize 
structural correlation between them based on a self-constraint loss. (b) We introduce a self-constrained  optimization method which uses the learned verification network as a performance assessment module to optimize the pose estimation of low-confidence keypoints during the inference stage. (c) Our extensive experimental results have demonstrated that our proposed method is able to significantly improve the performance of pose estimation and outperforms the existing methods by large margins. 

Compared to existing methods on cycle consistency and reciprocal learning, our  method has the following unique novelty. First, it addresses an important problem in prediction: how do we know if the prediction is accurate or not since we do not have the ground-truth. It establishes a self-matching constraint on high-confidence keypoints and uses the successfully learned verification network to verify if the refined predictions of low-confidence keypoints are accurate or not. Unlike existing prediction methods which can only perform forward inference, our method 
is able to perform further optimization of the prediction results during the inference stage, which can significantly improve the prediction accuracy and the generalization capability of the proposed method. 






\section{Method}
In this section, we present our self-constrained inference optimization  (SCIO) of structural groups for human pose estimation.

\subsection{Problem Formulation}
Human pose estimation, as a keypoint detection task, aims to detect the locations of body keypoints from the input image. Specifically, let  be the image of size . Our task is to locate  keypoints  from  precisely. Heatmap-based methods transform this problem to estimate  heatmaps  of size . Given a heatmap, the keypoint location can be determined using different grouping or peak finding methods \cite{DBLP:conf/cvpr/MoonCL19,DBLP:conf/cvpr/SuYXGW19}. 
For example, the pixel with the highest heatmap value can be designated as the location of the corresponding keypoint. 
Meanwhile, given a keypoint at location , the corresponding heatmap can be generated using the Gaussian kernel


In this work, the ground-truth heatmaps are denoted by 
.

\begin{figure*}[t]
\centering
\setlength{\abovecaptionskip}{-0.05cm} 
\setlength{\belowcaptionskip}{-0.8cm} 
\includegraphics[width=0.99\columnwidth]{fig/framework_pred_veri.png}
\centering
\caption{The overall framework of our proposed network. For an input image, heatmaps of all keypoints predicted by the  backbone are partitioned into 6 structural groups. During training stage, each group  is divided into two subsets: base keypoints and terminal keypoints. A prediction-verification network with self-constraints is developed to characterize the structural correlation between these two subsets. During testing, the learned verification network is used to refine the prediction results of the low-confidence terminal keypoints. }
\label{fig:framework}
\end{figure*}

\subsection{Self-Constrained Inference Optimization on Structural Groups}
\label{sec:overview}
Fig. \ref{fig:framework} shows the overall framework of our proposed SCIO method for pose estimation. 
We first partition the detected human body keypoints into 6 structural groups, which correspond to different body parts, including lower and upper limbs, as well as two groups for the head part, as illustrated in Fig. \ref{fig:groups}.
Each group contains four keypoints. We observe that these structural groups of four keypoints are the basic units for human pose and body motion. They are constrained by the biological structure of the human body.  There are significant freedom and variations between structural groups. For example, the left arm and the right arm could move and pose in totally different ways. In the meantime, within each group, the set of keypoints are constraining each other with strong structural correlation between them. 

\begin{figure}[h]
\centering
\setlength{\abovecaptionskip}{-0.05cm} 
\includegraphics[width=0.5\columnwidth]{fig/groups.png}
\centering
\caption{Partition of the body keypoints into 6 structural groups corresponding to different body parts. Each group has 4 keypoints.}
\label{fig:groups}
\end{figure}


As discussed in Section \ref{sec:intro}, we further partition each of these 6 structural groups into base keypoints and terminal keypoints. The base keypoints are near the body torso while the terminal keypoints are at the end or tip locations of the corresponding body part. 
Fig. \ref{fig:confidence} shows that the terminal keypoints are having much lower estimation confidence scores than those base keypoints during pose estimation. 
In this work, we denote these 4 keypoints within each group by  
 
where  is the terminal keypoint and the rest three  are the base keypoints near the torso. 
The corresponding heatmap are denoted by 
. 
To characterize the structural correlation within each structural group  , we propose to develop a self-constrained prediction-verification network. As illustrated in Fig. \ref{fig:framework}, the prediction network  predicts the 
heatmap of the terminal keypoint  from the base keypoints 
 with  feature map  as the visual context:

We observe that the feature map   provides important visual context for keypoint estimation.
The verification network  shares the same structure as the prediction network. It performs the backward prediction of keypoint  from the rest three:

Coupling the prediction and verification network together by passing the 
prediction output  of the prediction network into the verification network as input, we have the following prediction loop

This leads to the following self-constraint loss

This  prediction-verification network with a forward-backward prediction loop
learns the internal structural correlation between the base keypoints and the terminal keypoint. The learning process is guided by the self-constraint loss. If the internal structural correlation is successfully learned, then the self-constraint loss 
 generated by the forward and backward prediction loop should be small. 
This step is referred to as \textit{self-constrained learning}.

Once successfully learned, the verification network  can be used to verify if the prediction  is accurate or not. 
In this case, the self-constraint loss is used as an objective function to optimize the prediction  based on local search, which can be formulated as 

where  represents the heatmap generated from keypoint  using the Gaussian kernel.
This provides an effective mechanism for us to iteratively refine the prediction result based on the specific statistics of  the test sample. This adaptive prediction and optimization is not available in traditional network prediction which is purely forward without any feedback or adaptation. This feedback-based adaptive prediction will result in better generalization capability on the test sample. 
This step is referred to as \textit{self-constrained optimization}.
In the following sections, we present more details about the proposed self-constrained learning (SCL) and self-constrained optimization (SCO) methods.

\subsection{Self-Constrained Learning of Structural Groups}
In this section, we explain the self-constrained learning in more details. 
As illustrated in Fig. \ref{fig:framework}, the input to the prediction and verification networks, namely,   and , are all heatmaps generated by the baseline pose estimation network. In this work, we use the HRNet \cite{DBLP:conf/cvpr/0009XLW19} as our baseline, on top of which our proposed SCIO method is implemented. We observe that the visual context surrounding the keypoint location provides important visual cues for  refining the locations of the keypoints. For example, the correct location of the knee keypoint should be at the center of the knee image region. Motivated by this, we also pass the feature map  generated by the backbone network to the prediction and verification network as inputs. 

In our proposed scheme of self-constrained learning, the prediction and verification networks are jointly trained. Specifically, as illustrated in Fig. \ref{fig:framework}, the top branch shows the training process of the prediction network. Its input includes heatmaps 
  and the visual feature map .
The output of the prediction network is the predicted heatmap for keypoint , denoted by . 
During the training stage, this prediction is compared to its ground-truth  and form the prediction loss  which is given by 

The predicted heatmap , combined with 
the heatmaps  and  and the visual feature map , is passed to the verification network  as input.  The output of  will be the predicted heatmap for keypoint , denoted by .  
We then compare it with the ground-truth heatmap  and define the following self-constraint loss for the prediction network

These two losses are combined as  to train the prediction network .

Similarly, for the verification network, the inputs are heatmaps 
 and visual feature map . It predicts the heatmap  for keypoint . It is then, combined with  and  to form the input to the prediction network  which predicts the 
heatmap . Therefore, the overall loss function for the verification network is given by 

The prediction and verification network are jointly trained in an iterative manner. Specifically, during the training epochs for the prediction network, the verification network is fixed and used to compute the self-constraint loss for the prediction network. Similarly, during the training epochs for the verification network, the prediction network is fixed and used to compute the self-constraint loss for the verification network.


\subsection{Self-Constrained Inference Optimization of Low-Confidence Keypoints}
\label{sec:slo}

As discussed in Section \ref{sec:intro}, one of the major challenges in pose estimation is to improve the accuracy of hard keypoints, for example, those terminal keypoints. 
In existing approaches for network prediction, the inference process is purely forward. The knowledge learned from the training set is directly applied to the test set. There is no effective mechanism to verify if the prediction result is accurate or not since the ground-truth is not available. This  forward inference process often suffers from generalization problems since  there is no feedback process to adjust the prediction results based on the actual test samples. 

The proposed self-constrained inference optimization aims to address the above issue. The verification network , once successfully learned, can be used as a feedback module to evaluate the accuracy of the prediction result. This is achieved by mapping the prediction result  for the low-confidence keypoint back to the high-confidence keypoint . Using the self-constraint loss as an objective function, we can perform local search or refinement of the prediction result  to minimize the objective function, as formulated in (8). 
Here, the basic idea is that: if the prediction  becomes accurate during local search, then, using it as the input, the verification network should be able to accurately predict the high-confidence keypoint , which implies that the 
self-constraint loss  on the high-confidence keypoint  should be small.   

Motivated by this, we propose to perform local search and refinement of the low-confidence keypoint. Specifically, we add a small perturbation  onto the predicted result 
 and search its small neighborhood to minimize the self-constraint loss:


Here,  controls the search range and direction of the keypoint, and the direction will be dynamically adjusted with the loss.
 represents the heatmap generated from the keypoint location  using the Gaussian kernel.
In the Supplemental Material section, we provide further discussion on the extra computational complexity of the proposed SCIO method. 


\begin{table}
\begin{center}
\caption{
Comparison with the state-of-the-arts methods on COCO test-dev.
}
\label{tab:sota on COCO}
\begin{tabular}{l|l|ccccccc}
\hline\noalign{\smallskip}
Method & Backbone & Size & \text{} &  &  &   &  &   \\
\hline\noalign{\smallskip}
CMU-Pose \cite{DBLP:conf/cvpr/CaoSWS17} & - & - & 61.8 & 84.9 & 67.5 & 57.1 & 68.2 & 66.5\\
Mask-RCNN \cite{He_2017_ICCV} & R50-FPN & - & 63.1 & 87.3 & 68.7 & 57.8 & 71.4 & - \\
G-RMI \cite{DBLP:conf/cvpr/PapandreouZKTTB17} & R101 & 353257 & 64.9& 85.5 &71.3& 62.3&70.0 &69.7\\
AE \cite{DBLP:conf/nips/NewellHD17} & - &  512512& 65.5& 86.8& 72.3& 60.6& 72.6 &70.2\\
Integral Pose \cite{DBLP:conf/eccv/SunXWLW18} & R101 & 256256& 67.8 &88.2& 74.8 &63.9 &74.0 &-\\
RMPE \cite{Fang_2017_ICCV} &PyraNet& 320256& 72.3& 89.2 &79.1& 68.0& 78.6& -\\
CFN \cite{DBLP:conf/iccv/HuangGT17} & -& -& 72.6& 86.1& 69.7& \textbf{78.3}& 64.1& -\\
CPN(ensemble) \cite{Chen_2018_CVPR}& ResNet-Incep. &384288 &73.0& 91.7& 80.9 &69.5& 78.1 &79.0\\
CSM+SCARB \cite{DBLP:conf/cvpr/SuYXGW19} & R152& 384288 &74.3 &91.8& 81.9 &70.7 &80.2 &80.5\\
CSANet \cite{DBLP:journals/corr/abs-1905-05355} & R152& 384288& 74.5& 91.7 &82.1& 71.2 &80.2& 80.7\\
HRNet \cite{DBLP:conf/cvpr/0009XLW19} & HR48& 384288 &75.5& 92.5& 83.3& 71.9 &81.5& 80.5\\
MSPN \cite{DBLP:journals/corr/abs-1901-00148} & MSPN &384288 &76.1& {93.4} &83.8& 72.3 &81.5& 81.6\\
DARK \cite{DBLP:conf/cvpr/ZhangZD0Z20} &  HR48& 384288 &76.2& 92.5& 83.6& 72.5 &82.4& 81.1\\
UDP \cite{DBLP:conf/cvpr/0005ZGH20} &  HR48 &384288& 76.5 &92.7& 84.0& 73.0& 82.4& 81.6\\
PoseFix \cite{DBLP:conf/cvpr/MoonCL19}&  HR48+R152& 384288 &76.7 &92.6& 84.1& 73.1& 82.6& 81.5\\
Graph-PCNN \cite{DBLP:conf/eccv/WangLGDW20} & HR48 &384288 &76.8& 92.6& 84.3& 73.3& 82.7 &81.6\\
\hline\noalign{\smallskip}
\textbf{SCIO} (Ours) & HR48 & 384288 & \textbf{79.2} &  \textbf{93.5} & \textbf{85.8} & 74.1 & \textbf{84.2} & \textbf{81.6}\\
\textbf{Performance Gain} & & & \textbf{+2.4} &\textbf{+0.9}&\textbf{+1.5}&&\textbf{+1.5}&\textbf{+0.0}\\
\hline\noalign{\smallskip}
\end{tabular}
\end{center}
\end{table}
\vspace{-1.0cm}

\section{Experiments}
In this section, we present  experimental results, performance comparisons with state-of-the-art methods, and ablation studies to demonstrate the performance of our SCIO method.

\subsection{Datasets}
The comparison and ablation experiments are performed on MS COCO dataset \cite{DBLP:conf/eccv/LinMBHPRDZ14} and CrowdPose \cite{DBLP:conf/cvpr/LiWZMFL19} dataset, both of which contain very challenging scenes for pose estimation.

\textbf{MS COCO Dataset}: The COCO dataset contains challenging images with multi-person poses of various body scales and occlusion patterns in unconstrained environments. It contains 64K images and 270K persons labeled with 17 keypoints. We train our models on train2017 with 57K images including 150K persons and conduct ablation studies on val2017. We test our models on test-dev for performance comparisons with the state-of-the-art methods. In evaluation, we use the metric of Object Keypoint Similarity (OKS) score to evaluate the performance.

\textbf{CrowdPose Dataset}: The CrowdPose dataset contains 20K images and 80K persons labeled with 14 keypoints. Note that, for this dataset, we partition the keypoints into 4 groups, instead of 6 groups as in the COCO dataset. CrowdPose has more crowded scenes.
For training, we use the train set which has 10K images and 35.4K persons. For evaluation, we use the validation set which has 2K images and 8K persons, and the test set which has 8K images and 29K persons. 

\begin{table}[t]
\begin{center}
\caption{
Comparison with the state-of-the-arts methods on CrowdPose test-dev.
}
\label{tab:sota on Crowdpose}
\begin{tabular}{l|cccccccc}
\hline\noalign{\smallskip}
Method & Backbone & \text{}  &   \\
\hline\noalign{\smallskip}
Mask-RCNN \cite{He_2017_ICCV} & ResNet101 & 60.3  & -   \\
OccNet \cite{DBLP:conf/avss/GoldaKSB19} & ResNet50 & 65.5  & 66.6 \\
JC-SPPE \cite{DBLP:conf/cvpr/LiWZMFL19} & ResNet101 & 66  & 66.3    \\
HigherHRNet \cite{Cheng_2020_CVPR} &HR48 & 67.6  & -  \\
MIPNet \cite{Khirodkar_2021_ICCV} &HR48 & 70.0  & 71.1  \\
\hline\noalign{\smallskip}
\textbf{SCIO} (Ours) & HR48  & \textbf{71.5}  & \textbf{72.2} \\
\textbf{Performance Gain} &   & \textbf{+1.5}   & \textbf{+1.1}   \\
\hline\noalign{\smallskip}
\end{tabular}
\end{center}
\end{table}

\begin{table}[t]
\begin{center}
\caption{
Comparison with state-of-the-art of three backbones on COCO test-dev.
}
\label{tab:backbone}
\begin{tabular}{l|cccccccc}
\hline\noalign{\smallskip}
Method & Backbone & Size & \text{} &  &  &   &  &   \\
\hline\noalign{\smallskip}
SimpleBaseline \cite{DBLP:conf/eccv/XiaoWW18} & R152 &384288& 73.7& 91.9& 81.1 &70.3& 80.0 &79.0\\
SimpleBaseline & \multirow{2}{*}{R152} & \multirow{2}{*}{384288} & \multirow{2}{*}{\textbf{77.9}} & \multirow{2}{*}{\textbf{92.1}} & \multirow{2}{*}{\textbf{82.7}} & \multirow{2}{*}{\textbf{72.6}} & \multirow{2}{*}{\textbf{82.3}} & \multirow{2}{*}{\textbf{80.9}}\\
+\textbf{SCIO} (Ours)\\
\textbf{Performance Gain} &   &   & \textbf{+4.2} & \textbf{+0.2} & \textbf{+1.6} & \textbf{+2.3}& \textbf{+2.3} & \textbf{+1.9}\\
\hline\noalign{\smallskip}

HRNet \cite{DBLP:conf/cvpr/0009XLW19} & HR32& 384288& 74.9& 92.5& 82.8& 71.3& 80.9 &80.1\\
HRNet+\textbf{SCIO} (Ours) & HR32 & 384288 & \textbf{78.6} & \textbf{92.7} & \textbf{84.2} & \textbf{73.3} & \textbf{82.9} & \textbf{81.5}\\
\textbf{Performance Gain} &   &   & \textbf{+3.7} & \textbf{+0.2}  & \textbf{+1.4} & \textbf{+2.0}& \textbf{+2.0} & \textbf{+1.4}\\
\hline\noalign{\smallskip}

HRNet \cite{DBLP:conf/cvpr/0009XLW19} & HR48& 384288 &75.5& 92.5& 83.3& 71.9 &81.5& 80.5\\
HRNet+\textbf{SCIO} (Ours) & HR48 & 384288 & \textbf{79.2} &  \textbf{93.5} & \textbf{85.8} & 74.1 & \textbf{84.2} & \textbf{81.6}\\
\textbf{Performance Gain} & & & \textbf{+3.7} &\textbf{+1.0}&\textbf{+1.5}&\textbf{+2.2}&\textbf{+2.2}&\textbf{+0.0}\\
\hline\noalign{\smallskip}
\end{tabular}
\end{center}
\end{table}

\subsection{Implementation Details}
For fair comparisons, we use HRNet and ResNet as our backbone and follow the same training configuration as \cite{DBLP:conf/eccv/XiaoWW18} and \cite{DBLP:conf/cvpr/0009XLW19} for ResNet and HRNet, respectively. For the prediction and verification networks, we choose the FCN network \cite{long2015fully}.
The networks are  trained with the Adam optimizer. We choose a batch size of 36 and an initial learning rate of 0.001. The whole model is trained for 210 epochs. During inference, we set the number of search steps to be 50.

\subsection{Evaluation Metrics and Methods}
Following existing papers \cite{DBLP:conf/cvpr/0009XLW19}, we use the standard  Object Keypoint Similarity (OKS) metric which is defined as: 

Here  is the Euclidean distance between the detected keypoint and the corresponding ground truth,  is the visibility flag of the ground truth,  is the object scale, and  is a per-keypoint constant that controls falloff.  means if * holds,  equals to 1, otherwise,  equals to 0. We report standard average precision and recall scores:   , , , , , , , ,  at various OKS \cite{Geng_2021_CVPR,DBLP:conf/cvpr/0009XLW19}.


\begin{table}
\begin{center}
\caption{
Comparison with DARK and Graph-GCNN of input size 12896 on COCO val2017.
}
\label{tab:inputsize}
\begin{tabular}{l|cccccccc}
\hline\noalign{\smallskip}
Method & Backbone & Size & \text{} &  &  &   &  &   \\
\hline\noalign{\smallskip}
DARK \cite{DBLP:conf/cvpr/ZhangZD0Z20} &  HR48& 12896 &71.9&  89.1 & 79.6 & 69.2 & 78.0  &77.9\\
Graph-PCNN \cite{DBLP:conf/eccv/WangLGDW20}& HR48& 12896& 72.8& 89.2& 80.1& 69.9 &79.0 &78.6\\
\hline\noalign{\smallskip}
\textbf{SCIO} (Ours) & HR48& 12896& \textbf{73.7}& \textbf{89.6}& \textbf{80.9} & \textbf{70.3}& \textbf{79.4} & \textbf{79.1}\\
\textbf{Performance Gain} &   &   & \textbf{+0.9} & \textbf{+0.4}  & \textbf{+0.8} & \textbf{+0.4}& \textbf{+0.9} & \textbf{+0.8}\\
\hline\noalign{\smallskip}
\end{tabular}
\end{center}
\end{table}
\vspace{-1cm}

\subsection{Comparison to State of the Art}
We compare our SCIO method with other top-performing methods on the COCO test-dev and CrowdPose datasets. Table \ref{tab:sota on COCO} shows the performance comparisons with state-of-the-art methods on the MS COCO dataset. It should be noted that the best performance is reported here for each method. We can see that our SCIO method outperforms the current best by a large margin, up to 2.5\%, which is quite significant. 
Table \ref{tab:sota on Crowdpose} shows the results on challenging CrowdPose. In the literature, there are only few methods have reported results on this challenging dataset. Compared to the current best method MIPNet \cite{Khirodkar_2021_ICCV}, our SCIO method has improved the pose estimation accuracy by up to 1.5\%, which is quite significantly.

In Table \ref{tab:backbone}, we compare our SCIO with state-of-the-art methods using different backbone networks, including R152, HR32, and HR48 backbone networks. 
We can see that our SCIO method consistently outperforms existing methods. Table \ref{tab:inputsize} shows the performance comparison on pose estimation with different input image size, for example 12896 instead of 384288. We have only found two methods that reported results on small input images. 
We can see that our SCIO method also outperforms these two methods on small input images. 


\begin{table}[t]
\begin{center}
\caption{Ablations study on COCO val2017.} 
\label{tab:ablations}
\begin{tabular}{l|cccccccc}
\hline\noalign{\smallskip}
  &  &  &     &  \\
\hline\noalign{\smallskip}
Baseline & 76.3  & 90.8  & 82.9    & 81.2\\
Baseline + SCL & 78.3 & 92.9 & 84.9  & 81.3\\
Baseline + SCL + SCO &\textbf{79.5} & \textbf{93.7} & \textbf{86.0} & \textbf{81.6} \\
\hline\noalign{\smallskip}
\end{tabular}
\end{center}
\end{table}


\begin{table}
\begin{center}
\caption{Ablations study of terminal keypoints accuracy on COCO val2017.}
\label{tab:ablations of keypoints}
\begin{tabular}{l|cccccc}
\hline\noalign{\smallskip}
 & Left & Right & Left & Right & Left & Right\\
 & Ear & Ear & Wrist & Wrist & Ankle & Ankle\\
\hline\noalign{\smallskip}
HRNet & 0.6637  & 0.6652  & 0.5476   & 0.5511 & 0.3843 & 0.3871\\
\hline\noalign{\smallskip}
HRNet + \textbf{SCIO}(Ours) &\textbf{0.7987} & \textbf{0.7949} & \textbf{0.7124} & \textbf{0.7147} & \textbf{0.5526} & \textbf{0.5484}\\
\textbf{Performance Gain} & \textbf{+0.1350} & \textbf{+0.1297}  & \textbf{+0.1648} & \textbf{+0.1636}& \textbf{+0.1683} & \textbf{+0.1613}\\
\hline\noalign{\smallskip}
\end{tabular}
\end{center}
\end{table}

\begin{figure}
\centering
\setlength{\abovecaptionskip}{-0.05cm} 
\setlength{\belowcaptionskip}{-0.2cm} 
\includegraphics[width=\columnwidth]{fig/example.png}
\centering
\caption{Three examples of refinement of predicted keypoints. The top row is the original estimation. The bottom row is the refined version.}
\label{fig:example}
\end{figure}

\begin{figure}
\centering
\setlength{\abovecaptionskip}{-0.05cm} 
\setlength{\belowcaptionskip}{-0.4cm} 
\includegraphics[width=1\columnwidth]{fig/s2.png}
\centering
\caption{The decreasing of the self-constraint loss during local search and refinement of the predicted keypoint.}
\label{fig:loss}
\end{figure}

\subsection{Ablation Studies}
To systematically evaluate our method and study the contribution of each algorithm component, we use the HRNet-W48 backbone to perform a number of ablation experiments on the COCO val2017 dataset. Our algorithm has two major new components, the Self-Constrained Learning (SCL) and the Self-Constrained  optimization (SCO). In the first row of Table \ref{tab:ablations}, we report the baseline (HRNet-W48) results. The second row shows the results with the SCL. The third row shows results with the SCL and SCO of the prediction results. We can clearly see that each algorithm component is contributing significantly to the overall performance. In Table \ref{tab:ablations of keypoints}, We also use normalization and sigmoid functions to evaluate the loss of terminal keypoints, and the results show that the confidence of each keypoint from HRNet has been greatly improved after using SCIO.


Fig. \ref{fig:example} shows three examples of how the estimation keypoints have been refined by the self-constrained inference optimization method. The top row shows the original estimation of the keypoints. The bottom row shows the refined estimation of the keypoints. Besides each result image, we show the enlarged image of those keypoints whose estimation errors are large in the original method. However, using our self-constrained optimization method, these errors have been successfully corrected.
Fig. \ref{fig:loss} shows how the self-constraint loss decreases during the search process. We can see that the loss drops quickly and the keypoints have been refined to the correct locations. 
In the Supplemental Materials, we provide additional experiments and algorithm details for further understanding of the proposed SCIO method.






\section{Conclusion}
In this work, we observed that  human poses exhibit strong structural correlation  within keypoint groups, which can be  explored to improve the accuracy and robustness of their estimation. 
We developed a self-constrained prediction-verification network to learn this coherent spatial structure and to perform local refinement of the pose estimation results during the inference stage. 
We partition each keypoint group into two subsets, base keypoints and terminal keypoints, and develop a self-constrained prediction-verification network  to perform forward and backward predictions between them. This prediction-verification network design is able  to capture the local structural correlation between keypoints. 
Once successfully learned, we used the verification network as a feedback module to guide the local optimization of pose estimation results for low-confidence keypoints with the self-constraint loss on high-confidence keypoints as the objective function. Our extensive experimental results on benchmark MS COCO datasets demonstrated that the proposed SCIO method is able to significantly improve the pose estimation results. 



\bibliographystyle{splncs04}
\bibliography{egbib}
\end{document}
