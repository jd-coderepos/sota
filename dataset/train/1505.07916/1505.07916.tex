\documentclass{llncs}
\usepackage{graphicx}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{wrapfig}
\newcommand{\addedfragile}[1]{{\color{purple!50!black}{#1}}{}}
\newcommand{\added}[1]{#1}
\newcommand{\AbsSel}{\ensuremath{\mathsf{AbsSel}}}
\newcommand{\Atoms}{\ensuremath{\mathsf{Atoms}}}
\newcommand{\Concat}{\ensuremath{\mathsf{Concat}}}
\newcommand{\val}{\ensuremath{\mathsf{val}}}
\newcommand{\inv}{\ensuremath{\mathsf{inv}}}
\newcommand{\ite}{\ensuremath{\mathsf{ite}}}
\newcommand{\op}{\ensuremath{\mathsf{op}}}
\newcommand{\tr}{\ensuremath{\mathsf{Tr}}}
\newcommand{\plm}{\ensuremath{+_m}}
\newcommand{\isdef}{\ensuremath{\,\triangleq\,}}
\newcommand{\lsem}{\ensuremath{[\![}}
\newcommand{\rsem}{\ensuremath{]\!]}}
\newcommand{\ant}{\ensuremath{\mathsf{Ant}}}
\newcommand{\AntFail}{\ensuremath{\mathsf{AntFail}}}
\newcommand{\NoAntFail}{\ensuremath{\mathsf{NoAntFail}}}
\newcommand{\cons}{\ensuremath{\mathsf{Cons}}}
\newcommand{\constr}{\ensuremath{\mathsf{Constr}}}
\newcommand{\steword}{\ensuremath{\mathsf{STEWord}}}
\newcommand{\forte}{\ensuremath{\mathsf{Forte}}}
\newcommand{\Boolector}{\ensuremath{\mathsf{Boolector}}}
\newcommand{\true}{\ensuremath{\mathsf{true}}}
\newcommand{\false}{\ensuremath{\mathsf{false}}}
\newcommand{\arread}{\ensuremath{\mathsf{read}}}
\newcommand{\arupdate}{\ensuremath{\mathsf{update}}}
\newcommand{\mc}[1]{\ensuremath{\mathcal{{#1}}}}
\newcommand{\new}[1]{#1}


\begin{document}


\title{Word-level Symbolic Trajectory Evaluation}

\author{Supratik Chakraborty\inst{1} \and 
Zurab Khasidashvili\inst{2} \and 
Carl-Johan H. Seger\inst{3} \and \\
Rajkumar Gajavelly\inst{1} \and
Tanmay Haldankar\inst{1} \and 
Dinesh Chhatani\inst{1} \and \\
Rakesh Mistry\inst{1}}
\institute{IIT Bombay, India 
\thanks{R. Gajavelly, T. Haldankar and
  D. Chhatani contributed to this work when they were in IIT Bombay.}
\and Intel IDC, Haifa, Israel \and
Intel, Portland OR, USA
}

\maketitle

\begin{abstract}
Symbolic trajectory evaluation (STE) is a model checking technique
that has been successfully used to verify industrial designs.
Existing implementations of STE, however, reason at the level of bits,
allowing signals to take values in .  This limits the
amount of abstraction that can be achieved, and presents inherent
limitations to scaling.  The main contribution of this paper is to
show how much more abstract lattices can be derived automatically from
RTL descriptions, and how a model checker for the general theory of
STE instantiated with such abstract lattices can be implemented in
practice.  This gives us the first practical word-level STE engine,
called {\steword}.  Experiments on a set of designs similar to those
used in industry show that {\steword} scales better than
word-level BMC and also bit-level STE.
\end{abstract}

\section{Introduction}


Symbolic Trajectory Evaluation (STE) is a model checking technique
that grew out of multi-valued logic simulation on the one hand, and
symbolic simulation on the other hand~\cite{BryantSeger90}.  Among
various formal verification techniques in use today, STE comes closest
to functional simulation and is among the most successful formal
verifiation techniques used in the industry.  In STE, specifications
take the form of symbolic trajectory formulas that mix Boolean
expressions and the temporal next-time operator.  The Boolean
expressions provide a convenient means of describing different
operating conditions in a circuit in a compact form.  By allowing only
the most elementary of temporal operators, the class of properties
that can be expressed is fairly restricted as compared to other
temporal logics (see~\cite{Emerson95} for a nice survey).
Nonetheless, experience has shown that many important aspects of
synchronous digital systems at various levels of abstraction can be
captured using this restricted logic.  For example, it is quite
adequate for expressing many of the subtleties of system operation,
including clocking schemas, pipelining control, as well as complex
data
computations~\cite{SegerJOMABS05,KumarGuptaGhughal12,KaivolaEtAl09}.

In return for the restricted expressiveness of STE specifications, the
STE model checking algorithm provides siginificant computational
efficiency.  As a result, STE can be applied to much larger designs
than any other model checking technique.  For example, STE is
routinely used in the industry today to carry out complete formal
input-output verification of designs with several hundred thousand
latches \cite{KumarGuptaGhughal12,KaivolaEtAl09}.  Unfortunately, this
still falls short of providing an automated technique for formally
verifying modern system-on-chip designs, and there is clearly a need
to scale up the capacity of STE even further.

The first approach that was pursued in this direction was structural
decomposition.  In this approach, the user must break down a
verification task into smaller sub-tasks, each involving a distinct STE
run.  After this, a deductive system can be used to reason about the
collections of STE runs and verify that they together imply the
desired property of the overall design~\cite{JonesOSAM01}.
In theory, structural decomposition allows verification of arbitrarily
complex designs.  However, in practice, the difficulty and tedium of
breaking down a property into small enough sub-properties that can be
verified with an STE engine limits the usefulness of this approach
significantly.  In addition, managing the structural decomposition in
the face of rapidly changing RTL limits the applicability of
structural decomposition even further.

A different approach to increase the scale of designs that can be
verified is to use aggressive abstraction beyond what is provided
automatically by current STE implementations.  If we ensure that our
abstract model satisfies the requirements of the general theory of
STE, then a property that is verified on the abstract model holds on
the original model as well.  Although the general theory of STE allows
a very general circuit model~\cite{SegerBryant95}, all STE
implementations so far have used a three-valued circuit model.  Thus,
every bit-level signal is allowed to have one of three values: ,
 or , where  represents ``either  or ''.  This limits
the amount of abstraction that can be achieved.  The main contribution
of this paper is to show how much more abstract lattices can be
derived automatically from RTL descriptions, and how the general
theory of STE can be instantiated with this lattice to give a
practical word-level STE engine that provides significant gains in
capacity and efficiency on a set of benchmarks.

Operationally, word-level STE bears similarities with word-level
bounded model checking (BMC).  However, there are important
differences, the most significant one being the use of -based
abstractions on slices of words, called \emph{atoms}, in word-level
STE.  This allows a wide range of abstraction possibilities, including
a combination of user-specified and automatic abstractions -- often a
necessity for complex verification tasks.  Our preliminary
experimental results indicate that by carefully using -based
abstractions in word-level STE, it is indeed possible to strike a good
balance between accuracy (cautious propagation of ) and performance
(liberal propagation of ).

The remainder of the paper is organized as follows.  We discuss how
words in an RTL design can be split into atoms in
Section~\ref{sec:atomization}.  Atoms form the basis of abstracting
groups of bits.  In Section~\ref{sec:lattice}, we elaborate on the
lattice of values that this abstraction generates, and
Section~\ref{sec:encoding} presents a new way of encoding values of
atoms in this lattice.  We also discuss how to symbolically simulate
RTL operators and compute least upper bounds using this encoding.
Section~\ref{sec:wste} presents an instantiation of the general theory
of STE using the above lattice, and discusses an implementation.
Experimental results on a set of RTL benchmarks are presented in
Section~\ref{sec:experiments}, and we conclude in
Section~\ref{sec:conclusion}.

\section{Atomizing words}\label{sec:atomization}
In bit-level STE~\cite{BryantSeger90,SegerJOMABS05}, every variable is
allowed to take values from , where  denotes ``either
 or ''.  The ordering of information in the values ,  and
 is shown in the lattice in Fig.~\ref{ternary-lattice}, where a
value lower in the order has ``less information'' than one higher up
in the order.  The element  is added to complete the lattice,
and represents an unachievable over-constrained value.  Tools that
implement bit-level STE usually use dual-rail encoding to reason about
ternary values of variables.  In dual-rail encoding, every bit-level
variable  is encoded using two binary variables  and .
Intuitively,  indicates whether  can take the value , for
 in .  Thus, ,  and  are encoded by the
valuations ,  and , respectively, of .  By convention,  denotes .  An
undesired consequence of dual-rail encoding is the doubling of binary
variables in the encoded system.  This can pose serious scalability
issues when verifying designs with wide datapaths, large memories,
etc.  Attempts to scale STE to large designs must therefore raise the
level of abstraction beyond that of individual bits.

\begin{wrapfigure}[8]{R}{0.2\textwidth}
\begin{center}
\vspace*{-0.4in}
\includegraphics[scale=0.3]{ternary}
\caption{\label{ternary-lattice}Ternary lattice}
\end{center}
\end{wrapfigure}
In principle, one could go to the other extreme, and run STE at the level
of words as defined in the RTL design.  This requires defining a
lattice of values of words, and instantiating the general theory of
STE~\cite{SegerBryant95} with this lattice.  The difficulty with this
approach lies in implementing it in practice.  The lattice of values
of an -bit word, where each bit in the word can take values in
, is of size at least .  Symbolically representing
values from such a large lattice and reasoning about them is
likely to incur overheads similar to that incurred in bit-level STE.
Therefore, STE at the level of words (as defined in the RTL design)
does not appear to be a practical proposition for scaling.

The idea of splitting words into sub-words for the purpose of
simplifying analysis is not new (see e.g.~\cite{Joh01}).  An
aggressive approach to splitting (an extreme example being
bit-blasting) can lead to proliferation of narrow sub-words, making
our technique vulnerable to the same scalability problems that arise
with dual-rail encoding.  Therefore, we adopt a more controlled
approach to splitting.  Specifically, we wish to split words in such a
way that we can speak of an entire sub-word having the value 
without having to worry about which individual bits in the sub-word
have the value .  Towards this end, we partition every word in an
RTL design into sub-words, which we henceforth call \emph{atoms}, such
that every RTL statement (except a few discussed later) that reads or
updates a word either does so for all bits in an atom, or for no bit
in an atom.  In other words, no RTL statement (except the few
discussed at the end of this section) reads or updates an atom partially.  

\subsubsection{Some details of atomization}
To formalize the notion of atoms, let  be a word of width  in an
RTL design .  Let  denote the least significant bit position and
 denote the most significant bit position of .  For integer
constants ,  such that , we say that the
sub-word of  from bit position  to  is a \emph{slice} of ,
and denote it by .  let  be an abstract
selection operator that either reads or writes the slice .
Concrete instances of  are commonly used in RTL
designs, e.g. in the System-Verilog statement {\tt c[4:1] = a[10:7] +
  b[5:2]}. We say that  \emph{induces an
  atomization} of , as shown in Table II,where
 denotes the set of atoms into which  is partitioned.
\begin{table}
\begin{center}
\begin{tabular}{|c|c|}
\hline
{\bfseries Condition} & {\bfseries } \\
\hline
 and  &  \\
\hline
 and  &  \\
\hline
 and  & \\
\hline
 and  & \\
\hline
\end{tabular}
\caption{Computing atoms induced by }
\end{center}
\end{table}\label{atoms}

Given atomizations  and , we
define their \emph{coarsest refinement} to be the atomization in which
 and  belong to the same atom iff they belong
to the same atom in both  and
.  For every word  in the RTL
design, we maintain a working set, , of atoms.
Initially,  is initialized to .
For every concrete instance of  applied on  in an RTL
statement, we compute  using Table II, and
determine the coarsest refinement of  and
.  The working set  is
then updated to the coarsest refinement thus computed.  The above
process is then repeated for every RTL statement in the design.

The above discussion leads to a fairly straightforward algorithm for
identifying atoms in an RTL design.  We illustrate this on a simple example below.
\begin{wrapfigure}[16]{R}{0.5\textwidth}
\vspace*{-0.4in}
\begin{center}
\includegraphics[scale=0.4]{atomization}
\end{center}
\vspace*{-0.2in}
\caption{\label{atomization}Illustrating atomization}
\end{wrapfigure}
Fig.~\ref{atomization}(a) shows a System-Verilog code fragment, and
Fig.~\ref{atomization}(b) shows an atomization of words, where the
solid vertical bars represent the boundaries of atoms.  Note that
every System-Verilog statement in Fig.~\ref{atomization}(a) either
reads or writes all bits in an atom, or no bit in an atom.  Since we
wish to reason at the granularity of atoms, we must interpret
word-level reads and writes in terms of the corresponding atom-level
reads and writes.  This can be done either by modifying the RTL, or by
taking appropriate care when symbolically simulating the RTL.  For
simplicity of presentation, we show in Fig.~\ref{atomization}(c) how
the code fragment in Fig.~\ref{atomization}(b) would appear if we were
to use only the atoms identified in Fig.~\ref{atomization}(b).  Note
that no statement in the modified RTL updates or reads a slice of an
atom.  However, a statement may be required to read a slice of the
result obtained by applying an RTL operator to atoms (see, for example,
Fig.~\ref{atomization}(c) where we read a slice of the result obtained by
adding concatenated atoms). In our implementation, we do not modify the RTL.
Instead, we symbolically simulate the original RTL, but generate the
expressions for various atoms that would result from simulating the
modified RTL.

Once the boundaries of all atoms are determined, we choose to
disregard values of atoms in which some bits are set to , and the
others are set to  or .  This choice is justified since all bits
in an atom are  read or written together.  Thus, either all bits
in an atom are considered to have values in , or all of them
are considered to have the value .  This implies that values of an
-bit atom can be encoded using  bits, instead of using 
bits as in dual-rail encoding.  Specifically, we can associate an
additional ``invalid'' bit with every -bit atom.  Whenever the
``invalid'' bit is set, all bits in the atom are assumed to have the
value .  Otherwise, all bits are assumed to have values in .  We show later in Sections~\ref{subsec:sim-val} and
\ref{subsec:sim-inv} how the value and invalid bit of an atom can be
recursively computed from the values and invalid bits of the atoms on
which it depends.

Memories and arrays in an RTL design are usually indexed by variables
instead of by constants.  This makes it difficult to atomize memories
and arrays statically, and we do not atomize them.  Similarly, if a
design has a logical shift operation, where the amount of shift is
specified by a variable, it is difficult to statically identify
subwords that are not split by the shift operation.  We ignore all
such RTL operations during atomizaion, and instead use extensional
arrays~\cite{StumpBarrettDill01} to model and reason about them.
Section~\ref{subsec:sim-inv} discusses the modeling of
memory/array reads and writes in this manner.  


\section{Lattice of atom values}\label{sec:lattice}

Recall that the primary motivation for atomizing words is to identify
the right granularity at which an entire sub-word (atom) can be
assigned the value  without worrying about which bits in the
sub-word have the value .  Therefore, an -bit atom  takes
values from the set , where
 is a single abstract value that denotes an assignment of
 to at least one bit of .
Note the conspicuous absence of values like  in the above
set.
\begin{figure}[htbp]
\begin{center}
\hspace{-0.25in}\includegraphics[scale=0.25]{lattice-comparison}
\caption{\label{lattice-comparison} Atom-level and bit-level lattices}
\end{center}
\end{figure}
Fig.~\ref{lattice-comparison}(a) shows the lattice of values for a
-bit atom, ordered by information content.  The  element is
added to complete the lattice, and represents an unachievable
over-constrained value.  Fig.~\ref{lattice-comparison}(b) shows the
lattice of values of the same atom if we allow each bit to take values
in .  Clearly, the lattice in
Fig.~\ref{lattice-comparison}(a) is shallower and sparser than that
in Fig.~\ref{lattice-comparison}(b).

Consider an -bit word  that has been partitioned into
non-overlapping atoms of widths , where .  The lattice of values of  is given by the product of 
lattices, each corresponding to the values of an atom of .  For
convenience of representation, we simplify the product lattice by
collapsing all values that have at least one atom set to  (and
therefore represent unachievable over-constrained values), to a single
 element.
It can be verified that the height of the product lattice (after the
above simplification) is given by , the total number of elements
in it is given by  and the
number of elements at level  from the bottom is given by
, where .  It is not
hard to see from these expressions that atomization using few wide atoms (i.e.,
small values of  and large values of ) gives shallow and
sparse lattices compared to atomization using many narrow atoms (i.e.,
large values of  and small values of ).  The special case of a
bit-blasted lattice (see Fig.~\ref{lattice-comparison}(b)) is obtained
when  and  for every .

Using a sparse lattice is advantageous in symbolic reasoning since we
need to encode a small set of values.  Using a shallow lattice helps
in converging fast when computing least upper bounds -- an operation
that is crucially needed when performing symbolic trajectory
evaluation.  However, making the lattice of values sparse and shallow
comes at the cost of losing precision of reasoning.  By atomizing
words based on their actual usage in an RTL design, and by abstracting
values of atoms wherein some bits are set to  and the others are
set to  or , we strike a balance between depth and density of
the lattice of values on one hand, and precision of reasoning on the
other.

\section{Symbolic simulation with invalid-bit encoding}\label{sec:encoding}
As mentioned earlier, an -bit atom can be encoded with  bits
by associating an ``invalid bit'' with the atom.  For notational
convenience, we use  to denote the value of the  bits
constituting atom , and  to denote the value of its
invalid bit.  Thus, an -bit atom  is encoded as a pair
, where  is a bit-vector of width
, and  is of  type.  Given
, the value of  is given by
, where ``'' denotes
the usual ``if-then-else'' operator.  For clarity of exposition, we
call this encoding ``invalid-bit encoding''.  Note that invalid-bit
encoding differs from dual-rail encoding even when .
Specifically, if a -bit atom  has the value , we can use
either  or  for  in
invalid-bit encoding.  In contrast, there is a single value, namely
, that encodes the value  of  in dual-rail
encoding.  We will see in Section~\ref{subsec:sim-inv} how this degree
of freedom in invalid-bit encoding of  can be exploited to simplify
the symbolic simulation of word-level operations on
invalid-bit-encoded operands, and also to simplify the computation of
least upper bounds.

Symbolic simulation is a key component of symbolic trajectory
evaluation.  In order to symbolically simulate an RTL design in which
every atom is invalid-bit encoded, we must first determine the
semantics of word-level RTL operators with respect to invalid-bit
encoding.  Towards this end, we describe below a generic technique for
computing the value component of the invalid-bit encoding of the
result of applying a word-level RTL operator.  Subsequently, we
discuss how the invalid-bit component of the encoding is computed.

\subsection{Symbolically simulating values}\label{subsec:sim-val}
Let  be a word-level RTL operator of arity , and let 
be the result of applying  on , i.e.,
.  For each  in , suppose the bit-width of operand  is , and suppose the
bit-width of  is .  We assume that each operand is
invalid-bit encoded, and we are interested in computing the
invalid-bit encoding of a specified slice of the result, say
, where .  
Let  denote the RTL
semantics of .  For example, if  denotes -bit unsigned
addition, then  is the function that takes two
-bit operands and returns their -bit unsigned sum.  The following lemma
states that  can be computed if we know  and , for every .
Significantly, we do not need  for any  to compute .  
\begin{lemma}\label{correct-val}
  Let .  Then  is given by ,
  where .
\end{lemma}
\begin{proof}
  By definition of invalid-bit encoding, if  is
  , the value of  does not matter.  Hence, we
  focus on the case where  is .  By
  definition, in this case,  has a value in .  If the invalid bits of all operands  are
  , then    clearly computes the
  value of .  Otherwise, suppose  for some .  By definition of
  invalid-bit encoding,  can have any value in .
  However, since  is , it must be the case
  that  has a well-defined value in , regardless of what value  takes in .  Therefore, we can set the value of  to
   without affecting the value of .  By
  repeating this argument for all  such that  is
  , we see that  gives
       .
\end{proof}
Lemma~\ref{correct-val} tells us that when computing
, we can effectively assume that invalid-bit
encoding is not used.  This simplifies symbolic simulation with
invalid-bit encoding significantly.  Note that this simplification
would not have been possible had we not had the freedom to ignore
 when  is .

\subsection{Symbolically simulating invalid bits}\label{subsec:sim-inv}
We now turn to computing .  Unfortunately, computing
 precisely is difficult and involves
operator-specific functions that are often complicated.  We therefore
choose to approximate  in a sound manner with
functions that are relatively easy to compute.  Specifically, we allow
 to evaluate to  (denoting ) even in cases where a careful calculation would have
shown that  is not .
However, we never set  to {\false} if any bit in
 can take the value  in a bit-blasted evaluation of
.  
Striking a fine balance between the precision and computational
efficiency of the sound approximations is key to building a
practically useful symbolic simulator using invalid-bit encoding.  Our
experience indicates that simple and sound approximations of
 can often be carefully chosen to serve our purpose.
While we have derived templates for approximating 
for  obtained by applying all word-level RTL operators that
appear in our benchmarks, we cannot present all of them in detail here
due to space constraints.  We present below a discussion of how
 is approximated for a subset of important RTL
operators.  Importantly, we use a recursive formulation for computing
.  This allows us to recursively compute
invalid bits of atoms obtained by applying complex sequences of
word-level operations to a base set of atoms.  

\subsubsection{Word-level addition.} Let  denote an
-bit addition operator.  Thus, if  and  are -bit operands,
 generates an -bit  and a -bit .  Let the
carry generated after adding the least significant  bits of the
operands be denoted .  We discuss below how to compute
sound approximations of  and
, where  and .

It is easy to see that the value of  is completely
determined by ,  and .  Therefore, we can
approximate  as follows:


To see why the above approximation is sound, note that if
all of ,  and  are
, then ,  and  must have
non- values.  Hence, there is no uncertainty in the value
of  and .  On the other hand, if
any of ,  or  is
, there is uncertainty in the value of .

The computation of  (or ) is
interesting, and deserves special attention.  We identify three cases
below, and argue that  is  in each of these
cases.  In the following,  denotes the -bit constant
.
\begin{enumerate}
\item If ,
  then both  and  must be
  .  Therefore, there is no uncertainty in the values of
  either  or , and .
\item If , then the least significant  bits of
   are all .  Regardless of , it is easy to
  see that in this case,  and .
\item This is the symmetric counterpart of the case above, i.e.,
  .
\end{enumerate}
We now approximate  by combining the conditions
corresponding to the three cases above.  In other words,


\subsubsection{Word-level division.} Let  denote an
-bit division operator; this is among the most complicated
word-level RTL operators for which we have derived an approximation of
the invalid bit.  If  and  are -bit operands, 
generates an -bit quotient, say , and an -bit remainder,
say .  We wish to compute  and
, where .  We assume that if
 is , then ; the case of 
with  leads to a
``divide-by-zero'' exception, and is assumed to be handled separately.

The following expressions give sound approximations for
 and .  In these expressions, we
assume that  is a non-negative integer such that .  


Note that the constraint  in the
above formulation refers to a fresh variable  that does not
appear in the RTL.  
We will see later in Section~\ref{sec:wste} that a word-level STE
problem is solved by generating a set of word-level constraints, every
satisfying assignment of which gives a counter-example to the
verification problem.  We add constraints like  in the above formulation, to the set of word-level
constraints generated for an STE problem.  This ensures that every
assignment of  in a counterexample satisfies the required
constraints on .



To see why the above approximations for  and
 are sound, first consider the case where
.  Since we are unsure of the value of the divisor,
not much can be said about the remainder.  So, we set
 to .  The situation is slightly better for
the quotient.  If we know that , then since the
quotient of integer division is never larger than the dividend, we can
infer that  if .  Clearly, in this case
.  In all other sub-cases of , we set  to .

If , we know that  has a value in , but not .  Representing bit vectors by their
integer representations, let  be such that
.  We consider two
sub-cases below.
\begin{itemize}
\item  In this case,  effectively
  shifts  right by  bit positions, and the least significant 
  bits of  forms the remainder.
  Therefore,  is  if , is  padded to the left with  s if , and is  if .
  It follows that if , then 
  and .  Otherwise, , where .
it is easy to see that  is
 if , is  padded with  s to the
left if , and is  if .  
  By similar reasoning, if , then
;  otherwise, , where .
\item  In this case, we show below that
  if , then  can be approximated
  by .  If , then .  In all other cases, we approximate  and
   by .

  To see why the above approximations are sound, note that
   can be written as , where  and
   are the integer representations of  and ,
  respectively.  Clearly, .  Considering quotients
  and remainders on division by , suppose  and , where  and .  Suppose further that
  , where  and .  It is an easy exercise to see that the
  quotient of dividing  by  is , and the remainder is .  Thus,  and .  We discuss what
  happens when  and .
  \begin{itemize}
    \item If , then .  Since
      , we have  and .  It
      follows that .  If , then
       depends only on , which in turn, depends only
      on  and .  Therefore, 
      can be approximated by .

      We now show that  is indeed strictly less than .
      Since ,
      rearranging terms, we get .  If possible, let , where .
      Substituting for , we get .  Since , the
      left hand side of the above equation is at least as large as , while the right hand side is at most , which, in
      turn, is less than .  This gives a contradiction, and
      therefore, .
    \item If , we have .
      Therefore, , and .
  \end{itemize}
\end{itemize}
The above analysis yields the sound approximations for
 and  discussed above.

\subsubsection{If-then-else statements.} Consider a conditional
assignment statement ``{\tt if (BoolExpr) then x = Exp1; else x =
  Exp2;}''.  Symbolically simulating this statement gives .  The
following gives a sound approximation of . 

To see why the above approximation of  is sound, let
, where
 is a boolean expression, and  and
 are expressions of the same type as .  To compute
, we note that if , then  is simply
.  However, if
, then the value of 
could be  (denoting ) or  (denoting ).
Interestingly, if both  and
 are  (i.e., neither
 nor  are ), and
if , then
regardless of the value of , we have
.  This is formalized in the approximation
for  mentioned above.


\subsubsection{Bit-wise logical operations.} Let 
and  denote bit-wise negation and conjunction operators
respectively, for -bit words.  If , ,  and  are -bit
words such that  and , it is easy to
see that the following give sound approximations of  and
.

The invalid bits of other bit-wise logical operators (like
disjunction, xor, nor, nand, etc.) can be obtained by first expressing
them in terms of  and  and then using the above
approximations.


\subsubsection{Memory/array reads and updates.} Let
 be a -dimenstional array,  be an index
expression, and  be a variable and  be an
expression of the base type of .  On symbolically simulating the
RTL statement ``{\tt x = A[i];}'', we update the value of 
to , where the  operator
is as in the extensional theory of arrays
(see~\cite{StumpBarrettDill01} for details).  Similarly, on
symbolically simulating the RTL statement ``{\tt A[i] = Exp}'', we
update the value of array  to
,
where  is the (array-typed) expression for
 prior to simulating the statement, and the 
operator is as in the extensional theory of arrays. 

Since the expression for a variable or array obtained by symbolic
simulation may now have  and  operators, we
must find ways to compute sound approximations of the invalid bit for
expressions of the form . Note that since  is an array, the
symbolic expression for  is either (i)
, i.e. the initial value of  at
the start of symbolic simulation, or (ii)  for some expressions ,
 and , where  has the same
array-type as ,  has an index type, and
 has the base type of .  For simplicity of
exposition, we assume that all arrays are either completely
initialized or completely uninitialized at the start of symbolic
simulation.  The invalid bit in case (i) is then easily seen to be
 if  denotes an uninitialized
array, and  otherwise.  In case (ii), let  denote
.  The invalid bit of  can
then be approximated as:



To see why the above expression gives a sound approximation of
, note that if either  or  is
 (i.e. the corresponding invalid bit is ), we
conservatively set  to .  If neither
 nor  is , there are two cases to
consider.
\begin{itemize}
\item If , then
  .  Hence, the required invalid bit is
  .
\item If , then
  . Hence, the
  required invalid bit is .
\end{itemize}
If the RTL design has multi-dimensional arrays, we simply treat them as arrays of
arrays, and apply the same reasoning as above.  For example, if
 is a two-dimenstional array, the RTL statement ``{\tt
  B[i][j] = Exp;}'' updates the symbolic value of array 
to , where  is the
symbolic expression for  prior to simulating the RTL statement.
Similarly, the RTL statement ``{\tt x = B[i][j];}''updates the
symbolic value of  to .

\subsubsection{Shift operations.} We discuss below the
left-shift operation; the case of the right-shift operation can be
analyzed similarly.  A shift operation can specify either a constant
number of bit positions to shift, or a variable number of positions to
shift.  We analyze these two cases separately since shifting by a
variable number of positions does not allow us to statically identify
the operand's bit-slices of interest.  In either case, we assume that
a left shift operation pads s in the least signficant shifted
positions.  Let  denote a unary left-shift operator of the
first kind, where  is a positive integer constant, and let 
denote a binary left-shift operator of the second kind.  Let  be -bit words such that  and .
For simplicity of presentation, we assume no wrap-around in shifting;
the case of wrap-around can be analyzed in a similar way.  The
following equations give sound approximations of  and
, where .
\vspace*{-0.03in}



\subsection{Computing least upper bounds}\label{subsec:lub}
Let  and  be
invalid-bit encoded elements in the lattice of values for an
-bit atom.  We define  as follows.
  \begin{itemize}
    \item[(a)] If , then .
    \item[(b)] Otherwise,  and
       (or
      equivalently ).
  \end{itemize}
Note the freedom in defining  in case (b) above.  This
freedom comes from the observation that if , the
value of  is irrelevant.  Furthermore, if the condition in
case (a) is not satisfied and if both  and  are
, then .  This allows us to simplify
the expression for  on-the-fly by replacing it with
, if needed.  

\section{Word-level STE}\label{sec:wste}
In this section, we briefly review the general theory of
STE~\cite{SegerBryant95} instantiated to the lattice of values of
atoms.  An RTL design  consists of inputs, outputs and internal
words.  We treat bit-level signals as -bit words, and uniformly
talk of words.  Every input, output and internal word is assumed to be
atomized as described in Section~\ref{sec:atomization}.  Every atom of
bit-width  takes values from the set , where constant bit-vectors have been
represented by their integer values.  The values themselves are
ordered in a lattice as discussed in Section~\ref{sec:lattice}.  Let
 denote the ordering relation and  denote the 
operator in the lattice of values for an -bit atom.  The lattice of
values for a word is the product of lattices corresponding to every
atom in the word.  Let  denote the collection of all
atoms in the design, and let  denote the collection
of values of all atoms in .  A state of the design
is a mapping  such that if
 is an -bit atom, then  is a value in the set
.  Let
 denote the set of all states of the design.  Clearly 
forms a lattice -- one that is isomorphic to the product of lattices
corresponding to the atoms in .  

Given a design , let  define
the transition function of .  Thus, given a state  of  at
time , the next state of the design at time  is given by
.  To model the behavior of a design over time, we define
a \emph{sequence} of states as a mapping , where  denotes the set of natural
numbers.  A \emph{trajectory} for a design  is a sequence 
such that for all , .  Given two sequences  and , we abuse
notation and say that  iff for every , .

The general \emph{trajectory evaluation logic} of Seger and
Bryant~\cite{SegerBryant95} can be instantiated to words as follows.
A \emph{trajectory formula} is a formula generated by the grammar
\begin{tabular}{lllllllll}
 & ::= &  is  &  &  and  & 
                   &  &   &
\end{tabular}, where
 is an atom of ,  is a non-,
non- value in the lattice of values for , and  is
a quantifier-free formula in the theory of bit-vectors.  Formulas like
 in the grammar above are also called \emph{guards} in STE
parlance.


Following Seger et al~\cite{BryantSeger90,SegerJOMABS05}, the
\emph{defining sequence} of a trajectory formula  given the
assignment , denoted , is defined inductively as
follows.  Here,  denotes an arbitrary -bit atom in
 and .
\begin{itemize}
\item  if  and both 
  denote the same -bit atom, and is  otherwise.
\item 
\item  if , and is  otherwise.
\item  if , and is 
  otherwise.
\end{itemize}
Similarly, the \emph{defining trajectory} of  with respect to
a design , denoted  can be defined as
follows.
\begin{itemize}
\item 
\item  for every .
\end{itemize}
In symbolic trajectory evaluation, we are given an antecedent 
and a consequent  in trajectory evaluation logic.  We are also
given a quantifier-free formula  in the theory of bit-vectors
with free variables that appear in the guards of  and/or
.  We wish to determine if for every assignment  that
satisfies , we have .



\subsection{Implementation}
We have developed a tool called {\steword} that uses symbolic
simulation with invalid-bit encoding and SMT solving to perform STE.
Each antecedent and consequent tuple has the format , where  is a guard,  is the name of an
atom in the design under verification,  is a symbolic
expression over constants and guard variables that specifies the value
of , and  and  denote time points such that .

An antecedent tuple  specifies that given an
assignment  of guard variables, if , then atom
 is assigned the value of expression , evaluated on satisfying
assignments of ,
for all time in .  If, however, , atom  is assigned the value  for all
time in .  If  is an input atom, the
antecedent tuple effectively specifies how it is driven from time
 through .  Using invalid-bit encoding, the above
semantics is easily implemented by setting  to  and
 to  from time  through .  If  is an
internal atom, the defining trajectory requires us to compute the
 of the value driven by the circuit on  and the value
specified by the antecedent for , at every time point in .  The value driven by the circuit on  at any time
is computed by symbolic simulation using invalid-bit encoding, as
explained in Sections~\ref{subsec:sim-val} and \ref{subsec:sim-inv}.
The value driven by the antecedent can also be invalid-bit encoded, as
described above.  Therefore, the  can be computed as described in
Section~\ref{subsec:lub}.  If the  is not ,  and
 can be set to the value and invalid-bit, respectively, of
the .  In practice, we assume that the  is not  and
proceed as above. The conditions under which the  evaluates to
 are collected separately, as described below.  The values of
all atoms that are not specified in any antecedent tuple are obtained
by symbolically simulating the circuit using invalid-bit encoding.

If the  computed above evaluates to , we must set atom 
to an unachievable over-constrained value.  This is called
\emph{antecedent failure} in STE parlance.  In our implementation, we
collect the constraints (condition for case (a) in
Section~\ref{subsec:lub}) under which antecedent failure occurs for
every antecedent tuple in a set {\AntFail}.  Depending on the mode of
verification, we do one of the following:
\begin{itemize}
\item If the disjunction of formulas in {\AntFail} is satisfiable, we
  conclude that there is an assignment of guard variables that leads
  to an antecedent failure.  This can then be viewed as a failed run
  of verification.
\item We may also wish to check if  only for assignments  that do not satisfy
  any formula in .  In this case, we conjoin the negation
  of every formula in  to obtain a formula, say
  , that defines all assignments  of interest.
\end{itemize}

A consequent tuple  specifies that given an
assignment  of guard variables, if , then atom
 must have its invalid bit set to  and value set to
, evaluated on satisfying assignments of , for all time
in .  If , a
consequent tuple imposes no requirement on the value of atom .
Suppose that at time , a consequent tuple specifies a guard  and
a value expression  for an atom .  Suppose further that
 gives the invalid-bit encoded value of this
atom at time , as obtained from symbolic simulation.  Checking
whether 
for all assignments  reduces to checking the validity of the
formula .  Let us call this formula .  Let  denote
the set of all time points specified in all consequent tuples, and let
 denote the set of all atoms of the design.  The overall
verification goal then reduces to checking the validity of the formula
.  If we
wish to focus only on assignments  that do not cause any
antecedent failure, our verification goal is modified to check the
validity of .  In our implementation, we
use {\Boolector}~\cite{BrummayerBiere09}, a state-of-the-art solver
for bit-vectors and the extensional theory of arrays, to check the
validity (or satisfiability) of all formulas  generated by
{\steword}.

\section{Experiments}\label{sec:experiments}
We used {\steword} to verify properties of a set of System-Verilog
word-level benchmark designs.  Bit-level STE tools are often known to
require user-guidance with respect to problem decomposition and
variable ordering (for BDD based tools), when verifying properties of
designs with moderate to wide datapaths.  Similarly, BMC tools need to
introduce a fresh variable for each input in each time frame when the
value of the input is unspecified.  Our benchmarks were intended to
stress bit-level STE tools, and included designs with control and
datapath logic, where the width of the datapath was parameterized.
Our benchmarks were also intended to stress BMC tools by providing
relatively long sequences of inputs that could either be  or a
specified symbolic value, depending on a symbolic condition.  In each
case, we verified properties that were satisfied by the system and
those that were not.  For comparative evaluation, we implemented
word-level bounded model checking as an additional feature of
{\steword} itself.  Below, we first give a brief description of each
design, followed by a discussion of our experiments.

{\bfseries \emph{Design 1:}} Our first design was a three-stage
pipelined circuit that read four pairs of -bit words in each cycle,
computed the absolute difference of each pair, and then added the
absolute differences with a current running sum.  Alternatively, if a
reset signal was asserted, the pipeline stage that stored the sum was
reset to the all-zero value, and the addition of absolute differences
of pairs of inputs started afresh from the next cycle.  In order to
reduce the stage delays in the pipeline, the running sum was stored in
a redundant format and carry-save-adders were used to perform all
additions/subtractions. Only in the final stage was the non-redundant
result computed. In addition, the design made extensive use of clock
gating to reduce its dynamic power consumption -- a characteristic of
most modern designs and that significantly complicates formal
verification.  Because of the non-trivial control and
clock gating, the STE verification required a simple datapath
invariant.  Furthermore, in order to reduce the complexity in
specifying the correctness, we broke down the overall verification
goal into six properties, and verified these properties using several
datapath widths.

{\bfseries \emph{Design 2:}} Our second design was a pipelined serial
multiplier that read two -bit inputs serially from a single -bit
input port, multiplied them and made the result available on a
-bit wide output port in the cycle after the second input was
read.  The entire multiplication cycle was then re-started afresh.  By
asserting and de-asserting special input flags, the control logic
allowed the circuit to wait indefinitely between reading its first and
second inputs, and also between reading its second input and making
the result available.  We verified several properties of this circuit,
including checking whether the result computed was indeed the product
of two values read from the inputs, whether the inputs and results
were correctly stored in intermediate pipeline stages for various
sequences of asserting and de-asserting of the input flags, etc.  In
each case, we tried the verification runs using different values of
the bit-width .

{\bfseries \emph{Design 3:}} Our third design was an implementation of
the first stage in a typical digital camera pipeline.  The design is
fed the output of a single CCD/CMOS sensor array whose pixels have
different color filters in front of them in a Bayer mosaic pattern
\cite{MalvarLiWeiCutler04}. The design takes these values and performs
a ``de-mosaicing'' of the image, which basically uses a fairly
sophisticated interpolation technique (including edge detection) to
estimate the missing color values.  The challenge here was not only
verifying the computation, which entailed adding a fairly large number
of scaled inputs, but also verifying that the correct pixel values
were used. In fact, most non-STE based formal verification engines will
encounter difficulty with this design since the final result depends on
several hundreds of -bit quantities.

{\bfseries \emph{Design 4:}} Our fourth design is a more general
version of Design 3, that takes as input stream of values from a
single sensor with a mosaic filter having alternating colors, and
produces an interpolated red, green and blue stream as output.  Here,
we verify  different locations on the screen, which translates to
 different locations in the input stream. Analyzing this example
with BMC requires providing new inputs every cycle for over 
cycles, leading to a blow-up in the number of variables used.

For each benchmark design, we experimented with a bug-free version,
and with several buggy versions.  For bit-level verification, we used
both a BDD-based STE tool~\cite{SegerJOMABS05} and propositional SAT
based STE tool~\cite{RoordaClaessen05}; specifically, the tool
{\forte} was used for bit-level STE.  We also ran word-level BMC to
verify the same properties.

In all our benchmarks, we found that {\forte} and {\steword}
successfully verified the properties within a few seconds when the
bitwidth was small ( bits).  However, the running time of {\forte}
increased significantly with increasing bit-width, and for bit-widths
of  and above, {\forte} could not verify the properties without
serious user intervention.  In contrast, {\steword} required
practically the same time to verify properties of circuits with wide
datapaths, as was needed to verify properties of the same circuits
with narrower datapaths, and required no user intervention.  In
fact, the word-level SMT constraints generated for a circuit with a
narrow datapath are almost identical to those generated for a circuit
with a wider datapath, except for the bit-widths of atoms.  This is
not surprising, since once atomization is done, symbolic simulation is
agnostic to the widths of various atoms.  An advanced SMT solver like
Boolector is often able to exploit the word-level structure of the
final set of constraints and solve it without resorting to
bit-blasting.

The BMC experiments involved adding a fresh variable in each time
frame when the value of an input was not specified or conditionally
specified.  This resulted in a significant blow-up in the number of
additional variables, especially when we have long sequences of
conditionally driven inputs.  This in turn adversely affected
SMT-solving time, causing BMC to timeout in some cases.

To illustrate how the verification effort with {\steword} compared
with the effort required to verify the same property with a bit-level
BDD- or SAT-based STE tool, and with word-level BMC, we present a
sampling of our observations in Table I, where no user intervention
was allowed for any tool.  Here ``-'' indicates more than  hours
of running time, and all times are on an Intel Xeon 3GHz CPU, using
a single core.  In the column labeled ``Benchmark'',
Design-P corresponds to verifying property  (from a list of
properties) on Design .  The column labeled ``Word-level latches
(\# bits)'' gives the number of word-level latches and the total
number of bits in those latches for a given benchmark.  The column
labeled ``Cycles of Simulation'' gives the total number of time-frames
for which STE and BMC was run.  The column labeled ``Atom Size
(largest)'' gives the largest size of an atom after our atomization
step.  Clearly, atomization did not bit-blast all words,
allowing us to reason at the granularity of multi-bit atoms in {\steword}.

\begin{table}
\scriptsize
\begin{center}
\begin{tabular}{|c|c|c|c|c|c|c|}
\hline
Benchmark & {\steword} & {\forte}  & BMC & Word-level latches & Cycles of  & Atom Size \\
        &            & (BDD and SAT) &     & (\# bits)     & Simulation & (largest) \\
\hline
Design1-P1 & 2.38s                   & -                             & 3.71s & 14 latches & 12 & 31 \\
(32 bits)  &         & -                                   &  & (235 bits wide) & & \\
\hline
Design1-P1 & 2.77s                   & -                                   & 4.53s & 14 latches & 12 & 64 \\
(64 bits)  &         & -                                   &  & (463 bits wide) & & \\
\hline
Design2-P2 & 1.56s                   & -                             & 1.50s & 4 latches & 6 & 32\\
(16 bits)  &         & -                                   &  & (96 bits wide) & & \\
\hline
Design2-P2 & 1.65s                   & -                                   & 1.52s & 4 latches & 6 & 64\\
(32 bits)  &         & -                                   &  & (128 bits wide) & & \\
\hline
Design3-P3 & 24.06s                  & -                                   & - & 54 latches & 124 & 16 \\
(16 bits)  &         & -                                   &  & (787 bits wide) & & \\
\hline
Design4-P4 & 56.80s                  & -                                   & - & 54 latches & 260 & 16 \\
(16 bits)  &         & -                                   &  & (787 bits wide) & & \\
\hline
Design4-P4 & 55.65s                  & -                                   & - & 54 latches & 260 & 32 \\
(32 bits)  &         & -                                   &  & (1555 bits wide) & & \\
\hline
\end{tabular}
\end{center}
\caption{Comparing verification effort (time) with {\steword}, {\forte} and BMC}
\vspace*{-0.2in}
\label{compare-table}
\end{table}
Our experiments indicate that when a property is not satisfied by a
circuit, Boolector finds a counterexample quickly due to powerful
search heuristics implemented in modern SMT solvers.  BDD-based
bit-level STE engines are, however, likely to suffer from BDD size
explosion in such cases, especially when the bit-widths are large.  In
cases where there are long sequences of conditionally driven inputs
(e.g., design 4) BMC performs worse compared to {\steword}, presumably
beacause of the added complexity of solving constraints with
significantly larger number of variables.  In other cases, the
performance of BMC is comparable to that of {\steword}.  An important
observation is that the abstractions introduced by atomization and by
approximations of invalid-bit expressions do not cause {\steword} to
produce conservative results in any of our experiments.  Thus,
{\steword} strikes a good balance between accuracy and performance.
Another interesting observation is that for correct designs and
properties, SMT solvers (all we tried) sometimes fail to verify the
correctness (by proving unsatisfiability of a formula).  This points
to the need for further developments in SMT solving, particularly for
proving unsatisfiability of complex formulas.  Overall, our
experiments, though limited, show that word-level STE can be
beneficial compared to both bit-level STE and word-level BMC in
real-life verification problems.

We are currently unable to make the binaries or source of {\steword}
publicly available due to a part of the code being proprietary.  A
web-based interface to {\steword}, along with a usage document and the
benchmarks reported in this paper, is available at
http://www.cfdvs.iitb.ac.in/WSTE/

\section{Conclusion}\label{sec:conclusion}
Increasing the level of abstraction from bits to words is a promising
approach to scaling STE to large designs with wide datapaths.  In this
paper, we proposed a methodology and presented a tool to achieve this
automatically.  Our approach lends itself to a
counterexample guided abstraction refinement (CEGAR) framework, where
refinement corresponds to reducing the conservativeness in invalid-bit
expressions, and to splitting existing atoms into finer bit-slices.
We intend to build a CEGAR-style word-level STE tool as part of future
work.

\subsubsection{Acknowledgements.} We thank Taly Hocherman and Dan Jacobi for
their help in designing a System-Verilog symbolic simulator.  We thank
Ashutosh Kulkarni and Soumyajit Dey for their help in implementing and
debugging {\steword}.  
\bibliographystyle{plain} 
\begin{thebibliography}{10}

\bibitem{BrummayerBiere09}
R.~Brummayer and A.~Biere.
\newblock Boolector: An efficient {SMT} solver for bit-vectors and arrays.
\newblock In {\em Proc. of TACAS}, pages 174--177, 2009.

\bibitem{BryantSeger90}
R.~E. Bryant and C.-J.~H. Seger.
\newblock Formal verification of digital circuits using symbolic ternary system
  models.
\newblock In {\em Proc. of CAV}, pages 33--43, 1990.

\bibitem{Emerson95}
E.~A. Emerson.
\newblock Temporal and modal logic.
\newblock In {\em Hanbook of {T}heoretical {C}omputer {S}cience}, pages
  995--1072. Elsevier, 1995.

\bibitem{Joh01}
P.~Johannsen.
\newblock Reducing bitvector satisfiability problems to scale down design sizes
  for rtl property checking.
\newblock In {\em Proc. of HLDVT}, pages 123--128, 2001.

\bibitem{JonesOSAM01}
R.~B. Jones, J.~W. O'Leary, C.-J.~H. Seger, M.~Aagaard, and T.~F. Melham.
\newblock Practical formal verification in microprocessor design.
\newblock {\em IEEE Design {\&} Test of Computers}, 18(4):16--25, 2001.

\bibitem{KaivolaEtAl09}
R.~Kaivola, R.~Ghughal, N.~Narasimhan, A.~Telfer, J.~Whittemore, S.~Pandav,
  A.~Slobodov{\'a}, C.~Taylor, V.~Frolov, E.~Reeber, and A.~Naik.
\newblock Replacing {T}esting with {F}ormal {V}erification in {I}ntel
  {C}ore i7 {P}rocessor {E}xecution {E}ngine {V}alidation.
\newblock In {\em Proc. of CAV}, pages 414--429, 2009.

\bibitem{KumarGuptaGhughal12}
V.~M.~A. KiranKumar, A.~Gupta, and R.~Ghughal.
\newblock Symbolic trajectory evaluation: The primary validation vehicle for
  next generation intel{\textregistered} processor graphics fpu.
\newblock In {\em Proc. of FMCAD}, pages 149--156, 2012.

\bibitem{MalvarLiWeiCutler04}
H.~S. Malvar, H.~Li-Wei, and R.~Cutler.
\newblock High-quality linear interpolation for demosaicing of
  {B}ayer-patterned color images.
\newblock In {\em Proc. of ICASSP}, volume~3, pages 485--488, 2004.

\bibitem{RoordaClaessen05}
J.-W. Roorda and K.~Claessen.
\newblock A new {SAT}-based algorithm for symbolic trajectory evaluation.
\newblock In {\em Proc. of CHARME}, pages 238--253, 2005.

\bibitem{SegerBryant95}
C.-J.~H. Seger and R.~E. Bryant.
\newblock Formal verification by symbolic evaluation of partially-ordered
  trajectories.
\newblock {\em Formal Methods in System Design}, 6(2):147--189, 1995.

\bibitem{SegerJOMABS05}
C.-J.~H. Seger, R.~B. Jones, J.~W. O'Leary, T.~F. Melham, M.~Aagaard,
  C.~Barrett, and D.~Syme.
\newblock An industrially effective environment for formal hardware
  verification.
\newblock {\em IEEE Trans. on CAD of Integrated Circuits and Systems},
  24(9):1381--1405, 2005.

\bibitem{StumpBarrettDill01}
A.~Stump, C.~W. Barrett, and D.~L. Dill.
\newblock A decision procedure for an extensional theory of arrays.
\newblock In {\em Proc. of LICS}, pages 29--37. IEEE Computer Society, 2001.

\end{thebibliography}

\end{document}
