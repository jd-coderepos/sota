\def\arxiv{1}    

\let\accentvec\vec \documentclass{llncs}
\let\spvec\vec     \let\vec\accentvec 

\ifnum\arxiv=1
\pagestyle{plain}
\fi

\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{microtype}

\usepackage{amssymb}
\usepackage{amsmath}
\usepackage{amsfonts}

\newcommand{\proofEnd}{{\hfill\ensuremath{\blacksquare}}}
\newenvironment{proof_claim}{\upshape{\textsc{Proof of Claim.}}} {\hfill\ensuremath{\square}\smallskip}
\spnewtheorem{myClaim}{Claim}{\itshape}{\upshape}

\newcommand{\figPath}{.}
\usepackage{url}
\usepackage{hyperref}
\usepackage{xcolor}
\definecolor{darkblue}{rgb}{0,0,.5}
\hypersetup{colorlinks=true, breaklinks=true, linkcolor=darkblue, menucolor=darkblue, urlcolor=darkblue, citecolor=darkblue}


\usepackage{graphicx}
\usepackage{grffile}
\usepackage{subfigure}
\usepackage{sidecap}

\usepackage[neveradjust]{paralist}
\newenvironment{enumcases}{\setlength{\leftmargini}{10pt}\begin{compactenum}[\text{Case} 1:]}{\end{compactenum}}

\newcommand{\degr}{\ensuremath{d}}
\newcommand{\randv}{\ensuremath{D}}
\newcommand{\keys}{\ensuremath{n}}
\newcommand{\cells}{\ensuremath{m}}
\newcommand{\pmf}{\ensuremath{{\rho}}}
\newcommand{\mean}{{\mathrm{\scriptstyle\Delta}}}
\newcommand{\Amean}{\bar{\mean}}
\newcommand{\E}{\mathrm{E}}
\newcommand{\manList}[1]{\vskip 0.4em\noindent{#1}}
\newcommand{\floor}[1]{\ensuremath{\lfloor #1\rfloor}}
\newcommand{\ceil}[1]{\ensuremath{\lceil #1\rceil}}
\newcommand{\eps}{\ensuremath{\varepsilon}}
\newcommand{\blank}{\text{ }}
\newcommand{\graph}{\ensuremath{G}}
\newcommand{\graphWR}{\ensuremath{\tilde{G}}}
\newcommand{\low}{\ensuremath{l}}
\newcommand{\high}{\ensuremath{k}}
\newcommand{\abs}[1]{\lvert#1\rvert}
\newcommand{\fracd}[2]{\frac{\mathrm{d} #1}{\mathrm{d} #2}}
\newcommand{\bfrac}[2]{ \left(\frac{#1}{#2}\right) }
\newcommand{\pfail}{\mathbf{p}_{\mathrm{fail}}}
\newcommand{\psucc}{\mathbf{p}_{\mathrm{succ}}}
\newcommand{\evNM}{\bar{\mathcal{M}}}
\newcommand{\evM}{{\mathcal{M}}}
\newcommand{\evF}{{\mathcal{F}}}
\newcommand{\evD}{{\mathcal{D}}}
\newcommand{\evP}{{\mathcal{BI}}}
\newcommand{\evA}{{\mathcal{A}}}
\newcommand{\evB}{{\mathcal{B}}}
\newcommand{\Fail}{\mathrm{Fail}}
\newcommand{\fail}{\mathrm{fail}}
\newcommand{\bl}{\beta}
\newcommand{\hf}{\gamma}
\newcommand{\mgap}{\hspace{-1em}}

\begin{document}
 \abovedisplayskip0.12cm plus0.12cm minus0.12cm
 \belowdisplayskip0.12cm plus0.12cm minus0.12cm

\title{Towards Optimal Degree-distributions for Left-perfect Matchings in\texorpdfstring{\\}{}Random Bipartite Graphs}
\author{Martin Dietzfelbinger\thanks{Research supported by DFG grant DI 412/10-2.} \and Michael Rink}

\institute{Fakultät für Informatik und Automatisierung, Technische Universität Ilmenau
\email{\{martin.dietzfelbinger,michael.rink\}@tu-ilmenau.de}
}

\maketitle
\begin{abstract}
\vspace{-0.4cm}
Consider a random bipartite multigraph  with  left nodes and 
right nodes. Each left node  has  random right neighbors.
The average left degree  is fixed, .
We ask whether for the probability that  has a left-perfect matching
it is advantageous not to fix  for each left node  but rather choose it
at random according to some (cleverly chosen) distribution. We show the following,
provided that the degrees of the left nodes are independent: 
If  is an integer then it is optimal to use a fixed degree of  for all left nodes.
If  is non-integral then an optimal degree-distribution has the property that
each left node  has two possible degrees,  and ,
with probability  and , respectively, where  is from the closed interval~
and the average over all  equals .
Furthermore, if  and  is constant,
then each distribution of the left degrees that meets the conditions above determines the same
threshold  that has the following property as  goes to infinity:
If  then there exists a left-perfect matching with high probability.
If  then there exists no left-perfect matching with high probability.
The threshold  is the same as the known threshold for offline -ary cuckoo hashing
for integral or non-integral .
\vspace{-0.1cm}
\end{abstract}

\section{Introduction}
We study bipartite multigraphs  with left node set  and right node set ,
where each left node  from  has  right neighbors.
The right neighbors are chosen at random with replacement from ,
where the number of choices  is a random variable that follows some probability mass function .
Let  and let  as well as  for all  from .
For each  from  let  be the mean of , that is, ,
and let  be the average mean, i.e., .
We assume that the random variables  are independent and  is a given constant. 

Our aim is to determine a sequence of probability mass functions  for the random variables 
that maximizes the probability that the random graph 
has a matching that covers all left nodes, i.e., a left-perfect matching\footnote{In the following we will use ``matching'' and ``left-perfect matching'' synonymously.}.
We call such a sequence \emph{optimal}. Note that there must be some optimal sequence for compactness reasons.



\subsection{Motivation and Related Work}
Studying irregular bipartite graphs has lead to major improvements 
in the performance of erasure correcting codes.
For example in \cite{LMSS_Tornado_2001} Luby et al. showed how to increase the
fraction of message bits that can be recovered 
for a fixed number of check bits by using carefully
chosen degree sequences for both sides of the underlying bipartite graph.
The recovery process for erased message bits 
translates directly into a greedy algorithm 
for finding a matching in the bipartite graph associated with the recovery process.
This was the motivation for the authors of~\cite{DGMMPR_tight_2009_full,DGMMPR_tight_2010}
to study irregularity in the context of offline -ary cuckoo hashing.
Here one has a bipartite graph with left nodes corresponding to
keys and right nodes corresponding to table cells,
where each key randomly chooses table cells without replacement and 
the aim is essentially to find a left-perfect matching.
In \cite{DGMMPR_tight_2009_full} it was proven that if the degree of each left node 
follows some distribution with identical mean
and is independent of the other nodes then 
it is optimal in an asymptotic sense if
the degree of each left node is concentrated around its mean.
This is in contrast of the following observation 
in~\cite{R_mixed_preparation} in analogy to \cite{LMSS_Tornado_2001}:
an uneven distribution of the degrees of the left nodes
can increase the probability for the existence of a matching that has the advantage that it can be calculated
in linear time, by successively assigning left nodes to right nodes of degree one and removing them from the graph.

\subsection{Results}
We will show that for given parameters , and  there is an optimal sequence
of probability mass functions that concentrates the degree of the left nodes
around  and .
Furthermore, if  is an integer we can explicitly determine this optimal sequence. In the
case that  is non-integral we will identify a tight condition that an optimal sequence must meet. 
\begin{theorem}
\label{theo:main}
Let , as well as , and
let  be an optimal sequence for parameters .
Then the following holds for all .
\begin{compactenum}[(i)]
\item If  is an integer, then .
\item If  is non-integral, then  and .\end{compactenum}
\end{theorem}
The second statement is not entirely satisfying since it identifies no optimal solution.
However, we will give strong evidence that in the situation of Theorem~\ref{theo:main}~ there is no single,
simple description of a distribution that is optimal for all feasible node set sizes.

Since the case  is completely settled by Theorem~\ref{theo:main}~,
we focus on the cases where , with the additional condition that the number of left nodes is linear in the number of right nodes, that is  for constant .
We show that for sufficiently large  all sequences that meet the condition of Theorem~\ref{theo:main}~ 
asymptotically lead to the same matching probability. Therefore, we call these sequences \emph{near optimal}.
\begin{proposition}
\label{prop:thresholds}
Let , for constant , and let  be a near optimal sequence with average expected degree .
Then for sufficiently large  there is a threshold  such that the random graph  
has the following property. 
\begin{compactenum}[(i)]
\item  If  , then   has a matching with probability .
\item  If  , then    has no matching with probability .
\end{compactenum}
\end{proposition}
The threshold  is exactly the same as the threshold given in the context of -ary cuckoo hashing for
integral  \cite{FM_maximum_2009,FP_orientability_2010,DGMMPR_tight_2010}, and non-integral  \cite{DGMMPR_tight_2010}, where .

So in the case that  all near optimal sequences are hardly distinguishable in terms
of matching probability, at least asymptotically, but we will give strong evidence that there are only two sequences that
can be optimal, where the decision which one is the optimal one depends on the ratio .
\begin{conjecture}
\label{con:optimal}
Let  be an \emph{optimal sequence} for parameters  
in the situation of Theorem~\ref{theo:main}~ for  and constant  and 
. Let .
\begin{compactenum}[]
\item If  , then  for  nodes and  for  nodes 
(assuming that  is an integer).
\item If  , then  and   for all .
\end{compactenum}
\end{conjecture}
That is, if  is to the left of the threshold then it is optimal to fix the degrees of the left nodes, and
if  is to the right of the threshold then it is optimal to let each left node choose its degree at random
from  and , by identical, independent experiments.

\smallskip
\noindent\textbf{Overview of the paper}
The next section, which is also the main part, covers the proof of Theorem~\ref{theo:main}.
It is followed by a section devoted to the discussion of Conjecture~\ref{con:optimal}.
The proof of Proposition~\ref{prop:thresholds} is given in 
\ifnum\arxiv=1
Appendix~\ref{app:proposition}, since it is only using 
\else
the full version of this paper~\cite[Appendix B]{full_version}. It uses 
\fi
standard techniques on concentration bounds for nodes of certain degrees. 

\section{Optimality of Concentration in a Unit Length Interval}
In this section we prove Theorem~\ref{theo:main}.
We define the \emph{success probability} of a random graph as the probability that this graph has a matching.
Let  and  be fixed and consider some arbitrary but fixed sequence of probability mass functions .
We will show that if this sequence has certain properties then we can do a modification, obtaining a new sequence  
with the same average expected value , such that  has 
a strictly higher success probability than .
\begin{lemma}[{Variant of \cite[Proposition 4]{DGMMPR_tight_2010}}]
\label{lem:concentration_around_mean}
Let  be given.
Let  be arbitrary but fixed.
If in  two degrees with distance at least  have nonzero probability then  is not optimal.
\end{lemma}
The lemma was stated in \cite{DGMMPR_tight_2010} and proven in \cite{DGMMPR_tight_2009_full} for a slightly different graph model.
Its proof runs along the lines of \cite{DGMMPR_tight_2009_full}; it is 
\ifnum\arxiv=1
included in Appendix~\ref{app:lemma_concentration} for the convenience of the reader.
\else
given in~\cite[Appendix A]{full_version}.
\fi
After applying the first lemma repeatedly one sees that in an optimal sequence
each left node node has either a fixed degree (with probability 1) or two possible degrees with non-zero probability,
where these degrees differ by~1.
The lemma and~\cite{DGMMPR_tight_2009_full,DGMMPR_tight_2010} do not say anything about the relation between the degrees of different nodes.
This follows next.
\begin{lemma}
\label{lem:distance_at_most_2}
Let  be given, where for each  the only degrees with 
nonzero probability are from .
Let  be arbitrary but fixed.
If  and  have distance at least~, 
or  and  have distance at least~,
then  is not optimal.
\end{lemma}
Lemma~\ref{lem:distance_at_most_2} is proved in Section~\ref{sec:lemma_distance_at_most_2}.
Using Lemma~\ref{lem:distance_at_most_2} one concludes that an optimal sequence restricts the means , for each ,
to an open interval  for some integer constant . 
Hence all degrees that appear with non-zero probability must be from .
With the help of the next lemma one concludes that actually two values are enough.
\begin{lemma}
\label{lem:distance_2}
Let  be given, where for each  the only degrees with 
nonzero probability are from . 
Let  be arbitrary but fixed and assume that  and  are non-integral.
If  and  have distance  then  is not optimal.
\end{lemma}
Lemma~\ref{lem:distance_2} is proved in Section~\ref{sec:lemma_distance_2}.
Combining Lemmas~\ref{lem:concentration_around_mean},~\ref{lem:distance_at_most_2}, and \ref{lem:distance_2},
we obtain the following for an optimal sequence.
If  then it holds , for all ,
and all degrees that appear with non-zero probability must be from .
If  is an integer, then by definition of , we have  for all .
Hence Theorem~\ref{theo:main} follows.


So, to complete the proof of the theorem, it remains to show the three lemmas, which
is done in the following two sections for Lemmas~\ref{lem:distance_at_most_2} and \ref{lem:distance_2}, and 
in
\ifnum\arxiv=1
Appendix~\ref{app:lemma_concentration}
\else
\cite[Appendix A]{full_version}
\fi
for Lemma~\ref{lem:concentration_around_mean}.
We make use of the following definitions.

For each set  let  be the induced bipartite subgraph of  with
left node set  and right node set , particularly .
A matching in  is a matching that covers all left nodes (left-perfect matching).
We define  as the event that  has a matching.
\subsection{Average Degrees of Different Nodes are Close}
\label{sec:lemma_distance_at_most_2}
In this section we prove Lemma~\ref{lem:distance_at_most_2}.
Consider the probability mass functions  and  for the degrees  and  respectively.
By the hypothesis of the lemma,  and  are concentrated on two values each, i.e.,

with  and . By the assumption, we may arrange things so that  and
\begin{compactitem}
\item[] ,  as well as , ,
\item[or ] ,   as well as , .
\end{compactitem}\smallskip
We will show that changing  to 
and  to  such that  and , via

will strictly increase the probability that  has a matching, while it does not change . For this, will show

abusing condition notation a little to indicate changed probability spaces.
We fix the neighborhood  for the remaining elements  and therefore the graph .
Since there can be a matching for  only if there is a matching for  it is sufficient to show that

Let . Then \eqref{eq:failure_lemma_2}
holds if and only if
 
Note that if  then the summand regarding  and  on the left-hand side
is the same as the summand regarding  and  on the right-hand side.
Hence, to prove \eqref{eq:require_lemma_2} it is sufficient to show that

For this, consider the fixed graph . We classify the right nodes of  according to the following three types:
\begin{compactitem}
 \item We call  \emph{blocked}   if  is matched in all matchings of .
 \item We call  \emph{free}      if  is never matched in any matching of .
 \item We call  \emph{half-free} if  is neither a blocked nor a free node.
\end{compactitem}
Let  be the set of blocked nodes, let  be the set of free nodes, and let  be the set of half-free nodes.
Elements of  are called \emph{non-blocked} nodes.
For a moment consider only the non-blocked nodes. For each right node set 
let  be an auxiliary graph with node set  that
has an edge between two nodes  if and only if there exists a matching
for  in which  and  simultaneously are \emph{not} matched.
Let  be an arbitrary but fixed subset of . The following observation is crucial.
\begin{myClaim}
\label{claim:H_connected}
If  has any edges at all then it is connected.
\end{myClaim}
\begin{proof_claim}
First note that if there is a free node in  then  is connected by definition of the edge set of .
Therefore it remains to consider the case where all nodes of  are half-free nodes.
It is sufficient to show that if for three nodes  from  the edge 
is in  then one of the edges  or  must be present as well.
Assume for a contradiction  is an edge but  is neither adjacent to  nor to .
This implies that there are two matchings in ,  and  say,
such that in 
\begin{compactitem}
 \item node  is unmatched ( is a non-blocked node), but 
 \item nodes  and  are matched since edges  and  are not in ,
\end{compactitem}
and in  we have:
\begin{compactitem}
 \item node  is matched ( is a half-free node), but
 \item  and  are unmatched since edge  is in .
\end{compactitem}
Now consider the bipartite multigraph  consisting of all edges from both matchings and the corresponding nodes. The graph  has the following properties:
Nodes on the left side have degree 2 (both matchings are left-perfect). Nodes on the right side have degree 1 or 2, in particular, ,, have degree 1. Hence  has only paths and cycles of even length. On all paths and cycles edges from  and  alternate.
Nodes  and  must be at the ends of two distinct paths (since both are incident to -edges). Node  must be at the end of a path (incident to an -edge).

Without loss of generality, we may assume that  and  do not lie on the same path.
Starting from , we get a new matching in which neither  nor  are matched by
replacing the -edges on the path with  by the -edges on this path.
Therefore there must be an edge  in , which contradicts our assumption, proving the claim.
\end{proof_claim}

\noindent Now consider the set  of non-blocked nodes and the corresponding graph . 
We define  as the following binary relation: , for nodes  and , if
 is not an edge in .
\begin{myClaim}
The relation  (no edge) is an equivalence relation.
\end{myClaim}
\begin{proof_claim}
Clearly  is reflexive and symmetric. Assume for a contradiction  is not transitive.
That is, we have three nodes  and  with  and  but .
Let . Since , the edge  is in  and therefore in .
According to Claim \ref{claim:H_connected}  must be connected, i.e.,  and therefore  must contain  or .
Hence  or , which is a contradiction.
\end{proof_claim}

\noindent According to the claim it follows that the right node set  of  can be subdivided into
disjoint segments , where  is the set of blocked nodes and  are
the maximal independent sets in 
and the equivalence classes of , respectively.
For each pair , with , it holds that  is a complete bipartite graph.
Note that each free node leads to a one-element set .
With this characterization of  we can express the event that for 
a fixed neighborhood , , which admits a matching for
, there is no matching for  as follows

Let  be the event that 
has  many blocked nodes and  (nonempty) maximal independent sets according to the definition above,
with  and .
Let 

Then \eqref{eq:characterization_lemma_2} implies that

Using the law of total probability we can rewrite the value  (line below \eqref{eq:failure_lemma_2})
as follows:
-3ex]
                                                               \cdot&  \Pr(\evP_{S-\{y,z\}}(b,r,i_1,\ldots,i_r) \mid \evM_{S-\{y,z\}}) \blank.
\end{split}

\label{eq:fail_lemma_2}
  \fail(\high,\low)>\fail(\high-1,\low+1)\blank,

\label{eq:fail}
 \fail(\high,\low)=\bl^\high + \bl^\low - \bl^{\high+\low} + \sum_{j=1}^r \left[(\hf_j+\bl)^\high-\bl^\high \right] \cdot\left[(\hf_j+\bl)^\low-\bl^\low \right] \blank.

\label{eq:fail_left_and_right}
 \bl^\high + \bl^\low - \bl^{\high-1} - \bl^{\low+1}  >&\sum_{j=1}^r \left[(\hf_j+\bl)^{\high-1}-\bl^{\high-1} \right] \cdot\left[(\hf_j+\bl)^{\low+1}-\bl^{\low+1} \right] \notag\\
                                   &         - \left[(\hf_j+\bl)^\high-\bl^\high \right] \cdot\left[(\hf_j+\bl)^\low-\bl^\low \right]\notag\\
\Leftrightarrow \hspace{0.5cm}
(1-\bl)\cdot (\bl^\low -\bl^{\high-1})>& \sum_{j=1}^r \hf_j\cdot \underbrace{\left[\bl^\low \cdot(\hf_j+\bl)^{\high-1} -\bl^{\high-1}\cdot(\hf_j+\bl)^\low  \right]}_{\phi(\low,\high,\hf_j,\bl)} \blank.

 \frac{\partial\phi(\low,\high,\hf_j,\bl)}{\partial \hf_j}=&(\high-1)\cdot \bl^\low \cdot(\hf_j+\bl)^{\high-2}-\low\cdot \bl^{\high-1}\cdot(\hf_j+\bl)^{\low-1} \overset{!}{>}0\\
\Leftrightarrow  \ & \frac{\high-1}{\low} \cdot (\hf_j+\bl)^{\high-\low-1} > \bl^{\high-\low-1} \blank,

\pmf_y(\low)  =p, \ \pmf_y(\low+1)=1-p && \pmf_z(\low-1)=q, \ \pmf_z(\low)  =1-q \blank,

\pmf'_y(\low)=p+\eps, \ \pmf'_y(\low+1) =1-p-\eps && \pmf'_z(\low-1)=q-\eps, \ \pmf'_z(\low)=1-q+\eps \blank,

\Pr\left( \evNM_S \mid \pmf_y,\pmf_z \right) > \Pr\left( \evNM_S \mid \pmf'_y, \pmf'_z\right) \blank.

   \sum_{\substack{\degr_y\in\{\low,\low+1\}\\\degr_z\in\{\low-1,\low\}}} \Fail(\degr_y,\degr_z) \cdot \rho_y(\degr_y)\cdot\rho_z(\degr_z) 
 &> \sum_{\substack{\degr_y\in\{\low,\low+1\}\\\degr_z\in\{\low-1,\low\}}} \Fail(\degr_y,\degr_z) \cdot \rho'_y(\degr_y)\cdot\rho'_z(\degr_z) \blank. 

\label{eq:failure_lemma_3_eps}
 &&\left[ -\eps^2-\eps\cdot(p-q)\right]\cdot & \underbrace{\left[\Fail(\low,\low-1)+\Fail(\low+1,\low)-\Fail(\low,\low)-\Fail(\low+1,\low-1) \right]}_{K_0}\notag\\
 &&-\eps \cdot &\underbrace{\left[ \Fail(\low+1,\low-1)-\Fail(\low,\low)\right]}_{K_1}<0\notag\\
&&\Leftrightarrow \hspace{0.5cm}-\eps^2\cdot K_0 -\eps\cdot& \underbrace{\left[ (p-q)\cdot K_0+K_1\right]}_L\hspace{1.45cm}<0 \blank.

 \Fail(\low+1,\low)+\Fail(\low,\low-1)>2\cdot \Fail(\low,\low) \blank.

 \fail(\low+1,\low)+\fail(\low,\low-1)>2\cdot \fail(\low,\low) \blank.

(1-\bl)^2\cdot \left[ \bl^{\low-1}-\bl^{2\low-1} \right] >  &\sum_{j=1}^r (1-\bl)^2       \cdot \left[ (\hf_j+\bl)^\low\cdot \bl^{\low-1}-\bl^{2\low-1}\right] \\
                                                    - &\sum_{j=1}^r[1-(\hf_j+\bl)]^2 \cdot \left[ (\hf_j+\bl)^{2\low-1}           -(\hf_j+\bl)^{\low-1}\cdot \bl^\low\right] .

\label{eq:failure_lemma_3_x_y}
(1-\bl)^2\cdot \left[ \bl^{\low-1}-\bl^{2\low-1} \right] >    (1-\bl)^2 \cdot\sum_{j=1}^r  (\hf_j+\bl)^\low\cdot \bl^{\low-1} -r\cdot(1-\bl)^2\cdot \bl^{2\low-1} \blank.

 \sum_{j=1}^r (\hf_j+\bl)^{\low} &= \sum_{j=1}^r \sum_{i=0}^\low \binom{\low}{i}\cdot \hf_j^i \cdot \bl^{\low-i} = r\cdot \bl^\low +  \sum_{i=1}^\low \binom{\low}{i} \cdot \bl^{\low-i}\cdot \sum_{j=1}^r \hf_j^i \\
&< r\cdot \bl^\low +  \sum_{i=1}^\low \binom{\low}{i}\cdot  \bl^{\low-i}\cdot \Bigg[ \sum_{j=1}^r \hf_j\Bigg]^i 
=(r-1)\cdot \bl^\low +1 \blank,

\pmf_y(\low)=p, \ \pmf_y(\low+1)=1-p && \pmf_z(\low)=q, \ \pmf_z(\low+1)=1-q \blank,

\pmf'_y(\low)=p+\eps, \ \pmf'_y(\low+1)=1-p-\eps && \pmf'_z(\low)=q-\eps, \ \pmf'_z(\low+1)=1-q+\eps \blank,

   \sum_{\degr_y,\degr_z\in\{\low,\low+1\}} \mgap\Fail(\degr_y,\degr_z) \cdot \rho_y(\degr_y)\cdot\rho_z(\degr_z) 
 &>\mgap \sum_{\degr_y,\degr_z\in\{\low,\low+1\}}\mgap \Fail(\degr_y,\degr_z) \cdot \rho'_y(\degr_y)\cdot\rho'_z(\degr_z) \blank.

\label{eq:K}
 [-\eps^2 -\eps\cdot(p-q)]\cdot \underbrace{[ \Fail(\low,\low) -2\cdot \Fail(\low,\low+1) + \Fail(\low+1,\low+1) ]}_K < 0 \blank,

\label{eq:FAIL_last}
 \Fail(\low,\low)+\Fail(\low+1,\low+1)> 2\cdot \Fail(\low,\low+1) \blank.

\label{eq:fail_last}
\fail(\low,\low)+\fail(\low+1,\low+1)> 2\cdot \fail(\low,\low+1) \blank.

   \ 2 \cdot \bl^\low     - \bl^{2\low}   + \sum_{j=1}^r [(\hf_j+\bl)^\low    -\bl^\low]^2
 +2 \cdot \bl^{\low+1} - \bl^{2\low+2} + \sum_{j=1}^r [(\hf_j+\bl)^{\low+1}-\bl^{\low+1}]^2 \\
> \hspace{0.5cm} 2 \cdot \bl^\low + 2\cdot \bl^{\low+1} - 2\cdot \bl^{2\low+1} + 2\cdot\sum_{j=1}^r [(\hf_j+\bl)^{\low}-\bl^{\low}]\cdot [(\hf_j+\bl)^{\low+1}-\bl^{\low+1}] \blank,

 \sum_{j=1}^r \left[ (\hf_j+\bl)^{\low}\cdot (1-\hf_j-\bl) - \bl^\low\cdot(1-\bl)\right]^2 >  \bl^{2\low}\cdot(1-\bl)^2 \blank.

\pmf'_z(\low)  &=\pmf_z(\low)-\eps     &\pmf'_z(\high)&=\pmf_z(\high)-\eps \\
\pmf'_z(\low+1)&=\pmf_z(\low+1)+\eps   &\pmf'_z(\high-1)&=\pmf_z(\high-1)+\eps \blank,

\Pr\left( \evNM_S \mid \pmf_z \right) > \Pr\left( \evNM_S \mid \pmf'_z\right) \blank,

\label{eq:failure_lemma_1}
 \Pr\left( \evNM_S \mid \evM_{S-\{z\}}, \pmf_z \right) > \Pr\left( \evNM_S \mid \evM_{S-\{z\}}, \pmf'_z\right) \blank.

   &\sum_{b=0}^{\keys-1}\Pr\left( \evNM_S \mid \evM_{S-\{z\}}, \pmf_z,  \abs{B}=b \right)\cdot \Pr\left(\abs{B}=b \mid \evM_{S-\{z\}}, \pmf_z \right)\\
 > &\sum_{b=0}^{\keys-1}\Pr\left( \evNM_S \mid \evM_{S-\{z\}}, \pmf'_z, \abs{B}=b \right)\cdot \Pr\left(\abs{B}=b \mid \evM_{S-\{z\}}, \pmf'_z \right)\blank.

  &\sum_{b=0}^{\keys-1}\left[\sum_{d=1}^\cells \pmf_z(d)\cdot \bfrac{b}{\cells}^d \right] \cdot \Pr\left(\abs{B}=b \mid \evM_{S-\{z\}}, \pmf_z \right)\\
> &\sum_{b=0}^{\keys-1}\left[\sum_{d=1}^\cells \pmf'_z(d)\cdot \bfrac{b}{\cells}^d\right]\cdot \Pr\left(\abs{B}=b \mid \evM_{S-\{z\}}, \pmf'_z \right) \blank.

 & &\sum_{d=1}^\cells \pmf_z(d)\cdot \bfrac{b}{\cells}^d 
&> \sum_{d=1}^\cells \pmf'_z(d)\cdot \bfrac{b}{\cells}^d\\
\Leftrightarrow & &
\eps \cdot \bfrac{b}{\cells}^\low+\eps \cdot \bfrac{b}{\cells}^\high &> \eps \cdot \bfrac{b}{\cells}^{\low+1}+\eps \cdot \bfrac{b}{\cells}^{\high-1 }\\
\Leftrightarrow& &
\bfrac{b}{\cells}^{\low}\cdot\left(1-\frac{b}{\cells}\right)  &> \bfrac{b}{\cells}^{\high-1}\cdot\left(1-\frac{b}{\cells}\right) \blank, 

\label{eq:expected_degree}
 \E(Y^\low_x)
&=\pmf_x(\low)\cdot \frac{\binom{\cells}{\low}\cdot \low!}{ \cells^\low }
 +( 1-\pmf_x(\low))\cdot \frac{\binom{\cells}{\low}\cdot \low! \cdot \binom{\low+1}{2}}{\cells^{\low+1}} \text{, and} \\
 \E(Y^{\low+1}_x)&=( 1-\pmf_x(\low))\cdot \frac{\binom{\cells}{\low+1}\cdot (\low+1)!}{ \cells^{\low+1} }\notag \blank.

p_x=\E(Y_x)=\pmf_x(\low) \cdot \big( 1-\Theta(1/\cells) \big) + \Theta(1/\cells) \blank,

\E(X_{i+1} \mid X_0,\ldots,X_i)= \E(X_{i}+Z_{x_{i+1}} \mid X_0,\ldots,X_i)=X_i 

 \Pr\left( \abs{X_n-X_0}\geq n^\gamma \right)=\Pr\left( \abs{ Y - \E(Y)}\geq n^\gamma \right)\leq 2\cdot e^{{-2\cdot n^{2\cdot \gamma}}/{n}} \blank.

 \E(Y)=\sum_{x \in S}p_x= \big(1-\Theta(1/m) \big) \cdot \sum_{x\in S}\pmf_x(\low) + \Theta(1) \blank,

\begin{split}
\Pr\big( \evM[ &\graph   \big( \Amean,         ({\pmf}_x)_{x\in S} \big)] \big) \\
 &=\Pr\left( \evM[ \graph   \big( \Amean,         ({\pmf}_x)_{x\in S} \big)] \mid \evA \cup \evB \right) \cdot \Big(1-O\big(e^{-\keys^{2\delta-1}}\big)\Big)+O\big(e^{-\keys^{2\delta-1}}\big) \blank.
\end{split}

\pmf_y(\low)&=p  & \pmf_y(\low+1)=&1-p\\
\pmf_z(\low)&=q  & \pmf_z(\low+1)=&1-q \blank,

\pmf'_y(\low)=&p+\eps & \pmf'_y(\low+1)=&1-p-\eps\\
\pmf'_z(\low)=&q-\eps & \pmf'_z(\low+1)=&1-q+\eps \blank,

   \sum_{\degr_y,\degr_z\in\{\low,\low+1\}} \mgap \Fail(\degr_y,\degr_z) \cdot \rho_y(\degr_y)\cdot\rho_z(\degr_z) 
 &>\mgap\sum_{\degr_y,\degr_z\in\{\low,\low+1\}} \mgap\Fail(\degr_y,\degr_z) \cdot \rho'_y(\degr_y)\cdot\rho'_z(\degr_z) \blank.

 [-\eps^2 -\eps\cdot(p-q)]\cdot \underbrace{[ \Fail(\low,\low) -2\cdot \Fail(\low,\low+1) + \Fail(\low+1,\low+1) ]}_K < 0 \blank,

 \Fail(\low,\low)+\Fail(\low+1,\low+1)> 2\cdot \Fail(\low,\low+1) \blank,

\fail(\low,\low)+\fail(\low+1,\low+1)> 2\cdot \fail(\low,\low+1) \blank.

 \sum_{j=1}^r \left[ (\hf_j+\bl)^{\low}\cdot (1-\hf_j-y) - \bl^\low\cdot(1-\bl)\right]^2 >  \bl^{2\low}\cdot(1-\bl)^2 \blank,

 \sum_{j=1}^r \left[ \left(1+\frac{\hf_j}{\bl}\right)^{\low}\cdot \left(1-\frac{\hf_j}{1-\bl}\right) - 1\right]^2 >  1 \blank.

  \left[\cells-(\low+1)\cdot \cells^\delta \right]\cdot \Bigg[ \underbrace{\left(1+\frac{1}{b}\right)^{\low}\cdot \left(1-\frac{1}{m-b}\right)}_{f(\low)} - 1\Bigg]^2 >  1 \blank.

  \left[\cells-(\low+1)\cdot \cells^\delta \right]\cdot \underbrace{\Bigg[ \frac{\cells-2\cdot b-1}{b\cdot(m-b)}\Bigg]^2}_{g(b)} >  1 \blank.

Since  and  the inequality holds.
\fi
\end{document}
