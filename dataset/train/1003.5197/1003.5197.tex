\documentclass{LMCS}


\usepackage{enumerate}
\usepackage{hyperref}
\usepackage{natbib}
\usepackage{pdflscape} \let\cite=\citep


\usepackage[leqno]{amsmath}
\usepackage{amssymb}
\usepackage{amsthm}
\usepackage{braket}
\usepackage{bbold}
\usepackage{semantic}
\usepackage{mathpartir}
\usepackage{stmaryrd}
\usepackage{mathbbol} 


\newcommand{\comment}[2]{[{\sc #1:} \textsf{#2}]}
\newcommand{\ron}[1]{\comment{RG}{#1}}

\newcommand{\union}[0]{\ensuremath{\cup}}
\newcommand{\N}[0]{\ensuremath{\mathbb{N}}}



\newcommand{\terminal}[1]{\langle\text{#1}\rangle}
\newcommand{\desc}[1]{\ensuremath{\text{(#1)}}}
\newcommand{\metavar}[1]{\ensuremath{\mathit{#1}}}
\newcommand{\seq}[1]{\ensuremath{\overline{#1}}}
\newcommand{\mseq}[1]{\seq{\metavar{#1}}}
\newcommand{\produce}{\ensuremath{::=}}
\newcommand{\hole}{\square}
\newcommand{\compose}[2]{\ensuremath{#1 \circ #2}}
\newcommand{\fresh}[1]{\widetilde{#1}}
\newcommand{\fresht}[1]{(\widetilde{#1})|[X|]}
\newcommand{\freshr}[2]{(\widetilde{#1})|[#2|]}
\newcommand{\newfresh}[1]{\ensuremath{\mathcal{F}(#1)}}
\newcommand{\qsubst}[3]{\ensuremath{#1[#2/#3]}}
\newcommand{\subst}[3]{\ensuremath{\left.#1\right\rvert^{#2}_{#3}}}
\newcommand{\fsubst}[3]{\ensuremath{#1\rvert^{#2}_{#3}}}
\newenvironment{syntaxcategory}[1]
  {\begin{array}{lcll} \multicolumn{4}{l}{\mbox{\textbf{#1}}}\\}
  {\end{array}}

\newenvironment{tsyntaxcategory}[1]
  {\begin{array}[t]{lcll} \multicolumn{4}{l}{\mbox{\textbf{#1}}}\\}
  {\end{array}}

\newenvironment{transitionrule}
  {\begin{array}{rcll}}
  {\end{array}}

\newenvironment{ltransitionrule}
  {\begin{array}{lrcll}}
  {\end{array}}

\newenvironment{btransitionrule}
  {}

\newenvironment{equationaldef}[2]
  {\begin{array}{lcll}
    \multicolumn{4}{l}{\vspace{1ex}\boxed{#1}\quad\text{#2}}\\}
  {\end{array}}


\newsavebox{\saveboxedarray}
\newenvironment{boxedarray}[1]
  {\begin{lrbox}{\saveboxedarray}\end{lrbox}\fbox{\usebox{\saveboxedarray}}}

\newenvironment{inferbox}[0]
  {\begin{minipage}{\textwidth}\begin{mathpar}}
  {\end{mathpar}\end{minipage}}

\newenvironment{inferbox*}[0]
  {\begin{minipage}{\columnwidth}\begin{mathpar}}
  {\end{mathpar}\end{minipage}}



\newcommand{\etot}[0]{\mathcal{T}}
\newcommand{\ctom}[0]{\mathcal{M}}
\newcommand{\mtoc}[0]{\mathcal{C}}
\newcommand{\plug}[0]{\mathcal{U}}
\newcommand{\load}[0]{\mathcal{L}}
\newcommand{\unload}[0]{\mathcal{U}}
\newcommand{\ukont}[0]{\mathcal{K}}

\theoremstyle{plain}
\newtheorem{definition}{Definition}
\newtheorem{theorem}{Theorem}
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{corollary}[theorem]{Corollary}
\newtheorem{proposition}{Proposition}



\theoremstyle{remark}
 \newtheorem*{case}{Case}






\newenvironment{ronnote}{\begin{note}{{\sc NOTE TO SELF:\\}}}{\end{note}}



\mathlig{[]}{\hole}
\mathlig{[}{\lbrack}
\mathlig{]}{\rbrack}
\mathlig{|}{\mid}

\mathlig{++}{\texttt{+\kern-0.03em+}}

\newcommand{\aEq}[1]{\ensuremath{\stackrel{\mathrm{#1}}{=}}}


\newcommand{\mapsTo}[0]{\mbox{\ensuremath{\makebox[0pt][l]{\hspace{7pt}}\longmapsto}}}

\newcommand{\nam}[0]{\ensuremath{\longmapsto_{nam}}}
\newcommand{\Nam}[0]{\ensuremath{\mapsTo_{nam}}}
\newcommand{\aNam}[1]{\ensuremath{\stackrel{\mathrm{#1}}{\Nam}}}

\newcommand{\sr}[0]{\ensuremath{\longmapsto_{sr}}}
\newcommand{\Sr}[0]{\ensuremath{\mapsTo_{sr}}}
\newcommand{\aSr}[1]{\ensuremath{\stackrel{\mathrm{#1}}{\Sr}}}

\renewcommand{\comp}[0]{\ensuremath{\circ}} 

\newcommand{\kont}[1]{\!\Braket{#1}}
\newcommand{\answer}[1]{\llfloor#1\rrfloor}
\newcommand{\refocus}[1]{\Braket{#1}_f}
\newcommand{\rebuild}[1]{\Braket{#1}_b}
\newcommand{\reduce}[1]{\Braket{#1}_d}
\newcommand{\need}[1]{\Braket{#1}_n}

\newcommand{\notion}[0]{\ensuremath{\rightarrow_{\mathrm{need}}}}

\reservestyle{\command}{\textsl}
\reservestyle{\bfcommand}{\textbf}
\bfcommand{wf[\;wf],ok[\;ok]}


 
\command{runCC[runCC\;],pushPrompt[pushPrompt\;],withSubCont[withSubCont\;],pushSubCont[pushSubCont\;],newPrompt[newPrompt],let[let\;],in[\;in\;],if[if\;],then[then\;],else[else\;]}

\newcommand{\mysf}[1]{\textsf{\small #1}}

\reservestyle{\term}{\mysf}

\term{letrec[letrec\;],be[\;be\;],lin[\;in\;]}



\newcommand{\topic}[1]{}

\newcommand{\lambdaneed}[0]{\ensuremath{\lambda_{\text{need}}}}
\newcommand{\consa}[1]{\ensuremath{\braket{#1,\cdot}}}
\newcommand{\consd}[2]{\ensuremath{\braket{#1,#2}}}
\newcommand{\flatten}[1]{\ensuremath{\mathcal{F}(#1)}}

\newcommand{\PP}[2]{\ensuremath{P^{#1}_{#2}}}
\newcommand{\LF}[0]{\<letrec>}
\renewcommand{\LF}[0]{\ensuremath{\mathsf{LR}\;}}


\def\doi{6 (3:1) 2010}
\lmcsheading {\doi}
{1--37}
{}
{}
{Oct.~12, 2009}
{Jul.~11, 2010}
{}   




\begin{document}



\title{Lazy Evaluation and Delimited Control}

\author[R.~Garcia]{Ronald Garcia\rsuper a}
\address{{\lsuper a}Carnegie Mellon University}
\email{rxg@cs.cmu.edu}
\thanks{{\lsuper a}This work was supported by the National Science Foundation under
  Grant \#0937060 to the Computing Research Association for the CIFellows
  Project.}

\author[A.~Lumsdaine]{Andrew Lumsdaine\rsuper b} 
\address{{\lsuper{b,c}}Indiana University}
\email{\{lums,sabry\}@cs.indiana.edu}
\thanks{{\lsuper{b,c}}This work was supported by NSF awards CSR/EHS 0720857 and CCF 0702717}
\author[A.~Sabry]{Amr Sabry\rsuper c} 
\address{\vskip-6 pt}


\keywords{call-by-need, reduction semantics, abstract machines,
delimited continuations, lambda calculus}
\subjclass{D.3.1}




\begin{abstract}

  The call-by-need lambda calculus provides an equational framework for
  reasoning syntactically about lazy evaluation.  This paper
  examines its operational characteristics.

  By a series of reasoning steps, we systematically unpack the standard-order
  reduction relation of the calculus and discover a novel abstract machine
  definition which, like the calculus, goes ``under lambdas.''  We prove that
  machine evaluation is equivalent to standard-order evaluation.

  Unlike traditional abstract machines, delimited control plays a significant
  role in the machine's behavior.  In particular, the machine replaces the
  manipulation of a heap using store-based effects with disciplined management
  of the evaluation stack using control-based effects.  In short, state is
  replaced with control.

  To further articulate this observation, we present a simulation of
  call-by-need in a call-by-value language using delimited control operations.
\end{abstract}




\maketitle





\section{Introduction}
\label{sec:intro}


\topic{Laziness and Control}
From early on, the connections between lazy
evaluation~\cite{friedman76cons,henderson76lazy} and control operations seemed
strong. One of these seminal papers on lazy evaluation~\cite{henderson76lazy}
advocates laziness for its coroutine-like behavior. Specifically, it motivates
lazy evaluation with a solution to the \emph{same fringe} problem: how to
determine if two trees share the same fringe without first flattening each tree
and then comparing the resulting lists.  A successful solution to the problem
traverses just enough of the two trees to tell that they do not match.  The
same fringe problem is also addressed in Sussman and Steele's original
exposition of the Scheme programming language~\cite{sussman98scheme}. One of
their solutions uses a continuation passing-style representation of coroutines.
More recently, \citet{Biernacki20057} explores a number of continuation-based
solutions to same fringe variants.

Same fringe is not the only programming problem that can be solved using either
lazy evaluation or continuations.  For instance, lazy streams and continuations
are also used to implement and reason about
backtracking~\cite{wand04backtracking,kiselyov05backtracking}.  Strong
parallels in the literature have long suggested that lazy evaluation elegantly
embodies a stylized use of coroutines. Indeed, we formalize this connection.



\topic{Reasoning about Call-by-need}
Call-by-need evaluation combines the equational reasoning capabilities of
call-by-name with a more efficient implementation technology that
systematically shares the results of some computations.  However,
call-by-need's evaluation strategy makes it difficult to reason about the
operational behavior and space usage of programs.  In particular, call-by-need
evaluation obscures the control flow of evaluation.  To facilitate reasoning,
semantic
models~\cite{launchbury93natural,sestoft97machine,friedman07krivine,nakata10need},
simulations~\cite{OKASAKI94}, and tracing tools~\cite{gibbons96tracing} for
call-by-need evaluation have been developed.
Many of these artifacts use an explicit store or store-based
side-effects~\cite{wang90lazy} to represent values that are shared between
parts of a program.  Stores, being amorphous structures, make it difficult to
establish program properties or analyze program execution.  This representation
of program execution loses information about the control structure of
evaluation. 
 
The call-by-need lambda calculus was introduced by~\citet{ariola95need} as an
alternative to store-based formalizations of lazy evaluation.  It is an
equational framework for reasoning about call-by-need programs and languages.
Following~\citet{plotkin75byname}, these authors present a calculus and prove a
standardization theorem that links the calculus to a complete and deterministic
(i.e. standard order) reduction strategy.  The calculus can be used to formally
justify transformations, particularly compiler optimizations, because any terms
it proves equal are also contextually equivalent under call-by-need evaluation.

Call-by-need calculi were investigated by two
groups~\cite{maraist98need,ariola97need}.  The resulting two calculi are quite
similar but their subtle differences yield trade-offs that are discussed in the
respective papers.  Nonetheless, both papers connect their calculi to similar
standard-order reduction relations.

One notable feature of Ariola and Felleisen's calculus (and both standard-order
reduction relations) is the use of evaluation contexts within the notions of
reduction.  It has been observed that evaluation contexts correspond to
continuations in some presentations of language
semantics~\cite{felleisen86secd,biernacka07framework}.  However, in these
systems evaluation contexts are used to model variable references and
demand-driven evaluation, not first-class continuations.

This paper exposes how Ariola et al.'s call-by-need evaluation relates
to continuations.  By systematically unpacking the standard-order reduction
relation of the calculus, we discover a novel abstract machine that models
call-by-need style laziness and sharing without using a store.  Instead, the
machine manipulates its evaluation context in a manner that corresponds to a
stylized use of delimited control operations.  The machine's behavior reveals a
connection between control operations and laziness that was present but hidden
in the reduction semantics.

To directly interpret this connection in the terminology of delimited control,
we construct a simulation of call-by-need terms in the call-by-value language
of~\citet{dybvig07monadic}, which provides a general framework for delimited
continuations with first-class generative prompts. 




Our concrete specifications of the relationship between call-by-need and
delimited control firmly establish how lazy evaluation relates to continuations
and other control-oriented language constructs and effects.
Implementations of both the machine and the simulation are available at the
following url: \\
\verb|http://osl.iu.edu/~garcia/call-by-need.tgz|.


\section{The Call-by-need Lambda Calculus}

The remainder of this paper examines Ariola and Felleisen's formalization of
call-by-need~\cite{ariola97need}.  The terms of the calculus are standard:

The call-by-need calculus, in direct correspondence with the call-by-value and
call-by-name lambda calculi, distinguishes lambda abstractions as values:

Call-by-need is characterized by two fundamental properties: a computation is
only performed when its value is needed, and the result of any computation is
remembered and shared so that it only needs to be computed once.  This calculus
distinguishes two additional subsets of the term language to help represent
these properties.

To capture the notion of \emph{necessary} computations, the calculus
distinguishes the set of lambda abstractions that immediately need the value
of their argument.  To define this set, the calculus appeals to a notion of
evaluation contexts, a set of terms that each have a single hole () in
them:

Given the evaluation contexts, the set of lambda abstractions in question is
defined syntactically as , the set of lambda
abstractions whose bodies can be decomposed into an evaluation context and a
free instance of the abstracted variable.

The intuition for this definition is as follows.  Evaluation contexts are
essentially terms with a single \emph{hole} in them.  When used in the style
of~\citet{felleisen92revised}, evaluation contexts indicate those locations in
a program that are subject to evaluation. As such, a lambda abstractions of the
form  will immediately refer to the value of its argument
when its body is evaluated.  Here,  is not a language construct, but
rather metalinguistic notation for a side condition on the term in the body of
the lambda abstraction.

The syntactic structure of call-by-need evaluation contexts give some hint to
the nature of computation captured by this calculus.  First, the context
production  indicates that evaluation can focus on the operator position
of an application regardless of the structure of the operand.  This property is
also true of call-by-name and call-by-value and reflected in their respective
evaluation contexts.  Second, the  production indicates
the operand of an application expression can be evaluated only if the operator
is a lambda abstraction that immediately needs its argument.  This restriction
does not hold for call-by-value\footnote{assuming left-to-right evaluation of
  application expressions}, where any lambda abstraction in operator position
justifies evaluating the operand.  This restriction on evaluation corresponds
with our intuitive understanding of call-by-need.  Third, the  production indicates that evaluation can proceed \emph{under a lambda
  abstraction} when it is in operator position.  Though not immediately
obvious, this trait is used by the calculus to capture the process of sharing
computations among subterms.

To capture the notion of \emph{shared} computations, the call-by-need calculus 
distinguishes lambda abstractions with explicit bindings for some variables,
calling them \emph{answers}:

Answers are a syntactic representation of (partial) closures.  An answer takes
the form of a lambda term nested inside some applications.  The surrounding
applications simulate environment bindings for free variables in the nested
lambda term.
This representation makes it possible for the calculus to explicitly account
for variable binding and to syntactically model how call-by-need
evaluation shares lazily computed values.


The calculus has three notions of reduction:

The first reduction rule substitutes a value for a single variable instance in
an abstraction. The rule retains the binding and abstraction so as to share its
computation with other variable references as needed. The second and third
reduction rules commute an application with an answer binding to expose
opportunities for reduction without duplicating not-yet-needed computations.
These two rules help to ensure that computations will be shared among
references to a common variable.

As popularized by~\citet{barendregt}, each reduction assumes a hygiene
convention.  When combined with the evaluation contexts, the notions of
reduction yield a deterministic standard order reduction relation () and
its reflexive-transitive closure ().
\begin{defi}
  \label{def:sr}
   if and only if ,  
  and .
\end{defi}
Terms of the calculus satisfy unique decomposition, meaning that any
program (i.e. closed term) that is not an answer can be decomposed exactly one
way into a context  and redex . This property ensures that
 is deterministic.
Standard order reduction is an effective specification of call-by-need
evaluation: if  is a program (i.e. closed term), then  call-by-need
evaluates to an answer if and only if  for some answer .



\section{From Reduction Semantics to Machine Semantics}
\label{sec:reduction}

\topic{The point: Reduction Semantics don't immediately point to a
  tail-recursive implementation}

Some reduction semantics have been shown to correspond directly to abstract
machine semantics, thereby establishing the equivalence of a reducer and a
tail-recursive abstract machine
implementation~\cite{felleisen86secd,findler09redex}.  In particular,
\citet{danvyTRrefocusing} introduces a method and outlines criteria for
mechanically transforming reduction semantics into abstract machine semantics.
However, proceeding directly from the reduction semantics for call-by-need to a
tail-recursive abstract machine semantics poses some challenges that do not
arise with other reduction semantics like call-by-name and call-by-value.

A straightforward call-by-need reducer implementation na\"ively decomposes a
term into a context and a redex.  Any application could be one of three
different redexes, each of which is nontrivial to detect, so whenever the
decompose function detects an application, it sequentially applies several
recursive predicates to the term in hopes of detecting a redex.  If the term is
a redex, it returns; if not, it recursively decomposes the operator position.


Call-by-need redexes require more computational effort to
recognize than either call-by-name or call-by-value.  For instance, given a
term , only a fixed number of terminal operations are required to detect
whether  is a call-by-name redex: one to check if the term is an
application, one to access the operator position, and one to check if the
operator is an abstraction.

Contrast this with the call-by-need redex .  Given a call-by-need term , testing whether it matches this
redex form requires an unknown number of operations: check if~ is an
application; check if its operator position is a lambda abstraction; check, in
an unknown number of steps, if the operator's body can be decomposed into
, where  is both free in  and bound by the operator; and finally
check, in an unknown number of steps, if the operand has the inductive
structure of an answer.

To make matters worse, some terms can be decomposed into the form  in more
than one way.  For instance, consider the term .
It can be decomposed as both  and 
where  and . As such,
a recursive procedure for decomposing a term cannot stop at the first variable
it finds: it must be able to backtrack in a way that guarantees it will find
the right decomposition ---and in turn the right redex---if there is one.


Recall that one of the evaluation contexts has the form 
.  This means that redex evaluation can occur ``under
binders''~\cite{sabry04recursion,kameyama08closing}.
All three call-by-need notions of reduction shuffle lambda abstractions about
in unusual ways.  Furthermore, while reducing a recursive routine, a
call-by-need evaluator may end up performing reductions under multiple copies
of the same lambda abstraction.  Call-by-name and call-by-value evaluators can
address hygiene concerns by using environments and closures, but a call-by-need
evaluator must prevent its evaluation context from incorrectly capturing free
variable references.  Any evaluator that goes under lambdas must pay
particular attention to hygiene~\cite{xi97underlambda}.

Since this work was originally published, \citet{danvy10need} have adapted and
extended the method of \citet{danvyTRrefocusing} to produce a related
abstract machine for call-by-need.




\subsection{Towards an Abstract Machine}


To find call-by-need redexes tail-recursively, we apply an insight from
the CK abstract machine~\cite{felleisen86secd,findler09redex}.
The CK machine implements an evaluation strategy for call-by-value based on a
reduction semantics using the (inside-out) evaluation contexts 
and .  To find a redex, the machine iteratively
examines the outermost constructor of a term and uses the evaluation context to
remember what has been discovered.  Since call-by-value satisfies unique
decomposition, this approach will find the standard redex if there is one.

To illustrate this in action, we walk through an example.  Consider the program
.  Evaluation begins with configuration
.  Underlining
indicates subterms that the machine knows nothing about;  at the beginning of
evaluation, it knows nothing about the entire term.  On
the first step of the reduction, the machine detects that the term is an
application . 
To examine the term further, the machine must move its focus to either the
operator or operand of this application. Since the machine is tail recursive,
it must also push an evaluation context to store the as-yet uncovered structure
of the term.  The only context it can reliably push at this point is
: it cannot push
 because it has not yet discovered that the
operator position is a value.  So the machine pushes the
 context, which serves as a reminder that it is
focused on the operator of an application.

On the second step of the reduction, the machine detects that the operator is
an abstraction , and observes that the innermost
context is .  In response, the machine pops the
context, focuses on , and pushes the context
, since the operator is now known to be a
value.  This context serves as a reminder that evaluation is currently
focused on the operand of an application that can be reduced once that operand
becomes a value.

On the third step, the machine detects the abstraction 
, and remembers that the innermost context is
.  At this point, the machine has deduced
enough information to recognize the redex
.
This example illustrates how the CK machine uses a depth-first left-to-right
search strategy to detect call-by-value redexes.

Now consider the same term under call-by-need using a similar strategy. As with
call-by-value, the top-level application can be detected, the operand can be
pushed onto the evaluation context, and the operator can be exposed as the
abstraction .  At this point behavior must diverge
from call-by-value because the body of the abstraction is still unknown and
call-by-need does not have
 contexts for arbitrary .  However, call-by-need does
have contexts of the form
.
Therefore, it is possible to proceed under the first lambda abstraction, push
the context, and focus on .

The term is exposed as a variable , which combines with the
context  to form the term 
 (where~).  At this
point, enough information has been uncovered to push the context  and focus on .  The abstraction  is recognized, and with that a call-by-need redex
 has been found.
Success with this example suggests a promising strategy for implementing
call-by-need reduction tail-recursively.  




\subsection{An Initial Abstract Machine}
\label{sec:informal}
In this section, we elaborate the above search strategy into a simple but
inefficient tail-recursive abstract machine.  We present it without proof and
then by a series of correct transformations we derive an efficient machine that
we prove correct.




This abstract machine uses the same terms, values, and answers as the
calculus. However, it introduces two alternate notions.  First, the machine
uses a more versatile representation of evaluation contexts.  As observed
in~\citet{danvyTRrefocusing}, evaluation contexts can be mathematically
specified in more than one way. For optimal flexibility, we define evaluation
contexts as lists of frames, where the empty list  and single-frame lists
 are our simple units, and the operator  stands for list
concatenation.
0.5ex]
E & ::= & [\;] | [f] \comp E | E \comp [f] \0.5ex]
& &\text{and } E_1 \comp (E_2\comp E_3) = (E_1\comp E_2)\comp E_3\\
\end{boxedarray}  

\begin{boxedarray}{lcl}
 r & \produce & a\;t | (\kappa x.E)\;a 
\end{boxedarray}  

  \begin{boxedarray}{@{}l@{}}
     \vspace{1ex}
    \boxed{\refocus{E,t}}\quad\desc{Refocus} \\
    \begin{array}{rcl}
      \refocus{E, x}
      & \mapsto &
      \need{E,[\;],x} \0.5ex]

      \refocus{E, t_1\;t_2}
      & \mapsto &
      \refocus{E \comp [[]\;t_2], t_1} 
    \end{array}
\end{boxedarray}  

  \begin{boxedarray}{@{}l@{}}
     \vspace{1ex}
    \boxed{\rebuild{E,a}}\quad\desc{Rebuild} \\
    \begin{array}{rcl}
      \rebuild{[\;],a} & \mapsto & a \0.5ex]
      
      \rebuild{E \comp [(\lambda x.[])\; t_1], a} & \mapsto &
      \rebuild{E, (\lambda x.a)\; t_1} \  
These rules examine the current context and proceed to build a maximal
answer-shaped term, progressively wrapping binder frames around the current
answer.  If the entire context is consumed then evaluation has completed and
the entire program is an answer.  Upon reaching an operand or cont frame, a
redex has been found, and rebuild transitions to the reduce rules.  These rules
resemble the  rules of~\citet{danvyTRrefocusing}.

The \emph{need} rules also examine the context, but they
search for the binder frame that corresponds to the variable under focus.
A need configuration  represents the term .
0.5ex]
      \need{E_1 \comp [f], E_2, x} & \mapsto &
      \need{E_1,[f] \comp E_2, x} \  


Since input programs are closed, the associated binder must be somewhere in the
context.  Upon finding the right binder frame, a cont frame  is pushed onto the context and evaluation proceeds to refocus on the
operand from the associated binder frame.


The \emph{reduce} rules simulate the notions of reduction from the calculus.
A reduce configuration  represents the term  where a cont
 represents the term .
0.5ex]
    \begin{array}{rcl}
      \reduce{E_1, (\kappa x.E_2)\; v}
      & \mapsto &
      \refocus{E_1, (\lambda x.E_2[v])\; v} \0.5ex]

      \reduce{E, (\lambda x. a)\; t_1\; t_2}
      & \mapsto &
      \refocus{E, (\lambda x. a\;t_2)\; t_1} \0.5ex]
    \end{array} 
\end{boxedarray}

      (\lambda x.t_1)\;t_2 \notion\ \mathrm{let}\; x=t_2\; \mathrm{in}\; t_1

\begin{array}{llllll}
& \braket{[\;], \underline{(\lambda x.x)\;\lambda y.y}}_f & \mapsto &
\refocus{[[]\;\underline{\lambda y.y}], \underline{\lambda x.x}} & \mapsto &
\rebuild{[[]\;\underline{\lambda y.y}], \lambda x.\underline{x}} \1.0ex]
 \mapsto & 
\refocus{[(\kappa x.[\;])\;[]], \underline{\lambda y.y}} & \mapsto &
\rebuild{[(\kappa x.[\;])\;[]], \lambda y.\underline{y}} & \mapsto & 
\reduce{[\;], (\kappa x.[\;])\;\lambda y.\underline{y}} 
\end{array}

  \need{E_1 \comp [(\lambda x.[])\; t] \comp E_2, x}  \mapsto
\refocus{E_1 \comp [(\kappa x.E_2)\; []], t} \\
\text{where } \lbrack(\lambda x.[])\; t] \notin E_2

  \reduce{[\;], (\kappa x.[\;])\;\lambda y.\underline{y}} \mapsto
  \braket{[\;],\underline{(\lambda x.\lambda y.y)\;\lambda
      y.y}}_f

     \refocus{E_1, (\lambda x.E_2[v])\;v}  \mapsTo 
     \rebuild{E_1 \comp [(\lambda x.[])\;v] \comp E_2, v} 
  
  \reduce{E_1, (\kappa x.E_2)\; v}
  \mapsto 
  \rebuild{E_1 \comp [(\lambda x.[])\; v] \comp E_2, v} 

  \reduce{[\;], (\kappa x.[\;])\;\lambda y.\underline{y}} \mapsto
  \rebuild{[(\lambda x.[])\;(\lambda y.\underline{y})],\lambda y.\underline{y}} 

      \refocus{E, (\lambda x.a\;t_2)\; t_1} \mapsTo
      \reduce{E \comp [(\lambda x.[])\;t_1], a\;t_2}.
  
    \refocus{E_1,(\lambda x_2.(\lambda x_1.E_2[x_1])\; a)\; t} \mapsTo 
    \reduce{E_1 \comp [(\lambda x_2.[])\; t], (\kappa x_1.E_2)\; a}.
  
\reduce{E_1, (\kappa x_1.E_2)\;((\lambda x_2. a)\; t)} \mapsto
\reduce{E_1 \comp [(\lambda x_2.[])\; t], (\kappa x_1.E_2)\; a}

\reduce{E, (\lambda x. a)\; t_1\; t_2}
\mapsto 
\reduce{E \comp [(\lambda x.[])\;t_1], a\;t_2}

\begin{boxedarray}{lclr}
  a & \produce & \answer{E,v}, &\text{where }
  E = \overline{[(\lambda x_i.[])\;t_i]} \\
\end{boxedarray}  

  \rebuild{E_1 \comp [(\kappa x.E_2)\; []] \comp E_3, v} \mapsto
\reduce{E_1, (\kappa x.E_2)\; \answer{E_3,v}} \\
\text{where } E_3 = \overline{[(\lambda x_i.[])\;t_i]}

  \rebuild{[(\lambda x.[])\;\lambda y.\underline{y}],\lambda y.\underline{y}}
  \mapsto
  \Braket{\answer{[(\lambda x.[])\;\lambda y.\underline{y}],
      \lambda y.\underline{y}}}

  \begin{split}
  & E[((\lambda x_n.\, \dots 
  ((\lambda x_1. ((\lambda x_0.v)\; t_0)) \;t_1) \;\dots)\;t_n) \; t] 
 \Sr \\
  & E[((\lambda x_n.\, \dots 
  ((\lambda x_1. ((\lambda x_0.v\; t)\; t_0)) \;t_1) \;\dots)\;t_n)].
  \end{split}

  \begin{split}
    & E[(\lambda x.E[x])\;
    ((\lambda x_n.\, \dots 
    ((\lambda x_1. ((\lambda x_0.v)\; t_0)) \;t_1) \;\dots)\;t_n)]  \Sr  \\
    & E[((\lambda x_n.\, \dots ((\lambda x_1. ((\lambda x_0.
    (\lambda x.E[x])\; v)\; t_0)) \;t_1) \;\dots)\;t_n)].
  \end{split}

  \reduce{E_1, (\kappa x.E_2)\; \answer{E_3, v}} \mapsto 
  \rebuild{E_1 \comp E_3 \comp [(\lambda x.[])\;v] \comp E_2, v} \\
  \reduce{E_1, \answer{E_2,(\lambda x.t_1)}\;t_2} \mapsto
  \refocus{E_1 \comp E_2 \comp [(\lambda x.[])\; t_2], t_1} 

\begin{boxedarray}{lcl}
      X & \produce & \overline{x_i}\\
\end{boxedarray}  

      \tag{D.2} \reduce{X | E_1, \answer{E_2,\lambda x.t_1} \; t_2} \nam\
      \refocus{X,x' | E_1 \comp E_2 \comp [(\lambda x'.[])\;t_2], 
        t_1[x'/x]} \quad x' \notin X

\begin{boxedarray}{lcl}
      \Braket{X|E,?} & \produce & \Braket{X|\answer{E,v}} | \reduce{X|E,r} | 
      \refocus{X|E,t} \
We use the notation  below to uniformly discuss all
configuration types, where  refers to the list of names,  refers to the
context, and  refers to the term or redex.  For a final configuration
,  refers to the answer's underlying value , and
 corresponds to the answer's binder frames . We use the metavariable
 to range over configurations when the internal structure does not matter.

\pagebreak
The call-by-need abstract machine uses the set  of names to keep track of
\emph{active variables}: any variable  whose binding instance has
been pushed into a binder frame :
0.5ex]
  AV([(\lambda x.[])\;t] \comp E) & = & \set{x} \union AV(E) \0.5ex]
  AV([(\kappa x.E_1)\;[]] \comp E) & = &
  AV(E_1) \union \set{x} \union AV(E)
\end{boxedarray}

\begin{boxedarray}{lcl}
  CV([\;]) & = & \emptyset \0.5ex]
  CV(E \comp [[]\;t]) & = & CV(E)  \0.5ex]
  \\
  FV([\;]) & = & \emptyset \\
  FV([(\lambda x.[])\;t] \comp E) & = & FV(t) \union (FV(E) - \set{x}) \\
  FV([[]\;t] \comp E) & = & FV(E) \union FV(t) \\
  FV([(\kappa x.E_1)\;[]] \comp E) & = & FV(E) \union (FV(E_1) - \set{x})
\end{boxedarray}

  \begin{boxedarray}{@{}l@{}}
    \begin{inferbox*}
      \inference{X|E\<wf> & FV(?) \subseteq CV(E)}
      {\Braket{X|E,?}_c \<wf>} \quad c \not\equiv d
      \and
      \inference{X|(E_1\comp [(\kappa x.E_2)\;[]] \comp E_3) \<wf> &
        FV(v) \subseteq CV(E_1 \comp [(\kappa x.E_2)\;[]] \comp E_3)}
      {\reduce{X|E_1,(\kappa x.E_2)\;\answer{E_3,v}} \<wf>}
      \and
      \inference{X|(E_1 \comp [[]\;t] \comp E_2) \<wf> &
        FV(v) \subseteq CV(E_1 \comp [[]\;t] \comp E_2)}
      {\reduce{X|E_1,\answer{E_2,v}\;t_2} \<wf>}
    \end{inferbox*}    
  \end{boxedarray}

      FV(v) \subseteq CV(E_1 \comp [(\kappa x.E_2)\;[]] \comp E_3) = 
      CV(E_1 \comp E_3) \subseteq CV(E).
    
      FV(E_1) = FV(E_1 \comp [(\kappa x.E_2)\;[]]) = 
      FV(E_1 \comp [(\kappa x.E_2)\;[]] \comp E_3) = \emptyset.
    0.5ex]

      (D.2) &
      \reduce{X | E_1, \answer{E_2,\lambda x.t_1} \; t_2} &
      \nam &
      \refocus{X,x' | E_1 \comp E_2 \comp [(\lambda x'.[])\;t_2], t_1[x'/x]}
      & x' \notin X \\
    \end{ltransitionrule} \\  \\

    \vspace{1ex}
    \boxed{\refocus{X|E,t}}\quad\desc{Refocus} \\
    \begin{ltransitionrule}
      (F.1) &
      \refocus{X | E, x} & \nam & \need{X | E, x} & \0.5ex]

      (F.3) &
      \refocus{X | E, t_1\;t_2} & \nam &
      \refocus{X | E \comp [[]\;t_2], t_1} &
    \end{ltransitionrule} \\  \\

    \vspace{1ex}
    \boxed{\rebuild{X|E,v}}\quad\desc{Rebuild} \\
    \begin{ltransitionrule}
      (B.1) &
      \rebuild{X | E_b,v} & \nam & \Braket{X|\answer{E_b,v}} & \0.5ex]
      
      (B.3) &
      \rebuild{X | E_1 \comp [(\kappa x.E_2)\; []]\comp E_b, v} & \nam &
      \reduce{X | E_1, (\kappa x.E_2)\; \answer{E_b,v}} & \0.5ex]
      \multicolumn{5}{l}{\text{where }\lbrack(\lambda x.[])\; t] \notin E_2}
    \end{ltransitionrule}
 \end{boxedarray}
   \caption{Call-by-need Machine}
  \label{fig:transitions}
\end{figure*}






\section{Correctness of the Machine}

The previous section proves that the machine manipulates terms in a manner that
preserves variable binding. In this section, we prove that those manipulations
correspond to standard-order call-by-need evaluation.  

To proceed, we first establish correspondences between abstract machine
configurations and call-by-need terms.  As we have alluded to previously, 
abstract machine contexts correspond directly to calculus contexts:
0.5ex]
    \mtoc |[ [[]\; t] \comp E |] & = & \mtoc |[E|]\; t \0.5ex]
    \mtoc |[ [(\lambda x.[])\; t] \comp E |] & = &
    (\lambda x.\mtoc |[E|])\; t \
Redexes also map to call-by-need terms:
0.5ex]
    \mtoc |[ (\kappa x.E_1)\; \answer{E_2,v} |]  & = &
    (\lambda x.\mtoc |[E_1|][x])\;(\mtoc |[E_2|][v])
\end{boxedarray}

\begin{boxedarray}{lcl}
    \mtoc |[ \Braket{X|E,?} |]  & = & \mtoc |[E|][\;\mtoc |[?|]\;]
\end{boxedarray}
t \Sr\; a\quad\hbox{if and only if}\quad C \Nam
  \Braket{X|\answer{E,v}}

      (\lambda x.t_1)\;t_2 \:= \: \mathrm{let}\; x=t_2\; \mathrm{in}\; t_1

     \mathrm{let}\; x=t_2\; \mathrm{in}\; t_1  \notion{} (\lambda x.t_1)\;t_2 

 r ::= \dots | \mathrm{let}\; x=t_2\; \mathrm{in}\; t_1 

  \refocus{E,\mathrm{let}\; x=t_2\; \mathrm{in}\; t_1}
  \mapsto
  \reduce{E,\mathrm{let}\; x=t_2\; \mathrm{in}\; t_1}

  \reduce{E,\mathrm{let}\; x=t_2\; \mathrm{in}\; t_1}
  \mapsto
  \refocus{E,(\lambda x.t_1)\;t_2}

  \reduce{X|E,\mathrm{let}\; x=t_2\; \mathrm{in}\; t_1}
  \mapsto
  \refocus{X,x'|E\comp[(\lambda x'.[])\;t_2],t_1[x'/x]}

\begin{boxedarray}{lcl}
  t & \produce & \dots | b | f\;t \\
  v & \produce & \dots | b
\end{boxedarray}  

  \begin{boxedarray}{lclr}
    f\;v_1 & \notion{} & v_2 & \text{if } \delta(f,v_1) = v_2
  \end{boxedarray}

  \begin{boxedarray}{lcl}
    f\;((\lambda x.a)\;t) & \notion{} & (\lambda x. f\;a)\;t
  \end{boxedarray}

\begin{boxedarray}{lcl}
  E & \produce & \dots | f\;E
\end{boxedarray}

  (\lambda x . \mathrm{add1}\;x)\; 5 \notion\ (\lambda x.\mathrm{add1}\;5)\;5

  r ::= \dots | f\;a

  \begin{array}{rcl}
    \refocus{X|E,f\;t} & \nam & \refocus{X|E\comp [f\;[]],t} \\   
    \refocus{X|E,v} & \nam & \rebuild{X|E,v}   
  \end{array}

  \refocus{X|E \comp [f\;[]] \comp E_b,v} \nam\ \reduce{X|E,f\;\answer{E_b,v}}

   \reduce{X|E,f\;\answer{E_b,v}} \nam\ \rebuild{X|E\comp E_b,\delta(f,v)}

  \begin{boxedarray}{rcl}
  \mathtt{cons} & \equiv & \lambda x_1.\lambda x_2.\lambda d.d\;x_1\;x_2 \\
  \mathtt{car} & \equiv & \lambda p.p\;(\lambda x_1.\lambda x_2.x_1) \\
  \mathtt{cdr} & \equiv & \lambda p.p\;(\lambda x_1.\lambda x_2.x_2) \\
  \end{boxedarray}

  \begin{boxedarray}{rcl}   
    t & \produce & \dots | \mathtt{cons}\;t\;t | \mathtt{car}\;t |
    \mathtt{cdr}\;t | \consd{x}{x} \\
    v & \produce & \dots | \consd{x}{x} \\
    E & \produce & \dots | \mathtt{car}\;E | \mathtt{cdr}\;E
  \end{boxedarray}

  \begin{boxedarray}{rcl}    
    \mathtt{cons}\;t_1\;t_2 & \notion{}
    & (\lambda x_1.(\lambda x_2.\consd{x_1}{x_2})\;t_2)\;t_1 \\
    \mathtt{car}\;\consd{x_1}{x_2} & \notion{} & x_1 \\
    \mathtt{cdr}\;\consd{x_1}{x_2} & \notion{} & x_2 \\
  \end{boxedarray}

  r ::= \dots | \mathtt{cons}\;t_1\;t_2 | \mathtt{car}\;a | \mathtt{cdr}\;a

  \begin{boxedarray}{rcl}    
  \label{nam:cons1}
  \refocus{X|E,\mathtt{cons}\;t_1\;t_2} & \nam &
  \reduce{X|E,\mathtt{cons}\;t_1\;t_2} \\

  \refocus{X|E,\mathtt{car}\;t} & \nam & 
  \refocus{X|E \comp [\mathtt{car}\;[]], t}  \\

  \refocus{X|E,\mathtt{cdr}\;t} & \nam & 
  \refocus{X|E \comp [\mathtt{cdr}\;[]], t} \\

  \end{boxedarray}

  \begin{boxedarray}{rcl}    
  \label{nam:cons2}

  \rebuild{X| E \comp [\mathtt{car}\;[]] \comp E_b,v} & \nam &
  \reduce{X|E,\mathtt{car}\;\answer{E_b,v}} \\

  \rebuild{X| E \comp [\mathtt{cdr}\;[]] \comp E_b,v} & \nam &
  \reduce{X|E,\mathtt{cdr}\;\answer{E_b,v}} \\
  \end{boxedarray}

  \begin{boxedarray}{rcl}    
  \label{nam:cons3}
  \reduce{X|E,\mathtt{cons}\;t_1\;t_2} & \nam &
  \rebuild{X,x_1,x_2|
    E\comp [(\lambda x_1.[])\;t_1]\comp [(\lambda x_2.[])\;t_2],
    \consd{x_1}{x_2}} \\

  \reduce{X|E_1,\mathtt{car}\;\answer{E_2,\consd{x_1}{x_2}}} & \nam &
  \need{X|E_1 \comp E_2, x_1} \\

  \reduce{X|E_2,\mathtt{cdr}\;\answer{E_2,\consd{x_1}{x_2}}} & \nam & 
    \need{X|E_1 \comp E_2, x_2} \\
  \end{boxedarray}

  Y(\lambda y.\mathtt{cons}\;1\;y) \equiv  
  (\lambda f.(\lambda x.f\;(x\;x))\;(\lambda x.f\;(x\;x)))\; 
  (\lambda y.\mathtt{cons}\;1\;y)

 &  (\lambda f.(\lambda x.\underline{f}\;(x\;x))\;(\lambda x.f\;(x\;x)))\; 
  (\lambda y.\mathtt{cons}\;1\;y) \\
\notion\enspace\ & (\lambda f.(\lambda x.(\lambda y.\underline{\mathtt{cons}\;1\;y})\;
  (x\;x))\;
  (\lambda x.f\;(x\;x)))\; 
  (\lambda y.\mathtt{cons}\;1\;y) \\
 \notion\enspace\ &   (\lambda f.(\lambda x.(\lambda y.(\lambda x_1.
  (\lambda x_2.\consd{x_1}{x_2})\;y)\;1)\;
  (x\;x))\;(\lambda x.f\;(x\;x)))\; 
  (\lambda y.\mathtt{cons}\;1\;y) 

\begin{boxedarray}{lcl}
  t & \produce & x | \lambda x.t | t\;t |
  \<letrec> D \<lin> t \\
  D & \produce & x_1 \<be> t_1, \dots, x_n \<be> t_n \\
  v & \produce & \lambda x.t \\
  a & \produce & v | \<letrec> D \<lin> a \\
  E & \produce & [] | E\; t | \<letrec> D \<lin> E  \\
  & | &\<letrec> D, x \<be> E \<lin> E[x] \\
  & | &\<letrec> x_n \<be> E, D[x,x_n] \<lin> E[x] \\
  D[x,x_n] & \produce & x \<be> E[x_1], x_1 \<be> E[x_2], \dots, 
  x_{n-1} \<be> E[x_n], D
\end{boxedarray}  

\<letrec> D, x \<be> E \<lin> E[x] 

\<letrec> x_n \<be> E, D[x,x_n] \<lin> E[x]

\begin{boxedarray}{rlcl@{}}
(1)&(\lambda x.t_1)\;t_2 & \notion & \<letrec> x \<be> t_2 \<lin> t_1 \\
(2)&\<letrec> D, x \<be> v \<lin> E[x]  & \notion & 
\<letrec> D, x \<be> v, \<lin> E[v] \\
(3)&\<letrec> x_n \<be> v, D[x,x_n] \<lin> E[x]
 & \notion &  
\<letrec> x_n \<be> v, D[x,v] \<lin> E[x] \\
(4)&(\<letrec> D \<lin> a)\;t & \notion & \<letrec> D \<lin> a\;t \\

(5)&\begin{array}[t]{@{}l@{}}
\<letrec> 
x_{n} \<be> (\<letrec> D \<lin> a), D[x,x_n]\\
\<lin> E[x]
\end{array}
 & \notion &  
\begin{array}{@{}l@{}}
\<letrec> D, x_{n} \<be> a, D[x,x_n] \<lin> E[x]
\end{array}
\\

(6) &
\<letrec> D_1, x \<be> (\<letrec> D_2 \<lin> a)\<lin> E[x]
& \notion &  
\begin{array}{@{}l@{}}
\<letrec> D_2, D_1, x \<be> a \<lin> E[x]
\end{array}

\end{boxedarray}  

&  
\<letrec> y \<be> \mathtt{cons}\;1\;y \<lin> y \\
\notion\enspace\ &
\<letrec> y \<be> (\<letrec> x_1 \<be> 1 \<lin> 
(\<letrec> x_2 \<be> y \<lin> 
\consd{x_1}{x_2})) \<lin> y \\
\notion\enspace\ &
\<letrec> x_1 \<be> 1, y \<be> 
(\<letrec> x_2 \<be> y \<lin> 
\consd{x_1}{x_2}) \<lin> y \\
\notion\enspace\ &
\<letrec> x_1 \<be> 1, x_2 \<be> y, y \<be>
\consd{x_1}{x_2} \<lin> y \\
\notion\enspace\ &
\<letrec> x_1 \<be> 1, x_2 \<be> y, y \<be> 
\consd{x_1}{x_2} \<lin> \consd{x_1}{x_2}

\begin{boxedarray}{lcl}
  t & \produce & x | \lambda x.t | t\;t | \<letrec> D^{+} \<lin> t \
As with the calculus,  refers to sets of recursive bindings.  As needed,
we distinguish  possibly empty sets of bindings, , from nonempty
sets .  This precision is needed to discuss machine behavior.
The values of this machine are the lambda abstractions, but now answers are
defined as values wrapped in zero or more tiers of  bindings.

As we did for the prior machine, we introduce some representation changes that
help with presenting the letrec-machine.  The evaluation context is once again
replaced with a list of context frames.
0.5ex]
  & &\text{where } E \comp [\;] = [\;] \comp E = E\
The operand frame  and binding frame  are directly
analogous to the corresponding frames in the original abstract machine.  The
original cont frame, on the other hand, splits into two variants.  
The frame 

captures chain of dependencies that is currently under evaluation.  The
expression  stands for the inactive bindings in the frame, while the
expression  indicates a chain of dependencies.  While no
particular ordering is imposed on the bindings in , the chain of
dependencies represented by  is ordered. 
Our machine representation separates dependencies from other bindings.  In the
calculus,  also includes any other bindings .  In the machine,
 only captures the dependencies, and the other bindings 
are explicitly indicated.
Machine dependencies

correspond to calculus dependencies .  We allow  to
denote an empty chain.  Observe that the order of the
machine dependencies is reversed.  This ordering expresses that dependencies
are resolved in last-in first-out order.  When the value of  is
computed, its value will be used to compute the value of  and so on
until the value of  is computed and its value is returned to the body of
the  expression.  Machine dependencies form a stack of
computations that reference one another.  This behavior is clarified in the
behavior of the cyclic abstract machine.


The frame  closely resembles the old cont
frame , except that the  form may bind other variables
as well.  The absence of  in this frame explicitly indicates that
it has no chain of dependencies to be evaluated before substituting into the
body of the .


Machine answers are still binding-value pairs, but now each binding
is a recursive binding of multiple variables.



The set of redexes for the abstract machine follows.

The first redex form is the same as a form from the original machine.  The
second form is analogous to the  form from the original
machine.  The final redex form captures the case where one link in the chain of
dependencies is about to be resolved.

Figure~\ref{fig:letrec-machine} presents the transition rules of the cyclic
abstract machine. The machine relies on an operator , which
given a list of binder frames , flattens
them into a single binder frame . This
operation captures in aggregate the treatment of bindings by rules  and
 of the calculus.

The first three refocus rules are the same as the lambda calculus, while the
fourth rule is analogous to the equivalent rule for the let-calculus.  
The rebuild rules are also analogous to the lambda calculus, though now the
binder frames have the form .

The letrec-machine has two need rules,  for a variable
reference in the body of the corresponding , and 
for a variable reference that extends a (possible empty) chain of
dependencies. The need rule does not consider variable bindings that are
currently in a dependency chain, so evaluation will get stuck upon arriving at
a cycle.

There are four reduce rules.  The  rule, substitutes a value into the
body of a letrec after its value has been computed.  The  rule resolves
the most recent reference in a chain of dependencies.  Having computed the
value of , it returns to computing the value of , which needed
's value.  If the chain of dependencies has only one element
(i.e. ), then the chain is fully resolved.  The  rule
handles when an answer is applied to an expression. It combines calculus rules
 and .  Finally, the  rule handles  occurrences in
the source program.  In order to address hygiene, this rule must simultaneously
substitute for every bound variable in each binding as it focuses on the body
of the  expression.



The following is a machine trace of the cyclic  example:



\section{Simulating Call-by-need Using Control}


As we allude to above, call-by-need machine evaluation is highly suggestive of
delimited control operations, but the connection is indirect and mixed with the
other details of lazy evaluation.  In this section, we directly interpret this
connection in the terminology of delimited control.








Based on the operational behavior of the abstract machine from
Figure~\ref{fig:transitions}, we derive a simulation of call-by-need execution
under call-by-value augmented with delimited control operators.  In particular,
we translate call-by-need terms into the framework
of~\citet{dybvig07monadic}. First we overview the language of delimited control
operations.  Then we describe how the abstract machine performs delimited
control operations.  Next we present the simulation of call-by-need using
delimited control.  Finally we show its correctness.



\begin{landscape}
\begin{figure*}
  \centering\small
  \begin{boxedarray}{@{}l@{}}
    \vspace{1ex}
   \boxed{\reduce{X|E,r}}\quad\desc{Reduce} \\
    \begin{ltransitionrule}
      (D.1) & 
      \reduce{X | E_1, 
        (\LF x \<be> \answer{E_2,v},D^{*} \<lin> E_3)} & \nam &
      \rebuild{X | E_1 \comp
        [\LF x \<be> v, \flatten{E_2},D^{*} \<lin> []]  \comp E_3,v} \\

      (D.2) &
      \reduce{X | E_1, 
        (\LF x_{n+1} \<be> \answer{E_2,v}, \PP{x_n}{x_0}, D^{*} \<lin> E_3)} 
      & \nam & 
      \rebuild{X | E_1 \comp
        [\LF x_n \<be> [], \PP{x_{n-1}}{x_0}, x_{n+1} \<be> v,
        \flatten{E_2},D^{*} \<lin> E_3]  \comp E_n,v} \\

      (D.3) &
      \reduce{X | E_1, \answer{E_2,\lambda x.t_1} \; t_2} &
      \nam &
      \refocus{X,x' | E_1 \comp E_2 \comp [\LF x' \<be> t_2 \<lin> []],
        t_1[x'/x]}
      \quad x' \notin X \\

      (D.4) & 
      \reduce{X | E, \<letrec> \seq{x_i \<be> t_i} \<lin> t} & \nam &
      \refocus{X,\seq{x'_i} | E \comp 
        [\LF \seq{x'_i \<be> t_i[\seq{x'_i/x_i}]} \<lin> []], t} 
      \quad \seq{x'_i} \cap X = \emptyset
    \end{ltransitionrule} \\  \\

    \vspace{1ex}
    \boxed{\refocus{X|E,t}}\quad\desc{Refocus} \\
    \begin{ltransitionrule}
      (F.1) &
      \refocus{X | E, x} & \nam & \need{X | E, x} & \0.5ex]

      (F.3) &
      \refocus{X | E, t_1\;t_2} & \nam &
      \refocus{X | E \comp [[]\;t_2], t_1} & \\

      (F.4) & 
      \refocus{X | E, \<letrec> D^{+} \<lin> t} & \nam &
      \reduce{X | E, \<letrec> D^{+} \<lin> t} \\
    \end{ltransitionrule} \\  \\

    \vspace{1ex}
    \boxed{\rebuild{X|E,v}}\quad\desc{Rebuild} \\
    \begin{ltransitionrule}
      (B.1) &
      \rebuild{X | E_b,v} & \nam & \Braket{X|\answer{E_b,v}} & \0.5ex]


      (B.3) &
      \rebuild{X | E_1 \comp 
        [(\LF x \<be> [],D^{*} \<lin> E_2)] \comp E_b, v} & \nam &
      \reduce{X | E_1, 
        (\LF x \<be> \answer{E_b,v},D^{*} \<lin> E_2)} & \\


      (B.4) &
      \rebuild{X | E_1 \comp 
        [(\LF x_{n+1} \<be> [], \PP{x_n}{x_0}, D^{*} \<lin> E_2] \comp E_b, v} & \nam &
      \reduce{X | E_1, 
        (\LF x_{n+1} \<be> \answer{E_b,v}, \PP{x_n}{x_0}, D^{*} \<lin> E_2)} \\
      \multicolumn{5}{l}{\text{where }E_b = \overline{[\LF D^{+}_i  \<lin> []]}}
    \end{ltransitionrule} \\  \\

    \vspace{1ex}
    \boxed{\need{X|E,x}}\quad\desc{Need} \\
    \begin{ltransitionrule}
      (N.1) &
      \need{X | E_1 \comp 
        [\LF (x \<be> t, D^{*}) \<lin> []] \comp E_2^\dagger, x} & \nam &
      \refocus{X | E_1 \comp
        [\LF x \<be> [], D^{*} \<lin> E_2] , t}  & \0.5ex]
      \multicolumn{5}{l}{\text{where } (x \<be> t) \notin E^\dagger}
    \end{ltransitionrule}
 \end{boxedarray}
   \caption{Letrec Machine}
  \label{fig:letrec-machine}
\end{figure*}
\end{landscape}


\subsection{Delimited Control Operators}
\citet{dybvig07monadic} define a language with delimited control operators.
We explain these operators using a simplified variant of
the defining machine semantics.
0.5ex] 
  & | & \<withSubCont> t\; t | \<pushSubCont> t\; t \0.5ex]
  E & \produce & \hole | E[[]\;t] | E[(\lambda x.t)\;[]] 
  | E[\<pushPrompt> []\;t] \0.5ex]
  & | & E[\<pushSubCont> []\; t]\0.5ex] 
  p & \in & \mathbb{N} \
The language extends the call-by-value untyped lambda calculus with the four
operators , , , and
 as well as two new values: first-class \emph{prompts} ,
and first-class delimited continuations .  Its control structure is
defined using evaluation contexts , and metacontexts , which are
lists that interleave prompts and contexts. 
Metacontexts use Haskell list notation.
Prompts are modeled using natural numbers.

A program state comprises an expression , continuation , metacontinuation
, and fresh prompt source .  The initial state for a
program  is .
0.5ex]
      E[\<newPrompt>],M,p & \mapsto & E[p],M,p+1 \0.5ex]
  E[\<withSubCont> p_1\;\lambda x.t],M_1++(p_1:M_2),p_2 &\mapsto &
\hole[t[\Braket{E:M_1}/x]],M_2,p_2 \0.5ex]
E[\<pushSubCont>\!\Braket{M_1}\;t],M_2,p & \mapsto & 
\hole[t],M_1 ++ (E:M_2),p \0.5ex]
      \hole[v],p_1:M,p_2 & \mapsto & \hole[v],M,p_2 \


The four operators manipulate delimited continuations, or
\emph{subcontinuations}, which are part of an execution context.  The
 operator takes a prompt and a function; it captures the
smallest subcontinuation that is delimited by the prompt and passes it to the
function.  The non-captured part of the continuation becomes the new
continuation.  The prompt instance that delimited the captured subcontinuation
is discarded: it appears in neither the captured subcontinuation nor the
current continuation.  This operator
generalizes~~\cite{felleisen88prompts} and
\texttt{shift}~\cite{danvy90abstracting}.

The  operator takes a subcontinuation and an expression; it
composes the subcontinuation with the current continuation and proceeds to
evaluate its second argument in the newly extended continuation.

The  operator takes a prompt and an expression; it extends the
current continuation with the prompt and evaluates the expression in the newly
extended continuation.  The  operator returns a distinguished
fresh prompt each time it is called. These two operators generalize the
delimiting operators ~\cite{felleisen88prompts} and
\texttt{reset}~\cite{danvy90abstracting}, which extend a continuation with a
single common delimiter.

To illustrate these operators in action, we consider a program that uses
arithmetic and conditionals:

A fresh prompt is bound to  and pushed onto the continuation just prior to
evaluation of the  expression.   captures the
subcontinuation , which was delimited by~,
and binds it to .  The subcontinuation  is pushed twice, given the value
 the first time and  the second.  The result of
evaluation is the expression  which yields .


\subsection{Delimited Control Na\"ively Simulates the Machine} 

The call-by-need abstract machine performs two different kinds of partial
control capture.  To review, the rebuild and need rules of the abstract machine
both capture some portion of the evaluation context.  In particular, the
rebuild rules capture binder frames.  If only binder frames remain, then
execution is complete.  When either of the other frames is found, then a
reduction is performed.  On the other hand, the need rule captures the
evaluation context up to the binder that matches the variable whose value is
needed.

These actions of the abstract machine can be recast in the language of
delimited control capture.
First, the need rule uses the identity of its variable, which must be an active
variable, to delimit the context it captures. The well-formedness conditions
from Section~\ref{sec:hygiene} guarantee that each binder frame binds a unique
variable, so each active variable acts as a unique delimiter.
Second, the rebuild rule uses the nearest non-binder frame to delimit the
context it captures.  This means that rebuild operates as though the operand
frames, the cont frames, and the top of the evaluation context share a common
delimiter.  This guarantees that only binder frames are captured (as is
stipulated in the rules).

In short, call-by-need evaluation captures partial evaluation contexts.  These
partial evaluation contexts correspond to delimited continuations, and there
are two different kinds of delimitation, redex-based (for rebuild) and 
binder-based (for need). 

It is useful to also consider how the machine manipulates these delimited
continuations.  Each reduce rule in Figure~\ref{fig:transitions} immediately
pushes the context associated with an answer onto the current evaluation
context.  In this manner, binders are consistently moved above the point of
evaluation.  The reduce rule then operates on the value part of the answer and
the associated cont (for ) or term (for ).

Although each reduce rule pushes binders onto the evaluation context, only
the  rule creates new binders.  The variable bound by the answer's
underlying lambda abstraction may already be a member of the set , in which
case it must be alpha-converted to a fresh name with respect to the set
.  Also note that if  is alpha converted to , the body under call-by-value satisfies the equation .  Since we are using the identifiers  as delimiters,
and we never turn the binder frame  back into a term, we
can replace fresh variables  with fresh \emph{prompts}~\cite{balat04sums}.


\begin{figure}
  \centering\small
  \begin{boxedarray}{@{}l@{}}
    \text{Let  be a distinguished identifier:} \\ \\

      \mathcal{N}^P|[ t |]  =  \<runCC> 
      (\<let> s = \<newPrompt>\; \<in> \<pushPrompt> s \; \mathcal{N}|[ t |])
           \\ \\

      \mathcal{N}|[ x |]  = \mathsf{need}\;x \\ \\

      \mathcal{N}|[ t_1\;t_2 |] =  
      \begin{array}[t]{@{}l@{}}
        \mathsf{do}\;v_a <= \mathcal{N}|[t_1|] \\
        \mathsf{in}\; 
        \begin{array}[t]{@{}l@{}}
          \<let> x_p = \<newPrompt> \\
          \<in> 
          \begin{array}[t]{@{}l@{}}
            \mathsf{delay}\;\mathcal{N}|[t_2|]\;\mathsf{as}\;x_p \;
            \mathsf{in}\;(v_a \;x_p)
          \end{array} 
        \end{array} 
      \end{array} 
      \\ \\

      \mathcal{N}|[ \lambda x.t |]  = 
      \mathsf{return}\; \lambda x. \mathcal{N}|[ t |] \\ \\

      \hline
      \\

      \mathsf{return}\;v_a \equiv     
      \<withSubCont> s \; \lambda k_a.\Braket{k_a,v_a}  \\ \\

      \mathsf{do}\;x <= t_1 \;\mathsf{in}\; t_2 \equiv
      \begin{array}[t]{@{}l@{}}
          \<let> \Braket{k_a,x} = \<pushPrompt> s \; t_1 \\
          \!\!\<in> \<pushSubCont> k_a \; t_2
      \end{array} \\ \\

      \mathsf{delay}\; t_1\; \mathsf{as}\; x\;\mathsf{in}\; t_2 \equiv
      \begin{array}[t]{@{}l@{}}
            \<let> f_k = \<pushPrompt> x\; t_2\\
            \!\!\<in> f_k\; \lambda (). t_1 
      \end{array} \\ \\
 
      \mathsf{force}\;f \equiv f\;() \\ \\

      \mathsf{need}\;x \equiv\;
\begin{array}[t]{@{}l@{}}
          \<withSubCont> x \; \lambda k.\\
          \quad\lambda f_{th}. 
      \begin{array}[t]{@{}l@{}}

          \mathsf{do}\;v_a <= \mathsf{force}\;f_{th} \\
          \mathsf{in}\;
          \begin{array}[t]{@{}l@{}}
            \mathsf{delay}\;(\mathsf{return}\;v_a)\;\mathsf{as}\;x \\
            \mathsf{in}\;\<pushSubCont> k \; (\mathsf{return}\;v_a) \\ 
          \end{array} 
        \end{array} 
      \end{array} 
\\ \\

  \end{boxedarray}
  
   \caption{Translating CBN to CBV+Control}
  \label{fig:cbn-simulation}
\end{figure}


From these observations, we construct the simulation in
Figure~\ref{fig:cbn-simulation}.
The simulation can be understood as a direct encoding of the abstract machine
semantics for call-by-need.  To execute a program, , the
transformation uses  to initiate a control-based
computation, acquires a fresh prompt, and binds it to a distinguished variable
.  This prompt is the \emph{redex prompt}, which is used to delimit every
continuation that denotes a redex.

To expose the conceptual structure of the simulation, we define five syntactic
macros, , , , ,
and .  We accord no formal properties to them: they merely
simplify the presentation.  The  macro captures the nearest
subcontinuation that is delimited by the redex prompt . Since the 
delimiter appears before every reduction, the captured continuation is
guaranteed to contain only code equivalent to binder frames.  The translation
returns a tuple containing the subcontinuation and the argument to
, which must be a value; the tuple represents an answer.  So
the translation rule for lambda abstractions, ,
literally simulates the rebuild rules.

The  macro executes a term  under the current continuation
extended with the redex prompt. If the term returns an answer 
it immediately pushes the subcontinuation part and continues execution, binding
the value part to the variable .  As such, the translation rule for
applications, , executes  and binds the
resulting operator to . The answer binders are pushed by the 
macro, which starts the simulation of the  rule.

The remainder of the  rule is subtle. In the abstract machine, binder
frame variables delimit the need rules.  Since the delimited continuation
framework relies on prompts to delimit continuations, fresh prompts literally
substitute for variables~\cite{kiselyov06dynamic}.  The translation uses
 to acquire a fresh prompt  and then uses the
 macro to simulate pushing a binder frame: the context
 is analogous to the
binder frame .  The  macro anticipates
that its body returns a function  that expects the delayed argument, so it
applies  to a suspension of .  As we see below, the function  is a
cont .

In the context of , the simulation executes .  Since
alpha conversion of  can be written , the
term~ is analogous to : it substitutes
a fresh prompt for a fresh variable.


The  macro, which defines the translation rule for variables,
, captures the continuation delimited by  (which had
better be a prompt!) and returns a function  that closes
over both  and the captured continuation . This function is the cont
, with  modeling the bound variable of the same name, and
continuation  modeling . The function expects the binder frame , which is now at the top of the current continuation, to pass it the
suspension .  The simulation forces the
suspension, and the  macro pushes the resulting answer binders and
binds  to the underlying value.  Pushing the answer binders begins the
simulation of the  rule.

The simulation of  delays a computation that immediately returns the
result  of evaluating the term , pushes the continuation  associated
with the cont, and returns  to the extended continuation.  Now any
subsequent evaluation of  immediately returns the memoized value 
instead of recomputing .  This yields an answer  where
 is an empty subcontinuation.  The value  is delayed exactly as
before and is also returned from the properly extended continuation.  This part
of the translation bears close resemblance to the paradoxical 
combinator~\cite{curry-n-feys}, suggesting that the simulation requires
recursive types~\cite{shan07static}.


\section{Correctness of the Simulation}

We prove correctness of the simulation relative to the machine semantics.
Since we already proved correctness of the machine semantics relative to
standard-order reduction, the result is a proof that our simulation
provides a continuation semantics for call-by-need.

The previous discussion provides an informal justification for the structure of
the call-by-need simulation.  To prove the correctness of the simulation, we
appeal to the continuation semantics for delimited
control~\cite{dybvig07monadic}.  This semantics is completely standard for the
terms of the lambda calculus.  Figure~\ref{fig:dc-combinators} presents the
interesting parts of the semantics.  All CPS terms take a standard continuation
, but the control combinators also take a \emph{metacontinuation}
, which is a list of continuations and prompts, and a global prompt
counter .  The base continuation  delimits each proper
continuation and directs evaluation up the metacontinuation, discarding any
intervening prompts. Given a CPS program , the expression
 runs it.

\begin{figure}[t]
  \centering\small
  \begin{boxedarray}{@{}l@{}}
    newPrompt_c = \lambda\kappa.\lambda\gamma.\lambda q.\kappa\;q\;\gamma\;(q+1)
    \\
    withSubCont_c =  \lambda p.\lambda f.\lambda\kappa.\lambda\gamma.
    f\;(\kappa:\gamma^p_\uparrow)\;\kappa_0\;\gamma^p_\downarrow \\
    pushPrompt_c = \lambda p.\lambda t.\lambda\kappa.\lambda\gamma.
    t\;\kappa_0\; (p:\kappa:\gamma)  \\
    pushSubCont_c = \lambda\gamma'.\lambda t.\lambda\kappa.\lambda\gamma.
    t\;\kappa_0\; (\gamma'\! ++ (\kappa:\gamma)) \\
    \kappa_0 = \lambda v.\lambda\gamma\lambda q.\mathcal{K}(v,\gamma,q) \\
    \\
    \mathcal{K}(v,[\;],q) = v\\
    \mathcal{K}(v,p:\gamma,q) = \mathcal{K}(v,\gamma,q) \\
    \mathcal{K}(v,\kappa:\gamma,q) = \kappa\;v\;\gamma\;q \\
    \end{boxedarray}
   \caption{Delimited Control Combinators}
  \label{fig:dc-combinators}
\end{figure}


To prove correctness, we compose  with the delimited
continuation semantics to produce a translation  to the
 calculus augmented with arithmetic, lists, and the
operator  defined in Figure~\ref{fig:dc-combinators}.  We also
give each abstract machine configuration a denotation, defined in terms of
name-indexed denotations for its constituents  (see
Figures~\ref{fig:cbn-denote-term} through \ref{fig:cbn-denote-redex}).



\begin{figure}[ht]
  \centering\small
  \begin{boxedarray}{@{}l@{}}

    \mathcal{D}|[ t |]_X  =
    \Lambda |[ t |]\overline{[\iota(x_i,X)/x_i]}  \\ \\

      \Lambda^P |[ t|] =
      \Lambda |[t|]\; \kappa_0 \; (0:[\;])\; 1 \\ \\

      \Lambda |[ x |]  =  \\
      \begin{array}[t]{@{}l@{}}
\mathit{withSubCont_c}\;x \\
\quad \lambda k_x.\lambda k_1.k_1  \\
\quad\quad\: \lambda f_{th}.\lambda k_2. \\
\qquad\quad\;\: \mathit{pushPrompt_c}\; 0\; (f_{th}\;()) \\
\qquad\qquad\;(\lambda \Braket{k_a,v_a}\!.\\
\qquad\qquad\quad \mathit{pushSubCont_c}\; k_a \\
\qquad\qquad\qquad(\lambda k_3.\\
\qquad\qquad\qquad\;\:\mathit{pushPrompt_c}\; x \\
\qquad\qquad\qquad\quad(\mathit{pushSubCont_c}\; k_x \\
\qquad\qquad\qquad\qquad(\mathit{withSubCont_c}\; 0\; 
\lambda k_a. \lambda k. k \Braket{k_a, v_a})) \\
\qquad\qquad\qquad\quad(\lambda f_k.f_k\;
 (\lambda ().\mathit{withSubCont_c}\; 0\; \\
\qquad\qquad\qquad\qquad\qquad\qquad\quad\;
 \lambda k_a.\lambda k. k \Braket{k_a, v_a}) \\
\qquad\qquad\qquad\quad\qquad\qquad\!\!k_3)) \\
\qquad\qquad\qquad k_2) \\
      \end{array}  \\ \\

      \Lambda |[ t_1\;t_2 |] =  
      \begin{array}[t]{@{}l@{}}
\lambda k_1.\mathit{pushPrompt_c}\; 0\; \Lambda |[ t_1 |] \\
\qquad(\lambda\Braket{k_a,v_a}\!. \\
\qquad\quad\mathit{pushSubCont_c}\; k_a \\
\qquad\qquad(\lambda k_2. \\
\qquad\qquad\quad\mathit{newPrompt_c} \\
\qquad\qquad\qquad\lambda x_p.\mathit{pushPrompt_c}\; x_p\; (v_a\; x_p)  \\
\qquad\qquad\qquad\qquad\quad
(\lambda f_k.f_k\; (\lambda (). \Lambda |[ t_2 |])\; k_2)) \\
\qquad\qquad k_1) \\
      \end{array} \\ \\

      \Lambda |[ \lambda x.t |]  = 
      \begin{array}[t]{@{}l@{}}
\mathit{withSubCont_c}\;0 \;\lambda k_a.\lambda k. k
 \braket{k_a, \lambda x. \Lambda \Lbrack t \Rbrack} \\ 
      \end{array} 
  \end{boxedarray}
  
   \caption{Denotations for Terms}
  \label{fig:cbn-denote-term}
\end{figure}



Denotations of machine configurations are constructed from their components:
the configuration's focus , context , and list of names .  A machine
configuration denotes the translation of its focus applied to three arguments:
the base continuation  as its starting continuation, the denotation
of its context, bounded by the redex delimiter , as the metacontinuation,
and the size  of  plus 1 as its initial prompt.  The redex
delimiter attached to the metacontinuation handles the case when an answer
subsumes the entire context by returning the answer as the result.  The
denotation of the terminal machine configuration  is
treated separately to show how it corresponds directly to a final answer.

\begin{figure}[t]
  \centering\small
  \begin{boxedarray}{@{}l@{}}
      \iota (x_i,X) = \iota(x_i,[x_1,x_2,\dots,x_i,\dots,x_n])  =  i  \\ \\
      \lvert X \rvert = \lvert [x_1,x_2,\dots,x_i,\dots,x_n] \rvert  =  n  \\ \\
      \Lambda |[\Braket{X|E,?}_c |]  = 
      \mathcal{D}|[ ? |]_X \; \kappa_0 \; (\mathcal{D}|[ E |]_X ++ (0:[\;])) \;
      (\lvert X \rvert + 1)  \quad c\in\set{d,f,b,n} \\ \\
      \Lambda |[\Braket{X|\answer{E,\lambda x.t}}|] = 
      \braket{\mathcal{D}|[ E |]_X,\lambda x.\mathcal{D}|[ t |]_X}

    \end{boxedarray}
   \caption{Denotations for Names and Configurations}
  \label{fig:cbn-denote-misc}
\end{figure}

Our semantic translation takes advantage of  being a proper list of unique
names.  Free active variables denote prompts in our translation, and since 
is the redex delimiter, we assign to each variable its -based index in .
We use  as the global prompt counter to ensure that no
future prompts conflict with the current active variable denotations, thereby
guaranteeing hygiene (see Section~\ref{sec:hygiene}).


Each evaluation context frame denotes a two-element metacontinuation consisting
of a prompt and a proper continuation.  The prompt for a binder frame is the
prompt translation  of the bound variable .  The cont and
operand frames have redex prompts~.  These prompts guarantee that answer
building operations will arrive at the innermost redex.  Each continuation
function specializes a subexpression of the CPS translation for terms
 with the denotations of the context frame's parts.  Compare, for
instance, the denotation of an application, , to that of an operand
frame, .  The application term pushes the global prompt, and
executes  in the context of a continuation that receives an answer
.  The denotation of the operand frame is a metacontinuation
containing the same prompt and continuation.


\begin{figure}[ht]
  \centering\small
  \begin{boxedarray}{@{}l@{}}

    \mathcal{D}|[ E \comp [f] |]_X  =
    \mathcal{D}|[[f]|]_X ++ \mathcal{D}|[E|]_X  \\ \\

    \mathcal{D}|[ [\;] |]_X  =  [\;]  \\ \\

    \mathcal{D}|[ [\#] |]_X  =  \kappa_0:[\;]  \\ \\

    \mathcal{D}|[ [[]\; t_2] |]_X  =   0 : k' : [\;]  \\
        \text{where } k' = 
      \begin{array}[t]{@{}l@{}}
\lambda\Braket{k_a,v_a}\!. \\
\quad\mathit{pushSubCont_c}\; k_a \\
\qquad(\lambda k_2. \\
\qquad\quad\mathit{newPrompt_c} \\
\qquad\qquad\lambda x_p.\mathit{pushPrompt_c}\; x_p\; (v_a\; x_p)  \\
\qquad\qquad\qquad\quad(\lambda f_k.f_k\; (\lambda (). \mathcal{D}|[ t_2 |]_X)\; k_2)) \\
\qquad \kappa_0
      \end{array}  \\ \\ 

      \mathcal{D}|[ [(\lambda x.[])\; t_2] |]_X  =  \iota(x,X) : k' : [\;]  \\
        \text{where } k' = 
      \lambda f_k.f_k\; (\lambda (). \mathcal{D}|[ t_2 |]_X)\; \kappa_0 \\ \\



      \mathcal{D}|[ [(\kappa x.E)\;[]] |]_X  =   0 : k' : [\;]  \\
        \text{where } k' = \\
      \begin{array}[t]{@{}l@{}}
\;\lambda \Braket{k_a,v_a}\!.\\
\quad \mathit{pushSubCont_c}\; k_a \\
\qquad(\lambda k_3.\\
\qquad\;\:\mathit{pushPrompt_c}\; \iota(x,X) \\
\qquad\quad(\mathit{pushSubCont_c}\; \mathcal{D}|[E|]_X \\
\qquad\qquad(\mathit{withSubCont_c}\; 0\; 
\lambda k_a. \lambda k. k \Braket{k_a, v_a})) \\
\qquad\quad(\lambda f_k.f_k\;
 (\lambda ().\mathit{withSubCont_c}\; 0\;
\lambda k_a.\lambda k. k \Braket{k_a, v_a}) \\
\qquad\quad\qquad\qquad\!\!k_3)) \\
\qquad \kappa_0
      \end{array}

  \end{boxedarray}
  
   \caption{Denotations for Evaluation Contexts}
  \label{fig:cbn-denote-context}
\end{figure}




A redex denotes a CPS'ed term that closes over the denotations of its
constituents and implements the corresponding reduction step.

\begin{figure}
  \centering\small
  \begin{boxedarray}{@{}l@{}}
      \mathcal{D}|[ (\kappa x_1.E_1)\;\answer{E_2,\lambda x_2.t} |]_{X}  = \\
      \begin{array}[t]{@{}l@{}}
 \mathit{pushSubCont_c}\; \mathcal{D}|[ E_2 |]_X \\
\quad(\lambda k_3.\\
\quad\;\:\mathit{pushPrompt_c}\; \iota(x_1,X) \\
\quad\quad(\mathit{pushSubCont_c}\; \mathcal{D}|[ E_1 |]_X \\
\quad\qquad(\mathit{withSubCont_c}\; 0\; 
\lambda k_a. \lambda k. k \Braket{k_a, \lambda x_2.\Lbrack t \Rbrack_X})) \\
\qquad(\lambda f_k.f_k\;
 (\lambda ().\mathit{withSubCont_c}\; 0\;
\lambda k_a.\lambda k. k \Braket{k_a, \lambda x_2.\Lbrack t \Rbrack_X}) \\
\qquad\qquad\qquad\!\!k_3)) \\
      \end{array}  \\ \\

      \mathcal{D}|[ \answer{E,\lambda x.t_1}\;t_2 |]_X  =  \\
      \begin{array}[t]{@{}l@{}}
\mathit{pushSubCont_c}\; \mathcal{D}|[ E |]_X \\
\quad(\lambda k_2. \\
\quad\quad\mathit{newPrompt_c} \\
\quad\qquad\lambda x_p.\mathit{pushPrompt_c}\; x_p\;
((\lambda x.\mathcal{D}|[ t_1 |]_X)\; x_p)  \\
\quad\qquad\qquad\quad
(\lambda f_k.f_k\; (\lambda (). \mathcal{D}|[ t_2 |]_X)\; k_2)) \\
      \end{array} 
  \end{boxedarray}
  
   \caption{Denotations for Redexes}
  \label{fig:cbn-denote-redex}
\end{figure}






\topic{small modifications to the machine semantics to facilitate proving}
To facilitate our proof of correctness, we make a slight change to the machine
semantics.  In the machine, composing an empty context with the current
context is an identity operation.  The continuation semantics do not share
this property.  During execution, an empty continuation is denoted by the base
continuation .  If a continuation is captured or pushed in the
context of an empty continuation, then the empty continuation will be captured
as part of the metacontinuation or pushed onto the current metacontinuation
before reinstating the pushed continuation.  In short, the call-by-need machine
semantics guarantees that , but the continuation semantics do
not prove that .  Dybvig et al. discuss the notion of
proper tail recursion for delimited continuations.  Their operational
characterization of proper tail recursion corresponds to the latter equation.


To remove this mismatch, we add a \emph{ghost} frame  to our definition
of evaluation contexts.  The ghost frame denotes the metacontinuation
.  We also extend the unplug operation on evaluation contexts
such that it discards ghost frames: .
Finally, we alter the right hand side of transition rules that grab and push
continuations to pair ghost frames with composed evaluation contexts in a
manner consistent with the continuation semantics. For instance, the updated
 rule is as follows\footnote{The exact placement of ghost frames falls
  right out of the correctness proof.}:

These modifications do not alter the observable behavior of the machine while
modeling the property that pushing empty frames has meaning in the
continuation semantics.  



Given these denotations, it is straightforward to prove correctness of the
simulation relative to the abstract machine.

\begin{thm}
  If  is a closed term, then
  .
\end{thm}
\begin{proof}

\end{proof}

\begin{thm}
  If  then .
\end{thm}
\begin{proof}
  By cases on .  The proof utilizes beta, eta and 
  equivalences to establish correspondences.
\end{proof}


\section{Simulating Extensions}

Many straightforward language extensions also have straightforward simulations
under the above model.

Simulating  bindings essentially performs the same operations as
immediately applying a lambda abstraction.  

In contrast to the application rule, the variable  is directly assigned a
fresh prompt, rather than binding it to an auxiliary variable .  The body
of the let can be interpreted in place and substitution of the prompt is
implicit since  is already free in .

The translation for basic constants is analogous to that for lambda
abstractions:  the constant must be returned to the next redex.

For this translation, we assume that the call-by-value language provides
the same constants as the call-by-need language.

The translation for function constants is as follows:

Interpreting a function constant application forces its argument and then
acts on the value that is ultimately produced.  Since function expressions
yield values, the result is immediately returned.

The translation for  acquires two fresh prompts, uses them to
delay the argument to , and stores them as a pair.


The translations for  and  evaluate their
argument, retrieve a prompt from the resulting pair, and demand its value.






\section{Conclusions}


In this paper, we expose and examine the operational structure of lazy
evaluation as embodied in call-by-need semantics.  We present this
understanding in two ways: as an abstract machine whose operational behavior
involves control capture, and as a simulation of call-by-need under
call-by-value plus delimited control operations. Delimited control can be
used to simulate a global heap, but our particular simulation uses delimited
control operations to manage laziness locally, just like the calculus reduction
rules.

The artifacts of this investigation provide new tools for increasing our
understanding of lazy evaluation and its connections to control.  The abstract
machine could be used to establish connections to heap-based implementations of
call-by-need, and possibly modern graph-reduction based
formulations~\cite{peytonjones89spineless}.  In fact it seems that the calculus
and abstract machine may point out new structural and dynamic invariants that
are inherent to call-by-need evaluation but are hidden in the unstructured
representations of heaps.

The abstract machine and simulation might also provide new opportunities for
reasoning about the correctness of transformations applied to call-by-need
programs.  Surely the calculus provides the same equational reasoning powers as
the abstract machine.  However the machine may enable researchers to more
easily conceive transformations and justifications that are not as easy to
recognize in the reduction semantics.  Our simulation might be connected to
that of~\citet{OKASAKI94}.  The simulation might suggest new mechanisms by
which to embed call-by-need evaluation within call-by-value programs.

One significant difference between the two formulations of call-by-need lambda
calculi~\cite{maraist98need,ariola97need} is the status of variables.  Maraist
et al. consider variables to be values, whereas Ariola and Felleisen do not.
Ultimately, \citet{maraist98need} prove standardization against a
standard-order relation that does not consider variables to be values.  This
paper sheds no light on the inclusion of variables among the values, however it
demonstrates in stark detail the consequences of the latter design.  In the
abstract machine, the transition rules for lambda terms, namely the rebuild
rules, differ significantly from the transition rules for variables, the need
rules.  A similar distinction can be seen simply by observing the complexity of
their respective translations.  In short, our semantics interpret variables as
memoized computations rather than values.  Variables can be treated as 
values under deterministic call-by-value and call-by-name reduction; it remains
an open question whether the same could be achieved for call-by-need and if so
what its operational implications would be.


Our results reveal that a proliferation of semantic frameworks---reduction
semantics, machine semantics, etc---is a boon and not a crisis.  The reduction
semantics of call-by-need elegantly and mysteriously encode a rich semantics
whose broad implications can be seen in equivalent machine semantics and
continuation semantics.  As such, our work provides new perspectives from which
to reason about call-by-need, delimited control, and their respective
expressive powers.















\section{Acknowledgements}
We thank Daniel P. Friedman, Roshan James, William Byrd, Michael Adams, and the
rest of the Indiana University Programming Languages Group, as well as Jeremy
Siek, Zena Ariola, Phil Wadler, Olivier Danvy, and anonymous referees for
helpful discussions and feedback on this work.

\bibliographystyle{acmtrans}
\bibliography{need}



\end{document}
