\documentclass[preprint,12pt]{elsarticle}

\usepackage{yhmath}
\usepackage{url}
\usepackage{amssymb,wasysym}
\setcounter{tocdepth}{3}
\usepackage{graphicx}
\usepackage{wrapfig}
\usepackage{subfig}
\usepackage{color}
\usepackage{multirow}
\usepackage{epstopdf}
\usepackage[colorlinks=true]{hyperref}
\usepackage[usenames,dvipsnames]{xcolor,colortbl}
\usepackage[margin=1.2in]{geometry} 
\usepackage{lscape}




\def\rknn{\mbox{RNN}}
\def\r1nn{\mbox{RNN}}
\def\knng{\mbox{-NNG}}
\def\ksyg{\mbox{-SYG}}
\def\1syg{\mbox{-SYG}}


\newcommand{\etal}{\emph{et~al.}}
\newcommand{\ie}{\emph{i.e.}}
\newcommand{\eg}{\emph{e.g.}}


\graphicspath{{Images/}}

\newtheorem{theorem}{Theorem}[section]
\newtheorem{lemma}{Lemma}[section]
\newproof{proof}{Proof}
\newtheorem{remark}{Remark}
\newtheorem{observation}{Observation}[section]
\newtheorem{corollary}{Corollary}[section]
\newtheorem{definition}{Definition}[section]


\journal{Comput. Geom. Theory Appl.}

\begin{document}
\begin{frontmatter}


\title{Kinetic -Semi-Yao Graph and its Applications~\tnoteref{t1}}



\author{Zahed Rahmati\corref{cor1}}
\ead{zahedrahmati@gmail.com}

\author[rvt2]{Mohammad Ali Abam}
\ead{abam@sharif.edu}

\author[rvt1]{Valerie King}
\ead{val@uvic.ca}

\author[rvt1]{Sue Whitesides}
\ead{sue@uvic.ca}


\tnotetext[t1]{Preliminary versions of parts of this paper appeared in \textit{Proceedings of the 26th Canadian Conference on Computational Geometry} (CCCG 2014)~\cite{DBLP:journals/corr/RahmatiA13} and \textit{Proceedings of the 25th International Workshop on Combinatorial Algorithms} (IWOCA 2014)~\cite{RahmatiKW14_IWOCA14}.}


\cortext[cor1]{Corresponding author}

\address[rvt2]{Dept. of Computer Engineering, Sharif University of Technology, Tehran, Iran.}
\address[rvt1]{Dept. of Computer Science, University of Victoria, Victoria, Canada.}



\begin{abstract}
This paper introduces a new proximity graph, called \textit{the -Semi-Yao graph} (\ksyg), on a set  of points in , which is a supergraph of the -nearest neighbor graph (\knng) of . We provide a kinetic data structure (KDS) to maintain the \ksyg~on moving points, where the trajectory of each point is a polynomial function whose degree is bounded by some constant. Our technique gives the first KDS for the theta graph (\ie, \1syg) in . It generalizes and improves on previous work on maintaining the theta graph in~. 

As an application, we use the kinetic \ksyg~to provide the \textit{first} KDS for maintenance of all the -nearest neighbors in , for any . Previous works considered the  case only.

Our KDS for all the -nearest neighbors is \textit{deterministic}. The best previous KDS for all the -nearest neighbors in  is \textit{randomized}. Our structure and analysis are simpler and improve on this work for the  case. We also provide a KDS for all the -nearest neighbors, which in fact gives better performance than previous KDS's for maintenance of all the exact -nearest neighbors.

As another application, we present the \textit{first} KDS for answering \textit{reverse} -nearest neighbor queries on moving points in , for any .
\end{abstract}
\begin{keyword}
-nearest neighbors, reverse -nearest neighbor queries, kinetic data structure, continuous monitoring, continuous queries
\end{keyword}

\end{frontmatter}
\section{Introduction}
The physical and virtual worlds around us are full of moving objects, including players in multi-player game environments, soldiers in a battlefield, tourists in foreign environments, and mobile devices in wireless ad-hoc networks. The problems that deal with attributes  (\eg, closest pair) of sets of objects arising from the distances between objects are known as \textit{proximity problems}.  Considering (kinetic version of) a proximity problem on moving objects in order to solve a proximity problem is called a \textit{kinetic proximity problem}.

The maintenance of attributes of sets of moving points has been studied extensively over the past 15 years; see~\cite{rahmati2014simple} and references therein. A basic framework for this study, which is described in Section~\ref{sec:KDSframework}, is that of a kinetic data structure (KDS) which is in fact a set of data structures and algorithms to track the attributes of moving points. We consider some  fundamental proximity problems, which are stated in Section~\ref{sec:ProbStatment}, in this standard KDS model.

\subsection{Problem Statement}\label{sec:ProbStatment}
Let  be a set of  points in , where  is arbitrary but fixed. Finding the -nearest neighbors to a query point, which is called the \textit{-nearest neighbor} problem, is fundamental in computational geometry. The \textit{all -nearest neighbors} problem, a variant of the -nearest neighbor problem, is to find the -nearest neighbors to each point . Given any , the \textit{all -nearest neighbors} problem is to find some  for each point , such that the Euclidean distance  between  and  is within a factor of  of the Euclidean distance between  and its nearest neighbor. The graph constructed by connecting each point  to its -nearest neighbors is called the \textit{-nearest neighbor graph} (\knng). The \textit{closest pair} problem is to find the endpoints of the edge in the -NNG whose separation distance is minimum. 
The \textit{theta graph} is a well-studied sparse proximity graph~\cite{Clarkson:1987:AAS:28395.28402,Keil:1988:ACE:61764.61787}. This graph is constructed as follows. Partition the space around each point  into  polyhedral cones , . In each cone , a vector  is chosen as the cone axis. Then connect the point  to a particular point inside each cone , where the particular point is the element of  with minimum length projection on ~\footnote{By treating  as a parameter of the theta graph, one can obtain an important class of sparse graphs, called \textit{t-spanners}, with different stretch factors ~\cite{DBLP:journals/corr/BoseCMRV14}.}.

The \textit{reverse -nearest neighbor} (\rknn) problem is a variant of the -nearest neighbor problem that asks for the influence of a query point on a point set . Unlike the -nearest neighbor problem, the exact number of reverse -nearest neighbors of a query point is not known in advance, but as we prove in Lemma~\ref{the:RkNNsUprBnd} the number is upper-bounded by . The \rknn~problem is formally defined as follows: Given a query point , find the set  of all  in  for which  is one of -nearest neighbors of . Thus , where  denotes Euclidean distance, and  is the  nearest neighbor of  among the points in .

\subsection{KDS Framework}\label{sec:KDSframework}
Basch, Guibas, and Hershberger~\cite{Basch:1997:DSM:314161.314435} introduced the \textit{kinetic data structure framework} to maintain attributes (\eg, closest pair) of moving points. In the kinetic setting, we assume each coordinate of the trajectory of a point  is a polynomial function of degree bounded by some constant . The correctness of an attribute over time is determined based on correctness of a set of \textit{certificates}. A certificate is a boolean function of time, and its \textit{failure time} is the next time after the current time at which the certificate will become invalid. When a certificate fails, we say that an \textit{event} occurs. Using a \textit{priority queue} of the failure times of the certificates, we can know the next time after the current time that an event occurs. When the failure time of the certificate with highest priority in the priority queue is equal to the current time we invoke the update mechanism to reorganize the data structures and replace the invalid certificates with new valid ones. 

To analyse the performance of a KDS there are four standard criteria. A KDS distinguishes between two types of events: \textit{external events} and \textit{internal events}. An event that changes the desired attribute itself is called an external event, and those events that cause only some internal changes in the data structures are called internal events. If the ratio between the  worst-case number of internal events in the KDS to the worst-case number of external events is , the KDS is \textit{efficient}. If the response time of the update mechanism to an event is , the KDS is \textit{responsive}. The compactness of a KDS refers to size of the priority queue at any fixed time: if the KDS uses  certificates, it is \textit{compact}. The KDS is \textit{local} if the number of certificates associated with any point at any fixed time is . The locality of a KDS is an important criterion; if a KDS is local, it can be updated quickly when a point changes its trajectory.

\subsection{Related Work}\label{sec:RelatedWork}
\paragraph{Stationary setting.} 
For a set  of  stationary points, the closest pair problem can be solved in  time~\cite{4567872,Bentley:1976:DMS:800113.803652}. There is also a linear-time randomized algorithm to find the closest pair~\cite{FSHJ1078}. One can report all the -nearest neighbors in time ~\cite{Vaidya:1989:ONL:70530.70532}. For any , all the -nearest neighbors can be reported in time ~\cite{Dickerson:1996:APP:236464.236474}, in order of increasing distance; reporting the unordered set takes time ~\cite{Callahan366854,Clarkson:1983:FAN:1382437.1382825,Dickerson:1996:APP:236464.236474}. 


The reverse -nearest neighbor problem was first posed by Korn and Muthukrishnan~\cite{Korn:2000:ISB:342009.335415}  in the database community, where it was then considered extensively due to its many applications in, for example, decision support systems, profile-based marketing, traffic networks, business location planning, clustering and outlier detection, and molecular biology~\cite{Kumar:2008:EAR:1463434.1463483,DBLP:conf/sdm/LinED08}. In computational geometry, there exist two data structures~\cite{MaheshwariVZ02cccg2002,CheongIJCGA2011} that give solutions to the \rknn~problem. Both of these solutions only work for . Maheshwari~\etal~\cite{MaheshwariVZ02cccg2002} gave a data structure to solve the \r1nn~problem in . Their data structure uses  space and  preprocessing time, and an \r1nn~query can be answered in time . Cheong~\etal~\cite{CheongIJCGA2011} considered the \r1nn~problem in , where . Their method gives the same complexity as that of~\cite{MaheshwariVZ02cccg2002}~\footnote{It seems that the approach by Cheong~\etal~can be extended to answer \rknn~queries, for any , with preprocessing time , space , and query time .}.

\paragraph{Kinetic setting.}
For a set of  moving points in , where each trajectory of a point is a polynomial function of degree bounded by constant , Basch, Guibas, and Hershberger~\cite{Basch:1997:DSM:314161.314435} provided a KDS for maintenance of the closest pair. Their KDS uses linear space and processes  events, each in time . Here,  is an extremely slow-growing function.



Basch, Guibas, and Zhang~\cite{Basch:1997:PPM:262839.262998} used multidimensional range trees to maintain the closest pair in . For a fixed dimension , their KDS uses  space and processes  events, each in worst-case time . Their KDS is responsive, efficient, compact, and local.

Using multidimensional range trees, Agarwal, Kaplan, and Sharir (TALG'08)~\cite{Agarwal:2008:KDD:1435375.1435379} gave KDS's both for maintenance of the closest pair and for all the -nearest neighbors in . The closest pair KDS by Agarwal~\etal~uses  space and processes  events, each in amortized time ; this KDS is efficient, amortized responsive, local, and compact. Agarwal~\etal~gave the first efficient KDS to maintain all the -nearest neighbors in . For the efficiency of their KDS, they implemented range trees by using randomized search trees (treaps). Their \textit{randomized} kinetic approach uses  space and processes  events; the expected time to process all events is . Their all -nearest neighbors KDS is efficient, amortized responsive, compact, but in general is not local.

Rahmati, King, and Whitesides~\cite{Rahmati2014} gave the first KDS for maintenance of the theta graph in . Their method uses a constant number of kinetic Delaunay triangulations to maintain the theta graph. Their theta graph KDS uses linear space and processes  events with total processing time . Using the kinetic theta graph, they improved the previous KDS by Agarwal~\etal~to maintain all the -nearest neighbors in . In particular, their \textit{deterministic} kinetic algorithm, which is also arguably simpler than the randomized kinetic algorithm by Agarwal~\etal, uses  space and processes  events with total processing time . With the same complexity as their KDS for maintenance of all the -nearest neighbors, they maintain the closest pair over time. Their KDS's for maintenance of the theta graph, all the -nearest neighbors, and the closest pair are efficient, amortized responsive, compact, but in general are not local.

The reverse -nearest neighbor queries for a set of continuously moving objects has attracted the attention of the database community (see~\cite{Cheema:2012:CRK:2124885.2124903} and references therein). To our knowledge there is no previous solution to the kinetic \rknn~problem in the literature.
\subsection{Our Contributions}\label{sec:Contributions} 
We introduce a new sparse proximity graph, called the \textit{-Semi-Yao graph} (\ksyg), and then maintain the \ksyg~for a set of  moving points, where the trajectory of each point is a polynomial function of at most constant degree . We use a constant number of range trees to apply necessary changes to the \ksyg~over time. We prove that the edge set of the \ksyg~includes the pairs of the -nearest neighbors as a subset. This enables us to easily provide the \textit{first} kinetic solutions in  for maintenance of all the -nearest neighbors, and then, as another first, to answer \rknn~queries on moving points, for any .

Our KDS for maintenance of the \1syg~(\ie, theta graph), in fixed dimension , uses  space and processes  events with total processing time .  The KDS is compact, efficient, amortized responsive, and it is local. Our KDS generalizes the previous KDS for the \1syg~by Rahmati~\etal~\cite{Rahmati2014} which only works in . Also, our kinetic approach yields improvements on the previous KDS for maintenance of the \1syg~by Rahmati~\etal~\cite{Rahmati2014}: Our KDS is local, but their KDS is not;  in particular, each point in our KDS participates in  certificates, but in their KDS each point participates in  certificates. Also, our KDS handles  events, but their KDS handles  events in .

Our KDS for maintenance of all the -nearest neighbors uses  space and processes ) events; the total processing time to handle all the events is .  Our KDS is compact, efficient, amortized responsive, but it is not local in general. For each point  in the \1syg~we construct a tournament tree to maintain the edge with minimum length among the edges incident to the point . Summing over elements of all the tournament trees in our KDS is linear in , which leads to the total number of events , which is \textit{independent} of . Our \textit{deterministic} method improves with simpler structure and analysis of the previous \textit{randomized} kinetic algorithm by Agarwal~\etal~\cite{Agarwal:2008:KDD:1435375.1435379}: The expected total size of the tournament trees in their KDS for all -nearest neighbors is ; thus their KDS processes  events, which depends on . Also, we improve their KDS by a factor of  in the total cost. Furthermore, on average, each point in our KDS participates in  events, but in their KDS each point participates in  events.

For maintaining all the -nearest neighbors, neither our KDS nor the KDS by Agarwal~\etal~is local in the \textit{worst-case}, and furthermore, each event in our KDS and in their KDS is handled in a polylogarithmic \textit{amortized} time. To satisfy the locality criterion and to get a worst-case processing time for handling events, we provide a KDS for all the -nearest neighbors. In particular, for each point  we maintain some point  such that , where  is the nearest neighbor of  and  is the Euclidean distance between  and . This KDS uses  space, and handles  events, each in worst-case time ; it is compact, efficient, responsive, and local.




To answer an \rknn~query for a query point  at any time , we partition the -dimensional space into a constant number of cones around , and then among the points of  in each cone, we examine the  points having shortest projections on the cone axis. We obtain  candidate points for  such that  might be one of their -nearest neighbors at time . To check which if any of these candidate points is a reverse -nearest neighbor of , we maintain the  nearest neighbor  of each point  over time. By checking whether  we can easily check whether a candidate point  is one of the reverse -nearest neighbors of  at time . Given a KDS for maintenance of all the -nearest neighbors, an \rknn~query can be answered at any time  in  time. Note that if an event occurs at the same time , we first spend amortized time  to update all the -nearest neighbors, and then we answer the query.

Table~\ref{tab:AllResults} summarizes all the (previous and new) results for the kinetic proximity problems.  In this table, ``Dim.", ``Num.", and ``Proc." stand for ``Dimension", ``Number", and ``Processing", respectively. Here,  is an extremely slow-growing function, and  is the complexity of the -level, which are defined in Theorems~\ref{the:totallyDFcomplexity} and~\ref{the:k_levelComplexity}, respectively.

\begin{landscape}
\begin{table}
\centering
\begin{tabular}{|l|c|c|c|c|c|} \hline
\textsl{Kinetic problem} & \textsl{Dim.} & \textsl{Space} & \textsl{Num. of events} & \textsl{Proc. time} & \textsl{Local} \\ \hline
      Closest pair~\cite{Basch:1997:DSM:314161.314435}  &   &   &     &     /event  &   Yes   \\ \hline
      Closest pair~\cite{Basch:1997:PPM:262839.262998} &  &   &     &    /event  &   Yes   \\ \hline
      Closest pair~\cite{Agarwal:2008:KDD:1435375.1435379} &   &   &     &    /event  &   Yes   \\ \hline
      Closest pair~\cite{Rahmati2014} &  &   &     &     &   No   \\ \hline            
      All -NNs~\cite{Agarwal:2008:KDD:1435375.1435379} &   &   &     &     &   No   \\ \hline
      All -NNs~\cite{Rahmati2014} &  &   &     &     &   No   \\ \hline 
      All -NNs~[Here] &   &   &     &      &   No   \\ \hline       
      All -NNs [Here] &   &   &     &    /event &   Yes   \\ \hline   
     All -NNs~[Here] &   &   &     &    &   No   \\ \hline
      \1syg~\cite{Rahmati2014} &   &   &     &     &   No   \\ \hline 
      \1syg~[Here] &   &   &     &     &   Yes   \\ \hline
\end{tabular}
\caption{The previous results and our results for kinetic proximity problems.}
\label{tab:AllResults}
\end{table}
\end{landscape}
\subsection{Outline}\label{sec:Outline} 
In Section~\ref{sec:Preliminaries}, we describe the necessary background and review the theorems that we use throughout this paper. Section~\ref{sec:Relationship} provides key lemmas, and in fact introduces a new supergraph, namely the \textit{-Semi-Yao graph} (\ksyg), of the \knng. Section~\ref{sec:ReportKNNs} shows how to construct the \ksyg~and report all the -nearest neighbors. Section~\ref{sec:kineticKSYG} gives a kinetic approach for maintenance of the . Section~\ref{sec:applications}  provides two applications of the kinetic : maintenance of all the -nearest neighbors, and answering \rknn~queries on moving points. Section~\ref{sec:KineticEpsANN} shows how to maintain all the -nearest neighbors. Section~\ref{sec:conclusion} concludes.

\section{Preliminaries}\label{sec:Preliminaries}
\paragraph{Partitioning space around the origin.}
Let  be a unit vector in  with apex at the origin , and let  be a constant. We define an \textit{infinite right circular cone} with respect to  and  to be the set of points  such that the angle between  and  is at most ; Figure~\ref{fig:circularCone}(a) depicts an infinite right circular cone in . We define a \textit{polyhedral cone} of opening angle  with respect to  to be the intersection of  half-spaces such that the intersection is contained in an infinite right circular cone with respect to  and , and such that all the half-spaces contain the origin ; Figure~\ref{fig:circularCone}(b) depicts a polyhedral cone in , which is contained in the infinite right circular cone of Figure~\ref{fig:circularCone}(a). The angle between any two rays inside a polyhedral cone of opening angle  emanating from  is at most .

\begin{figure}[t!]
\centering
\includegraphics[scale=1]{ch6_circularCone.eps}
\caption{An infinite right circular cone and a polyhedral cone.}
\label{fig:circularCone}
\end{figure}

\begin{lemma}{\tt \cite{Abam:2011:KSX:1971362.1971367}}\label{the:NumofPolyCones}
The -dimensional space around a point can be covered by a collection of  interior-disjoint polyhedral cones of opening angle .
\end{lemma}

\paragraph{Kinetic rank-based range tree (RBRT).} Let  be a set of polyhedral cones of opening angle  with their apex at the origin  that together cover . Denote by  the bounding half-spaces  of , . Let  be the normal to , . Figure~\ref{fig:aConeC_l}(a) depicts  and  for the half-spaces  and  of a polyhedral cone  in . Let  denote the translated copy of  with apex at ; see Figure~\ref{fig:aConeC_l}(b). 

\begin{figure}[t!]
\begin{center}
\includegraphics[scale=1]{aConeC_l.eps}
\end{center}
\caption{(a) The cone  in  is bounded by  and . The coordinate axes  and  are orthogonal to  and . (b) A translation of  that moves the apex to .}
\label{fig:aConeC_l}
\end{figure}

Consider a set  of moving points. Using a \textit{kinetic range tree} data structure, one can process the moving points in  such that the points of  inside a query range can efficiently be reported at any time . By creating a kinetic range tree data structure  for the polyhedral cone , one can report the points in  for a query range  at time . 

Abam and de Berg~\cite{Abam:2011:KSX:1971362.1971367} introduced a variant of range trees, a \textit{rank-based range tree} (RBRT), that avoids rebalancing the range tree and gives a polylogarithmic worst-case processing time when an event occurs. Similar to a regular range tree (see~\cite{Berg:2008:CGA:1370949}), the points at level  of an RBRT , which is an RBRT corresponding to , are sorted at the leaves in ascending order according to their -coordinates. The skeleton of an RBRT  is independent of the position of the points in  and depends on the \textit{ranks} of the points in each of the -coordinates. The rank of a point in a tree at level  of the RBRT  is its position in the sorted list of all the points ordered by their -coordinates. Any tree at any level of the RBRT  is a balanced binary tree, and no matter how many points are in the tree, it is a tree on  ranks. The following gives the complexity of an RBRT .

\begin{theorem}\label{the:RBRTcomplexity}{\tt \cite{Abam:2011:KSX:1971362.1971367}}
An RBRT  uses  storage and can be constructed in  time. It can be described as a set of pairs  with the following properties. 
\begin{itemize}
\item Each pair  is generated from an internal node or a leaf node of a tree at level  of .
\item For any two points  and  in  where , there is a unique pair  such that  and .
\item For any pair , if  and , then  and . Here,  is the reflection of  through , which is intuitively formed by following the lines through  in the half-spaces of .
\item Each point  is in  pairs of , which implies that the number of elements of all the pairs  is .
\item For any point , all the sets  (resp. ), where  (resp. ), can be found in time .
\item The set  (resp. ) of points is the union of  sets  (resp. ), where the subscript  is such that  (resp. ). 
\end{itemize}
For a set of  moving points, where the trajectories are given by polynomials of degree bounded by a constant, the RBRT  can be maintained by processing  events, each in worst-case time .
\end{theorem}


\paragraph{Complexity of the -level.} Consider a set of  moving points, where the -coordinate  of each point  is a polynomial function of at most constant degree . The \textit{-level} of these polynomial functions is a set of points  such that each point  lies on a polynomial function, and such that it is above exactly  other polynomial functions; Figure~\ref{fig:k_level} depicts the -level and breakpoints on the -level of four polynomials. The -level tracks the  lowest point with respect to -axis.

Theorem~\ref{the:totallyDFcomplexity} gives the complexity of the -level (\ie, the number of breakpoints on the lower envelope) for a set of polynomial functions.  

\begin{theorem}\label{the:totallyDFcomplexity}{\tt \cite{Pettie:2013:SBD:2493132.2462390,Agarwal:1995:DSG:868483}}
The number of breakpoints on the -level of  totally-defined (resp. partially-defined), continuous, univariate  functions, such that each pair of them intersects at most  times, is at most  (resp. ). The sharp bounds on  are as follows:


here  and   denotes the inverse Ackermann function.
\end{theorem}

\begin{figure}[h]
\centering
\includegraphics[scale=1]{ch2_k_level.eps}
\caption{The -level of a set of four moving points.}
\label{fig:k_level}
\end{figure}

The following theorem gives the current bounds on the complexity of the -level.

\begin{theorem}\label{the:k_levelComplexity}{\tt \cite{AACS1998,chanii2005,Chan:2008:LAC:1377676.1377691,SharirM1991}}
The complexity of the -level of a set of  partially-defined polynomial functions, such that each pair of them intersects at most  times, is as follows:

A bound  of  can be converted to the -sensitive bound . The complexity of the -level is . \end{theorem}
\paragraph{Maintaining the  lowest point.} Assume we want to maintain the \textit{ lowest point} with respect to the -axis among a set  of moving points, where insertions and deletions into the point set  are allowed; the -coordinates of newly inserted points are polynomials of degrees bounded by some constant . 

Using a (dynamic and) \textit{kinetic tournament tree}, one can easily maintain the lowest point. The following summarizes the complexity of this data structure.

\begin{theorem}\label{the:KineticTT} {\tt (Theorem 3.1. of \cite{Agarwal:2008:KDD:1435375.1435379})}
Assume one is given a sequence of  insertions and deletions into a kinetic tournament tree whose maximum size at any time is  (assuming ). The tournament tree generates  events for a total cost of . Each point participates in  certificates, so each update/event can be handled in time . A kinetic tournament tree on  elements can be constructed in  time.  
\end{theorem}

To maintain the  lowest point (for any ) over time, we need to track the order of the moving points, so we use a (dynamic and) \textit{kinetic sorted list}. Each newly inserted point into a kinetic sorted list can exchange its order with other points at most  times.  Thus it is easy to obtain the following.

\begin{theorem}\label{the:KineticSL}
Given a sequence of  insertions and deletions into a kinetic sorted list whose maximum size at any time is . The kinetic sorted list generates  events. Each point participates in  certificates, so each update/event can be handled in time . A kinetic sorted list on  elements can be constructed in  time.  
\end{theorem}

\section{Key Lemmas: Relationships}\label{sec:Relationship}
Here we provide a key insight to obtain the relationships between the proximity problems that are stated in Section~\ref{sec:ProbStatment}.

Consider a polyhedral cone  with respect to , where   is a set of polyhedral cones of opening angle  with their apex at the origin  that together cover  (see Lemma~\ref{the:NumofPolyCones}). From now on, we assume that . Denote by  the cone axis of  (\ie, the vector in the direction of the unit vector  of , ; see Section~\ref{sec:Preliminaries}). Recall that  denote a translated copy of  with apex at . Denote by  the list of the points in , sorted by increasing order of their -coordinates.

\begin{lemma}\label{the:keyLemma2}
Let  be the  nearest neighbor of  among a set  of points in , and let  be the cone of  that contains . Then point  is among the first  points in .
\end{lemma}
\begin{proof}
Let . Then point  is the closest point to  among the points in ; see Figure~\ref{fig:ProofKeyLemma}(a). It can be proved by contradiction that point  has the minimum -coordinate among the points in  (Lemma 8.1 of~\cite{Agarwal:2008:KDD:1435375.1435379}): Assume there is a point  inside the cone  whose -coordinate is less than the -coordinate of ; see Figure~\ref{fig:ProofKeyLemma}(b) for an example where . Consider the triangle . Since  is the closest point to  among the points in , , which implies that angle . This is a contradiction, because  and .

Now we add the points , and   to the point set . Consider the worst case scenario that all these   points insert inside the cone , and that the -coordinates of all these points are less than the -coordinate of . Then the point  is still among the  first  points in the sorted list  .
\end{proof}

\begin{figure}[h]
\centering
\includegraphics[scale=1]{ProofKeyLemma.eps}
\caption{Point  is the  nearest neighbor of . After deleting the points  and , point  is the closest point to ; among the points in ,  has the minimum length projection on the bisector .}
\label{fig:ProofKeyLemma}
\end{figure}

Consider the \textit{-nearest neighbor graph} (\knng) of a point set , which is constructed by connecting each point in  to all its -nearest neighbors. Let  be the set of the first  points in the sorted list . If we connect each point  to the points in , for , we obtain what we call the \textit{-Semi-Yao graph}\footnote{Rahmati~\etal~\cite{Rahmati2014} called the theta graph the \textit{Semi-Yao graph} because of its close relationship to the Yao graph~\cite{DBLP:journals/siamcomp/Yao82}. Here, we call the generalization of the Semi-Yao graph, with respect to , the \textit{-Semi-Yao graph}.} (\ksyg). The \ksyg~has the following property. 

\begin{lemma}\label{the:NNGsubSYG}
The \knng~of a point set  in  is a subgraph of the \ksyg~of .
\end{lemma}
\begin{proof}
Lemma~\ref{the:keyLemma2} gives a necessary condition for  to be the  nearest neighbor of : , where  is such that .  Therefore, the edge set of the \ksyg~covers the edges of the \knng.
\end{proof}

Now we obtain the following, for answering \rknn~queries.

\begin{lemma}\label{the:RkNNsUprBnd}
The set of reverse -nearest neighbors of a query point  is a subset of the union of the sets , for . The number of reverse -nearest neighbors of the query point  is upper-bounded by .
\end{lemma}
\begin{proof}
Assume, among the points in , that  is the  nearest neighbor of some point , where . There exists a cone  of  such that . From Lemma~\ref{the:keyLemma2}, . Therefore, each of the -reverse nearest neighbors of  is in the union of , . 

We assume  is arbitrary but fixed, so  is a constant. Thus the cardinality of the union of  is , which implies that the number of reverse -nearest neighbors is upper-bounded by . 
\end{proof}
\section{Computing the \ksyg~and All -Nearest Neighbors}\label{sec:ReportKNNs}
Here we first describe how to compute the \ksyg, which will aid in understanding how our kinetic approach works. Then, via a construction of the \ksyg, we give a simple method for reporting all the -nearest neighbors. 

To efficiently construct the \ksyg, we need a data structure to perform the following operation efficiently: For each  and any of its cones , , find , the set of the first  points in the sorted list . Such an operation can be performed by using range tree data structures. For each cone , we construct an associated -dimensional range tree  as follows.


Consider a particular cone  with apex at ; see Figure~\ref{fig:aConeC_l}(a). The cone  is the intersection of  half-spaces   with coordinate axes .

The range tree  is a regular -dimensional range tree based on the -coordinates (see~\cite{Berg:2008:CGA:1370949}). The points at level  are sorted at the leaves according to their -coordinates. Any -dimensional range tree, \eg, , uses  space and can be constructed in time , and for any point , the points of  inside the query cone  whose sides are parallel to , , can be reported in time , where  is the cardinality of the set ~\footnote{For a set of stationary points, there are lots of improvements for answering rectangular range queries (\eg, see~\cite{Chan:2011:ORS:1998196.1998198}).}.

Now we add a new level to , based on the coordinate . To find  in an efficient time, we use the level  of , which is constructed as follows: For each internal node  at level  of , we create a list  sorted by increasing order of -coordinates of the points in . For the set  of  points in , the modified range tree , which now is a -dimensional range tree, uses  space and can be constructed in time ~\cite{Berg:2008:CGA:1370949}.
 
The following establishes the processing time for obtaining a set . 

\begin{lemma}\label{the:SortingLists}
Given , the set  can be found in time .
\end{lemma}
\begin{proof}
The set  is the union of  sets , where  ranges over internal nodes  at level  of . Consider the associated sorted lists . Given  sorted lists , the  point in  can be obtained in time  (Theorem 1 of~\cite{Frederickson1982197}). 

By examining the points in each of the  sorted lists whose -coordinates are less than or equal to the -coordinate of the  point, we can find the members of   in time .
\end{proof}


By Lemma~\ref{the:SortingLists}, we can find all the , for all . This gives the following.


\begin{corollary}\label{the:kSYG_Construction}
Using a data structure of size , the edges of the  of a set of  points in  can be reported in time .
\end{corollary}

Now we state and prove the cost of reporting all the -nearest neighbors in our approach, which in fact derives the known results in a new way~\footnote{For , both our data structure and the best previous data structure~\cite{Dickerson:1996:APP:236464.236474} have the same complexity for reporting all the -nearest neighbors. Arya~\etal~\cite{Arya:1998:OAA:293347.293348} have a kd-tree implementation to approximate the nearest neighbors of a query point that is in use by practitioners~\cite{10.1109/TVCG.2010.9} who have found it challenging to implement the theoretical algorithms~\cite{Vaidya:1989:ONL:70530.70532,Callahan366854,Clarkson:1983:FAN:1382437.1382825,Dickerson:1996:APP:236464.236474}. Since to report all the -nearest neighbors ordered by distance from each point our method uses multidimensional range trees, which can be easily implemented, we believe our method may be useful in practice.}.



\begin{theorem}\label{the:kNNG_Construction}
For a set of  points in , our data structure can report all the -nearest neighbors, in order of increasing distance from each point, in time . The data structure uses  space.
\end{theorem}
\begin{proof}
Suppose we are given the \ksyg~(see Corollary~\ref{the:kSYG_Construction}), which is a supergraph of the \knng~(from Lemma~\ref{the:NNGsubSYG}), and we want to report all the -nearest neighbors. 

Let  be the set of edges incident to the point  in the \ksyg. By sorting these edges in non-decreasing order according to their Euclidean lengths, which can be done in time , we can find the -nearest neighbors of   ordered by increasing Euclidean distance from . 

Since the number of edges in the  is  and each edge  belongs to exactly two sets  and , the time to find all the -nearest neighbors, for all the points , is . The proof obtains by combining this with the results of Corollary~\ref{the:kSYG_Construction}.
\end{proof}

\section{Kinetic -Semi-Yao Graph}\label{sec:kineticKSYG}
In Section~\ref{sec:KDSfor1SYG}, we first provide a KDS for the \ksyg, for . Then in Section~\ref{sec:KDSforkSYG} we extend our kinetic approach to any .

\subsection{The case }\label{sec:KDSfor1SYG}


The \1syg~remains unchanged as long as the order of the points in each of the coordinates , and  associated to each cone  remains unchanged. Therefore, to track the changes to the \1syg~over time, we distinguish between two types of events:

\begin{itemize}
\item \textbf{-swap event:} Such an event occurs if two points exchange their order in the -coordinate. 
\item \textbf{-swap event:} This event occurs whenever two points exchange their order in the -coordinate. 
\end{itemize}

The -swap events can be tracked by defining  kinetic sorted lists  of the points for each of the coordinates  (see Section~\ref{sec:Preliminaries}). In addition, to track the -swap events, we create a kinetic sorted list  of the points with respect to the -coordinates of the points.

Fix a cone , . Corresponding to the cone , we create kinetic ranked-based range trees (RBRTs)  (see Section~\ref{sec:Preliminaries}). Consider the corresponding cone separated pair decomposition (CSPD)  of . Let  be the point with minimum -coordinate among the points in . Denote by  the point in  with minimum -coordinate; in fact  is the point with the minimum -coordinate among the points , where the subscripts  are such that . Note that to maintain the \1syg, for each point , in fact we must track .
To apply required changes to  for all , when an event occurs, in addition , we need to maintain more information for each subscript  (\ie, at each internal node  at level  of ). The next paragraph describes the extra information.

Allocate a \textit{label} to each point in . Let  be a sorted list of the points  according to the labels of their . This sorted list is used to answer the following query while processing -swap events: Given a query point , find all the points  such that . Since we perform  updates (insertions/deletions) to the sorted lists  over time, we implement them using a dynamic binary search tree (\eg, a \textit{red-black tree}); each update is performed in worst-case time . Furthermore, for each , we create a set of links to  in the sorted lists ; denote this set by ; we use this set to efficiently delete a point  from the sorted lists  when we are handling the events.

In the preprocessing step before the motion, for any subscript  and for any point , we find  and , and then we construct  and .

\begin{lemma}\label{the:PreProcStep}
Our KDS uses   space and  preprocessing time.
\end{lemma}
\begin{proof}
By Theorem~\ref{the:RBRTcomplexity}, each point  is in at most  sets , and  sets , so the cardinality of each set  is , and the size of sets  and , for all , is . This implies that  the KDS uses  storage,  we can find all the  and  in time , and   we can sort the points  in all the  according to the labels of their  in  time, and then by tracing the members of the sorted lists , we can create  for all  in the same time  .
\end{proof}

Now let the points move. The following shows how to maintain and reorganize ,  and , for any subscript  and for any point ,  when a -swap event or an -swap event occurs. Note that maintenance of the sets , for all , in fact gives a kinetic maintenance of the \1syg.

\begin{figure}[t]
\centering
\includegraphics[scale=1]{ch6_Uswap.eps}
\caption{A -swap between  and  does not change the memberships of points in other cones.}
\label{fig:Uswap}
\end{figure}

\paragraph{Handling -swap events.} Consider a -swap between  and . Without loss of generality, assume  before the event; see Figure~\ref{fig:Uswap}. After the event,  moves outside the cone . Note that this event does not change the points in  for other points . Therefore, the only change that might happen to the \1syg~is to replace an edge incident to  inside the cone  with a new one. In particular, when two points  and  exchange their order with respect to the -coordinate, we perform the following steps.
\begin{itemize}
\item[\texttt{U1)}] We update the kinetic sorted list .
\item[\texttt{U2)}] A -swap event may change the structure of the RBRT , so we update .
\item[\texttt{U3)}] We delete the point(s)  from the sorted lists  where .
\item[\texttt{U4)}] We delete the members of .
\item[\texttt{U5)}] We update the values in .
\item[\texttt{U6)}] We find the point  in  whose -coordinate is minimum among all the  such that .
\item[\texttt{U7)}] We add the point  into all the sorted lists  according to the label of the new value of . Then we construct the set , which in fact is the new set of links to  in the sorted lists .
\end{itemize}

The following lemma gives the complexity of the steps \texttt{U1},...,\texttt{U7} above.

\begin{lemma}\label{the:Uswap}
For maintenance of the \1syg, our KDS handles  -swap events, each in worst-case time .
\end{lemma}
\begin{proof}
For a fixed dimension , (by Theorem~\ref{the:KineticSL}) the kinetic sorted lists , , handle  events, each in  time (Step \texttt{U1}). 

From Theorem~\ref{the:RBRTcomplexity}, an update to  takes  time (Step \texttt{U2}). By using the links in , Step \texttt{U3} can be done in  time. 

By Theorem~\ref{the:RBRTcomplexity}, all the  can be found in  time, so the values  can be updated in  worst-case time  (Step \texttt{U5}); also, since each point is in  sets , Step \texttt{U6} takes  time. 

Each operation in a sorted list  can be done in  time; this implies that Step \texttt{U7} takes  time.
\end{proof}

\paragraph{Handling -swap events.} Denote by  the -coordinate of . Let  and  be two consecutive points with  preceding  (\ie, ) before the -swap event. The structure of  remains unchanged when an -swap event between  and  occurs. Such an event might change the value of  of some points  of the sorted lists  and if so, we must find such points  and apply the required changes. 

The number of all changes to the \1syg~depends on how many points  have both  and  in their cones . Note that, while reporting the points in  for , both  and  might be in the same set  (see Figure~\ref{fig:Xswap}(a)) or in two different sets  and  (see Figure~\ref{fig:Xswap}(b)). To find such points , when an -swap event between  and  occurs, we seek (I) subscripts  where , and (II) subscripts  and  where  and . In the first case, we must find any point  such that  (\ie,  is the point with minimum -coordinate in the cone ). Then we replace  by  after the event: . This means that we replace the edge  of the \1syg~with . 


\begin{figure}[t]
\centering
\includegraphics[scale=1]{ch6_Xswap.eps}
\caption{Two cases when an -swap between  and  occurs.}
\label{fig:Xswap}
\end{figure}

Note that in the second case there is no point  such that , because . Also note that if there is a point  such that , we change the value of  to  if ; in the case that , there is a unique pair  where  and . Thus we can find  in the set  and we do not need to check whether point  is in  or not. In particular, for the second case, we only need to check whether there is a point  such that ; if so, we change the value of  to  ().

From the above discussion, the following steps summarize the update mechanism of our KDS for maintenance of the \1syg~when an -swap event occurs.

\begin{itemize}
\item[\texttt{X1)}] We update the kinetic sorted list .
\item[\texttt{X2)}] We find all the subscripts  such that  and . Also, we find all the subscripts  where  (see Figure~\ref{fig:Xswap}).
\item[\texttt{X3)}] For each subscript  (from Step \texttt{X2}), we find all the points  in the sorted list  where .
\item[\texttt{X4)}] For each  (from Step \texttt{X3}), using the links in , we update all the corresponding sorted lists : we delete  from them, change the value of  to , and add  into the sorted lists according to the label of .
\end{itemize}

The number of edges incident to a point  in the \1syg~is . Thus when an -swap event between  and some point  occurs, it might cause  changes to the \1syg. The following lemma proves that an -swap event can be handled in polylogarithmic amortized time.

\begin{lemma}\label{the:Xswap}
For maintenance of the \1syg, our KDS handles  -swap events with total processing time .
\end{lemma}
\begin{proof} 
From Theorem~\ref{the:KineticSL}, Step \texttt{X1} takes  time.  By Theorem~\ref{the:RBRTcomplexity}, all the subscripts  at Step \texttt{X2} can be found in  time.

For each  of Step \texttt{x3}, the update mechanism spends  time where  is the number of all the points  such that . For all the subscripts , the second step takes  time. Note that  is equal to the number of exact changes to the \1syg. Since the number of exact changes to the ~\1syg~of a set of  moving points in a fixed dimension  is  (Theorem 6 of~\cite{Rahmati2014}), the total processing time of Step \texttt{X3} for all the  -swap events is . 

For each  of Step \texttt{X4}, the processing time to apply changes to the KDS is . For each  of \texttt{X4}, it is in fact a change to the \1syg. Thus the update mechanism spends  time to handle all the  events.

Summing over the complexities of Steps \texttt{X1}-\texttt{X4}, for all the -swap events, gives the total processing time  .
\end{proof}

Now we obtain the main result of this section, which summarizes the complexity of the proposed KDS for the \1syg.

\begin{theorem}\label{the:KineticSYG}
Our KDS for maintenance of the \1syg~of a set of  moving points in , where the coordinates of each point are given by polynomials of at most constant degree , uses   space,  preprocessing time, and handles  events with a total cost of . The KDS is compact, efficient, amortized responsive, and local.
\end{theorem}
\begin{proof}
From Lemma~\ref{the:PreProcStep}, the KDS uses   preprocessing time and   space. The total cost to process all the  events is  (by Lemmas~\ref{the:Uswap} and ~\ref{the:Xswap}); this implies that the KDS is amortized responsive. 

Since the number of the certificates is , the KDS is compact. 

Each point in a kinetic sorted list participates in two certificates, one created with the previous point and one with the next point, which implies the KDS is local. 

Since the number of the external events is  and the number of the events that the KDS processes is , the KDS is efficient.
\end{proof}

\subsection{The general case: any }\label{sec:KDSforkSYG}
Here, we extend our kinetic approach to maintain the \ksyg, for any .

For maintenance of the \ksyg~over time, we must track the sets , , for each point . In order to do this, for each subscript , we need to maintain a list  of the points in , sorted in ascending order according to their -coordinates over time. Note that each set  is some , the set of points at the leaves of the subtree rooted at some internal node  at level  of the RBRT . To maintain these sorted lists , we add a new level to the RBRT ; the points at the new level are sorted at the leaves in ascending order according to their -coordinates. Therefore, for updating the modified RBRT , in addition to the -swap events, we handle the -swap events as well. The modified RBRT  behaves like a -dimensional RBRT. From Theorem~\ref{the:RBRTcomplexity}, when a -swap event or an -swap event occurs,  can be updated in worst-case time .

Denote by  the  point in .  To track and update the points in , for all the points , we maintain the following over time:

\begin{itemize}
\item A set of  kinetic sorted lists , , and  of the points in . We use these sorted lists to track the order of the points in the coordinates , , and , respectively.
\item For each , a sorted list  of the points in . The order of the points  in  is according to the labels of their . This sorted list  is used to efficiently answer the following query: Given a query point  and a , find all  such that .
\item The  point  in the sorted list . We maintain the values  in order to make necessary changes to the \ksyg~when an -swap event occurs.
\end{itemize}

As in Section~\ref{sec:KDSfor1SYG}, when the points move, we handle two types of events, \textit{-swap events} and \textit{-swap events}.

\paragraph{Handling -swap events.}
Let  before the -swap event. Whenever the two points  and  exchange their -order, the only change that might occur is the replacement of a member of  with a new one. In particular, when such an event occurs, we perform the following updates.

\begin{enumerate}
\item[\texttt{U1)}] We update the kinetic sorted list .
\item[\texttt{U2)}] We update  . If a point is deleted or inserted into a , we update the corresponding sorted list .
\item[\texttt{U3)}] After updating , a point  might be inserted or deleted from some  and change the values of . For all  where , before and after the event, we perform the following. We check whether the -coordinate of   is less than or equal to the -coordinate of ; if so, we take the successor or predecessor point of  in  as the new value for .
\item[\texttt{U4)}] We query to find .
\item[\texttt{U5)}] If we obtain a new value for , which in fact is the point with maximum -coordinate among the points in , we update all  such that .
\end{enumerate}


Now the following gives the complexity of handling -swap events.


\begin{lemma}\label{the:UswapEvents}
Our KDS for maintenance of the \ksyg~handles  -swap events, each in worst-case time .
\end{lemma}
\begin{proof}
Each swap event in a kinetic sorted list can be handled in  time (Step \texttt{U1}). Since each update (insertion/deletion) to  takes  time, and since each point is in  sets , Step \texttt{U2} takes  time. It is obvious that the processing time of Steps \texttt{U3} and \texttt{U5} is . From Lemma~\ref{the:SortingLists}, Step \texttt{U4} takes  time.

The trajectories of the points are given by  bounded degree polynomials, so the number of events, \ie, changes to the order of the points, is .
\end{proof}

\paragraph{Handling -swap events.}
Consider an -swap event between two consecutive points  and  with  preceding . This event does not change the elements of the pairs , but this event changes the -SYG if both  and  are in the cone , for some  such that . In particular, we perform the following updates when two points  and  exchange their -order.
\begin{enumerate}
\item[\texttt{X1)}] We update the kinetic sorted list ; this takes  time.
\item[\texttt{X2)}] We update , which takes  time.
\item[\texttt{X3)}] We find all the sets  where both  and  belong to  and such that . Also, we find all the sets  where . This step takes  time.
\item[\texttt{X4)}] For each  (from Step \texttt{X3}), we extract all the points  in the sorted lists  such that . Note that each change to the value of  is a change to the \ksyg.
\item[\texttt{X5)}] For each  (from Step \texttt{X4}), we update all the sorted lists  where : we delete  from the sorted lists , update the previous value of , which is , by the new value , and add  back to the sorted lists  according to the label of .
\end{enumerate}


To prepare for Lemma~\ref{the:XswapEvents} below, which summarizes the complexity of handling -swap events, we first give, in Lemma~\ref{the:allKSYGchanges}, an upper bound for the number of changes to the \ksyg~of a set of moving points.


\begin{lemma}\label{the:allKSYGchanges}
The number of changes to the \ksyg~of a set of  moving points, where the coordinates of each point are given by polynomial functions of at most constant degree , is , where  denotes the complexity of the -level of  partially-defined polynomial functions of degree bounded by some constant . 
\end{lemma}
\begin{proof}
Fix a point  and one of its cones . There are  insertions/deletions into the cone  over time. The -coordinates of these points create  partial functions. The \ksyg~changes if a change to  occurs. The number of all changes to  is equal to  the complexity of the -level of these  partial functions.

Therefore, summing over all the  points, the number of changes to the \ksyg~is within a linear factor of : . 
\end{proof}


\begin{lemma}\label{the:XswapEvents}
Our KDS for maintenance of the \ksyg~handles  -swap events with a total cost of .
\end{lemma}
\begin{proof}
The complexities of the first three steps are clear. For each found  from Step \texttt{X3}, Step \texttt{X4} takes  time, where  is the number of points  such that . Thus, for all the  sets  of Step \texttt{X3}, Step \texttt{X4} takes  time, where  is the number of exact changes to the \ksyg. Therefore, for all the  -swap events, the total processing time for this step is .

The processing time for Step \texttt{X5} is a function of . For each change to the \ksyg, this step spends  time to update the sorted lists . Thus the total processing time for all the -swap events in this step is .
\end{proof}


Now we can obtain the following.
\begin{theorem}\label{the:KinetickSYG}
For a set of  moving points in , where the coordinates of each point are polynomial functions of at most constant degree , our \ksyg~KDS uses  space and  preprocessing time, and handles  events with a total cost of .
\end{theorem}
\begin{proof}
The proof obtains by combining the results of Theorem~\ref{the:RBRTcomplexity} and Lemmas~\ref{the:UswapEvents} and~\ref{the:XswapEvents}.
\end{proof}
\section{The Applications}\label{sec:applications}
\subsection{Kinetic All -Nearest Neighbors}\label{sec:app_kNNs}
Let us be given a KDS for the \ksyg, a supergraph of the \knng~(from Theorems~\ref{the:KinetickSYG} and~\ref{the:KineticSYG}). This section shows how to maintain all the -nearest neighbors over time. We first consider the case , and then the general case, for any .


\paragraph{The case .}\label{sec:KDSfor1NNs}
We use dynamic and kinetic tournament trees (see Section~\ref{sec:Preliminaries}) to maintain all the -nearest neighbors. For each point  in the \1syg, we create a dynamic and kinetic tournament tree , whose elements are the edges incident to  in the \1syg. 

The following gives the complexity of our KDS for all -nearest neighbors.

\begin{theorem}\label{the:KineticAllNN}
Our KDS for maintenance of all the -nearest neighbors of a set of  moving points in , where the coordinates of each point are polynomial functions of at most constant degree , has the following properties. 
\begin{enumerate}
\item The KDS uses  space and  preprocessing time.
\item It processes  -swap events, each in worst-case time .
\item It processes  -swap events, for a total cost of .
\item The KDS processes  tournament events, and processing all the events takes  time.
\item The KDS is efficient, amortized responsive, compact, and each point participates in  certificates on average.
\end{enumerate}
\end{theorem}
\begin{proof}
Theorem~\ref{the:KineticSYG} gives the statements . 

Let   be the number of insertions/deletions into . By Theorem~\ref{the:KineticTT}, all , for all , generate at most  events. Since each edge is incident to two points, inserting (resp. deleting) an edge  into the \1syg~causes two insertions (resp. deletions) into  and . The number of all edge insertions/deletions into the \1syg~is  (Theorem 6 of~\cite{Rahmati2014}, so  . Hence the number of all events by all the dynamic and kinetic tournament trees is , and the total cost is . 

The ratio of the number of internal events  to the number of external events  is polylogarithmic, which implies that the KDS is efficient. 

The ratio of the total processing time to the number of internal events that the KDS processes is polylogarithmic, and so the KDS is amortized responsive.

The total size of all the tournament trees is , so the number of certificates of the tournament trees is linear. Also, the number of all certificates corresponding to the kinetic sorted lists  and  is linear. Thus the KDS is compact.  Since the number of all certificates is , each point participates in a constant number of certificates  on average.
\end{proof}


\paragraph{The general case: any .}\label{sec:KDSforkNNs}
For maintenance of the -nearest neighbors to each point , for any , we need to track the order of the edges incident to  in the \ksyg~according to their Euclidean lengths. This can easily be done by using a kinetic sorted list. 

Let  be the set of edges incident to point  in the \ksyg. Let  denote a kinetic sorted list that maintains the edges in  according to their Euclidean lengths. The following gives the complexity of our kinetic approach.

\begin{theorem}\label{the:KinetickNNs}
For a set of  moving points in , where the coordinates of each point are given by polynomials of at most constant degree , our KDS for maintenance of all the -nearest neighbors, ordered by distance from each point, uses  space and  preprocessing time. Our KDS handles  events, each in  amortized time .
\end{theorem}
\begin{proof}
Let  be the number of insertions/deletions to the set  over time. Since the cardinality of  is , each insertion into a kinetic sorted list  can cause  swaps. Each change (\eg, inserting/deleting an edge ) to the \ksyg~creates two insertions/deletions in the kinetic sorted lists  and ; this implies that  (from Lemma~\ref{the:allKSYGchanges}). By Theorem~\ref{the:KineticSL}, all the kinetic sorted lists , for all , handle a total of   events, each in time . Combining with Theorem~\ref{the:KinetickSYG}, we obtain the total processing time  for all the events.
\end{proof}

Now we measure the performance of our KDS for maintenance of all the -nearest neighbors in  by the four standard criteria in the KDS framework.

\begin{lemma}\label{the:kNNsPerfCri}
The efficiency, responsiveness, compactness, and locality of our KDS for maintenance of all the -nearest neighbors are ,  in an amortized sense, , and  on average, respectively.
\end{lemma}
\begin{proof}
Fix a point . The distances of the points of  to  create  functions, such that each pair of them intersects at most  times. The number of changes to the (ordered) -nearest neighbors  of  is equal to the complexity of the -level, which is   (by Theorem~\ref{the:k_levelComplexity}). Thus the total number of changes, for all , is . Since our KDS  handles  events (by Theorem~\ref{the:KinetickNNs}), the efficiency is .

Each event in our KDS can be handled in amortized time . This implies the proof of the responsiveness of the KDS.



For each two consecutive elements in each of the kinetic sorted lists , , and , we have a certificate. The size of the kinetic sorted lists  and  is , and the size of the kinetic sorted lists , for all , is . This implies that the compactness of our KDS is , and the number of certificates corresponding to each point is  on average.
\end{proof}
\subsection{\rknn~Queries for Moving Points}
Suppose we are given a query point  at some time . To find the reverse -nearest neighbors of , we seek the points in each cone  of  and find , the set of the first  points in . The union of , , contains a set of candidate points for  such that  might be one of their -nearest neighbors. We check whether these candidate points are the reverse -nearest neighbors of  at time  or not; this can be easily done by application of Theorem~\ref{the:KineticAllNN}/\ref{the:KinetickNNs}, which in fact maintains the  nearest neighbor  of each . Note that if one asks a query at time , which is coincident with the time when an event occurs in the all -nearest neighbors KDS, we first handle the event and then answer the query. 

The following theorem gives the main results of this section.

\begin{theorem}\label{the:KineticRkNNQ}
Consider a set  of  moving points in , where the coordinates of each one are given by bounded-degree polynomials. Our KDS uses  space and  preprocessing time. At any time , an \rknn~query can be answered in time , and the number of reverse -nearest neighbors for the query point is . If an event occurs at time , the KDS spends polylogarithmic amortized time on updating itself.
\end{theorem}
\begin{proof}
From Lemma~\ref{the:SortingLists}, the  candidate points for the query point  can be found in worst-case time . We use a KDS for maintenance of all the -nearest neighbors over time (see  Theorem~\ref{the:KineticAllNN}/\ref{the:KinetickNNs}). Checking a candidate point can be done in  time by comparing distance  to distance ; so it takes  time to check which of these candidate points (, ) are reverse -nearest neighbors of the query point .

If one asks a query at time , which coincides with the time when one of the events in the KDS occurs, we first spend polylogarithmic amortized time to handle the event (by  Theorems~\ref{the:KineticAllNN} and~\ref{the:KinetickNNs}), and then spend worst-case time  to answer the query.
\end{proof}

\section{Kinetic All -Nearest Neighbors}\label{sec:KineticEpsANN}
Let  be the nearest neighbor of  and let  be some point such that . We call  the \textit{-nearest neighbor} of . In this section, we provide a KDS to maintain some -nearest neighbor for any point . This KDS gives better performance than the KDS of Section~\ref{sec:app_kNNs} for maintenance of the exact all -nearest neighbors.


Consider a cone  of opening angle , which is bounded by  half-spaces. Let  be a vector inside the cone  that passes through the apex of . Recall a CSPD  for  with respect to the cone . Figure~\ref{fig:RNNgraph} depicts the cone  and a pair . 

\begin{figure}[h]
  \begin{center}
    \includegraphics[scale=1]{RNNgraph.eps}
  \end{center}
  \caption{A pair .}
  \label{fig:RNNgraph}
\end{figure}

Let  (resp. ) be the point with the maximum (resp. minimum) -coordinate among the points in  (resp. ). Let . We call the graph  the \textit{relative nearest neighbor graph} (or RNN graph for short) with respect to . Call the graph  the \textit{RNN graph}.  The RNN graph has the following interesting properties:  It can be constructed in  time by using a -dimensional RBRT,  it has  edges, and  the degree of each point is . Lemma~\ref{the:RNNGlemma} below shows another property of the RNN graph which leads us to find some -nearest neighbor for any point . 

\begin{lemma}\label{the:RNNGlemma}
Between all the edges incident to a point  in the RNN graph, there exists an edge  such that  is some -nearest neighbor to .
\end{lemma}
\begin{proof}
Let  be the nearest neighbor to  and let . From the definition of a CSPD with respect to , for  and  there exists a unique pair  such that  and . From Lemma~\ref{the:keyLemma2},  has the maximum -coordinate among the points in . 

Let  be the point with the minimum -coordinate among the points in . For any , there exist an appropriate angle  and a vector  such that ~\cite{Abam:2011:KSX:1971362.1971367}; this satisfies that . 

Therefore, the edge  which is an edge of the RNN graph gives some -nearest neighbor.
\end{proof}


Consider the set  of the edges of the RNN graph. Let . Denote by  the point in  whose -coordinate is minimum. Let  be a sorted list of the points in  in ascending order according to their -coordinates; the first point in  gives . 

From Lemma~\ref{the:RNNGlemma}, if the nearest neighbor of  is in some set , then  gives some -nearest neighbor to . Note that we do not know which cone , , of  contains the nearest neighbor of , but it is obvious that the nearest point to  among these  points  gives some -nearest neighbor of . Thus for all , we track the distances of all the  to  over time. A kinetic sorted list (or a tournament tree)  of size  with  certificates can be used to maintain the nearest point to . 

Similar to Section~\ref{sec:kineticKSYG} we handle two types of events, \textit{-swap events} and \textit{-swap events}. Note that we do not need to define a certificate for each two consecutive points in .  The following shows how to apply changes (\eg, insertion, deletion, and exchanging the order between two consecutive points) to the sorted lists  when an event occurs.

Each event can make  updates to the edges of . Consider an updated pair  that the value of  (resp. ) changes from  to . For this update, we must delete  (resp. ) form the sorted list  (resp. ) and insert  (resp. ) into  (resp. ). If the event is an -swap event, we must find all the subscripts  where  and check whether  or not; if so,  and  are in the same set  and we need to exchange their order in the corresponding sorted list . 

Now the following theorem gives the main result of this section. 


\begin{theorem}\label{the:KinEpsANN}
Our KDS for maintenance of all the -nearest neighbors of a set of  moving points in , where the trajectory of each one is an algebraic function of constant degree , uses  space and handles  events, each in the worst-case time . The KDS is compact, efficient, responsive, and local.
\end{theorem}
\begin{proof}
The proof of the preprocessing time and space follows from the properties of an RNN graph. Each event can make  changes to the edges of the RNN graph. Each update to a sorted list  can be done in . Thus an event can be handled in worst-case time .

Since each event makes  changes to the values of , and since the size of each kinetic sorted list  is constant, the number of all events to maintain all the -nearest neighbors is .

Each point participates in a constant number of certificates in the kinetic sorted lists corresponding to the coordinate axes  and . Since the degree of each point in the RNN graph is , a change to the trajectory of a point may causes  changes in the certificates of the kinetic sorted lists . Therefore, each point participates in  certificates.
\end{proof}
\section{Discussion and Conclusion}\label{sec:conclusion}
We have provided KDS's for  maintenance of both the \1syg~and all the -nearest neighbors, where the trajectories of the points are polynomials of degree bounded by some constant. These KDS's are amortized responsive. A future direction is to give KDS's for the \1syg~and all the -nearest neighbors such that each event can be handled in a polylogarithmic worst-case time. The next open direction is to design a local KDS for maintenance of all the -nearest neighbors.

Finding a linear-space KDS for all (approximate) -nearest neighbors in , such that it satisfies other standard performance criteria, is an interesting future work.

In order to answer \rknn~queries over time, for any , we have provided a KDS for all the -nearest neighbors. Our KDS is the first KDS for all the -nearest neighbors in , for any . It processes  events, each in amortized time . Another open problem is to design a KDS for maintenance of all the -nearest neighbors that processes less than  events.




\paragraph{\textbf{Acknowledgments}} We would like to thank Timothy M. Chan for his remarks on the best current bounds on the complexity of the -level of partially-defined bounded-degree polynomials, and also for his helpful comments in the analysis of the KDS for maintenance of all the -nearest neighbors.
\bibliographystyle{elsarticle-num}
\bibliography{References_Main}
\end{document}
