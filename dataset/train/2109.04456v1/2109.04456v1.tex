\section{Experiments}
\label{sec:results}

In this section, we describe our experimental setting, showcase the \textbf{driving performance} of NEAT in comparison to several baselines, present an \textbf{ablation study} to highlight the importance of different components of our architecture, and show the interpretability of our approach through \textbf{visualizations} obtained from our trained model.

\boldparagraph{Task}
We consider the task of navigation along pre-defined routes in CARLA version 0.9.10~\cite{Dosovitskiy2017CORL}. A route is defined by a sequence of sparse GPS locations (target locations). The agent needs to complete the route while coping with background dynamic agents (pedestrians, cyclists, vehicles) and following traffic rules. We tackle a new challenge in CARLA 0.9.10: each of our routes may contain several pre-defined dangerous \textbf{scenarios} (\eg unprotected turns, other vehicles running red lights, pedestrians emerging from occluded regions to cross the road).

\boldparagraph{Routes}
For training data generation, we store data using an expert agent along routes from the 8 publicly available towns in CARLA, randomly spawning scenarios at several locations along each route. We evaluate NEAT on the official CARLA Leaderboard~\cite{Leaderboard}, which consists of 100 secret routes with unknown environmental conditions. We additionally conduct an internal evaluation consisting of 42 routes from 6 different CARLA towns (Town01-Town06). Each route has a unique environmental condition combining one of 7 weather conditions (Clear, Cloudy, Wet, MidRain, WetCloudy, HardRain, SoftRain) with one of 6 daylight conditions (Night, Twilight, Dawn, Morning, Noon, Sunset). Additional details regarding our training and evaluation routes are provided in the supplementary. Note that in this new evaluation setting, the multi-lane road layouts, distant traffic lights, high density of background agents, diverse daylight conditions, and new metrics which strongly penalize infractions (described below) make navigation more challenging, leading to reduced scores compared to previous CARLA benchmarks~\cite{Dosovitskiy2017CORL,Codevilla2019ICCV}.

\boldparagraph{Metrics}
We report the official metrics of the CARLA Leaderboard, \textbf{Route Completion (RC)}, \textbf{Infraction Score (IS)}\footnote{The Leaderboard refers to this as infraction penalty. We use the terminology `score' since it is a multiplier for which higher values are better.} and \textbf{Driving Score (DS)}. For a given route, RC is the percentage of the route distance completed by the agent before it deviates from the route or gets blocked. IS is a cumulative multiplicative penalty for every collision, lane infraction, red light violation, and stop sign violation. Please refer to the supplementary material for additional details regarding the penalty applied for each kind of infraction. Finally, DS is computed as the RC weighted by the IS for that route. After calculating all metrics per route, we report the mean performance over all 42 routes. We perform our internal evaluation three times for each model and report the mean and standard deviation for all metrics.

\begin{table*}[t]
    \begin{tabular}{c c}
        \begin{subtable}[h]{0.55\textwidth}
            \small
            \setlength{\tabcolsep}{5pt}
            \centering
            \begin{tabular}{c | c | c c c}
                \textbf{Method} & \textbf{Aux. Sup.} & \textbf{RC} & \textbf{IS} & \textbf{DS} \\
                \hline
                CILRS~\cite{Codevilla2019ICCV} & Velocity & 35.460.41 & 0.660.02 & 22.970.90\\
                LBC~\cite{Chen2019CORL} & BEV Sem & 61.352.26 & 0.570.02 & 29.070.67 \\
                AIM~\cite{Prakash2021CVPR} & None & 70.042.31 & 0.730.03 & 51.250.17 \\
                \hline
                \multirow{3}{*}{AIM-MT} & 2D Sem & 80.213.55 & 0.740.02 & 57.952.76 \\
                 & BEV Sem & 77.933.06 & 0.780.01 & 60.622.33 \\
                 & Depth+2D Sem & \textbf{80.812.47} & 0.800.01 & 64.862.52 \\
                 \hline
                AIM-VA & 2D Sem & 75.401.53 & 0.790.02 & 60.940.79 \\
                \hline
                NEAT & BEV Sem & 79.173.25 & \textbf{0.820.01} & \textbf{65.101.75} \\
                \hline
                Expert & N/A & 86.052.58 & 0.760.01 & 62.692.36 \\
            \end{tabular}
            \caption{\textbf{CARLA 42 Routes.} We show the mean and standard deviation over 3 evaluations for each model. NEAT obtains the best driving score, on par with (and sometimes even outperforming) the expert used for data collection.}
            \label{tab:baselines}
            \vspace{0.0cm}
        \end{subtable}
        &
        \begin{subtable}[h]{0.40\textwidth}
            \small
            \setlength{\tabcolsep}{2.4pt}
        	\centering
        	\begin{tabular}{c | c | c | c c c}
                \textbf{\#} & \textbf{Method} & \textbf{Aux. Sup.} & \textbf{RC}  & \textbf{IS}  & \textbf{DS}  \\
        		\hline
        		1 & WOR~\cite{Chen2021ARXIV} & 2D Sem & 57.65 & 0.56 & 31.37 \\
        		2 & MaRLn~\cite{Toromanoff2020CVPR} & 2D Sem+Aff & 46.97 & 0.52 & 24.98 \\
        		3 & NEAT (Ours) & BEV Sem & 41.71 & 0.65 & 21.83 \\
        		4 & AIM-MT & Depth+2D Sem & 67.02 & 0.39 & 19.38 \\
        		5 & TransFuser~\cite{Prakash2021CVPR} & None & 51.82 & 0.42 & 16.93 \\
        		6 & LBC~\cite{Chen2019CORL} & BEV Sem & 17.54 & 0.73 & 8.94 \\
        		7 & CILRS~\cite{Codevilla2019ICCV}& Velocity & 14.40 & 0.55 & 5.37 \\
        	\end{tabular}
        	\caption{\textbf{CARLA Leaderboard.} Among all publicly visible entries (accessed in July 2021), NEAT obtains the third-best DS. Of the top 3 methods, NEAT has the highest IS, indicating safer driving on unseen routes.}
        	\label{tab:challenge}
        	\vspace{0.0cm}
        \end{subtable}
    \end{tabular}
    \vspace{-0.2cm}
    \caption{\textbf{Quantitative Evaluation on CARLA.} We report the RC, IS and DS over our 42 internal evaluation routes (\tabref{tab:baselines}) and 100 secret routes on the evaluation server~\cite{Leaderboard} (\tabref{tab:challenge}). We abbreviate semantics with ``Sem'' and affordances with ``Aff''.}
    \label{tab:results}
    \vspace{-0.3cm}
\end{table*}

\boldparagraph{Baselines}
We compare our approach against several recent methods. \textbf{CILRS}~\cite{Codevilla2019ICCV} learns to directly predict vehicle controls (as opposed to waypoints) from visual features while being conditioned on a discrete navigational command (follow lane, change lane left/right, turn left/right). It is a widely used baseline for the old CARLA version 0.8.4, which we adapted to the latest CARLA version. \textbf{LBC}~\cite{Chen2019CORL} is a knowledge distillation approach where a teacher model with access to ground truth BEV semantic segmentation maps is first trained using expert supervision to predict waypoints, followed by an image-based student model which is trained using supervision from the teacher. It is the state-of-the-art approach on CARLA version 0.9.6. We train LBC on our dataset using the latest codebase provided by the authors for CARLA version 0.9.10. \textbf{AIM}~\cite{Prakash2021CVPR} is an improved version of CILRS, where a GRU decoder regresses waypoints. To assess the effects of different forms of auxiliary supervision, we create 3 multi-task variants of AIM (\textbf{AIM-MT}). Each variant adds a different auxiliary task during training: (1) 2D semantic segmentation using a deconvolutional decoder, (2) BEV semantic segmentation using a spatial broadcast decoder~\cite{Watters2019ICLRWORK}, and (3) both 2D depth estimation and 2D semantic segmentation as in~\cite{Li2018ARXIV}. We also replace the CILRS backbone of Visual Abstractions~\cite{Behl2020IROS} with AIM, to obtain \textbf{AIM-VA}. This approach generates 2D segmentation maps from its inputs which are then fed into the AIM model for driving. Finally, we report results for the privileged \textbf{Expert} used for generating our training data.

\boldparagraph{Implementation} By default, NEAT's transformer uses  layers with 4 parallel attention heads. Unless otherwise specified, we use , , , , , , , ,  and . We use a weight of  on the  loss, set  for the intermediate iterations (), and set . For a fair comparison, we choose the best performing encoders for each model among ResNet-18, ResNet-34, and ResNet-50 (NEAT uses ResNet-34). Moreover, we chose the best out of two different camera configurations ( and ) for each model, using a late fusion strategy for combining sensors in the baselines when we set . Additional details are provided in the supplementary.

\subsection{Driving Performance}

Our results are presented in \tabref{tab:results}. \tabref{tab:baselines} focuses on our internal evaluation routes, and \tabref{tab:challenge} on our submissions to the CARLA Leaderboard. Note that we could not submit all the baselines from \tabref{tab:baselines} or obtain statistics for multiple evaluations of each model on the Leaderboard due to the limited monthly evaluation budget (200 hours). 

\boldparagraph{Importance of Conditioning}
We observe that in both evaluation settings, CILRS and LBC perform poorly. However, a major improvement can be obtained with a different conditioning signal. CILRS uses discrete navigational commands for conditioning, and LBC uses target locations represented in image space. By using target locations in BEV space and predicting waypoints, AIM and NEAT can more easily adapt their predictions to a change in driver intention, thereby achieving better scores. We show this adaptation of predictions for NEAT in \figref{fig:interp}, by predicting semantics and waypoint offsets for different target locations  and time steps . The waypoint offset formulation of NEAT introduces a bias that leads to smooth trajectories between consecutive waypoints ({\color{red}red lines} in ) towards the provided target location in {\color{blue}blue}.

\boldparagraph{AIM-MT and Expert} We observe that AIM-MT is a strong baseline that becomes progressively better with denser forms of auxiliary supervision. The final variant which incorporates dense supervision of both 2D depth and 2D semantics achieves similar performance to NEAT on our 42 internal evaluation routes but does not generalize as well to the unseen routes of the Leaderboard (\tabref{tab:challenge}). Interestingly, in some cases, AIM-MT and NEAT match or even exceed the performance of the privileged expert in \tabref{tab:baselines}. Though our expert is an improved version of the one used in~\cite{Chen2019CORL}, it still incurs some infractions due to its reliance on relatively simple heuristics and driving rules.

\begin{figure}[t!]
\centering
\includegraphics[width=\columnwidth]{interpolate.pdf}
\vspace{-0.7cm}
\caption{\textbf{NEAT Visualization.} We show  (left) and  (right) as we interpolate  and  for the scene in \figref{fig:teaser}. The {\color{green}green circles} highlight the different predicted ego-vehicle positions. On the right, we show the predicted trajectory and waypoint  in {\color{red}red}. Note how the model adapts its prediction to the target location  (shown in {\color{blue}blue}).}
\label{fig:interp}
\vspace{-0.3cm}
\end{figure}

\begin{figure}[t]
	\scriptsize
	\setlength{\tabcolsep}{3pt}
	\centering
	\begin{tabular}{c l}
		\multirow{13}{*}{\includegraphics[height=4.15cm]{gfx/ablation_2.pdf}} & \crule[bd9354]{6pt}{6pt} Default Configuration (Seed 1) \\
		& \crule[9e7540]{6pt}{6pt} Default Configuration (Seed 2) \\
		& \crule[fbeeac]{6pt}{6pt} 4 Classes (- Green Light) \\
		& \crule[f4d160]{6pt}{6pt} 6 Classes (+ Lane Marking) \\
		& \crule[00917c]{6pt}{6pt} Less Iterations () \\
		& \crule[025955]{6pt}{6pt} More Iterations () \\
		& \crule[b8b5ff]{6pt}{6pt} Shorter Horizon () \\
		& \crule[7868e6]{6pt}{6pt} Longer Horizon () \\
		& \crule[f8a1d1]{6pt}{6pt} No Side Views () \\
		& \crule[e36bae]{6pt}{6pt} No Transformer () \\
		& \crule[cd3e8d]{6pt}{6pt} No Intermediate Loss () \\
		& \crule[a4246a]{6pt}{6pt} No Semantic Loss () \\
		& \crule[721d4c]{6pt}{6pt} No Red Light Indicator \\
	\end{tabular}
	\vspace{-0.1cm}
	\caption{\textbf{Ablation Study.} We show the mean DS over our 42 evaluation routes for different NEAT model configurations. Expert performance is shown as a dotted line.}
	\label{fig:ablation}
	\vspace{-0.3cm}
\end{figure}

\begin{figure*}[t!]
\centering
\setlength{\tabcolsep}{1.5pt}
\begin{tabular}{c c c c}
	\multirow{2}{*}[0.08\textwidth]{\includegraphics[height=0.2\textwidth]{gfx/attention/0075_sem.png}} & \includegraphics[height=0.095\textwidth]{gfx/attention/0075.png} &
	\multirow{2}{*}[0.08\textwidth]{\includegraphics[height=0.2\textwidth]{gfx/attention/0130_sem.png}} & \includegraphics[height=0.095\textwidth]{gfx/attention/0130.png} \\
	 & \includegraphics[height=0.095\textwidth]{gfx/attention/0075_0_1.png} & & \includegraphics[height=0.095\textwidth]{gfx/attention/0130_0_1.png} \\
	 \multirow{2}{*}[0.08\textwidth]{\includegraphics[height=0.2\textwidth]{gfx/attention/0194_sem.png}} & \includegraphics[height=0.095\textwidth]{gfx/attention/0194.png} &
	\multirow{2}{*}[0.08\textwidth]{\includegraphics[height=0.2\textwidth]{gfx/attention/0451_sem.png}} & \includegraphics[height=0.095\textwidth]{gfx/attention/0451.png} \\
	 & \includegraphics[height=0.095\textwidth]{gfx/attention/0194_0_1.png} & & \includegraphics[height=0.095\textwidth]{gfx/attention/0451_0_1.png} \\
\end{tabular}
\vspace{-0.3cm}
\caption{\textbf{Attention Maps.} We visualize the semantics  for 4 frames of a driving sequence (legend: {\color{black}none}, {\color{violet}road}, {\color{blue}obstacle}, {\color{red}red light}, {\color{green}green light}). We highlight one particular  location as a white circle on each , for which we visualize the input and corresponding attention map . NEAT consistently attends to the region corresponding to the object of interest (from top left to bottom right: bicyclist, green light, vehicle and red light). Best viewed on screen, zoom in for details.}
\label{fig:att}
\vspace{-0.4cm}
\end{figure*}

\boldparagraph{Leaderboard Results} While NEAT is not the best performing method in terms of DS, it has the safest driving behavior among the top three methods on the Leaderboard, as evidenced by its higher IS. WOR~\cite{Chen2021ARXIV} is concurrent work that supervises the driving task with a Q function obtained using dynamic programming, and MaRLn is an extension of the Reinforcement Learning (RL) method presented in~\cite{Toromanoff2020CVPR}. WOR and MaRLn require 1M and 20M training frames respectively. In comparison, our training dataset only has 130k frames, and can potentially be improved through orthogonal techniques such as DAgger~\cite{Ross2011AISTATS,Prakash2020CVPR}.

\subsection{Ablation Study}

In \figref{fig:ablation}, we compare multiple variants of NEAT, varying the following parameters: training seed, semantic class count (), attention iterations (), prediction horizon (), input sensor count (), transformer layers (), and loss weights (). While a detailed analysis regarding each factor is provided in the supplementary, we focus here on four variants in particular: Firstly, we observe that different random training seeds of NEAT achieve similar performance, which is a desirable property not seen in all end-to-end driving models~\cite{Behl2020IROS}. Second, as observed by~\cite{Behl2020IROS}, 2D semantic models (such as AIM-VA and AIM-MT) rely heavily on lane marking annotations for strong performance. We observe that these are not needed by NEAT for which the default configuration with 5 classes outperforms the variant that includes lane markings with 6 classes. Third, in the shorter horizon variant () with only 2 predicted waypoints, we observe that the output waypoints do not deviate sharply enough from the vertical axis for the PID controller to perform certain maneuvers. It is also likely that the additional supervision provided by having a horizon of  in our default configuration has a positive effect on performance. Fourth, the gain of the default NEAT model compared to its version without the semantic loss () is 30\%, showing the benefit of performing BEV semantic prediction and trajectory planning jointly.

\boldparagraph{Runtime} To analyze the runtime overhead of NEAT's offset prediction task, we now create a hybrid version of AIM and NEAT. This model directly regresses waypoints from NEAT's encoder features  using a GRU decoder (like AIM) instead of predicting offsets. We still use a semantic decoder at train time supervised with only the cross-entropy term of Eq. \eqref{eqn:loss}. At test time, the average {runtime} per frame of the hybrid model (with the semantics head discarded) is 15.92 ms on a 3080 GPU. In comparison, the default NEAT model takes 30.37 ms, \ie, both approaches are real-time even with un-optimized code. Without the compute-intensive red light indicator, NEAT's runtime is only 18.60 ms. Importantly, NEAT (DS = 65.10) {significantly outperforms} the AIM-NEAT hybrid model (DS = 33.63). This shows that NEAT's attention maps and location-specific features lead to improved waypoint predictions.

\subsection{Visualizations}
Our supplementary video\footnote{\url{https://www.youtube.com/watch?v=gtO-ghjKkRs}} contains qualitative examples of NEAT's driving capabilities. For the first route in the video, we visualize attention maps  for different locations on the route in \figref{fig:att}. For each frame in the video, we randomly sample BEV  locations and pass them through the trained NEAT model until one of the locations corresponds to the class obstacle, red light, or green light. Four such frames are shown in \figref{fig:att}. We observe a common trend in the attention maps: NEAT focuses on the image corresponding to the object of interest, albeit sometimes at a slightly different location in the image. This can be attributed to the fact that NEAT's attention maps are over learned image features that capture information aggregated over larger receptive fields. To quantitatively evaluate this property, we extract the  image patch which NEAT assigns the highest attention weight for one random  location in each scene of our validation set and analyze its ground truth 2D semantic segmentation labels. The semantic class predicted by NEAT for  is present in the 2D patch in 79.67\% of the scenes.
