\documentclass{eptcs}
\usepackage{latexsym,amssymb}
\usepackage[leqno,fleqn]{amsmath}
\usepackage{proof}
\newtheorem{defn}{Definition}
\newtheorem{thm}[defn]{Theorem}
\newtheorem{prop}[defn]{Proposition}
\newtheorem{lem}[defn]{Lemma}
\newcommand{\proofbeg}{\textbf{Proof. }}
\newcommand{\proofend}{\hfill }
\newcommand{\GA}{\mathfrak{A}}
\newcommand{\KA}{\mathcal{K}}
\newcommand{\osigma}{\overline{\sigma}}
\newcommand{\KL}{\mathsf{KL}}
\newcommand{\LA}{\mathcal{L}}
\title{Kleene Algebras, Regular Languages and Substructural Logics}
\author{Christian Wurm \\
\texttt{cwurm@phil.uni-duesseldorf.de}}
\def\titlerunning{Kleene Algebras, Regular Languages and Substructural Logics}
\def\authorrunning{Christian Wurm}
\begin{document}

\maketitle
\begin{abstract}
We introduce the two substructural propositional logics , , 
which use disjunction, fusion and a unary, (quasi-)exponential 
connective. For both we prove strong completeness
with respect to the interpretation in Kleene 
algebras and a variant thereof.
We also prove strong completeness  for language models, where each
logic comes with a different interpretation.
We show that for both logics the cut rule is 
admissible and both have a decidable consequence relation.
\end{abstract}


\section{Introduction and Motivation}

We introduce two substructural logics, the logic  and
the logic , by providing a Gentzen-style sequent calculus.
 and  have the same syntax: they are propositional, 
and thus consist of a countable set of propositional variables together with
propositional connectives. They have the binary
connectives , where  is the classical \textit{or},
and  is the \textit{fusion} operator well-known from 
Lambek calculus, which is non-commutative and non-monotonic in
both directions. Moreover, they have the unary connective , which is similar
to the right exponential from linear logic, in the sense that it 
allows weakening and contraction on the right hand side of 
and can be introduced only under strict conditions on the left hand 
side.\footnote{See \cite{galatos:residuated} and \cite{restall:introduction} 
for treatment of the full Lambek calculus; \cite{girard:linear} for 
linear logic.}

We show that  can be interpreted in Kleene algebras (we use this
term in the sense of the axiomatization of \cite{kozen:kleene}) in a
natural way, and that this results in a strongly complete semantics
We can thus interpret formulas as languages with the standard interpretation
of regular expressions, consequence as set-theoretic inclusion,
and still have a strongly complete semantics. 
A similar approach has be taken by \cite{kozen:substructural}, but our
calculus differs substantially: in particular, it has a pure
Gentzen-style presentation, no structural rules, and apart from the (admissible) 
cut rule, its syntactic decidability can be neatly read off.
 differs minimally, but its semantics is much
less obvious:  is a fragment of , that is, every
valid sequent of  is valid in , but not vice versa. 
We show that
we can interpret it in a closely related variant of Kleene algebras,
and what is more interesting: we can interpret  expressions of these
algebras (and thus  formulas) 
as languages in the usual sense, with the only difference
that  is interpreted as Kleene plus instead of star, and get a
strongly complete language-theoretic semantics. From this we can easily
conclude that both logics are decidable (because the inclusion problem
for regular languages is decidable), and that the cut rule
is admissible for both logics: for every provable sequent, there is a
cut-free proof.

There are two main motivations for : as it is sound and complete
for Kleene algebras, we hardly need to explain its many possible
interpretations. What is firstly interesting about  is that it connects
logical questions with language-theoretic questions and regular expressions
(as has been done, in a rather different setting, by
\cite{babu:chop}). We thus can use language-theoretic
techniques to check theoremhood and consequence; and conversely, we can
use our cut-free sequent calculus to check whether the language denoted
by one regular expression is a subset of a language denoted by another 
one (which is still a ``hot topic" in computer science, see e.g.
\cite{hovland:inclusion}).
The main motivation for  is somewhat philosophical, but also
has a computational content: if we want to
interpret  as a logic of events/processes and  as a \textit{progressive
aspect} of a process (saying it is going on in some interval
rather than being completed in this interval), 
some of the  rules seem to be too strong,
whereas those of  seem to be reasonable. It is interesting and
instructive that many nice results from  -- cut-free sequent
calculus, decidable and complete algebraic and language-theoretic
semantics -- can be transferred to ; in particular, the
language-theoretic semantics of the latter is far from obvious.

\section{Syntax and Sequent Calculus of }

We now present the syntax of both  and . 
 The set of formulas is defined as follows:
let  be a countably infinite set of variables. Then
we define:
\begin{enumerate}
\item If , then .
\item If , then .
\item If , then .
\item If , then .
\end{enumerate}

This defines the set of formulas. I first say a word on the
intuitive meaning of formulas. Atomic propositions might be best
thought of as events or actions. The  should be clear,
representing a classical ``or" in a non-classical context. The 
can be read as ``and then", meaning temporal sequence of events. The
intuitive meaning of  can be thought of: ``is happening (or taking place)
some arbitrary number (including 0) of times". This is very close
to the intuitive interpretation of operations in Kleene algebras;
for more explicit considerations consider \cite{pratt:action}.

We let lowercase Greek letters range over formulas, uppercase
Greek letters over finite, possibly empty sequences of 
formulas,
which we write in the usual fashion just separated by
.  are substructural logics, that is, the usual
structural rules of weakening, contraction, monotonicity are
not legitimate. If we
present a sequence of formulas separated by , this means that the
sequence is ordered: we cannot exchange neither order nor 
cardinality of its elements, nor can we add or take away anything without an
additional rule. The
 is however associative, that is, 
for a sequence 
there is no precedence.
Now we define the derivability relation 
 of the logic  between sequences of formulas and
formulas. A substructural consequence relation as the one we
present here also gives rise to a structural consequence
relation (see \cite{galatos:residuated}), but we will not be
concerned with this here.
\\

(ax) 
 
(cut) 
\\

(I) 
 (I1) 

(I2) 
\\

(I) 

(I) 
\\

These rules are the usual axioms of sequent calculi, and usual rules for
 which should be familiar to anyone familiar with some 
substructural logic. In addition, we have to make sure that our logic
satisfies the distributive law for  and : 
(DIS1) 
and
(DIS2) .
(DIS1) is derivable from
the above rules, but (DIS2) is not (see \cite{restall:introduction}
for background), so 
we have to add a rule to make sure (DIS2) holds:
\\

(D) 
\\

This way, we make sure the distributive law holds for our logic.
Now comes the most interesting group of axioms and rules, namely the ones for
. 
\\

(ax?) 

(I?1) 

(I?2) 
\\

(I?1),(I?2) form a symmetric group; we use 
it in order to introduce formulas to the
left of the turnstile, if on the right there is a formula . By 
(ax?), the problem is not to get a formula  
on the right, but rather introduce
material on its left. The next group is responsible for introducing
the  on the left side of the turnstile.
\\

(?I1) 

(?I2) 
\\

This is sufficient for 
We now introduce the constants  as follows; note that we can also do
without, and the extension we thereby introduce is conservative.
\\

(1I) 

(I1) 

(0I) 
\\

Note that our 1 is weak, in the sense that it is not necessarily
derivable from any sequence; our 0 on the other side is strong:
everything is derivable from any sequence containing it.
So the two are not duals, and we do not have a strong 1 (usually 
written )
or a weak 0 (the strong 0 is usually denoted by ).
From the axioms it follows that 1 is the ``neutral element" 
(we already speak in algebraic terms) of , and
 the ``neutral element" of . Moreover,  is logically
equivalent to
, and  equivalent to . The cut rule goes without comment,
but we already presage that we will later show that it is admissible,
that is, anything derivable with cut is also derivable without it.
We define a -\textbf{proof tree}
as usual in logic: it is a (binary) labelled tree where each leaf is
labelled by an axiom, and each elementary subtree (node with its
two daughters) is labelled according to one of our inference rules. 
We say a sequent  is derivable (in ) by our
proof calculus, if there is a -proof tree such that
its root is labelled by .
If such a sequent is derivable, 
we write . 



\section{Kleene Algebras, Semantics of  and its Completeness}

For the semantics of  we use a well-known class of structures
(see \cite{kozen:kleene}, and \cite{conway:regular} as classical reference).
A \textbf{Kleene algebra} is an algebra , 
where  are binary operators,  is unary,  are
constants in  and
 is a set closed under the former
operations, and satisfying the following equations:
\\

(K1) 

(K2) 

(K3) 

(K4) 

(K5) 

(K6) 

(K7) 

(K8) 

(K9) 
\\

This means:  is an idempotent semiring. We write  for
; as usual,  has precedence over . 
 We also define a partial order
on  as usual:  if and only if .
To get a Kleene algebra, we still need two inequations and two 
quasi-equations for :
\\

(K10) 

(K11) 

(K12) If , then 

(K13) If , then .
\\

These axioms say that  is the unique smallest solution for 
in the inequation . As usual,  has precedence over 
both . By  we denote the class of
all Kleene algebras, that is, all algebras satisfying 
(K1)--(K13). Let  be a Kleene algebra. If an equation
(or inequation)  () holds in , we sometimes
write  (or ) for reasons of clarity.
If a certain (in)equation is valid in all Kleene algebras, we write
 () (equivalently, if it is valid in the free
Kleene algebra, see \cite{burris} for algebraic background).
 Two properties of Kleene algebras are extremely
important for us: 1.  is transitive
for any Kleene algebra  (and so is ), and secondly, 
respects concatenation: if 
, then . This follows from distributivity:
. This is 
equivalent to saying that from  it follows that ,
a property to which we refer as \textbf{strong transitivity}
(this is also known as monotonicity of , but we prefer to use
monotonicity in connection with weakening).

An \textbf{interpretation} 
 is defined as
follows: let  be an arbitrary
map from variables to ; 
we obtain  inductively as follows:
\begin{enumerate}
\item , if .
\item 
\item 
\item 
\item 
\item 
\end{enumerate}

We extend  also to \textit{sequences} of formulas:
for , put 
;
that is, the  of sequences is interpreted in the same manner
as .
Having defined , we define a \textbf{model} as a tuple
. We say a sequent  of  is
\textbf{true} in , in symbols
, if
 holds in 
(we also write: ).
In case we have a sequent of the form , where
 is the empty sequence, we write
 if
.

We write , if for all maps
, we have
; and we write
, if for all Kleene algebras
 and valuations , we have
. In that case, 
we also say that  is \textbf{valid}.
Our first main theorem is the following:

\begin{thm}
 if and only if 
.
\end{thm}

So we have soundness and strong completeness. We start
with the only if direction, which is the usual soundness.

\proofbeg
\textit{\textbf{Soundness}}: We perform the usual proof by induction; 
we only prove those
cases which are not standard and straightforward. 
(ax), (I), (I1),(I2),
(I),(I) are clear.
(D) follows from the distributive law in .
\\

(ax?) should be clear: it follows immediately from (K10) 
that  holds.
\\

(I?1) 
Assume , and 
. 
We have  (by (K13)), and  is transitive and
respects concatenation. Consequently, 
.
\\

(I?2) is similar.
\\

(?I1) 
Assume , and
.
From the premises and the fact that from  it follows
that ;\footnote{Because 
then } we thus have
,
and by (K12),
, and thus
.
\\

(?I2) is similar.
\\





(1I) clear for (K6) and the fact that  matches .

(I1) is also obviously correct, as the empty antecedent is interpreted as
1.

(0I) follows from (K7) and (K4). 

(cut) This corresponds to strong transitivity, which we have established for
.
\\

This completes the soundness direction. 
\\

We now prove \textbf{\textit{completeness}}. We proceed in the usual fashion:
we construct the algebra  of -terms modulo -equivalence, 
where  is  modulo logical equivalence. We prove that 
 is a Kleene algebra. From this we can conclude: if 
, then 
there is a Kleene algebra , 
assignment , such  that 
,
and consequently, . By
contraposition, it follows that if ,
then  (alternatively, this goes by a
direct argument: if something holds in all Kleene algebras, it holds
in , therefore it is provable).

\textbf{Definition of }, term algebra 
or Lindenbaum-Tarski construction.

Define  as follows:
 if  and
. This is obviously an equivalence 
relation, because  is reflexive and transitive. 
We now define , 
the set of equivalence classes of  under 
, which is the generator set of . 
The operators and constants of our algebra are 
the constructors and constants of
, so we get the algebra 
, and for 
,
we define  iff there are , and ; we define
the equality 
 as usual: , if  
and . 

As usually, we have to show that  is a congruence over
the constructors, in order to show that  is a congruence
and thus the operations on equivalence classes are independent
of representatives. We indicate the usual inductive procedure:

1. If , , then .
This is fairly straightforward:
\\

, 
and the other way round.

2. If , , then .
Straightforward:
\\

,
and the other way round.

3. If , then .

Take the following derivation:
\\


\\

So we have shown that  is a congruence over constructors,
and thus the quotient algebra is well-formed and independent of
representatives. Therefore, we will proceed in the sequel as
if congruence classes of formulas were formulas, and not distinguish
the two notationally.
Now comes the crucial step, namely to show that  actually
\textit{is} a Kleene algebra. We prove that by going through
the equations (K1)--(K13) one by one. Recall that for ,
the equations consist of two inequations; while in principle, we have
to prove both, we usually 
only prove one direction, as the other one is similar.
Also, we omit some proofs, which are well-known from
existing logics.
\\

(K1) 

Obvious, canonical proof.


(K2) 

Obvious, canonical proof.

(K3) 

Obvious.

(K4) 

 follows from (I1),
 holds because 
.

(K5) 

Standard, as sequences separated by  are associative.

(K6) 

Straightforward from (1I),(I1) and the the -rules.

(K7) 

Clear from (0I).

(K8) 


follows from (D);

follows from ,
 and 
(I).

(K9) 

similar.
\\

(K10) 

We have to show that
. Here the derivation:



\\


(K11) 

similar. 
\\

(K12) If , then 

Assume we
have . 
We first show that in this case, 
we must have , .
If the last rule of the derivation tree concerned the left-hand side, there is
no choice: the rule was (I), and the claim follows,
because otherwise application was not legitimate.

So assume the last rule concerned the right-hand side;
in that case, there are several possibilities.
(I) can be excluded for the structure of the antecedent 
(it does not
contain ); 
the -rules  change the right hand side only in case of
empty antecedent, so they can be excluded; so the only
candidates are  (D) and (I1),(I2). All of these rules have
a very nice property: they are (1) unary, and (2) applicable
regardless of the properties of left hand side of the
antecedent. So we can safely assume that
 has been derived from 
, such that the last rule applied to
derive
 was (I), and 
 has been subsequently derived 
by applications of (D), (I1) and (I2) only. Consequently,
we must have two valid derivations of 
, and . Now, as the rules
(D), (I1), (I2) do not care for the left hand side, we can
thus also derive , and .

We can apply exactly the same argument to show that if we can derive
, we can also derive . 
Thus we know
that if  holds, then we 
also have  and .
We can thus apply (?I1) to derive


\\

(K13) If , then .

similar.
\\

This shows that  is a Kleene algebra and completes the proof
of completeness.
\proofend

Note that for the completeness part of the proof, the cut-rule is
not needed, in fact it is not even mentioned! There are a number 
of important consequences which follow from this
result. But before we come to these, we first introduce the logic 
and prove a similar result.

\section{}

We now present a new logic , which is a fragment of .
Our motivation is the following: we would like to intuitively interpret 
 as a sort of progressive aspect of the event
, that is: if  means ``(in some interval)  is completed",
then  should mean: ``(in some interval)  
is going on". Obviously, then (ax?) is way too strong: we
cannot assert that just anything is going on. What we rather can assert
is the weaker implication: if something happens (possibly several times)
in an interval, then it is happening in this interval:
if in some interval I ate a pizza, I was eating a pizza in this interval,
though not the converse, for my starting and finishing
the pizza might be laying outside the interval.\footnote{This is known as 
the imperfective paradox, 
see \cite{moenssteedman:ontology}; if I crossed the street, I was
crossing it, but not vice versa.} In terms of logical consequence, 
the progressive  of an atomic
event  can be characterized as follows: it follows from any
(non-zero) number of iterations (in terms of ) 
of  and , 
and from nothing else, except for transitivity and logical laws which govern the
other connectives.\footnote{Of course, this is a gross
simplification; linguistically speaking there is much more to it.
See for example \cite{galton:aspect}.}
We devise  in order
to agree with our intuition on the progressive aspect of events;
one of our main results will be that whereas the  of  can be
interpreted as Kleene star, the  of  can be interpreted
as Kleene plus.

As we said, the syntax of  is identical to . 
Regarding its consequence relation and sequent calculus, we
can re-use also most of the rules and axioms of . So we just
say which rules are discarded, and which ones are new.
To obtain the rules for , we take away 
the axiom (ax?)
and substitute it with the weaker axiom  (+?)
It is clear that (+?) is derivable in .
Note that (+?) \textit{cannot} derive a sequent of the form
 or
. This is our intention; but as a consequence
we also need to reconsider the rules (?I1) and (?I2), which we 
replace by (?+1),(?+2): 
\\

(+?) 
 (?+1) 
 (?+2) 
\\

Regarding these rules, we have to say the following: given 
the cut rule, (?I1) and (?I2) are derivable from (?+1) and (?+2),
respectively (just assume you have the premises of (?I1), 
, ; by cut, you get
). The converse is not true: 
we cannot derive (?+1) and (?+2) without (ax?). In particular, it is easy to 
show that without these rules, we cannot derive the sequent
: just ask what was the
last rule applied to this sequent: the 
(I) rule was not applicable to derive this sequent, 
for , and any other rule is out of 
the question for the syntactic form of the sequent.
As long as we have the cut rule, we can moreover
derive (I?1),(I?2). What if the cut rule is lacking? I
do not see how to derive the two, but from 
cut admissibility, which we prove later on
for , it follows that the two do not allow
us to derive anything we could not derive without them in
 . 
On a related note, note that
(?+1),(?+2) are also admissible in , that is, they would not
add anything new to the calculus, though I do not see how they 
can be derived. As we have the cut rule, we could thus
substitute (I?1),(I?2) by (?+1),(?+2) in , thereby 
giving a more uniform treatment of  and . The 
reason we have not chosen this presentation is the 
following: for the alternative
presentation, (as far as I can see) 
we need the cut-rule to prove that its term-algebra is a Kleene-algebra,
so our simple semantic proof of cut admissibility (see section 9)
for ``standard"  would no longer work.





It is clear that  is a fragment 
of , as its axioms and inference rules
are derivable in . The question is: what exactly is the expressive
power of ? We will show the following: we can give it
a strongly complete semantics
in terms of (slightly modified) Kleene algebras and in terms of language models,
by only a minor change in interpretation: we interpret 
the connector  as Kleene \textit{plus} instead of star. So
what changes with the new axiom is essentially the meaning of ,
and nothing else. The proof of this is however slightly more
complicated, as we have to make several steps consisting in algebraic
embeddings. It is well known that we can 
define  as  (or ). But nonetheless we cannot
work directly with Kleene algebras, putting 
, because we have
, but none of the corresponding sequents is provable,
and thus completeness fails.

As we do not work directly with
Kleene algebras, we have to work with a variant and two embeddings.
We interpret  in a class of algebras
which we call . We show strong completeness for this 
semantics, where we first go
the usual way: we show that the term 
algebra  of  is a 
 algebra, such that if , 
then . 

We then have to show that strong completeness
also holds for the language-theoretic semantics. To this aim,
we devise two maps , which map  terms onto  terms
and vice versa. We show some validity-preserving 
properties of these maps,
which allow us to extend language-completeness results from
 to , without having to perform a complicated proof from scratch
as in \cite{kozen:completeness}.


\section{Algebraic Semantics: -algebras}

We now define a variant of Kleene algebras, namely  or
Kleene plus algebras. We have the connectives , where
 is unary, and constants 0,1.  We have (K1)--(K9) as in ;
then things change. We list the new axioms (K14+)--(K17+), together
with the more expectable, but ``wrong" axioms (K10+)--(K13+), just to show
how the latter can be derived from the former, but not vice versa:
\\

(K14+) . 

(K15+) .

(K16+) If , then .

(K17+) If , then .
\\

((K10+) )

((K11+) )

((K12+) If , then ) 

((K13+) If , then ) 
\\

(K10+)--(K13+) are very ``expectable": they just consist in
(K10)--(K13), where each time,  is replaced by .
If we ``read"  as  (or ), then they are valid
in ,
because then we have . But the reader has
to keep in mind that we have a different algebra here, where
 does not exist as a connective. (K14+) and (K15+) seem to be redundant
with (K10+),(K11+), and in fact they create redundancy: we can derive
(K10+) from (K14+) and (K11+) from (K15+), but not vice versa
(at least I do not see how): we can easily derive  
 from (K10+); but we still have to get rid of the 1.
Conversely, we can derive (K10+),(K11+) from (K14+),(K15+):
if , then ; this means:

iff .
Same holds for the pairs (K12+),(K13+) and (K16+),(K17+):
we can derive (K12+) from (K16+), because if , then
by strong transitivity , and thus . 
The converse does not hold, 
and in particular, (K12+),(K13+) do not allow us to derive .
With (K14+),(K16+) it is an easy exercise (put ).
So we axiomatize  by (K1)--(K9),(K14+)--(K17+);
we leave the other axioms for illustration and because they turn
out to be useful for proving properties of our later embeddings.

Most basic properties of  transfer to : 
is defined over  in the usual fashion and is thus reflexive,
transitive and antisymmetric. 
The same holds for the fact that  
respects concatenation, because of distributivity, and we thus have
strong transitivity. 
We now devise an \textbf{interpretation} of  in . 
We define  as usual, and  as before, the expectable
exception that
\\

.
\\



\section{Completeness of the Algebraic Semantics}

We take the usual definitions, and prove soundness and completeness
of  for :

\begin{thm}
We have   if and only if
.
\end{thm}

\proofbeg
We start with the \textit{if} direction (\textbf{\textit{soundness}}). 
Most of the axioms can be skipped, as the old soundness arguments
remain valid (as  is a fragment of
, and most equations of  are valid in ). 
We only need to prove that the inference rules regarding
 are sound with respect to .
\\

(+?) 
We have to show that if , 
then .
That is straightforward with (K14+),  according to which ,
and transitivity of .
\\

(?+1) 
We make the usual induction. Assume the premises
are satisfied, that is, we have
 and
; consequently,
 
and . 
Consequently, by the order definition,
we have .  
By (K16+) it follows that 
,
and thus
.
\\

(?+2) 
similar.
\\

(I?1) 
Assume the premises hold. Then we have 
 and 
. We have to show that
 . 
Because  respects concatenation, we know that
. 
From  and transitivity it follows that
.
\\

(I?2) 
similar.
\\

This completes the soundness direction. 
\\

\textbf{\textit{Completeness}}.

We do the same construction as before, now call  the
algebra ; we define  to be 
the set of , that is, the set
of congruence classes of  formulas under the congruence
, which is logical equivalence in .
We put  iff 
for some , 
and put  iff  
and .
We skip the proof that  is a congruence
over connectives, which is straightforward, and write 
congruence classes as if they were formulas.

To show completeness, we have to show that 
is a -algebra. 
Again, we can skip  most of the equations as the proof is
identical to the one for ;
we check only those in which  (which is  in )
occurs, and which are not derivable. 
\\

(K14+) . 

It is obvious that ; we need to show that 
. That is also easy:

; 

and consequently
.
\\

(K15+) similar.
\\

(K16+) If , then . 

Assume we have . Then by the same
argument as for , we can conclude that we have both
 and . 
Then by (?+1), we derive


\\

(K17+) is similar.
\\

This completes the proof.
\proofend

Note again that the cut rule is not needed for the completeness proof.
But this is not as satisfying as the other completeness theorem,
because we do not know nearly as much about  algebras
as about  algebras. We now establish some results showing
the algebraic correlation between  and .


\section{Algebraic Relations between  and }

We now prove  three lemmas, which together give us a very 
powerful result. Let  be a  algebra,
 be a  algebra. We define the
map  as follows: 
\begin{enumerate}
\item for  atomic, ;
\item ;
\item ;
\item .
\end{enumerate}

 is a map from -terms to -terms. 
Its most important property is the following, which is
intuitively clear, but still needs to be proved.

\begin{lem}
If , then .\footnote{The inverse
implication can also be proved in much the same way as lemma 4, just using
lemma 5 instead of lemma 3. This result does however not play a 
role in the sequel, so we do not explicitly state it.}
\end{lem}

\proofbeg
We have .
Consider a class of algebras , which consists of all
algebras which are -images of -algebras. 
Its axioms are exactly the -images of
axioms (K1+)--(K13+), but the terms have a different syntax:
 is just a single constructor over , to which the distributive,
commutative, associative laws etc. do not apply. 
It is immediately clear
(by the purely syntactic translation) that 
 if and only if .
Now, as we have shown before, all axioms (K1+)--(K13+)
are valid in . Moreover, the syntactic difference
of  and  needs not bother us, as long as we are
trying to prove that  inequations are valid in
: in the latter, nothing prevents us from treating
 as a unit, that is, not applying any of distributive,
commutative or associative laws to it. So the inequations valid
in  are a (proper) subset of the inequations valid in
; and so, as , we have
.
\proofend

Now we define a sort of inverse of ; define the map
 from  to  terms as follows:
\begin{enumerate}
\item  for atomic ;
\item ;
\item ;
\item .
\end{enumerate}



\begin{lem}
If , then .
\end{lem}

\proofbeg
Assume we have . As  is trivial for all
connectives but , we only treat terms of the form . 
It follows from
the the map  that in  all occurrences  occur in 
subterms . Now form the images , which are
-terms. By lemma 3, we have
. Here, all occurrences of  are in subterms
. By the usual laws, we have
. Moreover, we have 
; so we have ; 
same for
; and thus .
\proofend

\begin{lem}
If , then .
\end{lem}

\proofbeg
We show this in the same fashion as lemma 3: construct an
intermediate class of algebras , where  is a single constructor over
, to which associative, distributive laws do not apply, and
where all terms
have the form  for some -term , and all -axioms 
in their translation under 
are valid. We show that all these -images of -axioms 
are also valid (under the different syntactic reading
of !) within : 

(j(K14+)) . 

That is obviously derivable by , , ,
and strong transitivity.
(K15+) is similar. 

(j(K16+)) If , then . 

Just put  in the quasi-inequation 
``if , then ", and
we obtain  from the premise. As we have 
, the consequence is valid in  if the
premises are.
(K17+) is similar.

Again, all axioms of 
are valid in ; the possible manipulations of  are
also a subset thereof, so everything valid in  is valid in ;
if , then , and thus .
\proofend

These results are of course of some value on their own, because they
show us how the intuitive correlation of  and  corresponds 
to formal notions. Their importance for  reveals itself in the
next section, where we consider language models.



\section{Completeness of Language-theoretic Semantics}

As is well known, we can interpret -terms as regular
expressions; atomic terms are interpreted as letters (or as 
languages),
 as union,  as concatenation, and  as Kleene
star, that is, union of all finite iterations. Let  be
a  term; we denote the language it denotes under this
interpretation by .
If  is a term over the set of (atomic) generators , 
then  (the set of all finite strings of
-symbols). The following 
fundamental theorem for Kleene algebras was proved by 
Kozen in \cite{kozen:completeness}:

\begin{thm}
(Kozen)
We have  if and only if .
\end{thm}

From this theorem and the lemmas of the preceding section we can easily
derive a similar result for  algebras. Let  be a 
term. We can interpret  terms as languages as follows:
\begin{enumerate}
\item , for atomic ;
\item ;
\item ;
\item .
\end{enumerate}
Thus the  is interpreted as Kleene plus. We now show the following:

\begin{thm}
We have  if and only if 
.
\end{thm}

\proofbeg
\textit{If}: Assume . 
We can read
 as regular expressions with Kleene plus. By definition of the
Kleene plus in terms of the star, we have ,
same for . Consequently, ,
and by theorem 6, . By lemma 4,
we obtain . 

\textit{Only if}: Assume . 
By lemma 5, we then have , and thus
. So the claim
follows the fact that .
\proofend

From this follows that both  and  have a complete
language-theoretic semantics:

\begin{thm}
We have 
\begin{enumerate}
\item  if and only if 
; and
\item  if and only if 
.
\end{enumerate}
\end{thm}

Now, as under this interpretation, formulas of both  and
 denote regular languages, and the problem whether one
regular language (represented, e.g., as a regular expression)
is a subset of another one is decidable, we immediately get the following:

\begin{thm}
 are decidable, that is, for any sequent ,
we can effectively decide whether ,
 hold.
\end{thm}

So in order to decide whether a sequent is valid, we can just go
over the language-theoretic interpretation of formulas as regular
expressions. A more direct way to establish the
decidability of  is by showing that for every derivable
sequent, there is a proof which does not make use of the cut rule.


\section{Cut Admissibility}

We now show that in  cut is admissible, 
that is, for every proof of a sequent in the two calculi
there is a  cut-free proof.
\footnote{Contrary to some other
usage, we do not speak of cut elimination, because we only show
the existence of a cut free proof, whereas cut elimination means
that from a proof using cut we can effectively construct a cut free
proof.} 
This is important for the following reason:
the cut rule is the only rule in which there is material
in the antecedents, which is not in the consequent; so when we 
want to check whether a sequent is derivable in our
calculi, it is the only rule which makes the search space infinite;
for all other rules, we know how the antecedents have
to look like (in the sense of: there is a finite number of 
possible choices). So from cut admissibility follows that  are
decidable also ``inside the calculus", without a detour over
semantics. 

How does this result follow? We established the
soundness of the cut rule. But in order to show the completeness
direction of the algebraic semantics, proving the term 
algebra of  is a  algebra, respectively, 
we did not make any use of the cut rule. 
Now let  be the logics which 
result from taking all axioms and inference 
rules of  and , respectively,
except for the cut rule. To prove their soundness and completeness for 
, we can take over the proofs for  without
any change, except that we can do away with soundness of cut. 
So we have  
iff  iff ,
same for  and . The only problem with this reasoning
is that the interpretation  is a homomorphism rather than a
bijection, as it maps both  and  to . So
in addition we need a proof of the fact that 
 iff 
, and the
same for . This is however easy to show (cf. \cite{galatos:residuated},
Proposition 7.1). From this follows: 


\begin{thm}
In both , the cut rule is admissible.
\end{thm}




\section{Conclusion}

We have presented two propositional substructural logics,
strongly inspired by Kleene algebras and 
some considerations on processes. We have proved strong completeness 
theorems for algebraic semantics as well
as for language models. We have also
proved cut admissibility, from which follows the decidability of the
calculus by purely syntactic means (though the cut admissibility
proof itself is semantic). 
By our strong completeness, proof search in the calculus of 
can be reduced to the validity of an inequation in all Kleene algebras
(PSPACE-complete). There remains
the question whether for some subclass 
of formulas, we can do substantially better
(this is an approach commonly taken, see \cite{hovland:inclusion}): 
there might fall off a good 
algorithm for checking the inclusion relation
of languages denoted by two regular expressions.
Another question is the following: as can be seen from already
existing work (see e.g. \cite{buszkowski:action}), if we enrich
a substructural logic having an exponential as  with implication
(or vice versa), undecidability strikes rather quickly. Still,
the decidability results for  seem robust;	 
in particular, 
we conjecture that the \textit{external} consequence
relations (the smallest structural consequence relations generated
by the two, see e.g. \cite{galatos:residuated}) 
of the two logics are decidable.
These seem to us the most natural and
interesting questions to ask. 

\bibliographystyle{eptcs}
\bibliography{alles_7_14}
\end{document}
