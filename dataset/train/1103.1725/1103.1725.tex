

\documentclass[a4paper,twoside]{article}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc} \usepackage{RR,RRthemes}
\usepackage[dvips, 
  a4paper,
  hypertexnames=true, 
  backref=section, 
  colorlinks=true, 
  citecolor=blue,
  bookmarks=true, 
  bookmarksopen=true, 
  pdftitle=Adding\ Network\ Coding\ Capabilities\ to\ the\ WSNet\ Simulator, 
  pdfauthor=Wei\ Liang\ Choo\ -\ Frédéric\ Le\ Mouël\ -\ Katia\ Jaffrès-Runser\ -\ Marco Fiore, 
  pdfsubject=INRIA\ Technical\ Report, 
  pdfcreator=dvipdf,
  pdfkeywords=Network\ Coding\ -\ Wireless\ Sensor\ Network\ (WSN)\ -\ Simulation\ -\ WSNet]{hyperref}
\usepackage{graphicx}
\usepackage{listings}

\sloppy

\lstset{ language=Octave,                basicstyle=\footnotesize,       showspaces=false,               showstringspaces=false,         showtabs=false,                 frame=single,                   tabsize=2,                      captionpos=b,                   breaklines=true,                breakatwhitespace=false,        title=\lstname,                 }

\RRdate{March 2011}



\RRauthor{
Wei Liang Choo\thanks[univ]{University of Lyon, INSA-Lyon, CITI, F-69621, Villeurbanne, France, \texttt{\{firstname.lastname\}@insa-lyon.fr}}
\and
Frédéric Le Mouël\thanksref{univ}
\thanks[inria-amazones]{INRIA, AMAZONES Team}
\and
Katia Jaffrès-Runser\thanksref{univ}
\thanks[inria-swing]{INRIA, SWING Team}
\and
Marco Fiore\thanksref{univ}
\thanksref{inria-swing}
}

\authorhead{Choo \& Le Mouël \& Jaffrès-Runser \& Fiore}

\RRtitle{Implantation d'un module de codage de réseaux dans le simulateur WSNet}

\RRetitle{Adding Network Coding Capabilities \\ to the WSNet Simulator}

\titlehead{Adding Network Coding Capabilities to the WSNet Simulator}

\RRresume{Ce rapport technique présente l'implantation d'un module de codage de réseaux dans le simulateur de capteurs sans-fil WSNet. L'objectif de conception de ce module est d'avoir une interface de programmation générique pour ensuite spécialiser facilement différentes stratégies de codage: aléatoire, orienté-source/destination, intra/inter-flux, etc.}

\RRabstract{This technical report presents the implementation of a Network Coding module in WSNet - a Wireless Sensor Network simulator. This implementation provides a generic programming interface to allow an easy specialization of different coding strategies: random, source/destination-oriented, intra/inter-flow, etc.}

\RRmotcle{Codage des réseaux, Réseaux de capteurs sans-fil, Simulation, WSNet}

\RRkeyword{Network Coding, Wireless Sensor Network (WSN), Simulation, WSNet}

\RRthemeProj{swing}
\RRprojet{SWING}

\URRhoneAlpes 

\RRNo{0405}

\begin{document}

\makeRT 

\tableofcontents
\newpage

\section{Introduction}

Our goal is to study the impact of different Network Coding strategies~(NC) on end-to-end service delivery over mobile and wireless Disruption-Tolerant Networks~(DTNs). To realize this study, in a first step, we simulate a mobile and wireless DTN environment. This report presents (i) in section~\ref{section:context}, the context: DTN, NC and why we have chosen the WSNet simulator, (ii) in section~\ref{section:nc-module}, our NC framework provided in a WSNet module: architecture, generic API definition, packet storing, linear independence checking, real encoding/decoding.

\section{Context}
\label{section:context}

\subsection{Disruption-Tolerant Network}

Disruption-Tolerant Networking~(DTN) is an approach that seeks to address the non-constant nature of links in networks~\cite{Fall:2003:DNA:863955.863960}. This could be caused by mobility of the nodes or interference in the environment. 

\begin{figure}[!hbt]
\centering
\includegraphics[width=0.75\textwidth]{figures/DTN}
\caption{Disrupted Network Example}
\label{fig:dtn}
\end{figure}

Figure~\ref{fig:dtn} shows an example of DTN where, as a node moves, the link previously established is broken. The link may be established again once the node moves back into range of communicating with the original node. Conventional routing involves finding a path and forwarding packets from the source to the destination. However because of the link break, storing and then forwarding when the link is re-established may be needed - so introducing a delay. A common approach is to send out replicated packets to many nodes hoping that packets will reach the destination. However, this takes up large amounts of storage and bandwidth.

Strategies involving Network Coding are to be accessed to judge their impacts on delay/tolerance/capacity improvement of a DTN environment~\cite{Zhang06, 4509805, Altman:2010:DCC:1833515.1833540}.

\subsection{Network Coding}

Network Coding~(NC) is a technique where nodes of a network are able to combine together two more or received packets and transmit them~\cite{Fragouli:2006:NCI:1111322.1111337}. With enough information - enough encoded packets, the original packets can then be decoded at the destination. This is a change from just forwarding packets which can bring about potential throughput improvements and a high degree of robustness.

\begin{figure}[!hbt]
\centering
\includegraphics[width=0.65\textwidth]{figures/NC}
\caption{Network Coding Butterfly Example}
\label{fig:nc}
\end{figure}

Figure~\ref{fig:nc} presents the Butterfly Network Coding multicast example. S1 and S2 are Source nodes, R1 and R2 are Relay nodes, D1 and D2 are Destination nodes and x1 and x2 are packets from S1 and S2 respectively. D1 and D2 needs to receive both x1 and x2 packets. In the traditional packet sending method, x1 would be sent to D1 from S1 directly. But due to distance from D2, S1 will send x1 via R1 to R2 and then to D2. The same case is for S2 and D1. R1 forwards the whole packet x1 then x2, to R2 which then forwards it to D1 and D2. 
Using NC, when R1 receives both x1 and x2, R1 can combine the packets and send only one packet combining both x1 and x2 to R2 which forwards it to D1 and D2. D1 and D2 use this encoded packet to retrieve the other missing packet. In this case, NC thus helps in reducing the sending of a second packet from R1 and R2.

According to the network topologies considered (linear vs non-linear, multicast vs non-multicast, directed vs undirected, cyclic vs acyclic), different NC strategies exist to select and encode packets~\cite{katti2005}: random, unique/multi source-oriented, unique/multi destination-oriented, intra-session, inter-session, etc. We plan to develop and test social and service-oriented NC strategies and so we need a realistic simulation environment to compare them in a mobile and wireless DTN.

\subsection{WSNet Simulator}

WSNet is a simulator for large-scale Wireless Sensor Networks created and developed at the CITI Laboratory~\cite{Fraboulet:2007:WDP:1236360.1236385}. While several simulator exist for DTN~\cite{RomeroAmondaray:2008:DTN:1409985.1410006, keranen-theone}, WSNet main features - Node Simulation, Environment Simulation, Radio Medium Simulation and Extensibility - are particularly suitable for our NC testing. Radio medium simulation provides realistic radio channel modeling appropriate to test wireless communication in mobile DTN. Node Simulation allows the integration of the application level, suitable to test social and service-oriented NC strategies.

\begin{figure}[!hbt]
\centering
\includegraphics[width=0.55\textwidth]{figures/WSNet}
\caption{Modular Architecture of a WSNet Node}
\label{fig:wsnet}
\end{figure}

Figure~\ref{fig:wsnet} describes a node architecture that can be created in WSNet. There are already various standing modules that can be used for each part: support for complex nodes architecture~(MIMO systems, multiple radio/antenna interface support), support for energy consumption simulation, support for various propagation models, support for propagation delays, etc. Modules are attached on run time and an XML file is used to control the WSNet. 

\section{A Generic Network Coding Module in WSNet}
\label{section:nc-module}

\subsection{Module Configuration}

Using the WSNet extensibility feature~\cite{BenHamida2007a}, we have developed an application module that simulates a wireless DTN with NC by storing, selecting/dropping, encoding/decoding IP packets.

\begin{figure}[!hbt]
\centering
\includegraphics[width=0.55\textwidth]{figures/WSNet-NC}
\caption{Network-Coding Module in WSNet}
\label{fig:wsnet-nc}
\end{figure}

We configure and test it with different existing WSNet modules~\cite{BenHamida2007b} (cf Figure~\ref{fig:wsnet-nc} and Listing~\ref{list:confxml}). No routing module has currently been used since a static one, with the Butterfly example, was applied.

\lstinputlisting[language=XML,caption=DTNNC\_Butterfly\_example.xml,label=list:confxml]{listings/DTNNC_test_example.xml}

\subsection{Architecture Overview}

The Figure~\ref{fig:wsnet-nc-architecture} presents the architecture of the NC module. Each node includes the \texttt{functions.h} header file, entry point of the framework. This file defines (i) the common node structure, variables and data storage - detailed in section~\ref{section:node}, (ii) the common masking/encoding/decoding functions - detailed in section~\ref{section:nc-api} and (iii) useful logging functions - detailed in section~\ref{section:log-api}.

\begin{figure}[!hbt]
\centering
\includegraphics[width=\textwidth]{figures/WSNet-NC-Architecture}
\caption{Network-Coding Module Architecture}
\label{fig:wsnet-nc-architecture}
\end{figure}

\subsection{Node Definition}
\label{section:node}

\subsubsection{Node Type}

All common aspects of a node are included in \texttt{DTNNC\_dictionary.h}, \texttt{DTNNC\_node\_structure.h}, \texttt{DTNNC\_functions.h}, \texttt{DTNNC\_functions.c} and \texttt{DTNNC\_dataStorage\_handler.h}. Each node can then be specialized and instantiated to be a:

\begin{description}
\item[\emph{Source}] \hfill
  \begin{itemize}
  \item Creates packets
  \item Sends packets
  \end{itemize}
\newpage
\item[\emph{Sensor}] \hfill
  \begin{itemize}
  \item Stores received packets
  \item Encodes packets, including masking and xor-ing packets
  \item Decodes encoded packets, if possible and needed
  \item Sends encoded packets out
  \end{itemize}
\item[\emph{RelayDumb}] \hfill
  \begin{itemize}
  \item Forwards received packets
  \end{itemize}
\item[\emph{Sink}] \hfill
  \begin{itemize}
  \item Stores received packets
  \item Decodes 
  \end{itemize}
\end{description}

\subsubsection{Node Common Variable Definitions: \texttt{dictionary.h}}

\texttt{DTNNC\_dictionary.h} defines keywords to make code more readable and easier to use.

\lstinputlisting[language=C,caption=\texttt{DTNNC\_dictionary.h},label=list:ndict]{listings/DTNNC_dictionary.h}

\subsubsection{Node Structure: \texttt{node\_structure.h}}

\texttt{DTNNC\_node\_structure.h} defines the common structure of all nodes. It is easier to edit one structure for all nodes than to make a specific structure for each node type. Most variables are needed in all node types.

\lstinputlisting[language=C,caption=\texttt{DTNNC\_node\_structure.h},label=list:nstruc]{listings/DTNNC_node_structure.h}

\subsubsection{Node Management Functions: \texttt{node\_functions.h}}

\texttt{DTNNC\_node\_functions.h} allows to manage a node. It creates the variables, allocates the memory for variable structures, and sets the variables to default. This API simplifies the development. Editing or adding a new node variable requires the editing and adding of this variable in each node type’s source code file. With this API, it requires to be done only one time in one place.

\lstinputlisting[language=C,caption=\texttt{DTNNC\_node\_functions.h},label=list:nfunc]{listings/DTNNC_node_functions.h}

\subsubsection{Node Storage: \texttt{packet.h} \texttt{dataStorage\_handler.h}}

Data stored are IP packets. These packets are potentially xor-mixed packets, so a packet header includes the number and a table of sub-packet headers. A final sub-packet header contains an id (can be an application or a service id), a sequence number ordering a packet flow, a source and $n$ destinations (for broadcast or multicast). Packet data structure contains the real data (here a dummy example with 4 characters).

\lstinputlisting[language=C,caption=\texttt{DTNNC\_node\_dummy\_packet.h},label=list:npacket]{listings/DTNNC_node_dummy_packet.h}

\texttt{DTNNC\_dataStorage\_handler.h} defines generic functions providing the storage functionality. The data storage structure can easily be changed without changing many other code source files. Accessing data is allowed by using get and set methods and not accessing to the data directly.

\lstinputlisting[language=C,caption=\texttt{DTNNC\_dataStorage\_handler.h},label=list:nstorage]{listings/DTNNC_dataStorage_handler.h}

\subsection{Network-Coding API Definition}
\label{section:nc-api}

\subsubsection{Node NC Entry Point: \texttt{functions.h}}

\texttt{DTNNC\_functions.h} header file is the main entry point of our framework and connects all other files of the module. It defines the four functionalities of one node: storing / dropping / encoding / decoding IP packets. \\

\noindent Creation of a node only needs to include \texttt{DTNNC\_functions.h}

\lstinputlisting[language=C,caption=\texttt{DTNNC\_functions.h},label=list:func]{listings/DTNNC_functions.h}

\subsubsection{NC Masking: \texttt{functions\_mask.h}}

Before combining different packets, a choice of fragmenting data information of one packet can be done. Part of the data can be kept and part can be 'masked'. We use the word 'mask' for the randomly chosen coefficient used in the random linear network coding ($p = \sum_i \lambda_i p_i$, with $p_i$ the packet fragments, $\lambda_i$ the coefficients which are referred to in the following as 'masks'). \texttt{DTNNC\_functions\_mask.h} offers this masking function.

\lstinputlisting[language=C,caption=\texttt{DTNNC\_functions\_mask.h},label=list:funcm]{listings/DTNNC_functions_mask.h}

\subsubsection{NC Masking - one implementation: \texttt{functions\_mask.c}}

There are various methods that can be used to mask packet data. Upon consideration, the method described in Figure~\ref{fig:masking} is used.

\begin{figure}[!hbt]
\centering
\includegraphics[width=\textwidth]{figures/Masking}
\caption{One Data Masking Implementation: One Additional Byte / Byte to Bit conversion / Flow masking}
\label{fig:masking}
\end{figure}

One additional byte is added to the data packet during the packet memory allocation. The purpose is to tackle the problem of improper masking when the total bit size of the packet data is not a factor of the mask size. 

Packet data is copied byte by byte into a byte storage (byteStoreA). Data in byteStoreA is then transferred bit by bit into a bit storage (bitStoreB). Data in bitStoreB is then transferred bit by bit into a FPower/Size of Mask storage (fPowerStoreC) (in Figure~\ref{fig:masking}, size of the mask is 3). fPowerStoreC is then masked using the selected mask (in Figure~\ref{fig:masking}, the mask is 001). fPowerStoreC is then transferred back bit by bit to bitStoreB. bitStoreB is transferred bit by bit to byteStoreA. byteStoreA is then copied byte by byte into the dataHolder. Finally, the mask is stored into the argument storage of the dataHolder.

\subsubsection{NC Encoding: \texttt{functions\_encode.h}}

\texttt{DTNNC\_functions\_encode.h} encodes data depending on an encoding strategy.
	
The \texttt{encodeFunction} acts as a controller function. When this function is called, it first checks the encoding validity and then calls the real specific encoding function. Currently the checking consists in testing the node role: if the node is only a relay, it checks if there is only one packet in storage buffer and forwards that packet without changing it; if the node has an encoding role and several packets in the buffer, then the real specific encoding function is called.

\lstinputlisting[language=C,caption=\texttt{DTNNC\_functions\_encode.h},label=list:funce]{listings/DTNNC_functions_encode.h}

\subsubsection{NC Encoding - one implementation: \texttt{functions\_encode.c}}

We provide in the module one random XOR encoding implementation in \texttt{DTNNC\_encode\_XOR.h} and \texttt{DTNNC\_encode\_XOR.c}. Two random packets are chosen from the stored data in the node. As \texttt{rand()} of C is biased, an improved version of random is used: seeding of the random number is done at start of node setup at \texttt{init()} of each node type.

\lstinputlisting[language=C,caption=\texttt{DTNNC\_encode\_XOR.h},label=list:funcexor]{listings/DTNNC_encode_XOR.h}

\subsubsection{NC Decoding: \texttt{functions\_decode.h}}

\texttt{DTNNC\_functions\_decode.h} decodes data following a decoding strategy.

The \texttt{decodeFunction} acts also as a controller function. It checks linear dependency before decoding: it checks if the last received packet contains enough relevant new information comparing to existing information in the storage buffer. If so the decoding testing is applied.

\lstinputlisting[language=C,caption=\texttt{DTNNC\_functions\_decode.h},label=list:funcd]{listings/DTNNC_functions_decode.h}

\subsubsection{NC Decoding - one implementation: \texttt{functions\_decode.c}}

We provide in the module one Gaussian Elimination implementation in \texttt{DTNNC\_decode\_gaussian\_elimination.h} and \texttt{DTNNC\_decode\_gaussian\_elimination.c} (cf Listing~\ref{list:funcdgauss}). The \texttt{linearIndependentCheck} function implements the Linear Independence Checking; the \texttt{forwardSubstitution} function implements the first phase of the Gaussian method: the Forward Substitution; the \texttt{reverseElimination} function implements the second phase of the Gaussian method: the Reverse Elimination; the \texttt{reconstructPacket} function finally implements the third phase of the Gaussian method and retrieves the original packet.

\lstinputlisting[language=C,caption=\texttt{DTNNC\_decode\_gaussian\_elimination.h},label=list:funcdgauss]{listings/DTNNC_decode_gaussian_elimination.h}

We illustrate the Gaussian implementation with an example in Figures~\ref{fig:fs1}-\ref{fig:rc2}: a masking in the finite group $F_{2^3}$ has been applied on 2 packets from different sources.

\begin{enumerate}
\item Checking Linear Independence

Checking Linear Independence is basically the same as the Forward Substitution process and code. However doing forward substitution corrupts the matrix and if the modified matrix is not linearly independent, the original matrix cannot be retrieved easily.

Therefore the first step of checking linear independence phase is to clone the matrix into a temporary matrix for testing linear independence. As this is just a checking phase, data is not touched and therefore not cloned. Check for linear independence fails when the matrix lines swap is not successful, meaning a triangulation can not be performed. 

\item Forward Substitution

Figures~\ref{fig:fs1} to~\ref{fig:fs3} show how forward substitution is done. It starts from the top of the matrix and works in the binary format (even if the matrix is stored in an integer format).

\begin{itemize} 
\item Swap phase \hfill \\
If the first bit of the first column is not at 1, the algorithm finds the first row containing this 1 and data of the rows are swapped.

\begin{figure}[!hbt]
\centering
\includegraphics[width=0.7\textwidth]{figures/ForwardSubstitution1}
\caption{First step of Forward Substitution phase}
\label{fig:fs1}
\end{figure}

\begin{figure}[!hbt]
\centering
\includegraphics[width=0.7\textwidth]{figures/ForwardSubstitution2}
\caption{Second step of Forward Substitution phase}
\label{fig:fs2}
\end{figure}

\item XORing phase \hfill \\
The algorithm then checks other rows to find if the first bit of the first column is also at 1. Each matching rows are then xor-ed with the first swapped row, ensuring that only the first row has the first bit positioned to 1. All data of the row are xor-ed as well.
\end{itemize}

These Swap phase and the XORing phase are repeated for each row from top to bottom until a triangle of 1 is achieved in Figure~\ref{fig:fs3}.

\begin{figure}[!hbt]
\centering
\includegraphics[width=0.25\textwidth]{figures/ForwardSubstitution3}
\caption{Final state of Forward Substitution phase}
\label{fig:fs3}
\end{figure}

\item Reverse Elimination

Figures~\ref{fig:re1} to~\ref{fig:re3} show the reverse elimination process. It starts from the bottom of the matrix. From the bottom matrix last sub column, rows are scanned from bottom to up to ensure only that row is set at 1 in the sub column. Should a 1 be found, a XORing phase is applied and that row is xor-ed along with its data to remove the 1. The algorithm then proceeds on next rows till a diagonal line of 1, like in Figure~\ref{fig:re3}, is achieved.

\begin{figure}[!hbt]
\centering
\includegraphics[width=0.73\textwidth]{figures/ReverseElimination1}
\caption{First step of the Reverse Elimination phase}
\label{fig:re1}
\end{figure}

\begin{figure}[!hbt]
\centering
\includegraphics[width=0.73\textwidth]{figures/ReverseElimination2}
\caption{Second step of the Reverse Elimination phase}
\label{fig:re2}
\end{figure}

\begin{figure}[!hbt]
\centering
\includegraphics[width=0.25\textwidth]{figures/ReverseElimination3}
\caption{Final state of the Reverse Elimination phase}
\label{fig:re3}
\end{figure}

\newpage

\item Reconstruction of packets

Figure~\ref{fig:rc1} and Figure~\ref{fig:rc2} show how the reconstruction is done. A reconstruction packet storage is used to separate the fragmented packets from the reconstructed ones (the original data storage may be use later). From the top, (size of mask) number of rows are xor-ed to the first packet of the reconstruction storage to reconstruct the original packet. The data is Xor-ed as well. Then the same process of (size of mask) number of rows xor-ing is applied until the end of the matrix.

\begin{figure}[!hbt]
\centering
\includegraphics[width=0.73\textwidth]{figures/Reconstruction1}
\caption{First xor-ings of the Reconstruction phase}
\label{fig:rc1}
\end{figure}

\begin{figure}[!hbt]
\centering
\includegraphics[width=0.73\textwidth]{figures/Reconstruction2}
\caption{End of xor-ings, final state of Reconstruction phase}
\label{fig:rc2}
\end{figure}

\end{enumerate}

\newpage

\subsection{Log API Definition}
\label{section:log-api}

WSNet produces ASCII prints on standard output. \texttt{DTNNC\_functions\_log.h} defines some useful functions for printing out statistics logs and debug outputs. \texttt{DTNNC\_functions\_log.h} includes node common variables outputs: id, position, etc.

\lstinputlisting[language=C,caption=\texttt{DTNNC\_functions\_log.h},label=list:log]{listings/DTNNC_functions_log.h}

\texttt{DTNNC\_log\_normal.h} outputs statistics about 'normal' events of the Network Coding module use: number of packets received/sent, encoding/decoding/ linear checking, etc.

\lstinputlisting[language=C,caption=\texttt{DTNNC\_log\_normal.h},label=list:logn]{listings/DTNNC_log_normal.h}

\texttt{DTNNC\_log\_debug.h} implements debugging log functions. These functions print the internal node state.

\lstinputlisting[language=C,caption=\texttt{DTNNC\_log\_debug.h},label=list:logd]{listings/DTNNC_log_debug.h}

Debug outputs are data-packet specific. These functions do not show only the packet header but output also the packet data to check its correctness. Therefore changing the dummy packet data structure will require to reimplement these functions. For instance, such implementation of the \texttt{DTNNC\_log\_debug.h} API needs to be adapted.
\begin{lstlisting}
printf("] dataA [\end{lstlisting}

\newpage

\section{Conclusion}

This technical report has described the implementation of a \emph{Network Coding module for Wireless and Mobile DTN} in WSNet - a Wireless Sensor Network simulator. This module provides a generic framework that includes: 
\begin{itemize}
\item Programming Interfaces that defines a generic DTN node and its functionalities: IP packet storing, selecting/dropping, encoding/decoding.
\item Implementations for the main Network Coding functionalities: random selecting, random linear coding over $F_{2^n}$, Gaussian Elimination decoding.
\end{itemize}
Programming Interfaces has been generically defined to allow an easy specialization for future different coding strategies: source/destination-oriented, intra/inter-flow, application-oriented, social-oriented.

\newpage

\bibliographystyle{plain}
\bibliography{RT-0405}

\end{document}
