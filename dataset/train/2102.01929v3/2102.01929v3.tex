

\documentclass[final]{cvpr}

\usepackage{times}
\usepackage{epsfig}
\usepackage{graphicx}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{algpseudocode}
\usepackage{algorithm}
\usepackage{indentfirst}
\usepackage{tabularx,booktabs, etoolbox}
\usepackage{xcolor}
\usepackage{pifont}
\usepackage{multirow}
\usepackage{subfigure}
\usepackage{caption}
\usepackage{gensymb}


\newlength{\toprulewidth}
\setlength{\toprulewidth}{0.25ex}
\patchcmd{\toprule}{\heavyrulewidth}{\toprulewidth}{}{}

\newlength{\bottomrulewidth}
\setlength{\bottomrulewidth}{0.25ex}
\patchcmd{\bottomrule}{\heavyrulewidth}{\bottomrulewidth}{}{}



\usepackage[pagebackref=true,breaklinks=true,colorlinks,bookmarks=false]{hyperref}

\def\cvprPaperID{3200} \def\confYear{CVPR 2021}


\pagenumbering{gobble} \begin{document}





\title{Regularization Strategy for Point Cloud via Rigidly Mixed Sample}









\author{Dogyoon Lee \quad
       Jaeha Lee \quad
       Junhyeop Lee \quad
       Hyeongmin Lee \quad
       Minhyeok Lee \\
       Sungmin Woo \quad
       Sangyoun Lee \\ 
\vspace{0.01cm}\\
       Yonsei University \\
       {\tt\small \{nemotio,jaeha0725,jun.lee,minimonia,hydragon516,smw3250,syleee\}@yonsei.ac.kr}
}

\maketitle
\begin{abstract}
Data augmentation is an effective regularization strategy to alleviate the overfitting, which is an inherent drawback of the deep neural networks. However, data augmentation is rarely considered for point cloud processing despite many studies proposing various augmentation methods for image data. Actually, regularization is essential for point clouds since lack of generality is more likely to occur in point cloud due to small datasets. This paper proposes a Rigid Subset Mix~(RSMix)\footnote{Project page: \textit{\urlstyle{sf}\url{https://github.com/dogyoonlee/RSMix}}}, a novel data augmentation method for point clouds that generates a virtual mixed sample by replacing part of the sample with shape-preserved subsets from another sample. RSMix preserves structural information of the point cloud sample by extracting subsets from each sample without deformation using a neighboring function. The neighboring function was carefully designed considering unique properties of point cloud, unordered structure and non-grid. Experiments verified that RSMix successfully regularized the deep neural networks with remarkable improvement for shape classification. We also analyzed various combinations of data augmentations including RSMix with single and multi-view evaluations, based on abundant ablation studies.
\end{abstract}
\vspace{-0.3cm}





\begin{figure}[t!]
\includegraphics[scale=1.0]{./figures/figure_1_4.pdf} 
\caption{Qualitative results with RSMix. Purple~(left) and yellow~(middle) colored points indicate Rigid Subsets to be extracted from each sample to synthesize red and green colored mixed samples~(right).}
\vspace{-0.5cm}
      \label{fig:representative_figure}
\end{figure}



\section{Introduction} \label{section:Introduction}
Deep neural networks have achieved outstanding performances in various fields regardless of the data domains, such as image, video, speech, and point cloud. In particular, three-dimensional~(3D) point cloud processing is attracting considerable interest following the pioneering network PointNet~\cite{qi2017pointnet} development, since point clouds can be applied directly to deep learning without preprocessing. Although various tasks have been successfully addressed using point clouds, such as 3D object shape classification and part segmentation, inherent drawback of deep learning is still less considered in the point cloud domain.
Due to the typical nature of deep neural networks~(DNNs) that approximates the model from the given data distribution, the trained model tends to be overfitted regardless of the data domain. This lack of generality is a fundamental deep learning problem. One way to alleviate overfitting and generalize the model is data augmentation, which improves diversity of the training data.\\
\indent Various data augmentation methods have been recently proposed in the image domain as network regularization strategies, but data augmentation for point clouds has only rarely been considered. Actually, regularization is essential for point clouds since it is easier to be biased to the distribution of training samples than that of image. That is largely because point cloud datasets~\cite{wu20153d,chang2015shapenet,dai2017scannet} are typically considerably smaller and less diverse than image datasets, such as ImageNet~\cite{deng2009imagenet} and MSCOCO~\cite{lin2014microsoft}, which have millions of training data. For example, ModelNet40~\cite{wu20153d}, one of the most widely used point cloud dataset, includes only 12,311 models with 40 categories. Therefore, it is essential to improve the generality of models for point cloud.\\
\indent In the image domain, regional dropout~\cite{zhong2020random,singh2017hide,ghiasi2018dropblock,devries2017improved} and mixup-based methods~\cite{zhang2017mixup,verma2019manifold,yun2019cutmix,kim2020puzzle,harris2020fmix} have been proposed as data augmentation strategies, which are different to conventional methods, to generate virtual training samples. These methods are designed to improve generality of the neural network, preventing the model from being significantly affected by only small part of the sample that has discriminative characteristics by eliminating or mixing the part of the data. However, it is difficult to apply this intuition directly to the point clouds due to two inherent properties of point cloud: non-grid and order-invariance. Although Chen~\etal~\cite{chen2020pointmixup} applied the concept of Mixup~\cite{zhang2017mixup} to point clouds handling the properties of point cloud with linear interpolation based on optimal assignment, generated samples lost the structural information of the original sample due to distortion.\\
\indent This paper proposes Rigid Subset Mix~(RSMix), the shape-preserving data augmentation method for point clouds that can partially mix two samples, preserving the partial shapes of the original samples. We redefine the concept of mask region from image analysis and adapt it to 3D space to extract parts from each sample while preserving structural information of the point cloud. We also define a Rigid Subset~(RS) derived from the redefined mask region, a group of adjacent points within a certain distance from a specific query point using a neighboring function to address unique characteristics: unordered structure and non-grid. In contrast to PointMixup~\cite{chen2020pointmixup}, we can utilize structural information of the original point cloud sample intactly by using RS. In addition, we designed RS scale to vary, to improve diversity of the training sample, and hence increase regularization effects. Furthermore, RSMix can be used in conjunction with the existing data augmentation since it utilizes the part of the given data intactly. In the end, by introducing RS, we can improve generality of DNNs and give attention them to recognize parts of the object. In Section~\ref{subsection:mask_region_3d}, we describe in detail how to generate the virtual sample preserving shape of the source sample by extracting RS. In advance, we provide visualized RS samples to be extracted and resultant mixed samples in \figurename~\ref{fig:representative_figure}. \\
\indent We provide the experimental results for shape classification on ModelNet40~\cite{wu20153d} and ModelNet10~\cite{wu20153d} with the most representative DNN approaches~\cite{qi2017pointnet++,wang2019dynamic} for point clouds. RSMix successfully improved the network performance, outperforming the existing data augmentation methods. Moreover, abundant ablation studies for various combinations of existing data augmentation and RSMix verified that RSMix improved the model regardless of which conventional data augmentation method was employed.\\
\indent Meanwhile, we analyzed the experimental results with respect to two evaluation mechanisms to ensure fair comparisons. In fact, although the evaluation methods of shape classification on point cloud are divided into two ways: single and multi-view, many studies present their experimental results without clearly specifying their mechanism. This makes hard to quantitatively compare results among studies. Our experiments show that the results evaluated by single and multi-view approaches have significant differences. Therefore, it is essential to analyze experimental results along the evaluation methods. Sections \ref{subsection:ablation_study} presents analysis with single and multi-view approaches based on ablation studies.\\
\indent To summarize, this paper provides the following major contributions.
\begin{itemize}
	\item \textit{Shape preserving augmentation.} We propose new data augmentation method for point clouds that mixes training samples with preserved structures by using Rigid Subset~(RS). 
\item \textit{Significant improvement.} The proposed method remarkably improves DNN performances and robustness for shape classification and outperforms existing data augmentation strategies.
\item \textit{Complementary method.} RSMix can be used in conjunction with other data augmentation approaches. Abundant ablation studies verify that RSMix can be combined well with other augmentations and further improves the target model.
\end{itemize}





\section{Related Work} \label{section:Related_Work}
\noindent \textbf{Data Augmentation for Images.} Data augmentation is a regularization methods that expands the knowledge range that can be learned from training data by transforming data while retaining the essential sample meaning. Thus, the model becomes less dependent on the specific given data. Various methods have been proposed in the image domain in addition to conventional methods, such as random rotation, flip and crop. Some works have enabled the model to learn spatially distributed representation by removing the part of the data on pixel~\cite{zhong2020random,singh2017hide,devries2017improved} or feature map~\cite{ghiasi2018dropblock} basis. Furthermore, several mixup-based methods~\cite{zhang2017mixup,verma2019manifold,yun2019cutmix,kim2020puzzle,harris2020fmix} have been proposed that generate virtual samples by combining the two samples.\\
\indent Mixup~\cite{zhang2017mixup} generates virtual training samples by linearly interpolating two images and defining the mixed area ratio as a corresponding label. By introducing the combination between data, Mixup brings out the regularization effect and shows improved performance for several tasks. After Mixup, Verma~\etal~\cite{verma2019manifold} extended Mixup by applying the concept to the feature map, and Yun~\etal~\cite{yun2019cutmix} fusioned the concept of \cite{zhang2017mixup} and \cite{devries2017improved} to improve localization and classification ability of the model. In addition, Kim~\etal~\cite{kim2020puzzle} and Harris~\etal~\cite{harris2020fmix}  utilized saliency maps~\cite{kim2020puzzle} and Fourier transform~\cite{harris2020fmix}, respectively, to use semantically representative parts of the data when generating virtual samples. However, these approaches can only be applied to image based models rather than point clouds, because they have different data structures. Therefore, we propose the RSMix, novel mixup-based augmentation strategy for the point cloud that generates virtual samples considering the unique properties of point clouds .\f_{M_d}(x_{\alpha}, x_{\beta})1-\lambda)x_{\alpha}+\lambda x_{\beta}1-\lambda)f(x_{\alpha})+\lambda f(x_{\beta})1-\mathcal{M})\odot x_{\alpha}+\mathcal{M}\odot x_{\beta}1-z)\odot\Pi^{T}_{\alpha} x_{\alpha}+z\odot\Pi^{T}_{\beta}x_{\beta}1-\mathcal{H}(\mathcal{G}))\odot x_{\alpha}+\mathcal{H}(\mathcal{G})\odot x_{\beta}1-\lambda)x_{\alpha}+\lambda \mathcal{J}_{\phi^{*}}(x_{\alpha},x_{\beta})2pt]
\noindent \textbf{Data Augmentation on Point Cloud.} Data augmentation has not been extensively explored in the point cloud domain, aside from general conventional methods, such as randomly scaling, rotation, and jittering. Few studies~\cite{li2020pointaugment,choi2020part,chen2020pointmixup} dealt with data augmentation in the point cloud domain. Liu~\etal\cite{li2020pointaugment} proposed auto-augmentation network for point clouds to find an optimal combination of conventional data augmentation methods corresponding to each sample. Choi~\etal\cite{choi2020part} divided the sample into specific partitions and transformed or mixed each part independently. However, there is a limit to diversity of virtual sample because mixing is performed on inter-classes and specified grids are used for partitioning. PointMixup~\cite{chen2020pointmixup}, which is the closest method to our proposed approach, extends the concept of Mixup~\cite{zhang2017mixup} to point clouds through linear interpolation with optimal assignments between two samples. However, the generated samples have distorted structures which lead to the loss of structural information. Structural information is a core point cloud feature since they have no textural information. Therefore, we propose a more general data augmentation method for point clouds that can preserve shape of the original data .

\begin{figure*}
      \captionsetup{justification=centering}
\includegraphics[scale=1.0]{./figures/figure_2_final2.pdf} 
\caption{Overall pipeline of RSMix. Three steps to synthesize the mixed samples( using Rigid Subset~(RS).}
      \vspace{-0.3cm}
      \label{fig:RSMix_pipeline}
   \end{figure*}


\vspace{-0.2cm}
\section{Method} \label{section:method}
\subsection{Preliminary}\label{subsection:Preliminary}
Neural networks aim to model function  that describes the true distribution  for given data , where samples  have corresponding labels . It has been proved 
through \textit{Empirical Risk Minimization}~\cite{vapnik1971uniform} that  can be approximated by minimizing empirical risk  of the model by computational optimization using loss  and empirical distribution  for given data distribution as
\vspace{-0.3cm}

In data augmentation,  can be expanded to  with additional augmented data through \textit{vicinal risk minimization}~\cite{chapelle2001vicinal},
\vspace{-0.2cm}

where  is a vicinity distribution, \ie, the probability that virtual sample and label pair , are sampled from the vicinity of given sample and label pair . For image data, Zhang~\etal~\cite{zhang2017mixup} designed a vicinal distribution  that generated a virtual mixed sample-label pair  from two paired data  and  using mix function , for sample and , for label, as

where  beta distribution Beta, for . \tablename~\ref{table:mixupfunctions} shows the deformations of  in various ways using features from model ~\cite{verma2019manifold} or masking approaches such as binary mask ~\cite{yun2019cutmix}, salient data included mask ~\cite{kim2020puzzle}, or thresholding mask ~\cite{harris2020fmix} with filtered data  in the frequency domain. However, these mask-based approaches cannot be applied directly to point cloud, since point clouds have no grid and points can exist anywhere in 3D real space. Though Chen~\etal~\cite{chen2020pointmixup} solved this problem by linear interpolation between two point clouds, introducing optimal assignment , they could not generate virtual samples preserving shape of the original sample. Therefore, our goal is to generate a shape-preserved virtual sample that has combined information from both samples as well as proposing an adapted spatial mask for 3D data. We are inspired by concept of the mask region from image analysis, which preserves the part of the original data intactly.\ \label{eq:cut_mix_mixfunction}
f_{M_d}(x_{\alpha},x_{\beta})=(1-\mathcal{M})\odot x_{\alpha}+\mathcal{M}\odot x_{\beta},
\vspace{-0.1cm}
\odot\mathcal{M}d_u\times d_w[u_M,u_M+d_u]\times[w_M,w_M+d_w]\lambda=\frac{d_u d_w}{WH}u_M,w_M)\mathcal{M}d_u/2d_w/2\mathcal{M} \label{eq:mask_defi}
\mathcal{M} = \{(u_{i},w_{j})\vert\;\vert u_i - u_c\vert \leq \frac{d_u}{2},\vert w_j - w_c\vert \leq \frac{d_w}{2}\,\},
\vspace{-0.2cm}
u_i,w_j)i,j)thi=\{1,2,...,W\}j=\{1,2,...,H\}u_c,w_c)u_M+\frac{d_u}{2}, w_M+\frac{d_w}{2})u_{c},w_{c})\mathcal{A}2pt]
\noindent \textbf{Neighboring Rigid Subset.} We define two  sampled point sets normalized in the unit sphere as , where t.  is its Euclidean coordinates, which represents location of the point. We only consider coordinate information since RSMix operates on point-wise coordinates.\\
\indent We adapt the regional mask for image to spatial subset of each point sets from given point sets  and , by grouping adjacent points from a certain query point, , randomly chosen from . These subsets are denoted as  and  according to below Equation (\ref{eq:Rigid_Subset_Mask}).

which are grouped using the specific neighboring function . We define these subsets as Rigid Subset~(RS) since they preserve the sample shape rigidly. \\
\indent We introduce two instantiations for  to retain the original point set shape: K-Nearest Neighbor(KNN) to given  and Ball-query method that neighboring points in certain distance  from  as 

respectively, where  is sampled from beta distribution Beta, with parameter  as default, \ie, the uniform distribution, since  is normalized in the unit sphere. Both  are based on Euclidean distance in 3D space considering  the point cloud's unordered structure and free space around them. Each method has different characteristics on neighboring subsets with respect to the density or directional bias of given point sets. \\
\indent Meanwhile, we limit   , where  and  denote the upper bound number of points in RS and cardinality for the point set, respectively. We usually set  to preserve at least half of the original point sets. In addition, when using , we randomly sample points in  along the difference between  and  to maintain the , where  denotes a mixed sample described in below Insertion part. We compare and analyze the two methods for quantitative and visualized results in Section \ref{subsection:ablation_study}. Further, we also provide experiments with various  values in Section \ref{subsection:ablation_study}. \figurename~\ref{fig:RSMix_pipeline}(a) shows neighboring the RS from the each sample.\\mathcal{S}^{\alpha}\mathcal{S}^{\beta}\mathcal{P}^{\alpha}_{mix}\mathcal{S}^{\alpha}\mathcal{P}^{\alpha}\mathcal{S}^{\beta}\mathcal{P}^{\alpha}-\mathcal{S}^{\alpha}\mathcal{S}^{\beta}2pt]
\noindent \textbf{Insertion.} However,  and  are usually different because they are randomly chosen from  and , respectively. Hence, before insertion,  should be translated by the difference between the  two query points. We introduce translation function  to translate  by  as 

where  is a point in . Applying  to , the translated subset  is denoted as

Therefore, mixed sample  is defined as 

and \figurename~\ref{fig:RSMix_pipeline}(c) describes the inserted mixture sample. Thus, mix function  for RSMix can be expressed using as follow Equation~(\ref{eq:final_mix_function}) using  and  instead of  and .

where input arguments related to query points  and  are omitted for clarity.


\subsection{Mixture Ratio  for Training} \label{subsection:mixture_ratio}
In this Section, we define the mixture ratio , the ratio of  \wrt , to train the network for shape classification. In contrast to  or some previous image masks,  and  are often different when using the , since we apply same  to  and , despite of their different densities. Hence, we define

To explicitly consider the relation between  and . Finally, we define the label mix function as

which is same as in CutMix~\cite{yun2019cutmix}, to generate virtual label  for classification training. Detailed implementations are available in the supplementary material with pseudo-code.



\section{Experiments}
\vspace{-0.1cm}
\noindent \textbf{Datasets.} We evaluate RSMix on ModelNet40~\cite{wu20153d} and ModelNet10~\cite{wu20153d}, which are widely used point cloud classification benchmark datasets. ModelNet40 is small dataset which comprises 12,311 CAD models from 40 man-made object categories, and ModelNet10 is subset of ModelNet40 that includes only 4899 CAD models from 10 categories. We utilized the preprocessed data provided by PointNet~\cite{qi2017pointnet} for ModelNet40 with same train-test split, which were 1024 uniformly sampled points on mesh faces according to face area and normalized onto the unit sphere, and preprocessed ModelNet10 similarly. In particular, we ignored normals of samples since they are not available for real-data.\2pt]
\noindent \textbf{Single and Multi-view Evaluations.} Single and multi-view evaluations are separated depending on whether objects were evaluated from different angles or not. These approaches can be separated into two cases: with or without voting strategy to predict an object multiple times by rotating about an axis. The experiments adopted voting strategy of evaluating an object 12 times, rotating it 30 on its vertical~(y) axis between evaluations. Meanwhile, ModelNet40~\cite{wu20153d} has 10 classes with aligned poses/headings. Thus, it is trivial to separate the 10 classes with the remaining 30 classes if we don't do random rotation on test samples when evaluating the model. Hence, there are obvious differences between the results from single and multi-view evaluations. Appropriate combinations of augmentation strategies also vary depending on evaluation type. We investigated results from both evaluation strategies and explored optimal combinations of augmentations for different models by abundant ablation studies~(Sections~\ref{subsection:ablation_study}).\\sigma^{2}\sim\uparrow\uparrow\uparrow\uparrow\uparrow\uparrow\uparrow\uparrow\uparrow2pt]
\noindent \textbf{Comparison against PointMixup~\cite{chen2020pointmixup}.} We demonstrate results of RSMix for two evaluation methods against PointMixup~\cite{chen2020pointmixup}, the closest work to us, in \tablename~\ref{table:Comparison_PointMixup}. We compared pre-aligned and unaligned settings to for single and multi-view accuracies, respectively, since PointMixup~\cite{chen2020pointmixup} do not specify their evaluation method but each are similar. They follow the PointCNN~\cite{li2018pointcnn} setting discriminating pre-aligned and unaligned with horizontal rotation on point cloud samples. They randomly rotate the training point cloud along the y-axis for unaligned settings. For natural evaluation, we do not preprocess the dataset as pre-aligned or unaligned~(denoted as Raw in \tablename~\ref{table:Comparison_PointMixup}). RSMix achieves more competitive performance than PointMixup~\cite{chen2020pointmixup} for networks that use local information ~\cite{qi2017pointnet++,wang2019dynamic}, and further enhances the network’s ability to recognize local information.\^{knn}_{S}^{ball}_{S}\uparrow\uparrow\uparrow\uparrow\uparrow\uparrow^{knn}_{S}^{ball}_{S}\mathcal{A}_{knn}\mathcal{A}_{ball}\mathcal{A}_{ball}\mathcal{A}_{knn}\mathcal{A}_{knn}d_{knn}\mathcal{A}_{ball}r_{rigid}\mathcal{A}_{knn}r_{rigid}\mathcal{A}_{ball}\mathcal{S}^{\beta}\mathcal{A}_{ball}\mathcal{A}_{knn}\mathcal{A}_{ball}\mathcal{A}_{ball}2pt]
\begin{table}
\resizebox{\columnwidth}{!}{
         \begin{tabular}{ccccccc}
            \toprule
            Jitter+Shift & Rotation & Scaling & RandDrop & RSMix & ACC & ACC \\
			\midrule\midrule
			& & & & & 91.5 & 78.5 \\
			& & & & \ding{51} & \textbf{92.7(1.2} & 71.5(7.0 \\
			\midrule
			\ding{51} &  &  & & & 91.4 & 73.5 \\
			\ding{51} &  &  & & \ding{51} & 92.0(0.6 & 74.4(1.1 \\
			\ding{51} &  &  & \ding{51} & & 91.4 & 67.1 \\
			\ding{51} &  &  & \ding{51} & \ding{51} & 91.8(0.4 & 72.8(5.7 \\
			\midrule
			& \ding{51} & \ding{51} & & & 91.0 & 90.8 \\
			& \ding{51} & \ding{51} & & \ding{51} & 91.6(0.6 & \textbf{92.1(1.3} \\
			& \ding{51} & \ding{51} & \ding{51} & & 91.0 & 91.0 \\
			& \ding{51} & \ding{51} & \ding{51} & \ding{51} & 91.3(0.3 & 91.2(0.2 \\
			\midrule
			\ding{51} & \ding{51} & \ding{51} & & & 90.3 & 90.7 \\
			\ding{51} & \ding{51} & \ding{51} & & \ding{51} & 90.8(0.5 & 91.4(0.7 \\
			\ding{51} & \ding{51} & \ding{51} & \ding{51} & & 90.6 & 90.7 \\
			\ding{51} & \ding{51} & \ding{51} & \ding{51} & \ding{51} & 91.0(0.4 & 91.1(0.4 \\
            \bottomrule
      \end{tabular}}\caption{Ablation studies on evaluation accuracy with single(ACC(\%)) and multi-view(ACC(\%)) for PointNet++~\cite{qi2017pointnet++} on ModelNet40.}
\vspace{-0.4cm}
      \label{table:pointnet2_ablation}
\end{table}
\noindent \textbf{Single and multi-view evaluations with various combinations of augmentations.} RSMix can be applied in conjunction with existing ConvDA methods to further increase the diversity of mixed data since they are independent approaches. However, some combinations of augmentations can cause excessive deformation on the data sample, reducing the network's ability to recognize objects itself. Therefore, it is essential to analyze various combinations of augmentation strategies. We provide quantitative results in \tablename~\ref{table:pointnet2_ablation} with single and multi-view evaluations for PointNet++~\cite{qi2017pointnet++} on ModelNet40. RandDrop is the data augmentation method proposed in \cite{qi2017pointnet++} that randomly drops the points from sample so that network can extract the global features better. The results show that models with RSMix alone achieved the highest accuracy for single-view evaluation. In addition, overall experiments show better results without rotational augmentation for single-view evaluation. However, results with multi-view evaluation reveal that if the model is trained without rotational augmentation, network can be overfitted to directional bias of the dataset, ModelNet40. Hence, rotational augmentation is essential for multi-view evaluation. However, RSMix improves discriminative ability of the model with appropriate combinations with other augmentations regardless of evaluation type, because diversity of datasets increases significantly when RSMix is used in conjunction with rotation and scaling augmentations. \\
\indent In addition, we also provide the results for DGCNN~\cite{wang2019dynamic} in \tablename~\ref{table:dgcnn_ablation} with single-view evaluation on ModelNet40 and ModelNet10 with scaling augmentation as ConvDA, since single-view evaluation shows better results without rotational augmentation. We also obtained remarkable improvements with RSMix for all presented combinations.\\
\indent Therefore, we can notice three things as follows.
\begin{itemize}
	\item Single and multi-view evaluation performances differ significantly depending on the presence of rotational biases in the dataset.
\item Rotational augmentation reduces single-view evaluation performance, but must be included when training if evaluation is performed with multi-view evaluation.
\item RSMix successfully improved model generality by appropriate combination with other augmentation strategies regardless of evaluation type.
\end{itemize}
\begin{table}
   \tiny
\resizebox{\columnwidth}{!}{
         \begin{tabular}{ccccc}
	        \midrule
            ConvDA & RandDrop  & RSMix & ACC(\%) & Dataset \\
	        \specialrule{0.3pt}{1pt}{0.7pt}
	        \specialrule{0.3pt}{0.7pt}{1pt}
            &  & & 92.5 & MN40  \\
            &  & \ding{51} & 93.3(0.8 & MN40  \\
            \ding{51} & &  & 92.6 & MN40 \\
            \ding{51} & & \ding{51} & 93.4(0.8 & MN40 \\
            \ding{51} & \ding{51} &  &  92.8 & MN40 \\
            \ding{51} & \ding{51} & \ding{51} &  \textbf{93.5(0.7} & MN40 \\
	        \specialrule{0.2pt}{1pt}{1pt}
            &  & & 94.6 & MN10  \\
            &  & \ding{51} & 95.9(1.3 & MN10  \\
            \ding{51} &  &  & 94.8 & MN10 \\
            \ding{51} & & \ding{51} & 95.4(0.6 & MN10 \\
            \ding{51} & \ding{51} &  &  94.8 & MN10 \\
            \ding{51} & \ding{51} & \ding{51} &  \textbf{95.5(0.7} & MN10 \\
            \midrule
      \end{tabular}}
   \caption{Ablation studies for DGCNN\cite{wang2019dynamic} on ModelNet40(MN40) and ModelNet10(MN10). Random scaling augmentation was applied as ConvDA.}
\vspace{-0.5cm}
	\label{table:dgcnn_ablation}
\end{table}
\begin{table}[t!]
\resizebox{\columnwidth}{!}{
         \begin{tabular}{c|cc|cc|c}
\specialrule{1pt}{1pt}{1pt}
            \multirow{2}{*}{Transform} & \multirow{2}{*}{} & \multirow{2}{*}{RSMix} & ConvDA  & ConvDA & \multirow{2}{*}{Eval}\\
            & & & w/o RSMix & w/ RSMIx & \\
	        \specialrule{0.4pt}{1pt}{1pt}
	        \specialrule{0.4pt}{1pt}{1pt}
			\multirow{2}{*}{Jitter (=0.01)} & 90.0 & \textbf{90.6} & 90.8 & \textbf{91.0} & Single \\
			& \textbf{82.3} & 78.5 & 90.9 & \textbf{91.3} & Multi \\
	        \specialrule{0.4pt}{1pt}{1pt}
			\multirow{2}{*}{Jitter (=0.05)} & \textbf{15.3} & 13.0 & \textbf{23.4} & 21.2 & Single \\
			& \textbf{10.3} & 9.8 & \textbf{23.5} & 20.3 & Multi \\
	        \specialrule{0.4pt}{1pt}{1pt}
\multirow{2}{*}{X-axis } & 17.3 & \textbf{21.8} & 16.5 & \textbf{19.9} & Single \\
			& 18.0 & \textbf{22.1} & 16.7 & \textbf{19.8} & Multi \\
	        \specialrule{0.4pt}{1pt}{1pt}
			\multirow{2}{*}{Y-axis } & 56.7 & \textbf{60.9} & 90.0 & \textbf{91.0} & Single \\
			& 57.0 & \textbf{61.1} & 90.1 & \textbf{91.1} & Multi \\
	        \specialrule{0.4pt}{1pt}{1pt}
			\multirow{2}{*}{Z-axis } & 14.6 & \textbf{18.9} & 15.2  & \textbf{18.3} & Single \\
			& 14.9 & \textbf{19.3} & 14.8 & \textbf{18.4} & Multi \\
	        \specialrule{0.4pt}{1pt}{1pt}
			\multirow{2}{*}{X-axis } & 44.6 & \textbf{50.8} & 43.3 & \textbf{45.7} & Single \\
			& 44.9 & \textbf{51.1} & 43.5 & \textbf{45.6} & Multi \\
	        \specialrule{0.4pt}{1pt}{1pt}
			\multirow{2}{*}{Y-axis } & 75.5 & \textbf{79.2} & 90.2 & \textbf{91.0} & Single \\
			& 75.0 & \textbf{79.1} & 90.1  & \textbf{91.1} & Multi \\
	        \specialrule{0.4pt}{1pt}{1pt}
			\multirow{2}{*}{Z-axis } & 42.3 & \textbf{47.7} & 43.8 & \textbf{44.4} & Single \\
			& 41.7 & \textbf{47.9} & 43.3  & \textbf{44.4}  & Multi \\
	        \specialrule{0.4pt}{1pt}{1pt}
			\multirow{2}{*}{Scale (0.6)} & 90.7 & \textbf{92.2} & 90.4 & \textbf{91.0} & Single \\
			& \textbf{83.7} & 82.5 & 90.5 & \textbf{91.5} & Multi \\
	        \specialrule{0.4pt}{1pt}{1pt}
			\multirow{2}{*}{Scale (1.4)} & 90.7 & \textbf{92.1} & 90.5 & \textbf{91.2} & Single \\
			& \textbf{83.4} & 82.7 & 90.6 & \textbf{91.4} & Multi \\
	        \specialrule{0.4pt}{1pt}{1pt}
			\multirow{2}{*}{Scale (2.0)} & 90.7 & \textbf{92.3} & 90.4 & \textbf{91.0} & Single \\
			& \textbf{83.6} & 82.6 & 90.5 & \textbf{91.1} & Multi \\
\specialrule{0.4pt}{1pt}{1pt}
			\multirow{2}{*}{DropPoint (0.2)} & 88.2 & \textbf{91.9} & 87.4 & \textbf{91.0} & Single \\
			& 77.1 & \textbf{81.9} & 88.2 & \textbf{90.9} & Multi \\
\specialrule{1pt}{1pt}{1pt}
      \end{tabular}}
\caption{Robustness test of RSMix with or without ConvDA for PointNet++~\cite{qi2017pointnet++} on ModelNet40 using Random shift, scaling, rotation, and jitter augmentations as ConvDA.}
   \vspace{-0.5cm}
   \label{table:Robustness_test}
\end{table}
\noindent \textbf{Robustness Test.} We tested the robustness of RSMix with PointNet++~\cite{qi2017pointnet++} to four noisy environments: jitter, rotation, scaling, and DropPoint, in order to verify that our method makes the model robust to noise. \tablename~\ref{table:Robustness_test} verifies the impact of RSMix with single-view and multi-view evaluation for 2 cases against the use of the ConvDA. Especially, multi-view evaluation for rotational noisy environment along the y-axis was performed by rotating the sample along the x-axis for fair comparison. ConvDA includes jittering, shifting, scaling, and rotational augmentations with default settings as same as PointNet++~\cite{qi2017pointnet++}. The results in \tablename~\ref{table:Robustness_test} reveal that RSMix improves the robustness of model whether or not ConvDA was applied for rotation and DropPoint noise, since shape and scale of original point cloud were preserved. However, we achieved lower results with multi-view evaluation when only RSMix was applied for scaling noise. The reason is that if scaling noise is large, it is difficult for the model to interpret the data when viewed from different angles since shape is preserved but scale compared with the original data. Meanwhile, results differed greatly depending on the level of noise for jittering noise, where the shape of an object was not preserved. Although RSMix alone cannot improve robustness for multi-view evaluation, RSMix provided improvements when jitter noise was small for single-view evaluation regardless of ConvDA usage. However, robustness was reduced for both evaluation methods for large jitter noise when RSMix was applied because it was difficult for subsets extracted from each sample by RSMix to have sufficient shape information since the original sample shape was greatly distorted prior to applying RSMix.\\theta\theta,\thetar_{rigid}\mathcal{A}_{ball}\theta\theta\thetar_{rigid}n^{max}=r_{rigid}\theta=1.0\theta=1.0\theta4pt]
\noindent \textbf{Acknowledgements.} 
This work was supported by the Institute for Information and Communications Technology Promotion (IITP) funded by the Korean Government (MSIP) under Grant 2016-0-00197. This research was also supported by R\&D program for Advanced Integrated-intelligence for Identification (AIID) through the National Research Foundation of KOREA(NRF) funded by Ministry of Science and ICT (NRF-2018M3E3A1057289).


\newpage

{\small
\bibliographystyle{ieee_fullname}
\bibliography{egbib}
}

\end{document}
