\documentclass[11pt]{myclass}


\usepackage{amsmath,amssymb,epsfig,graphicx,graphics,color}
\usepackage{euscript}
\usepackage{picins}

\usepackage{macros}




\newcommand{\eps}{\varepsilon}

\renewcommand{\i}[1]{\ensuremath{\mathit{#1}}}
\renewcommand{\c}[1]{\ensuremath{\EuScript{#1}}}
\renewcommand{\b}[1]{\ensuremath{\mathbb{#1}}}
\newcommand{\B}[1]{\ensuremath{\textbf{#1}}}
\newcommand{\ext}{\textsf{E}}
\newcommand{\IP}[2]{\ensuremath{ \langle #1 , #2 \rangle}}
\newcommand{\wid}{\omega}
\newcommand{\CH}{\textsf{CH}}
\def\grid{\mathbb{G}}
\def\hcube{\mathbb{H}}
\def\excube{\mathbb{C}}
\def\naturals{\mathbb{N}}
\def\anchor{A}
\def\gridpts{B}
\def\A{\EuScript{A}}
\def\G{\EuScript{G}}
\def\kernel{\EuScript{K}}
\def\wkernel{\EuScript{L}}
\def\nbr{\psi}
\def\inbr{\varphi}
\def\span{\mathop{\mathrm{span}}}
\def\ceil#1{\lceil#1\rceil}

\newcommand{\conv}[1]{\mathop{\mathrm{conv}}(#1)}
\newcommand{\opt}[2]{\kappa(#1,#2)}
\newcommand{\dual}[1]{{#1}^*}
\newcommand{\poly}{\EuScript{P}}
\newcommand{\polyt}{\EuScript{P}}
\newcommand{\ball}{\mathbb{B}}
\newcommand{\intr}{\mathop{\mathrm{intr}}}
\newcommand{\fp}{\bar{p}}
\newcommand{\falpha}{\bar{\alpha}}
\newcommand{\fq}{\bar{q}}
\newcommand{\fDelta}{\bar{\Delta}}
\newcommand{\fr}{\bar{r}}
\newcommand{\point}[3]{{#1}[#3,#2]}

\newcommand{\rotate}[2]{{#1}[#2]}
\renewcommand{\L}{\EuScript{L}}

\newcommand{\mypara}[1]{\paragraph{\sffamily{\textbf{\emph{#1}}}}}


\newcommand\PPic[2]{
    \begin{minipage}{#1}\hspace{-0.4cm}
        \makebox[0cm][l]{\includegraphics{#2}}
    \end{minipage}}

\newlength{\ppicwd}
\newcommand\PPicCap[3]{
    \begin{minipage}{#1}\hspace{-0.4cm}
        \settowidth{\ppicwd}{\includegraphics{#2}}  \makebox[0cm][l]{\includegraphics{#2}}

       \vspace{-7\lineskip}
       \begin{minipage}{\ppicwd}
           \caption{#3}
       \end{minipage}
    \end{minipage}}




\title{Stability of -Kernels}
\author{Pankaj K. Agarwal\and 
Jeff M. Phillips\and 
Hai Yu}


\begin{document}
\begin{titlepage}
\maketitle

\begin{center} \today \end{center}

\begin{abstract}
Given a set  of  points in , an -kernel  
approximates the directional width of  in every direction within a relative 
 factor.  In this paper we study the stability of 
-kernels under dynamic insertion and deletion of points to  and by changing the approximation factor .
In the first case, we say an algorithm for dynamically
maintaining a -kernel is stable if at most  points
change in  as one point is inserted or deleted from .
We describe an algorithm to maintain an -kernel of 
size  in  
time per update.  Not only does our algorithm maintain a
stable -kernel, its update time is faster than any known
algorithm that maintains an -kernel of size
. 
Next, we show that if there is an -kernel of  of
size , which may be dramatically less than 
, then there is 
an -kernel of  of size 
.
Moreover, 
there exists a point set  in  and a parameter
 such that if every -kernel of  has size at
least , then any -kernel of  has size 
.
\footnote{Research supported by 
    subaward CIF-32 from NSF grant 0937060 to CRA, 
    by NSF under grants
    CNS-05-40347, CFF-06-35000, and DEB-04-25465, by ARO grants
    W911NF-04-1-0278 and W911NF-07-1-0376, by an NIH grant
    1P50-GM-08183-01, by a DOE grant OEG-P200A070505, and by a grant
    from the U.S.--Israel Binational Science Foundation.}
\end{abstract}
\end{titlepage}






\section{Introduction}
\label{sec:intro}

With recent advances in sensing technology, massive geospatial
data sets are being acquired at an unprecedented rate in many application
areas, including GIS, sensor networks, robotics, and spatial databases. Realizing the full potential of these data 
sets requires developing scalable algorithms for 
analyzing and querying them.  Among many interesting
algorithmic developments to meet this challenge,  there is an
extensive amount of work on computing a ``small summary'' of large 
data sets that preserves certain desired properties of the input data 
and on obtaining a good trade-off between the quality of the summary
and its size.  A coreset is one example of such approximate summaries.
Specifically, for an input set  and a function , 
a \emph{coreset}  is a subset of  (with respect to )
with the property that  approximates . If a small-size coreset
 can be computed quickly (much faster than computing ), then 
one can compute an approximate value of  by first
computing  and then computing . This 
coreset-based approach has been successfully used in a wide range of 
geometric optimization problems over the last decade.  See~\cite{AHV07} for a survey.



\paragraph{-kernels.} Agarwal~\etal~\cite{AHV04} introduced the notion
of -kernels and proved that it is a coreset for many functions.
For any direction , let 
 be the extreme point in  
along ;   is called 
the \emph{directional width} of  in direction .  
For a given ,  is called 
an \emph{-kernel} of  if 

for all directions .\footnote{This is a slightly stronger version of the definition than defined in 
\cite{AHV04} and an -kernel  gives a relative -approximation of  for all  (i.e. ).}
For simplicity, we assume , because for , 
one can choose a constant number of points to form an -kernel, and we assume  is constant.  
By definition, if  is an -kernel of  and  is a -kernel
of , then  is a -kernel of . 



Agarwal~{et~al.}~\cite{AHV04} showed that there exists
an -kernel of size  and it can be
computed in time . The running time was improved 
by Chan~\cite{Cha06} to  (see
also~\cite{YAPV04}).
In a number of applications, the input point set is being updated
periodically, so algorithms have also been developed to
maintain -kernels dynamically.
Agarwal~\etal~\cite{AHV04} had described a data structure to maintain
 an -kernel of size  
in  time per update.
The update time was recently improved by Chan~\cite{Cha08} to
. His approach can 
also maintain an -kernel of size  with 
update time .  If only insertions are allowed (e.g.\ in a streaming model),
the size of the data structure can be improved to 
~\cite{AY07,ZZ08}.


In this paper we study two problems related to the \emph{stability} of 
-kernels: how -kernels change as we update the input set or vary
the value of .


\paragraph{Dynamic stability.}
Since the aforementioned dynamic algorithms for maintaining an
-kernel focus on minimizing the size of the
kernel, changing a single point in the input set  may 
drastically change the resulting kernel.  This is particularly 
undesirable when the resulting kernel is used to build 
a dynamic data structure for maintaining another information.
For example, kinetic data structures (KDS) based on coresets have 
been proposed to maintain various
extent measures of a set of moving points~\cite{AHV07}. If an
insertion or deletion of an object changes the entire summary,
then one has to reconstruct the entire KDS instead of locally
updating it. In fact, many other dynamic data structures for maintaining
geometric summaries also suffer from this undesirable 
property~\cite{BCEG04,HS08,STZ04}.

We call an -kernel
\emph{-stable} if the insertion or deletion of a point 
causes the -kernel to change by at most  points.
For brevity, if , we call the -kernel to be
\emph{stable}. Chan's dynamic algorithm can be adapted to maintain
a stable -kernel of size ; see 
Lemma~\ref{lemma:chan} below.
An interesting question is whether there is an efficient algorithm 
for maintaining a stable -kernel of size
, as points are being inserted or
deleted.  Maintaining a stable -kernel dynamically 
is difficult for two main reasons.  
First, for an input set , many algorithms compute -kernels in 
two or more steps. They first construct a large -kernel 
 (e.g. see~\cite{AHV04,Cha08}), and then use a more 
expensive algorithm to create a small 
-kernel of .  However, if the first algorithm is unstable, then  may change completely each 
time  is updated.  
Second, all of the known -kernel algorithms rely on first finding 
a ``rough shape'' of the input set  (e.g., finding a small
box that contains ), estimating its fatness~\cite{BH01}.  
This rough approximation is used crucially in the computation
of the -kernel.  However, this shape is itself very unstable 
under insertions or deletions to .  Overcoming these
difficulties, we prove the following in
Section~\ref{sec:dynamic}: 


\begin{theorem}
\label{theo:dynamic}
Given a parameter , 
a stable -kernel of size  of a set of  points in  can be maintained under insertions and deletions in  time.
\end{theorem}

Note that the update time of maintaining an
-kernel of size  is better than
that in~\cite{Cha08}.
\paragraph{Approximation stability.}
If the size of an -kernel  is ,
 then decreasing  changes  quite predictably.
However, this is the worst-case bound, and
it is possible that the size of  may be quite small, e.g.,
, or in general much smaller than the  maximum
(efficient algorithms are known for computing
-kernels of near-optimal size~\cite{AHV07}).  Then 
how much can the size increase as we reduce the allowable
error from  to ?  
For any , let  denote the minimum size of an  
-kernel of . 
Unlike many shape simplification problems, in which the size of
simplification can change drastically as we reduce the value
of , we show (Section~\ref{sec:approx}) that 
this does not happen for -kernels and that
 can be expressed in terms of . 

\begin{theorem}
\label{theo:approx}
    For any point set  and for any , 
    
Moreover, there exist a point set  and some  such that 
   .
\end{theorem}


\section{Dynamic Stability}
\label{sec:dynamic}

In this section we describe an algorithm that proves 
Theorem~\ref{theo:dynamic}. The algorithm is composed of a sequence of 
modules, each with certain property.  
We first define the notion of anchor points and fatness of a 
point set and describe two algorithms for maintaining 
stable -kernels with respect to a fixed anchor:
one of them maintains a kernel of size  and the other 
of size ; the former has smaller update time.
Next, we briefly sketch how Chan's algorithm~\cite{Cha08} can be adapted to maintain a stable -kernel of size . 
Then we describe the algorithm for updating anchor points and 
maintaining a stable kernel as the anchors change. Finally, we put these 
modules together to obtain the final algorithm.
We make the following simple observation, which will be crucial for combining different modules.

\begin{lemma}[\textsf{Composition Lemma}]
If  is an -stable -kernel of  and  is an -stable -kernel of , then  is an -stable -kernel of .
\label{lem:chain}
\end{lemma}




\paragraph{Anchors and fatness of a point set.}
We call a point set  \emph{-fat} if 

If  is a constant, we sometimes just say that  is \emph{fat}.  
An arbitrary point set  can be made fat by applying an affine 
transform: we first choose a set of  \emph{anchor points} 
 using the following procedure of 
Barequet and Har-Peled~\cite{BH01}.  Choose  arbitrarily.  
Let  be the farthest point from .  Then inductively, 
let  be the farthest point from the flat 
.  (See Figure \ref{fig:transformTA}.)
The anchor points  define a bounding box  with center at  
and orthogonal directions defined by vectors from the flat 
 to .  The extents of  in each 
orthogonal direction is defined by placing each  on a bounding 
face and extending  the same distance from  in the 
opposite direction.  
Next we perform an affine transform  on  such that the vector from the flat  to  is equal to , where  .  
This ensures that .  The next
lemma shows that  is fat.

\begin{lemma}
\label{lemma:fat}
For all  and for ,

\end{lemma}

\begin{proof}
The first two inequalities follow by .  We can upper bound .
The volume of the convex hull  is  since it is a -simplex and  for each direction .  
We can then scale  by a factor  (shrinking the volume by factor ) so it fits in .  Now we can apply a lemma from \cite{HPbook} that the minimum width of a convex shape that is contained in  is at least  times its -dimensional volume, which is .  
The fatness of  follows from the fatness of .
\end{proof}




\vspace{-.1in}

\begin{figure}[htb]
\begin{center}
\begin{picture}(0,0)\includegraphics{figs/transform+.pdf}\end{picture}\setlength{\unitlength}{1579sp}\begingroup\makeatletter\ifx\SetFigFont\undefined \gdef\SetFigFont#1#2#3#4#5{\reset@font\fontsize{#1}{#2pt}\fontfamily{#3}\fontseries{#4}\fontshape{#5}\selectfont}\fi\endgroup \begin{picture}(8385,3055)(72,-3737)
\put(2401,-2236){\makebox(0,0)[lb]{\smash{{\SetFigFont{8}{9.6}{\rmdefault}{\mddefault}{\updefault}{\color[rgb]{0,0,0}}}}}}
\put(826,-3061){\makebox(0,0)[rb]{\smash{{\SetFigFont{8}{9.6}{\rmdefault}{\mddefault}{\updefault}{\color[rgb]{0,0,0}}}}}}
\put(1126,-1786){\makebox(0,0)[b]{\smash{{\SetFigFont{8}{9.6}{\rmdefault}{\mddefault}{\updefault}{\color[rgb]{0,0,0}}}}}}
\put(3451,-886){\makebox(0,0)[lb]{\smash{{\SetFigFont{8}{9.6}{\rmdefault}{\mddefault}{\updefault}{\color[rgb]{0,0,0}}}}}}
\put(7051,-886){\makebox(0,0)[lb]{\smash{{\SetFigFont{8}{9.6}{\rmdefault}{\mddefault}{\updefault}{\color[rgb]{0,0,0}}}}}}
\put(6901,-3661){\makebox(0,0)[lb]{\smash{{\SetFigFont{8}{9.6}{\rmdefault}{\mddefault}{\updefault}{\color[rgb]{0,0,0}}}}}}
\end{picture} \caption{ Anchor points , rectangle , and 
transform  applied to ;  square ,
two-dimensional grid , and one-dimensional grid
 on the edge  of .}
\label{fig:transformTA}
\end{center}
\end{figure}

Agarwal~\etal~\cite{AHV04} show if  is an -kernel of , then 
 is an -kernel of  for any affine transform , which 
implies that one can compute an -kernel of . We will need 
the following generalization of the definition of -kernel.
For two points sets  and , a subset  is called
an \emph{-kernel of  with respect to } if
 for all .



\paragraph{Stable -kernels for a fixed anchor.}


Let  be a set of anchor points of , as described above. We
describe algorithms for maintaining stable -kernels (with respect
to ) under the assumption that  remains a set of  anchor points of
, i.e., , as  is being 
updated by inserting
and deleting points. In view of the above discussion, without loss of generality,
we assume  and denote it by . As for the static
case~\cite{AHV04,Cha06}, we first describe a simpler algorithm that
maintains a stable -kernel of size , and then a 
more involved one that maintains a stable -kernel of size 
. 

Set  and draw a -dimensional grid  inside
 of size , i.e., the side-length of each grid cell is
at most ;  has  cells. For each grid
cell , let . For a point  lying 
in a grid cell , 
let  be the vertex of  nearest to the origin; we can
view  being \emph{snapped} to the vertex .
For each facet  of ,
 induces a -dimensional grid  on ;  contains
a \emph{column} of cells for each cell in . For 
each cell , we choose (at most) one point of  
as follows:
let  be the nonempty grid cell in the column of  
corresponding to  that is closest to . We choose an 
arbitrary point from ;
if there is no nonempty cell in the column, no point is chosen. Let
 be the set of chosen points. Set . Agarwal~\etal~\cite{AHV04} proved that 
 is an -kernel of .  Insertion or deletion of a point
in  affects at most one point in , and it can be updated in 
 time. Hence, we obtain the following:

\begin{lemma}
Let  be a set of  points in , let 
 be a set of anchor points of , and let 
be a parameter.   can be preprocessed in  time,
so that a (2d)-stable -kernel of  with respect to  of 
size  can be maintained in  time 
per update provided that  remains an anchor set of .
\label{lem:weak-fixed}
\end{lemma}


Agarwal~\etal~\cite{AHV04} and Chan~\cite{Cha06} have described algorithms for 
computing an -kernel of size . We adapt Chan's 
algorithm to maintain a stable -kernel with respect to a 
fixed anchor . We begin by mentioning a result of Chan that lies 
at the heart of his algorithm.

\begin{lemma}[Chan~\cite{Cha06}]
\label{lemma:discrete}
Let ,  for some , and
 a set of at most  points. For all grid points , the nearest
neighbors of each  in  can be computed in time .
\end{lemma}

We now set  for a constant  to be used in a much sparser grid than with . 
Let  and  be a facet of . 
We draw a -dimensional grid on  of size . 
Assuming  lies on the plane , we choose a set  of grid points.
For a subset  and a point , we define , i.e., the point in  such that the snapped point is nearest to . 
For a set , . 
There is a one to one mapping between the faces of  and , so we also use  to denote the corresponding facet of . 
Let  be the set of points chosen in the previous algorithm corresponding to facet  of  for computing an -kernel of . 
Set .  
Chan showed that  is an -kernel of  and thus an -kernel of . 
Scaling  and  appropriately and using Lemma~\ref{lemma:discrete},  can be computed in  time. Hence,  can be computed in  time.

Note that  can be the same for many points , so 
insertion or deletion of a point in  (and thus in ) may change
 significantly, thereby making  unstable. We circumvent this problem by introducing two new ideas. First,  is computed 
in two 
stages, and second it is computed in an iterative manner. We describe the 
construction and the update algorithm for ; the same algorithm is repeated
for all facets. 

We partition  into  boxes: for 
, 
we define
. We maintain a subset
. Initially, we set . Set .
We define a total order on the points of . Initially, we
sort  in lexicographic order, but the ordering will change as 
insertions and deletions are performed on .
Let  be the current ordering of . We 
define a map  as follows. Suppose
 have been defined. Let 
; here 
 denotes the snapped point of . We set
. We delete  from  (and 
from ) and recompute . Set  and .
Computing  and  takes 
 time, and, by Lemma~\ref{lemma:discrete}, 
 can be computed in  time.

It can be proved that the map  and the set  satisfy the following properties:
\begin{itemize} \denselist
\item[(P1)]  for ,
\item[(P2)] ,
\item[(P3)] .
\end{itemize}
Indeed, (P1) and (P2) follow from the construction, and (P3) follows from
(P2). (P3) immediately implies that  is an -kernel of .
Next, we describe the procedures for updating  when 
changes.  These procedures maintain (P1)--(P3), 
thereby ensuring that the algorithm maintains an -kernel. 

\textit{Inserting a point.} 
Suppose a point  is inserted into . 
We add  to . Suppose . We recompute . Next, we update  and 
 as  follows. We maintain a point . Initially, 
 is set to .  Suppose we have processed 
. Let  be the 
current . If , then we 
swap  and , otherwise neither  nor  is updated.
We then process .  After processing all points of  if , 
i.e., no  is updated, we stop. Otherwise, we add  to  and 
delete  from . 
The insertion procedure makes at most two changes in , and it can be 
verified that (P1)-(P3) are maintained.

\textit{Deleting a point.} 
Suppose  is deleted from .  Suppose . 
If , then . 
We delete  from  and  and recompute . 
If , i.e., there is a  with , then .
We delete  from  and , recompute , and 
add the new  to .  Let ; we remove  from  and recompute .
We modify the ordering of  by moving  from its current position to the end. This is the only place where the ordering of  is modified. 
Since  is now the last point in the ordering of , the new  does not affect any other . 
The deletion procedure also makes at most two changes in  and maintains (P1)--(P3).  

Finally, insertion or deletion of a point in  causes at most one insertion plus one deletion in , therefore we can conclude the following:

\begin{lemma}
\label{lem:strong-fixed}
Let  be a set of  points in ,  a set of 
anchor points of , and  a parameter. 
 can be preprocessed in  time into a 
data structure so that a stable -kernel of  with respect to 
of size  can be maintained in 
 time under insertion and deletion, 
provided that  remains an anchor set of .
\end{lemma}


\paragraph{Stabilizing Chan's dynamic algorithm.}
We now briefly describe how Chan's \cite{Cha08} dynamic -kernel algorithm can be adapted so that it maintains a stable -kernel of size . 
He bypasses the need of fixed anchors by partitioning  into  layers , where  is the inner-most layer and  is the outer-most layer,
 for a constant , and . 
 is constructed first, and then the rest of the layers are constructed recursively with the remaining points.
For each set  (for ) there exists a set of points  which serve as anchor points for  in the sense that 
they define a bounding box  (i.e., ).  Furthermore, for all  we have , and this remains true for  insertions or deletions to  for a constant .
After  updates in , the layers  are reconstructed. Also at this point layers  will need to be reconstructed if layer  is scheduled to be reconstructed in fewer than  updates.  
We set , and for , an -kernel  of  with respect to  is maintained using Lemma~\ref{lem:weak-fixed}.
The set  is an -kernel of ; 
.

When a new point  is inserted into , it is added to the outermost layer , i.e.,  is the largest such value, such that 
. If a point is inserted into or deleted from ,
we update  using Lemma \ref{lem:weak-fixed}. The update time follows
from the following lemma. 

\begin{lemma}\label{lemma:chan}
For any , an -kernel  of  of size  can be maintained in  time, and the number of changes in  at each update is .
\end{lemma}

\begin{proof}
Recall that if the insertion or deletion of a point does not require reconstruction of any layers, the update time is  and by Lemma~\ref{lem:weak-fixed}, only  changes occur in . 
We start by bounding the amortized time spent in reconstructing layers and their kernels.  

The kernel  of  is rebuilt if at least  updates have taken place since the last reconstruction, if  needs to be rebuilt for some , or 
if some  is rebuilt for  and  is scheduled to be rebuilt in fewer than  updates to .  These conditions imply that the th layer is rebuilt after every  updates where  is the smallest integer such that .  
The third condition acts to coordinate the rebuilding of the layers so that the th layer is not rebuilt after fewer than  updates since its last rebuild.  

 is rebuilt after  updates.  And .  Since the entire system is rebuilt after  updates, we call this interval a round.  We can bound the updates to  in a round by charging  each time a  is rebuilt, which occurs at most  times in a round.

Thus there are  updates to the -kernel  for every  updates to .  Thus, in an amortized sense, for each update to  there are  updates to .  

This process can be 
de-amortized by adapting the standard techniques for de-amortizing the 
update time of a dynamic data structure~\cite{Ove83}. 
If a kernel  is valid for  insertions or deletions to , then we start construction on the next kernel  after  insertions or deletions have taken place since the last time  was rebuilt.  All insertions can be put in a queue and added to  by the time  steps have transpired.  All deletions from old  to new  are then queued and removed from  before another  insertions or deletions.  This can be done by performing  queued insertions or deletions from  each insertion or deletion from .  
\end{proof}



\paragraph{Updating anchors.}

We now describe the algorithm for maintaining a stable -kernel when
anchors of  are no longer fixed and need to be updated dynamically. 
Roughly speaking,
we divide  into \emph{inner} and \emph{outer} subsets of points. 
The outer subset acts as a \emph{shield} so that a stable kernel of the inner
subset with respect to a fixed anchor can be maintained using 
Lemma~\ref{lem:weak-fixed} or~\ref{lem:strong-fixed}. When the 
outer subset can no longer act as a shield, we reconstruct the inner
and outer sets and start the algorithm again. We refer to the duration 
between two consecutive reconstruction steps as an \emph{epoch}. 
The algorithm maintains a stable kernel within each epoch, and 
the amortized number of changes in the kernel because of 
reconstruction at the beginning of a new epoch will be . As above, we 
use the same de-amortization technique to make the -kernel stable
across epochs. We now describe the algorithm in detail.

In the beginning of each epoch, we perform the following preprocessing.
Set  and compute a -kernel  of  
of size  using Chan's dynamic algorithm; we do not need the stable 
version of his algorithm described above.   can be updated
in  time per insertion/deletion.
We choose a parameter , which is set to  or 
. We create the outer subset of  by peeling off 
 ``layers'' of anchor points .
Initially, we set . Suppose we have constructed 
. Set ,
and  is an -kernel of .
Next, we construct the anchor set  of  
as described earlier in this section. We set 
and update  so that it is an -kernel of . Let 
, , and . Let
. By construction .   forms the outer subset and acts as a shield for , which is the inner subset. 
Set , where  is the constant in Lemma~\ref{lemma:fat}.

If  (resp.\ ), we maintain a stable
-kernel  of  with respect to  of size 
using Lemma~\ref{lem:weak-fixed} (resp.\ Lemma~\ref{lem:strong-fixed}).
Set 
; . We prove below that  is an 
-kernel of .
Let  be a point that is inserted into or deleted from .
If , then we update   using 
Lemma \ref{lem:weak-fixed} or \ref{lem:strong-fixed}.  On the other hand,
if  lies outside , we insert it into or delete it from .
Once  has been updated  times, we end the current epoch and discard the 
current . We begin a new epoch and reconstruct
, , and  as described above. 

The preprocessing step at the  beginning of a new epoch causes  changes in 
and there are at least  updates in each epoch, therefore 
the algorithm maintains a 
stable kernel in the amortized sense. As above, using a de-amortization 
technique, we can ensure that  is stable. The correctness of the 
algorithm follows from the following lemma.





\begin{lemma}
\label{lem:anchor}
 is always an -kernel of .
\end{lemma}

\begin{proof}
It suffices to prove the lemma for a single epoch. Since we begin a new 
epoch after  updates in , there is at least one  such that
. 
Thus we can show that  forms an -kernel of 
.  For any direction 

Thus, for any direction  the extreme point of  is either in  or .  In the first case,  approximates the width within a factor of .  In the second case, the extreme point is in  because all of  is in .  
Thus the set  has an -kernel in , and the rest of the points are also in , so  is an -kernel of the full set .  

The size of  starts at  because both  and  are of size .  At most  points are inserted outside of  and hence into , thus the size of  is still  after  steps.  Then the epoch ends.
\end{proof}


Using Lemmas~\ref{lem:weak-fixed} and~\ref{lem:strong-fixed}, we can
bound the update time and conclude the following.
\begin{lemma}
For a set  of  points in  and a parameter 
, there is a data structure that can maintain 
a stable -kernel of  of size:
\begin{itemize} \denselist
\item[(a)]  under insertions and deletions in time 
, or
\item[(b)]  in time .
\end{itemize}
\label{lem:stable-outter}
\end{lemma}

\begin{proof}
We build an outer kernel of size  in  time.  It lasts for  insertions or deletions, so its construction time can be amortized over that many steps, and thus it costs  time per insertion or deletion.

In maintaining the inner kernel the preprocessing time can be amortized over  steps, but the update time cannot.  
In case (a) we maintain the inner kernel of size  with Lemma \ref{lem:strong-fixed}.  The update time is .  
In case (b) we maintain the inner kernel of size  with Lemma~\ref{lem:weak-fixed}.  The update time is .  

The update time can be made worst case using a standard de-amortization techniques~\cite{Ove83}.  More specifically, we start rebuilding the inner and outer kernels after  steps and spread out the cost over the next  steps.  We put all of the needed insertions in a queue, inserting a constant number of points to  each update to .  Then after the new kernel is built, we enqueue required deletions from  and perform a constant number each update to  over the next  steps.  
\end{proof}

\paragraph{Putting it together.}

For a point set  of size , we can produce the 
best size and update time tradeoff for stable -kernels by 
invoking Lemma \ref{lem:chain} to compose three stable -kernel 
algorithms, as illustrated in Figure \ref{fig:compose}.  
We first apply Lemma \ref{lemma:chan} to maintain a stable 
-kernel  of  of size  
with update time .  
We then apply Lemma~\ref{lem:stable-outter} to maintain a stable 
-kernel  of  of size  
with update time .  
Finally we apply Lemma~\ref{lem:stable-outter} again to maintain a 
stable -kernel  of  of size 
 with update time 
.  
 is a stable -kernel of  of size
 with update time .  This completes the proof of
Theorem~\ref{theo:dynamic}.



\begin{figure}[htb]
\begin{center}
\begin{picture}(0,0)\includegraphics{figs/pipeline+.pdf}\end{picture}\setlength{\unitlength}{1579sp}\begingroup\makeatletter\ifx\SetFigFont\undefined \gdef\SetFigFont#1#2#3#4#5{\reset@font\fontsize{#1}{#2pt}\fontfamily{#3}\fontseries{#4}\fontshape{#5}\selectfont}\fi\endgroup \begin{picture}(11823,1224)(-11,-1273)
\put(10900,-461){\makebox(0,0)[b]{\smash{{\SetFigFont{8}{9.6}{\rmdefault}{\mddefault}{\updefault}{\color[rgb]{0,0,0}}}}}}
\put(10900,-961){\makebox(0,0)[b]{\smash{{\SetFigFont{8}{9.6}{\rmdefault}{\mddefault}{\updefault}{\color[rgb]{0,0,0}}}}}}
\put(3601,-461){\makebox(0,0)[b]{\smash{{\SetFigFont{8}{9.6}{\rmdefault}{\mddefault}{\updefault}{\color[rgb]{0,0,0}}}}}}
\put(3601,-961){\makebox(0,0)[b]{\smash{{\SetFigFont{8}{9.6}{\rmdefault}{\mddefault}{\updefault}{\color[rgb]{0,0,0}}}}}}
\put(7000,-461){\makebox(0,0)[b]{\smash{{\SetFigFont{8}{9.6}{\rmdefault}{\mddefault}{\updefault}{\color[rgb]{0,0,0}}}}}}
\put(6900,-961){\makebox(0,0)[b]{\smash{{\SetFigFont{8}{9.6}{\rmdefault}{\mddefault}{\updefault}{\color[rgb]{0,0,0}}}}}}
\put(1701,-361){\makebox(0,0)[b]{\smash{{\SetFigFont{8}{9.6}{\rmdefault}{\mddefault}{\updefault}{\color[rgb]{0,0,0}}}}}}
\put(601,-1036){\makebox(0,0)[b]{\smash{{\SetFigFont{8}{9.6}{\rmdefault}{\mddefault}{\updefault}{\color[rgb]{0,0,0}}}}}}
\put(601,-436){\makebox(0,0)[b]{\smash{{\SetFigFont{8}{9.6}{\rmdefault}{\mddefault}{\updefault}{\color[rgb]{0,0,0}}}}}}
\put(5401,-361){\makebox(0,0)[b]{\smash{{\SetFigFont{8}{9.6}{\rmdefault}{\mddefault}{\updefault}{\color[rgb]{0,0,0}}}}}}
\put(8881,-361){\makebox(0,0)[b]{\smash{{\SetFigFont{8}{9.6}{\rmdefault}{\mddefault}{\updefault}{\color[rgb]{0,0,0}}}}}}
\end{picture} \caption[Composing stable -kernel algorithms]{ Composing
stable -kernel algorithms.} 
\label{fig:compose}
\end{center}
\end{figure}




\vspace{-.2in}
\section{Approximation Stability}
\label{sec:approx}

In this section we prove Theorem~\ref{theo:approx}. 
We first give a short proof for the lower-bound and then a more involved proof of the upper bound.  For the upper bound, we first develop basic ideas and prove the theorem in  and  before generalizing to .

\subsection{Lower Bound}
Take a cyclic polytope with  vertices and  facets and convert it into a fat polytope  using standard procedures~\cite{AHV04}.  For a parameter , we add, for each facet  of , a point  that is  far away from the facet. Let  be the set of vertices of  together with the collection of added points. We choose  sufficiently small so that points in  are in convex position and all non-facet faces of  remain as faces of . Then the size of an optimal -kernel of  is at most  (by taking the vertices of  as an -kernel), but the size of an optimal -kernel is at least the number of facets of , because every point of the form  has to be present in the kernel. 
The first half of the lower bound is realized with  evenly-spaced points on a sphere, and hence the full lower bound is proved. 



\subsection{Upper Bound}
By \cite{AHV04}, it suffices to consider the case in which  is fat and the diameter of  is normalized to .  
Let  be an -kernel of  of the smallest size.  
Let , and  .  We have  by the definition of -kernels. It suffices to show that there is a set  such that for , , and  \cite{AHV04}.

For convenience, we assume that  is not necessarily a subset of points in ; instead, we only require  to be a subset of points in . By Caratheodory's theorem, for each point , we can choose a set  of at most  points such that .  We set  as the desired -kernel of ; .

Initially, we add a point into  for each point in .  If  lies on , we add  to .  Otherwise we project  onto  in a direction in which  is maximal in  and add the projected point to .  Abusing the notation slightly, we use  to denote the convex hull of these initial points.  
For simplicity, we assume  to be a simplicial polytope. 


\paragraph{Decomposition of .}
There are  types of simplices on .  In  these are points and edges.  In  these are points, edges, and triangles.  We can decompose  into a set of regions, each region  corresponding to a simplex  in .  For each simplex  in  let  denote the dual of  in the Gaussian diagram of .  
Recall that if  has dimension  (), then  has dimension .  
The region  is partitioned into a collection of  regions (where  is the number of faces of all dimensions in ).  Each simplex  in  corresponds to a region defined

For a subsimplex , we can similarly define a region 

In , there are two types of regions: point regions and edge regions.  
In , there are three types of regions: point regions (see Figure \ref{fig:decomposition}(a)), edge regions (see Figure \ref{fig:decomposition}(b)), and triangle regions (see Figure \ref{fig:decomposition}(c)).  

For convenience, for any point , where , and , we write  (which intuitively reads, the point whose projection onto  is  and which is at a distance  above  in direction ). 
We also write  (intuitively,  is obtained by rotating  w.r.t.~ from direction  to direction ).
Similarly, we write a simplex , where  is a simplex inside , , and , and write . 


We will proceed to prove the upper bound as follows.  For each type of region  we place a bounded number of points from  into  and then prove that all points in  are within a distance  from some point in .  
We begin by introducing three ways of ``gridding''  and then use these techniques to directly prove results for several base cases, which illustrate the main conceptual ideas.  These base cases will already be enough to prove the results in  and .  Finally we generalize this to  using an involved recursive construction.  
We set a few global values: , , and .  


\begin{description} \denselist
\item[1: Creating layers.]
For a point  we classify it depending on the value .  If , then  is already within  of .  We then divide the range  into a constant  number of cases using .  If , then we set .  We define  to be the set of points that are a distance exactly  from .  
\vspace{1mm}

\item[2: Discretize angles.]
We create a constant size -net  of directions with the following properties.
(1) For each  there is a direction  such that the angle between  and  is at most .
(2) For each  there is a point ; let .  
 is constructed by first taking a -net  of , then for each  choosing a point  where  is within an angle  of  (if one exists), and finally placing  in .  
\vspace{1mm}

\item[3: Exponential grid.]
Define a set  of distances where  and , so .  
For a face , let any  be called a \emph{support point of }.  
Let  be the vertices of the -simplex .  For each , and each  (where ), let  be the point at distance  from  on the segment .  
For each boundary facet  of , define a sequence of at most  simplices , each a homothet of , so the vertices of  lie on segments  where  (see Figure \ref{fig:correct-triangle}(a)).  
The translation of each  is defined so it intersects a point  (where ) and is as close to  as possible.  This set of -simplices for each  defines the exponential grid .
The full grid structure is revealed as this is applied recursively on each .  



The exponential grid  on a simplex  has two important properties for a point :  
\begin{itemize} \denselist
\item[(G1)] If  lies between boundary facet  and , let  be the intersection of the line segment  with ; then .
\item[(G2)] If  lies between  and  and the segment  intersects  at , let  be the intersection of  with the ray ; then .  
\end{itemize}
\end{description}


We now describe how to handle certain simple types of regions: where  is a point or an edge.  These will be handled the same regardless of the dimension of the problem, and they (the edge case in particular) will be used as important base cases for higher dimensional problems.  

\paragraph{Point regions.}
Consider a point region .  
For each  create -net  for , so  are the corresponding points where each  has .   Put each  in .  

\parpic[r]{\PPic{1.5cm}{figs/angle}} 
For any point , let  where  is the largest value such that  and  is the closest direction to ; set .  
First  because .  
Second  because the angle between  and  is at most , and they are rotated about the point .  
Thus .  

\begin{lemma}
\label{lem:point-reg}
For a point region , there exists a constant number of points  such that all points  are within a distance  of .  
\end{lemma}

\paragraph{Edge regions.}
Consider an edge region  for an edge  of .  
Orient  along the -axis.  
For each  and , let  be the set of points in  within an angle  of .  For each , we add to  the (two) points of 
with the largest and smallest -coordinates, denoted by  and .

\begin{figure}[htb!]
\centering{ \small 
\begin{tabular}{ccc}
\includegraphics[scale=1]{figs/edge-Psi-h.pdf} & \hspace{0.5cm} & 
\includegraphics[scale=1]{figs/edge-case-lines.pdf}\\
(a)  in  && (b) top view of  at height 
\end{tabular}
}
\caption{Illustration of 2 points in  for edge case with specific  and . }
\label{fig:edge-case}
\end{figure}


For any point , there is a point  such that  is the largest value less than  and  is the closest direction to .  Furthermore, .  
We can also argue that there is a point , because if  has smaller -coordinate than  or larger -coordinate than , then  cannot be in .  
Clearly the angle between  and  is less than .  This also implies that .  Thus , implying .

\begin{lemma}
\label{lem:edge-reg} 
For an edge region , there exists  points  such that for any point  there is a point  such that , , and, in particular, .  
\end{lemma}




\subsubsection{Approximation Stability in }

For  there are  points and edges in .  
Thus combining Lemmas~\ref{lem:point-reg} and~\ref{lem:edge-reg}  and we have proven Theorem~\ref{theo:approx} for .  

\begin{theorem}
For any point set  and for any  we have 

\end{theorem}


\subsubsection{Approximation Stability in }

\paragraph{Construction of .}
Now consider  and the point regions, edge regions, and triangle regions in the decomposition of  (see Figure \ref{fig:decomposition}).  By Lemmas \ref{lem:point-reg}  and \ref{lem:edge-reg} we can add  points to  to account for all point and edge regions.  We can now focus on the  triangle regions.


\begin{figure}[htb!]
\begin{center}
{\small 
\begin{tabular}{ccccc}
\includegraphics[scale=1]{figs/decomposition_1.pdf} 
& \hspace{1cm} & 
\includegraphics[scale=1]{figs/decomposition_2.pdf} 
& \hspace{1cm} & 
\includegraphics[scale=1]{figs/decomposition_3.pdf}
\\
(a)  is a vertex of  && (b)  is an edge of  && (c)  is a facet of 
\end{tabular}
}
\end{center}
\caption{Illustration of regions in the partition of  in three dimensions.}
\label{fig:decomposition}
\end{figure}


Consider a triangle region  for a triangle  in  (see Figure \ref{fig:correct-triangle}(a)),  consists of a single direction, the one normal to . 
Let  be the highest point of  in direction .  We add  to  and we create an exponential grid  with  as the support point.
For each edge  and  we add the intersection of  with the boundary of  to , as shown in Figure \ref{fig:correct-triangle}(b).  
Thus, in total we add  points to .



\paragraph{Proof of correctness.}


\begin{figure}[htb!]
\begin{center}
{\small 
\begin{tabular}{ccccc}
\includegraphics[scale=1]{figs/triangle-reg.pdf} 
& \hspace{0.1cm} & 
\includegraphics[scale=1]{figs/triangle-e.pdf} 
& \hspace{0.1cm} & 
\includegraphics[scale=1]{figs/slice.pdf}
\\
(a)  with  and  && (b) Subtriangle  of   && (c) Slice of (b) through , 
\end{tabular}
}
\end{center}
\caption{Illustration to aid correctness of approximation of triangle regions in .}
\label{fig:correct-triangle}
\end{figure}



Consider any point  and associate it with a boundary edge  of  such that .  Let  where  is the largest height such that .  
If segment  does not intersect any edge  parallel to  in , let .  
Otherwise, let  be the first segment parallel to  in  intersected by the ray , and let  be the intersection.  
Let  which must be in  by construction.  
If , then by (G1) we have , thus  and we are done.  
Otherwise, let  be the intersection of  with ray .  By (G2) .  Thus,  is below the segment  (see Figure \ref{fig:correct-triangle}(c)) and thus  since triangle  is in .  Finally, .  
This proves Theorem \ref{theo:approx} for .  

\begin{theorem}
For any point set  and for any  we have 

\end{theorem}


\subsubsection{Approximation Stability in }

\paragraph{Construction of .}
The number of regions in the decomposition of  is ~\cite{Zie95}.  For each region , we choose a set  of  points such that 
 
Then we set .

When  is a - or -simplex, we apply Lemmas \ref{lem:point-reg}  and \ref{lem:edge-reg}.  
Otherwise, to construct  we create a recursive exponential grid on .  
Specifically, for all  and  we choose a point  and construct an exponential grid  with  as the support point.  
Next, for each  we recursively construct exponential grids.  That is, for all  and  we choose another support point  and construct an exponential grid  on .  
At each iteration the dimension of the simplex in the exponential grids drops by one.  We continue the recursion until we get -simplices.  
Let  be the union of all exponential grids.  

Let  be a -simplex in .  For each height  and direction  we choose two points as described in the construction the edge region and add them to .  
We also place the support point of each  into .  
By construction, for a -simplex ,  contains  simplices and thus .  Hence .  




\paragraph{Proof of correctness.} 
Let  be a -face of  (). We need to show for any point , there is a point  (specifically ) such that .  

Before describing the technical details (mainly left to the appendix), we first provide some intuition regarding the proof.  For any  we first consider  where  is the largest .  If  we are done.  If , we need to find a ``helper point"  for .  If  we need to recursively find a ``helper point''  for , and so on until .  
Tracing back along the recursion, we can then prove that  (and hence ) has a nearby point in .
Note that we do not prove  is near .  Formally:

\begin{lemma}
\label{lem:helper}
We can construct a sequence of helper points  and simplices  with the following invariants:
We can construct a sequence of helper points  and simplices  with the following invariants:
   \begin{itemize} \denselist 
     \item[\emph{(I1)}] ;
     \item[\emph{(I2)}]  and  (for );
     \item[\emph{(I3)}]  and the dimension of  is ; and 
     \item[\emph{(I4)}]  (for ). 
   \end{itemize}
\end{lemma}

\begin{proof} 
Set  as above and .    
Assume that for an index ,  has been defined.  
Since (I1) implies , 
there is a direction  such that the angle between  and  is at most .  
Let  be the support point of , given  and . 
Let  be the facet of  such that .  If the segment  does not intersect any simplex in the family of  simplices induced by  and , then let  and terminate the recursion (see Figure \ref{fig:recursive_def}(a)).  
Otherwise, let  be the first such simplex intersected by the ray , and let  be the intersection point (see Figure \ref{fig:recursive_def}(b)).  
  
\begin{figure}[htb!]
\begin{center}
{\small 
\begin{tabular}{ccc}
\includegraphics[scale=1]{figs/term-early.pdf} 
& \hspace{1cm} & 
\includegraphics[scale=1]{figs/recur-case.pdf} \\
(a)  && (b) 
\end{tabular}
}
\end{center}
\caption{(a) Terminate early: . (b) Recursive case:  lies on the segment . }
\label{fig:recursive_def}
\end{figure}

To determine  we first find the direction , such that  lies on the segment .  Then  is determined as the maximum  such that . 
We can show (I1) is satisfied because  must be in  because  and  are, and then  lies on segment .  
We show (I4) by .  Invariant (I2) follows because  and thus .  
Invariant (I3) holds by construction.   

Assume the recursion does not terminate early.  At , since  and  is a line segment, we can apply Lemma \ref{lem:edge-reg} to  and find a point  such that  and .  
This completes the description of the recursive definition of helper points.  
\end{proof}



Let  be the last point defined in the sequence. By construction, .  
For each , let .
We have the following key lemma, which shows that  is close to a point .


\begin{lemma} \label{lem:key}
 For each , there is a point  such that 
 \begin{itemize} \denselist 
   \item[(1)] ; and  
   \item[(2)] . 
 \end{itemize}
\end{lemma}

\begin{proof}
We prove the lemma by induction on . For ,  since , the claim is trivially true by setting .  Assume the claim is true for some .  Now consider the case .  Let  be the intersection of the ray  with  on facet . 
Let  be the intersection of  with the line passing through  and parallel to  (see Figure~\ref{fig:induction}). There are two cases:
 
 \begin{figure}[htb!]
\begin{center}
\includegraphics[scale=1]{figs/exp-grid-induct.pdf}
\end{center}
\caption{The inductive step for proving  and .}
\label{fig:induction}
\end{figure}
 
 \smallskip 
 {\em Case 1:} If   (such that  according to (I3)) is the closest facet to , then  lies between  and .  Thus by (G1), we know that  . We set . As such, 

Moreover, since ,  lies on the segment  and therefore .

 \smallskip  
 {\em Case 2:} Otherwise. In this case, we have by (G2)
 
We set . First observe that

Furthermore, let  be the intersection of  with  (see Figure~\ref{fig:induction}(right)). We then have

  Therefore  lies below  and as such  since triangle .  
\end{proof}

We now complete the proof of Theorem \ref{theo:approx} with the following lemma.

\begin{lemma}
.  \end{lemma}

\begin{proof}
For  and , since  then .    

Since , then invariant (I4) implies that  and hence .  

Finally, for , Lemma~\ref{lem:key} implies that  , that , and . 

It follows that

as desired.
\end{proof}




\subsection{Remarks}
\begin{itemize} \denselist
\item[(1)] For ,   is only a factor of  and , respectively, larger than ; therefore, the sizes of optimal -kernels in these dimensions are relative stable. However, for , the stability drastically reduces in the worst case because of the superlinear dependency on .

\item[(2)] Neither the upper nor the lower bound in the theorem is tight. For , we can prove a tighter lower bound of . We conjecture in  that 
 
\end{itemize}






\bibliographystyle{mystyle}
\bibliography{bib-coreset}




\end{document}
