
\section{Proof of Theorem \ref{thm:fundamental}}
\label{app:proof_fundamental}


\begin{proof}
To model \emph{any} EPFO query, we need to at least model a subset of EPFO queries
, where the corresponding denotation sets are .
For the sake of modeling , without loss of generality, we consider assigning a single entity embedding  to all , so there are  kinds of entity vectors, .
To model all queries in , it is necessary to satisfy the following.

where  is the embedding of query . 
Eq.~\ref{eq:shatter} means that we can learn the  kinds of entity vectors such that for every query in , we can obtain its embedding to model the corresponding set using the distance function.
Notice that this is agnostic to the specific algorithm to embed query  into ; thus, our result is generally applicable to \emph{any} method that embeds the query into a single vector.

Crucially, satisfying Eq.~\ref{eq:shatter} is equivalent to  being able to shutter , \ie, any binary labeling of the points can be perfectly fit by some classifier in the function class. To sum up, in order to model any EPFO query, we need to at least model any query in , which requires the VC dimension of the distance function to be larger than or equal to .
\end{proof}

\section{Details about Computing  in Theorem \ref{thm:fundamental}}
\label{app:calculate_m}
Given the full KG  for the FB15k dataset, our goal is to find conjunctive queries  such that  are disjoint with each other.
For conjunctive queries, we use two types of queries: `1p' and `2i' whose query structures are shown in Figure \ref{fig:dgstructure}. 
On the FB15k, we instantiate 308,006 queries of type `1p', which we denote by . Out of all the queries in , 129,717 queries have more than one answer entities, and we denote such a set of the queries by .
We then generate a set of queries of type `2i' by first randomly sampling two queries from  and then taking conjunction; we denote the resulting set of queries by .

Now, we use  and  to generate a set of conjunctive queries whose denotation sets are disjoint with each other.
First, we prepare two empty sets , and . 
Then, for every , if  holds, we let  and . This procedure already gives us , where we have  conjunctive queries whose denotation sets are disjoint with each other.
We can further apply the analogous procedure for , which gives us a further increased , where we have  conjunctive queries whose denotation sets are disjoint with each other. Therefore, we get .

\section{Experiments on Link Prediction} \label{app:linkpred}

\begin{table*}[!h]
\centering
\begin{tabular}{|c|c|c|c|c|c|c|}
\hline
             & \multicolumn{2}{c|}{FB15k} & \multicolumn{2}{c|}{FB15k-237} & \multicolumn{2}{c|}{NELL995} \\ \hline
Method       & H@3          & MRR         & H@3            & MRR           & H@3           & MRR          \\ \hline
query2box    & 0.613        & 0.516       & 0.331          & 0.295         & 0.382            & 0.303           \\ \hline
query2box-1p & 0.633        & 0.531       & 0.323          & 0.292         & 0.415            & 0.320           \\ \hline
TransE       & 0.611        & 0.522       & 0.318          & 0.289         & 0.413            & 0.320           \\ \hline
\end{tabular}
\caption{Performance comparison on the simple link prediction task on the three datasets.}
\label{tab:linkpred}
\end{table*}


In Table \ref{tab:linkpred}, we report the link prediction performance (no multi-hop logical reasoning required) following the conventional metrics (taking average over the triples of head, relation, and tail). Here query2box is trained on all five query structures as shown in Figure \ref{fig:dgstructure}, and query2box-1p is only trained on simple 1p queries. We found that our query2box is comparable or slightly better than TransE on simple link prediction. Note that in the case of simple link prediction, we do not expect a huge performance gain by using box embeddings as link prediction does not involve logical reasoning nor handling a large set of answer entities. Also, we see that even if we train query2box over diverse queries, its performance on link prediction is still comparable to TransE and query2box-1p, which are trained solely on the link prediction task.

\section{Details on Query Generation}
\label{app:pre-traversal}
Given , , and  as defined in Section \ref{sec:querygeneration}, we generate training, validation and test queries of different query structures. During training, we consider the first 5 kinds of query structures. For evaluation, we consider all the 9 query structures in Fig.~\ref{fig:dgstructure}, containing query structures that are both seen and unseen during training time. We instantiate queries in the following way.

Given a KG and a query structure (which is a DAG), we use pre-order traversal to assign an entity and a relation to each node and edge in the DAG of query structure to instantiate a query. Namely, we start from the root of the DAG (which is the target node), we sample an entity  uniformly from the KG to be the root, then for every node connected to the root in the DAG, we choose a relation  uniformly from the in-coming relations of  in the KG, and a new entity  from the set of entities that reaches  by  in the KG. Then we assign the relation  to the edge and  to the node, and move on the process based on the pre-order traversal. This iterative process stops after we assign an entity and relation to every node and edge in DAG. The leaf nodes in the DAG serve as the anchor nodes. Note that during the entity and relation assignment, we specifically filter out all the degenerated queries, as shown in Fig. \ref{fig:exception}. Then we perform a post-order traversal of the DAG on the KG, starting from the anchor nodes, to obtain a set of answer entities to this query.

\begin{figure*}[t]
\label{fig:exception}
\centering
    \includegraphics[width=\textwidth]{figs/exception.pdf}
    \caption{Example of the degenerated queries, including (1)  and  appear along one path and (2) same anchor node and relation in intersections.}
\end{figure*}

When generating validation/test queries, we explicitly filter out trivial queries that can be fully answered by subgraph matching on /.
 


\section{Details of NELL995 Dataset} \label{app:nell}
Here we detail our pre-processing of the NELL995 dataset, which is originally presented by \citet{xiong2017deeppath}. 
Following \citet{allen2019understanding}, we first combine the validation and test sets with the training set to create the whole knowledge graph for NELL995. Then we create new validation and test set splits by randomly selecting 20,000 triples each from the whole knowledge graph. Note that we filter out all the entities that only appear in the validation and test sets but not in the training set. 

\newpage
\section{Dataset Statistics} \label{app:datastats}
Table \ref{tab:meta_kg} summarizes the basic statistics of the three datasets used in our experiments. Table \ref{tab:meta_query} summarizes the basic statistics of the generated logical queries.

\begin{table*}[t]
\centering
\small
\resizebox{\columnwidth}{!}{\begin{tabular}{|c|c|c|c|c|c|c|}
\hline
\textbf{Dataset} & \textbf{Entities} & \textbf{Relations} & \textbf{Training Edges} & \textbf{Validation Edges} & \textbf{Test Edges} & \textbf{Total Edges}\\
\hline
FB15k & 14,951 & 1,345 & 483,142 & 50,000 & 59,071 & 592,213\\
\hline
FB15k-237 & 14,505 & 237 & 272,115 & 17,526 & 20,438 & 310,079\\
\hline
NELL995 & 63,361 & 200 & 114,213 & 14,324 & 14,267 & 142,804\\
\hline
\end{tabular}
}
\caption{Knowledge graph dataset statistics as well as the split into training, validation, and test sets.}
\label{tab:meta_kg}
\end{table*}

\begin{table*}[t]
\centering
\small
\begin{tabular}{|l|c|c|c|c|c|c|}
\hline
         \textbf{Queries} & \multicolumn{2}{c|}{\textbf{Training}} & \multicolumn{2}{c|}{\textbf{Validation}} & \multicolumn{2}{c|}{\textbf{Test}} \\ \hline
\textbf{Dataset}     & 1p               & others           & 1p              & others          & 1p               & others          \\ \hline
FB15k     & 273,710          & 273,710          & 59,097          & 8,000           & 67,016           & 8,000           \\ \hline
FB15k-237 & 149,689          & 149,689          & 20,101          & 5,000           & 22,812           & 5,000           \\ \hline
NELL995     & 107,982          & 107,982          & 16,927          & 4,000           & 17,034           & 4,000           \\ \hline
\end{tabular}
\caption{Number of training, validation, and test queries generated for different query structures.}
\label{tab:meta_query}
\end{table*}

\section{Hyper-parameters} \label{app:expdetails}
We use embedding dimensionality of  and set ,  for the loss in Eq. \ref{thm:lossfunc}. We train all types of training queries jointly. In every iteration, we sample a minibatch size of 512 queries for each query structure (details in Appendix \ref{app:pre-traversal}), and we sample 1 answer entity and 128 negative entities for each query. We optimize the loss in Eq. \ref{thm:lossfunc} using Adam Optimizer \citep{kingma2014adam} with learning rate = 0.0001. We train all models for 250 epochs, monitor the performance on the validation set, and report the test performance.

\section{Analysis of Learned Box Offset size}\label{app:offset_analysis}
Here we study the correlation between the box size (measured by the L1 norm of the box offset) and the average number of entities that are contained in 1p queries using the corresponding relation. Table \ref{tab:boxoffset_analysis} shows the top 10 relations with smallest/largest box sizes.
We observe a clear trend that the size of the box has a strong correlation with the number of entities the box encloses. Specifically, we see that one-to-many relations tend to have larger offset embeddings, which demonstrates that larger boxes are indeed used to model sets of more points (entities).

\begin{table*}[!h]
\resizebox{\columnwidth}{!}{
\begin{tabular}{|l|c|c|c|l|c|c|}
\cline{1-3} \cline{5-7}
{\bf Top 10 relations with smallest box size}        & {\bf \#Ent} & {\bf Box size} &  & {\bf Top 10 relations with largest box size} & {\bf\#Ent} & {\bf Box size} \\ \cline{1-3} \cline{5-7} 
/architecture/.../owner                            & 1.0            & 2.3      &  & /common/.../topic                      & 3616.0         & 147.0    \\ \cline{1-3} \cline{5-7} 
/base/.../dog\_breeds                              & 2.0            & 4.0      &  & /user/...taxonomy                      & 1.0            & 137.2    \\ \cline{1-3} \cline{5-7} 
/education/.../campuses                            & 1.0            & 4.3      &  & /common/.../category                   & 1.3            & 125.6    \\ \cline{1-3} \cline{5-7} 
/education/.../educational\_institution            & 1.0            & 4.6      &  & /base/.../administrative\_area\_type   & 1.0            & 123.6    \\ \cline{1-3} \cline{5-7} 
/base/.../collective                               & 1.0            & 5.1      &  & /medicine/.../legal\_status            & 1.5            & 114.9    \\ \cline{1-3} \cline{5-7} 
/base/.../member                                   & 1.0            & 5.1      &  & /people/.../spouse                     & 889.8          & 114.3    \\ \cline{1-3} \cline{5-7} 
/people/.../appointed\_by                          & 1.0            & 5.2      &  & /sports/.../team                       & 397.9          & 113.9    \\ \cline{1-3} \cline{5-7} 
/base/.../fashion\_models\_with\_this\_hair\_color & 2.0            & 5.2      &  & /people/.../location\_of\_ceremony     & 132.0          & 108.4    \\ \cline{1-3} \cline{5-7} 
/fictional\_universe/.../parents                   & 1.0            & 5.5      &  & /sports/.../team                       & 83.1           & 104.5    \\ \cline{1-3} \cline{5-7} 
/american\_football/.../team                       & 2.0            & 6.7      &  & /user/.../subject                      & 495.0          & 104.2    \\ \cline{1-3} \cline{5-7} 
\end{tabular}}
\caption{Top 10 relations with smallest/largest box size in FB15k.}
\label{tab:boxoffset_analysis}
\end{table*}

\newpage
\section{MRR Results}

\begin{table*}[!h]
\resizebox{\columnwidth}{!}{
\begin{tabular}{lcccccccccc}
\hline
\multicolumn{1}{l|}{\textbf{Method}}         & \multicolumn{1}{c|}{\textbf{Avg}}   & \textbf{1p}    & \textbf{2p}    & \multicolumn{1}{c|}{\textbf{3p}}    & \textbf{2i}    & \multicolumn{1}{c|}{\textbf{3i}}    & \textbf{ip}    & \textbf{pi}    & \textbf{2u}    & \textbf{up}    \\ \hline
\multicolumn{11}{c}{\textbf{FB15k}}                                                                                                                                                                                                                                                   \\ \hline
\multicolumn{1}{l|}{\shortname}           & \multicolumn{1}{c|}{\textbf{0.41}}  & \textbf{0.654} & \textbf{0.373} & \multicolumn{1}{c|}{\textbf{0.274}} & \textbf{0.488} & \multicolumn{1}{c|}{\textbf{0.602}} & \textbf{0.194} & \textbf{0.339} & \textbf{0.468} & \textbf{0.301} \\ \hline
\multicolumn{1}{l|}{\baselinename}          & \multicolumn{1}{c|}{0.328}          & 0.505          & 0.320          & \multicolumn{1}{c|}{0.218}          & 0.439          & \multicolumn{1}{c|}{0.536}          & 0.139          & 0.272          & 0.3            & 0.244          \\
\multicolumn{1}{l|}{\baselinedouble} & \multicolumn{1}{c|}{0.326}          & 0.49           & 0.3            & \multicolumn{1}{c|}{0.222}          & 0.438          & \multicolumn{1}{c|}{0.532}          & 0.142          & 0.28           & 0.285          & 0.242          \\ \hline
\multicolumn{11}{c}{\textbf{FB15k-237}}                                                                                                                                                                                                                                                \\ \hline
\multicolumn{1}{l|}{\shortname}           & \multicolumn{1}{c|}{\textbf{0.235}} & \textbf{0.4}   & \textbf{0.225} & \multicolumn{1}{c|}{\textbf{0.173}} & \textbf{0.275} & \multicolumn{1}{c|}{\textbf{0.378}} & \textbf{0.105} & \textbf{0.18}  & \textbf{0.198} & \textbf{0.178} \\ \hline
\multicolumn{1}{l|}{\baselinename}          & \multicolumn{1}{c|}{0.203}          & 0.346          & 0.193          & \multicolumn{1}{c|}{0.145}          & 0.25           & \multicolumn{1}{c|}{0.355}          & 0.086          & 0.156          & 0.145          & 0.151          \\
\multicolumn{1}{l|}{\baselinedouble} & \multicolumn{1}{c|}{0.205}          & 0.346          & 0.191          & \multicolumn{1}{c|}{0.144}          & 0.258          & \multicolumn{1}{c|}{0.361}          & 0.087          & 0.164          & 0.144          & 0.149          \\ \hline
\multicolumn{11}{c}{\textbf{NELL995}}                                                                                                                                                                                                                                                 \\ \hline
\multicolumn{1}{l|}{\shortname}           & \multicolumn{1}{c|}{\textbf{0.254}} & \textbf{0.413} & \textbf{0.227} & \multicolumn{1}{c|}{\textbf{0.208}} & \textbf{0.288} & \multicolumn{1}{c|}{\textbf{0.414}} & \textbf{0.125} & \textbf{0.193} & \textbf{0.266} & \textbf{0.155} \\ \hline
\multicolumn{1}{l|}{\baselinename}          & \multicolumn{1}{c|}{0.21}           & 0.311          & 0.193          & \multicolumn{1}{c|}{0.175}          & 0.273          & \multicolumn{1}{c|}{0.399}          & 0.078          & 0.168          & 0.159          & 0.13           \\
\multicolumn{1}{l|}{\baselinedouble} & \multicolumn{1}{c|}{0.211}          & 0.309          & 0.192          & \multicolumn{1}{c|}{0.174}          & 0.275          & \multicolumn{1}{c|}{0.408}          & 0.08           & 0.17           & 0.156          & 0.129          \\ \hline
\end{tabular}
}
\caption{MRR results of \methodname vs. \baselinename on FB15k, FB15k-237 and NELL995.}
\label{tab:mrr-baseline}
\end{table*}

\begin{table*}[!h]
\resizebox{\columnwidth}{!}{
\begin{tabular}{lcccccccccc}
\hline
\multicolumn{1}{l|}{\textbf{Method}}     & \multicolumn{1}{c|}{\textbf{Avg}}   & \textbf{1p}    & \textbf{2p}    & \multicolumn{1}{c|}{\textbf{3p}}    & \textbf{2i}    & \multicolumn{1}{c|}{\textbf{3i}}    & \textbf{ip}    & \textbf{pi}    & \textbf{2u}    & \textbf{up}    \\ \hline
\multicolumn{11}{c}{\textbf{FB15k}}                                                                                                                                                                                                                                               \\ \hline
\multicolumn{1}{l|}{\shortname}       & \multicolumn{1}{c|}{\textbf{0.41}}  & 0.654          & \textbf{0.373} & \multicolumn{1}{c|}{\textbf{0.274}} & 0.488          & \multicolumn{1}{c|}{0.602}          & \textbf{0.194} & \textbf{0.339} & 0.468          & \textbf{0.301} \\ \hline
\multicolumn{1}{l|}{\avg}            & \multicolumn{1}{c|}{0.396}          & 0.648          & 0.368          & \multicolumn{1}{c|}{0.27}           & 0.476          & \multicolumn{1}{c|}{0.564}          & 0.182          & 0.295          & 0.465          & 0.3            \\
\multicolumn{1}{l|}{\deepsets}        & \multicolumn{1}{c|}{0.402}          & 0.631          & 0.371          & \multicolumn{1}{c|}{0.269}          & \textbf{0.499} & \multicolumn{1}{c|}{\textbf{0.605}} & 0.181          & 0.325          & 0.437          & 0.298          \\
\multicolumn{1}{l|}{\avgc}  & \multicolumn{1}{c|}{0.324}          & \textbf{0.688} & 0.236          & \multicolumn{1}{c|}{0.159}          & 0.378          & \multicolumn{1}{c|}{0.435}          & 0.122          & 0.225          & \textbf{0.498} & 0.178          \\
\multicolumn{1}{l|}{\share} & \multicolumn{1}{c|}{0.296}          & 0.511          & 0.273          & \multicolumn{1}{c|}{0.199}          & 0.351          & \multicolumn{1}{c|}{0.444}          & 0.132          & 0.233          & 0.311          & 0.213          \\ \hline
\multicolumn{11}{c}{\textbf{FB15k-237}}                                                                                                                                                                                                                                           \\ \hline
\multicolumn{1}{l|}{\shortname}       & \multicolumn{1}{c|}{\textbf{0.235}} & 0.4            & \textbf{0.225} & \multicolumn{1}{c|}{\textbf{0.173}} & \textbf{0.275} & \multicolumn{1}{c|}{\textbf{0.378}} & \textbf{0.105} & \textbf{0.18}  & 0.198          & \textbf{0.178} \\ \hline
\multicolumn{1}{l|}{\avg}            & \multicolumn{1}{c|}{0.219}          & 0.398          & 0.222          & \multicolumn{1}{c|}{0.171}          & 0.236          & \multicolumn{1}{c|}{0.328}          & 0.1            & 0.145          & 0.193          & 0.177          \\
\multicolumn{1}{l|}{\deepsets}        & \multicolumn{1}{c|}{0.23}           & 0.395          & 0.224          & \multicolumn{1}{c|}{0.172}          & 0.264          & \multicolumn{1}{c|}{0.372}          & 0.101          & 0.168          & 0.194          & 0.176          \\
\multicolumn{1}{l|}{\avgc}  & \multicolumn{1}{c|}{0.196}          & \textbf{0.41}  & 0.18           & \multicolumn{1}{c|}{0.122}          & 0.217          & \multicolumn{1}{c|}{0.274}          & 0.085          & 0.127          & \textbf{0.209} & 0.145          \\
\multicolumn{1}{l|}{\share} & \multicolumn{1}{c|}{0.18}           & 0.328          & 0.18           & \multicolumn{1}{c|}{0.131}          & 0.207          & \multicolumn{1}{c|}{0.289}          & 0.083          & 0.136          & 0.135          & 0.132          \\ \hline
\multicolumn{11}{c}{\textbf{NELL995}}                                                                                                                                                                                                                                             \\ \hline
\multicolumn{1}{l|}{\shortname}       & \multicolumn{1}{c|}{\textbf{0.254}} & 0.413          & \textbf{0.227} & \multicolumn{1}{c|}{\textbf{0.208}} & \textbf{0.288} & \multicolumn{1}{c|}{\textbf{0.414}} & \textbf{0.125} & \textbf{0.193} & 0.266          & \textbf{0.155} \\ \hline
\multicolumn{1}{l|}{\avg}            & \multicolumn{1}{c|}{0.235}          & 0.406          & 0.219          & \multicolumn{1}{c|}{0.2}            & 0.251          & \multicolumn{1}{c|}{0.342}          & 0.114          & 0.174          & 0.259          & 0.149          \\
\multicolumn{1}{l|}{\deepsets}        & \multicolumn{1}{c|}{0.246}          & 0.405          & 0.226          & \multicolumn{1}{c|}{0.207}          & 0.275          & \multicolumn{1}{c|}{0.403}          & 0.107          & 0.182          & 0.256          & 0.153          \\
\multicolumn{1}{l|}{\avgc}  & \multicolumn{1}{c|}{0.227}          & \textbf{0.468} & 0.191          & \multicolumn{1}{c|}{0.16}           & 0.234          & \multicolumn{1}{c|}{0.275}          & 0.094          & 0.162          & \textbf{0.332} & 0.125          \\
\multicolumn{1}{l|}{\share} & \multicolumn{1}{c|}{0.196}          & 0.318          & 0.187          & \multicolumn{1}{c|}{0.172}          & 0.228          & \multicolumn{1}{c|}{0.312}          & 0.098          & 0.156          & 0.169          & 0.127          \\ \hline
\end{tabular}
}
\caption{MRR results of \methodname vs. several variants on FB15k, FB15k-237 and NELL995.}
\label{tab:mrr-ablation}
\end{table*}