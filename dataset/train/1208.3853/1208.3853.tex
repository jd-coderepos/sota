\label{sec:algorithm}

In this section we deal with monitoring of an STL* formula, which means to determine the satisfaction of a formula over a finite length signal. 
The monitoring procedure introduced in this paper is inspired by constrained LTL model-checking~\cite{Calzone} and monitoring of STL formulae~\cite{Maler_STL}, but needed to be extended into 2D space due to freeze operator $\ast$. It is because the task is solved simultaneously for two time instants, actual time and frozen time.

The idea of the monitoring procedure is to construct a parse tree of the formula and check the satisfaction in a bottom-up manner. First step in checking a formula $\varphi$ over a signal $s$ is to construct a set of time points in which the formula $\varphi$ is satisfied.

\begin{definition}
	Let $\varphi$ be a STL* formula and $s$ be a real-valued signal. A~set $S_{\varphi,s} = \lbrace (t, t^\ast) \in [0, |s|] \times [0, |s|] \mid (s, t, t^\ast) \models \varphi \rbrace$ is called the \emph{satisfaction set} of formula $\varphi$ over signal $s$. We use short-form notation $S_\varphi$ whenever the signal $s$ is obvious from the context.
\end{definition}

Now we inductively construct satisfaction sets for nodes on higher levels of the parse tree. The last step of the procedure is to decide if $s \models \varphi$ from satisfaction set for the formula $\varphi$. According to Definition \ref{defSatisfactionSignal}, it is equivalent to checking whether the satisfaction set contains the point $(0, 0)$.

Constructing the satisfaction set for a general signal can be a very difficult task. For this reason we will consider the monitoring algorithm only for piecewise linear signals. This is a reasonable requirement because in most cases we deal with time series produced by numerical simulations of modelled systems or by some measurements. These series can be interpreted as piecewise linear signals considering the values changing linearly between two adjacent points. If required, other points can be generated in between the existing points to make the signal more precise. 


\begin{definition}
	A real-valued signal $s$ of order $n$ is called \emph{piecewise linear signal} iff all the projections $s_i(t) : [0, |s|] \rightarrow \mathbb{R}, i = 1, \ldots, n$ are piecewise linear functions defined on a finite set of intervals $\intervals = \lbrace I_1, I_2, \ldots, I_m \rbrace$ where $I_j \subseteq [0, |s|],j = 1,\ldots, m$ and $\bigcap\intervals= \emptyset, \bigcup\intervals= [0, |s|]$.
\end{definition}

\begin{theorem}[Inductive construction of the satisfaction set]
	\label{monitoring_STL*}
	Let $s$ be a piecewise linear signal and $\varphi$ a formula in STL*. The satisfaction set $S_\varphi$ of the formula $\varphi$ over the signal $s$ can be constructed inductively with respect to the structure of the formula $\varphi$:       
	\begin{equation*}
    	\begin{array}{lcl}
        	S_\mu & = & \lbrace (t, t^\ast) \in \mathbb{R}_0^+ \times \mathbb{R}_0^+ \mid \mu(s, t, t^\ast) = 1 \rbrace;\\
    		S_{\neg \varphi} & = & \mathbb{R}_0^+ \times \mathbb{R}_0^+ \setminus S_\varphi;\\ 
    		S_{\varphi_1 \vee \varphi_2} & = & S_{\varphi_1} \cup S_{\varphi_2};\\
			S_{\varphi_1 \until{a}{b} \varphi_2} & = & \lbrace (t, t^\ast) \in S_{\varphi_1} \mid \exists t' \in [t + a, t + b]: (t', t^\ast) \in S_{\varphi_2} \, \wedge\\
			& & \forall t'' \in [t, t'] : (t'', t^\ast) \in S_{\varphi_1}\rbrace;\\
			S_{\ast \varphi} & = & \lbrace (t, t^\ast) \in \mathbb{R}_0^+ \times \mathbb{R}_0^+ \mid (t, t) \in S_{\varphi}, t^\ast \in \mathbb{R}_0^+ \rbrace.\\ 
		\end{array}
	\end{equation*}

	\begin{proof}
		Each of the equations follows directly from the definition of semantics of STL* \eqref{STL*_sematics}.
	\end{proof}
\end{theorem}

The assumption of piecewise linear signals in combination with linearity of atomic predicates (Definitions \ref{defLinearPredicate}, \ref{defPredicate}) enables us to construct satisfaction sets for atomic predicates in polynomial time and to easily compute sets belonging to higher formulae. The formalism we use for the representation of satisfaction sets are convex polytopes.

\begin{definition}
	\label{defConvexPolytope}
	\emph{Convex polytope} $P \subseteq \mathbb{R}^n$ is a set $\lbrace x = (x_1, x_2, \ldots, x_n) \in \mathbb{R}^{n \times 1} \mid Ax \leq b \rbrace$ where $A \in \mathbb{R}^{m \times n}$ is a matrix and $b \in \mathbb{R}^{m \times 1}$ is a  column. A convex polytope in $\mathbb{R}^1$ is called a \emph{line segment}, in $\mathbb{R}^2$ a \emph{convex polygon}.
\end{definition}

Each inequality $\sum_{j=1}^n a_{ij} x_j \leq b_i$ in Definition \ref{defConvexPolytope} identifies a subspace of $\mathbb{R}^n$. The convex polytope is obtained as intersection of these subspaces.

\begin{theorem}
	\label{lemma}
	Assume $s$ a piecewise linear signal and $\intervals = \lbrace I_1, \ldots, I_m \rbrace$ the set of intervals on which $s$ is defined. Let $\mu$ be an atomic predicate over the signal $s$. The predicate $\mu(s, t, t^\ast) = \sum_{i=1}^{n} a_i s_i(t) + \sum_{i=1}^{n} b_i s_i(t^\ast) \sim b, \sim \in \lbrace <, \leq, >, \geq, = \rbrace$ is a linear function over the signal $s$ in variables $t$ and $t^\ast$ according to Definition \ref{defPredicate}. Denote $S^+_{i, j} \df \lbrace (t, t^\ast) \in I_i \times I_j \mid \mu(s, t, t^\ast) = 1 \rbrace$ where $i,j \in \lbrace 1, \ldots m \rbrace, I_i, I_j \in\intervals$ the set of time instants at which the atomic predicate $\mu$ is satisfied over signal $s$ on rectangular area $I_i \times I_j$ and $S^-_{i,j} \df (I_i \times I_j) \setminus S^+_{i,j}$ its complement. For $t \in I_i, t^\ast \in I_j$ there can arrive two situations:

\begin{enumerate}
	\item if $\sim\,\equiv\,=$, then the set $S^+_{i,j}$ makes a line segment (possibly degenerated to a single point or an empty set); 
	\item if $\sim\,\not\equiv\,=$, then the space $I_i \times I_j$ is divided by the line $\sum_{i=1}^{n} a_i s_i(t) + \sum_{i=1}^{n} b_i s_i(t^\ast) = b$ into two subspaces $S^+_{i,j}$ and $S^-_{i,j}$ (Figure \ref{figCut}). (Again, there might be a degenerated case when the line $\sum_{i=1}^{n} a_i s_i(t) + \sum_{i=1}^{n} b_i s_i(t^\ast) = b$ does not cross the rectangle $\lbrace (t, t^\ast) \in I_i \times I_j \rbrace$. In this case $S^+_{i,j} = \emptyset$ and $S^-_{i,j} = I_i \times I_j$ or vice versa).
\end{enumerate}

\begin{proof}
		Described properties result from the linear form of atomic predicates \ref{defPredicate} and from the fact that signal $s$ behaves linearly on each interval $I_i \in\intervals, i \in \lbrace 1, \ldots m \rbrace$.
	\end{proof}

\end{theorem}

\begin{figure}[h]
\vspace*{-3mm}
	\begin{center}
    \includegraphics[scale=0.4]{figures/cut.png}
     \caption{An illustration of the set $S^+_{i,j}$ for a formula $x^* < \frac{2}{3}x + \frac{28}{3}$ on the subspace $I_i \times I_j = [0, 4] \times [10, 13]$.}
    \label{figCut}
    \end{center}
\vspace*{-3mm}
\end{figure}


In both cases, the set $S^+_{i,j}$ makes a convex set easily describable by set operations over convex polytopes. In the first case, a line segment itself is a convex polytope. In the second case, either the set $S^+_{i,j}$ is a convex polytope, or (when $\sim \in \lbrace <, > \rbrace$) it is a convex polytope after subtraction of one bordering line segment, which is a polytope.

Using this algorithm we can express the satisfaction set $S_{\mu}$ as $S_{\mu} = \bigcup_{i,j \in\{1,...,m\}} S^+_{i,j}$, where $S^+_{i,j}$ are the sets described above constructed by set operations on polytopes. The set $S_{\mu}$ can be further simplified by joining adjacent polytopes. Having satisfaction sets for atomic predicates, we could inductively construct satisfaction sets for composite formulae from Theorem \ref{monitoring_STL*} again as operations on polytopes, which could be achieved in polynomial time~\cite{GeometricAlgorithms}. 

However, working with precise satisfaction sets as defined in Theorem \ref{monitoring_STL*} can be quite a difficult task. We have to work with polytopes of different dimensions (polygons, lines and points) and operations over sets of these objects can be unnecessarily demanding. In real-world applications, we could end up performing an expensive monitoring over noisy signals measured on imperfect devices or computed on computers with finite numerical precision. Hence think about less precise, yet faster monitoring algorithm.



We can imagine a \emph{noisy signal} as a signal measured or computed with finite precision. The actual values of the variables can differ from the values presented by the signal up to some error $\epsilon > 0$. This inaccuracy in the domain of values implies also inaccuracy in the time domain. When investigating the time instant in which some event occurred (e.g., $x > 0$) we cannot be sure when exactly it happened. That is because the critical value $x = 0$ is burdened by an error and it is possible that $x = 0$, but also that $x > 0$ or $x < 0$ in that particular time instant.





Imagine we are in the situation from Theorem \ref{lemma}, but working with a noisy signal. We cannot be sure about the border of the set $S^+_{i, j}$ due to the error $\epsilon$. The condition $\sum_{i=1}^{n} a_i s_i(t) + \sum_{i=1}^{n} b_i s_i(t^\ast) = b$ defining points on the border of $S^+_{i, j}$ could be easily broken by changing the values of the signal $s$ by arbitrary small values from $(0, \epsilon)$. For this reason, we will ignore these border points and count them as they were in $S^+_{i, j}$ or in $S^-_{i, j}$ depending on what would be computationally easier. As a consequence, in the first case in Theorem \ref{lemma}, $S^+_{i, j} = \emptyset$, and in the second case, it does not matter if $\sim{}\equiv{}<$ or $\sim{}\equiv{}\leq$.

As a result of this simplification, the set of allowed operators in atomic predicates is restricted to $\lbrace <, > \rbrace$. The remaining three operators lost their sense. With signals burden with some error $\epsilon > 0$ the satisfaction of atomic predicates can be meaningfully determined only for time instants inside the satisfaction set. 
Hence the satisfaction of a formula using the operator $=$, e.g., $x = b$ or $x = y + 2$, cannot be determined. Every reference to a precise value has to be replaced by a sufficiently large interval, e.g., formula $x = b$ can be replaced by $x \geq (b - \delta) \wedge x \leq (b + \delta)$ for some $\delta > \epsilon / 2$.

Based on these assumptions, monitoring can be solved approximately. For every pair of intervals $I_i, I_j \in\intervals$, the satisfaction set on this area can be described by a single convex polygon $S^+_{i,j}$. For the whole satisfaction set $S_{\mu,s}$ we get $S_{\mu,s} = \bigcup_{i, j \in\{1,...,m\}} S^+_{i,j}$. The problem of construction of satisfaction sets for composite formulae from Theorem \ref{monitoring_STL*} is reduced to operations with sets of convex polytopes in plane for which efficient algorithms exist~\cite{GeometricAlgorithms}. 
 
\begin{algorithm}[Approximative monitoring algorithm for piecewise linear signals]
\label{algorithm1}

\end{algorithm}
\smallskip
\textbf{Input:} A piecewise linear signal $s$ and an STL* formula $\varphi$.\\
\textbf{Output:} Answer to the question $s \models \varphi$.\\

Algorithm inductively constructs the satisfaction set $S_{\varphi}$:\\

All the computations are performed on parts of the signal $s$ of sufficient length. This can be computed according to \eqref{sufficientSignalLength}. If the signal does not have the sufficient length, the answer returned by the algorithm might be wrong. 


\begin{enumerate}


	\item $S_{\mu} = \bigcup_{i, j \in\{1,...,m\}} S^+_{i,j}$. The computation of the satisfaction sets $S^+_{i,j}$ for individual intervals is performed according to Theorem \ref{lemma}, but without determining the satisfaction of the borders (as was justified in this section).

	\item $S_{\neg \varphi} = (\intervals \times \intervals) \setminus S_{\varphi}$. The result can be computed as a simple Boolean operation on polygons. It is necessary to ensure that the resulting set consists only of convex polygons, which could be achieved for example by triangulation~\cite{GeometricAlgorithms}. 
	
	\item $S_{\varphi_1 \vee \varphi_2} = S_{\varphi_1} \cup S_{\varphi_2}$. Again a Boolean polygonal operation. 

	\item $S_{\ast \varphi} = \lbrace (t, t^\ast) \in \mathbb{R}_0^+ \times \mathbb{R}_0^+ \mid (t, t) \in S_{\varphi}, t^\ast \in \mathbb{R}_0^+ \rbrace$. The satisfaction set for the freeze operation can be computed by: (1) finding an intersection between the line $t^* = t$ and the satisfaction set $S_{\varphi}$ (black line segments in Figure~\ref{figFreezeSS-a}), (2) substituting values in the second component by the whole axis $t^\ast$, i.e., making a projection to the first component $t$ and then a Cartesian product with the axis $t^\ast$ (Figure \ref{figFreezeSS-b}).  
	
	
	
\begin{figure}[h]
   \centering  
	\subfloat[][]{\includegraphics[scale=0.4]{figures/ss1.png}
			\label{figFreezeSS-a}}
    \subfloat[][]{\includegraphics[scale=0.4]{figures/ss2.png}
			\label{figFreezeSS-b}}
    	
      	\caption{Example of computing satisfaction set for the formula $\ast \varphi$. a) The satisfaction set represented as a set of (overlapping) convex polygons (different colors are used only for depicting the fact that the set consists of convex polygons) and the line $t = t^\ast$. The regions of intersection of the line and the satisfaction set are depicted in black color. b) Resulting set $S_{\ast \varphi}$ obtained by projecting the intervals of intersection to the axis $t$ and making a Cartesian product with the axis $t^\ast$.}
	\label{figFreezeSS}    
    
\end{figure}



	\item \label{step} $S_{\varphi_1 \until{a}{b} \varphi_2} = \lbrace (t, t^\ast) \in S_{\varphi_1} \mid \exists t' \in [t + a, t + b]: (t', t^\ast) \in S_{\varphi_2} \wedge \forall t'' \in [t, t'] : (t'', t^\ast) \in S_{\varphi_1}\rbrace$. To be more illustrative, we explain this part of the algorithm from the geometrical point of view, identifying values $t$ with the horizontal axis and values $t^\ast$ with the vertical axis.
	
	
	
\begin{figure}[h]
   \centering  
	\subfloat[][$S_{\varphi_1}$]{\includegraphics[scale=0.4]{figures/alg1.png}
			\label{figAlgorithm1-a}}
    \subfloat[][$S_{\varphi_2}$]{\includegraphics[scale=0.4]{figures/alg2.png}
			\label{figAlgorithm1-b}}
    \subfloat[][$S_{\varphi_1} \cap S_{\varphi_2}$]{\includegraphics[scale=0.4]{figures/alg3.png}
			\label{figAlgorithm1-c}}
      	\caption{First step of computation of $S_{\varphi_1 \untilLTL_{[a, b]} \varphi_2}$ is to find the intersection $S_{\varphi_1} \cap S_{\varphi_2}$.}
	\label{figAlgorithm1}    
    
\end{figure}	

\begin{figure}[h]
   \centering  
	\subfloat[][$P \cup S_{\varphi_1}$]{\includegraphics[scale=0.4]{figures/alg4.png}
			\label{figAlgorithm2-a}}
    \subfloat[][ordered vertices]{\includegraphics[scale=0.4]{figures/alg5.png}
			\label{figAlgorithm2-b}}
    \subfloat[][rectangular polygons (stripes) \\$R_i, i = 1, \ldots, n - 1$]{\includegraphics[scale=0.4]{figures/alg6.png}
			\label{figAlgorithm2-c}}
      	\caption{Next, the space is divided into horizontal stripes. The task is solved in each stripe separately.}
	\label{figAlgorithm2}    
    
\end{figure}
	
	For each convex polygon $P \in S_{\varphi_1} \cap S_{\varphi_2}$ (Figure~\ref{figAlgorithm1-c}) the following procedure is performed:
		 \begin{enumerate}
			\item Vertices of polygons $\lbrace P \rbrace \cup S_{\varphi_1}$ are increasingly ordered by the second component $t^\ast$ (duplicates can be removed). Denote the ordered set $V \df (V_1, V_2, \ldots V_n)$ (Figures~\ref{figAlgorithm2-a},~\ref{figAlgorithm2-b});
			\item For $i = 1, \ldots, n-1$ every neighbouring pair of vertices $V_i = (t_{i}, t^\ast_{i}), V_{i+1} = (t_{i+1}, t^\ast_{i+1}) \in V$ specifies a rectangular polygon (stripe): $$R_{i} \df \lbrace (t, t^\ast) \in \mathbb{R}_0^+ \times [t_i^\ast, t_{i+1}^\ast] \rbrace$$ (Figure~\ref{figAlgorithm2-c}). 
			$R_{i}$ in a form of line segment is considered empty because we do not care about the border points.


			\item The task is solved in every stripe $R_{i}$ separately. For every nonempty $R_{i}$ denote $P_{i} \df R_{i} \cap P$ and $S_{i} \df R_{i} \cap S_{\varphi_1}$. Due to the way of construction of $R_{i}$, all polygons in $S_{i}$ and the single polygon $P_{i}$ have all their vertices on the upper ($t^\ast = t^\ast_{i+1}$) or the lower ($t^\ast = t^\ast_{i}$) border of the stripe $R_i$ (Figure~\ref{figAlgorithm3-a}). In fact, these polygons can take only the shape of a triangle or a trapezoid (Figure \ref{figStripe}).\\
			
\begin{figure}[h]
   \centering  
	\subfloat[][the stripe $R_4$]{\includegraphics[scale=0.4]{figures/alg7.png}
			\label{figAlgorithm3-a}}
    \subfloat[][points on the left side of the line $\overrightarrow{ul}$]{\includegraphics[scale=0.4]{figures/alg8.png}
			\label{figAlgorithm3-b}}
    \subfloat[][$A_4 = $ the rightmost polygon in $S'_{4}$]{\includegraphics[scale=0.4]{figures/alg9.png}
			\label{figAlgorithm3-c}}
      	\caption{The potential polygons are identified. (The solution cannot be placed further in time than the property $\varphi_2$. Moreover, the property $\varphi_1$ must continuously hold at all time points until $\varphi_2$ is satisfied.)}
	\label{figAlgorithm3}    
    
\end{figure}				
\enlargethispage*{5mm}			
Now we get rid of the polygons lying on the right side of $P_{i}$ because their points cannot be in the solution (they represent the time past the event $\varphi_2$). To do so, we isolate the upper and lower rightmost vertices of the polygon $P_{i}$. Denote them as $u = (u_t, u_{t^\ast})$ and $l = (l_t, l_{t^\ast})$ (Figure~\ref{figAlgorithm3-b}). We get a new area:

$$R'_{i} \df \lbrace (t, t^\ast) \in R_{i} \mid (t, t^\ast) \textnormal{ \small lies on the left side of the line } \overrightarrow{ul} \rbrace.$$

 The solution can lie only in this area, so we can restrict $S_{i}$ to $S'_{i} \df R'_{i} \cap S_{i}$. 
			
\begin{figure}[h]
	\begin{center}
    	\includegraphics[scale=0.35]{figures/stripe.png}
      	\caption{An example of a stripe and all possible shapes of polygons inside a stripe.}
      	\label{figStripe}
    \end{center}
\end{figure}
			
			
			\item All the adjoining polygons (sharing an edge) in $S'_{i}$ are connected to form maximal seamless convex polygons (e.g., the green and orange polygons in Figure~\ref{figAlgorithm3-b}).  
			
			\item Let $A_{i}$ be the rightmost polygon in $S'_{i}$ (Figure~\ref{figAlgorithm3-c}) (Even after connecting some polygons in $S'_{i}$ their shape can still be only triangular or trapezoidal (Figure \ref{figStripe}) so there is only one rightmost polygon in $S'_{i}$). Then $A'_{i} = A_{i} \cap (P_{i} \ominus (b, a))$ is the solution for the stripe $R_{i}$ (Figure~\ref{figAlgorithm4}).\\
The operation $\ominus$ is defined as $A \ominus (a, b) \df \lbrace (x, y) \in \mathbb{R} \times \mathbb{R} \mid \exists c \in (a, b): (x + c, y) \in A \rbrace$ which is equal to $A \oplus (-a, -b)$, where $\oplus$ is the Minkowski sum.
			
			\item The final satisfaction set is given by $S_{\varphi_1 \until{a}{b} \varphi_2} = \bigcup_{i=1}^{n-1} A'_{i}$.   
			
\begin{figure}[h]
   \centering  
	\subfloat[][$P_4$ before application of the operator $\ominus$]{\includegraphics[scale=0.4]{figures/alg10.png}
			\label{figAlgorithm4-a}}
    \subfloat[][the shifted polygon $P_4 \ominus (2.5, 2.5)$]{\includegraphics[scale=0.4]{figures/alg11.png}
			\label{figAlgorithm4-b}}
    \subfloat[][$A'_4 = A_4 \cap (P_4 \ominus (2.5, 2.5))$, the final solution in the stripe $R'_4$]{\includegraphics[scale=0.4]{figures/alg12.png}
			\label{figAlgorithm4-c}}
      	\caption{Last step is to consider the interval $[a, b]$ bounding the operator $\untilLTL$.}
	\label{figAlgorithm4}    
    
\end{figure}			
			
 \end{enumerate}

	\item The result $s \models \varphi$ which is equivalent to $(0, 0) \in S_\varphi$ is returned.

\end{enumerate}	


\begin{remark}

The satisfaction set for temporal operator future $\future{a}{b} \varphi \equiv \mathsf{true} \until{a}{b} \varphi$ (and hence $\globally{a}{b} \varphi$) can be computed more easily than according to the step \ref{step}. It can be obtained directly as $S_{\future{a}{b} \varphi} = S_{\varphi} \ominus (b, a)$.


\end{remark}



\subsection{Time and space complexity}
\enlargethispage{8mm}
Time and space complexity of all steps of the Algorithm \ref{algorithm1} is proportional to the number of polygons they are working with. Number of polygons generated in step 1 is at most $n^2$ for each atomic predicate, where $n$ is the number of intervals on which the signal is defined.

The number of polygons does not asymptotically change during the computation of operations described in other steps of the algorithm and all these functions do not work slower than $O(n^2)$ (see~\cite{GeometricAlgorithms} for more details). The output polygons also keep small number of vertices during the process.

The upper bound on the total computation time is therefore $O(kn^4)$, where $n$ is the number of intervals on which the signal is defined and $k$ is the size of the investigated formula.  

