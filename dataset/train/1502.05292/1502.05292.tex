\documentclass[a4paper,USenglish]{lipics}

\usepackage{microtype} 

\bibliographystyle{plain}\usepackage{tablefootnote}
\usepackage{algorithm}\usepackage{algpseudocode}

\newcommand{\var}[1]{\textrm{\texttt{#1}}}




\usepackage{color}
\usepackage{cleveref}
\usepackage{paralist} \usepackage{booktabs}


\newcommand{\bigoh}{\mathcal{O}}
\newcommand{\gabriele}[1]{\textcolor{red}{#1}}
\newcommand{\luigi}[1]{\textcolor{blue}{#1}}

\usepackage{thmtools, thm-restate}
\usepackage{xcolor}
\usepackage{tikz}
\usepackage[normalem]{ulem}







\newcommand{\nota}[1]{\marginnote{\textbf{#1}}}
\renewcommand{\qed}{\hfill }

\newcommand{\dft}{\textsc{DFT-Tree}}
\newcommand{\dfts}{\textsc{DFT-Trees}}





\title{Dynamic subtree queries revisited:\newline the Depth First Tour Tree}\titlerunning{Dynamic subtree queries revisited: the Depth First Tour Tree} 

\author[1]{Gabriele Farina}
\author[2]{Luigi Laura}
\affil[1]{Polytechnic University of Milan, Italy\\
\texttt{gabriele2.farina@mail.polimi.it}}
\affil[2]{``Sapienza'' Universiy of Rome, Italy\\
\texttt{laura@dis.uniroma1.it}}
\authorrunning{G. Farina and L. Laura} 




\Copyright{Gabriele Farina and Luigi Laura}

\subjclass{G.2.2 Graph Theory - Graph algorithms}\keywords{Graph Algorithms, Dynamic Tree, Betweenness Centrality}

\serieslogo{}\volumeinfo {Billy Editor and Bill Editors}{2}{Conference title on which this volume is based on}{1}{1}{1}\EventShortName{}
\DOI{10.4230/LIPIcs.xxx.yyy.p}

\newcommand{\runinsec}[1]{\noindent\textbf{\textsf{#1}}\quad}

\begin{document}
\maketitle

\begin{abstract}
\noindent In the \emph{dynamic tree problem} the goal is the maintenance of an arbitrary -vertex forest, where the trees are subject to joining and splitting by, respectively, adding and removing edges. Depending on the application, information can be associated to nodes or edges (or both), and queries might require to combine values in path or (sub)trees.

In this paper we present a novel data structure, called the \emph{Depth First Tour Tree}, based on a linearization of a DFS visit of the tree. Despite the simplicity of the approach, similar to the ET-Trees (based on a Euler Tour), our data structure is able to answer queries related to both paths and (sub)trees. In particular, focusing on subtree computations, we show how to customize the data structure in order to answer queries for three distinct applications: impact of the removal of an articulation point from a graph, betweenness centrality and closeness centrality of a dynamic tree. 
\end{abstract}











\section{Introduction}

In the \emph{dynamic tree problem} the goal is the maintenance of an arbitrary -vertex forest, where the trees are subject to joining and splitting by, respectively, adding and removing edges. Depending on the application, information can be associated to nodes or edges (or both), and queries might require to combine values in path or (sub)trees.

The dynamic tree problem has several applications, ranging from network flows~\cite{AMO93,GGT91,ST85,Tar97}, one of the original motivations, to other graph algorithms including connectivity~\cite{HK99}, biconnectivity~\cite{Fre83}, and minimum spanning trees~\cite{HK99,Fre85}, and other combinatorial problems~\cite{KMT03,Lan00}. 
With such a wealth of applications, it is not surprising the fact that there are several approaches to solve (at least partially) the dynamic tree problem using  time per operation: ST-trees~\cite{ST83,ST85}, ET-trees~\cite{HK99,Tar97}, topology trees~\cite{Fre85,Fre97a,Fre97b}, top trees~\cite{AHLT97,AHLT05,TW05}, RC-trees~\cite{ABV04,ABV05}, and Mergeable Trees~\cite{GKSTW11} that build up on the ST-tree and, as the name suggests, support also the \emph{merge} operation. All these approaches map a generic tree into a balanced one, and can be divided into three main categories: \emph{path decomposition} (ST-trees, Mergeable Trees), \emph{tree contraction} (topology trees, top trees, RC-trees), and \emph{linearization} (ET-trees);  refer to the dissertation of Werneck~\cite{Wer06} and the experimental comparison of Tarjan and Werneck~\cite{TW09} for a more complete picture about techniques and applications.
\3mm]
\runinsec{Contribution.}
We propose a novel data structure, combining the simplicity of the Euler Tour trees with the expressiveness of the Depth First visit of a tree. We believe that the contribution of our approach is twofold:
\begin{compactitem}
	\item the resulting data structure is simple, using only elementary concepts, and thus is easy to understand, analyze and implement;
	\item we give a \emph{unified framework} for treating a vast class of data aggregation tasks on subtrees.
\end{compactitem}
While our data structure is able to support basic operations on paths, it is primarily designed to aggregate data on subtrees, an operation which is usually non-trivial with other data structures.

Unlike ST-trees, topology trees and RC-trees, \dfts\ do not require the underlying forest to have vertices with bounded (constant) degree in order to efficiently cope with subtree queries. Degree restrictions can be avoided by \emph{ternarizing} the input forest but, as observed in \cite{Wer08}, ``this introduces a host of special cases'' and complicates the data structure. In the special case of ST-trees, some work has been done \cite{Radzik98implementationof} to support queries on subtrees {for a restricted set of operations} (for example, giving the minimum element of a given subtree) without the need for ternarization, but the resulting data structure is still very complicated, both to analyze and implement. The same task can be performed extremely easily with \dfts.

Furthermore, \dfts\ can naturally aggregate on all the children subtrees of a node  in parallel without having to pay a cost proportional to the degree of  itself: for example, as we will see, given a node  it takes , independently from the degree of , to answer the child of  whose subtree is the largest. This is an interesting feature that distinguishes our data structure, and can be useful for practical problems, as we will demonstrate in the final sections of this paper.

The extreme flexibility of use of the structure comes at the cost of its structural rigidity. In particular, while all other structural operations require logarithmic time in the forest size, the \textsc{evert} operation requires a cost proportional to the depth of the node being everted. However, when either the number of eversions is small compared to the total number of queries performed, or the costs of the eversion is amortized, the cost of \textsc{evert} can be regarded as being  like all the other structural operations. This is the case in all the applications we present.
\-4mm]
\textcolor{black!20!white}{\hrule}\vspace{4mm}
\includegraphics[width = 1\linewidth]{asy/fig3.pdf}
\caption{Effects of the \textsc{link}, \textsc{cut} and \textsc{condense} operations.\label{fig:linkcut}}
\end{figure}

Figure \ref{fig:dftvseuler} shows the depth first tour of an example tree of size 10, together with its linearization: an array that contains its parenthetical sequence; the Euler Tour of the same tree is shown for comparison: note that in an Euler Tour a node can appear several time; the size of an Euler Tour is , since an Euler Tour begins with a node and then, for each edge of the tree, both its endpoints are added exactly once, when entering the node. In Figure \ref{fig:linkcut} we can see the effects of the \textsc{link}, \textsc{cut} and \textsc{condense} operations on the tree and the corresponding parenthetical sequence.	

		\begin{definition}[depth of a parenthesis]
		We define the \emph{depth} of a parenthesis in a sequence of parentheses as the difference between the number of open parentheses and the number of closed parentheses in the prefix of the given sequence ending in that  parenthesis.
		\end{definition}
		The sequence of the depths of the parentheses coincides with the prefix sums of the sequence obtained by replacing every open parenthesis with a 1 and every closed parenthesis with a .
		
		\begin{definition}[summary of a sequence of parentheses]
		We define the \emph{summary} of a sequence of parentheses as the pair of integers , where  is the minimum between 0 and the minimum depth of the parentheses of the sequence, and  is equal to the difference between the depth of the last parenthesis and .
		\end{definition}
In the following, we  refer to the first value of the summary as to the \emph{down}-value, and to the second as to the \emph{up}-value. Note that the down-value of a summary is always non-positive, while the up-value is always non-negative. In Figure~\ref{fig:basic summary} we show a graphical representation of the depth of the parentheses in the sequence: for example, the summary of the whole sequence is the pair , whilst the summary of the first four parentheses is .
		\begin{figure}[t]\centering 
			\includegraphics[width = 0.7\linewidth]{asy/fig4.pdf}\\
			\caption{Depth of a sequence of parentheses. In this case, the summary of the sequence is the pair . The summary of the first four parentheses is .\label{fig:basic summary}}


		\end{figure}
		It should be clear that the summary of the sequence made of just one open parenthesis is , while the summary of the sequence made of just one closed parenthesis is .
		
		The following lemmas hold for any sequence of parentheses:


\begin{restatable}{lemma}{monotonicity}
\label{lem:monotonicity}
	The down-values of the prefixes, taken in order, of any sequence of parentheses form a monotonically decreasing sequence of integers.
\end{restatable}
		
\begin{restatable}{lemma}{balancedseq}
			\label{lem:balancedseq}
			A sequence of parentheses is balanced if, and only if, its summary is equal to . Any prefix of a balanced parenthetical sequence has down-value 0.
\end{restatable}

\begin{restatable}{lemma}{sumofsummaries}
\label{lem:sumofsummaries}
			Let  be two sequences of parenthesis having summary  and  respectively. The summary of the sequence  obtained by concatenating  and  is the pair , where the sum between summaries is defined as:
			
\end{restatable}


		
\begin{restatable}{lemma}{summarysumassociativity}
			\label{lem:summarysumassociativity}
			The sum of two summaries defined above is an associative operation.
\end{restatable}
		
		As a consequence of Lemma~\ref{lem:summarysumassociativity},  as we mentioned before, we can store in each vertex of the BBST the sum of the summaries of all the vertices in its subtree. We proceed with the following lemma:
\begin{restatable}{lemma}{lemfather}
		\label{lem:lemfather}
		Let \emph{\var{close-v}} be the close-node associated with the non-root node . The close-node associated with the parent of  is the first (leftmost) node \emph{\var{u}} after \emph{\var{close-v}} reaching depth  relative to \emph{\var{close-v}}.
\end{restatable}
Lemma~\ref{lem:lemfather}, together with the associativity of  and the monotonicity of the down values of the prefixes of any (sub)sequence of parentheses (Lemma~\ref{lem:monotonicity}), gives us an efficient way to locate the parent of any non-root node: we simply binary search the smallest prefix having a negative down-value, inside the suffix of the parenthetical sequence starting after \var{close-v}. Refer to figure~\ref{fig:father} for a visual insight. Similar properties hold for lca and ancestor: for example, for the -th ancestor we can (binary) search the first node reaching relative depth  with respect to \var{close-v}, after \var{close-v}.
\begin{figure}[t]
\centering\includegraphics[width = .85\linewidth]{asy/fig5.pdf}
\caption{Characterization of the parent of node , as stated in Lemma~\ref{lem:lemfather}. The values under the small dots represent the down-values of the prefixes.\label{fig:father}}
\end{figure}
		
\section{Subtree (and path) operations}
\label{sec:operations}

In this section we detail the subtree and path operations. As we mentioned before, we assume that each node  has an associated value (note that values can be generic objects, not only numbers), denoted by \textrm{val}. We have the following three generic operations on a node that operate, respectively, on its children, on its subtree, and on the path from the node to the root:
		\begin{compactitem}
			\item \textsc{reduce-children}: Computes the value of 
			
			where  are the children of node , and  is an associative operation (not necessarily invertible).
			\item \textsc{reduce-child-subtrees}: Computes the value of 
			where  are the children of node ,  and  are associative operations (not necessarily invertible), and  is some information about the subtree rooted at  and containing nodes .
			\item \textsc{combine}: Computes the value of
			
			where  are the nodes in the path from  to the root of the tree, and  is an associative and invertible operation.
		\end{compactitem}
Differently from all other arguments, the operations denoted with ,  and  used in the three operations above have to be known in advance, so that the \dft\ knows what partial evaluations it should memoize in the nodes.

Among the three operations, \textsc{combine} is the most straightforward, implementation-wise. The idea is to assign a value to both the open-nodes and close-nodes of the \dft: we assign the value of the vertex  to the open-node of , and the opposite value , i.e. the inverse of  with respect to operation , to the corresponding close-node. We can thus state the following lemma, depicted in Figure~\ref{fig:combine} for the case  is the traditional sum operator '':

			\begin{restatable}{lemma}{combinelemma}
				\label{lem:combine}
Let \emph{\var{open-v}} be the open node associated with the tree node . The value of 
				is equal to the -combination of the values of the nodes in the prefix of the \dft ending in \emph{\var{open-v}}.
			\end{restatable}


\begin{figure}[t]
\centering\includegraphics[width =\linewidth]{asy/fig8.pdf}
\caption{Visual insight for Lemma~\ref{lem:combine}. The numbers written in the nodes of the tree on the left represent the values assigned to the vertices.\label{fig:combine}}
\end{figure}
		

In order to implement \textsc{reduce-children} and \textsc{reduce-child-subtree}, we need to extend the summary of a sequence of parentheses. 

Let us note that it is possible to uniquely decompose any sequence of parentheses in three contiguous (possibly empty) pieces, namely a \emph{prefix}, a \emph{body} and a \emph{suffix}. If the down-value of the sequence is (strictly) negative, then the prefix ends in leftmost minimal-depth parenthesis of the sequence, and the body ends in the rightmost minimal-depth parenthesis. If, on the contrary, the down-value of the sequence is 0, we can distinguish two separate cases: if the up-value is 0, then both the prefix and the suffix are empty, and the body coincides with the whole sequence; else, both the prefix and the body are empty, and the suffix coincides with the whole sequence.
In any case, notice that the body of a sequence is a balanced subsequence, made of zero or more \emph{subtrees}. As an example, consider these five sequences:
\begin{compactitem}
\item \texttt{)()(()}: the prefix is \texttt{)}, the body is \texttt{()} and the suffix is \texttt{(()}
\item \texttt{)())}: the prefix is \texttt{)())}, both body and suffix are empty
\item \texttt{))(}: the prefix is \texttt{))}, the body is empty and the suffix is \texttt{(}
\item \texttt{(()}: both the prefix and the body are empty, and the suffix is \texttt{(()}
\item \texttt{(()())}: both the prefix and the suffix are empty, while the body is \texttt{(()())}
\end{compactitem}
 We use this property, i.e. the unique decomposition of a sequence of parentheses, in the two summaries, used respectively by \textsc{reduce-children} and \textsc{reduce-child-subtree} to incrementally aggregate information about subtrees. Below we report the simpler one, used in \textsc{reduce-children}:
			\begin{definition}[rc-summary]
				An \emph{rc-summary} of a sequence of parentheses is a tuple having these fields:
				\begin{compactitem}
					\item {\var{prefix-depth}}, the depth of the minimal-depth parenthesis
					\item {\var{body-combination}}, the -combination of the values of the nodes associated with the subtrees of the body of the sequence.
					\item {\var{suffix-depth}}, the difference between the depth of the last parenthesis and the depth of any minimal-depth parenthesis.
					\item {\var{suffix-info}}, the value associated with the first node of the suffix, if any.
				\end{compactitem}
			\end{definition}


The similar \emph{rcs-summary}, used in \textsc{reduce-child-subtree}, is reported in the Appendix. These two summaries, to be stored as usual in the nodes of the underlying BBST, and the three generic functions above can be used to implement several functions, and below we report few examples.
\4mm]
\noindent\textbf{\textsf{Functions implemented using}} \textsc{reduce-child-subtrees}\textbf{.}\quad
In the case of \textsc{reduce-child-subtrees} we can implement:
		\begin{compactitem}
			\item \textsc{subtree-sum}: Finds the sum of the values of the nodes in the subtree of node , and is equivalent to .
			\item \textsc{subtree-size}: Finds how many nodes are there in the subtree of node , and is equivalent to \textsc{subtree-sum} when  for every node  of the forest.
		 	\item \textsc{subtree-max}: Finds the maximal value among those of the nodes in the subtree of node , and is equivalent to .
			\item \textsc{maxsum-child}: Finds the maximal value of \textsc{subtree-sum} among the children of node . This is equivalent to . 	
		\end{compactitem}
\vspace{4mm}
\noindent\textbf{\textsf{Functions implemented using}} \textsc{combine}\textbf{.}\quad 		
		A simple example of \textsc{combine} is \textsc{depth}, which finds the depth of node , i.e. the distance from  to the root of the tree  belongs to. Indeed, this is equivalent to \textsc{combine}, assuming  for every node  of the forest. We can implement \textsc{distance}, i.e. the distance in the tree between  and , by computing .


If we want to compute the distances in a weighted tree (i.e., we have weights on the edges), the same idea holds; since we store the information in the nodes, we store the weight of an edge connecting a child node to the parent node inside the child node. 

\section{Applications}
\label{sec:applications}
In this section we show, in order to provide a few examples, how to use \dfts\ to solve several problems that can be modeled as subtree problems. In particular, in all the applications that we describe we will refer to a common scenario: we ask queries about a single node , and the queries can be answered by looking at the subtrees of , i.e. the subtrees rooted in the children of , together with the part of the tree that is above , that we will denote by : this is the part of the tree that we reach through the parent of . We will describe the applications in increasing order of complexity, from the perspective of the \dfts: indeed, as we will see, to compute the \emph{impact} of an articulation point  we need to compute the size of the subtrees of , and of ; for the \emph{betweenness centrality} we also need to evaluate the sum of the squared sizes of the subtrees of , and, finally, for the \emph{closeness centrality} we need the the sum of all the distances from  to every node, both in its subtree and above it. 


\subsection{Biconnectivity properties and impact of articulation points}

\begin{figure}[t]
	\centering \raisebox{0.6cm}{ \includegraphics[scale=.54]{asy/fig_artic_points_colored.pdf}}\hfill 	\includegraphics[scale=.60]{asy/fig_block_forest.pdf}
			\caption{A graph (left) and its Block Forest~\cite{WT92} (right).\label{fig:BF}}
\end{figure}

The \dft\ can be used to maintain all the (bi)connectivity properties of a streaming graph, following the same approach proposed by Westbrook and Tarjan~\cite{WT92}: as we mentioned before, it is sufficient to observe that the \dft\ supports all the operations needed by the algorithm of Westbrook and Tarjan~ to maintain the Block Forest (shown in Figure~\ref{fig:BF}), including \textsc{condense} that, as we mentioned before,  is not a standard operation in the case of the \emph{dynamic tree} problem. Indeed, it is possible to maintain connected and biconnected components, and bridges and articulation points of a streaming graph. 

We now show how to answer queries on the \emph{impact} of an articulation point. We recall, from~\cite{AFL12trac}, that the impact of an articulation point  is the number of nodes that get disconnected from the main connected component when  is removed from the graph. Looking at the the Block Forest, Figure~\ref{fig:BF} (right), it is easy to see that the articulation points are exactly the square nodes that connect two or more round nodes (the biconnected components). When an articulation point is removed, its Block Tree splits into pieces: in order to compute the impact, we need to know the size of each of them: the impact is, by definition, the sum of all the size of the trees except the largest one (the main connected component). If we refer the subtree operations seen in the previous section, we can use the \dft\ in the following way:
\begin{compactitem}
\item The value in each round node in the tree is 0 (they corresponds to biconnected components), and 1 in each square node (corresponding to real nodes in the graph).
\item The size of the Block Tree can be computed by finding the root of the tree, using \textsc{root} and then computing its \textsc{subtree-size}.
\item The size of the maximum subtree of  can be computed using \textsc{maxsum-child}.
\end{compactitem}
It is easy to see that, with the operations described above, we can compute the impact of a node, and thus we can state the following result.

\begin{restatable}{lemma}{lemimpact}
Using a \dft, it is possible to answer \emph{impact} queries of a vertex in time .
\end{restatable}

\subsection{Betweenness centrality}

The betweenness centrality definition involves shortest paths, but, since in  a tree there is exactly one path between each pair of nodes, the goal here is, given a vertex , to count all the paths that pass through it. We can do this using \dfts\ in the following way. Let us assume that vertex  has  children, each of them with a corresponding subtree (eventually made by one node only, i.e. the child is a leaf). Let us denote with  the subtrees of . The number of (shortest) paths through  can be partitioned into two  components: i) the paths between the subtrees of  and the rest of the tree, i.e. , and ii) the paths between all the possible pairs of subtrees of . The first component can be computed easily, using the fact that  . The second component is the sum of the products of all the possible pairs of sizes, i.e., ; its computation is more tricky, if we want to avoid the iteration for every subtree. The idea is the following: 
\begin{compactitem}
				\item The value of each node in the tree is the pair .
				\item We define  to be .
				\item We have, as an invariant, that the values computed by   are a couple made by a number and its square, e.g., . Note that this defines an associative operation.
				\item We define  to be  (i.e., the usual vector sum). 
			\end{compactitem}
Now, if we call \textsc{reduce-child-subtrees} we obtain, for , the couple made by the sum of the sizes of its subtrees, and by the sum of the squares of the sizes of its subtrees: . It is easy to see, using the rule of the square of a sum, that the needed second component can be obtained by the couple of values. This allow us to state the following Lemma.
\begin{restatable}{lemma}{bc}
Using a \dft, it is possible to answer \emph{betweenness centrality} queries of a vertex  in time .
\end{restatable}



\subsection{Closeness centrality}
\label{sub:cc}
The closeness centrality~\cite{Bav50} of a vertex is defined as the reciprocal of its \emph{farness}, the sum of the distances to all the other vertices. We now show how to maintain the farness of each vertex, using the \dfts. The main ingredients are:
\begin{compactitem}
\item We modify the \dfts\ in order to support the two following operations: \textsc{add-to-path} that adds  to all the vertices in the path between  and the root, and \textsc{add-to-subtree} that adds  to all the vertices in the subtree of . Note that we can implement both these operations in  per update and value query, without affecting the complexity of the structural operations.
\item each vertex stores two values, \textsc{up-dists} that is the sum of the distances to the vertices in , and \textsc{down-dists} that is the sum of the distances to the vertices in its subtree. Note that the farness of a vertex is the sum of this two values. 
\end{compactitem}
Now, just to provide an example: assume that we are doing a \textsc{link} operation, adding the edge between  and , whose weight is . Let us denote the size of the tree  (resp. ) belongs to with  (resp. ). The following operations need to be executed before the actual linking to maintain the information:
\begin{compactitem}
\item the \textsc{down-dists} of all the nodes in the path of  are increased by ;
\item the \textsc{up-dists} of all the nodes in the subtree of  (included) are increased by ;
\item the \textsc{up-dists} of all the nodes in the tree containing , with the only exception of the nodes in the path of , are increased by . In order to do so, we add it to all the nodes (i.e. the subtree of \textsc{root}), and then we subtract it from all the nodes in the path of . 
\end{compactitem}

The other structural update operations are similar, and can be derived in a similar fashion (we report them in the Appendix). This allow us to state the following Lemma.
\begin{restatable}{lemma}{bc}
Using a \dft, it is possible to answer \emph{closeness centrality} queries of a vertex in time .
\end{restatable}


\section{Conclusion and future works}
\label{sec:conclusion}


In this paper we presented a novel data structure, the \emph{Depth First Tour Tree}. This structure is based on a linearization of a DFS visit of the tree, similarly to the ET-Trees (based on a Euler Tour). 

The structure is simple and easy to implement; it provides a framework for a large class of data aggregation tasks -- especially on subtrees, a task that is usually non-trivial with other data structures. 
Furthermore, \dfts\ can naturally aggregate on all the children subtrees of a node  in parallel without having to pay a cost proportional to the degree of  itself: as we already mentioned, given a node  it takes , independently from the degree of , to answer the child of  whose subtree is the largest.

This flexibility, related to subtree queries, is paid by the \textsc{evert} operation, that requires a cost proportional to the depth of the node being everted. However, as discussed, when either the number of eversions is small compared to the total number of queries performed, or the costs of the eversion is amortized, the cost of \textsc{evert} can be regarded as being  like all the other structural operations. 

We showed that this is the case in all the applications presented in the previous section. We described how to customize the data structure in order to answer queries for three different applications: impact of the removal of an articulation point from a graph, betweenness centrality and closeness centrality of a dynamic tree. 

In the future, we plan to experimentally assess the performance of our data structure, and compare it with the existing alternatives, following the approach of \cite{TW09}. We believe that the simplicity of our approach, when compared e.g. to the work of \cite{Radzik98implementationof} in the context of the \textsc{subtree-max} operation, is likely to deliver faster and more readable code in practice.


		
\vfill 
\pagebreak








\bibliography{dynamic-tree}



\vfill 
\pagebreak
\appendix









\section{Implementation of \dfts\ using Splay Trees}
\label{app:implementation}

In this appendix we detail the pseudo-code for all the supported operations in a \dft, using the Splay Trees~\cite{ST85}, that are used by Tarjan and  and Tarjan~\cite{TW09} to implement both the ST-trees~\cite{ST83,ST85}, ET-trees~\cite{HK99,Tar97}.

The \dft\ is thus stored as an augmented splay tree, where the comparison  between two entries  and  of the depth first tour evaluates to \textsc{true} iff entry  comes before entry  in normal left-to-right order.

Since the focus of the paper has been devoted to subtree computations, we note here that in \Cref{sub:combine} we show an example of how to use \textsc{combine} to compute a path operation.


\subsection{Basic splay operations}


		We will take for granted the implementation of these basic operations on the splay tree, besides the  tree rotations, \textsc{splay}, \textsc{splay-erase}, \textsc{splay-min} / \textsc{splay-max} and \textsc{splay-predecessor} / \textsc{splay-successor}:
		\begin{description}
			\item[\textsc{splay-root}:] Returns the root node of the splay tree containing node .
			
			\item[\textsc{splay-lca}:] Returns the lowest common ancestor of the splay nodes  and . Of course,  and  must belong to the same splay tree (i.e. \textsc{splay-root} = \textsc{splay-root}).
			
			\item[\textsc{splay-merge}:] Joins the splay tree  containing node  with the splay tree  containing node . If  and  belong to the same tree, nothing happens. If  and  belong to different tree, the keys contained in  are considered to precede all the keys in .
			
			\item[\textsc{splay-split}:] Splits the splay tree  containing  into two different splay trees: the first contains all the keys which are , and the second contains all the keys which are .
			
			\item[\textsc{splay-precedes}]: Returns \textsc{true} if , \textsc{false} otherwise.
		\end{description}
		Operation \textsc{splay-root} can be implemented by simply moving from a node to its parent until we eventually reach the root of the splay tree. This method clearly results in amortized logarithmic complexity with respect to the tree size.
		
		\textsc{splay-lca} can be implemented by marking all the nodes in the path from  to the root, and then moving up the tree starting from , stopping at the first marked node found on this path, which corresponds to the sought ancestor.
		
Also, it is possible   (see \cite{GKSTW11})  to support \textsc{splay-merge} and \textsc{splay-split} in logarithmic time in the size of the trees involved.
		
		Implementation for \textsc{precedes} is given in \Cref{algo:precedes}.
		\begin{algorithm}[H]
		  \small
		  \caption{\small Implementation of \textsc{splay-precedes}}
		  \label{algo:precedes}
		  \begin{algorithmic}[1]
		    \Procedure{splay-precedes}{}\Comment{ and  are dft nodes.}
		    \State \var{successor}  \textsc{splay-successor}
			\State \textsc{splay-split}
			\State \var{answer}  (\textsc{spay-root}() == \textsc{splay-root}())
			\If{\var{successor}  \textsc{null}}\Comment{Restore tree.}
				\State \textsc{splay-merge}(, \var{successor})
			\EndIf
			\State \textbf{return} \var{answer}
		    \EndProcedure
		  \end{algorithmic}
		\end{algorithm}
		
		We will assume that every splay node contains a pointer to its \emph{twin}, i.e. to the other dft node associated to the same tree node.
		
In general, we will maintain a collection of disjoint splay trees, where in turn a splay tree can maintain the depth first tours of one or more (disjoint) trees. When a splay tree contains only one dft, we say that the dft has a \emph{dedicated} splay tree. We provide an internal operation, \textsc{splice}, which makes sure that the dft of the tree containing  gets a dedicated splay tree. Notice that \textsc{splice} alters the internal splay tree representation, without affecting the represented tree. Assuming that we already have implemented operation \textsc{root}, implementing \textsc{splice} in logarithmic time is rather straightforward and is done in \Cref{algo:splice}.
		\begin{algorithm}[H]
		  \small
		  \caption{\small Implementation of \textsc{splice}}
		  \label{algo:splice}
		  \begin{algorithmic}[1]
		    \Procedure{splice}{}
		    \State \var{open-root}  open-node of \textsc{root}
		    \State \var{close-root}  close-node of \textsc{root}
		    \State \var{predecessor}  \textsc{splay-predecessor}
		    \If{\var{predecessor}  \textsc{null}}
		    	\State \textsc{splay-split}(\var{predecessor})
		    \EndIf
			\State \textsc{splay-split}(\var{close-root})
		    \EndProcedure
		  \end{algorithmic}
		\end{algorithm}
		
		

	
	
		
\subsection{Import/export operations}
		

Building the \dft\ of a given tree, encoded in the adjacency list format, is a very simple task, and can be seen as an easy modification of the classical dfs algorithm.
		
		The opposite task, i.e., restoring the original tree given its depth first tour, is also very simple. Indeed, it is enough to keep track of the current open node using a stack, while we process every node in the given \dft: see~\Cref{alg:conversion}.
		\begin{algorithm}[H]
		  \small
		  \caption{\small Depth first tour to tree conversion\label{alg:conversion}}
		  \begin{algorithmic}[1]
		    \Procedure{dft-to-tree}{\var{DFT}}\Comment{\var{DFT} is a list here}
		    \State \var{s}  empty stack
		    \ForAll{(\var{node}, \var{tag}) \textbf{in} \var{DFT} \textbf{in order},}
		      \If{\var{tag} is an \emph{open-tag}}
			    \If{\var{s}.empty()}
	              \State mark \var{node} as the root of the tree
			    \Else
			      \State add \var{node} to the children of \var{s}.top().
			    \EndIf
			    \State \var{s}.push(\var{node})
		      \Else
		        \State \var{s}.pop()
		      \EndIf
		    \EndFor
		    \EndProcedure
		  \end{algorithmic}
		\end{algorithm}


		To perform \textsc{import-tree} we first construct the depth first tour of the input tree, and then build a splay tree corresponding to it. Since the order of the nodes in the depth first tour coincides with the order maintained by the underlying splay tree, we can perform a linear time tree construction as described in [...]. To correctly maintain the extra information stored in the nodes of the splay tree, we can propagate them from the leaves up to the root, combining them using the \textsc{recalc-extra-info} function, leading to an overhead which is linear in the size of tree, hence not affecting the total complexity of the operation.
		
		Operation \textsc{export-tree} performs an in-order traversal of the (spliced) splay tree, extracting a list version of the depth first tour it represents, and then runs \textsc{dft-to-tree} on it. Since both operations have linear complexity in the tree size, we can support \textsc{export-tree} in linear time.
		
		\subsection{Structural updates}
		
In this section we describe the implementation of the structural update operations on a \dft. In particular, the most important operations are the \textsc{link} and \textsc{cut}, whose effect on the parenthetical sequence is shown in \Cref{fig:linkcut}.

Suppose an edge is created between the root  of tree  and node  of tree . From the point of view of depth first tours, what happens is that the dft of  is inserted into the dft of  right after the open-node corresponding to . See \Cref{alg:link} below.

		\begin{algorithm}[H]
		  \small
		  \caption{\small Implementation of \textsc{link} \label{alg:link}}
		  \begin{algorithmic}[1]
		    \Procedure{link}{}
		    \If{\textbf{not} \textsc{same-tree}()}
			    \State \var{open-u}  open-node of node  in the dft
			   	\State \var{close-u}  close-node of node  in the dft
			   	\State \var{open-v}  open-node of node  in the dft
		    	\State \textsc{splay-split}(\var{open-u})
		    	\State \textsc{splay-merge}(\var{open-u}, \var{open-v})
		    	\State \textsc{splay-merge}(\var{open-u}, \var{close-u})
		    \EndIf
		    \EndProcedure
		  \end{algorithmic}
		\end{algorithm}	
		
		Operation \textsc{cut} is analogous and has the effect of extracting the sub-segment of the dft corresponding to the subtree rooted in , as illustrated in \Cref{fig:linkcut}. Its implementation is symmetric to the one of \textsc{link}:
		\begin{algorithm}[H]
		  \small
		  \caption{\small Implementation of \textsc{cut}}
		  \begin{algorithmic}[1]
		    \Procedure{cut}{}
		    \State \var{root}  \textsc{root}()
		    \If{  \var{root}}
				\State \var{open-v}  open-node of node  in the dft
				\State \var{close-v}  close-node of node  in the dft
				\State \var{open-root}  open-node of \var{root} in the dft
				\State \var{close-root}  close-node of \var{root} in the dft

				\State \textsc{splay-split}(\textsc{splay-predecessor}(\var{open-v}))
				\State \textsc{splay-split}(\var{close-v})
				\State \textsc{splay-merge}(\var{open-root}, \var{close-root})
		    \EndIf
		    \EndProcedure
		  \end{algorithmic}
		\end{algorithm}	
		Note that the call to \textsc{predecessor} in line 8 is licit: since  is not the root of the tree, \var{open-v} cannot be the first node in the dft.
		
		The effect of operation \textsc{condense}() on the dft of the tree is explored in \Cref{fig:condense}, and corresponds to the deletion of the open- and close-node associated with  in the dft.
\begin{figure}[t]\centering 
	\includegraphics[width = \linewidth]{asy/fig3.pdf}
			\caption{Effects of the \textsc{condense} operation on the dft.\label{fig:condense}}
		\end{figure}
		\begin{algorithm}[H]
		  \small
		  \caption{\small Implementation of \textsc{condense}}
		  \begin{algorithmic}[1]
		    \Procedure{condense}{}
			\State \var{open-v}  open-node of node  in the dft
			\State \var{close-v}  close-node of node  in the dft
			\State \textsc{splay-erase}(\var{open-v})
			\State \textsc{splay-erase}(\var{close-v})
		    \EndProcedure
		  \end{algorithmic}
		\end{algorithm}

		Operation  is equivalent to a call to  followed by a call .
		\begin{algorithm}[H]
		  \small
		  \caption{\small Implementation of \textsc{erase}}
		  \begin{algorithmic}[1]
		    \Procedure{erase}{}
			\State \textsc{cut}()
			\State \textsc{condense}()
		    \EndProcedure
		  \end{algorithmic}
		\end{algorithm}		 
		
Notice that both \textsc{erase} and \textsc{condense} may lead to dft having non-dedicated splay trees.
		
		Operation \textsc{evert} can be implemented in two different ways. The first one makes a call to \textsc{export-tree}, operates an  evert operation on the adjacency list version of the tree and finally rebuilds the splay version using \textsc{import-tree}, for a total of  operations on a tree of size . The second way of performing the eversion consists in the following recursive algorithm, whose complexity is , where  is the depth of node :
		\begin{algorithm}[H]
		  \small
		  \caption{\small Implementation of \textsc{evert}}
		  \begin{algorithmic}[1]
		    \Procedure{evert}{}
		    \State \var{root}  \textsc{root}()
			\If{}
				\State \var{parent}  \textsc{parent}()
				\State \textsc{cut}()
				\State \textsc{evert}(\var{parent})
				\State \textsc{link}(, \var{parent})
			\EndIf
		    \EndProcedure
		  \end{algorithmic}
		\end{algorithm}		
		
		\subsection{Non-structural operations}
		Operation \textsc{same-tree} is straightforward and corresponds to checking whether  or not.
		
		To implement \textsc{is-descendant} we first make the following observation:
		\begin{lemma}
			\item Let  and  be two nodes, having open-nodes {\var{open-u}}, \emph{\var{open-v}} and close-nodes \emph{\var{close-u}}, \emph{\var{close-v}} respectively. Node  is a descendant of node  if and only if  and .
		\end{lemma}
		Using the previous observation, implementing \textsc{is-descendant} becomes a straightforward task, shown in \Cref{algo:is descendant}.
		\begin{algorithm}[H]
		  \small
		  \caption{\small Implementation of \textsc{is-descendant}}
		  \label{algo:is descendant}
		  \begin{algorithmic}[1]
		    \Procedure{is-descendant}{}
			    \State \var{open-u}  open-node of node  in the dft
			    \State \var{close-u}  close-node of node  in the dft
			    \State \var{open-v}  open-node of node  in the dft
			    \State \var{close-v}  close-node of node  in the dft
			    \State \textbf{return} \textsc{splay-precedes}(\var{open-v}, \var{open-u})  \textsc{splay-precedes}(\var{close-u}, \var{close-v})
		    \EndProcedure
		  \end{algorithmic}
		\end{algorithm}
		
		Operation \textsc{list-children} repeatedly uses operation \textsc{splay-successor} to traverse consecutive siblings, shown in \Cref{algo:list children}.
		
		\begin{algorithm}[H]
		  \small
		  \caption{\small Implementation of \textsc{list-children}}
		  \label{algo:list children}
		  \begin{algorithmic}[1]
		    \Procedure{list-children}{}
			    \State \var{open-v}  open-node of node  in the dft
				\State \var{close-v}  close-node of node  in the dft
			    \State \var{current}  \textsc{splay-successor}(\var{open-v})
			    \State \var{children}  empty list
			    \While{\var{current}  \var{close-v}}
			    	\State \var{children}.push(tree node associated to \var{current})
			    	\State \var{current}  \textsc{splay-successor}(\var{current.twin})
			    \EndWhile
			    \State \textbf{return} \var{children}
		    \EndProcedure
		  \end{algorithmic}
		  Note: we recall that the twin of a dft node  is the (pointer to) the other dft node  associated to the same tree node as . In this case, line 8 finds the next sibling of the tree node associate with \var{current}.
		\end{algorithm}	
		\vspace{2mm}
		
		Operation \textsc{parent}, briefly described in \Cref{sec:dft} is the first non-trivial operation, as we begin to exploit the parenthetical sequence of dft and to work on the augmented splay tree nodes. As such, we first need to set some definitions about sequences of parentheses. \begin{lemma}
			The suffix of the dft of the whole tree starting after \var{close-v} begins with the concatenation of the dft of zero or more siblings of node , followed by the close-node of the parent of . 
		\end{lemma}
		
		We provide a visual insight in \Cref{fig:close father}.
		
		\begin{figure}[t]

\centering
			\includegraphics[width = .9\linewidth]{asy/fig5.pdf}\\
			\caption{Characterization of the close-node of the parent of . The small numbers under the dots represent the summary down-values.\label{fig:close father}}
		\end{figure}
		
		Given the monotonicity of the summary down-values noted above, we can devise a binary search algorithm for finding the parent of any non-root node, shown in \Cref{algo:father}.

			\begin{algorithm}[H]
			  \small
			  \caption{\small Implementation of \textsc{parent}}
			  \label{algo:father}
			  \begin{algorithmic}[1]
			  	\Procedure{recursive-parent}{\var{splay-node}, \var{summary}}\Comment{pre: the down-value of summary is 0}
			  		\If{\var{splay-node.left-child}  \textsc{null}}
			  			\If {(\var{summary}  \var{splay-node.left-child.range-summary}).\var{down-value} }
			  				\State \textbf{return} \textsc{recursive-parent}(\var{splay-node.left-child}, \var{summary})
			  			\Else
			  				\State \var{summary}  \var{summary}  \var{splay-node.left-child.range-summary}
			  			\EndIf
			  		\EndIf
			  		\If{(\var{summary}  \var{splay-node.node-summary}).\var{down-value} }
			  			\State \textbf{return} \var{splay-node}
			  		\Else
			  			\State \var{summary}  \var{summary}  \var{splay-node.node-summary}
			  		\EndIf
			  		\State \textbf{return} \textsc{recursive-parent}(\var{splay-node.right-child}, \var{summary})
			  	\EndProcedure
				\State
			    \Procedure{parent}{}
			    \State \var{root}  \textsc{root}()
				\If{}
					\State \var{close-v}  close-node of 
					\State \var{successor}  \textsc{splay-successor}(\var{close-v})
					\State \textsc{splay-split}(\var{close-v})
					\State \var{close-parent}  \textsc{recursive-parent}(\textsc{splay-root}(\var{successor}), )
					\State \textsc{splay-merge}(\var{close-v}, \var{successor})
					\State \textbf{return} the tree node having \var{close-parent} as close-node
				\Else
					\State \textbf{return} \textsc{null}
				\EndIf
			    \EndProcedure
			  \end{algorithmic}
			\end{algorithm}	

			
			Operation \textsc{lca} can be supported in a similar fashion, since the following result holds:
			\begin{lemma}[characterization of the lca]
				\label{prop:characterization of lca}
				Let  be distinct nodes belonging to the same tree, for which none is a descendant of the other, and let \emph{\var{close-u}} and \emph{\var{close-v}} be their close-nodes in the dft. Suppose further, without loss of generality, that . Consider the subsequence of the parenthetical sequence of , starting in \emph{\var{close-u}} and ending in \emph{\var{close-v}}, and let  be the leftmost dft-node having minimal depth. The lowest common ancestor of  and  is the parent  of the tree node corresponding to . More specifically,  is child of  closest to node , i.e. the second-to-last node in the path from  to .
			\end{lemma}
			
			See \Cref{fig:lca} for a visual insight. To quickly determine  we augment the concept of summary, so that it keeps track of some parenthesis reaching minimal depth. More formally, we consider the following definition:
			\begin{definition}\hspace{0mm}\emph{\textbf{(lca-summary of a sequence of parenthesis)}}
				The \emph{lca-summary} of a sequence of parentheses is an ordered pair , where  is the summary of the given sequence and  is a (pointer) reference to the leftmost parenthesis having depth equal to the down-value of . If no such parenthesis exists,  is set to \textsc{null}.
			\end{definition}
			
			It is easy to adapt the addition operator between summaries to lca-summaries, so that we can easily evaluate the lca-summary of the concatenation of two sequences, as can be seen in \Cref{prop:sum of lca-summaries}.

			\begin{figure}[t]

				\includegraphics[width = \linewidth]{asy/fig6.pdf}\\
				\caption{Characterization of the lca of nodes  and . The lca is the parent of , the node associated with any parenthesis having minimal depth.\label{fig:lca}}

			\end{figure}

			\begin{lemma}
				\label{prop:sum of lca-summaries}
				Let  be two sequences of parenthesis having lca-summary  and  respectively. The summary of the sequence  obtained by concatenating  and  is the pair , where the sum between lca-summaries is defined as:
				
			\end{lemma}
			\begin{lemma}
				\label{prop:pointer to null}
				Let  be the lca-summary of a sequence of parentheses. Pointer  points to \textsc{null} if and only if all the depths of the parentheses are (strictly) positive.
			\end{lemma}
			\begin{lemma}
				\label{prop:lca-summary sum associativity}
				The sum of two lca-summaries defined above is an associative operation.
			\end{lemma}
			
			Note that by Proposition~\ref{prop:pointer to null} it follows that the lca-summary associated with the range indicated in \Cref{prop:characterization of lca} has a non-\textsc{null} reference, since the first parenthesis of the range is a closed-parenthesis.
			
			As before, we augment the nodes of the splay tree so that every node keeps the extra values
			\begin{compactitem}
				\item \var{node-lca-summary}, corresponding to the lca-summary of the node in question;
				\item \var{range-lca-summary}, the lca-summary of the subsequence associated with the splay subtree rooted in the node in question.
			\end{compactitem}
			
			We sketch the algorithm for determining the lca of two nodes in \Cref{algo:lca}.
			\begin{algorithm}[H]
			  \small
			  \caption{\small Implementation of \textsc{lca}}
			  \label{algo:lca}
			  \begin{algorithmic}[1]
			    \Procedure{lca}{}
				    \If{\textsc{is-descendant}}
				    	\State \textbf{return} 
				    \State\hspace{-\algorithmicindent}\textbf{elseif} \textsc{is-descendant} \textbf{then}
				    	\State \textbf{return} 
				    \EndIf
				    \State \var{close-u}  close-node of node  in the dft
				    \State \var{close-v}  close-node of node  in the dft
				    \If{\textsc{splay-precedes}(\var{close-v},\var{close-u})}
				    	\State \textbf{return} \textsc{lca}()
				    \Else
				    	\State \var{pred-u}  \textsc{splay-predecessor}(\var{close-u})
				    	\State \var{succ-v}  \textsc{splay-successor}(\var{close-v})
				    	\State \textsc{splay-split}(\var{pred-u})
				    	\State \textsc{splay-split}(\var{close-v})
				   		\State \var{range-root}  \textsc{splay-root}(\var{close-v})
				   		\State \var{dft-w}  \var{range-root}.\var{range-lca-summary}.\var{p}
				   		\State \textsc{splay-merge}(\var{pred-u}, \var{close-u})
				   		\State \textsc{splay-merge}(\var{close-u}, \var{succ-v})
				   		\State   the tree node associated with \var{dft-w}
				   		\State \textbf{return} \textsc{parent}()
				    \EndIf
			    \EndProcedure
			  \end{algorithmic}
			  \textbf{Note:} note that, since lines 12-19 run only if  is not a descendant of  and  is not a descendant of , \var{prec-u} and \var{succ-v} are non-\textsc{null}, well-defined nodes.
			\end{algorithm}	
			
We conclude this section discussing how to implement \textsc{root}. One may be tempted to say that  is the node associated with the  of the splay tree containing the dft nodes corresponding to . Unfortunately, this is not true when the dft of the tree containing  is kept in a non-dedicated splay tree. Thus we need the following in \Cref{prop:characterization of root}.
			\begin{lemma}[characterization of the root]
				\label{prop:characterization of root}
				Let  be a node, and let \emph{\var{close-v}} be the close-node associated with . The close-node of the root of the tree containing  is the leftmost dft-node  \emph{\var{close-v}} having minimal depth.
			\end{lemma}			

			
In other words, \Cref{prop:characterization of root} states that the  value of the lca-summary of the suffix of the splay tree starting in \var{close-v} is the close-node of the root of . As before, \Cref{prop:pointer to null} guarantees that the  value of that range is not \textsc{null}, as the first node in the range is a closed parenthesis. This leads to an easy implementation, shown in \Cref{algo:root}.

			\begin{algorithm}[H]
			  \small
			  \caption{\small Implementation of \textsc{root}}
			  \label{algo:root}
			  \begin{algorithmic}[1]
			    \Procedure{root}{}
					\State \var{close-v}  close-node of node  in the dft
				    \State \var{predecessor}  \textsc{splay-predecessor}(\var{close-v})
				    \State \textsc{splay-split}(\var{predecessor})
				    \State \var{splay-root}  \textsc{splay-root}(\var{close-v})
				    \State \var{dft-w}  \var{range-root.range-lca-summary.p}
				    \State \textsc{splay-merge}(\var{predecessor}, \var{close-v})
				    \State   the tree node associated with \var{dft-w}
				    \State \textbf{return} 
			    \EndProcedure
			  \end{algorithmic}
			\end{algorithm}

			
		\subsection{Reductions and combinations}
\label{sub:combine}
			
			We recall that operation \textsc{combine}  value of 
			where  are the nodes in the path from  to the root of the tree, and  is any invertible associative binary operation acting on the values attached to the nodes. We augment the splay tree, adding two fields:
			\begin{compactitem}
				\item \var{item-val}, the value of the node, and
				\item \var{range-val}, the -combined value of \var{item-val} for all the dft nodes in the splay subtree rooted in the node in question
			\end{compactitem}
			In particular, if \var{v} is a dft node associated with the tree node , we set
			
			where  indicates the inverse of  with respect to .
			\begin{restatable}{lemma}{combinelemma2}
				\label{prop:combine}
Let \emph{\var{open-v}} be the open node associated with the tree node . The value of 
				is equal to the -combination of the \emph{\var{item-val}} of the nodes in the prefix of the dft ending in \emph{\var{open-v}}.
			\end{restatable}
			
As an example, consider the case in which  denotes the usual addition of real numbers: a visual insight for \Cref{prop:combine} is given in \Cref{fig:combine example}. The pseudocode of \textsc{combine} is detailed in \Cref{algo:combine}.

\begin{figure}[t!]
				\includegraphics[width = \linewidth]{asy/fig8.pdf}
				\caption{Visual insight for \Cref{prop:combine}\label{fig:combine example}. The numbers written in the nodes of the tree on the left represent the values assigned to the vertices.}
			\end{figure}

		

			\begin{algorithm}[H]
			  \small
			  \caption{\small Implementation of \textsc{combine}}
			  \label{algo:combine}
			  \begin{algorithmic}[1]
			    \Procedure{combine}{}
				    \State \var{open-v}  open-node of node  in the dft
					\State \var{close-root}  close-node of the tree root
					\State \textsc{splay-split}(\var{close-v})
					\State \var{answer}  \textsc{splay-root}(\var{close-v}).\var{range-val}
					\State \textsc{splay-merge}(\var{close-v}, \var{close-root})
					\State \textbf{return} \var{answer}
			    \EndProcedure
			  \end{algorithmic}
			\end{algorithm}
			
The rc-summary, defined in \Cref{sec:operations}, of the concatenation of sequences  and  is computed by \Cref{combinerc}. 
			\begin{algorithm}[H]
			  \small
			  \caption{\small Implementation of \textsc{combine-rc-summaries}\label{combinerc}}
			  \begin{algorithmic}[1]
			    \Procedure{combine-rc-summaries}{}
				    \State \var{answer}  empty rc-summary
				    \If {\var{s1.suffix-depth} + \var{s2.prefix-depth} }
				    	\State \var{answer.prefix-depth}  \var{s1.prefix-depth}
				    	\State \var{answer.body-combination}  \var{s1.body-combination}
				    	\State \var{answer.suffix-depth}  \var{s1.suffix-depth} + \var{s2.prefix-depth} + \var{s2.suffix-depth}
				    	\State \var{answer.suffix-info}  \var{s1.suffix-info}
				    \EndIf
				    \If {\var{s1.suffix-depth} + \var{s2.prefix-depth} }
				    	\State \var{answer.prefix-depth}  \var{s1.prefix-depth} + \var{s1.suffix-depth} + \var{s2.prefix-depth}
				    	\State \var{answer.body-combination}  \var{s2.body-combination}
				    	\State \var{answer.suffix-depth}  \var{s2.suffix-depth}
				    	\State \var{answer.suffix-info}  \var{s2.suffix-info}
				    \EndIf
				    \If {\var{s1.suffix-depth} + \var{s2.prefix-depth} }
				    	\State \var{answer.prefix-depth}  \var{s1.prefix-depth}
				    	\State \var{answer.body-combination}  \var{s2.body-combination}  \var{s1.body-combination}  \var{s1.suffix-info}
				    	\State \var{answer.suffix-depth}  \var{s2.suffix-depth}
				    	\State \var{answer.suffix-info}  \var{s2.suffix-info}
				    \EndIf
			    \EndProcedure
			  \end{algorithmic}
			\end{algorithm}
			We can augment the splay tree nodes as before, keeping track of the summary combination for every range associated with the nodes of the splay tree. The result of \textsc{combine-children} is equal to to \var{body-combination} field of the rc-summary of the range starting in the successor of \var{open-v} and ending in the predecessor of \var{close-v}.
			
			To support \textsc{combine-child-subtree} we need to extend the definition of rc-summaries to keep track of the partial combination in the prefix and the suffix.
	
For the sake of completeness we report below the summary used by \textsc{reduce-child-subtrees}. 
\begin{definition}[rcs-summary]
An \emph{rcs-summary} of a sequence of parentheses is a tuple having these fields:
\begin{compactitem}
	\item {{\var{prefix-depth}}}, the depth of the minimal-depth parenthesis
	\item {{\var{prefix--info}}}, the -combination of the values of the nodes associated with the prefix 
	\item {{\var{body--info}}}, the -combination of the values of the nodes associated with the body
	\item {{\var{body--info}}}, the -combination of the -values of the subtrees in the body
	\item {{\var{suffix--info}}}, the -combination of the values of the nodes associated with the body
	\item {{\var{suffix-depth}}}, the difference between the depth of the last parenthesis and the depth of any minimal-depth parenthesis.
\end{compactitem}
\end{definition}

\subsection{Applications: betweenness and closeness centrality}





We now need to show how to maintain the information related to \textsc{up-dists} and \textsc{down-dists} when we perform the following structural updates:
	\begin{compactitem}
		\item \textsc{link}
		\item \textsc{cut}
		\item \textsc{condense}
	\end{compactitem}
	Note that the other structural updates are maintained: \textsc{evert} is implemented using \textsc{link} and  \textsc{cut}; \textsc{erase} is implemented using \textsc{cut} and  \textsc{condense}.

\noindent \textbf{\textsc{link}}. As we mentioned in \Cref{sub:cc}, in the case of a \textsc{link} operation, where we add the edge between  and , whose weight is , the following operations need to be executed before the actual linking to maintain the information (we denote the size of the tree  (resp. ) belongs to with  (resp. )):
\begin{compactitem}
\item the \textsc{down-dists} of all the nodes in the path of  are increased by ;
\item the \textsc{up-dists} of all the nodes in the subtree of  (included) are increased by ;
\item the \textsc{up-dists} of all the nodes in the tree containing , with the only exception of the nodes in the path of , are increased by . In order to do so, we add it to all the nodes (i.e. the subtree of \textsc{root}), and then we subtract it from all the nodes in the path of . 
\end{compactitem}

	
\noindent	\textbf{\textsc{cut}}. The \textsc{cut} is the dual of the \textsc{link}, thus we execute the following operations after the cut:
\begin{compactitem}
\item the \textsc{down-dists} of all the nodes in the path of  are decreased by ;
\item the \textsc{up-dists} of all the nodes in the subtree of  (included) are decreased by ;
\item the \textsc{up-dists} of all the nodes in the tree containing , with the only exception of the nodes in the path of , are decreased by . In order to do so, we subtract if from all the nodes (i.e. the subtree of \textsc{root}), and then we add it to all the nodes in the path of . 
\end{compactitem}
		
\noindent	\textbf{\textsc{condense}}
When we condense node , let us denote by  the parent of  and by  the weight of the edge (,). We execute the following operations before condensing:
\begin{compactitem}
\item the \textsc{down-dists} of all the nodes in the path of  are decreased by ;
\item the \textsc{up-dists} of all the nodes in the subtree of  (included) are decreased by ;
\item the \textsc{up-dists} of all the nodes in the tree containing , with the only exception of the nodes in the path of , are decreased by . In order to do so, we subtract if from all the nodes (i.e. the subtree of \textsc{root}), and then we add it to all the nodes in the path of . 
\end{compactitem}


We now detail how to maintain a value in the node, such as \textsc{down-dists} and \textsc{up-dists}, under the two following operations: \textsc{add-to-path} that adds  to all the vertices in the path between  and the root, and \textsc{add-to-subtree} that adds  to all the vertices in the subtree of . 
In each node we 	maintain the following information, that will be used to derive the value of the node\footnote{Thus, in order to maintain both \textsc{down-dists} and \textsc{up-dists} we need six distinct values in a node: a  and   for \textsc{down-dists}, and a  and   for \textsc{up-dists}.}:
\begin{compactitem}
				\item , to be forwarded in the path of the node;
				\item , to be forwarded in the subtree of the node;
				\item , relative to the node.
			\end{compactitem}
	

In the begininning  and  are equal to , whilst  has the initial value of the node.

This allow us to state the following Lemma.
\begin{restatable}{lemma}{bc}
Using a \dft, it is possible to answer \emph{closeness centrality} queries of a vertex in time .
\end{restatable}


In the following we report the pseudocode of the affected operations, where we show the changes from the previously shown pseudocodes in red (best viewed in color).
		

			\begin{algorithm}[H]
			  \small
			  \caption{\small Implementation of \textsc{get-effective-val}}
			  \begin{algorithmic}[1]
			    \Procedure{get-effective-val}{}\Comment{}
			    	\State \textbf{return}  + (sum of  in the subtree of ) + (sum of  in the path of )
			    \EndProcedure
			  \end{algorithmic}
			\end{algorithm}
			
			\begin{algorithm}[H]
			  \small
			  \caption{\small Implementation of \textsc{increment-val} -- increase the value of node  by }
			  \begin{algorithmic}[1]
			    \Procedure{increment-val}{}\Comment{}
			    	\State 
			    \EndProcedure
			  \end{algorithmic}
			\end{algorithm}	
			
			
			\begin{algorithm}[H]
			  \small
			  \caption{\small Implementation of \textsc{change-val} -- set the value of node  to }
			  \begin{algorithmic}[1]
			    \Procedure{change-val}{}\Comment{}
			    	\State 
			    	\State 
			    \EndProcedure
			  \end{algorithmic}
			\end{algorithm}	
			

			\begin{algorithm}[H]
			  \small
			  \caption{\small Implementation of \textsc{link}}
			  \begin{algorithmic}[1]
			    \Procedure{link}{}
			    \If{\textbf{not} \textsc{same-tree}()}
			    	\State\textcolor{red}{ - sum of  of subtree of }
			    	\State\textcolor{red}{ - sum of  in the path of }
				    \State \var{open-u}  open-node of node  in the dft
				   	\State \var{close-u}  close-node of node  in the dft
				   	\State \var{open-v}  open-node of node  in the dft
			    	\State \textsc{splay-split}(\var{open-u})
			    	\State \textsc{splay-merge}(\var{open-u}, \var{open-v})
			    	\State \textsc{splay-merge}(\var{open-u}, \var{close-u})
			    \EndIf
			    \EndProcedure
			  \end{algorithmic}
			\end{algorithm}	
			
			\begin{algorithm}[H]
			  \small
			  \caption{\small Implementation of \textsc{cut}}
			  \begin{algorithmic}[1]
			    \Procedure{cut}{}
			    \State \var{root}  \textsc{root}()
			    \If{  \var{root}}
			    	\State\textcolor{red}{ + sum  in the subtree of }
			    	\State\textcolor{red}{ + sum of   in the path of }
					\State \var{open-v}  open-node of node  in the dft
					\State \var{close-v}  close-node of node  in the dft
					\State \var{open-root}  open-node of \var{root} in the dft
					\State \var{close-root}  close-node of \var{root} in the dft
					\State \textsc{splay-split}(\textsc{splay-predecessor}(\var{open-v}))
					\State \textsc{splay-split}(\var{close-v})
					\State \textsc{splay-merge}(\var{open-root}, \var{close-root})
			    \EndIf
			    \EndProcedure
			  \end{algorithmic}
			\end{algorithm}
			
			\begin{algorithm}[H]
			  \small
			  \caption{\small Implementation of \textsc{condense}}
			  \begin{algorithmic}[1]
			    \Procedure{condense}{}
			    \If{\textcolor{red}{}}
					\State\textcolor{red}{ = }
					\State\textcolor{red}{ = }
					\State\textcolor{red}{ = }
				\EndIf
				\State \var{open-v}  open-node of node  in the dft
				\State \var{close-v}  close-node of node  in the dft
				\State \textsc{splay-erase}(\var{open-v})
				\State \textsc{splay-erase}(\var{close-v})
			    \EndProcedure
			  \end{algorithmic}
			\end{algorithm}




\iffalse 
\section{Omitted proofs}

		Also, the following lemmas hold:
\begin{restatable}{lemma}{lemunbalanced}
			If a sequence  of parentheses has an unbalanced closed parenthesis (i.e. its down-value is strictly negative), so does any sequence obtained concatenating  with any other sequence.
\end{restatable}
\begin{restatable}{lemma}{lemprefix}
			The down-value of (the summary of) any prefix of a balanced sequence of parentheses is always 0.
\end{restatable}

\balancedseq*
\sumofsummaries*
\summarysumassociativity*
\lemfather*
\lemunbalanced*
\lemprefix*
\lemimpact*
\bc*


\section{COSE SCARTATE}

	Esiste una \textbf{dualità}, secondo me molto elegante, tra path e subtree. Infatti salterà fuori che per poter aggiungere un numero a tutto un sottoalbero dovremo fare una aggregazione su un path, mentre per modificare un path faremo una riduzione su un sottoalbero (elegante vero?).

	L'idea intelligente che sta sotto alla \textbf{modifica di un intero path}: se devo aggiungere  a tutti i numeri del path dalla radice a , sommo il valore  nel nodo  in un campo  (delta UP) inizialmente 0. A questo punto il valore di un nodo  è pari al suo valore originale + la somma di tutti i  del subtree di  (uso SUBTREE SUM).

	L'idea intelligente che sta sotto alla \textbf{modifica di un intero sottoalbero}: se devo aggiungere  a tutti i numeri del sottoalbero radicato in , sommo il valore  nel nodo  in un campo  (delta DOWN) inizialmente 0. A questo punto il valore di un nodo  è pari al suo valore originale + la somma di tutti i  del path da u alla radice (uso COMBINE).

	Non è difficile aggiustare questa cosa per fare anche link/cut/condense. Ad esempio, per link devo stare attendo ai , in modo che non inizino a influenzare i nodi dell'albero "sopra".


			\textcolor{blue}{Per i più puntigliosi, di nuovo predecessor non può mai essere null, perchè il predecessor di un close-node non è mai null (per ovvi motivi)...}


			\textcolor[rgb]{.4,.4,.4}{Nota per Luigi: secondo te è bene fare una figura per questa cosa, un visual insight come sopra?}


			The complexity of the algorithm just proposed is amortized  for a tree of size , because procedure \textsc{recursive parent} is called at most  times, where  is the height of the splay tree. \textcolor{blue}{Magari dire che successor non può essere NULL dato che v non è la radice.}
			\textcolor{blue}{Dire che \textsc{parent} = \textsc{ancestor} e che in effetti ci vuole pochissimo a cambiare dal cercare il padre a cercare l'ancestor. Infatti, l'ancestor  livelli sopra di me è il primo nodo dopo il mio close node che ragginge profondità . In recursive parent quindi basta cambiare i controlli  con i controlli . Se hai tanta voglia puoi stravolgere un po' tutto e dire che mostriamo solo come fare ancestor e che parent è ancestor(v, -1) e facciamo solo il codice di recursive-ancestor.}


		We will divide the operations in several paragraphs, in an attempt to make clear the logical dependencies between them. The description of the extra information contained in the nodes of the splay tree will be postponed to the paragraph explaining the implementation of the non-structural operations. For now, it is enough to assume that it is possible to implement the tree rotations so that these pieces of information are correctly maintained and updated in constant time. To do that, we can postulate a function \textsc{recalc-extra-info}, that is able to determine, in constant time,  the values of the fields stored in node  of the splay tree by combining the information stored in the left and right children of . This automatically implies that all the basic operations on the splay tree keep working in (amortized) logarithmic time in the size of the tree itself.
		
	\subsection{Extensions and final remarks}\vspace{-.5cm}\rule{\linewidth}{.5pt}\\textsc{combine}_\Delta(v) + \textrm{val}(v), where the call to \textsc{combine} is referred to the  values, while \textrm{val} refers to the original real numbers associated with the vertices.
			\end{compactitem}
			Some extra care has to be taken when performing structural modifications, like \textsc{evert} and \textsc{cut}, but it's easy to work around this complications without affecting the performance of the data structure.
			
			\textcolor{blue}{Nota per Luigi: è possibile supportare oltre a recursive-change-val e node-value anche subtree sum, in un modo un po' più fantasioso, ma sarebbe un po' lungo da spiegare. Magari possiamo tenerci questa informazione per noi e farla fruttare da qualche altra parte. Saper fare anche quell'ultima cosa è comoda per la closeness centrality.}
			
			Analogously, we can support the same set of operations above with \textsc{subtree-sum} replaced with \textsc{subtree-max}.
			
			\textcolor{blue}{Altre note che mi vengono in mente: sono capaci tutti a fare query sui sottoalberi in tempo , ma la sfida è farle in , perchè in tante applicazioni pratiche ti interessano solo pochi nodi, e ripetutamente. Quindi anche se è vero che con le strutture in  alla fine se chiedi ogni volta tutti i nodi paghi  (perchè ), in queste altre applicazioni magari per sapere ogni volta l'impact di nodi con altissimo degree paghi una sfracca di tempo. Insomma,  a volte è \textbf{troppo} sbilanciato.}

\fi 

\end{document}
