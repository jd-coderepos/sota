\documentclass[12pt,draftcls,onecolumn]{IEEEtran}





\newtheorem{defin}{Definition}\newtheorem{assump}{Assumption}
\newtheorem{theorem}{Theorem}
\newtheorem{prop}{Proposition}
\newtheorem{lemma}{Lemma}\newtheorem{alg}{Algorithm}\newtheorem{remark}{Remark}
\newtheorem{example}{Example}
\newtheorem{notations}{Notations}

\newcommand{\be}{}
\newcommand{\ba}{\begin{array}}
\newcommand{\ea}{\end{array}}
\newcommand{\bea}{}
\newcommand{\combin}[2]{\ensuremath{ \left( \ba{c} #1 \\ #2 \ea \right) }}
\newcommand{\diag}{{\mbox{diag}}}
\newcommand{\rank}{{\mbox{rank}}}
\newcommand{\dom}{{\mbox{dom{\color{white!100!black}.}}}}
\newcommand{\range}{{\mbox{range{\color{white!100!black}.}}}}
\newcommand{\image}{{\mbox{image{\color{white!100!black}.}}}}
\newcommand{\herm}{^{\mbox{\scriptsize H}}}  \newcommand{\sherm}{^{\mbox{\tiny H}}}       \newcommand{\tran}{^{\mbox{\scriptsize T}}}  \newcommand{\tranIn}{^{\mbox{-\scriptsize T}}}  \newcommand{\card}{{\mbox{\textbf{card}}}}
\newcommand{\asign}{{\mbox{}}}
\newcommand{\cf}{{\textit{cf.}}}

\newcommand{\vbar}{\raisebox{.17ex}{\rule{.04em}{1.35ex}}}
\newcommand{\vbarind}{\raisebox{.01ex}{\rule{.04em}{1.1ex}}}
\newcommand{\R}{\ifmmode {\rm I}\hspace{-.2em}{\rm R} \else  \fi}
\newcommand{\D}{\ifmmode {\rm I}\hspace{-.2em}{\rm D} \else  \fi}
\newcommand{\T}{\ifmmode {\rm I}\hspace{-.2em}{\rm T} \else  \fi}
\newcommand{\N}{\ifmmode {\rm I}\hspace{-.2em}{\rm N} \else \mbox{} \fi}
\newcommand{\B}{\ifmmode {\rm I}\hspace{-.2em}{\rm B} \else \mbox{} \fi}
\newcommand{\Hil}{\ifmmode {\rm I}\hspace{-.2em}{\rm H} \else \mbox{} \fi}
\newcommand{\C}{\ifmmode \hspace{.2em}\vbar\hspace{-.31em}{\rm C} \else \mbox{} \fi}
\newcommand{\Cind}{\ifmmode \hspace{.2em}\vbarind\hspace{-.25em}{\rm C} \else \mbox{} \fi}
\newcommand{\Q}{\ifmmode \hspace{.2em}\vbar\hspace{-.31em}{\rm Q} \else \mbox{} \fi}
\newcommand{\Z}{\ifmmode {\rm Z}\hspace{-.28em}{\rm Z} \else  \fi}

\newcommand{\sgn}{\mbox {sgn}}
\newcommand{\var}{\mbox {var}}
\newcommand{\E}{\mbox {E}}
\newcommand{\cov}{\mbox {cov}}
\renewcommand{\Re}{\mbox {Re}}
\renewcommand{\Im}{\mbox {Im}}
\newcommand{\cum}{\mbox {cum}}

\renewcommand{\vec}[1]{\bf{#1}}     \newcommand{\vecsc}[1]{\mbox {\boldmath \scriptsize }}     \newcommand{\itvec}[1]{\mbox {\boldmath }}
\newcommand{\itvecsc}[1]{\mbox {\boldmath }}
\newcommand{\gvec}[1]{\mbox{\boldmath }}

\newcommand{\balpha}{\mbox {\boldmath }}
\newcommand{\bbeta}{\mbox {\boldmath }}
\newcommand{\bgamma}{\mbox {\boldmath }}
\newcommand{\bdelta}{\mbox {\boldmath }}
\newcommand{\bepsilon}{\mbox {\boldmath }}
\newcommand{\bvarepsilon}{\mbox {\boldmath }}
\newcommand{\bzeta}{\mbox {\boldmath }}
\newcommand{\boldeta}{\mbox {\boldmath }}
\newcommand{\btheta}{\mbox {\boldmath }}
\newcommand{\bvartheta}{\mbox {\boldmath }}
\newcommand{\biota}{\mbox {\boldmath }}
\newcommand{\blambda}{\mbox {\boldmath }}
\newcommand{\bmu}{\mbox {\boldmath }}
\newcommand{\bnu}{\mbox {\boldmath }}
\newcommand{\bxi}{\mbox {\boldmath }}
\newcommand{\bpi}{\mbox {\boldmath }}
\newcommand{\bvarpi}{\mbox {\boldmath }}
\newcommand{\brho}{\mbox {\boldmath }}
\newcommand{\bvarrho}{\mbox {\boldmath }}
\newcommand{\bsigma}{\mbox {\boldmath }}
\newcommand{\bvarsigma}{\mbox {\boldmath }}
\newcommand{\btau}{\mbox {\boldmath }}
\newcommand{\bupsilon}{\mbox {\boldmath }}
\newcommand{\bphi}{\mbox {\boldmath }}
\newcommand{\bvarphi}{\mbox {\boldmath }}
\newcommand{\bchi}{\mbox {\boldmath }}
\newcommand{\bpsi}{\mbox {\boldmath }}
\newcommand{\bomega}{\mbox {\boldmath }}

\newcommand{\bolda}{\mbox {\boldmath }}
\newcommand{\bb}{\mbox {\boldmath }}
\newcommand{\bc}{\mbox {\boldmath }}
\newcommand{\bd}{\mbox {\boldmath }}
\newcommand{\bolde}{\mbox {\boldmath }}
\newcommand{\boldf}{\mbox {\boldmath }}
\newcommand{\bg}{\mbox {\boldmath }}
\newcommand{\bh}{\mbox {\boldmath }}
\newcommand{\bp}{\mbox {\boldmath }}
\newcommand{\bq}{\mbox {\boldmath }}
\newcommand{\br}{\mbox {\boldmath }}
\newcommand{\bs}{\mbox {\boldmath }}
\newcommand{\bt}{\mbox {\boldmath }}
\newcommand{\bu}{\mbox {\boldmath }}
\newcommand{\bv}{\mbox {\boldmath }}
\newcommand{\bw}{\mbox {\boldmath }}
\newcommand{\bx}{\mbox {\boldmath }}
\newcommand{\by}{\mbox {\boldmath }}
\newcommand{\bz}{\mbox {\boldmath }}




\newenvironment{Exx}
{\begin{adjustwidth}{0.022\linewidth}{0cm}
\begingroup\small
\vspace{-1.0em}
\raisebox{-.25em}{\rule{\linewidth}{0.3pt}}
\begin{example}
}
{
\end{example}
\vspace{-6mm}
\rule{\linewidth}{0.3pt}
\endgroup
\end{adjustwidth}}

\newenvironment{Algg}
{\begin{adjustwidth}{0.022\linewidth}{0cm}
\begingroup\footnotesize
\vspace{-1.0em}
\raisebox{-.25em}{\rule{\linewidth}{0.3pt}}
\begin{alg}
}
{
\end{alg}
\vspace{-6mm}
\rule{\linewidth}{0.3pt}
\endgroup
\end{adjustwidth}}



 \usepackage[dvips]{graphicx}
\usepackage{amsmath}
\usepackage{subfigure}
\usepackage{cite}
\usepackage{url}
\usepackage{rotating}
\usepackage{color}
\usepackage{xcolor}
\usepackage{supertabular}
\usepackage{changepage}

\usepackage{amssymb}
\usepackage{psfrag}
\usepackage{epstopdf}
\usepackage{epsfig}
\usepackage{tikz}
\usetikzlibrary{arrows,decorations.pathmorphing,backgrounds,fit,petri,positioning,matrix}
\usetikzlibrary{shapes,arrows}
\usepackage{multirow}
\usepackage{tkz-euclide}
\usetkzobj{all}
\usepackage{caption}

\newcommand{\KomM}[2]{{\textbf{{\color{blue!70!black}#1}}}{\sout{#2}}}
\newcommand{\add}[1]{{{\color{blue!0!black}#1}}}
\newcommand{\addnew}[1]{{{\color{blue!0!black}#1}}}
\newcommand{\addred}[1]{{{\color{red!70!black}#1}}}
\interfootnotelinepenalty=10000

\newcommand{\dis}{\discretionary{}{}{}} \newcommand{\goodgap}{\hspace{0.01\linewidth}} \newcommand{\goodgaptop}{\hspace{0.10\linewidth}} \newcommand{\goodgapp}{\hspace{0.05\linewidth}} \def\Blue#1{\color{blue!0!black}{#1}}
\DeclareMathOperator*{\argmax}{\arg\!\max}
\DeclareMathOperator*{\argmin}{\arg\!\min}




\renewcommand{\baselinestretch}{1.275}\AtBeginDocument{\setlength\abovedisplayskip{2mm}}
\AtBeginDocument{\setlength\belowdisplayskip{1.5mm}}
\allowdisplaybreaks[2]

\usepackage{setspace}


\hyphenation{op-tical net-works semi-conduc-tor}


\begin{document} \title{\addnew{On the Privacy of Optimization Approaches}}
\author{P.~C. Weeraddana,,~\IEEEmembership{Member,~IEEE,}
\thanks{P. C. Weeraddana, G. Athanasiou, M. Jakobsson, and C. Fischione with Electrical Engineering, KTH Royal Institute of Technology, Stockholm, Sweden. J. S. Baras is with the Department of Electrical and Computer Engineering, University of Maryland, USA. }
G. Athanasiou,~\IEEEmembership{Member,~IEEE,} \\ M. Jakobsson,~\IEEEmembership{Student Member,~IEEE,}  C. Fischione,~\IEEEmembership{Member,~IEEE,} \\ and J. S. Baras,~\IEEEmembership{Fellow,~IEEE}
}





\maketitle


\setlength{\baselineskip}{21pt}

\vspace{-10mm}
\begin{abstract}
\addnew{
Ensuring privacy of sensitive data is essential in many contexts, such as healthcare data, banks, e-commerce, wireless sensor networks, and social networks. It is common that different entities coordinate or want to rely on a third party to solve a specific problem. At the same time, no entity wants to publish its problem data during the solution procedure unless there is a privacy guarantee. Unlike cryptography and differential privacy based approaches, the methods based on optimization lack a quantification of the privacy they can provide. The main contribution of this paper is to provide a mechanism to quantify the privacy of a broad class of optimization approaches. In particular, we formally define a one-to-many relation, which relates a given adversarial observed message to an uncertainty set of the problem data. This relation quantifies the potential ambiguity on problem data due to the employed optimization approaches. The privacy definitions are then formalized based on the uncertainty sets. The properties of the proposed privacy measure is analyzed. The key ideas are illustrated with examples, including localization, average consensus, among others. 





}
\end{abstract}
\vspace{4mm}
\begin{keywords}\vspace{-0mm}
Privacy, distributed optimization, ADMM, secured multiparty computation.
\end{keywords}





\section{Introduction}
Privacy is central in many application domains, where parties jointly solve optimization problems. These interactions and collaborations are desirable to gain mutual benefits. For example, independent hospitals would like to coordinate for diagnostic decision making based on their existing patient records. Normally, optimization solvers require public data sharing, which substantially hinder the cooperation due to privacy concerns (e.g., privacy for patients' records). The challenge is how to \emph{solve} problems among parties, while preserving privacy of their individual data. \addnew
{
\subsection{Problem Statement}\label{subsec:problem_statement}
Formally, an -party design and decision making problem can be posed as follows:

Here,  is a scalar-valued objective function of the decision variables , given the problem data ,~\footnote{\addnew{Dimensions of 's, can also be problem data, which we considered known, throughout to avoid cumbersome notations.}} where  is the \emph{private} data (e.g., matrices) associated with entity~. Moreover,  and  are vector-valued nonlinear and affine functions, respectively.

We now pose the questions: \texttt{Q1}) How to quantify the privacy of the problem data ~? \texttt{Q2}) How to \emph{solve} problem~\eqref{eq:optimization_prob}, such that the ``privacy" of  is preserved ? 

}


\subsection{Existing Approaches}

\addnew
{
An ideal answer to \texttt{Q1} is \emph{perfect privacy}, where no information of the original problem data  can be extracted by a third party. However, answering \texttt{Q2} with perfect privacy is generally impossible. There is an alternative fundamental theory for answering \texttt{Q1}, namely, cryptography~\cite{Goldreich-book-2004}, which includes a number of mechanisms to encrypt the original problem data . The underlying privacy definition is called \emph{semantic security}~\cite[\S~5]{Goldreich-book-2004}. Loosely speaking, the semantic privacy means that nothing can be \emph{feasibly extracted} from the encrypted data. Given \texttt{Q1} is handled by the semantic security, \emph{secured multiparty computation} (SMC)~\cite{Yao-1982} is a well established framework for answering \texttt{Q2}. In principle, SMC is applied to almost any problem, given that the required computations are written as a Boolean circuit, or as an arithmetic circuit. However, the general objective and constraints of problem~\eqref{eq:optimization_prob} can be complicated functions, and therefore usually the associated solution approach become impractical~\cite{Damgard-06,Toft-2009},\cite[\S~2.3.2]{Bednarz-2012}.
}


\addnew
{
An alternative line of research for answering \texttt{Q1} considers the \emph{-differential privacy}~\cite{Dwork-McSherry-Nissim-Smith-2006}. The definition allows a non-negligible
information leakage, denoted by , as opposed to the cryptographic counterpart. Roughly speaking, the standard way of accomplishing -differential privacy for \texttt{Q2} is based on a random perturbation mechanism, where the underlying subroutines of the associated solution method is appropriately mutated by using random noise with specific statistical properties, \cf~\cite{Chaudhuri-Monteleoni-Sarwate-2011,Kifer-Smith-Thakurta-2012,Guptaetal-2010,Ny-Pappas-CDC-2013,Ny-Pappas-Alerton-2013,Huang-Mitra-Vaidya-2014}. As a consequence, there is a trade-off between the optimality of the solution of problem~\eqref{eq:optimization_prob} and the desired privacy level of the problem data, quantified by . In addition, the applicability of differential privacy based approaches for solving problem~\eqref{eq:optimization_prob} can usually be limited. Note that specifying the noise properties, such as variances to achieve a pre-specified differential privacy is solely dependent on the \emph{sensitivity} of the related functions (e.g., objective, constraint, subgradient functions) with respect to \emph{perturbations of the problem data}. In general, quantifying such sensitivities in a \emph{closed-form} is challenging. One can certainly compute some bounds. However, unless the bounds are tight, the noise variance computed based on the bounds will be over estimated, which in turn can degrade the optimality of the solution significantly~\cite{Dwork-McSherry-Nissim-Smith-2006,Chaudhuri-Monteleoni-Sarwate-2011,Huang-Mitra-Vaidya-2014}.


}

\addnew{
As opposed to the cryptography and differential privacy based methods discussed above, there is another class of approaches, which answers~\texttt{Q2}~\cite{Mangasarian-OptLet-2011,Mangasarian-OptMethSW-2011,Mangasarian-OptLet-2012,Mangasarian-Wild-2008,Mangasarian-Wild-Fung-2008,Bednarz-2012,Dreier-Kerschbaum-2011,Bednarz-Bean-Roughan-2009,Wang-Ren-Wang-11}, yet answers to~\texttt{Q1} are rather intuitively explained. The key idea of the methods is to use algebraic manipulations to disguise the original problem into an equivalent problem so that the problem data  is somehow hidden. We refer to these approaches as algebraic transformation methods. Algebraic transformation methods are promising in the sense that they are efficient and usually guarantee the optimality of the solution of problem~\eqref{eq:optimization_prob}, though privacy of the methods is not quantified. The approaches are typically applied to a broader class of problems, as opposed to the cryptographic or differential privacy based approaches. Therefore it is still desirable to quantify their privacy as response to~\texttt{Q1}.
}




\subsection{Our Contributions}


\addnew{The main contribution of this paper is to quantify the privacy properties of a broader class of optimization approaches, where the algebraic transformation methods  are particular cases. More specifically, the proposed privacy definition applies to 1) methods via standard objective/constraint transformations, 2) methods via standard variable transformations, 3) classical decomposition methods, e.g., primal and dual decomposition, and 4) state-of-the-art alternating direction method of multipliers method (ADMM).}


\addnew{To do this, the underlying disguise of problem data  due to those optimization approaches is formally represented as a one-to-many binary relation between the observed message of an adversary and an uncertainty set, in which the sensitive problem data  itself is a member. The privacy of the associated method can then be quantified by the properties of the uncertainty set. The properties of the proposed privacy measure is analyzed. Given an optimization approach as response to \texttt{Q2}, our definition answers \texttt{Q1}. Implications of the proposed privacy measure is discussed. Our privacy definition allows comparing the privacy of different optimization approaches applied to a problem. It quantifies the \emph{best} and the \emph{worst} privacy for an specified problem data. Several examples are given to illustrate the key ideas.}

In \S~\ref{sec:definitions} we present our new proposed definitions and other basic ones, useful for describing the privacy properties of optimization approaches. Application of the proposed privacy definitions for optimization approaches are illustrated in \S~\ref{sec:Opt_Approaches_Privacy}. Conclusions are given in~\S~\ref{sec:conclusions}.

\addnew{\emph{{Notations:}} Boldface lower case and upper case letters represent vectors and matrices, respectively, and calligraphy letters represent sets. The Euclidean- space and the positive integers are denoted by  and , respectively. The superscript  is the transpose. We use the notation  to denote . The identity matrix, all zero vector, and all one vector, are denoted by , , and , respectively. The -norm of  is denote by . The power set of an arbitrary space  is denoted by . A ball with radius  and center  is denoted by . Finally, we denote by , the component-wise inequality. }

\section{Privacy Quantifications}\label{sec:definitions}

\addnew{Original definitions together with other basic definitions and assumptions for quantifying the privacy properties of the optimization approaches are given. The essential implications of the definitions are also discussed.}

\addnew{
\subsection{Problem Data and the Adversary}\label{subsec:definitions_data_advsry}
}

\addnew{
\begin{defin}[Inputs, input tuples, and messages]\label{def:input}
Consider the problem~(\ref{eq:optimization_prob}). We call the \emph{set of problem data} , denoted , the \emph{inputs} of problem~(\ref{eq:optimization_prob}). Suppose , where  is a possibly vector valued function with non-constant components. Moreover, suppose that  lies in a metric space . We call , an \emph{input tuple} of . Finally, we call a finite length data structure , a \emph{message} of , where  represents any vector/matrix valued function. \hfill 
\end{defin}
}
\addnew{Note that elements of  represents the central components what the problem data owner cares about. The key points of the definition is illustrated in Example~\ref{ex:input_output1}. Throughout the paper we consider the following assumption on the input of a problem:}
\addnew{
\begin{assump}\label{assump:input}
The inputs of any optimization problem of the form~(\ref{eq:optimization_prob}) is deterministic, and therefore there is no associated statistical models. \hfill 
\end{assump}
}
The considered adversarial model and its associated knowledge is defined next. The definition of the adversary is similar to the passive eavesdroppers considered in~\cite[\S~5.1-5.3]{Goldreich-book-2004}. We consider the \emph{passive adversary} model throughout this paper.





\begin{defin}[\add{Passive adversary}]\label{def:adversary}
\add{In a multi-party environment, a party involved in solving a problem of the form~(\ref{eq:optimization_prob}), or even a third party, is called a passive adversary if it taps the messages of input of (\ref{eq:optimization_prob}) exchanged during different stages of the solution method, keeps a record of possibly all the messages exchanged, and tries to discover others' private~data.}  \hfill 
\end{defin}




\addnew{
\begin{defin}[Adversarial knowledge]\label{def:AdvsryKnowledge}
The set  of information that an adversary might exploit to discover the input of problem~(\ref{eq:optimization_prob}) is called the adversarial knowledge. The knowledge can contain messages  of the problem input, which we call the \emph{inevitable} knowledge. The rest of the knowledge  is called the \emph{auxiliary} knowledge. \hfill 
\end{defin}
}

\addnew{
Note that the inevitable knowledge contains messages (e.g., , \cf~Definition~\ref{def:input}) that must be revealed to a third party, such as transformed variants of inputs necessary for executing the solution method. The auxiliary knowledge can encompass components, such as eavesdropped measures of input elements, knowledge of optimality properties, etc.,~\cf~Example~\ref{ex:input_output1}. The following remark summarizes a property of  that will be useful later.

\begin{remark}\label{remark:knowledge}
For a given problem and its solution approach, the knowledge  of a third party can be further improved and can never be decreased as time elapses. In other words, given time , we have , where  denotes the adversarial knowledge at time . As a result, unless the underlying solution method is changed, it is always the case that . \hfill 
\end{remark}

Note that \emph{different} solution methods in general can yield different sets of knowledge, even if the problem is fixed. Finally, recall that the set  of the inputs/outputs is deterministic, \cf~Assumption~\ref{assump:input}. Therefore, the adversarial knowledge  does not contain elements such as probability density functions or cumulative distribution functions to describe statistical models for .}



\addnew
{
\begin{figure}[t]
\centering
\begin{tikzpicture}[scale=0.30]
\node (C) at (-3,0) {\scriptsize{}};
\node[ellipse,draw=black,fill=blue!20,minimum height=10mm,minimum width=60mm] (A) at (12,0) {\tiny{}};
\node[ellipse,draw=black,fill=white,minimum height=3mm,minimum width=3mm] (B) at (16.7,-0.2) {\tiny{}};
\draw (C) edge [-latex, thick, out=30,in=160]  node[above] {\tiny{}} (A) ;
\draw (C) edge [-latex, thick, out=-30,in=190]  node[below] {\tiny{}} (B) ;
\end{tikzpicture}
\captionof{figure}{\label{Fig:relation}\small{\addnew{Obfuscation of an input tuple , where , , , and the ellipsoids represent uncertainty sets of .}}}
\vspace{-7mm}
\end{figure}
}


\addnew{
\begin{defin}[Obfuscation of the input and uncertainty sets]\label{def:Obsf_Unctnty}
Let , , , and  denote the input, an input tuple, a message of problem~(\ref{eq:optimization_prob}), and the adversarial knowledge, respectively, \cf~Definition~\ref{def:input}. Suppose . We say  is obfuscated if there exists a \emph{one-to-many} \emph{binary relation}  from the singleton  to a nonempty set , such that . We call the (possibly unbounded) set , the uncertainty set for . \hfill 
\end{defin}
}

\addnew
{
The \emph{one-to-many} nature of such relations is the mechanism of achieving ambiguity in , \cf~Figure~\ref{Fig:relation}. An example to clarify Definition~\ref{def:Obsf_Unctnty} is given below:
\begin{Exx}\label{ex:input_output1}
Consider a client-cloud environment, where the client has an optimization problem with problem input , where  are private data that the client cares about. The cloud (potential adversary) solves the problem for the client. Suppose that the employed deterministic solution methods for the problem is such that client has to outsource the two scalars  and  to the cloud, where  and , that is the message . Suppose, in addition, cloud knows  (i.e., auxiliary knowledge) and wants to find input tuple . Then we have .
\end{Exx}
}


\addnew{
Trivially, having more knowledge of an input tuple  can only reduce the ambiguity in . This phenomenon is formally expressed in the following remark, \cf~Figure~\ref{Fig:relation}.
\begin{remark}\label{remark:relation}
Let  and  be relations defined as in Definition~\ref{def:Obsf_Unctnty} associated with a problem, where the \emph{inevitable} knowledge is identical in both cases, i.e.,  and  for some message . Then . \hfill 
\end{remark}
}



\addnew{We note that, in many interesting cases, the considered optimization approaches in this paper can be used to realize a relation  as defined in Definition~\ref{def:Obsf_Unctnty}. We capitalize on the properties of such relations resulted by optimization approaches, when quantifying the privacy.}

\addnew{
\subsection{Privacy Index}\label{subsec:privacyIndex}
}

\addnew{Given a relation  and its associated uncertainty set  that lies in a metric space  (\cf~Definition~\ref{def:Obsf_Unctnty}). We consider the following metrics to quantify the size and the spread of .
\begin{enumerate}
\item Diameter of , denoted \texttt{d}().
\item Counting measure of , denoted by ~\cite[p.~146]{McDonald-Weiss-2013}.
\item Affine dimension of , denoted \texttt{a}()~\cite[\S~2.1.3]{Boyd-Vandenberghe-04}.
\end{enumerate}
}



\addnew{
The diameter gives a measure of the worst discrepancy between any two points in the uncertainty set. In particular, we define \texttt{d} as follows:
\begin{defin}[Diameter/center of an uncertainty set]\label{def:adversary_attackmodel}
Given an input tuple  of the input  and  lies in a metric space . Let  denote the uncertainty set of . Then the diameter \texttt{d}~ is given~by
\be\label{eq:diameter}
\hspace{-0mm}\texttt{d}(\mathcal{U}_{\vec c}){=} \left\{\hspace{-1mm} \begin{array}{ll}
   2 \ \inf_{\vec v} \sup_{{\vec u}\in\mathcal{U}_{\vec c}} ||\vec v-u|| & \  \textrm{ is bounded}\\
  \infty  & \ \mbox{otherwise} \ ,
   \end{array} \right.
\ee
where  is some norm on . The argument  that achieves  is called the \emph{center} of  and is denoted by . If the set  is unbounded, we say any point in  achieves , i.e.,  is arbitrary.
\hfill 
\end{defin}

It is not difficult to see that the ball , denoted , is the smallest volume ball, which encloses . The metric  for measuring the size of the uncertainty set  can be interpreted and motivated as follows. Suppose the set  be bounded and an adversary wants to estimate . Because  is deterministic (\cf~Assumption~\ref{assump:input}), a reasonable criterion, from the view of the adversary, is to pick  that minimizes the associated worst-case
error  of a candidate guess . These strategies are known as \emph{worst-case robust designs}, \cf \cite[\S~6.4.2]{Boyd-Vandenberghe-04}. From \eqref{eq:diameter}, it follows that  and the adversary's worst discrepancy between its guess  and  is given by . On the other hand, if the set  is unbounded, a rational adversary has no preference for one point in  over another. Therefore, the adversary's worst discrepancy is unbounded above, irrespective of its guess .


The counting measure of an uncertainty set is an estimate of the number elements in it~\cite[p.~146]{McDonald-Weiss-2013}, and is defined below.
\begin{defin}[Counting measure of an uncertainty set]\label{def:Cardinality}
Given an input tuple  of the input  that lies in a metric space . Let  denote the uncertainty set of . The counting measure of  is , where  is
\be\label{eq:cardinality}
\mu(\mathcal{A})= \left\{ \begin{array}{ll}
  |\mathcal{A}| & \ \ \textrm{ is finite}\\
  \infty  & \ \ \mbox{otherwise} \ ,
   \end{array} \right.
\ee
with  denoting the cardinality of a \emph{finite} set. \hfill 
\end{defin}

The metric  for quantifying the uncertainty set  can be motivated as follows. If  is finite, the value  can be used to quantify the adversary's \emph{best} worst-case winning~\footnote{\addnew{Here the term \emph{winning} refers to the event of  guessing correctly .}} probability, denoted , and to characterizes the probability mass function (pmf) of adversary's guess, denoted , to achieve . Recall that  is deterministic,~\cf~Assumption~\ref{assump:input}. That is, the adversary has no statistical models for describing the variation in . Therefore, a natural criterion for any rational adversary is to choose a probability distribution that maximizes the resulting winning probability , among all possible probability distributions for . From basic probability rules, we get  and , as probabilistic intuition requires. If  is infinite, as our probabilistic intuition suggests,  ought to be . Thus,  quantifies the ``practical impossibility" of an \emph{exact} guess.





The last metric used to quantify the properties of  is its affine dimension, i.e., . In particular,  is the dimension of its affine hull~\cite[\S~2.1.3]{Boyd-Vandenberghe-04}. Roughly speaking,  quantifies the number of orthogonal directions, along which an adversary has to perform its search for locating .
}


\addnew{
Let us finally give a formal definition to quantify the privacy of optimization methods considered in this paper. To do this, we use the metrics , , and  discussed above.}
\addnew{
\begin{defin}[Privacy index]\label{def:input_privacy}
Let  denote the input of problem~(\ref{eq:optimization_prob}) and  denote any input tuple of  that lies in a metric space . Moreover, let  denote the uncertainty set of . Then we call the 3-component tuple  the privacy index of , where . Moreover, the corresponding tuple is denoted by , i.e., . \hfill 
\end{defin}
}
\addnew
{
\noindent Note that  is the adversary's \emph{best} worst-case loosing probability, i.e., . Some basic properties of the  are proved in the following proposition.
\begin{prop}\label{prop:privacy_index}
The privacy index  has the following properties:
\begin{enumerate}
\item[a)]  for all .
\item[b)]  is a singleton  .
\item[c)] , for all  and , where .
\item[d)] , for all unitary matrices  and , where .
\item[e)] .
\item[f)] Let  denote two uncertainty sets of . Then   , containing  such that , . \hfill 
\end{enumerate}

\end{prop}
\begin{proof}


\textit{a,b)} The proof of these parts follow directly from the definition of the metrics , , and .

\textit{c,d)} Theses parts follows from that translation and rotation do not change sets in .

\textit{e)} Let us first show that . If at least one set of  and  is unbounded, then  holds trivially because for any unbounded , . If  and  are bounded, for any ,  is bounded, so is . Moreover, if , then  for all . Therefore,  as required. The relation  follows from that . In particular, ,  being the counting measure on , is a measure space, \cf~\cite[p.~146]{McDonald-Weiss-2013}. Therefore, from \cite[Theorem~5.1]{McDonald-Weiss-2013}, , i.e., . Finally,  follows by definition.

\textit{f)} Let  and  for some  and unitary matrices . Then from the hypothesis and from part c), d), it follows that . Let us now find a particular choice , and  to compute  and . If both  are unbounded, then choose . The result follows immediately because . If only  is unbounded, the same choice of , and  yields the result, because . However, if both  are bounded, we have to be more specific. Recall that  is the smallest volume (bounded) ball containing , \cf~Definition~\ref{def:adversary_attackmodel}. Therefore,  a limit point  at the boundary of  such that ,  is nonempty, \cf~Figure~\ref{Fig:Prop-f}. Similarly,  a limit point  at the boundary of  such that ,  is nonempty. Then by construction,  and  satisfy the required necessary conditions, where  is a unitary matrix such that , , and , \cf~Figure~\ref{Fig:Prop-f}. To see this, note that the sets  are based on rotations and translations of the original sets . In particular, , , , . When , we conclude that  and, so is . Moreover, the rotation induced by  ensures , \cf~Figure~\ref{Fig:Prop-f}.

\noindent This completes the proof of the Proposition.
\end{proof}
}

\addnew
{
\begin{figure}[t]
\centering
\subfigure[]{
\begin{tikzpicture}[scale=.9]
\draw (-0.8,-0.5) circle (0.6cm);
\fill [color=blue!10,draw=blue!20] (-1.3196, -0.8000) rectangle ( -0.2804, -0.2000);
\draw [thick] (-0.5, 0.8660) -- (-0.5, -0.8660);
\draw [thick] (-0.5, -0.8660) -- (0.5, -0.8660);
\draw [thick] (0.5, -0.8660) -- (0.5, 0.8660);
\draw [thick] (0.5, 0.8660) -- (-0.5, 0.8660);

\draw (0,0) circle (1cm);
\node (a) at (-0.65,-0.13) {\tiny{}};
\fill [color=white,draw=black] (-0.5,-0.2) circle (1.0pt);
\fill [draw=black] (-0.5, -0.8660) circle (1.0pt) node [left]{\tiny{}};
\fill [draw=black] (-0.2804, -0.2000) circle (1.0pt) node [right]{\tiny{}};
\end{tikzpicture}
\label{fig:MinmaxVsSum-b}}
\subfigure[]{
\begin{tikzpicture}[scale=.9]
\draw (-1.0196,-0.5) circle (0.6cm);
\fill [color=blue!2,draw=blue!60] ( -1.5392, -0.8000) rectangle ( -0.5, -0.2000);
\draw [thin] (-0.5, 1.532) -- (-0.5, -0.20);
\draw [thin] (-0.5, -0.20) -- (0.5, -0.20);
\draw [thin] (0.5, -0.20) -- (0.5, 1.532);
\draw [thin] (0.5, 1.532) -- (-0.5, 1.532);

\draw (0,0.666) circle (1cm);
\fill [color=white,draw=black] (-0.5,-0.2) circle (1.0pt);
\draw [-latex] (-0.5, -0.2) -- (0.0196, 0.1000) node [right] {\tiny{}};
\draw [-latex] (-0.5, -0.2) -- (-0.75, -0.633) node [left] {\tiny{}};
\end{tikzpicture}
\label{fig:MinmaxVsSum-a}}
\subfigure[]{
\begin{tikzpicture}[scale=.9]
\draw (-1.0196,-0.5) circle (0.6cm);
\fill [color=blue!50,draw=blue!20] ( -1.5392, -0.8000) rectangle ( -0.5, -0.2000);
\draw [thick] ( -1.3660,  -1.7) -- (-0.5, -0.20);
\draw [thin] (-0.5, -0.20) -- (-1.3660, 0.3);
\draw [thin] (-1.3660, 0.3) -- (-2.2320, -1.2);
\draw [thin] (-2.2320, -1.2) -- (-1.3660,  -1.7);

\draw (-1.3660, -0.7) circle (1cm);
\fill [color=white,draw=black] (-0.5,-0.2) circle (1.0pt);
\node (a) at (-.5, 0.4) {\tiny{}};
\draw [-latex] (-0.5, -0.2) -- (0.0196, 0.1000) ;
\end{tikzpicture}
\label{fig:MinmaxVsSum-a}}
\captionof{figure}{\label{Fig:Prop-f}\small{\addnew{Proposition~\ref{prop:privacy_index}-(f): (a)~Original sets  (shaded box) and  (solid rectangular wire frame); (b) A representation of intermediate steps, where the  and  are shifted, yet they still contains ; (c)~Sets  (shaded box) and  (solid rectangular wire frame).}}}
\vspace{-8mm}
\end{figure}
}





\addnew{As we will see next, Proposition~\ref{prop:privacy_index} is useful for explaining interesting implications of the privacy index. Especially, the parts a), b) e), and f) of Proposition~\ref{prop:privacy_index} are more relevant.}

\addnew
{
\subsection{Implications of the Privacy Index}\label{subsec:privacyIndex}
}

\addnew
{
By definition, the privacy index  lies in the extended  and is nonnegative, \cf~Proposition~\ref{prop:privacy_index}-a). Moreover, Proposition~\ref{prop:privacy_index}-a) provides the \emph{smallest} and the \emph{largest} possible values of  for an input-tuple in . Note that if an uncertainty set  is a singleton, then it contains  only, \cf~Definition~\ref{def:Obsf_Unctnty}. Therefore, from Proposition~\ref{prop:privacy_index}-b), . Thus,  signifies zero privacy, where an adversary can exactly determine the associated input tuple.

Proposition~\ref{prop:privacy_index}-e) and f) provide a mechanism to compare different  vectors, wherefore the privacy of different solution methods can be compared. Proposition~\ref{prop:privacy_index}-e) and Remark~\ref{remark:knowledge} ensure that the optimization based approaches lacks robustness to adversarial attacks, such as those involving side information. In addition, Proposition~\ref{prop:privacy_index}-e) is useful to compute lower bounds for  of a complicated uncertainty set. The converse of Proposition~\ref{prop:privacy_index}-e) does not holds in general.

Proposition~\ref{prop:privacy_index}-f) is a weaker form of e): given a nonincreasing (with respect to ) sequence ,  a sequence  of sets, each containing  and . Thus, Proposition~\ref{prop:privacy_index}-f) gives a way to compare the privacy of two algorithms given the privacy indexes, irrespective of the underlying solution machinery. In addition, Proposition~\ref{prop:privacy_index}-f) suggests a natural ordering of privacy indexes in general, (Figure~\ref{fig:PrivacyOrdering}) providing meanings to the \emph{smallest} (i.e., ) and the \emph{largest} (i.e., ) privacy for an \emph{input tuple} , \cf~Proposition~\ref{prop:privacy_index}-a).
}

\vspace{3mm}
\section{{Optimization Approaches and their Privacy}}\label{sec:Opt_Approaches_Privacy}

\addnew
{
In this section, standard optimization approaches are concisely presented, \cf~\texttt{Q2}~\S~\ref{subsec:problem_statement}. Examples are given to quantify the privacy of these optimization approaches, \cf~\texttt{Q1}. All the examples are designed specifically to illustrate our point.}

\vspace{-1mm}
\subsection{Transformation of Objective and Constraint Functions}\label{subsec:Obj-Cons_transformation}

\addnew
{
Suppose  is monotonically increasing and . Moreover, suppose , with , is such that  and  is such that . Let \texttt{P} denote the problem formed by using  , , and , instead of , , and , respectively. Here  and  are th component of  and , respectively. Then  solves \texttt{P} if and only if it solves problem~\eqref{eq:optimization_prob}. With this method, potential obfuscation of problem data (\cf~Definition~\ref{def:Obsf_Unctnty}) is directly linked to the function compositions, , , and .
}

\addnew
{

\begin{figure}[t]
\centering
\begin{tikzpicture}[scale=0.45]
\draw[->] (0, 0.0272) -- coordinate (x axis mid) (7.5, 0.0272) node[right] {\tiny{}};
\draw[->] (0, 0.0272) -- coordinate (y axis mid)(0,4.5) node[above left] {\tiny{}};
\draw (0, 3.1564) -- (8.1, 3.1564) node[below] {\tiny{}};
\draw (2, 0.0272 ) -- (2, 4.5) node[above] {\tiny{}};
\node at (6.9,0.75) {\scriptsize{}};



\draw[color=red] plot[only marks,mark=ball, ball color=red] file {abcd1.table};
\draw[color=red] plot[only marks,mark=ball, ball color=blue] file {abcd2.table};
\draw[color=red] plot[only marks,mark=ball, ball color=red] file {abcd3.table};
\draw[color=red] plot[only marks,mark=ball, ball color=blue] file {abcd4.table};
\draw[color=red] plot[only marks,mark=ball, ball color=red] file {abcd5.table};
\draw[color=red] plot[only marks,mark=ball, ball color=blue] file {abcd6.table};
\draw[color=red] plot[only marks,mark=ball, ball color=red] file {abcd7.table};
\draw[color=red] plot[only marks,mark=ball, ball color=blue] file {abcd8.table};
\draw[color=red] plot[only marks,mark=ball, ball color=red] file {abcd9.table};
\draw[color=red] plot[only marks,mark=ball, ball color=blue] file {abcd10.table};




 \foreach \x in {0,1,2,3,4,5,6,7}
        \draw [xshift=-0](\x,0.0272) -- (\x ,-0.05)
            node[anchor=north] {\tiny{}};
\foreach \y/\ytext in {   0.0272/0,  0.1515/0.5, 0.8838/0.75, 4.2396/0.9}
        \draw (1pt,\y ) -- (-3pt,\y cm) node[anchor=east] {\tiny{}};
\draw [fill=blue,opacity=0.07] (2,3.1564) rectangle (7,4.5);
\draw [fill=red,opacity=0.07] (0,0.0272) rectangle (2,3.1564);
\draw [-to,shorten >=2pt, thick](7, 4.7) -- (6, 4.2396) ;
\draw [-to,shorten >=2pt, thick](6, 4.2396) -- (3, 3.1564) ;
\draw [-to,shorten >=2pt, thick] (3, 3.1564)-- (1, 1.4160) ;
\node at (16, 4.2396) {\footnotesize{arrows  improvements in }};
\end{tikzpicture}
\captionof{figure}{\label{fig:PrivacyOrdering}\small{\addnew{Feasible  for a fixed . The privacy corresponds to the points in the upper-right shaded area are better than that of the points in lower-left shaded area. Rest of the points are incomparable.}}}
\vspace{-6mm}
\end{figure}
}

\addnew{Scaling used in~\cite{Dreier-Kerschbaum-2011,Bednarz-Bean-Roughan-2009,Wang-Ren-Wang-11,Bednarz-2012} is a particular case of the objective and constrained transformation. In~\cite{Mangasarian-OptLet-2012}, authors handle their affine constraint functions, denoted , by using , where  is full column rank with the desired properties . Now, we present a new, yet an important example to convey the idea.}
\begin{Exx}[\addnew{Localization from range measurements}]\label{ex:L_norm_LS_problem}
\addnew
{
Suppose the area  with  contains  military deployed beacons, denoted , that serve civilian boats to locate their positions. Let  denote the position of boat \texttt{B}. The range measurements, denoted  and , , from the beacons are received by \texttt{B} to compute its location . In particular,  and  are the distance and the unit vector, respectively, from \texttt{B} to beacon . Assuming a linear measurement model with unknown noise, an estimate  of  is given by the solution of the problem, ,
where the variable is , and the problem data are  and . However, due to security reasons, military beacons do not want to send their range measurements, which are simply the polar coordinates of their positions, with respect to \texttt{B}.
Now the idea is to simply use the objective transformation , and let \texttt{B} solve
\be\label{eq:obj_squaring}\nonumber
\mbox{minimize}_{{\vec x}} \ {\vec x}\tran(\textstyle\sum_{i=1}^N{\vec a}_i{\vec a}_i\tran){\vec x}+ 2(\textstyle\sum_{i=1}^N{y}_i{\vec a}_i\tran){\vec x}\triangleq{\vec x}\tran\bar{\vec A}{\vec x}+2 {\bar{\vec y}}\tran{\vec x} \ .
\ee
The beacons communicate with each other to compute  and , which is transmitted to \texttt{B}, i.e., the message . Let us now explore the privacy of this method on the input tuple , the location of beacon~. Without loss of generality, let . Suppose \texttt{B} knows by definition , , 3) , , and, of course, , i.e., the auxiliary knowledge.
\addnew
{\vspace{-0mm}
\begin{figure}[h!]
\centering
\subfigure[]{
\begin{tikzpicture}[scale=0.35]
\fill [color=blue!10,draw=black,rotate=45] (0,0) ellipse (1.7cm and 1.2cm);
\fill [color=blue!10,rotate=135,opacity=0.0] (0,0) ellipse (4cm and 0.01cm);
\draw (0,0) circle (1cm);
\draw [thin] (0, 2) -- (0, -2);
\draw [thin] (-3, 0) -- (3, 0);
\fill [draw=black] (-1.4142, 1.4142) circle (2.0pt) node [above]{\tiny{}};
\fill [draw=black] (0,0) circle (2.0pt) node [above right ]{\tiny{}};
\end{tikzpicture}
\label{fig:MinmaxVsSum-b}}
\subfigure[]{
\begin{tikzpicture}[scale=0.35]
\fill [color=blue!10,draw=black,rotate=45] (0,0) ellipse (2.1cm and 0.55cm);
\fill [color=blue!10,rotate=135,opacity=0.0] (0,0) ellipse (4cm and 0.01cm);
\draw (0,0) circle (1cm);
\draw [thin] (0, 2) -- (0, -2);
\draw [thin] (-3, 0) -- (3, 0);
\fill [draw=black] (-1.4142, 1.4142) circle (2.0pt) node [above]{\tiny{}};
\draw [draw=black] ( 0.2419   , 0.9703) circle (2.2pt) ; \draw [draw=black] ( -0.2419   , -0.9703) circle (2.2pt) ;\draw [draw=black] ( -0.9703,-0.2419) circle (2.2pt) ;\draw [draw=black] ( 0.9703,0.2419) circle (2.2pt) ; \draw (0,0) edge [-latex, thin] (  0.4697,  1.8839) ;
\draw (0,0) edge [-latex, thin] ( -1.8839 ,-0.4697  ) ;
\draw (-1.4142,1.4142) edge [-, thin, opacity=0.2] (  0.4697,  1.8839) ;
\draw (-1.4142,1.4142) edge [-, thin, opacity=0.2] (   -1.8839 ,-0.4697 ) ;
\node (C) at (0.4697,  2) {\scriptsize{}};
\node (C) at (-2 ,-0.7) {\scriptsize{}};
\end{tikzpicture}
\label{fig:MinmaxVsSum-a}}
\subfigure[]{
\begin{tikzpicture}[scale=0.35]
\draw [thick] (-2.5, 2.5) -- (2.5, -2.5);
\draw (0,0) circle (1cm);
\draw [thin] (0, 2) -- (0, -2);
\draw [thin] (-3, 0) -- (3, 0);
\fill [draw=black] (-1.4142, 1.4142) circle (2.0pt) node [above]{\tiny{}};
\fill [draw=black] (0,0) circle (2.0pt) node [above right ]{\tiny{}};
\node (C) at (-2.9, 2.5) {\scriptsize{}};
\node (C) at (2.9, -2.5) {\scriptsize{}};
\end{tikzpicture}
\label{fig:MinmaxVsSum-a}}
\vspace{-5mm}
\end{figure}
}
Thus, , where .  Note that  is a necessary condition, by definition of . Let us next compute~.



We first build some intuition of . The figure above illustrates all possible cases, the circle and the shaded area represent the unit circle  and the ellipse , respectively. So, . Note that  is simply the magnitude of some vector in , which is spanned by vectors in . Now consider scenario 1, where . The scenario~1-cases (a),(b) yield , where the subscript of  denotes the scenario and the cases. The scenario 1-case~(c) yields . Now consider scenario 2, where . Clearly, the scenario~2-case~(a) doesn't exist. If scenario~2-case~(b),  is a set with  points, i.e.,  is on one of the  points, \cf~the open circles in (b). Moreover, because \texttt{B} knows ,  is either at  or , i.e., , \cf~figure (b). Thus, . If scenario~2-case~(c), we similarly get , the line segment of length , \cf~figure (c), i.e., . The  when  is similarly computed.

Based on our privacy index, . The first inequality clearly agrees with out intuition. The second equality agrees with our intuition in the sense that the ambiguity in  is identical in the associated two settings. The last inequality can be intuitively explained as follows: scenario 1,2-case (c) corresponds to a setting where the beacon measurements are linearly dependent, and therefore the beacon~1 can be any point along the line , as opposed to scenario 2-case (b), where the beacon measurements are not linearly dependent.}
\end{Exx}


\subsection{Transformation via Change of Variables}\label{subsec:chg_of_variable}

\addnew
{
Suppose the decision variable  in problem~\eqref{eq:optimization_prob} is in . Let  be a function  such that . Now consider the problem, denoted \texttt{Q}, achieved by the change of variables . Then \texttt{Q} is equivalent to problem~\eqref{eq:optimization_prob} in the sense that if  solves \texttt{Q}, then  solves problem~(\ref{eq:optimization_prob}). Note again that any potential obfuscation of problem data (\cf~Definition~\ref{def:Obsf_Unctnty}) is directly linked to the function compositions, , , and .
}

\addnew
{
All the approaches in~\cite{Mangasarian-OptLet-2011,Dreier-Kerschbaum-2011,Mangasarian-OptMethSW-2011,Bednarz-Bean-Roughan-2009,Wang-Ren-Wang-11,Bednarz-2012,Mangasarian-Wild-2008,Mangasarian-Wild-Fung-2008} can be obtained as a particular case of the \emph{change of variables}. In particular, those methods uses an affine . Let us now give an example for a case where  is not necessarily affine.}
\begin{Exx}[\addnew{Resource allocation}]\label{ex:nonlinear_change_variables}
\addnew
{
Suppose an ammunition supply depot (\texttt{ASD}) wants to transfer -types of nuclear-ammunition to the war field. Let  denote the radiation per unit volume of th ammunition type. The overall radiation should be no greater than a specified value . The containers for each type~ should be cubic of length . The criterion for computing the volume of type~ is determine by the penalty function , where  denote the priority levels of the th type. Suppose the \texttt{ASD} relies on a third party to compute the desired container box lengths , by   and . The problem data is , , and . On the other hand, suppose the ASD does not want to reveal the input tuples , .

What if ASD uses the change of variable  for all . Then it is sufficient to ask the third party (say \texttt{B}) to  ,
with variable  and problem parameters .
This method requires the transmission of the message  to \texttt{B}. Suppose \texttt{B} knows the dependence of  on  and the positivity of . Therefore, , which corresponds to . This is the highest possible privacy for an input tuple in , \cf~Proposition~\ref{prop:privacy_index}-(a).}
\end{Exx}


One can readily apply hybrid variants of the \emph{transformation via change of variables} and \emph{transformation of objective and constraints},~\cf~\cite{Dreier-Kerschbaum-2011,Wang-Ren-Wang-11}.


\subsection{Decomposition Methods}\label{subsec:decomposition_based_method}
\addnew
{
In this section, we highlight important aspects of decomposition methods for preserving privacy of problem data. In particular, the dual decomposition method is considered. Arguments, in the case of primal decomposition methods and ADMM method are similar.}



\addnew
{
We start by noting that the \emph{decomposition} methods are applied whenever the problem structure inherently possesses some separability properties, where the original problem can be solved by coordinating smaller subproblems, one for each subsystem. Thus, instead of problem~\eqref{eq:optimization_prob}, the general problem we consider in this section is given by

where the variables are  and , and  denotes the subsystem index. Typically, ,  and  are called local, interface, and global variables, respectively. The matrix  is a - matrix that maps  into the interface variables . This mapping accounts for the coupling of the problem and ensures consensus between subsystem interface variables and the global variables. The set  is the constraints at the subsystem~ and is dependent on the private problem data~. }\addnew{
Let us now summarize the standard dual decomposition algorithm and see how it preserves privacy for private data~.
\begin{Algg}\label{alg:dual_decomp_algorithm}
\noindent \emph{Dual Decomposition}

Given  such that . Set .

\textbf{while} \mbox{(stopping criterion)}

\begin{enumerate}
\item[1.] Subsystem~  , with . Let  denote the solution.
\item[2.] Subsystems coordinate to update global , i.e., .
\item[3.] Subsystem~ updates  as, . Set .
\end{enumerate}
\end{Algg}


In the algorithm above,  is an appropriate step size~\cite{Bertsekas-Tsitsiklis-97}. As far as the privacy of the problem data is concerned, the crucial step of the algorithm is step~2. This is because the coordination requires exchange of messages, which are dependent on the problem data. In particular, the th subsystem requires revealing message, denoted , where  and  is the number of iteration before the algorithm termination. Note that  is, in fact, the subgradients of dual master objective function~\cite{Bertsekas-Tsitsiklis-97}. Therefore, any potential obfuscation of problem data of subsystem~ is directly linked to the computed subgradients until the algorithm termination, i.e., . An example is given below.
}
\addnew{
\begin{Exx}[Average consensus]\label{ex:QP_multi_party_constraints_coupled}
Consider the computation of the arithmetic average  of  scalars, denoted , where each  is private to subsystem~. Note that  is simply the argument  that minimizes . This minimization can be equivalently posed as

with variables  and . Let us next show, without loss of generality, how Algorithm~\ref{alg:dual_decomp_algorithm} achieves privacy for input tuple  of subsystem~, given adversary is .

Note that the step~1 of Algorithm~1 is
\vspace{-5mm}
\be\label{eq:consensus}
y^{(k)}_i(c_i)\asign (c_i-\lambda_i/2) \ .
\ee
The step~2 is simply the average  and step~3 is . Thus, the message exposed by subsystem~ to subsystem~ is , where  is the total iterations.


Without explicitly describing the relation  (or equivalently the uncertainty set ), we use an alternative method, where the associated  is computed by construction. Now note that if for ,  and  satisfy \eqref{eq:consensus} for all , so is , where  is chosen such that . Indeed,  here parameterizes the uncertainty set . In particular, , which yields . This is the highest possible privacy for an input tuple in , \cf~Proposition~\ref{prop:privacy_index}-a).

Even though, we assume that subsystem  is a passive adversary (\cf~Definition~\ref{def:adversary}), it is easily seen that, even if  number of subsystems collude,  remains intact, given . In other words, as long as subsystem~ has at least one reliable subsystem~, , .
\end{Exx}
}
\addnew
{
}




\section{Conclusions}\label{sec:conclusions}
\addnew{
In this paper, a mechanism to quantify the privacy of a broader class of optimization approaches was proposed. We defined a one-to-many relation, which relates a given adversarial observed message to an uncertainty set of the problem data. The privacy measure was then designed based on the uncertainty sets. The properties of the proposed privacy measure was analyzed. From the definition it is clear that optimization based approaches lacks robustness to adversarial attacks, such as those involving side information. Our privacy definition clearly model those intrinsic properties of optimization approaches. The key ideas were illustrated by examples. An important possible extensions is to explore ways of designing optimization approaches to guarantee a specified privacy level.







}



\bibliographystyle{IEEEbib}
\bibliography{jour_short,conf_short,references,references_PPO}
\end{document}
