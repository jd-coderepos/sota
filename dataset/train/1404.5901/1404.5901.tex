

\documentclass[10pt,twocolumn,twoside]{IEEEtran}

\usepackage{fixltx2e}
\usepackage{etex}
\usepackage[noadjust]{cite}
\usepackage[cmex10]{amsmath}
\usepackage{amssymb}
\usepackage{bm}
\usepackage{mathcomp}
\usepackage{dsfont}
\usepackage{ellipsis}
\usepackage{graphicx}
\usepackage[caption=false,font=footnotesize]{subfig}
\usepackage{enumerate}
\usepackage{flushend}		

\renewcommand{\log}[1]{\ensuremath{\text{log}\!\left(#1\right)}}		\newcommand{\abs}[1]{\ensuremath{\lvert#1\rvert}}										\newcommand{\norm}[1]{\ensuremath{\lVert#1\rVert}}									\newcommand{\norminf}[1]{\ensuremath{\lVert#1\rVert_\infty}}				\newcommand{\normone}[1]{\ensuremath{\lVert#1\rVert_1}}							\newcommand{\vm}[1]{\ensuremath{\bm{\mathrm{#1}}}}									\newcommand{\mc}[1]{\ensuremath{\mathcal{#1}}}											\newcommand{\trans}{\ensuremath{\mathsf{T}}}												\newcommand{\Z}{\ensuremath{\mathds{Z}}}														\newcommand{\C}{\ensuremath{\mathbb{C}}}														\newcommand{\sg}[2]{\ensuremath{g_{\mathrm{#1},#2}}}								\newcommand{\sw}[1]{\ensuremath{w_{\mathrm{#1}}}}										\newcommand{\swtilde}[1]{\ensuremath{\tilde{w}_{\mathrm{#1}}}}			\newcommand{\spsi}[2]{\ensuremath{\psi_{\mathrm{#1},#2}}}						\newcommand{\seta}[2]{\ensuremath{\eta_{\mathrm{#1},#2}}}						\newcommand{\setatilde}[2]{\ensuremath{\tilde{\eta}_{\mathrm{#1},#2}}}   \newcommand{\salpha}[2]{\ensuremath{\alpha_{\mathrm{#1},#2}}}				\newcommand{\sbeta}[2]{\ensuremath{\beta_{\mathrm{#1},#2}}}					\newcommand{\sgamma}[2]{\ensuremath{\gamma_{\mathrm{#1},#2}}}				

\hyphenation{Forschungs-zentrum Lip-sch-itz}


\begin{document}

\title{Linearization of Time-Varying Nonlinear Systems Using A Modified Linear Iterative Method}

\author{Matthias~Hotz,~\IEEEmembership{Student Member,~IEEE,}
        Christian~Vogel,~\IEEEmembership{Senior Member,~IEEE}\thanks{The research leading to these results has received funding from the FFG
Competence Headquarter program under the project number 835187.}\thanks{Matthias Hotz was with FTW, Austria. He is now with the Associate Institute for
Signal Processing, Technische Universit{\"a}t M{\"u}nchen, Germany (e-mail: hotz@ieee.org).}
\thanks{Christian Vogel is with FTW, Austria (e-mail: c.vogel@ieee.org).
The Austrian Competence Center FTW Forschungszentrum Telekommunikation Wien GmbH
is funded within the program COMET - Competence Centers for Excellent Technologies
by BMVIT, BMWFJ, and the City of Vienna. The COMET program is managed by the FFG.}}

\maketitle


\begin{abstract}
The linearization of nonlinear systems is an important digital
enhancement technique. In this paper, a real-time capable post- and pre-linearization
method for the widely applicable time-varying discrete-time Volterra
series is presented. To this end, an alternative view on the Volterra
series is established, which enables the utilization of certain modified
linear iterative methods for linearization. For one particular linear
iterative method, the Richardson iteration, the corresponding post- and pre-linearizers are discussed
in detail. It is motivated that the resulting algorithm can be regarded
as a generalization of some existing methods. Furthermore, a simply verifiable
condition for convergence is presented, which allows the straightforward
evaluation of applicability. The proposed method is demonstrated by means
of the linearization of a time-varying nonlinear amplifier, which highlights
its capability of linearizing significantly distorted signals, illustrates the
advantageous convergence behavior, and depicts its robustness against modeling errors.
\end{abstract}

\begin{IEEEkeywords}
Linearization, equalization, digital predistortion, nonlinear systems, time-varying systems,
Volterra series, iterative methods, Richardson iteration, th-order inverse. \end{IEEEkeywords}

\IEEEpeerreviewmaketitle


\section{Introduction}
	\label{intro}

\IEEEPARstart{D}{igital} enhancement techniques became an effective
approach to improve the performance of analog systems due to rapid
advances in semiconductor technology~\cite{murmann2008}.
Linearization of nonlinear systems via real-time capable methods, as investigated in this paper,
is a particular digital enhancement technique. It is applied, e.g.,
to sensor linearization~\cite{zhuang2004}, amplifier predistortion~\cite{morgan2006},
channel equalization~\cite{benedetto1983}, and loudspeaker linearization~\cite{lashkari2006}.
The purpose of a linearizer is to compensate for the nonlinear behavior
of a nonlinear system, i.e., the nonlinear system in cascade with a
corresponding linearizer results in a defined linear behavior.
A special case thereof is equalization, where the targeted linear
behavior is the identity function.

Due to the lack of a unifying model for nonlinear systems, linearizers
are generally limited to a particular class of systems and, of course, linearization
is only possible if the nonlinear system preserves all information
(cf, e.g.,~\cite{geiger2011}). In this paper, nonlinearities
described by a \emph{time-varying discrete-time Volterra series} are considered. The
Volterra series is a widely used approximator for weakly nonlinear
systems~\cite{schetzen1980,rugh1981,mathews2000}. The objective of this paper is
the construction of a linearizer for a \emph{known} time-varying
discrete-time Volterra series. 
For the time-invariant Volterra series, the special case of equalization has already been
considered by Schetzen~\cite{schetzen1976} via the concept of a th-order inverse.
A th-order inverse is constructed by constraining the Volterra operators of the
overall system, i.e., the cascade of the nonlinear system and the th-order inverse. The
constraint applies to the Volterra operators up to order , whereas the operators
of higher order are arbitrary. Sarti and Pupolin~\cite{sarti1992} utilized
the fact that orders greater than  of the overall system are not constrained
to derive a recursive synthesis scheme for a th-order inverse that is less
complex compared to the th-order inverse in~\cite{schetzen1976}. However,
the analysis of the existence and convergence of a th-order inverse is
nontrivial and addressed, e.g., in~\cite{fang2001} for signals with finite energy.
An approach to linearization of the time-invariant Volterra series
is discussed by Nowak and Van Veen in~\cite{nowak1997}, where the
linearization problem is reformulated as a nonlinear fixed-point equation, which
is solved via successive approximation. They provide
an analysis of convergence with respect to a ``windowed  norm,'' which, again,
turns out as a nontrivial task. Aschbacher et al.~\cite{aschbacher2004} (cf.~\cite{redfern1998} as well)
reduce the linearization problem for a time-invariant Volterra series to
the root-finding problem, which is solved using the Newton method. However,
for this iterative algorithm the crucial analysis of convergence is even more
involved and the corresponding conditions have not been reported yet.
As all these methods are limited to time-invariant nonlinear systems, it is worthwhile
to mention that for linear time-varying (LTV) systems equalization techniques have already
been introduced. They may be divided roughly into two classes~\cite{vogel2012},
explicitly designed correction filters, where the equalization problem is posed as a
filter design problem~\cite{johansson2006,johansson2008}, and iterative correction filters,
where the desired equalization result is approximated iteratively~\cite{vogel2009,
tsui2011b,soudan2012}.

\subsection{Contributions and Outline}
	\label{intro:contrib}

Real-world nonlinear systems often vary with time, e.g., due to
temperature variations or other environmental changes.
However, all existing methods for nonlinear systems reviewed
above consider only a \emph{time-invariant} Volterra series. Although
it is possible to extend the methods in~\cite{schetzen1976,sarti1992} and~\cite{nowak1997} to
the time-varying Volterra series~\cite{soudan2011}, they potentially become prohibitively complex
in computational terms. This stems from the fact that the th-order inverse in~\cite{schetzen1976}
and~\cite{sarti1992} as well as the method in~\cite{nowak1997} require a (stable) inverse filter
for the first-order Volterra operator. This time-varying inverse filter is usually not known and,
in practice, has to be approximated using filter design techniques as discussed, e.g., in~\cite{vogel2012}.
Therefore, a change of the first-order Volterra operator implies the need for a computationally
costly filter design of its inverse.
Furthermore, the condition for convergence of all aforementioned methods is
either missing, very restrictive on the input signal, or rather complicate to
evaluate. Finally, it must be pointed out that in~\cite{soudan2011} a post-equalizer
for a time-varying Volterra series based on a nonlinear fixed point iteration is
discussed briefly, however, it completely lacks the critical analysis of convergence.
In this paper, the issues above are addressed via the following contributions:
\begin{enumerate}[a)]
	\item \emph{Alternative view on the Volterra series}: In Section~\ref{model}, an
		alternative description of the Volterra series
		is established, which provides a framework for the derivation of linearization
		methods based on certain modified linear iterative methods.
	\item \emph{Post- and pre-linearization}: Using this system model,
		a modification of the Richardson iteration is proposed in Section~\ref{mlim}, which permits its
		application for post- and pre-linearization of a time-varying
		discrete-time Volterra series as discussed in Sections~\ref{postlin} and~\ref{prelin}.
		The presented method is independent of the inverse of the first-order Volterra operator
		and, therefore, offers a computational advantage compared to the methods
		in~\cite{schetzen1976,sarti1992}, and~\cite{nowak1997} since the repeated and
		computationally costly inverse filter design is not necessary.
	\item \emph{Condition for convergence}: In Section~\ref{conv}, a sufficient condition
		for convergence is presented, which is particularly simple to evaluate and only requires
		a bounded input signal. Therewith, the applicability of the introduced linearization
		method is easily verified.
	\item \emph{Generalization}: In Section~\ref{relation}, it is shown that the
		proposed method is a generalization of the equalization
		method for LTV systems in~\cite{soudan2012}.
		Furthermore, it is motivated that the presented approach can be regarded as a generalization
		of the post-linearization method in~\cite{nowak1997} as well as the th-order inverse.
\end{enumerate}
Section~\ref{results} presents simulation results, which demonstrate the
proposed method by means of the linearization of a time-varying nonlinear amplifier
and highlight its properties.
Finally, Section~\ref{conclusion} concludes the paper. The theory presented in this
paper requires two results for the time-varying discrete-time Volterra series which
have not been established yet and, therefore, are contributed via the appendix of
this paper:
\begin{enumerate}
	\item[e)] \emph{Properties of a time-varying discrete-time Volterra series:}
		In Appendix~\ref{bibo}, the conditions for the convergence
		of a time-varying discrete-time Volterra series are presented.
		Furthermore, in Appendix~\ref{errprop}, it is proven that a convergent time-varying discrete-time
		Volterra series is Lipschitz continuous.
\end{enumerate}

\subsection{Relation to Adaptive Nonlinear Equalization}

In practical application scenarios, the nonlinear system is usually not
known and, as a consequence, two approaches towards linearization emerge, i.e.,
(a) the direct identification of the linearizer, and
(b) the identification of the nonlinear system and construction
of the linearizer. For (a), adaptive nonlinear filters may be utilized, e.g.,~\cite{mathews1991}.
However, the identification is complicated by the model selection as
the structure of the linearizing system is usually not known.
In contrast, for (b) the nonlinear system is identified,
whose structure is often known, e.g., in terms of its circuit schematics,
topology, or physical properties. This simplifies the model selection and,
consequently, the identification, which motivates the utilization of the
approach in (b) that may use the construction of the linearizer
discussed in this paper. The identification of a Volterra series is discussed, e.g.,
in~\cite{mathews2000,glentis1999,nemeth2002,weng2006,giannakis2001}
and is not addressed in this paper. 

\begin{figure}[!t]
	\centering
	\includegraphics{hotz1.pdf}
	\caption{Volterra system  with input signal  and output signal .}
	\label{fig:volterrasystem}
\end{figure}

\begin{figure*}[!t]
	\centering
	\includegraphics{hotz2.pdf}
	\caption{Richardson equalizer based on the Volterra system 
		with three iterations of~\eqref{eq:richeq} and the initialization in~\eqref{eq:richinit}.
		Due to the finite number of iterations, the reconstruction  is only an approximation
		of the desired reconstruction result .}
	\label{fig:richeq}
\end{figure*}



\section{System Model}
	\label{model}

The nonlinear system is modeled by a \emph{time-varying discrete-time Volterra series}, i.e.,
its complex-valued output sample  at time instant  is given
by~\cite{schetzen1980,rugh1981,mathews2000}

where  is the complex-valued input signal and  are the
complex-valued \emph{time-varying Volterra
kernels}.\footnote{In its most general form, the Volterra series includes a term of order ,
i.e., a time-varying offset . However, to simplify the discussion it is common
to require that the offset is compensated separately~\cite{mathews1991} and, therefore,
it is assumed that .} Throughout this paper, it is assumed that the Volterra series
converges for the given input signal, cf. Appendix~\ref{bibo} for a discussion of convergence.
As a simplified representation, the time-varying Volterra series operator  is defined
to describe the relation in~\eqref{eq:vsdef}, i.e.,

and the nonlinear system is referred to as the \emph{Volterra system}  in the remainder
of the text, cf. Fig.~\ref{fig:volterrasystem}.
For the derivation of the linearization algorithm proposed in this paper,
a new view on the Volterra system is established.
To this end, the sum over  in~\eqref{eq:vsdef} is evaluated as the outermost
sum and  is factored out, which permits the reformulation

where

The equivalent description in~\eqref{eq:vsconv} of the Volterra system
in~\eqref{eq:vsdef} resembles an LTV system with the time-varying impulse response
in~\eqref{eq:gxn}. However, the pretended impulse response  is not only time-varying
by means of a dependence of the coefficients on the time index , which is denoted by
the subscript , but depends on the input signal  as well, which is indicated by
the subscript  and symbolizes its \emph{nonlinear} nature.
The system description in~\eqref{eq:vsconv} can also be
cast in a matrix equation. Let  denote the space of bi-infinite
complex-valued sequences. The input vector  is defined as

and comprises the samples of the input signal .
Analogously, the output vector  is defined as

and comprises the samples of the output signal . Furthermore, an infinite
coefficient matrix  is defined,
whose elements  are given by

in which  denote the row and column index, respectively, and
where the subscript  denotes the dependence on the input vector .
Therewith, the matrix equation

constitutes an equivalent description of~\eqref{eq:vsconv} and, consequently,
of the Volterra system  in~\eqref{eq:vsdef}.

\subsection{Problem Statement}
	\label{model:problem}

Consider the case of an equalizer that is connected to the output of
the Volterra system  in Fig.~\ref{fig:volterrasystem}.
Then, equalization is the task of finding the input vector  given the
output vector  and the Volterra system . 
With the previously introduced system model, the unknown input vector
 can be found by solving the ``system of linear equations'' in~\eqref{eq:mtxeq}.
Indeed, post- and pre-linearization can be recast
as a problem with such a structure, which is discussed later on.
However, the coefficient matrix 
depends on the solution  and, therefore, is \emph{unknown}.
Furthermore, if the resulting algorithm should be real-time capable and, thus,
reconstruct the signal sample by sample, it has to operate row by row with
respect to the matrix equation. Consequently, in order to solve the linearization problem
at hand, an algorithm to solve the ``system of linear equations'' in~\eqref{eq:mtxeq}
is required, which (a) \emph{operates row by row} and
(b) \emph{determines the coefficient matrix}  alongside
the solution  by exploiting the structural knowledge.

\section{Modified Linear Iterative Method}
	\label{mlim}

There exist certain \emph{linear iterative methods}~\cite{kelley1995, isaacson1994, saad2003}
for solving systems of linear equations, whose iteration steps operate
row by row and, therefore, address problem (a) in Section~\ref{model:problem}.
These methods reformulate the problem of solving a system of linear
equations as a \emph{linear fixed-point problem}, which is solved using \emph{successive
approximation}~\cite{kelley1995}. A fixed-point equation comprises a function , where
the image of the solution  of the system of linear equations under 
is ~\cite{kelley1995}, i.e., .
There exist various approaches to rewrite a matrix equation of the form
in~\eqref{eq:mtxeq} as a fixed-point equation,
which eventually leads to different linear iterative methods~\cite{kelley1995,isaacson1994,saad2003}.
This paper focuses on the \emph{Richardson iteration},
but other linear iterative methods, e.g., the Jacobi and Gau\ss-Seidel iteration,
are applicable as well. Let  denote the identity matrix, then
adding  to the left and right hand side
of~\eqref{eq:mtxeq} results in the fixed-point equation

If the fixed-point  is determined using successive approximation,
the \emph{Richardson iteration} is obtained~\cite{kelley1995}, i.e.,

in which  is the iteration index.
Therefore, given an initial approximation  of the solution , this iteration
provides a sequence of approximations, which, under certain conditions, converges to the
fixed-point , i.e., .

\subsection{Modified Richardson Iteration}

The Richardson iteration in~\eqref{eq:richiter} requires the knowledge of the
coefficient matrix  and, consequently, cannot overcome problem
(b) in Section~\ref{model:problem}. It reconstructs the unknown input vector
 by iteratively improving an initial approximation  using the
output vector  and the \emph{unknown} coefficient matrix .
However, in iteration  the approximation  is already available and may
be used to approximate the coefficient matrix. To this end, in analogy to~\eqref{eq:axdef} the approximation
 of  based on  is defined in
terms of its elements  in row  and in column  as

where  and

Substitution of the coefficient matrix  in the Richardson iteration
in~\eqref{eq:richiter} with the approximation  yields

This modified Richardson iteration does not only generate approximations of the input vector , but
also of the coefficient matrix  and, consequently, overcomes problem (b)
in Section~\ref{model:problem} as well. Indeed, it provides a solution to a
significant class of systems as shown by the condition for convergence discussed
in Section~\ref{conv} later on.

\subsection{Richardson Equalizer}
	\label{mlim:richeq}

\begin{figure}[!t]
	\centering
	\includegraphics{hotz3.pdf}
	\caption{The post-linearizer for the Volterra system 
		generates an output signal  that corresponds to the response of the
		LTI filter  to the input signal , cf.~\eqref{eq:xludef}.}
	\label{fig:hnpostlin:a}
\end{figure}
\begin{figure}[!t]
	\centering
	\includegraphics{hotz4.pdf}
	\caption{Stimulation of the augmented Volterra system  with the signal 
		results in the same signal  as in Fig.~\ref{fig:hnpostlin:a} if the LTI
		filter  that relates  and  possesses a stable inverse filter .}
	\label{fig:postlinaltsys}
\end{figure}


The modified Richardson iteration in~\eqref{eq:richeqvec} is a matrix equation, but
for a real-time capable algorithm, the iteration needs to be sample-based. Therefore,
consider the evaluation of~\eqref{eq:richeqvec} row by row. Using~\eqref{eq:xvec},
\eqref{eq:yvec}, and~\eqref{eq:axrdef}, this results in

A comparison of the convolution of  with  to~\eqref{eq:vsconv}
reveals that it equals the response of the Volterra system  to the
input signal . Hence, a real-time capable algorithm based on the modified Richardson iteration,
for convenience called \emph{Richardson equalizer} in the remainder, is described by the
iteration

If  is causal,~\eqref{eq:richeq} is indeed realizable as a sample-based iteration,
i.e., the reconstruction  of the sample  depends only on previous
reconstructions , where . 
While the approximation  will equal the desired input sample 
if  and if the iteration converges,
a practical system can, of course, only implement a finite number of iterations.
This is not a limitation per se as the number of iterations can be
chosen so that the accuracy of the approximation suffices for the specific application.
However, this statement assumes that the approximation improves in every iteration or,
in other words, the error with respect to the solution decreases in every iteration.
This iterative reduction of the error is indeed ensured by the conditions for
convergence discussed in Section~\ref{conv}.
Still, the finite number of iterations introduces another issue, i.e.,
the initialization  influences the approximation accuracy.
While the initialization may be chosen arbitrarily, e.g., ,
it should be as close to the solution  as possible to improve the approximation result.
In Section~\ref{conv}, it is shown that the iteration in~\eqref{eq:richeq} converges
for \emph{moderately} nonlinear systems.
Under these circumstances, the output is a rough approximation of the input and
it turns out to be advantageous to use the initialization

Concluding, a Richardson equalizer based on three iterations of~\eqref{eq:richeq}
with the initialization in~\eqref{eq:richinit} is depicted in Fig.~\ref{fig:richeq}.

\begin{figure}[!t]
	\centering
	\includegraphics{hotz5.pdf}
	\caption{The pre-linearizer for the Volterra system 
		generates a signal  to which  responds with a signal 
		that corresponds to the response of the
		LTI filter  to the input signal , cf.~\eqref{eq:vlydef}.}
	\label{fig:hnprelin:a}
\end{figure}
\begin{figure}[!t]
	\centering
	\includegraphics{hotz6.pdf}
	\caption{Stimulation of the augmented Volterra system  with the signal 
		results in the same signal  as in Fig.~\ref{fig:hnprelin:a} if the LTI
		filter  that relates  and  possesses a stable inverse filter .}
	\label{fig:prelinaltsys}
\end{figure}



\section{Post-Linearization}
	\label{postlin}

Linearization is the problem of correcting the nonlinear behavior of a
given system to a defined linear behavior by cascading it with another
system, where the latter system is called
\emph{linearizer}. As the cascade of two nonlinear systems,
in general, exhibits a different behavior depending on the ordering of the
systems, two configurations arise, i.e., post- and pre-linearization.
In the case of post-linearization of a Volterra system , the
linearizer is connected to the output of  as depicted in
Fig.~\ref{fig:hnpostlin:a} and termed \emph{post-linearizer}
to distinguish it from the pre-linearizer discussed in Section~\ref{prelin}.
The desired behavior of the cascade is described by the linear time-invariant
(LTI) filter , i.e., the output signal  of the cascade is given by

in which  is the input signal of the cascade. Consequently, the task of the
post-linearizer is to reconstruct the signal  by observation of the signal  and
knowledge of the Volterra system . Given that the LTI filter  is
minimum-phase and, thus, possesses a stable inverse filter , i.e.,

the signal  in Fig.~\ref{fig:hnpostlin:a} can be regarded as the response
of an augmented Volterra system  to the input signal .
To this end, consider that the Volterra system  is the cascade of the
inverse filter  and the Volterra system , i.e.,

in which  denotes cascade connection. Then, the signal 
can be described as

which is illustrated in Fig.~\ref{fig:postlinaltsys}.
This corresponds to the relation in~\eqref{eq:hndef},
where the Richardson equalizer introduced in Section~\ref{mlim} provides
the means to reconstruct the signal . Consequently, the Richardson
equalizer described by the iteration~\eqref{eq:richeq} based on the Volterra
system  in~\eqref{eq:hnbreve} with the initialization in~\eqref{eq:richinit}
constitutes a post-linearizer for the Volterra system .


\section{Pre-Linearization}
	\label{prelin}

In the case of pre-linearization of a Volterra system ,
often called \emph{digital predistortion} as well, the
linearizer is connected to the input of  as depicted in
Fig.~\ref{fig:hnprelin:a} and termed \emph{pre-linearizer}.
The desired behavior of the cascade is described by the LTI filter ,
i.e., the output signal  of the cascade is given by

in which  is the input signal of the cascade. Consequently, the task of the
pre-linearizer is to reconstruct the signal  by observation of the signal  and
knowledge of the Volterra system  so that  filtered by 
results in the desired output signal  in~\eqref{eq:vlydef}. Analogous to
Section~\ref{postlin}, the signal  in Fig.~\ref{fig:hnprelin:a} can be regarded
as the response of an augmented Volterra system  to the input signal 
if the LTI filter  possesses a stable inverse filter .
To this end, consider that the Volterra system  is the cascade of
the Volterra system  and the inverse filter , i.e.,

Then, the signal  can be described as

which is illustrated in Fig.~\ref{fig:prelinaltsys}.
Again, it can be observed that this corresponds to the
relation in~\eqref{eq:hndef} and, thus, the Richardson equalizer provides
the means to synthesize the signal . Consequently, the Richardson
equalizer described by the iteration~\eqref{eq:richeq} based on the Volterra
system  in~\eqref{eq:hnring} with the initialization in~\eqref{eq:richinit}
constitutes a pre-linearizer for the Volterra system .

It is important to recognize that there is a difference in the approximation
mechanism between post- and pre-linearization if the Richardson equalizer
is utilized with a \emph{finite} number of iterations. With post-linearization, the
approximation generated by the Richardson iteration appears directly at the
output, i.e., any decrease in the approximation error is directly visible.
In the case of pre-linearization, the approximation generated by the Richardson
iteration traverses the Volterra system  before appearing at the output
of the cascade, i.e., the approximation is subject to a \emph{nonlinear} filtering
operation. However, as shown in Appendix~\ref{errprop}, a time-varying discrete-time
Volterra series is \emph{Lipschitz continuous} if it converges.
This implies that if the approximation error at the input decreases, the upper
bound on the approximation error at the output decreases as well. In other words,
an improvement in approximation accuracy at the input results in an improvement of
the worst-case approximation accuracy at the output and, consequently, the
application of the pre-linearizer is indeed appropriate.


\section{Conditions for Convergence}
	\label{conv}

The application of the Richardson equalizer or any
other iterative method is only reasonable if the iteration converges to the
solution. In order to study the conditions under which convergence of the
Richardson equalizer can be guaranteed, the error  in
iteration  is defined as

in which \vm{x} is the solution that satisfies the fixed-point equation
in~\eqref{eq:richitervec} and  is the approximation in
iteration  of the Richardson equalizer~\eqref{eq:richeqvec} in matrix notation.
The subtraction of~\eqref{eq:richeqvec} from~\eqref{eq:richitervec} and
utilization of~\eqref{eq:er1def} results in

which depicts the influence of the error  in the previous
iteration and the approximation error 
of the coefficient matrix. The Richardson equalizer converges to  if
the error decays to zero, i.e., .
An even more restrictive requirement is

which has to hold for all iterations .
In~\eqref{eq:ermondec},  denotes the supremum norm~\cite{rudin1964}, i.e.,
it requires the supremum of the error signal to be \emph{strictly} monotonically
decreasing with respect to the iteration index .\footnote{Note
that any valid norm may be used in~\eqref{eq:ermondec} and that the choice has an impact on the derivation
and the resulting condition for convergence. Due to its beneficial structure,
the supremum norm is employed.} In this case,
the approximation error needs to decrease in every iteration, which corresponds to
the requirement on the Richardson equalizer for a finite number of iterations
identified in Section~\ref{mlim:richeq}. Using~\eqref{eq:er1eq},
it is shown in Appendix~\ref{ccderi1} that if the function

of a Volterra system  satisfies the \emph{condition for convergence}

then \eqref{eq:ermondec} holds for the Richardson equalizer in~\eqref{eq:richeq}
with the initialization in~\eqref{eq:richinit}.
In~\eqref{eq:richpsi},  denotes the unit impulse sequence, i.e.,

 is defined as the sum of the absolute coefficients of the
th-order Volterra kernel at time instant , i.e.,

and the weighting factor  is given by

For practical systems, which operate only for a finite time,
the condition in~\eqref{eq:richcondconv} is particularly
simple to verify as it suffices to ensure that 
holds at \emph{every} time instant . This is simply a threshold on a weighted
sum of the absolute kernel coefficients, where the weights
depend on the input amplitude range which is usually known.

It follows from the condition in~\eqref{eq:richcondconv}
that the rate of time-variance of the Volterra system
has no impact on whether the Richardson equalizer converges as long as
 consistently remains below the threshold. Furthermore, it is worthwhile to mention that the coefficient ,
i.e., the coefficient of the first-order Volterra kernel
at time lag zero, is of particular significance since only its
difference from one contributes to the sum in~\eqref{eq:richpsi}.
Considering that the threshold on  in~\eqref{eq:richcondconv} is one,
this implies that the coefficient  is restricted to the open
interval  and, in general, it must be dominant, i.e.,
all other coefficients must be small compared to
. However, by appropriately delaying signals and
matching time indices, this restriction may be loosened
to some arbitrary coefficient of the first-order
Volterra kernel, instead of being mandatory for the coefficient at time lag .
As the corresponding structural modifications equal those for the method
in~\cite{soudan2012}, a detailed discussion thereof is omitted here
(see also Section~\ref{relation:ltveq}).

\subsection{Remarks to the Condition for Linearization}

If the Richardson equalizer is utilized for post- and pre-linearization,
the Volterra system  is the cascade of an LTI filter and a Volterra
system as given by~\eqref{eq:hnbreve} and~\eqref{eq:hnring}.
In order to discuss the implications thereof on the condition for convergence,
let the inverse filter  of the minimum-phase LTI filter 
be characterized by the impulse response , i.e.,

As shown in Appendix~\ref{linkernels}, the kernels of the Volterra
system  in~\eqref{eq:hnbreve} for post-linearization are given by

and the kernels of the Volterra system  in~\eqref{eq:hnring}
for pre-linearization are given by

Those results show that the rather restrictive condition for
convergence in~\eqref{eq:richcondconv} is mitigated as it applies
to the Volterra systems  and  only \emph{relative}
to the LTI filter . To exemplify this, consider  and
 to model a nonlinear amplifier of gain , where the
desired behavior  is an ideal amplifier with gain . Thus,
 is characterized by

In case of pre-linearization, it follows from~\eqref{eq:hpnprelindef}
that the kernels  equal the kernels  weighted by .
Therefore, the coefficients are weighted so that only the nonlinearity
relative to the linear gain has impact on the condition for convergence.
In case of post-linearization, it follows from~\eqref{eq:hpnpostlindef} that the
kernels  equal the kernels  weighted by .
However, in this setting the linearizer operates on the amplified signal,
cf. Fig.~\ref{fig:hnpostlin:a}. To investigate the implications in terms
of the unamplified signal , it is recognized from~\eqref{eq:xludef}
that . It can be seen from the
weighting factor in~\eqref{eq:wdef} that this amplification results in
an additional factor  for . Therefore, the weighting
of the kernels  does not only relate them to  by
weighting with , but also accounts for the change in signal amplitude by
including the factor .


\section{Relation to Other Methods}
	\label{relation}

\begin{figure}[!t]
	\centering
	\includegraphics{hotz7.pdf}
	\caption{
		Equivalent implementation of the post-linearization method in~\cite{nowak1997}
		and the th-order inverse in~\cite{kafka2002} for the Volterra system
		 using the post-linearizer in Section~\ref{postlin} with
		 set to the identity function.}
	\label{fig:nowakvsrich}
\end{figure}


\subsection{Equalization of Linear Weakly Time-Varying Systems}
	\label{relation:ltveq}

Soudan and Vogel~\cite{soudan2012} proposed an equalizer for linear weakly time-varying systems
which is based on the Richardson iteration. The method proposed in this paper
can be regarded as the generalization of the method in~\cite{soudan2012} from linear
to nonlinear systems and from equalization to linearization. In particular, if the
Volterra system  comprises only a linear (first-order) kernel, the
Richardson equalizer equals the iteration in~\cite{soudan2012}. Furthermore,
for a linear system the condition for convergence in~\eqref{eq:richcondconv} reduces to the
criterion provided in~\cite{soudan2012}.

\subsection{Nonlinear Iterative Methods}

Instead of applying modified linear iterative methods to~\eqref{eq:mtxeq},
it is possible to directly formulate a nonlinear fixed-point equation
based on~\eqref{eq:vsdef} and solve it via successive approximation as
presented by Nowak and Van Veen~\cite{nowak1997}. However, let the
first-order Volterra operator 
of the Volterra system  be defined as

and possess an inverse ,
which is a fundamental assumption in~\cite{nowak1997}.
Then, the post-linearizer in~\cite{nowak1997} for , which is realized as a
post-equalizer followed by an LTI filter, equals
the post-linearizer in Section~\ref{postlin} followed by the same LTI filter,
if the latter linearizer is based on the Volterra system

and  is set to the identity function, see Fig.~\ref{fig:nowakvsrich}.
In fact, it equals the extension of the post-linearizer in~\cite{nowak1997}
to \emph{time-varying} systems and also illustrates the dependence on the inverse
 considered in Section~\ref{intro:contrib}.
Consequently, the presented method may be regarded as a generalization
of the post-linearizer in~\cite{nowak1997}, as the latter amounts to the application
of the proposed post-linearizer to the augmented Volterra system  in~\eqref{eq:hncheck}.

\subsection{th-Order Inverse}

Due to the fact that the definition of a th-order inverse does
not constrain the Volterra kernels of order greater than  of the
overall system, different realizations exist~\cite{schetzen1976,sarti1992,kafka2002}.
If the post-linearizer in Section~\ref{postlin}, with  set to the identity
function, is applied to  in~\eqref{eq:hncheck} using the initialization

the resulting iteration equals the extension of the recursive synthesis technique for a
th-order inverse in~\cite[ch.~5.2.3]{kafka2002} to \emph{time-varying} systems,
cf. Fig~\ref{fig:nowakvsrich}.\footnote{The th-order inverse
in~\cite{kafka2002} is specified by the recursive scheme (5.24) therein. Adding
 to this equation, utilizing the
linearity of , and recognizing that  leads to
,
in which . This
recursive scheme corresponds to the iteration implemented by the post-linearizer in
Fig.~\ref{fig:nowakvsrich}.}
That is, the reconstruction after  iterations corresponds to the reconstruction
of the th-order inverse. Consequently, the
presented method may be regarded as a generalization of the th-order inverse
as well, as the latter constitutes a particular application of the presented post-linearizer.


\section{Simulation Results}
	\label{results}

In the following, the post- and pre-linearization methods introduced in this
paper are demonstrated by means of the linearization of a
nonlinear amplifier with time-varying gain and dynamic saturation.
This amplifier is modeled by the Volterra system  comprising the kernels

in which the coefficient vectors , , and 
with zero-based element indexing are given by

and the time-varying gain  is defined as

In the latter,  is the fundamental gain of the amplifier and
 denotes the number of samples used for the simulation. For the sake
of consistent notation, an equivalent Volterra system 
is defined for pre-linearization. The desired behavior of the amplifier is
an ideal gain of factor , i.e., the LTI filter  implements .
Consequently, its inverse  is characterized by the impulse
response  in~\eqref{eq:linvqdef}. The input to the amplifier shall
be bounded by  and, therefore, it follows from Fig.~\ref{fig:hnpostlin:a}
and~\eqref{eq:xludef} that for post-linearization

and from Fig.~\ref{fig:hnprelin:a} that for pre-linearization

The input signal to the nonlinear amplifier is the modulated sine wave

Consequently, the desired output
signal is . To achieve this output, the input is set to 
for post-linearization in Fig.~\ref{fig:hnpostlin:a} and to  for
pre-linearization in Fig.~\ref{fig:hnprelin:a}.
Depending on the bound  on the input of the nonlinear amplifier,
the distortion of the output signal varies and, in the following,
the linearization is studied for mildly, moderately, and severely
distorted output signals. Subsequently, the section concludes with
an investigation of the influence of modeling errors.


\subsection{Mild Distortion}
	\label{results:mild}

\begin{figure}[!t]\centering \includegraphics{hotz8.pdf}\caption{The solid line depicts the output signal of the nonlinear
	amplifier for  when stimulated with  in~\eqref{eq:sndef}. To support the
	visual evaluation of the time-varying gain and dynamic saturation,
	the envelope of the desired output signal is shown as a dashed line.}\label{fig:inoutcmpb075}\end{figure}\begin{figure}[!t]\centering \includegraphics{hotz9.pdf}\caption{SNR after post- and pre-linearization of the nonlinear amplifier with 
	with respect to the number of iterations performed in the Richardson equalizer.
	For  iterations, the SNR relates to the output signal without linearization.}\label{fig:snrb075}\end{figure}


For  the output signal of the nonlinear amplifier is only
mildly distorted as shown in Fig.~\ref{fig:inoutcmpb075}. The applicability
of the post- and pre-linearization methods is verified
using~\eqref{eq:simpostxinf} and~\eqref{eq:simprexinf} and the definition
of  in~\eqref{eq:hpnpostlindef} and~\eqref{eq:hpnprelindef}
in~\eqref{eq:richpsi}, respectively, to determine .
The maxima of  are at , which is significantly less
than one, and thus the condition in~\eqref{eq:richcondconv} guarantees convergence.
The linearization performance is measured with the signal-to-noise ratio (SNR)

which is a logarithmic measure for the deviation from the desired output signal . 
Post- and pre-linearization is performed with the Richardson equalizer in~\eqref{eq:richeq}
using  in~\eqref{eq:hnbreve} and~\eqref{eq:hnring}, respectively, and the initialization
in~\eqref{eq:richinit}. In Fig.~\ref{fig:snrb075}, the linearization performance is depicted
in terms of SNR with respect to the number of iterations employed in the Richardson
equalizer. It can be observed that both linearizers converge very fast. The improvement in
SNR per iteration is significant and it increases approximately linear with the number of
iterations. The performance for pre-linearization is somewhat inferior to that of
post-linearization, which is primarily a consequence of the nonlinear filtering of the
approximation as discussed in Section~\ref{prelin}.

\subsection{Moderate Distortion}
	\label{results:moderate}

\begin{figure}[!t]\centering \includegraphics{hotz10.pdf}\caption{The solid line depicts the output signal of the nonlinear
	amplifier for  when stimulated with  in~\eqref{eq:sndef}.}\label{fig:inoutcmpb1}\end{figure}\begin{figure}[!t]\centering \includegraphics{hotz11.pdf}\caption{SNR after post- and pre-linearization of the nonlinear amplifier with 
	with respect to the number of iterations performed in the Richardson equalizer.}\label{fig:snrb1}\end{figure}


For  the output signal of the nonlinear amplifier is moderately
distorted as shown in Fig.~\ref{fig:inoutcmpb1}. In this case, the maxima
of  are at , which is just below one, and thus the
condition in~\eqref{eq:richcondconv} still guarantees convergence.
The linearization performance is depicted in Fig.~\ref{fig:snrb1}.
It can be observed that the improvement in SNR per iteration is still significant, but less compared to
the performance for the mildly distorted signal in Fig.~\ref{fig:snrb075}. This
behavior is a consistent property of the Richardson equalizer, i.e., the
closer the bound imposed by the condition in~\eqref{eq:richcondconv}
is attained, the slower is the convergence.
Another characteristic observable in Fig.~\ref{fig:snrb1} is the deterioration in performance of
the pre-linearizer compared to the post-linearizer. Although this is, in part, explained by the
argument provided in the previous section, another issue becomes
evident here. In particular, the pre-linearizer operates on the signal 
and convergence is ensured for  bounded by~\eqref{eq:simprexinf}.
Thus, it is implicitly assumed that the maximum gain of the pre-linearizer is
one. For mild distortions this is approximately true, but for moderate and severe distortions
the pre-linearizer needs to compensate the saturation effect by amplification of the
input signal. Consequently, some samples are outside the bound of guaranteed convergence
and deteriorate the performance, a case which is investigated in more detail in the next section.

\subsection{Severe Distortion}

\begin{figure}[!t]\centering \includegraphics{hotz12.pdf}\caption{The solid line depicts the output signal of the nonlinear
	amplifier for  when stimulated with  in~\eqref{eq:sndef}.}\label{fig:inoutcmpb130}\end{figure}\begin{figure}[!t]\centering \includegraphics{hotz13.pdf}\caption{SNR after post- and pre-linearization of the nonlinear amplifier with 
	with respect to the number of iterations performed in the Richardson equalizer.}\label{fig:snrb130}\end{figure}
\begin{figure}[!t]\centering \subfloat[Error without linearization.]{\includegraphics{hotz14a.pdf}}\hfil \subfloat[Error after pre-linearization with  iterations.]{\includegraphics{hotz14b.pdf}}\caption{Error reduction for pre-linearization of the nonlinear amplifier with .
	In (b), it can be observed that for the majority of samples the iteration has
	practically converged. However, at the six major signal peaks the iteration
	starts to diverge, causing the SNR to deteriorate.}\label{fig:errorreductionpreb130}\end{figure}

For the moderate distortion discussed in the previous section, the bound
imposed by the condition in~\eqref{eq:richcondconv} is nearly attained.
Therefore, it represents the amount of distortion for which convergence
is guaranteed by this condition. However, \eqref{eq:richcondconv} is derived
by the repeated application of the triangle inequality, utilization of the
supremum norm as an upper bound on individual samples, and the upper bound
in~\eqref{eq:e0ltx}, cf. Appendix~\ref{ccderi1}. As the latter bound is not
exact and the worst case in terms of the other bounds appears to be quite
improbable, it is reasonable to try to linearize more severly distorted signals.
To this end, consider the input of the nonlinear amplifier to be bounded by .
The corresponding output signal is depicted in Fig.~\ref{fig:inoutcmpb130}.
In this case,  is between  and , which is
significantly above one, and thus the condition in~\eqref{eq:richcondconv}
cannot guarantee convergence.
However, the linearization performance in Fig.~\ref{fig:snrb130} illustrates that
the post-linearizer still converges. In case of the pre-linearizer, the issue identified
in the previous section becomes more severe. Due to the strong saturation, the pre-linearizer
needs to substantially amplify the signal peaks. The SNR initially improves because the
iteration converges for the majority of samples, but finally it starts to deteriorate
because of the divergence at the signal peaks as illustrated in Fig.~\ref{fig:errorreductionpreb130}.
In this context, it is important to recognize that due to the structure of the Richardson
equalizer in~\eqref{eq:richeq} and the memory in  the divergence can propagate to
neighboring samples with repeated iterations.
Concluding, the condition for convergence is rather conservative and the linearization
method presented in this paper may be utilized in cases of more severe distortion. However,
it should be kept in mind that the rate of convergence decreases and that
it may involve the risk of divergence induced by signal peaks.


\subsection{Modeling Errors}

The previous examples assumed that the nonlinear amplifier is perfectly
known. However, in practice the model is usually only an
approximation of the actual nonlinear system and, therefore, the impact of
modeling errors on the linearization performance is of interest.
In the following, this is investigated by employing the erroneous coefficient vectors

in the Volterra system used for linearization, which represents
a significant modeling error with respect to the nonlinear amplifier
based on the coefficient vectors in~\eqref{eq:coeffnlamp}. The
corresponding linearization performance is depicted in Fig.~\ref{fig:snrb1:moderr}
for . For the augmented Volterra system with modeling errors, the maxima of
 are at  and, therefore, convergence is guaranteed.
Indeed, the SNR increases in the first two iterations but, subsequently,
the convergence stalls. This stems from the
fact that the linearizers effectively linearize a \emph{different} Volterra
system, i.e., they converge to a different solution and the linearization
performance is limited by this deviation. Consequently, the
proposed linearization method is robust against modeling errors if the
condition for convergence is satisfied and the limitation in linearization
performance is determined by the severity of the modeling errors.

\begin{figure}[!t]\centering \includegraphics{hotz15.pdf}\caption{SNR after post- and pre-linearization of the nonlinear amplifier with 
	in the presence of modeling errors.}\label{fig:snrb1:moderr}\end{figure}



\section{Conclusion}
	\label{conclusion}

In this paper, a novel real-time capable method for the linearization of nonlinear systems
modeled by a time-varying discrete-time Volterra series was presented.
To this end, an alternative view on the Volterra series was established,
which resembles the description of an LTV system. Based on this system model,
a systematic approach to the modification of certain linear iterative methods was
proposed that permits their use for linearization. The modification was
presented for the Richardson iteration and its
utilization for post- and pre-linearization was discussed in detail.
It was shown that the resulting method is a generalization of the equalizer for
linear weakly time-varying systems in~\cite{soudan2012} and that it may
be regarded as a generalization of the post-linearizer in~\cite{nowak1997}
and the th-order inverse.
Due to the iterative structure of the proposed linearizers, their computational cost
scales with the required accuracy via the employed number of iterations.
With the presentation of a simply verifiable
condition for convergence, a practical tool to determine the applicability
of the method was established. By means of the linearization of a time-varying
nonlinear amplifier, the application of the proposed method was exemplified
and properties thereof were discussed. It was shown that the condition for
convergence can guarantee the applicability for mildly to moderately
distorted signals. In this case, the linearizers perform very well and the
iteration converges fast. Consequently, one or two iterations of the
underlying fixed-point iteration may already suffice to achieve a
practically relevant accuracy. It was demonstrated that the
method is also applicable to severely distorted signals, however,
by trading slower convergence and the risk of divergence.
Finally, it was shown that the method
is robust against modeling errors and that the performance penalty
is determined by the severity of the modeling errors.

The proposed method offers considerable potential for future research. Specifically,
the method was presented on the basis of the Richardson iteration, but it is
not limited to this particular linear iterative method. Therefore, other linear
iterative methods like the Jacobi or Gau\ss-Seidel iteration may be explored as
well, which includes the derivation of the corresponding modified iteration and
condition for convergence. Additionally, a preconditioner in terms of a
relaxation parameter might be incorporated to improve the convergence behavior.
In specific scenarios, where further information about the input
signal is available, a more elaborate performance analysis might be performed
by means of the derivation of a worst-case and average rate of convergence.
These results may also aid the design of practical systems as they support
the choice of the employed number of iterations.


\appendices


\section{Convergence of a Time-Varying\\ Discrete-Time Volterra Series}
	\label{bibo}

A time-varying discrete-time Volterra series  is \emph{convergent}
if the output of the system is finite for a given input signal~\cite{boyd1984}. For a further
analysis of convergence, let the supremum norm 
be the bound on the input signal . Using the triangle inequality, the bound
 on the input, and  in~\eqref{eq:hpnnorm}, it follows
from  in~\eqref{eq:vsdef} that

Let the \emph{bound function}  at time instant  be defined as (cf.~\cite{boyd1984})

Then it follows from~\eqref{eq:yub} that

Consequently, if a time-varying discrete-time Volterra series 
satisfies the condition

it converges for all input signals bounded by .
The bound function  in~\eqref{eq:bndfct} is a power series with non-negative coefficients
and, therefore, is finite for , where the radius of
convergence  is given by~\cite{rudin1964,boyd1984}

This implies that a time-varying discrete-time Volterra series 
satisfies~\eqref{eq:gbfltinfty} and, thus, converges if 

in which  is the \emph{radius of convergence}.


\section{Lipschitz Continuity of a Time-Varying Discrete-Time Volterra Series}
	\label{errprop}

A time-varying discrete-time Volterra series  is \emph{Lipschitz continuous} if

holds, where the system model in Section~\ref{model} is used,  is non-negative
and finite, and  and  are two input signal vectors
with the corresponding coefficient matrices  and
 in~\eqref{eq:axdef} and~\eqref{eq:axrdef}, respectively.
In the following, it is shown that a \emph{convergent} time-varying discrete-time
Volterra series  is Lipschitz continuous.\footnote{In fact, 
for a time-varying discrete-time Volterra series  with a radius of convergence
,  stimulated by the input vector  is continuous if 
and Lipschitz continuous if , cf. the proof
for the continuous-time Volterra series in~\cite{boyd1984}.}
The approach below is an adaptation of the corresponding proof for
the time-invariant continuous-time Volterra series in~\cite{boyd1984}.
Let  and  be two input vectors, where the difference
is given by  in~\eqref{eq:er1def}. Furthermore, let

in which  is the radius of convergence of . Thus,  is convergent
for  and  because  and

respectively, where the latter is obtained from the definition of 
in~\eqref{eq:er1def} by taking the supremum norm
and applying the triangle inequality. Using~\eqref{eq:axdef}, \eqref{eq:axrdef},
 defined in~\eqref{eq:gammadef} in Appendix~\ref{gammaub},
and the triangle inequality, the upper bound

is obtained. Using the upper bound~\eqref{eq:gammaabsub2} in Appendix~\ref{gammaub} on
 as well as 
in~\eqref{eq:hpnnorm} and the bound function  in~\eqref{eq:bndfct} enables

From the mean value theorem it follows that~\cite{rudin1964,boyd1984}

where  is the derivative of  and

Using this relation in~\eqref{eq:axryrubgbf} yields

which corresponds to~\eqref{eq:lipdef} where

Due to~\eqref{eq:gbfltinfty},~\eqref{eq:xerltr}, and~\eqref{eq:mvtgbf},  in~\eqref{eq:kappadef}
is indeed non-negative and finite, which completes the proof.


\section{Condition for Convergence for\\ the Richardson Equalizer}
	\label{ccderi1}

In this appendix, it is proven that~\eqref{eq:richcondconv}
guarantees convergence of the Richardson equalizer in~\eqref{eq:richeq}
with the initialization in~\eqref{eq:richinit} by showing that
it is a \emph{sufficient} condition for~\eqref{eq:ermondec} to hold.

\subsection{Problem Statement}

Using  in~\eqref{eq:er1eq} and the definition of
 and  in~\eqref{eq:axdef}
and~\eqref{eq:axrdef}, respectively, the error
 in iteration  at time instant  can be expressed as

Therewith, the supremum norm of  is upper bounded using
the triangle inequality as

where the first and second sum is given by
 and 
in~\eqref{eq:alphadef} and~\eqref{eq:betadef} in
Appendix~\ref{alphaub} and~\ref{betaub}, respectively. Using the upper bounds~\eqref{eq:alphaub}
and~\eqref{eq:betaub} for  and 
derived in Appendix~\ref{alphaub} and~\ref{betaub}, respectively, it follows that

where

and

It can be observed that  is monotonically
increasing with respect to the non-negative argument ,
which is relevant later on. Indeed, only
 depends on 
and, as can be seen in~\eqref{eq:wtildedef}, it is a polynomial of degree  with
non-negative coefficients and, therefore, monotonically increasing.
According to~\eqref{eq:er1leqereta}, if

holds for all iterations ,
the condition for convergence in~\eqref{eq:ermondec} holds as well. In the
following, sufficient conditions for~\eqref{eq:condeta} to hold in the
first iteration are derived. Subsequently,
this result is used for an inductive proof of convergence under the same conditions.


\subsection{Error Reduction in First Iteration}
	\label{ccderi1:base}
	
Due to the initialization in~\eqref{eq:richinit} and the system model in~\eqref{eq:mtxeq},
the initial error  is given by

With the definition of  in~\eqref{eq:axdef}, the supremum norm
of the initial error can be identified as

Due to the upper bound on  in~\eqref{eq:alphaub}
in Appendix~\ref{alphaub}, this norm is upper bounded by

where

A comparison of  to 
in~\eqref{eq:etardef} reveals that 
for all . Consequently, any condition that ensures~\eqref{eq:condeta}
enforces

as well. Therefore, it can be assumed that the initial error is bounded by

because a contradiction in this inequality would also invalidate~\eqref{eq:condeta}.
Due to the fact that  in~\eqref{eq:etardef}
is a monotonically increasing function for non-negative arguments, it follows
that

Consequently, requiring

ensures that~\eqref{eq:condeta} holds for the first
iteration and, therefore, .
Rewriting~\eqref{eq:er1def}, taking the supremum norm, and applying the
triangle inequality leads to~\eqref{eq:xrleqxer} and permits the bound

Using this upper bound in~\eqref{eq:wtildedef} for the argument 
gives\footnote{A comparison of  to the binomial theorem
shows that it corresponds to .}

Finally, utilizing this upper bound on  in~\eqref{eq:etardef} to
obtain an upper bound on  and, subsequently, using the result
in~\eqref{eq:supetaxnlt1} leads to the condition for convergence in~\eqref{eq:richcondconv}.


\subsection{Inductive Proof of Convergence}

Convergence of the Richardson equalizer can be ensured by induction if

holds, as, due to~\eqref{eq:er1leqereta}, this implies that~\eqref{eq:ermondec} holds.
The condition for convergence in~\eqref{eq:richcondconv} establishes the basis

which follows from \eqref{eq:etaxne0ltetaxnx} and~\eqref{eq:supetaxnlt1}. As a
consequence of~\eqref{eq:er1leqereta}, this basis implies .
As  is a monotonically increasing function for
non-negative arguments, it follows that~\eqref{eq:etar1leqetar} holds for 
and, due to~\eqref{eq:er1leqereta},~\eqref{eq:ermondec} holds for .
This induction step can be repeated ad infinitum and, therefore, completes the proof.


\section{Upper Bound for }
	\label{alphaub}

In this appendix, an upper bound for the absolute value of

is derived. Using the triangle inequality and the supremum norm 
as an upper bound on  yields

Substitution of  with~\eqref{eq:gxn} and application of the
triangle inequality permits the upper bound

With the supremum norm  as an upper bound on 
and  in~\eqref{eq:hpnnorm}, 
is upper bounded by



\section{Upper Bound for }
	\label{betaub}

In this appendix, an upper bound for the absolute value of

is derived. Using the triangle inequality and the supremum norm 
as an upper bound on  yields

Substituting the impulse responses with~\eqref{eq:gxn} and~\eqref{eq:gxrn}, respectively,
applying the triangle inequality, and utilizing 
defined in~\eqref{eq:gammadef} in Appendix~\ref{gammaub} results in the upper bound

Using the upper bound~\eqref{eq:gammaabsub1} on
 in Appendix~\ref{gammaub} 
and  in~\eqref{eq:hpnnorm} yields

Finally, using~\eqref{eq:gxrgxabssumub} in~\eqref{eq:betaabssumub} permits the upper bound



\section{Upper Bound for }
	\label{gammaub}

In this appendix, an upper bound for the absolute value of

is derived, where . Using the definition of 
in~\eqref{eq:er1def}, the absolute value of 
can be expressed as

If the first product therein is expanded, it contains a summand
that cancels with the second product. In order to find
an upper bound on the remaining terms, the first product is analyzed.
Using the triangle inequality and  and 
as upper bounds on  and , respectively, enables

For this bound, the binomial theorem gives

in which . It can be recognized that  corresponds to the
upper bound of the term that cancels with the second product in~\eqref{eq:gammaxer}
and, therefore,

Equivalently, this bound can be stated as



\section{Kernels of the Volterra System  for\\ Post- and Pre-Linearization}
	\label{linkernels}

\subsubsection{Post-Linearization}

For post-linearization, the Volterra system  is given by~\eqref{eq:hnbreve}.
From Fig.~\ref{fig:postlinaltsys} and the definition of the Volterra system
in~\eqref{eq:vsdef} it follows that

Using the definition of  in~\eqref{eq:linvdef} and  in~\eqref{eq:linvdefconv}
results in

The substitution , for , and
partition of the product yields

A comparison to~\eqref{eq:vsdef} shows that  is given by~\eqref{eq:vsdef}
with the Volterra kernels in~\eqref{eq:hpnpostlindef}.


\subsubsection{Pre-Linearization}

For pre-linearization, the Volterra system  is given by~\eqref{eq:hnring}.
From Fig.~\ref{fig:prelinaltsys} and the definition of  in~\eqref{eq:linvdefconv}
it follows that

Furthermore, from Fig.~\ref{fig:prelinaltsys} and the definition of the Volterra
system in~\eqref{eq:vsdef} it follows that  is given by

Using~\eqref{eq:prekernv} in~\eqref{eq:prekerny} yields

The substitution , for , results in

A comparison to~\eqref{eq:vsdef} shows that  is given by~\eqref{eq:vsdef}
with the Volterra kernels in~\eqref{eq:hpnprelindef}.


\bibliographystyle{IEEEtran}
\bibliography{tsp2014_hotz_vogel}

\vspace*{3em}

\end{document}
