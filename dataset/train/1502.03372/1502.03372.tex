
\documentclass[11pt]{article} 

      
\usepackage{geometry, array, xcolor}             
\usepackage{amsmath,amsfonts,graphicx, amssymb, placeins}
\usepackage{algorithm}
\usepackage[noend]{algpseudocode}
\usepackage{enumerate, url}
\usepackage{xargs}
\usepackage{cite}
\usepackage{subfig}
\usepackage{enumitem}
\usepackage[colorinlistoftodos]{todonotes}
\usepackage{dsfont}
\usepackage{soul}
\usepackage{xcolor}
\usepackage{footnote}
\makesavenoteenv{tabular}
\makesavenoteenv{table}
\usepackage{times}
\usepackage{titlesec}
\titlespacing*{\section}{6pt}{6pt}{6pt}
\titlespacing*{\subsection}{4pt}{4pt}{4pt}

\makeatletter
\def\mathcolor#1#{\@mathcolor{#1}}
\def\@mathcolor#1#2#3{\protect\leavevmode
  \begingroup
    \color#1{#2}#3\endgroup
}
\makeatother

\geometry{
  width=6.5in,
  height = 9in,
  left=1in,
  top=1in
}

\addtolength{\topsep}{-10pt}
\addtolength{\partopsep}{-5pt}
\addtolength{\itemsep}{-3pt}

\makeatletter
\g@addto@macro\normalsize{\setlength\abovedisplayskip{3pt}
  \setlength\belowdisplayskip{3pt}
  \setlength\abovedisplayshortskip{3pt}
  \setlength\belowdisplayshortskip{3pt}
}
\makeatother

\newcommand{\wratio}{R_w}

\DeclareGraphicsExtensions{.pdf,.png,.jpg}


\let\proof\relax
\let\endproof\relax
\usepackage{amsthm}

\makeatletter
\def\thm@space@setup{\thm@preskip=0pt
\thm@postskip=3pt}
\makeatother

\newtheorem{theorem}{Theorem}[section]
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{proposition}[theorem]{Proposition}
\newtheorem{claim}[theorem]{Claim}
\newtheorem{fact}[theorem]{Fact}
\newtheorem{corollary}[theorem]{Corollary}
\newtheorem{definition}[theorem]{Definition}
\newtheorem{observation}[theorem]{Observation}
\newenvironment{proof-sketch}{{\bf Proof Sketch:}}{\hfill\rule{2mm}{2mm}}
\newenvironment{note}{\noindent\textbf{Note:}}

\makeatletter
\newenvironment{proofof}[1]{\par
  \pushQED{\qed}\normalfont \topsep3\p@\relax
  \trivlist
  \item[\hskip\labelsep
        \bfseries
    Proof of #1\@addpunct{.}]\ignorespaces
}{\popQED\endtrivlist\@endpefalse
}
\makeatother

\makeatletter
\renewcommand{\paragraph}{\@startsection{paragraph}{4}{\z@}{1ex \@plus 1ex \@minus .2ex}{-.5em}{\normalfont\normalsize\bfseries}}
\makeatother

\newif\iffullpaper
\fullpapertrue 


\newcommand\Mark[1]{\textsuperscript#1}

\title{{A Fast Distributed Stateless Algorithm for -Fair Packing Problems}}
\author{
Jelena Mara\v{s}evi\'{c}\thanks{Supported in part by the NSF grant CNS-10-54856 and a Qualcomm Innovation Fellowship.}\\ 
Columbia University\\
{\tt jelena@ee.columbia.edu}\\
\and
Cliff Stein \thanks{Supported in part by the NSF grants CCF-1349602 and CCF-1421161.}\\
{Columbia University}\\
{\tt cliff@ieor.columbia.edu}\\
\and
Gil Zussman\thanks{Supported in part by the NSF grant CNS-10-54856 and the People Programme (Marie Curie Actions) of the European Union's Seventh Framework Programme (FP7/2007-2013) under REA grant agreement n[PIIF-GA-2013-629740].11.}\\
{Columbia University}\\
{\tt gil@ee.columbia.edu}
} 
\date{}

\newcommand{\littlesum}{\mathop{\textstyle\sum}}

\newcommand{\red}[1]{\textcolor{red}{#1}}

\iffullpaper
\allowdisplaybreaks[1]
\fi

\begin{document}
\maketitle
\begin{abstract}
Over the past two decades, fair resource allocation problems have received considerable attention in a variety of application areas. However, \emph{little progress has been made in the design of distributed algorithms with convergence guarantees for general and commonly used -fair allocations}.  In this paper, we study weighted -fair packing problems, that is, the problems of maximizing the objective functions (i)  when ,  and (ii)  when , over linear constraints , , where  are positive weights and  and  are non-negative. We consider the distributed computation model that was used for packing linear programs and network utility maximization problems. Under this model, \emph{we provide a distributed algorithm for general } that converges to an approximate solution in time (number of distributed iterations) that has an inverse polynomial dependence on the approximation parameter  and poly-logarithmic dependence on the problem size. \emph{This is the first distributed algorithm for weighted fair packing with poly-logarithmic convergence in the input size.} The algorithm uses simple local update rules and is stateless (namely,  it allows asynchronous updates, is self-stabilizing, and allows incremental and local adjustments). We also obtain a number of structural results that characterize fair allocations as the value of  is varied. These results deepen our understanding of fairness guarantees in fair packing allocations, and also provide insight into the behavior of fair allocations in the asymptotic cases , , and .  
\end{abstract}


\thispagestyle{empty}
\newpage



\section{Introduction}\label{section:intro}
\setcounter{page}{1}
\pagestyle{plain}

Over the past two decades, \emph{fair resource allocation} problems have received considerable attention in many  application areas, including  Internet congestion control \cite{low2002internet}, rate control in software defined networks \cite{mccormick2014real}, scheduling in wireless networks \cite{yi2008stochastic}, {multi-resource allocation and scheduling in datacenters} \cite{bonald2015multi, ghodsi2011dominant, joe2013multiresource, Im2014competitive}, and a variety of applications in operations research,  economics, and game theory
\cite{bertsimas2012efficiency, jain2007eisenberg}. In most of these applications, positive linear (packing) constraints arise as a natural model of the allowable allocations. 

In this paper, we focus on the problem of finding an {\em -fair} vector on the set determined by packing constraints  where all .\footnote{Although in the network congestion control literature the constraint matrix  is commonly assumed to be a 0-1 matrix \cite{kelly1998rate, kelly2014stochastic, yi2008stochastic, paganini2005congestion, MoWalrand2000, low2002internet}, important applications (such as, e.g., multi-resource allocation in datacenters) are modeled by a more general constraint matrix  with arbitrary non-negative elements \cite{bonald2015multi, ghodsi2011dominant, joe2013multiresource, Im2014competitive}.} We refer to this problem as fair packing. 
For a vector of positive weights  and , an allocation vector  of size  is weighted -fair, if for any alternative feasible vector :  \cite{MoWalrand2000}. For a compact and convex feasible region,  can be equivalently defined as a vector that solves the problem of maximizing  \cite{MoWalrand2000}, where: 

-fairness provides a trade-off between efficiency (sum of allocated resources) and fairness (minimum allocated resource) as a function of : the higher the , the better the fairness guarantees and the lower the efficiency \cite{atkinson1970measurement,bertsimas2012efficiency,lan2010axiomatic}.  Important special cases are 
proportional fairness () and max-min fairness ().  When , we have the ``unfair" case of  linear optimization.


Distributed algorithms for fair packing are of particular interest, as many applications are inherently distributed (such as, e.g., network congestion control), while in others parallelization is highly desirable due to the large problem size (as in, e.g., resource allocation in datacenters). We adopt the model of distributed computation commonly used in the design of 
packing linear programming (LP) algorithms \cite{AwerbuchKhandekar2009, d-allen2014using, d-bartal1997global, d-kuhn2006price, d-luby1993parallel, d-papadimitriou1993linear} and which generalizes the model from network congestion control \cite{kelly2014stochastic}.  In this model, an agent  controls the variable  and has information about: (i) the  column of the  constraint matrix , (ii) the weight , (iii) upper bounds on the global problem parameters , and , where , and , and (iv) in each round, the relative slack of each constraint  in which  takes part. 

Distributed algorithms for fair resource allocations have been most widely studied in the network congestion control literature, using a control-theoretic approach \cite{kelly1998rate, kelly2014stochastic, yi2008stochastic, paganini2005congestion, MoWalrand2000, low2002internet}. Such an approach yields continuous-time algorithms that converge after ``finite'' time; however, the convergence time of these algorithms as a function of the input size is poorly understood. Some  other distributed pseudo-polynomial-time approximation algorithms that can address -fair packing are described in Table~\ref{table:prev}. These algorithms all have convergence times that are at least linear in the parameters describing the problem.  

No previous work has given truly fast (poly-log iterations) distributed algorithms for the general case of -fair packing.  Only for the unfair  case (packing LPs), are such algorithms  known \cite{AwerbuchKhandekar2009, d-luby1993parallel, d-bartal1997global, dc-young2001sequential, d-kuhn2006price, d-allen2014using}.


\paragraph{Our Results.} 
\emph{We provide the first  efficient, distributed, {and stateless} algorithm for weighted -fair packing}, namely, for the problem ,  {where distributed agents update the values of 's asynchronously and react only to the current state of the constraints}. We assume that all non-zero entries  of matrix  satisfy . Considering such a normalized form of the problem is without loss of generality (see Appendix \iffullpaper \ref{appendix:scaling}\else {A} in the full version of the paper\fi).  

The approximation provided by the algorithm, to which we refer as the  -approximation, is (i) -multiplicative for , and (ii) -additive\footnote{Note that  cannot be avoided here, as additive approximation is not invariant to the scaling of the objective.} for , where . The main results are summarized in the following theorem, where, to unify the statement of the results, we treat  as a constant that is either equal to 1 or bounded away from 0 and 1, and we also loosen the bound in terms of  and . For a more detailed statement, see Theorems \ref{thm:convergence-alpha<1} -- \ref{thm:convergence-alpha>1}. 
\begin{theorem}
(Main Result) For a given weighted -fair packing problem , where  is given by (\ref{eq:f-alpha}), there exists a stateless and distributed algorithm (\textsc{-FairPSolver}) that computes an -approximate solution in  rounds.   
\end{theorem}

\emph{To the best of our knowledge, for any constant approximation parameter , our algorithm is the first distributed algorithm for weighted -fair packing problems with a poly-logarithmic convergence time.} 

The algorithm is \emph{stateless} according to the definition given by  Awerbuch and Khandekar \cite{AwerbuchKhandekar2009, awerbuch2007greedy}: it starts from any initial state, the agents update the variables  in a cooperative but uncoordinated manner, reacting only to the current state of the constraints that they observe, and without access to a global clock. Statelessness implies various desirable properties of a distributed algorithm, such as: asynchronous updates, self-stabilization, and incremental and local adjustments \cite{AwerbuchKhandekar2009, awerbuch2007greedy}.  

We also obtain the following structural results that characterize fair packing allocations as a function of the value of 
: 
\begin{itemize}[topsep=5pt, leftmargin=10pt]
\itemsep0em 
\item We derive a lower bound on the minimum coordinate of the fair packing allocation as a function of  and the problem parameters (Lemma \ref{lemma:lower-bound}). This bound deepens our understanding of how the fairness (a minimum allocated value) changes with . \item We prove that for , fair packing can be approximated by any approximation packing LP solver (Lemma \ref{lemma:LP-close-to-small-alpha-fair}). This result allows us to focus on the  cases.
\item We show that for , fair allocation is approximated by a fair allocation returned by our algorithm (Lemmas \ref{lemma:alpha-close-to-1-below} and \ref{lemma:alpha-close-to-1-above}).
\item We show that for , the fair packing allocation  and the max-min fair allocation  are -close to each other:  element-wise. This result is especially interesting as {(i)} max-min fair packing is not a convex problem, but rather a multi-objective problem 
(see, e.g., \cite{kleinberg1999fairness, radunovic2007unified}) {and (ii) the result yields the first convex relaxation of max-min fair allocation problems with a  gap}.
\end{itemize}

We now overview some of the main technical details of \textsc{-FairPSolver}.  In doing so, we point out connections to the two main bodies of previous work, from packing LPs\cite{AwerbuchKhandekar2009} and network congestion control \cite{kelly1998rate}. We also outline the new algorithmic ideas and proofs that were needed to obtain the results.  


\paragraph{The algorithm and KKT conditions.}
The algorithm  maintains primal and dual feasible solutions and updates each primal variable  whenever a Karush-Kuhn-Tucker (KKT) condition  is not \emph{approximately} satisfied. {In previous work, relevant update rules include}: \cite{kelly1998rate} (for ), where the update of each variable  is proportional to the difference , and \cite{AwerbuchKhandekar2009} (for ), where each  is updated by a multiplicative factor , whenever  is not {approximately} satisfied. {For our techniques (addressing a general ) such rules do not suffice and we introduce the following modifications}: (i) in the  case we use multiplicative updates by factors  and ,  where  and (ii) we use additional threshold values  to make sure that 's do not become too small.  These thresholds guarantee that we maintain a feasible solution, but they significantly complicate  (compared to the linear case) the argument that each step makes a significant progress.


\paragraph{Dual Variables.} 
In \textsc{-FairPSolver}, a dual variable  is an exponential function of the  constraint's relative slack: , where  and  are functions of global input parameters  and . Packing LP algorithms \cite{AwerbuchKhandekar2009, d-allen2014using, c-plotkin1995fast, d-bartal1997global, c-garg2007faster, c-fleischer2000approximating, c-koufogiannakis2007beating} use similar dual variables {with }. Our work requires choosing  to be a function of  rather than a constant.


\paragraph{Convergence Argument.}
The convergence analysis of \textsc{-FairPSolver} relies on the appropriately chosen concave potential function that is bounded below and above for , , and that increases with every primal update. The algorithm can also be interpreted as a gradient ascent on a regularized objective function (the potential function), using a generalized entropy regularizer (see \cite{d-allen2014using, c-allen2015nearly}). A  similar potential function was used in many works on packing and covering linear programs, such as, e.g., in \cite{AwerbuchKhandekar2009} and (implicitly) in \cite{dc-young2001sequential}. The Lyapunov function from \cite{kelly1998rate} is also equivalent to this potential function when , .  As in these works, the 
main idea in the analysis is to show that whenever a solution  is not ``close" to the optimal one, the potential function increases substantially.
However, our work requires several new ideas in the convergence proofs, the most notable being 
{\em stationary rounds}. A stationary round is roughly a time when the variables  do not change much and are close to the optimum. Poly-logarithmic convergence time is then obtained by showing that: (i) there is at most a poly-logarithmic number of non-stationary rounds where the potential function increases additively and the increase is ``large enough'', and (ii) in all the remaining non-stationary rounds, the potential function increases multiplicatively. 
Our use of stationary rounds is new, as is the use of Lagrangian duality and all the arguments that follow.  

\begin{table}[t]
\begin{center}
\small 
\renewcommand{\arraystretch}{1.1}
  \begin{tabular}{| c | c | c | c |}
    \hline
    \textbf{Paper} & \textbf{Number of Distributed Iterations}\footnote{The convergence times in \cite{cheung2013tatonnement, Beck2014Gradient, mosk2010fully} are not stated only in terms of the input parameters, but also in terms of intermediary parameters that depend on the problem structure. Stated here are our lowest estimates of the worst-case convergence times.} & \textbf{Statelessness} & \textbf{Notes} \\ \hline
     \cite{cheung2013tatonnement} &  &  Semi-stateless\footnote{A distributed algorithm is semi-stateless, if all the updates depend only on the current state of the constraints, the updates are performed in a cooperative but non-coordinated manner, and \emph{the updates need to be synchronous} \cite{d-allen2014using}.} & Only for \\ \hline
     \cite{Beck2014Gradient} &  & Not stateless &\\
    \hline
    \cite{mosk2010fully} & poly() & Semi-stateless & \\
    \hline
    \red{[this work]} & \mathcolor{red}{} & \red{Stateless} &\\
    \hline
  \end{tabular}
\end{center}
\caption{Comparison among distributed algorithms for fair packing.}\vspace{-15pt}
\label{table:prev}
\end{table}


\paragraph{Relationship to Previous Work.}

Very little progress has been made in the design of efficient distributed algorithms for the general class of -fair objectives. 
Classical work on distributed rate control algorithms in the networking literature uses a control-theoretic approach to optimize -fair objectives. While such an approach has been extensively studied and applied to various network settings \cite{kelly1998rate, kelly2014stochastic, yi2008stochastic, paganini2005congestion, MoWalrand2000, low2002internet}, it {has never been proven to have polynomial} convergence time {(and it is unclear whether such a result can be established)}.

Since -fair objectives are concave, their optimization over a region determined by linear constraints is solvable in polynomial time in a centralized setting through convex programming (see, e.g., \cite{boyd2009convex, nesterov2004introductory}). Distributed gradient methods for network utility maximization problems, such as e.g., \cite{Beck2014Gradient, mosk2010fully} summarized in Table \ref{table:prev}, can be employed to address the problem of -fair packing. However, the convergence times of these algorithms depend on the dual gradient's Lipschitz constant to produce good approximations. While \cite{Beck2014Gradient, mosk2010fully} provide a better dependence on the accuracy  than our work, the dependence on the dual gradient's Lipschitz constant, in general, leads to at least linear convergence time as a function of , , and . 

As mentioned before, some special cases have been addressed, particularly for max-min fairness () and for  packing LPs (). Relevant work on max-min fairness includes \cite{Bertsekas:1987:DN:12517, jaffe1981bottleneck, kumar2000fairness, kleinberg1999fairness, megiddo1974optimal, marasevic2014max,charny1995congestion}, but none of these works have poly-logarithmic convergence time.  
There is a long history of interesting work on packing LPs in both centralized and distributed settings, e.g., \cite{c-allen2015nearly, c-plotkin1995fast, c-koufogiannakis2007beating, c-garg2007faster, AwerbuchKhandekar2009, d-luby1993parallel, d-bartal1997global, dc-young2001sequential, d-kuhn2006price, d-allen2014using, garg2002line}.  Only a few of these works are stateless, including 
 the packing LP algorithm of Awerbuch and Khandekar \cite{AwerbuchKhandekar2009}, flow control algorithm of Garg and Young \cite{garg2002line}, and the algorithm of Awerbuch, Azar, and Khandekar \cite{awerbuch2008fast} for the special case of load balancing in bipartite graphs. Additionally, the packing LP algorithm of Allen-Zhu and Orecchia \cite{d-allen2014using} is ``semi-stateless''; the lacking property to make it stateless is that it requires synchronous updates. 
The  case of -fair packing problems is equivalent to the problem of finding an equilibrium allocation in Eisenberg-Gale markets with Leontief utilities (see \cite{cheung2013tatonnement}). Similar to the aforementioned algorithms, the algorithm from \cite{cheung2013tatonnement} converges in time linear in  but also (at least) linear in the input size (see Table 1).

{In terms of the techniques, closest to our work is the work by Awerbuch and Khandekar \cite{AwerbuchKhandekar2009} and we now highlight the differences compared to this work. \emph{Some preliminaries} of the convergence proof follow closely those from \cite{AwerbuchKhandekar2009}: mainly, Lemmas \ref{lemma:feasibility}, \ref{lemma:approx-comp-slack}, and \ref{lemma:potential-increase} use similar arguments as corresponding lemmas in \cite{AwerbuchKhandekar2009}. Some parts of the lemmas lower-bounding the potential increase in , , and  cases (Lemmas \ref{lemma:potential-increase-alpha<1}, \ref{lemma:potential-increase-proportional}, and \ref{lemma:potential-increase-alpha>1}) use similar arguments as \cite{AwerbuchKhandekar2009}, however, even those parts require additional results due to the existence of lower thresholds .}

{The similarity ends here, as the main convergence arguments are different than those used in \cite{AwerbuchKhandekar2009}. In particular, the convergence argument from \cite{AwerbuchKhandekar2009} relying on stationary intervals cannot be applied in the setting of fair objectives. More details about why this argument cannot be applied and where it fails are provided in Section \ref{section:convergence}. As already mentioned, we rely on the appropriately chosen definition of a stationary round. To show that in a stationary round a solution  is approximate, we use Lagrangian duality and bound the duality gap through an intricate case analysis. We remark that such an argument could not have been used in \cite{AwerbuchKhandekar2009}, since in the packing LP case there is no guarantee that the solution  is dual-feasible.
}

\paragraph{Organization of the Paper.} The rest of the paper is organized as follows. Section \ref{section:prelims} provides the background. Section \ref{section:algorithm} describes the algorithm, and Section \ref{section:convergence} \iffullpaper provides \else illustrates \fi the convergence analysis and structural results. \iffullpaper Section \ref{section:conclusion} concludes the paper. \else We conclude in Section \ref{section:conclusion}. {The omitted technical details can be found in the full version of the paper.}\fi

\section{Preliminaries}\label{section:prelims}

\paragraph{Weighted -Fair Packing.} Consider the following optimization problem with positive linear (packing) constraints:

where  is given by (\ref{eq:f-alpha}),  is the vector of variables,  is an  matrix with non-negative elements, and  is a vector with strictly positive\footnote{If, for some , , then trivially , for all  such that .} elements. We refer to  as the weighted -fair packing. 
The following definition and lemma introduced by Mo and Walrand \cite{MoWalrand2000} characterize weighted -fair allocations. In the rest of the paper, we will use the terms weighted -fair and -fair interchangeably.

\begin{definition}
\emph{\cite{MoWalrand2000}} Let  be a vector with positive entries and . A vector   is weighted -fair, if it is feasible and for any other feasible vector : 

\end{definition}
\begin{lemma}
\emph{\cite{MoWalrand2000}} A vector  solves  for functions  if and only if it is weighted -fair.
\end{lemma}

Notice in  that since , , and the partial derivative of the objective with respect to any of the variables  goes to  as , the optimal solution must lie in the positive orthant. Moreover, since the objective is strictly concave and maximized over a convex region, the optimal solution is unique and  satisfies strong duality (see, e.g., \cite{boyd2009convex}). The same observations are true for the scaled version of the problem denoted by  and introduced in the following subsection.


\paragraph{Normalized Form.}We consider the weighted -fair packing problem in the normalized form:

where
,  is defined by (\ref{eq:f-alpha}),  is a vector of positive weights,  is the vector of variables,  is an  matrix with non-negative entries, and  is a size- vector of 1's. We let  denote the maximum element of the constraint matrix , and assume that every entry  of  is non-negative, and moreover, that  whenever . The maximum weight is denoted by  and the minimum weight is denoted by . The sum of the weights is denoted by  and the ratio  by .  We remark that considering problem  in the normalized form  is without loss of generality:  any problem  can be scaled to this form by (i) dividing both sides of each inequality  by  and (ii) working with scaled variables , where . Moreover, such scaling preserves the approximation (\iffullpaper \ref{appendix:scaling} \else {see Appendix A in the full version of the paper}\fi). 

\paragraph{KKT Conditions and Duality Gap}\label{section:lower-bound-duality-gap}
We will denote the Lagrange multipliers for  as  and refer to them as ``dual variables''. The KKT conditions for  are \iffullpaper (see Appendix \ref{appendix:primal-dual-duality-gap})\else {(see Appendix B in the full version)}\fi:
-3pt]
y_i \geq 0, \quad\forall i\in\{1,...,m\} \quad &\text{(dual feasibility)}\tag{K2}\label{eq:K2}\-4pt]
{x_j}^\alpha\littlesum_{i=1}^m y_i A_{ij} = w_j, \quad \forall j\in \{1,...,m\}\quad &\text{(gradient conditions)}\tag{K4}\label{eq:K4}
G_{\alpha}(x, y) = 
\littlesum_{j=1}^n w_j\frac{{x_j}^{1-\alpha}}{1-\alpha}\big({\xi_j}^{\frac{\alpha-1}{\alpha}}-1\big) +\littlesum_{i=1}^m y_i - \littlesum_{j=1}^n  w_j x_j^{1-\alpha}\cdot {\xi_j}^{\frac{\alpha-1}{\alpha}},\label{eq:duality-gap-alpha}

G_1(x, y) = - \littlesum_{j=1}^n w_j \ln\Big(\frac{x_j\small{\sum_{i=1}^m} y_i A_{ij}}{w_j}\Big)+\littlesum_{i=1}^m y_i -W.\label{eq:duality-gap-proportional}
-8pt]
\hrule
\begin{algorithmic}[1]
\vspace{2pt}\Statex (Parameters  and  are set as described in the text below the algorithm.)
\Statex In each round of the algorithm:
\State , 
\State Update the dual variables:  
\If {}
\State 
\Else\If {}
\State 
\EndIf\EndIf
\end{algorithmic}}\vspace{-10pt}
\hrulefill
\caption{Pseudocode of \textsc{-FairPSolver} algorithm.}\vspace{-10pt}
\end{figure}

To allow for self-stabilization and dynamic changes, the algorithm runs forever at all the agents, which is a standard requirement for self-stabilizing algorithms (see, e.g., \cite{dolev2000self}). The convergence of the algorithm is measured as the number of rounds between the round in which the algorithm starts from some initial solution and the round in which it reaches an approximate solution, assuming that there are no hard reset events or node/constraint insertions/deletions in between. 

Without loss of generality, we assume that the input parameter  that determines the approximation quality satisfies  for any , and  for . 
The parameters , , and  are set as follows. For technical reasons (mainly due to reinforcing dominant multiplicative updates of the variables ), we set the values of the lower thresholds  below the actual lower bound of the optimal solution that we derive in Lemma \ref{lemma:lower-bound}:


We denote , . 
The constant  that multiplies the exponent in the dual variables  is chosen as . Because   only depends on  and on global parameters,  we also have , . The parameter  that appears in the exponent of the 's is chosen as . The ``absolute error'' of (\ref{eq:K4})  is set to . For , we set , where the choice of  is described below. For , we set , .

Similar to  \cite{AwerbuchKhandekar2009}, we choose the value of  so that if we set , in any round the value of each  changes by a multiplicative factor of at most . Since the maximum increase over any  in each iteration is by a factor , and  is feasible in each round (see Lemma \ref{lemma:feasibility}), we have that , and therefore, the maximum increase in each  is by a factor of . A similar argument holds for the maximum decrease.  Hence, we choose  so that:

and it suffices to set:


\noindent\textbf{Remark:} In the  cases, since , the maximum decrease in  is by a factor , .

\section{Convergence Analysis}\label{section:convergence}
 
In this section, we analyze the convergence time of \textsc{-FairPSolver}. We first state our main theorems and provide some general results that hold for all . We show that starting from an arbitrary solution, the algorithm reaches a feasible solution within poly-logarithmic (in the input size) number of rounds, and maintains a feasible solution forever after. Similar to \cite{AwerbuchKhandekar2009, dc-young2001sequential, kelly1998rate}, we use a concave potential function that, for feasible , is bounded below and above and increases with any algorithm update. \iffullpaper Then, we analyze the convergence time separately for three cases: , , and . 
With an appropriate definition of a \emph{stationary round} for each of the three cases, we show that in every stationary round,  approximates ``well'' the optimal solution by bounding the duality gap. On the other hand, for any non-stationary round, we show that the potential increases substantially. This large increase in the potential then leads to the conclusion that there cannot be too many non-stationary rounds, thus bounding the overall convergence time. \else Then, we sketch the proof of Theorem \ref{thm:convergence-alpha>1} (), while we defer the full proofs of  the three theorems to the full version of this paper. The main proof idea in all the cases is as follows. With an appropriate definition of a \emph{stationary round} for each of the three cases , , and , we show that in every stationary round,  approximates ``well'' the optimal solution by bounding the duality gap. On the other hand, for any non-stationary round, we show that the potential increases substantially. This large increase in the potential leads to the conclusion that there cannot be too many non-stationary rounds, thus bounding the overall convergence time. \fi

We make a few remarks here. First, we require that  be bounded away from zero. This requirement is without loss of generality because we show that when , any approximation LP provides a approximate solution to  (Lemma \ref{lemma:LP-close-to-small-alpha-fair}). Thus, when  we can switch to the algorithm of \cite{AwerbuchKhandekar2009}, and when , the convergence time remains poly-logarithmic in the input size and polynomial in . Second, the assumption that  in the  case is also without loss of generality, because we show that when  is close to 1 (roughly, ), we can approximate  by switching to the  case of the algorithm (Lemma \ref{lemma:alpha-close-to-1-below}). 
Finally, when , the algorithm achieves an approximation in time . We believe that a polynomial dependence on  is difficult to avoid in this setting, because by increasing , the gradient of the -fair utilities  blows up on the interval : as  increases,  quickly starts approaching a step function that is equal to  on the interval  and equal to 0 on the interval . To characterize the behavior of fair allocations as  becomes large, we show that when , all the coordinates of the fair vector are within a  multiplicative factor of the corresponding coordinates of the max-min fair vector (Lemma \ref{lemma:mmf-alpha-fair}). 

{Finally, we note that the main convergence argument from \cite{AwerbuchKhandekar2009} that uses an appropriate definition of \emph{stationary intervals} does not extend to our setting. The proof from \cite{AwerbuchKhandekar2009} ``breaks'' in the part that shows that the solution is approximate throughout any stationary interval, stated as Lemma 3.7 in \cite{AwerbuchKhandekar2009}. The proof of Lemma 3.7 in \cite{AwerbuchKhandekar2009} is by contradiction: assuming that the solution is not approximate, the proof proceeds by showing that at least one of the variables would increase in each round of the stationary interval, thus eventually making the solution infeasible and contradicting one of the preliminary lemmas. For , unlike the linear objective in \cite{AwerbuchKhandekar2009}, -fair objectives are negative, and the assumption that the solution is not approximate does not lead to any conclusive information. For , adapting the proof of Lemma 3.7 from \cite{AwerbuchKhandekar2009} leads to the conclusion that for at least one , in each round  of the stationary interval , where  is the optimal solution, and  is the solution at round . In \cite{AwerbuchKhandekar2009}, where , this implies that  increases in each round of the stationary interval, while in our setting () it is not possible to draw such a conclusion. }

\paragraph{Main Results.}

Our main results are summarized in the following three theorems. 
The objective is denoted by ,  denotes the solution at the beginning of round , and  denotes the optimal solution.

\begin{theorem}\label{thm:convergence-alpha<1}
(Convergence for ) \textsc{-FairPSolver} solves  approximately for  in time that is polynomial in . In particular, after at most

rounds, there exists at least one round  such that . Moreover, the total number of rounds  in which  is also bounded by (\ref{eq:thm-alpha<1-convergence-time}).
\end{theorem}

\begin{theorem}\label{thm:convergence-alpha=1} (Convergence for ) \textsc{-FairPSolver} solves  approximately in time that is polynomial in . 
In particular, after at most  

rounds, there exists at least one round  such that . Moreover, the total number of rounds  in which  is also bounded by (\ref{eq:alpha=1-conv-time-bound}).
\end{theorem}

\begin{theorem}\label{thm:convergence-alpha>1}
(Convergence for ) \textsc{-FairPSolver} solves  approximately for  in time that is polynomial in . 
In particular, after at most:
 
rounds, there exists at least one round  such that . Moreover, the total number of rounds  in which  is also bounded by (\ref{eq:thm-alpha>1-convergence-time}).
\end{theorem}

\iffullpaper \else Proofs of Theorem \ref{thm:convergence-alpha<1} and Theorem \ref{thm:convergence-alpha=1} are provided in {the full version of the paper}. We sketch the proof of Theorem \ref{thm:convergence-alpha>1} in Section \ref{section:alpha>1}.\fi



\paragraph{Feasibility and Approximate Complementary Slackness.}
The following three lemmas are preliminaries for the convergence time analysis. Lemma \ref{lemma:feasibility} shows that starting from a feasible solution, the algorithm always maintains a feasible solution. Lemma \ref{lemma:self-stabilization} shows that any violated constraint becomes feasible within poly-logarithmic number of rounds, and remains feasible forever after. Combined with Lemma \ref{lemma:feasibility}, Lemma \ref{lemma:self-stabilization} allows us to focus only on the rounds with feasible solutions . Lemma \ref{lemma:approx-comp-slack} shows that after a poly-logarithmic number of rounds,  approximate complementary slackness (KKT condition (\ref{eq:K3})) holds in an aggregate sense: . 

\begin{lemma}\label{lemma:feasibility}
If the algorithm starts from a feasible solution, then the algorithm maintains a feasible solution : ,  and , , in each round.
\end{lemma}
\iffullpaper
\begin{proof}
By the statement of the lemma, the solution is feasible initially. From the way that the algorithm makes updates to the variables , it is always true that , .

Now assume that  becomes infeasible in some round, and let  denote the (feasible) solution before that round,  denote the (infeasible) solution after the round. We have:

For this to be true,  must have increased over at least one coordinate  such that . For such a change to be triggered by the algorithm, it must also be true that:

Since, by the choice of , this term can increase by a factor of at most , it follows that:

This further implies:

and since whenever  we also have , we get:

On the other hand, since , , and :

which contradicts (\ref{eq:feasibility-less-that-wj}).
\end{proof}
\fi

\begin{lemma}\label{lemma:self-stabilization}
If for any : , then after at most  rounds, it is always true that .
\end{lemma}
\begin{proof}
Suppose that  for some . Then , and for every  with :

and therefore, none of the variables that appear in  increases.

Since , there exists at least one  with  such that . For each such , since :

and therefore,  decreases (by a factor ). As , after at most  rounds in which , we must have , and therefore, .
 
Using the same arguments as in the proof of Lemma \ref{lemma:feasibility}, the constraint  never gets violated again.
\end{proof}



\begin{lemma}\label{lemma:approx-comp-slack}
If the algorithm starts from a feasible solution, then after at most  rounds, it is always true that:
\begin{enumerate}[noitemsep,topsep=3pt]
\item There exists at least one approximately tight constraint: , 
\item , and
\item .
\end{enumerate}
\end{lemma}
\iffullpaper
\begin{proof}
Suppose that . Then for each  we have:

Due to Lemma \ref{lemma:feasibility}, we have that  is feasible in every round, which implies that  . This further gives:

and, therefore, all variables  increase by a factor . From Lemma \ref{lemma:feasibility}, since the solution always remains feasible, none of the variables can increase to a value larger than 1. Therefore, after at most  rounds, there must exist at least one  such that . If in any round  decreases, it can decrease by at most . Therefore, in every subsequent round 


For the second part of the lemma, let  be the set of constraints that are at least ``-looser" than the tightest constraint. Then for  we have 

This further gives:

 Moreover, for each  we have , since for :
 
Therefore:

Interchanging the order of summation in the last line, we reach the desired inequality.

The proof of the last part of the lemma follows from feasibility: ,  (Lemma \ref{lemma:feasibility}), and from .\end{proof}
\fi
Lemmas analogous to \ref{lemma:feasibility} and \ref{lemma:approx-comp-slack} also appear in \cite{AwerbuchKhandekar2009}. {However, the proofs of Lemmas \ref{lemma:feasibility} and \ref{lemma:approx-comp-slack} require new ideas compared to the proofs of the corresponding lemmas in \cite{AwerbuchKhandekar2009}. We need to be much more careful in our choice of lower thresholds  and constant  in the dual variables, particularly by choosing  as a function of several variables, rather than as a constant. The choice of 's is also sensitive as smaller 's would make the potential function range too large, while larger 's would cause more frequent decrease of ``small'' variables.  In either case, the convergence time would increase. }\paragraph{Decrease of Small Variables.}

The following lemma is also needed for the convergence analysis. It shows that if some variable   decreases by less than a multiplicative factor , i.e.,  and  decreases, then  must be part of at least one approximately tight constraint. This lemma will be used later to show that in any round the increase in the potential due to the decrease of ``small'' variables is dominated by the decrease of ``large'' variables (i.e., the variables that decrease by a multiplicative factor ). 

\begin{lemma}\label{lemma:small-x-tight-yi}
Consider the rounds that happen after the initial  rounds. If in some round there is  a variable  that decreases, then in the same round for some  with  it holds that:  and .
\end{lemma}
\iffullpaper
\begin{proof}
Suppose that some  triggers a decrease over the  coordinate.
The first part of the Lemma is easy to show, simply by using the argument that at least one term of a summation must be higher than the average, i.e., there exists at least one  with  such that:


For the second part, as , we have that:


Since  decreases, we have that , and therefore  

Moreover, as , and , it follows that:

Observe that for :

while for , since :

where we have used the generalized Bernoulli's inequality for  \cite{mitrinovic1970analytic}, and then .
Recalling that , and combining (\ref{eq:y-bound-1}) with (\ref{eq:eps-8-1}) and (\ref{eq:eps-8-1-2}):

Finally, as , it follows that 

which gives:

\end{proof}
\fi
 
\paragraph{Potential.}

We use the following potential function to analyze the convergence time:

where  and  is defined by (\ref{eq:f-alpha}).
The potential function is strictly concave and its partial derivative with respect to any variable  is:


The following fact (given in a similar form in \cite{AwerbuchKhandekar2009}), which follows directly from the Taylor series representation of concave functions, will be useful for the potential increase analysis:
\begin{fact}\label{fact:taylor}
For a differentiable concave function  and any two points :

\end{fact}

Using Fact \ref{fact:taylor} and (\ref{eq:potential-derivatives}), we show the following lemma:

\begin{lemma}\label{lemma:potential-increase}
Starting with a feasible solution and throughout the course of the algorithm, the potential function  never decreases. Letting  and  denote the values of  before and after a round update, respectively, the potential function increase is lower-bounded as:

\end{lemma}
\iffullpaper
\begin{proof}
Since  is concave, using Fact \ref{fact:taylor} and (\ref{eq:potential-derivatives}) it follows that:

If , then the term in the summation (\ref{eq:potential-increase-before-bounds}) corresponding to the change in  is equal to zero, and  has no contribution to the sum in (\ref{eq:potential-increase-before-bounds}). 

If , then, as  increases over the observed round, it must be . By the choice of the parameters, , and therefore

It follows that , and therefore 


Finally, if , then it must be . By the choice of the parameters, , implying

We get that , and therefore 

completing the proof.
\end{proof}
\fi

\iffullpaper
\subsection{Proof of Theorem \ref{thm:convergence-alpha<1}}\label{section:alpha<1}

The outline of the proof is as follows. We first derive a lower bound on the potential increase (Lemma \ref{lemma:potential-increase-alpha<1}), which will motivate the definition of a stationary round. Then, for the appropriate definition of a stationary round we will first show that in any stationary round, solution is approximate. Then, to complete the proof, we will show in any non-stationary round there is a sufficiently large increase in the potential function, which, combined with the bounds on the potential value will yield the result.

The following lemma lower-bounds the increase in the potential function in any round of the algorithm. 

\begin{lemma}\label{lemma:potential-increase-alpha<1}
If  and , ,  and , ,  denote the values of , , and  before and after a round, respectively, and , then if  is feasible:
\begin{enumerate}
\item ;
\item ;
\item .
\end{enumerate}
\end{lemma}
\begin{proof}
\\
\noindent\textbf{Proof of 1.} Observe that for , . From the proof of Lemma \ref{lemma:potential-increase}, we have that: 

The proof that

is implied by the proof of part 3 of this lemma (see below). 
For each , we have that:

Therefore:



\noindent\textbf{Proof of 2.} Let  denote the set of 's such that  increases in the current round. Then, recalling that for   and that from the choice of parameters :

Since , , it follows that 

Observing that for any  we have that , we get:



\noindent\textbf{Proof of 3.} Let  denote the set of 's such that  decreases in the current round. In this case not all the 's with  decrease by a multiplicative factor , since for : . We will first lower-bound the potential increase over 's that decrease multiplicatively: , so that . Recall that for :  and . It follows that:

Next, we prove that the potential increase due to decrease of  such that  is dominated by the potential increase due to 's that decrease multiplicatively by the factor . 

Choose any  such that , and let . From Lemma \ref{lemma:small-x-tight-yi}, there exists at least one  with , such that:


From (\ref{eq:x-tight-constraint}), there exists at least one  such that  and 
Since  and , using (\ref{eq:large-xp}), we have that . Recalling (\ref{eq:yi-lower-bound-zj}):

Recalling that , it further follows that:

Because  and , it follows that . Therefore:


As , we have that , and . Similar to (\ref{eq:yi-lower-bound-zj}), we can lower-bound  as:

Then, recalling , and using (\ref{eq:yi-lower-bound-zj-2}), it is simple to show that:

As  and , it immediately follows from (\ref{eq:alpha<1--small-var-inc-cond1}) that  decreases by a factor . 

In the rest of the proof we show that (\ref{eq:alpha<1--small-var-inc-cond1}) and (\ref{eq:alpha<1--small-var-inc-cond2}) imply that the increase in the potential due to the decrease of variable  dominates the increase in the potential due to the decrease of variable  by at least a factor . This result then further implies that the increase in the potential due to the decrease of variable  dominates the increase in the potential due to the decrease of \emph{all} small 's that appear in the constraint  ('s are such that , , and ).   

Consider the following two cases:  and .

\noindent\textbf{Case 1: }. Then, using (\ref{eq:alpha<1--small-var-inc-cond1}):

\noindent\textbf{Case 2: }. Then, using (\ref{eq:alpha<1--small-var-inc-cond2}):


Combining (\ref{eq:alpha<1-dominant-inc-1}) and (\ref{eq:alpha<1-dominant-inc-2}) with (\ref{eq:pot-increase-bound-multiplicative}), it follows that:

Finally, since for : :

completing the proof.
\end{proof}
Parts 2 and 3 of Lemma \cite{AwerbuchKhandekar2009} appear in a somewhat similar form in \cite{AwerbuchKhandekar2009}. However, part 3 requires significant additional results for bounding the potential change due to decrease of small 's (i.e., 's that are smaller than ) that were not needed in \cite{AwerbuchKhandekar2009}. The rest of the results in this paper are new.    

Consider the following definition of a stationary round:

\begin{definition}\label{def:alpha<1-stationary-round}
(Stationary round.) Let . A round is stationary if it happens after the initial  rounds, where  and , and both of the following two conditions hold:
\begin{enumerate}
\item , and
\item .
\end{enumerate}
\end{definition}

In the rest of the proof, we first show that in any stationary round, we have an approximate solution, while in any non-stationary round, the potential function increases substantially.

We first prove the following lemma, which we will then be used in bounding the duality gap.
\begin{lemma}\label{lemma:alpha<1-lower-bound-xi-j}
After the initial  rounds, where  and , in each round of the algorithm: , .
\end{lemma}
\begin{proof}
Suppose without loss of generality that the algorithm starts with a feasible solution. This assumption is w.l.o.g. because, from Lemma \ref{lemma:self-stabilization}, after at most  rounds the algorithm reaches a feasible solution, and from Lemma \ref{lemma:feasibility}, once the algorithm reaches a feasible solution, it always maintains a feasible solution. 

Choose any . Using the same argument as in the proof of Lemma \ref{lemma:feasibility}, after at most  rounds, there exists at least one round in which  (otherwise , which is a contradiction).

Observe that in any round for which ,  increases by a factor . Therefore, the maximum number of consecutive rounds in which  is at most , otherwise  would increase to a value larger than 1, making  infeasible, which is a contradiction due to Lemma \ref{lemma:feasibility}. The maximum amount by which  can decrease in any round is bounded by a factor . Therefore, using the generalized Bernoulli's inequality, it follows that in any round:

\end{proof}
A simple corollary of Lemma \ref{lemma:alpha<1-lower-bound-xi-j} is that:
\begin{corollary}\label{cor:alpha<1-lower-comp}
After the initial  rounds, where  and , in each round of the algorithm: .
\end{corollary}
\begin{proof}
From Lemma \ref{lemma:alpha<1-lower-bound-xi-j}, after the initial  rounds, it always holds , . Multiplying both sides of the inequality by ,  and summing over , the result follows.
\end{proof}

Recall that  denotes the primal objective. The following lemma states that any stationary round holds an -approximate solution.
\begin{lemma}\label{lemma:alpha<1-stationary-round}
In any stationary round: , where  is the optimal solution to .
\end{lemma}
\begin{proof}
Since, by definition, a stationary round can only happen after the initial  rounds, we have that  in that round is feasible, and also from Lemma \ref{lemma:approx-comp-slack}: . Therefore, recalling Eq. (\ref{eq:duality-gap-alpha}) for the duality gap and denoting , we have that:


From Lemma \ref{lemma:alpha<1-lower-bound-xi-j}, , . Partition the indices of all the variables as follows:

Then, using (\ref{eq:alpha<1-duality-gap-bound}):

where:

and 

The rest of the proof follows by upper-bounding  and .

\noindent\textbf{Bounding .} Observing that : , we can write  as:

Denote . It is simple to verify that  is a convex function. Since , , it follows that . Now:

If , then as , it follows that . Therefore:

If , then (using generalized Bernoulli's inequality and ):

On the other hand:

Combining (\ref{eq:alpha<1-r-1})--(\ref{eq:alpha<1-r-3}) with (\ref{eq:alpha<1-G-1}):


\noindent\textbf{Bounding .} Because the round is stationary and , we have that: . Using the second part of the stationary round definition and that  (follows from Lemma \ref{lemma:alpha<1-lower-bound-xi-j}):

Above, first inequality follows from  (part 2 of the stationary round definition) and Corollary \ref{cor:alpha<1-lower-comp}. Second inequality follows by breaking the left summation into two summations: those with  and those with . The third inequality follows from  and part 1 of the stationary round definition.

Observe that as , we have that . Using (\ref{eq:alpha<1-xjy-bound}), it follows that:


Finally, combining (\ref{eq:alpha<1-G-1-1}) and (\ref{eq:alpha<1-G-2}):

\end{proof}


\begin{proofof}{Theorem \ref{thm:convergence-alpha<1}}
From Lemma \ref{lemma:alpha<1-stationary-round}, in any stationary round: . Therefore, to prove the theorem, it suffices to show that there are at most  non-stationary rounds in total, where , because we can always run the algorithm for  to get an approximation, and this would only affect the constant in the convergence time. 

To bound the number of non-stationary rounds, we will show that the potential increases by a ``large enough'' multiplicative value in all the non-stationary rounds in which the potential is not too ``small''. For the non-stationary rounds in which the value of the potential is ``small'', we show that the potential increases by a large enough value so that there can be only few such rounds. 

In the rest of the proof, we assume that the initial  rounds have passed, so that  is feasible, and the statement of Lemma \ref{lemma:approx-comp-slack} holds. This does not affect the overall bound on the convergence time, as 


To bound the minimum and the maximum values of the potential , we will bound  and . Recall that . 

Since ,  is always feasible, and , , we have that:

and

Thus, we have:

and


Recall from Lemma \ref{lemma:potential-increase} that the potential never decreases. We consider the following three cases for the value of the potential:

\noindent \textbf{Case 1: }. Since in this case , we have that . From Lemma \ref{lemma:approx-comp-slack}, , thus implying: 

as  and . Combining Part 3 of Lemma \ref{lemma:potential-increase-alpha<1} and (\ref{eq:alpha<1-neg-phi-inc}), the potential increases by at least:

Since the potential never decreases, there can be at most 

Case 1 rounds.

\noindent\textbf{Case 2: .} From Lemma \ref{lemma:approx-comp-slack}, there exists at least one  such that . Since  , it is also true that , and as  and , it follows that . From (\ref{eq:alpha<1-p-alpha-bound}), we also have . Therefore:

If , then 

From Lemma \ref{lemma:approx-comp-slack}, 

From the third part of Lemma \ref{lemma:potential-increase-alpha<1}, the potential increases additively by at least 

and, therefore,  after at most

rounds.

\noindent\textbf{Case 3: .} In this case, . If the round is stationary, then from Lemma \ref{lemma:alpha<1-stationary-round}, . If the round is not stationary, then from Definition \ref{def:alpha<1-stationary-round}, either:
\begin{enumerate}
\item , or
\item .
\end{enumerate}
If the former is true, then using the first part of Lemma \ref{lemma:potential-increase-alpha<1}, the potential increases by at least . If the latter is true, from the third part of Lemma \ref{lemma:potential-increase-alpha<1}, the potential increases by at least .
It follows that there are at most 

non-stationary Case 3 rounds.

Combining the three cases with the bound on  (\ref{eq:tau1+tau0-bound}), the total convergence time is at most:

rounds, as claimed.
\end{proofof}


\subsection{Proof of Theorem \ref{thm:convergence-alpha=1}}\label{section:alpha=1}

The proof outline for the convergence of \textsc{-FairPSolver} in the  case is as follows. First, we show that in any round it cannot be the case that only ``small'' 's (i.e., 's that are smaller than ) decrease. In fact, we show that the increase in the potential due to updates of ``small'' variables is dominated by the increase in the potential due to those variables that decrease multiplicatively by a factor  (Lemmas \ref{lemma:mul-increase-prop} and \ref{lemma:potential-increase-proportional}). We then define a stationary round and show that: (i) in any non-stationary round the potential increases significantly, and (ii) in any stationary round, the solution  at the beginning of the round provides an additive --approximation to the optimum objective value.  


\begin{lemma}\label{lemma:mul-increase-prop}
Starting with a feasible solution, in any round of the algorithm: 
\begin{enumerate}
\item .
\item .
\end{enumerate}
\end{lemma}

\begin{proof}
Fix any round, and let  and  denote the values of  at the beginning and at the end of the round, respectively. If for all  , there is nothing to prove. 

Suppose that there exists some  that decreases. Then from Lemma \ref{lemma:small-x-tight-yi} there exists at least one  such that , and: 
\begin{itemize}
\item , and
\item .
\end{itemize}
Since , there exists at least one  such that . 
Recalling that :



Since  decreases, it must be . Using (\ref{eq:alpha=1-n-times-inc}):

and, therefore,  decreases as well. 
Moreover, since (\ref{eq:alpha=1-n-times-inc}) implies

the proof of the first part of the lemma follows. The second part follows from (\ref{eq:alpha=1-n-times-inc}) as well, since:

which, given that  was chosen arbitrarily, implies:

\end{proof}

\begin{lemma}\label{lemma:potential-increase-proportional}
Let  and  denote the values of  at the beginning and at the end of any fixed round, respectively. If  is feasible, then the potential increase in the round is at least:
\begin{enumerate}
\item \label{item:prop-1} ;
\item \label{item:prop-2} .
\item \label{item:prop-3} .
\end{enumerate}
\end{lemma}
\begin{proof}
\\
\noindent\textbf{Proof of \ref{item:prop-1}:}
Recall that:

Let , .

If , then  and . Since from the choice of parameters  increases by at most a factor of , it follows that: , which gives . Therefore:


\noindent\textbf{Proof of \ref{item:prop-2}:} The proof is equivalent to the proof of the second part of Lemma \ref{lemma:potential-increase-alpha<1} and is omitted.
 
\noindent\textbf{Proof of \ref{item:prop-3}:} Using that for  we have that  and , we can lower bound the increase in the potential as:

Now consider  such that . From the proof of Lemma \ref{lemma:mul-increase-prop}, for each such  there exists a constraint  and a variable  with  such that , , , and . If  then

On the other hand, if , then:

It follows from (\ref{eq:delta-phi-j-in-S-}) that:

Finally, since for  we have that :

\end{proof}

Consider the following definition of a stationary round:

\begin{definition}\label{def:alpha=1-stat-round}
A round is stationary if it happens after the initial  rounds, where ,  and if both of the following conditions hold:
\begin{itemize}
\item ;
\item .
\end{itemize}
\end{definition}

We first show that in any non-stationary round there is a sufficient progress towards the approximate solution.
\begin{lemma}\label{lemma:non-stat-round-alpha=1}
In any non-stationary round the potential function increases by at least .
\end{lemma}
\begin{proof}
A round is non-stationary if either of the two conditions from Definition \ref{def:alpha=1-stat-round} does not hold. If the first condition does not hold, then from the first part of Lemma \ref{lemma:potential-increase-proportional}, the potential increases by . If the second condition does not hold, then from either the second or the third part of Lemma \ref{lemma:potential-increase-proportional} the potential increases by at least .
\end{proof}

Before proving that in every non-stationary round, the solution is approximate, we will need the following intermediary lemma.
\begin{lemma}\label{lemma:cond-lower-bound}
Starting with a feasible solution and after at most  rounds, in any round of the algorithm:

\end{lemma}
\begin{proof}
First, we claim that after the algorithm reaches a feasible solution it takes at most  additional rounds for each agent  to reach a round in which . Suppose not, and pick any agent  for which in each of the  rounds following the first round that holds a feasible solution: . Then  increases in each of the rounds and after  rounds we have . Therefore, after at most  rounds the solution becomes infeasible, which is a contradiction (due to Lemma \ref{lemma:feasibility}).

Now choose any  and observe  over the rounds that happen after the first  rounds. The maximum number of consecutive rounds for which  is , otherwise we would have , a contradiction. Since in any round, due to the choice of the algorithm parameters,  decreases by at most a factor of , the minimum value that  can take is at least , thus completing the proof.
\end{proof}

Now we are ready to prove that a solution in a stationary round is approximate.
\begin{lemma}\label{lemma:alpha=1-stat-round}
In any stationary round: , where  is the optimal solution.
\end{lemma}
\begin{proof}
Since, due to Definition \ref{def:alpha=1-stat-round}, a stationary round can only happen after the initial  rounds, we have that in any stationary round the solution is feasible (Lemmas \ref{lemma:feasibility} and \ref{lemma:self-stabilization}) and approximate complementary slackness (Lemma \ref{lemma:approx-comp-slack}) holds. 

Recall the expression \iffalse(\ref{eq:duality-gap-proportional})\fi for the duality gap:

From the second part of Lemma \ref{lemma:approx-comp-slack}:

Therefore:

Since the round is stationary, we have that , which gives:

Let . The remaining part of the proof is to bound . 
For , we have that . To bound the remaining terms, we will use Lemma \ref{lemma:cond-lower-bound} and the bound of the sum of the weights  for which  (that is, ). It follows that:

Combining (\ref{eq:alpha=1-duality-gap-bound}) and (\ref{eq:bound-on-ln-terms}), and recalling that , the result follows.
\end{proof}


\begin{proofof}{Theorem \ref{thm:convergence-alpha=1}}
Consider the values of the potential in the rounds following the initial  rounds, where ,  (so that the solution  is feasible in each round and the approximate complementary slackness holds). Observe that .

We start by bounding the minimum and the maximum values that the potential can take. Recall (from Lemma \ref{lemma:potential-increase}) that the potential never decreases.

Due to Lemma \ref{lemma:feasibility}, , , and therefore we can bound the two summations in the potential as:



and


From (\ref{eq:alpha=1-pot-lbound-1}) and (\ref{eq:alpha=1-pot-lbound-2}):


On the other hand, from (\ref{eq:alpha=1-pot-ubound-1}) and (\ref{eq:alpha=1-pot-ubound-2}):


Consider the following two cases:

\noindent\textbf{Case 1: .}  Then  and . From the third part of Lemma \ref{lemma:approx-comp-slack}, we have that . Thus using the Part \ref{item:prop-2} of Lemma \ref{lemma:potential-increase-proportional}, we get that the potential increases by 

Finally, since , there can be at most  Case 1 rounds.

\noindent\textbf{Case 2: .}  Then . From Lemma \ref{lemma:alpha=1-stat-round}, if a round is stationary, then . If a round is non-stationary, from Lemma \ref{lemma:non-stat-round-alpha=1}, the potential increases (additively) by at least . Therefore, the maximum number of non-stationary rounds is at most:

Combining the results for the Case 1 and Case 2, the theorem follows by invoking \textsc{-FairPSolver} for the approximation parameter .
\end{proofof}


\subsection{Proof of Theorem \ref{thm:convergence-alpha>1}}\label{section:alpha>1}
The outline of the proof of Theorem \ref{thm:convergence-alpha>1} is as follows. First, we show that in any round of the algorithm the variables that decrease by a multiplicative factor  dominate the potential increase due to \emph{all the variables} that decrease (Lemma \ref{lemma:alpha>1-mul-increase-over-S-}). 
This result is then used in Lemma \ref{lemma:potential-increase-alpha>1} to show the appropriate lower bound on the potential increase. Observe that for  the objective function , and, consequently, the potential function  is negative for any feasible . To yield a poly-logarithmic convergence time in , and , the idea is to show that the negative potential  decreases by some multiplicative factor whenever  is not a ``good'' approximation to  -- the optimal solution to . This idea, combined with the fact that the potential never decreases (and therefore  never increases) and with upper and lower bounds on the potential then leads to the desired convergence time. 

\begin{lemma}\label{lemma:alpha>1-mul-increase-over-S-}
In any round of the algorithm in which the solution  at the beginning of the round is feasible:

and

\end{lemma}
\begin{proof}
If , , there is nothing to prove, so assume that there exists at least one  with . 
The proof proceeds as follows. First, we show that for each  for which  decreases by a factor less than  there exists at least one  that appears in at least one constraint  in which  appears and decreases by a factor . We then proceed to show that  is in fact such that 

and 

This will then imply that the terms  and  dominate \emph{the sum} of all the terms corresponding to 's with  and , thus completing the proof.

From Lemma \ref{lemma:small-x-tight-yi}, for each  with  there exists at least one constraint  such that:
\begin{itemize}
\item , and
\item .
\end{itemize}
Therefore, there exists at least one  with  such that , which further gives , where the last inequality follows from  and . Combining the inequality for  with the inequality for  above:



Using the generalized Bernoulli's inequality:  and  \cite{mitrinovic1970analytic}, and recalling that , , we further get:

which further implies:

as . Since  decreases, , and therefore  decreases as well.

Using similar arguments, as  and recalling that :


as  and  (since ).

From (\ref{eq:slackness-n-dominance}), it follows that 

which further implies the first part of the lemma.

For the second part, consider the following two cases:

\noindent\textbf{Case 1:} . Then:

implying the second part of the lemma.

\noindent\textbf{Case 2:} . Then:

thus implying the second part of the lemma and completing the proof.
\end{proof}
The following lemma lower-bounds the increase in the potential, in each round.
\begin{lemma}\label{lemma:potential-increase-alpha>1}
Let  and  denote the values of  before and after any fixed round, respectively, and let , . The potential increase in the round is lower bounded as:
\begin{enumerate}[noitemsep, topsep=5pt]
\item ;
\item ;
\item .
\end{enumerate}
\end{lemma}
\begin{proof}
\\
\noindent\textbf{Proof of 1.} From Lemma \ref{lemma:potential-increase}:

Let . 
From the proof of Lemma \ref{lemma:potential-increase}, if , then , as . If , then , which implies , and thus .
Therefore: , which further gives:

If , then , and therefore .

Similarly, if  and , then , and therefore . Using part 1 of Lemma \ref{lemma:alpha>1-mul-increase-over-S-}:


\noindent\textbf{Proof of 2:} Consider  such that . Then , , and using Lemma \ref{lemma:potential-increase}:

Using the second part of Lemma \ref{lemma:alpha>1-mul-increase-over-S-} and the fact that for : , we get the desired result:


\noindent\textbf{Proof of 3:} The proof is equivalent to the proof of Lemma \ref{lemma:potential-increase-alpha<1}, part 2, and is omitted for brevity. 
\end{proof}

Consider the following definition of a stationary round:
\begin{definition}\label{def:stationary-round}
(Stationary round.) A round is stationary, if both:
\begin{enumerate}[topsep = 5pt]
\item , and
\item 
\end{enumerate}
hold, where , . Otherwise, the round is non-stationary.
\end{definition}




The following two technical propositions are used in Lemma \ref{lemma:alpha>1-stationary-near-opt} for bounding the duality gap in stationary rounds.
\begin{proposition}\label{prop:alpha>1-duality-gap}
After the initial the initial  rounds, where , , it is always true that , where .
\end{proposition}
\begin{proof}
Recall from (\ref{eq:duality-gap-alpha}) that the duality gap for  in  is given as: 

From Lemma \ref{lemma:approx-comp-slack}, after at most initial  rounds:

and letting , we get:

\end{proof}

\begin{proposition}\label{prop:alpha>1-r-bound}
Let , where . If  and
 , 
then .
\end{proposition}
\begin{proof}

Observe the first and the second derivative of :

As ,  is convex for , and therefore: 
 
We have that:

On the other hand:

completing the proof.
\end{proof}

The following lemma states that in any stationary round current solution is an -approximate solution.
\begin{lemma}\label{lemma:alpha>1-stationary-near-opt}
In any stationary round that happens after the initial the initial  rounds, where , , we have that , where  is the optimal solution to  and  is the solution at the beginning of the round.
\end{lemma}
\begin{proof}
Observe that for any  (by the definition of  and ) we have that , which is equivalent to:


Using stationarity and (\ref{eq:tight-stationary-xk}):

Since , using (\ref{eq:bound-on-all-wj-xj}):

and therefore:

as  and .

As , from Proposition \ref{prop:alpha>1-duality-gap}:

From Proposition \ref{prop:alpha>1-r-bound}:


Observe . Since , each , and therefore:

Now, from stationarity  and using (\ref{eq:tight-active-objective-part}) we get:

Finally, combining (\ref{eq:approx-for-passive-x}) and (\ref{eq:approx-for-active-x}): 

\end{proof}
The following two lemmas are used for lower-bounding the potential increase in non-stationary rounds.

\begin{lemma}\label{lemma:alpha>1-large-sum-yi}
Consider any non-stationary round that happens after the initial  rounds, where , . Let  and  denote the values of  before and after the round update. If , then .
\end{lemma}
\begin{proof}
Observe that as ,

where the last inequality follows from Lemma \ref{lemma:approx-comp-slack}.

Since the round is not stationary, we have that either: 
\begin{enumerate}
\item , or
\item .
\end{enumerate}
\noindent\textbf{Case 1: .} If: 

then

and, from the first part of Lemma \ref{lemma:potential-increase-alpha>1}, the potential increase is lower bounded as:

On the other hand, if:

then, from the second part of Lemma \ref{lemma:potential-increase-alpha>1}:


\noindent\textbf{Case 2: .} Then, using the third part of Lemma \ref{lemma:potential-increase-alpha>1}:

where in the second line we have used that . This can be shown using the generalized Bernoulli's inequality and  as follows:

\end{proof}

\begin{lemma}\label{lemma:alpha>1-mul-inc-non-stat}
Consider any non-stationary round that happens after the initial  rounds, where , . Let  and  denote the values of  before and after the round update. If , then .
\end{lemma}
\begin{proof}
Observe that as ,


From the definition of a stationary round, we have either of the following two cases:

\noindent\textbf{Case 1:} . 
From the first part of Lemma \ref{lemma:potential-increase-alpha>1}, the increase in the potential is: . As , the increase in the potential is at least:


\noindent\textbf{Case 2:} . Using part 3 of Lemma \ref{lemma:potential-increase-alpha>1}, the increase in the potential is then . Therefore, using that  as in the proof of Lemma \ref{lemma:alpha>1-large-sum-yi}:


\end{proof}


\begin{proofof}{Theorem \ref{thm:convergence-alpha>1}}
We will bound the total number of non-stationary rounds that happen after the initial  rounds, where , . The total convergence time is then at most the sum of  rounds and the number of non-stationary rounds that happen after the initial  rounds, since, from Lemma \ref{lemma:alpha>1-stationary-near-opt}, in any stationary round: .

Consider the non-stationary rounds that happen after the initial  rounds. 
As , , it is simple to show that:

and


Recall that  and that the potential  never decreases.

There can be two cases of non-stationary rounds: those in which  dominates in the absolute value of the potential, and those in which  dominates in the absolute value of the potential. We bound the total number of the non-stationary rounds in such cases as follows.

\noindent\textbf{Case 1: .}  
From (\ref{eq:alpha>1-palpha-bounds}) and (\ref{eq:alpha>1-sum-yi-bounds}), in any such round, the negative potential is bounded as:

Moreover, from Lemma \ref{lemma:alpha>1-large-sum-yi}, in each Case 1 non-stationary round, the potential increases by at least . It immediately follows that there can be at most:

Case 1 non-stationary rounds, as .

\noindent\textbf{Case 2: .} From (\ref{eq:alpha>1-palpha-bounds}) and (\ref{eq:alpha>1-sum-yi-bounds}), in any such round, the negative potential is bounded as:

Moreover, from Lemma \ref{lemma:alpha>1-mul-increase-over-S-}, in each such non-stationary round the potential increases by at least . Therefore, there can be at most:

Case 2 non-stationary rounds.

The total number of initial  rounds can be bounded as:


Combining (\ref{eq:alpha>1-conv-bound-1}), (\ref{eq:alpha>1-conv-bound-2}), and (\ref{eq:alpha>1-conv-bound-3}), the total convergence time is at most:
 

Finally, running \textsc{-FairPSolver} for the approximation parameter , we get that in any stationary round , while the total number of non-stationary rounds is at most:
 
\end{proofof}

\else
\subsection{Proof Sketch of Theorem \ref{thm:convergence-alpha>1}}\label{section:alpha>1}

In this section, we outline the main ideas of the proof of Theorem \ref{thm:convergence-alpha>1}, while the technical details are omitted and are instead provided in the {full version of the paper}. 
First, we show that in any round of the algorithm the variables that decrease by a multiplicative factor  dominate the potential increase due to \emph{all the variables} that decrease (see Lemma {4.21} in the full paper). 
This result is then used in Lemma \ref{lemma:potential-increase-alpha>1} to show the following lower bound on the potential increase:



\begin{lemma}\label{lemma:potential-increase-alpha>1}
Let  and  denote the values of  before and after any fixed round, respectively, and let , . The potential increase in the round is lower bounded as:
\begin{enumerate}[noitemsep, topsep=5pt]
\item ;
\item ;
\item .
\end{enumerate}
\end{lemma}

Observe that for  the objective function , and, consequently, the potential function  is negative for any feasible . To yield a poly-logarithmic convergence time in , and , the idea is to show that the negative potential  decreases by some multiplicative factor whenever  is not a ``good'' approximation to  -- the optimal solution to . This idea, combined with the fact that the potential never decreases (and therefore  never increases) and with upper and lower bounds on the potential then leads to the desired convergence time. 
Consider the following definition of a stationary round:
\begin{definition}\label{def:stationary-round}
(Stationary round.) A round is stationary, if both:
\begin{enumerate}[topsep = 5pt]
\item , and
\item 
\end{enumerate}
hold, where , . Otherwise, the round is non-stationary.
\end{definition}
Recall the expression for the negative potential: . Then, using Lemma \ref{lemma:potential-increase-alpha>1}, it suffices to show that in a non-stationary round the decrease in the negative potential  is a multiplicative factor of the larger of the two terms  and . 
The last part of the proof is to show that the solution  that corresponds to any stationary round is close to the optimal solution. This part is done by appropriately upper-bounding the duality gap. Denoting by  the set of coordinates  for which  either increases or decreases in the observed stationary round and using Definition \ref{def:stationary-round}, we show that the terms  contribute to the duality gap by no more than . The terms corresponding to  are bounded recalling (from \textsc{-FairPSolver}) that for such terms . 
\fi
\subsection{Structural Properties of Fair Allocations}
\paragraph{Lower Bound on the Minimum Allocated Value.}
Recall (from Section \ref{section:prelims}) 
that the optimal solution  to  must lie in the positive orthant. We show in Lemma \ref{lemma:lower-bound} that not only does  lie in the positive orthant, but the minimum element of  can be bounded below as a function of the problem parameters. This lemma motivates the choice of parameters  in \textsc{-FairPSolver} (Section \ref{section:algorithm}). 


\begin{lemma}\label{lemma:lower-bound}
Let  be the optimal solution to . Then :
\begin{itemize}
\itemsep0pt
\item , if  ,
\item , if ,
\end{itemize}
where \footnote{With the abuse of notation,  is the indicator function of the expression , i.e., 1 if  holds, and 0 otherwise.} is the number of non-zero elements in the  row of the constraint matrix , and .
\end{lemma}
\iffullpaper
\begin{proof}
Fix . Let:


For the purpose of contradiction, suppose that  is the optimal solution to , and  for some fixed .  

To establish the desired result, we will need to introduce additional notation. We first break the set of (the indices of) constraints of the form  in which variable  appears with a non-zero coefficient into two sets,  and :
\begin{itemize}
\item Let  denote the set of the constraints from  that are not tight at the given optimal solution , and are such that  for . Let  denote the slack of the constraint .
\item Let  denote the set of tight constraints from  that are such that  for . Observe that since  is assumed to be optimal, .
\end{itemize}

Let . Notice that by increasing  to  none of the constraints from  can be violated (although all the constraints in  will; we deal with these violations in what follows).

In each constraint , there must exist at least one variable  such that , because , as each  is tight, and 
Select one such  in each constraint , and denote by  the set of indices of selected variables. Observe that  (), since an  can appear in more than one constraint. 

For each , let  denote the constraints in which  is selected, and let 

If we increase  by  and decrease  by  , each of the constraints  will be satisfied since, from (\ref{eq:epsilon-choice}) and from the fact that only one  gets selected per constraint , . Therefore, to construct an alternative feasible solution , we set ,  for , and  for all the remaining coordinates . 

Since  is the only coordinate over which  gets increased in , all the constraints  are satisfied. For  to be feasible, we must have in addition that  for . 
We show that  as follows:

where the second line follows from , and the last line follows from the choice of .

The last part of the proof is to show that , which contradicts the initial assumption that  is optimal, by the definition of -fairness from Section \ref{section:prelims}. We have that:

Consider one term from the summation (\ref{eq:sum-ind-terms}). From the choice of 's, we know that for each  there exist  such that , and at the same time (by the choice of ) we have , so that


\noindent\textbf{Case 1.} Suppose first that . Then , as .  Plugging into (\ref{eq:xk-general}), we have:


By the initial assumption, , and therefore 

since it must be  (). From (\ref{eq:xk}) and (\ref{eq:xj}), we get that every term in the summation (\ref{eq:sum-ind-terms}) is strictly positive, which implies:

and therefore  is not optimal.

\noindent\textbf{Case 2.} Now suppose that . Then 

Therefore:

as , and  (since for any : ).

Finally, from (\ref{eq:xk-general}) and (\ref{eq:xj-alpha1}) we get that every term in the summation (\ref{eq:sum-ind-terms}) is positive, which yields a contradiction.
\end{proof}
\fi

\paragraph{Asymptotics of Fair Allocations}

The following lemma states that for sufficiently small (but not too small) , the values of the linear and the fair objectives at their respective optimal solutions are approximately the same. This statement will then lead to a conclusion that to approximately solve an fair packing problem for a very small , one can always use an approximation packing LP algorithm. 
\begin{lemma}\label{lemma:LP-close-to-small-alpha-fair}
Let  be an fair packing problem with optimal solution , and  be the LP with the same constraints and the same weights  as  and an optimal solution . Then if , we have that , where .
\end{lemma}
\iffullpaper
\begin{proof}
The proof outline is as follows. First, we show that the fair objective  can be upper-bounded by a linear objective as . Then, to complete the proof, we use the optimality of  for the LP:  ( from the first part of the proof).

Let . Consider the case when . Solving  for , we get that it should be 


Choose  so that , which is equivalent to . Then to have , it suffices to have , because (i)  for , where  is the base of the natural logarithm, and (ii)  by the choice of .

Now, as , summing over  such that  we have:

Now we bound the rest of the terms in , i.e., we consider . Observe that since  for  is a feasible solution to  and  is the optimal solution to , we have that , which gives:

Therefore:

Combining (\ref{eq:large-coord-approx}) and (\ref{eq:small-coord-approx}), we now get:

Finally, since  optimally solves  (which has the same constraints and weights as ), we have that  is feasible for , and using (\ref{eq:alpha-LP}) and optimality of , it follows that:

as claimed.
\end{proof}
\fi
Observing that for any ,  (since, due to the scaling, ), a simple corollary of Lemma \ref{lemma:LP-close-to-small-alpha-fair} is that an approximation  to  () is also an approximation to , for . Thus, to find an approximate solution for , the packing LP algorithm of \cite{AwerbuchKhandekar2009} can be run, which means that there is a stateless distributed algorithm that converges in poly() time for  arbitrarily close to zero.

The following two lemmas show that when  is sufficiently close to 1,  can be approximated by approximately solving  with the same constraints and weights.

\begin{lemma}\label{lemma:alpha-close-to-1-below}
Let  be an approximate solution to a 1-fair packing problem  returned by \textsc{-FairPSolver}. Then, for any , where ,  is also a approximate solution to , where the only difference between  and  is in the value of  in the objective.
\end{lemma}
\iffullpaper
\begin{proof}
Suppose that  is a solution in some stationary round, provided by \textsc{-FairPSolver} run for . Fix that round. It is clear that if  is feasible in , it is also feasible in , since all the constraints in  and  are the same by the initial assumption. All that is required for a dual solution  to be feasible is that , for all , and therefore  is a feasible dual solution for . The rest of the proof follows by bounding the duality gap . Recall from (\ref{eq:duality-gap-alpha}) that: 


Since  is a solution from a stationary round, from the second part of the definition of a stationary round (Definition \ref{def:alpha=1-stat-round}), we have that:

Further, from Lemma \ref{lemma:approx-comp-slack}:


Next, we show that:

Rearranging the terms and taking logarithms of both sides in (\ref{eq:alpha-below=1-all-x-large}), we obtain the  equivalent inequality . Recall from \textsc{-FairPSolver} that in every (except for, maybe, the first) round . As , it therefore suffices to show that . But from the statement of the lemma, , completing the proof of (\ref{eq:alpha-below=1-all-x-large}).

Combining (\ref{eq:alpha-below-1-acs}) and (\ref{eq:alpha-below=1-all-x-large}), we get that:

where the second inequality follows from , .

Using (\ref{eq:alpha-below-1-bnd-1}), we can bound the duality gap (Eq. (\ref{eq:duality-gap-alpha-recap})) as:

To complete the proof, recall from Lemma \ref{lemma:cond-lower-bound} that in any round of the algorithm, for all : . As  and , , it holds that , , and therefore:

Finally, recalling that , and combining (\ref{eq:alpha-below-1-bnd-2}) with (\ref{eq:duality-gap-alpha-betterbound}), we get:

where the third inequality follows from , and the fourth inequality follows from  and .
\end{proof}
\fi

\begin{lemma}\label{lemma:alpha-close-to-1-above}
Let  be an approximate solution to a 1-fair packing problem  returned by \textsc{-FairPSolver}. Then, for any , where ,  is also a approximate solution to , where the only difference between  and  is in the value of  in the objective.
\end{lemma}
\iffullpaper
\begin{proof}
Similar to the proof of Lemma \ref{lemma:alpha-close-to-1-below}, we will fix an  from some stationary round of \textsc{-FairPSolver} run on , and argue that the same  approximates  by bounding the duality gap , although we will need to use a different set of inequalities since now . Similar to the proof of Lemma \ref{lemma:alpha-close-to-1-below}, as  is (primal-)feasible for ,  and  are primal- and dual-feasible for .

By the same token as in the proof of Lemma \ref{lemma:alpha-close-to-1-below}:

As  and , , we have that , , and therefore:

Therefore, we can write for the duality gap:

Notice that, as , the objective for , , is now negative.

Using the same arguments as in the proof of Lemma \ref{lemma:alpha-close-to-1-below}, it is straightforward to show that , . From Lemma \ref{lemma:cond-lower-bound}, we have that , , and therefore:

Recalling that  (by the statement of the lemma) and using (\ref{eq:alpha-above-1-bnd-2}), we have:

Finally, plugging (\ref{eq:alpha-above-1-bnd-3}) into (\ref{eq:alpha-above-1-duality-gap}), we have:

where the equality follows from , and the last inequality follows from .
\end{proof}
\fi

Finally, we consider the asymptotics of fair allocations, as  becomes large. This result complements the result from \cite{MoWalrand2000} that states that fair allocations approach the max-min fair one as  by showing how fast the max-min fair allocation is reached as a function of , and . First, for completeness, we provide the definition of max-min fairness.
\begin{definition}(Max-min fairness \cite{Bertsekas:1987:DN:12517}.) \label{def:max-min-fairness}
Let  be a compact and convex set. A vector  is max-min fair on  if for any vector  it holds that: if for some  , then there exists  such that  and . 
\end{definition}
On a compact and convex set , the max-min fair vector is unique (see, e.g., \cite{Sarkar-Tassiulas, radunovic2007unified}). The following lemma shows that for , the fair vector and the max-min fair vector are close to each other. Notice that because of a very large gradient of  as  becomes large, the max-min fair solution provides only an approximation to . 




\begin{lemma}\label{lemma:mmf-alpha-fair}
Let  be the optimal solution to ,  be the max-min fair solution for the convex and compact set determined by the constraints from . Then if , we have that:
\begin{enumerate}
\item , i.e.,  is an approximate solution to , and
\item , for all .
\end{enumerate}
\end{lemma}
\iffullpaper
\begin{proof}
Suppose that, starting with , we want to construct a solution  that is feasible in  and is such that . Then we need to increase at least one coordinate  of . Suppose that we increase a coordinate  by a factor , so that . Since  is the max-min fair vector, to keep  feasible, the increase over the  coordinate must be at the expense of decreasing some other coordinates  that satisfy . We will assume that whenever we decrease the coordinates to keep the solution feasible, we keep the solution Pareto optimal (i.e., we decrease the selected coordinates by a minimum amount). Using Fact \ref{fact:taylor}, we have:


Now, suppose that we want to further increase the  coordinate by some small . Call that new solution . Then, the total amount by which other coordinates must decrease to keep the solution feasible is at least , since the feasible region is determined by packing constraints and it must be , where , . Moreover, since  is max-min fair, each coordinate  that gets decreased must satisfy . It follows that:

The last inequality can be verified by solving the inequality  for , and verifying that it is implied by the initial assumption that .

Therefore, the maximum amount by which any coordinate of  can be increased to improve the value of the objective  is by a multiplicative factor of at most . Since we can construct , the optimal solution to , starting with  and by choosing a set of coordinates  that we want to increase and by only decreasing coordinates  such that  whenever coordinate  is increased, it follows that , .

Moreover, from (\ref{eq:mmf-part-1}) and (\ref{eq:mmf-part-2}):

and we can conclude that:

which means that  is an approximate solution to .

Now consider the coordinates we need to decrease when we construct a solution  from , such that . Suppose that to increase some other coordinates, a coordinate  is decreased by a factor : . As  is max-min fair, only coordinates larger than  can increase at the expense of decreasing . Suppose now that we decrease the  coordinate further by some small . Call that solution . Then the maximum number of other coordinates  that can further increase is . Moreover, each coordinate  that gets increased satisfies , and can be increased by at most . Using Fact \ref{fact:taylor}, it follows that: 

where the last inequality follows from , which is implied by the initial assumption that .

Therefore, using (\ref{eq:mmf-part-5}), the  coordinate can decrease by at most a multiplicative factor . Using similar arguments as for increasing the coordinates, it follows that , .
\end{proof}
\fi

\section{Conclusion}\label{section:conclusion}

We presented an efficient stateless distributed algorithm for the class of -fair packing problems. To the best of our knowledge, this is the first algorithm with poly-logarithmic convergence time in the input size.~{Additionally, we obtained results that characterize the fairness and asymptotic behavior of allocations in weighted fair packing problems that may be of independent interest.}~{An interesting} open problem is to determine the class of objective functions for which the presented techniques yield fast and stateless distributed algorithms, together with a unified convergence analysis. This problem is especially important in light of the fact that -fair objectives are not Lipschitz continuous, do not have a Lipschitz gradient, and their dual gradient's Lipschitz constant scales at least linearly with  and . Therefore, the properties typically used in fast first-order methods are lacking \cite{nesterov2004introductory,  zhuOrecchia2014novel}. {Finally, for applications of -fair packing that do not require uncoordinated updates, it seems plausible that the dependence on  in the convergence bound can be improved from  to  by relaxing the requirement for asynchronous updates, similarly as was done in \cite{d-allen2014using} over \cite{AwerbuchKhandekar2009}.}
 
\iffullpaper
\section*{Acknowledgements}

We thank Nikhil Devanur for pointing out the equivalence of the -fair packing for  and the problem of finding an equilibrium allocation in Eisenberg-Gale markets with Leontief utilities.
\fi
 
\newpage

\bibliographystyle{abbrv}
{\small
\bibliography{references}
}
\newpage
\iffullpaper
\appendix

\section{Scaling Preserves Approximation}\label{appendix:scaling}

Let the -fair allocation problem be given in the form:


\noindent  is an length vector of positive weights,  is the vector of variables,  is an  constraint matrix, and  is an length vector with positive entries. Denote .

It is not hard to see that the assumption   is without loss of generality, since for  we can always divide both sides of the inequality by  and obtain 1 on the right-hand side, since for (non-trivial) packing problems . Therefore, we can assume that the input problem has constraints of the form , although it may not necessarily be the case that  .

The remaining transformation that is performed on the input problem is:

where 


The problem  after the scaling becomes:

\begin{minipage}{.4\linewidth}

\end{minipage}

\begin{minipage}{.4\linewidth}

\end{minipage}\\
as  is a positive constant. Recall that \textsc{-FairPSolver} returns an approximate solution to , and observe that  is feasible for  if and only if  is feasible for .

Choose the dual variables (Lagrange multipliers) for the original problem  as:

and notice that 

It is clear that 's are feasible dual solutions, since the only requirement for the duals is non-negativity.

\subsection{Approximation for Proportional Fairness} 

Recall (from (\ref{eq:duality-gap-alpha})) that the duality gap for a given primal- and dual-feasible  and  is given as:

Since , we have that  for all , and using (\ref{eq:condition-equality}), it follows that

Since we demonstrate an additive approximation for the proportional fairness via the duality gap: , the same additive approximation follows for the original (non-scaled) problem.

\subsection{Approximation for -Fairness and }
For , we show that the algorithm achieves a multiplicative approximation for the scaled problem. In particular, we show that after the algorithm converges we have that: , where  is the optimal solution,  is the solution returned by the algorithm, and  is a constant.

Observe that since , we have that  and . Therefore:







\section{Primal, Dual, and the Duality Gap}\label{appendix:primal-dual-duality-gap}

\subsection{Proportionally Fair Resource Allocation}

In this section we consider -proportional resource allocation, often referred to as the weighted proportionally fair resource allocation. Recall that the primal is of the form:


The Lagrangian for this problem can be written as:

where  are Lagrange multipliers, and  are slack variables. The dual to this problem is:

where . To maximize , we first differentiate with respect to , :

which gives:

Plugging this back into the expression for , and noticing that, since  ,  is maximized for , we get that:

since  , and .

Let  denote the primal objective. The duality gap for any pair of primal-feasible  and dual-feasible (nonnegative)  is given by:

Since the primal problem maximizes a concave function over a polytope, the strong duality holds \cite{boyd2009convex}, and therefore  for any pair of primal-feasible  and dual-feasible , with equality if and only if  and  are primal- and dual- optimal, respectively.

\subsection{-Fair Resource Allocation for }

Recall that for  the primal problem is:


The Lagrangian for this problem can be written as:

where  and , for , are Lagrangian multipliers and slack variables, respectively.

The dual to  can be written as:

where .

Since  is differentiable with respect to  for , it is maximized for:

As  , we get that:


Similarly as before, for primal-feasible  and dual-feasible , the duality gap is given as:

Observing that:

we finally get:








































\fi

\end{document}