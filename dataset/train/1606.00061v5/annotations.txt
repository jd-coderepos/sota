[{'LEADERBOARD': {'Task': 'Visual Dialog', 'Dataset': 'VisDial v0.9 val', 'Metric': 'MRR', 'Score': '57.88'}}, {'LEADERBOARD': {'Task': 'Visual Dialog', 'Dataset': 'VisDial v0.9 val', 'Metric': 'Mean Rank', 'Score': '5.84'}}, {'LEADERBOARD': {'Task': 'Visual Dialog', 'Dataset': 'VisDial v0.9 val', 'Metric': 'R@1', 'Score': '43.51'}}, {'LEADERBOARD': {'Task': 'Visual Dialog', 'Dataset': 'VisDial v0.9 val', 'Metric': 'R@10', 'Score': '83.96'}}, {'LEADERBOARD': {'Task': 'Visual Dialog', 'Dataset': 'VisDial v0.9 val', 'Metric': 'R@5', 'Score': '74.49'}}, {'LEADERBOARD': {'Task': 'Visual Question Answering (VQA)', 'Dataset': 'COCO Visual Question Answering (VQA) real images 1.0 multiple choice', 'Metric': 'Percentage correct', 'Score': '66.1'}}, {'LEADERBOARD': {'Task': 'Visual Question Answering (VQA)', 'Dataset': 'VQA v1 test-std', 'Metric': 'Accuracy', 'Score': '62.1'}}, {'LEADERBOARD': {'Task': 'Visual Question Answering (VQA)', 'Dataset': 'VQA v1 test-dev', 'Metric': 'Accuracy', 'Score': '61.8'}}, {'LEADERBOARD': {'Task': 'Visual Question Answering (VQA)', 'Dataset': 'COCO Visual Question Answering (VQA) real images 1.0 open ended', 'Metric': 'Percentage correct', 'Score': '62.1'}}]
