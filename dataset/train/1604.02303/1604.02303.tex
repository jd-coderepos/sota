\documentclass[fontsize=11pt,DIV=13,paper=letter]{scrartcl}
\usepackage[pass,letterpaper]{geometry}

\textheight=653pt
\headheight=10pt
\footskip=35pt


\usepackage{amssymb,amsmath,amsfonts,amsthm,enumerate,array,multirow}




\newtheorem{theorem}{Theorem}\newtheorem{proposition}[theorem]{Proposition}
\newtheorem{claim}[theorem]{Claim}
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{corollary}[theorem]{Corollary}


\theoremstyle{definition}
\newtheorem{definition}[theorem]{Definition}
\newtheorem{remark}[theorem]{Remark}
\newtheorem{example}[theorem]{Example}

\newcommand{\wt}{\widetilde}
\newcommand{\sub}{\subseteq}
\newcommand{\la}{\langle}
\newcommand{\ra}{\rangle}
\newcommand{\A}{\mathcal{A}}
\newcommand{\Z}{\mathbb{Z}}
\newcommand{\N}{\mathbb{N}}
\newcommand{\Q}{\mathbb{Q}}
\newcommand{\F}{\mathcal{F}}
\newcommand{\s}{\mathcal{S}}
\newcommand{\LL}{\mathcal{L}}
\newcommand{\SL}{\mathrm{SL}(2,\Z)}
\newcommand{\GL}{\mathrm{GL}(2,\Z)}
\renewcommand{\phi}{\varphi}
\renewcommand{\epsilon}{\varepsilon}


\begin{document}


\title{\Large Decidability of the Membership Problem for  integer matrices\thanks{This research was supported by EPSRC grant EP/M00077X/1.}}

\author{\large Igor Potapov\thanks{Department of Computer Science, University of Liverpool. Email: {\tt potapov@liverpool.ac.uk}}
\and \large Pavel Semukhin\thanks{Department of Computer Science, University of Liverpool. Email: {\tt semukhin@liverpool.ac.uk}}}
\date{}

\maketitle

\begin{abstract}
The main result of this paper is the decidability of the membership problem for  nonsingular integer matrices. Namely, we will construct the first algorithm that for any nonsingular  integer matrices  and  decides whether  belongs to the semigroup generated by .

Our algorithm relies on a translation of the numerical problem on matrices into combinatorial problems on words. It also makes use of some algebraical properties of well-known subgroups of  and various new techniques and constructions that help to limit an infinite number of possibilities by reducing them to the membership problem for regular languages.
\end{abstract}

\section{Introduction}
Matrices and matrix products play a crucial role in a representation and analysis of various computational processes, 
i.e., linear recurrent sequences \cite{tHaHaHiKa05a,OW_ICALP2015-1,OW_ICALP2015-2}, arithmetic circuits \cite{GOW_STACS2015}, 
hybrid and dynamical systems \cite{OSW2015, BP2008},
probabilistic and quantum automata \cite{Blondel2005}, stochastic
games, broadcast protocols \cite{EFM1999},  optical systems \cite{GB94}, etc. 
Unfortunately, many simply formulated and elementary problems for matrices are inherently difficult to solve
even in dimension two, and most of these problems 
become undecidable in general starting from dimension three or four.
One of such hard questions is the {\sl Membership problem} in matrix semigroups:\\

\noindent
{\bf Membership problem:} Given a finite set of  matrices   and a matrix .
Determine if there exist an integer  and  such that 
.
In other words, determine whether a matrix  belongs to the semigroup generated by .\\

In this paper we solve an open problem by showing that  
the membership is decidable
for the semigroups of  nonsingular matrices over integers.
The membership problem was intensively studied since 1947 when A.Markov showed that 
this problem is undecidable for matrices in  even for a specific fixed set  \cite{Markov}. 
Later, M. Paterson in 1970 showed that a special case of the membership problem when  is equal to a zero matrix (known as {\sl Mortality problem})
is undecidable for matrices in . The decidability status of another special case of 
the membership problem --- the {\sl Identity problem} (i.e., when , the identity matrix) --- was unknown for a long time and
was only recently shown to be undecidable for integer matrices starting from dimension four \cite{Identity}, see also the solution to Problem 10.3 in \cite{solution10-3}. The undecidability of the
identity problem means that the {\sl Group problem} (of whether a matrix semigroup over integers forms a group) is undecidable 
starting from dimension four. A more recent survey of undecidable problems can be found in~\cite{CassaigneHHN14}.

The undecidability proofs in matrix semigroups are mainly based on  various techniques and methods for embedding
universal computations into matrix products. The case of dimension two is the most intriguing
since there is some evidence that if these problems are undecidable, then this cannot be proved using 
any previously known constructions. In particular, there is no injective semigroup morphism from pairs of words over any finite
alphabet (with at least two elements) into complex  matrices \cite{CHK99},
which means that the coding of independent pairs of words in  complex matrices is impossible and the exact encoding of
the Post Correspondence Problem or a computation of the Turing Machine cannot be used directly for proving undecidability
in  matrix semigroups over ,  or .
The only undecidability in the case of  matrices has been shown so far is the membership, 
freeness and vector reachability problems over quaternions \cite{BP_IC2008} or more precisely in the case of diagonal matrices over quaternions, 
which are simply double quaternions.
 


The problems for semigroups are rather hard, but there was a steady progress on decidable fragments over the last few decades.
First, both membership and vector reachability problems were shown to be decidable in polynomial time
for a semigroup generated by a single   matrix (known as the {\sl Orbit problem}) by Kannan and Lipton \cite{KL86} in 1986.
Later, in 1996 this decidability result was extended to a more general case of  
commutative matrices \cite{Babai}.
The generalization of this result for a special class of non-commutative matrices
(a class of row-monomial matrices over a commutative semigroup satisfying some natural effectiveness conditions)
was shown in 2004 in~\cite{LP2004}.
Even now we still have long standing open problems for matrix semigroups generated by a single matrix,
see, for example, the {\sl Skolem Problem} about reaching zero in a linear recurrence sequence (LRS), which in matrix 
form is a question of whether any power of a given integer matrix  has zero in the right upper corner \cite{STOC2013,COW_JACM}. It was recently shown
that the decidability of either Positivity or Ultimate Positivity
for integer LRS of order 6 would entail some major breakthroughs
in analytic number theory. The decidability of each of
these problems, whether for integer, rational, or algebraic
linear recurrence sequences, is open, although partial results
are known \cite{GOW_STACS2015,OSW2015,OW_ICALP2015-1,OW_ICALP2015-2}.

Due to a severe lack of methods and techniques the status of decision problems for  matrices (like membership, vector reachability, freeness) is remaining to be a long standing open problem. More recently, a new approach of translating numerical problems of  integer matrices into variety of combinatorial and computational problems on words over group alphabet and studying their transformations as specific rewriting systems have  led to a few results on decidability and complexity for some subclasses. 
In particular, this approach was successfully applied to proving the decidability of the membership problem for semigroups from  \cite{CK2005} in 2005,  designing the polynomial time algorithm for the membership problem for the modular group \cite{Gurevich2007} in 2007,  showing NP-hardness for most of the reachability problems in dimension two \cite{BP2012,BHP2012} in 2012,
and showing decidability of the vector/scalar reachability problems in  \cite{PS15} in 2015.

The main ingredient of the translation into combinatorial problems on words is the well-known result that the groups  and  are finitely generated. For example,  can be generated by a pair of matrices: 
\begin{center}
 and

with the following relations: ,  and .
\end{center}
Hence we can represent a matrix  as a word in the alphabet .


In \cite{CK2005} both the {\sl Identity} and the {\sl Group} problems are shown to be decidable in  . 
Moreover, it was also claimed more generally
that it is decidable whether or not a given nonsingular matrix belongs to a given finitely generated semigroup over integers.
Unfortunately, it appears that the proof of this more general claim (i.e., when we consider matrices with determinants different from~) has a significant gap,
and it only works for a small number of special cases. Namely, after translating the membership from  to , the authors describe a very short reduction 
from the membership problems in  to the one in  using some incorrect assumptions.
For instance, it was assumed that if  is an integer matrix with determinant one and  is a nonsingular integer matrix, then 
there exists an integer matrix  satisfying the following equation  . However, this is not true and here is a simple counter example.
Let  and , then from  it follows that 

. So  has fractional coefficients, and if the matrices  and  were in the generating set, then the argument from \cite{CK2005} would not work.

The main result of this paper is that the membership problem is decidable
for the semigroups of  nonsingular integer matrices. Our proof provides an algorithm for solving this problem, which is
based on the translation of the numerical problem on matrices into combinatorial problems on words and regular languages. We will also makes use of some well-known algebraical results like the uniqueness of the Smith normal form of a matrix and a fact that certain subgroups of  have finite index.


\section{Preliminaries}

The semigroup of  integer matrices is denoted by .
We use  to denote the special linear group of  matrices with integer coefficients, i.e.,  and  to denote the general linear group, i.e., .

A matrix is called \emph{nonsingular} if its determinant is not equal to zero.

If  is a finite collection of matrices from , then  denotes the semigroup generated by  (including the identity matrix), that is,  if and only if  or there are matrices  such that .

\section{Main result}

The main result of our paper is presented in Theorem \ref{thm:mem} which states that membership problem in dimension two is decidable.

\begin{theorem} \label{thm:mem}
There is an algorithm that decides for a given finite collection  of nonsingular matrices from  and a matrix  whether .
\end{theorem}

{\it Proof sketch.} Let  be all matrices from  whose determinant is different from~, and let  be the semigroup which is generated by all matrices from  with determinant , that is, . Then it is not hard to see that  if and only if  or there is a sequence of indices  and matrices  from  such that


The key point of the proof is that the value of  is bounded. Indeed, since , for , we have that . So to decide whether or not  we first need to check whether . If , then we need to go through all sequences  of length up to  and for every such sequence check whether there are matrices  from  such that . The rest of the paper is devoted to the proof that these problems are algorithmically decidable.

In Section \ref{GL} we describe an algorithm that decides whether . In fact, in Proposition~\ref{MPReg} we prove a stronger statement that it is decidable whether , where  is an arbitrary regular subset of , that is, a subset which is defined by a finite automaton. The precise definition of this notion is given in Section \ref{GL}. We will also show there that any semigroup in , and in particular , is a regular subset.

Proposition \ref{MPReg} provides an alternative proof for the decidability of the membership in  presented in \cite{CK2005}. The difference of our approach is that we do not introduce new symbols in the alphabet, and we explicitly construct an automaton  that accepts only canonical words. The construction of  will be also used in the next steps of our algorithm.

In Section \ref{1mat} we provide a proof for the decidability of the second problem in the special case when . Again, in Corollary \ref{cor:1diag} we prove a more general statement that for any two nonsingular matrices  and  from  and regular subsets  and , it is decidable whether there are matrices  and  such that .

Finally, in Section \ref{Gen} we describe an algorithm for the general case. Namely, in Theorem \ref{thm:diag} we will prove that for any nonsingular matrices  from  and for any regular subsets  of~, it is decidable whether there are matrices  such that .

\qed

{\it Remark.} The complexity of our algorithm is in EXPSPACE. The exponential blow-up in memory usage happens when we translate matrices into words and construct a finite automaton for the semigroup  (see the paragraph before Corollary \ref{cor:GL} in Section \ref{GL}). The other steps of the algorithm require only polynomial space.
Furthermore, our algorithm can be extended to check the membership not only for semigroups in  but for arbitrary regular subsets of nonsingular matrices from .

\subsection{Decidability of the membership problem in .}\label{GL}

We will use an encoding of matrices from  by words in alphabet . For this we define a mapping  as follows:

We can extend  to the morphism  in a natural way. It is a well-known fact that morphism  is surjective, that is, for every  there is a word  such that .

\begin{definition}
We call two words  and  from  \emph{equivalent}, denoted , if .

Two languages  and  in the alphabet  are \emph{equivalent}, denoted , if
\begin{enumerate}[(i)]
\item for each , there exists  such that , and
\item for each , there exists  such that .
\end{enumerate}
In other words,  if and only if .
Two finite automata  and  with alphabet  are \emph{equivalent}, denoted , if .
\end{definition}

To simplify the notation we will often write  instead of  when  and . Note that in this notation if  and , then we have  but not necessarily .

\begin{definition}
A subset  is called \emph{regular} or \emph{automatic} if there is a regular language  in alphabet  such that .
\end{definition}

Throughout the paper we will use the following abbreviation: if  is a positive integer and , then  denotes a words of length  which contains only letter , and  is assumed to be equal to the empty word.

\begin{definition}
A word  is called a \emph{canonical word} if it has the form

where , , and . In other words,  is \emph{canonical} if it does not contain subwords  or . Moreover, letter  may appear only once in the first position, and letter  may appear only once either in the first position or after .
\end{definition}

We will make use of Corollary \ref{cor:can} below which states that every matrix from  can be represented by a unique canonical word.

\begin{proposition}[\cite{LS,MKS,Ran}]\label{prop:can}
For every matrix , there is a unique canonical word  such that . Note that  does not contain letter  because .
\end{proposition}

\begin{corollary}\label{cor:can}
For every matrix , there is a unique canonical word  such that .
\end{corollary}

\begin{proof}
If , that is, , then by Proposition \ref{prop:can} there is a unique canonical word  such that . If , then  and again by Proposition \ref{prop:can} there is a unique canonical word  such that  or . Note that  is also a canonical word since  does not contain letter .
\end{proof}

\begin{proposition}\label{MPReg}
There is an algorithm that for any regular subset  and a matrix  decides whether .
\end{proposition}

\begin{proof}
Let  be a regular language such that , and let  be a finite automaton that recognizes , that is, . The words in  do not have to be in canonical form. So, we will construct a new automaton  whose language contains only canonical words and such that  is equivalent to , that is, . The construction of  consists of a sequence of transformations that insert new paths and -transitions into . The detailed description of this construction is given in Section \ref{Can} of the Appendix.

Using the automaton  we can decide whether . Indeed, by Corollary \ref{cor:can}, there is a unique canonical word  that represents the matrix , i.e., . Now we have the following equivalence:  if and only if . Therefore, to decide whether , we need to check whether  is accepted by .

\end{proof}

Note that any finitely generated semigroup  in  is a regular subset. Indeed, let  be canonical words that represent the matrices , respectively, and consider a regular language . Clearly , and hence the semigroup  is regular.
So as a corollary from Proposition \ref{MPReg} we obtain the decidability of the membership problem for semigroups in .

\begin{corollary}\label{cor:GL}
The membership problem for  is decidable. That is, there is an algorithm that for a given finite collection of matrices  and  from , decides whether .
\end{corollary}

\subsection{Special case: }\label{1mat}

In this section we show that for any two nonsingular matrices  and  from  and regular subsets  and , it is decidable whether there exist matrices  and  such that  (Corollary \ref{cor:1diag}). First, we prove this statement in the case when , where  is a diagonal matrix in the Smith normal form (Proposition \ref{prop:1diag}).

For the proof of this result we will use a few algebraical facts and results that are explained below. The most important of them is the following theorem about the Smith normal form of a matrix.

\begin{theorem}[Smith normal form \cite{KB79}] \label{SNF}
For any matrix , there are matrices  from  such that

for some  such that . The diagonal matrix , which is unique up to the signs of  and , is called the \emph{Smith normal form} of . Moreover, , , , and  can be computed in polynomial time.
\end{theorem}

\begin{definition}
If  is a subgroup of , then the sets  and , for , are called the \emph{left} and \emph{right cosets} of  in , respectively. An element  is called a \emph{representative} of the left coset  (respectively, of the right coset ).

The collection of left cosets or right cosets of  form a disjoint partition of . Moreover, the number of left cosets is equal to the number of right cosets, and this number is called the \emph{index} of  in , denoted . 
\end{definition}

For every natural , let us define the following subgroups of :


Let  be any matrix from  and let  be a diagonal matrix in the Smith normal form, where . Then the conjugation of  with  is equal to


From this formula we see that if , then  divides . On the other hand, if  is divisible by , then  is in , and in fact in . Thus we have the following criterion.
\begin{proposition}\label{prop:conj}
Suppose  is in  and  is a diagonal matrix of the above form, then  if and only if . Moreover, if , then .
\end{proposition}

\begin{theorem}\label{thm:ind}
The subgroups  and  have finite index in . Furthermore, there is an algorithm that for a given  computes representatives of the left and right cosets of  and  in .
\end{theorem}

\begin{proof}
We will only show how to compute representatives of the left cosets of  because the other cases are similar. For each pair of indices  such that , let us define a matrix  as follows. Let  be the identity matrix for . If , then consider  and let  and  be such that  and . Since  are relatively prime, there exist integers  and  such that . Hence if we let , then  belongs to .

Now consider an arbitrary matrix  from . Let  and , where . We will show that . If , then  is divisible by , and hence . Since we defined  to be the identity matrix, it follows that . If , then let  and let  be such that  and . In this case

and the lower left corner of  is equal to , which is divisible by . Thus .

So we showed that for any matrix  there is a pair  such that  or, equivalently, . Therefore, the collection  contains all left cosets of  in . In particular, the index of  in  is bounded by .

Note that some of the cosets in  may be equal to each other. In fact, two cosets  and  are equal if and only if . Since the domain of the subgroup  is a computable set, the equality of two cosets is a decidable property. Therefore, we can algorithmically choose a collection of pairwise nonequivalent representatives of the left cosets of  in .

\end{proof}

\begin{lemma}
\label{lem:regsub}
Let  and  be the languages that correspond to the subgroups  and , respectively, that is,  and . Then  and  are regular languages.
\end{lemma}

\begin{proof}
We will show that  is regular by constructing an automaton  that recognizes it. The proof for  is similar.

Let  be pairwise nonequivalent representatives of the right cosets of  in , which can be computed by Theorem \ref{thm:ind}. We will assume that  and hence . The automaton  will have  states , where  is the only initial and the only final state of . The transitions of  are defined as follows: there is a transition from  to  labelled by  if and only if the element  belongs to the coset . Note that since for every  and  there is exactly one  such that , the automaton  is deterministic.

We now show that the language of  is equal to . Take any word  and consider a run  of  on . Note that , and  is the initial state. Since  has transitions , for , we have that  and hence . Since , we can rewrite  as

If , that is, if  is accepted by , then  and . This implies that  because for all  we have . On the other hand, if , then it must be that , which can only happen if  and hence . This means that  is accepted by . Therefore, we proved that .

\end{proof}

Now for any automaton  with alphabet  we construct two automata  and , where  is a diagonal matrix in the Smith normal form. The automaton  recognizes inverses to the words from , that is:
\begin{enumerate}[(1)]
\item For every , there exists  such that .
\item For every , there exists  such that .
\end{enumerate}
In other words, for any matrix ,  if and only if .

{\bf Construction of the automaton .}
We will make use of the following equivalences, which are easy to check: , , , and . Informally speaking, to construct  we want to reverse the transitions in  and replace the labels by their inverses. More formally,  will have the same states as  plus some newly added states as explained below. The initial states of  are the final states of , and the final states of  are the initial states of . For every transitions of the form  and  in  we add the transitions  and  to , respectively. Furthermore, for every transitions of the form  and  in  we add the paths  and  to , respectively, where  are newly added states. It is not hard to verify that  has the desired properties.

\medskip
The purpose of the automaton  is to recognize conjugations of the words from  with matrix . To explain formally what this means, let  be a diagonal matrix in the Smith normal form, where . Recall that by Proposition \ref{prop:conj}, for any matrix ,  if and only if .
The automaton  will have the following properties:
\begin{enumerate}[(1)]
\item For every , there exists  such that .
\item For every , there exists  such that .
\end{enumerate}
In other words, we will have


{\bf Construction of the automaton .} Let  be a finite automaton in alphabet  and let  be a diagonal matrix in the Smith normal form, where .

Suppose that  has the states . Recall from the proof of Lemma \ref{lem:regsub} that the automaton , which recognizes , has the states , where  is the only initial and also the only final state. First, we construct an automaton  for the language  by taking the direct product of  and . Namely,  has the states , for  and . The initial states of  are of the form , where  is an initial state of , and the final states of  are of the form , where  is a final state of . Furthermore, there is a transition from  to  labelled by  if and only if there are transitions  and  in  and , respectively.

Next we replace every transition in  by a new path as follows. Let  be a transition in . So there must be a transition of the form  in . By construction of  as described in Lemma \ref{lem:regsub}, we have  or, equivalently, , where  are pairwise nonequivalent representatives of the right cosets of  in , such that . Hence  is a matrix with integer coefficients, that is, it belongs to . Let  be a canonical word\footnote{Actually, we can take  to be any word that represents . The fact that it is canonical is not important for our construction.} such that . Then we replace the transition  by a path of the form

where  are new states added to . Let  be an automaton that we obtain after applying the above procedure to .



To prove the first property of , take any . Then there must be an accepting run  of  on . For every transition  in the run , there is a path in  from  to  labelled by a word  such that , where . If we let , then  is accepted by . To prove that , we first note that since , the run  is an accepting run of  on , and in particular . Since , we can rewrite  as

Recall that for each , we have . Therefore,

This proves the first property of .

To prove the second property of , take any  and consider an accepting run of  on . This run passes through some states of the form , that are present in both  and , and some new states that exist only in . Let  be the subsequence of the states of the first type which appear in the accepting run of . They naturally divide  into subwords , where  is a label of the path from  to  for . By construction of , for each , there exists a symbol  for which there is a transition  in  and, moreover,  and .

Let , then  will be an accepting run of  on  and  will be an accepting run of  on . Thus . Furthermore, we have  and hence . So we can rewrite  as

From this we obtain the following equalities

This proves the second property of .


\begin{proposition}\label{prop:1diag}
Let  be a diagonal matrix in the Smith normal form and let  and  be two regular subsets of . Then it is decidable whether there exist matrices  and  such that .
\end{proposition}

\begin{proof}
Let  and  be finite automata such that  and , respectively. We will show that the equation  has a solution for some  and  if and only if \footnote{We remind that the construction of the automaton  is described in Section \ref{Can} of the Appendix.}.

First, suppose there exist matrices  and  such that . Let  and  be such that  and , respectively. Also let  for some . We can rewrite the equation  as . From this we can see that the matrix  must have integer coefficients. Hence, by Proposition \ref{prop:conj},  and . Since , there exists  such that . Also there is  such that . Since , we have . In other words,  and  are equivalent. Let  be a canonical word such that , then .

Now suppose there is a word  that belongs to . Hence there are words  and  such that  and  and . Therefore, there exists  such that . Also there exists  such that . Let  and . Then we have , which is equivalent to . Moreover, since  and , we have that  and .

The proof of the proposition now follows from the facts that the intersection of two regular languages is regular and that the emptiness problem for regular languages is decidable.
\end{proof}

\begin{corollary}\label{cor:1diag}
Let  and  be nonsingular matrices from  and let  and  be regular subsets of . Then it is decidable whether there exist matrices  and  such that .
\end{corollary}

\begin{proof}
Let  and  be the Smith normal forms of  and , respectively, that is,  and  for some . Without loss of generality, we can assume that  and  have strictly positive diagonal coefficients. Note that if the equation  has a solution for some , then, by Theorem \ref{SNF},  and  must have the same Smith normal form. Therefore, if , then the equation does not have a solution.

So suppose that  is the Smith normal form of  and . Then  is equivalent to , which we can rewrite as . Let  and . Then  and  are regular subsets of  because , and  are some fixed matrices. Now it is not hard to see that the equation  has a solution  such that  and  if and only if the equation  has a solution  such that  and . By Proposition \ref{prop:1diag}, this problem is decidable.
\end{proof}

\subsection{General case: }\label{Gen}

To prove an analog of Corollary \ref{cor:1diag} in the general case, we will extend the construction of the automaton  to  build an automaton  (where  are finite automata in alphabet  and  are nonsingular matrices from ) which will have the following properties:
\begin{enumerate}[(1)]
\item If  and there is a matrix  which satisfies the equation , then there is  such that  (and hence ).

\item If , then there are  such that .
\end{enumerate}

{\bf Construction of .}
The construction will be done by induction on~. We will use the following notations: If  and  are finite automata in alphabet , then  denotes the concatenation of  and . If  is an automaton and , then  denotes an automaton that recognizes the language . Similarly,  is an automaton that recognizes .

First, we construct an automaton , which will serve as a base for induction. Let  and  be  diagonal matrices with nonnegative coefficients which are equal to the Smith normal forms of  and , respectively. If , then define  to be an automaton that accepts the empty language. Otherwise, let  be the common Smith normal form of  and , and suppose  and  for some matrices . Let , ,  and  be canonical words that represent the matrices , ,  and , respectively, and define  to be the following automaton

The following proposition states that the automaton  indeed satisfies the desired properties.

\begin{proposition} \label{prop:aut1}
Let  be a finite automaton in alphabet , and let  and  be nonsingular matrices from . Then the automaton  has the following properties:
\begin{enumerate}[(1)]
\item If  and there is a matrix  which satisfies the equation , then there is  such that  (and hence ).

\item If , then there is  such that .
\end{enumerate}
\end{proposition}

\begin{proof}
Note that if  and  have different Smith normal forms, then by the uniqueness part of Theorem~\ref{SNF} the equation  cannot have a solution . Therefore, in this case both properties of  are trivially satisfied. Now suppose that  is the common Smith normal form of  and  and let  be matrices form  such that  and .

To see that the first property of  holds, let's take any  for which there is a matrix  that satisfies the equation . Hence we have that , which is equivalent to . Because , , and  are matrices from , we conclude that  is in . Then, by Proposition \ref{prop:conj}, we have  or, equivalently, . By the first property of the construction , there exists  such that . Let . Then  is in . Moreover, . The last equation is equivalent to , which is the same as . Hence the first property holds.

Now we prove the second property of . Let's take any . Then there exists  such that . By the second property of the construction , there exists  such that  and . The last two conditions are equivalent to the facts that  and . From the equation  we have that . Therefore, . The last equation is equivalent to , which is the same as . This proves the second property.

\end{proof}

We now explain how to construct an automaton . For convenience the description of this construction is enclosed in the following proposition.

\begin{proposition}\label{prop:autom}
Let  be finite automata in alphabet , and let  be nonsingular matrices from . Then there is an automaton  which has the following properties:
\begin{enumerate}[(1)]
\item If  and there is a matrix  which satisfies the equation , then there is  such that  (and hence ).

\item If , then there are  such that .
\end{enumerate}
\end{proposition}

The following lemma will play an important role in the proof of the inductive step in Proposition~\ref{prop:autom}. Informally speaking, it states that when we consider all possible Smith normal forms  for a fixed~, we can assume that  comes from a finite set of matrices.

\begin{lemma} \label{lem:fin}
Let  be a diagonal matrix in the Smith normal form and let  be representatives of the right cosets of  in . Then

\end{lemma}

\begin{proof}
Consider a matrix  for some  and choose  such that . In this case we have that , and thus  belongs to  by Proposition~\ref{prop:conj}. Let . Then we have an equality , and hence . The inclusion in the other direction is obvious.

\end{proof}

\begin{proof}[Proof of Proposition \ref{prop:autom}]
The proof will be done by induction of . The base case when  follows from Proposition \ref{prop:aut1}. Now suppose the proposition holds for , and thus we have a construction for the automata of the form  which satisfy the properties (1) and (2) above. Using these automata, we will show how to construct an automaton .

Let  be equal to the Smith normal form of the matrix  and let  be representatives of the right cosets of , which can be computed by Theorem \ref{thm:ind}.
Then we define  to be an automaton that recognizes the following union of regular languages


To see that the first property holds for , let's take , and suppose there is a matrix  which satisfies the equation

By Lemma \ref{lem:fin}, there is  and  such that . So the above equation is equivalent to the following system of equations

Since , by the inductive hypothesis there is a word  such that

and

Moreover, since , by Proposition \ref{prop:aut1}, there is a word  such that . Combining the last two equations together we obtain that

or, equivalently,

Note that

and hence . Therefore, property (1) holds.

To show the second property, let's take . Then there is  such that

Therefore, there are words  and  such that

and . By Proposition \ref{prop:aut1}, there is  such that

Furthermore, by the inductive hypothesis, there are  such that

Combining the last two equation together we obtain

Note that , and hence we have .  Therefore, property (2) holds.

\end{proof}

\begin{theorem}\label{thm:diag}
Let  be nonsingular matrices from  and let  be regular subsets of . Then it is decidable whether there exist matrices  such that .
\end{theorem}

\begin{proof}
Let  be finite automata such that , for each . Now consider an automaton  which was constructed in the proof of Proposition \ref{prop:autom}. We will show the following equivalence: there exist matrices  that satisfy the equation  if and only if

The statement of the theorem then follows from the decidability of the emptiness problem for regular languages. 

First, suppose there are matrices  such that . Then there are words  such that

By property (1) of Proposition \ref{prop:autom}, there is a word  such that

In particular, we have . Furthermore, by the construction of , there is a word  such that . So we have , that is, . Let  be the canonical word that is equivalent to  and . Then


On the other hand, suppose there is a word  such that

Then there are words  and  such that  and  and . Hence there is  such that . Also by property (2) of Proposition \ref{prop:autom}, there are words  such that

Since , we have that . Therefore, the above equation is equivalent to

Now if we let , then for each  the matrix  belongs to , and hence we have .

\end{proof}

\section{Appendix}

\subsection{Construction of the automaton }\label{Can}
Let  be a finite automaton with alphabet . We will construct a new automaton  such that the language of  contains only canonical words and , that is, . In order to do this, we will define a sequence of transformations called ,  and  which will have the following properties:
\begin{itemize}
\item ,
\item , that is,  accepts only those words that have at most one occurrence of  which may appear only in the first position,
\item  and, moreover,  accepts only those words that do not contain subwords of the form ,  and  for any ,
\item  accepts only canonical words,
\item finally, we will have the equivalences .
\end{itemize}
We now describe each of these transformations in detail.

{\bf Transformation .} We will make use of the following equivalences which can be easily verified: , , and .

First, for every transition  which appears in , we add new states ,  and a new path of the form . Note that since , the addition of such paths produces an equivalent automaton. Similarly, for any transition  in , we add new states , ,  and a path . Finally, for any transition  in , we add new states , , , ,  and a path . Again, the addition of such paths produces an equivalent automaton. Let us call this automaton .

Now for every pair of states ,  in , which are connected by a path labelled with , we add an -transition . We repeat this procedure iteratively until no new -transitions of this type can be added. Let  be the resulting automaton. Note that since  is equivalent to the empty word, which represents the identity matrix , the automaton  is equivalent to  and hence to~.

Let  be an automaton that recognizes the intersection . Obviously, the language of  is a subset of , so we only need to show that . Take any , then  and since , there is  such that . Next, we need to prove that for any , there is  such that .

Let us take any . To construct the required word , we first need to find all occurrences of letter  in . For example, suppose that , where each . If the number of 's is odd, then in each subword  with odd  we replace every occurrence of , , and  with , , and , respectively, and leave 's with even  unchanged. On the other hand, if the number of 's is even, then we apply such substitution to each  with even  and leave 's with odd  unchanged. Let  be the resulting word. Then by construction  and . Next, we repeatedly remove all occurrences of the subword  from . This will give us a word  such that  and  contains at most one letter , which may appear in the first position. Hence . This idea is illustrated by the following example. Let , so  contains an odd number of 's and hence

In the above formula parentheses are inserted only to visually separated subwords in . After removing subwords  from  we obtain  such that .
The next example illustrates the same idea for an even number of 's. Let , then

After removing  from  we obtain  such that . This completes the proof that .

{\bf Transformation .} To construct  from  we will make use of the following equivalences  and . We will also use the fact that  commutes with , , and , and that  is equivalent to the empty word.

First, we apply the following procedure to :
\begin{enumerate}[(1)]
\item For any pair of states ,  in  that are connected by a path labelled with , we add an -transition .

\item For any pair of states ,  in  that are connected by a path labelled with , where  (recall that  denotes the empty word), we add a new transition , where .

\item For any pair of states ,  in  that are connected by a path labelled with , where , we add a new transition , where  is such that .
\end{enumerate}
We repeat the above steps iteratively until no new transitions can be added.

Let  be the resulting automaton. By construction, we have . Let  be the regular language which consists of all words in alphabet  that do not contain subwords of the form ,  and  for any . Define  as an automaton that accepts the language . It is not hard to see that the language of  is contained in .

What is left to show is that . If , then , and hence  for some  because . On the other hand, if , then we can repeatedly remove subwords  from  and replace subwords of the form  and , for , with  and , respectively, where  and  is such that . Let  be a resulting word that does not contain subwords ,  and  for any . Then  and .

{\bf Transformation .} The words accepted by  are almost in canonical form with the exception that the letter  may appear in the middle of a word. To get rid of such 's we use a similar idea as in the construction of . Namely, we will use the following equivalences:  and . Note that we will not need the equivalence  because the letter  can appear only at the beginning of a word.

To construct  from , we do the following. First, for every transition  which appears in , we add new states ,  and a new path of the form . Similarly, for every transition  which appears in , we add new states ,  and a new path of the form . After that we iteratively add  transitions  for every pair of states ,  that are connected by a path with label . We do this until no new -transitions can be added. 

Let  be the resulting automaton, which is by construction equivalent to . Let  be the regular language which consists of all canonical words in alphabet . Define  as an automaton that accepts the language . Therefore,  accepts only canonical words.

The proof that  is similar to the proof that  given above. If , then  and hence  for some  because . On the other hand, if , then to construct  such that  we first find all occurrences of the letter  in . For example, let  has the form  or the form , where each . If the number of 's is odd, then in each  with odd  we replace every occurrence of  and  with  and , respectively, and leave 's with even  unchanged. If the number of 's is even, then we do the same substitution in all 's with even  and leave 's with odd  unchanged. After that we remove all occurrences of . If  is a resulting word, then  and . Moreover, since  is in canonical form, we also have . This idea is illustrated by the following example. Suppose , then after replacing suitable occurrences of  and  with  and , respectively, we obtain the word

After removing all occurrences of  we obtain the word  which is in canonical form, and hence . This completes the construction of .



\bibliographystyle{abbrv}
\bibliography{refs}


\end{document}
