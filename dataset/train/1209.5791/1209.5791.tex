\documentclass[11pt]{article}
\usepackage{amsmath, amssymb, amsthm, algorithm, algorithmic, color}
\usepackage{enumerate, graphicx, hyperref}
\usepackage{cite}
\usepackage{wrapfig}
\usepackage{authblk}
\usepackage[margin=1in]{geometry}
\newcommand{\Real}{\mathbf{R}}
\DeclareMathOperator{\rank}{rank}

\newtheorem{lemma}{Lemma}
\newtheorem{theorem}{Theorem}
\newtheorem{corollary}{Corollary}

\title{Windows into Relational Events:\\ Data Structures for\\ Contiguous Subsequences of Edges}
\author[1]{Michael J. Bannister}
\author[2]{Christopher DuBois}
\author[1]{David Eppstein}
\author[1]{Padhraic Smyth}
\affil[1]{Department of Computer Science, University of California, Irvine}
\affil[2]{Department of Statistics, University of California, Irvine}
\begin{document}
\maketitle
\begin{abstract}
We consider the problem of analyzing social network data sets in which the edges of the network have timestamps, and we wish to analyze the subgraphs formed from edges in contiguous subintervals of these timestamps. We provide data structures for these problems that use near-linear preprocessing time, linear space, and sublogarithmic query time to handle queries that ask for the number of connected components, number of components that contain cycles, number of vertices whose degree equals or is at most some predetermined value, number of vertices that can be reached from a starting set of vertices by time-increasing paths, and related queries.
\end{abstract}

\thispagestyle{empty}
\newpage
\setcounter{page}{1}
\pagestyle{plain}

\section{Introduction}
The study of algorithms for social network analysis has so far been concentrated primarily on computations involving graphs that are relatively static: either a fixed graph is given as input to algorithms for problems such as the computation of centrality~\cite{EppWan-SODA-01,Bra-JMS-01,OkaCheLi-FAW-08,Kin-08}, or the input graph is assumed to change gradually by insertions and deletions of vertices and edges, and these changes can be handled efficiently by dynamic graph algorithms~\cite{EppGalIta-ATCH-99,EppSpi-WADS-09,EppGooStr-COCOA-10}. These input models work well for networks that describe long-term ties such as friendship or supervisorial relations between people, and they often match the information provided by online service providers such as Facebook. However, there is a second type of social network data set, known variously as \emph{relational event data}~\cite{But-SM-08}, \emph{dyadic event data}~\cite{BraLerSni-ASONAM-09}, \emph{longitudinal network data}~\cite{GolZheFie-FTML-09,Noo-SN-11},  \emph{contact sequences}~\cite{Hol-PRE-05}, or \emph{time-ordered networks}~\cite{Moo-SF-02}, on which we would also like to perform efficient computations. This type of data models communication events between pairs of people rather than long-term ties; for instance, each datum in a data set might consist of the identities of the sender and recipient of a single email message along with its timestamp.\footnote{For example, Kossinets and Watts describe an email data set of this type with approximately 7 million email messages, sent by approximately 30,000 people within a single university campus over the course of a year~\cite{KosWat-AJS-09}.} At any instant of sampled time there is no graph, only a single edge.

It is only by grouping together multiple events over sliding windows of time that we can form a network from this type of relational event data~\cite{CorPreVol-JCGS-03,MooMcFBen-AJS-05,KosWat-AJS-09}. If a fixed window size is chosen, the sequence of time windows can be modeled by the insertion of an edge when it enters the window, and deletion when it leaves the window; these types of change are familiar in the analysis of algorithms as the basis for many dynamic graph algorithms~\cite{EppGalIta-ATCH-99}. However, the dynamic graph model is too restrictive for our purposes, because it may not be obvious what length of time window to use. Long windows present a relatively static view of the data, aggregating it into a single graph but losing all dynamic time information. Short windows capture the dynamics better but may be too sparse to see the entire pattern of connections; indeed, for very short windows, the subset of data within any window may have few or no vertices with degree higher than one. Thus, it may be useful to perform exploratory data analysis by testing different sizes of window to find the one that best balances connectivity with dynamics, or to study the same data set with multiple window sizes to show how its behavior varies with the time scale.

In this paper we provide for the first time an algorithmic model for the analysis of relational event data with windows chosen dynamically rather than a priori, and we also develop fundamental data structures that can perform this analysis efficiently. In our model, the input to a relational event data analysis problem is formulated as a sequence of (directed or undirected) edges, and we define a \emph{slice} of the data to be the graph formed by a contiguous subsequence of the input. The data structures that we describe  represent the entire relational data set using only linear space, can be constructed in near-linear time, and support queries that ask for statistical information about arbitrary slices of the data in sublogarithmic time per query. The graph properties that our data structures can handle include many quantities already studied (for static networks) by social networking researchers, including the following:
\begin{itemize}
\item We can count the number of connected components of a slice, the number of nontrivial components (with more than one vertex), the number of \emph{loopy components} (components that contain at least one cycle), the average size of a connected component,  the average size of a nontrivial connected component, and the number of \emph{loopy edges} (edges that close a cycle).  Such queries concern the connectivity structure of the network, providing insight into diffusion processes and the robustness of these processes to intervention.  In sexual networks, for example, a scarcity of short cycles implies the absence of a dense core, a fact with implications for the study and treatment of HIV \cite{BeaMooSto-AJS-04, PotPhiPlu-STI-02} and Gonorrhoea~\cite{DeSinWon-STI-04, PotMutRot-STI-02}. In such networks loopy edges represent reinfection events, which fuel the growth phase of an outbreak~\cite{PotMutRot-STI-02}.
\item We can count the number of isolated vertices in a slice, the number of isolated edges, the number of edges that have  neighboring edges for any constant~, and the number of vertices that have exactly or at most  neighboring edges or vertices for any predetermined (but not necessarily constant)~. These parameters provide access to the \emph{degree distribution} of a network, which has long been recognized as important in social network analysis; for instance, Seidman~\cite{Sei-SN-83} emphasizes the importance of distinguishing between networks with uniform degrees from networks in which there are a few high degree vertices and many low degree vertices.
\item We can count the number of repeated edges within a slice, the number of edges with multiplicity exactly or at most~, and the \emph{reciprocity} (relative proportion of pairs of vertices connected by directed edges in both directions to pairs connected only in one direction). In social networks where directed edges represent communication, reciprocity has been used to quantify the amount of social interaction versus broadcast communication~\cite{Gong11, Diego04}.
\item We can count the number of vertices that can be reached from a predetermined set of starting vertices, via (directed or undirected) paths in which the timestamps of the edges are monotonically increasing. These paths have also been called \emph{journeys}~\cite{BuiFerJar-WiOpt-03} or \emph{diffusion paths}~\cite{Moo-SF-02}; they are the possible transmission routes of information or contagion through the network, and the number of reachable nodes has been studied (for the aggregate graph rather than for slices) by Holme~\cite{Hol-PRE-05}. We can also count the number of vertices that can be reached by paths of this type with bounded hop count.
\item We can count the number of \emph{triad closure events} in which an edge belongs to at least one triangle formed by it and earlier edges within the slice. Triads and related transitivity properties such as the clustering coefficient have long been recognized as important in the structure of social networks~\cite{Gra-AJS-73,Rap-BMB-53} and the number of triad closure events, like monotonic reachability,  also incorporates time-dependence in its definition. Our data structure for counting them involves somewhat slower preprocessing, comparable to the time to find or count triangles in a static graph.
\end{itemize}

\begin{wrapfigure}[14]{r}{0.28\textwidth}
\vspace{-1.5em}
\centering
\includegraphics[width=0.28\textwidth]{figures/dom-q}
\vspace{-2em}
\caption{Example dominance query where the points in the shaded region are counted.}
\label{fig:dom-q}
\vspace{-0em}
\end{wrapfigure}
We show how to reduce each of these problems to two-dimensional \emph{dominance counting} queries on point sets derived from the input network, with  points per network edge. In the variant of two-dimensional dominance counting that we use, a data set consists of a set of  two-dimensional points with integer coordinates  satisfying , and each query must determine the number of points dominated by a query point , i.e., the number of points  with  and . Through a slight abuse of terminology we will use the term dominance counting when counting the number of points contained in any one of the four quadrants created by placing the query point  in the plane.  As we describe, many of the problems listed above can be reduced to dominance counting through a common unification in terms of the rank function of matroids,  generalizing a data transformation for one-dimensional colored range counting given by Gupta et al.~\cite{ColorRangeQueries}.
For the remaining problems (including isolated edges and monotonic reachability) our reduction instead passes through another two-dimensional range searching problem, rectangle stabbing. Combining our reductions with known dominance counting data structures~\cite{JaJMorShi-ISAAC-04} would allow us to solve these problems in linear space and query time , where  is the number of edges in the input network; in an appendix we provide a refined dominance counting structure that improves the query time to  where  is the number of edges in the queried slice. We also outline an alternative solution based on path-copying persistence~\cite{DSPersistent} and balanced binary trees that we expect to be more suitable for implementation; it uses  space and gives query time .

In another appendix, we adapt a lower bound of Mihai P{\v a}tra{\c s}cu for two-dimensional range counting~\cite{Pat-STOC-07} to the problems studied here, using reductions in the other direction from point sets to networks. We show that, in the cell probe model, with query time measured as a function only of the input size (rather than of the window size, as in our upper bounds) all data structures that use space  must take  query time to solve many of the queries considered here.

\section{Problem formulation}
Define a \emph{relational event graph}  to be a fixed set of vertices  together with a sequence of edges (or relational events)  between pairs of vertices. The graph is undirected if the pairs are unordered, and directed if the pairs are ordered. The pairs in the sequence are not required to be distinct from each other.
Given a relational event graph  we define the \emph{slice multigraph}  to be the multigraph with vertices  and edges .

We assume that the entire relational event graph  is given to us as input.  Our task is to construct a data structure from  that will allow us to compute the properties of its slices , for a query pair of indices . To avoid trivial solutions, queries in such a data structure should take less time than the  of an algorithm that constructs the slice multigraph and applies a static graph algorithm to it, and the data structure should use less space than the  of an algorithm that precomputes and stores the answers to all possible queries.

\section{Matroid rank}
We will turn many of our queries into a matroid rank problem. Recall~\cite{Lawler01, Welsh10} that a \emph{matroid} over a set  is a collection of subsets of  called \emph{independent sets} 
obeying the following three properties:
\begin{itemize}
\item The empty set is independent.
\item Every subset of an independent set is independent.
\item If  and  are independent sets and  is larger than~, then there exists  such that  is independent.
\end{itemize}
The \emph{rank} of a set  is the size of the largest independent subset of , and a \emph{circuit} is a minimal dependent subset (i.e., a set whose proper subsets are all independent).

We will define matroids over sequences  of elements (usually the edges of our input graph); we form slices  from contiguous subsequences of this sequence. The rank of  will then be useful for computing the numerical graph quantities we wish to compute; for instance, we will use the graphic matroid (whose rank is the number of edges in a spanning forest) to determine the numbers of connected components and loopy edges in a slice. In order to calculate the rank of a slice, we define the \emph{independence time}  for an element  to be the smallest index  such that , or  if the inequality holds for all . A straightforward induction on  shows that the rank of every slice  equals the number of matroid elements in the slice whose independence is before the interior of the slice.

Our meta-algorithm for precomputing  (needing details to be filled in for  specific matroids) assigns a weight to each element, equal to its index. It then incrementally considers the elements in sequence order, maintaining as it does a maximum-weight basis of the set of elements considered so far. When adding element  to the basis would cause it to remain independent, the augmented set becomes the new basis and in this case we set . However, when the previous basis and the new element together contain a circuit (necessarily a unique circuit), we form the new basis by removing the lightest element from this circuit, and adding  in its place; in this case,  is one more than the index of the removed element. Later, when we discuss specific matroids, we will describe how to quickly identify the circuit containing the new element and the lightest element of this circuit.

\begin{lemma}\label{lem:general-matroid}
The elements of  can be mapped to points in  such that the rank of  can be determined by a dominance counting query. The time needed for this mapping is the same as the time to compute  for all elements in .
\end{lemma}
\begin{proof}
We map each  to . To determine the rank of  we count the number of elements whose independence time is in the slice's range of indices, i.e.,   and . This three sided query can be reduced to the dominance counting query  and , as it is not possible to have . We then take the complement to count the edges whose independence time is before the interval.
\end{proof}

\section{Counting vertices by degree and edges by multiplicity}
In this section we use partition matroids (a standard type of matroid, defined below) to determine the number of vertices of bounded degree, the number of vertices of a specific degree, the number of edges of bounded multiplicity, the number of edges of a given multiplicity, and the reciprocity of a slice in a relational event graph. Our techniques can also solve the colored range counting problem considered in~\cite{ColorRangeQueries}, using colors to define the partition, and our Lemma~\ref{lem:vertex-degree} generalizes their data transformation approach for colored range counting.

In general, a partition matroid is defined over a set  that has been partitioned into a family of disjoint subsets  for , each of which is associated with a numeric parameter . A subset  of  is defined to be independent in the matroid if  has at most  elements for each . Each circuit of this matroid is a subset of exactly  elements of one of the sets . It is straightforward to verify that the independence system defined in this way satisfies the axioms of a matroid~\cite{Welsh10}.

Given a relational event graph  with edge sequence  and a parameter  we consider a partition matroid whose elements are the set of half-edges  and  for each edge  in . In this matroid we define a set  to be independent if each vertex of  appears at most  times in the first component of a half-edge, where  is a fixed parameter. That is, there is one set  for each vertex , containing all the half-edges , and the corresponding partition matroid parameter is . The rank of this partition matroid is given by 

\begin{lemma}\label{lem:vertex-degree}
We can compute  for the partition matroid described above in linear time and space.
\end{lemma}
\begin{proof}
We process the half-edges in index order, adding them to a dictionary that associates each vertex with a -element queue of insertion times. When inserting a new half-edge, if its endpoint's queue is full, we dequeue the top half-edge and record one more than its index for  of the current half-edge; otherwise we record  for  of the edge. Then, regardless of whether the queue was full, we add the half-edge to the queue. By storing the queues as linked lists this can be done in linear space and time.
\end{proof}

\begin{theorem}\label{thm:vertex-degree}
Given a relational event graph  the problems of determining the number of isolated vertices, vertices of a given degree~, and vertices of bounded degree in  can be reduced to dominance counting in linear time and space.
\end{theorem}

\begin{proof}
We use our solution to the matroid rank problem (Lemma~\ref{lem:general-matroid}) to create two data structures for the partition matroid with  and with . Then by performing two dominance counting queries we can compute

which is equal to the number of vertices of degree greater than . With the ability to count the number of vertices of degree greater than  we can easily compute the queries stated in the theorem by inclusion-exclusion.
\end{proof}

We define the \emph{multiplicity} of an edge in a directed or undirected relational event graph to be the number of other edges that have the same two endpoints (as an ordered or unordered pair, respectively).
We can count the distinct edges, the edges that have a given multiplicity, or the edges that have bounded multiplicity, using a partition matroid whose elements are the edges, and whose partitions group together edges that have the same ordered or unordered pair of endpoints.

\begin{theorem}
Given a (directed) relational event graph  the problems of determining the number of distinct directed or undirected edges, edges of bounded multiplicity, reciprocated edges, and the reciprocity in   can be reduced to dominance counting in linear time and space.
\end{theorem}

\begin{proof}
The number of edges with given multiplicity can be counted using ranks in a partition matroid, as in Theorem~\ref{thm:vertex-degree}.

To determine the number of reciprocated edges, we count the number of distinct edges in two different ways, interpreting the same graph once as a directed graph and a second time as an undirected graph. Reciprocated edges are counted twice as distinct directed edges but only once as undirected, and unreciprocated edges are counted once either way, so the number of reciprocated edges is the difference between the numbers of distinct directed and undirected edges. The reciprocity is then the ratio of reciprocated edges to all edges.
\end{proof}

\section{Counting connected components}
To count the number of connected components in a graph we use the \emph{graphic matroid}~\cite{Welsh10}, another standard type of matroid. The graphic matroid of an undirected graph  has the edges of  as its elements; a set of edges is independent in the graphic matroid if it forms a forest. A circuit in the graphic matroid is a simple cycle in , and the rank of the graphic matroid on a set of edges is the number of vertices minus the number of connected components.

To count connected components that contain cycles we use the \emph{bicycle matroid} (or \emph{bicircular matroid})~\cite{Matthews77}, a somewhat less-well-known matroid that also has the edges of a graph as its elements. In the bicycle matroid, a set of edges is independent if it forms a \emph{pseudoforest}, a graph that has at most one cycle per connected component or equivalently a graph in which each subgraph has at most as many edges as vertices. The rank of the bicycle matroid on a set of edges is the number of vertices minus the number of tree components.

To precompute  for both of these matroids, we use \emph{linking and cutting trees}~\cite{LinkCutArt, LinkCutBook}. These are data structures that may be used to represent a rooted forest, subject to updates that either insert edges (if the result of the insertion would still be a forest) or delete them. Cutting and linking trees also allow operations to look up the root of the tree containing a query vertex or the lightest edge on any path. Both updates and queries take logarithmic time per operation, and the overall data structure uses linear space.

\begin{lemma}\label{lem:connected-component}
We can precompute  for the graphic matroid in  time and linear space.
\end{lemma}
\begin{proof}
We store the vertices of  into a linking and cutting tree, and then process the edges in increasing order. When adding an edge  to the forest we check if it creates a cycle. If so, we find the lightest edge on the path from  to , record one more than its index as , remove the light edge from the forest, and add  to the forest. If adding  does not create a cycle, then we add it to the forest and record  for . For each edge we do  work, for a total processing time of .
\end{proof}

\begin{theorem}\label{thm:connected-component}
Given a relational event graph  the problems of determining the number of connected components, nontrivial connected components, average size of a connected component,  average size of a nontrivial connected component, and the number of loopy edges in  can be reduced to dominance counting in  time and linear~space.
\end{theorem}

\begin{proof}
The number of connected components follows from the matroid rank problem (Lemma~\ref{lem:general-matroid}) together with Lemma~\ref{lem:connected-component}. For nontrivial components we use Theorem~\ref{thm:vertex-degree} to count isolated vertices and subtract this value from the number of forests. The average component sizes can then be computed easily. To count the number loopy edges we observe that the number of loopy edges equals the total number of edges minus the number of edges in a spanning forest, i.e., it is the number of edges in the slice minus the graphic matroid rank of the slice.
\end{proof}

When computing  for the bicycle matroid we will need to dynamically maintain a pseudoforest. To do this we augment the linking and cutting tree with a dictionary whose keys are the tree roots and whose associated values are the lightest edges in the cycles of the corresponding pseudotrees (or null for tree components). Thus, the linking and cutting tree always stores the maximum spanning forest, and the dictionary holds the missing edges of each pseudotree.

\begin{lemma}\label{lem:loopy-component}
We can precompute  for the bicycle matroid in  time and linear space.
\end{lemma}
\begin{proof}
When adding a edge  we consider five possible cases: (1) two trees are joined, (2) a cycle is created in a tree,  (3) a tree and a pseudotree are joined, (4) a second cycle is formed in a pseudotree, (5) two pseudotrees are joined.

In cases (1), (2) and (3) we are left with a pseudoforest so we record  for . In case (2) we remove the lightest edge on the cycle formed by  from the linking and cutting tree, and place it in the dictionary; in all cases we add  to the linking and cutting tree. In case (3) we update the key for the lightest edge in the pseudotree with its new root, if the root changes.

In cases (4) and (5) we find and discard the lightest edge in the union of the two cycles and the path (if it exists) between them, 
either returning to a component with one cycle or splitting it into two components each with a cycle. We update the cutting and linking tree and dictionary, and record one more than the index of the discarded edge as .

Since we only added  space and  time to the procedure in Lemma~\ref{lem:connected-component} we have the same space and time bounds.
\end{proof}

\begin{theorem}
Given a relational event graph  the problems of determining the number of loopy components, tree components, and nontrivial tree components in  can be reduced to dominance counting in  time and linear space.
\end{theorem}
\begin{proof}
The number of trees follows from the matroid rank problem (Lemma~\ref{lem:general-matroid}) and Lemma~\ref{lem:loopy-component}. For loopy components we also build the data structure in Theorem~\ref{thm:connected-component} and subtract the number of trees from the number of connected components. For nontrivial trees we build the data structure in Theorem~\ref{thm:vertex-degree} and subtract the number of isolated vertices from the number of trees.
\end{proof}

\section{Counting edge neighbors}
In this section we compute the number of edges that have a given or bounded number of neighboring edges. This does not seem to be an instance of the matroid rank problem. Instead, we reduce it to a rectangle stabbing problem.

For an edge  we define a \emph{past neighbor} to be an edge  sharing at least one vertex with   and having , and we define a \emph{future neighbor} to be an edge  sharing at least one vertex with  and having . Let  denote the least  such that  has  neighbors in  by , and let  denote the greatest  such that  has  neighbors in~.

\begin{lemma}
We can precompute  and  in  time and linear space.
\end{lemma}
\begin{proof}
First we precompute  by processing the edges (as half-edges) in index order, adding them to a dictionary structure, as in Lemma~\ref{lem:vertex-degree}, indexed by the vertex and storing the insertion times in -sized queues. When inserting a new edge  we consider the queues for both  and . If the sum of the sizes of the two queues is less than  then we record  for . Otherwise we iterate through the queue to find the least  such that there are exactly  neighbors with index greater than  and record this as . Finally, we add the two half-edges to their respective queues, dropping the top half-edge if the queues overflow. This process is done in  time,  to iterate through the queues, and  space. To compute  we repeat the process in reverse, which takes  time in  space.
\end{proof}

\begin{lemma}\label{lem:rectangle-stabbing}
Given a set of rectangles, the problem of determining which rectangles are stabbed by (enclosing) a query point can be reduced to a constant number of dominance counting queries.
\end{lemma}

\begin{wrapfigure}[13]{r}{0.26\textwidth}
\vspace{-1em}
\centering
\includegraphics[width=0.23\textwidth]{figures/rectangle-stab-v2}
\vspace{-1em}
\caption{Turning stabbing into dominance.}
\label{fig:rectangle-stab}
\vspace{-2em}
\end{wrapfigure}
\noindent\emph{Proof.}
The number of rectangles stabbed by point  can be reduced to a linear combination of the counts of rectangle corners belonging to six different combinations of  corner type and apex- quadrant, using an inclusion-exclusion relation that seems to be folklore.
Figure~\ref{fig:rectangle-stab} provides an illustration: if we add  for each rectangle whose geometric relationship to  is indicated by the blue L-shapes, and  for each rectangle whose relation to  is indicated by the red L-shapes, then each rectangle containing  adds a total of  to this sum (only for its lower left corner) while each other rectangle adds zero (either with two corners that cancel each other, or no corners). Therefore the total sum equals the number of rectangles stabbed by .

Therefore, to answer rectangle stabbing queries, we may build three (signed) dominance counting data structures,  one for each of the nonempty quadrants in the figure, giving us the contributions from each quadrant. \qed

\begin{theorem}\label{thm:future-past}
Given a relational event graph  the problem of determining the number of edges with at most  past neighbors and at most  future neighbors in  can be reduced to dominance counting in  time and linear space.
\end{theorem}
\begin{proof}
An edge  has at most  past neighbors and at most  future neighbors in  (and is in ) precisely when .
If we view  as a point in , then this happens when the rectangle  encloses the point , which reduces to dominance counting by Lemma~\ref{lem:rectangle-stabbing}.
\end{proof}


\begin{corollary}
Given a relational event graph  the problem of determining the number of edges with  past neighbors and  future neighbors, the number of isolated edges, and the number of edges with  neighbors in  can be reduced to dominance counting in  time and linear space, except for the number of edges with  neighbors which takes  time and space.
\end{corollary}
\begin{proof}
For edges with past and future neighbors we use Theorem~\ref{thm:future-past} to compute the four data structures that compute  (the number of edges with past and future edges bounded by  and ) for all combinations of  and . Then to compute the number of edges with exactly  past neighbors and  future neighbors we use inclusion-exclusion:

To count isolated edges we set . To count edges with exactly  neighbors we sum over the edges with  past and  future neighbors for all combinations of  and  satisfying .
\end{proof}


\section{Determining influence}
In this section we designate a fixed set of vertices as \emph{influential vertices} and seek to find the number of \emph{influenced vertices}, where vertex  is influenced if there is a path of index-increasing edges from a influential vertex to~. Such a path will be called a \emph{path of influence}. If we think of the edges as communication events, then this models the flow of information from the influential vertices. Motivated by the degradation of information as it is relayed we also consider the number of \emph{-influenced} vertices, i.e., vertices that are on a path of influence with less than  edges. This query also does not appear to be an instance of the general matroid slice problem.

For each edge insertion  we define  to be the greatest  such that  is influenced in , and  the least  such that  is influenced in .

\begin{lemma}\label{lem:influence}
The values of  and  can be computed in linear time and space.
\end{lemma}
\begin{proof}
We consider the edges  in sequence order, setting  and  as we do.

The edge  is on a path on influence only if either  is a influential vertex or an influenced vertex ( is set). If  is an influential vertex, then . Otherwise, we set  to  when  or  is unset, and do nothing when . The computation of  is similar.
\end{proof}

\begin{theorem}\label{thm:influence}
Given a relational event graph  the problem of determining the number of influenced vertices in the slice  can be reduced to dominance counting in linear time and space.
\end{theorem}
\begin{proof}
We will count the number of influenced vertices in  by counting the number of destination vertices of edges in  that are not influenced (counted with multiplicity) and then taking the complement. A vertex  cannot be influenced in  unless there is an edges  in  with , i.e., . Now  is not influenced in  whenever , i.e., when the point  is in the rectangle . Now that the problem is reduced to rectangle stabbing we use Lemma~\ref{lem:rectangle-stabbing}.
\end{proof}

\begin{theorem}
Given a relational event graph and a predetermined value  the problem of determining the number of -influenced vertices in the slice  can be reduced to dominance queries in  time and linear space.
\end{theorem}
\begin{proof}
We modify the argument in Lemma~\ref{lem:influence} and Theorem~\ref{thm:influence} to keep track of  and  for -influence for each vertex and for each choice of   instead of just for influence. It takes  time per edge to update these times of -influence.
\end{proof}

\section{Counting triad closure events}

Define a \emph{triad closure event} in an undirected relational event graph to be an edge  within a given slice  such that  is the final edge of at least one triangle; that is, such that the other two edges of the triangle also belong to the same slice but are earlier in the sequence of edges than .
To count these events we define  to be the smallest index  such that  does not belong to a triangle in . Then, the number of triadic closure events for slice  is exactly the number of edges  satisfying , something that can be counted with the same mapping to  and dominance query in Lemma~\ref{lem:general-matroid}. The difficulty, for this problem, is in the preprocessing: how do we compute  efficiently, for all edges~?

To solve this problem, we adapt a data structure of Eppstein and Spiro~\cite{EppSpi-WADS-09} for counting triangles in a dynamic graph. This data structure is based on the concept of the \emph{-index} of the graph, the largest number  such that the graph contains at least  vertices of degree at least ; all graphs with  edges satisfy .  Eppstein and Spiro maintain a slowly-changing partition of the graph vertices into two subsets  and , where  contains  vertices and where every vertex in  has degree . We simplify this by computing the -index of the aggregate graph and partitioning its vertices into static subsets  and , where  and where every vertex in  has degree at most~.

Next, we loop through the edges in sequence order, maintaining as we do two hash tables  and  indexed by pairs of vertices. The first of these two tables, , stores the most recent edge with those two endpoints (if such an edge has already been encountered in the edge sequence). The second table,  stores the two-edge path from  to  via a third node  that maximizes the index of the earlier of the two edges  and , if  such a path exists and  has an edge~. We also maintain an adjacency list for each vertex, listing the vertices connected to it by edges that have already been encountered.

From this information, we can compute  in time : let  and  be the endpoints of , look up in  the best path through a vertex in , and find the best path through a vertex in  by testing all  choices for this vertex using  to test each choice in constant time. Once  has been computed, we may also update  and the adjacency lists in constant time. To update , for each endpoint  of  that belongs to , loop through each neighbor  of , find the two-edge path combining  and , and use this path to update  where  is the other endpoint of . This update process takes constant time per neighbor, and there are at most  neighbors, so again the time is .

\begin{theorem}
Given an undirected relational event graph  the problem of determining the number of triad closured in the slice  can be reduced to dominance counting in  time and linear space.
\end{theorem}
\begin{proof}
We perform the preprocessing steps described above to compute  for each edge , in total time , and then use the same persistent finger tree structure described in the matroid rank data structure (Lemma~\ref{lem:general-matroid}), using  in place of the similar index  of the matroid rank data structure.
\end{proof} 

\section{Conclusions}
We have described data structures for many counting problems on slices of relational event data. Our analysis separates preprocessing from queries,  but many of our data structures preprocess the data in sequence order, allowing queries to be interleaved with the addition of new data to the end of the sequence.

Many interesting social network parameters remain to be addressed, including the clustering coefficient, the -index, the number of vertices reachable via non-monotonic paths, and the size of the largest connected component. In addition, several of the parameters for the statistics we compute (such as the hop count and  influential vertices in our influence-counting structure) must be determined at preprocessing time, and it would be of interest to develop more flexible structures that can delay the choice of these parameters until query time. Thus, although we have shown many interesting graph statistics to be computable efficiently in our model, much more remains to be done.

\newpage

\subsection*{Acknowledgements.}
This research was supported in part by the National Science Foundation under grant 0830403, and by the Office of Naval Research under MURI grant N00014-08-1-1015.

{\raggedright
\bibliographystyle{abuser}
\bibliography{win-rel-events}}

\newpage
\appendix
\section{Window-sensitive dominance counting}

Suppose we are given as input a set  of  points, with integer coordinates in the range from  to ; we wish to answer \emph{dominance counting queries}, where a query specifies a point  and must count the number of points  with  and .
JaJa, Mortensen and Shi~\cite{JaJMorShi-ISAAC-04} provide a data structure for this problem, in the word RAM computation model, that uses linear space and achieves  query time. More precisely, they show (in their Lemma 5) that in a model of computation in which each word contains at least  bits of information and in which tables of size  may be precomputed,
then it is possible to represent sets of  points in space  and achieve query time . (Gupta et~al.{} make an additional assumption, that the points of their data set have distinct coordinates, but this can be achieved with no loss of generality and with no change to their space or query time bounds by sorting the points by their coordinate values and replacing the coordinates by indices into the sorted order.)
Applying this structure directly to the point sets generated from our reductions would give us query time  and space , where  is the number of edges in the given relational event graph. Instead, we show that it is possible to achieve slightly faster query time, , where  is the number of edges in the query slice.

The key observations needed for this improvement are the following:
\begin{itemize}
\item
All of the points  in the point sets generated by our reductions satisfy ; that is, they lie below the main diagonal  of the  square forming the bounding box of the points.
In the matroid rank problems, we may interpret  as being the index of each edge, and  as being the number  which is always less than the index itself; similar observations apply to the other problems.
\item
Each query on a slice  is translated to dominance queries determined by the point . The number of edges in the slice, , is proportional to the geometric distance  of this point from the main diagonal.
\end{itemize}

We may assume without loss of generality that the quadrant in which we wish to count points for a query  is the quadrant  that extends from the query point towards the main diagonal. It is not true that these are the only quadrants produced by our reductions from graph slice problems to dominance counting; however, the number of points in each of the other three quadrants may be easily computed by combining the number of points in this quadrant with halfspace range counting problems. The number of points in an axis-aligned halfspace can be determined trivially in linear space and constant time per query by precomputing the answer to each possible query halfspace.
Thus, it remains to show that, given any set of points below the main diagonal of the square, we can answer dominance counting problems for quadrants that point towards the main diagonal, in an amount of time per query that is a function of the distance from the diagonal.

To solve dominance counting problems on a given set of points, satisfying the assumptions, we partition the points into subsets, where subset  contains the points whose distance from the main diagonal is at most  and which are not in any set  for .
Then, in outline, we use a local coordinate system for each subset  in which the number of distinct coordinates is proportional to the number of points in  (allowing the data structure of JaJa et al. to be used in a space-efficient way) and we cover each subset  by data structures that each serve a range of  coordinates, in such a way that each point is covered by at most two data structures; again, this achieves linear space, while allowing a query within  to be performed quickly. Finally, we use \emph{fractional cascading}~\cite{ChaGui-Algo-86} to link each subset  to the next subset , allowing the transformation into the local coordinate systems to be performed quickly and allowing us to quickly find the subset  in which it is most appropriate to perform the query, reducing all lower-level queries to constant-time halfspace counting queries.

In more detail, we store the following for each subset :
\begin{itemize}
\item Lists of the points in , sorted both by their -coordinates and by their -coordinates.
\item For each point in , its indices in both sorted lists, allowing us to answer in constant time a halfspace counting query with the coordinate of that point.
\item Two lists  and , consisting both of points in  and of some points in  for , sorted by their -coordinates and -coordinates respectively.  consists of  together with the elements at even positions in , and similarly  consists of  together with the elements at even positions in . Each entry in  or  contains pointers to the nearest point in the sorted list for  and to the nearest point in  or . In this way, starting from , we can navigate from  to  in constant time.
\item For each point in , a translation of its coordinates into the local coordinate system of , obtained by compressing out coordinate values that occur neither as the -coordinate nor as the -coordinate of any point in . In this compressed coordinate system, all points remain below the main diagonal, and the number of distinct coordinates is at most equal to the number of points.
\item A sequence of the data structures of JaJa et al., each covering (for some integer ) the subset of points in  whose local coordinates have  and . Thus, there are at most  distinct - and -coordinates within one of these structures, so their query time is

Any query defined by a point  with  may be handled by one of these structures, determined in constant time by dividing the query coordinates by . Each point of  belongs to two of these structures, so the total space for all of these structures is .
\end{itemize}
In addition, we store an array indexed by coordinate, mapping coordinates in the coordinate space of the whole point set to their positions in lists  and .

\begin{theorem}
Given a set of  points below the main diagonal in an  integer grid, we can process them into a data structure of size  that handles dominance queries for which the query point is at distance  from the main diagonal in time  per query.
\end{theorem}

\begin{proof}
All of the data structures described above take space  for each set , so the total space is linear.

To answer a query, we start in . Within each set  for which the query quadrant extends beyond the distance of the set from the main diagonal and therefore could also contain points of , we translate the query into two halfspace queries, answer these queries in constant time, and use the  and  structure to progress to the next set  in constant time. In the final set , we translate the query into the local coordinate system and then use one of the data structures of JaJa et al.{} stored for this set to answer the query directly in time . This  time dominates the query (everything else is ) and thus the time per query is .
\end{proof}

When translated to our relational event graph problems, this gives query time bounds of the form  for querying slice  of a relational event graph with  edges.

We observe that the same improvement may also be applied to the one-dimensional colored range counting problem considered by Gupta et al.~\cite{ColorRangeQueries}: as in our results, Gupta et al.{} transform the given input into a range counting problem on a set of two-dimensional points below the main diagonal. They use three-sided range queries rather than dominance counting, but their queries may be replaced by a linear combination of two axis-aligned halfspace queries and a dominance query. And, as in our problems, the length of the query interval for colored range counting translates into the distance of the dominance query point from the main diagonal.

\section{Simplified dominance counting}
Our data structure for range searching uses fractional cascading layered on top of
multiple copies of the structure of JaJa, Mortensen and Shi~\cite{JaJMorShi-ISAAC-04}, which itself is quite complex and in turn relies on the fusion trees of Fredman and Willard~\cite{FreWil-JCSS-93}, which are also complex. Therefore, although it achieves a good asymptotic space and query time complexity, we do not expect this combination of methods to be easy to implement. In this section we outline an alternative data structure for the same dominance counting problems that we expect to be more practical, although its time and space bounds are larger and we have not tested its practicality. Additionally, compared to the data structure in the previous appendix, the structure we define in this appendix has the theoretical advantage that it can handle queries with weighted points (dominance sum queries) and not just queries with unweighted points (dominance counting queries).

\begin{figure}[t]
\centering\includegraphics[width=4in]{figures/foster-tree-24}
\caption{24-leaf binary tree formed from the zeroless binary representation . Each of the four shaded complete binary subtrees corresponds to one of the four digits of the binary representation, in left-to-right order.}
\label{fig:foster-tree-24}
\end{figure}

In outline, our data structure for this problem uses path-copying persistence~\cite{DSPersistent} applied to a form of balanced binary tree, optimized for queries on small slices.
The specific trees we use are based on the observation that every positive integer has a unique representation as a base-2 number in which each digit is either 1 or 2 (rather than the more traditional binary notation in which each digit is either 0 or 1).\footnote{For an analogous representation of positive integers in base~10 using digits with values from 1 to 10, without a zero digit, see Foster~\cite{Fos-MM-47}.} For instance,

Based on this fact, for every  we can form a tree  with exactly  leaves and  internal vertices: we represent  as  where each  and  is the number of digits in the representation of . We form a tree starting from a path of  nodes, extending leftwards from the root; the right child of the node in this path at distance  from the root is a complete binary tree with  leaves, and the left child of the last node in this path (at distance  from the root) is a complete binary tree with  leaves. Figure~\ref{fig:foster-tree-24} illustrates this construction for .

In , the path from the root to the th leaf (in the left-to-right ordering of the leaves) has length : it takes at most  steps to reach the complete binary subtree containing the th leaf, and another  steps to reach the leaf from the root of this subtree. In addition, the structural change needed to form  from  is small: the binary representation of  may be obtained from the representation of  by changing trailing 2's to 1's and incrementing the lowest order digit that is not a 2, and each of these operations corresponds to  changes to the structure of the tree. So, in the worst case,  and  differ in the connections of  of their nodes, and the average change per step in constructing  from  by a sequence of these increment steps is . In particular,  can be constructed in time .

We now describe how to use these trees to solve dominance range sum queries. We assume we are given as input a set of  points , each with a weight~. As in the previous section, we assume that , so all points are on or below the main diagonal of the  integer grid. We wish to handle queries that are given as arguments a pair of coordinates  and that return the query value

That is, we sum the weights of the points in the quadrant of the plane directed towards the main diagonal from the query point.

To do so, for each value of  in the range from  to  we store a tree  with the structure described above, with exactly  leaves. We represent each interior node of this tree as an object~, with four instance variables: a weight , a count , and left and right child pointers  and . We do not explicitly represent the leaf nodes of the tree, but they are useful for defining its structure. The count variable for each node stores the number of leaves in the right subtree beneath that node; it is zero for nodes that are themselves leaves. Although leaves are not represented explicitly within our structure, we nevertheless define the weight of the leaf in position  (in the left to right order of the leaves, starting from position~0 for the leftmost leaf) to be

That is, it is the sum of weights of points within row  of the  grid, up to column .
The weight of a node that is not a leaf is the sum of the weights of the leaves in its right subtree.

\begin{figure}[t]
\centering\includegraphics[width=4.5in]{figures/shared-trees}
\caption{The trees  for  derived from a  grid, and the pairs  stored with each internal node of each tree. The leaf nodes are shown in the figure but not explicitly represented.}
\label{fig:shared-trees}
\end{figure}

To save space, we make the trees  for different values of  share as much of their structure as they can. In particular, if trees  and  both contain nodes whose descendants form isomorphic subtrees, with leaves in the same positions in the left-to-right order and with the same leaf weights, then our data structure reuses the same node object for both of them. However, the parts of  and  that differ either structurally or in the weights stored in those nodes are represented in the data structure by separate nodes. Finally, for each  we store a pointer to the root of  and we store a number , the total weight of all the leaves in . Figure~\ref{fig:shared-trees} illustrates this structure of shared trees, weights, and counts for a set of points within a  grid.

To answer a query , we perform a binary search for  in tree , using the count values stored in each tree node to guide whether to step leftwards or rightwards at each point of the search. The query value is then the sum of the weight values of the nodes at which this search stepped leftwards. As a special case, the query  (which asks for the sum of weights of all points with ) is handled by returning . Thus, each query can be answered in time .

To construct  from , we perform the structural rearrangements needed to form  (creating new node objects for the root of each subtree in  that does not also appear as a subtree in . Then, for each point  with , we add  to the weight value of leaf  in , and update the cumulative weights stored at each ancestor of this leaf, creating new copies of each ancestor node in order to be able to store these updated weight values in  without disturbing the values already computed for . The total number of new nodes that need to be created in this step for each point  is .
Thus, the total number of new nodes needed to create the entire structure, which gives the space requirement for the structure as well as its construction time, is .

We have proved the following result:

\begin{theorem}
Suppose we are given  weighted points below the main diagonal in an  grid. Then in time  we may preprocess these points into a data structure of size  that supports dominance sum queries, given by a query point , in time  per query.
\end{theorem}

\section{Lower bounds}
\label{sec:lb}

Strengthening earlier results of Chazelle~\cite{Cha-JACM-90},
P{\v a}tra{\c s}cu provided lower bounds for two-dimensional range counting~\cite{Pat-STOC-07} that we adapt to our windowed relational event problems. Specifically, he showed that, for  given points in the Euclidean plane, it is hard to answer \emph{dominance queries}, asking for the number of given points  with  and  for some query pair . In the cell probe model of Fredman and Saks~\cite{FreSak-STOC-89}, with  bits per machine word, every data structure that can answering such queries using space  requires  time per query.

We adapt this lower bound to our windowed relational event problems, by showing how to translate a given set of  Euclidean points into a synthetic relational event data set in such a way that windowed queries into this data set simulate range counting queries. To do so, we construct a (static) 1-regular graph with  vertices and  isolated edges . We may assume without loss of generality (by perturbing the Euclidean points if necessary) that no two points have the same - or -coordinate as each other; since only the ordering of the points by their coordinates matters for handling dominance queries, we may also assume (as P{\v a}tra{\c s}cu does) that their coordinates are all integers in the range from  to . That is, we are assuming that there exists a permutation  of the integers from  to  such that the points in the given set of points all have coordinates of the form .

Given a point set in this form, we define a relational event data set with  events, where for each  in the range from  to , we include two copies of edge  in the data set, one at time  and a second copy at time . In this way, the number of given points dominated by the query pair  will exactly equal the number of repeated edges in the slice .

\begin{theorem}
\label{thm:lb}
For each of the problems of counting components, counting loopy components, counting isolated vertices, counting isolated edges, and counting repeated edges, any data structure for a relational event graph with  edges and space  requires  time per query.
\end{theorem}

\begin{proof}
For the data set produced by our translation, the answer to any one of these queries can be combined with the (trivially calculated) number of edges in a slice to give the number of repeated edges within a slice. Using the translation described above, this could then be used to answer two-dimensional range counting queries in the same asymptotic query bound. Since range counting queries cannot be answered more quickly than the query time stated in the theorem, neither can these graph queries.
\end{proof}

\begin{figure}[t]
\centering
\includegraphics[scale=0.55]{figures/influence-lower-bound}
\caption{Lower bound example for influenced vertices. The red vertex is influential; each remaining vertex is influenced only when the path leading to it is included in the slice.}
\label{fig:influence-lower-bound}
\end{figure}

A similar construction using a different relational event data set in the form of a tree of height two, using two-edge paths in place of the pairs of equal edges, shows that the same lower bound also holds for counting influenced vertices. Figure~\ref{fig:influence-lower-bound} shows the construction: for each pair of edges , the endpoint of  will be influenced whenever  lies in the query interval, but the endpoint of  will be influenced only if both  and  both lie in the query interval. Thus, as above, we can translate a two-dimensional range counting instance (represented as a permutation  of the numbers from  to  by including a edge  at time  in a relational event data set and by including edge  at time . We set the root of the tree as the sole influential vertex.

\begin{theorem}
\label{thm:lb2}
Any data structure for counting influenced vertices in a relational event graph with  edges and space  requires  time per query.
\end{theorem}

\begin{proof}
We use the translation described above. The answer to a dominance counting query for the query point  is given by , where  is the number of influenced vertices in the slice .
\end{proof}

\end{document}
