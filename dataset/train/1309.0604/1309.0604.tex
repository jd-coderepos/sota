\subsection{General cost measures}

Observe that the random linear coding strategy depends on the client to find a sufficient number of linearly independent combinations in caches that are not too far away. If  is small there is a significant probability that the information of the next cache is not linearly independent. Hence, one might argue that for small values of  there exists performance measures for which the partitioning strategy outperforms random linear coding. Our first result demonstrates that this is not true, \ie that random linear coding outperforms the partitioning strategy for any value of  and any cost function.
\begin{theorem}  \label{th:codingbetter}
Consider an arbitrary placement of caches, a bounded increasing function  and any . Then

\ie coding always outperforms partitioning.
\end{theorem}
The proof of the above theorem is given in Appendix~\ref{app:codingbetter}.
Note, that the above result in particular implies that coding is better than uncoded strategy
for any realization in case of placement according to a spatial Poisson process.



Since less than  caches can never provide the complete data, it is clear that the minimum cost that one can hope to achieve is given by the cost of contacting the nearest  caches. For notation convenience, denote the minimum expected cost as



Our next result provides a bound on the deviation of the cost of the coded strategy from .
\begin{theorem} \label{th:upper}
The expected cost of the coded strategy is upper bounded as

where .
\end{theorem}
\begin{IEEEproof} Let  denote the event that the first  caches provide a full rank system. Then

and the result follows from the assumption that  is bounded by  and , \cf~\cite{ho2006random} or~\cite{ncfundamentals}.
\end{IEEEproof}
We will illustrate the above result for a specific performance measure below. In particular, we will show that the coded strategy is close to optimal.

\subsection{Waiting time}

Next, we consider specific instances of the cost. First we consider  as defined in Section~\ref{ssec:w}. Before giving the results we will provide some definitions and results on the Gamma function. Let  denote the upper incomplete Gamma function, \ie

Furthermore, we define  and . The use of  for Poisson processes stems from the fact that for a Poisson random variable  with mean  we have

Therefore, the probability that , the distance to the -th nearest neigbor in an HPP of density  is at most  is



We are now ready to present our first result on . The proof of the next theorem is given in Appendix~\ref{app:wmain}.
\begin{theorem} \label{th:wmain}
Let the caches be distributed in the plane as HPP with density .
Then, the expected costs of the partitioning and coded strategies are

where  and .
\end{theorem}

To get an idea about the nature of the above involved equations, a reader may check Figure~\ref{fig:WHPPSimTheo}
where a numerical example is presented.





From the observation that

for any ,
we immediately obtain the following corollary which provides limiting expressions for  and  for .
\begin{corollary} \label{cor:w}
Let  and . We have

\end{corollary}

Next we turn our attention to the cost benefit of coding over partitioning, defined as the ratio .
Clearly, it is an optimistic prediction. However, in the numerical examples section we shall demonstrate that the actual gain is
typically close to this optimistic prediction. It follows readily from Corollary~\ref{cor:w} that

where  denotes the Beta function.


\begin{theorem} \label{th:benefit}
The benefit of coding over partitioning, , is increasing in . Moreover

Hence

with equality on the LHS iff .
\end{theorem}
\begin{IEEEproof}
We start with proving that , is increasing in .
Let . We have

where  is the digamma function~\cite{abramowitz1974handbook}. We need to show that

but this follows directly from the observation that .

The limiting expression follows from an application of Stirlings approximation.
\end{IEEEproof}
Note, that for , the upper bound in Theorem~\ref{th:benefit} reduces to ,  and  respectively.


\subsection{Cache miss probability}
Next let us consider the cache miss probability.
\begin{theorem}\label{thm:outage}
The cache miss probability of the partitioning and coded strategy are

\end{theorem}
\begin{IEEEproof}
For the coded strategy we have

since the -th nearest cache needs to be within distance .


For the uncoded strategy we have

which follows from the fact that each of the parts is found in the first neighbour in a (thinned) Poisson process of intensity .
\end{IEEEproof}

We note that the following asymptotics for equations in the statement of Theorem~\ref{thm:outage} take place


for large values of . This indicates that when increasing , the cache miss probability increases much faster for the uncoded
strategy than for the coded strategy. We shall illustrate this phenomenon with a specific numerical example in the next section.
