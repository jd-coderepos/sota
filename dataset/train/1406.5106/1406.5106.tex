
\section{Introduction}

The development of a context-free\footnote{As in context-free language, not a context-insensitive analysis.
} approach to control-flow analysis
(CFA2) by \citet{mattmight:Vardoulakis:2010:CFA2} provoked a shift in the
static analysis of higher-order
programs.
Prior to CFA2, a precise analysis of recursive behavior 
had been a challenge---even though flow analyses have an important role to play in 
optimization for functional languages, such as 
flow-driven inlining~\cite{mattmight:Might:2006:DeltaCFA},
interprocedural constant propagation~\cite{mattmight:Shivers:1991:CFA}
and type-check elimination~\cite{mattmight:Wright:1998:Polymorphic}.


While it had been possible to statically analyze
recursion \emph{soundly}, CFA2 made it possible to analyze recursion
\emph{precisely} by matching calls and returns without approximating the stack as -CFA does.
The approximation is only in the binding structure, and not the control structure of the program.
In its pursuit of recursion,
clever engineering steered CFA2 to a \emph{theoretically} intractable complexity, though in practice it performs well.
Its payoff is significant reductions in 
analysis time \emph{as a result of} corresponding increases
in precision.


For a visual measure of the impact, Figure~\ref{fig:diamond}
renders the abstract transition graph (a model of all possible traces through the program) for 
the toy program in Figure~\ref{fig:toy}.
\begin{figure}
\figrule
\begin{code}
(define (id x) x)

(define (f n)
  (cond [(<= n 1)  1]
        [else      (* n (f (- n 1)))]))

(define (g n)
  (cond [(<= n 1)  1]
        [else      (+ (* n n) (g (- n 1)))]))
    
(print (+ ((id f) 3) ((id g) 4)))
\end{code}
\caption{A small example to illuminate the strengths and weaknesses of
  both pushdown analysis and abstract garbage collection.}
\label{fig:toy}
\figrule
\end{figure}
For this example,
pushdown analysis
eliminates spurious return-flow from the
use of  recursion.
But, recursion is just one problem of many for flow analysis.
For instance, pushdown analysis still gets tripped up by
the
spurious cross-flow problem;
at calls to \texttt{(id f)}
and \texttt{(id g)} in the previous example,
it thinks \texttt{(id g)} could be \texttt{f} \emph{or} \texttt{g}.
CFA2 is not confused in this due to its precise stack frames, but can be confused by unreachable heap-allocated bindings.

Powerful techniques such as abstract garbage collection~\cite{mattmight:Might:2006:GammaCFA}
were developed to address the cross-flow problem (here in a way complementary to CFA2's stack frames).
The cross-flow problem arises because monotonicity prevents revoking a
judgment like ``procedure  flows to {\tt x},'' or ``procedure
 flows to {\tt x},'' once it's been made.

\begin{figure}
\begin{center}
\includegraphics[width=3in]{graph-0-cfa}
\\
(1) without pushdown analysis or abstract GC: 653 states
\\
\includegraphics[width=3in]{graph-0-pdcfa}
\\
(2) with pushdown only: 139 states
\\
\includegraphics[width=3.3in]{graph-0-cfa-gc}
\\
(3) with GC only: 105 states
\\
\includegraphics[width=2.5in]{graph-0-pdcfa-gc}
\\
(4) with pushdown analysis and abstract GC: 77 states
\end{center}

\caption{
We generated an abstract transition graph
for the same program from Figure~\ref{fig:toy} four times: 
 (1) without pushdown analysis or abstract garbage collection;
 (2) with only abstract garbage collection;
 (3) with only pushdown analysis;
 (4) with both pushdown analysis and abstract garbage collection.
With only pushdown or abstract GC, the abstract transition graph shrinks
by an order of magnitude, but in different ways.
The pushdown-only analysis is confused by variables 
that are bound to several different higher-order functions,
but for short durations.
The abstract-GC-only is confused by non-tail-recursive loop structure.
With both techniques enabled, the graph shrinks by nearly half yet again
and fully recovers the control structure of the original program.}
\label{fig:diamond}
\end{figure}


In fact, abstract garbage collection, by itself, also delivers significant
improvements to analytic speed and precision in many benchmarks.
(See Figure~\ref{fig:diamond} again for a visualization of that
impact.)


It is natural to ask: can abstract garbage collection and pushdown 
analysis work together?
Can their strengths be multiplied?
At first, the answer appears to be a disheartening~``\emph{No}.''




\subsection{The problem: The whole stack \emph{versus} just the top}


Abstract garbage collection seems to require more than pushdown analysis can
decidably provide: access to the full stack.
Abstract garbage collection, like its name implies, discards unreachable values
from an abstract store during the analysis.
Like concrete garbage collection, abstract garbage collection also begins its
sweep with a root set, and like concrete garbage collection, it must traverse
the abstract stack to compute that root set.
But, pushdown systems are restricted to viewing the top of the stack (or
a bounded depth)---a condition violated by this traversal.

Fortunately, abstract garbage collection does not need to arbitrarily modify
the stack.
It only needs to know the root set of addresses in the stack.
This kind of system has been studied before in the context of compilers that build a symbol table (a so-called ``one-way stack automaton''~\citep{ianjohnson:one-way-sa:ginsburg:1967}),in the context of first-order model-checking (pushdown systems with checkpoints~\citep{EsparzaKS03}),and also in the context of points-to analysis for Java (conditional weighted pushdown systems (CWPDS) ~\citep{ianjohnson:DBLP:conf/pepm/LiO10}).
We borrow the definition of (unweighted) conditional pushdown system (CPDS) in this work, though our analysis does not take CPDSs as inputs.


Higher-order flow analyses typically do not take a control-flow graph, or similar pre-abstracted object, as input and produce an annotated graph as output.
Instead, they take a program as input and ``run it on all possible inputs'' (abstractly) to build an approximation of the language's reduction relation (semantics), specialized to the given program.
This semantics may be non-standard in such a way that extra-semantic information might be accumulated for later analyses' consumption.
The important distinction between higher-order and first-order analyses is that the \emph{model} to analyze is built \emph{during} the analysis, which involves interpreting the program (abstractly).


When a language's semantics treats the control stack as an actual stack, \ie, it does not have features such as first-class continuations, an interpreter can be split into two parts:
 a function that takes the current state and returns all next states along with a pushed activation frame or a marker that the stack is unchanged;
 and a function that takes the current state, a possible ``top frame'' of the stack, and returns the next states after popping this frame.
This separation is crucial for an effective algorithm, since pushed frames are understood from program text, and popped frames need only be enumerated from a (usually small) set that we compute along the way.


Control-state reachability for the straightforward formulation of stack introspection ends up being uncomputable.
Conditional pushdown systems introduce a relatively weak regularity constraint on transitions' introspection:
a CPDS may match the current stack against a choice of finitely many regular languages of stacks in order to transition from one state to the next along with the stack action.
The general solutions to feasible paths in \emph{conditional} pushdown systems enumerate all languages of stacks that a transition may be conditioned on.
This strategy is a non-starter for garbage collection, since we delineate stacks by the addresses they keep live; this is exponential in the number of addresses.
The abstraction step that finitizes the address space is what makes the problem fall within the realm of CPDSs, even if the target is so big it barely fits.
But abstract garbage collection is special --- we can compute which languages of stacks we need to check against, given the current state of the analysis.
It is therefore possible to fuse the full benefits of abstract garbage collection with pushdown analysis.
The dramatic reduction in abstract transition graph size
from the top to the bottom in Figure~\ref{fig:diamond}
(and echoed by later benchmarks) conveys the impact
of this fusion.



\paragraph{Secondary motivations}
There are four secondary motivations for this work:
\begin{enumerate}
\item bringing context-sensitivity to pushdown analysis;
\item exposing the context-freedom of the analysis;
\item enabling pushdown analysis without continuation-passing style; and
\item defining an
  alternative algorithm for computing pushdown analysis,
  introspectively or otherwise.
\end{enumerate}
In CFA2, monovariant (0CFA-like) context-sensitivity is etched directly into
the abstract ``local'' semantics, which is in turn
phrased in terms of an explicit (imperative) summarization algorithm
for a partitioned continuation-passing style.
Our development exposes the classical parameters (exposed as
allocation functions in a semantics) that allow one to tune the
context-sensitivity and polyvariance (accomplishing (1)), thanks to
the semantics of the analysys formulated in the form of an
``abstracted abstract machine''~\cite{mattmight:VanHorn:2012:AAM}.


In addition, the context-freedom of CFA2 is buried implicitly
inside an imperative summarization algorithm.
No pushdown system or context-free grammar is explicitly identified.
Thus, a motivating factor for our work was to make 
the pushdown system in CFA2 explicit, and to make the control-state
reachability algorithm purely functional (accomplishing (2)).


A third motivation was to show that a transformation to continuation-passing
style is unnecessary for pushdown analysis.
In fact, pushdown analysis is arguably more natural over direct-style programs.
By abstracting all machine components except for the program stack, 
it converts naturally and readily into a pushdown system (accomplishing (3)).
In his dissertation, Vardoulakis showed a direct-style version of CFA2 that exploits the meta-language's runtime stack to get precise call-return matching.
The approach is promising, but its correctness remains unproven, and it does not apply to generic pushdown systems.


Finally, to bring much-needed clarity to algorithmic formulation of
pushdown analysis, we have included an appendix containing a reference
implementation in Haskell (accomplishing (4)).
We have kept the code as close in form to the mathematics as possible, so that
where concessions are made to the implementation, they are obvious.



\subsection{Overview}
We first review preliminaries to set a consistent feel for
terminology and notation, particularly with respect
to pushdown systems.
The derivation of the analysis 
begins with a concrete CESK-machine-style semantics for
A-Normal Form \lc{}.
The next step is an infinite-state abstract interpretation, 
constructed by
bounding the C(ontrol), E(nvironment) and S(tore) portions of the machine.
Uncharacteristically,
we leave the stack component---the K(ontinuation)---unbounded.

A shift in perspective reveals that this abstract interpretation is a pushdown
system.
We encode it as a pushdown automaton explicitly, and pose control state
reachability as a decidable language intersection problem.
We then extract a rooted pushdown system from the pushdown automaton.
For completeness, we fully develop pushdown analysis for higher-order programs,
including an efficient algorithm for computing reachable control states.
We go further by characterizing complexity and demonstrating the approximations
necessary to get to a polynomial-time algorithm.



We then introduce abstract garbage collection and quickly find
that it violates the pushdown model
with its traversals of the stack.
To prove the decidability of control-state reachability,
we formulate introspective pushdown systems, and 
recast abstract garbage collection within this framework.
We then review that control-state reachability is decidable for
introspective pushdown systems as well when
subjected to a straightforward regularity constraint.

We conclude with an implementation and empirical evaluation that shows strong
synergies between pushdown analysis and abstract garbage collection, including
significant reductions in the size of the abstract state transition graph.

\subsection{Contributions}
We make the following contributions:
\begin{enumerate}
\item Our primary contribution is an \emph{online} decision procedure
  for reachability in introspective pushdown systems, with a more
  efficient specialization to abstract garbage collection.


\item We show that classical notions of context-sensitivity, such as
  -CFA and poly/CFA, have direct generalizations in a pushdown
  setting.  CFA2 was presented as a monovariant
  analysis,\footnote{Monovariance refers to an abstraction that groups
    all bindings to the same variable together: there is \emph{one}
    abstract variant for all bindings to each variable.} whereas we
  show polyvariance is a natural extension.

\item We make the context-free aspect of CFA2 explicit: we clearly define and
identify the pushdown system.
We do so by starting with a classical CESK machine and systematically
abstracting until a pushdown system emerges.
We also remove the orthogonal frame-local-bindings aspect of CFA2, so as to
focus solely on the pushdown nature of the analysis.


\item (*) We remove the requirement for a global CPS-conversion
by synthesizing the analysis directly for direct-style (in
    the form of A-normal form lambda-calculus --- a local transformation).


\item We empirically validate claims of improved
precision on a suite of benchmarks.
We find synergies between 
pushdown analysis 
and
abstract garbage collection 
that makes the whole greater that the sum of its parts.

\item
We provide a mirror of the major formal development as working 
Haskell code in the appendix.  
This code illuminates dark corners
of pushdown analysis and it 
provides a concise formal reference implementation.


\end{enumerate}

(*) The CPS requirement distracts from the connection between continuations and stacks.
We do not discuss \texttt{call/cc} in detail, since we believe there are no significant barriers to adapting the techniques of \citet{dvanhorn:Vardoulakis2011Pushdown} to the direct-style setting, given related work in \citet{local:hopa-summaries}.
Languages with exceptions fit within the pushdown model since a throw can be modeled as ``pop until first catch.''


\section{Pushdown Preliminaries}

The literature contains  many equivalent definitions of pushdown machines, so
we adapt our own definitions from \citet{mattmight:Sipser:2005:Theory}.
\emph{Readers familiar with pushdown theory may wish to skip ahead.}



\subsection{Syntactic sugar}

When a triple  is an edge in a labeled graph:

Similarly, when a pair  is a graph edge:

We use both
string and vector notation for sequences:



\subsection{Stack actions, stack change and stack manipulation}


Stacks are sequences over a stack alphabet .
To reason about stack manipulation concisely,
we first turn stack alphabets into ``stack-action'' sets;
each character represents a change to the stack: push, pop or no
change.

For each character  in a stack alphabet , the
\defterm{stack-action} set  contains a push character
; a pop character ;
and a no-stack-change indicator, :

In this paper, the symbol  represents some stack action.


When we develop introspective pushdown systems, we are going
to need formalisms for easily manipulating stack-action strings
and stacks.
Given a string of stack actions, we can compact it into a minimal
string describing net stack change.
We do so through the operator , which cancels out opposing adjacent push-pop stack
actions:

so that

if there are no cancellations to be made in the string .


We can convert a net string back into a stack by stripping off the
push symbols with the stackify operator, :

and for convenience, .
Notice the stackify operator is defined for strings containing
only push actions. 




  \subsection{Pushdown systems}
  A \defterm{pushdown system} is a triple
   where:
  \begin{enumerate}

  \item  is a finite set of control states;

  \item  is a stack alphabet; and

  \item  is a transition relation.
  \end{enumerate}
The set  is 
  called the \defterm{configuration-space} of this pushdown system.
We use  to denote the class of all pushdown systems.
  \\

  \noindent
  For the following definitions, let .
  \begin{itemize}



  \item The labeled \defterm{transition relation} 
  determines whether one configuration may transition to another while performing the given stack action:
        


\item If unlabelled, the transition relation  checks whether \emph{any} stack action can enable the transition:


\item

For a string of stack actions :

for some configurations .

\item

For the transitive closure:


\end{itemize}



\paragraph{Note}
Some texts define the transition relation  so that 
.
In these texts,  means, ``if in control state  while the
character  is on top, pop the stack, transition to
control state  and push .''
Clearly, we can convert between these two representations by
introducing extra control states to our representation when it needs
to push multiple characters.



\subsection{Rooted pushdown systems}

A \defterm{rooted pushdown system} is a quadruple 
 in which 
 is a pushdown system and
 is an initial (root) state.
  is the class of all rooted pushdown
systems.
For a rooted pushdown system , we define 
the \defterm{reachable-from-root transition relation}:

In other words, the root-reachable transition relation also makes
sure that the root control state can actually reach the transition.


We overload the root-reachable transition relation to operate on
control states:

For both root-reachable relations, if we elide the stack-action label,
then, as in the un-rooted case, the transition holds if \emph{there
  exists} some stack action that enables the transition:
  


\subsection{Computing reachability in pushdown systems}

A pushdown flow analysis 
can be construed as
  computing the \emph{root-reachable}
  subset of control states in a rooted pushdown system, 
  :

Reps~\emph{et. al} and many others provide a straightforward ``summarization'' algorithm
to compute this set~\cite{mattmight:Bouajjani:1997:PDA-Reachability,dvanhorn:Kodumal2004Set,mattmight:Reps:1998:CFL,mattmight:Reps:2005:Weighted-PDA}.
We will develop a complete alternative to summarization, and then instrument this development for introspective pushdown systems.
Summarization builds two large tables: 
\begin{itemize}
\item{One maps ``calling contexts'' to ``return sites'' (AKA ``local
  continuations'') so that a returning function steps to all the
  places it must return to.}
\item{The other maps ``calling contexts'' to
  ``return states,'' so that any place performing a call with an
  already analyzed calling context can jump straight to the returns.}
\end{itemize}
This setup requires intimate knowledge of the language in question for where continuations should be segmented to be ``local'' and is strongly tied to function call and return.
Our algorithm is based on graph traversals of the transition relation for a generic pushdown system.
It requires no specialized knowledge of the analyzed language, and it avoids the memory footprint of summary tables.


\subsection{Pushdown automata}
A \defterm{pushdown automaton} is an input-accepting generalization
of a rooted pushdown system, a 7-tuple
 in which:
\begin{enumerate}
\item  is an input alphabet; 

\item  is a
  transition relation; 

\item  is a set of accepting states; and

\item  is the initial stack.

\end{enumerate}
We use  to denote the class of all pushdown automata.

Pushdown automata recognize languages over their input alphabet.
To do so, their transition relation may optionally consume an input
character upon transition.
Formally, a PDA 
recognizes the language :

where  is either the empty string  or a single character.



\subsection{Nondeterministic finite automata}
In this work, we will need a finite description of 
all possible stacks at a given control state within
a rooted pushdown system.
We will exploit the fact that the set of stacks
at a given control point is a regular language.
Specifically, we will extract a nondeterministic finite automaton
accepting that language from the structure
of a rooted pushdown system.
A \defterm{nondeterministic finite automaton} (NFA) is a quintuple
:
\begin{itemize}
\item  is a finite set of control states;

\item  is an input alphabet; 

\item  
is a transition relation.

\item  is a distinguished start state.

\item  is a set of accepting states.
\end{itemize}
We denote the class of all NFAs as .


\section{Setting: A-Normal Form 
-Calculus}
\label{sec:anf}

Since our goal is analysis of
\emph{higher-order languages}, we operate on the
\lc{}.
To simplify presentation of the concrete and abstract semantics, we choose 
A-Normal Form \lc{}.
(This is a strictly cosmetic
 choice: all of our results can be replayed \emph{mutatis mutandis} in
 the standard direct-style setting as well.
 This differs from CFA2's requirement of CPS, since ANF can be applied locally whereas CPS requires a global transformation.)
ANF enforces an order of evaluation and it requires
that all arguments to a function be atomic:





We use the CESK machine of \citet{mattmight:Felleisen:1987:CESK} to specify a small-step semantics
for ANF.
The CESK machine has an explicit stack, and under a structural abstraction, the stack
component of this machine directly becomes the stack component of a
pushdown system.
The set of configurations () for 
this machine has the four expected components (Figure~\ref{fig:cesk}).
\begin{figure}
\figrule

\captionsetup{justification=centering}
\caption{The concrete configuration-space.}
\label{fig:cesk}
\figrule
\end{figure}

\subsection{Semantics}

To define the semantics, we need five items:
\begin{enumerate}
\item  injects an expression into
a configuration:




\item{ evaluates atomic expressions:
}

\item{ transitions between
configurations. (Defined below.)}

\item{ computes the set of
 reachable machine configurations for a given program:
 }

\item{ 
chooses fresh store addresses for newly bound variables.
The address-allocation function is an opaque parameter in this semantics,
so that the forthcoming abstract semantics may also parameterize allocation. 
The nondeterministic nature of the semantics makes any choice of  sound \citep{mattmight:Might:2009:APosteriori}.
This parameterization provides the knob to tune the polyvariance and context-sensitivity of the resulting analysis.
For the sake of defining the concrete semantics, letting addresses be natural numbers suffices.
The allocator can then choose the lowest unused address:
}
\end{enumerate}









\paragraph{Transition relation}
To define the transition , we need three rules.
The first rule handles tail calls by evaluating the function into a closure, evaluating the argument into a value and then moving to the body of the closure's \lamterm{}:
\begin{center}
  \minipagebreak{0.50}[-1cm]{
  \overbrace{(\sembr{\appform{\fexpr}{\aexpr}}, \env, \store, \cont)}^{\conf}
  &\To
  \overbrace{(\expr,\env'',\store',\cont)}^{\conf'}
  \text{, where }
  \\
  (\sembr{\lamform{\vv}{\expr}}, \env') &= \ArgEval(\fexpr,\env,\store)}
  {0.45}[1mm]{\addr &= \alloc(\vv,\conf)
  \\
  \env'' &= \env'[\vv \mapsto \addr]
  \\
  \store' &= \store[\addr \mapsto \ArgEval(\aexpr,\env,\store)]
  \text.}
\end{center}

\noindent
Non-tail calls push a frame onto the stack and evaluate the call:


\noindent
Function return pops a stack frame:
\begin{center}
  \minipagebreak{0.50}[-1.1cm]{\overbrace{(\aexpr, \env, \store, (\vv,\expr,\env') :
      \cont)}^{\conf} &\To \overbrace{(\expr,\env'',\store',
      \cont)}^{\conf'} \text{, where }}
  {0.45}[5mm]{\addr &= \alloc(\vv,\conf)
    \\
    \env'' &= \env'[\vv \mapsto \addr]
    \\
    \store' &= \store[\addr \mapsto \ArgEval(\aexpr,\env,\store)]
    \text.}
\end{center}
\section{An Infinite-State Abstract Interpretation}
\label{sec:abstraction}
Our first step toward a static analysis 
is an abstract interpretation
into an \emph{infinite} state-space.
To achieve a pushdown analysis,
we simply
abstract away less than we normally would.
Specifically, 
we leave the stack height unbounded.

Figure~\ref{fig:abs-conf-space}
details the 
abstract configuration-space.
To synthesize it, we force addresses to be a finite set, but
crucially, we leave the stack untouched.
When we compact the set of addresses into a finite set, the machine
may run out of addresses to allocate, and when it does, the
pigeon-hole principle will force multiple closures to reside at the
same address.
As a result, to remain sound we change the range of the store to
become a power set in the abstract configuration-space.
The abstract transition relation has  components
analogous to those from the concrete semantics:


\begin{figure}
\figrule

\captionsetup{justification=centering}
\caption{The abstract configuration-space.}
\label{fig:abs-conf-space}
\figrule
\end{figure}


              \paragraph{Program injection}
              The abstract injection function 
              pairs an expression with an empty environment, an empty store and an
              empty stack to create the initial abstract configuration:
              


\paragraph{Atomic expression evaluation}
The abstract atomic expression evaluator, , returns the value of
an atomic expression in the context of an environment and a store;
it returns a \emph{set} of abstract closures:



\paragraph{Reachable configurations}
The abstract program evaluator  returns all of the configurations reachable from
the initial configuration:

Because there are an infinite number of abstract configurations, a
na\"ive implementation of this function may not terminate.
Pushdown analysis provides a way of precisely computing this set and both finitely and compactly representing the result.


\paragraph{Transition relation}
The abstract transition relation  has three rules, one of which has become nondeterministic.
A tail call may fork because there could be multiple abstract closures
that it is invoking:
\begin{center}
\minipagebreak{0.50}{\overbrace{(\sembr{\appform{\fexpr}{\aexpr}}, \aenv, \astore,
      \acont)}^{\aconf} &\aTo
    \overbrace{(\expr,\aenv'',\astore',\acont)}^{\aconf'} \text{,
      where } \\
    (\sembr{\lamform{\vv}{\expr}}, \aenv') &\in
    \aArgEval(\fexpr,\aenv,\astore)}
  {0.45}[1cm]{\aaddr &= \aalloc(\vv,\aconf)
    \\
    \aenv'' &= \aenv'[\vv \mapsto \aaddr]
    \\
    \astore' &= \astore \join [\aaddr \mapsto
    \aArgEval(\aexpr,\aenv,\astore)] \text.}
\end{center}
We define all of the partial orders shortly, but for stores:


\noindent
A non-tail call pushes a frame onto the stack and evaluates the call:




\noindent
A function return pops a stack frame:
\begin{center}
  \minipagebreak{0.50}[-1.1cm]{\overbrace{(\aexpr, \aenv, \astore, (\vv,\expr,\aenv') :
      \acont)}^{\aconf} &\aTo \overbrace{(\expr,\aenv'',\astore',
      \acont)}^{\aconf'} \text{, where }}
  {0.45}[5mm]{\aaddr &= \aalloc(\vv,\aconf)
    \\
    \aenv'' &= \aenv'[\vv \mapsto \aaddr]
    \\
    \astore' &= \astore \join [\aaddr \mapsto
    \aArgEval(\aexpr,\aenv,\astore)] \text.}
\end{center}
\paragraph{Allocation: Polyvariance and context-sensitivity}
\label{sec:polyvariance}
In the abstract semantics, the abstract allocation function
 determines the
polyvariance of the analysis.
In a control-flow analysis, \emph{polyvariance} literally refers to
the number of abstract addresses (variants) there are for each
variable.
An advantage of this framework over CFA2 is
that varying this abstract allocation function
instantiates pushdown versions of classical flow analyses.
All of the following allocation approaches can be used with the
abstract semantics. Note, though only a technical detail, that the concrete address space and allocation would change as well for the abstraction function to still work.
The abstract allocation function is a
parameter to the analysis.

\paragraph{Monovariance: Pushdown 0CFA}

Pushdown 0CFA uses variables themselves for abstract addresses:



For better precision, a program would be transformed to have unique binders.

  \paragraph{Context-sensitive: Pushdown 1CFA}

  Pushdown 1CFA pairs the variable with the current expression to get
  an abstract address:

  

  For better precision, expressions are often uniquely labeled so that textually equal expressions at different points in the program are distinguished.

    \paragraph{Polymorphic splitting: Pushdown poly/CFA}

    Assuming we compiled the program from a programming language with
    let expressions and we marked which identifiers were let-bound, we
    can enable polymorphic splitting:

    


        \paragraph{Pushdown -CFA}

        For pushdown -CFA, we need to look beyond the current state
        and at the last  states, necessarily changing the signature of  to .
By concatenating the expressions in the last  states together, and
        pairing this sequence with a variable we get pushdown -CFA:







  \subsection{Partial orders}

  For each set  inside the abstract configuration-space, we use the
  natural partial order, .
Abstract addresses and syntactic sets have flat partial orders.
For the other sets, the
  partial order lifts:
  \begin{itemize}
\item point-wise over environments:
  



\item component-wise over closures:
  

\item point-wise over stores:
  

\item component-wise over frames:
  

\item element-wise over continuations:
  

\item component-wise across configurations:
  
  \end{itemize}



  \subsection{Soundness}

  To prove soundness,  an abstraction map  connects the
  concrete and abstract configuration-spaces:
  
It is then easy to prove that the abstract transition relation
            simulates the concrete transition relation:
            \begin{theorem}
If , then
there exists  such that .
  \end{theorem}
  \begin{proof}
  The proof follows by case analysis on the
  expression in the configuration.
It is a straightforward adaptation of similar proofs, such as that of
  \citet{mattmight:Might:2007:Dissertation} for -CFA.
  \end{proof}




\section{From the Abstracted CESK Machine
  to a PDA}
\label{sec:pda}
In the previous section, we constructed an infinite-state abstract
interpretation of the CESK machine.
The infinite-state nature of the abstraction makes it difficult to see how
to answer static analysis questions.
Consider, for instance, a control flow-question:
\begin{center}
\emph{  At the call site , may a closure over
   be called?}
\end{center}
If the abstracted CESK machine were a finite-state machine, an
algorithm could answer this question by enumerating all reachable
configurations and looking for an abstract configuration
 in which
.
However, because the abstracted CESK machine may contain an infinite
number of reachable configurations, an algorithm cannot enumerate
them.


Fortunately, we can recast the abstracted CESK as a special kind of
infinite-state system: a pushdown automaton (PDA).
Pushdown automata occupy a sweet spot in the theory of computation:
they have an infinite configuration-space, yet many useful properties
(\eg, word membership, non-emptiness, control-state reachability)
remain decidable.
Once the abstracted CESK machine becomes a PDA, we can answer the
control-flow question by checking whether a specific regular language,
accounting for the states of interest, when intersected with the
language of the PDA, is nonempty.

The recasting as a PDA is a shift in perspective.
A configuration has an expression, an environment and a store. 
A stack character is a frame.
We choose to make the alphabet the set of control states, so that the
language accepted by the PDA will be sequences of control-states
visited by the abstracted CESK machine.
Thus, every transition will consume the control-state to which it
transitioned as an input character.
Figure~\ref{fig:acesk-to-pda} defines the program-to-PDA conversion
function .  (Note the implicit
use of the isomorphism .)


\begin{figure}
\figrule
\minipagebreak{0.45}[-5mm]{
\afPDA(\expr) &=
      (\QStates,\Alphabet,\StackAlpha,\transfunction,\qstate_0,\FStates,\vect{})
      \text{, where }
      \\
      \QStates &= \syn{Exp} \times \sa{Env} \times \sa{Store}
      \\
      \Alphabet &= \QStates
      \\
      \StackAlpha &= \sa{Frame}}
{0.50}
{(\qstate,\epsilon,\qstate',\qstate') \in \transfunction
  & \text{ iff }
  (\qstate, \acont)
  \aTo
  (\qstate', \acont)
  \text{ for all } \acont
  \\
  (\qstate,\aphrame_{-},\qstate',\qstate') \in \transfunction
  & \text{ iff }
  (\qstate, \aphrame : \acont)
  \aTo
  (\qstate',\acont)
  \text{ for all } \acont
  \\
  (\qstate,\aphrame'_{+},\qstate',\qstate') \in \transfunction
  & \text{ iff }
  (\qstate, \acont)
  \aTo
  (\qstate',\aphrame' : \acont)
  \text{ for all } \acont
  \\
  (\qstate_0,\vect{}) &= \aInject(\expr)
  \\
  \FStates &= \QStates
  \text.}
\captionsetup{justification=centering}
\caption{.
}
\label{fig:acesk-to-pda}
\figrule
\end{figure}

At this point, we can answer questions about whether a specified
control state is reachable by formulating a question about the
intersection of a regular language with a context-free language
described by the PDA.
That is, if we want to know whether the control state
 is reachable in a program , we can reduce the problem to determining:

where  is the concatenation of formal languages  and .

\begin{theorem}
  Control-state reachability is decidable.
\end{theorem}
\begin{proof}
  The intersection of a regular language and a context-free language
  is context-free (simple machine product of PDA with DFA).
The emptiness of a context-free language is decidable.
The decision procedure is easiest for CFGs: mark terminals, mark non-terminals that reduce to marked (non)terminals until we reach a fixed point. If the start symbol is marked, then the language is nonempty.
The PDA to CFG translation is a standard construction.
\end{proof}

Now, consider how to use control-state reachability to answer the
control-flow question from earlier.
There are a finite number of possible control states in which the
\lamterm{}  may flow to the function  in call site
; let's call this set of states :

What we want to know is whether any state in the set  is
reachable in the PDA.
In effect what we are asking is whether there exists a control state  such that:

If this is true, then  may flow to ; if false, then it
does not.



\paragraph{Problem: Doubly exponential complexity}
\label{sec:doubly-exponential}
The non-emptiness-of-intersection approach establishes decidability of
pushdown control-flow analysis.
But, two exponential complexity barriers make this technique
impractical.


First, there are an exponential number of both environments
() and stores () to consider for the set .
On top of that, computing the intersection of a regular language with
a context-free language will require enumeration of the
(exponential) control-state-space of the PDA.
The size of the control-state-space of the PDA is clearly doubly exponential:

As a result, this approach is doubly exponential.
For the next few sections, our goal will be to lower the complexity of
pushdown control-flow analysis.


\section{Focusing on Reachability}
\label{sec:pdreachability}

In the previous section, we saw that control-flow analysis reduces to
the reachability of certain control states within a pushdown system.
We also determined reachability by converting the
abstracted CESK machine into a PDA, and using emptiness-testing on a
language derived from that PDA.
Unfortunately, we also found that this approach is deeply exponential.

Since control-flow analysis reduced to the reachability of
control-states in the PDA, we skip the language problems and go
directly to reachability algorithms of
\citet{mattmight:Bouajjani:1997:PDA-Reachability,dvanhorn:Kodumal2004Set,mattmight:Reps:1998:CFL}
and \citet{mattmight:Reps:2005:Weighted-PDA} that determine the
reachable \emph{configurations} within a pushdown system.
These algorithms are even polynomial-time.
Unfortunately, some of them are polynomial-time in the number of
control states, and in the abstracted CESK machine, there are an
exponential number of control states.
We don't want to \emph{enumerate} the entire control state-space, or
else the search becomes exponential in even the best case.

 


To avoid this worst-case behavior, we present a straightforward
pushdown-reachability algorithm that considers only the
\emph{reachable} control states.
We cast our reachability algorithm as a fixed-point iteration, in
which we incrementally construct the reachable subset of a pushdown system.
A rooted pushdown system  is \emph{compact}
if for any , it is the case that:

and the domain of states and stack characters are exactly those that appear in :
\begin{itemize}
\item[]{}
\item[]{}
\end{itemize}
In other words, a rooted pushdown system is compact when its states, transitions and stack characters appear on legal paths from the initial control state.
We will refer to the class of compact rooted pushdown systems as .

We can compact a rooted pushdown system with a map:



In practice, the real difference between a rooted pushdown system and
its compact form is that our original system will be defined
intensionally (having come from the components of an abstracted CESK
machine), whereas the compact system will be defined extensionally,
with the contents of each component explicitly enumerated during its construction.

Our near-term goals are (1) to convert our abstracted CESK machine into
a rooted pushdown system and (2) to find an \emph{efficient} method
to compact it.

To convert the abstracted CESK machine into a rooted pushdown system,
we use the function :

\begin{center}
  \minipagebreak{0.45}{\afRPDS(\expr) &=
      (\QStates,\StackAlpha,\transfunction,\qstate_0)
      \\
      \QStates &= \syn{Exp} \times \sa{Env} \times \sa{Store}
      \\
      \StackAlpha &= \sa{Frame} 
      \\
      (\qstate_0,\vect{}) &= \aInject(\expr)}
  {0.50}{\qstate \pdedge^\epsilon \qstate' \in \transfunction & \text{ iff
     } (\qstate, \acont) \aTo (\qstate', \acont) \text{ for all }
     \acont
     \\
     \qstate \pdedge^{\aphrame_{-}} \qstate'
\in \transfunction & \text{ iff } (\qstate, \aphrame : \acont)
     \aTo (\qstate',\acont) \text{ for all } \acont
     \\
\qstate \pdedge^{\aphrame_{+}} \qstate' \in \transfunction &
     \text{ iff } (\qstate, \acont) \aTo (\qstate',\aphrame : \acont)
     \text{ for all } \acont
     \text.}
\end{center}


\section{Compacting a Rooted Pushdown System}
\label{sec:rpds-to-crpds}
We now turn our attention to compacting a rooted pushdown
system (defined intensionally) into its compact form (defined
extensionally).
That is, we want to find an implementation of the function .
To do so, we first phrase the construction as the least fixed point of a monotonic function.
This will provide a method (albeit an inefficient one) for computing
the function .
In the next section, we look at an optimized work-set driven
algorithm that avoids the inefficiencies of this section's algorithm.



The function  generates the monotonic iteration function we need:
\begin{center}
  \minipagebreak{0.40}[-1cm]{\mkCRPDS(M) &= f\text{, where }
    \\
    M &= (\QStates,\StackAlpha,\transfunction,\qstate_0)}
    {0.55}{f(\DSStates,\DSFrames,\DSEdges,\dsstate_0) &=
    (\DSStates',\DSFrames,\DSEdges',\dsstate_0) \text{, where }
    \\
    \DSStates' &= \DSStates \union \setbuild{ \dsstate' }{ \dsstate
      \in \DSStates \text{ and } \dsstate \mathrel{\underset{M}{\RPDTrans}}
      \dsstate' } \union \set{\dsstate_0}
    \\
    \DSEdges' &= \DSEdges \union \setbuild{ \dsstate \pdedge^\stackact
      \dsstate' }{ \dsstate \in \DSStates \text{ and } \dsstate
      \mathrel{\overset{\stackact}{\underset{M}{\RPDTrans}}} \dsstate' } \text.
}
\end{center}
Given a rooted pushdown system , each application of the function
 accretes new edges at the frontier of the system.
Once the algorithm reaches a fixed point, the system is complete:
\begin{theorem}\label{thm:mkCRPDS-correct}
  .
\end{theorem}
\begin{proof}
Let .
Let .
Observe that  for some .
When , then it easy to show that .
Hence, .

  To show , suppose this is not
  the case.
Then, there must be at least one edge in  that is not in
  .
Since these edges must be root reachable, let  be the first such edge in some path from the root.
This means that the state  is in .
Let  be the lowest natural number such that  appears in .
By the definition of , this edge must appear in , which means it must also appear in 
  , which is a contradiction.
Hence, .
\end{proof}



\subsection{Complexity: Polynomial and exponential}
\label{sec:compl-pol-exp}
 
To determine the complexity of this algorithm, we ask two questions:
how many times would the algorithm invoke the iteration function in
the worst case, and how much does each invocation cost in the
worst case?
The size of the final system bounds the run-time of the algorithm.
Suppose the final system has  states.
In the worst case, the iteration function adds only a single edge each
time.
Since there are at most  edges in the final graph, the maximum
number of iterations is .


The cost of computing each iteration is harder to bound.
The cost of determining whether to add a push edge is proportional to
the size of the stack alphabet, while the cost of determining whether
to add an -edge is constant, so the cost of determining all
new push and  edges to add is proportional to .
Determining whether or not to add a pop edge is expensive.
To add the pop edge
, we must prove that
there exists a configuration-path to the control state , in which
the character  is on the top of the stack.
This reduces to a CFL-reachability query~\cite{mattmight:Melski:2000:CFL}
at each node, the cost of which is ~\cite{dvanhorn:Kodumal2004Set}.

To summarize, in terms of the number of reachable control states, the
complexity of the most recent algorithm is:

While this approach is polynomial in the number of reachable
control states, it is far from efficient.
In the next section, we provide an optimized version of this
fixed-point algorithm that maintains a work-set and an
\ecg{} to avoid spurious recomputation.

Moreover, we have carefully phrased the complexity in terms of
``reachable'' control states because, in practice, compact rooted
pushdown systems will be extremely sparse, and because the maximum
number of control states is exponential in the size of the input
program.
After the subsequent refinement, we will be able to develop a hierarchy of
pushdown control-flow analyses that employs widening to achieve a
polynomial-time algorithm at its foundation.



\section{An Efficient Algorithm: Work-sets and 
    -Closure Graphs}
\label{sec:ecg-worklist}
We have developed a fixed-point formulation of the rooted pushdown
system compaction algorithm, but found that, in each iteration, it
wasted effort by passing over all discovered states and edges, even
though most will not contribute new states or edges.
Taking a cue from graph search, we can adapt the fixed-point algorithm
with a work-set.
That is, our next algorithm will keep a work-set of new states and
edges to consider, instead of reconsidering all of them.
We will refer to the compact rooted pushdown system we are constructing as a graph, since that is how we represent it ( is the set of nodes, and  is a set of labeled edges).

In each iteration, it will pull new states and edges from the work
list, insert them into the graph and then populate the
work-set with new states and edges that have to be added as a
consequence of the recent additions.

\subsection{-closure graphs}
Figuring out what edges to add as a consequence of another edge
requires care, for adding an edge can have ramifications on distant
control states.
Consider, for example, adding the -edge  into the following graph:

As soon this edge drops in, an -edge ``implicitly'' appears
 between  and  because the net
stack change between them is empty; the resulting graph looks like:

where we have illustrated the implicit -edge as a dotted line.

To keep track of these implicit edges, we will construct a second
graph in conjunction with the graph: an -closure
graph.
In the -closure graph, every edge indicates the existence of
a no-net-stack-change path between control states.
The -closure graph simplifies the task of figuring out
which states and edges are impacted by the addition of a new edge.

Formally, an \textbf{-closure graph}, , is
a set of edges.
Of course, all \ecg s are reflexive: every node has a self loop.
We use the symbol  to denote the class of all \ecg s.


We have two notations for finding ancestors and descendants of a state
in an \ecg{}:



\subsection{Integrating a work-set}
Since we only want to consider new states and edges in each iteration,
we need a work-set, or in this case, three work-sets:
\begin{itemize}
\item{ contains states to add,}
\item{ contains edges to add,}
\item{ contains new -edges.}
\end{itemize}
Let  be the space of work-sets.

\subsection{A new fixed-point iteration-space}
Instead of consuming a graph and producing a graph, the new fixed-point iteration function will consume and produce a graph,
an \ecg{}, and the work-sets.
Hence, the iteration space of the new algorithm is:

The \emph{I} in  stands for \emph{intermediate}.



\subsection{The -closure 
  graph work-list algorithm}
The function  generates the required iteration function (Figure~\ref{fig:mkcompact-ecg}).
\begin{figure}
\figrule

\caption{The fixed point of the function  contains
  the compact form of the rooted pushdown system .}
\label{fig:mkcompact-ecg}
\figrule
\end{figure}
Please note that we implicitly distribute union across tuples:

The functions , , ,  (defined shortly)
calculate the additional the graph edges and \ecg{} edges
(potentially) introduced by a new state or edge.

\paragraph{Sprouting}
Whenever a new state gets added to the graph, 
the algorithm must check whether that state has any new edges to contribute.
Both push edges and -edges do not depend on the current
stack, so any such edges for a state in the pushdown system's
transition function belong in the graph. 
The sprout function:

checks whether a new state could produce any new push edges or no-change edges.
We can represent its behavior diagrammatically (as previously, the
dotted arrows correspond to the corresponding additions to the
work-graph and -closure work graph):

which means if adding control state :
\begin{itemize}
\item[] add edge  if it exists
  in  (hence the arrow subscript ), and
\item[] add edge  if it exists in  .
\end{itemize}
Formally:




\paragraph{Considering the consequences of a new push edge}
Once our algorithm adds a new push edge to a graph, there
is a chance that it will enable new pop edges for the same stack frame
somewhere downstream.
If and when it does enable pops, it will also add new edges to the
\ecg{}.
The  function:

checks for -reachable states that could produce a pop.
We can represent this action by the following diagram (the arrow
subscript  indicates edges in the -closure graph):

which means if adding push-edge :
\begin{itemize}
  \item[] if pop-edge  is in , then
  \item[] \hspace{1.5em} add edge , and
  \item[] \hspace{1.5em} add -edge .
\end{itemize}
Formally:



\paragraph{Considering the consequences of a new pop edge}
Once the algorithm adds a new pop edge to a graph, it will create 
at least one new \ecg{} edge and possibly more by matching up with
upstream pushes.
The  function:

checks for -reachable push-edges that could match this pop-edge.
This action is illustrated by the following diagram:

which means if adding pop-edge :
\begin{itemize}
 \item[] if push-edge  is already in the graph, then
 \item[] \hspace{1.5em} add -edge .
\end{itemize}
Formally:

 
\paragraph{Considering the consequences of a new -edge}
Once the algorithm adds a new \ecg{} edge, it may transitively
have to add more \ecg{} edges, and it may connect an old push to
(perhaps newly enabled) pop edges.
The  function:

checks for newly enabled pops and \ecg{} edges:
Once again, we can represent this action diagrammatically:

which means if adding -edge :
\begin{itemize}
  \item[] if pop-edge  is in , then
  \item[] \hspace{2em} add -edge ; and
  \item[] \hspace{2em} add edge ; 
  \item[] add -edges ,
    , and
    .
\end{itemize}
Formally:






\subsection{Termination and correctness}
To prove that a fixed point exists, we show the iteration function is monotonic.
The key observation is that  and  drive all additions to, and are disjoint from,  and .
Since  and  monotonically increase in a finite space,  and  run out of room (full details in \autoref{lem:termination}).
Once the graph reaches a fixed point, all work-sets will be empty, and the \ecg{} will also be saturated.
We can also show that this algorithm is correct by defining first 
 as


and stating the following theorem:

\begin{theorem}\label{thm:eps-closure-correct}
  For all ,  and ,
  where .
\end{theorem}
In the proof of Theorem~\ref{thm:eps-closure-correct}, the 
case comes from an invariant lemma we have on :

\begin{lemma}
  
\end{lemma}
The  case follows from
\begin{lemma}
  For all traces ,
  there is both a corresponding path  and
  for all non-empty subtraces of , , if  then .
\end{lemma}

Since all edges in a compact rooted pushdown system must be in a path from the initial state, we can extract the edges from said paths using this lemma.

\subsection{Complexity: Still exponential, but more efficient}

As in the previous case (Section~\ref{sec:compl-pol-exp}), to
determine the complexity of this algorithm, we ask two questions: how
many times would the algorithm invoke the iteration function in the
worst case, and how much does each invocation cost in the worst case?
The run-time of the algorithm is bounded by the size of the final
graph plus the size of the \ecg.
Suppose the final graph has  states.
In the worst case, the iteration function adds only a single edge each
time.
There are at most  edges in the graph ( push edges, just as many pop edges, and  no-change edges) and
at most  edges in the \ecg{}, which bounds the number of
iterations.
Recall that  can be exponential in the size of the program, since  (and Section~\ref{sec:doubly-exponential} derived the exponential size of ).

Next, we must reason about the worst-case cost of adding an edge: how
many edges might an individual iteration consider?
In the worst case, the algorithm will consider every edge in every
iteration, leading to an asymptotic time-complexity of:

While still high, this is a an improvement upon the previous
algorithm.  
For sparse graphs, this is a reasonable algorithm.




\section{Polynomial-Time Complexity from Widening}
\label{sec:widening}

In the previous section, we developed a more efficient fixed-point
algorithm for computing a compact rooted pushdown system.
Even with the core improvements we made, the algorithm remained
exponential in the worst case, owing to the fact that there could be
an exponential number of reachable control states.
When an abstract interpretation is intolerably complex, the standard
approach for reducing complexity and accelerating convergence is
widening~\cite{mattmight:Cousot:1977:AI}.
Of course, widening techniques trade away some precision to gain this
speed.
It turns out that the small-step variants of finite-state CFAs are
exponential without some sort of widening as
well~\cite{dvanhorn:VanHorn-Mairson:ICFP08}.


To achieve polynomial time complexity for pushdown control-flow
analysis requires the same two steps as the classical case: (1)
widening the abstract interpretation to use a global,
``single-threaded'' store and (2) selecting a monovariant allocation
function to collapse the abstract configuration-space.
Widening eliminates a source of exponentiality in the size of the
store; monovariance eliminates a source of exponentiality from
environments.
In this section, we redevelop the pushdown control-flow analysis
framework with a single-threaded store and calculate
its complexity.



\subsection{Step 1: Refactor the concrete semantics}
First, consider defining the reachable states of the concrete
semantics using fixed points.
That is, let the system-space of the evaluation function be
sets of configurations:

We can redefine the concrete evaluation function:


\subsection{Step 2: Refactor the abstract semantics}
We can take the same approach with the abstract evaluation function,
first redefining the abstract system-space:

and then the abstract evaluation function:

What we'd like to do is shrink the abstract system-space with a
refactoring that corresponds to a widening.

\subsection{Step 3: Single-thread the abstract store}
We can approximate a set of abstract stores
 with 
the least-upper-bound of those stores: .
We can exploit this by creating a new abstract system space in which
the store is factored out of every configuration.
Thus, the system-space contains a set of \emph{partial configurations}
and a single global store:

We can factor the store out of the abstract transition relation as well, so that
:

which gives us a new iteration function,
,


\subsection{Step 4: Pushdown control-flow graphs}
Following the earlier graph reformulation of the compact rooted
pushdown system, we can reformulate the set of partial
configurations as a \emph{pushdown control-flow graph}.
A \defterm{pushdown control-flow graph} is a frame-action-labeled
graph over partial control states, and a \defterm{partial control
  state} is an expression paired with an environment:

In a pushdown control-flow graph, the partial control states are
partial configurations which have dropped the continuation component;
the continuations are encoded as paths through the graph.

\paragraph{A preliminary analysis of complexity}
Even without defining the system-space iteration function, we can ask,
\emph{How many iterations will it take to reach a fixed point in the worst
case?}
This question is really asking, \emph{How many edges can we add?}
And, \emph{How many entries are there in the store?}
Summing these together, we arrive at the worst-case number of
iterations:

With a monovariant allocation scheme that eliminates abstract environments, the number of iterations
ultimately reduces to:

which means that, in the worst case, the algorithm makes a cubic
number of iterations with respect to the size of the input
program.\footnote{In computing the number of frames, we note that in
  every continuation, the variable and the expression uniquely
  determine each other based on the let-expression from which they
  both came.
As a result, the number of abstract frames available in a
  monovariant analysis is bounded by both the number of variables and
  the number of expressions, \ie, .}

The worst-case cost of the each iteration would be dominated by a
CFL-reachability calculation, which, in the worst case, must consider
every state and every edge:

Thus, each iteration takes  and there are a maximum of  iterations, where  is the size of the program.
So, total complexity would be  for a monovariant
pushdown control-flow analysis with this scheme, where  is again the size of the program.
Although this algorithm is polynomial-time, we can do better.



\subsection{Step 5: Reintroduce 
  -closure graphs}\label{sec:pdcfa-eps}
Replicating the evolution from Section~\ref{sec:ecg-worklist} for this
store-widened analysis, we arrive at a more efficient polynomial-time
analysis.
An \ecg{} in this setting is a set of pairs of store-less,
continuation-less partial states:

Then, we can set the system space to include \ecg s:


Before we redefine the iteration function, we need another factored
transition relation.
The stack- and action-factored transition relation
 determines if a transition is possible
under the specified store and stack-action:




Now, we can redefine the iteration function (Figure~\ref{fig:widen-trans}).

\begin{figure}
\figrule


\caption{An \ecg{}-powered iteration function for pushdown control-flow analysis with a single-threaded store.}
\label{fig:widen-trans}
\figrule
\end{figure}

\begin{theorem}
Pushdown 0CFA with single-threaded store (PDCFA) can be computed in -time, where  is the
size of the program.
\end{theorem}
\begin{proof}
As before, the maximum number of iterations is cubic in the size of
the program for a monovariant analysis.
Fortunately, the cost of each iteration is also now bounded by the number
of edges in the graph, which is also cubic.
\end{proof}







\section{Introspection for Abstract Garbage Collection}
Abstract garbage collection~\cite{mattmight:Might:2006:GammaCFA} yields large
improvements in precision by using the abstract interpretation of garbage
collection to make more efficient use of the finite address space available
during analysis.
Because of the way abstract garbage collection operates, it grants exact
precision to the flow analysis of variables whose bindings die
between invocations of the same abstract context.
Because pushdown analysis grants exact precision in tracking return-flow, it is
clearly advantageous to combine these techniques.
Unfortunately, as we shall demonstrate, abstract garbage collection
breaks the pushdown model by requiring a full traversal of the stack to discover the
root set.


Abstract garbage collection modifies the transition relation
to conduct a ``stop-and-copy'' garbage collection before each
transition.
To do this, we define a garbage collection function 

on
configurations:

  where the pipe operation  yields the function , but with
  inputs not in the set  mapped to bottom---the empty set.
The reachability function 
  first computes the root set, and then the transitive closure of an
  address-to-address adjacency relation: 

where the function  
  finds the root addresses:
  
  and the  function
  finds roots down the stack:
  
  using a ``touches'' function, :
  
  and the relation
  
  connects adjacent addresses:
  

The new abstract transition relation is thus the composition of abstract garbage collection with the old transition relation:



\paragraph{Problem: Stack traversal violates pushdown constraint}

In the formulation of pushdown systems, the transition relation is restricted
to looking at the top frame, and in less restricted formulations that may read the stack,
the reachability decision procedures need the entire system up-front.
Thus, the relation  cannot be computed as
a straightforward pushdown analysis using summarization.


\paragraph{Solution: Introspective pushdown systems}
To accommodate the richer structure of the relation , we
now define \emph{introspective} pushdown systems.
Once defined, we can embed the garbage-collecting abstract interpretation
within this framework, and then focus on developing a control-state
reachability algorithm for these systems.


An \defterm{introspective pushdown system} is a quadruple
:
\begin{enumerate}

\item  is a finite set of control states;

\item  is a stack alphabet; 

\item  is a transition relation (where  implies ); and

\item  is a distinguished root control state. 
\end{enumerate}
The second component in the transition relation is 
a realizable stack at the given control-state.
This realizable stack distinguishes an introspective pushdown system
from a general pushdown system.
  denotes the class of all introspective pushdown
systems.


Determining how (or if) a control state 
transitions to a control state , requires knowing a
path taken to the state .
We concern ourselves with root-reachable states.
When ,
if there is a  such that  we say  is reachable via , where



\subsection{Garbage collection in introspective pushdown systems}

To convert the garbage-collecting,
abstracted CESK machine into an introspective pushdown system,
we use the function :
\begin{center}
  \minipagebreak{0.45}{\afIPDS(\expr) &= (\QStates,\StackAlpha,\transfunction,\qstate_0)
    \\
    \QStates &= \syn{Exp} \times \sa{Env} \times \sa{Store}
    \\
    \StackAlpha &= \sa{Frame}
    \\
    (\qstate_0,\vect{}) &= \aInject(\expr)} {0.50}{(\qstate,\acont,\epsilon,\qstate')
\in \transfunction & \text{ iff } \aCollect(\qstate, \acont) \aTo
    (\qstate', \acont)
\\
(\qstate,\aphrame : \acont,\aphrame_{-},\qstate') \in
    \transfunction & \text{ iff } \aCollect(\qstate, \aphrame :
    \acont) \aTo (\qstate',\acont)
\\
    (\qstate,\acont,\aphrame_{+},\qstate')
\in \transfunction & \text{ iff } \aCollect(\qstate, \acont) \aTo
    (\qstate',\aphrame : \acont)
\text.}
\end{center}


\section{Problem: Reachability for Introspective Pushdown Systems is Uncomputable}
\label{sec:ipds-incomputable}

As currently formulated, computing control-state reachability
for introspective pushdown systems is uncomputable.
The problem is that the transition relation expects to enumerate every possible
stack for every control point at every transition, without restriction.
\begin{theorem}
  Reachability in introspective pushdown systems is uncomputable.
\end{theorem}
\begin{proof}
  Consider an IPDS with two states --- {\tt searching} (start state) and
  {\tt valid} --- and a singleton stack alphabet of unit
  ().
For any first-order logic proposition, , we can define a
  reduction relation that interprets the length of the stack as an
  encoding of a proof of .
If the length encodes an ill-formed proof object, or is not a proof
  of , {\tt searching} pushes  on the stack
  and transitions to itself.
If the length encodes a proof of , transition
  to {\tt valid}.
By the completeness of first-order logic, if  is valid, there
  is a finite proof, making the pushdown system terminate in {\tt valid}.
  If it is not valid, then there is no proof and {\tt valid} is unreachable.
  Due to the undecidability of first-order logic, we definitely cannot have a decision procedure for
  reachability of IPDSs.
\end{proof}


To make introspective pushdown systems computable,
we must first refine our definition of introspective pushdown
systems to operate on \emph{sets} of stacks
and insist these sets be regular.

\newpage

A \defterm{conditional pushdown system} (CPDS) is a quadruple
:
\begin{enumerate}

\item  is a finite set of control states;

\item  is a stack alphabet; 

\item  is a transition relation (same restriction on stacks); and

\item  is a distinguished root control state,
\end{enumerate}
where  is the set of all regular languages formable with strings in .

The regularity constraint on the transition relations guarantees that
we can decide applicability of transition rules at each state, since (as we will see)
the set of all stacks that reach a state in a CPDS has decidable overlap with regular languages.
Let  denote the set of all conditional pushdown systems.

The rules for reachability with respect to sets of stacks are similar to those for IPDSs.


We will write  to mean there are  such that  is reachable via ,  and . We will omit the labels above if they merely exist.

\subsection{Garbage collection in conditional pushdown systems}

Of course, we must adapt abstract garbage collection to this refined framework.
To convert the garbage-collecting,
abstracted CESK machine into a conditional pushdown system,
we use the function :


Assuming we can overcome the difficulty of computing with some representation of a set of stacks, the intuition for the decidability of control-state reachability with garbage collection stems from two observations:
garbage collection operates on sets of addresses, and for any given control point there is a finite number of sets of sets of addresses.
The finiteness makes the definition of  fit the finiteness restriction of CPDSs.
The regularity of  (for any given , which we recall are finite sets) is apparent from a simple construction: let the DFA control states represent the subsets of , with  the start state and  the accepting state.
Transition from  to  for each  (no transition if the result is not a subset of ).
Thus any string of frames that has a stack root of  (and only ) gets accepted.

The last challenge to consider before we 
can delve into the mechanics of computing reachable control states
is \emph{how} to represent the sets of stacks 
that may be paired with each control state.
Fortunately, a regular language can describe the stacks that share the same root addresses,
the set of stacks at a control point are recognized by a one-way non-deterministic stack automaton (1NSA), \emph{and}, fortuitously,
non-empty overlap of these two is decidable (but NP-hard~\citep{ianjohnson:rounds:complexity:1973}).
The 1NSA describing the set of stacks at a control point is already encoded in the structure of the (augmented) CRPDS that we will accumulate while computing reachable control states.
As we develop an algorithm for control-state reachability, we will
exploit this insight (Section~\ref{sec:implementation}).


\section{Reachability in Conditional Pushdown Systems}
We will show a progression of constructions that take us along the following line:


In the first construction, we show that a CCPDS is finitely constructible in a similar fashion as in Section~\ref{sec:rpds-to-crpds}.
The key is to take the current introspective CRPDS and ``read off'' an automaton that describes the stacks accepted at each state.
For traditional pushdown systems, this is always an NFA, but introspection adds another feature: transition if the string accepted so far is accepted by a given NFA.
Such power falls outside of standard NFAs and into one-way non-deterministic stack automata (1NSA)\footnote{The reachable states of a 1NSA is known to be regular, but the paths are not.}.
These automata enjoy closure under finite intersection with regular languages and decidable emptiness checking~\citep{ianjohnson:one-way-sa:ginsburg:1967}, which we use to decide applicability of transition rules.
If the stacks realizable at  have a non-empty intersection with a set of stacks  in a rule , then there are paths from the start state to  that further reach .

The structure of the GC problem allows us to sidestep the 1NSA constructions and more directly compute state reachability.
We specialize to garbage collection in \autoref{sec:gc-pdcfa}.
We finally show a space-saving approximation that our implementation uses.


\subsection{One-way non-deterministic stack automata}

The machinery we use for describing the realizable stacks at a state is a generalized pushdown automaton itself.
A stack automaton is permitted to move a cursor up and down the stack and read frames (left and right on the input if two-way, only right if one-way), but only push and pop when the stack cursor is at the top.
Formally, a \defterm{one-way stack automaton} is a 6-tuple  where
\begin{enumerate}
\item  is a finite nonempty set of states,
\item  is a finite nonempty input alphabet,
\item  is a finite nonempty stack alphabet,
\item  is the transition relation,
\item  is the start state, and
\item  the set of final states
\end{enumerate}

An element of the transition relation, , should be read as, ``if at  the right of the stack cursor is prefixed by  and the input is prefixed by , then consume  of the input, transition to state , move the stack cursor in direction , and if at the top of the stack, perform stack action .''
This reading translates into a run relation on \defterm{instantaneous descriptions}, .
These descriptions are essentially machine states that hold the current control state, the stack split around the cursor, and the rest of the input.

where
\begin{center}
  \begin{minipage}{0.55\linewidth}
    
  \end{minipage}
  \begin{minipage}{0.40\linewidth}
  
\end{minipage}
\end{center}

The meta-functions  and  perform the stack actions and direct the stack cursor, respectively.
A string  is thus accepted by a 1NSA  iff there are  such that


Next we develop an introspective form of compact rooted pushdown systems that use 1NSAs for realizable stacks, and prove a correspondence with conditional pushdown systems.

\subsection{Compact conditional pushdown systems}\label{sec:icrpds}

Similar to rooted pushdown systems, we say a conditional pushdown system  is compact if all states, frames and edges are on some path from the root.
We will refer to this class of conditional pushdown systems as .
Assuming we have a way to decide overlap between the set of realizable stacks at a state and a regular language of stacks, we can compute the CCPDS in much the same way as in \autoref{sec:rpds-to-crpds}.



\newcommand*{\gadget}{\mathit{gadget}}
The function  performs the stack extraction with a construction that inserts the stack-checking NFA for each reduction rule after it has run the cursor to the bottom of the stack, and continues from the final states to the state dictated by the rule (added by meta-function ).
All the stack manipulations from  to  are -transitions in terms of reading input; only once control reaches  do we check if the stack is the same as the input, which captures the notion of a stack realizable at .
Once control reaches , we run down to the bottom of the stack again, and then match the stack against the input; complete matches are accepted.
To determine the bottom and top of the stack, we add distinct sentinel symbols to the stack alphabet, \textcent{} and \}, \transfunction, \dsstate_{\text{start}}, \set{\dsstate_{\text{final}}} ) \text{, where }
  \\
  \dsstate_{\text{start}}, \dsstate_{\text{down}}, \dsstate_{\text{check}}, \dsstate_{\text{final}} \text{ fresh, and } &\DSStates', \transfunction \text{ the smallest sets such that} \\
\set{\dsstate_{\text{start}}, \dsstate_{\text{down}}, \dsstate_{\text{check}}, \dsstate_{\text{final}}} &\subseteq \DSStates' \\
(\dsstate_{\text{start}}, \epsilon, \epsilon, \cdot, \text\textcent_+, \dsstate_0) &\in \transfunction
  \\
\gadget(\dsstate', \hat K, \stackchar_\pm, \dsstate'') \sqsubseteq (\transfunction, \DSStates')
  & \text{ if } (\dsstate', \hat K, \stackchar_\pm, \dsstate'') \in \DSEdges
\\ (\dsstate, \epsilon, \epsilon, \cdot, \, \epsilon, \uparrow, \epsilon, \dsstate_{\text{final}}) &\in \transfunction 

\gadget(\dsstate, \hat K, \stackchar_\pm, \dsstate') &= (\transfunction', Q \cup \set{\qstate_{\text{down}}, \qstate_{\text{out}}})\text{ where} \\
 \text{Let } N = (Q, \Sigma, \transfunction, \qstate_0, F) &\text{ be a fresh NFA recognizing } \hat K
 \text{, } \qstate_{\text{down}}, \qstate_{\text{out}} \text{ fresh states}
 \\ (\qstate, a, \epsilon, \uparrow, \epsilon, \qstate') \in \transfunction' &\text{ if } (\qstate, a, \qstate') \in \transfunction \text{, } a \in \Sigma
 \\ (\qstate, \epsilon, \epsilon, \cdot, \epsilon, \qstate') \in \transfunction' &\text{ if } (\qstate, \epsilon, \qstate') \in \transfunction
 \\ (\qstate, \_-, \qstate_{\text{out}}) \in \transfunction' &\text{ if } \qstate \in F
 \\ (\qstate_{\text{out}}, \epsilon, \epsilon, \cdot, \stackchar_\pm, \dsstate') \in \transfunction'
 \\ (\dsstate, \epsilon, \epsilon, \cdot, \\hat K\epsilonNM = (\QStates, \StackAlpha, \transfunction, \qstate_0)\fCCPDS(M) = (\DSStates, \StackAlpha, \DSIEdges, \qstate_0)\DSStates\DSIEdgesM \in \mathbb{CPDS}\fCCPDS(M) = \lfp(\mkCCPDS(M))M = (\QStates, \StackAlpha, \transfunction, \qstate_0) \in \mathbb{CPDS}(\DSStates, \StackAlpha, \DSIEdges, \qstate_0) = \lfp(\mkCCPDS(M))(\qstate_0,\vect{}) \mathrel{{\underset{M}{\PDTrans}}^*} (\qstate,\acont)\qstate \in \DSStates\Stacks(G)(\qstate)\acont\hat K\epsilon\apstate \in \sa{PState} = \syn{Exp} \times \sa{Env} \times \sa{Store}\aopstate \in \sa{OPState} = \sa{PState} \times \PowSm{\sa{Addr}}\atf_{\expr}\overset{A}{\underset{\stackact}{\apTo}}
\subseteq \sa{PState} \times \sa{PState}\lfp(\atf_\expr)\fCCPDS(\afIPDS'(\expr))\hat E \in \sa{Edge} = \Pow{\sa{PState} \times \PowSm{\sa{Addr}} \times \sa{Frame}_\pm \times \sa{PState}}\att : (\sa{PState} \to \PowSm{\sa{Addr}}) \to (\sa{PState} \to \PowSm{\sa{Addr}})\atf_\expr'{\mathcal R}(\apstate)
\supseteq A(\apstate, A)\lfp(\atf_\expr')\lfp(\atf_\expr)qqq_0q_0qqq\qstate'\epsilon\qstate\qstate \mathrel{\overset{\vec{\stackact}}{\underset{M}{\RPDTrans}}}
\qstate'[\vec{\stackact}] = \epsilon\epsilon\qstate\epsilon\epsilonqq\epsilonq\epsilon\qstate \xrightarrow{\epsilon}
  \qstate'\epsilon\qstate\epsilon\qstate'\epsilon\stackchar_-\qstate
  \xrightarrow{\stackchar_-} \qstate'\epsilon\qstate_1\qstate'\epsilon\qstate_1\epsilon\qstate\stackchar_+\qstate\epsilon\qstate\epsilon\stackchar_+\stackchar_+\epsilon\stackchar_+kkkkk\# e\#vkkkkk>>>>>>k \in \set{0, 1}k10^5kkkkkk\epsilonk\epsilon\epsilonkk'''\infty\# e\#v\#vk=0k=0k=1k=1>>k \in \set{0, 1}'''kk \in \set{0,1}\lam\lam\epsilon\lam\epsilonfggafa\mathcal{O}(n^6)\lambda$-calculus.
Like the present work, Midtgaard and Jensen start with the CESK
machine of \citet{mattmight:Flanagan:1993:ANF} and employ a
reachable-states model. 

The analysis is then constructed by composing well-known
Galois connections to reveal a 0CFA incorporating reachability.
The abstract semantics approximate the control stack component of the
machine by its top element.
The authors remark monomorphism materializes in two mappings: one
``mapping all bindings to the same variable,'' the other ``merging all
calling contexts of the same function.''
Essentially, the pushdown 0CFA of Section~\ref{sec:abstraction}
corresponds to Midtgaard and Jensen's analysis when the latter
mapping is omitted and the stack component of the machine is not
abstracted.
However, not abstracting the stack requires non-trivial mechanisms to compute the compaction of the pushdown system.

\paragraph{CFL- and pushdown-reachability techniques}
This work also draws on CFL- and pushdown-reachability
analysis~\cite{mattmight:Bouajjani:1997:PDA-Reachability,dvanhorn:Kodumal2004Set,mattmight:Reps:1998:CFL,mattmight:Reps:2005:Weighted-PDA}.
For instance, \ecg s, or equivalent variants thereof, appear in many
context-free-language and pushdown reachability algorithms.
For our analysis, we implicitly invoked these methods as subroutines.
When we found these algorithms lacking (as with their enumeration of
control states), we developed rooted pushdown system compaction.


CFL-reachability techniques have also been used to compute classical
finite-state abstraction CFAs~\cite{mattmight:Melski:2000:CFL} and
type-based polymorphic control-flow
analysis~\cite{mattmight:Rehof:2001:TypeBased}.
These analyses should not be confused with pushdown control-flow
analysis, which is computing a fundamentally more precise kind of CFA.
Moreover, Rehof and F\"ahndrich's method is cubic in the size of the
\emph{typed} program, but the types may be exponential in the size of
the program.
Finally, our technique is not restricted to typed programs.

\paragraph{Model-checking pushdown systems with checkpoints}
A pushdown system with checkpoints has designated finite automata for state/frame pairs.
If in a given state/frame configuration, and the automaton accepts the current stack, then execution continues.
This model was first created in \citet{EsparzaKS03} and describes its applications to model-checking programs that use Java's \texttt{AccessController} class, and performing better data-flow analysis of Lisp programs with dynamic scope, though the specific applications are not fully explored.
The algorithm described in the paper is similar to ours, but not ``on-the-fly,'' however, so such applications would be difficult to realize with their methods.
The algorithm discussed has multiple loops that enumerate all transitions within the pushdown system considered.
Again this is a non-starter for higher-order languages, since up-front enumeration would conservatively suggest that any binding called would resolve to any possible function.
This strategy is a sure-fire way to destroy precision and performance.

\paragraph{Meet-over-all-paths for conditional weighted pushdown systems}
A conditional pushdown system is essentially a pushdown system in which every state/frame pair is a checkpoint.
The two are easily interchangeable, but weighted conditional pushdown systems assign weights to reduction rules from a bounded idempotent semiring in the same manner as \citet{mattmight:Reps:2005:Weighted-PDA}.
The work that introduces CWPDSs uses them for points-to analysis for Java.
They solve the meet-over-all-paths problem by an incrementally translating a skeleton CFG into a WPDS and using WPDS++~\citep{ianjohnson:DBLP:conf/cav/LalR06} to discover more points-to information to fill in call/return edges.
The translation involves a heavy encoding and is not obviously correct.
The killer for its use for GC is that it involves building the product automaton of all the (minimized) condition automata for the system, and interleaving the system states with the automaton's states --- there are exponentially many such machines in our case, and even though the overall solution is incremental, this large automaton is pre-built.
It is not obvious how to incrementalize the whole construction, nor is it obvious that the precision and performance are not negatively impacted by the repeated invocation of the WPDS solver (as opposed to a work-set solution that only considers recently changed states).


The approach to incremental solving using first-order tools is an interesting approach that we had not considered.
Perhaps first-order and higher-order methods are not too far removed.
It is possible that these frameworks could be extended to request transitions --- or even further, checkpoint machines --- on demand in order to better support higher-order languages.
As we saw in this article, however, we needed access to internal data structures to compute root sets of addresses, and the ability to update a cache of such sets in these structures.
The marriage could be rocky, but worth exploring in order to unite the two communities and share technologies.

\paragraph{Model-checking higher-order recursion schemes}
There is terminology overlap with work by
\citet{mattmight:Kobayashi:2009:HORS} on model-checking higher-order
programs with higher-order recursion schemes, which are a
generalization of context-free grammars in which productions can take
higher-order arguments, so that an order-0 scheme is a context-free
grammar.
Kobyashi exploits a result by \citet{dvanhorn:Ong2006ModelChecking} which
shows that model-checking these recursion schemes is decidable (but
ELEMENTARY-complete) by transforming higher-order programs into
higher-order recursion schemes.

Given the generality of model-checking, Kobayashi's technique may be
considered an alternate paradigm for the analysis of
higher-order programs.
For the case of order-0, both Kobayashi's technique and our own
involve context-free languages, though ours is for control-flow
analysis and his is for model-checking with respect to a temporal
logic.
After these surface similarities, the techniques diverge.
In particular, higher-order recursions schemes are limited
to model-checking programs in the simply-typed 
lambda-calculus with recursion.


















\section{Conclusion}

Our motivation was to further probe the limits of decidability
for pushdown flow analysis of higher-order programs
by enriching it with abstract garbage collection.
We found that abstract garbage collection broke
the pushdown model, but not irreparably so.
By casting abstract garbage collection in terms of
an introspective pushdown system and synthesizing
a new control-state reachability algorithm, we have 
demonstrated the decidability of fusing two
powerful analytic techniques.

As a byproduct of our formulation, it was also easy
to demonstrate how polyvariant/context-sensitive 
flow analyses generalize to a pushdown formulation,
and we lifted the need to transform to continuation-passing style
in order to perform pushdown analysis.


Our empirical evaluation is highly encouraging: it shows that the fused
analysis provides further large reductions in the size of the abstract
transition graph---a key metric for interprocedural control-flow precision.
And, in terms of singleton flow sets---a heuristic metric for optimizability---the fused 
analysis proves to be a ``better-than-both-worlds'' combination.

Thus, we provide a sound, precise and polyvariant introspective
pushdown analysis for higher-order programs.



\section*{Acknowledgments}
We thank the anonymous reviewers of ICFP 2012 and JFP for their
detailed reviews, which helped to improve the presentation and
technical content of the paper.
Tim Smith was especially helpful with his knowledge of stack automata.
This material is based on research sponsored by DARPA under the programs 
Automated Program Analysis for Cybersecurity (FA8750-12-2-0106) and 
Clean-Slate Resilient Adaptive Hosts (CRASH). 
The U.S. Government is authorized to reproduce and
distribute reprints for Governmental purposes notwithstanding any copyright
notation thereon.








