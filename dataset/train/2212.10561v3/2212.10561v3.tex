\appendix
\renewcommand{\thefigure}{A.\arabic{figure}}
\setcounter{table}{0}  \renewcommand{\thetable}{A.\arabic{table}}

\onecolumn

\begin{figure*}[t]
\begin{lstlisting}[escapeinside={(*}{*)}]
select_airport_cities(city_road_cost, city_airport_cost): given a matrix representing the cost of building a road between any two cities, and a list representing the cost of building an airport in a city (where any two cities with airports are connected), return a list of the cities that should have airports built in them to minimize the total cost of building roads and airports such that all cities are connected. The list should be sorted in ascending order.
[[0,3,3],[3,0,3],[3,3,0]],[0,0,0] -> [0,1,2]
[[0,3,3],[3,0,3],[3,3,0]],[10,10,10] -> []
[[0,10,3],[10,0,11],[3,11,0]],[1,4,5] -> [0,1]
    sky_city_cost(city_road_cost, city_airport_cost): given a list of lists representing the cost of building a road between any two cities, and a list representing the cost of building an airport in a city, return a new cost matrix with a new node corresponding to the sky.
    [[1,2,3],[1,2,3],[1,2,3]],[4,5,6] -> [[1,2,3,4],[1,2,3,5],[1,2,3,6],[4,5,6,0]]
    minimum_spanning_tree(cost_matrix): given a list of lists representing the cost of each edge, return an adjacency matrix corresponding to the minimum spanning true.
    [[0,1,3,4],[1,0,2,100],[3,2,0,5],[4,100,5,0]] -> [[0,1,0,1],[1,0,1,0],[0,1,0,0],[1,0,0,0]]
    final_node_connectors(adjacency_matrix): given a list of lists representing an adjacency matrix, return a list of the nodes connected to the final node. However, if only one node is connected to the final node, return an empty list.
    [[0,1,0,1],[1,0,1,0],[0,1,0,0],[1,0,0,0]] -> []
    [[0,1,0,1],[1,0,1,0],[0,1,0,1],[1,0,1,0]] -> [0,2]
\end{lstlisting}
\vspace{-8px}
\caption{A potential programming assignment focused on problem-solving rather than implementation. The top-level function and asserts would be the assigned problem (which Codex \citep{chen2021evaluating} does not seem to be able to solve directly), while the other functions would be the student solution.}
\label{studentexample}
\vspace{-12px}
\end{figure*}
\section{Implications}
\label{implications}
Parsel is a natural language compiler framework that bridges the gap between natural language and programming language by allowing programmers to write high-level algorithmic designs in natural language and automatically compiling them into valid code. This has potential benefits for programmers, students, and code language models. 

\subsection{For Programmers}
\subsubsection{Current Limitations}
First, programming generation language models like Codex continue to be constrained primarily to individual functions, rarely exceeding a few dozen lines in practice \citep{chen2021evaluating,tabachnyk2022ml}. This is still a dramatic shift from foundational earlier works, which focused on the association between one line of natural language pseudocode with one line of code \citep{kulal2019spoc} or a line of text to a StackOverflow snippet \citep{yin2018learning}. Yet, these models perform worse the more unusual the desired functions are, and recent research suggests that people using these language models are more likely to introduce buggy code \citep{perry2022users}, although this is not yet conclusive \citep{sandoval2022security}.
\subsubsection{Potential Benefits}
On the other hand, results from Google and others indicate that professionals can write code more efficiently with large language models, and the benefits will likely only improve as they improve \citep{tabachnyk2022ml}. Since Parsel requires constraints that ensure functions behave as expected, this should encourage bug-free programs and avoid the need for manually checking that specific underlying functions are correct. Furthermore, a function written in Parsel is likely to be more resilient to breaking changes in the target language, especially syntactic changes (e.g. Python2 to Python3). In addition, a natural extension would draw on work on automatic unit testing \citep{daka2014survey} to suggest additional constraints where behavior is ambiguous between implementations of a function.

\subsection{For Students}
\subsubsection{Current Limitations}
In addition, these language models pose serious challenges for programming pedagogy -- existing introductory programming classes rely extensively on teaching syntax and how to implement algorithms over how to solve problems with them. Free language model-based tools like Copilot can essentially solve many of these introductory assignments directly, function by function. Those which cannot be solved currently will be increasingly solved \citep{denny2022conversing}.
\subsubsection{Potential Benefits}
Many students currently introduced to programming struggle with learning syntax and debugging unclear compiler or interpreter errors. However, abstracting away these details with a natural-language coding language will likely make learning to code more accessible to students who are just beginning to code. In addition, stepping away from implementation-focused assignments will allow a focus on higher-level problem-solving assignments earlier. These will allow for assignments that are more like those in mathematics. For example, for a problem like Figure~\ref{studentexample}, instead of choosing between requiring students to manually implement a problem-solving focused question like the top-level description of, or requiring teaching assistants to manually evaluate the reasoning for correctness, one could ask them to implement a solution in Parsel.
\subsection{For Code Language Models}
\subsubsection{Current Limitations}
Traditional programming languages result in some unique challenges for language models. For example, unlike natural languages, traditional programming languages are far less robust to slight variations in wording. In addition, traditional programming languages require many tokens for syntactic details and in some cases, may take many lines to express what can be expressed far more simply in language. For example, referring to a shortest-path algorithm or Conway's game of life takes far fewer tokens than actually implementing them. However, even with fairly nonstandard problems, LLMs have shown remarkable algorithmic generalization ability \citep{liang2022holistic,xu2022systematic,anilexploring,zhou2022teaching}. One alternative that has been explored is conversational code generation \citep{nijkamp2022conversational,yin2022natural}. However, these approaches have primarily focused on highly imperative programming structures. Moreover, they still require having the full program in context and do not clearly generalize to complex hierarchical programs with many functions. 

\subsubsection{Potential Benefits}
Parsel allows code language models to stay closer to natural language when generating code, which corresponds more closely to their primary source of training data. Moreover, it allows complex but standard methods to be described concisely, requiring fewer tokens to generate. One exciting additional benefit is the potential to generate solutions recursively: if the Parsel compiler is unable to find a solution for a set of functions, it should be possible to prompt the model to define new helper functions. In fact, we find that often the model attempts to reference undefined auxiliary functions when defining complex functions (e.g. ``count\_living\_neighbors(grid, i, j)'' in Conway's game of life), and as a result support an optional argument where the model can attempt to resolve NameErrors automatically by attempting to implement functions.


\section{Limitations}
\label{limitations}
There are several limitations to the current implementation of Parsel. First, Parsel relies on a code LLM to generate implementations of individual functions, and the quality of these implementations can vary depending on the specific model used and the complexity of the function descriptions. In particular, Parsel may struggle to generate correct code for individual functions with complex behavior (i.e. functions that Codex cannot implement). However, this can be mitigated by decomposing the complex functions into simpler ones that can be implemented more easily.

The current implementation of Parsel may struggle to generate correct code when there are many functions with complex dependencies or without constraints. This is because the number of implementation combinations to consider grows exponentially with the size of the largest strongly connected components. As discussed, this can limit Parsel's performance on some programs. However, approaches like \citet{chen2022codet} may be able to mitigate this.

Code LLMs, unfortunately, do not perform well on languages underrepresented in their training data -- with few examples to learn from, LLMs may struggle to generate correct code in these languages \citep{athiwaratkun2022multi}. However, some LLMs can learn new languages in context, allowing them to generate code in languages not in their training data \citep{athiwaratkun2022multi}. These limitations can impact the quality and reliability of the code generated with Parsel. In addition, because code LLMs have never been trained on Parsel, this harms their ability to generate it. While we could wait for Parsel to gain widespread adoption, it should also be possible to translate many existing codebases to Parsel. We include a proof-of-concept backtranslation/decompilation study in Appendix~\ref{appendixbacktranslation}.

In addition, the best open-source code LLMs currently available e.g. PolyCoder \citep{xu2022systematic} substantially underperform Codex, while Codex is competitive with other traditional LLMs on reasoning tasks \citep{liang2022holistic}. However, this dependence on closed models creates a vulnerability, as the providers of closed LLMs can change behavior (e.g. rate limits or model implementations) without warning. Indeed, between the time we started working on Parsel and this version of the paper, OpenAI ended widespread access to Codex, now available only by request.

Because of this, we evaluated a 2.7B CodeGen model from \citet{nijkamp2022codegen} with Parsel in the same configuration we used when evaluating APPS on Codex (in the 8x16 configuration). We found that it could solve none of the random 25 problems which we evaluated it on. However, despite these limitations, the current Parsel implementation has shown promising results in generating correct code for a variety of functions and languages. Many limitations will likely be ameliorated as code LLMs improve.

\section{Future Work}
\label{futurework}
In the future, we hope to more deeply integrate automatic unit test generation, especially in combination with user-provided tests \citep{daka2014survey,chen2022codet}. One method would be to identify edge cases and check whether the set of functions that successfully solve all existing tests disagree on any new tests. This could permit automatic decomposition without exponential growth in implementation combinations. Techniques like those proposed in \citet{zhang2022coder}, which would allow us to rerank a set of solutions, could also allow us to search the combinatorial space of solutions more quickly. Relatedly, for the robotic task planning, incorporating asserts at the execution level (e.g. checking whether the agent is close to the microwave, as in \citet{singh2022progprompt}) is a promising research direction. Furthermore, evaluating the examples in this paper, we found that using the minimum CodeT score across all generated functions was a consistently effective heuristic to identify good sets of functions. However, generating unit tests for all functions when generating Parsel programs instead of generating unit tests for a shared top-level function increases the inference cost from linear in the number of tasks to also being linear in the number of functions and Parsel programs generated. Finding a way to balance this tradeoff would likely be valuable.

In addition, we plan to incorporate ways of varying the ``confidence threshold'' of the language model. Ensuring that the descriptions are straightforward and unambiguous is important for more critical programs and parts of programs. In addition, when teaching students simpler concepts, requiring them to decompose the task further may be useful.

We would like to integrate value functions to allow decomposition to be done more methodically where no verification is possible. Specifically, automatically decomposing all functions that have not yet been implemented in an SCC is suboptimal and could be improved with a model of expected improvement due to expansion, as done for proof expansion in \citet{polu2020generative}. In addition, when decomposing functions, we would like to permit the model to reference already-defined functions (rather than to just define new ones). We might even use the code language model to determine which function to evaluate next.
Further, we aim to support more general reward functions for function implementations where multiple may be valid but we rank implementations based on a desired feature. These ``soft'' constraints may also allow new Parsel uses, e.g. planning stories in natural language \citep{anbang2022neural}.

Finally, we hope it would be possible to use Parsel as a framework for bootstrapping increasingly complex program generation (e.g. \citet{anthony2017thinking,zelikman2022star,odena2020bustle}). That is, by 1) generating Parsel examples from a purely natural language specification and then reinforcing those which successfully compile, and 2) by reinforcing the model with each successfully compiled component, we would likely be able to iteratively improve performance with an arbitrarily large dataset of examples.

Another feature that would be valuable would be the ability to incorporate multiple base tools with different kinds of specialized models, inspired by \citet{ibarz2022generalist} and \citet{dohan2022language}. That is, it would be valuable to allow a model to determine which target language to use, possibly combining them. For example, for large parts of the Tensorflow and PyTorch libraries, while their interfaces are written in Python, they depend heavily on large C++ codebases \citep{paszke2019pytorch,tensorflow2015-whitepaper}. Relatedly, \citet{cobbe2021training} showed that giving language models access to a calculator allowed them to solve more complex math word problems. This, combined with the observation that Parsel could also compile programs by generating language model prompts to be used as part of the program, may potentially allow the automatic generation of task-specific language model cascades \citep{dohan2022language}.

Another noteworthy addition would be the integration of Synchromesh \citep{poesia2022synchromesh}, ensuring that each new word or token generated by the model is actually possible within the grammar of the given formal language and does not violate other semantic constraints.

Ultimately, we hope that this specification for Parsel is a jumping-off point for a new way of thinking about programming and reasoning.

\section{Theorem Proving in Lean}
\label{theoremproving}
With the same framework, we can generate proofs in formal theorem-proving languages such as Lean, as in Figure~\ref{leanandexample}.
We include the translated version in the appendix. Note a nuance of Lean and theorem-proving languages is that the ability to run Lean on proof with no errors/warnings indicates the proof is correct (but is not a guarantee that the proof statement matches our claim in language). Thus, each function in a Lean Parsel proof has an ``implicit constraint.'' This makes it straightforward to identify which informal parts of a proof are most difficult to explicate. Generally, we believe Parsel can be a powerful tool for theorem proving.

Yet, we observed important challenges in this context, which we believe are avenues for future work and can be resolved.
For example, in datasets such as MiniF2F \citep{zheng2021minif2f}, many proofs require explicit calculations in intermediate steps. That is, many proofs are similar to ``Find the minimum value of  for . Show that it is 012.'' (from the informal MiniF2F introduced by \citet{jiang2022draft}). 
We believe that a dataset of proof statements (in natural and formal language), requiring complex proofs that are more abstract and less dependent on explicit calculations would allow us to better measure progress towards solving difficult theorems -- we leave this to future work.

\begin{figure}
\begin{minipage}{\textwidth}
\begin{minipage}{0.44\textwidth}
\centering
\begin{lstlisting}[breaklines=true, escapeinside={(*}{*)}, basicstyle=\fontsize{7}{8}\selectfont\ttfamily]
~^and_commute(p q: Prop): the and operator is^~ ~^commutative^~
~?show (p (**) q (**)  q (**) p) (**) (q (**) p (**) p (**) q)?~
  ~^p_q_implies_q_p(p q: Prop): if p (**) q, then q (**) p^~
  ~^q_p_implies_p_q(p q: Prop): if q (**) p, then p (**) q^~
\end{lstlisting}
\end{minipage}\hfill \hspace{1px}{\Large }\hspace{2px} \hfill
\begin{minipage}{0.24\textwidth}
\begin{lstlisting}[breaklines=true,escapeinside={(*}{*)},basicstyle=\fontsize{4}{4}\selectfont\selectfont\ttfamily,keywords = {lemma, Prop, begin, end, exact, intro, cases},numbersep=3pt]
-- if p (**) q, then q (**) p
lemma p_q_implies_q_p(p q: Prop):

    p (**) q (**) q (**) p :=
begin
    intro h,
    cases h with hp hq,
    split,
        exact hq,
        exact hp,
end
-- Description: if p (**) q, then q (**) p
-- if q (**) p, then p (**) q
lemma q_p_implies_p_q(p q: Prop):

    (q (**) p) (**) (p (**) q) :=
begin
  intro h,
  split,
    exact h.right,
    exact h.left,
end
\end{lstlisting}
\end{minipage}\hspace{0.015\textwidth}
\begin{minipage}{0.24\textwidth}
\centering
\begin{lstlisting}[breaklines=true,escapeinside={(*}{*)},basicstyle=\fontsize{4}{4}\selectfont\selectfont\ttfamily,firstnumber=last,keywords = {lemma, Prop, begin, end, exact, intro, cases, apply},numbers=left,numbersep=2pt]
/-
  Theorem:
    If q (**) p, then p (**) q
-/
-- the and operator is commutative
lemma and_commute(p q: Prop):
  (p (**) q (**) q (**) p) (**) (q (**) p (**) p (**) q) :=

begin
  apply and.intro,
  { apply p_q_implies_q_p },
  { apply q_p_implies_p_q }
end








(**)
\end{lstlisting}
\end{minipage}
\vspace{-10px}
\caption{Parsel to Lean (theorem proving)}
\label{leanandexample}
\vspace{1px}
\end{minipage} \end{figure}

\section{Optimizations}
\label{optimizations}
\vspace{-3px}
\subsection{Caching}
\vspace{-3px}
We cache responses from the language model with respect to the prompt and language model decoding parameters 1) to reduce the number of queries necessary and 2) to keep the programs generated mostly stable (i.e. a working function should continue working unless it or its children change). To this end, when the number of desired implementations increases for a pre-existing query with all other arguments fixed (temperature, number of decoding tokens, etc), we append the additional ones to those already generated.

\vspace{-3px}
\subsection{Automatic Function Infilling}
\vspace{-3px}
Sometimes, a function generated by a language model may call a function that is not yet implemented. In this case, we can (optionally) attempt to automatically generate and implement it based on its usage. The function is then incorporated into the call graph as a unit-test-less child of the function which calls it. To avoid infinite recursion and inefficient use of language model quota, we limit the number of times that this process can be applied to a function.

\subsection{Multiprocessing}
We use multiprocessing with a user-specified timeout to test many implementation sets in parallel to allow for many fast solutions to be tested alongside slower solutions\footnote{As anticipating the number of steps that a solution will take universally is a version of the halting problem and thus intractable.}.

\section{Parsel Pseudocode}
\begin{figure*}[t]
\vspace{-10px}
\begin{lstlisting}[basicstyle=\fontsize{6}{7.5}\selectfont\ttfamily]
parsel(program, target_language): synthesize a program from a string specifying a Parsel program.
  parse_program(program): parse the Parsel program string to a call graph
    create_root_node(): create a root node as the current function node, without any constraints
    parse_line(line, current_node, current_indent) -> function_graph: for each step up in indentation, set the current node to its parents. then, parse the definition, reference, or constraint.
      parse_definition(line): create a new function node, make it a child of the current node's parent, then assign it as current node.
      parse_reference(line): add reference as a child of current node if reference is an ancestor or a direct child of an ancestor
      parse_constraint(line): add the constraint to the current node's constraints.
  get_dependency_graph(function_graph) -> dependency_graph: taking the function graph, create a copy where all nodes without asserts also depend on their parents unless the target language implicitly tests all functions.
  identify_strongly_connected_components(dependency_graph): return SCCs of the dependency graph and the edges between the SCCs.
  synthesize_scc(scc, scc_graph): find an implementation string solving a given SCC, starting with SCC dependencies, then generating possible implementations of SCC functions, then finding an implementation combination satisfying the functions' constraints
    synthesize_children(scc, scc_graph): synthesize any SCCs this SCC depends on and add them to the implementation string.
      synthesize_scc
    generate_implementations(scc, n, children_implementation_str): for each function in the SCC, prompt the language model to generate n implementations of each function starting with the implementation string of the SCC's children.
    solve_constraints(scc, fn_implementations): taking the provided constraints of each function in the scc, evaluate a shuffled list of the direct product of implementations with the constraints until one passes all of them
      direct_product_implementations(fn_implementations): return the direct product of the list of lists of fn_implementations
      generate_constraints(fn_node): translate each of the constraints into an evaluation string idiomatic to the target language and add these to the list of combined implementations
      eval_str(scc, implementation_str): evaluate an implementation including constraints by running it in a target-language executor
      on_fail(scc, scc_graph): raise an error highlighting the scc which could not be synthesized
\end{lstlisting}
\vspace{-10px}
\caption{Pseudocode in the style of Parsel describing how Parsel synthesizes programs. A detailed version including automatic decomposition and automatic infilling is in Figure~\ref{fig:parselpseudo} of Appendix~\ref{parselpseudo}. Constraints are left out for clarity -- e.g. one could define a test function and validate the compilability (or lack thereof) of a set of reference Parsel programs.}
\label{shortpseudo}
\vspace{-10px}
\end{figure*}


\label{parselpseudo}
We include a longer-form Parsel pseudocode in the style of Parsel. Note this pseudocode does not include backtranslation.

\begin{figure*}[h]
\begin{lstlisting}[basicstyle=\fontsize{6}{8}\selectfont\ttfamily]
parsel(program, target_language, allow_autofill=False, allow_autodecomp=False): compile a program from a string specifying a Parsel program.
  parse_program(program): parse the Parsel program string to a call graph
    create_root_node(): create a root node as the current function node, without any constraints
    parse_line(line, current_node, current_indent) -> function_graph: for each step up in indentation, set the current node to its parents. then, parse the definition, reference, or constraint.
      parse_definition(line): create a new function node, make it a child of the current node's parent, then assign it as current node.
        parse_line_to_fn(line) -> name, args, rets, description: extract the function name, arguments, optionally returned variables, and description of the form "name(args) -> rets: description" if return variables are present else "name(args): description".
        populate_fn_node(name, args, rets, description): populate the new node's name, arguments, description, and optionally a list of returned variables.
      parse_reference(line): add reference as a child of current node if reference is an ancestor or a direct child of an ancestor
      parse_constraint(line): add the constraint to the current node's constraints.
  get_dependency_graph(function_graph) -> dependency_graph: taking the function graph, create a copy where all nodes without constraints also depend on their parents unless the target language implicitly tests all functions.
  identify_strongly_connected_components(dependency_graph): return SCCs of the dependency graph and the edges between the SCCs.
  compile_scc(scc, scc_graph, allow_autofill, allow_autodecomp): accumulate a implementation string which solves the current function
    compile_children(scc, scc_graph, allow_autofill, allow_autodecomp): compile any SCCs this SCC depends on and add them to the implementation string.
      compile_scc
      direct_product_implementations(fn_implementations): return the direct product of the list of lists of fn_implementations
    generate_implementations(scc, n, children_implementation_str): for each function in the SCC, generate n implementations of each function starting with the implementation string of the SCC's children.
      fn_implementation
    fn_implementation(fn_node, n): prompt the language model to generate n implementations of a function
      generate_prompt(fn_node): first prepend a string with all descriptions, names, arguments, and returns of fn_node's direct children, in a style idiomatic for the target language. then, add fn_node's description and function signature.
    solve_constraints(scc, fn_implementations, n, allow_autofill, allow_autodecomp): taking the provided constraints of each function in the scc, evaluate a shuffled list of the direct product of implementations with the constraints until one passes all of them
      generate_constraints(fn_node): translate each of the constraints into an evaluation string idiomatic to the target language
      eval_str(scc, implementation_str, allow_autofill): evaluate an implementation including constraints by running it in a target-language executor. if allow_autofill and the execution fails due to an undefined reference, attempt autofill
        exec_implementation(implementation_str): run the implementation, including constraints/tests, in a target-language-specific executor, returning whether it was successful
        attempt_autofill(scc, implementation_str, undefined_fn_use_example): create a new function node for the referenced function, then re-attempt to execute autofill
          add_undefined_fn(scc, implementation_str, undefined_fn_caller, undefined_fn_use_example): create a new function node for the undefined function as a child of the function which calls it and add it to the scc and implementation string. prompt the language model with the usage example as the description to generate a set of implementations.
            fn_implementation
          eval_str
      on_fail(scc, scc_graph, allow_autofill, allow_autodecomp): if allowing autodecomposition, attempt to decompose. otherwise, raise an error highlighting the scc which could not be compiled
        attempt_autodecomp(scc, scc_graph, allow_autofill, allow_autodecomp): prompt the language model to decompose each unimplemented function node.
          prompt_model(fn_node): prompt the language model, asking it to generate a "fn_name(arg): desc" for each subfunction necessary to implement the function node. add those functions to the scc, including a set of possible implementations for each.
            fn_implementation
          compile_scc
        raise_error(scc): raise an error that Parsel could compile the scc
\end{lstlisting}
\caption{Longer pseudocode of Parsel, including automatic infilling and automatic decomposition.}
\label{fig:parselpseudo}
\end{figure*}

\clearpage
\newpage

\section{Parsel Overview (Detailed)}
\label{parseldetailed}
We include a more detailed figure outlining Parsel.

\begin{figure*}[h]
\centering
\includegraphics[width=0.9\textwidth]{figures/fig0.pdf}
\caption{\textbf{Parsel overview (detailed)}.}
\label{fig:detailed=overview}
\vspace{-9px}
\end{figure*}

\section{Lisp Interpreter}
\label{lisp}
We include the Parsel code for a minimal Lisp interpreter.

\begin{figure*}
\begin{lstlisting}[basicstyle=\fontsize{6}{8}\selectfont\ttfamily]
An env is a dictionary of {'var':val} pairs, with a link to its outer environment in env['_outer'].
A procedure is a lambda expression, with parms, body, and env which calls eval_exp on the body.
#*#*#
evaluate_program(program): Initialize a standard environment. Parse and evaluate a list of expressions, returning the final result.
['(define square (lambda (r) (* r r)))', '(square 3)'] -> 9
  get_env(parms, args, env=None): Return a new env inside env with parms mapped to their corresponding args, and env as the new env's outer env.
  [], [] -> {'_outer': None}
  ['a'], [1] -> {'a': 1, '_outer': None}
  standard_env(includes=['math','ops','simple_math']): An environment with some Scheme standard procedures. Start with an environment and update it with standard functions.
  [] -> {'_outer': None}
    get_math(): Get a dictionary mapping math library function names to their functions.
    get_ops(): Get a dictionary mapping operator symbols to their functions: +, -, *, /, >, <, >=, <=, =.
    get_simple_math(): Get a dictionary mapping 'abs', 'min', 'max', 'not', 'round' to their functions.
    apply_fn_dict_key(fn_dict_generator, key, args_list): Return the value of fn_dict_generator()[key](*args_list) in standard_env.
    get_math, 'sqrt', [4] -> 2.0
    get_ops, '+', [1, 2] -> 3
    get_simple_math, 'abs', [-1] -> 1
      get_math
      get_ops
      get_simple_math
  parse_and_update(expression, env): Parse an expression, return the result.
  "(+ 1 (* 2 3))", {'+': (lambda x, y: x + y), '*': (lambda x, y: x * y), '_outer': None} -> 7
    eval_exp(x, env): Evaluate an expression in an environment and return the result. Check if x is a list, a string, or neither, and call the corresponding function.
    1, {'_outer': None} -> 1
      find(env, var): Find the value of var in the innermost env where var appears.
      {'a':4, '_outer':None}, 'a' -> 4
      {'_outer':{'a':4, '_outer':None}}, 'a' -> 4
      {'a':3, '_outer':{'a':4, '_outer':None}}, 'a' -> 3
      string_case(x, env): Return find(env, x).
      'a', {'a':4, '_outer':None} -> 4
        find
      list_case(x, env): Handle the function specified by the first value of x. Handle the first value of x being quote, if, define, set!, lambda, or otherwise. Return the result.
      ['quote', 'a'], {'_outer': None} -> 'a'
      ['if', True, 1, 2], {'_outer': None} -> 1
      ['define', 'a', 1], {'_outer': None} -> None
        get_procedure(parms, body, env): Return a procedure which evaluates body in a new environment with parms bound to the args passed to the procedure (in the same order as parms).
          eval_procedure(parms, body, env, args): Gets a procedure and returns the result of evaluating proc(*args) in env. Should not be called directly.
          ['r'], ['*', 'pi', ['*', 'r', 'r']], {'*': (lambda x, y: x * y), 'pi': 3, '_outer': None}, [1] -> 3
            get_procedure
            get_env
            eval_exp
        otherwise_case(x, env): Get the procedure by evaluating the first value of x. Then, evaluate the arguments and apply the procedure to them. Return the result.
        ['+', 1, 2], {'+': (lambda x, y: x + y), '_outer': None} -> 3
          eval_exp
        eval_exp
      not_list_case(x, env): Return x
      1, {} -> 1
    parse(program): Read a Scheme expression from a string.
    '(1 + (2 * 3))' -> [1, '+', [2, '*', 3]]
      tokenize(s): Convert a string into a list of tokens, including parens.
      "1 + 2" -> ['1', '+', '2']
      "1 + (2 * 3)" -> ['1', '+', '(', '2', '*', '3', ')']
      read_from_tokens(tokens): Translate tokens to their corresponding atoms, using parentheses for nesting lists.
      ['(', '1', '+', '(', '2', '*', '3', ')', ')'] -> [1, '+', [2, '*', 3]]
        atom(token): Numbers become numbers; every other token is a string.
        "1" -> 1
        "a" -> "a"
        "1.2" -> 1.2
    nested_list_to_str(exp): Convert a nested list into a string with nesting represented by parentheses.
    1 -> "1"
    [1, '+', [2, '*', 3]] -> "(1 + (2 * 3))"
\end{lstlisting}
\caption{Full Lisp interpreter implementation in Parsel, including constraints.}
\label{fig:lispinterpreter}
\end{figure*}

\clearpage
\newpage

\section{Case Study}

We include a simple example function we could not generate with Codex \citep{chen2021evaluating} directly from the top-level description in Figure~\ref{gameoflife}.  The corresponding Python code (included in the appendix) is exactly 58 non-whitespace lines of code, including 17 lines of comments (3 corresponding to the descriptions), 2 asserts, and 39 lines implementing the three functions described as well as an automatically generated \lstinline{get_number_of_active_cells_around_cell} function. In fact, using automatic decomposition, as discussed in Subsection~\ref{autodecomp}, it is not necessary to provide any of the function descriptions besides the top one. The model is (unsurprisingly) able to understand that \lstinline{game_of_life_inversion_iteration} can be broken down into \lstinline{invert_array} and \lstinline{game_of_life_iteration}.

\begin{figure*}[h]
\begin{lstlisting}
game_of_life_inversion_iteration(array_at_time_t): Takes a board and returns the next iteration of the game of life, but with all values flipped
[[0,0,1],[1,0,0],[1,0,0]] -> [[1,1,1],[1,0,1],[1,1,1]]
[[0,1,0,0],[1,0,1,0],[1,0,0,1],[0,1,1,0]] -> [[1,0,1,1],[0,1,0,1],[0,1,1,0],[1,0,0,1]]
    game_of_life_iteration(array_at_time_t) -> array_at_time_t_plus_1: Takes a board with active and inactive cells as a list of lists and returns the next iteration of the game of life
    array_inversion(array) -> inverted_array: Invert a square array by flipping 0's and 1's
\end{lstlisting}
\vspace{-8px}
\caption{An example Parsel program for Python that takes in a list of lists representing a state of Conway's game of life \citep{games1970fantastic} and returns the next state, with all the values inverted.}
\label{gameoflife}
\vspace{-12px}
\end{figure*}

\section{Parsel Prompts}
\label{parselprompts}

\begin{figure*}[h]
\begin{lstlisting}
# Description: given a list of lists representing the cost of each edge, return an adjacency matrix corresponding to the minimum spanning true.
def minimum_spanning_tree(cost_matrix):
\end{lstlisting}
\caption{Codex Prompt for an example leaf node}
\end{figure*}

\begin{figure*}[h]
\begin{lstlisting}
# Description: given a list of lists representing the cost of building a road between any two cities, and a list representing the cost of building an airport in a city, return a new cost matrix with a new node corresponding to the sky.
# Signature: sky_city_cost(city_road_cost, city_airport_cost)
from helpers import sky_city_cost

# Description: given a list of lists representing the cost of each edge, return an adjacency matrix corresponding to the minimum spanning true.
# Signature: minimum_spanning_tree(cost_matrix)
from helpers import minimum_spanning_tree

# Description: given a list of lists representing an adjacency matrix, return a list of the nodes connected to the final node. However, if only one node is connected to the final node, return an empty list.
# Signature: final_node_connectors(adjacency_matrix)
from helpers import final_node_connectors

# Description: given a matrix representing the cost of building a road between any two cities, and a list representing the cost of building an airport in a city (where any two cities with airports are connected), return a list of the cities that should have airports built in them to minimize the total cost of building roads and airports such that all cities are connected. The list should be sorted in ascending order.
# Uses: sky_city_cost, minimum_spanning_tree, final_node_connectors
def select_airport_cities(city_road_cost, city_airport_cost):
\end{lstlisting}
\caption{Codex Prompt for an example merge node}
\end{figure*}

\begin{figure*}[h]
\begin{lstlisting}
# Reviewer:
# Please explain the above function in one sentence with as much detail as possible.
# In your one-sentence description, specify the range and domain of your function precisely.
# Your description should be clear enough that someone could reimplement the function from it.
# Author:
# Sounds good, here's my one-sentence explanation of {name}:
# {name}
\end{lstlisting}
\caption{Prompt format to generate descriptions for backtranslation}
\end{figure*}

\clearpage
\newpage

\section{APPS Backtranslation}
\label{appendixbacktranslation}

\subsection{Backtranslation / decompiling.}
We anticipate that there are many programs that LLMs can implement by first generating Parsel code. But, as Parsel is a new framework, while language models can sometimes generate Parsel programs with few-shot prompts, it is not a syntax they have previously encountered. Thus, we may want to use existing code in other languages to construct datasets of Parsel programs from other languages. This requires us to first extract the call graph from the code, generate descriptions for each of the functions, and then generate Parsel programs from the graph. This call graph representation is convenient, so it is useful to have a bidirectional method to produce a graph from Parsel code and to produce Parsel code from the graph.

We filter the dataset to problems with starter code (providing the name of the evaluated function) and unit tests (provided as input-output pairs). For those tasks, we select solutions that define and call at least three functions, with at least one over 4 lines long and none over 15 lines. 

As a proof of concept, we show 10 Parsel solutions which we could automatically generate from the APPS solutions. We generated the descriptions by prompting Codex to explain each function and its inputs and outputs. From this, we use backtranslation to attempt to implement these solutions in Python. We then verify that they are correct by applying the original unit tests as constraints on the root function. As mentioned in Section~\ref{intro}, the Parsel code is substantially shorter in terms of lines of code. We include these in Appendix~\ref{appendixbacktranslation}.

\subsection{Examples}
We exclude the asserts in these examples for brevity - they correspond to those in the original dataset.

\begin{figure*}[h]
\begin{lstlisting}
longest_palindrome(s): longest_palindrome takes a string s and returns the longest palindrome in s.
  is_palindrome(s): is_palindrome returns True if the string s is the same forwards and backwards, and False otherwise.
  check(li, ri, s): check takes a string s, a left index li, and a right index ri, and returns the longest palindrome that starts at or before li and ends at or after ri.
    is_palindrome
\end{lstlisting}
\caption{Train Problem 1638, Solution 2}
\end{figure*}

\begin{figure*}[h]
\begin{lstlisting}[language=Python]
# longest_palindrome takes a string s and returns the longest palindrome in s.
def longest_palindrome(s):
    if len(s) <= 1:
        return s
    else:
        longest = s[0]
        for i in range(len(s)):
            for j in range(len(s)):
                if is_palindrome(check(i, j, s)) and len(check(i, j, s)) > len(longest):
                    longest = check(i, j, s)
        return longest

# is_palindrome returns True if the string s is the same forwards and backwards, and False otherwise.
def is_palindrome(s):
    if len(s) <= 1:
        return True
    else:
        return s[0] == s[-1] and is_palindrome(s[1:-1])

# check takes a string s, a left index li, and a right index ri, and returns the longest palindrome that starts at or before li and ends at or after ri.
def check(li, ri, s):
    while li >= 0 and ri < len(s) and s[li] == s[ri]:
        li -= 1
        ri += 1
    return s[li+1:ri]
\end{lstlisting}
\caption{Train Problem 1638, Solution 2}
\end{figure*}

\begin{figure*}
\begin{lstlisting}
case_id(c_str): case_id takes a string and returns a string that is either "kebab", "snake", "camel", or "none" depending on whether the input string is in kebab case, snake case, camel case, or none of the above.
  is_snake(s): is_snake takes a string and returns True if the string is snake_case and False otherwise.
  is_kebab(s): is_kebab takes a string and returns True if the string is a kebab-case string, and False otherwise.
  is_camel(s): is_camel returns True if the string s is not lowercase, does not contain dashes, and does not contain underscores.
\end{lstlisting}
\caption{Train Problem 2892, Solution 7}
\end{figure*}

\begin{figure*}
\begin{lstlisting}[language=Python]
# case_id takes a string and returns a string that is either "kebab", "snake", "camel", or "none" depending on whether the input string is in kebab case, snake case, camel case, or none of the above.
def case_id(c_str):
    if is_snake(c_str) == True:
        return "snake"
    elif is_kebab(c_str) == True:
        return "kebab"
    elif is_camel(c_str) == True:
        return "camel"
    else:
        return "none"

# is_snake takes a string and returns True if the string is snake_case and False otherwise.
def is_snake(s):
    if s[0].isalpha() and s[0].islower() and len(s) > 1:
        for char in s:
            if char.isalpha():
                if char.isupper():
                    return False
            elif char == '_':
                pass
            else:
                return False
        return True
    else:
        return False

# is_kebab takes a string and returns True if the string is a kebab-case string, and False otherwise.
def is_kebab(s):
    # if s is empty, False
    if s == '':
        return False
    # if s is not a string, False
    if type(s) != str:
        return False
    # if s is not lowercase, False
    if s != s.lower():
        return False
    # if s contains anything other than a-z or -, False
    for c in s:
        if not (c.isalpha() or c == '-'):
            return False
    # if s contains a - at the beginning or end, False
    if s[0] == '-' or s[-1] == '-':
        return False
    # if s contains more than one - in a row, False
    for i in range(len(s)-1):
        if s[i] == '-' and s[i+1] == '-':
            return False
    # otherwise, True
    return True


# is_camel returns True if the string s is not lowercase, does not contain dashes, and does not contain underscores.
def is_camel(s):
    return s != s.lower() and s.find('_') == -1 and s.find('-') == -1
\end{lstlisting}
\caption{Train Problem 2892, Solution 7}
\end{figure*}

\begin{figure*}
\begin{lstlisting}
find_2nd_largest(arr): find_2nd_largest takes a list of numbers and returns the second largest number in the list.
  filter_int(arr): filter_int takes an array of integers and returns an array of integers.
  sec_big(a, b): sec_big takes two numbers and returns the smaller of the two.
  sort(arr): sort takes an array of numbers and returns a sorted array of numbers.
  is_diff(arr): is_diff takes an array of numbers and returns True if there are any two numbers in the array that are different, and False if all the numbers in the array are the same.
\end{lstlisting}
\caption{Train Problem 3090, Solution 9}
\end{figure*}

\begin{figure*}
\begin{lstlisting}[language=Python]
# find_2nd_largest takes a list of numbers and returns the second largest number in the list.
def find_2nd_largest(arr):
    if len(arr) == 1:
        return None
    arr = filter_int(arr)
    if len(arr) == 0:
        return None
    if len(arr) == 1:
        return arr[0]
    arr = sort(arr)
    if is_diff(arr) == False:
        return None
    res = arr[len(arr) - 2]
    return res

# filter_int takes an array of integers and returns an array of integers.
def filter_int(arr):
    return list(filter(lambda x: type(x) == int, arr))

# sec_big takes two numbers and returns the smaller of the two.
def sec_big(a, b):
    if a > b:
        return b
    else:
        return a

# sort takes an array of numbers and returns a sorted array of numbers.
def sort(arr):
    return sorted(arr)

# is_diff takes an array of numbers and returns True if there are any two numbers in the array that are different, and False if all the numbers in the array are the same.
def is_diff(arr):
    for i in range(len(arr) - 1):
        if arr[i] != arr[i + 1]:
            return True
    return False
\end{lstlisting}
\caption{Train Problem 3090, Solution 9}
\end{figure*}

\begin{figure*}
\begin{lstlisting}
happy_numbers(n): happy_numbers takes a positive integer n and returns a list of all the happy numbers between 1 and n, inclusive.
  _is_happy_number(number): _is_happy_number takes a positive integer and returns True if the number is a happy number, False otherwise.
    _sum_squares(number): _sum_squares takes a non-negative integer and returns the sum of the squares of its digits.
\end{lstlisting}
\caption{Train Problem 3140, Solution 7}
\end{figure*}

\begin{figure*}
\begin{lstlisting}[language=Python]
# happy_numbers takes a positive integer n and returns a list of all the happy numbers between 1 and n, inclusive.
def happy_numbers(n):
    return [i for i in range(1, n + 1) if _is_happy_number(i)]

# _is_happy_number takes a positive integer and returns True if the number is a happy number, False otherwise.
def _is_happy_number(number):
    # We want to make sure that the number is positive
    if number < 0:
        return False
    # We want to make sure that the number is not 1
    if number == 1:
        return True
    # We want to keep track of the numbers we have used
    used_numbers = []
    # We want to loop through the number
    while number not in used_numbers:
        # We want to add the number to the list of used numbers
        used_numbers.append(number)
        # We want to find the sum of the squares of the digits of the number
        number = _sum_squares(number)
        # We want to check if the number is one
        if number == 1:
            # We want to return True
            return True
    # We want to return False
    return False

# _sum_squares takes a non-negative integer and returns the sum of the squares of its digits.
def _sum_squares(number):
    if number < 0:
        raise ValueError
    else:
        number = str(number)
        sum = 0
        for i in number:
            sum += int(i) ** 2
        return sum
\end{lstlisting}
\caption{Train Problem 3140, Solution 7}
\end{figure*}

\begin{figure*}
\begin{lstlisting}
am_i_wilson(n): am_i_wilson(n) returns True if n is a prime number between 2 and 563, inclusive, and False otherwise.
  is_prime(n): is_prime takes a positive integer n and returns True if n is prime and False otherwise.
  factorial(n): factorial(n) returns the product of all integers from 1 to n, inclusive.
\end{lstlisting}
\caption{Train Problem 3229, Solution 26}
\end{figure*}

\begin{figure*}
\begin{lstlisting}[language=Python]
# am_i_wilson(n) returns True if n is a prime number between 2 and 563, inclusive, and False otherwise.
def am_i_wilson(n):
    if is_prime(n) and 2 <= n and n <= 563:
        return (factorial(n-1) + 1) else:
        return False

# is_prime takes a positive integer n and returns True if n is prime and False otherwise.
def is_prime(n):
    if n == 2:
        return True
    if n == 3:
        return True
    if n return False
    if n return False
    i = 5
    w = 2
    while i * i <= n:
        if n return False
        i += w
        w = 6 - w
    return True


# factorial(n) returns the product of all integers from 1 to n, inclusive.
def factorial(n):
    if n == 0:
        return 1
    else:
        return n * factorial(n-1)
\end{lstlisting}
\caption{Train Problem 3229, Solution 26}
\end{figure*}

\begin{figure*}
\begin{lstlisting}
am_i_wilson(n): am_i_wilson takes a positive integer n and returns True if n is prime and (n-1)! + 1 is divisible by n^2, and False otherwise.
  fac(n): fac is a function that takes a positive integer n and returns the product of all integers from 1 to n.
  is_prime(n): is_prime takes a positive integer n and returns True if n is prime and False otherwise.
\end{lstlisting}
\caption{Train Problem 3229, Solution 71}
\end{figure*}

\begin{figure*}
\begin{lstlisting}[language=Python]
# am_i_wilson takes a positive integer n and returns True if n is prime and (n-1)! + 1 is divisible by n^2, and False otherwise.
def am_i_wilson(n):
    return is_prime(n) and (fac(n-1) + 1) 

# fac is a function that takes a positive integer n and returns the product of all integers from 1 to n.
def fac(n):
    if n == 0:
        return 1
    return n * fac(n-1)
# is_prime takes a positive integer n and returns True if n is prime and False otherwise.
def is_prime(n):
    if n == 2:
        return True
    elif n < 2 or n return False
    for i in range(3, int(n**0.5)+1, 2):
        if n return False
    return True
\end{lstlisting}
\caption{Train Problem 3229, Solution 71}
\end{figure*}

\begin{figure*}
\begin{lstlisting}
evil(n): evil(n) returns "It's Evil!" if n is an evil number, otherwise it returns "It's Odious!" The range of evil is the set of all integers, and the domain is the set of all strings.
  evilometer(n): evilometer(n) is a generator that yields n times if n is even, and yields n // 2 times if n is odd.
\end{lstlisting}
\caption{Train Problem 3321, Solution 33}
\end{figure*}

\begin{figure*}
\begin{lstlisting}[language=Python]
# evil(n) returns "It's Evil!" if n is an evil number, otherwise it returns "It's Odious!" The range of evil is the set of all integers, and the domain is the set of all strings.
def evil(n):
    gen = evilometer(n)
    if sum(list(gen)) return "It's Evil!"
    else:
        return "It's Odious!"

# evilometer(n) is a generator that yields n times if n is even, and yields n // 2 times if n is odd.
def evilometer(n):
    while n:
        yield n
        if n n //= 2
        else:
            n -= 1
\end{lstlisting}
\caption{Train Problem 3321, Solution 33}
\end{figure*}

\begin{figure*}
\begin{lstlisting}
circular_prime(number): circular_prime takes a number and returns True if it is a circular prime, and False otherwise.
  rotate(l, n): rotate takes a list and an integer and returns a new list with the last n elements of the original list moved to the front.
  is_prime(n): is_prime returns True if n is a prime number, and False otherwise.
\end{lstlisting}
\caption{Train Problem 3368, Solution 5}
\end{figure*}

\begin{figure*}
\begin{lstlisting}[language=Python]
# circular_prime takes a number and returns True if it is a circular prime, and False otherwise.
def circular_prime(number):
    if is_prime(number) == False:
        return False
    else:
        for i in range(len(str(number))-1):
            number = rotate(str(number), 1)
            if is_prime(int(number)) == False:
                return False
        return True

# rotate takes a list and an integer and returns a new list with the last n elements of the original list moved to the front.
def rotate(l, n):
    return l[-n:] + l[:-n]

# is_prime returns True if n is a prime number, and False otherwise.
def is_prime(n):
    if n < 2:
        return False
    for i in range(2, int(n ** 0.5) + 1):
        if n return False
    return True
\end{lstlisting}
\caption{Train Problem 3368, Solution 5}
\end{figure*}

\begin{figure*}
\begin{lstlisting}
circular_prime(n): circular_prime(n) returns True if n is a circular prime, and False otherwise.
  is_prime(n): is_prime takes a number n and returns True if n is prime and False if n is not prime.
  circul_num(n, l): circul_num takes an integer n and an integer l, and returns the integer that results from moving the first digit of n to the end of n, and then padding the result with zeros until it has length l.
\end{lstlisting}
\caption{Train Problem 3368, Solution 6}
\end{figure*}

\begin{figure*}
\begin{lstlisting}[language=Python]
# circular_prime(n) returns True if n is a circular prime, and False otherwise.
def circular_prime(n):
    # Check if n is a prime number.
    if not is_prime(n):
        return False
    else:
        # Get the length of n.
        length = len(str(n))
        # Get the first digit of n.
        first_digit = str(n)[0]
        # Get the number of rotations.
        rotations = length
        # Rotate n.
        while rotations > 0:
            # Get the new number.
            n = circul_num(n, length)
            # Check if n is a prime number.
            if not is_prime(n):
                return False
            # Decrement the number of rotations.
            rotations -= 1
        return True
# is_prime takes a number n and returns True if n is prime and False if n is not prime.
def is_prime(n):
    if n == 2 or n == 3:
        return True
    if n return False
    for i in range(3, int(n**0.5)+1, 2):   # only odd numbers
        if n return False
    return True

# circul_num takes an integer n and an integer l, and returns the integer that results from moving the first digit of n to the end of n, and then padding the result with zeros until it has length l.
def circul_num(n, l):
    n = str(n)
    digit = n[0]
    n = n[1:] + digit
    n = n.ljust(l, "0")
    return int(n)
\end{lstlisting}
\caption{Train Problem 3368, Solution 6}
\end{figure*}

\begin{figure*}
\begin{lstlisting}
list_squared(m, n): list_squared(m, n) returns a list of lists of integers, where each sublist contains an integer and its sum of squared divisors, and the integers are in the range [m, n] (inclusive).
  divisors_list(num): divisors_list takes a number and returns a list of all the divisors of that number.
  sum_squares(nums): sum_squares takes a list of numbers and returns the sum of the squares of those numbers.
  isSquarable(num): isSquarable takes a number and returns True if the number is a perfect square, and False otherwise.
\end{lstlisting}
\caption{Train Problem 3393, Solution 35}
\end{figure*}

\begin{figure*}
\begin{lstlisting}[language=Python]
# list_squared(m, n) returns a list of lists of integers, where each sublist contains an integer and its sum of squared divisors, and the integers are in the range [m, n] (inclusive).
def list_squared(m, n):
    result = []
    for num in range(m, n + 1):
        divisors = divisors_list(num)
        sum_of_squares = sum_squares(divisors)
        if isSquarable(sum_of_squares):
            result.append([num, sum_of_squares])
    return result
# divisors_list takes a number and returns a list of all the divisors of that number.
def divisors_list(num):
    divisors = []
    for i in range(1, num + 1):
        if num divisors.append(i)
    return divisors


# sum_squares takes a list of numbers and returns the sum of the squares of those numbers.
def sum_squares(nums):
    sum = 0
    for i in range(len(nums)):
        sum += nums[i]**2
    return sum

# isSquarable takes a number and returns True if the number is a perfect square, and False otherwise.
def isSquarable(num):
    root = num ** (1/2)
    if root return True
    else:
        return False
\end{lstlisting}
\caption{Train Problem 3393, Solution 35}
\end{figure*}


\clearpage
\newpage
\section{Compiled Examples}

\begin{figure*}[h]
\begin{lstlisting}[language=Python]
# Takes a board and returns the next iteration of the game of life, but with all values flipped
def game_of_life_inversion_iteration(array_at_time_t):
    # Your code here
    #return game_of_life_iteration(invert_array(array_at_time_t))
    return invert_array(game_of_life_iteration(array_at_time_t))

# Takes a board and returns the next iteration of the game of life
def invert_array(array_at_time_t):
    return [list(map(lambda x: 1-x, row)) for row in array_at_time_t]

# Takes a board and returns the board with all values flipped
def game_of_life_iteration(array_at_time_t):
    # The array that will be returned
    array_at_time_t_plus_1 = []

    # Iterate through the rows of the array
    for i in range(0, len(array_at_time_t)):
        # The array that will contain the next row
        next_row = []

        # Iterate through the columns of the array
        for j in range(0, len(array_at_time_t[i])):
            # The number of neighbors
            num_neighbors = 0

            # Iterate through the neighbors of the cell
            for k in range(-1, 2):
                for l in range(-1, 2):
                    # Don't count the cell itself
                    if k == 0 and l == 0:
                        continue

                    # Check if the neighbor is valid
                    if i + k >= 0 and i + k < len(array_at_time_t) and j + l >= 0 and j + l < len(array_at_time_t[i]):
                        # If the neighbor is alive, increment the number of neighbors
                        if array_at_time_t[i + k][j + l] == 1:
                            num_neighbors += 1

            # If the cell is alive, check if it should die
            if array_at_time_t[i][j] == 1:
                if num_neighbors < 2 or num_neighbors > 3:
                    next_row.append(0)
                else:
                    next_row.append(1)
            # If the cell is dead, check if it should become alive
            else:
                if num_neighbors == 3:
                    next_row.append(1)
                else:
                    next_row.append(0)

        # Add the next row to the array
        array_at_time_t_plus_1.append(next_row)

    # Return the next array
    return array_at_time_t_plus_1

assert game_of_life_inversion_iteration([[0, 0, 1], [1, 0, 0], [1, 0, 0]]) == [[1, 1, 1], [1, 0, 1], [1, 1, 1]]
assert game_of_life_inversion_iteration([[0, 1, 0, 0], [1, 0, 1, 0], [1, 0, 0, 1], [0, 1, 1, 0]]) == [[1, 0, 1, 1], [0, 1, 0, 1], [0, 1, 1, 0], [1, 0, 0, 1]]
\end{lstlisting}
\caption{Compilation of the program taking Conway's game of life \citep{games1970fantastic} and returning the next state, with the values inverted. In this case, we use automatic decomposition to generate the two subfunctions of \lstinline{game_of_life_iteration}.}
\label{pygameoflife}
\end{figure*}

\begin{figure*}[h]
\begin{lstlisting}[language=Python]
# Takes a board with active and inactive cells and returns the next iteration of the game of life, but with all the values flipped
def game_of_life_inversion_iteration(array_at_time_t):
    return array_inversion(game_of_life_iteration(array_at_time_t))

# Takes a board with active and inactive cells as a list of lists and returns the next iteration of the game of life
def game_of_life_iteration(array_at_time_t):
    array_at_time_t_plus_1 = []
    for row in range(len(array_at_time_t)):
        array_at_time_t_plus_1.append([])
        for column in range(len(array_at_time_t[row])):
            array_at_time_t_plus_1[row].append(0)
    for row in range(len(array_at_time_t)):
        for column in range(len(array_at_time_t[row])):
            if array_at_time_t[row][column] == 1:
                if count_neighbors(array_at_time_t, row, column) < 2:
                    array_at_time_t_plus_1[row][column] = 0
                elif count_neighbors(array_at_time_t, row, column) > 3:
                    array_at_time_t_plus_1[row][column] = 0
                else:
                    array_at_time_t_plus_1[row][column] = 1
            else:
                if count_neighbors(array_at_time_t, row, column) == 3:
                    array_at_time_t_plus_1[row][column] = 1
    return array_at_time_t_plus_1

# Invert a square array by replacing all 0's with 1's and vice versa
def array_inversion(array):
    inverted_array = []
    for i in range(len(array)):
        inverted_array.append([])
        for j in range(len(array[i])):
            inverted_array[i].append(1 - array[i][j])
    return inverted_array

# 
def count_neighbors(array_at_time_t, row, column):
    count = 0
    for i in range(row-1, row+2):
        for j in range(column-1, column+2):
            if i == row and j == column:
                continue
            if i < 0 or j < 0:
                continue
            if i >= len(array_at_time_t) or j >= len(array_at_time_t[0]):
                continue
            if array_at_time_t[i][j] == 1:
                count += 1
    return count


assert game_of_life_inversion_iteration([[0, 0, 1], [1, 0, 0], [1, 0, 0]]) == [[1, 1, 1], [1, 0, 1], [1, 1, 1]]
assert game_of_life_inversion_iteration([[0, 1, 0, 0], [1, 0, 1, 0], [1, 0, 0, 1], [0, 1, 1, 0]]) == [[1, 0, 1, 1], [0, 1, 0, 1], [0, 1, 1, 0], [1, 0, 0, 1]]

assert game_of_life_iteration([[0, 0, 1], [1, 0, 0], [1, 0, 0]]) == [[0, 0, 0], [0, 1, 0], [0, 0, 0]]
assert game_of_life_iteration([[0, 1, 0, 0], [1, 0, 1, 0], [1, 0, 0, 1], [0, 1, 1, 0]]) == [[0, 1, 0, 0], [1, 0, 1, 0], [1, 0, 0, 1], [0, 1, 1, 0]]

assert array_inversion([[1]]) == [[0]]
assert array_inversion([[0, 1], [1, 0]]) == [[1, 0], [0, 1]]
\end{lstlisting}
\caption{Compilation of the program taking Conway's game of life \citep{games1970fantastic} and returning the next state, with the values inverted. In this case, we use automatic infilling to generate the \lstinline{count_neighbors} function.}
\label{pygameoflife2}
\end{figure*}

\begin{figure*}[h]
\begin{lstlisting}[language=Python]
# Calls base_case if 1, otherwise recursion_rule
def collatz_recursion(num, cur_list=list()):
    if num == 1:
        return base_case(num, cur_list)
    else:
        return recursion_rule(num, cur_list)

# Returns the list with the number appended to it
def base_case(num, cur_list):
    cur_list.append(num)
    return cur_list


# Add num to list, collatz with 3n + 1 if odd or n / 2 if even
def recursion_rule(num, cur_list):
    cur_list.append(num)
    if num return collatz_recursion(num / 2, cur_list)
    else:
        return collatz_recursion((3 * num) + 1, cur_list)


assert collatz_recursion(19) == [19, 58, 29, 88, 44, 22, 11, 34, 17, 52, 26, 13, 40, 20, 10, 5, 16, 8, 4, 2, 1]
\end{lstlisting}
\caption{Compilation of the program generating a list corresponding to the Collatz conjecture.}
\label{pycollatz}
\end{figure*}

\begin{figure*}[h]
\label{leancommute}
\begin{lstlisting}[escapeinside={(*}{*)}, keywords = {lemma, Prop, begin, end, exact, intro, cases, apply}]
-- if p (**) q, then q (**) p
lemma p_q_implies_q_p(p q: Prop):

    p (**) q (**) q (**) p :=
begin
    intro h,
    cases h with hp hq,
    split,
        exact hq,
        exact hp,
end

-- Description: if p (**) q, then q (**) p
-- if q (**) p, then p (**) q
lemma q_p_implies_p_q(p q: Prop):

    (q (**) p) (**) (p (**) q) :=
begin
  intro h,
  split,
    exact h.right,
    exact h.left,
end

/-
  Theorem:
    If q (**) p, then p (**) q
-/
-- the and operator is commutative
lemma and_commute(p q: Prop):
  (p (**) q (**) q (**) p) (**) (q (**) p (**) p (**) q) :=

begin
  apply and.intro,
  { apply p_q_implies_q_p },
  { apply q_p_implies_p_q }
end

-- Description: if p (**) q, then p
-- Signature: p_and_q_implies_p(p q: Prop)

-- show (p (**) q (**) q (**) p) (**) (q (**) p (**) p (**) q)
\end{lstlisting}
\caption{Generated proof of \lstinline{and_commute}. We trim the post-proof comments elsewhere.}
\end{figure*}


\begin{figure*}[h]
\label{airports}
\begin{lstlisting}[escapeinside={(*}{*)}, basicstyle=\tiny\selectfont\ttfamily,language=Python]
# given a list of lists representing the cost of building a road between any two cities, and a list representing the cost of building an airport in a city, return a new cost matrix with a new node corresponding to the sky.
def sky_city_cost(city_road_cost, city_airport_cost):
    """
    :param city_road_cost: list of lists representing cost of road between any two cities
    :param city_airport_cost: list representing cost of an airport in a city
    :return: new cost matrix with a new node corresponding to the sky
    """
    # add new node for sky to cost matrix
    num_cities = len(city_road_cost)
    sky_city_cost = [[0 for _ in range(num_cities + 1)] for _ in range(num_cities + 1)]
    for i in range(num_cities):
        for j in range(num_cities):
            sky_city_cost[i][j] = city_road_cost[i][j]
    for i in range(num_cities):
        sky_city_cost[i][-1] = city_airport_cost[i]
        sky_city_cost[-1][i] = city_airport_cost[i]
    return sky_city_cost

# given a list of lists representing the cost of each edge, return an adjacency matrix corresponding to the minimum spanning true.
def minimum_spanning_tree(cost_matrix):
    # This is a list of the vertices that have been added to the MST
    visited = [0]
    # This is a list of the vertices that have not been added to the MST
    unvisited = [i for i in range(1, len(cost_matrix))]
    # This is a list of edges that are part of the MST
    edges = []
    # This is the adjacency matrix corresponding to the MST
    adjacency_matrix = [[0 for i in range(len(cost_matrix))] for j in range(len(cost_matrix))]
    while len(unvisited) > 0:
        # Get the index of the minimum edge
        min_edge_index = -1
        min_edge_value = float('inf')
        for i in range(len(visited)):
            for j in range(len(unvisited)):
                if cost_matrix[visited[i]][unvisited[j]] < min_edge_value:
                    min_edge_index = (visited[i], unvisited[j])
                    min_edge_value = cost_matrix[visited[i]][unvisited[j]]
        # Add the minimum edge to our MST
        edges.append(min_edge_index)
        # Add the unvisited vertex to the list of visited vertices
        visited.append(min_edge_index[1])
        # Remove the unvisited vertex from the list of unvisited vertices
        unvisited.remove(min_edge_index[1])
    # Add edges to the adjacency matrix
    for edge in edges:
        adjacency_matrix[edge[0]][edge[1]] = 1
        adjacency_matrix[edge[1]][edge[0]] = 1
    return adjacency_matrix

# given a list of lists representing an adjacency matrix, return a list of the nodes connected to the final node. However, if only one node is connected to the final node, return an empty list.
def final_node_connectors(adjacency_matrix):
    final_node = len(adjacency_matrix) - 1
    final_node_connectors = []
    for i in range(len(adjacency_matrix) - 1):
        if adjacency_matrix[i][final_node] == 1:
            final_node_connectors.append(i)
    if len(final_node_connectors) == 1:
        return []
    return final_node_connectors

# given a matrix representing the cost of building a road between any two cities, and a list representing the cost of building an airport in a city (where any two cities with airports are connected), return a list of the cities that should have airports built in them to minimize the total cost of building roads and airports such that all cities are connected. The list should be sorted in ascending order.
def select_airport_cities(city_road_cost, city_airport_cost):
    cost_matrix = sky_city_cost(city_road_cost, city_airport_cost)
    adjacency_matrix = minimum_spanning_tree(cost_matrix)
    return final_node_connectors(adjacency_matrix)

assert repr(str(select_airport_cities([[0, 3, 3], [3, 0, 3], [3, 3, 0]], [0, 0, 0]))) == repr(str([0, 1, 2]))
assert repr(str(select_airport_cities([[0, 3, 3], [3, 0, 3], [3, 3, 0]], [10, 10, 10]))) == repr(str([]))
assert repr(str(select_airport_cities([[0, 10, 3], [10, 0, 11], [3, 11, 0]], [1, 4, 5]))) == repr(str([0, 1]))

assert repr(str(sky_city_cost([[1, 2, 3], [1, 2, 3], [1, 2, 3]], [4, 5, 6]))) == repr(str([[1, 2, 3, 4], [1, 2, 3, 5], [1, 2, 3, 6], [4, 5, 6, 0]]))

assert repr(str(minimum_spanning_tree([[0, 1, 3, 4], [1, 0, 2, 100], [3, 2, 0, 5], [4, 100, 5, 0]]))) == repr(str([[0, 1, 0, 1], [1, 0, 1, 0], [0, 1, 0, 0], [1, 0, 0, 0]]))

assert repr(str(final_node_connectors([[0, 1, 0, 1], [1, 0, 1, 0], [0, 1, 0, 0], [1, 0, 0, 0]]))) == repr(str([]))
assert repr(str(final_node_connectors([[0, 1, 0, 1], [1, 0, 1, 0], [0, 1, 0, 1], [1, 0, 1, 0]]))) == repr(str([0, 2]))
\end{lstlisting}
\caption{Generated solution for \lstinline{select_airport_cities}.}
\end{figure*}



\begin{figure*}[h]
\label{pychess}
\begin{lstlisting}[escapeinside={(*}{*)},language=Python]
# chess_game takes a board and returns the winner of the game.
def chess_game(board):
    if weight(board) == 0:
        return 'Draw'
    if weight(board) > 0:
        return 'White'
    if weight(board) < 0:
        return 'Black'

# weight takes a board and returns the weight of the board.
def weight(board):
	weight = 0
	for row in range(len(board)):
		for col in range(len(board[row])):
			if board[row][col] != '.':
				weight += weight_helper(board, row, col, 0)
	return weight

# weight_helper takes a board, a row, a column, and a weight and returns the weight of the board.
def weight_helper(board, row, col, weight):
    if board[row][col] == '.':
        return 0
    elif board[row][col] == 'Q':
        return weight + 9
    elif board[row][col] == 'R':
        return weight + 5
    elif board[row][col] == 'B':
        return weight + 3
    elif board[row][col] == 'N':
        return weight + 3
    elif board[row][col] == 'P':
        return weight + 1
    elif board[row][col] == 'q':
        return weight - 9
    elif board[row][col] == 'r':
        return weight - 5
    elif board[row][col] == 'b':
        return weight - 3
    elif board[row][col] == 'n':
        return weight - 3
    elif board[row][col] == 'p':
        return weight - 1
    else:
        return weight

assert repr(str(chess_game('...QK...\n........\n........\n........\n........\n........\n........\n...rk...'))) == repr('White')
assert repr(str(chess_game('rnbqkbnr\npppppppp\n........\n........\n........\n........\nPPPPPPPP\nRNBQKBNR'))) == repr('Draw')
assert repr(str(chess_game('rppppppr\n...k....\n........\n........\n........\n........\nK...Q...\n........'))) == repr('Black')
assert repr(str(chess_game('....bQ.K\n.B......\n.....P..\n........\n........\n........\n...N.P..\n.....R..'))) == repr('White')
...
\end{lstlisting}
\caption{Generated solution for Problem 368 of the APPS test set, identifying the leader of a chess game from the board.}
\end{figure*}

\clearpage
\section{APPS Decomposition Prompts and Evaluation Hyperparameters}
\label{decomprompts}
We slightly loosen the requirements for Parsel programs generated by language models, treating redundant function definitions as references instead of raising errors. We sample everything with temperature=0.6, except the translations which we sample with temperature=0.2, a presence penalty of 0.1, and a logit bias to prevent it from generating the text ``\lstinline{def}'', as Codex has a tendency to degenerate to producing Python even when prompted with Parsel examples. We allow at most 500 tokens per function, but in practice found that they typically used less than half of them.

 For evaluation, we use a timeout of 0.04 seconds per solution and evaluate at most 100,000 implementations per generated Parsel program. 
 
 For the Codex-only ablation, we allow it to generate at most 1000 tokens, in large part due to the rate limit. In particular, there is a heuristic rate limit that rejects any calls requesting more than 4,000 tokens. As a result, any larger number of samples per problem would prevent batching more than 3 samples at a time.

\begin{figure*}[h] 
\begin{lstlisting}[escapeinside={(*}{*)}, language=Python]
"""An action plan is a list of strings that describes a sequence of steps to accomplish a task, To be correctly parsed, an action plan must be syntactically correct and contain only allowed actions and recognizable simple objects. Allowed actions: 'close' <arg1>, 'cut' <arg1>, 'drink' <arg1>, 'drop' <arg1>, 'eat' <arg1>, 'find' <arg1>, 'grab' <arg1>, 'greet' <arg1>, 'lie on' <arg1>, 'look at' <arg1>, 'open' <arg1>, 'plug in' <arg1>, 'plug out' <arg1>, 'point at' <arg1>, 'pour' <arg1> 'into' <arg2>, 'pull' <arg1>, 'push' <arg1>, 'put' <arg1> 'on' <arg2>, 'put' <arg1> 'in' <arg2>, 'put back' <arg1>, 'take off' <arg1>, 'put on' <arg1>, 'read' <arg1>, 'release', 'rinse' <arg1>, 'run to'  <arg1>, 'scrub' <arg1>, 'sit on' <arg1>, 'sleep', 'squeeze' <arg1>, 'stand up', 'switch off' <arg1>, 'switch on' <arg1>, 'touch' <arg1>, 'turn to' <arg1>, 'type on' <arg1>, 'wake up', 'walk to' <arg1>, 'wash' <arg1>, 'watch' <arg1>, 'wipe' <arg1>. To satisfy the common-sense constraints, each action step in this action plan must not violate the set of its pre-conditions (e.g. the agent cannot grab milk from the fridge before opening it) and post-conditions (e.g. the state of the fridge changes from "closed" to "open" after the agent opens it)."""
#*#*#
task_plan(): return a list of strings that represents an action plan to put a mug on the stall and bread on the desk.
-> "executable"
    put_object_on(object, place): return a list of strings that represents an action plan to put an object in a place. 
    "mug", "stall" -> "executable"
\end{lstlisting} 
\caption{Full Parsel program including header for Fig.  \ref{fig:overall-figure} example, with the \#*\#*\# as the header seperator. Note that we essentially just took the executability definition in \citep{huang2022language} and added the list of available actions. \label{virtualhome_header}}
\end{figure*}

\begin{figure*}[h] 
\begin{lstlisting}[escapeinside={(*}{*)}, language=Python]
"""-----Solution-----

Propose a clever and efficient high-level solution for this problem. Consider all edge cases and failure modes.

Some common strategies include:
Constructive algorithms, Binary search, Depth-first search (DFS) and similar algorithms, Dynamic programming, Bitmasks, Brute force, Greedy algorithms, Graphs, Two pointers, Trees, Geometry, Graph matchings, Hashing, Probabilities, Data structures, Sortings, Games, Number theory, Combinatorics, Divide and conquer, Disjoint set union (DSU), Expression parsing

Write out your reasoning first, and then describe your high-level solution and explain why it is correct.
\"\"\"
Let's think step by step to come up with a clever algorithm."""
\end{lstlisting} 
\caption{High-level sketch prompt for APPS programs}
\end{figure*}

\begin{figure*}[h] 
\begin{lstlisting}[escapeinside={(*}{*)}, language=Python,basicstyle=\fontsize{5}{5}\selectfont\ttfamily]
"""-----Translation-----
# Here is an example calculating the probability of landing on the same character in a random shift of an input string, based on the following problem:
# Vasya and Kolya play a game with a string, using the following rules. Initially, Kolya creates a string s, consisting of small English letters, and uniformly at random chooses an integer k from a segment [0, len(s) - 1]. He tells Vasya this string s, and then shifts it k letters to the left, i.e. creates a new string t = s_k + 1s_k + 2... s_ns_1s_2... s_k. Vasya does not know the integer k nor the string t, but he wants to guess the integer k. To do this, he asks Kolya to tell him the first letter of the new string, and then, after he sees it, open one more letter on some position, which Vasya can choose.
# Vasya understands, that he can't guarantee that he will win, but he wants to know the probability of winning, if he plays optimally. He wants you to compute this probability.
# Note that Vasya wants to know the value of k uniquely, it means, that if there are at least two cyclic shifts of s that fit the information Vasya knowns, Vasya loses. Of course, at any moment of the game Vasya wants to maximize the probability of his win.
\"\"\"
generate_cyclic_shifts(input_str): Calculates the average number of unique characters in the substrings of the input string that start with each character.
  parse_input(input_str): Takes a string and returns the input string
  compute_a_and_letter_pos(input_str): Generates the str_as_number_list and letter_pos lists. str_as_number_list is a list of integers that is used to store the character values of the input string. str_as_number_list is initialized as a list of 0s for twice the length of the input string. The values are calculated by taking the ASCII value of each character in the string and subtracting the ASCII value of the character 'a'. letter_pos is a list of lists, with each sublist containing the indices at which a particular character appears in the input string.
  compute_unique_characters(c, str_as_number_list, letter_pos) -> ans: Calculates the maximum number of unique characters in all substrings (for k=1 to length) that start with the character represented by c. letter_pos is a list of lists, with each sublist containing the indices at which a character appears in the input string. str_as_number_list is a list of integers that is used to store the character values of the input string.
    compute_unique_characters_for_k(c, k, str_as_number_list, letter_pos): Create a counts list of zeros for each of the 26 alphabetical characters. For each i in the sublist of positions of letter_pos[c], increment counts at str_as_number_list[i + k]. Return the number of counts which are exactly one.
  to_output_str(ans, input_str): Returns a string representation of ans divided by the length of the input string.
\"\"\"
(6 lines)

# And here is an example identifying the largest binary number according to the following rules:
# The Little Elephant has an integer a, written in the binary notation. He wants to write this number on a piece of paper.
# To make sure that the number a fits on the piece of paper, the Little Elephant ought to delete exactly one any digit from number a in the binary record. At that a new number appears. It consists of the remaining binary digits, written in the corresponding order (possible, with leading zeroes).
# The Little Elephant wants the number he is going to write on the paper to be as large as possible. Help him find the maximum number that he can obtain after deleting exactly one binary digit and print it in the binary notation.
\"\"\"
largest_binary_number(input_str): Returns the largest binary number that can be made by removing at most one digit from the input string.
  parse_input(input_str): Takes a string and returns the input string
  remove_zero(binary_str): Remove the first zero from the input string.
  to_output_str(bigger_str): Returns the bigger string.
\"\"\"
(4 lines)

# Here is an example of the format applied to identifying the winner of the following game:
# It is so boring in the summer holiday, isn't it? So Alice and Bob have invented a new game to play. The rules are as follows. First, they get a set of n distinct integers. And then they take turns to make the following moves. During each move, either Alice or Bob (the player whose turn is the current) can choose two distinct integers x and y from the set, such that the set doesn't contain their absolute difference |x - y|. Then this player adds integer |x - y| to the set (so, the size of the set increases by one).
# If the current player has no valid move, he (or she) loses the game. The question is who will finally win the game if both players play optimally. Remember that Alice always moves first.
\"\"\"
identify_winner(input_str): Returns the winner of the game.
  parse_input(input_str): Takes a string containing the length on the first line and the integers on the second and returns the list of integers
  num_moves(l): The number of moves is the largest element in the list divided by the greatest common divisor of all elements in the list, minus the length of the list.
    all_gcd(l): Returns the greatest common divisor of all elements in the list
  to_output_str(num_moves): Returns the string 'Alice' if the number of moves is odd and 'Bob' if the number of moves is even
\"\"\"
(5 lines)

# Limak is a little bear who loves to play. Today he is playing by destroying block towers. He built n towers in a row. The i-th tower is made of h_i identical blocks. For clarification see picture for the first sample.
# Limak will repeat the following operation till everything is destroyed.
# Block is called internal if it has all four neighbors, i.e. it has each side (top, left, down and right) adjacent to other block or to the floor. Otherwise, block is boundary. In one operation Limak destroys all boundary blocks. His paws are very fast and he destroys all those blocks at the same time.
# Limak is ready to start. You task is to count how many operations will it take him to destroy all towers.
\"\"\"
destroy_towers(input_str): Returns the number of operations it takes to destroy all towers.
  parse_input(input_str): Takes a string containing the number of towers on the first line and the heights of the towers on the second and returns the list of heights
  side_ones(heights_list): From a list of ints, set the first and last elements to 1 and return the list
  destroy_from_left(side_list): Copy the list and set each each element to the minimum of itself and one more than the element to its left, starting from the second element
  destroy_from_right(side_list): Copy the list and set each each element to the minimum of itself and one more than the element to its right, starting from the second to last element
  min_list(l1, l2): Return a list of the minimum of the corresponding elements of l1 and l2
  to_output_str(min_list): Return the string representation of the maximum element in the list
\"\"\"
(7 lines)

# Alex decided to go on a touristic trip over the country.
# For simplicity let's assume that the country has  cities and  bidirectional roads connecting them. Alex lives in city  and initially located in it. To compare different cities Alex assigned each city a score  which is as high as interesting city seems to Alex.
# Alex believes that his trip will be interesting only if he will not use any road twice in a row. That is if Alex came to city  from city , he may choose as the next city in the trip any city connected with  by the road, except for the city .
# Your task is to help Alex plan his city in a way that maximizes total score over all cities he visited. Note that for each city its score is counted at most once, even if Alex been there several times during his trip.
\"\"\"
max_score(input_str): Simple function returning the maximum score Alex can get.
  parse_input(input_str): Takes a string containing the number of cities and roads on one line, the scores of the cities on the next line, the roads on the next lines besides the last (1-indexed, make 0-indexed), and the starting city on the last line. It returns the city scores, the roads as an edge list, and the starting city.
  get_neighbors(edges): Returns a dictionary of the neighbors of each city, defaulting to an empty set.
  get_degrees_and_leaves(neighbors, root): Returns a dictionary of the degrees of each city, and a set of the leaves (excluding the root).
  remove_leaves(scores, neighbors, degrees, leaves, root): Create a 0-initialized defaultdict of total_extra, and an int of max_extra. Pop leaves until it is empty. Update total_extra and max_extra based on the parent's total_extra vs the leaf's score plus its total_extra, whichever is greater. Return max_extra.
    pop_leaf(neighbors, degrees, leaves, root): Pop off a leaf. Set parent to sole neighbor of the leaf and delete the leaf from the neighbors dictionary. Decrement the parent's degree. If the parent is not the root and has degree 1, add it to the leaves. Return the leaf and parent.
  to_output_str(scores, neighbors, root, max_extra): Returns the string of the maximum score Alex can get. If the root isn't in neighbors, return the score of the root. Otherwise, this is the sum of the scores of the cities left in neighbors, plus the returned encountered max_extra.
\"\"\"
(7 lines)

# Translate the following solution plan into the above format:
{solution_start}{solution_text}

TRANSLATE to Parsel.
\"\"\"
"""
\end{lstlisting} 
\caption{Translation prompt for APPS programs}
\end{figure*}

\clearpage
\newpage
\section{HumanEval Prompts}
\label{humanprompts}
We use the same zero-shot prompt to encourage the high-level sketch as in APPS. For translation we use:

\begin{figure*}[h] 
\begin{lstlisting}[escapeinside={(*}{*)}]
You will aim to solve the following problem in Parsel:
{question}

Translate the following solution plan into Parsel:
{solution_start}{solution_text}

You will translate a solution plan for a problem into Parsel. Each line should contain either a function description or a function reference.

A function description should be of the form:
```
function_name(arg1, arg2): Description of the function
```

A function reference should be of the form:
```
function_name
```

Use indentation to indicate dependencies between functions. For example, if function A calls function B, then function B should be indented under function A.
Make sure that the top-level function matches the name of the function in the solution plan.
\end{lstlisting} 
\caption{Translation prompt for GPT-4}
\end{figure*}


\clearpage
\newpage
\section{Robotic Plan Evaluation Details}
\label{questionnaire}

\subsection{Questionnaire}
Our questionnaire closely follows that of \citet{huang2022language}. We provide a figure with the directions for the accuracy version of the survey in the first image of Fig~\ref{survey}. We include an example question in the second image. Note that each participant was shown a random 5 questions with their answers in random order. The clarity survey instead asks ``For every question below, evaluate how easy it is to understand how the provided steps accomplish the task. Please rank the planned steps for each question from most understandable to least understandable (with 1 as the best and 3 as the worst).'' In addition, for the clarity survey, each question text instead said ``Rank the following plans based on which is the most understandable (1 = most understandable, 3 = least understandable).''

\subsection{Executability}
We find that the automated executability check is a less insightful metric than human evaluation, as it doesn't meaningfully reflect the plan's likelihood of successfully completing a task. Unfortunately, the code to replicate the executability measure from \citet{huang2022language} is unavailable. As an alternative, we developed our own executability checker using example code found on VirtualHome's GitHub repository, which evaluates if a proposed plan is syntactically accurate and can be executed within the VirtualHome environment. By leveraging Codex to generate eight Parsel programs for each of the 88 tasks and subsequently compiling them using the Parsel compiler, our method successfully produced executable solutions for all tasks. Conversely, \citet{huang2022language} managed executable plans for only 86 tasks. However, it is worth noting that our Parsel compiler explicitly incorporates this executability measure as a constraint, which explains the higher executability rates observed in our approach.

\begin{figure*}[h] 
\centering
\includegraphics[width=0.6\textwidth]{figures/survey_overview.png}\\
\includegraphics[width=0.6\textwidth]{figures/survey_question.png}
\caption{Screenshot of survey directions and example survey question. In this figure, the first  answer was generated by the baseline, the second was the indented Parsel version, and the third was the unindented Parsel version. However, note that the order is randomized for each participant. \label{survey}}
\end{figure*}

\clearpage
\newpage
\section{Human Case Study}
\label{humannofone}
\begin{figure*}[h]
\begin{lstlisting}
main(input_string): Takes an input line. First, splits it at newline, and stores the second line in a variable s and the third in t. Splits s in two parts at the asterisk, and checks whether the string t starts with the first part of s and ends with the second part. Returns the string "YES" if that condition is met, otherwise "NO". Also, it should always return "NO" if the length of t is smaller than the sum of the length of the parts of s.
"6 10\ncode*s\ncodeforces" -> "YES"
"6 10\ncodeforces\ncodeforces" -> "YES"
"6 10\ncode*morces\ncodeforces" -> "NO"
"6 10\na*a\na" -> "NO"
"6 10\na*a\naa" -> "NO"
\end{lstlisting}
\caption{Solution to \url{https://codeforces.com/problemset/problem/1023/A}}
\end{figure*}

\begin{figure*}[h]
\begin{lstlisting}
main(input_string): Parses the input and returns the minimum area of the input.
"3\n10 1\n20 2\n30 3" -> 180
"3\n3 1\n2 2\n4 3" -> 21
    parse_input(input_string): Takes the input line and first splits on newline. Ignores the first line, and parses each of the remaining lines as a tuple of two numbers, which give a list L of tuples. Returns L.
    "3\n10 1\n20 2\n30 3" -> [[10, 1], [20, 2], [30, 3]]
        parse_line(l): Splits l on space, converts each element to int, and returns the result of converting the result to a list.
        "10 1" -> [10, 1]
    enumerate_subsets_at_most_k(L, k): Returns all subsets of L with sizes ranging from 0 to k, inclusive.
    [1, 2, 3], 2 -> [[], [1], [2], [3], [1, 2], [1, 3], [2, 3]]
        enumerate_subsets(L, k): recusively enumerates the subsets of size k of the list L. Base cases: if k = 0, returns a list containing the empty list. If k > len(L), returns the empty list. Otherwise, first construct the subsets that contain the first element, then those that do not, and return their concatenation.
        [1, 2, 3], 2 -> [[1, 2], [1, 3], [2, 3]]
    minimum_area(whs): First, calls enumerate_subsets_at_most_k passing whs and half the length of whs rounded down. Returns the minimum result of calling compute_area on the list given by apply_inversions with whs and the subset.
    [[10, 1], [20, 2], [30, 3]] -> 180
    [[3, 1], [2, 2], [4, 3]] -> 21
        enumerate_subsets_at_most_k
        compute_area(whs): takes a list of pairs (width, height). Computes the sum of the widths and the maximum of the heights. Returns the product of those two numbers.
        [[1, 2], [3, 5]] -> 20
        [[10, 1], [20, 2], [30, 3]] -> 180
        apply_inversions(whs, subset): Takes a list of pairs of form (w, h) and a subset of indices to invert. Returns a list where the elements of whs whose index is in the subset are inverted to (h, w), and the others appear as given.
        [[1, 2], [3, 5]], [1] -> [[1, 2], [5, 3]]
        [[1, 2], [3, 5]], [] -> [[1, 2], [3, 5]]
\end{lstlisting}
\caption{Solution to \url{https://codeforces.com/problemset/problem/529/B}}
\end{figure*}

\begin{figure*}
\begin{lstlisting}
main(input): Converts the input to an integer and returns the value of f of n.
"1" -> 1
"2" -> 3
"3" -> 10
    f(n): First pre-computes the Pascal triangle up to n+1 using compute_pascal_triangle. Then, returns the value of dp(n, pascal_triangle)
    1 -> 1
    2 -> 3
    3 -> 10
        compute_pascal_triangle(N): returns a matrix with N + 1 rows where m[i][j] corresponds to "i choose k", i.e., the Pascal triangle. It is computed using dynamic programming: m[i][j] = m[i-1][j] + m[i-1][j-1]. All elements are modulo (10**9 + 7). The i-th row has only i columns.
        2 -> [[1], [1, 1], [1, 2, 1]]
        3 -> [[1], [1, 1], [1, 2, 1], [1, 3, 3, 1]]
        dp(n, pascal_triangle): first creates a list with (n + 1) zeros called L. Then fills it in with the following dynamic programming relation: base case is L[0] = 1; then, L[i] = sum (j in [1, i]) pascal_triangle[i-1][j-1] * L[i - j]. Finally, returns the following answer: sum (k in [1, n]) pascal_triangle[n][k] * L[n - k]. After each of these assignments, take modulo 10**9 + 7 to avoid big numbers.
        1, [[1], [1, 1], [1, 2, 1]] -> 1
        2, [[1], [1, 1], [1, 2, 1]] -> 3
        3, [[1], [1, 1], [1, 2, 1], [1, 3, 3, 1]] -> 10
\end{lstlisting}
\caption{Solution to \url{https://codeforces.com/problemset/problem/568/B} }
\end{figure*}

\begin{figure*}
\begin{lstlisting}
main(input): Reads the input line and counts how many pairs of elements pass the test.
"4 2\n2 3\n1 4\n1 4\n2 1" -> 6
"8 6\n5 6\n5 7\n5 8\n6 2\n2 1\n7 3\n1 3\n1 4" -> 1
    parse_input(input): Splits input as a sequence of lines. Each line is parsed as a list of two space-separated integers. The first line of input contains N and P, and the second to last lines are aggregated in a list L. Returns a list with three values: N, P and L.
    "4 2\n2 3\n1 4\n1 4\n2 1" -> [4, 2, [[2, 3], [1, 4], [1, 4], [2, 1]]]
    count_valid_pairs(L, p): for each distinct pair (i, j) both ranging from 0 to the length of L, counts how many of those pairs have score at least p in L given by compute_pair_score.
    [[2, 3], [1, 4], [1, 4], [2, 1]], 2 -> 6
    [[5, 6], [5, 7], [5, 8], [6, 2], [2, 1], [7, 3], [1, 3], [1, 4]], 6 -> 1
        compute_pair_score(a, b, L): receives two integers, a and b, and a list of pairs L. Returns how many elements of L contain either a + 1 or b + 1.
        1, 2, [[2, 3], [1, 4], [1, 4], [2, 1]] -> 2
        1, 1, [[2, 3], [1, 4], [1, 4], [2, 1]] -> 2
        0, 1, [[2, 3], [1, 4], [1, 4], [2, 1]] -> 4
        4, 5, [[2, 3], [1, 4], [1, 4], [2, 1]] -> 0
\end{lstlisting}
\caption{Solution to \url{https://codeforces.com/problemset/problem/420/C}}
\end{figure*}

\begin{figure*}
\begin{lstlisting}
main(input): parses the input as two space-separated integers, n and m. Return 2 * f(n, m) modulo 10**9 + 7
"2 3" -> 8
"3 2" -> 8
    f(n, m): computes fib(n) + fib(m) - 1
    2, 3 -> 4
        fib(m): computes the m-th fibonacci number modulo 10**9 + 7 using dynamic programming starting with dp[0] = 1 and dp[1] = 1, then dp[n] = (dp[n-1] + dp[n-2]) 1 -> 1
        2 -> 2
        3 -> 3
        4 -> 5
        5 -> 8
        6 -> 13
\end{lstlisting}
\caption{Solution to \url{https://codeforces.com/problemset/problem/1239/A}}
\end{figure*}

\clearpage
\newpage
\section{Parsel Language Nuances}
\label{nuances}
\subsection{Syntax}
\textbf{Descriptions.}
A function description is represented as a function name followed by comma-separated input arguments in parentheses, and optionally an arrow followed by what the function returns\footnote{Note that in Parsel, for Python one can also indicate in the description that a function should yield a value or is a generator.}, then a colon and text describing the function to be implemented. For example, as part of Conway's Game of Life, one might write \looseness=-1 

\begin{lstlisting}[breaklines=true,numbers=none]
count_living_neighbors(grid, i, j): count the number of living neighbors of the cell at the index (i, j)
\end{lstlisting}
A function generated from a description can call either the functions defined directly below the description in the function graph (indicated with indentation) or references directly below the description\footnote{A nuance here is the optional ability for undefined/out-of-scope functions which are generated by the code LLM to also be implemented automatically.}, both shown in Fig.~\ref{collatz}.


\textbf{Constraints.}
A constraint is represented as a function's input values comma-separated, optionally followed by an arrow and the expected output of the function. Constraints are provided at the same indentation as the preceding description. For example, after the definition of count\_living\_neighbors one can write
\begin{lstlisting}[breaklines=true,numbers=none]
[[1, 0], [0, 1]], 0, 0 -> 1
[[1, 0], [0, 1]], 0, 1 -> 2
\end{lstlisting}
\vspace{-3px}
This indicates that count\_living\_neighbors should return 1 when called with the arguments \lstinline[postbreak=]{[[1, 0], [0, 1]], 0, 0} and 2 when called with \lstinline[postbreak=]{[[1, 0], [0, 1]], 0, 1}. Notably, to apply complex constraints on functions, one can describe and constrain higher-order functions. For example:
\begin{lstlisting}[numbers=none]]
type_fn_output(fn, args): returns the type of the output of a function called with args
count_living_neighbors, ([[1, 0], [0, 1]], 0, 0) -> int
\end{lstlisting}
\vspace{-4px}
This indicates that the function count\_living\_neighbors should return an integer when called with the input arguments \lstinline[postbreak=]{[[1, 0], [0, 1]], 0, 0}.

What it means to satisfy constraints to validate a program varies from language to language: in Python, one can check that a program passes certain assert statements by evaluating them; however, in a theorem-proving language like Lean, where the ability to run a program (without skipping steps by using \lstinline{sorry} or \lstinline{oops} lines) shows that a proof holds, one would instead represent the formal proof statement as the specified constraint (that is, that you are actually proving what you set out to prove). For languages where correctness can be checked without any unit tests, their functions can be treated as also having implicit constraints.

\begin{figure}[h!]
    \centering
    \vspace{-5px}
    \includegraphics[width=0.4\columnwidth]{figures/collatz.pdf} \vspace{-10px}
    \caption{\lstinline{collatz_recursion} call graph. There is a strongly connected component formed by \lstinline{collatz_recursion} and \lstinline{recursion_rule}.}
    \label{fig:collatzgraph}
    \vspace{-5px}
\end{figure}

\textbf{References.} A reference is simply the name of a function defined in the current scope (see the next paragraph for details) within the function graph. A reference allows and encourages (via prompt) the parent function to use the referenced function. This allows for recursive function definitions and functions called by multiple functions.
For example, one can define an (overly verbose) version of the Collatz conjecture (a well-known recursive open question in mathematics) as shown in Figure~\ref{collatz}, where the final line is a reference. We visualize the corresponding call graph and its strongly connected components (SCC) in Figure~\ref{fig:collatzgraph}. In the Collatz functions, \lstinline{base_case} is implemented first as the \lstinline{collatz_recursion} SCC depends on it.



\subsection{Headers}
We also support program headers, allowing global contexts, used when implementing all new functions within a program. This is indicated by a line containing an optional string of special characters (e.g. ``\#*\#*\#'') separating the body and the text and is passed as a prefix to all prompts.

\subsection{Repeated Automatic Decomposition}
\label{autodecomp}
As indicated by a rapidly growing number of papers \citep{brohan2022can, huang2022language}, the task of decomposing a task into steps in natural language is one that language models are surprisingly capable of. As explored in concurrent work \citep{primer2022}, using language models to automatically and recursively decompose difficult open-ended problems to arbitrary depth is a powerful tool. Thus, we treat the ability to automatically decompose a Parsel function as a key feature of Parsel. This is an optional flag that prompts a language model to generate Parsel code corresponding to any additional subfunctions necessary when Parsel fails to implement a function. These proposed subfunctions are then added as child nodes to the decomposed function node. However, an additional consequence is that Parsel can thus be used to recursively decompose tasks into steps, by repeatedly identifying descriptions that cannot be directly implemented and attempting to decompose them.


\subsection{Scope.}
Scope in Parsel is defined by indentation. The scope  of a function  includes the set of functions that can be used as a reference for a given function -- that is, all functions where the indentations between the current function to the referenced function are strictly decreasing.

\subsection{Variations due to target language requirements.}
Certain aspects of the implementation are still target-language specific. As discussed above, the meaning and representation of a constraint may vary by language. Moreover, every language has a different evaluation function: executing Python is different than compiling and running C++ code, which is different than checking a proof with Lean. Further, every language will likely require a different prompt for the language model. Thus, we detail these particularities in language-specific configuration files.

\clearpage
\newpage

\section{Pipeline Figure Example}
\label{pipelineappendix}

\begin{figure}[h]
\begin{lstlisting}
Question:
The grand museum has just announced a large exhibit on jewelry from around the world. In the hopes of his potential future prosperity, the world-renowned thief and master criminal Edward Terrenando has decided to attempt the magnum opus of his career in thievery.

Edward is hoping to purloin a large number of jewels from the exhibit at the grand museum. But alas! He must be careful with which jewels to appropriate in order to maximize the total value of jewels stolen.

Edward has  knapsacks of size , , , up to , and would like to know for each the maximum sum of values of jewels that can be stolen. This way he can properly weigh risk vs. reward when choosing how many jewels to steal. A knapsack of size  can hold items if the sum of sizes of those items is less than or equal to . If you can figure out the best total value of jewels for each size of knapsack, you can help Edward pull off the heist of the century!

-----Input-----
Each input will consist of a single test case. Note that your program may be run multiple times on different inputs. The first line of input will consist of two space-separated integers  and , where  () is the number of jewels in the exhibit, and  () is the maximum size of knapsack available to Edward. The next  lines each will describe a jewel. Each line will consist of two space-separated integers  and , where  () is the size of the jewel, and  () is its value. Each jewel can only be taken once per knapsack, but each knapsack is an independent problem.

-----Output-----
Output  integers separated by whitespace. The first integer should be the maximum value of jewels that will fit in a knapsack of size . The second should be the maximum value of jewels in a knapsack of size , and so on.

-----Examples-----
Sample Input 1:
4 9
2 8
1 1
3 4
5 100
Sample Output 1:
1 8 9 9 100 101 108 109 109

Sample Input 2:
5 7
2 2
3 8
2 7
2 4
3 8
Sample Output 2:
0 7 8 11 15 16 19
\end{lstlisting}
\caption{Pipeline Figure Task}
\end{figure}


\begin{figure*}
\begin{lstlisting}
First, we need to figure out how to calculate the maximum sum of values of jewels for each size of knapsack. To do this, we can use a dynamic programming approach. 

We can create a two-dimensional array of size  where each row represents the different jewels and each column represents the different sizes of knapsack. The value of each cell in the array will represent the maximum sum of values of jewels that can be stolen for a given knapsack size. 

We can then iterate through the array, starting at the beginning. For each row, we can calculate the maximum sum of values of jewels that can be stolen for each knapsack size by taking the maximum of the value of the current cell and the value of the previous cell plus the value of the current jewel. 

At the end, we will have an array that contains the maximum sum of values of jewels that can be stolen for each knapsack size. We can then output these values as our answer. 

This algorithm is correct because we are calculating the maximum sum of values of jewels that can be stolen for each knapsack size by comparing the values of the current cell and the previous cell plus the value of the current jewel. This ensures that we are taking the maximum value for each knapsack size.
\end{lstlisting}
\caption{Pipeline Figure Sketch}
\end{figure*}

\begin{figure*}
\begin{lstlisting}
# Takes a string containing the number of jewels and knapsack sizes on the first line, the jewels on the next lines, and returns the number of jewels, the knapsack sizes, and the jewels.
def parse_input(input_str):
    lines = input_str.split('\n')
    first_line = lines[0].split(' ')
    num_jewels = int(first_line[0])
    knapsack_sizes = int(first_line[1])
    jewels = [[0, 0]] * num_jewels
    for i in range(1, num_jewels + 1):
        jewel = lines[i].split(' ')
        jewels[i - 1] = [int(jewel[0]), int(jewel[1])]
    return num_jewels, knapsack_sizes, jewels

# Returns the maximum sum of values of jewels that can be stolen for each knapsack size.
def max_sum_of_jewels_for_size_and_jewel(jewels, size, jewel):
    if size < 0:
        return 0
    elif jewel < 0:
        return 0
    elif jewel == 0:
        return jewels[jewel][1] if jewels[jewel][0] <= size else 0
    elif jewels[jewel][0] > size:
        return max_sum_of_jewels_for_size_and_jewel(jewels, size, jewel-1)
    else:
        return max(max_sum_of_jewels_for_size_and_jewel(jewels, size, jewel-1),
                   max_sum_of_jewels_for_size_and_jewel(jewels, size-jewels[jewel][0], jewel-1) + jewels[jewel][1])

# Returns the maximum sum of values of jewels that can be stolen for each knapsack size.
def max_sum_of_jewels_for_size(jewels, size):
    result = []
    for s in range(1, size + 1):
        result += [max_sum_of_jewels_for_size_and_jewel(jewels, s, len(jewels) - 1)]
    return result

# Returns the string of the maximum sum of values of jewels that can be stolen for each knapsack size.
def to_output_str(max_sum_of_jewels_for_size):
    return " ".join(map(str, max_sum_of_jewels_for_size))

# Returns the maximum sum of values of jewels that can be stolen for each knapsack size.
def max_sum_of_jewels(input_str):
    '''
    >>> max_sum_of_jewels('4 9\\n2 8\\n1 1\\n3 4\\n5 100\\n')
    '1 8 9 9 100 101 108 109 109'
    >>> max_sum_of_jewels('5 7\\n2 2\\n3 8\\n2 7\\n2 4\\n3 8\\n')
    '0 7 8 11 15 16 19'
    '''
    number_of_jewels, knapsack_sizes, jewels = parse_input(input_str)
    return to_output_str(max_sum_of_jewels_for_size(jewels, knapsack_sizes))


assert compare_output(max_sum_of_jewels, '4 9\n2 8\n1 1\n3 4\n5 100', '1 8 9 9 100 101 108 109 109')
assert compare_output(max_sum_of_jewels, '5 7\n2 2\n3 8\n2 7\n2 4\n3 8', '0 7 8 11 15 16 19')
assert compare_output(max_sum_of_jewels, '2 6\n300 1\n300 2', '0 0 0 0 0 0')
\end{lstlisting}

\caption{Pipeline Figure Sketch}
\end{figure*}

\clearpage
\newpage

\section{Other Details}
\subsection{Test Generation in HumanEval}
For our test generation in our HumanEval experiments, we generated a set of tests by prompting GPT-4 to \lstinline{"Generate an assert-based test for the following function. Answer with only a code block, and no other text. Do not wrap your asserts in a function.\n" + question} and then collecting and set-aggregating 100 completions.

\subsection{Backtracking}
We also support backtracking for the Parsel implementation step, where we re-implement descendants by sampling new solutions for dependencies if a correct solution is not found for a parent. This is necessary to improve the robustness of some of the Appendix examples such as Figure~\ref{fig:lispinterpreter}.

\subsection{Training Details}
Although we do not train any models, all models used are discussed throughout the paper. See Appendix~\ref{decomprompts} for more details about sampling hyperparameters.
\subsection{Error Bars}
We estimate a standard deviation of  for the best APPS result, given 1000 sampled problems. 
\subsection{Compute}
The most computationally intensive part of this research, by far (in terms of FLOPS), was the ablation using an open-source CodeGen model, which required several-hundred A100 hours. The rest of the inference was done through API calls.

\subsection{Generated Tokens}
\label{tokencounts}
For the APPS evaluation, in terms of tokens generated, it is hard to compare the models directly: The CodeT paper does not specify the number of tokens decoded for their evaluation. Without more detail about their evaluations, it is impossible to confidently estimate the tokens generated per program for the CodeT evaluation. The AlphaCode results sample at most 768 tokens per solution, but they do not report average statistics directly - based on Figure 11 in the AlphaCode paper \citep{li2022competition}, the majority of its generated solutions are 150 to 350 tokens long after removing dead code and comments. The competition-level problems (that we evaluate on) require more tokens on average. For their best reported results, their figures indicate they sample at least 20 billion tokens for the competition-level subset of APPS. On the other hand, for our best results, Parsel generates (on average) 491 tokens of Python code per program implementation, and because we implement each high-level sketch in Python sixteen times (i.e.  in our best ), we also sample on average 22 sketch tokens and 43 translation tokens per Python program implementation. Correspondingly, we sample roughly 7 million tokens for our APPS evaluation.


\subsection{Reproducibility}
While our contribution is not a model or dataset, we have released our code.