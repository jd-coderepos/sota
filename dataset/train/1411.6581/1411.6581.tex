\documentclass[runningheads]{llncs}


\usepackage{xspace}
\usepackage[utf8]{inputenc}
\usepackage{graphicx}
\usepackage{amsmath}
\usepackage{float}
\usepackage{amsfonts}
\usepackage{algorithm}      \usepackage{algpseudocode}  \usepackage{enumerate}
\usepackage{paralist}
\usepackage{enumitem}
\usepackage{hyperref}


\def\rankop{\textsf{rank}}
\def\selop{\textsf{select}}
\def\accessop{\textsf{access}}

\newcommand{\forbMMOne}{3\text{-}14\text{-}2}
\newcommand{\forbMMTwo}{2\text{-}41\text{-}3}
\newcommand{\mh}{\text{-}}

\newcommand{\numEdges}{m}
\newcommand{\minima}{t}
\newcommand{\rminmax}{\textsc{RMinMax}}
\newcommand{\rmin}{\textsc{RMin}}
\newcommand{\rmax}{\textsc{RMax}}
\newcommand{\rtopk}{\textsc{RTopK}}
\newcommand{\twoseq}{\mathcal{Q}}
\newcommand{\kseq}{\mathcal{Q}_k}
\newcommand{\opset}{\mathcal{C}}
\newcommand{\Oh}{\mathcal{O}}
\newcommand{\topconstant}[1][2]{c_{#1}}
\newcommand{\polylog}{\text{polylog}}

\title{Optimal Encodings for Range Top-\texorpdfstring{}{k},
  Selection, and Min-Max}

\author{Pawe{\l} Gawrychowski\inst{1}\thanks{Currently holding a post-doctoral position at Warsaw Center of Mathematics and Computer Science.}  \and Patrick K. Nicholson\inst{2}}
\institute{Institute of Informatics, University of Warsaw, Poland \and Max-Planck-Institut für Informatik, Saarbrücken, Germany}


\allowdisplaybreaks

\begin{document}

\pagestyle{plain}
\maketitle

\begin{abstract}
We consider encoding problems for range queries on arrays. In these
problems the goal is to store a structure capable of recovering the
answer to all queries that occupies the information theoretic minimum
space possible, to within lower order terms.  As input, we are given
an array , and a fixed parameter .  A
\emph{range top-} query on an arbitrary range  asks us to return the ordered set of indices  such that  is the -th largest
     element in , for .  A \emph{range
       selection} query for an arbitrary range 
     and query parameter  asks us to return the index of
     the -th largest element in .  We completely resolve
     the space complexity of both of these heavily studied
     problems---to within lower order terms---for all .
     Previously, the constant factor in the space complexity was known
     only for .  We also resolve the space complexity of another
     problem, that we call \emph{range min-max}, in which the goal is
     to return the indices of both the minimum and maximum elements in
     a range.
\end{abstract}


\section{Introduction}

Many important algorithms make use of range queries over arrays of
values as subroutines~\cite{N13,S13}.  As a prime example, text
indexes that support pattern matching queries often maintain an array
storing the lengths of the longest common prefixes between consecutive
suffixes of the text.  During a search for a pattern this array is
queried in order to find the position of the minimum value in a given
range.  That is, a subroutine is needed that can preprocess an array
 in order to answer \emph{range minimum queries}.  Formally, as
input to such a query we are given a range ,
and wish to return the index .
In text indexing applications memory is often the constraining factor,
so the question of how many bits are needed to answer range minimum
queries has been heavily studied.  After a long line of research
(see~\cite{BFPSS05,S07}), it has been determined that such queries can
be answered in constant time, by storing a data structure of size  bits~\cite{FH11}.  Furthermore, this space bound is optimal to
within lower order terms (see~\cite[Sec.~1.1.2]{FH11}).  The
interesting thing is that the space does not depend on the number of
bits required to store individual elements of the array .  After
constructing the data structure we can discard the array , while
still retaining the ability to answer range minimum queries.

Results of this kind, where it is shown that the solutions to all
queries can be stored using less space than is required to store the
original array, fall into the category of \emph{encodings}, and, more
generally, \emph{succinct} data structures~\cite{J89}.  Specifically,
given a set of combinatorial objects  we wish to represent an
arbitrary member of  using 
bits\footnote{We use  to denote .}, while still
supporting queries, if possible.  If queries can be supported by the
representation then we refer to it as a data structure, but if not,
then we refer to it as an encoding.  For the case of range minimum
queries or range maximum queries, the set  turns out to be
\emph{Cartesian trees}, which were introduced by Vuillemin~\cite{V80}.
For a given array , the Cartesian tree encodes the solution to all
range minimum queries, and similarly, if two arrays have the same
solutions to all range minimum queries, then their Cartesian trees are
identical~\cite{FH11}.

Recently, there has been a lot of interest the following two problems,
that generalize range maximum queries in two different ways.  The
input to each of the following problems is an array , that we
wish to preprocess into an encoding occupying as few bits as possible,
such that the answers to all queries are still recoverable.  We assume
a value  is fixed at preprocessing time.
\begin{itemize}

\item \textbf{Range top-:} Given an arbitrary query range  and , return the indices of the 
  largest values in .  This problem is the natural
  generalization of range maximum queries and has been the focus of a
  several papers, leading to asymptotically optimal lower and upper
  space bounds of  and  bits, proved by
  Grossi et al.~\cite{GINRS13} and Navarro, Raman, and
  Rao~\cite{NRS14}, respectively.  The latter upper bound is a data
  structure that can answer range top- queries in optimal
   time.

\item \textbf{Range -selection:} Given an arbitrary query range
   and , return the index of the
  -th largest value in .  This problem was studied in a
  series of recent papers (see~\cite{GPT09} and \cite{BGJS10} for
  further references), culminating in data structures that occupy a
  linear number of words, and can answer queries in  time~\cite{CW13}.  This query time matches a cell-probe
  lower bound for near-linear space data structures~\cite{JL11}. It is
  straightforward to see that any encoding of range top- queries is
  also an encoding for range -selection queries, though the
  question of how much time is required during a query remains
  unclear~\cite{NRS14}.  Very recently, Navarro, Raman, and
  Rao~\cite{NRS14} described a data structure that can be used to
  answer range -selection queries in optimal  time~\cite{NRS14}, and, like the range top- data structure,
  occupies  bits of space.
\end{itemize}


\subsubsection{Our Results}

We present the first space-optimal encodings to range top----and
therefore range selection also---as well as a new problem that we call
\emph{range min-max}, in which the goal is to return the indices of
both the minimum and maximum element in the array.  We emphasize that,
on their own, the encodings for range top- and selection do not
support queries efficiently: they merely store the solutions to all
queries in a compressed form.  However, our encoding for range min-max
can be augmented with  additional bits of data to create a data
structure that supports queries in  time.  Furthermore, even
without query support, our encodings for range top- and selection
address a problem posed in the papers of Grossi et al.~ \cite{GINRS13}
and Navarro et al.~\cite{NRS14}.

In Table~\ref{tab:results} we present a summary of previous and new
results.  Prior to this work, the only value for which the exact
coefficient of  was known was the case in which  (i.e., range
maximum queries).  For even  the best previous estimate was that
the coefficient of  is between  and
~\cite{PNRR14}. The lower bound of  was derived using
generating functions and an extensive computational
search~\cite{PNRR14}.  In contrast, our method is purely combinatorial
and gives the exact coefficient for all .  For  the
coefficients are (rounding up) , , and ,
respectively.


\begin{table}[!t]
\centering
\caption{\label{tab:results} Old and new results. Both upper and lower
  bounds are expressed in bits.  Our bounds make use of the binary
  entropy function .  For the entry marked with a  the
  claimed bound holds when .}
\begin{tabular}{|l|l|l|l|l|}
\hline
Ref. & Query & Lower Bound & Upper Bound & Query Time \\
\hline
\cite{FH11}   & max     &  &  &  \\ 
\cite{GINRS13,NRS14}     & top- &  &  &  \\ 
\cite{PNRR14}     & top- &  &  &  \\
\hline
Thm.~\ref{thm:min-max-ub},~\ref{thm:min-max-lb}     & min-max &  &  &  \\ 
Thm.~\ref{thm:top-k-ub},~\ref{thm:top-k-lb}     & top- &  &   & --- \\ 
Thm.~\ref{thm:top-k-ub},~\ref{thm:top-k-lb}     & top- &   &  & --- \\
\hline
\end{tabular}
\end{table}

As mentioned above, a negative aspect of our encodings is that they
appear to be somewhat difficult to use as the basis for a data
structure.  However, in Section~\ref{sec:datastructure}, we present a
data structure based on our encoding that \emph{nearly} matches the
optimal space bound.  Explicitly, we can achieve a space bound of
 bits with query time
.  Thus, our data structure achieves space
much closer to the optimal bound than the previous best
result~\cite{NRS14}, but the query time is worse.  We leave the
following data structure problem open: how can range top- and
selection queries be supported with optimal query time using space
matching our encodings (to within lower order terms)?

Finally, we wish to point out that although our formulation of the
range top- problem returns the indices in sorted order, the
constant factor in our lower bound also holds for the \emph{unsorted}
version, in which we return the indices in an arbitrary order,
provided .  This follows since any encoding strategy for
unsorted range top- can be used to construct a sorted top-
encoding, by padding the end of the input array with  values
larger than any other.  The unsorted encoding of this padded array can
be used to infer the solution to an arbitrary sorted top- query
 by examining the solutions to queries : see Appendix~\ref{sec:reduction} for details.





\subsubsection{Discussion of Techniques and Road Map} 

Prior work for top-, for , focused on encoding a
decomposition of the array, called a shallow
cutting~\cite{GINRS13,NRS14}.  Since shallow cuttings are a general
technique used to solve many other range searching
problems~\cite{M92,JL11}, these previous works~\cite{GINRS13,NRS14}
required additional information beyond storing the shallow cutting in
order to recover the answers to top- queries.  Furthermore, in
these works the exact constant factor is not disclosed, though we
estimate it to be at least twice as large as the bounds we
present. For the specific case of range top- queries a different
encoding has been proposed based on \emph{extended Cartesian
  trees}~\cite{PNRR14}.  In contrast to both of the previous
approaches, our encoding is based the approach of Fischer and
Heun~\cite{FH11}, who describe what is called a 2D min-heap
(resp. max-heap) in order to encode range minimum queries (resp. range
maximum queries).  We begin in Section~\ref{sec:min-max} by showing
how to generalize their technique to simultaneously answer both range
minimum and range maximum queries.  Our encoding provides the answer
to both using  bits in total, compared to  bits
using the trivial approach of constructing both encodings separately.
We then show this bound is optimal by proving that any encoding for
range min-max queries can be used to distinguish a certain class of
permutations.  We move on in Section~\ref{sec:top-k} to generalize
Fischer and Heun's technique in a clean and natural way to larger
values of .  Indeed, the encoding we present---like that of Fischer
and Heun---is simple enough to implement.  The main difficulty is
proving that the bound achieved by our technique is optimal.  For this
we enumerate a particular class of walks, via an application of the
so-called cycle lemma of Dvoretzky and Motzkin~\cite{DM47}.

Finally, in Section~\ref{sec:datastructure} we show that our encoding
can be used as the basis for a range top- data structure.  Though
the resultant space bound and query time are suboptimal, we note that
interesting challenges had to be overcome to design a data structure
based on our encoding.  Concisely, we required the ability to
decompose the encoding into smaller blocks in order to support queries
efficiently.  To do this we, in some sense, generalized the pioneers
approach of Jacobson~\cite{J89} via a non-trivial decomposition
theorem.  Since balanced parentheses representations appear in many
succinct data structures, we believe this will likely be of
independent interest.

\section{Optimal Encodings of Range Min-Max Queries\label{sec:min-max}}

In this section we describe our encoding for range min-max queries.
We use  to denote a range min-max query on a
subarray .  The solution to the query is the ordered set of
indices  such that  and .

\subsection{Review of Fischer and Heun's Technique}

We review the algorithm of Fischer and Heun~\cite{FH11} for
constructing the encoding of range minimum (resp. maximum) queries.


\begin{figure}
\centering
\includegraphics[width=\textwidth]{minmax.pdf}
\caption{\label{fig:perm}A trace of Fischer and Huen's algorithm for
  constructing the encoding for range minimum and maximum queries on
  an array .}
\end{figure}


Consider an array  storing  numbers. Without loss of
generality we can alter the values of the numbers so that they are a
permutation, breaking ties in favour of the leftmost element. To
construct the encoding for range minimum queries we sweep the array
from left to right\footnote{In the original paper the sweeping process
  moves from right to left, but either direction yields a correct
  algorithm by symmetry.}, while maintaining a stack. A string of bits
 (resp. ) will be emitted in reverse order as we
scan the array.  Whenever we push an element onto the stack, we emit a
one bit, and whenever we pop we emit a zero bit. Initially the stack
is empty, so we push the position of the first element we encounter on
the stack, in this case, .  Each time we increment the current
position, , we compare the value of  to that of the element
in the position , that is stored on the top of the stack.  While
 is not less than (resp. not greater than) , we pop the
stack.  Once  is less than (resp. greater than) the current
element or the stack becomes empty, we push  onto the stack.  When
we reach the end of the array, we pop all the elements on the stack,
emitting a zero bit for each element popped, followed by a one bit.
An example illustrating a trace of the algorithm described here can be
found in Figure~\ref{fig:perm}.

Fischer and Heun showed that the string of bits output by this process
can be used to encode a rooted ordinal tree in terms of its
\emph{depth first unary degree sequence} or DFUDS~\cite{FH11}.  To
extract the tree from a sequence, suppose we read  zero bits until
we hit the first one bit.  Based on this, we create a node  of
degree , and continue building first child of  recursively.
Since there are at most  stack operations, the tree is therefore
represented using  bits.  We omit the technical details of how a
query is answered, but the basic idea is to augment this tree
representation with succinct data structures supporting navigation
operations.  The following corollary summarizes part of their result:

\begin{lemma}[Corollary~5.6~\cite{FH11}]\label{lem:aux-index}
Given the DFUDS representation of  (resp. ) any
query  (resp. ) can be
answered in constant time using an index occupying  additional bits of space.
\end{lemma}

\subsection{Upper Bound for Range Min-Max Queries}

We propose the following encoding for a simultaneous representation of
 and .  Scan the array from left to right and
maintain two stacks: a min-stack for range minimum queries, and a
max-stack for range maximum queries.  Notice that in each step except
for the first and last, we are popping an element from exactly one of
the two stacks.  This crucial observation allows us to save space.  We
describe our encoding in terms of the min-stack and the max-stack
maintained as above.  Unlike before however, we maintain two separate
bit strings,  and . If the new element causes 
elements on the min-stack to be popped, then we prepend
 to the string , and prepend  to the string .
Otherwise, if the new element causes  elements on the
max-stack to be popped, we prepend  to the string ,
and  to the string .  Since exactly  elements are popped
during  push operations, the bit string  has length , and
the bit string  has length , for a total of  bits.

Before stating our theorem, we require the following result by Raman,
Raman, and Rao~\cite{RRR07}:

\begin{lemma}[\cite{RRR07}]\label{lem:rrr} Let  be a
  bit vector of length  bits, containing  one bits.  In the
  word-RAM model with word size  bits, there is a data
  structure of size  bits that
  supports the following operations in  time, for any :
\begin{enumerate}
\item : return the bit at index  in .
\item : return the number of bits with
  value  in .
\item : return the index of the -th
  bit with value .
\end{enumerate}
\end{lemma}

Next, we show that by using our encoding and Lemma~\ref{lem:rrr} it
is possible to also support queries on this encoding in  time.

\begin{theorem}\label{thm:min-max-ub}
There is a data structure that occupies  bits of space,
such that any query  can be answered in 
time.
\end{theorem}

\begin{proof}
By Corollary~\ref{lem:aux-index}, to prove the theorem, it is
sufficient to show that there is a data structure that occupies  bits of space, and can recover any block of  consecutive
bits from both  and  in  time.

If we have such a structure that can extract any
block from either DFUDS representation, then we can use it as an
oracle to access the DFUDS representation of either tree.  Thus, we
need only apply Lemma~\ref{lem:aux-index} to complete the theorem.
The data structure makes use of the bit strings  and , as well
as the following auxiliary data structures:

\begin{enumerate}

\item We precompute a lookup table  of size
   bits.  The lookup table takes two bit
  strings as input,  and , both with length , as well as a single bit .  We conceptually think of the
  bit string  as having the format
  ,
  where each . The table returns a new bit string
  , of length no greater than , that we will
  define next.  Let  be the concatenation operator, and define
  the function:
   If  then , and
   denotes the -th bit of .  Such a table occupies no
  more than the claimed amount of space, and can return  (as well
  as ) in  time.

\item Each bit in  corresponds to at least one bit in  or
  .  Also recall that at each step during preprocessing we
  append the value  in unary to  rather than  (as
  in the representation of Fischer and Heun).  Thus, we can treat each
  push operation (with the exception of the first and last)
  corresponding to a single one bit in  as representing three bits:
  two bits in  and one bit in  or two bits in
   and one bit in , depending on the corresponding
  value in .  We store a bit vector  of length  which
  marks the position in  of the bit corresponding to the -th bit of , for .  We do the analogous procedure for  and call
  the resulting bit vector .

\end{enumerate}

Suppose now that we support the operations rank and select on
, , and .  We use the data structure of
Lemma~\ref{lem:rrr} that for  and  will occupy

 

\noindent
bits, and for  will occupy no more than  bits.  Thus, our data structures at this point occupy
 bits in total, counting the space for .  We will describe
how to recover  consecutive bits of ; the procedure
for  is analogous.  Consider the distances between two
consecutive  bits having indices  and  in .
Suppose  in , for some constant
.  In this case we call the corresponding block  of
 consecutive bits of  \emph{min-good}, and otherwise
we call  \emph{min-bad}.  We also define similar notions for
\emph{max-good} and \emph{max-bad} blocks.  The problem now becomes
recovering any block (good or bad), since if the  consecutive
bits we wish to extract are not on block boundaries we can simply
extract two consecutive blocks which overlap the desired range, then
recover the bits in the range using bit shifting and bitwise
arithmetic.

If  is min-good, then we can recover it in 
time, since all we need to do is scan the corresponding segment of 
between the two s, as well as the segment of  starting at
.  We process the bits of  and  together
in blocks of  each, using the lookup table
: note that we can advance in  correctly by
determining  by counting the number of  bits in either in 
or .  This can be done using either an additional lookup table of
size  using constant time, or by storing the answer
explicitly in .  When we do this, there is one border
case which we must handle, which occurs when the last bit in  is
not a .  However, we can simply append a  to end of  in
this case, and then delete either  or  from the end of ,
depending on the value of .  This correction can be done in
 time using bit shifting and bitwise arithmetic.

If  is min-bad, then we store the answer explicitly.  This
can be done by storing the answer for each bad  in an array
of size  bits, where  is the number of bad blocks.  Since
 this is  bits in total.  We also must store yet another bit vector,
encoded using Lemma~\ref{lem:rrr}, marking the start of the min-bad
blocks, which occupies another  bits
by a similar calculation as before.  Thus, we can recover any block in
 using  bits in
 time.  

In fact, by examining the structure of Lemma~\ref{lem:rrr} in more
detail we can argue that it compresses  slightly for each bad
block, to get a better space bound than  bits. Consider all
the min-bad blocks  in  and the
max-bad blocks  in .  For a
given min-bad block , any max-bad block  can only
overlap its first or last  bits in .  This follows since
each bit in  corresponds to at least one bit in either 
or , and because less than half of these  bits can
correspond to bits in  (since the block is min-bad). Thus,
each bad block has a middle part of at least  bits, which
are not overlapped by any other bad block.  We furthermore observe
that these  middle bits are highly compressible, since
they contain at most  one bits, by the definition of a bad
block.  Since these  middle bits are compressed to their
zeroth-order entropy in chunks of  consecutive bits
by Lemma~\ref{lem:rrr}, we get that the space occupied by each of them
is at most
 
\noindent
The cost of explicitly storing the answer for the bad block was  bits. Since , and assuming  is sufficiently large, we
get that this additional  bits of space can be added to the
cost of storing the middle part of the bad block in compressed form,
without exceeding the cost of storing the middle part of the bad block
in uncompressed form.  The value of  came from a numeric
calculation by finding the first value of  such that
.  Thus, the total space bound is
 bits.  \qed
\end{proof}

\subsection{Lower Bound for Range Min-Max Queries}

Given a permutation , we say  contains the
permutation pattern  if there
exists a subsequence of  whose elements have the same relative
ordering as the elements in the pattern.  That is, there exist some
 such that for all  we
have that  if and only if .  For
example, if  then  contains the permutation
pattern : we use this hyphen notation to
emphasize that the indices need not be consecutive. In this case, the
series of indices in  matching the pattern are , ,  and .  If no hyphen is present between elements
 and  in the permutation pattern, then the indices 
and  must be consecutive: i.e., .  In terms
of the example,  does not contain the permutation pattern
.

A permutation  is a \emph{Baxter permutation}
if there exist no indices  such that  or .
Thus, Baxter permutations are those that do not contain 
and .  Permutations with less than  elements are
trivially Baxter permutations, and for permutations on  elements
the non-Baxter permutations are exactly  and .
Baxter permutations are well studied, and their asymptotic behaviour
is known (see, e.g., OEIS A001181~\cite{OEIS}).

We have the following lemma:

\begin{lemma}\label{lem:baxter}
Suppose  is a Baxter permutation, stored in an array 
such that .  If an encoding that can recover all range
minimum and maximum queries is constructed on , then  can be
recovered from the encoding.
\end{lemma}

\begin{proof}
In order to recover the permutation, it suffices to show that we can
perform pairwise comparisons on any two elements in  using range
minimum and range maximum queries. The proof follows by induction on
.

For the base case, for  there is exactly one permutation, so there
is nothing to recover. Thus, let us assume that the lemma holds for all
permutations on less than  elements.  For a permutation on 
elements, consider the sub-permutation induced by the array prefix
 and suffix .  These subpermutations must be
Baxter permutations, since deleting elements from the prefix or suffix
of a Baxter permutation cannot create a  or a .  Thus,
it suffices to show that we can compare  and , as all
the remaining pairwise comparisons can be performed by the induction
hypothesis.

Let  and  be the indices of
the minimum and maximum elements in the array, respectively. If
 or  we can compare  and , so
assume .  Without loss of generality we consider the
case where : the opposite case is symmetric (i.e., replacing
 with ), and  because . Consider an arbitrary index , and the result of
comparing  to  and  to  (that can be done by
the induction hypothesis, as ).  The result is a partial
order on three elements, and is either:
\begin{enumerate}
  \item One of the two chains  or , in which case we are done since  and  can be
    compared; or
 \item A partial order in which  is the minimum or maximum
   element, and  is incomparable with .
\end{enumerate}
If we are in the latter case for all , then let  if  is the minimum element in this partial order, and  otherwise. Because of how  and  were chosen,  and
. If we consider the values of  for all ,
there must exist two indices  such that  and
.  Therefore, the indices  form the forbidden
pattern , unless .  \qed
\end{proof}

\begin{theorem}\label{thm:min-max-lb}
Any data structure encoding range minimum and maximum queries
simultaneously must occupy  bits, for
sufficiently large values of .
\end{theorem}

\begin{proof}
Let  be the number of Baxter permutations on  elements.  It
is known (cf.~\cite{OEIS}) that . Since we can encode and recover each
one by the procedure discussed in Lemma~\ref{lem:baxter}, our encoding
data structure must occupy at least 
bits, if  is sufficiently large. \qed
\end{proof}

\section{Optimal Encodings for Top-\texorpdfstring{}{k} Queries\label{sec:top-k}}

In this section we use  to denote a range
top- query on the subarray .  The solution to such a query
is an ordered list of indices  such that
 is the -th largest element in .

\subsection{Upper Bound for Encoding Top-\texorpdfstring{}{k} Queries\label{sec:encoding-topk}}

Like the encoding for range min-max queries, our encoding for range
top- queries is based on representing the changes to a certain
structure as we scan through the array .  Each prefix in the array
will correspond to a different structure. We denote the structure,
that we will soon describe, for prefix  as , for all
. The structure  will allow us to answer
 for any . Our encoding will store the
differences between  and  for all .
Let us begin by defining a single instance for an arbitrary .

We first define the directed graph  with vertices
labelled , and where an edge  iff both
 and  for all .  We call
 the \emph{dominance graph} of , and say 
\emph{dominates} , or  is dominated by , if .  Next consider the out-degree  of the vertex labelled
 in . We define an array , where
 for .  The structure
 is defined as follows: take the array , and for each
entry  such that , replace  with
.  We use the notation  to refer to the -th
array entry in the structure . We refer to an index  to
be \emph{active} iff , and as \emph{inactive}
otherwise.  We note that  is reminiscent of the one-sided
top- structure of Grossi et al.~\cite{GINRS13}.

\begin{figure}
\centering
\includegraphics[width=0.9\textwidth]{update_staircases.pdf}
\caption{\label{fig:update}Geometric interpretation of how the
  structure  is updated to .  In the example , and the value of each active element in the array is represented
  by its height.  Black circles denote  values in the array
  , whereas crosses represent  values, and  values
  (inactive elements) are not depicted.  When the new point (empty
  circle) is inserted to the structure on the left, it increments the
  counters of the smallest  active elements, resulting in the
  picture on the right representing .}
\end{figure}

\begin{lemma}
\label{lem:active}
The total ordering of elements ,
where  are the active indices in
, can be recovered by examining only .
\end{lemma}

\begin{proof}
We scan the structure  from index  down to , maintaining
a total ordering on the active elements seen so far.  Initially, we
have an empty total ordering.  At each active location  the
value  indicates how many active elements in locations
 are larger than .  This follows since an
inactive element cannot dominate an active element in the graph
. Thus, we can insert  into the current total ordering
of active elements. \qed
\end{proof}

We define the \emph{size} of  as follows: .  The key observation is that
the structure  can be constructed from  using the
following procedure:

\begin{enumerate}
\item Compute the value . This
  quantity is always nonnegative, as we add one new element to the
  large staircase, which increases the size by at most .

\item Find the  indices among the active elements in
   such that their values in  are the smallest via
  Lemma~\ref{lem:active}.  Denote this set of indices as
  .

\item For each , set 
  iff , and 
  otherwise.

\item Add the new element at the end of the array, setting
  .
\end{enumerate}

Thus, to construct  all that is needed is  and the
value : see Figure~\ref{fig:update}.  This implies that by
storing  for  we can build any .

\begin{theorem}
\label{thm:top-k-ub}
Solutions to all queries  can be encoded in at most
 bits of space.
\end{theorem}

\begin{proof}
Suppose we store the bitvector .  This bitvector contains no more than  zero
bits.  This follows since each active counter can be incremented 
times before it becomes inactive.  Thus, storing the bitvector
requires no more than  bits.

Next we prove that this is all we need to answer a query .  We
use the encoding to construct . We know that
for every element at inactive index  in  there are at
least  elements with larger value in . Consequently,
these elements need not be returned in the solution, and
it is enough to recover the indices of the top- values among the elements
at active indices at least . We apply  Lemma~\ref{lem:active} on  to
recover these indices and return them as the solution.
\qed
\end{proof}








\subsection{Lower Bound for Encoding Top-\texorpdfstring{}{k} Queries}

The goal of this section is to show that the encoding from
Section~\ref{sec:encoding-topk} is, in fact, optimal. The first
observation is that all structures  for  can be
reconstructed with  queries.

\begin{lemma}
\label{lem:reconstruction-topk}
Any  can be reconstructed with  queries.
\end{lemma}

\begin{proof}
To reconstruct , we execute the query  for
each .  If index  is returned as the -th
largest element in , then by definition there are exactly
 elements in locations  with value larger than
.  Thus,  is an active location and .  If  is not returned by the query, then it is inactive
and we set .  \qed
\end{proof}

Recall that we encode all structures by specifying
.  We call an -tuple
of nonnegative integers 
\emph{valid} if it encodes some , i.e.,
if there exists at least one array  consisting of distinct
integers such that the structure constructed for  is exactly
the encoded , for every . Then the number of
bits required by the encoding is at least the logarithm of the number
of valid -tuples
. Our encoding from
Section~\ref{sec:encoding-topk} shows this number is at most
, but we need to argue in the other direction,
which is far more involved.

Recall that the size of a particular  is .  We would like to argue that there are many
valid -tuples .  This
will be proven in a series of transformations.

\begin{lemma}
\label{lem:valid-tuple-topk}
If  is valid, then for
any 
where , the tuple
 is also
valid.
\end{lemma}


\begin{proof}
Let  be an array such that the structure constructed for
 is exactly , for every . By
definition of , we have that .  Denote the number of
active elements in  with the corresponding entry set to
 as  for . For any , we can adjust
 so that it is larger than exactly the  smallest active
elements in . Thus, choosing any  results in a valid
.  Since , we have , proving the claim.  \qed
\end{proof}

Every valid -tuple  corresponds
in a natural way to a walk of length  in a plane, where we start
at  and perform steps of the form , for
.  We consider a subset of all such walks. Denoting
the current position by , we require that  is an
integer from . Under
such conditions, any walk corresponds to a valid -tuple
, because we can choose
 and apply
Lemma~\ref{lem:valid-tuple-topk}. Therefore, we can focus on counting
such walks.

The condition  is not
easy to work with, though. We will count more restricted walks
instead. A -restricted nonnegative walk of length  starts at
 and consists of  steps of the form , where
 for , such that the current
-coordinate is always nonnegative.  is an arbitrary set of
integers.

\begin{lemma}
\label{lem:restricted-walks-topk}
The number of valid -tuples is at least as large as the number
of -restricted nonnegative walks of length
.
\end{lemma}

\begin{proof}
We have already observed that the number of valid -tuples is at
least as large as the number of walks consisting of  steps of the
form , where  for
. We distinguish a subset of such walks, where the
first  steps are of the form , and then we always stay
above (or on) the line . Under such restrictions,  implies , so counting
-restricted nonnegative walks gives us a lower bound on
the number of valid -tuples.  \qed
\end{proof}

We move to counting -restricted nonnegative walks of length
. Again, counting them directly is non-trivial, so we introduce a
notion of -restricted returning walk of length , where we ignore
the condition that the current -coordinate should be always
nonnegative, but require the walk ends at .

\begin{figure}
\centering
\includegraphics[width=\textwidth]{cyclic_rot.pdf}
\caption{\label{fig:cyclic-rotation-topk}Left: a -restricted walk ending
  at . Right: a cyclic rotation of the walk on the left such
  that the walk is always nonnegative.}
\end{figure}

\begin{lemma}
\label{lem:cycle-lemma-topk}
The number of -restricted nonnegative walks of length  is at
least as large as the number of -restricted returning walks of
length  divided by .
\end{lemma}

\begin{proof}
This follows from the so-called cycle lemma~\cite{DM47}, but we prefer
to provide a simple direct proof.  We consider only -restricted
nonnegative walks of length  ending at , and denote their
set by . The set of -restricted returning walks of length 
is denoted by . The crucial observation is that a cyclic rotation
of any walk in  is also a walk in . Moreover, there is
always at least one such cyclic rotation which results in the walk
becoming nonnegative (see
Figure~\ref{fig:cyclic-rotation-topk}). Therefore, we can define a
total function , that takes a walk  and
rotates it cyclically as to make it nonnegative. Because there are
just  cyclic rotations of a walk of length , any element of
 is the image of at most  elements of  through
. Therefore,  as claimed.  \qed
\end{proof}

The only remaining step is to count -restricted
returning walks of length .  This is equivalent to
counting ordered partitions of  into parts
, where  for
every .  This follows since a partition of
size  corresponds to a step of size .

\begin{lemma}
The number of ordered partitions of  into  parts, where every
part is from , is at least , where
.
\end{lemma}

\begin{proof}
The number of ordered partitions of  into  parts, where there
are no restrictions on the sizes of the parts, is simply
. To take the restrictions into the account, we
first split  into blocks of length  (except for the last block,
which might be shorter). This creates  blocks. Then, we
additionally split the blocks into smaller parts, which ensures that
all parts are from . We restrict the smaller parts, so that the
first and the last smaller part in every block is strictly positive.
This ensures that given the resulting partition into parts, we can uniquely
reconstruct the blocks. Therefore, we only need to count the number of
ways we can split the blocks into such smaller parts, and by standard
reasoning this is at least .  This follows
by conceptually merging the last element in block  with the first
element in block , so that no further partitioning can happen
between them, and then partitioning the remaining set into 
pieces. Every such partition corresponds to a distinct restricted
partition obtained by splitting between the merged elements, which creates
 additional blocks. 
\qed
\end{proof}



We are ready to combine all the ingredients. Setting
, ,

and substituting, the number of bits required by the encoding is:

\noindent
Using the entropy function as a lower bound, this is at least
, where .  Thus, we
have the following theorem:

\begin{theorem}
\label{thm:top-k-lb}
For sufficiently large values of , any data structure that encodes
range top- queries must occupy  bits of space, where , and  can be selected to be any positive integer.  If , then
 can be chosen such that  and , yielding that the lower bound is  bits.
\end{theorem}


\section{\label{sec:datastructure}Data Structure for Top-\texorpdfstring{}{k} Queries}

In this section we show how to use the encoding of
Section~\ref{sec:encoding-topk} to construct a data structure that
supports top- queries efficiently.

The high-level idea is to decompose the array into blocks, and
construct a new array by storing the  largest elements in each
block.  Then, we build a naive structure over the new (short) array,
called the macro structure, and additionally store a small separate
structure for every block, called the micro structure. This is a
standard approach in succinct data structures, but as soon as we try
to apply it in the top- setting, quite a few difficulties
appear. The micro structures should be based on the encoding from
Section~\ref{sec:encoding-topk}, which in turn is based on encoding
how the 's change. But these changes can be, in some cases,
very non-local, and hence it is not obvious how the blocks should be
defined. This problem also occurs in, for example, encodings for
balanced parenthesis, where the so-called pioneers approach is
used~\cite{GRRR06}.  Here the situation is even more complex, and we
start with developing an appropriate decomposition through a series of
technical lemmas.  Then, using the decomposition, we construct the
macro structure, which allows us to answer any query spanning more
than one block, and the micro structure, which allows us to answer any
query fully inside a single block.

\subsection{Good Decompositions}

Consider the array , and the structure  at each array index
.  Recall that the structure  is an array, where
each entry is an integer drawn from the range .  For technical
reasons we define  to be an empty array.  See
Table~\ref{tab:twoseq} for an example of these definitions for .

\begin{table}
\centering
\caption{\label{tab:twoseq}Suppose .  We give the structures  for  in the following
  table. The encoding for  is: .}
\begin{tabular}{|r||c|c|c|c|c|c|c|c|c|}
\hline 
    & 1 & 2 & 3 & 4 & 5 & 6 & 7 & 8 & 9 \\
\hline
    & 46 & 31 & 93 & 16 & 45 & 77 & 25 & 57 & 26 \\
\hline
\hline
   &  &   &   &   &   &   &   &   &    \\
\hline 
   & {\bf 0} &   &   &   &   &   &   &   &    \\
\hline 
   & {\bf 0} & {\bf 0} &   &   &   &   &   &   &    \\
\hline 
   & {\bf 1} & {\bf 1} & {\bf 0} &   &   &   &   &   &    \\
\hline 
   & {\bf 1} & {\bf 1} & {\bf 0} & {\bf 0} &   &   &   &   &    \\
\hline 
   & {\bf 1} & {\bf 2} & {\bf 0} & {\bf 1} & {\bf 0} &   &   &   &    \\
\hline 
   & {\bf 2} & {\bf 2} & {\bf 0} & {\bf 2} & {\bf 1} & {\bf 0} &   &   &    \\
\hline 
   & {\bf 2} & {\bf 2} & {\bf 0} & {\bf 2} & {\bf 1} & {\bf 0} & {\bf 0} &   &    \\
\hline 
   & {\bf 2} & {\bf 2} & {\bf 0} & {\bf 2} & {\bf 2} & {\bf 0} & {\bf 1} & {\bf 0} &    \\
\hline 
   & {\bf 2} & {\bf 2} & {\bf 0} & {\bf 2} & {\bf 2} & {\bf 0} & {\bf 2} & {\bf 0} & {\bf 0}  \\ 
\hline
\end{tabular}
\end{table}


Let  be the set of all indices such
that  for ; this
set will include the index .  Furthermore, define .  In the example, , and .  Note that the encoding
described in Section~\ref{sec:encoding-topk} is such that  for .

Conceptually, we divide the range  into disjoint
\emph{even-blocks} of length : , for some
parameter  that we will fix later, and without loss of
generality, assume that  divides .  We use the notation
 to denote the range  for .

Our goal is to decompose the array into a collection of disjoint
\emph{blocks}.  Each block will have the property that it consists of
a range of at most  contiguous array elements, and will be also
contained within at most one even-block.  We refer to blocks that span
a single array element as \emph{singletons}.

Suppose our decomposition  consists of  blocks,
, and that block 
consists of the contiguous range  in , where , , and .  We call 
\emph{good} if:

\begin{enumerate}[label=\bfseries D\arabic*]

\item \label{en:size-const} Size Constraint: the total number of
  blocks is .

\item \label{en:weight-const} Weight Constraint: Consider the changes
  in the structures  that occur as we
  scan the indices of an arbitrary block , from left to
  right.  A good decomposition has that the number of changes (i.e.,
  increment operations) occurring in the structures as a result of the
  elements in a block is relatively small, if the block is not a
  singleton.  Formally, we have that  for  if  is not a
  singleton.  Note that this implies that the bit string
  
  has length at most .

\item \label{en:window-const} Window Constraint: Consider the changes
  in the structures that occur as we process each individual block.
  The indices of the structures that change are located in a
  relatively small range, if the block is not a singleton.  Formally,
  suppose that  for some .  Then we have that  for some ,
  if the block  is not a singleton.  We call
   the \emph{window} of block .

\end{enumerate}

The remainder of this section proves that we can construct a good
decomposition.

\begin{lemma}\label{lem:decomposition}
There is a good decomposition  of the array .
\end{lemma}

\begin{proof}
We describe a procedure for computing a decomposition satisfying these
conditions.  For each position , we define the
\emph{weight} .  The weight of a range in  is
equal to the sum of the weights of the positions it spans. Positions
with weight larger than  are called \emph{fat}, and will be
singletons in our decomposition.  Since each  corresponds to
 zero bits in the encoding plus one, and there are at most 
zero bits, the number of fat elements is at most .

Consider the remaining non-fat elements.  We combine these non-fat
elements into  blocks such that the weights of the ranges
is at most .  This can be done by iteratively merging pairs of
blocks (initially blocks are just individual non-fat elements), until
the sum of the weight of any two adjacent blocks exceeds .  When
this happens, every other block will have weight at least , and
by the argument above there can be at most  such blocks.
Furthermore, we subdivide these blocks along the boundaries of
even-blocks, introducing at most  additional blocks.  

We refer to the above decomposition as the \emph{initial
  decomposition}.  The initial decomposition satisfies
conditions~\ref{en:size-const} (in fact it has  blocks
rather than ), and~\ref{en:weight-const}, but not
necessarily~\ref{en:window-const}.  Thus, we must further refine the
blocks in order to ensure to create a good decomposition.  We do this by
splitting them using an iterative procedure that we now describe.

For each block  in the
initial decomposition, we scan it from left to right, calling the
current position .  We will split it into a (potentially large)
number of new blocks.  At each step, there are two cases depending on
whether the set  is
contained within a single even-block.  
\begin{enumerate}

\item If it is, then we extend the current block which begins at
  position  by adding position  to it.

\item If not, then we split the current block between positions  and , i.e., set .  Furthermore, when this
  occurs we make position  a singleton block. We then recursively
  apply the same procedure to the remaining unscanned part of the
  block adjusting the parameters appropriately.  Thus, we have
  introduced two additional blocks.
\end{enumerate}

Such a refinement clearly has the desired window property.  However,
the difficulty is arguing that the second case only occurs  times.  To show this, we use a charging argument in which each
split is charged to the rightmost even-block 
containing a position in .  We
will bound the number of times  can be charged for a
split by .

We say a position is -active if it is active in structure .
Consider the -active elements immediately before a split
occurs.  Consider the position  such that  and  is maximum.  We have that 
since  is, by definition, -active.  Moreover, since a
split occurred, there must be some block  where  containing a position  such that .  Since  is also -active this implies that
there are at most  -active positions contained in
, whose corresponding elements have values larger than
.  Thus, when a split occurs, all but at most  of the
-active locations contained in  are
incremented in .  Furthermore, any location not incremented
must be among the  largest values in .  Thus,
after  split operations, all but the  largest active locations
become inactive.  Since each split increments at least one location in
 at most  additional splits occur before all
elements in  become inactive.  Overall, at most  splits can occur before all elements in
 become inactive.

Since there are  even-blocks, we have that the total number of
blocks created by splits (or otherwise) is , completing
the proof. \qed
\end{proof}

\subsection{Navigating the Encoding}

Before discussing the data structures we store, we require an
additional result, called an \emph{indexable dictionary},
by Raman, Raman, and Rao~\cite{RRR07}:

\begin{lemma}[\cite{RRR07}]\label{lem:rrr-id} Let  be a
  bit vector of length  bits, containing  one bits.  In the
  word-RAM model with word size  bits, there is a data
  structure of size  bits that supports the
  following operations in  time, for any :
\begin{enumerate}
\item : return the bit at index  in .
\item : return the number of bits with
  value  in , iff .  If , then a flag is returned
  indicating that the operation cannot be supported.
\item : return the index of the -th
  bit with value .
\end{enumerate}
\end{lemma}


We apply Theorem~\ref{lem:decomposition} to partition  into
 blocks ,
where  is some parameter that will be fixed later on. We then
construct the following indexes:

\begin{enumerate}

\item \emph{Block index:} This is the rank/select data structure of
  Lemma~\ref{lem:rrr} constructed on a bit vector of length 
  marking the block boundaries.  This allows us to find the start of
  an arbitrary block in constant time. This bit vector occupies:

\noindent 
bits of space, by Lemma~\ref{lem:rrr}.

\item \emph{Encoding index:} Consider the bit vector storing the
  encoding  (described in Section~\ref{sec:encoding-topk}) on
  . For each zero bit in the encoding , we say that bit is
  \emph{associated} with the one bit immediately to its right.  That
  is, the zero bit at position  is associated with the one bit in
  position .  Since the -th one bit
  in the encoding is representing element , each zero bit
  associated with this one bit can also be said to be associated with
  . Suppose  is part of a block  which is
  contained in even-block  and has a window contained
  in even-block .  The  bits associated with
  position  come in exactly two flavors:

  \begin{enumerate}
    \item Internal increment: if the  bit corresponds an increment
      operation in  that occurs inside even-block 
    \item Window increment: if the  bit corresponds an increment
      operation in  that occurs inside the window 
  \end{enumerate}
  
  Suppose that for each  we create two bit vectors
   and .  These two bit vectors
  will be of the form  and , respectively,
  where  is the number of internal increments associated
  with position  and  is the number of window increments
  associated with position .  Note that . Let  and  be the
  concatenation of the  and  bit
  vectors, respectively.  Both of these bit vectors together have 
  one bits, and  zero bits.  Thus, storing  and
   in the smaller of the two representations discussed
  (either Lemma~\ref{lem:rrr} or \ref{lem:rrr-id}) will occupy  bits in
  total.  Note that we cannot perform rank operations on arbitrary
  positions in these bit vectors using the bound just stated, though
  we can perform arbitrary select operations.



\end{enumerate}

\begin{lemma}\label{lem:subarray-enc}
Using the above data structures we can recover the length  suffix
of the structure  for any ,  and  in  time.
\end{lemma}

\begin{proof}
Let , and consider the
range of  between .  This range
contains all the one bits in  associated with elements
, and also the zero bits associated
with these one bits that are internal increments.  Furthermore the
length of this range in  is at most , since
even in the case where every position in the even-block is a
singleton, the number of internal increments for each of these is
upper bounded by the length of the even-block, .  Thus, to recover
the fragment of the structure , we construct an array of
length  in which each index stores a 
bit number.  We process the internal increments associated with the
elements , , ..., etc. in order, calling the current
position , where . We maintain the total
ordering over all currently active elements in length 
suffix of  as follows.  Suppose position  is
associated with  internal increments (we can determine this by
comparing  and  in  time using the
encoding index).  We insert position  into the total order as
the -th smallest element, set its counter value to , and
increment the counters associated with the  smallest elements.  If
an incremented counter exceeds , then we remove it from the
total order.  Maintaining the total ordering as a linked list is
sufficient to process the fragment in  time per
position .  Since there are at most  positions, the
total time is . \qed
\end{proof}



\begin{lemma}\label{lem:subarray-query}
Given a subarray  that is contained within a block, we
can return a list  such that  stores the position of the
-th largest element in  in  time.
\end{lemma}

\begin{proof}
Using Lemma~\ref{lem:subarray-enc} we can build the length  suffix of the structure , which stores 
-bit numbers.  Once we have this length
 array, we scan it from right to left, constructing the total
order of elements in  by Lemma~\ref{lem:active}.  As
before, using a linked list to store the total order is sufficient to
achieve the claimed time bound. \qed
\end{proof}

\subsection{Version Control}

One issue that arises is that to answer queries we will need to
construct fragments of the structure  for various values of
, which are not necessarily short suffixes.  In particular, given a
block , we wish to be able to reconstruct its
\emph{window fragment}, which is the fragment of the structure
 corresponding to the window of block .
Suppose the window is even-block
. Lemma~\ref{lem:subarray-enc} only allows us to
construct the length  suffix of structure , rather
than the window fragment of .  Thus, we are interested
in how much space is required to recover a window fragment given what
we can recover using Lemma~\ref{lem:subarray-enc}.

\begin{lemma}
Suppose block  has window .  The
difference  between the window fragment of
 and the length  suffix of  can be
stored using  bits.  Using , in
addition to the other data structures described thus far, we can
construct the window fragment of  in time .
\end{lemma}

\begin{proof}
Lemmas~\ref{lem:subarray-enc} and~\ref{lem:active} allow us to recover
the total order  of the -active elements in the
window fragment in  time.  Consider the sequence of
positions in the array ,  that have window
increments associated with them occurring within the window fragment,
where  and .  Each element  can
be mapped to a position  in the total order .  It
is sufficient to record the  largest values in this mapping, as all
-active positions represented in  which are
smaller than the -th largest such value will become
-inactive.  Storing how these  values interleave with the
ordering  requires at most 
bits of space.  Note that we do not need to know the positions where
these elements occur in  in order to reconstruct the window
fragment, just their positions in the total ordering ,
which contains at most  elements. \qed
\end{proof}

We store  for each  (recall  is the
number of blocks).  This requires  bits of space in total.



\subsection{Decomposing Queries}

Any range top- query is either fully within a single block, or
consists of three parts: a suffix of a block  that we
call the \emph{left part}, then a number of full blocks
 that we call the
\emph{middle part}, and finally a prefix of a block 
that we call the \emph{right part}.  Note that any of these three
parts may be an empty range. Using the block index we can determine
these parts in  time.

We construct a new array  by keeping the  largest elements from
every block (if a block is a singleton, this is just one element) and
normalizing all the elements by sorting.  is stored explicitly and
augmented with a range maximum query structure, which allows us to
locate the  largest element in any query range via a three-sided
range reporting query: this can be done in  time and
 bits of space, using successive queries to a range
maximum structure built over  since we have access to these
elements.

Additionally, for every  such that  appears in , i.e., is
one of the  largest elements in its block, we store the positions
of the first  larger elements on its left in . This requires
space  bits.


\subsection{Wrap Up}

Now that we have described all of the data structures, we can explain
how to extract the positions of the top- elements, given a query
range .  The algorithm will consist of first finding the
positions of the top- elements in the middle part, and the total
ordering of elements in the left and right parts.  Extracting the
solution from the middle part is trivial, since we have a top- data
structure explicitly stored on the top- elements in each block.
Extracting the total ordering of elements from the left (or right)
part can be done by applying Lemma~\ref{lem:subarray-query} to the
even-block containing the left or right part.

At this point, we have at most three lists ,, and ,
storing positions of the top elements from the left, middle, and right
parts respectively, i.e.,  is the position of the -th
largest element in list . We now argue that we can merge these
lists.

\begin{lemma}
Suppose we are given a query .  A list  can be constructed
such that  is the position of the -th largest element, for , in  in time .
\end{lemma}

\begin{proof}
First, we construct the three lists ,  and  as
described above in time .  Then we merge the lists 
(the left part) with the list  (the middle part).  This is done
by examining the left pointers of each position in .  Consider
the subset  of positions in the
left part such that  has a left pointer to , for
.  If , then implies that  is
the -th largest element in the combination of the left and
middle parts.  Otherwise, it implies that  is not in the
top- in the combination of the two parts.  Using this procedure we
merge the lists  and , calling the result .

Next we describe how to merge  and  (the right part).  Recall
that the right part is a prefix of some block .  We
reconstruct the window fragment of  using
.  We then scan through  up to
position , performing window increments on the window fragment by
reading .  Let .  We read the window increments of
 from the range .  Since
 is not a singleton block (otherwise it would be
fully contained in the middle part), we have that the length of this
range in  is bounded by .  We process the window
increments in order to reconstruct the range  spanned
by the window of  in the structure .  During
this process, considering a position , we observe
that if , then ,
unless position  had been made inactive by a previous window
increment earlier in the process.  If  is not in
, then we can infer that 
immediately.  Thus, it is possible to insert the positions
 into the list  to construct the final list 
containing the top- positions in .  \qed

\end{proof}

From the above lemmas, we immediately get the following theorem:

\begin{theorem}
There is a data structure occupying
 bits of space,
and supports range top- queries in  time.
\end{theorem}

By setting , for a strictly increasing
function , we get the following result:

\begin{corollary}
For any strictly increasing function , there is a data structure
occupying  bits of space, and
supports range top- queries in  time.
\end{corollary}

\subsection{Improvement to Space Bound}

Our final theorem argues that we can slightly improve the space bound:

\begin{theorem}
\label{thm:ds-final} 
For any strictly increasing function , there is a data structure
occupying  bits
of space, and supports range top- queries in  time.
\end{theorem}

\begin{proof}
We observe that we need not store a  in the bit vector
 for elements that are not in the top- of their
prefix of their even block, as such elements perform no window
increments.  Initially, this does not seem to buy us anything, since
every position can be in the top- of the prefix of its even block,
but in this case we can take the reversal of the array.  We call an
element \emph{bad} if it is in the top- of the prefix or suffix of
its even block, and \emph{good} otherwise.

To bound the number of bad positions, consider the top- elements
in each even-block.  No other elements can be bad, since there is a
subset of size at least  of these top- elements on either its
right or left.  Next consider a good element.  It can only contribute
a one bit to  in  or to the reverse of , but not
both.  Thus, we have  elements contributing  one bits to the window encodings for either  or its
reverse.  We therefore need only record  one bits for the window encoding
bit vector of  or its reverse.  This reduces the leading term of
the space cost to .  To correct for
the fact that we have removed one bits from , we must
adjust select operations on this bit vector by explicitly storing, for
each block, how many elements in the block are good.  Then, when we
process the window increments in a block, we can determine whether an
element is good by examining its internal increments.  This adds an
overhead of  bits of space and
adds an  time cost for determining which elements are good
in a block. \qed
\end{proof}



\bibliographystyle{splncs03}
\bibliography{biblio}

\newpage

\appendix

\section{\label{sec:reduction}Lower bound for Unsorted Range Top-\texorpdfstring{}{k}}

Let a \emph{sorted} range top- query denote the problem of
returning the indices  of the  largest values in
a query range , in ascending order: i.e.,  is the
-th largest value.  Let an \emph{unsorted} range top- query
denote the weaker query in which the indices  are
returned in an arbitrary order.

\begin{lemma}
If  is the number of bits required to store an
encoding of sorted range top- queries on an array , then
at least  bits are required to store an encoding
of unsorted range top- queries.
\end{lemma}

\begin{proof}
Suppose there exists an encoding for unsorted range top- queries
that requires strictly less than  bits.  We will
show that such an encoding can be used to construct an encoding for
sorted range top- queries that occupies strictly less than
 bits.  We pad the input array  with 
additional values  such that 
for all  and .  We now claim that the
unsorted encoding for the padded array can be used to recover
solutions to all sorted range top-k queries on ranges in .
Given a query range , we examine the solutions to unsorted
range top- queries .  Let
 denote the set of indices in , ,  where  is the minimum
index such that , for .  By the method we use to pad , it implies that , since the solution to query  is
the set of indices in .  Thus, the index of the -th
largest element in the sorted solution can be extracted by computing
 for .  This follows
since the smallest element in  is removed, and a new
elemented added to create .  Therefore, we have a
contradiction, since any encoding for the sorted variant must occupy
 bits, and we have given an encoding that occupies
strictly less than  bits. \qed
\end{proof}

Thus, for  the previous lemma, combined with
Theorem~\ref{thm:top-k-lb} (which provides the function
), implies that the space required for the unsorted
encoding on an array of  elements is within additive lower order
terms of the space required for the sorted encoding on  elements.
\end{document}
