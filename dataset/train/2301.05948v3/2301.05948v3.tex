\pdfoutput=1


\documentclass[11pt]{article}
\usepackage{authblk}
\usepackage[utf8]{inputenc}

\usepackage[final]{acl}
\pagestyle{plain}
\usepackage{verbatim}
\usepackage{times}
\usepackage{latexsym}
\usepackage{booktabs}
\usepackage{tabulary}





\usepackage[draft]{minted}

\usepackage{hyperref,xcolor}
\usepackage{supertabular,booktabs}

\usepackage{hyperref}

\usepackage[T1]{fontenc}


\usepackage[utf8]{inputenc}

\usepackage{microtype}
\usepackage{longtable}

\newcommand\N{480}



\title{tasksource: A Dataset Harmonization Framework \\
for Streamlined NLP Multi-Task Learning and Evaluation} 



\author[1]{Damien Sileo}


\affil[1]{Univ. Lille, Inria, CNRS, Centrale Lille, UMR 9189 - CRIStAL, F-59000 Lille, France}
\affil[ ]{\url{damien.sileo@inria.fr}}

\begin{document}


\maketitle
\begin{abstract}
The HuggingFace Datasets Hub hosts thousands of datasets, offering exciting opportunities for language model training and evaluation. However, datasets for a specific task type often have different schemas, making harmonization challenging\footnote{\url{https://xkcd.com/927/}}. Multi-task training or evaluation necessitates manual work to fit data into task templates. Several initiatives independently tackle this issue by releasing harmonized datasets or providing harmonization codes to preprocess datasets into a consistent format. We identify patterns across previous preprocessing efforts, such as column name mapping and extracting specific sub-fields from structured data in a column. We then propose a structured annotation framework that ensures our annotations are fully exposed and not hidden within unstructured code. We release a dataset annotation framework and dataset annotations for more than 500 English tasks\footnote{\url{https://github.com/sileod/tasksource}}. These annotations include metadata, such as the names of columns to be used as input or labels for all datasets, which can save time for future dataset preprocessing, regardless of whether our framework is utilized. We fine-tune a multi-task text encoder on all tasksource tasks, outperforming every publicly available text encoder of comparable size in an external evaluation\footnote{\href{https://hf.co/sileod/deberta-v3-base-tasksource-nli}{\texttt{hf.co/sileod/deberta-v3-base-tasksource-nli}}}.

\end{abstract}

\section{Introduction}

Datasets are a key ingredient in modern artificial natural language processing (NLP). 

Language understanding models trained on unannotated corpora need to be evaluated, and individual datasets or benchmarks with multiple datasets provide an objective measure of targeted model capabilities. Supervised fine-tuning on annotated datasets also leads to better evaluations, and multi-task learning (MTL) \citep{Caruana1993MultitaskLA} or extreme MTL \citep{aribandi2022ext}, i.e. MTL with many tasks, improves robustness.


The HuggingFace Datasets \citep{2020HuggingFace-datasets} Hub hosts thousands of datasets. However, running evaluations or MTL on many datasets requires manual work because of a lack of standardization. Fine-tuning a model on multiple datasets requires alignment of datasets formats, even with a single task type (e.g. natural language inference). Because of that, various initiatives assemble datasets or preprocessing code to ease multi-task learning or benchmarking. However, they either distribute prepossessed copies of the datasets or preprocessing code associated with each dataset. Section \ref{sec:relatedwork} enumerates previous works enacting these two approaches.

The previous preprocessing codes implicitly use some metadata, such as mappings between column names and fields of a task, but extracting it is quite difficult. Code is not disentangled from metadata.
We propose a very concise dataset annotation format by relying on patterns reoccurring across several preprocessings. Most annotations fit in a single line, e.g:
\begin{minted}{python}
scitail = Classification(
  'sentence1',
  'sentence2',
  'gold_label')
\end{minted} 
The SciTail \citep{scitail} dataset on HF-Hub, noted \texttt{scitail\_ds}\footnote{\url{https://hf.co/datasets/scitail}} \citep{scitail} can be standardized by calling the \texttt{tasksource.scitail} function, and associated metadata can be retrieved with \mintinline{python}|tasksource.scitail.dict()|.

We annotate \N\ tasks, focusing on discriminative tasks to complement previous work better. We train a \texttt{deberta-base} text encoder on all of them simultaneously (Section \ref{sec:model}) leading to unprecedented model performance (Section \ref{sec:results}).

\section{Related work \label{sec:relatedwork}}
Various works harmonize existing datasets by either sharing preprocessed copies or preprocessings. Tasksource is a collection of preprocessings, and it is the largest for tasks excluding text generation tasks.
Text generations tasks have a relatively simple format (optional input text, and output text), and previous work such as  PromptSource \citep{bach2022promptsource} and SuperNatural Instructions\cite{supernaturalinstructions} did not provide structured annotations, as defined in section \ref{sec:datasetparsing}, but these can still be combined with acceptable efforts. 

\paragraph{Preprocessed copies}
BIG-Bench \citep{bigbench}, BigBio \citep{fries2022bigbio}, Natural and SuperNatural Instructions \citep{naturalinstructions,supernaturalinstructions}, PragmEval \citep{sileo-etal-2022-pragmatics}, UnifiedQA \citep{2020unifiedqa}, TweetEval \citep{barbieri2020tweeteval}, DiscoEval \citep{mchen-discoeval-19}, Silicone \citep{chapuis-etal-2020-hierarchical}, LexGLUE \citep{chalkidis-etal-2022-lexglue}, SetFit 
 \citep{tunstall2022efficient} distribute preprocessed copies of the original data with standardized format.

\paragraph{Collections of preprocessings}
SentEval \citep{conneau-etal-2017-supervised},  Jiant \citep{pruksachatkun-etal-2020-jiant}, BLUE \cite{peng2019transfer}, MetaEval \citep{sileo-moens-2022-analysis}, CrossFit \citep{ye-etal-2021-crossfit}, PromptSource \citep{bach2022promptsource} distribute the code required to jointly use some datasets with initially distinct structures. ExMix \citep{aribandi2022ext} is not released to our knowledge. The Muppet \citep{aghajanyan-etal-2021-muppet} authors did not release their preprocessing either.

Our work also pertains to extreme MTL \citep{aribandi2022ext,aghajanyan-etal-2021-muppet} and dataset count scaling.


\section{Structured dataset annotation \label{sec:datasetparsing}}

We define \textit{dataset parsing} as the mapping of a dataset into a task template. 

A task template is a type of task, like paraphrase detection, associated with a predetermined set of fields. For example, Paraphrase detection can be mapped to a task template \textsc{ParaphraseDetection(Sentence1, Sentence2, Label)}

A dataset is a set of examples with named and typed columns. \texttt{quora} is an example of a dataset hosted on the HuggingFace Datasets Hub \citep{2020HuggingFace-datasets}, illustrated in Table \ref{tab:quora}.


\begin{table}[h]
\begin{tabulary}{.85\linewidth}{LCL}
\toprule
\textbf{questions (sequence)} &
\textbf{is\_duplicate (bool)} \\ \midrule
\{ "id": {[} 1, 2 {]}, "text": {[} "What is the step by step guide to invest in share market in india?", "What is the step by step guide to invest in share market?" {]} \} &
  false \\
...& \\ \bottomrule
\end{tabulary}
\caption{One row of the Quora dataset, as hosted on the HuggingFace Datasets Hub. \label{tab:quora}}
\end{table}

A dataset parser for a specific dataset is a function that maps the whole dataset, or examples, to a task format, which can be \textsc{ParaphraseDetection} here.

As seen above, some benchmarks distribute harmonized datasets. This approach can save computations but can waste storage space, and make it harder to track all the design decisions that were applied to the original dataset. Users can also implement parsers themselves, or rely on external libraries to process examples on a restricted set of tasks. The previous preprocessings codes do not disentangle data and logic, and cannot be seen as semantic dataset annotations. This complicates the combinations of different preprocessing. Previous preprocessings also contain repetitive boilerplate code\footnote{i.e. \url{https://github.com/INK-USC/CrossFit/blob/master/tasks/aqua_rat.py}}.

We decompose  dataset parsing logic from annotations with  based on two observations:

(1) The fields of task type (e.g. \textsc{Sentence1},\textsc{Sentence2} for \textsc{ParaphraseDetection} can often be independently mapped to functions of dataset examples. Therefore, we can annotate a dataset with a task type, then annotate each field of a task type with a function that extracts the desired information from a dataset example.

(2) The field mapping functions are often selecting a column from examples: in that case, they can be annotated with the name of the relevant columns. Sometimes, as in the Quora dataset in Table \ref{tab:quora}, they are selecting a path from a nested structure: in that case, they can be annotated with a path. Fields can also be mapped to a constant -- some multiple-choice question-answering datasets always use the first choice as the correct choice and have an implicit constant label equal to 0. A field can also be mapped to a concatenation of the text of different columns, which can also be annotated with parameters.




\section{Tasksource dataset annotation format}


Once a dataset is annotated with a task type, each field of the task type has to be annotated with a function that takes an example from the dataset and returns the intended part of the example.
For brevity, we can annotate a field with a string \texttt{s} to denote the function \mintinline{python}|lambda x:x[s]|

The tasksource backend handles the annotations and turns them into harmonizing preprocessing. We consider 3 general task types:

\textsc{Classification(text1, text2, labels)} where \textsc{LABELS} has to be a function that takes an example and returns a class index. It can also return a float for regression tasks, or a fixed-size list for multi-label classification. 
\textsc{text1} takes a dataset example as input and returns the text extracted from the example.
\textsc{text2} is optional and is here to leverage the fact that most text encoders process text pairs with special care.


\textsc{MultipleChoice(prompt, 
choices, labels)}:
\textsc{choices} has to be a function that returns a list of text choices (the number of choices can differ across examples) extracted from an example. For concision, it can also be a list of column names to denote a list of textual choices already available in the example.  \textsc{labels} has to return the index of the correct choice (most tasks have only one correct answer).

\textsc{TokenClassification(tokens, labels)} where \textsc{tokens} takes an example as input and returns to a list of already split tokens,  \textsc{labels} return a list of labels aligned to the tokens ( label annotates the  token).



We also provide 3 structured function factories to cover additional use cases while exposing their behavior with parameters.

 \paragraph{\texttt{get}} enables to access nested objects. \mintinline{python}|get.questions.text[0]| is equivalent to \mintinline{python}|lambda x:x['questions']['text'][0]|

\paragraph{\texttt{constant}} provides constant functions. \texttt{constant(x)} is equivalent to \mintinline{python}|lambda *_:x|.

\paragraph{\texttt{cat}} concatenates multiple columns that contain strings. \mintinline{python}|cat(col1 col2)| is equivalent to \mintinline{python}|lambda x:x[col1]+x[col2]|.

\mbox{} 

An annotation to parse the Quora dataset in Table \ref{tab:quora} can then be written as follows:
\begin{minted}{python}
quora = Classification(
  text1=get.questions.text[0], 
  text2=get.questions.text[1],
  labels='is_duplicate')
\end{minted}

For completeness, we also allow optional \texttt{preprocess} and \texttt{postprocess} arguments to a task type. They should be functions that take the full dataset as input and return a dataset. We found this feature to be necessary in a few cases where datasets had unusable labels (e.g. negative label indexes) that caused errors, or to edit the metadata of a dataset, like the name of the labels when it needs to be changed.

\section{Tasksource annotations}
We select English datasets available on the HuggingFace Datasets Hub. We only consider discriminative tasks (Classification, Multiple-choice, Token Classification). We crawled all the tasks tagged with the English Language, and the Text-Classification task type\footnote{\url{https://hf.co/datasets?language=language:en&task_categories=task_categories:text-classification&sort=downloads}}
or Multiple Choice tag\footnote{\url{https://hf.co/datasets?task_categories=task_categories:multiple-choice&sort=downloads}}, as of January 2023.

As many tags are missing, to increase the coverage, we crawled the 1000 most popular datasets and used heuristics to identify discriminative tasks with labels with their fields names. We then ran a \texttt{fasttext} \citep{joulin2016fasttext} \texttt{langid} classifier to filter out untagged datasets with non-English text.

We only annotate datasets that do not require the user to manually download data or sign an agreement. We exclude datasets that require a particular library, with the exception of BIG-bench.
We also exclude tasks where high accuracy is not desirable, such as bias probing tasks \citep{nangia-etal-2020-crows} where accuracy measures bias, and tasks with input length that mostly exceeds 256 tokens.

 We  manually deduplicate the datasets which can be available individually or in benchmarks.

We also annotate the mapping between split names and train/validation/test splits. When the test splits are obfuscated (labels unavailable), we split the validation set and use half of it as a test set. Our goal is to reduce friction and individually submitting model test predictions to data owners can take a lot of time.
When no split is available, we do a 80/10/10\% split. We use a fixed 0 random seed. to help reproducibility.

Label handling was one of the pain points of the testing of the preprocessing functions. The tasksource backend preprocesses text labels to map them to integers. 

The Table in Appendix \ref{sec:appendix} enumerates all datasets annotated in the current version of tasksource\footnote{Annotations: \url{https://github.com/sileod/tasksource/blob/main/src/tasksource/tasks.py}}

\section{Pretraining a model on tasksource \label{sec:model}}
To demonstrate the potential of tasksource, we fine-tune a single \texttt{deberta-base-v3} \citep{he2021debertav3}\footnote{This is the best-performing unsupervisedly pretrained text encoder of this size according to the GLUE Benchmark \citep{wang2019glue}.} text encoder on all tasksource tasks.

Following BERT \citep{devlin-etal-2019-bert} standard setup, for token-classification tasks, we use a softmax classifier on top of the last layer encoded tokens to predict the token classes. For classification tasks and multiple-choice tasks, we use a classifier on top of the \texttt{[CLS]} sentinel token last layer.

We assign each task a different classification layer, but we tie the label weights (not biases) to each other if they are all identical. 

We oversample datasets by a factor of 2 if they have less than  examples then cap dataset size to  examples to foster dataset diversity. We randomly sample a task for each batch with a frequency proportional to the capped training dataset size and we add a learnable task-specific sentinel token to the shared sentinel token. We drop the task-specific token  of the time to teach the model to also work without these task embeddings, to reduce mismatch when using our model with the vanilla DeBERTa architecture.  We also noticed that this tended to improve general accuracy, since this forces cooperation across tasks.

We limit the number of choices to 4 for multiple-choice tasks, to limit redundant computations, as some datasets have more than 100 choices.

We use a learning rate of , a sequence length of 256, and a batch size of 24, with 16 accumulation steps to stabilize the multi-task optimization \citep{yu2020gradient}. We did not perform hyperparameter optimization.

We used the \texttt{tasknet}\footnote{Tasknet \citep{sileod22-tasknet} is 
 interface Huggingface Datasets with Huggingface Trainer.} library and a single RTX-6000 24GB GPU for 7 days (20k steps).
Using tasksource with tasknet enables concise multi-task training\footnote{\url{https://colab.research.google.com/drive/1iB4Oxl9_B5W3ZDzXoWJN-olUbqLBxgQS?usp=sharing}}.
\section{Results \label{sec:results}}

As of January 2023, an early version of our model ranks first among 3574 base-sized\footnote{This corresponds to 86M encoder parameters excluding embeddings.} model on  the \textit{Model Recycling} \citep{choshen2022start} external evaluation\footnote{\url{https://ibm.github.io/model-recycling}}
This evaluation comprises 36 representative English NLP tasks (Consisting of sentiment, NLI, Twitter, topic classification, and other general classification tasks), over 5 random seeds. These results are competitive with \texttt{deberta-large} models on GLUE. We did not observe any sign of over-fitting  yet which suggests that the network might still be undertrained.

\section{Conclusion}

We described a semantic, structured, concise, expressive dataset preprocessing annotation framework, which is associated with a parser and annotations, that can greatly facilitate new experiments for multi-task learning and improve reproducibility. We only scratched the surface of the potential of this generated task collection due to computational limitations. For future work, we plan to use tasksource to fully automate dataset parsing on new datasets with machine learning techniques to learn the parsing process. We also plan to work on a multilingual extension of tasksource annotations.

\bibliography{all,all_addendum}
\bibliographystyle{acl_natbib}
\onecolumn
\appendix
\section{Currently annotated preprocessings \label{sec:appendix}}
\begin{longtable}{lll}
\toprule
{} & preprocessing & task type \\
\midrule
\endfirsthead

\toprule
{} & preprocessing & task type \\
\midrule
\endhead
\midrule
\multicolumn{3}{r}{{Continued on next page}} \\
\midrule
\endfoot

\bottomrule
\endlastfoot
0 & glue/mnli \citep{N18-1101} & Classification \\
1 & glue/qnli \citep{N18-1101} & Classification \\
2 & glue/rte \citep{N18-1101} & Classification \\
3 & glue/wnli \citep{N18-1101} & Classification \\
4 & glue/mrpc \citep{N18-1101} & Classification \\
5 & glue/qqp \citep{N18-1101} & Classification \\
6 & glue/stsb \citep{N18-1101} & Classification \\
7 & super\_glue/boolq \citep{clark2019boolq} & Classification \\
8 & super\_glue/cb \citep{demarneff_simons_tonhauser_2019} & Classification \\
9 & super\_glue/multirc \citep{MultiRC2018} & Classification \\
10 & super\_glue/wic \citep{DBLP:journals/corr/abs-1808-09121} & Classification \\
11 & super\_glue/axg \citep{rudinger-EtAl:2018:N18} & Classification \\
12 & anli/a1 \citep{nie2019adversarial} & Classification \\
13 & anli/a2 \citep{nie2019adversarial} & Classification \\
14 & anli/a3 \citep{nie2019adversarial} & Classification \\
15 & babi\_nli/lists-sets \citep{weston2015towards} & Classification \\
16 & babi\_nli/basic-deduction \citep{weston2015towards} & Classification \\
17 & babi\_nli/positional-reasoning \citep{weston2015towards} & Classification \\
18 & babi\_nli/basic-coreference \citep{weston2015towards} & Classification \\
19 & babi\_nli/three-supporting-facts \citep{weston2015towards} & Classification \\
20 & babi\_nli/path-finding \citep{weston2015towards} & Classification \\
21 & babi\_nli/three-arg-relations \citep{weston2015towards} & Classification \\
22 & babi\_nli/yes-no-questions \citep{weston2015towards} & Classification \\
23 & babi\_nli/time-reasoning \citep{weston2015towards} & Classification \\
24 & babi\_nli/indefinite-knowledge \citep{weston2015towards} & Classification \\
25 & babi\_nli/counting \citep{weston2015towards} & Classification \\
26 & babi\_nli/size-reasoning \citep{weston2015towards} & Classification \\
27 & babi\_nli/compound-coreference \citep{weston2015towards} & Classification \\
28 & babi\_nli/basic-induction \citep{weston2015towards} & Classification \\
29 & babi\_nli/single-supporting-fact \citep{weston2015towards} & Classification \\
30 & babi\_nli/simple-negation \citep{weston2015towards} & Classification \\
31 & babi\_nli/two-arg-relations \citep{weston2015towards} & Classification \\
32 & babi\_nli/two-supporting-facts \citep{weston2015towards} & Classification \\
33 & babi\_nli/conjunction \citep{weston2015towards} & Classification \\
34 & sick/label \citep{marelli-etal-2014-sick} & Classification \\
35 & sick/relatedness \citep{marelli-etal-2014-sick} & Classification \\
36 & sick/entailment\_AB \citep{marelli-etal-2014-sick} & Classification \\
37 & snli \citep{snli:emnlp2015} & Classification \\
38 & scitail/snli\_format \citep{scitail} & Classification \\
39 & hans \citep{DBLP:journals/corr/abs-1902-01007} & Classification \\
40 & WANLI \citep{liu-etal-2022-wanli} & Classification \\
41 & recast/recast\_verbcorner \citep{poliak-etal-2018-collecting} & Classification \\
42 & recast/recast\_megaveridicality \citep{poliak-etal-2018-collecting} & Classification \\
43 & recast/recast\_sentiment \citep{poliak-etal-2018-collecting} & Classification \\
44 & recast/recast\_ner \citep{poliak-etal-2018-collecting} & Classification \\
45 & recast/recast\_kg\_relations \citep{poliak-etal-2018-collecting} & Classification \\
46 & recast/recast\_factuality \citep{poliak-etal-2018-collecting} & Classification \\
47 & recast/recast\_puns \citep{poliak-etal-2018-collecting} & Classification \\
48 & recast/recast\_verbnet \citep{poliak-etal-2018-collecting} & Classification \\
49 & probability\_words\_nli/reasoning\_1hop \citep{sileo2022probing} & Classification \\
50 & probability\_words\_nli/usnli \citep{sileo2022probing} & Classification \\
51 & probability\_words\_nli/reasoning\_2hop \citep{sileo2022probing} & Classification \\
52 & nan-nli/joey234--nan-nli & Classification \\
53 & nli\_fever & Classification \\
54 & breaking\_nli & Classification \\
55 & conj\_nli & Classification \\
56 & fracas & Classification \\
57 & dialogue\_nli & Classification \\
58 & mpe & Classification \\
59 & dnc & Classification \\
60 & recast\_white/fnplus & Classification \\
61 & recast\_white/sprl & Classification \\
62 & recast\_white/dpr & Classification \\
63 & joci & Classification \\
64 & robust\_nli/IS\_CS & Classification \\
65 & robust\_nli/LI\_LI & Classification \\
66 & robust\_nli/ST\_WO & Classification \\
67 & robust\_nli/PI\_SP & Classification \\
68 & robust\_nli/PI\_CD & Classification \\
69 & robust\_nli/ST\_SE & Classification \\
70 & robust\_nli/ST\_NE & Classification \\
71 & robust\_nli/ST\_LM & Classification \\
72 & robust\_nli\_is\_sd & Classification \\
73 & robust\_nli\_li\_ts & Classification \\
74 & gen\_debiased\_nli/snli\_seq\_z & Classification \\
75 & gen\_debiased\_nli/snli\_z\_aug & Classification \\
76 & gen\_debiased\_nli/snli\_par\_z & Classification \\
77 & gen\_debiased\_nli/mnli\_par\_z & Classification \\
78 & gen\_debiased\_nli/mnli\_z\_aug & Classification \\
79 & gen\_debiased\_nli/mnli\_seq\_z & Classification \\
80 & add\_one\_rte & Classification \\
81 & imppres/presupposition\_all\_n\_presupposition \citep{jeretic-etal-2020-natural} & Classification \\
82 & imppres/presupposition\_possessed\_definites\_existence \citep{jeretic-etal-2020-natural} & Classification \\
83 & imppres/presupposition\_cleft\_uniqueness\citep{jeretic-etal-2020-natural} & Classification \\
84 & imppres/presupposition\_question\_presupposition\citep{jeretic-etal-2020-natural} & Classification \\
85 & imppres/presupposition\_possessed\_definites\_uniqueness\citep{jeretic-etal-2020-natural} & Classification \\
86 & imppres/presupposition\_only\_presupposition\citep{jeretic-etal-2020-natural} & Classification \\
87 & imppres/presupposition\_both\_presupposition\citep{jeretic-etal-2020-natural} & Classification \\
88 & imppres/presupposition\_change\_of\_state\citep{jeretic-etal-2020-natural} & Classification \\
89 & imppres/presupposition\_cleft\_existence\citep{jeretic-etal-2020-natural} & Classification \\
90 & imppres/implicature\_quantifiers/prag \citep{jeretic-etal-2020-natural} & Classification \\
91 & imppres/implicature\_numerals\_2\_3/prag \citep{jeretic-etal-2020-natural} & Classification \\
92 & imppres/implicature\_numerals\_10\_100/prag \citep{jeretic-etal-2020-natural} & Classification \\
93 & imppres/implicature\_modals/prag \citep{jeretic-etal-2020-natural} & Classification \\
94 & imppres/implicature\_connectives/prag \citep{jeretic-etal-2020-natural} & Classification \\
95 & imppres/implicature\_gradable\_verb/prag \citep{jeretic-etal-2020-natural} & Classification \\
96 & imppres/implicature\_gradable\_adjective/prag \citep{jeretic-etal-2020-natural} & Classification \\
97 & imppres/implicature\_quantifiers/log \citep{jeretic-etal-2020-natural} & Classification \\
98 & imppres/implicature\_numerals\_2\_3/log \citep{jeretic-etal-2020-natural} & Classification \\
99 & imppres/implicature\_numerals\_10\_100/log \citep{jeretic-etal-2020-natural} & Classification \\
100 & imppres/implicature\_gradable\_adjective/log \citep{jeretic-etal-2020-natural} & Classification \\
101 & imppres/implicature\_connectives/log \citep{jeretic-etal-2020-natural} & Classification \\
102 & imppres/implicature\_modals/log \citep{jeretic-etal-2020-natural} & Classification \\
103 & imppres/implicature\_gradable\_verb/log \citep{jeretic-etal-2020-natural} & Classification \\
104 & glue\_diagnostics/diagnostics & Classification \\
105 & hlgd \citep{Laban2021NewsHG} & Classification \\
106 & paws/labeled\_final \citep{paws2019naacl} & Classification \\
107 & paws/labeled\_swap \citep{paws2019naacl} & Classification \\
108 & quora & Classification \\
109 & medical\_questions\_pairs \citep{mccreery2020effective} & Classification \\
110 & glue/cola \citep{N18-1101} & Classification \\
111 & glue/sst2 \citep{N18-1101} & Classification \\
112 & utilitarianism \citep{hendrycks2020ethics} & Classification \\
113 & amazon\_counterfactual/en \citep{oneill2021i} & Classification \\
114 & insincere-questions & Classification \\
115 & toxic\_conversations & Classification \\
116 & TuringBench \citep{huggingface:dataset} & Classification \\
117 & trec \citep{li-roth-2002-learning} & Classification \\
118 & vitaminc/tals--vitaminc \citep{schuster-etal-2021-get} & Classification \\
119 & hope\_edi/english \citep{chakravarthi-2020-hopeedi} & Classification \\
120 & rumoureval\_2019/RumourEval2019 \citep{gorrell-etal-2019-semeval} & Classification \\
121 & ethos/binary \citep{mollas2020ethos} & Classification \\
122 & ethos/multilabel \citep{mollas2020ethos} & Classification \\
123 & tweet\_eval/emotion \citep{barbieri2020tweeteval} & Classification \\
124 & tweet\_eval/irony \citep{barbieri2020tweeteval} & Classification \\
125 & tweet\_eval/offensive \citep{barbieri2020tweeteval} & Classification \\
126 & tweet\_eval/sentiment \citep{barbieri2020tweeteval} & Classification \\
127 & tweet\_eval/stance\_abortion \citep{barbieri2020tweeteval} & Classification \\
128 & tweet\_eval/stance\_atheism \citep{barbieri2020tweeteval} & Classification \\
129 & tweet\_eval/stance\_climate \citep{barbieri2020tweeteval} & Classification \\
130 & tweet\_eval/stance\_feminist \citep{barbieri2020tweeteval} & Classification \\
131 & tweet\_eval/stance\_hillary \citep{barbieri2020tweeteval} & Classification \\
132 & tweet\_eval/emoji \citep{barbieri2020tweeteval} & Classification \\
133 & tweet\_eval/hate \citep{barbieri2020tweeteval} & Classification \\
134 & discovery/discovery \citep{sileo-etal-2019-mining} & Classification \\
135 & pragmeval/squinky-informativeness \citep{DBLP:journals/corr/Lahiri15} & Classification \\
136 & pragmeval/squinky-implicature \citep{DBLP:journals/corr/Lahiri15} & Classification \\
137 & pragmeval/verifiability \citep{park2014identifying} & Classification \\
138 & pragmeval/squinky-formality \citep{DBLP:journals/corr/Lahiri15} & Classification \\
139 & pragmeval/emobank-valence \citep{buechel-hahn-2017-emobank} & Classification \\
140 & pragmeval/emobank-dominance \citep{buechel-hahn-2017-emobank} & Classification \\
141 & pragmeval/emobank-arousal \citep{buechel-hahn-2017-emobank} & Classification \\
142 & pragmeval/switchboard \citep{Godfrey:1992:STS:1895550.1895693} & Classification \\
143 & pragmeval/mrda \citep{shriberg2004icsi} & Classification \\
144 & pragmeval/sarcasm \citep{OrabySarc} & Classification \\
145 & pragmeval/persuasiveness-premisetype \citep{Persuasion2018Ng} & Classification \\
146 & pragmeval/persuasiveness-eloquence \citep{Persuasion2018Ng} & Classification \\
147 & pragmeval/persuasiveness-claimtype \citep{Persuasion2018Ng} & Classification \\
148 & pragmeval/persuasiveness-specificity \citep{Persuasion2018Ng} & Classification \\
149 & pragmeval/gum \citep{Zeldes2017} & Classification \\
150 & pragmeval/emergent \citep{Ferreira2016EmergentAN} & Classification \\
151 & pragmeval/persuasiveness-strength \citep{Persuasion2018Ng} & Classification \\
152 & pragmeval/stac \citep{asher-etal-2016-discourse} & Classification \\
153 & pragmeval/pdtb \citep{prasad-etal-2008-penn} & Classification \\
154 & pragmeval/persuasiveness-relevance \citep{Persuasion2018Ng} & Classification \\
155 & silicone/meld\_s \citep{chen2018emotionlines} & Classification \\
156 & silicone/sem \citep{mckeown2011semaine} & Classification \\
157 & silicone/oasis \citep{leech2003generic} & Classification \\
158 & silicone/meld\_e \citep{chen2018emotionlines} & Classification \\
159 & silicone/maptask \citep{thompson1993hcrc} & Classification \\
160 & silicone/iemocap \citep{busso2008iemocap} & Classification \\
161 & silicone/dyda\_e \citep{li2017dailydialog} & Classification \\
162 & silicone/dyda\_da \citep{li2017dailydialog} & Classification \\
163 & lex\_glue/eurlex \citep{chalkidis-etal-2021-multieurlex} & Classification \\
164 & lex\_glue/scotus \citep{spaeth2020} & Classification \\
165 & lex\_glue/ledgar \citep{tuggener-etal-2020-ledgar} & Classification \\
166 & lex\_glue/unfair\_tos \citep{lippi-etal-2019-claudette} & Classification \\
167 & language-identification & Classification \\
168 & imdb \citep{maas-EtAl:2011:ACL-HLT2011} & Classification \\
169 & rotten\_tomatoes \citep{Pang+Lee:05a} & Classification \\
170 & ag\_news \citep{Zhang2015CharacterlevelCN} & Classification \\
171 & yelp\_review\_full/yelp\_review\_full \citep{zhang2015character} & Classification \\
172 & financial\_phrasebank/sentences\_allagree \citep{Malo2014GoodDO} & Classification \\
173 & poem\_sentiment \citep{sheng2020investigating} & Classification \\
174 & dbpedia\_14/dbpedia\_14 \citep{lehmann2015dbpedia} & Classification \\
175 & amazon\_polarity/amazon\_polarity \citep{mcauley2013hidden} & Classification \\
176 & app\_reviews \citep{ZurichOpenRepositoryandArchive:dataset} & Classification \\
177 & hate\_speech18 \citep{gibert2018hate} & Classification \\
178 & sms\_spam \citep{Almeida2011SpamFiltering} & Classification \\
179 & humicroedit/subtask-1 \citep{hossain2019president} & Classification \\
180 & humicroedit/subtask-2 \citep{hossain2019president} & Classification \\
181 & snips\_built\_in\_intents \citep{DBLP:journals/corr/abs-1805-10190} & Classification \\
182 & banking77 \citep{Casanueva2020} & Classification \\
183 & hate\_speech\_offensive \citep{hateoffensive} & Classification \\
184 & yahoo\_answers\_topics & Classification \\
185 & stackoverflow-questions & Classification \\
186 & hyperpartisan\_news & Classification \\
187 & sciie & Classification \\
188 & citation\_intent & Classification \\
189 & go\_emotions/simplified \citep{demszky2020goemotions} & Classification \\
190 & scicite \citep{Cohan2019Structural} & Classification \\
191 & liar \citep{wang-2017-liar} & Classification \\
192 & lexical\_relation\_classification/K\&H+N \citep{wang-etal-2019-spherere} & Classification \\
193 & lexical\_relation\_classification/CogALexV \citep{wang-etal-2019-spherere} & Classification \\
194 & lexical\_relation\_classification/BLESS \citep{wang-etal-2019-spherere} & Classification \\
195 & lexical\_relation\_classification/EVALution \citep{wang-etal-2019-spherere} & Classification \\
196 & lexical\_relation\_classification/ROOT09 \citep{wang-etal-2019-spherere} & Classification \\
197 & linguisticprobing/subj\_number \citep{conneau-etal-2018-cram} & Classification \\
198 & linguisticprobing/bigram\_shift \citep{conneau-etal-2018-cram} & Classification \\
199 & linguisticprobing/top\_constituents \citep{conneau-etal-2018-cram} & Classification \\
200 & linguisticprobing/odd\_man\_out \citep{conneau-etal-2018-cram} & Classification \\
201 & linguisticprobing/past\_present \citep{conneau-etal-2018-cram} & Classification \\
202 & linguisticprobing/coordination\_inversion \citep{conneau-etal-2018-cram} & Classification \\
203 & linguisticprobing/tree\_depth \citep{conneau-etal-2018-cram} & Classification \\
204 & linguisticprobing/obj\_number \citep{conneau-etal-2018-cram} & Classification \\
205 & linguisticprobing/sentence\_length \citep{conneau-etal-2018-cram} & Classification \\
206 & crowdflower/sentiment\_nuclear\_power \citep{van2012designing} & Classification \\
207 & crowdflower/tweet\_global\_warming \citep{van2012designing} & Classification \\
208 & crowdflower/corporate-messaging \citep{van2012designing} & Classification \\
209 & crowdflower/economic-news \citep{van2012designing} & Classification \\
210 & crowdflower/airline-sentiment \citep{van2012designing} & Classification \\
211 & crowdflower/political-media-bias \citep{van2012designing} & Classification \\
212 & crowdflower/text\_emotion \citep{van2012designing} & Classification \\
213 & crowdflower/political-media-audience \citep{van2012designing} & Classification \\
214 & crowdflower/political-media-message \citep{van2012designing} & Classification \\
215 & ethics/commonsense \citep{hendrycks2020ethics} & Classification \\
216 & ethics/deontology \citep{hendrycks2020ethics} & Classification \\
217 & ethics/justice \citep{hendrycks2020ethics} & Classification \\
218 & ethics/virtue \citep{hendrycks2020ethics} & Classification \\
219 & emo/emo2019 \citep{chatterjee-etal-2019-semeval} & Classification \\
220 & google\_wellformed\_query \citep{faruqui2018identifying} & Classification \\
221 & tweets\_hate\_speech\_detection \citep{ZRoshanSharma:dataset} & Classification \\
222 & has\_part \citep{bhakthavatsalam2020dogs} & Classification \\
223 & blog\_authorship\_corpus/gender \citep{schler2006effects} & Classification \\
224 & blog\_authorship\_corpus/age \citep{schler2006effects} & Classification \\
225 & blog\_authorship\_corpus/horoscope \citep{schler2006effects} & Classification \\
226 & blog\_authorship\_corpus/job \citep{schler2006effects} & Classification \\
227 & open\_question\_type \citep{cao-wang-2021-controllable} & Classification \\
228 & health\_fact \citep{kotonya-toni-2020-explainable} & Classification \\
229 & mc\_taco \citep{ZKNR19} & Classification \\
230 & ade\_corpus\_v2/Ade\_corpus\_v2\_classification \citep{GURULINGAPPA2012885} & Classification \\
231 & circa \citep{louis_emnlp2020} & Classification \\
232 & EffectiveFeedbackStudentWriting & Classification \\
233 & promptSentiment \citep{mcauley2013hidden} & Classification \\
234 & promptNLI \citep{nie2019adversarial} & Classification \\
235 & promptSpoke & Classification \\
236 & promptProficiency & Classification \\
237 & promptGrammar \citep{warstadt2018neural} & Classification \\
238 & promptCoherence & Classification \\
239 & phrase\_similarity \citep{pham2022PiC} & Classification \\
240 & scientific-exaggeration-detection \citep{wright2021exaggeration} & Classification \\
241 & quarel & Classification \\
242 & fever-evidence-related/mwong--fever-related & Classification \\
243 & numer\_sense \citep{lin2020numersense} & Classification \\
244 & dynasent/dynabench.dynasent.r1.all/r1 \citep{potts-etal-2020-dynasent} & Classification \\
245 & dynasent/dynabench.dynasent.r2.all/r2 \citep{potts-etal-2020-dynasent} & Classification \\
246 & Sarcasm\_News\_Headline & Classification \\
247 & sem\_eval\_2010\_task\_8 \citep{hendrickx-etal-2010-semeval} & Classification \\
248 & auditor\_review/demo-org--auditor\_review & Classification \\
249 & Dynasent\_Disagreement & Classification \\
250 & Politeness\_Disagreement & Classification \\
251 & SBIC\_Disagreement & Classification \\
252 & SChem\_Disagreement & Classification \\
253 & Dilemmas\_Disagreement & Classification \\
254 & wiki\_qa \citep{YangYihMeek:EMNLP2015:WikiQA} & Classification \\
255 & cycic\_classification \citep{Kejriwal2020DoFC} & Classification \\
256 & sts-companion \citep{cer-etal-2017-semeval} & Classification \\
257 & commonsense\_qa\_2.0 & Classification \\
258 & lingnli \citep{parrish-etal-2021-putting-linguist} & Classification \\
259 & monotonicity-entailment \citep{yanaka-etal-2019-neural} & Classification \\
260 & scinli \citep{sadat-caragea-2022-scinli} & Classification \\
261 & naturallogic \citep{feng2020exploring} & Classification \\
262 & dynahate \citep{vidgen2021learning} & Classification \\
263 & syntactic-augmentation-nli \citep{min-etal-2020-syntactic} & Classification \\
264 & autotnli & Classification \\
265 & CONDAQA \citep{ravichander-et-al-2022-condaqa} & Classification \\
266 & scruples & Classification \\
267 & attempto-nli & Classification \\
268 & defeasible-nli/atomic & Classification \\
269 & defeasible-nli/snli & Classification \\
270 & help-nli \citep{yanaka-EtAl:2019:starsem} & Classification \\
271 & nli-veridicality-transitivity \citep{yanaka-etal-2021-exploring} & Classification \\
272 & natural-language-satisfiability \citep{https://doi.org/10.48550/arxiv.2211.05417} & Classification \\
273 & lonli \citep{Tarunesh2021TrustingRO} & Classification \\
274 & dadc-limit-nli \citep{Wallace2022Dynamic} & Classification \\
275 & FLUTE & Classification \\
276 & strategy-qa & Classification \\
277 & folio \citep{han2022folio} & Classification \\
278 & tomi-nli & Classification \\
279 & avicenna \citep{aghahadi2022avicenna} & Classification \\
280 & CREAK & Classification \\
281 & puzzte \citep{szomiu2021puzzle} & Classification \\
282 & spartqa-yn \citep{mirzaee-etal-2021-spartqa} & Classification \\
283 & temporal-nli \citep{thukral-etal-2021-probing} & Classification \\
284 & clcd-english & Classification \\
285 & twentyquestions & Classification \\
286 & counterfactually-augmented-imdb \citep{kaushik2020learning} & Classification \\
287 & counterfactually-augmented-snli \citep{kaushik2020learning} & Classification \\
288 & cnli \citep{huang2020cnligeneralization} & Classification \\
289 & boolq-natural-perturbations \citep{khashabi2020naturalperturbations} & Classification \\
290 & acceptability-prediction \citep{lau-etal-2015-unsupervised} & Classification \\
291 & equate \citep{ravichander2019equate} & Classification \\
292 & implicit-hate-stg1 \citep{elsherief-etal-2021-latent} & Classification \\
293 & chaos-mnli-ambiguity \citep{xzhou2022distnli} & Classification \\
294 & headline\_cause/en\_simple \citep{gusev2021headlinecause} & Classification \\
295 & logiqa-2.0-nli & Classification \\
296 & oasst1\_dense\_flat/quality & Classification \\
297 & oasst1\_dense\_flat/toxicity & Classification \\
298 & oasst1\_dense\_flat/helpfulness & Classification \\
299 & PARARULE-Plus \citep{bao2022multi} & Classification \\
300 & mindgames \citep{sileo2023mindgames} & Classification \\
301 & ambient \citep{liu-etal-2023-afraid} & Classification \\
302 & civil\_comments/toxicity \citep{DBLP:journals/corr/abs-1903-04561} & Classification \\
303 & civil\_comments/severe\_toxicity \citep{DBLP:journals/corr/abs-1903-04561} & Classification \\
304 & civil\_comments/obscene \citep{DBLP:journals/corr/abs-1903-04561} & Classification \\
305 & civil\_comments/threat \citep{DBLP:journals/corr/abs-1903-04561} & Classification \\
306 & civil\_comments/insult \citep{DBLP:journals/corr/abs-1903-04561} & Classification \\
307 & civil\_comments/identity\_attack \citep{DBLP:journals/corr/abs-1903-04561} & Classification \\
308 & civil\_comments/sexual\_explicit \citep{DBLP:journals/corr/abs-1903-04561} & Classification \\
309 & I2D2 & Classification \\
310 & hh-rlhf & MultipleChoice \\
311 & model-written-evals \citep{perez2022discovering} & MultipleChoice \\
312 & truthful\_qa/multiple\_choice \citep{lin2021truthfulqa} & MultipleChoice \\
313 & fig-qa & MultipleChoice \\
314 & bigbench/strange\_stories \citep{srivastava2022beyond} & MultipleChoice \\
315 & bigbench/arithmetic \citep{srivastava2022beyond} & MultipleChoice \\
316 & bigbench/formal\_fallacies\_syllogisms\_negation \citep{srivastava2022beyond} & MultipleChoice \\
317 & bigbench/implicatures \citep{srivastava2022beyond} & MultipleChoice \\
318 & bigbench/salient\_translation\_error\_detection \citep{srivastava2022beyond} & MultipleChoice \\
319 & bigbench/causal\_judgment \citep{srivastava2022beyond} & MultipleChoice \\
320 & bigbench/discourse\_marker\_prediction \citep{srivastava2022beyond} & MultipleChoice \\
321 & bigbench/timedial \citep{srivastava2022beyond} & MultipleChoice \\
322 & bigbench/general\_knowledge \citep{srivastava2022beyond} & MultipleChoice \\
323 & bigbench/evaluating\_information\_essentiality \citep{srivastava2022beyond} & MultipleChoice \\
324 & bigbench/cause\_and\_effect \citep{srivastava2022beyond} & MultipleChoice \\
325 & bigbench/hyperbaton \citep{srivastava2022beyond} & MultipleChoice \\
326 & bigbench/hindu\_knowledge \citep{srivastava2022beyond} & MultipleChoice \\
327 & bigbench/crass\_ai \citep{srivastava2022beyond} & MultipleChoice \\
328 & bigbench/movie\_recommendation \citep{srivastava2022beyond} & MultipleChoice \\
329 & bigbench/cifar10\_classification \citep{srivastava2022beyond} & MultipleChoice \\
330 & bigbench/logic\_grid\_puzzle \citep{srivastava2022beyond} & MultipleChoice \\
331 & bigbench/sentence\_ambiguity \citep{srivastava2022beyond} & MultipleChoice \\
332 & bigbench/fact\_checker \citep{srivastava2022beyond} & MultipleChoice \\
333 & bigbench/strategyqa \citep{srivastava2022beyond} & MultipleChoice \\
334 & bigbench/elementary\_math\_qa \citep{srivastava2022beyond} & MultipleChoice \\
335 & bigbench/temporal\_sequences \citep{srivastava2022beyond} & MultipleChoice \\
336 & bigbench/penguins\_in\_a\_table \citep{srivastava2022beyond} & MultipleChoice \\
337 & bigbench/goal\_step\_wikihow \citep{srivastava2022beyond} & MultipleChoice \\
338 & bigbench/dark\_humor\_detection \citep{srivastava2022beyond} & MultipleChoice \\
339 & bigbench/logical\_fallacy\_detection \citep{srivastava2022beyond} & MultipleChoice \\
340 & bigbench/irony\_identification \citep{srivastava2022beyond} & MultipleChoice \\
341 & bigbench/emojis\_emotion\_prediction \citep{srivastava2022beyond} & MultipleChoice \\
342 & bigbench/sports\_understanding \citep{srivastava2022beyond} & MultipleChoice \\
343 & bigbench/contextual\_parametric\_knowledge\_conflicts \citep{srivastava2022beyond} & MultipleChoice \\
344 & bigbench/intent\_recognition \citep{srivastava2022beyond} & MultipleChoice \\
345 & bigbench/crash\_blossom \citep{srivastava2022beyond} & MultipleChoice \\
346 & bigbench/real\_or\_fake\_text \citep{srivastava2022beyond} & MultipleChoice \\
347 & bigbench/ruin\_names \citep{srivastava2022beyond} & MultipleChoice \\
348 & bigbench/logical\_deduction \citep{srivastava2022beyond} & MultipleChoice \\
349 & bigbench/identify\_math\_theorems \citep{srivastava2022beyond} & MultipleChoice \\
350 & bigbench/vitaminc\_fact\_verification \citep{srivastava2022beyond} & MultipleChoice \\
351 & bigbench/hhh\_alignment \citep{srivastava2022beyond} & MultipleChoice \\
352 & bigbench/simple\_ethical\_questions \citep{srivastava2022beyond} & MultipleChoice \\
353 & bigbench/checkmate\_in\_one \citep{srivastava2022beyond} & MultipleChoice \\
354 & bigbench/similarities\_abstraction \citep{srivastava2022beyond} & MultipleChoice \\
355 & bigbench/novel\_concepts \citep{srivastava2022beyond} & MultipleChoice \\
356 & bigbench/snarks \citep{srivastava2022beyond} & MultipleChoice \\
357 & bigbench/abstract\_narrative\_understanding \citep{srivastava2022beyond} & MultipleChoice \\
358 & bigbench/social\_iqa \citep{srivastava2022beyond} & MultipleChoice \\
359 & bigbench/phrase\_relatedness \citep{srivastava2022beyond} & MultipleChoice \\
360 & bigbench/physics \citep{srivastava2022beyond} & MultipleChoice \\
361 & bigbench/gre\_reading\_comprehension \citep{srivastava2022beyond} & MultipleChoice \\
362 & bigbench/logical\_sequence \citep{srivastava2022beyond} & MultipleChoice \\
363 & bigbench/winowhy \citep{srivastava2022beyond} & MultipleChoice \\
364 & bigbench/movie\_dialog\_same\_or\_different \citep{srivastava2022beyond} & MultipleChoice \\
365 & bigbench/riddle\_sense \citep{srivastava2022beyond} & MultipleChoice \\
366 & bigbench/metaphor\_understanding \citep{srivastava2022beyond} & MultipleChoice \\
367 & bigbench/moral\_permissibility \citep{srivastava2022beyond} & MultipleChoice \\
368 & bigbench/nonsense\_words\_grammar \citep{srivastava2022beyond} & MultipleChoice \\
369 & bigbench/bbq\_lite\_json \citep{srivastava2022beyond} & MultipleChoice \\
370 & bigbench/physical\_intuition \citep{srivastava2022beyond} & MultipleChoice \\
371 & bigbench/navigate \citep{srivastava2022beyond} & MultipleChoice \\
372 & bigbench/reasoning\_about\_colored\_objects \citep{srivastava2022beyond} & MultipleChoice \\
373 & bigbench/metaphor\_boolean \citep{srivastava2022beyond} & MultipleChoice \\
374 & bigbench/analytic\_entailment \citep{srivastava2022beyond} & MultipleChoice \\
375 & bigbench/mnist\_ascii \citep{srivastava2022beyond} & MultipleChoice \\
376 & bigbench/misconceptions \citep{srivastava2022beyond} & MultipleChoice \\
377 & bigbench/authorship\_verification \citep{srivastava2022beyond} & MultipleChoice \\
378 & bigbench/social\_support \citep{srivastava2022beyond} & MultipleChoice \\
379 & bigbench/tracking\_shuffled\_objects \citep{srivastava2022beyond} & MultipleChoice \\
380 & bigbench/analogical\_similarity \citep{srivastava2022beyond} & MultipleChoice \\
381 & bigbench/figure\_of\_speech\_detection \citep{srivastava2022beyond} & MultipleChoice \\
382 & bigbench/understanding\_fables \citep{srivastava2022beyond} & MultipleChoice \\
383 & bigbench/question\_selection \citep{srivastava2022beyond} & MultipleChoice \\
384 & bigbench/undo\_permutation \citep{srivastava2022beyond} & MultipleChoice \\
385 & bigbench/conceptual\_combinations \citep{srivastava2022beyond} & MultipleChoice \\
386 & bigbench/unit\_interpretation \citep{srivastava2022beyond} & MultipleChoice \\
387 & bigbench/logical\_args \citep{srivastava2022beyond} & MultipleChoice \\
388 & bigbench/geometric\_shapes \citep{srivastava2022beyond} & MultipleChoice \\
389 & bigbench/code\_line\_description \citep{srivastava2022beyond} & MultipleChoice \\
390 & bigbench/fantasy\_reasoning \citep{srivastava2022beyond} & MultipleChoice \\
391 & bigbench/identify\_odd\_metaphor \citep{srivastava2022beyond} & MultipleChoice \\
392 & bigbench/empirical\_judgments \citep{srivastava2022beyond} & MultipleChoice \\
393 & bigbench/color \citep{srivastava2022beyond} & MultipleChoice \\
394 & bigbench/symbol\_interpretation \citep{srivastava2022beyond} & MultipleChoice \\
395 & bigbench/suicide\_risk \citep{srivastava2022beyond} & MultipleChoice \\
396 & bigbench/date\_understanding \citep{srivastava2022beyond} & MultipleChoice \\
397 & bigbench/cs\_algorithms \citep{srivastava2022beyond} & MultipleChoice \\
398 & bigbench/play\_dialog\_same\_or\_different \citep{srivastava2022beyond} & MultipleChoice \\
399 & bigbench/international\_phonetic\_alphabet\_nli \citep{srivastava2022beyond} & MultipleChoice \\
400 & bigbench/emoji\_movie \citep{srivastava2022beyond} & MultipleChoice \\
401 & bigbench/mathematical\_induction \citep{srivastava2022beyond} & MultipleChoice \\
402 & bigbench/implicit\_relations \citep{srivastava2022beyond} & MultipleChoice \\
403 & bigbench/anachronisms \citep{srivastava2022beyond} & MultipleChoice \\
404 & bigbench/odd\_one\_out \citep{srivastava2022beyond} & MultipleChoice \\
405 & bigbench/human\_organs\_senses \citep{srivastava2022beyond} & MultipleChoice \\
406 & bigbench/english\_proverbs \citep{srivastava2022beyond} & MultipleChoice \\
407 & bigbench/key\_value\_maps \citep{srivastava2022beyond} & MultipleChoice \\
408 & bigbench/dyck\_languages \citep{srivastava2022beyond} & MultipleChoice \\
409 & bigbench/known\_unknowns \citep{srivastava2022beyond} & MultipleChoice \\
410 & bigbench/disambiguation\_qa \citep{srivastava2022beyond} & MultipleChoice \\
411 & bigbench/entailed\_polarity \citep{srivastava2022beyond} & MultipleChoice \\
412 & bigbench/epistemic\_reasoning \citep{srivastava2022beyond} & MultipleChoice \\
413 & bigbench/presuppositions\_as\_nli \citep{srivastava2022beyond} & MultipleChoice \\
414 & blimp/sentential\_negation\_npi\_scope \citep{warstadt2019blimp} & MultipleChoice \\
415 & blimp/left\_branch\_island\_echo\_question \citep{warstadt2019blimp} & MultipleChoice \\
416 & blimp/inchoative \citep{warstadt2019blimp} & MultipleChoice \\
417 & blimp/principle\_A\_reconstruction \citep{warstadt2019blimp} & MultipleChoice \\
418 & blimp/complex\_NP\_island \citep{warstadt2019blimp} & MultipleChoice \\
419 & blimp/npi\_present\_2 \citep{warstadt2019blimp} & MultipleChoice \\
420 & blimp/existential\_there\_quantifiers\_2 \citep{warstadt2019blimp} & MultipleChoice \\
421 & blimp/wh\_vs\_that\_with\_gap \citep{warstadt2019blimp} & MultipleChoice \\
422 & blimp/superlative\_quantifiers\_1 \citep{warstadt2019blimp} & MultipleChoice \\
423 & blimp/coordinate\_structure\_constraint\_complex\_left\_branch \citep{warstadt2019blimp} & MultipleChoice \\
424 & blimp/matrix\_question\_npi\_licensor\_present \citep{warstadt2019blimp} & MultipleChoice \\
425 & blimp/principle\_A\_c\_command \citep{warstadt2019blimp} & MultipleChoice \\
426 & blimp/drop\_argument \citep{warstadt2019blimp} & MultipleChoice \\
427 & blimp/tough\_vs\_raising\_1 \citep{warstadt2019blimp} & MultipleChoice \\
428 & blimp/npi\_present\_1 \citep{warstadt2019blimp} & MultipleChoice \\
429 & blimp/coordinate\_structure\_constraint\_object\_extraction \citep{warstadt2019blimp} & MultipleChoice \\
430 & blimp/animate\_subject\_passive \citep{warstadt2019blimp} & MultipleChoice \\
431 & blimp/wh\_vs\_that\_with\_gap\_long\_distance \citep{warstadt2019blimp} & MultipleChoice \\
432 & blimp/wh\_questions\_subject\_gap\_long\_distance \citep{warstadt2019blimp} & MultipleChoice \\
433 & blimp/sentential\_subject\_island \citep{warstadt2019blimp} & MultipleChoice \\
434 & blimp/wh\_questions\_object\_gap \citep{warstadt2019blimp} & MultipleChoice \\
435 & blimp/principle\_A\_domain\_2 \citep{warstadt2019blimp} & MultipleChoice \\
436 & cos\_e/v1.0 \citep{rajani2019explain} & MultipleChoice \\
437 & cosmos\_qa \citep{huang-etal-2019-cosmos} & MultipleChoice \\
438 & dream \citep{sundream2018} & MultipleChoice \\
439 & openbookqa \citep{OpenBookQA2018} & MultipleChoice \\
440 & qasc \citep{allenai:qasc} & MultipleChoice \\
441 & quartz \citep{quartz} & MultipleChoice \\
442 & quail \citep{DBLP:conf/aaai/RogersKDR20} & MultipleChoice \\
443 & head\_qa/en \citep{vilares-gomez-rodriguez-2019-head} & MultipleChoice \\
444 & sciq \citep{SciQ} & MultipleChoice \\
445 & social\_i\_qa & MultipleChoice \\
446 & wiki\_hop/original \citep{welbl2018constructing} & MultipleChoice \\
447 & wiqa \citep{wiqa} & MultipleChoice \\
448 & piqa \citep{Bisk2020} & MultipleChoice \\
449 & hellaswag \citep{zellers2019hellaswag} & MultipleChoice \\
450 & super\_glue/copa \citep{roemmele2011choice} & MultipleChoice \\
451 & balanced-copa \citep{kavumba-etal-2019-choosing} & MultipleChoice \\
452 & e-CARE & MultipleChoice \\
453 & art \citep{anli} & MultipleChoice \\
454 & mmlu/nutrition \citep{hendryckstest2021} & MultipleChoice \\
455 & mmlu/college\_medicine \citep{hendryckstest2021} & MultipleChoice \\
456 & mmlu/philosophy \citep{hendryckstest2021} & MultipleChoice \\
457 & mmlu/global\_facts \citep{hendryckstest2021} & MultipleChoice \\
458 & mmlu/college\_mathematics \citep{hendryckstest2021} & MultipleChoice \\
459 & mmlu/college\_computer\_science \citep{hendryckstest2021} & MultipleChoice \\
460 & mmlu/college\_chemistry \citep{hendryckstest2021} & MultipleChoice \\
461 & mmlu/college\_biology \citep{hendryckstest2021} & MultipleChoice \\
462 & mmlu/clinical\_knowledge \citep{hendryckstest2021} & MultipleChoice \\
463 & mmlu/business\_ethics \citep{hendryckstest2021} & MultipleChoice \\
464 & mmlu/astronomy \citep{hendryckstest2021} & MultipleChoice \\
465 & mmlu/machine\_learning \citep{hendryckstest2021} & MultipleChoice \\
466 & mmlu/moral\_scenarios \citep{hendryckstest2021} & MultipleChoice \\
467 & mmlu/sociology \citep{hendryckstest2021} & MultipleChoice \\
468 & mmlu/us\_foreign\_policy \citep{hendryckstest2021} & MultipleChoice \\
469 & mmlu/virology \citep{hendryckstest2021} & MultipleChoice \\
470 & mmlu/world\_religions \citep{hendryckstest2021} & MultipleChoice \\
471 & mmlu/prehistory \citep{hendryckstest2021} & MultipleChoice \\
472 & mmlu/professional\_accounting \citep{hendryckstest2021} & MultipleChoice \\
473 & mmlu/professional\_law \citep{hendryckstest2021} & MultipleChoice \\
474 & mmlu/professional\_medicine \citep{hendryckstest2021} & MultipleChoice \\
475 & mmlu/professional\_psychology \citep{hendryckstest2021} & MultipleChoice \\
476 & mmlu/electrical\_engineering \citep{hendryckstest2021} & MultipleChoice \\
477 & mmlu/elementary\_mathematics \citep{hendryckstest2021} & MultipleChoice \\
478 & mmlu/anatomy \citep{hendryckstest2021} & MultipleChoice \\
479 & mmlu/abstract\_algebra \citep{hendryckstest2021} & MultipleChoice \\
480 & mmlu/medical\_genetics \citep{hendryckstest2021} & MultipleChoice \\
481 & mmlu/miscellaneous \citep{hendryckstest2021} & MultipleChoice \\
482 & mmlu/logical\_fallacies \citep{hendryckstest2021} & MultipleChoice \\
483 & mmlu/jurisprudence \citep{hendryckstest2021} & MultipleChoice \\
484 & mmlu/computer\_security \citep{hendryckstest2021} & MultipleChoice \\
485 & mmlu/international\_law \citep{hendryckstest2021} & MultipleChoice \\
486 & mmlu/human\_sexuality \citep{hendryckstest2021} & MultipleChoice \\
487 & mmlu/human\_aging \citep{hendryckstest2021} & MultipleChoice \\
488 & mmlu/high\_school\_world\_history \citep{hendryckstest2021} & MultipleChoice \\
489 & mmlu/college\_physics \citep{hendryckstest2021} & MultipleChoice \\
490 & mmlu/high\_school\_us\_history \citep{hendryckstest2021} & MultipleChoice \\
491 & mmlu/high\_school\_statistics \citep{hendryckstest2021} & MultipleChoice \\
492 & mmlu/conceptual\_physics \citep{hendryckstest2021} & MultipleChoice \\
493 & mmlu/high\_school\_psychology \citep{hendryckstest2021} & MultipleChoice \\
494 & mmlu/high\_school\_physics \citep{hendryckstest2021} & MultipleChoice \\
495 & mmlu/high\_school\_microeconomics \citep{hendryckstest2021} & MultipleChoice \\
496 & mmlu/high\_school\_mathematics \citep{hendryckstest2021} & MultipleChoice \\
497 & mmlu/econometrics \citep{hendryckstest2021} & MultipleChoice \\
498 & mmlu/high\_school\_macroeconomics \citep{hendryckstest2021} & MultipleChoice \\
499 & mmlu/high\_school\_government\_and\_politics \citep{hendryckstest2021} & MultipleChoice \\
500 & mmlu/high\_school\_geography \citep{hendryckstest2021} & MultipleChoice \\
501 & mmlu/high\_school\_european\_history \citep{hendryckstest2021} & MultipleChoice \\
502 & mmlu/high\_school\_computer\_science \citep{hendryckstest2021} & MultipleChoice \\
503 & mmlu/high\_school\_chemistry \citep{hendryckstest2021} & MultipleChoice \\
504 & mmlu/high\_school\_biology \citep{hendryckstest2021} & MultipleChoice \\
505 & mmlu/marketing \citep{hendryckstest2021} & MultipleChoice \\
506 & mmlu/management \citep{hendryckstest2021} & MultipleChoice \\
507 & mmlu/moral\_disputes \citep{hendryckstest2021} & MultipleChoice \\
508 & mmlu/formal\_logic \citep{hendryckstest2021} & MultipleChoice \\
509 & mmlu/security\_studies \citep{hendryckstest2021} & MultipleChoice \\
510 & mmlu/public\_relations \citep{hendryckstest2021} & MultipleChoice \\
511 & winogrande/winogrande\_xl \citep{ai2:winogrande} & MultipleChoice \\
512 & codah/codah \citep{chen2019codah} & MultipleChoice \\
513 & ai2\_arc/ARC-Challenge/challenge \citep{allenai:arc} & MultipleChoice \\
514 & ai2\_arc/ARC-Easy/challenge \citep{allenai:arc} & MultipleChoice \\
515 & definite\_pronoun\_resolution \citep{rahman2012resolving} & MultipleChoice \\
516 & swag/regular \citep{zellers2018swagaf} & MultipleChoice \\
517 & math\_qa & MultipleChoice \\
518 & lex\_glue/case\_hold \citep{Zheng2021} & MultipleChoice \\
519 & commonsense\_qa \citep{talmor-etal-2019-commonsenseqa} & MultipleChoice \\
520 & discosense & MultipleChoice \\
521 & medmcqa \citep{pmlr-v174-pal22a} & MultipleChoice \\
522 & aqua\_rat/tokenized \citep{ACL} & MultipleChoice \\
523 & logiqa \citep{liu2020logiqa} & MultipleChoice \\
524 & cycic\_multiplechoice \citep{Kejriwal2020DoFC} & MultipleChoice \\
525 & arct \citep{Habernal.et.al.2018.NAACL.ARCT} & MultipleChoice \\
526 & onestop\_qa \citep{starc2020} & MultipleChoice \\
527 & moral\_stories/full \citep{Emelin2021MoralSS} & MultipleChoice \\
528 & prost \citep{aroca-ouellette-etal-2021-prost} & MultipleChoice \\
529 & webgpt\_comparisons \citep{nakano2021webgpt} & MultipleChoice \\
530 & synthetic-instruct-gptj-pairwise & MultipleChoice \\
531 & wouldyourather & MultipleChoice \\
532 & summarize\_from\_feedback/comparisons \citep{stienon2020learning} & MultipleChoice \\
533 & SHP \citep{SHP} & MultipleChoice \\
534 & MedQA-USMLE-4-options-hf & MultipleChoice \\
535 & wikimedqa/medwiki \citep{sileo2023generating} & MultipleChoice \\
536 & cicero \citep{ghosal2022cicero} & MultipleChoice \\
537 & mutual \citep{mutual} & MultipleChoice \\
538 & NeQA & MultipleChoice \\
539 & quote-repetition & MultipleChoice \\
540 & redefine-math & MultipleChoice \\
541 & implicatures \citep{george2020conversational} & MultipleChoice \\
542 & race/high \citep{lai2017large} & MultipleChoice \\
543 & race/middle \citep{lai2017large} & MultipleChoice \\
544 & race-c \citep{pmlr-v101-liang19a} & MultipleChoice \\
545 & spartqa-mchoice \citep{mirzaee-etal-2021-spartqa} & MultipleChoice \\
546 & riddle\_sense \citep{lin-etal-2021-riddlesense} & MultipleChoice \\
547 & reclor \citep{yu2020reclor} & MultipleChoice \\
548 & ScienceQA\_text\_only \citep{10.1007/s00799-022-00329-y} & MultipleChoice \\
549 & ekar\_english & MultipleChoice \\
550 & path-naturalness-prediction & MultipleChoice \\
551 & cloth & MultipleChoice \\
552 & dgen & MultipleChoice \\
553 & oasst1\_pairwise\_rlhf\_reward & MultipleChoice \\
554 & conll2003/pos\_tags \citep{tjong-kim-sang-de-meulder-2003-introduction} & TokenClassification \\
555 & conll2003/chunk\_tags \citep{tjong-kim-sang-de-meulder-2003-introduction} & TokenClassification \\
556 & conll2003/ner\_tags \citep{tjong-kim-sang-de-meulder-2003-introduction} & TokenClassification \\
557 & wnut\_17/wnut\_17 \citep{derczynski-etal-2017-results} & TokenClassification \\
558 & ncbi\_disease/ncbi\_disease \citep{dougan2014ncbi} & TokenClassification \\
559 & acronym\_identification \citep{veyseh-et-al-2020-what} & TokenClassification \\
560 & jnlpba/jnlpba \citep{kim2004introduction} & TokenClassification \\
561 & species\_800/species\_800 \citep{pafilis2013species} & TokenClassification \\
562 & ontonotes\_english \citep{tjong-kim-sang-de-meulder-2003-introduction} & TokenClassification \\
563 & universal\_dependencies/en\_partut/deprel \citep{11234/1-3424} & TokenClassification \\
564 & universal\_dependencies/en\_lines/deprel \citep{11234/1-3424} & TokenClassification \\
565 & universal\_dependencies/en\_gumreddit/deprel \citep{11234/1-3424} & TokenClassification \\
566 & universal\_dependencies/en\_esl/deprel \citep{11234/1-3424} & TokenClassification \\
567 & universal\_dependencies/en\_ewt/deprel \citep{11234/1-3424} & TokenClassification \\
568 & universal\_dependencies/en\_gum/deprel \citep{11234/1-3424} & TokenClassification \\
\end{longtable} \nocite{sileo-lmrec-2022, laurer2022less}

\newpage
\section{Model Recycling results}
\begin{table}[H]
\centering
\begin{tabular}{@{}lll@{}}
\toprule
model\_name            & deberta-v3-base & +tasksource \\ \midrule
avg                    & 79.04           & \textbf{80.73}             \\
mnli (linear probe)               & -               & \textbf{93.73}             \\
20\_newsgroup          & 86.41           & \textbf{86.46}             \\
ag\_news               & 90.44           & \textbf{90.67}             \\
amazon\_reviews\_multi & 66.86           & \textbf{66.90}             \\
anli                   & 58.78           & \textbf{60.38}             \\
boolq                  & 82.99           & \textbf{85.66}             \\
cb                     & 75.00           & \textbf{82.14}             \\
cola                   & 86.57           & \textbf{87.15}             \\
copa                   & 58.40           & \textbf{81.00}             \\
dbpedia                & \textbf{79.43}  & 79.20                      \\
esnli                  & 91.93           & \textbf{91.54}             \\
financial\_phrasebank  & 84.48           & \textbf{85.20}             \\
imdb                   & 94.49           & \textbf{94.67}             \\
isear                  & 71.86           & \textbf{71.90}             \\
mnli\_mismatched       & 89.78           & \textbf{91.14}             \\
mrpc                   & \textbf{89.20}  & 88.73                      \\
multirc                & 62.26           & \textbf{63.82}             \\
poem\_sentiment        & 86.73           & \textbf{92.31}             \\
qnli                   & 93.51           & \textbf{93.72}             \\
qqp                    & 91.79           & \textbf{91.92}             \\
rotten\_tomatoes       & 90.42           & \textbf{90.99}             \\
rte                    & 82.35           & \textbf{90.61}             \\
sst2                   & 95.06           & \textbf{95.41}             \\
sst\_5bins             & 56.98           & \textbf{58.60}             \\
stsb                   & 90.28           & \textbf{91.81}             \\
trec\_coarse           & 97.76           & \textbf{96.80}             \\
trec\_fine             & \textbf{91.02}  & 90.80                      \\
tweet\_ev\_emoji       & 46.19           & \textbf{47.82}             \\
tweet\_ev\_emotion     & 83.95           & \textbf{85.71}             \\
tweet\_ev\_hate        & 56.21           & \textbf{57.47}             \\
tweet\_ev\_irony       & 79.82           & \textbf{83.04}             \\
tweet\_ev\_offensive   & 85.06           & \textbf{85.23}             \\
tweet\_ev\_sentiment   & 71.80           & \textbf{72.01}             \\
wic                    & \textbf{71.21}  & 69.44                      \\
wnli                   & \textbf{70.21}  & 67.61                      \\
wsc                    & 64.09           & \textbf{66.35}             \\
yahoo\_answers         & 72.03           & \textbf{72.07}             \\ \bottomrule
\end{tabular}
\end{table}
\end{document}
