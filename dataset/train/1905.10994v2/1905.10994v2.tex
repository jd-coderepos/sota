\documentclass{article}



\PassOptionsToPackage{round}{natbib}



\usepackage[final,nonatbib]{neurips_2019}




\usepackage{natbib}
	
\usepackage{amsmath,amsthm,amssymb,amsfonts}
\usepackage{microtype}
\usepackage{nicefrac} 
\usepackage{graphicx,subfig}
\usepackage{algorithm,algorithmic}
\usepackage{booktabs,multirow}
\usepackage{url}
\usepackage{hyperref}
\hypersetup{
    colorlinks=true,
    linkcolor=blue,
    filecolor=magenta,      
    urlcolor=blue,
    citecolor=blue,
}
\usepackage{wrapfig}
\usepackage{enumitem}
\usepackage[final]{pdfpages}


\usepackage{pifont}\newcommand{\cmark}{\ding{51}}\newcommand{\xmark}{\ding{55}}


\newcommand{\x}{\mathbf{x}}
\newcommand{\dx}{\dot{\mathbf{x}}}
\newcommand{\ddx}{\ddot{\mathbf{x}}}
\newcommand{\z}{\mathbf{z}}
\newcommand{\dz}{\dot{\mathbf{z}}}
\newcommand{\ddz}{\ddot{\mathbf{z}}}
\newcommand{\dr}{\dot{\mathbf{r}}}
\newcommand{\ddr}{\ddot{\mathbf{r}}}
\renewcommand{\L}{\mathbf{L}}
\renewcommand{\l}{{\ell}}
\newcommand{\bl}{{\boldsymbol\ell}}
\newcommand{\uv}{\mathbf{u}}
\newcommand{\y}{\mathbf{y}}
\newcommand{\h}{\mathbf{h}}
\renewcommand{\v}{\mathbf{v}}
\newcommand{\btau}{\boldsymbol{\tau}}
\newcommand{\e}{\mathbf{e}}
\renewcommand{\a}{\mathbf{a}}
\renewcommand{\t}{\mathbf{t}}
\newcommand{\f}{\mathbf{f}}
\newcommand{\g}{ {\mathbf{g} }}
\renewcommand{\r}{{\mathbf{r}}}
\newcommand{\m}{{\mathbf{m}}}
\newcommand{\p}{{\mathbf{p}}}
\newcommand{\mw}{{\mathbf{m}_w}}
\newcommand{\bg}{ {\boldsymbol\gamma}  }
\newcommand{\Y}{\mathbf{Y}}
\newcommand{\A}{\mathbf{A}}
\newcommand{\K}{\mathbf{K}}
\newcommand{\E}{\mathbb{E}}
\newcommand{\V}{\mathbb{V}}
\newcommand{\C}{\mathbf{C}}
\newcommand{\R}{\mathbb{R}}
\newcommand{\GP}{\mathcal{GP}}
\newcommand{\tL}{{\tilde{\mathcal{L}}}}
\newcommand{\0}{\mathbf{0}}
\newcommand{\N}{\mathcal{N}}
\newcommand{\X}{\mathbf{X}}
\newcommand{\s}{\mathbf{s}}
\newcommand{\dX}{\dot{\mathcal{X}}}
\newcommand{\w}{{\boldsymbol{\sigma}}}
\newcommand{\sig}{{\sigma}}
\renewcommand{\S}{{\mathbf{S}}}
\newcommand{\bS}{{\boldsymbol{\Sigma}}}
\newcommand{\bs}{{\boldsymbol{\sigma}}}
\newcommand{\bo}{\boldsymbol{\omega}}
\newcommand{\ba}{\boldsymbol{\alpha}}
\newcommand{\bb}{\boldsymbol{\beta}}
\newcommand{\bO}{\boldsymbol{\Omega}}
\renewcommand{\o}{{\omega}}
\renewcommand{\O}{{\Omega}}
\newcommand{\bmu}{{\boldsymbol{\mu}}}
\newcommand{\bt}{{\boldsymbol{\theta}}}
\newcommand{\tV}{\widetilde{V}}
\newcommand{\tU}{\widetilde{U}}
\newcommand{\tu}{\widetilde{\mathbf{u}}}
\newcommand{\tv}{\widetilde{\mathbf{v}}}
\newcommand{\tS}{\tilde{\Sigma}}
\newcommand{\tm}{\tilde{\mathbf{m}}}
\newcommand{\tmu}{\tilde{\boldsymbol{\mu}}}
\newcommand{\tg}{\tilde{\bg}}
\newcommand{\tf}{\tilde{f}}
\def\w{\mathbf{w}}
\newcommand{\Lb}{\mathcal{L}}
\newcommand{\Z}{\mathbf{Z}}
\newcommand{\W}{\mathcal{W}}
\newcommand{\tKf}{\tilde{K}_{f mm}}
\newcommand{\tKw}{\tilde{K}_{w mm}}
\newcommand{\tKg}{\tilde{K}_{\gamma mm}}
\newcommand{\tKo}{\tilde{K}_{\omega mm}}
\newcommand{\tKb}{\tilde{K}_{\beta mm}}
\newcommand{\Xt}{{\mathbf{X}_t}}
\newcommand{\Zg}{{\mathbf{Z}_g}}
\newcommand{\Zf}{{\mathbf{Z}_\mathbf{f}}}
\newcommand{\Ug}{{\mathbf{U}_g}}
\newcommand{\Uf}{{\mathbf{U}_\mathbf{f}}}
\newcommand{\ufj}{{\mathbf{u}_{\mathbf{f}j}}}
\newcommand{\ug}{{\mathbf{u}_g}}
\newcommand{\uw}{{\mathbf{u}_w}}
\newcommand{\us}{{\mathbf{u}_\sigma}}
\newcommand{\uo}{{\mathbf{u}_\omega}}
\newcommand{\ub}{{\mathbf{u}_\beta}}
\newcommand{\uf}{{\mathbf{u}_\mathbf{f}}}
\newcommand{\mf}{{\mathbf{m}_f}}
\newcommand{\Sf}{{\mathbf{S}_f}}
\newcommand{\mo}{{\mathbf{m}_\omega}}
\newcommand{\So}{{\mathbf{S}_\omega}}
\newcommand{\mb}{{\mathbf{m}_\beta}}
\newcommand{\Sb}{{\mathbf{S}_\beta}}
\newcommand{\mg}{{\mathbf{m}_\gamma}}
\newcommand{\Sg}{{\mathbf{S}_\gamma}}
\newcommand{\Sw}{{\mathbf{S}_w}}
\newcommand{\pbg}{\Phi(\bg)}
\newcommand{\pg}{\phi(\g)}
\newcommand{\Sn}{\sigma_n^2}
\newcommand{\fl}{\mathcal{L}_1}
\newcommand\numberthis{\addtocounter{equation}{1}\tag{\theequation}}
\newcommand{\bk}{\mathbf{k}}
\newcommand{\EVLI}{\textsc{evli}}
\newcommand{\VELI}{\textsc{veli}}
\DeclareMathOperator{\diag}{diag}
\DeclareMathOperator{\tr}{tr}
\DeclareMathOperator{\KL}{\textsc{kl}}
\DeclareMathOperator{\ELBO}{\textsc{elbo}}
\DeclareMathOperator{\mean}{mean}
\DeclareMathOperator{\cov}{\textbf{cov}}
\DeclareMathOperator{\var}{\textbf{var}}
\DeclareMathOperator*{\argmin}{arg\,min}
\DeclareMathOperator*{\argmax}{arg\,max}
\DeclareMathOperator{\vect}{vec}
\DeclareMathOperator{\dv}{div}

\newcommand{\Lagr}{\mathcal{L}}
\newcommand{\vS}{\mathbf{S}}
\newcommand{\ODE}{\textsc{ODE}}
\newcommand{\VAE}{\textsc{VAE}}
\newcommand{\adv}{\textsc{adv}}
\newcommand{\Disc}{\mathcal{D}}
\newcommand{\Gen}{\mathcal{G}}


\usepackage{xcolor}



\title{ODE$^2$VAE: Deep generative second order ODEs \\ with Bayesian neural networks}


\author{\c{C}a\u{g}atay~Y{\i}ld{\i}z$^{\text{1}}$, Markus~Heinonen$^{\text{1,2}}$, Harri L{\"a}hdesm{\"a}ki$^{\text{1}}$ \\
  Department of Computer Science\\
  Aalto University, Finland, FI-00076 \\
  \texttt{\{cagatay.yildiz, markus.o.heinonen, harri.lahdesmaki\}@aalto.fi}
}

\begin{document}
\maketitle

\begin{abstract}
We present Ordinary Differential Equation Variational Auto-Encoder (ODE$^2$VAE), a latent second order ODE model for high-dimensional sequential data. Leveraging the advances in deep generative models, ODE$^2$VAE can simultaneously learn the embedding of high dimensional trajectories and infer arbitrarily complex continuous-time latent dynamics. Our model explicitly decomposes the latent space into momentum and position components and solves a second order ODE system, which is in contrast to recurrent neural network (RNN) based time series models and recently proposed black-box ODE techniques. In order to account for uncertainty, we propose probabilistic latent ODE dynamics parameterized by deep Bayesian neural networks. We demonstrate our approach on motion capture, image rotation and bouncing balls datasets. We achieve state-of-the-art performance in long term motion prediction and imputation tasks.
\end{abstract}




\section{Introduction}
Representation learning has always been one of the most prominent problems in machine learning. Leveraging the advances in deep learning, variational auto-encoders (VAEs) have recently been applied to several challenging datasets to extract meaningful representations. Various extensions to vanilla VAE have achieved state-of-the-art performance in hierarchical organization of latent spaces, disentanglement and semi-supervised learning \citep{tschannen2018recent}. 

VAE based techniques usually assume a static data, in which each data item is associated with a single latent code. Hence, auto-encoder models for sequential data have been overlooked. More recently, there have been attempts to use recurrent neural network (RNN) encoders and decoders for tasks such as representation learning, classification and forecasting \citep{srivastava2015unsupervised,lotter2016deep,hsu2017unsupervised,li2018disentangled}. Other than neural ordinary differential equations (ODEs) \citep{chen2018neural} and Gaussian process prior VAEs (GPPVAE) \citep{casale2018gaussian}, aforementioned methods operate in discrete-time, which is in contrast to most of the real-world datasets, and fail to produce plausible long-term forecasts \citep{karl2016deep}. 

In this paper, we propose ODE$^2$VAEs that extend VAEs for sequential data with a latent space governed by a continuous-time probabilistic ODE. We propose a powerful second order ODE that allows modelling the latent dynamic ODE state decomposed as position and momentum. 
To handle uncertainty in dynamics and avoid overfitting, we parameterise our latent continuous-time dynamics with deep Bayesian neural networks and optimize the model using variational inference. 
We show state-of-the-art performance in learning, reproducing and forecasting  high-dimensional sequential systems, such as image sequences.
An implementation of our experiments and generated video sequences are provided at \href{https://github.com/cagatayyildiz/ODE2VAE}{https://github.com/cagatayyildiz/ODE2VAE}.

\section{Probabilistic second-order ODEs}


We tackle the problem of learning low-rank latent representations of possibly high-dimensional sequential data trajectories. We assume data sequences $\x_{0:N} := (\x_0, \x_1, \ldots, \x_N)$ with individual \emph{frames} $\x_k \in \R^D$ observed at time points $t_0, \ldots, t_N$. We will present the methodology for a single data sequence $\x_{0:N}$ for notational simplicity, but it is straighforward to extend our method to multiple sequences. The observations are often at discrete spacings, such as individual images in a video sequence, but our model also generalizes to irregular sampling. 

We assume that there exists an underlying generative low-dimensional continuous-time dynamical system, which we aim to uncover. Our goal is to learn latent representations $\z_t \in \R^d$ of the sequence dynamics with $d \ll D$, and reconstruct observations $\x_t \in \mathbb{R}^D$ for missing frame imputation and forecasting the system past observed time $t_N$.

\subsection{Ordinary differential equations}
In discrete-time sequential systems the state \emph{sequence} $\z_0, \z_1, \ldots$ is indexed by a discrete variable $k \in \mathbb{Z}$, and the state progression is governed by a transition function on the change $\Delta \z_k = \z_k - \z_{k-1}$. Examples of such models are auto-regressive models, Markov chains, recurrent models and neural network layers.

In contrast, continuous-time sequential systems model the state \emph{function} $\z_t : \mathcal{T} \to \R^d$ of a continuous, real-valued time variable $t \in \mathcal{T} = \R$. The state evolution is governed by a first-order time derivative
\begin{align}
\dz_t &:=  \frac{d \z_t}{dt} = \h(\z_t),
\end{align}
that drives the system state forward in infinitesimal steps over time. The differential $\h : \R^d \to \R^d$ induces a \emph{differential field} that covers the input space. Given an initial location vector $\z_0 \in \R^d$, the system then follows an \emph{ordinary differential equation} (ODE) model with state solutions
\begin{align}
    \z_T = \z_0 + \int_0^T \h(\z_t) dt.
\end{align}
The state solutions are in practise computed by solving this initial value problem with efficient numericals solvers, such as Runge-Kutta \citep{schober2019probabilistic}. Recently several works have proposed learning ODE systems $\h$ parametrised as neural networks \citep{chen2018neural} or as Gaussian processes \citep{heinonen18a}.


\subsection{Bayesian second-order ODEs} \label{sec:bsoode}

First-order ODEs are incapable of modelling high-order dynamics\footnote{Time-dependent differential functions $\f(\z,t)$ can indirectly approximate higher-order dynamics.}, such as acceleration or the motion of a pendulum. Furthermore, ODEs are deterministic systems unable to account for uncertainties in the dynamics. We tackle both issues by introducing Bayesian neural second-order ODEs
\begin{align}
\ddz_t &:= \frac{d^2 \z_t}{d^2 t} = \f_\W( \z_t, \dz_t ),
\end{align}
which can be reduced to an equivalent system of two coupled first-order ODEs
\begin{align}
    \Big\{
    \begin{matrix}
    \dot{\s}_t &=& \v_t \\
    \dot{\v}_t &=& \f_\W(\s_t,\v_t)
    \end{matrix}, 
    \qquad 
    \begin{bmatrix}
    \s_T \\ \v_T 
    \end{bmatrix}
    = 
    \begin{bmatrix}
    \s_0 \\ \v_0
    \end{bmatrix}
    + \int_0^T
    \underbrace{\begin{bmatrix}
    \v_t \\ \f_\W(\s_t, \v_t) 
    \end{bmatrix}}_{\tilde\f_\W( \z_t ) }
    dt, \label{eq:ode2}
\end{align}
where (with a slight abuse of notation) the state tuple $\z_t = (\s_t,\v_t)$ decomposes into the state \emph{position} $\s_t$, which follows the state \emph{velocity} (momentum) $\v_t$. The velocity or evolution of change is governed by a neural network $\f_\W(\s_t,\v_t)$ with a collection of weight parameters $\W = \{\mathbf{W}_\ell \}_{\ell=1}^L$ over its $L$ layers and the bias terms. We assume a prior $p(\W)$ on the weights resulting in a Bayesian neural network (BNN). Each weight sample, in turn, results in a deterministic ODE trajectory (see Fig.~\ref{fig:odes}).
\begin{figure}[t]
    \centering
    \includegraphics[width=\textwidth]{nips19-ode2vae-fig1.png}
    \caption{Illustration of dynamical systems. A continuous-time system underlying a discrete-time model \textbf{(a)} can be extended to a 2nd-order ODE with velocity component \textbf{(b)}. A Bayesian ODE characterises uncertain differential dynamics \textbf{(c)}, with the corresponding position-velocity phase diagram \textbf{(d)}. The gray arrows in \textbf{(d)} indicate the BNN $\f_\W(\s_t,\v_t)$ mean field wrt $p(\W)$.}
    \label{fig:odes}
\end{figure}

The BNN \emph{acceleration field} $\f_{\mathcal{W}} : \R^d \times \R^d \to \R^d$ depends on both state and velocity. For instance, in a pendulum system the acceleration $\ddz$ depends on both its current location and velocity. The system is now driven forward from starting position $\s_0$ and velocity $\v_0$, with the BNN determining only how the velocity $\v_t$ evolves. 



\subsection{Second order ODE flow}

The ODE systems are denoted as continuous normalizing flows when they are applied on random variables $\z_t$ \citep{rezende2014,chen2018ctf,grathwohl2018ffjord}. This allows following the progression of its density through the ODE. Using the instantaneous change of variable theorem \citep{chen2018ctf}, we obtain the instantaneous change of variable for our second order ODEs as
\begin{align} \label{eq-instantaneous1}
    \frac{\partial \log q(\z_t | \W)}{\partial t} = - \text{Tr} \left( \frac{d \tilde\f_\W(\z_t)}{d \z_t} \right) dt = - \text{Tr} \begin{pmatrix} \frac{{\partial \v_t}}{{\partial \s_t}} & \frac{{\partial \v_t}}{{\partial \v_t}} \\ \frac{\partial \f_\W(\s_t,\v_t) }{\partial \s_t} & \frac{\partial \f_\W(\s_t,\v_t) }{\partial \v_t} \end{pmatrix} = - \text{Tr} \left( \frac{\partial \f_\W(\s_t,\v_t) }{\partial \v_t} \right),
\end{align}
which results in the log densities over time,
\begin{align} \label{eq-instantaneous2}
\log q(\z_T | \W)  &= \log q(\z_0 | \W ) - \int_0^T \text{Tr} \left( \frac{\partial \f_\W(\s_t,\v_t) }{\partial \v_t} \right) dt.
\end{align}




































\section{ODE$^2$VAE model}

In this section we propose a novel dynamic VAE formalism for sequential data by introducing a second order Bayesian neural ODE model in the latent space to model the data dynamics. We start by reviewing the standard VAE models and then extend it to our ODE$^2$VAE model.


With auto-encoders, we aim to learn latent representations $\z \in \R^d$ for complex observations $\x \in \R^D$ parameterised by $\theta$, where often $d \ll D$. The posterior $p_\theta(\z | \x) \propto p_\theta(\x | \z) p(\z)$ is proportional to the prior $p(\z)$ of the latent variable and the \emph{decoding} likelihood $p_\theta(\x | \z)$. Parameters $\theta$ could be optimized by maximizing the marginal log likelihood but that generally involves intractable integrals. In variational auto-encoders (VAE) an amortized variational approximation $q_\phi(\z | \x) \approx p_\theta(\z | \x)$ with parameters $\phi$ is used instead 
\citep{jordan1999,kingma2013auto,rezende2014}. Variational inference that minimizes the Kullback-Leibler divergence, or equivalently maximizes the evidence lower bound (ELBO), results in efficient inference.




























\begin{figure}
    \centering
    \includegraphics[width=.99\textwidth]{fig2_v2.png}
    \caption{A schematic illustration of ODE$^2$VAE model. Position encoder ($\bmu_\s,\bs_\s$) maps the first item $\x_0$ of a high-dimensional data sequence into a distribution of the initial position $\s_0$ in a latent space. Velocity encoder ($\bmu_\v,\bs_\v$) maps the first $m$ high-dimensional data items $\x_{0:m}$ into a distribution of the initial velocity $\v_0$ in a latent space. Probabilistic latent dynamics are implemented by a second order ODE model $\tilde{\f}_\mathcal{W}$ parameterised by a Bayesian deep neural network ($\mathcal{W}$). Data points in the original data domain are reconstructed by a decoder.}
    \label{fig:fig2}  
\end{figure}

\subsection{Dynamic model}
\begin{wrapfigure}[9]{r}{.4\textwidth}
    \vspace*{-0.9cm}
\begin{align}
    \s_0 &\sim p(\s_0) \label{eq-gen1}\\
    \v_0 &\sim p(\v_0)  \\
    \s_t &= \s_0 + \int_{0}^{t} \v_\tau d\tau \\
    \v_t &= \v_0 + \int_{0}^{t} \f_{\text{true}}(\s_\tau,\v_\tau) d\tau \\ 
    \x_i &\sim p(\x_i|\s_i) \quad i \in [0,N] \label{eq-gen5}
\end{align}
\end{wrapfigure}
Building upon the ideas from black-box ODEs and variational auto-encoders, we propose to infer continuous-time latent position and velocity trajectories that live in a much lower dimensional space but still match the data well (see Fig.~\ref{fig:fig2} for illustration). 
For this, consider a generative model that consists of three components: {\em (i)} a distribution for the initial position $p(\s_0)$ and velocity $p(\v_0)$ in the latent space , {\em (ii)} true (unknown) dynamics defined by an acceleration field, and {\em (iii)} a {\em decoding} likelihood $p(\x_i|\s_i)$.
The generative model is given in Eqs.~\ref{eq-gen1}-\ref{eq-gen5}. Note that the decoding likelihood is defined only from the position variable. Velocity thus serves as an auxiliary variable, driving the position forward. 

\subsection{Variational inference}

As with standard auto-encoders, optimization of ODE$^2$VAE model parameters with respect to marginal likelihood would result in intractability and thus we resort to variational inference (see Fig.~\ref{fig:fig2}). We first combine the latent position and velocity components into a single vector $\z_t:= (\s_t,\v_t)$ for notational clarity, and assume the following factorized variational approximation for the unobserved quantities $q(\mathcal{W},\z_{0:N}|\x_{0:N}) = q(\mathcal{W})q_\text{enc}(\z_0|\x_{0:N})q_\text{ode}(\z_{1:N}|\x_{0:N},\z_0,\mathcal{W})$. As decribed in subsection \ref{sec:bsoode}, true dynamics are approximated by a BNN parameterized by $\mathcal{W}$ with the following variational approximation: $q(\mathcal{W}) = \N(\mathcal{W} | \m,s\mathbf{I})$. We use an amortized variational approximation for the latent initial position and velocity
\begin{align}
q_\text{enc}(\z_0 | \x_{0:N}) &= q_\text{enc}\left(\begin{pmatrix} \s_0 \\ \v_0 \end{pmatrix} \; \middle| \; \x_{0:N} \right) = \N \left( \begin{pmatrix} \bmu_\s(\x_{0}) \\ \bmu_\v(\x_{0:m}) \end{pmatrix}, \begin{pmatrix} \diag(\bs_\s(\x_{0})) & \0 \\ \0 & \diag(\bs_\v(\x_{0:m})) \end{pmatrix} \right) , \label{eg:qenc}
\end{align}
where $\bmu_\s,\bmu_\v,\bs_\s,\bs_\v$ are encoding neural networks. The encoder for the initial position depends solely on the first item in the data sequence $\x_0$, whereas the encoder for the initial velocity depends on multiple data points $\x_{0:m}$, where $m \le N$ is the amortized inference length. We use neural network encoders and decoders whose architectures depend on the application (see the supplementary document for details). The variational approximation for the latent dynamics $q_\text{ode}(\z_{1:N}|\x_{0:N},\z_0,\mathcal{W})$ is defined implicitly via the instantaneous change of variable for the second order ODEs shown in Eq.~\ref{eq-instantaneous1}. The initial density is given by the encoder $q_\text{enc}(\z_0 | \x_0)$, and density for later points can be solved by numerical integration using Eq.~\ref{eq-instantaneous2}. Note that we treat the entire latent trajectory evaluated at observed time points, $Z \equiv \z_{0:N}$, as a latent variable, and the latent trajectory samples $\z_{1:N}$ are solved conditioned on the ODE initial values $\z_0$ and BNN parameter values $\mathcal{W}$.  Finally, evidence lower bound (ELBO) becomes as follows (for brevity we define $X \equiv \x_{0:N}$):
\begingroup
\allowdisplaybreaks
\begin{align}
    \log p(X) &\ge \underbrace{-\KL[q(\mathcal{W},Z|X) || p(\mathcal{W},Z)] + \E_{q(\mathcal{W},Z|X)}[\log p(X|\mathcal{W},Z)] }_{\text{ELBO}}  \\ 
    &= -\E_{q(\mathcal{W},Z|X)} \left[\log \frac{q(\mathcal{W})q(Z|\mathcal{W},X)}{p(\mathcal{W})p(Z)} \right] + \E_{q(\mathcal{W},Z|X)}[\log p(X|\mathcal{W},Z)]   \\
    &= -\KL[q(\mathcal{W}) || p(\mathcal{W})] + \E_{q(\mathcal{W},Z|X)} \left[- \log \frac{q(Z|\mathcal{W},X)}{p(Z)} + \log p(X|\mathcal{W},Z) \right]   \\
    &= - \underbrace{\KL[q(\mathcal{W}) || p(\mathcal{W})]}_{\text{ODE regularization}} \label{eq:elbo} + \underbrace{\E_{q_{\text{enc}}(\z_0|X)} \left[ - \log \frac{q_{\text{enc}}(\z_0|X)}{p(\z_0)} + \log p(\x_0|\z_0) \right]}_{\text{VAE loss}} \notag \\  &\qquad + \underbrace{\sum_{i=1}^N \E_{q_{\text{ode}}(\mathcal{W},\z_i|X,\z_0)} \left[ -\log \frac{q_{\text{ode}}(\z_i|\mathcal{W},X)}{p(\z_i)} + \log p(\x_i|\z_i) \right]}_{\text{dynamic loss}} 
\end{align} 
\endgroup
where the prior distribution $p(\mathcal{W},\z_0)$ is a standard Gaussian. The prior density follows Eq.~\ref{eq-instantaneous2} with $\f_\mathcal{W}$ replaced by the unknown $\f_{\text{true}}$, which causes $p(\z_t),~t>1$ to be intractable.\footnote{Although our variational approximation model assumes deterministic second-order dynamics, the underlying true model may also have more complex or stochastic dynamics.} Thus, we resort to a simplifying assumption and place a standard regularizing Gaussian prior over $\z_{1:N}$.

We now examine each term in Eq.~\ref{eq:elbo}. The first term is the BNN weight penalty, which helps avoiding overfitting. The second term is the standard VAE bound, meaning that VAE is retrieved for sequences of length 1. The only (but major) difference between the second and the third terms is that the expectation is computed with respect to the variational distribution induced by the second order ODE. Finally, we optimize the Monte Carlo estimate of Eq. \ref{eq:elbo} with respect to variational posterior $\{\m,s\}$, encoder and decoder parameters, and also make use of reparameterization trick to tackle uncertanties in both the initial latent states and in the acceleration dynamics \citep{kingma2013auto}. 






\subsection{Penalized variational loss function}
A well-known pitfall of VAE models is that optimizing the ELBO objective does not necessarily result in accurate  inference \citep{alemi2017fixing}. Several recipes have already been proposed to counteract the imbalance between the $\KL$ term and reconstruction likelihood \citep{zhao2017infovae,higgins2017beta}. In this work, we borrow the ideas from \cite{higgins2017beta} and weight the $\KL[q(\mathcal{W}) || p(\mathcal{W})]$ term resulting from the BNN with a constant factor $\beta$. We choose to fix $\beta$ to the ratio between the latent space dimensionality and number of weight parameters, $\beta=|q|/|\W|$, in order to counter-balance the penalties on latent variables $\W$ and $\z_i$. 

Our variational model utilizes encoders only for obtaining the initial latent distribution. In cases of long input sequences, dynamic loss term can easily dominate VAE loss, which may cause the encoders to underfit. The underfitting may also occur in small data regimes or when the distribution of initial data points differs from data distribution. In order to tackle this, we propose to minimize the distance between the encoder distribution and the distribution induced by the ODE flow (Eqs. \ref{eg:qenc} and \ref{eq-instantaneous2}). At the end, we have an alternative, penalized target function, which we call ODE$^2$VAE-KL:
\begin{align}
 \Lagr_{\text{ODE}^2\text{VAE}} &= -\beta\KL[q(\mathcal{W}) || p(\mathcal{W})] + \E_{q(\mathcal{W},Z|X)} \left[- \log \frac{q(Z|\mathcal{W},X)}{p(Z)} + \log p(X|\mathcal{W},Z) \right]  \\ \notag 
 &\qquad - \gamma\E_{q(\W)} \left[\KL[q_{\text{ode}}(Z|X)||q_{\text{enc}}(Z|\W,X)]\right].
\end{align}
We choose the constant $\gamma$ by cross-validation. In practice, we found out that an annealing scheme in which $\gamma$ is gradually increased helps optimization, which is also used in \citep{karl2016deep,rezende2015variational}.


\subsection{Related work}
Despite the recent VAE and GAN breakthroughs, little attention has been paid to deep generative architectures for sequential data. Existing VAE-based sequential models rely heavily on RNN encoders and decoders \citep{chung2015recurrent,serban2017hierarchical}, with very few interest in stochastic models \citep{fraccaro2016sequential}. Some research has been carried out to approximate latent dynamics by LSTMs \citep{lotter2016deep,hsu2017unsupervised,li2018disentangled}, which results in observations to be included in latent transition process. Consequently, the inferred latent space and dynamics do not fully reflect the observed phenomena and usually fail to produce decent long term predictions \citep{karl2016deep}. In addition, RNNs are shown to be incapable of accurately modeling nonuniformly sampled sequences \citep{chen2018neural}, despite the recent efforts that incorporate time information in RNN architectures \citep{li2017time,xiao2018learning}.



Recently, neural ODEs introduced learning ODE systems with neural network architectures, and proposed it for the VAE latent space as well for simple cases \citep{chen2018neural}. In Gaussian process prior VAE, a GP prior is placed in the latent space over a sequential index \citep{casale2018gaussian}. To the best of our knowledge, there is no work connecting second order ODEs and Bayesian neural networks with VAE models.

\begin{table}[t]
    \centering
    \caption{Comparison of VAE-based models}
    \resizebox{\textwidth}{!}{
    \begin{tabular}{lccccr} 
    \toprule
        &              &                 & \multicolumn{2}{c}{Stochastic} & \\
    Method & Higher order & Continuous-time & dynamics & state &  Reference \\
    \midrule
    VAE & \xmark & \xmark & \xmark & \cmark & \citet{kingma2013auto} \\
    VRNN & \xmark & \xmark & \xmark & \cmark &  \citet{chung2015recurrent} \\
    SRNN & \xmark & \xmark & \cmark & \cmark &  \citet{fraccaro2016sequential} \\
    GPPVAE & \xmark & \cmark$^*$ & \xmark & \cmark & \citet{casale2018gaussian} \\
    DSAE & \xmark & \xmark & \cmark & \cmark & \citet{li2018disentangled} \\
    Neural ODE & \xmark & \cmark & \xmark & \cmark & \citet{chen2018neural} \\
    ODE$^2$VAE    & \cmark & \cmark & \cmark & \cmark & current work \\
    \bottomrule
    \end{tabular}
    }
    ${}^*$ GPPVAE uses a latent GP prior but only a discrete case was demonstrated in \citet{casale2018gaussian}.
    \label{tab:comparison}
\end{table}


\section{Experiments}
We illustrate the performance of our model on three different datasets: human motion capture (see the acknowledgements), rotating MNIST \citep{casale2018gaussian} and bouncing balls \citep{sutskever2009recurrent}. Our goal is twofold: First, given a walking or bouncing balls sequence, we aim to predict the future sensor readings and frames. Second, we would like to interpolate an unseen rotation angle from a sequence of rotating digits. The competing techniques are specified in each section. For all methods, we have directly applied the public implementations provided by the authors. Also, we have tried several values for the hyper-parameters with the same rigor and we report the best results. To numerically compare the models, we sample 50 predictions per test sequence and report the mean and standard deviation of the mean squared error (MSE) over future frames. We include the mean MSE of mean predictions (instead of trajectory samples) in the supplementary.

We implement our model in Tensorflow \citep{abadi2016}. Encoder, differential function and the decoder parameters are jointly optimized with Adam optimizer \citep{kingma2014adam} with learning rate 0.001. We use Tensorflow's own \texttt{odeint\_fixed} function, which implements fourth order Runge-Kutta method, for solving the ODE systems on a time grid that is five times denser than the observed time points. Neural network hyperparameters, chosen by cross-validation, are detailed in the supplementary material. We also include ablation studies with deterministic NNs and first order dynamics in the appendix.



\subsection{CMU walking data}
To demonstrate that our model can capture arbitrary dynamics from noisy observations, we experiment on two datasets extracted from CMU motion capture library. First, we use the dataset in \cite{heinonen18a}, which consists of 43 walking sequences of several subjects, each of which is fitted separately. The first two-third of each sequence is reserved for training and validation, and the rest is used for testing. Second dataset consists of 23 walking sequences of subject 35 \citep{gan2015deep}, which is partitioned into 16 training, 3 validation and 4 test sequences. We followed the preprocessing described in \citet{wang2008gaussian}, after which we were left with 50 dimensional joint angle measurements. 



We compare our ODE$^2$VAE against a GP-based state space model GPDM \citep{wang2008gaussian}, a dynamic model with latent GP interpolation VGPLVM \citep{damianou2011variational}, two black-box ODE solvers npODE \citep{heinonen18a} and neural ODEs \citep{chen2018neural}, as well as an RNN-based deep generative model DTSBN-S \citep{gan2015deep}. In test mode, we input the first three frames and the models predict future observations. GPDM and VGPLVM are not applied to the second dataset since GPDM optimizes its latent space for input trajectories and hence does not allow simulating dynamics from any random point, and VGPLVM implementation does not support multiple input sequences.

The results are presented in Table \ref{tab:cmu}. First, we reproduce the results in \citet{heinonen18a} by obtaining the same ranking among GPDM, VGPLVM and npODE. Next, we see that DTSBN-S is not able to predict the distant future accurately, which is a well-known problem with RNNs. As expected, all models attain smaller test errors on the second, bigger dataset. We observe that neural ODE usually perfectly fits the training data but failed to extrapolate on the first dataset. This overfitting problem is not surprising considering the fact that only ODE initial value distribution is penalized. On the contrary, our ODE$^2$VAE regularizes its entire latent trajectory and also samples from the acceleration field, both of which help tackling overfitting problem. We demonstrate latent state trajectory samples and reconstructions from our model in the supplementary.


\begin{table}[t]
	\caption{Average MSE on future frames}
	\label{tab:cmu}
	\vskip 0.15in
	\begin{center}
    \begin{small}
\begin{tabular}{lccr}
    	\toprule
    	       &  \multicolumn{2}{c}{Test error}   &  \\
    	       \cmidrule{2-3}
		 Model & Mocap-1 & Mocap-2 & Reference \\ 
	    \midrule
		 \textsc{GPDM} & 126.46 $\pm$ 34 & N/A & \cite{wang2008gaussian} \\
		 \textsc{VGPLVM}  & 142.18 $\pm$ 1.92 & N/A & \cite{damianou2011variational} \\
		 \textsc{DTSBN-S}  & 80.21 $\pm$ 0.04 & 34.86 $\pm$ 0.02 & \cite{gan2015deep}\\
		 \textsc{npODE} & 45.74 & 22.96 &  \cite{heinonen18a} \\
		 \textsc{NeuralODE} & 87.23 $\pm$ 0.02 & 22.49 $\pm$ 0.88 & \cite{chen2018neural} \\
		 ODE$^2$VAE & 93.07 $\pm$ 0.72  & 10.06 $\pm$ 1.4 & current work \\
		 ODE$^2$VAE-KL & \textbf{15.99 $\pm$ 4.16} & \textbf{8.09 $\pm$ 1.95} & current work\\
        \bottomrule
    \end{tabular}
\end{small}
    \end{center}
    \vskip -0.1in
\end{table}

\subsection{Rotating MNIST}
Next, we contrast our ODE$^2$VAE against recently proposed Gaussian process prior VAE (GPPVAE) \citep{casale2018gaussian}, which replaces the commonly \textit{iid} Gaussian prior with a GP and thus performs latent regression. We repeat the experiment in \cite{casale2018gaussian} by constructing a dataset by rotating the images of handwritten ``3'' digits. 
We consider the same number of rotation angles (16), training and validation sequences (360\&40), and leave the same rotation angle out for testing (see the first row of Figure \ref{fig:mnist}b for the test angle). 
In addition, four rotation angles are randomly removed from each rotation sequence to introduce non-uniform sequences and missing data (an example training sequence is visualized in the first row of Figure \ref{fig:mnist}a). 


Test errors on the unseen rotation angle are given in Table 3. 
During test time, GPPVAE encodes and decodes the images from the test angle, and the reconstruction error is reported. On the other hand, ODE$^2$VAE only encodes the first image in a given sequence, performs latent ODE integration starting from the encoded point, and decodes at given time points - \textit{without} seeing the test image even in test mode. In that sense, our model is capable of generating images with arbitrary rotation angles. Also note that both models make use of the angle/time information in training and test mode. An example input sequence with missing values and corresponding reconstructions are illustrated in Figure \ref{fig:mnist}a, where we see that ODE$^2$VAE nicely fills in the gaps. Also, Figure \ref{fig:mnist}b demonstrates our model is capable of accurately learning and rotating different handwriting styles.\\

\begin{minipage}[b]{\textwidth}
\begin{minipage}[t]{0.46\textwidth}
\centering
	\label{tab:mnist}
	\vskip 0.05in
    \captionof{table}{Average prediction errors on test angle}
	\begin{center}
    \begin{small}
    \begin{sc}
	\begin{tabular}{lc}
		\hline
		 Model & Test Error \\ 
	    \hline
		 $\textsc{GPPVAE-dis}^{\diamond}$ & 0.0309 $\pm$ 0.00002 \\
		 $\textsc{GPPVAE-joint}^{\diamond}$ & 0.0288 $\pm$
0.00005 \\
\textsc{ODE$^2$VAE} & 0.0194 $\pm$ 0.00006 \\
		 \textsc{ODE$^2$VAE-KL} & \textbf{0.0188 $\pm$ 0.0003} \\
        \hline
    \end{tabular}
    \end{sc}
    \end{small}
    \end{center}
\end{minipage}
\hfill
\begin{minipage}[t]{0.46\textwidth}
    \centering
    \strut\vspace*{-\baselineskip}\newline
    \includegraphics[width=\textwidth]{balls_error.eps}
    \captionof{figure}{Bouncing balls errors.}
    \vspace*{0.25cm}
    \label{fig:balls_error}
\end{minipage}
\end{minipage}


\subsection{Bouncing balls}
As a third showcase, we test our model on bouncing balls dataset, a standard benchmark used in generative temporal modeling literature \citep{gan2015deep,hsieh2018learning,lotter2015unsupervised}. The dataset consists of video frames of three balls bouncing within a rectangular box and also colliding with each other. The exact locations of the balls as well as physical interaction rules are to be inferred from the observed sequences. We make no prior assumption on visual aspects such as ball count, mass, shape or on the underlying physical dynamics.  


\begin{figure}
\centering
\includegraphics[width=\textwidth]{rot_mnist2.png}
  \caption{Panel \textbf{(a)} shows a training sequence with missing values (first row) and its reconstruction (second row). First row in panel \textbf{(b)} demonstrates test angles from different sequences, i.e., hand-writing styles, and below are model predictions.}
  \label{fig:mnist}
\end{figure}

We have generated a training set of 10000 sequences of length 20 frames and a test set of 500 sequences using the implementation provided with \cite{sutskever2009recurrent}. Each frame is 32x32x1 and pixel values vary between 0 and 1. We compare our method against DTSBN-S \citep{gan2015deep} and decompositional disentangled predictive auto-encoder (DDPAE) \citep{hsieh2018learning}, both of which conduct experiments on the same dataset. In test mode, first three frames of an input sequence are given as input and per pixel MSE on the following 10 frames are computed. We believe that measuring longer forecast errors is more informative about the inference of physical phenomena than reporting one-step-ahead prediction error, which is predominantly used in current literature \citep{gan2015deep,lotter2015unsupervised}.


\begin{figure}[b]
\centering
\includegraphics[width=\textwidth]{bballs.png}
  \caption{An example test sequence from bouncing ball experiment. Top row is the original sequence. Each model takes the first three frames as input and predicts the further frames.}
  \label{fig:balls}
\end{figure}

Predictive errors and example reconstructions are visualized in Figures~\ref{fig:balls_error} and~\ref{fig:balls}. The RNN-based DTSBN-S nicely extrapolates a few frames but quickly loses track of ball locations and the error escalates. DDPAE achieves a much smaller error over time; however, we empirically observed that the reconstructed images are usually imperfect (here, generated balls are bigger than the originals), and also the model sometimes fails to simulate ball collisions as in Figure \ref{fig:balls}. Our ODE$^2$VAE generates long and accurate forecasts and significantly improves the current state-of-the-art by almost halving the error. We empirically found out that a CNN encoder that takes channel-stacked frames as input yields smaller prediction error than an RNN encoder. We leave the investigation of better encoder architectures as an interesting future work.

\section{Discussion}
We have presented an extension to VAEs for continuous-time dynamic modelling. We decompose the latent space into position and velocity components, and introduce a powerful neural second order differential equation system. As shown empirically, our variational inference framework results in Bayesian neural network that helps tackling overfitting problem. We achieve state-of-the-art performance in long-term forecasting and imputation of high-dimensional image sequences. 

There are several directions in which our work can be extended. Considering divergences different than $\KL$ would lead to Wasserstein auto-encoder formulations \citep{tolstikhin2017wasserstein}. The latent ODE flow can be replaced by stochastic flow, which would result in an even more robust model. Proposed second order flow can also be combined with generative adversarial networks to produce real-looking videos.











\subsubsection*{Acknowledgements.} 
The data used in this project was obtained from \url{mocap.cs.cmu.edu}. The database was created with funding from NSF EIA-0196217. The calculations presented above were performed using computer resources within the Aalto University School of Science “Science-IT” project. This work has been supported by the Academy of Finland grants no. 311584 and 313271.

\bibliography{refs}
\bibliographystyle{plainnat}





































\newpage
\includepdf[pages=-]{supp.pdf}

\end{document}
