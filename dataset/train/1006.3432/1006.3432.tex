\documentclass{llncs}
\usepackage{float}
\floatstyle{ruled}
\usepackage{boxedminipage}
\usepackage{graphicx, subfigure}
\usepackage{epsfig}
\usepackage{theorem}
\usepackage{latexsym}
\usepackage{amssymb}
\newfloat{algorithm}{tbp}{loa}
\floatname{algorithm}{Algorithm}



\renewenvironment{proof}{{\it Proof. } }{{\hfill }\vspace{.5pc}}
\newenvironment{sketch}{{\bf Proof Outline. } }{{\hfill }\vspace{.5pc}}

\newcommand{\fixme}[1]
{
  \noindent
  \begin{boxedminipage}{\linewidth}
    \textsl{{\bf FIXME: #1}}
  \end{boxedminipage}
}

\newtheorem{specification}{Specification}
\newtheorem{lem}{Lemma}
\newcommand{\keywords}[1]{\par\addvspace\baselineskip
\noindent\keywordname\enspace\ignorespaces#1}

\newcommand{\eg}{\emph{e.g., }}
\newcommand{\ie}{\emph{i.e., }}
\newcommand{\aka}{\emph{a.k.a., }}

\begin{document}
\frontmatter          \pagestyle{headings}  \addtocmark{Deaf, Dumb, and Chatting Asynchronous Robots: 
        Enabling Distributed Computation and Fault-Tolerance Among Stigmergic Robot} 

\mainmatter              \title{Snap-Stabilizing Linear Message Forwarding\thanks{This work is supported by ANR SPADES grant.}
}

\author{
  Alain Cournier\inst{1} \and  
  Swan Dubois\inst{2} \and 
  Anissa Lamani\inst{1} \and 
  Franck Petit\inst{2} \and 
  Vincent Villain\inst{1} 
}

\authorrunning{Cournier {\em et al}.}   \tocauthor{ Alain Cournier, Swan Dubois, Anissa Lamani, Franck Petit, Vincent Villain}
\institute{
MIS, Universit\'e of Picardie Jules Verne, France 
\and
LiP6/CNRS/INRIA-REGAL, Universit\'e Pierre et Marie Curie - Paris 6, France 
}

\maketitle
\begin {abstract}

In this paper, we present the first snap-stabilizing message forwarding protocol that uses 
a number of buffers per node being independent of any global parameter, that is  buffers per 
link.  The protocol works on a linear chain of nodes, that is possibly an overlay on a large-scale and dynamic system,
\eg Peer-to-Peer systems, Grids\ldots  
Provided that the topology remains a linear chain and that nodes join and leave 
``neatly'', the protocol tolerates topology changes.  
We expect that this protocol will be the base to get similar results on more general topologies. 


\keywords {Dynamicity, Message Forwarding, Peer-to-Peer, Scalability, Snap-stabilization} 
\end {abstract}



\section{Introduction}

These last few years have seen the development of large-scale distributed systems.  
Peer-to-peer (P2P) architectures belong to this category.  They usually offer computational services or storage facilities.
Two of the most challenging issues in the development of such large-scale distributed 
systems are to come up with scalability and dynamicity.  {\em Scalability} is achieved by designing protocols 
with performances growing sub-linearly with the number of nodes (or, processors, participants).  {\em Dynamicity} refers to 
distributed systems in which topological changes can occur, \ie nodes may join or leave the system.

{\em Self-stabilization}~\cite{D00} is a general technique to design distributed systems that 
can tolerate arbitrary transient faults.  Self-stabilization is also well-known to be suitable for dynamic systems. 
This is particularly relevant whenever the distributed (self-stabilizing) protocol does not require any global parameters,
like the number of nodes () or the diameter () of the network.  
With such a self-stabilizing protocol, it is not required to change 
global parameters in the program (, , etc) when nodes join or leave the system.  Note that this property 
is also very desirable to achieve scalability. 

The {\em end-to-end communication} problem consists in delivery in finite time across the network of a sequence of 
data items generated at a node called the sender, to a designated node called the receiver.
This problem is generally split into the two following problems:
() the {\em routing} problem, \ie the determination of the path followed by the messages to reach their destinations;
() the {\em message forwarding} problem that consists in the management of network resources in order to forward messages. 
The former problem is strongly related to the problem of spanning tree construction. Numerous self-stabilizing solutions exist for this problem, \eg \cite{HC92,KK05,JT03}. 

In this paper, we concentrate on the latter problem, \ie the message forwarding problem.   
More precisely, it consists in the design of a protocol managing the mechanism allowing
the message to move from a node to another on the path from the sender  to the receiver .
To enable such a mechanism, each node on the path from  to  has a reserved memory space called buffers.
With a finite number of buffers, the message forwarding problem consists in avoiding deadlocks and livelocks (even
assuming correct routing table).
Self-stabilizing solutions for the message forwarding problem are proposed in \cite{APV96,KOR95}. 
Our goal is to provide a snap-stabilizing solution for this problem.
A {\em snap-stabilizing protocol}~\cite{Bui07}
guarantees that, starting from any configuration, it always behaves
according to its specification, \ie it is a
self-stabilizing algorithm which is optimal in terms of stabilization
time since it stabilizes in  steps.
Considering the message-forwarding problem, combined with a self-stabilizing routing protocol, 
snap-stabilization brings the desirable property that 
every message sent by the sender is delivered in finite time to the receiver.
By contrast, any self-stabilizing (but not snap-stabilizing) solution for this problem
ensures the same property, ``eventually''. 

The problem of minimizing the number of required buffers on each node is a crucial issue
for both dynamicity and scalability. 
The first snap-stabilizing solution for this problem can be found in~\cite{CDV09-1}.
Using  buffers per node, this solution is not suitable for large-scale system. 
The number of buffers is reduced to  in~\cite{CDV09-2}, which improves the scalability aspect.  However,
it works by reserving the entire sequence of buffers leading from the sender to the receiver.
Furthermore, to tolerate dynamicity, each time a topology change occurs in the system, 
both of them would have to rebuild required data structures, maybe on the cost of loosing 
the snap-stabilisation property.

In this paper, we present a snap-stabilizing message forwarding protocol that uses 
a number of buffers per node being independent of any global parameter, that is  buffers per 
link. The protocol works on a linear 
chain of nodes, that is possibly an overlay on a large-scale and dynamic system \eg Peer-to-Peer systems, Grids\ldots  
Provided that () the topology remains a linear chain and () that nodes join and leave 
``neatly'', the protocol tolerates topology changes.  By ``{\it neatly}'', we mean that when a node leaves the
system, it makes sure that the messages it has to send are transmitted, \ie all its buffers are free.    
We expect that this protocol will be the base to get similar results on more general topologies. 


The paper is structured as follow: In Section~\ref{sec:model}, we define our model and some useful terms that are used afterwards. 
In Section~\ref{sec:algo}, we first give an informal overview of our algorithm, followed by its formal description. 
In Section~\ref{sec:proof}, we prove the correctness of our algorithm.
Dynamicity is discussed in Section~\ref{sec:dynamicity}. We conclude the paper in Section~\ref{sec:conclu}.  

\section{Model and definitions\label{sec:model}}

\paragraph{\textbf{Network}.} 
We consider a network as an undirected connected graph  where  is the set of nodes (processors) and  is the set of bidirectional communication links. A link  exists if and only if the two processors  and  are neighbours. Note that, every processor is able to distinguish all its links. To simplify the presentation we refer to the link  by the label  in the code of . In our case we consider that the network is a chain of  processors.\\

\paragraph{\textbf{Computational model}.}
We consider in our work the classical local shared memory model introduced by Dijkstra~\cite{D74} known as the state model. In this model communications between neighbours are modelled by direct reading of variables instead of exchange of messages. The program of every processor consists in a set of shared variables (henceforth referred to as variable) and a finite number of actions. Each processor can write in its own variables and read its own variables and those of its neighbours. Each action is constituted as follow:

\begin{center}    \end{center}

The guard of an action is a boolean expression involving the variables of  and its neighbours. The statement is an action which updates one or more variables of . Note that an action can be executed only if its guard is true. Each execution is decomposed into steps. 

The state of a processor is defined by the value of its variables. The state of a system is the product of the states of all processors. The local state refers to the state of a processor and the global state to the state of the system.  

Let    and  an action of  (  ).  is {\em enabled} for  in  if and only if the guard of
 is satisfied by  in . Processor  is enabled in  if and only if at least one action is enabled at 
in . Let  be a distributed protocol which is a collection of binary transition relations denoted by
, on . An execution of a protocol  is a maximal sequence of configurations   such that,  ,  (called a step) if 
exists, else  is a terminal configuration. {\em Maximality} means that the sequence is either finite (and no action
of  is enabled in the terminal configuration) or infinite. All executions considered here are assumed to be
maximal.  is the set of all executions of . 
Each step consists on two sequential phases atomically executed:
() Every processor evaluates its guard;
() One or more enabled processors execute its enabled actions. 
When the two phases are done, the next step begins. 
This execution model is known as the \emph{distributed daemon}~\cite{BGM89}. 
We assume that the daemon is \emph{weakly fair}, meaning that if a processor  is continuously , 
then  will be eventually chosen by the daemon to execute an action.

In this paper, we use a composition of protocols.  We assume that the above statement () is applicable to every
protocol. In other words, each time an enabled processor  is selected by the daemon,  executes the enabled actions of every protocol.










\paragraph{\textbf{Snap-Stabilization}.} 
Let  be a task, and  a specification of  . A protocol  is snap-stabilizing for  if and only if ,  satisfies .



\paragraph{\textbf{Message Forwarding Problem}.}



The message forwarding problem is specified as follows: 

\begin{specification}[]\label{spec:SP}
A protocol  satisfies  if and only if the following two requirements are satisfied in every execution of :
\begin{enumerate}
\item Any message can be generated in a finite time;
\item Any valid message is delivered to its destination once and only once in a finite time.
\end{enumerate}
\end{specification}



\paragraph{\textbf{Buffer Graph}} 



In order to conceive our snap stabilizing algorithm we will use a structure called Buffer Graph introduced in \cite{MS78}. A Buffer Graph is defined as a directed graph where nodes are a subset of the buffers of the network and links are arcs connecting some pairs of buffers, indicating permitted message flow from one buffer to another one. Arcs are permitted only between buffers in the same node, or between buffers in distinct nodes which are connected by communication link.


Let us define our buffer graph (refer to Figure~\ref{BG}):

\begin{figure}
   \centering
   \includegraphics[width=9cm]{BG.eps}
   \caption{Buffer Graph}\label{BG}
\end{figure} 
 


\noindent
Each processor  has four buffers, two for each link  such as  (except for the processors that
are at the extremity of the chain that have only two buffers, since they have only one link). Each processor has two
input buffers denoted by ,  and two output buffers denoted by ,  such as  and  (one for each neighbour). The generation of a message is always done in the output buffer of the
link  so that, according to the routing tables,  is the next processor for the message in order to reach 
the destination.  Let us refer to  as the next buffer of Message~ stored in ,  
, . We have the following properties:
\begin{enumerate}
\item 
\item 
\end{enumerate}  







 
\section{Message Forwarding\label{sec:algo}}

In this section, we first give the idea of our snap stabilizing message forwarding algorithm in the informal overview, 
then we give the formal description followed by the correctness proofs. 

\subsection{Overview of the algorithm}

In this section, we provide an informal description of our snap stabilizing message forwarding algorithm that 
tolerates the corruption of the routing tables in the initial configuration. 

To ease the reading of the section, we assume that there is no message in the system whose the destination is not
in the system.  This restriction is not a problem as we will see in Section~\ref{sec:dynamicity}.

We assume that there is a self-stabilizing algorithm, , that calculates the routing tables and runs simultaneously to our
algorithm. We assume that our algorithm has access to the routing tables
via the function  which returns the identity of the neighbour to which  must forward the message to
reach the destination . To reach our purpose we define a buffer graph on the chain which consists of two chains,
one in each direction ( and  refer to Figure \ref{BG}). 

The overall idea of the algorithm is as follows: When a processor wants to generate a message, it consults the routing
tables to determine the next neighbour by which the message will transit in order to reach the destination. Note that
the generation is always done in the Output buffers. Once the message is on the chain, it follows the buffer chain
(according to the direction of the buffer graph) and if the messages can progress enough in the system (move) then it
will either meet its destination and hence it will be consumed in a finite time or it will reach the input buffer of
one of the processors that are at the extremity of the chain. In the latter case, if the processor that is at the
extremity of the chain is not the destination then, that means that the message was in the wrong direction. The idea
is to change the direction of the message by copying it in the output buffer of the same processor (directly (UT1) or
using the extra buffer (UT2), refer to Figure~\ref{BG}). 

Note that if the routing tables are stabilized and if all the messages are in the right direction then all the
messages can move on  or  only and no deadlock happens. However, in the opposite case (the routing tables are not stabilized or
some messages are in the wrong direction), deadlocks may happen if no control is introduced. For instance, suppose
that in the initial configuration all the buffers, uncluding the extra buffer of , contain different messages such that 
no message can be consumed. It is clear that in this case no message can move and the system is deadlocked. Thus in order to solve this problem we
have to delete at least one message. However, since we want a snap stabilizing solution we cannot delete a message
that has been generated. Thus we have to introduce some control mechanisms in order to avoid this situation to appear
dynamically (after the first configuration). In our case we decided to use the PIF algorithm that comprises two main
phases: Broadcast (Flooding phase) and Feedback (acknowledgement phase) to control and avoid deadlock situations.

Before we explain how the PIF algorithm is used, let us focus on the message progression again.
A buffer is said to be {\em free} if and only if it is empty (it contains no message) or contains the same message as
the input buffer before it in the buffer graph buffer. For instance, if  then  is a
free buffer. In the opposite case, a buffer is said to {\em busy}.
The transmission of messages produces the filling and the cleaning of each buffer, \ie each buffer is alternatively
free and busy. This mechanism clearly induces that {\em free slots} move into the buffer graph, a free slot
corresponding to a free buffer at a given instant. The moving of free slots is shown in Figure \ref{EmptySlot}\footnote{Note that in the
algorithm, the actions  and  are executed in the same step (refer to the guarded action ).}.
Notice that the free slots move in the opposite direction of the message progression.  This is the key feature on
which the PIF control is based.

\begin{figure}
 \begin{minipage}[b]{.46\linewidth}
  \begin{center}
  \epsfig{figure=Free1.eps,width=5.5cm}\\
  \textit{(a)} The input buffer of  is free. Node  can copy the message . 
  \end{center}
 \end{minipage} \hfill
 \begin{minipage}[b]{.46\linewidth}
 \begin{center}
 \epsfig{figure=Free2.eps,width=5.5cm}\\
  \textit{(b)} The output buffer of  is free. Node  can copy the message .
  \end{center}
 \end{minipage}\hfill
 \begin{minipage}[b]{.46\linewidth}
\begin{center}  
  \epsfig{figure=Free3.eps,width=5.5cm}\\
  \textit{(c)} The input buffer of  is free. Node  can copy the message .
  \end{center}
 \end{minipage}\hfill
 \begin{minipage}[b]{.46\linewidth}
 \begin{center}
 \epsfig{figure=Free4.eps,width=5.5cm}\\
  \textit{(d)} The output buffer of  is free. Node  can copy the message .
  \end{center}
 \end{minipage}
 \caption{An example showing the free slot moving.\label{EmptySlot}}
\end{figure}

When there is a message that is in the wrong direction in the Input buffer of the processor ,  copies
this message in its extra buffer releasing its Input buffer and it initiates a PIF wave at the same time. The aim of
the PIF waves is to escort the free slot that is in the input buffer of  in order to bring it in the Output
buffer of . Hence the message in the extra buffer can be copied in the output buffer to become in the right
direction. Once the PIF wave is initiated no message can be generated on this free slot, at each time the Broadcast
progresses on the chain the free slot moves as well following the PIF wave (the free slot moves by transmitting
messages on  (refer to Figure \ref{BG}). In the worst case, the free slot is the only one, hence by moving the
output buffer of the other extremity of the chain  becomes free. Depending on the destination of the message that
is in the input buffer of , either this message is consumed or copied in the Output buffer of . In both cases
the input buffer of  contains a free slot.

 In the same manner during the feedback phase, the free slot that is in the input buffer of the extremity  will
progress at the same time as the feedback of the PIF wave. Note that this time the free slot moves on  (see Figure
\ref{BG}). Hence at the end of the PIF wave the output buffer that comes just after the extra buffer contains a free
slot. Thus the message that is in the extra buffer can be copied in this buffer and deleted from the extra buffer.
Note that since the aim of the PIF wave is to bring the free slot in the output buffer of  then when the PIF
wave meets a processor that has a free buffer on  the PIF wave stops escorting the previous free slot and starts
the feedback phase with this second free slot (it escorts the new free slot on ). Thus it is not necessary to
reach the other extremity of the chain.





Now, in the case where there is a message in the extra buffer of  such as no PIF wave is executed then we are
sure that this message is an invalid message and can be deleted. In the same manner if there is a PIF wave that is
executed such that at the end of the PIF wave the Output buffer of  is not free then like in the previous case
we are sure that the message that is in the extra buffer is invalid and thus can be deleted. Thus when all the buffers are full such as all the messages are different and cannot be consumed, then the extra buffer of  will be released. 

Note that in the description of our algorithm, we assumed the presence of a special processor . This processor has an Extra buffer used to change the direction of messages that are in the input buffer of  however their destination is different from . In addition it has the ability to initiate a PIF wave. Note also that the other processors of the chain do not know where this special processor is. A symmetric solution can also be used (the two processors that are at the extremity of the chain execute the same algorithm) and hence both have an extra buffer and can initiate a PIF wave. The two PIF wave initiated at each extremity of the chain use different variable and are totally independent. 







\subsection{Formal description of the algorithm}




We first define in this section the different data and variables that are used in our algorithm. Next, we present the
PIF algorithm and give a formal description of the linear snap stabilizing message forwarding algorithm.

Character {\tt '?'} in the predicates and the algorithms means {\em any value}.


\begin{itemize}
\item \textbf{Data}
           \begin{itemize}
            \item  is a natural integer equal to the number of processors of the chain. 
            \item  is the set of processors' identities of the chain. 
            \item  is the set of identities of the neighbours of the processor p.   
           \end{itemize}
  \item \textbf{Message}
            \begin{itemize}
             \item :  contains the message by itself, \ie the data carried from the sender to the recipient,
                    is the identity of the message recipient, and
                    is a color number given to the message to avoid duplicated deliveries.
             \end{itemize}

  \item \textbf{Variable}
             \begin{itemize}
              \item \textit{In the forwarding algorithm}
                        \begin{itemize}
                         \item : The input buffer of  associated to the link .
                         \item : The output buffer of  associated to the link .
                         \item : The Extra buffer of processor  which is at the extremity of the chain.
                         \end{itemize}
             \item{\textit{ In the PIF algorithm}}
                          \begin{itemize}
                            \item  refers to the state of processor ,  is a pointer
to a neighbour of .\\
                           \end{itemize}
            \end{itemize}
            
   \item \textbf{Input/Output}
           \begin{itemize}
            \item : Boolean, allows the communication with the higher layer, it is set at true by the application and false by the forwarding protocol.
             \item : Boolean, allows the communication between the PIF and the forwarding algorithm, it is set at true by the forwarding algorithm and false by the PIF algorithm.
             \item{The variables of the PIF algorithm are the input of the forwarding algorithm.}
            \end{itemize}

   \item \textbf{Procedure}
            \begin{itemize}
             \item : refers to the neighbour of  given by the routing table for the destination .
             \item : delivers the message  to the higher layer of . 
             \item : chooses a color for the message  which is different from the color of the message 
                   that are in the buffers connected to the one that will contain .
             \end{itemize}
             
    \item{\textbf{Predicate}}
             \begin{itemize}
              \item{\textit{}:     }
               \item{:   ( ,   (    )).}
              \item{\textit{}:   ,  .}
              \item{\textit{init-PIF}:   (, ) 
\newline \noindent .}
               \item{\textit{}:        (,   ).}
\item{:    .} 
              \item{:         .}
               \item{ , we define  the predicate:   (the garde of TAction in  is enabled).}
               \item{  and ,  is defined by the predicate:  is true  TAction of  is enabled.}
\item{:  (    )  .\\}
               \end{itemize}
               
\item{We define a fair pointer that chooses the actions that will be performed on the output buffer of a processor . (Generation of a message or an internal transmission). }


\end{itemize}

\begin{algorithm}[htb]
\caption{PIF \label{algo:PIF}}
\begin{scriptsize}

   \begin{itemize}
       \item{\textbf{For the initiator ()}}\begin{itemize}
                \item{\textbf{B-Action::}} \textit{init-PIF } , .
                 \item{\textbf{C-Action::}}    ,   .\\
                 \end{itemize}
        \item{\textbf{For the leaf processors:   }} \begin{itemize}
                  \item{\textbf{F-Action::}}     .
                  \item{\textbf{C-Action::}}   ,    . \\
                   \end{itemize}
          \item {\textbf{For the processors}}\begin{itemize}
                    \item{\textbf{B-Action::}}  ,       ,   . 
                    \item{\textbf{F-Action::}}     ,   . 
                    \item{\textbf{C-Action::}}    ,    . \\
                      \end{itemize}
            \item {\textbf{Correction (For any processor)}} \begin{itemize}
                        \item {     .}
                        \item{    .}
                        \end{itemize}
   \end{itemize}
   \end{scriptsize}
\end{algorithm}

\begin{algorithm}[htb]
\caption{Message Forwarding \label{algo:MF}}
\begin{scriptsize}

   \begin{itemize}
       \item{\textbf{Message generation (For every processor) }}

     ::     [  ]  \textit{ } , .\\

       \item{\textbf{Message consumption (For every processor) }}

     :: \textit{, ; }  , .\\

        \item{\textbf{Internal transmission (For processors having 2 neighbors) }}

:: , , ;   ()  , .\\


         \item{\textbf{Message transmission from  to  (For processors having 2 neighbors) }} 

::      ()   .\\


         \item{\textbf{Erasing a message after its transmission (For processors having 2 neighbors) }}

:: ,   (,
)  ()    , .\\
             


         \item{\textbf{Erasing a message after its transmission (For the extremities) }}

::      
		() 
		 ()    , .\\
             
\item{\textbf{Road change (For the extremities) }}\begin{itemize}
               \item{::   [  ]  , .}
               \item{::       . }
               \item{::         , .}
               \item{::       [  ]     , .}
               \item{::              .}
               \item{::              , .}\\
           \end{itemize}
       \item{\textbf{Correction  (For ) }}\begin{itemize}
             \item{::       .}
             \item{::       .}
             \item{::       [(  )  ]  .}
            \end{itemize}       
       
  \end{itemize}
  \end{scriptsize}
  \end{algorithm}
  







\section{Proof of Correctness\label{sec:proof}}

In this section, we prove the correctness of our algorithm.
We first show that starting from an arbitrary configuration, our protocol is deadlock free.  Next, we show that no node
can be starved of generating a new message. Next, we show the snap-stabilizing property of our solution by showing that,
starting from any arbitrary configuration and even if the routing tables are not stabilized, every valid message is 
delivered to its destination once and only once in a finite time.  

Let us first state the following lemma:

\begin{lem}\label{PIF}
The PIF protocol (Algorithm 1) is snap-stabilizing.
\end{lem}  



\begin{proof}
Note that the PIF algorithm introduced here is similar to the one proposed in \cite{Bui07} which is a snap stabilizing algorithm. The new thing is that we introduced the idea of dynamic leafs, processors that satisfy some properties and act like a physical leaf (they execute the F-action once they have a neighbor in a broadcast phase). Hence instead of reaching all the nodes of the chain, the PIF wave stops advancing when it meets a dynamic leaf. Note that once an internal processor  executes the B-Action, it cannot execute the F-Action unless is has a neighbor  such as  (it cannot become a leaf) since to execute the F-action by any processor ,  or for the internal processor that executes the B-Action  (, ). Thus no processor becomes a dynamic leaf of the PIF wave once it executed the B-Action of the same PIF wave.
In another hand, note that the variable PIF-Request is a shared variable between the PIF algorithm and the forwarding algorithm, its role is to give the signal to the initiator to initiate the PIF wave. Hence we can deduct by analogy that the PIF algorithm proposed here is a snap stabilizing algorithm.
\end{proof}



We now show (Lemma~\ref{INTFree}) that the extra buffer located at  cannot be infinitely continuously busy.  As explained in
Section~\ref{sec:algo}, this solves the problem of deadlocks. 

\begin{lem}\label{INTFree}
If the extra buffer of the processor  () which is at the extremity of the chain contains a message then
this buffer becomes free after a finite time.
\end{lem}  

\begin{proof}
We know from Lemma~\ref{PIF} that each time 
launches a PIF wave, then this wave terminates.  When this happens, there are two cases:
\begin{enumerate}
\item{}. In this case  is enabled on . Since the daemon is weakly fair we are sure that  will be executed in a finite time. Thus  will be free in a finite time too.
\item{}. In this case, a PIF wave is executed on the chain. Note that  is the initiator (it is eventually considered as the initiator). According to Lemma \ref{PIF} the PIF is a Snap stabilizing algorithm. Hence, there will be a time when , . Two sub cases are possible:
\begin{itemize}
\item\label{BINT}{Either  or }. In this case  is enabled on . Since the daemon is weakly fair, this rule will be executed in a finite time. Hence the message that is in the extra buffer will be copied in  and deleted from  (see Rule ). Hence .
\item{ and }. Since  is enabled on  and the daemon is weakly fair,  will be executed in a finite time. Thus, the message that is in the extra buffer is deleted.  
\end{itemize}
 \end{enumerate}
 
From the cases above, we deduct that in the case where the extra buffer of  contains a message, then this message will be either deleted or copied in . Hence   will be free in a finite time and the lemma holds.     
\end{proof}


 We deduce from Lemma~\ref{INTFree} that if the routing tables are not stabilized and if there is a message locking the
Input buffer of , then this message is eventually copied in the extra buffer.  Since the latter is infinitely
often empty (Lemma~\ref{INTFree} again). 

From now on, we suppose that no generated message is deleted (we prove this property latter).

\begin{lem}\label{DeadStable}
All the messages progress in the system even if the routing tables are not stabilized.
\end{lem}

\begin{proof}
Note that if ,  is free then if there is a message in , then this message is automatically copied in . Hence it is sufficient to prove that the input buffer are free in a finite time. Thus Let's prove that , when there is a message in , this message is deleted from  in a finite time (). 



Note that the input-buffers are all at an even distance from the input buffer of the processor . Let define  as the distance between the input buffer of the processor  and the input buffer of processor  (In the direction of the buffer graph taken in account ). The lemma is proved by induction on . We define for this purpose the following predicate : \\

If there is a message  in  such as  is at distance  from the input buffer of  then one of these two cases happens:
\begin{itemize}
\item{ is consumed and hence delivered to its destination.}
\item{ is deleted from the input buffer and copied either in  or   in a finite time.}\end{itemize}

\textbf{Initialization}. Let's prove the result for . Suppose that there is a message  in  such as  and . Two cases are possible according to the destination () of :
\begin{itemize}
\item{. In this case, since the daemon is weakly fair and since  keep being enabled on  then  will be executed on  in a finite time and the message  in  is consumed. Thus  is true.}
 \item{}. Since the daemon is weakly fair we are sure that  will be activated. Two cases are possible:
 \begin{itemize}
\item{ or }. In this case  is enabled on . Hence the message  is copied in  and deleted from  since a new value overwrite it (see ). Thus  is true.
\item{ and }. According to Lemma \ref{INTFree},  will be free in a finite time. In another hand since the PIF is a snap stabilizing algorithm (refer to Lemma \ref{PIF}, we are sure that the B-Action of the initiator will be enabled on  in a finite time). Hence the message  will be copied in this case in  and deleted from  (Note that in the case where  then it is set at true (see rule )). Thus  is true.
\end{itemize}
 
\end{itemize}
 
In both cases either the message is consumed or it is removed from . Thus  is true.\\ 

\textbf{Induction}. let   . We assume that  is true and we prove that  is true as well (Recall that the input buffers are at an even distance from the input buffer of ). Let  be the buffer at distance  from the input buffer of  and  the one that is at distance  and contains the message . \\
In the case where the destination of  is  then it will be consumed in a finite time (the daemon is weakly fair and  keep being enabled on . Thus  will execute  in a finite time). Hence  is true. In the other case (the destination of  is different from ), since  is true then if there is a message  in  then we are sure that this message will be either consumed or copied in . Thus  ( is free). Two cases are possible according to the rule that is executed on  (depending on the value of the pointer on ) :
\begin{enumerate}
\item\label{INTER}{ executes . In this case the message  is copied in  and deleted from  since a new value overwrite it (refer to Rule ). Hence  is true.}
\item{ executes  (it generates a message). Hence  ( is the message generated by ). However, since  is true, then the message in  will be deleted from the buffer ( performs either an internal transmission or consume the message). Hence  in a finite time. Nevertheless, since  generated a message in the previous step, we are sure that it will execute  (since the pointer on the output buffer  is fair). Thus we retrieve case \ref{INTER}.}
\end{enumerate}

From the proof above, we deduct that all the messages in the chain progress in the system and no deadlock happens even if the routing tables are corrupted.

\end{proof}

Let us call a {\em valid PIF} wave every  wave that is initiated by the processor  at the same time as executing .

\begin{lem}\label{VPIF}
For every valid  wave, when the  is executed in the initiator either  or . 
\end{lem}

\begin{proof}
The idea of the proof is as follows: 
\begin{itemize}
\item{We prove first that during the broadcast phase there is a synchrony between the PIF and the forwarding
algorithm. Note that when the message that was in the input buffer of the initiator is copied in the extra buffer, the
input buffer becomes free. The free slot in that buffer progresses in the chain at the same time as the broadcast of the PIF
wave.}
\item{Once the PIF reaches a leaf, a new buffer becomes free in  (refer to Figure \ref{BG}).
\item{As in the broadcast phase, there is a synchrony between the PIF and the forwarding algorithm
during the feedback phase. (The feedback will escort the new free slot on  to the output buffer of .}})
\end{itemize}

Let's prove that during the broadcast phase there is a synchrony between the PIF and the forwarding algorithms.
Let's define for this purpose  the distance between the processor  and  the processor . We're going to prove the result  by induction on . let's define fot this purpose the predicate  as follow: \\

When the PIF wave is initiated and for each extra processor  () that executes the B-action we have: ! , ,       ().\\

\textbf{Initialization}. Let's prove that  is true. Since the PIF wave is valid, when the PIF wave was
initiated,  was executed at the same time. Hence, the message that was in  was copied in
, ,  and . Since  is not a leaf only
 or  and possibly  are enabled on . Note that after the execution of one of these rules
 (). In another hand  and  are not enabled only if the
 of the internal processor is enabled as well. Thus when the B-Action is executed (we are sure that this
will happen since the PIF algorithm is snap stabilizing and the daemon is weakly fair) either  or  (possibly
) are executed at the same time (Recall that when two actions from the PIF and the forwarding algorithm are
enabled on the same processor at the same time they are both executed). Hence ,
 and . Thus  is true. Note that if  is executed alone before the B-Action
then either  or  are still enabled on . Hence when the B-Action is executed one of these two actions are
executed as well.

\textbf{Induction}. Let   . We assume that  is true and we prove that  is true as well. Let  and  be the processors that are at distance  and  respectively from the processor . Since  is true, when the B-Action of the internal processor is executed on , ,  and . In the same manner as the proof of ,  or  and possibly  is enabled on . Note that  or  keep being enabled unless they are executed (Note that  cannot be executed since there is a PIF wave that is executed in the neighbourhood. Thus no message is generated). In another hand  and  cannot be executed unless the B-Action is enabled as well. Hence when the B-Action is executed either  or  or  is executed at the same time. Hence ,  and . Thus  is true. 

We can deduct that for the last processor  that is an internal processor ( and  leaf),  and ,  and  . Since  is the last processor which is an internal processor then  is a leaf. Two cases are possible:
\begin{itemize}
\item{The leaf is the processor  that is at the extremity of the chain such as . Either  or  are enabled on . Note that the F-Action is enabled as well since  is a leaf and . When one of these two rules is executed with the F-Action,  and .}
\item{The leaf  is not the processor that is at the border of the chain.} In this case either  or  or  are enabled. Recall that the F-action is enabled as well. Then once the F-Action of the internal processor and one of these rules are executed,  and .
\end{itemize}

Note that in both cases, once the leaf  executed the F-Action we have the following property:  and . Now in the same manner that we proved the synchrony between the PIF and the forwarding algorithm during the broadcast phase. We prove the synchrony between these two algorithms during the feedback phase. The proof is by induction on  using the following predicate: For every internal processor  that executes the F-Action, , ,  and  (). Then when the last internal processor executes that F-action (note that the last processor is the one that is neighbour to the initiator) these properties are verified. Hence the Output buffer of the initiator is becomes free and the lemma holds.

\end{proof}

In the remainder, we say that a message is in a {\em suitable} buffer if the buffer is on the right direction to its
destination.  
A message is said to be deleted if it is removed from the system without being delivered.

Let  be a message. According to Lemma \ref{DeadStable},  progresses in the system (no deadlock happens and no message stays in the same buffer indefinitely). 
So, if  is in a buffer that is not suitable for it, then  progresses in the system according to the buffer
graph. Thus, it eventually reaches an extremity, which changes its direction.  Now,  is ensured to reach its
destination, leading to the following lemma:

\begin{lem}\label{changeR}
For every message that is not in a suitable buffer, it will undergo exactly a single route change.
\end{lem}   


\begin{proof}
Let  be a message. 
According to Lemma \ref{DeadStable},  progresses in the system (no deadlock happens and no message stays in the same buffer indefinitely). 
So, if  is not in a buffer that is not suitable for it, then  progresses in the system according to the buffer
graph.
Two cases are possible:
\begin{itemize}
\item{ will be in a finite time in the Input buffer of the processor . Since the message is in a buffer that is not suitable for it,  is not the destination of . However we are sure that  will be free in a finite time (refer to Lemma \ref{INTFree}) and that the B-Action will be enabled on  in a finite time too (The PIF is a snap stabilizing algorithm). Hence the message in  will be copied in  and a PIF wave is initiated at the same time. In another hand, it has been shown in Lemma \ref{VPIF} that in the case of a valid PIF wave (Note that this is our case)  when the PIF ends () and C-Initiator is enabled on  (we are sure that this will happen since the PIF is snap stabilizing) and  becomes free. Hence  is enabled on  and the message that is in the extra buffer can be put in the output buffer of  and deleted from the extra buffer. Note that since the network is a chain and  is at the extremity of this chain, we are sure that the message will meet its destination since it can visit all the processors. Hence no other changes route are done.}
\item{The message will reach the input buffer of the processor  that is at the other extremity of the chain (). Since the messages progress in the system (see Lemma \ref{DeadStable})  will be free in a finite time. Hence when a message that is not intended to  is in  and since the daemon is weakly fair, we are sure that  will execute  in a finite time. Thus the message will be copied in  and deleted from . Now since  is at the extremity of the chain, the message will meet its destination hence no other route change is performed and the lemma holds.  }
\end{itemize}
\end{proof}

 Once the routing tables are stabilized, every new message is generated in a suitable buffer.  So, it is clear from Lemma~\ref{changeR} that the number of messages that are not
in a suitable buffer strictly decreases.  The next lemma follows:

\begin{lem}\label{SWBUF}
When the routing tables are stabilized and after a finite time, all the messages are in buffers that are suitable for them.
\end{lem}  

\begin{proof}
When the routing table are stabilized some of the messages still are in buffers that are not suitable for then. However, since the routing tables are stabilized, every message is generated in a suitable buffer, hence the number of 
messages that are in buffers that are not suitable for them does not increase. In another hand, According to Lemma \ref{changeR}, every message that is in the wrong direction will undergo exactly one route change and hence all the wrong messages that are in the system will be in the right direction in a finite time and the lemma holds. 

\end{proof}




 From there, it is important to show that any processor can generate a message in a finite time.  From
Lemma~\ref{SWBUF}, all the messages are in suitable buffers in a finite time.  Since the PIF waves are used for route
changes only, then no PIF wave will be initiated. That what we show in the two following lemmas:

\begin{lem}\label{PIFREQ}
In the case where PIF-Request=true, it will be set at false in a finite time.
\end{lem}  

\begin{proof}
Note that in the case where PIF-request is true and the B-Action of the initiator is enabled on , PIF-Request will be set at false when the B-Action is executed (see B-Action of the initiator). Otherwise two cases are possible according to the state of the initiator:
\begin{itemize}
\item{. In this case PIF-Request is set at false by the forwarding algorithm by executing  ( is enabled on  and the daemon is weakly fair).
\item{}. If  contains a messages and the destination of he message is not  then PIF-Request will be set at false by the PIF algorithm once the PIF-wave is initiated. However in the case where the input buffer of  is empty or contains a message to  then  is enabled and since the daemon is weakly fair  will be executed on  and hence PIF-Request is set at false.}
\end{itemize}
From the cases above we can deduct that if PIF-Request is true then it will be set at false in a finite time and the lemma holds.
\end{proof}


\begin{lem}\label{NOPIF}
When the routing tables are stabilized and all the messages are in suitable buffer, no PIF wave is initiated.
\end{lem}  

\begin{proof}
According to Lemma \ref{PIFREQ}. PIF-Request will be set at false in a finite time. Note that the only rule that set PIF-Request at true is . However  is never enabled since all the messages on the chain are in suitable buffer and since the routing tables are correct (all messages are generated in suitable buffer). Thus the lemma holds.
\end{proof}

From this point, the fair pointer mechanism cannot be disrupted by the PIF waves anymore. So, the fairness of message
generation guarantees the following lemma:
\begin{lem}\label{GMSG}
Any message can be generated in a finite time under a weakly fair daemon.
\end{lem}

\begin{proof}
According to Lemma \ref{NOPIF}, when the routing tables are stabilized and when all the messages are containing in
buffers that are suitable for them no PIF and no Road-change are executed. In another hand since the routing tables
are stabilized and since the buffer graph of the chain consists on two disjoint chains  (it is a DAG) then no deadlock
happens and all the messages progress in the system. Now suppose that the processor  wants to generate a message. Recall that the generation of a message  for the destination  is always done in the output buffer of the processor  connected to the link  such as . Two cases are possible
\begin{enumerate}
\item\label{free}{}. In this case, the processor executes either  or  in a finite time. the result of this execution depends on the value of the pointer. Two cases are possible:
\begin{itemize}
\item{the pointer refers to .} Then  executes  in a finite time and we obtain the result.
\item{the pointer refers to .} Then  executes  in a finite time. Hence  and we retrieve case ~\ref{Nfree}. Note that the fairness of the pointer guarantees us that this case cannot appear infinitely.
\end{itemize}
\item\label{Nfree}{.} Since all the messages move gradually in the buffer graph we are sure that  will be free in a finite time and we retrieve case  ~\ref{free}. \\
\end{enumerate} 
We can deduct that every processor can generate a message in a finite time.
\end{proof}



Due to the color management (Function~), the next lemma follows:

\begin{lem}\label{lem:duplicate}
The forwarding protocol never duplicates a valid message even if  runs simultaneously.
\end{lem}

\begin{proof}
Three cases are possible:
\begin{itemize}
\item{ is in . According to the rules that are enabled on , three cases are possible \\ } 
\begin{itemize}
\item{the message is consumed ( is executed ) hence the message  is deleted from  since a new value overwrites since  (Note that this happen only when .}
\item{ is executed . The message is copied in  (for the processor ) and deleted from  since a new value overwrites () in a sequential manner.}
\item{ is executed. The message is put in this case in  and deleted from  in a sequential manner hence only one copy is kept (  ). Note that these two rules are not enabled only if  does not contain the same message.}
\end{itemize}
\item{ is in . In this case the message  is copied in the input buffer of the processor  (). Hence two copies are in the system. However the message in  is not consumed and not transmitted unless the copy in  is deleted (see the rules  and ). } 
\item{ is in . In this case the message is either deleted or put in . Since this operation is a local operation (the copy is done between two buffer of the same processor) then the message is copied in the new buffer and deleted from the previous one in a sequential manner.}
\end{itemize}

From the cases above we can deduct that no message is duplicated in the system. Hence  is delivered at most once to its destination.
\end{proof}




 From Lemma~\ref{GMSG}, any message can be generated in a finite time.  
 From the PIF mechanism and its synchronization with the forwarding protocol the only message that can be deleted is
the message that was in the extra buffer at the initial configuration.  Thus:



\begin{lem}\label{KeepMSG}
Every valid message (that is generated by a processor) is never deleted unless it is delivered to its destination even
if   runs simultaneously.
\end{lem}  

\begin{proof}
The proof is by contradiction, suppose that there is a message  that is deleted without being delivered to its destination. 


By construction of , this cannot be a result of an internal forwarding since the message  is first of all copied in the Output-buffer  and then erased from the Input-buffer  since a new value overwrites it. Note that these two rules are enabled only if = or . Hence when the message  is copied in the  no message is deleted (one copy remains in  in the case where ). 

By the construction of Rule ,  the message is only copied in the Input-Buffer and not deleted from the Output-buffer at the neighbour processor simultaneously (the only rules that delete a message from the Output-buffer are  and  and the guards of these rules are not verified when  is enabled).

If  is enabled in processes , that means that  and , . When one of these two rules are enabled, . However according to the color management (Function Choice(c)),  we are sure that a copy of the message that was in  is in . 

By the construction of the rules  and , this cannot be the result of the execution of these two rules because the message that is in  such as  and  is not the destination, is copied in the Output buffer and deleted from the Input buffer sequentially and then  copies the message that is in  in  , so no message is deleted.

Concerning ,  such as  contains the message  and , which means that no PIF is executed. However, for , a message in  is copied in   (in the case where  is not the destination) only if  is enabled, however, when  is enabled  is enabled as well. Since in this case the two rules are executed at the same time, hence . Now, for the processor , Since the PIF is a valid PIF, when the  of  is enabled at the same time as the rules  or . If  is executed then  and  (since  or ), which is a contradiction, since in our case . If  is executed, then the message in the extra buffer of  () is copied in ,  becomes free and , which is a contradiction with our case. Hence we are sure that the message that is in the extra buffer of  is a message that was not generated by a processor. Hence when  is executed, this message is deleted (no valid message is deleted).

By the construction of the two rules  and , No valid message is deleted by the execution of the two rules, since the message is copied in the extra buffer () or in the Output buffer () and then it is deleted from the Input buffer () or the extra buffer ().

Concerning the rule , according to Lemma \ref{VPIF}, when the message that is in  is valid, when the  of the initiator is enabled either  or . However no such buffers exist. Hence the message in the extra buffer of  is not a valid message (it is not generated by a processor). Hence it can be deleted.

We can deduct from all the cases above that no message that is generated by a processor is deleted, hence the lemma holds.  

\end{proof}



\begin{theorem}
The proposed algorithm (Algorithms~\ref{algo:PIF} and~\ref{algo:MF}) is a snap-stabilizing message forwarding
algorithm (satisfying SP) under a weakly fair daemon. 
\end{theorem}

\begin{proof}
From Lemma~\ref{GMSG}, any message can be generated in a finite time.  
From Lemma~\ref{KeepMSG}, every valid message is never deleted unless it is delivered to its destination even if  runs simultaneously.
From Lemma~\ref{lem:duplicate}, no valid message is duplicated. 
Hence, the theorem holds.
\end{proof}



\textbf{Remarque}\\For any processor , Forwarding protocol delivers at most  invalid messages.\\


\begin{proof}
Assume that in the initial configuration all the buffers contain a message, since these messages were not generated by the processors of the system, they are invalid messages. Suppose that the destination of the message  in  is the processor  such as  and . Suppose that the daemon activates  which executes  and the F-action (it is a leaf) . Hence the message  is consumed and . Hence  becomes free and the  of the initiator is enabled,  will copy then the message from  in  and will execute the C-Action. In another hand, since there is no way to know if the messages are valid or not, they all be treated as if they are valid. Since the forwarding algorithm is snap stabilizing, all the messages that were in the buffer of the chain at the beginning are delivered. Since there is 4n-3 buffers in the system, then 4n-3 invalid messages can be delivered and the lemma holds. \\
\end{proof}




\section{Dynamicity\label{sec:dynamicity}}

In dynamic environments, processors may leave or join the network at any time. To keep our solution snap stabilizing we assume that there are no crashes and if a processor wants to leave the network (disconnect), it releases its buffers (it sends all the messages it has to send and wait for their reception by its neighbours) and accepts no more message before leaving.

In this discussion we assume that the rebuilt network is still a chain. It is fundamental to see that in dynamic
systems the problem of keeping messages for ghost destinations with the hope they will join the network again and the
lack of congestion are contradictory. If there is no bound on the number of leavings and joins this problem do not
admit any solution. The only way is to redefine the problem in the context of dynamicity. For example we can modify
the second point of the specification \textit{(SP)} as follows: A valid message  generated by the processor  to
the destination  is delivered to  in a finite time if ,  and  are continuously in the same connected
component during the forwarding of the message . Even if that could appear very strong, this kind of hypothesis is
often implied in practice. However we can remark that this new specification is equivalent to  in static
environments. Our algorithm can easily be adapted in order to be snap stabilizing for this new specification in
dynamic chains. 

Thus we can now delete some messages as follows: we suppose that every message has an additional boolean field
initially set to false. When a message reaches an extremity which is not its destination we have two cases:
\textit{(i)} The value of the boolean is false, then the processor sets it to true and sends it in the opposite
direction. \textit{(ii)} The value of the boolean is true, then the processor deletes it (in this case, if the message
is valid, it crossed all the processors of the chain without meeting its destination).

Finally, in order to avoid starvation of some processors, the speed of joins and leavings of the processors has to be
slow enough to avoid a sequence of PIF waves that could prevent some processors to generate some messages.





\section{Conclusion\label{sec:conclu}}

In this paper, we presented the first snap-stabilizing message forwarding protocol that uses 
a number of buffers per node being independent of any global parameter.  Our protocol works on a linear chain and 
uses only  buffers per link.  
It tolerates topology changes (provided that the topology remains a linear chain). 
This is a preliminary version to get the same result on more general topologies.  
In particular, by combining a snap-stabilizing message forwarding protocol with any self-stabilizing overlay protocols 
(\eg \cite{BBKLPR10} for DHT or \cite{AspnesS2003,CDPT07,CDPT08} for \emph{tries}), we would get a solution
ensuring users to get right answers by querying the overlay architecture.

\begin{scriptsize}
\bibliographystyle{splncs}
\bibliography{PIF}
\end{scriptsize}
\end{document}
