In this section, we adapt the ideas used in the algorithms for {\dst} to design improved algorithms for the {\ds} problem and some variants of it in subclasses of degenerated graphs.

\subsection{Introduction for \ds{}}

On general graphs {\ds} is W[2]-com\-ple\-te~\cite{DF99}. However, there are many interesting graph classes where {\FPT}-algorithms exist for {\ds}. The project of expanding the horizon where \FPT{} algorithms exist for \ds{} has produced a number of cutting-edge techniques of parameterized algorithm design. This has made {\ds} a cornerstone problem in parameterized complexity. For an example the initial study of parameterized subexponential algorithms for {\ds}, on planar graphs \cite{AlberBFKN02,FominT06} resulted in the development of bidimensionality theory characterizing a broad range of graph problems  that admit efficient approximation schemes, subexponential time \FPT{} algorithms and efficient polynomial time pre-processing (called {\em kernelization}) on minor closed graph classes~\cite{DemaineFHT05sub,DemaineHaj05}. Alon and Gutner~\cite{AlonG09} and Philip, Raman, and Sikdar~\cite{PhilipRS09} showed that \ds{} problem is {\FPT} on graphs of bounded degeneracy and on $K_{i,j}$-free graphs,  
respectively.

Numerous papers also concerned the approximability of \ds{}. It follows from~\cite{DuhF97} that \ds{} on general graphs can approximated to within roughly $\ln(\Delta(G)+1)$, where $\Delta(G)$ is the maximum degree in the graph $G$. On the other hand, it is NP-hard to approximate \ds{} in bipartite graphs of degree at most $B$ within a factor of $(\ln B - c\ln \ln B)$, for some absolute constant $c$~\cite{ChlebikC08}. Note that a graph of degree at most $B$ excludes $K_{B+2}$ as a topological minor, and, hence, the hardness also applies to graphs excluding $K_h$ as a topological minor. While a polynomial time approximation scheme (PTAS) is known for $K_h$-minor-free graphs~\cite{Grohe03}, we are not aware of any constant factor approximation for \ds{} on graphs excluding $K_h$ as a topological minor or $d$-degenerated graphs.



Based on the ideas from previous sections, we develop an algorithm for \ds{}.
Our algorithm for {\ds} on $d$-degenerated graphs improves over the $O^*(k^{O(dk)})$ time algorithm by Alon and Gutner~\cite{AlonG09}. In fact, it turns out that our algorithm is essentially optimal -- we show that, assuming the \ETH{}, the running time dependence of our algorithm on the degeneracy of the input graph and solution size $k$ cannot be significantly improved. Furthermore, we also give a factor $O(d^2)$ approximation algorithm for {\ds} on $d$-degenerated graphs. A list of our results for {\ds} is given below.

\begin{enumerate}
\item There is a $\bigoh^*(3^{hk+o(hk)})$-time algorithm for \ds{} on graphs excluding $K_h$ as a topological minor.
\item There is a $\bigoh^*(3^{dk+o(dk)})$-time algorithm for \ds{} on $d$-degenerated graphs. This implies that \ds{} is \FPT{} on $o(\log n)$-degenerated classes of graphs.
\item For any constant $c>0$, there is no $f(k)n^{o({\frac k {\log k} })}$-time algorithm on graphs of degeneracy $c \log n$ unless {\ETH} fails.
\item  There are no two functions $f$ and $g$ such that $g(d)=o(d)$ and there is an algorithm for {\ds} running in time $\bigoh^*(2^{g(d)f(k)})$, unless {\ETH} fails.
\item  There are no two functions $f$ and $g$ such that $f(k)=o(k)$ and there is an algorithm for {\ds} running in time $\bigoh^*(2^{g(d)f(k)})$, unless {\ETH} fails.
\item There is a $O(dn\log n)$ time factor $O(d^2)$ approximation algorithm for {\ds} on $d$-degenerated graphs.
\end{enumerate}

\subsection{{\ds} on graphs of bounded degeneracy}

We begin by giving an algorithm for {\ds} running in time $\bigoh^*(3^{hk+o(hk)})$ in graphs excluding $K_h$ as a topological minor. This improves over the $\bigoh^*(2^{\bigoh(kh \log h)})$ algorithm of \cite{AlonG09}. Though the algorithm we give here is mainly built on the ideas developed for the algorithm for {\dst}, the algorithm has to be modified slightly in certain places in order to fit this problem. We also stress this an example of how these ideas, with some modifications, can be made to fit problems other than {\dst}. We begin by proving lemmata required for the correctness of the base cases of our algorithm.


\begin{lemma}\label{lem:base_case_domset}
 Let $(G,k)$ be an instance of {\ds}. Let $Y\subseteq V$ be a set of vertices and let $B$ be the set of vertices (other than $Y$) dominated by $Y$. Let $W$ be the set of vertices of $G$ not dominated by $Y$, $B_h$ be the set of vertices of $B$ which dominate at least $d+1$ terminals in $W$ for some constant $d$, $B_l$ be the rest of the vertices of $B$, $W_h$ be the vertices of $W$ which have neighbors in $B_h\cup W$. If $\vert W\setminus W_h\vert >d(k-\vert Y\vert)$, then the given instance does not admit a solution which contains~$Y$.
\end{lemma}
\begin{proof}
Let $W\setminus W_h=W_l$. Since any vertex in $W_l$ does not have neighbors in $B_h\cup W\cup Y$, $G[W_l]$ is an independent set, and the only vertices which can dominate a vertex in $W_l$ are either itself, or a vertex of $B_l$. Any vertex of $W_l$ can only dominate itself (vertices of $B_l$ are already dominated by $Y$) and any vertex of $B_l$ can dominate at most $d$ vertices of $W$. Hence, if $\vert W_l\vert>d(k-\vert Y\vert)$, $W_l$ cannot be dominated by adding $k-\vert Y\vert$ vertices to $Y$. This completes the proof.  
\end{proof}






\begin{lemma}\label{lem:base_case_nederlof_domset}
 Let $(D,k)$ be an instance of {\ds}. 
Let $Y\subseteq V$ be a set of vertices and let $B$ be the set of vertices (other than $Y$) dominated by $Y$. Let $W$ be the set of vertices of $G$ not dominated by $Y$, $B_h$ be the set of vertices of $B$ which dominate at least $d+1$ terminals in $W$ for some constant $d$, $B_l$ be the rest of the vertices of $B$, $W_h$ be the vertices of $W$ which have neighbors in~$B_h\cup W$.

If $B_h\cup W_h$ is empty, then there is an algorithm which can test if this instance has a solution containing $Y$ in time~$\bigoh^*(2^{d(k-|Y|)})$.
\end{lemma}

\begin{proof}
The premises of the lemma imply that the only potentially non-empty sets are $Y$, $B_l$ and $W=W_l$. If $W$ is empty, we are done. Suppose $W$ is non-empty. 
We know that $\vert Y\vert \leq k$ and, by Lemma~\ref{lem:base_case_domset}, we can assume that $\vert W\vert \leq d(k-\vert Y\vert)$. 
Since $W$ is an independent set, the only vertices the vertices of $W$ can dominate (except for vertices dominated by $Y$), are themselves. Thus it is never worse to take a neighbor of them in the solution if they have one. The isolated vertices from $W$ can be simply moved to $Y$, as we have to take them into the solution. Now, it remains to find a set of vertices of $B_l$ of the appropriate size such that they dominate the remaining vertices of $W$. But in this case, we can reduce it to an instance of {\dst} and apply the algorithm from Lemma~\ref{lem:nederlof}.
The reduction is as follows. Consider the graph $G[B_l\cup W]$. Remove all edges between vertices in $B_l$. Let this graph be $G_{dst}$. Simply add a new vertex $r$ and add directed edges from $r$ to every vertex in $B_l$. Also orient all edges between $B_l$ and $W$, from $B_l$ to $W$. Now, $W$ is set as the terminal set. Now, since $\vert W\vert\leq dk$, it is easy to see that the algorithm \textsc{Nederlof}$(G_{dst},r, W,W)$ runs in time $\bigoh^*(2^{d(k-|Y|)})$.
 This completes the proof of the lemma. 
\end{proof}









\begin{theorem}\label{thm:top_algo_ds}
 {\ds} can be solved in time $\bigoh^*(3^{hk+o(hk)})$ on graphs excluding $K_h$ as a topological minor.
\end{theorem}


\begin{proof}

The algorithm we describe takes as input an instance $(G,k)$, and vertex sets $B,W, B_h$, $B_l$, $W_h$, $W_l$ and $Y$ and returns a smallest solution for the instance, which contains $Y$ if such a solution exists. If there is no such solution, then the algorithm returns a dummy symbol $S_\infty$. To simplify the description, we assume that $|S_\infty| = \infty $. The algorithm is a recursive algorithm and at any stage of recursion, the corresponding recursive step returns the smallest set found in the recursions initiated in this step.
For the purpose of this proof, we will always have $d_b=h-2$.  Initially, all the sets mentioned above are empty. 




\begin{figure}[t]
\centering
\includegraphics[width=250 pt,height=155 pt]{partition_ds.pdf}
\caption{An illustration of the sets defined in Theorem~\ref{thm:top_algo_ds}}
\label{fig:partition_domset}
\end{figure}



\noindent
At any point, while updating these sets, we will maintain the following invariants (see Fig.~\ref{fig:partition_domset}).
\begin{itemize}
\item The sets $B_h$, $B_l$, $W_h$, $W_l$ and $Y$ are pairwise disjoint.
\item The set $Y$ has size at most $k$.
\item $B$ is the set of vertices dominated by $Y$.
\item $W$ is the set of vertices not dominated by $Y$.
\item $B_h$ is the set of vertices of $B$ which dominate at least $d_b+1$ vertices of $W$.
\item $B_l$ is the set of vertices of $B$ which dominate at most $d_b$ vertices of $W$.
\item $W_h$ is the set of vertices of $W$ which have a neighbor in $B_h\cup W$.
\item $W_l$ are the remaining vertices of $W$.
\end{itemize}



\noindent

Observe that the sets $B_l$, $W_h$ and $W_l$ correspond to the sets $B_l$, $W_h$ and $W\setminus W_h$ defined in the statement of Lemma~\ref{lem:base_case_domset}. 
Hence, by Lemma~\ref{lem:base_case_domset}, if $\vert W_l\vert>d_b(k-\vert Y\vert)$, then there is no solution containing $Y$ and hence we return $S_\infty$ (see Algorithm~\ref{algo:minor_algo_domset}). 
If $B_h\cup W_h$ is empty, then we apply Lemma~\ref{lem:base_case_nederlof_domset} to solve the problem in time $\bigoh^*(2^{d_b (k-|Y|)})$. If $B_h\cup W_h$ is non-empty, then we find a vertex $v\in W_h$ with the least neighbors in $B_h\cup W_h$. Let $N$ be the set of these neighbors and let $\vert N\vert=d_w$. 

We then branch into $d_w+2$ branches described as follows. In the first $d_w+1$ branches, we move a vertex $u$ of $N \cup \{v\}$, to the set $Y$, and perform the following updates. We move the vertices of $W$ which are adjacent to $u$, to $B$, and update the remaining sets in a way that maintains the invariants mentioned above. More precisely, set $B_h$ as the set of vertices of $B$ which dominate at least $d_b+1$ vertices of $W$, $B_l$ as the set of vertices of $B$ which dominate at most $d_b$ vertices of $W$, $W_h$ as the set of vertices of $W$ which have a neighbor in $B_h\cup W$, and $W_l$ as the rest of the vertices of $W$. Finally, we recurse on the resulting instance.



In the last of the $d_w+2$ branches, that is, the branch where we have guessed that none of the vertices of $N$ are in the dominating set, we move the vertex $v$ to $W_l$, delete the vertices of $N\cap B_h$ and the edges from $v$ to $N\cap W_h$, to obtain the graph $G^\prime$. Starting from here, we then update all the sets in a way that the invariants are maintained. More precisely, set $B$ as the set of vertices dominated by $Y$, $W$ as the set of vertices not dominated by $Y$, set $B_h$ as the set of vertices of $B$ which dominate at least $d_b+1$ vertices of $W$, $B_l$ as the set of vertices of $B$ which dominate at most $d_b$ vertices of $W$, $W_h$ as the set of vertices of $W$ which have a neighbor in $B_h\cup W$, and $W_l$ as the rest of the vertices of $W$. Finally, we recurse on the resulting instance.\\


\noindent
{\bf Correctness.}
At each node of the recursion tree, we define a measure $\mu(I)=d_b (k-\vert Y\vert)-\vert W_l\vert$. We prove the correctness of the algorithm by induction on this measure. In the base case, when $d_b (k-\vert Y\vert)-\vert W_l\vert < 0$, then the algorithm is correct (by Lemma~\ref{lem:base_case_domset}). Now, we assume as induction hypothesis that the algorithm is correct on instances with measure less than some $\mu\geq 0$. Consider an instance $I$ such that $\mu(I)=\mu$. Since the branching is exhaustive, it is sufficient to show that the algorithm is correct on each of the child instances. To show this, it is sufficient to show that for each child instance $I^\prime$, $\mu(I^\prime)<\mu(I)$. In the first $d_w+1$ branches, the size of the set $Y$ increases by 1, and the size of the set $W_l$ does not decrease ($W_l$ has no neighbors in $B_h\cup W_l$). Hence, in each of these branches, $\mu(I^\prime)\leq \mu(I)-d_b$. In the final branch, though the size of the set $Y$ remains the 
same, the size of the set $W_l$ increases by at least 1. 
Hence, in this branch, $\mu(I^\prime)\leq \mu(I)-1$. Thus, we have shown that in each branch, the measure drops, hence completing the proof of correctness of the algorithm.\\

\begin{algorithm}[t]
   \SetKwInOut{Input}{Input}\SetKwInOut{Output}{Output}
  \Input{An instance $(G,k)$ of {\ds}, degree bound $d_b$, sets $B_h$, $B_l$, $Y$, $W_h$, $W_l$}
  \Output{A smallest solution of size at most $k$ and containing $Y$ for the instance $(D,k)$ if it exists and $S_\infty$ otherwise}

  \lIf{$\vert W_l\vert>d_b(k-\vert Y\vert)$}{\Return $S_\infty$}

   \ElseIf{$B_h=\emptyset$}{
      $S \leftarrow$ \textsc{Nederlof}$(G_{dst},r,W,W)$.\\
 \lIf{$|S| > k$}{$S \leftarrow S_\infty$}\\
 \Return $S$\\
 }

\Else{
$S \leftarrow S_\infty$\\
  \emph{Find vertex $v\in W_h$ with the least neighbors in $B_h\cup W_h$.}\\
\For{$u\in ((B_h \cup W_h)\cap N[v])$}{ $Y=Y\cup \{u\}$, perform updates to get $B_h^\prime$, $B_l^\prime$, $W_h^\prime$, $W_l^\prime$.\\
$S'\leftarrow$ {\sc DS-solve}($(G,k),d_b,B_h^\prime, B_l^\prime, Y, W_h^\prime, W_l^\prime$).\\
\lIf{$|S'| < |S|$}{$S \leftarrow S'$}\\
}
$W_l \leftarrow W_l\cup\{v\}$, perform updates to get new graph $G^\prime$ and sets $B_h^\prime$, $B_l^\prime$, $W_h^\prime$,$W_l^\prime$.\\
$S'\leftarrow$ {\sc DS-solve}($(G^\prime,k),d_b,B_h^\prime, B_l^\prime, Y, W_h^\prime, W_l$).\\
\lIf{$|S'| < |S|$}{$S \leftarrow S'$}\\
  \Return $S$
}
 \BlankLine
  \caption{Algorithm {\sc DS-solve} for {\ds}}\label{algo:minor_algo_domset}
\end{algorithm}\noindent
{\bf Analysis.} 
Since $D$ exludes $K_h$ as a topological minor, Lemma~\ref{lem:minorfree_small_degree}, combined with the fact that we set $d_b = h-2$, implies that $d_w^{\max}=ch^4$, for some $c$, is an upper bound on the maximum $d_w$ which can appear during the execution of the algorithm. 
We first bound the number of leaves of the recursion tree as follows. The number of leaves is bounded by 
$\sum_{i=0}^{d_b k} \binom{d_b k}{i} (d_w^{\max}+1)^{k-{\frac i {d_b}}}$. To see this, observe that each branch of the recursion tree can be described by a length-$d_b k$ vector as shown in the correctness paragraph. We then select $i$ positions of this vector on which the last branch was taken. Finally for  $k-{\frac i {d_b}}$ of the remaining positions, we describe which of the first at most $(d_w^{\max}+1)$ branches was taken. Any of the first $d_w^{max}+1$ branches can be taken at most $k-{\frac i {d_b}}$ times if the last branch is taken $i$ times.

The time taken along each root to leaf path in the recursion tree is polynomial, while the time taken at a leaf  for which the last branch was taken $i$ times is $\bigoh^*(2^{d_b (k - (k-{\frac i {d_b}}))})=\bigoh^*(2^{i+k})$ 
(see Lemmata~\ref{lem:base_case_domset} and~\ref{lem:base_case_nederlof_domset}). 
Hence, the running time of the algorithm is 
\[
\bigoh^* \left(\sum_{i=0}^{d_bk} \binom{d_bk}{i} (d_w^{\max}+1)^{k-{\frac i {d_b}}}\cdot 2^{i+k} \right)
=\bigoh^*\left((2d_w^{\max}+2)^k \cdot \sum_{i=0}^{d_bk} \binom{d_bk}{i} \cdot 2^i \right) =\bigoh^*\left((2d_w^{\max}+2)^k \cdot 3^{d_b k} \right).
\]
For $d_b= h-2$ and $d_w^{\max} =ch^4$
this is $\bigoh^*(3^{hk + o(hk)})$. This completes the proof of the theorem.

\end{proof}








\noindent
Observe that, when Algorithm \ref{algo:minor_algo_domset} is run on a graph of degeneracy $d$, setting $d_b=d$, combined with the simple fact that $d_w^{max}\leq d$ gives us the following theorem.

\begin{theorem}\label{}
 {\ds} can be solved in time $\bigoh^*(3^{dk+o(dk)})$ on graphs of degeneracy $d$.
\end{theorem}

\noindent
From the above two theorems and Lemma~\ref{lem:littleo}, we have the following corollary.

\begin{corollary}
If $\mathcal{C}$ is a class of graphs excluding $o(\log n)$-sized topological minors or an $o(\log n)$-degenerated class of graphs, then {\ds} parameterized by $k$ is {\FPT} on $\mathcal{C}$. 
\end{corollary}

\subsection{Hardness}

\begin{theorem}\label{thm:ds hardness logn}
{\ds} cannot be solved in time $f(k)n^{o({\frac {k} {\log k}})}$ on $c\log n$-degenerated graphs for any constant $c>0$, where $k$ is the solution size and $f$ is an arbitrary function, unless {\ETH} fails.
\end{theorem}

\begin{proof}
The proof is by a reduction from the restricted version of {\sc Set Cover} shown to be hard in Lemma~\ref{lem:set cover hardness}. Fix a constant $c>0$ and let $({\cal U}=\{u_1,\dots,u_n\},{\cal F}=\{F_1,\dots,F_m\},k)$ be an instance of {\sc Set Cover}, where the size of any set is at most $\gamma \log m$ for some constant $\gamma$. For each set $F_i$, we have a vertex $f_i$. For each element $u_i$, we have a vertex $x_i$. If an element $u_i$ is contained in the set $F_j$, then we add an edge $(f_j,x_i)$. Further, we add two vertices $r$ and $p$ and add edges $(r,f_i)$ for every $i$ and an edge $(r,p)$. Finally, we add star of size $m^{2\gamma/c}$ centered in $q$ disjoint from the rest of the graph. This completes the construction of the graph $G$. 

We claim that $({\cal U}, {\cal F}, k)$ is a {\Yes} instance of {\sc Set Cover} iff $(G,k+2)$ is a {\Yes} instance of {\ds}. Suppose that $\{F_1,\dots,F_k\}$ is a set cover for the given instance. It is easy to see that the vertices $q,r,f_1,\dots, f_k$ form a solution for the {\ds} instance.

In the converse direction, since one of $p$ and $r$ and at least one vertex of the star must be in any dominating set, we assume without loss of generality that $r$ and $q$ are contained in the minimum dominating set. Also, since $r$ dominates any vertex $f_i$, we may also assume that the solution is disjoint from the $x_i$'s. This is because, if $x_i$ was in the solution, we can replace it with an adjacent $f_j$ to get another solution of the same size. Hence, we suppose that $\{q,r,f_1,\dots, f_k\}$ is a solution for the {\ds} instance. Since the only way that some vertex $x_i$ can be dominated is by some $f_j$, and the construction implies that $u_i\in F_j$, the sets $\{F_1,\dots, F_k\}$ form a set cover for $({\cal U}, {\cal F}, k)$. This concludes the proof of equivalence of the two instances.

We claim that the degeneracy of the graph $G$ is bounded by $c \log  n_1$, where $n_1$ is the number of vertices in the graph $G$. First, we claim that the degeneracy of the graph $G$ is bounded by $\gamma \log m+1$. This follows from that each vertex $f_i$ has total degree at most $\gamma \log m +1$, each leaf of the star has degree 1 and if a subgraph contains none of these vertices, then it contains no edges.  Now, $n_1$ is at least $m^{2\gamma/c}$. Hence, $\log n_1  \geq (2\gamma/c)\log m$ and the degeneracy of the graph is at most $\gamma \log m +1 \leq c \cdot (2\gamma/c) \log m \leq c \log n_1$. Finally, since each vertex $f_i$ is incident to at most $\gamma \log m +1$ vertices, $n_1=\bigoh(m \log m + m^{2\gamma/c})$ and, thus, it is polynomial in $m$. Hence, an algorithm for {\ds} of the form $f(k)n_1^{o(\frac{k}{\log k})}$ implies an algorithm of the form $f(k)m^{o(\frac{k}{\log k})}$ for the {\sc Set Cover} instance. This concludes the proof of the theorem.
\end{proof}



\noindent
As a corollary of Theorem~\ref{thm:ds hardness logn}, and Lemma~\ref{lem:littleo}, we have the following corollary.



\begin{corollary}\label{cor:dependency on d}
There are no two functions $f$ and $g$ such that $g(d)=o(d)$ and there is an algorithm for {\ds} running in time $\bigoh^*(2^{g(d)f(k)})$ unless {\ETH} fails.
\end{corollary}




\noindent
From Theorem~\ref{thm:bounded degree subexp hard}, we can infer the following corollary.

\begin{corollary}\label{cor:dependency on k}
 There are no two functions $f$ and $g$ such that $f(k)=o(k)$ and there is an algorithm for {\ds} running in time $\bigoh^*(2^{g(d)f(k)})$, unless {\ETH} fails.
\end{corollary}

\begin{proof}
Suppose that there were an algorithm for {\ds} running in time $\bigoh^*(2^{g(d)f(k)})$, where $f(k)=o(k)$. Consider an instance $(G,k)$ of {\ds} where $G$ is a graph with maximum degree $c$. We can assume that the number of vertices of the graph is at most $ck+k$, since otherwise, it is a trivial {\No} instance. Hence, $k=\Theta(n)$ and thus, an algorithm running in time $\bigoh^*(2^{g(d)f(k)})$ will run in time $\bigoh^*(2^{g(c)f(k)})=\bigoh^*(2^{o(n)})$, and, by Theorem~\ref{thm:bounded degree subexp hard}, ETH fails.  
\end{proof}

\noindent
Thus, Corollaries \ref{cor:dependency on d} and \ref{cor:dependency on k} together show that, unless {\ETH} fails, our algorithm for {\ds} has the best possible dependence on both the degeneracy and the solution size.\\



\subsection{Approximating {\ds} on graphs of bounded degeneracy}

In this section, we adapt the ideas developed in the previous subsections, to design a polynomial-time $O(d^2)$-approximation algorithm for the {\ds} problem on $d$-degenerated graphs.

\begin{theorem}\label{thm:approx_ds}
 There is a $O(dn\log n)$-time $d^2$- approximation algorithm for the {\ds} problem on $d$-degenerated graphs. \end{theorem}

 \begin{proof}
The approximation algorithm is based on our {\FPT} algorithm, but whenever the branching algorithm would branch, we take all candidates into the solution and cycle instead of recursing. During the execution of the algorithm the partial solution is kept in the set $Y$ and vertex sets $B, W, B_h$, $B_l$, $W_h$, and $W_l$ are updated with the same meaning as in the branching algorithm. In the base case, all vertices of $W_l$ are taken into the solution. This last step could be replaced by searching a dominating set for the vertices in $W_l$ by some approximation algorithm for \textsc{Set Cover}. While this would probably improve the performance of the algorithm in practice, 
it does not 
improve the theoretical worst case bound.

\begin{algorithm}[t]
   \SetKwInOut{Input}{Input}\SetKwInOut{Output}{Output}
  \Input{An Undirected graph $G=(V,E)$ without isolated vertices}\Output{A dominating set for $G$ of size at most $O(d^2)$ times the size of a minimum dominating set}
$Y \leftarrow \emptyset$\\
$W_h \leftarrow V$\\
\While{$W_h \neq \emptyset$}
{\emph{Find vertex $v\in W_h$ with the least neighbors in $B_h\cup W_h$.}\label{approx_algo:find}\\
$Y \leftarrow Y \cup ((B_h \cup W_h)\cap N(v))$\label{approx_algo:branch}\\
$B \leftarrow$ vertices in $V\setminus Y$ with a neighbor in $Y$\\
$W \leftarrow V \setminus (Y \cup B)$\\
$B_h \leftarrow$ vertices in $B$ with at least $d+1$ neighbors in $W$\\
$B_l \leftarrow B \setminus B_h$\\
$W_h \leftarrow$ vertices in $W$ with a neighbor in $B_h$ or $W$\\
$W_l \leftarrow W \setminus W_h$\\
}
$Y \leftarrow Y \cup W_l$\label{approx_algo:base}\\
\Return $Y$\\
\BlankLine
\caption{Algorithm {\sc DS-approx} for {\ds}}\label{algo:approx_domset}
\end{algorithm}

 \noindent
{\bf Correctness.}
It is easy to see that the set $Y$ output by the algorithm is a dominating set for $G$. Now let $Q$ be an optimal dominating set for $G$. We want to show that $|Y|$ is at most $d^2$ times $|Q|$. In particular, we want to account every vertex of $Y$ to some vertex of $Q$, which ``should have been chosen instead to get the optimal set.'' Before we do that let us first observe, how the vertices can move around the sets during the execution of the algorithm. Once a vertex is added to $Y$ it is never removed. Hence, once a vertex is moved from $W$ to $B$, it is never moved back. But then the vertices in $B$ are only losing neighbors in $W$, and once they get to $B_l$ they are never moved anywhere else. Thus, vertices in $W_l$ can never get a new neighbor in $W$ or $B_h$ and they also stay in $W_l$ until Step~\ref{approx_algo:base}. The vertices of $B_h$ can get to $Y$ or $B_l$ and the vertices of $W_h$ can get to any other set during the execution of the algorithm.

Now let $v$ be the vertex found in Step~\ref{approx_algo:find} of Algorithm~\ref{algo:approx_domset} and $w$ be the vertex dominating it in $Q$. As in the branching algorithm, we know that $|(B_h \cup W_h)\cap N(v)| \leq d$ since the subgraph of $G$ induced by $(B_h \cup W_h)$ is $d$-degenerated. Hence at most $d$ vertices are added to $Y$ in Step~\ref{approx_algo:branch} of the algorithm. We charge the vertex $w$ for these at most $d$ vertices and make the vertex $v$ responsible for that. Finally, in Step~\ref{approx_algo:base} let $v \in W_l$ and $w$ be a vertex which dominates it in $Q$. We charge $w$ for adding $v$ to $Y$ and make $v$ responsible for it. Obviously, for each vertex added to $Y$, some vertex is responsible and some vertex of $Q$ is charged. It remains to count for how many vertices can be a vertex of $Q$ charged. 

Observe that whenever a vertex is responsible for adding some vertices to $Y$, it is $W$ and after adding these vertices it becomes dominated and, hence, moved to $B$. Therefore, each vertex becomes responsible for adding vertices only once and, thus, each vertex is responsible for adding at most $d$ vertices to $Y$. Now let us distinguish in which set a vertex $w$ of $Q$ is, when it is first charged. If $w$ is first charged in Step~\ref{approx_algo:branch} of the algorithm, then a vertex $v \in W_h$ is responsible for that and $w$ has to be either in $W_h$, $B_h$, or $B_l$, as vertices in $W_h$ do not have neighbors elsewhere. In the first two cases, if $w \neq v$, then it is moved to $Y$ and hence has no neighbors in $W$ anymore. If $v=w$, then it is moved to $B_l$, and it has no neighbors in $W$, as all of them are moved to $Y$. Thus, in these cases, after the step is done, $w$ has no neighbors in $W$ and, hence, is never charged again. If $w$ is in $B_l$, then it has at most $d$ neighbors in $W$ and, as each of them is responsible for adding at most $d$ vertices to $Y$, $w$ is charged for at most $d^2$ vertices. If a vertex $w$ is first charged in Step~\ref{approx_algo:base}, then it is $B_l$ or $W_l$, has at most $d$ neighbors in $W_l$, each of them being responsible for addition of exactly one vertex, so it is charged for addition of at most $d$ vertices. It follows, that every vertex of $Q$ is charged for addition of at most $d^2$ to $Y$ and, therefore, $|Y|$ is at most $d^2$ times $|Q|$.

 \noindent
{\bf Running time analysis.} 
To see the running time, observe first that by the above argument, every vertex is added to each of the sets at most once. Also a vertex is moved from one set to another only if some of its neighbors is moved to some other set or it is selected in Step~\ref{approx_algo:find}. Hence, we might think of a vertex sending a signal to all its neighbor, once it is moved to another set. There are only constantly many signals and each of them is sent at most once over each edge in each direction. Hence, all the updations of the sets can be done in $O(m)=O(dn)$-time, as the graph is $d$-degenerate. 
Also each vertex in $W_h$ can keep its number of neighbors in $W_h \cup B_h$ and update it whenever it receives a signal from some of its neighbors about being moved out of $W_h \cup B_h$. We can keep a heap of the vertices in $W_h$ sorted by a degree in  $W_h \cup B_h$ and update it in $O(\log n)$ time whenever the degree of some of the vertices change. This means $O(dn\log n)$ time to keep the heap through the algorithm. Using the heap, the vertex $v$ in Step~\ref{approx_algo:find} can be found in $O(\log n)$-time in each iteration. As in each iteration at least one vertex is added to $Y$, there are at most $n$ iterations and the total running time is $O(dn\log n)$.
\end{proof}

This algorithm can be also used for $K_h$-minor-free and $K_h$-topological-minor free graphs, yielding $O(h^2\cdot \log h)$-approximation and $O(h^4)$-approximation, as these graphs are $O(h \cdot \sqrt{\log h})$ and $O(h^2)$-degenerated, respectively. As far as we know, this is also the first constant factor approximation for dominating set in $K_h$-topological-minor free graphs. Although PTAS is known for $K_h$-minor-free graphs~\cite{Grohe03}, our algorithm can be still of interest due to its simplicity and competitive running time.