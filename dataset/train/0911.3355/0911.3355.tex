\documentclass{article}
\usepackage{fullpage,amssymb,amsmath,amsthm,algorithm2e}
\usepackage[all]{xy}
\def\eat#1{}
\def\us{\char`\_}
\def\subw#1#2#3{{#1[#2\,..\,#3]}}
\def\abs#1{{|\,#1\,|}}
\def\tree{\mathcal{T}}
\def\lca{\mathrm{lca}}
\newtheorem{theorem}{Theorem}
\newtheorem{proposition}[theorem]{Proposition}
\newtheorem{example}[theorem]{Example}
\newtheorem{lemma}[theorem]{Lemma}
\SetKw{KwFrom}{from} \SetKw{KwContinue}{continue}
\SetKw{KwBreak}{break} \SetKwFunction{KwExtend}{extend}
\SetKwFunction{KwSuffixTree}{make\us suffix\us tree}
\SetKwFunction{KwComputeMP}{compute\us mp}
\SetKwFunction{KwExtendMP}{extend\us mp}
\SetKwFunction{KwComputeRMP}{compute\us rmp}
\SetKwFunction{KwComputeLMP}{compute\us lmp}
\SetKwFunction{KwComputeCMP}{compute\us cmp}


\title{A Minimal Periods Algorithm with Applications}
\author{Zhi Xu}
\date{The University of Western Ontario, \\
Department of Computer Science, \\
Middlesex College, \\
London, Ontario, Canada N6A 5B7 \\
{\tt zhi\us xu@csd.uwo.ca} \\
\medskip
\today}
\begin{document}
\maketitle


\begin{abstract}
Kosaraju in ``Computation of squares in a string'' briefly described a
linear-time algorithm for computing the minimal squares starting at
each position in a word. Using the same construction of suffix
trees, we generalize his result and describe in detail how to
compute in -time the minimal th power, with period
of length larger than , starting at each position in a word 
for arbitrary exponent  and integer . We provide the
complete proof of correctness of the algorithm, which is somehow not
completely clear in Kosaraju's original paper. The algorithm can be
used as a sub-routine to detect certain types of pseudo-patterns in
words, which is our original intention to study the generalization.
\end{abstract}


\section{Introduction}
A word of the form  is called a square, which is the simplest
type of repetition. The study on repetitions in words has been
started at least as early as Thue's work \cite{Thue1906} in the
early 1900's. Since then, there are many work in the literature on
finding repetitions (periodicities), which is an important topic in
combinatorics on words. In the early 1980's, Slisenko
\cite{Slisenko1983} described a linear-time algorithm for finding
all syntactically distinct maximal repetitions in a word. Crochemore
\cite{Crochemore1983}, Main and Lorentz \cite{Main&Lorentz1985}
described a linear-time algorithm for testing whether a word
contains a square and thus testing whether a word contains any
repetition. Since a word  of length  may have 
square factors (for example, let ), usually only
primitively-rooted or maximal repetitions are computed. Crochemore
\cite{Crochemore1981} described an -time algorithm for
finding all maximal primitively-rooted integer repetitions, where
maximal means that a th power cannot be extend by either
direction to obtain a th power. The -time is
optimal since a word  of length  may have 
primitively-rooted repetitions (for example, let  be a Fibonacci
word). Apostolico and Preparata \cite{Apostolico&Preparata1983}
described an -time algorithm for finding all
right-maximal repetitions, which means a repetition  cannot be
extend to the right to obtain a repetition  such that
. Main and Lorentz \cite{Main&Lorentz1984}
described an -time algorithm for finding all maximal
repetitions. Gusfield and Stoye
\cite{Stoye&Gusfield1998,Gusfield&Stoye2004} also described several algorithms on finding repetitions. We know
that both the number of distinct squares \cite{Fraenkel&Simpson1998}
and the number of maximal repetitions (also called runs)
\cite{Kolpakov&Kucherov1999} in a words are in . This fact
suggests the existence of linear-time algorithms on repetitions that
are distinct (respectively, maximal). Main \cite{Main1989} described
a linear-time algorithm for finding all leftmost occurrences of
distinct maximal repetitions. Kolpakov and Kucherov
\cite{Kolpakov&Kucherov1999} described a linear-time algorithm for
finding all occurrences of maximal repetitions. For a most-recently
survey on the topic of repetitions in words, see the paper
\cite{Crochemore&Ilie&Rytter2009}.


Instead of considering repetitions from a global point of view,
there are works on a local point of view, which means repetitions at
each positions in a word. Kosaraju in a five-pages extended abstract
\cite{Kosaraju1994} briefly described a linear-time algorithm for
finding the minimal square starting at each position of a given
word. His algorithm is based on an alternation of Weiner's
linear-time algorithm for suffix-tree construction. In the same
flavor, Duval, Kolpakov, Kucherov, Lecroq, and Lefebvre
\cite{Duval&Kolpakov&Kucherov&Lecroq&Lefebvre2004} described a
linear-time algorithm for finding the local periods (squares)
centered at each position of a given word. There may be  primarily-rooted maximal repetitions starting at the same
position (for example, consider the left-most position in Fibonacci
words). So, neither of the two results can be obtained with the same
efficiency by directly applying linear-time algorithms on finding
maximal-repetitions.


In this paper, we generalize Kosaraju's algorithm
\cite{Kosaraju1994} for computing minimal squares. Instead of
squares, we discuss arbitrary th powers and show Kosaraju's
algorithm with proper modification can in fact compute minimal th
powers. Using the same construction of suffix trees, for arbitrary
integers  and , we describe in details a
-time algorithm for finding the minimal th power,
with period of length larger than , starting at each position of
a given word . ``\emph{The absence of a complete proof prevents
the comprehension of the algorithm} (Kosaraju's algorithm) \emph{in
full details
\ldots}.''\cite{Duval&Kolpakov&Kucherov&Lecroq&Lefebvre2004} In this
paper, we provide a complete proof of correctness of the modified
algorithm. At the end, we show how this -time algorithm
can be used as a sub-routine to detect certain types of
pseudo-patterns in words, which is the original intention why we
study this algorithm.


\section{Preliminary}
Let  be a word. The \emph{length}  of
 is . A \emph{factor}  of  is the word
 if ; otherwise
 is the \emph{empty word} . In particular,
 and  are called \emph{prefix} and
\emph{suffix}, respectively. The \emph{reverse} of  is the word
. Word  is called a \emph{th power} for
integer  if  for some non-empty word , where 
is called \emph{exponent} and  is called \emph{period}. The nd
power and the rd power are called \emph{square} and \emph{cube},
respectively.


The \emph{minimal (local) period}  larger than  of
word  with respect to exponent  is the smallest integer 
such that  is a th power, if there is such
one, or otherwise . For example,
 and . The
following results follow naturally by the definition of minimal
period.


\begin{lemma}\label{lemma:mpexpd}
Let  and  be two integers and  be a word. If
, then for any word ,
  
\end{lemma}
\begin{proof}
Suppose . We can write  for some
words  with . Then  and thus  is also a
prefix of . So , which
contradicts to our hypothesis. So . On the
other hand, if any word  is a prefix of , the word  is
also a prefix of . So . Therefore,
.
\end{proof}


\begin{lemma}\label{lemma:mpshrk}
Let  and  be two integers and  be a word. For any
word ,
  
\end{lemma}
\begin{proof}
Suppose . By Lemma~\ref{lemma:mpexpd}, it
follows that  and . So, by contraposition,
 when . On the other
hand, when , we can write 
for some words  such that . Then  is
also a prefix of  and thus . So, by
Lemma~\ref{lemma:mpexpd}, .
\end{proof}





The \emph{right minimal period array} of word  with respect to
exponent  and period larger than  is defined by
 for  and the
\emph{left minimal period array} of word  with respect to
exponent  and period larger than  is defined by
 for . For
example,



A \emph{suffix tree}  for a word  is a
rooted tree with each edge labeled by a non-empty word that
satisfies
\begin{quote}
\begin{enumerate}
  \item each internal node, other than the root, has at least two children,
  \item each label on edge from the same node begins with a different letter, and
  \item there are exactly  leaves  and
  1\leq i\leq n\\xymatrix{
  & & & +\infty,root\ar[dl]_{\tt0}\ar[dr]^{\tt1} & & \\
  & & +\infty\ar[dl]_{\tt01}\ar[dr]^{\tt1} & & +\infty\ar[dr]^{\tt0}\ar[d]_{\}\ar[d]^{\} & +\infty,leaf_{10} & +\infty\ar[dl]_{\tt01}\ar[d]^{\tt1001\} & +\infty,leaf_9 & +\infty\ar[dl]_{\tt01001\} & 2,leaf_5 \\
  & +\infty\ar[dl]_{\tt01001\} & 2,leaf_4 & +\infty,leaf_2 & +\infty,leaf_7 & \\
  3,leaf_1 & +\infty,leaf_6 & & & &
  }\tau(p(leaf_j))e_j=\tau(leaf_j)=x\tau(leaf_i)=x\tau(p(leaf_i))e_i. \;
  }
  \caption{Framework of Weiner's algorithm for constructing suffix tree}
  \label{figure:weiner}
\end{algorithm}


Once a node  is created, although the node-depth  may
change in later extensions by splitting on an edge in the path from
the root to node , the depth  will never change in
later extensions in a suffix tree. So we assume the depth
 is also stored on the node  in the suffix tree and
can be accessed in constant time. The update of  only
happens when  is created and can be computed by
, where  is the label on the edge
from  to . So computing and storing the information
 will not increase the computational complexity of the
construction of a suffix tree.


\section{The algorithm for computing  and }
First we show that how the minimal period  can be
obtained from the suffix tree  in linear time
. In particular, if
 and  satisfies ,
then the algorithm compute  in constant time, which is
one of the essential idea in the computing of  and
.


\begin{lemma}\label{lemma:mpcret}
Let  and  be two integers and  be the
suffix tree of a word . Then  can be computed in
 time.
\end{lemma}
\begin{proof}
Let . There is an
-time algorithm to compute
. First along the path from the  to the root, we
find the highest ancestor  of  such that
. Since , node  always
has a father and . Then we find the least
common ancestor of  with any other leaf  that is a
descendent of  and check whether the equation

holds. If no  satisfies (\ref{equation:mp}), then
; otherwise, , where  is the
smallest  that satisfies (\ref{equation:mp}). The algorithm is
presented in Algorithm~\ref{figure:mp}.

\begin{algorithm}
  \SetLine
  \linesnumbered
  \KwIn{a suffix tree  and two integers , .}
  \KwOut{the minimal period .}
  \Begin(function \KwComputeMP{, , }){
    \lIf{}{\Return{}} \lElse{} \;
    \lWhile{}{ \;}
     \;
    \tcp{linear-time preprocessing for constant-time finding }
    preprocessing the tree rooted at  for  \;
    \ForEach{leaf  being a descendent of  other than }{
      \If{}{
        \tcp{assert:  is a period of the word }
        \lIf{}{} \;
      }
    }
    \Return{} \;
  }
  \caption{Algorithm for computing  by using the suffix tree }
  \label{figure:mp}
\end{algorithm}

Now we prove the correctness of this algorithm. First we observe
that  for some non-empty word , if and only if the common
prefix of  and  is of length
at least , which means the leaf 
satisfies (\ref{equation:mp}). Furthermore, , if and only
if  satisfies
, which means
that  is a descendent of . (Since  has two
descendents,  is not a leaf and thus .)
So each time line~8 is executed, if and only if there is a
corresponding prefix of  that is a th power with period of
length . The minimal length of such period, if any, is
returned and the correctness is ensured.

Now we discuss the computational complexity of this algorithm. Let
 be the sub-tree rooted at  and  be the number of leaves
in . By the definition of suffix tree, each internal node has
at least two children in  and thus the number of internal nodes
in  is less than . Furthermore, the node-depth of any leaf
in  is also less than . So the computational time of the
algorithm is linear in . (For details on constant-time algorithm
finding lowest common ancestor with linear-time preprocessor, see
\cite{Harel&Tarjan1984,Schieber&Vishkin1988}.) In order to show the
computation is in -time, it
remains to see . We prove
 by contradiction. Suppose
. Since there are  leaves
 with the same ancestor , there are 
factors of length  such that
  
Since  for , by the pigeon hole
principle, there are two indices, say  and , such that
. Then the common
prefix of  and  is of length at
least , which means there is a prefix
of 
that is a th power with period of length . Then
, a contradiction. So the number of
leaves in  is  and thus the
algorithm is in -time.
\end{proof}


For a word , by definitions, the left minimal
period array and the right minimal period array satisfy the equation
  
So the left minimal period array of  can be obtained by computing
the right minimal period array of . Hence in what follows we only discuss the algorithm for computing
the right minimal period array of ; the algorithm for computing
the left minimal period array of  follows immediately.


A \emph{suffix tree with minimal periods}  for a
word  is a suffix tree  with a function , which
is defined at each node  such that .
By definitions, once  is created for a word
, the  can be obtained by reading the
value  at each leaf in order as follows:
  
The suffix tree with minimal periods satisfies the following
property.


\begin{lemma}\label{lemma:mpbond}
Let  and  be two integers and  be a word. For any
node  in the suffix tree with minimal periods 
such that , then either 
or  is between
  
\end{lemma}
\begin{proof}
Let  be a node in  such that
. Since  is a prefix of 
and , by Lemma~\ref{lemma:mpshrk}, it follows
that
  
Suppose . The common prefix of
 and
 is of length at least
. Then , since
 is the lowest ancestor of  in . Therefore,
either  or
.
\end{proof}


In what follows, we will show how to construct the 
for a word  with fixed  in linear time by a modified version
of Kosaraju's algorithm \cite{Kosaraju1994}. Kosaraju's algorithm
constructs only  but our modification can construct
 for arbitrary  and . Both
algorithms are based on the alternation of Weiner's algorithm
\cite{Weiner1973} for constructing suffix tree . Our
modified algorithm for computing  is illustrated in
Algorithm~\ref{figure:rmp}, where the added statements for updating
 are underlined. In addition to the suffix tree
, auxiliary suffix tree
 for some proper indices  is used.


The main idea is that we use the classic Weiner's algorithm to
construct the underlying suffix tree  step
by step. At each step, at most two nodes are created and we update
the  values on those new nodes. One possible new node  is
between two nodes  when a split on the edge from  to 
happens. Since  is already computed, we update
 directly. The other new node is the new leaf .
When , we update 
directly. Otherwise, we compute  by constructing
auxiliary suffix trees. The na\"ive way is to construct
 and then to compute
, both of which run in
 time. We instead construct a series
of trees  for some  in such a way that
. In addition, the
total cost of constructing the trees  is in  and each cost
of computing  in each  is
in .


\begin{algorithm}
  \SetLine
  \linesnumbered
  \KwIn{a word  and two integers , .}
  \KwOut{the right minimal period array .}
  \Begin(function \KwComputeRMP{, , }){
    construct  by constructing  \underline{with } \;
    \underline{, , and } \;
    \For{ \KwFrom  \KwTo }{
find the proper position  in  to insert the new node  \;
      \If{needed}{
        split an edge  to two  by adding a new node  \;
        \underline{\lIf{}{} \lElse{}} \;
      }
      create and label the edge  by T_i=\tree_\subw{w}{i}{n}j-i+1>{2k}d/{(k-1)}\delta(y)<d/2A\longleftarrow emptyA=emptyA=\tree_{\subw{w}{i}{j}}d/2\leq\delta(p(leaf_i))\leq2d\pi(y)\neq+\infty\pi(leaf_i)\longleftarrow\pi(y)A=emptyA\longleftarrowA\subw{w}{i}{j}A=emptyd\longleftarrow\delta(y)j\longleftarrow i+{(k+1)}d/{(k-1)}-1A\longleftarrow\subw{w}{i}{j}A\longleftarrowA\subw{w}{i}{j}\pi(leaf_i)\longleftarrowA\max\{s,\delta(y)/k\}k\forall v\textrm{ in }T_i:\pi(v)=mp_s^k(\tau(v))T_i={}_s^k\tree_{\subw{w}{i}{n}}rmp[i]\longleftarrow\pi(leaf_i)rmp[n]\longleftarrow+\inftyrmp{}_s^krmp_{w}k\geq2s\geq0{}_s^krmp_ww{}_s^krmp_w[i]\pi_s^k(leaf_i)T_iT_i={}_s^k\tree_\subw{w}{i}{n}\pi_s^kT_i\tree_\subw{w}{i}{n}\pi_s^k(v)v\tree_\subw{w}{i}{n}\pi_s^k(v)=mp_s^k(\tau(v)){}_s^k\tree_\subw{w}{j}{n}j<i\pi_s^k(v){}_s^k\tree_\subw{w}{i}{n}vT_i={}_s^k\tree_\subw{w}{i}{n}\pi_s^k(v)vv\tree_\subw{w}{n}{n}leaf_n\pi_s^k(root)=mp_s^k(\tau(root))=mp_s^k(\epsilon)=+\infty\pi_s^k(leaf_n)=mp_s^k(\tau(leaf_n))=mp_s^k(\subw{w}{n}{n})=+\inftyT_n={}_s^k\tree_\subw{w}{n}{n}T_{i+1}={}_s^k\tree_\subw{w}{i+1}{n}i1\leq i\leq n-1yleaf_ileaf_i\pi(y)xzyxyyz\tau(z)=\tau(y)uu\neq\epsilonmp_s^k(\tau(y))=mp_s^k(\tau(z))\abs{\tau(y)}\geq k\cdot
mp_s^k(\tau(z))mp_s^k(\tau(y))=+\infty\pi(leaf_i)\pi_s^kleaf_iy=p(leaf_i)\tau(leaf_i)=\tau(y)vv\neq\epsilonmp_s^k(\tau(y))\neq+\inftymp_s^k(\tau(leaf_i))=mp_s^k(\tau(y))mp_s^k(\tau(y))=+\inftymp_s^k(\tau(leaf_i))=mp_s^k(\subw{w}{i}{n})A=\tree_{\subw{w}{i}{j}}y=p(leaf_i)mp_s^k(\tau(leaf_i))>\delta(y)/kmp_s^k(\subw{w}{i}{n})=mp_s^k(\subw{w}{i}{j})\delta(p_{T_{i}}(leaf_{i}))\leq\delta(p_{T_{i+1}}(leaf_{i+1}))+1pp_{T_{i}}(leaf_{i+1})\neq p_{T_{i+1}}(leaf_{i+1})p_{T_{i+1}}(leaf_{i+1})leaf_{i+1}leaf_i,leaf_{i+1}T_ileaf_{i+1},leaf_{i+2}T_{i+1}\delta(p_{T_{i}}(leaf_{i}))
  =\delta(p_{T_{i}}(leaf_{i+1}))
  =\delta(p_{T_{i+1}}(leaf_{i+1}))+1.p_{T_{i}}(leaf_{i+1})=p_{T_{i+1}}(leaf_{i+1})\delta(p_{T_{i}}(leaf_{i}))
  \leq\delta(p_{T_{i}}(leaf_{i+1}))+1
  =\delta(p_{T_{i+1}}(leaf_{i+1}))+1.\delta(y)\leq j-i+1-2d/(k-1)y=p(leaf_i)AA\neq emptyA\delta(p(leaf_i))=di=j+1-(k+1)d/(k-1)\delta(p(leaf_i))=j-i+1-2d/(k-1)AAjdki1\delta(p_{T_{i}}(leaf_{i}))1\delta(p_{T_{i}}(leaf_{i}))\leq j-(i+1)+1-2d/(k-1)mp_s^k(\subw{w}{i}{n})=mp_s^k(\subw{w}{i}{j})mp_s^k(\subw{w}{i}{n})=+\inftymp_s^k(\subw{w}{i}{j})=+\infty=mp_s^k(\subw{w}{i}{n})mp_s^k(\subw{w}{i}{n})\neq+\inftymp_s^k(\subw{w}{i}{n})=mp_s^k(\tau(leaf_i))\leq\delta(y)/(k-1)j-i+1\leq2kd/(k-1)A\neq emptymp_s^k(\subw{w}{i}{j})=mp_s^k(\subw{w}{i}{n})T_i={}_s^k\tree_{\subw{w}{i}{n}}k\geq2s\geq0{}_s^krmp_wwO(k\abs{w})n=\abs{w}rmprmp={}_s^krmp_wT_1={}_s^k\tree_wO(n)\tree_wO(n)O(\log n)n-1O(n)A=\tree_{\subw{w}{i}{j}}mp_0^k(\subw{w}{i}{j})=mp_0^k(\subw{w}{i}{n})mp_0^k(\subw{w}{i}{n})>\delta(y)/kj-i+1\leq2kd/(k-1)\delta(y)\geq d/2A\neq emptyn-1O(kn)A=\tree_{\subw{w}{i}{j}}l1\leq m\leq lA=\tree_{\subw{w}{i_m}{j_m}}d_m=\delta(p_{T_{i_m}}(leaf_{i_m}))A=\tree_{\subw{w}{i_m'}{j_m}}j_m-(i_m'-1)+1>2kd_m/(k-1)\delta(p_{T_{i_m'-1}}(leaf_{i_m'-1}))<d_m/2A\neq emptyj_m-i+1\leq2kd/(k-1)i_m\leq i\leq i_m'Aj_m-(i_m'-1)+1>2kd_m/(k-1)j_m-i_m'+1=2kd_m/(k-1)j_m=i_m+(k+1)d_m/(k-1)-1ii_m-i_m'=\left(j_m-(k+1)d_m/(k-1)+1\right)-\left(j_m+1-2kd_m/(k-1)\right)=d_m.A\delta(p_{T_{i_m'-1}}(leaf_{i_m'-1}))<d_m/2\delta(p_{T_{i_m'-1}}(leaf_{i_m'-1}))-\delta(p_{T_{i_m}}(leaf_{i_m}))<-d_m/2\delta(p_{T_{i}}(leaf_{i}))-\delta(p_{T_{i+1}}(leaf_{i+1}))\leq1\delta(p_{T_1}(leaf_1))\geq0AT_1\poundswwi=1leaf_1A\delta(y)<d/2mp_s^k(\pounds\cdot w)=+\inftyO(n)O(n)+O(n)+O(n)+O(kn)+O(n)O(kn)k{}_s^krmp_w{}_s^klmp_wkw\Sigma\phi:\Sigma^*\to\Sigma^*\phi(\phi(w))=ww\in\Sigma^*\phi(uv)=\phi(v)\phi(u)u,v\in\Sigma^*\phi\phi\{\tt A,T,C,G\}{\tt A}\mapsto{\tt T}{\tt
T}\mapsto{\tt A}{\tt C}\mapsto{\tt G}{\tt G}\mapsto{\tt C}k\phiwk\phiww=x_1x_2\cdots x_kx_i=x_jx_i=\phi(x_j)1\leq i,j\leq k\{\tt
A,T,C,G\}\tt ACGCGT\tt ACGTACkk\tt ACGACGACGCGTACGwkkkO(\abs{w}^2\log\abs{w})k\phi(x)x^{k-1}x^{k-1}\phi(x)(x\phi(x))^{\frac{k}{2}}(x\phi(x))^{\lfloor\frac{k}{2}\rfloor}xk{}^\phi cmp_ww\phi{}^\phi cmp_{\tt0100101001}=[0,0,0,3,0,0,0,0,2,0,0]\phi{}^\phi cmp_ww\phiO(\abs{w})\tree_{w\pounds\phi(w)}\poundsw{}^\phi cmp_wn=\abs{w}\overline{w}=w\pounds\phi(w)\abs{\overline{w}}=2n+1\tree_{\overline{w}}\tau(\lca(leaf_{i+1},leaf_{2n-i+2}))\tau(leaf_{i+1})=\subw{\overline{w}}{i+1}{2n+1}\tau(leaf_{2n-i+2})=\subw{\overline{w}}{2n-i+2}{2n+1}\pounds\tau(leaf_{2n-i+2})\subw{\overline{w}}{1}{i}=\phi(\tau(leaf_{2n-i+2}))\tau(\lca(leaf_{i+1},leaf_{2n-i+2}))uu\subw{w}{i+1}{n}\phi(u)\subw{w}{1}{i}\phi\phi\tree_{\overline{w}}\lca\lcaO(\abs{w})w=\subw{w}{1}{n}\phi{}^\phi cmp_{w}w\phiT\longleftarroww\pounds\phi(w)\poundswT\lcai1n-1cmp[i]\longleftarrow\delta(\lca(leaf_{i+1},leaf_{2n-i+2}))cmp[0]\longleftarrow0cmp[n]\longleftarrow0{}^\phi cmp_{w}k\geq 2s\geq 0\phiwx^{k-1}\phi(x)\phi(x)x^{k-1}\abs{x}>sO(k\abs{w}){}_{\phantom{-1}s}^{k-1}lmp_w{}_{\phantom{-1}s}^{k-1}rmp_w{}^\phi cmp_wx^{k-1}\phi(x)\phi(x)x^{k-1}\abs{x}>si{}_{\phantom{-1}s}^{k-1}lmp_w[i]\leq{}^{\phi}cmp[i]{}_{\phantom{-1}s}^{k-1}rmp_w[i]\leq{}^{\phi}cmp[i-1]x^{k-1}\phi(x)\phi(x)x^{k-1}wx^{k-1}\phi(x)\abs{x}>s{}_{\phantom{-1}s}^{k-1}lmp_w[i]\leq{}^{\phi}cmp[i]i,1\leq i\leq nn=\abs{w}m={}_{\phantom{-1}s}^{k-1}lmp_w[i]\leq{}^{\phi}cmp[i]iw\subw{w}{i-(k-1)m+1}{i+m}x^{k-1}\phi(x)\abs{x}>sw\subw{w}{j}{j+kp-1}x^{k-1}\phi(x)p=\abs{x}>s{}_{\phantom{-1}s}^{k-1}lmp_w[j+(k-1)p-1]\leq p{}^{\phi}cmp[j+(k-1)p-1]\geq pm={}_{\phantom{-1}s}^{k-1}lmp_w[i]\leq{}^{\phi}cmp[i]i=j+(k-1)p-1{}_{\phantom{-1}s}^{k-1}lmp_wO(k\abs{w}){}^{\phi}cmpO(\abs{w})O(\abs{w})O(k\abs{w})w=\subw{w}{1}{n}\phis\geq0k\geq0wx^{k-1}\phi(x)\abs{x}>slmp\longleftarrowwsk-1rmp\longleftarrowwsk-1\phi(x)x^{k-1}cmp\longleftarroww\phii1nlmp[i]\leq cmp[i]rmp[i]\leq cmp[i-1]\phi(x)x^{k-1}wx^{k-1}\phi(x)\abs{x}>sk\geq 2s\geq 0\phiw\left(x\phi(x)\right)^{\frac{k}{2}}\left(x\phi(x)\right)^{\lfloor\frac{k}{2}\rfloor}xk\abs{x}>sO(\abs{w}^2/k){}^\phi cmp_wk-1s{}^\phi cmp_wsw\subw{w}{i}{j+kp-1}=x\phi(x)x\phi(x)\cdotsp=\abs{x}>sk{}^\phi
cmp_w[i+p-1],{}^\phi cmp_w[i+2p-1],\ldots,{}^\phi cmp_w[i+(k-1)p-1]\geq p>s{}^\phi cmp_wO(\abs{w})O(\abs{w}^2/k)O(\abs{w}^2/k)w=\subw{w}{1}{n}\phis\geq0k\geq0w\left(x\phi(x)\right)^{\frac{k}{2}}\left(x\phi(x)\right)^{\lfloor\frac{k}{2}\rfloor}xk\abs{x}>scmp\longleftarroww\phids+1\lfloor n/k\rfloori0d-1consecutive\longleftarrow0j1\lfloor (n-i)/d\rfloor-1cmp[i+jd]\geq dconsecutive\longleftarrow consecutive+1consecutive\longleftarrow0consecutive\geq k-1w\left(x\phi(x)\right)^{\frac{k}{2}}\abs{x}>s{}_0^2rmp_wk\geq2,s\geq0ks{}_s^krmp_w{}_s^klmp_wO(k\abs{w})\pi_s^k(v)vO(k\abs{w})wx^k\phi(x)\phi(x)x^k\abs{x}>sO(\abs{w}^2/k)w\left(x\phi(x)\right)^{\frac{k}{2}}\left(x\phi(x)\right)^{\lfloor\frac{k}{2}\rfloor}xk\abs{x}>sxx\cdots x\phi(x)\phi(x)x\cdots
xxx\phi(x)x\phi(x)\cdotsO(\abs{w}^2\log\abs{w})o(n\log n)$ algorithm for finding all repetitions in a string.
\newblock {\em J. Algorithms}, 5(3):422--432, 1984.

\bibitem{Main&Lorentz1985}
M.~Main and R.~Lorentz.
\newblock Linear time recognition of square free strings.
\newblock In A.~Apostolico and Z.~Galil, editors, {\em Combinatorial Algorithms
  on Words}, pages 272--278. Springer Verlag, 1985.

\bibitem{Main1989}
M.~G. Main.
\newblock Detecting leftmost maximal periodicities.
\newblock {\em Discrete Appl. Math.}, 25(1--2):145--153, 1989.

\bibitem{McCreight1976}
E.~M. {McCreight}.
\newblock A space-economical suffix tree construction algorithm.
\newblock {\em J. Assoc. Comput. Mach.}, 23(2):262--272, 1976.

\bibitem{Schieber&Vishkin1988}
B.~Schieber and U.~Vishkin.
\newblock On finding lowest common ancestors: Simplification and
  parallelization.
\newblock {\em {SIAM} J. Comput.}, 17(6):1253--1262, 1988.

\bibitem{Slisenko1983}
A.~O. Slisenko.
\newblock Detection of periodicities and string-matching in real time.
\newblock {\em J. Math. Sci. (N. Y.)}, 22(3):1316--1387, 1983.

\bibitem{Stoye&Gusfield1998}
J.~Stoye and D.~Gusfield.
\newblock Simple and flexible detection of contiguous repeats using a suffix
  tree preliminary version.
\newblock In M.~Farach-Colton, editor, {\em "Proc. 9th Combinatorial Pattern
  Matching"}, pages 140--152. Springer Verlag, 1998.

\bibitem{Thue1906}
A.~Thue.
\newblock {\"U}ber unendliche {Zeichenreihen}.
\newblock {\em Norske Vid. Selsk. Skr. I. Mat.-Nat. Kl.}, (7):1--22, 1906.

\bibitem{Ukkonen1992}
E.~Ukkonen.
\newblock Constructing suffix trees on-line in linear time.
\newblock In J.~V. Leeuwen, editor, {\em Proc. Information Processing 92, Vol.
  1, IFIP Transactions A-12}, pages 484--492. Elsevier, 1992.

\bibitem{Weiner1973}
P.~Weiner.
\newblock Linear pattern matching algorithms.
\newblock In {\em Proc. 14th IEEE Ann. Symp. on Switching and Automata Theory
  (SWAT)}, pages 1--11, 1973.

\end{thebibliography}
\end{document}
