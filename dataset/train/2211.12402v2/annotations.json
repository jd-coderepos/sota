[{'LEADERBOARD': {'Task': 'Video Retrieval', 'Dataset': 'MSR-VTT-1kA', 'Metric': 'text-to-video R@1', 'Score': '49.6'}}, {'LEADERBOARD': {'Task': 'Video Retrieval', 'Dataset': 'MSR-VTT-1kA', 'Metric': 'text-to-video R@5', 'Score': '76.7'}}, {'LEADERBOARD': {'Task': 'Video Retrieval', 'Dataset': 'MSR-VTT-1kA', 'Metric': 'text-to-video R@10', 'Score': '84.2'}}, {'LEADERBOARD': {'Task': 'Video Retrieval', 'Dataset': 'MSR-VTT-1kA', 'Metric': 'text-to-video R@1', 'Score': '47.6'}}, {'LEADERBOARD': {'Task': 'Video Retrieval', 'Dataset': 'MSR-VTT-1kA', 'Metric': 'text-to-video R@5', 'Score': '74.1'}}, {'LEADERBOARD': {'Task': 'Visual Question Answering (VQA)', 'Dataset': 'MSRVTT-QA', 'Metric': 'Accuracy', 'Score': '0.455'}}, {'LEADERBOARD': {'Task': 'Visual Question Answering (VQA)', 'Dataset': 'MSRVTT-QA', 'Metric': 'Accuracy', 'Score': '0.45'}}, {'LEADERBOARD': {'Task': 'Visual Question Answering (VQA)', 'Dataset': 'VQA v2 test-dev', 'Metric': 'Accuracy', 'Score': '81.9'}}, {'LEADERBOARD': {'Task': 'Visual Question Answering (VQA)', 'Dataset': 'VQA v2 test-dev', 'Metric': 'Accuracy', 'Score': '80.4'}}, {'LEADERBOARD': {'Task': 'Visual Question Answering (VQA)', 'Dataset': 'MSVD-QA', 'Metric': 'Accuracy', 'Score': '0.546'}}, {'LEADERBOARD': {'Task': 'Visual Question Answering (VQA)', 'Dataset': 'MSVD-QA', 'Metric': 'Accuracy', 'Score': '0.528'}}, {'LEADERBOARD': {'Task': 'Visual Question Answering (VQA)', 'Dataset': 'VQA v2 test-std', 'Metric': 'overall', 'Score': '81.8'}}, {'LEADERBOARD': {'Task': 'Visual Question Answering (VQA)', 'Dataset': 'VQA v2 test-std', 'Metric': 'overall', 'Score': '80.2'}}, {'LEADERBOARD': {'Task': 'Visual Reasoning', 'Dataset': 'NLVR2 Test', 'Metric': 'Accuracy', 'Score': '89.4'}}, {'LEADERBOARD': {'Task': 'Visual Reasoning', 'Dataset': 'NLVR2 Test', 'Metric': 'Accuracy', 'Score': '87.0'}}, {'LEADERBOARD': {'Task': 'Visual Reasoning', 'Dataset': 'NLVR2 Dev', 'Metric': 'Accuracy', 'Score': '88.7'}}, {'LEADERBOARD': {'Task': 'Visual Reasoning', 'Dataset': 'NLVR2 Dev', 'Metric': 'Accuracy', 'Score': '86.2'}}, {'LEADERBOARD': {'Task': 'Cross-Modal Retrieval', 'Dataset': 'Flickr30k', 'Metric': 'Image-to-text R@1', 'Score': '98.8'}}, {'LEADERBOARD': {'Task': 'Cross-Modal Retrieval', 'Dataset': 'Flickr30k', 'Metric': 'Image-to-text R@10', 'Score': '100'}}, {'LEADERBOARD': {'Task': 'Cross-Modal Retrieval', 'Dataset': 'Flickr30k', 'Metric': 'Image-to-text R@5', 'Score': '100'}}, {'LEADERBOARD': {'Task': 'Cross-Modal Retrieval', 'Dataset': 'Flickr30k', 'Metric': 'Text-to-image R@1', 'Score': '91.8'}}, {'LEADERBOARD': {'Task': 'Cross-Modal Retrieval', 'Dataset': 'Flickr30k', 'Metric': 'Text-to-image R@10', 'Score': '99.5'}}, {'LEADERBOARD': {'Task': 'Cross-Modal Retrieval', 'Dataset': 'Flickr30k', 'Metric': 'Text-to-image R@5', 'Score': '98.6'}}, {'LEADERBOARD': {'Task': 'Cross-Modal Retrieval', 'Dataset': 'Flickr30k', 'Metric': 'Image-to-text R@1', 'Score': '98.5'}}, {'LEADERBOARD': {'Task': 'Cross-Modal Retrieval', 'Dataset': 'Flickr30k', 'Metric': 'Text-to-image R@1', 'Score': '90.4'}}, {'LEADERBOARD': {'Task': 'Cross-Modal Retrieval', 'Dataset': 'Flickr30k', 'Metric': 'Text-to-image R@10', 'Score': '99.3'}}, {'LEADERBOARD': {'Task': 'Cross-Modal Retrieval', 'Dataset': 'Flickr30k', 'Metric': 'Text-to-image R@5', 'Score': '98.2'}}, {'LEADERBOARD': {'Task': 'Cross-Modal Retrieval', 'Dataset': 'COCO 2014', 'Metric': 'Image-to-text R@1', 'Score': '84.4'}}, {'LEADERBOARD': {'Task': 'Cross-Modal Retrieval', 'Dataset': 'COCO 2014', 'Metric': 'Image-to-text R@10', 'Score': '98.5'}}, {'LEADERBOARD': {'Task': 'Cross-Modal Retrieval', 'Dataset': 'COCO 2014', 'Metric': 'Image-to-text R@5', 'Score': '96.5'}}, {'LEADERBOARD': {'Task': 'Cross-Modal Retrieval', 'Dataset': 'COCO 2014', 'Metric': 'Text-to-image R@1', 'Score': '67.7'}}, {'LEADERBOARD': {'Task': 'Cross-Modal Retrieval', 'Dataset': 'COCO 2014', 'Metric': 'Text-to-image R@10', 'Score': '92.5'}}, {'LEADERBOARD': {'Task': 'Cross-Modal Retrieval', 'Dataset': 'COCO 2014', 'Metric': 'Text-to-image R@5', 'Score': '87.5'}}, {'LEADERBOARD': {'Task': 'Cross-Modal Retrieval', 'Dataset': 'COCO 2014', 'Metric': 'Image-to-text R@1', 'Score': '83.5'}}, {'LEADERBOARD': {'Task': 'Cross-Modal Retrieval', 'Dataset': 'COCO 2014', 'Metric': 'Image-to-text R@5', 'Score': '96.3'}}, {'LEADERBOARD': {'Task': 'Cross-Modal Retrieval', 'Dataset': 'COCO 2014', 'Metric': 'Text-to-image R@1', 'Score': '66.2'}}, {'LEADERBOARD': {'Task': 'Cross-Modal Retrieval', 'Dataset': 'COCO 2014', 'Metric': 'Text-to-image R@10', 'Score': '92.2'}}, {'LEADERBOARD': {'Task': 'Cross-Modal Retrieval', 'Dataset': 'COCO 2014', 'Metric': 'Text-to-image R@5', 'Score': '87.1'}}, {'LEADERBOARD': {'Task': 'Visual Grounding', 'Dataset': 'RefCOCO+ test B', 'Metric': 'Accuracy (%)', 'Score': '81.8'}}, {'LEADERBOARD': {'Task': 'Visual Grounding', 'Dataset': 'RefCOCO+ test B', 'Metric': 'Accuracy (%)', 'Score': '78.4'}}, {'LEADERBOARD': {'Task': 'Visual Grounding', 'Dataset': 'RefCOCO+ val', 'Metric': 'Accuracy (%)', 'Score': '87.6'}}, {'LEADERBOARD': {'Task': 'Visual Grounding', 'Dataset': 'RefCOCO+ val', 'Metric': 'Accuracy (%)', 'Score': '85.2'}}, {'LEADERBOARD': {'Task': 'Visual Grounding', 'Dataset': 'RefCOCO+ testA', 'Metric': 'Accuracy (%)', 'Score': '92.1'}}, {'LEADERBOARD': {'Task': 'Visual Grounding', 'Dataset': 'RefCOCO+ testA', 'Metric': 'Accuracy (%)', 'Score': '90.3'}}]
