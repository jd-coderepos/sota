\documentclass[11pt]{article}
\pdfoutput=1
\usepackage[centertags]{amsmath}
\usepackage{amssymb}


\newtheorem{theorem}{Theorem}[section]
\newtheorem{definition}{Definition}[section]
\newtheorem{corollary}{Corollary}[section]
\newtheorem{lemma}{Lemma}[section]
\newtheorem{example}{Example}[section]

\providecommand{\expectation}[2]{\mathbb{E}_{#2}\left[#1\right]}
\providecommand{\probab}[2]{\mathbb{P}_{#2}\left[#1\right]}

\providecommand{\binom}[2]{{#1\choose#2}}

\newenvironment{proof}[0]{\textit{Proof.} }{\hfill   } 


\providecommand{\degree}[2]{{\textrm{deg}_{#1}(#2)}}
\providecommand{\vcprob}[3]{f^{#1}_{#2}(#3)}

\providecommand{\virtual}[1]{\textrm{virtual}(#1)}
\providecommand{\real}[1]{\textrm{real}(#1)}
\providecommand{\init}[1]{\textrm{init}(#1)}

\providecommand{\rktree}[2]{G^{#1}(#2)}
\providecommand{\rbktree}[3]{G^{#1, #2}(#3)}
\providecommand{\tdeg}[2]{X_{#1}(#2)}
\providecommand{\adeg}[2]{P_{#1}(#2)}
\providecommand{\edeg}[2]{\expectation{\tdeg{#1}{#2}}{}}


\providecommand{\ktree}{k-tree}
\providecommand{\ktrees}{k-trees}





\renewcommand{\theequation}{\thesection.\arabic{equation}}

\newcommand{\figref}[1]{Figure~\ref{#1}}
\newcommand{\tabref}[1]{Table~\ref{#1}}
\newcommand{\lemref}[1]{Lemma~\ref{#1}}
\newcommand{\defref}[1]{Definition~\ref{#1}}
\newcommand{\thmref}[1]{Theorem~\ref{#1}}
\newcommand{\sectref}[1]{Section~\ref{#1}}

\newcommand{\Figref}[1]{Figure~\ref{#1}}
\newcommand{\Tabref}[1]{Table~\ref{#1}}
\newcommand{\Lemref}[1]{Lemma~\ref{#1}}
\newcommand{\Defref}[1]{Definition~\ref{#1}}
\newcommand{\Thmref}[1]{Theorem~\ref{#1}}
\newcommand{\Sectref}[1]{Section~\ref{#1}}



\newcommand{\strongc}{strongly -consistent}
\newcommand{\strongy}{strong -consistency}
\newcommand{\weakc}{weakly -consistent}
\newcommand{\weaky}{weak -consistency}
\newcommand{\scind}{SC-inducing}
\newcommand{\wcind}{WC-inducing}
\newcommand{\SC}{\mbox{SC}}
\newcommand{\WC}{\mbox{WC}}
\newcommand{\ratcv}{\mbox{ratio of constraints to variables}}

\newcommand{\union}{\cup}
\newcommand{\intersect}{\cap}
\newcommand{\nbr}{N}
\newcommand{\mindeg}{\theta}
\newcommand{\V}{V}
\newcommand{\E}{E}
\newcommand{\G}{G}
\newcommand{\Gset}{{\mathcal{G}}}
\newcommand {\setdelim}        {\; | \;}

\newcommand{\biject}{\pi}
\newcommand{\bijection}{\leftrightarrow}

\newcommand{\trip}{T}
\newcommand{\tripset}{{\mathcal \trip}}
\newcommand{\lbl}{L}
\newcommand{\albl}{{\mathcal \lbl}}
\newcommand{\alblt}{\albl(\tripset)}


\newcommand{\bdtnm}{{\mathcal B}^{d,t}_{n,m}}
\newcommand{\model}[1]{\bdtnm[{#1}]}
\newcommand{\flawless}{\model{{\mathcal M}}}
\newcommand{\genmodel}{\model{\albl}}
\newcommand{\modelb}{\bdtnm}
\newcommand{\modelsc}{\model{\SC}}
\newcommand{\modelwc}{\model{\WC}}

\newcommand{\D}{D}
\newcommand{\sized}{d}
\newcommand{\val}{\alpha}
\newcommand{\vala}{\alpha}
\newcommand{\valb}{\beta}
\newcommand{\valc}{\gamma}
\newcommand{\vald}{\delta}

\newcommand{\var}{x}
\newcommand{\constr}{C}
\newcommand{\tight}{t}




\newcommand{\evar}[2]{\var_{#2}:{#1}}
\newcommand{\envar}[1]{\var:{#1}}
\newcommand{\clause}[1]{{#1} }
\newcommand{\bnot}[1]{\overline{#1}}
\newcommand{\bor}{\vee}
\newcommand{\instance}{{\mathcal{I}}}
\newcommand{\cnf}{{\mathrm{CNF}}}
\newcommand{\vars}{{\mathrm{var}}}

\newcommand{\mdl}{{\mindeg_{\ell}}}
\newcommand{\sizel}{\sized_{\ell}}
\newcommand{\xl}{{\var_{\ell}}}
\newcommand{\dl}{{\D_{\ell}}}
\newcommand{\vl}{{\V_{\ell}}}
\newcommand{\pil}{{\biject_{\ell}}}
\newcommand{\vall}{\val_{\ell}}
\newcommand{\idl}{\iota_{\ell}}


\newcommand{\xr}{{\var_r}}
\newcommand{\dr}{{\D_r}}
\newcommand{\vr}{{\V_r}}
\newcommand{\pir}{{\biject_r}}
\newcommand{\sizer}{\sized_r}
\newcommand{\mdr}{{\mindeg_r}}
\newcommand{\valr}{\val_r}
\newcommand{\idr}{\iota_{r}}

\newcommand{\blockset}{{\mathbf \Pi}}
\newcommand{\block}[1]{\Pi_{#1}}
\newcommand{\nblocks}{k}
\newcommand{\bijectb}{\biject^{*}}
\newcommand{\vbl}{\V_{\blockset\ell}}
\newcommand{\vbr}{\V_{\blockset r}}
\newcommand{\vb}{v'}
\newcommand{\wb}{w'}
\newcommand{\Gb}{\G_{\blockset}}
\newcommand{\eb}{\E_{\blockset}}


\newcommand{\allblocks}{BB}
 
\topmargin -1.1 cm
\oddsidemargin 0.2 in
\evensidemargin 0 in
\textwidth 6.0 in
\textheight 8.6 in 
\parskip 0.1cm

\begin{document}

\title{The Degree Distribution of Random k-Trees}


\author{Yong Gao \thanks{Supported in part by NSERC Discovery Grant RGPIN 327587-06} \\
    Department of Computer Science, \\
    Irving K. Barber School of Arts and Sciences, \\
    University of British Columbia Okanagan, \\
    Kelowna, Canada V1V 1V7
}
\maketitle

\begin{abstract}
A power law degree distribution is established for
a graph evolution model based on the graph class of \ktrees. This \ktree-based
graph process
can be viewed as an idealized model that captures some characteristics of
the preferential attachment and copying mechanisms that existing evolving graph processes
fail to model due to technical obstacles. The result also serves as a further cautionary note
reinforcing the point of view that a power law degree distribution
should not be regarded as
the only important characteristic of a complex network, as has been previously argued \cite{dimitris05power,li05,mitzenmacher05}.





\end{abstract}
 
 


\section{Introduction}

Since the discovery of the power-law degree distribution of the web graphs and other complex large-scale networks, many random models
for such networks have been proposed \cite{albert02complex,bollobas01scalefree,cooper03,dorogovtsev02}.
By studying a variety of graph models with a power law degree distribution, it is hoped that one can gain insight into the characteristics
of real-world complex networks that are algorithmically exploitable, and can use these models as a tool for empirical studies \cite{chakrabarti06}.
It is therefore desirable to have random models that not only exhibit power law degree distributions, but also have other
structural features specified in a controlled manner.

Most of the existing models for complex networks
define a graph evolution process in which vertices are added to the current graph one at a time.
In each time step, the newly-added vertex is connected to
a number of existing vertices selected according to some probability distribution.
Two popular ways to specify the probability distribution for vertex selection are \textit{preferential attachment}
and \textit{copying}
(also known as \textit{duplication}). In the preferential attachment model, an existing vertex is selected with probability
in proportion to its vertex degree. In the copying model, neighbors of an existing vertex (selected uniformly at random) are
sampled to determine the vertices to connect to.


Bollobas et al. \cite{bollobas01scalefree}  proved the first rigorous result on the power law degree distribution of such
graph evolution models, showing that with high probability the degree distribution of the Barabasi-Albert model \cite{albert02complex}
obeys a power law .
Since then, many variants of the preferential attachment model have been proposed
by introducing additional parameters that manipulate the probability with which an existing vertex is to be selected. The motivation
is to construct models that obey a power law degree distribution with the exponent depending on some adjustable parameters so that
a variety of power law distributions observed in the real-world setting can be modelled.
Jordan \cite{jordan06} analyzed a slightly generalized model investigated by Dorogovtsev et al. \cite{dorog00}
and showed that for large constant , the proportion of vertices of  degree 
follows a power law  with the exponent  determined by two adjustable parameters.
Aiello, Chung, and Lu \cite{aiello01} and Cooper and Frieze \cite{cooper03} studied even more general
preferential-attachment  models with a set of parameters. These parameters specify the number of existing vertices to be selected in each step and control in a
probabilistic way how these vertices are selected. A vertex can be selected by sampling uniformly at random from existing vertices or by the preferential attachment mechanism.
Among the other results, Cooper and Frieze showed that in their general model the proportion of vertices of degree  follows a power law with the
exponent  determined by the model parameters. In all of the preferential attachment
models, it is an essential assumption that the vertices to be connected to the new vertex are selected independently of each other.

The first model with copying mechanism for the web graphs is proposed in \cite{kumar}.  A similar model, called the duplication model, arises in the context of biological networks \cite{chung03}.
With the copying mechanism,  a new vertex  is connected
to a set of existing vertices using the following scheme:
\begin{enumerate}
\item An existing vertex  is selected uniformly at random to copy from.
\item Let  be the set of neighbors of  in .
The vertex  is then connected to a subset of  selected in a probabilistic fashion.
The number of neighbors that  is connected to is called the out-degree of .
\end{enumerate}
Without any extra work, the above copying mechanism generates a star-like graph centered on the initial graph .
To overcome this limitation, Kumar et al. \cite{kumar} require that the out-degree (i.e., the number of out-edges) is a constant
and implement this by connecting the new vertex to either its neighbors or other vertices selected uniformly at random  which is crucial for the construction to work.
For the case that the out-degree is 1, it was proved in \cite{kumar} that the in-degree sequence has a power law distribution with high probability.

In the duplication models studied in \cite{chung03,bebek06},  is extended to contain all the neighbors of  and each vertex in this extended  is
connected to  independently with a certain probability. As noted in \cite{bebek06}, a correction step has to be employed to avoid the generation
of degenerate graph processes.  Power law distributions for the expected fraction of vertices of a given degree are proved
in \cite{chung03,bebek06}. 
Cooper and Frieze \cite{cooper03} use a copying scheme in which the neighbors of  is selected one at a time
by repeating the process a number of times independently. This makes the (highly-complicated) analysis
more approachable, but spoils to a large extent the idea of
the copying mechanism that is intended to capture the phenomenon that neighboring vertices are likely to be connected together to a new vertex.

In this paper, we study a random model for the well-known graph class of \ktrees,
which may serve as an alternative (and idealized) model in the study of complex networks.
The notion of k-trees is a generalization of trees and is closely related to the concept of treewidth in graph theory \cite{kloks94}.
We show that the degree distribution of a graph evolution process obtained by a straightforward randomization of the recursive definition of \ktrees\ obeys the power law

with high probability for large , where  is the parameter that characterizes the degree to which a graph is tree-like.
In addition to introducing an alternative model with preferential attachment and copying mechanisms, we hope that
the fact that a power law degree distribution exists in such a graph class with quite unique structural characteristics
serves as a further cautionary note, reinforcing the viewpoint that a power law degree distribution should not be regarded as
the only important characteristic of a complex network, as has been previously argued in \cite{li05,mitzenmacher05}. We note that in \cite{dimitris05power}, 
the inherent bias of existing approaches in the empirical study of 
the Internet graph was identified --- it was shown that the widely-used 
traceroute sampling method ``can make power laws appear where none existed in
the underlying graphs!" 






In the next section, we introduce the construction of the random \ktrees and discuss its relation to existing models of complex networks.
In Section 3, we prove the power law degree distribution of random \ktrees.
We conclude in Section 4 
with a discussion on the construction of random partial \ktrees.


\section{Random k-Trees: the Construction}

Throughout this paper, the degree of a vertex  in a graph  is denoted by .  A -clique of a graph is understood as a complete subgraph on a set of  vertices. All the graphs considered in this paper are undirected. 


The construction of a random \ktree\ is based on the following simple randomization of the recursive definition of \ktrees\ \cite{kloks94}.
Starting with an initial clique  of size , a sequence of graphs  is constructed by adding vertices to the graph one at a time.
To construct , we add a new vertex  and then connect it to the  vertices of a k-clique selected
uniformly at random from all the k-cliques in .
We call the graph process  a \textit{k-tree process}.

\subsection{Relations to Existing Models}
In this subsection, we discuss some basic properties of the -tree process, 
including the number of -cliques in  and the probability 
that an existing vertex of a given degree is connected to a new vertex. These properties 
are needed in the proof of  our main result. They also enable us to illustrate further the relations between the -tree process and existing graph evolution models.     

Let  be the set of cliques of size  in the graph .
It is easy to see that when a new vertex is added, exactly  new -cliques are created and none of the existing -cliques is destroyed.
So, taking into consideration the initial clique of size , we see that the total number of -cliques in
 is


Consider a vertex  in . 
Since every time a new vertex is added and connected to the vertex , 
exactly   new -cliques are created
that contain  as one of its vertices, the total number of -cliques in  containing  is

where the first term is the number of the -cliques containing  that are created when  is added to the graph and the second term is the total number of -cliques 
containing  that are created later on when  is connected to new vertices. 

Therefore given  (i.e., conditional on ),  the conditional
probability for  to be connected to the new vertex  is

where . 

Note that the above expression only depends on the degree of  in . 
It follows that, given ,
the conditional probability for  to be connected to  is

where .
We see that even though there is no explicit preferential-attachment mechanism employed, equation (\ref{eq-attach-prob}) shows that the construction scheme does have a similar effect.

\subsection{The Advantages of Random -Trees}
The \ktree\ construction scheme can be viewed as a very rigid copying mechanism; In step , the new vertex 
is connected to an existing vertex  selected uniformly at random from  and to a subset of  vertices selected uniformly at random
without replacement from the  neighbors that are connected to  in step .

As has been discussed in Section 1, in almost all the existing  preferential-attachment models
and copying models, there is an essential assumption that old vertices to be connected to 
a new vertex are selected independently. The random -tree model studied in the current paper
is unique in that  these vertices are selected in a highly correlated manner. This
captures in a better way the phenomenon that neighboring vertices are more likely to be 
connected to a new vertex, which is exactly what the copying mechanism tries to model.  
In addition, the random -tree has by construction a treewidth  --- a structural
feature of algorithmic significance that none of the existing models  
has a mechanism to control.  
       






\section{The Degree Distribution of Random -Trees}
This section is devoted to proving that for the \ktree\ process, the proportion of vertices of degree  follows asymptotically
a power law  with  exponent .  Throughout the discussion, we assume that
 is a fixed constant. 
In the following, we use  to denote the random variable for the total number
of vertices of degree  in , and write    

which, by Stirling's approximation, is approximately

for large .

Denote by 
the -algebra generated by the \ktree\ process up to time . 
We use  to denote the indicator function of an event . To ease the presentation, we 
use  to denote the indicator function of the event that the degree of the vertex 
 in  is , i.e.,


The following simple observation will be used to deal with the case .
\begin{lemma}
\label{lem:base}
For any vertex  and , . Furthermore, for 
any k-clique in  contains at most one vertex with .
\end{lemma}
\begin{proof}
The first claim that  follows from the fact that when a new vertex is added, 
it is connected to the  vertices of the selected -clique.  

We use induction to prove the second claim. First, consider the base case of . Recall that  
is obtained by connecting a new vertex  to the vertices of a -clique 
in the initial -clique. We see that in  there are exactly two vertices of degree , namely
the vertex  and one of the vertices in  that is not connected to .
Therefore, no -clique in  contains more than one vertex of degree , and thus the second claim 
holds for the base case of . 

Assume that the second claim holds for . Consider the graph  obtained from . 
Note that by adding a new vertex  to  and connecting it to the vertices of a -clique in 
, exactly  new -cliques are created each of which has  as its only vertex of degree . By the assumption that the second claim holds for ,  
no -clique in  contains more than one
vertices of degree . This completes the induction step and the second claims follows.             
\end{proof}




The next theorem shows that the expected degree sequence of the \ktree\ process obeys a power law distribution.
\begin{theorem}
\label{theorem-average}
Let  be the expected number of vertices with degree  in the random \ktree\ . There exists a
constant  (independent of ) such that for any ,

where  is a constant that is independent of  and .
\end{theorem}

The above result is proved by first establishing a recurrence  
for the expected number  of vertices with a given degree, and then showing that 
 can be asymptotically approximated by  where
the sequence  is the unique solution to the following simple recurrence relation 


Recall that to construct the graph  from ,
a new vertex added to the graph  will be connected to all the vertices of
a randomly-selected k-clique. This creates a high correlation between the degree of the vertices.
A recurrence is still possible due to the fact that
the conditional probability for a vertex  to have
a degree  in  given  only depends on
the degree of  in . A detailed account is given in the following proof.



\begin{proof}\ [\textbf{Proof of Theorem \ref{theorem-average}}]
To begin with, consider the base case .
Due to Lemma~\ref{lem:base}, we have

Let  be the event that a -clique containing a vertex of degree  is selected
in step  and let  be its indicator function. We have

where  is the complement of .

By Lemma~\ref{lem:base}, a -clique contains at most 
one vertex of degree . It follows that the conditional expectation
of  (which is equal to the conditional probability of ) 
is equal to , the  total number of degree- vertices
in , times the conditional probability that a degree-
vertex is selected to be connected to , i.e.,    


Therefore, by the basic  properties of conditional expectation in theory of probability,
we have

where the last equality is due to the fact that  is measurable
with respect to  (i.e., in the context of discrete probability space, 
is a function of ).

Combining equation (\ref{eq:condp-base}) and equation (\ref{eq:conde-base}), we have

By the mathematical definition,  itself
is a random variable measurable with respect to . 
Recall, from the probability theory, that the unconditional
expectation of the conditional expectation of a random variable is equal to the 
unconditional expectation of the random variable itself. So, we have

Therefore, by taking expectations on both sides of equation
(\ref{eq:conde-base1}), we get the following recurrence 


Solving the above recurrence (\ref{eq:conde-baser}) with  gives us


We now consider the general case of . 
Recall that  is the indicator function of the event
.  The total number of 
vertices of degree  in  can thus be written as
. 
By the additive property of conditional expectation, we have

Due to the way in which  is constructed,  the vertex  has degree  in 
 if and only if one of the following two situations occurs:
\begin{enumerate}
\item The degree of  in  is , and   is not selected to be connected
to ; or
\item The degree of  in  is , and  is selected to be connected
to .   
\end{enumerate}
Therefore,  letting  be the event that  is selected to be connected to , we have

We claim that 

We prove the claim by the mathematical definition of conditional expectation.
Consider any event .  
(Recall that  is the indicator function of the event
.) We have 

where the second last equality is due to the fact that the event 
 completely determines 
the (conditional probability of) the event .
The claim then follows from the mathematical definition of conditional expectation.

Similarly, we have

 
Combining equations (\ref{eq:conde-indicator}), (\ref{eq:conde-g1}),
and (\ref{eq:conde-g2}), we see that
for any ,

Also note that for , by the construction of  we have 
 
for any .
Summing over  on both sides of equation (\ref{eq-cond-indicator}) and based
on equation (\ref{eq-cond-total}), we have

Recall that the unconditional expectation of the condition expectation of a random variable
 is equal to the unconditional expectation of the random variable itself. 
Taking unconditional  expectations  on both sides of equation (\ref{eq-recurr-1}),
we get the following recurrence equation for the expected number of vertices of degree :

Using the recurrence equation (\ref{eq-Y-recursion}) and 
the base case equation (\ref{eq-formula-base}), we now prove
that 
 is asymptotically upper bounded by a constant, 
where the  sequence \{ is the
unique solution to the following simple recurrence equation      

Let . For the base case , we have from 
equation (\ref{eq-formula-base}) that .
For the general case , we have from equation (\ref{eq-Y-recursion}) that

By the definition of  (equation (\ref{eq-limit-case})), we see that

Thus, we have

From (\ref{eq-limit-case}), we see that  for any .
Since  by (\ref{eq:epsilon})  and since 

by the definition of  , we can use (\ref{eq:epsilon:bound}) to prove by induction
 that there exists a constant  independent of  such that for any ,
 is bounded by a constant  independent of  and , and therefore
 
To complete the proof of Theorem~\ref{theorem-average},
we see from the definition of  that

which by Stirling's approximation is
approximately   for large .
\end{proof}


Next, we show that , the number of vertices of degree , concentrates on its expectation,  which together with
Theorem \ref{theorem-average}, establishes the power law degree distribution of the \ktree\ process.


\begin{theorem}
\label{theorem-proportion}
Let  be the total number of vertices of degree  in . For any , we have

\end{theorem}
\begin{proof}
Consider the martingale  and the associated martingale difference sequence

If we can show that

then an application of Azuma's Inequality (see, e.g. Theorem 7.4.2 of \cite{alon00}) gives   (\ref{eq-proportion}).

For each , let
 be the collection of size-(k+1) vertex subsets  of the form  where
.  is the collection of the possible (k+1)-cliques in  that
contain  as one of their vertices. We call  the head of a subset  and write .

Now consider the probability space  defined over the product space
. A sample point  is
said to be a \textit{realization} of a \ktree\ if for any , the vertex subset
 is such that  is a subset
of  for some .

Let  be the set of sample points that are realizations of a \ktree.
The probability measure  is defined as follows. It
has  as its support and for each ,

The reason for , where , to be defined as in the above is explained  
as follows. Let  be the -tree on the vertex set  such that
for each , when  is added, it is connected to
a subset of  vertices from some  where .    
The probability that the random -tree  obtained according to our construction
is equal to  is
 
where the term  is the conditional probability 
(given ) that a specific size- vertex subset in a specific 
is selected to be connected to .  


For any , writing   for the total number of vertices of degree 
in the \ktree\ realized by , we have


The following argument is motivated by a similar one used in \cite{cooper03}.
Let  be a sample point and
 be the collection of sample points that agree with
 for , i.e.,


Consider a size-(k+1) vertex set  such that
. Define  to be the collection of the sample points
 such that

We claim that there is a one-to-one correspondence between the elements of
 and .

Assume that  and
.
The claimed one-to-one correspondence
can be shown by the mapping defined as follows. For each , define
. For each , define  as
\begin{enumerate}
\item  for any ;
\item ; and
\item for each ,  is a size-(k+1) vertex subset defined as
\begin{enumerate}
\item if  doesn't contain the vertex , then , and
\item if  contains , then  is obtained by replacing
 each vertex  with .
\end{enumerate}
\end{enumerate}
For any , since the only vertices whose vertex degree might have been changed by the
mapping  are those
in  and , we have



Since the probability measure  assigns equal probability  to the sample points,

holds due to the definition of conditional expectation:

and

This completes the proof.
\end{proof}

\section{Concluding Remarks}
In this paper, we have shown that a simple evolving graph model based on the the notion of -trees has a power law degree distribution with high probability. Due to its simplicity and unique structures, we think this model of evolving graphs provides a useful alternative in the modeling, analysis, and simulations of complexity networks such as the web graphs that have attracted much attention \cite{chakrabarti06}.  The fact that    
a power law degree distribution exists in such a graph models with quite unique characteristics
also serves as a further cautionary note, reinforcing the viewpoint that a power law degree 
distribution should not be regarded as the only important feature of a complex network, as has been previously argued in \cite{dimitris05power,li05,mitzenmacher05}.                
      


A partial \ktree\ is a subgraph of a \ktree. To enrich the modelling power of the class of models, it is desirable to have a natural model of
random partial \ktrees.  It is tempting to think of the following model based on the construction of the \ktree\ process:  For each vertex  in
, delete randomly-selected  of its  out-edges for some 
. In \cite{gao06waw}, we claimed that a model of random partial \ktrees\ obtained in this way has
a power law degree distribution , which turns out to be flawed. A few alternatives have since then been
investigated, resulting in very unnatural random models. We leave it as an open question the existence of a natural evolution model for the partial \ktrees.



















































\section*{Acknowledgements} 
The author would like to thank the anonymous referees for their constructive comments, and 
Christopher Hobson for his help in conducting simulations on a random partial k-tree model.
\bibliographystyle{plain}
\bibliography{../treewidth,../complex_networks,../random_graph}



\end{document}
