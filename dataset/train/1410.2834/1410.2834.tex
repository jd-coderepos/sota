\section{Experimental Results}
\label{sec:result}

	In this section, we present the results for two accomplished tests. The fist one is a  comparison between the FCHP-IP mathematical formulation and the FCHP-ILS heuristic. The second is a  comparison between the FCHP-ILS heuristic and the combination of  Amazonâ€™s Auto Scaling and Load Balancing mechanisms \cite{AS,ELB}  executed in two real small-scale scenarios.

\subsection{Comparing FCHP-IP and FCHP-ILS}
	 We evaluate FCHP-ILS, in terms of  quality of solution and execution time,  by comparing it with the solutions given by the formulation FCHP-IP when solved with the CPLEX $12.5.1$ \cite{cplex}. Those tests were run  in a computer with a processor Intel Core i7-3820 3.60GHz  and  a 32Gb memory running Ubuntu $12.04$. The  FCHP-ILS was implemented in the Programming language C/C++, gcc version $4.6.3$.
	
	 Those programs were run over a set of instances created from a  real trace obtained from the 1998 World Cup site \cite{copa98}.  Because this trace presents a huge number of requests, the total time of the trace was discretized in hours and only the requests for the ten most accessed contents in each interval of time were considered. Thus, instances with reduced size, but still presenting flash-crowd events, were created. Remark that the original instance could not be solved in a reasonable time by the CPLEX. 

Table \ref{Instance} presents for each of the twelve created instances, the  associated number of contents, requests and number of periods (hours). The last two instances were created by the synthetic trace generator and used for the real experiments, described in the next section.
	
\begin{table}[htp]
\small
\setlength{\tabcolsep}{3mm}
\caption{Instance description}
\begin{center}
\setlength{\tabcolsep}{0.6mm}
\begin{tabular}{|c|r|r|r|}
\hline 
Instance & \# of Contents  & \# of Requests & Periods (hours) \\
\hline
1	&	44	&	1798		&	12		\\
2	&	60	&	1696		&	12	    \\
3	&	88	&	983	    	&	12		\\
4	&	52	&	3546		&	24		\\
5	&	96	&	3427		&	24		\\
6	&	150	&	1922		&	24		\\
7   &   47  &   4327	    &   36      \\
8   &   83  &   4073        &   36      \\
9   &   99  &   1676        &   36      \\
10   &  69  &   7110 		&   48      \\
11   &   3  &   105         &   60      \\
12   &   4  &   186         &   60      \\
\hline
\end{tabular}
\end{center}
\label{Instance}
\end{table}
	
Table \ref{teorico} shows the results obtained by FCHP-IP and FCHP-ILS. The first column identifies the instance. The following six columns present the results obtained by FCHP-IP: number of hired  on demand servers, the total cost, the attendance cost, replication cost, backlog cost and the execution time to obtain the optimum solution. Following, the next columns present the same results of FCHP-ILS. Finally, the last column, shows the gap between the solutions given by FCHP-ILS and FCHP-IP. The  values shown for FCHP-ILS are averages of three executions, where  $3$, $7$ and $1$ were used for the number of iterations, the number of perturbations and the value of $d$ ({\bf $d-$Delay} neighbourhood), respectively. 


\begin{table}[htp]
\scriptsize
\caption{Results of FCHP-ILS Metaheuristic and FCHP-IP Mathematical Formulation using CPLEX.}
\begin{center}
\setlength{\tabcolsep}{1mm}
\begin{tabular}{|c|crrrcr|crrrcr|c|}
\hline 
\multirow{3}{0.5cm}{Inst} & \multicolumn{6}{|c|}{FCHP-IP} & \multicolumn{6}{|c|}{FCHP-ILS} & Gap\\
\cline{2-13}
 & Serv & \multicolumn{4}{|c|}{Time Cost} & & Serv & \multicolumn{4}{|c|}{Time Cost} & & \\
 &  OD & \multicolumn{1}{|c}{Total} & Attend & Repli & \multicolumn{1}{c|}{Back} & Time & OD & \multicolumn{1}{|c}{Total} & Attend & Repli & \multicolumn{1}{c|}{Back} & Time & (\%)\\
\hline 
1	&	14	&	1726.9	&	1639.6	&	87.3	&	0	&	134.6	&	7	&	2647.0	&	2486.3	&	160.8	&	0	&	93.7	&	53.3	\\
2	&	8	&	1993.6	&	1869.2	&	124.4	&	0	&	174.9	&	6	&	2139.6	&	1979.2	&	160.4	&	0	&	57.8	&	7.3	\\
3	&	8	&	607.4	&	446.6	&	160.8	&	0	&	44.2	&	2	&	749.4	&	573.3	&	176.1	&	0	&	73.8	&	23.4	\\
4	&	8	&	3512.8	&	3349.2	&	163.6	&	0	&	546.5	&	15	&	5570.4	&	5242.5	&	327.8	&	0	&	359.1	&	58.6	\\
5	&	26	&	2065.3	&	1775.4	&	289.9	&	0	&	230.1	&	5	&	2390.8	&	2065.4	&	325.4	&	0	&	168.5	&	15.8	\\
6	&	55	&	7167.0	&	6664.4	&	502.6	&	0	&	36619.4	&	9	&	8355.6	&	7604.4	&	751.2	&	0	&	185.7	&	16.6	\\
7	&	12	&	4991.3	&	4785.4	&	205.9	&	0	&	781.4	&	19	&	7914.9	&	7505.4	&	409.5	&	0	&	319.6	&	58.6	\\
8	&	10	&	3721.1	&	3344.6	&	376.5	&	0	&	610.2	&	15	&	5616.8	&	5084.6	&	532.2	&	0	&	230.4	&	50.9	\\
9	&	19	&	1179.1	&	750.4	&	428.7	&	0	&	280.2	&	8	&	1622.2	&	1040.4	&	581.8	&	0	&	79.7	&	37.6	\\
10*	&	43	&	7586.3	&	7202.0	&	384.3	&	0	&	2483.8	&	26	&	11763.0	&	11087.0	&	681.7	&	0	&	1308.6	&	55.1	\\
11*	&	440	&	28451.7	&	21957.4	&	6494.3	&	0	&	7388.8	&	123	&	28764.8	&	21957.4	&	6807.4	&	0	&	967.5	&	1.1	\\
12*	&	239	&	41228.2	&	32208.9	&	9019.3	&	0	&	14382.2	&	282	&	42036.2	&	32208.9	&	9827.3	&	0	&	6564.4	&	2.0	\\
\hline
Avg	&		&		&		&		&		&	5306.4 	&		&		&		&		&		&	867.4 	&	31.7	\\
\hline 
\end{tabular}
\end{center}
\label{teorico}
\end{table}
	

	In this table, we can observe a high gap for some instances. This is due to the difficult of the considered problem. The FCHP problem extends the Replica Placement Problem (RPP), which belongs to the NP-hard class \cite{aioffi05}. For small instances of the problem,  FCHP-ILS   takes a long time to find good solutions. However, as the input data increases, the FCHP-IP is not capable of proving the optimality of the solution in a reasonable time. Moreover,  FCHP-IP needs a higher memory capacity to solve bigger instances.  The results for instances $6$, $11$ and $12$ show that FCHP-ILS is more suitable in those cases, when  the gap and the execution time were reduced when compared with the averages results. Furthermore, in the last three instances, the CPLEX could not prove the optimality of the solution due to lack of memory. Remark that the two last instances were used in the real experiments.
	
\subsection{Comparing FCHP-ILS and Auto Scaling in real scenarios}	
		
	In order to analyze the performance of  FCHP-ILS  in a  commercial cloud, we executed it in two smalls scenarios of the problem and compared with the mechanism provided by the  popular  Auto Scaling and Load Balancing of the Amazon.
	We used the synthetic trace generator of flash-crowd events,  described in Section \ref{sec:background}, to generate the  clients'  requests.  The  Web application was developed using Apache Tomcat $6.0$ \cite{tomcat}.
	
	In the first scenario, the Web application offers  three different contents  with  the following sizes: $1.9$, $1.5$ and $0.9$ Gbytes. The \textit{ramp-up phase} occurs between $1140$ and $1740$ seconds, the \textit{sustained traffic phase} from $1800$ to $1860$ seconds,  and the \textit{ramp-down phase} in the interval from $1920$ to $2460$ seconds, as shown in  Figure \ref{fc-figure1}. 
	
	\begin{figure}[ht]
\centering
\begin{center}
\includegraphics[scale=0.5]{acessos_seg_novos.pdf} 
\end{center}
\caption{New generated requests per second for the first scenario.}
\label{fc-figure1}
\end{figure}

	
	In the second scenario, the Web application offers four different contents  with  the following sizes: $0.8$, $1.0$, $1.5$ and $2.0$ Gbytes. In this scenario there are two flash-crowd events. For the first flash crowd, the \textit{ramp-up phase} occurs between $540$ and $1140$ seconds, the \textit{sustained traffic phase} from $1200$ to $1320$ seconds,  and the \textit{ramp-down phase} in the interval from $1380$ to $1860$ seconds. For the second one,  the \textit{ramp-up phase} occurs between $1500$ and $2100$ seconds, the \textit{sustained traffic phase} from $2160$ to $2220$ seconds,  and the \textit{ramp-down phase} in the interval from $2280$ to $2820$ seconds. The accesses for this scenario are shown in Figure \ref{fc-figure2}. 
	
	
\begin{figure}[ht]
\centering
\begin{center}
\includegraphics[scale=0.5]{acessos_real_2_seg.pdf} \\
\end{center}
\caption{New generated requests per second for the second scenario.}
\label{fc-figure2}
\end{figure}
		
	In both tests, the servers' bandwidth is  $10$ Mbytes/s while  the clients' bandwidth  is $1$ Mbytes/s  bandwidth  in average. The content of $0.9$ Gbytes was the only one involved in the flash crowd for the first test and the contents of $0.8$ and $1.0$ Gbytes for the second one.
	
	The main objective to create and execute the second scenario was to analyze how these two approaches, Auto Scaling and  FCHP-ILS,  behave in a flash-crowd event with two distinct contents at overlapping periods of time. 

	To have a fair comparison, in both approaches, the flash crowd was detected in the same time and the Web application started by using two virtual machines of type \textit{m3.large}  of the Amazon, each one containing all the contents.	
	
	The Auto Scaling was configured to allocate new virtual machines (Web servers) in the beginning of the flash crowd. 
	Note that, during a flash crowd, the solution provided by Auto Scaling allocates virtual machines based on a static virtual image that must contain all contents of the Web application.
	 So it continued to use  \textit{m3.large} virtual machines,  which have  enough capacity to store the three contents. The  Load Balancing service is employed to evenly distribute the client's requests among the used  servers. 
	
	In our approach, requests are treated by a machine that has a similar role  of the one which executes the Auto Scaling and  Load Balancing service. It is responsible for directing the received requests to the virtual machines; when a flash crowd  occurs,  executing   FCHP-ILS;   and,  in accordance with the results given by FCHP-ILS, replicating contents or allocating  new virtual machines. Remark, however, that in our approach the new  allocated virtual machines can be different from the originally allocated ones. It allows for the Web application to use heterogeneous resources of the clouds. In our tests, cheaper and smaller virtual machines were allocated to store only the contents that were involved in the flash-crowd event. 
	
	In both approaches, more six virtual machines were hired during the flash crowd in the first scenario and more eight for the second one. However,  FCHP-ILS hired \textit{m3.medium} virtual machines with  enough storage capacity to keep only the contents involved in the flash crowd, which reduced the financial costs. In the first scenario, by using Auto Scaling the total financial cost was \$$4.25$, while in our approach was \$$3.11$. The execution times were similar, around $5560$ seconds. In the second scenario, the total financial cost was \$$5.60$ for the Auto Scaling solution and was \$$4.08$ for our solution. Again, the execution times were similar, around $5140$ seconds. Note that for both scenarios, with only one content involved in the flash crowd and with distinct contents at overlapping periods of time, the proposed solution, FCHP-ILS, presents satisfactory results in real environments.