\documentclass[10pt,twocolumn,letterpaper]{article}

\usepackage{iccv}

\usepackage{times,epsfig,graphics,graphicx,caption,float,subcaption,booktabs,xcolor,multirow,multicol,array,color,ifthen,tabu,colortbl,url,xparse,mathtools,patchcmd,enumitem,amssymb,xspace,nicefrac,microtype,amsmath,amsfonts}

\usepackage[title]{appendix}

\newcommand{\Lc}{\mathbf{X}}
\newcommand{\Ll}{l}
\newcommand{\La}{\mathbf{\alpha}}
\newcommand{\Lx}{\mathbf{\Delta x}}
\newcommand{\Ly}{\mathbf{\Delta y}}
\newcommand{\ours}{F-Clip}

\newcommand{\dai}[1]{\textcolor[rgb]{1,0,0}{xili: #1}}
\newcommand{\ym}[1]{{\color{red}{YM: #1}}}



\usepackage[breaklinks=true,bookmarks=false]{hyperref}




\def\iccvPaperID{9710} \def\httilde{\mbox{\tt\raisebox{-.5ex}{\symbol{126}}}}

\ificcvfinal\pagestyle{empty}\fi


\begin{document}

\title{ICCV Supplementary Material}

\author{First Author\\
Institution1\\
Institution1 address\\
{\tt\small firstauthor@i1.org}
\and
Second Author\\
Institution2\\
First line of institution2 address\\
{\tt\small secondauthor@i2.org}
}

\maketitle
\ificcvfinal\thispagestyle{empty}\fi



\newpage


To make a fair comparison with the previous state-of-the-art method HAWP~\cite{xue2020holistically}, we adopt the hyper-parameter settings including the 1) backbone, 2) longer training epoch, 3) data augmentation, and 4) focal loss on HAWP same as our best performance model \ours~(HR).

\noindent\paragraph{Backbone.}
Our method employ a strong backbone network HRnet \cite{sun2019deep} (short for HR in Table~\ref{tab:2stage_long}). As shwon in Table~\ref{tab:2stage_long}, the HRnet do not bring significantly performance improvement for HAWP.

\noindent\paragraph{Training Epochs.}
Our method needs more training iterations to converge because we use a strong backbone network.  
As shown in Table~\ref{tab:2stage_long} below, additional training epochs do not improve significantly the performance of state-of-the-art two-stage methods HAWP. 

\noindent\paragraph{Data Augmentation.}
As shown in single-stage object detection methods~\cite{liu2016ssd,centernet}, applying a more complex data augmentation does not improve the performance of two-stage networks.  We also see the same phenomena, as shown in Table~\ref{tab:2stage_long}.

\noindent\paragraph{Focal Loss.} 
Focal loss~\cite{lin2017focal} is designed to handle the balance between positive and negative samples. We apply the focal loss on the junction detector of HAWP. As shown in Table~\ref{tab:2stage_long} below, the focal loss makes a bad effect on the performance of HAWP. 

\noindent\paragraph{Analysis.} 
Both two-stage wireframe detection methods LCNN \cite{zhou2019end} and HAWP are junction based methods. The performance of junction detection will dominate the performance of overall wireframe detection. Our \ours~is a single stage method which skip the detection of junction and predicts the line directly. Compare with line detection, the local feature is enough for the detection of junction. Hence, hourglass backbone with a short training epoch (30 epochs) is enough for converging to a good result, a strong backbone HRnet with a longer training epoch (300 epoch) does not bring significant performance improvement for HAWP. Meanwhile, focal loss on the junction detector even makes a bad effect on the performance of HAWP.



\begin{table}[!h]
    \centering
    \small
    \setlength{\tabcolsep}{5.5pt}
    \renewcommand{\arraystretch}{1.2}
    \begin{tabular}{c|c|c|c|c|c}
    Method & backbone & epoch & DataAug & focal-loss & sAP \\
    \hline
    \hline
    \multirow{5}{*}{HAWP} & HG & 30  & ~          & ~          & 62.5 \\
     ~                    & HG & 300 & ~          & ~          & 62.8 \\
     ~                    & HR & 300 & ~          & ~          & 63.1 \\
     ~                    & HR & 300 & \checkmark & ~          & 63.0 \\
     ~                    & HR & 300 & \checkmark & \checkmark & 62.4 \\                    
     \hline
    Ours                  & HR & 300 & \checkmark & \checkmark & 64.5 
    \end{tabular}
    \vspace{8pt}
    \caption{HAWP with longer training epochs, hrnet backbone, focal loss, and the same data augmentation as ours.}
    \label{tab:2stage_long}
\end{table}

{\scriptsize
\bibliographystyle{ieee_fullname}
\bibliography{egbib}
}

\end{document}