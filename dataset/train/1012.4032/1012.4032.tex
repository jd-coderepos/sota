\documentclass[colorlinks=true,linkcolor=black,urlcolor=black,citecolor=blue,submission,copyright,creativecommons]{eptcs}

\providecommand{\event}{DCM 2011}

\usepackage{amsmath,amsfonts,amssymb,amsthm}
\usepackage{prooftree}
\usepackage{graphicx}

\newtheorem{theorem}{Theorem}[section]
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{corollary}[theorem]{Corollary}
\newtheorem{definition}{Definition}[section]
\newtheorem{example}{Example}[section]

\newcommand{\subst}[2]{[{#1}/{#2}]}
\newcommand{\lvec}{\ensuremath{\lambda^{\!\!\textrm{vec}}}}
\newcommand{\canon}[1]{[#1]}
\newcommand{\cocanon}[1]{\{#1\}}
\newcommand{\inner}[2]{\langle{#1}|{#2}\rangle}
\newcommand{\normalised}[1]{{#1}\!\downarrow}
\newcommand{\Bool}{\mathbb{B}}
\newcommand{\True}{\mathbb{T}}
\newcommand{\False}{\mathbb{F}}
\newcommand{\true}{{\bf true}}
\newcommand{\false}{{\bf false}}
\newcommand{\eg}{\emph{e.g.}~}
\newcommand{\ie}{\emph{i.e.}~}
\newcommand{\cf}{\emph{cf}~}
\newcommand{\fv}[1]{\ensuremath{f\!v}(#1)}	
\newcommand{\FV}[1]{\ensuremath{FV}(#1)}	
\newcommand{\ve}[1]{\mathrm{\textbf{#1}}}
\newcommand{\type}{\colon\!}
\newcommand{\Sc}{\mathsf{S}}
\newcommand{\sui}[1]{\sum_{i=1}^{#1}}
\newcommand{\suj}[1]{\sum_{j=1}^{#1}}
\newcommand{\suk}[1]{\sum_{k=1}^{#1}}
\newcommand{\recap}[3]{\noindent\textbf{#1 \ref{#3}} (#2)\textbf{.}}
\newcommand{\xrecap}[2]{\noindent\textbf{#1 \ref{#2}}}
\newcommand{\ket}[1]{{|{#1}\rangle}}

\newcommand{\Neutral}{\mathcal{N}}
\newcommand{\CT}{\Lambda_0}
\newcommand{\SN}{{\it SN}_0}
\newcommand{\Red}{{\rm Red}}
\newcommand{\RC}{\mathsf{RC}}
\newcommand{\RCn}{{\bf RC}}
\newcommand{\bcal}[1]{\mathsf{#1}}
\newcommand{\denot}[1]{{[\!|{#1}|\!]}}




\title{A Type System for the Vectorial Aspect of the Linear-Algebraic Lambda-Calculus}
\author{Pablo Arrighi
\institute{LIP, \'{E}cole Normale Sup\'erieure de Lyon\\
46 all\'ee d'Italie\\
69364 Lyon cedex 07, France
}
\institute{LIG, Universit\'e de Grenoble\\
220, rue de la Chimie\\
38400 Saint Martin d'H\`eres, France}
\email{pablo.arrighi@imag.fr}
\and
Alejandro D\'iaz-Caro
\institute{LIG, Universit\'e de Grenoble\\
220, rue de la Chimie\\
38400 Saint Martin d'H\`eres, France}
\institute{LIPN, Universit\'e Paris 13, Sorbonne Paris Cit\'e\\
99 av. J-B Cl\'ement,\\
93430 Villetaneuse, France}
\email{alejandro@diaz-caro.info}
\and
Beno\^it Valiron
\institute{LIPN, Universit\'e Paris 13, Sorbonne Paris Cit\'e\\
99 av. J-B Cl\'ement,\\
93430 Villetaneuse, France}
\institute{University of Pennsylvania\\
CIS Department\\
Philadelphia, PA 19104, USA}
\email{benoit.valiron@monoidal.net}
}

\def\titlerunning{A Type System for the Vectorial Aspects of the
  Linear-Algebraic
  -Calculus}
\def\authorrunning{P. Arrighi, A. D\'iaz-Caro \& B. Valiron}
\begin{document}
\maketitle

\begin{abstract}
  We describe a type system for the linear-algebraic
  lambda-calculus. The type system accounts for the part of the
  language emulating linear operators and vectors, i.e. it is
  able to statically describe the linear combinations of terms
  resulting from the reduction of programs.  This gives rise to an
  original type theory where types, in the same way as terms, can be
  superposed into linear combinations.  We show that the resulting
  typed lambda-calculus is strongly normalising and features a weak
  subject-reduction.
\end{abstract}

\section{Introduction}
A number of recent works seek to endow the -calculus with a
structure of vector space; this agenda has emerged simultaneously in
two different contexts (albeit
related~\cite{DiazcaroPerdrixTassonValironHOR10}). A first line of
work forked from the study of relational models of linear logic. In
\cite{EhrhardRegnierTCS03,TassonTLCA09,VauxMSCS09}, various algebraic
lambda-calculi, that is, languages with vectorial structures, are
considered. These languages are based on an interpretation of
intuitionistic logic by linear logic. A second line of work
\cite{ArrighiDiazcaroQPL09,ArrighiDowekRTA08,DiazcaroPetitWoLLIC12}
considers linear combinations of terms as a sort of ``quantum
superposition''. This paper stems from this second approach.

In quantum computation, data is encoded on normalised vectors in
Hilbert spaces. For our purpose, it is enough to say that a Hilbert
space is a vector space over the field of complex numbers. The
smallest space usually considered is the space of {\em qubits}. This
space is the two-dimensional vector space , and comes
with a chosen orthonormal basis denoted by . A
general quantum bit (or qubit) is a normalised vector , where . The operations on
qubits that we consider are the {\em quantum gates}, \ie unitary
operations. For our purpose, their interesting property is to be {\em
  linear}.

The language we consider in this paper will be called the {\em
  vectorial lambda-calculus}, denoted by . It is
inspired from {\it Lineal}~\cite{ArrighiDowekRTA08}. This language
admits the regular constructs of lambda-calculus: variables
, lambda-abstractions  and application
. It also admits linear combinations of terms:
,  and  are terms. The
scalar  ranges over the ring of complex numbers. As in~\cite{ArrighiDowekRTA08}, it behaves in a
call-by-value oriented manner, in the sense that  first reduces to  until {\em basis terms} are reached, at which point beta-reduction applies. The
lambda-binder is not linear with respect to the vectorial
structure:  is not the same thing as
; in fact abstractions and variables are exactly what is meant by basis terms.

The set of the normal forms of the terms can then be interpreted as a vector space and the
term  can be seen as the application of
the linear operator  to the vector~.
The goal of this paper is to give a formal description of this
intuition at the level of the type system.


\paragraph{Related works and contribution.}
This paper is part of a general research framework aiming at
understanding the relationship between quantum computation and
algebraic lambda-calculi
\cite{AltenkirchGrattageLICS05,ArrighiDowekRTA08,tonder04lambda,ValironQPL10}. The ultimate
goal of this research path is to design a typed language whose terms
can be interpreted both as quantum data and descriptions of quantum
algorithms. The type system would then provide a ``quantum theoretical logic'' and
the language a Curry-Howard isomorphism for quantum computation.

The central question this paper is concerned with is the nature of the
type system to be used. The solution we are proposing is an extension
of two languages designed in \cite{ArrighiDiazcaroQPL09} and
\cite{DiazcaroPetitWoLLIC12}.

The first paper~\cite{ArrighiDiazcaroQPL09} is uniquely concerned with the addition of
scalars in the type system. If  is a scalar and
 is a sequent,  is of type
. The developed language actually provides a static analysis
tool for {\it probabilistic} computation, when the scalars are taken
to be {\it positive real numbers}. It however fails to address the issue in
this paper: without sums but with negative numbers, the term  is typed with , a type which fails to exhibits the fact that we have a superposition of terms.

The second paper~\cite{DiazcaroPetitWoLLIC12} is concerned with the addition of sums to a
regular type system. In this case, if  and  are two valid sequents,
 is of type . However, the language considered is only the {\it
  additive} fragment of {\it Lineal}, it leaves scalars out of the picture.

The paper we present here builds on these two approaches. Its goal is
to characterise the notion of vectors in the vectorial
lambda-calculus. Because of the possible negative or complex
coefficients, this requires to keep track of the `direction' as well
as the `amplitude' of a term.  We propose a type system with both sums
and scalars, reflecting the vectorial structure of the vectorial
lambda-calculus. 
Interestingly enough, combining the two separate features of
\cite{ArrighiDiazcaroQPL09,DiazcaroPetitWoLLIC12} raises subtle novel
issues. In the end we achieve a type system which is such that if  has type , then it must reduce to a  of the form , where the 's
are basis terms.  The resulting language is strongly normalising,
confluent, and features a weak-subject reduction.


\paragraph{Plan of the paper.}
In Section~\ref{sec:language}, we present the language. We discuss the
differences with the original language {\it
  Lineal}~\cite{ArrighiDowekRTA08}. In
Section~\ref{sec:vectorial}, we expose the type system and the problem
arising from the possibility of having linear combinations of types.
Section~\ref{sec:sr} is devoted to subject reduction. We first say
why the usual result is not valid, then we provide a solution and a
candidate subject reduction theorem; the rest of the section is
concerned with the proof of the result.  In Section~\ref{sec:conf}, we prove confluence and strong normalisation for this setting.
Finally we close the paper with some examples in
Section~\ref{sec:examples} and conclusions in
Section~\ref{sec:conclusion}.


\section{The Terms}\label{sec:language}

We consider the untyped language \lvec\ described in
Figure~\ref{fig:Vec}. It is based on {\em Lineal}
\cite{ArrighiDowekRTA08}: terms come in two flavours, basis terms
which are the only ones that will substitute a variable in a
-reduction step, and general terms. 

Terms are considered modulo associativity and commutativity of
the operator~, making the reduction into an {\em AC-rewrite system}
\cite{JouannaudKirchnerSIAM86}.
Scalars (notation ) form a ring
.
The typical ring we consider in the examples is
the ring of complex numbers. In particular, we shall use the shortcut
notation  in place of .
The set of free variables of a term is defined
as usual: the only operator binding variables is the
-abstraction.
The operation of substitution on terms (notation~)
is defined in the usual way for the regular lambda-term constructs, by
taking care of variable renaming to avoid capture. For a linear
combination, the substitution is defined as follows: .

In addition to -reduction, there are fifteen rules stemming from the oriented axioms of vector spaces \cite{ArrighiDowekRTA08}, specifying
the behaviour of sums and products.
A general term  is thought
of as a linear combination of terms . When we apply  to this superposition, 
reduces to .

Note that we need to choose a reduction strategy: we cannot reduce the
term  both to  and to . Indeed, the former reduces to
 whereas the latter reduces to
. Since this calculus inherits from
\cite{ArrighiDiazcaroQPL09,ArrighiDowekRTA08,DiazcaroPetitWoLLIC12}, we
consider the beta-reduction acting in a call-by-value oriented way (in fact, ``call-by-base'' is a more accurate name).



\begin{figure}[!ht]
\centering
\scalebox{0.8}{\fbox{\begin{tabular}{@{}c@{}}

\\
\begin{tabular}{p{4cm}p{4cm}p{4cm}}
\emph{Group E:}

  

 

 

 

 

&
\emph{Group F:}

	

	

	
	
	 
\medskip

\emph{Group B:}

 
&
 \emph{Group A:}

 

 

 

 

 

 
\end{tabular}
\\begin{array}[t]{l@{\hspace{1.5cm}}r@{\ ::=\quad}l}
      \text{\em Types:} & T,R,S & U~|~\alpha\cdot T~|~T+R\\
      \text{\em Unit types:} & U,V,W & X~|~U\to T~|~\forall X.U
\end{array}\prooftree
\justifies\Gamma, x\type{U}\vdash x\type{U}
\using ax
\endprooftree
\qquad
\prooftree\Gamma\vdash\ve{t}\type T
\justifies\Gamma\vdash\ve{0}\type 0\cdot T
\using 0_I
\endprooftree
\qquad
\prooftree\Gamma, x\type{U} \vdash\ve{t}\type T
\justifies\Gamma \vdash \lambda x.\ve{t}\type{U}\to T
\using\to_I
\endprooftree\prooftree\Gamma \vdash\ve{t}\type\!\!\sui{n}\alpha_i\cdot \forall\vec{X}.(U\to T_i) \qquad \Gamma\vdash\ve{r}\type\!\!\suj{m}\beta_j\cdot {V_j}\qquad
{
\forall V_j,\exists\vec{W}_j, U[\vec{W}_j/\vec{X}]=V_j
}
\justifies\Gamma \vdash(\ve{t})~\ve{r}\type\sui{n}\suj{m} \alpha_i\times\beta_j\cdot {T_i[\vec{W}_j/\vec{X}]}
\using\to_E
\endprooftree
\prooftree\Gamma\vdash\ve{t}\type \sui{n}\alpha_i\cdot U_i\quad{X\notin FV(\Gamma)}
\justifies\Gamma\vdash\ve{t}\type\sui{n}\alpha_i\cdot \forall X.U_i
\using \forall_I
\endprooftree
\qquad
\prooftree\Gamma\vdash\ve{t}\type \sui{n}\alpha_i\cdot \forall X.U_i
\justifies\Gamma\vdash\ve{t}\type \sui{n}\alpha_i\cdot U_i[V/X]
\using \forall_E
\endprooftree
\prooftree\Gamma\vdash\ve{t}\type T
\justifies\Gamma\vdash\alpha\cdot \ve{t}\type\alpha\cdot T
\using\alpha_I
\endprooftree
\qquad
\prooftree\Gamma\vdash\ve{t}\type T\qquad\Gamma\vdash\ve{r}\type R
\justifies\Gamma\vdash\ve{t}+\ve{r}\type T+R
\using +_I
\endprooftree
\qquad
\prooftree\Gamma\vdash\ve{t}\type T\qquad T\equiv R
\justifies\Gamma\vdash\ve{t}\type R
\using\equiv
\endprooftree

\end{tabular}}}
 \caption{Types and typing rules of \lvec.}
 \label{fig:types}
\end{figure}

The following lemmas give some properties of the equivalence
relation. Types are linear combinations of unit types
(Lemma~\ref{lem:typecharact}). Finally, the equivalence is well-behaved with respect to
type constructs (Lemma~\ref{lem:equivforall}).

\begin{lemma}[Types characterisation]\label{lem:typecharact}
 For any type , there exist ,  and unit types  such that .
\end{lemma}
\begin{proof}
 Structural induction on . If  is a unit type, take  and so . If , then by the induction hypothesis , so . If , then by the induction hypothesis  and , so .
\end{proof}


\begin{lemma}[Equivalence ]\label{lem:equivforall}~
\begin{enumerate}
 \item\label{it:equivforall1} 
.
 \item\label{it:equivforall2} .
 \item\label{it:equivforall3} .
\end{enumerate}
\end{lemma}
\begin{proof}
 Straightforward case by case analysis over the equivalence rules.
\end{proof}


\subsection{Typing Rules}

The typing rules are described in Figure~\ref{fig:types}. 
Contexts are denoted by , , etc. and are defined as sets , where  is a term variable appearing only once in the set, and  is a unit type.
The axiom
() and the arrow introduction rule () are the usual
ones. The rule () to type the term  takes into account
the discussion at the beginning of Section~\ref{sec:vectorial}. This rule
also ensures that the type of  is inhabited, discarding
problematic types like . Any sum of typed terms can be
typed using Rule . Similarly, any scaled typed term can be typed
with . Rule  ensures that equivalent types can
be used to type the same terms. Finally, the particular form of the
arrow-elimination rule () is due to the rewrite rules in
group~A that distribute sums and scalars over application. 

The need and use of this complicated arrow elimination can be
illustrated by three examples.

\begin{example}\rm
  Rule  is easier to read for trivial linear
  combinations. It states that provided that  and , if there exists
  some type  such that , then since the sequent
   is valid, we also have
  .
\end{example}

\begin{example}\rm
  Consider the terms  and , of respective types
   and . The term  is of type
  . We would reasonably expect the term  to be also of type . This is the case
  thanks to Rule . Indeed, type the term  with the
  type  and we can now apply the rule.
\end{example}

\begin{example}\label{ex:3}\rm
  A slightly more evolved example is the projection of a pair of
  elements. It is possible to encode in {\em System F} the notion of pairs
  and projections: , ,  and
  . Provided that , ,  and  have respective types , ,
   and , the type of  is  and the type of  is . The term 
  and  can be typed respectively with  and .
    The term  is then typable of type , thanks
  to Rule . Note that this is consistent with the rewrite
  system, since it reduces to .
\end{example}


\section{Subject Reduction}\label{sec:sr}

Since the terms of  are not explicitly typed, we are bound to
have sequents such as  and
 with distinct types  and 
for the same term .
Using Rules
 and  we get the valid typing judgement
. Given that 
reduces to , a regular subject reduction
would ask for the valid sequent .  Since in general we do not
have , we need to find a way around
this.

A first natural solution could be by using the notion of principal
types. However, since our type system can be seen as an extension of {\em System~F},
the usual examples for the absence of principal types apply to our
settings: we cannot rely on that.

A second potentially natural solution could be to ask for the sequent
 to be valid. If we force this typing rule into the system, it
seems to solve the problem but then the type of a term becomes pretty
much arbitrary: with typing context , the term
 could be typed with any combination
, when .

The approach we favour in this paper is by using a notion of order on
types. The order, denoted with , will be chosen so that
the factorisation rules make the
types of terms smaller according to the order. We will ask in
particular that  and  whenever  and  are types for the same
term. 
This approach can also be extended to solve a second pitfall coming the
rule . Indeed, although  is well-typed for any inhabited , the sequent
 is not valid in general. We therefore extend
the ordering to also allow .


\subsection{An Ordering Relation on Types.}

We start with another relation  inspired from
\cite{Barendregt92}. This relation can be deduced from Rules
 and  as follows: write  if either
 and  or  and
. We denote the reflexive
(with respect to ) and transitive closure of  with .
The relation  admits a subsumption lemma.

\begin{lemma}[-subsumption]\label{lem:subsumption}
  For any context , any term  and any types  such that  and no free type variable in  occurs in . Then 
   implies .
\end{lemma}
\begin{proof}
 One can assume  (if not, there must be an equivalence
 instead, so the lemma would hold due to the -rule). So
 for all  one has , thus
  and using
  or , we get . Since  we finally get . Repeating the process we eventually reach .
\end{proof}


We can now define the ordering relation  on types
discussed above as the
smallest reflexive transitive relation satisfying the rules:
\begin{enumerate}
 \item 
   if there are  such that  and .
\item  for any type .
\item If , then .
\item If  and , then ,  ,  and .
\end{enumerate}
Note that the fact that  and  does not imply that . Indeed, although , we do not have .
Note also that this ordering is not a subtyping relation. Indeed,
although  is valid and
, the
sequent  is not valid.


\subsection{Weak Subject Reduction}
Let  be any reduction rule from Figure~\ref{fig:Vec}. We denote  a one-step reduction by rule .
A weak version of the subject reduction theorem can be stated as follows.
\begin{theorem}[Weak subject reduction]\label{thm:subjectreduction}
  For any terms , , any context  and any type
  , if  and , then:
  \begin{enumerate}
   \item if  Group F, then ;
   \item if  Group F, then
    such that  and
   .
  \end{enumerate}
\end{theorem}

\noindent How weak is this {\em weak} subject reduction? First, note that the usual subject
reduction result holds for most of the rules. 
Second, Theorem~\ref{thm:subjectreduction} ensures that a term  of a
given type, when reduced, can be typed with a type that is also valid
for the term . 
Third, we can characterise the order relation as follows.
\begin{lemma}[Order characterisation]\label{lem:orderchar} For any type , unit types   and scalars , if , then there exist a scalar , a natural number , a set  and a unit type  such that  and .
\end{lemma}
\begin{proof}
 Structural induction on .
\end{proof}


How informative is the type judgement? The following three lemmas express formal relations between the types and their terms.

\begin{lemma}[Scalars, scaling]\label{lem:scalars}\label{cor:scaling}
  For any context , term , type  and scalar
  , if , then there
  exists a type  such that  and if
  , .  Moreover, if
  , then
  .
\end{lemma}
\begin{proof}
 The first part of the Lemma follows by induction on the typing derivation.
The second part of the Lemma, , follows as corollary. If , we have just proved that there exists  such that  and . It is easy to check that , so using rule , .
\end{proof}


Lemma~\ref{cor:scaling} is precursor of the generation lemma for
scalars (Lemma~\ref{lem:genLinComb}). However it is more specific since it
assumes a specific type and therefore more accurate in the sense that
it gives a specific type for the inverted rule which is not possible
in the actual generation lemma. 

Lemma~\ref{lem:scalars} excludes the case of scaling by . It is
covered by the following (whose proof is done by induction on the
typing derivation).

\begin{lemma}[Zeros]\label{lem:zeros}
For any context , term , unit types  and scalars , if , then  and there are scalars  such that .\qed
\end{lemma}

A basis term can always be given a unit type (the proof is also done by induction on the typing derivation).
\begin{lemma}[Basis terms]\label{lem:basevectors}
  For any context , type  and basis term , if
   then there exists a unit type  such
  that .\qed
\end{lemma}

In the remainder of this section we provide a few definitions and lemmas that are required in order to prove Theorem~\ref{thm:subjectreduction}.

In the same way that we can change a type in a sequent by an
equivalent one using rule , we can prove that this can also be
done in the context (proof by induction on the typing derivation).

\begin{lemma}[Context equivalence]\label{lem:contextequiv} For any
  term , any context  and any type
  , if  and 
  where , then .\qed
\end{lemma}

The following lemma is standard in proofs of subject reduction for
{\em System~F}-like systems, and can be found, \eg in
\cite[Ch. 4]{Barendregt92}. It
ensures that by substituting type variables for type or term variables
in an adequate manner, the derived type is still valid.

\begin{lemma}[Substitution lemma]\label{lem:substitution} For any term
  , basis term , term variable , context ,
  types , ,  and type variables ,
  \begin{enumerate}
  \item\label{it:substitution1} if , then ;
  \item\label{it:substitution2} if ,  and , then .
  \end{enumerate}
\end{lemma}
\begin{proof}
Both results follow by induction on the typing derivation.
\end{proof}

\noindent Proving subject reduction requires the proof that each reduction rule
preserves types. Thus three generation lemmas are required: two
classical ones, for applications (Lemma~\ref{lem:genapp}) and for
abstractions (Lemma \ref{lem:genabs} and
Corollary~\ref{cor:genabs}) and one for linear combinations: sums,
scalars and zero (Lemma~\ref{lem:genLinComb}). The first two lemmas follow by induction on the typing derivation.

\begin{lemma}[Generation lemma (application)]\label{lem:genapp} For
  any terms , , any context  and any type ,
  if , then there exist natural
  numbers , unit types , types 
  and scalars  and  ,
  such that , , for all , there exists  such that
   and .\qed
\end{lemma}

\begin{lemma}[Generation lemma (abstraction)]\label{lem:genabs} For any term variable , term , context  and type , if , there exist types  and  such that  and .\qed
\end{lemma}

The following lemma is needed for the proof of Corollary~\ref{cor:genabs}.

\begin{lemma}[Arrows comparison]\label{lem:arrowcomp}
 For any types  and any unit types , if , then there exist  such that .
\end{lemma}
\begin{proof}
 A map  from types to types is defined by
, , ,  and .

We need two intermediate results (the first one follows from a structural induction on  and the second one is a case by case analysis on  using the first result).
\begin{enumerate}
 \item\label{it:ir1} For any type  and unit type , there exists a unit type  such that 
 \item\label{it:ir2} For any types , , if  then 
\end{enumerate}
Proof of the lemma: by definition  which by \ref{it:ir2} is equivalent to .
\end{proof}


\begin{corollary}[of Lemma \ref{lem:genabs}]\label{cor:genabs} For any
  context , term variable , term , type variables
   and types  and , if
   then the
  typing judgement  is valid.
\end{corollary}
\begin{proof}
  By Lemma \ref{lem:genabs}, there exist  such that  and . Note that , so by Lemma~\ref{lem:arrowcomp}, there are
   such that 
  so  and . Also by Lemma~\ref{lem:substitution},
  . By Lemma~\ref{lem:contextequiv} and Rule
  , . If , we are done. Otherwise,  appears free in . 
Since  and , according to Lemma~\ref{lem:subsumption},  can be obtained from  as a type for : we would need to use Rule ; thus  cannot appear free in , which constitutes a contradiction. So, .
\end{proof}

\begin{lemma}[Generation lemma (linear combinations)]\label{lem:genLinComb}
    For any context , scalar , terms  and 
  and types  and :
  \begin{enumerate}
   \item if  then there exist types  and
   such that ,  and ;
  \item if , then there exists a type
   such that  and ;
  \item if , then there exists a type  such
  that .
    \end{enumerate}
\end{lemma}
\begin{proof}
 All the cases follow by structural induction on the typing derivation.
\end{proof}


\subsection{Proof of Theorem~\ref{thm:subjectreduction}}
We are now ready to prove Theorem \ref{thm:subjectreduction}.

\begin{proof}
Let  and . We proceed by induction. We only give two interesting cases.
\begin{description}
 \item[.]
         Let . Then by
         Lemma~\ref{lem:genLinComb}, there are types  such that
          and
          with .
         By Lemma~\ref{lem:genLinComb}, there exists a type  such
         that 
         and , and there
         exists a type  such that  and .
		\begin{itemize}
		 \item If  (or analogously ), then by Lemma~\ref{lem:scalars},  and so by  we conclude . Notice that . Also using Rules  and  we conclude .
		 
		 \item If , then notice that
                    and
                   . Using again Rules  and , we conclude .
		\end{itemize}
		
\item[.]
      Let . Then by
      Lemma~\ref{lem:genapp}, there exist numbers , scalars
      , a unit type
      , and general types  such that
       and  with  and
      where for all ,  is such that .
       
      By Lemma~\ref{lem:basevectors},  and
      for all , . Analogously  where for all , . So  and . Then by Rule , ,  and .

      Thus, by Corollary~\ref{cor:genabs}, . Notice that . By Lemma~\ref{lem:substitution}, we have
      . Since , and since all the  are equivalents
      between them, this type is equivalent to
      . By
      Lemma~\ref{lem:subsumption}, we conclude .\qedhere
\end{description}
\end{proof}


\section{Confluence and Strong Normalisation}\label{sec:conf}
 The language has the usual properties for a typed lambda-calculus: the reduction is locally confluent and the type system enforces strong normalisation. From these two results, we infer the confluence of the rewrite system.
 
\begin{theorem}[Local confluence]\label{thm:localconf}
   For any terms ,  and , if  and , then there exists a term  such that  and . 
\end{theorem}
\begin{proof}
   First, one proves the local confluence of the algebraic fragment of the rewrite system (that is, all the rules minus the beta-reduction). This has been automatised~\cite{BenCoqProof} using COQ~\cite{ManualCOQ}.
The proof of confluence of the beta-reduction alone is a
   straightforward extension of the proof of confluence of the usual
   untyped -calculus which can be found in many textbooks,
   \eg \cite[Sec. 1.3]{Krivine90}.
Finally, a straightforward induction entails that the two fragments commute: this entails the local confluence of the whole rewrite system.
\end{proof}

For proving strong normalisation of well-typed terms, we use reducibility candidates, a well-known method described for example in~\cite[Ch. 14]{GirardLafontTaylor89} The technique is adapted to linear combinations of terms. 
 
A {\em neutral term} is a term that is not a lambda-abstraction and
that does reduce to anything. The set of {\em closed neutral terms} is denoted with . We write  for the set of closed terms and  for the set of closed, strongly normalising terms. If  is any term,  is the set of all terms  such that .
It is naturally extended to sets of terms. We say that a set  of closed terms is a reducibility candidate, denoted with  if the following conditions are verified:
\begin{description}
 \item[] Strong normalisation: .
 \item[] Stability under reduction:  implies .
 \item[] Stability under neutral expansion: If  and  then .
 \item[] The common inhabitant: .
\end{description}
\noindent We define the following operations on reducibility
candidates. Let  and  be in .
 is the closure of  under  and
, where  is a base term. If  is a
family of reducibility candidates,  is
the closure of 
under  and . If there is only one type  in the sum, we
write  instead.

\begin{lemma}\label{lem:RCop}
  If ,  and all the 's are in ,
  then so are ,  and
  .
\end{lemma}
\begin{proof}
We need an intermediate result first, showing that
\begin{quote}
if  is a family of strongly normalising term, then so is any linear combination of term made of the 
\end{quote}
Proof of this result: Let .  We define the
  {\em algebraic context}  by the following grammar: 
We claim that for all algebraic contexts  and all strongly
  normalising terms  that are not linear combinations (that
  is, of the form ,  or ), the term
   is also strongly normalising.
The claim is proven by induction on , the sum over
   of the sum of the lengths of all the possible rewrite sequences
  starting with .

\noindent Proof of the lemma:
  \begin{description}
   \item[]
	 : Assume that  is not in . Then there is an infinite sequence of reductions  with .  So there is an infinite sequence of reduction  starting with , for all base terms .  This contradicts the definition of .
: We must show that if  and , then . Let  such that for all , . Then by  in , , and so .  If  is neutral and , then  since . If , it does not reduce.
 and : Trivially true by definition.
\item[]
	 : If , the result is trivial by
           condition  on the  and the previous result about linear combination of strongly normalising terms. If  is neutral and , then  is strongly normalising since all elements of  are strongly normalising.
 and : Trivially true by definition.
: Since , by ,  is also in
           the set.
\item[]
	 : Trivial since for all , .
: Let , then for all ,  and so by  in , . Thus .
: Let  and . Then , and thus, by  in , , which implies .
: By , , then .\qedhere
   \end{description}
\end{proof}

A \emph{single type valuation} is a partial function from type variables to reducibility candidates, that we define as a sequence of comma-separated mappings, with  denoting the empty valuation:
.
Type variables are interpreted using pairs of single type valuations, that we simply call {\em valuations}, with common domain:
 with .
Given a valuation , the {\em complementary valuation}  is the pair . We write  for the valuation . A valuation is called \emph{valid} if for all , .

To define the interpretation of a type , we use the following
result.

\begin{corollary}[of Lemma~\ref{lem:typecharact}]\label{cor:typedecomp}
  Any type  has a unique canonical decomposition
   such that for all , .
\end{corollary}
\begin{proof}
   By Lemma~\ref{lem:typecharact}, . Suppose that there exist
   such that . Then notice that .
  Repeat the process until there is no more 
  such that .
\end{proof}

The interpretation  of a type  in a
valuation~ defined for each free type variable
of~ is given by: , , ,
and if  is the canonical decomposition
of  then 
.
From Lemma~\ref{lem:RCop}, the interpretation of any type is a reducibility candidate.

Reducibility candidates deal with closed terms, whereas proving the adequacy lemma by induction requires the use of open terms with some assumptions on their free variables, that will be guaranteed by a context. Therefore we use \emph{substitutions}  to close terms: , then  and .

  Given a context , we say that a substitution~
  \emph{satisfies}~ for the valuation~
  (notation:~) when~
  implies  (Note the change in
  polarity).  Let , such that for all
  , , which always exists by
  Corollary~\ref{cor:typedecomp}.
A typing judgement , is said to be \emph{valid} (notation ) if for every valuation~, and set of valuations , where  acts on , and for every substitution~, we have .
\medskip

\begin{lemma}[Adequacy Lemma]\label{lem:SNadeq}
Every derivable typing judgement is valid: For every valid sequent , we have .\qed
\end{lemma}
\begin{proof}
 The proof uses a few auxiliary lemmas.
 \begin{enumerate}
  \item\label{lem:polar1}   Given a (valid) valuation , for all types  we have . 
  {\em Proof:} Structural induction on T
\item\label{lem:polar2} Let  and  be two valuations such that ,  and . Then for any type  we have  and .
  {\em Proof:} Structural induction on .
\item\label{lem:1cdotrc}
  For all reducibility candidates , . Moreover, if  is a base term, then
  . 
  {\em Proof:} For all , the term . Since
  , we conclude using .
  Now, consider . We proceed by structural induction on .
\item\label{lem:sumrc}
  For all reducibility candidates ,
  , if  and , then . 
  {\em Proof:} By structural induction on  and
  .
\item\label{lem:applirc}
  Suppose that  and , then
  . 
  {\em Proof:} Induction on the definition of .
 \end{enumerate}
 
 \noindent The proof of the adequacy lemma is done by induction on the size of
the typing derivation of , relying on these
results.
\end{proof}


\begin{theorem}[Strong normalisation]\label{th:SN}
  If  is a valid sequent, then  is strongly normalising.
\end{theorem}
\begin{proof}
  If  is the list , the sequent  is valid. Using Lemma~\ref{lem:SNadeq}, we deduce that for any valuation  and any substitution , we have . By construction,  does nothing on : . Since  is a reducibility candidate,  is strongly normalising. Now suppose that  were not strongly normalising. There would be an infinite rewrite sequence of terms   starting with . But then  would then be an infinite rewrite sequence of terms starting with a strongly normalising term: contradiction. Therefore,  is strongly normalising.
\end{proof}

 
  
\begin{corollary}[Confluence]
  If  is a valid typing judgement and if
   and , then there exists 
  such that  and .
\end{corollary}
\begin{proof}
  A rewrite system that is both locally confluent and strongly
  normalising is confluent~\cite{terese03}.
\end{proof}

\section{Expressing Matrices and Vectors}\label{sec:examples}

In this section we come back to the motivating example introducing the
type system and we show how {\lvec} handles the Hadamard gate, and how
to encode matrices and vectors.

With an empty typing context, the booleans 
 and 
can be respectively typed with the types 
 and .
The superposition has the following type . (Note that it can also be typed with ).

With an empty typing context, the linear map  sending 
to  and  to
 is written as
.
The following sequent is valid: 
.

This is consistent with the discussion in the introduction:
the Hadamard gate is the case  and
.  One can check that with an empty typing context,
 is well typed of type
, as expected since it reduces to
.

The term  is
well-typed of type . Since the term reduces to
, this is still consistent with the subject reduction: we
indeed have
.


\section{Conclusion} \label{sec:conclusion}
In this paper we define a strongly normalising, confluent,
typed,
algebraic -calculus satisfying a weak subject reduction. The
language allows making arbitrary linear combinations of
-terms . Its {\em
  vectorial} type system is a fine-grained analysis tool describing the
``vectorial'' properties of typed terms: First, it keeps track of the
`amplitude of a term', \ie if  and  both have the same
type , then  has type
. Then it keeps track of the `direction of a
term', \ie if  and  have types  and 
respectively, then  has type
. This type system is expressive enough to be able to
type the encoding of matrices and vectors.

The resulting type system has the property that if  then there exists  such that
 and , where
each  is a basis term of type . Such a  is
obtained by normalising  under all rules but the factorisation
rules. Within such a  there may be subterms of the form
 of type
, which are redexes for the
factorisation rules. Under our type system, the reduct
 can be given both the types
 and .

The tool we propose in this paper is a first step towards lifting the ``quantumness'' of algebraic lambda-calculi to the level of a type based analysis. It is also a step
towards a ``quantum theoretical logic'' coming readily with a Curry-Howard
isomorphism. The logic we are sketching merges intuitionistic logic
and vectorial structure. It results into a novel and intriguing tool.

The next step in the study of the quantumness of the linear algebraic
lambda-calculus is the exploration of the notion of orthogonality
between terms, and the validation of this notion by means of a compilation
into quantum circuits. The work in~\cite{ValironQPL10} shows
that it is worthwhile pursuing in this direction.

\paragraph{Acknowledgements}
We would like to thank 
Michele Pagani
and
Barbara Petit
for enlightening discussions.
This work was partially supported by the ANR--JCJC project CausaQ and grants from DIGITEO and Région \^Ile-de-France.


\begin{thebibliography}{10}
\providecommand{\bibitemdeclare}[2]{}
\providecommand{\urlprefix}{Available at }
\providecommand{\url}[1]{\texttt{#1}}
\providecommand{\href}[2]{\texttt{#2}}
\providecommand{\urlalt}[2]{\href{#1}{#2}}
\providecommand{\doi}[1]{doi:\urlalt{http://dx.doi.org/#1}{#1}}
\providecommand{\bibinfo}[2]{#2}

\bibitemdeclare{inproceedings}{AltenkirchGrattageLICS05}
\bibitem{AltenkirchGrattageLICS05}
\bibinfo{author}{Thorsten Altenkirch} \& \bibinfo{author}{Jonathan~J. Grattage}
  (\bibinfo{year}{2005}): \emph{\bibinfo{title}{A functional quantum
  programming language}}.
\newblock In: {\sl \bibinfo{booktitle}{Proceedings of {LICS}-2005}},
  \bibinfo{publisher}{IEEE Computer Society}, pp. \bibinfo{pages}{249--258},
  \doi{10.1109/LICS.2005.1}.
\newblock \urlprefix\url{http://arxiv.org/abs/quant-ph/0409065}.

\bibitemdeclare{inproceedings}{ArrighiDiazcaroQPL09}
\bibitem{ArrighiDiazcaroQPL09}
\bibinfo{author}{Pablo Arrighi} \& \bibinfo{author}{Alejandro D{\'\i}az-Caro}
  (\bibinfo{year}{2011}): \emph{\bibinfo{title}{Scalar system {F} for
  linear-algebraic lambda-calculus: towards a quantum physical logic}}.
\newblock In \bibinfo{editor}{Bob Coecke}, \bibinfo{editor}{Prakash Panangaden}
  \& \bibinfo{editor}{Peter Selinger}, editors: {\sl
  \bibinfo{booktitle}{Proceedings of {QPL}-2009}}, {\sl
  \bibinfo{series}{Electronic Notes in Theoretical Computer Science}}
  \bibinfo{volume}{270/2}, \bibinfo{publisher}{Elsevier}, pp.
  \bibinfo{pages}{219--229}, \doi{10.1016/j.entcs.2011.01.033}.
\newblock \urlprefix\url{http://arxiv.org/abs/0903.3741}.

\bibitemdeclare{inproceedings}{ArrighiDowekRTA08}
\bibitem{ArrighiDowekRTA08}
\bibinfo{author}{Pablo Arrighi} \& \bibinfo{author}{Gilles Dowek}
  (\bibinfo{year}{2008}): \emph{\bibinfo{title}{Linear-algebraic
  lambda-calculus: higher-order, encodings, and confluence}}.
\newblock In \bibinfo{editor}{Andrei Voronkov}, editor: {\sl
  \bibinfo{booktitle}{Proceedings of {RTA}-2008}}, {\sl
  \bibinfo{series}{Lecture Notes in Computer Science}} \bibinfo{volume}{5117},
  \bibinfo{publisher}{Springer}, pp. \bibinfo{pages}{17--31},
  \doi{10.1007/978-3-540-70590-1\_2}.
\newblock \urlprefix\url{http://arxiv.org/abs/quant-ph/0612199}.

\bibitemdeclare{book}{Barendregt92}
\bibitem{Barendregt92}
\bibinfo{author}{Henk~P. Barendregt} (\bibinfo{year}{1992}):
  \emph{\bibinfo{title}{Lambda-calculi with types}}.
\newblock {\sl \bibinfo{series}{Handbook of Logic in Computer
  Science}}~\bibinfo{volume}{{II}}, \bibinfo{publisher}{Oxford University
  Press}.

\bibitemdeclare{inproceedings}{DiazcaroPerdrixTassonValironHOR10}
\bibitem{DiazcaroPerdrixTassonValironHOR10}
\bibinfo{author}{Alejandro D\'iaz-Caro}, \bibinfo{author}{Simon Perdrix},
  \bibinfo{author}{Christine Tasson} \& \bibinfo{author}{Beno\^it Valiron}
  (\bibinfo{year}{2010}): \emph{\bibinfo{title}{Equivalence of algebraic
  lambda-calculi}}.
\newblock In: {\sl \bibinfo{booktitle}{Proceedings of the 5th International
  Workshop on Higher-Order Rewriting, {HOR}-2010}},
  \bibinfo{address}{Edinburgh, UK}, pp. \bibinfo{pages}{6--11}.
\newblock \urlprefix\url{http://arxiv.org/abs/1005.2897}.

\bibitemdeclare{inproceedings}{DiazcaroPetitWoLLIC12}
\bibitem{DiazcaroPetitWoLLIC12}
\bibinfo{author}{Alejandro D\'iaz-Caro} \& \bibinfo{author}{Barbara Petit}
  (\bibinfo{year}{2012}): \emph{\bibinfo{title}{Linearity in the non-deterministic call-by-value setting}}.
  \newblock In \bibinfo{editor}{Luke Ong} \& \bibinfo{editor}{Ruy de Queiroz}, editors: {\sl
	    \bibinfo{booktitle}{Proceedings of {WoLLIC}-2012}}, {\sl
	        \bibinfo{series}{Lecture Notes in Computer Science}} \bibinfo{volume}{7456},
		  \bibinfo{publisher}{Springer}, pp. \bibinfo{pages}{216--231}.
		\newblock \urlprefix\url{http://arxiv.org/abs/1011.3542}.
\newblock \bibinfo{note}{To appear}.

\bibitemdeclare{article}{EhrhardRegnierTCS03}
\bibitem{EhrhardRegnierTCS03}
\bibinfo{author}{Thomas Ehrhard} \& \bibinfo{author}{Laurent Regnier}
  (\bibinfo{year}{2003}): \emph{\bibinfo{title}{The differential
  lambda-calculus}}.
\newblock {\sl \bibinfo{journal}{Theoretical Computer Science}}
  \bibinfo{volume}{309}(\bibinfo{number}{1}), pp. \bibinfo{pages}{1--41},
  \doi{10.1016/S0304-3975(03)00392-X}.

\bibitemdeclare{book}{GirardLafontTaylor89}
\bibitem{GirardLafontTaylor89}
\bibinfo{author}{Jean-Yves Girard}, \bibinfo{author}{Yves Lafont} \&
  \bibinfo{author}{Paul Taylor} (\bibinfo{year}{1989}):
  \emph{\bibinfo{title}{Proofs and Types}}.
\newblock {\sl \bibinfo{series}{Cambridge Tracts in Theoretical Computer
  Science}}~\bibinfo{volume}{7}, \bibinfo{publisher}{Cambridge University
  Press}.
\newblock \urlprefix\url{http://www.paultaylor.eu/stable/Proofs+Types.html}.

\bibitemdeclare{article}{JouannaudKirchnerSIAM86}
\bibitem{JouannaudKirchnerSIAM86}
\bibinfo{author}{Jean-Pierre Jouannaud} \& \bibinfo{author}{H\'el\`ene
  Kirchner} (\bibinfo{year}{1986}): \emph{\bibinfo{title}{Completion of a set
  of rules modulo a set of equations}}.
\newblock {\sl \bibinfo{journal}{SIAM Journal on Computing}}
  \bibinfo{volume}{15}(\bibinfo{number}{4}), pp. \bibinfo{pages}{1155--1194},
  \doi{10.1145/800017.800519}.

\bibitemdeclare{book}{Krivine90}
\bibitem{Krivine90}
\bibinfo{author}{Jean-Louis Krivine} (\bibinfo{year}{1990}):
  \emph{\bibinfo{title}{Lambda-calcul: Types et Mod{\`e}les}}.
\newblock \bibinfo{series}{{\'E}tudes et Recherches en Informatique},
  \bibinfo{publisher}{Masson}.

\bibitemdeclare{inproceedings}{TassonTLCA09}
\bibitem{TassonTLCA09}
\bibinfo{author}{Christine Tasson} (\bibinfo{year}{2009}):
  \emph{\bibinfo{title}{Algebraic totality, towards completeness}}.
\newblock In \bibinfo{editor}{Pierre-Louis Curien}, editor: {\sl
  \bibinfo{booktitle}{Proceedings of {TLCA}-2009}}, {\sl
  \bibinfo{series}{Lecture Notes in Computer Science}} \bibinfo{volume}{5608},
  \bibinfo{publisher}{Springer}, pp. \bibinfo{pages}{325--340},
  \doi{10.1007/978-3-642-02273-9\_24}.
\newblock \urlprefix\url{http://arxiv.org/abs/0912.2349}.

\bibitemdeclare{book}{terese03}
\bibitem{terese03}
\bibinfo{author}{{TeReSe}} (\bibinfo{year}{2003}): \emph{\bibinfo{title}{Term
  Rewriting Systems}}.
\newblock {\sl \bibinfo{series}{Cambridge Tracts in Theoretical Computer
  Science}}~\bibinfo{volume}{55}, \bibinfo{publisher}{Cambridge University
  Press}.

\bibitemdeclare{manual}{ManualCOQ}
\bibitem{ManualCOQ}
\bibinfo{author}{{The Coq Development Team}} (\bibinfo{year}{2010}):
  \emph{\bibinfo{title}{Reference Manual}}, \bibinfo{edition}{8.3} edition.
\newblock \bibinfo{organization}{INRIA}.
\newblock \urlprefix\url{http://coq.inria.fr/doc}.

\bibitemdeclare{article}{tonder04lambda}
\bibitem{tonder04lambda}
\bibinfo{author}{Andr{\'e} van Tonder} (\bibinfo{year}{2004}):
  \emph{\bibinfo{title}{A Lambda-calculus for quantum computation}}.
\newblock {\sl \bibinfo{journal}{SIAM Journal of Computing}}
  \bibinfo{volume}{33}, pp. \bibinfo{pages}{1109--1135},
  \doi{10.1137/S0097539703432165}.
\newblock \urlprefix\url{http://arxiv.org/abs/quant-ph/0307150}.

\bibitemdeclare{inproceedings}{ValironQPL10}
\bibitem{ValironQPL10}
\bibinfo{author}{Beno{\^\i}t Valiron} (\bibinfo{year}{2010}):
  \emph{\bibinfo{title}{Orthogonality and algebraic lambda-calculus}}.
\newblock In: {\sl \bibinfo{booktitle}{Proceedings of the 7th International
  Workshop on Quantum Physics and Logic, {QPL}-2010}},
  \bibinfo{address}{Oxford, UK}, pp. \bibinfo{pages}{169--175}.
\newblock
  \urlprefix\url{http://www.cs.ox.ac.uk/people/bob.coecke/QPL_proceedings.html}.

\bibitemdeclare{misc}{BenCoqProof}
\bibitem{BenCoqProof}
\bibinfo{author}{Beno\^it Valiron} (\bibinfo{year}{2011}):
  \emph{\bibinfo{title}{Local confluence of the algebraic fragment: proof in
  COQ}}.
\newblock
  \urlprefix\url{http://www.monoidal.net/vectorial-lvec-coqproof.tar.bz2}.

\bibitemdeclare{article}{VauxMSCS09}
\bibitem{VauxMSCS09}
\bibinfo{author}{Lionel Vaux} (\bibinfo{year}{2009}): \emph{\bibinfo{title}{The
  algebraic lambda-calculus}}.
\newblock {\sl \bibinfo{journal}{Mathematical Structures in Computer Science}}
  \bibinfo{volume}{19}(\bibinfo{number}{5}), pp. \bibinfo{pages}{1029--1059},
  \doi{10.1017/S0960129509990089}.
\newblock \urlprefix\url{http://hal.archives-ouvertes.fr/hal-00379750}.

\end{thebibliography}



\end{document}
