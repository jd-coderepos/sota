\documentclass{aims}
\usepackage{paralist}
  \usepackage{graphics} \usepackage{epstopdf}\usepackage[colorlinks=true]{hyperref}

 \usepackage{mathrsfs}
\usepackage{amssymb}
\usepackage{cite}
\usepackage{graphicx}
\usepackage{epsfig}
\usepackage{color}
\usepackage{amsfonts}
\usepackage{amsthm}
\usepackage{amsmath}
\newtheorem{remark}{Remark}
\newtheorem{prop}{\textbf{Proposition}}
\newtheorem{thm}{\textbf{Theorem}}
\newtheorem{cor}{\textbf{Corollary}}
\newtheorem{lem}{\textbf{Lemma}}
\def\eq#1{}
\def\eqa#1{}
\def\eqan#1{}
\newcommand{\diag}{{\rm diag\;}}
\newcommand{\proofbox}{\hfill\mbox{}}
\newcommand{\image}{{\rm Im\;}}
\newcommand{\Span}{{\rm span\;}}
\newcommand{\rank}{{\rm rank\;}}
\newcommand{\Dim}{{\rm dim\;}}
\def\n{{\bf n}}
 \def\qed{ \rule{.1in}{.1in}}
\hypersetup{urlcolor=blue, citecolor=red}


  \textheight=8.2 true in
   \textwidth=5.0 true in
    \topmargin 30pt
     \setcounter{page}{1}

\def\currentvolume{X}
 \def\currentissue{X}
  \def\currentyear{2015}
   \def\currentmonth{XX}
    \def\ppages{X--XX}
     \def\DOI{10.3934/xx.xx.xx.xx}






\title[Decentralized gradient algorithm for linear equations] {Decentralized gradient algorithm for solution of a linear equation}

\author[Anderson and Mou and Morse and Helmke]{}

\keywords{Autonomous Systems; Distributed Algorithms; Linear Equations.}

\email{brian.anderson@anu.edu.au}
 \email{mous@purdue.edu}
 \email{as.morse@yale.edu}
 \email{helmke@mathematik.uni-wuerzburg.de}

\thanks{This work of Brian D. O. Anderson is supported
by Australian Research Council Discovery Project DP-130103610, by NICTA (National ICT Australia), and by a DAAD-GO8 collaborative grant. The research of A. Stephen Morse is supported by the US Air Force Office of Scientific Research and by the National Science Foundation.The research of U. Helmke  has been supported by the grants HE 1858/13-1 (German Research Foundation) and 57139792 (DAAD-ARC Go8).}

\thanks{ Corresponding author: Brian D. O. Anderson}

\begin{document}
\maketitle

\centerline{\scshape Brian D. O. Anderson}
\medskip
{\footnotesize
\centerline{College of Engineering and Computer Science }
   \centerline{The Australian National University}
   \centerline{ Canberra, Australia}
} 

\medskip

\centerline{\scshape Shaoshuai Mou}
\medskip
{\footnotesize
\centerline{ School of Aeronautics and Astronautics}
   \centerline{Purdue University}
   \centerline{West Lafayette, IN, USA}
}

\medskip

\centerline{\scshape A. Stephen Morse}
\medskip
{\footnotesize
\centerline{Department of Electrical Engineering}
   \centerline{Yale University}
   \centerline{New Haven, CT, USA}
}

\medskip

\centerline{\scshape Uwe Helmke}
\medskip
{\footnotesize
\centerline{Department of Mathematics}
   \centerline{W{\"u}rzburg University}
   \centerline{W{\"u}rzburg, Germany}
}


\bigskip




\begin{abstract}
The paper develops a technique for solving a linear equation  with a square and nonsingular matrix , using a decentralized gradient algorithm. In the language of control theory, there are  agents, each storing at time  an -vector, call it , and a graphical structure associating with each agent a vertex of a fixed, undirected and connected but otherwise arbitrary graph  with vertex set and edge set  and  respectively.  We provide differential equation update laws  for the  with the property that each  converges to the solution of the linear equation exponentially fast. The equation for  includes additive terms weighting those  for which vertices in  corresponding to the -th and -th agents are adjacent. The results are extended to the case where  is not square but has full row rank, and bounds are given on the convergence rate.
\end{abstract}

\section{Introduction}

Among the contributions of John Moore was a significant body of work,
largely conducted with the last author of this paper, in which methods of control theory
were applied to provide algorithms solving various problems of linear
algebra, for example, matrix diagonalization. Typically, differential
equations were constructed whose solutions evolved in time to a steady
state containing the desired result. For example, for a given square
matrix, the equation might be initialized by the matrix and converge
to a steady state solution that is a diagonal matrix with eigenvalues
equal to those of the given matrix.  Many of these results are set
out in the book \cite{UJ94Book}.

This paper offers another contribution along these lines: we show how
to solve a linear equation  in a \emph{distributed} way by a network of agents. Different from parallel algorithms in computer science  \cite{O96Cam,RJ05Cam,CAnd97Report} which usually require a common shared memory, a major novel feature of distributed algorithms lies in their implementation on multi-agent networks in which agents are provided with local memories and can communicate with each other. In the parallel world, the graph is chosen by the designer to maximize efficiency of computation in some sense whereas  in ours it may be given by other considerations such as communication requirements. When a linear equation of interest involves millions or more unknowns, it is likely to be impossible for a single memory to even store the whole linear equation. Such large scale linear equations can easily arise in electromagnetic field problems, in which the boundary integral technique is employed to recover the solution of a differential equation in space by an appropriate integration of the solution on the two-dimensional boundary surface \cite{Edelman93}. Another potential problem with the shared memory in parallel algorithms is the data safety. Security concerns often arise due to the fact that different agents are usually not necessarily in the same domain of trust. For example, when a customer turns to cluster computers for the help of computations which contain sensitive information such as business financial records, personally identifiable health information, etc, the customer may not be willing to share all such information with computers in the cluster \cite{CKJQ13TPD}. One natural way to avoid these problems is by developing such distributed algorithms for multi-agent networks. Since agents may also be physically separated from each other, each agent typically is  able to communicate only with certain other nearby agents. There are typically communication constraints on the information flow across multi-agent networks, which consequently preclude centralized processing and result in great interest of distributed algorithms.

One direction for solving linear equations in a distributed way is by reformulating them as a distributed optimization problem and then trying to employ existing algorithms in \cite{JAM12TAC,AA14TAC,DJJ14TAC,TAA14TAC} to solve them. Rather than go through the intermediate step of problem reformulation, the authors of \cite{SA13ECC,SJA13Allerton,SJA14TAC} have recently proposed a distributed algorithm for directly solving linear equations based on a so-called \emph{agreement principle}, which was implicitly used in \cite{AAP10TAC}. Here is the key idea: each agent limits the update of its state vector to satisfy its private equation, which is part of the linear equation ; at the same time a control is developed to drive all agents' states to reach a consensus vector, which means that this consensus vector must be the solution of .  Algorithms obtained along this direction were first shown to work for non-singular matrix  on fixed undirected networks in \cite{SA13ECC} and then were generalized to handle time-varying networks in \cite{SJA14TAC}.

In contract to the discrete-time algorithm proposed in \cite{SJA14TAC}, this paper proposes a continuous time algorithm and in so doing provides a different perspective on solving a linear equation in a distributed manner.
  The particular update rule for agent 's state is

where with ,  denotes the set of labels of agent 's neighbors' from which agent  receives information,  is the state vector associated with agent , and the particular form of the coefficients  will be given subsequently. Now a feature of the algorithm is that it is, using the language of control theory, a form of {\it{consensus}} algorithm. This means that the different  converge as  to a common value, which will be the solution of the equation . However what is probably the most distingishing feature of this work is its use of a  basic  result  from differential geometry,   which is perhaps not so well known  in control theory, to give a more or less immediate proof  of the paper's main result. In particular we use the fact that a gradient flow algorithm associated with a real analytic function on a real analytic Riemannian
manifold  necessarily converges to a fixed point. This result is
perhaps better known for the case of gradient flow algorithms in Euclidean space, see \cite{Lojasie84};
its more general form on Riemannian manifolds goes back to work of \cite{KTA00Math}.

The structure of the paper is as follows. In the next section, we motivate the form of the differential equations and state the main result.   The following section proves the main result, and Section 4 offers some comments on the convergence rate. Section 5 contains remarks relevant to future research.







\section{Establishing the consensus differential equations}

Our starting point is the algebraic linear equation

in which  is non-singular and . We shall rewrite the equation with  denoting the -th row of  as

 We shall later impose the requirement that  is nonsingular, but for the moment the requirement is not in force.

The second rewriting of equations can be interpreted as stating that  is a member of  different manifolds (here affine subspaces), viz .  Our approach to finding  relies on finding  vectors  each of which belongs for all time to a particular manifold, in that

and so moving the  that they become more and more like each other. If and when they take a common value,  call it , it is obvious that it must satisfy the equation  (whether or not  is invertible).

The basis for adjusting the  involves setting up a cost function which penalizes any differences between them. To this end, consider also a connected graph  with  vertices, and each is associated with an -vector .  Consider also the following cost function:


Clearly  achieves a global minimum of zero if and only if all  have a common value. (Connectivity of the graph is essential to conclude the `only if' statement).

Now let  denote the manifold , and
let . Formally, one can regard 
as the set of vectors  in   obeying  scalar constraints of the form
 (One should think of  as a vector obtained by stacking the ).
The function  is obviously defined on , but it is
also defined on the affine subspace . We observe that  is clearly
  convex. This implies that the restriction  of 
  to   is convex too because the  are affine spaces, which shows a very useful property
  of . In the following proposition, we state two easily established properties linking the cost function to the linear equation.

\begin{prop} Assume that the equation  is
  solvable. \begin{enumerate}
\item[(i)] The restricted cost function  possesses a global minimum . It is
  unique if and only if  has a unique solution.
\item[(ii)] The local
  minima of  coincide with the global minima, and
  these in turn coincide with the set of critical points of
  .
\end{enumerate}
\end{prop}

The second part (ii) in the above Proposition is an immediate consequence of standard properties of smooth
convex functions on vector spaces .





If we were to regard the function  as defined on
 , and sought to compute a gradient flow from an arbitrary initial point in an attempt to reach the minimum, there would result

While this would result in a steady state in which all  had the
same value, they would not be guaranteed to remain on the original
manifold. To remedy this defect, we obtain the gradient of  on the
manifold . The way this is done in the
  optimization literature \cite{UJ94Book,David69}, given that the manifolds
 and therefore the manifold  are embedded in
a Euclidean space, is to simply project the gradient onto the tangent
space of the manifold. Because  , it is not hard to check that this is equivalent to projecting  onto the manifold , Because the manifold  is an affine subspace, the tangent space is the set of vectors  for which .  Now given an arbitrary , its projection onto the tangent space of the manifold  is simply , where  denotes the orthogonal projection matrix to the kernel of  and for non-zero  one has

where  denotes the projection matrix.
More precisely, this means that replacing (\ref{eq:ordinarygrad}), we have for the gradient flow on the manifold 

Of course we also require that the trajectory begins on , i.e. we require

It is easy to check using the differential equation that , which implies the trajectory stays on the manifold.

And now we can state the main result:
\begin{thm}\label{Thm_main}
Consider the linear equation  with  and
. Consider also a connected graph  with  vertices, and let 
denote the neighbor set of vertex . If  is nonsingular, the
equation set (\ref{eq:projgrad}) with the initial condition (\ref{eq:initialcond}) has the property that  for all  as . Moreover, convergence is exponentially fast.  If  for some  and has full row rank, convergence occurs to a solution of .
\end{thm}

The proof of Theorem \ref{Thm_main} will be given later. One might well imagine that in the course of solving the differential equation set, round-off or other errors could move the  of the relevant manifold . This can be accommodated by adding a further term to the equations which restores the trajectory towards the manifold. The equations remain linear in character.

\begin{cor}\label{Cor_1}
Adopt the hypotheses of the theorem, save that (\ref{eq:projgrad}) is replaced by

and let the initial condition now be free. Then the conclusions of the theorem continue to hold.
\end{cor}

The proof of Corollary \ref{Cor_1} will be given in the next section. Further generalization of (\ref{eq:projgrad}) and (\ref{eq:modprojgrad}) can be achieved by introducing scalar positive gain constants (varying with ) in the equations, thus (\ref{eq:modprojgrad}) could be replaced, for arbitrary positive  and , by






\section{Proof of Main Results}

We start this section with the proof of Theorem \ref{Thm_main}. By way of overview, we know from the general theory of
 real analytic gradient flows outlined in \cite{KTA00Math} that convergence must occur to an equilibrium point of the equations, and that because the manifolds  and thus the manifold  are closed, the equilibrium point must lie in  and thus the equilibrium values of the  must lie in each . The equilibrium is necessarily a critical point of . Now Proposition 1 (ii) indicates that the only critical points of  are the global minima of . Under the hypothesis that  is square and nonsingular, or that it is has full row rank, there is an  such that . An equilibrium point of the equations is given by  for all , which means that   assumes the form ). Such a value of  gives rise to , i.e. corresponds to a global minimum. Conversely, at a global minimum, we can argue that   must take the form indicated, and then it follows that . For suppose, in order to obtain a contradiction, that at a global minimum, there held , and  for some pair . Because of the connectedness of the graph , there is a path of edges in  connecting vertex  to vertex . Since , there must hold for some edge, call it , along this path that , and then immediately  is seen to be nonzero since  is one of the summands making up .
Thus  does not attain its global minimum. Hence a necessary and sufficient condition for any equilibrium point to which the equations converge is that consensus is attained, i.e.  for all  and the common value is a solution of .

 We now give a more explicit algebraic derivation of the same conclusion, which will be useful in pinning down the exponential rate of convergence.
Let  denote the Laplacian matrix associated with ; note
that the connectivity property for  implies that  is
nonnegative definite symmetric, with one eigenvalue at the origin, and
the associated eigenspace is the span of ,
  where  denotes the vector with entries all 1. Let 
denote the unit vector in  with 1 in the -th position. Denote the
matrix formed by placing the   next to one another as
 
(This should be distinguished from , which is obtained by stacking the ). At the equilibrium, there holds

This implies that

for some scalars  (which may be zero). In turn, with  , there results

Since  is in the kernel of , there results

and because the vectors  are independent under the theorem hypothesis (whether or not  is square), we have that the  are all zero, that  and therefore the columns of  are identical, i.e. consensus holds.


Exponential convergence follows from the fact that the equations are linear and time-invariant. If convergence occurs, it is necessarily exponential. This completes the proof of Theorem \ref{Thm_main}, and we shall return to the question of the rate of convergence subsequently.

\bigskip


To prove the corollary, we let , where  is a constant vector such that . From  and (\ref{eq:modprojgrad}) one has
  which together with  implies  Thus \eq{\label{eq_error1}\dot e_i=-P_i\sum_{j\in \mathcal N_i}(e_i-e_j)-(I-P_i)e_i, \quad i\in \n}
To write the equations (\ref{eq_error1}) in a more compact form, we let ,  and . One has \eq{\label{eq_error2}\dot e=-(P\bar{L}+I-P)e} Proving that all  converge to  exponentially fast is equivalent to proving that  converges to 0 exponentially fast, for which we need the following lemma:
\begin{lem}\label{Lem_eig} If , all eigenvalues of  are real and positive.
\end{lem}

To prove Lemma \ref{Lem_eig} we need the following lemma about eigenvalues.
\begin{lem}\label{Lem_eigP}
If  and  are square matrices of the same size, then  and  have the same eigenvalues.
\end{lem}
\noindent{\bf Proof of Lemma \ref{Lem_eigP}:} By Sylvester's Determinant Theorem \cite{Syl51}, one has \eq{\det(I-\frac{1}{\lambda}MN)=\det( I-\frac{1}{\lambda}NM)} for . Thus  and  share the same non-zero eigenvalues. Moreover, by , one has if  is an eigenvalue of  or , it must be also the eigenvalue of the other. Thus  and  share the same eigenvalues if they are both square of the same size. 

\noindent{\bf Proof of Lemma \ref{Lem_eig}:} Let us first establish that the eigenvalues of  are identical with those of  (We will then analyse the eigenvalues of the latter matrix) To see this, observe that because , 
Hence the eigenvalues of  are the same as those of  by Lemma \ref{Lem_eigP}. Consequently, the eigenvalues of  are the same as those of . Observe first that  is positive semi-definite since  and  are positive semi-definite. Thus to prove Lemma \ref{Lem_eig}, it is sufficient to establish that  is non-singular. We will prove this in the following by assuming the contrary to obtain a contradiction.


Suppose there is a nonzero  for which . Then clearly

It follows that  and so  for some . Then again from the fact that , we obtain  for all , whence  and thus  is zero. Then  is non-singular. 
\bigskip


The fact that exponentially fast convergence occurs means that if  is varying, the algorithm will still lead to an approximate consensus solution of , with the quality of the approximation linked to the rate of variation of .



\section{Convergence rates}
There is an alternative way of writing the equations (\ref{eq:projgrad}) in the following compact form
 where .
Evidently, when the  are linearly independent, there are  eigenvalues of  at the origin, and the remainder have negative real parts. The rate of exponential convergence of the system (\ref{eq_x0}) to its equilibrium is determined by the smallest non-zero eigenvalue of  which we shall denote by .

Note that  and  have the same eigenvalues because  and  and  have the same eigenvalues. Thus  is real and positive and is equal to the smallest non-zero eigenvalue of . In order to find a bound for , we will study non-zero eigenvalues of .



Let  be a square orthogonal matrix such that the columns  and  form a basis for  and , respectively.
Then  The last equality (\ref{eq_QQ}) comes from  since the columns of  forms a basis for  and .

Thus all non-zero eigenvalues of  are the same as those of the non-singular matrix . From  and the Poincare Separation Theorem \cite{RC85Book}, one has \eq{\label{eq_rho1}\lambda_1(\bar{L})\leq \lambda_1(\bar Q^{\top} \bar L \bar Q)\leq \lambda_{n+1}(\bar L)} where  denote the th smallest eigenvalue of a Hermitian matrix. Since  and  is the Laplacian of a connected graph, one has \eq{\label{eq_rho2}\lambda_1(\bar L)=0,\quad \lambda_{n+1}(\bar L)=\lambda_2(L)}
Recall that  is equal to the smallest non-zero eigenvalue of , which is similar to . Then \eq{\label{eq_rho3}\rho=\lambda_1(\bar{Q}^{\top}\bar{L}\bar{Q})} From (\ref{eq_rho1}) to (\ref{eq_rho3}), one reaches a trivial lower bound for , which is 0, and the following upper bound:
\begin{thm}
The smallest non-zero eigenvalue of  is upper bounded by \eq{ \rho \leq \lambda_2(L)}
\end{thm}
\begin{remark}
 is called the algebraic connectivity of a graph. It is bounded below by \cite{Mohar91} \eq{\label{eq_upL}\lambda_2(L)\geq \frac{4}{nD}} with  the diameter of the graph, and is bounded above by   for  with equality holding if and only if the graph is complete \cite{Fan97}. This further gives an upper bound of  in terms of the number of agents in the network.

From (\ref{eq_upL}) one observes that  could be very small, which suggests  may be close to 0 for certain graphs. Moreover, (\ref{eq_rho3}) implies that  is related to both  and , the latter of which is determined by the matrix . It may be impossible to obtain a non-trivial lower bound for  without assuming more about  beyond non-singularity.
\end{remark}
\section{Conclusions}

There are a number of issues that are related to the ideas of this paper, but remain unexplored. We comment briefly on some of them.

In case the matrix  is tall, in general the equation  cannot be solved, but it does make sense to search for a least squares solution. Theoretically, this could be obtained in the full rank case by working with the linear equation , but any such approach requiring the initial computation of  and  might be contrary to the spirit of seeking a decentralized solution because of  the associated computations.  For example, in distributed parameter estimation \cite{SJK12IT}, a multi-agent network aims to solve a group of observation equations . Because the  are usually contaminated with measurement noise, the whole linear equation  is usually overdetermined.  How then to obtain a least squares solution is for the moment an open problem. An alternative idea to obtain the least square solution in a distributed way was briefly mentioned in \cite{SJA14TAC} by solving a larger linear equation than . However, this idea requires each agent to control an augmented state vector the dimension of which does not scale well with the number of agents in the network. This scaling problem has recently been partially ameliorated in \cite{SAZLD15SCL} by assuming a sparse structure for the linear equations of interest.

It would clearly be relevant to contemplate algorithms in which rows of  were grouped together. The manifolds  would be defined by equations like  where  was a fat matrix. The changes to the algorithm and the associated proof are trivial to contemplate. One issue is what the difference in computational burden might be.

Evidently, the fact that the only requirement on the graph is that it be connected allows the overlaying of a concept like sparseness for each of the equations for , that is the differential equation for  need only have at most one other  feeding into it.  How to exploit sparseness in the matrix  is less clear. Obviously though, inner products involving  are easier to compute when  is sparse.

In the introduction, we noted that a discrete form of the algorithm is available, see \cite{SA13ECC,SJA13Allerton,SJA14TAC}. It should be immediately derivable from the equations presented here. Whether there could be issues of stiffness that would cause problems in discretizing the equations is unknown.

In numerical linear algebra, the difficulty of executing certain calculations is frequently evaluated, and often the formula involves the dimension of the underlying matrices. It is evident here there are tradeoffs possible between convergence rate, storage requirements and complexity requirements in an implementation of a differential equation solver. How all these interact and what sort of comparison can be made with conventional counts for matrix inversion is unknown.

There are several other more significant directions in which this work might be developed. First, one could seek to add linear inequalities or more generally convex inequalities into the problem statement. Reference \cite{AAP10TAC}  can be thought of as  explaining the use of consensus for distributed optimization in discrete time, and its existence is prima facie evidence of the reasonableness of seeking to generalize the ideas of this paper. Second,  in coding theory there are sometimes requirements to solve linear equations with tall matrices whose entries are in a finite field. One might speculate  as to whether a consensus approach could work, and be of benefit, for such problems. Of course, the notion of projection onto manifolds would not be expected to play any role.
Last, we comment that the device of representing the equation to be solved as a consensus problem, and using a series of manifolds as a lens through which to view the problem, is a device that can find application to many control tasks. For example, consider the task of aligning three coordinate frames each in . This is a consensus problem on a sphere, and gradient flow on a sphere is easy to compute. Thus one can readily devise an algorithm to secure the alignment.


\begin{thebibliography}{99}
\bibitem{UJ94Book}  [10.1007/978-1-4471-3467-1]
     \newblock U. Helmke and J. B. Moore,
     \newblock \emph{Optimization and Dynamical Systems},
     \newblock Communications and Control Engineering,  Springer, London, 1994.

\bibitem{O96Cam}
     \newblock O. Axelsson,
     \newblock \emph{Iterative Solution Methods},
     \newblock Cambridge University Press, 1996.

\bibitem{RJ05Cam}
     \newblock R. Mehmood and J. Crowcroft,
     \newblock \emph{Parallel Iterative Solution Method of Large Sparse Linear Equation Systems},
     \newblock Technical Report, University of Cambridge, 2005.

\bibitem{CAnd97Report}
     \newblock C. Anderson,
     \newblock \emph{Solving linear eqauations on parallel distributed memory architectures by extrapolation},
     \newblock Technical Report, Royal Institute of Technology, 1997.

\bibitem{Edelman93}
     \newblock A. Edelman,
     \newblock \emph{Large dense numerical linear algebra in 1993: The Parallel Computing Influence},
     \newblock Technical Report, 1993.


\bibitem{CKJQ13TPD} [10.1109/TPDS.2012.206]
    \newblock C. Wang, K. Ren, J. Wang and Q. Wang, \newblock Harnessing the cloud for securely outsourcing large-scale systems of linear equations,
    \newblock \emph{IEEE Transactions on Parallel and Distributed Systems}, \textbf{24}(6) (2013), 1172--1181.

\bibitem{JAM12TAC} [10.1109/TAC.2011.2161027]
    \newblock J. C. Duchi, A. Agarwal and M. J. Wainwright, \newblock Dual Averaging for Distributed Optimization: Convergence Analysis and Network Scaling,
    \newblock \emph{IEEE Transactions on Automatic Control}, \textbf{57}(3) (2012), 592--606.


\bibitem{AA14TAC} [10.1109/TAC.2014.2364096]
    \newblock A. Nedic and A. Olshevsky, \newblock Distributed Optimization Over Time-Varying Directed Graphs,
    \newblock \emph{IEEE Transactions on Automatic Control}, \textbf{60}(3) (2014), 601--615.

\bibitem{DJJ14TAC} [10.1109/TAC.2014.2298712]
    \newblock D. Jakovetic, J. M. F. Moura and J. Xavier, \newblock Fast Distributed Gradient Methods,
    \newblock \emph{IEEE Transactions on Automatic Control}, \textbf{59}(5) (2014), 1131--1146.

\bibitem{TAA14TAC} [ 10.1109/TAC.2014.2308612]
    \newblock T. Chang, A. Nedic and A. Scaglione, \newblock Distributed constrained optimization by consensus-based primal-dual perturbation method,
    \newblock \emph{IEEE Transactions on Automatic Control}, \textbf{59}(6) (2014), 1524--1538.

\bibitem{SA13ECC}
    \newblock S. Mou and A. S. Morse, \newblock A Fixed-Neighbor,Distributed Algorithm for Solving a Linear Algebraic Equation,
    \newblock \emph{European Control Conference}, (2013), 2269--2273.

\bibitem{SJA13Allerton}
    \newblock S. Mou, J. Liu and A. S. Morse, \newblock A Distributed Algorithm for Solving a Linear Algebraic Equation,
    \newblock \emph{the 51st Annual Allerton Conference on Communication, Control and Computing}, (2013), 267--274.

\bibitem{SJA14TAC} [10.1109/TAC.2015.2414771]
    \newblock S. Mou, J. Liu and A. S. Morse, \newblock A Distributed Algorithm for Solving a Linear Algebraic Equation,
    \newblock \emph{IEEE Transactions on Automatic Control}, (2015).

\bibitem{AAP10TAC} [10.1109/TAC.2010.2041686]
    \newblock A. Nedic, A. Ozdaglar and P. A. Parrilo, \newblock Constrained Consensus and Optimization in Multi-Agent Networks,
    \newblock \emph{IEEE Transactions on Automatic Control}, \textbf{55}(4) (2010), 922--938.

\bibitem{Lojasie84}
    \newblock S. Lojasiewicz, \newblock Sur les trajectoires du gradient dune fonction analytique,
    \newblock \emph{Seminari di Geometria, Universita degli Studi di Bologna}, 1984, 115--117.

\bibitem{KTA00Math} [10.2307/2661354]
    \newblock K. Kurdyka, T. Mostowski and A. Parusinski, \newblock Proof of the gradient conjecture of R. Thom,
    \newblock \emph{Annals of Mathematics}, \textbf{152}(3) (2000), 763--792.

\bibitem{David69}
     \newblock D. G. Luenberger,
     \newblock \emph{Optimization by vector space methods},
     \newblock John Wiley and Sons, 1969.


\bibitem{Syl51} [10.1080/14786445108646735]
    \newblock J. J. Sylvester, \newblock On the relation between the minor determinants of linearly equivalent quadratic functions,
    \newblock \emph{Phylosophical Magazine}, \textbf{1}(4) (1851), 295--305.

\bibitem{RC85Book}
     \newblock R. A. Horn and C. R. Johnson,
     \newblock \emph{Matrix Analysis},
     \newblock Cambridge University Press, 1985.

\bibitem{Mohar91} [10.1.1.96.2577]
    \newblock B. Mohar, \newblock The Laplacian Spectrum of Graphs,
    \newblock \emph{Graph Theory, Combinatorics and Applications}, 1991, 871--898.

\bibitem{Fan97}
     \newblock F. R. K. Chung,
     \newblock \emph{Spectral Graph Theory},
     \newblock American Mathematical Society, 1997.

\bibitem{SJK12IT} [10.1109/TIT.2012.2191450]
    \newblock S. Kar, J. M. F. Moura and K. Ramanan, \newblock Distributed Parameter Estimation in Sensor Networks: Nonlinear Observation Models and Imperfect Communication,
    \newblock \emph{IEEE Transactions on Information Theory}, \textbf{58}(6) (2012), 1--52.

\bibitem{SAZLD15SCL}
    \newblock S. Mou, A. S. Morse, Z. Lin, L. Wang and D. Fullmer, \newblock A Distributed Algorithm for Efficiently Solving Linear Equations and Its Applications,
    \newblock \emph{Systems and Control Letters, Submitted}, 2015.


\end{thebibliography}

\medskip
Received xxxx 20xx; revised xxxx 20xx.
\medskip

\end{document}
