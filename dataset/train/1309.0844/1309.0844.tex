\documentclass{LMCS}

\def\dOi{9(3:23)2013}
\lmcsheading {\dOi}
{1--21}
{}
{}
{Feb.~16, 2012}
{Sep.~18, 2013}
{}

\ACMCCS{[{\bf Theory of computation}]: Logic; Semantics and
  reasoning---Program semantics---Denotational semantics}

\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{amstext}
\usepackage{xspace}
\usepackage{url}
\usepackage{xy}
\xyoption{all}
\usepackage{enumerate,hyperref}

\message{<Paul Taylor's Proof Trees, 2 August 1996>}


\def\introrule{{\cal I}}\def\elimrule{{\cal E}}\def\andintro{\using{\land}\introrule\justifies}\def\impelim{\using{\Rightarrow}\elimrule\justifies}\def\allintro{\using{\forall}\introrule\justifies}\def\allelim{\using{\forall}\elimrule\justifies}\def\falseelim{\using{\bot}\elimrule\justifies}\def\existsintro{\using{\exists}\introrule\justifies}

\def\andelim#1{\using{\land}#1\elimrule\justifies}\def\orintro#1{\using{\lor}#1\introrule\justifies}

\def\impintro#1{\using{\Rightarrow}\introrule_{#1}\justifies}\def\orelim#1{\using{\lor}\elimrule_{#1}\justifies}\def\existselim#1{\using{\exists}\elimrule_{#1}\justifies}



\newdimen\proofrulebreadth \proofrulebreadth=.05em
\newdimen\proofdotseparation \proofdotseparation=1.25ex
\newdimen\proofrulebaseline \proofrulebaseline=2ex
\newcount\proofdotnumber \proofdotnumber=3
\let\then\relax
\def\hfi{\hskip0pt plus.0001fil}
\mathchardef\squigto="3A3B
\newif\ifinsideprooftree\insideprooftreefalse
\newif\ifonleftofproofrule\onleftofproofrulefalse
\newif\ifproofdots\proofdotsfalse
\newif\ifdoubleproof\doubleprooffalse
\let\wereinproofbit\relax
\newdimen\shortenproofleft
\newdimen\shortenproofright
\newdimen\proofbelowshift
\newbox\proofabove
\newbox\proofbelow
\newbox\proofrulename
\def\shiftproofbelow{\let\next\relax\afterassignment\setshiftproofbelow\dimen0 }
\def\shiftproofbelowneg{\def\next{\multiply\dimen0 by-1 }\afterassignment\setshiftproofbelow\dimen0 }
\def\setshiftproofbelow{\next\proofbelowshift=\dimen0 }
\def\setproofrulebreadth{\proofrulebreadth}

\def\prooftree{\ifnum  \lastpenalty=1
\then   \unpenalty
\else   \onleftofproofrulefalse
\fi
\ifonleftofproofrule
\else   \ifinsideprooftree
        \then   \hskip.5em plus1fil
        \fi
\fi
\bgroup \setbox\proofbelow=\hbox{}\setbox\proofrulename=\hbox{}\let\justifies\proofover\let\leadsto\proofoverdots\let\Justifies\proofoverdbl
\let\using\proofusing\let\endprooftree\fi
\proofdotsfalse\doubleprooffalse
\let\thickness\setproofrulebreadth
\let\shiftright\shiftproofbelow \let\shift\shiftproofbelow
\let\shiftleft\shiftproofbelowneg
\let\ifwasinsideprooftree\ifinsideprooftree
\insideprooftreetrue
\setbox\proofabove=\hbox\bgroup\egroup  \shortenproofleft=\dimen0
\shortenproofright=\dimen1
\proofrulebreadth=\dimen2
\proofbelowshift=\dimen3
\proofdotseparation=\dimen4
\proofdotnumber=\count255
}

\def\proofover{\eproofbit \setbox\proofbelow=\hbox\bgroup \let\wereinproofbit\proofover
\displaystyle
}\def\proofoverdots{\eproofbit \proofdotstrue
\setbox\proofbelow=\hbox\bgroup \let\wereinproofbit\proofoverdots

}

\def\endprooftree{\eproofbit \dimen5 =0pt\dimen0=\wd\proofabove \advance\dimen0-\shortenproofleft
\advance\dimen0-\shortenproofright
\dimen1=.5\dimen0 \advance\dimen1-.5\wd\proofbelow
\dimen4=\dimen1
\advance\dimen1\proofbelowshift \advance\dimen4-\proofbelowshift
\ifdim  \dimen1<0pt
\then   \advance\shortenproofleft\dimen1
        \advance\dimen0-\dimen1
        \dimen1=0pt
\ifdim  \shortenproofleft<0pt
        \then   \setbox\proofabove=\hbox{\kern-\shortenproofleft\unhbox\proofabove}\shortenproofleft=0pt
        \fi
\fi
\ifdim  \dimen4<0pt
\then   \advance\shortenproofright\dimen4
        \advance\dimen0-\dimen4
        \dimen4=0pt
\fi
\ifdim  \shortenproofright<\wd\proofrulename
\then   \shortenproofright=\wd\proofrulename
\fi
\dimen2=\shortenproofleft \advance\dimen2 by\dimen1
\dimen3=\shortenproofright\advance\dimen3 by\dimen4
\ifproofdots
\then
        \dimen6=\shortenproofleft \advance\dimen6 .5\dimen0
        \setbox1=\vbox to\proofdotseparation{\vss\hbox{}\vss}\setbox0=\hbox{\advance\dimen6-.5\wd1
                \kern\dimen6
                \unhbox\proofrulename}\else   \dimen6=\fontdimen22\the\textfont2 \dimen7=\dimen6
        \advance\dimen6by.5\proofrulebreadth
        \advance\dimen7by-.5\proofrulebreadth
        \setbox0=\hbox{\kern\shortenproofleft
                \ifdoubleproof
                \then   \hbox to\dimen0{\mkern-2mu=\mkern-2mu}\else   \vrule height\dimen6 depth-\dimen7 width\dimen0
                \fi
                \unhbox\proofrulename}\ht0=\dimen6 \dp0=-\dimen7
\fi
\let\doll\relax
\ifwasinsideprooftree
\then   \let\VBOX\vbox
\else   \ifmmode\else\fi
        \let\VBOX\vcenter
\fi
\VBOX   {\baselineskip\proofrulebaseline \lineskip.2ex
        \expandafter\lineskiplimit\ifproofdots0ex\else-0.6ex\fi
        \hbox   spread\dimen5   {\hfi\unhbox\proofabove\hfi}\hbox{\box0}\hbox   {\kern\dimen2 \box\proofbelow}}\doll \global\dimen2=\dimen2
\global\dimen3=\dimen3
\egroup \ifonleftofproofrule
\then   \shortenproofleft=\dimen2
\fi
\shortenproofright=\dimen3
\onleftofproofrulefalse
\ifinsideprooftree
\then   \hskip.5em plus 1fil \penalty2
\fi
}

 
\newcommand{\pullback}[1][dr]{\save*!/#1-1.2pc/#1:(-1,1)@^{|-}\restore}
\makeatother
 \newdir{ >}{{}*!/-7.5pt/@{>}}
 \newdir{|>}{!/4.5pt/@{|}*:(1,-.2)@^{>}*:(1,+.2)@_{>}}
 \newdir{ |>}{{}*!/-3pt/@{|}*!/-7.5pt/:(1,-.2)@^{>}*!/-7.5pt/:(1,+.2)@_{>}}
\newcommand{\xyline}[2][]{\ensuremath{\smash{\xymatrix@1#1{#2}}}}
\newcommand{\xyinline}[2][]{\ensuremath{\smash{\xymatrix@1#1{#2}}}^{\rule[8.5pt]{0pt}{0pt}}}
\makeatletter

\newif\ifignore \ignorefalse
\newcommand{\auxproof}[1]{
\ifignore\mbox{}\newline
\textbf{PROOF:} \dotfill\newline
{\it #1}\mbox{}\newline
\textbf{ENDPROOF}\dotfill
\fi}

\newtheorem{theorem}{Theorem}
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{proposition}[theorem]{Proposition}
\newtheorem{corollary}[theorem]{Corollary}
\newtheorem{definition}[theorem]{Definition}
\newtheorem{example}[theorem]{Example}
\newtheorem{remark}[theorem]{Remark}
\newtheorem{question}[theorem]{Question}
\newtheorem{conjecture}[theorem]{Conjecture}
\newtheorem{assumption}[theorem]{Assumption}
\newenvironment{myproof}[1][Proof]{ \begin{trivlist}\item[\hskip \labelsep {\bfseries #1}]}{ \end{trivlist}}
\newcommand{\QEDbox}{\square}
\newcommand{\QED}{\hspace*{\fill}}
\newcommand{\QEDhere}{\tag*{}}

\newcommand{\after}{\mathrel{\circ}}
\newcommand{\cat}[1]{\ensuremath{\mathbf{#1}}}
\newcommand{\Cat}[1]{\ensuremath{\mathbf{#1}}}
\newcommand{\op}{\ensuremath{^{\mathrm{op}}}}
\newcommand{\idmap}[1][]{\ensuremath{\mathrm{id}_{#1}}}
\newcommand{\id}[1]{\idmap[#1]}
\newcommand{\support}{\ensuremath{\mathrm{supp}}}
\newcommand{\st}{\ensuremath{\mathsf{st}}}
\newcommand{\dst}{\ensuremath{\mathsf{dst}}}
\newcommand{\dis}{\ensuremath{\mathsf{dis}}}
\newcommand{\Alg}{\textsl{Alg}\xspace}
\newcommand{\CoAlg}{\textsl{CoAlg}\xspace}
\newcommand{\StMnd}{\textsl{StMnd}\xspace}
\newcommand{\Mon}{\textsl{Mon}\xspace}
\newcommand{\CoMon}{\textsl{CoMon}\xspace}
\newcommand{\CCoMon}{\textsl{CCoMon}\xspace}
\newcommand{\Act}{\textsl{Act}\xspace}
\newcommand{\Idl}{\textsl{Idl}\xspace}
\newcommand{\Dwn}{\textsl{Dwn}\xspace}
\newcommand{\Mlt}{\ensuremath{\mathcal{M}}}
\newcommand{\Dstr}{\ensuremath{\mathcal{D}}}
\newcommand{\E}{\ensuremath{\mathcal{E}}}
\newcommand{\NNO}{\ensuremath{\mathbb{N}}}
\newcommand{\scalar}{\mathrel{\bullet}}
\newcommand{\smallotimes}{\mathrel{\scriptstyle\otimes}}
\newcommand{\powerset}{\mathcal{P}}
\newcommand{\Pow}{\powerset}
\newcommand{\nePow}{\powerset^{+}}
\newcommand{\powersetfin}{\mathcal{P}_{\mathit{fin}}}
\newcommand{\powersetnefin}{\mathcal{P}_{\mathit{fin}}^{+}}
\newcommand{\Sets}{\Cat{Sets}\xspace}
\newcommand{\PoSets}{\Cat{PoSets}\xspace}
\newcommand{\MSL}{\Cat{MSL}\xspace}
\newcommand{\Dcpo}{\Cat{Dcpo}\xspace}
\newcommand{\Frm}{\Cat{Frm}\xspace}
\newcommand{\BifMRel}{\Cat{BifMRel}\xspace}
\newcommand{\sotimes}{\mathrel{\raisebox{.05pc}{}}}
\newcommand{\tuple}[1]{\ensuremath{\langle #1 \rangle}}
\newcommand{\set}[2]{\{#1\;|\;#2\}}
\newcommand{\setin}[3]{\{#1\in#2\;|\;#3\}}
\newcommand{\conjun}{\mathrel{\wedge}}
\newcommand{\disjun}{\mathrel{\vee}}
\newcommand{\dirjoin}{\bigvee\nolimits^{\uparrow}}
\newcommand{\all}[2]{\forall{#1}.\,#2}
\newcommand{\allin}[3]{\forall{#1\in#2}.\,#3}
\newcommand{\ex}[2]{\exists{#1}.\,#2}
\newcommand{\exin}[3]{\exists{#1\in#2}.\,#3}
\newcommand{\lamin}[3]{\lambda{#1\in#2}.\,#3}
\newcommand{\lam}[2]{\lambda{#1}.\,#2}
\newcommand{\downset}{\mathop{\downarrow}\!}
\def\ddownset{\mathop{\rlap{}\raisebox{.4ex}{}}}
\newcommand{\upset}{\mathop{\uparrow}\!}
\newcommand{\congrightarrow}{\mathrel{\stackrel{
           \raisebox{.5ex}{}}{
           \raisebox{0ex}[0ex][0ex]{}}}}
\newcommand{\conglongrightarrow}{\mathrel{\stackrel{
           \raisebox{.5ex}{}}{
           \raisebox{0ex}[0ex][0ex]{}}}}


\renewcommand{\arraystretch}{1.3}
\renewcommand{\arraycolsep}{3pt}

\begin{document}

\title{Bases as Coalgebras}
\author[B. Jacobs]{Bart Jacobs}

\address{Institute for Computing and Information Sciences (iCIS), 
Radboud University Nijmegen, The Netherlands.} 
\urladdr{www.cs.ru.nl/B.Jacobs}



\keywords{category, monad, algebra, coalgebra, basis, 
  Kock-Z\"oberlein monad, comonoid, no-cloning}
\subjclass{F.4.1}

\begin{abstract}
The free algebra adjunction, between the category of algebras of a
monad and the underlying category, induces a comonad on the category
of algebras. The coalgebras of this comonad are the topic of study in
this paper (following earlier work).  It is illustrated how such
coalgebras-on-algebras can be understood as bases, decomposing each
element  into primitives elements from which  can be
reconstructed via the operations of the algebra. This holds in
particular for the free vector space monad, but also for other monads,
like powerset or distribution. For instance, continuous dcpos or
stably continuous frames, where each element is the join of the
elements way below it, can be described as such coalgebras. Further,
it is shown how these coalgebras-on-algebras give rise to a comonoid
structure for copy and delete, and thus to diagonalisation of endomaps
like in linear algebra.
\end{abstract}



\maketitle


\section{Introduction}\label{IntroSec}

The concept of basis in mathematics is best known for a vector space.
It involves a way of writing an arbitrary vector  as finite linear
combination , using special base vectors
, which are mutually independent. In the current paper this
phenomenon will be studied at a more general level, using algebras and
coalgebras.  A vector space is an algebra --- to be precise, an
Eilenberg-Moore algebra of a particular monad --- and the
decompositions can be described as a coalgebra . The fact that bases are coalgebras is the main, novel
observation. It applies to other structures than vector spaces, like
directed complete partial orders and convex sets.

In general, algebras are used for composition and coalgebras for
decomposition.  An algebra , for a functor
or a monad , can be used to produce elements in  from
ingredients structured by . Conversely, a coalgebra  allows one to decompose an element in  into its
ingredients with structure according to . This is the fundamental
difference between algebraic and coalgebraic data structures. 

Assume an arbitrary category , carrying a monad , as
in the lower left corner of the next diagram.


\noindent The category  of algebras of the monad  comes
with a standard adjunction . This
adjunction induces a comonad  on , see
Section~\ref{ComonadSec} for details. Then we can form the category
 of coalgebras of the comonad ,
with standard adjunction , inducing a monad  on
. This process can be continued, and gives rise
to an alternating sequence of monads and comonads.

This situation~\eqref{MonadIterDiag} has been studied by various
authors, see
\textit{e.g.}~\cite{Barr69,RoseburghW91,Jacobs94b,Kock95}. One obvious
question is: does the sequence~\eqref{MonadIterDiag} stabilise?
Stabilisation after 2 steps is proven in~\cite{Barr69} for monads on
. Here we prove stabilisation in 3 steps for special monads (of
so-called Kock-Z{\"o}berlein type) on , see below.

But more importantly, here it is proposed that a
-coalgebra on a -algebra can be seen as a
\emph{basis} for this algebra, see Section~\ref{ComonadSec}. In
particular, in Section~\ref{SetSec} it will be shown that the concept
of basis in linear algebra gives rise to such a coalgebra
 for the multiset monad ; this
coalgebra decomposes an element  of a vector space  into a
formal sum  given by its coefficients
 for a Hamel basis , see Theorem~\ref{OperatorCoalgThm}
for more details. In the same vein, the operation that sends an
element of a convex set to a formal convex sum of extreme elements is
an instance of such a coalgebra.

Other examples arise in an order-theoretic setting, see
Section~\ref{OrderSec}.  Here one uses the notion of monad of
Kock-Z{\"o}berlein type --- where ,
see~\cite{Kock95,Escardo98}. We describe how such monads fit in the
present setting (with continuous dcpos as coalgebras), and add a new
result (Theorem~\ref{KZCoAlgBasisThm}) about
algebras-on-coalgebras-on-algebras, see Section~\ref{OrderSec}.  This
builds on rather old (little noticed) work of the
author~\cite{Jacobs94b}.

The first two steps of the sequence~\eqref{MonadIterDiag} are also
relevant in the semantics of effectful programming based on monads.
In~\cite{Levy06} it is shown that the exception monad transformer is a
monad itself---so it can play the role of 
in~(\ref{MonadIterDiag})---and that its algebras provide a syntax for
raising exceptions, whereas the associated coalgebra/basis takes care
of exception handling. These results are intriguing and need to be
tested and investigated further, but that is beyond the scope of this
paper.  We mention them only briefly in Section~\ref{ExceptionSec}.

In recent work~\cite{CoeckePV12} in the categorical foundations of
quantum mechanics it is shown that orthonormal bases in
finite-dimensional Hilbert spaces are equivalent to comonoids
structures (in fact, Frobenius algebras). These como\-noids are used
for copying and deleting elements. In Section~\ref{ComonoidSec} it is
shown how bases as coalgebras (capturing bases-as-decomposition) also
give rise to such comonoids (capturing
bases-as-copier-and-deleter). These comonoids can be used to formulate
in general terms what it means for an endomap to be diagonalised. This
is illustrated for a.o.\ the Pauli functions.



\section{Comonads on categories of algebras}\label{ComonadSec}

In this preliminary section we investigate the situation of a monad
and the induced comonad on its category of algebras. We shall see that
coalgebras of this comonad capture the notion of basis, in a very
general sense. This will be illustrated later in several situations
see in particular Subsection~\ref{VectorSpaceSubsec}.

For an arbitrary monad , with
unit  and multiplication , there is a category  of
(Eilenberg-Moore) algebras, together with a left adjoint  (for free
algebra functor) to the forgetful functor . This adjunction  induces a comonad on the category , which we shall
write as  in:
\vspace*{-1em}


\noindent For an algebra  there are counit  and comultiplication  maps in  given by:




\auxproof{
In general, for an adjunction  the induced comonad  
comes with counit 
inherited from the adjunction and comultiplication  given by .

In this case, starting from the free algebra adjunction 
the unit is the unit of the monad, and the counit , at an algebra, is this algebra itself, as a map of algebras:

}


\begin{defi}
\label{BasisDef}
Consider a monad  together with
the comonad  induced by ,
as in~(\ref{ComonadFromMonadDiag}). A \emph{basis} for a -algebra
 is a
-coalgebra on this algebra, given by a map of
algebras  of the form:


\noindent Thus, a basis  is a map  in
 satisfying  and  and  in:

\end{defi}


\noindent As we shall see a basis as described above may be understood as
providing a decomposition of each element  of an algebra into a
collection  of basic elements that together form .  The
actual basic elements  involved can be
obtained as the indecomposable ones, via the following equaliser in
the underlying category.


\noindent One can then ask in which cases the map of algebras
, induced by the equaliser , is an isomorphism. This is (almost
always) the case for monads on \Sets, see
Proposition~\ref{SetsBasisProp} below. But first we observe that free
algebras always carry a basis.



\begin{lem}
\label{FreeAlgCoalgLem}
Free algebras have a canonical basis: each 
carries a -coalgebra, namely given by . This
gives a situation:

\end{lem}


\begin{myproof}
It is easy to check that  is a morphism in  and
a -coalgebra:


\auxproof{

}
\end{myproof}



\noindent The object  of basic elements, as
in~(\ref{BasisEqualiserDiag}), in the situation of this lemma is the
original set  in case the monad  satisfies the so-called
\emph{equaliser requirement}~\cite{Moggi88}, which says precisely that
 is the equaliser of . This requirement does
\emph{not} hold, for instance, for the powerset monad.



There is some redundancy in the data described in
Definition~\ref{BasisDef}. This is implicitly used in the description
of syntax for exception in~\cite{SchroderM04} (with only `handle' as
coalgebra and no `raise' algebra, see also~\cite{Levy06} and
Section~\ref{ExceptionSec}).


\begin{lem}
Assume a monad , with induced
comonad .
Having:
\begin{iteMize}{}
\item a -algebra  together with a
  -coalgebra 
\end{iteMize}

\noindent is the same as having:
\begin{iteMize}{}
\item a map  in  which forms an
  equaliser diagram in :

\end{iteMize}
\end{lem}


\begin{myproof}
Assuming an algebra and coalgebra  as above, it is easy to check
that  is the equaliser of  and
.

\auxproof{
Recall that , so . If also  satisfies
, then  satisfies:


\noindent Moreover,  is the only such map: if  also satisfies , then .
}

The other direction is a bit more work: assume we have  forming an equaliser of  and . 
Consider the map  defined in the diagram:


\noindent Using the equaliser property one checks that  is a
-algebra, and that  satisfies the
-coalgebra requirements from
Definition~\ref{BasisDef}. \qed

\auxproof{
First we need to check that the map  actually
equalises:


\noindent Further,  is an algebra:


\noindent Obviously, , since . By construction of ,  is a map of algebras . Hence we only need to verify:

}
\end{myproof}


The comonad 
from~(\ref{ComonadFromMonadDiag}) gives rise to a category of
coalgebras , where this
forgetful functor has a right adjoint, which maps an algebra
 to the diagonal coalgebra  as in~(\ref{ComonadFromMonadStructEqn}).  Thus we
obtain a monad on the category , written as
, like in the
sequence~\eqref{MonadIterDiag}. On a basis , for an algebra , there is a
unit  and multiplication
 in
.

\auxproof{ 
Explicitly, for algebras  and  and a basis 
there is a bijective correspondence:


\noindent It is given by:
\begin{iteMize}{}
\item for  take .
It is a map of algebras  since:


\item for  take .
This is both a map of algebras  and of coalgebras
:

\end{iteMize}

\noindent Finally,


In particular, for a -coalgebra  on an algebra  we have unit  in  and counit
 in  of this
adjunction . The induced
monad  thus has multiplication  in a situation:


\noindent using that 
and .
}

By iterating this construction as in~\eqref{MonadIterDiag} one obtains
alternating monads and comonads. Such iterations are studied for
instance in~\cite{Barr69,RoseburghW91,Jacobs94b,Kock95}. In special
cases it is known that the iterations stop after a number of
cycles. This happens after 2 iterations for monads on sets, as we
shall see next, and after 3 iterations for Kock-Z{\"o}berlein monads
in Section~\ref{OrderSec}. This stabilisation means that in presence
of sufficiently many iterated (co)algebraic operations, the algebraic
structure that we start from becomes free --- typically on some atoms
or basic elements.



\section{Set-theoretic examples}\label{SetSec}


It turns out that for monads on the category \Sets only free algebras
have bases. This result goes back to~\cite{Barr69}. We repeat it in
the present context, with a sketch of proof.  Subsequently we describe
the situation for the powerset monad (from~\cite{Jacobs94b}), the
free vector space monad, and the distribution monad.


\begin{prop}
\label{SetsBasisProp}
For a monad  on \Sets, if an algebra
 has a basis
 with non-empty
equaliser  as
in~(\ref{BasisEqualiserDiag}), then the induced map  is an isomorphism of algebras and coalgebras. In
particular, in the set-theoretic case any algebra with a non-empty
basis is free.
\end{prop}


\begin{myproof}
Let's consider the equaliser  of
 from~(\ref{BasisEqualiserDiag}) in
\Sets. It is a so-called coreflexive equaliser, because there is a map
, namely the algebra , satisfying . It is well-known---see
\textit{e.g.}~\cite[Lemma~6.5]{Mesablishvili06} or the dual result
in~\cite[Volume~I, Example~2.10.3.a]{Borceux94}---that if
 such coreflexive equalisers in \Sets are split,
and thus absolute. The latter means that they are preserved under any
functor application. In particular, by applying  we obtain a new
equaliser in \Sets, of the form:


\noindent The resulting map  is the inverse to the adjoint transpose
, since:
\begin{iteMize}{}
\item ;

\item the other equation follows because  is equaliser, and thus
  mono:

\end{iteMize}

\noindent Hence the homomorphism of algebras , from
 to  is an isomorphism. In particular,
 in~(\ref{RestrictedBaseDiag}) is a
map of algebras, as inverse of an isomorphism of algebras. It is not
hard to see that it is also an isomorphism between the coalgebras
 and , as in Lemma~\ref{FreeAlgCoalgLem}. \qed

\auxproof{ 
We include the split equaliser argument in \Sets,
  following~\cite[Lemma~6.5]{Mesablishvili06}.
Consider a diagram:


\noindent It is called a \textit{split equaliser} if there are maps
 and  with


\noindent Such a split equaliser is indeed an equaliser:
\begin{iteMize}{}
\item if  satisfies , then  satisfies: .

\item if also  satisfies ,
then 
\end{iteMize}

\noindent Clearly, split equalisers are preserved under functor
application, and are thus absolute.

Now assume in~ that ,  is mono and satisfies
, and that  form a coreflexive pair, via
 satisfying . Thus we can form the cokernel pair  of  as pushout:


\noindent The first claim is that this induced map  is injective.
We can construct  explicitly as , where  is
the least equivalence relation on  containing the pairs
, for . Thus,
 contains the following elements:
\begin{iteMize}{}
\item , for ;
\item , for ;
\item , for ;
\item , for .
\end{iteMize}

\noindent Reflexivity and symmetry are obvious, by construction.  For
transitivity, assume we have pairs  and ,
where . The composed pair  is then also covered by the abover description,
namely by the first item.

An element  of  is thus of the form:
\begin{iteMize}{}
\item , in which case
, and thus ;
\item , where , and then , and thus ;
\item , where , and then , and thus .
\end{iteMize}

\noindent If , then by applying , we see:
\begin{iteMize}
\item if , then the second
and third cases cannot occur for , so  for some . But then , and
so .

\item if  with , the first case for
   cannot occur; the second case immediatly yields ,
  so we concentrate on the third: if , then
  , and thus . Now we use that  is the
  equaliser of , so that there is an  with .  But
  this is impossible.

\item The case  is handled similarly.
\end{iteMize}

Since  and  is injective (as
equaliser) there is a section  with , making  a split mono. Also, , so that
there is an  with ,
using that  is injective. We know form a map  in:


\noindent By construction, this pair  makes 
a split equaliser.

In a next step  makes  a split equaliser, since  and
.

\medskip

Finally we also check that  is a map of coalgebras, in:


\noindent This is simple:

}
\end{myproof}


\subsection{Complete lattices}\label{CompleteLatticeSubsec}

Consider the powerset monad  on \Sets, with the category
 of complete lattices and join-preserving maps
as its category of algebras.  The induced comonad
 as
in~(\ref{ComonadFromMonadDiag}) sends a complete lattice  to
the lattice  of subsets, ignoring the original
order .  The counit  sends a subset 
to its join ; the comultiplication  sends  to the subset of
singletons .

An (Eilenberg-Moore) coalgebra of the comonad
 on  is a map  in  satisfying
 and . More concretely, this says that  and . It is
shown in~\cite{Jacobs94b} that a complete lattice  carries
such a coalgebra structure  if and only if  is \emph{atomic},
where:


\noindent Thus, such a coalgebra of the comonad
, if it exists, is uniquely determined and
gives a decomposition of lattice elements into the atoms below it. The
atoms in the lattice thus form a basis.

(Recall: the complete lattice  is atomic when each element is the
join of the atoms below it. And an atom  is a non-zero element
with no non-zero elements below it, satisfying: 
implies  for some .)

The equaliser~(\ref{BasisEqualiserDiag}) for the basic elements in
this situation, for an atomic complete lattice , is the set of
atoms: 
 

\noindent If , the induced map  is an isomorphism, by Lemma~\ref{SetsBasisProp}.



\subsection{Vector spaces}\label{VectorSpaceSubsec}

For a semiring  one can define the multiset monad  on
 by . Such an element 
can be identified with a formal finite sum  with
multiplicities  for elements . The unit of
this monad  is given by
singleton multisets: . The multiplication  involves (matrix)
multiplication: , where  is the multiplication of the
semiring .

The category of algebras  of the multiset monad
 is the category of  of modules over :
commutative monoids with -scalar multiplication, see
\textit{e.g.}~\cite{CoumansJ13} for more information. The induced
comonad  from~(\ref{ComonadFromMonadDiag}) sends such a module
 to the free module  of finite
multisets (formal sums) on the underlying set , ignoring the
existing module structure on . The counit and comultiplication are
given by:


\noindent The formal sum (multiset) in the middle is mapped by the
counit  to an actual sum in , namely to its
interpretation.  The comultiplication  maps this formal sum to
a multiset of multisets, with the inner multisets given by singletons
.

The following is a novel observation, motivating the view of
coalgebras on algebras as bases.


\begin{thm}
\label{OperatorCoalgThm}
Let  be a vector space, say over  or .
Coalgebras  correspond to (Hamel)
bases on .
\end{thm}



\begin{myproof}
Suppose we have a basis  for the vector space . Then
we can define a coalgebra  via (finite) formal sums , where  is the -th coefficient of
 wrt\ .  By construction we have
. The equation  holds because , for basic elements
.

Conversely, given a coalgebra  take  as
in~(\ref{BasisEqualiserDiag}). Any finite subset of elements of
 is linearly independent: if ,
for finitely many , then in ,


\noindent Hence , for each . Next, since , each  in 
satisfies , so that . Because
, each element  can be
expressed as sum of such basic elements. \qed
\end{myproof}



A basis for complete lattices in
Subsection~\ref{CompleteLatticeSubsec}, if it exists, is uniquely
determined. In the context of vector spaces bases are unique up to
isomorphism.

Our next example involves convex sets, where extreme points play the
role of base vectors. Via the language of coalgebras we can make the
similarity with vector spaces explicit.


\subsection{Convex sets}\label{ConvexSubsec}

The (discrete probability) distribution monad  on  is
given by .  The unit and multiplication of this monad are as for the
multiset monad , described above.

Algebras of the distribution monad can be identified with ``convex
sets'' (see \textit{e.g.}~\cite{Jacobs10e}), where convex sums exist:
the mapping  sends a formal convex combination
to an actual convex sum. A typical example is the unit interval
. Notice that it does not have arbitrary sums; but convex sums
exist in .  An algebra homomorphism preserves such convex
sums. Such a map is usually called `affine'. We write  for
this category  of convex sets and affine maps.

A point  in a convex set  is called \textit{extreme} if it
does not occur as non-trivial convex combination: if , then  and , for some , and
thus  for . One usually writes  for the subset of extreme points. In a free convex set ,
for a set , the extreme points are the singletons ,
for . Thus .

Now assume we have a coalgebra  for the induced comonad . We form the subset  as in~(\ref{BasisEqualiserDiag}), and claim
, that is, these basic elements in  are
precisely the extreme points.

It is easy to see that there is an inclusion : if  is extreme, and  is a formal sum
, then  equals the actual sum
. But then  and , for
some  --- and  for . Hence .

For the reverse inclusion , assume  satisfies , and , where  and . Since  is an algebra homomorphism,
it preserves convex sums:


\noindent But then , and so  for each .
Hence  is a singleton sum, making  extreme.

We thus see that a -coalgebra  determines a coalgebra , as in~(\ref{RestrictedBaseDiag}), that describes
each element as convex sum of extreme points. As we have seen, this
map  is an isomorphism  describing each convex set with a basis as a
free convex set on its extreme points. This is the essence of the
equivalence of categories .

The situation is reminiscent of the Krein-Milman theorem, which states
that a convex and compact subset  of a locally convex space is
equal to the closed convex hull of its extreme points: , where  is the closure
operation. What we have here is a non-topological version of such a
result.




\section{Order-theoretic examples}\label{OrderSec}


Assume  is a poset-enriched category. This means that all
homsets  are posets, and that pre- and post-composition
are monotone. In this context maps  and
 in opposite direction form an adjunction
 (or Galois connection) if there are inequalities
 and ,
corresponding to unit and counit of the adjunction. In such a
situation the adjoints  determine each other.

A monad  on such a poset-enriched category
 is said to be of \textit{Kock-Z{\"o}berlein type} or just a
\textit{Kock-Z{\"o}berlein monad} if  is monotone and  holds in the homset . This
notion is introduced in~\cite{Kock95} in proper 2-categorical form.
Here we shall use the special `poset' instance---like
in~\cite{Escardo98} where the dual form occurs. The following result
goes back to~\cite{Kock95}; for convenience we include the proof.




\begin{thm}
\label{KZAlgThm}
Let  be a Kock-Z{\"o}berlein monad on a poset-enriched category
. For a map  in  the
following statements are equivalent.
\begin{enumerate}[\em(1)]
\item  is an (Eilenberg-Moore) algebra
of the monad ;

\item  is a left-adjoint-left-inverse of the
  unit ; this means that  is a reflection.
\end{enumerate}
\end{thm}




\begin{myproof}
First assume  is an algebra,
\textit{i.e.}~satisfies  and . It suffices to prove ,
corresponding to the unit of the reflection, since the equation
 is the counit (isomorphism). This is easy, by
naturality: .

In the other direction, assume  is
left-adjoint-left-inverse of the unit ,
so that  and . We
have to prove . In one direction, we
have:


\noindent since , and
thus . For the reverse inequality we
use:

\end{myproof}



In a next step we consider the induced comonad  on the
category  of algebra of a Kock-Z{\"o}berlein monad , as
in~\eqref{MonadIterDiag}. A first, trivial but important, observation
is that the category  is also poset enriched. It is not hard
to see that the comonad  is also of Kock-Z{\"o}berlein
type, in the sense that for each algebra
 we have:


\noindent by~(\ref{KZMuEqn}). Thus one may expect a result similar to
Theorem~\ref{KZAlgThm} for coalgebras of this comonad
. It is formulated in~\cite[Thm.~4.2]{Kock95} (and
attributed to the present author). We repeat the poset version in the
current context.



\begin{thm}
\label{KZCoAlgThm}
Let  be a Kock-Z{\"o}berlein monad on a poset-enriched category
, with induced comonad  on the category of
algebras . Assume an algebra . For
a map , forming a map of algebras in,


\noindent the following statements are equivalent.
\begin{enumerate}[\em(1)]
\item  is an
  (Eilenberg-Moore) coalgebra of the comonad ;

\item  is a
  left-adjoint-right-inverse of the counit ; this means that  is a coreflection.
\end{enumerate}
\end{thm}



\begin{myproof}
Assume  is a -coalgebra, \textit{i.e.}~,  and , like in Definition~\ref{BasisDef}. We have to prove , which is obtained in:


\noindent Conversely, assume a coreflection , so that  and . We have to prove
. In one direction we have , and thus .  In the other direction, we use:
\vspace{3 pt}
\end{myproof}


\noindent One can iterate the  construction, as
in~\eqref{MonadIterDiag}. Below we show that for Kock-Z{\"o}berlein
monads the iteration stops after 3 steps. First we need another
characterisation. The proof is as before.


\begin{lem}
\label{KZAlgCoAlgLem}
Let  be a Kock-Z{\"o}berlein monad on a poset-enriched category
, giving rise to comonad  on 
and monad  on
. Assume:
\begin{iteMize}{}
\item an algebra  in ;
\item a coalgebra  on  in
  ;
\item an algebra  on  in
  , where:
\begin{iteMize}{}
\item  and ,
since  is a -algebra;

\item , since  is a map of algebras
;

\item , since  is a map of
algebras .
\end{iteMize}
\end{iteMize}



\noindent The following statements are then equivalent.
\begin{enumerate}[\em(1)]
\item  is an
  algebra of the monad ;

\item  is a
  left-adjoint-left-inverse of the unit . \qed
\end{enumerate}
\end{lem}


\auxproof{
First assume  is a
-algebra. We have to show that there is a
reflection , \textit{i.e.}~that  and
. The former holds by assumption, and the
latter holds because:


In the other direction, assume  is a map of algebras
 with a reflection . We have
to show that  is a -algebra,
\textit{i.e.}~satisfies  and . Again, the former holds by assumption, and for the
latter we have , since , and thus . For the
reverse inequality we use:

}



The next result shows how such series of adjunctions can arise.


\begin{lem}
\label{KZAlgCoAlgAlgLem}
Assume an algebra  of a Kock-Z{\"o}berlein
monad. The free algebra  then carries multiple (co)reflections
(algebras and coalgebras) in a situation:


\noindent This yields a functor  between categories of
algebras.
\end{lem}


\begin{myproof}
We check all (co)reflections from right to left.
\begin{iteMize}{}
\item In the first case the counit is the identity since ; because  for a Kock-Z{\"o}berlein
  monad, we get a unit . (This follows already from
  Theorem~\ref{KZAlgThm}.)

\item In the next case we have a coreflection 
  since the unit is the identity , and:
  .

\item Finally one gets a reflection  from the
  reflection  from Theorem~\ref{KZAlgThm}:  and . \qed
\end{iteMize}

\auxproof{
To be precise, we also have to check:
\begin{iteMize}{}
\item  is a map of algebras ;
this is obvious.

\item  is a map of coalgebras , and a map of algebras ;
  the latter is trivial, and for the former we use naturality:
  .
\end{iteMize}

Additionally, if  is a map of algebras
 in , then  is a morphsm of algebras  in
. This is obvious.
}
\end{myproof}



\noindent This lemma describes the only form that such structures can have.
This is the main (new) result of this section.



\begin{thm}
\label{KZCoAlgBasisThm}
If we have a reflection-coreflection-reflection chain  on an object , like in
Lemma~\ref{KZAlgCoAlgLem}, then  is a free algebra.

Thus: for a Kock-Z{\"o}berlein monad , the functor  is an equivalence of
categories.
\end{thm}


\begin{myproof}
Assume  on , and consider the
equaliser~(\ref{BasisEqualiserDiag}) in:


\noindent We use the letter `' because the elements in  will
turn out to be compact elements, in the examples later on. The first
thing we note is:


\noindent This follows since  is a mono, and:


Next we observe that the object  carries a -algebra structure
 inherited from , as in:


\noindent It is an algebra indeed, since:


\noindent The other algebra equation is left to the reader.

\auxproof{
First we make explicit what it means for a map  in to be an algebra (on coalgebra  on
algebra ):
\begin{iteMize}{}
\item  and ,
since  is a -algebra;

\item , since  is a map of algebras
;

\item , since  is a map of
algebras .
\end{iteMize}

\noindent Now we use that the equaliser map  is a mono in:

}

Next we show that the transpose  of the equaliser  is
an isomorphism of algebras . The inverse is , since:

We continue to check that the assumed chain of adjunctions  is related to the chain  in~(\ref{KZAlgCoAlgAlgEqn}) via these
isomorphisms. In particular we still need to check that the
following two square commute.


\noindent These square commute since:

We still have to check that the functor  is an equivalence.  In the
reverse direction, given a coalgebra  on , we take the induced
algebra  on the
equaliser~(\ref{KZCoAlgBasisEqual}). Then 
is an isomorphism of -algebras, as we have
    seen.

For the isomorphism in the other direction, assume we start from an
algebra , obtain the
-algebra  described in the chain  in~(\ref{KZAlgCoAlgAlgEqn}),
and then form the equaliser~(\ref{KZCoAlgBasisEqual}); it now looks as
follows.


\noindent This is the equaliser requirement~\cite{Moggi88}, which
holds since  carries an algebra structure. Clearly,  by naturality. And if a map  satisfies , then
 factors through  via , since


\noindent This  is unique with this property, since if  also satisfies , then . \qed
\end{myproof}




In the remainder of this section we review some examples.


\subsection{Dcpos over Posets}\label{DcpoSubsec}

The main example from~\cite{Jacobs94b} involves the ideal monad 
on the category \PoSets of partially ordered sets with monotone
functions between them. In the light of Theorems~\ref{KZAlgThm}
and~\ref{KZCoAlgThm} we briefly review the essentials.

For a poset  let  be the set of directed
downsets in , ordered by inclusion. This  is in fact a monad
on \PoSets with unit  given by principal downset
 and multiplication  by union.  This monad is of Kock-Z{\"o}berlein type since for
 we have:


\auxproof{
For a poset  a subset  is called directed if
it is non-empty and for each pair  there is a  with . The set  contains the downclosed
directed subsets, ordered by inclusion. The mapping  yields a functor : for  one defines .
}

\noindent Applying Theorem~\ref{KZAlgThm} to the ideal monad yields the
(folklore) equivalence of the following points.
\begin{enumerate}[(1)]
\item  is a directed complete partial order (dcpo): each directed
  subset  has a join  in ; 

\item The unit 
  has a left adjoint---which is the join;

\item  carries a (necessarily unique) algebra structure , which is also the join. 
\end{enumerate}

\noindent Additionally, algebra maps are precisely the continuous
functions. Thus we may use as category .

The monad  on  induces a comonad on , written
, with counit  and comultiplication , so that . In order to characterise coalgebras
of this comonad  we need the following. In a dcpo
, the way below relation  is defined as: for ,


\noindent A \emph{continuous poset} is then a dcpo in which for each
element  the set  is
directed and has  as join. These elements way-below  may be seen
as a (local) basis.

\auxproof{
It is easy to see that . Thus  is
anti-symmetric. It is obviously transitive. Further, if  then . We shall make use below of the following
interpolation result, which is a mild generalization of~\cite[VII,
  Lemma 2.4]{Johnstone82}. 


\begin{lem}
\label{InterpolationLem}
For each continuous function  between
continuous posets  one has:

\end{lem}


\begin{myproof}
Given , consider the subset  which is directed and has  as
supremum. Thus, if , then , for some
. But then  for some . Hence  and . \qed

\auxproof{
We check that  is directed: if , say  for , then, because  is continuous, there is
a  with . Then  and thus
. Since  is also continuous there is an 
with  and . Hence .

Then:

}

\end{myproof}
}


The following equivalence formed the basis for~\cite[Thm.~4.2]{Kock95}
(of which Theorem~\ref{KZCoAlgThm} is a special case).  The
equivalence of points~(1) and~(2) is known from the literature, see
e.g.~\cite[VII, Proposition~2.1]{Johnstone82},
\cite[Proposition~2.3]{Hoffmann79},
or~\cite[Theorem~I-1.10]{GierzHKLMS03}. The equivalence of points~(2)
and~(3) is given by Theorem~\ref{KZCoAlgThm}.

For a dcpo , the following statements are equivalent.
\begin{enumerate}[(1)]
\item  is a continuous poset;

\item The counit  of the comonad
   on \Dcpo has a left adjoint (in \Dcpo); it is
  .

\item  carries a (necessarily unique) -coalgebra
  structure , which is also
  . 
\end{enumerate}





\auxproof{
We shall prove the equivalence of the first two points. In one
direction, if  is a continuous dcpo, then  is a continuous function: for a directed subset
 one has:


\noindent The implication  is
obvious; for , assume ; then by interpolation (Lemma~\ref{InterpolationLem}, with
), there is a  with . But then
 for some  and thus . Next we have to
prove the adjoint correspondence:


\noindent where . For the downward direction, if
, then . Upwards: if  and , then 
and so  for some . But then  since  is a
downset.

Now assume the existence of a left adjoint  in \Dcpo.
Hence  is a continuous function  with
, for
. We then have , since in one
direction,  yields . And
conversely, from  we get , and so .

It thus suffices to prove .
\begin{iteMize}{}
\item[()] Let . In order to show ,
  assume  for  directed. Then  with . Since
  , the adjunction  yields . Hence ,
  which gives a  with .

\item[()] If , then  for
some . But then , because the latter is
a downset. \qed
\end{iteMize}
}







\auxproof{
A map  in  is an
-coalgebra map if and only if for each ,



\noindent First assume  is such a coalgebra map.  If , then
, being in the set on the right, is also in the set on the
left. Thus , and  is monotone.

In the reverse direction, assume  is monotone with respect to
. We show that the above equation holds.
1mm]
& \Longrightarrow &
\ex{z}{y \ll f(z) \mbox{ and } z\ll x} \quad\mbox{by interpolation}
   \quad\quad \1mm]
& \Longrightarrow &
y\in\downset\set{f(z)}{z\in\ddownset x} \1mm]
& \Longrightarrow &
\ex{z}{y \leq f(z) \mbox{ and } f(z)\ll f(x)}  
     \quad\rlap{since  is monotone}\1mm]
& \Longrightarrow &
y\in\ddownset f(x). 
\end{array}\eqno{\qEd}\begin{array}{rcl}
\Dwn(X)
& = &
\set{U\subseteq X}{U \mbox{ is downclosed}}
\end{array}\begin{array}{rcl}
(\bigvee U) \conjun (\bigvee V)
& = &
\bigvee\set{(\bigvee U)\conjun y}{y\in V} \\
& = &
\bigvee\set{\bigvee\set{x\conjun y}{x\in U}}{y\in V} \\
& = &
\bigvee(U\cap V),
\end{array}\begin{prooftree}
\bigvee U \;\leq\; x
\Justifies
U \;\subseteq\; \downset x
\end{prooftree}\begin{array}{rcl}
\big(\bigvee \after \downset\big)(x)
& = &
\bigvee\downset x \\
& = &
x \\
\big(\bigvee \after \Dwn(\bigvee)\big)(A)
& = &
\bigvee\downset\set{\bigvee U}{U\in A} \\
& \smash{\stackrel{(*)}{=}} &
\bigvee\bigcup A \\
& = &
\big(\bigvee \after \bigcup\big)(A),
\end{array}\begin{array}{rcl}
a(U) \conjun y
& = &
a(U) \conjun a(\downset y) \\
& = &
a(U \cap \downset y) \\
& = &
a(\set{x\conjun y}{x\in U}),
\end{array}\begin{array}{rcl}
U \cap \downset y
& = &
\set{x\conjun y}{x\in U}
\end{array}\xymatrix@C-1pc{
& \Alg(\E)\ar@(ul,ur)^-{\overline{\E}=FU}\ar[dl]_{\dashv}\ar@/^3.5ex/[dr]
& \\
\StMnd(\cat{A})\ar@(dl,dr)[]_-{\E}\ar@/^3.5ex/[ur]^{F}
   & & \CoAlg\rlap{}\ar[ul]_{\dashv}
}\hspace*{-5em}\begin{prooftree}
{\xymatrix{ \llap{}T(E+-)\ar@{=>}[r]^-{\sigma} & T 
   \rlap{\quad\small map of monads, as -algebra}}}
\Justifies
{\xymatrix{ E\ar[r]_-{r} & T(0)}}
\end{prooftree}\xymatrix{
\widehat{\sigma} = \Big(E\ar[r]^-{\eta} & 
   T(E)\ar[r]^-{T(\kappa_{1})}_-{\cong} & T(E+0)\ar[r]^-{\sigma_0} & 
   T(0)\Big).
}\xymatrix{
\widehat{r}_{X} = \Big(T(E+X)\ar[rr]^-{T([T(!)\after r,\eta])} & &
   T^{2}(X)\ar[r]^-{\mu} & T(X)\Big).
}\xymatrix@R-1.5pc{
\eta^{\E(T)} = \Big(X\ar[r]^-{\eta} & T(X)\ar[r]^-{T(\kappa_{2})} &
   T(E+X)\Big) \\
\mu^{\E(T)} = \Big(T(E + T(E + X))
   \ar[rr]^-{T([T(\kappa_{1})\after\eta, \idmap])}
   & & T^{2}(E+X)\ar[r]^-{\mu} & T(E+X)\Big)
}\begin{array}{rcl}
\big(\mu^{\E(T)}_{X} \after \eta^{\E(T)}_{T(E+X)}\big)
& = &
\mu \after T([T(\kappa_{1})\after\eta, \idmap]) \after T(\kappa_{2})
   \after \eta \\
& = &
\mu \after T(\idmap) \after \eta \\
& = &
\idmap \\
\big(\mu^{\E(T)}_{X} \after T(E+\eta^{\E(T)}_{X})\big)
& = &
\mu \after T([T(\kappa_{1})\after\eta, \idmap]) \after 
   T([\kappa_{1}, \kappa_{2} \after T(\kappa_{2}) \after \eta]) \\
& = &
\mu \after T([T(\kappa_{1})\after\eta, T(\kappa_{2}) \after \eta]) \\
& = &
\mu \after T([\eta \after \kappa_{1}, \eta \after \kappa_{2}]) \\
& = &
\mu \after T(\eta) \after T([\kappa_{1}, \kappa_{2}]) \\
& = &
\idmap \after T(\idmap) \\
& = &
\idmap \\
\big(\mu^{\E(T)}_{X} \after T(E+\mu^{\E(T)}_{X})\big) 
& = &
\mu \after T([T(\kappa_{1})\after\eta, \idmap]) \after 
   T([\kappa_{1}, \kappa_{2} \after \mu \after 
      T([T(\kappa_{1})\after\eta, \idmap])]) \\
& = &
\mu \after T([T(\kappa_{1})\after\eta, \mu \after 
      T([T(\kappa_{1})\after\eta, \idmap])]) \\
& = &
\mu \after T([\mu \after \eta \after T(\kappa_{1})\after\eta, 
   \mu \after T([T(\kappa_{1})\after\eta, \idmap])]) \\
& = &
\mu \after T(\mu) \after T([T(T(\kappa_{1})\after\eta) \after \eta, 
   T([T(\kappa_{1})\after\eta, \idmap])]) \\
& = &
\mu \after \mu \after T^{2}([T(\kappa_{1})\after\eta, \idmap]) \after
   T([T(\kappa_{1})\after\eta, \idmap]) \\
& = &
\mu \after T([T(\kappa_{1})\after\eta, \idmap]) \after
   \mu \after T([T(\kappa_{1})\after\eta, \idmap]) \\
& = &
\big(\mu^{\E(T)}_{X} \after \mu^{\E(T)}_{T(E+X)}\big)
\end{array}\xymatrix@C-1pc{
T(E+X)\times Y\ar[r]^-{\st} &
   T((E+X)\times Y)\ar[r]^-{T(\dis)}_-{\cong} & 
   T((E\times Y)+(X\times Y))\ar[rr]^-{T(\pi_{1}+\idmap)} & &
   T(E+(X\times Y)
}\begin{array}{rcl}
\lefteqn{\E(T)(f\times g) \after \st^{\E(T)}} \\
& = &
T(\idmap+(f\times g)) \after
   T(\pi_{1}+\idmap) \after T(\dis) \after \st \\
& = &
T(\pi_{1}+(f\times g)) \after T(\dis) \after \st \\
& = &
T(\pi_{1}+\idmap) \after 
   T((\idmap\times g)+(f\times g)) \after T(\dis) \after \st \\
& = &
T(\pi_{1}+\idmap) \after T(\dis) \after 
   T((\idmap+f)\times g) \after \st \\
& = &
T(\pi_{1}+\idmap) \after T(\dis) \after \st \after
   (T(\idmap+f)\times g) \\
& = &
\st^{\E(T)} \after (\E(T)(f)\times g) \\
\lefteqn{\E(T)(\pi_{1}) \after \st^{\E(T)}} \\
& = &
T(\idmap+\pi_{1}) \after T(\pi_{1}+\idmap) \after T(\dis) \after \st \\
& = &
T(\pi_{1}+\pi_{1}) \after T(\dis) \after \st \\
& = &
T(\pi_{1}) \after \st \\
& = &
\pi_{1} \\
\lefteqn{\E(T)(\alpha^{-1}) \after \st^{\E(T)} \after 
   (\st^{\E(T)}\times\idmap)} \\
& = &
T(\idmap+\alpha^{-1}) \after T(\pi_{1}+\idmap) \after T(\dis) \after \st 
   \after 
   \big((T(\pi_{1}+\idmap) \after T(\dis) \after \st)\times\idmap\big) \\
& = &
T(\pi_{1}+\alpha^{-1}) \after T(\dis) \after 
   T((\pi_{1}+\idmap)\times\idmap) \after T(\dis\times\idmap) \after
   \st \after (\st\times\idmap) \\
& = &
T(\pi_{1}+\alpha^{-1}) \after T((\pi_{1}\times\idmap)+(\idmap\times\idmap))
   \after T(\dis) \after T(\dis\times\idmap) \after
   \st \after (\st\times\idmap) \\
& = &
T((\pi_{1}\after\pi_{1})+\alpha^{-1}) 
   \after T(\dis) \after T(\dis\times\idmap) \after
   \st \after (\st\times\idmap) \\
& = &
T(\pi_{1}+\idmap) \after T(\alpha^{-1}+\alpha^{-1}) 
   \after T(\dis) \after T(\dis\times\idmap) \after
   \st \after (\st\times\idmap) \\
& = &
T(\pi_{1}+\idmap) \after T(\dis) \after T(\alpha^{-1}) \after 
  \st \after (\st\times\idmap) \\
& = &
T(\pi_{1}+\idmap) \after T(\dis) \after \st \after \alpha^{-1} \\
& = &
\st^{\E(T)} \after \alpha^{-1}.
\end{array}\begin{array}{rcl}
\lefteqn{\st^{\E(T)} \after (\eta^{\E(T)}\times\idmap)} \\
& = &
T(\pi_{1}+\idmap) \after T(\dis) \after \st \after 
   \big((T(\kappa_{2})\after \eta)\times\idmap\big) \\
& = &
T(\pi_{1}+\idmap) \after T(\dis) \after T(\kappa_{2}\times\idmap) \after
   \st \after (\eta\times\idmap) \\
& = &
T(\pi_{1}+\idmap) \after T(\kappa_{2}) \after \eta \\
& = &
T(\kappa_{2}) \after \eta \\
& = &
\eta^{\E(T)} \\
\lefteqn{\st^{\E(T)} \after (\mu^{\E(T)}\times\idmap)} \\
& = &
T(\pi_{1}+\idmap) \after T(\dis) \after \st \after 
   ((\mu \after T([T(\kappa_{1})\after\eta, \idmap]))\times\idmap) \\
& = &
T(\pi_{1}+\idmap) \after T(\dis) \after \mu \after  T(\st) \after \st
   \after (T([T(\kappa_{1})\after\eta, \idmap])\times\idmap) \\
& = &
\mu \after T^{2}(\pi_{1}+\idmap) \after T^{2}(\dis) \after T(\st) 
   \after T([T(\kappa_{1})\after\eta, \idmap]\times\idmap) \after \st \\
& = &
\mu \after T^{2}(\pi_{1}+\idmap) \after T^{2}(\dis) \after T(\st) 
   \after T(\nabla\times\idmap) \after
   T((T(\kappa_{1})\after\eta) + \idmap)\times\idmap) \after \st \\
& = &
\mu \after T^{2}(\pi_{1}+\idmap) \after T^{2}(\dis) \after T(\st) 
   \after T(\nabla) \after T(\dis) \after 
   T((T(\kappa_{1})\after\eta) + \idmap)\times\idmap) \after \st \\
& = &
\mu \after T^{2}(\pi_{1}+\idmap) \after T^{2}(\dis) \after T(\st) 
   \after T(\nabla) \after 
   T(((T(\kappa_{1})\after\eta)\times\idmap) + (\idmap\times\idmap))
   \after T(\dis) \after \st \\
& = &
\mu \after T^{2}(\pi_{1}+\idmap) \after T^{2}(\dis) \after T(\st) 
   \after T([(T(\kappa_{1})\after\eta)\times\idmap, \idmap])
   \after T(\dis) \after \st \\
& = &
\mu \after T([T(\pi_{1}+\idmap) \after T(\dis) \after \st
   \after (T(\kappa_{1})\times\idmap) \after (\eta\times\idmap), 
   T(\pi_{1}+\idmap) \after T(\dis) \after \st])
   \after T(\dis) \after \st \\
& = &
\mu \after T([T(\pi_{1}+\idmap) \after 
   T(\dis \after (\kappa_{1}\times\idmap)) \after \st
   \after (\eta\times\idmap), 
   T(\pi_{1}+\idmap) \after T(\dis) \after \st])
   \after T(\dis) \after \st \\
& = &
\mu \after T([T(\pi_{1}+\idmap) \after T(\kappa_{1}) \after \eta,
   T(\pi_{1}+\idmap) \after T(\dis) \after \st])
   \after T(\dis) \after \st \\
& = &
\mu \after T([T(\kappa_{1} \after \pi_{1}) \after \eta,
   T(\pi_{1}+\idmap) \after T(\dis) \after \st])
   \after T(\dis) \after \st \\
& = &
\mu \after T([T(\kappa_{1})\after\eta \after \pi_{1},
   T(\pi_{1}+\idmap) \after T(\dis) \after \st]) \after 
   T(\dis) \after \st \\
& = &
\mu \after T([T(\kappa_{1})\after\eta, \idmap]) \after 
   T(\pi_{1}+(T(\pi_{1}+\idmap) \after T(\dis) \after \st)) \after 
   T(\dis) \after \st \\
& = &
\mu \after T([T(\kappa_{1})\after\eta, \idmap]) \after 
   T(\idmap+(T(\pi_{1}+\idmap) \after T(\dis) \after \st)) \after 
   T(\pi_{1}+\idmap) \after T(\dis) \after \st \\
& = &
\mu^{\E(T)} \after T(E+\st^{\E(T)}) \after 
\st^{\E(T)}.
\end{array}\begin{array}{rcl}
\E(\sigma)_{X}
& = &
\sigma_{E+X} \colon T(E+X) \longrightarrow S(E+X).
\end{array}\begin{array}{rcl}
\E(\sigma) \after \eta^{\E(T)}
& = &
\sigma \after T(\kappa_{2}) \after \eta \\
& = &
S(\kappa_{2}) \after \sigma \after \eta \\
& = &
S(\kappa_{2}) \after \eta \\
& = &
\eta^{\E(S)} \\
\E(\sigma) \after \mu^{\E(T)}
& = &
\sigma \after \mu \after T([T(\kappa_{1})\after\eta, \idmap]) \\
& = &
\mu \after \sigma \after T(\sigma) \after 
   T([T(\kappa_{1})\after\eta, \idmap]) \\
& = &
\mu \after \sigma \after 
   T([\sigma \after T(\kappa_{1})\after\eta, \sigma]) \\
& = &
\mu \after S([S(\kappa_{1})\after \sigma \after\eta, \sigma]) 
   \after \sigma \\
& = &
\mu \after S([S(\kappa_{1})\after \eta, \sigma]) 
   \after \sigma \\
& = &
\mu \after S([S(\kappa_{1})\after\eta, \idmap]) 
   \after S(\idmap+\sigma) \after \sigma \\
& = &
\mu \after S([S(\kappa_{1})\after\eta, \idmap]) \after \sigma
   \after T(\idmap+\sigma) \\
& = &
\mu^{\E(S)} \after \E(\sigma) \after 
   \E(T)(\E(\sigma)) \\
\st^{\E(T)} \after (\E(\sigma)\times\idmap) 
& = &
T(\pi_{1}+\idmap) \after T(\dis) \after \st \after (\sigma\times\idmap) \\
& = &
T(\pi_{1}+\idmap) \after T(\dis) \after \sigma \after \st \\
& = &
\sigma \after S(\pi_{1}+\idmap) \after S(\dis) \after \st \\
& = &
\E(\sigma) \after \st^{\E(S)}.
\end{array}\begin{array}{rcl}
\eta^{\E}_{T,X}
& = &
T(\kappa_{2}) \colon T(X) \longrightarrow T(E+X).
\end{array}\begin{array}{rcl}
\E(\sigma) \after \eta^{\E}_{T} 
& = &
\sigma \after T(\kappa_{2}) \\
& = &
S(\kappa_{2}) \after \sigma \\
& = &
\eta^{\E}_{S} \after \sigma.
\end{array}\begin{array}{rcl}
\eta^{\E} \after \eta
& = &
T(\kappa_{2}) \after \eta \\
& = &
\eta^{\E(T)} \\
\mu^{\E(T)} \after \eta^{\E} \after T(\eta^{\E})
& = &
\mu \after T([T(\kappa_{1})\after\eta, \idmap]) \after T(\kappa_{2})
   \after T^{2}(\kappa_{2}) \\
& = &
\mu \after T^{2}(\kappa_{2}) \\
& = &
T(\kappa_{2}) \after \mu \\
& = &
\eta^{\E} \after \mu \\
\st^{\E(T)} \after (\eta^{\E}\times\idmap) 
& = &
T(\pi_{1}+\idmap) \after T(\dis) \after \st \after 
   (T(\kappa_{2})\times\idmap) \\
& = &
T(\pi_{1}+\idmap) \after T(\dis) \after T(\kappa_{2}\times\idmap) 
  \after \st \\
& = &
T(\pi_{1}+\idmap) \after T(\kappa_{2}) \after \st \\
& = &
T(\kappa_{2}) \after \st \\
& = &
\eta^{\E} \after \st
\end{array}\begin{array}{rcl}
\mu^{\E}_{T,X} 
& = &
T([\kappa_{1},\idmap])\colon T(E + (E+X)) \longrightarrow T(E+X)
\end{array}\begin{array}{rcl}
\mu^{\E} \after \E^{2}(\sigma)
& = &
T([\kappa_{1},\idmap]) \after \sigma \\
& = &
\sigma \after S([\kappa_{1},\idmap]) \\
& = &
\E(\sigma) \after \mu^{\E}.
\end{array}\begin{array}{rcl}
\mu^{\E} \after \eta^{\E^{2}(T)}
& = &
T([\kappa_{1},\idmap]) \after \E(T)(\kappa_{2}) \after
   \eta^{\E(T)} \\
& = &
T([\kappa_{1},\idmap]) \after T(\idmap+\kappa_{2}) \after
   T(\kappa_{2}) \after \eta \\
& = &
T([\kappa_{1},\kappa_{2}]) \after T(\kappa_{2}) \after \eta \\
& = &
T(\kappa_{2}) \after \eta \\
& = &
\eta^{\E(T)}.
\end{array}\xymatrix@R-1.5pc@C+1pc{
T(E+T(E+-)) = \E(T)^{2}\ar@{=>}[r]^-{\mu^{\E(T)}} &
   \E(T) \\
T(E+(E+-)) = \E^{2}(T)\ar@{=>}[r]^-{\mu^{\E}_{T}} &
   \E(T) \\
}\xymatrix@C+1pc{
\E^{2}(T)\E^{2}(T)\ar[d]_{\mu^{\E^{2}(T)}}
      \ar[r]^-{\mu^{\E}_{\E^{2}(T)}} & 
   \E(T)\E^{2}(T)
      \ar[r]^-{\E(T)\mu^{\E}_{T}} & 
   \E(T)\E(T)\ar[d]^{\mu^{\E(T)}} \\
\E^{2}(T)\ar[rr]_-{\mu^{\E}_{T}} & & \E(T)
}\xymatrix@R-1.5pc{
\E^{2}(T)\E^{2}(T)(X)\ar@{=}[d]
   \ar[rr]^-{\E(T)([\E(T)(\kappa_{1}) \after
       \eta^{\E(T)}_{E},\idmap])} & &
   \E(T)^{2}(E+X)\ar@{=}[d]\ar[r]^-{\mu^{\E(T)}_{E+X}} &
   \E^{2}(T)(X)\ar@{=}[d] \\
T(E+(E+T(E+(E+X))))\ar@/_4ex/[rr]_-{T(\idmap+([T(\idmap+\kappa_{1}) 
   \after T(\kappa_{1}) \after \eta_{E}, \idmap]))} & &
   T(E+T(E+(E+X)))\ar@/_4ex/[dr]_-{\mu \after 
       T([T(\kappa_{1})\after\eta,\idmap])}  & 
   T(E+(E+X))\ar@{=}[d] \\
& & & \E(T)(E+X)
}\begin{array}{rcl}
\lefteqn{\mu^{\E(T)} \after \E(T)\mu^{\E}_{T} 
   \after \mu^{\E}_{\E^{2}(T)}} \\
& = &
\mu \after T([T(\kappa_{1})\after\eta, \idmap]) \after
   T(\idmap+T([\kappa_{1},\idmap])) \after T([\kappa_{1},\idmap]) \\
& = &
\mu \after T([T(\kappa_{1})\after\eta, T([\kappa_{1},\idmap])]) 
   \after T([\kappa_{1},\idmap]) \\
& = &
\mu \after T([T(\kappa_{1})\after\eta, 
   [T(\kappa_{1}) \after \eta, T([\kappa_{1},\idmap])]]) \\
& = &
\mu \after T^{2}([\kappa_{1},\idmap]) \after 
   T([T(\kappa_{1})\after\eta, [T(\kappa_{1}) \after \eta, \idmap]]) \\
& = &
\mu \after T^{2}([\kappa_{1},\idmap]) \after 
   T([T(\kappa_{1})\after\eta,\idmap]) \after
   T(\idmap+([T(\kappa_{1}) \after \eta, \idmap])) \\
& = &
T([\kappa_{1},\idmap]) \after \mu \after 
   T([T(\kappa_{1})\after\eta,\idmap]) \after
   T(\idmap+([T(\idmap+\kappa_{1}) \after T(\kappa_{1}) \after 
   \eta, \idmap])) \\
& = &
\mu^{\E} \after \mu^{\E^{2}(T)}
\end{array}\begin{prooftree}
{\xymatrix{ \llap{}\E(T)\ar@{=>}[r]^-{\sigma} & T
   \rlap{\quad algebra}}}
\Justifies
{\xymatrix{ E \ar[r]_-{r} & T(0) }}
\end{prooftree}\xymatrix{
\overline{\sigma} = \Big(E\ar[r]^{\eta} & 
   T(E)\ar[r]^-{T(\kappa_{1})}_-{\cong} & T(E+0)\ar[r]^-{\sigma_0} & 
   T(0)\Big).
}\xymatrix{
\overline{r}_{X} = \Big(T(E+X)\ar[rr]^-{T([T(!)\after r,\eta])} & &
   T^{2}(X)\ar[r]^-{\mu} & T(X)\Big).
}\begin{array}{rcl}
\overline{r}_{Y} \after \E(T)(f)
& = &
\mu \after T([T(!)\after r,\eta]) \after T(\idmap+f) \\
& = &
\mu \after T([T(!)\after r,\eta \after f]) \\
& = &
\mu \after T([T(f) \after T(!)\after r, T(f) \after \eta]) \\
& = &
\mu \after T^{2}(f) \after T([T(!)\after r, \eta]) \\
& = &
T(f) \after \mu \after T([T(!)\after r, \eta]) \\
& = &
T(f) \after \overline{r}_{X}
\end{array}\begin{array}{rcl}
\overline{r} \after \eta^{\E(T)}
& = &
\mu \after T([T(!)\after r,\eta]) \after T(\kappa_{2}) \after \eta \\
& = &
\mu \after T(\eta) \after \eta \\
& = &
\eta \\
\overline{r} \after \mu^{\E(T)}
& = &
\mu \after T([T(!)\after r,\eta]) \after \mu \after
   T([T(\kappa_{1}) \after \eta, \idmap]) \\
& = &
\mu \after \mu \after T^{2}([T(!)\after r,\eta]) \after 
   T([T(\kappa_{1}) \after \eta, \idmap]) \\
& = &
\mu \after T(\mu) \after 
   T([T(T(!)\after r) \after \eta, T([T(!)\after r,\eta])]) \\
& = &
\mu \after T([\mu \after T^{2}(!)\after T(r) \after \eta, 
   \mu \after T([T(!)\after r,\eta])]) \\
& = &
\mu \after T([T(!)\after \mu \after \eta \after r, 
   \mu \after T([T(!)\after r,\eta])]) \\
& = &
\mu \after T([\mu \after T(\eta \after\, !)\after r, 
   \mu \after T([T(!)\after r,\eta])]) \\
& = &
\mu \after T(\mu) \after 
   T([T(!)\after r, T([T(!)\after r,\eta])]) \\
& = &
\mu \after \mu \after T^{2}([T(!)\after r,\eta]) \after 
   T([T(!)\after r, \idmap]) \\
& = &
\mu \after T([T(!)\after r,\eta]) \after \mu \after 
   T([T(!)\after r, \idmap]) \\
& = &
\mu \after T([T(!)\after r,\eta]) \after \mu \after 
   T(\mu) \after T([T(\eta \after !)\after r,\eta]) \\
& = &
\mu \after T([T(!)\after r,\eta]) \after \mu \after 
   \mu \after T([T(!)\after r,\eta]) \\
& = &
\mu \after \mu \after T^{2}([T(!)\after r,\eta]) \after 
   \mu \after T([T(!)\after r,\eta]) \\
& = &
\mu \after T(\mu \after T([T(!)\after r,\eta])) \after 
   \mu \after T([T(!)\after r,\eta]) \\
& = &
\mu \after T(\overline{r}) \after \overline{r} \\
\st \after (\overline{r}\times\idmap)
& = &
\st \after ((\mu \after T([T(!)\after r,\eta]))\times\idmap) \\
& = &
\mu \after T(\st) \after \st \after (T([T(!)\after r,\eta])\times\idmap) \\
& = &
\mu \after T(\st) \after T([T(!)\after r,\eta]\times\idmap) \after \st \\
& = &
\mu \after T(\st) \after T(\nabla\times\idmap) \after 
    T(((T(!)\after r) + \eta)\times\idmap) \after \st \\
& = &
\mu \after T(\st) \after T(\nabla) \after T(\dis) \after 
    T(((T(!)\after r) + \eta)\times\idmap) \after \st \\
& = &
\mu \after T(\st) \after T(\nabla) \after 
    T(((T(!)\after r)\times\idmap) + (\eta\times\idmap))
   \after T(\dis) \after \st \\
& = &
\mu \after T([\st \after (T(!)\times\idmap) \after (r\times\idmap),
   \st \after (\eta\times\idmap)]) \after T(\dis) \after \st \\
& \smash{\stackrel{(*)}{=}} &
\mu \after T([T(!) \after \pi_{1} \after (r\times\idmap),
   \st \after (\eta\times\idmap)]) \after T(\dis) \after \st \\
& = &
\mu \after T([T(!)\after r \after \pi_{1},\eta]) \after
   T(\dis) \after \st \\
& = &
\mu \after T([T(!)\after r,\eta]) \after T(\pi_{1}+\idmap) \after
   T(\dis) \after \st \\
& = &
\overline{r} \after \st^{\E(T)}.
\end{array}\xymatrix{
& T(0)\times Y\ar[d]_{\idmap\times\,!}\ar@/_4ex/[ddl]_{\pi_1}\ar[dr]^{\st}
      \ar[rrr]^-{T(!)\times\idmap} & & & T(X)\times Y\ar[d]^{\st} \\
& T(0)\times 1\ar[dl]_{\pi_1}\ar[dr]^{\st} & 
   T(0\times Y)\ar[d]^{\cong}\ar[rr]^-{T(!\times\idmap)} & & 
   T(X\times Y) \\
T(0)\ar@/_12ex/[rrrru]^-{T(!)} & & 
   T(0\times 1)\ar[ll]_-{T(\pi_{1})}^-{\cong}
}\begin{array}{rcl}
\overline{r} \after \eta^{\E}
& = &
\mu \after T([T(!) \after r, \eta]) \after T(\kappa_{2}) \\
& = &
\mu \after T(\eta) \\
& = &
\idmap \\
\overline{r} \after \mu^{\E}
& = &
\mu \after T([T(!) \after r, \eta]) \after T([\kappa_{1},\idmap]) \\
& = &
\mu \after T([T(!) \after r, [T(!) \after r, \eta]]) \\
& = &
\mu \after T([\mu \after T(\eta\after\,!) \after r, 
   \mu \after \eta \after [T(!) \after r, \eta]]) \\
& = &
\mu \after T(\mu) \after  
   T([T(!) \after r, T([T(!) \after r, \eta]) \after \eta]) \\
& = &
\mu \after \mu \after T^{2}([T(!) \after r, \eta]) \after 
   T([T(!) \after r, \eta]) \\
& = &
\mu \after T([T(!) \after r, \eta]) \after \mu \after 
   T([T(!) \after r, \eta]) \\
& = &
\overline{r} \after \E(\overline{r}).
\end{array}\begin{array}{rcl}
\overline{\overline{\sigma}}_{X}
& = &
\mu \after T([T(!)\after \overline{\sigma}, \eta]) \\
& = &
\mu \after T([T(!)\after \sigma_{0} \after T(\kappa_{1}) \after \eta, 
   \eta]) \\
& = &
\mu \after T([\sigma_{X} \after T(\idmap+\,!) \after T(\kappa_{1})
    \after \eta, \eta]) \\
& = &
\mu \after T([\sigma_{X} \after T(\kappa_{1}) \after \eta, \eta]) \\
& = &
\mu \after T([\sigma_{X} \after T(\kappa_{1}) \after \eta, 
   \sigma_{X} \after \eta^{\E(T)}]) \\
& = &
\mu \after T(\sigma_{X}) \after T([T(\kappa_{1}) \after \eta, 
   T(\kappa_{2}) \after \eta]) \\
& = &
\mu \after T(\sigma_{X}) \after T([\eta \after \kappa_{1}, 
   \eta \after \kappa_{2}]) \\
& = &
\mu \after T(\sigma_{X}) \after T(\eta) \\
& = &
\mu \after T(\sigma_{X}) \after \sigma_{X} \after \eta^{\E}
   \after T(\eta) \\
& = &
\sigma_{X} \after \mu^{\E(T)} \after T(\kappa_{2}) \after
   T(\eta) \\
& = &
\sigma_{X} \after \mu \after T([T(\kappa_{1}) \after \eta, \idmap]) 
   \after T(\kappa_{2}) \after T(\eta) \\
& = &
\sigma_{X} \after \mu \after T(\eta) \\
& = &
\sigma_{X} \\
\overline{\overline{r}}
& = &
\overline{r}_{0} \after T(\kappa_{1}) \after \eta \\
& = &
\mu_{0} \after T([r, \eta_{0}]) \after T(\kappa_{1}) \after \eta \\
& = &
\mu_{0} \after T(r) \after \eta \\
& = &
\mu_{0} \after \eta \after r  \\
& = &
r.
\end{array}
\label{ComonoidDefEqn}
\begin{array}{rcl}
d_{b}
& = &
{\xymatrix@C-.5pc{
\Big(X\ar[r]^-{b} & TX\ar[r]^-{T(\Delta)} &
   T(X\times X)\ar[r]^-{\xi^{-1}}_-{\cong} & 
   T(X)\otimes T(X)\ar[r]^-{a\otimes a} & X\otimes X\Big)
}} \

\noindent where we use the underlying comonoid structure
 on  in the underlying category .
\end{prop}



\begin{myproof}
It is not hard to see that these  and  are maps of algebras:


\noindent The verification of the comonoid properties involves lengthy
calculations, which are basically straightforward. We just show that
 is neutral element for , using the equations from
Definition~\ref{BasisDef}.


\end{myproof}







\auxproof{ 
We first check that  are maps of algebras:





The verification of the comonoid properties involves lengthy
calculations, which are basically straightforward. We just show that
 is neutral element for , using the equations from
Definition~\ref{BasisDef}.


Associativity:


\noindent In a similar way one obtains the same outcome by starting from:


\noindent This comultiplication  is commutative:



For functoriality, assume two algebras , for , carrying
-coalgebras . A map of coalgebras  is
given by a map  satisfying  and .
This  is then a map 
between the induced comonoid. For instance,





It is not hard to see that when the monoidal structure on  is
cartesian, applying the constructions~(\ref{ComonoidDefEqn}) to the
coalgebra  on a free
algebra , as in Lemma~\ref{FreeAlgCoalgLem}, yields essentially
this comonoid:


The unit is obtained as , and the comultiplication as:

}


\begin{exa}
\label{ComonoidEx}
To make the comonoid construction~(\ref{ComonoidDefEqn}) more
concrete, let  be a vector space, say over the complex numbers
, with a Hamel basis, described as a coalgebra  like in
Theorem~\ref{OperatorCoalgThm}, with basic elements ,
satisfying . The counit 
from~\eqref{ComonoidDefEqn} first represents a vector wrt.\ this
basis, and then adds the (finitely many) coefficients:
 

\noindent Similarly, the comultiplication  as in~\eqref{ComonoidDefEqn} is the composite:


\noindent like in~\cite{CoeckePV12}. 

(For Hilbert spaces one uses orthonormal bases instead of Hamel bases;
the counit  of the comonoid then exists only in the
finite-dimensional case. The comultiplication  seems more relevant,
see also below, and may thus also be studied on its own, like
in~\cite{AbramskyH12}, without finiteness restriction.)



Another example is the ideal monad  from Subsection~\ref{DcpoSubsec}. It preserves finite
products, and as a result, the induced monoidal structure on the
category of algebras  is cartesian. Hence the
comonoid structure~(\ref{ComonoidDefEqn}) is given by actual diagonals
and (unique) maps to the final object. For instance, when  on algebras:

\end{exa}



\noindent In general, given a comonoid , an endomap  may be called \emph{diagonalised}---wrt.~this
comonoid, or actually, comultiplication ---if there is a ``map of
eigenvalues''  such that  equals the
composite:


\noindent In case the diagonal  is part of a comonoid, with a
counit , then this eigenvalue map  equals
.

\auxproof{
Assume  is diagonalised as above. Then:

}

In the special case where the comonoid comes from a
coalgebra (basis) , like
in~(\ref{ComonoidDefEqn}), an endomap of algebras , say on , is diagonalised
if there is a map of algebras  such
that  is:



\noindent where  is a strength map of the form , which exists because the monad  is
assumed to be commutative.


\begin{exa}
\label{BifMRelEx}
Recall the multiset monad  from
Subsection~\ref{VectorSpaceSubsec}, where  is a semiring.
In~\cite{Jacobs11a} it is used to defined a dagger category
 of ``bifinite multirelations''.  Objects are sets ,
and maps  in  are multirelations  which factor both as
 and as . This means
that for each  there are finitely many  with , and
similarly, for each  there are finitely many  with . Composition of  and  is done via matrix multiplication: . The identity  is
the given by  and  if . 

Here we don't need the dagger  on , but for
completeness we briefly mention how it arises, assuming that 
carries an involution , like
conjugation on the complex numbers. For a map 
there is an associated map  in the
reverse direction, obtained by swapping arguments and involution:
, like in a conjugate
transpose. This makes  a dagger category.

The category  is symmetric monoidal, with  as
tensor and  as tensor unit. Coproducts  give
biproducts. Interestingly, each object  carries a (canonical)
diagonal  given by:


\noindent There is in general no associated counit .

Now let's see what it means that a map  in
 is diagonalised wrt.\ this . It would require an
eigenvalue map , that is, a function  in , so that 
satisfies:


\noindent Hence such a diagonalised map is a diagonal matrix.
\end{exa}


What precisely is a diagonalised form depends on the diagonalisation
(comonoid) map  involved. This is clear in the following example,
involving Pauli matrices.



\begin{exa}
\label{PauliEx}
We consider the set  as vector space over
, and thus as algebra of the (commutative) multiset monad
 via the map
 that sends a formal
sum  of pairs in
 to the pair of sums .

The familiar Pauli spin functions  are given by:


\noindent We concentrate on ; it satisfies
 and . These eigenvectors  and  are organised in a
basis , as in Definition~\ref{BasisDef},
via the following formal sum.


\noindent It expresses an arbitrary element of
 in terms of this basis of eigenvectors. It is not
hard to see that  is a
-coalgebra; for instance:


\auxproof{


We also check that  is a map of algebras:


The equaliser~(\ref{BasisEqualiserDiag}) for the basic elements
yields the expected outcome:

}

\noindent The comonoid structure 
induced by  as in~(\ref{ComonoidDefEqn}) is given by
 and . The eigenvalue map
 is given
by . The eigenvalues  appear by
application to the basic elements:  and
. Further, the Pauli function
 is diagonalised as in~(\ref{ComonoidDiagEqn})
via these , since:


\auxproof{



Alternatively, elaborating the formula~(\ref{AlgDiagEqn}) yields:

}

\noindent In a similar way one defines for the other Pauli functions
 and :




\end{exa}







\noindent The situation that we have is similar to what one finds in categorical
models of linear logic, where the exponential , giving arbitrarily
many copies of , is interpreted via a comonad  carrying a
comonoid structure  for
weakening and contraction. In the current situation we have a basis as
a coalgebra , so that we get a comonoid structure
on , instead of on .

The next result can be interpreted informally as: base vectors are
copyable.



\begin{prop}
\label{BaseCopyProp}
Assume an algebra  with an
`element'  in  that is
in the basis of a coalgebra , as in the
equaliser diagram~(\ref{BasisEqualiserDiag}):


\noindent This  is then copyable, in the sense that the
following diagram commutes


\noindent where  is the comultiplication associated with 
as in~(\ref{ComonoidDefEqn}).
\end{prop}


\begin{myproof}
Since  is a free algebra, the map of algebras  can be written as , for the
element  in the underlying
category. Then:


\noindent Now we use that  is a monoidal isomorphism in:


\noindent in order to prove that  is copyable:

\end{myproof}


\noindent The converse of this result is not true: for the ideal monad in
Example~\ref{ComonoidEx} every element is copyable, but not every
element is compact, \textit{i.e.}~in a basis, see
Subsection~\ref{DcpoSubsec}.

Comonoids make tensors cartesian, see~\cite{Fox76,CoeckeP08}, so
that they bring us into the classical world. This cartesian structure
already exists for coalgebras, as the next result shows.


\begin{prop}
\label{CoalgComonoidProductProp}
The comonoid structure~(\ref{ComonoidDefEqn}) restricts to a comonoid
in the category  of bases. Therefore, this
category has finite products.  Moreover, the restriction of the free
functor  to , as in Lemma~\ref{FreeAlgCoalgLem},
preserves finite products.
\end{prop}


\begin{myproof}
First one checks that the maps  in~(\ref{ComonoidDefEqn}) are
homomorphisms of coalgebras. Then one uses that the comonad
 is monoidal,
see~\cite[Prop.~5.7]{Jacobs94a}, so that the products of coalgebras
can be defined as:


\noindent where on the right-hand-side we use the map:


\noindent in which  is the universal bi-homomorphism. \qed
\end{myproof}

\auxproof{
Given a coalgebra  on , the unit map 
is a map of algebras \& coalgebras:


\noindent Moreover, it is the unique one, since if  is also a map of -coalgebras, then it
is a map of comonoids, by Proposition~\ref{CoalgComonoidProp}, and
thus:


We turn to products, and define projections:


\noindent and similarly for . This gives maps of algebras,
by construction:


\noindent where we have overloaded the -notation. It is
also a map of coalgebras:


Next, assume homomorphisms . Take as
tuple . We need to check that
comultiplications  are maps of coalgebras . This requires some care, and a better understanding of
the monoidal transformations involved. We recall that the map , for ,
is obtained in:


\noindent with inverse for  given by:


\noindent The map  used in the description
of the product coalgebra is then the composite:


\noindent where we consider the  as algebras.

In order to see that  is a map in  we
need to prove:


\noindent We proceed in two steps.


\noindent Similarly,


We can now prove the familiar tuple equations:


The final equation requires more work:


The restriction of the free functor 
to , as in
Lemma~\ref{FreeAlgCoalgLem}, preserves finite products, since it
may be described as:


\noindent so that  is the final object  as
described in the proof of~\ref{CoalgComonoidCor}. For binary
products, consider the following diagram in , forming
an isomorphism between coalgebras.


\noindent The triangle on the right commutes by definition of
, see the `auxproof' of Theorem~\ref{MonadAlgStructThm}.
Moreover, this isomorphism  commutes with the projections:

}


\section{Conclusions}

This paper elaborates the novel view that coalgebras-on-algebras are
bases, in a very general sense. This applies to coalgebras of the
comonad that is canonically induced on a category of algebras of a
monad. Various set-theoretic and order-theoretic examples support this
view. It remains to be investigated to what extent this view also
applies in program semantics, beyond the example of the exception
monad transformer. Also, the connection between bases and copying,
that is so important in quantum mechanics, exists in the current
abstract setting.


\subsection*{Acknoledgements} Thanks are due to Paul Blain Levy, Jorik
Mandemaker, and Paul Taylor, for helpful information and discussions
about the earlier version~\cite{Jacobs11d} of this paper.


\bibliographystyle{plain} 


\begin{thebibliography}{10}

\bibitem{Abramsky10b}
S.~Abramsky.
\newblock No-cloning in categorical quantum mechanics.
\newblock In S.~Gay and I.~Mackie, editors, {\em Semantical Techniques in
  Quantum Computation}, pages 1--28. Cambridge Univ. Press, 2010.

\bibitem{AbramskyH12}
S.~Abramsky and C.~Heunen.
\newblock {H-algebras} and nonunital {Frobenius} algebras: first steps
  in infinite-dimensional categorical quantum mechanics.
\newblock {\em Clifford Lectures, AMS Proceedings of Symposia in Applied
  Mathematics}, 71:1--24, 2012.

\bibitem{BanaschewskiB88}
B.~Banaschewski and G.~Br{\"u}mmer.
\newblock Stably continuous frames.
\newblock {\em Math. Proc. Cambridge Phil. Soc.}, 114:7--19, 1988.

\bibitem{Barr69}
M.~Barr.
\newblock Coalgebras in a category of algebras.
\newblock In {\em Category Theory, Homology Theory and their Applications {I}},
  number~86 in Lect. Notes Math., pages 1--12. Springer, Berlin, 1969.

\bibitem{Borceux94}
F.~Borceux.
\newblock {\em Handbook of Categorical Algebra}, volume 50, 51 and 52 of {\em
  Encyclopedia of Mathematics}.
\newblock Cambridge Univ. Press, 1994.

\bibitem{Coecke10a}
B.~Coecke.
\newblock Quantum picturalism.
\newblock {\em Contemp. Physics}, 51(1):59--83, 2010.

\bibitem{CoeckeP08}
B.~Coecke and D.~Pavlovi{\'c}.
\newblock Quantum measurements without sums.
\newblock In G.~Chen, L.~Kauffman, and S.~Lamonaco, editors, {\em Mathematics
  of Quantum Computing and Technology}, pages 559--596. Taylor and Francis,
  2008.

\bibitem{CoeckePV12}
B.~Coecke, D.~Pavlovi{\'c}, and J.~Vicary.
\newblock A new description of orthogonal bases.
\newblock {\em Math. Struct. in Comp. Sci.}, pages 1--13, 2012.

\bibitem{CoumansJ13}
D.~Coumans and B.~Jacobs.
\newblock Scalars, monads and categories.
\newblock In C.~Heunen, M.~Sadrzadeh, and E.~Grefenstette, editors, {\em
  Quantum Physics and Linguistics. A Compositional, Diagrammatic Discourse},
  pages 184--216. Oxford Univ. Press, 2013.

\bibitem{Escardo98}
M.~Escard{\'o}.
\newblock Properly injective spaces and function spaces.
\newblock {\em Topology and its Applications}, 98(1-2):75--120, 1999.

\bibitem{Fox76}
T.~Fox.
\newblock Coalgebras and cartesian categories.
\newblock {\em Communic. in Algebra}, 4(7):665--667, 1976.

\bibitem{GierzHKLMS03}
G.~Gierz, K.H. Hofmann, , K.~Keimel, J.D. Lawson, M.~Mislove, and D.~Scott.
\newblock {\em Continuous Lattices and Domains}, volume~93 of {\em Encyclopedia
  of Mathematics}.
\newblock Cambridge Univ. Press, 2003.

\bibitem{Hoffmann79}
R.-E. Hoffmann.
\newblock Continuous posets and adjoint sequences.
\newblock {\em Semigroup Forum}, 18:173--188, 1979.

\bibitem{Jacobs94b}
B.~Jacobs.
\newblock Coalgebras and approximation.
\newblock In A.~Nerode and Yu.~V. Matiyasevich, editors, {\em Logical
  Foundations of Computer Science}, number 813 in Lect. Notes Comp. Sci., pages
  173--183. Springer, Berlin, 1994.

\bibitem{Jacobs94a}
B.~Jacobs.
\newblock Semantics of weakening and contraction.
\newblock {\em Ann. Pure \& Appl. Logic}, 69(1):73--106, 1994.

\bibitem{Jacobs10e}
B.~Jacobs.
\newblock Convexity, duality, and effects.
\newblock In C.~Calude and V.~Sassone, editors, {\em IFIP Theoretical Computer
  Science 2010}, number 82(1) in IFIP Adv. in Inf. and Comm. Techn., pages
  1--19. Springer, Boston, 2010.

\bibitem{Jacobs11d}
B.~Jacobs.
\newblock Bases as coalgebras.
\newblock In A.~Corradini, B.~Klin, and C.~C{\"\i}rstea, editors, {\em
  Conference on Algebra and Coalgebra in Computer Science (CALCO 2011)}, number
  6859 in Lect. Notes Comp. Sci., pages 237--252. Springer, Berlin, 2011.

\bibitem{Jacobs11a}
B.~Jacobs.
\newblock Coalgebraic walks, in quantum and {Turing} computation.
\newblock In M.~Hofmann, editor, {\em Foundations of Software Science and
  Computation Structures}, number 6604 in Lect. Notes Comp. Sci., pages 12--26.
  Springer, Berlin, 2011.

\bibitem{JaskelioffaM10}
M.~Jaskelioffa and E.~Moggi.
\newblock Monad transformers as monoid transformers.
\newblock {\em Theor. Comp. Sci.}, 51-52:4441--4466, 2010.

\bibitem{Johnstone82}
P.~Johnstone.
\newblock {\em Stone Spaces}.
\newblock Number~3 in Cambridge Studies in Advanced Mathematics. Cambridge
  Univ. Press, 1982.

\bibitem{Kock71b}
A.~Kock.
\newblock Bilinearity and cartesian closed monads.
\newblock {\em Math. Scand.}, 29:161--174, 1971.

\bibitem{Kock71a}
A.~Kock.
\newblock Closed categories generated by commutative monads.
\newblock {\em Journ. Austr. Math. Soc.}, XII:405--424, 1971.

\bibitem{Kock95}
A.~Kock.
\newblock Monads for which structures are adjoint to units.
\newblock {\em Journ. of Pure \& Appl. Algebra}, 104:41--59, 1995.

\bibitem{Levy06}
P.~Levy.
\newblock Monads and adjunctions for global exceptions.
\newblock In {\em Math. Found. of Programming Semantics}, number 158 in Elect.
  Notes in Theor. Comp. Sci., pages 261--287. Elsevier, Amsterdam, 2006.

\bibitem{LiangHJ95}
S.~Liang, P.~Hudak, and M.~Jones.
\newblock Monad transformers and modular interpreters.
\newblock In {\em Principles of Programming Languages}, pages 333--343. ACM
  Press, 1995.

\bibitem{Mesablishvili06}
B.~Mesablishvili.
\newblock Monads of effective descent type and comonadicity.
\newblock {\em Theory and Applications of Categories}, 16(1):1--45, 2006.

\bibitem{Moggi88}
E.~Moggi.
\newblock Partial morphisms in categories of effective objects.
\newblock {\em Inf. \& Comp.}, 76(2/3):250--277, 1988.

\bibitem{Moggi91a}
E.~Moggi.
\newblock Notions of computation and monads.
\newblock {\em Inf. \& Comp.}, 93(1):55--92, 1991.

\bibitem{NielsenC00}
M.~Nielsen and I.~Chuang.
\newblock {\em Quantum Computation and Quantum Information}.
\newblock Cambridge Univ. Press, 2000.

\bibitem{RoseburghW91}
R.~Rosebrugh and R.~Wood.
\newblock Constructive complete distributivity {II}.
\newblock {\em Math. Proc. Cambridge Phil. Soc.}, 10:245--249, 1991.

\bibitem{SchroderM04}
L.~Schr{\"o}der and T.~Mossakowski.
\newblock Generic exception handling and the {Java} monad.
\newblock In C.~Rattray, S.~Maharaj, and C.~Shankland, editors, {\em Algebraic
  Methods and Software Technology}, number 3116 in Lect. Notes Comp. Sci.,
  pages 443--459. Springer, Berlin, 2004.

\end{thebibliography}
\vspace{-30 pt}
\end{document}
