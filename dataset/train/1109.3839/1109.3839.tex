








\documentclass[10pt,conference,compsocconf,letterpaper]{IEEEtran}


\usepackage{comment}
\usepackage{graphicx}
\usepackage{subfigure}
\usepackage{algorithm}


\usepackage{amsmath}
\usepackage{algorithmic}

\def\baselinestretch{0.95}

\textwidth=18.0cm
\textheight=24.0cm





\newcommand{\case}[1]{\noindent{\textbf{Case}} \textbf{#1:} }
\newcommand{\Case}[1]{\noindent{\em Case} #1: }



\newtheorem{lemma}{\bf Lemma}
\newtheorem{theorem}[lemma]{\bf Theorem}
\newtheorem{corollary}[lemma]{\bf Corollary}
\newtheorem{fact}[lemma]{Fact}
\newcommand{\proofend}{
{\hfill{}}
\ }
\newcommand{\dvgraph}{divided vertex graph}
\newcommand{\wrt}{with respect to }




















\ifCLASSINFOpdf
\else
\fi




























































\hyphenation{op-tical net-works semi-conduc-tor}


\begin{document}
\title{Dynamic Deferral of Workload for Capacity Provisioning in Data Centers}


\author{\IEEEauthorblockN{Muhammad Abdullah Adnan\IEEEauthorrefmark{1}, Ryo Sugihara\IEEEauthorrefmark{2}, Yan Ma\IEEEauthorrefmark{3} and Rajesh K. Gupta\IEEEauthorrefmark{1}}
\IEEEauthorblockA{\IEEEauthorrefmark{1}University of California San Diego, \IEEEauthorrefmark{2}Amazon.com, \IEEEauthorrefmark{3}Shandong University}
}















\maketitle


\begin{abstract}
Recent increase in energy prices has led researchers to find better ways for capacity provisioning in data centers to reduce energy wastage due to the variation in workload. This paper explores the opportunity for cost saving utilizing the flexibility from the Service Level Agreements (SLAs) and proposes a novel approach for capacity provisioning under bounded latency requirements of the workload. We investigate how many servers to be kept active and how much workload to be delayed for energy saving while meeting every deadline. We present an offline LP formulation for capacity provisioning by dynamic deferral and give two online algorithms to determine the capacity of the data center and the assignment of workload to servers dynamically. We prove the feasibility of the online algorithms and show that their worst case performance are bounded by a constant factor with respect to the offline formulation. We validate our algorithms on a MapReduce workload by provisioning capacity on a Hadoop cluster and show that the algorithms actually perform much better in practice compared to the naive `follow the workload' provisioning, resulting in 20-40\% cost-savings.
\end{abstract}












\section{Introduction}
With the advent of cloud computing, data centers are emerging all over the world and their energy consumption becomes significant; as estimated 61 million MWh per year, costing about 4.5 billion dollars \cite{23}. Naturally, energy efficiency in data centers has been pursued in various ways including the use of renewable energy \cite{22,25} and improved cooling efficiency \cite{26,30,17}, etc. Among these, improved scheduling algorithm is a promising approach for its broad applicability regardless of hardware configurations. Among the attempts to improve scheduling \cite{17, 9}, recent effort has focussed on optimization of schedule under performance constraints imposed by Service Level Agreements (SLAs). Typically, a SLA specification provides a measure of flexibility in scheduling that can be exploited to improve performance and efficiency \cite{n9,n10}. To be specific, latency is an important performance metric for any web-based service and is of great interest for service providers who run their services on data centers.
The goal of this paper is to utilize the flexibility from the SLAs for different types of workload to reduce energy consumption. The idea of utilizing SLA information to improve performance and efficiency is not entirely new. Recent work explores utilization of application deadline information for improving the performance of the applications (e.g. see \cite{n10, n6}). But the opportunities for energy efficiency remain unexplored, certainly in a manner that seeks to establish bounds on the energy cost from the proposed solutions.




In this paper, we are interested in minimizing the energy consumption of a data center under guarantees on latency/ deadline. We use the deadline information to defer some tasks so that we can reduce the total cost for energy consumption for executing the workload and switching the state of the servers. We determine the portion of the released workload to be executed at the current time and the portions to be deferred to be executed at later time slots without violating deadlines. Our approach is similar to `valley filling' that is widely used in data centers to utilize server capacity during the periods of low loads \cite{9}. But the load that is used for valley filling is mostly background/maintenance tasks (e.g. web indexing, data backup) which is different from actual workload. In fact current valley filling approaches ignore the workload characteristics for capacity provisioning. In this paper, we determine how much work to defer for valley filling in order to reduce the current and future energy consumption while provably ensuring satisfaction of SLA requirements. Later we generalize our approach for more general workloads where different jobs have different deadlines.

This paper makes three contributions. First, we present an LP formulation for capacity provisioning with dynamic deferral of workload. The formulation not only determines capacity but also determines the assignment of workload for each time slot. As a result the utilization of each server can be determined easily and resources can be allocated accordingly. Therefore this method well adapts to other scheduling policies that take into account dynamic resource allocation, priority aware scheduling, etc.

Second, we design two optimization based online algorithms depending on the nature of the deadline. For uniform deadline, our algorithm named {\it Valley Filling with Workload (VFW())}, looks ahead  slots to optimize the total energy consumption. The algorithm uses the valley filling approach to defer some workload to execute in the periods of low loads. For nonuniform deadline, we design a {\it Generalized Capacity Provisioning (GCP)} algorithm that reduces the switching (on/off) of servers by balancing the workloads in adjacent time slots and thus reduces energy consumption.  We prove the feasibility of the solutions and show that the performance of the online algorithms are bounded by a constant factor with respect to the offline formulation.

Third, we validate our algorithms using MapReduce traces (representative workload for data centers) and evaluate cost savings achieved via dynamic deferral. We run simulations to deal with a wide range of settings and show significant savings in each of them. Over a period of 24 hours, we find more than 40\% total cost saving for GCP and around 20\% total cost saving for VFW() even for small deadline requirements. We compare the two online algorithms with different parameter settings and find that GCP gives more cost savings than VFW(). In order to show that our algorithms work on real systems, we perform experiments on a 35 node Hadoop cluster and find energy savings of 6.02\% for VFW() and 12\% for GCP over a period of 4 hours. The experimental results show that the peak energy consumption for the operation of a data center can be reduced by provisioning capacity and scheduling workload using our algorithms.








The rest of the paper is organized as follows. Section II presents the model that we use to formulate the optimization and gives the offline formulation. In Section III, we present the VFW() algorithm for determining capacity and workload assignment dynamically when the deadline is uniform. In Section IV, we illustrate the GCP algorithm with nonuniform deadline. Section V discusses the extension of our algorithms for long jobs. In Section VI and VII, we illustrate the simulation and experimental results respectively. In Section VIII, we describe the state of the art research related to capacity provisioning and Section IX concludes the paper.





\section{Model Formulation}
In this section, we describe the model we use for capacity provisioning via dynamic deferral. We note that the assumptions used in this model are minimal and this formulation captures many properties of current data center capacity and workload characteristics.

\subsection{Workload Traces}
To build a realistic model, we need real workload from data centers but the data center providers are reluctant to publish their production traces due to privacy issues and competitive concerns. To overcome the scarcity of publicly available traces, efforts have been made to extract summary statistics from production traces and workload generators based on those statistics have been proposed \cite{n4,n5}. For the purposes of this paper, we use such a workload generator and use the MapReduce traces released by Chen et al \cite{n4}. MapReduce framework is widely used in Data centers and acts as representative workload where each of the jobs consists of 3 steps of computation: map, shuffle and reduce \cite{n3}. Figure~\ref{fig:original_workload}(a) illustrates the statistical  MapReduce traces over 24 hours generated from real Facebook traces.



\begin{figure}[!t]
\centerline{\subfigure[Original Workload]{\includegraphics[width
=1.7in]{original_workload_a_.png}
}
\hfil
\subfigure[Batch and Interactive Job]{\includegraphics[width=1.7in]{mix_workload_a_.png}
}}
\caption{Illustration of (a) original workload and (b) distinction between batch and small interactive jobs.
}
\label{fig:original_workload}
\end{figure}





Typically the workload traces consist of a mix of batch and interactive jobs. Chen et al. carried out an interactive analysis to classify the workload and showed that the workload is dominated (98\%) by small and interactive jobs showing significant and unpredictable variation with time. Table~\ref{table:trace} illustrates the classification on the MapReduce traces by -means clustering based on the sizes of map, shuffle and reduce stages (in bytes) with  and Figure~\ref{fig:original_workload}(b) shows the distinction in time variation between the long batch jobs and small interactive jobs. To adapt with the large variation in the small and interactive workload, valley filling methods have been proposed using the low priority batch jobs to fill in the periods of low workload \cite{Liu}. However, Chen et al. have shown that the portion of low priority long jobs (2\%) are insufficient to reduce the variation (to smooth) in the workload curve \cite{n5}. In this paper, we propose valley filling with workload (mix of long and interactive jobs) and devise algorithms for capacity provisioning by scheduling jobs under bounded latency requirements.



\begin{table}[!t]
\caption{Cluster Sizes and Medians by -means Clustering on the MapReduce Trace} \centering  \begin{tabular}{r r r r r} \hline\hline                        \# Jobs & \% Jobs & Input & Shuffle & Output \\ [0.5ex] \hline                  5691 & 96.56 & 15 KB & 0 & 685 KB \\ 116 & 1.97 & 44 GB & 15 GB  & 84 MB  \\
27 & 0.46 & 56 GB & 145 GB & 16 GB \\
23 & 0.39 & 123 GB & 0 & 52 MB \\
19 & 0.32 & 339 KB & 0 & 48 GB\\ [1ex]      8 & 0.14 & 203 GB & 404 GB & 3 GB \\
5 & 0.08 & 529 GB & 0 & 53 KB \\
3 & 0.05 & 46 KB & 0 & 199 GB\\
1 & 0.02 & 7 TB & 48 GB & 101 GB \\
1 & 0.02 & 913 GB& 8 TB & 61 KB \\
\hline \end{tabular}
\label{table:trace} \end{table}
























\subsection{Workload Model}
We consider a workload model where the total workload varies over time. The time interval we are interested in is  where  can be arbitrarily large. In practice,  can be a year and the length of a time slot  could be as small as 2 minutes (the minimum time required to change power state of a server). In our model, each job has a deadline  (in terms of number of slots) associated with it, where  is a nonnegative integer. In other words, a job released at time , needs to be executed within time slot . We first model for small interactive jobs having length less than . Later in Section V, we extend our model for mix of jobs with arbitrary lengths. Based on the nature of deadlines, we have two cases: (i) uniform deadline, when deadline is uniform for all the jobs; (ii) non-uniform deadlines, when different jobs have different deadlines. In Section II and III, we formulate model and algorithm for the case of uniform deadline and the non-uniform deadline case is considered in Section IV.
Let  be the amount of workload released at time slot . Since the deadline  is uniform for all the jobs, the total amount of work  must be executed by the end of time slot . Since  varies over time, we often refer to it as a {\it workload curve}.










We consider data center as a collection of homogeneous servers. The total number of servers  is fixed and given but each server can be turned on/off to execute the workload. We normalize  by the processing capability of each server i.e.  denotes the number of servers required to execute the workload at time . We assume for all , . Let  be the portion of the released workload  that is assigned to be executed at server  at time slot  where  represents the deferral with . Let  be the number of active servers during time slot . Then .

Let  be the total workload assigned at time  to server  and  be the total assignment at time . Then we can think of  as the utilization of the th server at time  i.e. . Thus . From the data center perspective, we focus on two important decisions during each time slot : (i) determining , the number of active servers, and (ii) determining , assignment of workload to the servers.

\subsection{Cost Model}
The goal of this paper is to minimize the cost (price) of energy consumption in data centers. The energy cost function consists of two parts: operating cost and switching cost. {\it Operating cost} is the cost for executing the workload which in our model is proportional to the assigned workload. We use the common model for energy cost for typical servers which is an affine function:

where  and  are constants (e.g. see \cite{20}) and  is the assigned workload (utilization) of a server at a time slot. Although we use this general model for cost function, other models considering nonlinear parameters such as temperature, frequency can easily be adopted in the model which will make it a nonlinear optimization problem. Our algorithms can be applied for such nonlinear models by using techniques for solving nonlinear optimizations as each optimization is considered as a single independent step in the algorithms.





{\it Switching cost } is the cost incurred for changing state (on/off) of a server. We consider the cost of both turning on and turning off a server. Switching cost at time  is defined as follows:  where  is a constant (e.g. see \cite{9,21}).


\subsection{Optimization Problem}
Given the models above, the goal of a data center is to choose the number of active servers (capacity)  and the dispatching rule  to minimize the total cost during , which is captured by the following optimization:
\begin{IEEEeqnarray}{lll}
\label{equn:opt1}
 \text{min}_{x_t,m_t}\quad & \sum_{t=1}^T \sum_{i=1}^{m_t}  C(x_{i,t}) + \beta \sum_{t=1}^T |m_t-m_{t-1}|\\
 \text{subject to}\quad &  \sum_{i=1}^{m_t} \sum_{d=0}^{D} x_{i,d,t} = L_t  \qquad\qquad\qquad \forall t\nonumber\\
 &  \sum_{i=1}^{m_t} \sum_{d=0}^{D} x_{i,d,t-d} \le m_t  \qquad\qquad\quad \forall t\nonumber\\
 &  \sum_{d=0}^{D} x_{i,d,t-d} \le 1  \qquad\qquad\qquad\forall i, \forall t\nonumber\\
 &  0\le m_t \le M \qquad\qquad\qquad\qquad \forall t\nonumber\\
 &  x_{i,d,t}\ge 0  \qquad\qquad\qquad\qquad\forall i, \forall d, \forall t.\nonumber
\end{IEEEeqnarray}
Since the servers are identical, we can simplify the problem by dropping the index  for . More specifically, for any feasible solution , we can make another solution by  (i.e., replacing every  by the average of  for all ) without changing the value of the objective function while satisfying all the constraints after this conversion. Then we have the following optimization equivalent to~(\ref{equn:opt1}):
\begin{IEEEeqnarray}{cll}
\label{equn:opt2}
 \text{min}_{x_t,m_t}\quad & \sum_{t=1}^T  m_tC(x_t/m_t) + \beta \sum_{t=1}^T |m_t-m_{t-1}|&\\
 \text{subject to}\quad &  \sum_{d=0}^{D} x_{d,t} = L_t   &\forall t \nonumber\\
  &  \sum_{d=0}^{D} x_{d,t-d} \le m_t   &\forall t\nonumber\\
  &  0\le m_t \le M  &\forall t\nonumber\\
  &  x_{d,t}\ge 0    &\forall d, \forall t.\nonumber
\end{IEEEeqnarray}
where  represents the portion of the workload  to be executed at a server at time . We further simplify the problem by showing that any optimal assignment for (\ref{equn:opt2}) can be converted to an equivalent assignment that uses earliest deadline first (EDF) policy (see Figure~\ref{fig:lemma1}). More formally, we have the following lemma:

\begin{lemma}
\label{lemma:edf}  Let  and  be the optimal assignments of workload obtained from the solution of optimization~(\ref{equn:opt2}) at times  and  respectively where  and . If  with  and  for any  then we can obtain another assignments  and  where  and .
\end{lemma}

\begin{proof}
We prove it by constructing  and  from  and . We change the assignments ,  and ,  to obtain  and  as illustrated in Figure~\ref{fig:lemma1}.
\begin{figure}[!ht]
\begin{center}
\includegraphics[width=3.3in]{lemma1.png}
\caption{Assignments can be determined from their release times and EDF policy.}
\label{fig:lemma1}
\end{center}
\end{figure}
We now determine . Note that all the workloads released between (including) time slots  to  can be executed at time  without violating deadline since . Also all the workloads released between (including) time slots  to  can be executed at time  without violating deadline since . Hence the new assignment of workloads cannot violate any deadline. We determine  at a point where  and  and  such that . Similarly for , we have the new assignment as:  
  and   and  such that .
\end{proof}





According to lemma~\ref{lemma:edf}, we do not need both  and  as indices of . We can use the release time  to determine the deadline  and differentiate between the jobs using their deadlines. Thus, we drop the index  of . At time , unassigned workload from  to  is executed according to EDF policy while minimizing the objective function. To formulate the constraint that no assignment violates any deadline we define delayed workload  with maximum deadline .

We call the delayed curve  for the workload as {\it deadline curve}. Thus we have two fundamental constraints on the assignment of workload for all :

\begin{enumerate}
\item[(C1)] Deadline Constraint: 
\item[(C2)] Release Constraint: 
\end{enumerate}

Condition (C1) says that all the workloads assigned up to time  cannot violate deadline and Condition (C2) says that the assigned workload up to time  cannot be greater than the total released workload up to time . Using these constraints we reformulate the optimization~(\ref{equn:opt2}) as follows:

\begin{IEEEeqnarray}{cLl}
\label{equn:opt3}
 \text{min}_{x_t,m_t}\quad & \sum_{t=1}^T  m_tC(x_t/m_t) + \beta \sum_{t=1}^T |m_t-m_{t-1}|&\\
 \text{subject to}\quad & \sum_{j=1}^{t} l_j \le \sum_{j=1}^{t} x_j \le \sum_{j=1}^{t} L_j  & \forall t\nonumber\\
 &  \sum_{j=1}^{T} x_j = \sum_{j=1}^{T} L_j   & \nonumber\\
 &  0\le x_t \le m_t \le M   & \forall t\nonumber
\end{IEEEeqnarray}

Since the operating cost function  is an affine function, the objective function is linear as well as the constraints.  Hence it is clear that the optimization (\ref{equn:opt3}) is a linear program. Note that capacity  in this formulation is not constrained to be an integer. This is acceptable because data centers consists of thousands of active servers and we can round the resulting solution with minimal increase in cost. Figure~\ref{fig:solutionrandom}(a) illustrates the offline optimal solutions for  and  for a dynamic workload generated randomly. The performance of the optimal offline solution on two realistic workload are provided in Section VI.



\begin{figure}[!t]
\centerline{\subfigure[Offline optimal]{\includegraphics[width
=1.7in]{solution_a_.png}
}
\hfil
\subfigure[VFW()]{\includegraphics[width=1.7in]{solution_b_.png}
}}
\caption{Illustration of (a) offline optimal solution and (b) VFW() for arbitrary workload generated randomly; time slot length = 2 min, , .}
\label{fig:solutionrandom}
\end{figure}



\section{Valley Filling with Workload}
In this section, we consider the online case, where at any time , we do not have information about the future workload  for . At each time , we determine the  and   by applying optimization over the already released unassigned workload which has deadline in future  slots. Note that the workload released at or before , can not be delayed to be assigned after time slot . Hence we do not optimize over more than  slots.  We simplify the online optimization by solving only for  and determine  by making  at time . This makes the online algorithm not to waste any execution capacity that cannot be used later for executing workload. But the cost due to switching in the online algorithm may be higher than the offline algorithm. Thus our goal is to design strategies to reduce the switching cost. In the online algorithm, we reduce the switching cost by optimizing the total cost for the interval .

When the deadline is uniform, we can reduce the switching cost even more by looking beyond  slots. We do that by accumulating some workload from periods of high loads and execute that amount of workload later in valleys without violating constraints (C1) and (C2). Note that by accumulation we do not violate deadline as at each slot, we execute a portion of the accumulated workload by swapping with the newly released workload by EDF policy. To determine the amount of accumulation and execution we use `-delayed workload'. Thus the online algorithm namely Valley Filling with Workload (VFW()) looks ahead  slots to determine the amount of execution. Let  be the {\it -delayed curve} with delay of  slots for .

Then we can call the deadline curve as {\it -delayed curve} and represent it by . We determine the amount of accumulation and execution by controlling the set of feasible choices for  in the optimization. For this purpose, we use the -delayed curve to restrict the amount of accumulation. By having a lower bound on  for the valley (low workload) and an upper bound it for the high workload, we control the execution in the valley and accumulation in the other parts of the curve. Thus in the online algorithm, we have two types of optimizations: Local Optimization and Valley Optimization. Local Optimization is used to smooth the `wrinkles' (we define {\it wrinkles} as the small variation in the workload in adjacent slots e.g. see Figure~\ref{fig:valleyopt}) within  consecutive slots and accumulate some workload. On the other hand, Valley Optimization fills the valleys with the accumulated workload.

\begin{figure}[!t]
\begin{center}
\includegraphics[width=3.3in]{valleyopt.png}
\caption{The curves  and  and their intersection points. The peak from the  curve is cut and used to fill the valley of the same curve. The amount of workload that is accumulated/delayed is bounded by .}
\label{fig:valleyopt}
\end{center}
\end{figure}



\subsection{Local Optimization}
The {\it local optimization} applies optimization over future  slots and finds the optimum capacity for current slot by executing no more than -delayed workload. Let  be the current time slot. At this slot we apply a slightly modified version of offline optimization (\ref{equn:opt3}) in the interval . We apply the following optimization LOPT(, , , ) to determine  in order to smooth the wrinkles by optimizing over  consecutive slots. We restrict the amount of execution to be no more than the -delayed workload while satisfying the deadline constraint (C1).
\begin{IEEEeqnarray}{cLl}
\label{lopt}
 \text{min}_{m_t}\quad & (e_0 + e_1)\sum_{j=t}^{t+D}  m_j + \beta \sum_{j=t}^{t+D} |m_j-m_{j-1}|\\
 \text{subject to}\quad &\sum_{j=1}^{t} l^D_j\le \sum_{j=1}^{t} m_j     \nonumber\\
 &  \sum_{j=1}^{t+D} m_j = \sum_{j=1}^{t} l^\delta_j  \nonumber\\
 &  0\le m_k \le M  \qquad \qquad \qquad t\le k \le t+D\nonumber
\end{IEEEeqnarray}
After solving the local optimization, we get the value of  for the current time slot and assign .  For the next time slot  we solve the local optimization again to find the values for  and . Note that the deadline constraint (C1) and the release constraint (C2) are satisfied at time , since from the formulation .



\begin{comment}
At this slot we have knowledge of the workload from  to  and hence we know the delayed workload from  to . To determine the values of  and  for the current slot , . Since we are optimizing , there will be some  accumulated workload (possibly zero) for the local optimization at time .  Let  be the accumulated workload for the local optimization at time . Then  is the sum of three parts: (i) the local accumulated workload from the previous slot , (ii) the accumulated workload due to the difference in  and   and (iii) the change of global accumulation  (which will be discussed in the next subsection) due to the change in the estimate for maximum accumulation  according to lemma~\ref{lemma:offline1}. Hence 

Since , we use only the positive difference. If the difference is negative, we just use zero. This phenomenon is captured using the  sign where . Let . Note that the amount of accumulated workload accounted in  is the actual accumulated workload which is different from the accumulation constraint. We now formulate the optimization for   such that it follows the  curve as well as smooths the wrinkles in the delayed curve . Hence in the formulation we restrict the accumulation constraint (C3) to follow the  curve.
\end{comment}


\begin{comment}

\end{comment}


\subsection{Valley Optimization}
In {\it valley optimization}, the accumulated workload from the local optimization is executed in `global valleys'. Before giving the formulation for the valley optimization we need to detect a valley.


Let  be the sequence of intersection points of  and  curves (see Figure~\ref{fig:valleyopt}) in nondecreasing order of their x-coordinates ( values).  Let  be the sequence of points on  with delay  added with each intersection point  on  such that  for all . We discard  all the intersection points (if any) between  and  from the sequence such that . Note that at each intersection point , the curve from  to  is known. To determine whether the curve  between  and  is a valley, we calculate the area 
If  is negative, then we regard the curve between  and  as a {\it global valley} though it may contain several small peaks and valleys. If the curve between  and  is a global valley, we fill the valley with some (possibly all) of the accumulated workload by executing more than the -delayed workload while satisfying the release constraint (C2). For each , we apply the following optimization  VOPT(, , , ) in the interval  to find the value of  where .
\begin{IEEEeqnarray}{cLl}
\label{equn:gopt}
 \text{min}_{m_t}\quad & (e_0 + e_1) \sum_{j=t}^{t+D}  m_j + \beta \sum_{j=t}^{t+D} |m_j-m_{j-1}|\\
 \text{subject to}\quad & \sum_{j=1}^{t} l^D_j\le \sum_{j=1}^{t} m_j \quad \quad\quad\quad\quad\quad \quad   \nonumber\\
 &  \sum_{j=1}^{t+D} m_j = \sum_{j=1}^{t} L_j  \nonumber\\
 &  0\le m_k \le M  \quad \quad\quad\quad\quad\quad \quad t\le k \le t+D\nonumber
\end{IEEEeqnarray}
Note that the deadline constraint (C1) and the release constraint (C2) are satisfied at time , since  . We apply the valley optimization (\ref{equn:gopt}) for  each  and local optimization (\ref{lopt}) for each time slot  where  for all . For each  we apply the valley optimization (\ref{equn:gopt}) for global valley in the interval  in order to execute all the accumulated workload. Algorithm~\ref{VFW} summarizes the procedures for VFW(). For each new time slot , Algorithm~\ref{VFW} detects a valley by checking whether the curves  and  intersects. If  is inside a valley, Algorithm~\ref{VFW} applies valley optimization (VOPT); local optimization (LOPT), otherwise. Figure~\ref{fig:solutionrandom}(b) illustrates the nature of solutions from VFW() for  and . Note that  is a parameter for the online algorithm VFW().



\begin{algorithm}
\caption{VFW()}
\label{VFW}
{\small{
\begin{algorithmic}[1]
\STATE ; 
\STATE ; 
\FOR {{\bf each} new time slot }
\STATE 
\STATE 
\IF { and  intersects  }
\STATE Calculate Area 
\IF {}
\STATE 
\ENDIF
\ELSIF { and }
\STATE 
\ELSE
\STATE 
\ENDIF
\IF{}
\STATE   LOPT(,,,)
\ELSE
\STATE   VOPT(,,,)
\ENDIF
\STATE 
\ENDFOR
\end{algorithmic}
}}
\end{algorithm}




\subsection{Analysis of the Algorithm}
We first prove the feasibility of the solutions from the VFW() algorithm and then analyze the competitive ratio of this algorithm with respect to the offline formulation~(\ref{equn:opt3}). First, we have the following theorem about the feasibility.


\begin{theorem}
\label{theorem:online3}
The VFW() algorithm gives feasible solution for any .
\end{theorem}

\begin{proof}
We prove this theorem inductively by showing that the choice of any feasible  from an optimization applied in the interval  do not result in infeasibility in the optimization applied in the next time slot . Initially, the optimization in VFW() is applied for the interval  with  for . Hence the optimization applied in the intervals  gives feasible   because  for .

Now suppose the VFW() gives feasible  in an interval . We have to prove that there exists feasible choice for  for the optimization applied at . The deadline constraint (C1) and the release constraint (C2) are satisfied for . Hence, . Since , . Thus for any feasible choice of , we can always obtain feasible solution for  such that the above inequality holds.
\end{proof}


We now analyze the competitive ratio of the online algorithm with respect to the offline formulation~(\ref{equn:opt3}). We denote the operating cost of the solution vectors  and  by  , switching cost by  and total cost by   . We have the following lemma.


\begin{lemma}
\label{lemma:online24}

\end{lemma}

\begin{proof}
Switching cost at time  is , since . Then   where .
\end{proof}

Let  and  be the offline solution vectors from optimization (\ref{equn:opt3}). The following theorem proves that the competitive ratio of the VFW() algorithm is bounded by a constant with respect to the offline formulation~(\ref{equn:opt3}).



\begin{theorem}
\label{theorem:online1}
.
\end{theorem}

\begin{proof}
Since the offline optimization assigns all the workload in the  interval, , where we used  for all . Hence .

In the online algorithm, we set  and   for all . Hence by lemma~\ref{lemma:online24}, we have .
\end{proof}





\section{Generalized Capacity Provisioning}
We now consider the general case where the deadline requirements are not same for all the jobs in a workload. Let  be the maximum possible deadline.
We decompose the workload according to their associated deadline. Suppose  be the portion of the workload released at time  and has deadline  for . We have .


The workload to be executed at any time slot  can come from different previous slots  where  as illustrated in Figure~\ref{fig:fine-grained}(a). Hence we redefine the deadline curve  and represent it by . Assuming  if , we define . Then the offline formulation remains the same as formulation (\ref{equn:opt3}) with the deadline curve  replaced by .
\begin{IEEEeqnarray}{cLl}
\label{equn:finegrained}
 \text{min}_{x_t,m_t}\quad & \sum_{t=1}^T  m_tC(x_t/m_t) + \beta \sum_{t=1}^T |m_t-m_{t-1}| &\\
 \text{subj. to}\quad & \sum_{j=1}^{t} l'_j \le \sum_{j=1}^{t} x_j \le \sum_{j=1}^{t} L_j  & \forall t  \nonumber\\
 &  \sum_{j=1}^{T} x_j = \sum_{j=1}^{T} L_j  &  \nonumber\\
 &  0\le x_t \le m_t \le M  &\forall t  \nonumber
\end{IEEEeqnarray}

We now consider the online case. Delaying the workload up to their maximum deadline may increase the switching cost since it may increase the variation in the workload compared to the original workload (see Figure~\ref{fig:fine-grained}(b)). Hence at each time we need to determine the optimum assignment and capacity that reduces the switching cost from the original workload while satisfying each individual deadline. We can apply the VFW() algorithm from the previous section with  where  is the minimum deadline for the workload. If  is small, VFW() does not work well because  becomes too small to detect a valley. Hence we use a novel approach for distributing the workload  over the  slots such that the change in the capacity between adjacent time slots is minimal (see Figure~\ref{fig:fine-grained}(c)). We call this algorithm as Generalized Capacity Provisioning (GCP) algorithm.

\begin{figure}[!t]
\begin{center}
\includegraphics[width=3.4in]{fine-grained.png}
\caption{Illustration of workload with different deadline requirements. (a) workload released at different times have different deadlines, (b) the delayed workload , may increase the switching cost due to large variation, (c) distribution of workload in adjacent slots by GCP to reduce the variation in workload.}
\label{fig:fine-grained}
\end{center}
\end{figure}


In the GCP algorithm, we apply optimization to determine  at each time slot  and make . The optimization is applied over the interval  since at time slot  we can have workload that has deadline up to  slots. Hence at each time , the released workload is a vector of  dimension. Let,  where  if there is no workload with deadline  at time . Let  be the vector of unassigned workload released up to time . The vector  is updated from  at each time slot by subtracting the capacity  and then adding .  Note that  is subtracted from the vector   in order to use unused capacity  to execute already released workload at time  by following EDF policy (see lines 4-17 in Algorithm~\ref{GCP}).  Let  be the vector after subtracting  with  and  for . Then  where  if . Then the optimization GCP-OPT(, , ) applied at each   over the interval  is as follows:
\begin{IEEEeqnarray*}{cll}
\label{equn:fine-grained}
 \text{min}_{m_t} & (e_0 + e_1)\sum_{j=t}^{t+\nu} m_{j} + \beta \sum_{j=t}^{t+\nu} |m_{j}-m_{j-1}|& \quad \quad \IEEEyessubnumber\\
 \text{subject to} & \quad  \sum_{j=0}^{\nu} m_{t+j} = \sum_{j=0}^{\nu} y_{j,t}  & \IEEEyessubnumber \\
& \quad \sum_{k=0}^{j} m_{t+k}  \ge \sum_{k=0}^{j} y_{k,t}  \qquad 0\le j\le \nu-1 & \IEEEyessubnumber\\
&  \quad 0\le m_{t+j} \le M  \qquad \qquad 0\le j \le \nu & \IEEEyessubnumber
\end{IEEEeqnarray*}

Note that the optimization (\ref{equn:fine-grained}) solves for  values. We only use  as the capacity and assignment of workload at time . Algorithm~\ref{GCP} summarizes the procedures for GCP. The GCP algorithm gives feasible solutions because it works with the unassigned workload and constraint (7c) ensures deadline constraint (C1) and constraint (7b) ensures the release constraint (C2). The competitive ratio for the GCP algorithm is same as the competitive ratio for VFW() because in GCP,  and release constraint (C2) holds at every  making .


\begin{algorithm}[!t]
\caption{GCP}
\label{GCP}
{\small{
\begin{algorithmic}[1]
\STATE 
\STATE 
\FOR {{\bf each} new time slot }
\STATE           \COMMENT{ represents the unused capacity}
\FOR { to }
\IF { }
\STATE 
\ELSE
\STATE 
\IF { }
\STATE 
\ELSE
\STATE 
\ENDIF
\ENDIF
\ENDFOR
\STATE 
\STATE   GCP-OPT(, , )
\STATE 
\ENDFOR
\end{algorithmic}
}}
\end{algorithm}




\section{Extension for Long Jobs}
In this section, we extend our model for `Long Jobs'. By {\it long jobs} we mean the jobs that have length greater than the time slot length  and each of which has a given deadline requirement greater than its length. To extend the model for long jobs we estimate the length of the long jobs, decompose the long jobs into small pieces () and assign deadline to each of them.




\subsection{Estimation of Execution Time}
If all the jobs are short interactive jobs with execution time less than the time-slot length, then we do not need to estimate the completion time of the jobs. But for a mix of short and long jobs we need estimation.




Since our targeted workload is MapReduce, we present a method for estimating execution time of a MapReduce job.  The MapReduce performance model is illustrated in Figure~\ref{fig:mapreduce}. A MapReduce job  is defined in \cite{Estimation_MapReduce} as a 7 tuple , where  is the size of map input data;  is the size of intermediate shuffle data;  is the size of output reduce data;  is the number of mappers that  is divided into;  is the number of reducers assigned for  to output;  is the running time of a mapper with input size ;  is the running time of a reducer with input size .  We compute the number of map and reduce tasks by dividing the input size  and output size  by the HDFS (Hadoop Distributed File System) block size respectively. Let ,  and  be the data read rate, data output rate and network transfer rate respectively. Then the execution times of map, shuffle and reduce tasks can be estimated by the following equations \cite{Estimation_MapReduce}.
\begin{IEEEeqnarray*}{ll}
\mathcal{T}_{m} = \frac{S}{XV_i} + f(\frac{S}{X}) + \frac{S'}{XV_o}&\\
\mathcal{T}_{s} = \frac{S'}{XYV_n}&\\
\mathcal{T}_{r} = g(\frac{S'}{Y}) + \frac{S''}{YV_o}&
\end{IEEEeqnarray*}

\begin{figure}[!t]
\begin{center}
\includegraphics[width=3.3in]{mapreduce.png}
\caption{MapReduce Performance Model.}
\label{fig:mapreduce}
\end{center}
\end{figure}

The map and reduce tasks run in parallel and may need several rounds to finish if the total number of available task slots is less than the number of mappers or reducers. If at most  mappers and  reducers are completed at each round, then the number of rounds of map and reduce tasks are  and  respectively. Based on whether the reducers have to wait for data transfer to complete, we have two cases. If , reducers have to wait for data transfers to complete and when , reducers do not need to wait for completion of mappers except during the first round. Then the estimated execution time for job  is,













\subsection{Decomposition and Deadline Assignment}
The long jobs can be preemptive and non-preemptive. Based on these two types we have two ways to decompose and assign deadlines to them.

\subsubsection*{Preemptive Jobs}
Let  be a preemptive job with execution time  (), release time  and deadline  (in terms of number of slots). Then the length of the job  is  time slots. Since the job is preemptive, we safely decompose it into small pieces  where  for . We assign the deadline for each of the small pieces to  (see Figure~\ref{fig:longjob}(a)). We set the release time of the first piece  and the release times of the other pieces to  for . Since a piece  is released after its preceding piece , this technique satisfies any precedence constraint the particular job may have.


\begin{figure}[!ht]
\centerline{\subfigure[Preemptive Jobs]{\includegraphics[width
=1.6in]{premptive.png}
}
\hfil
\subfigure[Non-preemptive Jobs]{\includegraphics[width=1.6in]{nonpremptive.png}
}}
\caption{Release times and deadlines for pieces of Long Jobs.}
\label{fig:longjob}
\end{figure}














\subsubsection*{Non-preemptive Jobs}
To make scheduling decision for a job , we consider it to be consisting of  small pieces where  for  and . We schedule the first chunk  with deadline  and suppose that our algorithm schedules it at time  (see Figure~\ref{fig:longjob}(b)). Then we assign the release time of the other pieces  for  to be  and assign deadline  for each of them. Since the deadline is zero for the later pieces and they are released as soon as the previous piece finishes, the algorithm ensures enough capacity for the execution of the job without preemption.












\section{Simulation}
In this section, we evaluate the cost incurred by the VFW() and GCP algorithm relative to optimal solution in the context of workload generated from realistic data. First, we motivate our evaluation by a detailed analysis of simulation results. Then in Section VII, we validate the simulation results by performing experiments on a Hadoop cluster.



\subsection{Simulation Setup}
We use realistic parameters in the simulation setup and provide conservative estimates of cost savings resulting from our proposed VFW() and GCP algorithms.



\subsubsection*{Cost benchmark}
Currently data centers typically do not use dynamic capacity provisioning based on the variation of the workload \cite{9}. A naive approach for capacity provisioning is to follow the workload curve and determine the capacity and assignment of workload accordingly. Clearly it is not a good approach because for capacity provisioning it does not take into account the cost incurred due to switching. Yet this is a very conservative estimate as it does not waste any execution capacity and meets all the deadline. We compare the total cost from the VFW() and GCP algorithms with the `follow the workload' () strategy and evaluate the cost reduction.



\subsubsection*{Cost function parameters}
The total cost is characterized by  and  for the operating cost and  for the switching cost. In the operating cost,  represents the proportion of the fixed cost and  represents the load dependent energy consumption.  The energy consumption of the current servers is dominated by the fixed cost \cite{19}. Therefore we choose  and . The switching cost parameter  represents the wear-and-tear due to changing power states in the servers. We choose  for slot length of 5 minutes such that it works as an estimate of the time a server should be powered down (typically one hour \cite{9,21}) to outweigh the switching cost with respect to the operating cost.



\subsubsection*{Workload description}
We use two publicly available MapReduce traces as examples of dynamic workload. The MapReduce traces were released by Chen et al. \cite{n4} which are produced from real Facebook traces for one day (24 hours) from a cluster of 600 machines. We count the number of different types of job submissions over a time slot length of 5 minutes to find the released workload curve (Figure~\ref{fig:workload}). We then use the length estimation to find the actual workload curve showing active jobs over time and use that as a dynamic workload (Figure~\ref{fig:workload}) for simulation. The two samples we use represent strong diurnal properties and have variation from typical workload (Workload A) to bursty workload (Workload B). The released jobs will be delayed to reduce the variations in the active workload curve.


\begin{figure}[!t]
\centerline{\subfigure[Workload A]{\includegraphics[width
=1.7in]{workload_a_.png}
}
\hfil
\subfigure[Workload B]{\includegraphics[width=1.7in]{workload_b_.png}
}}
\caption{Illustration of the MapReduce traces as dynamic workload used in the experiments. The active jobs are shown with job length estimation.}
\label{fig:workload}
\end{figure}


\subsubsection*{Length estimation parameters}
Since we do not know any parameters from the Facebook cluster, we assume that the cluster has enough task slots so that all the map and reduce tasks are completed in the first round. Hence  and . HDFS block size is typically 128MB. So  and . We assume  and  to be linear,  and  where s/MB and s/MB \cite{Estimation_MapReduce}. We use typical values for data rates, ,  and  \cite{n9,Estimation_MapReduce}. For our experiments, we consider the jobs to be non-preemptive. Hence we do not need to decompose the jobs and only assign deadlines to them. Figure~\ref{fig:workload} shows the variation in active workload over time with estimation of job lengths.






\begin{table*}[!t]
  \centering
  \caption{Cluster Sizes and Deadlines for Workload Classification for GCP}
   \begin{tabular}{c|r|r|r|r|r|r|r|r|r|r|c}
    \hline \hline
    Cluster & \multicolumn{5}{c|}{Workload A}        & \multicolumn{5}{c|}{Workload B}        & Deadline \\
    \hline
          & \# Jobs & \% Jobs &  (MB) &  (MB) &  (MB) & \# Jobs & \% Jobs &  (MB) &  (MB) &  (MB) & (\# slots) \\ \hline
    1     & 5691  & 96.56 & 0.02  & 0.00  & 0.67  & 6313  & 95.10 & 0.02  & 0.00  & 0.48  & 1 \\
    2     & 116   & 1.97  & 44856.77 & 15493.69 & 83.89 & 223   & 3.36  & 39356.46 & 6594.93 & 99.26 & 2 \\
    3     & 27    & 0.46  & 57121.85 & 148012.87 & 16090.40 & 41    & 0.62  & 110076.24 & 282.08 & 1.60  & 3 \\
    4     & 23    & 0.39  & 125953.59 & 0.00  & 51.89 & 25    & 0.38  & 379363.01 & 0.00  & 521.45 & 4 \\
    5     & 19    & 0.32  & 0.33  & 0.00  & 49045.29 & 16    & 0.24  & 0.04  & 0.00  & 40355.53 & 5 \\
    6     & 8     & 0.14  & 207984.10 & 414045.45 & 3095.56 & 7     & 0.11  & 132529.27 & 383548.19 & 31344.38 & 6 \\
    7     & 5     & 0.08  & 541522.77 & 0.00  & 0.05  & 4     & 0.06  & 258152.65 & 1020741.05 & 22631.52 & 7 \\
    8     & 3     & 0.05  & 0.05  & 0.00  & 203880.59 & 3     & 0.05  & 0.29  & 0.00  & 311410.40 & 8 \\
    9     & 1     & 0.02  & 7201446.27 & 48674.26 & 0.10  & 3     & 0.05  & 1182734.09 & 3.93  & 0.01  & 9 \\
    10    & 1     & 0.02  & 934594.27 & 8413335.44 & 0.06  & 3     & 0.05  & 0.56  & 0.00  & 622103.12 & 10 \\
    \hline
    \end{tabular}\label{table:gcp}\end{table*}





\subsubsection*{Deadline assignment}
For VFW(), the deadline  is uniform and is assigned in terms of number of slots the workload can be delayed. For our simulation, We vary  from  slots which gives latency from 5 minutes upto 1 hour. This is realistic as deadlines of 8-30 minutes for MapReduce workload have been used in the literature \cite{n10,n11}. For GCP, we use k-means clustering to classify the workload into 10 groups based on the map, shuffle and reduce bytes (). The characteristics of each group are depicted in Table~\ref{table:gcp}. From Table~\ref{table:gcp}, it is evident that smaller jobs dominate the workload mix, as discussed in Section IIA. For each new class of jobs we assign a deadline from  slots such that smaller class has larger deadline and larger class of jobs has smaller deadline. The deadline for a job should not be less than the length of a job. If the assigned deadline is less than the job length, we update the deadline to be equal to the length of the job.





































\subsection{Analysis of the Simulation}
We now analyze the impact of different parameters on cost savings provided by VFW() and GCP. We then compare VFW() and GCP for uniform deadline (GCP-U).




\subsubsection*{Impact of deadline}
The first parameter we study is the impact of different deadline requirements of the workload on the cost savings. Figure~\ref{fig:deadline} shows that even for deadline  as small as 2 slots, the cost is reduced by 40\% for GCP-U, 20\% for VFW() while the offline algorithm gives a cost saving of 60\% compared to the naive algorithm. It also shows that for all the algorithms, large  gives more cost savings as more workload can be delayed to reduce the variation in the workload. As  grows larger the cost reduction from GCP-U and VFW() approaches offline cost saving which is as much as 70\%. For VFW(), the cost saving is always less than GCP-U for both the workload.





\begin{figure}[!t]
\centerline{\subfigure[Workload A]{\includegraphics[width
=1.7in]{deadline_a_.png}
}
\hfil
\subfigure[Workload B]{\includegraphics[width=1.7in]{deadline_b_.png}
}}
\caption{Impact of deadline on cost incurred by GCP-U, Offline and VFW() with . }
\label{fig:deadline}
\end{figure}




\subsubsection*{Impact of  for VFW()}
The parameter  is used as a lookahead to detect a valley in the VFW() algorithm. If  is large, valley detection performs well but it may be too late to fill the valley due to the deadlines. On the other hand if  is small, valley detection does not work well because the capacity has already gone down to the lowest value. Figure~\ref{fig:valleydetect} illustrates the valley detection for small  and large . Although the cost savings from VFW() largely depends on the nature of the workload curve, Figure~\ref{fig:delta} shows that  is a conservative estimate for better cost savings.



\begin{figure}[!t]
\begin{center}
\includegraphics[width=3.0in]{valley.png}
\caption{Valley detection for (a) small  and (b) large  for VFW().}
\label{fig:valleydetect}
\end{center}
\end{figure}


\begin{figure}[!t]
\centerline{\subfigure[Workload A]{\includegraphics[width
=1.7in]{delta_a_.png}
}
\hfil
\subfigure[Workload B]{\includegraphics[width=1.7in]{delta_b_.png}
}}
\caption{Impact of  for VFW() with deadline . }
\label{fig:delta}
\end{figure}


\subsubsection*{Performance of GCP}
We evaluated the cost savings from GCP by assigning different deadline by classifying the workload as shown in Table~\ref{table:gcp}. For conservative estimates of deadline requirements (1-10), we found 47.66\% cost reduction for Workload A and 45.65\% cost reduction for Workload B each of which remains close to the offline optimal solutions.






\subsubsection*{Comparision of VFW() and GCP}
We compare GCP for uniform deadline (GCP-U) with VFW() for . Figure~\ref{fig:deadline} illustrates the cost reduction for VFW() and GCP-U with different deadlines . For both the workload, GCP-U performs better than VFW(). However for some workload, valley filling with workload as in VFW() can be more beneficial than provisioning capacity for  consecutive slots as in GCP. Hence we conclude that the comparative performance of the online algorithms depends largely on the nature of the workload. Since both the algorithms are based on linear program, they take around 10-12ms to compute schedule at each step.















\section{Experimentation}
In this section, we validate our algorithms on MapReduce workload by provisioning capacity on a Hadoop cluster. We evaluate the cost-savings by energy consumption calculated from common power model using different measured metrics.

\subsection{Experimental Setup}
We setup a Hadoop cluster (version 0.20.205) consisting of 35 nodes on Amazon's Elastic Compute Cloud (EC2) \cite{n1,n2}. Each node in the cluster is a small instance with 1 virtual core, 1.7 GB memory, 160 GB storage. We configured one node as master and four core nodes to contain the Hadoop DFS and the other 30 nodes as task nodes. The provisioning is done on the task nodes dynamically. We used the Amazon Elastic MapReduce service for provisioning capacity on the Hadoop cluster. Amazon Elastic MapReduce takes care of provisioning machines and migration of tasks between machines while keeping all data available. We used the Statistical Workload Injector for MapReduce (SWIM) \cite{n4} to generate the MapReduce workload for our cluster using the Facebook traces from Figure~\ref{fig:workload}(a). We run our experiment for 4 hours with slot length of 5 minutes. For the traces of Figure~\ref{fig:workload}(a), 602 jobs were released in the first 48 slots.

We first schedule the jobs and provision the task nodes by the `follow the workload' strategy. We then schedule the same jobs and provision the task nodes using our algorithms as illustrated in Figure~\ref{fig:solution}. In order to make comparison between VFW() and GCP algorithms we used a uniform deadline of 10 minutes (). In each of the experiments, we measured the seven metrics (available from Amazon Cloudwatch) for each of the `running' nodes in each time slot over the time interval of 4 hours and 10 minutes (50 slots). In the last 2 slots, the capacity of the task nodes were provisioned to zero for the `follow the workload' algorithm while our algorithms execute the delayed workload in those slots. All the jobs released in the first 48 slots were completed before the end of 50th slot. The seven metrics that are available for measurement for each virtual machines are: CPUUtilization, DiskReadBytes, DiskReadOps, DiskWriteBytes, DiskWriteOps, NetworkIn and NetworkOut.







\begin{figure*}[!t]
\centerline{\subfigure[Follow the workload]{\includegraphics[width =
2.2in]{experiment_follow0_D2.png}
}
\hfil
\subfigure[VFW()]{\includegraphics[width=2.2in]{experiment_vfw0_D2.png}
}
\hfil
\subfigure[GCP-U]{\includegraphics[width =2.2in]{experiment_gcp0_D2.png}
}
}
\caption{The solutions for (a) Follow the workload, (b) VFW() and (c) GCP-U algorithms with uniform deadline  slots,  and time slot = 5 mins.}
\label{fig:solution}
\end{figure*}










\subsection{Experimental Results}
We now discuss the results from the experimentation and compare the energy consumption between different algorithms.




\subsubsection*{Power Metering}
We use the general power model to evaluate energy consumption for the algorithms \cite{n7,n8}. The energy consumed by a virtual machine is represented as the sum of the energy consumption for utilization, disk operations and network IO,

where the energy consumption is over the duration . The energy consumption for each of the components over a time slot  (of length ) can be computed by the following equations.
\begin{IEEEeqnarray}{lll}
E_{util,vm}(t) &= & \alpha_{cpu} u_{cpu}(t) + \gamma_{cpu} \\
E_{disk,vm}(t) &= & \alpha_{rb} b_r(t) + \alpha_{wb} b_w(t) \nonumber\\
& & + \alpha_{ro} n_r(t) + \alpha_{wo} n_w(t) + \gamma_{disk} \nonumber\\
E_{net,vm}(t) &= & \alpha_{ni} b_{in}(t) + \alpha_{no} b_{out}(t) + \gamma_{net}\nonumber
\end{IEEEeqnarray}
where  is the average utilization,  and  are the total bytes read and written to disk,  and  are the total number of disk read and writes and  and  are the total bytes of network IO for the virtual machine over the time interval . Since the difference in energies for disk read and write and network input and output are negligible \cite{n7}, we use common parameters , , and  by taking the sum of the respective values.  We normalize each of these values with their respective maximum values (in the interval ) so that each of these become a fraction between 0 and 1 and can be put in equation~(\ref{eqn:energy1}),
\begin{IEEEeqnarray}{lll}
\label{eqn:energy2}
E_{vm}(t) &= & \alpha_{cpu} u_{cpu}(t) + \gamma_{cpu} \\
& & + \alpha_{disk} u_{disk}(t) + \gamma_{disk} + \alpha_{dops} u_{dops}(t) + \gamma_{dops} \nonumber\\
& & + \alpha_{net} u_{net}(t) + \gamma_{net} \nonumber
\end{IEEEeqnarray}
where ,  and  represent the normalized values of , , and  respectively.
If  machines are active at time slot , then the total energy consumed over the time interval  can be computed using the following equation:

where  is the energy consumed at machine  over time slot . To compute energy consumption, we used parameters from \cite{n8} listed in Table~\ref{table:parameter}. Typical values are used for cpu utilization, disk I/O and network I/O. Idle disk/network powers are negligible with respect to dynamic power and scale of workload.



\begin{table}[!ht]
  \centering
  \caption{Power Model Parameters}
    \begin{tabular}{c|l|c}
    \hline\hline
    Parameter & Comment & Value   \\
    \hline
     &  Scaling factor: Utilization    &   25.70      \\
     &   Scaling factor: Disk Rd/Wr.     &   7.21        \\
     &  Scaling factor: Disk Op.     &      0     \\
     &  Scaling factor: Network IO     &      0.66      \\
     &   Idle cpu power consump.    &    60.30         \\
    ,  &  Idle disk power consump.    &    0      \\
     &   Idle network power consump.   &        0    \\
    \hline
    \end{tabular}\label{table:parameter}\end{table}




The total energy consumption and the \% reduction with respect to `follow the workload' in each of the metrics for different schedules are illustrated in Table~\ref{table:reduction}. For the period of 4 hours 10 minutes (50 slots), GCP algorithm gives energy reduction of 12\% which is significantly better than the reduction of 6.02\% from the VFW() algorithm. The reductions from both the algorithms are far better with respect to workload schedule without provisioning. Table~\ref{table:reduction} also shows that variation in CPU utilization, Disk I/O and Network I/O across different algorithms. This variation results from the difference in capacity provisioning across algorithms that changes migration of jobs and disk I/O in the cluster. Figure~\ref{fig:energyconsumption} illustrates the average energy consumption within each slot over the time interval showing significant reduction in the peak energy consumption. As the provisioning algorithms cut off peaks from the workload and provision the machines without wasting computation capacity, they reduce the peak energy consumption for the data center.


\begin{table*}[!t]
  \centering
  \caption{Total energy consumption and the total values for different Metrics from the cluster for different schedule}
    \begin{tabular}{l|c|c|c|c|c|c}
    \hline\hline
    Metrics & No Provisioning & Follow  & VFW() &  \% Reduction & GCP-U &  \% Reduction \\
    \hline
    Energy Consumption(kWh) &   8.60    &   4.46    &  4.19     &    6.02   & 3.93 & 11.96 \\
    CPUUtilization(sum) &   32505.95    &   22805.98    &  21014.51     &     7.86  & 20400.02& 10.55 \\
    DiskReadBytes(GB) &   0.25    &   12.95    &   7.56    &     41.64  & 3.85 & 70.29 \\
    DiskWriteBytes(GB) &  10.42     &   8.01    &   8.44    &    -5.48   & 6.55 & 18.19\\
    DiskReadOps(count) &  18883     &   1109320    &   710451    &    35.96 & 396070 & 64.30   \\
    DiskWriteOps(count) &  1746347     &   1134108    &   1020343    &    10.03 & 901860 &  20.48  \\
    NetworkIn(GB) &  45.69     &   42.30    &   43.69    &    -3.29  & 42.88 & -1.38 \\
    NetworkOut(GB) &  44.21     &  42.45     &   38.64    &    8.97  & 41.48 &  2.29\\
    \hline
    \end{tabular}\label{table:reduction}\end{table*}












\begin{figure}[!t]
\begin{center}
\includegraphics[width=2.5in]{energy_time.png}
\caption{Average energy consumption from the cluster with time slots of 5 minutes, over a period of 4 hours.}
\label{fig:energyconsumption}
\end{center}
\end{figure}





\begin{comment}

\subsubsection*{Cluster size and time interval}
We choose the cluster size to be 35 and the time interval to be the first 4 hours. The original traces released by Chen et al. \cite{n4} came from a 600 node cluster and using their technique we generate workload for our cluster of 35 nodes. However their technique has a `system sizing issue' which we have encountered while running the trace for a long period (24 hours). The problem is that their method can scale the input/shuffle/output bytes but does not scale the size (number) of the workload. For this reason, some of the jobs fail when the workload size grows larger in the later time slots during the execution. That's why we choose a small time interval of (4 hours) in order to ensure that none of the jobs fail during the experiment. Given the deadline of 10 minutes, our choices of schedule length and cluster size are sufficiently long that the original workload variation is captured over the 4 hour run while exploiting the slack to produce gains in energy savings (Figure~\ref{fig:solution}).







\subsubsection*{Choice of deadline, D}
We choose the deadline requirement to be 10 minutes for the MapReduce workload. This is realistic because MapReduce workloads have deadlines in the range of minutes as deadlines from 8-30 minutes for these workloads have been used in the literature \cite{n9,n10,n11,n12}. Moreover deadline may vary for different applications and for some of them the deadline can be zero. Our GCP algorithm is designed considering all these cases and it works well for any kind of deadline/workload mix as demonstrated by simulation and experiment.
Again, the deadline requirement for some applications e.g. High Performance Computing (HPC) is large in order of hours and for some applications it is small in order of minutes \cite{n12,24}. Hence we study the impact of different deadline requirements varying from 10 minutes to 1 hour in the simulation (see Figure~\ref{fig:deadline}). Our simulation results highlight that even if the deadline is as small as one slot (10 minutes), we save around 40\% energy consumption (over 24 hours) compared to without using dynamic deferral.


\end{comment}


\section{Related Work}
With the importance of energy management in data centers, many scholars have applied energy-aware scheduling because of its low cost and practical applicability. In energy-aware scheduling, most work tries to find a balance between energy cost and performance loss through DVFS (Dynamic Voltage and Frequency Scaling) and DPM (Dynamic Power Management), which are the most common system-level power saving methods.  Beloglazov et al. \cite{1} give the taxonomy and survey on energy management in data centers. Dynamic capacity provisioning is part of DPM technique.  Chase et al. \cite{2} introduce the executable utility functions to quantify the value of performance and use economic approach to achieve resource provisioning.  Pinheiro et al. \cite{3} consider resource provisioning in both application and operating system level. They dynamically turn on or turn off nodes to adapt to the changing load, but do not consider the switching cost.

Most work on dynamic capacity provisioning for independent workload uses models based on queueing theory \cite{4,8}, or control theory \cite{7,29}. Recently Lin et al. \cite{9} used more general and common energy model and delay model and designed a provisioning algorithm for service jobs (e.g. HTTP requests) considering switching cost for the machines. They proposed a lazy capacity provisioning (LCP) algorithm which dynamically turns on/off servers in a data center to minimize energy cost and delay cost for scheduling workload. However their algorithm does not perform well for high peak-to-mean ratio (PMR) of the workload and does not provide bound on maximum delay. Moreover, LCP aims at minimizing the average delay while we regard latency as the deadline constraint. Instead of penalizing the delay, we purposely defer jobs within deadline in order to reduce the switching cost of the servers.



Many applications in real world require delay bound or deadline constraint e.g. see Lee et al. \cite{24}. In the context of energy conservation, deadline is usually a critical adjusting tool between performance loss and energy consumption. Energy efficient deadline scheduling was first studied by Yao et al. \cite{10}. They proposed algorithms, which aim to minimize energy consumption for independent jobs with deadline constraints on a single variable-speed processor. After that, a series of work was done to consider online deadline scheduling in different scenarios, such as discrete-voltage processor, tree-structured tasks, processor with sleep state and overloaded system \cite{11,12}. In the context of data center, most prior work on energy management merely talks about minimizing the average delay without any bound on the delay. Recently, Mukherjee et al. \cite{17} proposed online algorithms considering deadline constraints to minimize the computation, cooling and migration energy for machines.  Goiri et al. \cite{Goiri} considered only batch jobs and proposed GreenSlot, a scheduler with deadline requirements for the jobs. GreenSlot predicts the amount of solar energy that will be available in near future and schedules the workload to maximize the green energy consumption while meeting the jobs' deadline. However these works are on job assignment problem and not on dynamic resource provisioning problem, where the number of needed servers is given in advance.





Recently researchers have used scheduling with deferral to improve performance of MapReduce jobs \cite{n6,n11}. Although MapReduce was designed for batch jobs, it has been increasingly used for small time-sensitive jobs. Delay scheduling with performance goals was proposed by Zaharia et al. \cite{n6} for scheduling jobs inside a Hadoop cluster with given resources. Verma et al. introduced a SLA-driven scheduling and resource provisioning framework considering given soft-deadline requirements for the MapReduce jobs \cite{n9,n10}. In contrast to these works, we consider hard-deadlines and schedule jobs within those deadlines and provision capacity to save energy.
Recently, Chen et al. \cite{n5} identified a large class of interactive MapReduce workload and proposed policies for scheduling batch and small interactive jobs in separate cluster without any provisioning mechanism for the machines in the cluster. In contrast, we propose provisioning algorithms for the mix of batch and interactive jobs under bounded latency with constant competitive ratio.




















\section{Conclusion}
We have shown that significant reduction in energy consumption can be achieved by dynamic deferral of workload for capacity provisioning inside data centers. We have proposed two new algorithms, VFW() and GCP, for provisioning the capacity and scheduling the workload while guaranteeing the deadlines. The algorithms take advantage from the flexibility in the latency requirements of the workloads for energy savings and guarantee bounded cost and bounded latency under very general settings - arbitrary workload, general deadline and general energy cost models. Further both the VFW() and GCP algorithms are simple to implement and do not require significant computational overhead. Additionally, the algorithms have constant competitive ratios and offer noteworthy cost savings as proved by theory and demonstrated by simulations respectively. We have validated our algorithms on MapReduce workload by provisioning capacity on a Hadoop cluster. For a small interval of 4 hours, we found 6.02\% total energy savings for VFW() and 12\% for GCP with respect to the naive `follow the workload' approach. Both the algorithms achieve more than 50\% reduction in energy consumption with respect to `no provisioning' which is a common practice for the current data center providers. Although we have used MapReduce workload for validation, our algorithms can be applied for any workload as data centers have separate (physical/virtual) clusters for MapReduce and non-MapReduce jobs. The provisioning can be done on each such cluster. In order to reduce the energy consumption, the data center providers should provision their capacity (physical/virtual) and utilize the flexibilities from SLAs via dynamic deferral.





\section*{Acknowledgment}
This work was sponsored in part by the Multiscale Systems
Center (MuSyC) and NSF Variability Expedition.

{\small{




\begin{thebibliography}{1}
\bibitem{23}
\emph{Server and Data Center Energy Efficiency,} Final Report to Congress, U.S. Environmental Protection
Agency, 2007.

\bibitem{22}
Z. Liu, M. Lin, A. Wierman, S. Low, and L. Andrew, {\emph Greening Geographical Load Balancing,} in Proc. ACM
SIGMETRICS, 2011.
\bibitem{25}
C. Stewart and K. Shen, \emph{Some Joules Are More Precious Than Others: Managing Renewable Energy in the
Datacenter,} in Proc. Power Aware Comput. and Sys., October 2009.
\bibitem{26}
E. Pakbaznia and M. Pedram, \emph{Minimizing data center cooling and server power costs}, in Proc. ISLPED, 2009.
\bibitem{30}
R. K. Sharma, C. E. Bash, C. D. Patel, R. J. Friedrich, J. S. Chase, \emph{Balance of Power: Dynamic Thermal Management for Internet Data Centers,} IEEE Internet Computing, 9(1), pp. 42-49, 2005.
\bibitem{17}
T. Mukherjee, A. Banerjee, G. Varsamopoulos, and S. K. S. Gupta, \emph{Spatio-Temporal Thermal-Aware Job Scheduling to Minimize Energy Consumption in Virtualized Heterogeneous Data Centers}, Computer Networks, 53(17), 2009.
\bibitem{9}
M. Lin, A. Wierman, L. H. Andrew, E. Thereska, \emph{Dynamic right-sizing for power-proportional data centers}, in Proc. IEEE INFOCOM, 2011.

\bibitem{n9}
A. Verma, L. Cherkasova, R. Campbell, \emph{SLO- Driven Right-Sizing and Resource Provisioning of MapReduce Jobs}, in Proc. LADIS, 2011.

\bibitem{n10}
A. Verma, L. Cherkasova, R. Campbell, \emph{Resource Provisioning Framework for MapReduce Jobs with Performance Goals,} in Proc. Middleware, 2011.


\bibitem{n6}
M. Zaharia, D. Borthakur, J. S. Sarma, K. Elmeleey, S. Shenker, and I. Stoica, \emph{Delay Scheduling: A Simple Technique for Achieving Locality and Fairness in Cluster Scheduling}, in Proc. EuroSys, 2010.

\bibitem{n4}
Y. Chen, A. Ganapathi, R.Griffith, R. Katz, \emph{The Case for Evaluating MapReduce Performance Using Workload Suites,}
in Proc. IEEE MASCOTS, 2011.

\bibitem{n5}
Y. Chen, S. Alspaugh, D. Borthakur, R. Katz, \emph{Energy Efficiency for Large-Scale MapReduce Workloads with Significant Interactive Analysis,} in Proc. EuroSys, 2012.

\bibitem{Liu}
D. Xu and X. Liu, \emph{Geographic trough filling for Internet datacenters,} In Proc. of IEEE INFOCOM, 2012.


\bibitem{n3}
J. Dean and S. Ghemawat, \emph{MapReduce: Simplified Data Processing on Large Clusters}, Comm. of the ACM, 51(1), pp. 107-113, 2008.

\bibitem{20}
\emph{SPEC power data on SPEC website at http://www.spec.org.}

\bibitem{21}
P. Bodik, M. P. Armbrust, K. Canini, A. Fox, M. Jordan, and D. A. Patterson, \emph{A case for adaptive datacenters to conserve energy and improve reliability}, UCBerkeley, Tech. Report UCB/EECS-2008-127, 2008.

\bibitem{19}
L. A. Barroso, and U. H\"{o}lzle, \emph{The case for energy-proportional computing.} IEEE Computer, 40(12), pp. 33-37, 2007.

\bibitem{Estimation_MapReduce}
Y. Xiao, S. Jianling, \emph{Reliable Estimation of Execution Time of MapReduce Program}, China Communications, 8(6), pp 11-18, 2011.


\bibitem{n1}
Amazon Elastic MapReduce.
http://aws.amazon.com/elasticmapreduce/.

\bibitem{n2}
Apache Hadoop. http://hadoop.apache.org/.


\bibitem{n7}
A. Kansal, F. Zhao, J. Liu, N. Kothari, and A. Bhattacharya, \emph{Virtual Machine Power Metering and Provisioning,} in Proc. SoCC, 2010.

\bibitem{n8}
R. Lent, \emph{Evaluating the performance and power consumption of systems with virtual machines,} in Proc. IEEE CloudCom, Nov. 2011.


\bibitem{n11}
K. Kc and K. Anyanwu, \emph{Scheduling Hadoop Jobs to Meet Deadlines,} in Proc. IEEE CloudCom, 2010.



\bibitem{24}
C. B. Lee, and A. Snavely, \emph{Precise and realistic utility functions for user-centric performance analysis of schedulers}, in Proc. IEEE HPDC, 2007.









\bibitem{1}
A.~Beloglazov, R.~Buyya, Y.~C. Lee, A.~Zomaya, \emph{A taxonomy and survey of energy-efficient data centers and cloud computing systems}, Advances in Computers, Elsevier: Amsterdam, 2011.

\bibitem{2}
J. S. Chase, D. C. Anderson, P. N. Thakar, A. M. Vahdat, and R. P. Doyle, \emph{Managing energy and server resources in hosting centers}, in Proc. ACM SOSP, pp. 103-116, 2001.
\bibitem{3}
E. Pinheiro, R. Bianchini, E. Carrera, and T. Heath, \emph{Load balancing and unbalancing for power and performacne in cluster-based systems}, in Proc. Compilers and Operating Sys. for Low Power, 2001.
\bibitem{4}
A. Gandhi, M. Harchol-Balter, R. Das, and C. Lefurgy, \emph{Optimal power allocation in server farms}, in Proc. ACM Sigmetrics, 2009.
\bibitem{8}
D. Meisner, B. T. Gold, and T. F. Wenisch, \emph{The PowerNap Server Architecture}, ACM trans. Computer systems (TOCS), 29(1), 2011.
\bibitem{7}
Y. Chen, A. Das, W. Qin, A. Sivasubramaniam, Q. Wang, and N. Gautam, \emph{Managing server energy and operational costs in hosting centers}, in Proc. ACM Sigmetrics, 2005.

\bibitem{29}
R. Urgaonkar, U. C. Kozat, K. Igarashi, and M. J. Neely, \emph{Dynamic resource allocation and power management in virtualized data centers,} in Proc. IEEE/IFIP NOMS, 2010.


\bibitem{10}
F. Yao, A. Demers, and S. Shenker, \emph{A scheduling model for reduced CPU energy}, in Proc IEEE FOCS, pp. 374-382, 1995.

\bibitem{11}
H. L. Chan, J. W. Chan, T. W. Lam, L. K. Lee, K. S. Mak, P. W. Wong, \emph{Optimizing throughput and energy in online deadline scheduling}, ACM Trans. Algorithms 6(1), 1-10, 2009.

\bibitem{12}
X. Han, T. W. Lam, L. K. Lee, I. K. To and P. W. Wong, \emph{Deadline scheduling and power management for speed bounded processors}, Theor. Comput. Sci. 411(40-42), 3587-3600, 2010.

\bibitem{Goiri} I. Goiri et al. \emph{GreenSlot: Scheduling Energy Consumption in
Green Datacenters.} In Proc. of Supercomputing, November 2011.



\end{thebibliography}

}}












\begin{comment}

\section{Introduction}
This demo file is intended to serve as a ``starter file''
for IEEE conference papers produced under \LaTeX\ using
IEEEtran.cls version 1.7 and later.
I wish you the best of success.

\hfill mds

\hfill January 11, 2007

\subsection{Subsection Heading Here}
Subsection text here.


\subsubsection{Subsubsection Heading Here}
Subsubsection text here.

















\section{Conclusion}
The conclusion goes here.







\section*{Acknowledgment}


The authors would like to thank...









\begin{thebibliography}{1}

\bibitem{IEEEhowto:kopka}
H.~Kopka and P.~W. Daly, \emph{A Guide to \LaTeX}, 3rd~ed.\hskip 1em plus
  0.5em minus 0.4em\relax Harlow, England: Addison-Wesley, 1999.

\end{thebibliography}


\end{comment}

\end{document}
