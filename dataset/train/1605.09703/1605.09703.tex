In this section we give a variational formulation of the control problem of determining the optimal scheduler for a CTMDP. 
We show how to approximate statistically in an unbiased way the functional gradient of the time-bounded reachability probability, and give a convergent algorithm to achieve this. 





\subsection{Reachability probability as a functional}












As defined in Section \ref{sec:preliminaries}, a scheduler is a way of resolving non-determinism by associating a (time-dependent) probability to each action/ state pair. 
We will realise a scheduler as a vector $\mathbf{f}$ of  functions $f_{\alpha}: E \times [0,T] \rightarrow \mathbb{R}$, one for each action $\alpha \in \mathcal{A}$, where $E$ is the compact subset of $\mathbb{R}^n$ used to define $S$ for the PCTMDP formalism. The corresponding probability of an action $\alpha$ at a state $\vec{X}$ can be retrieved using the soft-max (logistic) transform as follows:
\begin{equation}
p_{\vec{X}}(\alpha \mid t) \equiv \sigma(t,\alpha,\vec{X}) = \frac{\exp(f_{\alpha}(\vec{X}, t))}{\sum_{\alpha' \in \mathcal{A}} \exp(f_{\alpha'}(\vec{X}, t))}, \qquad \vec{X} \in S, t\in [0,T]
\end{equation}
Given a scheduler $\sigma$, a CTMDP is reduced  to a CTMC $\mathcal{M}_{\sigma}$, and the problem of estimating the probability of a reachability property $\phi = \diamond_I G$ can be reduced to the computation of a transient probability for $\mathcal{M}_{\sigma}$ by standard techniques \cite{Baier2003}.
The satisfaction probability can be therefore viewed as a {\it functional} 
\[
Q\colon\mathcal{F}\rightarrow\mathbb{R}
\]
where $\mathcal{F}$ is the set of all possible scheduler functions.
The functional is defined explicitly as follows: consider a sample trajectory $\{s, a, t\}_n \equiv s_0\xrightarrow{\alpha_0,t_0}s_1\xrightarrow{\alpha_1,t_1}\ldots s_n\xrightarrow{\alpha_n,t_n}s_{n+1}$ from the CTMC $\mathcal{M}_{\sigma}$ obtained from the CTMDP by selecting a scheduler. Let $\phi= \diamond_I G$, $I=[t_1,t_2]$ be a reachability property, and denote by $ \{s, a, t\}_n \models \phi$ the fact that the trajectory reaches $G$ within the specified time bound. We can encode it in the following indicator function:
\begin{equation}
I_{\phi}(\{s, a, t\}_n) = 
\begin{cases}
1, \quad \{s, a, t\}_n \models \phi \\
0, \quad \mathrm{otherwise}.
\end{cases}
\end{equation}
Then the expected reachability value associated with the scheduler $\sigma$, represented by the vector of functions $\mathbf{f}=\{ f_\alpha\}_{\alpha\in\mathcal{A}}$, is defined as follows:
\begin{equation}
Q\left[\mathbf{f}(\vec{X}, t)\right]=E_{\mathcal{M}_{\sigma}}\left[I_{\phi}(\{s, a, t\}_n)\right],
\label{reward}
\end{equation}
where expectation is taken with respect to the distribution on trajectories of $\mathcal{M}_{\sigma}$.
Notice that in general it is computationally very hard to analytically compute the r.h.s.\ in the above equation, as it amounts to transient analysis for a time-inhomogeneous CTMC; we therefore need to resort to statistical model checking methods \cite{SB:Zuliani:2009:StatMC,MC:YounesSimmons:INFCOMP2006:statMC} to approximate in a Monte Carlo way the expectation in equation \eqref{reward}.

To formulate the continuous time control problem of determining the optimal scheduler, we need to define the concept of functional derivative.

\begin{definition}
Let $Q\colon\mathcal{F}\rightarrow\mathbb{R}$ be a functional defined on a space of functions $\mathcal{F}$. 
The {\it functional derivative} of $Q$ at $f\in\mathcal{F}$ along a function $g\in\mathcal{F}$, denoted by $\frac{\delta Q}{\delta f}$, is defined by 
\begin{equation}
\int \frac{\delta Q}{\delta f}(\vec{X}, t) \, g(\vec{X}, t) \, ds dt = \lim_{\epsilon \rightarrow 0} \frac{Q[f(\vec{X}, t) + \epsilon g(\vec{X}, t)] - Q[f(\vec{X}, t)]}{\epsilon}
\label{eq:directionalDerivativeApprox}
\end{equation}
whenever the limit on the r.h.s. exists.  \end{definition}
Notice that if we restrict ourselves to piecewise constant functions on a grid, the definition above returns the standard definition of gradient of a finite-dimensional function.
We can now give a variational definition of optimal scheduler
\begin{lemma}
An optimal scheduler $\sigma$ is associated with a function $f$ such that 
\begin{equation}
max_{g\in\mathcal{F}} \left\| \int \frac{\delta Q}{\delta f}(\vec{X}, t) \, g(\vec{X}, t) \, ds dt \right\|_2=0\label{varFormulation}
\end{equation}
where $\Vert\cdot\Vert_2$ denotes the $L^2$ norm on functions.
\end{lemma}
The variational formulation above allows us to attack the problem via direct optimisation through a gradient ascent algorithm, as we will see below.





















\subsection{Stochastic Estimation of the Functional Gradient}

It is well-known that a gradient ascent approach is guaranteed to find the global optimum of a convex objective function.
Gradient ascent starts from an initial solution which is updated iteratively towards the direction that induces the steepest change in the objective function; that direction is given by the gradient of the function.
For a functional $Q[f]$ the concept of gradient is captured by the functional derivative $\frac{\delta Q}{\delta f}$, which is a function of $\vec{X}, t$ that dictates the rate of change of the functional $Q$ when $f$ is perturbed at the point $(\vec{X}, t)$.
In the case of functional optimisation, the gradient ascent update will have the form:
\begin{equation}
f' = f + \gamma \frac{\delta Q}{\delta f}
\end{equation}
where $\gamma$ is the learning rate which controls the effect of each update, and $\frac{\delta Q}{\delta f}$ is the functional derivative of $Q$. Unfortunately, an analytic expression for the functional derivative of the functional defined in \eqref{reward} is usually not available.

We can however obtain an unbiased estimate of the functional derivative by using the infinite-dimensional generalisation of this simple lemma
\begin{lemma}\label{finDimGrad}
Let $q\colon\mathbb{R}^n\rightarrow\mathbb{R}$ be a smooth function, and let $\nabla q(\mathbf{v})$ be its gradient at a point $\mathbf{v}$. 
Let $\mathbf{w}$ be a random vector from an isotropic, zero mean distribution $p(\mathbf{w})$. 
For $\epsilon\ll 1$, define  \begin{equation}
\hat{\mathbf{w}}= 
\begin{cases}
\mathbf{w}, \quad  \mathrm{if\ } q(\mathbf{v}+\epsilon\mathbf{w}) - q(\mathbf{v}) > 0 \\
-\mathbf{w}, \quad \mathrm{otherwise}.
\end{cases}\label{flipper}
\end{equation}
Then\[
E_p\left[\epsilon\hat{\mathbf{w}}\right]\propto\nabla q(\mathbf{v})+O(\epsilon^2).\]
\end{lemma}
\begin{proof}
The tangent space of $\mathbb{R}^n$ at the point $\mathbf{v}$ is naturally decomposed in the orthogonal direct sum of a subspace of dimension 1 parallel to the gradient, and a subspace of dimension $n-1$ tangent to the level surfaces of the function $q$. 
For small $\epsilon$, any change in the value of the function $q$ will be due to movement in the gradient direction. 
As the distribution $p$ is isotropic, every direction is equally likely in $\mathbf{w}$; however, the flipping operation in the definition of $\hat{\mathbf{w}}$ in \eqref{flipper} ensures that the component of $\hat{\mathbf{w}}$ along the gradient $\nabla q(\mathbf{v})$ is always positive, while it does not affect the orthogonal components. 
Therefore, in expectation, $\hat{\mathbf{w}}$ returns the direction of the functional gradient.
\end{proof}



\subsection{Scheduler representation in terms of basis functions}

In order to obtain an unbiased estimate of a functional gradient, we need to define a zero-mean isotropic distribution on a suitable space of functions. To do so, we introduce the concept of Gaussian Process, a generalisation of the multivariate Gaussian distribution to infinite dimensional spaces of functions (see, e.g. \cite{Rasmussen2006}).

\begin{definition} A Gaussian Process (GP) over an input space $\mathcal{X}$ is an infinite-dimensional family of real-valued random variables indexed by $x\in\mathcal{X}$ such that, for every finite subset $X\subset\mathcal{X}$, the finite dimensional marginal obtained by restricting the GP to $X$ follows a multi-variate normal distribution.
\end{definition}
Thus, a GP can be thought as a distribution over functions $f\colon\mathcal{X}\rightarrow\mathbb{R}$ such that, whenever the function is evaluated at a finite number of points, the resulting random vector is normally distributed. In the following, we will only consider $\mathcal{X}=\mathbb{R}^d$ for some integer $d$.

Just as the Gaussian distribution is characterised by two parameters, a GP is characterised by two functions, the {\it mean} and {\it covariance} function. The mean function plays a relatively minor role, as one can always add a deterministic mean function, without loss of generality; in our case, since we are interested in obtaining small perturbations, we will set it to zero. The covariance function, which captures the correlations between function values at different inputs, instead plays a vital role, as it defines the type of functions which can be sampled from a GP. We will use the {\it Radial Basis Function} (RBF) covariance, defined as follows:
\begin{equation}
\mathrm{cov}(f(x_1),f(x_2))=k(x_1,x_2)=\alpha^2\exp\left[-\frac{\Vert x_1-x_2\Vert^2}{\lambda^2}\right].\label{rbfCov}
\end{equation}
where $\alpha$ and $\lambda$ are the amplitude and length-scale parameters of the covariance function.
To gain insight into the geometry of the space of functions associated with a GP with RBF covariance, we report without proof the following lemma (see e.g. Rasmussen \& Williams, Ch 4.2.1 \cite{Rasmussen2006}).
\begin{lemma}\label{denseLemma}
Let $\mathcal{F}_N$ be the space of random functions $f=\sum_{j=1}^N w_j\phi_j(x)$  generated by taking linear combinations of basis functions  $\phi_j(x)=\exp\left[-\frac{\Vert x-\mu_j\Vert^2}{\lambda^2}\right]$, with $\mu_j\in\mathbb{R}$ and independent Gaussian coefficients $w_j\sim\mathcal{N}(0,\alpha^2/N)$.
The sample space of a GP with RBF covariance defined by \eqref{rbfCov} is the infinite union of the the spaces $\mathcal{F}_N$.
\end{lemma}

We refer to the basis functions entering in the constructive definition of GPs given in Lemma \ref{denseLemma} as {\it kernel functions}. Two immediate consequences of the previous Lemma are important for us:\begin{itemize}
\item{A GP with RBF covariance defines an {\it isotropic} distribution in its sample space (this follows immediately from the i.i.d.\ definition of the weights in Lemma \ref{denseLemma})};
\item{The sample space of a GP with RBF covariance is a dense subset of the space of all continuous functions (see also \cite{bortolussi:smoothed16} and references therein).}
\end{itemize}





GPs therefore provide us with a convenient way of extending the procedure described in Lemma \ref{finDimGrad} to the infinite dimensional setting.
In particular, Lemma \ref{denseLemma} implies that any scheduler function $f \in \mathcal{F}$ that is a sample from a GP (with RBF covariance) can be approximated to arbitrary accuracy in terms of basis functions as follows:
\begin{equation}
f(\vec{X}, t) = \sum_{j=1}^N w_j \exp\left[-0.5 ([\vec{X},t]^{\top}-\mu_j)^{\top} \Lambda^{-1} ([\vec{X},t]^{\top}-\mu_j) \right]
\end{equation}
where $\mu_j \in \mathbb{R}^n \times [0,T]$ is the centre of a Gaussian kernel function, $\Lambda$ is a diagonal matrix that contains $n+1$ squared length-scale parameters of the kernel functions, and $n$ is the dimensionality of the state-space.
This formulation allows describing functions (aka points in an infinitely dimensional Hilbert space) as points in the finite vector space spanned by the weights $\mathbf{w}$.
Note that the proposed basis function representation implies relaxation of the population variables to the continuous domain, though in  practice we are only interested in evaluating $f(\vec{X}, t)$ for integer-valued $\vec{X}$. 

The advantage of the kernel representation is that we do not need to account for all states $\vec{X} \in S$, but only for $N$ Gaussian kernels with centres $\mu_j$ for $1 \leq j \leq N$.
Therefore, the value of the scheduler at a particular state $\vec{X}$ will be determined as a linear combination of the kernel functions, with proximal kernels contributing more due to the exponential decay of the kernel functions.
This method offers a compact representation of the scheduler, and essentially does not suffer from state-space explosion, as we treat states as continuous. Moreover, we do not lose accuracy, as every function on $S$ can be extended to a continuous function on $E$ by interpolation.
On the practical side, we consider that the kernel functions are spread evenly across the joint space (state space \& time), and the length-scale for each dimension is considered to be equal to the distance of two successive kernels.\footnote{Kernel functions typically also have an amplitude parameter, which we consider to be equal to 1.}




\subsection{A Stochastic Gradient Ascent Algorithm}

Given a scheduler $\sigma$, we first evaluate the reachability probability via statistical model checking. 
We then perturb the corresponding functions $f_{\alpha}$ by adding a draw from a zero-mean GP with marginal variance scaled by $\epsilon\ll 1$, and evaluate again by statistical model checking the probability of the perturbed scheduler. If this is increased, we take a step in the perturbed direction, otherwise we take a step in the opposite direction. Notice that this procedure can be repeated for multiple independent perturbation functions to obtain a more robust estimate. 
The whole procedure is described in Algorithm \ref{alg:estimateGradient}, which produces an estimate for the gradient of the functional $Q$ at a vector $\mathbf{f}$ of functions $f_{\alpha}$ by considering the average of $k$ random directions.
\begin{algorithm}[ht!]
\caption{Estimate the functional gradient of $Q[\mathbf{f}]$}
\label{alg:estimateGradient}
\begin{algorithmic}
\REQUIRE Vector $\mathbf{f}$ of functions $f_{\alpha}$, scaling factor $\epsilon$, batch size $k$
\ENSURE An estimate of the functional derivative (gradient) $\nabla Q \equiv \frac{\delta Q}{\delta \mathbf{f}}$
	\STATE Set gradient $\nabla Q = 0$
	\STATE Evaluate $Q[\mathbf{f}]$ via statistical model checking
	\FOR{$i=1$ to $k$}
		\STATE Consider random direction $\mathbf{g}$ such that $\forall \alpha \in \mathcal{A}$, we have:
		\[ g_a \sim \mathcal{N}(0, 1) \]
		\STATE Evaluate $Q[\mathbf{f} + \epsilon \mathbf{g}]$
		\STATE Estimate the directional derivative:
		\[ \nabla_{\mathbf{g}} Q = \frac{Q[\mathbf{f} + \epsilon \mathbf{g}] - Q[\mathbf{f}]}{\epsilon} \]
		\IF{$\nabla_{\mathbf{g}}Q > 0$}
			\STATE $\nabla Q \leftarrow \nabla Q + \frac{1}{k} \mathbf{g}$
		\ELSE
			\STATE $\nabla Q \leftarrow \nabla Q - \frac{1}{k} \mathbf{g}$
		\ENDIF
	\ENDFOR
\end{algorithmic}
\end{algorithm}
We are now ready to state our main result:
\begin{theorem}
Algorithm \ref{alg:estimateGradient} gives an unbiased estimate of the functional gradient of the functional $Q[f_\alpha]$.
\end{theorem}
\begin{proof} Since both the statistical model checking estimation and the gradient estimation are unbiased and independent of each other, this follows.
\end{proof}

\begin{algorithm}[ht!]
\caption{Stochastic gradient ascent for $Q[\mathbf{f}]$}
\label{alg:gradientAscent}
\begin{algorithmic}
\REQUIRE Initial function vector $\mathbf{f}_0$, learning rate $\gamma_0$, $n_{\max}$ iterations
\ENSURE A function vector $\mathbf{f}$ that approximates a local optimum of $Q$
	\FOR {$n \leftarrow 1$ \TO $n_{\max}$}
		\STATE Estimate the functional gradient $\nabla Q$ by using Algorithm \ref{alg:estimateGradient}
		\STATE Update: $\mathbf{f}_n \leftarrow \mathbf{f}_{n-1} + \gamma_{n-1} \nabla Q$
	\ENDFOR
\end{algorithmic}
\end{algorithm}


Therefore, we can use this stochastic estimate of the functional gradient to devise a stochastic gradient ascent algorithm which directly solves the variational problem in equation \eqref{varFormulation}.
This is summarised in Algorithm \ref{alg:gradientAscent}, which requires as input an initial vector of functions $\mathbf{f}_0$, and a learning rate $\gamma_0$.
The effects of the learning rate on the convergence properties of the method have been extensively studied in the literature.
In particular, for a decreasing learning rate convergence is guaranteed in the strictly convex scenario, if the following conditions are satisfied: $\sum_{n} \gamma_n = \infty$ and $\sum_{n} \gamma^2_n < \infty$ \cite{Murata1999,Bottou2010}, suggesting a $\Theta(n^{-1})$ decrease for the learning rate.
In non-convex problems, such as the ones considered in this work, the $\Theta(n^{-1})$ decrease is generally too aggressive, leading to vulnerability to local optima.
Following the recommendations of \cite{Bottou2012}, we adopt a more conservative strategy:
\begin{equation}
\gamma_n = \gamma_0\; n^{-1/2}
\end{equation}
where $\gamma_0$ is an initial value for the learning rate, which is problem dependent.
















