

\documentclass[a4paper,twocolumn]{autart}

\usepackage{times,bm}

\usepackage{graphicx,psfrag,enumerate,subfigure}
\usepackage{amssymb}
\usepackage{amsmath}
\usepackage{calrsfs}
\usepackage{subeqnarray}
\usepackage{latexsym}


\newtheorem{definition}{Definition}
\newtheorem{theorem}{Theorem}
\newtheorem{remark}{Remark}
\newtheorem{example}{Example}
\newtheorem{lemma}{Lemma} 
\newtheorem{corollary}{Corollary} 
\newtheorem{proposition}{Proposition} 

\newtheorem{assumption}{Assumption}


\def\tr{\mathop{\mathrm{tr}}\nolimits} \def\diag{\mathop{\mathrm{diag}}\nolimits} \def\Ker{\mathop{\mathrm{Ker}}\nolimits} 

\setlength\arraycolsep{2pt}



\begin{document}
\begin{frontmatter}

\title{Distributed robust estimation over
  randomly switching networks using  consensus\thanksref{footnoteinfo}}


\thanks[footnoteinfo]{This work was supported by the Australian
  Research Council.}

\author[First]{V.~Ugrinovskii}\ead{v.ugrinovskii@gmail.com} 

\address[First]{School of Engineering and IT, University of NSW
  at the 
  Australian Defence Force Academy, Canberra, ACT, 2600, Australia}

          
\begin{keyword}                           Large-scale systems, distributed robust estimation, worst-case transient
consensus, vector Lyapunov functions.    
\end{keyword}

\begin{abstract} 
 The paper considers a distributed robust estimation problem over a network
 with Markovian randomly varying topology. The objective is to deal with
 network variations
 locally, by switching observer gains at affected nodes only. 
 We propose sufficient conditions which guarantee a suboptimal 
 level of relative disagreement of estimates in such observer networks. When the
 status of the network is known globally, these sufficient conditions enable the
 network gains to be computed by solving certain LMIs. When the nodes are
 to rely on a locally available information about the network topology,
 additional rank constraints are used to condition the gains, given this
 information. The results are complemented by necessary conditions which relate
 properties of the interconnection graph Laplacian to the mean-square
 detectability of the 
 plant through measurement and interconnection channels. 
 
\end{abstract}

\end{frontmatter}

\section{Introduction}

One of the motivations for using distributed multisensor networks is to make
the network resilient to loss of communication. This has led to an
extensive research into 
distributed filtering over networks with time-varying,
randomly switching topology. 
In particular, 
the Markovian approach to the analysis and synthesis of 
estimator networks has received a significant attention in relation to the
problems involving random data loss in channels 
with memory which are governed
by a Markov
switching rule~\cite{SS-2009,MMB-2009}. 


In addition to capturing memory properties of physical communication channels,
Markovian models allow for other random events in the
network, such as sensor failures and recovery,  to be considered in a
systematic manner within the
Markov jump systems framework. However, the Markov jump
systems theory usually assumes the complete
state of the underlying Markov chain to be known to every  controller or
filter~\cite{LUO1}
. In the context of
distributed estimation and control, this requires each node
of the network to know the complete instantaneous state of the network to
be able to deploy suitable gains. To circumvent such an
unrealistic assumption, the literature focuses on networks whose
communication state is governed by a random process decomposable
into independent two-state Markov processes describing the status of
individual links~\cite{LGM-2006,SS-2009}, even though this typically leads to  design conditions whose complexity
grows exponentially~\cite{LGM-2006}. Also, the
assumption of independence between communication links may not always be
practical, e.g., when dealing with congestions.

The objective of this paper is to develop a distributed filtering technique
which overcomes the need for broadcast of global communication topology and
does not require Markovian segmentation of the network. Our main
contribution is the methodology of robust distributed observer design
which enables the node observers to be implemented in a truly distributed
fashion, by utilizing only locally available information about the system's
connectivity, and without assuming the independence of communication
links. This information structure constraint is a key
distinction of this work, compared with the existing results, e.g.,
\cite{SS-2009,LGM-2006}.  In addition, the proposed methodology allows to
incorporate other random events such as sensor failures and recoveries.   


The paper focuses on the case where the plant to be observed, as well
as sensing and communication models are not known perfectly. To deal with uncertain perturbations in the
plant, sensors and communications, we employ the distributed 
filtering framework which has received a significant deal of attention in
the recent literature~\cite{SWH-2010,U6,LaU1}. 
The motivation for
considering  observers in this paper, instead of Kalman filters~\cite{SS-2009},
is to obtain observers that have guaranteed robustness 
properties. It is well known that the standard Kalman filter 
is sensitive to modelling errors~\cite{PSB}, and
consensus Kalman filters may
potentially suffer from the same shortcomings. 
This explains our interest in robust performance guarantees in the presence of  
uncertainty. 

In contrast to~\cite{SS-2009,SWH-2010}, in this paper the node
estimators are sought to reach relative 
consensus about the estimate of the reference plant. As an extension of the
consensus estimation methodology~\cite{Olfati-Saber-2007}, our approach
responds to the challenge posed by the presence of uncertain perturbations in
the plant, measurements and interconnections. Typically, a perfect consensus
between sensors-agents is not possible due to perturbations. 
To address this challenge, we employ
the approach based on optimization of the transient relative 
consensus performance metric, originally proposed 
in~\cite{U6}. We approach the robust
consensus-based estimation problem from the dissipativity viewpoint, 
using vector storage functions and vector supply rates~\cite{HCN-2004}. 
This allows us to establish both mean-square robust convergence and robust
convergence with probability 1 of the distributed filters under
consideration and guarantee a prespecified level of 
mean-square disagreement between node estimates in the presence of
perturbations and random topology changes.  

The information structure constraint, where the filters must rely on the local
knowledge of the network topology, poses the main challenge in
the derivation of the above-mentioned results. The
standard framework of Markov jump systems is not directly applicable
to the problem of designing locally constrained filters whose information
about the network status is non-Markovian. 
To overcome this difficulty, we adopt the approach recently proposed for 
decentralized control of jump parameter systems~\cite{XiUP1}. It involves a
two-step design procedure. First, an auxiliary distributed estimation
problem is solved under 
simplifying assumption that the complete Markovian network topology is
instantaneously available at each node. However, we seek a solution to
this problem using a network of \emph{non-fragile} estimators subject to
uncertainty~\cite{HC-2000}. Resilience of the auxiliary estimator to
uncertain perturbations is the key 
property to allow this auxiliary 
uncertain estimator network to be modified, at the second step, into an
estimator network which satisfies the information structure constraint and
retains robust performance of the auxiliary design.  



An important question in connection with our
distributed observer architecture is concerned
with  requirements on the communication topology under which the 
consensus of node observers is achievable. 
For networks of one- or two-dimensional agents, and
networks consisting of identical agents, conditions for consensus are tightly
related to properties of the graph Laplacian
matrix~\cite{OM-2004,RB-2005,ZLD-2011}. In a more general situation 
involving nonidentical node observers, the role of the interconnection graph
is often hidden behind the design conditions,
e.g., see \cite{SS-2009,SWH-2010}. Our second contribution is to show that
for the distributed 
estimation problem under consideration to have a solution, the standard
requirement for the graph Laplacian to have a simple zero eigenvalue must be
complemented by detectability properties of certain matrix pairs formed by
parameters of the observers and interconnections.  

The paper is organized as follows. The problem formulation is given in
Section~\ref{Distr.Cons}. Section~\ref{sec:design-global} studies an
auxiliary distributed 
estimation problem without the information structure constraints. The
results of this section are then used in Section~\ref{main} where the main
results of the paper are given. Section~\ref{requirements} discusses
requirements on the observer communication
topology. Section~\ref{Example} presents an
illustrating example. 


\paragraph*{Notation}  is the real
Euclidean -dimensional vector space, with the norm ;   denotes the transpose of a matrix or a
vector. Also, for a given ,
. 
, and
 is the identity matrix in ; we will omit the
subscript  when this causes no ambiguity. 
For , ,
we write  (), when   is positive definite
(positive semidefinite).  
  denotes the Kronecker product of matrices.

  is the block-diagonal matrix, whose  diagonal
  blocks are . The symbol  in  position 
of a block-partitioned matrix denotes the transpose of the  block of
the matrix.  is the Lebesgue space of
-valued vector-functions , defined on ,
with the norm . 


\section{Problem formulation}\label{Distr.Cons}

\subsection{Networks with Markovian switching topology}\label{networks}

Consider a directed weakly connected
graph , where 
is the set of nodes, and  is the set of edges. The edge  
originating at node  and ending at node  represents the event ``
transmits information to ''. In accordance with a common convention, we
consider graphs without 
self-loops, i.e., . However, each node is assumed
to have complete information about its filter, measurements and the
status of incoming communication links. 

We consider two types of random events at each
node. Firstly, node neighborhoods change randomly as a result of random link
dropouts and recovery. Also, to account for sensor adjustments in
response to these changes, as well as sensor failures/recoveries, we 
allow for random variations of the sensing regime at each node. 
Letting ,  denote an
observed process and its measurement taken at node  at time , and
using a standard linear relation between these quantities

such adjustments are associated with randomly varying coefficients ,
, . These random events are additional
to link dropouts.  This leads us to consider the combined evolution of each
node's neighbourhood and sensing regime.   

\begin{definition}\label{Distinct.N}
For a node , let ,  be its neighbourhood set and the measurement matrix 
triplet, respectively,
at a certain time .  The pair , is said to represent the \emph{local
communication and sensing state} (or simply the \emph{local state}) of node 
 at time . Two states of  at times , , 
, 

are distinct if\/
, or
.
\end{definition}
From now on, we associate with every node  the ordered collection of all
its feasible distinct local states and denote the
corresponding index .
The time evolution of each local state will be represented by a random mapping
.     

The global configuration and sensing pattern of the network at
any time can be uniquely determined from its local states. This leads us to
define the \emph{global state} of the network as an -tuple
, where . 
Consider the ordered collection of all feasible global states of the
network and let  denote its 
index set.  In general, not all
combinations of local states correspond to feasible global states. Owing to
dependencies between network links and/or sensing regimes, the number of
feasible global states may be substantially smaller than the cardinality of
the set  of all
combinations of local states. The one-to-one mapping between
the set of feasible global states  
 and its index set  will be denoted
, i.e., , where  is the index of the
-tuple  .  Also, we write
, whenever . 

Using the one-to-one mapping , define the \emph{global} process 
 to describe the evolution
of the network global state. 
The local state processes  are related to it as
 .  Throughout the paper, we
assume that
 is a stationary Markov random process  defined in a
filtered probability space , where  denotes a 
right-continuous filtration with 
respect to which  is adapted\footnote{In the sequel,
  we will consider the
  filtration generated by a composite Markov process consisting of
   and error dynamics of the estimator introduced in the next section.}   
  \cite{BC-2009}. 
The -algebra  is the minimal
-algebra which contains all measurable sets from the filtration
. 
The transition probability rate matrix of the Markov chain  will be denoted , with
 and ~\cite{BC-2009}.  


Using the global state process , the time evolution of the
communication graph can be represented by a random graph-valued process
, whose value at every time instance is a directed
subgraph of . It is assumed that for all ,
 is weakly connected and has the same vertex set as
. When , 
 will denote the adjacency
matrix of the digraph . Note that
 if and only if . Here
and hereafter, the symbol  describes the neighbourhood
of node  when this node is in local state . In accordance with
this notation,  is the neighbourhood
of node  when the network is in global state . Also,  
, 
, and  denote the
in- and out-degrees of node  and the Laplacian matrix of the
corresponding graph , respectively.    


We will use the notation  to refer to the
switching network described above. Since  is 
stationary, then each 
process  is also stationary. However, in general the local state
processes  are not Markov, and the components of the
multivariate process  may statistically
depend on each other. Hence our network model allows for
dependencies between links within the network. 

  
\subsection{Distributed estimation with 
  consensus}
Consider a plant described by the equation

Here  is the state,  is a deterministic
disturbance. We assume that , and that the solution of (\ref{eq:plant.1})
exists on any finite interval , and is -integrable on
. 

Also, consider an observer network  whose nodes take measurements of the plant
(\ref{eq:plant.1}) as follows 

where  represents the deterministic measurement 
uncertainty at sensing node , . The 
coefficients of equation (\ref{U6.yi.1}) take values in given sets of
constant matrices of compatible dimensions, 

It will be assumed throughout the paper that  for all  and . 

The measurements  are processed at node  according to the following
estimation algorithm (cf. \cite{SS-2009,U6,LaU1}): 
 
where  is the signal received at node  from node ,

 describes the channel uncertainty affecting the
information 
transmission from node  to . It is assumed that  belongs  to 
the class of mean-square -integrable random disturbances, adapted to the
filtration . 

It will be further assumed that
 for all  and ,
. Also in (\ref{UP7.C.d.loc}), ,  are
matrix-valued functions of the local state process . These
functions are the design parameters of the algorithm describing innovation
and interconnection gains of the observer (\ref{UP7.C.d.loc}). Note that 
the coupling and
observer gains ,   are required to be
functions of the local state (i.e., functions of ), rather than the
global state. This `locality' information structure 
constraint is additional to the assumption about the Markov nature of the communication
graph; cf.~\cite{SS-2009} where the complete communication
graph was assumed to be known at each node. The problem in this paper is to determine these functions to
satisfy certain robust performance criteria to be presented in
Definition~\ref{Def1} below. 


\begin{remark}\label{rem2}
In equation (\ref{vij}), the matrices 
and  do not depend on
  . This is
to reflect a situation where  
node  \emph{always} broadcasts its information to node , but node 
randomly fails to receive this information, or chooses not to accept it,
e.g. due to random congestion. 
It is possible to consider a
more general situation where the matrices  and  also depend on
. Technically, this more general case is no different from the one
pursued here.
\end{remark}

Associated with the system (\ref{eq:plant.1}) and the set of filters
(\ref{UP7.C.d.loc}) is
the disagreement function~(cf.~\cite{OM-2004})  

. 
It represents the average (over the set of all
nodes) of the total disagreement between the estimate at each node, and the
estimates computed at the neighbouring nodes, when the network is in state . 
Following~\cite{U6}, we adopt  to define
the transient consensus performance metric in the distributed estimation problem
defined below.   

Let ,  denote
the conditional probability and conditional expectation, given  , .  Also, given a matrix , let



\begin{definition}\label{Def1}
The distributed estimation problem under consideration is
to determine switching observer gains
 and interconnection coupling gains
, for the filters 
(\ref{UP7.C.d.loc}) which ensure that the following conditions are
satisfied:
  \begin{enumerate}[(i)]
  \item
In the absence of the uncertainty, all node estimators converge
exponentially in the mean-square sense and converge asymptotically with probability~1:


\item Given a constant , 
the following mean-square  consensus performance is guaranteed


\item
 All estimators converge in the mean-square and with probability 1:

  \end{enumerate}
\end{definition}
Properties (\ref{convergence}) and (\ref{convergence.P1}) refer to
different types of asymptotic behaviour of the estimation errors. Condition
(\ref{convergence}) states that  converges to 
in the mean-square  sense. From the Chebyshev inequality, this also implies that
,
that is, almost all estimator trajectories converge in  sense.
Property (\ref{convergence.P1}) states that  converges to zero
asymptotically for almost
all realizations of the global state process . This is a stronger
property; in general, it does not follow from the a.s.~
convergence. For that reason, both convergence properties are
considered in Definition~\ref{Def1}.    

\section{An auxiliary global distributed estimation
  problem}\label{sec:design-global} 

\subsection{Non-fragile distributed estimation}  

In this section, we temporarily lift the locality information structure
constraint and assume the
global communication and sensing state process  to be available at
every node. 

For every  define 
, . Note that .
Then, the measurements taken at node  can be rewritten in terms of
the global state process :  


The auxiliary problem in this section is concerned with estimation of the
state of the uncertain plant (\ref{eq:plant.1}), (\ref{U6.yi.2}) using a
network of estimators subject to uncertainty, as follows 

Here, ,   are matrix-valued functions of the 
state of the global Markov chain  to be found, and ,
, and  are estimator perturbations. It is
assumed that these perturbations are random processes adapted to the filtration
 and such that the multivariate process 
 is Markov with respect to that
filtration. Also in this section, it will be assumed that these
uncertainties satisfy the following norm-bound conditions:

where ,  are given constants, and  
 is the estimation error of the auxiliary estimator 
at node , which evolves 
according to the
equations 
 

It will be shown in Section~\ref{main}
that when the locality information structure constraints are imposed,
this will result in an uncertainty due to the mismatch between filter error
dynamics in the network subject to these constraints, and 
the errors which would arise in the same network if its communication state was
known globally. It will be shown
in the proof of 
Theorem~\ref{T.main} that this uncertainty satisfies conditions
(\ref{wv.constr}). The resilience of the constraint-free auxiliary network 
(\ref{UP7.C.d.2}) to this uncertainty will be used in the next section to
show that the
network~(\ref{UP7.C.d.loc}), constructed from the auxiliary solution,
maintains the same convergence and robust  consensus performance
properties when the information structure constraints are enforced.    

\begin{definition}\label{Def1.aux}
The auxiliary distributed consensus estimation problem is to
determine sets of gains
, 
, , for the filters 
(\ref{UP7.C.d.2}) to ensure the following:
\begin{enumerate}[(i)]
  \item
When , the interconnected system consisting of
subsystems (\ref{e.w}) must be exponentially stable in the mean-square
sense and asymptotically 
stable with probability 1 for all estimator perturbations ,
, and  for which the correspondingly modified
constraints (\ref{wv.constr}) hold. 

\item
In the presence of exogenous disturbances , the
mean-square consensus 
performance condition in (\ref{objective.i.1}) is satisfied for all
admissible estimator perturbations  ,
, and  subject to (\ref{wv.constr}).

\item
 All estimators converge in the mean-square and with probability 1; i.e.,
 conditions (\ref{convergence}), (\ref{convergence.P1}) hold. 
\end{enumerate} 
\end{definition}


A solution to this auxiliary problem is
given in Theorem~\ref{T.aux} below.  The conditions of
the theorem involve the following linear matrix inequalities in the variables
, , , ,
, , :   

where 



\begin{theorem}\label{T.aux}
Suppose the network  and the constants ,
,  and  are such that 
the coupled LMIs (\ref{T4.1}) and (\ref{T4.LMI.1})
in the variables , , ,
, ,  
, , are feasible. 
Then the network of observers (\ref{UP7.C.d.2}) with

solves the auxiliary estimation problem in Definition~\ref{Def1.aux}. The
matrix  in condition (\ref{objective.i.1}) 
corresponding to this solution is ,
where .  
\end{theorem}

The proof of Theorem~\ref{T.aux} is given in the Appendix. 

\subsection{Special case: Broadcast of the global state}   

When the global Markov state of the network is available at
every node, the solution to the distributed
 consensus estimation problem can be obtained from
Theorem~\ref{T.aux} by letting  
 and taking
.

\begin{corollary}\label{Corollary}
Suppose the network  and the constants 
and  are such that the following coupled LMIs in the variables 
, ,  
, , are feasible:

Then the network of observers (\ref{UP7.C.d.2}) with
 and , 
defined in (\ref{Lim})
solves the estimation problem in Definition~\ref{Def1.aux}. The
matrix  in condition (\ref{objective.i.1})
corresponding to this solution is ,
where .  
\end{corollary}


\section{The main result}\label{main}

In this section, the solution to the auxiliary distributed estimation
problem developed in Section~\ref{sec:design-global}  will be used to
obtain a distributed estimator whose nodes utilize only locally available 
information. This will be achieved by  
taking the asymptotic conditional expectation of the auxiliary gains, given 
a local state. 
Our method is based on the following
technical result of \cite{XiUP1}. 


\begin{lemma}
  \label{prop:1}
  Suppose the Markov process  is irreducible and has a unique
  invariant distribution . Given a matrix-valued function
  , for every node  and for all
    we have:  
  
\end{lemma}





Now let , , , be the coefficients of the
auxiliary distributed estimator obtained in
Theorem~\ref{T.aux}. Using Lemma~\ref{prop:1}, for each  and  we define 
  
From Lemma~\ref{prop:1}, the processes   are then
the asymptotic minimum variance approximations of the corresponding processes
. 
However, unlike , the
evolution of  is governed by the local
communication and sensing state process .  

To formulate the main result of this paper, 
consider the collection of the LMIs in the variables
, , ,  and ,
consisting of the LMIs (\ref{T4.1}), (\ref{T4.LMI.1}), and the following
additional LMIs, 

where ,  are the same constants as those employed in
the LMIs (\ref{T4.1}), (\ref{T4.LMI.1}), and
1ex]
\Delta_{ij}^{K,k}&\triangleq &\frac{\sum\limits_{l:l\neq k,
    \atop\Phi_i(l)=\Phi_i(k)}\!\!\!\!\!
\gamma^2\bar\lambda_l
      \left[Y_i^k-Y_i^l\right]H_{ij}'F_{ij}^{-1}}{\sum_{l:\Phi_i(l)=\Phi_i(k)}
      \bar\lambda_l } 
      .

&&\mathrm{rank}\left[\begin{array}{cc} Y_i^k & I \\ I & X_i^k
  \end{array}
\right] \le n, 
  \label{rank}

 K_{ij}^k&=&\gamma^2Y_i^kH_{ij}'F_{ij}^{-1},  \label{Kim.Y} \nonumber
 \\
 L_i^k&=&\left[\gamma^2Y_i^k(C_i^k)'+
B_2 (D_i^k)'\right](E_i^k)^{-1}. \label{Lim.Y}

   \label{eq:32.K}
  K_{ij}^k - \tilde K_{ij}^{\Phi_i(k)} &=&
  \frac{\sum_{l:l\neq k, \Phi_i(l)=\Phi_i(k)}  \bar\lambda_l 
\left[K_{ij}^k-K_{ij}^l\right]}{\sum_{l:\Phi_i(l)=\Phi_i(k)}
\bar\lambda_l}, \\
  \label{eq:32.L}
  L_i^k - \tilde L_i^{\Phi_i(k)} &=&
  \frac{\sum_{l:l\neq k, \Phi_i(l)=\Phi_i(k)}
      \bar\lambda_l \left[L_i^k-L_i^l\right]} {\sum_{l:\Phi_i(l)=\Phi_i(k)}
      \bar\lambda_l },

\|\tilde L_i^{\Phi_i(k)}-L_i^k\|^2\le \alpha_i^2, \quad
\|\tilde K_{ij}^{\Phi_i(k)}-K_{ij}^k\|^2\le \beta_{ij}^2. 
\label{wv.constr.nb}

   \omega_i   &=&(\tilde
    L_i^{\eta_i(t)}-L_i^{\eta(t)})(C_i^{\eta(t)}e_i(t)+D_i^{\eta(t)}\xi+\bar
    D_i^{\eta(t)}\xi_i), \nonumber \\
   \omega_{ij}^{(1)} &=&
(\tilde K_{ij}^{\eta_i(t)}-K_{ij}^{\eta(t)})(H_{ij}e_i+G_{ij}w_{ij}), 
\nonumber \\
   \omega_{ij}^{(2)}&=&-
(\tilde K_{ij}^{\eta_i(t)}-K_{ij}^{\eta(t)})H_{ij}e_j,
\label{wv}
 
  \label{undetect.C}
\bar{\mathcal{O}}^k\cap \prod_{i=1}^N\mathcal{C}_i^k =\{0\} \quad \forall k\in 
\mathcal{I}.

  \label{supermart}
\hspace{-5ex}\mathsf{E}\left[v(t)+\int_s^t\psi(\theta)d\theta
    \big|\bar{\mathcal{F}}_s\right]\le v(s) +
  \mathsf{E}\left[\int_s^t\phi(\theta)d\theta\big|\bar{\mathcal{F}}_s\right].

\lefteqn{[\mathfrak{L}_i V_i](e,k)\triangleq
\sum\nolimits_{l=1}^M\lambda_{kl}V_i(e_i,l)+\left(\frac{\partial V_i}{\partial
    e_i}\right)^T \Big((A-L_i^kC_i^k)e_i} && \\
&& + \sum\nolimits_{j\in
    \mathbf{V}_i^{k_i}} K_{ij}^k(H_{ij}(e_j-e_i)-G_{ij}w_{ij})\\
&&+(\hat B_2-L_i^k\hat D_i^k)\hat \xi_i 
-\omega_i-\sum\nolimits_{j\in
  \mathbf{V}_i^{k_i}}(\omega_{ij}^{(1)}+\omega_{ij}^{(2)})\Big). 
 
\lefteqn{[\mathfrak{L}V](e,k)
+ \sum\nolimits_{i=1}^N\Big[
  \tau_i^k(\alpha_i^2 \|C_i^k e_i+\hat D_i^k\hat
  \xi_i\|^2-\|\omega_i\|^2)} && \nonumber \\
&& 
+\sum\nolimits_{j\in\mathbf{V}_i^{k_i}}\theta_{ij}^k(\beta_{ij}^2\|H_{ij}e_i+G_{ij}w_{ij}\|^2-\|\omega_{ij}^{(1)}\|^2)\nonumber \\
&&+\sum\nolimits_{j\in\mathbf{V}_i^{k_i}}\vartheta_{ij}^k(\beta_{ij}^2\|H_{ij}e_j\|^2-\|\omega_{ij}^{(2)}\|^2)\Big]
=
\sum\nolimits_{i=1}^N\mathfrak{R}_i(e,k), 

\lefteqn{\mathfrak{R}_i(e,k)\triangleq [\mathfrak{L}_iV_i](e,k) 
  + \tau_i^k\left(\alpha_i^2 \|C_i^k e_i+\hat D_i^k\hat
  \xi_i\|^2-\|\omega_i\|^2\right)} && \nonumber \\
&& 
+\sum_{j\in\mathbf{V}_i^{k_i}}\theta_{ij}^k\left(\beta_{ij}^2\|H_{ij}e_i+G_{ij}w_{ij}\|^2-\|\omega_{ij}^{(1)}\|^2\right)\nonumber \\
&& 
+e_i'\Big(\sum_{j:~
    i\in\mathbf{V}_j^{k_j}}\vartheta_{ji}^k\beta_{ji}^2H_{ji}'H_{ji}\Big)e_i-
\sum_{j\in\mathbf{V}_i^{k_i}}\vartheta_{ij}^k\|\omega_{ij}^{(2)}\|^2. \qquad 
\label{LV.1}

\mathfrak{R}_i(e,k)&\le& e_i'U_ie_i+2e_i'X_i^k\sum_{j\in
  \mathbf{V}_i^{k_i}}K_{ij}^kH_{ij}e_j \nonumber \\
&& +\gamma^2(\|\xi\|^2+\|\xi_i\|^2)+ \gamma^2\sum_{j\in
  \mathbf{V}_i^{k_i}}\|w_{ij}\|^2, \label{Rem.2}

\lefteqn{U_i=X_i^k\left(A-\hat B_2(\hat D_i^k)'(E_i^k)^{-1}C_i^k\right)} &&\\
&&+\left(A-\hat B_2(\hat D_i^k)'(E_i^k)^{-1}C_i^k\right)'
X_i^k+\sum_{l=1}^M\lambda_{kl}X_i^l 
\nonumber \\
&&+\Big(\frac{1}{\tau_i^k}+\!\!\sum_{j\in\mathbf{V}_i^{k_i}}\!\!\Big(\frac{1}{\theta_{ij}^k}+\frac{1}{\theta_{ij}^k}\Big)\Big)X_i^kX_i^k+\!\!\sum_{j:~
    i\in\mathbf{V}_j^{k_j}}\!\!\vartheta_{ji}^k\beta_{ji}^2H_{ji}'H_{ji} 
\\
&&+\frac{1}{\gamma^2}X_i^k
\hat B_2\left(I-(\hat D_i^k)'(E_i^k)^{-1} \hat
    D_i^k\right)\hat B_2'X_i^k 
 \nonumber \\
&&-\gamma^2(C_i^k)'(E_i^k)^{-1}C_i^k
-\gamma^2\sum_{j\in\mathbf{V}_i^{k_i}}H_{ij}'F_{ij}^{-1}H_{ij}.
  \label{Ui}

e_i'U_ie_i+2e_i'X_i^k\sum_{j\in
    \mathbf{V}_i^{k_i}}K_{ij}^kH_{ij}e_j+(p_i^k+q_i^k)\|e_i\|^2 \nonumber \\
-2e_i'\sum_{j\in\mathbf{V}_i^{k_i}}e_j
< \sum_{j=1}^N \pi_{ij}^k (e_j'X_j^ke_j),
\label{Ui.2}

  \label{pi}
  \pi_{ij}^k=\begin{cases} -2\delta_i, & j=i, \\
 \frac{2\delta_j}{q_j^k+1}, & j\in \mathbf{V}_i^{k_i}, \\
0, &\text{otherwise}.
\end{cases}  

\lefteqn{\mathfrak{R}_i(e,k)+(p_i^k+q_i^k) \|e_i\|^2-2e_i' \sum_{j\in\mathbf{V}_i^{k_i}} e_j< \gamma^2\|\hat \xi_i\|^2} && \nonumber \\
&& +\gamma^2\sum_{j\in
  \mathbf{V}_i^{k_i}} \|w_{ij}\|^2 +
\sum_{j\in\mathbf{V}_i^k\cup \{i\}} \pi_{ij}^k V_j(e_j,k). 
\label{***}

\lefteqn{N\Psi^k(e)+[\mathfrak{L} V](e,k)\le  -\epsilon 
V(e,k) } && \nonumber \\
 && + \gamma^2\sum_{i=1}^N\left (\|\xi_i\|^2+ \|\xi\|^2+ \sum_{j\in
  \mathbf{V}_i^{k_i}} \|w_{ij}\|^2 \right).
\label{lyap.3}

\lefteqn{\mathsf{E}\left[V(e(t),\eta(t))\Big|e(s),\eta(s)\right]-V(e(s),\eta(s))}
&& \nonumber \\
&&
+\mathsf{E}\left[\int_s^t(\epsilon V(e(t),\eta(t))+N\Psi^{\eta(t)}(e(t))dt\Big|e(s),\eta(s)\right]
\nonumber \\
&&\le \gamma^2\mathsf{E}\left[\int_s^t\left(\sum_{i=1}^N\|\xi_i(t)\|^2+
    \|\xi(t)\|^2 \right.\right. \nonumber \\
&&+ \sum_{j=1}^N \mathbf{a}_{ij}^{\eta(t)}\|w_{ij}(t)\|^2 \Bigg)dt\Bigg|e(s),\eta(s)\Bigg].
\label{lyap.5}

 \phi(t)&\triangleq& \sum_{i=1}^N\left(\|\xi_i(t)\|^2+
  \|\xi(t)\|^2+\sum_{j=1}^N \mathbf{a}_{ij}^{\eta(t)}\|w_{ij}(t)\|^2\right), \\
  \psi(t)&\triangleq& N\Psi^{\eta(t)}(e(t))+\epsilon V(e(t),\eta(t))

satisfy the conditions of Lemma~\ref{Supermartingale.Lemma}. 
This leads to the
conclusion that 

a.s., and also  a.s.. Due to the condition 
for all , we conclude that   exists and  a.s.. This
implies  with probability 1 for all  and
arbitrary disturbances ; i.e.,
(\ref{convergence.P1}) holds. 

In the case where , , , the above observation
immediately yields the statement of the theorem about internal stability of
the system (\ref{e.w}), (\ref{Lim}) with probability
1. The claim of internal exponential mean-square stability follows directly
from (\ref{lyap.3}), since  by definition.   

Also, by taking the
expectation conditioned on ,  on both sides of
(\ref{lyap.5}) and then letting , we obtain 
condition (\ref{objective.i.1}), in which .   
Condition (\ref{convergence}) follows from (\ref{lyap.5}) in a similar
manner. Taking the
expectation conditioned on ,  on both sides of
(\ref{lyap.5}), then dropping the nonnegative term  and
letting , we establish that
. 
Hence . 
 \hfill 


\newcommand{\noopsort}[1]{} \newcommand{\printfirst}[2]{#1}
  \newcommand{\singleletter}[1]{#1} \newcommand{\switchargs}[2]{#2#1}
\begin{thebibliography}{10}

\bibitem{BC-2009}
A.~Bain and D.~Crisan.
\newblock {\em Fundamentals of Stochastic Filtering}.
\newblock Springer, NY, 2009.

\bibitem{CdV-2002}
E.~F. Costa and J.~B.~R. do~Val.
\newblock On the observability and detectability of continuous-time {M}arkov
  jump linear systems.
\newblock {\em SIAM J. Contr. Optim.}, 41:1295-1314, 2002.

\bibitem{EOA-1997}
L.~El Ghaoui, F.~Oustry, and M.~Ait Rami.
\newblock A cone complementarity linearization algorithm for static
  output-feedback and related problems.
\newblock {\em IEEE Tran. Automat. Contr.}, 42:1171-1176, 1997.

\bibitem{HCN-2004}
W.~M. Haddad, V.~Chellaboina, and S.~G. Nersesov.
\newblock Vector dissipativity theory and stability of feedback
  interconnections for large-scale non-linear dynamical systems.
\newblock {\em Int. J. Contr.}, 77:907-919, 2004.

\bibitem{HC-2000}
W.~M. Haddad and J.~R. Corrado.
\newblock Robust resilient dynamic controllers for systems with parametric
  uncertainty and controller gain variations.
\newblock {\em Int. J. Contr.}, 73:1405-1423, 2000.

\bibitem{LGM-2006}
C.~Langbort, V.~Gupta, and R.~Murray.
\newblock Distributed control over failing channels.
\newblock {\em Networked Embedded Sensing and Control}, pp. 325--342. Springer,
  2006.

\bibitem{LUO1}
L.~Li, V.~Ugrinovskii, and R.~Orsi.
\newblock Decentralized robust control of uncertain {M}arkov jump parameter
  systems via output feedback.
\newblock {\em Automatica}, 43:1932-1944, 2007.

\bibitem{MMB-2009}
I.~Matei, N.~C. Martins, and J.~S. Baras.
\newblock Consensus problems with directed {M}arkovian communication patterns.
\newblock In {\em Proc. 2009 ACC}, 2009.

\bibitem{Olfati-Saber-2007}
R.~Olfati-Saber.
\newblock Distributed {K}alman filtering for sensor networks.
\newblock In {\em Proc. 46th IEEE CDC}, 2007.

\bibitem{OM-2004}
R.~Olfati-Saber and R.~M. Murray.
\newblock Consensus problems in networks of agents with switching topology and
  time-delays.
\newblock {\em IEEE Trans. Automat. Contr.}, 49:1520-1533, 2004.

\bibitem{OHM-2006}
R.~Orsi, U.~Helmke, and J.~B. Moore.
\newblock A {N}ewton-like method for solving rank constrained linear matrix
  inequalities.
\newblock {\em Automatica}, 42:1875-1882, 2006.

\bibitem{PSB}
I.~R. Petersen and A.~V. Savkin.
\newblock {\em Robust Kalman Filtering for Signals and Systems with Large
  Uncertainties}.
\newblock Birkh\"{a}user Boston, 1999.

\bibitem{RB-2005}
W. Ren and R.~W. Beard.
\newblock Consensus seeking in multiagent systems under dynamically changing
  interaction topologies.
\newblock {\em IEEE Tran. Automat. Contr.}, 50:655-661, 2005.

\bibitem{RS-1971}
H.~Robbins and D.~Siegmund.
\newblock A convergence theorem for nonnegative almost supermartingales and
  some applications.
\newblock In J.~S. Rustagi, Ed., {\em Optimizing Methods in Statistics}.
  Academic Press, 1971.

\bibitem{SWH-2010}
B.~Shen, Z.~Wang, and Y.~S. Hung.
\newblock Distributed -consensus filtering in sensor networks with
  multiple missing measurements: {T}he finite-horizon case.
\newblock {\em Automatica}, 46:1682-1688, 2010.

\bibitem{SWL-2011}
B.~Shen, Z.~Wang, and X.~Liu.
\newblock A stochastic sampled-data approach to distributed 
  filtering in sensor networks.
\newblock {\em IEEE Trans. Circuits Syst. I: Regular Papers},
  58(9):2237--2246, 2011.

\bibitem{SS-2009}
M.~V. Subbotin and R.~S. Smith.
\newblock Design of distributed decentralized estimators for formations with
  fixed and stochastic communication topologies.
\newblock {\em Automatica}, 45:2491-2501, 2009.

\bibitem{U6}
V.~Ugrinovskii.
\newblock Distributed robust filtering with  consensus of
  estimates.
\newblock {\em Automatica}, 47:1-13, 2011.

\bibitem{LaU1}
V.~Ugrinovskii and C.~Langbort.
\newblock Distributed  consensus-based estimation of uncertain
  systems via dissipativity theory.
\newblock {\em IET Control Theory \& App.}, 5:1458-1469, 2010.

\bibitem{XiUP1}
J.~Xiong, V.~A. Ugrinovskii, and I.~R. Petersen.
\newblock Local mode dependent decentralized stabilization of uncertain
  {M}arkovian jump large-scale systems.
\newblock {\em IEEE Tran. Automat. Contr.}, 54:2632-2637,
  2009.

\bibitem{YGH-2009}
J.~Yao, Z.-H. Guan, and D.~J. Hill.
\newblock Passivity-based control and synchronization of general complex
  dynamical networks.
\newblock {\em Automatica}, 45:2107-2113, 2009.

\bibitem{ZLD-2011}
H.~Zhang, F.~L. Lewis, and A.~Das.
\newblock Optimal design for synchronization of cooperative systems: {S}tate
  feedback, observer and output feedback.
\newblock {\em IEEE Tran. Automat. Contr.}, 56:1948-1952, 2011.

\end{thebibliography}

\end{document}
