\documentclass[10pt]{article}
\usepackage[T1]{fontenc}
\usepackage[a4paper]{geometry}
\usepackage{amssymb}
\usepackage{graphicx,psfig}

\newlength{\algowidth}
\setlength{\algowidth}{\textwidth}
\addtolength{\algowidth}{-1cm}
\def\uneligne{\centerline{\rule{0.9\textwidth}{0.5pt}}}
\def\algo#1#2{\paragraph{#1}\-\hrulefill\par
\vspace*{-0.5\baselineskip}
            \parbox{0.9\textwidth}{\sf\flushleft
                        #2}\par\vskip 2pt\uneligne\par\vskip 2pt}

\newenvironment{itemiz}{\begin{itemize}
            \setlength{\itemsep}{0cm}}{\end{itemize}}

\newenvironment{enumerat}{\begin{enumerate}\setlength{\itemsep}{0cm}\setlength{\parindent}{0cm}\setlength{\parskip}{0cm}}{\end{enumerate}}

\newcommand{\bi}{\begin{itemize}}
\newcommand{\ei}{\end{itemize}}
\newcommand{\bd}{\begin{description}}
\newcommand{\ed}{\end{description}}
\newcommand{\be}{\begin{enumerate}}
\newcommand{\ee}{\end{enumerate}}
\newcommand{\bc}{\begin{center}}
\newcommand{\ec}{\end{center}}

\def\tabulation{xxx\=xxx\=xxx\=xxx\=xxx\=xxx\=xxx\=xxx\=xxx\= \kill}
\def\dbar#1{{\overline\delta}_{#1}}
\def\dubar#1{{\underline\delta}_{\,#1}}
\def\twolines{\baselineskip=1.25\normalbaselineskip}

\bibliographystyle{article}
\def\bibfmta#1#2#3#4{{\textsc{#1}.}\ {#2}, \textit{#3}, #4.}
\bibliographystyle{book}
\def\bibfmtb#1#2#3#4{{\textsc{#1}.}\ \textit{#2}, {#3}, #4.}

\newtheorem{thm}{Theorem}[section]
\newtheorem{lemm}{Lemma}[section]
\newtheorem{defi}{Definition}[section]
\newenvironment{proof}{\begin{trivlist}
                       \item[]\hspace{0cm}\textbf{Proof: }
                       \hspace{0cm} }{\hfill 
                       \end{trivlist}}
                       
\newenvironment{rmk}{\begin{trivlist}
                       \item[]\hspace{0cm}\textbf{Remark}}{
                       \end{trivlist}}
        
\begin{document}

\title{A Uniform Self-Stabilizing \\
Minimum Diameter Spanning Tree Algorithm \\
{\small (Extended Abstract)}}

\author{Franck Butelle\thanks{Universit\'{e} Paris 10 
- 92000 Nanterre. France.},\  
Christian Lavault\thanks{LIPN, CNRS URA 1507, 
Universit\'{e} Paris-Nord\ 93430 Villetaneuse. France.},\ 
Marc Bui\thanks{Universit\'{e} Paris 10 - 92000 Nanterre. France.}
}
\date{\empty}
\maketitle

\begin{abstract}
We present a uniform self-stabilizing algorithm, which solves the
problem of distributively finding a minimum diameter spanning tree of
an arbitrary positively real-weighted graph. Our algorithm consists
in two stages of stabilizing protocols. The first stage is a uniform
randomized stabilizing {\em unique naming} protocol, and the second
stage is a stabilizing {\em MDST} protocol, designed as a {\em fair
composition} of Merlin--Segall's stabilizing protocol and a
distributed deterministic stabilizing protocol solving the (MDST)
problem. The resulting randomized distributed algorithm presented
herein is a composition of the two stages; it stabilizes in
 expected time, and uses  memory bits (where  is the order of
the graph,  is the maximum degree of the network, 
is the diameter in terms of hops, and  is
the largest edge weight). To our knowledge, our protocol is the very
first distributed algorithm for the (MDST) problem. Moreover, it is
fault-tolerant and works for any anonymous arbitrary network.
\end{abstract}

\section{Introduction}\label{intro}
Many computer communication networks require nodes to broadcast
information to other nodes for network control purposes, which is done
efficiently by sending messages over a spanning tree of the network.
Now optimizing the worst-case message propagation delays over a
spanning tree is naturally achieved by reducing the diameter to a
minimum (see Sect.~\ref{mdstprob}); especially in high-speed
networks (where the message delay is essentially equal to the
propagation delay). However, when communication links fail or come up,
and when processors crash or recover, the spanning tree may have to
be rebuilt. When the network's topology changes, one option is to
perform anew the entire computation of a spanning tree with a minimum
diameter from scratch. We thus examine the question of designing an
efficient fault-tolerant algorithm, which constructs and dynamically
maintains a minimum diameter spanning tree of any anonymous
network. The type of fault-tolerance we require is so-called {\em
``self-stabilization''}, which means, informally, that an algorithm
must be able to ``recover'' from any arbitrary transient fault. In
this setting, we exhibit a self-stabilizing minimum diameter spanning
tree.  Our algorithm is asynchronous, it works for arbitrary anonymous
network topologies (unique processes ID's are not required), it is
uniform (i.e., every process executes the same code; processes are
identical), symmetry is broken by randomization, and it stabilizes in
efficient time complexity.

\subsection{Self-Stabilizing Protocols}\label{ssproto}
We consider distributed networks where processes and links from time
to time can crash and recover (i.e., dynamic networks), where
additionally, when processes recover, their memory may be recovered
within an arbitrary inconsistent state (to model arbitrary memory
corruption). Despite these faults, we wish the network to be able to
maintain and/or to be able to rebuilt certain information about itself
(e.g., in this particular case, maintaining a minimum diameter
spanning tree). When the intermediate period between one recovery and
the next failure is long enough, the system stabilizes.

The theoretical formulation of this model was put forth in the seminal
paper of Dijkstra \cite{Dijk74}, who, roughly, defined the network to
be ``self-stabilizing'' if starting from an {\em arbitrary} initial
state (i.e., after any sequence of faults), the network after some
bounded period of time (denoted as {\em stabilization time}) exhibits
a behaviour as if it was started from a good initial state (i.e,
stabilizes to a ``good'' behaviour, or ``legitimate state''). Notice
that such a formulation does not allow any faults during computation,
but allows an arbitrary initial state. Thus, if new faults occur
during computation, it is modelled in a self-stabilizing formulation
as if it were a {\em new initial state} from which the network again
must recover.
In summary, self-stabilization is a very strong fault-tolerance
property which covers many types of faults and provides a uniform approach
to the design of a variety of fault-tolerant algorithms.

\subsection{The Minimum Diameter Spanning Tree (MDST) Problem}\label{mdstprob}
The use of a control structure spanning the entire network is a
fundamental issue in distributed systems and interconnection networks.
Since {\em all} distributed total algorithms have a time complexity
, where  is the network diameter, a spanning tree of
minimum diameter makes it possible to design a wide variety of time
efficient distributed algorithms.

Let  be a connected, undirected, positively real-weighted
graph. The {\bf (MDST) problem} is to find a spanning tree of~ of
minimum diameter.

In the remainder of the paper, we denote the problem (MDST), {\em
MDST} denotes the protocol and MDST abbreviates the ``Minimum Diameter
Spanning Tree''.

\subsection{Related Works and Results}
The few literature related to the (MDST) problem mostly deals
either with graph problems in the Euclidian plane (Geometric Minimum
Diameter Spanning Tree), or with the Steiner spanning tree
construction (see~\cite{HLCW91,IhRW91}). The (MDST) problem is clearly
a generalization of the (GMDST) problem. Note that when edge weights are
real numbers (possibly negative), The (MDST) problem is NP-complete.

Surprisingly, although the importance of having a MDST is well-known,
only few papers have addressed the question of how to design
algorithms which construct such spanning trees.  While the problem of
finding and dynamically maintaining a minimum spanning tree has been
extensively studied in the literature (e.g., \cite{Awer87,GaHS83} and
\cite{AwCK90,EITT+92}), there exist no algorithms that
construct and maintain dynamically information about the diameter,
despite the great importance of this issue in the applications. (Very
recently, the distributed (MDST) problem was addressed in
\cite{BuBu93b,Lava95}). In this paper, we present an algorithm which
is robust to transient failures, and dynamically maintains a minimum
diameter spanning tree of any anonymous network: a much more efficient
(computationally cheaper) solution indeed than recomputing from
scratch over and over again.

As opposed to the (quasi-) absence of investigations dealing with the
(MDST) problem, and although self-stabilization is quite a new strand
of research in distributed computing, a large number of
self-stabilizing algorithms and theoretical related results were
proposed during the past few years (e.g.,
\cite{AfBr89,AnEH92,AKMP+93,APVD94,DoIM91a,DoIM91b,DoIM93,DoIM95b,KaPe93,ShRR95,Varg94}).  Due to their features,
self-stabilizing protocols were first used in the design of many
existing systems (e.g., DECNET protocols \cite {Perl83}).

Our distributed self-stabilizing algorithm is composed of a first
uniform stabilizing randomized stage protocol {\em UN} of {\em
``unique naming''} for arbitrary anonymous networks and of a second
stabilizing stage protocol {\em MDST}, which constructs a MDST. The
second stage performs a MDST protocol for {\em named} networks which
results after the first stage stabilizes.  This second stage is itself
constructed as the {\em fair composition}
\cite{DoIM93,DoIM95b,ShRR95} of Merlin--Segall's stabilizing
distributed routing protocol and a new deterministic
protocol for the (MDST) problem. The resulting algorithm  is
thus a composition of the two stages (see Sect.~\ref{correct})
to obtain a randomized, uniform, self-stabilizing MDST algorithm 
for general anonymous graph systems.

The complexity of protocols is analyzed by the following
complexity measures. The {\bf Time Complexity} of a self-stabilizing
algorithm is mainly defined as the time required for stabilization (or {\em
``round complexity''}). More formally, the {\em stabilization time} of a
self-stabilizing deterministic (resp. randomized) algorithm is the
maximal (resp. maximal expected) number of rounds that takes the
system to reach a legitimate configuration, where the maximum is taken
over all possible executions (see the model  in Sect.~\ref{model}). 
The {\bf Space Complexity} of a self-stabilizing algorithm can be
expressed as the number of bits required to store the state of each
process; i.e., in the message passing model, the maximal size of local
memory used by a process. The {\bf Communication Complexity} is
measured in terms of the number of bits of the registers; i.e., in the
message passing model, the maximal number of bits exchanged by the
processes until an execution of the algorithm stabilizes. The time,
space and communication complexities of a composed algorithm are the
sum of the complexities of the combined protocols.

\subsubsection{Main contributions of the present paper}
\bi
\item A first stage consisting of a uniform stabilizing randomized
{\em UN}  protocol for any arbitrary network~, which is an adapted
variant of the UN protocol designed in \cite{AnEH92}. In model ,
our randomized {\em UN} protocol stabilizes in 
expected time, with a space complexity .
\item An original second stage stabilizing protocol {\em MDST}, which is
designed as the fair composition of Merlin--Segall's stabilizing
routing protocol and a new deterministic protocol for the (MDST)
problem. The second stage thus constructs a MDST of the named network
. In the model , the protocol {\em MDST} stabilizes in
 time, and its space complexity
is  bits (where  is the maximum degree
of~,  is the diameter in terms of hops and  is the
largest edge weight).
\item In model , the resulting randomized composed algorithm
 stabilizes in  expected
time and uses
 memory bits. To our knowledge, it appears
to be the very first algorithm to {\em distributively} solve the (MDST)
problem. Moreover, our randomized distributed algorithm  is
fault-tolerant and works for any anonymous arbitrary network.
\ei

The remainder of the paper is organized as follows: in
Sect.~\ref{model}, we define the formal model  and
requirements for uniform, self-stabilizing protocols, and in
Sect.~\ref{algo} we present the stages of the composed uniform
self-stabilizing MDST algorithm . Section~\ref{correct} and
Sect.~\ref{anal} are devoted to the correctness proof, and to the
complexity analysis of stabilizing protocols ({\em UN}, {\em MDST},
and algorithm ), respectively. The paper ends with concluding
remarks in Sect.~\ref{concl}.

\section{Model  (Message Passing)}\label{model}
Formal definitions regarding Input/Output Automata are omitted from this
abstract \cite{APVD94,Varg94}.

{\bf IO Automata, Stabilization, Time Complexity --}
An Input/Output Automaton (IOA) is a state machine with state transitions
which are given labels called {\em actions}. There are three kinds of actions.
The environment affects the automaton through {\em input actions} which
must be responded to in any state. The automaton affects the environment
through {\em output actions}; these actions are controlled by the automaton
to only occur in certain states. {\em Internal actions} only change the
state of the automaton without affecting the environment.

Formally, an IOA is defined by a {\em state} set , an {\em action} set
, a {\em signature Z} (which classifies  into input, output, and
internal actions), a {\em transition relation} , and a non-empty set of {\em initial states} . We mostly
deal with {\em uninitialized IOA}, for which  ( finite). An action
 is said to be {\em enabled} in state  if there exist  such
that ; input actions are always enabled.
When an IOA ``runs'', it produces an execution. An {\em execution fragment}
is an alternating sequence of states and actions ,
such that  for all . An execution fragment
is {\em fair} if any internal or output action which is continuously
enabled eventually occurs. An {\em execution} is an execution fragment
which starts with an initial state and is fair. A {\em schedule} is a
subsequence of an execution consisting only of the actions. A {\em
behaviour} is a subsequence of a schedule consisting only of its input
and output actions. Each IOA generates a set of behaviours. Finally, let
 and  denote two IOA, we say that  {\em stabilizes} to  if
every behaviour of  has a suffix which is also a behaviour of .

For time complexity, we assume that every internal or output action which
is continuously enabled occurs in one unit of time. We say that 
stabilizes to  in time  if  stabilizes to  and every behaviour
of  has a suffix which occurs within time . The {\em stabilization
time} from  to  is the smallest  such that  stabilizes to 
in time .

{\bf Network Model --} The model  is for message passing
protocols. The system is a standard point-to-point asynchronous
distributed network consisting of  communicating processes
connected by  bidirectional links. As usual, the network topology
is described by a connected undirected graph , devoid of
multiple edges and loop-free.  is defined on a set  of vertices
representing the processes and  is a set of edges representing the
bidirectional communication links operating between neighbouring
vertices: in the sequel, , and .  We view
communication interconnection networks as undirected graphs.
Henceforth, we use the terms {\em graph} (resp. {\em nodes}/{\em
edges}) and {\em network} (resp. {\em processes}/{\em links})
interchangeably.

Each node and link is modelled by an IOA \cite{APVD94,Varg94}.  A
protocol is {\em uniform} if all processes perform the same protocol
and are indistinguishable; i.e., in our model, we do not assume that
processes have unique identities (ID's). We drop the adjective
``uniform'' from now on. The model  assumes that the messages
are transferred on links in FIFO order, and in a finite but unbounded
delay.  It is also assumed that any non-empty set of processes may
start the algorithm (such starting processes are ``initiators''),
while each non-initiator remains quiescent until reached by some
message.  In model , processes have no global knowledge about
the system (no structural information is assumed), but only know their
neighbours in the network (through the mere knowledge of their ports).
In particular, the model  assumes that nothing is known about
the network size  or the diameter  (no upper bound on  or
on  is either known). Regarding the use of memory,  is
such that the amount of memory used by the protocols remains bounded,
i.e., only a bounded number of messages are stored on each link at any
instant. The justification for this assumption is twofold: first, not
much can be done with unbounded links in a stabilizing setting
\cite{APVD94,DoIM91a,Varg94}, and secondly, real channels are
inherently bounded anyway. In other words, we model bounded links as
unit capacity data links which can store at any given instant at most
one circulating message. A link  from node  to node  is
modelled as a queue , which can store at most one message from
some message alphabet  at any instant time. The external
interface to the link  includes an input action {\sc
Send} (``send message  from ''), an output action {\sc
Receive} (``deliver message  at ''), and an output
action {\sc Free} (``the link  is currently free'').  If a
{\sc Send} occurs when , the effect is
that ; when , {\sc Free} is
enabled.  If a {\sc Send} occurs when , there is no change of state. Note that by the above timing
assumptions, a message stored in a link will be delivered in one unit
of time.

We refer to \cite{APVD94} for detailed and formal definitions of the
notions of {\em queued node automaton}, {\em network automaton for a
graph G}, and similarly for the notions of {\em internal reset} and
{\em stabilization by local checking and global reset}. (See
Sect.~\ref{correct} for the definition of local checkability and the
statement of the two main theorems used in the correctness proof of the
algorithm).

\section{The Algorithm}\label{algo}
Let  be a connected, undirected, positively
real-weighted graph, where the weight of an edge  is
given by . In the remainder of the paper, we use the
graph theoretical terminology and notation. The weight of a path
 of~ () is defined as
. For all nodes  and ,
the {\em distance} from  to , denoted , is the lowest
weight of any path length from  to  in  ( if no such
path exists).  The distance  represents the {\em shortest
path} from  to , and the largest (maximal) distance from node
 to all other nodes in , denoted , is the {\em
separation} of node : viz. ~\cite{Chri75}.   denotes the diameter of , defined as
, and  the diameter in
terms of hops.  denotes the radius of , defined as
.  represents a shortest-paths
tree (SPT) rooted at node : .  The set of all SPT's of  is then
denoted . The name of the graph will be omitted when it is clear from the context.

\subsection{A High-Level Description}

\subsubsection{Unique Naming Protocol} \label{un}
The {\em unique naming} protocol solves the (UN) problem, where each
process  must select one ID distinct from all other processes'.
The protocol executes propagation of information (propagation of the
ID of process ) and feedback ( collects the ID's of all other
processes): i.e., a ``PIF'' protocol.  Our randomized stabilizing
protocol {\em UN} is a variant of the memory adaptive UN PIF protocol
presented in \cite{AnEH92} and slightly differs in the following
respects.  First, our results hold for the message passing model , even though they can easily be transposed in the link register
model (and {\em vice versa}: the results in \cite{AnEH92} can easily
be extended to the message passing model).  Next, we do not use the
ranking phase designed in the original protocol, but a simple ID's
conflict checking phase. Besides, our maximum estimate for the size of
the network is arbitrarily chosen to be  (see the proof of
Theorem~\ref{thm:unc} in~\cite{BuBL95}), instead of  in~\cite{AnEH92}.  Note that the model  assumes that
nothing is known about  or  (not even an upper bound),
therefore, the UN Monte-Carlo protocol in
\cite{AnEH92} {\em cannot} be turned into a randomized Las Vegas
protocol (e.g., a protocol solving the (UN) problem with probability~1).

Due to the lack of space, we do not give a detailed description of our
protocol {\em UN} herein. A full description of the three phases executed
in the protocol
can be found in~\cite{AnEH92} (for the original version) and in~\cite{BuBL95}
(for our own variant). However, for better understanding of self-stabilization
(showed in Sect.~\ref{correct}), let us just point out the behaviour of
protocol {\em UN}
in phase~3. Each process in phase~3 repeatedly broadcasts a message
with its ID. At the end of each broadcast, if  detects a conflict, it
initiates a Reset. In addition,  collects the ID's of all other processes
(provided by feedback) and checks that all processes have unique ID's.
The variable  contains the list of ID's of the visited processes.
At the beginning of each broadcast, it is set to the initiator's ID;
each visited process attaches its own ID to the list before forwarding it
to its neighbours.
After stabilization, every process remains forever in phase~3.

\subsubsection{Construction of a MDST} \label{mdst}
The definition of separation must be generalized to {\em ``dummy nodes''}
(so-called in contrast to actual vertices of ). Such a fictitious
node may possibly be inserted on any edge . Thus, let 
be an edge of weight , a dummy node  inserted on
 is defined by specifying the weight  of the segment
.  According to the definition, the separation  of
a {\em general node} , whether it is an actual vertex in  or a
dummy node, is clearly given by: .
A node  such that  is
called an {\it absolute center} of the graph. Recall that 
always exists in a connected graph, and that is not unique in general.

\begin{figure}[hbt]
\centering
\includegraphics[height=5cm]{mdstex.jpg}
\caption{Example of a MDST  ( and )}
\label{fig:mdst}
\end{figure}

Similarly, the definition of  is also generalized so as to
take these dummy nodes into account. Finding a MDST actually amounts
to search for an absolute center  of , and the SPT rooted
at  is then a MDST of . Such is the purpose of the
following Lemma:

\begin{lemm}\label{lem:abscenter} {\rm \cite{CaGM80}}
The (MDST) problem for a given graph  is (polynomially) reducible to
the problem of finding an absolute center of .
\end{lemm}

\subsubsection{Computation of an absolute center of a graph} \label{center}\hfill

\noindent
According to the results in~\cite{Chri75}, we use the following Lemma
to find an absolute center of~.

\begin{lemm}\label{lem:hackimi}
Let  be a weighted graph. An absolute center 
of  is constructed as follows:

\vspace{-0.9\baselineskip}
\be
\item[(i)] On each edge , find a general node 
of minimum separation.
\item[(ii)] Among all the above 's,  is a node
achieving the smallest separation.
\ee
\end{lemm}

\begin{proof}(the proof is constructive)

{\em (i)} This first step is performed as follows: for each edge , let
. Since the distance  is the length
of either a path , or a path ,


If we plot  and  in Cartesian coordinates for fixed , the
real-valued functions  and 
(separately depending on  in the range ) are
represented by two line segments  and ,
with slope  and , respectively. For a given , the
smallest of the two terms  and 
(in~(\ref{eq:sep})) is thus found by taking the {\em convex cone} of
 and . By repeating the above process for
each node , all convex cones of segments 
and  are clearly obtained (see
Fig.~\ref{fig:bound}).

Now we can draw the {\em upper boundary}  () of all the above convex cones of segments  and .  is thus a curve made up
of piecewise linear segments, which passes through several local
minima (see Fig.~\ref{fig:bound}). The point  achieving the
smallest minimum value (i.e., the global minimum) of 
represents the absolute center  of the edge~.

\medskip
{\em (ii)} By definition of the 's, , and  achieves the
smallest separation. Therefore, an absolute center of the graph is found
at any point where the minimum of all 's is attained.
\end{proof}

\begin{figure}[htb]
\centering
\includegraphics[height=5cm]{mdstenv.jpg}
\caption{Example of an upper boundary }
\label{fig:bound}
\end{figure}

By Lemma~\ref{lem:hackimi}, we may consider this method from an
algorithmic viewpoint. For each , let  be the set of
pairs  Now, a pair  is said to {\em dominate} a
pair  iff , and  (viz. the
convex cone of  is over the convex cone of ).
Any such pair  will be ignored when it is dominated by
another pair .

Notice that the local minima of the upper boundary 
(numbered from~1 to 3 in Fig.~\ref{fig:bound}) are located at the
intersection of segments  and
, when all dominated pairs are removed. If we
sort the set  in descending order with respect to the
first term of each remaining pair , we thus obtain the list
 consisting in all such
remaining ordered pairs. Hence, the smallest minimum of 
for a given edge  clearly provides an absolute center .
(See Procedure {\tt Gamma\_star()} in Sect.~\ref{formal}). By
Lemma~\ref{lem:hackimi}, once all the 's are computed,
an absolute center  of the graph is obtained. By
Lemma~\ref{lem:abscenter}, finding a MDST of the graph reduces to
the problem of computing~.

\subsubsection{All-Pairs Shortest-Paths Protocol (APSP)}\label{apsp}\hfill

\noindent
In the previous paragraph, we consider distances
 and , for all  and each edge . Such
distances must be computed by a failsafe distributed routing protocol,
e.g., Merlin--Segall's APSP protocol designed in~\cite{MeSe79}.

The justification for this choice is threefold. First, shortest paths
to each destination  are computed by executing the protocol
independently for each . Thus, an essential property of
Merlin--Segall's algorithm is that the routing tables are cycle-free
at any time (Property (a) in \cite{MeSe79}).  Next, the protocol is
also adapted to any change in the topology and the weight of edges
(Property (b)).  Finally, the protocol converges in dynamic networks
and is indeed self-stabilizing (Property (c)). (See
Lemma~\ref{lem:l}).

\subsection{A Formal Description}\label{formal}
Assume the list  defined above (in Paragraph~\ref{center}) to be
already constructed (for example with a heap,
whenever the routing tables are computed), the following procedure computes
the value of  for any fixed edge~.

\algo{Procedure {\tt Gamma\_star()}}{
\begin{tabbing}\tabulation\>
{\bf var}  : real \hspace{0.5cm} {\bf Init}  ;
 ;\+\\
{\bf For} i=1 to  {\bf do}\+\\
{\sl compute the intersection  of segments  and
~:}\\
 ;
\\
{\bf if}  {\bf then}  ;  ;\-\\
{\bf Return}(,)
\end{tabbing}
}

The distributed protocol {\em MDST} finds a MDST of an input graph
 by computing the diameter of the SPT's for all nodes.
Initially, an edge weight  is only known by its two
endpoints  and .  In the first stage, the randomized,
stabilizing protocol {\em UN} provides each process  with its
unique ID, denoted  (see Sect.~\ref{un}).

\algo{Protocol  (for process )}{
\begin{tabbing}xxx\=\kill\>
{\bf Type} \=elt : {\bf record} ,
 : real ; , : integer {\bf end} ;\+\\
{\bf Var} \> : set of elt ; ,  : elt ;
, , ,  : real ;\+\\
 : array of weights ;\hspace{2cm}{\em (*  estimates  *)}
\end{tabbing}
\vspace{-2mm}
\be
\item {\bf For all} \\
Compute ,  and  ; \hfill{\em (* by Merlin--Segall's protocol *)}
\item  ;
\item {\bf While}  {\bf do for} any
edge  s.t. 
    \be
    \item  {\tt Gamma\_star()} ;
    \item {\bf If}  {\bf then}
     ;
    \ee
\item  ;
\item {\bf Receive}  from all sons of 
in \\
( is s.t. ) ;
 ;
\item Minimum finding:
    \be
    \item Compute  s.t.

;\\
    {\bf Send}  to father in  ;
    \item {\bf If}  {\bf then}
    upon reception of  from all sons of ,
     forwards  to all other nodes.
    \ee
\ee
\vspace{-2mm}
}

\begin{rmk}
In order to complete self-stabilization, the deterministic protocol
{\em MDST} must be repeatedly executed .

A {\em sequential} algorithm for the (MDST) problem may also be
derived from the above protocol, since  is then a MDST of ,
where  is the general node s.t. .
\end{rmk}

\noindent
{\bf Improvements:}\, In practice, some improvements in protocol {\em MDST}
can easily be carried out. Indeed, reducing the enumeration of dummy nodes
may be done by discarding several edges of  from the exploration.
To be able to discard an edge, we only need to know bounds on the minimum
diameter  of all spanning trees of . Note that the lower bound on
 is obviously , and that  is also bounded from above by the
minimum diameter taken over all SPT's, viz. . In the example of Fig.~\ref{fig:mdst}, such
improvements lead to discard from the exploration the edges
EF, AB, AC, BF, CD, DE, EG, FG. (See~\cite{BuBL95}).

\section{Correctness}
\subsection{Self-Stabilization}\label{ss}
Fix a network automaton  for a given graph , the definition of
local checkability is stated as follows~\cite{APVD94}.

\begin{defi}\label{def:local}
Let  be a set of local predicates, and let 
be any predicate of . A network automaton  is locally
checkable for  using  if the following conditions hold.

(i) For all states , if  satisfies  for all
, then .

(ii) There exists  such that  satisfies 
for all .

(iii) Each  is stable: for all transitions
 of , if  satisfies  then so does .
\end{defi}

The main theorem in \cite{APVD94} is about self-stabilization by local
checking and global reset. Roughly, it shows that any protocol which
is locally checkable for some global property can be transformed into
an equivalent protocol, which stabilizes to a variant of the protocol
in which the global property holds in its initial state. This
transformation increases the time complexity by an overhead given
in~\cite[Theorem 10]{APVD94}.

Also recall the fundamental Theorem~\ref{thm:comp} which states the
fair composition of two stabilizing protocols  and  \cite{DoIM93}.
\begin{thm}\label{thm:comp}
If the four conditions hold,

(i) protocol  stabilizes to ;

(ii) protocol  stabilizes to  if  holds;

(iii) protocol  does not change variables used by  once
 holds; and,

(iv) all executions are fair w.r.t. both  and ,

then the fair composition of  and  stabilizes to .
\end{thm}

\subsection{Correctness Proof}\label{correct}
Let  be a predicate over the variables of protocol {\em UN},
and  a predicate over the variables of protocol {\em MDST}
(see Sect.~\ref{model}). Now, protocol {\em MDST} is the fair combination
of two subprotocols. The first protocol uses Merlin--Segall's APSP routing
algorithm (see Sect.~\ref{apsp}),
while the second subprotocol deterministically
computes the value  (see Sect.~\ref{center}). Hence, the local
predicates  and  corresponding to the predicates
 and , respectively, are defined by

where the variable  is defined in Sect.~\ref{un}.
And, similarly,


Note that this does not mean that the estimate values  are exact,
but that they are not too bad. Of course, if some distances  are
wrong, it may cause the construction of a MDST to fail. However, the
routing protocol is self-stabilizing, and after a while the estimate
distances shall be correct and a MDST will be found.

\begin{lemm}\label{lem:l}
Let  be the set of local predicates over the
variables of the randomized protocol UN. A network automaton 
is locally checkable for  using .
\end{lemm}

\begin{proof}
(By Definition \ref{def:local}).
Condition {\em (i)} clearly holds by the definition of .
Condition {\em (ii)} holds for a state  such that
processes ID's are all distinct in phase~3.

Now suppose  satisfies . In the case when
no failures occur,  and  obviously remain in phase~3 by construction
of protocol {\em UN}. In the case when nodes recoveries occur (with
arbitrary ID's),  and  are able to detect conflicts and if
necessary they initiate a Reset. After a while, each process (and
especially  and ) returns to phase~3 with one unique ID.
Therefore, condition {\em (iii)} holds.
\end{proof}

\begin{lemm}\label{lem:l'}
Let  be the set of local predicates over the variables
of Merlin--Segall's APSP protocol.
A network automaton  is locally checkable for  using .
\end{lemm}

\begin{proof}
(By Definition \ref{def:local}).
Condition {\em (i)} clearly holds by the definition of .
Since  is connected, there exists a path  such that the
distance  is finite. Hence, condition {\em (ii)} holds
for the corresponding state .
Finally, condition {\em (iii)} clearly holds by convergence
of Merlin--Segall's routing protocol. (See \cite[Property~(c)]{MeSe79}, and
Sect.~\ref{apsp}).
\end{proof}
Recall that  denotes the best value of 
computed so far at node . We show now that both protocols {\em MDST} and  stabilize to the
desired postcondition  defined by:

The local predicate  corresponding to  is defined by:


\begin{lemm}\label{lem:mdst-stab}
Assume processes ID's are all distinct, the protocol MDST stabilizes to
.
\end{lemm}

\begin{proof} (Sketch) First, protocol {\em MDST} is locally checkable for
 using the set .
By Definition~\ref{def:local}, conditions {\em (i)} and {\em (ii)} clearly
hold.
Condition {\em (iii)} derives from the fact that Merlin--Segall's
protocol stabilizes to , while the computation of  is
deterministic. Consequently, protocol {\em MDST} is locally checkable
and stabilizes to  by \cite[Theorem~10]{APVD94}.
\end{proof}

\begin{thm}\label{thm:algostab}
The randomized algorithm  stabilizes to  with probability~1.
\end{thm}

\begin{proof} The following conditions hold.

{\em (i)} By Lemma~\ref{lem:l} and \cite[Theorem~10]{APVD94},
protocol {\em UN} stabilizes to  with probability~1.

{\em (ii)} By Lemma~\ref{lem:mdst-stab},
protocol {\em MDST} stabilizes to  if  holds.

{\em (iii)} By construction,
protocol {\em UN} does not change variables used by {\em MDST}
once  holds.

{\em (iv)} Since protocol {\em MDST} terminates,
there are only finitely many executions of {\em MDST} between two
executions of {\em UN}. The protocol {\em UN} stabilizes to
 with probability~1
and since  is true, each ID remains unchanged,
and so does the computation of . Therefore,
all executions are fair w.r.t. to both {\em UN} and {\em MDST}.

By Theorem~\ref{thm:comp}, algorithm  which is the
fair composition of {\em UN} and {\em MDST} stabilizes to 
with probability~1.
\end{proof}

\section{Analysis}\label{anal}

\subsection{Protocol }
The three phases executed in protocol {\em UN} are described in
\cite{AnEH92,BuBL95}. (See Sect.~\ref{un}).

\begin{lemm}\label{lem:rounds}
Each Reset lasts at most  rounds. If two processes have the
same ID, then within at most  rounds some process in the network
will order a Reset. After a Reset, it takes the system  rounds
either to perform global memory adaptation, or to complete another
Reset.
\end{lemm}
Note that the maximum number of rounds needed for the completion of phases
1 and 2 is exactly .
\begin{lemm}\label{lem:ID's}
If  processes choose random ID's from the set ,
where , all ID's will be unique with probability
, for all .
\end{lemm}

\begin{proof}
The probability  that all processes randomly choose distinct ID's is

Assuming that , or  yields

Since , we
have that  when . Hence,
it is sufficient to randomly select the  identities from the set ,
with , in which case the identities are all
distinct with probability , for fixed .
\end{proof}

\begin{lemm}\label{lem:reset}
If after a Reset there exist  distinct ID's in the network, then a
Reset is initiated by the end of phase 2 with probability .
\end{lemm}

\sloppypar
\begin{thm}\label{thm:unc}
Let  be the maximum degree of the network. Starting from any state,
the probability that the system will stabilize in  rounds is , for some constant
 which does not depend on the network. The expected number
of rounds until protocol UN stabilizes is . The maximal
memory size used by each process in any execution of protocol UN is at most
 bits.
\end{thm}

\subsection{Protocol }\label{mdstcomp}

\begin{lemm}\label{lem:mdstc}
The time complexity of protocol MDST is at most
, and its space complexity is
 bits, where  is the largest edge weight.
\end{lemm}

\begin{proof}
It is shown in~\cite{MeSe79} that after  update
rounds, all shortest paths of at most  hops have been correctly
computed, so that after at most  rounds, all shortest paths to
node  are computed.  Shortest paths to each destination are
computed by executing the protocol independently for each destination.
Since a round costs  time, the stabilization time of
Merlin--Segall's protocol is .  Now, the computation of
 requires a minimum finding over a tree (viz., ) and
local computations on each adjacent edge of  (viz., ,
where  is the maximum degree). Hence, the stabilization time
of the protocol {\em MDST} is .

Finally,  space complexity is needed to maintain
global routing tables.
\end{proof}
Note that since , the ``hop time complexity''
used above is more accurate.

\subsection{Complexity Measures of Algorithm }

The following theorem summarizes our main result, and its proof follows from
the previous Lemma.

\begin{thm}\label{thm:complex}
Starting from any state, the probability that algorithm  will
stabilize is , for some constant  which
does not depend on the network. Recall  be the diameter
of~ in terms of hops,  the maximum degree, and  the
largest edge weight. The expected time complexity of  is
, and its space complexity is
at most  bits.
\end{thm}

Since the number of messages required in Merlin--Segall's protocol is
at most , the communication complexity of  is
 bits (where  bits is the largest
message size).

\section{Concluding Remarks}\label{concl}
We proposed a uniform self-stabilizing algorithm for distributively
finding a MDST of a positively weighted graph. Our algorithm is new.
It works for arbitrary anonymous networks topologies, symmetry is
broken by randomization; it stabilizes in  expected time, and requires at most  memory bits. The assumptions of our model  are quite
general, and in some sense, the algorithm might be considered
reasonably efficient in such a setting (even though the communication
complexity appears to be the weak point of such algorithms).
Whatsoever, the stabilization complexities can be improved in terms
of time and space efficiency by restricting the model's assumptions
and using the very recent results proposed in \cite{Dole94} and
\cite{AKMP+93}. First, the randomized uniform self-stabilizing
protocol presented in \cite{Dole94} provides each (anonymous) process
of a uniform system with a distinct identity. This protocol for unique
naming uses a predefined fixed amount of memory and stabilizes within
 expected time (where  is the diameter of the network).
Secondly, following \cite{AKMP+93}, we may restrict our model and assume
that a pre-specified bound  on the diameter  is known.
In  time units, the stabilizing protocol in \cite{AKMP+93} produces
a shortest paths tree rooted at the minimal ID node of the network;
in addition, the complexity of the space requirement and messages size
is . In this restricted model (i.e., assuming the knowledge
of an upper bound on ), the fair composition of the two protocols yields
a randomized uniform self-stabilizing algorithm which finds a MDST with
stabilization time (at most)  and space complexity . 
In this setting, the fact that the space complexity does {\em not}
depend on  makes the solution more adequate for dynamic networks.

\begin{thebibliography}{10}

\bibitem{AfBr89}\bibfmta
{Y.~Afek, G.~Brown}
{Self-stabilization of the alternating-bit protocol}
{Proc. Symp. Reliable Distr. Syst.}{pages 80-83, 1989}

\bibitem{AnEH92}\bibfmta
{E.~Anagnostou, R.~El-Yaniv, V.~Hadzilacos}
{Memory adaptative self-stabilizing protocols}
{Proc. WDAG}{pages 203-220, 1992}

\bibitem{Awer87}\bibfmta
{B.~Awerbuch}
{Optimal distributed algorithms for minimum weight spanning tree,
counting, leader election and related problems}
{Proc. ACM STOC}{pages 230-240, 1987}

\bibitem{AwCK90}\bibfmta
{B.~Awerbuch, I.~Cidon, S.~Kutten}
{Communication-optimal maintenance of replicated information}
{Proc. IEEE FOCS}{pages 492-502, 1990}

\bibitem{AKMP+93}\bibfmta
{B.~Awerbuch, S.~Kutten, Y.~Mansour, B.~Patt-Shamir, G.~Varghese}
{Time optimal self-stabilizing synchronization}
{Proc. ACM STOC}{1993}

\bibitem{APVD94}\bibfmta
{B.~Awerbuch, B.~Patt-Shamir, G.~Varghese, S.~Dolev}
{Self-stabilization by local checking global reset}
{Proc. WDAG}{pages 326-339, 1994}

\bibitem{BuBu93b}\bibfmta
{M.~Bui F.~Butelle}
{Minimum diameter spanning tree}
{OPOPAC Proc. Int. Workshop on Principles of Parallel
Computing}{pages 37-46. Herm\`es \& Inria, 1993}

\bibitem{BuBL95}\bibfmta
{F.~Butelle, C.~Lavault, M.~Bui}
{A uniform self-stabilizing minimum diameter spanning tree algorithm}
{RR. 95-07, LIPN, University of Paris-Nord}{May 1995}

\bibitem{CaGM80}\bibfmta
{P.~M. Camerini, G.~Galbiati, F.~Maffioli}
{Complexity of spanning tree problems: Part I}
{Europ. J. Oper. Research}{\textbf{5}:346-352, 1980}

\bibitem{Chri75}\bibfmtb
{N.~Christophides}
{Graph Theory: An algorithmic approach}
{Computer Science Applied Mathematics}{Academic press, 1975}

\bibitem{Dijk74}\bibfmta
{E.~W. Dijkstra}
{Self-stabilizing systems in spite of distributed control}
{CACM, \textbf{17}}{(11):643-644, 1974}

\bibitem{Dole94}\bibfmta
{S.~Dolev}
{Optimal Time Self-Stabilization in Uniform Dynamic Systems}
{Proc. 6th Int. Conf. on Parallel Distributed Computing Systems}{1994}

\bibitem{DoIM91a}\bibfmta
{S.~Dolev, A.~Israeli, S.~Moran}
{Resource bounds on self-stabilizing message driven protocols}
{Proc. ACM PODC}{1991}

\bibitem{DoIM91b}\bibfmta
{S.~Dolev, A.~Israeli, S.~Moran}
{Uniform dynamic self-stabilizing leader election Part 1: 
Complete graph protocols}{Proc. WDAG}{1991}

\bibitem{DoIM93}\bibfmta
{S.~Dolev, A.~Israeli, S.~Moran}
{Self-stabilization of dynamic systems assuming read/write atomicity}
{Distributed Computing}{\textbf{7}(1):3-16, 1993}

\bibitem{DoIM95b}\bibfmta
{S.~Dolev, A.~Israeli, S.~Moran}
{Uniform self-stabilizing leader election Part 2: General graph
protocol}{Technical report, Technion, Israel}{March 1995}

\bibitem{EITT+92}\bibfmta
{D.~Eppstein, G.~F. Italiano, R.~Tamassia, R.~E. Tarjan, J.~Westbrook, M.~Yung}
{Maintenance of a minimum spanning forest in a dynamic plane graph}
{J. of Alg.}{\textbf{13}:33-54, 1992}

\bibitem{GaHS83}\bibfmta
{R.~G. Gallager, P.~A. Humblet, P.~M. Spira}
{A distributed algorithm for minimum weight spanning trees}
{TOPLAS}{\textbf{5}(1):66-77, 1983}

\bibitem{HLCW91}
{J.-M. Ho, D.~T. Lee, C.-H. Chang, C.~K. Wong}
{Minimum diameter spanning trees related problems}
{SIAM J. Comput.}{\textbf{20}(5):987-997, Oct. 1991}

\bibitem{IhRW91}\bibfmta
{E.~Ihler, G.~Reich, P.~Wildmayer}
{On shortest networks for classes of points in the plane}
{Int. Workshop on Comp. Geometry - Meth., Algo. Applic.}
{LNCS: 103-111, 1991}

\bibitem{KaPe93}\bibfmta
{S.~Katz, K.~J. Perry}
{Self-stabilizing extensions for message-passing systems}
{Distributed Computing}{7:17-26, 1993}

\bibitem{Lava95}\bibfmtb
{C.~Lavault}
{\'Evaluation des algorithmes distribu\'{e}s : analyse,
complexit\'{e}, m\'{e}thode}{Herm\`es}{1995}

\bibitem{MeSe79}\bibfmta
{P.~M. Merlin A.~Segall}
{A failsafe distributed routing protocol}
{IEEE Trans. Comm.}{COM-27(9):1280-1287, Sept. 1979}

\bibitem{Perl83}\bibfmta
{R.~Perlman}
{Fault-tolerant broadcast of routing information}
{Computer Networks}{\textbf{7}:395-405, 1983}

\bibitem{ShRR95}\bibfmta
{S.~K. Shukla, D.~Rosenkrantz, S.~S. Ravi}
{Observations on self-stabilizing graph algorithm for anonymous
networks}{Technical report, University of Albany, NY}{1995}

\bibitem{Varg94}\bibfmta
{G.~Varghese}
{Self-stabilization by counter flushing}
{Proc. ACM PODC}{pages 244-253, 1994}

\end{thebibliography}
\end{document}
