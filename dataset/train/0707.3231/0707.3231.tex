\documentclass{article}


\usepackage{makeidx}        
\usepackage{graphicx}        
                             
\usepackage{multicol}        
\usepackage[bottom]{footmisc}

\usepackage{paralist}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{color} 
\usepackage{flafter}
\usepackage[width=0.9\linewidth]{caption}
\usepackage[vlined,ruled,titlenumbered]{algorithm2e}

\usepackage{hyperref}

\usepackage{amsthm}
\newtheorem{definition}{Definition}
\newtheorem*{definition*}{Definition}
\newtheorem{lemma}{Lemma}
\newtheorem{theorem}{Theorem}
\newtheorem{proposition}{Proposition}
\newtheorem*{proposition*}{Proposition}


\newcommand\ex{\mathrm{E}}
\newcommand\prob{\mathrm{P}}
\newcommand\var{\mathrm{Var}}
\newcommand\Real{\mathbb{R}}

\newcommand\qedheretext[1]{\hspace*{0mm}\hfill\qedsymbol\raisebox{-0.5em}{\;#1}}
\newcommand\qedsymboltext[1]{\qedsymbol\raisebox{-0.5em}{\;#1}}



\graphicspath{{.}{graphics/}}


\begin{document}

\title{Estimation of Small - Reliabilities in Acyclic Networks}
\author{Marco Laumanns and Rico Zenklusen \\
\small\texttt{\{marco.laumanns,rico.zenklusen\}@ifor.math.ethz.ch}\\
\small ETH Zurich, Institute for Operations Research, 8092 Zurich, Switzerland
}

\maketitle


\begin{abstract}
In the classical - network reliability
problem a fixed network  is given including two designated
vertices  and  (called terminals). The edges are
subject to independent random failure, and the task is to compute
the probability that  and  are connected in
the resulting network, which is known to be -complete.
In this paper we are interested in approximating the -
reliability in case of a directed acyclic original
network . We introduce and analyze an
specialized version of a Monte-Carlo algorithm given
by Karp and Luby. 
For the case of uniform edge failure probabilities, we
give a \mbox{worst-case} bound on the number of samples that
have to be drawn to obtain an  approximation,
being sharper than the original upper bound.
We also derive a variance reduction of the
estimator which reduces the expected number of iterations
to perform to achieve the desired accuracy when
applied in conjunction with different stopping rules.
Initial computational results on two types of random networks
(directed acyclic Delaunay graphs and a slightly modified version
of a classical random graph) with up to one million vertices are presented.
These results show the advantage of the introduced Monte-Carlo approach compared
to direct simulation when small reliabilities have to
be estimated and demonstrate its applicability on \mbox{large-scale}
instances.

\end{abstract}


\section{Introduction}
In the classical - network reliability problem, a
fixed graph  with two special vertices  and 
 is given whose edges fail (disappear) independently of
each other with some given probability. The task is to
determine the probability that  and  are still
connected in the resulting network after edge failures. A
famous related problem is the all-terminal reliability
problem, where the goal is to determine the probability that
all vertices are still connected to each other after edge
failures (for further information on various reliability
problems see  \cite{colbourn_1987_combinatorics}).
Both problems are known to be computationally hard
(-complete) even for very restricted classes of graphs 
\cite{valiant_1979_complexity,provan_1983_complexity}.
In particular, the - reliability problem
remains hard in the case when  is a directed acyclic planar graph of maximal degree
three \cite{provan_1986_complexity}. Therefore we are interested in finding
approximations.

Randomized algorithms respecting some
relative error bound with high probability have shown to be
interesting approaches for different reliability
problems
\cite{karp_1985_montecarlo,karger_1995_randomized,karger_1997_implementing}.
As we are interested in relative error
bounds, there is a significant difference between the
estimation of the failure probability of the network
and estimating the probability that the
network is intact after edge failures. This results from the
fact that estimating small probabilities by sampling is in
general much more difficult than estimating large probabilities.
Moreover, the techniques used for the estimation of reliability values
often differ significantly from those used for the estimation
of the failure probability.
Most of the literature concentrates on estimating the
failure probability because in typical applications, as
communication or electrical networks, we have a
highly reliable network and are interested in accurately estimating the
probability of rare failures.

In this paper, we concentrate on estimating the probability that the network is intact, i.e., the
probability that there is a path from  to  after edge
failures. This is motivated by certain models of spreading processes on networks, such as
disease spreading, which can be mapped onto reliability
problems \cite{grassberger_1983_critical,sander_2001_percolation,warren_2001_firewalls,newman_2002_spread,newman_2003_structure}. In this context,
a path from  to  represents the spread of
a disease from  to , and we are interested in estimating the
probability of the rare event that the disease spreads over a
long distance from  to  .

The basis of our approach is a method presented by Karp and Luby
\cite{karp_1985_montecarlo} for estimating the
failure probability in an - reliability problem when the
graph  is planar, which can be easily adapted for estimating the
probability of connectedness of  and  on an arbitrary graph .
To be efficiently applicable, however, the underlying graph 
needs to fulfill some additional properties, such as very low
intactness probabilities of the edges and low vertex degrees.
Furthermore, a computationally expensive preprocessing phase is
required, which computes different quantities needed to efficiently
sample from the proposed sample space. This makes the method not
suited for application on large networks. We show in
this paper that in the case of a directed acyclic network ,
some of these problems can be circumvented, and the resulting
algorithm can be applied to \mbox{large-scale} instances. The 
simplifications are due to the fact that generating
an - path uniformly at random in an acyclic graph can be
performed in linear time (see Section~\ref{sec:technical_details}). Except for very restricted classes of initial networks such
as series-parallel
networks (see \cite{satyanarayana_1985_lineartime} for
further information), no practically useful methods for estimating small
- reliabilities on large networks are known. Considering directed
acyclic graphs can thus be seen as a natural next step.

The paper is organized as follows. We begin with some
preliminaries in Section~\ref{sec:preliminaries}.
In Section~\ref{sec:direct_montecarlo} the
direct \mbox{Monte-Carlo} approach is described and
its efficiency is analyzed. Section~\ref{sec:our_algorithm}
then presents our algorithm for the estimation of small
reliabilities in directed acyclic graphs up to some technical details that
are explained in Section~\ref{sec:technical_details}. In
Section~\ref{sec:nb_samples} we discuss how many samples have
to be drawn in our algorithm to obtain a good estimate of
the reliability with high probability.
Section~\ref{sec:computational_results} contains
computational results on two types of random directed acyclic networks
comparing the direct \mbox{Monte-Carlo}
approach with our algorithm and demonstrating the applicability
of our algorithm on \mbox{large-scale} instances.

\section{Preliminaries}\label{sec:preliminaries}

Let  be a directed acyclic network, where
\begin{compactitem}
\item  is the set of vertices (with ),
\item  is the set of edges (with ), and
\item  is a function associating
  a failure probability with every edge of the network.
\end{compactitem}

We call a network  satisfying these properties an acyclic
reliability network.
Furthermore, we fix two special vertices . Every
edge  fails with probability
 independently of the others. Let  be the
resulting graph over the intact edges after the realization of the edge failures.
We say that  is
intact if it contains a path from  to ,
otherwise we say that  is in a failed state.
Finally, the - reliability   of the
network  is defined as the probability of  being
intact.

Let  be the function which
associates with every edge its probability of being intact,
i.e., . It is sometimes easier
to look at our reliability model in a different way where edges
appear rather than disappear. In this model we would begin
with an empty network and flip a biased coin for all
potential edges  to determine whether they appear.

We are mainly interested in ~approximations
for , i.e., algorithms
returning an estimate of  accurate to
within a relative error of  with probability
at least .
To determine how many samples we have to draw in a
\mbox{Monte-Carlo} algorithm to obtain an ~approximation
we often refer to the Generalized \mbox{Zero-One} Estimator Theorem
introduced by Dagum et al. in \cite{dagum_2000_optimal}. The theorem is repeated
below.

\begin{theorem}[Generalized Zero-One Estimator Theorem]\label{thm:generalized_01_thm}
Let  be a random variable taking values in  and let
 denote independent random variables distributed
identically to . If
 and

then

\end{theorem}

We typically use the theorem in the following form. If
 then  is an
~approximation for  (using the fact
that a random variable  taking values in 
satisfies ).

\section{A direct Monte-Carlo approach}\label{sec:direct_montecarlo}

In this section we consider a simple \mbox{Monte-Carlo} approach and
show that it is efficient for sufficiently large values of
, but inefficient for the estimation of small
reliabilities.
In this approach we simply flip a biased coin for every edge 
and observe whether  and  are connected in the resulting graph. Let
 be the random variable corresponding to this approach
where  if the resulting network is intact and  otherwise.
The random variable  has thus a Bernoulli
distribution with parameter 
and the reliability is estimated without bias by 
generating  independent realizations of  and returning their
empirical mean which we denote by . 
A central question when using this method is how
large  has to be chosen to obtain an ~approximation.
A direct application of Theorem~\ref{thm:generalized_01_thm}
gives the following:

\begin{theorem}\label{thm:montecarlo_approx}
 is an ~approximation of
 if  satisfies

\end{theorem}

When  is bounded below by
,  is an FPRAS (~approximation algorithm
with running time bounded by a polynomial in  and the
input size). The difficult case is the estimation of small values, i.e.,
small reliabilities . This problem
motivated the construction of the algorithm to be presented next.

\section{Monte-Carlo method for estimating small reliabilities}\label{sec:our_algorithm}

The backbone of our algorithm is an
adaption of the \mbox{Monte-Carlo} method presented in
\cite{karp_1985_montecarlo}.
Our algorithm exploits that, in a directed acyclic network,
we can easily (in linear time) calculate
the mean number of intact paths from  to  after the edge failures.
This value is normally a good estimate for the reliability
in highly unreliable networks as in such networks an intact
state typically contains only
a few paths from  to . Using a \mbox{Monte-Carlo} approach,
our algorithm then estimates the ratio between
 and the mean number of intact paths from  to  after edge
failures. Multiplying this estimate
with the mean number of intact paths from  to  yields
finally an estimate for the - reliability of the network.

Note that the ratio between the mean number of intact paths from  to  after
edges failures and the reliability to estimate, i.e., the reciprocal of the value we
estimate in our algorithm, is exactly the mean number of
intact paths from  to  after edge failures conditioned on the event that
the network will be intact after the failure process. One of the main problems for
the development of methods for directly estimating this ratio is the difficulty
of choosing a sample out of the pool of intact states with probability proportional to
its real appearance probability. In fact such a sampling procedure could easily be
transformed into an FPRAS for the estimation of 
using techniques presented by Jerrum et al. \cite{jerrum_1986_random}.


\subsection{Notation}
Let  be the set of all
possible states of the network  after the realization of the edge failures,
where a state  represents the collection of intact
edges.
Furthermore, let  be the set of all intact states.
For every state 
we denote by  the probability that  occurs after
the edge failure process, i.e., \;.
In particular, the weight of the set  is the reliability
we want to estimate, .

Let  be the set of all paths in
 from  to . A path  is simply represented
by a subset of the edges . For every state  we
denote by  the set
of all paths from  to  in state . A state 
is intact if and only if we have
.
With every path 
we associate a weight  which is the probability
that all edges on the path will be intact after the edge
failure process, \;.

The mean number of intact paths from  to 
after edge failures can thus be
written as . In
Section~\ref{sec:technical_details} we will see how this quantity
can be efficiently calculated in acyclic graphs.

\subsection{Estimating the ratio between
\texorpdfstring{{\mathversion{bold}}}{} and the mean number of intact paths from
\texorpdfstring{{\mathversion{bold}} to {\mathversion{bold}}}{ to } after edge
failures}



To estimate the ratio between the reliability and the mean number
of intact paths from  to  after edge failures we
sample out of the sample space

where we associate the weight  with every element .
This sample space has the following
interesting properties. On the one hand, the weight of the sample
space is exactly the mean number of intact paths from  to 
after edge failures, i.e.,

On the other hand, it is easy to sample
elements of  with probability proportional to their
weights by the following two-step procedure.
In a first step, a path  is drawn
with probability proportional to its weight . How this
can be done efficiently will be discussed in
Section~\ref{sec:technical_details}. In the second step,
all edges not contained in  are sampled corresponding to their
appearance probabilities. The appeared edges of the second step together
with the edges in  form an intact state . The tuple
 is finally the sampled state.

We will now introduce influence values for the elements in 
such that the expected influence value of a sample of  is
equal to . The expected influence value
can then be estimated by a standard \mbox{Monte-Carlo} algorithm.

The approach taken in \cite{karp_1985_montecarlo} was to fix for every intact
state  an arbitrary - path . We begin by following this approach and
introduce later on another idea to reduce the
variance of the estimator. With every sample we associate an
influence value which
is equal to one if the sample is of the form 
and equal to zero otherwise. The influence value of a sample
corresponds therefore
to the realization of a Bernoulli variable with parameter

which is precisely the value we would like to estimate. By repeating the sampling procedure
 times and counting the fraction of samples of the
form  we therefore obtain an unbiased estimator 
for  with variance


Another unbiased estimator  for 
with smaller variance than  can be
obtained by associating an influence value
 with every sample
, and we define
 to be simply the mean of the influence values
of our samples. This
approach is particularly interesting in our case as the fact
of  being acyclic allows to compute the value
 in linear time (see Section~\ref{sec:technical_details})
and thus does not increase the overall worst-case complexity of our
algorithm. The reduction of the variance decreases the expected number
of iterations to perform for obtaining an  approximation
when applying a stopping criterion as presented in
Section~\ref{sec:nb_samples}.

Unfortunately, we cannot guarantee some minimal decrease of the variance
of the estimator  compared to  as there are instances
of reliability networks where we have an arbitrarily low decrease.
On the other hand, it is easy to find instances where the variance
reduces by an arbitrarily high factor.

We finally estimate  by multiplying  by
the weight of the sampling space () which can be calculated
efficiently as shown in the next section.  Algorithm \ref{alg:montecarlo_psi}
gives a pseudocode for an implementation of the - reliability
estimation based on .
Note that the sampling of the edges not on the path performed in
Algorithm~\ref{alg:montecarlo_psi} in lines
\ref{algline:sampling_remaining_edges} to \ref{algline:end_sampling} can
be done more efficiently as in general we do not need to sample all edges
for calculating .
In Section~\ref{sec:technical_details} we will see how this part of the algorithm can
be improved and show how to perform the remaining unspecified parts of our algorithm.
More precisely, we will discuss the following operations, where  represents the
time needed for generating a random number uniformly in :
\begin{compactitem}
\item Sampling in  time a path according to line~\ref{algline:path_sampling} of
Algorithm~\ref{alg:montecarlo_psi},
\item Determining in  time the weight  of the sampling space  used in
line~\ref{algline:w_omega} of Algorithm~\ref{alg:montecarlo_psi},
\item Sampling edges not being on the initial path 
and calculating  as needed in
lines~\ref{algline:sampling_remaining_edges} to
\ref{algline:multiplicity} of Algorithm~\ref{alg:montecarlo_psi}.
\end{compactitem}

\linesnumbered
\begin{algorithm}[H]
\SetLine
\caption{Estimation of 
based on \label{alg:montecarlo_psi}}
\SetKwInOut{Input}{Input}
\SetKwInOut{Output}{Output}
\Input{An acyclic reliability network  with two special
  terminals  and the number  of iterations to perform}
\Output{An estimate for }
\;
\For{ to }{
\;
Draw a random path  out of the set 
with probability proportional to \label{algline:path_sampling}\;
\;
\ForEach{}{\label{algline:sampling_remaining_edges}
  Take a sample  of a Bernoulli variable with parameter
   to determine whether the edge  appears\;
  \If{ (the edge appears)}{
    \;
  }
}\label{algline:end_sampling}
Determine \label{algline:multiplicity}\;
\;
}
\;
Determine \label{algline:w_omega}\;
\Return{}
\end{algorithm}

\section{Algorithmic details}\label{sec:technical_details}

\subsection{Sampling \texorpdfstring{{\mathversion{bold}}-{\mathversion{bold}}}{-} paths}

We begin by studying how paths can be efficiently sampled
according to line \ref{algline:path_sampling} of Algorithm~\ref{alg:montecarlo_psi}.
The idea is to start at the terminal
 and then to construct a path to  by successively
adding new edges. The choice of a new edge augmenting the
current partial path is done in the following way. With every
edge  we associate a weight 
which is the sum of the weights of all paths from  to 
using edge , i.e.,


During the path sampling method, after a partial path from
 to some vertex  is constructed, we choose an
outgoing edge of vertex  with probability
proportional to the weights . It is easy to
verify that this procedure effectively samples a path
 with probability proportional to
 as desired. Furthermore, the edge weights
 can be easily computed by the following
procedure.

We suppose without loss of generality that every edge lies
on at least one path from  to  in . All edges not
satisfying this condition can be eliminated in  time
in a preprocessing step. We then determine a
topological order of the vertices. By the condition mentioned above
it is clear that  will be the last vertex in
the topological order. We go through the vertices in reverse topological order
and determine at each step the weights  of the
edges entering the current vertex. At the first step we look
at every edge  incident to  and determine its weight
 which is equal to . The weights of
the other edges can then be determined in linear time
by using the following recursive
formula which follows from the definition of the weights
 in (\ref{eq:widetilde_w}),


\noindent
where for ,  (resp. ) denotes the set of all
edges going out of  (resp. all edges entering ).

\subsection{Determining \texorpdfstring{{\mathversion{bold}}}{}}

Another subproblem in Algorithm~\ref{alg:montecarlo_psi} is the
calculation of , the weight of the sample
space. Having already calculated the weight function
, this problem can easily be solved by
expressing  in terms of 
as follows.




\subsection{Sampling edges outside the initial path and calculating
\texorpdfstring{{\mathversion{bold}}}{}}\label{subsec:sampling_remaining_edges}

As the sampling of the remaining edges in
lines~\ref{algline:sampling_remaining_edges} to
\ref{algline:end_sampling} of Algorithm~\ref{alg:montecarlo_psi}
is used only for the calculation of , we do not
have to know all intact edges but only those on a
path from  to . One way of improving the procedure is to
sample only edges that can be reached from . This can be done
by keeping track of the set of nodes  that
are currently reachable from
. At the beginning, these are the nodes on the initial path
. Then all edges going out of  will be
sampled, and for every appeared edge we add its endpoint to
. This procedure is repeated until there are
no edges outgoing from  that have not already been sampled.

Finally, the determination of  in
line~\ref{algline:multiplicity} of Algorithm~\ref{alg:montecarlo_psi}
can be easily done by an
analogue technique to the one used to calculate 
where this time we work on the subgraph of  over the edges in
 where we give a weight of one to every edge.

\section{Number of samples to draw}\label{sec:nb_samples}

In this section we analyze how many samples have to be drawn
in our algorithm to obtain an  approximation.

\subsection{A priori bounds}

Using Theorem~\ref{thm:generalized_01_thm} we can derive the following bound.

\begin{theorem}\label{thm:montecarlo_importance_approx}
If the number of samples  satisfies

then  and  are both
 approximations of .
\end{theorem}

In Subsection~\ref{subsec:ratio_bounds}, we discuss upper bounds
for the ratio  which allow to apply
Theorem~\ref{thm:montecarlo_importance_approx} in practice and
to formulate conditions a network has to satisfy under which
Algorithm~\ref{alg:montecarlo_psi} is an FPRAS for
estimating .

\subsection{Stopping criteria}

In practice, the use of a stopping
criterion typically allows to reduce the number of samples to
take as
we can profit from information gained during the execution
of the algorithm. Furthermore, we do not suffer from a possibly
weak upper bound for .
In \cite{dagum_2000_optimal}, Dagum et al. present two stopping criteria,
applicable to our algorithm and ensuring that
the result of the algorithm is an  approximation
of . In the computational results, the second
algorithm (named \textit{Approximation Algorithm }) is
used.

\subsection{Bounding the ratio \texorpdfstring{{\mathversion{bold}}}{}}\label{subsec:ratio_bounds}

In this subsection, we discuss upper bounds on the ratio
. Together with Theorem~\ref{thm:montecarlo_importance_approx},
these bounds allow us to bound the
number of iterations needed for our algorithm to deliver an
 approximation.
The bounds discussed in this
section are correct not only for the case of directed acyclic
reliability networks but also for the more general case
of arbitrary directed, undirected or
even mixed reliability networks.

\paragraph{Previous results}

Karp an Luby \cite{karp_1985_montecarlo} gave the following upper bound on
the ratio  (in a slightly different context).

\begin{theorem}\label{thm:karp_bound_multiplicities}

\end{theorem}

When combining the above theorem with
Theorem~\ref{thm:montecarlo_importance_approx} we obtain that
Algorithm~\ref{alg:montecarlo_psi} is an FPRAS if
 is bounded by a polynomial in the input size
of the reliability network .
In the special case of uniform edge failure probabilities,
i.e., ,
Theorem~\ref{thm:karp_bound_multiplicities} reduces to

and implies that if

then Algorithm~\ref{alg:montecarlo_psi} is an FPRAS for
estimating .

\paragraph{Improved bound in the case
  of uniform edge failure probability}\label{sec:bound}

We now give a new bound on
 for the case of uniform edge failure probabilities,
which is sharper than (\ref{eq:karp_bound_multiplicities_uniform}),
especially in the case when the reliability network  is
not too dense and does not contain long paths from 
to .

To quantify the sparsity
of a graph we introduce the notion of \textit{\mbox{edge-vertex} bound}.
We say that a graph 
has an \mbox{edge-vertex} bound of  if for any subset of the
vertices  we have that there are at most  edges in the subgraph of  induced by the vertices
. The best \mbox{edge-vertex} bound of a graph can be determined
in polynomial time by reduction to a flow problem \cite{gallo_1989_fast}. Furthermore,
, where  is the maximum degree of the
vertices in , can be used as a simple valid \mbox{edge-vertex} bound.
Our new bound is given by the following theorem (see Appendix for a proof).

\begin{theorem}\label{thm:improved_bound}
Let  be a reliability network with
uniform edge failure probability ,
\mbox{edge-vertex} bound  and let  respectively  be the minimal and maximal length
of any - path in . Then we
have

\end{theorem}

The first term of the minimum in our bound is a
slight improvement over the bound given by
(\ref{eq:karp_bound_multiplicities_uniform}). This can be
seen by observing that . Contrary to bound
(\ref{eq:karp_bound_multiplicities_uniform}), the first term
of our bound may
be sharp. Furthermore it is independent of the graph topology and can easily
be generalized to \mbox{non-uniform} failure probabilities.

The second term of the minimum in
Theorem~\ref{thm:improved_bound} tries to exploit some
structure of the underlying network and is particularly interesting
for graphs with a low \mbox{edge-vertex} bound  and without
long paths. For example, when working with networks where  is bounded
by a constant and ,
Theorem~\ref{thm:improved_bound} implies that
Algorithm~\ref{alg:montecarlo_psi} is an FPRAS when
,
which is a much weaker condition than the bound given by (\ref{eq:karp_bound_q}).

\section{Computational results}\label{sec:computational_results}

In order to test our algorithm we used two random generators for
creating directed acyclic graphs with low reliability. These generators are introduced in
the first part of this section. In a second part, we analyze the
running time of our algorithm on networks created by these
generators with different sizes and reliabilities.
Furthermore, the proposed algorithm is compared to a
direct \mbox{Monte-Carlo} simulation.

\subsection{Test instances}


\paragraph{Delaunay graphs (DEL)}

Our generator for directed acyclic Delaunay graphs takes two parameters, the number of
vertices  and a uniform edge intactness probability .
We begin by choosing  points uniformly at random in the unit square and consider the
undirected graph given by a Delaunay triangulation of these points. The two
terminals  and  are chosen as two vertices with maximal Euclidian
distance. We give a linear orientation to the edges corresponding to
the vector from  to , i.e., an (undirected) edge  is oriented
as  if the vector from  to  and the one from  to  have
a \mbox{non-negative} scalar product, otherwise we take the orientation .
Finally, all edges get uniform intactness probability equal to .
One can easily observe that this construction guarantees that every vertex lies
on a path from  to .



\paragraph{Topological construction (TC)}

A second generator we use has three parameters, the number of vertices
, a density parameter  allowing to control the
expected number of edges in the graph and a parameter  influencing
the intactness probabilities. We begin with an empty
graph over  vertices  where  and .
The graph will be constructed such that  is a topological
order of the vertices. In a first step, all edges of the graph are introduced,
then intactness probabilities are assigned to the edges.

For  we introduce an edge from  to . This
ensures that all vertices are on a path from  to .
All other possible edges will be present
with probability , i.e., for every  with 
we add an edge  with probability .

Finally, the intactness probability of an edge  is a number chosen
uniformly at random in the interval . By choosing
, edges connecting topological near vertices have in general higher
intactness probabilities than edges connecting vertices being far away from each
other in the topological order. Therefore, smaller values for 
result in less reliable networks. The value of  will typically be
chosen in .

\paragraph{Parameter choice}

The parameters were fixed in such a way that networks of different reliabilities
were obtained for graphs with ,, and  vertices.
We generated DEL instances
for every
 for every graph size .
For the creation of TC instances
the parameter  was always chosen such that the expected degree of
every vertex is equal to ten. This ensures that all graphs generated with the TC
generator having the same number of vertices also have about the same number of edges
and simplifies the comparison of running times. For every graph size 
instances were generated for .

The computational results presented in this section have been obtained on workstations
equipped with an AMD processor 3200+ and 1GB of RAM.

\subsection{Results and interpretations}

As a first observation, we noticed that the dependence of the running time
on  and  is essentially proportional to
 as predicted. We therefore
fixed ,  for all results presented in this section.

Figure~\ref{fig:relrun} shows the running time
of the proposed algorithm as a function of the estimated reliability. As
expected, the running time grows when larger reliabilities have to be estimated,
as an intact state contains often several paths from  to . TC instances
with about the same reliability as DEL instances are much easier to tackle.
This comes from the fact that DEL instances are rather locally connected,
whereas most edges in TC instances were randomly chosen. Local connectedness
has the effect that when having an intact path  from  to , there is
a good chance that several small subpaths of  can be replaced by other intact
subpaths with the same start and endpoint. Every subpath which can be replaced
in this way raises the number of intact paths from  to . Furthermore, as
the replaceable subpaths are small it is likely that large groups of them are
disjoint, implying that various combinations of these subpath replacements
yield new intact paths from  to .
Figure~\ref{fig:relrun} shows that
even instances with  vertices could be solved in reasonable time
as long as the estimated reliability was not too large.

\begin{figure}[h!]
\begin{center}
\resizebox{\linewidth}{!}{\includegraphics{del_relrun.pdf}\hspace*{5mm}\includegraphics{tc_relrun.pdf}}
\caption{\label{fig:relrun} Running times of the proposed algorithm in
  function of the estimated reliabilities for DEL instances (on
  the left) and TC instances (on the right).}
\end{center}
\end{figure}

For the comparison of the proposed \mbox{Monte-Carlo} algorithm with
a direct \mbox{Monte-Carlo} approach, instances with  vertices
were used as most of these instances could have been solved in
reasonable time by both algorithms. As well as the proposed
\mbox{Monte-Carlo} algorithm, the direct \mbox{Monte-Carlo}
algorithm was implemented by using the sampling technique explained
in \ref{subsec:sampling_remaining_edges} allowing to reduce the
time needed per iteration in most instances.
Figure~\ref{fig:1000_compare} shows
the running times of both algorithms on DEL and TC instances with 
vertices. As expected, the direct \mbox{Monte-Carlo} approach has an
approximately linear dependence on the reciprocal of the
estimated reliability.
Figure~\ref{fig:1000_compare} shows
the strength of the proposed algorithm when low reliabilities
have to be estimated.

\begin{figure}[h!]
\begin{center}
\resizebox{\linewidth}{!}{\includegraphics{del_1000_compare.pdf}\hspace*{5mm}\includegraphics{tc_1000_compare.pdf}}
\caption{\label{fig:1000_compare} Running times of the proposed
algorithm (prop. algo.) and the direct \mbox{Monte-Carlo} (MC) approach
for DEL instances (on the left) and TC instances (on the right) with 
 vertices.}
\end{center}
\end{figure}

As the running time of the direct \mbox{Monte-Carlo} approach
depends nearly linear in  (see
Figure~\ref{fig:1000_compare}) and
we expect that the proposed algorithm has a running time approximately
proportional to  (i.e. the reciprocal of the value
to estimate), we
expect the ratio between the running time of the proposed algorithm
and the direct \mbox{Monte-Carlo} approach is approximately linear
in . This is confirmed by Figure~\ref{fig:1000_wOmegarunratio}
showing the ratio of the running time of both algorithms in function
of  for DEL and TC instances with  vertices.
It is not surprising that both algorithms need about the same running time
when  is near to one. This observation allows to perform a
simple a priori test for deciding which algorithm is better suited
for a particular instance. Given an instance, we first calculate
 (in linear time). If  it is likely that
the proposed algorithm will be faster than the direct \mbox{Monte-Carlo}
approach. When , the direct \mbox{Monte-Carlo} approach
is likely to be the more efficient algorithm.

\begin{figure}[ht!]
\begin{center}
\includegraphics[width=0.6\linewidth]{1000_wOmegarunratio.pdf}
\caption{\label{fig:1000_wOmegarunratio} Comparison of the running time of the proposed
algorithm and the direct \mbox{Monte-Carlo} approach in function of 
for networks with  vertices.}
\end{center}
\end{figure}

\section{Conclusions}

An adapted version of the Monte-Carlo algorithm given by Karp and Luby
in \cite{karp_1985_montecarlo} was presented and analyzed.
The new algorithm is specialized for directed acyclic graphs and is suited for the estimation
of small reliabilities. Computational results show the successful
application of the proposed algorithm on two types of randomly
generated large-scale instances 
and its advantage compared to the direct \mbox{Monte-Carlo} approach
when very small reliabilities have to be estimated.
Previous algorithms for accurate estimation of - reliability
were only applicable on either very small instances or on
a very restricted class of initial networks.
For the case of uniform
edge failure probabilities, a \mbox{worst-case} bound
on the number of samples to be drawn was given that sharpens a bound presented in
\cite{karp_1985_montecarlo} and is significantly stronger in the case of
relatively sparse graphs without long paths from  to .


One important open question in this domain is if there exists an FPRAS
for estimating - reliability in directed acyclic graphs. It would be interesting to
find algorithms allowing to tackle instances
efficiently that cannot be solved in reasonable time by our algorithm or the
direct \mbox{Monte-Carlo} approach.
Another point is the generalization of the upper bound for 
for the case of \mbox{non-uniform} failure probabilities.
Additionally for the case of general (not necessarily acyclic) networks
there seem to be no practically efficient algorithms at the moment for the
estimation of low reliabilities on large instances.



\bibliographystyle{plain}
\bibliography{networks}


\section*{Appendix}

\subsubsection*{Proof of Theorem~\ref{thm:improved_bound}}

Let  be a
sample drawn
according to lines
\mbox{\ref{algline:path_sampling}-\ref{algline:end_sampling}}
of \mbox{Algorithm~\ref{alg:montecarlo_psi}}. We define the
influence value  of the sample as in
Section~\ref{sec:our_algorithm} as a random variable


As discussed in Section~\ref{sec:our_algorithm}, the influence
value of a sample from  can be used as an unbiased estimator for
 as we have


By the above equation, the reciprocal of a lower bound on 
is an upper bound on . We will therefore
deduce the bound given in Theorem~\ref{thm:improved_bound} by
deriving a lower bound bound on .

Let  be the subset of all elements of the sample
space  where the initial chosen path has length 
and the total number of appeared edges is , i.e.,



It is clear that all elements  appear with equal probability
and can be
sampled by the method described in Algorithm~\ref{alg:uniform_Omegalk}. This method is introduced just
for theoretical analysis.

\linesnumbered
\begin{algorithm}[H]
\SetLine
\caption{Sampling uniformly from \label{alg:uniform_Omegalk}}
Choose uniformly a path  with length \;
\;
\;
\For{ to }{Choose an edge  uniformly
  at random\;
\;
\;}
\Return{}
\end{algorithm}

With every edge  added in the \mbox{for-loop} of
Algorithm~\ref{alg:uniform_Omegalk} we associate a multiplicity
 equal to  if both endpoints of 
are saturated by edges in 
and equal to  otherwise. Intuitively, the multiplicity
is a measure for the influence of an added
edge in Algorithm~\ref{alg:uniform_Omegalk} on the ratio
. The following lemma formalizes this
intuition.

\begin{lemma}\label{lem:multiplicity}
Let  be an intact state constructed as described in
Algorithm~\ref{alg:uniform_Omegalk}. Then we have

\end{lemma}

Before proving this lemma, we discuss the link between the lemma
and Algorithm~\ref{alg:uniform_Omegalk}. In general there
are multiple ways to get an intact state  with
Algorithm~\ref{alg:uniform_Omegalk}. Depending on how the
state  was obtained, the multiplicities associated with
the edges in  are different. As
Lemma~\ref{lem:multiplicity} is true for every possible way
of obtaining state  by Algorithm~\ref{alg:uniform_Omegalk}, it
is applicable even to intact states that were not
constructed through Algorithm~\ref{alg:uniform_Omegalk}. One
just has to fix a possible way how the state  could have
been constructed by Algorithm~\ref{alg:uniform_Omegalk},
i.e., an - path  has to be fixed as well
as an order for the edges in  specifying in
which sequence those edges were chosen in
Algorithm~\ref{alg:uniform_Omegalk}.
The multiplicities can then be calculated with respect to this order, and
Lemma~\ref{lem:multiplicity} can be applied.

\begin{proof}[Proof of Lemma~\ref{lem:multiplicity}]
Let  be an intact state
constructed as described in
Algorithm~\ref{alg:uniform_Omegalk}. We define
 to be the set of
all edges added to the initial path  during the
construction of . Let  be
the following partitioning of the edges in .

We prove the following statement, which immediately
implies Lemma~\ref{lem:multiplicity}.

\begin{proposition*}
For every set  there exists at
most one - path in the state  that contains all
edges of  and none of .
\end{proposition*}

Lemma~\ref{lem:multiplicity} follows from the above
proposition by the following observation. The proposition
implies that there are at most as many different -
paths in  as there are subsets of . We
therefore have

which finally implies


It remains to prove the proposition. Let  and suppose that we have two different
- paths  such that both
contain all edges of  and none of
. This implies that their
symmetric difference 
contains a cycle consisting only of edges in , thus
contradicting the fact that  does not contain cycles
(any cycle in  contains at least one element of ).\\
\end{proof}

With the aid of Lemma~\ref{lem:multiplicity} we prove
the following intermediate result.

\begin{lemma}\label{lem:bound_Omegalk}
Let 
with  and  be
a random sample from the sample space
according to Algorithm~\ref{alg:montecarlo_psi}. We have

\end{lemma}

\begin{proof}[Proof of Lemma~\ref{lem:bound_Omegalk}]
Let  be a sample corresponding
to a result of Algorithm~\ref{alg:uniform_Omegalk} for the
given  and .
Conditioned on ,  has therefore the same
distribution as .
Let  be the random variables
corresponding to the multiplicities of the edges in
. By Lemma~\ref{lem:multiplicity} we
have


Let . Observe that independently of which
path  and which edges  were
chosen, we have that at most  vertices in
 are saturated by the edges in  ( vertices are saturated
through  and every additional edge saturates at most two
new vertices in ). Let  be the vertices in  which
are saturated by .

In Algorithm~\ref{alg:uniform_Omegalk}, the edge  is chosen
uniformly at random from the remaining edges . As  is sparse
with \mbox{edge-vertex} bound  we have that at most  edges have both
endpoints in . Furthermore,  of these edges were already
chosen. We therefore have the following stochastic
inequality (which is true for any realization of
):


The stochastic inequality above allows to give a simple
bound on the following conditional expectation:


Applying the above inequality, the expectation in
(\ref{eq:ex_multiplicities}) can be developed as

The last inequality comes from the fact that  for  and  for .
Developing further, we finally get the result of
Lemma~\ref{lem:bound_Omegalk}.

\end{proof}

Beginning with the result of Lemma~\ref{lem:bound_Omegalk}
we now prove Theorem~\ref{thm:improved_bound} by first weakening and
then eliminating the conditioning on .
Let  be the set of all elements of the sample
space  where the initial chosen path has length
, i.e.,


Let  be the random variable corresponding to the number
of edges that appeared additionally to the ones of the
initial path, when drawing an element out of .
Note that  is binomially distributed as


Using Lemma~\ref{lem:bound_Omegalk} we get


By replacing  by  in the first term of the
above maximum we get the first part of the inequality in Theorem~\ref{thm:improved_bound}, i.e.,


The remaining part of Theorem~\ref{thm:improved_bound} will be shown
by developing the second term of (\ref{eq:bound_Omegal}) further.
We will use the inequality

which is true for any  and a result shown by
Hamza \cite{hamza_1995_smallest} stating that the distance between
the median and the mean of a binomial random variable is at most
.
Therefore, when choosing
, we have
 and get the following result:

This implies the second part of the inequality in
Theorem~\ref{thm:improved_bound} as

which completes the proof of Theorem~\ref{thm:improved_bound}.


\end{document}
