\documentclass[3p,twocolumn]{elsarticle}
\usepackage{amsmath, amssymb, amsfonts, amsthm}
\usepackage{graphicx}
\usepackage{gastex}
\usepackage{wrapfig}
\theoremstyle{plain}
\usepackage{hyperref}
\usepackage{lineno}

\newtheorem*{theorem}{Theorem}
\newtheorem{lemma}{Lemma}
\newtheorem*{conjecture}{Conjecture}
\theoremstyle{definition}
\newtheorem*{example}{Example}
\newcommand{\LCE}{\mathit{LCE}}
\newcommand{\lcp}{{\sf lcp}}
\newcommand{\sa}{{\sf sa}}
\newcommand{\nodes}{{\sf nds}}
\newcommand{\nil}{\mathbf{nil}}



\journal{Information Processing Letters}
\bibliographystyle{elsart-num-sort}
\begin{document}

\begin{frontmatter}

\title{Computing Runs on a General Alphabet}

\author{Dmitry Kosolobov} \address{Ural Federal University, Ekaterinburg, Russia}

\begin{abstract}
We describe a RAM algorithm computing all runs (maximal repetitions) of a given string of length  over a general ordered alphabet in  time and linear space. Our algorithm outperforms all known solutions working in  time provided , where  is the alphabet size. We conjecture that there exists a linear time RAM algorithm finding all runs.
\end{abstract}


\begin{keyword}
runs \sep general alphabet \sep maximal repetitions \sep linear time \sep  repetitions
\end{keyword}

\end{frontmatter}


\section{Introduction}

Repetitions in strings are fundamental objects in both stringology and combinatorics on words. In some sense the notion of \emph{run}, introduced by Main~\cite{Main}, allows to grasp the whole repetitive structure of a given string in a relatively simple form. Informally, a run of a string is a maximal periodic substring that is at least as long as twice its minimal period (the precise definition follows). In~\cite{KolpakovKucherov} Kolpakov and Kucherov showed that any string of length  contains  runs and proposed an algorithm computing all runs in linear time on an integer alphabet  and  time on a general ordered alphabet, where  is the number of distinct letters in the input string. Recently, Bannai et al. described another interesting algorithm computing all runs in  time~\cite{BannaiIInenagaNakashimaTakedaTsuruta}. Modifying the approach of \cite{BannaiIInenagaNakashimaTakedaTsuruta}, we prove the following theorem.
\begin{theorem}
For a general ordered alphabet, there is an algorithm that computes all runs in a string of length  in  time and linear space.
\end{theorem}
This is in contrast to the result of Main and Lorentz \cite{MainLorentz} who proved that any algorithm deciding whether a string over a general \emph{unordered} alphabet has at least one run requires  comparisons in the worst case.

Our algorithm outperforms all known solutions when the number of distinct letters in the input string is sufficiently large (e.g., ). It should be noted that the algorithm of Kolpakov and Kucherov can hardly be improved in a similar way since it strongly relies on a structure (namely, the Lempel--Ziv decomposition) that cannot be computed in  time on a general ordered alphabet (see \cite{Kosolobov}).

Based on some theoretical observations of \cite{Kosolobov}, we conjecture that one can further improve our result.
\begin{conjecture}
For a general ordered alphabet, there is a linear time algorithm computing all runs.
\end{conjecture}


\section{Preliminaries}

A \emph{string of length } over an alphabet  is a map , where  is referred to as the length of , denoted by . We write  for the th letter of  and  for . A string  is a \emph{substring} (or a \emph{factor}) of  if  for some  and . The pair  is not necessarily unique; we say that  specifies an \emph{occurrence} of  in . A string can have many occurrences in another string. A substring  (respectively, ) is a \emph{prefix} (respectively, \emph{suffix}) of . An integer  is a \emph{period} of  if  and  for all ;  is the \emph{minimal period} of  if  is the minimal positive integer that is a period of . For integers  and , the set  (possibly empty) is denoted by . Denote  and .

A \emph{run} of a string  is a substring  whose period is at most half of the length of  and such that both substrings  and , if defined, have strictly greater minimal periods than .

We say that an alphabet is \emph{general} and \emph{ordered} if it is totally ordered and the only allowed operation is comparing two letters. Hereafter,  denotes the input string of length  over a general ordered alphabet.

In the \emph{longest common extension ()} problem one has to preprocess  for queries  returning for given positions  and  of  the length of the longest common prefix of the suffixes  and . It is well known that one can perform the  queries in constant time after preprocessing  in  time, where  is the number of distinct letters in  (e.g., see \cite{HarelTarjan}). It turns out that the time consumed by the  queries is dominating in the algorithm of \cite{BannaiIInenagaNakashimaTakedaTsuruta}; namely, one can prove the following lemma.
\begin{lemma}[{see \cite[Alg. 1 and Sect. 4.2]{BannaiIInenagaNakashimaTakedaTsuruta}}]
Suppose we can answer in an online fashion any sequence of   queries on  in  time for some function ; then we can find all runs of  in  time.\label{LCEtoRuns}
\end{lemma}

In what follows we describe an algorithm that computes   queries in  time and thus prove Theorem using Lemma~\ref{LCEtoRuns}. The key notion in our construction is a \emph{difference cover}. Let . A set  is called a difference cover of  if for any , there exist  such that . Clearly . Conversely, for any , there is a difference cover of  with  elements: for example, the difference cover , which is depicted in Fig.~\ref{fig:simpleDC}. For further discussions and estimations of minimal difference covers, see \cite{ColbournLing,MereghettiPalano,Singer}.
\begin{figure}[htb]
\centering
{\large
\begin{picture}(100,6)
\gasset{Nframe=n,Nw=5,Nh=3,AHnb=0,linewidth=0.25}
\put(39.5,2){\makebox(0,0)[cb]{}}
\put(40,   -5){\makebox(0,0)[cb]{}}
\end{picture}
}
\caption{Simple difference cover of  with .}\label{fig:simpleDC}
\end{figure}
\begin{example}
The set  is a difference cover of~.


\end{example}

Our algorithm utilizes the following interesting property of difference covers.
\begin{lemma}[see \cite{BurkhardtKarkkainen}]
Let  be a difference cover of . For any integers , there exists  such that  and .\label{DiffCoverProperty}
\end{lemma}


\section{Longest Common Extensions}

At the beginning, our algorithm fixes an integer  (the precise value of  is given below). Let  be a difference cover of  of size . Denote . Obviously, we have . Our algorithm builds in  time a data structure that can calculate  in constant time for any . To compute  for arbitrary , we simply compare  and  from left to right until we reach positions  and  such that  and , and then we obtain  in constant time. By Lemma~\ref{DiffCoverProperty}, we have  and therefore, the value  can be computed in  time. Thus, our algorithm can execute any sequence of   queries in  time. Putting , we obtain . Now it suffices to describe the data structure answering the  queries on the positions from .

Let  be the sequence of all positions from  in the increasing lexicographical order of the corresponding suffixes . Our algorithm builds a \emph{longest common prefix array}  such that  for  and a \emph{sparse suffix array}  such that  for  and  for . Obviously  for . Based on this observation, we equip the  array with the \emph{range minimum query (RMQ)} structure~\cite{FischerHeun} that allows to compute  for any  in  time. Now, to answer  for , we first obtain  and  and then answer  using the RMQ structure on the  array. Since the RMQ structure can be built in  time~\cite{FischerHeun}, it remains to describe how to construct  and .

In general our construction is similar to that of~\cite{KosolobovLempelZiv}. We use the fact that the set  has ``period'' , i.e., for any , we have  provided . For simplicity, assume that  is a special letter that is smaller than any other letter in . Our algorithm iteratively inserts the suffixes  in the arrays  and  from right to left. Suppose, for some , we have already inserted in  and  the suffixes  for all . More precisely, denote by  the sequence of all positions  in the increasing lexicographical order of the corresponding suffixes ; we suppose that  for ,  for , and  for . We are to insert the suffix  in  and . In order to perform the insertions efficiently, during the construction, the arrays  and  are represented by balanced search trees with some auxiliary structures as described below.

\paragraph{1. Balanced search tree for } The  array is represented by an augmented balanced search tree so that any RMQ query and modification on  take  amortized time.

\paragraph{2. List } We store all positions  on a linked list  in the lexicographical order of the corresponding suffixes. We maintain on this list the order maintenance data structure of~\cite{BenderColeDemaineFarachColtonZito} that allows to determine whether a given node of  precedes another node of  in constant time. The insertion of a new node in  takes amortized constant time. To provide constant time access to the nodes of , we maintain an array  such that  is the node of  corresponding to position  if , and  otherwise.

\paragraph{3. Balanced search tree for } It is straightforward that, for any ,  is equal to one plus the number of nodes of  preceding . So, we store all nodes of  in an augmented balanced search tree allowing to calculate the number of nodes preceding  in  time (since the comparison of two nodes takes  time). This tree together with the list  and the array  allows to compute  in  time.

\paragraph{4. Trie } We maintain a compacted trie  that contains the strings  for all  (we assume  for all  and thus  is always well defined). We maintain on  the data structure of~\cite{FranceschiniGrossi} supporting insertions in  amortized time. Let  be the leaf of  corresponding to a string . We augment  with a balanced search tree  that contains nodes  for all positions  such that  (see Figure~\ref{fig:treeS}). We use  to compute in  time the immediate predecessor and successor of any given node , where , in the set of nodes stored in . It is easy to see that  together with the associated search trees occupies  space in total.

\begin{example}
Let . The set  is a difference cover of . Consider the string }M = \{i \in [1..n] \colon (i\bmod \tau^2) \in D\}SSM\cap (k..n]Sabcababcab4, 9, 1wB_44{+}\tau^2 = 8, 9{+}\tau^2 = 13, 1{+}\tau^2 = 5w[8..n], w[13..n], w[5..n]B_1, B_2, \ldots, B_9M\lcp\saw[k..n]\lcp\saw[k..k{+}\tau^2]SO(\tau^2 + \log n)Sw[k..k{+}\tau^2]SO(1)\lcpw[k..n]\LCEw[k..n]S\lcpw[k..n]L\saB_aaSO(\log n)Sw[k..k{+}\tau^2]aSw[k..k{+}\tau^2]O(\log n)\nodes[k{+}\tau^2]k{+}\tau^2 \in MB_a\nodes[x]\nodes[y]\nodes[x]B_aL\nodes[y]\nodes[k{+}\tau^2]\nodes[x]\nodes[y]B_aw[x{-}\tau^2..x] = w[y{-}\tau^2..y] = w[k..k{+}\tau^2]w[x{-}\tau^2..n]w[y{-}\tau^2..n]w[k..n]\{w[x..n] \colon x\in M\cap (k..n]\}\nodes[k]L\nodes[x{-}\tau^2]\nodes[y{-}\tau^2]\LCE(k, x{-}\tau^2) = \tau^2 + \LCE(k{+}\tau^2, x)\LCE(k, y{-}\tau^2) = \tau^2 + \LCE(k{+}\tau^2, y)\LCE(k{+}\tau^2, x) = \LCE(i'_{\sa[k{+}\tau^2]}, i'_{\sa[x]})\LCE(k{+}\tau^2, y) = \LCE(i'_{\sa[k{+}\tau^2]}, i'_{\sa[y]})O(\log n)\sa\lcpO(\log n)\lcp\saO(n)\lcp\saO(\tau^2 + \log n)\lcp\saO(\frac{n}{\tau}(\tau^2 + \log n))O(n)k\LCEnO(k + n)$ time. However, we do not yet have a theoretical evidence for such strong results.

Another interesting direction is a generalization of our result for the case of online algorithms (e.g., see~\cite{HongChen} and~\cite{Kosolobov2}).

\subparagraph*{Acknowledgements}
The author would like to thank Gregory Kucherov for inviting in Universit{\'e} Paris-Est, where the present result was obtained, and the anonymous referee who simplified the proof and highly improved the quality of the paper.

\section*{References}

\bibliography{faster_runs}

\end{document}
