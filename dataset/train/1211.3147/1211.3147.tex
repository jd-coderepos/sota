
\documentclass[10pt, conference, compsocconf]{IEEEtran}

\ifCLASSINFOpdf
\else
\usepackage[dvips]{graphicx}
\DeclareGraphicsExtensions{.eps}
\fi

\usepackage{times,amsmath,amsfonts,epsfig}
\usepackage{graphics}
\usepackage{graphicx,epstopdf}
\usepackage{wrapfig}
\usepackage{subfigure}
\usepackage{multirow}
\newtheorem{thm}{Theorem}\newtheorem{dfn}{Definition}
\newtheorem{prop}[thm]{Proposition}
\usepackage{algorithm}
\usepackage{algorithmic}
\usepackage{framed}
\usepackage{array}
\usepackage{hyphenat}
\hyphenation{en-crypt-ed}


\begin{document}

\title{Secure Computation of Top-K Eigenvectors for Shared Matrices in the Cloud}

\author{\IEEEauthorblockN{James Powers, Keke Chen}
\IEEEauthorblockA{Data Intensive Analysis and Computing Lab (DIAC)\\
Ohio Center of Excellence in Knowledge Enabled Computing (Kno.e.sis)\\
Department of Computer Science and Engineering, Wright State University\\
\{powers.4,keke.chen\}@wright.edu}
}

\maketitle


\begin{abstract}
With the development of sensor network, mobile computing, and web applications, data are now collected from many distributed sources to form big datasets. Such datasets can be hosted in the cloud to achieve economical processing. However, these data might be highly sensitive requiring secure storage and processing. We envision a cloud-based data storage and processing framework that enables users to economically and securely share and handle big datasets. Under this framework, we study the matrix-based data mining algorithms with a focus on the secure top-k eigenvector algorithm. Our approach uses an iterative processing model in which the authorized user interacts with the cloud to achieve the result. In this process, both the source matrix and the intermediate results keep confidential and the client-side incurs low costs. The security of this approach is guaranteed by using Paillier Encryption and a random perturbation technique. We carefully analyze its security under a cloud-specific threat model. Our experimental results show that the proposed method is scalable to big matrices while requiring low client-side costs.
\end{abstract}

\begin{IEEEkeywords}
cloud computing; big matrix; power iteration; MapReduce; security; performance;
\end{IEEEkeywords}

\IEEEpeerreviewmaketitle

\section{Introduction}
With the development and wide deployment of web services, mobile applications, and sensor networks, data are now collected from many distributed sources to form big datasets. For example, users of mobile devices are becoming ``citizen sensors'' \cite{goodchild07} to generate information about the world via tools like Twitter and location-based services. Such datasets have become a valuable asset to the data owner. 
This paradigm raises a number of challenges for data storage, sharing, and analysis.
\begin{itemize}
\item Most data collectors, such as mobile devices and sensors, have very limited resources to store and process data. Thus, the data have to be sent to servers or clouds. 
\item The collected data may be highly sensitive. So it becomes necessary to transfer, store, and process them securely. 
\item Users might be authorized by the data owner to use the data. Processing and analyzing the secured big data will require a huge amount of computing resources to be allocated on demand, where cloud computing is the ideal platform.
\end{itemize}

With these problems in mind, we envision a cloud-based data storage and processing framework that enables users to economically and securely share and handle big matrices collected from distributed sources. The data owners and data consumers do not need to own powerful computational infrastructures - they need only a PC to interact with the cloud infrastructure to economically finish the data intensive computing. 

The key problem of this framework is the security of data. The data owner loses the control of the data once the data are exported to the cloud. For many reasons, such as a compromised cloud infrastructure or insider attacks conducted by the provider's employees, the cloud provider may not be considered a trusted party. Storing data securely is trivial, but processing data securely in the cloud is very challenging because the underlying infrastructure is owned by the untrusted cloud provider. Our framework aims to enable the trusted parties to securely conduct computation on encrypted data on top of untrusted cloud infrastructures. 

The most relevant approach is fully homomorphic encryption \cite{gentry09,naehrig11}, which, however, is too expensive to be practical. As users expect to use the cloud to minimize the client-side costs, in general, approaches, which demand high costs on communication and the client side, cannot be moved to the cloud setting (Section \ref{sec:related} for more details).   

\textbf{Scope and Contributions.} Securely sharing, analyzing, and mining datasets in the cloud is a rather broad issue. In this paper, we study a specific problem with the proposed framework: matrix-based data mining, and more specifically, we focus on the secure and efficient iterative methods for finding the approximate top-k eigenvectors of a secured large matrix in the cloud. 

Eigendecomposition \cite{saad11} has broad applications in many important areas including information retrieval \cite{deerwester90} and PageRank \cite{brin98} for ranking web search results. The common algorithm to find all eigenvectors will cost  in time complexity, which is prohibitively expensive for large dimensionality . When the matrix is large, the iterative methods (i.e., power-iteration based methods \cite{arnoldi51,cullum85}) are used to find the approximate top-k eigenvectors instead. The most expensive step of the iterative methods is the matrix-vector multiplication.    



In the proposed framework, we use the \emph{partially homomorphic} Paillier encryption system \cite{paillier99} to encrypt the values which enables the processing of encrypted data in the cloud. The data owner manages the keys and owns the data in the cloud. At the data owner's request, the data collectors encrypt vectors (e.g., describing the interactions in social network or preferences over books) and submit them to the cloud to form the big matrix. The data owner or the authorized data consumer, who has only limited computing resources, then interacts with the cloud to conduct an iterative computation to find the approximate top-k eigenvectors. 

The core component of this framework is the secure matrix-vector multiplication between the encrypted matrix stored in the cloud and the vector provided by the client. Paillier encryption is used to enable computations over encrypted data in the cloud, which is much more efficient than the existing fully homomorphic encryption methods \cite{gentry09}. However, it can only provide homomorphic addition, handicapped for homomorphic matrix computation. We develop an efficient perturbation-based protocol to overcome this problem and ensure no information is leaked in the computation. It also guarantees low costs  in the trusted client side (the data owner, data collectors, and the authorized data consumers) to fully take advantage of cloud computing. We also develop a MapReduce program to process the secure matrix-vector multiplication to fully exploit the parallelism and scalability enabled by the cloud platform. 




An extensive evaluation has been conducted on the proposed method. The result shows that the cloud-side parallel processing on encrypted data is efficient and scalable, and the client-side costs are quite acceptable. 

The remaining part of the paper is organized as follows. Section \ref{sec:pre} gives background knowledge about the proposed approach, including a brief description on the Paillier encryption system, the power iteration methods, and the MapReduce programming model. Section \ref{sec:approach} describes the design of the approach and also analyzes its correctness, security, and costs. Section \ref{sec:exp} presents the results of experimental evaluation with a focus on the storage and computing costs in both the cloud and client sides. Section \ref{sec:related} shows some related work on secure computation in the cloud.

\section{Preliminaries} \label{sec:pre}


In the following, we will briefly describe our notation and background knowledge about eigenvalue decomposition, Paillier encryption, and MapReduce programming. 

\textbf{Notation}
For clear presentation, we will use Greek characters to represent scalars, lower case letters for vectors, indexed lower case letters for the elements in the vector, and capital letters for matrices or submatrices. In particular,  represents the group of -dimensional vectors of integers with moduluo .
We use  to denote a set of vectors (or values). 



\textbf{Power Iteration for Eigenvalue Decomposition.} Finding eigenvalues and eigenvectors of a square matrix has many important applications in science and engineering domains. In particular, eigenvalue decomposition has been an important tool in data analysis. For example, Principal Component Analysis (PCA) depends on eigenvalue decomposition \cite{jolliffe86}. In information retrieval, it is used to find the relationship between words and documents on a text corpus \cite{deerwester90}. Google's patented PageRank technique\cite{brin98} is also related to eigenvalue decomposition. 

The matrices from these applications are normally very large. Thus, the direct computation method that costs  is not a viable option. Instead, for large matrices, power iteration based methods, such as the Arnoldi \cite{arnoldi51} and Lanczos methods \cite{cullum85}, are used for finding the top-k eigenvectors. 
Assume , , is a  real matrix and  is a random -dimensional vector. We sketch these methods in Algorithm \ref{alg:power-it}.
\begin{algorithm}[htb]
\caption{Framework of Power Iteration Methods}\label{alg:power-it}
\begin{algorithmic}[1]
\STATE  random -D vector;  
\FOR{i  1 to }
\STATE ;
\STATE other operations of cost  specific to the Arnoldi or Lanczos methods.  
\ENDFOR
\STATE Post-processing with a cost  to generate eigenvectors. 
\end{algorithmic}
\end{algorithm}

Note that in this iterative framework, the most expensive operation is the line . Other operations are only related to processing  and some auxiliary  matrix. Usually, only a few eigenvectors are needed and thus  is typically small (e.g., k=10). The remaining computations, specific to the Arnoldi and Lanczos methods cost only . With the matrix stored in the cloud, we can let the cloud take care of the most expensive part while the client handles the remaining low-cost steps. 


\textbf{Paillier Encryption.} 
Fully homomorphic encryption aims to allow addition and multiplication to be conducted on encrypted values without decryption. Paillier Encryption is a partially homomorphic encryption scheme that is much more efficient than the fully homomorphic ones \cite{gentry09}, but only preserves homomorphic addition, i.e. 

Multiplication cannot be implemented on top of  and  in Paillier encryption. However, with one operand not encrypted, say , multiplication can still be implemented as

where \emph{mod\_power} means the modulo power operation \cite{katz07}. For simplicity of presentation, we use  to represent \\. It has been proven that Paillier Encryption has strong security guarantee, satisfying the definition of semantic security.

Therefore, to implement more complicated operations with Paillier encryption, one has to expose one of the operands which becomes the security hole. Finding a way to limit the exposure and maintain data privacy will be one of the challenging tasks in the application. 





\section{Secure Top-k Eigenvector Computation in the Cloud}\label{sec:approach}
In this section, we will describe the major components in our approach. We begin with the general computational framework and describe the roles of the client and cloud components. Next, we present the security/threat model and discuss our assumptions and potential attack points. We follow with the secure power iteration algorithm that is built up with Paillier encryption and random perturbation. Then, we briefly discuss the cloud-side MapReduce algorithm. Finally, we formally analyze the security and cost of the proposed approach. We show that our approach can minimize the cost of the client-side computation while providing excellent performance for processing big matrices with strong security guarantee.

\subsection{Computational Framework}

Our framework involves four parties: cloud, data owner, data collectors, and authorized data users. It reflects the highly distributed nature in data intensive computing where collecting data, storing data, and processing data might be handled by different distributed parties. 

Figure \ref{fig:framework} illustrates the relationship and interaction between these parties. The non-cloud parties: the data owner, the data collectors/contributors, and the authorized users are trusted. The data owner controls all rights to the data, distributes public keys, and asks the data collectors/contributors to upload the collected data which are encrypted by a public key. The data owner can process the pooled data by him/herself or authorize other users to use the encrypted data. Each data collector may contribute a small part of the data, e.g., a row of the matrix. Practical examples may include the interactions with other users or the recommendations on items during a period. The data owner or the authorized users can interact with the cloud to conduct matrix analysis tasks. Note that encrypted data will have a size much larger than the original one. The authorized users cannot afford to download the encrypted big matrix and conduct computations locally. Instead, they want to fully utilize the benefits of cloud computing and minimize the client-side cost. 
\begin{figure}[tbh]
\centering
\begin{minipage}{\linewidth}
\centering
\includegraphics[width=\linewidth]{framework}
\caption{Framework for conducting matrix mining with the cloud.}\label{fig:framework}
\end{minipage}
\end{figure}

\subsection{Threat Model}

\textbf{Assumptions.} Our security analysis is built on the important features of the discussed architecture. Under this setting, we believe the following assumptions are appropriate. 
\begin{itemize}
\item The cloud provider is not trustable and may silently observe the data and the computation to find useful information, e.g., the eigenvectors.
\item Only the data owner and the authorized users can use the proprietary matrix. The data owner authorizes some trusted users to use the data. They will not intentionally breach the confidentiality. We consider insider attacks to be orthogonal to our research.\item The client-side system and the communication channels are properly secured and no part of the confidential matrix or the computation results can be leaked. 
\item Adversaries can see the secured matrix and the submitted plaintext vectors for secure matrix-vector computation, but nothing else.
\end{itemize}
These assumptions can be maintained and reinforced by applying appropriate security policies. 

\textbf{Protected Assets.} Data confidentiality is the central issue in our approach. While the integrity of data and computation is also an important issue, it is orthogonal to our study. Due to the space limitation, we will not cover data and computation integrity techniques \cite{wang11}, which are typically used to prevent adversaries from actively tampering with the data or computation. Therefore we can assume the ``honest but curious'' adversary model. 

\textbf{Attacker's goal.} The attacker is interested in recovering (or estimating) the matrix elements and the computing result, i.e., the eigenvectors and eigenvalues. 

\textbf{Security Definition.} The protected matrix is indistinguishable to chosen-plaintext attack (IND-CPA). The submitted plaintext vectors in the computation are no different from random samples uniformly drawn from a sufficiently large vector space (with  elements in the set, if  is the number of bits for encoding). The protocol will not reveal any additional information.  

\subsection{Data Collection}\label{sec:data}
\textbf{Representation of Data.} In order to use the Paillier encryption system all data need to be converted to \emph{non-negative big integers} \cite{paillier99}. However, in practice, we process matrices in the real value domain. A valid method to preserve the desired precision, e.g.,  decimal places, is to multiply the original value by  to scale up the values and drop the remaining decimal places. In addition, we also need to shift the values so that the domain is positive. This process is clearly reversible so that the results can be correctly recovered. With a typical key length of 1024, we have enough digits to preserve the precision. 





\textbf{Submitting data.} To prepare for collecting data, the data owner will generate one -dimensional random vector , .  is then encrypted with the Paillier public key:\\ , which is then distributed to the data collectors. 

The data collectors submit their row(s) of the matrix, denoted as  for the collector , in the encrypted form to the cloud storage. In addition, they also calculate the result of  with the following homomorphic method and submit it to the data owner. Assume  is one row of 

Note that the number of elements in  is the same as the number of rows to be submitted to the cloud by the collector, which is typically one. Finally, the data owner collects all  and decrypts them to find .


\subsection{Secure Power Iteration Protocol}


To protect the plaintext vectors submitted to the cloud in power iteration, the authorized data user must perform a few steps to prepare for the perturbation approach. Then, the client side collaborates with the cloud side to finish the secure matrix-vector multiplication in the iterations. 

\textbf{Preparing the Perturbation Pool.} The authorized data user will receive , , and the decryption key from the data owner, and then select  -dimensional random vectors, where  is small, say , and send them to the cloud. These random vectors will be used to perturb and protect the vectors  in each iteration. Let's denote them as the seed random vectors , for i=1..m, . 

For each random vector , a secure computation of  is performed in the cloud as follows. With the homomorphic properties of Pailier encryption, for the -th element of the resultant vector , we have

where  is the -th element of the vector  and  is the element  of the matrix . 
Note this secure matrix-vector computation is also used later in each iteration. The result  is sent back to the client side and decrypted for later processing. 
After the preparation stage, the authorized user holds the random vectors  and the resultant vectors , for i=1..m.


\textbf{Iteration}. The iteration stage starts with the random vector , then applies the formula  and other low-cost steps as described in the Arnoldi and Lanczos methods. It is important to protect  in each iteration - otherwise, the eigenvectors are revealed. 
We apply the following method to protect the privacy of computation, the security of which will be analyzed in detail later.

To calculate  from  and  with the Paillier homomorphic operations,  cannot be encrypted. We design a perturbation method to protect  before sending it to the cloud. The basic idea is to use a random vector  and send 

to the cloud instead, where  is a big random prime number so that  is large enough to contain all the values in the application domain. We design  with the seed random vectors generated during the preparation stage:

for , where  and  are randomly drawn from . The purpose of including  in perturbation is to provide better security, which will be discussed later. As the results,  and , have been computed in the preparation stage and the previous steps,  can be conveniently calculated by

with only the client-side vector operations (a  cost). 

Then, the cloud side will take , apply formula \ref{eq:matrix-vector2} to calculate , and send the result back. The client side decrypts  to get . With  known, we have . Once we have , it is easy to calculate  for the next iteration. Additional operations (as described in the Arnoldi and Lanczos methods) have a cost of , which can be conveniently performed with only client-side operations. 


\subsection{Cloud-side MapReduce Computation}



Data encrypted with Paillier encryption are significantly larger than the unencrypted values. With a 1024-bit key, a 64-bit double-type original value becomes a 2048-bit encrypted one, a 32-time increase. This cost cannot be avoided by using any encryption schemes based on the assumption of Diffie-Hellman or large-integer factorization \cite{katz07}. This literally turns a common-size problem to a ``big data'' problem, which requires us to exploit the parallel processing power in the cloud.   

With this problem in mind, we designed the MapReduce version of homomorphic matrix-vector multiplication. The client passes the perturbed vector  as a parameter to the MapReduce program and the cloud computes and returns . 
Below we describe the MapReduce formulation of the cloud-side computation of .

\newcommand{\map}{\ensuremath{\mbox{\bf map}}}
\newcommand{\reduce}{\ensuremath{\mbox{\bf reduce}}}
\newcommand{\partition}{\ensuremath{\mbox{\bf partition}}}
\begin{algorithm}[htb]

\caption{The MapReduce Matrix-Vector Multiplication program on encrypted matrix}
\begin{algorithmic}[1]
\STATE \map
\STATE : some rows of the encrypted matrix  that are distributed to the specific Map; : the perturbed vector sent by the client.
\FOR{each row of : }
\STATE Emit()
\ENDFOR
\end{algorithmic}
\medskip
\begin{algorithmic}[1]
\STATE \partition
\STATE : the row number; : the total number of reduces.
\STATE return ;
\end{algorithmic}
\medskip
\begin{algorithmic}[1]
\STATE \reduce()
\STATE : the row number; : the result.
\STATE Emit;
\end{algorithmic}
\end{algorithm}

The MapReduce program is rather straightforward. The Map function applies the secure matrix-vector multiplication formula (Eq. \ref{eq:matrix-vector2}), and emits the results indexed by the row number. The Map outputs are partitioned and sorted by row number and sent to the corresponding identity Reducer which writes the data segment to disk. Because we used the binary representation for the encrypted elements of the matrix,  we also designed special input/output format classes to handle the binary data.   












\subsection{Security Analysis}
The proposed algorithm consists of three components (1) data collection, (2) the random perturbation step in the client side, and (3) the matrix-vector multiplication based on data encrypted with the Paillier encryption scheme. Component (1) and (3) are secure as long as the Paillier encryption is secure. 
Thus, the security of the approach only depends on that of component (2). 

In perturbation preparation, the curious cloud provider is able to collect the initial random seed vectors  in the perturbation pool and the progressively generated perturbed vectors . In addition, the adversary could be aware that  may converge to the dominant eigenvector corresponding to the largest eigenvalue in  iterations \cite{saad11}.

\textbf{Security of  in a single run.} The first problem is whether the adversary can gain additional information by observing the known vectors  and . We want to show that: 
\begin{prop}
The known  and  do not reveal any information about .   
\end{prop} 
\begin{proof}First, we prove the  case. Other cases are similar. 
Let . Recall that Equation \ref{eq:hidden-vector} is  for . Thus, . With the known  and unknown , it is clear that if the adversary can guess  from any uniformly random sample drawn from  with non-negligible advantage, then she/he can also distinguish  from random vectors. 

Let  be represented as , where  and  is secret. If ,  and  are drawn uniformly at random, the problem of distinguishing  from uniformly random samples over  is exactly the decision version of the \emph{Learning with Errors} (LWE) problem discussed by Regev \cite{regev05}. It is already known that such  cannot be distinguished from uniformly random samples if  is randomly drawn and  are secret \cite{regev05}. Therefore,  cannot be distinguished from uniformly random samples as well. The same conclusion can be extended to the cases of  with more unknowns included. We skip the details here.

Because  cannot be distinguished from uniformly random samples, regardless of how  appears (as  will look similar with sufficiently large ),  cannot be distinguished from any set of random vectors. Thus, the series  does not help the adversary gain any additional information about .  
\end{proof} 



\textbf{Statistical Inference Attack.} The curious cloud provider may look at multiple runs of eigendecomposition conducted by different users. As all users start with the same , will the multiple runs provide an opportunity for statistical inference? Below we describe an inference attack that looks at the statistical property of the series and analyze the risk under this attack. 


Again, we start with the simplest case . The statistical inference attack treats  and  as random variables and tries to estimate  and  with random samples. Theoretically,  and . Correspondingly, the estimate . In practice, this estimation has to depend on   samples of :  observed by the attacker. We want to show that:
\begin{prop}
The proposed random perturbation method is computationally secure to the statistical inference attack.
\end{prop}
\begin{proof}
We use the  case to prove the statement. Let's analyze the statistical property of  to see the effectiveness of this attack. 
As shown in the earlier analysis,  cannot be distinguished from a uniformly random sample in the domain . In the integer domain , a uniformly random variable  has a mean value  and variance .
Thus, we can assume it is from the same distribution and each element has the properties  and , for . The estimate  of  can be established as . However, the accuracy of this estimate is determined by the variance of , which has the same variance as . With   independent samples the variance of  is

To gain sufficiently small variance for the estimation, the number of samples  would be as large as . In the case of using long integers,  will be in the range of , which can be further increased if a longer representation is used. It is impractical that the authorized users will conduct this number of computations. Therefore, the statistical inference attack is ineffective. 
\end{proof}

\subsection{Cost Analysis}
The cost of the approach can be analyzed according to the three parties we described. 

\textbf{Data Collector} needs to encrypt one vector, which costs  value encryptions, conduct one homomorphic dot product, which has a similar cost to vector encryption (see Section \ref{sec:exp}), and transmit the encrypted vector to the cloud, which has a cost of . In total, its computational and transmission costs are .

\textbf{Authorized User} needs to prepare the perturbation pool, which costs  in transmission and also  decryptions, where  is small. In power iterations, it needs  decryptions in total for getting the  eigenvectors, and  space for storing the encrypted values. As  and  are small, the client side costs are small - in general, a PC can handle such a workload. This is an important feature for users to fully enjoy the benefits of cloud computing.
 


\textbf{Cloud Side} has a  storage cost for encrypted matrix elements, as well as computation costs on MapReduce-based secure matrix-vector multiplication. Because the major cost is on the Map phase, with  Map slots in the Hadoop cluster, the total cost is about . The storage cost is proportional to the number of encrypted values, and related to the key size. 

We will conduct extensive experiments to carefully evaluate these costs.  


\section{Experiments}\label{sec:exp}


To show the effectiveness of the proposed research, we conducted a set of experiments to evaluate the efficiency of processing in the three involved parties: the data collectors, the authorized users, and the cloud.   


\subsection{Setup}
The client machine is configured with 128 GB of RAM and four quad-core AMD processors. The cloud-side MapReduce program was tested using the Hadoop cluster at Wright State University. The cluster is configured with 16 slave nodes running Apache Hadoop version 1.0.3. Each slave node is configured with 16 GB of RAM, four quad-core AMD processors, 16 map slots, 12 reduce slots, and a 64MB HDFS block size.  The cloud-side MapReduce program was implemented with Java, and the client-side programs with C++ and the GMP library (gmplib.org). 


We use a 1024-bit key in our experiments. Paillier encryption with key sizes less than 1024 is considered not secure \cite{lenstra01}. 
The experiments are conducted with simulated matrices. Because the studied problem is fundamental and general to all applications it is sufficient to use simulated data. The original matrices use double values as the elements (8 bytes per value). As discussed in section \ref{sec:data}, these matrices are converted to long integers for encryption to preserve sufficient precision. The encrypted matrices are used as input to the MapReduce jobs in the power iteration algorithm. 

\subsection{Data Collector Costs}
Each data collector in the framework will generate one vector (or a few), encrypt them, and deliver them to the cloud. In addition, it will conduct the secured vector dot-products for generating . Thus, the data collector's major costs are on vector encryption, secure vector dot-products, and transmission. These costs are determined by the basic cost of Paillier encryption (i.e., the key size) and the number of dimensions.

\begin{table}[tbh]
\centering
\scriptsize
\begin{tabular}{|c|c|c|c|c|}
\hline
\multirow{2}{*}{Encoding} & Encrypt & Dot Product & Size & Compressed \\
& (sec) & (ms) & (bytes) & (bytes) \\
\hline
Text& 56 & 3.7 & \textbf{\emph{6.1M}} & \textbf{\emph{3.5M}} \\
Binary& 56 & 3.7 & 2.5M & 2.5M\\
\hline
\end{tabular}
\caption{Data Collector costs for a 10,000-dimension vector.} \label{tab:collector-costs}
\vspace{-0.5cm}
\normalsize
\end{table}
 
We use the binary encoding scheme to minimize the size of encrypted data, which also minimizes communication and cloud storage. Basically, the size of an encrypted value in binary representation has twice the size of the encryption key, e.g. a 64-bit double-type value will become 2048-bit encrypted value with a 1024-bit key. We show a simple comparison using a 1024-bit key for a 10,000-dimension vector in Table \ref{tab:collector-costs}. 

Compared to the binary representation, a naive text representation of big integers without compression will cost about 150\% more in space (and 40\% more with compression) but the computation time is about the same. 
The binary representation does not significantly compress due to the randomized nature of encrypted values. 

\subsection{Client-side Costs in Iterations}
In each iteration of the proposed algorithm, the client side will receive the encrypted vector  from the cloud, decrypt it, regenerate a plaintext perturbed vector, and submit it for the next iteration. We will evaluate the communication, memory, and computation costs of the corresponding steps.  

The communication costs consist of receiving the encrypted vector from the cloud and sending the plaintext perturbed vector back to the cloud. We use the number of bytes to represent these costs. According to the previous discussion, an encrypted vector of 10,000 dimensions will cost 2.56M bytes, which needs to be transmitted to the client side. In comparison, the returned plain vector of 10,000 long integers has 80K bytes. These sizes are also linearly proportional to the number of dimensions.

The computational steps include decrypting the vector and constructing the new plaintext vector. Let the perturbation pool contain 10 randomly generated vectors. Table \ref{tab:client-comp-cost} shows the cost distribution with different dimensions. As observed, decryption takes most of the time. Since decryption can be easily done in parallel with a multicore processor, this cost can be further reduced.   

\begin{table}[tbh]
\centering
\scriptsize
\begin{tabular}{|c|c|c|c|c|}
\hline
Dimension &  size & Decrypt  & Other processing \\
\hline
10000& 2.56MB& 31s & 5ms \\
30000& 7.68MB &94s & 16ms \\
50000& 12.8MB & 149s & 26ms \\
\hline
\end{tabular}
\caption{Client computation costs for various vector dimensions.} \label{tab:client-comp-cost}
\vspace{-0.5cm}
\normalsize
\end{table}
The memory cost consists of the encrypted vector and the plain vectors in the perturbation pool. According to the algorithm, after each iteration, the resultant  will be added to the perturbation pool. However, since the number of iterations is normally small, the pool requires only a limited amount of memory. For example, with 10,000 dimensions and a pool size of 10, 10 iterations need only about 2M bytes of memory to hold the plain long integer vectors.


\subsection{Cloud-side Costs}
The cloud side has major costs in storing the encrypted data and computing the secure matrix-vector multiplication. Note that encrypted data has significantly larger size. It is impractical for an authorized user to download and process the data locally. We show some real numbers in Table \ref{tab:cloud-storage-cost} to give a more concrete idea of the problem scale. 



\begin{table}[tbh]
\scriptsize
\centering
\begin{tabular}{|c|c|c|}
\hline
Matrix dimension &Unencrypted (GB) & Encrypted (GB) \\
\hline
10000& 0.8 & 25.8\\
30000&7.2 & 232.0\\
50000&20.0& 645.0\\
\hline
\end{tabular}
\caption{Storage cost for matrices encrypted with a 1024-bit key.} \label{tab:cloud-storage-cost}
\vspace{-0.5cm}
\normalsize
\end{table}
 
Clearly, data in such scales cannot be processed using traditional methods. Instead, we have to fully exploit the parallel processing power in the cloud. The cloud side computation consists of the secure matrix-vector multiplication. The matrix is stored in the form of row vector sets and split into data blocks of 64MB in the Hadoop file system. The MapReduce framework assigns each block to a Map. This allows sets of vector-vector dot products to occur in parallel. Because the expensive operations happen in the Map phase, the number of Maps determines the overall performance. 

\begin{figure}[tbh]
\centering
\begin{minipage}{.9\linewidth}
\centering
\includegraphics[width=\linewidth]{mr-cost-combine}
\vspace{-0.75cm}
\caption{MapReduce costs of one encrypted matrix-vector computation.  Processing cost is approximately determined by the number of Map rounds.}\label{fig:mr-cost-combine}
\end{minipage}
\vspace{-0.5cm}
\end{figure}

Figure \ref{fig:mr-cost-combine} shows the cost increase trend with different sizes of encrypted matrices. With the number of dimensions less than 10,000, the Map phase can be done in one round with the in-house Hadoop cluster. With more dimensions, more Map rounds are needed and the total time cost is proportional to the number of Map rounds. On average each Map round costs about 30-40 seconds. This shows great scalability. As we increase the size of the cluster (with more Map slots) to maintain one Map round, the overall cost will stay constant (around 40 seconds as shown in the figure). 

\begin{figure}[tbh]
\centering
\begin{minipage}{.9\linewidth}
\centering
\includegraphics[width=\linewidth]{cost-summary}
\vspace{-0.75cm}
\caption{ A summary of the cloud-side and client-side costs shows low client-side cost and the cloud-side efficiency due to the optimized MapReduce implementation. \newline }
\label{fig:cost-summary}
\end{minipage}
\end{figure}
\vspace{-0.5cm}

The overall cost distribution over the cloud and the client side for one iteration using the in-house cluster is shown in Figure \ref{fig:cost-summary}. With increased dimensions, the cloud-side cost dominates the overall cost.

   

\section{Related Work}\label{sec:related}
A framework for securely outsourcing general computations is given in \cite{gennaro10}.  However, this framework is based on Gentry's fully homomorphic encryption scheme \cite{gentry09} rendering it impractical due to the high computational costs and ciphertext sizes.  A simple test with the Scarab FHE library (hcrypt.com/scarab-library)  yielded ciphertext sizes more than ten times those generated using Paillier \cite{paillier99}.  Very recent work by Naehrig et al. \cite{naehrig11} propose a secure outsourcing solution for problems which only require the encryption scheme to be ``somewhat'' homomorphic (SHE).  They use the SHE scheme of \cite{bv11a} which provides reasonably efficient computational performance but still suffers from large ciphertexts.

Atallah et al. \cite{atallah10} use a more directed approach and present secure outsourcing solutions that are specific to large scale systems of linear equations and matrix multiplication applications.  These solutions fall short in that they leak private information, depend on multiple non-colluding servers, and require a large communication overhead, respectively.  Wang et al. \cite{wang11} use an iterative approach for solving linear equations via client-cloud collaboration.  However, their approach has several  weaknesses.  First, their approach requires that the entire unencrypted matrix be present at the client side.  Secondly, the client side must perform a problem transformation step with a computation cost of .  These weaknesses render the approach impractical for big matrices and do not fully utilize the benefit of the cloud.  

Secure multiparty computation (SMC) solutions \cite{nissim06, cramer01, kiltz07} currently exist for various linear algebra problems.  In general, the SMC solutions do not translate well to the secure outsourcing scenario. Each of the SMC parties typically holds a share of the data in plaintext form and conducts computation with it. In our approach, the cloud holds the encrypted data. In addition, the SMC approaches normally have high communication overhead between the parties, which is not desired in cloud-based computing.



\section{Conclusion}\label{sec:conclusion}
In this paper we present an iterative processing approach for finding top-k eigenvectors from encrypted data in the cloud. The security of this approach is implemented with the Paillier encryption system and an efficient random vector perturbation. It is carefully designed so that the client-side computation cost is minimized. We also develop a MapReduce program to efficiently process the cloud-side encrypted matrix-vector multiplication. The experimental results demonstrate the storage and computational costs needed to setup and use the proposed approach and show the scalability of the design. 

In future work, we will optimize our algorithm for sparse matrices and formulate techniques to detect dishonest or lazy service providers.



\bibliographystyle{IEEEtrans}
\bibliography{paper,paper_jim} 

\end{document}
