

\section{Experiment}
\subsection{Dataset}

The MUSDB18-HQ dataset~\cite{MUSDB18} consists of 150 songs, each sampled at 44100 Hz with 2 channels. Each song contains 4 independent tracks: 'vocals', 'drums', 'bass', and 'other'. For our experiment, the dataset is split into a training set with 86 songs, a test set with 50 songs, and the remaining 14 songs are left for hyperparameter tuning. For data augmentation, we use pitch shift semitone in \{-2, -1, 0, 1, 2\} and time stretch with the percentage in \{-20, -10, 0, 10, 20\}.

\subsection{Experimental Setup}
We use AdamW optimizer with learning rate  for our model. The model is trained on 6 second chunks with L1 loss rather than L2 on waveforms, since some of the training data is unclean\footnote{E.g. 'The So So Glos - Emergency' and 'The Districts - Vermont' at 1:44.}. We use two A40 GPUs with batch sizes of 8 each. For MUSDB18-HQ training, the epoch size is set to 3240 chunks and the model is trained for 4082 epochs. For fine-tuning, the epoch size is set to 324 chunks and the model is trained for 300 epochs. In both scenarios, we picked the model that has the best Utterance-level SDR (uSDR)~\cite{mitsufuji_music_2022} on the validation set. 

For STFT, we use a window size of 6144 and hop length 1024. For 'vocals', 'drums' and 'other', we cut the frequency bins to 2048~\cite{kimKUIELabMDXNetTwoStreamNeural2021}. We set the bottleneck factor  in TDF of Fig.~\ref{fig:v3}. For 'bass', we cut the frequency bins to 864 and we set  in TDF. For IDPM, we set L = 4 and ensure that each Group Norm has 16 channels~\cite{wu_group_2018}. We set  for the up/down-sampling layers as shown in Fig.~\ref{fig:arch}.

\subsection{Evaluation Metrics}
We use Source-to-Distortion Ratio (SDR) for performance measurement.

\noindent \textbf{Chunk-level SDR (cSDR)}~\cite{SiSEC18} calculates SDR on 1 second chunks and reports the median value.


\noindent \textbf{Utterance-level SDR (uSDR)}~\cite{mitsufuji_music_2022} calculates the SDR for each song and reports its mean value.



\section{Results and Discussion}
\subsection{Hyper-parameters and Performance}
In this section, we experiment with different combinations of hyper-parameters and study the impact on the cSDR, uSDR and inference time. The results are presented in Table~\ref{tbl:hyer}.

\noindent \textbf{TFC-TDF Block} We noticed that TFC-TDF v3 residual block is more effective than TFC-TDF v2, significantly improving SDRs with minimal impact on training time.

\noindent \textbf{Heads and Channels} Increasing the number of channels  from 32 to 48 offers slightly better performance but results in 4x more inference time. It was observed that inference time is appreciably reduced by setting  compared to  provided . However, it takes double the epochs to attain the same level of SDRs while maintaining similar training times.

\noindent \textbf{Layers of IDPM} Increasing the repeats  of IDPM significantly increases the inference time, however, the SDRs tend to decrease. Hence, setting  is sufficient to achieve good SDRs and inference time as compared to .


\begin{table}[h]
    \centering
    \caption{Validation Set SDRs for 'vocals'. Experiments are carried out on mono audio (mid-channel) with 1500 epochs. The inference time is measured on a single RTX 3090 (24 GB) with a 3 minute input audio. Batch size is set to 4.}\label{tbl:hyer}
    \begin{tabular}{cccc|ccc}\hline
        g& H &  L& block&cSDR &uSDR & inference time\\\hline
        32 &2 &  4& v2& 8.78 & 10.05 & 3.6 s\\
\textbf{48}& 2 & 4& v2 & 9.17 & 10.42 & 15.8 s\\
        32 &\textbf{1} & 4& v2& 8.97 & 10.26 & 12.9 s\\
        32 & \textbf{1} &  \textbf{10}& v2 & 8.93 & 10.14 & 30.6 s\\
        32 &2 &  4& \textbf{v3}&\textbf{9.41}&\textbf{10.50}& \textbf{2.34} s
        \\\hline
    \end{tabular}
	
\end{table}





\subsection{Study on Generalization Ability}
As depicted in Table~\ref{tbl:gen}, for untuned DTTNet, the uSDRs of the intricate test patterns in the bespoke dataset are lower compared to MUSDB18-HQ test set. The uSDR for \textit{All} patterns (MUSDB18-HQ + intricate patterns) is 5.64 dB lower than the MUSDB18-HQ for untuned DTTNet. 


For each pattern, DTT + VC outperforms DTT + NVC. On the MUSDB18-HQ test set, we observed 0.07 dB uSDR improvement for DTT + VC compared to DTT. When considering all the patterns, the uSDR for DTT + VC is 5.67 dB higher than the uSDR of DTT possibly because of the diversity of the patterns during training. Additionally, for \textit{Vocal Chops}, DTT + NVC shows lower uSDR possibly because this pattern does not appear in the training data leading to overfitting.

Furthermore, although we obtained 0.07 dB uSDR improvement on the MUSDB18-HQ test set using DTT + VC, cSDR drops by 0.12 dB compared to DTT. This suggests that our bespoke dataset is slightly smaller, posing a risk of overfitting.








\begin{table}[h]
    \centering
    \caption{uSDR results on various test sets, with the best performance highlighted in boldface.}\label{tbl:gen}
    \begin{adjustbox}{width=0.45\textwidth}
    \begin{tabular}{cccc}\hline


        Test Set &DTT &DTT + NVC &DTT + VC\\\hline



MUSDB18-HQ & 10.15 & 10.07 & \textbf{10.22} \\ 
+ Wah Guitar & 7.97 & 9.73 & \textbf{10.04} \\ 
+ Horns & 8.23 & 9.95 & \textbf{10.14} \\ 
+ Sirens & 6.07 & 9.71 & \textbf{9.91} \\ 
+ Up-filters & 8.56 & 9.72 & \textbf{9.97} \\ 
+ Vocal Chops & 9.90 & 9.10 & \textbf{10.87} \\ 
+ All & 4.51 & 8.38 & \textbf{10.18} \\ 
\hline
    \end{tabular}
    \end{adjustbox}
	
\end{table}

\subsection{Comparison with the State-of-the-art (SOTA)}
As indicated in Table~\ref{results}, our DTTNet achieves higher cSDR on the 'vocals' track against BSRNN (SOTA) with only 13.3\% of its parameter size. Moreover, we also achieved a higher cSDR on the 'other' track compared to TFC-TDF UNet v3 (SOTA) with only 28.6\% of its parameter size.
\begin{table}[h]
    \centering
    \caption{cSDR in dB on MUSDB18-HQ Test Set. For parameter size (Params), we measure the single source model times the number of sources.  uses bag of 4 models. The parameter of  is measured based on the available code.\protect\footnotemark}\label{results}
    \begin{adjustbox}{width=0.48\textwidth}
    \begin{tabular}{c cccc c}\hline
        Model &vocals &drums & bass & other  & Params
        \\\hline

ResUNetDecouple+~\cite{kong_decoupling_2021}& 
        8.98 & 6.62 & 6.04 & 5.29  & 102.0 M  4\\
        
        CWS-PResUNet~\cite{liu_cws-presunet_2021} & 
        8.9 &  6.38  & 5.93 & 5.84  & 202.6 M  4\\
        
        Hybrid Demucs (v3)~\cite{defossez_hybrid_2021} & 
        8.13 &  8.24 &  \textbf{8.76} &5.59  & 83.6 M  4\\
        
        HT Demucs~\cite{rouard_hybrid_2022} & 
        7.93 &  7.94 &  8.48 & 5.72  &  42.0 M\\
        
        BSRNN~\cite{luo_music_2022} & 
        10.01 &  \textbf{9.01} &  7.22& 6.70& 37.6 M  4\\
        
        KUIELab-MDX-Net~\cite{kimKUIELabMDXNetTwoStreamNeural2021} &8.97  &7.20  &7.83 &5.90  & 7.4 M  4\\
        
        TFC-TDF UNet v3~\cite{kim_sound_2023} & 
        9.59 &  8.44 &  8.45 & 6.86 & 70.0 M\\\hline
        
        
        \textbf{DTTNet (Proposed)} & \textbf{10.12} & 7.74 & 7.45 & \textbf{6.92} & \textbf{5.0 M  4} \\ 
\hline 
    \end{tabular}
    
    \end{adjustbox}
	
\end{table}
\footnotetext{\url{https://github.com/amanteur/BandSplitRNN-Pytorch}}