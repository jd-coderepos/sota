Our ultimate goal is to learn an effective classifier from the noisy labeled dataset without any form of human supervision (i.e., label verification), prior knowledge on the target domain, or label/noise distribution. In this section, we elaborate our multi-step model training framework. As is illustrated in Fig. \ref{fig:iterative_labelnet}, we first describe vector representation, which is necessary for similarity measure and label prediction in our framework. Next, our proposed probabilistic dependence model ``NoiseRank'' is elaborated for ranking dataset examples based on their likelihood of being noisy. Finally, we discuss the iterative model training steps. 














\subsection{Vector Representation} \label{sec:rep_learning}

The vector space representation (i.e., embeddings) is a core component of our design because we rely on the vector representations to determine content similarity between examples in the given noisy dataset. Our framework is agnostic to any modality as well as the solution for learning representations. However, a high-quality representation improves the similarity measure and thus our unsupervised method for label noise detection. In Sec. \ref{sec:labelnet_classification}, we will discuss how we improve the representation through iterative training.

With the vector representation, we could determine the content similarity. More formally, let the noisy labeled dataset be denoted as $\mathcal{D} = \{(x_i, y_i)\}_{i=1}^{N}$ where $x_i\in \mathbb{R}^m$ is the vector representation for example $i$, and $y_i \in \{1,2 \dots C\}$ is the given label (potentially incorrect) with $C\geq2$ being the total number of classes in the dataset. In this work, we define instance similarity in terms of Euclidean distance between $x_i$ and $x_j$ as $d(x_i, x_j) = \| x_i - x_j \|_2$.






































\subsection {Label Noise Detection}



In this section, we first describe our process for generating class prototypes, that are representative instances selected for each of the $C$ classes in the dataset; followed by our non-parametric approach to generate label predictions, $y_i^\prime$, for each prototype $i$. Let $Y = \{y'_i\}_{i=1}^P$ denote the predictions. Next, we elaborate the proposed dependence model, named NoiseRank, to globally rank the dataset examples based on their likelihood of having incorrect labels given their vector representations, labels and predictions. 





\subsubsection {Generating class prototypes} 
\label{sec:class_prototypes} Each of the $C$ classes in the dataset can be represented by a set of class prototypes, i.e. a representative subset of instances in that class. We select the prototypes using K-means clustering on the vector space representations of instances in each class, given by the noisy labels. As a rule of thumb \cite{kodinariya2013review}, we select $\floor{\sqrt{\rho/2}}$ cluster centroids per class, where $\rho$ is the average number of instances per class in the dataset. Selecting class prototypes is beneficial towards improving scalability when the number of dataset instances grows.
We find that it is also important for robustness in high noise datasets, and K-means based selection is effective compared to randomly selected prototypes.

\subsubsection {Generating label predictions} 
\label{sec:label_pred} For each prototype instance $i$ represented by vector $x_i$, we generate the predicted label  $y_i^\prime$ by a weighted k nearest neighbor classifier, as specified in Eq. \ref{weighted_knn}.

\begin{equation}\label{weighted_knn}
    y_i^\prime = \argmax_{v \in \{1,2\dots C\}} \sum_{x_j \in \mathcal{N}(x_i)} \kappa(x_i, x_j) \mathbbm{1}\{y_j=v\}
\end{equation}

where $\mathbbm{1}$ is the indicator function, and the distance kernel function $\kappa(x_i, x_j)$ is used to weigh the contribution of each neighbor $x_j$ in the neighborhood $\mathcal{N}$ comprising the $k$ nearest neighbors of $x_i$:  

\begin{equation} \label{eq:dist_kernel}
    \kappa(x_i, x_j) = \frac{1}{b + d(x_i, x_j)^e}
\end{equation}
where $d(x_i, x_j)$ is the distance function discussed in Sec.~\ref{sec:rep_learning}, and $b>0$ and $e>0$ are parameters for the bias and weight exponent, respectively. The kernel function is negatively correlated to the distance function. For example, when $e=2$, the kernel will be inversely proportional to the squared distance between the instances. Since $0 \leq d(x_i, x_j) \leq \infty$, by setting a positive bias $b$, we can prevent $\kappa(x_i, x_j)$ from being undefined when $d=0$.

\subsubsection {Dependence Model Formulation} \label{sec:dep_formulate}

Our formulation is to estimate the posterior probability $P(x_{i}, y_{i}|\mathcal{D}, Y)$ that indicates the likelihood of label noise for all examples $(x_{i},y_{i})$ in the dataset $\mathcal{D}$ and rank them based on this estimate. 
For this purpose, we use Markov Random Fields (also known as MRFs or ``dependence models'' \cite{MetzlerMRF05,YalnizPAMI19}) which provide a generic framework for modeling the joint distribution of a large set of random variables. 

In dependence models, conditional dependencies are defined only for certain groups of random variables called ``cliques'', and are represented with edges in an undirected graph. We represent the graph with $G$ and the cliques in the graph as $C(G)$ in our formulations. For each type of clique $c\in C(G)$, we define a non-negative potential function $\phi(c;\Lambda)$ parameterized by $\Lambda$. The joint probabilities are estimated based on the Markov assumption as follows:

\begin{equation} \label{eq:mrf}
P(x_{i},y_{i},\mathcal{D},Y) = \frac{1}{Z} \prod_{c\in C(G)} \phi(c;\Lambda)
\end{equation}
where $Z = \sum_{x_{i},y_{i},\mathcal{D}, Y}\prod_{c\in C(G)} \phi(c;\Lambda)$ is a normalization term.
Computing $Z$ is very expensive due to the large number of summands. Since our aim is to rank examples in the dataset based on their posterior probabilities $P(x_{i},y_{i}|\mathcal{D},Y)$ and ignoring $Z$ in this formulation does not change the ranking result, the posterior probability is estimated as follows:  
\begin{eqnarray}
P(x_{i},y_{i}|\mathcal{D},Y) &=& \frac{P(x_{i},y_{i},\mathcal{D},Y)}{P(\mathcal{D},Y)} \\ \nonumber
 & \; {\buildrel {rank} \over =}\; & \log P(x_{i},y_{i},\mathcal{D},Y) - \log P(\mathcal{D},Y) \\
 \nonumber
 & \; {\buildrel {rank} \over =}\;& \sum_{c\in C(G)} \log \phi(c;\Lambda)
\end{eqnarray}
where $\; {\buildrel {rank} \over =}\;$ indicates rank equivalence. The formulation is a sum of logarithm of potential functions over all cliques. For simplification purposes, the potential function is assumed to be $\phi(c;\Lambda) = \exp(\lambda_c f(c))$,
where $f(c)$ is the feature function over the clique $c$ and
$\lambda_c$ is the weight for the feature function.
The final ranking function is computationally tractable and linear over feature functions:
\begin{equation}
P(x_{i},y_{i}|\mathcal{D},Y) \; {\buildrel {rank} \over =}\; \sum_{c\in C(G)}
\lambda_c f(c) 
\label{eq:rankfunction}
\end{equation}

Depending on the choice of the feature functions and their corresponding weights, the final ranking score in~\ref{eq:rankfunction} can be negative. In the next subsection, we elaborate our dependence model for the task of label noise detection by explicitly defining each clique, its feature function $f(c)$ and the corresponding weight $\lambda_c$.







\subsubsection{Dependence Graph Construction}

\begin{figure}[t]
\centering
\includegraphics[width=85mm]{img/dependence_graph_fixed.png}
\caption{The dependence graph illustrated for a given example $i$ in a database containing five examples. Clique types and weights are determined based on the given $y_i$ and $y_j$ and predicted labels $y_j^\prime$. Edge lengths indicate distance in the vector representation space}
\label{fig:dependence_graph}
\end{figure}








In our formulation, we define cliques between all pairs of examples $(i,j)$ where $i \neq j$ and $i \in \mathcal{D}, j \in P$ for dataset $\mathcal{D}$ with size $N$ and set of all prototypes $P \subseteq \mathcal{D}$. There are $\mathcal{O}(N|P|)$ cliques defined in the dependence graph. 
Each example is associated with its given label $y_i$ and each prototype is associated with its given label $y_j$ and predicted label $y_j^\prime$, which are used for determining the clique weights as shown in Fig. \ref{fig:dependence_graph} and explained below.
All cliques are assumed to share the same feature function $f(c) = \kappa(x_i, x_j)$ as defined by the kernel function in Eq. \ref{eq:dist_kernel}. 











We differentiate cliques into four types based on the values of the given and predicted labels of the examples. 
The first clique type, denoted by $c_{11}$, is for all pairs of examples $(i, j)$ that share the same given label. If the examples share the same label (i.e., $y_i = y_j$), we assign a negative ``blame'' score (i.e., reward) weighted by $f(c)$ to example $i$ so that it ranks lower in the final rank list of examples sorted by their overall MRF scores. For this clique type, we set the clique weight parameter as $\lambda_c = -1$. 

The second clique type is denoted by $c_{10}$. It is defined for all pairs of examples $(i, j)$ with different labels (i.e., $y_i \neq y_j$) where $y_{j}^\prime = y_{j}$. In this case, example $j$ blames example $i$ for providing an incorrect prediction vote, even though the false vote did not change the prediction output $y_{j}^\prime$ which is consistent with example $j$'s original label $y_j$. For this type, we set $\lambda_c = 1 - \alpha$, where $\alpha$ is a hyper-parameter defined in the range $[0.5,1]$ to control the impact of incorrect vote (i.e., $y_j^\prime \neq y_i)$ on the blame score. 







The third clique type, denoted by $c_{01}$, is for all pairs of examples $(i, j)$ with different labels (i.e., $y_i \neq y_j$) where $y_{j}^\prime \neq y_{j}$ and $y_{j}^\prime \neq y_{i}$. In other words, the prediction output $y_{j}^\prime$ is different from both its own label $y_{j}$ and example $i$'s label $y_i$. While example $i$ did not directly influence the mispredicted label, it did not contribute towards the correct prediction. By setting $\lambda_c = \alpha$, example $j$ assigns a scaled blame score to example $i$.



The fourth clique type, denoted by $c_{00}$, is for all pairs of examples $(i, j)$ with different labels (i.e., $y_i \neq y_j$) where $y_{j}^\prime \neq y_{j}$ and $y_{j}^\prime = y_{i}$. Example $j$ blames example $i$ strongly for supporting a prediction different from its own label $y_j$ which is the same as its prediction $y_j^\prime$. For this type, we set $\lambda_c = \alpha \times b_{f}$ where $b_{f}$ in $[1,inf)$ is the ``blame factor'' and controls the strength of the blame.










\subsubsection{NoiseRank Score Function}




The final ranking function in Eq. \ref{eq:combined_score_func} is the sum of all blame and reward scores accumulated for example $i$ according to Eq. \ref{eq:rankfunction}. 


\begin{eqnarray}
\left.
\begin{aligned} 
&P(x_{i},y_{i}|\mathcal{D},Y) \; {\buildrel {rank} \over =}\;          
  \sum_{(x_i, x_j)\in c_{11}} -\kappa(x_i, x_j) \\ 
&+ \sum_{(x_i, x_j) \in c_{10}} (1 - \alpha) \kappa(x_i, x_j) 
+ \sum_{(x_i, x_j) \in c_{01}} \alpha \kappa(x_i, x_j)  \\ 
&+ \sum_{(x_i, x_j) \in c_{00}} (\alpha \times b_f) \kappa(x_i, x_j)
\end{aligned} \right.
\label{eq:combined_score_func}
\end{eqnarray}
The aggregate score $P(x_{i},y_{i}|\mathcal{D},Y)$ is the basis for ranking instances in the dataset. The rank reflects the relative likelihood of being mislabeled and the impact on mispredictions, accounted for in the penalty function. Since the score function is unbounded, detecting label noise given the ranked list requires threshold $\delta \geq 0$ to determine if an instance with detected label noise should be retained ($w=1$) or removed ($w=0$) from the dataset.

\begin{equation} \label{eq:discard}
    w(x_i)=\begin{cases}
    0, & \text{if $P(x_{i},y_{i}|\mathcal{D},Y) > \delta $} \\
    1, & \text{otherwise}
    \end{cases}
\end{equation}








It should be noted that as the dataset size increases, computing the ranking function over all $\mathcal{O}(N|P|)$ pairs is less efficient. Moreover, the value of the feature function $f(c)$ approaches zero as distances between pairs increase. We therefore limit the cliques to the $k$ closest neighbors of example $i$ for assigning blame and reward scores as defined above. This approximation is quite effective especially because the blame and reward scores diminish rapidly and approach zero as distances get larger. 
Another note is that we use the same $k$ value in the score function and in the kernel function (Eq.~\ref{eq:dist_kernel}) for both computing the aggregate rank score function and generating label predictions $y_j^\prime$ for simplification purposes. 












\subsection{Iterative Training}\label{sec:labelnet_classification}
We provide a generic iterative framework to learn classifiers with label noise reduction. As described earlier, the vector space representations of examples in the dataset are used in determining content similarity for noise ranking. Initially, representations can be learned with the available (potentially noisy) labels. In order to improve the learned representations, we can iterate over representation learning, noise ranking and reduction, model training, in order.

The framework is agnostic to the model used for representation learning and classification, depending on the content modality. At a first step, we train the classifier model (eg. standard CNN with simple cross-entropy loss) with the available noisy dataset $D$. The classifier can be used to extract representations for examples in the dataset, which are used to run label noise detection with \algName and remove the examples that are ranked as noisy (i.e., $w(x_i)=0$). Finally, we fine-tune the trained model with the denoised subset of the dataset. 








