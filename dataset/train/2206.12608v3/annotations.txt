[{'LEADERBOARD': {'Task': 'Machine Reading Comprehension', 'Dataset': 'DREAM', 'Metric': 'Accuracy', 'Score': '69.2'}}, {'LEADERBOARD': {'Task': 'Machine Reading Comprehension', 'Dataset': 'DREAM', 'Metric': 'Accuracy', 'Score': '64.3'}}, {'LEADERBOARD': {'Task': 'Natural Language Inference', 'Dataset': 'QNLI', 'Metric': 'Accuracy', 'Score': '93.6%'}}, {'LEADERBOARD': {'Task': 'Natural Language Inference', 'Dataset': 'QNLI', 'Metric': 'Accuracy', 'Score': '91.4%'}}, {'LEADERBOARD': {'Task': 'Natural Language Inference', 'Dataset': 'MultiNLI', 'Metric': 'Matched', 'Score': '88'}}, {'LEADERBOARD': {'Task': 'Natural Language Inference', 'Dataset': 'MultiNLI', 'Metric': 'Matched', 'Score': '85'}}, {'LEADERBOARD': {'Task': 'Semantic Textual Similarity', 'Dataset': 'STS Benchmark', 'Metric': 'Spearman Correlation', 'Score': '0.892'}}, {'LEADERBOARD': {'Task': 'Semantic Textual Similarity', 'Dataset': 'STS Benchmark', 'Metric': 'Spearman Correlation', 'Score': '0.865'}}, {'LEADERBOARD': {'Task': 'Sentiment Analysis', 'Dataset': 'SST-2 Binary classification', 'Metric': 'Accuracy', 'Score': '96.3'}}, {'LEADERBOARD': {'Task': 'Sentiment Analysis', 'Dataset': 'SST-2 Binary classification', 'Metric': 'Accuracy', 'Score': '94.1'}}, {'LEADERBOARD': {'Task': 'Named Entity Recognition (NER)', 'Dataset': 'WNUT 2017', 'Metric': 'F1', 'Score': '57.3'}}, {'LEADERBOARD': {'Task': 'Named Entity Recognition (NER)', 'Dataset': 'WNUT 2017', 'Metric': 'F1', 'Score': '49.8'}}]
