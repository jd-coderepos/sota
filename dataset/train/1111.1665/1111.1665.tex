\documentclass[11pt]{article}
\pdfoutput=1
\usepackage[left=1in,right=1in,top=1in,bottom=1in]{geometry}
\usepackage{latexsym}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{graphicx}
\usepackage{url}
\usepackage[belowskip=-5pt,aboveskip=0pt]{caption}

\newtheorem{theorem}{Theorem}
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{corollary}[theorem]{Corollary}

\newenvironment{proof}{\noindent\textbf{Proof: }\ignorespaces}
  {\hspace*{\fill}\medskip}


\def\A{{\mathcal{A}}}

\title{De-amortizing Binary Search Trees}
\author{Prosenjit Bose, S\'ebastien Collette, Rolf Fagerberg and
  Stefan Langerman}


\author{
Prosenjit Bose\thanks{School of Computer Science, Carleton
University. Email: \texttt{jit@scs.carleton.ca}. Research supported in
part by NSERC.}
\and
S\'ebastien Collette\thanks{Charg\'e de recherches du F.R.S.-FNRS,
  Département d'Informatique, Universit\'e Libre de Bruxelles. 
Email: \texttt{secollet@ulb.ac.be}.}
\and
Rolf Fagerberg\thanks{Department of Mathematics and Computer Science,
University of Southern Denmark. Email: \texttt{rolf@imada.sdu.dk}.
Partially supported by
the Danish Council for Independent Research, Natural Sciences.}
\and 
Stefan Langerman\thanks{Ma{\^\i}tre de recherches du F.R.S.-FNRS,
  Département d'Informatique, Universit\'e Libre de Bruxelles. 
Email: \texttt{stefan.langerman@ulb.ac.be}.}
}

\date{}

\begin{document}
\maketitle
\abstract{
We present a general method for de-amortizing essentially any
Binary Search Tree (BST) algorithm. In particular, by transforming Splay
Trees, our method produces a BST that has the same asymptotic cost as Splay
Trees on any access sequence while performing each search in 
worst case time.  By transforming Multi-Splay Trees, we obtain a BST that
is  competitive, satisfies the scanning theorem, the static
optimality theorem, the static finger theorem, the working set theorem,
and performs each search in  worst case time.
Moreover, we prove that if there is a dynamically optimal BST algorithm,
then there is a dynamically optimal BST algorithm that answers every search
in  worst case time.
}

\thispagestyle{empty}

\newpage

\setcounter{page}{1}

\section{Introduction}

Over half a century since the discovery of rotation-based Binary Search
Trees, their exact performance is still not fully understood.
The very first works on BST focused on maintaining the tree balanced
( height and search time) after performing insertions and
deletions  \cite{avl,redblack}, or guaranteeing better average case bounds
for searches with known distributions \cite{optimum1}.

By introducing splay trees \cite{splay}, Sleator and Tarjan proposed an
alternate view of the problem, where instead of looking at the cost of
individual searches, it is the entire cost of a sequence of accesses
which is bounded, using amortized analysis.

The purpose of this article is to show that the two approaches are not
exclusive---i.e., that it is possible to combine the good amortized
performances of self-adjusting and other adaptive BST with strong worst
case guarantees for individual searches.

\paragraph{The BST Model.}
In order to describe accurately our results, we choose one BST model among
several existing standard variants, most of which are asymptotically
equivalent. In line with previous work, we will not consider insertions and
deletions. Hence, our BST model consists of a binary search tree 
containing the  distinct keys  with their natural
order. The position of a finger, initially at the root of , is
maintained, and the following two \emph{BST operations}, each of unit cost,
are allowed: 1) moving the finger from a node to its parent or to one of
its children, and 2) performing a rotation between the node pointed to by
the finger and its parent.

Given the current tree~ and the current finger position, an
\emph{access} to a key  is a list of BST operations (finger movements
and rotations), during which the finger position is at the node containing
 at least once.

For an input sequence  of keys to be accessed, a
BST algorithm  that \emph{realizes}  returns a list  of BST
operations for accessing the keys  in that order---that
is, where  is a subsequence of the sequence of keys pointed to by the
finger during the execution of .  An \emph{offline} algorithm 
is given the entire sequence  and the starting tree  as input and
then outputs the sequence of operations , while an \emph{online}
algorithm is fed the keys from~ one by one and must output the BST
operations for the access of one key before the next key is given. More
formally, A is online if  is a prefix of  whenever  is a
prefix of . The \emph{cost} of  is the number of BST operations
it contains.

Note that the model, as all the standard variants of the BST model used in
competitive analysis of online BST algorithms, only requires the algorithm
to list the BST operations~ to be performed (see, e.g, \cite{wilber89}). In particular, the
model does not restrict how those operations are generated, what auxiliary
memory is used in order to generated them, or even how much time is used to
generate them.

Of course, real-world implementations of practical BST algorithms have some
sensible limits on their time and space usage. In fact, almost all BST
implementations in the literature besides adhering to the standard BST
model described above
also have the following additional features: they work in the pointer
machine model, use no more space than the tree itself plus  words of
balance information in each node of the tree and  extra working
variables, and generate their access sequence~ in time proportional
to the BST model cost of . The majority of this paper is devoted to
showing how to de-amortize BST algorithms, with a method working in the
standard BST model. As a final step, we show how to extend the method to
maintain the additional features just listed, should the BST algorithm
being de-amortized have these.
 
Denote by  the best offline algorithm, that is,  is a
shortest possible list of operations that realizes . An algorithm 
(online or offline) is {\em -competitive} if we have  for all sequences~. It is {\em dynamically
optimal} if it is -competitive.

\paragraph{Prior works}
The study of self-adjusting BSTs to minimize the overall cost over a
sequence of accesses was initiated by Allen and Munro \cite{allen}
with their analysis of the move-to-root and the simple exchange
heuristics, and then by Sleator and Tarjan with the introduction of
Splay trees \cite{splay}, which they conjectured to be dynamically
optimal.  They show how the running time of Splay trees can be upper
bounded in several ways as a function of the access sequence. They
prove the \emph{balance theorem} (accesses run in 
amortized), the \emph{static optimality theorem} (any sequence of
accesses runs within a constant factor of the time to run it on the
best possible static tree for that sequence; in particular it reaches
the entropy bound), the static finger theorem (access  runs
in , where  is the number of keys between the
query item  and any fixed \emph{finger} element ), the
\emph{working set theorem} (access  runs in time 
where  is the number of distinct elements accessed since the
previous access to ), and the \emph{scanning theorem} (accessing
all nodes in symmetric order takes time ). They also conjectured
the \emph{dynamic finger theorem} (access to  runs in amortized
 where  is the previous item in the access
sequence), which was subsequently proved by Cole \cite{cole,cole2}.
All bounds above are amortized.

On another front, Wilber \cite{wilber89} gave a formal analysis of
several variants of the BST model, providing equivalence reductions
between them, and provided two lower bounds on the number of
operations that any BST algorithm must perform for a given sequence.
In particular, he proved that the bit reversal sequence requires
 amortized operations per access. 
These lower bounds were recently generalized
in \cite{rectcover,BST_SODA2009}. 
Splay trees were also shown to be \emph{key independent optimal}
\cite{keyindependent}, that is, they are -competitive if the order of the
keys is arbitrary or random, and that they are -competitive with
respect to a wide class of balanced BST algorithms \cite{Georgakopoulos200464}.

New bounds have been designed: the \emph{queueish} bound (opposite of the
working set bound: the number of elements \emph{not} accessed since
the last access to ) was shown not to be achievable by any BST algorithm
\cite{queaps}. Recent papers have attempted to engineer a BST that satisfies the
unified property, a bound that implies both the dynamic finger and the working set
bound \cite{unified,unified2}. The \emph{skip-splay trees} \cite{skipsplay}
perform each access within a multiplicative factor  of
the unified bound, amortized. The \emph{layered working set trees} \cite{workingsettrees}
are BSTs that achieve the working set bound worst case. By combining
it with the skip-splay structure, the authors show how to achieve the
unified bound, amortized, with an additive cost of . 

The first significant breakthrough on the competitive analysis of BST
algorithms came with the invention of \emph{tango trees} \cite{tangotrees}, the first
provably -competitive BST. This result was subsequently
improved independently by the \emph{multi-splay trees}
\cite{multisplay} and the \emph{chain-splay trees} \cite{chain-splay} which both offer
the additional guarantee of performing each access in 
amortized time. Further properties of multi-splay trees were proved in
\cite{multisplayprop}, where they were shown to satisfy static
optimality, the static finger property, the working set property, and
key-independent optimality. They further satisfy the dequeue property
which is not known to be satisfied by splay trees.

In recent years, the question was raised as to whether the good
amortized properties could be reconciled with the  worst
case bounds satisfied by well balanced trees such as AVL or red-black
trees.
Such results were known for static trees \cite{balancestatic}, however
recent works gave indication that strong balance constraints at every
node forces the working set bound to be an amortized lower bound, thus forbidding
any such tree to have stronger properties such as the dynamic finger property
\cite{skiplists_SODA08} (the proof was given for self-adjusting
skip-lists and B-trees, however the proofs can easily be adapted to
BST with balance constraints at every node). However, it remained open
whether relaxing the balance condition to just bounding the height of
the tree would be compatible with obtaining better amortized performances.
In \cite{competworstcase}, a BST based on Tango trees \cite{tangotrees} is engineered to be both
-competitive and guarantees  worst case
access time for each access. However, this structure is unlikely to
possess all the other desirable properties of Splay trees.

\paragraph{Our results}

In this article we show that it is possible to automatically transform \emph{any}
BST algorithm into one that provides worst case time guarantees per access
while keeping the same asymptotic amortized running times. Our core result
shows how to keep a BST balanced while losing only a constant factor in the
running time:
\begin{itemize}
\item Any BST algorithm  on tree  can be transformed into a BST
algorithm  on a tree  whose amortized cost is within a constant
factor of the original algorithm, and for which the depth of  is always
. If  is online, so is .
\end{itemize}
Using this, we then show how to de-amortize the BST and answer each query
in  worst case cost:
\begin{itemize}
\item Any BST algorithm  on tree  can be transformed into a BST
algorithm  on tree  such that for any access sequence ,
 and each access to a node is performed in  operations worst case. If  is online, so is .
\end{itemize}

Finally, we show that we can extend the method to maintain the additional
features of real-world online BST algorithms described above, in a way
which turns amortized upper bounds on the BST algorithm into worst case
performance per access. In particular, we have:

\begin{itemize}
\item Any online BST algorithm  on tree  that performs  accesses
in  operations can be transformed into an online BST
algorithm  on tree  such that for any access sequence ,
 and each access to a node is performed in  operations worst case.
If  works in the pointer machine model, with working space being 
words of information in the nodes and  global working variables, and
computes each access to a key in time proportional to the number of BST
operation of the access, then so does .

\end{itemize}

Applying this transformation to Splay trees, we obtain a BST that
executes every sequence within a constant factor of the Splay tree and
thus satisfies the scanning theorem, the working set property, static
optimality, the key-independent optimality, the static finger
property, the dynamic finger property, and that performs each access
in  worst case. 
By transforming Multi-Splay Trees, we obtain a BST that
is  competitive, satisfies the scanning theorem, the
working set property, static optimality, the key-independent
optimality, the static finger property, and
performs each search in  worst case time. 
Furthermore, if there is a dynamically optimal BST algorithm, then
there is one that additionally performs every search in 
operations worst case.

\paragraph{Structure of paper}

In the next section we show how to implement a stack as a binary
search tree with bounded height. This will be used as a building block
in Section~\ref{sec:simulation} to simulate the operations of any BST
using another BST of bounded height. Finally, we show how to use this
rebalanced tree to de-amortize the BST algorithm in Section~\ref{sec:de-amortization}.

\section{Pop-Tarts}

We start by implementing a stack using a balanced BST. We differentiate
internal nodes, which always have two children, and leaves which have no
children (leaves can also be seen as empty pointers). In order to fit
the stack data structure in the BST model, we assume that nodes to be
pushed onto the stack appear as the parent of the root of the current
stack, and that nodes are pushed onto the stack in decreasing key order
(that is, after the push operation the old stack is the right child of
the newly inserted node, and its left child is a leaf). Our later
application of the stack structure fulfils these assumptions. An empty
stack is composed of one leaf.  The structure will maintain the
invariant that the left child of the root is always a leaf, to allow for
easy pop operations. After each push or pop operation, the structure is
allowed to perform a sequence of operations in the BST model (finger
movements and rotations), and at the end of the sequence, the finger is
back at the root. Leaves can have a weight associated to them, and we
use the convention that internal nodes all have weight 1 (it would not
be difficult to generalize these structures to support arbitrary
internal weights, however this is not necessary for our application).

A BST implementing a stack in this manner we call a
\emph{Pop-tart}\footnote{Pop-Tarts are a line of crazy good~\cite{crazygood} breakfast products that {\em pop} out of the toaster, which remind us of popping a stack. Pop-tart is a trademark of the Kellogg
Company.}. A pop-tart is \emph{good} if push and pop operations are
performed in  amortized time and  worst-case time.  It
is \emph{crazy good}~\cite{crazygood} if it is good and the depth of every leaf of weight
 is , where  is the
total weight of all leaves in the pop-tart, or  for an
unweighted pop-tart with  leaves\footnote{We slightly abuse the big-Oh notation and write
 to mean a function which is smaller than 
for some constants  and .}.

In the remainder of this section, we will describe three pop-tart
structures. The first two lay down ground concepts that will be used to
construct the third pop-tart (Chocolate), which is always crazy good.

\paragraph{Vanilla Pop-Tart.}
Implementing a good pop-tart is easy. In fact, performing no BST
operations after each push or pop operation will produce a linear tree
with exactly  time per operation. This elementary implementation
is called \emph{Vanilla Pop-Tart}.  A vanilla pop-tart will be
crazy-good if the weight of each pushed leaf is always larger than the
total weight of all other leaves in the pop-tart.

\begin{lemma}
The Vanilla Pop-Tart is crazy good if nodes are added in decreasing key
order and new leaves have weight larger or equal to the total weight of
all other leaves in the pop-tart.  That is, it uses  time per push
and pop operation and the depth of a leaf of weight  is at most
 where  is the total weight of all leaves in the
pop-tart.
\end{lemma}
\begin{proof}
The proof is by induction. If the pop-tart contains one leaf, then it is
at depth 0, this covers the base case.  Assume by induction that the
lemma is true for the right subtree of the root, which is of total
weight . Then the left child of the root is the last added leaf and
it has weight at least , thus, . The left child of the
root is at depth . Any other leaf in the tree by
induction is at depth at most .
\end{proof}

\paragraph{Cherry Pop-Tart.}
We now describe the \emph{Cherry Pop-Tart}, which is a crazy good
pop-tart if all leaves have weight 1. Although Cherry Pop-tarts are not
used explicitly in this paper, they serve as a warm up, introducing some
key concepts needed to define the Chocolate Pop-tart structure, which is
used later.

The algorithm used is a variant of a 2-4 tree implemented as a BST.  On
a high level, it may be viewed as reversing edges on the leftmost path
in a red-black tree, and then having a permanent finger at the leftmost
internal node (effectively making it the root of the BST).

In greater detail: The Cherry Pop-tart is a BST with the nodes on the
right path of the tree grouped into layers. A layer consists of
consecutive nodes on the right path, and the left subtrees of these
nodes are called \emph{crumbs}. The right child of the last node in the
layer is the top node of the next layer (except for the last layer,
where it is the original leaf of the initial empty stack). By definition
of BSTs, the layers are linearly ordered, that is, all keys in a layer
are smaller than the keys in the next layer.

We number the layers as follows: the layer containing the root is
layer~0, the next one along the right path is layer~1, and so on.  We
maintain the invariants that each layer has between 1 and 3 nodes on the
right path (hence that many crumbs), and that the crumbs pointed to by
layer~ (called \emph{-crumbs}) are perfectly balanced trees
containing exactly  leaves. See Figure~\ref{fig:cherry-pop-tart}.
\begin{figure}
\begin{center}
\includegraphics[scale=0.50]{figure1} 
\end{center}
\caption{layers and crumbs of a Cherry Pop-tart.}
\label{fig:cherry-pop-tart}
\end{figure}

The invariant is true for a pop-tart containing one node: that node is
layer~0 and it points to one -crumb (containing one leaf). When a new
node is pushed as the parent of the root, it is added to
layer~0. Layer~0 therefore has one more node and one more
-crumb. Either the new layer~0 still has no more than 3 crumbs,
maintaining the invariant, or layer~0 now has 4 -crumbs (each
composed of exactly one leaf). In this case, we perform a left rotation
between the last two nodes of the layer. This replaces the last two
nodes of the layer with one node whose left pointer points to a
-crumb. We now move that node from layer~0 to layer~1. See
Figure~\ref{fig:cherry-pop-tart-rot}.
\begin{figure}
\begin{center}
\includegraphics[scale=0.50]{figure2} 
\end{center}
\caption{Restoring the Cherry Pop-tart invariant at level~.}
\label{fig:cherry-pop-tart-rot}
\end{figure} 
Again, the reconfiguration could either stop there or ripple down
further.  In general, as a node is added as the parent of the first node
in layer , either layer  still has no more than 3
-crumbs, or we preform a rotation on the node between the last two
crumbs, forming a -crumb with twice as many leaves which is
inserted into layer . A pop operation works symmetrically, by
removing the first node of layer~0 (whose left child is a leaf) and
restoring the invariant, that is, if layer~0 contains no more nodes,
we perform a right rotation on the first node of layer~1, transforming
it into two nodes that are moved into layer~0.  If layer~1 is now empty,
we repeat the operation on the first node of layer~2 and so on.

\begin{lemma}
The Cherry Pop-Tart is crazy good if nodes are added in decreasing
key order and all leaves have weight~1. That
is, it uses  amortized time and  worst case time per
push and pop operation and its tree has height . 
\end{lemma}
\begin{proof}
To show that a push or pop operation has amortized cost
, we assign a potential of 0 to layers with 2 nodes,
and a potential of 1 to layers with 1 or 3 nodes. A push or pop
operation has actual cost proportional to the number of layers that
had to be readjusted to restore the invariant. Each readjusted layer had
a potential of 1 before the operation (i.e., had 3 nodes before a push
or 1 node before a pop) and of 0 after the operation (i.e., has 2
nodes exactly). Therefore, the decrease of potential pays exactly for
the readjustments. The insertion or deletion in the last layer possibly
increases its potential by 1, which is the amortized cost of the
operation. Therefore, this pop-tart is good.

Since layer  has at least one -crumb containing  leaves, a
pop-tart with  leaves has at most  layers, each having crumbs
of height , thus the total height of the tree is .
So in the unweighted case, this pop-tart is crazy-good.
\end{proof}

The next lemma shows that the Cherry Pop-tart is crazy-good even in
some weighted cases. 
\begin{lemma}\label{lem:cherry-pop-tart}
The Cherry Pop-Tart is crazy good if nodes are added in decreasing
key order and new leaves are added with increasing weights.
That is, it uses  amortized time per push and pop operation and
the depth of a leaf of weight  is  where  is the
total weight of all leaves in the pop-tart.
\end{lemma}
\begin{proof}
We use the exact same structure as in the previous lemma. Observe that
by the conditions in the lemma, an inorder traversal of the tree will
meet the leaves in order of decreasing weight. Since -crumbs
contain~ leaves, the layer containing the  heaviest leaf in
the pop-tart has index at most , hence has crumbs of depth at
most . So the depth of the  heaviest leaf is at most
. If the  heaviest leaf is of weight , then the
total weight  of all leaves in the pop-tart is at least , hence
the depth of that leaf is at most . Thus, the
pop-tart is crazy good.
\end{proof}

In order to allow for arbitrary weight order, we will have to modify
slightly the data structure. We call the next structure the
\emph{Chocolate Pop-Tart}.

\paragraph{Chocolate Pop-Tart.}
Again, the structure will be decomposed into a sequence of layers whose
nodes form a right path and point to crumbs. This time, the right path
of the  layer will be composed of 1 to 3 \emph{regular} nodes
whose left child is an -crumb, then a \emph{next} node whose left
child points to the next layer and whose right child points to a subtree
called the \emph{icing}. This will be called the \emph{structural invariant}.  See Figure~\ref{fig:chocoloate-pop-tart}.
\begin{figure}
\begin{center}
\includegraphics[scale=1]{figure3} 
\end{center}
\caption{Level  in the Chocolate Pop-tart.}
\label{fig:chocoloate-pop-tart}
\end{figure} 
The icing is itself a stack, implemented using a Vanilla Pop-tart (that
is, a simple linear tree), whose leaves will be
\emph{frozen}\footnote{or \emph{frosted}} subtrees of the chocolate
pop-tart. In order for the icing to be crazy-good, we will ensure that
the nodes (frosted subtrees) pushed onto it will always be at least as
heavy as the total weight of the icing.  The subtrees to be frosted and
pushed into the icing of level~ will always be the next node and the
entire subtree rooted at the top node of level .  Therefore, we
maintain the invariant that the total weight of layer  (that is,
the the total weight of the subtree rooted at the topmost node of that
layer) is smaller than the total weight of the icing of layer 
(\emph{thick icing invariant}). If
violated, layer  will be frosted and pushed into the icing, to
maintain the invariant.

The last layer, say, layer , is incomplete: it is composed of 0 to 3
regular nodes, has no pointer to the next layer, and always contains an
icing as its rightmost subtree. It can only have 0 regular nodes if the
icing contains exactly one element (which is always an -crumb).

As before, when a new node is pushed onto the -layer (starting with
), 
either the -layer has at most 3 regular nodes, in which case we are
done, or it contains 4 regular nodes and we need to restore the structural
invariant.  We start by performing a left rotation between the two
lowest regular nodes in the layer, creating an -crumb.  We have
two cases to consider. If the  layer is not the last one, then
we perform a left rotation between the next node and the lowest regular
node, to move the new -crumb and its node to the 
layer.  On the other hand, if the  layer is the last one, then
it has no next node. Then the lowest regular node becomes a next node
which points to the new  layer. That  layer
contains 0 regular nodes, no next node and an icing which contains the
-crumb as its only leaf.

Having done this, there are again two cases to consider: if the total
weight of the subtree rooted at the (new) top node of the 
layer is smaller than the total weight of the icing of the 
layer, then we proceed with the insertion of the -crumb, by
restoring the structural invariant if necessary, and so on. Otherwise, we restore
the thick icing invariant by frosting the
 layer without modifying it further (even if it contains now
4 regular nodes), and push it and its parent node (the next node of the
 layer) into the icing of the  layer. The  layer
then becomes the last layer. It has no next node and two regular nodes.

The deletion operation is symmetric: when the first regular node of the
 layer is deleted, either the layer still has at least one
regular node left, in which case we are done, or we have to restore the
structural invariant.  If  is not the last layer, we pull two nodes and their
associated -crumbs from the  layer (by performing two
right rotations and possibly recursively restoring the invariant in the
 layer).  If the  layer is only composed of an
icing (which then contains one frosted -crumb), we defrost the
icing, perform a right rotation, transforming the next layer into two
regular nodes pointing to -crumbs and the  layer becomes the
last one.  On the other hand, if  is the last layer, then we pop a
frosted subtree from the icing (unless it contains only one leaf), and
perform a right rotation to turn the frosted subtree into one regular
node and a next node, the latter pointing to the new, unfrosted,
 layer and to the remaining icing.

\begin{lemma}\label{lem:chocolate-pop-tart}
The Chocolate Pop-Tart is crazy good if nodes are added in decreasing
key order and new leaves are added with arbitrary weights.
That is, it uses  amortized time per push and pop operation and
the depth of a leaf of weight  is  where  is the
total weight of all leaves in the pop-tart.
\end{lemma}
\begin{proof}
We first show that the Chocolate Pop-tart is good, that is, it uses
 amortized time per push and pop operation.
For this, we assign a potential of 0 to layers with 2 regular nodes,
and a potential of 1 to all other layers. 
A push operation will cause a bunch of reconfigurations in successive
layers, that end in either adding a crumb to a layer that does not
overflow, or pushing an element in the icing of a layer. Either case
costs  amortized. As in the case of Cherry Pop-tarts, it is
easily verified that every layer that overflows had 3 regular nodes
before, and thus a potential of 1, and two regular nodes after, so a
potential of 0 (except possibly for the last rearranged layer).
Likewise, during a pop operation, the potential of a rearranged layer
(except the last one) goes from 1 to 0 since the number of regular
nodes it contains goes from 1 to 2.
Thus, the decrease of potential of a layer during a push or a pop pays
for its rearrangement, while the amortized cost of  pays for the
potential increase and the rearrangement in the last node and the push
in the icing if it occurs.

It now remains to prove that the depth of a node of weight  is
. 
The proof will be by induction on the layer number. Consider the subtree
rooted at the first node of the  layer and let  be the
total weight of that subtree.
Assume by induction that at any moment in the algorithm, any leaf of weight  has
depth  starting from the
root of the  layer. 
We want to show that in the subtree rooted at the first node of the
 layer, any leaf of weight  has depth 
.
Obviously, the hypothesis is true for an  layer 
that contains only an icing with one frosted -crumb,
since all its leaves are at distance ;
this covers the base case.

For a  layer, we consider the leaves located 
(i) in -crumbs pointed by regular nodes, 
(ii) in the  layer if it exists, and 
(iii) in the icing of the  layer.
Any leaf of type (i) is at distance  which is small enough.
For type (ii) leaves, notice that as long as -crumbs are being moved
from the  layer to the  layer without being
frosted and pushed to the icing, . Therefore, for
any leaf of weight  in the subtree of the  layer, the
depth of that leaf is at most 

which is below the desired bound.

Finally for case (iii), since the icing of the  layer is
implemented as a Vanilla pop-tart and the frosted subtrees are pushed
with (total) weights always larger than all other leaves (frosted
subtrees) in the icing, the icing is crazy good, that is, a frosted
subtree of total weight  will have its root at depth at most 
. 
Let  be the parent of the frosted subtree containing the node of
weight , let  be the
weight of the subtree rooted at . The depth of  is at most 
 since the left child of every node on the right
path of the icing contains at least half of the weight of that node.  
Every frosted subtree has its first node whose left pointer points to
a possibly heavy -crumb, and whose right pointer points to what
used to be the  layer at some point in time. Let  be the
weight of that  layer. Then  otherwise the
 layer would have been frosted earlier. 
By induction, a leaf of weight  in this former  layer must
have depth no more than 



which is the desired bound. 
A leaf in the -crumb pointed by the left pointer of the root node
of the frosted subtree has weight at most , and its depth is

This completes the induction proof. For , we have that any leaf
of weight  has depth at most , so the chocolate
pop-tart is crazy-good for arbitrary weights. 
\end{proof}

Note that all pop-tarts described in this section can also be flipped
to maintain elements pushed in increasing order. If the cherry or
chocolate pop-tarts need to be implemented in a real-world BST,
 extra bits of information in each node is sufficient
for storing the function of that node (regular, next, icing, crumb). 

\section{Simulation}\label{sec:simulation}
We now show how to efficiently simulate any BST algorithm while keeping
the tree of logarithmic height. The method will work for trees with
weighted nodes as well. Let  be the weight of the node with key 
and let .  For unweighted trees, set  and
.  We represent the tree  of the original BST algorithm using a
heavy path decomposition. To construct this decomposition, we denote
every edge of  as either \emph{solid} or \emph{dotted}. For each
non-leaf node, the edge to its child with largest total subtree weight
(or the left child, in case of a tie) is a solid edge, and the edge to
its other child is dotted. The solid edges form \emph{heavy paths}
connected together by dotted edges.

We simulate the original BST algorithm as follows: When its finger is at
the root of , each heavy path is implemented using a pair of weighted
pop-tarts: a heavy path from node  to node  (with  an ancestor
of ) is a sequence of nodes that can be decomposed into the
subsequence  of nodes smaller than  on the path, and the
subsequence  of nodes larger than  on the path. Note that
 is increasing, and  is decreasing. In our simulation,
the end of the path  does not change, but  can move up or down
along the path to the root. As  moves up, the new nodes are added to
 in decreasing order, or to  in increasing order.

The sequences  and  will each be stored in the weighted
chocolate pop-tart structure described in the previous section, and
these two pop-tarts will be left and right children of ,
respectively, see Fig.~\ref{fig:double-pop-tart}.
\begin{figure}
\begin{center}
\includegraphics[scale=0.50]{figure4}
\end{center}
\caption{Representing a heavy path with Pop-tarts.}
\label{fig:double-pop-tart}
\end{figure}
Each node on the path is connected via a dotted edge to a subtree which
will be considered as a leaf in the pop-tart, whose weight is exactly
the total weight of all the nodes in that subtree. The subtrees
contained in those leaves will be structured in the same manner,
recursively.  The nodes in the tree will contain two extra bits, one to
determine if the edge to its parent node is solid or dotted, and another
to determine if the next node on its heavy path is in  or
.

When the finger  is not at the root  of the tree, the path from
the finger to the the root is also represented as a pair of pop-tarts in
a similar way, but this time upside-down (see Fig.~\ref{fig:finger}).
\begin{figure}
\begin{center}
\includegraphics[scale=0.65]{figure5}
\end{center}
\caption{Representing the finger in general position.}
\label{fig:finger}
\end{figure}
Thus, as  walks down, the elements of  are added in
increasing order, and the elements of  are added in decreasing
order.  Hence, finger movements in the original BST algorithm can be
implemented using one push and one pop operation by transferring a node
from one pop-tart to the other using  rotations. Likewise,
rotations in the original BST algorithm only involve the first few nodes
on the pop-tarts linked from the finger, and thus can be implemented in
 rotations and push/pop operations. Note that the finger in the
tree maintained by our simulation always stays at the root.

Any path from the root to a node  of weight  uses at most 
dotted edges. Further, let  be the total weights of
the successive heavy paths (along with their descendants) on the path from
the root to . By Lemma~\ref{lem:chocolate-pop-tart}, the  heavy
path will be stored at depth  in the pop-tart of the
 heavy path, and node  will be at depth 
in the pop-tart of the last heavy path.  Thus, the total depth of  in
the tree is bounded by a telescoping sum that sums up to .
Clearly, if  is online, so is . We obtain:

\begin{theorem}\label{thm:simulation}
Given a BST algorithm  with a starting tree , there is a BST
algorithm  with a starting tree  such that ,
and such that the depth of a node  in  is always 
and the finger is always at the root of . If  is online, so is
.
\end{theorem}

If the simulation needs to be implemented in a real-world BST,  extra
bits per node is sufficient for storing the structure of
the original tree and the function of each node in the simulation:
each node needs to indicate wether each of its 
children is part of the same heavy path or not, and for all nodes on
the path from  to , a bit must be stored to determine if the
next node on the path is stored in  or in .
Note that if  is unbalanced, it is necessary to restructure it into
 in order to obtain the depth bound. However if the starting
position of  already have this property, we can start with
 unchanged and restructure the tree
during the execution of the algorithm every time the finger enters a
yet unexplored subtree.

\section{De-amortization}\label{sec:de-amortization}
We are now ready to show how to de-amortize BST algorithms.

\begin{theorem}\label{thm:offline}
For any BST algorithm  with a starting tree  there is a BST
algorithm  with a starting tree  such that for any access
sequence ,  and each access to a node is
performed in  operations worst case. If  is online, so is .
\end{theorem}
\begin{proof}
Using Theorem~\ref{thm:simulation}, transform  and  into  and
 such that the depth of node  in  is always  for some
constant .  Algorithm  is then modified in the following way: while
running the sequence of operations in , every time 
operations from the original  sequence have been performed without accessing the next unaccessed
element of the input sequence, access this element by moving the finger to it
and back (thereby inserting  extra BST operations into the sequence at this point).
Thus every access is performed in worst case , and the total cost of the sequence is
the same within a factor . If  is online, so is .
\end{proof}

Again, it is usually necessary to transform the starting tree in order to
achieve a  worst case bound per access, for example in the case
when  is very unbalanced.  If the starting tree  has height  however, it is not necessary to modify it and we can, as described
above, restructure the tree during the execution of the algorithm every
time the finger enters a yet unexplored subtree.

As mentioned in the introduction, real-world BST algorithms normally work
in the pointer machine model, with working space for the algorithm being
 words of information in the nodes of the tree, and  global
working variables. Additionally, they can be implemented to find their BST
operations for a key~ in time proportional to the number of these
operations (i.e., in time proportional to the cost in the BST model).

A natural goal is that our de-amortized output algorithm should adhere to
these constraints if the input algorithm does. We now describe how to do
this, given bounds on the amortized behaviour of the input BST
algorithm. In particular, we show how any real-world online BST algorithm
with  amortized time bounds (such as e.g.\ Splay Trees) can be
transformed into an online BST algorithm with  worst case time
bounds, while not changing their running time on any sequence by more than
a constant factor. In the following theorem, the formulation is slightly
more general.

\begin{theorem}\label{thm:online}
Let  be a function in . For any online BST algorithm
 that for some starting tree  is guaranteed to perform  accesses
in  operations, there is an online BST algorithm
 and a starting tree  such that  for
any access sequence , and such that  performs each access to a
node in  operations worst case.
If  works in the pointer machine model, with working space being 
words of information in the nodes and  global working variables, and
computes each access to a key in time proportional to the number of BST
operation of the access, then so does .
\end{theorem}
\begin{proof}
The general idea is the same as in Theorem~\ref{thm:offline}, except
that  is replaced by .
The main problem to overcome is that for some 's, the number of BST
operations of  may be larger than , due to the amortization
in~ (and the amortization added when transforming it into~). These
BST operations cannot all be executed before the access to  has to be
finished by a traversal of the balanced tree of~ and  has to
be served next by the online algorithm~. In short, in the execution
of~, its point in the input sequence can lag behind that of~,
and the problem is how~ efficiently can keep track of what
operations to do next when executing~.

We do this by maintaining a queue~ containing the keys whose accesses
have already been performed in  but whose BST operations in the
execution of  still have to be done. Thus,  always contains a
(possibly empty) suffix of the keys , where  is the
key last accessed by~. The  operations of the oldest key in~
may be partly executed, and we store the state of the process of  on
that key in the global variables of  (we assume such a state can be
stored in  words for~, which implies that it also can be done
for~).

To adhere to our notion of practical BST algorithms, we implement the
queue by a linked list of queue nodes, with each node of the list stored in a node of
the tree as a pair of words. The first word is the key stored at that
position in the queue and the second word is a list pointer to the next
queue node, represented by the key of the tree node containing
that queue node.  Note that following a list pointer may require walking
 steps in the tree and so enqueue or dequeue operations will
cost that much.

We now give the details of~. It uses the following three basic
routines.
\textbf{A:} Restart the  process of the last key in~, and then
perform  process work on this and the following keys~, doing a
dequeue each time the process for the last key finishes. The routine
ends when  has done  BST operations, or  runs
empty. Here,  is a constant to be determined later.
\textbf{B:} Perform  BST operations on the newest key of . The
routine ends when  such operations have been performed, or the
operations have all been done.
\textbf{C:} Access the newest key of  by a search in the tree
maintained. Enqueue the key in~.

Given these routines, the actions of~ on the next input key are:
\begin{quote}
\textbf{IF}  is not empty:\\
\mbox{}~~~~do \textbf{A}\\
\textbf{IF}  is [now] empty:\\
\mbox{}~~~~do \textbf{B}\\
\mbox{}~~~~\textbf{IF} routine \textbf{B} ended by all operations being
done: exit [skipping \textbf{C} below]\\
do \textbf{C}
\end{quote}

This takes  time worst case, since each of the routines
do. We now want to argue that  on any
sequence~, by charging all work of~ to work of  that has
been executed. There are five different types of actions of~
possible, with routine sequences as follows: \textbf{AB}, \textbf{ABC},
\textbf{AC}, \textbf{B}, and \textbf{BC}.

The action \textbf{B} starts and ends with  empty, and takes time
proportional to the work done on , hence that work can be charged.
The action \textbf{BC} starts with  empty, ends with  non-empty,
takes time , and does  work on , hence that work
can be charged.
The action \textbf{ABC} starts with  non-empty, ends with 
non-empty, has  empty in the meantime, takes time  and
does  work on , hence that work can be charged.
The action \textbf{AB} starts with  non-empty, ends with  empty,
takes time  but does possibly only  work on
. However, the action (either \textbf{BC} or \textbf{ABC}) during
which  last turned from empty to non-empty did  work on ,
hence that work can be charged.

Remaining is the action \textbf{AC}, which has  non-empty from start
to end. Note that in the \textbf{A}~part, the  BST
operations of  for  can be a couple of dequeues
(each taking  operations), all of keys for which there are a
constant amount of  work. Hence, we cannot charge the  work on a
per-action basis, and a more elaborate charging argument is needed:
Consider a sequence of  \textbf{AC} actions, following an action
(either \textbf{BC} or \textbf{ABC}) during which  last turned from
empty to non-empty. There have been exactly  elements enqueued
(during \textbf{C} parts) since the queue was last empty, of which (at
least) the last is still present. Hence, during the  \textbf{AC}
actions at most  dequeues can have been done. Also, exactly 
restarts,  key accesses via the balanced tree, and  enqueues have
been done. All these sum up to at most  BST operations
for , for some constant . Let  be a constant such that
. At least  BST operations have been done by  during the
 actions, and those not included in the sum above must be 
process work. Thus, by choosing  large enough that , at least half of the work done must be  process work. Hence, we
can charge all  work to  work executed during the  actions.

Summing up, over the entire sequence, all work of  can be charged
to executed work of , with no work of  being charged more than a
constant number of times.  Hence, . By
 from Theorem~\ref{thm:simulation}, the claim
 of Theorem~\ref{thm:online} follows.

Finally, as the queue has only room for  elements, we need to
guarantee that the queue does not overflow. The queue overflows exactly
when  \textbf{AC} actions in a row have taken place. By the argument
above, at least   work has been
executed, which for  large enough leads to a contradiction with the
guarantee on 's performance.

\end{proof}

We note that one feature of BST algorithms not maintained by
Theorem~\ref{thm:online} is the exact amount of information stored in tree
nodes, besides the search key. For classical BST algorithms, this varies
from zero bits in Splay trees, over one bit in red-black trees, two bits in
AVL-trees, to  bits in weight-balanced trees and treaps. Algorithm
 from Theorem~\ref{thm:online} always uses  bits.



\bibliographystyle{abbrv}
\bibliography{splay}

\end{document}
